<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Advanced 3D Representations | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="machine-perception">
<meta name="description" content="3D representations
In this section, we present some of the most common 3D representations used in computer graphics and computer vision. Each representation has its own advantages and disadvantages, and the choice of representation often depends on the specific application.
Voxels
With voxels we discretize 3D space into a 3d grid, it is an intuitive manner to represent the data, but it has limited resolution.
It needs $\mathcal{O}(n^{3})$ memory.
Points and Volumetric primitives
We can discretize surfaces into 3D points.
Yet, this does not model connectivity, and might vary from frame to frame if it is a video.">
<meta name="author" content="Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/advanced-3d-representations/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/advanced-3d-representations/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>






      <script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-WW6NN2QGKF');
        }
      </script><meta property="og:url" content="https://flecart.github.io/notes/advanced-3d-representations/">
  <meta property="og:site_name" content="X. Angelo Huang&#39;s Blog">
  <meta property="og:title" content="Advanced 3D Representations">
  <meta property="og:description" content="3D representations In this section, we present some of the most common 3D representations used in computer graphics and computer vision. Each representation has its own advantages and disadvantages, and the choice of representation often depends on the specific application.
Voxels With voxels we discretize 3D space into a 3d grid, it is an intuitive manner to represent the data, but it has limited resolution. It needs $\mathcal{O}(n^{3})$ memory.
Points and Volumetric primitives We can discretize surfaces into 3D points. Yet, this does not model connectivity, and might vary from frame to frame if it is a video.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="notes">
    <meta property="article:tag" content="Machine-Perception">
      <meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:title" content="Advanced 3D Representations">
<meta name="twitter:description" content="3D representations
In this section, we present some of the most common 3D representations used in computer graphics and computer vision. Each representation has its own advantages and disadvantages, and the choice of representation often depends on the specific application.
Voxels
With voxels we discretize 3D space into a 3d grid, it is an intuitive manner to represent the data, but it has limited resolution.
It needs $\mathcal{O}(n^{3})$ memory.
Points and Volumetric primitives
We can discretize surfaces into 3D points.
Yet, this does not model connectivity, and might vary from frame to frame if it is a video.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Advanced 3D Representations",
      "item": "https://flecart.github.io/notes/advanced-3d-representations/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Advanced 3D Representations",
  "name": "Advanced 3D Representations",
  "description": "3D representations In this section, we present some of the most common 3D representations used in computer graphics and computer vision. Each representation has its own advantages and disadvantages, and the choice of representation often depends on the specific application.\nVoxels With voxels we discretize 3D space into a 3d grid, it is an intuitive manner to represent the data, but it has limited resolution. It needs $\\mathcal{O}(n^{3})$ memory.\nPoints and Volumetric primitives We can discretize surfaces into 3D points. Yet, this does not model connectivity, and might vary from frame to frame if it is a video.\n",
  "keywords": [
    "machine-perception"
  ],
  "articleBody": "3D representations In this section, we present some of the most common 3D representations used in computer graphics and computer vision. Each representation has its own advantages and disadvantages, and the choice of representation often depends on the specific application.\nVoxels With voxels we discretize 3D space into a 3d grid, it is an intuitive manner to represent the data, but it has limited resolution. It needs $\\mathcal{O}(n^{3})$ memory.\nPoints and Volumetric primitives We can discretize surfaces into 3D points. Yet, this does not model connectivity, and might vary from frame to frame if it is a video.\nMany hardware cameras (like LiDAR) use this representation, and it is also used in some 3D reconstruction methods.\nMeshes We discretize vertices and faces, we know about connectivity. GPUs were made to handle this kind of data for example. Yet we have a limited number of vertices and faces (fixed resolution, which means we have an approximation error). Unreal Engine 5 Nanite has a way to decide when to use more triangles (more detail), or less (example long fields). Usually most fine-grained description is around one triangle per pixel (more is useless, you cannot render it). But as scientists, we like to represent it as continuous functions.\nImplicit Representations We can represent surfaces as the level-set of a continuous function =\u003e We have arbitrary topologies (for intro to topology see Topological Spaces). We use neural networks to approximate these implicit functions and shapes. Many many complex shapes can be represented with these implicit functions, but they need to be converted to representations above to be visualized.\nSignal Distance Fields (SDF) Normally, SDF (signal distance field $f_{\\theta} : \\mathbb{R}^{3} \\times \\mathcal{X} \\to R$) values are stored in a grid (this is quite memory consuming), meaning every cell stores the signed distance from the surface (negative means inside, positive means outside).\nNeural Implicit Representations Here we have neural networks that represent space information (if the shape is inside or outside).\nTwo representations - Occupancy Networks and DeepSDF We use simple MLP (see Neural Networks) to represent these images.\nOccupancy networks are just classification problems (you sample points, and decide if a point is inside or outside).\nDeepSDF is a regression problem, you sample points and predict the signed distance from the surface (you find level sets to know the surface).\nThe other idea is that we can use these neural fields also for color, lighting, radiance, and similar things (meaning more information)! Another nice thing is that normals are **gradients of the level set**, during backpropagation we have this information for free. The only problem when the translation to meshes happens is that at vertices, the normals are not well defined. Learning Implicit Shapes This section explores most common ways to learn the implicit representations mentioned above.\nWatertight meshes We can create some sort of a surrogate model after having a first easily renderable (but more memory costly model) in the following way:\nWith these kinds of meshes we sample 3D points in space we query occupancy to the model (this is some ground value). After creating this dataset, then you can use a cross entropy loss to train the implicit shape. Marching Cubes can extract renderable meshes from these implicit shapes, it is a way to convert the implicit representation to a mesh.\nLearning from Points See this paper -\u003e (Gropp et al. 2020). The main problem with this format is that we have no connectivity information, and we need to learn it from the data. For example if you have some points in a circle, it is not obvious to define whether if a points is actually inside or outside the circle.\nFor example, both of the following solutions are plausible: $$ \\lVert \\nabla f_{\\theta}(\\boldsymbol{x}) \\rVert_{2} = 1 $$ We won’t explain the maths behind this, but it is a way to enforce the model to learn the distance field.\n$$ \\mathcal{L}(\\theta) = \\sum_{i \\in I} \\lvert f_{\\theta}(\\boldsymbol{x}_{i}) \\rvert^{2} + \\lambda \\sum_{j \\in J} \\left( \\lVert \\nabla f_{\\theta}(\\boldsymbol{x}_{j}) \\rVert_{2} - 1\\right)^{2} $$ This was introduced from a paper in 2020 cited above.\nLearning from Images The following is the general idea of this technique:\nWe usually have video from 2D images. We model geometry and appearance with neural implicit fields. We can use a differentiable renderer to render the images, and then optimize the parameters of the implicit field with a loss function that compares the rendered images with the original ones. Once you have this renderer trained, we can use it to render new images from different viewpoints. References [1] Gropp et al. “Implicit Geometric Regularization for Learning Shapes” PMLR 2020\n",
  "wordCount" : "770",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/advanced-3d-representations/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Advanced 3D Representations
    </h1>
    <div class="post-meta">4 min&nbsp;·&nbsp;Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul><ul>
                <li>
                    <a href="#3d-representations" aria-label="3D representations">3D representations</a><ul>
                        
                <li>
                    <a href="#voxels" aria-label="Voxels">Voxels</a></li>
                <li>
                    <a href="#points-and-volumetric-primitives" aria-label="Points and Volumetric primitives">Points and Volumetric primitives</a></li>
                <li>
                    <a href="#meshes" aria-label="Meshes">Meshes</a></li>
                <li>
                    <a href="#implicit-representations" aria-label="Implicit Representations">Implicit Representations</a></li>
                <li>
                    <a href="#signal-distance-fields-sdf" aria-label="Signal Distance Fields (SDF)">Signal Distance Fields (SDF)</a></li></ul>
                </li>
                <li>
                    <a href="#neural-implicit-representations" aria-label="Neural Implicit Representations">Neural Implicit Representations</a><ul>
                        
                <li>
                    <a href="#two-representations---occupancy-networks-and-deepsdf" aria-label="Two representations - Occupancy Networks and DeepSDF">Two representations - Occupancy Networks and DeepSDF</a></li></ul>
                </li>
                <li>
                    <a href="#learning-implicit-shapes" aria-label="Learning Implicit Shapes">Learning Implicit Shapes</a><ul>
                        
                <li>
                    <a href="#watertight-meshes" aria-label="Watertight meshes">Watertight meshes</a></li>
                <li>
                    <a href="#learning-from-points" aria-label="Learning from Points">Learning from Points</a></li>
                <li>
                    <a href="#learning-from-images" aria-label="Learning from Images">Learning from Images</a></li></ul>
                </li></ul>
                    </ul>
                    
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="3d-representations">3D representations<a hidden class="anchor" aria-hidden="true" href="#3d-representations">#</a></h3>
<p>In this section, we present some of the most common 3D representations used in computer graphics and computer vision. Each representation has its own advantages and disadvantages, and the choice of representation often depends on the specific application.</p>
<h4 id="voxels">Voxels<a hidden class="anchor" aria-hidden="true" href="#voxels">#</a></h4>
<p>With voxels we <strong>discretize</strong> 3D space into a 3d grid, it is an <em>intuitive</em> manner to represent the data, but it has limited resolution.
It needs $\mathcal{O}(n^{3})$ memory.</p>
<h4 id="points-and-volumetric-primitives">Points and Volumetric primitives<a hidden class="anchor" aria-hidden="true" href="#points-and-volumetric-primitives">#</a></h4>
<p>We can discretize surfaces into 3D points.
Yet, this does not model <em>connectivity</em>, and might vary from frame to frame if it is a video.</p>
<p>Many hardware cameras (like LiDAR) use this representation, and it is also used in some 3D reconstruction methods.</p>
<h4 id="meshes">Meshes<a hidden class="anchor" aria-hidden="true" href="#meshes">#</a></h4>
<p>We discretize vertices and faces, we know about <em>connectivity</em>. GPUs were made to handle this kind of data for example.
Yet we have a limited number of vertices and faces (<strong>fixed resolution</strong>, which means we have an approximation error).
Unreal Engine 5 Nanite has a way to decide when to use more triangles (more detail), or less (example long fields). Usually most fine-grained description is around one triangle per pixel (more is useless, you cannot render it).
But as scientists, we like to represent it as continuous functions.</p>
<h4 id="implicit-representations">Implicit Representations<a hidden class="anchor" aria-hidden="true" href="#implicit-representations">#</a></h4>
<p>We can represent surfaces as the level-set of a continuous function =&gt; We have arbitrary topologies (for intro to topology see <a href="/notes/topological-spaces">Topological Spaces</a>).
We use neural networks to approximate these <em>implicit</em> functions and shapes.
Many many complex shapes can be represented with these implicit functions, but they need to be converted to representations above to be visualized.</p>
<h4 id="signal-distance-fields-sdf">Signal Distance Fields (SDF)<a hidden class="anchor" aria-hidden="true" href="#signal-distance-fields-sdf">#</a></h4>
<p>Normally, SDF (signal distance field $f_{\theta} : \mathbb{R}^{3} \times \mathcal{X} \to R$) values are stored in a grid (this is quite memory consuming), meaning every cell stores the signed distance from the surface (negative means inside, positive means outside).</p>
<h3 id="neural-implicit-representations">Neural Implicit Representations<a hidden class="anchor" aria-hidden="true" href="#neural-implicit-representations">#</a></h3>
<p>Here we have neural networks that represent space information (if the shape is inside or outside).</p>
<h4 id="two-representations---occupancy-networks-and-deepsdf">Two representations - Occupancy Networks and DeepSDF<a hidden class="anchor" aria-hidden="true" href="#two-representations---occupancy-networks-and-deepsdf">#</a></h4>
<p>We use simple MLP (see <a href="/notes/neural-networks">Neural Networks</a>) to represent these images.</p>
<ul>
<li>
<p>Occupancy networks are just classification problems (you sample points, and decide if a point is inside or outside).</p>
</li>
<li>
<p>DeepSDF is a regression problem, you sample points and predict the signed distance from the surface (you find level sets to know the surface).</p>
</li>
</ul>
<img src="/images/notes/Advanced 3D Representations-20250524193309961.webp" style="width: 100%" class="center" alt="Advanced 3D Representations-20250524193309961">
The other idea is that we can use these neural fields also for color, lighting, radiance, and similar things (meaning more information)!
Another nice thing is that normals are **gradients of the level set**, during backpropagation we have this information for free. The only problem when the translation to meshes happens is that at vertices, the normals are not well defined.
<h3 id="learning-implicit-shapes">Learning Implicit Shapes<a hidden class="anchor" aria-hidden="true" href="#learning-implicit-shapes">#</a></h3>
<p>This section explores most common ways to learn the implicit representations mentioned above.</p>
<h4 id="watertight-meshes">Watertight meshes<a hidden class="anchor" aria-hidden="true" href="#watertight-meshes">#</a></h4>
<p>We can create some sort of a <em>surrogate model</em> after having a first easily renderable (but more memory costly model) in the following way:</p>
<ul>
<li>With these kinds of meshes we sample 3D points in space</li>
<li>we query occupancy to the model (this is some ground value).</li>
<li>After creating this dataset, then you can use a cross entropy loss to train the implicit shape.</li>
</ul>
<p><strong>Marching Cubes</strong> can extract renderable meshes from these implicit shapes, it is a way to convert the implicit representation to a mesh.</p>
<h4 id="learning-from-points">Learning from Points<a hidden class="anchor" aria-hidden="true" href="#learning-from-points">#</a></h4>
<p>See this paper -&gt; <a href="https://proceedings.mlr.press/v119/gropp20a.html">(Gropp et al. 2020)</a>.
The main problem with this format is that we have no connectivity information, and we need to learn it from the data. For example if you have some points in a circle, it is not obvious to define whether if a points is actually inside or outside the circle.</p>
<p>For example, both of the following solutions are plausible:
<img src="/images/notes/Advanced 3D Representations-20250524194839528.webp" style="width: 100%" class="center" alt="Advanced 3D Representations-20250524194839528"></p>
$$
\lVert \nabla f_{\theta}(\boldsymbol{x}) \rVert_{2} = 1
$$<p>
We won&rsquo;t explain the maths behind this, but it is a way to enforce the model to learn the distance field.</p>
$$
\mathcal{L}(\theta) = \sum_{i \in I} \lvert f_{\theta}(\boldsymbol{x}_{i}) \rvert^{2} + \lambda \sum_{j \in J} \left(  \lVert \nabla f_{\theta}(\boldsymbol{x}_{j}) \rVert_{2}  - 1\right)^{2}
$$<p>
This was introduced from a paper in 2020 cited above.</p>
<h4 id="learning-from-images">Learning from Images<a hidden class="anchor" aria-hidden="true" href="#learning-from-images">#</a></h4>
<p>The following is the general idea of this technique:</p>
<ul>
<li>We usually have video from 2D images.</li>
<li>We model geometry and appearance with neural implicit fields.</li>
<li>We can use a differentiable renderer to render the images, and then optimize the parameters of the implicit field with a loss function that compares the rendered images with the original ones.
Once you have this renderer trained, we can use it to render new images from different viewpoints.</li>
</ul>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p>[1] Gropp et al. <a href="https://proceedings.mlr.press/v119/gropp20a.html">“Implicit Geometric Regularization for Learning Shapes”</a> PMLR  2020</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://flecart.github.io/tags/machine-perception/">Machine-Perception</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advanced 3D Representations on x"
            href="https://x.com/intent/tweet/?text=Advanced%203D%20Representations&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fadvanced-3d-representations%2f&amp;hashtags=machine-perception">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advanced 3D Representations on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fadvanced-3d-representations%2f&amp;title=Advanced%203D%20Representations&amp;summary=Advanced%203D%20Representations&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2fadvanced-3d-representations%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advanced 3D Representations on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2fadvanced-3d-representations%2f&title=Advanced%203D%20Representations">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advanced 3D Representations on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2fadvanced-3d-representations%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advanced 3D Representations on whatsapp"
            href="https://api.whatsapp.com/send?text=Advanced%203D%20Representations%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2fadvanced-3d-representations%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advanced 3D Representations on telegram"
            href="https://telegram.me/share/url?text=Advanced%203D%20Representations&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fadvanced-3d-representations%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Advanced 3D Representations on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Advanced%203D%20Representations&u=https%3a%2f%2fflecart.github.io%2fnotes%2fadvanced-3d-representations%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
