<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Parametric Modeling | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="machinelearning">
<meta name="description" content="In this note we will first talk about briefly some of the main differences of the three main approaches regarding statistics: the bayesian, the frequentist and the statistical learning methods and then present the concept of the estimator, compare how the approaches differ from method to method, we will explain maximum likelihood estimator and the Rao-Cramer Bound.
Short introduction to the statistical methods Bayesian 🟩 With bayesian methods we often assume a prior on the parameters, often human picked, that allows to give a regularizer term over the possible distribution that we are trying to model.">
<meta name="author" content="Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/parametric-modeling/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/parametric-modeling/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>




<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>





<script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-WW6NN2QGKF', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="Parametric Modeling" />
<meta property="og:description" content="In this note we will first talk about briefly some of the main differences of the three main approaches regarding statistics: the bayesian, the frequentist and the statistical learning methods and then present the concept of the estimator, compare how the approaches differ from method to method, we will explain maximum likelihood estimator and the Rao-Cramer Bound.
Short introduction to the statistical methods Bayesian 🟩 With bayesian methods we often assume a prior on the parameters, often human picked, that allows to give a regularizer term over the possible distribution that we are trying to model." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://flecart.github.io/notes/parametric-modeling/" />
<meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png" />
<meta property="article:section" content="notes" />



<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png" />
<meta name="twitter:title" content="Parametric Modeling"/>
<meta name="twitter:description" content="In this note we will first talk about briefly some of the main differences of the three main approaches regarding statistics: the bayesian, the frequentist and the statistical learning methods and then present the concept of the estimator, compare how the approaches differ from method to method, we will explain maximum likelihood estimator and the Rao-Cramer Bound.
Short introduction to the statistical methods Bayesian 🟩 With bayesian methods we often assume a prior on the parameters, often human picked, that allows to give a regularizer term over the possible distribution that we are trying to model."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Parametric Modeling",
      "item": "https://flecart.github.io/notes/parametric-modeling/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Parametric Modeling",
  "name": "Parametric Modeling",
  "description": "In this note we will first talk about briefly some of the main differences of the three main approaches regarding statistics: the bayesian, the frequentist and the statistical learning methods and then present the concept of the estimator, compare how the approaches differ from method to method, we will explain maximum likelihood estimator and the Rao-Cramer Bound.\nShort introduction to the statistical methods Bayesian 🟩 With bayesian methods we often assume a prior on the parameters, often human picked, that allows to give a regularizer term over the possible distribution that we are trying to model.",
  "keywords": [
    "machinelearning"
  ],
  "articleBody": "In this note we will first talk about briefly some of the main differences of the three main approaches regarding statistics: the bayesian, the frequentist and the statistical learning methods and then present the concept of the estimator, compare how the approaches differ from method to method, we will explain maximum likelihood estimator and the Rao-Cramer Bound.\nShort introduction to the statistical methods Bayesian 🟩 With bayesian methods we often assume a prior on the parameters, often human picked, that allows to give a regularizer term over the possible distribution that we are trying to model. The prior is just an assumption on the distribution of the model $p(\\theta)$ and the likelihood $P(X \\mid \\theta)$, where $X$ are the features, and $\\theta$ the model. After we have these two distributions defined, we can then use the famous Bayes rule to compute the posterior, and chose the best possible model given our dataset in this manner. This induces a distribution over possible $\\theta$ that we can consider. Another characteristic is that the Bayes’ rule is often infeasible to compute practically. So what we compute is $$ p(\\theta \\mid X) = \\frac{1}{z}p(X \\mid \\theta) p(\\theta) $$ The quantity $P(X \\mid \\theta)$ could be very complicated if our model is complicated.\nFrequentist 🟩 Fisher founded this view of statistics. (Murphy 2012) has a nice Chapter (6) about this topic. Frequentist methods start by having assumptions on the space of the model parameters (this is the $\\mathcal{C}$ class), so we have a family of models $\\mathcal{H} = \\left\\{ p_{\\theta} : \\theta \\in \\mathcal{C} \\right\\}$, but now this assumption is not a belief on the data itself, instead, a restriction that you have to pose in order to limit your search space (the need arises from practical purposes, not from beliefs, we want the most general possible models). Another aspect of frequentism is conditioning only on the observed data, and not on any priors. This methods leads to certain paradoxes of this type of modeling. But then, instead of using the Bayes’ rule, they just try to maximize the possibility that a certain $\\theta$ has given rise to that data. In formulas we have: $$ \\hat{\\theta}_{ML} = \\arg \\max_{\\theta} \\log p_{\\theta}(x_{1}, \\dots, x_{n}) $$ We assume the data is i.i.d so we need to estimate this value: $$ \\hat{\\theta}_{ML} = \\arg \\max_{\\theta} \\log \\sum_{i = 1}^{n} p_{\\theta}(x_{i}) $$ This is how maximum likelihood estimators naturally arise with the frequentist approach. This is asymptotically true.\nUsually with enough data and big models, frequentist’s methods are preferred.\nStatistical learning 🟩 The last possible interpretation, the statistical learning approach, I think is due to (Vapnik 2006)’s studies on Statistical learning theory, asserts that the best method is the one that minimizes the risk, meaning it should have the least error on the test split of our dataset. This risk is not accessible so we need to minimize the empirical risk So we try to chose the $\\theta$ is this way: $$ \\hat{\\theta}_{SL} = \\arg \\min_{\\theta} \\mathcal{R}(f) = \\arg \\min_{\\theta} \\mathbb{E}_{X, Y} \\mathcal{L} (f(X), Y) $$ So we choose an approximation for the risk which is $$ \\hat{R}(f) = \\frac{1}{n} \\sum_{i = 1}^{n} \\mathcal{L}(f(x_{i}), y_{i}) $$ And then choose the best $f$ from his family of functions\nThree problems in statistical learning The goal of statistical learning is to find a function $f : \\mathcal{X} \\to \\mathcal{Y}$ such that the error rate is minimized. We define the error rate to be just the cases where $f(x) \\neq y$. Let’s have so a simple model:\n$$ \\lim_{ n \\to \\infty } \\frac{1}{n} \\sum_{i= 1}^{N}\\mathbb{1} \\left\\{ f(x_{i}) \\neq y_{i} \\right\\} = \\mathbb{E}_{\\mathcal{x}, \\mathcal{y} \\sim p^{*}} [\\mathbb{1} \\left\\{ f(x) \\neq y \\right\\} ] $$ So we want to minimize the following value: $$ \\min_{f}\\mathbb{E}_{\\mathcal{x}, \\mathcal{y} \\sim p^{*}} [\\mathbb{1} \\left\\{ f(x) \\neq y \\right\\} ] $$ We don’t know anything about $f$, we need to have some assumptions, the easiest is to define a hypothesis class. We don’t know the starting distribution $p^{*}$, we solve this by collecting training samples so that we have an estimate of the starting distribution. (This is the fundamental problem in machine learning, we have empirical distribution, never the true distribution!) The risk $\\mathcal{R}$ is not differentiable, we solve this by choosing a loss function $\\mathcal{L} : \\mathcal{Y} \\times \\mathcal{Y} \\to \\mathbb{R}$ such that this is differentiable. We can write the starting problem in the following way as a proxy for the expected value. $$ \\min_{f \\in \\mathcal{H}} \\frac{1}{n} \\sum_{i \\leq n} \\mathcal{L} (f(x_{i}), y_{i}) $$ This image summarizes the whole pipeline Let’s have a simple example. Let’s attempt to chose the hypothesis class for the iris setosa classification problem. We arbitrarily choose $X$ and $Y$ to be\n$Y \\sim Bern(0.5)$ $X\\mid Y \\sim \\mathcal{N(\\mu_{y}, \\Sigma)}$ Then we can use Bayes rule to find $P(Y=y \\mid X = x) \\propto P(X = x \\mid Y = y) P(Y = y)$ and we can define then a simple loss, for example the classical binary cross entropy loss.\nBayesian and Frequentist head to head Estimators Estimators are functions or procedures that in this context of parametric models allow us to pin-point the correct parameters $\\theta$, in the case of the frequentist view, or give a distribution over possible $\\theta$s. Usually the generating function is called a density function parameterized by the $\\theta$ so we have to define the class of models and likelihood first.\nWe will mainly focus in this setting with the Maximum likelihood estimator\nThe Maximum Likelihood Estimator Given an assumption on the likelihood, we define the Maximum likelihood function to be $$ \\mathcal{L}(\\theta) = \\prod_{i=1}^{n} f(X^{(i)} ; \\theta) $$ Definition of MLE 🟩– We define the Maximum Likelihood Estimator (MLE) to be simply the best maximum likelihood $$ \\hat{\\theta}_{ML} = \\arg \\max_{\\theta} \\mathcal{L}(\\theta) $$ Sometimes is useful to consider the log-likelihood because sums are usually easier to handle. We will indicate the log version with $\\ell(\\theta)$. Usually the loss is the likelihood of the data, this is why it’s called Maximum Likelihood estimator.\nProperties of the MLE 🟨++ The important thing here is to be able to name the properties, not prove them. You can see a good presentation of these properties with (Wasserman 2004) chapter 9 (page 127 on wards). Three main properties concern us:\nConsistency: (meaning it will converge to the true parameter, if modelling assumptions are correct e.g. function family) In formula it means that a point estimator $\\hat{\\theta}_{n}$ of a $\\theta$ is consistent if it converges in probability which is: $$ \\forall \\varepsilon \u003e 0, \\mathbb{P}(\\lvert \\hat{\\theta}_{n} - \\theta \\rvert \u003e \\varepsilon) \\to_{n \\to \\infty} 0 $$ See Central Limit Theorem and Law of Large Numbers for definition of convergence in probability, the proof is not trivial and has many technicalities. Asymptotic efficiency: For well-behaved estimators, the MLE has the smallest variance for large $n$. - For example the median estimator satisfies $\\sqrt{ n } (\\theta_{\\text{ median}} - \\theta_{*}) = \\mathcal{N}\\left( 0, \\sigma^{2} \\frac{\\pi}{2} \\right)$, but the MLE doesn’t have that $\\pi$ factor. Asymptotically normal: meaning the error will be Gaussian if we have too many samples. Which means that $$ \\frac{\\hat{\\theta} - \\theta_{*}}{\\text{standard error}} \\sim \\mathcal{N}(0, 1) $$ Informally, this theorem states that the distribution of the parameters $\\theta$ that we find with MLE follows a normal distribution $\\mathcal{N}(\\theta_{*}, se)$. This theorem holds also for estimated standard errors. The interesting thing is that with this method we can build asymptotic confidence intervals for MLE, which can come quite handy in many occasions, and rival the bayesian approach for confidence intervals. The proof is quite hard, it is presented in the appendix of Chapter 9 of (Wasserman 2004). Equivariance meaning: if $\\hat{\\theta}$ is MLE of $\\theta$ then for any given $g$ we have that $g(\\hat{\\theta})$ is the MLE of $g(\\theta)$. I don’t know what is this useful for, but nice to know. We will discuss these properties one by one. These properties are the reason why MLE is preferred over other estimators, such as means or medians.\nWe want to say that an estimator is efficient if it uses its information well, which means $$ \\lim_{ n \\to \\infty } \\mathbb{E} \\left[ (\\hat{\\theta}_{ML} - \\theta_{0})^{2} \\right] = \\frac{1}{I_{n}(\\theta_{0})} $$ Where $I_{n}$ is the fisher information. Every estimator is lower bounded by this. (this is the maximum efficiency) and it’s very important.\nBiases usually are good if it includes information that is correct with the data. (helps it learn faster, an example of why bias works is the Stein estimator, but I didn’t understood exactly why). Simple cases and reasoning for first principles usually helps you build the intuition to attack more complex cases. This is something you would need to keep in mind.\nMLE is overconfident 🟥 TODO: see Sur and Candes 2018\nOne can show that there are many examples where logistic regression (see Linear Regression methods) is quite biased. This is a problem especially with high dimensional data. There are some numerical instabilities with correlated features, especially when we are trying to invert something small (floating point imprecisions!)\nYou can see it quite easily: Remember that the ordinary least squares solution is $(X^{T}X)^{-1}X^{T}y$, let’s suppose we use Singular Value Decomposition and write $X = V^{T}DU$ then we have $X^{T}X = U^{T}DVV^{T}DU = U^{T}D^{2}U$ Inverting this we get $U^{T}D^{-2}U$ and multiplying with the original one we get $\\beta = U^{T}D^{-1}Vy$ but the matrix $D^{-1}$ is quite unstable, especially when you are inverting small numbers.\nOne nice thing about this decomposition is that the inference is just $X\\beta = V^{T}Vy$ and that is a nice form.\nRao-Cramer Bound 🟨 Professor says this bound has same principle with the Heisenberg’s uncertainty principle with the Cauchy-Schwarz inequality somehow. But I don’t know about that.\nLet’s consider a likelihood $p(y \\mid \\theta)$, for $\\theta \\in \\Theta$ which is our parameter space, and some samples $y_{1}, \\dots, y_{n} \\sim p(y \\mid \\theta_{0})$, using a particular $\\theta_{0}$. We want to know how precisely can we estimate the value $\\theta_{0}$ given $n$ samples. So let’s define an estimator $\\hat{\\theta}$ and consider the expected deviation $\\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta_{0})^{2} \\right]$, which tells us how much can the estimated value $\\hat{\\theta}$ vary compared to the ground truth. One nice thing is that this holds for every distribution.\nScore function We consider the value of a score to be (use the log because perhaps the $p$ could be large, and we try to see how much it varies when varying the parameters, we are interested in this value because you know, Massimi minimi multi-variabile, if it’s 0 it should have some nice properties regarding maximum value of our likelihood). $$ \\Lambda := \\frac{ \\partial }{ \\partial \\theta } \\log p(y \\mid \\theta) = \\frac{\\left( \\frac{ \\partial }{ \\partial \\theta } p(y \\mid \\theta) \\right)}{p(y \\mid \\theta)} $$ Let’s define the bias to be $$ b_{\\hat{\\theta}} = \\mathbb{E}_{y \\mid \\theta} [ \\hat{\\theta} (y_{1}, \\dots, y_{n})] - \\theta $$ Now let’s consider the value of the expected score: $$ \\mathbf{E}_{y \\mid \\theta} \\Lambda = \\int p(y \\mid \\theta) \\cdot \\frac{1}{p(y \\mid \\theta)} \\frac{ \\partial }{ \\partial \\theta } p(y \\mid \\theta) \\, dy = \\int \\frac{ \\partial }{ \\partial \\theta } p(y \\mid \\theta) \\, dy = \\frac{ \\partial }{ \\partial \\theta } 1 = 0 $$ which is an interesting result.\nScore estimator Covariance Let’s consider another value: $$ \\mathbf{E}_{y \\mid \\theta} \\left[ \\Lambda \\cdot \\hat{\\theta} \\right] = \\frac{ \\partial }{ \\partial \\theta } \\int p(y \\mid \\theta) \\hat{\\theta} \\, dy = \\frac{ \\partial }{ \\partial \\theta } \\mathbf{E}_{y \\mid \\theta} \\left[ \\hat{\\theta} \\right] = \\frac{ \\partial }{ \\partial \\theta } \\left( \\mathbf{E}_{y \\mid \\theta} \\left[ \\hat{\\theta} \\right] - \\theta \\right) + 1 = \\frac{ \\partial }{ \\partial \\theta } b_{\\hat{\\theta}} + 1 $$ And the first part is surprisingly the bias of our estimator, so we want to see how much we can lower the bias value when we want to assess these kinds of problems.\nWe now consider the cross correlation between $\\Lambda$ and $\\hat{\\theta}$\n$$ \\mathbf{E}_{y \\mid \\theta} \\left[ ( \\Lambda - \\mathbf{E} \\Lambda)( \\hat{\\theta} - \\mathbf{E} \\hat{\\theta}) \\right] = \\mathbf{E}_{y \\mid \\theta}\\left[ \\Lambda \\cdot \\hat{\\theta} \\right] - \\mathbf{E}_{y \\mid \\theta} \\left[ \\Lambda \\mathbf{E} \\hat{\\theta} \\right] = \\mathbb{E}_{y \\mid \\theta} \\left[ \\Lambda \\cdot \\hat{\\theta} \\right] $$ We now use Cauchy-Schwarz Inequality to observe that\n$$ \\mathbb{E}_{y \\mid \\theta} \\left[ \\Lambda \\cdot \\hat{\\theta} \\right] ^{2} = \\left( \\mathbf{E}_{y \\mid \\theta} \\left[ ( \\Lambda)( \\hat{\\theta} - \\mathbf{E} \\hat{\\theta}) \\right] \\right)^{2} \\leq \\mathbf{E}_{y \\mid \\theta}\\left[ \\Lambda^{2} \\right] \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\mathbf{E} \\hat{\\theta}) ^{2} \\right] $$ We now expand the second term: $$ \\begin{align} \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\mathbf{E} \\hat{\\theta}) ^{2} \\right] \u0026= \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] - 2 \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta) (\\mathbf{E} \\hat{\\theta} - \\theta) \\right] + \\mathbf{E}_{ y \\mid \\theta} \\left[ (\\mathbf{E} \\hat{\\theta} - \\theta)^{2} \\right] \\\\ \u0026= \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] - 2 \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta) b_{\\hat{\\theta}} \\right] + b^{2}_{\\hat{\\theta}} \\\\ \u0026= \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] - b^{2}_{\\hat{\\theta}} \\end{align} $$ Which is just $= \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] - b^{2}_{\\hat{\\theta}}$\nFinal Bound Putting everything together we have that\n$$ \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] \\geq\n\\frac{\\mathbb{E}{y \\mid \\theta} \\left[ \\Lambda \\cdot \\hat{\\theta} \\right] ^{2}}{\\mathbf{E}{y \\mid \\theta}\\left[ \\Lambda^{2} \\right] } + b^{2}_{\\hat{\\theta}} \\frac{\\left( \\frac{ \\partial }{ \\partial \\theta } b_{\\hat{\\theta}} + 1 \\right)^{2}}{\\mathbf{E}{y \\mid \\theta}\\left[ \\Lambda^{2} \\right] } + b^{2}{\\hat{\\theta}} $$\nIf we have an unbiased estimator, which means that $b_{\\hat{\\theta}} = 0$ then we have that the expected difference of the models is always greater than the expected value of the double power of the score, also known as the fisher information in maths:\n$$ \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] \\geq \\frac{1}{\\mathbf{E}_{y \\mid \\theta} \\left[ \\Lambda^{2} \\right] } = \\frac{1}{I_{n}(\\theta_{0})} $$ If instead we have a biased estimator, sometimes is advantageous because the numerator could actually be smaller.\nFisher information Fisher information is defined as the variance of the score function. We discovered that the fisher information has something to do with the Rao-Cramer bound, let’s briefly analyze that:\n$$ \\mathbf{E}_{y \\mid \\theta} \\left[ \\Lambda^{2} \\right] = \\int p(y \\mid \\theta) \\left( \\frac{ \\partial }{ \\partial \\theta } \\log p(y \\mid \\theta) \\right)^{2} \\, dy =: I^{(1)}(\\theta) $$ Where $I(\\theta)$ is the fisher information. We can also define the Fisher information as the Variance of the score function i.e. : $$ I(\\theta) = Var(\\Lambda) = \\mathbb{E}_{y \\mid \\theta}[(\\Lambda - \\mathbb{E}_{y \\mid \\theta}[\\Lambda])^{2}] $$ And simplifying, as we know that the mean of the score function is 0.\nFisher information could also be written as the derivative with respect of theta of the score function, if $\\log p(y \\mid \\theta)$ is twice differentiable. See wikipedia.\nThe Multi-variable case 🟨++ Let’s consider this $$ I^{(n)} (\\theta) = \\int p(y_{1}\\dots y_{n} \\mid \\theta) \\left( \\frac{ \\partial }{ \\partial \\theta } \\log p(y_{1} \\dots y_{n}) \\right)^{2} \\, dy_{1}\\dots dy_{n} $$ And assuming we have independent variables we can see with some tricks and reasoning about the mean that: $$ \\int p(y_{1}\\dots y_{n} \\mid \\theta) \\left( \\frac{ \\partial }{ \\partial \\theta } \\log p(y_{1} \\dots y_{n}) \\right)^{2} \\, dy_{1}\\dots dy_{n} = \\int p(y_{1}\\dots y_{n} \\mid \\theta) \\left( \\sum \\Lambda_{i}^{2} \\right) \\, dy_{1}\\dots dy_{n} = n I^{(1)}(\\theta) $$ Which is a nice property of the fisher information\nStein estimator If we use this estimator we have that it is consistently better than the MLE, but we can’t prove that this is the best ever possible. This has been known as stein’s paradox for some time. See here. This video gives a nice intuition about Stein’s estimator, you can visualize it as a biased estimator that concentrates variance by warping the space closer to the origin, so that all the candidate solutions are acqually closer to the true solution.\nWe have to assume we have a multivariate random variable with $\\mathbb{R}^{d}$ with $d \\geq 3$ the exact details are not important, but we want to say that MLE is not always the best, this is the surprising fact.\n$$ \\hat{\\theta}_{JS} := \\left( 1 - \\frac{(d - 2)\\sigma^{2}}{\\lVert y \\rVert ^{2}} \\right) y $$ We then have that $$ \\mathbb{E}\\left[ (\\hat{\\theta}_{JS}- \\theta_{0})^{2} \\right] \\leq \\mathbb{E}\\left[ (\\hat{\\theta}_{MLE}- \\theta_{0})^{2} \\right] $$ References [1] Murphy “Machine Learning: A Probabilistic Perspective” 2012\n[2] Vapnik “Estimation of Dependences Based on Empirical Data” Springer 2006\n[3] Wasserman “All of Statistics: A Concise Course in Statistical Inference” Springer Science \u0026 Business Media 2004\n",
  "wordCount" : "2735",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/parametric-modeling/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Parametric Modeling
    </h1>
    <div class="post-meta">13 min&nbsp;·&nbsp;Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul><ul>
                <li>
                    <a href="#short-introduction-to-the-statistical-methods" aria-label="Short introduction to the statistical methods">Short introduction to the statistical methods</a><ul>
                        
                <li>
                    <a href="#bayesian-" aria-label="Bayesian 🟩">Bayesian 🟩</a></li>
                <li>
                    <a href="#frequentist-" aria-label="Frequentist 🟩">Frequentist 🟩</a></li>
                <li>
                    <a href="#statistical-learning-" aria-label="Statistical learning 🟩">Statistical learning 🟩</a></li>
                <li>
                    <a href="#three-problems-in-statistical-learning" aria-label="Three problems in statistical learning">Three problems in statistical learning</a></li>
                <li>
                    <a href="#bayesian-and-frequentist-head-to-head" aria-label="Bayesian and Frequentist head to head">Bayesian and Frequentist head to head</a></li></ul>
                </li></ul>
                    
                <li>
                    <a href="#estimators" aria-label="Estimators">Estimators</a><ul>
                        
                <li>
                    <a href="#the-maximum-likelihood-estimator" aria-label="The Maximum Likelihood Estimator">The Maximum Likelihood Estimator</a><ul>
                        
                <li>
                    <a href="#definition-of-mle---" aria-label="Definition of MLE 🟩&ndash;">Definition of MLE 🟩&ndash;</a></li>
                <li>
                    <a href="#properties-of-the-mle-" aria-label="Properties of the MLE 🟨&#43;&#43;">Properties of the MLE 🟨++</a></li>
                <li>
                    <a href="#mle-is-overconfident-" aria-label="MLE is overconfident 🟥">MLE is overconfident 🟥</a></li></ul>
                </li>
                <li>
                    <a href="#rao-cramer-bound-" aria-label="Rao-Cramer Bound 🟨">Rao-Cramer Bound 🟨</a><ul>
                        
                <li>
                    <a href="#score-function" aria-label="Score function">Score function</a></li>
                <li>
                    <a href="#score-estimator-covariance" aria-label="Score estimator Covariance">Score estimator Covariance</a></li>
                <li>
                    <a href="#final-bound" aria-label="Final Bound">Final Bound</a></li></ul>
                </li></ul>
                </li></ul>
                    
                <li>
                    <a href="#fracmathbbe_y-mid-theta-left-lambda-cdot-hattheta-right-2mathbfe_y-mid-thetaleft-lambda2-right---b2_hattheta" aria-label="\frac{\mathbb{E}{y \mid \theta} \left[ \Lambda \cdot \hat{\theta} \right] ^{2}}{\mathbf{E}{y \mid \theta}\left[ \Lambda^{2} \right] } &#43; b^{2}_{\hat{\theta}}">\frac{\mathbb{E}{y \mid \theta} \left[ \Lambda \cdot \hat{\theta} \right] ^{2}}{\mathbf{E}{y \mid \theta}\left[ \Lambda^{2} \right] } + b^{2}_{\hat{\theta}}</a><ul>
                        <ul>
                        
                <li>
                    <a href="#fisher-information" aria-label="Fisher information">Fisher information</a><ul>
                        
                <li>
                    <a href="#the-multi-variable-case-" aria-label="The Multi-variable case 🟨&#43;&#43;">The Multi-variable case 🟨++</a></li></ul>
                </li>
                <li>
                    <a href="#stein-estimator" aria-label="Stein estimator">Stein estimator</a></li></ul>
                    </ul>
                </li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>In this note we will first talk about briefly some of the main differences of the three main approaches regarding statistics: the bayesian, the frequentist and the statistical learning methods and then present the concept of the estimator, compare how the approaches differ from method to method, we will explain maximum likelihood estimator and the Rao-Cramer Bound.</p>
<h3 id="short-introduction-to-the-statistical-methods">Short introduction to the statistical methods<a hidden class="anchor" aria-hidden="true" href="#short-introduction-to-the-statistical-methods">#</a></h3>
<h4 id="bayesian-">Bayesian 🟩<a hidden class="anchor" aria-hidden="true" href="#bayesian-">#</a></h4>
<p>With bayesian methods we often assume a <strong>prior</strong> on the parameters, often human picked, that allows to give a <em>regularizer</em> term over the possible distribution that we are trying to model. The prior is just an assumption on the distribution of the model $p(\theta)$ and the likelihood $P(X \mid \theta)$, where $X$ are the features, and $\theta$ the model.
After we have these two distributions defined, we can then use the famous Bayes rule to compute the posterior, and chose the best possible model given our dataset in this manner. This induces a <em>distribution</em> over possible $\theta$ that we can consider. Another characteristic is that the Bayes&rsquo; rule is often infeasible to compute practically.
So what we compute is
</p>
$$
p(\theta \mid X) = \frac{1}{z}p(X \mid \theta) p(\theta) 
$$
<p>The quantity $P(X \mid \theta)$ could be very complicated if our model is complicated.</p>
<h4 id="frequentist-">Frequentist 🟩<a hidden class="anchor" aria-hidden="true" href="#frequentist-">#</a></h4>
<p>Fisher founded this view of statistics. <a href="https://mitpress.mit.edu/9780262018029/machine-learning/">(Murphy 2012)</a> has a nice Chapter (6) about this topic.
Frequentist methods start by having assumptions on the space of the model parameters (this is the $\mathcal{C}$ class), so we have a family of models $\mathcal{H} = \left\{ p_{\theta} : \theta \in \mathcal{C} \right\}$, but now this assumption is not a belief on the data itself, instead, a <em>restriction that you have to pose in order to limit your search space</em> (the need arises from practical purposes, not from beliefs, we want the most general possible models). Another aspect of frequentism is conditioning only on the observed data, and not on any priors.
This methods leads to certain paradoxes of this type of modeling.
But then, instead of using the Bayes&rsquo; rule, they just try to maximize the possibility that a certain $\theta$ has given rise to that data. In formulas we have:
</p>
$$
\hat{\theta}_{ML} = \arg \max_{\theta} \log p_{\theta}(x_{1}, \dots, x_{n})
$$
<p>
We assume the data is i.i.d so we need to estimate this value:
</p>
$$
\hat{\theta}_{ML} = \arg \max_{\theta} \log \sum_{i = 1}^{n} p_{\theta}(x_{i})
$$
<p>
This is how <strong>maximum likelihood estimators</strong> naturally arise with the frequentist approach. This is asymptotically true.</p>
<p>Usually with <em>enough data</em> and big models, frequentist&rsquo;s methods are preferred.</p>
<h4 id="statistical-learning-">Statistical learning 🟩<a hidden class="anchor" aria-hidden="true" href="#statistical-learning-">#</a></h4>
<p>The last possible interpretation, the statistical learning approach, I think is due to <a href="http://link.springer.com/10.1007/0-387-34239-7">(Vapnik 2006)</a>&rsquo;s studies on Statistical learning theory, asserts that the best method is the one that minimizes the risk, meaning it should have the least error on the test split of our dataset. This risk is not accessible so we need to minimize the empirical risk
So we try to chose the $\theta$ is this way:
</p>
$$
\hat{\theta}_{SL} = \arg \min_{\theta} \mathcal{R}(f) = \arg \min_{\theta} \mathbb{E}_{X, Y} \mathcal{L} (f(X), Y)
$$
<p>
So we choose an approximation for the risk which is
</p>
$$
\hat{R}(f) = \frac{1}{n} \sum_{i = 1}^{n} \mathcal{L}(f(x_{i}), y_{i})
$$
<p>
And then choose the best $f$ from his family of functions</p>
<h4 id="three-problems-in-statistical-learning">Three problems in statistical learning<a hidden class="anchor" aria-hidden="true" href="#three-problems-in-statistical-learning">#</a></h4>
<p>The goal of statistical learning is to find a function $f : \mathcal{X} \to \mathcal{Y}$ such that the error rate is minimized. We define the error rate to be just the cases where $f(x) \neq y$.
Let&rsquo;s have so a simple model:</p>
$$
\lim_{ n \to \infty }  \frac{1}{n} \sum_{i= 1}^{N}\mathbb{1} \left\{ f(x_{i}) \neq y_{i}  \right\} 
= \mathbb{E}_{\mathcal{x}, \mathcal{y} \sim p^{*}} [\mathbb{1} \left\{ f(x) \neq y \right\} ]
$$
<p>So we want to minimize the following value:
</p>
$$
\min_{f}\mathbb{E}_{\mathcal{x}, \mathcal{y} \sim p^{*}} [\mathbb{1} \left\{ f(x) \neq y \right\} ]
$$
<ol>
<li>We don&rsquo;t know anything about $f$, we need to have some assumptions, the easiest is to define a <em>hypothesis class</em>.</li>
<li>We don&rsquo;t know the starting distribution $p^{*}$, we solve this by collecting <em>training samples</em> so that we have an estimate of the starting distribution. (This is the <em>fundamental</em> problem in machine learning, we have empirical distribution, never the true distribution!)</li>
<li>The risk $\mathcal{R}$ is not <strong>differentiable</strong>, we solve this by choosing a <strong>loss function</strong> $\mathcal{L} : \mathcal{Y} \times \mathcal{Y} \to \mathbb{R}$ such that this is differentiable.
We can write the starting problem in the following way as a proxy for the expected value.
$$
\min_{f \in \mathcal{H}} \frac{1}{n} \sum_{i \leq n} \mathcal{L} (f(x_{i}), y_{i})
$$</li>
</ol>
<p>This image summarizes the whole pipeline
<img src="/images/notes/Parametric Models-20240926153044335.webp" alt="Parametric Models-20240926153044335"></p>
<p>Let&rsquo;s have a simple example. Let&rsquo;s attempt to chose the hypothesis class for the iris setosa classification problem.
We arbitrarily choose $X$ and $Y$ to be</p>
<ol>
<li>$Y \sim Bern(0.5)$</li>
<li>$X\mid Y \sim \mathcal{N(\mu_{y}, \Sigma)}$</li>
</ol>
<p>Then we can use Bayes rule to find $P(Y=y \mid X = x) \propto P(X = x \mid Y = y) P(Y = y)$ and we can define then a simple loss, for example the classical binary cross entropy loss.</p>
<h4 id="bayesian-and-frequentist-head-to-head">Bayesian and Frequentist head to head<a hidden class="anchor" aria-hidden="true" href="#bayesian-and-frequentist-head-to-head">#</a></h4>
<img src="/images/notes/Parametric Models-20240810200203475.webp" alt="Parametric Models-20240810200203475">
<h2 id="estimators">Estimators<a hidden class="anchor" aria-hidden="true" href="#estimators">#</a></h2>
<p>Estimators are functions or procedures that in this context of parametric models allow us to pin-point the correct parameters $\theta$, in the case of the frequentist view, or give a distribution over possible $\theta$s. Usually the generating function is called a <strong>density</strong> function parameterized by the $\theta$ so we have to define the class of models and likelihood first.</p>
<p>We will mainly focus in this setting with the Maximum likelihood estimator</p>
<h3 id="the-maximum-likelihood-estimator">The Maximum Likelihood Estimator<a hidden class="anchor" aria-hidden="true" href="#the-maximum-likelihood-estimator">#</a></h3>
<p>Given an assumption on the likelihood, we define the <strong>Maximum likelihood function</strong> to be
</p>
$$
\mathcal{L}(\theta) = \prod_{i=1}^{n} f(X^{(i)} ; \theta)
$$
<h4 id="definition-of-mle---">Definition of MLE 🟩&ndash;<a hidden class="anchor" aria-hidden="true" href="#definition-of-mle---">#</a></h4>
<p>We define the Maximum Likelihood Estimator (MLE) to be simply the best maximum likelihood
</p>
$$
\hat{\theta}_{ML} = \arg \max_{\theta} \mathcal{L}(\theta)
$$
<p>Sometimes is useful to consider the <strong>log-likelihood</strong> because sums are usually easier to handle. We will indicate the log version with $\ell(\theta)$.
Usually the loss is the likelihood of the data, this is why it&rsquo;s called Maximum <em>Likelihood</em> estimator.</p>
<h4 id="properties-of-the-mle-">Properties of the MLE 🟨++<a hidden class="anchor" aria-hidden="true" href="#properties-of-the-mle-">#</a></h4>
<p>The important thing here is to be able to name the properties, not prove them. You can see a good presentation of these properties with (Wasserman 2004) chapter 9 (page 127 on wards).
Three main properties concern us:</p>
<ol>
<li><strong>Consistency</strong>: (meaning it will converge to the true parameter, if modelling assumptions are correct e.g. function family)
<ul>
<li>In formula it means that a point estimator $\hat{\theta}_{n}$  of a $\theta$ is consistent if it converges in probability which is:
$$
	\forall \varepsilon > 0, \mathbb{P}(\lvert \hat{\theta}_{n} - \theta \rvert  > \varepsilon) \to_{n \to \infty} 0
$$</li>
<li>See <a href="/notes/central-limit-theorem-and-law-of-large-numbers/">Central Limit Theorem and Law of Large Numbers</a> for definition of convergence in probability, the proof is not trivial and has many technicalities.</li>
</ul>
</li>
<li><strong>Asymptotic efficiency</strong>: For well-behaved estimators, the MLE has the smallest variance for large $n$.
- For example the median estimator satisfies $\sqrt{ n } (\theta_{\text{ median}} - \theta_{*}) = \mathcal{N}\left( 0, \sigma^{2} \frac{\pi}{2} \right)$, but the MLE doesn&rsquo;t have that $\pi$ factor.</li>
<li><strong>Asymptotically normal</strong>: meaning the error will be Gaussian if we have too many samples. Which means that
$$
\frac{\hat{\theta} - \theta_{*}}{\text{standard error}} \sim \mathcal{N}(0, 1)
$$
<ul>
<li>Informally, this theorem states that the distribution of the parameters $\theta$  that we find with MLE follows a normal distribution $\mathcal{N}(\theta_{*}, se)$. This theorem holds also for estimated standard errors. The interesting thing is that with this method we can build <strong>asymptotic confidence intervals</strong> for MLE, which can come quite handy in many occasions, and rival the bayesian approach for confidence intervals.</li>
<li>The proof is quite hard, it is presented in the appendix of Chapter 9 of (Wasserman 2004).</li>
</ul>
</li>
<li><strong>Equivariance</strong> meaning: if $\hat{\theta}$ is MLE of $\theta$ then for any given $g$ we have that $g(\hat{\theta})$ is the MLE of $g(\theta)$. I don&rsquo;t know what is this useful for, but nice to know.</li>
</ol>
<p>We will discuss these properties one by one. These properties are the reason why MLE is preferred over other estimators, such as means or medians.</p>
<p>We want to say that an estimator is <strong>efficient</strong> if it uses its information well, which means
</p>
$$
\lim_{ n \to \infty } \mathbb{E} \left[  (\hat{\theta}_{ML} - \theta_{0})^{2} \right]  = \frac{1}{I_{n}(\theta_{0})}
$$
<p>
Where $I_{n}$ is the <strong>fisher information</strong>. Every estimator is lower bounded by this. (this is the maximum efficiency) and it&rsquo;s very important.</p>
<p>Biases usually are good if it includes information that is correct with the data. (helps it learn faster, an example of why bias works is the Stein estimator, but I didn&rsquo;t understood exactly why).
Simple cases and reasoning for first principles usually helps you build the intuition to attack more complex cases. This is something you would need to keep in mind.</p>
<h4 id="mle-is-overconfident-">MLE is overconfident 🟥<a hidden class="anchor" aria-hidden="true" href="#mle-is-overconfident-">#</a></h4>
<p>TODO: see Sur and Candes 2018</p>
<p>One can show that there are many examples where logistic regression (see <a href="/notes/linear-regression-methods/">Linear Regression methods</a>) is quite biased. This is a problem especially with <strong>high dimensional</strong> data.
There are some <em>numerical instabilities</em> with correlated features, especially when we are trying to invert something small (floating point imprecisions!)</p>
<p>You can see it quite easily:
Remember that the <em>ordinary least squares solution</em> is $(X^{T}X)^{-1}X^{T}y$, let&rsquo;s suppose we use <a href="/notes/singular-value-decomposition/">Singular Value Decomposition</a> and write $X = V^{T}DU$ then we have $X^{T}X = U^{T}DVV^{T}DU = U^{T}D^{2}U$ Inverting this we get $U^{T}D^{-2}U$ and multiplying with the original one we get $\beta = U^{T}D^{-1}Vy$  but the matrix $D^{-1}$ is quite unstable, especially when you are inverting small numbers.</p>
<p>One nice thing about this decomposition is that the inference is just $X\beta = V^{T}Vy$ and that is a nice form.</p>
<h3 id="rao-cramer-bound-">Rao-Cramer Bound 🟨<a hidden class="anchor" aria-hidden="true" href="#rao-cramer-bound-">#</a></h3>
<p>Professor says this bound has same principle with the Heisenberg&rsquo;s uncertainty principle with the Cauchy-Schwarz inequality somehow. But I don&rsquo;t know about that.</p>
<p>Let&rsquo;s consider a likelihood $p(y \mid \theta)$, for $\theta \in \Theta$ which is our parameter space, and some samples $y_{1}, \dots, y_{n} \sim p(y \mid \theta_{0})$, using a particular $\theta_{0}$.
We want to know <em>how precisely</em> can we estimate the value $\theta_{0}$ given $n$ samples. So let&rsquo;s define an estimator $\hat{\theta}$ and consider the <strong>expected deviation</strong> $\mathbf{E}_{y \mid \theta} \left[ (\hat{\theta} - \theta_{0})^{2} \right]$, which tells us how much can the estimated value $\hat{\theta}$ vary compared to the ground truth.
One nice thing is that this holds for every distribution.</p>
<h4 id="score-function">Score function<a hidden class="anchor" aria-hidden="true" href="#score-function">#</a></h4>
<p>We consider the value of a <strong>score</strong> to be (use the log because perhaps the $p$ could be large, and we try to see how much it varies when varying the parameters, we are interested in this value because you know, <a href="/notes/massimi-minimi-multi-variabile/">Massimi minimi multi-variabile</a>, if it&rsquo;s 0 it should have some nice properties regarding maximum value of our likelihood).
</p>
$$
\Lambda := \frac{ \partial  }{ \partial \theta }  \log p(y \mid \theta) = \frac{\left( \frac{ \partial  }{ \partial \theta } p(y \mid \theta) \right)}{p(y \mid \theta)}
$$
<p>
Let&rsquo;s define the <strong>bias</strong> to be
</p>
$$
b_{\hat{\theta}} = \mathbb{E}_{y \mid \theta} [ \hat{\theta} (y_{1}, \dots, y_{n})] - \theta
$$
<p>Now let&rsquo;s consider the value of the <strong>expected score</strong>:
</p>
$$
\mathbf{E}_{y \mid \theta} \Lambda 
=  \int p(y \mid \theta) \cdot \frac{1}{p(y \mid \theta)} \frac{ \partial  }{ \partial \theta } p(y \mid \theta) \, dy 
=  \int \frac{ \partial  }{ \partial \theta } p(y \mid \theta) \, dy 
= \frac{ \partial  }{ \partial \theta } 1 = 0 
$$
<p>
which is an interesting result.</p>
<h4 id="score-estimator-covariance">Score estimator Covariance<a hidden class="anchor" aria-hidden="true" href="#score-estimator-covariance">#</a></h4>
<p>Let&rsquo;s consider another value:
</p>
$$
\mathbf{E}_{y \mid \theta} \left[ \Lambda \cdot \hat{\theta} \right]  
= \frac{ \partial  }{ \partial \theta }  \int p(y \mid \theta) \hat{\theta} \, dy 
= \frac{ \partial }{ \partial \theta } \mathbf{E}_{y \mid \theta} \left[ \hat{\theta} \right] 
= \frac{ \partial }{ \partial \theta }  \left( \mathbf{E}_{y \mid \theta} \left[ \hat{\theta} \right]  - \theta \right)  + 1 
= \frac{ \partial  }{ \partial \theta } b_{\hat{\theta}} + 1
$$
<p>
And the first part is surprisingly the <strong>bias</strong> of our estimator, so we want to see how much we can lower the <em>bias</em> value when we want to assess these kinds of problems.</p>
<p>We now consider the cross correlation between $\Lambda$ and $\hat{\theta}$</p>
$$
\mathbf{E}_{y \mid \theta} \left[ ( \Lambda - \mathbf{E} \Lambda)( \hat{\theta} - \mathbf{E} \hat{\theta}) \right] 
= \mathbf{E}_{y \mid \theta}\left[ \Lambda \cdot \hat{\theta} \right] - \mathbf{E}_{y \mid \theta} \left[ \Lambda \mathbf{E} \hat{\theta} \right] 
= \mathbb{E}_{y \mid \theta} \left[ \Lambda \cdot \hat{\theta} \right] 
$$
<p>
We now use <a href="/notes/cauchy-schwarz-inequality/">Cauchy-Schwarz Inequality</a> to observe that<br>
</p>
$$
\mathbb{E}_{y \mid \theta} \left[ \Lambda \cdot \hat{\theta} \right] ^{2} = 
\left( \mathbf{E}_{y \mid \theta} \left[ ( \Lambda)( \hat{\theta} - \mathbf{E} \hat{\theta}) \right] \right)^{2} \leq \mathbf{E}_{y \mid \theta}\left[ \Lambda^{2} \right]  \mathbf{E}_{y \mid \theta} \left[  (\hat{\theta} - \mathbf{E} \hat{\theta}) ^{2} \right] 
$$
<p>
We now expand the second term:
</p>
$$
\begin{align}
\mathbf{E}_{y \mid \theta} \left[  (\hat{\theta} - \mathbf{E} \hat{\theta}) ^{2} \right] 
&=
\mathbf{E}_{y \mid \theta} \left[  (\hat{\theta} - \theta)^{2} \right] - 2  \mathbf{E}_{y \mid \theta} \left[ (\hat{\theta} - \theta) (\mathbf{E} \hat{\theta} - \theta) \right]  + \mathbf{E}_{ y \mid \theta} \left[ (\mathbf{E} \hat{\theta} - \theta)^{2} \right] 
 \\
&= \mathbf{E}_{y \mid \theta} \left[  (\hat{\theta} - \theta)^{2} \right] - 2  \mathbf{E}_{y \mid \theta} \left[ (\hat{\theta} - \theta) b_{\hat{\theta}} \right]  + b^{2}_{\hat{\theta}} \\
&= \mathbf{E}_{y \mid \theta} \left[  (\hat{\theta} - \theta)^{2} \right] - b^{2}_{\hat{\theta}}
\end{align}
$$
<p>
Which is just $= \mathbf{E}_{y \mid \theta} \left[  (\hat{\theta} - \theta)^{2} \right] - b^{2}_{\hat{\theta}}$</p>
<h4 id="final-bound">Final Bound<a hidden class="anchor" aria-hidden="true" href="#final-bound">#</a></h4>
<p>Putting everything together we have that</p>
<p>$$
\mathbf{E}_{y \mid \theta} \left[ (\hat{\theta} - \theta)^{2} \right]
\geq</p>
<h1 id="fracmathbbe_y-mid-theta-left-lambda-cdot-hattheta-right-2mathbfe_y-mid-thetaleft-lambda2-right---b2_hattheta">\frac{\mathbb{E}<em>{y \mid \theta} \left[ \Lambda \cdot \hat{\theta} \right] ^{2}}{\mathbf{E}</em>{y \mid \theta}\left[ \Lambda^{2} \right] } + b^{2}_{\hat{\theta}}<a hidden class="anchor" aria-hidden="true" href="#fracmathbbe_y-mid-theta-left-lambda-cdot-hattheta-right-2mathbfe_y-mid-thetaleft-lambda2-right---b2_hattheta">#</a></h1>
<p>\frac{\left( \frac{ \partial  }{ \partial \theta } b_{\hat{\theta}} + 1 \right)^{2}}{\mathbf{E}<em>{y \mid \theta}\left[ \Lambda^{2} \right] } + b^{2}</em>{\hat{\theta}}
$$</p>
<p>If we have an <strong>unbiased estimator</strong>, which means that $b_{\hat{\theta}} = 0$ then we have that the expected difference of the models is always greater than the expected value of the double power of the score, also known as the <strong>fisher information</strong> in maths:</p>
$$
 \mathbf{E}_{y \mid \theta} \left[ (\hat{\theta} - \theta)^{2} \right] \geq \frac{1}{\mathbf{E}_{y \mid \theta} \left[ \Lambda^{2} \right] } = \frac{1}{I_{n}(\theta_{0})}
$$
<p>
If instead we have a biased estimator, sometimes is advantageous because the numerator could actually be smaller.</p>
<h3 id="fisher-information">Fisher information<a hidden class="anchor" aria-hidden="true" href="#fisher-information">#</a></h3>
<p>Fisher information is defined as the <strong>variance of the score function</strong>.
We discovered that the fisher information has something to do with the Rao-Cramer bound, let&rsquo;s briefly analyze that:</p>
$$
\mathbf{E}_{y \mid \theta} \left[ \Lambda^{2} \right] 
= \int p(y \mid \theta) \left( \frac{ \partial  }{ \partial \theta } \log p(y \mid \theta)  \right)^{2}  \, dy =: I^{(1)}(\theta)
$$
<p>
Where $I(\theta)$ is the fisher information.
We can also define the Fisher information as the Variance of the score function i.e. :
</p>
$$
I(\theta) = Var(\Lambda) = \mathbb{E}_{y \mid \theta}[(\Lambda - \mathbb{E}_{y \mid \theta}[\Lambda])^{2}]
$$
<p>
And simplifying, as we know that the mean of the score function is 0.</p>
<p>Fisher information could also be written as the derivative with respect of theta of the score function, if $\log p(y \mid \theta)$ is twice differentiable. See <a href="https://en.wikipedia.org/wiki/Fisher_information#Definition">wikipedia</a>.</p>
<h4 id="the-multi-variable-case-">The Multi-variable case 🟨++<a hidden class="anchor" aria-hidden="true" href="#the-multi-variable-case-">#</a></h4>
<p>Let&rsquo;s consider this
</p>
$$
I^{(n)} (\theta) = \int p(y_{1}\dots y_{n} \mid \theta) \left( \frac{ \partial  }{ \partial \theta } \log p(y_{1} \dots y_{n}) \right)^{2} \, dy_{1}\dots dy_{n} 
$$
<p>
And assuming we have independent variables we can see with some tricks and reasoning about the mean that:
</p>
$$
\int p(y_{1}\dots y_{n} \mid \theta) \left( \frac{ \partial  }{ \partial \theta } \log p(y_{1} \dots y_{n}) \right)^{2} \, dy_{1}\dots dy_{n}  = \int  p(y_{1}\dots y_{n} \mid \theta) \left( \sum \Lambda_{i}^{2} \right) \, dy_{1}\dots dy_{n}   = n I^{(1)}(\theta)
$$
<p>
Which is a nice property of the fisher information</p>
<h3 id="stein-estimator">Stein estimator<a hidden class="anchor" aria-hidden="true" href="#stein-estimator">#</a></h3>
<p>If we use this estimator we have that it is <strong>consistently better</strong> than the MLE, but we can&rsquo;t prove that this is the best ever possible. This has been known as stein&rsquo;s paradox for some time. See <a href="https://www.youtube.com/watch?v=cUqoHQDinCM&ab_channel=Mathemaniac">here</a>. This video gives a nice intuition about Stein&rsquo;s estimator, you can visualize it as a biased estimator that concentrates variance by warping the space closer to the origin, so that all the candidate solutions are acqually closer to the true solution.</p>
<p>We have to assume we have a multivariate random variable with $\mathbb{R}^{d}$ with $d \geq 3$ the exact details are not important, but we want to say that MLE is not always the best, this is the surprising fact.</p>
$$
\hat{\theta}_{JS} := \left( 1 - \frac{(d - 2)\sigma^{2}}{\lVert y \rVert ^{2}} \right) y
$$
<p>We then have that
</p>
$$
\mathbb{E}\left[ (\hat{\theta}_{JS}- \theta_{0})^{2}  \right] 
\leq \mathbb{E}\left[ (\hat{\theta}_{MLE}- \theta_{0})^{2}  \right] 
$$
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p>[1] Murphy <a href="https://mitpress.mit.edu/9780262018029/machine-learning/">“Machine Learning: A Probabilistic Perspective”</a>  2012</p>
<p>[2] Vapnik <a href="http://link.springer.com/10.1007/0-387-34239-7">“Estimation of Dependences Based on Empirical Data”</a> Springer 2006</p>
<p>[3] Wasserman “All of Statistics: A Concise Course in Statistical Inference” Springer Science &amp; Business Media 2004</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://flecart.github.io/tags/machinelearning/">Machinelearning</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Parametric Modeling on x"
            href="https://x.com/intent/tweet/?text=Parametric%20Modeling&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fparametric-modeling%2f&amp;hashtags=machinelearning">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Parametric Modeling on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fparametric-modeling%2f&amp;title=Parametric%20Modeling&amp;summary=Parametric%20Modeling&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2fparametric-modeling%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Parametric Modeling on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2fparametric-modeling%2f&title=Parametric%20Modeling">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Parametric Modeling on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2fparametric-modeling%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Parametric Modeling on whatsapp"
            href="https://api.whatsapp.com/send?text=Parametric%20Modeling%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2fparametric-modeling%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Parametric Modeling on telegram"
            href="https://telegram.me/share/url?text=Parametric%20Modeling&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fparametric-modeling%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Parametric Modeling on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Parametric%20Modeling&u=https%3a%2f%2fflecart.github.io%2fnotes%2fparametric-modeling%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
