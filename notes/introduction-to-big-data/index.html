<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Introduction to Big Data | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="📓big-data">
<meta name="description" content="Data Science is similar to physics: it attemps to create theories of realities based on some formalism that another science brings. For physics it was mathematics, for data science it is computer science.
Data has grown expeditiously in these last years and has reached a distance that in metres is the distance to Jupiter. The galaxy is in the order of magnitude of 400 Yottametres, which has $3 \cdot 8$ zeros following after it. So quite a lot. We don&rsquo;t know if the magnitude of the data will grow this fast but certainly we need to be able to face this case.">
<meta name="author" content="
By Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/introduction-to-big-data/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f790d9af969c56c079c1ce2d5972a04486bf3d6144295d5fba319830e1e55a7a.css" integrity="sha256-95DZr5acVsB5wc4tWXKgRIa/PWFEKV1fujGYMOHlWno=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/introduction-to-big-data/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>






      <script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-WW6NN2QGKF');
        }
      </script><meta property="og:url" content="https://flecart.github.io/notes/introduction-to-big-data/">
  <meta property="og:site_name" content="X. Angelo Huang&#39;s Blog">
  <meta property="og:title" content="Introduction to Big Data">
  <meta property="og:description" content="Data Science is similar to physics: it attemps to create theories of realities based on some formalism that another science brings. For physics it was mathematics, for data science it is computer science. Data has grown expeditiously in these last years and has reached a distance that in metres is the distance to Jupiter. The galaxy is in the order of magnitude of 400 Yottametres, which has $3 \cdot 8$ zeros following after it. So quite a lot. We don’t know if the magnitude of the data will grow this fast but certainly we need to be able to face this case.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="notes">
    <meta property="article:tag" content="📓Big-Data">
      <meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:title" content="Introduction to Big Data">
<meta name="twitter:description" content="Data Science is similar to physics: it attemps to create theories of realities based on some formalism that another science brings. For physics it was mathematics, for data science it is computer science.
Data has grown expeditiously in these last years and has reached a distance that in metres is the distance to Jupiter. The galaxy is in the order of magnitude of 400 Yottametres, which has $3 \cdot 8$ zeros following after it. So quite a lot. We don&rsquo;t know if the magnitude of the data will grow this fast but certainly we need to be able to face this case.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Introduction to Big Data",
      "item": "https://flecart.github.io/notes/introduction-to-big-data/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Introduction to Big Data",
  "name": "Introduction to Big Data",
  "description": "Data Science is similar to physics: it attemps to create theories of realities based on some formalism that another science brings. For physics it was mathematics, for data science it is computer science. Data has grown expeditiously in these last years and has reached a distance that in metres is the distance to Jupiter. The galaxy is in the order of magnitude of 400 Yottametres, which has $3 \\cdot 8$ zeros following after it. So quite a lot. We don\u0026rsquo;t know if the magnitude of the data will grow this fast but certainly we need to be able to face this case.\n",
  "keywords": [
    "📓big-data"
  ],
  "articleBody": "Data Science is similar to physics: it attemps to create theories of realities based on some formalism that another science brings. For physics it was mathematics, for data science it is computer science. Data has grown expeditiously in these last years and has reached a distance that in metres is the distance to Jupiter. The galaxy is in the order of magnitude of 400 Yottametres, which has $3 \\cdot 8$ zeros following after it. So quite a lot. We don’t know if the magnitude of the data will grow this fast but certainly we need to be able to face this case.\nEarly versions Small History of Information systems We can pinpoint three main historical developments of information systems that coincide with some revolutions in human history. 0. First humans just stored their information in the brains. The stories, culture was mainly transmitted orally from person to person. This was similar to the point made in (Harari 2024) by professor Harari: this allowed humans to create networks of information that created large scale alliances.\nHumans invent writing: first the people needed some storage for economical transactions, this created the need to have some durable tables were to store this information. Humans invent the printing press: Gutemberg’s innovation allowed information storage and duplication to be much more cheaper compared to the historical manual copying and writing. This empowered ideas like the christian religion to spread even further and have much higher impact. Invention of the silicon based processors. This innovation enabled further storage and processing, and ultra-fast communication, having another deep effect on humanity as a whole. 20k Ishango Bone is one of the first. 250 BC there was a library of Alexandria. With physical books it was very difficult to get some higher level trends. Now we can just analyze hundreds, and millions of documents in a very fast manner.\nCodd’s Data Independence Edgar Codd suggested that a usable database management system should hide all the physical complexity from the user and expose instead a simple, clean model.\nSee (Codd 1970). The other important contribution in the paper is the suggestion to use tables, which gave birth to the relational languages and algebra.\nAs in Architettura e livelli 1, 2, the data systems are divided into inter-operating levels, that communicate with each other using interfaces. This makes easy to update the underlying level without the upper one noticing.\nDatabase management systems A database management system stack can be viewed as a four-layer stack:\nA logical query language with which the user can query data; A logical model for the data; A physical compute layer that processes the query on an instance of the model; A physical storage layer where the data is physically stored. Evaluating an Information system Velocity For the velocity we care about the capacity, throughput and latency. Capacity is how much you can store, throughput is how fast can you read, and latency is how much you have to wait until the first byte of data. Some of the first devices in 1956 had capacities of 5MB $(1.7m \\times 1.5m)$, throughput of 12.5kB/s and latencies of 600ms. Now in 2024 it has capacities of 26TB $(14.7cm \\times 2.6cm)$, throughput of 261MB/s and latencies of 4ms.\nThe important thing to observe is that\nCapacity has exploded very fast, more than one million orders of magnitude! Also throughput has increased, by only by about 4 orders of magnitude Latency has not advanced much. The important consideration is that if we want to process the same amount of data, it’s much more important to parallelize so that we can read faster.\nImage from Big data introduction Course, Ghislain Fourny\nVolume How big should data be to be considered to be part of big data? We need first to learn something about the scales :D and orders of magnitude!. Those should be learned by hearth\nKilo - 1000 Mega - 1.000.000 Giga - 1.000.000.000 Tera - 1.000.000.000.000 Peta - 1.000.000.000.000.000 Exa - 1.000.000.000.000.000.000 Zetta - 1.000.000.000.000.000.000.000 Yotta - 1..000.000.000.000.000.000.000.000 Ronna - 1.000.000.000.000.000.000.000.000.000 Quetta - 1.000.000.000.000.000.000.000.000.000.000 When we go on the other side we have\nMilli Micro nano Pico femto atto zepto yocto All by hearth! The threshold for big data is currently the Peta because it can’t be stored in a single computer.\nVariety Data could have different shapes, it’s important for the exam that you learn these shapes by hearth:\nGraphs Cubes Unstructured (Text is a often cited example of this). Trees Tables A definition of Big Data Big Data is a portfolio of technologies that were designed to store, manage and analyze data that is too large to fit on a single machine while accommodating for the issue of growing discrepancy between capacity, throughput and latency.\nThis has some links with the definition of data, information, knowledge and wisdom, that you can find here.\nUsage examples There are some real life companies and environments where storing many many gigabytes of data everyday is the most common thing ever: for example\nCERN produces 50PB of data every year, and most of these data needs to be analyzed, see Massive Parallel Processing. Sloan Digital Sky Survey (SDSS) which attempts to map every part of the sky produces 200 GB of data every day. It has the most detailed 3D map of the sky Also biology DNA can be seen as a data storage device. Reading and Writing intensive systems These are called respectively OLAP (Online Analytical Processing) and OLTP (Online Transaction Processing for the write intensive. This has been explained in a more detailed manner in Data Cubes.\nTechniques for Big Data We appoint two as the main techniques used to handle big amounts of data. Many of these arise due to the ever growing amount of data in modern times:\nParallelization: if we have many many processors, it’s easy to read many pages at the same time. This is what is leveraged in Massive Parallel Processing. Batch Processing: due to the discrepancy between throughput and latency, it’s often better to read a lot of data at the same time, and then process it in a batch. This is also leveraged in systems like MapReduce introduced in Massive Parallel Processing. Paradigms of data storage ETL framework This is the classical database approach: We load the data in the database and let the underlying system handle it. This method needs some added cost in extracting, transforming and loading the data that we have stored previously in an optimized format so that it can be used for views, or else.\nData Lakes We usually refer to Data Lakes when we store our data with Distributed file systems or using Cloud Storage: cheap ways to dump the data without caring about the possibility of modifying them.\nWe typically store data in the filesystem, where it is viewed simply as files. This approach works well when we only need to read the data. It’s often referred to as in situ storage because there is no need to extract the data first. However, the drawback arises when we need to modify the data, as it can lead to numerous inconsistencies.\nAnother significant limitation of filesystems is that they cannot scale to manage billions of files efficiently.\nThis is what the professors in the first database course says Filesystem: are not the perfect technology to handle this type of load, see Introduction to databases.\nScaling principles Usually the best thing is to make things work in a single computer, then it’s cheaper to scale horizontally, and then to scale vertically, adding better hardware.\nCurrent Limits When A relational table grows too much, a single system could have difficulty in handling it. Common limits nowadays are:\nMillions of rows Cloud Storage, Distributed file systems, Massive Parallel Processing, usually handle well data with lots of rows (samples, with the same columns) More than 256 columns, we usually use Wide Column Storage. With a lot of nested data. We use Document Stores, like MongoDB, where the Markup is quite important. There are also problems for file-systems:\nDifficulty on collaborating on the same file with the same Filesystem Doesn’t scale over billions of files, standard filesystems are not designed to handle so much data. Scaling vertically There are two ways of scaling, scaling vertically or horizontally. Scaling Up concerns in building better machines, building better algorithms and being more efficient with what exactly we have.\nScaling horizontally Scaling horizontally is the simple idea of adding more things, it could be more computers, more ram, more disk, more CPUs. But these have some physical limits that we should need to keep track of.\nThere is a physical limit of number of computers in a data-center (1k to 100k which seems to be the hard limit constrained by energy and cooling requirements). Zürich’s datacenter consumes as much energy as an airport. And we have about 1-200 cores in a single computer of a datacenter.\nWe also have a limit for RAM and local storage. Respectively about 0.016-24TB of RAM and 1-30TB of storage. Its unthinkable that the RAM memory has the same order of magnitude of local storage. This is because in memory databases are becoming more common (they are usually faster, lower latency).\nWe also have a bandwidth of 1-200Gbit/s for a single server on an Ethernet cable.\nWe have standardized rack units for every server (or storage if the module is just for storage), storage and routers, they are usually connected together by switches and similar networking thingies. Usually we have 1-4 rack units for a server\nType Range Computers in Data Center 1k-100k (100k hard limit for electricity designs) Cores in a Single computer 200 RAM 0.016-24TB Network Bandwidth 1-200 Gbit Racks per server (module) 1-4 HDD Storage 26TB Throughput 261MB/s Latency 4 ms Analysis of bottlenecks We already have said that a way to improve on the possible bottlenecks of our systems is having better code: using our resources in a better manner. The easier way is choosing to buy more resources. Important bottlenecks in our context are CPU, Memory, RAM, and network. We can know if have one of these bottlenecks by monitoring the real-time resource usages.\nDisk-IO -\u003e MapReduce and Spark, or using Parquet instead of JSON can\nIn fact, you should always first try to improve your code before scaling out. The vast majority of data processing use cases fit on a single machine, and you can save a lot of money as well as get a faster system by squeezing the data on a machine (possibly compressed) and writing very efficient code.\nFor example, an easy way to address a memory bottlenecks is to analyze the classes that are instantiated many many times, but their fields are not often used, or have repeated information. Scaling up should be the last resource!.\nFor CPU, we should pay attention to the places we are doing so much class hierarchy, type checking, useless loops, overridden methods (they have to dynamically retrieve the function!) And too many method calls that are not easily inlinable.\nFor DIsk-IO, we use better formats, or compression, and parallel processing frameworks.\nFor Network, try to get rid of data that doesn’t need to be transmitted, and put it in a nicer format so that it is easier to compress it! (This is called Push Down). And use batch processing.\nEvolution of the data stack We have 10 layers, instead of the 7 Architettura e livelli 1, 2 of the ISO OSI layers of the networking. We will rebuild the whole datastack and understand how every layer works together with one another to handle the big data.\nWe will link for each part some important nodes regarding those\nStorage: Cloud Storage, Wide Column Storage, Distributed file systems Encoding and Syntax: Markup Data models and Validation: Data Models and Validation Processing: Massive Parallel Processing References [1] Harari “Nexus: A Brief History of Information Networks from the Stone Age to AI” Random House 2024 [2] Codd “A Relational Model of Data for Large Shared Data Banks” Communications of the ACM Vol. 13(6), pp. 377--387 1970 ",
  "wordCount" : "2008",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/introduction-to-big-data/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Introduction to Big Data
    </h1>
    <div class="post-meta">Reading Time: 10 minutes&nbsp;·&nbsp;
By Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul><ul>
                <li>
                    <a href="#early-versions" aria-label="Early versions">Early versions</a><ul>
                        
                <li>
                    <a href="#small-history-of-information-systems" aria-label="Small History of Information systems">Small History of Information systems</a></li>
                <li>
                    <a href="#codds-data-independence" aria-label="Codd&rsquo;s Data Independence">Codd&rsquo;s Data Independence</a></li>
                <li>
                    <a href="#database-management-systems" aria-label="Database management systems">Database management systems</a></li></ul>
                </li>
                <li>
                    <a href="#evaluating-an-information-system" aria-label="Evaluating an Information system">Evaluating an Information system</a><ul>
                        
                <li>
                    <a href="#velocity" aria-label="Velocity">Velocity</a></li>
                <li>
                    <a href="#volume" aria-label="Volume">Volume</a></li>
                <li>
                    <a href="#variety" aria-label="Variety">Variety</a></li>
                <li>
                    <a href="#a-definition-of-big-data" aria-label="A definition of Big Data">A definition of Big Data</a></li>
                <li>
                    <a href="#usage-examples" aria-label="Usage examples">Usage examples</a></li>
                <li>
                    <a href="#reading-and-writing-intensive-systems" aria-label="Reading and Writing intensive systems">Reading and Writing intensive systems</a></li>
                <li>
                    <a href="#techniques-for-big-data" aria-label="Techniques for Big Data">Techniques for Big Data</a></li></ul>
                </li>
                <li>
                    <a href="#paradigms-of-data-storage" aria-label="Paradigms of data storage">Paradigms of data storage</a><ul>
                        
                <li>
                    <a href="#etl-framework" aria-label="ETL framework">ETL framework</a></li>
                <li>
                    <a href="#data-lakes" aria-label="Data Lakes">Data Lakes</a></li></ul>
                </li>
                <li>
                    <a href="#scaling-principles" aria-label="Scaling principles">Scaling principles</a><ul>
                        
                <li>
                    <a href="#current-limits" aria-label="Current Limits">Current Limits</a></li>
                <li>
                    <a href="#scaling-vertically" aria-label="Scaling vertically">Scaling vertically</a></li>
                <li>
                    <a href="#scaling-horizontally" aria-label="Scaling horizontally">Scaling horizontally</a></li>
                <li>
                    <a href="#analysis-of-bottlenecks" aria-label="Analysis of bottlenecks">Analysis of bottlenecks</a></li></ul>
                </li></ul>
                    
                <li>
                    <a href="#evolution-of-the-data-stack" aria-label="Evolution of the data stack">Evolution of the data stack</a></li></ul>
                    
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Data Science is similar to physics: it attemps to create theories of realities based on some formalism that another science brings. For physics it was mathematics, for data science it is computer science.
Data has grown expeditiously in these last years and has reached a distance that in metres is the distance to Jupiter. The galaxy is in the order of magnitude of 400 Yottametres, which has $3 \cdot 8$ zeros following after it. So quite a lot. We don&rsquo;t know if the magnitude of the data will grow this fast but certainly we need to be able to face this case.</p>
<h3 id="early-versions">Early versions<a hidden class="anchor" aria-hidden="true" href="#early-versions">#</a></h3>
<h4 id="small-history-of-information-systems">Small History of Information systems<a hidden class="anchor" aria-hidden="true" href="#small-history-of-information-systems">#</a></h4>
<p>We can pinpoint three main historical developments of information systems that coincide with some revolutions in human history.
0. First humans just stored their information in the brains. The stories, culture was mainly transmitted orally from person to person. This was similar to the point made in <a href="https://books.google.ch/books/about/Nexus.html?id=OcwbEQAAQBAJ&redir_esc=y">(Harari 2024)</a> by professor Harari: this allowed humans to create networks of information that created large scale alliances.</p>
<ol>
<li>Humans <strong>invent writing</strong>: first the people needed some storage for economical transactions, this created the need to have some durable tables were to store this information.</li>
<li>Humans invent the <strong>printing press</strong>: Gutemberg&rsquo;s innovation allowed information storage and duplication to be much more cheaper compared to the historical manual copying and writing. This empowered ideas like the christian religion to spread even further and have much higher impact.</li>
<li>Invention of the <strong>silicon based processors</strong>. This innovation enabled further storage and processing, and ultra-fast communication, having another deep effect on humanity as a whole.</li>
</ol>
<p>20k Ishango Bone is one of the first. 250 BC there was a library of Alexandria. With physical books it was very difficult to get some higher level trends. Now we can just analyze hundreds, and millions of documents in a very fast manner.</p>
<h4 id="codds-data-independence">Codd&rsquo;s Data Independence<a hidden class="anchor" aria-hidden="true" href="#codds-data-independence">#</a></h4>
<blockquote>
<p>Edgar Codd suggested that a usable database management system should hide all the physical complexity from the user and expose instead a simple, clean model.</p></blockquote>
<p>See <a href="https://dl.acm.org/doi/10.1145/362384.362685">(Codd 1970)</a>.
The other important contribution in the paper is the suggestion to use tables, which gave birth to the relational languages and algebra.</p>
<p>As in <a href="/notes/architettura-e-livelli-1,-2">Architettura e livelli 1, 2</a>, the data systems are divided into inter-operating levels, that communicate with each other using interfaces. This makes easy to update the underlying level without the upper one noticing.</p>
<h4 id="database-management-systems">Database management systems<a hidden class="anchor" aria-hidden="true" href="#database-management-systems">#</a></h4>
<p>A database management system stack can be viewed as a <strong>four</strong>-layer stack:</p>
<ul>
<li>A logical query language with which the user can query data;</li>
<li>A logical model for the data;</li>
<li>A physical compute layer that processes the query on an instance of the model;</li>
<li>A physical storage layer where the data is physically stored.</li>
</ul>
<h3 id="evaluating-an-information-system">Evaluating an Information system<a hidden class="anchor" aria-hidden="true" href="#evaluating-an-information-system">#</a></h3>
<h4 id="velocity">Velocity<a hidden class="anchor" aria-hidden="true" href="#velocity">#</a></h4>
<p>For the velocity we care about the <strong>capacity</strong>, <strong>throughput</strong> and <strong>latency</strong>.
Capacity is how much you can store, throughput is how fast can you read, and latency is how much you have to wait until the first byte of data.
Some of the first devices in 1956 had capacities of 5MB $(1.7m \times 1.5m)$, throughput of 12.5kB/s and latencies of 600ms.
Now in 2024 it has capacities of 26TB $(14.7cm \times 2.6cm)$, throughput of 261MB/s and latencies of 4ms.</p>
<p>The important thing to observe is that</p>
<ul>
<li>Capacity has exploded very fast, more than one million orders of magnitude!</li>
<li>Also throughput has increased, by only by about 4 orders of magnitude</li>
<li>Latency has not advanced much.</li>
</ul>
<p>The important consideration is that if we want to process the same amount of data, it&rsquo;s much more important to <strong>parallelize</strong> so that we can read faster.</p>
<figure class="center">
<img src="/images/notes/Introduction to Big Data-20241007191516420.webp" style="width: 100%"   alt="Introduction to Big Data-20241007191516420" title="Introduction to Big Data-20241007191516420"/>
<figcaption><p style="text-align:center;">Image from Big data introduction Course, Ghislain Fourny</p></figcaption>
</figure>
<h4 id="volume">Volume<a hidden class="anchor" aria-hidden="true" href="#volume">#</a></h4>
<p>How big should data be to be considered to be part of big data?
We need first to learn something about the scales :D and <strong>orders of magnitude!</strong>. Those should be learned by hearth</p>
<ul>
<li>Kilo - 1000</li>
<li>Mega - 1.000.000</li>
<li>Giga - 1.000.000.000</li>
<li>Tera - 1.000.000.000.000</li>
<li>Peta - 1.000.000.000.000.000</li>
<li>Exa - 1.000.000.000.000.000.000</li>
<li>Zetta - 1.000.000.000.000.000.000.000</li>
<li>Yotta - 1..000.000.000.000.000.000.000.000</li>
<li>Ronna - 1.000.000.000.000.000.000.000.000.000</li>
<li>Quetta - 1.000.000.000.000.000.000.000.000.000.000</li>
</ul>
<p>When we go on the other side we have</p>
<ul>
<li>Milli</li>
<li>Micro</li>
<li>nano</li>
<li>Pico</li>
<li>femto</li>
<li>atto</li>
<li>zepto</li>
<li>yocto</li>
</ul>
<p>All by hearth!
The threshold for big data is currently the <strong>Peta</strong> because it <em>can&rsquo;t be stored</em> in a single computer.</p>
<h4 id="variety">Variety<a hidden class="anchor" aria-hidden="true" href="#variety">#</a></h4>
<p>Data could have different shapes, it&rsquo;s important for the exam that you learn these shapes by hearth:</p>
<ul>
<li>Graphs</li>
<li>Cubes</li>
<li>Unstructured (Text is a often cited example of this).</li>
<li>Trees</li>
<li>Tables</li>
</ul>
<h4 id="a-definition-of-big-data">A definition of Big Data<a hidden class="anchor" aria-hidden="true" href="#a-definition-of-big-data">#</a></h4>
<blockquote>
<p><strong>Big Data</strong> is a portfolio of technologies that were designed to store, manage and analyze data that is too large to fit on a single machine while accommodating for the issue of growing discrepancy between capacity, throughput and latency.</p></blockquote>
<p>This has some links with the definition of data, information, knowledge and wisdom, that you can find <a href="https://chatgpt.com/share/66eb3aaa-1358-8009-9762-7950782fa6b1">here</a>.</p>
<h4 id="usage-examples">Usage examples<a hidden class="anchor" aria-hidden="true" href="#usage-examples">#</a></h4>
<p>There are some real life companies and environments where storing many many gigabytes of data everyday is the most common thing ever: for example</p>
<ul>
<li>CERN produces <strong>50PB</strong> of data <strong>every year</strong>, and most of these data needs to be analyzed, see <a href="/notes/massive-parallel-processing">Massive Parallel Processing</a>.</li>
<li>Sloan Digital Sky Survey (<strong>SDSS</strong>) which attempts to <em>map every part of the sky</em> produces <strong>200 GB</strong> of data every day. It has the most detailed 3D map of the sky
Also biology DNA can be seen as a data storage device.</li>
</ul>
<h4 id="reading-and-writing-intensive-systems">Reading and Writing intensive systems<a hidden class="anchor" aria-hidden="true" href="#reading-and-writing-intensive-systems">#</a></h4>
<p>These are called respectively <strong>OLAP (Online Analytical Processing)</strong> and <strong>OLTP (Online Transaction Processing</strong> for the write intensive.
This has been explained in a more detailed manner in <a href="/notes/data-cubes">Data Cubes</a>.</p>
<h4 id="techniques-for-big-data">Techniques for Big Data<a hidden class="anchor" aria-hidden="true" href="#techniques-for-big-data">#</a></h4>
<p>We appoint two as the main techniques used to handle big amounts of data. Many of these arise due to the ever growing amount of data in modern times:</p>
<ol>
<li><strong>Parallelization</strong>: if we have many many processors, it&rsquo;s easy to read many pages at the same time. This is what is leveraged in <a href="/notes/massive-parallel-processing">Massive Parallel Processing</a>.</li>
<li><strong>Batch Processing</strong>: due to the discrepancy between throughput and latency, it&rsquo;s often better to read a lot of data at the same time, and then process it in a batch. This is also leveraged in systems like MapReduce introduced in <a href="/notes/massive-parallel-processing">Massive Parallel Processing</a>.</li>
</ol>
<h3 id="paradigms-of-data-storage">Paradigms of data storage<a hidden class="anchor" aria-hidden="true" href="#paradigms-of-data-storage">#</a></h3>
<h4 id="etl-framework">ETL framework<a hidden class="anchor" aria-hidden="true" href="#etl-framework">#</a></h4>
<p>This is the classical database approach:
We load the data in the database and let the underlying system handle it. This method needs some added cost in extracting, transforming and loading the data that we have stored previously in an optimized format so that it can be used for views, or else.</p>
<h4 id="data-lakes">Data Lakes<a hidden class="anchor" aria-hidden="true" href="#data-lakes">#</a></h4>
<p>We usually refer to <em>Data Lakes</em> when we store our data with <a href="/notes/distributed-file-systems">Distributed file systems</a> or using <a href="/notes/cloud-storage">Cloud Storage</a>: cheap ways to dump the data without caring about the possibility of modifying them.</p>
<p>We typically store data in the <strong>filesystem</strong>, where it is viewed simply as files. This approach works well when we only need to <em>read</em> the data. It&rsquo;s often referred to as <em>in situ</em> storage because there is no need to extract the data first. However, the drawback arises when we need to <em>modify</em> the data, as it can lead to numerous inconsistencies.</p>
<p>Another significant limitation of filesystems is that they <strong>cannot scale to manage billions of files</strong> efficiently.</p>
<p>This is what the professors in the first database course says <a href="/notes/filesystem">Filesystem</a>: are not the perfect technology to handle this type of load, see <a href="/notes/introduction-to-databases">Introduction to databases</a>.</p>
<h3 id="scaling-principles">Scaling principles<a hidden class="anchor" aria-hidden="true" href="#scaling-principles">#</a></h3>
<p>Usually the best thing is to make things work in a single computer, then it&rsquo;s cheaper to scale horizontally, and then to scale vertically, adding better hardware.</p>
<h4 id="current-limits">Current Limits<a hidden class="anchor" aria-hidden="true" href="#current-limits">#</a></h4>
<p>When A relational table grows too much, a single system could have difficulty in handling it.
Common limits nowadays are:</p>
<ol>
<li>Millions of rows
<ol>
<li><a href="/notes/cloud-storage">Cloud Storage</a>, <a href="/notes/distributed-file-systems">Distributed file systems</a>, <a href="/notes/massive-parallel-processing">Massive Parallel Processing</a>, usually handle well data with lots of rows (samples, with the same columns)</li>
</ol>
</li>
<li>More than 256 columns, we usually use <a href="/notes/wide-column-storage">Wide Column Storage</a>.</li>
<li>With a lot of nested data.
<ol>
<li>We use <a href="/notes/document-stores">Document Stores</a>, like MongoDB, where the <a href="/notes/markup">Markup</a> is quite important.</li>
</ol>
</li>
</ol>
<p>There are also problems for file-systems:</p>
<ol>
<li>Difficulty on collaborating on the same file with the same <a href="/notes/filesystem">Filesystem</a></li>
<li>Doesn&rsquo;t scale over billions of files, standard filesystems are not designed to handle so much data.</li>
</ol>
<h4 id="scaling-vertically">Scaling vertically<a hidden class="anchor" aria-hidden="true" href="#scaling-vertically">#</a></h4>
<p>There are two ways of scaling, scaling vertically or horizontally.
Scaling Up concerns in building better machines, building better algorithms and being more efficient with what exactly we have.</p>
<h4 id="scaling-horizontally">Scaling horizontally<a hidden class="anchor" aria-hidden="true" href="#scaling-horizontally">#</a></h4>
<p>Scaling horizontally is the simple idea of adding more things, it could be more computers, more ram, more disk, more CPUs. But these have some physical limits that we should need to keep track of.</p>
<p>There is a physical limit of number of computers in a data-center (1k to 100k which seems to be the hard limit constrained by energy and cooling requirements). Zürich&rsquo;s datacenter consumes as much energy as an airport.
And we have about 1-200 cores in a single computer of a datacenter.</p>
<p>We also have a limit for RAM and local storage. Respectively about 0.016-24TB of RAM and 1-30TB of storage. Its unthinkable that the RAM memory has the same order of magnitude of local storage. This is because in memory databases are becoming more common (they are usually faster, lower latency).</p>
<p>We also have a bandwidth of 1-200Gbit/s for a single server on an Ethernet cable.</p>
<p>We have standardized <strong>rack</strong> units for every server (or storage if the module is just for storage), storage and routers, they are usually connected together by <em>switches</em> and similar networking thingies. Usually we have 1-4 rack units for a server</p>
<table>
  <thead>
      <tr>
          <th>Type</th>
          <th>Range</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Computers in Data Center</td>
          <td>1k-100k (100k hard limit for electricity designs)</td>
      </tr>
      <tr>
          <td>Cores in a Single computer</td>
          <td>200</td>
      </tr>
      <tr>
          <td>RAM</td>
          <td>0.016-24TB</td>
      </tr>
      <tr>
          <td>Network Bandwidth</td>
          <td>1-200 Gbit</td>
      </tr>
      <tr>
          <td>Racks per server (module)</td>
          <td>1-4</td>
      </tr>
      <tr>
          <td>HDD Storage</td>
          <td>26TB</td>
      </tr>
      <tr>
          <td>Throughput</td>
          <td>261MB/s</td>
      </tr>
      <tr>
          <td>Latency</td>
          <td>4 ms</td>
      </tr>
  </tbody>
</table>
<h4 id="analysis-of-bottlenecks">Analysis of bottlenecks<a hidden class="anchor" aria-hidden="true" href="#analysis-of-bottlenecks">#</a></h4>
<p>We already have said that a way to improve on the possible bottlenecks of our systems is having <strong>better code</strong>: using our resources in a better manner. The easier way is choosing to buy more resources.
Important bottlenecks in our context are CPU, Memory, RAM, and network. We can know if have one of these bottlenecks by monitoring the <em>real-time resource usages</em>.</p>
<p>Disk-IO -&gt; MapReduce and Spark, or using Parquet instead of JSON can</p>
<blockquote>
<p>In fact, you should always first try to improve your code before scaling out. The vast majority of data processing use cases fit on a single machine, and you can save a lot of money as well as get a faster system by squeezing the data on a machine (possibly compressed) and writing very efficient code.</p></blockquote>
<p>For example, an easy way to address a memory bottlenecks is to analyze the classes that are instantiated many many times, but their fields are not often used, or have repeated information.
<strong>Scaling up should be the last resource!</strong>.</p>
<p>For CPU, we should pay attention to the places we are doing so much class hierarchy, type checking, useless loops, overridden methods (they have to dynamically retrieve the function!) And too many method calls that are not easily inlinable.</p>
<p>For DIsk-IO, we use better formats, or compression, and parallel processing frameworks.</p>
<p>For Network, try to get rid of data that doesn&rsquo;t need to be transmitted, and put it in a nicer format so that it is easier to compress it! (This is called Push Down). And use batch processing.</p>
<h2 id="evolution-of-the-data-stack">Evolution of the data stack<a hidden class="anchor" aria-hidden="true" href="#evolution-of-the-data-stack">#</a></h2>
<p>We have 10 layers, instead of the 7 <a href="/notes/architettura-e-livelli-1,-2">Architettura e livelli 1, 2</a> of the ISO OSI layers of the networking.
<img src="/images/notes/Introduction to Big Data-20240924145135862.webp" style="width: 100%" class="center" alt="Introduction to Big Data-20240924145135862"></p>
<p>We will rebuild the whole datastack and understand how every layer works together with one another to handle the big data.</p>
<p>We will link for each part some important nodes regarding those</p>
<ul>
<li><strong>Storage</strong>: <a href="/notes/cloud-storage">Cloud Storage</a>, <a href="/notes/wide-column-storage">Wide Column Storage</a>, <a href="/notes/distributed-file-systems">Distributed file systems</a></li>
<li><strong>Encoding and Syntax</strong>: <a href="/notes/markup">Markup</a></li>
<li><strong>Data models and Validation</strong>: <a href="/notes/data-models-and-validation">Data Models and Validation</a></li>
<li><strong>Processing</strong>: <a href="/notes/massive-parallel-processing">Massive Parallel Processing</a></li>
</ul>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p id=harariNexusBriefHistory2024>[1] Harari <a href="https://books.google.ch/books/about/Nexus.html?id=OcwbEQAAQBAJ&redir_esc=y">“Nexus: A Brief History of Information Networks from the Stone Age to AI”</a> Random House 2024
 </p>
<p id=coddRelationalModelData1970>[2] Codd <a href="https://dl.acm.org/doi/10.1145/362384.362685">“A Relational Model of Data for Large Shared Data Banks”</a> Communications of the ACM Vol. 13(6), pp. 377--387 1970
 </p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://flecart.github.io/tags/big-data/">📓Big-Data</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Big Data on x"
            href="https://x.com/intent/tweet/?text=Introduction%20to%20Big%20Data&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-big-data%2f&amp;hashtags=%f0%9f%93%93big-data">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Big Data on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-big-data%2f&amp;title=Introduction%20to%20Big%20Data&amp;summary=Introduction%20to%20Big%20Data&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-big-data%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Big Data on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-big-data%2f&title=Introduction%20to%20Big%20Data">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Big Data on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-big-data%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Big Data on whatsapp"
            href="https://api.whatsapp.com/send?text=Introduction%20to%20Big%20Data%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-big-data%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Big Data on telegram"
            href="https://telegram.me/share/url?text=Introduction%20to%20Big%20Data&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-big-data%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Big Data on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Introduction%20to%20Big%20Data&u=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-big-data%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
