<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Notes on X. Angelo Huang&#39;s Blog</title>
    <link>https://flecart.github.io/notes/</link>
    <description>Recent content in Notes on X. Angelo Huang&#39;s Blog</description>
    <image>
      <title>X. Angelo Huang&#39;s Blog</title>
      <url>https://flecart.github.io/images/papermod-cover.png</url>
      <link>https://flecart.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.143.1</generator>
    <language>en</language>
    <atom:link href="https://flecart.github.io/notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Communication in the Cloud</title>
      <link>https://flecart.github.io/notes/communication-in-the-cloud/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/communication-in-the-cloud/</guid>
      <description>&lt;p&gt;How can we coordinate services to actually understand what they are doing, or what the user wants them to do? How to manage networks errors? This note will mainly focus on high level communication protocols to coordinate this kind of communication.&lt;/p&gt;
&lt;h2 id=&#34;remote-procedure-calls&#34;&gt;Remote Procedure Calls&lt;/h2&gt;
&lt;h3 id=&#34;history-and-basic-idea&#34;&gt;History and Basic Idea&lt;/h3&gt;
&lt;p&gt;This has been the main idea, introduced in 1984, using the idea of &lt;strong&gt;stubs&lt;/strong&gt;, see &lt;a href=&#34;https://dl.acm.org/doi/10.1145/2080.357392&#34;&gt;(Birrell &amp;amp; Nelson 1984)&lt;/a&gt;. The system basically calls the remote procedure as i&lt;em&gt;f it was local&lt;/em&gt; on the high level, but on a lower level a network request is sent.
The architecture has remained the same in these years.
It hides all the complexity in the stub (marshaling, binding and sending, without caring about the sockets and communication matters).
One problem is that it might be hiding the complexity too well. The programmer has surely an ease of programming, but design consideration should consider overloads generated by the network communication.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Datacenter Hardware</title>
      <link>https://flecart.github.io/notes/datacenter-hardware/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/datacenter-hardware/</guid>
      <description>&lt;p&gt;We want to optimize the parts of the datacenter hardware such that the cost of operating the datacenter as a &lt;em&gt;whole&lt;/em&gt; would be lower, we need to think about it as a whole.&lt;/p&gt;
&lt;h3 id=&#34;datacenter-cpus&#34;&gt;Datacenter CPUs&lt;/h3&gt;
&lt;h4 id=&#34;different-requirements&#34;&gt;Different requirements&lt;/h4&gt;
&lt;p&gt;Hardware needs high level isolation (because it will be shared among different users).
Usually high workloads and moving a lot of data around.&lt;/p&gt;
&lt;p&gt;They have a spectrum of low and high end cores, so that if you have high parallelism you can use lower cores, while for resource intensive tasks, its better to have high end cores, especially for latency critical tasks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>HTTP e REST</title>
      <link>https://flecart.github.io/notes/http-e-rest/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/http-e-rest/</guid>
      <description>&lt;p&gt;HTTP is the acronym for HyperText Transfer Protocol.&lt;/p&gt;
&lt;h3 id=&#34;caratteristiche-principali-3&#34;&gt;Caratteristiche principali (3)&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/HTTP e REST/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/HTTP e REST/Untitled&#34;&gt;
&lt;ol&gt;
&lt;li&gt;Comunicazioni fra client e server, e quanto sono comunicate le cose si chiude la connessione e ci sono politiche di caching molto bone (tipo con i proxy)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generico&lt;/strong&gt;: perch√© √® un protocollo utilizzato per caricare moltissime tipologie di risorse!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stateless&lt;/strong&gt;, ossia non vengono mantenute informazioni su scambi vecchi, in un certo modo ne abbiamo parlato in &lt;a href=&#34;https://flecart.github.io/notes/sicurezza-delle-reti&#34;&gt;Sicurezza delle reti&lt;/a&gt; quando abbiamo parlato di firewall stateless.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Solitamente possiamo intendere questo protocollo come utile per &lt;strong&gt;scambiare risorse&lt;/strong&gt; di cui abbiamo parlato in &lt;a href=&#34;https://flecart.github.io/notes/uniform-resource-identifier&#34;&gt;Uniform Resource Identifier&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Compiler Limitations</title>
      <link>https://flecart.github.io/notes/compiler-limitations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/compiler-limitations/</guid>
      <description>&lt;h4 id=&#34;on-compiler&#34;&gt;On Compiler&lt;/h4&gt;
&lt;p&gt;Adding compilation flags to &lt;code&gt;gcc&lt;/code&gt; not always makes it faster, it just enables a specific set of optimization methods. It&amp;rsquo;s also good to turn on &lt;em&gt;platform specific&lt;/em&gt; flags to turn on some specific optimization methods to that architecture.
Remember that compilers are &lt;strong&gt;conservative&lt;/strong&gt;, meaning they do not apply that optimization if they think it does not always apply.&lt;/p&gt;
&lt;h4 id=&#34;what-are-they-good-at&#34;&gt;What are they good at&lt;/h4&gt;
&lt;p&gt;Compilers are good at: mapping program to machine ‚ñ™ register allocation ‚ñ™ instruction scheduling ‚ñ™ dead code elimination ‚ñ™ eliminating minor inefficiencies&lt;/p&gt;</description>
    </item>
    <item>
      <title>Human Vision</title>
      <link>https://flecart.github.io/notes/human-vision/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/human-vision/</guid>
      <description>&lt;p&gt;Vision is THE most important sense for humans. Most of the information we get is through vision&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;90% vision&lt;/li&gt;
&lt;li&gt;8% tactile, touch&lt;/li&gt;
&lt;li&gt;3% hearing
I have no idea how did they measure this aspect.
This is true for humans, but for mice for example it is different, they have probably a 64x64 pixel resolution equivalent. For humans, visual data is more important, it is faster compared to speech and other senses.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Human vision is estimated to be about 576 Megapixels of data (3M snapshots patched together with saccades, that has that pixel image value), since it can distinguish 0.6arc-minutes (0.01 degrees). There is an estimate of about  60kk rods and 3kk cones.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Memoria</title>
      <link>https://flecart.github.io/notes/memoria/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/memoria/</guid>
      <description>&lt;h2 id=&#34;41-caratteristiche-della-memoria&#34;&gt;4.1 Caratteristiche della Memoria&lt;/h2&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Memoria/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Memoria/Untitled&#34;&gt;
&lt;p&gt;La gerarchia della memoria, pi√π si va gi√π pi√π spazio si ha, pi√π √® lento il caricamento delle informazioni&lt;/p&gt;
&lt;h3 id=&#34;411-catalogazione-della-memoria&#34;&gt;4.1.1 Catalogazione della memoria&lt;/h3&gt;
&lt;p&gt;Le tipologie di memoria sono presenti a fianco.&lt;/p&gt;
&lt;p&gt;In generale pi√π la memoria √® veloce da riprendere, pi√π √® costosa da memorizzare (c&amp;rsquo;√® poco spazio)&lt;/p&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Memoria/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Memoria/Untitled 1&#34;&gt;
&lt;h3 id=&#34;412-byte-e-word&#34;&gt;4.1.2 Byte e Word&lt;/h3&gt;
&lt;p&gt;Il libro a pagina 74 parte con la discussione del perch√© si √® preferito &lt;strong&gt;evitare la BCD&lt;/strong&gt; (Binary coded decimal, in cui i numeri da 0 a 9 erano codificato da 4 bit), per questioni di efficienza.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Message Passing</title>
      <link>https://flecart.github.io/notes/message-passing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/message-passing/</guid>
      <description>&lt;p&gt;ora abbiamo alcune primitive per passarci i messaggi, vogliamo creare metodo in modo che i processi si possano sincronizzare mandando messaggi.&lt;/p&gt;
&lt;p&gt;la memoria &lt;strong&gt;√® sempre privata&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;primitive&#34;&gt;Primitive&lt;/h2&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Message Passing/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Message Passing/Untitled&#34;&gt;
&lt;h3 id=&#34;send-e-receive-&#34;&gt;Send e receive üü©&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Send&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spedizione del messaggio&lt;/li&gt;
&lt;li&gt;input deve avere un &lt;strong&gt;identificato al processo su cui spedire.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Se si vuole espandere si possono avere &lt;strong&gt;multicast e broadcasting&lt;/strong&gt; ma non li studieremo in questo corso.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Receive&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Ricevi messaggi&lt;/p&gt;
&lt;h2 id=&#34;tassonomia-dei-message-passing-&#34;&gt;Tassonomia dei message passing (!)üü©&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fast Fourier Transforms</title>
      <link>https://flecart.github.io/notes/fast-fourier-transforms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/fast-fourier-transforms/</guid>
      <description>&lt;p&gt;The algorithm has been the same, some ideas are in &lt;a href=&#34;https://flecart.github.io/notes/fourier-series&#34;&gt;Fourier Series&lt;/a&gt;, but architectures change, which means there are new ways to make this algorithm even faster.&lt;/p&gt;
&lt;h4 id=&#34;example-of-transforms&#34;&gt;Example of transforms&lt;/h4&gt;
&lt;p&gt;We have learned in &lt;a href=&#34;https://flecart.github.io/notes/algebra-lineare-numerica&#34;&gt;Algebra lineare numerica&lt;/a&gt;, &lt;a href=&#34;https://flecart.github.io/notes/cambio-di-base&#34;&gt;Cambio di Base&lt;/a&gt; that linear transforms are usually a &lt;strong&gt;change of basis&lt;/strong&gt;. They are matrix vector multiplications (additions and multiplications by &lt;em&gt;constants&lt;/em&gt;). The optimizations are based on what sorts of transforms we have (e.g. &lt;a href=&#34;https://flecart.github.io/notes/sparse-matrix-vector-multiplication&#34;&gt;Sparse Matrix Vector Multiplication&lt;/a&gt;, or dense versions).
The same idea applies also for Fourier transforms.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cloud Storage</title>
      <link>https://flecart.github.io/notes/cloud-storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cloud-storage/</guid>
      <description>&lt;h2 id=&#34;object-stores&#34;&gt;Object Stores&lt;/h2&gt;
&lt;h3 id=&#34;characteristics-of-cloud-systems&#34;&gt;Characteristics of Cloud Systems&lt;/h3&gt;
&lt;h4 id=&#34;object-storage-design-principles-&#34;&gt;Object storage design principles üü®++&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t want the hierarchy that is common in &lt;a href=&#34;https://flecart.github.io/notes/filesystem&#34;&gt;Filesystem&lt;/a&gt;s, so we need to simplify that and have these four principles:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Black-box objects&lt;/li&gt;
&lt;li&gt;Flat and global &lt;strong&gt;key-value&lt;/strong&gt; model (trivial model, easy to access, without the need to trasverse a file hierarchy).&lt;/li&gt;
&lt;li&gt;Flexible &lt;strong&gt;metadata&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Commodity hardware (the battery idea of Tesla until 2017).&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;object-storage-usages-&#34;&gt;Object storage usages üü©&lt;/h4&gt;
&lt;p&gt;Object storage are useful to store things that are usually read-intensive. Some examples are&lt;/p&gt;</description>
    </item>
    <item>
      <title>Content Delivery Networks</title>
      <link>https://flecart.github.io/notes/content-delivery-networks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/content-delivery-networks/</guid>
      <description>&lt;p&gt;CDNs are intermediary servers that replicate read intensive data to provide better performance when user requests them.
A close relative of CDNs is edge computing (e.g. gaming stations) where lots of computation is done directly close to the user.&lt;/p&gt;
&lt;h4 id=&#34;types-of-cdns&#34;&gt;Types of CDNs&lt;/h4&gt;
&lt;p&gt;Mainly three types of CDNs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Highly distributed ones.&lt;/li&gt;
&lt;li&gt;Database based ones.&lt;/li&gt;
&lt;li&gt;Ad-hoc CDNs.
&lt;img src=&#34;https://flecart.github.io/images/notes/Content Delivery Networks-20250403143719218.webp&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Content Delivery Networks-20250403143719218&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;advantages-and-disadvantages&#34;&gt;Advantages and disadvantages&lt;/h4&gt;
&lt;p&gt;The main reason we use CDNs is to lower the value of latency: we are in fact bringing the data closer to the user.
We have much less data in length to be transmitted.
Yet we have some disadvantages too:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fast Linear Algebra</title>
      <link>https://flecart.github.io/notes/fast-linear-algebra/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/fast-linear-algebra/</guid>
      <description>&lt;p&gt;Many problems in scientific computing include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solving linear equations&lt;/li&gt;
&lt;li&gt;Eigenvalue computations&lt;/li&gt;
&lt;li&gt;Singular value decomposition&lt;/li&gt;
&lt;li&gt;LU/Cholesky/QR decompositions&lt;/li&gt;
&lt;li&gt;etc&amp;hellip;
And the userbase is quite large for this types of computation (number of scientists in the world is growing exponentially )&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;quick-history-of-performance-computing&#34;&gt;Quick History of Performance Computing&lt;/h4&gt;
&lt;p&gt;Early seventies it was EISPACK and LINPACK. Then In similar years Matlab was invented, which simplified a lot compared to previous systems.
LAPACK redesigned the algorithms in previous libraries to have better block-based locality.
BLAS are kernel functions for each computer, while LAPACK are the higher level functions build on top of BLAS (1, 2,3).
Then another innovation was ATLAS, which automatically generates the code for BLAS for each architecture.
This is called &lt;strong&gt;autotuning&lt;/strong&gt; because it does a search of possible enumerations and chooses the fastest one.
Now autotuning has been done a lot for NN systems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Livello applicazione e socket</title>
      <link>https://flecart.github.io/notes/livello-applicazione-e-socket/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/livello-applicazione-e-socket/</guid>
      <description>&lt;h1 id=&#34;livello-trasporto&#34;&gt;Livello trasporto&lt;/h1&gt;
&lt;h2 id=&#34;protocolli-classici&#34;&gt;Protocolli classici&lt;/h2&gt;
&lt;h3 id=&#34;introduzione-a-tcp-e-upd&#34;&gt;Introduzione a TCP e UPD&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Livello applicazione e socket/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Livello applicazione e socket/Untitled&#34;&gt;
&lt;p&gt;Il quarto livello dei protocolli dell‚Äôarchitettura di Internet √® il livello trasporto (transport), ed √® basato su due protocolli in particolare: il Transmission Control Protocol (&lt;strong&gt;TCP&lt;/strong&gt;) e lo User Data Protocol (&lt;strong&gt;UDP&lt;/strong&gt;), che possono essere usati in alternativa tra loro.&lt;/p&gt;
&lt;p&gt;Questo √® nel genere di *&lt;em&gt;connession oriented&lt;/em&gt; e non, il primo, TCP √® connection oriented, l&amp;rsquo;altro no, questa √® l‚Äôunica differenza fra i due. Questa differenza √® spiegata in maggior dettaglio qui &lt;a href=&#34;https://flecart.github.io/notes/0.3.8-servizi-orientati-alla-connessione--e-non-üü®+&#34;&gt;0.3.8 Servizi orientati alla connessione  e non üü®+&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Memoria virtuale</title>
      <link>https://flecart.github.io/notes/memoria-virtuale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/memoria-virtuale/</guid>
      <description>&lt;h2 id=&#34;memoria-virtuale&#34;&gt;Memoria virtuale&lt;/h2&gt;
&lt;h3 id=&#34;perch√©-√®-utile-la-mv--&#34;&gt;Perch√© √® utile la MV? üü®-&lt;/h3&gt;
&lt;p&gt;I programmi non usano tutta la memoria, ma pensano di averla tutta disponibile dal suo punto di vista. L&amp;rsquo;idea principale √® che molte zone di memoria sono inutili per lungo tempo, possono essere utilizzati per altro.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;caricamento codice dinamico&lt;/strong&gt; Per esempio anche a caricare il codice di un compilatore √® diviso in fasi, se andiamo a caricare tutto, stiamo utilizzando solo un pezzo piccolo, tanta inefficienza, se una pagina contiene una parte del compilatore potrei caricare in memoria solamente le parti eseguite sul momento, giusto per fare un esempio diciamo.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Crescita dei segmenti stack, heap&lt;/strong&gt;, ad esempio ci permette di far crescere come ci pare la stack, e anche caricare solamente le parti della stack che ci servono, e mantenere la memoria libera per altro.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gestione degli errori.&lt;/strong&gt; che utilizzer√† i dati solamente della parte di gestione di memoria attuale diciamo.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;paginazione-a-richiesta-&#34;&gt;Paginazione a richiesta üü©‚Äî&lt;/h3&gt;
&lt;p&gt;Questo √® un aspetto della cache delle pagine di cui abbiamo gi√† parlato in &lt;a href=&#34;https://flecart.github.io/notes/livello-os&#34;&gt;Livello OS&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Paginazione e segmentazione</title>
      <link>https://flecart.github.io/notes/paginazione-e-segmentazione/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/paginazione-e-segmentazione/</guid>
      <description>&lt;h1 id=&#34;memoria-sistema-operativo&#34;&gt;Memoria sistema Operativo&lt;/h1&gt;
&lt;p&gt;Guardare &lt;a href=&#34;https://flecart.github.io/notes/memoria-virtuale&#34;&gt;Memoria virtuale&lt;/a&gt; Per vedere come vengono rimpiazzate le pagine&lt;/p&gt;
&lt;p&gt;In quest sezione andiamo a parlare di come fanno molti processi a venire eseguiti insieme, anche se lo spazio di memoria fisico √® lo stesso. Andiamo quindi a parlare di spazio di indirizzi, risoluzione di questi indirizzi logici, segmentazione e paginazione. (e molto di pi√π!)&lt;/p&gt;
&lt;h2 id=&#34;mmu&#34;&gt;MMU&lt;/h2&gt;
&lt;p&gt;Controlla se l‚Äôaccesso di memoria √® bono o meno.  (traduzione fra indirizzo logico e fisico)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sparse Matrix Vector Multiplication</title>
      <link>https://flecart.github.io/notes/sparse-matrix-vector-multiplication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/sparse-matrix-vector-multiplication/</guid>
      <description>&lt;h3 id=&#34;algorithms-for-sparse-matrix-vector--multiplication&#34;&gt;Algorithms for Sparse Matrix-Vector  Multiplication&lt;/h3&gt;
&lt;h4 id=&#34;compressed-sparse-row----&#34;&gt;Compressed Sparse Row  üü®&amp;ndash;&lt;/h4&gt;
&lt;p&gt;This is an optimized way to store rows for sparse matrices:
&lt;img src=&#34;https://flecart.github.io/images/notes/Cache Optimization-20250331112244798.webp&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Cache Optimization-20250331112244798&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;sparse-mvm-using-csr&#34;&gt;Sparse MVM using CSR&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;smvm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;double&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;col_idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;row_start&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;double&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;double&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;double&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;cm&#34;&gt;/* Loop over m rows */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt; &lt;span class=&#34;cm&#34;&gt;/* Scalar replacement since reused */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;cm&#34;&gt;/* Loop over non-zero elements in row i */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;row_start&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;row_start&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;col_idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s analyze this code:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Spatial locality&lt;/strong&gt;: with respect to &lt;code&gt;row_start&lt;/code&gt;, &lt;code&gt;col_idx&lt;/code&gt; and &lt;code&gt;values&lt;/code&gt; we have spatial locality.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Temporal locality&lt;/strong&gt;: with respect to &lt;code&gt;y&lt;/code&gt; we have temporal locality. (Poor temporal with respect to $x$)&lt;/li&gt;
&lt;li&gt;Good storage efficiency for the sparse matrix.&lt;/li&gt;
&lt;li&gt;But it is 2x slower than the dense matrix multiplication when the matrix is dense.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;block-csr&#34;&gt;Block CSR&lt;/h4&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Sparse Matrix Vector Multiplication-20250331112834561.webp&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Sparse Matrix Vector Multiplication-20250331112834561&#34;&gt;
&lt;p&gt;But we cannot do block optimizations for the cache with this storage method.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Conditioning Theory</title>
      <link>https://flecart.github.io/notes/conditioning-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/conditioning-theory/</guid>
      <description>&lt;h2 id=&#34;associative-conditioning&#34;&gt;Associative Conditioning&lt;/h2&gt;
&lt;h3 id=&#34;classical-conditioning&#34;&gt;Classical Conditioning&lt;/h3&gt;
&lt;h4 id=&#34;pavlovs-experiment&#34;&gt;Pavlov&amp;rsquo;s experiment&lt;/h4&gt;
&lt;p&gt;He was interested in digestive systems of dogs. Then he notices that if we show food to dog, they start to salivate.
If paired with sound (tuning fork) they start to salivate even if they just hear the sound.
He defines two states:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Before conditioning&lt;/li&gt;
&lt;li&gt;During conditioning&lt;/li&gt;
&lt;li&gt;After conditioning state.
Important words are &lt;strong&gt;conditioned stimulus&lt;/strong&gt;, &lt;strong&gt;conditioned response&lt;/strong&gt;. And their oppose (unconditioned).
It is important that it is quite consistent.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Associate unconditioned stimulus with conditioned stimulus.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cache Optimization</title>
      <link>https://flecart.github.io/notes/cache-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cache-optimization/</guid>
      <description>&lt;h3 id=&#34;locality-principles&#34;&gt;Locality principles&lt;/h3&gt;
&lt;p&gt;Remember the two locality principles in &lt;a href=&#34;https://flecart.github.io/notes/memoria&#34;&gt;Memoria&lt;/a&gt;. &lt;strong&gt;Temporal locality&lt;/strong&gt; and &lt;strong&gt;spatial locality&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id=&#34;temporal-locality&#34;&gt;Temporal Locality&lt;/h4&gt;
&lt;p&gt;Some elements just are accessed many times in time. This is an example of a &lt;em&gt;temporal locality&lt;/em&gt;.&lt;/p&gt;
&lt;h4 id=&#34;spatial-locality&#34;&gt;Spatial locality&lt;/h4&gt;
&lt;p&gt;Some elements are accessed close to each other, this is an idea of spatial locality.
In modern architectures, the a line of cache is usually 64 bytes.&lt;/p&gt;
&lt;p&gt;For example consider this snippet:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Sum is an example of &lt;em&gt;temporal locality&lt;/em&gt; as the same memory location (or register) is accessed many times, and the access of the array &lt;code&gt;a&lt;/code&gt; is an example of spatial locality.
loops cycle through the same instructions, this is an example of temporal locality.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Skylake Microprocessor</title>
      <link>https://flecart.github.io/notes/skylake-microprocessor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/skylake-microprocessor/</guid>
      <description>&lt;p&gt;The Skylake processor is a 2015 Intel processor.&lt;/p&gt;
&lt;h4 id=&#34;the-intel-processor&#34;&gt;The Intel Processor&lt;/h4&gt;
&lt;p&gt;In 1978 Intel made the choice to have retrocompatibility for every processor. At that time they had the 8086 processor, with some number of memory bits.
For backwards compatibility intructions have usually just grown.
They used geographic locations because these are not suable.
If we want new code to run for old processors, we should need to put specific flags.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Recurrent Neural Networks</title>
      <link>https://flecart.github.io/notes/recurrent-neural-networks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/recurrent-neural-networks/</guid>
      <description>&lt;p&gt;Recurrent Neural Networks allows us to model &lt;em&gt;arbitrarily long&lt;/em&gt; sequence dependencies, at least in theory. This is very handy, and has many interesting theoretical implication. But here we are also interested in the practical applicability, so we may need to analyze common architectures used to implement these models, the main limitation and drawbacks, the nice properties and some applications.&lt;/p&gt;
&lt;p&gt;These network can bee seen as &lt;strong&gt;chaotic&lt;/strong&gt; systems (non-linear dynamical systems), see Introduction to Chaos Theory.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cloud Reliability</title>
      <link>https://flecart.github.io/notes/cloud-reliability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cloud-reliability/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Reliability is the ability of a system to remain &lt;strong&gt;operational&lt;/strong&gt; over time, i.e., to offer the service it was designed for.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Cloud Hardware and software fails. In this note, we will try to find methods to analyze and predict when components fail, and how we can prevent this problem.&lt;/p&gt;
&lt;h3 id=&#34;defining-the-vocabulary&#34;&gt;Defining the vocabulary&lt;/h3&gt;
&lt;h4 id=&#34;availability&#34;&gt;Availability&lt;/h4&gt;
$$
\text{Availability} = \frac{\text{Uptime}}{\text{Uptime} + \text{Downtime}}
$$&lt;h4 id=&#34;mttf-mean-time-to-failure&#34;&gt;MTTF: Mean Time To Failure&lt;/h4&gt;
$$
\text{MTTF} = \frac{1}{r}
$$&lt;p&gt;
This definition does not include repair time, and assumes the failures are independent with each other.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Devices OS</title>
      <link>https://flecart.github.io/notes/devices-os/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/devices-os/</guid>
      <description>&lt;h2 id=&#34;devices&#34;&gt;Devices&lt;/h2&gt;
&lt;h3 id=&#34;categorizzazione-6-&#34;&gt;Categorizzazione (6)üü®-&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Trasferimento dei dati&lt;/li&gt;
&lt;li&gt;Accesso al device&lt;/li&gt;
&lt;li&gt;sinfonia del trasferimento&lt;/li&gt;
&lt;li&gt;condivisone fra processi&lt;/li&gt;
&lt;li&gt;Velocit√† del trasferimento&lt;/li&gt;
&lt;li&gt;I/O direction (scrittura o lettura)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Vediamo che molte caratteristiche sono riguardo il trasferimento&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide categorizzazione I/O&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Devices OS/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Devices OS/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;blocchi-o-caratteri--&#34;&gt;Blocchi o caratteri üü©-&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide devices blocchi o caratteri&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Devices OS/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Devices OS/Untitled 1&#34;&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Devices OS/Untitled 2.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Devices OS/Untitled 2&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tecniche-di-gestione-devices-4--&#34;&gt;Tecniche di gestione devices (4) üü®-&lt;/h3&gt;
&lt;h4 id=&#34;buffering&#34;&gt;Buffering&lt;/h4&gt;
&lt;p&gt;Possiamo mettere un buffer per favorire la comunicazione fra i devices. la cosa migliore che fa √® creare maggiore efficienza. Un altro motivo √® la &lt;strong&gt;velocit√† diversa di consumo&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Queueing Theory</title>
      <link>https://flecart.github.io/notes/queueing-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/queueing-theory/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Queueing theory is the theory behind what happens when you have lots of jobs, scarce resources, and subsequently long queues and delays. It is literally the ‚Äútheory of queues‚Äù: what makes queues appear and how to make them go away.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is basically what happens in clusters, where you have a limited number of workers that need to execute a number of jobs.&lt;/p&gt;
&lt;p&gt;We need some little maths to model the &lt;strong&gt;stochastic process&lt;/strong&gt; of request arrivals.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Birdsong and Song System</title>
      <link>https://flecart.github.io/notes/birdsong-and-song-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/birdsong-and-song-system/</guid>
      <description>&lt;p&gt;How are inputs made into motion? We analyze feedback systems in auditory systems in birds.&lt;/p&gt;
&lt;h4 id=&#34;motivation&#34;&gt;Motivation&lt;/h4&gt;
&lt;p&gt;Birds are very good at producing and reproducing songs by moving their vocal cords complexly (sensory motor learning).
Birds and Humans do not have much of a common ancestry (last one was fishes).
71% of the birds, both female and male birds sing, for Zebra finch it is a mating behaviour, so only male sing.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cloud Computing Services</title>
      <link>https://flecart.github.io/notes/cloud-computing-services/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cloud-computing-services/</guid>
      <description>&lt;h2 id=&#34;cloud-computing-an-overview&#34;&gt;Cloud Computing: An Overview&lt;/h2&gt;
&lt;p&gt;Cloud shifted the paradigm from owning hardware to renting computing resources on-demand. Hardware became a service.&lt;/p&gt;
&lt;h4 id=&#34;key-players-in-the-cloud-industry-&#34;&gt;Key Players in the Cloud Industry üü®&lt;/h4&gt;
&lt;p&gt;The cloud computing market is dominated by several major providers, often referred to as the &amp;ldquo;Big Seven&amp;rdquo;, also called &lt;strong&gt;hyper-scalers&lt;/strong&gt;. They are usually not interested in making it interoperable (they prefer the lock-in).&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Amazon Web Services (AWS)&lt;/strong&gt;: The largest provider, offering a comprehensive suite of cloud services.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Microsoft Azure&lt;/strong&gt;: Known for deep integration with enterprise systems and hybrid cloud solutions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Google Cloud Platform (GCP)&lt;/strong&gt;: Excels in data analytics, AI/ML, and Kubernetes-based solutions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IBM Cloud&lt;/strong&gt;: Focuses on hybrid cloud and enterprise-grade AI.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Oracle Cloud&lt;/strong&gt;: Specializes in database solutions and enterprise applications.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alibaba Cloud&lt;/strong&gt;: The leading provider in Asia, offering services similar to AWS.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Salesforce&lt;/strong&gt;: A major player in SaaS, particularly for CRM and business applications.&lt;br&gt;
These providers collectively control the majority of the global cloud infrastructure market, enabling scalable and on-demand computing resources for businesses worldwide.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;capital-and-operational-expenses-in-the-cloud&#34;&gt;Capital and Operational Expenses in the Cloud&lt;/h3&gt;
&lt;h4 id=&#34;definition-for-capex-and-opex-&#34;&gt;Definition for CapEx and OpEx üü•&lt;/h4&gt;
&lt;p&gt;Cloud computing transforms traditional IT cost structures by shifting expenses from &lt;strong&gt;capital expenditures (CapEx)&lt;/strong&gt;, such as purchasing servers and data centers, to &lt;strong&gt;operational expenditures (OpEx)&lt;/strong&gt;, where users pay only for the resources they consume.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cluster Resource Management</title>
      <link>https://flecart.github.io/notes/cluster-resource-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cluster-resource-management/</guid>
      <description>&lt;p&gt;We need to find an efficient and effective manner to allocate the resources around. This is what the resource management layer does.&lt;/p&gt;
&lt;h3 id=&#34;introduction-to-the-problem&#34;&gt;Introduction to the problem&lt;/h3&gt;
&lt;h4 id=&#34;what-is-cluster-resource-management&#34;&gt;What is Cluster Resource Management?&lt;/h4&gt;
&lt;p&gt;Most of the time, the user specifies an amount of resources, and then the cluster decides how much to allocate (but approaches like &lt;a href=&#34;https://doi.org/10.1145/2541940.2541941&#34;&gt;(Delimitrou &amp;amp; Kozyrakis 2014)&lt;/a&gt;, do it differently).
There are mainly two parts in cluster resource management:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Allocation&lt;/strong&gt;: deciding how many resources an application.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Assignment&lt;/strong&gt;: from which physical machine you can effectively put the application.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;types-of-management-architectures&#34;&gt;Types of management architectures&lt;/h4&gt;
&lt;p&gt;We mainly divide the management architectures in three ways:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Container Virtualization</title>
      <link>https://flecart.github.io/notes/container-virtualization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/container-virtualization/</guid>
      <description>&lt;h2 id=&#34;containers&#34;&gt;Containers&lt;/h2&gt;
&lt;h4 id=&#34;what-is-a-container-&#34;&gt;What is a Container üü®++&lt;/h4&gt;
&lt;p&gt;We have explored virtual machines in &lt;a href=&#34;https://flecart.github.io/notes/architettura-software-del-os#macchine-virtuali&#34;&gt;Architettura software del OS#Macchine virtuali&lt;/a&gt;.
Containers do not virtualize everything, but just the environment where the application is run. This includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Libraries&lt;/li&gt;
&lt;li&gt;Binaries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can see it as a &lt;em&gt;lightweight&lt;/em&gt; VM, even if they do not offer the full level of isolation of traditional virtual machines.&lt;/p&gt;
&lt;figure class=&#34;center&#34;&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Container Virtualization-20250226134043539.webp&#34; style=&#34;width: 100%&#34;   alt=&#34;Container Virtualization-20250226134043539&#34; title=&#34;Container Virtualization-20250226134043539&#34;/&gt;
&lt;figcaption&gt;&lt;p style=&#34;text-align:center;&#34;&gt;Image from the course slides&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h4 id=&#34;containers-vs-virtual-machines-vms---&#34;&gt;Containers vs. Virtual Machines (VMs) üü®&amp;ndash;&lt;/h4&gt;
&lt;p&gt;Docker is one of the most famous containerization tools, but there are many others like Podman, LXC, or Singularity. They have different roles and scopes.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Control Plane</title>
      <link>https://flecart.github.io/notes/control-plane/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/control-plane/</guid>
      <description>&lt;h3 id=&#34;tipologie-di-control-plane&#34;&gt;Tipologie di control plane&lt;/h3&gt;
&lt;p&gt;La control plane √® la parte al livello di rete che si occupa di &lt;strong&gt;riempire le tabelle di instradamento dei router&lt;/strong&gt;. In questo caso si possono in generare dividere gli algoritmi in due grandi famiglie&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Centralizzati&lt;/strong&gt;, anche chiamati &lt;strong&gt;algoritmi LS( Link state)&lt;/strong&gt; perch√© devono conoscere in che modo sono collegati i router fra di loro. Solitamente le &lt;strong&gt;SDN&lt;/strong&gt; ossia software defined networking di cui abbiamo parlato in &lt;a href=&#34;https://flecart.github.io/notes/data-plane&#34;&gt;Data Plane&lt;/a&gt; utilizzano questi metodi, c&amp;rsquo;√® un server centralizzato (che per ragioni di tolleranza pu√≤ anche essere distribuito, per√≤ diciamo che √® esterno al router la decisione)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Distribuiti&lt;/strong&gt; in cui nessuno ha informazioni complete sulla rete, ma √® possibile scambiarsi informazioni sui vicini e congiungere cos√¨ al percorso pi√π breve. Vengono in questa sede utilizzati algoritmi di &lt;strong&gt;distance vector&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Possono anche essere &lt;strong&gt;statici&lt;/strong&gt;, ma dato che la topologia della rete √® spesso dinamica √® difficile che vengano utilizzati. Sono molto pi√π preferibili gli algoritmi dinamici che vanno ogni tot ad aggiornare le tabelle.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Plane</title>
      <link>https://flecart.github.io/notes/data-plane/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/data-plane/</guid>
      <description>&lt;h2 id=&#34;introduzione-data-or-control-plane&#34;&gt;Introduzione Data or Control plane&lt;/h2&gt;
&lt;p&gt;Come fanno i router a fare forwarding dei pacchetti? Come fanno a decidere come e dove mandare? Sono le tabelle di instradamento che decidono il prossimo hop del pacchetto.
Si pu√≤ dire di &lt;strong&gt;end-to-end&lt;/strong&gt; perch√© solamente il sender e receiver andranno a livello applicazione, e leggeranno le cose (se criptato veramente solo loro riescono a fare questo).&lt;/p&gt;
&lt;h3 id=&#34;funzioni-principali&#34;&gt;Funzioni principali&lt;/h3&gt;
&lt;p&gt;Il &lt;strong&gt;data plane&lt;/strong&gt; √® la parte che si occupa di fare il forwarding, ossia risponde a domande come &amp;ldquo;come faccio a mandare in modo efficiente questo pacchetto l√¨?&amp;rdquo; mentre il &lt;strong&gt;control plane&lt;/strong&gt; si occupa di fare il routing, ossia risponde a domande &amp;ldquo;Dove mando il pacchetto che ho?&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linguaggi Deterministici e DPDA</title>
      <link>https://flecart.github.io/notes/linguaggi-deterministici-e-dpda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/linguaggi-deterministici-e-dpda/</guid>
      <description>&lt;h2 id=&#34;dpda&#34;&gt;DPDA&lt;/h2&gt;
&lt;h3 id=&#34;definizione-2&#34;&gt;Definizione (2)üü©&lt;/h3&gt;
&lt;p&gt;La definizione di DPDA √® molto simile a quella trattata in &lt;a href=&#34;https://flecart.github.io/notes/linguaggi-liberi-e-pda&#34;&gt;Linguaggi liberi e PDA&lt;/a&gt;, con solo costraints sulla deterministicit√†, che si traducono in due condizioni:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Al massimo posso avere un risultato per ogni coppia di lettura e simbolo su stack&lt;/li&gt;
&lt;li&gt;Se ho una transizione senza leggere, posso avere solo quella&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Linguaggi Deterministici e DPDA/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Linguaggi Deterministici e DPDA/Untitled 1&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;linguaggio-libero-deterministico&#34;&gt;Linguaggio libero deterministico&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Un linguaggio √® libero deterministico se esiste un PDA che lo riconosce per &lt;strong&gt;stato finale&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linguaggi liberi e PDA</title>
      <link>https://flecart.github.io/notes/linguaggi-liberi-e-pda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/linguaggi-liberi-e-pda/</guid>
      <description>&lt;p&gt;In questa parte del nostro percorso nei linguaggi di programmazione proviamo ad espandere NFA e DFA in modo che possano riconoscere linguaggi come $ww^r | w \in \{a, b\}^*$ , con r maggiore o uguale a zero (r per dire che √® il contrario di w) (questo linguaggio per il pumping lemma).&lt;/p&gt;
&lt;h4 id=&#34;grammatiche-libere-da-contesto&#34;&gt;Grammatiche libere da contesto&lt;/h4&gt;
$$
G = \langle \mathcal{N}, S, \Sigma, \mathcal{R} \rangle 
$$&lt;p&gt;
Dove $\mathcal{N}$ sono i non terminali, $S$ √® il non terminale iniziale, $\Sigma$ sono l&amp;rsquo;alfabeto dei simboli finali e $\mathcal{R}$ le relazioni possibili.
Spesso lo scriviamo solo tramite le relazioni, perch√© √® la forma pi√π compatta.
I nodi di una derivazione da grammatica libera da contesto √® chiamato &lt;strong&gt;costituente del linguaggio&lt;/strong&gt;. Questo √® pi√π importante in linguistica.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LR(k) e YACC</title>
      <link>https://flecart.github.io/notes/lrk-e-yacc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/lrk-e-yacc/</guid>
      <description>&lt;h2 id=&#34;lrk&#34;&gt;LR(k)&lt;/h2&gt;
&lt;h3 id=&#34;grammatiche-lrk-&#34;&gt;Grammatiche LR(k) üü©&lt;/h3&gt;
&lt;p&gt;Anche in questo caso proviamo a generalizzare il concetto dei pirmi k caratteri, in modo da generalizzare in qualche senso il concetto di LR(k), quindi &lt;strong&gt;andiamo a modificare la closure&lt;/strong&gt; considerando ora first k&lt;/p&gt;
&lt;p&gt;Per ricordarti come si calcolava first k, andare a guardare &lt;a href=&#34;https://flecart.github.io/notes/top-down-parser&#34;&gt;Top-down Parser&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;il problema che poi diventa pratico riguardo questo √® l&amp;rsquo;impossibilit√† di gestire &lt;strong&gt;stringhe lunghezza k&lt;/strong&gt; che sono una assurdit√† (esponenziale per la lunghezza)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Macchine Astratte</title>
      <link>https://flecart.github.io/notes/macchine-astratte/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/macchine-astratte/</guid>
      <description>&lt;h3 id=&#34;definizione-ed-esempi-per-macchine-astratte-&#34;&gt;Definizione ed esempi per macchine astratte üü©&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Una macchina astratta √® un qualunque insieme di algoritmi e strutture di dati che permettono di memorizzare ed eseguire il linguaggio $L$, quindi una macchina astratta esiste per esguire &lt;strong&gt;il proprio linguaggio&lt;/strong&gt; (inteso come insieme finito di istruzioni primitive che riesce ad  comprendere e eseguire).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Si pu√≤ proprio dire che &lt;em&gt;esiste una simbiosi&lt;/em&gt; fra macchina e linguaggio. Si potrebbe dire che la macchina fisica √® soltanto una implementazione FISICA di un linguaggio, ossia una macchina che capisce ed esegue quel linguaggio e che sia solamente un caso particolare della macchina astratta.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Nomi e Scope</title>
      <link>https://flecart.github.io/notes/nomi-e-scope/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/nomi-e-scope/</guid>
      <description>&lt;h2 id=&#34;i-nomi-e-oggetti&#34;&gt;I Nomi e oggetti&lt;/h2&gt;
&lt;h3 id=&#34;oggetti-denotati-e-identificatori&#34;&gt;Oggetti denotati e identificatoriüü©&lt;/h3&gt;
&lt;p&gt;I nomi sono sequenze di caratteri o numeri aka: &lt;strong&gt;token alfanumerico&lt;/strong&gt; (anche &lt;strong&gt;IDENTIFICATORE&lt;/strong&gt; (per token guardare &lt;a href=&#34;https://flecart.github.io/notes/grammatiche-regolari&#34;&gt;Grammatiche Regolari&lt;/a&gt;) utilizzate principalmente come &lt;strong&gt;Astrazione sul controllo e sui dati&lt;/strong&gt; (quindi sono cose molto pi√π facili da ricordare rispetto il suo encoding binario o a indirizzi). Infatti utilizziamo i nomi per evitare di interessarci di informazioni come l&amp;rsquo;indirizzo di memoria del nostro dato o per creare una interfaccia con visibili solo nome della procedura e parametri.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Object orientation</title>
      <link>https://flecart.github.io/notes/object-orientation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/object-orientation/</guid>
      <description>&lt;p&gt;Ripasso Prox: 10
Ripasso: May 29, 2023
Ultima modifica: May 19, 2023 10:33 AM
Primo Abbozzo: May 8, 2023 9:20 AM
Stato: üåïüåïüåïüåïüåë
Studi Personali: No&lt;/p&gt;
&lt;h1 id=&#34;elementi-di-ripasso&#34;&gt;Elementi di ripasso&lt;/h1&gt;
&lt;h1 id=&#34;object-orientation&#34;&gt;Object orientation&lt;/h1&gt;
&lt;h2 id=&#34;il-tipo-di-dato-astratto&#34;&gt;il tipo di dato astratto&lt;/h2&gt;
&lt;h3 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h3&gt;
&lt;p&gt;Per questi tipi di dato non ci interessa di sapere cosa ci sia sotto (storato come bit? storato come sabbia boh), ci interessa solamente che abbia quei metodi, che possiamo in un certo senso identificare come la sua capsula, &lt;strong&gt;opaca&lt;/strong&gt; in questo caso.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Polimorfismo</title>
      <link>https://flecart.github.io/notes/polimorfismo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/polimorfismo/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;monoforfo-&#34;&gt;Monoforfo üü©&lt;/h3&gt;
&lt;p&gt;Quando non posso utilizzare un tipo come parametro. Ossia non possiamo definire una funzione generica.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide monomorfismo&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Polimorfismo/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Polimorfismo/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;polimorfismo&#34;&gt;Polimorfismo&lt;/h2&gt;
&lt;p&gt;Polimorfismo, come dice il nome, significa avere tante forme, in questo caso tanti tipi. Ma avere tanti tipi non √® una cosa ambigua? Questa cosa si risolve solitamente a compile time (facendo checks di sottotipo, oppure dispatch della funzione corretta).&lt;/p&gt;
&lt;h3 id=&#34;tipologie-di-polimorfismo-3-&#34;&gt;Tipologie di Polimorfismo (3) üü©&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide tipologie di monomorfismo&lt;/p&gt;</description>
    </item>
    <item>
      <title>Semantica di un linguaggio</title>
      <link>https://flecart.github.io/notes/semantica-di-un-linguaggio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/semantica-di-un-linguaggio/</guid>
      <description>&lt;h2 id=&#34;vincoli-sintattici-contestuali&#34;&gt;Vincoli sintattici contestuali&lt;/h2&gt;
&lt;h3 id=&#34;intro-dipendenze-da-contesto-&#34;&gt;Intro: dipendenze da contesto üü©&lt;/h3&gt;
&lt;p&gt;I vincoli sintattici non sono esprimibili tramite BNF perch√© dipendono dal contesto, mentre le grammatiche libere sono per definizione libere da contesto, vogliamo quindi trovare una soluzione a questo problema. Vengono usati metodi Ad-Hoc nella fase di &lt;strong&gt;analisi semantica&lt;/strong&gt; del programma.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Grammatiche dipendenti dal contesto&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Queste grammatiche sono molto pi√π complicate (e lente) rispetto a quelle libere da contesto, quindi √® poco pratico e non utilizzabile (tempo esponenziale, quindi non finisce mai).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Semplificazione grammatiche</title>
      <link>https://flecart.github.io/notes/semplificazione-grammatiche/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/semplificazione-grammatiche/</guid>
      <description>&lt;h2 id=&#34;gestione-del-non-determinismo&#34;&gt;Gestione del non determinismo&lt;/h2&gt;
&lt;p&gt;Il modo pi√π facile per gestire il non determinsmo √® &lt;strong&gt;semplificare le grammatiche&lt;/strong&gt; quindi andiamo a vedere metodi per fare ci√≤.&lt;/p&gt;
&lt;h3 id=&#34;semplificazione-grammatiche-5&#34;&gt;Semplificazione grammatiche (5)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Semplificazione grammatiche/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Semplificazione grammatiche/Untitled 1&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;No produzioni del tipo $A \to \varepsilon$ per bottom up (altrimenti va all&amp;rsquo;infinito!)&lt;/li&gt;
&lt;li&gt;No produzioni unitarie, cos√¨ evito cicli in cui da A derivo s√© stesso.&lt;/li&gt;
&lt;li&gt;No simboli inutili&lt;/li&gt;
&lt;li&gt;No ricorsione sinistra (divergenza per top-down)&lt;/li&gt;
&lt;li&gt;Fattorizzazione della grammatica&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;eliminazione-delel-produzioni-nulle&#34;&gt;Eliminazione delel produzioni nulle&lt;/h2&gt;
&lt;p&gt;Vogliamo creare un algoritmo utile ad eliminare le produzioni che non ci piacciono.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Teoria dei Tipi</title>
      <link>https://flecart.github.io/notes/teoria-dei-tipi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/teoria-dei-tipi/</guid>
      <description>&lt;p&gt;Ripasso Prox: 30
Ripasso: June 6, 2023
Ultima modifica: May 14, 2023 6:13 PM
Primo Abbozzo: March 13, 2023 9:20 AM
Studi Personali: No&lt;/p&gt;
&lt;h1 id=&#34;elementi-di-ripasso&#34;&gt;Elementi di ripasso&lt;/h1&gt;
&lt;h1 id=&#34;teoria-dei-tipi&#34;&gt;Teoria dei Tipi&lt;/h1&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;definizione-&#34;&gt;Definizione üü©‚Äî&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Un metodo sintattico &lt;strong&gt;praticabile&lt;/strong&gt; per dimostrare
l&amp;rsquo;assenza di determinati comportamenti del
programma, fatto classificando le unit√† sintattiche in
base ai tipi di valore che assumono&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Vogliamo che fosse praticabile nel senso che effettivamente lo possiamo implementare, cio√® ci permettono di avere certe tipologie di garanzia. ma ancora √® una definizione molto ampia. E di solito si pu√≤ fare una analisi statica del comportamento del programma.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Top-down Parser</title>
      <link>https://flecart.github.io/notes/top-down-parser/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/top-down-parser/</guid>
      <description>&lt;h2 id=&#34;top-down&#34;&gt;Top-down&lt;/h2&gt;
&lt;h3 id=&#34;algoritmo-di-parsing-&#34;&gt;Algoritmo di parsing üü©&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Top-down Parser/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Top-down Parser/Untitled 1&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Questo si potrebbe considerare come algoritmo classico di parsing con non determinismo. (vado avanti, ed esploro tutto, senza look ahead).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Esempio di esecuzione&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Top-down Parser/Untitled 2.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Top-down Parser/Untitled 2&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;commenti-efficienza-di-sopra-&#34;&gt;Commenti efficienza di sopra üü©&lt;/h3&gt;
&lt;p&gt;√à molto inefficiente, in particolare si potrebbe trovare una compessit√† esponenziale del tipo&lt;/p&gt;
&lt;p&gt;$O(b^{|w|})$, con b il massimo numero di produzioni. (la produzione maggiore la espando sempre!)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Valutazione Espressioni</title>
      <link>https://flecart.github.io/notes/valutazione-espressioni/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/valutazione-espressioni/</guid>
      <description>&lt;h1 id=&#34;espressioni-comandi-ricorsione&#34;&gt;Espressioni, Comandi, Ricorsione&lt;/h1&gt;
&lt;h2 id=&#34;espressioni&#34;&gt;Espressioni&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Con espressione intendiamo una entit√† sintattica, che una volta valutata &lt;strong&gt;ritorner√† un valore&lt;/strong&gt;, oppure non termina, in questo caso si dice che la espressione √® INDEFINITA.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Questa √® una definizione √® leggermente ambigua dato che non abbiamo una definizione precisa di valutazoine, che √® fortemente dipendente dalla macchina astratta in cui viene eseguito.&lt;/p&gt;
&lt;h3 id=&#34;notazioni-sintassi-possibili-3-&#34;&gt;Notazioni (sintassi possibili) (3) üü©&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Notazione infissa&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Questa √® la notazione classica matematica, per cose tipo $a -b$, in cui l&amp;rsquo;operando sta nel mezzo degli operatori.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Architettura software del OS</title>
      <link>https://flecart.github.io/notes/architettura-software-del-os/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/architettura-software-del-os/</guid>
      <description>&lt;p&gt;A seconda dell&amp;rsquo;utilizzatore l‚ÄôOS pu√≤ essere molte cose, come solamente l‚Äôinterfaccia se sei un programmatore, servizi (se sei un utente, ma gran parte dei servizi sono astratti e l&amp;rsquo;utente ne pu√≤ anche essere a non-conoscenza).&lt;/p&gt;
&lt;p&gt;Ma se sei un programmatore OS ti interessa capire le componenti principali dell‚ÄôOS&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slide componenti OS alto livello
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Architettura software del OS/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Architettura software del OS/Untitled&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduzione-sui-componenti-salto&#34;&gt;Introduzione sui componenti (salto)&lt;/h2&gt;
&lt;p&gt;Questa parte la salto perch√© √® una descrizione molto generale di cosa si occupa L‚Äôos verso drivers, processi, filesystem I/O, quindi non √® molto importante&lt;/p&gt;</description>
    </item>
    <item>
      <title>Clustering</title>
      <link>https://flecart.github.io/notes/clustering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/clustering/</guid>
      <description>&lt;h3 id=&#34;gaussian-mixture-models&#34;&gt;Gaussian Mixture Models&lt;/h3&gt;
&lt;p&gt;This set takes inspiration from chapter 9.2 of &lt;a href=&#34;https://link.springer.com/book/9780387310732&#34;&gt;(Bishop 2006)&lt;/a&gt;.
We assume that the reader already knows quite well what is a &lt;a href=&#34;https://flecart.github.io/notes/gaussian-mixture-models&#34;&gt;Gaussian mixture model&lt;/a&gt; and we will just restate the models here. We will discuss the problem of estimating the best possible parameters (so, this is a density estimation problem) when the data is generated by a mixture of Gaussians.&lt;/p&gt;
$$
\mathcal{N}(x \mid \mu, \Sigma) = \frac{1}{\sqrt{ 2\pi }} \frac{1}{\lvert \Sigma \rvert^{1/2}  } \exp \left( -\frac{1}{2} (x - \mu)^{T} \Sigma^{-1}(x - \mu) \right) 
$$&lt;h4 id=&#34;problem-statement-&#34;&gt;Problem statement üü©&lt;/h4&gt;
$$
p(z) = \prod_{i = 1}^{k} \pi_{i}^{z_{i}}
$$&lt;p&gt;
Because we know that $z$ is a $k$ dimensional vector that has a single digit indicating which Gaussian was chosen.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gaussians</title>
      <link>https://flecart.github.io/notes/gaussians/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/gaussians/</guid>
      <description>&lt;p&gt;Gaussians are one of the most important family of probability distributions.
They arise naturally in the &lt;a href=&#34;https://flecart.github.io/notes/central-limit-theorem-and-law-of-large-numbers&#34;&gt;law of large numbers&lt;/a&gt; and have some nice properties that we will briefly present and prove here in this note. They are also quite common for &lt;a href=&#34;https://flecart.github.io/notes/gaussian-processes&#34;&gt;Gaussian Processes&lt;/a&gt; and the &lt;a href=&#34;https://flecart.github.io/notes/clustering&#34;&gt;Clustering&lt;/a&gt; algorithm. They have also something to say about &lt;a href=&#34;https://flecart.github.io/notes/maximum-entropy-principle&#34;&gt;Maximum Entropy Principle&lt;/a&gt;.
The best thing if you want to learn this part actually well is section 2.3 of &lt;a href=&#34;https://link.springer.com/book/9780387310732&#34;&gt;(Bishop 2006)&lt;/a&gt;, so go there my friend :)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Anomaly Detection</title>
      <link>https://flecart.github.io/notes/anomaly-detection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/anomaly-detection/</guid>
      <description>&lt;p&gt;Anomaly detection is a problem in machine learning that is of a big interest in industry. For example a bank needs to identify problems in transactions, doctors need it to see illness, or suspicious behaviors for law (no Orwell here).
The main difference between this and classification is that here we have no classes.&lt;/p&gt;
&lt;h4 id=&#34;setting-of-the-problem&#34;&gt;Setting of the problem&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s say we have a set $X = \left\{ x_{1}, \dots, x_{n} \right\} \subseteq \mathcal{N} \subseteq \mathcal{X} = \mathbb{R}^{d}$  We say this set is the normal set, and $X$ are our samples but it&amp;rsquo;s quite complex, so we need an approximation to say whether if a set is normal or not.
We need a function $\phi : \mathcal{X} \to \left\{ 0, 1 \right\}$ with $\phi(x) = 1 \iff x \not \in \mathcal{N}$.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bayesian neural networks</title>
      <link>https://flecart.github.io/notes/bayesian-neural-networks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/bayesian-neural-networks/</guid>
      <description>&lt;h3 id=&#34;robbins-moro-algorithm&#34;&gt;Robbins-Moro Algorithm&lt;/h3&gt;
&lt;h4 id=&#34;the-algorithm&#34;&gt;The Algorithm&lt;/h4&gt;
$$
w_{n+1} = w_{n} - \alpha_{n} \Delta w_{n}
$$&lt;p&gt;For example with $\alpha_{0} &gt; \alpha_{1} &gt; \dots &gt; \alpha_{n} \dots$, and $\alpha_{t} = \frac{1}{t}$ they satisfy the condition (in practice we use a constant $\alpha$, but we lose the convergence guarantee by Robbins Moro).
More generally, the Robbins-Moro conditions re:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$\sum_{n} \alpha_{n} = \infty$&lt;/li&gt;
&lt;li&gt;$\sum_{n} \alpha_{n}^{2} &lt; \infty$
Then the algorithm is guaranteed to converge to the best answer.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;One nice thing about this, is that we &lt;strong&gt;don&amp;rsquo;t need gradients&lt;/strong&gt;.
But often we use gradient versions (stochastic gradient descent and similar), using auto-grad, see &lt;a href=&#34;https://flecart.github.io/notes/backpropagation&#34;&gt;Backpropagation&lt;/a&gt;.
But learning with gradients brings some drawbacks:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Architecture of the Brain</title>
      <link>https://flecart.github.io/notes/architecture-of-the-brain/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/architecture-of-the-brain/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;First, the brain is organized into functionally specific areas, and second, neurons in different parts of the vertebrate nervous system, indeed in all nervous systems, are quite similar.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;small-comparison-with-computers&#34;&gt;Small comparison with Computers&lt;/h4&gt;
&lt;p&gt;A gross observation between computer&amp;rsquo;s transistors and human neurons is that there a big difference of numbers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;trillions of transistors vs billions of neurons.&lt;/li&gt;
&lt;li&gt;6 orders of magnitude frequency difference.&lt;/li&gt;
&lt;li&gt;Many many neural types and different types of connections.&lt;/li&gt;
&lt;li&gt;And the digital vs analog and chemical modes of communication.&lt;/li&gt;
&lt;li&gt;Parallel processor abilities.&lt;/li&gt;
&lt;li&gt;Fixed vs plastic architectures
But this is comparing with transistors with one higher level object, so this comparison might not be completely fair.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And only some brain areas are similar to real neural networks&lt;/p&gt;</description>
    </item>
    <item>
      <title>Backpropagation</title>
      <link>https://flecart.github.io/notes/backpropagation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/backpropagation/</guid>
      <description>&lt;p&gt;Backpropagation is perhaps the most important algorithm of the 21st century. It is used everywhere in machine learning and is also connected to computing marginal distributions. This is why all machine learning scientists and data scientists should understand this algorithm very well.
An important observation is that this algorithm is &lt;strong&gt;linear&lt;/strong&gt;: the time complexity is the same as the forward pass. Derivatives are unexpectedly cheap to calculate. This took a lot of time to discover. See &lt;a href=&#34;https://colah.github.io/posts/2015-08-Backprop/&#34;&gt;colah&amp;rsquo;s blog&lt;/a&gt;.
&lt;a href=&#34;https://youtu.be/VMj-3S1tku0?si=wRCObFw7woZTwU56&#34;&gt;Karpathy&lt;/a&gt; has a nice resource for this topic too!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Memory in Human Brain</title>
      <link>https://flecart.github.io/notes/memory-in-human-brain/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/memory-in-human-brain/</guid>
      <description>&lt;p&gt;Here we attempt to answer what is memory, how is it stored and retrieved.&lt;/p&gt;
&lt;p&gt;Memory is a process by which information is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encoded&lt;/li&gt;
&lt;li&gt;Stored&lt;/li&gt;
&lt;li&gt;Retrieved
The brain has different types of memories, and certain brain regions are specialized for this task.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;ebbinghaus-curves&#34;&gt;Ebbinghaus Curves&lt;/h4&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Memory in Human Brain-20250312200342781.webp&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Memory in Human Brain-20250312200342781&#34;&gt;
&lt;p&gt;Other experiments destroy  parts of the cortex and correlate this with recall.&lt;/p&gt;
&lt;h3 id=&#34;types-of-memory&#34;&gt;Types of memory&lt;/h3&gt;
&lt;p&gt;TODO see Kendal67-1 figure.&lt;/p&gt;
&lt;h4 id=&#34;sensory-memory&#34;&gt;Sensory memory&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;iconic memory (remembering images) 150-500 milliseconds&lt;/li&gt;
&lt;li&gt;Echoic memory (recognizing some sounds) usually retained for 1 to 2 seconds.
This memory is filtered by &lt;em&gt;consciousness/attention&lt;/em&gt; to be passed to short term working memory.
The register capacity of this memory is considered to be quite large.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;short-term-memory&#34;&gt;Short-term memory&lt;/h4&gt;
&lt;p&gt;it has an explicit storage of about 7 +- 2 items (so very small).
Depending on attention level, it is retained for 2 to 18 seconds.
It seems the representation here is often &lt;strong&gt;vocal&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cluster Management Policies</title>
      <link>https://flecart.github.io/notes/cluster-management-policies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cluster-management-policies/</guid>
      <description>&lt;h3 id=&#34;introduction-to-cluster-management&#34;&gt;Introduction to cluster management&lt;/h3&gt;
&lt;p&gt;How can we &lt;strong&gt;allocate&lt;/strong&gt; the resources in a cluster in an efficient manner? How can we allocate resources fairly?&lt;/p&gt;
&lt;h4 id=&#34;two-step-allocations-&#34;&gt;Two step allocations üü®++&lt;/h4&gt;
&lt;p&gt;There are two main kinds of allocation: first you need to allocate resources to a process, then allocate the process physically in the cluster.&lt;/p&gt;
&lt;h4 id=&#34;private-and-public-cluster-management-&#34;&gt;Private and public cluster management üü•++&lt;/h4&gt;
&lt;p&gt;Cluster management could be private or public.&lt;/p&gt;
&lt;p&gt;Private means every app is managing their own sub-cluster: each app receives a private, &lt;strong&gt;static&lt;/strong&gt; set of resources. Here it is easier to manage hardware for various needs.
Public means there is a big cluster, like standard third party&lt;/p&gt;</description>
    </item>
    <item>
      <title>Generative Adversarial Networks</title>
      <link>https://flecart.github.io/notes/generative-adversarial-networks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/generative-adversarial-networks/</guid>
      <description></description>
    </item>
    <item>
      <title>Notazione Asintotica</title>
      <link>https://flecart.github.io/notes/notazione-asintotica/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/notazione-asintotica/</guid>
      <description>&lt;h2 id=&#34;introduzione-alla-notazione-asintotica&#34;&gt;Introduzione alla notazione asintotica&lt;/h2&gt;
&lt;p&gt;Cercare di definire il tempo impiegato da una funzione per essere eseguita &lt;strong&gt;in termini di DIMENSIONE dell&amp;rsquo;input&lt;/strong&gt;. **(il numero di bit a livello basso basso)&lt;/p&gt;
&lt;p&gt;Ma abbiamo il problema di misura, in quanto dobbiamo considerare delle variabili che siano indipendenti rispetto alla macchina.&lt;/p&gt;
&lt;h3 id=&#34;caratteristiche-della-notazione&#34;&gt;Caratteristiche della notazione&lt;/h3&gt;
&lt;p&gt;Vogliamo considerare una notazione asintotica (che guarda quanto fa il comportamento verso l&amp;rsquo;infinito)&lt;/p&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Notazione Asintotica/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Notazione Asintotica/Untitled&#34;&gt;
### Accesso di memoria
Ogni operazione in un processore moderno ha in generale un numero di accessi in memoria constante (solitamente abbiamo sempre un numero fissato di operandi possibile, questo significa che se un certo algoritmo ha una certa complessit√†, resta di questa complessit√† anche tenendo in considerazione le operazioni di accesso di memoria).
&lt;p&gt;Questo discorso non tiene pi√π se teniamo in considerazione numeri a precisione infinita, che possono avere un numero arbitrario di accessi in memoria per poter essere computato.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Perceptron Model</title>
      <link>https://flecart.github.io/notes/the-perceptron-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/the-perceptron-model/</guid>
      <description>&lt;p&gt;The &lt;strong&gt;perceptron&lt;/strong&gt; is a fundamental binary linear classifier introduced by &lt;a href=&#34;https://psycnet.apa.org/record/1959-09865-001&#34;&gt;(Rosenblatt 1958)&lt;/a&gt;. It maps an input vector $\mathbf{x} \in \mathbb{R}^n$ to an output $y \in \{0,1\}$ using a weighted sum followed by a threshold function.&lt;/p&gt;
&lt;h3 id=&#34;the-mathematical-definition&#34;&gt;The Mathematical Definition&lt;/h3&gt;
&lt;p&gt;Given an input vector $\mathbf{x} = (x_1, x_2, \dots, x_n)$ and a weight vector $\mathbf{w} = (w_1, w_2, \dots, w_n)$, the perceptron computes:&lt;/p&gt;
$$
z = \mathbf{w}^\top \mathbf{x} + b = \sum_{i=1}^{n} w_i x_i + b
$$&lt;p&gt;where $b$ is the &lt;strong&gt;bias&lt;/strong&gt; term. The output is determined by the Heaviside step function:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Massive Parallel Processing</title>
      <link>https://flecart.github.io/notes/massive-parallel-processing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/massive-parallel-processing/</guid>
      <description>&lt;p&gt;We have a group of mappers that work on dividing the keys for some reducers that actually work on that same group of data. The bottleneck is the assigning part: when mappers finish and need to handle the data to the reducers.&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;h4 id=&#34;common-input-formats-&#34;&gt;Common input formats üü®&lt;/h4&gt;
&lt;p&gt;You need to know well what&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Shards&lt;/li&gt;
&lt;li&gt;Textual input&lt;/li&gt;
&lt;li&gt;binary, parquet and similars&lt;/li&gt;
&lt;li&gt;CSV and similars&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sharding-&#34;&gt;Sharding üü©&lt;/h4&gt;
&lt;p&gt;It is a common practice to divide a big dataset into &lt;em&gt;chunks&lt;/em&gt; (or shards), smaller parts which recomposed give the original dataset.
For example, in &lt;a href=&#34;https://flecart.github.io/notes/cloud-storage&#34;&gt;Cloud Storage&lt;/a&gt; settings we often divide big files into chunks, while in &lt;a href=&#34;https://flecart.github.io/notes/distributed-file-systems&#34;&gt;Distributed file systems&lt;/a&gt; the system automatically divides big files into native files of maximum 10 GB size.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Neural mechanisms</title>
      <link>https://flecart.github.io/notes/neural-mechanisms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/neural-mechanisms/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;The synaptic connections that define such circuits are typically made in a dense tangle of dendrites, axons terminals, and glial cell processes that together constitute what is called neuropil.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;knee-jerk-response&#34;&gt;Knee-Jerk Response&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Neural mechanisms-20250217161536263.webp&#34; width=&#34;649&#34; class=&#34;center&#34; alt=&#34;Neural mechanisms-20250217161536263&#34;/&gt;
&lt;p&gt;The &lt;strong&gt;knee-jerk reflex&lt;/strong&gt; (also known as the &lt;strong&gt;patellar reflex&lt;/strong&gt;) is a classic example of a &lt;strong&gt;mono-synaptic reflex arc&lt;/strong&gt;, which involves a direct connection between sensory and motor neurons, as well as inhibitory circuits to regulate movement.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Central Processing Unit</title>
      <link>https://flecart.github.io/notes/central-processing-unit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/central-processing-unit/</guid>
      <description>&lt;p&gt;La struttura moderna degli elaboratori sono basati principalmente sull&amp;rsquo;&lt;strong&gt;architettura di Von Neuman,&lt;/strong&gt; l&amp;rsquo;unica differenza √® che gli elementi di questa architettura.&lt;/p&gt;
&lt;h2 id=&#34;struttura-e-funzione-della-cpu&#34;&gt;Struttura e funzione della CPU&lt;/h2&gt;
&lt;p&gt;La CPU si pu√≤ dividere in tre parti principali:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Una unit√† di controllo che coordina i processi&lt;/li&gt;
&lt;li&gt;Registri che immagazzinano temporaneamente piccole quantit√† di informazioni&lt;/li&gt;
&lt;li&gt;ALU che fa i calcoli ordinategli dalla CPU&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;registri-principali&#34;&gt;Registri Principali&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Program Counter o Instruction Pointer
&lt;ul&gt;
&lt;li&gt;Contiene un pointer all&amp;rsquo;istruzione da eseguire cos√¨ lo prende dalla memoria&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Instruction Register
&lt;ul&gt;
&lt;li&gt;Contiene l&amp;rsquo;istruzione da eseguire&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Memory Address Register
&lt;ul&gt;
&lt;li&gt;Prende l&amp;rsquo;indirizzo del contenuto interessante dalla memoria&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Memory Data Register
&lt;ul&gt;
&lt;li&gt;Prende il contenuto dalla memoria&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Program Status Word
&lt;ul&gt;
&lt;li&gt;Raccoglie lo stato di esecuzione del programma, se fallisce se tutto ok oppure se ci sono errori&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;alu&#34;&gt;ALU&lt;/h3&gt;
&lt;p&gt;Aritmetic Logic Unit, √® la componente che fa i calcoli.
Per sapere cosa deve fare, √® la Control Unit che collega certe vie dai registri all&amp;rsquo;ALU.
A seconda del genere di architettura pu√≤ collegarsi direttamente in memoria (CISC) oppure sempre passando per i registri (solitamente RISC)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Circuiti Sequenziali</title>
      <link>https://flecart.github.io/notes/circuiti-sequenziali/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/circuiti-sequenziali/</guid>
      <description>&lt;h2 id=&#34;71-introduzione&#34;&gt;7.1 Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;711-perch√©-usarli&#34;&gt;7.1.1 Perch√© usarli&lt;/h3&gt;
&lt;p&gt;Sono utili per mantenere delle informazioni nel tempo&lt;/p&gt;
&lt;h3 id=&#34;712-caratteristiche&#34;&gt;7.1.2 Caratteristiche&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Hanno feedback&lt;/strong&gt; cio√® ci sono degli output che tornano dentro al circuito, quindi √® molto difficile senza sapere niente cosa succede dentro&lt;/p&gt;
&lt;p&gt;Questo circuito non √® combinatorio, che √® formalizzabile in modo deterministico con l&amp;rsquo;lgebra booleana.&lt;/p&gt;
&lt;h3 id=&#34;713-il-bit-di-memoria&#34;&gt;7.1.3 Il Bit di memoria&lt;/h3&gt;
&lt;p&gt;Questo bit ha due input, un load e un input, se il load √® attivo comincia a storare, altrimenti l&amp;rsquo;output √® sempre il bit che ha memoriazzato.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Active Learning</title>
      <link>https://flecart.github.io/notes/active-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/active-learning/</guid>
      <description>&lt;p&gt;Active Learning concerns methods to decide how to sample the most useful information in a specific domain; how can you select the best sample for an unknown model?
Gathering data is very costly, we would like to create some principled manner to choose the best data point to humanly label in order to have the best model.&lt;/p&gt;
&lt;p&gt;In this setting, we are interested in the concept of &lt;strong&gt;usefulness of information&lt;/strong&gt;. One of our main goals is to &lt;em&gt;reduce uncertainty&lt;/em&gt;, thus, &lt;a href=&#34;https://flecart.github.io/notes/entropy&#34;&gt;Entropy&lt;/a&gt;-based (mutual information) methods are often used.
For example, we can use active learning to choose what samples needs to be labelled in order to have highest accuracy on the trained model, when labelling is costly.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Estensioni di Turing e altre macchine</title>
      <link>https://flecart.github.io/notes/estensioni-di-turing-e-altre-macchine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/estensioni-di-turing-e-altre-macchine/</guid>
      <description>&lt;p&gt;Sono variazioni possibili equivalenti:
‚Ä¢ Nastri addizionali ‚Ä¢ Testine addizionali ‚Ä¢ Nastri infiniti su entrambi i lati ‚Ä¢ Non-determinismo ‚Ä¢ Scelta probabilistica ‚Ä¢ Scelta quantistica
Si pu√≤ dire che la definizione di TM √® stata &lt;strong&gt;robusta&lt;/strong&gt; nella storia perch√© tantissimi formalismi che intuitivamente sembrano essere molto diversi rispetto alla TM alla fine possono essere dimostrate essere equivalenti.&lt;/p&gt;
&lt;h3 id=&#34;turing-con-nastri-addizionali&#34;&gt;Turing con nastri addizionali&lt;/h3&gt;
&lt;p&gt;Questo √® presente in modo abbastanza facile sul Sipser.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduzione ad architettura</title>
      <link>https://flecart.github.io/notes/introduzione-ad-architettura/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduzione-ad-architettura/</guid>
      <description>&lt;h3 id=&#34;11-il-principio-di-astrazioneimplementazione&#34;&gt;1.1 Il principio di astrazione/implementazione&lt;/h3&gt;
&lt;p&gt;Astrazione per macchine livello n con linguaggi n.&lt;/p&gt;
&lt;h2 id=&#34;12-i-livelli-principali-di-astrazione&#34;&gt;1.2 I livelli principali di astrazione&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Livelli in breve&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Introduzione ad architettura/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Introduzione ad architettura/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;121-livello-0&#34;&gt;1.2.1 Livello 0&lt;/h3&gt;
&lt;p&gt;Qua √® utile indagare la&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://flecart.github.io/notes/porte-logiche&#34;&gt;Porte Logiche&lt;/a&gt; in cui si indagano in un modo molto alto il funzionamento di porte&lt;/p&gt;
&lt;p&gt;√à il livello fisico delle porte logiche e dell&amp;rsquo;ingegneria elettrica.&lt;/p&gt;
&lt;h3 id=&#34;122-livello-1&#34;&gt;1.2.2 Livello 1&lt;/h3&gt;
&lt;p&gt;Link utili potrebbero essere la
&lt;a href=&#34;https://flecart.github.io/notes/central-processing-unit&#34;&gt;Central Processing Unit&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduzione SO</title>
      <link>https://flecart.github.io/notes/introduzione-so/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduzione-so/</guid>
      <description>&lt;h3 id=&#34;scopi-del-sistema-operativo-&#34;&gt;Scopi del sistema operativo üü©&lt;/h3&gt;
&lt;p&gt;Un sistema operativo √® una &lt;strong&gt;astrazione sul HW&lt;/strong&gt; che permette di&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gestire l‚Äôesecuzione di pi√π programmi assieme (concorrenza), tramite virtualizzazione CPU e Memoria&lt;/li&gt;
&lt;li&gt;Gestire le risorse (Quindi I/O, RAM, Memoria, Networking)&lt;/li&gt;
&lt;li&gt;Fornisce una interfaccia di programmazione (API) molto pi√π generale e potente, in grado di astrarre da dettagli di livello basso, vicini all‚ÄôHardware (come device drivers).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Quindi in breve il SO √® n &lt;strong&gt;programma&lt;/strong&gt; che crea un ambiente civile per i programmi in cui interagire, e facilita molto il lavoro al programmatore per la sua interfaccia nuova. (si potrebbe dire che sia una macchina virtuale con un suo linguaggio (che √® l‚ÄôAPI) se seguiamo la terminologia di &lt;a href=&#34;https://flecart.github.io/notes/macchine-astratte&#34;&gt;Macchine Astratte&lt;/a&gt;)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Monte Carlo Methods</title>
      <link>https://flecart.github.io/notes/monte-carlo-methods/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/monte-carlo-methods/</guid>
      <description>&lt;p&gt;DI Law of Large Numbers e Central limit theorem ne parliamo in &lt;a href=&#34;https://flecart.github.io/notes/central-limit-theorem-and-law-of-large-numbers&#34;&gt;Central Limit Theorem and Law of Large Numbers&lt;/a&gt;.
Usually these methods are useful when you need to calculate following something similar to Bayes rule, but don&amp;rsquo;t know how to calculate the denominator, often infeasible integral. We estimate this value without explicitly calculating that.&lt;/p&gt;
&lt;p&gt;Interested in $\mathbb{P}(x) = \frac{1}{z} \mathbb{P}^{*}(x) = \frac{1}{Z} e^{-E(x)}$
Can evaluate E(x) at any x.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Problem 1 Make samples x(r) ~ 2 P&lt;/li&gt;
&lt;li&gt;Problem 2 Estimate expectations  $\Phi = \sum_{x}\phi(x)\mathbb{P}(x)$)
What we&amp;rsquo;re not trying to do:&lt;/li&gt;
&lt;li&gt;We&amp;rsquo;re not trying to find the most probable state.&lt;/li&gt;
&lt;li&gt;We&amp;rsquo;re not trying to visit all typical states.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;law-of-large-numbers&#34;&gt;Law of large numbers&lt;/h3&gt;
$$
S_{n} = \sum^n_{i=1} x_{i} ,:, \bar{x}_{n} = \frac{S_{n}}{n}
$$$$
\bar{x}_{n} \to \mu
$$&lt;p&gt;
Ossia il limite converge sul valore atteso di tutte le variabili aleatorie.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Analysis of Neural Codes</title>
      <link>https://flecart.github.io/notes/analysis-of-neural-codes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/analysis-of-neural-codes/</guid>
      <description>&lt;h2 id=&#34;metodi-di-registrazione-informazione&#34;&gt;Metodi di registrazione informazione&lt;/h2&gt;
&lt;p&gt;Ci stiamo chiedendo in che modo possiamo registrare attivit√† del cervello e quindi cercare di fare decoding delle informazioni presenti
Prima parliamo di alcune tecniche non invasive che ci permettono di vedere alcune attivit√† presenti nel cervello.&lt;/p&gt;
&lt;h3 id=&#34;metodi-macroscopici&#34;&gt;Metodi macroscopici&lt;/h3&gt;
&lt;h4 id=&#34;functional-magnetic-resonance-imaging&#34;&gt;Functional Magnetic Resonance Imaging&lt;/h4&gt;
&lt;p&gt;Un metodo √® &lt;strong&gt;fMRI&lt;/strong&gt;. (ci sono cose ) TODO capire come funziona&lt;/p&gt;
&lt;h4 id=&#34;electro-encephalo-gram&#34;&gt;Electro-Encephalo-Gram&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;EEG&lt;/strong&gt; che prende direttamente dai segnali
Ma il drawback di entrambi √® che &lt;strong&gt;non registrano attivit√† del singolo array&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Firing-rate based Network models</title>
      <link>https://flecart.github.io/notes/firing-rate-based-network-models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/firing-rate-based-network-models/</guid>
      <description>&lt;h4 id=&#34;the-potassium-exchange-values&#34;&gt;The Potassium Exchange values&lt;/h4&gt;
&lt;p&gt;We use the measurement by Cole and Curthis 40mS/cm squared was their measure of Potassium ions leaving the membrane&lt;/p&gt;
$$
\Delta Q = Idt = GA \Delta E dt
$$&lt;p&gt;The potassium concentration is 0.155 moles per litre.
Where $G$ is the conductance per unit area, $A$ the membrane surface, $E$ voltage deflection
Remember that the conductance is the reciprocal of the resistance, and $V = IR \implies I = \frac{V}{R} = GV$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Neural Sytems</title>
      <link>https://flecart.github.io/notes/introduction-to-neural-sytems/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-neural-sytems/</guid>
      <description>&lt;h4 id=&#34;what-is-a-neural-system&#34;&gt;What is a neural system?&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;A neural system is an intricately organized network of specialized cells‚Äîprimarily neurons, along with a variety of supportive glial cells‚Äîthat processes and transmits information via electrical and chemical signals. In biological organisms, such systems underpin the entire nervous system, coordinating functions that range from basic reflexes to the complex interplay of perception, thought, and behavior. Early studies in neurobiology revealed that even simple neural circuits can generate coordinated responses, while modern neuroscience has shown that vast, hierarchically structured networks (such as the central and peripheral nervous systems) are responsible for the rich tapestry of animal behavior and cognition&lt;/p&gt;</description>
    </item>
    <item>
      <title>Synapses</title>
      <link>https://flecart.github.io/notes/synapses/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/synapses/</guid>
      <description>&lt;p&gt;Synapses are the connections that exist between one neuron and another, so we can think of them as the &lt;strong&gt;communication channel&lt;/strong&gt; between neurons.&lt;/p&gt;
&lt;h3 id=&#34;gap-junctions&#34;&gt;Gap Junctions&lt;/h3&gt;
&lt;h4 id=&#34;electrical-based-&#34;&gt;Electrical based üü©&lt;/h4&gt;
&lt;p&gt;These are also called &lt;strong&gt;Gap Junctions&lt;/strong&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/The Neuron-1704441720132.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;The Neuron-1704441720132&#34;&gt;&lt;br&gt;
These are more direct connections between neurons, allowing excitation ions to pass through quite directly (this is the difference compared to chemically based ones). It‚Äôs a circuit more similar to an electronic one because it‚Äôs &lt;strong&gt;faster&lt;/strong&gt;.
Another characteristic of these kinds of synapses is that they are &lt;strong&gt;two-way&lt;/strong&gt; channels.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Neuron</title>
      <link>https://flecart.github.io/notes/the-neuron/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/the-neuron/</guid>
      <description>&lt;h3 id=&#34;some-history-reticular-theory-vs-neuron-doctrine&#34;&gt;Some history: Reticular Theory vs Neuron Doctrine&lt;/h3&gt;
&lt;p&gt;The late 19th century witnessed a debate in neuroscience between &lt;strong&gt;Camillo Golgi&lt;/strong&gt; and &lt;strong&gt;Santiago Ram√≥n y Cajal&lt;/strong&gt;, two pioneers whose opposing views shaped our understanding of the nervous system. This debate centered on the &lt;strong&gt;structural and functional organization of neurons&lt;/strong&gt;, culminating in their joint reception of the &lt;strong&gt;1906 Nobel Prize in Physiology or Medicine&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id=&#34;golgis-reticular-theory&#34;&gt;Golgi‚Äôs Reticular Theory&lt;/h4&gt;
&lt;p&gt;Golgi proposed the &lt;strong&gt;Reticular Theory&lt;/strong&gt; based on his staining techniques (see &lt;a href=&#34;https://flecart.github.io/notes#staining-methods&#34;&gt;#Staining methods&lt;/a&gt;), which held that:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Livello ISA</title>
      <link>https://flecart.github.io/notes/livello-isa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/livello-isa/</guid>
      <description>&lt;p&gt;il livello isa √® il livello delle istruzioni&lt;/p&gt;
&lt;h2 id=&#34;81-struttura&#34;&gt;8.1 Struttura&lt;/h2&gt;
&lt;p&gt;Potremmo definire l&amp;rsquo;architettura di un elaboratore come tutte le parti del processore che una persona abbia bisogno di sapere per scrivere codice assembly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Istruzioni possibili&lt;/li&gt;
&lt;li&gt;Registri&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Solitamente le istruzioni sono divise in due parti:&lt;/p&gt;
&lt;h3 id=&#34;811-opcode-e-indirizzamento&#34;&gt;8.1.1 Opcode e indirizzamento&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Opcode&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Questo opcode indica la tipologia di istruzione.&lt;/p&gt;
&lt;p&gt;Per esempio per l&amp;rsquo;architettura HACK √® il primo bit, che indica se √® una istruzione C oppure una istruzione A.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache Spark</title>
      <link>https://flecart.github.io/notes/apache-spark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/apache-spark/</guid>
      <description>&lt;p&gt;This is a new framework that is faster than MapReduce (See &lt;a href=&#34;https://flecart.github.io/notes/massive-parallel-processing&#34;&gt;Massive Parallel Processing&lt;/a&gt;). It is written in Scala and has a more functional approach to programming.
Spark extends the previous MapReduce framework to a generic distributed dataflow, properly modeled as a DAG.
There are other benefits of using Spark instead of the Map reduce Framework:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spark processes data in memory, avoiding the disk I/O overhead of MapReduce, making it significantly faster.&lt;/li&gt;
&lt;li&gt;Spark uses a DAG to optimize the entire workflow, reducing data shuffling and stage count.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But MapReduce sometimes has its advantages:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bayesian Information Criterion</title>
      <link>https://flecart.github.io/notes/bayesian-information-criterion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/bayesian-information-criterion/</guid>
      <description>&lt;h3 id=&#34;bayesian-information-criterion-bic&#34;&gt;&lt;strong&gt;Bayesian Information Criterion (BIC)&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;Bayesian Information Criterion (BIC)&lt;/strong&gt; is a model selection criterion that helps compare different statistical models while penalizing model complexity. It is rooted in Bayesian probability theory but is commonly used even in frequentist settings.&lt;/p&gt;
&lt;h3 id=&#34;mathematically-precise-definition&#34;&gt;&lt;strong&gt;Mathematically Precise Definition&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;For a statistical model $M$ with $k$ parameters fitted to a dataset $\mathcal{D} = \{x_1, x_2, \dots, x_n\}$, the BIC is defined as:&lt;/p&gt;
$$
\text{BIC} = -2 \cdot \ln \hat{L} + k \cdot \ln(n)
$$&lt;p&gt;where:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bayesian Linear Regression</title>
      <link>https://flecart.github.io/notes/bayesian-linear-regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/bayesian-linear-regression/</guid>
      <description>&lt;p&gt;We have a prior $p(\text{model})$, we have a posterior $p(\text{model} \mid \text{data})$, a likelihood $p(\text{data} \mid \text{model})$ and $p(\text{data})$ is called the &lt;em&gt;evidence&lt;/em&gt;.&lt;/p&gt;
&lt;h4 id=&#34;classical-linear-regression&#34;&gt;Classical Linear regression&lt;/h4&gt;
$$
y = w^{T}x + \varepsilon
$$&lt;p&gt;
Where $\varepsilon \sim \mathcal{N}(0, \sigma_{n}^{2}I)$ and it&amp;rsquo;s the irreducible noise, an error that cannot be eliminated by any model in the model class, this is also called &lt;strong&gt;aleatoric uncertainty&lt;/strong&gt;.
One could write this as follows: $y \sim \mathcal{N}(w^{T}x, \sigma^{2}_{n}I)$ and it&amp;rsquo;s the exact same thing as the previous, so if we look for the MLE estimate now we get&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bayesian Optimization</title>
      <link>https://flecart.github.io/notes/bayesian-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/bayesian-optimization/</guid>
      <description>&lt;p&gt;While &lt;a href=&#34;https://flecart.github.io/notes/active-learning&#34;&gt;Active Learning&lt;/a&gt; looks for the most informative points to recover a &lt;em&gt;true&lt;/em&gt; underlying function, Bayesian Optimization is just interested to find the maximum of that function.
In Bayesian Optimization, we ask for the best way to find &lt;em&gt;sequentially&lt;/em&gt; a set of points $x_{1}, \dots, x_{n}$ to find $\max_{x \in \mathcal{X}} f(x)$ for a certain unknown function $f$. This is what the whole thing is about.&lt;/p&gt;
&lt;h3 id=&#34;definitions&#34;&gt;Definitions&lt;/h3&gt;
&lt;p&gt;First we will introduce some useful definitions in this context. These were also somewhat introduced in N-Bandit Problem, which is one of the classical optimization problems we can find in the literature.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Beta and Dirichlet Distributions</title>
      <link>https://flecart.github.io/notes/beta-and-dirichlet-distributions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/beta-and-dirichlet-distributions/</guid>
      <description>&lt;h1 id=&#34;the-beta-distribution&#34;&gt;The beta distribution&lt;/h1&gt;
&lt;p&gt;The beta distribution is a powerful tool for modeling probabilities and proportions between 0 and 1. Here&amp;rsquo;s a structured intuition to grasp its essence:&lt;/p&gt;
&lt;h3 id=&#34;core-concept&#34;&gt;Core Concept&lt;/h3&gt;
&lt;p&gt;The beta distribution, defined on $[0, 1]$, is parameterized by two shape parameters: &lt;strong&gt;Œ± (alpha)&lt;/strong&gt; and &lt;strong&gt;Œ≤ (beta)&lt;/strong&gt;. These parameters dictate the distribution‚Äôs shape, allowing it to flexibly represent beliefs about probabilities, rates, or proportions.&lt;/p&gt;
&lt;h3 id=&#34;key-intuitions&#34;&gt;Key Intuitions&lt;/h3&gt;
&lt;h4 id=&#34;a-pseudo-counts-interpretation&#34;&gt;&lt;strong&gt;a. &amp;ldquo;Pseudo-Counts&amp;rdquo; Interpretation&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Œ±&lt;/strong&gt; acts like &amp;ldquo;successes&amp;rdquo; and &lt;strong&gt;Œ≤&lt;/strong&gt; like &amp;ldquo;failures&amp;rdquo; in a hypothetical experiment.
&lt;ul&gt;
&lt;li&gt;Example: If you use &lt;strong&gt;Beta(5, 3)&lt;/strong&gt;, it‚Äôs as if you‚Äôve observed &lt;strong&gt;5 successes&lt;/strong&gt; and &lt;strong&gt;3 failures&lt;/strong&gt; &lt;em&gt;before seeing actual data&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;After observing &lt;strong&gt;x real successes&lt;/strong&gt; and &lt;strong&gt;y real failures&lt;/strong&gt;, the posterior becomes &lt;strong&gt;Beta(Œ±+x, Œ≤+y)&lt;/strong&gt;. This makes beta the &lt;strong&gt;conjugate prior&lt;/strong&gt; for the binomial distribution (bernoulli process).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;b-shape-flexibility&#34;&gt;&lt;strong&gt;b. Shape Flexibility&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Uniform distribution&lt;/strong&gt;: When &lt;strong&gt;Œ± = Œ≤ = 1&lt;/strong&gt;, all values in [0, 1] are equally likely.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bell-shaped&lt;/strong&gt;: When &lt;strong&gt;Œ±, Œ≤ &amp;gt; 1&lt;/strong&gt;, the distribution peaks at &lt;strong&gt;mode = (Œ±-1)/(Œ±+Œ≤-2)&lt;/strong&gt;.
&lt;ul&gt;
&lt;li&gt;Symmetric if &lt;strong&gt;Œ± = Œ≤&lt;/strong&gt; (e.g., &lt;strong&gt;Beta(5, 5)&lt;/strong&gt; is centered at 0.5).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;U-shaped&lt;/strong&gt;: When &lt;strong&gt;Œ±, Œ≤ &amp;lt; 1&lt;/strong&gt;, density spikes at 0 and 1 (useful for modeling polarization, meaning we believe the model to only produce values at 0 or 1, not in the middle.).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Skewed&lt;/strong&gt;: If &lt;strong&gt;Œ± &amp;gt; Œ≤&lt;/strong&gt;, skewed toward 1; if &lt;strong&gt;Œ≤ &amp;gt; Œ±&lt;/strong&gt;, skewed toward 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;c-moments&#34;&gt;&lt;strong&gt;c. Moments&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mean&lt;/strong&gt;: $Œ±/(Œ±+Œ≤)$ ‚Äì your &amp;ldquo;expected&amp;rdquo; probability of success.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Variance&lt;/strong&gt;: $Œ±Œ≤ / [(Œ±+Œ≤)¬≤(Œ±+Œ≤+1)]$ ‚Äì decreases as &lt;strong&gt;Œ±&lt;/strong&gt; and &lt;strong&gt;Œ≤&lt;/strong&gt; grow (more confidence).&lt;/li&gt;
&lt;/ul&gt;
$$
\text{Mode} = \frac{\alpha - 1}{\alpha + \beta - 2}
$$&lt;h3 id=&#34;the-mathematical-model&#34;&gt;The mathematical model&lt;/h3&gt;
$$
\text{Beta} (x \mid a, b) = \frac{1}{B(a, b)} \cdot x^{a -1 }(1 - x)^{b - 1}
$$&lt;p&gt;
Where $B(a, b) = \Gamma(a) \Gamma(b) / \Gamma( + b)$
And $\Gamma(t) = \int_{0}^{\infty}e^{-x}x^{t - 1} \, dx$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Counterfactual Invariance</title>
      <link>https://flecart.github.io/notes/counterfactual-invariance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/counterfactual-invariance/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Machine learning cannot distinguish between causal and environment features.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;shortcut-learning&#34;&gt;Shortcut learning&lt;/h4&gt;
&lt;p&gt;Often we observe &lt;strong&gt;shortcut learning&lt;/strong&gt;: the model learns some dataset dependent shortcuts (e.g. the machine that was used to take the X-ray) to make inference, but this is very brittle, and is not usually able to generalize.&lt;/p&gt;
&lt;p&gt;Shortcut learning happens when there are correlations in the test set between causal and non-causal features. Our object of interest should be the main focus, not the environment around, in most of the cases. For example, a camel in a grass land should still be recognized as a camel, not a cow.
One solution could be engineering &lt;strong&gt;invariant representations&lt;/strong&gt; which are independent of the environment. So having a kind of encoder that creates these representations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cross Validation and Model Selection</title>
      <link>https://flecart.github.io/notes/cross-validation-and-model-selection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cross-validation-and-model-selection/</guid>
      <description>&lt;p&gt;There is a big difference between the empirical score and the expected score; in the beginning, we had said something about this in &lt;a href=&#34;https://flecart.github.io/notes/introduction-to-advanced-machine-learning&#34;&gt;Introduction to Advanced Machine Learning&lt;/a&gt;. We will develop more methods to better comprehend this fundamental principles.&lt;/p&gt;
&lt;p&gt;How can we estimate the expected risk of a particular estimator or algorithm? We can use the &lt;strong&gt;cross-validation&lt;/strong&gt; method. This method is used to estimate the expected risk of a model, and it is a fundamental method in machine learning.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Cubes</title>
      <link>https://flecart.github.io/notes/data-cubes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/data-cubes/</guid>
      <description>&lt;p&gt;Data Cubes is a data format especially useful for heavy reads. It has been popularized in business environments where the main use for data was to make reports (many reads).
This also links with the OLAP (Online Analytical Processing) vs OLTP (Online Transaction Processing) concepts, where one is optimized for reads and the other for writes.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The main driver behind data cubes was business intelligence. While
traditional relational database systems are focused on the day-to-day
business of a company and record keeping (with customers placing or-
ders, inventories kept up to date, etc), business intelligence is focused on
the production of high-level reports for supporting C-level executives
in making informed decisions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Models and Validation</title>
      <link>https://flecart.github.io/notes/data-models-and-validation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/data-models-and-validation/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;A data model is an abstract view over the data that hides the way it is stored physically.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The same idea from &lt;a href=&#34;https://dl.acm.org/doi/10.1145/362384.362685&#34;&gt;(Codd 1970)&lt;/a&gt;
This is why we should not modify data directly, but pass though some abstraction that maintain the properties of that specific data model.&lt;/p&gt;
&lt;h2 id=&#34;data-models&#34;&gt;Data Models&lt;/h2&gt;
&lt;h4 id=&#34;tree-view-&#34;&gt;Tree view üü©&lt;/h4&gt;
&lt;p&gt;We can view all JSON and XML data, as presented in &lt;a href=&#34;https://flecart.github.io/notes/markup&#34;&gt;Markup&lt;/a&gt;, as &lt;strong&gt;trees&lt;/strong&gt;. This structure is usually quite evident, as it is inherent in their design. Converting from the tree structure to a memory model is known as serialization, while the reverse process is called &lt;strong&gt;parsing&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dependency Parsing</title>
      <link>https://flecart.github.io/notes/dependency-parsing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/dependency-parsing/</guid>
      <description>&lt;p&gt;This set of note is still in TODO&lt;/p&gt;
&lt;p&gt;Dependency Grammar has been much bigger in Europe compared to USA, where Chomsky&amp;rsquo;s grammars ruled. One of the main developers of this theory is Lucien Tesni√®re (1959):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚ÄúThe sentence is an organized whole, the constituent elements of which are words. Every word that
belongs to a sentence ceases by itself to be isolated as in the dictionary. Between the word and its neighbors, the mind perceives connections, the totality of which forms the structure of the sentence.
The structural connections establish dependency relations between the words. Each connection in principle unites a superior term and an inferior term. The superior term receives the name governor (head). The inferior term receives the name subordinate (dependent).‚Äù ~&lt;em&gt;Lucien Tesni√®re&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Diffusion Models</title>
      <link>https://flecart.github.io/notes/diffusion-models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/diffusion-models/</guid>
      <description>&lt;p&gt;Diffusion is a physical process that models random motion, first analyzed by Brown when studying pollen grains in water. In this section, we will first analyze a simplified 1-dimensional version, and then delve into diffusion models for images, the ones closest to &lt;a href=&#34;http://arxiv.org/abs/2006.11239&#34;&gt;(Ho et al. 2020)&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;the-diffusion-process&#34;&gt;The Diffusion Process&lt;/h3&gt;
&lt;p&gt;This &lt;a href=&#34;https://arxiv.org/pdf/cond-mat/0701242&#34;&gt;note&lt;/a&gt; follows original Einstein&amp;rsquo;s presentation, here we have a simplified version.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s suppose we have a particle at $t = 0$ at some position $i$. We have a probability of jumping to the left of $p$ to right of $q$, the rest is staying at the same position.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dirichlet Processes</title>
      <link>https://flecart.github.io/notes/dirichlet-processes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/dirichlet-processes/</guid>
      <description>&lt;p&gt;The DP (Dirichlet Processes) is part of family of models called &lt;strong&gt;non-parametric&lt;/strong&gt; models.
Non parametric models concern learning models with potentially infinite number of parameters.
One of the classical application is unsupervised techniques like clustering.
Intuitively, clustering concerns in finding &lt;em&gt;compact subsets&lt;/em&gt; of data, i.e. finding groups of points in the space that are particularly close by some measure.&lt;/p&gt;
&lt;h3 id=&#34;the-dirichlet-process&#34;&gt;The Dirichlet Process&lt;/h3&gt;
&lt;p&gt;See &lt;a href=&#34;https://flecart.github.io/notes/beta-and-dirichlet-distributions&#34;&gt;Beta and Dirichlet Distributions&lt;/a&gt; for the definition and intuition of these two distributions.
One quite important thing that Dirichlet allows to do is the ability of assigning an ever growing number of clusters to data. This models are thus quite flexible to change and growth.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Distributed file systems</title>
      <link>https://flecart.github.io/notes/distributed-file-systems/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/distributed-file-systems/</guid>
      <description>&lt;p&gt;We want to know how to handle systems that have a large number of data. In previous lesson we have discovered how to quickly access and make Scalable systems with huge dimensions, see &lt;a href=&#34;https://flecart.github.io/notes/cloud-storage&#34;&gt;Cloud Storage&lt;/a&gt;. Object storage could store billions of files, we want to handle millions of petabyte files.&lt;/p&gt;
&lt;h3 id=&#34;designing-dfss&#34;&gt;Designing DFSs&lt;/h3&gt;
&lt;h4 id=&#34;the-use-case&#34;&gt;The Use Case&lt;/h4&gt;
&lt;p&gt;Remember that the size of the files where heavily limited for &lt;a href=&#34;https://flecart.github.io/notes/cloud-storage&#34;&gt;Cloud Storage&lt;/a&gt;. The physical limitation was due to the limited size of a single hard disk, which was usually in the order of the Terabytes.
Here, we would like to easily store &lt;em&gt;petabytes&lt;/em&gt; of data in a single file, for example &lt;strong&gt;big datasets&lt;/strong&gt;.
Another feature that should be easily supported is &lt;strong&gt;highly concurrent access&lt;/strong&gt; to the filesystem, last but not least being able to set up permissions in the system.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Document Stores</title>
      <link>https://flecart.github.io/notes/document-stores/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/document-stores/</guid>
      <description>&lt;p&gt;p&amp;gt; Document stores provide a native database management system for &lt;strong&gt;semi-structured&lt;/strong&gt; data. Document stores also scale to Gigabytes or Terabytes of data, and typically millions or billions of records (a record being a JSON object or an XML document).&lt;/p&gt;
&lt;h3 id=&#34;introduction-to-document-stores&#34;&gt;Introduction to Document Stores&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;A document store, unlike a data lake, manages the data &lt;em&gt;directly&lt;/em&gt; and the users do not see the physical layout.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Unlike data lakes, using document stores prevent us from breaking data independence and reading the data file directly: it offers an automatic manager service for &lt;strong&gt;semi-structured&lt;/strong&gt; data that we need to throw and read quickly.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ensemble Methods</title>
      <link>https://flecart.github.io/notes/ensemble-methods/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/ensemble-methods/</guid>
      <description>&lt;p&gt;The idea of ensemble methods goes back to Sir Francis Galton. In 787, he noted that although not every single person got the right value, the average estimate of a crowd of people predicted quite well.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The main idea of ensemble methods is to combine relatively weak classifiers into a highly accurate predictor.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;The motivation for boosting was a procedure that combines the outputs of many ‚Äúweak‚Äù classifiers to produce a powerful ‚Äúcommittee.‚Äù&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fisher&#39;s Linear Discriminant</title>
      <link>https://flecart.github.io/notes/fishers-linear-discriminant/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/fishers-linear-discriminant/</guid>
      <description>&lt;h4 id=&#34;a-simple-motivation&#34;&gt;A simple motivation&lt;/h4&gt;
&lt;p&gt;Fisher&amp;rsquo;s Linear Discriminant is a simple idea used to linearly classify our data.
&lt;img src=&#34;https://flecart.github.io/images/notes/Fisher&#39;s Linear Discriminant-20241031125847321.webp&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Fisher&#39;s Linear Discriminant-20241031125847321&#34;&gt;&lt;/p&gt;
&lt;p&gt;The image above, taken from &lt;a href=&#34;https://link.springer.com/book/9780387310732&#34;&gt;(Bishop 2006)&lt;/a&gt;, is the summary of the idea.  We clearly see that if we first project using the direction of maximum variance (See Principal Component Analysis) then the data is not linearly separable, but if we take other notions into consideration, then the idea becomes much more cleaner.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gaussian Processes</title>
      <link>https://flecart.github.io/notes/gaussian-processes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/gaussian-processes/</guid>
      <description>&lt;p&gt;Gaussian processes can be viewed through a Bayesian lens of the function space: rather than sampling over individual data points, we are now sampling over entire functions. They extend the idea of &lt;a href=&#34;https://flecart.github.io/notes/bayesian-linear-regression&#34;&gt;bayesian linear regression&lt;/a&gt; by introducing an infinite number of feature functions for the input XXX.&lt;/p&gt;
&lt;p&gt;In geostatistics, Gaussian processes are referred to as &lt;em&gt;kriging&lt;/em&gt; regressions, and many other models, such as &lt;a href=&#34;https://flecart.github.io/notes/kalman-filters&#34;&gt;Kalman Filters&lt;/a&gt; or radial basis function networks, can be understood as special cases of Gaussian processes. In this framework, certain functions are more likely than others, and we aim to model this probability distribution.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Graph Databases</title>
      <link>https://flecart.github.io/notes/graph-databases/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/graph-databases/</guid>
      <description>&lt;p&gt;We have first cited the graph data model in the &lt;a href=&#34;https://flecart.github.io/notes/introduction-to-big-data&#34;&gt;Introduction to Big Data&lt;/a&gt; note.
Until now, we have explored many aspects of relational data bases, but now we are changing the data model completely. The main reason driving this discussion are the limitations of classical relational databases: queries like traversal of a high number of relationships, reverse traversal requiring
also indexing foreign keys (need double index! Index only work in one direction for relationship traversal, i.e. if you need both direction you should build an index both for the forward key and backward key), looking for patterns in the relationships, are especially expensive when using normal databases.
We have improved over the problem of joining with relational database using &lt;a href=&#34;https://flecart.github.io/notes/document-stores&#34;&gt;Document Stores&lt;/a&gt; with three data structure, but these &lt;em&gt;cannot&lt;/em&gt; have cycles.
We call &lt;em&gt;index-free adjacency&lt;/em&gt;: we use physical memory pointers to store the graph.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Advanced Machine Learning</title>
      <link>https://flecart.github.io/notes/introduction-to-advanced-machine-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-advanced-machine-learning/</guid>
      <description>&lt;h2 id=&#34;introduction-to-the-course&#34;&gt;Introduction to the course&lt;/h2&gt;
&lt;p&gt;Machine learning offers a new way of thinking about reality: rather than attempting to directly capture a fragment of reality, as many traditional sciences have done, we elevate to the meta-level and strive to create an automated method for capturing it.&lt;/p&gt;
&lt;p&gt;This first lesson will be more philosophical in nature. We are witnessing a &lt;strong&gt;paradigm shift&lt;/strong&gt; in the sense described by Thomas Kuhn in his theory of scientific revolutions. But what drives such a shift, and how does it unfold?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Big Data</title>
      <link>https://flecart.github.io/notes/introduction-to-big-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-big-data/</guid>
      <description>&lt;p&gt;Data Science is similar to physics: it attemps to create theories of realities based on some formalism that another science brings. For physics it was mathematics, for data science it is computer science.
Data has grown expeditiously in these last years and has reached a distance that in metres is the distance to Jupiter. The galaxy is in the order of magnitude of 400 Yottametres, which has $3 \cdot 8$ zeros following after it. So quite a lot. We don&amp;rsquo;t know if the magnitude of the data will grow this fast but certainly we need to be able to face this case.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Natural Language Processing</title>
      <link>https://flecart.github.io/notes/introduction-to-natural-language-processing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-natural-language-processing/</guid>
      <description>&lt;p&gt;The landscape of NLP was very different in the beginning of the field.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;But it must be recognized that the notion &amp;lsquo;probability of a sentence&amp;rsquo; is an entirely useless one, under any known interpretation of this term 1968 p 53. &lt;em&gt;Noam Chomsky&lt;/em&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Probability was not seen very well (Chomsky has said many wrong things indeed), and linguists were considered useless. Recently deep learning and computational papers are ubiquitous in major conferences in linguistics, e.g. ACL.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kalman Filters</title>
      <link>https://flecart.github.io/notes/kalman-filters/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/kalman-filters/</guid>
      <description>&lt;p&gt;Here is a historical treatment on the topic: &lt;a href=&#34;https://jwmi.github.io/ASM/6-KalmanFilter.pdf.&#34;&gt;&lt;a href=&#34;https://jwmi.github.io/ASM/6-KalmanFilter.pdf&#34;&gt;https://jwmi.github.io/ASM/6-KalmanFilter.pdf&lt;/a&gt;.&lt;/a&gt;
Kalman Filters are defined as follows:&lt;/p&gt;
&lt;p&gt;We start with a variable $X_{0} \sim \mathcal{N}(\mu, \Sigma)$, then we have a &lt;em&gt;motion model&lt;/em&gt; and a &lt;em&gt;sensor model&lt;/em&gt;:&lt;/p&gt;
$$
\begin{cases}
X_{t + 1} = FX_{t} + \varepsilon_{t}  &amp;  F \in \mathbb{R}^{d\times d}, \varepsilon_{t} \sim \mathcal{N}(0, \Sigma_{x})\\
Y_{t} = HX_{t} + \eta_{t}  &amp;  H \in \mathbb{R}^{m \times d}, \eta_{t} \sim \mathcal{N}(0, \Sigma_{y})
\end{cases}
$$&lt;p&gt;Inference is just doing things with the &lt;a href=&#34;https://flecart.github.io/notes/gaussians&#34;&gt;Gaussians&lt;/a&gt;.
One can interpret the $Y$ to be the observations and $X$ to be the underlying beliefs about a certain state.
We see that the Kalman Filters satisfy the &lt;em&gt;Markov Property&lt;/em&gt;, see &lt;a href=&#34;https://flecart.github.io/notes/markov-chains&#34;&gt;Markov Chains&lt;/a&gt;.
These independence properties allow a easy characterization of the joint distribution for Kalman Filters:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kernel Methods</title>
      <link>https://flecart.github.io/notes/kernel-methods/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/kernel-methods/</guid>
      <description>&lt;p&gt;As we will briefly see, Kernels will have an important role in many machine learning applications. In this note we will get to know what are Kernels and why are they useful. Intuitively they measure the &lt;strong&gt;similarity&lt;/strong&gt; between two input points. So if they are close the kernel should be big, else it should be small.&lt;/p&gt;
&lt;p&gt;We briefly state the requirements of a Kernel, then we will argue with a simple example why they are useful.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Language Models</title>
      <link>https://flecart.github.io/notes/language-models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/language-models/</guid>
      <description>&lt;p&gt;In order to understand language models we need to understand &lt;strong&gt;structured prediction&lt;/strong&gt;. If you are familiar with &lt;a href=&#34;https://flecart.github.io/notes/sentiment-analysis&#34;&gt;Sentiment Analysis&lt;/a&gt;, where given an input text we need to classify it in a binary manner, in this case the output space usually scales in an &lt;em&gt;exponential&lt;/em&gt; manner. The output has some structure, for example it could be a tree, it could be a set of words etc&amp;hellip; This usually needs an intersection between statistics and computer science.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linear Regression methods</title>
      <link>https://flecart.github.io/notes/linear-regression-methods/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/linear-regression-methods/</guid>
      <description>&lt;p&gt;We will present some methods related to regression methods for data analysis.
Some of the work here is from (Hastie et al. 2009). This note does not treat the bayesian case, you should see &lt;a href=&#34;https://flecart.github.io/notes/bayesian-linear-regression&#34;&gt;Bayesian Linear Regression&lt;/a&gt; for that.&lt;/p&gt;
&lt;h3 id=&#34;problem-setting&#34;&gt;Problem setting&lt;/h3&gt;
$$
Y = \beta_{0} + \sum_{j = 1}^{d} X_{j}\beta_{j}
$$&lt;p&gt;We usually don&amp;rsquo;t know the distribution of $P(X)$ or $P(Y \mid X)$ so we need to assume something about these distributions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Log Linear Models</title>
      <link>https://flecart.github.io/notes/log-linear-models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/log-linear-models/</guid>
      <description>&lt;p&gt;Log Linear Models can be considered the most basic model used in natural languages. The main idea is to try to model the correlations of our data, or how the posterior $p(y \mid x)$ varies, where $x$ is our single data point features and $y$ are the labels of interest. This is a &lt;em&gt;form of generalization&lt;/em&gt; because contextualized events (x, y) with similar descriptions tend to have similar probabilities.&lt;/p&gt;
&lt;p&gt;These kinds of models are so common that it has been discovered in many fields (and thus assuming different names): some of the most famous are Gibbs distributions, undirected graphical models, Markov Random Fields or Conditional Random Fields, exponential models, and (regularized) maximum entropy models. Special cases include logistic regression and Boltzmann machines.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Markov Processes</title>
      <link>https://flecart.github.io/notes/markov-processes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/markov-processes/</guid>
      <description>&lt;p&gt;Andiamo a parlare di processi Markoviani. Dobbiamo avere bene a mente il contenuto di &lt;a href=&#34;https://flecart.github.io/notes/markov-chains&#34;&gt;Markov Chains&lt;/a&gt; prima di approcciare questo capitolo.&lt;/p&gt;
&lt;h3 id=&#34;markov-property&#34;&gt;Markov property&lt;/h3&gt;
&lt;p&gt;Uno stato si pu√≤ dire di godere della propriet√† di Markov se, intuitivamente parlando, possiede gi√† tutte le informazioni necessarie per predire lo stato successivo, ossia, supponiamo di avere la sequenza di stati $(S_n)_{n \in \mathbb{N}}$, allora si ha che $P(S_k | S_{k-1}) = P(S_k|S_0S_1...S_{k - 1})$, ossia lo stato attuale in $S_{k}$ dipende solamente dallo stato precedente.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Markup</title>
      <link>https://flecart.github.io/notes/markup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/markup/</guid>
      <description>&lt;h3 id=&#34;introduzione-alle-funzioni-del-markup-&#34;&gt;Introduzione alle funzioni del markup üü©&lt;/h3&gt;
&lt;p&gt;La semantica di una parola √® caratterizzata dalla mia scelta (design sul significato). Non mi dice molto, quindi proviamo a raccontare qualcosa in pi√π.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Definiamo markup ogni mezzo per rendere esplicita una particolare &lt;em&gt;interpretazione&lt;/em&gt; di un testo.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In particolare √® un modo per esplicitare qualche significato. (un po&amp;rsquo; come la punteggiatura, che da qualche altra informazione oltre le singole parole, rende pi√π chiaro l&amp;rsquo;uso del testo).&lt;/p&gt;</description>
    </item>
    <item>
      <title>On The Double Descent Phenomenon</title>
      <link>https://flecart.github.io/notes/on-the-double-descent-phenomenon/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/on-the-double-descent-phenomenon/</guid>
      <description>&lt;p&gt;Double descent is a striking phenomenon in modern machine learning that challenges the traditional bias‚Äìvariance tradeoff. In classical learning theory, increasing model complexity beyond a certain point is expected to increase test error because the model starts to overfit the training data. However, in many contemporary models‚Äîfrom simple linear predictors to deep neural networks‚Äîa second descent in test error emerges as the model becomes even more overparameterized.&lt;/p&gt;
&lt;p&gt;At its core, the double descent curve can be understood in three stages. In the first stage, as the model‚Äôs capacity increases, the error decreases because the model is better able to capture the underlying signal in the data. As the model approaches the interpolation threshold‚Äîwhere the number of parameters is roughly equal to the number of data points‚Äîthe model fits the training data exactly. This exact fitting, however, makes the model extremely sensitive to noise, leading to a spike in test error. Surprisingly, when the model complexity is increased further into the highly overparameterized regime, the training algorithm (often stochastic gradient descent) tends to select from the many possible interpolating solutions one that exhibits desirable properties such as lower norm or smoothness. This implicit bias toward simpler, more generalizable solutions causes the test error to decrease again, producing the second descent.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Parametric Modeling</title>
      <link>https://flecart.github.io/notes/parametric-modeling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/parametric-modeling/</guid>
      <description>&lt;p&gt;In this note we will first talk about briefly some of the main differences of the three main approaches regarding statistics: the bayesian, the frequentist and the statistical learning methods and then present the concept of the estimator, compare how the approaches differ from method to method, we will explain maximum likelihood estimator and the Rao-Cramer Bound.&lt;/p&gt;
&lt;h3 id=&#34;short-introduction-to-the-statistical-methods&#34;&gt;Short introduction to the statistical methods&lt;/h3&gt;
&lt;h4 id=&#34;bayesian-&#34;&gt;Bayesian üü©&lt;/h4&gt;
$$
p(\theta \mid X) = \frac{1}{z}p(X \mid \theta) p(\theta) 
$$&lt;p&gt;The quantity $P(X \mid \theta)$ could be very complicated if our model is complicated.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Part of Speech Tagging</title>
      <link>https://flecart.github.io/notes/part-of-speech-tagging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/part-of-speech-tagging/</guid>
      <description>&lt;h4 id=&#34;what-is-a-part-of-speech&#34;&gt;What is a part of Speech?&lt;/h4&gt;
&lt;p&gt;A part of speech (POS) is a &lt;strong&gt;category of words that display similar syntactic behavior&lt;/strong&gt;, i.e.,
they play similar roles within the grammatical structure of sentences. It has been known since the Latin era that some categories of words behave similarly (verbs for declination for example).&lt;/p&gt;
&lt;p&gt;The intuitive take is that knowing a specific part of speech can help understand the &lt;strong&gt;meaning&lt;/strong&gt; of the sentence.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Performance at Large Scales</title>
      <link>https://flecart.github.io/notes/performance-at-large-scales/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/performance-at-large-scales/</guid>
      <description>&lt;p&gt;Some specific phenomenons in modern systems happen only when we scale into large systems. This note will gather some observations about the most important phenomena we observe at these scales.&lt;/p&gt;
&lt;h4 id=&#34;tail-latency-phenomenon&#34;&gt;Tail Latency Phenomenon&lt;/h4&gt;
&lt;p&gt;Tail latency refers to the high-end response time experienced by
When scaling our services, using &lt;a href=&#34;https://flecart.github.io/notes/massive-parallel-processing&#34;&gt;Massive Parallel Processing&lt;/a&gt;, and similar technology, it is not rare that
a small percentage of requests in a system experience a &lt;strong&gt;high-end response&lt;/strong&gt; time, typically measured at the 95th or 99th percentile.
This significant delays that can degrade user experience or system reliability.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Planning</title>
      <link>https://flecart.github.io/notes/planning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/planning/</guid>
      <description>&lt;p&gt;There is huge literature on planning. We will attack this problem from the view of probabilistic artificial intelligence.
In this case we focus on continuous, fully observed with non-linear transitions, an environment often used for robotics. It&amp;rsquo;s called Model Predictive Control (MPC).&lt;/p&gt;
&lt;blockquote&gt;
\[...\]&lt;p&gt; Moreover, modeling uncertainty in our model of the environment can be extremely useful in deciding where to explore. Learning a model can therefore help to dramatically reduce the sample complexity over model-free techniques.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Probabilistic Parsing</title>
      <link>https://flecart.github.io/notes/probabilistic-parsing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/probabilistic-parsing/</guid>
      <description>&lt;h2 id=&#34;language-constituents&#34;&gt;Language Constituents&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;A constituent is a word or a group of words that function as a single unit within a
hierarchical structure&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is because there is a lot of evidence pointing towards an hierarchical organization of human language.&lt;/p&gt;
&lt;h4 id=&#34;example-of-constituents&#34;&gt;Example of constituents&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s have some examples:
John speaks [Spanish] fluently
John speaks [Spanish and French] fluently&lt;/p&gt;
&lt;p&gt;Mary programs the homework [in the ETH computer laboratory]
Mary programs the homework [in the laboratory]&lt;/p&gt;</description>
    </item>
    <item>
      <title>Provably Approximately Correct Learning</title>
      <link>https://flecart.github.io/notes/provably-approximately-correct-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/provably-approximately-correct-learning/</guid>
      <description>&lt;p&gt;PAC Learning is one of the most famous theories in learning theory. Learning theory concerns in answering questions like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is learnable? Somewhat akin to &lt;a href=&#34;https://flecart.github.io/notes/la-macchina-di-turing&#34;&gt;La macchina di Turing&lt;/a&gt; for computability theory.&lt;/li&gt;
&lt;li&gt;How well can you learn something?
PAC is a framework that allows to formally answer these questions.
Now there is also a bayesian version of PAC in which there is a lot of research.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;some-definitions&#34;&gt;Some definitions&lt;/h3&gt;
&lt;h4 id=&#34;empirical-risk-minimizer-and-errors&#34;&gt;Empirical Risk Minimizer and Errors&lt;/h4&gt;
$$
\arg \min_{\hat{c} \in \mathcal{H}} \hat{R}_{n}(\hat{c})
$$&lt;p&gt;
Where the inside is the empirical error.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Querying Denormalized Data</title>
      <link>https://flecart.github.io/notes/querying-denormalized-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/querying-denormalized-data/</guid>
      <description>&lt;p&gt;TODO: write the introduction to the note.&lt;/p&gt;
&lt;p&gt;JSONiq purports as an easy query language that could run everywhere. It attempts to solve common problems in SQL i.e. the lack of support for nested data structures and also the lack of support for JSON data types.
A nice thing about JSONiq is that it is functional, which makes its queries quite powerful and flexible. It is also declarative and &lt;strong&gt;set-based&lt;/strong&gt;. These are some commonalities with SQL.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Rademacher Complexity</title>
      <link>https://flecart.github.io/notes/rademacher-complexity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/rademacher-complexity/</guid>
      <description>&lt;p&gt;This note used the definitions present in &lt;a href=&#34;https://flecart.github.io/notes/provably-approximately-correct-learning&#34;&gt;Provably Approximately Correct Learning&lt;/a&gt;. So, go there when you encounter a word you don&amp;rsquo;t know. Or search online&lt;/p&gt;
&lt;h2 id=&#34;rademacher-complexity&#34;&gt;Rademacher Complexity&lt;/h2&gt;
$$
\mathcal{G}  = \left\{ g : (x, y) \to L(h(x), y) : h \in \mathcal{H} \right\} 
$$&lt;p&gt;
Where $L : \mathcal{Y} \times \mathcal{Y} \to \mathbb{R}$ is a generic loss function.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Rademacher complexity captures the richness of a family of functions by measuring the degree to which a hypothesis set can fit random noise. From (Mohri et al. 2012).&lt;/p&gt;</description>
    </item>
    <item>
      <title>RL Function Approximation</title>
      <link>https://flecart.github.io/notes/rl-function-approximation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/rl-function-approximation/</guid>
      <description>&lt;p&gt;These algorithms are good for scaling state spaces, but not actions spaces.&lt;/p&gt;
&lt;h3 id=&#34;the-gradient-idea&#34;&gt;The Gradient Idea&lt;/h3&gt;
&lt;p&gt;Recall Temporal difference learning and Q-Learning, two model free policy evaluation techniques explored in &lt;a href=&#34;https://flecart.github.io/notes/tabular-reinforcement-learning&#34;&gt;Tabular Reinforcement Learning&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;a-simple-parametrization-&#34;&gt;A simple parametrization üü©&lt;/h4&gt;
&lt;p&gt;The idea here is to parametrize the value estimation function so that &lt;em&gt;similar inputs&lt;/em&gt; gets &lt;em&gt;similar values&lt;/em&gt; akin to &lt;a href=&#34;https://flecart.github.io/notes/parametric-modeling&#34;&gt;Parametric Modeling&lt;/a&gt; estimation we have done in the other courses. In this manner, we don&amp;rsquo;t need to explicitly explore every single state in the state space.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Semirings</title>
      <link>https://flecart.github.io/notes/semirings/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/semirings/</guid>
      <description>&lt;p&gt;Semirings allow us to generalize many many common operations. One of the most powerful usages is the algebraic view of dynamic programming.&lt;/p&gt;
&lt;h3 id=&#34;definition-of-a-semiring&#34;&gt;Definition of a semiring&lt;/h3&gt;
&lt;p&gt;A semiring is a 5-tuple $R = (A, \oplus, \otimes, \bar{0}, \bar{1})$ such that.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$(A, \oplus, \bar{0})$ is a commutative monoid&lt;/li&gt;
&lt;li&gt;$(A, \otimes, \bar{1})$ is a monoid&lt;/li&gt;
&lt;li&gt;$\otimes$ distributes over $\oplus$.&lt;/li&gt;
&lt;li&gt;$\bar{0}$ is annihilator for $\otimes$.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;monoid&#34;&gt;Monoid&lt;/h4&gt;
&lt;p&gt;Let $K, \oplus$ be a set and a operation, then:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sentiment Analysis</title>
      <link>https://flecart.github.io/notes/sentiment-analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/sentiment-analysis/</guid>
      <description>&lt;p&gt;Sentiment analysis is one of the oldest tasks in natural language processing. In this note we will introduce some examples and terminology, some key problems in the field and a simple model that we can understand by just knowing &lt;a href=&#34;https://flecart.github.io/notes/backpropagation&#34;&gt;Backpropagation&lt;/a&gt; &lt;a href=&#34;https://flecart.github.io/notes/log-linear-models&#34;&gt;Log Linear Models&lt;/a&gt; and the &lt;a href=&#34;https://flecart.github.io/notes/softmax-function&#34;&gt;Softmax Function&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We say:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Polarity:&lt;/strong&gt; the orientation of the sentiment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Subjectivity:&lt;/strong&gt; if it expresses personal feelings.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See &lt;a href=&#34;http://text-processing.com/demo/sentiment&#34;&gt;demo&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;some-applications&#34;&gt;Some applications:&lt;/h4&gt;
&lt;p&gt;Businesses use sentiment analysis to understand if users are happy or not with their product. It&amp;rsquo;s linked to revenue: if the reviews are good, usually you make more money. But companies can&amp;rsquo;t read every review, so they want automatic methods.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Softmax Function</title>
      <link>https://flecart.github.io/notes/softmax-function/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/softmax-function/</guid>
      <description>&lt;p&gt;Softmax is one of the most important functions for neural networks. It also has some interesting properties that we list here. This function is part of &lt;a href=&#34;https://flecart.github.io/notes/the-exponential-family&#34;&gt;The Exponential Family&lt;/a&gt;, one can also see that the sigmoid function is a particular case of this softmax, just two variables.
Sometimes this could be seen as a relaxation of the action potential inspired by neuroscience (See &lt;a href=&#34;https://flecart.github.io/notes/the-neuron&#34;&gt;The Neuron&lt;/a&gt; for a little bit more about neurons). This is because we need &lt;strong&gt;differentiable&lt;/strong&gt;, for gradient descent. The action potential is an all or nothing thing.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Support Vector Machines</title>
      <link>https://flecart.github.io/notes/support-vector-machines/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/support-vector-machines/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://cs229.stanford.edu/main_notes.pdf&#34;&gt;This&lt;/a&gt; is a quite good resource about this part of Support Vector Machines (step by step derivation). &lt;a href=&#34;https://link.springer.com/book/9780387310732&#34;&gt;(Bishop 2006)&lt;/a&gt; chapter 7 is a good resource. The main idea about this &lt;em&gt;supervised&lt;/em&gt; method is separating with a &lt;strong&gt;large gap&lt;/strong&gt;. The thing is that we have a hyperplane, when this plane is projected to lower dimensional data, it can look like a non-linear separator. After we have found this separator, we can intuitively have an idea of &lt;em&gt;confidence&lt;/em&gt; based on the distance of the separator.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tabular Reinforcement Learning</title>
      <link>https://flecart.github.io/notes/tabular-reinforcement-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/tabular-reinforcement-learning/</guid>
      <description>&lt;p&gt;This note extends the content &lt;a href=&#34;https://flecart.github.io/notes/markov-processes&#34;&gt;Markov Processes&lt;/a&gt; in this specific context.&lt;/p&gt;
&lt;h3 id=&#34;standard-notions&#34;&gt;Standard notions&lt;/h3&gt;
&lt;h4 id=&#34;explore-exploit-dilemma-&#34;&gt;Explore-exploit dilemma üü©&lt;/h4&gt;
&lt;p&gt;We have seen something similar also in &lt;a href=&#34;https://flecart.github.io/notes/active-learning&#34;&gt;Active Learning&lt;/a&gt; when we tried to model if we wanted to look elsewhere or go for the maximum value we have found.
The dilemma under analysis is the &lt;strong&gt;explore-exploit&lt;/strong&gt; dilemma: whether if we should just go for the best solution we have found at the moment, or look for a better one.
This also has implications in many other fields, also in normal human life there are a lot of balances in these terms.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Exponential Family</title>
      <link>https://flecart.github.io/notes/the-exponential-family/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/the-exponential-family/</guid>
      <description>&lt;p&gt;This is the generalization of the family of function where &lt;a href=&#34;https://flecart.github.io/notes/softmax-function&#34;&gt;Softmax Function&lt;/a&gt; belongs. Many many functions are part of this family, most of the distributions that are used in science are part of the exponential family, e.g. beta, Gaussian, Bernoulli, Categorical distribution, Gamma, Beta, Poisson, are all part of the exponential family.
The useful thing is the generalization power of this set of functions: if you prove something about this family, you prove it for every distribution that is part of this family.
This family of functions is also closely linked too Generalized Linear Models (GLMs).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transliteration systems</title>
      <link>https://flecart.github.io/notes/transliteration-systems/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/transliteration-systems/</guid>
      <description>&lt;p&gt;This note is still a TODO.&lt;/p&gt;
&lt;p&gt;Transliteration is learning learning a function to map strings in one character set to strings in another character set.
The basic example is in &lt;strong&gt;multilingual&lt;/strong&gt; applications, where it is needed to have the same string written in different languages.&lt;/p&gt;
&lt;p&gt;The goal is to develop a probabilistic model that can map strings from
input vocabulary $\Sigma$ to an output vocabulary $\Omega$.&lt;/p&gt;
&lt;p&gt;We will extend the concepts presented in &lt;a href=&#34;https://flecart.github.io/notes/automi-e-regexp&#34;&gt;Automi e Regexp&lt;/a&gt; for Finite state automata  to a weighted version. You will also need knowledge from &lt;a href=&#34;https://flecart.github.io/notes/descrizione-linguaggio&#34;&gt;Descrizione linguaggio&lt;/a&gt; for definitions of alphabets and strings, Kleene Star operations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Variational Inference</title>
      <link>https://flecart.github.io/notes/variational-inference/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/variational-inference/</guid>
      <description>$$
p(\theta \mid x_{1:n}, y_{1:n}) = \frac{1}{z} p(y_{1:n} \mid \theta, x_{1:n}) p(\theta \mid x_{1:n}) \approx q(\theta \mid \lambda)
$$&lt;p&gt;For &lt;a href=&#34;https://flecart.github.io/notes/bayesian-linear-regression&#34;&gt;Bayesian Linear Regression&lt;/a&gt; we had high dimensional &lt;a href=&#34;https://flecart.github.io/notes/gaussians&#34;&gt;Gaussians&lt;/a&gt; which made the inference &lt;em&gt;closed form&lt;/em&gt;, in general this is not true, so we need some kinds of approximation.&lt;/p&gt;
&lt;h2 id=&#34;laplace-approximation&#34;&gt;Laplace approximation&lt;/h2&gt;
&lt;h4 id=&#34;introduction-to-the-idea-&#34;&gt;Introduction to the Idea üü©&lt;/h4&gt;
$$
\psi(\theta) \approx \hat{\psi}(\theta) = \psi(\hat{\theta}) + (\theta-\hat{\theta} ) ^{T} \nabla \psi(\hat{\theta}) + \frac{1}{2} (\theta-\hat{\theta} ) ^{T} H_{\psi}(\hat{\theta})(\theta-\hat{\theta} ) = \psi(\hat{\theta}) + \frac{1}{2} (\theta-\hat{\theta} ) ^{T} H_{\psi}(\hat{\theta})(\theta-\hat{\theta} ) 
$$&lt;p&gt;
We simplified the term on the first order because we are considering the mode, so the gradient should be zero for the stationary point.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Wide Column Storage</title>
      <link>https://flecart.github.io/notes/wide-column-storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/wide-column-storage/</guid>
      <description>&lt;h3 id=&#34;introduction-to-wide-column-storages&#34;&gt;Introduction to Wide Column Storages&lt;/h3&gt;
&lt;p&gt;One of the bottlenecks of traditional relational databases is the speed of the Joints, which could be done in $\mathcal{O}(n)$ using a merge join, assuming some indexes are present which make the keys already sorted.
The other solution, of just using &lt;a href=&#34;https://flecart.github.io/notes/distributed-file-systems&#34;&gt;Distributed file systems&lt;/a&gt;, is also not optimal: they have usually a high latency, with high throughput, that is not optimal with the series of small files that it is optimized for.
While Object Storages, do not have APIs that could be helpful -&amp;gt; &lt;strong&gt;richer logical model&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Campo elettrico</title>
      <link>https://flecart.github.io/notes/campo-elettrico/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/campo-elettrico/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;intuizione-del-campo-elettrostatico&#34;&gt;Intuizione del campo elettrostatico&lt;/h3&gt;
&lt;h4 id=&#34;elettrostatico-vs-elettrodinamico-&#34;&gt;Elettrostatico vs elettrodinamico üü©&lt;/h4&gt;
&lt;p&gt;Andiamo a chiamare &lt;strong&gt;elettrostatico&lt;/strong&gt; perch√© nel nostro caso non si sta muovendo nessuna carica all&amp;rsquo;itnerno di questo campo.&lt;/p&gt;
&lt;h4 id=&#34;propriet√†-del-campo-elettrostatico-5-&#34;&gt;Propriet√† del campo elettrostatico (5) üü®&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Le linee di forza in ogni punto dello spazio sono tangenti e concorde al campo in quel punto;&lt;/li&gt;
&lt;li&gt;le linee di forza si addensano dove l&amp;rsquo;intensit√† del campo e maggiore;&lt;/li&gt;
&lt;li&gt;le linee di forza non si incrociano mai, in quanto in ogni punto il campo √® definito univocamente e non pu√≤ avere due direzioni distinte.&lt;/li&gt;
&lt;li&gt;le linee di forza hanno origine dalle cariche positive e terminano sul cariche negative; qualora ci siano solo cariche dello stesso segno le linee di forza si chiudono all&amp;rsquo; infinito;&lt;/li&gt;
&lt;li&gt;nel caso di cariche di segno opposto, ma eguali in modulo, tutte le linee the partono dalle cariche positive si chiudono su quelle negative (&lt;strong&gt;induzione completa&lt;/strong&gt;), alcune passando eventualmente per l&amp;rsquo;infinito; se invece le cariche non sono eguali in modulo, alcune linee terminano o provengono dall&amp;rsquo; infinito.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;carica-esploratrice-&#34;&gt;Carica esploratrice üü©&lt;/h4&gt;
&lt;p&gt;√à anche chiamata &lt;strong&gt;carica di prova&lt;/strong&gt;, √® una carica &lt;em&gt;fittizia&lt;/em&gt; messa per esplorare la &lt;strong&gt;struttura del campo elettrico&lt;/strong&gt; in un certo spazio&lt;/p&gt;</description>
    </item>
    <item>
      <title>Leggi di Ohm</title>
      <link>https://flecart.github.io/notes/leggi-di-ohm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/leggi-di-ohm/</guid>
      <description>&lt;p&gt;Gli argomenti della lezione 31 Ottobre sono circa da pagina 164 fino a 185 del mazzoldi.&lt;/p&gt;
&lt;h3 id=&#34;leggi-di-ohm&#34;&gt;Leggi di Ohm&lt;/h3&gt;
&lt;h4 id=&#34;introduzione-microscopica-&#34;&gt;Introduzione microscopica üü©&lt;/h4&gt;
&lt;h1 id=&#34;vecj---n-e-vecv_d&#34;&gt;Sappiamo che
$$
\vec{J} = -n e \vec{v}_{d}&lt;/h1&gt;
&lt;p&gt;ne^{2} t \frac{\vec{E}}{m}
$$
Vedi analisi della velocit√† di deriva col modello del 1900 in &lt;a href=&#34;https://flecart.github.io/notes/corrente-elettrica&#34;&gt;Corrente Elettrica&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Dove abbiamo utilizzato la definizione di densit√† di corrente e la velocit√† fra collisioni ed altre
Questo √® una motivazione per considerare la densit√† di corrente come se fosse nello stesso verso.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Potenziale Elettrostatico</title>
      <link>https://flecart.github.io/notes/potenziale-elettrostatico/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/potenziale-elettrostatico/</guid>
      <description>&lt;h3 id=&#34;introduzione-al-potenziale-elettrostatico&#34;&gt;Introduzione al potenziale elettrostatico&lt;/h3&gt;
&lt;p&gt;Abbiamo studiato in dinamica che il potenziale √® un concetto strettamente legato al Lavoro, ossia dalla quantit√† di energia necessaria per spostare un oggetto da un punto all&amp;rsquo;altro, vogliamo cercare di definire le relazioni che intercorrono nel caso della forza elettromagnetica&lt;/p&gt;
&lt;h4 id=&#34;rotore-nullo--forza-conservativa-&#34;&gt;Rotore nullo =&amp;gt; forza conservativa üü©&lt;/h4&gt;
$$
\vec{\nabla}  \times \vec{F} \implies \vec{F} \text{ √® una forza conservativa}
$$$$
\oint_{L} \vec{F} \cdot d\vec{l} = \iint_{S} \vec{\nabla} \times \vec{F} \,d\vec{s}
$$&lt;p&gt;
E se abbiamo che il rotore √® nullo, allora la forza √® conservativa perch√© per definizione √® conservativa se non dipende dal percorso, e la cosa che un circuito chiuso √® sufficiente per dimostrare il sopra.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Central Limit Theorem and Law of Large Numbers</title>
      <link>https://flecart.github.io/notes/central-limit-theorem-and-law-of-large-numbers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/central-limit-theorem-and-law-of-large-numbers/</guid>
      <description>&lt;h2 id=&#34;bounds&#34;&gt;Bounds&lt;/h2&gt;
&lt;h3 id=&#34;markov-bound&#34;&gt;Markov Bound&lt;/h3&gt;
$$
P(X \geq y) \leq \frac{E[X]}{y}
$$$$
yP(X \geq y) = y\int _{x =y}^{+\infty} f(x) \, dx \leq \int _{x=y}^{+\infty} x f(x) \, d \leq \int _{-\infty}^{+\infty}xf(x) \, d = E[X]  
$$&lt;p&gt;
Il che finisce la dimostrazione.&lt;/p&gt;
&lt;h3 id=&#34;chebychev-bound&#34;&gt;Chebychev Bound&lt;/h3&gt;
$$
P(\lvert x - E[X] \rvert  \geq y) \leq \frac{\sigma^{2}}{y^{2}}
$$&lt;p&gt;
E in pratica dice che all&amp;rsquo;infinito viene tutto compattata sul valore atteso
La dimostrazione √® abbastanza semplice, si sostituisce $(x - E[X])^{2}$ su $X$ di Markov e $\varepsilon^{2}$ a $y$ e poi si dovrebbe gi√† avere il risultato&lt;/p&gt;</description>
    </item>
    <item>
      <title>Equazioni non lineari</title>
      <link>https://flecart.github.io/notes/equazioni-non-lineari/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/equazioni-non-lineari/</guid>
      <description>&lt;p&gt;Per trovare i zeri di una funzione continua non lineare &lt;strong&gt;non esistono&lt;/strong&gt; alcuni metodi diretti che ci portano subito a una soluzione. Per questo motivo andremo ad analizzare molteplici pasis iterativi per trovare i zeri di una funzione.&lt;/p&gt;
&lt;p&gt;La discussione di convergenza di ordine p √® stata gi√† discussa nelle note introduttive convergenza e iterazione, per quanto riguarda i metodi iterativi per risolvere sistemi di equazioni lineari&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Globale e local
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Equazioni non lineari/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Equazioni non lineari/Untitled&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ricordiamo di  &lt;a href=&#34;https://flecart.github.io/notes/norme-e-condizionamento&#34;&gt;Norme e Condizionamento&lt;/a&gt;, in cui il condizionamento era pi√π o meno una stima di quanto cambia la soluzione quando cambia brevemente l&amp;rsquo;input. Ma ora vogliamo estendere il concetto per equazioni non lineari.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Codifica dei caratteri</title>
      <link>https://flecart.github.io/notes/codifica-dei-caratteri/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/codifica-dei-caratteri/</guid>
      <description>&lt;h3 id=&#34;introduzione-sullencoding&#34;&gt;Introduzione sull&amp;rsquo;encoding&lt;/h3&gt;
&lt;p&gt;Ossia trattiamo metodi per codificare caratteri dei linguaggi umani, come ASCII, UCS e UTF.&lt;/p&gt;
&lt;p&gt;Digitalizzare significa encodarlo in un sistema che possa essere memorizzato su un dispositivo di memorizzazione elettronico. Ovviamente non possiamo mantenere l&amp;rsquo;informazione cos√¨ come √®, ma vogliamo memorizzarne una forma equivalente, ma pi√π facile da manipolare dal punto di vista del computer. Creiamo quindi un mapping, o anche isomorfismo tra il valore di mappatura (o encoding), solitamente un valore numerico, tra il singolo valore atomico originale e il numero.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Lagrange Multipliers</title>
      <link>https://flecart.github.io/notes/lagrange-multipliers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/lagrange-multipliers/</guid>
      <description>&lt;p&gt;This is also known as &lt;em&gt;Lagrange Optimization&lt;/em&gt; or &lt;em&gt;undetermined multipliers&lt;/em&gt;. Some of these notes are based on Appendix E of &lt;a href=&#34;https://link.springer.com/book/9780387310732&#34;&gt;(Bishop 2006)&lt;/a&gt;, others were found when studying bits of rational mechanics.
Also &lt;a href=&#34;https://web.stanford.edu/~boyd/cvxbook/&#34;&gt;(Boyd &amp;amp; Vandenberghe 2004)&lt;/a&gt; chapter 5 should be a good resource on this topic.&lt;/p&gt;
$$
\begin{array} \\
\min f_{0}(x)  \\
\text{subject to } f_{i}(x) \leq 0 \\
h_{j}(x) = 0
\end{array}
$$&lt;h3 id=&#34;lagrangian-function&#34;&gt;Lagrangian function&lt;/h3&gt;
$$
\mathcal{L}(x, \lambda, \nu) = f_{0}(x) + \sum \lambda_{i}f_{i}(x) + \sum\nu_{j}h_{j}(x)
$$&lt;p&gt;
We want to say something about this function, because it is able to simplify the optimization problem a lot, but first we want to study this mathematically.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Markov Chains</title>
      <link>https://flecart.github.io/notes/markov-chains/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/markov-chains/</guid>
      <description>&lt;h3 id=&#34;introduzione-alle-catene-di-markov&#34;&gt;Introduzione alle catene di Markov&lt;/h3&gt;
&lt;h4 id=&#34;la-propriet√†-di-markov&#34;&gt;La propriet√† di Markov&lt;/h4&gt;
&lt;p&gt;Una sequenza di variabili aleatorie $X_{1}, X_{2}, X_{3}, \dots$ gode della propriet√† di Markov se vale:&lt;/p&gt;
$$
P(X_{n}| X_{n - 1}, X_{n - 2}, \dots, X_{1}) = P(X_{n}|X_{n-1})
$$&lt;p&gt;
Ossia posso scordarmi tutta la &lt;strong&gt;storia precedente&lt;/strong&gt;, mi interessa solamente lo stato precedente per sapere la probabilit√† attuale.&lt;/p&gt;
&lt;p&gt;Da un punto di vista filosofico/fisico, ha senso perch√© mi sta dicendo che posso predire lo stato successivo se ho una conoscenza (completa, (lo dico io completo, originariamente non esiste)) del presente.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Normalizzazione dei database</title>
      <link>https://flecart.github.io/notes/normalizzazione-dei-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/normalizzazione-dei-database/</guid>
      <description>&lt;h3 id=&#34;introduzione-alla-normalizzazione&#34;&gt;Introduzione alla normalizzazione&lt;/h3&gt;
&lt;h4 id=&#34;perch√©-si-normalizza-&#34;&gt;Perch√© si normalizza? üü©&lt;/h4&gt;
&lt;p&gt;Cercare di aumentare la qualit√† del nostro database, perch√© praticamente andiamo a risolvere delle anomalie possibili al nostro interno, e questo aiuta per la qualit√†.
Solitamente queste anomalie sono interessanti per sistemi write intensive, in cui vogliamo mantenere i nostri dati in una forma buona. Per√≤ capita non raramente che vogliamo solamente leggere. In quei casi sistemi come &lt;a href=&#34;https://flecart.github.io/notes/cloud-storage&#34;&gt;Cloud Storage&lt;/a&gt;, &lt;a href=&#34;https://flecart.github.io/notes/distributed-file-systems&#34;&gt;Distributed file systems&lt;/a&gt; potrebbero risultare pi√π effettivi.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Banach Spaces</title>
      <link>https://flecart.github.io/notes/banach-spaces/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/banach-spaces/</guid>
      <description>&lt;h3 id=&#34;what-are-banach-spaces&#34;&gt;What are Banach Spaces?&lt;/h3&gt;
&lt;p&gt;A &lt;strong&gt;Banach space&lt;/strong&gt; is a complete normed vector space, meaning that every Cauchy sequence in the space converges to a limit within the space.
See &lt;a href=&#34;https://flecart.github.io/notes/spazi-vettoriali&#34;&gt;Spazi vettoriali&lt;/a&gt; for the formal definition.&lt;/p&gt;
&lt;h3 id=&#34;examples-of-banach-spaces&#34;&gt;Examples of Banach Spaces&lt;/h3&gt;
&lt;p&gt;In this section, we list some examples of the most common Banach Spaces&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$\ell^p$ Spaces (Sequence Spaces)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Defined as:
$$
     \ell^p = \left\{ (x_n)_{n\in \mathbb{N}} \mid \sum_{n=1}^{\infty} |x_n|^p &lt; \infty \right\}, \quad 1 \leq p &lt; \infty
     $$&lt;/li&gt;
&lt;li&gt;The norm is given by:
$$
     \|x\|_p = \left( \sum_{n=1}^{\infty} |x_n|^p \right)^{1/p}
     $$&lt;/li&gt;
&lt;li&gt;When $p = \infty$, we define:
$$
     \ell^\infty = \left\{ (x_n)_{n\in \mathbb{N}} \mid \sup_n |x_n| &lt; \infty \right\}
     $$
with the norm $\|x\|_{\infty} = \sup_n |x_n|$.&lt;/li&gt;
&lt;li&gt;These spaces are Banach under their respective norms.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$L^p$ Spaces (Function Spaces)&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fatou&#39;s Lemma</title>
      <link>https://flecart.github.io/notes/fatous-lemma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/fatous-lemma/</guid>
      <description>&lt;p&gt;Fatou&amp;rsquo;s lemma is a fundamental result in measure theory that deals with the relationship between limits and integrals of sequences of non-negative measurable functions.
See the &lt;a href=&#34;https://en.wikipedia.org/wiki/Fatou%27s_lemma&#34;&gt;wikipedia&lt;/a&gt; page for further info.&lt;/p&gt;
&lt;h3 id=&#34;statement-of-fatous-lemma&#34;&gt;Statement of Fatou&amp;rsquo;s Lemma&lt;/h3&gt;
&lt;p&gt;Let $(f_n)$ be a sequence of non-negative measurable functions on a measure space $(X,\mu)$. Then:&lt;/p&gt;
$$\int \liminf_{n \to \infty} f_n \,d\mu \leq \liminf_{n \to \infty} \int f_n \,d\mu$$&lt;p&gt;In words, this means that the integral of the limit inferior of a sequence of functions is less than or equal to the limit inferior of their integrals.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Limiti</title>
      <link>https://flecart.github.io/notes/limiti/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/limiti/</guid>
      <description>&lt;p&gt;Riguardare &lt;a href=&#34;https://flecart.github.io/notes/successioni&#34;&gt;Successioni&lt;/a&gt; per avere primo attacco sui limiti&lt;/p&gt;
&lt;h2 id=&#34;41-limiti-finiti-al-finito&#34;&gt;4.1 Limiti finiti al finito&lt;/h2&gt;
&lt;h3 id=&#34;411-intorno-sferico&#34;&gt;4.1.1 Intorno sferico&lt;/h3&gt;
&lt;p&gt;Dato l&amp;rsquo;insieme $\mathbb{R}$ si definisce l&amp;rsquo;intorno sferico aperto di $x \in \mathbb{R}$ di raggio $r \in \mathbb{R}$ l&amp;rsquo;insieme
$I_r(x) = (x -r, x + r)$ questa nozione √® molto importante per definire il limite. Lo useremo subito su un punto di accumulazione&lt;/p&gt;
&lt;h3 id=&#34;412-punto-di-accumulazione&#34;&gt;4.1.2 Punto di accumulazione&lt;/h3&gt;
&lt;p&gt;Un punto di accumulazione $x$ di un insieme $A \subseteq \mathbb{R}$ √® un punto tale per cui mi posso avvicinare in modo indefinito  in quel punto. Infatti deve $\forall r &gt; 0 \in R, \exists x_ 1 \in A : x_1 \in I_r(x) \wedge x_1 \not= x$ ossia per cui $A \cap I_r(x) \not= \varnothing$.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Serie</title>
      <link>https://flecart.github.io/notes/serie/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/serie/</guid>
      <description>&lt;p&gt;Questo √® un tentativo di aggiungere un argomento che non era presente quando abbiamo fatto il corso due anni fa. Inizio la scrittura il 2024-03-03. Questo non √® stato trattano nel corso, ma √® importante per molte cose. Quindi introduco questo appunto.&lt;/p&gt;
&lt;h2 id=&#34;introduzione-alle-serie&#34;&gt;Introduzione alle serie&lt;/h2&gt;
&lt;p&gt;Le serie infinite sono dei mostri strani perch√© non si comportano spesso come dovrebbero.&lt;/p&gt;
&lt;h3 id=&#34;definizione-di-convergenza&#34;&gt;Definizione di convergenza&lt;/h3&gt;
$$
\lim_{ n \to \infty }  f_{n} = c
$$&lt;p&gt;
con $c$ un numero reale.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spazi vettoriali</title>
      <link>https://flecart.github.io/notes/spazi-vettoriali/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/spazi-vettoriali/</guid>
      <description>&lt;h1 id=&#34;spazi-vettoriali&#34;&gt;Spazi vettoriali&lt;/h1&gt;
&lt;h2 id=&#34;11-piano-cartesiano&#34;&gt;1.1 Piano cartesiano&lt;/h2&gt;
&lt;h3 id=&#34;111-definizione&#34;&gt;1.1.1 Definizione&lt;/h3&gt;
&lt;p&gt;Possiamo considerare il piano cartesiano come l&amp;rsquo;insieme $\R^2$ potremmo dire che esiste una corrispondenza fra una coordinata e un punto del piano, una volta che abbiamo definito un punto di origine. Si pu√≤ vedere anche come corrispondenza biunivoca con vettori del piano per l&amp;rsquo;origine (parte dall&amp;rsquo;origine).&lt;/p&gt;
&lt;p&gt;Questa cosa vale anche per uno spazio n-dimensionale, non soltanto due, ma per semplicit√† di introduzione di questo lo faccio con 2&lt;/p&gt;</description>
    </item>
    <item>
      <title>Derivate</title>
      <link>https://flecart.github.io/notes/derivate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/derivate/</guid>
      <description>&lt;h2 id=&#34;geometria-introduttiva&#34;&gt;Geometria introduttiva&lt;/h2&gt;
&lt;h3 id=&#34;tangente-e-pendenza&#34;&gt;Tangente e pendenza&lt;/h3&gt;
&lt;p&gt;Si pu√≤ trovare la relazione fra la pendenza della retta e la tangente.&lt;/p&gt;
&lt;p&gt;Possiamo analizzare la retta dal punto di vista analitico, della formula e si pu√≤ dimostrare che data una retta nella forma $y = mx + q$ $m$ √® la pendenza della retta.&lt;/p&gt;
&lt;h3 id=&#34;formula-generale-delle-rette&#34;&gt;Formula generale delle rette&lt;/h3&gt;
&lt;p&gt;Dati qualunque due punti .$(x_1, y_1), (x_2, y_2)$ possiamo dire che la pendenza √® esprimibile come&lt;/p&gt;</description>
    </item>
    <item>
      <title>Maximum Entropy Principle</title>
      <link>https://flecart.github.io/notes/maximum-entropy-principle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/maximum-entropy-principle/</guid>
      <description>&lt;p&gt;The maximum entropy principle is one of the most important guiding motives in artificial artificial intelligence. Its roots emerge from a long tradition of probabilistic inference that goes back to Laplace and Occam&amp;rsquo;s Razor, i.e. the principle of parsimony.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s start with a simple example taken from Andreas Kraus&amp;rsquo;s Lecture notes in the ETH course of Probabilistic Artificial Intelligence:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Consider a criminal trial with three suspects, A, B, and C. The
collected evidence shows that suspect C can not have committed
the crime, however it does not yield any information about sus-
pects A and B. Clearly, any distribution respecting the data must
assign zero probability of having committed the crime to suspect
C. However, any distribution interpolating between (1, 0, 0) and
(0, 1, 0) respects the data. The principle of indifference suggests
that the desired distribution is $(\frac{1}{2}, \frac{1}{2}, 0)$, and indeed, any alterna-
tive distribution seems unreasonable.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Multi Variable Derivatives</title>
      <link>https://flecart.github.io/notes/multi-variable-derivatives/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/multi-variable-derivatives/</guid>
      <description>&lt;h4 id=&#34;multi-variable-derivative&#34;&gt;Multi-variable derivative&lt;/h4&gt;
&lt;h1 id=&#34;endbmatrix&#34;&gt;To the people that are not used to matrix derivatives (like me) it could be useful to see how
$$
\frac{ \partial u^{T}Su }{ \partial u }  = 2Su
$$
First, we note that if you derive with respect to some matrix, the output will be of the same dimension of that matrix. That notation is just deriving every single component independently and then joining them together, so it will be better understood as as
$$
\frac{ \partial u^{T}Su }{ \partial u }  =
\begin{bmatrix}
\frac{ \partial u^{T}Su }{ \partial u_{1} }  \
\dots \
\frac{ \partial u^{T}Su }{ \partial u_{M} }  \
\end{bmatrix}&lt;/h1&gt;
$$
So we can prove each derivative independently, it&#39;s just a lot of manual work!
We see that $u^{T}Su$ is just a quadratic form, studied in &lt;a href=&#34;https://flecart.github.io/notes/massimi-minimi-multi-variabile#forme-quadratiche&#34;&gt;Massimi minimi multi-variabile#Forme quadratiche&lt;/a&gt; so it is just computing this:
$$&lt;p&gt;
u^{T}Su = \sum_{i, j = 1, 1}^{M} u_{i}u_{j}S_{ij} \implies \frac{ \partial u^{T}Su }{ \partial u_{1} } =2u_{1}S_{11} + \sum_{j \neq 1}^{M}(u_{j}S_{1j}  + u_{j}S_{j1}) = 2\left( u_{1}S_{11} + \sum_{j \neq 1}u_{j}S_{1j} \right) = 2(Su)_{1}
$$
Last equation is true because $S$ is a symmetric matrix, then we easily see that indeed it&amp;rsquo;s true that indeed it&amp;rsquo;s the first row of the $Su$ matrix multiplied by 2.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Optimal Minimax Facility Location</title>
      <link>https://flecart.github.io/notes/optimal-minimax-facility-location/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/optimal-minimax-facility-location/</guid>
      <description>&lt;p&gt;In this note we will briefly present one problem common in operation research.
The practical needs that formulated this problem are quite obvious: choosing the best location to build some important services for communities.&lt;/p&gt;
&lt;p&gt;The optimal minimax facility location refers to the placement of a facility (such as a warehouse, hospital, or service center) in such a way that the &lt;strong&gt;maximum distance or cost&lt;/strong&gt; between the facility and any of the demand points (such as customers, patients, or users) is minimized. This approach is particularly useful when the goal is to ensure that no demand point is too far from the facility, thus providing a form of equity in service delivery.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Structured Query Language</title>
      <link>https://flecart.github.io/notes/structured-query-language/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/structured-query-language/</guid>
      <description>&lt;h3 id=&#34;little-bits-of-history&#34;&gt;Little bits of history&lt;/h3&gt;
&lt;p&gt;It was invented in 1970 in Almaden (San Jose) by IBM (Don Chamberlin, Raymond Boyce worked on this) for the first relational database, called system R. Then for copyright issues it hasn&amp;rsquo;t been called SEQUEL, so they branded it as SQL.&lt;/p&gt;
&lt;h4 id=&#34;sql-is-a-declarative-language&#34;&gt;SQL is a declarative language&lt;/h4&gt;
&lt;p&gt;With declaratives language there is a separation between what I call the intentionality and the actual process. In declarative languages we just say what we want the result to be, and don&amp;rsquo;t care what the actual implementation is like.
This allows queries to be executed and optimized in different ways, even if the query on the surface is the same&lt;/p&gt;</description>
    </item>
    <item>
      <title>Successioni</title>
      <link>https://flecart.github.io/notes/successioni/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/successioni/</guid>
      <description>&lt;h2 id=&#34;31-successioni&#34;&gt;3.1 Successioni&lt;/h2&gt;
$$
\begin{cases}
f: \mathbb{N} \to \mathbb{R} \\
n \to f(n) \\
\{a\}_{n \in \mathbb{N}} \vee a_n
\end{cases}
$$$$
\left\{ a \right\} _{n \in \mathbb{N}}
$$&lt;h3 id=&#34;311-immagine-e-successione&#34;&gt;3.1.1 Immagine e successione&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;L&amp;rsquo;immagine di una successione (l&amp;rsquo;insieme dei suoi elementi) &lt;strong&gt;non √® una successione!&lt;/strong&gt; la successione √® anche ordinata.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;312-limitazioni-della-successione&#34;&gt;3.1.2 Limitazioni della successione&lt;/h3&gt;
&lt;p&gt;Come per gli insiemi si pu√≤ definire se &lt;strong&gt;l&amp;rsquo;insieme √® limitato superiormente, inferiormente o entrambi&lt;/strong&gt;, a seconda di come lo definiamo in questo modo possiamo poi farci altri ragionamenti&lt;/p&gt;</description>
    </item>
    <item>
      <title>Uniform Resource Identifier</title>
      <link>https://flecart.github.io/notes/uniform-resource-identifier/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/uniform-resource-identifier/</guid>
      <description>&lt;h1 id=&#34;uri&#34;&gt;URI&lt;/h1&gt;
&lt;p&gt;Sono stata LA vera invenzione di Berners Lee accennati in &lt;a href=&#34;https://flecart.github.io/notes/storia-del-web&#34;&gt;Storia del web&lt;/a&gt;. Il problema √® avere un modo per identificare una risorsa in modo univoco sull‚Äôinternet.&lt;/p&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;la-risorsa-&#34;&gt;La risorsa üü©&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Una risorsa √® qualunque struttura che sia oggetto di scambio tra
applicazioni all‚Äôinterno del World Wide Web.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ora una risorsa pu√≤ essere qualunque cosa, non solamente solo un file! Quindi √® agnostico rispetto a contenuto oppure metodo di memorizzazione del dato, appare anche in questo ambiente importante vedere quanto siano importanti standard che permettano una comunicazione&lt;/p&gt;</description>
    </item>
    <item>
      <title>Relational Algebra</title>
      <link>https://flecart.github.io/notes/relational-algebra/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/relational-algebra/</guid>
      <description>&lt;h2 id=&#34;introduzione-allalgebra-relazionale&#34;&gt;Introduzione all&amp;rsquo;algebra relazionale&lt;/h2&gt;
&lt;h3 id=&#34;confronto-con-relazioni-matematiche&#34;&gt;Confronto con relazioni matematiche&lt;/h3&gt;
&lt;p&gt;Le relazioni come le intendiamo in database sono leggermente diverse rispetto a quelle presenti per le relazioni matematiche:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Non conta l&amp;rsquo;ordine&lt;/li&gt;
&lt;li&gt;Ci sono gli attributi&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Per il resto se introduciamo questo sistema per tenere conto delle astrazioni, possiamo analizzarle matematicamente, e questo ci fornisce qualche sicurezza in pi√π diciamo.&lt;/p&gt;
&lt;h4 id=&#34;four-types-of-operations&#34;&gt;Four types of operations&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Set operations&lt;/strong&gt;: union, intersection, difference&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Filter queries&lt;/strong&gt;: Projecting or selecting&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Renaming queries&lt;/strong&gt;: renames&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Join&lt;/strong&gt;: correlare tuple di relazioni diverse&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;definition-of-tuples-&#34;&gt;Definition of tuples üü©&lt;/h4&gt;
&lt;p&gt;Le relazioni sono esattamente quelle definite in matematica, per√≤ noi aggiungiamo anche gli attributi, in modo da poter considerare l&amp;rsquo;ordine delle colonne non importante.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bloom Filters</title>
      <link>https://flecart.github.io/notes/bloom-filters/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/bloom-filters/</guid>
      <description>&lt;h3 id=&#34;how-bloom-filters-work&#34;&gt;&lt;strong&gt;How Bloom Filters Work&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;A &lt;strong&gt;Bloom filter&lt;/strong&gt; is a space-efficient probabilistic data structure used to test whether an element is &lt;strong&gt;possibly in a set&lt;/strong&gt; or &lt;strong&gt;definitely not in a set&lt;/strong&gt;. It allows for false positives but never false negatives.&lt;/p&gt;
&lt;p&gt;One example of application is the membership query in &lt;a href=&#34;https://flecart.github.io/notes/wide-column-storage&#34;&gt;Wide Column Storage&lt;/a&gt;, HBase. They make document lookup faster by completely skipping some HFiles.&lt;/p&gt;
&lt;h3 id=&#34;structure-and-initialization&#34;&gt;Structure and Initialization&lt;/h3&gt;
&lt;p&gt;A Bloom filter consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;strong&gt;bit array&lt;/strong&gt; of size $m$, initialized to all &lt;strong&gt;0s&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;$k$ independent &lt;strong&gt;hash functions&lt;/strong&gt;, each mapping an input element to one of the $m$ positions in the bit array.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;common-operations&#34;&gt;Common operations&lt;/h2&gt;
&lt;h3 id=&#34;insertion-of-an-element&#34;&gt;Insertion of an Element&lt;/h3&gt;
&lt;p&gt;To insert an element $x$:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gestione delle risorse</title>
      <link>https://flecart.github.io/notes/gestione-delle-risorse/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/gestione-delle-risorse/</guid>
      <description>&lt;h1 id=&#34;gestione-delle-risorse&#34;&gt;Gestione delle risorse&lt;/h1&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;definizione-classe-fungibilit√†&#34;&gt;Definizione classe, fungibilit√†&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Classe di risorse&lt;/strong&gt; sono un insieme di risorse fra loro equivalenti (nel senso che uno pu√≤ rimpiazzare l‚Äôuso dell&amp;rsquo;altro), anche detti fungibili.&lt;/p&gt;
&lt;h3 id=&#34;statico-o-dinamico&#34;&gt;Statico o dinamico&lt;/h3&gt;
&lt;p&gt;Anche in economia ci sono tali definizioni! Queste risorse possono essere allocate staticamente o dinamicamente, in modo simile a quanto abbiamo detto in &lt;a href=&#34;https://flecart.github.io/notes/gestione-della-memoria&#34;&gt;Gestione della memoria&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Statico quando gi√† in fase di compilazione del processo, o di avviamento del processo gli d√≤ la memoria, e quella sar√† per tutti il tempo della sua vita.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Entropy</title>
      <link>https://flecart.github.io/notes/entropy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/entropy/</guid>
      <description>&lt;p&gt;Questo √® stato creato da 1948 Shannon in &lt;a href=&#34;https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf&#34;&gt;(Shannon 1948)&lt;/a&gt;. Questa nozione √® basata sulla nozione di probabilit√†, perch√© le cose rare sono pi√π informative rispetto a qualcosa che accade spesso.&lt;/p&gt;
&lt;h3 id=&#34;introduction-to-entropy&#34;&gt;Introduction to Entropy&lt;/h3&gt;
&lt;h4 id=&#34;the-shannon-information-content&#34;&gt;The Shannon Information Content&lt;/h4&gt;
$$
h(x = a_{i}) = \log_{2}\frac{1}{P(x = a_{i})}
$$&lt;p&gt;
We will see that the entropy is a weighted average of the information, so the expected information content in a distribution.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://flecart.github.io/notes/kolmogorov-complexity&#34;&gt;Kolmogorov complexity&lt;/a&gt; √® un modo diverso per definire la complessit√†.
Legato √® &lt;a href=&#34;https://flecart.github.io/notes/neural-networks#kullback-leibler-divergence&#34;&gt;Neural Networks#Kullback-Leibler Divergence&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Merkle Trees</title>
      <link>https://flecart.github.io/notes/merkle-trees/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/merkle-trees/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Merkle Trees: A Fundamental Structure in Cryptography&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Merkle trees, introduced by Ralph Merkle in 1979, are a pivotal data structure in cryptographic systems. These binary hash trees enable efficient and secure verification of data integrity within distributed systems. Their design capitalizes on hash functions to reduce computational overhead, making them indispensable in blockchain and peer-to-peer networks.&lt;/p&gt;
&lt;h3 id=&#34;what-are-merkle-trees&#34;&gt;What are Merkle Trees?&lt;/h3&gt;
&lt;h4 id=&#34;structure-and-construction&#34;&gt;Structure and Construction&lt;/h4&gt;
&lt;p&gt;A Merkle tree is a rooted binary tree where:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tabelle di hash</title>
      <link>https://flecart.github.io/notes/tabelle-di-hash/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/tabelle-di-hash/</guid>
      <description>&lt;h2 id=&#34;introduzione-alle-tabelle-di-hash&#34;&gt;Introduzione alle Tabelle di Hash&lt;/h2&gt;
&lt;h3 id=&#34;511-prototipo&#34;&gt;5.1.1 Prototipo&lt;/h3&gt;
&lt;p&gt;Vogliamo implementare le operazioni del prototipo dizionario presentato in &lt;a href=&#34;https://flecart.github.io/notes/strutture-di-dati-elementari&#34;&gt;Strutture di dati elementari&lt;/a&gt;, e vogliamo fare solo queste 3 ma molto bene.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Insert O(1)&lt;/li&gt;
&lt;li&gt;Delete O(1)&lt;/li&gt;
&lt;li&gt;Search in O(1)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;La struttura dati di hash riesce a fare bene queste singole operazioni&lt;/p&gt;
&lt;p&gt;Si vedr√† che &lt;strong&gt;l&amp;rsquo;array&lt;/strong&gt; modificato √® il modo migliore per avere questo hash, solo generalizzando un modo per indicizzarlo che non saranno numeri (indici).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Interactive Theorem Provers</title>
      <link>https://flecart.github.io/notes/interactive-theorem-provers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/interactive-theorem-provers/</guid>
      <description>&lt;p&gt;Most of times the pattern of proving and verifying it is like this $prove \to verify$, that is: there is an entity that generates the solution, andPo then another that tries to verify it.
But more expressive algorithms could be possible if there is &lt;strong&gt;interaction&lt;/strong&gt; between the two entities, ones that try to prove it, and others try to verify it.
From some point of view, this is similar from what AlphaGo does when searching, there is a part that guides the search, another that actually searches for it. Or the modern &lt;a href=&#34;https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/&#34;&gt;alpha geometry&lt;/a&gt; in modern times.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Index, B-trees and hashes</title>
      <link>https://flecart.github.io/notes/index-b-trees-and-hashes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/index-b-trees-and-hashes/</guid>
      <description>&lt;h2 id=&#34;indexes&#34;&gt;Indexes&lt;/h2&gt;
&lt;p&gt;Trattiamo qui di alcuni metodi che sono utilizzati per costruire indici&lt;/p&gt;
&lt;h3 id=&#34;introduction-to-indexes&#34;&gt;Introduction to indexes&lt;/h3&gt;
&lt;p&gt;Gli indici sono una struttura di dati aggiuntiva che ci permette di ricercare pi√π in fretta alcuni valori per le queries. In questa sezione proviamo ad approfondire in che modo possono essere costruite e gestite.&lt;/p&gt;
&lt;h4 id=&#34;search-keys-&#34;&gt;Search keys üü©&lt;/h4&gt;
&lt;p&gt;Sono in breve la cosa che vogliamo andare a cercare. Solitamente sono nella forma
&lt;strong&gt;&amp;lt;key, label&amp;gt;&lt;/strong&gt;, che ci permette di trovare in fretta il label, che si potrebbe intendere come il valore che noi stiamo provando a cercare.&lt;/p&gt;</description>
    </item>
    <item>
      <title>IPSec protocol</title>
      <link>https://flecart.github.io/notes/ipsec-protocol/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/ipsec-protocol/</guid>
      <description>&lt;p&gt;Questo √® un protocollo di sicurezza a livello Rete e non pi√π a livello socket!&lt;/p&gt;
&lt;p&gt;Perch√© vorremmo avere sicurezza a questo livello? √à una cosa troppo comune da dover mettere a livello superiore (ma solitamente viene messa a questo livello per la sicurezza, quindi non √® implementata ovunque per dire), quindi IPsec vuole facilitare l&amp;rsquo;implementazione dei principi CIA a un livello pi√π basso, in modo che sia flessibile e customization.&lt;/p&gt;</description>
    </item>
    <item>
      <title>k-esimo priority-q DSU</title>
      <link>https://flecart.github.io/notes/k-esimo-priority-q-dsu/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/k-esimo-priority-q-dsu/</guid>
      <description>&lt;p&gt;Questo documento √® totalmente concentrato sull&amp;rsquo;analisi del problema della selezione del k-esimo elemento.&lt;/p&gt;
&lt;h2 id=&#34;71-introduzione-al-problema&#34;&gt;7.1 Introduzione al problema&lt;/h2&gt;
&lt;p&gt;Dato un array di elementi vogliamo cercare di trovare un modo efficiente per selezionare il k-esimo elemento, ossia un elemento che sia maggiore di k-1 elementi&lt;/p&gt;
&lt;h3 id=&#34;711-note-sullutilizzo&#34;&gt;7.1.1 Note sull&amp;rsquo;utilizzo&lt;/h3&gt;
&lt;p&gt;Questo algoritmo √® utile per esempio per sapere cosa displayare in una pagina di ricerca, perch√© per esempio posso avere blocchi di tanta roba 140k, mentre ovviamente posso selezionare solamente un blocco ristretto.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Logica meta-linguistica</title>
      <link>https://flecart.github.io/notes/logica-meta-linguistica/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/logica-meta-linguistica/</guid>
      <description>&lt;p&gt;Con questo documento iniziamo a parlare di logica, alcuni paradossi famosi all&amp;rsquo;interno di questo mondo.&lt;/p&gt;
&lt;h1 id=&#34;paradossi-metalinguistici&#34;&gt;Paradossi Metalinguistici&lt;/h1&gt;
&lt;h2 id=&#34;antinomie-e-paradossi&#34;&gt;Antinomie e Paradossi&lt;/h2&gt;
&lt;h3 id=&#34;antinomia&#34;&gt;Antinomia&lt;/h3&gt;
&lt;p&gt;Definizione di antinomia √® un ragionamento corretto da cui deriva una conclusione errata, probabilmente √® &lt;strong&gt;l&amp;rsquo;insieme o campo in cui stiamo operando ad essere errato&lt;/strong&gt; e bisogna cercare di ridefinirlo in modo pi√π corretto, in quanto &lt;strong&gt;le premesse erano accettabili&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;paradosso&#34;&gt;Paradosso&lt;/h3&gt;
&lt;p&gt;Paradosso quando il ragionamento corretto va &lt;em&gt;contro&lt;/em&gt; l&amp;rsquo;intuizione, come il paradosso dei gemelli in fisica e simili. &lt;strong&gt;premesse erano accettabili&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Poisson processes</title>
      <link>https://flecart.github.io/notes/poisson-processes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/poisson-processes/</guid>
      <description>&lt;p&gt;I processi di Poisson sono dei &lt;strong&gt;processi stocastici&lt;/strong&gt;, interpretabili come  collezione indicizzata dal tempo di variabili aleatorie.
Esempi semplici sono una uniforme, altri pi√π complessi potrebbe essere una catena di Markov (see &lt;a href=&#34;https://flecart.github.io/notes/markov-chains&#34;&gt;Markov Chains&lt;/a&gt;) (utile per modellare cammini randomici) o quella di Poisson spiegata qui.&lt;/p&gt;
&lt;h3 id=&#34;introduzione-ai-processi-di-poisson&#34;&gt;Introduzione ai processi di Poisson&lt;/h3&gt;
&lt;h4 id=&#34;arrival-processes&#34;&gt;Arrival processes&lt;/h4&gt;
&lt;p&gt;Sia una sequenza di variabili aleatorie $0 &lt; S_{1} &lt; S_{2} &lt; \dots$ (il fatto che sia positivo  significa che per ogni elemento del dominio vale che quell&amp;rsquo;elemento √® &amp;lt;, non so se mi sono spiegato.)
&lt;img src=&#34;https://flecart.github.io/images/notes/Poisson processes-20240128100752878.webp&#34; width=&#34;443&#34; class=&#34;center&#34; alt=&#34;Poisson processes-20240128100752878&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Relazioni fra insiemi</title>
      <link>https://flecart.github.io/notes/relazioni-fra-insiemi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/relazioni-fra-insiemi/</guid>
      <description>&lt;h2 id=&#34;coppia-ordinata&#34;&gt;Coppia ordinata&lt;/h2&gt;
&lt;h3 id=&#34;definizione-di-kuratowsky&#34;&gt;Definizione di Kuratowsky&lt;/h3&gt;
&lt;p&gt;Una coppia ordinata √® definita dall&amp;rsquo;insieme&lt;/p&gt;
$$
\langle X, Y \rangle = \{X, \{X, Y\}\}
$$&lt;p&gt;√à quindi chiaro che due coppie ordinate sono uguali fra di loro nel caso in cui gli elementi sono uguali ma anche la loro posizione sono uguali&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Teorema caratterizzazione delle coppie&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Relazioni fra insiemi/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Relazioni fra insiemi/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;definizione-di-wiener&#34;&gt;Definizione di Wiener&lt;/h3&gt;
$$
(X,Y) := \{\{\{X\}, \varnothing\}, \{\{Y\}\}\}
$$&lt;h3 id=&#34;definizione-di-hausdorff&#34;&gt;Definizione di Hausdorff&lt;/h3&gt;
$$
(X,Y) := \{\{X, 1\}, \{X,2\}\}
$$&lt;h3 id=&#34;propriet√†-fondamentale-coppie-ordinate&#34;&gt;Propriet√† fondamentale coppie ordinate&lt;/h3&gt;
&lt;p&gt;Due coppie ordinate si dicono uguali se e solo se il primo elemento dei due sono uguali e la stessa cosa per il secondo&lt;/p&gt;</description>
    </item>
    <item>
      <title>Semafori</title>
      <link>https://flecart.github.io/notes/semafori/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/semafori/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;concetto-principale--&#34;&gt;Concetto principale üü©-&lt;/h3&gt;
&lt;p&gt;√à sempre stato introdotto da Dijkstra, 1965 (Cooperating Sequential Processes) utilizzato come strumento di cooperazione semplice&lt;/p&gt;
&lt;p&gt;Questo √® un sistema fortemente ispirato dai semafori che regolano gli incroci stradali.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;due o pi√π processi possono cooperare attraverso semplici
segnali, in modo tale che un processo possa essere bloccato
in specifici punti del suo programma finch√© non riceve un
segnale da un altro processo&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;primitive-dei-semafori--&#34;&gt;Primitive dei semafori üü©-&lt;/h3&gt;
&lt;p&gt;Il semaforo solitamente √® una &lt;strong&gt;variabile intera non negativa&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spazi di probabilita</title>
      <link>https://flecart.github.io/notes/spazi-di-probabilita/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/spazi-di-probabilita/</guid>
      <description>&lt;p&gt;In order to define the concept of probability formally, we need first to introduce some mathematical concepts.&lt;/p&gt;
&lt;h2 id=&#34;la-probabilit√†&#34;&gt;La probabilit√†&lt;/h2&gt;
&lt;h2 id=&#34;termini&#34;&gt;Termini&lt;/h2&gt;
&lt;h3 id=&#34;esito-ed-esperimenti-aleatorio&#34;&gt;Esito ed esperimenti aleatorio&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;L‚Äôevento&lt;/strong&gt; √® quello che accade, mentre un esperimento aleatorio qualcosa di cui vogliamo andare a misurare la probabilit√† diciamo.
&lt;strong&gt;Esperimento aleatorio:&lt;/strong&gt; esperimento di cui non conosciamo il risultato con certezza.
&lt;strong&gt;Esito&lt;/strong&gt;: risultato dell‚Äôesperimento aleatorio&lt;/p&gt;
&lt;h3 id=&#34;spazio-campionario-ed-evento&#34;&gt;Spazio campionario ed evento&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Spazio campionatorio&lt;/strong&gt;
Lo spazio campionatorio √® l&amp;rsquo;insieme di tutti gli stati possibili per una certa cosa da misurare (ossia di un esperimento aleatorio), gli stati sono talvolta anche chiamati &lt;em&gt;sample points&lt;/em&gt; oppure &lt;em&gt;outcomes&lt;/em&gt; in modo pi√π semplice.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Wireless attack vectors</title>
      <link>https://flecart.github.io/notes/wireless-attack-vectors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/wireless-attack-vectors/</guid>
      <description>&lt;p&gt;In this note we will talk about some common ways to attack wireless based devices.&lt;/p&gt;
&lt;h3 id=&#34;attacking-an-automated-door&#34;&gt;Attacking an automated door&lt;/h3&gt;
&lt;p&gt;Usually these doors are opened by radio frequency keys, and can be opened easily (e.g. replay attacks, Jam the frequency)&lt;/p&gt;
&lt;h4 id=&#34;jamming&#34;&gt;Jamming&lt;/h4&gt;
&lt;p&gt;This is the easiest way to attack. Just send many signals to make a certain frequency un-usable in our space.
But with Frequency hopping this attack is solved. See &lt;a href=&#34;https://flecart.github.io/notes/tecnologia-wireless#frequency-hopping&#34;&gt;Tecnologia Wireless#Frequency Hopping&lt;/a&gt;
But this method could be easily known and observed (enables eavesdropping, against confidentiality, a principle in &lt;a href=&#34;https://flecart.github.io/notes/theoretical-notions-of-security#ciaa-principles-of-security&#34;&gt;Theoretical Notions of Security#CIAA principles of security&lt;/a&gt;.) if the initial seed is known.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bag of words</title>
      <link>https://flecart.github.io/notes/bag-of-words/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/bag-of-words/</guid>
      <description>&lt;p&gt;Bag of words only takes into account the &lt;strong&gt;count&lt;/strong&gt; of the words inside a document, ignoring all the syntax and boundaries. This method is very common for email classifications techniques.
We can say bag of words can be some sort of &lt;strong&gt;pooling&lt;/strong&gt;, it&amp;rsquo;s similar to the computer vision analogue.
It&amp;rsquo;s difficult to say what is the best method (also a reason why people say NLP is difficult to teach).&lt;/p&gt;
&lt;h3 id=&#34;introduction-to-bag-of-words&#34;&gt;Introduction to bag of words&lt;/h3&gt;
&lt;p&gt;Faremo una introduzione di applicazione di &lt;a href=&#34;https://flecart.github.io/notes/na√Øve-bayes&#34;&gt;Na√Øve Bayes&lt;/a&gt; applicato alla classificazione di documenti.
&lt;img src=&#34;https://flecart.github.io/images/notes/Bag of words-20240907182135341.webp&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Bag of words-20240907182135341&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Object detection and Segmentation</title>
      <link>https://flecart.github.io/notes/object-detection-and-segmentation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/object-detection-and-segmentation/</guid>
      <description>&lt;h3 id=&#34;definition-of-problems&#34;&gt;Definition of problems&lt;/h3&gt;
&lt;h4 id=&#34;object-detection&#34;&gt;Object detection&lt;/h4&gt;
&lt;p&gt;Bisogna trovare all&amp;rsquo;interno dell&amp;rsquo;immagine quali siano gli oggetti presenti, e in pi√π &lt;strong&gt;vogliamo sapere dove siano&lt;/strong&gt; quindi utilizzare una bounding box per caratterizzarli sarebbe buono.&lt;/p&gt;
&lt;h4 id=&#34;object-segmentation&#34;&gt;Object segmentation&lt;/h4&gt;
&lt;p&gt;√à riuscire a caratterizzare categoria per categoria per &lt;strong&gt;singoli pixels&lt;/strong&gt;m e per questo motivo potrei riuscire a fare delle image map in cui colorare singoli oggetti in una categoria.&lt;/p&gt;
&lt;h3 id=&#34;datasets&#34;&gt;Datasets&lt;/h3&gt;
&lt;h4 id=&#34;example-datasets&#34;&gt;Example datasets&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Pascal VOC 2012&lt;/li&gt;
&lt;li&gt;Coco datasets&lt;/li&gt;
&lt;li&gt;Cityscapes dataset&lt;/li&gt;
&lt;li&gt;Autogenerated datasets
But I don&amp;rsquo;t know much about these datasets&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;applications&#34;&gt;Applications&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Auto drive&lt;/li&gt;
&lt;li&gt;Campo medico (per segmentazione medica o riconoscimento immagini).&lt;/li&gt;
&lt;li&gt;reidentificazione.&lt;/li&gt;
&lt;li&gt;Key posse extimations.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;u-net&#34;&gt;U-net&lt;/h4&gt;
&lt;p&gt;Il primo skip connection ci permette di capire bene quali siano i bordi, perch√© sappiamo che la convoluzione riesce a prendere bene&lt;/p&gt;</description>
    </item>
    <item>
      <title>Optimization methods</title>
      <link>https://flecart.github.io/notes/optimization-methods/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/optimization-methods/</guid>
      <description>&lt;p&gt;Metodi altri sono trovare una &lt;strong&gt;approssimazione&lt;/strong&gt; facile da calcolare (simile all&amp;rsquo;approccio del modello surrogato credo).
Ma nel nostro caso proviamo a trovare metodi di esplorare lo &lt;strong&gt;spazio dei parametri&lt;/strong&gt; in modo intelligente.&lt;/p&gt;
&lt;h3 id=&#34;deterministic-methods&#34;&gt;Deterministic methods&lt;/h3&gt;
&lt;p&gt;Sono utilizzabili quando ci sono delle propriet√† come convessit√†, limitatezza, continuit√†.&lt;/p&gt;
&lt;h4 id=&#34;newton-raphson-method&#34;&gt;Newton Raphson method&lt;/h4&gt;
&lt;p&gt;Molte implementazioni in R usano questo metodo, √®&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Perfetto quando $h$ √® quadratico, e in statistica molti problemi sono quadratici e funziona in modo perfetto&lt;/li&gt;
&lt;li&gt;Ma in cose non lineari si ha meno performance (perch√© l&amp;rsquo;hessiana √® molto instabile per l&amp;rsquo;inversione, si dice che √® mal condizionata, e si fa con attenzione.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;l&amp;rsquo;unica cosa da sapere secondo me √®&lt;/p&gt;</description>
    </item>
    <item>
      <title>Massimi minimi multi-variabile</title>
      <link>https://flecart.github.io/notes/massimi-minimi-multi-variabile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/massimi-minimi-multi-variabile/</guid>
      <description>&lt;h2 id=&#34;matrice-jacobiana&#34;&gt;Matrice Jacobiana&lt;/h2&gt;
&lt;p&gt;√à un modo per scrivere il gradiente di una funzione quando √® in una certa forma.&lt;/p&gt;
&lt;p&gt;Data una funzione $f: \mathbb{R}^n \to \mathbb{R}^p$
ossia per esempio $x=(x_1,...,x_n) \to(f_1(x),...,f_p(x))$
Se le p funzioni di arrivo sono differenziabili, allora la matrice Jacobiana √® definita in questo modo:&lt;/p&gt;
&lt;p&gt;$$J_f(x) = \begin{pmatrix}
\delta_{x_1} f_1(x) &amp;amp; &amp;hellip; &amp;amp; \delta_{x_n} f_1(x)\
. &amp;amp; . &amp;amp; . \
\delta_{x_1} f_p(x) &amp;amp; &amp;hellip; &amp;amp; \delta_{x_n} f_p(x)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Autovalori e Autovettori</title>
      <link>https://flecart.github.io/notes/autovalori-e-autovettori/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/autovalori-e-autovettori/</guid>
      <description>&lt;p&gt;Ha senso solamente parlare di autovettori quando si ha una &lt;strong&gt;applicazione lineare con stesso dominio e stesso codominio.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Vorremmo trovare una buona matrice che sia diagonale.&lt;/p&gt;
&lt;h2 id=&#34;61-diagonalizzabilit√†&#34;&gt;6.1 Diagonalizzabilit√†&lt;/h2&gt;
&lt;h3 id=&#34;611-definizione-per-funzione-e-matrice&#34;&gt;6.1.1 Definizione per funzione e matrice&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Cambio di Base e Autovalori/Untitled 3.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Cambio di Base e Autovalori/Untitled 3&#34;&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Cambio di Base e Autovalori/Untitled 4.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Cambio di Base e Autovalori/Untitled 4&#34;&gt;
&lt;p&gt;Questo perch√© vorrei una base in cui si abbia un matrice diagonale. (quindi probabilmente P √® una matrice identit√†).&lt;/p&gt;</description>
    </item>
    <item>
      <title>CSS</title>
      <link>https://flecart.github.io/notes/css/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/css/</guid>
      <description>&lt;h1 id=&#34;cascading-style-sheets&#34;&gt;Cascading Style Sheets&lt;/h1&gt;
&lt;p&gt;Inizialmente HTML era per la presentazione, abbiamo ancora un p√≤ di attributi storici e tag storici per questa parte di presentazione descritto in &lt;a href=&#34;https://flecart.github.io/notes/markup&#34;&gt;Markup&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;√à un linguaggio &lt;strong&gt;indipendente&lt;/strong&gt; per la descrizione della grafica. La cosa bella √® iil fatto di essere indipendente, quindi √® adatto a HTML, a XML e simili.&lt;/p&gt;
&lt;p&gt;Una cosa particolare √® il &lt;strong&gt;cascading&lt;/strong&gt; quindi il fatto che dichiarazioni pi√π nuove sovrascrivano o espandino dichiarazione vecchie.&lt;/p&gt;</description>
    </item>
    <item>
      <title>HTML</title>
      <link>https://flecart.github.io/notes/html/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/html/</guid>
      <description>&lt;h2 id=&#34;un-p√≤-di-storia&#34;&gt;Un p√≤ di storia&lt;/h2&gt;
&lt;p&gt;√à importante capire un p√≤ di storia per vedere che strano robo abbiamo oggi.
Due linee di sviluppo, uno √® uno standard di W3C, l&amp;rsquo;altro √® il living standard. √à di fortissimo cambiamento, quindi di difficile definizione! (cambia significato sia di semantica e che di sintassi).&lt;/p&gt;
&lt;p&gt;Nel 1997 abbiamo HTML4 che √® stata considerata la versione finale, per cui un sacchissimo di siti web fino al 2008 sono stati implementato con questo HTML&lt;/p&gt;</description>
    </item>
    <item>
      <title>Grafi</title>
      <link>https://flecart.github.io/notes/grafi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/grafi/</guid>
      <description>&lt;h2 id=&#34;rappresentazione-e-terminologia&#34;&gt;Rappresentazione e terminologia&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Operazioni importanti&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Grafi/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Grafi/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;definizione-di-grafo&#34;&gt;Definizione di grafo&lt;/h3&gt;
&lt;p&gt;√à un insieme di nodi e di archi. (prendili da insiemi corretti)&lt;/p&gt;
&lt;h3 id=&#34;metodi-di-rappresentazione&#34;&gt;Metodi di rappresentazione&lt;/h3&gt;
&lt;h4 id=&#34;liste-di-incidenza&#34;&gt;Liste di incidenza&lt;/h4&gt;
&lt;p&gt;In pratica numero tutti gli archi e storo il valore dell&amp;rsquo;arco incidente per ogni nodo.
Diventa una tabella con una parte i nodi e l&amp;rsquo;altra gli archi. Avr√≤ dei valori -1 e 1 che marcano partenza e arrivo.
La cosa carina di questo metodo √® che pu√≤ essere generalizzata anche per Ipergrafi, in cui gli archi possono avere pi√π di una partenza o arrivo.
Solitamente √® memorizzato come una lista, quindi esattamente nodo partenza e arrivo per ogni edge.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Metadati web e web semantico</title>
      <link>https://flecart.github.io/notes/metadati-web-e-web-semantico/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/metadati-web-e-web-semantico/</guid>
      <description>&lt;h1 id=&#34;metadati-web&#34;&gt;Metadati web&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://csunibo.github.io/tecnologie-web/lucidi/teoria/23-metadati.pdf&#34;&gt;&lt;a href=&#34;https://csunibo.github.io/tecnologie-web/lucidi/teoria/23-metadati.pdf&#34;&gt;https://csunibo.github.io/tecnologie-web/lucidi/teoria/23-metadati.pdf&lt;/a&gt;&lt;/a&gt;
&lt;a href=&#34;https://csunibo.github.io/tecnologie-web/lucidi/teoria/24-a-web-semantico-lod-rdf-json-ld.pdf&#34;&gt;&lt;a href=&#34;https://csunibo.github.io/tecnologie-web/lucidi/teoria/24-a-web-semantico-lod-rdf-json-ld.pdf&#34;&gt;https://csunibo.github.io/tecnologie-web/lucidi/teoria/24-a-web-semantico-lod-rdf-json-ld.pdf&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;inconfrontabilit√†-del-sapere&#34;&gt;inconfrontabilit√† del sapere&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Stessa informazione in forme diverse&lt;/li&gt;
&lt;li&gt;Stessa parola per cose diversa.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;serializzazione&#34;&gt;Serializzazione&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Metadati web e web semantico/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Metadati web e web semantico/Untitled&#34;&gt;
&lt;p&gt;La semantica √® relegata alle &lt;strong&gt;applicazioni&lt;/strong&gt; che devono decidere in che modo interpretarli, oppure esseri umani.&lt;/p&gt;
&lt;h3 id=&#34;pics&#34;&gt;PICS&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Platform for Internet Content Selection&lt;/strong&gt; vuole cercare di tenere sotto controllo i materiali del film. √à un sistema di rating. ‚Üí &lt;strong&gt;tanti criteri di classificazione&lt;/strong&gt; a seconda dei criteri ideologici su cui voglio andare a basarmi.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fourier Series</title>
      <link>https://flecart.github.io/notes/fourier-series/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/fourier-series/</guid>
      <description>&lt;h2 id=&#34;intuition&#34;&gt;Intuition&lt;/h2&gt;
$$
\frac{1}{\sqrt{ 2\pi }}, \frac{\cos(kx)}{\sqrt{ \pi }}, \frac{\sin(kx)}{\sqrt{ \pi }}, \dots
$$$$
\int_{0}^{2\pi} (\sin (kx))^{2} \, dx  = \int_{0}^{2\pi} (\cos(kx))^{2} \, dx  = \pi
$$$$
\int_{0}^{2\pi}\sin(kx)\sin(hx) \, dx = \int_{0}^{2\pi}\cos(kx)\cos(hx) \, dx = 0
$$$$
\int_{0}^{2\pi}\sin(kx)\cos(hx) \, dx = \int_{0}^{2\pi} \sin(kx) \, dx = \int_{0}^{2\pi}\cos(hx) \, dx = 0   
$$&lt;h3 id=&#34;proofs-of-the-relations&#34;&gt;Proofs of the relations&lt;/h3&gt;
&lt;p&gt;In this section we quickly prove why the above equations hold.
First we all agree that $\int_{0}^{2\pi} \sin(kx) \, dx = \int_{0}^{2\pi} \cos(hx) \, dx = 0$ because their period divides $2\pi$ and the sum of the area of a period is clearly 0. Or we can explicitly find the primitive and solve&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cauchy-Schwarz Inequality</title>
      <link>https://flecart.github.io/notes/cauchy-schwarz-inequality/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cauchy-schwarz-inequality/</guid>
      <description>&lt;p&gt;This note briefly states and proves one of the most famous inequalities in geometry/analysis.&lt;/p&gt;
&lt;h3 id=&#34;theorem-statement&#34;&gt;Theorem Statement&lt;/h3&gt;
$$
\left( \sum_{i = 1}^{n} x_{i}y_{i} \right) ^{2} \leq \left( \sum_{i= 1}^{n} x^{2}_{i} \right)  \left( \sum_{i = 1}^{n} y^{2}_{i} \right)
$$$$
\lvert \langle u, v \rangle  \rvert ^{2} \leq \langle u, u \rangle  \cdot \langle v, v \rangle 
$$&lt;p&gt;
with $u = \left( x_{1}, \dots, x_{n} \right)$ and  $v = \left( y_{1}, \dots, y_{n} \right)$  and the $\langle \cdot, \cdot \rangle$ operator is the &lt;a href=&#34;https://flecart.github.io/notes/inner-product-spaces&#34;&gt;inner product&lt;/a&gt;.
We have equality if and only if $u$ and $v$ are linearly dependent (this one is easy to prove if seen from the vectorial view).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Na√Øve Bayes</title>
      <link>https://flecart.github.io/notes/na%C3%AFve-bayes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/na%C3%AFve-bayes/</guid>
      <description>&lt;h3 id=&#34;introduzione-a-na√Øve-bayes&#34;&gt;Introduzione a Na√Øve Bayes&lt;/h3&gt;
&lt;p&gt;NOTE: this note should be reviewed after the course I took in NLP. This is a very old note, not even well written.&lt;/p&gt;
&lt;p&gt;Bisognerebbe in primo momento avere benissimo in mente il significato di &lt;strong&gt;probabilit√† condizionata&lt;/strong&gt; e la regola di naive Bayes in seguito.&lt;/p&gt;
&lt;h4 id=&#34;bayes-ad-alto-livello-&#34;&gt;Bayes ad alto livello üü©&lt;/h4&gt;
&lt;p&gt;Da un punto di vista intuitivo non √® altro che predire la cosa che abbiamo &lt;strong&gt;visto pi√π spesso in quello spazio&lt;/strong&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Na√Øve Bayes-1696854772448.jpeg&#34; width=&#34;500&#34; class=&#34;center&#34; alt=&#34;Na√Øve Bayes-1696854772448&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Inverse Transform</title>
      <link>https://flecart.github.io/notes/inverse-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/inverse-transform/</guid>
      <description>&lt;p&gt;NOTE: this is an old set of note, and it is of quite bad quality, it should be completely rewritten.&lt;/p&gt;
$$
F(x) = \int _{-\infty}^{x} f(t) \, dt 
$$&lt;p&gt;
A volte la densit√† non √® definita, mentre la funzione cumulativa lo √® , per questo spesso cominciamo a definire partendo dalla definizione.&lt;/p&gt;
$$
F_{X}(x) = \mathbb{P}(X \leq x)
= \int_{-\infty}^{x} f_{X}(z) \, dz
$$&lt;h3 id=&#34;generalized-inverse&#34;&gt;Generalized inverse&lt;/h3&gt;
&lt;p&gt;This is known as the &lt;em&gt;universality of the uniform&lt;/em&gt;, every invertible CDF can be written with respect to the uniform distribution.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reinforcement Learning, a introduction</title>
      <link>https://flecart.github.io/notes/reinforcement-learning-a-introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/reinforcement-learning-a-introduction/</guid>
      <description>&lt;p&gt;The main difference between reinforcement learning and other machine learning, pattern inference methods is that reinforcement learning takes the concept of &lt;strong&gt;actions&lt;/strong&gt; into its core: models developed in this field can be actively developed to have an effect in its environment, while other methods are mainly used to summarize interesting data or generating sort of reports.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Reinforcement learning&lt;/strong&gt;¬†(&lt;strong&gt;RL&lt;/strong&gt;) is an interdisciplinary area of¬†&lt;a href=&#34;https://en.wikipedia.org/wiki/Machine_learning&#34;&gt;machine learning&lt;/a&gt;¬†and¬†&lt;a href=&#34;https://en.wikipedia.org/wiki/Optimal_control&#34;&gt;optimal control&lt;/a&gt;¬†concerned with how an¬†&lt;a href=&#34;https://en.wikipedia.org/wiki/Intelligent_agent&#34;&gt;intelligent agent&lt;/a&gt;¬†ought to take¬†&lt;a href=&#34;https://en.wikipedia.org/wiki/Action_selection&#34;&gt;actions&lt;/a&gt;¬†in a dynamic environment in order to maximize the¬†&lt;a href=&#34;https://en.wikipedia.org/wiki/Reward-based_selection&#34;&gt;cumulative reward&lt;/a&gt;. &lt;em&gt;~Wikipedia page&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Alberi di decisione</title>
      <link>https://flecart.github.io/notes/alberi-di-decisione/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/alberi-di-decisione/</guid>
      <description>&lt;h2 id=&#34;introduzione-agli-alberi-di-decisione&#34;&gt;Introduzione agli alberi di decisione&lt;/h2&gt;
&lt;h3 id=&#34;setting-del-problema--&#34;&gt;Setting del problema üü©-&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Alberi di decisione-1696950382366.jpeg&#34; width=&#34;576&#34; class=&#34;center&#34; alt=&#34;Alberi di decisione-1696950382366&#34;/&gt;
&lt;h3 id=&#34;spazio-delle-ipotesi&#34;&gt;Spazio delle ipotesi&lt;/h3&gt;
&lt;h4 id=&#34;definizione-spazio-ipotesi----&#34;&gt;Definizione spazio ipotesi üü©&amp;mdash;&lt;/h4&gt;
&lt;p&gt;Per spazio delle ipotesi andiamo a considerare l&amp;rsquo;insieme delle &lt;em&gt;funzioni rappresentabili dal nostro modello&lt;/em&gt;.
Questo implica che &lt;strong&gt;l&amp;rsquo;allenamento ricerca l&amp;rsquo;ipotesi&lt;/strong&gt; ossia la parametrizzazione &lt;em&gt;ottimale&lt;/em&gt; del nostro modello, ottimale in quanto &lt;em&gt;minimizza&lt;/em&gt; l&amp;rsquo;errore che viene compiuto nel training set.&lt;/p&gt;
&lt;p&gt;L&amp;rsquo;insieme iniziale si pu√≤ anche considerare come &lt;strong&gt;inductive bias&lt;/strong&gt; ossia il restringimento solamente a certe ipotesi e non tutte. Altrimenti abbiamo no free lunch.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Problemi di accoppiamento</title>
      <link>https://flecart.github.io/notes/problemi-di-accoppiamento/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/problemi-di-accoppiamento/</guid>
      <description>&lt;p&gt;I problem idi accoppiamento sono abbastanza comuni per ottimizzazione a grafi. In questa serie di note andiamo a trattare brevemente i problemi principali, con un accenno veloce ad alcuni algoritmi di soluzione per esse.&lt;/p&gt;
&lt;h3 id=&#34;grafo-bipartito&#34;&gt;Grafo bipartitoüü©&lt;/h3&gt;
&lt;p&gt;Un grafo bipartito √® un insieme $(O \cup D), (A)$ di nodi e di archi. Tutti i nodi sono o fra i nodi di origine oppure fra i nodi di destinazione, e gli archi sono solamente collegati fra nodi di origine e nodi di destinazione.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reti di flusso</title>
      <link>https://flecart.github.io/notes/reti-di-flusso/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/reti-di-flusso/</guid>
      <description>&lt;p&gt;Questi problemi sono una &lt;strong&gt;sottoclasse della programmazione lineare&lt;/strong&gt; con variabili reali. (Alcuni riescono a riconoscere se un problema √® in questa forma, e lo risolvono in modo istantaneo se questo succede).&lt;/p&gt;
&lt;p&gt;Un problema dei router √® un classico problema di flusso, che si risolvono con questi algoritmi polinomiali&lt;/p&gt;
&lt;h2 id=&#34;note-introduttive&#34;&gt;Note introduttive&lt;/h2&gt;
&lt;h3 id=&#34;rete-terminologia&#34;&gt;Rete, terminologia&lt;/h3&gt;
&lt;p&gt;In questo caso andiamo ad indicare con rete un grafo con $G = (N, A)$ con $N$ nodi e $A$ archi, che solitamente sono diretti con pesi associati.
Possiamo interpretare gli archi come &lt;strong&gt;canali&lt;/strong&gt; in cui fluiranno un qualcosa (ad esempio acqua in un tubo). Questi possono essere discreti o continui (mi sembra di ricordare che il discreto stranamente √® pi√π facile del continuo, non  so se vale anche in questo caso).
Abbiamo poi i &lt;em&gt;nodi&lt;/em&gt; che sono &lt;strong&gt;punti di ingresso e uscita&lt;/strong&gt; della nostra rete.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tarjan e MCMF</title>
      <link>https://flecart.github.io/notes/tarjan-e-mcmf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/tarjan-e-mcmf/</guid>
      <description>&lt;p&gt;Questa sezione la tengo separata rispetto agli altri per favorire lo studio, cos√¨ questa roba nuova la ripasso pi√π spesso, in seguito si pu√≤ accorpare.&lt;/p&gt;
&lt;h2 id=&#34;goldberg-tarjanpush-relabel&#34;&gt;Goldberg Tarjan/Push-relabel&lt;/h2&gt;
&lt;p&gt;Questo algoritmo √® importante perch√© introduce ragionamenti sul &lt;strong&gt;minimo locale&lt;/strong&gt; che possa alla fine essere ricomposto come soluzione globale.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0hI89H39USg&#34;&gt;Questa lezione youtube&lt;/a&gt; lo spiega da Dio&lt;/p&gt;
&lt;h3 id=&#34;preflusso-&#34;&gt;Preflusso üü©&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Tarjan e MCMF/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Tarjan e MCMF/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La parte nuova di questa cosa √® che i vincoli di bilanciamento possono diventare una disuguaglianza. (cio√® quello che arriva √® di pi√π rispetto quanto va fuori.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Asymptotic Equipartition Property</title>
      <link>https://flecart.github.io/notes/asymptotic-equipartition-property/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/asymptotic-equipartition-property/</guid>
      <description>&lt;p&gt;Sembra essere molto simile a &lt;a href=&#34;https://flecart.github.io/notes/central-limit-theorem-and-law-of-large-numbers&#34;&gt;Central Limit Theorem and Law of Large Numbers&lt;/a&gt; per√≤ per &lt;a href=&#34;https://flecart.github.io/notes/entropy&#34;&gt;Entropy&lt;/a&gt;.
This is also called &lt;strong&gt;Shannon&amp;rsquo;s source coding theorem&lt;/strong&gt; see &lt;a href=&#34;https://www.youtube.com/watch?v=0SxJl5G2bp0&amp;list=PLruBu5BI5n4aFpG32iMbdWoRVAA-Vcso6&amp;index=3&amp;ab_channel=JakobFoerster&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;enunciato-aep&#34;&gt;Enunciato AEP&lt;/h3&gt;
$$
-\frac{1}{n} \log p(X_{1}, X_{2}, \dots, X_{n}) \to H(X)
$$&lt;p&gt;
in probability (la definizione data in &lt;a href=&#34;https://flecart.github.io/notes/central-limit-theorem-and-law-of-large-numbers#convergence-in-probability&#34;&gt;Central Limit Theorem and Law of Large Numbers#Convergence in probability&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Un modo alternativo per enunciarla √® cos√¨, segue il metodo in (MacKay 2003).&lt;/p&gt;
$$
\left\lvert  \frac{1}{N} H_{\delta}(X^{N}) - H(x)  \right\rvert \leq \varepsilon
$$&lt;p&gt;Ossia a grandi linee: dato una variabile aleatoria $X$ e $N$ estrazioni della stessa, possiamo comprimere questa sequenza in $NH(X)$.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Integrali</title>
      <link>https://flecart.github.io/notes/integrali/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/integrali/</guid>
      <description>&lt;h2 id=&#34;81-introduzione&#34;&gt;8.1 Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;811-il-problema-che-risolve&#34;&gt;8.1.1 Il problema che risolve&lt;/h3&gt;
&lt;p&gt;Vogliamo cercare di creare un metodo matematico che sia utile per calcolare area di qualunque curva.&lt;/p&gt;
&lt;p&gt;L&amp;rsquo;idea principale per risolvere questo problema √® approssimare l&amp;rsquo;area, lo facciamo utilizzando rettangoli, la formalizzazione sar√† molto aiutata dal limite.&lt;/p&gt;
&lt;h3 id=&#34;812-sottografico-di-funzione&#34;&gt;8.1.2 Sottografico di funzione&lt;/h3&gt;
$$
A = \{ (x,y) \in \mathbb{R}^2 | x \in D(f(x)), 0\leq y \leq f(x)\}
$$&lt;p&gt;Praticamente sto prendendo tutti in punti positivi sotto al grafico.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Grammatiche Regolari</title>
      <link>https://flecart.github.io/notes/grammatiche-regolari/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/grammatiche-regolari/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;definizione-grammatica-regolare-&#34;&gt;Definizione grammatica regolare üü©&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Definizione&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Grammatiche Regolari/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Grammatiche Regolari/Untitled 1&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In pratica posso avere solamente come terminali a, oppure un suffisso a su un non terminale.&lt;/p&gt;
&lt;p&gt;Queste grammatiche sono interessanti perch√© √® molto facile costruire un automa che sia in grado di riconoscere questo linguaggio.&lt;/p&gt;
&lt;p&gt;Seguendo una definizione pi√π &lt;em&gt;lasca&lt;/em&gt; possono anche accettare dei nonterminali &lt;strong&gt;epsilon&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;espressione-regolare-a-nfa-&#34;&gt;Espressione regolare a NFA üü©&lt;/h3&gt;
&lt;p&gt;Questa sezione √® anche presente in &lt;a href=&#34;https://flecart.github.io/notes/automi-e-regexp&#34;&gt;Automi e Regexp&lt;/a&gt;, per√≤ √® riportata qui cos√¨ c‚Äô√® l‚Äôinsieme di tutte le cose in un unico posto.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hopital, Taylor, Peano</title>
      <link>https://flecart.github.io/notes/hopital-taylor-peano/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/hopital-taylor-peano/</guid>
      <description>&lt;h2 id=&#34;71-de-hopital&#34;&gt;7.1 De Hopital&lt;/h2&gt;
&lt;h3 id=&#34;711-lemmi-preliminari&#34;&gt;7.1.1 Lemmi preliminari&lt;/h3&gt;
&lt;p&gt;Questo lemma preliminare era gi√† presente per la prova del &lt;a href=&#34;https://flecart.github.io/notes/limiti#teorema-degli-zeri&#34;&gt;teorema degli zeri&lt;/a&gt;&lt;/p&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Hopital, Taylor, Peano/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Hopital, Taylor, Peano/Untitled&#34;&gt;
&lt;p&gt;Questo lemma √® molto interessante perch√© mette in relazione il finito (le successioni) con l&amp;rsquo;infinito (i reali)
In molte dimostrazioni si d√† per scontato questo lemma, ma √® una sottigliezza importante che giustifica l&amp;rsquo;utilizzo di successioni per limiti reali.
Ci permette di semplificare molto le dimostrazioni perch√© riusciamo a trattare le successioni molto meglio.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Accessibilit√†</title>
      <link>https://flecart.github.io/notes/accessibilit%C3%A0/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/accessibilit%C3%A0/</guid>
      <description>&lt;p&gt;Ci chiediamo come facciamo a rendere sistemi informatici accessibili a persone attraverso certe tecnologie.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide esempi di disabilit√†&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Accessibilit√†/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Accessibilit√†/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;√à meglio renderlo accessibile perch√© √® illegale (nel senso che stai facendo una discriminazione verso un certo insieme di persone).&lt;/p&gt;
&lt;h2 id=&#34;wgac&#34;&gt;WGAC&lt;/h2&gt;
&lt;p&gt;Queste sono alcuni principi di accessibilit√†, basati su 4 principi fondamentali&lt;/p&gt;
&lt;h3 id=&#34;4-principi-del-wgac&#34;&gt;4 principi del WGAC&lt;/h3&gt;
&lt;p&gt;POUR per facilit√† di ricordarsi&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Perceivable (che ci siano le informazioni necessarie per l&amp;rsquo;accessibilit√†)&lt;/li&gt;
&lt;li&gt;Operable&lt;/li&gt;
&lt;li&gt;Understandable&lt;/li&gt;
&lt;li&gt;Robus&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;linguaggio&#34;&gt;Linguaggio&lt;/h3&gt;
&lt;p&gt;Il tag del linguaggio √® utilizzato per sapere in che accento leggere e dare gli ordini.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ambienti di sviluppo</title>
      <link>https://flecart.github.io/notes/ambienti-di-sviluppo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/ambienti-di-sviluppo/</guid>
      <description>&lt;h1 id=&#34;ambienti-di-sviluppo&#34;&gt;Ambienti di sviluppo&lt;/h1&gt;
&lt;p&gt;Ambiente di sviluppo √® diverso rispetto all‚Äôambiente di deploy! bisognare fare delle differenze, sono dell macchine diverse, in questa sezione di documenti andiamo a parlare di norme e modi di lavorare per facilitare il metodo di sviluppo.&lt;/p&gt;
&lt;h2 id=&#34;note-di-compatibilit√†&#34;&gt;Note di compatibilit√†&lt;/h2&gt;
&lt;h3 id=&#34;front-end&#34;&gt;Front-end&lt;/h3&gt;
&lt;p&gt;Le compatibilit√†, soprattutto per cose browser (quindi front-end) cambiano molto spesso, come fare a trackare queste cose? C&amp;rsquo;√® un sito molto carino come &lt;a href=&#34;https://caniuse.com/&#34;&gt;&lt;a href=&#34;https://caniuse.com/&#34;&gt;https://caniuse.com/&lt;/a&gt;&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;La &lt;strong&gt;browser list&lt;/strong&gt;, √® utilizzata per specificare unt browser di target per la nostra applicazione, non ho capito bene cosa serve.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cookie e autenticazione</title>
      <link>https://flecart.github.io/notes/cookie-e-autenticazione/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cookie-e-autenticazione/</guid>
      <description>&lt;h1 id=&#34;cookies&#34;&gt;Cookies&lt;/h1&gt;
&lt;p&gt;Gli utilizzi pi√π soliti sono per Autenticazione e per  Autorizzazione, perch√© sono delle informazioni che il server genera e mette al client, come se fossero dei segreti cifrati.&lt;/p&gt;
&lt;h2 id=&#34;cookie&#34;&gt;Cookie&lt;/h2&gt;
&lt;p&gt;Questi sono una estensione di netscape, che si appoggiano al protocollo HTTP per implementare certe funzionalit√† (soprattutto il fatto di essere &lt;strong&gt;stateless&lt;/strong&gt;, quindi √® utile per avere informazioni sugli stati su qualcosa.)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide cookie&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Cookie e autenticazione/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Cookie e autenticazione/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Vengon utilizzati header specifici per settare il cookie.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Javascript</title>
      <link>https://flecart.github.io/notes/javascript/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/javascript/</guid>
      <description>&lt;h1 id=&#34;javascript&#34;&gt;Javascript&lt;/h1&gt;
&lt;p&gt;Obiettivo principale √® esegurie codice clientside&lt;/p&gt;
&lt;h2 id=&#34;un-p√≤-di-storia&#34;&gt;Un p√≤ di storia&lt;/h2&gt;
&lt;p&gt;nato all‚Äôinizio della prima guerra dei browser (da netscape, explorer √® in visual basic comunque non compatibile con JS) come il fratellino di java nel senso che runnava ovunque, attualmente √® ECMAScript, ed √® la versione migliore. (era pensato per fare microscript!)&lt;/p&gt;
&lt;p&gt;ECMAScript quando √® nato √® il nucleo a tutte le implementazioni JS eseistenti fino a quel momento (che √® stato molto caotico!)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Logistic Regression</title>
      <link>https://flecart.github.io/notes/logistic-regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/logistic-regression/</guid>
      <description>&lt;p&gt;Queste note sono molto di base. Per cose leggermente pi√π avanzate bisogna guardare &lt;a href=&#34;https://flecart.github.io/notes/bayesian-linear-regression&#34;&gt;Bayesian Linear Regression&lt;/a&gt;, &lt;a href=&#34;https://flecart.github.io/notes/linear-regression-methods&#34;&gt;Linear Regression methods&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;introduzione-alla-logistic-regression&#34;&gt;Introduzione alla logistic regression&lt;/h2&gt;
&lt;h3 id=&#34;giustificazione-del-metodo&#34;&gt;Giustificazione del metodo&lt;/h3&gt;
&lt;p&gt;Questo √® uno dei modelli classici, creati da &lt;strong&gt;Minsky&lt;/strong&gt; qualche decennio fa
In questo caso andiamo direttamente a computare il valore di $P(Y|X)$ durante l&amp;rsquo;inferenza, quindi si parla di modello &lt;strong&gt;discriminativo&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id=&#34;introduzione-al-problema&#34;&gt;Introduzione al problema&lt;/h4&gt;
&lt;p&gt;Supponiamo che&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Y$ siano variabili booleane&lt;/li&gt;
&lt;li&gt;$X_{i}$ siano variabili continue&lt;/li&gt;
&lt;li&gt;$X_{i}$ siano indipendenti uno dall&amp;rsquo;altro.&lt;/li&gt;
&lt;li&gt;$P(X_{i}| Y= k)$ sono modellate tramite distribuzioni gaussiane $\mathbb{N}(\mu_{ik}, \sigma_{i})$
&lt;ul&gt;
&lt;li&gt;NOTA! la varianza non dipende dalle feature!, questo mi permetterebbe di poi togliere la cosa quadratico dopo, rendendo poi l&amp;rsquo;approssimazione lineare&lt;/li&gt;
&lt;li&gt;Per esempio se utilizziamo nelle immagini, avrebbe senso normalizzare pixel by pixel, e non image wide con un unico valore, √® una assunzione, che se funziona dovrebbe poi far andare meglio la regressione logistica!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$Y$ √® una distribuzione bernoulliana.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ci chiediamo come √® fatto $P(Y|X)$?&lt;/p&gt;</description>
    </item>
    <item>
      <title>On intuitive notions of probability</title>
      <link>https://flecart.github.io/notes/on-intuitive-notions-of-probability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/on-intuitive-notions-of-probability/</guid>
      <description>&lt;p&gt;This note will mainly attempt to summarize the introduction of some intuitive notions of probability used in common sense human reasoning. Most of what is said here is available here &lt;a href=&#34;https://www.cambridge.org/core/books/probability-theory/9CA08E224FF30123304E6D8935CF1A99&#34;&gt;(Jaynes 2003)&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;three-intuitive-notions-of-probability&#34;&gt;Three intuitive notions of probability&lt;/h4&gt;
&lt;p&gt;Jaynes presents some forms of inference that are not possible in classical first order or propositional logic, yet they are frequent in human common sense reasoning.
Let&amp;rsquo;s present some rules and some examples along them:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Storia del web</title>
      <link>https://flecart.github.io/notes/storia-del-web/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/storia-del-web/</guid>
      <description>&lt;h2 id=&#34;guerre-dei-browser&#34;&gt;Guerre dei browser&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Prima guerra ~1995&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Fra netscape, una forma di rete (?) che poi viene ripresa da firefox da Mozilla, dopo che √® stato mandato in bancarotta da Microsoft (che ha ancora con IE una grandissima fetta del mercato in questo primo periodo).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Secondo periodo di guerra ~2010&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Quando arriva chrome, che vuole creare un browser che risolva tutti i problemi per creare integrazioni sui browser di altre aziende), mentre IE ha perso interesse per nuove features, che in questo periodo sono capi del proprio mercato.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bias Variance Trade-off</title>
      <link>https://flecart.github.io/notes/bias-variance-trade-off/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/bias-variance-trade-off/</guid>
      <description>&lt;p&gt;This note should be considered deprecated.
There is not much about Bias Variance Trade-off, and its quite random and old. For a correct derivation for this, you should consider looking at &lt;a href=&#34;https://flecart.github.io/notes/linear-regression-methods&#34;&gt;Linear Regression methods&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;√à una cosa ormai risaputa che c&amp;rsquo;√® una sorta di trade-off fra la varianza e il bias per una certo modello. Aumentare la varianza del modello certamente ci permetter√† di avere un modello che abbia un errore di training molto basso, per√≤ appena vede dei dati nuovi non sar√† in grado di generalizzare correttamente.
Dall&amp;rsquo;altra parte avere un bias alto significa avere un modello eccessivamente semplice, poco flessibile, che comunque allenato non riesce ad avere una grande accuratezza n√© in fase di allenamento, n√© di in fase di validazione o di test.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Algorithmic Probability</title>
      <link>https://flecart.github.io/notes/algorithmic-probability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/algorithmic-probability/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;Information theory must precede probability theory, and not be based on it. By the very essence of this discipline, the foundations of information theory have a finite combinatorial character.&amp;rdquo;&lt;/em&gt;  Kolmogorov, A. N. (1983).¬†&lt;a href=&#34;http://rainbow.ldeo.columbia.edu/~alexeyk/Papers/Kolmogorov1983.pdf&#34;&gt;Combinatorial foundations of information theory and the calculus of probabilities&lt;/a&gt;.&lt;br&gt;
&lt;em&gt;Russian mathematical surveys&lt;/em&gt;,¬†&lt;em&gt;38&lt;/em&gt;¬†(4), 29-40.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;it is clear that elements requiring an extremely large number of words for their definition should be considered as having an extremely low probability.&amp;rdquo;&lt;/em&gt; (Borel E.,¬†&lt;a href=&#34;https://link.springer.com/content/pdf/10.1007/BF03019651.pdf&#34;&gt;1909&lt;/a&gt;¬†p. 272).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Minimi quadrati</title>
      <link>https://flecart.github.io/notes/minimi-quadrati/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/minimi-quadrati/</guid>
      <description>&lt;h2 id=&#34;note-matematiche-introduttive&#34;&gt;Note matematiche introduttive&lt;/h2&gt;
&lt;h3 id=&#34;vettori-ortonormali-&#34;&gt;Vettori ortonormali üü©&lt;/h3&gt;
&lt;p&gt;Questa parte √® fatto molto meglio in &lt;a href=&#34;https://flecart.github.io/notes/inner-product-spaces&#34;&gt;Inner product spaces&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Due vettori si dicono ortonormali se $vv^T = ||v|| = 1$ e sono ortogonali, ossia $v_i v^T_j = 0$ con i e j diversi fra di loro&lt;/p&gt;
&lt;h3 id=&#34;matrici-ortogonale-4--&#34;&gt;Matrici ortogonale (4) üü©-&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Matrici si dicono ortonomali se le sue colonne sono vettori sono ortonormali&lt;/p&gt;&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Matrici ortonormali sono &lt;strong&gt;isometrie&lt;/strong&gt;, cio√® mantengono le distanze.&lt;/li&gt;
&lt;li&gt;Queste matrici sono tutte non singolari e quadrate per definizione&lt;/li&gt;
&lt;li&gt;La sua inversa √® ortogonale&lt;/li&gt;
&lt;li&gt;La sua inversa √® uguale alla trasposta&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;slide Propriet√† matrice ortonormale&lt;/p&gt;</description>
    </item>
    <item>
      <title>Singular Value Decomposition</title>
      <link>https://flecart.github.io/notes/singular-value-decomposition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/singular-value-decomposition/</guid>
      <description>&lt;p&gt;Next time, use &lt;a href=&#34;https://rich-d-wilkinson.github.io/MATH3030/3.3-linalg-SVD.html&#34;&gt;this&lt;/a&gt; resource.&lt;/p&gt;
&lt;p&gt;Di solito √® utilizzata per &lt;strong&gt;ridurre lo spazio utilizzato&lt;/strong&gt; trattenendo la maggiore quantit√† di informazione possibile, utilizzata spesso in Principal Component Analys&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Enunciato SVD slide&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 5.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Minimi quadrati/Untitled 5&#34;&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Immagine esplicativa&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 6.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Minimi quadrati/Untitled 6&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Questo √® qualcosa che si pu√≤ applicare a &lt;strong&gt;qualunque matrice&lt;/strong&gt;. Sono di particolare interesse le matrici con numero di colonne maggiore del numero di righe.1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide vecchia&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 7.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Minimi quadrati/Untitled 7&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;relazione-valori-singolari-con-aat--&#34;&gt;Relazione valori singolari con AAt üü©-&lt;/h3&gt;
&lt;p&gt;Con k ho il numero di numeri non zero che sono il &lt;strong&gt;rango della matrice&lt;/strong&gt;. Questa matrice √® particolare, la chiamiamo gramiano ed √® sempre definita positiva.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Descrizione linguaggio</title>
      <link>https://flecart.github.io/notes/descrizione-linguaggio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/descrizione-linguaggio/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;Per questa parte c‚Äô√® un sacco di roba in comune con &lt;a href=&#34;https://flecart.github.io/notes/tecniche-di-definizione-di-semantica-(4&#34;&gt;Tecniche di definizione di semantica (4) üü©&lt;/a&gt;-üü©)&lt;/p&gt;
&lt;p&gt;Trattiamo alcune caratteristiche che descrivono ad alto livello un linguaggio di programmazione. √à da notare che questa parte della spiegazione del linguaggio non √® limitante al solo linguaggio di programmazione, √® utile per analizzare tutti i linguaggi (tranne la parte di implementazione)&lt;/p&gt;
&lt;h3 id=&#34;sintassi--&#34;&gt;Sintassi üü©-&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Relazione fra segni&lt;/em&gt;. si occupa di decidere quando una frase √® corretta.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to databases</title>
      <link>https://flecart.github.io/notes/introduction-to-databases/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-databases/</guid>
      <description>&lt;h2 id=&#34;basi-di-dati&#34;&gt;Basi di dati&lt;/h2&gt;
&lt;h3 id=&#34;cosa-√®-un-database-2-&#34;&gt;Cosa √® un database? (2) üü©&lt;/h3&gt;
&lt;p&gt;Si potrebbe intendere come un &lt;strong&gt;insieme&lt;/strong&gt; di dati &lt;strong&gt;strutturato&lt;/strong&gt;, &lt;em&gt;utili&lt;/em&gt; per certi obiettivi di enterprise, aziende pubbliche o simili (uno delle necessit√† che la rivoluzione informatica ha pi√π contribuito diciamo.)&lt;/p&gt;
&lt;p&gt;Un altro significato pi√π importante √®&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Un insieme di dati gestito da un Database Management System&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Tristemente con questa definizione anche excel √® un DBMS&amp;hellip;&lt;/p&gt;
&lt;p&gt;Solitamente sono utilizzati per gestire &lt;strong&gt;grandi quantit√† di dati&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Relational Model</title>
      <link>https://flecart.github.io/notes/relational-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/relational-model/</guid>
      <description>&lt;p&gt;This is the classical format that we encounter, it is the format used for relational databases introduced in &lt;a href=&#34;https://flecart.github.io/notes/introduction-to-databases&#34;&gt;databases course introduction&lt;/a&gt;, introduced in &lt;a href=&#34;https://dl.acm.org/doi/10.1145/362384.362685&#34;&gt;(Codd 1970)&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;introduzione-i-modelli-di-dati&#34;&gt;Introduzione, i modelli di dati&lt;/h3&gt;
&lt;h4 id=&#34;lista-modelli-di-dati-4&#34;&gt;Lista modelli di dati (4)&lt;/h4&gt;
&lt;p&gt;Nel tempo sono stati sviluppati molti modelli di dati:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Relational Data Model:&lt;/strong&gt; This is the most common data model and uses tables to represent data. It organizes data into rows and columns, where each row represents a record, and each column represents an attribute of that record. Relationships between data are established through keys.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Programmazione lineare</title>
      <link>https://flecart.github.io/notes/programmazione-lineare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/programmazione-lineare/</guid>
      <description>&lt;p&gt;Vogliamo cercare di restare nel nostro spazio delle soluzioni ammissibili, senza dover stare ad esplorare tutto, vogliamo andare a concentrarci su una parte specifica di essa. Vogliamo utilizzare una struttura fondamentale per i problemi di programmazione lineare, che √® quello con cui vogliamo andare a fare. Il fatto √® che spostandoci leggermente da un punto tra le soluzioni, possiamo gestire in modo molto semplice il modo con cui si sposta la retta dei valori.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Norme e Condizionamento</title>
      <link>https://flecart.github.io/notes/norme-e-condizionamento/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/norme-e-condizionamento/</guid>
      <description>&lt;h1 id=&#34;errore-inerente&#34;&gt;Errore inerente&lt;/h1&gt;
&lt;p&gt;Bisogna cercare di generalizzare il concetto di errore e lo si fa con la norma&lt;/p&gt;
&lt;h2 id=&#34;norma-vettoriale&#34;&gt;Norma vettoriale&lt;/h2&gt;
&lt;p&gt;√à una funzione da $f: \mathbb{R}^n \to \mathbb{R}$ indicata con due barrette, questa funzione mi d√† un concetto di distanza.&lt;/p&gt;
&lt;h3 id=&#34;propriet√†-della-norma&#34;&gt;Propriet√† della norma&lt;/h3&gt;
&lt;p&gt;Si definisce una norma una funzione che soddisfa queste propriet√†&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$\lVert x \rVert \geq 0$ per ogni $x \in \mathbb{R}^{n}$&lt;/li&gt;
&lt;li&gt;$\lVert x \rVert = 0 \iff x = 0$&lt;/li&gt;
&lt;li&gt;$\lVert \alpha x \rVert = \lvert \alpha \rvert \lVert x \rVert$ per ogni $x \in \mathbb{R}^{n}$ e $\alpha \in \mathbb{R}$&lt;/li&gt;
&lt;li&gt;Vale la disuguaglianza triangolare, ossia $\forall x, y \in \mathbb{R}^{n}, \lVert x + y \rVert \leq \lVert x \rVert + \lVert y \rVert$.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;convessit√†&#34;&gt;Convessit√†&lt;/h3&gt;
&lt;p&gt;Analizzato meglio in &lt;a href=&#34;https://flecart.github.io/notes/analisi-di-convessit√†&#34;&gt;Analisi di Convessit√†&lt;/a&gt;.
Si pu√≤ dimostrare tramite la propriet√† 3 e 4 che la norma √® una funzione convessa.
Infatti sia $f$ la funzione che soddisfa le propriet√† della norma (quindi effettivamente si pu√≤ chiamare norma). Allora:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tecniche algoritmiche</title>
      <link>https://flecart.github.io/notes/tecniche-algoritmiche/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/tecniche-algoritmiche/</guid>
      <description>&lt;p&gt;In questa nota andiamo a parlare in modo sommario (si impara probabilmente molto meglio con la pratica) di generali tipologie di approcci che esistono per affrontare problemi di tipo algoritmico.&lt;/p&gt;
&lt;h2 id=&#34;divide-et-impera&#34;&gt;Divide et impera&lt;/h2&gt;
&lt;h3 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h3&gt;
&lt;p&gt;Abbiamo gi√† visto L&amp;rsquo;utilizzo di questa tecnica per quick e merge sort in &lt;a href=&#34;https://flecart.github.io/notes/algoritmi-di-ordinamento&#34;&gt;Algoritmi di ordinamento&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Questa tecnica si focalizza in tre passi fondamentali:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Dividere il problema in sotto-problemi&lt;/li&gt;
&lt;li&gt;Risolvere il sotto-problema&lt;/li&gt;
&lt;li&gt;Mergiare le soluzioni di questi sotto-problemi.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Questa √® pi√π una tecnica che si impara di pi√π con la pratica, andremo a fare un problema che utilizza questa tecnica&lt;/p&gt;</description>
    </item>
    <item>
      <title>Advanced SQL</title>
      <link>https://flecart.github.io/notes/advanced-sql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/advanced-sql/</guid>
      <description>&lt;h3 id=&#34;check-function&#34;&gt;Check function&lt;/h3&gt;
&lt;p&gt;A volte pu√≤ essere molto pesante, perch√©&lt;/p&gt;
&lt;h4 id=&#34;what-does-check-do&#34;&gt;What does check do?&lt;/h4&gt;
&lt;p&gt;Viene utilizzato per introdurre un &lt;strong&gt;constraint&lt;/strong&gt; check per avere sicurezza su un range.
&lt;img src=&#34;https://flecart.github.io/images/notes/Structured Query Language-1697711487638.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Structured Query Language-1697711487638&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;check-e-innestamenti--&#34;&gt;Check e innestamenti üü©-&lt;/h4&gt;
&lt;p&gt;Pu√≤ essere che certe implementazioni non permettano il check innestato, questo √® una cosa molto pesante, perch√© ogni modifica deve andare a &lt;strong&gt;rifare la modifica ai subalterni&lt;/strong&gt;, quindi questo √® pesante pesante.&lt;/p&gt;
&lt;h4 id=&#34;assertions---&#34;&gt;Assertions üü©&amp;ndash;&lt;/h4&gt;
&lt;p&gt;Sono dei &lt;strong&gt;check&lt;/strong&gt; fatti al &lt;strong&gt;livello dello schema&lt;/strong&gt;, quindi valgono sempre, e possono essere riutilizzati in table diversi credo.
Un altro aspetto √® che √® &lt;strong&gt;database wide&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Variabili aleatorie</title>
      <link>https://flecart.github.io/notes/variabili-aleatorie/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/variabili-aleatorie/</guid>
      <description>&lt;p&gt;Le variabili aleatorie ci permettono di dire qualcosa sullo spazio di probabilit√† senza andare troppo nei dettagli a considerare singoli eventi e cose simili.&lt;/p&gt;
&lt;h2 id=&#34;variabili-aleatorie-discrete&#34;&gt;Variabili aleatorie discrete&lt;/h2&gt;
&lt;p&gt;Con le variabili aleatorie cominciamo ad entrare nel noccio della questione, finalmente possiamo in un certo senso legare l‚Äôoutcome di un evento, alla probabilit√† dell‚Äôevento.&lt;/p&gt;
&lt;h3 id=&#34;definizione-variabili-aleatorie-&#34;&gt;Definizione Variabili aleatorie üü©&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Si definisce variabile aleatoria $X$ una funzione da $\Omega \to E$, con $\Omega$ il nostro spazio campionario, e $E$ qualunque insieme (quando $E = \mathbb{R}$ si parla di &lt;strong&gt;variabile aleatoria reale&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Information Theory</title>
      <link>https://flecart.github.io/notes/introduction-to-information-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-information-theory/</guid>
      <description>&lt;p&gt;The course will be more about the the quantization, talking about lossless and lossy compression (how many bits will be needed to describe something? This is not a CS course so it will not be so much algorithmically focused course), then we will talk about channel and capacity and DMC things.
Most of the things explained in the Lapidoth course will be theoretical there will be some heavy maths.&lt;/p&gt;
&lt;p&gt;The professor starts with some mathy definitions (not very important, just that the $\mathbb{E}[ \cdot]$ needs a domain to be defined, so notations like $\mathbb{E}[x]$ do not make sense, while $\mathbb{E}[g(x)]$ do make sense because $g(x) : \mathcal{X} \to \mathbb{R}$).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Expressiveness of NN</title>
      <link>https://flecart.github.io/notes/expressiveness-of-nn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/expressiveness-of-nn/</guid>
      <description>&lt;h2 id=&#34;the-perceptron&#34;&gt;The perceptron&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide summary of working of perceptron&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Expressiveness of NN/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Expressiveness of NN/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note on the bias&lt;/strong&gt;: it is only useful to move the treshhold where to consider the output to be 1 and where to be 1.&lt;/p&gt;
&lt;p&gt;Now we ask what can be predicted by a perceptron?&lt;/p&gt;
&lt;p&gt;We can see the update rule of the perceptron:&lt;/p&gt;
$$
\begin{cases}
w = w + \alpha x  \\
b = b + \alpha
\end{cases}
$$$$
\alpha = \begin{cases}
0  &amp;  \Theta(x \theta + b) = y \\
-1  &amp;  \Theta(x \theta + b) &gt; y \\
1  &amp;  \Theta(x \theta + b) &lt; y 
\end{cases}
$$&lt;h4 id=&#34;linearly-separability-necessity&#34;&gt;Linearly separability necessity&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Hyperplanes&lt;/strong&gt;, because that equation is an hyperplane, so we are sure that we can predict an hyperplane, and that it, and it‚Äôs only it. (it‚Äôs predicting wheter it can be above or below that line).
So the perceptron is correct &lt;strong&gt;only if the data is linearly separable&lt;/strong&gt;!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Connettivi Logici, correttezza, variabili</title>
      <link>https://flecart.github.io/notes/connettivi-logici-correttezza-variabili/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/connettivi-logici-correttezza-variabili/</guid>
      <description>&lt;h2 id=&#34;81-dimostrazione-teorema-invarianza&#34;&gt;8.1 Dimostrazione teorema invarianza&lt;/h2&gt;
&lt;h3 id=&#34;811-introduzione&#34;&gt;8.1.1 Introduzione&lt;/h3&gt;
&lt;p&gt;Basi: Due proposizioni sono equivalenti quando valgono sugli stessi mondi.&lt;/p&gt;
&lt;p&gt;quindi $\forall v, \llbracket F \rrbracket ^v \equiv \llbracket G \rrbracket ^ v$.&lt;/p&gt;
&lt;p&gt;Vogliamo dire che dati un buco presente in una proposizione, queste valgono sempre, sono in effetti equivalenti. Il buco la prendo come una variabile proposizionale.  (riempire = rimpiazzare il buco)&lt;/p&gt;
&lt;h3 id=&#34;812-operazione-di-sostituzione&#34;&gt;8.1.2 Operazione di sostituzione&lt;/h3&gt;
&lt;p&gt;Si pu√≤ notare che ci sono 4 casi base, mentre le altre 4 sono per ricorsione strutturale.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Metric Spaces</title>
      <link>https://flecart.github.io/notes/metric-spaces/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/metric-spaces/</guid>
      <description>&lt;p&gt;There is a close relationship between topologies and metric spaces. We will see that every metric space directly induces a topology based on its metric. (from a CS point of view, this means topologies are more general than metric spaces).&lt;/p&gt;
&lt;h3 id=&#34;definition-of-metric-space&#34;&gt;Definition of Metric Space&lt;/h3&gt;
&lt;p&gt;üü©
We say that  $(\mathcal{X}, d)$ is a metric space if $\mathcal{X}$ is a set and $d$ a function $\mathcal{X} \times \mathcal{X} \to \mathbb{R}$ such that:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Time and Space Complexity</title>
      <link>https://flecart.github.io/notes/time-and-space-complexity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/time-and-space-complexity/</guid>
      <description>&lt;p&gt;In this note we explore a theme of time and space complexity. Those are cardinal themes in Theoretical CS.
Time -&amp;gt; execution step bounds on algorithms
Space -&amp;gt; the cells visited by a &lt;a href=&#34;https://flecart.github.io/notes/la-macchina-di-turing&#34;&gt;Turing Machine&lt;/a&gt; when executed.&lt;/p&gt;
&lt;h2 id=&#34;introduction-to-time-complexity&#34;&gt;Introduction to Time Complexity&lt;/h2&gt;
&lt;p&gt;This note will build upon know techniques of algorithms analysis explained in &lt;a href=&#34;https://flecart.github.io/notes/notazione-asintotica&#34;&gt;Notazione Asintotica&lt;/a&gt;.
We will need big-$O$ notation and $o$ notation.
L&amp;rsquo;idea √® che il problema di decisione √® decidibile se limito la lunghezza del teorema.
Simile al &lt;a href=&#34;https://en.wikipedia.org/wiki/Chaitin%27s_constant&#34;&gt;numero di Chaitin&lt;/a&gt;, che non √® computabile, ma √® approssimabile quanto si vuole. In un certo senso √® computabile.
The general idea is to ask how the function $\varphi$ that maps the longest $n$ proof to the number of steps of computation behaves.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Topological Spaces</title>
      <link>https://flecart.github.io/notes/topological-spaces/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/topological-spaces/</guid>
      <description>&lt;h4 id=&#34;introduction-to-topological-spaces&#34;&gt;Introduction to topological spaces&lt;/h4&gt;
&lt;p&gt;We want now to extend the idea of continuity presented in &lt;a href=&#34;https://flecart.github.io/notes/limiti#funzione-continua&#34;&gt;limits&lt;/a&gt;, which is a function $f : E^{n} \to E^{n}$ is continuous if given $x$ then $\forall\varepsilon &gt; 0$ $\exists \delta$ such that $\forall y : \lVert y -x \rVert &lt; \delta \implies \lVert f(y) - f(x) \rVert &lt; \varepsilon$.
But we want to get rid of the idea of distance, and base our definition on the idea of neighborhoods, which in $E^{n}$ are just spherical radius centered around a point.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to statistical learning</title>
      <link>https://flecart.github.io/notes/introduction-to-statistical-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-statistical-learning/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;This is a short introduction to statistical learning, made with the help of the book &lt;a href=&#34;https://link.springer.com/10.1007/978-3-031-38747-0&#34;&gt;(James et al. 2023)&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;statistical learning refers to a set of approaches for estimating $f$ .&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;utilizzi-del-statistical-learning&#34;&gt;Utilizzi del statistical learning&lt;/h3&gt;
&lt;p&gt;Solitamente sono due gli utilizzi &lt;strong&gt;Predizione&lt;/strong&gt; e &lt;strong&gt;inferenza&lt;/strong&gt;. Per predizione intendiamo il miglior modello che possa produrre le Y che ancora non conosciamo.
Per inferenza significa il miglior modello f per predire Y che conosciamo.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Integrali multi-dimensionali</title>
      <link>https://flecart.github.io/notes/integrali-multi-dimensionali/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/integrali-multi-dimensionali/</guid>
      <description>&lt;p&gt;Andremo ad analizzare integrali di funzioni continue su &lt;strong&gt;insiemi semplici (domini normali&lt;/strong&gt;) .&lt;/p&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;y-semplice-e-regolarit√†&#34;&gt;&lt;strong&gt;Y-semplice e regolarit√†&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;√à un insieme semplice di punti, in pratica, se considero un intervallo limitato e due funzioni definite in questo intervallo tale che una √® sempre minore dell‚Äôaltra, l‚Äôinsieme y-semplice sono i punti compresi fra queste&lt;/p&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Integrali multi-dimensionali/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Integrali multi-dimensionali/Untitled&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Definizione del libro
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Integrali multi-dimensionali/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Integrali multi-dimensionali/Untitled 1&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;intuizione-integrale&#34;&gt;Intuizione integrale&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Definizione del prof.
Dato un insieme semplice A e una funzione continua $f:A \to R$ allora √® ben definito l‚Äôintegrale
$$
    \int_Af(x, y) dxdy \in R
    $$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Osservazione 1:&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Topology</title>
      <link>https://flecart.github.io/notes/introduction-to-topology/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-topology/</guid>
      <description>&lt;p&gt;This small note is an introduction to Topology that follows the introductory arguments of (Armstrong 2013).&lt;/p&gt;
&lt;h2 id=&#34;eulers-theorem&#34;&gt;Euler&amp;rsquo;s Theorem&lt;/h2&gt;
&lt;p&gt;We will start our journey in topology following a classical example in the history of Mathematics the relation:&lt;/p&gt;
$$
v - e + f = 2
$$&lt;p&gt;
Valid for classical Polyhedrons.&lt;/p&gt;
&lt;h3 id=&#34;basic-definitions&#34;&gt;Basic definitions&lt;/h3&gt;
&lt;h4 id=&#34;polyhedron&#34;&gt;Polyhedron&lt;/h4&gt;
&lt;p&gt;It&amp;rsquo;s a collection of &lt;em&gt;plane polygons&lt;/em&gt; (see &lt;a href=&#34;https://flecart.github.io/notes/programmazione-lineare#poliedro&#34;&gt;Programmazione lineare#Poliedro&lt;/a&gt;) such that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Every polygon shares each of its edges with exactly another polygon&lt;/li&gt;
&lt;li&gt;We have vertexes that can be shared by many polygons.
Informally we have a &lt;strong&gt;piece of surface&lt;/strong&gt; with a vertex.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;theorem-statement&#34;&gt;Theorem statement&lt;/h3&gt;
&lt;p&gt;If we have a Polygon $P$ such that&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vapnik-Chervonenkis Dimension</title>
      <link>https://flecart.github.io/notes/vapnik-chervonenkis-dimension/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/vapnik-chervonenkis-dimension/</guid>
      <description>&lt;p&gt;This note will introduce the ideas presented by Vapnik, presented in &lt;a href=&#34;https://books.google.ch/books?id=ttJkAwAAQBAJ&#34;&gt;(Shalev-Shwartz &amp;amp; Ben-David 2014)&lt;/a&gt; chapter 6. Briefly this says that infinite-size classes are indeed learnable.&lt;/p&gt;
&lt;p&gt;This set of note is still a work in progress. But it&amp;rsquo;s very important for statistical learning theory.&lt;/p&gt;
&lt;p&gt;We have that if $\lvert  \mathcal{H} \rvert &lt; \infty \implies vc(\mathcal{H} \rvert) \leq \log_{2} \lvert \mathcal{H}$
Example: if $\mathcal{H}$ is the set of linear classifiers on $\mathbb{R}^{d}$ then we have that the dimension is $d + 1$.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Alberi BST e AVL</title>
      <link>https://flecart.github.io/notes/alberi-bst-e-avl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/alberi-bst-e-avl/</guid>
      <description>&lt;h1 id=&#34;alberi-bst-e-avl&#34;&gt;Alberi BST e AVL&lt;/h1&gt;
&lt;h2 id=&#34;41-alberi-binari-di-ricerca-bst&#34;&gt;4.1 Alberi binari di ricerca (BST)&lt;/h2&gt;
&lt;p&gt;Queste sono delle varianti rispetto all&amp;rsquo;albero, descritto in modo molto sommario sopra (binario perch√© ogni nodo ha al massimo due figli, mentre l&amp;rsquo;albero pu√≤ averne quanti se ne vuole).&lt;/p&gt;
&lt;h3 id=&#34;411-introduzione&#34;&gt;4.1.1 Introduzione&lt;/h3&gt;
&lt;p&gt;La caratteristica principale dell&amp;rsquo;albero di ricerca √® una condizione sulle chiavi (che hanno i figli).&lt;/p&gt;
&lt;p&gt;Infatti questo albero binario di ricerca si pu√≤ vedere come una implementazione della struttura astratta del dizionario. (che ricordiamo, √® un struttura in cui a ogni nodo sono presenti due valori, una chiave (tute differenti) e un dato, e sono definite tre operazioni principali, possiamo vederla come interfaccia).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Algebra Logica</title>
      <link>https://flecart.github.io/notes/algebra-logica/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/algebra-logica/</guid>
      <description>&lt;h1 id=&#34;strutture-algebriche&#34;&gt;Strutture algebriche&lt;/h1&gt;
&lt;h2 id=&#34;differenza-matematica-e-informatica&#34;&gt;Differenza matematica e informatica&lt;/h2&gt;
&lt;p&gt;Una osservazione per quanto riguarda la logica intuizionista √® che sta a met√† fra matematica e informatica perch√© la &lt;em&gt;dimostrazione intuizionista possiede in s√© un algoritmo e una struttura di dati.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Infatti di solito l&amp;rsquo;informatico scrive senza fare la dimostrazione dell&amp;rsquo;algoritmo mentre il matematico scrive la dimostrazione senza fare l&amp;rsquo;algoritmo (inoltre pu√≤ definire degli enti ed oggetti che non siano rappresentabili come dati in quanto possono essere infiniti.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Algoritmi di ordinamento</title>
      <link>https://flecart.github.io/notes/algoritmi-di-ordinamento/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/algoritmi-di-ordinamento/</guid>
      <description>&lt;h2 id=&#34;61-introduzione&#34;&gt;6.1 Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;611-limportanza-del-topic&#34;&gt;6.1.1 L‚Äôimportanza del topic&lt;/h3&gt;
&lt;p&gt;Gli algoritmi di ordinamento sono molto di base per la comprensione dell&amp;rsquo;ampio raggio degli algoritmi. Utilizzano l&amp;rsquo;analisi, introducono tecniche di risoluzione dei problemi computazionali come greedy, divide et impera e simile. Permettono un primo uso di astrazioni e l&amp;rsquo;analisi di sottoproblemi.&lt;/p&gt;
&lt;h3 id=&#34;612-il-problema&#34;&gt;6.1.2 Il problema&lt;/h3&gt;
&lt;p&gt;Il problema √® trovare una permutazione di un insieme di numeri iniziali tale per cui tale insieme di numeri si ordinato:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Antenne</title>
      <link>https://flecart.github.io/notes/antenne/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/antenne/</guid>
      <description>&lt;h2 id=&#34;omnidirezionali&#34;&gt;Omnidirezionali&lt;/h2&gt;
&lt;h3 id=&#34;antenne-omnidirezionali-&#34;&gt;Antenne omnidirezionali üü©&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slides antenne omnidirezionali&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Antenne/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Antenne/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Il senso di omnidirezionale √® in tutte le direzioni dell&amp;rsquo;antenna (nota: non √® isotropico, perch√© non √® da un singolo punto).&lt;/p&gt;
&lt;p&gt;in passato era importante andare a guardare la direzione per trovare la polarizzazione migliore. Praticamente irradia a 360 gradi sul piano permedicolare all‚Äôantenna.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Esempio pattern di radiazione&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Antenne/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Antenne/Untitled 1&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Questo genere di antenne sono &lt;strong&gt;irrealizzabili&lt;/strong&gt; la pi√π simile √® la antenna dipolo dipolo, ma comunque non rispetta le antenne in questo verso diciamo. ricorda i dBi che abbiamo citato in &lt;a href=&#34;https://flecart.github.io/notes/fisica-del-wireless&#34;&gt;Fisica del Wireless&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Architettura e livelli 1, 2</title>
      <link>https://flecart.github.io/notes/architettura-e-livelli-1-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/architettura-e-livelli-1-2/</guid>
      <description>&lt;h3 id=&#34;perch√©-a-stack--&#34;&gt;Perch√© a stack üü©-&lt;/h3&gt;
&lt;p&gt;Capire l‚Äôarchitettura significa capire la struttura (l‚Äôorganizzazione) del nostro app e comprenderne i motivi (i sottoproblemi risolti) che ogni livello prova a risolvere&lt;/p&gt;
&lt;p&gt;La soluzione che √® stata individuata, e ha rappresentato uno dei principali cardini del successo delle reti e della nascita di Internet, √® data dalla separazione delle classi di protocolli in livelli. La struttura dei livelli dei protocolli di rete prende il nome di architettura dei protocolli di rete.
Il concetto di architettura dei protocolli, suddivisa in livelli, √® semplice ed √® basato su alcune condizioni.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Asymmetric Cryptography</title>
      <link>https://flecart.github.io/notes/asymmetric-cryptography/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/asymmetric-cryptography/</guid>
      <description>&lt;h2 id=&#34;public-key-encryption&#34;&gt;Public Key Encryption&lt;/h2&gt;
&lt;p&gt;We now define a formally what is a  public key encryption&lt;/p&gt;
&lt;h3 id=&#34;formal-definition-of-public-key-encryption&#34;&gt;Formal definition of Public Key Encryption&lt;/h3&gt;
&lt;p&gt;We define a 3-tuple formed as follows: $(G, E, D)$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$G$ is the generator for the private and public keys, from now on identified as $(pk, sk)$ (public key and secret key)&lt;/li&gt;
&lt;li&gt;$E(pk, m)$ the encryption algorithm, that takes the $pk$ and the message in input&lt;/li&gt;
&lt;li&gt;$D(sk, c)$ the decryption algorithm, that takes the $sk$ and the ciphertext in input.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now is this definition useful? i don&amp;rsquo;t think so! We can&amp;rsquo;t create theorems for it, too general I suppose. Is it clear? yes! I think this is the usefulness of maths in many occasions, it delivers some complex information in a concise and understandable manner.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Block Ciphers</title>
      <link>https://flecart.github.io/notes/block-ciphers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/block-ciphers/</guid>
      <description>&lt;p&gt;Utilizzano blocchi per cifra invece che stream generators. $n$ bits in input and $m$ bits in output generally a key is &lt;strong&gt;expanded&lt;/strong&gt; into multiple keys, one for each rounds, and applied to a &lt;em&gt;round function&lt;/em&gt; that iterates on the $m$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DES 56 bit&lt;/li&gt;
&lt;li&gt;3DES 56*3 bit di chiave&lt;/li&gt;
&lt;li&gt;AES che pu√≤ andare a 128, 196 o 256
Solitamente i stream ciphers studiati in &lt;a href=&#34;https://flecart.github.io/notes/otp-and-stream-ciphers&#34;&gt;OTP and Stream Ciphers&lt;/a&gt; sono pi√π veloci.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Cipher&lt;/th&gt;
          &lt;th&gt;Speed MB/sec&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;RC4&lt;/td&gt;
          &lt;td&gt;126&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Salsa20&lt;/td&gt;
          &lt;td&gt;643&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Sosemanuk&lt;/td&gt;
          &lt;td&gt;727&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;AES&lt;/td&gt;
          &lt;td&gt;13&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;3DES&lt;/td&gt;
          &lt;td&gt;109&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;data-encryption-standard&#34;&gt;Data Encryption Standard&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Block Ciphers-20240525101348320.webp&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Block Ciphers-20240525101348320&#34;&gt;
- 1974 da IBM su commissione di NSA (Horst Feistel designed Lucifer at IBM in early 1970)
- 1976 DES is federal standard with key-len 56 bits and block-len 64 bits.
&lt;p&gt;in quel periodo era solamente fatta dalla intelligence, non c‚Äôera bisogno di comunicazioni per il pubblico in quel periodo.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cammini</title>
      <link>https://flecart.github.io/notes/cammini/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cammini/</guid>
      <description>&lt;h2 id=&#34;11-il-cammino-minimo&#34;&gt;1.1 Il cammino minimo&lt;/h2&gt;
&lt;h3 id=&#34;111-definizione-e-caratteristiche&#34;&gt;1.1.1 Definizione e caratteristiche&lt;/h3&gt;
&lt;h3 id=&#34;112-costi-negativi&#34;&gt;1.1.2 Costi negativi&lt;/h3&gt;
&lt;p&gt;Sono cose molto brutte&lt;/p&gt;
&lt;h3 id=&#34;113-cammino-minimo-semplice&#34;&gt;1.1.3 Cammino minimo semplice&lt;/h3&gt;
&lt;h3 id=&#34;costruzione-di-cammini-minimi&#34;&gt;Costruzione di cammini minimi&lt;/h3&gt;
&lt;h2 id=&#34;12-vertici&#34;&gt;1.2 Vertici&lt;/h2&gt;
&lt;h3 id=&#34;121-definizione-distanza-fra-due-vertici&#34;&gt;1.2.1 definizione distanza fra due vertici&lt;/h3&gt;
&lt;p&gt;Costo del cammino minimo che li connette&lt;/p&gt;
&lt;h3 id=&#34;condizione-di-bellman&#34;&gt;Condizione di bellman&lt;/h3&gt;
&lt;h3 id=&#34;albero-dei-cammini-minimi&#34;&gt;Albero dei cammini minimi&lt;/h3&gt;
&lt;h2 id=&#34;rilassamento&#34;&gt;Rilassamento&lt;/h2&gt;
&lt;h3 id=&#34;definizione&#34;&gt;Definizione&lt;/h3&gt;
&lt;p&gt;Si va a vedere dove non funziona la disuguaglianza triangolare, se localmente non funziona ovvero se per esempio succede $D_{xu} + \omega(u,y) &lt; D_{xy}$ per qualche vertice all&amp;rsquo;interno del grafo, so di per certo che la distanza $D_{xy}$ non √® una distanza, quindi possiamo riassegnarla in modo che verifichi la disuguaglianza&lt;/p&gt;</description>
    </item>
    <item>
      <title>Classical Cyphers</title>
      <link>https://flecart.github.io/notes/classical-cyphers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/classical-cyphers/</guid>
      <description>&lt;h1 id=&#34;introduzione-a-crittografia&#34;&gt;Introduzione a Crittografia&lt;/h1&gt;
&lt;p&gt;al corso di crittografia di Christof Paar su Youtube, con aggiunte del corso Unibo.&lt;/p&gt;
&lt;h2 id=&#34;classifications-and-definitions&#34;&gt;Classifications and definitions&lt;/h2&gt;
&lt;p&gt;Classification nowadays as many many applications like, and it‚Äôs a increasing important field&lt;/p&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Introduzione/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Introduzione/Untitled&#34;&gt;
&lt;h3 id=&#34;cryptology-2-&#34;&gt;Cryptology (2) üü©&lt;/h3&gt;
&lt;p&gt;La branca comunemente riferita come crittografia √® divisa principalmente in due campi &lt;strong&gt;crittografia e cryptanalysis&lt;/strong&gt; in cui una cerca di creare nuovi metodi per cifrare i messaggi, e l‚Äôaltro prova ad attaccare questi messaggi ritrovando il messaggio originale.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deduzione naturale</title>
      <link>https://flecart.github.io/notes/deduzione-naturale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/deduzione-naturale/</guid>
      <description>&lt;p&gt;La deduzione naturale √® un possibile sistema deduttivo che utilizza il linguaggio naturale per questo motivo pi√π beginner friendly. Lo facciamo prima per la &lt;a href=&#34;https://flecart.github.io/notes/logica-proposizionale&#34;&gt;Logica Proposizionale&lt;/a&gt; che √® molto facile&lt;/p&gt;
&lt;h2 id=&#34;il-sistema-deduttivo&#34;&gt;Il sistema deduttivo&lt;/h2&gt;
&lt;p&gt;Poniamo l&amp;rsquo;esistenza di Assiomi (formule in una certa logica) e &lt;a href=&#34;https://flecart.github.io/notes#regole-di-inferenza&#34;&gt;regole di inferenza&lt;/a&gt; definite sotto.
Esempi sono $P \vdash \varphi$ se $\varphi$ √® un assioma. O altre cose simili con $\land$ e simili&amp;hellip;&lt;/p&gt;
&lt;p&gt;Una &lt;strong&gt;dimostrazione&lt;/strong&gt; allora √® una sequenza di $\varphi_{1}, \dots, \varphi_{n}$ dove $\varphi_{i}$ √® derivata con le regole di inferenza e $\varphi_{1}, \dots, \varphi_{i - 1}$.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fisica del Wireless</title>
      <link>https://flecart.github.io/notes/fisica-del-wireless/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/fisica-del-wireless/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;radio-&#34;&gt;Radio üü©&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&amp;quot;/images/notes/image/universita/ex-notion/Fisica del Wireless/Untitled.png&amp;quot; style=&amp;quot;width: 100%&amp;quot; class=&amp;quot;center&amp;quot; alt=&amp;quot;image/universita/ex-notion/Fisica del Wireless/Untitled&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Antenna: converte corrente in segnali radiorequenza e viceversa. le segnali radiofrequenza sono onde radio con frequenza diversa per rappresentare 1 o 0. Un altro modo per mandare 1 o 0 sarebbe semplicemente cambiare l‚Äôintensit√† della onda, mantenendo la stessa frequenza.&lt;/p&gt;
&lt;p&gt;Viene utilizzata una variazione di potenziale elettrico per creare il segnale, dovrebbe essere un oscillatore armonico in pratica credo.
Creando questo flusso di elettroni, crea anche un campo elettromagnetico a lui ortogonale, questa √® l‚Äôonda radio, che si propaga alla velocit√† della luce.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gruppi Normali</title>
      <link>https://flecart.github.io/notes/gruppi-normali/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/gruppi-normali/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;definizione-normalit√†&#34;&gt;Definizione normalit√†&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Gruppi Normali/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Gruppi Normali/Untitled&#34;&gt;
&lt;h3 id=&#34;test-del-sottogruppo-normale&#34;&gt;Test del sottogruppo normale&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Gruppi Normali/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Gruppi Normali/Untitled 1&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Dimostrazione&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Gruppi Normali/Untitled 2.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Gruppi Normali/Untitled 2&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;il-gruppo-quoziente&#34;&gt;Il gruppo quoziente&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Gruppi Normali/Untitled 3.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Gruppi Normali/Untitled 3&#34;&gt;
&lt;p&gt;L‚Äôimportanza del gruppo normale √® che quando esso vale, possiamo avere il gurppo fattore&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Dimostrazione&lt;/p&gt;
&lt;p&gt;!&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Gruppi Normali/Untitled 4.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Gruppi Normali/Untitled 4&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Introduzione a Logica</title>
      <link>https://flecart.github.io/notes/introduzione-a-logica/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduzione-a-logica/</guid>
      <description>&lt;p&gt;Lo scopo della logica √®&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Correttezza&lt;/strong&gt; del ragionamento, anche verificata attraverso algoritmi predittivi.
&lt;ul&gt;
&lt;li&gt;Si svilupperanno linguaggi logici&lt;/li&gt;
&lt;li&gt;I metodi per la veridicit√† di una sentenza.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Possibilit√†&lt;/strong&gt; e metodi del ragionamento logico&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Completezza e non-deducibilit√†&lt;/strong&gt; di alcuni ragionamenti
&lt;ul&gt;
&lt;li&gt;Necessit√† di completezza delle ipotesi: pi√π ipotesi = ragionamento valido?&lt;/li&gt;
&lt;li&gt;Completezza delle tesi, impossibile.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Una necessit√† della logica √® Meta-logica:&lt;/p&gt;
&lt;p&gt;La logica si deve cercare di basare su certe basi, spesso queste non sono certe, per√≤ danno un certo grado di sicurezza ‚Üí Se la base √® solida allora tutto il ragionamento di una parte √® giusta&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduzione a reti</title>
      <link>https://flecart.github.io/notes/introduzione-a-reti/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduzione-a-reti/</guid>
      <description>&lt;p&gt;Questa nota raccoglie note introduttive al corso di reti dei calcolatori fatto all&amp;rsquo;universit√† di Bologna.&lt;/p&gt;
&lt;h3 id=&#34;011-definizione-di-rete-di-calcolatori-2--&#34;&gt;0.1.1 Definizione di rete di calcolatori (2) üü©-&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Introduzione a reti/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Introduzione a reti/Untitled&#34;&gt;
&lt;p&gt;I requisiti sono principalmente 2&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Essere autonomi nel calcolo (capacit√† di eseguire dei programmi)&lt;/li&gt;
&lt;li&gt;Essere interconnessi (capacit√† di ricevere ed inviare dei segnali)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Gli scopi sono principalmente per la comunicazione fra utenti o calcolatori.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Non-esempi&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Rete telefonica, &lt;em&gt;non sono autonomi&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Rete televisiva&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Esempi&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduzione algoritmi</title>
      <link>https://flecart.github.io/notes/introduzione-algoritmi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduzione-algoritmi/</guid>
      <description>&lt;h1 id=&#34;0-introduzione&#34;&gt;0 Introduzione&lt;/h1&gt;
&lt;h2 id=&#34;01-lalgoritmo&#34;&gt;0.1 L‚Äôalgoritmo&lt;/h2&gt;
&lt;p&gt;Vogliamo cercare di creare algoritmi, ovvero soluzioni a problemi computazionali che &lt;strong&gt;non dipendono dal linguaggio&lt;/strong&gt; di programmazione.&lt;/p&gt;
&lt;h3 id=&#34;011-definizione&#34;&gt;0.1.1 Definizione&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Procedura per risolvere un problema in un numero &lt;strong&gt;finito&lt;/strong&gt; di passi (quindi un algoritmo deve finire)&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;012-origine-della-parola&#34;&gt;0.1.2 Origine della parola&lt;/h3&gt;
&lt;p&gt;Il nome &amp;ldquo;algoritmo&amp;rdquo; deriva da un nome di un matematico persiano dell 800 d.c. &lt;em&gt;Muhammad ibn Musa al-Khwarizmi&lt;/em&gt;, che latinizzato diventa &lt;em&gt;algorithmi&lt;/em&gt;, quindi i latini hanno creato la parola!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Key Exchange protocols</title>
      <link>https://flecart.github.io/notes/key-exchange-protocols/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/key-exchange-protocols/</guid>
      <description>&lt;p&gt;Metodi di key exchange&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Trusted Key parties (sono come Certificate authorities studiati in &lt;a href=&#34;https://flecart.github.io/notes/sicurezza-delle-reti&#34;&gt;Sicurezza delle reti&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Merkle Puzzles&lt;/li&gt;
&lt;li&gt;DH protocol&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;trusted-third-parties&#34;&gt;Trusted Third parties&lt;/h2&gt;
&lt;h3 id=&#34;squared-key-problem&#34;&gt;Squared Key problem&lt;/h3&gt;
&lt;p&gt;Un problema abbastanza ovvio √® che per storare le chiavi di tutti c&amp;rsquo;√® una necessit√† $O(n^{2})$ on $O(n)$ users
Se c&amp;rsquo;√® un trusted key parties il numero delle chiavi si riduce di molto, ritorna ad essere lineare!&lt;/p&gt;
&lt;h3 id=&#34;protocols&#34;&gt;Protocols&lt;/h3&gt;
&lt;h4 id=&#34;toy-exchange-protocol&#34;&gt;Toy Exchange protocolüü©&lt;/h4&gt;
&lt;p&gt;TTP = Trusted Third party (simile a quanto poi si avr√† in &lt;a href=&#34;https://flecart.github.io/notes/asymmetric-cryptography&#34;&gt;Asymmetric Cryptography&lt;/a&gt;)
&lt;img src=&#34;https://flecart.github.io/images/notes/Key Exchange protocols-20240312110014411.webp&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Key Exchange protocols-20240312110014411&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Livello di Rete</title>
      <link>https://flecart.github.io/notes/livello-di-rete/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/livello-di-rete/</guid>
      <description>&lt;h1 id=&#34;reti-di-reti&#34;&gt;Reti di Reti&lt;/h1&gt;
&lt;p&gt;Le parti importanti per questo sono &lt;a href=&#34;https://flecart.github.io/notes/data-plane&#34;&gt;Data Plane&lt;/a&gt; e &lt;a href=&#34;https://flecart.github.io/notes/control-plane&#34;&gt;Control Plane&lt;/a&gt; (che ha saltato quasi tutto, ma almeno dijkstra lo dovresti fare bene)&lt;/p&gt;
&lt;h2 id=&#34;introduzione-puoi-skippare-&#34;&gt;Introduzione (puoi skippare üü©)&lt;/h2&gt;
&lt;p&gt;La puoi skipppare perch√© tratta in modo molto generare parti che saranno trattati in modo pi√π approfondito in seguito. La parte importante forse √® il riassunto di cosa faccia questo livello.&lt;/p&gt;
&lt;h3 id=&#34;discussione-rete-locale-globale&#34;&gt;Discussione rete locale globale&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Livello di Rete/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Livello di Rete/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;No, non √® possible creare una connessione globale utilizzando le tecnologie locali, come hub, switch e simili, perch√© causerebbe &lt;strong&gt;flooding&lt;/strong&gt; e impedirebbe scalabilit√† e crescita dinamica che √® classica della rete&lt;/p&gt;</description>
    </item>
    <item>
      <title>Livello di trasporto</title>
      <link>https://flecart.github.io/notes/livello-di-trasporto/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/livello-di-trasporto/</guid>
      <description>&lt;h1 id=&#34;livello-di-trasporto&#34;&gt;Livello di trasporto&lt;/h1&gt;
&lt;p&gt;Si parla di &lt;strong&gt;livello logico&lt;/strong&gt; di trasporto, ma gran parte ne abbiamo gi√† parlato in &lt;a href=&#34;https://flecart.github.io/notes/livello-applicazione-e-socket&#34;&gt;Livello applicazione e socket&lt;/a&gt; di UDP, TCP e Socket. &lt;strong&gt;trasporto end-to-end&lt;/strong&gt;, nel senso che livello traporto viene visto solamente ad inizio e alla fine, in tutti i nodi intermedi non √® visto sto pacchetto.&lt;/p&gt;
&lt;h3 id=&#34;udp-3--&#34;&gt;UDP (3) üü©-&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide UDP&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Livello di trasporto/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Livello di trasporto/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Classico inizio e fine porta del socket.&lt;/li&gt;
&lt;li&gt;Lunghezza, si pu√≤ vedere che massimo √® 2 alla 16, e poi il checksum per vedere se √® comunicato bene.&lt;/li&gt;
&lt;li&gt;8 byte di header, quindi molto efficiente!&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Sposto a livello applicazione il check al mancato pacchetto. (esempio DNS)&lt;/li&gt;
&lt;li&gt;Oppure casi in cui perdere pacchetti non √® molto importante.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CARATTERISTICHE UDP&lt;/p&gt;</description>
    </item>
    <item>
      <title>Livello OS</title>
      <link>https://flecart.github.io/notes/livello-os/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/livello-os/</guid>
      <description>&lt;h2 id=&#34;91-caratteristiche&#34;&gt;9.1 Caratteristiche&lt;/h2&gt;
&lt;p&gt;Il sistema operativo non ha sempre avuto una interfaccia grafica.&lt;/p&gt;
&lt;h3 id=&#34;911-in-generale&#34;&gt;9.1.1 In generale&lt;/h3&gt;
&lt;p&gt;Principalmente √® un &lt;strong&gt;gestore delle risorse&lt;/strong&gt; come il disco, la CPU, l&amp;rsquo;output e l&amp;rsquo;input.&lt;/p&gt;
&lt;p&gt;√à qualcosa che si infrappone come interfaccia fra le applicazioni e quello che √® presente sotto.&lt;/p&gt;
&lt;h3 id=&#34;912-ambiti-principali&#34;&gt;9.1.2 Ambiti principali&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Livello OS/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Livello OS/Untitled&#34;&gt;
&lt;h2 id=&#34;92-paginazione&#34;&gt;9.2 Paginazione&lt;/h2&gt;
&lt;p&gt;Al programma non interessa se effettivamente √® presente in memoria fisica questa quantit√† di memoria, si di solito basta sempre.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Logica del Primo ordine</title>
      <link>https://flecart.github.io/notes/logica-del-primo-ordine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/logica-del-primo-ordine/</guid>
      <description>&lt;h1 id=&#34;logica-del-primo-ordine&#34;&gt;Logica del primo ordine&lt;/h1&gt;
&lt;p&gt;Questa √® la logica pi√π utilizzata dai matematici&lt;/p&gt;
&lt;h3 id=&#34;limitatezza-della-logica-proposizionale&#34;&gt;Limitatezza della logica proposizionale&lt;/h3&gt;
&lt;p&gt;La logica proposizionale classica non √® in grado di ragionare sull&amp;rsquo;infinito
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Logica del Primo ordine/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Logica del Primo ordine/Untitled&#34;&gt;&lt;/p&gt;
&lt;p&gt;Fino ad ora abbiamo utilizzato una metalogica per giustificare il per ogni e l&amp;rsquo;esiste nelle dimostrazioni fin&amp;rsquo;ora.&lt;/p&gt;
&lt;p&gt;Dobbiamo quindi dare una definizione pi√π formale dei &lt;strong&gt;quantificatori&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;obiettivo-della-logica-del-primo-ordine&#34;&gt;Obiettivo della logica del primo ordine&lt;/h3&gt;
&lt;p&gt;Si pu√≤ quindi identificare come l&amp;rsquo;obiettivo della logica di primo ordine l&amp;rsquo;introduzione dei quantificatori dell&amp;rsquo;universale e dell&amp;rsquo;esiste&lt;/p&gt;</description>
    </item>
    <item>
      <title>Logica Proposizionale</title>
      <link>https://flecart.github.io/notes/logica-proposizionale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/logica-proposizionale/</guid>
      <description>&lt;p&gt;Con la logica proposizionale studiamo le denotazioni che hanno un valore di verit√†, ovvero deve essere una sentenza assertiva. Studio solamente le connotazioni che hanno una capacit√† denotativa, in quanto √® solo quello ch emi importa.&lt;/p&gt;
&lt;h2 id=&#34;61-la-sintassi&#34;&gt;6.1 La sintassi&lt;/h2&gt;
&lt;p&gt;Vengono qui definite le produzioni che valgono in ogni singolo mondo.&lt;/p&gt;
$$
F ::= \top|\bot|A|B|...|\not F| F \wedge F| F \vee F| F \implies F
$$&lt;p&gt;Questa √® la BNF della nostra sintassi.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mac Wifi</title>
      <link>https://flecart.github.io/notes/mac-wifi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/mac-wifi/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;Ricordiamo che vogliamo cercare di &lt;strong&gt;arbitrare l‚Äôaccesso al canale fisico sottostante&lt;/strong&gt;. In questo momento andiamo ad assumere di avere gi√† tutto l‚Äôimpianto di trasmissione fisica che abbiamo in &lt;a href=&#34;https://flecart.github.io/notes/tecnologia-wireless&#34;&gt;Tecnologia Wireless&lt;/a&gt;, &lt;a href=&#34;https://flecart.github.io/notes/modulazione-wireless&#34;&gt;Modulazione wireless&lt;/a&gt; &lt;a href=&#34;https://flecart.github.io/notes/fisica-del-wireless&#34;&gt;Fisica del Wireless&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;obiettivi&#34;&gt;Obiettivi:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Arbitraggio del singolo canale fisico (la tesi di dottorato del prof era su collision avoidance di wifi).
&lt;ol&gt;
&lt;li&gt;Sia in tempo&lt;/li&gt;
&lt;li&gt;Sia in spazio (come gestire il segnale mandato nello stesso spazio)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Utilizzo minimo di energia&lt;/li&gt;
&lt;li&gt;Quality of service&lt;/li&gt;
&lt;li&gt;Adaptive behaviour (come il 6G che vuole andare ad utilizzare AI per fare predizione).&lt;/li&gt;
&lt;li&gt;Evitare segnale spaghetti o jammed
&lt;ol&gt;
&lt;li&gt;Collisioni fanno sprecare energia ad entrambi (sia ricevente sia sender)&lt;/li&gt;
&lt;li&gt;bisogna trovare un metodo per fare risoluzione (controllare il sender riguardo la trasmissione, in quanto non sono in grado di trasmettere e ascoltare in modo contemporaneo)&lt;/li&gt;
&lt;li&gt;Questo si lega alla parte di arbitraggio del canale&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ricordiamo che ethernet provava ad ascoltare il segnale e provare a trasmettere, si pu√≤ utilizzare la stessa cosa anche qui? No, ethernet permetteva di ascolatare il segnale nel momento di generazione, mentre wifi non pu√≤, perch√© semplicemente il segnale prodotto localmente √® molto pi√π grande. Inoltre wifi ha anche bisogno di fare multiplexing sullo &lt;strong&gt;spazio&lt;/strong&gt; non solo nel tempo come per l‚Äôethernet.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Memory Corruption</title>
      <link>https://flecart.github.io/notes/memory-corruption/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/memory-corruption/</guid>
      <description>&lt;p&gt;First of all, we need to have a strong understanding of how a program allocates memory during its execution. See &lt;a href=&#34;https://flecart.github.io/notes/memoria&#34;&gt;Memoria&lt;/a&gt;, &lt;a href=&#34;https://flecart.github.io/notes/memoria-virtuale&#34;&gt;Memoria virtuale&lt;/a&gt; and other notes about &lt;a href=&#34;https://flecart.github.io/notes/nomi-e-scope&#34;&gt;Nomi e Scope&lt;/a&gt;, &lt;a href=&#34;https://flecart.github.io/notes/gestione-della-memoria&#34;&gt;Gestione della memoria&lt;/a&gt;.
The thing you have to remember is that&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Every new function call allocates a new block, with his local variables.&lt;/li&gt;
&lt;li&gt;How the calling parameters are stored in the stack&lt;/li&gt;
&lt;li&gt;How the heap is allocated (common heap algos are in &lt;a href=&#34;https://flecart.github.io/notes/gestione-della-memoria&#34;&gt;Gestione della memoria&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;How the stack grows (and how it can overflow it, and overwriting important data).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;common-attack-vectors&#34;&gt;Common attack vectors&lt;/h2&gt;
&lt;p&gt;We use C, as it is the easiest way to show how this could be attacked.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Modulazione wireless</title>
      <link>https://flecart.github.io/notes/modulazione-wireless/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/modulazione-wireless/</guid>
      <description>&lt;h3 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h3&gt;
&lt;h3 id=&#34;digital-modulation--&#34;&gt;Digital modulation  üü®&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide introduzione&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Modulazione wireless/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Modulazione wireless/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Modulazione digitale: prendiamo un dato digitale e trasmesso con un segnale analogico, come le RF.&lt;/p&gt;
&lt;p&gt;ASK: amplitude shift keying&lt;/p&gt;
&lt;p&gt;FSK: frequency shift&lt;/p&gt;
&lt;p&gt;PSK: phase shift&lt;/p&gt;
&lt;p&gt;Questi sono i tre metodi principali, che dipendono dalle caratteristiche dell‚Äôonda descritte in &lt;a href=&#34;https://flecart.github.io/notes/fisica-del-wireless&#34;&gt;Fisica del Wireless&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TRE CARATTERISTICHE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Power&lt;/p&gt;
&lt;p&gt;Resistenza interferenze. (robustezza)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ANALOG MODULATION&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Per modulare un segnale analogico si utilizzano principalemente &lt;strong&gt;AM o FM&lt;/strong&gt;, amplitude o frequency modulation, raramente si utilizza PM.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Network Address Translation</title>
      <link>https://flecart.github.io/notes/network-address-translation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/network-address-translation/</guid>
      <description>&lt;h1 id=&#34;nat-network-address-translation&#34;&gt;NAT Network address translation&lt;/h1&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;Col il NAT possiamo avere tutto lo spazio degli IP di cui abbiamo bisogno, che per√≤ non sono esposti. All&amp;rsquo;esterno vengono esposte solamente l‚ÄôIP del NAT.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Schema classico NAT&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Network Address Translation/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Network Address Translation/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Quindi in breve&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;All&amp;rsquo;esterno √® esposto solamente l&amp;rsquo;indirizzo del router&lt;/strong&gt;, il router, a seconda della porta giusta, d√† in risposta al computer giusto, quindi all&amp;rsquo;interno della nostra rete conosciamo tutti gli indirizzi IP giusti.&lt;/p&gt;</description>
    </item>
    <item>
      <title>OTP and Stream Ciphers</title>
      <link>https://flecart.github.io/notes/otp-and-stream-ciphers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/otp-and-stream-ciphers/</guid>
      <description>&lt;h3 id=&#34;xor-operation&#34;&gt;XOR operation&lt;/h3&gt;
&lt;p&gt;√à una operazione binaria abbastanza semplice  per√≤ ci sar√† importante per andare ad analizzare dei cifrari di un certo genere. Come il ONE TIME PAD che faremo fra poco in &lt;a href=&#34;https://flecart.github.io/notes/otp-and-stream-ciphers.&#34;&gt;OTP and Stream Ciphers.&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;teorema-cifratura-con-xor&#34;&gt;Teorema cifratura con XOR&lt;/h4&gt;
&lt;p&gt;Prendiamo $X$ una variabile aleatoria in $\left\{ 0,1 \right\}^{n}$ &lt;strong&gt;uniforme&lt;/strong&gt;, sia $Y$ una variabile aleatoria su uno stesso dominio come vogliamo. Tali per cui $X, Y$ siano indipendenti
Allora avremo che $C = X \oplus Y$ √® una variabile aleatoria &lt;strong&gt;uniforme&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Porte Logiche</title>
      <link>https://flecart.github.io/notes/porte-logiche/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/porte-logiche/</guid>
      <description>&lt;p&gt;In questa nota andiamo a trattare argomenti come tabelle di verit√†. Mappe di Karnaugh. E piccolissima introduzione ai circuiti integrati.&lt;/p&gt;
&lt;h2 id=&#34;boole&#34;&gt;Boole&lt;/h2&gt;
&lt;p&gt;Un signor Boole ha creato le basi dell&amp;rsquo;algebra booleana su cui si basano le porte logiche dei computer moderni.&lt;/p&gt;
&lt;h3 id=&#34;tabelle-di-verit√†&#34;&gt;Tabelle di verit√†&lt;/h3&gt;
&lt;p&gt;Le tabelle di verit√† sono sufficienti per descrivere il funzionamento di una porta logica.&lt;/p&gt;
&lt;p&gt;Questa cosa √® possibile grazie alla limitatezza delle funzioni all&amp;rsquo;interno dell&amp;rsquo;insieme $\{0,1\}$ dominio di partenza e fine dell&amp;rsquo;algebra booleana.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Rappresentazione delle informazioni</title>
      <link>https://flecart.github.io/notes/rappresentazione-delle-informazioni/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/rappresentazione-delle-informazioni/</guid>
      <description>&lt;h2 id=&#34;61-codifiche&#34;&gt;6.1 Codifiche&lt;/h2&gt;
&lt;p&gt;Si utilizzano codifiche, che sono delle &lt;strong&gt;convenzioni&lt;/strong&gt;, qualcosa che un gruppo di umani ha deciso fosse utile darci un significato.&lt;/p&gt;
&lt;h3 id=&#34;611-codifica-posizionale&#34;&gt;6.1.1 Codifica posizionale&lt;/h3&gt;
&lt;p&gt;Dove $d_i$ √® il valore in posizione $i$ e $b$ √® la base&lt;/p&gt;
$$
\sum_{i=0}^k d_ib
$$&lt;h3 id=&#34;612-ottale-esadecimale-e-binario&#34;&gt;6.1.2 Ottale, esadecimale e binario&lt;/h3&gt;
&lt;p&gt;Queste sono le codifiche principali per i computer in quanto sono comodi da visualizzare. Inoltre Ottale e esadecimale in particolare sono riassunti dei binari, cio√® sono dei sottoinsiemi che possiedono ancora tutte le caratteristiche e quindi sono comodi&lt;/p&gt;</description>
    </item>
    <item>
      <title>Relazioni di Ricorrenza</title>
      <link>https://flecart.github.io/notes/relazioni-di-ricorrenza/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/relazioni-di-ricorrenza/</guid>
      <description>&lt;h3 id=&#34;iterazione&#34;&gt;Iterazione&lt;/h3&gt;
&lt;p&gt;Questo metodo semplicemente consiste di calcolare tutte le operazioni e scriverlo con una notazione asintotica.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;slide&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Relazioni di Ricorrenza/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Relazioni di Ricorrenza/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sostituzione-induzione&#34;&gt;Sostituzione (induzione)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;slide&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Relazioni di Ricorrenza/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Relazioni di Ricorrenza/Untitled 1&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Analisi della relazione di ricorrenza di fibonacci&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Si pu√≤ dimostrare utilizzando l&amp;rsquo;induzione che una relazione di questo tipo&lt;/p&gt;
$$
T(n) = \begin{cases}
O(1) \\
T(n-1) + T(n-2) + 1
\end{cases}
$$&lt;p&gt;Si trova che √® $O(2^n), \Omega(2^{n/2})$&lt;/p&gt;
&lt;p&gt;Analisi finale.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Semantica intuizionista</title>
      <link>https://flecart.github.io/notes/semantica-intuizionista/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/semantica-intuizionista/</guid>
      <description>&lt;p&gt;Molto importante questo documento per avere chiara la differenza fra la logica intuizionista e la &lt;a href=&#34;https://flecart.github.io/notes/logica-proposizionale&#34;&gt;Logica Proposizionale&lt;/a&gt; classica.&lt;/p&gt;
&lt;p&gt;Questa logica intuizionista non si preoccupa del noumeno platonico, ma solo di una prova reale.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Introduzione:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;wikipedia&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Semantica intuizionista/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Semantica intuizionista/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-11-scopi-di-intuizionista-3&#34;&gt;9 11 Scopi di intuizionista (3)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Semantica dell&amp;rsquo;evidenza ‚Üí costruzione della prova&lt;/li&gt;
&lt;li&gt;Semantica della conoscenza diretta = conoscenza diretta&lt;/li&gt;
&lt;li&gt;Semantica della calcolabilit√† = programma, algoritmo della soluzione&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;91-invenzione-o-scoperta&#34;&gt;9.1 Invenzione o scoperta&lt;/h2&gt;
&lt;p&gt;La semantica intuizionista vede la matematica come una creazione (e questa cosa interessa molto all&amp;rsquo;informatico perch√© √® una prova., mentre la semantica classica vede la matematica come una scoperta&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sicurezza delle reti</title>
      <link>https://flecart.github.io/notes/sicurezza-delle-reti/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/sicurezza-delle-reti/</guid>
      <description>&lt;h3 id=&#34;obiettivi-della-sicurezza--&#34;&gt;Obiettivi della sicurezza (!!!) üü©&lt;/h3&gt;
&lt;p&gt;Vogliamo creare delle reti che abbiamo certe garanzie di sicurezza, soprattutto:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Confidenzialit√†&lt;/strong&gt;, non vorremmo che il nostro messaggio sia intercettabile e leggibili da persone intermedie&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integrit√†&lt;/strong&gt;: non vogliamo che messaggi possano essere cambiati senza intervento del sender&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autenticazione&lt;/strong&gt;: vorremmo sapere con chi stiamo parlando, e vorremmo essere sicuri che non stiano mentendo sull‚Äôidentit√†.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sicurezza operativa&lt;/strong&gt;(Availability): vorremmo essere in grado di poter continuare a fornire il servizio (quindi non sia possibile dossare, o installare malware che modifichino il comportamento del servizio).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Questi sono stati trattati un po&amp;rsquo; in &lt;a href=&#34;https://flecart.github.io/notes/theoretical-notions-of-security&#34;&gt;Theoretical Notions of Security&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sintassi e RI strutturali</title>
      <link>https://flecart.github.io/notes/sintassi-e-ri-strutturali/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/sintassi-e-ri-strutturali/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Programmare e dimostrare sono sostanzialmente la stessa attivit√† ~&lt;em&gt;Coen&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ma non secondo l&amp;rsquo;industria&amp;hellip;&lt;/p&gt;
&lt;h3 id=&#34;411-definizione-e-necessit√†&#34;&gt;4.1.1 Definizione e necessit√†&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Branca della linguistica, studia creazione di proposizione e il loro collegamento per la creazione di un periodo&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In seguito la semantica d√† un metodo a queste proposizioni in modo che abbiano un senso.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Utile o necessario per la definizione del linguaggio artificiale&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;412-alfabeto-stringa-linguaggio-e-grammatica&#34;&gt;4.1.2 Alfabeto, stringa, linguaggio e grammatica&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Alfabeto&lt;/strong&gt;: Insieme non vuoto di simboli (che spesso sono diversi fra di loro)
&lt;strong&gt;Stringa&lt;/strong&gt; seguenza finita (vuoto √® possibile) di simboli $\epsilon = \varnothing$
&lt;strong&gt;Linguaggio&lt;/strong&gt;: insieme di stringhe (di qualunque tipo, finito o infinito).
&lt;strong&gt;Grammatica&lt;/strong&gt; formalismo (un insieme di regole che lo rende finito) che definisce un linguaggio&lt;/p&gt;</description>
    </item>
    <item>
      <title>Strutture di dati elementari</title>
      <link>https://flecart.github.io/notes/strutture-di-dati-elementari/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/strutture-di-dati-elementari/</guid>
      <description>&lt;h2 id=&#34;31-introduzione&#34;&gt;3.1 Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;311-cosa-sono&#34;&gt;3.1.1 Cosa sono&lt;/h3&gt;
&lt;p&gt;Le strutture di dati si interessano solamente di &lt;strong&gt;come memorizzare i dati&lt;/strong&gt;, non necessariamente va a memorizzare un tipo di dato concreto.&lt;/p&gt;
&lt;p&gt;Quindi + sul come - sul cosa.&lt;/p&gt;
&lt;h3 id=&#34;312-prototipo-e-implementazione&#34;&gt;3.1.2 Prototipo e implementazione&lt;/h3&gt;
&lt;p&gt;Avevamo introdotto la differenza fra algoritmo e programma all&amp;rsquo;inizio del corso, andiamo ora a definire la differenza fra prototipo e implementazione:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prototipo:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;va a fare una descrizione dei metodi che deve avere una determinata struttura di dati. Lo puoi intendere come una specie di &lt;em&gt;interfaccia&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tecnologia Wireless</title>
      <link>https://flecart.github.io/notes/tecnologia-wireless/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/tecnologia-wireless/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;spettro-del-wireless-networks-skip&#34;&gt;Spettro del wireless networks (skip)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide spettro Wirelesss networks&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Tecnologia Wireless/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Tecnologia Wireless/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Questo solamente la classica differenziazione fra radio, visibile, raggi x raggi gamma etcetera.&lt;/p&gt;
&lt;p&gt;Se andiamo a guardare le onde radio, quelle che ci interessano, se ho frequenza alta ho densit√† di frequenza alta, se ho frequenza bassa ho alta capacit√† di suparamento di ostacoli.&lt;/p&gt;
&lt;p&gt;ISM √® una banda da 2 a 5.0 GHz e c&amp;rsquo;√® tutto il WiFi, bluetooth. (anche wifi a 5 ghz.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Teorema di Lagrange</title>
      <link>https://flecart.github.io/notes/teorema-di-lagrange/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/teorema-di-lagrange/</guid>
      <description>&lt;h2 id=&#34;classi-laterali&#34;&gt;Classi laterali&lt;/h2&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Teorema di Lagrange/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Teorema di Lagrange/Untitled&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Dimostrazione dei lemmi sopra.
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Teorema di Lagrange/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Teorema di Lagrange/Untitled 1&#34;&gt;&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Teorema di Lagrange/Untitled 2.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Teorema di Lagrange/Untitled 2&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La cosa interessante di questa parte √® possiamo usare una classe laterale per partizionare il gruppo iniziale!&lt;/p&gt;
&lt;h2 id=&#34;il-teorema-di-lagrange&#34;&gt;Il teorema di Lagrange&lt;/h2&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Teorema di Lagrange/Untitled 3.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Teorema di Lagrange/Untitled 3&#34;&gt;
Dividere significa che **partiziona** l&#39;insieme iniziale in alcuni insiemi distinti.
L&#39;insieme $G:H$ √® l&#39;insieme che contiene tutti i cosets, credo.
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Dimostrazione&lt;/p&gt;</description>
    </item>
    <item>
      <title>Teoria assiomatica degli insiemi</title>
      <link>https://flecart.github.io/notes/teoria-assiomatica-degli-insiemi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/teoria-assiomatica-degli-insiemi/</guid>
      <description>&lt;h2 id=&#34;21-elementi-di-base&#34;&gt;2.1 Elementi di base&lt;/h2&gt;
&lt;h3 id=&#34;211-definizione-e-caratteristiche&#34;&gt;2.1.1 Definizione e caratteristiche&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Tutto √® un insieme (su questo &lt;em&gt;si basa la maggior parte della matematica&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Efficace nella descrizione degli oggetti (infiniti √® ez), ma &lt;strong&gt;non √® efficiente&lt;/strong&gt; nel calcolo in quanto non d√† nessun indizio sul&amp;rsquo;implementazione in memoria o sul modo per calcolarlo, c&amp;rsquo;√® solo una associazione&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Si pu√≤ concludere che per l&amp;rsquo;informatico non serve a molto questa teoria, ma √® la base per la matematica.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Tor protocol</title>
      <link>https://flecart.github.io/notes/the-tor-protocol/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/the-tor-protocol/</guid>
      <description>&lt;h2 id=&#34;some-notes&#34;&gt;Some notes&lt;/h2&gt;
&lt;h4 id=&#34;mix-based-systems&#34;&gt;Mix-based systemsüü®&lt;/h4&gt;
&lt;p&gt;Created in 1981 by David Chaum.
Very similar to the previous one, in practice, in the end, it acts as a proxy but not only does it take and receive, but it also mixes together the packets it has received from the sources, applying its key.&lt;/p&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Introduction to Cyber Security-20240326102655961.webp&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Introduction to Cyber Security-20240326102655961&#34;&gt;
&lt;p&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt;
The public-private mixing system is very slow. For this reason, a network of nodes is established, each having a symmetric key, making it much faster.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Theoretical Notions of Security</title>
      <link>https://flecart.github.io/notes/theoretical-notions-of-security/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/theoretical-notions-of-security/</guid>
      <description>&lt;h2 id=&#34;ciaa-principles-of-security&#34;&gt;CIAA principles of security&lt;/h2&gt;
&lt;p&gt;We have already  outlined these principles in &lt;a href=&#34;https://flecart.github.io/notes/sicurezza-delle-reti&#34;&gt;Sicurezza delle reti&lt;/a&gt; and talked about the concepts of authentication and integrity. Here we try to deepen these concepts and delve a little bit more on the attack vectors
These are acronyms, usually called CIA and AAA for infrastructure&lt;/p&gt;
&lt;h3 id=&#34;confidentiality&#34;&gt;Confidentiality&lt;/h3&gt;
&lt;p&gt;This is one concerns about the secrecy of the sent message. We do not want others to be able to access and read what we are doing.&lt;/p&gt;</description>
    </item>
    <item>
      <title>TLS-SSL protocol</title>
      <link>https://flecart.github.io/notes/tls-ssl-protocol/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/tls-ssl-protocol/</guid>
      <description>&lt;p&gt;First time we talked about this was in &lt;a href=&#34;https://flecart.github.io/notes/sicurezza-delle-reti#protocollo-ssl&#34;&gt;Sicurezza delle reti#Protocollo SSL&lt;/a&gt; But that was a simple toy model.&lt;/p&gt;
&lt;h2 id=&#34;secure-socket-layer&#34;&gt;Secure Socket Layer&lt;/h2&gt;
&lt;p&gt;Secure socket Layer and TLS add security (see security principles in &lt;a href=&#34;https://flecart.github.io/notes/theoretical-notions-of-security&#34;&gt;Theoretical Notions of Security&lt;/a&gt;) on the transport layers, whereas &lt;a href=&#34;https://flecart.github.io/notes/ipsec-protocol&#34;&gt;IPSec protocol&lt;/a&gt; adds it to the network level. So this works on a higher level of abstraction following the ISO OSI framework &lt;a href=&#34;https://flecart.github.io/notes/architettura-e-livelli-1,-2#livelli-iso/osi&#34;&gt;Architettura e livelli 1, 2#Livelli ISO/OSI&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;SSL is the old version of the TLS protocol.
This provides &lt;strong&gt;integrity&lt;/strong&gt; and &lt;strong&gt;confidentiality&lt;/strong&gt; to the communication, see &lt;a href=&#34;https://flecart.github.io/notes/theoretical-notions-of-security&#34;&gt;Theoretical Notions of Security&lt;/a&gt;.
The main difference of SSL and TLS is that this has vulnerabilities like POODLE attack&lt;/p&gt;</description>
    </item>
    <item>
      <title>User authentication</title>
      <link>https://flecart.github.io/notes/user-authentication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/user-authentication/</guid>
      <description>&lt;p&gt;The user authentication is one of the most important parts for computer security, because &lt;em&gt;every security policy&lt;/em&gt; starts with authentication.
This authentication should be &lt;strong&gt;easy to use&lt;/strong&gt;, if not users will not use this. So this should be a good compromise.&lt;/p&gt;
&lt;p&gt;Parts of authentication security security:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Registration&lt;/li&gt;
&lt;li&gt;Authentication check&lt;/li&gt;
&lt;li&gt;Recovery
These three are the main parts of security.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;some-challenges-in-user-authentication&#34;&gt;Some challenges in user authentication&lt;/h3&gt;
&lt;h4 id=&#34;intermediate-principals&#34;&gt;Intermediate principals&lt;/h4&gt;
&lt;p&gt;A part that we will not cover are the &lt;em&gt;intermediate principals&lt;/em&gt; which attach the mean of transmission or intermediate devices used in the transmission. E.g. a key-logger in the client system is enough to compromise the security of the authentication.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Verita, Teorie, modelli, connotazione, denotazione</title>
      <link>https://flecart.github.io/notes/verita-teorie-modelli-connotazione-denotazione/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/verita-teorie-modelli-connotazione-denotazione/</guid>
      <description>&lt;p&gt;Questa √® una necessit√† per stabilire il significato di una sintassi definiti.&lt;/p&gt;
&lt;h2 id=&#34;51-verit√†-e-realt√†&#34;&gt;5.1 Verit√† e Realt√†&lt;/h2&gt;
&lt;p&gt;La verit√† ha solamente senso quando lo si relaziona con un mondo sensibile, ossia il mondo che si pu√≤ percepire con i nostri sensi.&lt;/p&gt;
&lt;h3 id=&#34;511-verit√†-parametrica-e-assoluta&#34;&gt;5.1.1 Verit√† parametrica e assoluta&lt;/h3&gt;
&lt;p&gt;Se un esperimento √® ripetibile all&amp;rsquo;interno del mondo sensibili allora questa √® considerata come una &lt;strong&gt;verit√† parametrica&lt;/strong&gt;, ossia dipende da uno stato del mondo sensibile.&lt;/p&gt;</description>
    </item>
    <item>
      <title>VLAN</title>
      <link>https://flecart.github.io/notes/vlan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/vlan/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;Quando abbiamo una switch, ma vogliamo allo stesso momento andare a creare pi√π LAN, allora abbiamo bisogno delle VLAN. Questi switch che hanno delle VLAN si chiamano &lt;strong&gt;managed switches&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Queste vlan sono numerate (ricorda l‚Äôespericomento cn LUCA!).&lt;/p&gt;
&lt;h3 id=&#34;il-problema&#34;&gt;Il problema&lt;/h3&gt;
&lt;p&gt;Sono un protocollo livello 2 (Link-Layer, di collegamento), non vorremmo per esempio che un broadcast di una certa rete vada anche in altre reti che non centrino praticamente nulla, come possiamo vedere in figura.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Wifi 802-11</title>
      <link>https://flecart.github.io/notes/wifi-802-11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/wifi-802-11/</guid>
      <description>&lt;p&gt;In this document, we will discuss the actual Wi-Fi standard that we can find in the market.&lt;/p&gt;
&lt;p&gt;The initial slides consist of extensive lists of Wi-Fi technologies and their uses, such as Bluetooth network, Wi-Fi network, long-range Wi-Fi, and 3G network.&lt;/p&gt;
&lt;p&gt;However, they are currently out of service.&lt;/p&gt;
&lt;h2 id=&#34;service-sets&#34;&gt;Service Sets&lt;/h2&gt;
&lt;h3 id=&#34;basic-service-set&#34;&gt;Basic Service Set&lt;/h3&gt;
&lt;p&gt;There are various divisions within the service set, each of which provides certain types of service.&lt;/p&gt;
&lt;p&gt;In the basic service, we have things like &lt;strong&gt;SSID&lt;/strong&gt;, which is the service set identifier that is broadcasted in the beacon as described in &lt;a href=&#34;https://flecart.github.io/notes/mac-wifi&#34;&gt;Mac Wifi&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Consensus protocols</title>
      <link>https://flecart.github.io/notes/consensus-protocols/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/consensus-protocols/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;Vogliamo tenere in modo sincronizzato alcune macchine, questo √® il nostro obiettivo. Questo √® un problema abbastanza difficile‚Ä¶ Come tenere in sync se ci sono alcuni nodi maligni o la rete che non √® bona?&lt;/p&gt;
&lt;h3 id=&#34;assunzioni-principali-2&#34;&gt;Assunzioni principali (2)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Esiste internet&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Esiste Crittografia&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Queste sono le assunzioni che non saranno mai rilassate per l‚Äôintero corso, diciamo che sono la nostra base su cui possiamo andare a costruire la base per il nostro studio.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Filesystem</title>
      <link>https://flecart.github.io/notes/filesystem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/filesystem/</guid>
      <description>&lt;h3 id=&#34;perch√©-filesystem&#34;&gt;Perch√© filesystem?&lt;/h3&gt;
&lt;p&gt;Questa √® l&amp;rsquo;idea presa dall&amp;rsquo;archivio, come se fosse un ufficio che deve tenere delle pratiche ordinate in cartelle e cartelloni.&lt;/p&gt;
&lt;p&gt;L‚Äôutilizzo principale √® dare un &lt;strong&gt;interfaccia comune di accesso ai dispositivi.&lt;/strong&gt; perch√© dispositivi diversi hanno sotto modi di accedere diversi, questa interfaccia facilita molto l&amp;rsquo;accesso.&lt;/p&gt;
&lt;h3 id=&#34;informazioni-dei-files-5-&#34;&gt;Informazioni dei files (5+) üü®&lt;/h3&gt;
&lt;p&gt;Il file √® &lt;strong&gt;l‚Äôunit√† logica di memorizzazione&lt;/strong&gt;. il formato che c&amp;rsquo;√® dentro √® gestito dall&amp;rsquo;applicazione, non dal file system!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Goals of Distributed systems</title>
      <link>https://flecart.github.io/notes/goals-of-distributed-systems/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/goals-of-distributed-systems/</guid>
      <description>&lt;h1 id=&#34;dependable-systems&#34;&gt;Dependable systems&lt;/h1&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;Possiamo individuare alcune propriet√† dei sistemi distribuiti. Per√≤ non siamo riusciti a renderli logicamente validi. Sono ancora un p√≤ misti di linguaggio naturale e della sua ambiguit√†!
Comunque possiamo ridurci per guardare quanto un sistema sia affidabile a guardare poche sue caratteristiche precise.&lt;/p&gt;
&lt;h3 id=&#34;caratteristiche-fondamentali-4&#34;&gt;Caratteristiche fondamentali (4)&lt;/h3&gt;
&lt;p&gt;Queste propriet√† sono pensate naturalmente caratterizzanti dei sistemi. In particolare dovrebbero essere tutti misurabili.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Availability&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Che risponde nell‚Äôistante in cui fai una richiesta.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduzione a blockchain</title>
      <link>https://flecart.github.io/notes/introduzione-a-blockchain/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduzione-a-blockchain/</guid>
      <description>&lt;h2 id=&#34;blockchain-stack&#34;&gt;Blockchain stack&lt;/h2&gt;
&lt;p&gt;Vogliamo andare ora a descrivere la stack delle blockchain, in modo simile a quanto fatto con le internet, perch√© anche qui possiamo organizzarlo a stack!&lt;/p&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Introduzione a blockchain/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Introduzione a blockchain/Untitled&#34;&gt;
&lt;p&gt;Nota: le astrazioni fra questi layer non sono definiti bene come osi osint.&lt;/p&gt;
&lt;h3 id=&#34;layer---0-internet&#34;&gt;Layer - 0 Internet&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Internet (semi-reliable point-to-point communication) and cryptography (specifically, cryptographic hash functions and secure digital signatures).&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;layer---1-consensus&#34;&gt;Layer - 1 Consensus&lt;/h3&gt;
&lt;p&gt;Ci concentreremo sui protocolli di questo per la maggior parte di quanto faremo! Bitcoin, Ethereum sono tutti a questo livello.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Monitor</title>
      <link>https://flecart.github.io/notes/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/monitor/</guid>
      <description>&lt;p&gt;Questo √® un modo di pi√π alto livello per creare programmazione concorrente.&lt;/p&gt;
&lt;h2 id=&#34;introduzione-ai-monitor&#34;&gt;Introduzione ai monitor&lt;/h2&gt;
&lt;p&gt;Questo costrutto per la programmazione concorrente, prende molto dalla programmazione agli oggetti, abbiamo delle variabili presenti al monitor, &lt;strong&gt;private&lt;/strong&gt; solamente accessibili ad essa, tramite procedure che sono &lt;strong&gt;mutex&lt;/strong&gt; automaticamente!&lt;/p&gt;
&lt;h3 id=&#34;elementi-costituenti-&#34;&gt;Elementi costituenti üü©&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dati locali&lt;/li&gt;
&lt;li&gt;Sequenza di inizializzazione&lt;/li&gt;
&lt;li&gt;Procedure di entrata&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Appena provo a chiamare una procedura, questa √® fatta gi√† in mutua esclusione!.&lt;/p&gt;
&lt;p&gt;E &lt;strong&gt;possono modificare dati locali&lt;/strong&gt; solo tramite chiamate a sue procedure&lt;/p&gt;</description>
    </item>
    <item>
      <title>Note sull‚Äôarchitettura</title>
      <link>https://flecart.github.io/notes/note-sullarchitettura/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/note-sullarchitettura/</guid>
      <description>&lt;h2 id=&#34;interrupt&#34;&gt;Interrupt&lt;/h2&gt;
&lt;h3 id=&#34;descrizione-iniziale-&#34;&gt;Descrizione iniziale üü©&lt;/h3&gt;
&lt;p&gt;Di interrupt e trap se n‚Äô√® parlato un p√≤ in &lt;a href=&#34;https://flecart.github.io/notes/livello-isa&#34;&gt;Livello ISA&lt;/a&gt; di architettura, ora andiamo ad approfondire come viene gestito a livello SO.&lt;/p&gt;
&lt;p&gt;Un interrupt √® un &lt;strong&gt;segnale&lt;/strong&gt; che viene mandato o da un dispositivo hardware (di solito dopo la fine di un processo input output) oppure da software, in questo caso viene chiamato &lt;strong&gt;trap&lt;/strong&gt; che √® un interrupt software sincrono..&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide Interrupt Hardware e software&lt;/p&gt;</description>
    </item>
    <item>
      <title>Processi e thread</title>
      <link>https://flecart.github.io/notes/processi-e-thread/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/processi-e-thread/</guid>
      <description>&lt;p&gt;Il processo e la gestione dell&amp;rsquo;esecuzione √® uno dei compiti principali dei sistemi operativi. Lo vuole fare in maniera efficace ed efficiente, come descritto in &lt;a href=&#34;https://flecart.github.io/notes/note-sull‚Äôarchitettura&#34;&gt;Note sull‚Äôarchitettura&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide schema generale tabelle&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Processi e thread/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Processi e thread/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;processi&#34;&gt;Processi&lt;/h2&gt;
&lt;p&gt;Il process control block √® la struttura di dati principali da comprendere.&lt;/p&gt;
&lt;p&gt;Ha una tabella dei file aperti, che sono dei file descriptor (all&amp;rsquo;interno della propria struttura di dati), riferiti a una tabella dell&amp;rsquo;interno sistema credo, e questi puntano a un VNode che permette di localizzarlo nella memoria secondaria.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Programmi Concorrenti</title>
      <link>https://flecart.github.io/notes/programmi-concorrenti/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/programmi-concorrenti/</guid>
      <description>&lt;p&gt;Vorremmo cercare di stabilire una teoria riguardante programmi che vengono eseguiti appunto concorrentemente, senza una esecuzione classica uno dpo l‚Äôaltro&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Esempio mini-programma rallentamento&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;pthread.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;%s&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100000000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;argc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;char&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;argv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[])&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pthread_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pthread_create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Uno&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pthread_create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Due&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pthread_join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pthread_join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example output:&lt;/p&gt;
&lt;p&gt;Due
Uno
Uno
Due
Uno
Due
Due
Uno
Due
Uno
Due
Uno
Due
Uno
Due
Uno
Due
Uno
Due
Uno&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Esempio 2 mini-programma rallentamento&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;pthread.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;count&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;argc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;char&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;argv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[])&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;pthread_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;t2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;pthread_create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Uno&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;pthread_create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Due&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;pthread_join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;pthread_join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;%d&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Vogliamo creare un &lt;strong&gt;modello&lt;/strong&gt; teorico che riesca a rappresentare il concetto di processi concorrenti, questo √® il modello concorrente&lt;/p&gt;</description>
    </item>
    <item>
      <title>Replication and consistency</title>
      <link>https://flecart.github.io/notes/replication-and-consistency/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/replication-and-consistency/</guid>
      <description>&lt;h1 id=&#34;replication-and-consistency&#34;&gt;Replication and consistency&lt;/h1&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;Ci sono due vantaggi principali nella replicazione dei dati&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Velocit√†&lt;/strong&gt;
&lt;ol&gt;
&lt;li&gt;Vicinanza geografica (quindi meno tempo ad andare a tornare)&lt;/li&gt;
&lt;li&gt;Maggiore computazione, quindi avere molti pi√π processori che cercano di offrire lo stesso servizio.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Affidabilit√†&lt;/strong&gt;
&lt;ol&gt;
&lt;li&gt;Cos√¨ se una sede diventa corrotta, posso avere abbondanza, avere una copia da una altra parte, cos√¨ non perdo le informazioni!&lt;/li&gt;
&lt;li&gt;Se una macchina cade in errore, ho altre macchine che lo sostituiscono! Quindi dal punto di vista dell‚Äôutente funziona ancora.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ma provare ad avere lo stesso dato in zone diverse porta a grandi problemi riguardo la &lt;strong&gt;consistenza&lt;/strong&gt;! Come facciamo ad avere la garanzia che due cose diverse abbiano la stessa informazione?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scheduler</title>
      <link>https://flecart.github.io/notes/scheduler/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/scheduler/</guid>
      <description>&lt;p&gt;Il suo scopo principale √® &lt;strong&gt;gestire l&amp;rsquo;avvicendamento dei processi.&lt;/strong&gt; Ad esempio sospendere il processo che chiede I/O. O un sistema time sharing, quando arriva un interrupt sul time.&lt;/p&gt;
&lt;p&gt;Solitamente il nome scheduler √® solamente un gestore dell&amp;rsquo;avvicendamento, si pu√≤ quindi utilizzare per indicare scheduler di altro tipo.&lt;/p&gt;
&lt;h2 id=&#34;note-introduttive&#34;&gt;Note introduttive&lt;/h2&gt;
&lt;h3 id=&#34;diagramma-di-gantt&#34;&gt;Diagramma di Gantt&lt;/h3&gt;
&lt;p&gt;Questo √® il diagramma per presentare lo scheduling, ossia da quando a quando √® eseguito cosa&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Esempio gantt&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sicurezza OS</title>
      <link>https://flecart.github.io/notes/sicurezza-os/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/sicurezza-os/</guid>
      <description>&lt;p&gt;Possiamo classificare tre aree generali quando si parla di sicurezza informatica:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hardware&lt;/li&gt;
&lt;li&gt;Software&lt;/li&gt;
&lt;li&gt;human-ware.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Non tratteremo in particolare esattamente come ogni campo viene declinato, per√≤ possiamo&lt;/p&gt;
&lt;p&gt;Una altra tendenza generale √® che &lt;strong&gt;pi√π √® complessa pi√π √® insicura&lt;/strong&gt;. e questo senso di insicurezza cresce in modo maggiore rispetto al lineare.&lt;/p&gt;
&lt;h3 id=&#34;security-principles&#34;&gt;Security principles&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Open Design&lt;/strong&gt; perch√© cos√¨ pu√≤ essere scrutata da pi√π persone&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Economy of mechanism&lt;/strong&gt; spiegata &lt;a href=&#34;https://flecart.github.io/notes#sistema-politica-e-meccanismi&#34;&gt;sotto&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fail-safe defaults&lt;/strong&gt; questo molto importante perch√© molti sistemi hanno dei default che possono essere exploitati.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Complete mediation&lt;/strong&gt;: cos√¨ abbiamo qualcosa che tracka tutti gli accessi, che &lt;em&gt;controlla&lt;/em&gt; gli accessi.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Least privilege&lt;/strong&gt; questo va a braccetto con il fail-safe.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Privilege separation&lt;/strong&gt; cos√¨ possiamo mettere in modo indipendente un privilegio per qualcos&amp;rsquo;altro.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;cia-properties&#34;&gt;CIA properties&lt;/h4&gt;
&lt;p&gt;Ne abbiamo parlato in modo leggermente inverso in &lt;a href=&#34;https://flecart.github.io/notes/sicurezza-delle-reti&#34;&gt;Sicurezza delle reti&lt;/a&gt; e in &lt;a href=&#34;https://flecart.github.io/notes/theoretical-notions-of-security&#34;&gt;Theoretical Notions of Security&lt;/a&gt;.
In questo caso sono&lt;/p&gt;</description>
    </item>
    <item>
      <title>Syncronous model</title>
      <link>https://flecart.github.io/notes/syncronous-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/syncronous-model/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Da ricordare il &amp;ldquo;The State Machine Replication (SMR) Problem&amp;rdquo; in &lt;a href=&#34;https://flecart.github.io/notes/consensus-protocols&#34;&gt;Consensus protocols&lt;/a&gt; che √® importantissimo per comprendere questa parte.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Storia locale&lt;/li&gt;
&lt;li&gt;Transazioni al singolo noto&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Problema del sync fra tutti questi nodi.&lt;/p&gt;
&lt;h3 id=&#34;goal-of-smr-solution-in-blockchains&#34;&gt;Goal of SMR solution in blockchains&lt;/h3&gt;
&lt;p&gt;Andiamo a considerare alcune propriet√† di safety e liveness &lt;a href=&#34;https://flecart.github.io/notes/programmi-concorrenti&#34;&gt;Programmi Concorrenti&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Consistenza&lt;/strong&gt; i nodi devono essere daccordo su quale transazione mettere prima e dopo ‚Üí stessa storia per tutte le transazioni. (con la possibilit√† di alcuni nodi che siano indietro, ma solo prefisso!).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Liveness&lt;/strong&gt; che vogliamo dire che tutte le transazioni valide devono essere aggiunte alla fine&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;assunzioni-per-sincrono-4&#34;&gt;Assunzioni per sincrono (4)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Permissioned&lt;/strong&gt;, ossia i nodi del nostro modello sono fissi, non possiamo averne di pi√π, non possiamo averne di meno e sono conosciuti.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Public key infrastructure&lt;/strong&gt;, Ogni nodo ha una coppia pubblica e privata.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Synchronous&lt;/strong&gt;,
&lt;ol&gt;
&lt;li&gt;esiste una sorta di stato globale, e tutti i nodi condividono questa informazione.
0, 1, ‚Ä¶ t.&lt;/li&gt;
&lt;li&gt;I messaggi sono tutti mandati bene, e arrivano esattamente uno step dopo. (mandato al tempo t, arriva a t + 1).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Onest√†&lt;/strong&gt; di tutti i nodi (sar√† lasciato subito questa assunzione).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;4‚Äô. Una percentuale dei nodi √® bizantina.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Analisi di Convessit√†</title>
      <link>https://flecart.github.io/notes/analisi-di-convessit%C3%A0/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/analisi-di-convessit%C3%A0/</guid>
      <description>&lt;p&gt;Questo argomento √® stato trattato durante dopo la discussione dei &lt;a href=&#34;https://flecart.github.io/notes/massimi-minimi-multi-variabile&#34;&gt;Massimi minimi multi-variabile&lt;/a&gt;, per√≤ √® stato ripreso anche nella forma R to R, quindi credo necessiti di un foglio a parte.&lt;/p&gt;
&lt;h3 id=&#34;affine-set&#34;&gt;Affine set&lt;/h3&gt;
&lt;h4 id=&#34;lines&#34;&gt;Lines&lt;/h4&gt;
$$
x = \theta x_{1} + (1 - \theta)x_{2}
$$&lt;p&gt;
This is a parametrization of the line
Example:&lt;/p&gt;
&lt;h4 id=&#34;def-affine-set&#34;&gt;Def: affine set&lt;/h4&gt;
&lt;p&gt;A combination where the coefficients &lt;strong&gt;add up to&lt;/strong&gt; 1.
We can say that this set is unique given two points.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Metodi di Discesa</title>
      <link>https://flecart.github.io/notes/metodi-di-discesa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/metodi-di-discesa/</guid>
      <description>&lt;h2 id=&#34;introduzione-ai-metodi-di-discesa&#34;&gt;Introduzione ai metodi di discesa.&lt;/h2&gt;
&lt;h3 id=&#34;generali-sui-metodi-di-discesa&#34;&gt;Generali sui metodi di discesa&lt;/h3&gt;
&lt;p&gt;Vogliamo creare algoritmi che riescano a trovare i punti di minimo delle funzioni non vincolate.&lt;/p&gt;
&lt;p&gt;In generale &lt;strong&gt;si trova un punto stazionario (condizioni necessarie)&lt;/strong&gt; ma non √® garantito lo stato ottimo.&lt;/p&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Metodi di Discesa/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Metodi di Discesa/Untitled&#34;&gt;
&lt;p&gt;Solitamente sono divisi in &lt;strong&gt;first order methods&lt;/strong&gt; in cui viene considerata solamente la derivata prima della funzione. E cose di metodi superiori.&lt;/p&gt;
&lt;h3 id=&#34;condizioni-di-arresto-classiche-2--&#34;&gt;Condizioni di arresto classiche (2) üü©-&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;</description>
    </item>
    <item>
      <title>Calcolo differenziale</title>
      <link>https://flecart.github.io/notes/calcolo-differenziale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/calcolo-differenziale/</guid>
      <description>&lt;h2 id=&#34;101-derivata-parziale&#34;&gt;10.1 Derivata parziale&lt;/h2&gt;
&lt;p&gt;La derivata vuole descrivere quanto varia una funzione al variare dell&amp;rsquo;input. Ma ora siamo in pi√π dimensioni, quindi vogliamo descrivere il variare dell&amp;rsquo;input come il variare della distanza euclidea&lt;/p&gt;
&lt;p&gt;$\dfrac{\delta f}{\delta x}(x,y) = \lim _{h \to 0} \dfrac{f(x + h, y) - f(x, y)}{h}$ ovvero sto facendo variare solamente una variabile (la y in questo caso √® come se fosse una costante!?) Questo √® un &lt;strong&gt;rapporto incrementale su una direzione&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Inner product spaces</title>
      <link>https://flecart.github.io/notes/inner-product-spaces/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/inner-product-spaces/</guid>
      <description>&lt;p&gt;This set of notes tries to fix what I haven&amp;rsquo;t learned in 2021 course in algebra. It&amp;rsquo;s about inner product spaces.
A good online reference on the topic is &lt;a href=&#34;https://rich-d-wilkinson.github.io/MATH3030/2.3-linalg-innerprod.html&#34;&gt;wilkinson&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;definitions&#34;&gt;Definitions&lt;/h2&gt;
&lt;h3 id=&#34;inner-product-space&#34;&gt;Inner product space&lt;/h3&gt;
&lt;p&gt;We define the &lt;a href=&#34;https://flecart.github.io/notes/spazi-vettoriali&#34;&gt;vector space&lt;/a&gt; $V$ to be a inner product space, if we define a inner product operator ($\langle \cdot, \cdot \rangle : V \times V \to R$) such that the following are valid:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It is linear on both arguments:
$$
\langle \alpha x_{1} + \beta x_{2}, y \rangle = \alpha \langle x_{1}, y \rangle  + \beta \langle x_{2}, y \rangle 
$$&lt;/li&gt;
&lt;li&gt;It is a &lt;strong&gt;symmetric operator&lt;/strong&gt;: $\langle x, y \rangle = \langle y, x \rangle$&lt;/li&gt;
&lt;li&gt;It is &lt;strong&gt;positive definite&lt;/strong&gt; that is we have $\forall x \in V: \langle x, x \rangle \geq 0$ with equality only if $x = \boldsymbol{0}$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;An example of such operator is the classical &lt;strong&gt;cosine distance&lt;/strong&gt; which is just the angle, or &lt;strong&gt;euclidean distance&lt;/strong&gt;. Also all $p-\text{norms}$ are inner products.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Analisi multi-variabile</title>
      <link>https://flecart.github.io/notes/analisi-multi-variabile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/analisi-multi-variabile/</guid>
      <description>&lt;p&gt;In questo capitolo cerchiamo di andare oltre alla singola dimensione per l&amp;rsquo;analisi.&lt;/p&gt;
&lt;h3 id=&#34;lo-spazio-mathbbrn&#34;&gt;Lo spazio $\mathbb{R}^{n}$&lt;/h3&gt;
&lt;p&gt;Possiamo definire uno spazio &lt;strong&gt;Rn&lt;/strong&gt; come il prodotto cartesiano fra l&amp;rsquo;insieme R un numero di volte uguale a n $\mathbb{R} \times \mathbb{R} \times ... \times\mathbb{R} = \mathbb{R}^n$&lt;/p&gt;
&lt;p&gt;Allora &lt;strong&gt;un tipico elemento&lt;/strong&gt; in Rn √® nella forma $(x_1,...,x_n)$, questo elemento si chiama punto, mentre gli elelmenti in R che costituiscono questo elemento si chiamano componenti.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Osservazione&lt;/strong&gt;
La maggior parte dei risultati che dimostro nello &lt;strong&gt;spazio ordinario (R3)&lt;/strong&gt; si pu√≤ dimostrare per Rn, non andiamo pi√π nel dettaglio perch√© i problemi che ho in spazi maggiori sono parte di materiale per analisi 2&lt;/p&gt;</description>
    </item>
    <item>
      <title>Duality Theory</title>
      <link>https://flecart.github.io/notes/duality-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/duality-theory/</guid>
      <description>&lt;p&gt;√à una branca dell&amp;rsquo;algebra lineare che ci permette di semplificare tutti i concetti.&lt;/p&gt;
&lt;h2 id=&#34;intro-dualit√†&#34;&gt;Intro dualit√†üü©&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&amp;quot;/images/notes/image/universita/ex-notion/Programmazione lineare/Untitled 8.png&amp;quot; style=&amp;quot;width: 100%&amp;quot; class=&amp;quot;center&amp;quot; alt=&amp;quot;image/universita/ex-notion/Programmazione lineare/Untitled 8&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Si fa una sorta di trasposta alla matrice di A.&lt;/li&gt;
&lt;li&gt;y √® pari al numero di righe di A&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La trasformazione al duale √® molto facile, ed √® abbastanza intuitiva una volta che capiamo che vogliamo andare a fare l‚Äôupper bound.&lt;/p&gt;
&lt;h3 id=&#34;dualit√†-asimmetrica-&#34;&gt;Dualit√† asimmetrica üü•+&lt;/h3&gt;
&lt;h3 id=&#34;teorema-debole-di-dualit√†-&#34;&gt;Teorema debole di dualit√† üü©&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;</description>
    </item>
    <item>
      <title>Insiemi numerici</title>
      <link>https://flecart.github.io/notes/insiemi-numerici/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/insiemi-numerici/</guid>
      <description>&lt;aside&gt;
üí° Questa prima parte degli appunti √® fortemente mancante
&lt;/aside&gt;
&lt;h2 id=&#34;11-insiemistica&#34;&gt;1.1 Insiemistica&lt;/h2&gt;
&lt;p&gt;Tutta Questa prima roba di insiemistica √® fatta molto meglio nel corso di logica, in particolare in questo documento&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://flecart.github.io/notes/teoria-assiomatica-degli-insiemi&#34;&gt;Teoria assiomatica degli insiemi&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;111-definizione-e-caratteristiche-degli-insiemi&#34;&gt;1.1.1 Definizione e caratteristiche degli insiemi&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Definizione di Campo ordinato (operazioni fra certi insiemi, sia per la addizione, per la moltiplicazione e simili)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Corpo commutativo&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sono definiti somma e moltiplicazione e propriet√† come commutativit√†, associativit√†, distributiva, inversi, opposti, zero e nullo&lt;/p&gt;</description>
    </item>
    <item>
      <title>R e Intervalli</title>
      <link>https://flecart.github.io/notes/r-e-intervalli/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/r-e-intervalli/</guid>
      <description>&lt;h2 id=&#34;21-necessit√†-e-caratteristiche-di-r&#34;&gt;2.1 Necessit√† e caratteristiche di R&lt;/h2&gt;
&lt;h3 id=&#34;211-radici-di-n-non-perfetti-e-q&#34;&gt;2.1.1 Radici di N non perfetti e Q&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/R e Intervalli/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/R e Intervalli/Untitled&#34;&gt;
&lt;p&gt;$\sqrt{n} \in \mathbb{Q} \implies n \text{ √® quadrato perfetto}$&lt;/p&gt;
&lt;p&gt;Fai lemma della divisibilit√† fra due numeri&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lemma:&lt;/strong&gt;
Dati $m,n,l$ tali che $MCD(m,l)=1$ e $l | m n$ allora  allora $l | n$
Questo si risolve con ragionamenti sui fattori di m e n.
Per dimostrare che √® razionale la radice di solamente una radice perfetta parto da un numero razionale, faccio certi ragionamenti e scoprir√≤ alla fine che il numero deve essere una radice perfetta.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stirling&#39;s Approximation</title>
      <link>https://flecart.github.io/notes/stirlings-approximation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/stirlings-approximation/</guid>
      <description>$$
x! \approx x^{x}e^{-x}\sqrt{ 2\pi x } \iff \ln x! \approx x\ln x - x  + \frac{1}{2} \ln(2\pi x)
$$&lt;p&gt;This proof (more like an interesting justification). is taken from page 2 of (MacKay 2003).&lt;/p&gt;
$$
P(r \mid \lambda) = \frac{e^{-\lambda}\lambda^{r}}{r!}
$$$$
e^{-\lambda} \frac{\lambda^{\lambda}}{\lambda!} \approx \frac{1}{\sqrt{ 2\pi \lambda }}
\implies \lambda! \approx \lambda^{\lambda}e^{-\lambda}\sqrt{ 2\pi \lambda }
$$&lt;p&gt;
Which finishes the derivation of the approximation.&lt;/p&gt;
&lt;h3 id=&#34;approximation-of-the-binomial&#34;&gt;Approximation of the binomial&lt;/h3&gt;
&lt;p&gt;A quick derivation with the Stirling&amp;rsquo;s approximation gives a nice approximation for log of the binomials&lt;/p&gt;</description>
    </item>
    <item>
      <title>Teoremi Base Analisi</title>
      <link>https://flecart.github.io/notes/teoremi-base-analisi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/teoremi-base-analisi/</guid>
      <description>&lt;h3 id=&#34;def-massimo-minimo-relativo-locale&#34;&gt;Def: Massimo minimo relativo (locale)&lt;/h3&gt;
$$
\exists r &gt; 0 : f(x) \leq f(x_{0}), \, \forall x \in \mathcal{A} \cap I_{r}(x_{0})
$$&lt;p&gt;
Dove $I_{r}(x_{0}) = \left[ x_{0} -r, x_{0} + r \right]$, √® un intorno&lt;/p&gt;
&lt;h3 id=&#34;def-massimo-minimo-assoluto&#34;&gt;Def: Massimo minimo assoluto&lt;/h3&gt;
$$
f(x) \leq f(x_{0}), \, \forall x \in \mathcal{A}
$$&lt;h2 id=&#34;fermat&#34;&gt;Fermat&lt;/h2&gt;
&lt;h3 id=&#34;621-ipotesi&#34;&gt;6.2.1 Ipotesi&lt;/h3&gt;
&lt;p&gt;Sia data una funzione $f: \left[ a, b \right] \to \mathbb{R}$
Se abbiamo che&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$x_{0} \in \left( a, b \right)$ √® un punto di massimo o minimo relativo&lt;/li&gt;
&lt;li&gt;$f$ √® derivabile in $x_{0}$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Implica che $f&#39;(x_{0}) = 0$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduzione a ottimizzazione Combinatoria</title>
      <link>https://flecart.github.io/notes/introduzione-a-ottimizzazione-combinatoria/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduzione-a-ottimizzazione-combinatoria/</guid>
      <description>&lt;p&gt;L‚Äôottimizzazione combinatoria √® un altro nome per la ricerca operativa. √à uno &lt;strong&gt;strumento&lt;/strong&gt; utile a prendere le decisioni migliori, fatto sta che √® anche molto utile al machine learning e si potrebbe dire che ne sia una base, questa √® una cosa molto buona.&lt;/p&gt;
&lt;h2 id=&#34;ricerca-operativa&#34;&gt;Ricerca operativa&lt;/h2&gt;
&lt;p&gt;Questo √® un campo a &lt;strong&gt;forte impatto economico&lt;/strong&gt; perch√© prova a minimizzare i costi e massimizzare i profitti.&lt;/p&gt;
&lt;h3 id=&#34;steps--&#34;&gt;Steps üü©, üü®&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Individuazione del problema (almeno riconoscere che ci sia un problema)&lt;/li&gt;
&lt;li&gt;Raccoglimento dei dati&lt;/li&gt;
&lt;li&gt;Modellizzazione del problema&lt;/li&gt;
&lt;li&gt;Ricerca di una soluzione&lt;/li&gt;
&lt;li&gt;Analisi dei risultati della soluzione&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;La ricerca operativa si interessa principalmente degli step 3 e 4, nonostante gli steps non sempre vengono eseguiti in maniera lineare, ma c‚Äô√® un ciclo di feedback a riguardo.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Modelizzazione</title>
      <link>https://flecart.github.io/notes/modelizzazione/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/modelizzazione/</guid>
      <description>&lt;h1 id=&#34;programmazione-lineare&#34;&gt;Programmazione lineare&lt;/h1&gt;
&lt;p&gt;Programmazione lineare contiene alcuni algoritmi utili per risolvere certi problemi di ottimizzazione.&lt;/p&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;Andiamo in questa sezione a definire un problema di programmazione lineare&lt;/p&gt;
&lt;h3 id=&#34;definizione--&#34;&gt;Definizione üü©-&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Variabili reali&lt;/em&gt; che saranno le variabili del nostro problema, sono in numero finito (eg. tutti in Rn)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Funzione obiettivo&lt;/em&gt; che ci definisce il costo $f: \R^n \to \R$&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Vincoli lineari&lt;/em&gt; che limitano il dominio delle variabili reali e li mettono in relazione fra di loro&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Se le variabili appartengono agli interi andiamo a parlare di &lt;strong&gt;programmazione lineare intera&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Simplesso e B&amp;B</title>
      <link>https://flecart.github.io/notes/simplesso-e-bb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/simplesso-e-bb/</guid>
      <description>&lt;h2 id=&#34;algoritmo-del-simplesso&#34;&gt;Algoritmo del simplesso&lt;/h2&gt;
&lt;h3 id=&#34;ricerca-della-direzione-migliore&#34;&gt;Ricerca della direzione migliore&lt;/h3&gt;
&lt;h3 id=&#34;ricerca-dello-step&#34;&gt;Ricerca dello step&lt;/h3&gt;
&lt;h3 id=&#34;pseudocodice&#34;&gt;Pseudocodice&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;
&lt;p&gt;B sono gli indici di partenza, poi questi vengono aggiornati&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Simplesso e B&amp;B/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Simplesso e B&amp;B/Untitled&#34;&gt;
&lt;p&gt;In riga 5 vado a checkare se ho &lt;strong&gt;direzioni di crescita possibili&lt;/strong&gt;, se √® tutto positivo non ne ho.&lt;/p&gt;
&lt;p&gt;in riga 6, si sceglie il pi√π piccol per &lt;strong&gt;evitare loop&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;L&amp;rsquo;idea in generale va in questo modo&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Cerco di trovare il duale e confrontarlo con la x attuale
&lt;ol&gt;
&lt;li&gt;Se sono uguali, allora ho trovato l‚Äôottimo ed esco&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Altrimenti cerco una direzione di crescita che sia anche ammissibile&lt;/li&gt;
&lt;li&gt;Continuo fino a trovare un vertice, se ho il vertice allora mi muovo l√¨ e riapplico,
altrimenti √® illimitata, se non esiste un vertice.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;correttezza&#34;&gt;Correttezza&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;</description>
    </item>
    <item>
      <title>Proximal Polixy Optimization</title>
      <link>https://flecart.github.io/notes/proximal-polixy-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/proximal-polixy-optimization/</guid>
      <description>&lt;p&gt;This documents attempts to briefly present the algorithm and some experiments found online about it.
The following repo seems to be a good resource: &lt;a href=&#34;https://github.com/ericyangyu/PPO-for-Beginners&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Usually, PPO is explained as an &lt;strong&gt;actor critic framework&lt;/strong&gt;. This means there is an &lt;em&gt;agent&lt;/em&gt; that acts on the environment, and then there is a &lt;em&gt;critic&lt;/em&gt; that collects the feedback from the environment.
The main idea about this framework is to &lt;em&gt;select&lt;/em&gt; a policy that is similar, so that it is &lt;em&gt;less probable&lt;/em&gt; that a bad policy, a very different policy from the original is selected. This is achieved by clipping over the advantage. And then&lt;/p&gt;</description>
    </item>
    <item>
      <title>Geometrie di spire</title>
      <link>https://flecart.github.io/notes/geometrie-di-spire/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/geometrie-di-spire/</guid>
      <description>&lt;h3 id=&#34;spire&#34;&gt;Spire&lt;/h3&gt;
&lt;h4 id=&#34;spira-quadrata&#34;&gt;Spira quadrata&lt;/h4&gt;
&lt;p&gt;Questo √® descritto nell&amp;rsquo;esempio 8.1 del Mazzoldi.
√à stato descritto anche in un esercizio in classe (non √® importante).&lt;/p&gt;
&lt;h4 id=&#34;spira-circolare-&#34;&gt;Spira circolare üü©&lt;/h4&gt;
&lt;p&gt;Vedere pagina 245
Vogliamo cercare il valore del campo sull&amp;rsquo;asse della spira circolare.
&lt;img src=&#34;https://flecart.github.io/images/notes/Geometrie di spire-1704296692075.jpeg&#34; width=&#34;500&#34; class=&#34;center&#34; alt=&#34;Geometrie di spire-1704296692075&#34;/&gt;
Questo √® semplice, basta usare la prima di Laplace e trovare l&amp;rsquo;apporto del campo magnetico al centro.
Si pu√≤ anche pensare come momento magnetico, allora si utilizza sempre lo stesso discorso per la spira quadrata classica e il suo momento.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Algebra lineare numerica</title>
      <link>https://flecart.github.io/notes/algebra-lineare-numerica/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/algebra-lineare-numerica/</guid>
      <description>&lt;p&gt;In questa sezione andiamo ad indagare metodi di &lt;strong&gt;scomposizione&lt;/strong&gt;, iterativi e non. Ci sono molte matrici importanti per questa parte che dovremmo prendere confidenza.&lt;/p&gt;
&lt;h4 id=&#34;immagini&#34;&gt;Immagini&lt;/h4&gt;
&lt;p&gt;Lab 2 images&lt;/p&gt;
&lt;h2 id=&#34;metodo-di-gauss&#34;&gt;Metodo di gauss&lt;/h2&gt;
&lt;p&gt;Vogliamo cercare un metodo per calcolare soluzioni a sistemi di equazione del genere:&lt;/p&gt;
&lt;p&gt;$Ax = b$, classico. Supponiamo che questo sistema abbia una soluzione.&lt;/p&gt;
&lt;p&gt;Il nostro obiettivo sarebbe scomporre la matrice $A = LU$
come prodotto di due matrici Lower triangular e Upper triangular.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Algebra modulare</title>
      <link>https://flecart.github.io/notes/algebra-modulare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/algebra-modulare/</guid>
      <description>&lt;h1 id=&#34;algebra-modulare&#34;&gt;Algebra modulare&lt;/h1&gt;
&lt;h2 id=&#34;assunzioni&#34;&gt;Assunzioni&lt;/h2&gt;
&lt;p&gt;Andiamo ora ad assumere  l&amp;rsquo;esistenza e correttezza di alcune cose di base. (in teoria si possono dimostrare da cose pi√π di base, ma non ho tempo).&lt;/p&gt;
&lt;h3 id=&#34;teorema-fondamentale-dellalgebra&#34;&gt;Teorema fondamentale dell&amp;rsquo;algebra&lt;/h3&gt;
&lt;p&gt;Ogni numero intero si fattorizza in modo unico.&lt;/p&gt;
&lt;h3 id=&#34;algoritmo-di-euclide&#34;&gt;Algoritmo di Euclide&lt;/h3&gt;
&lt;p&gt;La conseguenza pi√π importante di questo teorema, dovuto ad Euclide √® che
se ho $a, b \in \mathbb{Z}$ allora esistono resto e dividendo fra i due. Ossia
$\exists q, p : a\mid b = qk + p$ per qualche $k$ intero&lt;/p&gt;</description>
    </item>
    <item>
      <title>Applicazioni lineari</title>
      <link>https://flecart.github.io/notes/applicazioni-lineari/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/applicazioni-lineari/</guid>
      <description>&lt;h2 id=&#34;31-introduzione-e-definizione&#34;&gt;3.1 Introduzione e definizione&lt;/h2&gt;
&lt;p&gt;Si definisce applicazione lineare una funzione (omomorfica) che preserva la struttura dello spazio vettoriale, ossia vale che&lt;/p&gt;
$$
f:V \to W, \text{ tale che } \\
f(u + v) = f(u) +f(v)\\,
f(\lambda v) = \lambda f(v)
$$&lt;p&gt;
Vengono mantenute alcune caratteristiche principali.
In modo simile si possono definire omomorfismi per tutte le altre strutture algebriche, la cosa importante √® che lo spazio d&amp;rsquo;arrivo possieda ancora tutte le stesse operazioni.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Base e dimensione</title>
      <link>https://flecart.github.io/notes/base-e-dimensione/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/base-e-dimensione/</guid>
      <description>&lt;h2 id=&#34;21-basi&#34;&gt;2.1 Basi&lt;/h2&gt;
&lt;h3 id=&#34;211-definizione&#34;&gt;2.1.1 Definizione&lt;/h3&gt;
&lt;p&gt;Un insieme di vettori $v_1,...,v_n$ sono basi di uno spazio vettoriale $V$ se sono soddisfatte queste propriet√†&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$V = \langle v_1,...,v_n\rangle$&lt;/li&gt;
&lt;li&gt;$v_1,...,v_n$ sono linearmente indipendenti&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Dalla propriet√† 2 potremmo anche dire che √® il minimo insieme di vettori necessario per avere questa base.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Finitamente generato&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Se l&amp;rsquo;insieme dei vettori nella base √® finito allora posso dire che √® finitamente generato&lt;/p&gt;
&lt;p&gt;Ma possiamo trovare anche spazi che non sono finitamente generati come $\R[x]$ che non hanno un numero finito di basi (perch√© dipende dal grado dei polinomi che pu√≤ essere infinito).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cambio di Base</title>
      <link>https://flecart.github.io/notes/cambio-di-base/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cambio-di-base/</guid>
      <description>&lt;h2 id=&#34;nozioni-da-avere-prima-di-cambio-di-base&#34;&gt;Nozioni da avere prima di Cambio di Base&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://flecart.github.io/notes/applicazioni-lineari&#34;&gt;Applicazioni lineari&lt;/a&gt;
&lt;ol&gt;
&lt;li&gt;La definizione di applicazione lineare&lt;/li&gt;
&lt;li&gt;La matrice associata&lt;/li&gt;
&lt;li&gt;L&amp;rsquo;esistenza e unicit√† di una applicazione lineare rispetto a una base&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Le coordinate di un punto rispetto a una base.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;matrice-del-cambio-di-base&#34;&gt;Matrice del Cambio di Base&lt;/h2&gt;
&lt;p&gt;Se ho due spazi vettoriali&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Intuizione in $R$
Le coordinate dei punti in $R$ sono uguali a $V$ per le basi canoniche, ma questo vale solamente per $R$, ora vogliamo andare a dire una cosa pi√π forte, il cambio di base
Poi sar√† importantissimo questa nozione, applicazione di base in ML √® Principal Component Analysis.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Se ho una applicazione lineare $F: V \to W$ e un insieme di basi del dominio e del codominio, allora esiste una matrice $A \in M_{m \times n} (\mathbb{R})$ tali che vale il cambio di base.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Determinanti</title>
      <link>https://flecart.github.io/notes/determinanti/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/determinanti/</guid>
      <description>&lt;h2 id=&#34;determinanti&#34;&gt;Determinanti&lt;/h2&gt;
&lt;p&gt;I determinanti sono un numero associato alle matrici quadrate. Pi√π o meno ne sono il riassunto.&lt;/p&gt;
&lt;h3 id=&#34;propriet√†&#34;&gt;Propriet√†&lt;/h3&gt;
&lt;p&gt;Le prime 3 sono quelle fondamentali per calcolare il tutto, i numeri dopo il 3 sono alcune conseguenze.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;det I = 1&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cambiare righe ‚Üí cambiare il segno della determinante.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Importante)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Se moltiplico una riga per una costante, il determinante √® moltiplicato per questa costante.&lt;/li&gt;
&lt;li&gt;Se sommo una costante a una riga, allora il determinante √® una somma strana&amp;hellip;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Immagine di esempio&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduzione algebra</title>
      <link>https://flecart.github.io/notes/introduzione-algebra/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduzione-algebra/</guid>
      <description>&lt;p&gt;Tutta sta parte si fa in modo formale in &lt;a href=&#34;https://flecart.github.io/notes/sistemi-lineari-e-determinanti&#34;&gt;Sistemi Lineari e determinanti&lt;/a&gt;, quindi potresti saltarla totalmente&lt;/p&gt;
&lt;h2 id=&#34;equazioni-lineari&#34;&gt;Equazioni lineari&lt;/h2&gt;
&lt;p&gt;L&amp;rsquo;obiettivo dell&amp;rsquo;algebra lineare √® risolvere n equazioni con n sconosciuti di primo grado.
Cosa che ci riesce con grandissimo successo! Andiamo ora a definire meglio cosa √® una equazione lineare&lt;/p&gt;
&lt;h3 id=&#34;definizione&#34;&gt;Definizione&lt;/h3&gt;
&lt;p&gt;Una equazione lineare √® una equazione a coefficienti appartenenti a un certo campo (che pu√≤ essere R) e incognite il cui grado √® 1 e che siano indipendenti:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Measure Theory</title>
      <link>https://flecart.github.io/notes/measure-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/measure-theory/</guid>
      <description>&lt;p&gt;Ultima modifica: September 18, 2022 9:43 AM
Primo Abbozzo: September 16, 2022 9:52 AM
Studi Personali: Yes&lt;/p&gt;
&lt;h1 id=&#34;elementi-di-ripasso&#34;&gt;Elementi di ripasso&lt;/h1&gt;
&lt;h1 id=&#34;measure-theory&#34;&gt;Measure Theory&lt;/h1&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;requirements-of-the-measure-function&#34;&gt;Requirements of the measure function&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Measure Theory/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Measure Theory/Untitled&#34;&gt;
&lt;p&gt;Vorremmo cercare di &lt;strong&gt;estendere il concetto di misurabilit√†&lt;/strong&gt; a gruppi molto pi√π ampi di un singolo intervallo, vorrei creare una funzione che sia in grado di misurare degli insiemi. *su vedr√† che sono impossibili).&lt;/p&gt;
&lt;h3 id=&#34;impossibilit√†-di-questi-requirements-assurdo&#34;&gt;Impossibilit√† di questi requirements (assurdo)&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Measure Theory/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Measure Theory/Untitled 1&#34;&gt;
&lt;p&gt;&lt;strong&gt;Costruzione dell‚Äôinsieme di interesse&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sistemi Lineari e determinanti</title>
      <link>https://flecart.github.io/notes/sistemi-lineari-e-determinanti/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/sistemi-lineari-e-determinanti/</guid>
      <description>&lt;h2 id=&#34;41-sistemi-lineari&#34;&gt;4.1 Sistemi lineari&lt;/h2&gt;
&lt;p&gt;La cosa buona √® che possiamo analizzare il sistema lineare utilizzando tutti i teoremi che abbiamo sviluppato finora, quindi siamo molto pi√π potenti per attaccare questo problema.&lt;/p&gt;
&lt;p&gt;Definiamo un sistema lineare cos√¨&lt;/p&gt;
&lt;p&gt;$Ax = b$ con A la matrice associata.&lt;/p&gt;
&lt;h3 id=&#34;411-preimmagine&#34;&gt;4.1.1 Preimmagine&lt;/h3&gt;
&lt;p&gt;Data una applicazione lineare $F:V \to W$, allora la controimmagine √® l&amp;rsquo;insieme dei vettori di V che fanno a finire in quel punto, in matematichese:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gruppi</title>
      <link>https://flecart.github.io/notes/gruppi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/gruppi/</guid>
      <description>&lt;h2 id=&#34;definizione-gruppo&#34;&gt;Definizione gruppo&lt;/h2&gt;
&lt;p&gt;Qualunque insieme pi√π operazione tale per cui:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Esistenza dell&amp;rsquo;inverso per ogni elemento $\forall g \in G, \exists g^{-1} \in G : gg^{-1} = e$&lt;/li&gt;
&lt;li&gt;Esistenza di un elemento neutro $\exists e \in G: \forall g \in G, eg = g$&lt;/li&gt;
&lt;li&gt;Associativit√†: $(gh)f = g(hf)$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Closure&lt;/strong&gt;: $\forall g, h \in G \implies gh \in G$&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;unicit√†-dellelemento-neutro&#34;&gt;Unicit√† dell‚Äôelemento neutro&lt;/h3&gt;
&lt;p&gt;Supponiamo di avere un gruppo $G$ e due elementi neutri $e, f$
Allora abbiamo che
$ae = a = af$ per√≤ se moltiplichiamo per l&amp;rsquo;inversa abbiamo che
$a^{-1}ae = a^{-1}af \implies e = f$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gruppi ciclici e permutazioni</title>
      <link>https://flecart.github.io/notes/gruppi-ciclici-e-permutazioni/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/gruppi-ciclici-e-permutazioni/</guid>
      <description>&lt;h1 id=&#34;gruppi-ciclici-e-permutazioni&#34;&gt;Gruppi ciclici e permutazioni&lt;/h1&gt;
&lt;h2 id=&#34;il-gruppo-ciclico&#34;&gt;Il gruppo ciclico&lt;/h2&gt;
&lt;h3 id=&#34;definizione-gruppo-ciclico&#34;&gt;Definizione gruppo ciclico&lt;/h3&gt;
&lt;p&gt;Abbiamo definito in &lt;a href=&#34;https://flecart.github.io/notes/gruppi&#34;&gt;Gruppi&lt;/a&gt; per la prima volta il significato di gruppo ciclico generato da un elemento del gruppo, questo insieme si √® poi dimostrato essere un sottogruppo del gruppo&lt;/p&gt;
$$
G = \left\{ a^{n} \mid n \in \mathbb{Z} \right\} 
$$&lt;p&gt;
Dove &lt;strong&gt;a&lt;/strong&gt; √® chiamato &lt;strong&gt;elemento generatore&lt;/strong&gt;.&lt;/p&gt;
$$
ord(G) = \lvert \langle a \rangle  \rvert 
$$&lt;h3 id=&#34;criterio-ai--aj&#34;&gt;Criterio $a^{i} = a^{j}$&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Gruppi ciclici e permutazioni/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Gruppi ciclici e permutazioni/Untitled 1&#34;&gt;
Probabilmente ha qualche relazione con &lt;a href=&#34;https://flecart.github.io/notes/teorema-di-lagrange&#34;&gt;Teorema di Lagrange&lt;/a&gt;.
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;note sull&amp;rsquo;enunciato
entrambe le frecce $\impliedby$ sono abbastanza ovvie.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Common problems in Theoretical CS</title>
      <link>https://flecart.github.io/notes/common-problems-in-theoretical-cs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/common-problems-in-theoretical-cs/</guid>
      <description>&lt;p&gt;This note is useful to gather in a single place the description of some common problems in CS and their theoretical implications explained in other notes.&lt;/p&gt;
&lt;h2 id=&#34;the-clique-problem&#34;&gt;The Clique problem&lt;/h2&gt;
&lt;h3 id=&#34;description-of-the-problem&#34;&gt;Description of the problem&lt;/h3&gt;
&lt;p&gt;This problem is in NP, find all sub-graphs where all nodes are connected (this set of nodes forms a complete graph).&lt;/p&gt;
&lt;p&gt;We can prove that the problem is in NP because there is an easy non-deterministic algorithm that computes it.
See &lt;a href=&#34;https://flecart.github.io/notes/time-and-space-complexity#clique-problem&#34;&gt;Time and Space Complexity#Clique problem&lt;/a&gt; for details of this proof.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Complexity Hierarchies</title>
      <link>https://flecart.github.io/notes/complexity-hierarchies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/complexity-hierarchies/</guid>
      <description>&lt;p&gt;Intractable problems are solvable in principle, but in reality they require so much time or space that there no physical computers that can solve them in reasonable time.
We would like to define a clear hierarchy of these set of problems.&lt;/p&gt;
&lt;h2 id=&#34;space-hierarchies&#34;&gt;Space Hierarchies&lt;/h2&gt;
&lt;h3 id=&#34;def-space-constructible&#34;&gt;Def: Space constructible&lt;/h3&gt;
&lt;p&gt;We say that a function $f: \mathbb{N} \to \mathbb{N}$ such that $f(n) \geq O(\log n)$ is space constructible if there exists a function from $1^{n} \to \langle f(n) \rangle$ is $O(f(n))$ &lt;a href=&#34;https://flecart.github.io/notes/time-and-space-complexity&#34;&gt;space complexity&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cook-Levin and Savitch</title>
      <link>https://flecart.github.io/notes/cook-levin-and-savitch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cook-levin-and-savitch/</guid>
      <description>&lt;p&gt;Cook Levin theorem is important because says that in 1971 if $SAT \in P$ then $NP = P$. We will start with this idea to define the concept of &lt;strong&gt;NP-completeness&lt;/strong&gt;. Let&amp;rsquo;s start with the basics.&lt;/p&gt;
&lt;h3 id=&#34;poly-reduction&#34;&gt;Poly-reduction&lt;/h3&gt;
&lt;h4 id=&#34;def-poly-reduction&#34;&gt;Def: poly-reductionüü©&lt;/h4&gt;
$$
x \in L&#39; \iff f(x) \in L
$$&lt;p&gt;
This is very similar to the &lt;a href=&#34;https://flecart.github.io/notes/halting-theorem-and-reducibility#mapping-reducibility&#34;&gt;Halting Theorem and Reducibility#Mapping reducibility&lt;/a&gt;.
The difference is that it needs to be &lt;em&gt;polynomially-bounded&lt;/em&gt;, so to say, it is efficient function.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Halting Theorem and Reducibility</title>
      <link>https://flecart.github.io/notes/halting-theorem-and-reducibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/halting-theorem-and-reducibility/</guid>
      <description>&lt;h3 id=&#34;halting-theorem&#34;&gt;Halting theorem&lt;/h3&gt;
&lt;p&gt;Questo √® un problema fondamentale, che abbiamo trattato anche in &lt;a href=&#34;https://flecart.github.io/notes/fondamenti-teorica#halting-problem&#34;&gt;Fondamenti teorica#Halting problem&lt;/a&gt;, ma qui lo ritrattiamo, perch√© cos√¨ lo rifacciamo per bene. In parte √® stato trattato anche al corso di Logica.&lt;/p&gt;
&lt;h4 id=&#34;enunciato-halting-theorem&#34;&gt;Enunciato Halting theoremüü©&lt;/h4&gt;
$$
HALT = \left\{ \langle x, y \rangle \in \Sigma^{*} \times \Sigma^{*}: x = code(M),M \text{ si ferma su } x\right\}
$$&lt;h4 id=&#34;dimostrazione-halting-theorem&#34;&gt;Dimostrazione Halting theoremüü©&lt;/h4&gt;
&lt;p&gt;La parte del s√¨ √® facile perch√© basta eseguirlo e vedere che si ferma (quindi abbiamo una &lt;a href=&#34;https://flecart.github.io/notes/la-macchina-di-turing#la-macchina-di-turing-universale&#34;&gt;La macchina di Turing#La macchina di Turing universale&lt;/a&gt;. Se si ferma appartiene al linguaggio, altrimenti √® la parte in cui diverge.&lt;/p&gt;</description>
    </item>
    <item>
      <title>La macchina di Turing</title>
      <link>https://flecart.github.io/notes/la-macchina-di-turing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/la-macchina-di-turing/</guid>
      <description>&lt;h3 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h3&gt;
&lt;h4 id=&#34;note-filosofiche-non-impo&#34;&gt;Note filosofiche (non impo)&lt;/h4&gt;
&lt;p&gt;Bisogna in primo momento cercare di definire &lt;strong&gt;cosa √® la computazione&lt;/strong&gt; e cosa √® un computer.
Aristotele faceva la distinzione fra propriet√† &lt;strong&gt;essenziali&lt;/strong&gt; e &lt;strong&gt;accidentali&lt;/strong&gt;. Quelle essenziali sono proprie dell&amp;rsquo;oggetto.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Una sedia pu√≤ essere fatta di legno o di metallo, ma questa propriet√† √® accidentale, ovvero, essa rimane una sedia indipendentemente dal materiale di cui √® fatta.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Solitamente in matematica si prova ad astrarre (vedi &lt;a href=&#34;https://flecart.github.io/notes/astrazione-sul-controllo&#34;&gt;Astrazione sul controllo&lt;/a&gt; per nota generale sull&amp;rsquo;astrazione). Per√≤ in questo campo si sono trovati molte concezioni equivalenti. Fino ad arrivare a concepire la tesi di Church-Turing. Il prof. nota che questo √® strano, perch√© in altre discipline si converge in unico modello, mentre qui molte cose sono indifferenti.
Questo √® importante per capire come la concezione di Computer Science si √® evoluta &lt;a href=&#34;https://dl.acm.org/doi/10.1145/1880066.1880067&#34;&gt;(Denning 2010)&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Teorema di Rice</title>
      <link>https://flecart.github.io/notes/teorema-di-rice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/teorema-di-rice/</guid>
      <description>&lt;h2 id=&#34;introduction-to-the-rice-theorem&#34;&gt;Introduction to the Rice Theorem&lt;/h2&gt;
&lt;p&gt;Ci sono molti teoremi che non possono essere decisi, vedere &lt;a href=&#34;https://flecart.github.io/notes/halting-theorem-and-reducibility&#34;&gt;Halting Theorem and Reducibility&lt;/a&gt;.
Qui andiamo a chiederci quale sia l&amp;rsquo;insieme dei problemi decidibili.&lt;/p&gt;
&lt;h3 id=&#34;propriet√†-dei-linguaggi-tm&#34;&gt;Propriet√† dei linguaggi TMüü©&lt;/h3&gt;
$$
L_{\mathcal{M}} = \left\{ x \in \Sigma^{*}: \mathcal{M} \text{ accetta } x \right\} 
$$$$
L_{\mathcal{M}} = L_{\mathcal{M}&#39;} \implies P(\mathcal{M}) = P(\mathcal{M}&#39;)
$$&lt;p&gt;
Definiamo questa &lt;strong&gt;non triviale&lt;/strong&gt; se esiste una macchina per cui √® 0, e una per cui √® 1 (ossia non √® costante).
Practically this definition is useful when we need to have a difference between the language and the Turing machine that decides that language.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fn Ordine superiore</title>
      <link>https://flecart.github.io/notes/fn-ordine-superiore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/fn-ordine-superiore/</guid>
      <description>&lt;p&gt;Questa parte √® strettamente collegata conl a parte di &lt;a href=&#34;https://flecart.github.io/notes/astrazione-sul-controllo&#34;&gt;Astrazione sul controllo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Si parla di &lt;strong&gt;passare le funzioni come dati&lt;/strong&gt;. e quindi possono essere passati come se fossero dei parametri.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;un linguaggio di programmazione √® di ordine superiore qualora
ammetta funzioni sia come parametro che come risultato di altre funzioni.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;La parte molto simile alla precedente √® il fatto di &lt;strong&gt;valutare&lt;/strong&gt; la funzione nell&amp;rsquo;ambiente iniziale, quindi bisogna utilizzare un sistema simile a quello del passaggio per nome.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Probabilistic Turing Machines</title>
      <link>https://flecart.github.io/notes/probabilistic-turing-machines/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/probabilistic-turing-machines/</guid>
      <description>&lt;h2 id=&#34;introduction-to-the-probabilistic-turing-machine&#34;&gt;Introduction to the probabilistic Turing Machine&lt;/h2&gt;
&lt;p&gt;Most of real phenomena are better comprehended by a probabilistic view. This pushes to build a formal model that takes probability into account&lt;/p&gt;
&lt;h3 id=&#34;def-probabilistic-tm&#34;&gt;Def: Probabilistic TM&lt;/h3&gt;
$$
\mathbb{P}(b) = 2^{-k}
$$&lt;p&gt;
Where $k$ is the length of the branch.
Then the probability of accepting the word is given by this:&lt;/p&gt;
$$
\mathbb{P}(\mathcal{M} \text{ accepts }  \omega) = \sum_{b \text{ is an accepting branch}} \mathbb{P}(b)
$$&lt;p&gt;
Note that this is very similar to the Algorithmic probability defined in &lt;a href=&#34;https://flecart.github.io/notes/kolmogorov-complexity&#34;&gt;Kolmogorov complexity&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Compression Algorithms</title>
      <link>https://flecart.github.io/notes/compression-algorithms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/compression-algorithms/</guid>
      <description>&lt;h3 id=&#34;lempel-ziv-welch-algorithm&#34;&gt;Lempel-Ziv-Welch Algorithm&lt;/h3&gt;
&lt;h4 id=&#34;introduzione-sul-funzionamento&#34;&gt;Introduzione sul funzionamento&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Primo scan con un dizionario indexato dei singoli caratteri&lt;/li&gt;
&lt;li&gt;Poi viene cercato di raggruppare caratteri a coppie.&lt;/li&gt;
&lt;li&gt;Se una coppia √® gi√† presente nel dizionario, allora aggiungo al dizionario una cosa pi√π lunga e metto un code diverso&lt;/li&gt;
&lt;li&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Introduction to Algorithmic Information and Complexity-20240217115716857.webp&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Introduction to Algorithmic Information and Complexity-20240217115716857&#34;&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Esempio di sopra.
La cosa carina √® che il dizionario si pu√≤ ricostruire in fase di decoding.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Astrazione sul controllo</title>
      <link>https://flecart.github.io/notes/astrazione-sul-controllo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/astrazione-sul-controllo/</guid>
      <description>&lt;h2 id=&#34;significato-di-astrazione&#34;&gt;Significato di astrazione&lt;/h2&gt;
&lt;p&gt;L&amp;rsquo;astrazione √® una cosa fondamentale nell&amp;rsquo;informatica, l‚Äôabbiamo visto anche nella prima lezione in assoluto per architettura, il sistema a strati di &lt;a href=&#34;https://flecart.github.io/notes/architettura-e-livelli-1,-2&#34;&gt;Architettura e livelli 1, 2&lt;/a&gt; reti e simili.&lt;/p&gt;
&lt;p&gt;Il principali metodi sono &lt;strong&gt;astrazioni sul controllo e sui dati&lt;/strong&gt; sui dati stiamo cominciando a parlarne in &lt;a href=&#34;https://flecart.github.io/notes/teoria-dei-tipi&#34;&gt;Teoria dei Tipi&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Le astrazioni sono utili a &lt;strong&gt;nascondere dettagli&lt;/strong&gt; per qualche fenomeno o simile (ricorda l&amp;rsquo;esempio della mappa, che non √® il territorio √® una astrazione su essa, che contiene ancora informazioni utili). Vogliamo quindi &lt;strong&gt;concentrarci su quanto ci interessa&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Automi e Regexp</title>
      <link>https://flecart.github.io/notes/automi-e-regexp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/automi-e-regexp/</guid>
      <description>&lt;p&gt;Per l‚Äôanalisi lessicale vogliamo cercare di ricordare le &lt;strong&gt;parole legali&lt;/strong&gt; all&amp;rsquo;interno di questo linguaggio e questo √® fatto con i linguaggi regolari.&lt;/p&gt;
&lt;h2 id=&#34;introduzione-a-analizzatori-lessicali&#34;&gt;Introduzione a analizzatori lessicali&lt;/h2&gt;
&lt;h3 id=&#34;token-&#34;&gt;Token üü©&lt;/h3&gt;
&lt;p&gt;Struttura del token √® fatto da due parti&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identificatore della classe del token&lt;/li&gt;
&lt;li&gt;Identificatore del valore del token&lt;/li&gt;
&lt;li&gt;Pattern e lessema ci sono direi boh&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pattern-e-lessema-&#34;&gt;Pattern e Lessema üü©&lt;/h3&gt;
&lt;p&gt;I pattern sono una descrizione generale della forma dei valori di una classe di token.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bottom-up Parser LR(0)</title>
      <link>https://flecart.github.io/notes/bottom-up-parser-lr0/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/bottom-up-parser-lr0/</guid>
      <description>&lt;p&gt;Descrivo ora alcune domande utili per ripasso:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Quali sono schematicmente quali sono le operazioni migliori per un parser top-down?&lt;/li&gt;
&lt;li&gt;Cosa √® un prefisso viabile?&lt;/li&gt;
&lt;li&gt;Quali sono i conflitti possibli, e come risolverli‚Ä¶&lt;/li&gt;
&lt;li&gt;Non sai nemmeno definire inmodo formale cosa sia un item&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;bottom-up&#34;&gt;Bottom up&lt;/h2&gt;
&lt;h3 id=&#34;intro-shift-reduce-e-lr-&#34;&gt;Intro shift-reduce e LR üü©&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Bottom-up Parser LR(0)/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Bottom-up Parser LR(0)/Untitled 1&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In breve:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Shift = simbolo terminale messo nella stack&lt;/li&gt;
&lt;li&gt;Riduzione utilizzando una produzione&lt;/li&gt;
&lt;li&gt;LR = dettura da Sinistra, creazione della stringa da destra (derivazione rightmost)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;algoritmo-classico-&#34;&gt;Algoritmo classico üü®+&lt;/h3&gt;
&lt;p&gt;Quello che credo che intendevo per questo algoritmo classico √® quello non deterministico, nel senso che prova a fare backtracking, finch√© non ha finito tutte le possibilit√†, oppure trova la derivazione giusta.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bottom-up Parser LR(1)</title>
      <link>https://flecart.github.io/notes/bottom-up-parser-lr1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/bottom-up-parser-lr1/</guid>
      <description>&lt;p&gt;Si pu√≤ osservare che per il parser costruito in &lt;a href=&#34;https://flecart.github.io/notes/bottom-up-parser-lr(0&#34;&gt;Bottom-up Parser LR(0)&lt;/a&gt;), non riesce a riconoscere di linguaggi semplici come $L = \{a, ab\}$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Esempio di quanto detto
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Bottom-up Parser -LR(1)/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Bottom-up Parser -LR(1)/Untitled 1&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;parser-slr1&#34;&gt;Parser SLR(1)&lt;/h2&gt;
&lt;p&gt;Questi parser qui utilizzano l‚Äôidea del look ahead ampiamente utilizzata in &lt;a href=&#34;https://flecart.github.io/notes/top-down-parser&#34;&gt;Top-down Parser&lt;/a&gt;, per escludere molte produzioni.&lt;/p&gt;
&lt;p&gt;La s sta per &lt;strong&gt;simple&lt;/strong&gt;, perch√© utilizza una idea semplice :D, credo ahah boh.&lt;/p&gt;
&lt;h3 id=&#34;riduzione-con-follow-&#34;&gt;Riduzione con follow üü©&lt;/h3&gt;
&lt;p&gt;noi vogliamo &lt;strong&gt;ridurre solamente se ho follow&lt;/strong&gt; corretto il terminale finale della stringa.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Explainability of CNN</title>
      <link>https://flecart.github.io/notes/explainability-of-cnn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/explainability-of-cnn/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Capire in che modo una rete convoluzionale ci pu√≤ dare insight migliori su come funzionano questi networks.&lt;/p&gt;
&lt;h3 id=&#34;visualizzazione-dei-hidden-layers&#34;&gt;Visualizzazione dei hidden layers&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide visualization&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Explainability of CNN/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Explainability of CNN/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Potremmo fissare una immagine anche a caso, e modificare la x in modo che sia pi√π simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fondamenti teorica</title>
      <link>https://flecart.github.io/notes/fondamenti-teorica/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/fondamenti-teorica/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://virtuale.unibo.it/pluginfile.php/1295166/mod_resource/content/0/Lez18-Gorrieri.pdf&#34;&gt;&lt;a href=&#34;https://virtuale.unibo.it/pluginfile.php/1295166/mod_resource/content/0/Lez18-Gorrieri.pdf&#34;&gt;https://virtuale.unibo.it/pluginfile.php/1295166/mod_resource/content/0/Lez18-Gorrieri.pdf&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;halting-problem&#34;&gt;Halting problem&lt;/h2&gt;
&lt;p&gt;Questo asserisce che &lt;strong&gt;non esiste nessun programma che sia in grado di decidere la terminazione di un altro programma&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Questo √® un problema che ci √® interessante perch√© vorremmo costruire un compilatore che  sia in grado di osservare &lt;strong&gt;tutti gli errori possibili&lt;/strong&gt; del programma. Come vedremo tra poco la risposta sar√† negativa.&lt;/p&gt;
&lt;h3 id=&#34;dimostrazione-tesi-&#34;&gt;Dimostrazione tesi üü®++&lt;/h3&gt;
&lt;p&gt;Supponiamo che questo programma esista, lo chiamiamo &lt;code&gt;check(P)&lt;/code&gt; che restituisce 0 se termina 1 se non termina, allora devo poter essere in grado di scrivere un programma di questo genere&lt;/p&gt;</description>
    </item>
    <item>
      <title>Garbage Collection</title>
      <link>https://flecart.github.io/notes/garbage-collection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/garbage-collection/</guid>
      <description>&lt;h2 id=&#34;on-dangling-pointers&#34;&gt;On dangling pointers&lt;/h2&gt;
&lt;h3 id=&#34;tombstones-&#34;&gt;Tombstones üü©&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slides tombstones&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Garbage Collection/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Garbage Collection/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Quando alloco, alloco anche una tombstone, e tutti i riferimenti passano per quella. (quindi ho due dereference per l‚Äôaccesso) quando vado a deallocare segno la tombstone come RIP, NULL.&lt;/p&gt;
&lt;p&gt;Dopo molto tempo ho il problema del cimitero che diventa molto grande. Anche se non punta pi√π a niente, il cimitero.&lt;/p&gt;
&lt;h3 id=&#34;keys-and-locks-&#34;&gt;Keys and locks üü©&lt;/h3&gt;
&lt;p&gt;Un p√≤ di overhead in pi√π dal punto di vista della memoria, che √® doppio&lt;/p&gt;</description>
    </item>
    <item>
      <title>Interpolazione</title>
      <link>https://flecart.github.io/notes/interpolazione/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/interpolazione/</guid>
      <description>&lt;p&gt;Vogliamo in questa sezione andare ad indagare la costruzione di funzioni che passano in tutti i punti che vogliamo, appunto interpolare. La funzione √® molto simile alla regressione trattata in &lt;a href=&#34;https://flecart.github.io/notes/minimi-quadrati&#34;&gt;Minimi quadrati&lt;/a&gt; (con il metodo della regressione, chiamato anche approssimazione ai minimi quadrati).&lt;/p&gt;
&lt;p&gt;Quindi mentre la precedente voleva andare a minimizzare l&amp;rsquo;errore, questo attuale va a creare proprio da 0 la funzione che ci passa sempre.&lt;/p&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;Andremo a creare una funzione f tale che per ogni x in input si abbia &lt;strong&gt;esattamente&lt;/strong&gt; la y in output&lt;/p&gt;</description>
    </item>
    <item>
      <title>Isomorfismi</title>
      <link>https://flecart.github.io/notes/isomorfismi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/isomorfismi/</guid>
      <description>&lt;p&gt;Gli isomorfismi sono delle propriet√† fondamentali per stabilire una sorta di equivalenza fra i gruppi. Utilizziamo questi isomorfismi per parlare della stessa cosa ma in modi diversi.&lt;/p&gt;
&lt;h2 id=&#34;31-introduzione&#34;&gt;3.1 Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;311-definizione&#34;&gt;3.1.1 Definizione&lt;/h3&gt;
&lt;p&gt;Un gruppo si dice isomorfo rispetto ad un altro gruppo se, in paroloni semplici, esiste una funzione bigettiva tale che preservi l&amp;rsquo;operazione del gruppo.&lt;/p&gt;
&lt;p&gt;In altre parole&lt;/p&gt;
$$
\phi:A \to B,\phi(ab) = \phi(a)\phi(b)
$$&lt;h3 id=&#34;312-step-di-dimostrazione&#34;&gt;3.1.2 Step di dimostrazione&lt;/h3&gt;
&lt;p&gt;Esiste un modo preciso per dimostrare se due gruppi sono isomorfi. In particolare:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Object Detection</title>
      <link>https://flecart.github.io/notes/object-detection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/object-detection/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h3 id=&#34;semantic-segmentation&#34;&gt;Semantic segmentation&lt;/h3&gt;
&lt;p&gt;Vorremo trovare &lt;strong&gt;regioni che corrispondano a categorie diverse&lt;/strong&gt;. E dividere in questo modo l‚Äôimmagine secondo zone di informazione.&lt;/p&gt;
&lt;h3 id=&#34;object-detection&#34;&gt;Object detection&lt;/h3&gt;
&lt;p&gt;Vogliamo trovare &lt;strong&gt;il pi√π piccolo box&lt;/strong&gt; che vada a contenere l‚Äôoggetto. Questo √® fatto con il &lt;strong&gt;bounding box&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In questo caso la funzione di loss √® un p√≤ pi√π difficile da definire, si utilizza la funzione &lt;strong&gt;intersection over union&lt;/strong&gt; con le aree, in pratica la percentuale di immagine comune diciamo.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Probabilita condizionata e indipendenza</title>
      <link>https://flecart.github.io/notes/probabilita-condizionata-e-indipendenza/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/probabilita-condizionata-e-indipendenza/</guid>
      <description>&lt;h2 id=&#34;condizionata&#34;&gt;Condizionata&lt;/h2&gt;
&lt;h3 id=&#34;definizione-&#34;&gt;Definizione üü©&lt;/h3&gt;
&lt;p&gt;Andiamo a definire una probabilit√† di un evento $A$, condizionata a un evento non nullo $B$, come&lt;/p&gt;
$$
P(A|B) = \dfrac{P(A\cap B)}{P(B)}
$$&lt;p&gt;Questo √® la cosa fondamentale per poter considerare cose come bayes perch√© in questo modo abbiamo una certa relazione fra causa ed effetto e anche il contrario! Cosa che ci piace molto molto molto.&lt;/p&gt;
&lt;h3 id=&#34;la-definizione-di-sopra-√®-un-probabilit√†-&#34;&gt;La definizione di sopra √® un probabilit√† üü©&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Probabilit√† condizionata e indipendenza/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Probabilit√† condizionata e indipendenza/Untitled&#34;&gt;
&lt;p&gt;&lt;strong&gt;Dimostrazione&lt;/strong&gt; mia&lt;/p&gt;</description>
    </item>
    <item>
      <title>Algebra dei tipi</title>
      <link>https://flecart.github.io/notes/algebra-dei-tipi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/algebra-dei-tipi/</guid>
      <description>&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Algebra dei tipi/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Algebra dei tipi/Untitled&#34;&gt;
&lt;h3 id=&#34;equivalenza-dei-tipi-2-&#34;&gt;Equivalenza dei tipi (2) üü©&lt;/h3&gt;
&lt;p&gt;Quando possiamo dire che due tipi siano uguali? Solitamente vengono utilizzati due metodi:&lt;/p&gt;
&lt;h4 id=&#34;equivalenza-nominale&#34;&gt;Equivalenza Nominale&lt;/h4&gt;
&lt;p&gt;Quando un nuono tipo introduce un nuovo nome diverso fra tutti i presenti. Credo cos√¨ vada golang.
Quindi in questo caso si pu√≤ dire che un tipo &lt;strong&gt;√® equivalente solamente a s√© stesso&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Vogliamo fare in questo modo perch√© se definiamo un nuovo tipo solitamente dovrebbe avere funzioni diverse, quindi √® giusto che sia diverso da uqello iniziale.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Classi OOP</title>
      <link>https://flecart.github.io/notes/classi-oop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/classi-oop/</guid>
      <description>&lt;h2 id=&#34;introduzione-a-oop&#34;&gt;Introduzione a OOP&lt;/h2&gt;
&lt;p&gt;Per la definizione di classe andare a guardare &lt;a href=&#34;https://flecart.github.io/notes/object-orientation&#34;&gt;Object orientation&lt;/a&gt;, per√≤ lo ripeto in questa occasione, √® solamente un modello su cui andare a costruire degli oggetti.&lt;/p&gt;
&lt;h3 id=&#34;capisaldi&#34;&gt;Capisaldiüü©&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Incapsulazione&lt;/li&gt;
&lt;li&gt;Astrazione&lt;/li&gt;
&lt;li&gt;Ereditariet√†&lt;/li&gt;
&lt;li&gt;Dispatch dinamico&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;costruttori--&#34;&gt;Costruttori üü©-&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Classi OOP/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Classi OOP/Untitled&#34;&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Classi OOP/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Classi OOP/Untitled 1&#34;&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Classi OOP/Untitled 2.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Classi OOP/Untitled 2&#34;&gt;
&lt;p&gt;Il costruttore √® un codice utilizzato per &lt;strong&gt;inizializzare correttamente lo stato&lt;/strong&gt; interno. Le regole sono le stesse dei metodi sovraccaricati (dinamica per la chiamata, statica per il numero dei parametri che prende in input).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deblur di immagini</title>
      <link>https://flecart.github.io/notes/deblur-di-immagini/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/deblur-di-immagini/</guid>
      <description>&lt;h3 id=&#34;origini-di-sfocatura&#34;&gt;Origini di sfocatura&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&amp;quot;/images/notes/image/universita/ex-notion/Immagini/Untitled.png&amp;quot; style=&amp;quot;width: 100%&amp;quot; class=&amp;quot;center&amp;quot; alt=&amp;quot;image/universita/ex-notion/Immagini/Untitled&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;Rumore causata da problemi fisici che sono &lt;strong&gt;errori di lettura&lt;/strong&gt; del segnale analogico Questo si indica anche come errore gaussiano bianco e si pu√≤ considerare &lt;em&gt;additivo&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Rumore causato dalla digitalizzazione, quindi dalla discretizzazione di essa.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide formalizzazione errori per sfocatura&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Immagini/Untitled 1.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Immagini/Untitled 1&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;point-spread-function&#34;&gt;Point spread function&lt;/h3&gt;
&lt;p&gt;Un unico pixel bianco sembra influenzare il suo ambiente nero, come in immagine&lt;/p&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Immagini/Untitled 2.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Immagini/Untitled 2&#34;&gt;
&lt;p&gt;Vorremmo utilizzare delle funzioni ce siano in grado di approssimare questa funzione.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gestione della memoria</title>
      <link>https://flecart.github.io/notes/gestione-della-memoria/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/gestione-della-memoria/</guid>
      <description>&lt;h2 id=&#34;memoria-statica&#34;&gt;Memoria statica&lt;/h2&gt;
&lt;h3 id=&#34;elementi-in-memoria-statica-4--&#34;&gt;Elementi in memoria statica (4) üü©-&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Variabili globali&lt;/li&gt;
&lt;li&gt;Istruzioni macchina&lt;/li&gt;
&lt;li&gt;Costanti&lt;/li&gt;
&lt;li&gt;(Variabili locali, paramentri e ritorno di funzione?)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Le primi tre elementi descritti di sopra sono sicuramente presenti dopo la fase di compilazione, infatti sono allocati dal compilatore in una zona presente nell‚Äôeseguibile (un esempio √® il READONLY per le stringhe in C).&lt;/p&gt;
&lt;p&gt;Quindi se vogliamo&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Avere funzioni ricorsive&lt;/li&gt;
&lt;li&gt;Potere allocare e deallocare variabili in modo dinamico&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Abbiamo bisogno di far uso di Pila o Heap, che riescano a cresere e restringersi in modo dinamico.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gestione delle eccezioni</title>
      <link>https://flecart.github.io/notes/gestione-delle-eccezioni/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/gestione-delle-eccezioni/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;metodi-alternativi-di-gestione-degli-errori-3-&#34;&gt;Metodi alternativi di gestione degli errori (3) üü©&lt;/h3&gt;
&lt;p&gt;A volte le computazioni falliscono. Potremmo gestirle con i result come accennato in &lt;a href=&#34;https://flecart.github.io/notes/polimorfismo&#34;&gt;Polimorfismo&lt;/a&gt;, per√≤ diventa molto macchinoso fare tutte le funzioni che debbano inoltrare solamente delle results. bisogna trovare un modo pi√π naturale. Ecco che arriva una gestione delle eccezioni direttamente nel linguaggio. Si tratta un sistema di comunicazione degli errori.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ALTRI METODI&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Results, stile monadico, vedi sopra.&lt;/li&gt;
&lt;li&gt;definire dei valori eccezionali (questo si va spesso in C)&lt;/li&gt;
&lt;li&gt;Il chiamato dice al chiamante una cosa da chiamare quando fallisce. Diciamo &lt;strong&gt;inversione del controllo&lt;/strong&gt; perch√© in questo caso √® il chiamato che dice cosa fare. Ma rende il codice poco composizionale, quindi difficile da seguire.
(Questa √® la soluzione molto pi√π simile alla gestione effettiva degli errori). Ma nelle eccezioni vere non √® il chiamato che ritorn al&amp;rsquo;indirizzo da eseguire ma √® il runtime che decide cosa andare ad eseguire. Questa cosa non interrompe il flusso del calcolo&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Con le eccezioni vogliamo &lt;strong&gt;trasferire il controllo a un gestore delle eccezioni&lt;/strong&gt; questo gestore solitamente si trova sulla stack (va a risalire tutta la stack di chiamata fino a raggiungere questo gestore).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduzione alla probabilita</title>
      <link>https://flecart.github.io/notes/introduzione-alla-probabilita/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduzione-alla-probabilita/</guid>
      <description>&lt;h1 id=&#34;note&#34;&gt;Note:&lt;/h1&gt;
&lt;p&gt;Questo corso √® troppo astratto. Pi√π che probabilit√† tratta di teoria della Misura. Quindi affossato‚Ä¶&lt;/p&gt;
&lt;p&gt;Link della serie: &lt;a href=&#34;https://www.youtube.com/watch?v=172m7qVy_FQ&amp;list=PLrb6X_RiBI94b6dzCx-QwM-r0aZpJyPxS&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=172m7qVy_FQ&amp;amp;list=PLrb6X_RiBI94b6dzCx-QwM-r0aZpJyPxS&#34;&gt;https://www.youtube.com/watch?v=172m7qVy_FQ&amp;list=PLrb6X_RiBI94b6dzCx-QwM-r0aZpJyPxS&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;campo-di-probabilit√†&#34;&gt;Campo (di probabilit√†)&lt;/h1&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Introduzione alla probabilit√†/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Introduzione alla probabilit√†/Untitled&#34;&gt;
&lt;p&gt;Nota:&lt;/p&gt;
&lt;p&gt;2 e 3 ‚áí 4&lt;/p&gt;
&lt;p&gt;2 e 4 ‚áí 3&lt;/p&gt;
&lt;p&gt;Quindi 3 e 4 sono interscambiabili, e si potrebbe eliminare uno dei due.&lt;/p&gt;
&lt;p&gt;Anche il fatto che il vuoto sia presente in F si pu√≤ omettere. combinando 1 e 2 ottengo il vuoto (complementare dell‚Äôinsieme che prenda tutto).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Calcolo di numeri finiti</title>
      <link>https://flecart.github.io/notes/calcolo-di-numeri-finiti/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/calcolo-di-numeri-finiti/</guid>
      <description>&lt;h1 id=&#34;1-calcolo-dei-numeri-finiti&#34;&gt;1 Calcolo dei numeri finiti&lt;/h1&gt;
&lt;p&gt;Il calcolo √® numerico perch√© si differenzia rispetto a un calcolo normale perch√© √® &lt;em&gt;finito&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;11-errore-nei-calcoli&#34;&gt;1.1 Errore nei calcoli&lt;/h2&gt;
&lt;h3 id=&#34;111-tipologie-di-errore-5-&#34;&gt;1.1.1 Tipologie di errore (5) üü©&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Errore di misura&lt;/strong&gt;, dovuto alle imperfezioni dello strumento di misura dei dati del problema.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Errore di troncamento&lt;/strong&gt;, quando un procedimento infinito viene realizzato come procedimento finito. (esempio: calcolo del valore di una funzione tramite sviluppo in serie, perch√© dato che l‚Äôalgoritmo deve essere finito, devo prima o poi interrompere il calcolo, ecco qui l‚Äôerrore).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Errore inerente&lt;/strong&gt;, dovuto al fatto che i dati di un problema non sono in una forma buona diciamo&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Errore di rappresentazione (simil troncamento)&lt;/strong&gt; non sempre appartengono all‚Äôinsieme $\mathbb{F}$ dei numeri rappresentabili e quindi vengono approssimati.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Errore algoritmico&lt;/strong&gt;, dovuto al &lt;em&gt;propagarsi&lt;/em&gt; degli errori di arrotondamento sulle singole operazioni in un procedimento complesso.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;112-misura-dellaccuratezza-&#34;&gt;1.1.2 Misura dell‚Äôaccuratezza üü©&lt;/h3&gt;
&lt;p&gt;Anche per l‚Äôaccuratezza di una misura utilizziamo degli errori (questi tipi di errori li hai anche studiati in fisica durante il liceo).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Algorithmic Information and Complexity</title>
      <link>https://flecart.github.io/notes/introduction-to-algorithmic-information-and-complexity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-algorithmic-information-and-complexity/</guid>
      <description>&lt;h3 id=&#34;quick-introduction&#34;&gt;Quick introduction&lt;/h3&gt;
&lt;p&gt;Si assume che la descrizione pi√π &lt;em&gt;intelligente&lt;/em&gt; di un qualcosa √® la stringa &lt;strong&gt;pi√π corta&lt;/strong&gt; che descrive quella, un po&amp;rsquo; forse √® arbitrario, perch√© minore complessit√†, non √® detto che sia direttamente relazionata con la difficolt√† di descriverla.&lt;/p&gt;
&lt;p&gt;Nel caso di AIT, diciamo che una cosa random non √® compressibile, altrimenti posso scriverla in modo pi√π compatto. √à importante stabilire che l&amp;rsquo;alfabeto che abbiamo per rappresentare qualcosa √® fissato a priori.
&lt;em&gt;Qualunque cosa che possiamo codare&lt;/em&gt; si pu√≤ analizzare da questo punto di vista della complessit√†.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Model of Analogies</title>
      <link>https://flecart.github.io/notes/model-of-analogies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/model-of-analogies/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;The human ability of making analogies proceeds in such a way as to keep complexity minimal.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Perch√© facciamo questo? Perch√© √® la cosa pi√π semplice da fare! Anche su Vapnik&amp;rsquo;s dimensions √® simile questa idea!&lt;/p&gt;
&lt;p&gt;Occam razor, Epicuro, con Solomonoff che ha risolto problema dell&amp;rsquo;induzione che Hume pensava di fare con abitudini. Attualmente IQ tests provano a misurare la capacit√† di estendere questo.&lt;/p&gt;
&lt;h3 id=&#34;analogia&#34;&gt;Analogia&lt;/h3&gt;
&lt;p&gt;Studiamo l&amp;rsquo;analogia come oggetto matematico perch√© sembra essere una capacit√† molto difficile da generalizzare e utilizzare nelle macchine.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Condensatori con dielettrici</title>
      <link>https://flecart.github.io/notes/condensatori-con-dielettrici/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/condensatori-con-dielettrici/</guid>
      <description>&lt;h3 id=&#34;introduzione-ai-dielettrici&#34;&gt;introduzione ai dielettrici&lt;/h3&gt;
&lt;h4 id=&#34;esperimenti-metalli-e-dielettrici-&#34;&gt;Esperimenti metalli e dielettrici üü©&lt;/h4&gt;
$$
V_{s} = (h - s) E_{0}
$$&lt;p&gt;
Questo √® vero perch√© semplicemente in mezzo al conduttore il campo elettrico √® nullo, come spiegato in &lt;a href=&#34;https://flecart.github.io/notes/conduttori-elettrici&#34;&gt;Conduttori elettrici&lt;/a&gt;, quindi durante l&amp;rsquo;integrale, il percorso √® semplicemente minore, esattamente di quella quantit√†.&lt;/p&gt;
$$
k = \frac{V_{0}}{V_{k}} &lt; 1
$$&lt;h4 id=&#34;costante-dielettrica-relativa-&#34;&gt;Costante dielettrica relativa üü©&lt;/h4&gt;
$$
E_{k} = \frac{V_{k}}{h} = \frac{V_{0}}{kh} = \frac{E_{0}}{k} = \frac{\sigma_{0}}{k\varepsilon_{0}} = \frac{\sigma_{k}}{\varepsilon_{0}} = \frac{\sigma_{0}}{\varepsilon}
$$$$
E_{k} = \frac{\sigma_{0}}{\varepsilon_{0}} - \frac{\sigma_{p}}{\varepsilon_{0}}
$$$$
\sigma_{p} = \frac{k - 1}{k} \sigma_{0}
$$$$
\sigma_{k} = \sigma_{0} - \sigma_{p} = \frac{\sigma_{0}}{k}
$$&lt;p&gt;
Qui si pu√≤ giocare un po&amp;rsquo; senza nessun problema!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Condensatori nel vuoto</title>
      <link>https://flecart.github.io/notes/condensatori-nel-vuoto/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/condensatori-nel-vuoto/</guid>
      <description>&lt;h3 id=&#34;introduzione-ai-condensatori&#34;&gt;Introduzione ai condensatori&lt;/h3&gt;
&lt;h4 id=&#34;analisi-introduttiva-condensatori-tubi-di-flusso-&#34;&gt;Analisi introduttiva condensatori: tubi di flusso üü©&lt;/h4&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Materiali e campo elettrico-1697456372758.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Materiali e campo elettrico-1697456372758&#34;&gt;
Consideriamo un **tubo di flusso infinitesimo** come in immagine. abbiamo che  $dQ$ √® la carica totale dentro al cubo. Tale che segua le linee di campo.
Il flusso totale sarebbe
$$
\oint_{\Sigma} \vec{E} \cdot d\vec{s} = \frac{Q_{T}}{\varepsilon_{0}}
$$
Sappiamo anche che
$$
\vec{E}_{1}d\vec{s}_{1} + \vec{E}_{2}d\vec{s}_{2} = \frac{dQ_{T}}{\varepsilon_{0}}
$$
Ma scegliamo il cubo di flusso in modo che le superfici siano **perpendicolari al nostro campo**, e cos√¨ posso considerare il problema da un puro punto di vista **scalare**.
Sapendo che nell&#39;esempio sott il campo non √® esistente, allora posso scrivere il campo elettrico che va fuori, semplicemente in punto di vista scalare:
$$
E_{2} = \frac{dQ}{\varepsilon_{0}ds_{2}}
$$
esChe √® molto molto simile alla forma $\frac{\sigma}{\varepsilon_{0}}$.
il parametro di nostro interesse in questo esempio (almeno la cosa di nostro interesse) √® *il concetto di distanza*, se ci allontaniamo dalla nostra superficie, $dS_{2}$ diventa pi√π larga
&lt;h4 id=&#34;introduzione-ai-condensatori-&#34;&gt;Introduzione ai condensatori üü©&lt;/h4&gt;
&lt;p&gt;Poniamo di avere due armature metalliche qualsiasi, che abbiamo &lt;strong&gt;cariche uguali ed opposte in segno&lt;/strong&gt; di una forma qualunque a distanza qualunque, in questo setting teorico.
La cosa interessante √® che suppongo di avere &lt;a href=&#34;https://flecart.github.io/notes#induzione-completa&#34;&gt;#Induzione completa&lt;/a&gt; in questo caso.
√à una necessit√† per l&amp;rsquo;analisi dei condensatori.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Corrente Elettrica</title>
      <link>https://flecart.github.io/notes/corrente-elettrica/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/corrente-elettrica/</guid>
      <description>&lt;h2 id=&#34;introduzione-alla-corrente-elettrica&#34;&gt;Introduzione alla corrente elettrica&lt;/h2&gt;
&lt;h3 id=&#34;considerazioni-generali&#34;&gt;Considerazioni generali&lt;/h3&gt;
&lt;h4 id=&#34;elettroni-liberi-nei-materiali&#34;&gt;Elettroni liberi nei materiali&lt;/h4&gt;
&lt;p&gt;Ricorda che √® un &lt;strong&gt;reticolo cristallino&lt;/strong&gt;, con un elettrone nell&amp;rsquo;ultimo orbitale poco legato, quindi facilmente ionizzabile, in cui gli elettroni si possono muovere facilmente, e abbiamo che $n \approx 8.5 \times 10^{28} \frac{e^{-}}{m^{3}}$ nel rame
Per l&amp;rsquo;argento abbiamo 5.9 con stesso ordine di grandezza.&lt;/p&gt;
&lt;h4 id=&#34;velocit√†-media-elettroni-senza-campo-elettrico-&#34;&gt;Velocit√† media elettroni senza campo elettrico üü©&lt;/h4&gt;
$$
\vec{v}_{m} = \sum_{i = 1} ^{N} \frac{\vec{v}_{i}}{N} = 0
$$$$
\frac{1}{2}  m_{e} v^{2} = \frac{3}{2} k T
$$&lt;p&gt;
Con $k = 1.38 \times 10 ^{-23} J / K$ questo da studiare in altro posto&amp;hellip;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Database logical design</title>
      <link>https://flecart.github.io/notes/database-logical-design/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/database-logical-design/</guid>
      <description>&lt;h3 id=&#34;introduzione-al-design-logico&#34;&gt;Introduzione al design logico&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Conoscenze sul carico dell&amp;rsquo;applicazione, ossia se ha pi√π read rispetto a writes per esempio, sono dei priors in pratica&lt;/li&gt;
&lt;li&gt;Un design concettuale spiegato in precedenza.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;E si avr√† in output un design logico con anche un po&amp;rsquo; di documentazione.
&lt;img src=&#34;https://flecart.github.io/images/notes/Database logical design-1700046979267.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Database logical design-1700046979267&#34;&gt;&lt;/p&gt;
&lt;p&gt;bisogna in questa fase &lt;strong&gt;valutare la performance&lt;/strong&gt; principalmente su &lt;em&gt;indicatori&lt;/em&gt;, ossia una operazione quante istanze visiter√†? Invece di garanzie sul numero di transazioni al secondo.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Design del database</title>
      <link>https://flecart.github.io/notes/design-del-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/design-del-database/</guid>
      <description>&lt;h3 id=&#34;processo-design-del-database&#34;&gt;Processo design del database&lt;/h3&gt;
&lt;h4 id=&#34;il-design&#34;&gt;Il design&lt;/h4&gt;
&lt;h4 id=&#34;some-design-steps-3-non-impo&#34;&gt;Some design steps (3) (non impo)&lt;/h4&gt;
&lt;h5 id=&#34;how-to-gather-requirements-&#34;&gt;How to gather requirements? üü®+&lt;/h5&gt;
&lt;p&gt;Come si pu√≤ raccogliere i dati degli utilizzatori?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;parlare col il personale che dovr√† utilizzare questi sistemi&lt;/li&gt;
&lt;li&gt;Documentazione esistente&lt;/li&gt;
&lt;li&gt;Interview di persone che dovr√† utilizzare queste risorse&lt;/li&gt;
&lt;li&gt;O Moduli per fare sampling&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;top-down-approach&#34;&gt;Top-down approach&lt;/h5&gt;
&lt;p&gt;La cosa brutta √® che questi requisiti non possono essere standardizzati, ci sono molte necessit√†, molto diverse fra i loro, quindi √® utile andare a parlare con gli esperti e capire cosa abbiano bisogno per i dati.
Consiglio del prof. √® partire dai senior e poi scendere, perch√© quelli in alto hanno un punto di vista &lt;em&gt;pi√π ampio ma con meno dettagli&lt;/em&gt; diciamo.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Design patterns</title>
      <link>https://flecart.github.io/notes/design-patterns/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/design-patterns/</guid>
      <description>&lt;h3 id=&#34;introduction-to-design-patterns&#34;&gt;Introduction to design patterns&lt;/h3&gt;
&lt;h4 id=&#34;introduzione-personale-&#34;&gt;Introduzione personale üü©&lt;/h4&gt;
&lt;p&gt;I design patterns sono simili a dei &lt;em&gt;plug and play&lt;/em&gt;, ossia delle &lt;strong&gt;soluzioni che hanno funzionato bene&lt;/strong&gt; in passato e che sono ora riutilizzati.
Solitamente dovrebbe essere una &lt;strong&gt;abilit√† implicita&lt;/strong&gt;, cio√® un buon programmatore √® in grado di fare senza pensarci, dovrebbe essere automatico. Infatti quando uno fa il design non lo fa esplitamente seguendo un certo modello, ma farlo solitamente risulta utile per guidare il processo.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dipolo elettrico</title>
      <link>https://flecart.github.io/notes/dipolo-elettrico/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/dipolo-elettrico/</guid>
      <description>&lt;p&gt;Questo problema √® stato trattato in modo un po&amp;rsquo; pi√π semplificato (nel caso in cui la carica era esattamente a met√† in &lt;a href=&#34;https://flecart.github.io/notes/campo-elettrico#dipolo-elettrico&#34;&gt;Campo elettrico#Dipolo elettrico&lt;/a&gt;).
Questo problema √® stato storico, utilizzato per analizzare l&amp;rsquo;atomo.&lt;/p&gt;
&lt;h3 id=&#34;potenziale-del-dipolo-elettrico---&#34;&gt;Potenziale del dipolo elettrico üü©&amp;ndash;&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Momento di dipolo-1698054569445.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Momento di dipolo-1698054569445&#34;&gt;
$$
V(P) = V_{r^{+}} + V_{r^{-}} = \frac{q}{4\pi\varepsilon_{0}}\left( \frac{1}{r^{+}} - \frac{1}{r^{-}} \right)
$$$$
r^{+} - r^{-} = -a \cos \theta
$$$$
\left( \frac{1}{r^{+}} - \frac{1}{r^{-}} \right) = \frac{a\cos \theta}{r^{2}}
$$$$
V(P) 
= \frac{1}{4\pi\varepsilon_{0}}\frac{qa\cos \theta}{r^{2}}
= \frac{1}{4\pi\varepsilon_{0}}\frac{P\cos \theta}{r^{2}}
= \frac{1}{4\pi\varepsilon_{0}} \frac{\vec{P}\cdot \hat{r}}{r^{2}}
$$&lt;ol&gt;
&lt;li&gt;Direttamente proporzionale al momento di tipolo&lt;/li&gt;
&lt;li&gt;Inversamente proporzionale al quadrato del raggio.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;campo-elettrico-nel-dipolo&#34;&gt;Campo elettrico nel dipolo&lt;/h3&gt;
$$
\vec{E} = \frac{1}{4\pi\varepsilon_{0}} \vec{P} \cdot \frac{\hat{r}}{r^{3}}
$$$$
\vec{E} = -\vec{\nabla} V
$$&lt;h4 id=&#34;componente-parallela-&#34;&gt;Componente parallela üü©&lt;/h4&gt;
$$
\vec{E} = - \vec{\nabla}V = -\frac{\delta V}{\delta x}\hat{i}  -\frac{\delta V}{\delta y}\hat{j} -\frac{\delta V}{\delta z}\hat{k}
$$&lt;p&gt;
Sappiamo che $\vec{P} = P\hat{k}$ e $\vec{r} = x\hat{i} + y \hat{j} + z \hat{k}$ allora abbiamo che $\vec{P} \cdot \vec{r} = Pz$
Poi abbiamo che $z = r \cos \theta$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Divergenza e Circuitazione</title>
      <link>https://flecart.github.io/notes/divergenza-e-circuitazione/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/divergenza-e-circuitazione/</guid>
      <description>&lt;h3 id=&#34;scalare&#34;&gt;Scalare&lt;/h3&gt;
&lt;h4 id=&#34;scalare-e-gradiente-&#34;&gt;Scalare e gradiente üü©&lt;/h4&gt;
$$
\varphi(x, y, z) : \mathbb{R}^{3} \to \mathbb{R}
$$$$\vec{\nabla}\varphi = ( \frac{\delta\varphi}{\delta x}, \frac{\delta\varphi}{\delta y}, \frac{\delta\varphi}{\delta z}) =  \frac{\delta\varphi}{\delta x} \hat{i} +  \frac{\delta\varphi}{\delta y} \hat{j} + \frac{\delta\varphi}{\delta z} \hat{k}$$&lt;p&gt;
Se consideriamo il gradiente da solo √® un campo vettoriale (dice la direzione della derivata multidimensionale).&lt;/p&gt;
&lt;h4 id=&#34;gradiente-in-coordinate-polari-&#34;&gt;Gradiente in coordinate polari üü®&lt;/h4&gt;
&lt;p&gt;Questo √® un po&amp;rsquo; pi√π difficile da gestire, per√≤ √® abbastanza facile una volta che si fanno certe osservazioni.
Sappiamo che $dV  = \vec{\nabla} V \cdot d\vec{s}$, TODO: finire la dimostrazione, √® descritta bene a pagina 47 del mazzoldi.&lt;/p&gt;</description>
    </item>
    <item>
      <title>General SWE principles</title>
      <link>https://flecart.github.io/notes/general-swe-principles/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/general-swe-principles/</guid>
      <description>&lt;p&gt;This small note sections tries to fix 5 important concepts in software engineering&lt;/p&gt;
&lt;h3 id=&#34;sub-system-and-modules-&#34;&gt;Sub-system and modules üü©&lt;/h3&gt;
&lt;p&gt;We need to differentiate from sub-system, which is a part of a system that tries to achieve some objective, and a &lt;strong&gt;module&lt;/strong&gt;, which is more &lt;em&gt;language specific&lt;/em&gt; way of saying imported file, or set of functions or classes.&lt;/p&gt;
&lt;h3 id=&#34;information-hiding-&#34;&gt;Information hiding üü©&lt;/h3&gt;
&lt;p&gt;This is a very important principle present in &lt;a href=&#34;https://flecart.github.io/notes/classi-oop-&#34;&gt;object oriented programming&lt;/a&gt;.
Within this philosophy we should &lt;strong&gt;be able to access only public&lt;/strong&gt; methods or data, this allows the construction of &lt;em&gt;abstractions&lt;/em&gt; that allow us to think at a higher level.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to computational statistics</title>
      <link>https://flecart.github.io/notes/introduction-to-computational-statistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-computational-statistics/</guid>
      <description>&lt;h3 id=&#34;what-is-it-for&#34;&gt;What is it for&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Estimation&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sampling&lt;/strong&gt; generate numbers from &lt;em&gt;any&lt;/em&gt; distribution! (distributions are important in statistics).
&lt;ol&gt;
&lt;li&gt;Density&lt;/li&gt;
&lt;li&gt;Cumulative distribution (and others similar).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optimization&lt;/strong&gt; how to find computationally the min and max of functions.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Generating?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Random (difficile anche filosoficamente definire cosa significa questo).
&lt;ol&gt;
&lt;li&gt;Molto importante perch√© si assume in Comp stats che abbiamo il random vero, e questa assunzione che non vale pu√≤ rompere cose.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;And independent&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;sample-proportion&#34;&gt;Sample proportion&lt;/h4&gt;
&lt;p&gt;Average of something (example of the lake cannonball).&lt;/p&gt;</description>
    </item>
    <item>
      <title>La qualit√† del software</title>
      <link>https://flecart.github.io/notes/la-qualit%C3%A0-del-software/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/la-qualit%C3%A0-del-software/</guid>
      <description>&lt;p&gt;Dato che il software sta diventando sempre pi√π diffuso, diventa sempre pi√π importante andare a definire delle metriche che possano garantirne la qualit√†, ossia la non frequenza di errori o bug che possono in qualche modo limitarne la qualit√†.&lt;/p&gt;
&lt;h4 id=&#34;error-fault-and-failure&#34;&gt;Error, Fault and Failure&lt;/h4&gt;
&lt;p&gt;Secondo la definizione esatta data da IEEE, questi tre termini hanno un significato ben specifico, molto diverso.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Error, sono comportamenti non previsti da un comportamento dell&amp;rsquo;utente, oppure il programmatore capisce male le specifiche.&lt;/li&gt;
&lt;li&gt;Fault sono i bugs, degli errori nel codice che creano un comportamento non previsto&lt;/li&gt;
&lt;li&gt;Failure, sono comportamenti non previsti da specifiche, che crea un &lt;strong&gt;guasto&lt;/strong&gt; e non permette il funzionamento&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;qualit√†-del-software&#34;&gt;Qualit√† del software&lt;/h3&gt;
&lt;h4 id=&#34;rating-and-ranking&#34;&gt;Rating and Ranking&lt;/h4&gt;
&lt;p&gt;Il rating √® l&amp;rsquo;assegnazione di un punteggio assoluto di qualit√† riguardo al prodotto.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Magnetismo nella materia</title>
      <link>https://flecart.github.io/notes/magnetismo-nella-materia/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/magnetismo-nella-materia/</guid>
      <description>&lt;h3 id=&#34;analisi-macroscopica&#34;&gt;Analisi macroscopica&lt;/h3&gt;
&lt;h4 id=&#34;setting-dellesperimento-&#34;&gt;Setting dell&amp;rsquo;esperimento üü©&lt;/h4&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Magnetismo nella materia-1701163856145.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Magnetismo nella materia-1701163856145&#34;&gt;
$$
\vec{F} = -\vec{\nabla} \cdot U \implies F 
= -\vec{\nabla}(\vec{m} \cdot \vec{B})
= \pm m \frac{dB}{dx}
$$&lt;p&gt;
La prima relazione si deriva da definizione di lavoro e forza. (esteso al caso di una forza applicata su spira che non √® banale, facciamola brevemente).&lt;/p&gt;
$$
Fds = dW = -dU = i \nabla \Phi(B) ds \implies F = i\nabla \Phi(B) = m \cdot \nabla B = -\nabla U
$$&lt;p&gt;La cosa da notare √® che per campi uniformi abbiamo che si pu√≤ definire il lavoro.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Modelli AGILE</title>
      <link>https://flecart.github.io/notes/modelli-agile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/modelli-agile/</guid>
      <description>&lt;h3 id=&#34;socialit√†-dello-sviluppo-del-software-3--&#34;&gt;Socialit√† dello sviluppo del software (3) üü®-&lt;/h3&gt;
&lt;p&gt;Si assume che&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;√à difficile assegnarsi i compiti, bisogni di utenti, tempi di consegna (+ persone difficile)&lt;/li&gt;
&lt;li&gt;√à facile scrivere software (almeno software classico, e non computazione scientifica)&lt;/li&gt;
&lt;li&gt;La gente sia brava tecnicamente che socialmente √® una cosa rara&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;vs-waterfall-3-&#34;&gt;VS Waterfall (3) üü®++&lt;/h3&gt;
&lt;p&gt;Pianificare tutto come viene descritto nel modello del waterfall non √® possibile.
Per i seguenti motivi&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Non √® chiaro cosa vuole l&amp;rsquo;utente finale (quindi sarebbe meglio avere feedback continuo).&lt;/li&gt;
&lt;li&gt;Non si sa gi√† dall&amp;rsquo;inizio cosa √® che interessa all&amp;rsquo;utente, per questo motivo si consegna il prodotto passo passo per &lt;strong&gt;feedback continuo&lt;/strong&gt; dato che i requisiti cambiano nel tempo.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;giustificazione-agile-alto-livello-&#34;&gt;Giustificazione agile alto livello üü©&lt;/h4&gt;
&lt;p&gt;Vorremo una metodologia che permetta una &lt;strong&gt;iterazione&lt;/strong&gt; ossia un cambio continuo specifiche in funzione di un &lt;strong&gt;utente&lt;/strong&gt;, vogliamo fare le cose a seconda di quanto vuole l&amp;rsquo;utente.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Modelli Lineari di sviluppo</title>
      <link>https://flecart.github.io/notes/modelli-lineari-di-sviluppo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/modelli-lineari-di-sviluppo/</guid>
      <description>&lt;h2 id=&#34;introduzione-ai-modelli-lineari&#34;&gt;Introduzione ai modelli lineari&lt;/h2&gt;
&lt;h3 id=&#34;processi-di-sviluppo&#34;&gt;Processi di sviluppo&lt;/h3&gt;
&lt;h4 id=&#34;definizione&#34;&gt;Definizione&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;L‚Äôinsieme strutturato di attivit√†, eventi, documenti e procedure necessari per la costruzione di un sistema software&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;cosa-viene-descritto-4-&#34;&gt;Cosa viene descritto (4) üü©&lt;/h4&gt;
&lt;p&gt;Questo √® proprio quanto vuole studiare l&amp;rsquo;ingegneria del software -&amp;gt; &lt;strong&gt;metodi di sviluppo&lt;/strong&gt;, in modo da portare i migliori risultati possibile.&lt;/p&gt;
&lt;p&gt;Nella formazione classica va a definire 4 concetti (soprattutto utili nel lavoro di gruppo, al fine di comunicare nella maniera pi√π efficace):&lt;/p&gt;</description>
    </item>
    <item>
      <title>Onde elettromagnetiche</title>
      <link>https://flecart.github.io/notes/onde-elettromagnetiche/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/onde-elettromagnetiche/</guid>
      <description>$$
\vec{\nabla} \times \vec{B} = \mu_{0}\vec{J} + \mu_{0}\varepsilon_{0} \frac{\delta \vec{E}}{\delta t} 
$$$$
\vec{\nabla} \times \vec{E} =  - \frac{\delta \vec{B}}{\delta t}
$$&lt;p&gt;
Con questi abbiamo le onde elettromagnetiche.&lt;/p&gt;
&lt;p&gt;Nel vuoto possiamo dire che &lt;em&gt;non abbiamo densit√† di corrente&lt;/em&gt;, per questo posso andare nel vuoto, sono due cose che si autosostengono.
Sono &lt;strong&gt;simmetriche a meno di costante&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Questo ci dice che&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Preso un campo elettrico che varia nel tempo (tipo una carica oscillante).&lt;/li&gt;
&lt;li&gt;Questo mi dice che si genera un campo magnetico prima non esistente&lt;/li&gt;
&lt;li&gt;Questo campo che varia nel tempo va a creare un altro campo elettrico&lt;/li&gt;
&lt;li&gt;Quindi abbiamo un processo che continua cos√¨ all&amp;rsquo;infinito sostenendosi.
In queste due equazioni abbiamo la luce.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2 circuitazioni
2 Leggi di gauss
e le 4 equazioni di Maxwell sono in grado di descrivere tutti i fenomeni elettromagnetici.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Proximal Policy Optimization</title>
      <link>https://flecart.github.io/notes/proximal-policy-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/proximal-policy-optimization/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://arxiv.org/abs/1707.06347&#34;&gt;(Schulman et al. 2017)&lt;/a&gt; √® uno degli articoli principali che praticamente hanno dato via al campo.
Anche questo √® buono per Policy gradients:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lilianweng.github.io/posts/2018-04-08-policy-gradient/&#34;&gt;&lt;a href=&#34;https://lilianweng.github.io/posts/2018-04-08-policy-gradient/&#34;&gt;https://lilianweng.github.io/posts/2018-04-08-policy-gradient/&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;introduzione-a-ppo&#34;&gt;Introduzione a PPO&lt;/h3&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] Schulman et al. &lt;a href=&#34;http://arxiv.org/abs/1707.06347&#34;&gt;‚ÄúProximal Policy Optimization Algorithms‚Äù&lt;/a&gt; arXiv preprint arXiv:1707.06347 2017&lt;/p&gt;</description>
    </item>
    <item>
      <title>Randomness</title>
      <link>https://flecart.github.io/notes/randomness/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/randomness/</guid>
      <description>&lt;h3 id=&#34;introduzione-alla-randomicit√†&#34;&gt;Introduzione alla Randomicit√†&lt;/h3&gt;
&lt;p&gt;Questo √® principalmente basato su &lt;a href=&#34;http://link.springer.com/10.1007/978-3-030-11298-1&#34;&gt;(Li &amp;amp; Vit√°nyi 2019)&lt;/a&gt; Capito 1.9
Sembra che la nozione di random sia alla fine una cosa molto profonda. Per esempio, un caso lampante che le definizioni non funzionano nel caso di numeri trascendenti √® che catalogano i numeri di $\pi$ come se fossero casuali, mentre in realt√† possono essere trovati mediante procedimenti precisi. √à una distinzione filosoficamente molto interessante.&lt;/p&gt;
&lt;p&gt;Alla fine sembra ci sia un link molto diretto con la crittografia, si pu√≤ vedere &lt;a href=&#34;https://books.google.it/books/about/Cryptography.html?id=FAPLBQAAQBAJ&#34;&gt;(Stinson 2005)&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Requisiti e backlog del software</title>
      <link>https://flecart.github.io/notes/requisiti-e-backlog-del-software/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/requisiti-e-backlog-del-software/</guid>
      <description>&lt;h2 id=&#34;introduzione-sui-requisiti-del-software&#34;&gt;Introduzione sui requisiti del software&lt;/h2&gt;
&lt;h3 id=&#34;note-introduttive&#34;&gt;Note introduttive&lt;/h3&gt;
&lt;h4 id=&#34;in-linguaggio-naturale-dizionario-&#34;&gt;In linguaggio naturale (dizionario) üü•+&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Sono tutte le &lt;strong&gt;qualit√† necessarie&lt;/strong&gt; per &lt;em&gt;uno scopo ben determinato&lt;/em&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Secondo il prof. I requisiti sono dei &lt;strong&gt;desideri&lt;/strong&gt; ossia ci√≤ che idealmente vorresti riguardo qualcosa (nel nostro caso il software). Ma credo sia anche una tendenza italiana di fare le cose meglio possibile senza mai soddisfare tutto&lt;/p&gt;
&lt;h4 id=&#34;functional-requirements-&#34;&gt;Functional requirements üü©&lt;/h4&gt;
&lt;p&gt;Sono &lt;strong&gt;ci√≤ che permetter√† di fare il sistema&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reti convoluzionali</title>
      <link>https://flecart.github.io/notes/reti-convoluzionali/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/reti-convoluzionali/</guid>
      <description>&lt;p&gt;Abbiamo trattato i modelli classici in Convolutional NN. Con i vecchi files di notion&lt;/p&gt;
&lt;h3 id=&#34;il-kernel&#34;&gt;Il Kernel&lt;/h3&gt;
&lt;p&gt;I punti interessanti delle immagini sono solamente i &lt;strong&gt;punti di cambio&lt;/strong&gt; solo che attualmente siamo in stato discreto, quindi ci √® difficile usare una derivata, si usano kernel del tipo:
$\left[ 1, 0, -1 \right]$, che sar√† positivo se cresce verso sinistra, negativo se scende.
&lt;img src=&#34;https://flecart.github.io/images/notes/Reti convoluzionali-1700037160855.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Reti convoluzionali-1700037160855&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;feature-map&#34;&gt;feature map&lt;/h4&gt;
&lt;p&gt;Sono delle mappe che rappresentano alcune informazioni interessanti della nostra immagine.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scelta del PO</title>
      <link>https://flecart.github.io/notes/scelta-del-po/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/scelta-del-po/</guid>
      <description>&lt;p&gt;La cosa che rende il PO diverso rispetto agli sviluppatori √® la &lt;strong&gt;conoscenza&lt;/strong&gt; delle necessit√† del cliente. Questo permette di prioritizzare del task e capire in che modo dovrebbe essere il prodotto finale. In questo modo si crea una &lt;strong&gt;vision&lt;/strong&gt; del prodotto.
Pensiamo che il PO debba condividere questa informazione e prendere decisioni di gruppo.&lt;/p&gt;
&lt;h4 id=&#34;domande-da-fare&#34;&gt;Domande da fare:&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;La user interface, come sembra il wireframe?&lt;/li&gt;
&lt;li&gt;Pensavamo di utilizzare i social solamente per i login, pensavate di utilizzare anche per altro durante il gioco?
&lt;ol&gt;
&lt;li&gt;Bassa priorit√† (poter condividere i risultati con un post).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Vorreste poter selezionare il livello del bot? Quanto sarebbe il massimo livello e quale il minimo?
4. Per kriegspiel la forza √® massima.&lt;/li&gt;
&lt;li&gt;Cosa √® la modalit√† &amp;lsquo;mob&amp;rsquo; per giocare (2 descrizione del problema documento progetto).
&lt;ol&gt;
&lt;li&gt;si intende il social che permette di condividere mosse.&lt;/li&gt;
&lt;li&gt;tutte le persone interessante possono rispondere con tempo un giorno, e la maggioranza determina la risposta.&lt;/li&gt;
&lt;li&gt;Bassa priorit√†.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Esistono i soci (utenti registrati) e non, cosa pu√≤ fare un utente non registrato? E quelli registrati? O definiamo noi?&lt;/li&gt;
&lt;li&gt;Che genere di commenti deve fare l&amp;rsquo;AI durante la partita?
&lt;ol&gt;
&lt;li&gt;Va bene qualunque commento (anche in giro), commenti interessanti sul contesto).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;In che modo salvare una partita? Solamente la sequenza delle mosse o possibilit√† di riprendere la partita?
&lt;ol&gt;
&lt;li&gt;Non √® richiesto poter salvare e riprendere nei giochi a informazione incompleta&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;La seconda cosa interessante per l&amp;rsquo;utente?
&lt;ol&gt;
&lt;li&gt;Leaderboard (non per noi, ELO).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Cosa deve avere la leaderboard per giochi diversi da bad chess?
&lt;ol&gt;
&lt;li&gt;Legato all&amp;rsquo;ELO questa, il classico.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;O mobile o web o come ci pare (non √® importante).
No sicurezza, non √® importante.
50 giocatori max.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scrum Method</title>
      <link>https://flecart.github.io/notes/scrum-method/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/scrum-method/</guid>
      <description>&lt;h3 id=&#34;introduzione-idea-principale&#34;&gt;Introduzione (idea principale)&lt;/h3&gt;
&lt;h4 id=&#34;in-breve-essence-card--&#34;&gt;In breve: essence card üü©-&lt;/h4&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Scrum Method-1697470925893.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Scrum Method-1697470925893&#34;&gt;
Giallo = Prodotto.
&lt;h4 id=&#34;metafora-staffetta-rugby-&#34;&gt;Metafora staffetta-rugby üü©&lt;/h4&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Scrum Method-1697097959678.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Scrum Method-1697097959678&#34;&gt;
&lt;p&gt;Con altri metodi si fanno produzioni stile &lt;em&gt;staffetta&lt;/em&gt;, ossia un membro sta fermo, finch√© non ha il testimone e poi si uccide correndo&amp;hellip;
Il metodo pi√π utile ispirato a scrum √® rugby, che tutti si muovo insieme collaborando.
&lt;strong&gt;Un po&amp;rsquo; di tutto √® fatto&lt;/strong&gt; durante lo sprint&lt;/p&gt;
&lt;h4 id=&#34;cicli-di-base-3-&#34;&gt;Cicli di base (3) üü©&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Planning&lt;/strong&gt;: in cui vengono scelti i task da eseguire durante questo sprint, solitamente questo viene preso da un &lt;em&gt;subset&lt;/em&gt; dei task descritti dal product owner.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Execution&lt;/strong&gt;: questo √® abbastanza chiaro, si sviluppa.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Retrospective and review&lt;/strong&gt;: in cui vengono identificati i problemi che sono stati incontrati durante lo sviluppo, e modi possibili per risolverli.
!&lt;a href=&#34;https://flecart.github.io/notes/scrum-method-1697098147819.jpeg-&#34;&gt; 500&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;lo-sprint-3--&#34;&gt;Lo sprint (3) üü©-&lt;/h4&gt;
&lt;p&gt;Una cosa molto importante che aiuter√† di gran lunga lo sviluppo √® la &lt;strong&gt;costanza&lt;/strong&gt; che
&lt;img src=&#34;https://flecart.github.io/images/notes/Scrum Method-1697098373334.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Scrum Method-1697098373334&#34;&gt;
Si scelgono&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sezioni Critiche</title>
      <link>https://flecart.github.io/notes/sezioni-critiche/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/sezioni-critiche/</guid>
      <description>&lt;p&gt;Ripasso Prox: 80
Ripasso: May 21, 2023
Ultima modifica: March 12, 2023 10:00 AM
Primo Abbozzo: October 8, 2022 11:30 AM
Stato: üåïüåïüåïüåïüåë
Studi Personali: No&lt;/p&gt;
&lt;h1 id=&#34;elementi-di-ripasso&#34;&gt;Elementi di ripasso&lt;/h1&gt;
&lt;h1 id=&#34;2-sezioni-critiche&#34;&gt;2 Sezioni Critiche&lt;/h1&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;La parte di un programma che utilizza una o pi√π risorse
condivise viene detta sezione critica (critical section, o CS)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Andiamo in questa altra parte a valutare certe soluzioni:&lt;/p&gt;
&lt;h3 id=&#34;programma-desempio-&#34;&gt;Programma d‚Äôesempio üü©&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Sezioni Critiche/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Sezioni Critiche/Untitled&#34;&gt;
&lt;p&gt;Vorremmo garantire che &lt;strong&gt;a = b invariante.&lt;/strong&gt; (espressione logica verificata nell&amp;rsquo;esecuzione di questo programma). quindi una coerenza di uno prima dell&amp;rsquo;altro vogliamo.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spettrometri di massa</title>
      <link>https://flecart.github.io/notes/spettrometri-di-massa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/spettrometri-di-massa/</guid>
      <description>&lt;h3 id=&#34;particelle-in-campi-magnetici&#34;&gt;Particelle in campi magnetici&lt;/h3&gt;
&lt;h4 id=&#34;moto-in-campo-magnetico-uniforme-&#34;&gt;Moto in campo magnetico uniforme üü©&lt;/h4&gt;
&lt;p&gt;Se abbiamo una particella carica con velocit√† uniforme in campo magnetico uniforme, come abbiamo detto in precedenza, una forza centripeta, questo far√† &lt;strong&gt;curvare la carica&lt;/strong&gt;, una cosa interessante sarebbe provare a capire &lt;strong&gt;raggio di curvatura&lt;/strong&gt; della nostra carica. Sotto in immagine abbiamo l&amp;rsquo;esempio di curvatura.
&lt;img src=&#34;https://flecart.github.io/images/notes/Magnetismo-1700054485909.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Magnetismo-1700054485909&#34;&gt;&lt;/p&gt;
$$
F = qvB= ma = \frac{mv^{2}}{r}
\implies r = \frac{mv^{2}}{qvB} = \frac{mv}{qB} = \frac{p}{qB}
$$&lt;p&gt;
Dove $p$ √® la quantit√† di moto, quantit√† che credo sia relazionata al lavoro ed inerzia, parte di fisica 1 che non ho studiato da pi√π di due anni.
Questa stessa relazione, conoscendo il raggio &lt;em&gt;pu√≤ essere usata per calcolare il campo magnetico!&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>System Design</title>
      <link>https://flecart.github.io/notes/system-design/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/system-design/</guid>
      <description>&lt;p&gt;NOTA: tolgo dalle note perch√© non mi sembra importante.&lt;/p&gt;
&lt;h3 id=&#34;introduction-to-system-design&#34;&gt;Introduction to system design&lt;/h3&gt;
&lt;h4 id=&#34;packages-vs-diagrams--&#34;&gt;Packages vs diagrams üü©-&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Packages &lt;strong&gt;fisica implementazione&lt;/strong&gt;, perch√© √® una cosa utile per lo sviluppo&lt;/li&gt;
&lt;li&gt;Diagrams &lt;strong&gt;logica visualizzazione&lt;/strong&gt; perch√© aiuta solamente a comprendere meglio come funziona il sistema in toto.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;components&#34;&gt;Components&lt;/h3&gt;
&lt;h4 id=&#34;what-is-a-component-3-&#34;&gt;What is a component (3) üü®&lt;/h4&gt;
&lt;p&gt;√à una &lt;strong&gt;entit√† totalmente indipendente&lt;/strong&gt; che funziona a s√©, un esempio √® il &lt;em&gt;dll, dynamically loaded libraries&lt;/em&gt; presente nei sistemi di windows.
Una cosa √® che &lt;strong&gt;espongono interfacce&lt;/strong&gt; per interagirci, e questi possono essere utilizzati per creare sistemi complessi.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Database Management System</title>
      <link>https://flecart.github.io/notes/the-database-management-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/the-database-management-system/</guid>
      <description>&lt;h2 id=&#34;struttura-del-dbms&#34;&gt;Struttura del DBMS&lt;/h2&gt;
&lt;h3 id=&#34;introduzione-ai-dbms&#34;&gt;Introduzione ai DBMS&lt;/h3&gt;
&lt;h4 id=&#34;schema-riassuntivo&#34;&gt;Schema riassuntivo&lt;/h4&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/The Database Management System-1700648809120.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;The Database Management System-1700648809120&#34;&gt;
#### Operazioni classiche
Ci stiamo chiedendo, come facciamo a descrivere i processi che portano alla comprensione della query e della retrieval degli elementi utili?
Questo deve fare il DBMS, ossia capace di 
- Aggiornare tuple
- Trovare tuple
- Gestire gli accessi
- Gestire accessi concorrenti?
### Query processor
#### Query compiler (3)  üü©
- Parsing (crea l&#39;albero di derivazione per la nostra query)
- Pre-processing (fa check semantici sulla query)
- Optimization, si occupa lui di migliorare L&#39;ottimizzazione
#### Execution engine üü©
Esegue l&#39;effettiva computazione per la query, ed √® il punto d&#39;incontro col resto (indexes, e logging per dire)
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Esegue il piano di esecuzione&lt;/strong&gt; che probabilmente un livello superiore ha calcolato&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interagisce&lt;/strong&gt; con tutti gli altri componenti del db (ad esempio Log per transazioni e durabilit√†, buffer e scheduler delle operazioni prolly).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Anche se non so nei dettagli in che modo esegue questo (alla fine roba assembly? che livello di astrazione ha?)&lt;/p&gt;</description>
    </item>
    <item>
      <title>The RLHF pipeline</title>
      <link>https://flecart.github.io/notes/the-rlhf-pipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/the-rlhf-pipeline/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://huyenchip.com/2023/05/02/rlhf.html&#34;&gt;&lt;a href=&#34;https://huyenchip.com/2023/05/02/rlhf.html&#34;&gt;https://huyenchip.com/2023/05/02/rlhf.html&lt;/a&gt;&lt;/a&gt; √® un blog post che lo descrive in modo abbastanza dettagliato e buono.&lt;/p&gt;
&lt;h2 id=&#34;introduzione-a-rlhf&#34;&gt;Introduzione a RLHF&lt;/h2&gt;
&lt;p&gt;Questo √® il processo che √® quasi la migliore per la produzione di LLM moderni (maggior parte si basano su questo per dire).&lt;/p&gt;
&lt;h3 id=&#34;struttura-generale&#34;&gt;Struttura generale&lt;/h3&gt;
&lt;p&gt;Si pu√≤ dire che RLHF si divida in 3 parti fondamentali&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Completion&lt;/strong&gt; il modello viene allenato a completare parole dal web,solitamente √® molto inutile&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fine tuning&lt;/strong&gt; per le singole task, per esempio riassumere, rispondere in certo modo etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reinforcement Learning&lt;/strong&gt; basato su un &lt;strong&gt;reward model&lt;/strong&gt; scoperto.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Partiamo con l&amp;rsquo;approccio di reinforcement learning che √® la parte un po&amp;rsquo; pi√π interessante in questo momento&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tokenization</title>
      <link>https://flecart.github.io/notes/tokenization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/tokenization/</guid>
      <description>&lt;h3 id=&#34;introduction-to-tokenization&#34;&gt;Introduction to tokenization&lt;/h3&gt;
&lt;p&gt;Tokenization is the process of converting normal strings into small little pieces that could be fed into one of our models. It usually comes from a tradition in programming languages, as we can see in &lt;a href=&#34;https://flecart.github.io/notes/automi-e-regexp&#34;&gt;Automi e Regexp&lt;/a&gt; where we define a specific token to have a known pattern, usually recognized by regular expressions.&lt;/p&gt;
&lt;p&gt;There have been historically been many approaches to tokenization, let&amp;rsquo;s see a few:&lt;/p&gt;
&lt;h4 id=&#34;un-approccio-semplice-e-non-funzionante&#34;&gt;Un approccio semplice (e non funzionante)&lt;/h4&gt;
&lt;p&gt;Uno dei primi approcci che potrebbe venire in mente per questo problema di divisione delle parole √® avere delle componenti fisse (ad esempio lettere di alfabeto, o lettere) e utilizzare queste per fare tokenization.
Cio√® stiamo mappando parti delle parole in modo greedy, prima arriva meglio √®. Si potrebbe rappresentare in questo modo:
Da &lt;a href=&#34;https://github.com/microsoft/LoRA/blob/main/examples/NLU/notebooks/01-training-tokenizers.ipynb&#34;&gt;questo ipynb&lt;/a&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/Tokenization-20240121105419785.webp&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Tokenization-20240121105419785&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Unified Modeling Language</title>
      <link>https://flecart.github.io/notes/unified-modeling-language/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/unified-modeling-language/</guid>
      <description>&lt;h4 id=&#34;cosa-√®&#34;&gt;Cosa √®&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;UML&lt;/strong&gt; √® un linguaggio di modelling (molto vecchio) ma ancora di continua evoluzione, da
un punto di vista storico √® nato insieme ai concetti di &lt;strong&gt;Object Oriented Programming&lt;/strong&gt; che ora √® molto presente all&amp;rsquo;interno dell&amp;rsquo;industria, descritto bene in &lt;a href=&#34;https://flecart.github.io/notes/classi-oop&#34;&gt;Classi OOP&lt;/a&gt;, anche se in questa occasione sviluppata in maniera molto pi√π intuitiva (grafica).&lt;/p&gt;
&lt;h4 id=&#34;perch√©-serve-&#34;&gt;Perch√© serve üü©&lt;/h4&gt;
&lt;p&gt;Per cercare di &lt;strong&gt;comunicare&lt;/strong&gt; quanto necessario riguardo struttura e dinamicit√† dell&amp;rsquo;architettura.&lt;/p&gt;
&lt;h3 id=&#34;struttura-di-uml&#34;&gt;Struttura di UML&lt;/h3&gt;
&lt;h4 id=&#34;structural-diagram-&#34;&gt;Structural Diagram üü®++&lt;/h4&gt;
&lt;p&gt;These diagrams focus on representing the &lt;strong&gt;static structure of a system&lt;/strong&gt;. They help depict the components, classes, objects, and their relationships in a system. Some common structural diagrams in UML include:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vettore potenziale</title>
      <link>https://flecart.github.io/notes/vettore-potenziale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/vettore-potenziale/</guid>
      <description>&lt;h3 id=&#34;introduzione-al-vettore-potenziale&#34;&gt;Introduzione al vettore potenziale&lt;/h3&gt;
&lt;h4 id=&#34;definizione-vettore-potenziale-&#34;&gt;Definizione vettore potenziale üü©&lt;/h4&gt;
$$
\vec{B} = \vec{\nabla} \times \vec{A}
$$&lt;p&gt;
Con un campo vettoriale a caso $\vec{A}$, vedremo che questo campo avr√† qualche utilit√† per fare i calcoli.&lt;/p&gt;
&lt;p&gt;Possiamo notare che soddisfa la propriet√† dell &lt;strong&gt;campo solenoidale&lt;/strong&gt; citato in &lt;a href=&#34;https://flecart.github.io/notes/magnetismo&#34;&gt;Magnetismo&lt;/a&gt;, infatti&lt;/p&gt;
$$
\vec{\nabla} \cdot \vec{B} = \vec{\nabla} \cdot (\vec{\nabla} \times \vec{A}) = 0
$$&lt;p&gt;
Perch√© sappiamo che la divergenza del rotore  (questo operatore dico) √® sempre nullo per ragioni di Cauchy, se ne parla in &lt;a href=&#34;https://flecart.github.io/notes/divergenza-e-circuitazione&#34;&gt;Divergenza e Circuitazione&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Accept Reject algorithm</title>
      <link>https://flecart.github.io/notes/accept-reject-algorithm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/accept-reject-algorithm/</guid>
      <description>&lt;h4 id=&#34;some-useful-links&#34;&gt;Some useful links&lt;/h4&gt;
&lt;p&gt;Main results: &lt;a href=&#34;https://jblevins.org/notes/accept-reject&#34;&gt;&lt;a href=&#34;https://jblevins.org/notes/accept-reject&#34;&gt;https://jblevins.org/notes/accept-reject&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Intuition: &lt;a href=&#34;https://en.wikipedia.org/wiki/Rejection_sampling&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Rejection_sampling&#34;&gt;https://en.wikipedia.org/wiki/Rejection_sampling&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;La cosa √® che faccio sampling fra due distribuzioni diverse e devo settare anche un parametro (e a seconda di certe cose diventa molto lento).&lt;/p&gt;
&lt;h4 id=&#34;introduzione-al-metodo&#34;&gt;Introduzione al metodo&lt;/h4&gt;
&lt;p&gt;Vorrei utilizzare una funzione $g$ per generarne una altra, questo √® il fulcro del concetto.
L&amp;rsquo;idea principale √®:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Conosco la funzione densit√† della funzione $f$ che voglio andare a generare&lt;/li&gt;
&lt;li&gt;Riesco a generare seguendo una funzione semplice, la chiamo $g$, &lt;strong&gt;candidate density&lt;/strong&gt;. (che √® la densit√† che utilizzo per calcolare il target che non conosco molto bene).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ma devono esserci due cose:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ampere e Faraday</title>
      <link>https://flecart.github.io/notes/ampere-e-faraday/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/ampere-e-faraday/</guid>
      <description>&lt;h3 id=&#34;relazioni-con-fili---ampere&#34;&gt;Relazioni con fili - Ampere&lt;/h3&gt;
&lt;h4 id=&#34;legge-di-biot-savartformalizzazione-esperienza-di-ampere-&#34;&gt;Legge di Biot-Savart/Formalizzazione esperienza di Ampere üü©&lt;/h4&gt;
&lt;p&gt;Poniamo che ho due fili in cui scorra della corrente, voglia capire la forza per unit√† di lunghezza del filo uno su due e viceversa.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;So che entrambi generano campo magnetico&lt;/li&gt;
&lt;li&gt;So che il campo magnetico induce forza su correnti in movimento.
Supponiamo che la loro distanza sia $D$, allora avremo che:
Per la prima legge so:
$$
d\vec{B} = \mu_{0}i d\vec{l} \times \frac{\hat{r}}{4\pi r^{2}}
$$
da questo posso calcolare il campo magnetico totale, in un modo simile a quanto fatto in precedenza per il campo elettrico  (solo che in questo caso abbiamo il prodotto seno, quindi l&amp;rsquo;angolo che conviene scegliere √® un po&amp;rsquo; diverso), e una volta che ho questo posso usare la seconda legge per avere la forza, questo √® il piano.
&lt;img src=&#34;https://flecart.github.io/images/notes/Magnetismo-1700471121392.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Magnetismo-1700471121392&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
$$
\vec{B} = \int _{Filo} \frac{\mu_{0}i}{4\pi}  d\vec{l} \times \frac{\hat{r}}{r^{2}}
= \hat{k} \frac{\mu i}{4\pi} \int_{-\frac{\pi}{2}}^{+\pi/2} \frac{dl}{r^{2}} \sin \theta
$$$$
r\sin \theta = D \implies r = \frac{D}{\sin \theta}
$$$$
\frac{D}{l} = \tan \theta \implies l = \frac{D}{\tan \theta} \implies dl = D \frac{d\theta}{\sin ^{2}\theta}
$$$$
\lvert \vec{B} \rvert = \frac{\mu_{0}i}{4\pi} \int _{\pi}^{0} \frac{\sin \theta}{D} d\theta \, dx 
= \frac{\mu_{0}i}{4\pi D} (-\cos \theta) ^{0}_{\pi} = \frac{\mu_{0}i}{2\pi D} 
$$&lt;p&gt;
Da qui abbiamo ottenuto la legge di &lt;strong&gt;Biot Savart&lt;/strong&gt;.
Qui notiamo che il campo magnetico circola intorno al filo (√® tangente al campo magnetico in questo caso, molto simile).
&lt;img src=&#34;https://flecart.github.io/images/notes/Magnetismo-1700472671563.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Magnetismo-1700472671563&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Conduttori elettrici</title>
      <link>https://flecart.github.io/notes/conduttori-elettrici/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/conduttori-elettrici/</guid>
      <description>&lt;h2 id=&#34;campo-elettrico-nei-materiali&#34;&gt;Campo elettrico nei materiali&lt;/h2&gt;
&lt;p&gt;Se prendiamo un &lt;strong&gt;conduttore&lt;/strong&gt;, gli elettroni in questi materiali sono liberi, significa che sono liberi di muoversi come vogliono, si pu√≤ dire che &amp;ldquo;vadano in giro&amp;rdquo; (per esempio questo vale per il rame).&lt;/p&gt;
&lt;p&gt;il &lt;strong&gt;reticolo cristallino&lt;/strong&gt; √® al struttura regolare che √® comune nei materiali, in cui gli atomi sono sempre a distanza costante (o comunque a pattern regolari) uno dall&amp;rsquo;altro $r$ per esempio.&lt;/p&gt;
&lt;h3 id=&#34;campo-e-materiali-6&#34;&gt;Campo e materiali (6)&lt;/h3&gt;
&lt;h4 id=&#34;schermatura-del-campo--&#34;&gt;Schermatura del campo (!) üü©&lt;/h4&gt;
&lt;p&gt;Quando un materiale conduttore √® sottoposto a un campo elettrico *gli elettroni si mettono in modo da &lt;strong&gt;schermare&lt;/strong&gt; il campo esterno, in modo tale da raggiungere un equilibrio.
&lt;img src=&#34;https://flecart.github.io/images/notes/Campo elettrico-1696921500696.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Campo elettrico-1696921500696&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kolmogorov complexity</title>
      <link>https://flecart.github.io/notes/kolmogorov-complexity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/kolmogorov-complexity/</guid>
      <description>&lt;p&gt;Gran parte di quanto scrivo ora √® tratto da &lt;a href=&#34;http://link.springer.com/10.1007/978-3-030-11298-1&#34;&gt;(Li &amp;amp; Vit√°nyi 2019)&lt;/a&gt;.
Chaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni &amp;lsquo;60!&lt;/p&gt;
&lt;p&gt;Solomonoff lo ha trovato sul problema dell&amp;rsquo;induzione all&amp;rsquo;et√† di 38 anni, Kolmogorov invece era gi√† tardi, ha gi√† trovato gli assiomi della probabilit√† e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilit√†, nel 68 all&amp;rsquo;et√† di 19 anni.
In AI teorico questo sembra un tema molto importante.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Legge di Coulomb</title>
      <link>https://flecart.github.io/notes/legge-di-coulomb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/legge-di-coulomb/</guid>
      <description>&lt;h2 id=&#34;introduzione-elettromagnetismo&#34;&gt;Introduzione elettromagnetismo&lt;/h2&gt;
&lt;h3 id=&#34;note-storiche-triboelettricit√†&#34;&gt;Note storiche: triboelettricit√†&lt;/h3&gt;
&lt;p&gt;Il concetto di &lt;strong&gt;campo&lt;/strong&gt; √® fondamentale per l&amp;rsquo;elettromagnetismo (vs forza in meccanica)
da un punto di vista storico √® nato tramite l&amp;rsquo;osservazione in fenomeni come lo strofinio fra vetro e pelle, dopo il quale hanno osservato ci fosse una forza nascosta (appunto &lt;strong&gt;ombra&lt;/strong&gt; dal greco di electron).
Il vetro si caricava poi abbastanza da poter attrarre carta per esempio. &lt;a href=&#34;https://youtu.be/iHBNWiHJaQQ?si=0GPKmcE2Oeh69zXj&#34;&gt;esempio dell&amp;rsquo;esperimento&lt;/a&gt;.  Se viene fatto invece fra due lastre in vetro invece diventa &lt;em&gt;repulsiva&lt;/em&gt; invece che attrattiva.
Questo effetto √® chiamato &lt;strong&gt;triboelettricit√†&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Legge di Gauss</title>
      <link>https://flecart.github.io/notes/legge-di-gauss/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/legge-di-gauss/</guid>
      <description>&lt;h3 id=&#34;introduzione-alla-legge-di-gauss&#34;&gt;Introduzione alla legge di gauss&lt;/h3&gt;
&lt;h4 id=&#34;giustificazione-con-angoli-solidi---&#34;&gt;Giustificazione con angoli solidi üü®&amp;ndash;&lt;/h4&gt;
$$
d\Phi = \vec{E}\cdot  \vec{dS} = \lvert \vec{E} \rvert \lvert \vec{dS} \rvert \cos \theta = \frac{1}{4\pi\varepsilon_{0}}\frac{1}{r^{2}} ds = \frac{Q}{4\pi\varepsilon}d\Omega 
$$&lt;p&gt;
Il secondo passaggio √® giustificabile andando su coordinate polari considerando &lt;strong&gt;l&amp;rsquo;angolo solido&lt;/strong&gt; di un oggetto quindi non dovrebbe essere un problema.&lt;/p&gt;
$$
\Phi = \int _{\sum} \, d\Phi= \int _{\sum}  \frac{Q}{4\pi\varepsilon}\, d\Omega =  \frac{Q}{4\pi\varepsilon}\int _{\sum}  \, d\Omega   = \frac{Q}{4\pi\varepsilon} 4\pi = \frac{Q}{\varepsilon}
$$&lt;p&gt;
Nota &lt;strong&gt;il flusso dipende solamente dalla CARICA&lt;/strong&gt;, indipendente dalla singola posizione.
!&lt;a href=&#34;https://flecart.github.io/notes/campo-elettrico-1696844095493.jpeg-&#34;&gt; 300&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Magnetismo</title>
      <link>https://flecart.github.io/notes/magnetismo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/magnetismo/</guid>
      <description>&lt;h3 id=&#34;introduzione-ai-campi-magnetici&#34;&gt;Introduzione ai campi magnetici&lt;/h3&gt;
&lt;h4 id=&#34;introduzione-storica-non-impo-&#34;&gt;Introduzione storica (non impo) üü©&lt;/h4&gt;
&lt;p&gt;Il magnetismo √® stato in primi osservato e documentato da Greci, che hanno osservato che materiali metallici come &lt;em&gt;ferro&lt;/em&gt;, questo √® successo in &lt;em&gt;magnesia&lt;/em&gt;, una penisola dell&amp;rsquo;Asia minore, mentre &lt;em&gt;elettro&lt;/em&gt; era pi√π sull&amp;rsquo;ambra, che credo fosse il nome dato a quel materiale.&lt;/p&gt;
&lt;p&gt;Una cosa nota era che se vicino a un materiale magnetico, venivano create linee con materiale ferroso all&amp;rsquo;estremit√† (limatura magnetica).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Project Management</title>
      <link>https://flecart.github.io/notes/project-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/project-management/</guid>
      <description>&lt;h4 id=&#34;project-product-management-project-management&#34;&gt;Project, product management, project management&lt;/h4&gt;
&lt;p&gt;Bisogna capire queste definizioni.
Vedere &lt;a href=&#34;https://dynamik.vercel.app/ingegneria-del-software/lucidi/13-gestione-del-progetto.pdf?from=informatica,&#34;&gt;&lt;a href=&#34;https://dynamik.vercel.app/ingegneria-del-software/lucidi/13-gestione-del-progetto.pdf?from=informatica&#34;&gt;https://dynamik.vercel.app/ingegneria-del-software/lucidi/13-gestione-del-progetto.pdf?from=informatica&lt;/a&gt;,&lt;/a&gt; slide 5 per definizione&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Progetto: inizia e finisce in tempo preciso.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;√à importante comunque ricordare gli steps principali per il progetto ossia ideazione, creazione, mantenimento, rilascio, e poi morte, questo in genere √® per qualunque progetto.&lt;/p&gt;
&lt;h3 id=&#34;project-manager&#34;&gt;Project Manager&lt;/h3&gt;
&lt;h4 id=&#34;compiti-principali-costi-e-risorse&#34;&gt;Compiti principali (costi e risorse)&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Vedere se il progetto √® fattibile&lt;/li&gt;
&lt;li&gt;Allocare risorse&lt;/li&gt;
&lt;li&gt;Monitorare come sta andando. (preventivo e consuntivo).
&lt;img src=&#34;https://flecart.github.io/images/notes/Project Management-1701099646139.jpeg&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;Project Management-1701099646139&#34;&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;work-breakdown-structure&#34;&gt;Work Breakdown structure&lt;/h3&gt;
&lt;h4 id=&#34;descrizione-wbs&#34;&gt;Descrizione WBS&lt;/h4&gt;
&lt;p&gt;√à una suddivisione del progetto in piccoli sottoparti che si possono gestire in modo autonomo.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
