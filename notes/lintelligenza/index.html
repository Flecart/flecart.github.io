<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>lâ€™intelligenza | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="no-tags">
<meta name="description" content="Ripasso Prox: 30 Ultima modifica: January 26, 2023 10:03 PM Primo Abbozzo: June 28, 2022 8:53 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No
Elementi di ripasso August 22, 2022
1 Introduzione Lâ€™intelligenza artificiale Ã¨ un campo in velocissima espansione, con giÃ  un mercato enorme di un trillion dollars.
Inoltre il suo campo di studi spazia da moltissimi campi, Ã¨ per questo che quasi potresti considerarla universale.
1.1 Lâ€™intelligenza artificiale 1.1.1 Cosa Ã¨ (2) Nel tempo si Ã¨ cercato di definire con esattessa cosa sia lâ€™intelligenza artificiale.">
<meta name="author" content="Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/lintelligenza/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/lintelligenza/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>


<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-WW6NN2QGKF', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="lâ€™intelligenza" />
<meta property="og:description" content="Ripasso Prox: 30 Ultima modifica: January 26, 2023 10:03 PM Primo Abbozzo: June 28, 2022 8:53 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No
Elementi di ripasso August 22, 2022
1 Introduzione Lâ€™intelligenza artificiale Ã¨ un campo in velocissima espansione, con giÃ  un mercato enorme di un trillion dollars.
Inoltre il suo campo di studi spazia da moltissimi campi, Ã¨ per questo che quasi potresti considerarla universale.
1.1 Lâ€™intelligenza artificiale 1.1.1 Cosa Ã¨ (2) Nel tempo si Ã¨ cercato di definire con esattessa cosa sia lâ€™intelligenza artificiale." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://flecart.github.io/notes/lintelligenza/" />
<meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png" />
<meta property="article:section" content="notes" />



<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png" />
<meta name="twitter:title" content="lâ€™intelligenza"/>
<meta name="twitter:description" content="Ripasso Prox: 30 Ultima modifica: January 26, 2023 10:03 PM Primo Abbozzo: June 28, 2022 8:53 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No
Elementi di ripasso August 22, 2022
1 Introduzione Lâ€™intelligenza artificiale Ã¨ un campo in velocissima espansione, con giÃ  un mercato enorme di un trillion dollars.
Inoltre il suo campo di studi spazia da moltissimi campi, Ã¨ per questo che quasi potresti considerarla universale.
1.1 Lâ€™intelligenza artificiale 1.1.1 Cosa Ã¨ (2) Nel tempo si Ã¨ cercato di definire con esattessa cosa sia lâ€™intelligenza artificiale."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "lâ€™intelligenza",
      "item": "https://flecart.github.io/notes/lintelligenza/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "lâ€™intelligenza",
  "name": "lâ€™intelligenza",
  "description": "Ripasso Prox: 30 Ultima modifica: January 26, 2023 10:03 PM Primo Abbozzo: June 28, 2022 8:53 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso August 22, 2022\n1 Introduzione Lâ€™intelligenza artificiale Ã¨ un campo in velocissima espansione, con giÃ  un mercato enorme di un trillion dollars.\nInoltre il suo campo di studi spazia da moltissimi campi, Ã¨ per questo che quasi potresti considerarla universale.\n1.1 Lâ€™intelligenza artificiale 1.1.1 Cosa Ã¨ (2) Nel tempo si Ã¨ cercato di definire con esattessa cosa sia lâ€™intelligenza artificiale.",
  "keywords": [
    "no-tags"
  ],
  "articleBody": "Ripasso Prox: 30 Ultima modifica: January 26, 2023 10:03 PM Primo Abbozzo: June 28, 2022 8:53 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso August 22, 2022\n1 Introduzione Lâ€™intelligenza artificiale Ã¨ un campo in velocissima espansione, con giÃ  un mercato enorme di un trillion dollars.\nInoltre il suo campo di studi spazia da moltissimi campi, Ã¨ per questo che quasi potresti considerarla universale.\n1.1 Lâ€™intelligenza artificiale 1.1.1 Cosa Ã¨ (2) Nel tempo si Ã¨ cercato di definire con esattessa cosa sia lâ€™intelligenza artificiale. In generare si Ã¨ basato su alcuni parametri cardine ossia:\nLa capacitÃ  di replicare attivitÃ  umane / la capacitÃ  di applicare attivitÃ  razionali La capacitÃ  di ragionare / il comportamento intelligente Su questi due binomi sono stati fatti dei modelli, andiamo ora a scoprire in che senso lâ€™intelligenza artificiale Ã¨ intelligente.\n1.1.2 Modelli generali Tra i modelli presenti quello di maggiore interesse nel tempo Ã¨ stato lâ€™ultimo, per il resto vanno a toccare molti campi che sono un pÃ² fuori dalle competenze dellâ€™informatico. (credo)\nAgire umanamente\nCome il test di turing, definisce lâ€™intelligenza artificiale come un software che riesce ad emulare il comportamento umano, talmente che non riusciresti a riconoscerlo.\nMa i ricercatori hanno preferito cercare di capire cosa Ã¨ lâ€™intelligenza in sÃ©, invece di cercare di emulare quella umana.\nPensare umanamente\nQuesto modello ha un campo molto fiorente nelle scienze cognitive, attraverso scan delle immagini, o comunque una conoscenza approfondita in primo luogo della stessa conoscenza umana, vogliamo cercare di costruire un intelligenza artificiale che ne emuli le capacitÃ  (pensiero interiore, psicologia etc).\nPensare logico\nQuesto Ã¨ stato uno dei primi metodi per costruire un software che si potesse considerare intelligente. Si basa sugli sviluppi della logica come campo di studi: ossia la possibilitÃ  di costruire software che siano in grado di dimostrare tutto il possibile.\nOppure utilizzando una analisi probabilistica, per analizzare la realtÃ .\nAgire logico\nLâ€™immagine dellâ€™agente Ã¨ stato il metodo piÃ¹ florido nella storia dellâ€™intelligenza artificiale nel momento in cui se ne voleva costruire una. Tanto che lâ€™obiettivo della costruzione di un ente che potesse agire in modo logico in un ambiente si potrebbe considerare come se fosse un modello standard per la costruzione di un intelligenza artificiale.\nUn problema perÃ² sorge: allineamento dei valori: a volte fare la cosa logicamente piÃ¹ corretta non Ã¨ la migliore soluzione, esempio se lâ€™obiettivo fosse vincere a tutti i costi una partita a scacchi, lâ€™agente, con la possibilitÃ  di agire sullâ€™ambiente circostante, potrebbe compiere azioni che solitamente considereremmo ingiuste, al solo scopo di raggiungere questo obiettivo! â†’ vorremmo costruire qualche agente che sia in grado di portare un beneficio provato (dimostrato).\n1.2 Lâ€™agente Definiamo in modo molto generale, lâ€™agente come qualcosa che possiede attuatori e percettori per interagire e percepire lâ€™ambiente (che puÃ² essere molto vario).\nUn concetto importante Ã¨ che lâ€™agente puÃ² basare il suo output attraverso solamente ciÃ² che ha percepito (dallâ€™inizio fino al tempo corrente) quindi potremmo considerare lâ€™esistenza di una funzione agente che mappa sequenza input â†’ azione. e lâ€™implementazione di essa.\n1.2.1 La razionalitÃ  Vogliamo cercare di dare una definizione di razionalitÃ  in qualunque agente, e si puÃ² formalizzare in questo modo: PEAS FRAMEWORK (performance, env, actuators, sensors)\nUna funzione di performance Lâ€™insieme delle conoscenze a priori sul mondo Lâ€™insieme delle azioni possibili sul mondo La sequenza di percepimento Con questi 4 oggetti, definiamo che lâ€™agente Ã¨ intelligente se la funzione che prende in input la sequenza di percezione e le conoscenze sul mondo, dia in output lâ€™azione che massimizza la performance.\nLa misura della performance\nIl modo migliore che abbiamo per misurare la performance Ã¨ sulle conseguenze che ha sullâ€™ambiente. Quindi valutare se lâ€™effetto che ha Ã¨ positivo (sempre in funzione alla positivitÃ  descritta da chi ha progettato lâ€™agente) o negativo.\nUna nota: Ã¨ importante costruire la performance secondo gli effetti sullâ€™ambiente, e non secondo il modo con cui si dovrebbe comportare lâ€™agente!\nMa non Ã¨ detto che sia il modo migliore per fare ciÃ², Ã¨ un problema piÃ¹ filosofico (quello sugli effetti uguali, ma uno sta basso e fa sempre, mentre lâ€™altro Ã¨ molto efficiente a momenti e per il resto del tempo sta proprio fermo).\nOnniscienza ed autonomia\nNon possiamo avere un agente che sappia tutto, bisogna tarare la performance su questa osservazione: lâ€™azione scelta non deve essere la migliore possibile in assoluto (altrimenti lâ€™agente dovrebbe sapere tutto) ma dovrebbe essere la migliore azione in guadagno atteso.\nQuesto comporta la migliore decisione che possa massimizzare scelte future (come raccolta delle informazioni si spende un pÃ² di tempo per raccogliere piÃ¹ informazioni sullâ€™ambiente) oppure lâ€™azione stessa nel caso si abbia giÃ  conoscenza sullâ€™ambiente.\nÃˆ da notare che il caso in cui si ha una totale conoscenza sullâ€™ambiente a priori (caso anche di alcune specie di animali come lowly dung beetle o sphex wasp) toglie di autonomia (ossia la capacitÃ  di agire a seconda di input ambientali e non solo secondo conoscenze a priori) allâ€™agente, e potrebbe non dare le soluzioni volute (in questi casi lâ€™agente agisce soltanto, perchÃ© pensa di sapere giÃ  tutto).\n1.2.2 Lâ€™ambiente Ci sono una moltitudine di variabili che possono risultare utili per classificare un ambiente tra cui:\nDeterminismo-nondeterminismo o stocastico OsservabilitÃ  parziale-totale singolo-multi agente episodico - sequenziale (si basa o no su eventi passati?) statico o dinamico (o semidinamico) (lâ€™ambiente puÃ² cambiare quando lâ€™agente pensa sul da farsi?) discreto o continuo (gli stati sono infiniti o finiti?) conosciuto o sconosciuto (i risultati delle azioni sono conosciute a priori, come se fossero leggi della fisica). Per esempio, il progetto mnk-game Ã¨ un ambiente che Ã¨ Determinista, totalmente osservabile, agente multiplo, sequenziale, statico, discreto e conosciuto.\nQuesti direi sono i 7 cardini che definiscono ad alto livello un ambiente.\n1.3 Tipologie di agente In questa parte vengono descritti le tipologie di agente a cui si Ã¨ pensato. Parlando in generale Ã¨ come se fossero dei modelli che vengono costruiti uno sopra lâ€™altro, in senso crescente, fino ad arrivare allâ€™agente che apprende come modello finale (correntemente piÃ¹ gettonato).\nI modelli qui presentati sono molto astratti, utili per semplicitÃ  e chiarezza, ma non ci aiuta in alcun modo per capire come implementare tale modello, tutti gli agenti qui presentati saranno di questo tipo\n1.3.1 Basati su riflessi Lâ€™agente che si basa sui riflessi Ã¨ il piÃ¹ semplice degli agenti che possono essere presenti. Come dice il nome si basa sul concetto di riflesso molto simile al riflesso umano, come sbattere le ciglia, scattare via da una fonte di calore simili azioni.\nSi tratta di un agente che agisce sulla singola percezione e trova lâ€™azione corrispondente a seguito di questa. Le percezioni passate non interessano proprio, sa giÃ  agire subito dalla percezione presente.\nCaratteristiche di questo agente:\nStaticitÃ  nelle azioni, esegue solo ciÃ² per cui Ã¨ programmato, quasi fosse un if-then agent, infatti dovremmo parlare di regole di condizione-azione\nNecessitÃ  di osservabilitÃ  totale, altrimenti Ã¨ difficile che faccia lâ€™azione piÃ¹ intelligente\nModello in breve\n1.3.2 Basati su modelli Questo modello si puÃ² considerare una espansione al modello precedente. Si cerca piano piano di rendere lâ€™agente piÃ¹ flessibile, e non soltanto qualcosa di programmato, come se fosse un singolo algoritmo:\nOra lâ€™agente possiede un modello interno del mondo, che Ã¨ cambiato a seconda della percezione nel momento. Quindi lâ€™azione ora non Ã¨ presa solamente secondo la percezione attuale, ma anche secondo il modello del mondo, e la percezione attuale.\nCaratteristiche\nFunzione di transizione del modello, che serve per aggiornare il modello interno del mondo a seconda dei cambiamenti percepiti Funzione di sensore, che traduce le informazioni percepite in funzione dello stato del mondo (es. se ho la telecamera sporca di acqua per la pioggia, lâ€™input sarÃ  un pÃ² diverso) Quindi maggiore flessibilitÃ  in confronto alla precedente.\nModello in breve\n1.3.3 Basati su obiettivi Lâ€™ulteriore espansione di questo agente rispetto alla precedente Ã¨ che ora il modello tiene conto anche delle possibili conseguenze future delle proprie azioni in funzione del raggiungimento o meno del proprio obiettivo\nCaratteristiche\nEsistenza di un obiettivo ben dichiarato proprio (che condiziona la funzione di valutazione) PossibilitÃ  di rimpiazzare lâ€™obiettivo precedente con uno simile (flessibilitÃ ) Aggiornamenti su conseguenze delle proprie azioni sullo stato del raggiungimento per lâ€™obiettivo Modello in breve\n1.3.4 Basati su utility cerca di valutare se Ã¨ una conseguenza buona o cattiva, a seconda di una propria funzione di valutazione che cerchi di rispettare il meglio possibile la funzione di valutazione dellâ€™ambiente in cui Ã¨ presente.\nÃˆ buono in caso ci possano essere degli obiettivi che si eliminano uno a vicenda, Ã¨ buono per trovare i tradeoff **comune in molte situazioni (es. voglio arrivare piÃ¹ in fretta possibile, ma non voglio investire persone).\nCaratteristiche\nUna funzione di valutazione che cerca di massimizzare il valore atteso della propria azione. Modello in breve\n1.3.5 Basati su apprendimento Al fine di avere un agente flessibile che possa adattarsi in ambienti anche molto differenti fra di loro, vorremmo creare un metodo per cui lâ€™agente possa imparare dai propri errori. Questo modello si prefissa lâ€™obiettivo di creare un framework generale per un agente che impara.\nCaratteristiche:\nCritico: cerca di valutare le azioni prese dallâ€™agente e pone consigli su cosa cambiare Elemento apprendimento: che cambia lo stato di conoscenza interna dellâ€™agente in modo che possa prendere decisioni migliori, grazie al feedback del critico generatore di problemi che propone nuovi problemi/esperimenti che possono migliorare altri tratti dellâ€™agente. Modello in breve\nLâ€™agente vecchio Ã¨ interamente raccolto nel performance element\n2 Registro ripassi dello in breve ",
  "wordCount" : "1568",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/lintelligenza/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;Â»&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      lâ€™intelligenza
    </h1>
    <div class="post-meta">8 min&nbsp;Â·&nbsp;Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#elementi-di-ripasso" aria-label="Elementi di ripasso">Elementi di ripasso</a></li>
                <li>
                    <a href="#1-introduzione" aria-label="1 Introduzione">1 Introduzione</a><ul>
                        
                <li>
                    <a href="#11-lintelligenza-artificiale" aria-label="1.1 Lâ€™intelligenza artificiale">1.1 Lâ€™intelligenza artificiale</a><ul>
                        
                <li>
                    <a href="#111-cosa-%c3%a8-2" aria-label="1.1.1 Cosa Ã¨ (2)">1.1.1 Cosa Ã¨ (2)</a></li>
                <li>
                    <a href="#112-modelli-generali" aria-label="1.1.2 Modelli generali">1.1.2 Modelli generali</a></li></ul>
                </li>
                <li>
                    <a href="#12-lagente" aria-label="1.2 Lâ€™agente">1.2 Lâ€™agente</a><ul>
                        
                <li>
                    <a href="#121-la-razionalit%c3%a0" aria-label="1.2.1 La razionalitÃ ">1.2.1 La razionalitÃ </a></li>
                <li>
                    <a href="#122-lambiente" aria-label="1.2.2 Lâ€™ambiente">1.2.2 Lâ€™ambiente</a></li></ul>
                </li>
                <li>
                    <a href="#13-tipologie-di-agente" aria-label="1.3 Tipologie di agente">1.3 Tipologie di agente</a><ul>
                        
                <li>
                    <a href="#131-basati-su-riflessi" aria-label="1.3.1 Basati su riflessi">1.3.1 Basati su riflessi</a></li>
                <li>
                    <a href="#132-basati-su-modelli" aria-label="1.3.2 Basati su modelli">1.3.2 Basati su modelli</a></li>
                <li>
                    <a href="#133-basati-su-obiettivi" aria-label="1.3.3 Basati su obiettivi">1.3.3 Basati su obiettivi</a></li>
                <li>
                    <a href="#134-basati-su-utility" aria-label="1.3.4 Basati su utility">1.3.4 Basati su utility</a></li>
                <li>
                    <a href="#135-basati-su-apprendimento" aria-label="1.3.5 Basati su apprendimento">1.3.5 Basati su apprendimento</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#2-registro-ripassi" aria-label="2 Registro ripassi">2 Registro ripassi</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Ripasso Prox: 30
Ultima modifica: January 26, 2023 10:03 PM
Primo Abbozzo: June 28, 2022 8:53 AM
Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•
Studi Personali: No</p>
<h1 id="elementi-di-ripasso">Elementi di ripasso<a hidden class="anchor" aria-hidden="true" href="#elementi-di-ripasso">#</a></h1>
<p>August 22, 2022</p>
<h1 id="1-introduzione">1 Introduzione<a hidden class="anchor" aria-hidden="true" href="#1-introduzione">#</a></h1>
<p>Lâ€™intelligenza artificiale Ã¨ un campo in velocissima espansione, con giÃ  un mercato enorme di un trillion dollars.</p>
<p>Inoltre il suo campo di studi spazia da moltissimi campi, Ã¨ per questo che quasi potresti considerarla <strong>universale</strong>.</p>
<h2 id="11-lintelligenza-artificiale">1.1 Lâ€™intelligenza artificiale<a hidden class="anchor" aria-hidden="true" href="#11-lintelligenza-artificiale">#</a></h2>
<h3 id="111-cosa-Ã¨-2">1.1.1 Cosa Ã¨ (2)<a hidden class="anchor" aria-hidden="true" href="#111-cosa-Ã¨-2">#</a></h3>
<p>Nel tempo si Ã¨ cercato di definire con esattessa cosa sia lâ€™intelligenza artificiale. In generare si Ã¨ basato su alcuni parametri cardine ossia:</p>
<ul>
<li>La capacitÃ  di replicare attivitÃ  umane / la capacitÃ  di applicare attivitÃ  razionali</li>
<li>La capacitÃ  di ragionare / il comportamento intelligente</li>
</ul>
<p>Su questi due binomi sono stati fatti dei modelli, andiamo ora a scoprire in che senso lâ€™intelligenza artificiale Ã¨ intelligente.</p>
<h3 id="112-modelli-generali">1.1.2 Modelli generali<a hidden class="anchor" aria-hidden="true" href="#112-modelli-generali">#</a></h3>
<p>Tra i modelli presenti quello di maggiore interesse nel tempo Ã¨ stato lâ€™ultimo, per il resto vanno a toccare molti campi che sono un pÃ² fuori dalle competenze dellâ€™informatico. (credo)</p>
<p><strong>Agire umanamente</strong></p>
<p>Come il test di turing, definisce lâ€™intelligenza artificiale come un software che riesce ad emulare il comportamento umano, talmente che non riusciresti a riconoscerlo.</p>
<p>Ma i ricercatori hanno preferito cercare di capire cosa Ã¨ lâ€™intelligenza in sÃ©, invece di cercare di emulare quella umana.</p>
<p><strong>Pensare umanamente</strong></p>
<p>Questo modello ha un campo molto fiorente nelle <em>scienze cognitive</em>, attraverso scan delle immagini, o comunque una conoscenza approfondita in primo luogo della stessa conoscenza umana, vogliamo cercare di costruire un intelligenza artificiale che ne emuli le capacitÃ  (pensiero interiore, psicologia etc).</p>
<p><strong>Pensare logico</strong></p>
<p>Questo Ã¨ stato uno dei primi metodi per costruire un software che si potesse considerare intelligente. Si basa sugli sviluppi della logica come campo di studi: ossia la possibilitÃ  di costruire software che siano in grado di dimostrare tutto il possibile.</p>
<p>Oppure utilizzando una analisi probabilistica, per analizzare la realtÃ .</p>
<p><strong>Agire logico</strong></p>
<p>Lâ€™immagine dellâ€™agente Ã¨ stato il metodo piÃ¹ florido nella storia dellâ€™intelligenza artificiale nel momento in cui se ne voleva costruire una. Tanto che lâ€™obiettivo della costruzione di un ente che potesse agire in modo logico in un ambiente si potrebbe considerare come se fosse un modello standard per la costruzione di un intelligenza artificiale.</p>
<p>Un problema perÃ² sorge: allineamento dei valori: a volte fare la cosa logicamente piÃ¹ corretta non Ã¨ la migliore soluzione, esempio se lâ€™obiettivo fosse vincere a tutti i costi una partita a scacchi, lâ€™agente, con la possibilitÃ  di agire sull&rsquo;ambiente circostante, potrebbe compiere azioni che solitamente considereremmo ingiuste, al solo scopo di raggiungere questo obiettivo! â†’ vorremmo costruire qualche agente che sia in grado di portare un beneficio provato (dimostrato).</p>
<h2 id="12-lagente">1.2 Lâ€™agente<a hidden class="anchor" aria-hidden="true" href="#12-lagente">#</a></h2>
<p>Definiamo in modo molto generale, lâ€™agente come qualcosa che possiede <strong>attuatori e percettori</strong> per interagire e percepire lâ€™ambiente (che puÃ² essere molto vario).</p>
<p>Un concetto importante Ã¨ che lâ€™agente puÃ² basare il suo output attraverso solamente ciÃ² che ha percepito (dall&rsquo;inizio fino al tempo corrente) quindi potremmo considerare lâ€™esistenza di una <strong>funzione agente</strong> che mappa sequenza input â†’ azione. e lâ€™implementazione di essa.</p>
<h3 id="121-la-razionalitÃ ">1.2.1 La razionalitÃ <a hidden class="anchor" aria-hidden="true" href="#121-la-razionalitÃ ">#</a></h3>
<p>Vogliamo cercare di dare una definizione di razionalitÃ  in qualunque agente, e si puÃ² formalizzare in questo modo: <strong>PEAS FRAMEWORK</strong> (performance, env, actuators, sensors)</p>
<ol>
<li>Una funzione di performance</li>
<li>Lâ€™insieme delle conoscenze a priori sul mondo</li>
<li>Lâ€™insieme delle azioni possibili sul mondo</li>
<li>La sequenza di percepimento</li>
</ol>
<p>Con questi 4 oggetti, definiamo che lâ€™agente Ã¨ intelligente se la funzione che prende in input la sequenza di percezione e le conoscenze sul mondo, dia in output lâ€™azione che massimizza la performance.</p>
<p><strong>La misura della performance</strong></p>
<p>Il modo migliore che abbiamo per misurare la performance Ã¨ sulle conseguenze che ha sull&rsquo;ambiente. Quindi valutare se lâ€™effetto che ha Ã¨ positivo (sempre in funzione alla positivitÃ  descritta da chi ha progettato lâ€™agente) o negativo.</p>
<p>Una nota: Ã¨ importante costruire la performance secondo gli effetti sull&rsquo;ambiente, e non secondo il modo con cui si dovrebbe comportare lâ€™agente!</p>
<p>Ma non Ã¨ detto che sia il modo migliore per fare ciÃ², Ã¨ un problema piÃ¹ filosofico (quello sugli effetti uguali, ma uno sta basso e fa sempre, mentre lâ€™altro Ã¨ molto efficiente a momenti e per il resto del tempo sta proprio fermo).</p>
<p><strong>Onniscienza ed autonomia</strong></p>
<p>Non possiamo avere un agente che sappia tutto, bisogna tarare la performance su questa osservazione: lâ€™azione scelta non deve essere la migliore possibile in assoluto (altrimenti lâ€™agente dovrebbe sapere tutto) ma dovrebbe essere la migliore azione in guadagno atteso.</p>
<p>Questo comporta la migliore decisione che possa massimizzare scelte future (come <em>raccolta delle informazioni</em> si spende un pÃ² di tempo per raccogliere piÃ¹ informazioni sullâ€™ambiente) oppure lâ€™azione stessa nel caso si abbia giÃ  conoscenza sullâ€™ambiente.</p>
<p>Ãˆ da notare che il caso in cui si ha una totale conoscenza sullâ€™ambiente a priori (caso anche di alcune specie di animali come lowly dung beetle o sphex wasp) toglie di autonomia (ossia la capacitÃ  di agire a seconda di input ambientali e non solo secondo conoscenze a priori) allâ€™agente, e potrebbe non dare le soluzioni volute (in questi casi lâ€™agente agisce soltanto, perchÃ© pensa di sapere giÃ  tutto).</p>
<h3 id="122-lambiente">1.2.2 Lâ€™ambiente<a hidden class="anchor" aria-hidden="true" href="#122-lambiente">#</a></h3>
<p>Ci sono una moltitudine di variabili che possono risultare utili per classificare un ambiente tra cui:</p>
<ol>
<li>Determinismo-nondeterminismo o stocastico</li>
<li>OsservabilitÃ  parziale-totale</li>
<li>singolo-multi agente</li>
<li>episodico - sequenziale (si basa o no su eventi passati?)</li>
<li>statico o dinamico (o semidinamico) (lâ€™ambiente puÃ² cambiare quando lâ€™agente pensa sul da farsi?)</li>
<li>discreto o continuo (gli stati sono infiniti o finiti?)</li>
<li>conosciuto o sconosciuto (i risultati delle azioni sono conosciute a priori, come se fossero leggi della fisica).</li>
</ol>
<p>Per esempio, il progetto mnk-game Ã¨ un ambiente che Ã¨  Determinista, totalmente osservabile, agente multiplo, sequenziale, statico, discreto e conosciuto.</p>
<p>Questi direi sono i 7 cardini che definiscono ad alto livello un ambiente.</p>
<h2 id="13-tipologie-di-agente">1.3 Tipologie di agente<a hidden class="anchor" aria-hidden="true" href="#13-tipologie-di-agente">#</a></h2>
<p>In questa parte vengono descritti le tipologie di agente a cui si Ã¨ pensato. Parlando in generale Ã¨ come se fossero dei modelli che vengono costruiti uno sopra lâ€™altro, in senso crescente, fino ad arrivare allâ€™agente che apprende come modello finale (correntemente piÃ¹ gettonato).</p>
<p>I modelli qui presentati sono molto astratti, utili per semplicitÃ  e chiarezza, ma non ci aiuta in alcun modo per capire come implementare tale modello, tutti gli agenti qui presentati saranno di questo tipo</p>
<h3 id="131-basati-su-riflessi">1.3.1 Basati su riflessi<a hidden class="anchor" aria-hidden="true" href="#131-basati-su-riflessi">#</a></h3>
<p>Lâ€™agente che si basa sui riflessi Ã¨ il piÃ¹ semplice degli agenti che possono essere presenti. Come dice il nome si basa sul concetto di riflesso molto simile al riflesso umano, come sbattere le ciglia, scattare via da una fonte di calore simili azioni.</p>
<p>Si tratta di un agente che agisce sulla singola percezione e trova lâ€™azione corrispondente a seguito di questa. Le percezioni passate non interessano proprio, sa giÃ  agire subito dalla percezione presente.</p>
<p><strong>Caratteristiche di questo agente:</strong></p>
<ul>
<li>
<p>StaticitÃ  nelle azioni, esegue solo ciÃ² per cui Ã¨ programmato, quasi fosse un if-then agent, infatti dovremmo parlare di regole di condizione-azione</p>
</li>
<li>
<p>NecessitÃ  di osservabilitÃ  totale, altrimenti Ã¨ difficile che faccia lâ€™azione piÃ¹ intelligente</p>
</li>
<li>
<p>Modello in breve</p>
  <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled">
  <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 1.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 1">
</li>
</ul>
<h3 id="132-basati-su-modelli">1.3.2 Basati su modelli<a hidden class="anchor" aria-hidden="true" href="#132-basati-su-modelli">#</a></h3>
<p>Questo modello si puÃ² considerare una espansione al modello precedente. Si cerca piano piano di rendere lâ€™agente piÃ¹ flessibile, e non soltanto qualcosa di programmato, come se fosse un singolo algoritmo:</p>
<p>Ora lâ€™agente possiede un modello interno del mondo, che Ã¨ cambiato a seconda della percezione nel momento. Quindi lâ€™azione ora non Ã¨ presa solamente secondo la percezione attuale, ma anche secondo il modello del mondo, e la percezione attuale.</p>
<p><strong>Caratteristiche</strong></p>
<ol>
<li>Funzione di transizione del modello, che serve per aggiornare il modello interno del mondo a seconda dei cambiamenti percepiti</li>
<li>Funzione di sensore, che traduce le informazioni percepite in funzione dello stato del mondo (es. se ho la telecamera sporca di acqua per la pioggia, lâ€™input sarÃ  un pÃ² diverso)</li>
</ol>
<p>Quindi maggiore flessibilitÃ  in confronto alla precedente.</p>
<ul>
<li>
<p>Modello in breve</p>
  <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 2.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 2">
  <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 3.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 3">
</li>
</ul>
<h3 id="133-basati-su-obiettivi">1.3.3 Basati su obiettivi<a hidden class="anchor" aria-hidden="true" href="#133-basati-su-obiettivi">#</a></h3>
<p>Lâ€™ulteriore espansione di questo agente rispetto alla precedente Ã¨ che ora il modello tiene conto anche delle possibili conseguenze future delle proprie azioni in funzione del raggiungimento o meno del proprio obiettivo</p>
<p><strong>Caratteristiche</strong></p>
<ol>
<li>Esistenza di un obiettivo ben dichiarato proprio (che condiziona la funzione di valutazione)</li>
<li>PossibilitÃ  di rimpiazzare lâ€™obiettivo precedente con uno simile (flessibilitÃ )</li>
<li>Aggiornamenti su conseguenze delle proprie azioni sullo stato del raggiungimento per lâ€™obiettivo</li>
</ol>
<ul>
<li>
<p>Modello in breve</p>
  <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 4.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 4">
</li>
</ul>
<h3 id="134-basati-su-utility">1.3.4 Basati su utility<a hidden class="anchor" aria-hidden="true" href="#134-basati-su-utility">#</a></h3>
<p>cerca di valutare se Ã¨ una conseguenza buona o cattiva, a seconda di una propria <em>funzione di valutazione</em> che cerchi di rispettare il meglio possibile la funzione di valutazione dellâ€™ambiente in cui Ã¨ presente.</p>
<p>Ãˆ buono in caso ci possano essere degli obiettivi che si eliminano uno a vicenda, Ã¨ buono per trovare i tradeoff **comune in molte situazioni (es. voglio arrivare piÃ¹ in fretta possibile, ma non voglio investire persone).</p>
<p><strong>Caratteristiche</strong></p>
<ol>
<li>Una funzione di valutazione che cerca di <em>massimizzare il valore atteso della propria azione.</em></li>
</ol>
<ul>
<li>
<p>Modello in breve</p>
  <img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 5.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 5">
</li>
</ul>
<h3 id="135-basati-su-apprendimento">1.3.5 Basati su apprendimento<a hidden class="anchor" aria-hidden="true" href="#135-basati-su-apprendimento">#</a></h3>
<p>Al fine di avere un agente flessibile che possa adattarsi in ambienti anche molto differenti fra di loro, vorremmo creare un metodo per cui lâ€™agente possa imparare dai propri errori. Questo modello si prefissa lâ€™obiettivo di creare un framework generale per un agente che impara.</p>
<p><strong>Caratteristiche:</strong></p>
<ol>
<li>Critico: cerca di valutare le azioni prese dallâ€™agente e pone consigli su cosa cambiare</li>
<li>Elemento apprendimento: che cambia lo <em>stato di conoscenza interna</em> dellâ€™agente in modo che possa prendere decisioni migliori, grazie al feedback del critico</li>
<li>generatore di problemi che propone nuovi problemi/esperimenti che possono migliorare altri tratti dellâ€™agente.</li>
</ol>
<ul>
<li>
<p>Modello in breve</p>
<p>Lâ€™agente vecchio Ã¨ interamente raccolto nel performance element</p>
</li>
</ul>
<img src="/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 6.png" alt="image/universita/ex-notion/lâ€™intelligenza/Untitled 6">
<pre><code>&lt;img src=&quot;/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 6.png&quot; alt=&quot;image/universita/ex-notion/lâ€™intelligenza/Untitled 6&quot;&gt;
</code></pre>
<h1 id="2-registro-ripassi">2 Registro ripassi<a hidden class="anchor" aria-hidden="true" href="#2-registro-ripassi">#</a></h1>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>dello in breve</td>
<td></td>
</tr>
</tbody>
</table>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://flecart.github.io/tags/no-tags/">No-Tags</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share lâ€™intelligenza on x"
            href="https://x.com/intent/tweet/?text=l%e2%80%99intelligenza&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2flintelligenza%2f&amp;hashtags=no-tags">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share lâ€™intelligenza on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2flintelligenza%2f&amp;title=l%e2%80%99intelligenza&amp;summary=l%e2%80%99intelligenza&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2flintelligenza%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share lâ€™intelligenza on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2flintelligenza%2f&title=l%e2%80%99intelligenza">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share lâ€™intelligenza on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2flintelligenza%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share lâ€™intelligenza on whatsapp"
            href="https://api.whatsapp.com/send?text=l%e2%80%99intelligenza%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2flintelligenza%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share lâ€™intelligenza on telegram"
            href="https://telegram.me/share/url?text=l%e2%80%99intelligenza&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2flintelligenza%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share lâ€™intelligenza on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=l%e2%80%99intelligenza&u=https%3a%2f%2fflecart.github.io%2fnotes%2flintelligenza%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
