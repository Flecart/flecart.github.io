<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Sparse Matrix Vector Multiplication | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="advanced-systems-lab">
<meta name="description" content="Algorithms for Sparse Matrix-Vector  Multiplication
Compressed Sparse Row
This is an optimized way to store rows for sparse matrices:

Sparse MVM using CSR
void smvm(int m, const double* values, const int* col_idx,
          const int* row_start, double* x, double* y) {
    int i, j;
    double d;

    /* Loop over m rows */
    for (i = 0; i &lt; m; i&#43;&#43;) {
        d = y[i]; /* Scalar replacement since reused */

        /* Loop over non-zero elements in row i */
        for (j = row_start[i]; j &lt; row_start[i &#43; 1]; j&#43;&#43;) {
            d &#43;= values[j] * x[col_idx[j]];
        }

        y[i] = d;
    }
}
Let&rsquo;s analyze this code:

Spatial locality: with respect to row_start, col_idx and values we have spatial locality.
Temporal locality: with respect to y we have temporal locality. (Poor temporal with respect to $x$)
Good storage efficiency for the sparse matrix.
But it is 2x slower than the dense matrix multiplication when the matrix is dense.

Block CSR

But we cannot do block optimizations for the cache with this storage method.">
<meta name="author" content="
By Xuanqiang Angelo Huang">
<link rel="canonical" href="https://flecart.github.io/notes/sparse-matrix-vector-multiplication/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f790d9af969c56c079c1ce2d5972a04486bf3d6144295d5fba319830e1e55a7a.css" integrity="sha256-95DZr5acVsB5wc4tWXKgRIa/PWFEKV1fujGYMOHlWno=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/sparse-matrix-vector-multiplication/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>






      <script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-WW6NN2QGKF');
        }
      </script><meta property="og:url" content="https://flecart.github.io/notes/sparse-matrix-vector-multiplication/">
  <meta property="og:site_name" content="X. Angelo Huang&#39;s Blog">
  <meta property="og:title" content="Sparse Matrix Vector Multiplication">
  <meta property="og:description" content="Algorithms for Sparse Matrix-Vector Multiplication Compressed Sparse Row This is an optimized way to store rows for sparse matrices: Sparse MVM using CSR void smvm(int m, const double* values, const int* col_idx, const int* row_start, double* x, double* y) { int i, j; double d; /* Loop over m rows */ for (i = 0; i &lt; m; i&#43;&#43;) { d = y[i]; /* Scalar replacement since reused */ /* Loop over non-zero elements in row i */ for (j = row_start[i]; j &lt; row_start[i &#43; 1]; j&#43;&#43;) { d &#43;= values[j] * x[col_idx[j]]; } y[i] = d; } } Let’s analyze this code:
Spatial locality: with respect to row_start, col_idx and values we have spatial locality. Temporal locality: with respect to y we have temporal locality. (Poor temporal with respect to $x$) Good storage efficiency for the sparse matrix. But it is 2x slower than the dense matrix multiplication when the matrix is dense. Block CSR But we cannot do block optimizations for the cache with this storage method.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="notes">
    <meta property="article:published_time" content="2024-04-07T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-04-07T00:00:00+00:00">
    <meta property="article:tag" content="Advanced-Systems-Lab">
      <meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:title" content="Sparse Matrix Vector Multiplication">
<meta name="twitter:description" content="Algorithms for Sparse Matrix-Vector  Multiplication
Compressed Sparse Row
This is an optimized way to store rows for sparse matrices:

Sparse MVM using CSR
void smvm(int m, const double* values, const int* col_idx,
          const int* row_start, double* x, double* y) {
    int i, j;
    double d;

    /* Loop over m rows */
    for (i = 0; i &lt; m; i&#43;&#43;) {
        d = y[i]; /* Scalar replacement since reused */

        /* Loop over non-zero elements in row i */
        for (j = row_start[i]; j &lt; row_start[i &#43; 1]; j&#43;&#43;) {
            d &#43;= values[j] * x[col_idx[j]];
        }

        y[i] = d;
    }
}
Let&rsquo;s analyze this code:

Spatial locality: with respect to row_start, col_idx and values we have spatial locality.
Temporal locality: with respect to y we have temporal locality. (Poor temporal with respect to $x$)
Good storage efficiency for the sparse matrix.
But it is 2x slower than the dense matrix multiplication when the matrix is dense.

Block CSR

But we cannot do block optimizations for the cache with this storage method.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Sparse Matrix Vector Multiplication",
      "item": "https://flecart.github.io/notes/sparse-matrix-vector-multiplication/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Sparse Matrix Vector Multiplication",
  "name": "Sparse Matrix Vector Multiplication",
  "description": "Algorithms for Sparse Matrix-Vector Multiplication Compressed Sparse Row This is an optimized way to store rows for sparse matrices: Sparse MVM using CSR void smvm(int m, const double* values, const int* col_idx, const int* row_start, double* x, double* y) { int i, j; double d; /* Loop over m rows */ for (i = 0; i \u0026lt; m; i++) { d = y[i]; /* Scalar replacement since reused */ /* Loop over non-zero elements in row i */ for (j = row_start[i]; j \u0026lt; row_start[i + 1]; j++) { d += values[j] * x[col_idx[j]]; } y[i] = d; } } Let\u0026rsquo;s analyze this code:\nSpatial locality: with respect to row_start, col_idx and values we have spatial locality. Temporal locality: with respect to y we have temporal locality. (Poor temporal with respect to $x$) Good storage efficiency for the sparse matrix. But it is 2x slower than the dense matrix multiplication when the matrix is dense. Block CSR But we cannot do block optimizations for the cache with this storage method.\n",
  "keywords": [
    "advanced-systems-lab"
  ],
  "articleBody": "Algorithms for Sparse Matrix-Vector Multiplication Compressed Sparse Row This is an optimized way to store rows for sparse matrices: Sparse MVM using CSR void smvm(int m, const double* values, const int* col_idx, const int* row_start, double* x, double* y) { int i, j; double d; /* Loop over m rows */ for (i = 0; i \u003c m; i++) { d = y[i]; /* Scalar replacement since reused */ /* Loop over non-zero elements in row i */ for (j = row_start[i]; j \u003c row_start[i + 1]; j++) { d += values[j] * x[col_idx[j]]; } y[i] = d; } } Let’s analyze this code:\nSpatial locality: with respect to row_start, col_idx and values we have spatial locality. Temporal locality: with respect to y we have temporal locality. (Poor temporal with respect to $x$) Good storage efficiency for the sparse matrix. But it is 2x slower than the dense matrix multiplication when the matrix is dense. Block CSR But we cannot do block optimizations for the cache with this storage method.\nBlocked Sparse MVM void smvm_2x2(int bm, const int *b_row_start, const int *b_col_idx, const double *b_values, double *x, double *y) { int i, j; double d0, d1, c0, c1; /* Loop over bm block rows */ for (i = 0; i \u003c bm; i++) { d0 = y[2 * i]; /* Scalar replacement since reused */ d1 = y[2 * i + 1]; /* Dense micro MVM */ for (j = b_row_start[i]; j \u003c b_row_start[i + 1]; j++, b_values += 2 * 2) { c0 = x[2 * b_col_idx[j] + 0]; /* Scalar replacement since reused */ c1 = x[2 * b_col_idx[j] + 1]; d0 += b_values[0] * c0; d1 += b_values[2] * c0; d0 += b_values[1] * c1; d1 += b_values[3] * c1; } y[2 * i] = d0; y[2 * i + 1] = d1; } } Temporal locality both with respect to y and x Lower storage for indexes, but higher for the data. Computational overhead due to the zeros. They discovered that the performance was quite machine dependent, they couldn’t se clearly a pattern in the beginning. Then if you wanted to use autotuning using matrix multiplication, then you would have just too many choices (r, c, variables are too much from 1 to 12). The conversion from CSR to blocked CSR is not trivial, the authors estimated it to cost about 10 Single Matrix Vector Multiplications, so the total cost of the search would be 1440 single matrix vector multiplications, which is just too much. See Fast Linear Algebra for ATLAS model.\nSimple model They created a simple model to compare the performance of the blocked sparse MVM with the standard sparse MVM. They got the perfromances for a dense matrix: that was speed up, divided by the computational overhead (slowdown, due to the zeros). This model has been proven to work quite well.\nCompression methods for MVM It is memory bound, so if you find nice compression ways, you can get higher performance!\nValue Compression #### Index Compression Pattern-based compression Minuet This is one algorithm that is used for sparse matrix convolutions, original solutions use hash tables, but these are not very much cache efficient. Cache Optimization is one note that you can see. They tried many different hash functions, but it’s different to design one that has high locality, while keeping the hash properties. See (Yang et al. 2023).\nSorted queries make it more memory friendly, which has nice improvements even if computationally is more expensive. In Binary Search lookup you have smaller blocks that have nicer locality, and use binary search in one of the blocks. This is one example of explicitly designed blocks that help make things faster (computationally cheaper and memory friendly). This was 19.2x times faster in GPU tables.\nThey are able to reconfigure the computation in order to make it $\\mathcal{O}(M \\log \\log M)$ and efficient for data movement. It is also possible to use SRAM, the same idea that was present in (Dao et al. 2022).\nThey get 2.2x maximum in object detection at the end.\nReferences [1] Yang et al. “Minuet: Accelerating 3D Sparse Convolutions on GPUs” arXiv preprint arXiv:2401.06145 2023 [2] Dao et al. “FLASHATTENTION: Fast and Memory-Efficient Exact Attention with IO-awareness” Curran Associates Inc. 2022 ",
  "wordCount" : "710",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "2024-04-07T00:00:00Z",
  "dateModified": "2024-04-07T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang Angelo Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/sparse-matrix-vector-multiplication/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Sparse Matrix Vector Multiplication
    </h1>
    <div class="post-meta"><span title='2024-04-07 00:00:00 +0000 UTC'>April 7, 2024</span>&nbsp;·&nbsp;Reading Time: 4 minutes&nbsp;·&nbsp;
By Xuanqiang Angelo Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul><ul>
                <li>
                    <a href="#algorithms-for-sparse-matrix-vector--multiplication" aria-label="Algorithms for Sparse Matrix-Vector  Multiplication">Algorithms for Sparse Matrix-Vector  Multiplication</a><ul>
                        
                <li>
                    <a href="#compressed-sparse-row" aria-label="Compressed Sparse Row">Compressed Sparse Row</a></li>
                <li>
                    <a href="#sparse-mvm-using-csr" aria-label="Sparse MVM using CSR">Sparse MVM using CSR</a></li>
                <li>
                    <a href="#block-csr" aria-label="Block CSR">Block CSR</a></li>
                <li>
                    <a href="#blocked-sparse-mvm" aria-label="Blocked Sparse MVM">Blocked Sparse MVM</a></li>
                <li>
                    <a href="#simple-model" aria-label="Simple model">Simple model</a></li></ul>
                </li>
                <li>
                    <a href="#compression-methods-for-mvm" aria-label="Compression methods for MVM">Compression methods for MVM</a><ul>
                        
                <li>
                    <a href="#value-compression" aria-label="Value Compression">Value Compression</a></li>
                <li>
                    <a href="#pattern-based-compression" aria-label="Pattern-based compression">Pattern-based compression</a></li></ul>
                </li>
                <li>
                    <a href="#minuet" aria-label="Minuet">Minuet</a></li></ul>
                    </ul>
                    
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="algorithms-for-sparse-matrix-vector--multiplication">Algorithms for Sparse Matrix-Vector  Multiplication<a hidden class="anchor" aria-hidden="true" href="#algorithms-for-sparse-matrix-vector--multiplication">#</a></h3>
<h4 id="compressed-sparse-row">Compressed Sparse Row<a hidden class="anchor" aria-hidden="true" href="#compressed-sparse-row">#</a></h4>
<p>This is an optimized way to store rows for sparse matrices:
<img src="/images/notes/Cache Optimization-20250331112244798.webp" style="width: 100%" class="center" alt="Cache Optimization-20250331112244798"></p>
<h4 id="sparse-mvm-using-csr">Sparse MVM using CSR<a hidden class="anchor" aria-hidden="true" href="#sparse-mvm-using-csr">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">smvm</span><span class="p">(</span><span class="kt">int</span> <span class="n">m</span><span class="p">,</span> <span class="k">const</span> <span class="kt">double</span><span class="o">*</span> <span class="n">values</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span><span class="o">*</span> <span class="n">col_idx</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">          <span class="k">const</span> <span class="kt">int</span><span class="o">*</span> <span class="n">row_start</span><span class="p">,</span> <span class="kt">double</span><span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="kt">double</span><span class="o">*</span> <span class="n">y</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">double</span> <span class="n">d</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="cm">/* Loop over m rows */</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">m</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">d</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span> <span class="cm">/* Scalar replacement since reused */</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="cm">/* Loop over non-zero elements in row i */</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="n">row_start</span><span class="p">[</span><span class="n">i</span><span class="p">];</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">row_start</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">];</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">d</span> <span class="o">+=</span> <span class="n">values</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">col_idx</span><span class="p">[</span><span class="n">j</span><span class="p">]];</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>Let&rsquo;s analyze this code:</p>
<ul>
<li><strong>Spatial locality</strong>: with respect to <code>row_start</code>, <code>col_idx</code> and <code>values</code> we have spatial locality.</li>
<li><strong>Temporal locality</strong>: with respect to <code>y</code> we have temporal locality. (Poor temporal with respect to $x$)</li>
<li>Good storage efficiency for the sparse matrix.</li>
<li>But it is 2x slower than the dense matrix multiplication when the matrix is dense.</li>
</ul>
<h4 id="block-csr">Block CSR<a hidden class="anchor" aria-hidden="true" href="#block-csr">#</a></h4>
<img src="/images/notes/Sparse Matrix Vector Multiplication-20250331112834561.webp" style="width: 100%" class="center" alt="Sparse Matrix Vector Multiplication-20250331112834561">
<p>But we cannot do block optimizations for the cache with this storage method.</p>
<h4 id="blocked-sparse-mvm">Blocked Sparse MVM<a hidden class="anchor" aria-hidden="true" href="#blocked-sparse-mvm">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">smvm_2x2</span><span class="p">(</span><span class="kt">int</span> <span class="n">bm</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b_row_start</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b_col_idx</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">              <span class="k">const</span> <span class="kt">double</span> <span class="o">*</span><span class="n">b_values</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">y</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">double</span> <span class="n">d0</span><span class="p">,</span> <span class="n">d1</span><span class="p">,</span> <span class="n">c0</span><span class="p">,</span> <span class="n">c1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="cm">/* Loop over bm block rows */</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">bm</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">d0</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span><span class="p">];</span>     <span class="cm">/* Scalar replacement since reused */</span>
</span></span><span class="line"><span class="cl">        <span class="n">d1</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="cm">/* Dense micro MVM */</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="n">b_row_start</span><span class="p">[</span><span class="n">i</span><span class="p">];</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">b_row_start</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">];</span> <span class="n">j</span><span class="o">++</span><span class="p">,</span> <span class="n">b_values</span> <span class="o">+=</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">c0</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">b_col_idx</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">0</span><span class="p">];</span> <span class="cm">/* Scalar replacement since reused */</span>
</span></span><span class="line"><span class="cl">            <span class="n">c1</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">b_col_idx</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">d0</span> <span class="o">+=</span> <span class="n">b_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">c0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="n">d1</span> <span class="o">+=</span> <span class="n">b_values</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">c0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="n">d0</span> <span class="o">+=</span> <span class="n">b_values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">c1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="n">d1</span> <span class="o">+=</span> <span class="n">b_values</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="n">c1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">y</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">d0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">y</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">d1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><ul>
<li>Temporal locality both with respect to <code>y</code> and <code>x</code></li>
<li>Lower storage for indexes, but higher for the data.</li>
<li>Computational overhead due to the zeros.</li>
</ul>
<p>They discovered that the performance was quite machine dependent, they couldn&rsquo;t se clearly a pattern in the beginning. Then if you wanted to use autotuning using matrix multiplication, then you would have just too many choices (r, c, variables are too much from 1 to 12).
The conversion from CSR to blocked CSR is not trivial, the authors estimated it to cost about 10 Single Matrix Vector Multiplications, so the total cost of the search would be 1440 single matrix vector multiplications, which is just too much.
See <a href="/notes/fast-linear-algebra">Fast Linear Algebra</a> for ATLAS model.</p>
<h4 id="simple-model">Simple model<a hidden class="anchor" aria-hidden="true" href="#simple-model">#</a></h4>
<p>They created a simple model to compare the performance of the blocked sparse MVM with the standard sparse MVM.
They got the perfromances for a dense matrix: that was speed up, divided by the computational overhead (slowdown, due to the zeros).
This model has been proven to work quite well.</p>
<h3 id="compression-methods-for-mvm">Compression methods for MVM<a hidden class="anchor" aria-hidden="true" href="#compression-methods-for-mvm">#</a></h3>
<p>It is memory bound, so if you find nice compression ways, you can get higher performance!</p>
<h4 id="value-compression">Value Compression<a hidden class="anchor" aria-hidden="true" href="#value-compression">#</a></h4>
<img src="/images/notes/Sparse Matrix Vector Multiplication-20250331114937698.webp" style="width: 100%" class="center" alt="Sparse Matrix Vector Multiplication-20250331114937698">
#### Index Compression
<img src="/images/notes/Sparse Matrix Vector Multiplication-20250331115326387.webp" style="width: 100%" class="center" alt="Sparse Matrix Vector Multiplication-20250331115326387">
<h4 id="pattern-based-compression">Pattern-based compression<a hidden class="anchor" aria-hidden="true" href="#pattern-based-compression">#</a></h4>
<img src="/images/notes/Sparse Matrix Vector Multiplication-20250331115128267.webp" style="width: 100%" class="center" alt="Sparse Matrix Vector Multiplication-20250331115128267">
<h3 id="minuet">Minuet<a hidden class="anchor" aria-hidden="true" href="#minuet">#</a></h3>
<p>This is one algorithm that is used for sparse matrix convolutions, original solutions use <strong>hash tables</strong>, but these are not very much cache efficient. <a href="/notes/cache-optimization">Cache Optimization</a> is one note that you can see. They tried many different hash functions, but it&rsquo;s different to design one that has high locality, while keeping the hash properties.
See <a href="http://arxiv.org/abs/2401.06145">(Yang et al. 2023)</a>.</p>
<p>Sorted queries make it more memory friendly, which has nice improvements even if computationally is more expensive.
In Binary Search lookup you have smaller blocks that have nicer locality, and use binary search in one of the blocks. This is one example of explicitly designed blocks that help make things faster (computationally cheaper and memory friendly). This was 19.2x times faster in GPU tables.</p>
<p>They are able to reconfigure the computation in order to make it $\mathcal{O}(M \log \log M)$ and efficient for data movement.
It is also possible to use SRAM, the same idea that was present in <a href="/notes/sparse-matrix-vector-multiplication#daoFLASHATTENTIONFastMemoryefficient2022">(Dao et al. 2022)</a>.</p>
<p>They get 2.2x maximum in object detection at the end.</p>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p id=yangMinuetAccelerating3D2023>[1] Yang et al. <a href="http://arxiv.org/abs/2401.06145">“Minuet: Accelerating 3D Sparse Convolutions on GPUs”</a> arXiv preprint arXiv:2401.06145 2023
 </p>
<p id=daoFLASHATTENTIONFastMemoryefficient2022>[2] Dao et al. “FLASHATTENTION: Fast and Memory-Efficient Exact Attention with IO-awareness” Curran Associates Inc.  2022
 </p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://flecart.github.io/tags/advanced-systems-lab/">Advanced-Systems-Lab</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Sparse Matrix Vector Multiplication on x"
            href="https://x.com/intent/tweet/?text=Sparse%20Matrix%20Vector%20Multiplication&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fsparse-matrix-vector-multiplication%2f&amp;hashtags=advanced-systems-lab">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Sparse Matrix Vector Multiplication on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fsparse-matrix-vector-multiplication%2f&amp;title=Sparse%20Matrix%20Vector%20Multiplication&amp;summary=Sparse%20Matrix%20Vector%20Multiplication&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2fsparse-matrix-vector-multiplication%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Sparse Matrix Vector Multiplication on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2fsparse-matrix-vector-multiplication%2f&title=Sparse%20Matrix%20Vector%20Multiplication">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Sparse Matrix Vector Multiplication on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2fsparse-matrix-vector-multiplication%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Sparse Matrix Vector Multiplication on whatsapp"
            href="https://api.whatsapp.com/send?text=Sparse%20Matrix%20Vector%20Multiplication%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2fsparse-matrix-vector-multiplication%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Sparse Matrix Vector Multiplication on telegram"
            href="https://telegram.me/share/url?text=Sparse%20Matrix%20Vector%20Multiplication&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fsparse-matrix-vector-multiplication%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Sparse Matrix Vector Multiplication on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Sparse%20Matrix%20Vector%20Multiplication&u=https%3a%2f%2fflecart.github.io%2fnotes%2fsparse-matrix-vector-multiplication%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
