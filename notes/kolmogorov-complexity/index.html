<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Kolmogorov complexity | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="no-tags">
<meta name="description" content="Gran parte di quanto scrivo ora è tratto da (Li &amp; Vitányi 2019). Chaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni &lsquo;60!
Solomonoff lo ha trovato sul problema dell&rsquo;induzione all&rsquo;età di 38 anni, Kolmogorov invece era già tardi, ha già trovato gli assiomi della probabilità e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilità, nel 68 all&rsquo;età di 19 anni.">
<meta name="author" content="Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/kolmogorov-complexity/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/kolmogorov-complexity/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>




<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>





<script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-WW6NN2QGKF', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="Kolmogorov complexity" />
<meta property="og:description" content="Gran parte di quanto scrivo ora è tratto da (Li &amp; Vitányi 2019). Chaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni &lsquo;60!
Solomonoff lo ha trovato sul problema dell&rsquo;induzione all&rsquo;età di 38 anni, Kolmogorov invece era già tardi, ha già trovato gli assiomi della probabilità e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilità, nel 68 all&rsquo;età di 19 anni." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://flecart.github.io/notes/kolmogorov-complexity/" />
<meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png" />
<meta property="article:section" content="notes" />



<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png" />
<meta name="twitter:title" content="Kolmogorov complexity"/>
<meta name="twitter:description" content="Gran parte di quanto scrivo ora è tratto da (Li &amp; Vitányi 2019). Chaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni &lsquo;60!
Solomonoff lo ha trovato sul problema dell&rsquo;induzione all&rsquo;età di 38 anni, Kolmogorov invece era già tardi, ha già trovato gli assiomi della probabilità e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilità, nel 68 all&rsquo;età di 19 anni."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Kolmogorov complexity",
      "item": "https://flecart.github.io/notes/kolmogorov-complexity/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Kolmogorov complexity",
  "name": "Kolmogorov complexity",
  "description": "Gran parte di quanto scrivo ora è tratto da (Li \u0026amp; Vitányi 2019). Chaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni \u0026lsquo;60!\nSolomonoff lo ha trovato sul problema dell\u0026rsquo;induzione all\u0026rsquo;età di 38 anni, Kolmogorov invece era già tardi, ha già trovato gli assiomi della probabilità e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilità, nel 68 all\u0026rsquo;età di 19 anni.",
  "keywords": [
    "no-tags"
  ],
  "articleBody": "Gran parte di quanto scrivo ora è tratto da (Li \u0026 Vitányi 2019). Chaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni ‘60!\nSolomonoff lo ha trovato sul problema dell’induzione all’età di 38 anni, Kolmogorov invece era già tardi, ha già trovato gli assiomi della probabilità e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilità, nel 68 all’età di 19 anni. In AI teorico questo sembra un tema molto importante.\nCi sono degli esempi carini nella compressione di numeri naturali e stringhe binarie in Introduction to Algorithmic Information and Complexity.\nIntuizione Kolmogorov Per quanto ho capito io sulle motivazioni che sono state base alla creazione di questo concetto è il concetto che: per descrivere cose complesse c’è necessità di più parole. Questa idea molto intuitiva la possiamo tradurre da un punto informatico come il programma più corto per produrre un certo output.\nUn esempio classico è una comparazione fra una stringa 01010101010101 contro una altra del tipo 11101111111100101011110000010101. Intuitivamente potremmo dire che la prima stringa sia molto più semplice da descrivere rispetto alla seconda stringa, abbiamo però bisogno di un modo formale per descrivere questo concetto.\nFormalizzazione Definizione Kolmogorov Definiamo la complessità di Kolmogorov $K_{L}(\\omega )$ per un certo linguaggio di programmazione $L$ come la minima lunghezza del programma tale per cui se eseguita sulla macchina astratta di $L$ dia come output $\\omega$ .\nQuesta definizione si può riscrivere come $$ C(x) = \\min_{p}\\left\\{ length(p) : U(p) = x \\right\\} $$ Ossia il programma più corto che se eseguito su una macchina di Turing completa ho $x$ .\nNOTA: questa definizione seppur meno informale di prima, non è ancora quella formalmente accettata, però fa il suo per trasmettere l’idea, vedere il libro [^2] per definizione matematicamente corretta (e anche molto più astrusa)\nComplessità condizionale\nla complessità di Kolmogorov condizionale $K_{L}(\\omega | x)$ è la lunghezza minima di un programma che prende in input $x$ e produce in output $\\omega$ . (si legge proprio come se fosse un qualcosa di condizionato)\nLEMMA Ora diventa chiaro che un programma che stampa una qualunque stringa, sia sufficiente per dare in output, per questo motivo vale che: $$ K(x) \\le \\lvert x \\rvert + c \\tag{1} $$ Dove $c$ è una costante per codificare le istruzioni per stampare. Più intuitivamente un programma di questo genere può stampare il carattere (dimostreremo in seguito, in #Teorema dell’invarianza che idea simile vale per ogni linguaggio)\nQuesto lemma giustifica anche la seguente definizione\nStringhe incomprimibili una stringa $\\omega$ si dice incomprimibile nel momento in cui $K(\\omega) = \\lvert \\omega \\rvert + O(1)$ Che insieme all’upper bound di sopra, si avrà che è il massimo di complessità che può avere.\nKolmogorov condizionato Condizionato $K(A|B)$ significa che diamo alla nostra macchina di turing in input anche $B$ per codificare $A$ . Puoi vedere subito che la complessità di $K(A|A)$ è $0$ perché la macchina di turing può non fare nulla $\\varepsilon$ è il programma diciamo, e avere subito un risultato. Intuitivamente avere qualcosa in più non fa altro che ridurre il codice necessario, quindi possiamo dire che $K(A|B) \\leq K(A)$ . E qui si può creare anche una nozione di indipendenza.\nChain Rule Afferma che per qualunque oggetto vale che $$ K(A|B) \\geq K(A, B) - K(B) $$ Ossia la codifica di entrambi, sia $A$ che $B$ è necessariamente minore di codificare prima $B$ e poi usare questa per codificare $A$ . Si può dimostrare ma intuitivamente questa legge sembra parlare in modo chiaro.\nQuesto vale se assumiamo che tutte le parole godano della Prefix Property Bottom-up Parser LR(1)Algorithmic Probability. Se non vale la regola diventa $$ C(s_{1}) \\leq C(s_{2}) + C(s_{1} | s_{2}) + O(\\log(C(s_{2}))) $$ Il motivo di questo $O$ grande strano è che\n$\\log(C(s_{2}))$ is the maximal length of the information needed to separate the program that computes $s_{2}$ from what comes next (as we cannot guarantee that this program is uniquely decodable, contrary to the prefix case).\nMa non lo ho capito ancora bene.\nIncomputabilità di Kolmogorov Dimostrazione: Supponiamo che sia computabile, allora abbiamo un programma $P$ che calcola il programma minimo. Ora possiamo usare questo programma per trovare una stringa la cui complessità di Kolmogorov sia più lunga di un certo $n$ . Questo si può fare provando ad aggiungere roba (probabilmente qui mi serve un lemma che dice che è crescente stretto e non lasco). Ma la complessità di questa nuova stringa trovata deve essere uguale alla complessità di $n$ , che gli dò in input! (più costante per la ricerca che ignoro per Kolmogorov). Questo significa che $K(n) \u003e n$ che è assurdo perché $K(n) \\approx \\log_{2}(n)$ che è strettamente minore di $n$ .\nPossiamo però approssimare il valore, e per molte cose questo basta!\nKolmogorov complexity is an ideal notion that can be approximated, but that is not computable.\nUn pseudocodice di esempio per computare una cosa più complessa (anche se non ho la dimostrazione che fa quello che deve fare, perché in teoria credo può continuare in modo arbitrariamente lungo, solo che la probabilità che non finisca tende a 0)\ndef MoreComplex(n): i =1 while True: for m in range(2**i): s = bin(m)[2:] if cc(s) \u003e n: return s i += 1 Teorema dell’invarianza Questo è un teorema fondamentale (e anche di base) per quanto riguarda la definizione della teoria inerente a questa complessità. Ci permette di affermare che il concetto di complessità è indipendente dal linguaggio di programmazione utilizzato, e ci darà presto anche alcuni risultati interessanti sulla computabilità di questa funzione (in modo diverso rispetto alle classiche dimostrazioni che si possono trovare in teoria della computabilità). Quindi questo teorema è fondamentale per stabilire l’oggettività della proprietà. Così possiamo dire che è una proprietà dell’oggetto, non di come lo stai valutando. Quindi non dipende dalla capacità/architettura di chi sta valutando il linguaggio.\nSiano $L$ e $L^{'}$ due linguaggi Turing completi, allora per ogni stringa $\\omega$ si ha che $$K_{L}(\\omega) = K_{L^{'}}(\\omega) + O(1)\\tag{2}$$ Dimostrazione: Essendo $L$ e $L^{'}$ dei linguaggi Turing completi, allora posso scrivere un programma in $L^{'}$ che esegua la macchina astratta di $L$ e quindi mantenga tutta la semantica del linguaggio $L$ (vedere Macchine Astratte per la definizione di interprete).\nAllora si avrà che $$ K_{L^{'}}(w) = K_{L}(\\omega) + |I| \\tag{2.1} $$ ossia il costo per esprimere la complessità della string $\\omega$ in $L^{'}$ è equivalente al costo per esprimere il programma $p$ in $L$ , ed eseguirlo con un interprete (che avrà una lunghezza finita, e costante una volta fissato i due linguaggi). L’interprete esiste perché stiamo usando macchine di Turing universali per la descrizione della lunghezza.\nNOTE: Grazie a questa proprietà da ora in poi potremo parlare di $K(\\omega)$ indipendentemente da linguaggio su cui è stato scritto, dato che tanto distano di una costante uno dall’altro.\nNOTE2: È una cosa molto curiosa il fatto che sia dipendente dall’osservatore, anche se abbiamo una differenza, perché cose importanti per qualcuno, sono codificate in modo differente da ognuno. Questo è un pensiero molto deep, e l’esempio della versione della macchina è chiaro.\nEsistenza di stringhe complesse Un risultato importante che sarà utile alla dimostrazione della non computabilità della funzione di complessità di Kolmogorov è la seguente:\u003e $$ \\forall n \\in \\mathbb{N}, \\exists \\omega : K(w) \\geq n $$ che è un risultato che non sembra avere molto senso perché ci sta dicendo che esistono delle stringhe di complessità infinita (forse queste stringhe sono quelle non computabili, perché il programma che lo descrive dovrebbe avere lunghezza infinita).\nDimostrazione: La dimostrazione di questo teorema non è altro che una applicazione del pigeonhole principle. In un certo senso salta fuori dalla relazione fra il finito e l’infinito, come quelle cose assurde che $2n$ è in bigezione con i numeri naturali. Siamo nel mondo di Turing, quindi i programmi saranno anch’esse delle stringhe binarie. Consideriamo tutti i programmi di lunghezza zero. Questo produrrà la stringa vuota, ossia la stringa di complessità zero. Supponiamo ora tutti i programmi di lunghezza uno. Al massimo potremo avere due stringhe con questa complessità. E così via. Intuitivamente: dato che il numero delle stringhe $\\omega$ che possono esistere sono infinite, anche i la lunghezza dei programmi utilizzati per generare queste stringhe sono infinite, perché banalmente un programma di lunghezza $n$ può generare al massimo $2^n$ stringhe diverse, un numero finito, anche se enormemente ampio.\nNon calcolabilità della funzione di Kolmogorov La funzione di Kolmogorov non è calcolabile su un macchina di Turing\nDimostrazione: Supponiamo che esista una macchina di Turing $M$ che prenda in input una stringa $\\omega$ e ritorni $K(\\omega)$ . Utilizzeremo il teorema #Esistenza di stringhe complesse\nAllora utilizziamo questa macchina di Turing $M$ per costruirne una altra $M^{'}$ che si comporti in questo modo:\ninput n for each string w in alphabet: do if K(w) \u003e= n: return w done endfor In pratica vado a scorrere tutte le parole nell’alfabeto infinito, so che prima o poi troverò una stringa tale per cui $K(w) \\geq n$ perché ne abbiamo dimostrato l’esistenza precedentemente. Questa macchina allora descriverà la stringa $\\omega$ che viene in output, dato l’input $n$ .\nMa allora abbiamo che $$ n \\leq K(\\omega) \\leq \\lvert \\langle M^{'}, n \\rangle \\rvert + O(1) = O(1) + \\lvert n \\rvert = O(1) + O(\\log(n)) = O(\\log(n)) $$ Ed è assurdo perché afferma che $O(n) \\leq O(\\log(n))$ che sarà vero per $n$ abbastanza alto.\nUpper bound con entropia Kolmogorov si può vedere come una cosa più generale dell’entropia di Shannon Entropy, si può vedere come una approssimazione di essa perché basta prendere $L \\approx \\log_{2}\\left( \\frac{1}{p} \\right)$ e si ha l’entropia Shannoniana. La cosa carina è che Kolmogorov ha senso anche in assenza di frequenze e probabilità.\nCose che non ho capito Per qualche motivo la complessità di un oggetto scende quando l’entropia è massima (ah, quando sono tutti uguali le probabilità, la complessità scende)\nParte vecchia dal libro di complexity Questo è il teorema fondamentale di questo campo, che ricordiamo prova a cercare di creare una teoria sulle descrizioni di minima lunghezza per qualcosa, questo dovrebbe essere in grado di risolvere il problema del limite della probabilità, e cose di teoria dell’informazione che non ho ancora ben compreso.\nComunque si è notato che si può definire una classe di equivalenza, e fra queste esiste una classe speciale che è quello di descrizione minima. Partiamo però dalla definizione di di complessità diciamo: $$ C_{f}(x) = min\\{l(p) : f(p) = n(x)\\} $$ $f$ è una macchina di turing.\nUna volta definito questo e creato un insieme fisso di macchine o funzioni si può estendere questo modello in classi di equivalenza, perché possiamo utilizzare $\\langle n, p \\rangle$ on $n$ l’index alla macchina corretta e $p$ il nostro programma (anche se non ho capito perché si assume che il programma sia comprensibile a qualunque macchina, e non ho capito perché la funzione la si può intendere come se fosse una macchina, questa è una parte di teorica che mi dovrei recuperare).\nComunque fatto questo, si può mostrare come data una sequenza contabile di funzioni $\\phi_{1}, \\phi_{2}, \\dots, \\phi_{n}$ allora posso andare a definirmi $\\phi_{n}(p) = \\phi_{0}(\\langle n, p \\rangle)$ anche se non ho capito cosa voglio dire qui, con $\\phi_{0}$ la funzione computata da una macchina di Turing universale $U$ . Indicheremo $$ C_{\\phi_{0}}(x) = C(x) $$ per ogni programma $x$ .\nReferences [1] Li \u0026 Vitányi “An Introduction to Kolmogorov Complexity and Its Applications” Springer International Publishing 2019\n",
  "wordCount" : "1905",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/kolmogorov-complexity/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Kolmogorov complexity
    </h1>
    <div class="post-meta">9 min&nbsp;·&nbsp;Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul><ul>
                <li>
                    <a href="#intuizione-kolmogorov" aria-label="Intuizione Kolmogorov">Intuizione Kolmogorov</a></li></ul>
                    
                <li>
                    <a href="#formalizzazione" aria-label="Formalizzazione">Formalizzazione</a><ul>
                        
                <li>
                    <a href="#definizione-kolmogorov" aria-label="Definizione Kolmogorov">Definizione Kolmogorov</a><ul>
                        
                <li>
                    <a href="#stringhe-incomprimibili" aria-label="Stringhe incomprimibili">Stringhe incomprimibili</a></li>
                <li>
                    <a href="#kolmogorov-condizionato" aria-label="Kolmogorov condizionato">Kolmogorov condizionato</a></li>
                <li>
                    <a href="#chain-rule" aria-label="Chain Rule">Chain Rule</a></li>
                <li>
                    <a href="#incomputabilit%c3%a0-di-kolmogorov" aria-label="Incomputabilità di Kolmogorov">Incomputabilità di Kolmogorov</a></li></ul>
                </li>
                <li>
                    <a href="#teorema-dellinvarianza" aria-label="Teorema dell&rsquo;invarianza">Teorema dell&rsquo;invarianza</a><ul>
                        
                <li>
                    <a href="#esistenza-di-stringhe-complesse" aria-label="Esistenza di stringhe complesse">Esistenza di stringhe complesse</a></li>
                <li>
                    <a href="#non-calcolabilit%c3%a0-della-funzione-di-kolmogorov" aria-label="Non calcolabilità della funzione di Kolmogorov">Non calcolabilità della funzione di Kolmogorov</a></li>
                <li>
                    <a href="#upper-bound-con-entropia" aria-label="Upper bound con entropia">Upper bound con entropia</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#cose-che-non-ho-capito" aria-label="Cose che non ho capito">Cose che non ho capito</a></li>
                <li>
                    <a href="#parte-vecchia-dal-libro-di-complexity" aria-label="Parte vecchia dal libro di complexity">Parte vecchia dal libro di complexity</a></li></ul>
                    
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Gran parte di quanto scrivo ora è tratto da <a href="http://link.springer.com/10.1007/978-3-030-11298-1">(Li &amp; Vitányi 2019)</a>.
Chaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni &lsquo;60!</p>
<p>Solomonoff lo ha trovato sul problema dell&rsquo;induzione all&rsquo;età di 38 anni, Kolmogorov invece era già tardi, ha già trovato gli assiomi della probabilità e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilità, nel 68 all&rsquo;età di 19 anni.
In AI teorico questo sembra un tema molto importante.</p>
<p>Ci sono degli esempi carini nella compressione di numeri naturali e stringhe binarie in <a href="/notes/introduction-to-algorithmic-information-and-complexity/">Introduction to Algorithmic Information and Complexity</a>.</p>
<h3 id="intuizione-kolmogorov">Intuizione Kolmogorov<a hidden class="anchor" aria-hidden="true" href="#intuizione-kolmogorov">#</a></h3>
<p>Per quanto ho capito io sulle motivazioni che sono state base alla creazione di questo concetto è il concetto che: <em>per descrivere cose complesse c&rsquo;è necessità di più parole</em>.
Questa idea molto intuitiva la possiamo tradurre da un punto informatico come <strong>il programma più corto per produrre un certo output</strong>.</p>
<p>Un esempio classico è una comparazione fra una stringa <em>01010101010101</em> contro una altra del tipo <em>11101111111100101011110000010101</em>.
Intuitivamente potremmo dire che la prima stringa sia molto più semplice da descrivere rispetto alla seconda stringa, abbiamo però bisogno di un modo formale per descrivere questo concetto.</p>
<h2 id="formalizzazione">Formalizzazione<a hidden class="anchor" aria-hidden="true" href="#formalizzazione">#</a></h2>
<h3 id="definizione-kolmogorov">Definizione Kolmogorov<a hidden class="anchor" aria-hidden="true" href="#definizione-kolmogorov">#</a></h3>
<blockquote>
<p>Definiamo la complessità di Kolmogorov </p>
$K_{L}(\omega )$
<p> per un certo linguaggio di programmazione </p>
$L$
<p> come la minima lunghezza del programma tale per cui se eseguita sulla macchina astratta di </p>
$L$
<p> dia come output </p>
$\omega$
<p>.</p>
</blockquote>
<p>Questa definizione si può riscrivere come
</p>
$$
C(x) = \min_{p}\left\{ length(p) : U(p) = x \right\} 
$$
<p>
Ossia il programma più corto che se eseguito su una macchina di Turing completa ho </p>
$x$
<p>.</p>
<p>NOTA: questa definizione seppur meno informale di prima, non è ancora quella formalmente accettata, però fa il suo per trasmettere l&rsquo;idea, vedere il libro [^2] per definizione matematicamente corretta (e anche molto più astrusa)</p>
<p><strong>Complessità condizionale</strong></p>
<blockquote>
<p>la complessità di Kolmogorov condizionale </p>
$K_{L}(\omega | x)$
<p> è la lunghezza minima di un programma che prende in input </p>
$x$
<p> e produce in output </p>
$\omega$
<p>. (si legge proprio come se fosse un qualcosa di condizionato)</p>
</blockquote>
<p><strong>LEMMA</strong>
Ora diventa chiaro che un programma che stampa una qualunque stringa, sia sufficiente per dare in output, per questo motivo vale che:
</p>
$$
K(x) \le \lvert x \rvert  + c \tag{1}
$$
<p>
Dove </p>
$c$
<p> è una costante per codificare le istruzioni per stampare.
Più intuitivamente un programma di questo genere può stampare il carattere (dimostreremo in seguito, in <a href="/notes/kolmogorov-complexity/#teorema-dell-invarianza">#Teorema dell&rsquo;invarianza</a> che idea simile vale per ogni linguaggio)</p>
<p>Questo lemma giustifica anche la seguente definizione</p>
<h4 id="stringhe-incomprimibili">Stringhe incomprimibili<a hidden class="anchor" aria-hidden="true" href="#stringhe-incomprimibili">#</a></h4>
<blockquote>
<p>una stringa </p>
$\omega$
<p> si dice <em>incomprimibile</em> nel momento in cui </p>
$K(\omega) = \lvert \omega \rvert + O(1)$
</blockquote>
<p>Che insieme all&rsquo;upper bound di sopra, si avrà che è il massimo di complessità che può avere.</p>
<h4 id="kolmogorov-condizionato">Kolmogorov condizionato<a hidden class="anchor" aria-hidden="true" href="#kolmogorov-condizionato">#</a></h4>
<p>Condizionato </p>
$K(A|B)$
<p> significa che diamo alla nostra macchina di turing in input anche </p>
$B$
<p> per codificare </p>
$A$
<p>. Puoi vedere subito che la complessità di </p>
$K(A|A)$
<p> è </p>
$0$
<p> perché la macchina di turing può non fare nulla </p>
$\varepsilon$
<p> è il programma diciamo, e avere subito un risultato.
Intuitivamente avere qualcosa in più non fa altro che ridurre il codice necessario, quindi possiamo dire che </p>
$K(A|B) \leq K(A)$
<p>. E qui si può creare anche una nozione di indipendenza.</p>
<h4 id="chain-rule">Chain Rule<a hidden class="anchor" aria-hidden="true" href="#chain-rule">#</a></h4>
<p>Afferma che per qualunque oggetto vale che
</p>
$$
K(A|B) \geq K(A, B) - K(B)
$$
<p>
Ossia la codifica di entrambi, sia </p>
$A$
<p> che </p>
$B$
<p> è necessariamente minore di codificare prima </p>
$B$
<p> e poi usare questa per codificare </p>
$A$
<p>. Si può dimostrare ma intuitivamente questa legge sembra parlare in modo chiaro.</p>
<p>Questo vale se assumiamo che tutte le parole godano della <em>Prefix Property</em> <a href="/notes/bottom-up-parser-lr1/">Bottom-up Parser LR(1)</a><a href="/notes/algorithmic-probability/">Algorithmic Probability</a>.
Se non vale la regola diventa
</p>
$$
C(s_{1}) \leq C(s_{2}) + C(s_{1} | s_{2}) + O(\log(C(s_{2})))
$$
<p>
Il motivo di questo </p>
$O$
<p> grande strano è che</p>
<blockquote>
$\log(C(s_{2}))$
<p> is the maximal length of the information needed to separate the program that computes </p>
$s_{2}$
<p>  from what comes next (as we cannot guarantee that this program is uniquely decodable, contrary to the prefix case).</p>
</blockquote>
<p>Ma non lo ho capito ancora bene.</p>
<h4 id="incomputabilità-di-kolmogorov">Incomputabilità di Kolmogorov<a hidden class="anchor" aria-hidden="true" href="#incomputabilità-di-kolmogorov">#</a></h4>
<p>Dimostrazione:
Supponiamo che sia computabile, allora abbiamo un programma </p>
$P$
<p> che calcola il programma minimo.
Ora possiamo usare questo programma per trovare una stringa la cui complessità di Kolmogorov sia più lunga di un certo </p>
$n$
<p>. Questo si può fare provando ad aggiungere roba (probabilmente qui mi serve un lemma che dice che è crescente stretto e non lasco).
Ma la complessità di questa nuova stringa trovata deve essere uguale alla complessità di </p>
$n$
<p>, che gli dò in input! (più costante per la ricerca che ignoro per Kolmogorov).
Questo significa che </p>
$K(n) > n$
<p> che è assurdo perché </p>
$K(n) \approx \log_{2}(n)$
<p> che è strettamente minore di </p>
$n$
<p>.</p>
<p>Possiamo però approssimare il valore, e per molte cose questo basta!</p>
<blockquote>
<p>Kolmogorov complexity is an ideal notion that can be approximated, but that is not computable.</p>
</blockquote>
<p>Un pseudocodice di esempio per computare una cosa più complessa (anche se non ho la dimostrazione che fa quello che deve fare, perché in teoria credo può continuare in modo arbitrariamente lungo, solo che la probabilità che non finisca tende a 0)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">MoreComplex</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>  
</span></span><span class="line"><span class="cl">    <span class="n">i</span> <span class="o">=</span><span class="mi">1</span>  
</span></span><span class="line"><span class="cl">    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>  
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="n">i</span><span class="p">):</span>  
</span></span><span class="line"><span class="cl">            <span class="n">s</span> <span class="o">=</span> <span class="nb">bin</span><span class="p">(</span><span class="n">m</span><span class="p">)[</span><span class="mi">2</span><span class="p">:]</span>      
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">cc</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">:</span>    <span class="k">return</span> <span class="n">s</span>  
</span></span><span class="line"><span class="cl">        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span></code></pre></div><h3 id="teorema-dellinvarianza">Teorema dell&rsquo;invarianza<a hidden class="anchor" aria-hidden="true" href="#teorema-dellinvarianza">#</a></h3>
<p>Questo è un teorema fondamentale (e anche di base) per quanto riguarda la definizione della teoria inerente a questa complessità. Ci permette di affermare che il concetto di complessità è <strong>indipendente dal linguaggio di programmazione utilizzato</strong>, e ci darà presto anche alcuni risultati interessanti sulla computabilità di questa funzione (in modo diverso rispetto alle classiche dimostrazioni che si possono trovare in teoria della computabilità). Quindi questo teorema è <em>fondamentale</em> per stabilire <strong>l&rsquo;oggettività</strong> della proprietà. Così possiamo dire che è una proprietà dell&rsquo;oggetto, non di come lo stai valutando. Quindi non dipende dalla capacità/architettura di chi sta valutando il linguaggio.</p>
<blockquote>
<p>Siano </p>
$L$
<p> e </p>
$L^{'}$
<p> due linguaggi Turing completi, allora per ogni stringa </p>
$\omega$
<p> si ha che </p>
$$K_{L}(\omega) = K_{L^{'}}(\omega)  + O(1)\tag{2}$$
</blockquote>
<p><strong>Dimostrazione</strong>:
Essendo </p>
$L$
<p> e </p>
$L^{'}$
<p> dei linguaggi Turing completi, allora posso scrivere un programma in </p>
$L^{'}$
<p> che esegua la macchina astratta di </p>
$L$
<p> e quindi mantenga tutta la semantica del linguaggio </p>
$L$
<p> (vedere <a href="/notes/macchine-astratte/">Macchine Astratte</a> per la definizione di interprete).<br>
Allora si avrà che
</p>
$$
K_{L^{'}}(w) = K_{L}(\omega) + |I| \tag{2.1}
$$
<p>
ossia il costo per esprimere la complessità della string </p>
$\omega$
<p> in </p>
$L^{'}$
<p> è equivalente al costo per esprimere il programma </p>
$p$
<p> in </p>
$L$
<p>, ed eseguirlo con un interprete (che avrà una lunghezza finita, e costante una volta fissato i due linguaggi).
L&rsquo;interprete esiste perché stiamo usando macchine di Turing universali per la descrizione della lunghezza.</p>
<p>NOTE:
Grazie a questa proprietà da ora in poi potremo parlare di  </p>
$K(\omega)$
<p> <strong>indipendentemente da linguaggio</strong> su cui è stato scritto, dato che tanto distano di una costante uno dall&rsquo;altro.</p>
<p>NOTE2:
È una cosa molto curiosa il fatto che sia dipendente dall&rsquo;osservatore, anche se abbiamo una differenza, perché cose importanti per qualcuno, sono codificate in modo differente da ognuno. Questo è un pensiero molto deep, e l&rsquo;esempio della versione della macchina è chiaro.</p>
<h4 id="esistenza-di-stringhe-complesse">Esistenza di stringhe complesse<a hidden class="anchor" aria-hidden="true" href="#esistenza-di-stringhe-complesse">#</a></h4>
<p>Un risultato importante che sarà utile alla dimostrazione della non computabilità della funzione di complessità di Kolmogorov è la seguente:&gt;
</p>
$$
\forall n \in \mathbb{N}, \exists \omega : K(w) \geq n
$$
<p>che è un risultato che non sembra avere molto senso perché ci sta dicendo che esistono delle stringhe di complessità infinita (forse queste stringhe sono quelle non computabili, perché il programma che lo descrive dovrebbe avere lunghezza infinita).</p>
<p><strong>Dimostrazione</strong>:
La dimostrazione di questo teorema non è altro che una applicazione del pigeonhole principle. In un certo senso salta fuori dalla relazione fra il finito e l&rsquo;infinito, come quelle cose assurde che </p>
$2n$
<p> è in bigezione con i numeri naturali.
Siamo nel mondo di Turing, quindi i programmi saranno anch&rsquo;esse delle stringhe binarie.
Consideriamo tutti i programmi di lunghezza zero. Questo produrrà la stringa vuota, ossia la stringa di complessità zero.
Supponiamo ora tutti i programmi di lunghezza uno. Al massimo potremo avere due stringhe con questa complessità.
E così via. Intuitivamente: dato che il numero delle stringhe </p>
$\omega$
<p> che possono esistere sono infinite, anche i la lunghezza dei programmi utilizzati per generare queste stringhe sono infinite, perché banalmente un programma di lunghezza </p>
$n$
<p> può generare al massimo </p>
$2^n$
<p> stringhe diverse, un numero finito, anche se enormemente ampio.</p>
<h4 id="non-calcolabilità-della-funzione-di-kolmogorov">Non calcolabilità della funzione di Kolmogorov<a hidden class="anchor" aria-hidden="true" href="#non-calcolabilità-della-funzione-di-kolmogorov">#</a></h4>
<blockquote>
<p>La funzione di Kolmogorov non è calcolabile su un macchina di Turing</p>
</blockquote>
<p><strong>Dimostrazione</strong>:
Supponiamo che esista una macchina di Turing </p>
$M$
<p> che prenda in input una stringa </p>
$\omega$
<p> e ritorni </p>
$K(\omega)$
<p>. Utilizzeremo il teorema <a href="/notes/kolmogorov-complexity/#esistenza-di-stringhe-complesse">#Esistenza di stringhe complesse</a></p>
<p>Allora utilizziamo questa macchina di Turing </p>
$M$
<p> per costruirne una altra </p>
$M^{'}$
<p> che si comporti in questo modo:</p>
<pre tabindex="0"><code>input n
for each string w in alphabet:
do
	if K(w) &gt;= n:
		return w
done
endfor
</code></pre><p>In pratica vado a scorrere tutte le parole nell&rsquo;alfabeto infinito, so che prima o poi troverò una stringa tale per cui </p>
$K(w) \geq n$
<p> perché ne abbiamo dimostrato l&rsquo;esistenza precedentemente. Questa macchina allora descriverà la stringa </p>
$\omega$
<p> che viene in output, dato l&rsquo;input </p>
$n$
<p>.</p>
<p>Ma allora abbiamo che
</p>
$$
n \leq K(\omega) \leq \lvert \langle M^{'}, n \rangle    \rvert + O(1) = O(1) + \lvert n \rvert = O(1) + O(\log(n)) = O(\log(n))  
$$
<p>Ed è assurdo perché afferma che </p>
$O(n) \leq O(\log(n))$
<p> che sarà vero per </p>
$n$
<p> abbastanza alto.</p>
<h4 id="upper-bound-con-entropia">Upper bound con entropia<a hidden class="anchor" aria-hidden="true" href="#upper-bound-con-entropia">#</a></h4>
<p>Kolmogorov si può vedere come una cosa più generale dell&rsquo;entropia di Shannon <a href="/notes/entropy/">Entropy</a>, si può vedere come una <strong>approssimazione di essa</strong> perché basta prendere
</p>
$L \approx \log_{2}\left( \frac{1}{p} \right)$
<p> e si ha l&rsquo;entropia Shannoniana.
La cosa carina è che Kolmogorov ha senso anche in assenza di frequenze e probabilità.</p>
<h2 id="cose-che-non-ho-capito">Cose che non ho capito<a hidden class="anchor" aria-hidden="true" href="#cose-che-non-ho-capito">#</a></h2>
<p>Per qualche motivo la complessità di un oggetto scende quando l&rsquo;entropia è massima (ah, quando sono tutti uguali le probabilità, la complessità scende)</p>
<h2 id="parte-vecchia-dal-libro-di-complexity">Parte vecchia dal libro di complexity<a hidden class="anchor" aria-hidden="true" href="#parte-vecchia-dal-libro-di-complexity">#</a></h2>
<p>Questo è il teorema fondamentale di questo campo, che ricordiamo prova a cercare di creare una teoria sulle descrizioni di minima lunghezza per qualcosa, questo dovrebbe essere in grado di risolvere il problema del limite della probabilità, e cose di teoria dell&rsquo;informazione che non ho ancora ben compreso.</p>
<p>Comunque si è notato che si può definire una classe di equivalenza, e fra queste esiste una classe speciale che è quello di descrizione minima. Partiamo però dalla definizione di di complessità diciamo:
</p>
$$
 C_{f}(x) = min\{l(p) : f(p) = n(x)\}
$$
$f$
<p> è una macchina di turing.</p>
<p>Una volta definito questo e creato un insieme fisso di <em>macchine</em> o funzioni si può estendere questo modello in classi di equivalenza, perché possiamo utilizzare </p>
$\langle n, p \rangle$
<p> on </p>
$n$
<p> l&rsquo;index alla macchina corretta e </p>
$p$
<p> il nostro programma (anche se non ho capito perché si assume che il programma sia comprensibile a qualunque macchina, e non ho capito perché la funzione la si può intendere come se fosse una macchina, questa è una parte di teorica che mi dovrei recuperare).</p>
<p>Comunque fatto questo, si può mostrare come data una sequenza contabile di funzioni </p>
$\phi_{1}, \phi_{2}, \dots, \phi_{n}$
<p> allora posso andare a definirmi </p>
$\phi_{n}(p) = \phi_{0}(\langle n, p \rangle)$
<p> anche se non ho capito cosa voglio dire qui, con </p>
$\phi_{0}$
<p> la funzione computata da una macchina di Turing universale </p>
$U$
<p> . Indicheremo </p>
$$
C_{\phi_{0}}(x) = C(x)
$$
<p> per ogni programma </p>
$x$
<p>.</p>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p>[1] Li &amp; Vitányi <a href="http://link.springer.com/10.1007/978-3-030-11298-1">“An Introduction to Kolmogorov Complexity and Its Applications”</a> Springer International Publishing 2019</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://flecart.github.io/tags/no-tags/">No-Tags</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Kolmogorov complexity on x"
            href="https://x.com/intent/tweet/?text=Kolmogorov%20complexity&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fkolmogorov-complexity%2f&amp;hashtags=no-tags">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Kolmogorov complexity on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fkolmogorov-complexity%2f&amp;title=Kolmogorov%20complexity&amp;summary=Kolmogorov%20complexity&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2fkolmogorov-complexity%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Kolmogorov complexity on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2fkolmogorov-complexity%2f&title=Kolmogorov%20complexity">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Kolmogorov complexity on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2fkolmogorov-complexity%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Kolmogorov complexity on whatsapp"
            href="https://api.whatsapp.com/send?text=Kolmogorov%20complexity%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2fkolmogorov-complexity%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Kolmogorov complexity on telegram"
            href="https://telegram.me/share/url?text=Kolmogorov%20complexity&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fkolmogorov-complexity%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Kolmogorov complexity on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Kolmogorov%20complexity&u=https%3a%2f%2fflecart.github.io%2fnotes%2fkolmogorov-complexity%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
