<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Cloud Storage | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="üììbig-data">
<meta name="description" content="Paradigms of data storage ETL framework üü© This is the classical database approach: We load the data in the database and let the underlying system handle it. This method needs some added cost in extracting, transforming and loading the data that we have stored previously in an optimized format so that it can be used for views, or else.
Data Lakes üü© We usually refer to Data Lakes when we store our data with Distributed file systems or using Cloud Storage: cheap ways to dump the data without caring about the possibility of modifying them.">
<meta name="author" content="Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/cloud-storage/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/cloud-storage/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>




<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>





<script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-WW6NN2QGKF', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="Cloud Storage" />
<meta property="og:description" content="Paradigms of data storage ETL framework üü© This is the classical database approach: We load the data in the database and let the underlying system handle it. This method needs some added cost in extracting, transforming and loading the data that we have stored previously in an optimized format so that it can be used for views, or else.
Data Lakes üü© We usually refer to Data Lakes when we store our data with Distributed file systems or using Cloud Storage: cheap ways to dump the data without caring about the possibility of modifying them." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://flecart.github.io/notes/cloud-storage/" />
<meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png" />
<meta property="article:section" content="notes" />



<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png" />
<meta name="twitter:title" content="Cloud Storage"/>
<meta name="twitter:description" content="Paradigms of data storage ETL framework üü© This is the classical database approach: We load the data in the database and let the underlying system handle it. This method needs some added cost in extracting, transforming and loading the data that we have stored previously in an optimized format so that it can be used for views, or else.
Data Lakes üü© We usually refer to Data Lakes when we store our data with Distributed file systems or using Cloud Storage: cheap ways to dump the data without caring about the possibility of modifying them."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Cloud Storage",
      "item": "https://flecart.github.io/notes/cloud-storage/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Cloud Storage",
  "name": "Cloud Storage",
  "description": "Paradigms of data storage ETL framework üü© This is the classical database approach: We load the data in the database and let the underlying system handle it. This method needs some added cost in extracting, transforming and loading the data that we have stored previously in an optimized format so that it can be used for views, or else.\nData Lakes üü© We usually refer to Data Lakes when we store our data with Distributed file systems or using Cloud Storage: cheap ways to dump the data without caring about the possibility of modifying them.",
  "keywords": [
    "üììbig-data"
  ],
  "articleBody": "Paradigms of data storage ETL framework üü© This is the classical database approach: We load the data in the database and let the underlying system handle it. This method needs some added cost in extracting, transforming and loading the data that we have stored previously in an optimized format so that it can be used for views, or else.\nData Lakes üü© We usually refer to Data Lakes when we store our data with Distributed file systems or using Cloud Storage: cheap ways to dump the data without caring about the possibility of modifying them.\nWe typically store data in the filesystem, where it is viewed simply as files. This approach works well when we only need to read the data. It‚Äôs often referred to as in situ storage because there is no need to extract the data first. However, the drawback arises when we need to modify the data, as it can lead to numerous inconsistencies.\nAnother significant limitation of filesystems is that they cannot scale to manage billions of files efficiently.\nThis is what the professors in the first database course says Filesystem: are not the perfect technology to handle this type of load, see Introduction to databases.\nObject storage design principles üü®‚Äì We don‚Äôt want the hierarchy that is common in Filesystems, so we need to simplify that and have these four principles:\nBlack-box objects Flat and global key-value model (trivial model, easy to access, without the need to trasverse a file hieararchy). Flexible metadata Commodity hardware (the battery idea of Tesla until 2017). Scaling principles Usually the best thing is to make things work in a single computer, then it‚Äôs cheaper to scale horizontally, and then to scale vertically, adding better hardware.\nCurrent Limits When A relational table grows too much, a single system could have difficulty in handling it. Common limits nowadays are:\nMillions of rows Cloud Storage, Distributed file systems, Massive Parallel Processing, usually handle well data with lots of rows (samples, with the same columns) More than 256 columns, we usually use Wide Column Storage. With a lot of nested data. We use Document Stores, like MongoDB, where the Markup is quite important. Scaling vertically üü© There are two ways of scaling, scaling vertically or horizontally. Scaling Up concerns in building better machines, building better algorithms and being more efficient with what exactly we have.\nScaling horizontally üü©‚Äì Scaling horizontally is the simple idea of adding more things, it could be more computers, more ram, more disk, more CPUs. But these have some physical limits that we should need to keep track of.\nThere is a physical limit of number of computers in a data-center (1k to 100k which seems to be the hard limit constrained by energy and cooling requirements). Z√ºrich‚Äôs datacenter consumes as much energy as an airport. And we have about 1-200 cores in a single computer of a datacenter.\nWe also have a limit for RAM and local storage. Respectively about 0.016-24TB of RAM and 1-30TB of storage. Its unthinkable that the RAM memory has the same order of magnitude of local storage. This is because in memory databases are becoming more common (they are usually faster, lower latency).\nWe also have a bandwidth of 1-200Gbit/s for a single server on an Ethernet cable.\nWe have standardized rack units for every server (or storage if the module is just for storage), storage and routers, they are usually connected together by switches and similar networking thingies. Usually we have 1-4 rack units for a server\nType Range Computers in Data Center 1k-100k (100k hard limit for electricity designs) Cores in a Single computer 200 RAM 0.016-24TB Network Bandwidth 1-200 Gbit Racks per server (module) 1-4 HDD Storage 26TB Throughput 261MB/s Latency 4 ms Analysis of bottlenecks üü© We already have said that a way to improve on the possible bottlenecks of our systems is having better code: using our resources in a better manner. The easier way is choosing to buy more resources. Important bottlenecks in our context are CPU, Memory, RAM, and network. We can know if have one of these bottlenecks by monitoring the real-time resource usages.\nDisk-IO -\u003e MapReduce and Spark, or using Parquet instead of JSON can\nIn fact, you should always first try to improve your code before scaling out. The vast majority of data processing use cases fit on a single machine, and you can save a lot of money as well as get a faster system by squeezing the data on a machine (possibly compressed) and writing very efficient code.\nObject Stores Object storage usages üü© Object storages are useful to store things that are usually read-intensive. Some examples are\nStatic websites Images, Videos or video chunks Big files that are usually only to read (e.g. datasets). Service Level Agreements (4) üü®++ We will talk now about Service Level Agreements which are important to understand the contract part of using cloud services. So, if a company does not satisfy these requirements, one can sue them for breach of contract.\nScalability We have 100 buckets per account that could be extended on request.\nDurability We lose 1 in a $10^{11}$ objects during a year (which is 99.999999999% of durability), which is quite strong (so there is still a possibility that the object is lost). This is useful for the lawyers because they can offer a guarantee. If this is not respected then people can sue them.\nAvailability We have an availability of 99.99% which means maximum of 1h for a year. Usually it‚Äôs useful to remember the percentages of availability:\n99% 4 days/year\n99.9% 9 hours/year\n99.99% 53 minutes/year\n99.999% 6 minutes/year\n99.9999% 32 seconds/year\n99.99999% 4 seconds/year\nResponse time Legally it‚Äôs hard to guarantee average speeds, so what they do is actually count the times where the service is guaranteed to be below a certain threshold! So they guarantee that in $99.9\\%$ of the cases they have a response lower than $300 ms$, in other cases its higher. However, as it is usually difficult to satisfy a latency requirements which is often geographically dependent answer, S3 offers guarantees based on system throughput, which is how many reads and writes it can handle without any problem. Amazon S3 Amazon used to sell books, then they started to rent cloud services because they had too many machines that most of the time they were not using. This was a big win from an economical point of view. They created amazon web services. Now they are selling these abstractions: Amazon S3 stands for simple storage service.\nS3 Document Identification üü© With S3 every document is identified by a bucket id and a object id, which could be maximum 5 TB (probably physical constraints of the file), it is only possible to upload an object in a single chunk if it is less than 5 GB. The buckets can uniquely identify that in the world. The maximum amount of buckets that a user can have is 100 by default.\nWe don‚Äôt know how S3 works underneath, they have not published it.\nStorage Classes üü®‚Äì The cost of the storage service changes with the frequency of the access. For example\nAmazon Glacier has a very high latency (hours to get the files), but its cost is quite low. This should be used for example for backups! With these applications we don‚Äôt care if the answer is in seconds. Hours is fine. Standard with infrequent access: we have a cost of retrieving, with less availability Standard: it‚Äôs just the standard S3 structure. Accessing a resource üü© We use Uniform Resource Identifier to identify the resource we want to access, and the usually send a REST request to modify, delete or get it.\nThis is an example of a S3 bucket [http://bucket.s3.amazonaws.com/object-name](http://bucket.s3.amazonaws.com/object-name`) (if you want to access the bucket, just remove the object identifier!). We can have operations like PUT, GET, DELETE for Buckets and objects.\nUsage Examples üü© Most common usage of buckets is storing read intensive data, like static websites or dataset shards (which then become useful for systems like MapReduce or Spark). The performance is nice, the professor reports about 300ms for the website to load. Usually you can see a hierarchy on the UI for such systems, but that is just for interface, under the hood, we just have a flat key-value store.\nIt is common to place a content delivery network (CDN) service on top of the storage bucket of a website in order to accelerate and cache these files at multiple places on the planet.\nAzure Blob Storage In this section we will describe the service provided by Azure cloud on cloud storage.\nAzure Document Identification üü©‚Äì Azure blob storage needs 3 id to identify a document:\nAccount Container (bucket equivalent), which is sometimes called partition in literature. Blob (document id equivalent) 195 GB for an Append Blob to 190.7 TB for a Block Blob. The maximum storage size is different! Object APIs üü® And we can divide the files into blocks which support a higher size.\nBlocks are for data. Maximum size of 50k 4GB blocks, about 190.7 TB. Append are for logs because they are optimized to append stuff, of maximum size of 195 GB. Which corresponds to 50k 4MB blocks. Page are for in memory virtual machines maximum size of 8 terabytes. Stamps üü©‚Äì Azure Blob Storage is organized into the so called storage stamps. These stamps are 10-20 racks with 18 storage nodes each (maximum storage for a stamp is about 30PB of data). Usually kept below 80% data (if not they‚Äôll have a warning), else they could buy more storage or move data elsewhere.\nReplication (2) üü®‚Äì They have two types of replications:\nIntra-stamp: which is synchronous way of replicating (immediately replicated). Inter-stamp: asynchronously replicating to other stamps. Regions (2) üü©‚Äì As with AWS, they have regions to optimize for latency and be resistant to natural catastrophes. The latency part is intuitive: if a data center is physically closer to you, then it‚Äôs more probable that the data will be served faster. Natural catastrophes are mitigated by having the data in different regions, so if one is destroyed, then the data is still safe.\nKey-value stores S3 is far more slower than typical database systems to store and query the data. In the order of hundreds of 100ms against 1-9ms for key-value stores. So two orders of difference! Too high latency for some uses!.\nKey value stores (aka associative arrays, we use map data structure) solve this problem and can be adapted to be used as a database system, the cost is that the type of objects we can store is far smaller, in the order of few hundreds of kilobytes.\nCharacteristics of Key-value stores üü® This is designed for performance and scalability, but it gives up consistency for eventual consistency. This is usually a simpler version, but it doesn‚Äôt have the same features as more complex data storage systems, as relational database management systems.\nUsually these are used for shopping carts for a very large online shop, another is for storing likes and comments on social media\nDesign principles of Key-value stores (4) üü•++ Incremental stability New nodes can join the system at any time, and nodes can leave the system at any time, sometimes gracefully, sometimes in a sudden crash. But we don‚Äôt need to have too many nodes to crash, which is not the scope of our course.\nSymmetry No node is particular in any way, the nodes are similar to one and another. They run the same code.\nDecentralization There is no leader or orchestrator in the network. Note that symmetric protocols could elect a leader nonetheless, while in this case we have the strict requirement not to have a leader.\nHeterogeneity the nodes may have different CPU power, amounts of memory, etc.\nComparison With ObjectStorage Limitations compared to S3 and Azure Blob Storage üü© Yet, this brings some drawbacks: We have the values to be far smaller, about 400kb of data (this is what Dynamo does) and we cannot store metadata It has a simplified APIs that just supports get, put or delete the document, with a given key or value (in reality there is also a context variable). This is why they are often more suitable for real-time data, simplicity and speed.\nWhat are Contexes? These values are the state of the updates for every node, this is used to merge the vector clocks in case of need. Providing a context to get or put, allows the key-value store to correctly update the context so that later in case of partitions, it could be exactly solved.\nCommon Usage Patterns Particular usages are for example shopping carts, likes and comments on social media, and so on.\nOne of the typical use cases for a key-value store is storing shopping carts for a very large online shop, another is for storing likes and comments on social media.\nbest seller lists, shopping carts, customer preferences, session management, sales rank, and product catalog, from (DeCandia et al. 2007).\nChord protocol The amazon paper (DeCandia et al. 2007) describes this system.\nThis is based on a distributed hashing protocol. We use hashes because they have some properties to be robust against failures of some kind, which I have not understood.\nWith this protocol, every node has an ID. For example a code in $2^{128}$ (Dynamo indeed uses 128 bytes). If we have a key $k$ this is assigned to a position on the ring. Then from this position we follow the ring clockwise until we find a node, this node should handle the value of this key.\nConsistent Hashing The ring structure of the Chord protocol is called consistent hashing. It has been designed to minimize the amount of transfer of data in distributed systems that join and leave frequently. See Tabelle di hash for a primer of how hashing works.\nOther systems use this type of hashing, like the CassandraDB or CDN services. It acts as an automatic load balancing system.\nThe principle advantage of consistent hashing is that departure or arrival of a node only affects its immediate neighbors and other nodes remain unaffected.\nJoin, Leave and Crash üü© When a node joins, the should take the responsibility of part of the data in front of him in a clockwise fashion. When a node leaves, it should give responsibility of part of the data to the node in front of him. Clearly this is not possible when we have a crash, this is why we need redundancy, which is easily done by having 2-range redundancy, but it can be set to any value.\nOne thing that should be noted with the updates is how it handles the replication: only single node modifies, but after it propagates the update to the replicas and receives acks. Then you use vector clocks to choose the highest update number. A nice parallel with vector clocks is the parallel between these and the Newtonian physics vs Structure of spacetime and different timelines.\nReads on Dinamo üü®‚Äì A client periodically picks a random Dynamo node and downloads its current view of Dynamo membership state. Using this information the client can determine which set of nodes form the preference list for any given key.\nA preference list is just a map of each object and the node that is currently storing that object. With the classical Chord protocol the so called finger tables where used where you could employ binary search to find the node that is responsible for the key. With finger tables, each node knows what the following nodes to the power of two have, so that the search could be employed.\nEvery time a node wants to look up a key¬†$k$, it will pass the query to the closest successor or predecessor (depending on the finger table) of¬†$k$¬†in its finger table (the ‚Äúlargest‚Äù one on the circle whose ID is smaller than¬†$k$), until a node finds out the key is stored in its immediate successor.\nProbably this approach has been dismissed because it is a little bit more burgeoning to update the finger table on joins or leaves, and preference lists are a better practical solution.\nThis is called the client driven approach, and from their tests, it seems twice as fast as the server driven approach.\nPreference lists üü© This solves the problem of finding the actual node that has the data we are querying for. It is just a table with a key -\u003e and nodes that have it. We have distributed algorithms that make the nodes agree on this preference list which is just knowing what machine is responsible for what interval range. For each key range, the first node on the list is called the coordinator node, it this fails, the random node that has gotten request attempt to contact every node until one answers. $R$ is the minimum number of nodes from which the value needs to be retrieved for it to be considered consistent. $W$ is the minimum number of nodes for which an ack should be received to consider it towards a successful read. We have the theoretical necessity that $R + W \u003e N$ to set up a quorum system, whose acknowledgement is based on the majority of notes that have accepted a certain modification. Sometimes the system is also configured to values less than $N$ for a better latency, which is configurable by the developer.\nTuning the values for $R$ and $W$ scale the performance stability of reads and writes. For example read-intensive applications, would prefer to have $R=1$ and $W=N$ so that it is fast to read, but could potentially read some inconsistent data. The most common configuration is $N=3, R=2, W=2$ for Dynamo.\nAdvantages and disadvantages üü®+ Pros:\nHighly scalable Robust to failure (because we replicate data with the ones in front of us). Self-organizing. I don‚Äôt know if the above properties are exclusive, but they are nice Cons:\nOnly lookup, no search (obvious) No data-integrity (we don‚Äôt have a way to check for integrity constraints) Security issues (Need to understand this) Virtual Nodes üü© Two problems arise with the Chord protocol: there could be large gaps in the Circle and the underlying machines could have different hardware proposals. The idea is to have some nodes take other nodes in a way proportional to its hardware. In this manner, if a node has more resources, it has more nodes, which implies it is expected to handle more data (which is fine because it has more resources).\nCAP Theorem Statement of CAP üü© We can only have two of the following properties:\nConsistency (doesn‚Äôt depend on the machine that answers to your request). Availability (it should answer something). Partition tolerance (the system continues to function even if the network linking its machines is occasionally partitioned.) We don‚Äôt have ACID anymore (see Advanced SQL) in the case of Big Data. So now we have 3 possible scenarios, which correspond to the 3 couples that is possible to have with these properties.\nFor example, let‚Äôs say we have a partition of the network then we have two cases: not available until the network is connected again, but we still have the same data. Or we have two parts that answer differently (this is usually called eventual consistency, because after the network is connected then it will return to the consistent state), but are still available to the users.\nWhen network partitions happen we need to choose what property we want to keep, so we have three possible cases: CP, CA or AP. Services like Dynamo Key value store (see Cloud Storage#Key-value stores) choose AP and thus have eventual consistency.\nVector Clocks üü®‚Äì Sometimes when we have a network partition we lose the linear timing of the system and so we have directed acyclic graphs\nWe have vectors for updates by different nodes. The merge is done by a certain node and updates the vector again.\nThe merge happens in the following manner: just choose the maximum value for each resource that has been modified. This grants consistency, but could lose some data.\nPACELC Theorem üü©‚Äì PACELC is a generalization of the CAP theorem. The acronym PACELC stands for:\nP: Partition tolerance (as in the CAP theorem). A: Availability. C: Consistency. E: Else. L: Latency. C: Consistency. PACELC integrates the latency in normal running cases. We can tradeoff between being low latency but accepting some inconsistencies, or being consistent with a little higher latency.\nReferences [1] DeCandia et al. ‚ÄúDynamo: Amazon‚Äôs Highly Available Key-Value Store‚Äù ACM SIGOPS Operating Systems Review Vol. 41(6), pp. 205‚Äì220 2007\n",
  "wordCount" : "3436",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/cloud-storage/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;¬ª&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Cloud Storage
    </h1>
    <div class="post-meta">17 min&nbsp;¬∑&nbsp;Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul><ul>
                <li>
                    <a href="#paradigms-of-data-storage" aria-label="Paradigms of data storage">Paradigms of data storage</a><ul>
                        
                <li>
                    <a href="#etl-framework-" aria-label="ETL framework üü©">ETL framework üü©</a></li>
                <li>
                    <a href="#data-lakes-" aria-label="Data Lakes üü©">Data Lakes üü©</a></li>
                <li>
                    <a href="#object-storage-design-principles---" aria-label="Object storage design principles üü®&ndash;">Object storage design principles üü®&ndash;</a></li></ul>
                </li>
                <li>
                    <a href="#scaling-principles" aria-label="Scaling principles">Scaling principles</a><ul>
                        
                <li>
                    <a href="#current-limits" aria-label="Current Limits">Current Limits</a></li>
                <li>
                    <a href="#scaling-vertically-" aria-label="Scaling vertically üü©">Scaling vertically üü©</a></li>
                <li>
                    <a href="#scaling-horizontally---" aria-label="Scaling horizontally üü©&ndash;">Scaling horizontally üü©&ndash;</a></li>
                <li>
                    <a href="#analysis-of-bottlenecks-" aria-label="Analysis of bottlenecks üü©">Analysis of bottlenecks üü©</a></li></ul>
                </li></ul>
                    
                <li>
                    <a href="#object-stores" aria-label="Object Stores">Object Stores</a><ul>
                        <ul>
                        
                <li>
                    <a href="#object-storage-usages-" aria-label="Object storage usages üü©">Object storage usages üü©</a></li>
                <li>
                    <a href="#service-level-agreements-4-" aria-label="Service Level Agreements (4) üü®&#43;&#43;">Service Level Agreements (4) üü®++</a></li></ul>
                    
                <li>
                    <a href="#amazon-s3" aria-label="Amazon S3">Amazon S3</a><ul>
                        
                <li>
                    <a href="#s3-document-identification-" aria-label="S3 Document Identification üü©">S3 Document Identification üü©</a></li>
                <li>
                    <a href="#storage-classes---" aria-label="Storage Classes üü®&ndash;">Storage Classes üü®&ndash;</a></li>
                <li>
                    <a href="#accessing-a-resource-" aria-label="Accessing a resource üü©">Accessing a resource üü©</a></li>
                <li>
                    <a href="#usage-examples-" aria-label="Usage Examples üü©">Usage Examples üü©</a></li></ul>
                </li>
                <li>
                    <a href="#azure-blob-storage" aria-label="Azure Blob Storage">Azure Blob Storage</a><ul>
                        
                <li>
                    <a href="#azure-document-identification---" aria-label="Azure Document Identification üü©&ndash;">Azure Document Identification üü©&ndash;</a></li>
                <li>
                    <a href="#object-apis-" aria-label="Object APIs üü®">Object APIs üü®</a></li>
                <li>
                    <a href="#stamps---" aria-label="Stamps üü©&ndash;">Stamps üü©&ndash;</a></li>
                <li>
                    <a href="#replication-2---" aria-label="Replication (2) üü®&ndash;">Replication (2) üü®&ndash;</a></li>
                <li>
                    <a href="#regions-2---" aria-label="Regions (2) üü©&ndash;">Regions (2) üü©&ndash;</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#key-value-stores" aria-label="Key-value stores">Key-value stores</a><ul>
                        <ul>
                        
                <li>
                    <a href="#characteristics-of-key-value-stores-" aria-label="Characteristics of Key-value stores üü®">Characteristics of Key-value stores üü®</a></li>
                <li>
                    <a href="#design-principles-of-key-value-stores-4-" aria-label="Design principles of Key-value stores (4) üü•&#43;&#43;">Design principles of Key-value stores (4) üü•++</a></li></ul>
                    
                <li>
                    <a href="#comparison-with-objectstorage" aria-label="Comparison With ObjectStorage">Comparison With ObjectStorage</a><ul>
                        
                <li>
                    <a href="#limitations-compared-to-s3-and-azure-blob-storage-" aria-label="Limitations compared to S3 and Azure Blob Storage üü©">Limitations compared to S3 and Azure Blob Storage üü©</a></li>
                <li>
                    <a href="#what-are-contexes" aria-label="What are Contexes?">What are Contexes?</a></li>
                <li>
                    <a href="#common-usage-patterns" aria-label="Common Usage Patterns">Common Usage Patterns</a></li></ul>
                </li>
                <li>
                    <a href="#chord-protocol" aria-label="Chord protocol">Chord protocol</a><ul>
                        
                <li>
                    <a href="#consistent-hashing" aria-label="Consistent Hashing">Consistent Hashing</a></li>
                <li>
                    <a href="#join-leave-and-crash-" aria-label="Join, Leave and Crash üü©">Join, Leave and Crash üü©</a></li>
                <li>
                    <a href="#reads-on-dinamo---" aria-label="Reads on Dinamo üü®&ndash;">Reads on Dinamo üü®&ndash;</a></li>
                <li>
                    <a href="#preference-lists-" aria-label="Preference lists üü©">Preference lists üü©</a></li>
                <li>
                    <a href="#advantages-and-disadvantages-" aria-label="Advantages and disadvantages üü®&#43;">Advantages and disadvantages üü®+</a></li>
                <li>
                    <a href="#virtual-nodes-" aria-label="Virtual Nodes üü©">Virtual Nodes üü©</a></li></ul>
                </li>
                <li>
                    <a href="#cap-theorem" aria-label="CAP Theorem">CAP Theorem</a><ul>
                        
                <li>
                    <a href="#statement-of-cap-" aria-label="Statement of CAP üü©">Statement of CAP üü©</a></li>
                <li>
                    <a href="#vector-clocks---" aria-label="Vector Clocks üü®&ndash;">Vector Clocks üü®&ndash;</a></li>
                <li>
                    <a href="#pacelc-theorem---" aria-label="PACELC Theorem üü©&ndash;">PACELC Theorem üü©&ndash;</a></li></ul>
                </li></ul>
                </li></ul>
                    
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="paradigms-of-data-storage">Paradigms of data storage<a hidden class="anchor" aria-hidden="true" href="#paradigms-of-data-storage">#</a></h3>
<h4 id="etl-framework-">ETL framework üü©<a hidden class="anchor" aria-hidden="true" href="#etl-framework-">#</a></h4>
<p>This is the classical database approach:
We load the data in the database and let the underlying system handle it. This method needs some added cost in extracting, transforming and loading the data that we have stored previously in an optimized format so that it can be used for views, or else.</p>
<h4 id="data-lakes-">Data Lakes üü©<a hidden class="anchor" aria-hidden="true" href="#data-lakes-">#</a></h4>
<p>We usually refer to <em>Data Lakes</em> when we store our data with <a href="/notes/distributed-file-systems/">Distributed file systems</a> or using <a href="/notes/cloud-storage/">Cloud Storage</a>: cheap ways to dump the data without caring about the possibility of modifying them.</p>
<p>We typically store data in the <strong>filesystem</strong>, where it is viewed simply as files. This approach works well when we only need to <em>read</em> the data. It&rsquo;s often referred to as <em>in situ</em> storage because there is no need to extract the data first. However, the drawback arises when we need to <em>modify</em> the data, as it can lead to numerous inconsistencies.</p>
<p>Another significant limitation of filesystems is that they <strong>cannot scale to manage billions of files</strong> efficiently.</p>
<p>This is what the professors in the first database course says <a href="/notes/filesystem/">Filesystem</a>: are not the perfect technology to handle this type of load, see <a href="/notes/introduction-to-databases/">Introduction to databases</a>.</p>
<h4 id="object-storage-design-principles---">Object storage design principles üü®&ndash;<a hidden class="anchor" aria-hidden="true" href="#object-storage-design-principles---">#</a></h4>
<p>We don&rsquo;t want the hierarchy that is common in <a href="/notes/filesystem/">Filesystem</a>s, so we need to simplify that and have these four principles:</p>
<ol>
<li>Black-box objects</li>
<li>Flat and global <strong>key-value</strong> model (trivial model, easy to access, without the need to trasverse a file hieararchy).</li>
<li>Flexible <strong>metadata</strong></li>
<li>Commodity hardware (the battery idea of Tesla until 2017).</li>
</ol>
<h3 id="scaling-principles">Scaling principles<a hidden class="anchor" aria-hidden="true" href="#scaling-principles">#</a></h3>
<p>Usually the best thing is to make things work in a single computer, then it&rsquo;s cheaper to scale horizontally, and then to scale vertically, adding better hardware.</p>
<h4 id="current-limits">Current Limits<a hidden class="anchor" aria-hidden="true" href="#current-limits">#</a></h4>
<p>When A relational table grows too much, a single system could have difficulty in handling it.
Common limits nowadays are:</p>
<ol>
<li>Millions of rows
<ol>
<li><a href="/notes/cloud-storage/">Cloud Storage</a>, <a href="/notes/distributed-file-systems/">Distributed file systems</a>, <a href="/notes/massive-parallel-processing/">Massive Parallel Processing</a>, usually handle well data with lots of rows (samples, with the same columns)</li>
</ol>
</li>
<li>More than 256 columns, we usually use <a href="/notes/wide-column-storage/">Wide Column Storage</a>.</li>
<li>With a lot of nested data.
<ol>
<li>We use <a href="/notes/document-stores/">Document Stores</a>, like MongoDB, where the <a href="/notes/markup/">Markup</a> is quite important.</li>
</ol>
</li>
</ol>
<h4 id="scaling-vertically-">Scaling vertically üü©<a hidden class="anchor" aria-hidden="true" href="#scaling-vertically-">#</a></h4>
<p>There are two ways of scaling, scaling vertically or horizontally.
Scaling Up concerns in building better machines, building better algorithms and being more efficient with what exactly we have.</p>
<h4 id="scaling-horizontally---">Scaling horizontally üü©&ndash;<a hidden class="anchor" aria-hidden="true" href="#scaling-horizontally---">#</a></h4>
<p>Scaling horizontally is the simple idea of adding more things, it could be more computers, more ram, more disk, more CPUs. But these have some physical limits that we should need to keep track of.</p>
<p>There is a physical limit of number of computers in a data-center (1k to 100k which seems to be the hard limit constrained by energy and cooling requirements). Z√ºrich&rsquo;s datacenter consumes as much energy as an airport.
And we have about 1-200 cores in a single computer of a datacenter.</p>
<p>We also have a limit for RAM and local storage. Respectively about 0.016-24TB of RAM and 1-30TB of storage. Its unthinkable that the RAM memory has the same order of magnitude of local storage. This is because in memory databases are becoming more common (they are usually faster, lower latency).</p>
<p>We also have a bandwidth of 1-200Gbit/s for a single server on an Ethernet cable.</p>
<p>We have standardized <strong>rack</strong> units for every server (or storage if the module is just for storage), storage and routers, they are usually connected together by <em>switches</em> and similar networking thingies. Usually we have 1-4 rack units for a server</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Range</th>
</tr>
</thead>
<tbody>
<tr>
<td>Computers in Data Center</td>
<td>1k-100k (100k hard limit for electricity designs)</td>
</tr>
<tr>
<td>Cores in a Single computer</td>
<td>200</td>
</tr>
<tr>
<td>RAM</td>
<td>0.016-24TB</td>
</tr>
<tr>
<td>Network Bandwidth</td>
<td>1-200 Gbit</td>
</tr>
<tr>
<td>Racks per server (module)</td>
<td>1-4</td>
</tr>
<tr>
<td>HDD Storage</td>
<td>26TB</td>
</tr>
<tr>
<td>Throughput</td>
<td>261MB/s</td>
</tr>
<tr>
<td>Latency</td>
<td>4 ms</td>
</tr>
</tbody>
</table>
<h4 id="analysis-of-bottlenecks-">Analysis of bottlenecks üü©<a hidden class="anchor" aria-hidden="true" href="#analysis-of-bottlenecks-">#</a></h4>
<p>We already have said that a way to improve on the possible bottlenecks of our systems is having <strong>better code</strong>: using our resources in a better manner. The easier way is choosing to buy more resources.
Important bottlenecks in our context are CPU, Memory, RAM, and network. We can know if have one of these bottlenecks by monitoring the <em>real-time resource usages</em>.</p>
<p>Disk-IO -&gt; MapReduce and Spark, or using Parquet instead of JSON can</p>
<blockquote>
<p>In fact, you should always first try to improve your code before scaling out. The vast majority of data processing use cases fit on a single machine, and you can save a lot of money as well as get a faster system by squeezing the data on a machine (possibly compressed) and writing very efficient code.</p>
</blockquote>
<h2 id="object-stores">Object Stores<a hidden class="anchor" aria-hidden="true" href="#object-stores">#</a></h2>
<h4 id="object-storage-usages-">Object storage usages üü©<a hidden class="anchor" aria-hidden="true" href="#object-storage-usages-">#</a></h4>
<p>Object storages are useful to store things that are usually read-intensive. Some examples are</p>
<ul>
<li>Static websites</li>
<li>Images, Videos or video chunks</li>
<li>Big files that are usually only to read (e.g. datasets).</li>
</ul>
<h4 id="service-level-agreements-4-">Service Level Agreements (4) üü®++<a hidden class="anchor" aria-hidden="true" href="#service-level-agreements-4-">#</a></h4>
<p>We will talk now about <strong>Service Level Agreements</strong> which are important to understand the contract part of using cloud services. So, if a company does not satisfy these requirements, one can sue them for breach of contract.</p>
<ul>
<li>
<p><strong>Scalability</strong>
We have 100 buckets per account that could be <em>extended on request</em>.</p>
</li>
<li>
<p><strong>Durability</strong>
We lose 1 in a $10^{11}$ objects during a year (which is 99.999999999% of durability), which is quite strong (so there is still a possibility that the object is lost). This is useful for the lawyers because they can offer a guarantee. If this is not respected then people can sue them.</p>
</li>
<li>
<p><strong>Availability</strong>
We have an availability of 99.99% which means maximum of 1h for a year. Usually it&rsquo;s useful to remember the percentages of availability:</p>
</li>
</ul>
<p>99% 4 days/year<br>
99.9% 9 hours/year<br>
99.99% 53 minutes/year<br>
99.999% 6 minutes/year<br>
99.9999% 32 seconds/year<br>
99.99999% 4 seconds/year</p>
<ul>
<li><strong>Response time</strong>
Legally it&rsquo;s hard to guarantee average speeds, so what they do is actually <em>count</em> the times where the service is guaranteed to be below a certain threshold!
So they guarantee that in $99.9\%$ of the cases they have a response lower than $300 ms$, in other cases its higher.
However, as it is usually difficult to satisfy a latency requirements which is often geographically dependent answer, S3 offers guarantees based on <em>system throughput</em>, which is how many reads and writes it can handle without any problem.</li>
</ul>
<h3 id="amazon-s3">Amazon S3<a hidden class="anchor" aria-hidden="true" href="#amazon-s3">#</a></h3>
<p>Amazon used to sell books, then they started to rent cloud services because they had too many machines that most of the time they were not using. This was a big win from an economical point of view. They created <em>amazon web services</em>. Now they are selling these abstractions: Amazon S3 stands for <em>simple storage service</em>.</p>
<h4 id="s3-document-identification-">S3 Document Identification üü©<a hidden class="anchor" aria-hidden="true" href="#s3-document-identification-">#</a></h4>
<p>With S3 every document is identified by a <strong>bucket id</strong> and a <strong>object id</strong>, which could be maximum <em>5 TB</em> (probably physical constraints of the file), it is only possible to upload an object in a <em>single</em> chunk if it is <strong>less than 5 GB</strong>. The buckets can <em>uniquely</em> identify that in the world.
The maximum amount of buckets that a user can have is 100 by default.</p>
<p>We don&rsquo;t know how S3 works underneath, they have not published it.</p>
<h4 id="storage-classes---">Storage Classes üü®&ndash;<a hidden class="anchor" aria-hidden="true" href="#storage-classes---">#</a></h4>
<p>The cost of the storage service changes with the frequency of the access. For example</p>
<ul>
<li><strong>Amazon Glacier</strong> has a very high latency (<em>hours</em> to get the files), but its cost is quite low. This should be used for example for backups! With these applications we don&rsquo;t care if the answer is in seconds. Hours is fine.</li>
<li>Standard with infrequent access: we have a cost of retrieving, with less availability</li>
<li>Standard: it&rsquo;s just the standard S3 structure.</li>
</ul>
<h4 id="accessing-a-resource-">Accessing a resource üü©<a hidden class="anchor" aria-hidden="true" href="#accessing-a-resource-">#</a></h4>
<p>We use <a href="/notes/uniform-resource-identifier/">Uniform Resource Identifier</a> to identify the resource we want to access, and the usually send a <a href="/notes/http-e-rest/">REST</a> request to modify, delete or get it.</p>
<p>This is an example of a S3 bucket <code>[http://bucket.s3.amazonaws.com/object-name</code>](<a href="http://bucket.s3.amazonaws.com/object-name%60">http://bucket.s3.amazonaws.com/object-name`</a>) (if you want to access the bucket, just remove the object identifier!).
We can have operations like PUT, GET, DELETE for Buckets and objects.</p>
<h4 id="usage-examples-">Usage Examples üü©<a hidden class="anchor" aria-hidden="true" href="#usage-examples-">#</a></h4>
<p>Most common usage of buckets is storing read intensive data, like <strong>static websites</strong> or <strong>dataset shards</strong> (which then become useful for systems like MapReduce or Spark).
The performance is nice, the professor reports about 300ms for the website to load.
Usually you can see a hierarchy on the UI for such systems, but that is just for interface, under the hood, we just have a <strong>flat</strong> key-value store.</p>
<blockquote>
<p>It is common to place a content delivery network (<strong>CDN</strong>) service on top of the storage bucket of a website in order to accelerate and cache these files at multiple places on the planet.</p>
</blockquote>
<h3 id="azure-blob-storage">Azure Blob Storage<a hidden class="anchor" aria-hidden="true" href="#azure-blob-storage">#</a></h3>
<p>In this section we will describe the service provided by Azure cloud on cloud storage.</p>
<h4 id="azure-document-identification---">Azure Document Identification üü©&ndash;<a hidden class="anchor" aria-hidden="true" href="#azure-document-identification---">#</a></h4>
<p>Azure blob storage needs <em>3</em> id to identify a document:</p>
<ul>
<li>Account</li>
<li>Container (bucket equivalent), which is sometimes called <strong>partition</strong> in literature.</li>
<li>Blob (document id equivalent)
195 GB for an Append Blob to 190.7 TB for a Block Blob. The maximum storage size is different!</li>
</ul>
<h4 id="object-apis-">Object APIs üü®<a hidden class="anchor" aria-hidden="true" href="#object-apis-">#</a></h4>
<p>And we can divide the files into <strong>blocks</strong> which support a higher size.</p>
<ul>
<li>Blocks are for <em>data</em>. Maximum size of 50k 4GB blocks, about 190.7 TB.</li>
<li>Append are for <em>logs</em> because they are optimized to append stuff, of maximum size of 195 GB. Which corresponds to 50k 4MB blocks.</li>
<li>Page are for <em>in memory virtual machines</em> maximum size of 8 terabytes.</li>
</ul>
<h4 id="stamps---">Stamps üü©&ndash;<a hidden class="anchor" aria-hidden="true" href="#stamps---">#</a></h4>
<p>Azure Blob Storage is organized into the so called <strong>storage stamps</strong>.
These stamps are 10-20 racks with 18 storage nodes each (maximum storage for a stamp is about 30PB of data). Usually kept below 80% data (if not they&rsquo;ll have a warning), else they could buy more storage or move data elsewhere.</p>
<h4 id="replication-2---">Replication (2) üü®&ndash;<a hidden class="anchor" aria-hidden="true" href="#replication-2---">#</a></h4>
<p>They have two types of replications:</p>
<ul>
<li><strong>Intra-stamp</strong>: which is synchronous way of replicating (immediately replicated).</li>
<li><strong>Inter-stamp</strong>: asynchronously replicating to other stamps.</li>
</ul>
<h4 id="regions-2---">Regions (2) üü©&ndash;<a hidden class="anchor" aria-hidden="true" href="#regions-2---">#</a></h4>
<p>As with AWS, they have regions to optimize for <strong>latency</strong> and be resistant to <strong>natural catastrophes</strong>.
The latency part is intuitive: if a data center is physically <em>closer</em> to you, then it&rsquo;s more probable that the data will be served faster.
Natural catastrophes are mitigated by having the data in different regions, so if one is destroyed, then the data is still safe.</p>
<h2 id="key-value-stores">Key-value stores<a hidden class="anchor" aria-hidden="true" href="#key-value-stores">#</a></h2>
<p>S3 is far more slower than typical database systems to store and query the data. In the order of hundreds of 100ms against 1-9ms for key-value stores.
So two orders of difference! <em>Too high latency</em> for some uses!.</p>
<p>Key value stores (aka <strong>associative arrays</strong>, we use map data structure) solve this problem and can be adapted to be used as a database system, the cost is that the type of objects we can store is far smaller, in the order of few hundreds of kilobytes.</p>
<h4 id="characteristics-of-key-value-stores-">Characteristics of Key-value stores üü®<a hidden class="anchor" aria-hidden="true" href="#characteristics-of-key-value-stores-">#</a></h4>
<p>This is designed for <strong>performance and scalability</strong>, but it <em>gives up</em> consistency for <strong>eventual consistency</strong>. This is usually a <strong>simpler</strong> version, but it doesn&rsquo;t have the same features as more complex data storage systems, as relational database management systems.</p>
<p>Usually these are used for shopping carts for a very large online shop, another is for storing likes and comments on social media</p>
<h4 id="design-principles-of-key-value-stores-4-">Design principles of Key-value stores (4) üü•++<a hidden class="anchor" aria-hidden="true" href="#design-principles-of-key-value-stores-4-">#</a></h4>
<ul>
<li>
<p><strong>Incremental stability</strong>
New nodes can <em>join the system at any time</em>, and nodes can leave the system at any time, sometimes gracefully, sometimes in a sudden crash. But we don&rsquo;t need to have too many nodes to crash, which is not the scope of our course.</p>
</li>
<li>
<p><strong>Symmetry</strong>
No node is particular in any way, the nodes are similar to one and another. <em>They run the same code</em>.</p>
</li>
<li>
<p><strong>Decentralization</strong>
There is no leader or orchestrator in the network. Note that symmetric protocols could elect a leader nonetheless, while in this case we have the strict requirement not to have a leader.</p>
</li>
<li>
<p><strong>Heterogeneity</strong>
the nodes may have different CPU power, amounts of memory, etc.</p>
</li>
</ul>
<h3 id="comparison-with-objectstorage">Comparison With ObjectStorage<a hidden class="anchor" aria-hidden="true" href="#comparison-with-objectstorage">#</a></h3>
<h4 id="limitations-compared-to-s3-and-azure-blob-storage-">Limitations compared to S3 and Azure Blob Storage üü©<a hidden class="anchor" aria-hidden="true" href="#limitations-compared-to-s3-and-azure-blob-storage-">#</a></h4>
<p>Yet, this brings some drawbacks:
We have the values to be far smaller, about 400kb of data (this is what <em>Dynamo</em> does) and we <strong>cannot store metadata</strong>
It has a simplified APIs that just supports <em>get</em>, <em>put</em> or <em>delete</em> the document, with a given key or value (in reality there is also a context variable).
This is why they are often more suitable for real-time data, simplicity and speed.</p>
<h4 id="what-are-contexes">What are Contexes?<a hidden class="anchor" aria-hidden="true" href="#what-are-contexes">#</a></h4>
<p>These values are the state of the updates for every node, this is used to merge the vector clocks in case of need.
Providing a context to get or put, allows the key-value store to correctly update the context so that later in case of partitions, it could be exactly solved.</p>
<h4 id="common-usage-patterns">Common Usage Patterns<a hidden class="anchor" aria-hidden="true" href="#common-usage-patterns">#</a></h4>
<p>Particular usages are for example shopping carts, likes and comments on social media, and so on.</p>
<blockquote>
<p>One of the typical use cases for a key-value store is <strong>storing shopping carts</strong> for a very large online shop, another is for storing <strong>likes</strong> and comments on social media.</p>
</blockquote>
<blockquote>
<p>best seller lists, shopping carts, customer preferences, session management, sales rank, and product catalog, from <a href="https://dl.acm.org/doi/10.1145/1323293.1294281">(DeCandia et al. 2007)</a>.</p>
</blockquote>
<h3 id="chord-protocol">Chord protocol<a hidden class="anchor" aria-hidden="true" href="#chord-protocol">#</a></h3>
<p>The amazon paper <a href="https://dl.acm.org/doi/10.1145/1323293.1294281">(DeCandia et al. 2007)</a> describes this system.</p>
<p>This is based on a <strong>distributed hashing protocol</strong>. We use hashes because they have some properties to be robust against failures of some kind, which I have not understood.</p>
<p>With this protocol, every node has an ID. For example a code in $2^{128}$ (Dynamo indeed uses 128 bytes). If we have a key $k$ this is assigned to a position on the ring. Then from this position we follow the ring clockwise until we find a node, this node should handle the value of this key.</p>
<h4 id="consistent-hashing">Consistent Hashing<a hidden class="anchor" aria-hidden="true" href="#consistent-hashing">#</a></h4>
<p>The ring structure of the Chord protocol is called <strong>consistent hashing</strong>. It has been designed to minimize the amount of transfer of data in distributed systems that join and leave frequently. See <a href="/notes/tabelle-di-hash/">Tabelle di hash</a> for a primer of how hashing works.</p>
<p>Other systems use this type of hashing, like the CassandraDB or CDN services. It acts as an automatic load balancing system.</p>
<blockquote>
<p>The principle advantage of consistent hashing is that departure or arrival of a node only affects its <em>immediate neighbors</em> and other nodes remain unaffected.</p>
</blockquote>
<h4 id="join-leave-and-crash-">Join, Leave and Crash üü©<a hidden class="anchor" aria-hidden="true" href="#join-leave-and-crash-">#</a></h4>
<p>When a node joins, the should take the responsibility of part of the data in front of him in a clockwise fashion.
When a node leaves, it should give responsibility of part of the data to the node in front of him. Clearly this is not possible when we have a crash, this is why we need <em>redundancy</em>, which is easily done by having <em>2-range</em> <strong>redundancy</strong>, but it can be set to any value.</p>
<p>One thing that should be noted with the updates is how it handles the replication: only single node modifies, but after it propagates the update to the replicas and receives acks.
Then you use <strong>vector clocks</strong> to choose the highest update number.
A nice parallel with vector clocks is the parallel between these and the Newtonian physics vs Structure of spacetime and different timelines.</p>
<h4 id="reads-on-dinamo---">Reads on Dinamo üü®&ndash;<a hidden class="anchor" aria-hidden="true" href="#reads-on-dinamo---">#</a></h4>
<blockquote>
<p>A client periodically picks a random Dynamo node and downloads its current view of Dynamo membership state. Using this information the client can determine which set of nodes form the <strong>preference list</strong> for any given key.</p>
</blockquote>
<p>A preference list is just a map of each object and the node that is currently storing that object. With the classical Chord protocol the so called <em>finger tables</em> where used where you could employ binary search to find the node that is responsible for the key. With finger tables, each node knows what the following nodes to the power of two have, so that the search could be employed.</p>
<blockquote>
<p>¬†Every time a node wants to look up a key¬†$k$, it will pass the query to the closest successor or predecessor (depending on the finger table) of¬†$k$¬†in its finger table (the &ldquo;largest&rdquo; one on the circle whose ID is smaller than¬†$k$), until a node finds out the key is stored in its immediate successor.</p>
</blockquote>
<p>Probably this approach has been dismissed because it is a little bit more burgeoning to update the finger table on joins or leaves, and preference lists are a better practical solution.</p>
<p>This is called the <strong>client driven</strong> approach, and from their tests, it seems twice as fast as the server driven approach.</p>
<h4 id="preference-lists-">Preference lists üü©<a hidden class="anchor" aria-hidden="true" href="#preference-lists-">#</a></h4>
<p>This solves the problem of finding the actual node that has the data we are querying for. It is just a table with a key -&gt; and nodes that have it.
We have distributed algorithms that make the nodes <em>agree</em> on this preference list which is just knowing what machine is responsible for what interval range.
For each key range, the first node on the list is called the <strong>coordinator</strong> node, it this fails, the random node that has gotten request attempt to contact every node until one answers.
$R$ is the minimum number of nodes from which the value needs to be retrieved for it to be considered consistent. $W$ is the minimum number of nodes for which an ack should be received to consider it towards a successful read.
We have the theoretical necessity that $R + W > N$ to set up a <strong>quorum</strong> system, whose acknowledgement is based on the majority of notes that have accepted a certain modification.
Sometimes the system is also configured to values less than $N$ for a better latency, which is configurable by the developer.</p>
<p>Tuning the values for $R$ and $W$ scale the performance stability of reads and writes. For example read-intensive applications, would prefer to have $R=1$ and $W=N$ so that it is fast to read, but could potentially read some inconsistent data.
The most common configuration is $N=3, R=2, W=2$ for Dynamo.</p>
<h4 id="advantages-and-disadvantages-">Advantages and disadvantages üü®+<a hidden class="anchor" aria-hidden="true" href="#advantages-and-disadvantages-">#</a></h4>
<p><strong>Pros:</strong></p>
<ul>
<li>Highly scalable</li>
<li>Robust to failure (because we replicate data with the ones in front of us).</li>
<li><strong>Self-organizing</strong>.
I don&rsquo;t know if the above properties are exclusive, but they are nice</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Only lookup, no search (obvious)</li>
<li>No data-integrity (we don&rsquo;t have a way to check for integrity constraints)</li>
<li>Security issues (Need to understand this)</li>
</ul>
<h4 id="virtual-nodes-">Virtual Nodes üü©<a hidden class="anchor" aria-hidden="true" href="#virtual-nodes-">#</a></h4>
<p>Two problems arise with the Chord protocol: there could be large gaps in the Circle and the underlying machines could have different hardware proposals.
The idea is to have some nodes take other nodes in a way <em>proportional</em> to its hardware. In this manner, if a node has more resources, it has more nodes, which implies it is expected to handle more data (which is fine because it has more resources).</p>
<h3 id="cap-theorem">CAP Theorem<a hidden class="anchor" aria-hidden="true" href="#cap-theorem">#</a></h3>
<h4 id="statement-of-cap-">Statement of CAP üü©<a hidden class="anchor" aria-hidden="true" href="#statement-of-cap-">#</a></h4>
<p>We can only have two of the following properties:</p>
<ol>
<li>Consistency (doesn&rsquo;t depend on the machine that answers to your request).</li>
<li>Availability (it should answer something).</li>
<li>Partition tolerance (the system continues to function even if the network linking its machines is occasionally partitioned.)</li>
</ol>
<p>We don&rsquo;t have ACID anymore (see <a href="/notes/advanced-sql/">Advanced SQL</a>) in the case of Big Data.
So now we have 3 possible scenarios, which correspond to the 3 couples that is possible to have with these properties.</p>
<p>For example, let&rsquo;s say we have a partition of the network then we have two cases: not available until the network is connected again, but we still have the same data. Or we have two parts that answer differently (this is usually called <strong>eventual consistency</strong>, because after the network is connected then it will return to the consistent state), but are still available to the users.</p>
<p>When network partitions happen we need to choose what property we want to keep, so we have three possible cases: CP, CA or AP. Services like Dynamo Key value store (see <a href="/notes/cloud-storage/#key-value-stores">Cloud Storage#Key-value stores</a>) choose AP and thus have eventual consistency.</p>
<h4 id="vector-clocks---">Vector Clocks üü®&ndash;<a hidden class="anchor" aria-hidden="true" href="#vector-clocks---">#</a></h4>
<p>Sometimes when we have a network partition we lose the linear timing of the system and so we have directed acyclic graphs</p>
<p><img loading="lazy" src="/notes/introduction-to-big-data-20241001142744556.webp" alt="Example of a DAG due to network partition"  />

We have vectors for updates by different nodes. The merge is done by a certain node and updates the vector again.</p>
<p>The merge happens in the following manner: just choose the maximum value for each resource that has been modified. This grants consistency, but could lose some data.</p>
<h4 id="pacelc-theorem---">PACELC Theorem üü©&ndash;<a hidden class="anchor" aria-hidden="true" href="#pacelc-theorem---">#</a></h4>
<p>PACELC is a generalization of the CAP theorem. The acronym PACELC stands for:</p>
<ul>
<li><strong>P</strong>: Partition tolerance (as in the CAP theorem).</li>
<li><strong>A</strong>: Availability.</li>
<li><strong>C</strong>: Consistency.</li>
<li><strong>E</strong>: Else.</li>
<li><strong>L</strong>: Latency.</li>
<li><strong>C</strong>: Consistency.</li>
</ul>
<p>PACELC integrates the <strong>latency</strong> in normal running cases.
We can tradeoff between being low latency but accepting some inconsistencies, or being consistent with a little higher latency.</p>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p>[1] DeCandia et al. <a href="https://dl.acm.org/doi/10.1145/1323293.1294281">‚ÄúDynamo: Amazon&rsquo;s Highly Available Key-Value Store‚Äù</a> ACM SIGOPS Operating Systems Review Vol. 41(6), pp. 205&ndash;220 2007</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://flecart.github.io/tags/big-data/">üììBig-Data</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Cloud Storage on x"
            href="https://x.com/intent/tweet/?text=Cloud%20Storage&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fcloud-storage%2f&amp;hashtags=%f0%9f%93%93big-data">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Cloud Storage on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fcloud-storage%2f&amp;title=Cloud%20Storage&amp;summary=Cloud%20Storage&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2fcloud-storage%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Cloud Storage on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2fcloud-storage%2f&title=Cloud%20Storage">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Cloud Storage on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2fcloud-storage%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Cloud Storage on whatsapp"
            href="https://api.whatsapp.com/send?text=Cloud%20Storage%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2fcloud-storage%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Cloud Storage on telegram"
            href="https://telegram.me/share/url?text=Cloud%20Storage&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fcloud-storage%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Cloud Storage on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Cloud%20Storage&u=https%3a%2f%2fflecart.github.io%2fnotes%2fcloud-storage%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
