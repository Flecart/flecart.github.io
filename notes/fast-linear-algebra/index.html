<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Fast Linear Algebra | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="advanced-systems-lab">
<meta name="description" content="Many problems in scientific computing include:

Solving linear equations
Eigenvalue computations
Singular value decomposition
LU/Cholesky/QR decompositions
etc&hellip;
And the userbase is quite large for this types of computation (number of scientists in the world is growing exponentially )

Quick History of Performance Computing
Early seventies it was EISPACK and LINPACK. Then In similar years Matlab was invented, which simplified a lot compared to previous systems.
LAPACK redesigned the algorithms in previous libraries to have better block-based locality.
BLAS are kernel functions for each computer, while LAPACK are the higher level functions build on top of BLAS (1, 2,3).
Then another innovation was ATLAS, which automatically generates the code for BLAS for each architecture.
This is called autotuning because it does a search of possible enumerations and chooses the fastest one.
Now autotuning has been done a lot for NN systems.">
<meta name="author" content="
By Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/fast-linear-algebra/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f790d9af969c56c079c1ce2d5972a04486bf3d6144295d5fba319830e1e55a7a.css" integrity="sha256-95DZr5acVsB5wc4tWXKgRIa/PWFEKV1fujGYMOHlWno=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/fast-linear-algebra/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>






      <script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-WW6NN2QGKF');
        }
      </script><meta property="og:url" content="https://flecart.github.io/notes/fast-linear-algebra/">
  <meta property="og:site_name" content="X. Angelo Huang&#39;s Blog">
  <meta property="og:title" content="Fast Linear Algebra">
  <meta property="og:description" content="Many problems in scientific computing include:
Solving linear equations Eigenvalue computations Singular value decomposition LU/Cholesky/QR decompositions etc… And the userbase is quite large for this types of computation (number of scientists in the world is growing exponentially ) Quick History of Performance Computing Early seventies it was EISPACK and LINPACK. Then In similar years Matlab was invented, which simplified a lot compared to previous systems. LAPACK redesigned the algorithms in previous libraries to have better block-based locality. BLAS are kernel functions for each computer, while LAPACK are the higher level functions build on top of BLAS (1, 2,3). Then another innovation was ATLAS, which automatically generates the code for BLAS for each architecture. This is called autotuning because it does a search of possible enumerations and chooses the fastest one. Now autotuning has been done a lot for NN systems.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="notes">
    <meta property="article:tag" content="Advanced-Systems-Lab">
      <meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:title" content="Fast Linear Algebra">
<meta name="twitter:description" content="Many problems in scientific computing include:

Solving linear equations
Eigenvalue computations
Singular value decomposition
LU/Cholesky/QR decompositions
etc&hellip;
And the userbase is quite large for this types of computation (number of scientists in the world is growing exponentially )

Quick History of Performance Computing
Early seventies it was EISPACK and LINPACK. Then In similar years Matlab was invented, which simplified a lot compared to previous systems.
LAPACK redesigned the algorithms in previous libraries to have better block-based locality.
BLAS are kernel functions for each computer, while LAPACK are the higher level functions build on top of BLAS (1, 2,3).
Then another innovation was ATLAS, which automatically generates the code for BLAS for each architecture.
This is called autotuning because it does a search of possible enumerations and chooses the fastest one.
Now autotuning has been done a lot for NN systems.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Fast Linear Algebra",
      "item": "https://flecart.github.io/notes/fast-linear-algebra/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Fast Linear Algebra",
  "name": "Fast Linear Algebra",
  "description": "Many problems in scientific computing include:\nSolving linear equations Eigenvalue computations Singular value decomposition LU/Cholesky/QR decompositions etc\u0026hellip; And the userbase is quite large for this types of computation (number of scientists in the world is growing exponentially ) Quick History of Performance Computing Early seventies it was EISPACK and LINPACK. Then In similar years Matlab was invented, which simplified a lot compared to previous systems. LAPACK redesigned the algorithms in previous libraries to have better block-based locality. BLAS are kernel functions for each computer, while LAPACK are the higher level functions build on top of BLAS (1, 2,3). Then another innovation was ATLAS, which automatically generates the code for BLAS for each architecture. This is called autotuning because it does a search of possible enumerations and chooses the fastest one. Now autotuning has been done a lot for NN systems.\n",
  "keywords": [
    "advanced-systems-lab"
  ],
  "articleBody": "Many problems in scientific computing include:\nSolving linear equations Eigenvalue computations Singular value decomposition LU/Cholesky/QR decompositions etc… And the userbase is quite large for this types of computation (number of scientists in the world is growing exponentially ) Quick History of Performance Computing Early seventies it was EISPACK and LINPACK. Then In similar years Matlab was invented, which simplified a lot compared to previous systems. LAPACK redesigned the algorithms in previous libraries to have better block-based locality. BLAS are kernel functions for each computer, while LAPACK are the higher level functions build on top of BLAS (1, 2,3). Then another innovation was ATLAS, which automatically generates the code for BLAS for each architecture. This is called autotuning because it does a search of possible enumerations and chooses the fastest one. Now autotuning has been done a lot for NN systems.\nVector sum Matrix vector product MMM (scales with the cache size, so this was the preferred version for speed). On Strassen’s Algorithm Indeed there are faster methods for matrix to matrix multiplication Yet, it is much less numerically stable and complex compared to the standard one, and it is not used in practice.\nATLAS Architecture Fixes some hyperparameters (bounds, possible choices. hardware parameters) Then it generates the code for each architecture. Tests it on the architecture Repeasts and chooses the best one. But this is not quite transparent, it does not tell you why it is the best. Others have built a Model-Based ATLAS that finds the parameters in theory for the code. It gives you some understanding.\nAn advantage is that this model is able to adapt to new architectures, and it is not limited to the ones that are already in the database (but we don’t know why it chooses that, so it is scientifically unsatisfactory).\nOptimizing MMM Loop Order Consider a multiplication in the form $C = AB$. And a loop in the form:\nfor (i = 0; i \u003c n; i++) for (j = 0; j \u003c n; j++) for (k = 0; k \u003c n; k++) C[i][j] += A[i][k] * B[k][j]; Then it is better to have:\ni-j-k if B is smaller than A (B is re-used). j-i-k if A is smaller than B (A is re-used). Blocking for Cache This is called micro-MMM. Blocking is used to improve the cache locality. It uses mini matrix matrix multipications. ATLAS uses this count for the cache size: $N_{B}^{2} \\leq \\min(C, 80^{2})$. The idea is that the working set should fit into memory.\nThe classical model is $3N_{B}^{2} \\leq C_{1}$ but closer analysis can highlight the following:\n$B$ is reused $A$ is used only once. $$ \\underbrace{N_{B}^{2}}_{\\text{all of } b} + \\underbrace{N_{B}}_{\\text{row of }a} + \\underbrace{1}_{\\text{ element of } c} \\leq C_{1} $$ It might also be useful to take block size into measure: $$ \\left\\lceil \\frac{N_{B}^{2}}{B_{1}} \\right\\rceil + \\left\\lceil \\frac{N_{B}}{B_{2}} \\right\\rceil + 1 \\leq \\frac{C_{1}}{B_{1}} $$ We would like to evict the row of $A$, and always keep the matrix $B$ in cache. But it is not possible in practice to make this fit perfectly, cache eviction is not software controlled. In reality, we need to fit at least two rows of $A$. In the model we might need to fit a little bit more.\nBlocking for Registers This is called micro-MMM This is the reason why ATLAS prefers the second version, better instruction level parallelism.\nSo the optimized version should take this into account, and when it still fits into memory, you should do the outer loop.\nTypes of dependencies In hardware, it might be that every logica register has many physical registers under it. Some renaming is done at the hardware level (aliased). - CPU can do the renaming on the fly (this was relevant for the matric multiplication analysis). Micro-MMM model $$ M_{U} \\cdot N_{U} + N_{U} + M_{U} \\leq Reg $$ The number of registers, which is 16 usually. (In the paper, the count of the registers is a little more complex).\nRead after write mechanisms in real ATLAS code, but the hardware renaming solved it.\nFor b we only use a single register, one for a and 14 for C. Virtual Address Performance Incluences Cache lookup can start in parallel with the address translation (faster access to level 1 and 2 caches). Exactly the last 6 bits match with the row for the cache lookup. Cannot change page size -\u003e cache line size is fixed, you can only extend memory of cache with associativity. Uses TLBs (See Paginazione e segmentazione) to know what physical page is associated to the virtual page. For skylake:\n128 entries for instructions (which is a lot for instruction pages) 64 entries for data: few cycles of penalty STLB miss with 1536 entries, is very very expensive (as long as the data is in this cache, then it is ok, about 6MB it seems), but it fits in the L2 cache (slowdown for address translation). Evil Patterns If you repeatedly access more pages than the TLB can handle, then it would be much slower (see working set in Memoria virtuale). We just needs jumps larger than the page size, like 4kb. For example, in matrix matrix multiplication, we have M jumps for AB=C, matrix B, and this could make you load many many pages.\nA contiguous, B is contiguous working set, C has $N_{B}$ pages if $M$ is too big. But if we consider the BLAS MMM multiplication, then the answer could be a little different, It could be that $B$ matrix is spread over too many matrices.\nSpiral Spiral is a tool developed by Püschel at ETH and aims to automate the writing of many fast performance algorithms. This course has already shown that you can get huge improvements by applying those optimization methods.\nIdea of Spiral program generation We start to optimize at the math level. Check Fast Fourier Transforms for the Fourier ideas. One example is Kronecker I4 is very nice to optimize. There are other versions that are also very nice. The problem becomes converting mathematically the first expression to a version that is easily optimized. There is sometimes many possible substitutions, so the problem becomes trying to find the most efficient one.\n",
  "wordCount" : "1030",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/fast-linear-algebra/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Fast Linear Algebra
    </h1>
    <div class="post-meta">Reading Time: 5 minutes&nbsp;·&nbsp;
By Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul>
                <li>
                    <a href="#quick-history-of-performance-computing" aria-label="Quick History of Performance Computing">Quick History of Performance Computing</a></li>
                <li>
                    <a href="#on-strassens-algorithm" aria-label="On Strassen&rsquo;s Algorithm">On Strassen&rsquo;s Algorithm</a></li>
                <li>
                    <a href="#atlas-architecture" aria-label="ATLAS Architecture">ATLAS Architecture</a></li></ul>
                    
                <li>
                    <a href="#optimizing-mmm" aria-label="Optimizing MMM">Optimizing MMM</a><ul>
                        
                <li>
                    <a href="#loop-order" aria-label="Loop Order">Loop Order</a></li>
                <li>
                    <a href="#blocking-for-cache" aria-label="Blocking for Cache">Blocking for Cache</a></li>
                <li>
                    <a href="#blocking-for-registers" aria-label="Blocking for Registers">Blocking for Registers</a></li>
                <li>
                    <a href="#types-of-dependencies" aria-label="Types of dependencies">Types of dependencies</a></li>
                <li>
                    <a href="#micro-mmm-model" aria-label="Micro-MMM model">Micro-MMM model</a></li></ul>
                </li>
                <li>
                    <a href="#virtual-address-performance-incluences" aria-label="Virtual Address Performance Incluences">Virtual Address Performance Incluences</a><ul>
                        
                <li>
                    <a href="#evil-patterns" aria-label="Evil Patterns">Evil Patterns</a></li></ul>
                </li>
                <li>
                    <a href="#spiral" aria-label="Spiral">Spiral</a><ul>
                        
                <li>
                    <a href="#idea-of-spiral-program-generation" aria-label="Idea of Spiral program generation">Idea of Spiral program generation</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Many problems in scientific computing include:</p>
<ul>
<li>Solving linear equations</li>
<li>Eigenvalue computations</li>
<li>Singular value decomposition</li>
<li>LU/Cholesky/QR decompositions</li>
<li>etc&hellip;
And the userbase is quite large for this types of computation (number of scientists in the world is growing exponentially )</li>
</ul>
<h4 id="quick-history-of-performance-computing">Quick History of Performance Computing<a hidden class="anchor" aria-hidden="true" href="#quick-history-of-performance-computing">#</a></h4>
<p>Early seventies it was EISPACK and LINPACK. Then In similar years Matlab was invented, which simplified a lot compared to previous systems.
LAPACK redesigned the algorithms in previous libraries to have better block-based locality.
BLAS are kernel functions for each computer, while LAPACK are the higher level functions build on top of BLAS (1, 2,3).
Then another innovation was ATLAS, which automatically generates the code for BLAS for each architecture.
This is called <strong>autotuning</strong> because it does a search of possible enumerations and chooses the fastest one.
Now autotuning has been done a lot for NN systems.</p>
<ol>
<li>Vector sum</li>
<li>Matrix vector product</li>
<li>MMM (scales with the cache size, so this was the preferred version for speed).</li>
</ol>
<h4 id="on-strassens-algorithm">On Strassen&rsquo;s Algorithm<a hidden class="anchor" aria-hidden="true" href="#on-strassens-algorithm">#</a></h4>
<p>Indeed there are faster methods for matrix to matrix multiplication
Yet, it is much less numerically stable and complex compared to the standard one, and it is not used in practice.</p>
<h4 id="atlas-architecture">ATLAS Architecture<a hidden class="anchor" aria-hidden="true" href="#atlas-architecture">#</a></h4>
<ol>
<li>Fixes some hyperparameters (bounds, possible choices. hardware parameters)</li>
<li>Then it generates the code for each architecture.</li>
<li>Tests it on the architecture</li>
<li>Repeasts and chooses the best one.
<img src="/images/notes/Fast Linear Algebra-20250324105542265.webp" style="width: 100%" class="center" alt="Fast Linear Algebra-20250324105542265"></li>
</ol>
<p>But this is not quite transparent, it does not tell you why it is the best.
Others have built a <strong>Model-Based ATLAS</strong> that finds the parameters in theory for the code. It gives you some understanding.</p>
<p>An advantage is that this model is able to adapt to new architectures, and it is not limited to the ones that are already in the database (but we don&rsquo;t know why it chooses that, so it is <em>scientifically unsatisfactory</em>).</p>
<h3 id="optimizing-mmm">Optimizing MMM<a hidden class="anchor" aria-hidden="true" href="#optimizing-mmm">#</a></h3>
<h4 id="loop-order">Loop Order<a hidden class="anchor" aria-hidden="true" href="#loop-order">#</a></h4>
<p>Consider a multiplication in the form $C = AB$.
And  a loop in the form:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
</span></span></code></pre></div><p>Then it is better to have:</p>
<ul>
<li>i-j-k if B is smaller than A (B is re-used).</li>
<li>j-i-k if A is smaller than B (A is re-used).</li>
</ul>
<h4 id="blocking-for-cache">Blocking for Cache<a hidden class="anchor" aria-hidden="true" href="#blocking-for-cache">#</a></h4>
<p>This is called <strong>micro-MMM</strong>.
Blocking is used to improve the cache locality.
It uses mini matrix matrix multipications. ATLAS uses this count for the cache size: $N_{B}^{2} \leq \min(C, 80^{2})$.
The idea is that the working set should fit into memory.</p>
<p>The classical model is $3N_{B}^{2} \leq C_{1}$ but closer analysis can highlight the following:</p>
<ul>
<li>$B$ is reused</li>
<li>$A$ is used only once.
$$
 \underbrace{N_{B}^{2}}_{\text{all of } b} + \underbrace{N_{B}}_{\text{row of }a} + \underbrace{1}_{\text{ element of } c} \leq C_{1}
$$
It might also be useful to take block size into measure:
$$
\left\lceil  \frac{N_{B}^{2}}{B_{1}}  \right\rceil  + \left\lceil  \frac{N_{B}}{B_{2}}  \right\rceil  + 1 \leq \frac{C_{1}}{B_{1}}
$$</li>
</ul>
<p>We would like to evict the row of $A$, and always keep the matrix $B$ in cache.
But it is not possible in practice to make this fit perfectly, cache eviction is not software controlled.
In reality, we need to fit at least two rows of $A$. In the model we might need to fit a little bit more.</p>
<h4 id="blocking-for-registers">Blocking for Registers<a hidden class="anchor" aria-hidden="true" href="#blocking-for-registers">#</a></h4>
<p>This is called <strong>micro-MMM</strong>
This is the reason why ATLAS prefers the second version, better instruction level parallelism.</p>
<img src="/images/notes/Fast Linear Algebra-20250324113716991.webp" style="width: 100%" class="center" alt="Fast Linear Algebra-20250324113716991">
<p>So the optimized version should take this into account, and when it still fits into memory, you should do the outer loop.</p>
<h4 id="types-of-dependencies">Types of dependencies<a hidden class="anchor" aria-hidden="true" href="#types-of-dependencies">#</a></h4>
<img src="/images/notes/Fast Linear Algebra-20250324114924896.webp" style="width: 100%" class="center" alt="Fast Linear Algebra-20250324114924896">
In hardware, it might be that every logica register has many physical registers under it. Some renaming is done at the hardware level (aliased).
- CPU can do the renaming on the fly (this was relevant for the matric multiplication analysis).
<h4 id="micro-mmm-model">Micro-MMM model<a hidden class="anchor" aria-hidden="true" href="#micro-mmm-model">#</a></h4>
$$
M_{U} \cdot N_{U} + N_{U} + M_{U} \leq Reg
$$<p>
The number of registers, which is 16 usually. (In the paper, the count of the registers is a little more complex).</p>
<p>Read after write mechanisms in real ATLAS code, but the hardware renaming solved it.</p>
<ul>
<li>For b we only use a single register, one for a and 14 for C.</li>
</ul>
<h3 id="virtual-address-performance-incluences">Virtual Address Performance Incluences<a hidden class="anchor" aria-hidden="true" href="#virtual-address-performance-incluences">#</a></h3>
<p>Cache lookup can start in <strong>parallel</strong> with the address translation (faster access to level 1 and 2 caches).
Exactly the last 6 bits match with the row for the cache lookup.
Cannot change page size -&gt; cache line size is fixed, you can only extend memory of cache with associativity.
Uses TLBs (See <a href="/notes/paginazione-e-segmentazione">Paginazione e segmentazione</a>) to know what physical page is associated to the virtual page.
For skylake:</p>
<ul>
<li>128 entries for <strong>instructions</strong> (which is a lot for instruction pages)</li>
<li>64 entries for data: few cycles of penalty</li>
<li>STLB miss with 1536 entries, is very very expensive (as long as the data is in this cache, then it is ok, about 6MB it seems), but it fits in the L2 cache (slowdown for address translation).</li>
</ul>
<h4 id="evil-patterns">Evil Patterns<a hidden class="anchor" aria-hidden="true" href="#evil-patterns">#</a></h4>
<p>If you repeatedly access more pages than the TLB can handle, then it would be much slower (see working set in <a href="/notes/memoria-virtuale">Memoria virtuale</a>).
We just needs jumps larger than the page size, like 4kb. For example, in matrix matrix multiplication, we have M jumps for AB=C, matrix B, and this could make you load many many pages.</p>
<ul>
<li>A contiguous, B is contiguous working set, C has $N_{B}$ pages if $M$ is too big.</li>
</ul>
<p>But if we consider the BLAS MMM multiplication, then the answer could be a little different, It could be that $B$ matrix is spread over too many matrices.</p>
<h3 id="spiral">Spiral<a hidden class="anchor" aria-hidden="true" href="#spiral">#</a></h3>
<p>Spiral is a tool developed by Püschel at ETH and aims to automate the writing of many fast performance algorithms. This course has already shown that you can get huge improvements by applying those optimization methods.</p>
<h4 id="idea-of-spiral-program-generation">Idea of Spiral program generation<a hidden class="anchor" aria-hidden="true" href="#idea-of-spiral-program-generation">#</a></h4>
<p>We start to optimize at the math level.
Check <a href="/notes/fast-fourier-transforms">Fast Fourier Transforms</a> for the Fourier ideas.
<img src="/images/notes/Fast Linear Algebra-20250505103301129.webp" style="width: 100%" class="center" alt="Fast Linear Algebra-20250505103301129"></p>
<p>One example is Kronecker I4 is very nice to optimize. There are other versions that are also very nice. The problem becomes converting mathematically the first expression to a version that is easily optimized. There is sometimes many possible substitutions, so the problem becomes trying to find the most efficient one.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://flecart.github.io/tags/advanced-systems-lab/">Advanced-Systems-Lab</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Fast Linear Algebra on x"
            href="https://x.com/intent/tweet/?text=Fast%20Linear%20Algebra&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2ffast-linear-algebra%2f&amp;hashtags=advanced-systems-lab">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Fast Linear Algebra on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2ffast-linear-algebra%2f&amp;title=Fast%20Linear%20Algebra&amp;summary=Fast%20Linear%20Algebra&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2ffast-linear-algebra%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Fast Linear Algebra on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2ffast-linear-algebra%2f&title=Fast%20Linear%20Algebra">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Fast Linear Algebra on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2ffast-linear-algebra%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Fast Linear Algebra on whatsapp"
            href="https://api.whatsapp.com/send?text=Fast%20Linear%20Algebra%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2ffast-linear-algebra%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Fast Linear Algebra on telegram"
            href="https://telegram.me/share/url?text=Fast%20Linear%20Algebra&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2ffast-linear-algebra%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Fast Linear Algebra on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Fast%20Linear%20Algebra&u=https%3a%2f%2fflecart.github.io%2fnotes%2ffast-linear-algebra%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
