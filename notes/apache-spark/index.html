<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Apache Spark | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="üììbig-data">
<meta name="description" content="This is a new framework that is faster than MapReduce (See Massive Parallel Processing). It is written in Scala and has a more functional approach to programming.
Spark extends the previous MapReduce framework to a generic distributed dataflow, properly modeled as a DAG.
There are other benefits of using Spark instead of the Map reduce Framework:

Spark processes data in memory, avoiding the disk I/O overhead of MapReduce, making it significantly faster.
Spark uses a DAG to optimize the entire workflow, reducing data shuffling and stage count.

But MapReduce sometimes has its advantages:">
<meta name="author" content="Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/apache-spark/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/apache-spark/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>






      <script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-WW6NN2QGKF');
        }
      </script><meta property="og:url" content="https://flecart.github.io/notes/apache-spark/">
  <meta property="og:site_name" content="X. Angelo Huang&#39;s Blog">
  <meta property="og:title" content="Apache Spark">
  <meta property="og:description" content="This is a new framework that is faster than MapReduce (See Massive Parallel Processing). It is written in Scala and has a more functional approach to programming. Spark extends the previous MapReduce framework to a generic distributed dataflow, properly modeled as a DAG. There are other benefits of using Spark instead of the Map reduce Framework:
Spark processes data in memory, avoiding the disk I/O overhead of MapReduce, making it significantly faster. Spark uses a DAG to optimize the entire workflow, reducing data shuffling and stage count. But MapReduce sometimes has its advantages:">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="notes">
    <meta property="article:tag" content="üììBig-Data">
      <meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:title" content="Apache Spark">
<meta name="twitter:description" content="This is a new framework that is faster than MapReduce (See Massive Parallel Processing). It is written in Scala and has a more functional approach to programming.
Spark extends the previous MapReduce framework to a generic distributed dataflow, properly modeled as a DAG.
There are other benefits of using Spark instead of the Map reduce Framework:

Spark processes data in memory, avoiding the disk I/O overhead of MapReduce, making it significantly faster.
Spark uses a DAG to optimize the entire workflow, reducing data shuffling and stage count.

But MapReduce sometimes has its advantages:">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Apache Spark",
      "item": "https://flecart.github.io/notes/apache-spark/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Apache Spark",
  "name": "Apache Spark",
  "description": "This is a new framework that is faster than MapReduce (See Massive Parallel Processing). It is written in Scala and has a more functional approach to programming. Spark extends the previous MapReduce framework to a generic distributed dataflow, properly modeled as a DAG. There are other benefits of using Spark instead of the Map reduce Framework:\nSpark processes data in memory, avoiding the disk I/O overhead of MapReduce, making it significantly faster. Spark uses a DAG to optimize the entire workflow, reducing data shuffling and stage count. But MapReduce sometimes has its advantages:\n",
  "keywords": [
    "üììbig-data"
  ],
  "articleBody": "This is a new framework that is faster than MapReduce (See Massive Parallel Processing). It is written in Scala and has a more functional approach to programming. Spark extends the previous MapReduce framework to a generic distributed dataflow, properly modeled as a DAG. There are other benefits of using Spark instead of the Map reduce Framework:\nSpark processes data in memory, avoiding the disk I/O overhead of MapReduce, making it significantly faster. Spark uses a DAG to optimize the entire workflow, reducing data shuffling and stage count. But MapReduce sometimes has its advantages:\nUltra-large datasets that do not fit in memory: For massive datasets that don‚Äôt fit even across a large Spark cluster‚Äôs memory, MapReduce‚Äôs disk-based processing can be more manageable. Strict fault tolerance requirements: MapReduce‚Äôs fault tolerance mechanism is very robust, as it writes intermediate results to HDFS, which may be preferred in environments where data recovery is critical. Low hardware resources: Spark requires more memory and computational resources than MapReduce, so in resource-constrained environments, MapReduce may be a more practical choice. Resilient Distributed Datasets RDDs are the main innovation in this section. The idea, presented (Zaharia et al. 2012), is that keeping the data in memory, when possible, gives an order of magnitude performance increase. See Performance at Large Scales for comparison of the speed of access in various memories.\nUsually, they are seen as Dataframes with a specific schema.\nRDDs fault tolerance Previous methods implemented fault tolerance by saving and persisting the intermediate data that could be produced during the computation. RDDs save the lineage (transformations graph), somewhat akin to a DAG that we often see for machine learning methods like Backpropagation.\nRDD memorization We can keep RDD mainly in three forms:\nDeserialized in memory data: fastest access Serialized in memory: slower access, but less memory Disk: slowest access, but more space (this is often used when RDDs cannot fit into the main memory). Resilient distributed datasets‚Äô Lifecycle Resilient distributed datasets (RDD) are the unit data blocks of Apache Spark. These blocks are created, transformed and written back into the disk.\nResilient means that they remain in memory or on disk on a ‚Äúbest effort‚Äù basis, and can be recomputed if need be. Distributed means that, just like the collections of key-value pairs in MapReduce, they are partitioned and spread over multiple machines.\nRDDs can be anything, not just Key-value pairs as in MapReduce.\nCreation The RDD is created by fetching the used data from the disk or somewhere else. These RDDs can also be so large that cannot fit on a single machine. Spark automatically infers the schema from discovering the JSON Lines file. This adds a static performance cost, but then allows for sql queries inside spark!\nTransformation Instead of just MapReduce, apache spark introduces the notion of transformations. There are hundreds of possible transformations that can be composed like a blocks of LEGO.\nExample of some possible transformations\nFilter (basically a selection on possible values) Map (this can implement a projection for example, it takes a row (single item) and returns some function of it). flatMap (this is a map, but flattens the output of the map, which could be a list). distinct (maps some items evaluated as the same to a single value). sample (take some random items from the start values). join: put a tuple grouping by key value. subtractByKey: binary operation that returns the keys in the first operand that do not appear for the second. Some can also be binary operations, for example:\nunion Cartesian product There are also some possible transformations that are specifically tailored for key-value pairs. reduceByKey: this implements the reduce phase of the map reduce framework. We could also just drop the keys or values as a transformation. groupByKey: all key-values with the same key are grouped together. sortByKey: we can sort by key. We can keep the key and also map the corresponding values. Action Actions make the transformation permanent. Usually Apache emplyes lazy evaluation: the transformations are not executed until the action is called. Sometimes we say data is materialized when it is actually computed and stored on the machines (which happens only when the action is triggered).\nExample of actions are:\nCollect (just collects all the RDDs and flushes them on the client machine). Count (example count by key, or count how many times a value occurs). It is possible to count also by value, somehow this action uses a lot of memory, and if we have too many distinct values, it is possible that the task fails because of memory overflow. Take (return first $n$ values) Top (return last $n$ values). takeSample, similar as before, but samples randomly soem actions. saveAsTextFile, saves the whole RDD in a Cloud Storage service, e.g. S3. lookup (returns one key-value that matches the key). Because there is some time for setup, the first execution time is usually larger.\nPhysical Architecture Narrow dependency transformations In this case, the computation depends only on a single value. Which means, this could be easily parallelized. So, if the data is spread over different machines, all narrow dependencies could be executed in parallel, following this diagram: This is the equivalent of a memory and CPU slot when we were talking about MapReduce. If we have more Tasks than slots, then the faster slots usually get assigned more tasks (this usually improves the latency), so that we can have as few as idle computers as possible. Within a slot, tasks are executed sequentially. We could also split the slots inside a single node, by assigning them different number of cores.\nThe opposite of narrow dependency is called a wide dependency. A stage is a sequential lineage of narrow dependency transformations. This is to clearly distinguish them with the shuffling stage which is often a bottleneck of the system.\nChains of narrow dependencies the physical calls of the underlying map/filter/etc functions are directly chained on each input value to directly produce the corresponding final, output value, meaning that the intermediate RDDs are not even materialized anywhere and exist purely logically. From ({fourny} 2024).\nCommunication over the network is usually not efficient. If we have a sequence of narrow dependency transformations, usually every transformation is done on a chain on the same machine, meaning the intermediate steps of the RDD usually are not even materialized, but we just do subsequent function calls! This chain is called a stage, which is a computation step that can occur sequentially on a single machine without materializing the intermediate RDDs.\nSubmitting a spark task We can set some hyperparameters for spark to know how many resources it needs (for example executors, or memory), and the code for the task that needs to be executed.\nThis is called spark-submit.\nWide dependency transformations These types of tasks need some shuffling, corresponding to the communication step of the MapReduce framework. In these cases, we can have a DAG describing all the transformations of the tasks, and one can have a topological order on the execution.\nFor clusters, the stages are usually in sequential.\nOptimization methods Pinning a RDD If a RDD is used in many successive RDDs, we can pin this in memory, and forgetting all the old RDDs so that we can be efficient in applying these new operations. Example of pinning from the course slides.\nThis is often also called checkpointing. This is often not worthwhile when we have just Narrow dependency transformations, as usually the bottleneck is the shuffling. We would spend a lot more memory to safe a little bit of time.\nPrepartitioning This is an optimization method that enables us to prevent shuffling.\nIf, however, Spark knows that the data is already located where it should be, then shuffling is not needed. A simple example is when data is sorted before being grouped with the same keys as for sorting: then, Spark has the knowledge that the groups are already consistent with their physical location, and that no additional shuffling is needed between sorting and grouping.\nFor example, if we have blocks that are sorted across blocks, but not inside, even if I would normally require shuffling, in this case we do not need that. There are some ways to explicitly defined the partitions in Spark.\nSpark SQL For normal SQL, you should take a look at Structured Query Language. Spark usually converts the JSON or CSV into a dataframe, which can also be converted back to RDD if needed.\nExplode Some operations of SQL only exist within spark. For example explode, which is also called lateral view. Allows to have first normal form by expanding the nested data (e.g. arrays) to have more values.\nIts effect is that the rows are duplicated into as many rows as items in the array, and one particular item of the array is placed on each duplicated row in the corresponding column.\nDistributing and Clustering Spark SQL also allows for different grouping information. Sort operation in Spark happens only locally.\nThe DISTRIBUTE BY clause forces a repartition by putting all rows with the same value (for the specified field(s)) into the same new partition.\nCluster is just mapping by key, and having all the same keys in the same machine. Note that these operations are against the principle of data independence proposed by Codd.\nIn Spark SQL, the DISTRIBUTE BY clause is used to control the physical distribution of the data across different nodes of the cluster. When you use this clause, it forces a repartition of the data such that all rows that have the same values for the specified columns are grouped into the same partition. This is especially useful when you anticipate subsequent operations that benefit from this specific distribution, like certain JOIN operations or SORT BY operations within partitions.\nFor example, consider the following query:\nSELECT first_name, last_name FROM persons WHERE age \u003e= 65 GROUP BY country HAVING COUNT(*) \u003e= 1000 DISTRIBUTE BY country; In this scenario, the¬†DISTRIBUTE BY country¬†clause ensures that all rows with the same¬†country¬†are brought together into the same partition. This can be beneficial for performance, especially in large-scale data processing, as it minimizes the amount of data shuffled across the network during subsequent operations that might need to group or join data by the¬†country¬†field.\nShuffling operations Remember that shuffles are usually the bottleneck of our transformations. We need to remember this! Some examples are group by or order by operations. Examples of operations that need shuffling are:\nreduceByKey or Group by key and similars Joins distinct operations References [1] Zaharia et al. ‚ÄúResilient Distributed Datasets: A Fault-Tolerant Abstraction for in-Memory Cluster Computing‚Äù USENIX Association 2012 [2] {fourny} ‚ÄúThe Big Data Textbook‚Äù Self Published 2024 ",
  "wordCount" : "1779",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/apache-spark/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;¬ª&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Apache Spark
    </h1>
    <div class="post-meta">9 min&nbsp;¬∑&nbsp;Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul><ul>
                <li>
                    <a href="#resilient-distributed-datasets" aria-label="Resilient Distributed Datasets">Resilient Distributed Datasets</a><ul>
                        
                <li>
                    <a href="#rdds-fault-tolerance" aria-label="RDDs fault tolerance">RDDs fault tolerance</a></li>
                <li>
                    <a href="#rdd-memorization" aria-label="RDD memorization">RDD memorization</a></li>
                <li>
                    <a href="#resilient-distributed-datasets-lifecycle" aria-label="Resilient distributed datasets&rsquo; Lifecycle">Resilient distributed datasets&rsquo; Lifecycle</a></li>
                <li>
                    <a href="#creation" aria-label="Creation">Creation</a></li>
                <li>
                    <a href="#transformation" aria-label="Transformation">Transformation</a></li>
                <li>
                    <a href="#action" aria-label="Action">Action</a></li></ul>
                </li>
                <li>
                    <a href="#physical-architecture" aria-label="Physical Architecture">Physical Architecture</a><ul>
                        
                <li>
                    <a href="#narrow-dependency-transformations" aria-label="Narrow dependency transformations">Narrow dependency transformations</a></li>
                <li>
                    <a href="#chains-of-narrow-dependencies" aria-label="Chains of narrow dependencies">Chains of narrow dependencies</a></li>
                <li>
                    <a href="#submitting-a-spark-task" aria-label="Submitting a spark task">Submitting a spark task</a></li>
                <li>
                    <a href="#wide-dependency-transformations" aria-label="Wide dependency transformations">Wide dependency transformations</a></li></ul>
                </li>
                <li>
                    <a href="#optimization-methods" aria-label="Optimization methods">Optimization methods</a><ul>
                        
                <li>
                    <a href="#pinning-a-rdd" aria-label="Pinning a RDD">Pinning a RDD</a></li>
                <li>
                    <a href="#prepartitioning" aria-label="Prepartitioning">Prepartitioning</a></li></ul>
                </li>
                <li>
                    <a href="#spark-sql" aria-label="Spark SQL">Spark SQL</a><ul>
                        
                <li>
                    <a href="#explode" aria-label="Explode">Explode</a></li>
                <li>
                    <a href="#distributing-and-clustering" aria-label="Distributing and Clustering">Distributing and Clustering</a></li>
                <li>
                    <a href="#shuffling-operations" aria-label="Shuffling operations">Shuffling operations</a></li></ul>
                </li></ul>
                    </ul>
                    
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>This is a new framework that is faster than MapReduce (See <a href="/notes/massive-parallel-processing">Massive Parallel Processing</a>). It is written in Scala and has a more functional approach to programming.
Spark extends the previous MapReduce framework to a generic distributed dataflow, properly modeled as a DAG.
There are other benefits of using Spark instead of the Map reduce Framework:</p>
<ul>
<li>Spark processes data in memory, avoiding the disk I/O overhead of MapReduce, making it significantly faster.</li>
<li>Spark uses a DAG to optimize the entire workflow, reducing data shuffling and stage count.</li>
</ul>
<p>But MapReduce sometimes has its advantages:</p>
<ul>
<li>Ultra-large datasets that do not fit in memory: For massive datasets that don‚Äôt fit even across a large Spark cluster‚Äôs memory, MapReduce‚Äôs disk-based processing can be more manageable.</li>
<li>Strict fault tolerance requirements: MapReduce‚Äôs fault tolerance mechanism is very robust, as it writes intermediate results to HDFS, which may be preferred in environments where data recovery is critical.</li>
<li>Low hardware resources: Spark requires more memory and computational resources than MapReduce, so in resource-constrained environments, MapReduce may be a more practical choice.</li>
</ul>
<h3 id="resilient-distributed-datasets">Resilient Distributed Datasets<a hidden class="anchor" aria-hidden="true" href="#resilient-distributed-datasets">#</a></h3>
<p>RDDs are the main innovation in this section. The idea, presented <a href="https://dl.acm.org/doi/10.5555/2228298.2228301">(Zaharia et al. 2012)</a>, is that keeping the data in memory, when possible, gives an order of magnitude performance increase. See <a href="/notes/performance-at-large-scales">Performance at Large Scales</a> for comparison of the speed of access in various memories.</p>
<p>Usually, they are seen as Dataframes with a specific schema.</p>
<h4 id="rdds-fault-tolerance">RDDs fault tolerance<a hidden class="anchor" aria-hidden="true" href="#rdds-fault-tolerance">#</a></h4>
<p>Previous methods implemented fault tolerance by saving and persisting the intermediate data that could be produced during the computation. RDDs save the <strong>lineage</strong> (transformations graph), somewhat akin to a DAG that we often see for machine learning methods like <a href="/notes/backpropagation">Backpropagation</a>.</p>
<h4 id="rdd-memorization">RDD memorization<a hidden class="anchor" aria-hidden="true" href="#rdd-memorization">#</a></h4>
<p>We can keep RDD mainly in three forms:</p>
<ul>
<li>Deserialized in memory data: fastest access</li>
<li>Serialized in memory: slower access, but less memory</li>
<li>Disk: slowest access, but more space (this is often used when RDDs cannot fit into the main memory).</li>
</ul>
<h4 id="resilient-distributed-datasets-lifecycle">Resilient distributed datasets&rsquo; Lifecycle<a hidden class="anchor" aria-hidden="true" href="#resilient-distributed-datasets-lifecycle">#</a></h4>
<p>Resilient distributed datasets (RDD) are the unit data blocks of Apache Spark. These blocks are created, transformed and written back into the disk.</p>
<blockquote>
<p>Resilient means that they remain in memory or on disk on
a ‚Äúbest effort‚Äù basis, and can be recomputed if need be. Distributed
means that, just like the collections of key-value pairs in MapReduce,
they are partitioned and spread over multiple machines.</p></blockquote>
<p>RDDs can be anything, not just Key-value pairs as in MapReduce.</p>
<h4 id="creation">Creation<a hidden class="anchor" aria-hidden="true" href="#creation">#</a></h4>
<p>The RDD is created by fetching the used data from the disk or somewhere else. These RDDs can also be so large that cannot fit on a single machine.
Spark automatically infers the schema from discovering the JSON Lines file. This adds a static performance cost, but then allows for sql queries inside spark!</p>
<h4 id="transformation">Transformation<a hidden class="anchor" aria-hidden="true" href="#transformation">#</a></h4>
<p>Instead of just MapReduce, apache spark introduces the notion of <strong>transformations</strong>. There are hundreds of possible transformations that can be composed like a blocks of LEGO.</p>
<p>Example of some possible transformations</p>
<ul>
<li><strong>Filter</strong> (basically a selection on possible values)</li>
<li><strong>Map</strong> (this can implement a projection for example, it takes a row (single item) and returns some function of it).</li>
<li><strong>flatMap</strong> (this is a map, but flattens the output of the map, which could be a list).</li>
<li>distinct (maps some items evaluated as the same to a single value).</li>
<li><strong>sample</strong> (take some random items from the start values).</li>
<li><strong>join</strong>: put a tuple grouping by key value.</li>
<li><strong>subtractByKey</strong>: binary operation that returns the keys in the first operand that do not appear for the second.</li>
</ul>
<p>Some can also be binary operations, for example:</p>
<ul>
<li><strong>union</strong></li>
<li>Cartesian product
There are also some possible transformations that are specifically tailored for key-value pairs.</li>
<li><strong>reduceByKey</strong>: this implements the reduce phase of the map reduce framework.</li>
<li>We could also just drop the keys or values as a transformation.</li>
<li><strong>groupByKey</strong>: all key-values with the same key are grouped together.</li>
<li><strong>sortByKey</strong>: we can sort by key.</li>
<li>We can keep the key and also map the corresponding values.</li>
</ul>
<h4 id="action">Action<a hidden class="anchor" aria-hidden="true" href="#action">#</a></h4>
<p>Actions make the transformation permanent. Usually Apache emplyes <strong>lazy evaluation</strong>: the transformations are not executed until the action is called. Sometimes we say data is <strong>materialized</strong> when it is actually computed and stored on the machines (which happens only when the action is triggered).</p>
<p>Example of actions are:</p>
<ul>
<li>Collect (just collects all the RDDs and flushes them on the client machine).</li>
<li>Count (example count by key, or count how many times a value occurs).
<ul>
<li>It is possible to count also by <em>value</em>, somehow this action uses a lot of memory, and if we have too many distinct values, it is possible that the task fails because of memory overflow.</li>
</ul>
</li>
<li>Take (return first $n$ values)</li>
<li>Top (return last $n$ values).</li>
<li>takeSample, similar as before, but samples randomly soem actions.</li>
<li>saveAsTextFile, saves the whole RDD in a <a href="/notes/cloud-storage">Cloud Storage</a> service, e.g. S3.</li>
<li>lookup (returns one key-value that matches the key).</li>
</ul>
<p>Because there is some time for setup, the first execution time is usually larger.</p>
<h3 id="physical-architecture">Physical Architecture<a hidden class="anchor" aria-hidden="true" href="#physical-architecture">#</a></h3>
<h4 id="narrow-dependency-transformations">Narrow dependency transformations<a hidden class="anchor" aria-hidden="true" href="#narrow-dependency-transformations">#</a></h4>
<p>In this case, the computation depends only on a single value. Which means, this could be easily parallelized.
So, if the data is spread over different machines, all narrow dependencies could be executed in <strong>parallel</strong>, following this diagram:
<img src="/images/notes/Massive Parallel Processing-20241109161812672.webp" style="width: 100%" class="center" alt="Massive Parallel Processing-20241109161812672">
This is the equivalent of a memory and CPU slot when we were talking about MapReduce.
If we have more Tasks than slots, then the faster slots usually get assigned more tasks (this usually improves the latency), so that we can have as few as idle computers as possible. Within a slot, tasks are executed <em>sequentially</em>.
We could also split the slots inside a single node, by assigning them different number of cores.</p>
<p>The opposite of narrow dependency is called a <strong>wide dependency</strong>.
A <strong>stage</strong> is a sequential <em>lineage</em> of narrow dependency transformations. This is to clearly distinguish them with the shuffling stage which is often a bottleneck of the system.</p>
<h4 id="chains-of-narrow-dependencies">Chains of narrow dependencies<a hidden class="anchor" aria-hidden="true" href="#chains-of-narrow-dependencies">#</a></h4>
<blockquote>
<p>the physical calls of the underlying map/filter/etc functions are directly chained on each input value to directly produce the corresponding final, output value, meaning that the intermediate RDDs are not even materialized anywhere and exist purely logically. From <a href="https://ghislainfourny.github.io/big-data-textbook/">({fourny} 2024)</a>.</p></blockquote>
<p>Communication over the network is usually not efficient. If we have a sequence of narrow dependency transformations, usually every transformation is done on a chain on the <strong>same machine</strong>, meaning the intermediate steps of the RDD usually are not even materialized, but we just do subsequent function calls!
This chain is called a <strong>stage</strong>, which is a computation step that can occur sequentially on a single machine without materializing the intermediate RDDs.</p>
<h4 id="submitting-a-spark-task">Submitting a spark task<a hidden class="anchor" aria-hidden="true" href="#submitting-a-spark-task">#</a></h4>
<p>We can set some hyperparameters for spark to know how many resources it needs (for example executors, or memory), and the code for the task that needs to be executed.</p>
<p>This is called <code>spark-submit</code>.</p>
<h4 id="wide-dependency-transformations">Wide dependency transformations<a hidden class="anchor" aria-hidden="true" href="#wide-dependency-transformations">#</a></h4>
<p>These types of tasks need some <strong>shuffling</strong>, corresponding to the communication step of the MapReduce framework. In these cases, we can have a DAG describing all the transformations of the tasks, and one can have a topological order on the execution.</p>
<p>For clusters, the stages are usually in <em>sequential</em>.</p>
<h3 id="optimization-methods">Optimization methods<a hidden class="anchor" aria-hidden="true" href="#optimization-methods">#</a></h3>
<h4 id="pinning-a-rdd">Pinning a RDD<a hidden class="anchor" aria-hidden="true" href="#pinning-a-rdd">#</a></h4>
<p>If a RDD is used in many successive RDDs, we can pin this in memory, and forgetting all the old RDDs so that we can be efficient in applying these new operations.
<img src="/images/notes/Massive Parallel Processing-20241109170821523.webp" style="width: 100%" class="center" alt="Massive Parallel Processing-20241109170821523">
Example of pinning from the course slides.</p>
<p>This is often also called <strong>checkpointing</strong>. This is often not worthwhile when we have just Narrow dependency transformations, as usually the bottleneck is the shuffling. We would spend a lot more memory to safe a little bit of time.</p>
<h4 id="prepartitioning">Prepartitioning<a hidden class="anchor" aria-hidden="true" href="#prepartitioning">#</a></h4>
<p>This is an optimization method that enables us to prevent shuffling.</p>
<blockquote>
<p>If, however, Spark knows that the data is already located where it should be, then shuffling is not needed. A simple example is when data is sorted before being grouped with the same keys as for sorting: then, Spark has the knowledge that the groups are already consistent with their physical location, and that no additional shuffling is needed between sorting and grouping.</p></blockquote>
<p>For example, if we have blocks that are sorted across blocks, but not inside, even if I would normally require shuffling, in this case we do not need that. There are some ways to explicitly defined the partitions in Spark.</p>
<h3 id="spark-sql">Spark SQL<a hidden class="anchor" aria-hidden="true" href="#spark-sql">#</a></h3>
<p>For normal SQL, you should take a look at <a href="/notes/structured-query-language">Structured Query Language</a>.
Spark usually converts the JSON or CSV into a dataframe, which can also be converted back to RDD if needed.</p>
<h4 id="explode">Explode<a hidden class="anchor" aria-hidden="true" href="#explode">#</a></h4>
<p>Some operations of SQL only exist within spark.
For example <strong>explode</strong>, which is also called <em>lateral view</em>. Allows to have first normal form by expanding the nested data (e.g. arrays) to have more values.</p>
<blockquote>
<p>Its effect is that the rows are duplicated into as many rows as items in the array, and one particular item of the array is placed on each duplicated row in the corresponding column.</p></blockquote>
<img src="/images/notes/Apache Spark-20241109174056181.webp" style="width: 100%" class="center" alt="Apache Spark-20241109174056181">
<h4 id="distributing-and-clustering">Distributing and Clustering<a hidden class="anchor" aria-hidden="true" href="#distributing-and-clustering">#</a></h4>
<p>Spark SQL also allows for different grouping information. Sort operation in Spark happens only locally.</p>
<blockquote>
<p>The DISTRIBUTE BY clause forces a repartition by putting all rows with the same value (for the specified field(s)) into the same new partition.</p></blockquote>
<p>Cluster is just mapping by key, and having all the same keys in the same machine.
Note that these operations are against the principle of data independence proposed by Codd.</p>
<p>In Spark SQL, the <code>DISTRIBUTE BY</code> clause is used to control the physical distribution of the data across different nodes of the cluster. When you use this clause, it forces a repartition of the data such that all rows that have the same values for the specified columns are grouped into the same partition. This is especially useful when you anticipate subsequent operations that benefit from this specific distribution, like certain <code>JOIN</code> operations or <code>SORT BY</code> operations within partitions.</p>
<p>For example, consider the following query:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="line"><span class="cl"><span class="k">SELECT</span><span class="w"> </span><span class="n">first_name</span><span class="p">,</span><span class="w"> </span><span class="n">last_name</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">persons</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">WHERE</span><span class="w"> </span><span class="n">age</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">65</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">country</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">HAVING</span><span class="w"> </span><span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">1000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">DISTRIBUTE</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">country</span><span class="p">;</span><span class="w">
</span></span></span></code></pre></div><p>In this scenario, the¬†<code>DISTRIBUTE BY country</code>¬†clause ensures that all rows with the same¬†<code>country</code>¬†are brought together into the same partition. This can be beneficial for performance, especially in large-scale data processing, as it minimizes the amount of data shuffled across the network during subsequent operations that might need to group or join data by the¬†<code>country</code>¬†field.</p>
<h4 id="shuffling-operations">Shuffling operations<a hidden class="anchor" aria-hidden="true" href="#shuffling-operations">#</a></h4>
<p>Remember that shuffles are usually the bottleneck of our transformations. We need to remember this!
Some examples are group by or order by operations.
Examples of operations that need shuffling are:</p>
<ul>
<li>reduceByKey or Group by key and similars</li>
<li>Joins</li>
<li>distinct operations</li>
</ul>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p id=zahariaResilientDistributedDatasets2012>[1] Zaharia et al. <a href="https://dl.acm.org/doi/10.5555/2228298.2228301">‚ÄúResilient Distributed Datasets: A Fault-Tolerant Abstraction for in-Memory Cluster Computing‚Äù</a> USENIX Association  2012
 </p>
<p id=fournyBigDataTextbook2024>[2] {fourny} <a href="https://ghislainfourny.github.io/big-data-textbook/">‚ÄúThe Big Data Textbook‚Äù</a> Self Published 2024
 </p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://flecart.github.io/tags/big-data/">üììBig-Data</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Apache Spark on x"
            href="https://x.com/intent/tweet/?text=Apache%20Spark&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fapache-spark%2f&amp;hashtags=%f0%9f%93%93big-data">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Apache Spark on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fapache-spark%2f&amp;title=Apache%20Spark&amp;summary=Apache%20Spark&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2fapache-spark%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Apache Spark on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2fapache-spark%2f&title=Apache%20Spark">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Apache Spark on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2fapache-spark%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Apache Spark on whatsapp"
            href="https://api.whatsapp.com/send?text=Apache%20Spark%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2fapache-spark%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Apache Spark on telegram"
            href="https://telegram.me/share/url?text=Apache%20Spark&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fapache-spark%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Apache Spark on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Apache%20Spark&u=https%3a%2f%2fflecart.github.io%2fnotes%2fapache-spark%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
