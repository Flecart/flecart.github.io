<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Notes | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Notes - X. Angelo Huang&#39;s Blog">
<meta name="author" content="Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://flecart.github.io/notes/index.xml">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>






      <script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-WW6NN2QGKF');
        }
      </script><meta property="og:url" content="https://flecart.github.io/notes/">
  <meta property="og:site_name" content="X. Angelo Huang&#39;s Blog">
  <meta property="og:title" content="Notes">
  <meta property="og:description" content="Here I write and share about interesting topics I learn.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="website">
      <meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:title" content="Notes">
<meta name="twitter:description" content="Here I write and share about interesting topics I learn.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }
  ]
}
</script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span class="active">Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header"><div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a></div>
  <h1>
    Notes
    <a href="/notes/index.xml" title="RSS" aria-label="RSS">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
        stroke-linecap="round" stroke-linejoin="round" height="23">
        <path d="M4 11a9 9 0 0 1 9 9" />
        <path d="M4 4a16 16 0 0 1 16 16" />
        <circle cx="5" cy="19" r="1" />
      </svg>
    </a>
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Introduction to Natural Language Processing
    </h2>
  </header>
  <div class="entry-content">
    <p>The landscape of NLP was very different in the beginning of the field.
â€œBut it must be recognized that the notion â€˜probability of a sentenceâ€™ is an entirely useless one, under any known interpretation of this term 1968 p 53. Noam Chomsky.
Probability was not seen very well (Chomsky has said many wrong things indeed), and linguists were considered useless. Recently deep learning and computational papers are ubiquitous in major conferences in linguistics, e.g. ACL.
...</p>
  </div>
  <footer class="entry-footer">2 min&nbsp;Â·&nbsp;Xuanqiang &#39;Angelo&#39; Huang</footer>
  <a class="entry-link" aria-label="post link to Introduction to Natural Language Processing" href="https://flecart.github.io/notes/introduction-to-natural-language-processing/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Kalman Filters
    </h2>
  </header>
  <div class="entry-content">
    <p>Here is a historical treatment on the topic: https://jwmi.github.io/ASM/6-KalmanFilter.pdf. Kalman Filters are defined as follows:
We start with a variable $X_{0} \sim \mathcal{N}(\mu, \Sigma)$, then we have a motion model and a sensor model:
$$ \begin{cases} X_{t &#43; 1} = FX_{t} &#43; \varepsilon_{t} &amp; F \in \mathbb{R}^{d\times d}, \varepsilon_{t} \sim \mathcal{N}(0, \Sigma_{x})\\ Y_{t} = HX_{t} &#43; \eta_{t} &amp; H \in \mathbb{R}^{m \times d}, \eta_{t} \sim \mathcal{N}(0, \Sigma_{y}) \end{cases} $$Inference is just doing things with the Gaussians. One can interpret the $Y$ to be the observations and $X$ to be the underlying beliefs about a certain state. We see that the Kalman Filters satisfy the Markov Property, see Markov Chains. These independence properties allow a easy characterization of the joint distribution for Kalman Filters:
...</p>
  </div>
  <footer class="entry-footer">3 min&nbsp;Â·&nbsp;Xuanqiang &#39;Angelo&#39; Huang</footer>
  <a class="entry-link" aria-label="post link to Kalman Filters" href="https://flecart.github.io/notes/kalman-filters/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Kernel Methods
    </h2>
  </header>
  <div class="entry-content">
    <p>As we will briefly see, Kernels will have an important role in many machine learning applications. In this note we will get to know what are Kernels and why are they useful. Intuitively they measure the similarity between two input points. So if they are close the kernel should be big, else it should be small.
We briefly state the requirements of a Kernel, then we will argue with a simple example why they are useful.
...</p>
  </div>
  <footer class="entry-footer">9 min&nbsp;Â·&nbsp;Xuanqiang &#39;Angelo&#39; Huang</footer>
  <a class="entry-link" aria-label="post link to Kernel Methods" href="https://flecart.github.io/notes/kernel-methods/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Linear Regression methods
    </h2>
  </header>
  <div class="entry-content">
    <p>We will present some methods related to regression methods for data analysis. Some of the work here is from (Hastie et al. 2009). This note does not treat the bayesian case, you should see Bayesian Linear Regression for that.
Problem setting $$ Y = \beta_{0} &#43; \sum_{j = 1}^{d} X_{j}\beta_{j} $$We usually donâ€™t know the distribution of $P(X)$ or $P(Y \mid X)$ so we need to assume something about these distributions.
One approach is assuming the distribution $Y \mid X \sim \mathcal{N}(f(X), \sigma^{2}I)$ and then solve the log likelihood on the probability If we use a statistical learning approach then we know we want to minimize this $\arg \min_{f} \sum_{i = 1}^{n} (y_{i} - f(x_{i}))^{2}$ which is what is often used. Both methods end with the same solution. Usually for these kind of problems we use the Least Squares Method, initially studied in Minimi quadrati. We will describe it again better in this setting. Letâ€™s consider the linear model
...</p>
  </div>
  <footer class="entry-footer">9 min&nbsp;Â·&nbsp;Xuanqiang &#39;Angelo&#39; Huang</footer>
  <a class="entry-link" aria-label="post link to Linear Regression methods" href="https://flecart.github.io/notes/linear-regression-methods/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Markov Processes
    </h2>
  </header>
  <div class="entry-content">
    <p>Andiamo a parlare di processi Markoviani. Dobbiamo avere bene a mente il contenuto di Markov Chains prima di approcciare questo capitolo.
Markov property Uno stato si puÃ² dire di godere della proprietÃ  di Markov se, intuitivamente parlando, possiede giÃ  tutte le informazioni necessarie per predire lo stato successivo, ossia, supponiamo di avere la sequenza di stati $(S_n)_{n \in \mathbb{N}}$, allora si ha che $P(S_k | S_{k-1}) = P(S_k|S_0S_1...S_{k - 1})$, ossia lo stato attuale in $S_{k}$ dipende solamente dallo stato precedente.
...</p>
  </div>
  <footer class="entry-footer">12 min&nbsp;Â·&nbsp;Xuanqiang &#39;Angelo&#39; Huang</footer>
  <a class="entry-link" aria-label="post link to Markov Processes" href="https://flecart.github.io/notes/markov-processes/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Markup
    </h2>
  </header>
  <div class="entry-content">
    <p>Introduzione alle funzioni del markup ðŸŸ© La semantica di una parola Ã¨ caratterizzata dalla mia scelta (design sul significato). Non mi dice molto, quindi proviamo a raccontare qualcosa in piÃ¹.
Definiamo markup ogni mezzo per rendere esplicita una particolare interpretazione di un testo.
In particolare Ã¨ un modo per esplicitare qualche significato. (un poâ€™ come la punteggiatura, che da qualche altra informazione oltre le singole parole, rende piÃ¹ chiaro lâ€™uso del testo).
...</p>
  </div>
  <footer class="entry-footer">8 min&nbsp;Â·&nbsp;Xuanqiang &#39;Angelo&#39; Huang</footer>
  <a class="entry-link" aria-label="post link to Markup" href="https://flecart.github.io/notes/markup/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">On The Double Descent Phenomenon
    </h2>
  </header>
  <div class="entry-content">
    <p>Double descent is a striking phenomenon in modern machine learning that challenges the traditional biasâ€“variance tradeoff. In classical learning theory, increasing model complexity beyond a certain point is expected to increase test error because the model starts to overfit the training data. However, in many contemporary modelsâ€”from simple linear predictors to deep neural networksâ€”a second descent in test error emerges as the model becomes even more overparameterized.
At its core, the double descent curve can be understood in three stages. In the first stage, as the modelâ€™s capacity increases, the error decreases because the model is better able to capture the underlying signal in the data. As the model approaches the interpolation thresholdâ€”where the number of parameters is roughly equal to the number of data pointsâ€”the model fits the training data exactly. This exact fitting, however, makes the model extremely sensitive to noise, leading to a spike in test error. Surprisingly, when the model complexity is increased further into the highly overparameterized regime, the training algorithm (often stochastic gradient descent) tends to select from the many possible interpolating solutions one that exhibits desirable properties such as lower norm or smoothness. This implicit bias toward simpler, more generalizable solutions causes the test error to decrease again, producing the second descent.
...</p>
  </div>
  <footer class="entry-footer">3 min&nbsp;Â·&nbsp;Xuanqiang &#39;Angelo&#39; Huang</footer>
  <a class="entry-link" aria-label="post link to On The Double Descent Phenomenon" href="https://flecart.github.io/notes/on-the-double-descent-phenomenon/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Planning
    </h2>
  </header>
  <div class="entry-content">
    <p>There is huge literature on planning. We will attack this problem from the view of probabilistic artificial intelligence. In this case we focus on continuous, fully observed with non-linear transitions, an environment often used for robotics. Itâ€™s called Model Predictive Control (MPC).
\[...\] Moreover, modeling uncertainty in our model of the environment can be extremely useful in deciding where to explore. Learning a model can therefore help to dramatically reduce the sample complexity over model-free techniques.
...</p>
  </div>
  <footer class="entry-footer">8 min&nbsp;Â·&nbsp;Xuanqiang &#39;Angelo&#39; Huang</footer>
  <a class="entry-link" aria-label="post link to Planning" href="https://flecart.github.io/notes/planning/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Probabilistic Parsing
    </h2>
  </header>
  <div class="entry-content">
    <p>Language Constituents A constituent is a word or a group of words that function as a single unit within a hierarchical structure
This is because there is a lot of evidence pointing towards an hierarchical organization of human language.
Example of constituents Letâ€™s have some examples: John speaks [Spanish] fluently John speaks [Spanish and French] fluently
Mary programs the homework [in the ETH computer laboratory] Mary programs the homework [in the laboratory]
...</p>
  </div>
  <footer class="entry-footer">5 min&nbsp;Â·&nbsp;Xuanqiang &#39;Angelo&#39; Huang</footer>
  <a class="entry-link" aria-label="post link to Probabilistic Parsing" href="https://flecart.github.io/notes/probabilistic-parsing/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Provably Approximately Correct Learning
    </h2>
  </header>
  <div class="entry-content">
    <p>PAC Learning is one of the most famous theories in learning theory. Learning theory concerns in answering questions like:
What is learnable? Somewhat akin to La macchina di Turing for computability theory. How well can you learn something? PAC is a framework that allows to formally answer these questions. Now there is also a bayesian version of PAC in which there is a lot of research. Some definitions Empirical Risk Minimizer and Errors $$ \arg \min_{\hat{c} \in \mathcal{H}} \hat{R}_{n}(\hat{c}) $$ Where the inside is the empirical error.
...</p>
  </div>
  <footer class="entry-footer">11 min&nbsp;Â·&nbsp;Xuanqiang &#39;Angelo&#39; Huang</footer>
  <a class="entry-link" aria-label="post link to Provably Approximately Correct Learning" href="https://flecart.github.io/notes/provably-approximately-correct-learning/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="prev" href="https://flecart.github.io/notes/page/13/">
      Â«&nbsp;Prev&nbsp;13/37
    </a>
    <a class="next" href="https://flecart.github.io/notes/page/15/">Next&nbsp;15/37&nbsp;Â»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
