<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Probabilistic Parsing | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="ðŸ’¬natural-language-processing">
<meta name="description" content="Language Constituents A constituent is a word or a group of words that function as a single unit within a hierarchical structure
This is because there is a lot of evidence pointing towards an hierarchical organization of human language.
Example of constituents Let&rsquo;s have some examples: John speaks [Spanish] fluently John speaks [Spanish and French] fluently
Mary programs the homework [in the ETH computer laboratory] Mary programs the homework [in the laboratory]">
<meta name="author" content="Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/probabilistic-parsing/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/probabilistic-parsing/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>




<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>





<script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-WW6NN2QGKF', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="Probabilistic Parsing" />
<meta property="og:description" content="Language Constituents A constituent is a word or a group of words that function as a single unit within a hierarchical structure
This is because there is a lot of evidence pointing towards an hierarchical organization of human language.
Example of constituents Let&rsquo;s have some examples: John speaks [Spanish] fluently John speaks [Spanish and French] fluently
Mary programs the homework [in the ETH computer laboratory] Mary programs the homework [in the laboratory]" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://flecart.github.io/notes/probabilistic-parsing/" />
<meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png" />
<meta property="article:section" content="notes" />



<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png" />
<meta name="twitter:title" content="Probabilistic Parsing"/>
<meta name="twitter:description" content="Language Constituents A constituent is a word or a group of words that function as a single unit within a hierarchical structure
This is because there is a lot of evidence pointing towards an hierarchical organization of human language.
Example of constituents Let&rsquo;s have some examples: John speaks [Spanish] fluently John speaks [Spanish and French] fluently
Mary programs the homework [in the ETH computer laboratory] Mary programs the homework [in the laboratory]"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Probabilistic Parsing",
      "item": "https://flecart.github.io/notes/probabilistic-parsing/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Probabilistic Parsing",
  "name": "Probabilistic Parsing",
  "description": "Language Constituents A constituent is a word or a group of words that function as a single unit within a hierarchical structure\nThis is because there is a lot of evidence pointing towards an hierarchical organization of human language.\nExample of constituents Let\u0026rsquo;s have some examples: John speaks [Spanish] fluently John speaks [Spanish and French] fluently\nMary programs the homework [in the ETH computer laboratory] Mary programs the homework [in the laboratory]",
  "keywords": [
    "ðŸ’¬natural-language-processing"
  ],
  "articleBody": "Language Constituents A constituent is a word or a group of words that function as a single unit within a hierarchical structure\nThis is because there is a lot of evidence pointing towards an hierarchical organization of human language.\nExample of constituents Letâ€™s have some examples: John speaks [Spanish] fluently John speaks [Spanish and French] fluently\nMary programs the homework [in the ETH computer laboratory] Mary programs the homework [in the laboratory]\nThese sentences can be swapped without problem with each other. These group of words work like a single unit.\nAmbiguity ðŸŸ¨â€“ We expand on the first notions of ambiguity of natural language introduced here. We can see that ambiguous sentences have different constituents. Here is an example: [Fruit flies] [like [a green banana]] or Fruit [flies [like [a green banana]]]\nSources of ambiguity are\nattachment: I [shot [an elephant] [in my pajamas]] vs. I [shot [an elephant [in my pajamas]]] modifier scope [[plastic cup] holder] vs. [plastic [cup holder]] (Is it a holder for plastic cups or a cup holder made of plastic?) Others that are not treated here. Having different parse trees correspond to different consituents! The main idea is to create a probability distribution over possible parse trees, as some are more probable than others, then learn this distribution from data. Binding This is the analogous for natural language. We have studied these in many different settings: analysis of programming languages Nomi e Scope, logic Logica del Primo ordine and operative systems Paginazione e segmentazione. TODO: explain in the context of natural languages.\nContext-Free Grammar extensions We first introduced context free in these documents Descrizione linguaggio and Linguaggi liberi e PDA. Here we expand on a probabilistic version to model the likeliness of a given parse of an ambiguous structure.\nProbabilistic Context-Free Grammars The easiest way to extend this is to assign a probability to each production. After we have this, then the probability of a given three is just the product of all the production probabilities. This is a easy and natural way to extend the classic notion of derivation trees.\nPCFG are Locally Normalized This is easy because given some production rules $N \\to \\alpha_{1}, \\dots N \\to \\alpha_{n}$ we have that $$ \\sum_{k = 1}^{K} p(\\alpha_{k} \\mid N) = 1 $$ Which mean for a single non-terminal, we would like that the sum of the probabilities of the productions is one, i.e. it is not leaked elsewhere. This is the same idea presented in Language Models.\nWeighted CFGs Instead of assigning a probability, we just add a weight to each of the production. In this case, what is important is the relative weight of the productions. Then we can use the same idea in Log Linear Models to put them back into a probability space. This is easier as we just need to assign a score over the productions, and not a probability. WCFGs are Globally Normalized WCFGs are structured Softmax Function because given a tree $t$ we have that\n$$ p(t) = \\frac{1}{Z} \\prod_{r \\in t} \\exp[\\text{(score}(r)] $$ The difficult thing here is to compute the normalizing constant because $\\mathcal{T}$ can be infinite: $$ Z = \\sum_{t' \\in \\mathcal{T}} \\prod_{r \\in t'}\\exp[\\text{(score}(r)] $$ For some grammars the normalizer could also diverge For example with the grammar $\\left\\{ S \\to S, S \\to a \\right\\}$ has infinite derivations of the same string $a$, but there are infinite ones.\nNormalized Grammars We solve this problem by converting the grammar into a Chomsky Normal Form (see Semplificazione grammatiche#Chomsky Normal Form). In this case the number of possible trees is no longer infinite, but around $\\mathcal{O}(4^{n})$, which is the number of rooted binary trees, which follows Catalan Numbers for some reason unknown to me. We lose the original structure of our tree but we gain on the possibility of computing the normalizer.\nIn this manner we can compute the probability of having a certain parse tree $t$, given a sentence $s$ as follows: $$ p(t \\mid s) = \\frac{1}{Z(s)} \\prod_{X \\to Y Z \\in t} \\exp(\\text{score}(X \\to Y Z)) \\cdot \\prod_{X \\to a \\in t} \\exp(\\text{score}(X \\to a)) $$ We have effectively splitted the score in two parts, one for the non-terminal and one for the terminal. The normalizer is just the sum over all possible trees for a given sentence. $$ Z(s) = \\sum_{t' \\in \\mathcal{T}(s)} \\prod_{X \\to Y Z \\in t'} \\exp(\\text{score}(X \\to Y Z)) \\cdot \\prod_{X \\to a \\in t'} \\exp(\\text{score}(X \\to a)) $$ The CKY parser Introduction to CKY The Cockeâ€“Kasamiâ€“Younger Algorithm provides an efficient way to compute the normalizer for a CNF grammar, in $\\mathcal{O}(n^{3} \\lvert \\mathcal{R} \\rvert)$, with $n$ length of our sentence and $\\lvert \\mathcal{R} \\rvert$ size of the rule-set of the CNF. Originally this algorithm has been developed for a classical recognition problem: given a string, recognize if the grammar accepts it. Goodman wrote a paper generalizing the algorithm to arbitrary semirings. Humans parse in linear time usually perhaps: they donâ€™t need to rehearse and go back in the string. There could be local patches where humans are non-linear (i.e. they go back and try to make sense of it), but mostly a\nSee wikipedia for the pseudocode of the algorithm.\nThe Algorithm This is another dynamic programming algorithm. Originally, it has been used to compute the normalizer for a WCFG, but then it has been generalized by Goodman (1999) to arbitrary semirings. This allows to compute different things like\nBest parse tree Entropy of parse tree distribution Normalizing constant (its the case we are interested in) Letâ€™s analyze this algorithm in detail. We need a WCFG, a score function for each production rule, and a sentence $s$ for which we want to compute the normalizer for the parsing trees. We first initialize the base of our dynamic programming table with the scores of the terminal rules. Then we iterate over the length of the sentence, and for each cell we iterate over the possible splits of the sentence in two parts, and we check if the two parts can be generated by the non-terminal $X$ in a span (a contiguous substring). If they can, then we add the score of the rule $X \\to Y Z$ to the score of the cell. This algorithm can be visualized in the following diagram: It is a little weird for the count starts, but other than that it is quite intuitive.\n",
  "wordCount" : "1061",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/probabilistic-parsing/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;Â»&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Probabilistic Parsing
    </h1>
    <div class="post-meta">5 min&nbsp;Â·&nbsp;Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul>
                <li>
                    <a href="#language-constituents" aria-label="Language Constituents">Language Constituents</a><ul>
                        
                <li>
                    <a href="#example-of-constituents" aria-label="Example of constituents">Example of constituents</a></li>
                <li>
                    <a href="#ambiguity---" aria-label="Ambiguity ðŸŸ¨&ndash;">Ambiguity ðŸŸ¨&ndash;</a></li>
                <li>
                    <a href="#binding" aria-label="Binding">Binding</a></li></ul>
                </li></ul>
                    
                <li>
                    <a href="#context-free-grammar-extensions" aria-label="Context-Free Grammar extensions">Context-Free Grammar extensions</a><ul>
                        
                <li>
                    <a href="#probabilistic-context-free-grammars" aria-label="Probabilistic Context-Free Grammars">Probabilistic Context-Free Grammars</a><ul>
                        
                <li>
                    <a href="#pcfg-are-locally-normalized" aria-label="PCFG are Locally Normalized">PCFG are Locally Normalized</a></li></ul>
                </li>
                <li>
                    <a href="#weighted-cfgs" aria-label="Weighted CFGs">Weighted CFGs</a><ul>
                        
                <li>
                    <a href="#wcfgs-are-globally-normalized" aria-label="WCFGs are Globally Normalized">WCFGs are Globally Normalized</a></li>
                <li>
                    <a href="#normalized-grammars" aria-label="Normalized Grammars">Normalized Grammars</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#the-cky-parser" aria-label="The CKY parser">The CKY parser</a><ul>
                        <ul>
                        
                <li>
                    <a href="#introduction-to-cky" aria-label="Introduction to CKY">Introduction to CKY</a></li>
                <li>
                    <a href="#the-algorithm" aria-label="The Algorithm">The Algorithm</a>
                </li>
            </ul>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="language-constituents">Language Constituents<a hidden class="anchor" aria-hidden="true" href="#language-constituents">#</a></h3>
<blockquote>
<p>A constituent is a word or a group of words that function as a single unit within a
hierarchical structure</p>
</blockquote>
<p>This is because there is a lot of evidence pointing towards an hierarchical organization of human language.</p>
<h4 id="example-of-constituents">Example of constituents<a hidden class="anchor" aria-hidden="true" href="#example-of-constituents">#</a></h4>
<p>Let&rsquo;s have some examples:
John speaks [Spanish] fluently
John speaks [Spanish and French] fluently</p>
<p>Mary programs the homework [in the ETH computer laboratory]
Mary programs the homework [in the laboratory]</p>
<p>These sentences can be swapped without problem with each other. These group of words work like a single unit.</p>
<h4 id="ambiguity---">Ambiguity ðŸŸ¨&ndash;<a hidden class="anchor" aria-hidden="true" href="#ambiguity---">#</a></h4>
<p>We expand on the first notions of ambiguity of natural language introduced <a href="/notes/logica-meta-linguistica/#paradosso">here</a>.
We can see that ambiguous sentences have different constituents.
Here is an example: [Fruit flies] [like [a green banana]] or Fruit [flies [like [a green banana]]]</p>
<p>Sources of ambiguity are</p>
<ul>
<li><strong>attachment</strong>: I [shot [an elephant] [in my pajamas]] vs. I [shot [an elephant [in my pajamas]]]</li>
<li><strong>modifier scope</strong> [[plastic cup] holder] vs. [plastic [cup holder]] (Is it a holder for plastic cups or a cup holder made of plastic?)</li>
<li>Others that are not treated here.
Having different parse trees correspond to different consituents! The main idea is to create a probability distribution over possible parse trees, as some are more probable than others, then learn this distribution from data.</li>
</ul>
<h4 id="binding">Binding<a hidden class="anchor" aria-hidden="true" href="#binding">#</a></h4>
<p>This is the analogous for natural language. We have studied these in many different settings: analysis of programming languages <a href="/notes/nomi-e-scope/">Nomi e Scope</a>, logic <a href="/notes/logica-del-primo-ordine/">Logica del Primo ordine</a> and operative systems <a href="/notes/paginazione-e-segmentazione/">Paginazione e segmentazione</a>.
TODO: explain in the context of natural languages.</p>
<h2 id="context-free-grammar-extensions">Context-Free Grammar extensions<a hidden class="anchor" aria-hidden="true" href="#context-free-grammar-extensions">#</a></h2>
<p>We first introduced context free in these documents <a href="/notes/descrizione-linguaggio/">Descrizione linguaggio</a> and <a href="/notes/linguaggi-liberi-e-pda/">Linguaggi liberi e PDA</a>.
Here we expand on a probabilistic version to model the <em>likeliness</em> of a given parse of an ambiguous structure.</p>
<h3 id="probabilistic-context-free-grammars">Probabilistic Context-Free Grammars<a hidden class="anchor" aria-hidden="true" href="#probabilistic-context-free-grammars">#</a></h3>
<p>The easiest way to extend this is to <strong>assign a probability to each production</strong>. After we have this, then the probability of a given three is just the product of all the production probabilities. This is a easy and natural way to extend the classic notion of derivation trees.</p>
<img src="/images/notes/Probabilistic Parsing-20241010122154169.webp" alt="Probabilistic Parsing-20241010122154169">
<h4 id="pcfg-are-locally-normalized">PCFG are Locally Normalized<a hidden class="anchor" aria-hidden="true" href="#pcfg-are-locally-normalized">#</a></h4>
<p>This is easy because given some production rules $N \to \alpha_{1}, \dots N \to \alpha_{n}$ we have that
</p>
$$
\sum_{k = 1}^{K} p(\alpha_{k} \mid N) = 1
$$
<p>
Which mean for a single non-terminal, we would like that the sum of the probabilities of the productions is one, i.e. it is not leaked elsewhere. This is the same idea presented in <a href="/notes/language-models/">Language Models</a>.</p>
<h3 id="weighted-cfgs">Weighted CFGs<a hidden class="anchor" aria-hidden="true" href="#weighted-cfgs">#</a></h3>
<p>Instead of assigning a probability, we just add a weight to each of the production. In this case, what is important is the relative weight of the productions.
Then we can use the same idea in <a href="/notes/log-linear-models/">Log Linear Models</a> to put them back into a probability space. This is easier as we just need to assign a <strong>score</strong> over the productions, and not a probability.
<img src="/images/notes/Probabilistic Parsing-20241010122402072.webp" alt="Probabilistic Parsing-20241010122402072"></p>
<h4 id="wcfgs-are-globally-normalized">WCFGs are Globally Normalized<a hidden class="anchor" aria-hidden="true" href="#wcfgs-are-globally-normalized">#</a></h4>
<p>WCFGs are <strong>structured <a href="/notes/softmax-function/">Softmax Function</a></strong> because given a tree $t$ we have that<br>
</p>
$$
p(t) = \frac{1}{Z} \prod_{r \in t} \exp[\text{(score}(r)]
$$
<p>The difficult thing here is to compute the <strong>normalizing constant</strong> because $\mathcal{T}$ can be infinite:
</p>
$$
Z = \sum_{t' \in \mathcal{T}} \prod_{r \in t'}\exp[\text{(score}(r)]
$$
<p>
For some grammars the normalizer could also diverge
For example with the grammar $\left\{ S \to S, S \to a \right\}$ has infinite derivations of the same string $a$, but there are infinite ones.</p>
<h4 id="normalized-grammars">Normalized Grammars<a hidden class="anchor" aria-hidden="true" href="#normalized-grammars">#</a></h4>
<p>We solve this problem by converting the grammar into a Chomsky Normal Form (see <a href="/notes/semplificazione-grammatiche/#chomsky-normal-form">Semplificazione grammatiche#Chomsky Normal Form</a>).
In this case the number of possible trees is no longer infinite, but around $\mathcal{O}(4^{n})$, which is the number of rooted binary trees, which follows Catalan Numbers for some reason unknown to me.
We lose the original structure of our tree but we gain on the possibility of computing the normalizer.</p>
<p>In this manner we can compute the probability of having a certain parse tree $t$, given a sentence $s$ as follows:
</p>
$$
p(t \mid s) = \frac{1}{Z(s)} \prod_{X \to Y Z \in t} \exp(\text{score}(X \to Y Z)) \cdot \prod_{X \to a \in t} \exp(\text{score}(X \to a))
$$
<p>
We have effectively splitted the score in two parts, one for the non-terminal and one for the terminal.
The normalizer is just the sum over all possible trees for a given sentence.
</p>
$$
Z(s) = \sum_{t' \in \mathcal{T}(s)} \prod_{X \to Y Z \in t'} \exp(\text{score}(X \to Y Z)) \cdot \prod_{X \to a \in t'} \exp(\text{score}(X \to a))
$$
<h2 id="the-cky-parser">The CKY parser<a hidden class="anchor" aria-hidden="true" href="#the-cky-parser">#</a></h2>
<h4 id="introduction-to-cky">Introduction to CKY<a hidden class="anchor" aria-hidden="true" href="#introduction-to-cky">#</a></h4>
<p>The Cockeâ€“Kasamiâ€“Younger Algorithm provides an efficient way to compute the normalizer for a CNF grammar, in $\mathcal{O}(n^{3} \lvert \mathcal{R} \rvert)$, with $n$ length of our sentence and $\lvert \mathcal{R} \rvert$ size of the rule-set of the CNF.
Originally this algorithm has been developed for a classical recognition problem: given a string, recognize if the grammar accepts it.
Goodman wrote a paper generalizing the algorithm to arbitrary semirings.
Humans parse in linear time usually perhaps: they don&rsquo;t need to rehearse and go back in the string. There could be <strong>local patches</strong> where humans are non-linear (i.e. they go back and try to make sense of it), but mostly a</p>
<p>See <a href="https://en.wikipedia.org/wiki/CYK_algorithm">wikipedia</a> for the pseudocode of the algorithm.</p>
<h4 id="the-algorithm">The Algorithm<a hidden class="anchor" aria-hidden="true" href="#the-algorithm">#</a></h4>
<p>This is another dynamic programming algorithm. Originally, it has been used to compute the normalizer for a WCFG, but then it has been generalized by Goodman (1999)  to arbitrary semirings. This allows to compute different things like</p>
<ul>
<li>Best parse tree</li>
<li>Entropy of parse tree distribution</li>
<li>Normalizing constant (its the case we are interested in)
<img src="/images/notes/Probabilistic Parsing-20241108155517538.webp" alt="Probabilistic Parsing-20241108155517538">
Let&rsquo;s analyze this algorithm in detail.
We need a WCFG, a score function for each production rule, and a sentence $s$ for which we want to compute the normalizer for the parsing trees.
We first initialize the base of our dynamic programming table with the scores of the terminal rules.
Then we iterate over the length of the sentence, and for each cell we iterate over the possible splits of the sentence in two parts, and we check if the two parts can be generated by the non-terminal $X$ in a span (a contiguous substring). If they can, then we add the score of the rule $X \to Y Z$ to the score of the cell.</li>
</ul>
<p>This algorithm can be visualized in the following diagram:
<img src="/images/notes/Probabilistic Parsing-20241108161431309.webp" alt="Probabilistic Parsing-20241108161431309">
It is a little weird for the count starts, but other than that it is quite intuitive.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://flecart.github.io/tags/natural-language-processing/">ðŸ’¬Natural-Language-Processing</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Probabilistic Parsing on x"
            href="https://x.com/intent/tweet/?text=Probabilistic%20Parsing&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fprobabilistic-parsing%2f&amp;hashtags=%f0%9f%92%acnatural-language-processing">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Probabilistic Parsing on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fprobabilistic-parsing%2f&amp;title=Probabilistic%20Parsing&amp;summary=Probabilistic%20Parsing&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2fprobabilistic-parsing%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Probabilistic Parsing on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2fprobabilistic-parsing%2f&title=Probabilistic%20Parsing">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Probabilistic Parsing on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2fprobabilistic-parsing%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Probabilistic Parsing on whatsapp"
            href="https://api.whatsapp.com/send?text=Probabilistic%20Parsing%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2fprobabilistic-parsing%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Probabilistic Parsing on telegram"
            href="https://telegram.me/share/url?text=Probabilistic%20Parsing&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fprobabilistic-parsing%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Probabilistic Parsing on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Probabilistic%20Parsing&u=https%3a%2f%2fflecart.github.io%2fnotes%2fprobabilistic-parsing%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
