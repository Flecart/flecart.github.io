<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Neural Networks | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="🥘deep-learning, machine-perception">
<meta name="description" content="Introduction: a neuron
I am lazy, so I&rsquo;m skipping the introduction for this set of notes. Look at Andrew Ng&rsquo;s Coursera course for this part (here are the notes). Historical paper is (Rosenblatt 1958).
One can view a perceptron to be a Log Linear Models with the temperature of the softmax that goes to 0 (so that it is an argmax).
Trained with a stochastic gradient descent with a batch of 1 (this is called the perceptron update rule, see The Perceptron Model).">
<meta name="author" content="Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/neural-networks/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/neural-networks/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>






      <script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-WW6NN2QGKF');
        }
      </script><meta property="og:url" content="https://flecart.github.io/notes/neural-networks/">
  <meta property="og:site_name" content="X. Angelo Huang&#39;s Blog">
  <meta property="og:title" content="Neural Networks">
  <meta property="og:description" content="Introduction: a neuron I am lazy, so I’m skipping the introduction for this set of notes. Look at Andrew Ng’s Coursera course for this part (here are the notes). Historical paper is (Rosenblatt 1958). One can view a perceptron to be a Log Linear Models with the temperature of the softmax that goes to 0 (so that it is an argmax). Trained with a stochastic gradient descent with a batch of 1 (this is called the perceptron update rule, see The Perceptron Model).">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="notes">
    <meta property="article:tag" content="🥘Deep-Learning">
    <meta property="article:tag" content="Machine-Perception">
      <meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:title" content="Neural Networks">
<meta name="twitter:description" content="Introduction: a neuron
I am lazy, so I&rsquo;m skipping the introduction for this set of notes. Look at Andrew Ng&rsquo;s Coursera course for this part (here are the notes). Historical paper is (Rosenblatt 1958).
One can view a perceptron to be a Log Linear Models with the temperature of the softmax that goes to 0 (so that it is an argmax).
Trained with a stochastic gradient descent with a batch of 1 (this is called the perceptron update rule, see The Perceptron Model).">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Neural Networks",
      "item": "https://flecart.github.io/notes/neural-networks/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Neural Networks",
  "name": "Neural Networks",
  "description": "Introduction: a neuron I am lazy, so I\u0026rsquo;m skipping the introduction for this set of notes. Look at Andrew Ng\u0026rsquo;s Coursera course for this part (here are the notes). Historical paper is (Rosenblatt 1958). One can view a perceptron to be a Log Linear Models with the temperature of the softmax that goes to 0 (so that it is an argmax). Trained with a stochastic gradient descent with a batch of 1 (this is called the perceptron update rule, see The Perceptron Model).\n",
  "keywords": [
    "🥘deep-learning", "machine-perception"
  ],
  "articleBody": "Introduction: a neuron I am lazy, so I’m skipping the introduction for this set of notes. Look at Andrew Ng’s Coursera course for this part (here are the notes). Historical paper is (Rosenblatt 1958). One can view a perceptron to be a Log Linear Models with the temperature of the softmax that goes to 0 (so that it is an argmax). Trained with a stochastic gradient descent with a batch of 1 (this is called the perceptron update rule, see The Perceptron Model).\nStructure of a neuron Artificial neurons, though inspired by biological neurons (see The Neuron), are not exact replicas. There are key differences:\nBiological neurons encode time information between their spikes. They do not spike in a forward clean order, but have recurrent feedbacks that in ANN often are not modelled. They are a lot more energy efficient compared to ANN. Mathematical description A single layer of a function can be written in the following way:\n$$ F(\\theta)(x) = \\phi(Wx + b) $$ Which can be summarized by: linear part + activation function. Where $F(\\theta)$ is a partial function that returns another function, $\\theta = (W, b)$ a vector, this is just a way to separate the bias with the parameters. The $\\phi$ is the non linearity, that is needed for the universal approximation function.\nCompositionality The main idea in going deep is extract features of increasing complexity, it’s like attempting to give it more computation so that it is possible to extract more interesting parts. We can mathematically view deep networks in the following way:\n$$ x = F^{(l)} F^{(l - 1)} \\dots F^{(0)}(x_{0}) $$ And a composition of layers!\nModularity We can compose parts of the network together! For example residual networks are a clear example, or the inception network.\nUniversal approximation theorem This theorem states that neural networks can approximate any continuous function to arbitrary precision. The idea is just using a single layer with a non-linear activation function to write level sets. The proof is here (Hornik et al. 1989). This is a nice interactive website that proves it: here.\nMore formally: Let $\\sigma: \\mathbb{R} \\rightarrow \\mathbb{R}$ be a non-constant, bounded and continuous (activation) function $I_m$ denotes the $m$-dimensional unit hypercube $[0,1]^m$ and the space of real-valued functions on $I_m$ is denoted with $C(I_m)$.\nThen any function $f \\in C(I_m)$ can be approximated given any $\\epsilon \u003e 0$, integer $N$, real constants $v_i, b_i \\in \\mathbb{R}$ and real vectors $\\mathbf{w}_i \\in \\mathbb{R}^m$ for $i = 1, \\dots, N$:\n$$ f(\\mathbf{x}) \\approx g(\\mathbf{x}) = \\sum_{i=1}^{N} v_i \\sigma(\\mathbf{w}_i^T \\mathbf{x} + b_i) $$And: $|g(\\mathbf{x}) - f(\\mathbf{x})| \u003c \\epsilon$ , for all $\\mathbf{x} \\in I_m$\nHopfield Networks Hopfield networks are a type of recurrent neural network that can store and retrieve patterns. They are particularly useful for associative memory tasks, where the network can recall a stored pattern given a noisy or partial input.\nThe Hopfield Network Model $$ \\Theta = \\sum_{i = 1}^{s} \\left[ x_{t}x_{t}^{T} - \\boldsymbol{I}_{n} \\right] $$ One can prove that this matrix is symmetric, and that it is irreflexive (meaning $\\forall j: \\Theta_{jj} = 0$).\nThe update Rule The state of each neuron can be either 0 or 1, and the network evolves over time according to the following update rule:\n$$ x_{t + 1} = \\begin{cases} \\text{sign}(\\Theta x_{t}) \u0026 \\text{ if } \\Theta x_{t} \\neq 0 \\\\ x_{t} \u0026 \\text{ if } \\Theta x_{t} = 0 \\end{cases} $$Training network tricks Activation functions Solitamente le funzioni classiche per i network neurali sono sigmoid, tanh, e ReLU. La cosa brutta delle prime due è vanishing gradient, perché se il valore è molto grosso o molto piccolo, la derivata è molto vicino allo 0, quindi è molto difficile aggiornare.\nThe activation function is presented as $\\phi$ before. One thing to note is that this non-linearity doesn’t mix the dimensions together. Let me explain clearly with some maths:\nWe say that $\\phi: \\mathbb{R}^{n} \\to \\mathbb{R}^{n}$ and it’s a composition of some $\\bar{\\phi}: \\mathbb{R} \\to \\mathbb{R}$ which are just applied independently to every dimension.\nOther properties are:\nIncreasing Continuous There are important to remember from a mathematical point of view. Level Sets $$ L_{f}(z) = \\left\\{ x : \\phi(w\\cdot x + \\beta) = z \\right\\} \\perp w $$ These are also called generalized linear models, or ridge functions.\nReLU activation $$ f(x) = \\begin{cases} 0,\\, \\text{ if } x \u003c 0 \\\\ x, \\, \\text{ if } x \\geq 0 \\end{cases} $$The important thing to notice is that when it backpropagates, it just activates or kills the signal, allowing the gradient to flow naturally, and not vanish.\n$$ \\frac{ \\partial x^{(k+1)} }{ \\partial x^{(k)} } = \\sigma'(W^{(k)}x^{(k)} + b) W^{(k)} $$ And $\\sigma'$ in the case of the ReLU is just 0 or 1, which aids toward the problem of vanishing gradient and similars. The thing to note is that this doesn’t exactly work as an activation function if the input depends on $x$ with more than one parameter\nHyperbolic tangent This activation is usually preferred to the Sigmoid, better treated in Logistic Regression, because it has sign symmetry.\nImportance of Non linearity The main reason we need non linearity is that we want to be able to learn complex functions, and this is not possible with a linear function. We can see this by the fact that a composition of linear functions is still a linear function.\nLet’s analyze the topic mathematically: Suppose you have input data $x \\in \\mathbb{R}^{n}$ and a function $\\sigma : \\mathbb{R}^{n} \\to \\mathbb{R}^{n}: \\sigma(x) = \\alpha x + \\beta$, the problem is the if you nest layers: $\\forall l \\in \\left[ 1, L \\right], x^{[l]} = \\alpha(W^{[l]} x^{l - 1}] + b^{[l]}) + \\beta$ which is just another affine mapping. This means all the layers are the same as if I used a single layer. Using Kernel Methods could help in this case, but it often needs feature engineering which is done by humans.\nOptimization Momentum, praticamente un gradient descent che tiene conto delle computazioni passate, e calcola la direzione anche secondo quelle (quindi se vado su e giù e a destra sempre nelle iterazioni passate, andrò a destra più spesso diciamo, questa è l’intuizione per questa idea).\nUna cosa molto strana è che il training delle NN è molto stabile. Cioè vari un pò l’input e non varia molto l’ouput!\nPossibili motivi:\nWeights Loss function Internal redundancy? cioè ho troppi parametri e questo lo rende bello.(teoria del prof) Loss functions $$ \\mathcal{l}(y, \\hat{y}) = \\frac{1}{2} \\lVert y - \\hat{y} \\rVert ^{2} $$$$ l(\\theta)(x, y) = l(y, F(\\theta)(x)) $$Sometimes you need to tailor the loss function to the problem you are trying to solve! For example a very famous function is the Softmax Function, for multiclass classification. In the case you just have two classes then it’s the logistic function.\n$$ l(y, \\hat{p}) = - \\log \\hat{p}_{y} $$ If we view this from an information theoretical point of view, then it’s the expected length of our codeword.\nRisks After we have the loss we can go on and define the empirical risk, which is just:\n$$ \\mathcal{R}(\\theta; \\mathcal{S}) := \\mathbb{E}_{\\mathcal{S}} [\\ell(\\theta)] := \\frac{1}{s} \\sum_{i = 1}^{s} \\ell(\\theta)(x_{i}, y_{i}) = \\frac{1}{s} \\sum_{i = 1}^{s} \\ell(y_{i}, F(\\theta)(x_{i})) $$This is the training risk, and same thing could be defined for the test risk.\nQuirks of Neural Networks This section presents some counter-intuitive phenomena that pertain neural networks. Classical theories predict opposite behaviours compared the ones we list here.\nGrokking Grokking refers to the phenomenon where a neural network initially exhibits poor generalization despite achieving low training loss, but after extended training, it suddenly generalizes well without any further changes to the dataset or training procedure. This phenomenon was first observed in algorithmic tasks, where models would first memorize the training data before gradually developing a more structured, generalizable understanding.\nThis delayed phase transition challenges conventional notions of overfitting and suggests that prolonged training on sufficiently large datasets can sometimes lead to emergent generalization. A possible explanation is that neural networks first fit simpler patterns before refining their internal representations to capture deeper structure.\nDouble Descent The double descent phenomenon describes a peculiar behavior in the generalization performance of neural networks as model capacity increases. Unlike classical machine learning theory, which suggests that increasing model complexity leads to overfitting beyond a certain point, double descent reveals a second improvement in generalization performance at very high capacity.\nThis behavior is characterized by two distinct regions:\nClassical Bias-Variance Tradeoff: In the underparameterized regime, increasing model complexity improves performance until it reaches the interpolation threshold, where it perfectly fits the training data but generalizes poorly. Modern Overparameterization: Beyond this interpolation threshold, further increasing model capacity counterintuitively leads to improved generalization. Neural networks often enter this second descent phase, where overfitting seems to subside, and test performance improves. The authors define a measure of Effective Model Complexity (EMC) as the maximum number of samples that can be memorized by the model, and make an analysis with this. They show that in some specific cases it hurts to have more data, as more data shifts the critical regime to the right.\nLabel Memorization Neural networks have a remarkable capacity to memorize training data, even when the labels are randomized. Studies show that deep models can fit arbitrary labels, suggesting that memorization is an inherent property rather than a failure of training. However, memorization does not necessarily contradict generalization: modern deep networks balance memorization with pattern recognition.\nAll the models overfit, doesn't matter what model you use, you learn random noise.\nKey insights into label memorization include:\nMemorization is a function of dataset size and model capacity: Larger networks can store training examples verbatim, but this does not always harm test accuracy, particularly in large-scale training scenarios. Memorization and generalization can coexist: Empirical results suggest that networks first learn patterns present in the data before resorting to memorization for harder examples. References [1] Rosenblatt “The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain.” None 1958 [2] Hornik et al. “Multilayer Feedforward Networks Are Universal Approximators” Neural Networks Vol. 2(5), pp. 359--366 1989 ",
  "wordCount" : "1674",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/neural-networks/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Neural Networks
    </h1>
    <div class="post-meta">8 min&nbsp;·&nbsp;Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul>
                <li>
                    <a href="#introduction-a-neuron" aria-label="Introduction: a neuron">Introduction: a neuron</a><ul>
                        
                <li>
                    <a href="#structure-of-a-neuron" aria-label="Structure of a neuron">Structure of a neuron</a><ul>
                        
                <li>
                    <a href="#mathematical-description" aria-label="Mathematical description">Mathematical description</a></li>
                <li>
                    <a href="#compositionality" aria-label="Compositionality">Compositionality</a></li>
                <li>
                    <a href="#modularity" aria-label="Modularity">Modularity</a></li>
                <li>
                    <a href="#universal-approximation-theorem" aria-label="Universal approximation theorem">Universal approximation theorem</a></li></ul>
                </li>
                <li>
                    <a href="#hopfield-networks" aria-label="Hopfield Networks">Hopfield Networks</a><ul>
                        
                <li>
                    <a href="#the-hopfield-network-model" aria-label="The Hopfield Network Model">The Hopfield Network Model</a></li>
                <li>
                    <a href="#the-update-rule" aria-label="The update Rule">The update Rule</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#training-network-tricks" aria-label="Training network tricks">Training network tricks</a><ul>
                        
                <li>
                    <a href="#activation-functions" aria-label="Activation functions">Activation functions</a><ul>
                        
                <li>
                    <a href="#level-sets" aria-label="Level Sets">Level Sets</a></li>
                <li>
                    <a href="#relu-activation" aria-label="ReLU activation">ReLU activation</a></li>
                <li>
                    <a href="#hyperbolic-tangent" aria-label="Hyperbolic tangent">Hyperbolic tangent</a></li>
                <li>
                    <a href="#importance-of-non-linearity" aria-label="Importance of Non linearity">Importance of Non linearity</a></li></ul>
                </li>
                <li>
                    <a href="#optimization" aria-label="Optimization">Optimization</a><ul>
                        
                <li>
                    <a href="#loss-functions" aria-label="Loss functions">Loss functions</a></li>
                <li>
                    <a href="#risks" aria-label="Risks">Risks</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#quirks-of-neural-networks" aria-label="Quirks of Neural Networks">Quirks of Neural Networks</a><ul>
                        <ul>
                        
                <li>
                    <a href="#grokking" aria-label="Grokking">Grokking</a></li>
                <li>
                    <a href="#double-descent" aria-label="Double Descent">Double Descent</a></li>
                <li>
                    <a href="#label-memorization" aria-label="Label Memorization">Label Memorization</a></li></ul>
                    </ul>
                </li></ul>
                    
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="introduction-a-neuron">Introduction: a neuron<a hidden class="anchor" aria-hidden="true" href="#introduction-a-neuron">#</a></h2>
<p>I am lazy, so I&rsquo;m skipping the introduction for this set of notes. Look at Andrew Ng&rsquo;s Coursera course for this part (<a href="https://cs229.stanford.edu/main_notes.pdf">here</a> are the notes). Historical paper is <a href="https://psycnet.apa.org/record/1959-09865-001">(Rosenblatt 1958)</a>.
One can view a perceptron to be a <a href="/notes/log-linear-models">Log Linear Models</a> with the temperature of the softmax that goes to 0 (so that it is an argmax).
Trained with a stochastic gradient descent with a batch of 1 (this is called the perceptron update rule, see <a href="/notes/the-perceptron-model">The Perceptron Model</a>).</p>
<h3 id="structure-of-a-neuron">Structure of a neuron<a hidden class="anchor" aria-hidden="true" href="#structure-of-a-neuron">#</a></h3>
<p>Artificial neurons, though inspired by biological neurons (see <a href="/notes/the-neuron">The Neuron</a>), are not exact replicas.
There are key differences:</p>
<ul>
<li>Biological neurons encode time information between their spikes.</li>
<li>They do not spike in a forward clean order, but have recurrent feedbacks that in ANN often are not modelled.</li>
<li>They are a lot more energy efficient compared to ANN.</li>
</ul>
<h4 id="mathematical-description">Mathematical description<a hidden class="anchor" aria-hidden="true" href="#mathematical-description">#</a></h4>
<p>A single layer of a function can be written in the following way:</p>
$$
F(\theta)(x) = \phi(Wx + b)
$$<p>
Which can be summarized by: <strong>linear part + activation function</strong>.
Where $F(\theta)$ is a partial function that returns another function, $\theta = (W, b)$ a vector, this is just a way to separate the bias with the parameters. The $\phi$ is the non linearity, that is needed for the universal approximation function.</p>
<h4 id="compositionality">Compositionality<a hidden class="anchor" aria-hidden="true" href="#compositionality">#</a></h4>
<p>The main idea in going deep is <strong>extract features of increasing complexity</strong>, it&rsquo;s like attempting to give it more computation so that it is possible to extract more interesting parts. We can mathematically view deep networks in the following way:</p>
$$
x = F^{(l)} F^{(l - 1)} \dots F^{(0)}(x_{0})
$$<p>
And a composition of layers!</p>
<h4 id="modularity">Modularity<a hidden class="anchor" aria-hidden="true" href="#modularity">#</a></h4>
<p>We can compose parts of the network together! For example residual networks are a clear example, or the inception network.</p>
<h4 id="universal-approximation-theorem">Universal approximation theorem<a hidden class="anchor" aria-hidden="true" href="#universal-approximation-theorem">#</a></h4>
<p>This theorem states that neural networks can approximate any <strong>continuous function</strong> to arbitrary precision. The idea is just using a single layer with a non-linear activation function to write level sets.
The proof is here <a href="https://www.sciencedirect.com/science/article/pii/0893608089900208">(Hornik et al. 1989)</a>.
This is a nice interactive website that proves it: <a href="http://neuralnetworksanddeeplearning.com/chap4.html">here</a>.</p>
<p><strong>More formally</strong>:
Let $\sigma: \mathbb{R} \rightarrow \mathbb{R}$ be a non-constant, bounded and continuous (activation) function
$I_m$ denotes the $m$-dimensional unit hypercube $[0,1]^m$ and the space of real-valued functions on $I_m$ is denoted with $C(I_m)$.</p>
<p>Then any function $f \in C(I_m)$ can be approximated given any $\epsilon > 0$, integer $N$, real constants $v_i, b_i \in \mathbb{R}$ and real vectors $\mathbf{w}_i \in \mathbb{R}^m$ for $i = 1, \dots, N$:</p>
$$
f(\mathbf{x}) \approx g(\mathbf{x}) = \sum_{i=1}^{N} v_i \sigma(\mathbf{w}_i^T \mathbf{x} + b_i)
$$<p>And: $|g(\mathbf{x}) - f(\mathbf{x})| < \epsilon$ , for all $\mathbf{x} \in I_m$</p>
<h3 id="hopfield-networks">Hopfield Networks<a hidden class="anchor" aria-hidden="true" href="#hopfield-networks">#</a></h3>
<p>Hopfield networks are a type of recurrent neural network that can store and retrieve patterns. They are particularly useful for associative memory tasks, where the network can recall a stored pattern given a noisy or partial input.</p>
<h4 id="the-hopfield-network-model">The Hopfield Network Model<a hidden class="anchor" aria-hidden="true" href="#the-hopfield-network-model">#</a></h4>
$$
\Theta = \sum_{i = 1}^{s} \left[ x_{t}x_{t}^{T} - \boldsymbol{I}_{n} \right] 
$$<p>
One can prove that this matrix is symmetric, and that it is irreflexive (meaning $\forall j: \Theta_{jj} = 0$).</p>
<h4 id="the-update-rule">The update Rule<a hidden class="anchor" aria-hidden="true" href="#the-update-rule">#</a></h4>
<p>The state of each neuron can be either 0 or 1, and the network evolves over time according to the following update rule:</p>
$$
x_{t + 1} = 
\begin{cases}
\text{sign}(\Theta x_{t}) & \text{ if } \Theta x_{t} \neq 0 \\ 
x_{t} & \text{ if } \Theta x_{t} = 0
\end{cases}
$$<h2 id="training-network-tricks">Training network tricks<a hidden class="anchor" aria-hidden="true" href="#training-network-tricks">#</a></h2>
<h3 id="activation-functions">Activation functions<a hidden class="anchor" aria-hidden="true" href="#activation-functions">#</a></h3>
<p>Solitamente le funzioni classiche per i network neurali sono sigmoid, tanh, e ReLU. La cosa brutta delle prime due è <strong>vanishing gradient</strong>, perché se il valore è molto grosso o molto piccolo, la derivata è molto vicino allo 0, quindi è molto difficile aggiornare.</p>
<p>The activation function is presented as $\phi$ before.
One thing to note is that this <em>non-linearity</em> doesn&rsquo;t mix the dimensions together. Let me explain clearly with some maths:</p>
<p>We say that $\phi: \mathbb{R}^{n} \to \mathbb{R}^{n}$ and it&rsquo;s a composition of some $\bar{\phi}: \mathbb{R} \to \mathbb{R}$ which are just applied independently to every dimension.</p>
<p>Other properties are:</p>
<ul>
<li>Increasing</li>
<li>Continuous
There are important to remember from a mathematical point of view.</li>
</ul>
<h4 id="level-sets">Level Sets<a hidden class="anchor" aria-hidden="true" href="#level-sets">#</a></h4>
$$
L_{f}(z) = \left\{ x : \phi(w\cdot x + \beta) = z \right\}  \perp w
$$<p>
These are also called <strong>generalized linear models</strong>, or <strong>ridge functions</strong>.</p>
<h4 id="relu-activation">ReLU activation<a hidden class="anchor" aria-hidden="true" href="#relu-activation">#</a></h4>
$$
f(x) = 
\begin{cases}
0,\, \text{ if } x < 0 \\
x, \, \text{ if } x \geq 0
\end{cases}
$$<p>The important thing to notice is that when it <a href="/notes/backpropagation">backpropagates</a>, it just activates or kills the signal, allowing the gradient to flow naturally, and not vanish.</p>
$$
\frac{ \partial x^{(k+1)} }{ \partial x^{(k)} }  = \sigma'(W^{(k)}x^{(k)} + b) W^{(k)}
$$<p>
And $\sigma'$ in the case of the ReLU is just 0 or 1, which aids toward the problem of vanishing gradient and similars.
The thing to note is that this doesn&rsquo;t exactly work as an activation function if the input depends on $x$ with more than one parameter</p>
<h4 id="hyperbolic-tangent">Hyperbolic tangent<a hidden class="anchor" aria-hidden="true" href="#hyperbolic-tangent">#</a></h4>
<p>This activation is usually preferred to the Sigmoid, better treated in <a href="/notes/logistic-regression">Logistic Regression</a>, because it has <strong>sign symmetry</strong>.</p>
<h4 id="importance-of-non-linearity">Importance of Non linearity<a hidden class="anchor" aria-hidden="true" href="#importance-of-non-linearity">#</a></h4>
<p>The main reason we need non linearity is that we want to be able to learn complex functions, and this is not possible with a linear function. We can see this by the fact that a composition of linear functions is still a linear function.</p>
<p>Let&rsquo;s analyze the topic mathematically:
Suppose you have input data $x \in \mathbb{R}^{n}$ and a function $\sigma : \mathbb{R}^{n} \to \mathbb{R}^{n}: \sigma(x) = \alpha x + \beta$, the problem is the if you nest layers: $\forall l \in \left[ 1, L \right], x^{[l]} = \alpha(W^{[l]} x^{l - 1}] + b^{[l]}) + \beta$ which is just another affine mapping.
This means all the layers are the same as if I used a <strong>single layer</strong>.
Using <a href="/notes/kernel-methods">Kernel Methods</a> could help in this case, but it often needs feature engineering which is done by humans.</p>
<h3 id="optimization">Optimization<a hidden class="anchor" aria-hidden="true" href="#optimization">#</a></h3>
<p>Momentum, praticamente un gradient descent che tiene conto delle computazioni passate, e calcola la direzione anche secondo quelle (quindi se vado su e giù e a destra sempre nelle iterazioni passate, andrò a destra più spesso diciamo, questa è l’intuizione per questa idea).</p>
<p>Una cosa molto strana è che il training delle NN è molto stabile. Cioè vari un pò l’input e non varia molto l’ouput!</p>
<p>Possibili motivi:</p>
<ol>
<li>Weights</li>
<li>Loss function</li>
<li>Internal redundancy? cioè ho troppi parametri e questo lo rende bello.(teoria del prof)</li>
</ol>
<h4 id="loss-functions">Loss functions<a hidden class="anchor" aria-hidden="true" href="#loss-functions">#</a></h4>
$$
\mathcal{l}(y, \hat{y}) = \frac{1}{2} \lVert y - \hat{y} \rVert ^{2}
$$$$
l(\theta)(x, y) = l(y, F(\theta)(x))
$$<p>Sometimes you need to tailor the loss function to the problem you are trying to solve!
For example a very famous function is the <a href="/notes/softmax-function">Softmax Function</a>, for multiclass classification. In the case you just have two classes then it&rsquo;s the logistic function.</p>
$$
l(y, \hat{p}) = - \log \hat{p}_{y}
$$<p>
If we view this from an information theoretical point of view, then it&rsquo;s the expected length of our codeword.</p>
<h4 id="risks">Risks<a hidden class="anchor" aria-hidden="true" href="#risks">#</a></h4>
<p>After we have the loss we can go on and define the empirical risk, which is just:</p>
$$
\mathcal{R}(\theta; \mathcal{S}) := \mathbb{E}_{\mathcal{S}} [\ell(\theta)] := \frac{1}{s} \sum_{i = 1}^{s} \ell(\theta)(x_{i}, y_{i}) = \frac{1}{s} \sum_{i = 1}^{s} \ell(y_{i}, F(\theta)(x_{i}))
$$<p>This is the training risk, and same thing could be defined for the test risk.</p>
<h2 id="quirks-of-neural-networks">Quirks of Neural Networks<a hidden class="anchor" aria-hidden="true" href="#quirks-of-neural-networks">#</a></h2>
<p>This section presents some counter-intuitive phenomena that pertain neural networks. Classical theories predict opposite behaviours compared the ones we list here.</p>
<h4 id="grokking">Grokking<a hidden class="anchor" aria-hidden="true" href="#grokking">#</a></h4>
<p>Grokking refers to the phenomenon where a neural network initially exhibits poor generalization despite achieving low training loss, but after extended training, it <strong>suddenly</strong> generalizes well without any further changes to the dataset or training procedure.
This phenomenon was first observed in algorithmic tasks, where models would first memorize the training data before gradually developing a more structured, generalizable understanding.</p>
<p>This <strong>delayed phase transition</strong> challenges conventional notions of overfitting and suggests that prolonged training on sufficiently large datasets can sometimes lead to emergent generalization. A possible explanation is that neural networks first fit simpler patterns before refining their internal representations to capture deeper structure.</p>
<img src="/images/notes/Neural Networks-20250520105028299.webp" style="width: 100%" class="center" alt="Neural Networks-20250520105028299">
<h4 id="double-descent">Double Descent<a hidden class="anchor" aria-hidden="true" href="#double-descent">#</a></h4>
<p>The double descent phenomenon describes a peculiar behavior in the generalization performance of neural networks as model capacity increases. Unlike classical machine learning theory, which suggests that increasing model complexity leads to overfitting beyond a certain point, double descent reveals a second improvement in generalization performance at very high capacity.</p>
<p>This behavior is characterized by two distinct regions:</p>
<ol>
<li><strong>Classical Bias-Variance Tradeoff:</strong> In the underparameterized regime, increasing model complexity improves performance until it reaches the interpolation threshold, where it perfectly fits the training data but generalizes poorly.</li>
<li><strong>Modern Overparameterization:</strong> Beyond this interpolation threshold, further increasing model capacity counterintuitively leads to improved generalization. Neural networks often enter this second descent phase, where overfitting seems to subside, and test performance improves.</li>
</ol>
<p>The authors define a measure of <strong>Effective Model Complexity (EMC)</strong> as the maximum number of samples that can be <em>memorized</em> by the model, and make an analysis with this.
They show that in some specific cases it <strong>hurts</strong> to have more data, as more data shifts the <strong>critical regime</strong> to the right.</p>
<img src="/images/notes/Neural Networks-20250520104845697.webp" style="width: 100%" class="center" alt="Neural Networks-20250520104845697">
<h4 id="label-memorization">Label Memorization<a hidden class="anchor" aria-hidden="true" href="#label-memorization">#</a></h4>
<p>Neural networks have a remarkable capacity to memorize training data, even when the labels are randomized. Studies show that <em>deep models can fit arbitrary labels</em>, suggesting that memorization is an inherent property rather than a failure of training. However, memorization does not necessarily contradict generalization: modern deep networks balance memorization with pattern recognition.</p>
<figure class="center">
<img src="/images/notes/Neural Networks-20250520104516903.webp" style="width: 100%"   alt="Neural Networks-20250520104516903" title="Neural Networks-20250520104516903"/>
<figcaption><p style="text-align:center;">All the models overfit, doesn't matter what model you use, you learn random noise.</p></figcaption>
</figure>
<p>Key insights into label memorization include:</p>
<ul>
<li><strong>Memorization is a function of dataset size and model capacity:</strong> Larger networks can store training examples verbatim, but this does not always harm test accuracy, particularly in large-scale training scenarios.</li>
<li><strong>Memorization and generalization can coexist:</strong> Empirical results suggest that networks first learn patterns present in the data before resorting to memorization for harder examples.</li>
</ul>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p id=rosenblattPerceptronProbabilisticModel1958>[1] Rosenblatt <a href="https://psycnet.apa.org/record/1959-09865-001">“The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain.”</a> None 1958
 </p>
<p id=hornikMultilayerFeedforwardNetworks1989>[2] Hornik et al. <a href="https://www.sciencedirect.com/science/article/pii/0893608089900208">“Multilayer Feedforward Networks Are Universal Approximators”</a> Neural Networks Vol. 2(5), pp. 359--366 1989
 </p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://flecart.github.io/tags/deep-learning/">🥘Deep-Learning</a></li>
      <li><a href="https://flecart.github.io/tags/machine-perception/">Machine-Perception</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks on x"
            href="https://x.com/intent/tweet/?text=Neural%20Networks&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fneural-networks%2f&amp;hashtags=%f0%9f%a5%98deep-learning%2cmachine-perception">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fneural-networks%2f&amp;title=Neural%20Networks&amp;summary=Neural%20Networks&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2fneural-networks%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2fneural-networks%2f&title=Neural%20Networks">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2fneural-networks%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks on whatsapp"
            href="https://api.whatsapp.com/send?text=Neural%20Networks%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2fneural-networks%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks on telegram"
            href="https://telegram.me/share/url?text=Neural%20Networks&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fneural-networks%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Neural%20Networks&u=https%3a%2f%2fflecart.github.io%2fnotes%2fneural-networks%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
