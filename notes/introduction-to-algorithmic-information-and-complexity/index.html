<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Introduction to Algorithmic Information and Complexity | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Quick introduction
Si assume che la descrizione più intelligente di un qualcosa è la stringa più corta che descrive quella, un po&rsquo; forse è arbitrario, perché minore complessità, non è detto che sia direttamente relazionata con la difficoltà di descriverla.
Nel caso di AIT, diciamo che una cosa random non è compressibile, altrimenti posso scriverla in modo più compatto. È importante stabilire che l&rsquo;alfabeto che abbiamo per rappresentare qualcosa è fissato a priori.
Qualunque cosa che possiamo codare si può analizzare da questo punto di vista della complessità.">
<meta name="author" content="
By Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/introduction-to-algorithmic-information-and-complexity/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f790d9af969c56c079c1ce2d5972a04486bf3d6144295d5fba319830e1e55a7a.css" integrity="sha256-95DZr5acVsB5wc4tWXKgRIa/PWFEKV1fujGYMOHlWno=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/introduction-to-algorithmic-information-and-complexity/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>






      <script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-WW6NN2QGKF');
        }
      </script><meta property="og:url" content="https://flecart.github.io/notes/introduction-to-algorithmic-information-and-complexity/">
  <meta property="og:site_name" content="X. Angelo Huang&#39;s Blog">
  <meta property="og:title" content="Introduction to Algorithmic Information and Complexity">
  <meta property="og:description" content="Quick introduction Si assume che la descrizione più intelligente di un qualcosa è la stringa più corta che descrive quella, un po’ forse è arbitrario, perché minore complessità, non è detto che sia direttamente relazionata con la difficoltà di descriverla.
Nel caso di AIT, diciamo che una cosa random non è compressibile, altrimenti posso scriverla in modo più compatto. È importante stabilire che l’alfabeto che abbiamo per rappresentare qualcosa è fissato a priori. Qualunque cosa che possiamo codare si può analizzare da questo punto di vista della complessità.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="notes">
      <meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:title" content="Introduction to Algorithmic Information and Complexity">
<meta name="twitter:description" content="Quick introduction
Si assume che la descrizione più intelligente di un qualcosa è la stringa più corta che descrive quella, un po&rsquo; forse è arbitrario, perché minore complessità, non è detto che sia direttamente relazionata con la difficoltà di descriverla.
Nel caso di AIT, diciamo che una cosa random non è compressibile, altrimenti posso scriverla in modo più compatto. È importante stabilire che l&rsquo;alfabeto che abbiamo per rappresentare qualcosa è fissato a priori.
Qualunque cosa che possiamo codare si può analizzare da questo punto di vista della complessità.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Introduction to Algorithmic Information and Complexity",
      "item": "https://flecart.github.io/notes/introduction-to-algorithmic-information-and-complexity/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Introduction to Algorithmic Information and Complexity",
  "name": "Introduction to Algorithmic Information and Complexity",
  "description": "Quick introduction Si assume che la descrizione più intelligente di un qualcosa è la stringa più corta che descrive quella, un po\u0026rsquo; forse è arbitrario, perché minore complessità, non è detto che sia direttamente relazionata con la difficoltà di descriverla.\nNel caso di AIT, diciamo che una cosa random non è compressibile, altrimenti posso scriverla in modo più compatto. È importante stabilire che l\u0026rsquo;alfabeto che abbiamo per rappresentare qualcosa è fissato a priori. Qualunque cosa che possiamo codare si può analizzare da questo punto di vista della complessità.\n",
  "keywords": [
    
  ],
  "articleBody": "Quick introduction Si assume che la descrizione più intelligente di un qualcosa è la stringa più corta che descrive quella, un po’ forse è arbitrario, perché minore complessità, non è detto che sia direttamente relazionata con la difficoltà di descriverla.\nNel caso di AIT, diciamo che una cosa random non è compressibile, altrimenti posso scriverla in modo più compatto. È importante stabilire che l’alfabeto che abbiamo per rappresentare qualcosa è fissato a priori. Qualunque cosa che possiamo codare si può analizzare da questo punto di vista della complessità.\nThe complexity of an object is assessed by finding\nthe shortest among the available binary descriptions\nof that object.\nQuesta cosa permette di descrivere la complessità di un oggetto in modo assoluto (cioè a sé stante, mentre la entropia)\nInformation is what is left when any redundant data is thrown away.\nSi basa sulla ipotesi che se tolgo qualcosa comincio a non capirci più diciamo di quella cosa, quindi è tutto importante di quella stringa.\nSimple is frequent\nÈ una assunzione che si ha su AIT, però in natura non è sempre vero, perché un sasso lungo può essere semplice per noi da comprendere, però resta una cosa rara da trovare per dire. Bisogna capire bene che cosa questa metrica mi sta misurando! La cosa è che stranamente questa legge empirica sembra vera sul web! Words are optimally stored in memory according to the frequency of the use. Però non ci dice come avviene questo processo di aggiornamento della capacità della mente di fronte all’adattarsi a questi dati.\nRelative complexity Complexity of objects in different environments can vary, we say that this is a conditioned complexity: Un esempio banale: Prendiamo un insieme ordinato di elementi, allora posso rappresentare univocamente l’elemento tramite la rappresentazione del suo indice. Questo permette di semplificare molto la descrizione di quell’oggetto, ma comunque descriverlo nella sua interessa conoscendo il prior.\nWhen an object can be retrieved from a list,\nits complexity within the list can be estimated\nby the length of the binary representation of its rank.\nUpper bound con complexity When an object belongs to a set of size $N$,\nits complexity in that set cannot exceed $\\log_{2}(N)$\nPer utilizzare l’indexing di una lista, mi basta poter essere in grado di codificare il numero più alto presente, quindi la grandezza dell’insieme per descrivere l’elemento, per questo motivo posso affermare la frase di sopra. Questo bound mi permette di descrivere la complessità di oggetti senza ordine.\nRappresentazione dei Numeri interi $$ \\lceil \\log_{2}(n + 1) \\rceil $$ Usiamo il $+1$ per risolvere il problema col logaritmo di 0, questa comunque è una buona misura. Solo che non è il codice minimo, possiamo prendere il codice $\\lceil \\log_{2}(n + 3) - 1 \\rceil$ come un codice migliore, perché possiamo togliere 1 perché iniziamo a contare con la cifra 1. Possiamo prefixare qualcosa per scegliere il metodo di codifica. Per esempio un numero $90000$ si può encodare come $9$ con $4$ per encodare l’esponente del 10. Ma spendiamo il bit per indexare il metodo di codifica.\nIn generale per rappresentare cose non numeri, si possono utilizzare strutture che rappresentano univocamente quell’oggetto e poi usare la complessità su queste strutture. Non è chiaro sempre come utilizzare queste strutture.\nQuasi-continuous complexity In questa parte analizziamo come varia la lunghezza di descrizione per i numeri, notiamo che segue più o meno la curva logaritmica, con i drops previsti per i numeri rotondi, come da intuizione (lo schema di coding presentato ha questa proprietà).\n$$ \\lvert C(n + h) - C(n) \\rvert \\leq f(\\lvert h \\rvert ) + O(1) $$ Mentre sappiamo che per una funzione continua quello dovrebbe essere 0.\nGenerati da questo codice Compressibilità di stringhe binarie Un risultato che consegue dalla limitatezza di stringhe di bassa lunghezza abbiamo che:\nSe dati un insieme di tutte le stringhe binarie lunghe $N$, volessimo contrarre la descrizione di almeno $k$, avremmo che solo $\\frac{1}{2^{k - 1}}$ delle $2^{N}$ stringhe iniziali possono essere compresse per $k$ o più digits.\n$$ \\sum_{i=k}^{N} 2^{N - i} = 2^{N - k + 1} - 1 $$$$ \\frac{2^{N - k + 1}}{2^{N}} = \\frac{1}{2^{k - 1}} $$ E questo è un valore che decresce in modo esponenziale, per questo le stringhe compressibili di molto sono veramente veramente poche.\nUna cosa interessante è che per qualunque compressore $Z$ che si possa creare, se prendiamo sequenze binarie $N$ almeno una non è compressibile.\nExpanding compressors Una osservazione banale ci dice che se il compressore è una funzione con stesso dominio e codominio, e che sia iniettiva affinché sia univocamente decodabile, allora certe stringhe vengono espande invece che compresse! Solitamente nella pratica l’espansione succede perché il compressore aggiunge dei markers per dire che è stato compresso.\nQuesto ci dice che il compressor non deve comprimere sempre, ma solamente comprimere in modo dipendente dal contesto secondo me.\nZipf’s Law Elaborato insieme a un altro tizio che si chiama Condon relaziona la frequenza di una parola nel linguaggio con il rank, ossia un dizionario che ordina le parole per frequenza d’uso. https://babel.hathitrust.org/cgi/pt?id=mdp.39015008729983\u0026view=1up\u0026seq=7 Il contributo di Zips è una spiegazione di questo fenomeno empirico dato da Condon.\nEnunciato di Zipf $$ r_{f}(w) \\approx \\frac{c}{f(w)} $$ dove $f(w)$ è la frequenza della parola, e $r_{f}(w)$ è il suo rank, con una costante a caso $c$.\nThis means that the 10th most frequent word is 10 times more frequent than the 100th most frequent word, which is itself 10 times more frequent than the 1000th most frequent word, which is itself 10 times more frequent than the 10 000th most frequent word, and so on\nSembra che questa legge valga per molte lingue, non solo l’inglese.\nMinimize effort and time to find the right word to use. Questa è la spiegazione a questo fenomeno.\nCorrispondenza sulla complessità dei codici Complexity of the meaning = complexity of word Complexity is related to the frequency of the word Questo spiega anche cose sulla ripetizione spaziata in (Brown et al. 2014). E ha senso, cose che vediamo più spesso ci appaiono come semplici, cose che vediamo singola volta sono abbastanza complesse, la relazione sulla complessità sembra essere fortemente legata alla frequenza della parola. Che bella idea.\nNormalized information distance Basato su (Li et al. 2004).\nFor any pair of objects, NID determines what is common to them, and only keeps their difference to measure the distance that separates them.\nCalcolo del NID Misurare la differenza di informazione attraverso il Kolmogorov Condizionato quindi $max[K(x|y), K(y|x)]$ il max ci aiuta a rendere la distanza simmetrica. Normalizzare la differenza di informazione, perché vogliamo una nota relativa di questa misura. $max(K(x), K(y))$ che rappresenta la massima complessità di entrambi gli oggetti che vogliamo confrontare. Usare Kolmogorov complexity#Chain Rule cosicché possiamo riscrivere il numeratore. $$ NCD(x, y) = \\frac{K(x, y) - min[K(x), K(y)]}{max(K(x), K(y))} $$$$ NCD(x, y) = \\frac{max[K(x|y), K(y|x)]}{max(K(x), K(y))} $$Questo non è computabile perché $K$ non è computabile, ma possiamo stimarlo con un compressore reale. La cosa triste è che il compressore non prende in considerazione la semantica. Per la semantica è interessante usare la (Cilibrasi \u0026 Vitanyi 2007), usando google per stimare la distanza. e questa la chiama la Normalized Google Distance.\nUniversal distance $$ \\forall D; \\forall x, y: D_{U}(x, y) \u003c D(x, y) + C_{D} $$ Questo: $max[K(x|y), K(y|x)]$ è una distanza universale. Che è una cosa molto interessante.\nReferences [1] Cilibrasi \u0026 Vitanyi “The Google Similarity Distance” arXiv preprint arXiv:cs/0412098 2007 [2] Brown et al. “Make It Stick: The Science of Successful Learning” Harvard University Press 2014 [3] Li et al. “The Similarity Metric” IEEE Transactions on Information Theory Vol. 50(12), pp. 3250--3264 2004 ",
  "wordCount" : "1265",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/introduction-to-algorithmic-information-and-complexity/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Introduction to Algorithmic Information and Complexity
    </h1>
    <div class="post-meta">Reading Time: 6 minutes&nbsp;·&nbsp;
By Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul><ul>
                <li>
                    <a href="#quick-introduction" aria-label="Quick introduction">Quick introduction</a><ul>
                        
                <li>
                    <a href="#relative-complexity" aria-label="Relative complexity">Relative complexity</a></li>
                <li>
                    <a href="#upper-bound-con-complexity" aria-label="Upper bound con complexity">Upper bound con complexity</a></li>
                <li>
                    <a href="#rappresentazione-dei-numeri-interi" aria-label="Rappresentazione dei Numeri interi">Rappresentazione dei Numeri interi</a></li>
                <li>
                    <a href="#quasi-continuous-complexity" aria-label="Quasi-continuous complexity">Quasi-continuous complexity</a></li>
                <li>
                    <a href="#compressibilit%c3%a0-di-stringhe-binarie" aria-label="Compressibilità di stringhe binarie">Compressibilità di stringhe binarie</a></li></ul>
                </li>
                <li>
                    <a href="#expanding-compressors" aria-label="Expanding compressors">Expanding compressors</a></li>
                <li>
                    <a href="#zipfs-law" aria-label="Zipf&rsquo;s Law">Zipf&rsquo;s Law</a><ul>
                        
                <li>
                    <a href="#enunciato-di-zipf" aria-label="Enunciato di Zipf">Enunciato di Zipf</a></li>
                <li>
                    <a href="#corrispondenza-sulla-complessit%c3%a0-dei-codici" aria-label="Corrispondenza sulla complessità dei codici">Corrispondenza sulla complessità dei codici</a></li></ul>
                </li>
                <li>
                    <a href="#normalized-information-distance" aria-label="Normalized information distance">Normalized information distance</a><ul>
                        
                <li>
                    <a href="#calcolo-del-nid" aria-label="Calcolo del NID">Calcolo del NID</a></li>
                <li>
                    <a href="#universal-distance" aria-label="Universal distance">Universal distance</a></li></ul>
                </li></ul>
                    </ul>
                    
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="quick-introduction">Quick introduction<a hidden class="anchor" aria-hidden="true" href="#quick-introduction">#</a></h3>
<p>Si assume che la descrizione più <em>intelligente</em> di un qualcosa è la stringa <strong>più corta</strong> che descrive quella, un po&rsquo; forse è arbitrario, perché minore complessità, non è detto che sia direttamente relazionata con la difficoltà di descriverla.</p>
<p>Nel caso di AIT, diciamo che una cosa random non è compressibile, altrimenti posso scriverla in modo più compatto. È importante stabilire che l&rsquo;alfabeto che abbiamo per rappresentare qualcosa è fissato a priori.
<em>Qualunque cosa che possiamo codare</em> si può analizzare da questo punto di vista della complessità.</p>
<blockquote>
<p>The complexity of an object is assessed by finding<br>
the <strong>shortest</strong> among the available binary descriptions<br>
of that object.</p></blockquote>
<p>Questa cosa permette di descrivere la complessità di un oggetto in modo assoluto (cioè a sé stante, mentre la entropia)</p>
<blockquote>
<p><strong>Information</strong> is what is left when any redundant data is thrown away.</p></blockquote>
<p>Si basa sulla ipotesi che se tolgo qualcosa comincio a non capirci più diciamo di quella cosa, quindi è tutto importante di quella stringa.</p>
<blockquote>
<p><strong>Simple is frequent</strong></p></blockquote>
<p>È una assunzione che si ha su AIT, però in natura non è sempre vero, perché un sasso lungo può essere semplice per noi da comprendere, però resta una cosa rara da trovare per dire. Bisogna capire bene che cosa questa metrica mi sta misurando! La cosa è che stranamente questa legge empirica sembra vera sul web!
Words are <em>optimally stored in memory</em> according to the frequency of the use. Però non ci dice come avviene questo processo di aggiornamento della capacità della mente di fronte all&rsquo;adattarsi a questi dati.</p>
<h4 id="relative-complexity">Relative complexity<a hidden class="anchor" aria-hidden="true" href="#relative-complexity">#</a></h4>
<p>Complexity of objects in different environments can vary, we say that this is a <strong>conditioned complexity:</strong>
Un esempio banale:
Prendiamo un insieme ordinato di elementi, allora posso rappresentare univocamente l&rsquo;elemento tramite la rappresentazione del suo indice. Questo permette di semplificare molto la descrizione di quell&rsquo;oggetto, ma comunque descriverlo nella sua interessa conoscendo il prior.</p>
<blockquote>
<p>When an object can be retrieved from a list,<br>
its complexity within the list can be estimated<br>
by the length of the binary representation of its rank.</p></blockquote>
<h4 id="upper-bound-con-complexity">Upper bound con complexity<a hidden class="anchor" aria-hidden="true" href="#upper-bound-con-complexity">#</a></h4>
<blockquote>
<p>When an object belongs to a set of size $N$,<br>
its complexity in that set cannot exceed $\log_{2}(N)$</p></blockquote>
<p>Per utilizzare l&rsquo;indexing di una lista, mi basta poter essere in grado di codificare il numero più alto presente, quindi la grandezza dell&rsquo;insieme per descrivere l&rsquo;elemento, per questo motivo posso affermare la frase di sopra.
Questo bound mi permette di <strong>descrivere la complessità</strong> di oggetti senza ordine.</p>
<h4 id="rappresentazione-dei-numeri-interi">Rappresentazione dei Numeri interi<a hidden class="anchor" aria-hidden="true" href="#rappresentazione-dei-numeri-interi">#</a></h4>
$$
\lceil \log_{2}(n + 1) \rceil 
$$<p>
Usiamo il $+1$ per risolvere il problema col logaritmo di 0, questa comunque è una buona misura.
Solo che non è il codice minimo, possiamo prendere il codice $\lceil \log_{2}(n + 3) - 1 \rceil$ come un codice migliore, perché possiamo togliere 1 perché iniziamo a contare con la cifra 1.
Possiamo prefixare qualcosa per scegliere il metodo di codifica. Per esempio un numero $90000$ si può encodare come $9$ con $4$  per encodare l&rsquo;esponente del 10. Ma spendiamo il bit per indexare il metodo di codifica.</p>
<p>In generale per rappresentare cose non numeri, si possono utilizzare <strong>strutture</strong> che rappresentano univocamente quell&rsquo;oggetto e poi usare la complessità su queste strutture.
Non è chiaro sempre come utilizzare queste strutture.</p>
<h4 id="quasi-continuous-complexity">Quasi-continuous complexity<a hidden class="anchor" aria-hidden="true" href="#quasi-continuous-complexity">#</a></h4>
<p>In questa parte analizziamo come varia la lunghezza di descrizione per i numeri, notiamo che segue più o meno la curva logaritmica, con i drops previsti per i numeri rotondi, come da intuizione (lo schema di coding presentato ha questa proprietà).</p>
$$
\lvert C(n + h) - C(n) \rvert \leq f(\lvert h \rvert ) + O(1)
$$<p>
Mentre sappiamo che per una funzione continua quello dovrebbe essere 0.</p>
<p>Generati da <a href="https://aiai.telecom-paris.fr/src_CompactIntegerCoding.html">questo codice</a>
<img src="/images/notes/Introduction to Algorithmic Information and Complexity-20240212185519221 1.webp" style="width: 100%" class="center" alt="Introduction to Algorithmic Information and Complexity-20240212185519221 1">
<img src="/images/notes/Introduction to Algorithmic Information and Complexity-20240212185511465 1.webp" style="width: 100%" class="center" alt="Introduction to Algorithmic Information and Complexity-20240212185511465 1"></p>
<h4 id="compressibilità-di-stringhe-binarie">Compressibilità di stringhe binarie<a hidden class="anchor" aria-hidden="true" href="#compressibilità-di-stringhe-binarie">#</a></h4>
<p>Un risultato che consegue dalla limitatezza di stringhe di bassa lunghezza abbiamo che:</p>
<blockquote>
<p>Se dati un insieme di tutte le stringhe binarie lunghe $N$, volessimo contrarre la descrizione di almeno $k$, avremmo che solo $\frac{1}{2^{k - 1}}$ delle $2^{N}$ stringhe iniziali possono essere compresse per $k$ o più digits.</p></blockquote>
$$
\sum_{i=k}^{N} 2^{N - i} = 2^{N - k + 1} - 1
$$$$
\frac{2^{N - k + 1}}{2^{N}} = \frac{1}{2^{k - 1}}
$$<p>
E questo è un valore che decresce in modo esponenziale, per questo le stringhe compressibili di molto sono veramente veramente poche.</p>
<p>Una cosa interessante è che per qualunque compressore $Z$ che si possa creare, se prendiamo sequenze binarie $N$ almeno una non è compressibile.</p>
<h3 id="expanding-compressors">Expanding compressors<a hidden class="anchor" aria-hidden="true" href="#expanding-compressors">#</a></h3>
<p>Una osservazione banale ci dice che se il compressore è una funzione con stesso dominio e codominio, e che sia iniettiva affinché sia univocamente decodabile, allora certe stringhe vengono espande invece che compresse!
Solitamente nella pratica l&rsquo;espansione succede perché il compressore aggiunge dei markers per dire che è stato compresso.</p>
<p>Questo ci dice che il compressor non deve comprimere sempre, ma solamente comprimere in modo dipendente dal contesto secondo me.</p>
<h3 id="zipfs-law">Zipf&rsquo;s Law<a hidden class="anchor" aria-hidden="true" href="#zipfs-law">#</a></h3>
<p>Elaborato insieme a un altro tizio che si chiama <em>Condon</em> relaziona la frequenza di una parola nel linguaggio con il rank, ossia un dizionario che ordina le parole per frequenza d&rsquo;uso.
<a href="https://babel.hathitrust.org/cgi/pt?id=mdp.39015008729983&view=1up&seq=7"><a href="https://babel.hathitrust.org/cgi/pt?id=mdp.39015008729983&amp;view=1up&amp;seq=7">https://babel.hathitrust.org/cgi/pt?id=mdp.39015008729983&view=1up&seq=7</a></a>
Il contributo di Zips è una spiegazione di questo fenomeno empirico dato da Condon.</p>
<h4 id="enunciato-di-zipf">Enunciato di Zipf<a hidden class="anchor" aria-hidden="true" href="#enunciato-di-zipf">#</a></h4>
$$
r_{f}(w) \approx \frac{c}{f(w)}
$$<p>
dove $f(w)$ è la frequenza della parola, e $r_{f}(w)$ è il suo rank, con una costante a caso $c$.</p>
<blockquote>
<p>This means that the 10th most frequent word is 10 times more frequent than the 100th most frequent word, which is itself 10 times more frequent than the 1000th most frequent word, which is itself 10 times more frequent than the 10 000th most frequent word, and so on</p></blockquote>
<p>Sembra che questa legge valga per molte lingue, non solo l&rsquo;inglese.</p>
<p>Minimize effort and time to find the right word to use. Questa è la spiegazione a questo fenomeno.</p>
<h4 id="corrispondenza-sulla-complessità-dei-codici">Corrispondenza sulla complessità dei codici<a hidden class="anchor" aria-hidden="true" href="#corrispondenza-sulla-complessità-dei-codici">#</a></h4>
<img src="/images/notes/Introduction to Algorithmic Information and Complexity-20240217152227258.webp" style="width: 100%" class="center" alt="Introduction to Algorithmic Information and Complexity-20240217152227258">
<ol>
<li>Complexity of the meaning = complexity of word</li>
<li>Complexity is related to the frequency of the word</li>
<li></li>
</ol>
<img src="/images/notes/Introduction to Algorithmic Information and Complexity-20240217152451349.webp" style="width: 100%" class="center" alt="Introduction to Algorithmic Information and Complexity-20240217152451349">
<p>Questo spiega anche cose sulla ripetizione spaziata in <a href="https://books.google.it/books/about/Make_It_Stick.html?id=oneWAwAAQBAJ">(Brown et al. 2014)</a>. E ha senso, cose che vediamo più spesso ci appaiono come semplici, cose che vediamo singola volta sono abbastanza complesse, la relazione sulla complessità sembra essere fortemente legata alla frequenza della parola. Che bella idea.</p>
<h3 id="normalized-information-distance">Normalized information distance<a hidden class="anchor" aria-hidden="true" href="#normalized-information-distance">#</a></h3>
<p>Basato su <a href="https://ieeexplore.ieee.org/document/1362909">(Li et al. 2004)</a>.</p>
<blockquote>
<p>For any pair of objects, NID determines what is common to them, and only keeps their difference to measure the distance that separates them.</p></blockquote>
<h4 id="calcolo-del-nid">Calcolo del NID<a hidden class="anchor" aria-hidden="true" href="#calcolo-del-nid">#</a></h4>
<ol>
<li>Misurare la differenza di informazione attraverso il <a href="/notes/kolmogorov-complexity#kolmogorov-condizionato-">Kolmogorov Condizionato</a> quindi $max[K(x|y), K(y|x)]$ il max ci aiuta a rendere la distanza <em>simmetrica</em>.</li>
<li><strong>Normalizzare</strong> la differenza di informazione, perché vogliamo una nota relativa di questa misura. $max(K(x), K(y))$ che rappresenta la massima complessità di entrambi gli oggetti che vogliamo confrontare.</li>
<li>Usare <a href="/notes/kolmogorov-complexity#chain-rule">Kolmogorov complexity#Chain Rule</a> cosicché possiamo riscrivere il numeratore.</li>
</ol>
$$
NCD(x, y) = \frac{K(x, y) - min[K(x), K(y)]}{max(K(x), K(y))}
$$$$
NCD(x, y) = \frac{max[K(x|y), K(y|x)]}{max(K(x), K(y))}
$$<p>Questo non è computabile perché $K$ non è computabile, ma possiamo stimarlo con un compressore reale. La cosa triste è che il compressore non prende in considerazione la semantica.
Per la semantica è interessante usare la <a href="http://arxiv.org/abs/cs/0412098">(Cilibrasi &amp; Vitanyi 2007)</a>, usando google per stimare la distanza. e questa la chiama la <strong>Normalized Google Distance</strong>.</p>
<h4 id="universal-distance">Universal distance<a hidden class="anchor" aria-hidden="true" href="#universal-distance">#</a></h4>
$$
\forall D; \forall x, y: D_{U}(x, y) < D(x, y) + C_{D}
$$<p>
Questo: $max[K(x|y), K(y|x)]$ è una distanza universale. Che è una cosa molto interessante.</p>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p id=cilibrasiGoogleSimilarityDistance2007>[1] Cilibrasi & Vitanyi <a href="http://arxiv.org/abs/cs/0412098">“The Google Similarity Distance”</a> arXiv preprint arXiv:cs/0412098 2007
 </p>
<p id=brownMakeItStick2014>[2] Brown et al. <a href="https://books.google.it/books/about/Make_It_Stick.html?id=oneWAwAAQBAJ">“Make It Stick: The Science of Successful Learning”</a> Harvard University Press 2014
 </p>
<p id=liSimilarityMetric2004>[3] Li et al. <a href="https://ieeexplore.ieee.org/document/1362909">“The Similarity Metric”</a> IEEE Transactions on Information Theory Vol. 50(12), pp. 3250--3264 2004
 </p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Algorithmic Information and Complexity on x"
            href="https://x.com/intent/tweet/?text=Introduction%20to%20Algorithmic%20Information%20and%20Complexity&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-algorithmic-information-and-complexity%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Algorithmic Information and Complexity on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-algorithmic-information-and-complexity%2f&amp;title=Introduction%20to%20Algorithmic%20Information%20and%20Complexity&amp;summary=Introduction%20to%20Algorithmic%20Information%20and%20Complexity&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-algorithmic-information-and-complexity%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Algorithmic Information and Complexity on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-algorithmic-information-and-complexity%2f&title=Introduction%20to%20Algorithmic%20Information%20and%20Complexity">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Algorithmic Information and Complexity on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-algorithmic-information-and-complexity%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Algorithmic Information and Complexity on whatsapp"
            href="https://api.whatsapp.com/send?text=Introduction%20to%20Algorithmic%20Information%20and%20Complexity%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-algorithmic-information-and-complexity%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Algorithmic Information and Complexity on telegram"
            href="https://telegram.me/share/url?text=Introduction%20to%20Algorithmic%20Information%20and%20Complexity&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-algorithmic-information-and-complexity%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Introduction to Algorithmic Information and Complexity on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Introduction%20to%20Algorithmic%20Information%20and%20Complexity&u=https%3a%2f%2fflecart.github.io%2fnotes%2fintroduction-to-algorithmic-information-and-complexity%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
