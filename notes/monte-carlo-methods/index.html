<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Monte Carlo Methods | X. Angelo Huang&#39;s Blog</title>
<meta name="keywords" content="➕probabilistic-artificial-intelligence">
<meta name="description" content="DI Law of Large Numbers e Central limit theorem ne parliamo in Central Limit Theorem and Law of Large Numbers.
Usually these methods are useful when you need to calculate following something similar to Bayes rule, but don&rsquo;t know how to calculate the denominator, often infeasible integral. We estimate this value without explicitly calculating that.
Interested in $\mathbb{P}(x) = \frac{1}{z} \mathbb{P}^{*}(x) = \frac{1}{Z} e^{-E(x)}$
Can evaluate E(x) at any x.

Problem 1 Make samples x(r) ~ 2 P
Problem 2 Estimate expectations  $\Phi = \sum_{x}\phi(x)\mathbb{P}(x)$)
What we&rsquo;re not trying to do:
We&rsquo;re not trying to find the most probable state.
We&rsquo;re not trying to visit all typical states.

Law of large numbers
$$
S_{n} = \sum^n_{i=1} x_{i} ,:, \bar{x}_{n} = \frac{S_{n}}{n}
$$$$
\bar{x}_{n} \to \mu
$$
Ossia il limite converge sul valore atteso di tutte le variabili aleatorie.">
<meta name="author" content="
By Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="https://flecart.github.io/notes/monte-carlo-methods/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f790d9af969c56c079c1ce2d5972a04486bf3d6144295d5fba319830e1e55a7a.css" integrity="sha256-95DZr5acVsB5wc4tWXKgRIa/PWFEKV1fujGYMOHlWno=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://flecart.github.io/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://flecart.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://flecart.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://flecart.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://flecart.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://flecart.github.io/notes/monte-carlo-methods/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
<script type="text/javascript" async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>






      <script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-WW6NN2QGKF');
        }
      </script><meta property="og:url" content="https://flecart.github.io/notes/monte-carlo-methods/">
  <meta property="og:site_name" content="X. Angelo Huang&#39;s Blog">
  <meta property="og:title" content="Monte Carlo Methods">
  <meta property="og:description" content="DI Law of Large Numbers e Central limit theorem ne parliamo in Central Limit Theorem and Law of Large Numbers. Usually these methods are useful when you need to calculate following something similar to Bayes rule, but don’t know how to calculate the denominator, often infeasible integral. We estimate this value without explicitly calculating that.
Interested in $\mathbb{P}(x) = \frac{1}{z} \mathbb{P}^{*}(x) = \frac{1}{Z} e^{-E(x)}$ Can evaluate E(x) at any x.
Problem 1 Make samples x(r) ~ 2 P Problem 2 Estimate expectations $\Phi = \sum_{x}\phi(x)\mathbb{P}(x)$) What we’re not trying to do: We’re not trying to find the most probable state. We’re not trying to visit all typical states. Law of large numbers $$ S_{n} = \sum^n_{i=1} x_{i} ,:, \bar{x}_{n} = \frac{S_{n}}{n} $$$$ \bar{x}_{n} \to \mu $$ Ossia il limite converge sul valore atteso di tutte le variabili aleatorie.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="notes">
    <meta property="article:published_time" content="2025-01-15T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-01-15T00:00:00+00:00">
    <meta property="article:tag" content="➕Probabilistic-Artificial-Intelligence">
      <meta property="og:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://flecart.github.io/images/papermod-cover.png">
<meta name="twitter:title" content="Monte Carlo Methods">
<meta name="twitter:description" content="DI Law of Large Numbers e Central limit theorem ne parliamo in Central Limit Theorem and Law of Large Numbers.
Usually these methods are useful when you need to calculate following something similar to Bayes rule, but don&rsquo;t know how to calculate the denominator, often infeasible integral. We estimate this value without explicitly calculating that.
Interested in $\mathbb{P}(x) = \frac{1}{z} \mathbb{P}^{*}(x) = \frac{1}{Z} e^{-E(x)}$
Can evaluate E(x) at any x.

Problem 1 Make samples x(r) ~ 2 P
Problem 2 Estimate expectations  $\Phi = \sum_{x}\phi(x)\mathbb{P}(x)$)
What we&rsquo;re not trying to do:
We&rsquo;re not trying to find the most probable state.
We&rsquo;re not trying to visit all typical states.

Law of large numbers
$$
S_{n} = \sum^n_{i=1} x_{i} ,:, \bar{x}_{n} = \frac{S_{n}}{n}
$$$$
\bar{x}_{n} \to \mu
$$
Ossia il limite converge sul valore atteso di tutte le variabili aleatorie.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://flecart.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Monte Carlo Methods",
      "item": "https://flecart.github.io/notes/monte-carlo-methods/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Monte Carlo Methods",
  "name": "Monte Carlo Methods",
  "description": "DI Law of Large Numbers e Central limit theorem ne parliamo in Central Limit Theorem and Law of Large Numbers. Usually these methods are useful when you need to calculate following something similar to Bayes rule, but don\u0026rsquo;t know how to calculate the denominator, often infeasible integral. We estimate this value without explicitly calculating that.\nInterested in $\\mathbb{P}(x) = \\frac{1}{z} \\mathbb{P}^{*}(x) = \\frac{1}{Z} e^{-E(x)}$ Can evaluate E(x) at any x.\nProblem 1 Make samples x(r) ~ 2 P Problem 2 Estimate expectations $\\Phi = \\sum_{x}\\phi(x)\\mathbb{P}(x)$) What we\u0026rsquo;re not trying to do: We\u0026rsquo;re not trying to find the most probable state. We\u0026rsquo;re not trying to visit all typical states. Law of large numbers $$ S_{n} = \\sum^n_{i=1} x_{i} ,:, \\bar{x}_{n} = \\frac{S_{n}}{n} $$$$ \\bar{x}_{n} \\to \\mu $$ Ossia il limite converge sul valore atteso di tutte le variabili aleatorie.\n",
  "keywords": [
    "➕probabilistic-artificial-intelligence"
  ],
  "articleBody": "DI Law of Large Numbers e Central limit theorem ne parliamo in Central Limit Theorem and Law of Large Numbers. Usually these methods are useful when you need to calculate following something similar to Bayes rule, but don’t know how to calculate the denominator, often infeasible integral. We estimate this value without explicitly calculating that.\nInterested in $\\mathbb{P}(x) = \\frac{1}{z} \\mathbb{P}^{*}(x) = \\frac{1}{Z} e^{-E(x)}$ Can evaluate E(x) at any x.\nProblem 1 Make samples x(r) ~ 2 P Problem 2 Estimate expectations $\\Phi = \\sum_{x}\\phi(x)\\mathbb{P}(x)$) What we’re not trying to do: We’re not trying to find the most probable state. We’re not trying to visit all typical states. Law of large numbers $$ S_{n} = \\sum^n_{i=1} x_{i} ,:, \\bar{x}_{n} = \\frac{S_{n}}{n} $$$$ \\bar{x}_{n} \\to \\mu $$ Ossia il limite converge sul valore atteso di tutte le variabili aleatorie.\n$$ var(\\hat{x}_{n}) = \\frac{\\sigma^{2}}{n} \\to 0 $$Strong Law of large Numbers $$ \\mathbb{P}(\\lim_{ n \\to \\infty } \\bar{x}_{n} =\\mu) = 1 $$$$ \\bar{h}_{n} = \\sum_{i=1}^{n} \\frac{h(x_{i})}{n} $$ E questo converge $O(\\sqrt{ n })$ per la legge dopo.\nCentral limit theorem Data una sequenza di variabili aleatorie, $X_{1}, X_{2}, \\dots, X_{n}\\dots$, tali che siano i.i.d tali per cui $E(X_{1}) = E(X_{2}) = \\dots = E(X_{n}) =\\dots = \\mu$ tale che sia finito, e con varianza tutti uguali $= \\sigma^{2}$ finito.\n$$ \\sqrt{ n } (\\hat{x}_{n} - \\mu) \\to N(0, \\sigma^{2}) $$ La prima parte è una variabile aleatoria e converge a quel valore. (questo permette di utilizzare la gaussiana quando $n$ è grande abbastanza).\nMonte carlo integration $$ \\int_{X} h(x) \\cdot f(x) dx = E_{f}[h(x)] = \\mu $$ Questo è tutto il significato dell’integrazione di monte carlo (molte variabili aleatorie per stimare il valore di qualcosa). E questo vale sempre, anche se $f$ non è una funzione di densità, basta che sia positiva (basta riscalare).\nIl motivo per cui funziona è per LLN, perché abbiamo che convergerà su $\\mu$ in lungo termine, basta considerare molte variabili aleatorie consecutive.\nCose interessanti:\nPosso stimare il valore atteso grazie a LLN Posso stimare la varianza grazie ad essa Posso stimare variabili condizionali. Importance sampling Deve soddisfare la cosa del supporto (contiene supporto sia di h che di f) Deve avere varianza finita per i pesi che sono trovati. (ci sono metodi per stimare poi il $g$). la frazione $\\frac{f}{g}$ deve essere limitata e la varianza di $h$ rispetto alla densità $f$ deve essere finita. Bound on samples TODO: this should be interesting and important and should use Hoeffding’s inequality.\nMarkov Chain Monte Carlo L’idea principale di Markov Chain Monte carlo è di costruire una catena di Markov tale che si possa utilizzare per generare dalla distribuzione difficilmente trattabile. Uno dei metodi principali per fare ciò è utilizzare tecniche si sampling.\nMetropolis Hastings The Sampling Algorithm From Bishop Deep Learning Book\nWe observe that this sampling algorithm takes idea from Markov Chains balanced equation’s property of stationary distributions and the Accept Reject algorithm for sampling some distributions. Also in this case, we don’t care about the normalization constant for $p$, the distribution that we would like to sample from. We choose the that acceptance probability as it allows us to satisfy the balance equation and thus, the stationary property of the constructed Chain.\nWith Metropolis-Hasting we need to\nBe able to calculate the density for the target distribution Be able to sample easily from the $q$ distribution. Then it has some links with Random Walks inside the space we want to sample. $$ \\alpha = \\min\\left(1, \\frac{p(x')q(x \\mid x')}{p(x)q(x' \\mid x)}\\right) $$ Where $x$ is the current state and $x'$ is the proposed state.\nStationary Distribution We can prove that with that acceptance rate, the probability of transitioning in a given state satisfies the balance equation for the stationary distribution, which implies we can have a well behaved Markov Chain, and continue to sample from this.\n$$ p(x)q(x' \\mid x) \\alpha = p(x')q(x \\mid x') \\alpha $$ To prove this, just consider the two possible cases for the min function.\nCon distribuzioni Gaussiane $$ \\frac{r(x' \\mid x)}{r(x \\mid x')} = \\frac{\\mathcal{N}(x'; x, \\tau I)}{\\mathcal{N}(x; x', \\tau I)} = 1 $$ Quindi il coefficiente $\\alpha$ si può scrivere anche solo come le distribuzioni $\\frac{q(x)}{q(x')}$ che se si assume una distribuzione di Gibbs, si può intendere come un $\\exp(f(x) - f(x'))$, che è di facile interpretazione. Quindi possiamo fare sampling solamente considerando il rapporto fra le due distribuzioni.\nVariations and Improvements Metropolis-Hastings’ sample efficiency could be improved by adding information about the gradient of the distribution. This is the idea behind the Langevin algorithm.\nMetropolis Adjusted Langevin Algorithm $$ r(x'\\mid x) = \\mathcal{N}(x'; x + \\tau \\nabla f(x), 2\\tau I)\\propto \\exp\\left( -\\frac{1}{2} \\left\\| \\frac{x' - x - \\tau \\nabla \\log p(x)}{G} \\right\\|^2 \\right), $$ § It is possible to show that for log-concave distributions (e.g., Bayesian log. Regression), MALA efficiently converges to the stationary distribution (mixing time is polynomial in the dimension)\nSomehow, one can prove that if $\\tau \\to 0$ then the Metropolis Hastings tends to always accept the proposal, which is why it is more efficient. The version of Metropolis Hastings that always accepts is called Unadjusted Langevin Algorithm.\n$$ p(\\theta \\mid x_{1:n}, y_{1:n}) = \\frac{1}{Z} \\exp(\\log p(\\theta) + \\sum_{i=1}^{n} \\log p(y_{i} \\mid x_{i}, \\theta)) $$$$ \\theta_{t+1} = \\theta_{t} + \\tau \\nabla_{\\theta} \\log p(\\theta) + \\tau \\sum_{i=1}^{n} \\nabla_{\\theta} \\log p(y_{i} \\mid x_{i}, \\theta) + \\varepsilon $$ Where $\\varepsilon \\sim \\mathcal{N}(0, 2\\tau I)$\nThe drawback of this method is that computing the energy for the whole dataset is expensive for large datasets. This is why sometimes we use a stochastic version of this algorithm. Which drives to the stochastic gradient Langevin dynamics.\nStochastic Gradient Langevin Dynamics The double value for the Noise signal is justifiable if you study diffusion processes. So if you want to know how the $2$ factor comes into play when analyzing the process take a look at those courses. One can also estimate the update of the gradient of the likelihood by having $m$ samples and then using that values for the update: So the algorithm for the update becomes:\nSample $m$ points and then update $\\theta$ as follows: $$ \\theta_{t+1} = \\theta_{t} + \\tau \\nabla_{\\theta} \\log p(\\theta) + \\tau\\frac{n}{m} \\sum_{i=1}^{m} \\nabla_{\\theta} \\log p(y_{i} \\mid x_{i}, \\theta) + \\varepsilon $$ Langevin Monte Carlo TODO: this is just an Outlook, and it is left out from here.\nLandscape of sampling methods we can broadly categorize optimization methods based on the use of\nMomentum Stochasticity Sampling Then we would have this cube. Gibbs Sampling These are probably not very important for the exam. We use a collapsed version of Gibbs Sampling for Dirichlet Processes.\nThe Idea Gibbs sampling is a special case of Metropolis Hasting, in this case the proposal distribution $r$ is as follows:\n$$ r_{i}(x' \\mid x) = \\begin{cases} p(x_{i}' \\mid x'_{-i}) \u0026 \\text{if } x' \\text{ differs from } x \\text{ only in } i \\\\ 0 \u0026 \\text{else} \\\\ \\end{cases} $$ We just focus on a single coordinate difference. Similar to the coordinate descent in some manner.\nProof of correctness This sections proves that Gibbs Sampling indeed gives the original distribution. We will use a similar idea presented for #Metropolis Hastings.\n$$ \\begin{align} \\alpha_{i}(x'\\mid x) = \\min \\left(1, \\frac{p(x')}{p(x)} \\right) = 1 \\end{align} $$A simple code example This code example shows how we can sample from a multivariate Gaussian using Gibbs sampling. Note that we just need to be able to compute marginals in order to sample this.\nimport numpy as np import matplotlib.pyplot as plt # Define parameters of the bivariate Gaussian mu1, mu2 = 0, 0 # Means sigma1, sigma2 = 1, 1 # Standard deviations rho = 0.8 # Correlation coefficient # Derived quantities cov = rho * sigma1 * sigma2 # Covariance Sigma = np.array([[sigma1**2, cov], [cov, sigma2**2]]) # Covariance matrix Sigma_inv = np.linalg.inv(Sigma) # Precision matrix # Conditional distributions def sample_x1_given_x2(x2, mu1, mu2, sigma1, sigma2, rho): cond_mean = mu1 + rho * (sigma1 / sigma2) * (x2 - mu2) cond_var = (1 - rho**2) * sigma1**2 return np.random.normal(cond_mean, np.sqrt(cond_var)) def sample_x2_given_x1(x1, mu1, mu2, sigma1, sigma2, rho): cond_mean = mu2 + rho * (sigma2 / sigma1) * (x1 - mu1) cond_var = (1 - rho**2) * sigma2**2 return np.random.normal(cond_mean, np.sqrt(cond_var)) # Gibbs Sampling def gibbs_sampling(num_samples, burn_in=100): samples = [] x1, x2 = 0, 0 # Initial values for _ in range(num_samples + burn_in): x1 = sample_x1_given_x2(x2, mu1, mu2, sigma1, sigma2, rho) x2 = sample_x2_given_x1(x1, mu1, mu2, sigma1, sigma2, rho) samples.append((x1, x2)) return np.array(samples[burn_in:]) # Discard burn-in samples # Run Gibbs Sampling num_samples = 5000 samples = gibbs_sampling(num_samples) # Plot results plt.figure(figsize=(8, 6)) plt.scatter(samples[:, 0], samples[:, 1], alpha=0.5, s=5, label=\"Samples\") plt.title(\"Gibbs Sampling: Bivariate Gaussian\", fontsize=14) plt.xlabel(\"$X_1$\", fontsize=12) plt.ylabel(\"$X_2$\", fontsize=12) plt.axhline(0, color='gray', linewidth=0.5) plt.axvline(0, color='gray', linewidth=0.5) plt.grid(alpha=0.3) plt.legend() plt.show() ",
  "wordCount" : "1449",
  "inLanguage": "en",
  "image": "https://flecart.github.io/images/papermod-cover.png","datePublished": "2025-01-15T00:00:00Z",
  "dateModified": "2025-01-15T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://flecart.github.io/notes/monte-carlo-methods/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. Angelo Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://flecart.github.io/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://flecart.github.io/" accesskey="h" title="X. Angelo Huang&#39;s Blog (Alt + H)">X. Angelo Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://flecart.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://flecart.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://flecart.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://flecart.github.io/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Monte Carlo Methods
    </h1>
    <div class="post-meta"><span title='2025-01-15 00:00:00 +0000 UTC'>January 15, 2025</span>&nbsp;·&nbsp;Reading Time: 7 minutes&nbsp;·&nbsp;
By Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul>
                <li>
                    <a href="#law-of-large-numbers" aria-label="Law of large numbers">Law of large numbers</a><ul>
                        
                <li>
                    <a href="#strong-law-of-large-numbers" aria-label="Strong Law of large Numbers">Strong Law of large Numbers</a></li>
                <li>
                    <a href="#central-limit-theorem" aria-label="Central limit theorem">Central limit theorem</a></li></ul>
                </li>
                <li>
                    <a href="#monte-carlo-integration" aria-label="Monte carlo integration">Monte carlo integration</a><ul>
                        
                <li>
                    <a href="#importance-sampling" aria-label="Importance sampling">Importance sampling</a></li>
                <li>
                    <a href="#bound-on-samples" aria-label="Bound on samples">Bound on samples</a></li></ul>
                </li></ul>
                    
                <li>
                    <a href="#markov-chain-monte-carlo" aria-label="Markov Chain Monte Carlo">Markov Chain Monte Carlo</a><ul>
                        
                <li>
                    <a href="#metropolis-hastings" aria-label="Metropolis Hastings">Metropolis Hastings</a><ul>
                        
                <li>
                    <a href="#the-sampling-algorithm" aria-label="The Sampling Algorithm">The Sampling Algorithm</a></li>
                <li>
                    <a href="#stationary-distribution" aria-label="Stationary Distribution">Stationary Distribution</a></li>
                <li>
                    <a href="#con-distribuzioni-gaussiane" aria-label="Con distribuzioni Gaussiane">Con distribuzioni Gaussiane</a></li></ul>
                </li>
                <li>
                    <a href="#variations-and-improvements" aria-label="Variations and Improvements">Variations and Improvements</a><ul>
                        
                <li>
                    <a href="#metropolis-adjusted-langevin-algorithm" aria-label="Metropolis Adjusted Langevin Algorithm">Metropolis Adjusted Langevin Algorithm</a></li>
                <li>
                    <a href="#stochastic-gradient-langevin-dynamics" aria-label="Stochastic Gradient Langevin Dynamics">Stochastic Gradient Langevin Dynamics</a></li>
                <li>
                    <a href="#langevin-monte-carlo" aria-label="Langevin Monte Carlo">Langevin Monte Carlo</a></li>
                <li>
                    <a href="#landscape-of-sampling-methods" aria-label="Landscape of sampling methods">Landscape of sampling methods</a></li></ul>
                </li>
                <li>
                    <a href="#gibbs-sampling" aria-label="Gibbs Sampling">Gibbs Sampling</a><ul>
                        
                <li>
                    <a href="#the-idea" aria-label="The Idea">The Idea</a></li>
                <li>
                    <a href="#proof-of-correctness" aria-label="Proof of correctness">Proof of correctness</a></li>
                <li>
                    <a href="#a-simple-code-example" aria-label="A simple code example">A simple code example</a>
                </li>
            </ul>
            </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>DI Law of Large Numbers e Central limit theorem ne parliamo in <a href="/notes/central-limit-theorem-and-law-of-large-numbers">Central Limit Theorem and Law of Large Numbers</a>.
Usually these methods are useful when you need to calculate following something similar to Bayes rule, but don&rsquo;t know how to calculate the denominator, often infeasible integral. We estimate this value without explicitly calculating that.</p>
<p>Interested in $\mathbb{P}(x) = \frac{1}{z} \mathbb{P}^{*}(x) = \frac{1}{Z} e^{-E(x)}$
Can evaluate E(x) at any x.</p>
<ul>
<li>Problem 1 Make samples x(r) ~ 2 P</li>
<li>Problem 2 Estimate expectations  $\Phi = \sum_{x}\phi(x)\mathbb{P}(x)$)
What we&rsquo;re not trying to do:</li>
<li>We&rsquo;re not trying to find the most probable state.</li>
<li>We&rsquo;re not trying to visit all typical states.</li>
</ul>
<h3 id="law-of-large-numbers">Law of large numbers<a hidden class="anchor" aria-hidden="true" href="#law-of-large-numbers">#</a></h3>
$$
S_{n} = \sum^n_{i=1} x_{i} ,:, \bar{x}_{n} = \frac{S_{n}}{n}
$$$$
\bar{x}_{n} \to \mu
$$<p>
Ossia il limite converge sul valore atteso di tutte le variabili aleatorie.</p>
$$
var(\hat{x}_{n}) = \frac{\sigma^{2}}{n} \to 0
$$<h4 id="strong-law-of-large-numbers">Strong Law of large Numbers<a hidden class="anchor" aria-hidden="true" href="#strong-law-of-large-numbers">#</a></h4>
$$
\mathbb{P}(\lim_{ n \to \infty } \bar{x}_{n} =\mu) = 1
$$$$
\bar{h}_{n} = \sum_{i=1}^{n} \frac{h(x_{i})}{n}
$$<p>
E questo converge $O(\sqrt{ n })$ per la legge dopo.</p>
<h4 id="central-limit-theorem">Central limit theorem<a hidden class="anchor" aria-hidden="true" href="#central-limit-theorem">#</a></h4>
<p>Data una sequenza di variabili aleatorie, $X_{1}, X_{2}, \dots, X_{n}\dots$, tali che siano i.i.d tali per cui $E(X_{1}) = E(X_{2}) = \dots = E(X_{n}) =\dots = \mu$ tale che sia <strong>finito</strong>, e con varianza tutti uguali $= \sigma^{2}$ <strong>finito</strong>.</p>
$$
\sqrt{ n } (\hat{x}_{n} - \mu) \to N(0, \sigma^{2})
$$<p>
La prima parte è una <strong>variabile aleatoria</strong> e converge a quel valore. (questo permette di utilizzare la gaussiana quando $n$ è grande abbastanza).</p>
<h3 id="monte-carlo-integration">Monte carlo integration<a hidden class="anchor" aria-hidden="true" href="#monte-carlo-integration">#</a></h3>
$$
\int_{X} h(x) \cdot f(x) dx = E_{f}[h(x)] = \mu
$$<p>
Questo è tutto il significato dell&rsquo;integrazione di monte carlo (molte variabili aleatorie per stimare il valore di qualcosa).
E questo vale sempre, anche se $f$ non è una funzione di densità, basta che sia positiva (basta riscalare).</p>
<p>Il motivo per cui funziona è per LLN, perché abbiamo che convergerà su $\mu$ in lungo termine, basta considerare molte variabili aleatorie consecutive.</p>
<p>Cose interessanti:</p>
<ol>
<li>Posso stimare il valore atteso grazie a LLN</li>
<li>Posso stimare la varianza grazie ad essa</li>
<li>Posso stimare variabili condizionali.</li>
</ol>
<h4 id="importance-sampling">Importance sampling<a hidden class="anchor" aria-hidden="true" href="#importance-sampling">#</a></h4>
<ol>
<li>Deve soddisfare la cosa del supporto (contiene supporto sia di h che di f)</li>
<li>Deve avere <strong>varianza finita</strong> per i pesi che sono trovati. (ci sono metodi per stimare poi il $g$).
<ol>
<li>la frazione $\frac{f}{g}$ deve essere limitata e la varianza di $h$ rispetto alla densità $f$ deve essere finita.</li>
</ol>
</li>
</ol>
<h4 id="bound-on-samples">Bound on samples<a hidden class="anchor" aria-hidden="true" href="#bound-on-samples">#</a></h4>
<p>TODO: this should be interesting and important and should use Hoeffding&rsquo;s inequality.</p>
<h2 id="markov-chain-monte-carlo">Markov Chain Monte Carlo<a hidden class="anchor" aria-hidden="true" href="#markov-chain-monte-carlo">#</a></h2>
<p>L&rsquo;idea principale di Markov Chain Monte carlo è di costruire una <strong>catena di <a href="/notes/markov-chains">Markov</a></strong> tale che si possa utilizzare per generare dalla distribuzione difficilmente trattabile. Uno dei metodi principali per fare ciò è utilizzare tecniche si sampling.</p>
<h3 id="metropolis-hastings">Metropolis Hastings<a hidden class="anchor" aria-hidden="true" href="#metropolis-hastings">#</a></h3>
<h4 id="the-sampling-algorithm">The Sampling Algorithm<a hidden class="anchor" aria-hidden="true" href="#the-sampling-algorithm">#</a></h4>
<figure class="center">
<img src="/images/notes/Monte Carlo Methods-20241202181900146.webp" style="width: 100%"   alt="Monte Carlo Methods-20241202181900146" title="Monte Carlo Methods-20241202181900146"/>
<figcaption><p style="text-align:center;">From Bishop Deep Learning Book</p></figcaption>
</figure>
<p>We observe that this sampling algorithm takes idea from <a href="/notes/markov-chains">Markov Chains</a> balanced equation&rsquo;s property of stationary distributions and the <a href="/notes/accept-reject-algorithm">Accept Reject algorithm</a> for sampling some distributions. Also in this case, we don&rsquo;t care about the normalization constant for $p$, the distribution that we would like to sample from.
We choose the that acceptance probability as it allows us to satisfy the balance equation and thus, the stationary property of the constructed Chain.</p>
<p>With Metropolis-Hasting we need to</p>
<ol>
<li>Be able to calculate the density for the target distribution</li>
<li>Be able to sample easily from the $q$ distribution.
Then it has some links with <a href="/notes/diffusion-models">Random Walks</a> inside the space we want to sample.</li>
</ol>
$$
\alpha = \min\left(1, \frac{p(x')q(x \mid x')}{p(x)q(x' \mid x)}\right)
$$<p>
Where $x$ is the current state and $x'$ is the proposed state.</p>
<h4 id="stationary-distribution">Stationary Distribution<a hidden class="anchor" aria-hidden="true" href="#stationary-distribution">#</a></h4>
<p>We can prove that with that acceptance rate, the probability of transitioning in a given state satisfies the balance equation for the stationary distribution, which implies we can have a well behaved Markov Chain, and continue to sample from this.</p>
$$
p(x)q(x' \mid x) \alpha = p(x')q(x \mid x') \alpha
$$<p>
To prove this, just consider the two possible cases for the min function.</p>
<h4 id="con-distribuzioni-gaussiane">Con distribuzioni Gaussiane<a hidden class="anchor" aria-hidden="true" href="#con-distribuzioni-gaussiane">#</a></h4>
$$
\frac{r(x' \mid x)}{r(x \mid x')} = \frac{\mathcal{N}(x'; x, \tau I)}{\mathcal{N}(x; x', \tau I)} = 1
$$<p>
Quindi il coefficiente $\alpha$ si può scrivere anche solo come le distribuzioni $\frac{q(x)}{q(x')}$ che se si assume una distribuzione di Gibbs, si può intendere come un $\exp(f(x) - f(x'))$, che è di facile interpretazione.
Quindi possiamo fare sampling solamente considerando il rapporto fra le due distribuzioni.</p>
<h3 id="variations-and-improvements">Variations and Improvements<a hidden class="anchor" aria-hidden="true" href="#variations-and-improvements">#</a></h3>
<p>Metropolis-Hastings&rsquo; sample efficiency could be improved by adding information about the gradient of the distribution. This is the idea behind the Langevin algorithm.</p>
<h4 id="metropolis-adjusted-langevin-algorithm">Metropolis Adjusted Langevin Algorithm<a hidden class="anchor" aria-hidden="true" href="#metropolis-adjusted-langevin-algorithm">#</a></h4>
$$
r(x'\mid x) = \mathcal{N}(x'; x + \tau \nabla f(x), 2\tau I)\propto \exp\left( -\frac{1}{2} \left\| \frac{x' - x - \tau \nabla \log p(x)}{G} \right\|^2 \right),
$$<blockquote>
<p>§ It is possible to show that for log-concave distributions (e.g., Bayesian log. Regression), MALA efficiently converges to the stationary distribution (mixing time is polynomial in the dimension)</p></blockquote>
<p>Somehow, one can prove that if $\tau \to 0$ then the Metropolis Hastings tends to always accept the proposal, which is why it is more efficient.
The version of Metropolis Hastings that always accepts is called <em>Unadjusted Langevin Algorithm</em>.</p>
$$
p(\theta \mid x_{1:n}, y_{1:n}) = \frac{1}{Z} \exp(\log p(\theta) + \sum_{i=1}^{n} \log p(y_{i} \mid x_{i}, \theta))
$$$$
\theta_{t+1} = \theta_{t} + \tau \nabla_{\theta} \log p(\theta) + \tau \sum_{i=1}^{n} \nabla_{\theta} \log p(y_{i} \mid x_{i}, \theta) + \varepsilon 
$$<p>
Where $\varepsilon \sim \mathcal{N}(0, 2\tau I)$</p>
<p>The drawback of this method is that computing the energy for the whole dataset is expensive for large datasets. This is why sometimes we use a stochastic version of this algorithm. Which drives to the stochastic gradient Langevin dynamics.</p>
<h4 id="stochastic-gradient-langevin-dynamics">Stochastic Gradient Langevin Dynamics<a hidden class="anchor" aria-hidden="true" href="#stochastic-gradient-langevin-dynamics">#</a></h4>
<p>The double value for the Noise signal is justifiable if you study diffusion processes. So if you want to know how the $2$ factor comes into play when analyzing the process take a look at those courses.
One can also estimate the update of the gradient of the likelihood by having $m$ samples and then using that values for the update:
So the algorithm for the update becomes:</p>
<ol>
<li>Sample $m$ points and then update $\theta$ as follows:
$$
\theta_{t+1} = \theta_{t} + \tau \nabla_{\theta} \log p(\theta) + \tau\frac{n}{m} \sum_{i=1}^{m} \nabla_{\theta} \log p(y_{i} \mid x_{i}, \theta) + \varepsilon 
$$</li>
</ol>
<h4 id="langevin-monte-carlo">Langevin Monte Carlo<a hidden class="anchor" aria-hidden="true" href="#langevin-monte-carlo">#</a></h4>
<p>TODO: this is just an Outlook, and it is left out from here.</p>
<h4 id="landscape-of-sampling-methods">Landscape of sampling methods<a hidden class="anchor" aria-hidden="true" href="#landscape-of-sampling-methods">#</a></h4>
<p>we can broadly categorize optimization methods based on the use of</p>
<ul>
<li>Momentum</li>
<li>Stochasticity</li>
<li>Sampling
Then we would have this cube.
<img src="/images/notes/Monte Carlo Methods-20241104133523681.webp" style="width: 100%" class="center" alt="Monte Carlo Methods-20241104133523681"></li>
</ul>
<h3 id="gibbs-sampling">Gibbs Sampling<a hidden class="anchor" aria-hidden="true" href="#gibbs-sampling">#</a></h3>
<p>These are probably not very important for the exam.
We use a collapsed version of Gibbs Sampling for <a href="/notes/dirichlet-processes">Dirichlet Processes</a>.</p>
<h4 id="the-idea">The Idea<a hidden class="anchor" aria-hidden="true" href="#the-idea">#</a></h4>
<p>Gibbs sampling is a special case of Metropolis Hasting, in this case the proposal distribution $r$ is as follows:</p>
$$
r_{i}(x' \mid x) =
\begin{cases}
  p(x_{i}' \mid x'_{-i}) & \text{if } x' \text{ differs from } x \text{ only in } i \\
0  & \text{else} \\
\end{cases}
$$<p>
We just focus on a single coordinate difference.
Similar to the coordinate descent in some manner.</p>
<h4 id="proof-of-correctness">Proof of correctness<a hidden class="anchor" aria-hidden="true" href="#proof-of-correctness">#</a></h4>
<p>This sections proves that Gibbs Sampling indeed gives the original distribution. We will use a similar idea presented for <a href="/notes#metropolis-hastings">#Metropolis Hastings</a>.</p>
$$
\begin{align}
\alpha_{i}(x'\mid x) = \min \left(1, \frac{p(x')}{p(x)} \right) = 1
\end{align}
$$<h4 id="a-simple-code-example">A simple code example<a hidden class="anchor" aria-hidden="true" href="#a-simple-code-example">#</a></h4>
<p>This code example shows how we can sample from a multivariate Gaussian using Gibbs sampling. Note that we just need to be able to compute marginals in order to sample this.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Define parameters of the bivariate Gaussian</span>
</span></span><span class="line"><span class="cl"><span class="n">mu1</span><span class="p">,</span> <span class="n">mu2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span> <span class="c1"># Means</span>
</span></span><span class="line"><span class="cl"><span class="n">sigma1</span><span class="p">,</span> <span class="n">sigma2</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="c1"># Standard deviations</span>
</span></span><span class="line"><span class="cl"><span class="n">rho</span> <span class="o">=</span> <span class="mf">0.8</span> <span class="c1"># Correlation coefficient</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Derived quantities</span>
</span></span><span class="line"><span class="cl"><span class="n">cov</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">sigma1</span> <span class="o">*</span> <span class="n">sigma2</span> <span class="c1"># Covariance</span>
</span></span><span class="line"><span class="cl"><span class="n">Sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">sigma1</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">cov</span><span class="p">],</span> <span class="p">[</span><span class="n">cov</span><span class="p">,</span> <span class="n">sigma2</span><span class="o">**</span><span class="mi">2</span><span class="p">]])</span> <span class="c1"># Covariance matrix</span>
</span></span><span class="line"><span class="cl"><span class="n">Sigma_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Sigma</span><span class="p">)</span> <span class="c1"># Precision matrix</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Conditional distributions</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">sample_x1_given_x2</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">mu1</span><span class="p">,</span> <span class="n">mu2</span><span class="p">,</span> <span class="n">sigma1</span><span class="p">,</span> <span class="n">sigma2</span><span class="p">,</span> <span class="n">rho</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">cond_mean</span> <span class="o">=</span> <span class="n">mu1</span> <span class="o">+</span> <span class="n">rho</span> <span class="o">*</span> <span class="p">(</span><span class="n">sigma1</span> <span class="o">/</span> <span class="n">sigma2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">mu2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">cond_var</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">rho</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma1</span><span class="o">**</span><span class="mi">2</span>
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">cond_mean</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cond_var</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">sample_x2_given_x1</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">mu1</span><span class="p">,</span> <span class="n">mu2</span><span class="p">,</span> <span class="n">sigma1</span><span class="p">,</span> <span class="n">sigma2</span><span class="p">,</span> <span class="n">rho</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">cond_mean</span> <span class="o">=</span> <span class="n">mu2</span> <span class="o">+</span> <span class="n">rho</span> <span class="o">*</span> <span class="p">(</span><span class="n">sigma2</span> <span class="o">/</span> <span class="n">sigma1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x1</span> <span class="o">-</span> <span class="n">mu1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">cond_var</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">rho</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma2</span><span class="o">**</span><span class="mi">2</span>
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">cond_mean</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cond_var</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Gibbs Sampling</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">gibbs_sampling</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">burn_in</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">	<span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span> <span class="c1"># Initial values</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span> <span class="o">+</span> <span class="n">burn_in</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">		<span class="n">x1</span> <span class="o">=</span> <span class="n">sample_x1_given_x2</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">mu1</span><span class="p">,</span> <span class="n">mu2</span><span class="p">,</span> <span class="n">sigma1</span><span class="p">,</span> <span class="n">sigma2</span><span class="p">,</span> <span class="n">rho</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">x2</span> <span class="o">=</span> <span class="n">sample_x2_given_x1</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">mu1</span><span class="p">,</span> <span class="n">mu2</span><span class="p">,</span> <span class="n">sigma1</span><span class="p">,</span> <span class="n">sigma2</span><span class="p">,</span> <span class="n">rho</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="n">burn_in</span><span class="p">:])</span> <span class="c1"># Discard burn-in samples</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Run Gibbs Sampling</span>
</span></span><span class="line"><span class="cl"><span class="n">num_samples</span> <span class="o">=</span> <span class="mi">5000</span>
</span></span><span class="line"><span class="cl"><span class="n">samples</span> <span class="o">=</span> <span class="n">gibbs_sampling</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Plot results</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">samples</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;Samples&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;Gibbs Sampling: Bivariate Gaussian&#34;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;$X_1$&#34;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;$X_2$&#34;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://flecart.github.io/tags/probabilistic-artificial-intelligence/">➕Probabilistic-Artificial-Intelligence</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Monte Carlo Methods on x"
            href="https://x.com/intent/tweet/?text=Monte%20Carlo%20Methods&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fmonte-carlo-methods%2f&amp;hashtags=%e2%9e%95probabilistic-artificial-intelligence">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Monte Carlo Methods on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fmonte-carlo-methods%2f&amp;title=Monte%20Carlo%20Methods&amp;summary=Monte%20Carlo%20Methods&amp;source=https%3a%2f%2fflecart.github.io%2fnotes%2fmonte-carlo-methods%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Monte Carlo Methods on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fflecart.github.io%2fnotes%2fmonte-carlo-methods%2f&title=Monte%20Carlo%20Methods">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Monte Carlo Methods on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fflecart.github.io%2fnotes%2fmonte-carlo-methods%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Monte Carlo Methods on whatsapp"
            href="https://api.whatsapp.com/send?text=Monte%20Carlo%20Methods%20-%20https%3a%2f%2fflecart.github.io%2fnotes%2fmonte-carlo-methods%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Monte Carlo Methods on telegram"
            href="https://telegram.me/share/url?text=Monte%20Carlo%20Methods&amp;url=https%3a%2f%2fflecart.github.io%2fnotes%2fmonte-carlo-methods%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Monte Carlo Methods on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Monte%20Carlo%20Methods&u=https%3a%2f%2fflecart.github.io%2fnotes%2fmonte-carlo-methods%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://flecart.github.io/">X. Angelo Huang&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
