<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Autoencoders | X. A. Huang&#39;s Blog</title>
<meta name="keywords" content="machinelearning">
<meta name="description" content="In questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders Blog di riferimento Blog secondario che sembra buono
Introduzione agli autoencoders L&rsquo;idea degli autoencoders è rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso è la compressione con loss. Per cosa intendiamo qualunque tipologia di dato, che può spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder.">
<meta name="author" content="Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="http://localhost:1313/content/notes/autoencoders/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/content/notes/autoencoders/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-WW6NN2QGKF', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="Autoencoders" />
<meta property="og:description" content="In questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders Blog di riferimento Blog secondario che sembra buono
Introduzione agli autoencoders L&rsquo;idea degli autoencoders è rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso è la compressione con loss. Per cosa intendiamo qualunque tipologia di dato, che può spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/content/notes/autoencoders/" />
<meta property="og:image" content="http://localhost:1313/images/papermod-cover.png" />
<meta property="article:section" content="notes" />



<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://localhost:1313/images/papermod-cover.png" />
<meta name="twitter:title" content="Autoencoders"/>
<meta name="twitter:description" content="In questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders Blog di riferimento Blog secondario che sembra buono
Introduzione agli autoencoders L&rsquo;idea degli autoencoders è rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso è la compressione con loss. Per cosa intendiamo qualunque tipologia di dato, che può spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "http://localhost:1313/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Autoencoders",
      "item": "http://localhost:1313/content/notes/autoencoders/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Autoencoders",
  "name": "Autoencoders",
  "description": "In questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders Blog di riferimento Blog secondario che sembra buono\nIntroduzione agli autoencoders L\u0026rsquo;idea degli autoencoders è rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso è la compressione con loss. Per cosa intendiamo qualunque tipologia di dato, che può spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder.",
  "keywords": [
    "machinelearning"
  ],
  "articleBody": "In questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders Blog di riferimento Blog secondario che sembra buono\nIntroduzione agli autoencoders L’idea degli autoencoders è rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso è la compressione con loss. Per cosa intendiamo qualunque tipologia di dato, che può spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder. Una volta scelta una tipologia di dato, come per gli algoritmi di compressione, valutiamo come buono il modello che riesce a comprimere in modo efficiente e decomprimere in modo fedele rispetto all’originale. Abbiamo quindi un trade-off fra spazio latente, che è lo spazio in cui sono presenti gli elementi compressi, e la qualità della ricostruzione. Possiamo infatti osservare che se spazio latente = spazio originale, loss di ricostruzione = 0 perché basta imparare l’identità. In questo senso si può dire che diventa sensato solo quando lo spazio originale sia minore di qualche fattore rispetto all’originale. Quando si ha questo, abbiamo più difficoltà di ricostruzione, e c’è una leggera perdita in questo senso.\nProprietà interessanti Vogliamo in un certo senso imporre una regolarità nello spazio latente perché questo ci permette di esprimere in un modo più coerente da quanto ci attendiamo le cose dello spazio:\nSe prendiamo un punto vicino a un encoding noto, ci aspettiamo che sia simile al punto stesso Se prendiamo un punto del nostro spazio latente ci aspettiamo che dia qualcosa di sensato Rispettivamente queste proprietà sono state chiamate continuità e completezza.\nVariational Auto-Encoders Intuizione L’idea sembra avere uno spazio regolarizzato, ossia un $z \\sim \\mathcal{N}(\\mu, \\sigma^{2}I)$ con $\\sigma$ vettore di dimensione spazio latente e $\\mu$ degli offset che rappresentano media. Quindi il decoder parametrizzato secondo $\\theta$ dovrà essere in una forma dipendente da questa.\nInsieme a questo utilizziamo anche un encoder parametrizzato con $\\phi$ che dovrà darci indicazioni su $z$, per esempio media e varianza.\nSecondo Murphy-1, Questo dovrebbe essere molto simile a un lavoro di uno 95, vedi capitolo su VAE in que libro.\nLa formulazione dei VAE sembra molto simile ai Factor Analysis. Che è una caratterizzazione di un certo tipo sia spazio latente che quello normale.\nSetting del problema In questo senso vogliamo cercare di regolarizzare il nostro spazio latente assumendo che $$ p(x | z) \\sim \\mathrm{N}(media, varianza) $$ Ossia i samples della parte condizionata nello spazio latente non sono altro che una media e varianza dipendenti solo dalla parte condizionale, mentre $p(z) = N(0, 1)$ multidimensionale (quindi varianza $I$)\nELBO e derivazione Se assumiamo questo, allora la loss di Kullback-Leibler diventa abbastanza carina, perché infatti abbiamo che\n$$ KL(q_{x}(z), p(z|x)) = E_{x \\sim q_{x} }(\\log(q_{x}(z))) - E_{x \\sim q_{x}}\\left(\\log( \\frac{p(x, z)}{p(x)}) \\right) $$ $$ = E_{x \\sim q_{x}}(\\log(q_{x}(z))) - E_{x \\sim q_{x}}(\\log(p(x, z))) + E_{z \\sim q_{x}}(\\log(p(x))) = E_{z \\sim q_{x}}(\\log(p(x))) - E_{z \\sim q_{x}}\\left( \\log\\left( \\frac{p(x, z)}{q_{x}(z)} \\right) \\right) $$ Ora le ultime due si chiamano rispettivamente evidence e ELBO che sta per Evidence Lower Bound Notiamo che la evidence non dipende da $z$, infatti avremmo che $$ E_{z \\sim q_{x}}(p(x)) = \\int {-\\infty}^{+\\infty} q{x}(z) p(x) , dz = p(x) \\int {-\\infty}^{+\\infty} q{x}(z) dz = p(x) $$ Quindi se vogliamo minimizzare la divergenza, ci basta Massimizzare ELBO nel nostro caso.\nEsplicitazione di ELBO Possiamo lavorare ancora di più su ELBO, provando ad esplicitarne alcuni valori, infatti possiamo considerare\n$$ ELBO = E_{z \\sim q_{x}}\\left( \\log\\left( \\frac{p(x, z)}{q_{x}(z)} \\right) \\right) =E_{z \\sim q_{x}}\\left( \\log\\left( p(x|z) \\right) \\right) + E_{z \\sim q_{x}}\\left( \\log\\left( \\frac{p(z)}{q_{x}(z)} \\right) \\right) $$ $$ = E_{z \\sim q_{x}}\\left( \\log\\left( p(x|z) \\right) \\right) - KL(q_{x}(z), p(z)) $$\nOssia abbiamo il secondo termine che prova a regolarizzare la distribuzione $q$ trovata, e il primo termine che è un maximum likelihood, simile a quanto trovato per Naïve Bayes nel corso di Asperti. Questo è la nostra loss per il VAE.\nOra l’ultimo passo sarebbe come esplicitare ELBO in modo che possa essere implementato come loss di una net?\nDerivazione della loss per VAE Vedere qui, è calcolosa, ma molto carina, e ti permette di impratichirti con gaussiane multivariabili.\nAlla fine si avrà come risultato:\n$$ KL(q_{x}(z), p(z)) = -\\frac{1}{2} \\sum_{j=1}^{J}(1 + \\log \\sigma^{2}{j} - \\mu^{2}{j} - \\sigma^{2}_{j}) $$ Derivazione di KL per la loss Vedere https://mr-easy.github.io/2020-04-16-kl-divergence-between-2-gaussian-distributions/. E poi sostituire. Per l’expectation della forma quadratica vedere qui https://statproofbook.github.io/P/mean-qf.html.\nAllora, sappiamo che $p(z) = \\mathcal{N}(0, \\mathcal{I})$ quindi ha una forma ben nota, dovremo cercare di fare questa piccolissima derivazione.\n",
  "wordCount" : "745",
  "inLanguage": "en",
  "image": "http://localhost:1313/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/content/notes/autoencoders/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. A. Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="X. A. Huang&#39;s Blog (Alt + H)">X. A. Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Autoencoders
    </h1>
    <div class="post-meta">4 min&nbsp;·&nbsp;Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul>
                <li>
                    <a href="#introduzione-agli-autoencoders" aria-label="Introduzione agli autoencoders">Introduzione agli autoencoders</a></li>
                <li>
                    <a href="#propriet%c3%a0-interessanti" aria-label="Proprietà interessanti">Proprietà interessanti</a></li></ul>
                    
                <li>
                    <a href="#variational-auto-encoders" aria-label="Variational Auto-Encoders">Variational Auto-Encoders</a><ul>
                        
                <li>
                    <a href="#intuizione" aria-label="Intuizione">Intuizione</a></li>
                <li>
                    <a href="#setting-del-problema" aria-label="Setting del problema">Setting del problema</a></li>
                <li>
                    <a href="#elbo-e-derivazione" aria-label="ELBO e derivazione">ELBO e derivazione</a><ul>
                        
                <li>
                    <a href="#esplicitazione-di-elbo" aria-label="Esplicitazione di ELBO">Esplicitazione di ELBO</a></li>
                <li>
                    <a href="#derivazione-della-loss-per-vae" aria-label="Derivazione della loss per VAE">Derivazione della loss per VAE</a>
                </li>
            </ul>
            </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>In questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders
<a href="https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73">Blog di riferimento</a>
<a href="https://mbernste.github.io/posts/vae/">Blog secondario che sembra buono</a></p>
<h3 id="introduzione-agli-autoencoders">Introduzione agli autoencoders<a hidden class="anchor" aria-hidden="true" href="#introduzione-agli-autoencoders">#</a></h3>
<p>L&rsquo;idea degli autoencoders è rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso è la compressione con loss.
Per cosa intendiamo qualunque tipologia di dato, che può spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder.
Una volta scelta una tipologia di dato, come per gli algoritmi di compressione, valutiamo come buono il modello che riesce a comprimere in modo efficiente e decomprimere in modo fedele rispetto all&rsquo;originale.
Abbiamo quindi un trade-off fra spazio latente, che è lo spazio in cui sono presenti gli elementi compressi, e la qualità della ricostruzione.
Possiamo infatti osservare che se <strong>spazio latente = spazio originale, loss di ricostruzione = 0</strong> perché basta imparare l&rsquo;identità.
In questo senso si può dire che diventa sensato solo quando lo spazio originale sia minore di qualche fattore rispetto all&rsquo;originale. Quando si ha questo, abbiamo più difficoltà di ricostruzione, e c&rsquo;è una leggera perdita in questo senso.</p>
<h3 id="proprietà-interessanti">Proprietà interessanti<a hidden class="anchor" aria-hidden="true" href="#proprietà-interessanti">#</a></h3>
<p>Vogliamo in un certo senso imporre una <strong>regolarità nello spazio latente</strong> perché questo ci permette di esprimere in un modo più coerente da quanto ci attendiamo le cose dello spazio:</p>
<ol>
<li>Se prendiamo un punto vicino a un encoding noto, ci aspettiamo che sia simile al punto stesso</li>
<li>Se prendiamo un punto del nostro spazio latente ci aspettiamo che dia qualcosa di sensato</li>
</ol>
<p>Rispettivamente queste proprietà sono state chiamate <strong>continuità e completezza</strong>.</p>
<h2 id="variational-auto-encoders">Variational Auto-Encoders<a hidden class="anchor" aria-hidden="true" href="#variational-auto-encoders">#</a></h2>
<h3 id="intuizione">Intuizione<a hidden class="anchor" aria-hidden="true" href="#intuizione">#</a></h3>
<p>L&rsquo;idea sembra avere uno spazio regolarizzato, ossia un
$z \sim \mathcal{N}(\mu, \sigma^{2}I)$ con $\sigma$ vettore di dimensione spazio latente e $\mu$ degli offset che rappresentano media.
Quindi il decoder parametrizzato secondo $\theta$ dovrà essere in una forma dipendente da questa.</p>
<p>Insieme a questo utilizziamo anche un encoder parametrizzato con $\phi$ che dovrà darci indicazioni su $z$, per esempio media e varianza.</p>
<p>Secondo Murphy-1, Questo dovrebbe essere molto simile a un lavoro di uno 95, vedi capitolo su VAE in que libro.</p>
<p>La formulazione dei VAE sembra molto simile ai Factor Analysis. Che è una caratterizzazione di un certo tipo sia spazio latente che quello normale.</p>
<h3 id="setting-del-problema">Setting del problema<a hidden class="anchor" aria-hidden="true" href="#setting-del-problema">#</a></h3>
<p>In questo senso vogliamo cercare di regolarizzare il nostro spazio latente assumendo che
$$
p(x | z) \sim \mathrm{N}(media, varianza)
$$
Ossia i samples della parte condizionata nello spazio latente non sono altro che una media e varianza dipendenti solo dalla parte condizionale, mentre $p(z) = N(0, 1)$ multidimensionale (quindi varianza $I$)</p>
<h3 id="elbo-e-derivazione">ELBO e derivazione<a hidden class="anchor" aria-hidden="true" href="#elbo-e-derivazione">#</a></h3>
<p>Se assumiamo questo, allora la loss di Kullback-Leibler diventa abbastanza carina, perché infatti abbiamo che</p>
<h1 id="klq_xz-pzx--e_x-sim-q_x-logq_xz---e_x-sim-q_xleftlog-fracpx-zpx-right">$$
KL(q_{x}(z), p(z|x)) = E_{x \sim q_{x} }(\log(q_{x}(z))) - E_{x \sim q_{x}}\left(\log( \frac{p(x, z)}{p(x)}) \right)</h1>
<p>$$
$$
= E_{x \sim q_{x}}(\log(q_{x}(z))) - E_{x \sim q_{x}}(\log(p(x, z))) + E_{z \sim q_{x}}(\log(p(x)))
= E_{z \sim q_{x}}(\log(p(x)))  - E_{z \sim q_{x}}\left( \log\left( \frac{p(x, z)}{q_{x}(z)} \right) \right)
$$
Ora le ultime due si chiamano rispettivamente <strong>evidence</strong> e <strong>ELBO</strong> che sta per Evidence Lower Bound
Notiamo che la evidence non dipende da $z$, infatti avremmo che
$$
E_{z \sim q_{x}}(p(x))  = \int <em>{-\infty}^{+\infty} q</em>{x}(z) p(x) , dz = p(x)  \int <em>{-\infty}^{+\infty} q</em>{x}(z) dz = p(x)
$$
Quindi se vogliamo minimizzare la divergenza, ci basta Massimizzare ELBO nel nostro caso.</p>
<h4 id="esplicitazione-di-elbo">Esplicitazione di ELBO<a hidden class="anchor" aria-hidden="true" href="#esplicitazione-di-elbo">#</a></h4>
<p>Possiamo lavorare ancora di più su ELBO, provando ad esplicitarne alcuni valori, infatti possiamo considerare</p>
<p>$$
ELBO = E_{z \sim q_{x}}\left( \log\left( \frac{p(x, z)}{q_{x}(z)} \right) \right)
=E_{z \sim q_{x}}\left( \log\left( p(x|z) \right) \right)  + E_{z \sim q_{x}}\left( \log\left( \frac{p(z)}{q_{x}(z)} \right) \right)
$$
$$
= E_{z \sim q_{x}}\left( \log\left( p(x|z) \right) \right)  - KL(q_{x}(z), p(z))
$$</p>
<p>Ossia abbiamo il secondo termine che prova a regolarizzare la distribuzione $q$ trovata, e il primo termine che è un maximum likelihood, simile a quanto trovato per <a href="//notes/na%C3%AFve-bayes">Naïve Bayes</a> nel corso di Asperti.
Questo è la nostra loss per il VAE.</p>
<p>Ora l&rsquo;ultimo passo sarebbe come esplicitare ELBO in modo che possa essere implementato come loss di una net?</p>
<h4 id="derivazione-della-loss-per-vae">Derivazione della loss per VAE<a hidden class="anchor" aria-hidden="true" href="#derivazione-della-loss-per-vae">#</a></h4>
<p>Vedere <a href="https://mbernste.github.io/posts/vae/#appendix-derivation-of-the-kl-divergence-term-when-the-variational-posterior-and-prior-are-gaussian">qui</a>, è calcolosa, ma molto carina, e ti permette di impratichirti con gaussiane multivariabili.</p>
<p>Alla fine si avrà come risultato:</p>
<p>$$
KL(q_{x}(z), p(z)) = -\frac{1}{2} \sum_{j=1}^{J}(1 + \log \sigma^{2}<em>{j} - \mu^{2}</em>{j} - \sigma^{2}_{j})
$$
<strong>Derivazione di KL</strong> per la loss
Vedere <a href="https://mr-easy.github.io/2020-04-16-kl-divergence-between-2-gaussian-distributions/.">https://mr-easy.github.io/2020-04-16-kl-divergence-between-2-gaussian-distributions/.</a>
E poi sostituire.
Per l&rsquo;expectation della forma quadratica vedere qui <a href="https://statproofbook.github.io/P/mean-qf.html.">https://statproofbook.github.io/P/mean-qf.html.</a></p>
<p>Allora, sappiamo che $p(z) = \mathcal{N}(0, \mathcal{I})$ quindi ha una forma ben nota, dovremo cercare di fare questa piccolissima derivazione.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/machinelearning/">Machinelearning</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Autoencoders on x"
            href="https://x.com/intent/tweet/?text=Autoencoders&amp;url=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fautoencoders%2f&amp;hashtags=machinelearning">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Autoencoders on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fautoencoders%2f&amp;title=Autoencoders&amp;summary=Autoencoders&amp;source=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fautoencoders%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Autoencoders on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fautoencoders%2f&title=Autoencoders">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Autoencoders on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fautoencoders%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Autoencoders on whatsapp"
            href="https://api.whatsapp.com/send?text=Autoencoders%20-%20http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fautoencoders%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Autoencoders on telegram"
            href="https://telegram.me/share/url?text=Autoencoders&amp;url=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fautoencoders%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Autoencoders on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Autoencoders&u=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fautoencoders%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="http://localhost:1313/">X. A. Huang&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
