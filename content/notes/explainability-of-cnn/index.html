<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Explainability of CNN | X. A. Huang&#39;s Blog</title>
<meta name="keywords" content="no-tags">
<meta name="description" content="Ultima modifica: April 4, 2023 6:19 PM Primo Abbozzo: April 1, 2023 11:11 AM Studi Personali: No
Elementi di ripasso Explainability of CNN Introduction Capire in che modo una rete convoluzionale ci può dare insight migliori su come funzionano questi networks.
Visualizzazione dei hidden layers Slide visualization
Potremmo fissare una immagine anche a caso, e modificare la x in modo che sia più simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa.">
<meta name="author" content="Xuanqiang &#39;Angelo&#39; Huang">
<link rel="canonical" href="http://localhost:1313/content/notes/explainability-of-cnn/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/content/notes/explainability-of-cnn/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-WW6NN2QGKF"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-WW6NN2QGKF', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="Explainability of CNN" />
<meta property="og:description" content="Ultima modifica: April 4, 2023 6:19 PM Primo Abbozzo: April 1, 2023 11:11 AM Studi Personali: No
Elementi di ripasso Explainability of CNN Introduction Capire in che modo una rete convoluzionale ci può dare insight migliori su come funzionano questi networks.
Visualizzazione dei hidden layers Slide visualization
Potremmo fissare una immagine anche a caso, e modificare la x in modo che sia più simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/content/notes/explainability-of-cnn/" />
<meta property="og:image" content="http://localhost:1313/images/papermod-cover.png" />
<meta property="article:section" content="notes" />



<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://localhost:1313/images/papermod-cover.png" />
<meta name="twitter:title" content="Explainability of CNN"/>
<meta name="twitter:description" content="Ultima modifica: April 4, 2023 6:19 PM Primo Abbozzo: April 1, 2023 11:11 AM Studi Personali: No
Elementi di ripasso Explainability of CNN Introduction Capire in che modo una rete convoluzionale ci può dare insight migliori su come funzionano questi networks.
Visualizzazione dei hidden layers Slide visualization
Potremmo fissare una immagine anche a caso, e modificare la x in modo che sia più simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "http://localhost:1313/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Explainability of CNN",
      "item": "http://localhost:1313/content/notes/explainability-of-cnn/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Explainability of CNN",
  "name": "Explainability of CNN",
  "description": "Ultima modifica: April 4, 2023 6:19 PM Primo Abbozzo: April 1, 2023 11:11 AM Studi Personali: No\nElementi di ripasso Explainability of CNN Introduction Capire in che modo una rete convoluzionale ci può dare insight migliori su come funzionano questi networks.\nVisualizzazione dei hidden layers Slide visualization\nPotremmo fissare una immagine anche a caso, e modificare la x in modo che sia più simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa.",
  "keywords": [
    "no-tags"
  ],
  "articleBody": "Ultima modifica: April 4, 2023 6:19 PM Primo Abbozzo: April 1, 2023 11:11 AM Studi Personali: No\nElementi di ripasso Explainability of CNN Introduction Capire in che modo una rete convoluzionale ci può dare insight migliori su come funzionano questi networks.\nVisualizzazione dei hidden layers Slide visualization\nPotremmo fissare una immagine anche a caso, e modificare la x in modo che sia più simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa.\nForse questo è anche il metodo con cui vengono generate le immagini??\nExamples of extracted patterns\nProbabilmente tutte le CNN vanno quindi a tentare ad estrarre questo genere di patterns dall’immagine iniziale.\nRicreazione di immagini Vogliamo computare la rappresentazione interna dell’immagine, ossia l’attivazione prodotta da una certa immagine, e da questo possiamo sintetizzare una immagine e poi continuare a fare gradient descent su questa per massimizzare. Una volta al minimo dovremmo avere l’immagine migliore per questo layer.\nSlide di esempio\nPer un certo layer non c’è differenza fra quei 6 immagini\nQuindi prima partivamo da noise, da questo partiamo da una immagine già e guardiamo in che modo è rappresentato in questo layer.\nSlide sulla tecnica di solito utilizzata per queste\nSi puònotare che è più difficile recovery dell’immagine nei layers lontani, probabilmente perché sta creando una specie di astrazione dell’immagine iniziale, quindi l’immagine sarebbe l’immagine dell’astrazione. Riusciamo a visualizzare una astrazione, che sembra una contraddizione.\nInceptionism Style transfer Come facciamo a ricreare una immagine utilizzando lo stile di un certo autore?\nEsempi di risultati con style transfer\nMa come facciamo a catturare un concetto astratto di stile di un certo autore?\nConcetto di stile di un autore Non vogliamo solamente avere un contenuto simile (come abbiamo fatto prima, nei primi layers è una cosa abbastanza semplice) vorremmo proprio essere in grado di catturare lo stile dell’artista. Quindi da un punto di vista astratto\nSlides stile autore\nCi interessa la correlazione fra features maps di un certo livello, e quando abbiamo una immagine vogliamo allenare per massimizzare la similitudine con la correlazione fra le feature maps.\nData manifolds perché facile ingannare le reti Si può vedere che con le tecniche dello stile si possono ingannare molto facilmente le reti di sopra. Questo è perché fanno delle classificazioni, fanno discriminazione anziché generazione. Ossia con generazione provo a stimare la probabilità iniziale che si sia creato la cosa che vogliamo classficiare e con questa probabilità poi andiamo a fare la predizione.\nInvece nelle tecniche discriminazione vanno solamente a fare una discriminazione di dati, una cosa statistica. (la frontiera può essere molto diversa rispetto alla funzione che lo ha generata diciamo.\nSeguendo comunque il ragionamento sui manifolds di data possiamo dire che è molto improbabile ~0, che generando a caso, sia una immagine sensata. Infatti lo spazio delle immagini è enorme, la maggior parte sono ranodm per umani, però stiamo provando a fare questo un modello di discriminazione (quindi è chiaro che molte zone che per noi non hanno senso, sono rappresentate nella rete neurale come categorizzate in un certo modo).\nAutoencoders Vogliamo cercare di cambiare lo spazio in modo che la parte delle immagini sensate sia meglio descrivibile, vogliamo andare in pratica a creare una descrizione compatta di quello che vogliamo analizzare. Con gli autoencoder andremo proprio a comprimere il data manifold e poi lavorare su questa compressione.\nSlide intuizione autoencoder\nQuello che vorremmo fare è una funzione identità per certe cose (dato che sono meno, non possiamo fare altro che perdere altre informazioni, ma vogliamo solamente perdere informazioni che non ci servano).\nPossiblità della compressione\nLa compressione dovrebbe essere possibile perché stiamo cercando regolarità nel data, cosa che ci dovrebbe essere perché noi umani riusciamo a riconoscere questi pattern, non riusciamo ad insegnarlo ad una macchina. (quando è molto random però non si può comprimere, stranamente il random è la cosa con più informazione in termini di teoria dell’informazione, ma meno informazione per noi umani, che strana questa asimmetria).\nCaratteristiche della compressione\nSlide caratteristiche\nLa cosa di maggior rilievo è il fatto del loss, che non riusciamo a fare un reverse che diventi proprio uguale! E poi funziona solamente con data simili (con caratteristiche fortemente correlate fra di loro.\n",
  "wordCount" : "717",
  "inLanguage": "en",
  "image": "http://localhost:1313/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Xuanqiang 'Angelo' Huang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/content/notes/explainability-of-cnn/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "X. A. Huang's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="X. A. Huang&#39;s Blog (Alt + H)">X. A. Huang&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/notes/">Notes</a></div>
    <h1 class="post-title entry-hint-parent">
      Explainability of CNN
    </h1>
    <div class="post-meta">4 min&nbsp;·&nbsp;Xuanqiang &#39;Angelo&#39; Huang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#elementi-di-ripasso" aria-label="Elementi di ripasso">Elementi di ripasso</a></li>
                <li>
                    <a href="#explainability-of-cnn" aria-label="Explainability of CNN">Explainability of CNN</a><ul>
                        
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a><ul>
                        
                <li>
                    <a href="#visualizzazione-dei-hidden-layers" aria-label="Visualizzazione dei hidden layers">Visualizzazione dei hidden layers</a></li>
                <li>
                    <a href="#ricreazione-di-immagini" aria-label="Ricreazione di immagini">Ricreazione di immagini</a></li></ul>
                </li>
                <li>
                    <a href="#inceptionism" aria-label="Inceptionism">Inceptionism</a></li>
                <li>
                    <a href="#style-transfer" aria-label="Style transfer">Style transfer</a><ul>
                        
                <li>
                    <a href="#concetto-di-stile-di-un-autore" aria-label="Concetto di stile di un autore">Concetto di stile di un autore</a></li></ul>
                </li>
                <li>
                    <a href="#data-manifolds" aria-label="Data manifolds">Data manifolds</a><ul>
                        
                <li>
                    <a href="#perch%c3%a9-facile-ingannare-le-reti" aria-label="perché facile ingannare le reti">perché facile ingannare le reti</a></li>
                <li>
                    <a href="#autoencoders" aria-label="Autoencoders">Autoencoders</a>
                </li>
            </ul>
            </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Ultima modifica: April 4, 2023 6:19 PM
Primo Abbozzo: April 1, 2023 11:11 AM
Studi Personali: No</p>
<h1 id="elementi-di-ripasso">Elementi di ripasso<a hidden class="anchor" aria-hidden="true" href="#elementi-di-ripasso">#</a></h1>
<h1 id="explainability-of-cnn">Explainability of CNN<a hidden class="anchor" aria-hidden="true" href="#explainability-of-cnn">#</a></h1>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>Capire in che modo una rete convoluzionale ci può dare insight migliori su come funzionano questi networks.</p>
<h3 id="visualizzazione-dei-hidden-layers">Visualizzazione dei hidden layers<a hidden class="anchor" aria-hidden="true" href="#visualizzazione-dei-hidden-layers">#</a></h3>
<ul>
<li>
<p>Slide visualization</p>
  <img src="/images/notes/image/universita/ex-notion/Explainability of CNN/Untitled.png" alt="image/universita/ex-notion/Explainability of CNN/Untitled">
</li>
</ul>
<p>Potremmo fissare una immagine anche a caso, e modificare la x in modo che sia più simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa.</p>
<p>Forse questo è anche il metodo con cui vengono generate le immagini??</p>
<ul>
<li>
<p>Examples of extracted patterns</p>
  <img src="/images/notes/image/universita/ex-notion/Explainability of CNN/Untitled 1.png" alt="image/universita/ex-notion/Explainability of CNN/Untitled 1">
</li>
</ul>
<p>Probabilmente tutte le CNN vanno quindi a tentare ad estrarre questo genere di patterns dall’immagine iniziale.</p>
<h3 id="ricreazione-di-immagini">Ricreazione di immagini<a hidden class="anchor" aria-hidden="true" href="#ricreazione-di-immagini">#</a></h3>
<p>Vogliamo <strong>computare la rappresentazione interna dell’immagine</strong>, ossia l’attivazione prodotta da una certa immagine, e da questo possiamo sintetizzare una immagine e poi continuare a fare gradient descent su questa per massimizzare. Una volta al minimo dovremmo avere l’immagine migliore per questo layer.</p>
<ul>
<li>
<p>Slide di esempio</p>
  <img src="/images/notes/image/universita/ex-notion/Explainability of CNN/Untitled 2.png" alt="image/universita/ex-notion/Explainability of CNN/Untitled 2">
<p>Per un certo layer non c’è differenza fra quei 6 immagini</p>
</li>
</ul>
<p>Quindi prima partivamo da noise, da questo partiamo da una immagine già e guardiamo in che modo è rappresentato in questo layer.</p>
<ul>
<li>
<p>Slide sulla tecnica di solito utilizzata per queste</p>
  <img src="/images/notes/image/universita/ex-notion/Explainability of CNN/Untitled 3.png" alt="image/universita/ex-notion/Explainability of CNN/Untitled 3">
</li>
</ul>
<p>Si puònotare che è <strong>più difficile recovery dell’immagine nei layers lontani</strong>, probabilmente perché sta creando una specie di astrazione dell’immagine iniziale, quindi l’immagine sarebbe l’immagine dell’astrazione. Riusciamo a visualizzare una astrazione, che sembra una contraddizione.</p>
<h2 id="inceptionism">Inceptionism<a hidden class="anchor" aria-hidden="true" href="#inceptionism">#</a></h2>
<h2 id="style-transfer">Style transfer<a hidden class="anchor" aria-hidden="true" href="#style-transfer">#</a></h2>
<p>Come facciamo a ricreare una immagine utilizzando lo stile di un certo autore?</p>
<ul>
<li>
<p>Esempi di risultati con style transfer</p>
  <img src="/images/notes/image/universita/ex-notion/Explainability of CNN/Untitled 4.png" alt="image/universita/ex-notion/Explainability of CNN/Untitled 4">
  <img src="/images/notes/image/universita/ex-notion/Explainability of CNN/Untitled 5.png" alt="image/universita/ex-notion/Explainability of CNN/Untitled 5">
</li>
</ul>
<p>Ma come facciamo a catturare un concetto astratto di stile di un certo autore?</p>
<h3 id="concetto-di-stile-di-un-autore">Concetto di stile di un autore<a hidden class="anchor" aria-hidden="true" href="#concetto-di-stile-di-un-autore">#</a></h3>
<p>Non vogliamo solamente avere un contenuto simile (come abbiamo fatto prima, nei primi layers è una cosa abbastanza semplice) vorremmo proprio essere in grado di <strong>catturare lo stile dell’artista</strong>. Quindi da un punto di vista astratto</p>
<ul>
<li>
<p>Slides stile autore</p>
  <img src="/images/notes/image/universita/ex-notion/Explainability of CNN/Untitled 6.png" alt="image/universita/ex-notion/Explainability of CNN/Untitled 6">
</li>
</ul>
<p>Ci interessa la <strong>correlazione fra features maps</strong> di un certo livello, e quando abbiamo una immagine vogliamo allenare per massimizzare la similitudine con la correlazione fra le feature maps.</p>
<h2 id="data-manifolds">Data manifolds<a hidden class="anchor" aria-hidden="true" href="#data-manifolds">#</a></h2>
<h3 id="perché-facile-ingannare-le-reti">perché facile ingannare le reti<a hidden class="anchor" aria-hidden="true" href="#perché-facile-ingannare-le-reti">#</a></h3>
<p>Si può vedere che con le tecniche dello stile si possono <strong>ingannare molto facilmente le reti</strong> di sopra. Questo è perché fanno delle classificazioni, fanno discriminazione anziché generazione. Ossia con generazione provo a stimare la probabilità iniziale che si sia creato la cosa che vogliamo classficiare e con questa probabilità poi andiamo a fare la predizione.</p>
<p>Invece nelle tecniche discriminazione vanno solamente a fare una discriminazione di dati, una cosa statistica. (la frontiera può essere molto diversa rispetto alla funzione che lo ha generata diciamo.</p>
<p>Seguendo comunque il ragionamento sui manifolds di data possiamo dire che <strong>è molto improbabile ~0, che generando a caso, sia una immagine sensata</strong>. Infatti lo spazio delle immagini è enorme, la maggior parte sono ranodm per umani, però stiamo provando a fare questo un modello di discriminazione (quindi è chiaro che molte zone che per noi non hanno senso, sono rappresentate nella rete neurale come categorizzate in un certo modo).</p>
<h3 id="autoencoders">Autoencoders<a hidden class="anchor" aria-hidden="true" href="#autoencoders">#</a></h3>
<p>Vogliamo cercare di cambiare lo spazio in modo che la parte delle immagini sensate sia meglio descrivibile, vogliamo andare in pratica a creare una descrizione compatta di quello che vogliamo analizzare. Con gli autoencoder andremo proprio a <strong>comprimere il data manifold</strong> e poi lavorare su questa compressione.</p>
<ul>
<li>
<p>Slide intuizione autoencoder</p>
  <img src="/images/notes/image/universita/ex-notion/Explainability of CNN/Untitled 7.png" alt="image/universita/ex-notion/Explainability of CNN/Untitled 7">
<p>Quello che vorremmo fare è una funzione identità per certe cose (dato che sono meno, non possiamo fare altro che perdere altre informazioni, ma vogliamo solamente perdere informazioni che non ci servano).</p>
</li>
</ul>
<p><strong>Possiblità della compressione</strong></p>
<p>La compressione dovrebbe essere possibile perché <strong>stiamo cercando regolarità nel data</strong>, cosa che ci dovrebbe essere perché noi umani riusciamo a riconoscere questi pattern, non riusciamo ad insegnarlo ad una macchina. (quando è molto random però non si può comprimere, stranamente il random è la cosa con più informazione in termini di teoria dell’informazione, ma meno informazione per noi umani, che strana questa asimmetria).</p>
<p><strong>Caratteristiche della compressione</strong></p>
<ul>
<li>
<p>Slide caratteristiche</p>
  <img src="/images/notes/image/universita/ex-notion/Explainability of CNN/Untitled 8.png" alt="image/universita/ex-notion/Explainability of CNN/Untitled 8">
</li>
</ul>
<p>La cosa di maggior rilievo è il fatto del <strong>loss</strong>, che non riusciamo a fare un reverse che diventi proprio uguale! E poi funziona solamente con data simili (con caratteristiche fortemente correlate fra di loro.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/no-tags/">No-Tags</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Explainability of CNN on x"
            href="https://x.com/intent/tweet/?text=Explainability%20of%20CNN&amp;url=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fexplainability-of-cnn%2f&amp;hashtags=no-tags">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Explainability of CNN on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fexplainability-of-cnn%2f&amp;title=Explainability%20of%20CNN&amp;summary=Explainability%20of%20CNN&amp;source=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fexplainability-of-cnn%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Explainability of CNN on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fexplainability-of-cnn%2f&title=Explainability%20of%20CNN">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Explainability of CNN on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fexplainability-of-cnn%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Explainability of CNN on whatsapp"
            href="https://api.whatsapp.com/send?text=Explainability%20of%20CNN%20-%20http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fexplainability-of-cnn%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Explainability of CNN on telegram"
            href="https://telegram.me/share/url?text=Explainability%20of%20CNN&amp;url=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fexplainability-of-cnn%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Explainability of CNN on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Explainability%20of%20CNN&u=http%3a%2f%2flocalhost%3a1313%2fcontent%2fnotes%2fexplainability-of-cnn%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="http://localhost:1313/">X. A. Huang&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
