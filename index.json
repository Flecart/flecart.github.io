[{"content":"Ultima modifica: October 19, 2022 5:02 PM Primo Abbozzo: June 3, 2022 11:34 AM Studi Personali: No\nArgomenti da ripetere Ripassare proprietÃ  e conseguenze per lo spazio vettoriale Capitolo 4 Dimostrazione teorema del completamento (2 tesi) Di conseguenza ripetere in modo piÃ¹ formale il capitolo 4 Capitolo 5 Bigezione fra spazio delle applicazioni lineari da n a m con le matrici n a m. LinearitÃ  per composizione lineare bigettiva sse invertibile Errore nella dimostrazione di iniettivitÃ  per kernel F Dimensione sistema lineare omogeneo Capitolo 6 Teorema caratterizzazione della preimmagine igettiva sse invertibile Errore nella dimostrazione di iniettivitÃ  per kernel F Dimensione sistema lineare omogeneo Capitolo 6 Teorema caratterizzazione della preimmagine ","permalink":"https://flecart.github.io/notes/appunti-per-lorale/","summary":"Ultima modifica: October 19, 2022 5:02 PM Primo Abbozzo: June 3, 2022 11:34 AM Studi Personali: No\nArgomenti da ripetere Ripassare proprietÃ  e conseguenze per lo spazio vettoriale Capitolo 4 Dimostrazione teorema del completamento (2 tesi) Di conseguenza ripetere in modo piÃ¹ formale il capitolo 4 Capitolo 5 Bigezione fra spazio delle applicazioni lineari da n a m con le matrici n a m. LinearitÃ  per composizione lineare bigettiva sse invertibile Errore nella dimostrazione di iniettivitÃ  per kernel F Dimensione sistema lineare omogeneo Capitolo 6 Teorema caratterizzazione della preimmagine igettiva sse invertibile Errore nella dimostrazione di iniettivitÃ  per kernel F Dimensione sistema lineare omogeneo Capitolo 6 Teorema caratterizzazione della preimmagine ","title":"Appunti per lâ€™orale"},{"content":"Introduzione Intuizione del campo elettrostatico Elettrostatico vs elettrodinamico ðŸŸ© Andiamo a chiamare elettrostatico perchÃ© nel nostro caso non si sta muovendo nessuna carica all\u0026rsquo;itnerno di questo campo.\nProprietÃ  del campo elettrostatico (5) ðŸŸ¨ Le linee di forza in ogni punto dello spazio sono tangenti e concorde al campo in quel punto; le linee di forza si addensano dove l\u0026rsquo;intensitÃ  del campo e maggiore; le linee di forza non si incrociano mai, in quanto in ogni punto il campo Ã¨ definito univocamente e non puÃ² avere due direzioni distinte. le linee di forza hanno origine dalle cariche positive e terminano sul cariche negative; qualora ci siano solo cariche dello stesso segno le linee di forza si chiudono all\u0026rsquo; infinito; nel caso di cariche di segno opposto, ma eguali in modulo, tutte le linee the partono dalle cariche positive si chiudono su quelle negative (induzione completa), alcune passando eventualmente per l\u0026rsquo;infinito; se invece le cariche non sono eguali in modulo, alcune linee terminano o provengono dall\u0026rsquo; infinito. Carica esploratrice ðŸŸ© Ãˆ anche chiamata carica di prova, Ã¨ una carica fittizia messa per esplorare la struttura del campo elettrico in un certo spazio\nTalvolta (Mencuccini), si potrebbe definire il valore del campo come $$ \\vec{E}(\\vec{r}) = \\lim_{ q \\to 0 } \\frac{\\vec{F}}{q} $$ in questo caso $q$ Ã¨ una carica di prova, talmente piccola che non varia il campo, utilizzato per sondare il valore del campo in un certo punto. Da un punto di vista intuitivo, costruiamo la linea passo passo, a tratti infinitesimi, e componiamo tutto lo spazio con queste.\nCampo come grandezza ðŸŸ© Il campo elettrico Ã¨ proprio una grandezza fisica (ossia una proprietÃ  misurabile di un oggetto non Ã¨ solo una cosa comoda matematicamente), che Ã¨ solitamente utilizzata per conoscere la forza applicata dal campo elettrico in un certo punto. Ãˆ una caratteristica dello spazio e una carica Ã¨ in grado di modificare questo aspetto.\nSi rappresentano uscenti se positiva, entrante se negativa Definizione di campo elettrico ðŸŸ© $$ \\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q}{R^{2}} \\hat{R} $$ Dove $Q$ Ã¨ la sorgente di carica, si puÃ² usare il principio di sovrapposizione anche in questo caso\nFlusso di campo vettoriale ðŸŸ© Dato un certo campo vettoriale, il flusso studia la relazione fra questi e una superficie a scelta. Intuitivamente si potrebbe dire quante linee di campo attraversano quella superficie.\nNormalmente si indica cosÃ¬ $$ \\phi_{S}(\\vec{F}) = \\iint_{S} \\vec{F} \\cdot d\\vec{s} = \\iint_{S} \\vec{F} \\cdot \\hat{n} \\, ds $$ Con $\\hat{n}$ indicato per marcare che deve essere orientato e perpendicolare alla superficie considerata. Esempio di vettori normali alla superficie, nel nostro esempio il valore di $\\hat{n}$.\nCampo tangenziale e parallelo ðŸŸ© Questa parte la devo ancora scrivere per bene, in breve andiamo a trattare della discontinuitÃ  del flusso di fronte a una superficie carica, e il fatto che la circuitazione parallela Ã¨ 0. La discontinuitÃ  Ã¨ trattata a pagina 79 del Mazzoldi.\nQuesta parte serve per spiegare alcune proprietÃ  del campo nei materiali conduttori trattata in Conduttori elettrici. Alla fine possiamo andare a concludere che $$ \\Delta \\vec{E}_{\\parallel} = 0 $$ Questo Ã¨ necessario per poter spiegare la rifrazione nei mezzi, vedi Condensatori con dielettrici.\nProblemi classici Dipolo elettrico Fatto (molto) meglio in Dipolo elettrico\nIntroduzione al problema del dipolo elettrico ðŸŸ© Questo sarÃ  uno dei nostri primi problemi (e probabilmente anche fra le piÃ¹ semplici che ci permetteranno di analizzare il campo). Abbiamo due cariche (stessa carica assoluta), una positiva e una negativa, vogliamo andare a capire come Ã¨ fatto il campo elettrico attorno a queste cariche.\nModellizzazione del problema dipolo elettrico ðŸŸ¨+ Consideriamo un punto esattamente a metÃ  fra le due cariche, sia $d$ la distanza fra le due cariche, mettiamo il nostro sistema di riferimento come in figura. il campo elettrico in quel punto Ã¨ dato da. $$ \\vec{E}_{tot} = \\vec{E}_{+} + \\vec{E}_{-} = \\frac{Q}{4\\pi \\varepsilon_{0}}\\left( \\frac{\\hat{R}_{+}}{R^{2}_{+}} + \\frac{\\hat{R}_{-}}{R^{2}_{-}} \\right) $$ Usiamo ora l\u0026rsquo;ipotesi che il punto sia a metÃ , abbiamo allora che la distanza in modulo sia uguale, avremo che $$ \\vec{E}_{tot} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q}{R^{3}}\\left( \\left( y \\hat{j} - \\frac{d}{2} \\hat{k} \\right) - \\left( y \\hat{j} + \\frac{d}{2} \\hat{k} \\right) \\right) = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q}{R^{3}} (-d \\hat{k}) $$ Il valore $-d Q\\hat{k}$ avrÃ  un significato speciale, sarÃ  il momento di dipolo\nIl momento di dipolo (2) ðŸŸ© Direttamente proporzionale fra $d$, la distanza fra le cariche e $q$ la quantitÃ  di carica delle due. Mi da informazioni sulla geometria e sulla carica del sistema Per questo Ã¨ comodo poter analizzare un caso cosÃ¬ semplificato di dipolo\nDistribuzione di carica uniforme lineare infinita Questa sarÃ  la nostra seconda applicazione del concetto di campo e di sovrapposizione che conosciamo\nIntroduzione problema carica uniforme lineare ðŸŸ© Abbiamo sull'asse $Z$ una distribuzione uniforme lineare, vogliamo cercare di capire come Ã¨ fatto il campo in questo caso #### Modellizzazione problema carica uniforme lineare infinita ðŸŸ© Consideriamo un punto $P$ come in figura, sia dato un piccolissimo contributo di campo $d \\vec{E}$, vogliamo cercare di capire come Ã¨ fatto questo contributo per l'intera linea lineare. Possiamo fare una osservazione di simmetria e affermare che la componente $z$ si elimina (ad ogni carica corrisponde una uguale e contraria)., mentre la componente $x$, quella che esce o entra dal piano Ã¨ inesistente per come Ã¨ fatto il sistema la soluzione diventa quindi $\\vec{E} = E_{y} \\hat{j}$ ossia $$ E_{y} = \\int \\lvert d\\vec{E} \\rvert \\cos \\theta = \\frac{\\lambda}{4\\pi\\varepsilon_{0}} \\int _{-\\infty}^{+\\infty} \\frac{dz}{r^{2}} \\cos \\theta $$ Le ultime tre sono strettamente relazione fra di loro, quindi le possiamo esprimere con cose di angoli, ora l\u0026rsquo; integrale finale diventerebbe, con $r'$ la distanza del punto con la linea retta. Questo funziona perchÃ© si puÃ² osservare che $$ dz = r' \\, \\frac{ d \\tan\\theta}{d\\theta} $$ PerchÃ© cosÃ¬ abbiamo espresso totalmente l\u0026rsquo;altezza in funzione dell\u0026rsquo;angolo, Ã¨ un trick che Ã¨ stato usato molto spesso quindi Ã¨ molto importante che te lo impari.\n$$ \\int _{-\\infty}^{+\\infty} \\frac{dz}{r^{2}} \\cos \\theta = \\int _{-\\frac{\\pi}{2}}^{+\\frac{\\pi}{2}} \\frac{\\cos\\theta}{r'}d\\theta $$ La soluzione diventa quindi $$ E_{y} = \\frac{1}{2\\pi\\varepsilon_{0}} \\frac{\\lambda}{r'} $$ Osservazione variare campo elettrico al variare dei problemi visti ðŸŸ© Un osservazione interessante Ã¨ che il campo elettrico Ã¨\nSingola carica -\u0026gt; $\\frac{1}{r^{2}}$ Dipolo elettrico -\u0026gt; $\\frac{1}{r^{3}}$ Lineare -\u0026gt; $\\frac{1}{r}$ Miscellanea: problemi semplici Flusso in una sfera ðŸŸ© Questa Ã¨ una semplicissima applicazione della definizione di flusso. Consideriamo una sfera, poniamo il sistema di riferimento al centro di questa sfera, ci chiediamo quanto Ã¨ il flusso del campo radiale che varia come $\\vec{F} = k \\vec{r}, \\vec{r} = (x, y , z)$?\nApplicando la definizione di flusso abbiamo: $$ \\phi_{s}(\\vec{F}) = \\oint \\vec{F} \\cdot d\\vec{s} = \\iint k \\vec{r} \\cdot d\\vec{s} = kr \\iint ds =4\\pi r^{3}k $$ Potenziale elettrostatico Introduzione al potenziale elettrostatico Abbiamo studiato in dinamica che il potenziale Ã¨ un concetto strettamente legato al Lavoro, ossia dalla quantitÃ  di energia necessaria per spostare un oggetto da un punto all\u0026rsquo;altro, vogliamo cercare di definire le relazioni che intercorrono nel caso della forza elettromagnetica\nRotore nullo =\u0026gt; forza conservativa ðŸŸ© Teorema: $$ \\vec{\\nabla} \\times \\vec{F} \\implies \\vec{F} \\text{ Ã¨ una forza conservativa} $$ Il motivo Ã¨ che per il teorema presente in #Teorema di stokes, abbiamo che $$ \\oint_{L} \\vec{F} \\cdot d\\vec{l} = \\iint_{S} \\vec{\\nabla} \\times \\vec{F} \\,d\\vec{s} $$ E se abbiamo che il rotore Ã¨ nullo, allora la forza Ã¨ conservativa perchÃ© per definizione Ã¨ conservativa se non dipende dal percorso, e la cosa che un circuito chiuso Ã¨ sufficiente per dimostrare il sopra.\nNote mie che non ho ben capito: Questo si puÃ² dimostrare senza molta difficoltÃ  se scriviamo la forza di coulomb nella forma cartesiana, alla fine facendo la derivata si dovrebbe cancellare tutto.\nForza radiale =\u0026gt; forza conservativa ðŸŸ© Consideriamo una qualunque forza radiale e qualunque percorso lineare Consideriamo il setting come in immagine, abbiamo un qualunque percorso, e una carica che crea forza in modo radiale diciamo.\nAllora possiamo osservare se prendiamo un segmentino infinitesimale, ci sembrerÃ  una scaletta, ma la forza coseno Ã¨ attiva solamente in $\\bar{AB} \\text{ e } \\bar{CD}$ questo ci permette di affermare che il lavoro (quella cosa potenziale) Ã¨ solamente dipendente dalla distanza\nFormula dell\u0026rsquo;energia potenziale elettrostatica ðŸŸ© Proviamo in questo momento a derivare la formula per il potenziale elettrostatico, valido per praticamente ogni percorso\n$$ L_{AB} = -\\int _{A}^{B} \\vec{F} \\cdot d\\vec{r} = -\\int _{A}^{B} \\lvert \\vec{F} \\rvert ds \\cos \\theta = -\\int _{A}^{B} \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Qq}{r_{p}^{2}} \\cos \\theta \\, ds = -\\frac{Qq}{4\\pi\\varepsilon_{0}} \\int _{A}^{B} \\frac{1}{r_{p}^{2}} \\, dr_{p} = \\frac{Qq}{4\\pi\\varepsilon_{0}} \\left( \\frac{1}{r_{a}} - \\frac{1}{r_{b}} \\right) $$ (col coseno dello spazio percorso, abbiamo che il valore dipenden solamente dalla distanza, per questo motivo Ã¨ semplice, un altro motivo per spiegare questo Ã¨ spezzettare il percorso con zigzag infinitesimi). E dall\u0026rsquo;ultimo possiamo capire il potenziale classicamente definito\n$$ U(r) = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Qq}{r} + const $$ Quindi dipende solamente dalla distanza a meno di una costante additiva. Il motivo per cui (credo) possiamo utilizzare la costante additiva Ã¨ che ci basta fissare un altro punto ad hoc, fissato un altro punto, diventa allora possibile definire il potenziale o l\u0026rsquo;energia potenziale in ogni punto dello spazio prendendo quello come riferimento.\nForza elettromotrice ðŸŸ© Spiegato in maggiore dettaglio in Leggi di Ohm, dove iniziamo a parlare di circuiti. La circuitazione per un campo elettrico Ã¨ definito in modo molto simile a quello di una forza qualunque\n$$ \\mathbb{\\varepsilon} = \\oint_{L} \\vec{E} \\cdot d\\vec{l} $$ E valgono esattamente le stesse proprietÃ  che abbiamo dimostrato sopra riguardo al rotore.\nPotenziale elettrostatico Definizione ðŸŸ© Questa non Ã¨ una energia, si potrebbe dire che Ã¨ la capacitÃ  di creare energia potenziale per singole cariche\nDefiniamo $$ V(A) = \\frac{U(A)}{q} $$ Che in un certo senso Ã¨ il lavoro fatto dal campo, non dalla forza (NOTA: non Ã¨ corretto dire lavoro di un campo, non credo sia un concetto ben definito).\nAnalisi di dimensionalitÃ  per potenziale elettrostatico ðŸŸ© $$ V(r) = \\frac{1}{4\\pi \\varepsilon_{0}} \\frac{Q}{r} \\implies \\left[ V \\right] = \\left[ U \\right] \\left[ Q^{-1} \\right] =\\left[ M \\right] \\left[ L^{2} \\right] \\left[ T^{-2} \\right] \\left[ Q^{-1} \\right] $$ E quindi potremmo misurare il campo elettrico anche come volt su metri, per la definizione con gli integrali\nPrincipio di sovrapposizione per potenziale elettrostatico ðŸŸ© L\u0026rsquo;esatto principio che abbiamo descritto in precedenza per il campo elettrico vale anche il per il potenziale elettrostatico, anzi potrebbe essere utile nel calcolo del campo elettrico stesso se possiamo derivare in un singolo punto, otteniamo il campo elettrico in quel punto.\nSuperfici equipotenziali ðŸŸ© Possiamo definire delle sfere che abbiamo tutti lo stesso potenziale elettrostatico, che da un punto di vista matematico basta stessa r ma serve il concetto di angolo solito per poter caratterizzare matematicamente questo concetto.\nTODO: avere superficie della sfera con angoli solidi, perchÃ© questa Ã¨ l\u0026rsquo;analisi piÃ¹ semplice per superfici equipotenziali di singola carica\nEquazione di PoissonðŸŸ© $$ \\vec{\\nabla} \\cdot \\vec{E} = \\vec{\\nabla} \\cdot (-\\vec{\\nabla}V) = \\frac{\\rho}{\\varepsilon_{0}} $$ Quindi l\u0026rsquo;equazione di poisson Ã¨\n$$ \\nabla^{2} V = -\\frac{\\rho}{\\varepsilon_{0}} $$ Nel caso in cui non ci sia carica in un punto nello spazio abbiamo l\u0026rsquo;equazione di Laplace\n$$ \\nabla^{2} V = 0 $$ Per qualche motivo a me oscuro, la soluzione dell\u0026rsquo;equazione di Poisson in coordinate cartesiane Ã¨:\n$$ V(x, y, z) = \\frac{1}{4\\pi\\varepsilon_{0}} \\int _{\\Sigma} \\frac{\\rho(x', y', z')\\, dx'dy'dz'}{\\sqrt{ (x - x')^{2} + (y - y')^{2} + (z - z') ^{2} }} $$ Questo risulta utile per caratterizzare la soluzione dell\u0026rsquo;equazione di Poisson per il Vettore potenziale.\n","permalink":"https://flecart.github.io/notes/campo-elettrico/","summary":"Introduzione Intuizione del campo elettrostatico Elettrostatico vs elettrodinamico ðŸŸ© Andiamo a chiamare elettrostatico perchÃ© nel nostro caso non si sta muovendo nessuna carica all\u0026rsquo;itnerno di questo campo.\nProprietÃ  del campo elettrostatico (5) ðŸŸ¨ Le linee di forza in ogni punto dello spazio sono tangenti e concorde al campo in quel punto; le linee di forza si addensano dove l\u0026rsquo;intensitÃ  del campo e maggiore; le linee di forza non si incrociano mai, in quanto in ogni punto il campo Ã¨ definito univocamente e non puÃ² avere due direzioni distinte.","title":"Campo elettrico"},{"content":"2016 Feb SELECT DISTINCT C.RV, C.TonalitÃ , C.Nome, C.Data FROM Concerto AS C JOIN Movimenti AS M ON C.RV=M.RV WHERE Tempo=\u0026#34;Largo\u0026#34; SELECT M.RV, M.Numero, M.Tempo, M.Durata FROM Concerto AS C JOIN Movimenti AS M ON C.RV=M.RV WHERE C.Data\u0026gt;1720 GROUP BY M.RV, M.Numero, M.Tempo, M.durata HAVING COUNT(M.Numero) \u0026gt; 3 Sbagliato il secondo perchÃ© il group by non grouppa bene, bisogna fare query innestata\n$$ \\pi_{RV, Numero,Tempo, Durata}(\\sigma_{Durata \u003e 120}(Mov) \\bowtie \\sigma_{strumento=\"violino\"}Strumentazione) $$ $$ \\pi_{RV, Numero, Tempo, Durata)}(\\sigma_{Strumento=Cembalo}(Strumentazione) \\bowtie Concerti \\bowtie \\sigma_{Numero=3}(mov)) - $$ $$ \\pi_{RV, Numero, Tempo, Durata)}(\\sigma_{Strumento=Cembalo}(Strumentazione) \\bowtie Concerti \\bowtie \\sigma_{Numero\u003e3}(mov)) $$ Random exercises Relational algebra https://docs.google.com/presentation/d/1OuxnSOqHkj6Uq6xCSGzfK0mAlCn3xGZUVThRiFzQkrQ/edit#slide=id.g4f418699b7_0_16\nExercise 4 $$ \\pi_{\\text{Name}} (\\sigma_{\\text{Price} \u003e \\text{age} \\cdot 10}(\\text{PERSON} \\bowtie \\rho_{Id \u003c- Person}(\\text{ENROLLMENT}) \\bowtie \\rho_{Course \u003c- name}(\\text{COURSE}))) $$ Should be correct, the prof. solution renamed another thing\nExercise 5 $$ \\pi_{\\text{Name}, \\text{Surname}} ( \\sigma_{\\text{Mark} = 30} (\n\\rho_{\\text{Student} \u0026lt;- Id}(STUDENT) \\bowtie EXAM\n) ) $$ Prof solution uses a property of join selection.\nExercise 6 $$ \\pi_{\\text{Name}, \\text{Surname}}( \\pi_{\\text{Id}, \\text{Name}, \\text{Surname}} ( (STUDENT) )\n\\pi_{\\text{Id}, \\text{Name}, \\text{Surname}} ( \\sigma_{\\text{Mark} = 30} (\n\\rho_{\\text{Student} \u0026lt;- Id}(STUDENT) \\bowtie EXAM ) ) ) $$\nDevo tenere l\u0026rsquo;ID perchÃ© ci potrebbero essere omonimi.\nExercise 7 $$ \\pi_{\\text{SupName}} ( \\rho_{\\text{SupName} \u0026lt;- \\text{Name}}(SUPPLIER) \\bowtie_{\\text{Id} = \\text{SupId}} \\sigma_{Quantity \u0026gt; 0}(SUPPLYING)\n\\bowtie_{\\text{ProdId} = \\text{Id}} \\sigma_{\\text{Name} \\neq \\text{PX274}}(PRODUCT)\n) $$\nSQL exercises Exercise 1 SELECT DISTINT LECTURER.Surname FROM LECTURER, STUDENT WHERE LECTURER.surname == STUDENT.surname Other solution\nSELECT DISTINCT Surname FROM LECTURER INTERSECT SELECT DISTINCT Surname FROM STUDENT Exercise 2 (da rifare) Questo Ã¨ sbagliato\nSELECT L.Surname FROM LECTURER AS L JOIN EDITION AS E ON L.Id == E.Lecturer JOIN (SELECT Course, COUNT(Student) as passed FROM EDITION GROUP BY Course) ON E.Course == Course WHERE passed \u0026gt;= 10 LECTURER(Id, Surname, Dept) STUDENT(Id, Surname) COURSE(Code, Name) EDITION(Course, Year, Lecturer) EXAM(Student, Course, Year)\nSELECT DISTINCT L.Surname FROM LECTURER AS L, EDITION AS C, EXAM AS E WHERE L.Id = C.Lecturer AND C.Course = E.Course AND C.Year = E.Year GROUP BY L.Id, L.Surname, C.Course, C.Year HAVING COUNT(*) \u0026gt; 10\nExercise3 Select MIN(Mile) as Minimum, MAX(Mile) as Maximum FROM train WHERE Departure = \u0026#34;Boston\u0026#34; AND Arrival = \u0026#34;Chicago\u0026#34; Exercise 4 SELECT R.Name FROM Region as R, Residence AS C WHERE R.Name == C.Region GROUP BY Region.Name HAVING COUNT(Region.Name) \u0026lt; Region.Population # Questo sicuramente sbagliato! Infatti lo Ã¨! GPT introduce una bella soluzione:\nSELECT R._Name FROM Region R WHERE R.Population \u0026gt; ( SELECT COUNT(*) FROM Residence RS WHERE RS.Region = R._Name ); Exercise 5 Select F.title FROM Film AS F WHERE 7 \u0026lt;= ( select AVG(Rating) FROM RATING WHERE FilmID = F.FilmId ) AND F.Year \u0026gt;= 1990 AND F.Year \u0026lt;= 2000 Exercise 6 Select MIN(User.AGE) FROM RATING NATURAL JOIN FILM NATURAL JOIN USER Where RATING.Rating \u0026gt; 8 and FILM.Title = \u0026#34;Blade runner\u0026#34; 7 Dobbiamo in qualche modo usare tutte e quattro le relazioni, perchÃ© vogliamo comporre le informazioni\nSELECT P.Name, P.Song FROM PLAYLIST as P WHERE EXISTS ( SELECT FROM SONG as S, ALBUM as B, ARTIST as A, WHERE P.Song = S.ID and S.Albumb = B.ID and B.Artist = A.ID and B.Year \u0026lt; 2001 and A.Labels = \u0026#34;UMG\u0026#34; ) Exercise 12 SELECT R.Name, SUM(S.Profits) FROM ROOM R JOIN SCREENING S ON R.Code = S.Room WHERE R.City = \u0026#34;Rome\u0026#34; AND S.Date \u0026gt;= \u0026#34;01/01/05\u0026#34; AND S.Date \u0026lt;= \u0026#34;31/01/05\u0026#34; GROUP BY R.Code, R.Name HAVING SUM(S.Profits) \u0026gt; 20000 Exercise 13 FROM FILM F JOIN SCREEENING S ON JOIN ROOM R 27 Ho bisogno di un aggregato, perchÃ© devo sapere il numero di novels in cui appare\nAvrÃ² bisogno di Characters e Novel, perchÃ© questi sono le cose prese.\nUn groupby CodeNov, Title e Name, potrebbe essere sensato. Come faccio ad esprimere il concetto che sono apparsi in piÃ¹ di un novel?\nPosso intanto creare una view in cui ho il nome del carattere e numero di\nSELECT name, sum(CodeNov) FROM CHARACTERS GROUP BY name HAVING sum(CodeNov) \u0026gt; 1; Questa query la chiamo A1 e mi sarÃ  utile come subquery !? Si, basta aggiungere un having e poi l\u0026rsquo;abbiamo! Alla fine non avevo bisogno della relazione Novel.\n28 Ho bisogno di sapere se Ã¨ italiano l\u0026rsquo;autore, e Novel, quindi dovrei fare join per selezionare solamente le Novel italiane. Poi dovrei fare join ancora per capire se ho o meno il film. E devo contare anche i films\u0026hellip;\nSeleziono Novelle italiane\nSELECT N.CodeNov FROM NOVEL AS N, AUTHORS AS A WHERE N.Author == A.Name AND Country = \u0026#34;it\u0026#34; Questa la chiamo A1\nPosso usare questo e una dicitura Groupby per finalizzare.\nSELECT N1.title, F.Code FROM NOVEL as N1, FILM as F WHERE N1.CodeNov = F.Novel AND N1.CodeNov in A1 GROUP BY N1.title, F.Code HAVING sum(F.Code) \u0026gt; 1 Non so se posso rimuovere F.code fra le select.\n29 SELECT Title FROM NOVEL WHERE CodeNov not in ( SELECT N.CodeNov FROM NOVEL as N, FILM as F WHERE N.CodeNov = F.Novel ) Questa mi sembra facile, conoscendo perÃ² query innestate\n30 SELECT Title FROM NOVEL WHERE CodeNov not in ( SELECT N.CodeNov FROM NOVEL as N, CHARACTERS as C WHERE N.CodeNov = C.CodeNov AND C.Gender = \u0026#34;Male\u0026#34; ) Mi sembra ok anche se la soluzione Ã¨ diversa rispetto a quello del prof. Una cosa che non ho capito della soluzione del prof Ã¨ perchÃ© ha bisogno di selezionare anche codeNov\u0026hellip;\nDesign concettuale Esercizio 1 Proviamo ad identificare\nClinica ID Chiave address numero di telefono Tool ID chiave descrizione Specialista ID Nome Cognome Numero telefono SLista (1, N) Collaboratori ID nome cognome Visita Codice Date Time Clinica -\u0026gt; Visit (1, N), Clinica \u0026lt;- Visit (1, 1) assign Visit -\u0026gt; Spec (1, N), Visit \u0026lt;- Spec (0, N) DO Spec -\u0026gt; Tool (0, N), Spec \u0026lt;- Tool (1, N) Use Coll -\u0026gt; Tool (1, N), Coll \u0026lt;- Tool (0, N) Responsabile Spec -\u0026gt; Coll (0, N), Spec \u0026lt;- Coll (1, N), work Esercizio 2 Corsi Nome prezzo max attendee Membri Generalizzazione ereditarietÃ , esclusiva (se si puÃ² stare da una parte o dall\u0026rsquo;altra allo stesso tempo), totale (perchÃ© o Ã¨ uno o nell\u0026rsquo;altro) e si indica con la freccetta riempita. ID Nome Surname Phone number Trainer Cliente etÃ  Card Numero progressivo + esterno (cliente) prezzo totale Cliente - Card -\u0026gt; (0, N), \u0026lt;- (1, 1) own\nTrainer - Corso, -\u0026gt; (0, N), \u0026lt;- (1, 2), responsabile, Venduto Ã¨ giusto anche (1, N) in questo caso, perchÃ© non Ã¨ detto.\nCliente - Corso, -\u0026gt; (0, N), \u0026lt;- (0, N), Enroll, vincolo relazionale esterno.\nCard - Corso, -\u0026gt; (1, N), \u0026lt;- (0, N), Made-f\nMax A \u0026gt;= client e anche by card.\nCosto carta \u0026lt; costo corsi a cui da accesso\nEsercizio 3 Company (financial market?) Code Name Share capital Registered office City state Rating Agency Code Name financial instrument Nome + (company) Performance Figli (esclusivo, totale in questo caso) Derivati Shares Bonds Maturity date Fins - ocmp, -\u0026gt; (1, 1) , \u0026lt;- (1, N), issue Value Comp - Agency, -\u0026gt; (1, N), \u0026lt;- (1, N), rating Value Comp - Comp, -\u0026gt; (1, N), \u0026lt;- (1, N) Hold Percentuale BR:\n","permalink":"https://flecart.github.io/notes/database-exercises/","summary":"2016 Feb SELECT DISTINCT C.RV, C.TonalitÃ , C.Nome, C.Data FROM Concerto AS C JOIN Movimenti AS M ON C.RV=M.RV WHERE Tempo=\u0026#34;Largo\u0026#34; SELECT M.RV, M.Numero, M.Tempo, M.Durata FROM Concerto AS C JOIN Movimenti AS M ON C.RV=M.RV WHERE C.Data\u0026gt;1720 GROUP BY M.RV, M.Numero, M.Tempo, M.durata HAVING COUNT(M.Numero) \u0026gt; 3 Sbagliato il secondo perchÃ© il group by non grouppa bene, bisogna fare query innestata\n$$ \\pi_{RV, Numero,Tempo, Durata}(\\sigma_{Durata \u003e 120}(Mov) \\bowtie \\sigma_{strumento=\"violino\"}Strumentazione) $$ $$ \\pi_{RV, Numero, Tempo, Durata)}(\\sigma_{Strumento=Cembalo}(Strumentazione) \\bowtie Concerti \\bowtie \\sigma_{Numero=3}(mov)) - $$ $$ \\pi_{RV, Numero, Tempo, Durata)}(\\sigma_{Strumento=Cembalo}(Strumentazione) \\bowtie Concerti \\bowtie \\sigma_{Numero\u003e3}(mov)) $$ Random exercises Relational algebra https://docs.","title":"Database exercises"},{"content":"Ripasso Prox: 12 Ultima modifica: May 12, 2022 10:55 AM Primo Abbozzo: April 7, 2022 9:25 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso 7 Problema k-esimo Questo documento Ã¨ totalmente concentrato sull\u0026rsquo;analisi del problema della selezione del k-esimo elemento.\n7.1 Introduzione al problema Dato un array di elementi vogliamo cercare di trovare un modo efficiente per selezionare il k-esimo elemento, ossia un elemento che sia maggiore di k-1 elementi\n7.1.1 Note sull\u0026rsquo;utilizzo Questo algoritmo Ã¨ utile per esempio per sapere cosa displayare in una pagina di ricerca, perchÃ© per esempio posso avere blocchi di tanta roba 140k, mentre ovviamente posso selezionare solamente un blocco ristretto.\nEs: mostrare i primi k in ordine di rilevanza!\n7.2 Prime soluzioni Notiamo che possiamo riadattare le soluzioni ai problemi di ordinamento per trovare il k-esimo elemento.\n7.2.1 Selezione del minimo Questo Ã¨ un algoritmo che va a modificare il selection sort (utilizzando la stessa idea per creare un subarray crescente).\nSlide\nFaccio k cicli per trovare i k minimi per circa n volte, anche se l\u0026rsquo;analisi esatta Ã¨ data da questa sommatoria, che Ã¨ qualcosa di simile, ma non esattamente quello.\n$\\sum_{i = n - k + 1} ^{n} i$\n7.2.2 HeapSelect Io utilizzo una heap per trovare i k-esimi minimi, praticamente sto facendo un heap sort, ma con l\u0026rsquo;altra heap, e sto espellendo piccoli elementi uno alla volta..\nSlide\nPiccole note sul costo (funziona se ordini inferiori!)\n7.2.3 QuickSelect Un primo approccio potrebbe essere utile cercare di ordinare l\u0026rsquo;array con questo e prendere il k-esimo elemento.\nPoi noto che posso sfruttare il divide e conquer di qucksort per sapere quanti elementi sono minori di k! ho principalmente 3 casi:\nPseudoalgo mio (molto a parole)\nho esattamente k - 1 elementi minori di x nel primo insieme dopo il partition, quindi ritorno x.\nHo meno elementi di k - 1 minori di x dopo il partition, quindi vado a cercare il k esimo in questo insieme qui.\nHo piÃ¹ elementi di k - 1 minori di x dopo il partition, vado a cercare l\u0026rsquo;offset corretto nell\u0026rsquo;altro insieme.\nPseudocodice di slide\nPseudocodice bandiera nazionale che serve qui\nAnalisi nel caso ottimo e pessimo (e medio)\nL\u0026rsquo;ottimo e pessimo Ã¨ abbastanza facile perchÃ© si riconduce esattamente all\u0026rsquo;analisi di quicksort\nIn pratica O(n) nel caso migliore (perchÃ© ora ho una chiamata ricorsiva in meno)\nO(n2) nel caso peggiore perchÃ© Ã¨ identico a quicksort.\nIl caso medio Ã¨ un pÃ² piÃ¹ difficile da analizzare, dimostreremo che Ã¨ in O(n). vediamo perchÃ©\nAnalisi medio\nSupponiamo che scegliamo sempre la partizione sfavorevole (quindi da n/2 a n), allora la relazione di ricorrenza (supponendo distribuzione uniforme semplice di queste possibilitÃ ) ho\nPosso dimostrare utilizzando la sostituzione questo. fine\n8 Priority-Queue Ãˆ di solito implementata con la Heap. Iniziamo a fare una descrizione di questa strututra\nAltre implementazioni che perÃ² non sono richieste ma interessanti\nBinomial Heap fibo-heap 8.1 Introduzione Questa struttura di dati sarÃ  utile in seguito per algoritmi di grafi come Dijstra o Prim per il MST.\nQuesta struttura come la Heap (anche fattibile con fibo-heap o heap binomiali!), manterrÃ  il minimo, non Ã¨ esattamente FIFO o LIFO come stack e queue\n8.1.1 Interfaccia della struttura Insertion (log n) Deletion (log n) Creation (n) Slide delle operazioni\n8.1.2 Esempi di utilizzi Base per altri algoritmi (come Dijstra o Prim) Processing di pacchetti per il routing Qualunque posto in cui c\u0026rsquo;Ã¨ bisogno di processare secondo un certo ordine 8.2 D-heap La differena con la heap normale Ã¨ che questo Ã¨ un albero che abbia d-rami.\nSlide di descrizione\n8.2.1 Altezza e Memorizzazione Lemma altezza della heap\nQuesta dimostrazione sull\u0026rsquo;altezza dell\u0026rsquo;heap Ã¨ molto simile a tutti gli alberi binari. Come gli alberi binari possiamo memorizzarli facendo un offset sulla cella attuale!\nMemorizzazione della d-heap\nOperazioni helper importanti:\nSono molto utilizzate per le operazioni di delete, insertion e simili.\nMuovi alto e muovi basso\n8.2.2 Sunto dei costi e note L\u0026rsquo;unica operazione che puÃ² essere complessa Ã¨ la deletion, in cui bisogna contemplare anche il bubble up (viene eseguito solo una volta questa oppure bubble down).\nRiassunto in slide\n9 Union-Find 9.1 Introduzione Questa struttura di dati ci sarÃ  utile per gestire insiemi disgiunti\n9.1.1 Interfaccia della struttura Vedere se due elementi appartengono allo stesso insieme trovare il rappresentante Unire degli insiemi Slide interfaccia\nOgni insieme Ã¨ indicato da uno e un solo rappresentante, un suo elemento che fa finta di essere l\u0026rsquo;insieme stesso. Questa Ã¨ l\u0026rsquo;idea piÃ¹ importante per comprendere la rappresentazione di questa struttura di dati.\n9.1.2 Intuizione sullâ€™utilizzo Ho un insieme di ingredienti che siano tutti separati, vorrei unirli con magari un certo ordine, creando delle nuove cose. E continuare a vedere se li ho giÃ  uniti o meno.\nAlla fine vedo l\u0026rsquo;unione degli elementi in questo modo\nEsempio di problema risolto con DSU\nSlide possibili implementazione (trattati subito dopo\n9.2 QuickFind Find in tempo costante e union in tempo lineare (possibile ammortizzare a tempo costante) 9.2.1 Metodi di rappresentazione (only lista) Un insieme Ã¨ rappresentato tramite un albero di altezza UNO.\nQuesto Ã¨ possibile tramite una lista concatenata, in cui ogni nodo punta sempre al nodo rappresentante.\nSlide rappresentazione tramite liste\nCi aggiungo io che si puÃ² utilizzare anche un semplice array e l\u0026rsquo;index come un pointer per creare tale struttura.\n9.2.2 Union e sunto delle operazioni L\u0026rsquo;union di due insiemi Ã¨ una sovrascrittura del pointer del rappresentante dell\u0026rsquo;insieme che viene unito, come si puÃ² intuire nell\u0026rsquo;esempio di union.\nIl find Ã¨ immediato, perchÃ© deve risalire di solamente un arco.\nEsempio di operazione di union\nRiassunto delle operazioni\n9.2.3 Euristica del peso (!!) Voglio cercare di limitare il tempo di unione di due insiemi.\nL\u0026rsquo;idea Ã¨ unire l\u0026rsquo;insieme con meno figli a quello con di piÃ¹. mi mantengo questa informazione sulla radice dell\u0026rsquo;albero.\nSlide dell\u0026rsquo;idea\nCosto di Union\nIl tempo resta lineare, perÃ² Ã¨ almeno dimezzato l\u0026rsquo;upper bound del tempo necessario per fare questa operazione.\nCosto ammortizzato\nPosso osservare che per la proprietÃ  sopra, se una foglia cambia radice l\u0026rsquo;insieme di arrivo Ã¨ grande almeno il doppio dell\u0026rsquo;insieme precedente, questa proprietÃ  mi permette di concludere che al massimo posso swappare log n volte.\nQuesto ragionamento mi permette di concludere un costo ammortizzato per questa operazione di union\nAnalisi union ammortizzato\nNotiamo che al massimo, in una union, $n/2$ elementi possono cambiare parente Quindi il caso pessimo di union in questo modo resta in $O(n)$, ma possiamo fare di meglio.\nNota: dopo n - 1 union, sto facendo union con se stesso, che non ha senso, quindi resto con n - 1, che Ã¨ il caso pessimo d union).\n9.3 QuickUnion Ãˆ una altra rappresentazione dell\u0026rsquo;union find, in cui Ã¨ presente una foresta (uguale alla precedente, ma in questo caso posso avere anche altezza superiore a 1!)\n9.3.1 Introduzione alla struttura e implementazione (array) Slide sulla struttura\nSlide di rappresentazione dell\u0026rsquo;array\nSi utilizza il parent vector!\n9.3.2 Find e sunto delle operazioni Per union basta infatti prendere la radice del primo insieme e farla puntare alla radice dell\u0026rsquo;insieme in cui si vuole unire, invece che farlo puntare a sÃ© stesso (fa questa ultima cosa perchÃ© era la radice)\nSlide di riassunto\n9.3.3 Euristica del rank (!!) Voglio cercare di limitare il tempo di ricerca del rappresentante. L\u0026rsquo;idea Ã¨ nel momento di fare l\u0026rsquo;union, lo faccio scegliendo di unire l\u0026rsquo;elemento con rank minore (ovvero con altezza dell\u0026rsquo;albero minore) con quello maggiore.\nAnalisi caso pessimo\nUpper bound rank di x (dim)\nLa dimostrazione Ã¨ abbastanza noiosa, basta che tengo in considerazione i tre casi: quando rank(a) = rank(b), quando Ã¨ minore, e quando Ã¨ maggiore, sapendo l\u0026rsquo;ipotesi induttiva, non dovrebbe essere tanto difficile concludere quanto voluto.\n(se ho una limitazione superiore all\u0026rsquo;altezza dell\u0026rsquo;albero allora Ã¨ chiaro che il find Ã¨ in log n.\nIn questo modo riesco proprio a creare un upper bound logaritmico al find, a differenza del costo ammortizzato di questo con l\u0026rsquo;euristica del peso in quickfind.\n","permalink":"https://flecart.github.io/notes/k-esimo-priority-q-dsu/","summary":"Ripasso Prox: 12 Ultima modifica: May 12, 2022 10:55 AM Primo Abbozzo: April 7, 2022 9:25 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso 7 Problema k-esimo Questo documento Ã¨ totalmente concentrato sull\u0026rsquo;analisi del problema della selezione del k-esimo elemento.\n7.1 Introduzione al problema Dato un array di elementi vogliamo cercare di trovare un modo efficiente per selezionare il k-esimo elemento, ossia un elemento che sia maggiore di k-1 elementi","title":"k-esimo priority-q DSU"},{"content":"Ripasso Prox: 60 Ripasso: July 12, 2023 Ultima modifica: May 13, 2023 11:33 PM Primo Abbozzo: December 13, 2022 10:36 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso NAT Network address translation Introduzione Col il NAT possiamo avere tutto lo spazio degli IP di cui abbiamo bisogno, che perÃ² non sono esposti. All\u0026rsquo;esterno vengono esposte solamente lâ€™IP del NAT.\nSchema classico NAT\nQuindi in breve\nAll\u0026rsquo;esterno Ã¨ esposto solamente l\u0026rsquo;indirizzo del router, il router, a seconda della porta giusta, dÃ  in risposta al computer giusto, quindi all\u0026rsquo;interno della nostra rete conosciamo tutti gli indirizzi IP giusti.\nAddr translation table ðŸŸ© Sembra che ad ogni richiesta ci sia una table di transizione all\u0026rsquo;interno del router che matcha porta â†’ indirizzo locale corretto!.\nEsempio funzionamento ðŸŸ© Slide\nUn client locale fa una richiesta esterna, viene inviato al router Il router salva la porta allâ€™IP interno e invia fuori Il server fuori ritorna la risposta alla porta corretta del router Il router manda questa risposta al client con l\u0026rsquo;indirizzo corrispondente a quella porta Controversie NAT (3) ðŸŸ¨+ Slide\nil router dovrebbero lavorare solamente sul livello 3 (IP), qui sta andando anche livello trasporto, per capire come mandare (infatti ha bisogno di un socket spiegato in Socket (!!!) ðŸŸ©), dato che ha bisogno anche del livello di porta).\nLâ€™obiettivo di avere piÃ¹ indirizzi Ip non dovrebbe essere risolto con questa sorta di hack, dovrebbe essere risolto con IPv6 utilizzare il NAT sembra una specie di Hack.\nInoltre tutte le richieste devono passare da questo router e manipolate per poter accedere alla rete dietro il NAT, non abbiamo il pretesto per parlare di end-to-end. (il prof. parla di lato porcherie (dietro il nat) e il lato bello che Ã¨ il fuori, e il router sembra quasi lâ€™ambiente di cambio vestiti, in modo che tutti si possano comprendere, lol).\nUna cosa molto brutta Ã¨ fare NAT di NAT. Dall\u0026rsquo;altra parte i NAT sembrano un modo per isolare computer di cui non mi fido (che conoscono un falso IP proprio che non Ã¨ raggiungibile esternamente.).\n","permalink":"https://flecart.github.io/notes/network-address-translation/","summary":"Ripasso Prox: 60 Ripasso: July 12, 2023 Ultima modifica: May 13, 2023 11:33 PM Primo Abbozzo: December 13, 2022 10:36 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso NAT Network address translation Introduzione Col il NAT possiamo avere tutto lo spazio degli IP di cui abbiamo bisogno, che perÃ² non sono esposti. All\u0026rsquo;esterno vengono esposte solamente lâ€™IP del NAT.\nSchema classico NAT\nQuindi in breve\nAll\u0026rsquo;esterno Ã¨ esposto solamente l\u0026rsquo;indirizzo del router, il router, a seconda della porta giusta, dÃ  in risposta al computer giusto, quindi all\u0026rsquo;interno della nostra rete conosciamo tutti gli indirizzi IP giusti.","title":"Network Address Translation"},{"content":"Ripasso Prox: 13 Ripasso: December 22, 2021 Ultima modifica: October 27, 2022 12:16 PM Primo Abbozzo: October 5, 2021 1:03 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Dubbi passati Capire perchÃ© nel calcolo dell\u0026rsquo;errore\nDimostrazione sottrazione fra due numeri\nCapire meglio come Ã¨ fatto la somma di due cifre in questa architettura capire meglio il codice di Hamming per correzione di un bit (provare a rifare l\u0026rsquo;esercizio da solo) Are esercizi su hamming e floating point December 8, 2021 6:21 PM 6 Rappresentazione delle informazioni 6.1 Codifiche Si utilizzano codifiche, che sono delle convenzioni\n6.1.1 Codifica posizionale Dove $d_i$ Ã¨ il valore in posizione $i$ e $b$ Ã¨ la base\n$$ \\sum_{i=0}^k d_ib $$ 6.1.2 Ottale, esadecimale e binario Queste sono le codifiche principali per i computer in quanto sono comodi da visualizzare. Inoltre Ottale e esadecimale in particolare sono riassunti dei binari, cioÃ¨ sono dei sottoinsiemi che possiedono ancora tutte le caratteristiche e quindi sono comodi\n6.1.3 Conversione di base Se la conversione Ã¨ fra ottali, esadecimali o binari allora Ã¨ molto semplice perchÃ© basta prendere un gruppo di bit e caricare un numero a seconda di quanto valga, la conversione dovrebbe essere abbastanza semplice.\nAnche la conversione da questi in base 10 non Ã¨ difficile, basta utilizzare la formula in codifica posizionale\nTecnica delle conversioni successive BINâ†’ DEC\nQuesta Ã¨ una tecnica leggermente diversa ma fatta per parti piccoline, parti dal numero piÃ¹ significativo e da lÃ¬ moltiplichi ogni volta per 2 e aggiungi 1 se c\u0026rsquo;Ã¨\nDEC â†’ BIN\nSi continua a dividere per due e si tiene il resto come risultato del numero binario.\nQuesto corrisponde al contrario delle conversioni successive\n6.2 Numeri negativi 6.2.1 Modulo e segno Un primo modo di codificare Ã¨ solamente prendere la cifra piÃ¹ significativa come se fosse un uno e contare in modo uguale, ma questa codifica non Ã¨ molto utile poi per la somma, bisogna inventare un nuovo metodo.\n6.2.2 Complemento a 1 Il complemento a 1 Ã¨ praticamente la negazione del valore di 1. La cosa che non funziona Ã¨ che la somma non funziona perfettamente, esiste un zero positivo e un zero negativo, mentre invece per il complemento a 2 funziona grazie al modulo.\nQuesta codifica riesce a fare, dati $k \\text{ bit }, [-2^{k - 1} + 1, 2^{k-1} - 1]$ Per esempio -127 e 127\nSomma\nLa somma del complemento a 1 deve tenere conto del riporto se esiste (probabilmente causato dall\u0026rsquo;esistenza di uno 0 negativo), invece il complemento a due no.\n6.2.3 Complemento a 2 Il complemento a 2 Ã¨ fattibile a con questa formula:\ndati $b_{k},b_{k-1}...b_0$ con ogni $b$ i valori in rappresentazione binaria del numero, il numero nella forma decimale corrispondente Ã¨\n$$ x = \\sum_{i=0}^{k-1}b_{i}2^k - b_k 2^k $$ In pratica Ã¨ il complemento a 1 sommato 1, si puÃ² vedere mettendo tutti i numeri su un cerchio e notare che il complemento a 2 ha la parte negativa spostata di uno, in particolare si puÃ² dire che il complemento a 2 utilizza il modulo.\n$k \\text{ bit }, [-2^{k - 1}, 2^{k-1} - 1]$, per esempio -128 fino a 127\n6.2.4 Codifica in eccesso Ad alcuni non piace che lo 0 si trovi proprio a 00000000, quindi lo metto a 10000000, cosÃ¬ a 0000000 ho il numero piÃ¹ piccolo rappresentabile. In pratica sto sommando due alla k-1 rispetto alla rappresentazione normale di complemento a due.\nScelte, non so perchÃ© lo facciano perÃ².\n6.3 Floating point 6.3.1 La codifica Bisogna definire una mantissa(frazione) e caratteristica(esponente) e segno sono gli elementi piÃ¹ importanti per la definizione di un floating point:\nIn particolare rappresentiamo N come $f \\times 10 ^{e}$ con f frazione e e esponente.\nLa mantissa Ã¨ definita tramite esponenti negativi.\n6.3.2 Overflow e underflow Questa codifica ha degli errori nella rappresentazione di numeri troppo grandi o troppo piccoli\n6.3.3 ISEE 754 Questo Ã¨ lo standard industriale per codificare floating points numbers.\nÃˆ costituito da un totale di 32 bit per BINARY32, ma esiste anche il BINARY64 che utilizza un ragionamento molto simile per i floating points:\n1 bit per segno 8 per l\u0026rsquo;esponente 23 per la mantissa 6.3.4 Tecnica codifica Per trovare la codifica di un floating point, si moltiplica per due il numero che si deve codificare, e ogni volta che l\u0026rsquo;unitÃ  Ã¨ un uno si mette un uno, altrimenti uno zero, questo perchÃ© la moltiplicazione equivale a uno shift a sinistra.\n6.4 Caratteri Creo una funzione binaria per ogni carattere esistente, storicamente si utilizzavano 8 bit per fare questa codifica, di cui i primi 32 erano caratteri speciali per la stampa tipografica, altri erano utilizzati per maiuscole e minuscole e caratteri speciali\n6.4.1 ASCII American Standard Code of information exchange, Ã¨ la codifica storica per i caratteri, questa codifica perÃ² non bastava perchÃ© bisognava aggiungere codifiche per caratteri non alfabetici oppure agli emoji\n6.4.2 Unicode Ã¨ l\u0026rsquo;espansione con 16 bit al posto di 8 ma sono finiti molto presto e quindi c\u0026rsquo;Ã¨ bisogno di qualche altra forma che possa essere molto piÃ¹ sicur\n6.4.3 UTF-8 Questa Ã¨ il nome della codifica moderna che permette di avere molti altri caratteri invece che solamente i caratteri dell\u0026rsquo;alfabeto inglese. (esempio gli accenti italiani sono codificati con UTF-8)\nDinamico in quanto puÃ² prendre da 1 a 4 byte in modo dinamico.\nEsiste anche UTF-16 ma non Ã¨ ancora diffuso come UTF-8\n6.5 Errori 6.5.1 NecessitÃ  di errori Raggi cosmici, (mandare segnali a sonde spaziali Ã¨ molto facile avere interferenze e gli errori sono comuni) Errori di memorizzazione di trasmissione Vibrazioni e radiazioni dell\u0026rsquo;ambiente circostante, quindi vogliamo trasmettere in modo che non ci siano errori di trasmissione. A volte non c\u0026rsquo;Ã¨ necessitÃ  di controllare errori: esempio il protocollo UDP\nOppure se voglio fare una transazione il codice di errore allora Ã¨ molto piÃ¹ importanti\n6.5.2 Parola codice Sto aggiungendo a m bit r bit di controllo e prendo n = m + r come la parola codice che contiene\nInformazioni di controllo correttezza (si prende che ci sia una probabilitÃ  molto piccola di errori). Informazioni da trasmettere 6.5.3 Costo controllo delle informazioni C\u0026rsquo;Ã¨ una differenza fra la correzione di un errore e il rilevamento, la correzione Ã¨ molto piÃ¹ dispendiosa. C\u0026rsquo;Ã¨ un modo per correggere in modo semplice? Con poco costo?\n6.5.4 Distanza di Hamming Praticamente Ã¨ il numero di 1 dopo che si ha uno xor fra tutti.\nPer rappresentare di mettono n numeri in un cubo n dimensionale, e si valuta la distanza fra i due.\n6.5.5 Minima distanza per trovare un errore The minimum Hamming distance is used to define some essential notions in coding theory, such as error detecting and error correcting codes. In particular, a code C is said to be k error detecting if, and only if, the minimum Hamming distance between any two of its codewords is at least k+1.\nCome mai per trovare un errore su d bytes servono d + 1 bits? come mai per corregger di piÃ¹?\n6.5.6 Minima distanza per correggere un errorre A code C is said to be k-errors correcting if, for every word w in the underlying Hamming space H, there exists at most one codeword c (from C) such that the Hamming distance between w and c is at most k. In other words, a code is k-errors correcting if, and only if, the minimum Hamming distance between any two of its codewords is at least 2k+1. This is more easily understood geometrically as any closed balls of radius k centered on distinct codewords being disjoint.[2] These balls are also called Hamming spheres in this context.[4]\nAssunto massimo un bit sbagliato abbiamo che il codice correttore deve soffisfare\n$2^m(1 + n) \\leq 2 ^n$\nIl bit di paritÃ  utilizza tanti bit.\nUna parola puÃ² essere solo una sbagliata e poi m modi di sbagliarla ancora\n6.5.7 Studio del bit paritÃ  In pratica Ã¨ lo Xor fra tutti i bit della parola, quindi molto utile per scoprire errori di un singolo bit. Utile per rilevare gli errori.\n6.5.8 Codice di hamming Sull\u0026rsquo;ALU Ci sono alcune operazioni interessanti per come l\u0026rsquo;ALU calcola ciÃ² che calcola\nDimostrazione trucco per sottrazione !\nE poi nel caso + 1, basta sommare - 1, che si conosce\nShifters ! sottrazione\n!\nE poi nel caso + 1, basta sommare - 1, che si conosce\nShifters !\n","permalink":"https://flecart.github.io/notes/rappresentazione-delle-informazioni/","summary":"Ripasso Prox: 13 Ripasso: December 22, 2021 Ultima modifica: October 27, 2022 12:16 PM Primo Abbozzo: October 5, 2021 1:03 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Dubbi passati Capire perchÃ© nel calcolo dell\u0026rsquo;errore\nDimostrazione sottrazione fra due numeri\nCapire meglio come Ã¨ fatto la somma di due cifre in questa architettura capire meglio il codice di Hamming per correzione di un bit (provare a rifare l\u0026rsquo;esercizio da solo) Are esercizi su hamming e floating point December 8, 2021 6:21 PM 6 Rappresentazione delle informazioni 6.","title":"Rappresentazione delle informazioni"},{"content":"Ripasso Prox: 23 Ripasso: January 3, 2023 Ultima modifica: December 25, 2022 10:21 AM Primo Abbozzo: October 21, 2022 10:04 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Reti di flusso Questi problemi sono una sottoclasse della programamzione lineare con variabili reali. (Alcuni riescono a riconoscere se un problema Ã¨ in questa forma, e lo risolvono in modo istantaneo se questo succede).\nUn problema dei router Ã¨ un classico problema di flusso, che si risolvono con questi algoritmi polinomiali\nNote introduttive Rete, terminologia ðŸŸ© Slide\nLo sai Grafi. ma andiamo a ripeterlo\nGrafo def Def arco e il loro peso (discreto o continuo) Nodi Cose nuove:\nSbilanciamento, mi da informazione riguardo se il nodo vuole ricevere o dare fuori, quindi il fatto che sia negativo positivo puÃ² essere buona roba.\nSlide\nImportante sapere cosa sono nodo di input, output e trasferimento e quando un nodo si puÃ² chiare in questo modo.\nOltre a ciÃ² possiamo definire capacitÃ  inferiore e superiore degli archi, e definire unconcetto di ammissibilitÃ  di un trasferimento di un arco quando la quantitÃ  che ci passa rispetta queste condizioni.\nVincoli di un problema di flusso (3) ðŸŸ¨+ Domanda e offerta globale Conservazione del flusso sol nodo locale AmissimiblitÃ  del flusso Slide\nIl perchÃ© si utilizzano grafi Ã¨ perchÃ© sono espressivi per questo genere di problemi, ossia sono molto utili per modellizzare questo. E hanno una complessitÃ  gestibile perchÃ© sono stati molto studiati ed esistono algoritmi efficienti per questa(credo)\nNormalizzazione della capacitÃ  inferiore (3) ðŸŸ©- Si tratta in questa parte di trasformare il problema in un altro problema con le capacitÃ  inferiori nulle, basta considerare questa cosa nel calcolo della funzione obiettivo e rimodulare i valori degli archi (per capacitÃ  superiore).\nLe 3 cose per normalizzare\nTogliere l a capacitÃ  superiore Aggiungere l a b (cosÃ¬ flusso si conserva Considerare il costo di questo flusso CioÃ¨ semplifico mettendo quanto deve passare per la capacitÃ  inferiore come flusso proveniente dall\u0026rsquo;esterno!\nSlide\nModelizzazione del flusso di costo minimo (!!!) (3) ðŸŸ¨- Slide\nCome si puÃ² notare la condizione Ã¨ molto facile da scrivere.\nMinimizzare il costo $cx$, con x il vettore dei flussi, c il vettore dei costi Condizione di massimo flusso $\\forall i, 0\\leq x_i \\leq u_i$, con u il vettore dei massimi E tutte le condizioni di bilanciamento $Ex = b$ con E la matrice (probabilmente sparsa) che mi calcola lâ€™incidenza (0, 1, -1 per dire esiste, entrata o uscita), che devono essere uguali a b. Condizione dei pozzi ðŸŸ©\nSpesso Ã¨ molto buono idealizzare con un solo pozzo di entrata e un solo pozzo di uscita. Al fine di avere questo risultato si creano due pozzi aggiuntivi , uno che prende tutte le entrate e una che prende tutte le uscite\nSlide costruzione dei pozzi e sorgenti\nCondizione limiti di nodoðŸŸ¨â€”\nPer modellizzare cose come i router, che sono sÃ¬ dei nodi, ma hanno dei limiti per trasmettere e ricevere creiamo un nodo fittizio che sia in grado di rappresentare questo genere di occazioni\nslide\nProblema del flusso massimo Caratteristiche flusso max (3) ðŸŸ© Slide definizione del problema\nDa notare che questo problema puÃ² essere visto come caso particolare di MCF in cui\nCosti sono nulli Sbilanciamenti sono nulli Presenza di arco fittizio con capacitÃ  infinita da target a source Tagli Definizione ðŸŸ© Slide\nIn pratica Ã¨ una partizione dei nodi di una rete.\nUn s-t taglioÃ¨ un taglio in cui s e t stanno in partizioni differenti (dato che sono due le partizioni direi che stanno nelle due partizioni corrispondenti).\nAndiamo ora a caratterizzare gli archi.\nA+ attraversa da s a t\nA- attraversa da t a s.\nEsempio di Taglio\nI rossi sono A+, i verdi sono A-\nEsempio del prof piÃ¹ contorto\nProprietÃ  !! (2) ðŸŸ© Ossia il flusso Ã¨ uguale a ciÃ² che attraversa il taglio, e tutto questo Ã¨ sempre minore alla capacitÃ  del taglio!\nDimostrazione\nPer 1 in pratica prende la differenza iniziale e riscrive i nodi di trasferimento (quindi input - output = 0) in altro modo per averlo nella forma che ci piace). Gli archi interni si cancellano fra di loro, gli archi esterni in Nt non vengono proprio contati, quindi possiamo andare a considerare solamente gli archi della frontiera quindi andiamo a finire in questo modo.\nDimo Slides\nFlusso e capacitÃ  del taglio ðŸŸ© Le proprietÃ  dei tagli spiegati in precedenza sono dei punti fondamentali per lâ€™analisi di questo problema di flusso!.\nIl valore di un flusso ammissibile Ã¨ sempre minore o uguale della capacitÃ  di qualunque taglio.\nAndremo a cercare un caso in cui il flusso = capacitÃ . In quanto trovato questo taglio, questo Ã¨ un flusso massimo! Per il lemma precedente non puÃ² crescere ancora.\nFord Fulkerson Andremo in questa parte ad introdurre alcuni concetti molto utili che ci porteranno alla definizione dellâ€™algoritmo di Ford Fulkelson.\nGrafi residui ðŸŸ© Utile per dirmi se possono ancora migliorare o meno in un arco.\nQuindi ci dÃ  un concetto di flusso rimanente per un arco (termine mio questo) utilizzato per decidere se possiamo utilizzarlo o meno per migliorare qualcosa.\nSlide\nCammini aumentanti ðŸŸ© Chiachiamo in questo modo i cammini nel grafo dei residui. Lo chiamiamo in questo modo perchÃ© ci permette di avere piÃ¹ flusso da s a t. In particolare lo utilizzo in questo modo\nSe Ã¨ un arco discorde diminuisco il valore del flusso. Se Ã¨ un arco concorde aumento il flusso. Il valore di aumento o diminuzione Ã¨ il minimo del residuo fra tutti gli archi, questa cosa la chiamiamo capacitÃ  del cammino aumentante.\nSlide\nLâ€™algoritmo ðŸŸ© Lâ€™algoritmo si traduce nel\nSetta flusso iniziale a 0 Prendi un cammino aumentante a caso, se esiste aggiungi al flusso il valore di cui Ã¨ aumentato, altrimenti ritorna il flusso. Continua finchÃ© non esci. Slide\nCorrettezza ðŸŸ¨ Per dimostrare la correttezza Ã¨ spesso molto bello trovare lâ€™invariante, in questo caso Ã¨ il seguente lemma\nSe x Ã¨ un flusso ammissibile, allora Ã¨ ammissibile anche il flusso modificato con una iterazione dellâ€™algoritmo. Se ho il flusso massimo, allora non posso trovare cammini aumentanti o flussi altri.\nSlide lemmi su flusso massimo e ammissibilitÃ , con cammini aumentanti\nLemma fondamentale per correttezza, esistenza di taglio v\nNOTA: raggiungibili con un cammino aumentante!\nIntera dimostrazione insieme\nComplessitÃ  ðŸŸ¨+ Possiamo dire che ha fine solo se ha capacitÃ  intere, altrimenti potrebbe essere che non termini mai. Il prof dice che questo algo dÃ  troppa libertÃ  per cui la complessitÃ  non Ã¨ sotto controllo.\nTeorema e dimostrazione complessitÃ  casi interi\nMa questa Ã¨ una complessitÃ  pseudopolinomiale nel senso che Ã¨ polinomiale solo se non si utilizza la compressione logaritmica nella rappresentazione degli interi (quindi polinomiale nel tempo, ma non nella rappresentazione in memoria).\nMa comunque il termine U ci Ã¨ abbastanza brutto.\nMax Flow Min Cut (!) ðŸŸ© Se riusciamo a dimostrare che il massimo flusso Ã¨ â‰¥ di un taglio allora mettendo insieme al lemma sul upper bound del massimo flusso ho finito.\nUtilizziamo il risultato nella dimostrazione di FF, assumento che abbiamo un flusso massimo, quindi non ci sono cammini aumentanti, allora abbiamo un taglio di capacitÃ  v, per cui ho finito.\nEnunciato e dimo\nEdmonds Karp Introduzione ðŸŸ© Questo algoritmo non Ã¨ altro che una implementazione di Ford_fulkerson. Quindi sappiamo giÃ  che sia corretta. Utilizza una bfs per trovare il cammino aumentante migliore.\nUtilizzando la bfs, quindi scegliemo sempre il percorso piÃ¹ corto questa Ã¨ una delle proprietÃ  di maggior rilievo per EK.\nLemma distanze di EK (non chiede dim) ðŸŸ¨â€” Questo Ã¨ un lemma che caratterizza fortemente EK, perchÃ© Ã¨ una conseguenza della sua ricerca in BFS che trova gli archi critici piÃ¹ corti prima di quelli piÃ¹ lunghi.\nÃˆ anche fondamentale per fare il calcolo della complessitÃ  dell\u0026rsquo;algoritmo!\nEnunciato\nDimostrazione (non fatta in classe) preso dal cormen\nComplessitÃ  (!!) ðŸŸ¨+ Il lemma di sopra ci permette di togliere il termine sulla capacitÃ  degli archi.\nEnunciato\nIl motivo Ã¨ che per il lemma precedente ogni arco puÃ² essere considerato al piÃ¹ |N| volte, con N il numero dei nodi. Quindi Applico BFS, per ogni arco, al piÃ¹ N volte, costo $O(NM^2)$\nHint dimostrazione\nAndiamo a considerare gli archi che vengono saturati durante il percorso di un cammino aumentante (questo esiste sempre perchÃ© il cammino aumentante Ã¨ costruito sul minimo del percorso.\nVogliamo dire che ogni arco puÃ² essere al massimo considerato critico N volte, per cui al massimo ho NA.\nDopo aver fatto questa osservazione, bisogna andare a fare un ragionamento sulla distanza, che continua a crescere per ogni iterazione, e lo puÃ² fare per al massimo il numero di nodi, prima di diventare staccato.\nDimostrazione\nGoldberg-Tarjan Slide algoritmo\n!\n","permalink":"https://flecart.github.io/notes/reti-di-flusso/","summary":"Ripasso Prox: 23 Ripasso: January 3, 2023 Ultima modifica: December 25, 2022 10:21 AM Primo Abbozzo: October 21, 2022 10:04 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Reti di flusso Questi problemi sono una sottoclasse della programamzione lineare con variabili reali. (Alcuni riescono a riconoscere se un problema Ã¨ in questa forma, e lo risolvono in modo istantaneo se questo succede).\nUn problema dei router Ã¨ un classico problema di flusso, che si risolvono con questi algoritmi polinomiali","title":"Reti di flusso"},{"content":"1 Spazi vettoriali 1.1 Piano cartesiano 1.1.1 Definizione Possiamo considerare il piano cartesiano come l\u0026rsquo;insieme $\\R^2$ potremmo dire che esiste una corrispondenza fra una coordinata e un punto del piano, una volta che abbiamo definito un punto di origine. Si puÃ² vedere anche come corrispondenza biunivoca con vettori del piano per l\u0026rsquo;origine (parte dall\u0026rsquo;origine).\nQuesta cosa vale anche per uno spazio n-dimensionale, non soltanto due, ma per semplicitÃ  di introduzione di questo lo faccio con 2\n1.1.2 Operazioni definite Possiamo definire una somma fra questi punti in coordinata e un prodotto.\nSomma\n$\\forall a,b,c,d \\in \\R \\,\\,\\langle a,b\\rangle + \\langle c,d \\rangle = \\langle a + c, b+d\\rangle$\n(dovremmo definire invece queste cose nello spazio vettoriale, in quanto non necessariamente dobbiamo averle in R)\nProdotto scalare\n$\\forall a,b \\in V, \\lambda \\in \\R, \\lambda\\langle a, b\\rangle = \\langle \\lambda a, \\lambda b \\rangle$\n1.2 Introduzione agli spazi vettoriali 1.2.1 Assiomi di base Definiamo qui le proprietÃ  necessarie per essere uno spazio vettoriale.\nGruppo abeliano rispetto alla addizione (4) $V \\times V \\to V$ Moltiplicazione Ã¨ scalare, definito su un campo $C \\times V \\to V$ AssociativitÃ  Neutro Vale distributivitÃ  destra e sinistra che collega addizione e prodotto 1.2.2 Conseguenze principali degli assiomi 1.2.3 Interpretazione geometrica (2) Principalmente ci sono due interpretazioni possibili. Per punti o vettori.\nPunti esiste una corrispondenza biunivoca fra uno spazio n-dimensionale e la coordinata Vettori esiste una corrispondenza biunivoca fra vettori che iniziano dall\u0026rsquo;origine e in punti. 1.2.4 Polinomi a coefficienti in R (Esempio) Questo Ã¨ un esempio di spazio vettoriale. Si puÃ² fare una verifica per vedere che gli assiomi sono soddisfatti.\nAltri spazi vettoriali sono l\u0026rsquo;insieme delle matrici con coefficienti reali, l\u0026rsquo;insieme delle funzioni continue in R.\n1.2.5 Sottospazio vettoriale (def e banale) Un sottospazio vettoriale Ã¨ un sottoinsieme che Ã¨ chiuso per l\u0026rsquo;addizione e moltiplicazione.\nSia U un sottospazio di V, allora per definizione vale:\nU non Ã¨ vuoto chiuso rispetto somma Chiuso rispetto moltiplicazione Il sottospazio banale Ã¨ un sottospazio che contiene solo l\u0026rsquo;elemento nullo per l\u0026rsquo;addizione\nSi puÃ² anche trovare una serie di assiomi equivalenti per il sottospazio\n1\u0026rsquo;. il vettore $0_v$appartiene al sottospazio U, e valgono 2 e 3\nE si puÃ² scrivere una proprietÃ  equivalente a 2 e 3, ossia chiuso rispetto a una combinazione lineare.\nEsercizio\nDimostrare che le ipotesi 2 e 3 implicano che $\\lambda a + \\lambda_2b \\in V,$ con i lambda valori del campo.\n1.2.6 Minimi sottospazi (classificazione sottospazi di R2) Se prendiamo un punto nel piano, ci basta una retta che passa per essa e per l\u0026rsquo;origine per avere il minimo sottospazio che lo contenga.\nIl ragionamento per dire che Ã¨ il minimo Ã¨ piÃ¹ o meno su questa scia:\nSe contiene quel punto diverso da 0, allora deve contenere tutti i punti sulla retta almeno (altrimenti non Ã¨ chiuso per il prodotto scalare). Se ne contiene di piÃ¹ non Ã¨ piÃ¹ il minimo sottospazio, se ne contenesse di meno allora ci sarebbe un assurdo con il punto uno. Si puÃ² dire la stessa cosa per 2 o piÃ¹ punti allineati. Se perÃ² non sono allineati, allora devo prendere il loro span. Ovvero se ho $u, v$ indipendenti fra di loro allora il minimo sottospazio Ã¨\n$\\alpha v + \\beta u$ che Ã¨ l\u0026rsquo;intero piano. (questo poi Ã¨ anche la condizione 23 per dimostrare che Ã¨ sottopiano).\nSu questa analisi puÃ² dimostrare che gli unici sottospazi di R2 sono 3.\nBanale Retta R2 Possiamo formalizzare il senso di piÃ¹ piccolo sottospazio che contiene un elemento come l\u0026rsquo;insieme sottospazio che Ã¨ contenuto in ogni altro sottospazio (e si potrebbe dire quindi anche che non esiste un altro sottospazio piÃ¹ piccolo)\n1.3 Combinazioni lineari 1.3.1 definizione Si dice che $v$ Ã¨ combinazione lineare di vettori $v_1, ... v_n$ se esistono $\\lambda_1,...,\\lambda_n \\in K$ tali che\n$\\lambda_1v_1 + ....+ \\lambda_n v_n = v$\nPossiamo prendere l\u0026rsquo;insieme delle combinazioni lineari cihe scriviamo come\n$\\langle v_1, ..., v_n \\rangle = \\{\\lambda_1 v_1 +... + \\lambda_n v_n | \\lambda_1, ..., \\lambda_n \\in R\\}$\nSe $V = \\langle v_1, ..., v_n \\rangle$ allora i vettori $v_1, ..., v_n$ generano lo spazio vettoriale $V$\n1.3.2 Proposizione 3.1.5 minimo sottospazio (chiede in esame) Enunciato:\nSia $V$ uno spazio vettoriale, allora $v_1, ..., v_n \\in V$ allora $\\langle v_1,...v_n\\rangle$ Ã¨ uno sottospazio vettoriale di $V$ ed Ã¨ il minimo sottospazio vettoriale contenenti questi punti.\nDimostrazione: esercizio (non troppo complessa).\nhint di dimostrazione\nBisogna dimostrare due cose: 1 Ã¨ uno sottospazio vettoriale (soddisfa quei tre requisiti) e 2 Ã¨ il minimo sottospazio vettoriale, quindi qualunque latro sottospazio vettoriale che contiene quei punti contiene anche questo spazio vettoriale).\n1.3.3 Prop 3.1.8 dipendenza lineare + 1 (relativo a span) sia $\\langle v_1, ..., v_n \\rangle$ uno spazio vettoriale generato da quei vettori, considero $\\langle v_1, ..., v_n, \\omega \\rangle$ con $\\omega$ una combinazione vettoriale dei vettori base, allora si ha che\n$\\langle v_1, ..., v_n \\rangle = \\langle v_1, ..., v_n, \\omega \\rangle$\nHint di dimostrazione\nil primo Ã¨ contenuto nel secondo (abbastanza ovvio, basta che tengo W 0), devo dimostrare che il secondo Ã¨ contenuto nel primo.\n(in pratica riesco a dimostrare che qualunque combinazione lineare con $\\omega$ Ã¨ esprimibile come combinazione lineare dei vettori che generano lo spazio vettoriale iniziale\nUn altro modo per dimostrarlo Ã¨ prendere Z generato dal primo insieme di vettori, so che tutti questi vettori sono contenuti in Z, cosÃ¬ anche omega Ã¨ contenuto, allora si ha per la 3.1.5 che questo spazio vettoriale Ã¨ contenuto in Z.\nSi puÃ² dimostrare una cosa anche contraria, ovvero\n$\\langle v_1, ..., v_n \\rangle = \\langle v_1, ..., v_n, \\omega \\rangle \\implies \\omega$ combinazione lineare di $v_1,..., v_n$\n1.4 Indipendenza lineare Questo concetto di indipendenza lineare ci permette di definire una base per uno spazio vettoriale (ossia il minimo insieme di vettori necessario per generare uno spazio)\n1.4.1 Definizione Un insieme di vettori $v_1,..., v_n$ sono linearmente indipendenti sse $\\alpha_1v_1 + ... + \\alpha_nv_n = 0 \\iff \\alpha_1 = ... = \\alpha_n = 0$\nUn insieme di vettori allora si dice linearmente dipendente se esiste un insieme di coefficienti tali che non tutti diversi da zero ottengo che $\\alpha_1v_1 + ... + \\alpha_n = 0$\nOsservazione\nSe un insieme di vettori contiene il vettore $0_v$ allora so per certo che sono linearmente dipendenti in quanto a questo vettore posso molitplicare qualunque cosa, fatto che va contro la definizione di indipendenza lineare\n1.4.2 Prop 3.2.4 Corrispondenza combinazione e dipendenza lineare (chiede) Enunciato\nSe $v_1,...,v_n$ vettori dipendenti fra loro $\\iff$ almeno uno di essi Ã¨ combinazione lineare di dell\u0026rsquo;insieme dei vettori in questione.\nDimostrazione\n$\\implies$\nSiano v1\u0026hellip; vn vettori dipendenti fra loro, dobbiamo dimostrare che esiste uno che sia combinazione lineare di altri.\nPer ipotesi di dipendenza se $\\lambda_1v_1 +... + \\lambda_nv_n =0, \\exists k, 0 \u003c k \\leq n, \\lambda_k \\neq 0$.\nAllora $\\lambda_kv_k = -(\\lambda_1v_1 +...+ \\lambda_{k-1}v_{k-1} +\\lambda_{k+1}v_{k+1} +...+ \\lambda_nv_n)$ e da qui Ã¨ abbastanza ovvio che posso scrivere $v_k$ come combinazione lineare di altri.\n$\\impliedby$\nSia $v_k$ una combinazione lineare dell\u0026rsquo;insieme di vettori $v_1, ..., v_{k-1},v_{k+1},..., v_n$\nAllora ho che $v_k = \\lambda_1v_1 +...+ \\lambda_{k-1}v_{k-1} +\\lambda_{k+1}v_{k+1} +...+ \\lambda_nv_n$ per certi valori di lambda.\nAllora se considero questa combinazione lineare\n$-\\lambda_1v_1 +... -\\lambda_{k-1}v_{k-1} + 1\\cdot v_k -\\lambda_{k+1}v_{k+1} +...- \\lambda_nv_n$ ottengo che questo Ã¨ uguale a 0 e in particolare ho che il coefficiente di $v_k$ Ã¨ diverso da 0, quindi questi vettori sono dipendenti.\nOsservazione (sui multipli)\nNel caso in cui ho due vettori, il fatto che uno Ã¨ combinazione lineare dell\u0026rsquo;altro Ã¨ equivalente a dire che uno Ã¨ multiplo dell\u0026rsquo;altro.,\n1.4.3 Geometria nella dipendenza lineare Due vettori\nAbbiamo detto che due vettori sono linearmente dipendenti quando uno sono multiplo dell\u0026rsquo;altro, possiamo intendere questo fatto algebrico come un fatto geometrico osservando che tali vettori devono giacere sulla stessa retta\nTre vettori\nIn modo analogo al precedente, possiamo concludere che tre vettori sono linearmente dipendenti sse giacciono su uno stesso piano (COMPLANARI)\nPiÃ¹ vettori\nSe ho n vettori, questi se fossero indipendenti giacerebbero su uno spazio n-dimensionale, appena Ã¨ possibile esprimerli come appartenenti a uno spazio di dimensione minore di n, allora posso dire che questi n vettori sono dipendenti, questa Ã¨ l\u0026rsquo;astrazione necessaria per comprendere questo fatto.\n","permalink":"https://flecart.github.io/notes/spazi-vettoriali/","summary":"1 Spazi vettoriali 1.1 Piano cartesiano 1.1.1 Definizione Possiamo considerare il piano cartesiano come l\u0026rsquo;insieme $\\R^2$ potremmo dire che esiste una corrispondenza fra una coordinata e un punto del piano, una volta che abbiamo definito un punto di origine. Si puÃ² vedere anche come corrispondenza biunivoca con vettori del piano per l\u0026rsquo;origine (parte dall\u0026rsquo;origine).\nQuesta cosa vale anche per uno spazio n-dimensionale, non soltanto due, ma per semplicitÃ  di introduzione di questo lo faccio con 2","title":"Spazi vettoriali"},{"content":"Ripasso Prox: 60 Ripasso: June 1, 2023 Ultima modifica: June 1, 2023 12:46 PM Primo Abbozzo: October 21, 2022 1:09 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Domande chieste\nGrammatiche regolari Introduzione Definizione grammatica regolare ðŸŸ© Definizione\nIn pratica posso avere solamente come terminali a, oppure un suffisso a su un non terminale.\nQueste grammatiche sono interessanti perchÃ© Ã¨ molto facile costruire un automa che sia in grado di riconoscere questo linguaggio.\nSeguendo una definizione piÃ¹ lasca possono anche accettare dei nonterminali epsilon\nEspressione regolare a NFA ðŸŸ© Questa sezione Ã¨ anche presente in Automi e Regexp, perÃ² Ã¨ riportata qui cosÃ¬ câ€™Ã¨ lâ€™insieme di tutte le cose in un unico posto.\nEnunciato\nDimostrazione\nMi creo un automa che riconosce in modo ricorsivo (per tutte le produzioni della grammatica delle regexp\nGuarda lezione 7\nDa grammatica regolare a NFA (!) ðŸŸ© In modo simile a quanto si fa per la dimostrazione per espressioni regolari rappresentabili come NFA anche questa Ã¨ cosÃ¬\nDimostrazione\nDa DFA a grammatica regolare (chiede) ðŸŸ© Dimostrazione\nGrammatica regolare a linguaggio regolare ðŸŸ© Dimostrazione molto informale\nPraticamente l\u0026rsquo;idea principale Ã¨ fare rimpiazzamenti ricorsivi finchÃ© non lo ho in una forma bella.\nRiassunto tutte le equivalenze NFA, DFA, grammatiche ed espressioni.\nRiassunto delle equivalenze ðŸŸ©- Câ€™Ã¨ una precisa domanda che chiede di discutere in modo generale le equivalenze, quindi metto anche questo doc.\nSlide\nCostruzione dello scanner Introduzione ðŸŸ© Slide\nPer fare questa cosa rientra il problema di creazione della DFA da NFA piÃ¹ piccola possibile!.\nNon so come si faccia, ma almeno ora sai che esiste questo problema.\nAd intuito possiamo andare ad affermare che un automa Ã¨ minimo quando non ci sono due stati equivalenti ossia, sempre ad intuito, non li possono compattare in uno, quindi non ho ridondanza di stati.\nEsempio di minimizzazione\nEquivalenza ed indistiguibilitÃ  (di stati) ðŸŸ© Slide\nOssia se due stati sono in grado di riconoscere esattamente lo stesso linguaggio, sono equivalenti. Ma ogni stringa del linguaggio Ã¨ una cosa difficile da gestire, per questo motivo provo a dimostrare che non siano equivalenti, ossia lo stato di accettazione per una stessa stringa sia diversa partendo dalla stringa vuota\nSlide strategia\nProvo a togliere tutti\nFamiglia di relazioni (5) ðŸŸ©- Slide\nIn pratica sto andando a guardare se lo stato finale Ã¨ lo stesso o meno, partendo dalla stringa nulla, poi andando avanti a costruire altre, e continuando a togliere se lo stato finale ora Ã¨ diverso.\nQuesta Ã¨ una relazione di equivalenza.\nProprietÃ \nDimo proprietÃ  4, se non cambia ho finito ðŸŸ¨ Ossia se non tolgo piÃ¹ coppie in un passo, allora il mio algoritmo dovrÃ  essere finito.\nDimostrazione\nEsempio di applicazione dellâ€™algoritmo di minimizzazione\nMinimizzazione In questa parte andremo a trattare definizioni e algoritmi utili a minimizzare un automa DFA (nel senso di meno stati possibili).\nAlgoritmo degli stati equivalenti ðŸŸ© Algos\nPraticamente vado a marcare per tutte le cose possibili (partendo dalla relazione 0). Vado a marcare se non appartengono alla stessa relazione di equivalenza (ossia sono diversi). E se i percorsi piÃ¹ lunghi finiscono su altre celle giÃ  occupate, allora marco anche questo, con un segno diverso, per dire che non sono equivalenti per un certo percorso piÃ¹ lungo.\nDimostrazione correttezza algoritmo ðŸŸ¨+ Enunciato di terminazione e correttezza dellâ€™algoritmo\nDimostrazione di sopra\nTerminazione Ã¨ dipendente dalla proprietÃ  4 a 5, cioÃ¨ che se non cambia a un passo, allora non cambia a nessun passo, e la 5 che mi dice che ad ogni passo ne marco almeno uno (e questi sono numeri finiti).\nDistinguibilitÃ  se la casella marcata allora esiste un percorso che termina in modo diverso da uno rispetto all\u0026rsquo;altro, in altro termine esiste una stringa che Ã¨ riconosciuta da uno ma non Ã¨ riconosciuta da un altro! (ma se lo ho marcato in questo modo allora Ã¨ ovvio che succeda questo!).\nAutoma minimo (4) ðŸŸ© Questa definizione tratta le caratteristiche formali di un automa minimo costruito da un DFA valido.\n(minimizzare gli stati, la funzione di transizione e gli stati accettati).\nIn pratica nello stesso stato dellâ€™automa minimo ci metto tutti gli stati equivalenti ad essa, in questo senso di minimo!\nDefinizione\nProbabilmente in questo passo intendevo sono 3 le cose nuove differenti\nStati possibili devono essere gli equivalenti fra tutti. Transizioni Ã¨ ora fatto su stati equivalenti Stato iniziale Ã¨ la classe di equivalenza sullo stato iniziale Gli stati accettati sono le classi si equivalenza sugli stati finali.. Alfabeto Ã¨ lo stesso. Equivalenza automa minimo e originale (non chiede) ðŸŸ¨â€” Slide linguaggio riconosciuto Ã¨ lo stesso, ed Ã¨ anche il minimo\nDimostrazione\nIn pratica per dimostrare il minimo suppongo che esista un automa con ancora meno stati, questi due (il minimo nuovo e il minimo costruito) devono riuscire a riconoscere esattamente le stesse cose, ma essendo questo con ancora meno, deve essere che il minimo costruito abbia due stati equivalenti, cosa che non puÃ² succedere col nostro algoritmo\nLex/Flex e Yacc Questi sono analizzatori lessicali che prendono in input un file di definizioni regolari e restituisce un programma in C che riesca a riconoscere questi automi\nDiagramma semplificativo di quanto fa\nStruttura di file Lex (3) ðŸŸ© Slide riassunto\nDichiarazioni\nPraticamente in sta parte ci sono le definizioni regolari che abbiamo discusso piÃ¹ sopra nello stesso documento che ci rende la scrittura di espressioni regolari molto piÃ¹ semplice\nRegole\nQui definisci tutte le espressioni regolari che ti servono. Definite in schema di\nPattern â†’ azione\nOssia se un pattern Ã¨ riconosciuto, esegui una azione.\nFunzioni ausiliarie\nNel caso in cui le azione sono tropp complesse una serie di funzioni ausiliare possono essere molto utili\nFunzionamento di Lex (4) ðŸŸ¨+ In questa parte descriviamo brevemente le regole che il lex utilizza per decidere cosa fare.\nMatcha seguendo le regole A paritÃ  di matching diversa, sceglie quello il matching piÃ¹ lungo A paritÃ  di lunghezza di matching, sceglie quello listato prima Se non matcha, viene dato in output la stringa inalterata Esistono funzioni per gestire i match, la stringa matchata, la lunghezza della stringa matchata (yytext e yylenght) Esistono funzioni per matchare di piÃ¹ o di meno, come yymore e yyless. Yacc ðŸŸ© A differenza di Lex, Yacc si occupa di generare la sintassi.\nQuesto Ã¨ un analizzatore sintattico, quindi sarÃ  trattato nel dettaglio in un capitolo successivo. Per ora basta capire che i processi di scanning e parsing sono eseguiti piÃ¹ o meno in parallelo, Ã¨ il parser che chiede ogni volta il token, evitando di avere in memoria rappresentazioni differenti della stessa cosa.\nyylval sono variabili comuni che permettono di scambiare informazioni.\nyylex() Ã¨ cchiamato da yacc nel momento di richiesta di lessemi\nPumping Lemma (!!!) ðŸŸ© Enunciato\nDimostrazione\nNegazione del pumping lemma\nAlcuni esercizi da fare\npumpingLemmaExerALRsol.pdf\nProprietÃ  dei linguaggi regolari (5) ðŸŸ© unione concatenazione stella di Kleene Complemento Intersezione Dimostrazione\n","permalink":"https://flecart.github.io/notes/grammatiche-regolari/","summary":"Ripasso Prox: 60 Ripasso: June 1, 2023 Ultima modifica: June 1, 2023 12:46 PM Primo Abbozzo: October 21, 2022 1:09 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Domande chieste\nGrammatiche regolari Introduzione Definizione grammatica regolare ðŸŸ© Definizione\nIn pratica posso avere solamente come terminali a, oppure un suffisso a su un non terminale.\nQueste grammatiche sono interessanti perchÃ© Ã¨ molto facile costruire un automa che sia in grado di riconoscere questo linguaggio.","title":"Grammatiche Regolari"},{"content":"Ripasso Prox: 30 Ripasso: January 1, 2022 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: September 24, 2021 10:13 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Dubbi vecchi Sulle premesse di antinomi e paradossi. Capire cantor per l\u0026rsquo;ultimo paradosso Se ti va approfondisci la prima teoria degli insiemi e la storia del dibattito matematico iniziale. Funzioni non totali 1 Paradossi Metalinguistici 1.1 Antinomie e Paradossi 1.1.1 Antinomia Definizione di antinomia Ã¨ un ragionamento corretto da cui deriva una conclusione errata, probabilmente Ã¨ l\u0026rsquo;insieme o campo in cui stiamo operando ad essere errato e bisogna cercare di ridefinirlo in modo piÃ¹ corretto, in quanto le premesse erano accettabili\n1.1.2 Paradosso Paradosso quando il ragionamento corretto va contro l\u0026rsquo;intuizione, come il paradosso dei gemelli in fisica e simili. premesse erano accettabili\nFalsi paradossi: in cui c\u0026rsquo;Ã¨ un errore del ragionamento da cui viene dedotto un ragionamento errato.\n1.2 Linguaggio naturale Da ora NL = Natural Language\n1.2.1 Caratteristiche del NL Il linguaggio naturale Ã¨ il linguaggio comunemente utilizzato come italiano, inglese arabo e cinese etc. utilizzato nella maggior parte della vita quotidiana.\nQuesto linguaggio non Ã¨ utile per i ragionamenti rigorosi come descrizione del calcolo o dimostrazioni in quanto questo linguaggio Ã¨:\nFortemente dipendente dal contesto Ambigua grammatica: e.g. Il poliziotto ha ucciso il ladro con la pistola (pistola mezzo oppure compagnia?) 1.2.2 Paradossi in NL Paradossi visti in classe:\nIo mento eterologico Ã¨ eterologico. Le cause individuate per i paradossi sono\nUtilizzo meta-linguistico, ce si riferisce sul linguaggio stesso (Io mento).\nLinguaggio naturale potrebbe essere cosÃ¬ ampio che puÃ² parlare di sÃ© stesso, per esempio: contare numero di sillabe o parole, o mischiare il senso del linguaggio o simile, questo genera paradossi. Sarebbe difficile esprimere idee senza la negazione in poche parole. Per scoprire l\u0026rsquo;utilizzo meta linguistico si utilizza un teorema di invarianza delle denotazioni\nAuto applicazione di meta-linguistico a se stesso (eterologico Ã¨ eterologico).\nCerco di usare qualcosa su sÃ© stesso, anche se la definizione dell\u0026rsquo;aggettivo non dovrebbe essere utilizzate in questo modo, possiamo dire che perde di senso L\u0026rsquo;utilizzo della negazione (x minore non definibile in meno di 1000 parole).\nL\u0026rsquo;utilizzo della negazione su sÃ© stesso e anche la negazione di sÃ© stesso crea antinomia (paradosso NL) 1.2.3 Ricerca di un linguaggio formale La negazione Ã¨ necessaria per fare i ragionamenti, non si puÃ² togliere.\nNon si riesce a evitare di applicare una definizione su sÃ© stessa, dopo che hai oggetto e soggetto puoi scegliere dove applicarlo, cioÃ¨ Ã¨ brutto evitare solamente l\u0026rsquo;applicazione a sÃ© stesso, una volta creata la preposizione puÃ² essere usata senza questi piccoli vincoli.\nI\u0026rsquo;uso metalinguistico invece si puÃ² evitare, e quindi bisogna abbandonare il linguaggio naturale e approdare in un linguaggio artificiale, il linguaggio rigoroso della matematica.\n1.3 Linguaggio Matematico 1.3.1 Storia dell\u0026rsquo;insiemistica Quando ancora la matematica non era ancora scienza diversa dalla informatica, i matematici si mettevano proprio a calcolare modi di calcolo,\nVennero studiate le basi e introdotte la teoria degli insiemi, da Cantor, una base per tutta la matematica attuale, ma questo viene messo in crisi dal paradosso di Russel, creando due filosofie matematiche, gli insiemisti e altri contrari.\nParadosso di Russel: $X = \\{ Y \\,|\\, Y \\not\\in Y \\, \\}$ e si ha ancora un paradosso auto-refere\nDopo tutta questa diatriba, venne creato circa nel 1930 il significato di calcolare, credo e venne creato il campo dell\u0026rsquo;informatica.\n1.3.2 Paradosso di Russel Analisi del paradosso\nPossiamo vedere che la teoria degli insiemi Ã¨ possibile creare paradossi:\nPresente l\u0026rsquo;uso della negazione La negazione, la caratteristica usata Ã¨ fatta in modo autoreferenziale Gli insiemi possono contenere sÃ© stessi, e quindi Ã¨ possibile l\u0026rsquo;use meta-linguistico. Quindi non puÃ² esistere un insieme che li contenga tutti come voleva sostenere Cantor.\nSoluzione trovata\nSu questa soluzione basa l\u0026rsquo;intera matematica e non si sa se ci sono altri paradossi dentro questo. Potrebbe essere errata anche questa.\nLimitazioni sulla creazione di insiemi che abbiano proprietÃ  comunque â†’ Assioma di comprensione deve essere gettata. Assioma di separazione ovvero gli elementi devono essere presi da un insieme esistente e una proprietÃ  di questo insieme (quindi posso solamente restringere un insieme). Ãˆ definita come separata la collezione di tutti gli insiemi, per evitare il paradosso di autoreferenzialitÃ , prevenire l\u0026rsquo;uso meta-linguistico. 1.4 Paradossi Informatici 1.4.1 Esistenza di paradossi La composizione di funzioni, cioÃ¨ l\u0026rsquo;utilizzo in modo meta-linguistico delle informazioni informatiche Ã¨ necessaria Sia in linguaggi funzionali, imperativi, basta saltare, quindi si puÃ² modificare un programma ~~ Insieme che contiene insieme, molto simile questa cosa. La negazione delle affermazioni Ã¨ necessaria Una funzione applicata su sÃ© stessa Ã¨ presente, possibilissima l\u0026rsquo;autoreferenzialitÃ  Per questo motivo non si puÃ² evitare il paradosso nell\u0026rsquo;ambito dell\u0026rsquo;informatica.\n1.4.2 Paradosso sulle funzioni non totali Riguardare se sei in grado di definire il significato di\nEspressivitÃ  di un linguaggio\nConvergenza e divergenza di una funzione\ntotalitÃ  di una funzione\nTotalitÃ  significa che una funzione riesca a restituire un output in tempo finito.\n$f(g) = not\\,(g(g))$ Ã¨ una funzione che puÃ² creare un paradosso, se analizzata si possono trovare tutti i tre ingredienti per la creazione di paradosso:\nC\u0026rsquo;Ã¨ la negazione, c\u0026rsquo;Ã¨ l\u0026rsquo;uso meta-linguistico (composizione di funzione) e se al posto di $g$ ci metto $f$ c\u0026rsquo;Ã¨ anche l\u0026rsquo;auto-referenzialitÃ , creando un paradosso.\nðŸ’¡ Le funzioni matematiche danno sempre risultato, invece le funzioni informatiche possono divergere. 1.4.3 Paradosso sulla divergenza Questo Ã¨ il problema della fermata discusso in Halting Theorem and Reducibility#Halting theorem Nelle funzioni informatiche c\u0026rsquo;Ã¨ una fase di calcolo ed elaborazione delle informazioni. Nelle funzioni matematiche sono solamente una relazione fra insiemi (ossia calcolano un unico input). Una funzione tale che $f(g,x) = true \\, iff \\, g(x) \\downarrow$ Definisco una funzione: $h(g) = \\uparrow if \\,f(g,g) \\, else \\downarrow$\nQuesto porta alla conclusione che non esiste un programma che decida se un altro diverga.$f(g) = \\uparrow if \\,f(g,g) \\, else \\downarrow$\n1.4.4 Paradosso sull\u0026rsquo;espressivitÃ  di funzioni matematiche Spiegata per filo e per segno per la diagonalizzazione di cantor Relazioni fra insiemi#Diagonalizzazione di Cantor\n!\n","permalink":"https://flecart.github.io/notes/logica-meta-linguistica/","summary":"Ripasso Prox: 30 Ripasso: January 1, 2022 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: September 24, 2021 10:13 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Dubbi vecchi Sulle premesse di antinomi e paradossi. Capire cantor per l\u0026rsquo;ultimo paradosso Se ti va approfondisci la prima teoria degli insiemi e la storia del dibattito matematico iniziale. Funzioni non totali 1 Paradossi Metalinguistici 1.1 Antinomie e Paradossi 1.1.1 Antinomia Definizione di antinomia Ã¨ un ragionamento corretto da cui deriva una conclusione errata, probabilmente Ã¨ l\u0026rsquo;insieme o campo in cui stiamo operando ad essere errato e bisogna cercare di ridefinirlo in modo piÃ¹ corretto, in quanto le premesse erano accettabili","title":"Logica meta-linguistica"},{"content":"Ripasso Prox: 3 Ultima modifica: May 8, 2022 11:57 AM Primo Abbozzo: April 12, 2022 12:50 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso 10 Tecniche Algoritmiche 13-DivideEtImpera.pdf\n10.1 Divide et impera 10.1.1 Introduzione Abbiamo giÃ  visto L\u0026rsquo;utilizzo di questa tecnica per quick e merge sort in Algoritmi di ordinamento\nQuesta tecnica si focalizza in tre passi fondamentali:\nDividere il problema in sotto-problemi Risolvere il sotto-problema Mergiare le soluzioni di questi sotto-problemi. Questa Ã¨ piÃ¹ una tecnica che si impara di piÃ¹ con la pratica, andremo a fare un problema che utilizza questa tecnica\n10.1.2 La torre di Hanoi Storia sotto\nEnunciato\nSoluzione con ricorsione\n10.1.3 Moltiplicazione fra interi Si utilizza una tecnica divide ed impera per moltiplicare assieme i due numeri.\nQuindi divido il numero in parte superiore e parte inferiore\u0026hellip;\nPrima applicazione\nMa si potrÃ  notare che questo metodo non porta a migliroamenti\nMoltiplicazione piÃ¹ efficiente\n10.1.4 Sottovettore di valore massimo Questo Ã¨ un problema classico che ho giÃ  riscontrato in maximum subarray sum.\nAlgoritmo banale\nVa a guardare tutte le sottosequenze possibili, che sono O(N2) perchÃ© Ã¨ uguale al numero di coppie di indici (ordinate) che si possono prendere.\nAlgoritmo Divide et Impera\nSi nota che la massima sottosequenza Ã¨ o nella parte destra o sinistra, oppure in mezzo, quindi si conside\nAlgo\n10.2 Greedy Greedy Ã¨ buono quando si puÃ² Dimostrare (e se non lo dimostri perdi un sacco di tempo a implementare una soluzione che non Ã¨ nemmeno giusta) e si basa sui sottoproblemi ottimali.\n10.2.1 Problema del resto In cui basta scegliere la moneta migliore ogni volta (perchÃ© sicuramente(con piccolo ragionamento) ci vorranno meno monete rispetto a usare altre)\nUn osservazione Ã¨ che puÃ² fallire in sistemi non CANONICI.\n10.2.2 Job scheduling Si avrÃ  che basta ordinare secondo la lunghezza minore (perchÃ© si guadagna sempre in questo caso)\nHuffman coding Si crea un albero di codifica che sia il meno profondo possibile, in questo modo ho un modo piÃ¹ formale per giustificare il fatto di avere la minima codifica.\nPseudocodice per lâ€™albero di huffman.\nHuffman(real f[1..n], char c[1..n]) â†’ Tree Q â† new MinPriorityQueue() integer i; for i â† 1 to n do z â† new TreeNode(f[i], c[i]); Q.insert(f[i], z); endfor for i â† 1 to n â€“ 1 do z1 â† Q.findMin(); Q.deleteMin(); z2 â† Q.findMin(); Q.deleteMin(); z â† new TreeNode(z1.f + z2.f, \u0026#39;\u0026#39;); z.left â† z1; z.right â† z2; Q.insert(z1.f + z2.f, z); endfor return Q.findMin(); Programmazione dinamica Abbiamo risolto fibonacci, Maximum subarray sum con la programmazione dinamica, entrambi in O(n).\nOra andiamo a parlare del problema piÃ¹ importante per la programmazione dinamica, il problema dello zaino\nKnapsack problem z\nDistanza di levenstein Seam Carving 11 Registro ripassi ante per la programmazione dinamica, il problema dello zaino Knapsack problem z\nDistanza di levenstein Seam Carving 11 Registro ripassi ","permalink":"https://flecart.github.io/notes/tecniche-algoritmiche/","summary":"Ripasso Prox: 3 Ultima modifica: May 8, 2022 11:57 AM Primo Abbozzo: April 12, 2022 12:50 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso 10 Tecniche Algoritmiche 13-DivideEtImpera.pdf\n10.1 Divide et impera 10.1.1 Introduzione Abbiamo giÃ  visto L\u0026rsquo;utilizzo di questa tecnica per quick e merge sort in Algoritmi di ordinamento\nQuesta tecnica si focalizza in tre passi fondamentali:\nDividere il problema in sotto-problemi Risolvere il sotto-problema Mergiare le soluzioni di questi sotto-problemi.","title":"Tecniche algoritmiche"},{"content":"Ripasso Prox: 19 Ripasso: May 22, 2023 Ultima modifica: May 6, 2023 5:58 PM Primo Abbozzo: April 3, 2023 1:22 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Algebra dei tipi Slide introduzione algebra dei tipi\nEquivalenza dei tipi (2) ðŸŸ© Quando possiamo dire che due tipi siano uguali? Solitamente vengono utilizzati due metodi:\nEQUIVALENZA NOMINALE\nQuando un nuono tipo introduce un nuovo nome diverso fra tutti i presenti. Credo cosÃ¬ vada golang.\nQuindi in questo caso si puÃ² dire che un tipo Ã¨ equivalente solamente a sÃ© stesso.\nVogliamo fare in questo modo perchÃ© se definiamo un nuovo tipo solitamente dovrebbe avere funzioni diverse, quindi Ã¨ giusto che sia diverso da uqello iniziale.\nSlide equivalenza nominale\nEQUIVALENZA DI STRUTTURA\nOssia quando tutte le operazioni, strutture e sottoelementi sono uguali possiamo andare a definire una equivalenza di struttura. (vado anche di piÃ¹ a guardare come vengo utilizzati, a tempo di compilazione).\nIn un modo forse piÃ¹ intuitivo possiamo dire che abbiamo una equivalenza di struttura quando tutti i campi allâ€™interno della struttura sono gli stessi.\nSlide equivalenza di struttura\nPossiamo anche utilizzare una forma piÃ¹ lasca (molto ispirata dal duck typing) chaichiamo questa la compatibilitÃ  di tipo).\nDuck typing e confronto equivalenza ðŸŸ© Questo Ã¨ molto simile a quanto si fa in duck typing in slide\nSlide duck typing\nIf it walks like a duck, and it quacks like a duck, then it must be a duck. ~a duck\nSlide confronto fra i tipi di equivalenza\nIn pratica possiamo dire che lâ€™equivalenza nominale porta vantaggi rispetto a quello strutturale.\nNotazione molto piÃ¹ chiara per tipi ricorsivi. Di solito si utilizza una cosa di messo, tipo una parte nominale per dichiarare, e poi fare un controllo strutturale in secondo momento. Controllo del sottotipaggio Ã¨ molto piÃ¹ semplice dal punto di vista nominale. CompatibilitÃ  dei tipi (3) ðŸŸ¨++ Diciamo che il tipo T Ã¨ compatibile con il tipo s, se un valore di tipo T Ã¨ ammesso in un qualsiasi contesto in cui sarebbe richiesto un valore di tipo s.\nQuesto Ã¨ abbastanza naturale, la compatibilitÃ  essendo anche simmetrica, sussume anche un ordine parziale (riflessivo e transitivo) su questo possiamo andare ad avere tipi compatibili con lâ€™iniziale (quindi convertibili, o se parli con set theory li puoi vedere uguali).\nSlide compatibilitÃ  dei tipi\nQuando ho queste proprietÃ :\nAbitanti di un tipo sono anche abitanti di tipo2 (ad esempio in rust andiamo a definire le traits sulle structs). Ci sono le stesse operazioni Conversioni canoniche, o arbitrarie. Allora potrei prendere il primo tipo e considerarlo come del secondo, in questo senso posso dire che sono dei tipi compatibili fra di loro.\nConversione di tipiðŸŸ©- Slide conversione dei tipi\nPuÃ² essere silente o espicito, se il silente non Ã¨ controlalto potrebbe dare dei bugs.\nImportante sottolineare la differenza fra conversione sintattica che in pratica Ã¨ solamente una interpretazione diversa della zona di memoria (stessa grandezza credo) oppure proprio da una funzione che applichi questa conversione.\nQuando faccio una conversioen diretta sto facendo una coercizione, ossia una conversione diretta seguendo un certo modo, anche detto marshalling).\nType inference Type inference\nSlide type inference\nQuando con il parsing riesco ad accumulare informazioni irguardo un certo tipo o operazione, quindi riesco ad assegnare un tipo senza che sia stato specificato in modo esplicito.\nAlla fine vado a risolvere una specie di equazioni con i tipi. Se non Ã¨ possibile avere abbastanza informazioni per escludere tutto si ritorna un errore. (semmai con una proposta di segnatura, o signature)\nSlide algoritmo di unificazione (non si fa credo)\n","permalink":"https://flecart.github.io/notes/algebra-dei-tipi/","summary":"Ripasso Prox: 19 Ripasso: May 22, 2023 Ultima modifica: May 6, 2023 5:58 PM Primo Abbozzo: April 3, 2023 1:22 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Algebra dei tipi Slide introduzione algebra dei tipi\nEquivalenza dei tipi (2) ðŸŸ© Quando possiamo dire che due tipi siano uguali? Solitamente vengono utilizzati due metodi:\nEQUIVALENZA NOMINALE\nQuando un nuono tipo introduce un nuovo nome diverso fra tutti i presenti. Credo cosÃ¬ vada golang.","title":"Algebra dei tipi"},{"content":"Relazioni con fili - Ampere Legge di Biot-Savart/Formalizzazione esperienza di Ampere ðŸŸ© Poniamo che ho due fili in cui scorra della corrente, voglia capire la forza per unitÃ  di lunghezza del filo uno su due e viceversa.\nSo che entrambi generano campo magnetico So che il campo magnetico induce forza su correnti in movimento. Supponiamo che la loro distanza sia $D$, allora avremo che: Per la prima legge so: $$ d\\vec{B} = \\mu_{0}i d\\vec{l} \\times \\frac{\\hat{r}}{4\\pi r^{2}} $$ da questo posso calcolare il campo magnetico totale, in un modo simile a quanto fatto in precedenza per il campo elettrico (solo che in questo caso abbiamo il prodotto seno, quindi l\u0026rsquo;angolo che conviene scegliere Ã¨ un po\u0026rsquo; diverso), e una volta che ho questo posso usare la seconda legge per avere la forza, questo Ã¨ il piano. Calcoliamo ora il valore del campo magnetico per una corrente di lunghezza infinita, una osservazione fondamentale Ã¨ che i contributi sono stesso verso quindi posso solamente sommare e concentrarmi sul modulo: $$ \\vec{B} = \\int _{Filo} \\frac{\\mu_{0}i}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}} = \\hat{k} \\frac{\\mu i}{4\\pi} \\int_{-\\frac{\\pi}{2}}^{+\\pi/2} \\frac{dl}{r^{2}} \\sin \\theta $$ Dovremo scrivere $dl$ e $r$ in funzione dell\u0026rsquo;angolo. L\u0026rsquo;obiettivo Ã¨ poi scomporre l\u0026rsquo;integrale in due parti. metÃ  sotto e metÃ  sopra: $$ r\\sin \\theta = D \\implies r = \\frac{D}{\\sin \\theta} $$ E $$ \\frac{D}{l} = \\tan \\theta \\implies l = \\frac{D}{\\tan \\theta} \\implies dl = D \\frac{d\\theta}{\\sin ^{2}\\theta} $$ Sostituendo tutto questo dentro otteniamo: $$ \\lvert \\vec{B} \\rvert = \\frac{\\mu_{0}i}{4\\pi} \\int _{\\pi}^{0} \\frac{\\sin \\theta}{D} d\\theta \\, dx = \\frac{\\mu_{0}i}{4\\pi D} (-\\cos \\theta) ^{0}_{\\pi} = \\frac{\\mu_{0}i}{2\\pi D} $$ Da qui abbiamo ottenuto la legge di Biot Savart. Qui notiamo che il campo magnetico circola intorno al filo (Ã¨ tangente al campo magnetico in questo caso, molto simile). Possiamo utilizzare questo per calcolare la forza applicata in un tratto di filo:\n$$ d\\vec{F} = i_{2}d\\vec{l} \\times (-\\vec{k})\\frac{\\mu i_{1}}{2\\pi D} $$ Quindi otteniamo una forza $$ d\\vec{F} = \\frac{i_{1}i_{2}}{2\\pi D} d\\vec{l} \\implies \\vec{F} = \\frac{i_{1}i_{2}L}{2\\pi D} $$ Questo vale perchÃ© abbiamo considerato fili infiniti rettilinei. Per la terza legge della dinamica la forza esercitata da due su uno Ã¨ la stessa, invertita perÃ², e questo conferma anche quanto sperimentalmente trovato con l\u0026rsquo;esperienza di ampere\nDefinizioni di dimensioni ðŸŸ© L\u0026rsquo;ampere posso definirlo in questo modo: corrente percorsa in due fili paralleli nel momenti in cui la distanza Ã¨ un singolo metro, e la lunghezza Ã¨ un metro e ho una forza uguale a $2\\times 10^{-7} N$ . Questo poi mi permette di definire il Coulomb in termini di corrente. Ãˆ una definizione utile per anche avere in automatico il valore di $\\mu_{0}$ (quindi molto artificiale secondo me).\nOsservazioni\nLinee chiuse del campo $\\vec{B}$ il flusso Ã¨ nullo, perchÃ© le linee sono chiuse (questo Ã¨ coerente con Gauss) Posso usare la regola della mano destra per sapere la direzione del campo magnetico Posso calcolare la circuitazione del campo magnetico generato da una corrente Posso calcolare la circuitazione, e scelgo una circonferenza chiusa:\nCircuitazione del campo magnetico (!) ðŸŸ© $$ \\oint_{\\Gamma} \\vec{B}d\\vec{r} = \\oint_{\\gamma} \\frac{\\mu_{0}i}{2\\pi} \\frac{dr}{R} = \\frac{\\mu_{0}i}{2\\pi} \\frac{1}{R} \\oint_{\\gamma} dr = \\frac{\\mu_{0}i}{2\\pi} \\frac{1}{R} 2\\pi R = \\mu_{0}i $$ Ossia dipende dalla corrente. La stessa relazione vale anche se scelgo un percorso spezzato! perchÃ© se scelgo il raggio, in quel caso la circuitazione Ã¨ nulla, perchÃ© Ã¨ perpendicolare alla direzione del campo! Il motivo Ã¨ perchÃ© come sopra i raggi si semplificano, e rimane solamente l\u0026rsquo;angolo, che si semplificherÃ  alla fine.\nProviamo a formalizzare questo discorso, poniamo di avere due circonferenze concentriche che rappresentano la direzione del nostro campo magnetico, poniamo che il tratto sul $R_{1}$ sia di $\\theta_{1}$ e il tratto su $R_{2}$ sia di $\\theta_{2}$ , e che $\\theta_{1} + \\theta_{2} = 2\\pi$, abbiamo allora che\n$$ \\oint_{\\Gamma} \\vec{B} d\\vec{r} = \\frac{\\mu_{0}i}{2\\pi} \\left( \\frac{1}{R_{1}} \\theta_{1}R_{1} + \\frac{1}{R_{2}} \\theta_{2}R_{2} \\right) = \\mu_{0}i $$ Questo discorso ha delle similitudini con l\u0026rsquo;analisi del Potenziale elettrico in Campo elettrico. Anche lÃ¬ spezzettavamo, e concludevamo conservativitÃ  per cose radiali.\nLegge di Ampere ðŸŸ© La circuitazione di $\\vec{B}$ lungo una qualsiasi linea chiusa Gamma, Ã¨ pari all\u0026rsquo;intensitÃ  di corrente complessiva concatenata alla linea chiusa moltiplicata per la permeabilitÃ  magnetica del vuoto\nQuesto Ã¨ motivato da quanto fatto sopra per la circuitazione del campo magnetico, solo che quando l\u0026rsquo;abbiamo derivato l\u0026rsquo;abbiamo fatto per un filo rettilineo uniforme.\nIn un certo senso questa legge Ã¨ simile a Legge di Gauss perchÃ© consideriamo solamente le correnti dentro alla nostra circuitazione (come per gauss si considerava solamente le cariche all\u0026rsquo;interno).\nCorrente concatenata (!!) ðŸŸ© Dobbiamo capire il significato di corrente concatenata, possiamo riprendere la definizione di corrente elettrica che abbiamo dato durante Corrente Elettrica, e considerare una superficie piÃ¹ ampia! Infatti considero la superficie aperta con bordo $\\Gamma$, dalla definizione di densitÃ  di corrente, non mi importa che questa superficie sia oltre il nostro filo, puÃ² esser piÃ¹ ampio , e in questo senso la corrente Ã¨ sempre quella, definita come $$ i = \\int _{\\Sigma} \\vec{J} \\cdot d\\vec{s} $$ Considero una altra superficie a cappello come in figura (in cui il rosso Ã¨ vuoto, perchÃ© Ã¨ superficie aperta, ci piace questo perchÃ© non ci limita sulla forma della superficie), allora provo a calcolare il flusso su questo. Definisco il verso di $ds$ come convenzione, in base alla circuitazione (stessa della corrente diciamo.) Qualsiasi superficie aperta con bordo Gamma, riscrivendo l\u0026rsquo;equazione precedente: $$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{r} = \\mu_{0} \\int _{\\Sigma(\\Gamma)} \\vec{J} \\cdot d\\vec{s} $$ Ampere in forma differenziale ðŸŸ© Guardare Divergenza e Circuitazione, Ã¨ il teorema di Stokes quello che utilizziamo:\n$$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{r} = \\int _{\\Sigma(\\Gamma)} \\vec{\\nabla} \\times \\vec{B} \\cdot d\\vec{s}= \\mu_{0} \\int _{\\Sigma(\\Gamma)} \\vec{J} \\cdot d\\vec{s} $$ Allora possiamo scrivere la legge di Ampere in forma differenziale e abbiamo: $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} $$ Da cui abbiamo ancora che $B$ non Ã¨ conservativo, e quindi non ha senso chiedersi del lavoro fatto dal campo.\nTerza legge di Maxwell (Ampere-Maxwell) ðŸŸ© Come si gestisce il caso in cui l\u0026rsquo;intensitÃ  della corrente cambia? Ricordiamo la legge di continuitÃ  della corrente, ossia abbiamo $$ \\begin{cases} \\vec{\\nabla} \\cdot \\vec{J} + \\frac{\\delta \\rho}{\\delta t} = 0 \\\\ \\vec{\\nabla} \\cdot \\vec{E} = \\frac{\\rho}{\\varepsilon_{0}} \\implies \\rho = \\varepsilon_{0} \\vec{\\nabla}\\cdot \\vec{E} \\end{cases} \\implies $$ $$ \\implies \\vec{\\nabla} \\cdot \\vec{J} = -\\left( \\varepsilon_{0} \\vec{\\nabla} \\frac{\\delta \\vec{E}}{dt} \\right) \\implies \\vec{\\nabla}\\left( \\vec{J} + \\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} \\right) = 0 $$ Questa legge vale non solo per il caso stazionario (esteso). In $J$ sono presenti le correnti concatenate, ma anche quelle atomiche (le correnti di magnetizzazione esplorate in Magnetismo nella materia).\nDa questo possiamo ricavare la altra legge di Maxwell (inizialmente non considerato dalla Royal Academy, sarÃ  utilizzabile solo per correnti non stazionarie)\n$$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$ Si estende con la parte di Maxwell: $$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{r} = \\mu_{0} \\int _{\\Sigma(\\Gamma)} \\vec{J} \\cdot d\\vec{s} + \\mu_{0}\\varepsilon_{0} \\frac{d\\left( \\int _{\\Sigma(\\Gamma)} \\vec{E} \\, ds \\right)}{dt} $$ Questo Ã¨ fondamentale! PerchÃ© basta far variare il campo elettrico e questo crea un campo magnetico!\nSono quattro equazioni differenziali a derivate parziali (stessa cosa per il campo elettrico), e con questo si puÃ² risolvere tutto.\nDensitÃ  di corrente di spostamento ðŸŸ© Il termine nuovo che ha introdotto Maxwell Ã¨ chiamato densitÃ  di corrente di spostamento e si puÃ² vedere che hanno le stesse dimensioni infatti $$ \\vec{J}_{s} = \\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$ Guardare Condensatori nel vuoto per il ragionamento sul condizionatore e corrente di spostamento. Si chiama corrente perchÃ© ha le stesse dimensioni delle correnti.\nUna nota interessante Ã¨ vedere questo come viene derivato: Partendo dalla equazione di continuitÃ  della corrente, abbiamo che\n$$ \\vec{\\nabla} \\cdot \\vec{J} = - \\frac{\\delta \\rho}{\\delta t} = -\\frac{\\delta}{\\delta t} (\\varepsilon_{0} \\vec{\\nabla} \\cdot \\vec{E}) \\implies \\vec{\\nabla} \\cdot \\left( \\vec{J} + \\frac{\\delta}{\\delta t} (\\varepsilon_{0} \\vec{E}) \\right) = 0 $$ E dato che sommo anche quello Ã¨ una densitÃ , e la chiamo densitÃ  di corrente di spostamento.\nCampi magnetici non stazionari Questi possono indurre una forza elettromotrice. Faraday ha indagato questa possibilitÃ  e attraverso molti esperimenti si cerca di verificare questo.\nEsperimento di Faraday per campi magnetici non stazionari ðŸŸ¨ 1. Magnete statico: Ha messo prima una calamita su un circuito, ma questo non genera corrente 2. Magnete in estrazione: genera una corrente che nel solenoide (comunque spira) ha un campo magnetico attrattivo 3. Magnete in inserimento: campo magnetico repulsivo generato dalla corrente Osservazioni:\nLa corrente Ã¨ piÃ¹ grande quanto Ã¨ piÃ¹ grande la velocitÃ  v Quando la calamita Ã¨ dentro al solenoide, non si ha corrente Si ha una forza opposta al movimento Viene generata corrente Invertendo i poli si ha la stessa cosa (solo con verso della corrente opposta). Questi risultati sono uguali quando si usa un circuito affacciato al primo (ci sono esattamente le stesse cose di prima). -\u0026gt; Un flusso variabile puÃ² generare forza elettromotrice.\nQuarta legge di Maxwell (Faraday-Neumann-Lenz) ðŸŸ© $$ \\varepsilon_{IND} = -\\frac{d\\Phi(\\vec{B})}{dt} \\implies \\oint_{\\Gamma} \\vec{E} \\cdot \\vec{r} = -\\frac{d\\Phi(\\vec{B})}{dt} = - \\frac{d}{dt} \\left( \\int _{\\Sigma(\\Gamma))} \\vec{B} \\cdot d\\vec{s} \\, \\right) $$ Posso scrivere anche utilizzando il teorema del rotore (e il fatto che integro e derivo rispetto a variabili indipendenti) nella forma differenziale: $$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} $$ In cui ho una informazione puntuale.\nEnunciato in modo matematico da Ampere, e attraverso testo da Faraday. Che Ã¨ in pratica il risultato sperimentale osservato precedentemente.\nA volte il fatto che Ã¨ opposto si dice che sia grazie agli esperimenti di Lenz. ed Ã¨ necessaria per la conservazione dell\u0026rsquo;energia. L\u0026rsquo;orientazione della superficie $\\Sigma$ Ã¨ data dalla regola della mano destra (e quindi decide il verso).\nPossiamo individuare tre casi in cui la variazione non Ã¨ nulla, li andiamo a discutere uno a uno.\n$B = f(t)$ $\\theta = \\theta(t)$ $\\Sigma = \\Sigma(t)$ Angolo variabile nel tempo ðŸŸ© Supponiamo di avere un campo magnetico costante, vogliamo cercare di guardare quant\u0026rsquo;Ã¨ la corrente indotta quando la spira ruota. Supponiamo ruoti con $\\omega = \\frac{d\\theta}{dt}$ Allora: $$ \\Phi(\\vec{B}) = \\int _{\\Sigma} \\vec{B} \\cdot \\, d \\vec{s} = BS \\cos \\theta(t) \\implies \\varepsilon_{IND} = BS \\sin \\theta \\omega $$ Qui abbiamo una corrente alternata. Ãˆ interessante notare che abbiamo corrente alternata anche se non c\u0026rsquo;Ã¨ nessuna forza elettromotrice.\nFlusso variabile nel tempo ðŸŸ© Supponiamo di avere un circuito in parallelo con una corrente che cambia intensitÃ , cosÃ¬ ho un flusso distante.\n$i = kt$, $\\lvert B \\rvert = \\frac{\\mu_{0}i(t)}{2\\pi r}$ $$ \\varepsilon_{IND} = -d \\frac{\\Phi(\\vec{B})}{dt} = i_{I}R $$ Con $R$ la resistenza del circuito e $i_{I}$ la corrente indotta. Per il verso della superficie Ã¨ uguale, si fa una assunzione sul verso della corrente e poi si avrÃ  il verso della corrente vera come segno.\ncalcoliamo il flusso allora:\n$$ \\Phi(\\vec{B}) = \\int _{\\Sigma} \\lvert \\vec{B} \\rvert \\, d\\vec{S} = \\int _{\\Sigma} \\frac{\\mu_{0}i}{2\\pi r}\\, \\vec{dS} = \\frac{\\mu_{0}i}{2\\pi} \\int_{D}^{D+L} \\frac{1}{r}L\\, dr = \\frac{\\mu_{0}iL}{2\\pi} \\ln\\left( \\frac{D+L}{D} \\right) $$ Allora otteniamo che, sapendo che $i(t) = kt$ $$ \\frac{d\\Phi(\\vec{B})}{dt} = \\frac{\\mu_{0}L}{2\\pi} \\ln\\left( \\frac{D+L}{D} \\right)k $$ Con questo poi posso descrivere la FEM indotta e quindi avere la direzione della corrente\nArea variabile nel tempo ðŸŸ© Consideriamo un circuito con una barra che si muove di velocitÃ  costante, in questo senso varia l'area, e un campo magnetico uscente costante, sappiamo che $A = x_{0} + vt$ Allora $$ \\Phi(\\vec{B}) = \\oint_{\\Sigma} \\lvert \\vec{B} \\rvert d\\vec{S} = -BS(t) $$ Abbiamo allora che $$ \\varepsilon_{IND} = BLv $$ Notiamo che abbiamo bisogno di una forza per continuare a tenerlo La forza che viene applicata Ã¨\n$$ \\vec{F} = i_{I}lB \\hat{r} = \\frac{BLv}{R} LB = \\frac{B^{2}L^{2}v}{R} $$ Per avere velocitÃ  costante, bisogna avere una forza che annulli questo, in modo che sia inerziale.\nBarra in movimento ðŸŸ© Da questo esperimento proveremo che correnti vengono generati anche nel vuoto. Consideriamo una barretta che si muove in un campo magnetico costante. Allora abbiamo che deve valere $$ qvB = qE_{IND} \\implies E_{IND} = vB $$ E sapendo che in questo caso semplice abbiamo $$ \\Delta V = \\int_{\\Gamma}\\vec{E} d\\vec{l} = El $$ Che possiamo mettere dentro: $$ \\Delta V = vBl $$ Questa Ã¨ la differenza di potenziale generata all\u0026rsquo;interno. Abbiamo una giustificazione che la forza elettromotrice Ã¨ generata dalla forza di Lorentz, e questo funziona anche nello spazio vuoto. E solitamente questo non Ã¨ conservativo (se Ã¨ indotto non Ã¨ statico solitamente, perchÃ© ci sarÃ  qualcosa che varia).\nVogliamo cercare di ricavare una equazione di conservazione dell\u0026rsquo;energia in elettromagnetismo classico\n","permalink":"https://flecart.github.io/notes/ampere-e-faraday/","summary":"Relazioni con fili - Ampere Legge di Biot-Savart/Formalizzazione esperienza di Ampere ðŸŸ© Poniamo che ho due fili in cui scorra della corrente, voglia capire la forza per unitÃ  di lunghezza del filo uno su due e viceversa.\nSo che entrambi generano campo magnetico So che il campo magnetico induce forza su correnti in movimento. Supponiamo che la loro distanza sia $D$, allora avremo che: Per la prima legge so: $$ d\\vec{B} = \\mu_{0}i d\\vec{l} \\times \\frac{\\hat{r}}{4\\pi r^{2}} $$ da questo posso calcolare il campo magnetico totale, in un modo simile a quanto fatto in precedenza per il campo elettrico (solo che in questo caso abbiamo il prodotto seno, quindi l\u0026rsquo;angolo che conviene scegliere Ã¨ un po\u0026rsquo; diverso), e una volta che ho questo posso usare la seconda legge per avere la forza, questo Ã¨ il piano.","title":"Ampere e Faraday"},{"content":"1 Calcolo dei numeri finiti Il calcolo Ã¨ numerico perchÃ© si differenzia rispetto a un calcolo normale perchÃ© Ã¨ finito.\n1.1 Errore nei calcoli 1.1.1 Tipologie di errore (5) ðŸŸ© Errore di misura, dovuto alle imperfezioni dello strumento di misura dei dati del problema. Errore di troncamento, quando un procedimento infinito viene realizzato come procedimento finito. (esempio: calcolo del valore di una funzione tramite sviluppo in serie, perchÃ© dato che lâ€™algoritmo deve essere finito, devo prima o poi interrompere il calcolo, ecco qui lâ€™errore). Errore inerente, dovuto al fatto che i dati di un problema non sono in una forma buona diciamo Errore di rappresentazione (simil troncamento) non sempre appartengono allâ€™insieme $\\mathbb{F}$ dei numeri rappresentabili e quindi vengono approssimati. Errore algoritmico, dovuto al propagarsi degli errori di arrotondamento sulle singole operazioni in un procedimento complesso. 1.1.2 Misura dellâ€™accuratezza ðŸŸ© Anche per lâ€™accuratezza di una misura utilizziamo degli errori (questi tipi di errori li hai anche studiati in fisica durante il liceo).\nErrore assoluto $|stimato - expected|$ di solito ha poco valore perchÃ© dipende dal contesto, molto piÃ¹ importante il relativo Errore relativo $E_a /expected$ questo molto buono, ed Ã¨ in pratica simile allâ€™errore percentuale Questo errore mi riesce effettivamente a dare un concetto di precisione del calcolo. Errore percentuale in pratica Ã¨ lâ€™errore percentuale $\\cdot 100\\%$ 1.2 Rappresentazione dei numeri ðŸŸ©- Gli argomenti presentati in questa sezione sono giÃ  stati trattati in modo anche pratico nel corso di Architettura degli elaboratori in Rappresentazione delle informazioni, qui andremo ad approfondire di piÃ¹ da un punto di vista matematico.\n1.2.1 Numeri interi ðŸŸ© Questa parte Ã¨ totalmente omessa perchÃ© presente in Rappresentazione delle informazioni\nLa stessa parte, sempre presente lÃ¬, tratta dellâ€™algoritmo di conversione dei numeri interi in binario e decimale\n1.2.2 Numeri reali ðŸŸ© Slide per la rappresentazioni.\nLa prima cifra deve essere diversa da 0 per garantire unicitÃ  al numero.\nEsercizio: ricava la formula che rappresenta ogni numero reale in una base qualunque.\n1.3 Sistema floating point ðŸŸ© 1.3.1 Rappresentazione matematica dellâ€™insieme ðŸŸ© Slide\nlâ€™insieme\n$$ \\mathbb{F}(\\beta, t, L, U) = \\{0\\} \\cup \\{x \\in \\R = sign(x) \\beta ^p \\sum_{i = 1}^t d_i \\beta^{-i}\\}\\\\ 0 \\leq d_i \u003c \\beta, i \\in \\N_+, d_1 \\neq 0, L \\leq p \\leq U $$ descrive tutti i numeri nella retta reale che sono rappresentabili secondo il sistema floating point\nQuesto insieme $\\mathbb{F}$ Ã¨ finito, non continuo.\n1.3.2 Rappresentazione del numero nel calcolatore ðŸŸ© Se il numero che vogliamo rappresentare Ã¨ nellâ€™insieme, allora Ã¨ facile, prendiamo quel numero Altrimenti si utilizza un troncamento o arrotondamento della mantissa al numero di $\\mathbb{F}$ piÃ¹ adatto, vediamo come agiscono questi due metodi. Notiamo che questo caso succede quando $\\exists i \u003e t : d_i \\neq 0$.\nTroncamento rappresento tutto il numero fino a $t$ e poi ignoro il resto. Un altro modo per vedere il troncamento Ã¨ che arrotonda sempre al ribasso, mai dopo, prende il numero di $\\mathbb{F}$ piÃ¹ vicino e minore del numero che vogliamo convertire.\nArrotondamento simile al troncamento, ma arrotonda. Che si conosca non câ€™Ã¨ un coso hardware che lo faccia (o comunque implementa questo algo:https://stackoverflow.com/questions/4572556/concise-way-to-implement-round-in-c)\n1.3.3 Breve discussione sui parametri ðŸŸ© $\\beta$, descrive la base di rappresentazione del nostro insieme $t$, descrive il numero di cifre utilizzate per la rappresentazione, principalmente influiscono sulla precisione (densitÃ  dei numeri nellâ€™intervallo, vedi sezione sequente). $U$ descrive il upper bound per la caratteristica (esponente alla base) $L$ uguale a $U$ ma Ã¨ un lower bound.\nQuindi $U, L$ descrivono il range di rappresetnazione per il nostro insieme di rappresentazione\n1.3.4 DensitÃ  dei numeri ðŸŸ© Slide\nSi puÃ² notare che col metodo di rappresentazione esposto sopra si possono individuare informazioni sulla dispersione dei numeri nella retta.\nIn ogni intervallo di lunghezza $[\\beta ^p, \\beta^{p + 1}]$ ho $(\\beta - 1)\\beta^{t- 1}$ numeri, distanziati in maniera uguale una dallâ€™altra (solo in questo intervallo), appena salgo di intervallo, lâ€™intervallo cresce. Questo Ã¨ anch eun motivo dellâ€™underflow, in cui quando sono troppo vicino allo zero, lâ€™intervallo Ã¨ troppo piccolo. (credo, Ã¨ da rivedere questa cosa).\nIl motivo di questi numeri Ã¨ perchÃ© ho $\\beta - 1$ numero di modi per scegliere il primo numero (che deve essere diverso da nullo) e il restanti cifre della mantissa come li voglio\n1.3.5 Standard IEEE ðŸŸ¨+ Slide descrizione dei floating points per lo standard IEEE\nIn piÃ¹ sono riservati alcuni numeri per $+0, -0, +\\infty, -\\infty$. e NaN (esempio quando faccio 0 * inf ho un NaN)\nNota questi valori non sono codificabili nella forma che Ã¨ presente in slide, perÃ² lei li vuole cosÃ¬ quindi impara a memoria per l\u0026rsquo;esame saddo.\n1.3.6 Errore di rappresentazione ed errore di macchina ðŸŸ©- Con double $\\approx 10^{-16}$, con float $\\approx 10^{-7}$\nDefinizione simile di epsilon, ma nellâ€™altro verso ðŸŸ¨ TODO: chiedere se le due definizioni sono equivalenti pg 50 pdf introduzione al calcolo numerico\neps Ã¨ il piÃ¹ piccolo numero macchina positivo tale che $eps + 1 \u003e 1$, in pratica Ã¨ il piÃ¹ piccolo numero che Ã¨ arrotondato al piÃ¹ piccolo numero rappresentabile da $\\mathbb{F}$.\nPer il calcolo dellâ€™eps per il valore dellâ€™errore macchina ti puoi rifare a questo post machine epsilon value for IEEE double precision standard alternative proof using relative error\nLa prof ha sbagliato in questa parte, ha copiato il valore di epsilon per lâ€™arrotondamento con normalizzazione che parte da 1, quindi il valore corretto di epsilon dovrebbe essere $\\varepsilon_{mach} = \\dfrac{1}{2}\\beta ^ {1-t}$. Anche la pagina di wiki spiega bene questa parte di dimostrazione dellâ€™errore macchina\n1.4 Aritmetica floating point 1.4.1 Definizione di funzione ðŸŸ© Ã¨ una funzione $\\circ : F \\times F \\to F$, ma puÃ² succedere che una operazione che prende due operandi da F e F non sia ancora in F, e quindi c\u0026rsquo;Ã¨ bisogno di arrotondarlo ad F, causando un errore di\n$$ | \\dfrac{x \\circ y - x \\cdot y}{x \\cdot y} | \u003c \\epsilon $$ Il valore Ã¨ sempre minore perchÃ© epsilon Ã¨ il maggior errore possibile per singola operazione\nPropagazione dellâ€™errore ðŸŸ© Il processo di propagazioen dellâ€™errore Ã¨ molto difficile da tenere in considerazione, quindi ci limitiamo a considerare alcuni casi tipici di errori inerenti nellâ€™operazione di somma e sottrazione:\nNOTA: per questa parte $\\varepsilon$ Ã¨ definito come il piÃ¹ grande numero tale che $1 + \\varepsilon = 1$, che Ã¨ quasi equivalente all\u0026rsquo;altro.\nSomma di due numeri con esponente molto differente, perchÃ© finisce che il computer non ha abbastanza bit in mantissa per rappresentare il risultato, e quindi deve andarea troncare. Questo incide principalemente su bit di poco significanza. $(1 + \\varepsilon) + (1 + \\varepsilon) = 1 + 1 = 2$, cosÃ¬ abbiamo perso $2\\varepsilon)$ Differenza fra numeri molto simili, questo incide su bit di grande signfiicanza: Esempio: ( $(1 + \\varepsilon) - (1 - \\varepsilon) = 0$ abbiamo perso $2\\varepsilon$, ma questo Ã¨ un errore relativo direi piÃ¹ grosso, credo. Importanti sono lâ€™esempio presente nelle slides epr il calcolo del numero di nepero\n","permalink":"https://flecart.github.io/notes/calcolo-di-numeri-finiti/","summary":"1 Calcolo dei numeri finiti Il calcolo Ã¨ numerico perchÃ© si differenzia rispetto a un calcolo normale perchÃ© Ã¨ finito.\n1.1 Errore nei calcoli 1.1.1 Tipologie di errore (5) ðŸŸ© Errore di misura, dovuto alle imperfezioni dello strumento di misura dei dati del problema. Errore di troncamento, quando un procedimento infinito viene realizzato come procedimento finito. (esempio: calcolo del valore di una funzione tramite sviluppo in serie, perchÃ© dato che lâ€™algoritmo deve essere finito, devo prima o poi interrompere il calcolo, ecco qui lâ€™errore).","title":"Calcolo di numeri finiti"},{"content":"Ultima modifica: January 10, 2023 10:49 AM Primo Abbozzo: January 5, 2023 9:38 AM Studi Personali: No\nElementi di ripasso Dependable systems Introduzione Possiamo individuare alcune proprietÃ  dei sistemi distribuiti. PerÃ² non siamo riusciti a renderli logicamente validi. Sono ancora un pÃ² misti di linguaggio naturale e della sua ambiguitÃ ! Comunque possiamo ridurci per guardare quanto un sistema sia affidabile a guardare poche sue caratteristiche precise.\nCaratteristiche fondamentali (4) Queste proprietÃ  sono pensate naturalmente caratterizzanti dei sistemi. In particolare dovrebbero essere tutti misurabili.\nAvailability\nChe risponde nellâ€™istante in cui fai una richiesta.\nReliability\nReliable quando non crasha quando comincia a runnare.\nSafety\nNiente di catastrofico avviene, ossia qualcosa da cui non si puÃ² tornare indietro. Vorrei riuscire a riprendere lâ€™esecuzione dopo i crash.\nMaintanability\nQuanto Ã¨ facile risolvere i problemi quando succedono i problemi.\nFaults Definiamo concetti come errori, faults, system failure. Rispettivamente sono definiti come\nErrore: Ã¨ uno stato del sistema che ha causato il comportamento inaspettato faults: cosa che ha causato lo stato dâ€™errore. system failure: quando non si comporta come secondo le specifiche. Noi vorremmo avere un modo per controllare i faults. Quindi sistemi che riescano a prevedere, rimuovere e prevenire faults.\nClassificazione dei faults\nSorts of faults (tempo)\nObiettivi dei sistemi distribuiti Possiamo andare ad individuare alcuni principi cardine nella costruzione dei sistemi distribuiti\nTrasparenza Vogliamo che la distanza fisica della locazione del server non sia percepibile, quindi lâ€™esperienza del sistema distribuito sia come nascosto. Possiamo andare ad individuare molti (probabilmente troppe) tipologie di trasparenza, e non tutte possono essere facilmente garantite (non tutte poi dovrebbero essere garantite secondo me)\nOpenness Per aprirsi alla non-predittibilitÃ  dellâ€™ambiente in cui presente, il sistema deve essere in grado di cambiare componenti, accettarne dei nuovi, e sapere comunicare con questi. Per questo motivo chiamiamo un sistema distribuito OPEN.\nChiaramente un linguaggio comune per cui parlarsi deve esistere. Diventano quindi importanti le IDL (interface definition Languages) linguaggi nati proprio per definire solamente delle interfacce di comunicazione. (++ sijntassi del protocollo, un buon esempio puÃ² essere protobuf).\nScalabilitÃ  Come puÃ² scalare il nostro sistema distribuito. Di solito puÃ² scalare verticalmente oppure orrizzontalmente. Per verticale diciamo comprare una macchina piÃ¹ potente. Per orizzontale diciamo comprare piÃ¹ macchine.\nUn problema per la scalabilitÃ , molto legata alla trasparenza Ã¨ mascherare la latency di comunicazione.\nAvailability PiÃ¹ o meno questo dovrebbe essere il vantaggio dei sistemi distribuiti, che essendo replicati, Ã¨ molto probabile che siano tutti ON. Questo concetto dellâ€™availability comunque racchiude il concetto di quanto spesso ti risponde alle tue richieste.\nTipologie di sistemi distribuiti Distributed computing systems Questi sono i sistemi principalmente devoti al calcolo scientifico. (Quindi utilizzo di protocolli come Beowulf, che permettono un calcolo molto veloce e coordinato in Rete LAN, utile a fare calcoli molto simili.\nQueste cose si dividono in cluster, e grid. Il primo fa cose molto simili fra di loro. Il secondo puÃ² fare anche cose diverse (mi pare, non ne sono sicuro).\nIl cluster possiede stesso sistema operativo e sono solitamente messi nella stessa zona, collegati a una LAN molto veloce. Di solito Ã¨ questo il modo con cui si costruisce un supercomputer, perchÃ© Ã¨ la cosa piÃ¹ economica ammassare tanti computer insieme che lavorino bene per avere potenza di calcolo superiore.\nEsempio cluster beowulf\nInvece i Grid sono utili per connettere aree amministrative diverse. Quindi bohâ€¦ Forse connessione fra uni diverse, filesystem condiviso?? buo.\nDistributed information systems Storicamente Ã¨ stato presente un fortissimo bisogno di coordinare i basi di dati di dipartimenti anche molto diversi affinchÃ© non ci sia una ripetizione inutile di dati che possa andare a causare una burocrazia molto elevata. Câ€™Ã¨ stato quindi bisogno di creare un sistema di middleware condiviso a tutti i basi di dati che provava a rendere consistente tutte le basi di dati diverse.\nPervasive systems Attualmente tutte le persone possiedono dispositivi di calcolo, quindi Ã¨ importante dare risalto anche a questo modello di sistema distribuito.\nPrincipalmente i metodi per questa parte la dividiamo in 2 parti:\nSensori che inviano costantemente dati (overhead network e il server che li deve processare) Sensori che hanno un processore locale, e dati locale, che rispondono in modo coerente (come se fossere un unico sistema) quando sono chiesti da una query Paxos Paxos Ã¨ un protocollo utile per risolvere il problema di Bizantine agreement, creato da Lamport nel 1998. per BA guardare Syncronous model.\nLâ€™idea Ã¨ dividire il processo di agreement in due fasi. Una priomise e un commit.\nPoi andiamo a definire alcuni agenti principali in questo protocollo. Dei proposers,** acceptors, quorum**.** I primi propongono, gli altri accettano. QUando Ã¨ stato raggiunto un quorum, allora si va alla seconda fase, quella di commit o accettazione, se Ã¨ rifiutato si torna a prima, altrimenti si va al commit. PuÃ² esserci livelock?\n","permalink":"https://flecart.github.io/notes/goals-of-distributed-systems/","summary":"Ultima modifica: January 10, 2023 10:49 AM Primo Abbozzo: January 5, 2023 9:38 AM Studi Personali: No\nElementi di ripasso Dependable systems Introduzione Possiamo individuare alcune proprietÃ  dei sistemi distribuiti. PerÃ² non siamo riusciti a renderli logicamente validi. Sono ancora un pÃ² misti di linguaggio naturale e della sua ambiguitÃ ! Comunque possiamo ridurci per guardare quanto un sistema sia affidabile a guardare poche sue caratteristiche precise.\nCaratteristiche fondamentali (4) Queste proprietÃ  sono pensate naturalmente caratterizzanti dei sistemi.","title":"Goals of Distributed systems"},{"content":"What is it for Estimation Sampling generate numbers from any distribution! (distributions are important in statistics). Density Cumulative distribution (and others similar). Optimization how to find computationally the min and max of functions. Generating?\nRandom (difficile anche filosoficamente definire cosa significa questo). Molto importante perchÃ© si assume in Comp stats che abbiamo il random vero, e questa assunzione che non vale puÃ² rompere cose. And independent Sample proportion Average of something (example of the lake cannonball).\nFiga la possibilitÃ  di fare sampling secondo una distribuzione, partendo dalla $U$.\nLista delle nozioni Generalized inverse definition.\nFai la dimostrazione della generalized inverse transform (non dovrebbe essere tanto difficile, una volta che enunci quanto importante dovrebbe andare liscio).\nCosa dice la inverse transform? PerchÃ© possiamo partire dalla distribuzione uniforme?\nIn che modo Ã¨ relazionato la distribuzione $\\exp$ con chi squared, gamma e beta distribution?\nGeneralized transform formula (not in the exam, serve per avere le densitÃ  e non la CDF) ðŸŸ¥, non ho proprio capito perchÃ© funziona, in questo corso si impara solo ad imparare a memoria ed applicare queste cose.\nCome fare sampling fra distribuzioni discrete (che Ã¨ la soluzione idiota).\nSampling discrete from long tail distributions.\nExplain and use the accept reject method.\nProbabilitÃ  di accettazione, sia normalizzato che non normalizzato.\nFare gli esercizi a fine capitolo due per accept reject. (registrazione 7 primi 50 minuti parlano di questo).\nGuardare meglio l\u0026rsquo;esempio 3.4 per l\u0026rsquo;importance sampling (e la roba dei tail sampling).\nMinuto 52 Lecture 11, ci sono gli esercizi dispari del capitolo 3.\nFino a Lecture 12 minuto 48 ci sono altri esercizi.\nCose pratiche Essere in grado di implementare grafico e calcolare i valori per la inverse (esattamente quelli). ","permalink":"https://flecart.github.io/notes/introduction-to-computational-statistics/","summary":"What is it for Estimation Sampling generate numbers from any distribution! (distributions are important in statistics). Density Cumulative distribution (and others similar). Optimization how to find computationally the min and max of functions. Generating?\nRandom (difficile anche filosoficamente definire cosa significa questo). Molto importante perchÃ© si assume in Comp stats che abbiamo il random vero, e questa assunzione che non vale puÃ² rompere cose. And independent Sample proportion Average of something (example of the lake cannonball).","title":"Introduction to computational statistics"},{"content":"Ripasso Prox: 55 Ripasso: July 2, 2023 Ultima modifica: June 9, 2023 12:26 PM Primo Abbozzo: November 5, 2022 10:55 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Domande\nLinguaggi Deterministici e DPDA DPDA Definizione (2) ðŸŸ© La definizione di DPDA Ã¨ molto simile a quella trattata in Linguaggi liberi e PDA, con solo costraints sulla deterministicitÃ , che si traducono in due condizioni:\nAl massimo posso avere un risultato per ogni coppia di lettura e simbolo su stack Se ho una transizione senza leggere, posso avere solo quella Slide\nLinguaggio libero deterministico Un linguaggio Ã¨ libero deterministico se esiste un PDA che lo riconosce per stato finale.\nProprietÃ  accettazione per DPDA ðŸŸ© Per stato finale accettato resta sempre, cambia un pÃ² lâ€™accettazione per pila vuota, in cui si deve avere una prefix property.\nQuesta prefix property ha un certo interesse perchÃ© basta aggiungere un simbolo che non Ã¨ presente nellâ€™alfabeto, e ho la prefix property! (guarda esempi Lez12 prime slide).\nPrefix property ðŸŸ© Due parole del linguaggio in cui il primo Ã¨ interamente dentro il secondo.\nslide Prefix property\nSe aggiungo un simbolo $ riesco a far sempre che ci sia la prefix property.\nLa dimostrazione Ã¨ piÃ¹ o meno su questa scia. affinchÃ© uno sia prefisso dellâ€™altro, deve avere il dollaro nella stessa posizione, allora hanno la stessa lunghezza, ma se hanno la stessa lunghezza devono essere uguali, ecco la prefix property.\nEsiste DPDA che riconosce linguaggi regolari ðŸŸ© Enunciato\nDimostrazione\nPraticamente la dimostrazione Ã¨ la stessa per Grammatiche Regolari, ma ho anche lo stack, basta che non lo uso e ho finito.\nNon ambiguitÃ  dei DPDAðŸŸ© Enunciato\nQuindi se esiste un DPDA che riconosce il linguaggio, si puÃ² creare una grammatica non ambigua che riconosce lo stesso linguaggio.\nCon la lezione del 29/11 abbiamo introdotto che un linguaggio Ã¨ deterministico sse SLR(1) in LR(k) e YACC, quindi probabile che i DPDA posso essere ricondotti in una forma deterministica a singolo\nProprietÃ  dei linguaggi deterministici ðŸŸ© Complemento sÃ¬ Unione o intersezione no. Complemento probabilmente sÃ¬ perchÃ© basta applicare lo stesso ragionamento fatto per le regex in Automi e Regexp, ossia basta invertire gli stati accettati.\nPer dimostrare che non sono chiusi per intersezione o unione sarebbe buona cosa fornire un esempio.\nEsempio non intersezione â‡’ non unione.\nAnalizzatori sintattici In modo simile a quanto presentato in Grammatiche Regolari nell discussione dei Lex.\nQuesta parte utilizziamo abbiamo i strumenti automatici che prendono una grammatica libera e resituiscono un DPDA\nTipologie di parser (2-2-2) ðŸŸ© Slide tipologie (det-nondet)\nSlide tipologie (top-bottob)\nOltre a ciÃ² possiamo anche dividere i parse a seconda di\nLettura da destra o da sinistra Creazione derivaizone rightmost o leftmost Numero di look ahead. Quindi per esempio se ho una grammatica che inizia a leggere da sinistra, crea derivazione leftmost e ha un lookahead di 1, lo rappresento come $LL(1)$\nTop down parsing con PDA singolo stato ðŸŸ© Simile a quanto fatto in Linguaggi liberi e PDA per il teorema di equivalenza di linguaggio libero e PDA, vado a crearmi un automa in un certo modo (in particolare con singolo stato riconosce per pila vuota).\nSlide enunciato\nQuesta Ã¨ una semplice soluzione non deterministica, possiamo togliere questo non determinismo con il Look Ahead come rpesentato sotto\nLook Ahead (+) ðŸŸ© Posso andare a guardare la lettera avanti per capire in che modo comportarmi con la derivazione.\nUtilizzo una tabella di parsing per capire in che modo devo espandere il non-terminale.\nEsempio di look ahead 1\ncon $S := aSb|\\varepsilon$\nNote per risolvere i conflitti\nPosso\nFattorizzare (creare una nuov agrammatic aequivalente senza ricorsione sinistra che non riesco a gestirla, va a divergere, quindi non finisce mai Fare un look ahead maggiore di 1 Queso Ã¨ utile per togliere il non determinismo.\nBottom up parsing (3)ðŸŸ¨- Slide rappresentazione classica\nSi tratta sempre della creazione di un PDA a singolo stato!, ma fatto in modo di verso, in modo tale che ci sia una uderivazione rightmost.\nImportanti in questa parte sono 3 operazioni\nShift, in cui facci ocrescere verso destra la pila, come se stessi facendo lo shift Reduce, quando creo il non terminale come se fosse una espansione di non terminale. Accept Esempio di creazione di parser bottom up\nEsempio di derivazione con il parser di sopra\nProblema non determinismo per sopra\nMa comunque andiamo a discutere meglio di questa parte in Bottom-up Parser LR(0).\nTipologie di conflitti di bottom up Shift-reduce Reduce-Reduce Oltre a questo c\u0026rsquo;Ã¨ un grandissimo problema delle produzioni del tipo $A \\to \\varepsilon$, perchÃ© queste divergono sempre, quindi Ã¨ meglio non avere grammatiche con questa produzione se vogliamo utilizzare parsing bottom up.3\n","permalink":"https://flecart.github.io/notes/linguaggi-deterministici-e-dpda/","summary":"Ripasso Prox: 55 Ripasso: July 2, 2023 Ultima modifica: June 9, 2023 12:26 PM Primo Abbozzo: November 5, 2022 10:55 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Domande\nLinguaggi Deterministici e DPDA DPDA Definizione (2) ðŸŸ© La definizione di DPDA Ã¨ molto simile a quella trattata in Linguaggi liberi e PDA, con solo costraints sulla deterministicitÃ , che si traducono in due condizioni:\nAl massimo posso avere un risultato per ogni coppia di lettura e simbolo su stack Se ho una transizione senza leggere, posso avere solo quella Slide","title":"Linguaggi Deterministici e DPDA"},{"content":"Ripasso Prox: 40 Ripasso: December 22, 2021 Ultima modifica: October 27, 2022 12:16 PM Primo Abbozzo: September 27, 2021 3:02 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Exercise\nAs it is mentioned in the question that there are two motorcycle gang in the area and one of them always tells truth and the other always tell lies. The missionary also does not know which gang tells the truth and which do not. So, there are two possibility that could happen :\nThe missionary can ask both the gangs if the road goes to the disneyland but there would be a confusion because one of the gang is ought to be lying than the other so he would get one yes and one no. Sam goes if he would ask the question indirectly as if the road does not go to the disneyland then also he would get one yes and one no which will again create the confusion. So, to ask a question which will solve the problem without creating the confusion would be :\nSo, the missionary should actually ask both the gangs about what would be answer of the other gang for the question that if the road goes to the disneyland or not and in this way he would get either a yes or a no from both the gangs. So, we get the correct answer by taking technique with both the gangs.\nVecchie domande\nCodice gray, cosa Ã¨? Forma canonica di una funzione Mintermini PerchÃ© la porta nand Ã¨ concettualmente in grado di creare tutte le porte logiche possibili?\nDecember 14, 2021 3:43 PM\n5 Porte Logiche 5.1 Boole Un signor Boole ha creato le basi dell\u0026rsquo;algebra booleana su cui si basano le porte logiche dei computer moderni.\n5.1.1 Tabelle di veritÃ  Le tabelle di veritÃ  sono sufficienti per descrivere il funzionamento di una porta logica.\nQuesta cosa Ã¨ possibile grazie alla limitatezza delle funzioni all\u0026rsquo;interno dell\u0026rsquo;insieme $\\{0,1\\}$ dominio di partenza e fine dell\u0026rsquo;algebra booleana.\n5.1.2 ProprietÃ  nell\u0026rsquo;algebra di Boole Prova a spiegare da solo queste leggi:\nProprietÃ : 9\nIdentitÃ  Null Idempotenza Inverso Commutativo Associativo Distributivo Assorbimento De morgan La tabella con le leggi\nEsercizio in classe:\n$\\bar{A} + A \\not= \\bar{A}A$ Dimostrare sta cosa usando le leggi di de Morgan ( e non dicendo che Ã¨ la legge dell\u0026rsquo;inverso), in pratica dire che $\\bar{A} + A = \\overline{\\bar{A}A}$. dsafds\n5.1.3 Funzione booleana Si possono utilizzare delle funzioni booleane per mappare gli zeri e uno a certi\nEsercizio in classe\nScrivere la tabella di veritÃ  per\n$$ A + \\overline{(B + C)}B $$ La soluzione Ã¨ che vale solo per $A$, il secondo addendo Ã¨ tutto\nMintermini\nÃˆ una variabile o la negazione di una variabile\nSu $n$ termini Ã¨ l\u0026rsquo;AND fra tutti il min termine, attraverso relazioni di mintermini si puÃ² creare una funzione booleana.\nÃˆ l\u0026rsquo;unica combinazione booleana in cui in una riga sola Ã¨ uno mentre in ogni altra riga Ã¨ falsa\nUna forma canonica\nÃˆ una somma di alcuni mintermini, e questa Ã¨ unica per ogni funzione **booleana.\nLa forma canonica o funzione canonica di una espressione booleana Ã¨ un\u0026rsquo;espressione logica contenente tutte le variabili booleane in forma vera o negata, in forma di prodotti fondamentali o somme fondamentali di essi. Essa si ricava dalla tabella della veritÃ .\nCircuiti combinatori: Sono l\u0026rsquo;implementazione della funzione booleana, e sono deterministici.\n5.2 Transistor e Array 5.2.1 Struttura di un transistor Un transistor Ã¨ composto da tre parti principali:\nUn collettore che riceve una corrente esterna stabile Una base che riceve una corrente esterna e cambia la struttura del transistor a seconda che ci sia o no Un emettitore che lascia passare se c\u0026rsquo;Ã¨ corrente, altrimenti si comporta come resistenza infinita. 5.2.2 Nand, Not e Nor 5.2.3 Array programmabili Un insieme di And e Or che rappresentano la forma canonica per un elemento. Si possono programmare fondendo o lasciando alcuni fusibili per simulare l\u0026rsquo;uso del not, come in figura.\n5.3 Mappa di Karnaugh 5.3.1 Introduzione Ãˆ un metodo che prende la forma canonica e cerca di semplificarla con qualcosa di molto piÃ¹ facile da implementare (prende una forma canonica e restituisce elementi semplificati) Non fa peggio della forma canonica ergo una forma semplificata o uguale che dia stessi output.\nSi puÃ² fare anche a 3D o 4D per permettere l\u0026rsquo;uso per piÃ¹ input ma non sempre Ã¨ facile immaginarsi 4 dimensioni, queste devono soddisfare il codice grey.\n5.3.2 Codice gray (specchio) La mappa di Karnaugh deve essere un codice Gray\nCostruisco con la tecnica a specchio cioÃ¨ da una riga all\u0026rsquo;altro sto cambiando solamente una singola cifra.\nUtilizzando invece la numerazione delle tabelle di veritÃ  non funziona in quanto non possiede questa proprietÃ .\nDalla pagina di wikipedia\n5.3.3 Esempi di applicazione Disegno\nSi possono scrivere in due modi, a seconda di come piace\nRaggruppamento\nbisogna creare grossi raggruppamenti ossia catturare piÃ¹ uni possibile con pochi, fatto questo sono sicuro di creare una forma minimale.\nDopo questo scegli il raggruppamento piÃ¹ piccolo e sarai abbastanza sicuro che sia minimale\n5.4 Circuiti integrati Di solito sono pezzi di silicone che variano di grandezza e struttura a seconda degli input e dei output per quello che si deve fare (questi sono anche chiamati Chip)\n5.4.1 LGA PGA Large Grid Array, Pin grid Array.\nCi sono due tipologie di Pin per i circuiti integrati\n! sti sono anche chiamati Chip)\n5.4.1 LGA PGA Large Grid Array, Pin grid Array.\nCi sono due tipologie di Pin per i circuiti integrati\n!\n","permalink":"https://flecart.github.io/notes/porte-logiche/","summary":"Ripasso Prox: 40 Ripasso: December 22, 2021 Ultima modifica: October 27, 2022 12:16 PM Primo Abbozzo: September 27, 2021 3:02 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Exercise\nAs it is mentioned in the question that there are two motorcycle gang in the area and one of them always tells truth and the other always tell lies. The missionary also does not know which gang tells the truth and which do not.","title":"Porte Logiche"},{"content":"Ripasso Prox: 12 Ripasso: January 4, 2023 Ultima modifica: December 30, 2022 12:31 PM Primo Abbozzo: November 23, 2022 4:26 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Problemi di accoppiamento Introduzione (defs) Grafo bipartito ðŸŸ© Un grafo bipartito Ã¨ un insieme $(O \\cup D), (A)$ di nodi e di archi. Tutti i nodi sono o fra i nodi di origine oppure fra i nodi di destinazione, e gli archi sono solamente collegati fra nodi di origine e nodi di destinazione.\nAccoppiamenti (lessico) ðŸŸ© Consideriamo $M$ archi che non abbiano nodi in comune, vogliamo cercare in questo senso di fare un accoppiamento fra i nodi di origine e i nodi di destinazione.\ndiciamo accoppiamento perfetto se tutti i nodi sono stati accoppiati\nArco di bottleneck Ã¨ l\u0026rsquo;arco di costo massimo, che si dice costo di bottleneck.\nAccoppiamento di massima cardinalita Trasformazione del problema ðŸŸ© Vogliamo cercare di utilizzare gli algoritmi noti sui flussi di costo minimo e flusso massimo, algo di flusso massimo. In questo caso se giriamo il problema in modo opportuno possiamo renderlo un problema di flusso massimo\nCreo nuovo nodo fittizzio di origine e destinazione, in modo simile a quanto fatto in precedenza in Reti di flusso CapacitÃ  degli archi sono tutti 1, se c\u0026rsquo;Ã¨ flusso lo prendo, altrimenti no. (in questo senso i flussi devono essere interi! Osservazioni sulla tipologia di path ðŸŸ© La path che viene in questo modo creata dovrÃ  essere per forza alternanti, che vanno a rimbalzare fra i nodi interni!\nRicorda cosa sono gli archi interni e gli archi estermi.\nDato un insieme $M$ di tutti gli archi del nostro grafo bipartito che andiamo a prendere, consideriamo archi interni questi, ed archi estermi l\u0026rsquo;insieme $P - M$, con P tutti gli archi.\nChiaramente devo passare dalla sorgente alla destinazione, e lo posso fare solamente una volta per ecco che si puÃ² dire che\n$$ |P_e| - |P_i| = 1 $$ con Pe l\u0026rsquo;insieme degli archi esterni che prendo e Pi lâ€™insieme degli archi interni che vado a prendere, vado poi solamente a considerare la cardinalitÃ  di questo robo.\nQuesta osservazione Ã¨ importante per poter mettere in relazione molto stretta il fatto che i cammini aumentanti â†” cammini alternanti con quella proprietÃ , perchÃ© in questo modo il cammino alternante inizia e finisce in un nodo esterno, cioÃ¨ un nodo che non Ã¨ mai stato utilizzato per lâ€™accoppiamento.\nAccoppiamento di costo minimo Possiamo utilizzare gli algoritmi di MCMF per risolvere questo problema qui!\nImportante notare che gli accoppiamenti devono essere perfetti, ossia non ho nessun nodo libero.\nAccoppiamento di minimo bottleneck Anche qui deve esere fra tutti gli accopiamenti perfetti.\nIn questo caso si cerca di avere il minimo arco maggiore possibile, non per forza il minimo di costo.\n","permalink":"https://flecart.github.io/notes/problemi-di-accoppiamento/","summary":"Ripasso Prox: 12 Ripasso: January 4, 2023 Ultima modifica: December 30, 2022 12:31 PM Primo Abbozzo: November 23, 2022 4:26 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Problemi di accoppiamento Introduzione (defs) Grafo bipartito ðŸŸ© Un grafo bipartito Ã¨ un insieme $(O \\cup D), (A)$ di nodi e di archi. Tutti i nodi sono o fra i nodi di origine oppure fra i nodi di destinazione, e gli archi sono solamente collegati fra nodi di origine e nodi di destinazione.","title":"Problemi di accoppiamento"},{"content":"Campo elettrico nei materiali Se prendiamo un conduttore, gli elettroni in questi materiali sono liberi, significa che sono liberi di muoversi come vogliono, si puÃ² dire che \u0026ldquo;vadano in giro\u0026rdquo; (per esempio questo vale per il rame).\nil reticolo cristallino Ã¨ al struttura regolare che Ã¨ comune nei materiali, in cui gli atomi sono sempre a distanza costante (o comunque a pattern regolari) uno dall\u0026rsquo;altro $r$ per esempio.\nCampo e materiali (6) Schermatura del campo (!) ðŸŸ© Quando un materiale conduttore Ã¨ sottoposto a un campo elettrico *gli elettroni si mettono in modo da schermare il campo esterno, in modo tale da raggiungere un equilibrio. Se andiamo a chiamare $\\vec{E}_{i}$ il campo elettrico indotto dentro il materiale, allora avremo che\n$$ 0 = \\vec{F}_{0} = e(\\vec{E}_{i} + \\vec{E}) \\implies\\vec{E}_{i} = -\\vec{E} $$ L\u0026rsquo;osservazione principale che porta a questo risultato Ã¨ il fatto che nel primo momento c\u0026rsquo;Ã¨ uno spostamento di carica. Questo Ã¨ l\u0026rsquo;unico risultato sperimentale che abbiamo. Le cariche sono ferme all\u0026rsquo;interno del conduttore.\nMa questa carica da dove origina? Dove sono posizionate? Sono sulla superficie o anche dentro il materiale?\nCariche non sono dentro al conduttore (!) ðŸŸ© In ogni punto interno al conduttore, all\u0026rsquo;equilibrio la carica elettrica Ã¨ nulla, come avveniva in assenza del campo elettrico.\nQuesto implica che da dentro il conduttore non cambia niente.\nSi puÃ² dimostrare con la divergenza, praticamente che la densitÃ  di carica volumetrica resta nulla, perchÃ© il campo elettrico totale Ã¨ ancora nullo.\n$$ \\vec{\\nabla} \\cdot\\vec{E}_{T} = \\frac{\\rho}{\\varepsilon_{0}} \\land \\vec{E}_{T} = 0 \\implies \\rho=0 $$ Si puÃ² anche dimostrare usando Legge di Gauss per i campi elettrici Cariche si spostano in superficie ðŸŸ© Lo spostamento di cariche elettriche determinato dal campo elettrico esterno all\u0026rsquo;equilibrio si risolve in un ri-arrangiamento di carica che interessa solo la superficie del conduttore\nLa componente tangente non esiste sulla superficie, perchÃ© altrimenti le cariche si muoverebbero, invece la componente normale esiste sigma su $\\varepsilon_{0}$, Nel caso di cariche positiva c\u0026rsquo;Ã¨ proprio una forza sempre normale alla superficie, che spinge cariche fuori, in presenza di campo elettrico\nUn altra spiegazione per cui Ã¨ sempre normale Ã¨ riguardante la differenza di potenziale, sappiamo che $$ dV = \\nabla V \\cdot ds = -\\vec{E} \\cdot ds $$ Sappiamo che per una componente tangenziale su superficie equipotenziale la variazione di $V$ Ã¨ nulla, quindi non esiste nessuna componente tangenziale, solamente quella normale. Possiamo anche scrivere\n$$ \\nabla V = \\frac{dV}{dn} $$ dove $\\hat{n}$ Ã¨ il vettore normale alla superficie equipotenziale\nSe Ã¨ negativa Ã¨ esattamente il contrario\nInfluenza sul campo elettrico ðŸŸ© Dato un conduttore immerso in un campo elettrico esterno, all\u0026rsquo;equilibrio, altera le linee di campo anche all\u0026rsquo;esterno del conduttore. Il cambiamento delle linee di campo dipende dalla geometria del conduttore. Le linee di campo sulla superficie del conduttore sono normali e hanno modulo $\\frac{\\sigma}{\\varepsilon_{0}}$\nQuesto implica -\u0026gt; cambio del campo elettrico. L\u0026rsquo;induzione elettrostatica cambia il campo elettrico esterno, perchÃ© serve per schermare all\u0026rsquo;esterno. Quindi basta anche un conduttore neutro per cambiare il campo esterno 2. Un altro modo per cambia il campo Ã¨ introdurre nuove cariche.\nQuesto Ã¨ anche un modo per testare la conduttivitÃ  di un materiale, le linee di campo DEVONO essere 90 gradi ad entrare\nSuperficie equipotenziale come conduttore ðŸŸ© La superficie del conduttore Ã¨ equipotenziale, cosÃ¬ come l\u0026rsquo;interno\nPer avere questo risultato vedere sotto #Potenziale sulla superficie.\nCampo elettrico in geometria cava ðŸŸ© Se un conduttore cavo viene immerso in un campo elettrico esterno, all\u0026rsquo;equilibrio, il campo elettrico all\u0026rsquo;interno della cavitÃ  Ã¨ nullo e non vi sono cariche elettriche indotte sulla superficie della cavitÃ \nPoniamo che la nostra geometria abbia un buco, Ã¨ corretto che certe cariche si mettono sulla superficie della nostra geometria?\nSe proviamo a considerare Gauss una superficie che comprende tutta la superficie, la carica totale della nostra superficie Ã¨ 0, ma non mi dÃ  informazioni su come sono messe le cariche, stessa cosa probabilmente per la divergenza utilizzato in questo caso.\nConsideriamo in questo caso la circuitazione, allora $$ \\oint_{\\Gamma}\\vec{E} \\cdot d\\vec{r} = 0 = \\int _{A}^{B} \\vec{E} \\, d\\vec{r} + \\int _{B}^{A} \\vec{E} \\, d\\vec{r} = \\int _{A}^{B} \\vec{E} \\, d\\vec{r} $$ Questo perchÃ© la forza Ã¨ conservativa, prendo una circuitazione che si muova SULLA linea di campo e si chiuda dentro al conduttore. (l\u0026rsquo;integrale dentro il conduttore Ã¨ nullo perchÃ© il campo stesso Ã¨ nullo.)\nMentre nel buco il campo Ã¨ normale, quindi avremmo che\n$$ \\int _{A}^{B} \\vec{E} \\, d\\vec{r} = \\int _{A}^{B} \\lvert \\vec{E} \\rvert \\, dr \\cos 0 \\neq 0, \\text{ nel caso in cui il campo sia presente} $$ Quindi $\\vec{E} = 0$, questo Ã¨ il principio di schermatura, se abbiamo qualcosa di conduttore, non passa. Negli ascensori se varia troppo in fretta, non viene fermato, perchÃ© gli elettroni ci mettono un po\u0026rsquo; a rimettersi in sesto. Un altro motivo Ã¨ che non Ã¨ puramente metallica (conduttrice) questo ascensore. Altri fenomeni Singola Carica elettrica in geometria cava ðŸŸ© Le cariche si sposteranno, e cercheranno anche in questo caso di schermare. Se considero una superficie che li rinchiude, in questo caso avrÃ² un campo elettrico. $$ \\oint_{\\Sigma} \\vec{E} d\\vec{s} = \\frac{Q_{T}}{\\varepsilon_{0}} = \\frac{1}{\\varepsilon_{0}} (Q + Q_{I}) = 0 \\implies Q_{I} = Q $$ Ossia la carica sulla superficie Ã¨ **esattamente uguale alla carica nel buco**, per questo motivo scherma, il motivo per cui fa 0 Ã¨ perchÃ© direttamente sulla superficie Flusso esterno: $$ \\oint_{\\Sigma} \\vec{E} d\\vec{s} = \\frac{1}{\\varepsilon_{0}} (Q + Q_{C}) = \\frac{Q}{\\varepsilon_{0}} $$ PerchÃ© la carica del conduttore Ã¨ neutra, per ipotesi non era carica. $Q_{C} = Q_{I} + Q_{E}$ ossia carica interna (sul buco interno e sul buco esterno), ma in questo caso allora posso concludere che $Q_{E} = -Q_{I} = Q$, ossia sia una superficie esterna, sia la superficie interna vengono influenzate da questa carica.\nInduzione completa ðŸŸ© Fenomeno descritto in precedenza Ã¨ **l'induzione completa** come fenomeno. Nel caso in cui **tutte le linee di campo** entrano nel conduttore. In un certo senso se stai fuori dal materiale conduttore, Ã¨ come se lasciasse passare il campo senza problemi (se sto molto lontano **sembra singola carica**) (invece di renderlo radiale, sto cambiando leggermente la\\ direzione del campo *sulla superficie* se sto vicino). **Il campo interno non viene schermato** Materiale conduttore carico ðŸŸ© Supponiamo di avere un materiale conduttore carico, anche in assenza di campo elettrico. Nel caso precedente avevamo analizzato il caso di un conduttore neutro in campo elettrico, la differenza qui Ã¨ che Ã¨ il conduttore stesso che Ã¨ carico\nPosso avere esattamente le stesse proprietÃ  dette prima per conduttore immerso in campo elettrico\nLe cariche sono ferme Potenziale elettrico Ã¨ costante La carica elettrica dentro il conduttore Ã¨ 0 campo elettrico Ã¨ normale sulla superficie ed Ã¨ $\\frac{\\sigma}{\\varepsilon_{0}}$ Le cariche sono sulla superficie (si provano e repellere il piÃ¹ possibile). Se il conduttore Ã¨ cavo allora le cariche restano su quella esterna. Una altra applicazione Ã¨ il parafulmine perchÃ© la carica si distribuisce sempre all\u0026rsquo;esterno.\nDistribuzione di carica e densitÃ  superficiale in conduttori connessi ðŸŸ©\u0026mdash; Supponiamo di avere due sfere connesse da un filo conduttore (quindi la carica Ã¨ libera di connettersi), ci andiamo a chiedere che se metto $Q$ in questo sistema, in che modo si distribuisce? Io so che $R_{1} = 2R_{2}$ Noi sappiamo che il **potenziale sulla superficie** Ã¨ uguale, i due potenziali devono essere uguali anche nel nostro caso (altrimenti forse non Ã¨ bilanciato) $$ V(1) = V(2) \\implies \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q_{1}}{2R_{2}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q_{2}}{R_{2}} \\implies \\frac{Q_{1}}{Q_{2}} = \\frac{R_{1}}{R_{2}} \\implies Q_{1} = 2Q_{2} $$ Dove abbiamo definito che $$ V(1) = V(R_{1}) - V(\\infty) = V(R_{1}) = \\int _{R_{1}}^{\\infty} \\vec{E}\\, d\\vec{r} = \\int _{R_{1}} ^{\\infty} \\lvert \\vec{E} \\rvert \\, dr = \\int _{R_{1}} ^{\\infty} \\frac{Q}{4\\pi\\varepsilon_{0}} \\frac{1}{ r^{2}} \\, dr = \\frac{Q}{4\\pi\\varepsilon_{0}} -\\frac{1}{r} | _{R_{1}}^{\\infty} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q}{R_{1}} $$ **DensitÃ  superficiale:** Qui andiamo ad analizzare come cambia la distribuzione di densitÃ  superficiale per cose connesse, noi sappiamo per definizione che $$ \\sigma = \\frac{Q}{S} = \\frac{Q}{4\\pi R^{2}} \\implies Q_{1} = \\sigma_{1} 4\\pi R_{1}^{2} $$ Questo vale anche per $Q_{2}$ ossia abbiamo che $$ \\frac{\\sigma_{1}4\\pi R_{1}^{2}}{ \\sigma_{2} 4\\pi R_{2}^{2}} = \\frac{Q_{1}}{Q_{2}} = \\frac{R_{1}}{R_{2}} \\implies \\frac{\\sigma_{1}}{\\sigma_{2}} = \\frac{R_{2}}{R_{1}} $$ In cui la densitÃ  superficiale Ã¨ maggiore! Questo spiega anche i casi in cui piÃ¹ Ã¨ piccola la superficie, la densitÃ  superficiale Ã¨ maggiore, e questo spiega il motivo per cui nei temporali non piace stare in cose sottili. Se il raggio di curvatura Ã¨ piccola, la carica sarÃ  molto piÃ¹ densa. (punta = raggio di curvatura infinitesimo). Sembra in qualche modo questo concetto una naturale ottimizzazione che segue lola voronoi perchÃ© se una cosa Ã¨ appuntita, cambia in fretta, ha bisogno di piÃ¹ punti per essere descritta, sembra che in modo naturale avviene anche in questo caso :).\nQuesta cosa funziona anche per la Terra stessa, e si potrebbe considerare come quantitÃ  infinita di carica, ed Ã¨ questo il significato di mettere a terra (si puÃ² scaricare a terra carica in eccesso).\nPotenziale nei conduttori in equilibrio Potenziale interno al conduttore ðŸŸ© Si puÃ² dimostrare, senza molta difficoltÃ  che il potenziale Ã¨ sempre 0 all\u0026rsquo;interno del conduttore.\n$$ \\Delta V = V(A) - V(B) = \\int _{A}^{B}\\vec{E} \\cdot \\, d\\vec{r} = 0 $$ PerchÃ© il campo elettrico Ã¨ 0. -\nPotenziale sulla superficie ðŸŸ© Per risultato precedente, Ã¨ sempre perpendicolare col campo, quindi Ã¨ sempre 0, perchÃ© stiamo considerando il prodotto coseno. Si puÃ² concludere che in questo caso l\u0026rsquo;intera superficie Ã¨ equipotenziale. $$ \\Delta V = V(C) - V(D) = \\int _{C}^{D} \\vec{E} \\, d\\vec{r} = 0 $$ ","permalink":"https://flecart.github.io/notes/conduttori-elettrici/","summary":"Campo elettrico nei materiali Se prendiamo un conduttore, gli elettroni in questi materiali sono liberi, significa che sono liberi di muoversi come vogliono, si puÃ² dire che \u0026ldquo;vadano in giro\u0026rdquo; (per esempio questo vale per il rame).\nil reticolo cristallino Ã¨ al struttura regolare che Ã¨ comune nei materiali, in cui gli atomi sono sempre a distanza costante (o comunque a pattern regolari) uno dall\u0026rsquo;altro $r$ per esempio.\nCampo e materiali (6) Schermatura del campo (!","title":"Conduttori elettrici"},{"content":"Esercizi random 18-10 Questi si riferiscono ad esercizi prevalentemente fatti in Campo elettrico\nEsercizio 1 $$ \\vec{E} = - \\alpha y^{3} \\hat{i} - 3\\alpha xy^{2} \\hat{j} -3\\beta z^{2}\\hat{k} $$ Vogliamo andare a calcolare $V(x, y , z)$\ncheck campo conservativo (altrimenti TODO: capire il perchÃ©, non riesco a calcolare questo se non Ã¨ conservativo) Check del rotore, e si vede che Ã¨ conservativo. Probabilmente allora il potenziale dipende dal percorso, ma questa cosa non ci piace affatto (quindi rende senza senso) Scelgo il percorso (e spezzetto tutti i percorsi.) Soluzioni poste Soluzione sbagliata (facendo 0 da sempre e ho sbagliato anche i vettori): $$ V(x, y, z) = -\\alpha y^{3}P_{x}\\hat{i} - \\alpha xP_{y}^{3}\\hat{j} - \\beta P_{z}^{3}\\hat{k} $$ Soluzione controllata: $$ V(x, y , z) = \\alpha xy^{3} + \\beta z^{2} $$ Poi questo si puÃ² controllare tenendo in mente che $\\vec{\\nabla}\\cdot V = -\\vec{E}$\nEsercizio 2 Luglio 2023 Date 3 particelle puntiformi con una carica $Q = 2 \\cdot 10^{-6} C$ per tutti e $m = 5 \\cdot 10^{-3} Kg$, fissati ai vertici di un triangolo equilatero, con $l = 2cm$ lato. In un certo instante una particella viene liberata, calcolare\nIl modulo della velocitÃ  a distanza infinita. Quanto vale il modulo della forza su Q_3 quando la sua velocitÃ  Ã¨ la metÃ  della precedente. Soluzioni proposte Cariche ferme, abbiamo un campo elettrostatico, e quindi osserviamo un campo conservativo, significa che l\u0026rsquo;energia cinetica finale sarÃ  la stessa di quella potenziale iniziale. $$ E_{i} = q_{0}(V_{1} + V_{2}) + 0 $$ 0 per dire che non ha energia cinetica all\u0026rsquo;inizio.\n$$v = \\lvert Q \\rvert \\sqrt{ \\frac{1}{m\\pi\\varepsilon_{0}l} }, \\implies 37.9\\frac{m}{s}$$ Seconda parte Bisogna sempre utilizzare la conservazione dell\u0026rsquo;energia, calcolare cosÃ¬ la distanza in questo caso. SarÃ  $\\frac{4}{3}l$\nDopo aver ottenuto la distanza, si finisce calcolando il valore della forza che Ã¨ uguale a $$ \\vec{F} = \\frac{1}{2\\pi\\varepsilon_{0}} \\frac{Q^{2}}{\\frac{16}{9}l^{2}} \\cos \\theta $$ E theta si ottiene facendo cose con angoli (triangolo rettangolo con 4/3 l e 1/2 l)\nEsercizio 3 In un riferimento cartesiano, abbiamo un potenziale di $V = b - ax^{3}$, si consideri il volume delimitato da un cubo di lato $l$ con uno spigolo sull\u0026rsquo;origine. Calcolare la carica dentro questo cubo.\nSoluzione proposta Uso gauss su tutte le facce, e noto che in 4 Ã¨ 0 perchÃ© il campo varia solo in $x$, per questo motivo poi calcolando il tutto abbiamo che il flusso Ã¨ $3al^{4}$ e poi si usa gauss per dire che la soluzione Ã¨ $$ Q = 3al^{4}\\varepsilon_{0} $$ Altra soluzione Si prova a calcolare $\\rho$ e poi si integra su tutto il cubo, si ottiene risultato uguale a sopra e si usa la divergenza\n$$ \\vec{\\nabla} \\cdot \\vec{E} = \\frac{\\rho}{\\varepsilon_{0}} $$ Si ottiene che $$ \\rho = 6ax\\varepsilon_{0} $$ E poi diventa molto piÃ¹ facile da gestire col triplo integrale.\nEsercizio 4 Data una superficie piana e una carica su di essa, entrambe sono cariche positivamente, in che posizione Ã¨ carica dopo che Ã¨ passato un certo tempo $t$? la distanza in funzione del tempo $x(t)$? e la velocitÃ  in funzione della distanza?\nSoluzioni proposte VelocitÃ  dopo un certo tempo $t$. $$ v = \\frac{q\\sigma}{2m\\varepsilon_{0}}t \\implies d= \\frac{q\\sigma}{2m\\varepsilon_{0}} \\frac{1}{2}t^{2} \\implies v = \\sqrt{ \\frac{dq\\sigma}{\\varepsilon_{0}m} } $$ Seconda soluzione Si puÃ² fare lo stesso usando la conservazione dell\u0026rsquo;energia. $$ K_{A} + U_{A} = K_{d} + U_{d} $$ Prendo direttamente il percorso tangenziale\n$$ q(V_{D} - V_{A}) = \\frac{1}{2}mv^{2} \\implies q \\int _{A}^{B} \\vec{E} \\cdot \\, d\\vec{x} = \\frac{q\\sigma d}{2\\varepsilon_{0}} = \\frac{1}{2}mv^{2} $$ Esercizio 5 gennaio 2023 Una densitÃ  di carica volumetrica $\\rho(\\vec{r})$ Ã¨ presente in una regione di spazio sferico con $r \u003c R$ tale densitÃ  genera all\u0026rsquo;interno della sfera un campo elettrostatico descritto dall\u0026rsquo;equazione $\\vec{E} = Ar^{3}\\hat{r}$ si assume che fuori dalla sfera ci sia il vuoto.\nDeterminare la densitÃ  di carica della sfera. Potenziale elettrostatico su un punto della superficie sferica, assumendo che potenziale all\u0026rsquo;infinito sia 0. Soluzioni Il cheat Ã¨ sapere la divergenza con coordinate polari: $$ div E_{r} = \\frac{1}{r^{2}} \\frac{\\delta}{\\delta r} r^{2} E_{r} $$ E sapendo questo poi era cavolata, ma facendolo in altro modo bisogna andare in coordinate cartesiane.\n$$ \\rho = \\varepsilon_{0}5Ar^{2} $$ Soluzione 2 In coordinate cartesiane abbiamo che $$ \\vec{E} = A (x^{2} + y ^{2} + z^{2}) (x \\hat{i} + y \\hat{j} + z \\hat{k}) $$ E dovrebbe venire uguale alla fine.\nProblema 2 Calcolo la carica totale e viene come soluzione $$ Q = 4A\\pi\\varepsilon_{0}R^{5} $$ Con questo ho tutto per finire il problema due $$ V(R) - V(\\infty) = \\int _{R}^{\\infty} \\vec{E} \\, d\\vec{r} \\implies \\int_{A}^{\\infty} \\frac{AR^{5}}{r^{2}} d\\vec{r} $$ E poi si trova $AR^{4}$ come soluzione finale.\nEsercizi lezione 25 Ottobre Esercizio 1 Supponiamo di avere due sfere, $r_{1}, r_{2}$ e carica $q_{1}, q_{2}$, inizialmente scollegate. In seguito li attacco con un filo conduttore di capacitÃ  trascurabile,\nquanto Ã¨ la distribuzione di carica sulle sfere ora? Quanto Ã¨ il valore del nuovo potenziale elettrostatico? Quanto Ã¨ l\u0026rsquo;energia dissipata dal collegamento? Punto uno $$ q_{1}' = \\frac{(q_{1} + q_{2})r_{1}}{r_{2} + r_{1}} $$ Si ottiene facendo sempre il discorso di uguale potenziale.\nPunto due Per il secondo punto una volta ottenuta la carica Ã¨ facile ottenere il nuovo potenziale: $$ V_{1}' = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}'}{r_{1}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1} + q_{2}}{r_{2} + r_{1}} $$ nel caso in cui non fossero state delle sfere, mi ricavavo il nuovo valore utilizzando la relazione del condensatore, che ricordiamo dipendono solamente dalla geometria, che Ã¨ ancora la stessa. $$ q_{1}' = C_{1}V_{1}' $$ $$ q_{1} = C_{1}V_{1} $$ Punto tre Non la calcoliamo in modo esplicito perchÃ© non si semplifica, ma basta fare totale prima meno totale adesso\u0026hellip;\nEsercizio 2 Abbiamo una regione di piano delimitata da $[-d, d]$ sull\u0026rsquo;asse delle $x$ una distribuzione di carica uniforme $\\rho$, calcolare campo elettrico e potenziale elettrico nello spazio.\nSoluzione Andiamo a considerare il cilindro come in figura, per ragioni di simmetria sul lato lungo del cilindro il campo Ã¨ nullo, quindi le uniche superfici da considerare sono le due esterne $$ \\oint \\vec{E} \\cdot d\\vec{s} = \\int _{\\Sigma} \\vec{E} \\, d\\vec{s} + \\int _{\\Sigma} \\vec{E} \\, d\\vec{s} = 2E\\delta $$ Sappiamo che il campo elettrico Ã¨ parallelo a $x$ e costante, perchÃ© in pratica Ã¨ come se stessimo nel caso di superficie piana infinita carica, solo che in questo caso Ã¨ bidimensionale. Allora abbiamo: $$ 2E\\delta = \\frac{Q_{tot}}{\\varepsilon_{0}} \\implies 2E\\delta = \\frac{\\rho V}{\\varepsilon_{0}} \\implies 2E\\delta = \\frac{\\rho 2\\delta d}{\\varepsilon_{0}} \\implies E = \\frac{\\rho d}{\\varepsilon_{0}} $$ Con $\\delta$ la superficie del cerchio di base del nostro cilindro. Abbiamo allora stabilito il campo elettrico che Ã¨ abbastanza coerente con la formula di campo elettrico per piano carico infinito (cambia solo di costante 2 al denominatore credo). Ci chiediamo allora, internamente quanto vale? si puÃ² applicare lo stesso ragionamento e sarÃ  di valore $$ E = \\frac{\\rho x}{\\varepsilon_{0}},\\, x \\in (-d, d) $$ da questo si puÃ² ricavare il potenziale Il potenziale Ã¨ preso fino a $V$ Interno: $$ V(x) = -\\frac{\\rho x^{2}}{\\varepsilon_{0}}, \\, x \\in (-d, d) $$ Esterno:\n$$ V(x) = \\rho d \\frac{d - x}{\\varepsilon_{0}} - \\frac{\\rho d^{2}}{\\varepsilon_{0}}, \\, x \\in (-\\infty, -d) \\cup(d, +\\infty) $$ Potrebbe essere che ci sia un 2 in meno, Ã¨ da rifare questo esercizio per verificare questo.\nEsercizio 3 Supponiamo di avere una sfera di densitÃ  uniforme $\\rho$ di raggio$r_{1}$ e una cavitÃ  sferica al suo interno di raggio $r_{2} \u003c r_{1}$, calcolare campo elettrico circostante. Soluzione $$\\vec{E}_{tot} = \\frac{\\rho}{3\\varepsilon_{0}} \\vec{r}$$ con $\\vec{r}$ il vettore della congiungente dei centri.\nEsercizio 4 Questo Ã¨ un problema classico studiato anche alle superiori, abbiamo un elettrone che passa in un condensatore di lunghezza $l$ e campo elettrico $E$ diretto verso il basso. L\u0026rsquo;elettrone ha velocitÃ  lungo l\u0026rsquo;asse $x$ uguale a $v_{0}$.\nQuanto ci mette a percorrere la lunghezza del condensatore? Quanto Ã¨ l\u0026rsquo;angolo di deflessione della velocitÃ  dopo che Ã¨ uscito. Soluzione: Ci mette esattamente $t = \\frac{l}{v_{0}}$ secondi a percorrere il condensatore. Nel frattempo Ã¨ sottoposto a una forza $eE$ lungo una altra direzione. Si puÃ² allora dimostrare che la quantitÃ  di deflessione Ã¨ uguale a $$ y = \\frac{eE}{2m} t^{2} $$ con $m$ la massa dell\u0026rsquo;elettrone. Mentre la velocitÃ  finale Ã¨ di $V_{y} = \\frac{eE}{m}t$ Possiamo allora calcolare l\u0026rsquo;angolo di deflessione $$ \\frac{V_{y}}{V_{x}} = \\frac{eE}{m} \\frac{l}{v_{0}} \\cdot \\frac{1}{v_{0}} = \\frac{eE}{m} \\frac{l}{v_{0}^{2}} $$ E si prende l\u0026rsquo;arcotangente inversa di quel valore di sopra.\nPreparazione parziale 1 3 Luglio 2023 Esercizio 1 Soluzione riportata $$ v = \\frac{q}{\\sqrt{ \\pi\\varepsilon_{0}m L }} $$ $$ F = 9 \\frac{\\sqrt{ 119 }}{256} \\frac{q^{2}}{\\pi\\varepsilon_{0}L^{2}} $$ Secondo punto Dal primo punto abbiamo che $$ U = \\frac{2q^{2}}{4\\pi\\varepsilon_{0}} \\cdot \\frac{1}{L} $$ Scriviamo la soluzione al punto b, che mi sembra errata. Poniamo la conservazione dell\u0026rsquo;energia\n$$ U_{i} + \\frac{1}{2}m v_{i}^{2} = U_{f} + \\frac{1}{2}mv_{f}^{2} \\implies U_{i} = \\frac{1}{2}m (v_{f}^{2} - v_{i}^{2}) $$ Essendo che $v_{i} = \\frac{1}{2}v_{f}$ abbiamo $$ U_{i} = \\frac{1}{2}m\\left( \\frac{3}{4}v_{f}^{2} \\right) = \\frac{3}{8}mv_{f}^{2} $$ Per soluzione trovata sopra si ha che $$ U_{i} = \\frac{2q^{2}}{4\\pi\\varepsilon_{0}} \\cdot \\frac{1}{L_{i}} = \\frac{3}{8}mv^{2}_{f} \\implies L_{i} = \\frac{2q^{2}}{4\\pi\\varepsilon_{0}} \\cdot \\frac{8}{3} \\frac{1}{mv_{f}^{2}} = \\frac{4}{3} \\frac{q^{2}}{\\pi\\varepsilon_{0}mv_{f}^{2}} = \\frac{4}{3} \\frac{q^{2}}{\\pi\\varepsilon_{0}m} \\cdot \\frac{\\pi\\varepsilon_{0}mL}{q^{2}} = \\frac{4}{3}L $$ Con il valore della distanza in linea retta possiamo poi calcolare la forza presente:\n$$ F_{tot} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{2q^{2}}{L^{2}_{i}} \\cdot \\cos \\theta = \\frac{1}{2\\pi\\varepsilon_{0}} \\frac{9q^{2}}{16L^{2}} \\cos \\theta $$ Con theta l\u0026rsquo;angolo che si forma fra $L_{i}$ e la congiungente al centro, per questo motivo possiamo scrivere $$ \\cos \\theta = \\frac{\\sqrt{ L_{i}^{2} - \\left( \\frac{L}{2} \\right)^{2} }}{L_{i}} =\\frac{\\sqrt{ \\frac{16}{9}L^{2} - \\frac{1}{4}L^{2} }}{\\frac{4}{3}L} =\\frac{3}{4}\\sqrt{ \\frac{64 - 9}{36} } = \\frac{1}{8}\\sqrt{ 55 } $$ Possiamo allora mettere questo valore nell\u0026rsquo;equazione di sopra e ci viene\n$$ F_{tot} = \\frac{1}{2\\pi\\varepsilon_{0}} \\frac{9q^{2}}{16L^{2}} \\frac{1}{8} \\sqrt{ 55} = \\frac{9\\sqrt{ 55 }}{256} \\cdot \\frac{q^{2}}{\\pi\\varepsilon_{0}L^{2}} $$ 24 Gennaio 2022 Esercizio 1 Viene riportato $$ \\sigma_{i} = -\\frac{q}{4\\pi r^{2}} $$ per la superficie interna E $$ \\sigma_{e} = \\frac{3q}{4\\pi r^{2}} $$ Per la superficie esterna. C\u0026rsquo;Ã¨ una imprecisione riguardante\nPunto b Per la superficie interna potremmo considerare una superficie di gauss all\u0026rsquo;interno del conduttore. Sappiamo che essendo dentro il conduttore deve essere che il campo elettrico sia nullo. Quindi sarÃ  stata disposta una quantitÃ  di carica sul conduttore tale da annullare $q$ presente al centro: $$ \\oint \\vec{E} \\cdot d\\vec{s} = \\frac{q_{tot}}{\\varepsilon_{0}} = (q + \\sigma_{i} 4\\pi R^{2}) $$ Esercizi 25 Ottobre Esercizio 1 Supponiamo di avere due sfere, $r_{1}, r_{2}$ e carica $q_{1}, q_{2}$, inizialmente scollegate. In seguito li attacco con un filo conduttore di capacitÃ  trascurabile,\nquanto Ã¨ la distribuzione di carica sulle sfere ora? Quanto Ã¨ il valore del nuovo potenziale elettrostatico? Quanto Ã¨ l\u0026rsquo;energia dissipata dal collegamento? Punto uno $$ q_{1}' = \\frac{(q_{1} + q_{2})r_{1}}{r_{2} + r_{1}} $$ Si ottiene facendo sempre il discorso di uguale potenziale.\nPunto due Per il secondo punto una volta ottenuta la carica Ã¨ facile ottenere il nuovo potenziale: $$ V_{1}' = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}'}{r_{1}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1} + q_{2}}{r_{2} + r_{1}} $$ nel caso in cui non fossero state delle sfere, mi ricavavo il nuovo valore utilizzando la relazione del condensatore, che ricordiamo dipendono solamente dalla geometria, che Ã¨ ancora la stessa. $$ q_{1}' = C_{1}V_{1}' $$ $$ q_{1} = C_{1}V_{1} $$ Punto tre Non la calcoliamo in modo esplicito perchÃ© non si semplifica, ma basta fare totale prima meno totale adesso\u0026hellip;\nEsercizio 2 Abbiamo una regione di piano delimitata da $[-d, d]$ sull\u0026rsquo;asse delle $x$ una distribuzione di carica uniforme $\\rho$, calcolare campo elettrico e potenziale elettrico nello spazio.\nSoluzione Andiamo a considerare il cilindro come in figura, per ragioni di simmetria sul lato lungo del cilindro il campo Ã¨ nullo, quindi le uniche superfici da considerare sono le due esterne $$ \\oint \\vec{E} \\cdot d\\vec{s} = \\int _{\\Sigma} \\vec{E} \\, d\\vec{s} + \\int _{\\Sigma} \\vec{E} \\, d\\vec{s} = 2E\\delta $$ Sappiamo che il campo elettrico Ã¨ parallelo a $x$ e costante, perchÃ© in pratica Ã¨ come se stessimo nel caso di superficie piana infinita carica, solo che in questo caso Ã¨ bidimensionale. Allora abbiamo: $$ 2E\\delta = \\frac{Q_{tot}}{\\varepsilon_{0}} \\implies 2E\\delta = \\frac{\\rho V}{\\varepsilon_{0}} \\implies 2E\\delta = \\frac{\\rho 2\\delta d}{\\varepsilon_{0}} \\implies E = \\frac{\\rho d}{\\varepsilon_{0}} $$ Con $\\delta$ la superficie del cerchio di base del nostro cilindro. Abbiamo allora stabilito il campo elettrico che Ã¨ abbastanza coerente con la formula di campo elettrico per piano carico infinito (cambia solo di costante 2 al denominatore credo). Ci chiediamo allora, internamente quanto vale? si puÃ² applicare lo stesso ragionamento e sarÃ  di valore $$ E = \\frac{\\rho x}{\\varepsilon_{0}},\\, x \\in (-d, d) $$ da questo si puÃ² ricavare il potenziale Il potenziale Ã¨ preso fino a $V$ Interno: $$ V(x) = -\\frac{\\rho x^{2}}{\\varepsilon_{0}}, \\, x \\in (-d, d) $$ Esterno:\n$$ V(x) = \\rho d \\frac{d - x}{\\varepsilon_{0}} - \\frac{\\rho d^{2}}{\\varepsilon_{0}}, \\, x \\in (-\\infty, -d) \\cup(d, +\\infty) $$ Potrebbe essere che ci sia un 2 in meno, Ã¨ da rifare questo esercizio per verificare questo.\nEsercizio 3 Supponiamo di avere una sfera di densitÃ  uniforme $\\rho$ di raggio$r_{1}$ e una cavitÃ  sferica al suo interno di raggio $r_{2} \u003c r_{1}$, calcolare campo elettrico circostante. Soluzione $$\\vec{E}_{tot} = \\frac{\\rho}{3\\varepsilon_{0}} \\vec{r}$$ con $\\vec{r}$ il vettore della congiungente dei centri.\nEsercizio 4 Questo Ã¨ un problema classico studiato anche alle superiori, abbiamo un elettrone che passa in un condensatore di lunghezza $l$ e campo elettrico $E$ diretto verso il basso. L\u0026rsquo;elettrone ha velocitÃ  lungo l\u0026rsquo;asse $x$ uguale a $v_{0}$.\nQuanto ci mette a percorrere la lunghezza del condensatore? Quanto Ã¨ l\u0026rsquo;angolo di deflessione della velocitÃ  dopo che Ã¨ uscito. Soluzione: Ci mette esattamente $t = \\frac{l}{v_{0}}$ secondi a percorrere il condensatore. Nel frattempo Ã¨ sottoposto a una forza $eE$ lungo una altra direzione. Si puÃ² allora dimostrare che la quantitÃ  di deflessione Ã¨ uguale a $$ y = \\frac{eE}{2m} t^{2} $$ con $m$ la massa dell\u0026rsquo;elettrone. Mentre la velocitÃ  finale Ã¨ di $V_{y} = \\frac{eE}{m}t$ Possiamo allora calcolare l\u0026rsquo;angolo di deflessione $$ \\frac{V_{y}}{V_{x}} = \\frac{eE}{m} \\frac{l}{v_{0}} \\cdot \\frac{1}{v_{0}} = \\frac{eE}{m} \\frac{l}{v_{0}^{2}} $$ E si prende l\u0026rsquo;arcotangente inversa di quel valore di sopra.\nEsercizi random 10-gennaio-2023 Es 3 Trattiamo il punto 2:\n$$ P_{\\tau} = \\vec{J} \\cdot \\vec{E} = \\frac{\\vec{I}}{S} \\cdot \\vec{E} = \\frac{\\rho I^{2}}{S^{2}} = \\frac{\\rho V^{2}}{R^{2} \\cdot S^{2}} = \\frac{V^{2}}{\\rho L^{2}} $$ Ha senso perchÃ© in questo esercizio il campo elettrico cambia a seconda della distanza dell\u0026rsquo;asse, quindi in vogliamo sostituire la resistenza in un certo punto lungo l\u0026rsquo;asse e non dell\u0026rsquo;intero conduttore.\nProblemi sezione campo elettrico Problemi classici col flusso Problema: Flusso del cilindro su carica lineare ðŸŸ¨+ Consideriamo una linea con distribuzione di carica uniforme $\\lambda$ questo Ã¨ un campo perpendicolare, e si puÃ² dire che questo campo abbia simmetria cilindrica Sapendo la carica di questo cilindro possiamo calcolare il flusso che passa in questo cilindro, quindi abbiamo $$ \\oint_{\\Sigma}\\vec{E}\\vec{ds} = \\frac{Q_{T}}{\\varepsilon_{0}} = \\lambda \\cdot \\frac{h}{\\varepsilon_{0}}, h \\text{ la lunghezza} $$ Inoltre sapendo che $\\vec{E}$ Ã¨ sempre perpendicolare, e il valore in modulo Ã¨ sempre lo stesso (per come abbiamo costruito il cilindro). Dall\u0026rsquo;altra parte ora calcoliamo l\u0026rsquo;integrale che ci siamo definiti in questo modo: $$ \\oint_{\\Sigma} \\vec{E} \\vec{ds} = \\int _{\\Sigma_{l}}\\vec{E} \\, \\vec{ds_{l}} + \\int _{\\Sigma_{up}}\\vec{E} \\, \\vec{ds_{up}} + \\int _{\\Sigma_{dw}}\\vec{E} \\, \\vec{ds_{dw}} $$ Notando che il campo Ã¨ perpendicolare, abbiamo che $$ \\int _{\\Sigma_{dw}}\\vec{E} \\, \\vec{ds_{dw}} = 0 $$ $$ \\\\ \\int _{\\Sigma_{up}}\\vec{E} \\, \\vec{ds_{up}} = 0 $$ Sfruttando il fatto che il modulo del campo elettrico Ã¨ costante, basta andare a calcolare l\u0026rsquo;area della superficie laterale: $$ \\\\ \\int _{\\Sigma_{l}}\\vec{E} \\, \\vec{ds_{l}} = \\lvert \\vec{E} \\rvert \\int _{\\Sigma_{l}}\\, \\vec{ds_{l}} = \\lvert \\vec{E} \\rvert 2\\pi\\cdot rh $$ Mettendo assieme con una equazione di sopra con gauss abbiamo $$ \\lvert \\vec{E} \\rvert 2\\pi\\cdot rh = \\lambda \\cdot \\frac{h}{\\varepsilon_{0}} \\implies \\lvert \\vec{E} \\rvert = \\frac{\\lambda}{\\varepsilon_{0}} \\frac{1}{2\\pi r} $$ NOTA: la cosa figa Ã¨ che se Ã¨ costante allora posso utilizzare la legge di gauss in questo modo, di portare fuori il modulo del campo!\nProblema: campo elettrico su piano elettrico, $\\sigma$ costante ðŸŸ© Consideriamo una superficie con densitÃ  di carica $\\sigma$ che sia costante, andiamo a valutare il campo elettrico in un punto $p$ a distanza $r$ dalla superficie.\nOsservazione: Il campo di E Ã¨ diretto perpendicolarmente, in modo simile alla precedente, sempre per ragioni di simmetria, per ogni carica ne esiste una simmetrica, quindi il campo Ã¨ strutturato in questo modo\u0026hellip;\nSi avrÃ  che $$ (\\oint_{\\Sigma} \\lvert \\vec{E} \\rvert \\, \\vec{ds} = \\int _{\\Sigma_{l}}\\vec{E} \\, \\vec{ds_{l}} + \\int _{\\Sigma_{up}}\\vec{E} \\, \\vec{ds_{up}} + \\int _{\\Sigma_{dw}}\\vec{E} \\, \\vec{ds_{dw}} = \\int _{\\Sigma_{up}}\\vec{E} \\, \\vec{ds_{up}} + \\int _{\\Sigma_{dw}}\\vec{E} \\, \\vec{ds_{dw}} = ) $$ $$ \\lvert \\vec{E} \\rvert (\\int _{\\Sigma_{dw}} \\, \\vec{ds_{dw}} + \\int _{\\Sigma_{up}} \\, \\vec{ds_{up}} ) = 2 \\lvert \\vec{E} \\rvert \\pi r^{2} = \\pi r^{2}\\cdot \\frac{\\sigma}{\\varepsilon_{0}} \\implies \\lvert \\vec{E} \\rvert = \\frac{\\sigma}{2\\varepsilon_{0}} $$ Questo si puÃ² dimostrare per una superficie qualsiasi ($A$) e sarebbe piÃ¹ elegante, lo puoi vedere in immagine questa cosa.\nProblema per casa: Supponiamo di avere una distribuzione indefinita su una linea in un cilindro infinito, vorrei avere la distribuzione di $\\vec{E}(\\vec{r})$\nProblema altro (diff piani) Prendiamo una superficie qualsiasi, con densitÃ  $\\sigma$ costante, e proviamo a prendere un cilindro infinitesimo, di area $dA$ e altezza $dh$, con la legge di gauss su questa superficie piana (come se fosse costante), posso calcolare il flusso di campo elettrico.\nProviamo ad usare gauss e vedere come va il flusso? avrÃ² $\\vec{E}\\vec{ds_{u}} + \\vec{E}\\vec{ds_{l}} + \\vec{E}\\vec{ds_{d}} = \\frac{dQ_{T}}{\\varepsilon_{0}} = dA \\frac{\\sigma}{\\varepsilon_{0}}$ sempre su tutte e tre le superfici, dato che ci interessa la superficie, facciamo tendere $dh \\to 0$ , cosÃ¬ riesco ad approssimare la superficie in questo modo avrÃ² che la superficie laterale sarÃ  0. $$ \\vec{E}\\vec{ds_{u}} + \\vec{E}\\vec{ds_{d}} = Eds_{u}\\cos \\theta_{u} + E ds_{d}\\cos \\theta_{d} $$ Ossia provo a proiettare E sulla direzione perpendicolare sulla superficie. abbiamo quindi $E_{\\perp}^{u}dA + E_{\\perp}^{d}dA = \\frac{\\sigma dA}{\\varepsilon_{0}} \\implies E_{\\perp}^{u }+ E_{\\perp}^{d} = \\frac{\\sigma}{\\varepsilon_{0}}$ $$ \\lvert E_{\\perp}^{u}\\hat{u} + E_{\\perp}^{d}\\hat{v} \\rvert = \\frac{\\sigma}{\\varepsilon_{0}} \\implies \\Delta E_{\\perp} = \\frac{\\sigma}{\\varepsilon_{0}} $$ C\u0026rsquo;Ã¨ una discontinuitÃ , che Ã¨ dipendente dal fatto di avere la normale o meno, dovrei approfondire e vedere in che modo\u0026hellip; TODO: capire cosa significa avere discontinuitÃ  in questa parte\u0026hellip;\nSuperficie cilindrica carica (!) ðŸŸ¨\u0026ndash; Problema: Supponiamo di avere un cilindro di lunghezza infinita con una certa carica distribuita uniformemente. Capire come Ã¨ fatto il campo elettrico ed energia potenziale al variare del raggio (distanza dell\u0026rsquo;asse principale).\nDato il setting in figura (una carica distribuita indefinitivamente sulla superficie di un cilindro), proviamo a considerare un cilindro all'interno del cilindro grosso, andiamo a provare a calcolare il flusso $$ \\oint_{\\Sigma}\\vec{E}\\cdot \\vec{ds} = E(r) \\oint_{\\Sigma}ds = E(r) 2\\pi rh = 0 \\implies E(r) = 0, r \u003c R $$ Supponiamo che siano invertiti, che la carica sia contenuta rispetto al cilindro che abbiamo, allora abbiamo che $$ \\vec{E}(r) 2\\pi rh = \\frac{Q_{\\Sigma}}{\\varepsilon_{0}} = \\frac{\\sigma(2\\pi hR)}{\\varepsilon_{0}} \\implies E(r) = \\frac{Q}{2\\pi\\varepsilon_{0}rh} = \\frac{\\sigma R}{\\varepsilon_{0} r} $$ Facendo l\u0026rsquo;analisi di dimensione abbiamo $$ [\\sigma 2\\pi R] = [CL^{-2}L] = [CL^{-1}] \\to \\lambda $$ Che Ã¨ la stessa dimensione di una densitÃ  lineare di carica\nCon questa osservazione si puÃ² dire che: $$ E(r) = \\frac{\\lambda}{2\\pi\\varepsilon_{0}r}\\hat{r} $$ Che Ã¨ molto simile al problema del filo di lunghezza infinita, anche con il cilindro esterno (ed Ã¨ sensato perchÃ© un filo infinito Ã¨ come se se fosse un cilindro!) vai a vedere Campo elettrico#Distribuzione di carica uniforme lineare infinita\nCon questa analisi possiamo dire che segue questo andamento. Con la seconda parte $\\propto \\frac{1}{r}$\nPotenziale Possiamo fare delle assunzioni preliminari sul fatto che $V(R) = 0$ e che $V(\\infty) = \\infty$\n$$ r \u003e R \\implies V(r) - V(R) = \\int _{r}^{R} \\vec{E}\\cdot d \\vec{r} = \\frac{\\sigma_{2}\\pi R}{2\\pi\\varepsilon_{0}} \\int _{r}^{R} \\, \\frac{dr}{r} = \\frac{\\sigma_{2}\\pi R}{2\\pi\\varepsilon_{0}} \\ln\\left( \\frac{R}{r} \\right) $$ Mentre all\u0026rsquo;interno, dato che il campo Ã¨ 0, resta sempre 0 il potenziale elettrico, costante.\nSuperficie cilindrica uniformemente carica ðŸŸ¥ Questo Ã¨ uguale al precedente, solo che che carico tutto, anche l\u0026rsquo;interno di essa in modo uniforme. Se prendo il raggio, allora torno al modo equivalente precedente (quindi sembra in pratica una densitÃ  lineare di carica!). Cambia nel caso in cui il raggio ora Ã¨ interno.\n$$ r \u003c R \\implies \\oint \\vec{E} \\cdot d \\vec{s} = E(r) 2\\pi rh = \\frac{Q_{\\Sigma}}{\\varepsilon_{0}} = \\frac{\\rho \\pi r^{2}h}{\\varepsilon_{0}} \\implies \\vec{E}(r) = \\frac{\\rho}{2\\varepsilon_{0}} \\vec{r} $$ In questo caso il campo aumenta linearmente. Potenziale Esternamente il potenziale Ã¨ ancora uguale al precedente, internamente invece cambia leggermente $$ V(r) - V(R) = \\int _{r}^{R} \\vec{E}(r) \\, d \\vec{r} = \\frac{\\rho}{2\\varepsilon_{0}} \\cdot \\frac{R^{2} - r^{2}}{2} $$ Esercizio sul calcolo della divergenza: TODO: vedere se la divergenza Ã¨ zero su una linea normale idiota al punto p TODO: vedere divergenza in coordinate sferiche (formula strana)\u0026hellip;. dipende dal raggio TODO: guardare quanto Ã¨ buono.\n$$ \\vec{E}(x, y ,z) = \\frac{Q}{4\\pi\\varepsilon_{0}} \\frac{xi + yj + zk}{(x^{2} + y^{2} + z^{2})^{3/2}} $$ ","permalink":"https://flecart.github.io/notes/elettromagnetismo-esercizi-fatti/","summary":"Esercizi random 18-10 Questi si riferiscono ad esercizi prevalentemente fatti in Campo elettrico\nEsercizio 1 $$ \\vec{E} = - \\alpha y^{3} \\hat{i} - 3\\alpha xy^{2} \\hat{j} -3\\beta z^{2}\\hat{k} $$ Vogliamo andare a calcolare $V(x, y , z)$\ncheck campo conservativo (altrimenti TODO: capire il perchÃ©, non riesco a calcolare questo se non Ã¨ conservativo) Check del rotore, e si vede che Ã¨ conservativo. Probabilmente allora il potenziale dipende dal percorso, ma questa cosa non ci piace affatto (quindi rende senza senso) Scelgo il percorso (e spezzetto tutti i percorsi.","title":"Elettromagnetismo esercizi fatti"},{"content":"Elementi di ripasso Gruppi normali e quoziente Introduzione Definizione normalitÃ  Test del sottogruppo normale Dimostrazione\nIl gruppo quoziente Lâ€™importanza del gruppo normale Ã¨ che quando esso vale, possiamo avere il gurppo fattore\nDimostrazione\n!\n","permalink":"https://flecart.github.io/notes/gruppi-normali/","summary":"Elementi di ripasso Gruppi normali e quoziente Introduzione Definizione normalitÃ  Test del sottogruppo normale Dimostrazione\nIl gruppo quoziente Lâ€™importanza del gruppo normale Ã¨ che quando esso vale, possiamo avere il gurppo fattore\nDimostrazione\n!","title":"Gruppi Normali"},{"content":"Ripasso Prox: 36 Ripasso: June 1, 2022 Ultima modifica: October 19, 2022 5:05 PM Primo Abbozzo: December 12, 2021 11:58 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso significato di compatibilitÃ  Il vettore dei termini noti, non ti ricordavi la parola termini noti ðŸ˜€ 0 Introduzione Tutta sta parte si fa in modo formale in Sistemi Lineari e determinanti, quindi potresti saltarla totalmente\n0.1 Equazioni lineari L\u0026rsquo;obiettivo dell\u0026rsquo;algebra lineare Ã¨ risolvere n equazioni con n sconosciuti di primo grado. Cosa che ci riesce con grandissimo successo! Andiamo ora a definire meglio cosa Ã¨ una equazione lineare\n0.1.1 Definizione Una equazione lineare Ã¨ una equazione a coefficienti appartenenti a un certo campo (che puÃ² essere R) e incognite il cui grado Ã¨ 1 e che siano indipendenti:\nes.\n$$ a_1x_1 + a_2x_2 +...+a_nx_n=b $$ lo puoi considerare come una equazione lineare, mentre cose come\n$$ \\begin{cases} x^2 = 2 \\\\ xy = 2 \\\\ \\end{cases} $$ Non lo sono.\n0.1.2 Equivalenza e compatibilitÃ  Equivalenza: due sistemi sono equivalenti quanto hanno le stesse soluzioni\nCompatibilitÃ : Un sistema si dice compatibile quando ammette soluzioni\n0.1.3 Soluzione di una equazione lineare Una soluzione di una equazione lineare a n variabili, Ã¨ una n-tupla di valori ordinati che soddisfano l\u0026rsquo;equazione. La cosa che ci interesserÃ  sarÃ  la soluzione di un sistema di equazioni lineari ovvero tante equazioni lineari che vogliono essere tutte soddisfatte allo stesso momento.\n0.1.4 ProprietÃ  dellâ€™uguaglianza Ãˆ molto importante per comprendere le equazioni comprendere le due proprietÃ  dell\u0026rsquo;uguaglianza che si studiano di solito alle medie.\nSono due, una per la somma e una per la moltiplicazione scalare.\nSomma: Data una eguaglianza a = b, questa Ã¨ uguale sse per ogni c, c + a = c + b. Moltiplicazione scalare: Data una eguaglianza a = b, questa Ã¨ uguale sse per ogni c si ha ca = cb (la prof ha tolto il caso in c = 0) 0.2 Le matrici 0.2.1 Definizione Potremmo definire la matrice solamente come una tabella che contiene dei numeri, a volte nemmeno si dÃ  il nome di tabella, ma solamente come una collezione indicizzata di coefficienti.\npotresti definire matrice cosÃ¬ $M = (a_{ij})_{nm}$\nIn genere una matrice di dimensione nxm si scrive in notazione sul campo su cui Ã¨ definito, per esempio\n$M_{n \\times m}(\\R)$, se Ã¨ quadrata di solito si sottindende l\u0026rsquo;altra dimensione e si scrive $M_n(\\R)$.\n0.2.2 Vettori riga e colonna Si potrebbero definire dei vettori riga e colonna a seconda delle dimensioni della matrice:\ndi dimensione 1xn sono vettori riga\ndi dimensione nx1 sono vettori colonna\nQuesti vettori sono importanti poi per scomporre la matrice, quindi ora basta tenerli a mente\n0.2.3 Costruzione della somma e prodotto scalare Possiamo sempre fare la somma di due matrici con le stesse dimensioni definite sullo stesso campo.\nSomma\nInfatti se prendiamo A e B , la matrice somma C Ã¨ la matrice costituita dalla somma elemento per elemento (somma per indici corrispondenti).\nScalare\nPer il prodotto scalare moltiplichiamo ogni elemento della matrice per quel coefficiente.\n0.2.4 Prodotto matriciale Questo prodotto fra matrici Ã¨ piÃ¹ complessa rispetto alla somma e il prodotto. (Ãˆ utile perchÃ© le matrici rappresentano una trasformazione nello spazio, questo prodotto rappresenta la composizione fra le funzioni che rappresentano).\nTratto da wikipedia\nQuindi vogliamo avere che il numero delle colonne del primo sia uguale al numero delle righe del secondo. Questo Ã¨ soddisfatta questa condizione possiamo sempre fare la moltiplicazione. Lo facciamo cosÃ¬, consideriamo il risultato fra il prodotto del vettore riga i con il vettore colonna j, questo Ã¨ un prodotto scalare, che mi restituirÃ  un unico numero, questo Ã¨ il valore di $c_{ij}$\nProprietÃ :\nSi puÃ² dimostrare che il prodotto fra matrici gode della proprietÃ \nAssociativa Distributiva Non Ã¨ commutativa!\n0.2.5 Transposizione Si puÃ² definire una matrice trasposta, bisogna scambiare gli indici associati. Es:\n$(A^T)_{ij} = (A)_{ji}$ con i, j gli indici della matrice\n0.3 Matrici a scala Matrice a scala: Si ha quando considerando il primo elemento non nullo partendo da sinistra, sotto di questo sta uno 0, e eementi a sinistra di questo sono nulli ( o niente), partendo a contare dall\u0026rsquo;alto.\n0.3.1 Matrice associata a un sistema Si puÃ² associare una matrice a ogni sistema lineare, come in figura.\nDal libro\nNotare il significato di matrice completa o incompleta presente nella slides\nCostruendo la matrice associata completa, dobbiamo distinguere fra la matrice delle incognite, dei coefficienti e dei termini noti\n0.3.2 Pivot e RR Pivot: per ogni riga, il primo valore da sinistra per cui non Ã¨ nullo, Ã¨ il valore di pivot\nRango righe: il rango righe di una matrice a scala Ã¨ il numero di pivot totale, si indica spesso con $rr_a()$ questo determina anche una dimensione dello spazio vettoriale o simili, li vedi in Spazi vettoriali\n0.3.3 Risolvere una matrice a scala Quando ho una matrice a scala diventa molto semplice risolvere il sistema per sostituzione.\nRiesco subito a determinare se la matrice ha soluzione finita, infinita e simili. (Ã¨ una cosa pratica quindi non ti metto appunti qui).\nPer avere in generale un feeling generale su questo:\n$rr(A) = rr(A|b)$ una sola soluzione $rr(A) \u003c rr(A|b)$ impossibile $rr(A) \u003e rr(A|b)$ infinite soluzioni con certe variabili libere 0.3.4 Operazioni elementari (3) Possiamo agire sul sistema (e quindi anche sulla matrice associata al sistema) con certe operazioni che mi cambiano la matrice ma non cambiano la soluzione del sistema\nScambio posizione riga di due equazioni Moltiplicazione per un numero reale diverso da 0 (deriva dalle proprietÃ  dell\u0026rsquo;uguaglianza descritto in precedenza) Sommare (o sottrarre) una riga all\u0026rsquo;altra. (quindi unendola alla 2 posso farlo con una riga scalata) 0.3.5 Trasformazione in matrice a scala Data una matrice normale possiamo sempre trasformalo in matrice a scala\nUna volta ottenuta questa matrice possiamo andare ad analizzarla con il rango righe come sopra\n0.3.6 Sistema omogeneo Un sistema di equazioni si dice omogeneo quando i termini noti sono tutti 0.\nQuesto sistema ha sempre almeno una soluzione la soluzione banale tutti 0.\n0.3.6 Sistema omogeneo Un sistema di equazioni si dice omogeneo quando i termini noti sono tutti 0.\nQuesto sistema ha sempre almeno una soluzione la soluzione banale tutti 0.\n","permalink":"https://flecart.github.io/notes/introduzione-algebra/","summary":"Ripasso Prox: 36 Ripasso: June 1, 2022 Ultima modifica: October 19, 2022 5:05 PM Primo Abbozzo: December 12, 2021 11:58 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso significato di compatibilitÃ  Il vettore dei termini noti, non ti ricordavi la parola termini noti ðŸ˜€ 0 Introduzione Tutta sta parte si fa in modo formale in Sistemi Lineari e determinanti, quindi potresti saltarla totalmente\n0.1 Equazioni lineari L\u0026rsquo;obiettivo dell\u0026rsquo;algebra lineare Ã¨ risolvere n equazioni con n sconosciuti di primo grado.","title":"Introduzione algebra"},{"content":"Ripasso Prox: 5 Ripasso: May 17, 2023 Ultima modifica: May 12, 2023 12:21 PM Primo Abbozzo: May 3, 2023 1:48 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Mac Wifi Introduzione Ricordiamo che vogliamo cercare di arbitrare lâ€™accesso al canale fisico sottostante. In questo momento andiamo ad assumere di avere giÃ  tutto lâ€™impianto di trasmissione fisica che abbiamo in Tecnologia Wireless, Modulazione wireless Fisica del Wireless.\nObiettivi: ðŸŸ¨â€” Arbitraggio del singolo canale fisico (la tesi di dottorato del prof era su collision avoidance di wifi). Sia in tempo Sia in spazio (come gestire il segnale mandato nello stesso spazio) Utilizzo minimo di energia Quality of service Adaptive behaviour (come il 6G che vuole andare ad utilizzare AI per fare predizione). Evitare segnale spaghetti o jammed Collisioni fanno sprecare energia ad entrambi (sia ricevente sia sender) bisogna trovare un metodo per fare risoluzione (controllare il sender riguardo la trasmissione, in quanto non sono in grado di trasmettere e ascoltare in modo contemporaneo) Questo si lega alla parte di arbitraggio del canale Ricordiamo che ethernet provava ad ascoltare il segnale e provare a trasmettere, si puÃ² utilizzare la stessa cosa anche qui? No, ethernet permetteva di ascolatare il segnale nel momento di generazione, mentre wifi non puÃ², perchÃ© semplicemente il segnale prodotto localmente Ã¨ molto piÃ¹ grande. Inoltre wifi ha anche bisogno di fare multiplexing sullo spazio non solo nel tempo come per lâ€™ethernet.\nAnticollisione primo tentativo (esempio nf) Allora, in questa parte continuiamo ad analizzare un protocollo che tenti di evitare la collisione, si puÃ² utilizzare un sistema simile ad ethernet?\nRisposta negativa: non evita le collisioni Slide fenomeno\nNonostante i senders non sentano niente, c\u0026rsquo;Ã¨ interferenza, credo si chiami anche problema del terminale nascosto, perchÃ© non senti lâ€™interferenza (asimmetria di informazioni).\nNon arbitra niente alla fineâ€¦ Classificazione accesso multiplo MACWIFI (2+) (!) ðŸŸ©â€” Slide protocolli\nSenza contesa, ossia si cerca di evitare la contesa della rete wifi Centralizzati statici, con un coordinatore statico che dica quando puoi comunicare (prenotazioni registrate da un coordinatore) â†’ garanzia del servizio Costo coordinatore (centralizzato, quindi se cade cade tutto, facile da attaccare) Costo allocazione statica delle risorse. token-based chi vuole comunicare tiene solamente il token (solo che il rischio Ã¨ che si perda il token per una interferenza o simili). Content, provare a prendersi il segnale, o provare finchÃ© non ci si riesce. Probabilistico Ã¨ quello piÃ¹ sicuro dal punto di vista della sicurezza, e ha allocazione dinamica di servizi (provare a comunicare a tempi random, probabilisticamente parlando provandoci cosÃ¬ prima o poi si comunicherÃ ). Solo che ha il problema delle collissioni ,quindi sarebbe molto buono questo metodo di allocazioen dinamica con il server centrale (0 collisioni e 0tempi vuoti). Solo che il coordinatore ha un costo. â†’ reliability della comunicazione. Deterministico (mi sono distratto a configurare alacritty e non ho capito). Abbiamo un accesso probabilistico in cui si prova a comunciare nel vuoto (nel senso che non si puÃ² spegnere questa rete, nel caso della presenza di un accesso centralizzato allora si utilizza quella. (ma nessuno paga))\nAloha protocol Funzionamento in breve ðŸŸ© Ãˆ stato uno dei primi protocolli radio presenti. Stiamo parlando di 1970, Abramson1970 era alle Hawaii e aveva solamente dispositivi radio a disposizione, sono le prime sperimentazioni.\nSlide aloha protocol\nIl round trip time veniva calcolato, se non riceve lâ€™ack aspetta un tempo un pÃ² random. (il seme sarÃ  diverso, tipo lâ€™id della scheda di rete, il tempo di backoff che coincida Ã¨ abbastanza basso)\nAnalisi dominio di collisione ðŸŸ© Ci vogliamo chiedere quando Ã¨ il time frame in cui puÃ² avvenire una collisione?\nSiano due comunicanti, che devono entrambi trasmettere, se uno trasmette, quando non potrebbe trasmettere l Ã¡ltro per evitare la connessioen? Ci interessa solamente il tempo.\nLa risposta Ã¨ semplice, vogliamo solo che sia una dimensione di frame prima e una dimensione di frame dopo: tempo/slot di collisione Ã¨ due volte.\nSlide intuizione dominio di collisione\nCon questa osservazione, possiamo cambiare leggermente l\u0026rsquo;algoritmo di aloha al fine di risolvere, o meglio alleviare, il problema della collisione:\nSlotted aloha ðŸŸ© Lo slotted aloha permette solamente la trasmissione in certi slot di tempo, questo aiuta ad alleviare il problema della collisione:\nHa senso che la dimensione dello slot Ã¨ dimensione massima del frame con anche trasmission delay vogliamo andare a contare anche il delay della trasmissione perchÃ© altrimenti due frames possono comunque influenzarsi fra di loro durante la trasmissione.\nSlide slotted aloha\nQuindi ora il tempo di vulnerabilitÃ  Ã¨ ridotto a slot + propagation, invece che due slots (anche se solitamente pensavo che il tempo di propagazione Ã¨ maggiore? Credo dipendaâ€¦).\nCSMA Carrier sense multiple access\nIntroduzione all\u0026rsquo;algoritmo ðŸŸ© Slide CSMA\nIn questo caso il FVT (frame vulnerability time) Ã¨ due volte il propagation, perchÃ© se sono dentro a questo intervallo allora non sento il segnale dell\u0026rsquo;altro, che non Ã¨ ancora arrivato. Questo valore solitamente Ã¨ molto piÃ¹ piccolo rispetto al frame size.\nSlotted CSMA ðŸŸ© Alla fine molto simile questa idea allo slotted aloha, tutti possono trasmettere soltanto in certi slots di times\nSlotted csma\nThroughput comparison ðŸŸ© Slide thorughput\nVediamoc he il throughput cambia molto seguendo i protocolli (e va giÃ¹ perchÃ© ci sono troppe collisioni se provo a trasmettere troppo.\nMi serve sapere il numero di stazioni trasmittenti, una cosa che non conosco generalmente.\nMACA hidden and exposed terminals ðŸŸ©â€” Vogliamo cercare di limitare le trasmittenti a comunicare bene con un ricevitore (sto ragionando sull esempio di ACBD in mezzo) cioÃ¨ in un caso di hidden terminal in cui due senders non si sentono fra di loro, ma il loro segnale potrebbe interferire in un certo punto.\nUn problema opposto Ã¨ il exposed terminal quando il sender Ã¨ condiviso da piÃ¹ host, un host che vorrebbe comunicare, a un host diverso, non puÃ² comunicare perchÃ© sente questo.\nRTS and CTS (credo = MACA) ðŸŸ¨++ Slide RTS and CTS\nUn altro problema di hidden terminal oltre alla trasmissione su un terminale comune Ã¨ il fatto che se CB provano a comunicare a persone differenti (rispettivamente ad A e D, B non puÃ² perchÃ© sente ricevere).\nUna soluzione semplice Ã¨ semplicemente chiedere al canale ricevente se ci sono interferenze o meno. (un pacchetto breve che si chaiama RTS (request to send).) questo Ã¨ un piccolo pacchetto, potrebbe interferire, si spera che faccia molti pochi interferenze.\nIl ricevitore risponde con un CTS (clear to send) Se il cts Ã¨ ricevuto allora comincia a rispondere.\nâ†’ Non ho carrier sensing qui.\nRTS and CTS drawback Non abbiamo garanzia di comunicazione senza interferenze, questa garanzia c\u0026rsquo;Ã¨ solamente quando il range di comunicazione sono uguali fra di loro, un esempio in cui non funziona Ã¨ lâ€™esempio qui sotto in cui esiste una rete grande ch epossa andare a fare interferenza con tutte.\nSlide drawback\nMACAW Voglio ritardare il RTS in un tempo casuale in modo che non sovrappongano fra di loro. C\u0026rsquo;Ã¨ carrier sensing **per gli acks, posso spedire solo quando mando RTS cosÃ¬ posso ricevere ack in silenzio. Gli altri quando sentono dovrebbero restare in silenzio.\nRTS Carrier sensing (anche questa credo sia la cosa nuova, il sistema RTS/CTS Ã¨ lo stesso di MACA) backoff (questa Ã¨ lâ€™unica cosa nuov acredo). Lâ€™unico che ha preso la RTS sarÃ  lâ€™unico a comunicare, gli altri stanno in silenzion perchÃ© sentono il canale occupato.\nSi puÃ² settare il RTS threshhol superiore alla soglia per dire che non verrÃ  mai utilizzato.\nEsempio MACAW\nChe Ã¨ molto simile a un coordinator function with backoff, solo che questo Ã¨ senza infrastruttura, mentre nell\u0026rsquo;altro credo ci sia.\nAd hoc networks (non chiede) Ci sono delle cose nuove che sono delle veicole infrastructures ossia in realtÃ  non esisterebbe una infrastruttura per questa connessione, ma passa da veicolo a veicolo quindi Ã¨ una comunicazione locale. fino a un certo punto in cui alla fine si comunica con una infrastruttura. Come se le auto stesse fossero diventati dei sensori del traffico (quindi molte auto ferme riescono a dire se c\u0026rsquo;Ã¨ troppo traffico o meno.\nnon sono ancora diffusi questi servizi, ma stanno arrivanto, u n altro metodo Ã¨ fare unitÃ  di ricarica per i veicoli.\nC\u0026rsquo;Ã¨ una trasmissione con CSMA/CA , poi c\u0026rsquo;Ã¨ una fase di contention in cui si potrebbero trasmettere cose e cose di altro tipo. ci otrebbero essere un sacco di rts che vadano a vuoto. Ognuna delle fasi di rts Ã¨ un passaggio indipendente in cui si rischia ancora la collisione.\nMa quando trasmette indietro potrei avere delle (la collisione :\nFast forward intra-stream in cui il RTS del nodo successivo Ã¨ interpretato dal nodo davanti come se fosse un ACK, questo risolve il problema delle itnerferenze (la fase di contesa non ci sarebbe piÃ¹). (c\u0026rsquo;Ã¨ un campo che rappresenta il tipo di questo segnale, che valga sia come ack sia come rts). Quick exchange inter-stream, se i due nodi intermedi hanno cose da scambiarsi in direzioni diverse, potrebbe essere una buonissima soluzione il fatto di scambiarsi i dati nello stesso stream di dati (dopo l\u0026rsquo;ack di una direzione viene mandato il dato dell\u0026rsquo;altra direzione). Se uno cade allora c\u0026rsquo;Ã¨ tempo vuoto e viene itnerpretato come autorizzazioen alla trasmissione\nCarrier sensing virtuale (non chiede) Carrier sensing virtuale sapere che il canale sia occupato senza andare ad ascoltarlo? Appena sentono un RTS, e se sanno la lunghezza del campo di trasmissione classico (Network Allocation Vector NAV) allora sicuramente nessuno ascolta il canale.\nQuesto fa risparmiare batteria al destinatario. E trasmettere prende un sacco di energia, anche solamente andare ad ascoltare consuma.\nFAMA (non fare) Voglio utilizzare una solgia adattiva oltre la quale comincio ad utilizzare il meccanismo rts/cts. Solitamente questo mi serve quando ho troppe connessioni.\nSe il frame Ã¨ minore di una soglia allor anon ha bisogno di rts/cts, altrimenti ha bisogno.\nAnche questo Ã¨ per reti ad hoc.\nCoordinator functions Ci sono principalemente due meccanismi che vanno a regolare lâ€™accesso al canale\nSlide coordination functions\nCâ€™Ã¨ lâ€™access point che fa un beacon e che rende possibile la coordinazione (cose come il nome della rete e annuncio della sua esistenza Ã¨ il beacon che sempre ogni tanto manda il beacon!).\nUna volta fatto una comunciazione coordinata dÃ  il temop alla DCF. In questo momento lâ€™AP non comunca\nPoint coordination function ðŸŸ© Slide PCF\nQuando esiste un access point che cerchi di evitare le collisioni e governi tutto la comunicazione nel canale.\nQuesta cosa Ã¨ bella perchÃ© funziona anche se muore l\u0026rsquo;access point. Ma alla fine lâ€™unica cosa rimasta Ã¨ la DCF, quindi abbiamo molte piÃ¹ collisioni. (perchÃ© creare firmware era molto costoso).\nInterframe spaces ðŸŸ©- Slide Interframe spaces\nPoint, ditributed and short,, sono una ddurata di tempo in cui carrier sensing deve avere vuoto prima di poter tentare di comunicare.\nSIFS tempo prima di autorizzare la comunicazione qualcuno che sa giÃ  che deve parlare a seconda del contesto (e dovrebbe essere solamente un unico host) Se non parte significa o che sia morto o non ci sia nessuno. E Questo Ã¨ necessario per avere un PIFS PIFS questo Ã¨ il tempo per far parlare l\u0026rsquo;access point. se nemmeno questo c\u0026rsquo;Ã¨ (ad esempio se l\u0026rsquo;access point vuole permettere la comunicazione contesa) allora il tempo aumenta e diventa un difs. (puÃ² essere che trasmettino un polling, con l\u0026rsquo;id di quello che deve andare a trasmettere). DIFS Questo Ã¨ come dire un liberi tutti quindi si rientra al tempo di contesa del WIFI. Distributed coordination function ðŸŸ© Slide DCF\nSpazio RTS-CTS anche adattivo con una soglia\nTempo Ã¨ avoidance con carrier sensing, in un ambiente distribuito. In questo caso tutti provano a comunicare, finchÃ© non ci riescono.\nLo slot non Ã¨ l\u0026rsquo;intero frame come in ALOHA, ma solamente il tempo di propagazione (esempio il tempo necessario per la luce in 100 metri), gli slots sono messi in questo senso. Nello slot successivo sicuramente il tentativo Ã¨ stato ricevuto.\nil backoff Ã¨ basato sul numero di questi slot vuoti che abbiamo ascoltato. E se vado a 0 allora mi metto a comunicare in modo descritto da sopra.\nIl numero degli slot dovrebbe dipendere dal numero di comunicanti questo non Ã¨ a priori definito (e non Ã¨ nemmeno possibile stimarla secondo il prof).\nGestione del backoff ðŸŸ© Standard 802.11 per backoff\nIl backoff Ã¨ via via crescente, si potrebbe dire che sia la come la dimensione della finestra di contesa CW = contention window che Ã¨ diversa rispetto alla congestion window, perÃ² il signfiicato Ã¨ completamente diverso! Congestion trattato in Livello di trasporto serve per mandare tot frammenti allo stesso tempo senza far esplodere il router (il livello Ã¨ diverso!) mentre ora siamo a livello fisico, e si prova a comunicare localmente.\nLa cosa brutta Ã¨ che deve andare a sperimentare contesa per sapere quanta contesa ci sia! Per questo motivo si dice che non sia efficiente: se il canale Ã¨ occupato con questo metodo ci provi lo stesso e quindi vai a disturbare.\nQuando va a 0 allora io faccio proprio la tramissi contione e aspetto ack, se arrivo Ã¨ ok, altrimenti si aumenta timer nel backoff e si rifÃ . Continua finchÃ© non ce la fai.\n","permalink":"https://flecart.github.io/notes/mac-wifi/","summary":"Ripasso Prox: 5 Ripasso: May 17, 2023 Ultima modifica: May 12, 2023 12:21 PM Primo Abbozzo: May 3, 2023 1:48 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Mac Wifi Introduzione Ricordiamo che vogliamo cercare di arbitrare lâ€™accesso al canale fisico sottostante. In questo momento andiamo ad assumere di avere giÃ  tutto lâ€™impianto di trasmissione fisica che abbiamo in Tecnologia Wireless, Modulazione wireless Fisica del Wireless.\nObiettivi: ðŸŸ¨â€” Arbitraggio del singolo canale fisico (la tesi di dottorato del prof era su collision avoidance di wifi).","title":"Mac Wifi"},{"content":"Ripasso Prox: 40 Ripasso: December 24, 2021 Ultima modifica: September 30, 2022 3:18 PM Primo Abbozzo: October 6, 2021 11:03 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Vecchi dubbi Classe di equivalenza Dimostrazione della proprietÃ  fondamentale della coppia ordinata di Kuratowsky Costruzione di R. Definizione di spazio di funzioni 21/11 ho ripassato, prodotto cartesiano, funzioni, spazi, classi equiv, insiemi quoziente, dovrei ancora ripassare la dimostrazione di suriettiva e iniettiva presenti in laboratorio Anche definizione e dimostrazione di Cantor, insiemi infiniti, costruzione di R, Z, N. 3 Relazioni fra insiemi 3.1 Coppia ordinata 3.1.1 Definizione di Kuratowsky Una coppia ordinata Ã¨ definita dall\u0026rsquo;insieme\n$$ \\langle X, Y \\rangle = \\{X, \\{X, Y\\}\\} $$ Ãˆ quindi chiaro che due coppie ordinate sono uguali fra di loro nel caso in cui gli elementi sono uguali ma anche la loro posizione sono uguali\nTeorema caratterizzazione delle coppie\n3.1.2 Definizione di Wiener $$ (X,Y) := \\{\\{\\{X\\}, \\empty\\}, \\{\\{Y\\}\\}\\} $$ 3.1.3 Definizione di Hausdorff $$ (X,Y) := \\{\\{X, 1\\}, \\{X,2\\}\\} $$ 3.1.4 ProprietÃ  fondamentale coppie ordinate Due coppie ordinate si dicono uguali se e solo se il primo elemento dei due sono uguali e la stessa cosa per il secondo\nDimostrazione\nDImostrazione di wiki, difficile\n3.2 Prodotto cartesiano 3.2.1 Definizione del prodotto $$ \\forall A, \\forall B, \\exists C,\\forall Z (Z \\in C \\iff \\exists a, \\exists b(a \\in A \\, \\wedge \\, b \\in B \\, \\wedge \\, Z \\in \\langle a, b\\rangle)) $$ Utilizzando un linguaggio naturale, stiamo prendendo tutti gli elementi da due insiemi e stiamo prendendo una coppia ordinata: prendiamo tutte le coppie ordinate possibili.\nquesto si indica con $A \\times B$\n3.2.2 Relazione e con il Vuoto Una relazione Ã¨ una qualunque sottoinsieme di $A \\times B$\nQuesta cosa si scrive come $a\\mathcal{R}b \\iff \\langle a,b \\rangle \\in \\mathcal{R}$\nTeorema relazioni da e verso insiemi vuoti.\nSe $\\mathcal{R} \\subseteq A \\times \\empty \\text{ or } \\empty \\times A \\text{ allora } \\mathcal{R} = \\empty$ questo si dimostra che il prodotto cartesiano con un insieme vuoto Ã¨ sempre vuoto, quindi l\u0026rsquo;unica relazione esistente Ã¨ il vuoto.\n3.3 Funzione Per ogni elemento di un elemento dominio, si ha solo una unica immagine in un insieme d\u0026rsquo;arrvo immagine, si scrive $X f Y$:\n$$ \\forall X(X \\in A \\implies \\exists! Y, X f Y) $$ L\u0026rsquo;abuso di notazione tipico dei matematici Ã¨ una falsitÃ  perchÃ© sembra che la funzione calcoli Y, inveritÃ  non calcola niente, ma solamente Ã¨ una relazione. Ecco l\u0026rsquo;abuso di notazione.\n3.3.1 Spazio di funzioni $\\forall A, \\forall B, \\exists C, \\forall f (f \\in C \\iff \\text{ f Ã¨ una funzione dal dominio A e codominio B} \\text{ e si ha che C = } B^A)$\n3.3.2 Funzioni da e verso insieme vuoti Se Ã¨ il codominio vuoto, allora non esistono funzioni possibili perchÃ© non esistono relazioni possibili, non ho nessun elemento da collegare agli elementi del dominio.\n$\\empty^A = \\empty$\nSe il dominio Ã¨ vuoto, allora esiste la funzione vuota, che non fa nulla, perchÃ© tanto non ho nessun X appartenente a A da loopare, non faccio niente quindi creo l\u0026rsquo;insieme che non ha nulla.\n$B^\\empty = \\{\\empty\\}$\nSe sia codominio che dominio sono vuoti allora devo prima loopare nel dominio, che Ã¨ vuoto, quindi giÃ  l\u0026rsquo;insieme vuoto ho creato.\n3.4 Relazioni RST 3.4.1 ProprietÃ  delle relazioni Riflessiva se $\\forall X, X\\mathcal{R}X$\nSImmetrica $\\forall X, \\forall Y X\\mathcal{R}Y \\implies Y\\mathcal{R}X$\nTransitiva $\\forall X,Y,Z (X\\mathcal{R}Y \\wedge Y\\mathcal{R}Z\\implies X\\mathcal{R}Z)$\nProprietÃ \nEsempi\n= Vale tutti e tre\n\u0026lt; Transitiva non simmetrica e non riflessiva\nâ‰¤ transitiva e riflessiva ma non simmetrica\nâ‰  Ã¨ simmetrica e bbasta\n3.4.2 Ordinamento stretto Una funzione che sia transitiva e non riflesssiva, per esempio il \u0026lt; o il \u0026gt;\n3.4.3 Ordinamento lasco Una funzione che sia transitiva e riflessiva per esempio â‰¤ o il â‰¥\nIn piÃ¹ si puÃ² dire che sia antisimmetrica, cioÃ¨ che se vale $x\\mathcal{R}y \\wedge y\\mathcal{R}x \\implies x = y$\nUn altro buon esempio Ã¨ la relazione di divisione.\n3.4.4 Equivalenza Se ha tutte e tre le proprietÃ  si puÃ² dire che sia una relazione di equivalenza.\nQuesta relazione Ã¨ utile per confrontare oggetti perchÃ© Ã¨ come dire che sono la stessa cosa due elementi quando soddisfano una relazione di equivalenza.\nDire che sono uguali Ã¨ stato un qualcosa di cui la matematica si Ã¨ interessata storicamente, dire uguale Ã¨ diverso da dire che sono equivalenti.\nEsercizio Difficile\nSoluzione\nMisc\n3.5 Classi $\\equiv\\subseteq A \\times A \\text{ Ã¨ una relazione di equivalenza, allora la classe di equivalenza di } x\\in A \\text{ rispetto a } \\equiv \\text{ Ã¨ definito come }[x]_\\equiv =^{def} \\{ y \\in A | y \\equiv x\\}$\n3.5.1 Relazioni fra classi di equivalenza Fra tutte le classi di equivalenza di ha che ho le due classi sono equivalenti fra di loro, oppure sono diverse (disgiunte) fra di loro.\nAbbozzo di dim\nPreso classe equivalente X, Y,allora per la transivitÃ  Z Ã¨ transitivo sia a Z X sia a Y, e poi si puÃ² utilizzare, usiamo l\u0026rsquo;assioma di estensionalitÃ  per dimostrare che le due classi sono uguali.\nPoi cerco l\u0026rsquo;intersezione, se nell\u0026rsquo;intersezione di due classi di equivalenza trovo un Z, ho che queste due classi sono identitiche, e se sono identiche so che ci sono Z e simili.\n3.5.2 Insieme quoziente L\u0026rsquo;insieme quoziente contiene tutti gli elementi (classi di equivalenza) possibili (disgiunti per la classe di equivalenza).\nÃ¨ definita come, fatto con l\u0026rsquo;assioma di rimpiazzamento (posso creare un insieme se possiedo una funzione)\n$$ U_{/\\equiv} := \\{[x]_\\equiv \\,|\\, x \\in U \\} $$ UtilitÃ \nQuesti insiemi sono utili per costruire ancora, scegliere qualche proprietÃ  a seconda del bisogno.\n3.5.3 Costruzione di $\\Z$ Partendo dall\u0026rsquo;insieme del prodotto cartesiano $\\N \\times \\N$ definiamo ogni coppia $\\langle a, b\\rangle$ come $a - b$. Allora possiamo definire una classe di equivalenza per il risultato di una sottrazione\u0026hellip;\nPreso l\u0026rsquo;insieme quoziente di tutte queste classi di equivalenza si puÃ² creare $\\Z$ e lo possiamo indicare con numeri come al solito.\nQuindi invece di indicare un numero in Zeta come una classe di equivalenza, indico normalmente con + -.\n3.5.4 Costruzione di $\\mathbb{Q}$ Uguale a Z solo che invece della sottrazione creo la somma\nEsistenza funzione bigettiva N â†’ Q\n3.6 CardinalitÃ  di un insieme 3.6.1 Intuizione dalle funzioni Si puÃ² creare una prima intuizione dal concetto di iniettivitÃ , suriettivitÃ  e bigezione di funzioni fra due insiemi sul concetto di cardinalitÃ \nIniettivitÃ \nSe il codominio fosse piÃ¹ piccolo del dominio, per il principio dei cassetti deve esserci una relazione che punta allo stesso elemento nel codominio, per cui la cardinalitÃ  del codominio deve essere piÃ¹ grande\nSuriettivitÃ \nSe il dominio fosse piÃ¹ piccolo del cominio, non avrei abbastanza frecce per raggiungere tutti gli elementi del codominio, quindi sarebbe impossibile una funzione suriettiva.\nBigettivitÃ \nSe per iniettivitÃ  e suriettivitÃ  i due insiemi devono essere uguali per cardinalitÃ \n3.6.2 Definizione di cardinalitÃ  Due elementi hanno la stessa cardinalitÃ  sse esiste una bigezione fra i due, e quindi possono definire una classe di equivalenza indicata\n$U_{/\\equiv}$ e posso poi definire anche una classe quoziente delle relazioni di equivalenza.\n3.6.3 Definizione con insiemi Ãˆ possibile, con un lunghissimo lavoro, costruire questa classe attraverso solamente gli insiemi questa classe, invece di utilizzare le classi di equivalenza.\nIn altre parole si puÃ² dimostrare che Ã¨ abbastanza piccola la classe dei numeri cardinali\nCritica al matematico\nIl matematico indica con lo stesso numero un numero cardinale e il numero naturale, ma per definizione di numero cardinale e numero naturale sono diverse, il primo Ã¨ una classe di quivalenza ddell\u0026rsquo;insieme {1,2,3} (che contiene in sÃ© tutti gli insiemi di 3 elementi, fra qui anche il numero naturale 3, mentre per definizione del numero natuale 3 Ã¨ {0,1,2}\n3.6.4 Abuso di notazione e aleph Si indica la classe di equivalenza per la classe di equivalenza $[x]_{/\\equiv}$ come $|x|$\nIn particolare per indicare la cardinalitÃ  dei numeri naturali Ã¨ $\\aleph_0$\n3.6.5 Insiemi infiniti Fra questi definiamo anche l\u0026rsquo;insieme finito che praticamente Ã¨ definito come la negazione dell\u0026rsquo;insieme finito.\n3.7 Albergo di Hilbert Hilbert Ã¨ stato uno dei matematici piÃ¹ famosi a fine secolo scorso e creÃ² i problemi del millennio per lo sviluppo della matematica attuale.\n3.7.1 Albergo finito e infinito Se Ã¨ finito allora non si puÃ² accomodare in nessun modo.\nMa se invece Ã¨ infinito? Una soluzione potrebbe essere che ogni cliente si muova nella stanza col numero seguente e si potrebbe trovare di nuovo altro spazio.\n3.7.2 Definizione di infinito Infinito Ã¨ quando in bigezione con un suo sottoinsieme proprio, ma non Ã¨ sÃ© stesso. In simboli: $A \\subset B \\wedge \\exists f: B f A$ e f sia bigettiva.\nqui infatti esiste un paradosso, in quanto essendo essendo un sottoinsieme allora si puÃ² dire che sia piÃ¹ piccolo, ma con l\u0026rsquo;intuizione dell\u0026rsquo;infinito possiamo dire che hanno la stessa cardinalitÃ , hanno la stessa grandezza.\n3.7.3 Ordinamento sugli infiniti \u0026lt;, â‰¤ â‰¤ Ordinamento lasco\nEsiste una classe di equivalenza di ordinamento lasco sse dati due insiemi A, B si ha |A| â‰¤ |B| se esiste una iniezione fra |A| o |B|\n\u0026lt; Ordinamento stretto\nÃˆ simile al precedente, ma devo togliere l\u0026rsquo;uguale quindi dico che non esiste una bigezione.\nDiagonalizzazione di Cantor Dimostrazione diagonalizzazione di Cantor Teorema $|T| \u003c | 2^T|$\nDimostrare per assurdo che non esiste una funzione bigettiva da T a $2^T$ e poi dimostrare che esiste una funzione iniettiva da T a $2^T$.\nLa funzione iniettiva Ã¨ semplice perchÃ© basta mappare ogni T al suo singoletto equivalente in $2^T$\nIn seguito dimostriamo per assurdo che non esiste una funzione bigettiva.\nSupponiamo una funzione bigettiva, al fine di creare l\u0026rsquo;assurdo abbiamo bisogno dei tre elementi presentati in Logica meta-linguistica. Quindi meta linguistica, riflessione e negazione.\nDefiniamo quindi un insieme $A = \\{x \\in T| x \\not\\in g(x) \\}$ data la funzione $g(x)$ bigettiva.\n(Possiamo definire x che appartiene all\u0026rsquo;insieme imamgine perchÃ© l\u0026rsquo;insieme di arrivo sono degli insiemi, in quanto Ã¨ l\u0026rsquo;insieme delle parti).\nMa allora data l\u0026rsquo;iniettivitÃ  della funzione $g(y) \\in 2^T$ esiste un $y \\in T$, ma allora $y \\in g(x) \\iff y \\not\\in g(x)$ e quindi porta all\u0026rsquo;assurdo.\nDimostrazione con tabella Questa Ã¨ quella usata in R e Intervalli#InnumerabilitÃ  di R.\nSupponiamo che l\u0026rsquo;intervallo $[0, 1[$ sia numerabile, ossia esiste una funzione $f: \\mathbb{N} \\to [0, 1[$ che sia bigettiva. Scriviamo tutti i numeri possibili in forma binaria\nAvremo una tabella simile: che ci dice che\nNatural Real number 1 0,00001010101\u0026hellip; 2 0,100101011010 E continua all\u0026rsquo;infinito (poi sopra sarebbe bello avere anche uno 0), allora posso creare un nuovo numero che per costruzione non Ã¨ mappato da nessun naturale (flippo i numeri sulla diagonale). Quindi non Ã¨ suriettiva, e la costruzione porta ad un assurdo. 3.8.2 Sintesi Dim Data la dimostrazione abbastanza complicata (per me boh) provo a rilistare i passaggi principali utili per questa dimostrazione.\nUtilizzare l\u0026rsquo;assurdo per dimostrare l\u0026rsquo;inesistenza di una funzione bigettiva Utilizzare la suriettivitÃ  della funzione bigettiva per creare un insieme che possa dare un assurdo. Allora $g(y) = A$ definito con quella proprietÃ  per assurdo, questa deve esistere per suriettivitÃ  Devo creare un y appartenente a $T$ l\u0026rsquo;insieme iniziale perchÃ© cosÃ¬ comincio a creare qualcosa Dico assurdo perchÃ© entrambi i casi, che $y \\in A, y\\not\\in A$ creano assurdo perchÃ© implicano tra di loro. 3.8.3 |T| \u0026lt; |T^T| Questo Ã¨ un corollario della diagonalizzazione di Cantor, che utilizza una semplice disuguaglianza di una funzione caratteristica.\nL\u0026rsquo;unica cosa nuova Ã¨ $\\mathbb{B}^T \\leq |T^T|$ questo Ã¨ vero perchÃ© le funzioni che restituiscono un booleano, sono un sottoinsieme delle funzioni che restituiscono T, quindi iniezione Ã¨ semplice da trovare e si dimostra.\n3.8.4 Funzione caratteristica Data un\u0026rsquo;insieme booleano, prendiamo un insieme che restituisce vero se l\u0026rsquo;elemento appartiene, falso se non lo fa.\n$\\mathbb{B}$ Ã¨ un insieme con due elementi indicati con 1, 0.\n$\\chi_c \\in \\mathbb{B} ^A$, posso dire che esiste una bigezione fra questo e l\u0026rsquo;insieme delle parti di A.\nAAAAAA, ovvio, per ogni sottoinsieme C, esiste una unica funzione che mi dice se questi elementi appartengono o meno ad A!\n3.8.5 ImpossibilitÃ  eguaglianza in matematica Questo teorema ci dice che non si puÃ² creare totalmente una funzione implementata che sia precisa come una funzione matematica.\nData una funzione che va da un insieme grande da un insieme grande, Ã¨ possibile che non possa essere implementata\nCuriositÃ \nPer il matematico, data una qualunque funzione, la probabilitÃ  che sia implementabile, Ã¨ molto vicina a Zero\n3.9 Costruzione di \\R Immaginando un numero reale, si ha che un $n\\in\\R$ in puÃ² rappresentare come una parte intera e una sequenza infinita di numeri dopo (di cui possiamo solo approssimare).\n3.9.1 CardinalitÃ  dei reali superiore di Aleph 0 Per semplicitÃ , prendiamo la rappresentazione in base due di questo numero, allora questo $\\in B^\\N$\n(Questo si puÃ² vedere senza molti problemi, quanto la sequenza Ã¨ infinita, prendo per ogni posizione dopo la virgola arriva a un numero Booleano)\nEs. 0,111100001111\u0026hellip;\nN 0 0123456789\u0026hellip;.\nMa se queste funzioni appartengono a questo spazio di funzioni, si puÃ² finire dicendo che Ã¨ $|B^\\N| \u003e |N|$\n3.9.2 Esempio sulla densitÃ  di R I numeri hanno possibilmente infinite cifre dopo la virgola, ma Ã¨ possibile tenerli solamente per $\\dfrac{1}{10^n}$ con n il numero di cifre dopo la virgola (e ci stanno un sacco di numeri).\nQuesta successione tende chiaramente a 0. Quindi le probabilitÃ  sono quasi nulle.\nEsercizi Sulle classi di equivalenza\nDimostrare che l\u0026rsquo; insieme A appartiene all\u0026rsquo; insieme unione per una qualunque classe di equivalenza in A\nSuriettivita o iniettivita di una funzione\nDimostrare che se f o g sono suriettive o iniettive, allora la funzione composizione fra le due sono anche sse suriettive o iniettive. vita o iniettivita di una funzione\nDimostrare che se f o g sono suriettive o iniettive, allora la funzione composizione fra le due sono anche sse suriettive o iniettive.\n","permalink":"https://flecart.github.io/notes/relazioni-fra-insiemi/","summary":"Ripasso Prox: 40 Ripasso: December 24, 2021 Ultima modifica: September 30, 2022 3:18 PM Primo Abbozzo: October 6, 2021 11:03 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Vecchi dubbi Classe di equivalenza Dimostrazione della proprietÃ  fondamentale della coppia ordinata di Kuratowsky Costruzione di R. Definizione di spazio di funzioni 21/11 ho ripassato, prodotto cartesiano, funzioni, spazi, classi equiv, insiemi quoziente, dovrei ancora ripassare la dimostrazione di suriettiva e iniettiva presenti in laboratorio Anche definizione e dimostrazione di Cantor, insiemi infiniti, costruzione di R, Z, N.","title":"Relazioni fra insiemi"},{"content":"Ripasso Prox: 5 Ultima modifica: May 6, 2023 5:51 PM Primo Abbozzo: March 14, 2023 10:50 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nVariabili aleatorie discrete Con le variabili aleatorie cominciamo ad entrare nel noccio della questione, finalmente possiamo in un certo senso legare lâ€™outcome di un evento, alla probabilitÃ  dellâ€™evento.\nIntroduzione Definizione VA ðŸŸ© Si definisce variabile aleatoria $X$ una funzione da $\\Omega \\to E$, con Omega il nostro spazio campionario, e $E$ qualunque insieme (quando $E = \\mathbb{R}$ si parla di variabile aleatoria reale\nQuindi un esempio classico per il dado, potremmo definire una variabile aleatoria dallo spazio campionario $\\Omega = [1, 2, 3, 4, 5, 6]$ ai reali, tali che $X(1) = 1, X(2) = 2$ etc, in questo senso stiamo facendo una funzione fra abitanti di insiemi diversi, ma resta una funzione.\nSpesso variabili aleatorie rappresentano un qualcosa che dipende dallâ€™esito, questo valore puÃ² essere numerico come in questo caso (noi in questo corso resteremo al numerico), ma non Ã¨ necessario che lo sia.\nvariabili aleatorie piÃ¹ interessanti per esempio il numero di lanci medio per avere 6, obboh, hai molte libertÃ  di creare le funzioni.\nNOTA: solitamente indichiamo il dominio della variabile aleatoria come da uno spazio di probabilitÃ , ossia in cui $P$ sia definita. Questa notazione ci risutlerÃ  comodo quando andiamo a parlare di distribuzione di probabilitÃ  di uno spazio aleatorio.\n(Legge) Distribuzione di probabilitÃ  ðŸŸ© Definiamo una funzione $P_X$ in questo modo:\n$$ P_X(A) = P(\\{\\omega \\in \\Omega: X(w) \\in A\\}), A \\subseteq E $$ Possiamo dimostrare che questa Ã¨ effettivamente una probabilitÃ  su $E$! Basta dimostrare la sigma additivitÃ  e il fatto che $P_X(E) = 1$, l\u0026rsquo;ultimo Ã¨ ovvio, perchÃ© per come Ã¨ definito X, abbiamo che $\\Omega = \\{\\omega \\in \\Omega: X(w) \\in E\\}$\nIl secondo punto Ã¨ leggermente piÃ¹ complicato, ma lascio al lettore.\nInoltre andiamo a definire questo insieme come lâ€™esito associato\n$$ \\text{Esito associato a una variabile aleatoria X:} \\\\ \\{\\omega \\in \\Omega: X(w) \\in A\\} $$ Def: Funzione di ripartizione (CDF) ðŸŸ© ProprietÃ  Fn ripartizione discreta (4) ðŸŸ¨- MonotÃ²na crescente (tal cred lol) Continua a destra $\\lim_{x \\to -\\infty} F_X(x) = 0$ $\\lim_{x \\to +\\infty} F_X(x) = 1$ Dimostrazione delle proprietÃ \nDef: DensitÃ  discreta La funzione di probabilitÃ  di massa o anche densitÃ  discreta ci dice nellâ€™insieme di arrivo quanto sia probabile che si abbia quel valore, possiamo rappresentarlo in questo modo:\n$$ p_X(x) = P(\\{w\\in \\Omega: X(w) = x\\}), x\\in E $$ Variabili aleatorie discrete Si parla di variabili aleatorie discrete quando il sottoinsieme $S_X \\subseteq E$ degli elementi tali per cui $P_X(S_X) \u003e 0$, Ã¨ o finito o numerabile, allora in questi casi se $\\forall y \\in S_X$ definiamo una probabilitÃ , abbiamo una probabilitÃ !\nTeorema di caratterizzazione delle variabili aleatorie discrete Slide del teorema\nQuesto teorema ci dice una cosa molto stupida sulle variabili aleatorie, una cosa che credo abbiamo giÃ  dimostrato in Spazi di probabilita, che in pratica Ã¨ la stessa.\nIn pratica ci sta dicendo che tutte le variabili aleatorie discrete possono essere descritte secondo la probabilitÃ  di massa\nVariabili aleatorie continue Le variabili aleatorie continue ci sono utili quando vogliamo descrivere qualcosa che Ã¨ difficilmente discretizzabile, come per esempio lâ€™emivita di una batteria. Fatto sta che il suo modello ha un sacco di peculiaritÃ  che lo rendono molto diversa rispetto a una variabile aleatoria normale:\nIntroduzione ProprietÃ  di VA continua (2) $\\forall x \\in \\R, f_X(x) = 0$ $\\int_{-\\infty}^\\infty f_X(x)dx = 1$ Si puÃ² poi dimostrare che\n$P(a \\leq x\\leq b) = \\int_a^bf_X(x)dx$ Si noti che non abbiamo piÃ¹ bisogno che $f_X (x) \\leq 1 \\forall x \\in \\R$, basta che l\u0026rsquo;integrale di tutto sia 1\nPer la propreitÃ  1 abbiamo questo fatto:\nla probabilitÃ  che una variabile aleatoria continua X assuma valori in un intervallo non dipende dal fatto che gli estremi dellâ€™intervallo siano inclusi o esclusi,\nNon univocitÃ  della densitÃ  la funzione f_X definita in precedenza sarebbe la funzione di densitÃ  continua della nostra probabilitÃ . Fatto sta che cosÃ¬ definita se cambiamo la nostra funzione in un numero finito oppure infinto numerabile di punti, allora l\u0026rsquo;integrale possiede ancora lo stesso valore, quindi Ã¨ una densitÃ  valida (basta provare a spezzare la somma dell\u0026rsquo;integrale per tutti i punti in cui si Ã¨ cambiato e si puÃ² verificare questo dato).\n","permalink":"https://flecart.github.io/notes/variabili-aleatorie/","summary":"Ripasso Prox: 5 Ultima modifica: May 6, 2023 5:51 PM Primo Abbozzo: March 14, 2023 10:50 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nVariabili aleatorie discrete Con le variabili aleatorie cominciamo ad entrare nel noccio della questione, finalmente possiamo in un certo senso legare lâ€™outcome di un evento, alla probabilitÃ  dellâ€™evento.\nIntroduzione Definizione VA ðŸŸ© Si definisce variabile aleatoria $X$ una funzione da $\\Omega \\to E$, con Omega il nostro spazio campionario, e $E$ qualunque insieme (quando $E = \\mathbb{R}$ si parla di variabile aleatoria reale","title":"Variabili aleatorie"},{"content":"Ripasso Prox: 4 Ripasso: December 23, 2022 Ultima modifica: January 3, 2023 11:54 AM Primo Abbozzo: November 17, 2022 11:22 AM Stato: ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Immagini Introduzioni Origini di sfocatura Slide\nRumore causata da problemi fisici che sono errori di lettura del segnale analogico Questo si indica anche come errore gaussiano bianco e si puÃ² considerare additivo. Rumore causato dalla digitalizzazione, quindi dalla discretizzazione di essa. Slide formalizzazione errori per sfocatura\nPoint spread function Un unico pixel bianco sembra influenzare il suo ambiente nero, come in immagine\nVorremmo utilizzare delle funzioni ce siano in grado di approssimare questa funzione.\nFunzioni solitamente utilizzate per approssimare e risultati\nConvoluzioni Questa cosa lo avevo giÃ  studiato credo per CNN, in AI. La prof lo scrive in modo molto incomprensibile, ma Ã¨ la stessa cosaâ€¦ Che cosa triste..\nSlides\nRicostruzione immagini Ossia cerco di identificare le cause del blur, e da quello provo a tornare indietro\nResto della slide\nDa tenere in mente il fatto che A Ã¨ mal condizionata!. Vogliamo quindi introdurre alcuni metodi di regolarizzazione in modo da far diventare piÃ¹ gestibile questo problema. (quindi vorremmo avere una matrice equivalente che sia piÃ¹ gestibile).\nTODO: vedere perchÃ© minimi quadrati Ã¨ mal condizionato.\nRegolarizzazione Andiamo ad utilizzare un funzionale di regolarizzazione con un parametro che mi indica quanto Ã¨ influenza la funzione finale.\nRegolarizzazione Tiknohov e Morozov Slide riassuntiva\nDi solito come funzione phi di x metto lâ€™identitÃ  e come lambda un valore che scelgo provando tante cose e prendendo alla fine il piÃ¹ grande che mi soddisfa\ne Ã¨ lâ€™errore causato dal blur\nSi puÃ² saltare la regolarizzazione con le altre norme ðŸ’€ perchÃ© alla prof non piace, saddo.\nPeak signal to Noise Ratio Quanto piÃ¹ il valore Ã¨ alto piÃ¹ lâ€™immagine Ã¨ buona, questo Ã¨ un buon parametro per valutare che la funzione di approssimazione sia buona.\n","permalink":"https://flecart.github.io/notes/deblur-di-immagini/","summary":"Ripasso Prox: 4 Ripasso: December 23, 2022 Ultima modifica: January 3, 2023 11:54 AM Primo Abbozzo: November 17, 2022 11:22 AM Stato: ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Immagini Introduzioni Origini di sfocatura Slide\nRumore causata da problemi fisici che sono errori di lettura del segnale analogico Questo si indica anche come errore gaussiano bianco e si puÃ² considerare additivo. Rumore causato dalla digitalizzazione, quindi dalla discretizzazione di essa. Slide formalizzazione errori per sfocatura","title":"Deblur di immagini"},{"content":"Ripasso Prox: 23 Ripasso: December 28, 2022 Ultima modifica: December 27, 2022 5:09 PM Primo Abbozzo: September 23, 2022 9:32 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Misa di dicembre, poâ€™ tolgo perchÃ© Ã¨ poco importante il modulo di introduzione\nIntroduzione (prolly non chiede niente di questo) Lâ€™ottimizzazione combinatoria Ã¨ un altro nome per la ricerca operativa. Ãˆ uno strumento utile a prendere le decisioni migliori, fatto sta che Ã¨ anche molto utile al machine learning e si potrebbe dire che ne sia una base, questa Ã¨ una cosa molto buona.\nRicerca operativa Questo Ã¨ un campo a forte impatto economico perchÃ© prova a minimizzare i costi e massimizzare i profitti.\nSteps ðŸŸ©, ðŸŸ¨ Individuazione del problema (almeno riconoscere che ci sia un problema) Raccoglimento dei dati Modellizzazione del problema Ricerca di una soluzione Analisi dei risultati della soluzione La ricerca operativa si interessa principalmente degli step 3 e 4, nonostante gli steps non sempre vengono eseguiti in maniera lineare, ma câ€™Ã¨ un ciclo di feedback a riguardo.\nModelli (3) ðŸŸ© Un modello Ã¨ una descrizione astratta, e scritta nel linguaggio della matematica, della parte di realtÃ  utile al processo decisionale\nGiochi\nCi sono una serie di agenti in un ambiente con alcune regole precise, i risultati sono visti come causati dall\u0026rsquo;interazione fra gli agenti. (Abbastanza recente, presente nel secolo scorso)\nEquilibrio Strategia sono due concetti molto interessanti per questo tipo di modellizzazione.\nSimulazioni\nSi cerca di capire cosa succede facendo una simulazione, Ã¨ certo che la possibilitÃ  di generare numeri casuali Ã¨ fondamentale in questo passo. Eg metodi monte-carlo\nAnalitici\nQuesti sono i modelli interessanti alla ricerca operativa perchÃ© tratta in modo matematico il modello, cercando il minimo o massimo di una funzione (si vede qui che ci sarebbe biosgno dianalisi, fa strano che non lo abbia messo nei prerequisiti).\nSono fedeli al problema, e devono essere astratti.\nUn problema Un problema non Ã¨ nientâ€™altro che una domanda, espressa in termini generali, ma la cui risposta dipende da un certo numero di parametri e variabili.\nQuindi possiamo affermare che un problema di ricerca operativa venga descritta tramite:\nParametri e variabili che sono in gioco Quanto la soluzione deve soddisfare per essere valida Sembra un pÃ² come se fosse un problema di CSP\nParametri e variabili ðŸŸ© Ãˆ importantissimo fare una distinzione fra parametri e variabili.\nVariabile Ã¨ un valore ignoto che vorremmo trovare, spesso in funzione di parametri. Parametri sono valori, che possono essere conosciuti o meno, che supponiamo essere conosciute. eg. $ax^2 + bx + c=d$ i parametri sono $a,b,c,d$ e la variabile Ã¨ solo $x$, perchÃ© noi vorremmo trovare x in funzione dei parametri.\nIstanza di un problema ðŸŸ© Con la definizione di parametri Ã¨ variabili si fa una distinzione fra una istanza di un problema, oppure il problema in senso generale. Quando i parametri non sono piÃ¹ simbolici, allora Ã¨ una istanza, perchÃ© effettivamente ora possiamo andare a calcolare la soluzione.\nQuindi una sostituzione di tutti i parametri simbolici, con valori reali (probabilmetne ottenuti da osservazione, da dati) si ha una istanza di una soluzione.\nAmmissibilitÃ  delle soluzioni ðŸŸ© Vogliamo cercare ora di definire da un punto di vista matematico cosa sia l\u0026rsquo;insieme delle soluzioni ammissibili.\nOssia, vorremmo trovare gli $x$, le variabili prese in un campo grande, come puÃ² essere $\\R$. Quindi un primo step Ã¨ trovare lâ€™insieme delle soluzioni in funzione dei parametri.\nLe variabili che soddisfano tutti i costraints sono $x \\in \\mathbb{F}_p \\subseteq \\mathbb{G}$., con G un insieme in cui vivono le variabili.\nLe variabili $x \\in \\mathbb{G} - \\mathbb{F}$ sono non ammissibili.\nFunzione obiettivo !! ðŸŸ© Ãˆ una misura di una bontÃ  della soluzione. spesso definita come $c_p : \\mathbb{F}_p \\to \\R$, ossia dalle soluzioni ammissibili ai Reali. Vorremmo cercare di minimizzare o massimizzare la soluzione a questo problema con questa funzione di valutazione o obiettivo. Si puÃ² vedere molto facilmente che il problema di massimo Ã¨ equivalente al problema di minimo invertendo.\nSoluzione ottima Ã¨ il valore di $x \\in \\mathbb{F}_p : x = min \\{c_p(y) : y \\in \\mathbb{y}_p \\}$, definiremo questa x come $Z_p = x$\nValore ottimo Ã¨ $c_p(x) \\in \\mathbb{F}_p$ con $x$ il valore di sopra.\nCatalogazione dei problemi Ottimizzazione, decisione e certificato ðŸŸ© Problema di ottimizzazione\nVogliamo trovare il minimo in qualcosa. Ma questo di solito Ã¨ un problema molto difficile perchÃ© bisogna prima trovare le soluzioni possibili, e poi bisogna anche trovare la migliore fra queste soluzioni possibili\nProblema di decisione\nSi tratta di cercare una soluzione $g: g \\in \\mathbb{F}_p$\nProblema di certificato\nVogliamo cercare di verificare se una soluzione Ã¨ nell\u0026rsquo;insieme che ci piaccia.\nsi tratta di verificare che se data $g$ si ha che $g \\in \\mathbb{F}_p$\nConversione da certificazione e ottimizzazione ðŸŸ¨ Possiamo dire che un problema di certificazione dare dei valori fissati, quelli che ci piacciono sono di valore basso, in questo modo converto subito il valori che ci piacciono in questo caso come soluzioni del problema di ottimizzazione:\n$c_p(x) = 0 : x \\in F_p$, $c_p(x) = 1: x \\not\\in F_p$\nPossiamo anche convertire un problema di ottimizzazione in un problema decisionale, se conosciamo il costo ottimo Ã¨ semplice formalizzarlo, altrimenti si fa $\\leq k$ un valore fisso scelto\nSlide\nTipi di soluzione ai problemi ðŸŸ©- Vuoto\nNon c\u0026rsquo;Ã¨ nessuna soluzione, faremo finta che il costo per implementare la soluzione a questo problema sia infinito\n$Z_p = \\infty$\nIllimitato (inferiormente o superiormente)\nOssia ho troppe soluzioni ammissibili,e possono prendere sempre una soluzione che abbia un costo minore:\nIn questo caso posso dire che $Z_p = -\\infty$ nel caso di un problema di minimizzazione.\nDi solito sono problemi artificiosi, nel mondo reale non succede quasi mai, anch emeno volte del vuoto.\nOttimo Finito, soluzione ottima non finita\nNel caso in cui esiste un costo finito, ma non esiste nel nostro insieme di partenza una soluzione che abbia questo costo\nesempio:\n$\\inf \\{ x \\in \\R : x \u003e 0\\}$, il minimo Ã¨ in 0, ma nessuno ci arriva.\nAd esempio utilizzare delle relazioni lasche evita questo problema.\nOttimo finito e soluzione finita\nCaso che ci piace\nAlgoritmi esatti e euristici ðŸŸ©-, ðŸŸ¨ Ossia descriviamo lâ€™algoritmo esatto e sappiamo che in output sarÃ  la soluzione perfetta, solo che la maggior parte dei casi Ã¨ troppo lento.\nLâ€™algoritmo euristico deve restituire un valore che sia simile al valore ottimo, quindi spesso Ã¨ molto piÃ¹ efficiente. Possiamo in questo caso definire un concetto di approssimazione inferiore e superiore\nLa qualitÃ  dellâ€™algoritmo euristico si puÃ² misurare col concetto di errore, quindi sia $R_p(g)$ lâ€™errore relativo rispetto al valore ottimo per questo problema, allora si puÃ² dire che lâ€™algoritmo Ã¨ $\\varepsilon$-approssimato quando produce soluzioni $g :$ $R_p(g) \\leq \\varepsilon$\nRilassamenti ðŸŸ©, ðŸŸ¨ Vogliamo cercare di applicare le soluzioni del problema per permettere lâ€™esistenza di algoritmi di complessitÃ  inferiori ( e per i problemi di minimo provare ad approssimare al ribasso, in modo tale che la soluzione ottima reale non Ã¨ meno della soluzione trovata\nSlide\nLa nota principale Ã¨ quando la soluzione del problema rilassato Ã¨ esattamente uguale al problema iniziale, in questo caso posso concludere di aver giÃ  trovato la soluzione ottimale per il problema iniziale.\n","permalink":"https://flecart.github.io/notes/introduzione-a-ottimizzazione-combinatoria/","summary":"Ripasso Prox: 23 Ripasso: December 28, 2022 Ultima modifica: December 27, 2022 5:09 PM Primo Abbozzo: September 23, 2022 9:32 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Misa di dicembre, poâ€™ tolgo perchÃ© Ã¨ poco importante il modulo di introduzione\nIntroduzione (prolly non chiede niente di questo) Lâ€™ottimizzazione combinatoria Ã¨ un altro nome per la ricerca operativa. Ãˆ uno strumento utile a prendere le decisioni migliori, fatto sta che Ã¨ anche molto utile al machine learning e si potrebbe dire che ne sia una base, questa Ã¨ una cosa molto buona.","title":"Introduzione a ottimizzazione Combinatoria"},{"content":"SocialitÃ  dello sviluppo del software (3) ðŸŸ¨- Si assume che\nÃˆ difficile assegnarsi i compiti, bisogni di utenti, tempi di consegna (+ persone difficile) Ãˆ facile scrivere software (almeno software classico, e non computazione scientifica) La gente sia brava tecnicamente che socialmente Ã¨ una cosa rara VS Waterfall (3) ðŸŸ¨++ Pianificare tutto come viene descritto nel modello del waterfall non Ã¨ possibile. Per i seguenti motivi\nNon Ã¨ chiaro cosa vuole l\u0026rsquo;utente finale (quindi sarebbe meglio avere feedback continuo). Non si sa giÃ  dall\u0026rsquo;inizio cosa Ã¨ che interessa all\u0026rsquo;utente, per questo motivo si consegna il prodotto passo passo per feedback continuo dato che i requisiti cambiano nel tempo. Giustificazione agile alto livello ðŸŸ© Vorremo una metodologia che permetta una iterazione ossia un cambio continuo specifiche in funzione di un utente, vogliamo fare le cose a seconda di quanto vuole l\u0026rsquo;utente.\nMetodologia agile La metodologia AGILE Ã¨ nata basandosi sulla giapponese Toyota system.\nEtica (!!!) (4) ðŸŸ¨++ Creati verso l\u0026rsquo;anno 2000 https://agilemanifesto.org/iso/it/manifesto.html\nIndividui e interazioni piÃ¹ che a processi e strumenti\nSoftware che funziona piÃ¹ che a documentazione completa\nCollaborazione col cliente piÃ¹ che a negoziazione contrattuale\nReagire al cambiamento piÃ¹ che a seguire un piano\nUmani :)\nDal punto di vista della burocrazia, dovrebbe essere sempre ben documentato il software.\nSoftware Ã¨ difficile da tutelare perchÃ© non Ã¨ tangibile come cosa.\nLa possibilitÃ  di negoziare tutto, invece che seguire un piano di tre anni diciamo.\nPrincipi (12) ðŸŸ¨ Proviamo a cercare di commentare questi principi uno per uno\nÃˆ la regola per user-centered philosophy. il fatto che il gruppo deve essere coeso al fine di fare un buon lavoro. La capacitÃ  di adattamento. Il fatto che deve funzionare perchÃ© alla fine questo serve all\u0026rsquo;utente finale. Si ribadisce il punto 4 perchÃ© quello che deve essere misurato Ã¨ il funzionamento del codice. Ribadisce l\u0026rsquo;importanza del team, il fatto che devono essere motivati. Regole imposte dall\u0026rsquo;alto sono il male, il team si dovrebbe organizzare da solo riguardo architetture e requisiti. (non sempre avere uno che fa tutto Ã¨ di aiuto). Faccia a faccia Ã¨ meglio rispetto ad online. Sostenibile nel senso di investimento di risorse, senza sprecare risorse e che siano sufficienti per fare quello che devi fare. Lo interpreto come fare cose che dovrebbero essere modulari e facilmente estendibili. Semplice Ã¨ piÃ¹ facile da leggere e capire. La capacitÃ  di cambiare e adattarsi a seconda di come si evolve la situazione. (scrum master proverÃ  a far capire cosa c\u0026rsquo;Ã¨ da fare capire diciamo). Extreme programming The XP life-cicle (4) ðŸŸ© Questa Ã¨ stata una delle prime forme di sviluppo iterativo che sono esistite, si puÃ² dire che Ã¨ un precursore di Scrum Method.\nIn contrario rispetto: se funziona quanto basta, Defines features, che sono le cose che vorrebbe Poi il developer stima il costo per l\u0026rsquo;implementazione, si deve alla fine dare un prezzo al software. Customer sceglie fra quelle che puÃ² Poi si costruisce Valori XP (4) ðŸŸ¨++ semplicitÃ  (vedi 11 #Principi (12) ðŸŸ¨) comunicazione (ossia collaborazione internamente) feedback (comunicazione con l\u0026rsquo;utente) coraggio nel modificare comportamento non funzionato in passato, quindi sempre relazionato sulla capacitÃ  di cambiamento Modificare e buttare parte del codice. Che si traducono in modo effettivo in:\nTutti devono capire specifiche e cose riguardo il codice. Usato per gruppi di piccola grandezza Ci deve essere un rappresentante Other practices Minimum Viable Product ðŸŸ© L\u0026rsquo;idea Ã¨ non costruire alla fine un qualcosa di funzionante, ma partire con giÃ  con qualcosa di funzionante e reiterare, migliorando alcuni pezzi Quando si avrÃ  un MVP, allora si potrebbe anche fare un test di accettazione, ossia mostrare quanto fatto al cliente e ricevere un primo feedback.\nUser stories Definition of stories ðŸŸ© Vengono descritte ciÃ² che gli utenti possono o non possono fare utilizzando le user stories diciamo. Secondo il prof. Missiroli queste user stories devono anche avere un input e un output. (che non Ã¨ sensato perÃ².). Poi devono essere stimate e prioritizzate\nPrioritÃ  e story points ðŸŸ© Queste storie solitamente sono caratterizzate da un ordine di prioritÃ  che descrive ciÃ² che deve essere fatto e ciÃ² che non dovrebbe diciamo. Sono utili perchÃ© aiutano a definire un ordine in cui andare ad affrontare le varie task, definito dal singolo cliente. Gli sviluppatori fanno poi una stima delle risorse utilizzate chiamate story points per cercare di dare una stima del costo in sforzo per sviluppare ciÃ². Il processo di scelta delle task che dovranno essere fatte si chiama planning game, ed Ã¨ fatta all\u0026rsquo;inizio di ogni iterazione.\nFormato preferito (3) ðŸŸ©- Questo Ã¨ il formato preferito per andare a descrivere delle user stories (con l\u0026rsquo;aspetto della motivazione in piÃ¹ per aiutare il programmatore a capire meglio cosa deve andare a fare).\nTipo di utente Obiettivo Motivazione (non funzionale per il codice, ma buono per immedesimarsi in quello che dovremo fare). Questo Ã¨ importante, ci aiuta a capire bene in che modo sia l\u0026rsquo;importante per il cliente, cioÃ¨ quello che dovrÃ  essere implementato.\nCarpaccio di elefante Secondo Missoroli Ã¨ meglio che le storie siano verticali ossia che spaziano praticamente ogni campo (un po\u0026rsquo; di tutto per l\u0026rsquo;appunto, ma che allo stesso tempo siano molto specifiche), per me non ha molto senso perchÃ© sono due cose che vanno uno contro l\u0026rsquo;altro, non vogliamo che US tocchi tutto. e hanno\nstima prioritÃ  Condizioni di accettazione (test) oltre alle singole motivazioni Ma secondo me non ci ha capito niente\u0026hellip;\nMoscow Method (4) ðŸŸ©\u0026ndash; Questo Ã¨ un metodo utilizzato per scegliere quali user stories andare ad implementare.\nMust: funzioni che DEBBONO esserci nel prodotto Should: funzioni che DOVREBBERO esserci Could: funzioni che POTREBBERO esserci Wont: funzioni che NON INSERIREMO nella versione attuale https://www.agilebusiness.org/page/ProjectFramework_10_MoSCoWPrioritisation\nBacklog ðŸŸ© Ãˆ l\u0026rsquo;insieme dei task (ossia delle #User stories ðŸŸ¨) che devono essere fatte, e hanno delle prioritÃ , che ad ogni iterazione possono cambiare l\u0026rsquo;ordine.\nQuesta parte viene solitamente divisa in due perchÃ© una Ã¨ nel backlog, l\u0026rsquo;altro quello che si vuole implementare durante lo sprint.\nEpiche ðŸŸ© Saranno alla fine sempre delle user-stories, ma dato che sono molto grandi solitamente sono divisi in task piÃ¹ semplici.\nTask ðŸŸ© User stories sono richieste dall\u0026rsquo;utente, mentre le task sono dei pezzi utili per la production, qualcosa che Ã¨ lecito per lo sviluppatore, ma non ovvio per il cliente.\nFramework Invest The INVEST framework is a set of criteria used to assess the quality of user stories in Agile development. It was introduced by Bill Wake as a reminder of the characteristics that good user stories should possess. The INVEST acronym stands for:\nIndependent: Each user story should be independent, meaning that it can be developed, tested, and delivered without relying on other stories. This helps in prioritizing and sequencing stories based on business value. Negotiable: User stories should not be overly detailed or rigid. They should allow for negotiation between the development team and the product owner, fostering collaboration and adaptation as the project progresses. Valuable: Each user story should deliver value to the end user or customer. It\u0026rsquo;s important that the work being done is meaningful and contributes to the overall goals of the project. Estimable: The team should be able to estimate the effort required to implement a user story. This helps in planning and prioritizing work effectively. If a story is too vague or complex to estimate, it may need to be broken down into smaller, more manageable pieces. Small: User stories should be small enough to be completed within a single iteration or sprint. This helps in maintaining a steady and predictable pace of development, and it allows for frequent releases of working software. Testable: There should be clear criteria for determining when a user story is complete. This ensures that the development team and stakeholders have a shared understanding of what needs to be done and can confirm that the story meets the specified requirements. By applying the INVEST criteria, Agile teams aim to create user stories that are well-defined, manageable, and focused on delivering value to the customer. This, in turn, contributes to the overall success of the Agile development process.\nCasi d\u0026rsquo;uso Descrizione casi d\u0026rsquo;uso ðŸŸ© I casi d\u0026rsquo;uso sono un metodo per descrivere i requirements vedi Requisiti e backlog del software, tali per cui abbiano il massimo valore possibile. Sono un modo diverso rispetto alle user stories descritte in Modelli AGILE per fare questo. Definisce un scenario dettagliato su esattamente cosa vuole del prodotto, il contesto in questo caso Ã¨ molto importante.\nDa quanto mi sembra di aver capito Ã¨ proprio una descrizione passo passo per ogni cosa che vuole fare l\u0026rsquo;utente.\nSolitamente questo viene rappresentato con una specie di UML, come descritto in Unified Modeling Language.\nNOTA: non c\u0026rsquo;Ã¨ nessun concetto di tempo all\u0026rsquo;interno di questo diagramma, a differenza di sequence e collaboration diagrams.\nI casi d\u0026rsquo;uso sono piÃ¹ utili a descrivere il contesto in cui il software lavora, e per comprendere in che modo puÃ² aiutare i clienti con il sistema software.\nL\u0026rsquo;attore ðŸŸ© Sono enti, umani o macchine, che agiscono su un sistema e da questo ottengono valore (servizio, calcolo o simili). Solitamente questi sono distinti in business e tecnici, i primi sono direttamente per clienti, i secondi sono operazionali, per far funzionare bene tutto, sono piÃ¹ interne come cose.\nEstensioni e inclusioni di casi d\u0026rsquo;uso Sono quando alcuni utilizzi devono avere delle funzionalitÃ  necessarie in questo caso includes, oppure funzionalitÃ  che sono estese da qualcosaltro, l\u0026rsquo;unica cosa che cambia Ã¨ il verso da cui parte la freccia.\nTest driven development Filosofia TDD ðŸŸ© Solitamente il test per una funzione viene scritta dopo che il codice Ã¨ giÃ  stato scritto. Questo porta a scrivere codice che spesso non Ã¨ testabile Un approccio alternativo Ã¨ partire direttamente dalle specifiche ed andare ad implementare del test prima del codice in pratica il codice ci saranno solamente backbones diciamo. Test di accettazione ðŸŸ© Sono dei test (quindi sempre nella verifica che il software soddisfi i requisiti o meno, non automatici, che vengono fatti insieme al cliente, in modo tale per cui alla fine la user story venga accettata, questo Ã¨ solitamente chiamato User acceptance testing perchÃ© Ã¨ fatto col cliente.\nRefactoring Migliorare il codice esistente mantenendo la funzionalitÃ  inalterata\nSolitamente Ã¨ una cosa necessaria, perchÃ© il codice evolve continuamente, utile a diminuire il technical debt.\nVantaggi refactoring (2) ðŸŸ© Alcuni esempi possono essere\nrenderlo piÃ¹ leggibile Astrarre dove necessario Buttare codice non necessario Semplificare codice con stessa funzionalitÃ . semplicitÃ  di mantenimento Astrazioni Operazioni di refactoring classiche ðŸŸ© Aggiungere, cancellando o rinominando Spostare classi nel codice e nella catena di derivazione. Su classi, membri, funzioni statiche, data temporaneo. Pair programming Dinamiche driver navigator ðŸŸ© Driver and navigator, uno che scrive il codice e l\u0026rsquo;altro che legge e guarda se ci sono alcuni difetti o modi in cui si puÃ² scrivere il codice (solitamente sono scambiati durante la stessa giornata)\nPlus: proprietÃ  collettiva del codice, dovrebbe essere famigliare a tanti nel progetto (forse tutti) ProprietÃ  collettiva del codice ðŸŸ¨++ Tutti dovrebbero essere in grado di capire e modificare secondo necessitÃ  una parte del codice.\nSe codice Ã¨ complesso non verrÃ  mantenuto o usato.\nAltri argomenti Convenzioni di codifica TODO:\nSostenibilitÃ  dello sviluppo TODO:\nIntegrazione del codice (!) ðŸŸ© Ossia fare small releases, giorno per giorno viene integrata una nuova funzionalitÃ  che viene accettata e validata dal team. Questo poi Ã¨ una cosa normalissima in Scrum Method, in cui si vanno proprio per piccoli rilasci.\nStanding Meeting (3) (!) ðŸŸ© Cosa fatto ieri Cosa si vuole fare oggi Quali sono i problemi maggiori, Ã¨ per portare il team tutti sulla stessa pagina. ","permalink":"https://flecart.github.io/notes/modelli-agile/","summary":"SocialitÃ  dello sviluppo del software (3) ðŸŸ¨- Si assume che\nÃˆ difficile assegnarsi i compiti, bisogni di utenti, tempi di consegna (+ persone difficile) Ãˆ facile scrivere software (almeno software classico, e non computazione scientifica) La gente sia brava tecnicamente che socialmente Ã¨ una cosa rara VS Waterfall (3) ðŸŸ¨++ Pianificare tutto come viene descritto nel modello del waterfall non Ã¨ possibile. Per i seguenti motivi\nNon Ã¨ chiaro cosa vuole l\u0026rsquo;utente finale (quindi sarebbe meglio avere feedback continuo).","title":"Modelli AGILE"},{"content":"Planning Automatico Vogliamo andare a creare un programma che sia in grado di creare un piano per fare una azione, andiamo in questo capitolo gli algoritmi storicamente migliori adatti a risolvere questo problema\nIl problema di pianificazione Andiamo a rappresentare il nostro problema di pianificazione con un linguaggio molto simile alla Logica del Primo ordine.\nÃˆ il PDDL ossia il Planning domain definition language\nPDDL Questo linguaggio Ã¨ definito da\nUna serie di predicati in FOL iniziali Una serie di predicati in FOL di arrivo Una serie di azioni Con una serie di precondizioni E una serie di effetti Il nostro obiettivo sarÃ  principalmente raggiungere un obiettivo finale, utilizzando le azioni per cambiare lo stato attuale\nEsempio\nIn cui si puÃ² notare che una soluzione di questo problema Ã¨ molto semplice:\nAlgoritmi generali Gli algoritmi principali per risolvere la PDDL sono di due tipologie\nForward search Backward search Entrambe dovrebbero avere delle euristiche molto forti per funzionare in un ambiente reale. (nota: essendo questa poi una rappresentazione fattorizzata del mondo, si possono creare delle euristiche indipendenti dal dominio molto forti!).\nSulla soddisfacibilitÃ  booleana\nSi puÃ² anche trasformare il problema di pianificazione in un problema di logica proposizionale da dare in pasto ad un sat solver. Con lo stato attuale dei sat solver questo potrebbe anche essere considerato una soluzione possibile interessante.\nAltri metodi da almeno tenere in mente i nomi\nPlanning graph\nSituation calculus **praticamente sat-plan ma con la FOL\nPartial ordering planning, molto figo perchÃ© ci fanno i rover per andare su marte questo ðŸ˜€, Ã¨ usato perchÃ© puoi vedere in modo molto chiaro il motivo per cui ha scelto questo piano.\nBackward search Vogliamo partire dallâ€™obiettivo, dal nostro goal, ed andare indietro fino a trovare uno stato che sia adatto allo stato iniziale.\nPer fare questo vogliamo cercare azioni che siano rilevanti, ossia le cui precondizioni non siano assurde con quello che avremmo giÃ . Questo aiuta moltro a diminuire il fattore di branching.\nPer maggiori dettagli su come si faccia lâ€™update dello stato andare a vedere sul libro.\nForward search Praticamente andiamo a guardare tutte le soluzioni, Ã¨ la stessa cosa di un Problemi di ricerca ed Ã¨ quindi facilmente attaccabile (se non per la grandezza dello spazio di ricerca) dagli algoritmi lÃ¬ studiati. Il piÃ¹ importante dei quali resta sempre A* con una buona euristica.\n","permalink":"https://flecart.github.io/notes/planning-automatico/","summary":"Planning Automatico Vogliamo andare a creare un programma che sia in grado di creare un piano per fare una azione, andiamo in questo capitolo gli algoritmi storicamente migliori adatti a risolvere questo problema\nIl problema di pianificazione Andiamo a rappresentare il nostro problema di pianificazione con un linguaggio molto simile alla Logica del Primo ordine.\nÃˆ il PDDL ossia il Planning domain definition language\nPDDL Questo linguaggio Ã¨ definito da","title":"Planning automatico"},{"content":"Ripasso Prox: 24 Ripasso: December 23, 2022 Ultima modifica: January 2, 2023 9:50 AM Primo Abbozzo: September 22, 2022 12:03 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nAlgebra lineare numerica Immagini Lab 2 images\nMetodo di gauss Vogliamo cercare un metodo per calcolare soluzioni a sistemi di equazione del genere:\n$Ax = b$, classico. Supponiamo che questo sistema abbia una soluzione.\nIl nostro obiettivo sarebbe scomporre la matrice $A = LU$ come prodotto di due matrici Lower triangular e Upper triangular.\nAlgoritmo per matrici Upper e lower triangular ðŸŸ© Nel caso io abbia una matrice Lower o Upper triangular, i sistemi nella forma $Lx=b$ sono risolvibili con un algoritmo abbastanza banale che qui non riporto (sostituzioni via viaâ€¦)\nIl costo Ã¨ di $O(n^2)$ e non ti scordare il /2 perchÃ© a lei piace\nScomposizione A = LU ðŸŸ© Questo Ã¨ un algoritmo che necessita di una osservazione abbastanza difficile:\nNoto che durante l\u0026rsquo;applicazione dellâ€™algoritmo di gauss, per creare il pivot su una colonna, Ã¨ esattamente come se moltiplicassi per una (matrice identitÃ  + fattori per la colonna di interesse).\nCome in esempio\nSi puÃ² notare inoltre che che lâ€™inverso di L1 Ã¨ in una forma molto bella, esattamente la stessa con numeri invertiti!, inoltre la moltiplicazione fra Ln Ã¨ anchâ€™essa in una forma molto carina!!! Facilita molto il prodotto. In questo modo mi creo una matrice L, in cui Ã¨ molto facile invertire.\ncosto $O(n^3/3)$ per la fattorizzazione LU e poi n2 due volte per risolvere L e U\nScomposizione con permutazione ðŸŸ© Ogni tanto potrebbe capitare che ci sia il bisogno di permutare, altrimenti non ho nessuna soluzione, da notare che questo Ã¨ un passo all\u0026rsquo;interno dellâ€™algoritmo di gauss.\nInoltre scegliere il maggiore dovrebbe aiutare ad eliminare mini-errorini dovuti allâ€™imprecisione della somma floating point.\nAlgoritmo\nForma finale scomposizioni ðŸŸ© Se utilizziamo una sorta di pivoting parziale ossia per ridurre gli errori scegliamo il massimo della colonna (come del resto fa lâ€™algoritmo di sopra) allora non abbiamo bisogno di permutare colonne), se vogliamo invece un pivoting totale allora dobbiamo permutare le colonne e la matrice diventa qualcosa del tipo\n$A = QLUP$ con Q le permutazioni su riga, e P quelle su colonna (quelle su colonna non Ã¨ che ci importa molto, perchÃ© basta moltiplicare per $P^T$, ossia la sua inversa per x e si risolvono problemi di questo genereâ€¦ dato che alla fine $PP^T = I$\nMetodo di Cholesky ðŸŸ© Se prendo una matrice A simmetrica definita positiva (ricorda analisi per questo), allora con questo metodo riesco a riscriverla nella forma $A = LL^T$, e so che la matrice L triangolare inferiore non Ã¨ singolare perchÃ© ho tutti gli autovalori positivi.\nQuesto metodo costa $O(n^3/6)$ leggermente piÃ¹ veloce della fattorizzazione di Gauss.\nUna volta fatto la scomposizione poi va subito\n$Ly = b, L^Tx = y$ e si risolve, sul come funziona l\u0026rsquo;algoritmo, per ora ci importa solamente che Ã¨ piÃ¹ veloce.\nSe non Ã¨ simmetrico o non Ã¨ definita positiva il programma crasha (lel che non sa come funzioni la prof. Ã¨ un sapere, non un conoscere, come diceva Bononi)\nMatrici simmetriche semidefinite o definite positive ðŸŸ© Se prendo un qualunque vettore e vale\n$$ x^TAx \\geq 0 $$ Oppure avendo autovalori sempre positivi sono maggiore di 0, si puÃ² vedere che Ã¨ equivalente.\nGuarda Massimi minimi multi-variabile nella sezione forme quadratiche per questo.\nMetodi iterativi Sono buoni perchÃ© l\u0026rsquo;errore di questi Ã¨ molto piÃ¹ alto, ma spesso molto piÃ¹ veloce, mentre per i metodi diretti Ã¨ esattamente il contrario (errore basso, alta complessitÃ ).\nIn modo molto generale, possiamo definire un metodo iterativo come una funzione $G$ applicata all\u0026rsquo;input stesso: $x_n = G(x_{n - 1})$\nNote introduttive convergenza e iterazione Questa sotto Ã¨ la definizione di convergenza ad $\\alpha$ con ordine $p \\geq 1$\nSpesso la convergenza Ã¨ fissata da una condizione di arresto (che puÃ² essere dipendente anche dal numero di iterazioni. Possiamo definire C = fattore di convergenza quando $p = 1$, perchÃ© piÃ¹ Ã¨ piccolo piÃ¹ converge in fretta. C\u0026rsquo;Ã¨ anche una relazione simile fra i p, piÃ¹ Ã¨ grande, in questo caso, piÃ¹ velocemente converge.\nMetodi iterativi stazionari Idee Generali ðŸŸ© Questi sono nella forma $x _{k +1} = Hx_k + d_k$ Poi scriverlo come una differenza di matrici in particolare vorre $A = M - N$ , dove $M$ sia non singolare (e possibilmente facilmente invertibile). Se ciÃ² Ã¨ possibile allora\n$Ax = b \\implies Mx - Nx = b \\implies x = M^{-1}Nx + M^{-1}b \\implies x = Tx + c$\nUna volta avuto questa matrice $T$ possiamo riutilizzarla per ogni iterazione di successione!\nAvremo che $x_k = Tx_{k - 1} + c$, e si ha che $x* = \\lim x_k$ deve essere che\n$$ x* = Tx* + c $$ E vorremmo che questo metodo converga per ogni input quindi potrei mettere un x_0 a casissimo\nUna cosa non espressa durante la lezione Ã¨ che $N = M - A$ quindi\n$$ M^{-1}N = M^{-1}(M - A) = I - M^{-1}A $$ Che ci permette di scrivere la stessa cosa sente fare utilizzo della matrice $N$ e secondo me Ã¨ piÃ¹ clean. Questa cosa Ã¨ presente nel libro.\nCondizione necessaria e sufficiente di convergenza ðŸŸ© Teorema sulla condizione di convergenza:\nQuesto risultato si puÃ² connettere col raggio spettrale e si puÃ² concludere che converge sse\n$$ \\rho(T) \u003c 1 $$ Metodo di Jacobi ðŸŸ© Sia $D$ la parte diagonale di $A$, allora lâ€™iterazione in questa forma converge e si chiama metodo di jacobi\n$$ x_{k + 1} = (I -D^{-1}A)x_k + D^{-1}b $$ Nota: attento che la prof non ha insegnato in questo modo! Quindi probabilmente se te la chiede diglielo nella forma che le piace,\n$M = D, N = E + F$\nMetodo Gauss-Seidel ðŸŸ© Si ricorda che $A = D - E - F$ in modo molto strano di scriverloâ€¦\nSi fa uso della matrice Lower con anche la diagonale, per il resto Ã¨ esattamente uguale a tutto il resto per i metodi iterativi., quindi\n$$ M = D - E, N = F $$ Condizioni di convergenza per Jacobi e Gauss-Seidel ðŸŸ¥ Per comprendere questa parte Ã¨ importante il concetto di matrice con diagonale dominante. In parole umane deve essere che ogni elemento sulla matrice deve essere maggiore della somma di tutto quanto non stia sulla diagonale maggiore.\nSlide condizioni\nNota questi sono in pratica da imparare a memoria, ma non me ne ricordo!\nGradiente coniugato Questo Ã¨ un metodo di arresto molto misterioso, direi di cacharla ðŸ¤‘.\nMetodi di cui non ha parlato Metodo SOR Metodi di Rilassamento Metodi di Krylov ","permalink":"https://flecart.github.io/notes/algebra-lineare-numerica/","summary":"Ripasso Prox: 24 Ripasso: December 23, 2022 Ultima modifica: January 2, 2023 9:50 AM Primo Abbozzo: September 22, 2022 12:03 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nAlgebra lineare numerica Immagini Lab 2 images\nMetodo di gauss Vogliamo cercare un metodo per calcolare soluzioni a sistemi di equazione del genere:\n$Ax = b$, classico. Supponiamo che questo sistema abbia una soluzione.\nIl nostro obiettivo sarebbe scomporre la matrice $A = LU$ come prodotto di due matrici Lower triangular e Upper triangular.","title":"Algebra lineare numerica"},{"content":"Ripasso Prox: 3 Ripasso: December 15, 2021 Ultima modifica: September 30, 2022 3:20 PM Primo Abbozzo: December 15, 2021 9:18 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nStrutture algebriche Differenza matematica e informatica Una osservazione per quanto riguarda la logica intuizionista Ã¨ che sta a metÃ  fra matematica e informatica perchÃ© la dimostrazione intuizionista possiede in sÃ© un algoritmo e una struttura di dati.\nInfatti di solito l\u0026rsquo;informatico scrive senza fare la dimostrazione dell\u0026rsquo;algoritmo mentre il matematico scrive la dimostrazione senza fare l\u0026rsquo;algoritmo (inoltre puÃ² definire degli enti ed oggetti che non siano rappresentabili come dati in quanto possono essere infiniti.\nUn opinione personale Ã¨ che l\u0026rsquo;informatica Ã¨ piÃ¹ pratica, e limitata in quanto non puÃ² estendersi al ragionamento infinito ma deve essere limitata al calcolo. Questo Ã¨ si molto piÃ¹ utile ma molto meno creativo. Si puÃ² attaccare perÃ² il problema in questi modi!\nOsservazioni generali La matematica utilizza questi metodi da molto tempo prima dell\u0026rsquo;esistenza di una macchina di calcolo.\nI concetti generali di matematica che si sono sviluppati nei secoli sono astrazioni e generalizzazioni. (non esiste ancora una base simile in informatica, e.g. le classi di java hanno proprio degli errori logici al suo interno, anche se non so esattamente quali, ma Coen dice di sÃ¬)\nAstrazione e generalizzazione Tesi di Church-Turing Vedere La macchina di Turing#Tesi di Church-Turing Guarda Questa tesi (non Ã¨ un teorema) definisce il significato di espressivitÃ  di un linguaggio di programmazione.\nIn altre parole deve avere:\nUn modo di ciclare branching (if condition) E numeri Ma quindi i linguaggi di programmazione non cambiano per capacitÃ  di calcolo, bensÃ¬ nella capacitÃ  di astrazione e generalizzazione.\nAssiomi di Peano Vedere https://it.wikipedia.org/wiki/Assiomi_di_Peano Sono i classici assiomi che caratterizzano i numeri naturali\nEsiste $0$, questo Ã¨ facile basta definirlo nel termine (vedi Logica del Primo ordine Esiste la funzione successore I successori si comportano bene ossia $\\forall x \\forall y ((S(x) = S(y)) \\implies x = y)$ Non esiste il predecessore di $0$ ossia $\\neg \\exists x \\mid S(x) = 0$ Esiste sempre il successore se non Ã¨ zero, $\\forall x \\mid \\neg(x = 0) \\to \\exists y: S(y) = x$ Wiki prende questo passo leggermente diverso, ma forse il concetto Ã¨ esattamente lo stesso. Astrazione Vedere note come Astrazione sul controllo per altri generi di astrazione, comunque Ã¨ una cosa molto importante per informatica e scienze.\nAlcune caratteristiche le trascuro perchÃ© sono accessorie (dipendono dall\u0026rsquo;implementazione, dal caso specifico), questo mi permetti cambiare una implementazione trattenendo aspetti degli oggetti che mi interessino. esempio di astrazione Ã¨ il quozientamento perchÃ© in questa operazione trattenevo solamente gli aspetti che mi interessavano buttando via tutto il resto. (il quozientamento non esiste in programmazione per la sua incapacitÃ  di gestire l\u0026rsquo;infinito)\nEsempio implementazione e astrazione di numeri naturali\nL\u0026rsquo;implementazione posso farla in molti modi, qui ne sono rappresentati due.\nMentre il concetto astratto sono le regole che mi definiscono l\u0026rsquo;ente (in questo caso gli assiomi di peano, il fatto che devo avere uno Zero una successione e l\u0026rsquo;insieme generali dei numeri naturali, un elemento appartiene a questo insieme solamente se Ã¨ uguale allo zero oppure Ã¨ un successore di un numero di questo insieme. S deve essere iniettiva. E nessun successore Ã¨ uguale allo zero).\nEsempio implementazione e astrazione liste di interi\nGeneralizzazione Quindi vorrei che una caratteristica in un caso particolare sia vero anche in molti altri casi!\nBenefici di ciÃ² (4) Struttura algebrica L\u0026rsquo;elemento neutro (generalizzazione di essa) Si una generalizzazione esiste ed Ã¨ questa:\nQueste generalizzazioni sono utili nel caso mi creino una teoria utile da studiare dal punto di vista astratto (cosÃ¬ posso scoprire altre proprietÃ ).\nSe questa teoria Ã¨ utile per comprendere concetti piÃ¹ bassi (dal punto di vista di livelli di astrazione) allora posso dire che queste sono teorie informative.\nDefinizione struttura algebrica Il magma Ã¨ il concetto fondamentale per una struttura algebrica come in definizione.\nChiamiamo magma perchÃ© non Ã¨ ancora solidificato, qualcosa di abbastanza astratto. Dopo avere introdotto questi concetti astratti posso studiarle! Posso studiare una cosa che ho creato, mi piace sta scienza, perchÃ© chi ha creato qualcosa non sa a priori bene cosa ha creato.\nProdotto cartesiano in left unital magma Nell\u0026rsquo;esempio C Ã¨ un prodotto cartesiano di R per questo motivo riesco a dirlo da questa generalizzazione!\nMorfismi Il morfismo mi permette di preservare alcune proprietÃ  che perdo in astrazione\u0026rsquo;s trasformazione (un esempio Ã¨ la perdita della struttura di numeri quando lo rappresento con un LUM (Left Unital Magma)\nQuesto concetto Ã¨ importante anche in informatica perchÃ© vuol dire che posso prima applicare la funzione sulla somma di implementazioni oppure applicarli singolarmente.\nIsomorfismo L\u0026rsquo;isomorfismo Ã¨ simile a un morfismo a due parti (in cui vale questa relazione in entrambe le parti) quindi funzione bigettiva in cui anche l\u0026rsquo;inverso sia un morfismo. Questa cosa mi dice che esiste una certa corrispondenza fra strutture algebriche.\nEnunciato ed esempio\n","permalink":"https://flecart.github.io/notes/algebra-logica/","summary":"Ripasso Prox: 3 Ripasso: December 15, 2021 Ultima modifica: September 30, 2022 3:20 PM Primo Abbozzo: December 15, 2021 9:18 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nStrutture algebriche Differenza matematica e informatica Una osservazione per quanto riguarda la logica intuizionista Ã¨ che sta a metÃ  fra matematica e informatica perchÃ© la dimostrazione intuizionista possiede in sÃ© un algoritmo e una struttura di dati.\nInfatti di solito l\u0026rsquo;informatico scrive senza fare la dimostrazione dell\u0026rsquo;algoritmo mentre il matematico scrive la dimostrazione senza fare l\u0026rsquo;algoritmo (inoltre puÃ² definire degli enti ed oggetti che non siano rappresentabili come dati in quanto possono essere infiniti.","title":"Algebra Logica"},{"content":"Ripasso Prox: 20 Ripasso: May 22, 2022 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: May 2, 2022 3:23 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nQuesto argomento Ã¨ stato trattato durante dopo la discussione dei Massimi minimi multi-variabile, perÃ² Ã¨ stato ripreso anche nella forma R to R, quindi credo necessiti di un foglio a parte.\nAffine set Lines Let\u0026rsquo;s take two points in $\\mathbb{R}$ $x_{1}, x_{2}$, if we consider the parametrization $$ x = \\theta x_{1} + (1 - \\theta)x_{2} $$ This is a parametrization of the line\nExample: Def: affine set A combination where the coefficients add up to 1. We can say that this set is unique given two points.\nExample: solution of $\\left\\{ x \\mid Ax = b \\right\\}$ is an affine set (easy to prove). It can be proven that every affine set is a solution of such set of algorithms\nConvex sets It\u0026rsquo;s an affine set, where $0 \\leq \\theta \\leq 1$. Sometimes it\u0026rsquo;s written like $\\left[ x_{1}, x_{2} \\right]$. Sometimes this is called a convex combination of the two values.\nEvery element of the set sees each other clearly, this is the intuitive notion of the convex sets Convex combination Given $x_{1}, x_{2}, \\dots, x_{k}$ then a convex combination is (sometimes called mixture, or weighted average, or expectation)\n$$ x = \\theta_{1}x_{1} + \\dots + \\theta_{n}x_{n} $$ Where $\\theta_{1} + \\dots + \\theta_{n} = 1, \\theta_{i} \\geq 0$\nConvex Hull It\u0026rsquo;s the convex combination of all points in $S$. (so it\u0026rsquo;s defined by the borders usually). It can be viewed as the Smallest convex set that contains a set of points!\nConvex Cone Here we don Â´t have the requirement that it all sums to one. so $x_{1}, x_{2}$, the convex cone is the set of points such that exists $\\theta_{1}, \\theta_{2}$ that $$ x = \\theta_{1}x_{1} + \\theta_{2}x_{2} $$ Proper:\nClosed (contains borders) Has an interior (some point in the middle of the borders). Doesn\u0026rsquo;t contain lines (pointed) It\u0026rsquo;s convex Norm Cone $$ \\left\\{ (x, t) \\mid \\lVert x \\rVert \\leq t \\right\\} $$ Also known as Lorentz cone (probably used for things related to relativity).\nPositive Semidefinite Cone Let $S^{n}$ be the set of symmetric matrices with $n$ elements, of dimension $\\frac{(n + 1)n}{2}$. $S^{n}_{++}$ denotes the positive definite set, with one $+$ indicating semidefinite. Sublevel set $f: \\mathbb{R}^{n} \\to \\mathbb{R}$ such that:\n$$ C_{\\alpha} = \\left\\{ x \\in dom f \\mid f(x) \\leq \\alpha \\right\\} $$ It\u0026rsquo;s a function that it\u0026rsquo;s the best limited to a certain value $\\alpha \\in \\mathbb{R}$\nEpigraph of function $$ epi f = \\left\\{ (x , t) \\in \\mathbb{R}^{n + 1} \\mid x \\in dom f, f(x) \\leq t \\right\\} $$ it\u0026rsquo;s the part of the function that is bigger or equal to the function.\nRelation with convex functions the function $f$ is convex iff $epi f$ is a convex set. So if $f$ creates a convex set above it, we can say it\u0026rsquo;s convex, this is a bridge between functions and geometry.\nConvessitÃ  e ConcavitÃ  Definizione di convessitÃ  Funzione $f : \\mathbb{R}^{n} \\to \\mathbb{R}$ Ã¨ convessa se vale, con $0 \\leq \\theta \\leq 1$ $$ f(\\theta x + (1 - \\theta)y) \\leq \\theta f(x) + (1 - \\theta) f(y) $$ Concavo se $-f$ Ã¨ convesso\nL\u0026rsquo;approccio seguente Ã¨ quella fatta in analisi, ma Ã¨ abbastanza brutta. Ãˆ convessa se la derivata seconda Ã¨ diversa da 0, ma non Ã¨ una buona definizione perchÃ© non Ã¨ direttamente relazionata con la concavitÃ .\nPossiamo definire la funzione secondo le tangenti, potremmo dire che la retta tangente sia sempre minore del grafico, in altro modo Ã¨ una forma di tailor!\n$f: A \\to R$ tale che f sia derivabile, allora se prendo un intervallo $(a,b) \\subseteq A$ posso dire che la funzione Ã¨ convessa in questo intervallo se $\\forall x,k \\in (a,b)$ ottengo che\n$f(x) \\geq f(k) + f'(k)(x -k) = T_1(x)$\nDefinizione vera Non vorremmo avere una definizione che dipenda dall\u0026rsquo;esistenza della derivata, quindi sia f una funzione ben definita, allora Ã¨ convessa sse $\\exists m$ nel dominio per cui valga che $f(x) \\geq f(y) + m(x - y)$\nOppure:\nDefinizione secondo libro (con i segmenti)\nAllora cerchiamo una definizione migliore:\nsia $f : \\mathbb{R}^n \\to \\mathbb{R}$ allora questa funzione si dice convessa sse $\\forall t \\in [0,1]$ si ha che\n$\\forall a,b \\in \\R^n: f(tb + (1 - t)a) \\leq t f(b) + (1-t) f(a)$ se vale con $\u003c$ posso dire che Ã¨ strettamente convessa.\nIntuizione:\nComunque prenda un punto all\u0026rsquo;interno di un intervallo ho che la funzione valutata in questo punto Ã¨ minore della somma della congiungente di questi due punti.\nExamples of convex and concave functions Convex function to a line Consider $g(t) = f(x + tv)$ where the domain of $g$ are the $t$ such that $x + vt$ are in the domain of $f$. Then $f$ is convex iff $g$ is.\nFirst-order condition in $\\mathbb{R}$ Questo Ã¨ un risultato molto simile a quanto ottenuto con le funzioni crescenti e la loro derivata prima, che si puÃ² trovare in Teoremi Base Analisi.\nEnunciato Sia una funzione $f: \\mathbb{R} \\to \\mathbb{R}$, allora $f$ Ã¨ convessa sse la sua derivata prima Ã¨ $\u003e0$.\nLa dimostrazione Ã¨ abbastanza diretta quindi la si omette. (perÃ² la dovresti fare lo stesso perchÃ© Ã¨ importante).\nHintini di dimostrazione $\\implies$ Supponiamo che f sia convessa, allora vale quella formula in definizione, voglio dimostrare che la derivata sia crescente. (scrivo quella definizione due volte e ottengo qualcosa del tipo $0 \\geq$ intervallo * (intervallo funzione, e si puÃ² risolvere senza molti problemi ottenendo il voluto, bisogna fare soprattutto attenzione a come definisci questi indici se vuoi andare a farlo in modo formale. $\\impliedby$ Supponiamo che la derivata sia crescente, allora poi vado ad utilizzare lagrange (due volte, prima con un intervallo x y tale che $x \u003c y$ e poi il contrario) fatto questo utilizzo la crescenza della derivata per concludere Corollario Possiamo utilizzare il risultato sopra per concludere che una funzione Ã¨ convessa sse la derivata seconda Ã¨ maggiore uguale a 0 (si possono utilizzare i teoremi riguardante le relazioni fra derivate e crescenza per questa).\nSegmento in Rn e convessitÃ  di punti Dati due punti in $\\mathbb{R}^n$ si puÃ² individuare il segmento in due punti $x, y$ come l\u0026rsquo;insieme costituito da\n$\\{x + t (y - x) | t \\in [0,1]\\} = [x, y]$\nSI puÃ² verificare che che Ã¨ uguale alla linea che li collega, in particolare Ã¨ una retta parametrica. Avendo questa definizione di segmento, posso andare a definire l\u0026rsquo;insieme convesso per Rn!.\nConvessitÃ  di un insieme di punti\nUn insieme di punti si dice convesso se $\\forall a, b \\in A \\subseteq \\mathbb{R}^n, [a,b] \\subseteq A$ (e la definizione di insieme concavo non esiste, potremmo dire non convesso, ma non che sia concavo).\nAvendo questo si puÃ² dimostrare che l\u0026rsquo;intersezione di semipiani Ã¨ convesso.\nFirst-order condition in $\\mathbb{R}^{n}$ Possiamo allargare la definizione di funzione convessa che abbiamo dato poco fa in modo che ora sia buona anche a funzioni di piÃ¹ variabili.\nf una funzione ben definita, allora Ã¨ convessa sse $\\forall a,b \\in A$ si ha che\n$f(a) \\geq f(b) + \\nabla f(b)^{T}(a - b)$ e per parlare di funzione concava basta rovesciare la disuguaglianza.\nQuesta formula da l\u0026rsquo;idea che la funzione deve essere sempre sopra al piano tangente per ogni punto! Si puÃ² vedere come primo ordine Taylor approx ad un certo punto.\nSecond-order condition in $\\mathbb{R}^{n}$ sia $A \\subseteq \\mathbb{R}^n$ che sia aperto e convesso, sia $f\\in C^2(A) \\to \\mathbb{R}$ allora $f$ Ã¨ convessa su A $\\iff$ $Hf(x) \\geq 0, \\forall x \\in A$.\nNon Ã¨ definito ora il concetto di crescenza per un gradiente, o vettore, quindi vogliamo passare prima sul gradiente. Una funzione Ã¨ convessa sse la matrice hessiana Ã¨ semi-definita positiva. Sia la espansione di taylor come l\u0026rsquo;abbiamo definita prima (con resto secondo Lagrange). PuÃ² essere utile dare un occhiata al teorema di Lagrange al secondo ordine a piÃ¹ dimensioni prima\n$f(w + vt) = f(w) + \\langle \\nabla f(w), v \\rangle t + \\dfrac{1}{2}\\langle Hf(c)v,v\\rangle t^2$\nDimostrazione $\\impliedby$ Dato che $\\dfrac{1}{2}\\langle Hf(c)v,v\\rangle t^2 \\geq 0$ posso conclude la convessitÃ  (ossia la disuguaglianza appare abbastanza in fretta) $\\implies$ Assumiamo ora la convessitÃ , vogliamo dimostrare che la hessiana sia semidefinita positiva. Per l\u0026rsquo;espansione di taylor ho che $f(a + h) = f(a) + \\langle\\nabla f(a), h\\rangle + \\dfrac{1}{2}\\langle H(f(a + \\theta h)) h, h\\rangle$ definendo a, h e theta correttamente. Per la convessitÃ  ho che $f(a + h) \\geq f(a) + \\langle\\nabla f(a), h \\rangle$ e questo vale $\\forall h : a + h \\in A$ Ma allora so che $\\dfrac{1}{2}\\langle H(f(a + \\theta h)) h, h\\rangle \\geq 0$ (perchÃ© altrimenti ci sarebbe un valore in input per cui nonvale la condizione di convessitÃ .\nDevo dimostrare che $v \\in \\mathbb{R}^n \\neq 0 : a + v \\in A$, $\\langle H(f(a)) v, v\\rangle \\geq 0$, scelgo una successione in questo modo: $h_k = 1/k \\cdot v$ che tende a 0 per k che tende a infinito. Definito in questo modo ho che c\u0026rsquo;Ã¨ un theta per cui valga $\\dfrac{1}{2}\\langle H(f(a + \\theta v/k)) v/k, v/k\\rangle \\geq 0 \\iff \\dfrac{1}{2}\\langle H(f(a + \\theta v/k)) v, v\\rangle \\geq 0$ arrivato a questo punto mando k all\u0026rsquo;infintio e utilizzo\nPer continuitÃ  ho che il limite $\\lim_{k \\to \\infty}$ Ã¨ uguale a $\\langle H(f(a)) v, v\\rangle$ la permanenza del segno per concludere il voluto (se ogni elemento della successione Ã¨ maggiore di 0 allora anche il limite a cui sta tendendo Ã¨ maggiore di 0)\nHow to know if a set is convex Definition application Try to prove the #Convex combination theorem. Aka, $\\forall x_{1}, x_{2} \\in C, 0 \\leq \\theta \\leq 1 \\implies \\theta x_{1} + (1 - \\theta)x_{2} \\in C$ But this is the last resort, not advised by prof. Stephen Boyd\nComposition of convex-preserving operations If we can create the $C$ by using this composition we can still have a convex set!\nIntersection is convex The intersection of convex sets is convex\nThis is easily provable.\nExample of interesting case: Consider $p(t) = x_{1}\\cos t + \\dots + x_{n}\\cos nt$ The set $\\left\\{ x \\in \\mathbb{R}^{n} \\mid \\lvert p(t) \\rvert \\leq 1 : t \\in \\left[ 0, \\frac{\\pi}{3} \\right] \\right\\}$ is convex. (It\u0026rsquo;s easy to show that this is an intersection of slabs (see lecture 2, the idea is beautiful, although not formally defined or proved, but it seems intuitive!))\nAffine functions are convex preserving Affine functions preserve convex sets\nIf we apply an affine function (that is just linear function + $b$) aka : $f(x) = Ax + b$. Because the inverse of affine is affine (if it exist), also the inverse of affine functions are inverse. This is easy to prove too.\nPerspective functions are convex preserving $P : \\mathbb{R}^{n + 1} \\to \\mathbb{R}^{n}$ is a perspective function (lower dimensional!)\nFor example a function is $P(x, t) = \\frac{x}{t}$\nImages and inverse images of convex sets under perspective are convex\nNot sure why is it true.\nAffine-fractional functions are convex preserving $$ f(x) = \\frac{Ax + b}{c^{T}x + d} $$ Example of these functions are mapping from 3D in computer geometry to flat camera views. Teoremi importanti Jensen Questo Ã¨ uno dei teoremi legati alla convessitÃ  (concavitÃ  piÃ¹ usati in assoluto). Una applicazione classica Ã¨ per il il valore atteso, analizzato in Variabili aleatorie e simili. La cosa carina Ã¨ che lui non l\u0026rsquo;ha inventato, ma ha detto che tipo 14 tizi stavano usando sta cosa, senza chiamarla per nessun nome, quindi l\u0026rsquo;ha popolarizzato.\nSia $f$ una funzione convessa in un intervallo $[a, b] \\subseteq \\mathbb{R}$, allora vale che $$ f(\\lambda a + (1 - \\lambda)b) \\leq \\lambda f(a) + (1 - \\lambda) f(b) $$ Questa Ã¨ la formulazione semplice, ma si puÃ² estendere per qualunque combinazione convessa dell\u0026rsquo;input (per combinazione convessa di $a_{1}, a_{2}, \\dots, a_{n}$ intendo $a_{1}\\lambda_{1} + \\dots + a_{n}\\lambda_{n}$ dei parametri $\\lambda_{1}, \\lambda_{2}, \\dots, \\lambda_{n}$ tale per cui $\\sum_{i=1}^{n}\\lambda_{i} = 1$).\nNon so bene la dimostrazione, ma l\u0026rsquo;intuizione Ã¨ abbastanza semplice in due variabili, se combini due punti su una retta sopra la funzione, questa sarÃ  maggiore del valore che ricevi combinando gli input, dato che Ã¨ convessa Ã¨ una funzione ad $U$.\nJensen for quasi convex functions $$ f(\\lambda a + (1 - \\lambda)b) \\leq \\max (f(a), f(b)) $$ Convexity preserving operations Pointwise Supremum If we take the max of some convex functions, this max is convex. (It\u0026rsquo;s intuitive if we see the max as the intersection of the epi sets of the functions!) In maths:, given convex functions\nSame with the infimum we can say that if $f(x, y)$ is convex for $(x, y) \\in C$ then $$ g(x) = \\inf_{y \\in C} f(x, y) $$ Is convex, sometimes called partial minimization. (partial maximization is convex too!). This could be used to prove something about shur\u0026rsquo;s complement but I don\u0026rsquo;t remember it.\nComposition of scalar functions Given $f : \\mathbb{R}^{n} \\to \\mathbb{R}$ and $h : \\mathbb{R} \\to \\mathbb{R}$ then the function $f = h(g(x))$ is convex if $g$ and $h$ is and $\\hbar$ is nondecreasing. Also if $g$ is concave and $\\hbar$ is nonincreasing.\nA good way to remember this is proving it for $n=1$ and it\u0026rsquo;s differentiable so you can get it back.\nThis argument is extendable to multiple dimensions, the same conditions hold, just for different indexes.\nGiven $g: \\mathbb{R}^{n} \\to \\mathbb{R}^{k}$ and $h: \\mathbb{R}^{k} \\to \\mathbb{R}$ Then $f(x) = h(g(x)) = h(g_{1}(x), \\dots, g_{k}(x))$ is convex is\n$g_{i}$ is convex, $h$ is convex and $\\hbar$ is nondecreasing in each argument $g_{i}$ is concave, $h$ is convex and $\\hbar$ is nonincreasing in each argument. Easy to prove something like $\\sum -\\log(x_{i})$ is convex. This is a more general test than the others.\nPerspective functions the perspective of $f: \\mathbb{R}^{n} \\to \\mathbb{R}$ is a function $g: \\mathbb{R}^{n} \\times \\mathbb{R} \\to \\mathbb{R}$ $$ g(x, t) = tf(x / t) $$ Where the domain of $g$ is $\\left[ (x , t) \\mid x / t \\in dom f, t \u003e 0 \\right]$\nIf a function $f$ is convex, so is it\u0026rsquo;s perspective!\nConjugate function The conjugate function of $f$ is $$ f^{*}(y) = \\sup_{x \\in dom f} (y^{T}x - f(x)) $$ And this function is convex, even if $f$ is not! The intuition is that this is the supremum of an affine function, so it should be more intuitive that that is linear! Usually when we are talking about conjugates, we expect that the conjugate of the conjugate is the original thing. In this case, it not true. In this case it\u0026rsquo;s the convex envelope, but it\u0026rsquo;s not important here.\nQuasi-convex function $f$ quasi convex if $dom f$ sub-level sets are convex for all $\\alpha$. (remember the sub-level sets are the parts in the domain such that are less than a value). The intuition is that if the function goes below a certain threshold, it does it only once in the whole domain.\n","permalink":"https://flecart.github.io/notes/analisi-di-convessit%C3%A0/","summary":"Ripasso Prox: 20 Ripasso: May 22, 2022 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: May 2, 2022 3:23 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nQuesto argomento Ã¨ stato trattato durante dopo la discussione dei Massimi minimi multi-variabile, perÃ² Ã¨ stato ripreso anche nella forma R to R, quindi credo necessiti di un foglio a parte.\nAffine set Lines Let\u0026rsquo;s take two points in $\\mathbb{R}$ $x_{1}, x_{2}$, if we consider the parametrization $$ x = \\theta x_{1} + (1 - \\theta)x_{2} $$ This is a parametrization of the line","title":"Analisi di ConvessitÃ "},{"content":"Ripasso Prox: 21 Ultima modifica: November 29, 2022 10:56 AM Primo Abbozzo: November 1, 2022 7:59 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nIntroduzione a Crittografia al corso di crittografia di Christof Paar su Youtube, con aggiunte del corso Unibo.\nClassifications and definitions Classification nowadays as many many applications like, and itâ€™s a increasing important field\nCryptology (2) ðŸŸ© La branca comunemente riferita come crittografia Ã¨ divisa principalmente in due campi crittografia e cryptanalysis in cui una cerca di creare nuovi metodi per cifrare i messaggi, e lâ€™altro prova ad attaccare questi messaggi ritrovando il messaggio originale.\nRelazione con Sicurezza informatica ðŸŸ© Questo campo si puÃ² considerare una piccola branca della sicurezza informatica, che Ã¨ praticamente necessaria per la sicurezza, perÃ² allo stesso tempo non puÃ² essere utilizzata da sola, ha bisogno anche di sistemi operativi sicuri, hardware sicuro etcâ€¦\nCryptography ðŸŸ© Questo Ã¨ quello che ci interessa, ed Ã¨ ciÃ² che il corso tratta.\nSymmetrical ciphers Asymmetrical ciphers Protocols Classification of cryptoattacks 3 ðŸŸ©- We define attack vector as a possible way to attack a cipher\nClassical Cryptanalisys Bruteforce Analytical attacks (Properties of the Cipher, useful to decrypt it) Social engineering (like a people that gives you the key) (phishing) Implementation attacks (Attack hardware to discover key) Side channel analysis (eg. power consumption related to the key). Ovviamente questi sono molto diversi rispetto ai reali (nella vita reale ci sono molti attack vectors), secondo la Jocelyne, sembra che crypto sembra una scienza perchÃ© definisci metodi di risoluzione di errore per singolo attack vector, che puoi dimostrare come solido, ma nella vita reale credo che hai bisogno che sia valido per ogni tipologia di attacco (ne basta una per distruggerti e ritrovare la chiave diciamo).\nSymmetric cryptography Vogliamo cercare di trovare un modo di comunicare attraverso un canale di comunicazione insicuro, questo Ã¨ il problema principale di questa critografia.\nCanali insicuri possono essere per esempio\nInternet Wifi Setting classico del problema di comunicazione\nAllora introduco uno step di criptazione e decrittazione fra il pirmo e lâ€™ultimo comunicante.\nQuesto Ã¨ un scenario leggermente piÃ¹ generale, in cui nel mezzo c'Ã¨ un attaccante, solitamente un *eve* o altro che ha accesso a $c$ e prova a decrittare. On security of cipher One important note is that the security of the cipher is not enough to mantain a security of the algorithm. But experience says itâ€™s not! (Ma nonostante questo Ã¨ stato fatto per centinaia e centinaia di anni, ora sappiamo che Ã¨ cosa stupida).\nAnd a bad thing about this is that there is no clear way to know if a cipher is secure or not, usually what is done is that the algorithm is made public and if nobody knows how to break it is considered secure.\nAnd itâ€™s very easy to build something that is breakable!!!\nKerckhoffsâ€™ Principle 1883 Enunciato kerckhoff ðŸŸ©- This is the most important principle of the course!\nA cryptosystem should be secure even if the attacker (oscar in this case) knows all the details about the system, with the exception of the secret key.\nHow can we make sense of this? This is counterintuitive. Maybe because in the past there were like two keys, the key and the algorithm itself, seems like that this setting didnâ€™t help to have a better security. But historically speaking, this principle seems to hold.\nSubstitution cipher Vedere #Affine and Caesar Cipher per definizione formale.\nThis was one of the oldest ciphers in history. (Old and stupid ciphers by the Professor).\nHistorical ciphers Operates on letters (solitamente delle permutazioni) Replace ever plaintext letter by a fixed ciphertext letter, this was the main idea. Examples\nCaesar Cipher, replace with a shift (bruteforce easy attack! The keyspace is very small) Function that replaces each letterwith another letter with bijective. bruteforce, itâ€™s too big for a braindead bruteforce to attack this function. 26! Frequency attack because in the language the letters are not equally distributed! And this works. (when the most frequent letter is discovered a big part of ciphertext is found!) And a bad thing is that same letter to same letter (frequency attack)!!!! Attacco di frequenza ðŸŸ© In teoria la chiave Ã¨ una permutazione (nel caso di vigenere, quindi avremmo $26! \\approx 2^{88}$ di keysize, perÃ² un attacco di frequenza Ã¨ troppo forte per questo genere di cifrari. Fatto per la prima volta da Al-Kindi 800 AD.\nAttacco brute-force ðŸŸ© Un modo semplice, ma non molto pratico per fare questa definizione Ã¨ la corrente: dati una coppia $M, C$ di plaintext e ciphertext, un attacco bruteforce su un insieme di chaivi $K = \\left\\{ k_{1}, k_{2}, \\dots \\right\\}$ consiste nel provare almeno una chiave (solitamente unica) per cui vale $$ D(C, k_{i}) = M $$ Ossia la chiave che usando $D$ abbiamo il plaintext. Solitamente questo valore non si puÃ² calcolare, perchÃ© avremmo bisogno di $M$, quindi abbiamo il problema dei falsi positivi all\u0026rsquo;interno del nostro spazio di interesse. (vedere sezione 5.2 di (Paar \u0026amp; Pelzl 2010))\nVigenÃ¨re Cipher Esempio intuitive VigenÃ¨re ðŸŸ© Tentativo formalizzazione ðŸŸ© Consideriamo una chiave $k = (k_{1}, k_{2}, \\dots, k_{l})$ Ognuno equivalente al shift presente in cesare #Affine and Caesar Cipher. Ripetiamo la chiave piÃ¹ volte e cifriamo col shift cipher corrispondente ogni lettera. Questo fa nascere l\u0026rsquo;idea dei rotori senza problemi!\nAttacco a VigenÃ¨re ðŸŸ© Guess the length of the key l using some methods Divide the cyphertext into l shift cipher encryptions Use frequency analysis on each shift cipher Ãˆ una specie di algoritmo, e si riutilizza la vulnerabilitÃ  presente sui shift ciphers normali. L\u0026rsquo;attacco a frequenza diventa piÃ¹ difficile rispetto a Cesare, ma ancora possibile (molti ciphers indipendenti). Per il primo steps un plaintext attack Ã¨ facilissimo per esempio! Qualcuno ha fatto la domanda su come scoprire la lunghezza chiave alla prof. La prof non sa come attaccarlo, e ha detto solo bruteforce su lunghezza. Poi ha citato un caso di plain-text senza chiamarlo plain-text. Ma Ã¨ stata molto vaga. Bad. Ha detto anche entrare nel sistema per trovarlo\u0026hellip; lol.\nRotor machines Main idea of rotors ðŸŸ¨- Queste macchine sono nate principalmente nel secolo scorso, da queste idee\nMultiple rounds of substitution, encryption consists of mapping a letter many times â—‹ M Mechanical/electrical wiring to automate the encryption/decryption process La meccanizzazione Ã¨ stata risolta dal punto di vista del red team da Turing, che ha dato un contributo fondamentale (Turing 1950).\nEsempi storici di rotor machines I moderni simili sono DES e AES, li tratteremo un po' piÃ¹ avanti. ### Security of the Key Note sulla lunghezza della chiave (non fare) Andiamo in questa parte a misurare la sicurezza di una chiave di fronte agli attacchi. Una prima nota molto importante Ã¨ il fatto che questa misura della lunghezza ha senso solamente quando si parla di bruteforce, infatti la lunghezza della chiave non puÃ² difendere contro side-channel oppure frequency-attacks.\nLa lunghezza della chiave per cifrari simmetrici e asimmetrici cambia. Segretezza perfetta ðŸŸ©- Secondo Shannon 1949. Consideriamo un cifrario $E, D$ su $K, M, C$, allora si dice che si ha perfect secrecy quando $\\forall m_{0},m_{1} \\in M$ tale per cui $\\mid m_{0} \\mid = \\mid m_{1} \\mid$ , dove $k$ Ã¨ presa uniforme. e $\\forall c \\in C$ $$ \\mathbb{P}(E(k, m_{0}) = c) = \\mathbb{P}(E(k, m_{1}) = c) $$ Detto in altre parole, se ho un certo cipher-text, ho la stessa probabilitÃ  di avere qualunque messaggio possibile di una certa lunghezza rispetto al messaggio iniziale. Quando succede questo there are no computational assumptions about the attacker, this is why this is also called unconditional security or perfect security.\nIl cyphertext potrebbe essere qualunque messaggio!, cioÃ¨ non posso attaccare il $c$ sapendo solo $c$ con la segretezza perfetta. Altri autori come Stinson definisco tale per cui $P(E|M) = P(E)$. Attualmente non mi Ã¨ chiaro se le due definizioni sono equivalenti.\nL\u0026rsquo;idea Ã¨ limitare qualunque informazione che si puÃ² trovare dalla chiave come\nNon posso ritrovare la chiave dai processi di $E$ e $D$ Non posso ritrovare il plain-text da ciphertext. Una definizione equivalente sembra essere: dato un $M$ deve essere che $\\forall e \\in E, P(e|M) = P(e) \\not = 0$ (https://www3.cs.stonybrook.edu/~omkant/L02-short.pdf) Questo significa che il $e$ Ã¨ indipendente da M quando non si conosce la chiave, nel senso che non riesci prendere nessuna informazione (se inverti con bayes dovresti avere stesso valore). Si puÃ² dimostrare che la seconda definizione, piÃ¹ l\u0026rsquo;ipotesi che $\\lvert K \\rvert = \\lvert P \\rvert = \\lvert C \\rvert$ Ã¨ equivalente alla prima (il contrario dovrebbe essere facile!?).\nSegretezza perfetta e lunghezza chiave ðŸŸ¨+ Si puÃ² dimostrare che per avere segretezza perfetta Ã¨ necessario avere\n$$ \\lvert K \\rvert \\geq \\lvert M \\rvert $$ Questa proprietÃ  rende cifrari come OTP molto difficili da usare nella pratica, perchÃ© non riusciamo a comunicare questo valore, che tra l\u0026rsquo;altro dovrebbe essere utilizzato una singola volta.\nProof: https://cs.ioc.ee/yik/schools/win2006/massey/slides1.pdf Dove $H$ Ã¨ l\u0026rsquo;informazione Shannon. quindi $H(P) = \\sum_{x} P(x)\\log\\left( \\frac{1}{P(x)} \\right)$, e la lunghezza Ã¨ strettamente dipendente dall\u0026rsquo;entropia. Questo Shannon lo ha dimostrato nel 1949.\nUna altra dimo Ã¨ su (Stinson 2005) 3.3, abbastanza ez.\nUnconditional security ðŸŸ© La nota importante Ã¨ il fatto che sia infinito, anche se ho il tempo dellâ€™universo o maggiore non posso mai rompere un cifrario sicuro incondizionalmente. (molti cifrari sicuri nella pratica quindi non sono sicuri sequendo questa definizione). Questo dovrebbe essere equivalente alla definizione di sopra si segretezza perfetta.\nCome vedremo câ€™Ã¨ un cifrario teoricamente sicuro, ma nella pratica di poco utilizzo\nAffine and Caesar Cipher Definizione shift cipher ðŸŸ© Sono definizioni 1.4.3 presenti su (Paar \u0026amp; Pelzl 2010). Shift Cipher\nSiano $x,y,k \\in \\mathbb{Z}_{26}$ Allora l\u0026rsquo;encryption Ã¨ $$ e_{k}(x) \\equiv x + k, \\mod 26 $$ Mentre il decryption Ã¨ $$ d_{k}(y) = y - k \\mod 26 $$ Definizione affine cipher ðŸŸ© Affine cipher Siano $x, y, a, b \\in \\mathbb{Z}_{26}$ Encryption: $$ e_{k}(x) = y \\equiv a\\cdot x + b \\mod 26 $$ Decription $$ d_{k}(y) = x \\equiv a^{-1}\\cdot(y - b) \\mod 26 $$ Con la restrizione del fatto che affinchÃ© $a$ sia invertibile dobbiamo avere $gcd(a, 26) = 1$\nAritmetica modulare Guardare Algebra modulare, perchÃ© Ã¨ praticamente quella stessa roba, molto importante crittografia, ma andiamo a trattare in un altro modo\nSul modulo ðŸŸ© Il resto non Ã¨ unico! ci possono essere molte cose che soddisfano quelle cose Il resto si puÃ² considerare una classe di equivalenza. Anelli ðŸŸ© Un anello Ã¨ un insieme di elementi su cui sono definite certe proprietÃ  di interesse.\nEsiste somma e prodotto e sono chiusi. E ci sono molte altre coseâ€¦ Slide\nLâ€™inverso non ci deve stare\nReferences [1] Turing â€œI.â€”COMPUTING MACHINERY AND INTELLIGENCEâ€ Mind Vol. LIX(236), pp. 433\u0026ndash;460 1950\n[2] Stinson â€œCryptography: Theory and Practice, Third Editionâ€ CRC Press 2005\n[3] Paar \u0026amp; Pelzl â€œUnderstanding Cryptography: A Textbook for Students and Practitionersâ€ Springer 2010\n","permalink":"https://flecart.github.io/notes/classical-cyphers/","summary":"Ripasso Prox: 21 Ultima modifica: November 29, 2022 10:56 AM Primo Abbozzo: November 1, 2022 7:59 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nIntroduzione a Crittografia al corso di crittografia di Christof Paar su Youtube, con aggiunte del corso Unibo.\nClassifications and definitions Classification nowadays as many many applications like, and itâ€™s a increasing important field\nCryptology (2) ðŸŸ© La branca comunemente riferita come crittografia Ã¨ divisa principalmente in due campi crittografia e cryptanalysis in cui una cerca di creare nuovi metodi per cifrare i messaggi, e lâ€™altro prova ad attaccare questi messaggi ritrovando il messaggio originale.","title":"Classical Cyphers"},{"content":"Ripasso Prox: 30 Ripasso: May 17, 2023 Ultima modifica: April 29, 2023 11:56 AM Primo Abbozzo: March 29, 2023 11:18 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Devices OS Devices Categorizzazione (6)ðŸŸ¨- Trasferimento dei dati Accesso al device sinconia del trasferimento condivisone fra processi VelocitÃ  del trasferimento I/O direction (scrittura o lettura) Vediamo che molte caratteristiche sono riguardo il trasferimento\nSlide categorizzazione I/O\nBlocchi o caratteri ðŸŸ©- Slide devices blocchi o caratteri\nTecniche di gestione devices (4) ðŸŸ¨- BUFFERING\nPossiamo mettere un buffer per favorire la comunicazione fra i devices. la cos amigliore che fa Ã¨ creare maggiore efficienza. Un altro motivo Ã¨ la velocitÃ  diversa di consumo.\nAnche le schede audio, in cui viene riempito un buffer e poi lâ€™audio viene playato da questo (differenza consumer e producer), anche per questo motivo Ã¨ difficile sincornizzare dispositivi differenti (se hanno buffer distinti).\nCACHE\nInvece la cache Ã¨ trasparente pe ril programma, e rende il tutto piÃ¹ veloce.\nLa differenza maggiore con il buffering Ã¨ che qui viene mantenuta una copia, non una istanza dellâ€™informazione.\nSPOOLING\nGia trattato per le stampanti in Gestione delle risorse\nSCHEDULING I/O\nSlides devices\nStorage area network ðŸŸ© Slide SAN\nIl vantaggio principale Ã¨ resilienza del server, che ho il device in altra parte. (non ho iil tight coupling fra server e disco in questo modo, prima se si rompe qualunque, si rompe il servizio).\nOra se si rompe un server, ci sarÃ  un altro server che sostituisce, se si rompe un storage array, ci sarÃ  ridondanza, e altro storage ti risponderebbe. Si vede che questa parte Ã¨ strettamente collegata con cose fatte in Reti di Calcolatori\nMemoria secondaria Solid State Drive ðŸŸ¨+ Slide SSD\nUn sacco di vantaggi come\nVelocitÃ  di accesso Meno consumo energetico Meno fragilitÃ  VelocitÃ  di lettura Ã¨ molto veloce. Poche scritture (comuqnue tante) comunque limitati cicli di scrittura. Uniforme velocitÃ  in tutto il disco (questo rende l\u0026rsquo;accesso veloce :D). Non andiamo ad approfondire sugli algoritmi di scheduling per le scritture a banco, trattiamo meglio gli HDD.\nHard Disk Drive ðŸŸ¨+ Soffrono molto i terremoti perchÃ© la testina Ã¨ vicina al disco e non soffrono problemi di pressione.\nDevo avere:\nTestine settore giusto La traccia desiderata si muova e mi dia le cose giuste Questo mi crea 3 parametri per valutare questo accesso\nVelocitÃ  di rotazione, Tempo di seek o di cambiare cilindro**, velocitÃ  di trasferimento**.\nSolitamente il tempo piÃ¹ lungo Ã¨ per il cilindro, poi devo andare alla sezione, e andare alla testina corretta.\nIn generale sul disco:\nOssia solitamente mezzo giro, + tempo cambio\nVALUTAZIONE TEMPO DI ACCESSO\nSlide tempi di accesso per dischi\nIn media 100 giri al secondo, quindi tipo 5 ms per andare a trovare la testina corretta, potrebbe essere 2.5 se Ã¨ il doppio o 1, ma lâ€™ordine di grandezza resta questo per il ritardo.\nRAID Introduzione ai Redundant Array of Indipendent Disks I RAID ne abbiamo parlato in Memoria. Come facciamo a stare su alla velocitÃ  del processore se questa va a crescere in modo esponenziale? Parallelizzazione della ricerca!. Ecco perchÃ© ci serve raid (oltre alla ridondanza quindi piÃ¹ sicuro). E possono anche fallire. â†’ ammette recovery.\nE una altra cosa bella dei raid Ã¨ che sono hot-swappable cioÃ¨ li puoi sostituire anche quando stanno runnando.\nSlide RAID\nlivello 0 (striping) ðŸŸ© I dati vengono messi su piÃ¹ dischi. Viene utilizzato per applicazioni in cui serve velocitÃ , senza interesse di perdita di dati. Ad esempio in dipartimento ci mettono copie di SO per aggiornare il sistema operativo.\nUTILIZZI:\nper grandi trasferimenti di dati, efficiente, in particolare se la quantitÃ  di dati richiesta Ã¨ relativamente grande rispetto alla dimensione degli strip\nper un gran numero di richieste indipendenti efficiente, in particolare se la quantitÃ  di dati richiesta Ã¨ paragonabile alla dimensione degli strip\nSlide RAID 0\nhttps://www.notion.so\nLivello 1 (mirroring) ðŸŸ© Ci sono 2n dischi e metÃ  sono delle copie esatte.\nSlide RAID 1\nIn questo caso la scrittura Ã¨ piÃ¹ lenta della lettura.\nTollera un singolo guasto al massimo, o piÃ¹ dischi differenti (non devono essere le due copie diciamo). Si dice fault tolerance livello 1.\nLivello 4 ðŸŸ© Slide introduzione raid livello 4\nUtilizzo un intero disco solamente per la paritÃ  su un disco. cosÃ¬ se si rompe un disco riesco a ricostruire le informazioni di quel disco.\nNon Ã¨ efficiente perchÃ© se cambio un dato devo andare sempre a fare due write su dischi diversi. E poi continuo sempre a scrivere sullo stesso disco! Quindi fai finta 4 write contemporanei, per aggiornare gli altri dischi! Per questo c\u0026rsquo;Ã¨ il bottleneck\nLivello 5 ðŸŸ© Slide intuizione raid livello 5\nSe c\u0026rsquo;Ã¨ un disco rotto si rallenta, ma non si perdono dei dati! Ã¨ il funzionamento degradato dei raid.\nNon ho problemi di bottleneck, e ho ancora la velocitÃ  del livello 1\nLivello 6 ðŸŸ¨++ Slide raid livello 6\nhttp://www.cs.unibo.it/~renzo/doc/p245-blaum\nQuesto Ã¨ per cose sicure, riesce a tollerare livello 2 fino a due dischi rotti.\nOvviamente Ã¨ una paritÃ  diversa, in modo che riesco ad avere piÃ¹ fault tolerance.\nSi utilizza un XOR in diagonale e questo sembra funzionare, anche se non ho capito perchÃ©.\nIntuizione mia\nIn pratica qualunque modo prendi due dischi non di check (se uno Ã¨ un disco di check Ã¨ molto ez).\nAllora puoi fare questo:\nRecovery dei dischi in alto a sinistra e in basso a destra, questi si possono recoverare solamente con i bits diagonali, quindi posso giÃ  farlo. Utilizzo questi strips recuperati e utilizzo quelli orizzontali per recuperare lâ€™altro della stessa row, poi utilizzo diagonale per recuperare quelli corrispondenti in row diverse e continuo cosÃ¬ e riesco a recuperare tutto., Sarebbe molto utile fare un esempio per mostrare questo, ma spero che il me futuro quando legge questo riesca a ricordarsi lâ€™esempio su carta.\nAlgoritmi per HHD First Come First Served ðŸŸ© Questo Ã¨ un algoritmo fair, nel senso che eseguo a seconda di quanto viene, questo non general starvation. PerÃ² non minimizza il numero di seek, quindi in generale Ã¨ piÃ¹ lento. Se invece facciamo in batch, in gruppo di richeiste alla volta sarebbe molto piÃ¹ semplice!\nQuesta Ã¨ l\u0026rsquo;idea del prossimo algoritmo\nShortest Seek Time First ðŸŸ© seleziona la richieste che prevede il minor spostamento della testina dalla posizione corrente\npuÃ² provocare starvation, quando arrivano tante vicine, non visito mai quelle lontane!\nQuindi non abbiamo fairness, e non câ€™Ã¨ una buona velocitÃ  di risposta per le richieste agli estremi.\nLook - Algoritmo dellâ€™ascensore ðŸŸ© Praticamente vado avanti indietro, e quando arrivo alla fine torno indietro, continuo cosÃ¬ a soddisfare le richieste.\nIl tempo medio di accesso non Ã¨ omogeneo, le tracce centrali sono accesse piÃ¹ spesso.\nEsempio ascensore\nDISCUSSIONE DI IMPLEMENTAZIONE\nSi utilizzano due code. Una coda a scendere e una coda a salire.\nPotrei creare starvation quando mi arrivano richieste sullo stesso cilindro, quindi quando succede devo mettere la richiesta nell\u0026rsquo;altra coda.\nImplementazione delle due code\nC-Look ðŸŸ© Ãˆ molto simile all\u0026rsquo;algoritmo dellâ€™ascensore, ma solo che quando arrivo alla fine torno allâ€™inizio.\nNon ho ancora capito in quali casi puÃ² essere utile.\nSlide esempio C-Look\n","permalink":"https://flecart.github.io/notes/devices-os/","summary":"Ripasso Prox: 30 Ripasso: May 17, 2023 Ultima modifica: April 29, 2023 11:56 AM Primo Abbozzo: March 29, 2023 11:18 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Devices OS Devices Categorizzazione (6)ðŸŸ¨- Trasferimento dei dati Accesso al device sinconia del trasferimento condivisone fra processi VelocitÃ  del trasferimento I/O direction (scrittura o lettura) Vediamo che molte caratteristiche sono riguardo il trasferimento\nSlide categorizzazione I/O\nBlocchi o caratteri ðŸŸ©- Slide devices blocchi o caratteri","title":"Devices OS"},{"content":"Ripasso Prox: 60 Ripasso: June 1, 2023 Ultima modifica: May 29, 2023 3:34 PM Primo Abbozzo: February 27, 2023 9:07 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Gestione della memoria Memoria statica Elementi in memoria statica (4) ðŸŸ©- Variabili globali Istruzioni macchina Costanti (Variabili locali, paramentri e ritorno di funzione?) Le primi tre elementi descritti di sopra sono sicuramente presenti dopo la fase di compilazione, infatti sono allocati dal compilatore in una zona presente nellâ€™eseguibile (un esempio Ã¨ il READONLY per le stringhe in C).\nQuindi se vogliamo\nAvere funzioni ricorsive Potere allocare e deallocare variabili in modo dinamico Abbiamo bisogno di far uso di Pila o Heap, che riescano a cresere e restringersi in modo dinamico.\nImplementazione di funzioni statiche ðŸŸ© Si potrebbe anche utilizzare la memoria statica per implementare le funzioni, ma questo ha il fortissimo drawback che non permette la ricorsione in quanto stiamo assumento che in ogni momento di esecuzione la funzione Ã¨ chiamata una singola volta. (ho un unico indirizzo di memoria per l\u0026rsquo;indirizzo di ritorno.\nInfatti se chiamassimo in modo ricorsivo questa funzione, perderemmo alcuni valori, come l\u0026rsquo;indirizzo di ritorno, il valore di ritorno precedente, e porterebbe in uno stato invalido.\nOltre a questo avremmo un elevato uso della memoria nel caso in cui il numero di chiamate di funzioni sia in media minore del numero di dichiarazioni di funzione (avremmo un sacco di funzioni inutilizzate).\nSlide di quanto memorizzato per la funzione statica\nFigura 7.1 Gestione della memoria statica. per le funzioni\nSull\u0026rsquo;efficienza\nSolitamente se utilizziamo questo metodo il compilatore solitamente Ã¨ in grado di accedere a delle variabili utilizzando un OFFSET senza dover stare a fare risoluzione di nomi simbolici (una volta che abbiamo un frame o RdA, possiamo calcolare la posizione della variabile locale, o parametro attraverso lâ€™offset sul base pointer, che qui Ã¨ anche chiamato puntatore di RdA). Qualcosina in piÃ¹ forse c\u0026rsquo;Ã¨ da fare sulle variabili non locali\nUn altra ottimizzazione Ã¨ memorizzare i risultati intermedi su REGISTRI invece che utilizzare la stack. In generale ci sono moltissimi modi di ottimizzare, quindi non andiamo a parlare di questo.\nGestione della pila La pila Ã¨ la struttura piÃ¹ comoda per la gestione dei blocchi di codice, che come abbiamo descritto in Nomi e Scope, devono essere LIFO, ossia il blocco piÃ¹ annidato deve finire prima di uscire. Questo Ã¨ il motivo per cui possiamo giustificare la gestione della pila. Ecco che si giustifica l\u0026rsquo;idea di creazione della pila di sistema.* Che Ã¨ in grado di stabilire le posizioni delle variabili locale, dei parametri attraverso un Offset rispetto al base pointer del frame.\nRecord di attivazione di blocchi (3) ðŸŸ© Ne abbiamo accennato in 8.4.1 Activation record, parlando anche lÃ¬ dei record di attivazione, in questo momento andremo a parlarne in modo piÃ¹ approfondito.\nOra parliamo brevemente di record attivazione di blocchi, per questi quando entriamo in un nuovo blocco vogliamo creare spazio per queste cose:\nVariabili intermedie (per storare calcolo intermedio) Variabili locali nuove Catena dinamica che mi dice in quale blocco sono, ed Ã¨ utilizzato per eliminare tutto il nuovo spazio allocato in questo blocco. Esempio:\nFigura 7 .3 Allocazione del record di attivazione per I blocchi A e B nell\u0026rsquo;Esempio 7.2.\nRecord di attivazione per funzioni (7) ðŸŸ© Questi record di attivazione, anche chiamate RdA in modo abbreviato hanno lo stesso concetto per i record di attivazione per i blocchi, ma devono avere qualche informazione in piÃ¹ per indirizzo di ritorno e modo di ritornare la variabile di output.\nTutti i 3 punti per i RdA dei blocchi Catena statica per gli scope (che attualmente non so in che modo venga utilizzata) Indirizzo di ritorno, per il program counter Indirizzo per il Valore di ritorno I parametri di chiamata della funzione. Figura 7.7 Struttura del record di attivazione per una procedura.\nGestione della pila a runtime (!!!) ðŸŸ¨++ In questa parte andiamo a parlare di alcune istruzioni che sono utili per implementare questo sistema di RdA in un linguaggio classico.\nAndiamo a parlare di sequenza di chiamata per l\u0026rsquo;insieme di procedure che deve eseguire il chiamante prima di entrare nel blocco della funzioen chiamata, e una sequenza di ritorno per uscire dal blocco, poi di prologo e epilogo per lâ€™uscita. ora nel pezzo sequente andiamo a descrivere alcune istruzioni da eseguire per entrare ed uscire da un blocco di RdA di una funzione.\nQuesta divisione Ã¨ necessaria perchÃ© alcune cose possono essere fatte solo dal chiamante, e altre solo dal chiamato!\nChiamata di funzione\nQuesta parte interessa la parte di sequenza di chiamata e il prologo della funzione.\nAllocazione dello spazio necessario nella stack (per parametri, variabili locali, e risultati intermedi, e catene statiche e dinamiche). Passare i parametri (di solito copiati nella nuova RdA) Aggiornare il puntatore di RdA al nuovo, in C di solito Ã¨ il base pointer, anche chiamato frame pointer. Salvare quanto necessario dai registri (e.g. il chiamante deve settare lâ€™indirizzo di ritorno della funzione). Salvare il PC precedente, e settare il nuovo PC. Eseguire codice di inizializzazione specifico del linguaggio, se c\u0026rsquo;Ã¨ (anche in C mi pare ci fossero alcune istruzioni, di solito erano nel prologo, come dei push rbp). Ritorno del controllo al programma chiamante\nRipristinare i valori dei registri precedenti. Risettare il PC precedente Copiare il valore di ritorno nell\u0026rsquo;indirizzo giusto ripristinare il puntatore di RdA Deallocare la parte della stack che non utilizziamo piÃ¹. Esecuzione di codice di uscita. Gestione della heap Per la heap non Ã¨ possibile utilizzare stack perchÃ© in questo caso l\u0026rsquo;utilizzo non soddisfa la proprietÃ  LIFO tipida della stack, posso freeare una cosa anche prima di una cosa allocata dopo diciamo. Bisogna quindi creare un metodo di gestione dinamica della memoria differente.\nQuesto Ã¨ solamente una zona contigua di memoria diversa dalla stack, in cui possiamo allocare e deallocare dinamicamente cose, non câ€™entra niente con la struttura di dati!\nDimensione fissa ðŸŸ© Questa Ã¨ l\u0026rsquo;implementazione della heap piÃ¹ semplice, in pratica divido tutto il mio array disponibile in blocchi liberi disponibili.\nQuando vado ad allocare un blocco, vado a togliere questo blocco e metterlo a disposizione al chiamante, a chi ha allocato il blocco, e tolgo questo blocco dai liberi, ora la lista dei liberi punterÃ  al prossimo blocco libero.\nQuando vado a deallocare il blocco non faccio altro che marcare come libero il blocco, reinserendolo nella lista dei liberi.\nDimensione variabile ðŸŸ©- Questa Ã¨ una soluzione molto piÃ¹ bella per quanto riguarda la soluzione della frammentazione interna, ossia quanta parte di memoria ho ancora inutilizzato, se ho richiesto un blocco (e.g. prima se avevo blocchi da 256, anche se volevo un singolo byte, mi dava un blocco da 256 e gran parte della memoria sarebbe stata sprecata per allocazione dinamica.)\nOra vorrei dividere tutta la memoria che ho secondo una certa logica, solitamente si puÃ² dividere in due modi di gestire questa cosa:\nHeap dimensione variabile a liste multiple\nQuesta Ã¨ una gestione della lista in cui ho piÃ¹ liste di una certa grandezza, i sistemi principali sono a buddy system o fibonacci heap. Discuteremo solamente il primo sistema, il secondo sistema Ã¨ molto simile, con una leggera efficienza in piÃ¹ perchÃ© utilizzando i numeri di fibonacci si ha minore frammentazione interna**.**\nAllora se richiedo un blocco di grandezza n, vado a cercare il blocco libero nella lista di k, con grandezza piÃ¹ grande di n (in buddy system le liste sono tutte di grandezze di potenze di due).\nSe trovo una lista allora alloco e restituisco. Se invece non c\u0026rsquo;Ã¨, allora vado a cercare nelle liste piÃ¹ grosse se c\u0026rsquo;Ã¨. Se lo trovo, allora lo spezzo a metÃ , creando i buddies, uno lo aggiungo alla lista dei liberi della lista precedente, l\u0026rsquo;altra la restituisco come blocco allocato.\nin fase di deallocazione vado a controllare se ho dei buddies spezzati, se esistono e sono liberi allora li ricompongo e li metto nella lista grossa originale, altrimenti rimane nella lista libera piÃ¹ piccola!\nHeap a singola lista ðŸŸ© Anche in questo caso possiamo avere dei problemi di frammentazione quando allochiamo e deallochiamo gli elementi della lista libera che possediamo, ne abbiamo parlato sempre in architettura quando abbiamo accennato alla paginazione: 9.3.2 In memoria: frammentazione esterna. Infatti anche qui possiamo andare a parlare di politiche di first and best FIT. Questi sono entrambi metodi di inserimento lineare, il primo favorisce il tempo, il secondo lâ€™efficienza in memoria.\nCon questo sistema ho un blocco di spazio UNICO disponibile. Quindi se chiedo n, posso effettivamente allocarti un blocco grosso n, senza nessuna frammentazione. Questo posso continuare finchÃ© non finisco la memoria. Quando la finisco potrei gestirla in due modi praticamente.\nLista dei liberi\nIn questo caso quando faccio free faccio append di tutti i blocchi deallocati alla lista dei liberi. Posso inserire controlli che quando ho due blocchi contigui nei liberi li compatto assieme. Questo Ã¨ la compattazione parziale.\nPoi quando finisco la memoria utilizzo direttamente la lista dei liberi per allocare nuovi blocchi, questo puÃ² portare al problema di frammentazione interna o esterna. Ci metto in tempo lineare ad allocare. (oppure posso tenere i blocchi ordinati, se utilizzo alberi ordinati allora log(n) per tirare via ed inserire.) Ma in generale ci sono molti modi per gestire questa struttura di dati.\nCompattazione della memoria libera\nQuando finisco la memoria, risolvo la frammentazione esterna rimettendo assieme tutti i blocchi allocati, e poi posso continuare l\u0026rsquo;algoritmo di sopra, allocando esattamente quando mi richiede.\nIl problema di questo metodo Ã¨ che difficilmente posso spostare le cose, che Ã¨ una precondizione per poter utilizzare questo metodo.\nImplementazione delle regole di scope Abbiamo parlato per la prima volta di scope in Nomi e Scope.\nScope statico ðŸŸ© Per implementare lo scope statico vogliamo utilizzare la catena statica presente all\u0026rsquo;interno del record di attivazione per poter risalire al blocco giusto.\nIn particolare dividiamo in due casi, il caso in cui il nome chiamato sia presente nell\u0026rsquo;ambiente locale del chiamante, e il caso in cui non lo sia. Questo Ã¨ importante perchÃ© nella fase di sequenza di chiamata dovrebbe essere il lavoro del chiamante per impostare il puntatore di catena statica del chiamato. Notare che in questa sezione utilizziamo nomi come chiamante chiamato, ma il chiamato potrebbe anche essere riferimento al nome di una variabile, il concetto di risalita Ã¨ comune.\nCaso presente nellâ€™ambiente locale\nQuesto Ã¨ il caso semplice, so che la catena statica deve puntare al chiamante, quindi basta inserirla nel record di attivazione del chiamato!\nCaso non presente\nQuesto Ã¨ una cosa leggermente piÃ¹ complessa, se io so che il chiamato Ã¨ a livello di annidamento statico n (per tenersi queste informazioni probabilmente si utilizzano informazioni di annidamento e di ambienti locale, che sono comunque presenti nella struttura (statica), e quindi le posso calcolare al momento di compilazione)), e il chiamante a livello di m, devo percorrere k = m - n, livelli per trovare il puntatore di catena statica del chiamato e settarlo puntatore di catena statica del nuovo RdA che mi ritrovo dopo aver risalito di k sulla catena statica.\nQuesto lo so perchÃ© dato che il chiamato Ã¨ esterno, so che Ã¨ presente nellâ€™ambiente non locale, quindi non puÃ² che essere a livello di annidamento inferiore, quindi risalire la catena statica Ã¨ corretto.\nChiaramente Ã¨ una cosa molto inefficiente fare k dereferenziazioni di pointer per arrivare fino al punto che mi interessa, vedremo subito dopo un metodo per velocizzare questo sistema di scope statico.\nEsempio funzionamento\n!\nFigura 7.14 Catena statica per la struttura precedente e la sequenza di chiamate A, B, C, D, E, C.\nstatico: Il display ðŸŸ© Vogliamo trovare un metodo piÃ¹ veloce per settare il RdA nel campo della catena statica, tanto che possiamo ridurre a k dereferenziazioni a solamente un numero costante piccolo (2, ma poi il problema precedente non Ã¨ brutto dato che il numero di annidamenti per linguaggi reali sta molto piccolo in generale, di solito 3).\nAllora un modo per fare questo Ã¨ tenersi un altro array, che contenga un puntatore a seconda del livello di annidamento!\nIdea: tenersi una struttura ausiliaria che viene aggiornato ad ogni cambio di ambiente che contenga il puntatore alla struttura statica di riferimento a ogni livello. (chiaramente il livello massimo si annidamento, va a determinare la lunghezza del display).\nDue accessi, uno nel display per trovare il RdA corretto, l\u0026rsquo;altro accesso per trovare lâ€™index della variabile locale corretta.\nFunzionamento generale\nSia m il livello di annidamento del chiamato, allora salvo il valore che c\u0026rsquo;era prima, perchÃ© il display sarÃ  comune a tutti i livelli diversi da m.\nQuando ritorno ripristino il vecchio valore, in questo senso il display contiene tutte le RdA statiche a seconda del livello di annidamento, e posso utilizzare questo per capire il puntatore di catena statica.\nEsempio display\n!\nFigura 7.15 Display per la struttura di Figura 7.13 e la sequenza di chiamate A,' B, C, D, E, C.\nScope dinamico: La ricerca per nome ðŸŸ© Questa Ã¨ la soluzione piÃ¹ lenta che potrebbe esistere, che Ã¨ quella della ricerca per nome negli RdA, in pratica risalgo i record fin quando non lo trovo o lo trovo.\nUn problema diventa andare ad attivare o disattivare le variabili a seconda del fatto di averlo giÃ  visto o meno, e dello scope.\nSlide descrive questo metodo\nScope dinamico lista associazioni ðŸŸ© Una cosa banale Ã¨ tenersi una lista di associazioni globale, chiamata A-list (che viene usato in lisp) che si tiene conto di tutte le associazioni attive. Un entrare e uscire da un certo ambiente non si tratta altro che andare a manipolare questa lista globale di associazioni.\nCercare un valore dellâ€™associazione a runtime non sarebbe altro che andare a scorrersi la lista fino a trovare il simbolo di mio interesse, alla prima occorrenza, perchÃ© quella Ã¨ la piÃ¹ recente.\nEntro in nuovo ambiente non faccio altro che aggiungere nella A-list i valori locali\nEsco dallâ€™ambiente non faccio altro che poppare i valori locali\nRicerca simboli non faccio che scorrere tutta la A-list per trovare il valore corretto.\nChiaramente questo runtime non Ã¨ che sia molto invitante (nella pratica perÃ² Ã¨ sufficiente, anche se non avrei comunque una efficienza di C), quindi vorremmo trovare anche metodi migliori per implementare lo scope dinamico.\nUn altro metodo comparabile per inefficienza Ã¨ scorrersi le RdA finchÃ© non troviamo il simbolo di nostro interesse..\nSvantaggi\nDevo memorizzare i nomi in momento di esecuzione, per poter ritrovare l\u0026rsquo;istanza. Lentezza ad accedere valori globali, che sono in cima alla lista. Entrambi questi svantaggi sono risolti con la CRT esposta nella squenza successiva.\nCentral Referencing environment Table ðŸŸ© Durante l\u0026rsquo;esecuzione e durante le entrate in ogni ambiente locale, posso tenermi un array di tutti i simboli che posso avere (oppure una hastable). Questo mi permette di accedere al simbolo in tempo costante, e se a tempo di compilazione conosco tutte le variabili a mia disposizione, poi mi basta accedere con offset, e non mi serve sapere il nome originario! (se invece non Ã¨ nota bisogna utilizzare la hastable).\nIn questo modo ho un leggere overhead in piÃ¹ per uscire ed entrare in un blocco. PerchÃ© devo aggiornare l\u0026rsquo;array globale di liste, perÃ² mi implementa in modo semplice questo scope dinamico.\nPer tenere conto dei valori vecchi abbiamo principalmente due metodi:\nTenersi la stack degli elementi nascosti che viene ripristinata quando usciamo dal blocco (quindi Ã¨ temporaneo per tenere i vecchi valori) Lista dei vecchi valori, ossia ogni elemento si tiene una lista, che possiamo interpretarla come stack per ogni valore, che contiene i vecchi valori, in testa solamente il valore piÃ¹ recente. Esempio stack elementi nascosti\nEsempio lista vecchi valori\n","permalink":"https://flecart.github.io/notes/gestione-della-memoria/","summary":"Ripasso Prox: 60 Ripasso: June 1, 2023 Ultima modifica: May 29, 2023 3:34 PM Primo Abbozzo: February 27, 2023 9:07 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Gestione della memoria Memoria statica Elementi in memoria statica (4) ðŸŸ©- Variabili globali Istruzioni macchina Costanti (Variabili locali, paramentri e ritorno di funzione?) Le primi tre elementi descritti di sopra sono sicuramente presenti dopo la fase di compilazione, infatti sono allocati dal compilatore in una zona presente nellâ€™eseguibile (un esempio Ã¨ il READONLY per le stringhe in C).","title":"Gestione della memoria"},{"content":"Ultima modifica: September 18, 2022 9:43 AM Primo Abbozzo: September 16, 2022 9:52 AM Studi Personali: Yes\nElementi di ripasso Measure Theory Introduzione Requirements of the measure function Vorremmo cercare di estendere il concetto di misurabilitÃ  a gruppi molto piÃ¹ ampi di un singolo intervallo, vorrei creare una funzione che sia in grado di misurare degli insiemi. *su vedrÃ  che sono impossibili).\nImpossibilitÃ  di questi requirements (assurdo) Costruzione dellâ€™insieme di interesse\nConsideriamo la classe di equivalenza definita come in immagine, mi costruisco (credo si chiami cosets) $\\Lambda$ in quel modo, prendendo le classi di equivalenza, posso dire che questo lambda non Ã¨ numerabile, perchÃ© se lo fosse ogni elemento di R sarebbe rappresentabile con lambda e un pezzo di X (ad esempio .\nAllora mi costruisco $\\Omega$ definito con assioma della scelta prendendo un singolo elemento in ogni classe di equivalenza. Ãˆ chiaro che questo insieme cosÃ¬ creato sia innumerabile.\nInoltre lo creo in modo che $\\Omega \\subseteq (0, 1)$, credo sia abbastanza intuitivo vedere che câ€™Ã¨ sempre un elemento compreso, quindi basta translare.\nOra vado a utilizzare la regola 2, ossia invarianza per traslazione.\n$\\forall p, q \\in \\mathbb{Q}\\, (\\Omega + p) \\cap (\\Omega + q) = \\empty \\iff p \\neq q$\nSupponiamo che lâ€™intersezione non sia vuota, allora $\\exists x : x = \\alpha + p = \\beta + q$, ossia ho che $\\alpha - \\beta = q - p \\implies \\alpha \\equiv \\beta \\implies \\alpha = \\beta \\implies p = q$ lâ€™uguaglianza dalla relazione di equivalenza deriva dal fatto che appartengono alla stessa classe di equivalenza, ma per costruzione ne ho presa solo una, quindi sono uguali. Quindi se lâ€™intersezione non Ã¨ vuota ho che p e q sono uguali. se sono uguali, invece, Ã¨ chiaro che la loro intersezione Ã¨ lâ€™insieme stesso, quindi non Ã¨ vuota.\nUpper bound\nOra che abbiamo questa invarianza, sarebbe utile per cercare di utilizzare 3 e farci dei bounds, e poi dimostrare lâ€™assurdo con questi bounds, allora considero lâ€™insieme $\\bigcup_{-1","permalink":"https://flecart.github.io/notes/measure-theory/","summary":"Ultima modifica: September 18, 2022 9:43 AM Primo Abbozzo: September 16, 2022 9:52 AM Studi Personali: Yes\nElementi di ripasso Measure Theory Introduzione Requirements of the measure function Vorremmo cercare di estendere il concetto di misurabilitÃ  a gruppi molto piÃ¹ ampi di un singolo intervallo, vorrei creare una funzione che sia in grado di misurare degli insiemi. *su vedrÃ  che sono impossibili).\nImpossibilitÃ  di questi requirements (assurdo) Costruzione dellâ€™insieme di interesse","title":"Measure Theory"},{"content":"https://huyenchip.com/2023/05/02/rlhf.html Ã¨ un blog post che lo descrive in modo abbastanza dettagliato e buono.\nIntroduzione a RLHF Questo Ã¨ il processo che Ã¨ quasi la migliore per la produzione di LLM moderni (maggior parte si basano su questo per dire).\nStruttura generale Si puÃ² dire che RLHF si divida in 3 parti fondamentali\nCompletion il modello viene allenato a completare parole dal web,solitamente Ã¨ molto inutile Fine tuning per le singole task, per esempio riassumere, rispondere in certo modo etc. Reinforcement Learning basato su un reward model scoperto. Partiamo con l\u0026rsquo;approccio di reinforcement learning che Ã¨ la parte un po\u0026rsquo; piÃ¹ interessante in questo momento\nHuman Feedback Introduzione al metodo Dato che utilizziamo gli LLM come aiutanti per noi umani, Ã¨ importante che il loro output sia il piÃ¹ possibile allenato sulle preferenze di noi umani. Per questo motivo dobbiamo creare un metodo che permetta di allenare il modello basandoci su queste preferenze.\nThe reward model Come descritto da (Ziegler et al. 2020), un approccio inizialmente utilizzato Ã¨ provare a definire in modo esplicito un modello $r(x, y)$ in cui $x$ Ã¨ il prompt iniziale e $y$ Ã¨ la completion data dal modello. Segue poi uno schema del genere: $y_{1}, y_{2}, y_{3}, y_{4}$ generati dal modello, poi questi vengono rankati in ordine di preferenza (oppure anche solamente il migliore fra i quattro, poi si utilizzano 4 e non due in questo papero perchÃ© cosÃ¬ una persona puÃ² scegliere, solo piÃ¹ veloce per dire). E da questo si puÃ² allenare in un modo che non ho ancora capito una cosa di preferenza.\nReferences [1] Ziegler et al. â€œFine-Tuning Language Models from Human Preferencesâ€ arXiv preprint arXiv:1909.08593 2020\n","permalink":"https://flecart.github.io/notes/the-rlhf-pipeline/","summary":"https://huyenchip.com/2023/05/02/rlhf.html Ã¨ un blog post che lo descrive in modo abbastanza dettagliato e buono.\nIntroduzione a RLHF Questo Ã¨ il processo che Ã¨ quasi la migliore per la produzione di LLM moderni (maggior parte si basano su questo per dire).\nStruttura generale Si puÃ² dire che RLHF si divida in 3 parti fondamentali\nCompletion il modello viene allenato a completare parole dal web,solitamente Ã¨ molto inutile Fine tuning per le singole task, per esempio riassumere, rispondere in certo modo etc.","title":"The RLHF pipeline"},{"content":"Bounds Markov Bound Questo bound Ã¨ abbastanza banale se fatto da un punto di vista grafico, comunque afferma che $$ P(X \\geq y) \\leq \\frac{E[X]}{y} $$ Il motivo Ã¨ che $$ yP(X \\geq y) = y\\int _{x =y}^{+\\infty} f(x) \\, dx \\leq \\int _{x=y}^{+\\infty} x f(x) \\, d \\leq \\int _{-\\infty}^{+\\infty}xf(x) \\, d = E[X] $$ Il che finisce la dimostrazione.\nChebychev Bound Questa Ã¨ una conseguenza abbastanza diretta sul bound precedente: Afferma che $$ P(\\mid x - E[X] \\mid \\geq y) \\leq \\frac{\\sigma^{2}}{y^{2}} $$ E in pratica dice che all\u0026rsquo;infinito viene tutto compattata sul valore atteso La dimostrazione Ã¨ abbastanza semplice, si sostituisce $(x - E[X])^{2}$ su $X$ di Markov e $\\varepsilon^{2}$ a $y$ e poi si dovrebbe giÃ  avere il risultato\nChernoff Bound Moments of random variable https://en.wikipedia.org/wiki/Moment-generating_function Per capire il significato di questo bound invece, Ã¨ necessario prima capire cosa sia un moment generating function. Ãˆ una funzione generale che crea i momenti di una variabile aleatoria. Un momento per una variabile aleatoria Ã¨ descrivibile come n-esimo momento: $E[X^{n}]$ La funzione generatrice dei momenti Ã¨ describile come: $$ M_{X}(\\lambda) = E[\\exp(\\lambda X)] $$ Il motivo per cui vale, Ã¨ che con l\u0026rsquo;espansione di taylor, vedi Hopital, Taylor, Peano Possiamo estrarre in modo abbastanza semplice i momenti: Infatti: $$ e^{tX} = 1 + tX + \\frac{t^{2}X^{2}}{2!} + \\frac{t^{3}X^{3}}{3!} + \\dots $$ Quindi per esempio se volessimo il primo momento, prendiamo la derivata rispetto a $t$e settiamo $t=0$, perchÃ© la cosa molto bella Ã¨ che i coefficienti si cancellano tutti, e l\u0026rsquo;unico termine che rimane senza $t$ Ã¨ il momento cercato, per questo motivo estraiamo easy i momenti.\nDimostrazione Chernoff\u0026rsquo;s Bound Anche questa Ã¨ una conseguenza abbastanza immediata di Markov, viene affermato che $$ P(Z \\geq t) \\leq \\inf_{s \u003e 0} e^{-st} M_{Z}(s) = \\inf_{s \u003e 0} e^{-st} E[e^{sZ}] $$ Guardandolo dall\u0026rsquo;altro in basso non ho idea del perchÃ© valga.\nLa dimostrazione avviene cosÃ¬ $$ P(Z \\geq t) = P(e^{sZ} \\geq e^{st}) \\leq \\frac{E[e^{sZ}]}{e^{st}} $$ Dove $s$ Ã¨ qualunque $s \u003e 0$ perchÃ© per quello la funzione resta crescente, e quindi la dimostrazione vale ancora. La cosa interessante di questo bound Ã¨ che la probabilitÃ  che succeda scende in modo esponenziale.\nHoeffding\u0026rsquo;s Inequality L\u0026rsquo;enunciato Ã¨ che se considero la somma delle classiche variabili aleatorie con stessa media varianza $S_{n}$ allora vale che, tale per cui con probabilitÃ  $1$ vale che $a_{i} \\leq X_{i} \\leq b_{i}$ $$ P(\\lvert S_{n} - \\mathbf{E}[S_{n}] \\rvert \\geq t) \\leq e^{-2t^{2}/\\sum(b_{i} - a_{i})^{2} } $$ Questo ci dice quanto velocemente la media converge nel valore atteso che ci aspettiamo per la legge dei grandi numeri\nLa dimostrazione di questo mi sembra abbastanza tecnica, c\u0026rsquo;Ã¨ bisogno di guardare https://web.eecs.umich.edu/~cscott/past_courses/eecs598w14/notes/03_hoeffding.pdf Oppure https://cs229.stanford.edu/extra-notes/hoeffding.pdf.\nNon ho bene capito l\u0026rsquo;utilitÃ  se non nel caso Bernoulliano in cui sembra si semplifichi abbastanza questo.\nLaw of Large numbers Weak Law La dimostrazione di questo Ã¨ molto semplice, basta avere Chebicheff\nQuesta Ã¨ l\u0026rsquo;intuizione di quanto presente nell WLLN Abbiamo mean square convergence.\nAbbiamo che vale:\n$$ \\mathbb{P}\\left( \\left( \\frac{S_{n} - n\\bar{X}}{n} \\right)^{2} \u003e y \\right) \\leq \\frac{\\sigma^{2}_{X}}{ny} $$ E poi settando $y = \\varepsilon^{2}$ si puÃ² avere il risultato. Nella forma corretta. Vedere capitolo 1.5 in https://ocw.mit.edu/courses/6-262-discrete-stochastic-processes-spring-2011/resources/mit6_262s11_chap01/.\nSi puÃ² scrivere: $$ \\lim_{ n \\to \\infty } E \\left[ \\left( \\frac{S_{n}}{n} - \\bar{X} \\right)^{2} \\right] = 0 $$ In questo senso possiamo dire che la successione $S_{n}$ arriverÃ  sempre alla media.\nRicordiamo che $S_{n} = X_{1} + X_{2} + \\dots + X_{n}$. Dove tutte le variabili $X_{i}$ sono IID con media $\\bar{X}$ e varianza $\\sigma^{2}$.\nWeak law without finite variance Potremo scrivere $$ \\lim_{ n \\to \\infty } \\mathbb{P}\\left( \\mid \\frac{S_{n}}{n} - E[X]\\mid \u003e \\varepsilon \\right) = 0 $$ Teorema 1.5.3 nelle note.\nConvergence types Per qualche motivo che non ho ancora capito Ã¨ importante andare a distinguere tipologie di convergenza diverse fra di loro.\nConvergence in distribution Una sequenza di variabili aleatorie $Z_{1}, Z_{2}, \\dots$ converge in distribuzione se vale $$ \\lim_{ n \\to \\infty } F_{Z_{n}}(z) = F_{Z}(z) $$ Per ogni $z$ in cui $F_{Z}(z)$ Ã¨ continua. Una sequenza di distribuzioni che converge a una distribuzione. Un esempio in cui questo vale Ã¨ il central limit theorem in cui definiamo $$ Z_{n} = \\frac{S_{n} -n\\bar{X}}{\\sigma \\sqrt{ n }} $$ Converge alla normale, 0, 1 gaussiana. Un altro esempio Ã¨ la weak law of large numbers, in cui $\\frac{S_{n}}{n}$ converge a $\\bar{X}$.\nConvergence in probability Se prendiamo una sequenza $Z_{1}, Z_{2}, \\dots$ a $Z$ se vale $$ \\lim_{ n \\to \\infty } P(\\mid Z_{n} - Z\\mid \u003e \\varepsilon) = 0 $$ Vale anche qui l\u0026rsquo;esempio della WLLN.\nConvergence in mean square Una sequenza di $Z_{1}, Z_{2}, \\dots$ converge in mean square a $Z$ se vale $$ \\lim_{ n \\to \\infty } E[(Z_{n} - Z)^{2}] = 0 $$ La nota Ã¨ che Mean Square -\u0026gt; Convergence probability -\u0026gt; Convergence in distribution.\nConvergence almost everywhere (Il prof. lo chiama with probability 1 e secondo lui serve sapere measure theory per poter comprendere la definizione originale).\nDefiniamo una sequenza $Z_{1}, Z_{2}, \\dots$ e $\\Omega$ il suo spazio campionatorio e sia $Z$ una altra variabile aleatoria, allora la sequenza converge con probabilitÃ  1 se vale\n$$ \\mathbb{P}(\\{\\omega \\in \\Omega : \\lim_{ n \\to \\infty }Z_{n}(\\omega) = Z(\\omega) \\}) = 1 $$ Ossia, per definizione di variabile aleatoria $Z_{n}(\\omega)$ Ã¨ un valore reale, queste sequenze di numeri reali a volte convergono, se convergono vogliamo che il valore sia esattamente $Z(\\omega)$. Quello che vogliamo dire con questo Ã¨ che la probabilitÃ  degli elementi dello spazio campionatorio che creano sequenze che convergono Ã¨ uguale a 1.\nThe strong Law Central Limit Theorem The Bernoulli Case The theorem $$ \\lim_{ n \\to \\infty } \\left[ \\mathbb{P}\\left( \\frac{S_{n} - n\\bar{X}}{\\sqrt{ n }\\sigma} \\leq y \\right)\\right] = \\int_{-\\infty}^{y} \\frac{1}{\\sqrt{ 2\\pi }} \\exp\\left( -\\frac{x^{2}}{2} \\right) \\, dx $$ Ossia che la sequenza di variabili aleatorie $$ Z_{i} = \\frac{S_{i} - n\\bar{X}}{\\sqrt{i} \\sigma} $$ ConvergerÃ  alla gaussiana normale. Ãˆ un motivo per cui Ã¨ una distribuzione molto importante.\n","permalink":"https://flecart.github.io/notes/central-limit-theorem-and-law-of-large-numbers/","summary":"Bounds Markov Bound Questo bound Ã¨ abbastanza banale se fatto da un punto di vista grafico, comunque afferma che $$ P(X \\geq y) \\leq \\frac{E[X]}{y} $$ Il motivo Ã¨ che $$ yP(X \\geq y) = y\\int _{x =y}^{+\\infty} f(x) \\, dx \\leq \\int _{x=y}^{+\\infty} x f(x) \\, d \\leq \\int _{-\\infty}^{+\\infty}xf(x) \\, d = E[X] $$ Il che finisce la dimostrazione.\nChebychev Bound Questa Ã¨ una conseguenza abbastanza diretta sul bound precedente: Afferma che $$ P(\\mid x - E[X] \\mid \\geq y) \\leq \\frac{\\sigma^{2}}{y^{2}} $$ E in pratica dice che all\u0026rsquo;infinito viene tutto compattata sul valore atteso La dimostrazione Ã¨ abbastanza semplice, si sostituisce $(x - E[X])^{2}$ su $X$ di Markov e $\\varepsilon^{2}$ a $y$ e poi si dovrebbe giÃ  avere il risultato","title":"Central Limit Theorem and Law of Large Numbers"},{"content":"Ripasso Prox: 40 Ripasso: June 21, 2022 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: February 21, 2022 1:20 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\n8 Integrali 8.1 Introduzione 8.1.1 Il problema che risolve Vogliamo cercare di creare un metodo matematico che sia utile per calcolare area di qualunque curva.\nL\u0026rsquo;idea principale per risolvere questo problema Ã¨ approssimare l\u0026rsquo;area, lo facciamo utilizzando rettangoli, la formalizzazione sarÃ  molto aiutata dal limite.\n8.1.2 Sottografico di funzione $$ A = \\{ (x,y) \\in \\R^2 | x \\in D(f(x)), 0\\leq y \\leq f(x)\\} $$ Praticamente sto prendendo tutti in punti positivi sotto al grafico.\n8.2 Somma di Riemann La somma di riemann sta alla base della definizione di integrale.\n8.2.1 Intuizione a rettangoli Vorremmo cercare di approssimare l\u0026rsquo;area del grafico utilizzando un sacco di rettangoli di stessa ampiezza\n8.2.2 Definizione (formula) Diviso l\u0026rsquo;intervallo di interesse, che chiamiamo $[a,b]$ con n intervalli di stessa lunghezza, e presa in questi $\\xi_k$ n punti a caso per ogni intervallo, allora consideriamo la somma di Riemann:\n$$ h = \\dfrac{b- a}{n},\\\\ S = \\sum_{i=1}^nf(\\xi_i) \\cdot h $$ 8.3 Integrale di Riemann 8.3.1 Criterio di integrabilitÃ  secondo Riemann Se una funzione Ã¨ continua su un certo intervallo, allora Ã¨ integrabile secondo Riemann qui\nDimostrazione (Non richiesta) Servono teoremi che non hai mai fatto tipo heine borel etc. 8.3.2 Osservazioni su questo integrale $\\int_a^af(x) = 0$ perchÃ© si puÃ² notare che l\u0026rsquo;ampiezza del rettangolo Ã¨ 0, quindi sto sommando uno 0. Nel caso di funzione costante\u0026hellip;. bah non lo scrivo nemmeno perchÃ© se ragioni sulla somma di Riemann Ã¨ abbastanza banale. 8.3.3 ProprietÃ  dellâ€™integrale LinearitÃ  (se ho f, g continue sullo stesso intervallo, allora l\u0026rsquo;integrale della funzione somma Ã¨ uguale alla somma degli integrali singoli). (posso anche moltiplicare per un fattore e considerare la funzione fattore * f, o fattore * g).\nAdditivitÃ , posso dividere l\u0026rsquo;intervallo su cui sto integrando come la somma di due intervalli che coprono tutto l\u0026rsquo;intervallo iniziale\nConvenzione: se b\u0026lt;a e ho un integrale tipo cosÃ¬ $\\int^b_a = -\\int^a_b$, ovvero cambio il segno. Questa convenzione mi permette di scriverlo per ogni punto (basta che sia continuo).\nMonotonia, (se ho due funzioni definite in un intervallo in cui entrambe sono continue tali che f \u0026lt; g, allora anche l\u0026rsquo;integrale possiede questa disuguaglianza).\n8.3.4 Teorema della media integrale In modo simile alla media finita, in cui andiamo a dividere il numero di addendi per il valore della somma totale, possiamo andare a definire una media anche per gli integrali.\nPartiamo dalla somma di Riemann, per poi andare dalla media integrale:\n$$ \\text{INTUIZIONE: }S_n = \\sum^n_{k=1} f(\\xi_k)\\dfrac{b-a}{n} \\implies \\dfrac{S_n}{b-a} = \\dfrac{\\sum^n_{k=1}f(\\xi_k)}{n} $$ $$ f:[a,b] \\to \\mathbb{R} \\text{ continua }\\\\ \\exists c \\in [a,b] \\, t.c. \\,\\\\ \\dfrac{1}{b-a} \\int_a^bf(x)dx = f(c) $$ Dimostrazione: Si utilizza il teorema del valore intermedio: qui in passato $\\exists x_0, x_1 \\in [a,b]$, questi sono scelti in modo tale per cui $f(x_0) = min, f(x_1) = max$ che Ã¨ effettivamente ciÃ² che dice weierstrass per l\u0026rsquo;estremo valore, poi utilizziamo la definizione di funzione per diree che esitono anche tali x0 e x1, per ricordarci delle loro proprietÃ  li chiamiamo m e M sotto. $$ \\exists m, M \\in [a,b]\\text{ che diano massimo e minimo per weierstrass, ovvero che:} \\\\ f(m) \\leq f(x) \\leq f(M) \\, \\forall x \\in [a,b] \\text{ utilizziamo la monotonia dlel'integrale} \\\\ \\int_a^b f(m)dx \\leq \\int_a^b f(x)dx \\leq \\int_a^b f(M)dx ,\\\\\\text{ noto che alcuni sono costanti, allora} \\\\ f(m)(b-a) \\leq \\int_a^b f(x)dx \\leq f(M)(b-a) \\implies f(m) \\leq \\dfrac{1}{b-a} \\int_a^b f(x)dx \\leq f(M) $$ Arrivati all\u0026rsquo;ultimo passo allora possiamo dire che esiste un tale c, grazie al teorema del valore intermedio.\nMini riassunto del valore intermedio (che serve qui)\nUna funzione continua su un intervallo per Weierstrass possiede un minimo e un massimo, grazie al teorema degli zeri possiamo costruirci una funzione tale per cui si annulli per qualunque punto all\u0026rsquo;interno di questo intervallo. CioÃ¨ possiamo concludere che\n$\\forall y \\in [m,M], \\exists c \\in [a,b] | f(c) = y$\n8.4 Primitiva e f integrale 8.4.1 La primitiva Una primitiva F di una funzione f Ã¨ una funzione definita nello stesso intervallo tale per cui per tutti i valori si ha che F\u0026rsquo;(x) = f(x).\n8.4.2 UnicitÃ  della primitiva La funzione primitiva Ã¨ unica a meno di una costante, in un intervallo ben definito. Possiamo osservare che esistono infinite primitive aggiungendo costanti.\nMa si puÃ² dire che questa funzione Ã¨ unica in quanto:\nDimostrazione\nSiano f e g primitive di una funzione a. Allora consideriamo la funzione h definita come f - g. Ã¨ chiaro che la sua derivata Ã¨ a - a, quindi 0, quindi la sua derivata Ã¨ sempre 0.\nPer una conseguenza del teorema di lagrange ho che h deve essere una constante. Per cui si ha la relazione f = g + C. e abbiamo trovato che le funzioni primitive sono tutte a meno di costante\nI capitoli sotto sono probabilmente utili per altre cose dopo\n8.4.3 La funzione integrale Sia f una funzione continua definita su un certo intervallo. sia c un punto in questo intervallo, allora posso avere una funzione I tale che\n$$ I_c(x) = \\int^x_cf(t)dt $$ Ovvero sto prendendo tutta l\u0026rsquo;area da un punto a un punto di input di variabile per una certa funzione. chiamo c punto base.\n8.4.4 Osservazione sulla funzione integrale (fondamentale 1) Sia $f$ continua su $(a_0, b_0)$ sia $c \\in (a_0, b_0)$ allora $\\forall x \\in (a_0, b_0)$ ho che $I_c'(x) = f(x)$\nAccenno di dimostrazione mia\nvogliamo f(x) continua e definita in un intervallo.\nLa funzione integrale sarÃ  fondamentale poi per il calcolo integrale. Possiamo relazionarla strettamente con la funzione primitiva, in quanto se fosse una primitiva, sarebbe uguale a un integrale che ci piace. Proviamo a giustificare questa cosa, proviamo a prenderne la sua derivata:\n$$ \\dfrac{I_c(x) - I_c(x_0)}{x - x_0} = \\dfrac{\\int^x_cf(x)dx - \\int^{x_0}_c f(x)dx}{x - x_0} = \\dfrac{\\int_{x_0}^xf(x)dx}{x - x_0} $$ E questa ultima cosa esiste, ed Ã¨ compresa fra il massimo e il minimo della funzione f(x) per il teorema della media integrale.\nNon siamo stati abbastanza formali per la dimostrazione di esistenza della derivata. Vogliamo dire che\n$$ \\lim_{x \\to x_0}\\dfrac{\\int_{x_0}^xf(x)dx}{x - x_0} = f(x) $$ Andiamo a dividere la dimostrazione di questo limite in limite destro e limite sinistro.\nVogliamo creare una successione (perchÃ© l\u0026rsquo;equivalente Ã¨ una cosa reale, si puÃ² dimostrare).\nPer media integrale diciamo che $\\exists c, x_0 \\leq c \\leq x : f(c) = \\dfrac{\\int_{x_0}^xf(x)dx}{x - x_0}$ , riusciamo quindi per ogni succesione xn che tende a x0 trovare una successione cn che tenda a x0 per carabinieri, quindi esiste questo limite ed Ã¨ uguale a f(x), si fa la stessa cosa con l\u0026rsquo;altro.\nDimostrazione nelle note del prof\n8.4.5 Tutte le funzioni integrali di f differiscono per una costante Una cosa molto simile alle funzioni primitive! basta svolgere i calcoli in modo simile alla funzione integrale con c diversi ðŸ™‚ e ottengo che la loro differenza Ã¨ sempre una costante! Questo mi fa pensare che potrebbe essere una primitiva! E infatti per 8.4.4 lo Ã¨\n8.4.6 Teorema di Torricelli (fondamentale del calcolo integrale) Enunciato\nData una funzione f definita in un intervallo aperto in R continua, e una altra funzione primitiva della prima F, allora si ha\n$\\int^b_af(x)dx = F(b) - F(a)$\nDimostrazione mia\nSia c un numero reale a Caso, sia $I_c(x)$ la funzione integrale relativa a $f$, per dimostrazione precedente ho che $I_c(x)$ Ã¨ una primitiva di $f$, allora per l\u0026rsquo;unicitÃ  della primitiva a meno di costante ho che $I_c(b) - I_c(a) = F(b) - F(a)$ (tolto costanti e simili)\n8.4.7 Fondamentale del calcolo generalizzato Enunciato\nSia $f: I\\to\\R \\text{ continua}\\\\ h: \\R \\to I \\text{ derivabile}$, vogliamo calcolare l\u0026rsquo;integrale di sopra. e sia $A_c(x)$ la funzione integrale\nAllora vale che $D(A(h(x)) = D(\\int_c^{h(x)}f(t)dt) = f(h(x))h'(x)$\nVorrei dimostrare in questo teorema la possibilitÃ  di valutare l\u0026rsquo;integrale con una altra variabile.\nad esempio come calcolare\n$$ \\int_c^{g(x)}f(x)dx $$ E vogliamo ricondurci a funzioni integrali normali.\nInnanzitutto proviamo a ricordare alcuni risultati passati (derivata di funzione composta e il fondamentale).\nRisultati passati utili ora\nSia I un intervallo di R, sia $I_c(x) = \\int _c^xf(t)dt$ per il teorema fondamentale ho che $I_c'(x) = f(x)$ in ogni punto.\nConsidero ora $H_c(x) = \\int_x^cf(x)dt$, questo, grazie alla convenzione sugli integrali Ã¨ uguale a $-I_c(x)$\nDimostrazione\nPrendiamo l\u0026rsquo;integrale\n$$ \\forall z \\in I, I_c(z) = \\int_c^zf(t)dt $$ Allora se semplicemente sostituisco h(x) a z, allora sto facendo questo\n$I_c(h(x)) = \\int _c^{h(x)}f(t)dt$, che non Ã¨ altro che una funzione composta.\nProviamo allora a prenderne la derivata, che per il teorema fondamentale del calcolo integrale Ã¨ f(x). Quindi\n$$ f(x) = I_c'(x) \\text{ dal teorema fondamentale} \\\\ D(I_c(h(x)) = h'(x)I_c'(h(x)) \\text{ dalla derivata di f composta} \\\\ h'(x)I_c'(h(x)) = h'(x)f(h(x)) \\text{ sostituendo} $$ 8.4.8 Integrale generalizzato (Integrale funzioni con discontinuitÃ ) !! Possiamo andare a definire un intervallo di integrazione infinito, come $0, +\\infty$, basta definirlo con un limite.\nse esiste il limite (altrimenti non Ã¨ definito) e si definisce in modo analogo per il infinito negativo.\n$$ \\lim_{z\\to+\\infty} \\int^z_af(x)dx = \\int^{+\\infty}_a f(x)dx $$ 8.5 Calcolo di integrali 8.5.1 Tabella degli integrali Sono pigro per scrivere tutti\n8.5.2 Funzioni composte siano due funzioni componibili (quindi dominio codominio compatibili).\nLa primitiva di una funzione\n$$ g \\cdot f = \\int g'(f(x))f'(x) $$ 8.5.3 Integrazione per parti notiamo che\n$D(F(x)g(x)) = f(x)g(x) + F(x)g'(x)$\nSe prendiamo ora l\u0026rsquo;integrale da entrambe le parti e giriamo un pÃ² di cose riusciamo a trovare l\u0026rsquo;integrale che cerchiamo, in questo senso\n$$ \\int f(x)g(x) = F(x)g(x) - \\int F(x)g'(x) $$ Questo Ã¨ dimostrabile grazie al teorema fondamentale, che dice qualcosa a riguardo la derivata di una primitiva Ã¨ la funzione integranda di un integrale.\nAlcune funzioni classiche che si fanno per parti\n$f(x) = xe^x$\n$f(x) = ln(x)$\n$x^n \\arctan(x)$\n8.5.4 Sostituzione (cambio di variabile) Un pÃ² di teoria:\nsia h una funzione doppiamente derivabile da I in J, e f una funzione continua da J a R, allora, dati alpha e beta in I, si ha questa relazione:\n$$ \\int_{h(\\alpha)}^{h(\\beta)}f(x)dx = \\int_\\alpha^\\beta f(h(t))h'(t)dt $$ La dimostrazione si ha con il teorema fondamentale dell\u0026rsquo;integrale generalizzato, piÃ¹ precisamenta guardare il toggle sotto.\ndimostrazione\nVogliamo dimostrare che una funzione integranda in\nSiano F, G due funzioni da I a R, voglio dimostrare che\n$F(z) = \\int_{h(\\alpha)}^{h(z)} f(x)dx, G(z) = \\int_\\alpha^z f(h(x))h'(x)dx$ queste due siano uguali\nCerco di dimostrare che abbiano la stessa derivata (per cui le funzioni originali distano al massimo di una costante) e che siano uguali in un punto (per cui sono uguali ovunque).\nL\u0026rsquo;ultima tesi si fa in modo immediato perchÃ© sto provando ad integrale in un unico punti, quindi sono entrambe 0.\n$G'(z) = f(h(z))h'(z)$ per la prima versione del teorema fondamentale del calcolo\n$F'(z) = f(h(z))h'(z)$ per la dimostrazione precedente in questo passo, quindi sono la stessa funzione.\nQuesto termina la dimostrazione\nesempio (sostituendo con t^2)\n$$ \\int e^{\\sqrt{x}}dx = 2e^{\\sqrt{x}}(\\sqrt{x} - 1) + c $$ ","permalink":"https://flecart.github.io/notes/integrali/","summary":"Ripasso Prox: 40 Ripasso: June 21, 2022 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: February 21, 2022 1:20 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\n8 Integrali 8.1 Introduzione 8.1.1 Il problema che risolve Vogliamo cercare di creare un metodo matematico che sia utile per calcolare area di qualunque curva.\nL\u0026rsquo;idea principale per risolvere questo problema Ã¨ approssimare l\u0026rsquo;area, lo facciamo utilizzando rettangoli, la formalizzazione sarÃ  molto aiutata dal limite.","title":"Integrali"},{"content":"Ripasso Prox: 36 Ripasso: June 6, 2023 Ultima modifica: May 9, 2023 10:02 PM Primo Abbozzo: March 23, 2023 1:29 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Memoria sistema Operativo Guradare Memoria virtuale Per vedere come vengono rimpiazzate le pagine\nIn quest sezione andiamo a parlare di come fanno molti processi a venire eseguiti insieme, anche se lo spazio di memoria fisico Ã¨ lo stesso. Andiamo quindi a parlare di spazio di indirizzi, risoluzione di questi indirizzi logici, segmentazione e paginazione. (e molto di piÃ¹!)\nMMU Controlla se lâ€™accesso di memoria Ã¨ bono o meno. (traduzione fra indirizzo logico e fisico)\nCosa succederebbe se non fosse hardware?\nLa performance sarebbe molto peggiore. Sicurezza, si dovrebbe implementare uno mode switch e andare al kernel mode per accedere (syscall per accedere ad indirizzi di memoria), quindi non si utilizza mai, perchÃ© sarebbe ancora piÃ¹ lentooo. Memory manager ðŸŸ© Its job is to keep track of which parts of memory are in use and which parts are not in use, to allocate memory to processes when they need it and deallocate it when they are done, and to manage swapping between main memory and disk when main memory is too small to hold all the processes. (pg. 373 Tanenbaum)\nCOSA FA il MMEMORY MANAGER?\nTiene traccia della memoria libera Configura la MMU Binding (3) ðŸŸ© In questo caso parliamo di associazione fra indirizzi logici e indirizzi fisici, in pratica ad altro livello, ma la stessa cosa. Nomi e Scope parliamo di binding fra variabili e nome della variabile.\nLÃ¬ abbiamo deciso 4 modi in cui si puÃ² fare il binding! Sono molto simili rispetto a quelle, perÃ² ora stiamo parlando a un livello piÃ¹ basso.\nBINDING A COMPILAZIONE\nDue istanze del programma non possono mai essere eseguiti CONTEMPORANEAMENTE, come per microcontrollori si puÃ² fare una cosa simile.\nChiamato codice assoluto. perchÃ© Ã¨ mappato direttamente in una certa zona in fase di compilazione, non cambierÃ  MAI.\nStessi indirizzi per ogni esecuzione del programma.\nSlide binding compilazione\nSlide vantaggi e svantaggi\nBINDING A CARICAMENTO\nTutti gli indirizzi sono offsettati da un indirizzo 0.\nIn questo senso quando carico una istanza del programma, basta offsettare tutti gli indirizzi a un certo punto.\nSlide binding a caricamento\nSlide vantaggi e svantaggi\nSi pone piÃ¹ onere al loader che deve sapere dove caricarti la roba. PerÃ² anche qui niente hardware!\nBINDING A ESECUZIONE\nAnche qui câ€™Ã¨ lâ€™offset, ma Ã¨ piÃ¹ fine. Lâ€™eseguibile pensa di avere gli indirizzi offsettati da 0, poi a runtime la MMU traduce questo indirizzo logico allâ€™indirizzo reale, che Ã¨ offsettato a qualcosa.\nSlide binding a esecuzione\nRegistri MMU Registro di locazione ðŸŸ© In pratica abbiamo una tabella, molto simile a una tabella Network Address Translation di rete, ma con scopi molto diversi.\nAllo stesso modo in cui un pacchetto entra, viene fatto match nella tabella ed esce in modo diverso, abbiamo una registro di rilocazione che fa lo stesso JOB.\nSlide Registro di rilocazione\nSolitamente\nCodice Dati Stack Extra (utilizzi speciali, tipo copia da stack a dato o simili, praticamente usi come ti pare). Registro di limite ðŸŸ© Questo nuovo registro permette di fare controlli sulla sicurezza. Praticamente fa check su indirizzi, se lâ€™indirizzo soddisfa regola e.g. maggiore di 1000 allora manda avanti, altrimenti in errore\nSlide registro di limite\nLoading dinamico ðŸŸ© Routine vengono caricate solo quando le chiamo, le abbiamo giÃ  fatte in archietttura quando abbiamo parlato di traslazione di indirizzi dinamici 9.4.4 Indirizzamento dinamico. Generava una trap, e poi veniva trovato lâ€™indirizzo corretto.\nLINKING STATICO E DINAMICO\nNota Loading â‰  Linking!, perÃ² posso fare loading dinamico con linking dinamico. ðŸ˜€\nStatico invece Ã¨ quando lâ€™eseguibile ha tutte le funzioni che gli servono (copiate e incollate dentro lâ€™eseguibile, senza dipendenze esterne, molto piÃ¹ pesante, ma Ã¨ isolato, diciamo).\nSlide vantaggi svantaggi\nMINIDEMO LOADING\nProva a compilare un file e poi compilare con\n#include \u0026lt;stdio.h\u0026gt; int main() { puts(\u0026#34;eee\u0026#34;); } gcc -o out prova.c, normalmente linka dinamicamente, che puoi vedere con nm,\nse runni con la flag -static e fai la stessa cosa, allora vedi che il sinbolo Ã¨ definito.\nAllocazione pagine Definizioni: ðŸŸ© ALLOCARE: Significa assegnare spazio di memoria fisica al programma.\nSTATICA DINAMICA,: se resta per l\u0026rsquo;intera vita del programma o meno.\nCONTIGUA O NON CONTIGUA: se la memoria mappata Ã¨ tutta a un filo senza buchi o meno.\nSlide definizioni\nPartizioni fisse ðŸŸ¨ Questa Ã¨ una tecnica molto simile alla gestione della heap in blocchi fissi Gestione della memoria. In pratica ho delle partizioni fisse.\nSlide partizioni fisse\nSolitamente sono utili per sistemi Embedded, in cui non vuoi perdere tempo a fare conversioni, e vuoi questa cosa statica.\nPoi câ€™Ã¨ di nuovo il pippone della frammentazione interna ed esterta presente in Gestione della memoria, e in Livello OS. Si parla anche di soluzioni a questo, come la compattazione, ne abbiamo giÃ  parlato, quindi qui sto zitto.\nNOTA SULLA COMPATTAZIONE:\nQuando voglio fare compattazione, devo interrompere certi programmi, copiare tutto il programma ad indirizzo diverso, cambio indirizzo di allocazione e poi lo posso far ripartire (quindi da stato running a ready dopo queste operazioni), perÃ² lentissimo!.\nBitmap ðŸŸ© In pratica tutta la memoria viene divisa in qualche chunks di memoria, per esempio se ho in totale 1024 byte di memoria, potrei dividerla in blocchi da 32 byte, allora mi tengo una bitmap di 1024 /32 = 32, cosÃ¬ so che mi dovrÃ² tenere una bitmap di 32 bits, un bit mi indica 1 se ho usato quel blocco, 0 altrimenti.\nPer allocare in questa struttura di dati basta andare a cercare una serie di blocchi contigui liberi.\nSlide bitmap\nLinked list ðŸŸ© Tutti i blocchi sono tenuti in una lista linkata, che ha un booleano per indicare se Ã¨ occupato o meno, e poi la lunghezza. Lâ€™allocazione Ã¨ uno scorrimento di questa lista linkata.\nSlide linked list\nQuando vengono deallocati, si puÃ² utilizzare la compattazione parziale di cui abbiamo parlato in Gestione della memoria.\nSlide compattazione parziale\nCi sono altri generi di algoritmi, come next fit, oppure worst fit, perÃ² alla fine hanno performance molto peggiori rispetto a first o best fit. In generale questi problemi fanno ancora frammentazione, quindi non Ã¨ che siano buone buone buone come cose.\nPaginazione Le tecniche di paginazione nascono per essere una alternativa molto piÃ¹ efficiente rispetto ai metodi di fitting precedenti, per questo motivo ora andiamo a descriverlo:\nAndare a guardare Algoritmi di paging per capire in che modo vengono gestite le pagine.\nDescrizione idee generale ðŸŸ© La memoria del programma Ã¨ divisa in pagine, e poi questo Ã¨ messo nella memoria fisica dette frame, e sarÃ  gestita dalla MMU. La frammentazione interna esiste ma Ã¨ molto minimo, la frammentazione esterna non esiste proprio ora.\nSlide esempio di paginazione\nImplementazione della paginazione ðŸŸ© Questa Ã¨ esattamente la parte che abbiamo spiegato in Livello OS, in pratica, l\u0026rsquo;indirizzo logico viene diviso in indirizzo di paginazione e indirizzo di memoria dentro la pagina stessa\nPer esempio se ho 4096 bit per una singola pagina (standard attuale), ho che nellâ€™intero indirizzo della pagina Ã¨ data dai primi 20 bit, l\u0026rsquo;inddirizzo allâ€™interno della pagina dai next 12.\nEsempio di utilizzo della paginazione\nDESIGN DELLA PAGINAZIONE\nBlocchi potenza di due cosÃ¬ Ã¨ facile dividere gli indirizzi senza altre conversioni Non troppo grosso, cosÃ¬ fa meno frammentazione Non troppo piccolo, cosÃ¬ non ho troppe pagine. Storare la tabella delle pagine (2) ðŸŸ© Dobbiamo trovare un modo per storare la tabella delle pagine, per esempio con un giga di memoria sarebbero circa un milione di pagine, storare in una tabella stile registri (come NAT di reti) Ã¨ troppo costoso come metodo.\nMettere in memoria, dovresti fare due accessi una nella page table, e una in memoria (e quindi molto lento!).\nQuindi vogliamo fare qualcosa di mezzo:\nLa page table sta in memoria In MMU sta una cache della page table per risoluzione di indirizzi recenti, guarda Memoria, questa si chaima Translation lookaside buffer, utilizzata la tecnica dei registri associativi, quelli che abbiamo utilizzato nell\u0026rsquo;implementazione dei Router in Data Plane, praticamente ti fanno ili confronto in modo immediato. Slide TLB\nEsempio tabella di pagine nuovo\nQuando il TLB missa, crea una trap, e iil sistema operativo rimette nella TLB quello che manca. Solitamente se sono grandi 10 celle Ã¨ giÃ  sufficiente, perchÃ© principio di localitÃ  Ã¨ molto imporntante\nSegmentazione Introduzione idee segmentazione ðŸŸ© Anche questo ne abbiamo giÃ  parlato in architettura Livello OS.\nComunque divido il programma logicamente in diverse sezioni\nConcettualmente diversi (quindi regole di accesso diverse)\nLe singole aree contengono codice omogeneo (e.g. Testo â†’ area codice).\nEsempio di aree di segmentazione\nAllora se dividiamo in questo modo individiamo l\u0026rsquo;indirizzo logico come\n(nome-segmento, offset del segmento) â†’ indirizzo fisico.\nMa come fare a ricondurre questo con le pagine? Come metterlo dentro la MMU?\nVedremo lâ€™utilizzo di una tecnica ibrida che unisce segmentazione con paginazione.\nConfronto con paginazione (!) ðŸŸ¨+ Slide differenze segmentazione e paginazione\nAllocare segmenti in memoria Ã¨ totalmente simile allâ€™allocazione di zone di memoria contigue in memoria quindi devo tornare ad utilizzare algoritmi per memoria continua, per questo motivo ho forti problemi di frammentazione, quindi torno ad avere problemi come in precedenza!\nImplementazione segmentazione ðŸŸ© Per i motivi di sopra, utilizzo la paginazione per andare con segmentazione, divido i segmenti in pagine!\nQuesto implica aumento della frammentazione interna. dato che per ogni segmento posso perdere pezzi nella pagina allocata (perÃ² alla fine Ã¨ molto ininfluente, al massimo 4k di ram per pagina)\nImplementazione slide\nEccesso del segmento â†’ segmentation fault ecco da dove deriva il nome ðŸ˜€\n","permalink":"https://flecart.github.io/notes/paginazione-e-segmentazione/","summary":"Ripasso Prox: 36 Ripasso: June 6, 2023 Ultima modifica: May 9, 2023 10:02 PM Primo Abbozzo: March 23, 2023 1:29 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Memoria sistema Operativo Guradare Memoria virtuale Per vedere come vengono rimpiazzate le pagine\nIn quest sezione andiamo a parlare di come fanno molti processi a venire eseguiti insieme, anche se lo spazio di memoria fisico Ã¨ lo stesso. Andiamo quindi a parlare di spazio di indirizzi, risoluzione di questi indirizzi logici, segmentazione e paginazione.","title":"Paginazione e segmentazione"},{"content":"Introduzione sui requisiti del software Note introduttive In linguaggio naturale (dizionario) ðŸŸ¥+ Sono tutte le qualitÃ  necessarie per uno scopo ben determinato.\nSecondo il prof. I requisiti sono dei desideri ossia ciÃ² che idealmente vorresti riguardo qualcosa (nel nostro caso il software). Ma credo sia anche una tendenza italiana di fare le cose meglio possibile senza mai soddisfare tutto\nFunctional requirements ðŸŸ© Sono ciÃ² che permetterÃ  di fare il sistema\nEsempio:\nIl sistema permetterÃ  di prenotare un taxi e di avere una stima del tempo di attesa\nNel nostro caso possiamo anche definire scenario ossia un caso di utilizzo concreto del sistema e user story come ciÃ² che il cliente vuole che il sistema debba fare.\nLegge di Humphrey ðŸŸ¨- I requisiti di un nuovo prodotto software non saranno chiari finchÃ© gli utenti non iniziano a usarlo\nOssia finchÃ© non ho una prima soluzione, non so bene cosa voglio -\u0026gt; \u0026ldquo;I\u0026rsquo;ll know it when I\u0026rsquo;ll see it\u0026rdquo;. In un certo senso questo giustifica anche la scelta di iniziare a costruire subito, perchÃ© prima non puoi sapere, quindi non puoi farne un design. Quando hai una prima versione, poi puoi iterarci.\nProcesso di analisi del requisito (3) ðŸŸ¨++ Ãˆ una analisi preliminare, ossia prima ancora di iniziare lo sviluppo e serve per:\nCapire ciÃ² che vuole il cliente (quindi le funzionalitÃ  che deve avere il sistema finale). Questo Ã¨ stabilito senza sapere come effettivamente viene implementato il sistema. Cosa deve soddisfare il sistema, quindi una proprietÃ  Test per verifica dei requisiti, quindi capire esattamente cosa testare, perchÃ© la proprietÃ  possa essere verificabile Vincoli per esempio di sistema operativo, o risorse (quindi giochi per esempio), oppure di tempo, per esempio in cose real time. (o ciÃ² che deve essere costruito, cose funzionali) Requisiti in livelli diversi ðŸŸ¨- Certe formulazioni di requisiti sono piÃ¹ utili a certe parti d\u0026rsquo;azienda, dipende dal livello di astrazione che deve avere il requisito. vedere il triangolino in immagine: User Personae ðŸŸ© Sono degli utenti ideali, che dovrebbero essere i nostri utenti. Esempio: Ci chiediamo cosa fa questo utente ideale? Quali sono i suoi obiettivi? Cosa fa di solito di abitudine?\nBacklog management Digital product management Passi per la creazione del prodotto digitale (3) ðŸŸ¨\u0026ndash; Ricerca di mercato: ci chiediamo quali sono i prodotti utili? Ideazione del prodotto: quali sono i target principali? Cosa deve essere il prodotto? Per chi Ã¨ buono il prodotto? Requisiti del prodotto piano dettagliato di tutti i requisiti ","permalink":"https://flecart.github.io/notes/requisiti-e-backlog-del-software/","summary":"Introduzione sui requisiti del software Note introduttive In linguaggio naturale (dizionario) ðŸŸ¥+ Sono tutte le qualitÃ  necessarie per uno scopo ben determinato.\nSecondo il prof. I requisiti sono dei desideri ossia ciÃ² che idealmente vorresti riguardo qualcosa (nel nostro caso il software). Ma credo sia anche una tendenza italiana di fare le cose meglio possibile senza mai soddisfare tutto\nFunctional requirements ðŸŸ© Sono ciÃ² che permetterÃ  di fare il sistema","title":"Requisiti e backlog del software"},{"content":"Ultima modifica: November 3, 2021 11:27 AM Primo Abbozzo: November 3, 2021 11:24 AM Studi Personali: No\nCosto computazionale In modo intuitivo il costo in tempo Ã¨ il numero di cicli di clock che il computer deve avere per forza per finire l\u0026rsquo;esecuzione di un codice.\nSi cerca di avere un costo massimo quindi possiamo fare per casi:\nCosto condizionale Costo guardia piÃ¹ max guardia\ncosto_della_guardia + max(costo_ramo_then, costo_ramo_else)\nCosto iterativo numero_iterazioni*(costo_della_guardia+costo_del_corpo) + costo della guardia dia piÃ¹ max guardia\ncosto_della_guardia + max(costo_ramo_then, costo_ramo_else)\nCosto iterativo numero_iterazioni*(costo_della_guardia+costo_del_corpo) + costo della guardia\n","permalink":"https://flecart.github.io/notes/costo-computazionale/","summary":"Ultima modifica: November 3, 2021 11:27 AM Primo Abbozzo: November 3, 2021 11:24 AM Studi Personali: No\nCosto computazionale In modo intuitivo il costo in tempo Ã¨ il numero di cicli di clock che il computer deve avere per forza per finire l\u0026rsquo;esecuzione di un codice.\nSi cerca di avere un costo massimo quindi possiamo fare per casi:\nCosto condizionale Costo guardia piÃ¹ max guardia\ncosto_della_guardia + max(costo_ramo_then, costo_ramo_else)\nCosto iterativo numero_iterazioni*(costo_della_guardia+costo_del_corpo) + costo della guardia dia piÃ¹ max guardia","title":"Costo computazionale"},{"content":"Ripasso Prox: 60 Ripasso: May 18, 2023 Ultima modifica: May 12, 2023 7:59 PM Primo Abbozzo: September 19, 2022 11:11 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Vecchi ripassi Esempi di rete di calcolatori e non Metodi di valutazione della qualitÃ  della rete Il connettore di rete 0 Introduzione 0.1 Introduzione 0.1.1 Definizione di rete di calcolatori (2) ðŸŸ©- Slide\nI requisiti sono principalmente 2\nEssere autonomi nel calcolo (capacitÃ  di eseguire dei programmi) Essere interconnessi (capacitÃ  di ricevere ed inviare dei segnali) Gli scopi sono principalmente per la comunicazione fra utenti o calcolatori.\nNon-esempi\nRete telefonica, non sono autonomi Rete televisiva Esempi\nSmartphones con wi-fi WWW E-mail Una rete di calcolatori Ã¨ un insieme di dispositivi autonomi, cioÃ¨ in grado di eseguire e svolgere autonomamente i compiti programmati di calcolo e di comunicazione, interconnessi tra loro da supporti fisici alla trasmissione di segnali. Non sono considerate reti di calcolatori, ad esempio, nÃ© le reti di comunicazione telefonica (i cui terminali telefonici non sono dispositivi autonomi), nÃ© le reti di distribuzione televisiva (in quanto i televisori non sono dispositivi autonomi in grado di comunicare informazione). Nel prosieguo della presentazione, con il generico termine di â€œreteâ€ o â€œrete di comunicazioneâ€ intenderemo implicitamente solo le reti di calcolatori elettronici. Con lâ€™avvento dei calcolatori elettronici, e con la loro diffusione tra comunitÃ  sempre piÃ¹ grandi di utenti, Ã¨ emersa lâ€™esigenza e lâ€™utilitÃ  di fornire un supporto alla comunicazione tra utenti, attraverso lâ€™uso del calcolatore, supportando innovativi servizi di comunicazione per lâ€™utente, quali ad esempio il World Wide Web e la posta elettronica. In tempi piÃ¹ recenti si sono sviluppati ulteriormente i sistemi di rete includendo Internet of Things (IoT), reti senza fili (Wireless), ecc. Le necessitÃ  di comunicare e condividere informazione sono tra i principali motivi che favoriscono la nascita e lo sviluppo di reti di calcolatori. La fruizione dellâ€™informazione contenuta in questo corso rappresenta un esempio. Un ulteriore aspetto che ha favorito la nascita e la diffusione delle reti di calcolatori Ã¨ legato alla possibilitÃ  di condividere dispositivi costosi, altrimenti sotto-utilizzati, come ad esempio stampanti o capienti dispositivi di memorizzazione dei dati, e la possibilitÃ  di accedere e lavorare sui dati di un calcolatore, senza doversi spostare fisicamente sul calcolatore stesso. Una rete di calcolatori puÃ² consentire di eseguire calcoli complessi in parallelo e in maniera distribuita, aumentando le prestazioni per lâ€™ottenimento dei risultati. In tal senso, le reti rendono possibile la scalabilitÃ  dei sistemi di comunicazione e di calcolo: il numero di dispositivi usati, e lâ€™investimento relativo, possono essere dimensionati dinamicamente in funzione delle richieste di servizio. In tempi recenti, le reti sono utilizzate in particolare per supportare la comunicazione utente, secondo svariate forme e applicazioni, oppure per supportare la comunicazione diretta tra dispositivi pervasivi e mobili (es. Internet of Things, Wireless Networks), ecc\n0.1.2 Classificazione delle reti (5 principali) ðŸŸ© Slide\nUna prima classificazione delle reti di calcolatori si basa sulla dimensione delle reti stesse. Non esiste in generale un criterio ben definito per tale classificazione, ma ci si basa su considerazioni generali, riguardanti la dimensione dellâ€™area di copertura geografica della rete, ovvero lâ€™area entro la quale possano esistere dispositivi connessi.\nLe reti personali (PAN) sono reti di comunicazione per connettere dispositivi vicini tra loro, ad esempio sul corpo di una persona o entro una stanza. Un esempio potrebbe essere dato dalla connessione di due dispositivi indossabili, sensori e smartphone, oppure calcolatori, una stampante e un agenda elettronica. Le reti personali sono di solito finanziate e gestite dal singolo utente che le utilizza.\nLe reti locali (LAN) sono molto spesso reti gestite e mantenute da organizzazioni, universitÃ , enti o aziende. Esse connettono calcolatori nel raggio di qualche centinaio di metri, ad esempio su interi edifici o campus universitari. Ad esempio, la rete delle aule del Dipartimento.\nLe reti metropolitane (MAN) hanno connessioni in un raggio dellâ€™ordine delle decine di chilometri, e possono connettere intere aree urbane. Esse sono mantenute e gestite da fornitori di servizi di comunicazione (provider) e gestori di servizi telefonici.\nLe reti geografiche (WAN) sono reti in grado di coprire distanze internazionali e addirittura planetarie. Tali reti sono mantenute e gestite da enti nazionali e internazionali, oppure da grossi enti o gestori delle comunicazioni. Lâ€™organizzazione e la struttura di tali reti puÃ² essere molto complessa, e puÃ² risultare composta da diverse parti, e da diverse tecnologie, eterogenee e integrate (ad esempio, molte reti collegate tra loro con tecnologie cablate o in fibra, fino a reti basate su comunicazione satellitare senza fili).\nInternet (inter-networking, ossia comunicazione di rete fra rete diverse) Ã¨ una rete di reti, composta da molte reti diverse connesse tra loro, integrate grazie a un insieme di regole comuni: i protocolli della rete Internet.\nAlcuni esempi PAN Anche reti allâ€™interno del corpo stesso! (es. per autenticazione). (qualcosa che passa da un pezzo del corpo a un altro pezzo). (molto piccola) LAN Alma-wifi (wireless) â†’ WLAN MAN Alma-wifi, perchÃ© ce in molte parti della cittÃ  (diffusa con ripetitori, che allâ€™insieme hanno una rete metropolitana). NOTA: MAN (e piÃ¹ in generale le reti) si possono espandere componendo reti piÃ¹ piccole NOTA: la grandezza della rete influenza i problemi che la rete deve risolvere. WAN Internet Câ€™Ã¨ un problema di comunicazione, come connettere tutti i calcolatori del mondo??? 0.1.3 Evoluzione e costi della rete (storia, non richiesta) ðŸŸ¨ Slide\nLo sviluppo delle reti di calcolatori, che ha permesso la nascita di Internet, non sarebbe stato possibile senza una distribuzione dei costi di realizzazione e gestione delle infrastrutture tra molte entitÃ .\nUn pÃ² di storia Storicamente, la prima rete di Internet nasce da un esperimento nel 1969, connettendo solo 4 calcolatori di 4 universitÃ  americane (con linee di telefoni!).\nDa allora molte entitÃ  hanno dato il loro contributo per lo sviluppo e la diffusione delle reti di calcolatori. Allâ€™inizio del 2003 Internet contava oltre 172 milioni di calcolatori (fonte Internet Software Consortium). GiÃ  nel 2017 si parla di oltre 4 miliardi di dispositivi connessi (anche se non tutti connessi allo stesso momento). Entro 5-7 anni si raggiungeranno i 60 miliardi di dispositivi connessi, realizzando lâ€™avvento dellâ€™Internet of Things.\nPoi si Ã¨ sviluppata (dal primo esperimento, si racconta che HELL sia stato il primo messaggio, poi c\u0026rsquo;Ã¨ stato un system crash) grazie ad ingesti investimenti militari, poi aziende private. Queste aziende private poi rivendono al cliente finale.\nSui costi Per quello che riguarda i costi, la realizzazione, mantenimento e gestione dellâ€™infrastruttura di una rete molto ampia richiede investimenti economici elevati, che possono essere maggiori a seconda del grado di avanzamento delle tecnologie e delle prestazioni richieste.\nCosti MAN e WAN\nAlcune delle infrastrutture principali delle reti estese MAN e WAN (e di Internet) hanno costi affrontabili solo attraverso un consistente investimento e una pianificazione delle ricadute commerciali da parte di consorzi o fornitori di servizi di comunicazione nazionali e multinazionali.\nCosti LAN\nTuttavia, la maggior percentuale del complesso delle infrastrutture di rete che compongono Internet risultano essere mantenute e gestite capillarmente da piccoli gestori e piccoli gruppi, con investimenti relativamente modesti per la realizzazione di piccole reti locali (LAN). Lâ€™integrazione di un insieme molto vasto di reti grandi e soprattutto piccole reti locali, eterogenee e distribuite su tutto il pianeta, ha permesso la crescita incrementale, il successo commerciale e la esplosiva diffusione delle reti su scala globale, fino a Internet.\nCosti utente finale\nLâ€™utente delle reti paga tipicamente per i servizi di trasmissione offerti dalle reti, con tariffe che possono essere basate sul tempo di collegamento, sulla quantitÃ  di dati.\n0.1.4 Valutazione prestazioni della rete (2) ðŸŸ© Slide\nPer ciÃ² che riguarda le prestazioni delle reti di calcolatori, lâ€™utente Ã¨ principalmente interessato a due indici: la capacitÃ  di trasmissione (impropriamente detta velocitÃ  della rete) e il ritardo del collegamento di rete.\nLa capacitÃ  di trasmissione si misura sulla base della quantitÃ  di dati che Ã¨ possibile comunicare in un secondo mediante la rete. I dati digitali del calcolatore si misurano in bit o in byte (gruppi di 8 bit), e di conseguenza lâ€™unitÃ  di misura usata tipicamente per misurare la capacitÃ  di trasmissione dei dati di una rete Ã¨ il numero di bit oppure di byte trasmessi al secondo (bit/sec, byte/sec). Spesso si usano i prefissi Kilo (K) per le migliaia, Mega (M) per i milioni e Giga (G) per i miliardi di bit o byte al secondo, Tera (T) per le migliaia di miliardi, ecc. (esempio Kbit/sec, Kbyte/sec). Il ritardo del collegamento di rete indica il tempo necessario ai dati per transitare dal mittente al destinatario finale sulla rete. I fattori del ritardo (non solo questi): la distanza fisica del collegamento i tempi necessari alla gestione delle regole dei processi di comunicazione in rete (protocolli) che i dati devono subire durante il loro tragitto. (che puÃ² essere anche fisico letterale: eg. aereo o furgone, invece che fibra o reti, questo Ã¨ un protocollo ðŸ™‚). Variazione del ritardo (es. coda per furgoni, congestione delle linee e simili) Jitter (su quale sia meglio, dipende sempre dagli utilizzi â†’ Streaming? o semplice scaricare? a seconda di quanto ci serve Ã¨ meglio la rete blu o rossa) Ovviamente sono da preferire reti dotate di basso ritardo, in quanto ciÃ² favorisce la rapiditÃ  e lâ€™interattivitÃ  del processo di comunicazione. Per fare un parallelo intuitivo, pensando alle reti come a tubi che trasportano bit, la capacitÃ  di trasmissione equivale al diametro del tubo, mentre il ritardo equivale al tempo che i bit impiegano ad attraversare una serie di tubi in tutta la loro lunghezza.\n0.2 Componenti della rete Introduzione generali dei componenti principali ðŸŸ©- Slide\nEsempi di pezzi di rete\nLa connessione di un calcolatore a una rete di calcolatori richiede un insieme essenziale di componenti, hardware e software, in aggiunta al calcolatore elettronico di base.\nLâ€™elemento primario da aggiungere al calcolatore Ã¨ il dispositivo (o scheda) di rete: si tratta di un dispositivo hardware di comunicazione, fisicamente collegato al calcolatore, in grado di codificare e trasmettere, oppure ricevere e decodificare i dati inviati dal calcolatore alla rete, e dalla rete al calcolatore. I mezzi di trasmissione sono supporti fisici alla propagazione e trasmissione di segnali, quali cavi o fili elettrici, fibre ottiche, o semplicemente lo spazio tridimensionale nel quale si propagano le onde radio. Tali mezzi di trasmissione realizzano lâ€™infrastruttura fisica della rete. Il costo di realizzazione dellâ€™infrastruttura di rete rappresenta spesso un fattore rilevante e critico per la diffusione e lâ€™implementazione di reti di calcolatori. Il connettore di rete Ã¨ semplicemente unâ€™interfaccia standard presente sul dispositivo di rete, per il collegamento del dispositivo di rete al mezzo di trasmissione. Esistono vari connettori, diversi a seconda del tipo di tecnologia impiegata per la rete di comunicazione. I connettori possono avere varie forme, e tipicamente permettono il collegamento solo quando le tecnologie dei dispositivi di rete, dei protocolli di gestione, e dei mezzi di trasmissione sono tra loro compatibili. I dispositivi di rete sono amministrati da componenti software del sistema operativo, e devono rispettare un insieme di regole standard per la gestione dei processi di comunicazione, definite dai protocolli di rete. I protocolli di rete sono un insieme di regole, univocamente definite, per garantire la compatibilitÃ  e la corretta configurazione e gestione delle fasi della comunicazione tra i dispositivi di rete.\n0.2.1 Mezzo fisico di trasmissione ðŸŸ© Slide\nEsempi mezzi di trasmissione\nIl mezzo di trasmissione Ã¨ lâ€™elemento fisico che supporta la propagazione dei segnali trasmessi tra i dispositivi della rete. Ne abbiamo parlato anche nella sezione dispositivi di rete Le connessioni di rete possono essere realizzate mediante tre mezzi di trasmissione diversi:\ncavi conduttori fibre ottiche connessioni senza fili. I cavi di materiale conduttore (cavetti, doppino intrecciato o cavo coassiale), sono in grado di propagare segnali elettrici, cioÃ¨ variazioni di tensione e corrente elettrica. Questi mezzi fisici sono i piÃ¹ utilizzati nelle reti locali, e nelle brevi distanze, per il loro buon rapporto tra costo e prestazioni. Oggi tale mezzo trasmissivo Ã¨ in grado di supportare trasmissioni dati con una capacitÃ  dellâ€™ordine del miliardo di bit al secondo (1-2 Gbit/sec).\nLa tecnologia a fibre ottiche Ã¨ tecnologicamente avanzata, e si basa sulla trasmissione di segnali ottici, cioÃ¨ di luce, vincolata allâ€™interno di una sottile fibra di vetro purissimo. La fibra Ã¨ sottile come un capello, Ã¨ elastica ed Ã¨ protetta da una guaina esterna per facilitare il suo impiego. Il costo della fibra non Ã¨ molto elevato, tuttavia la fibra Ã¨ molto delicata per quanto riguarda la connessione degli estremi (giunzione) e questo influisce molto sui costi di distribuzione e di realizzazione dellâ€™infrastruttura di rete. La capacitÃ  di una fibra ottica puÃ² arrivare oggi a qualche decina di migliaia di miliardi di bit al secondo (oltre 10000 Gbit/sec).\nOnde elettromagnetiche e dalla loro propagazione nello spazio. Esempi in tal senso sono forniti dalle onde radio e dalla luce infrarossa. Tali tecnologie vengono dette senza fili (wireless). Le reti senza fili sono molto interessanti, e la loro diffusione Ã¨ oggi esplosiva, in quanto permettono la mobilitÃ  dei dispositivi e degli utenti. La capacitÃ  dei collegamenti senza fili puÃ² arrivare oggi a qualche decina di milioni di bit al secondo (1- 54 Mbit/sec). Il limite della tecnologia senza fili Ã¨ dato dalla vulnerabilitÃ  del segnale rispetto ad errori e interferenza dei segnali, e dai limiti fisici della propagazione dei segnali. Due dispositivi possono essere connessi senza fili solo se rimangono entro un limite di distanza $d$ che dipende dalla potenza del segnale radio emesso dal trasmettitore, e da eventuali ostacoli intermedi per il segnale. Inoltre non Ã¨ precisa, nel senso che non si riesce in modo effettivo ad isolare la direzione di arrivo (la destination e sorgente non sono isolate).\nCollisione Ã¨ un problema molto comune per\nOgni rete puÃ² essere realizzata attraverso un singolo mezzo fisico di trasmissione, oppure attraverso la composizione di mezzi fisici eterogenei.\nCanali, vedi canali di comunicazione, dividono spesso il mezzo di comunicazione. (si potrebbe infatti dire che il singolo mezzo di comunicazione abbia un fascio di canali)\n0.2.2 Dispositivo o scheda di rete ðŸŸ© Slide\nLe schede di rete permettono la comunicazione in rete tra calcolatori diversi, attraverso i vari mezzi di trasmissione illustrati, avviene mediante dispositivi interni o periferiche esterne del calcolatore. Queste schede sono collegate al calcolatore attraverso unâ€™interfaccia di collegamento del calcolatore: su tale interfaccia transitano i dati (bit di informazione) da trasmettere in rete, oppure ricevuti dalla rete.\nLa scheda di rete si occupa inoltre di trasformare i bit di informazione in segnali trasmissibili sul mezzo di trasmissione della rete e viceversa: tali trasformazioni si chiamano codifica e decodifica dei dati. Un connettore di rete pone direttamente in contatto la scheda di rete con il mezzo di trasmissione per lâ€™invio e ricezione dei segnali in rete.\nIn sintesi, la funzione della scheda di rete Ã¨ quella di memorizzare temporaneamente, codificare, decodificare, trasmettere e ricevere i dati da e verso il mezzo di trasmissione (cioÃ¨ la rete) o il calcolatore.\nIdentificazione della scheda di rete Il tipo della scheda di rete viene identificato a seconda del mezzo trasmissivo, e soprattutto a seconda dei protocolli di comunicazione utilizzati per la codifica, e per la trasmissione dei dati in rete. Per le reti locali (LAN) basate su mezzo di trasmissione cablato, le tecnologie piÃ¹ diffuse sono chiamate con il nome del protocollo di comunicazione primario: ad esempio Ethernet, nelle varianti a 10, 100 Mbit/sec (Fast Ethernet) e 1000 Mbit/sec (Gigabit Ethernet).\nPer le reti LAN senza fili (WLAN), le schede di rete piÃ¹ diffuse sono denominate Wi-Fi (da 11 a 54 Mbit/sec), e Bluetooth (da 1 a 2 Mbit/sec). Ogni scheda di rete, per permettere di essere identificata univocamente nel contesto di una rete locale, dispone dalla sua costruzione di un indirizzo univoco (unico) a livello mondiale, non modificabile, detto indirizzo MAC (Medium Access Control), spesso questa scheda di rete Ã¨ specifica per il mezo trasmissivo!. Tali indirizzi vengono assegnati dai costruttori delle schede, per evitare che si possano originare indirizzi MAC duplicati. (spesso hai moltissime informazioni riguardo al modello della scheda di rete e del produttore solo guardando questo).\nIl MAC si occupa anche di evitare le collisioni (come non lo so).\n0.2.3 Protocolli di rete ðŸŸ© Slide (la parte sullâ€™architettura presente in slide Ã¨ trattata in Architettura e livelli 1, 2\nLe regole che governano i processi di comunicazione in rete, tra dispositivi e sistemi eterogenei\nPerchÃ© Ã¨ necessario: La necessitÃ  di accordarsi su regole e servizi comuni per la comunicazione di rete ha lo scopo di permettere una completa compatibilitÃ  e supporto alla comunicazione su sistemi, tecnologie e dispositivi eterogenei.\nAl fine di far ciÃ² definiscono delle regole semantiche (processi) e sintattiche (struttura pacchetto) formali.\nI protocolli definiscono aspetti e regole semantiche sulla sequenza dei messaggi, e regole sintattiche sul formato dei messaggi scambiati durante la comunicazione. La definizione dei protocolli di rete deve prevedere e supportare diverse finalitÃ  di comunicazione.\nNon ha quindi senso definire un protocollo rigido, ma ha senso definire classi di protocolli, deputate a svolgere e gestire determinate funzioni della comunicazione. Tali classi di protocolli, opportunamente organizzate, permettono di semplificare la gestione della rete, ma Ã¨ necessario definire in modo non ambiguo le relazioni tra le classi di protocolli (ovvero quale protocollo si occupa di gestire un certo problema? Come avviene il dialogo tra protocolli?)\n0.3 Struttura della rete 0.3.1 Strutture della connessione di rete (4) ðŸŸ© Slide\nUn collegamento o connessione fisica di rete Ã¨ fornita da un mezzo di trasmissione (ad esempio un cavo, una fibra ottica oppure lo spazio per la propagazione di onde radio) che sia condiviso tra due o piÃ¹ dispositivi ad esso collegati, e che permetta il trasferimento di segnali, e quindi informazione, tra i dispositivi stessi.\nUnâ€™infrastruttura di rete rappresenta lâ€™insieme dei collegamenti o connessioni fisiche esistenti tra tutti i dispositivi di una rete.\nLa comunicazione tra una coppia qualsiasi di calcolatori in rete, detti nodi (oppure host) della rete, Ã¨ possibile se esiste un collegamento diretto tra i nodi, oppure se esiste una sequenza di collegamenti, detta cammino, che permetta la comunicazione dei segnali passando per eventuali nodi e collegamenti intermedi.\nClassi di strutture di connessione della rete. (4)\nLe connessioni di rete punto a punto, come nellâ€™esempio (a), sono connessioni che possono essere instaurate tra una coppia di calcolatori, senza coinvolgerne altri. Esse rappresentano il caso piÃ¹ semplice di infrastruttura di rete, e sono semplici da gestire. Reti completamente connesse: Le connessioni di rete multiple permettono di connettere contemporaneamente un dispositivo a molti altri dispositivi. Nellâ€™esempio (b) viene mostrata una infrastruttura di rete nella quale ogni nodo Ã¨ connesso attraverso un linea dedicata ad ogni altro nodo. Questa infrastruttura di rete viene detta completamente connessa, ed Ã¨ molto ridondante: infatti esistono molti cammini, oltre al collegamento diretto, per connettere ogni coppia di nodi passando per nodi intermedi. Una simile infrastruttura di rete si puÃ² ritenere a volte troppo complessa e costosa. Ad esempio, sarebbe impensabile disporre di una connessione dedicata (cioÃ¨ un filo diretto) da ogni calcolatore ad ogni altro calcolatore sulle reti mondiali. Reti parzialmente connesse: Nellâ€™esempio c, malgrado il ridotto numero di collegamenti rispetto al caso b, Ã¨ comunque possibile per ogni dispositivo trasferire segnali, cioÃ¨ comunicare, verso ogni altro dispositivo. In altre parole esiste un cammino, attraverso le connessioni disponibili, per trasferire informazione tra ogni coppia di dispositivi della rete.Nella rete (c) esiste perÃ² un fattore di rischio: in seguito a un guasto di una connessione, potrebbe risultare un insieme di componenti separato da tutti gli altri, detto â€œpartizioneâ€ della rete (esempio d). Le partizioni della rete limitano il grado di comunicazione possibile, e possono essere dovute a cause fisiche (guasti fisici della connessione) oppure a cause che dipendono da cattive applicazioni delle regole di utilizzo (ovvero dei protocolli, che vedremo in seguito). 0.3.2 Topologia di rete ðŸŸ© Slide\nTopologie di rete sono i diversi schemi di connessione sono possibili per creare le infrastrutture di rete\nTopologia per PAN e locali LAN: Topologia ad anello (esempio a) Ã¨ basata sullâ€™organizzazione delle connessioni tra i dispositivi, in modo da creare un anello chiuso. Ogni componente puÃ² comunicare con ogni altro componente inviando i segnali attraverso la sequenza di connessioni in senso orario o antiorario. La topologia a stella (esempio b) prevede un componente centrale direttamente connesso a tutti gli altri. Ogni componente periferico puÃ² comunicare con ogni altro componente periferico passando attraverso il componente centrale. La topologia a bus (esempio c) prevede che ogni componente abbia una connessione verso un bus condiviso (cioÃ¨ una connessione condivisa da tutti). Questo tipo di connessione permette di introdurre una delle problematiche fondamentali che saranno trattate in seguito: la gestione dellâ€™accesso al bus, ovvero il decidere chi possa trasmettere tra tutti i possibili dispositivi, per evitare sovrapposizioni delle trasmissioni. La topologia ad albero (esempio d) prevede unâ€™organizzazione gerarchica delle connessioni. Se pensiamo allâ€™analogia con un albero genealogico, esiste un dispositivo (nonno) che connette direttamente due o piÃ¹ dispositivi (figli), ognuno dei quali a sua volta connette direttamente un numero variabile di dispositivi (nipoti), e cosÃ¬ via.\nMano a mano che le reti piÃ¹ piccole vengono collegate tra loro e organizzate in strutture di rete piÃ¹ grandi, la topologia della rete globale puÃ² diventare incredibilmente complessa, e quindi uno schema topologico generalizzato non Ã¨ quasi mai applicabile. In questo caso si parla di rete con topologia a grafo complesso, oppure a maglia. In tali topologie a grafo, possono essere presenti cammini multipli che connettono coppie di nodi, dando luogo a possibili alternative per la connessione dei dispositivi. Questo fatto puÃ² ridurre il rischio di incorrere in partizioni della rete, in quanto un certo grado di ridondanza dei cammini di connessione permette di aggirare i collegamenti soggetti a eventuali guasti.\n0.3.3 I due generali ðŸŸ© Ãˆ possibile implementare una comunicazione sicura in un ambiente che possa fallire, anzi con un nemico che voglia far fallire questo?\nFai finta che A = 3, B = 3, e C = 5, ma A e B sono separati, Ã¨ possibile avere una comunicazione per attaccare insieme? Se A o B attaccano da soli verrebbero ammazzati.\nSemplificazione del problema dei due generali\nCome si manda il messaggio in modo sicuro? Se si manda il singolo messaggio, senza aspettare nessuna risposta, allora Ã¨ molto insicuro (per niente sicuro) che il messaggio sia arrivato.\nPer questo motivo si aspetta un acknowledgment, e un altro acknowledgment dallâ€™altra parte â†’ SYN/ACK protocol Ã¨ simile.\nMa facendo in questo modo non si Ã¨ mai sicuri che lâ€™altro abbia ricevuto il messaggio. La rete a due Ã¨ fallibile, e questo Ã¨ dimostrato.\n0.3.4 Reti commutazione a circuito ðŸŸ© Slide\nNelle reti a commutazione di circuito, i dati vengono trasmessi tra un mittente e un destinatario finale agli estremi di un cammino end-to-end (circuito) di canali di comunicazione punto a punto. Il circuito viene negoziato e prenotato, attraverso opportune procedure (come avviene quando si digita un numero per una chiamata telefonica). Una volta identificati e ottenuti i canali che collegano mittente e destinatario, la comunicazione dati puÃ² avvenire anche come unâ€™unica sequenza di bit, senza interruzioni.\nVantaggi\nNon câ€™Ã¨ bisogno di dichiarare periodicamente chi sia il mittente e il destinatario dei dati, in quanto entrambi sono fissati al momento della creazione del circuito riservato (riservato = prenotato da qualcuno). Ridotto ritardo di trasmissione per i dati, in quanto ogni nodo intermedio ha giÃ  disponibile il canale libero uscente sul quale inviare immediatamente i dati ricevuti sul canale entrante, dal mittente fino al destinatario finale. Svantaggi\nUtilizzo basso dei canali del circuito QuantitÃ  dei dati da trasmettere non Ã¨ grande I dati arrivano a gruppi, intervallati da tempi di vuoto. Inefficienza di utilizzo delle risorse del circuito nei casi sopraelencati (il canale resta tutto occupato). Pagato a tempo! Un pÃ² di tempo in piÃ¹ per prenotare il percorso allâ€™inizio. 0.3.5 Reti commutazione a pacchetto ðŸŸ© Slides\nLa maggior parte delle reti per trasmissione dati digitali, inclusa la rete di reti globale Internet, sono di questo tipo.\nCome funziona\nI dati digitali vengono suddivisi in pacchetti separati, e vengono trasmessi su canali ad accesso multiplo (broadcast, non per forza deve essere punto a punto ). Per consentire la corretta ricezione dei dati, Ã¨ perÃ² necessario includere in ogni pacchetto lâ€™informazione sullâ€™identitÃ  del rispettivo mittente e soprattutto del destinatario. Si attua in questo modo la condivisione di un canale unico per diversi flussi di pacchetti appartenenti a diversi mittenti e destinatari. Componendo in serie una sequenza di canali broadcast a commutazione di pacchetto, i nodi ricevitori devono di volta in volta farsi carico di verificare se il pacchetto sia giunto a destinazione o, in caso contrario, possono provvedere allâ€™inoltro del pacchetto ricevuto sul successivo canale broadcast.\nSvantaggi\nRitardo per la comunicazione dei dati tra mittente e destinatario (piÃ¹ lenti dovuto allâ€™esigenza di iterare piÃ¹ volte la ricezione e lâ€™inoltro di pacchetti su canali broadcast in sequenza. Maggiore rischio di collisione dei pacchetti (perdita di pacchetti) A causa dei jitter, i pacchetti possono arrivare in ordine diverso(perdita di ordine â†’ riordinamento) Se utilizzo il broadcast, serve il mittente e il destinatario Vantaggi\nmaggiore utilizzo dei canali ad accesso multiplo, e quindi alla possibilitÃ  di tariffare la comunicazione in base ai dati trasmessi, e non in base al tempo necessario. 0.3.6 Canali di comunicazione della rete ðŸŸ© Slide\nBisogna dire che Ã¨ una virtualizzazione sul mezzo di comunicazione, ossia si utilizza il mezzo di comunicazione come se avesse alcuni canali diversi (che non interferiscono fra di loro) quindi possiamo riutilizzare la stessa risorsa fisica!\nDa riallacciarsi con mezzi di comunicazione per capire come sono implementate fisicamente i canali di comunicazione.\nI canali punto a punto si basano sullâ€™accordo tra un mittente e un destinatario riguardante la definizione del canale da usare (in figura equivale al colore). Solo due dispositivi possono usare il canale di tipo punto a punto a loro riservato. Possiamo creare un canale logico da un singolo mezzo trasmissivo (eg una frequenza diversa, che possono essere filtrate). Il problema principale di questo Ã¨ che Ã¨ fisso, ossia posso comunicare solamente con un unico computer, senza poter cambiare il destinatario, direi che abbia piÃ¹ problemi nel momento di wiring.\nI canali ad accesso multiplo (broadcast) sono canali sui quali tutti possono trasmettere e dove tutti ricevono le trasmissioni di altri (chiaramente il problema di collissione Ã¨ molto alto). Half duplex o uno trasmette o uno riceve mentre i Full-duplex possono trasmettere e ricevere contemporaneamente. Spesso per queste reti c\u0026rsquo;Ã¨ un master e dei slave che gestiscono.\nEthernet risolve questo problema senza fare utilizzo di un master, utilizza un sistema di ___ (non mi ricordo, Ã¨ comunque una race condition) lo risolve con un sistema di counter interno dopo il quale, se Ã¨ ancora vuoto il canale di comunicazione broadcast, prova a fare la comunciazione.\n0.3.7 Problema delle collisioni su canali multiple ðŸŸ¨ Un problema per i canali ad accesso multiplo Ã¨ legato alla possibile collisione di segnali appartenenti allo stesso canale di comunicazione. Se due trasmissioni di segnali si sovrappongono nel tempo sullo stesso canale di comunicazione, lâ€™effetto sui segnali puÃ² essere distruttivo e lâ€™esito della comunicazione puÃ² essere nullo. Intuitivamente, se due dispositivi trasmettono i loro segnali contemporaneamente, nessuno ricevitore sarÃ  in grado di capire quali bit di informazione siano stati trasmessi.\nIl problema delle collisioni Ã¨ molto critico, e determina lâ€™esigenza di arbitraggio nellâ€™accesso al canale: chi trasmette e quando? Il problema dellâ€™arbitraggio puÃ² essere banale su canali punto a punto, dove mittente e destinatario possono definire semplici leggi (cioÃ¨ protocolli di gestione della comunicazione) per evitare le collisioni: ad esempio, trasmetto io, poi trasmetti tu. In canali condivisi ad accesso multiplo (broadcast) il problema risulta invece molto complesso, in quanto occorre definire leggi non ambigue, in grado di regolare gli accessi da parte di molti utenti, evitando le collisioni.\nIl problema principale delle collisioni Ã¨ che fanno perdere tempo o infomazioni (se il nostro protocollo non le gestisce).\nUtilizzo\nDi solito Ã¨ uguale a $capacitÃ  \\cdot overhead$, ad esempio se trasmetto 100 bit e solo 1 un bit Ã¨ di informazione, questo Ã¨ l\u0026rsquo;utilizzo del protocollo. Questo va a misurare efficienza di informazioni di questo protocollo.\n0.3.8 Servizi orientati alla connessione e non ðŸŸ¨+ Slide\nI servizi orientati alla connessione (connection-oriented) garantiscono che la spedizione di pacchetti di dati tra mittente e destinatario sia equivalente a una trasmissione affidabile e corretta. In altre parole, essi implementano una serie di operazioni attraverso le quali tutti i pacchetti perduti saranno ritrasmessi, e correttamente ordinati, fino a ricostruire esattamente tutta lâ€™informazione trasmessa. Lâ€™implementazione di tale tipo di servizi potrebbe essere basata sulla definizione di vari protocolli alternativi. Ad esempio, potrebbe essere definito un cammino riservato unico per i pacchetti. Intuitivamente, ciÃ² equivarrebbe a un circuito virtuale per lâ€™invio dei pacchetti. Un altro modo per ottenere tale servizio potrebbe essere basato sulla numerazione dei pacchetti inviati, sul riordino dei pacchetti ricevuti e sulla richiesta di ri-trasmissione dei pacchetti perduti.\nIn breve questo risolve un problema di:\nRiordinamento dei pacchetti\nSoluzione riordinamento\nBasta numerare i pacchetti e poi far riordinare dal destinatario, questo Ã¨ un problema molto facile da risolvere\nReinvio dei pacchetti perduti\nSoluzione reinvio\nBisogna che il destinatario mandi degli acknowledgements. Anche questi possono essere persi.\nProblema tempo da aspettare prima di reinviare il pacchetto Pacchetto duplicato quando si perde l\u0026rsquo;acknowledgement o ci mette troppo. I servizi non orientati alla connessione (connectionless) non si preoccupano di garantire lâ€™ordine corretto dei pacchetti inviati e nemmeno la ricezione di tutti i pacchetti. Tale servizio Ã¨ simile allâ€™invio dei pacchetti in modo analogo a una sequenza di lettere attraverso la posta ordinaria.\nNon ci importa l\u0026rsquo;ordine di arrivo nÃ© per forza alcuni buchi.\nQuesto Ã¨ come sono le reti normali, normalmente sono connectionless, con un protocollo in piÃ¹ sono connection-oriented.\nIn modo molto veloce si potrebbe dire che i servizi non orientati alla connessione non garantiscono nulla.\n","permalink":"https://flecart.github.io/notes/introduzione-a-reti/","summary":"Ripasso Prox: 60 Ripasso: May 18, 2023 Ultima modifica: May 12, 2023 7:59 PM Primo Abbozzo: September 19, 2022 11:11 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Vecchi ripassi Esempi di rete di calcolatori e non Metodi di valutazione della qualitÃ  della rete Il connettore di rete 0 Introduzione 0.1 Introduzione 0.1.1 Definizione di rete di calcolatori (2) ðŸŸ©- Slide\nI requisiti sono principalmente 2\nEssere autonomi nel calcolo (capacitÃ  di eseguire dei programmi) Essere interconnessi (capacitÃ  di ricevere ed inviare dei segnali) Gli scopi sono principalmente per la comunicazione fra utenti o calcolatori.","title":"Introduzione a reti"},{"content":"DI Law of Large Numbers e Central limit theorem ne parliamo in Central Limit Theorem and Law of Large Numbers.\nLaw of large numbers Data una sequenza di variabili aleatorie, $X_{1}, X_{2}, \\dots, X_{n}\\dots$, tali che siano i.i.d tali per cui $E(X_{1}) = E(X_{2}) = \\dots = E(X_{n}) =\\dots = \\mu$ tale che sia finito. Consideriamo $$ S_{n} = \\sum^n_{i=1} x_{i} ,:, \\bar{x}_{n} = \\frac{S_{n}}{n} $$ Allora questo teorema afferma che: $$ \\bar{x}_{n} \\to \\mu $$ Ossia il limite converge sul valore atteso di tutte le variabili aleatorie.\nInoltre se abbiamo che la varianza di tutte le variabili aleatorie, abbiamo che $$ var(\\hat{x}_{n}) = \\frac{\\sigma^{2}}{n} \\to 0 $$ Strong Law of large numebrs $$ \\mathbb{P}(\\lim_{ n \\to \\infty } \\bar{x}_{n} =\\mu) = 1 $$ Ci permette di prendere la sample average per quei valori di mezzo. E posso fare la stima della nostra funzione di interesse $h$ tenendo conto: $$ \\bar{h}_{n} = \\sum_{i=1}^{n} \\frac{h(x_{i})}{n} $$ E questo converge $O(\\sqrt{ n })$ per la legge dopo.\nCentral limit theorem Data una sequenza di variabili aleatorie, $X_{1}, X_{2}, \\dots, X_{n}\\dots$, tali che siano i.i.d tali per cui $E(X_{1}) = E(X_{2}) = \\dots = E(X_{n}) =\\dots = \\mu$ tale che sia finito, e con varianza tutti uguali $= \\sigma^{2}$ finito.\nAbbiamo come risultato che $$ \\sqrt{ n } (\\hat{x}_{n} - \\mu) \\to N(0, \\sigma^{2}) $$ La prima parte Ã¨ una variabile aleatoria e converge a quel valore. (questo permette di utilizzare la gaussiana quando $n$ Ã¨ grande abbastanza).\nMonte carlo integration Abbiamo che: $$ \\int_{X} h(x) \\cdot f(x) dx = E_{f}[h(x)] = \\mu $$ Questo Ã¨ tutto il significato dell\u0026rsquo;integrazione di monte carlo (molte variabili aleatorie per stimare il valore di qualcosa). E questo vale sempre, anche se $f$ non Ã¨ una funzione di densitÃ , basta che sia positiva (basta riscalare).\nIl motivo per cui funziona Ã¨ per LLN, perchÃ© abbiamo che convergerÃ  su $\\mu$ in lungo termine, basta considerare molte variabili aleatorie consecutive.\nCose interessanti:\nPosso stimare il valore atteso grazie a LLN Posso stimare la varianza grazie ad essa Posso stimare variabili condizionali. Importance sampling Deve soddisfare la cosa del supporto (contiene supporto sia di h che di f) Deve avere varianza finita per i pesi che sono trovati. (ci sono metodi per stimare poi il $g$). la frazione $\\frac{f}{g)}$ deve essere limitata e la varianza di $h$ rispetto alla densitÃ  $f$ deve essere finita. ","permalink":"https://flecart.github.io/notes/monte-carlo-integration/","summary":"DI Law of Large Numbers e Central limit theorem ne parliamo in Central Limit Theorem and Law of Large Numbers.\nLaw of large numbers Data una sequenza di variabili aleatorie, $X_{1}, X_{2}, \\dots, X_{n}\\dots$, tali che siano i.i.d tali per cui $E(X_{1}) = E(X_{2}) = \\dots = E(X_{n}) =\\dots = \\mu$ tale che sia finito. Consideriamo $$ S_{n} = \\sum^n_{i=1} x_{i} ,:, \\bar{x}_{n} = \\frac{S_{n}}{n} $$ Allora questo teorema afferma che: $$ \\bar{x}_{n} \\to \\mu $$ Ossia il limite converge sul valore atteso di tutte le variabili aleatorie.","title":"Monte carlo integration"},{"content":"NOTA: tolgo dalle note perchÃ© non mi sembra importante.\nIntroduction to system design Packages vs diagrams ðŸŸ©- Packages fisica implementazione, perchÃ© Ã¨ una cosa utile per lo sviluppo Diagrams logica visualizzazione perchÃ© aiuta solamente a comprendere meglio come funziona il sistema in toto. Components What is a component (3) ðŸŸ¨ Ãˆ una entitÃ  totalmente indipendente che funziona a sÃ©, un esempio Ã¨ il dll, dynamically loaded libraries presente nei sistemi di windows. Una cosa Ã¨ che espongono interfacce per interagirci, e questi possono essere utilizzati per creare sistemi complessi.\nQuindi riassumendo:\nIndipendenza da altri software (almeno Ã¨ contenuto) Presenza di interfacce per interagirci Risolvono un certo problema specifico (appunto isolato) Se ho questo allora posso rappresentare la struttura in esecuzione con i diagrammi di sopra, a seconda di come li carico scarico e simili.\nDifference with collaboration diagrams ðŸŸ¥+ nel nostro caso Ã¨ una dipendenza esterna non Ã¨ una estensione ereditaria come potrebbe sembrare se lo analizziamo come class diagram.\nCi permette lo stesso di creare diagrammi che rappresentano in che modo i singoli oggetti comunicano con altri.\n#### Stereotypes ðŸŸ¥ Capire un po' meglio questa parte. Node What is a node ðŸŸ© Sono una risorsa computazionale, quindi con CPU e memoria per poter eseguire qualcosa. Un esempio sono micro-controllori per temperatura, smart-home e simili. Questo Ã¨ qualcosa di base se vogliamo andare ad analizzare cose come sistemi distribuiti e nodi di computazione in quel punto.\nDifference with components (1) ðŸŸ© I componenti rappresentano il pacchetto logico per una esecuzione, quindi sono piÃ¹ strutturali, astratti, rappresentano in che modo esegue un certo sistema. Mentre i nodi sono rappresentazione fisica esecuzione, in cui effettivamente eseguono qualcosa, prima solo per rappresentarlo, quindi deployment di ciÃ²\nReal Time UML Una delle caratteristiche fondamentali dei real time Ã¨ che hanno garanzia di esecuzione entro tot tempo, questa Ã¨ una cosa anche indagata per gli schedulers, vedi Scheduler#SISTEMI A REALTIME (non fare)\nTime events (3) ðŸŸ¨ Change event: rappresentano il momento in cui una azione Ã¨ avvenuta e quindi probabilmente deve essere gestito un cambio di stato in questo caso. Time Event: descrivono quanto deve essere fatto un evento, per esempio Fra 5 minuti alle 12 P.M. Timing costraints entro quanto tempo deve essere fatto (o ogni quanto). Solo che manca un linguaggio per esprimere questi constraints. Esempio: Object Contraint Language Introduzione a OCLðŸŸ¥ Ã¨ un linguaggio di modellazione utilizzato per modellare in modo non ambiguo tutte le pre e post condizioni per un linguaggio. Ãˆ un linguaggio puro. Secondo Succi Ã¨ utile quando facciamo i test durante il progetto.\n","permalink":"https://flecart.github.io/notes/system-design/","summary":"NOTA: tolgo dalle note perchÃ© non mi sembra importante.\nIntroduction to system design Packages vs diagrams ðŸŸ©- Packages fisica implementazione, perchÃ© Ã¨ una cosa utile per lo sviluppo Diagrams logica visualizzazione perchÃ© aiuta solamente a comprendere meglio come funziona il sistema in toto. Components What is a component (3) ðŸŸ¨ Ãˆ una entitÃ  totalmente indipendente che funziona a sÃ©, un esempio Ã¨ il dll, dynamically loaded libraries presente nei sistemi di windows.","title":"System Design"},{"content":"La struttura del neurone #### Parti strutturali principali (2) ðŸŸ© Possiamo identificare tre parti principali per quanto riguarda la struttura di un singolo neurone\nAssoni che si occupano di mandare activation potential signal all\u0026rsquo;esterno, a comunicare con altre cellule. Il segnale che parte dall\u0026rsquo;assone inizia da una sezione che viene chiamato segmento iniziale. Dentriti che si occupano di ricevere segnali da altri neuroni. Gli assoni e dentriti non sono connessi, ma c\u0026rsquo;Ã¨ un piccolo spazio in mezzo a questi che si chiama Synaptic cleft, (la scoperta di questo Ã¨ stato di stupore, in passato pensavano che fosse una cosa continua il cervello, invece abbiamo qualche piccola unitÃ  discreta, scoperto con la colorazione d\u0026rsquo;argento metodi di Golgi) l\u0026rsquo;informazione in questo spazio pre e post sinaptico Ã¨ gestito da neurotrasmettitori.\nSolitamente per un singolo neurone siamo nell\u0026rsquo;ordine di grandezza dei micrometri\nPossiamo anche analizzare il neurone da un punto di vista delle parti funzionali principali, in tal caso diventano 4, come espressi in immagine, per tipologie di neuroni differenti. La cosa magicamente interessante Ã¨ che i collegamenti possono essere tanto diversi, ma rispettare alla fine un concetto simile abbastanza coerente delle parti (in un certo senso anche qui troviamo il ragionamento per astrazioni comune in informatica, probabilmente dal punto di vista fisico dei neurotrasmettitori ci saranno cose diverse, ma offrono la stessa interfaccia in cui attaccarsi per cosÃ¬ dire).\nClassificazioni dei neuroni ðŸŸ© Ci sono molte tipologie di neuroni in natura, specialmente differiscono a seconda se stiamo parlando di vertebrati o invertebrati. In generale possiamo caratterizzarli in\nUnipolar Bipolar Multipolar Che viene riassunto dal diagramma sottostante. Solitamente i multipolar sono dei vertebrati. Convergenza e divergenza ðŸŸ© Questa Ã¨ una cosa che probabilmente non abbiamo in modo naturale nelle reti, si parla di divergenza del segnale neuronale nel momento in cui un singolo neurone eccitato va a comunicare con molti neuroni, potenzialmente attivandone molti. Convergenza invece quando un neurone, prendiamo caso quello incaricato per fare contrarre il muscolo, deve prendere input da molti neuroni sensoriali, e quindi decidere se si deve contrarre o estendere a seconda di questa informazione.\nRamÃ³n two principles ðŸŸ¨ Veder 24 del KANDEL Principle of dynamic polarization: afferma che l\u0026rsquo;eccitazione di un neurone va linearmente in un verso (prolly per escludere il fatto che torni indietro)\nConnectional specificity: afferma che c\u0026rsquo;Ã¨ un senso, una semantica per cosÃ¬ dire, sul perchÃ© certi neuroni sono connessi assieme.\nCellule Gliali Funzione ed etimologia ðŸŸ© Solitamente queste cellule, come dice il nome stesso latino, simile all\u0026rsquo;inglese glue, sono cellule di collegamento, ossia permettono la comunicazione corretta fra un neurone all\u0026rsquo;altro.\nTipologie di cellule gliali (3) ðŸŸ¨ I primi formano la mielina per gli assoni nel sistema centrale, i secondi in quello periferico (Ã¨ un burrito, molti avvolgimenti). I terzi non si conosce la funzione. Circuiti neuronali Sono dei pattern di collegamento che si possono trovare fra i neuroni. In modo naturale si sviluppano dei piccoli sistemi che inibiscono o eccitano i propri vicini in qualche modo speciale. TODO: capire perchÃ© sono importanti.\nFeedforward inhibition Feedback inhibition Sinapsi Sono il collegamento che esiste fra un neurone e un altro, quindi potremmo intenderlo come il canale di comunicazione fra un neurone e un altro.\nGap Junction ðŸŸ© Sono dei collegamenti piÃ¹ diretti fra i neuroni, e permettono di passare ioni di eccitazione in modo abbastanza diretto (questa Ã¨ la differenza con quelli basati su cose chimiche), Ã¨ un circuito piÃ¹ simile a quello elettronico, perchÃ© Ã¨ **piÃ¹ veloce**. Solitamente Ã¨ necessario per cose veloci, quando vogliamo fare andare dei neuroni assieme, come i arc reflexes.\nChemical basedðŸŸ© Sono delle porte piÃ¹ lente, i classici, quelli che poi andiamo a chiamare neurotrasmettitori, quando abbiamo un potenziale di azione, le vesicles vengono rilasciate nello spazio intracellulare, sull\u0026rsquo;altro neurone ci sono dei recettori che prendono questi neurotrasmettitori e si attivano di conseguenza.\nLa cosa interessante di questo metodo Ã¨ che il recettore puÃ² cambiare porte per capire quanto gli importa questa nuova informazione. (quindi se gli importa quel segnale, puÃ² aumentare il numero di porte altrimenti diminuirle, almeno questa Ã¨ la teoria).\nLa corteggia cerebrale consiste in una fra le parti piÃ¹ importanti del cervello. Consiste in 6 strati uniformi di neuroni che seguono un pattern simile.\n1, 4 hanno input da higher cortical areas, 4 da parti sottocorticali, 6, con quelle interne come talami.\nCorrelazioni con tempo di action potential Fra due neuroni che comunicano, c\u0026rsquo;Ã¨ una correlazione abbastanza evidente che implica un aumento della forza della connessione (synaptic strength) con il tempo degli spykes. Long Term Depression e Long Term Potentiation si chiamano.\nEPSP Ã¨ Excitatory Post-Synaptic potentiation, nell\u0026rsquo;immagine vediamo che se il secondo neurone si attiva dopo che si Ã¨ attivato il primo neurone, allora tendono a potenziare il segnale, altrimenti diminuire.\nPer la diminuzione ha senso perchÃ© Ã¨ come se io ti dessi indietro il segnale (anche se non necessariamente connessi), oppure l\u0026rsquo;altro Ã¨ stanco lol.\n","permalink":"https://flecart.github.io/notes/the-neuron/","summary":"La struttura del neurone #### Parti strutturali principali (2) ðŸŸ© Possiamo identificare tre parti principali per quanto riguarda la struttura di un singolo neurone\nAssoni che si occupano di mandare activation potential signal all\u0026rsquo;esterno, a comunicare con altre cellule. Il segnale che parte dall\u0026rsquo;assone inizia da una sezione che viene chiamato segmento iniziale. Dentriti che si occupano di ricevere segnali da altri neuroni. Gli assoni e dentriti non sono connessi, ma c\u0026rsquo;Ã¨ un piccolo spazio in mezzo a questi che si chiama Synaptic cleft, (la scoperta di questo Ã¨ stato di stupore, in passato pensavano che fosse una cosa continua il cervello, invece abbiamo qualche piccola unitÃ  discreta, scoperto con la colorazione d\u0026rsquo;argento metodi di Golgi) l\u0026rsquo;informazione in questo spazio pre e post sinaptico Ã¨ gestito da neurotrasmettitori.","title":"The Neuron"},{"content":"Security principles We have already outlined these principles in Sicurezza delle reti and talked about the concepts of authentication and integrity. Here we try to deepen these concepts and delve a little bit more on the attack vectors These are acronyms, usually called CIA and AAA for infrastructure\nConfidentiality This is one concerns about the secrecy of the sent message. We do not want others to be able to access and read what we are doing.\nEavesdropping ðŸŸ© This is an example of attack of confidentiality. The setting is usually like this: Eve that intercepts the message sent by each other. For example in network security, it is quite easy to eavesdrop with Wireshark or similars.\nIntegrity Integrity concerns with message tampering. The received message should be the same as the sent one (man in the middle are common attacks).\nAuthentication Authentication is important when we need to know to whom we are talking to. We should need to be sure that that is exactly the person (or the machine) we are trying to connect (or talk to). In this framework it is about integrity.\nSpoofing attacks ðŸŸ© When an attacker authenticates as another user.\nManipulation attacks ðŸŸ© This is tampering.\nAvailability The system should be available, that is accessible by its users.\nDenial of service attacks ðŸŸ© For example if you have limited number of ports, a common example of denial of service attack is the Syn flooding where multiple services ask to open a TCP connection, but it doesn\u0026rsquo;t continue with the communication, leaving the port occupied but useless.\nAnonymity On the internet we are not anonymous we are always tracked by ISP, cookies and many other strategies that I am not even aware of. This is a problem we we want to be anonymous, so how can we reach this target??\nAnonymity by proxy ðŸŸ© We just use another computer to repeat my information, this computer doesn\u0026rsquo;t have access to the underlying information, but it substitutes his IP to ours, so the end receiver doesn\u0026rsquo;t exactly know where the initial message comes from.\nMix-based systems ðŸŸ¨ Created in 1981 by David Chaum. Very similar to the previous one, in practice, in the end, it acts as a proxy but not only does it take and receive, but it also mixes together the packets it has received from the sources, applying its key.\nDisadvantage: The public-private mixing system is very slow. For this reason, a network of nodes is established, each having a symmetric key, making it much faster.\nThe important thing to note is that this system has been influential in modern tor networks.\nFullz dataleak A fullz dataleak has the minimum indispensable to create bank accounts or pay with credit cards\nName and Surname birthdate fiscal code phone number residence address So its very important to keep this information private!\nThe Tor Ecosystem This system tries to anonymize the user with principles similar to #Anonymity by proxy. The initial user message goes through different relays before reaching the end destination. The system is a little bit more complex than this, so we are breaking down a connection example\nIt\u0026rsquo;s called onion because each relay has only an outer layer of the onion. The core is what the end user receives.\nHow Tor Works The Tor network sends the payload through three random relay servers in the network. Information about what we are accessing, from who, is not accessible. But some information is still accessible, for example:\nOur ISP knows that we are trying to access the Tor network, because we need a listing of tor nodes. The exit relay knows to whom we are talking to, as this information is needed to send the message. As the exit node is often public, they are often blocked by institutions, like banks.\nOverlay networks Rete â€œoverlayâ€. Una rete chiusa al quale interno vengono distribuiti dati in forma anonima. Questo Ã¨ il principio dei servizi onion.\nService setup When a service is put onto this network it connects to some intro nodes whose role is to introduce clients to the servers. The map server-\u0026gt;intro nodes is then saved into another node, which is called the directory node. This node contain mappings from services and intro points.\nClient Connection The client that wants to connect to an anonymous service needs to know who are the intro nodes. He asks the directory node who gives him the connections. Directory gives him a descriptor, that is verified with the original .onion address who acts as a secure key.\nThe the client asks a secret string from a rendezvous node. The secret string and rendezvous are then sent to the intro nodes, and these sent it to the original service that decides whether to accept or not that service.\nIf it accepts, it sends the secret to the rendezvous, who then creates a circuit between the client and the server. Now everything can be sent and received anonymously.\nOld section Some concepts Security vogliamo impedire modi che un altro possa accedere ad informazioni riservate\nObiettivo solo qualcuno puÃ² leggere una password.\nPolicy Threath models, and mechanism. sono modi che potrebbero essere attaccati (permessi, provare a rompere la password, attaccare il sistema operativo e simili). Questo Ã¨ un buon framework generale, ma nella pratica non Ã¨ mai utilizzato. Utilizziamo questa pratica per introdurre al corso.\nÃˆ molto difficile prevedere tutti i tipi di attacco, lâ€™unica soluzione Ã¨ iterare provare a sapere dal passato ed evolvere le policy che vengono messe. Da questo si puÃ² capire che non Ã¨ perfetto. Cose da considerare sono\nCosto dellâ€™attacco Big payoff: cose che costano poco da implementare per il difensore, ma che rendono lâ€™attaccante molto inabilitato. Recuperare fra gli attacchi. Di solito gli attacchi sono fatti perchÃ© Ã¨ facile! Ãˆ facile connettersi agli altri computer nel mondo.\nPolicy flaws examples Business class airfare (tipo cambiare il biglietto dopo essere andati su, bisogna investire in un sistema che non permetta di fare questo).\nSchool system. (Students â†’ nothing, Director â†’ reads all, Teacher can add student and change password of students), un insegnante puÃ² aggiungere il director come studente e cambiargli la password, e uno studente puÃ² accedere al computer dellâ€™insegnante ðŸ’€\nYahoo recovery password asks questions! But it was listed in the wikipedia page of the persone, so breaked xD.\nCrazy gmail attack\nInsecure defaults Sono molto importanti perchÃ© Ã¨ molto facile dimenticarsi di cambiare il default in caso sia molto debole come sistema.\nDefault password! (pubblicati e.g. da un manuale riguardo qualcosa). Default permission. (e.g. amazon S3 bucket public by default). Threat model problems Sono cose che un attaccante puÃ² utilizzare per entrare nel sistema.\nClipper chips of the 90â€™ Secret design /impl, non si puÃ² supporre che il design sia nascosto, si puÃ² sempre disassemblare col giusto tempo, quindi Ã¨ facilmente rompibile diciamo, se diventa abbastanza importante da dover essere rotto. (per questo Ã¨ meglio avere una chiave) Prova a dare una occhiata al kerchoffs principle in Classical Cyphers.\nNon assumere che lâ€™utente sia conoscitore delle pratiche generali della sicurezza (e.g. dirgli che ciÃ² che scarica puÃ² essere un virus). list of attack vectors! Soft dev Source git (add backdoor that is integrated!) so the compiling shipped the attacked version\nXcode in china, compromised mirror.\nSw Updates.\nInitialization of seed?\n(some checks, and in many places, probabilmente si dimentica qualche check!)\nRandomness in Virtual machines (molto limitato, poche fonti di randomness come tastiera e cose simili.\nAppunti prof\nIntroduction ============ Welcome to 6.858 -- Computer Systems Security Course structure Lectures will be MW1-2:30, in 32-123. One paper per lecture. Tentative schedule online. Likely stable up until spring break. Lectures after spring break may change. Read the paper before lecture, and submit before lecture: Answer to a short homework question (link from schedule page). Your own question about the paper (will try to answer in lecture). Some papers about production systems, others about research ideas Even if the overall system described in the paper didn\u0026#39;t pan out, many of the ideas and techniques in the paper are important and useful. Interrupt, ask questions, point out mistakes. [http://es.csail.mit.edu:8080/room/6.858/2adb3e10](http://es.csail.mit.edu:8080/room/6.858/2adb3e10) One quiz, one final exam. Quiz during class, final during finals week. Assignments: Five labs. Defenses and/or attacks on fairly real systems. Not a lot of coding, but lots of non-standard thinking. Poke into obscure corners of x86 asm, C, Python, Javascript, .. Office hours for lab/lecture help. Lab 1, buffer overflows, first part due this Friday. Start early. Two options for Lab 5: Ordinary lab, or your choice of final project, in groups. For projects: Presentations at the end of the semester. Think of projects you\u0026#39;d like to work on as you\u0026#39;re reading papers. Both attack- or defense-oriented projects are possible. Discuss project ideas with course staff ahead of time. Two lecturers: Frans, Nickolai. 4 TAs: Rayden, Noah, Cattalyya, Jonathan. Sign up for Piazza (link on course web site). Mostly questions/answers about labs. We will post any important announcements there. Warning about security work/research on MITnet (and in general). You will learn how to attack systems, so that you know how to defend them. Know the rules: [http://ist.mit.edu/network/rules](http://ist.mit.edu/network/rules) Don\u0026#39;t mess with other peoples\u0026#39; data/computers/networks w/o permission. Ask course staff for advice if in doubt. 6.858 is about building secure computer systems Secure = achieves some property despite attacks by adversaries. Systematic thought is required for successful defense. Details matter! High-level plan for thinking about security: Goal: what your system is trying to achieve. e.g. only Alice should read file F. Common goals: confidentiality, integrity, availability. Policy: some plan (rules) that will get your system to achieve the goal. e.g. set permissions on F so it\u0026#39;s readable only by Alice\u0026#39;s processes. e.g. require a password and two-factor authentication. Threat model: assumptions about what the attacker can do. e.g. can guess passwords, cannot physically steal our server. Mechanism: software/hardware that your system uses to enforce policy. e.g. user accounts, passwords, file permissions, encryption. policy might include human components (e.g., do not share passwords) that\u0026#39;s outside of the scope of the security mechanisms Often layered: mechanism of one layer is policy of next level down. Building secure systems is hard -- why? Example: 6.858 grade file, stored on an Athena AFS server. Policy: only TAs should be able to read and write the grades file. Easy to implement the *positive* aspect of the policy: There just has to be one code path that allows a TA to get at the file. But security is a *negative* goal: We want no tricky way for a non-TA to get at the file. There are a huge number of potential attacks to consider! Exploit a bug in the server\u0026#39;s code. Guess a TA\u0026#39;s password. Steal a TA\u0026#39;s laptop, maybe it has a local copy of the grades file. Intercept grades when they are sent over the network to the registrar. Get a job in the registrar\u0026#39;s office, or as a 6.858 TA. Result: One cannot get policies/threats/mechanisms right on the first try. One must usually iterate: Design, watch attacks, update understanding of threats and policies. Post-mortems important to understand Public databases of vulnerabilities (e.g., https://cve.mitre.org/) Encourage people to report vulnerabilities (e.g., bounty programs) Defender is often at a disadvantage in this game. Defender usually has limited resources, other priorities. Defender must balance security against convenience. A determined attacker can usually win! Defense in depth Recovery plan (e.g., secure backups) Most of this lecture is about failures to make you start thinking in this way What\u0026#39;s the point if we can\u0026#39;t achieve perfect security? Perfect security is rarely required. Make cost of attack greater than the value of the information. So that perfect defenses aren\u0026#39;t needed. Make our systems less attractive than other peoples\u0026#39;. Works well if attacker e.g. just wants to generate spam. Find techniques that have big security payoff (i.e. not merely patching holes). We\u0026#39;ll look at techniques that cut off whole classes of attacks. Successful: popular attacks from 10 years ago are no longer very fruitful. Sometimes security *increases* value for defender: VPNs might give employees more flexibility to work at home. Sandboxing (JavaScript, Native Client) might give me more confidence to run software I don\u0026#39;t fully understand. No perfect physical security either. But that\u0026#39;s OK: cost, deterrence. One big difference in computer security: attacks are cheap. What goes wrong # 1: problems with the policy. I.e. system correctly enforces policy -- but policy is inadequate. Example: Business-class airfare. Airlines allow business-class tickets to be changed at any time, no fees. Is this a good policy? Turns out, in some systems ticket could have been changed even AFTER boarding. Adversary can keep boarding plane, changing ticket to next flight, ad infinitum. Revised policy: ticket cannot be changed once passenger has boarded the flight. Sometimes requires changes to the system architecture. Need computer at the aircraft gate to send updates to the reservation system. Example: Verifying domain ownership for TLS certificates. Browser verifies server\u0026#39;s certificate to ensure talking to the right server. Certificate contains server\u0026#39;s host name and cryptographic key, signed by some trusted certificate authority (CA). Browser has CA\u0026#39;s public key built in to verify certificates. CA is in charge of ensuring that certificate is issued only to legitimate domain (hostname) owner. Typical approach: send email to the contact address for a domain. Some TLDs (like .eu) do not reveal the contact address in ASCII text. Most likely to prevent spam to domain owners. Instead, they reveal an ASCII image of the email address. One CA (Comodo) decided to automate this by OCR\u0026#39;ing the ASCII image. Turns out, some ASCII images are ambiguous! E.g., foo@a1telekom.at was mis-OCRed as foo@altelekom.at Adversary can register mis-parsed domain name, get certificate for someone else\u0026#39;s domain. [ Ref: [https://www.mail-archive.com/dev-security-policy@lists.mozilla.org/msg04654.html](https://www.mail-archive.com/dev-security-policy@lists.mozilla.org/msg04654.html) ] Example: Fairfax County, VA school system. [ Ref: [http://catless.ncl.ac.uk/Risks/26.02.html#subj7.1](http://catless.ncl.ac.uk/Risks/26.02.html#subj7.1) ] Student can access only his/her own files in the school system. Superintendent has access to everyone\u0026#39;s files. Teachers can add new students to their class. Teachers can change password of students in their class. What\u0026#39;s the worst that could happen if student gets teacher\u0026#39;s password? Student adds the superintendent to the compromised teacher\u0026#39;s class. Changes the superintendent\u0026#39;s password, since they\u0026#39;re a student in class. Logs in as superintendent and gets access to all files. Policy amounts to: teachers can do anything. Example: Sarah Palin\u0026#39;s email account. [ Ref: [http://en.wikipedia.org/wiki/Sarah_Palin_email_hack](http://en.wikipedia.org/wiki/Sarah_Palin_email_hack) ] Yahoo email accounts have a username, password, and security questions. User can log in by supplying username and password. If user forgets password, can reset by answering security Qs. Some adversary guessed Sarah Palin\u0026#39;s high school, birthday, etc. Policy amounts to: can log in with either password *or* security Qs. No way to enforce \u0026#34;Only if user forgets password, then ...\u0026#34; Thus user should ensure that password *and* security Qs are both hard to guess. Example: Mat Honan\u0026#39;s accounts at Amazon, Apple, Google, etc. [ Ref: [http://www.wired.com/gadgetlab/2012/08/apple-amazon-mat-honan-hacking/all/](http://www.wired.com/gadgetlab/2012/08/apple-amazon-mat-honan-hacking/all/) ] Honan an editor at wired.com; someone wanted to break into his gmail account. Gmail password reset: send a verification link to a backup email address. Google helpfully prints part of the backup email address. Mat Honan\u0026#39;s backup address was his Apple @me.com account. Apple password reset: need billing address, last 4 digits of credit card. Address is easy, but how to get the 4 digits? How to get hold of that e-mail? Call Amazon and ask to add a credit card to an account. No authentication required, presumably because this didn\u0026#39;t seem like a sensitive operation. Call Amazon tech support again, and ask to change the email address on an account. Authentication required! Tech support accepts the full number of any credit card registered with the account. Can use the credit card just added to the account. Now go to Amazon\u0026#39;s web site and request a password reset. Reset link sent to the new e-mail address. Now log in to Amazon account, view saved credit cards. Amazon doesn\u0026#39;t show full number, but DOES show last 4 digits of all cards. Including the account owner\u0026#39;s original cards! Now attacker can reset Apple password, read gmail reset e-mail, reset gmail password. Lesson: attacks often assemble apparently unrelated trivia. Lesson: individual policies OK, but combination is not. Apple views last 4 as a secret, but many other sites do not. Lesson: big sites cannot hope to identify which human they are talking to; at best \u0026#34;same person who originally created this account\u0026#34;. security questions and e-mailed reset link are examples of this. Example: Insecure defaults. Well-known default passwords in routers. Public default permissions in cloud services (e.g., objects in AWS S3 bucket). Secure defaults are crucial because of the \u0026#34;negative goal\u0026#34; aspect. Large systems are complicated, lots of components. Operator might forget to configure some component in their overall system. Important for components to be secure if operator forgets to configure them. Policies typically go wrong in \u0026#34;management\u0026#34; or \u0026#34;maintenance\u0026#34; cases. Who can change permissions or passwords? Who can access audit logs? Who can access the backups? Who can upgrade the software or change the configuration? Who can manage the servers? Who revokes privileges of former admins / users / ...? What goes wrong # 2: problems with threat model / assumptions. I.e. designer assumed an attack wasn\u0026#39;t feasible (or didn\u0026#39;t think of the attack). Example: assume the design/implementation is secret \u0026#34;Security through obsecurity\u0026#34; Clipper chip [ Ref: [https://en.wikipedia.org/wiki/Clipper_chip](https://en.wikipedia.org/wiki/Clipper_chip) ] Broken secret crypto functions Example: most users are not thinking about security. User gets e-mail saying \u0026#34;click here to renew your account\u0026#34;, then plausible-looking page asks for their password. Or dialog box pops up with \u0026#34;Do you really want to install this program?\u0026#34; Or tech support gets call from convincing-sounding user to reset password. Example: computational assumptions change over time. MIT\u0026#39;s Kerberos system used 56-bit DES keys, since mid-1980\u0026#39;s. At the time, seemed fine to assume adversary can\u0026#39;t check all 2^56 keys. No longer reasonable: now costs about $100. [ Ref: [https://www.cloudcracker.com/dictionaries.html](https://www.cloudcracker.com/dictionaries.html) ] Several years ago, 6.858 final project showed can get any key in a day. Example: assuming a particular kind of a solution to the problem. Many services use CAPTCHAs to check if a human is registering for an account. Requires decoding an image of some garbled text, for instance. Goal is to prevent mass registration of accounts to limit spam, prevent high rate of password guessing, etc. Assumed adversary would try to build OCR to solve the puzzles. Good plan because it\u0026#39;s easy to change image to break the OCR algorithm. Costly for adversary to develop new OCR! Turns out adversaries found another way to solve the same problem. Human CAPTCHA solvers in third-world countries. Human solvers are far better at solving CAPTCHAs than OCRs or even regular users. Cost is very low (fraction of a cent per CAPTCHA solved). [ Ref: [https://www.cs.uic.edu/pub/Kanich/Publications/re.captchas.pdf](https://www.cs.uic.edu/pub/Kanich/Publications/re.captchas.pdf) ] Example: all TLS CAs are fully trusted. If attacker compromises CA, can generate fake certificate for any server name. Originally there were only a few CAs; seemed unlikely that attacker could compromise a CA. But now browsers fully trust 100s of CAs! In 2011, two CAs were compromised, issued fake certs for many domains (google, yahoo, tor, ...), apparently used in Iran (?). [ Ref: [http://en.wikipedia.org/wiki/DigiNotar](http://en.wikipedia.org/wiki/DigiNotar) ] [ Ref: [http://en.wikipedia.org/wiki/Comodo_Group](http://en.wikipedia.org/wiki/Comodo_Group) ] In 2012, a CA inadvertently issued a root certificate valid for any domain. [ Ref: [http://www.h-online.com/security/news/item/Trustwave-issued-a-man-in-the-middle-certificate-1429982.html](http://www.h-online.com/security/news/item/Trustwave-issued-a-man-in-the-middle-certificate-1429982.html) ] Several other high-profile incidents since then too. Mistake: maybe reasonable to trust one CA, but not 100s. Example: assuming your hardware is trustworthy. If NSA is your adversary, turns out to not be a good assumption. [ Ref: [https://www.schneier.com/blog/archives/2013/12/more_about_the.html](https://www.schneier.com/blog/archives/2013/12/more_about_the.html) ] Example: assuming you are running the expected software. 1. In the 80\u0026#39;s, military encouraged research into secure OS\u0026#39;es. Surprise: successful attacks by gaining access to development systems Mistake: implicit trust in compiler, developers, distribution, \u0026amp;c 2. Apple\u0026#39;s development tools for iPhone applications (Xcode) are large. Downloading them from China required going to Apple\u0026#39;s servers outside of China. Takes a long time. Unofficial mirrors of Xcode tools inside China. Some of these mirrors contained a modified version of Xcode that injected malware into the resulting iOS applications. Found in a number of high-profile, popular iOS apps! [ Ref: [https://en.wikipedia.org/wiki/XcodeGhost](https://en.wikipedia.org/wiki/XcodeGhost) ] Classic paper: Reflections on Trusting Trust. Example: decomissioned disks. Many laptops, desktops, servers are thrown out without deleting sensitive data. One study reports large amounts of confidential data on disks bought via ebay, etc. [ Ref: [https://simson.net/page/Real_Data_Corpus](https://simson.net/page/Real_Data_Corpus) ] Example: software updates. Apple iPhone software updates vs FBI. [ Ref: [http://www.apple.com/customer-letter/](http://www.apple.com/customer-letter/) ] Chrome extensions bought by malware/adware vendors. [ Ref: [https://arstechnica.com/security/2014/01/malware-vendors-buy-chrome-extensions-to-send-adware-filled-updates/](https://arstechnica.com/security/2014/01/malware-vendors-buy-chrome-extensions-to-send-adware-filled-updates/) ] Node.js library updated to include code that steals Bitcoin keys. [ Ref: [https://www.theregister.co.uk/2018/11/26/npm_repo_bitcoin_stealer/](https://www.theregister.co.uk/2018/11/26/npm_repo_bitcoin_stealer/) ] Example: machines disconnected from the Internet are secure? Stuxnet worm spread via specially-constructed files on USB drives. What to do about threat model problems? More explicit threat models, to understand possible weaknesses. Simpler, more general threat models. E.g., should a threat model assume that system design is secret? May be incrementally useful but then hard to recover. Probably not a good foundation for security. Better designs may eliminate / lessen reliance on certain assumptions. E.g., alternative trust models that don\u0026#39;t have fully-trusted CAs. E.g., authentication mechanisms that aren\u0026#39;t susceptible to phishing. What goes wrong # 3: problems with the mechanism -- bugs. Bugs routinely undermine security. Rule of thumb: one bug per 1000 lines of code. Bugs in implementation of security policy. But also bugs in code that may seem unrelated to security, but they are not. Good mindset: Any bug is a potential security exploit. Especially if there is no isolation around the bug. Example: Apple\u0026#39;s iCloud password-guessing rate limits. [ Ref: [https://github.com/hackappcom/ibrute](https://github.com/hackappcom/ibrute) ] People often pick weak passwords; can often guess w/ few attempts (1K-1M). Most services, including Apple\u0026#39;s iCloud, rate-limit login attempts. Apple\u0026#39;s iCloud service has many APIs. One API (the \u0026#34;Find my iPhone\u0026#34; service) forgot to implement rate-limiting. Attacker could use that API for millions of guesses/day. Lesson: if many checks are required, one will be missing. Example: Missing access control checks in Citigroup\u0026#39;s credit card web site. [ Ref: [http://www.nytimes.com/2011/06/14/technology/14security.html](http://www.nytimes.com/2011/06/14/technology/14security.html) ] Citigroup allowed credit card users to access their accounts online. Login page asks for username and password. If username and password OK, redirected to account info page. The URL of the account info page included some numbers. e.g. x.citi.com/id=1234 The numbers were (related to) the user\u0026#39;s account number. Adversary tried different numbers, got different people\u0026#39;s account info. The server didn\u0026#39;t check that you were logged into that account! Lesson: programmers tend to think only of intended operation. Example: poor randomness for cryptography. Need high-quality randomness to generate the keys that can\u0026#39;t be guessed. Android\u0026#39;s Java SecureRandom weakness leads to Bitcoin theft. [ Ref: [https://bitcoin.org/en/alert/2013-08-11-android](https://bitcoin.org/en/alert/2013-08-11-android) ] [ Ref: [https://www.nilsschneider.net/2013/01/28/recovering-bitcoin-private-keys.html](https://www.nilsschneider.net/2013/01/28/recovering-bitcoin-private-keys.html) ] Bitcoins can be spent by anyone that knows the owner\u0026#39;s private key. Many Bitcoin wallet apps on Android used Java\u0026#39;s SecureRandom API. Turns out the system sometimes forgot to seed the PRNG! A Pseudo-Random Number Generator is deterministic after you set the seed. So the seed had better be random! As a result, some Bitcoin keys turned out to be easy to guess. Adversaries searched for guessable keys, spent any corresponding bitcoins. Really it was the nonce in the ECDSA signature that wasn\u0026#39;t random, and repeated nonce allows private key to be deduced. Lesson: be careful. Embedded devices generate predictable keys. Problem: embedded devices, virtual machines may not have much randomness. As a result, many keys are similar or susceptible to guessing attacks. [ Ref: [https://factorable.net/weakkeys12.extended.pdf](https://factorable.net/weakkeys12.extended.pdf) ] Casino slot machines. [ Ref: [https://www.wired.com/2017/02/russians-engineer-brilliant-slot-machine-cheat-casinos-no-fix/](https://www.wired.com/2017/02/russians-engineer-brilliant-slot-machine-cheat-casinos-no-fix/) ] Example: Moxie\u0026#39;s SSL certificate name checking bug [ Ref: [http://www.wired.com/2009/07/kaminsky/](http://www.wired.com/2009/07/kaminsky/) ] Certificates use length-encoded strings, but C code often is null-terminated. CAs would grant certificate for amazon.com\\0.nickolai.org Browsers saw the \\0 and interpreted as a cert for amazon.com Lesson: parsing code is a huge source of security bugs. Example: buffer overflows (see below). Case study: buffer overflows. An important class of security problems, for which many attacks and defenses are known. This is the topic of Lab 1. Suppose your web server has a bug in the HTTP input parsing. On certain inputs, it crashes. Should you be worried? Let\u0026#39;s take a look at a simplified example. % cat readreq.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; char * gets(char *buf) { int c; while((c = getchar()) != EOF \u0026amp;\u0026amp; c != \u0026#39;\\n\u0026#39;) *buf++ = c; *buf = \u0026#39;\\0\u0026#39;; return buf; } int read_req(void) { char buf[128]; int i; gets(buf); i = atoi(buf); return i; } int main() { int x = read_req(); printf(\u0026#34;x = %d\\n\u0026#34;, x); } % gcc -g -static -fno-stack-protector -fcf-protection=none readreq.c -o readreq % ./readreq 1234 % ./readreq AAAAAAAAAAAA....AAAA Why did it crash? We should think \u0026#34;this is a bug; could an attacker exploit it?\u0026#34; Let\u0026#39;s figure out what exactly is happening. Need to know details of x86-64. % gdb ./readreq b read_req r disas $rip info reg Where is buf[]? print \u0026amp;buf[0] print $rsp print \u0026amp;i Aha, buf[] is on the stack, followed by i. The sub $0x90, %rsp allocates space for buf[] and i. Let\u0026#39;s draw a picture of what\u0026#39;s on the stack. +------------------+ | main()\u0026#39;s frame | | | | | +------------------+ | return address | +------------------+ %rbp ------\u0026gt; | saved %rbp | +------------------+ | i | +------------------+ | ... | +------------------+ | buf[127] | | ... | %rsp ------\u0026gt; | buf[0] | +------------------+ The x86 stack grows down in addresses. push == decrement %rsp, then write to *%rsp %rbp is \u0026#34;frame pointer\u0026#34; -- saved stack ptr at function entry. x $rbp x $rbp+8 Let\u0026#39;s see what the saved return %rip refers to: disas 0x00401cf3 It\u0026#39;s the instruction in main() after the call to read_req() OK, back to read_req, just before gets() disas $rip next AAAAAAA...AAA (190 times) What did gets() do to the stack? print \u0026amp;buf[0] Hmm, 190 is more than 128! How can that be? x $rbp x $rbp+8 Saved frame pointer and return eip are 0x41414141! What\u0026#39;s 0x41? next disas stepi stepi disas Now about to execute read_req()\u0026#39;s return instruction. x $rsp note rip will be 0x41414141 stepi -- crash, this is our seg fault Is this a serious problem? I.e. if our web server code had this bug, could an attacker exploit it to break into our computer? Is the attacker limited to jumping somewhere random? No: \u0026#34;code injection\u0026#34; attack. How does the adversary know the address of the buffer? Simulate attack: handle SIGSEGV nopass set{long}$rsp=\u0026lt;address of lea before call to printf in main\u0026gt;. What can the adversary do once they are executing injected code? If the process is running as root or Administrator, can do anything. Even if not, can still send spam, read files (web server, database), .. Can load bigger program from somewhere on the net. What happens if stack grows up, instead of down? Stack frame for read_req() has buf[] at highest address, so won\u0026#39;t overflow onto read_req()\u0026#39;s return %rip. Can an attacker still exploit this bug? How to defend against buffer overflows? Use a language that checks array bounds automatically. For C: Don\u0026#39;t call gets(). Intel lets you mark the stack as non-executable. Is this a 100% solution for C? Randomize layout, canaries, \u0026amp;c Structure the application to limit damage from bugs (Lab 2). Good news: simple buffer overruns like this do not work any more. Buffer overflow lessons: Bugs are a problem in all parts of code, not just in security mechanism. Policy may be irrelevant if the implementation has bugs. But stay tuned; there is hope for the defense. ","permalink":"https://flecart.github.io/notes/secury-principles-and-tor/","summary":"Security principles We have already outlined these principles in Sicurezza delle reti and talked about the concepts of authentication and integrity. Here we try to deepen these concepts and delve a little bit more on the attack vectors These are acronyms, usually called CIA and AAA for infrastructure\nConfidentiality This is one concerns about the secrecy of the sent message. We do not want others to be able to access and read what we are doing.","title":"Secury Principles and Tor"},{"content":"This is my first blog post. I\u0026rsquo;s the first time I\u0026rsquo;m writing something that would be published on my personal web-page. Programmers are used to write hello world programs as first line when they first approach a new language. It\u0026rsquo;s been a long tradition. This is something similiar for me in this moment as I write this.\nI\u0026rsquo;m writing the first blog post in my website, I still have no idea of what I will be talking about in the next posts, they will probably be some thoughs and ideas of things i learn along the way, likely related to tech or University.\nAnyway I aim to write some high-quality content, something the other people would consider as valuable. This first post is just useful to test the functionalities and looks of this small platform.\nSee you in the next posts.\nUPDATE\nI still havenÂ´t got in the habit to write blog post in a regular manner, but i think now i have an activity that could help me to learn more about my fields of interest and also write more on my blog!\nI think that a two-week study of whatever subject I\u0026rsquo;m interested in and write a post for a week in which i explain what I have learned and my own thoughts about it could be a nice idea\nI\u0026rsquo;ll update this when I have more ideas about this.\n","permalink":"https://flecart.github.io/hello-world/","summary":"First blog post","title":"Hello World"},{"content":"Ripasso Prox: 9 Ripasso: May 5, 2023 Ultima modifica: July 10, 2023 8:41 PM Primo Abbozzo: May 15, 2023 9:17 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Classi e OOP Introduzione Per la definizione di classe andare a guardare Object orientation, perÃ² lo ripeto in questa occasione, Ã¨ solamente un modello su cui andare a costruire degli oggetti.\nCapisaldi (!!) (4) ðŸŸ© Incapsulazione Astrazione EreditarietÃ  Dispatch dinamico Costruttori ðŸŸ©- Slide costruttori\nIl costruttore Ã¨ un codice utilizzato per inizializzare correttamente lo stato interno. Le regole sono le stesse dei metodi sovraccaricati (dinamica per la chiamata, statica per il numero dei parametri che prende in input).\nIncapsulazione Carat incapsulazione ðŸŸ© ossia la distinzione fra pubblico e privato, il fatto che posso decidere quanto nascondere e quanto esporre. All\u0026rsquo;esterno sono esposte solamente le interfacce che sono solitamente pubblici.\nSolamente le cose dichiarate come pubbliche sono esposte, mentre tutto lo stato interno Ã¨ nascosto e non Ã¨ accessibile all\u0026rsquo;esterno.\nSottotipi (liskov) ðŸŸ© Questo Ã¨ il principio di sostituzione di liskov, che in pratica ci dice che se S Ã¨ sottotipo di T, allora posso utilizzare S in qualunque posto di T.\nSe utilizizmao una notazione matematica, allora se ho unap roprietÃ  per un oggetto in T allora questa proprietÃ  vale anche per un oggetto in S.\nDifferenza tipo e classe ðŸŸ© C\u0026rsquo;Ã¨ una differenza fra struttura delle operazioni (quindi il tipo, cosa prendo e cosa ritorno) con lâ€™implementazione effettiva delle funzioni, i check per privati e pubblici (implementati dalle classi). Quando dichiariamo alla classe Ã¨ come se dichiarassimo allo stesso momento una interfaccia per essa.\nconsideriamo la definizione di una classe come accompagnata da una definizione implicita di un\u0026rsquo;interfaccia della vista pubblica di quella classe.\nIn questo senso la classe diventa un elemento nel nostro sistema dei tipi.\nAstrazione (!) ðŸŸ© La nozione di astrazione Ã¨ strettamente legata all\u0026rsquo;interfaccia implicita che la classe induce.\nLâ€™astrazione di permette di andare ad elaborare con alcuni concetti che nativamente non esistono, per esempio non esiste nativamente il tipo Euro, ma puÃ² essere implementata attraverso il tipo concreto degli interi. Le classi forniscono delle interfacce che permettono una modifica controllata dellâ€™oggetto che viene rappresentato, questo Ã¨ il significato di astrazione.\nle interfacce ci permettono di fornire ai clienti una descrizione del \u0026ldquo;contratto\u0026rdquo; che i nostri oggetti promettono di soddisfare, senza costringerci a fornire la loro effettiva implementazione.\nossia descrive ciÃ² che prende in input, ciÃ² che deve andare a ritornare. senza dire esattamente come Ã¨ implementata quella logica.\nClassi astratte ðŸŸ© Sono una via di mezzo fra interfaccia e classe nel senso che possono lasciare delle funzioni non implementate\nEreditarietÃ  Sottotipaggio ed ereditarietÃ  (2) Ci sono due keyworks principali quando andiamo a parlare di sottotipaggoi ed ereditarietÃ , sono extends and implements.\nExtends: prende anche i metodi (proprio l\u0026rsquo;implementazione) di tutti metodi e gli stati del genitore. Doppia operazione: Relazione di sottotipaggio col tipo da cui estende Prendere tutti i metodi dichiarati sono presenti ora anche qui. Implements: crea l\u0026rsquo;implementazione dellâ€™interfaccia astratta. C\u0026rsquo;Ã¨ una leggera differenza fra queste keywords se utilizzate per interfacce oppure per classi. Credo l\u0026rsquo;unica cosa che cambia Ã¨ che per extends nelle classi mi porto dietro anche stati e funzioni e anche i vincoli di incapsulamento.\nIn breve: sottotipi parlano di operazioni, e manipolazione i interfacce fre la varie classi, mentre lâ€™ereditarietÃ  va a parlare di metodi che possono essere utilizzate o meno.\nDifferenza principale fra sottotipaggio ed ereditarietÃ \nShadowing Come gestire i casi di ereditarietÃ  in cui una stessa variabile Ã¨ stata dichiarata con esattamente lo stesso nome?\nRegole di scoping statico! In pratica il parent Ã¨ visto come uno scope piÃ¹ esterno, e si risolve in questo modo.\nOverriding dei metodi Coerentemente al principio di astrazione, posso cambiare il contenuto (quindi la semantica) di una funzione senza cambiarne la signature, sulla stessa logica posso reimplementare un metodo in un child class.\nUna differenza tra l\u0026rsquo;overriding dei metodi e lo shadowing delle variabili Ã¨ che il primo Ã¨ risolto dinamicamente, mentre il secondo Ã¨ risolto staticamente.\nModificatori di visibilitÃ  (2) Ci sono dei modi per andare a modificare la visibilitÃ  durante le relazioni di ereditarietÃ  fra le classi, queste son ooil packaged e protected\npackaged: se sei un figlio allora puoi vedere i metodi privati (tutto lo stesso pacchetto puÃ² vedere questi metodi. Protected: tutte le sottoclassi, anche in moduli diversi possono utilizzare le funzioni ereditate protected, solo che l\u0026rsquo;esterno non puÃ² comunque andare ad accederci. Tipi intersezione Questi tipi intersezione prendono in input due classi e creano una classe che abbia entrambe le caratteristiche delle due classi. Sono diverse dai tipi unione, perchÃ© questi tipi unione possono essere o uno o lâ€™altro, nel senso che non sono entrambi in contemporanea!.\nIn un certo senso sono concatenati questi valori. Una cosa interessante Ã¨ che il grafico delle inheritance Ã¨ un DAG\nEreditarietÃ  multipla problemi: diamante Slide introduzione dei problemi di ereditarietÃ  (2 sol)\nQuesta implementazione ha molti problemi quando eredito due cose che hanno una intersezione, come per esempio un metodo con lo stesso nome. Allora come si risolve questo problema?\nIl problema principale Ã¨ la diamond of death\nDynamic dispatch Early and late binding Late: quando ho lâ€™oggetto io vado a cercare lâ€™oggetto, se lo trovo allora lo eseguo, se non câ€™Ã¨ allora continuo la ricerca finchÃ© non lo trovo, allora do errore: Ã¨ una cosa molto simile al prototyping.\nEarly: Utilizza infomrazioni statiche per risolvere lâ€™ambiguitÃ , questo dovrebbe farlo C per esempio.\nMetodi statici Niente ci vieta di andare a definire dei metodi statici che vengono risolti in modo statico.\nImplementazione degli oggetti (link) SI potrebbe tenere una lista linkata fra tutte le ereditarietÃ , solo che diventa una cosa molto lenta, perchÃ© potrebbero esserci molti accessi: vado a cercare fino al top se ci sia o meno questo metodo per una certa classe.\nEarly and late binding Accesso via offset: per accedere allo stato, faccio in modo molto simile alle struct, che in pratica vanno a calcolare offset rispetto a qualcosa, il calcolo dellâ€™offset per il singolo stato Ã¨ molto veloce, una cosa leggermente piÃ¹ complicata Ã¨ la ricerca del metodo corretto, se questo Ã¨ stato sovrascritto o simile. (fa ricerca lineare, va su finchÃ© non trova il metodo.\nCHIAMATA DEL METODO\nNon solo vogliamo andare a creare uno stack frame, variabili locali e parametri abbiamo in piÃ¹ anche le variabili di istanza! Semplicemente prende il this e ci applica lâ€™offset per prendere le informazioni, le slides lo fanno molto piÃ¹ complicato.\nVtables(!!) Ogni oggetto ha un puntatore alla propria vtable della propria classe, con giÃ  tutti i puntatori alle funzioni corrette per le funzioni.\nSlides ereditarietÃ \nDovrebbe funzionare solamente per ereditarietÃ  singola, non so per la multipla come funziona questa della vtable.\nClasse base fragile Câ€™Ã¨ il problema della composizionalitÃ , nel senso che non possiamo andare a compilarli in modo diverso, se cambiamo una classe padre, allora bisogna andare a ricompilare tutti childs, Ã¨ un problema di ingegneria del software questo.\nType parameter erasure In Java fragile Ci sono alcuni metodi per andare a gestire il problema della classe fragile. Come gestire questo problema quando l\u0026rsquo;intera classe Ã¨ stata compilata a sÃ© stante. Viene risolto a caricamento e la prima reference viene risolta e sostituita al codice di ricerca col riferimento al codice effettivo.\n","permalink":"https://flecart.github.io/notes/classi-oop/","summary":"Ripasso Prox: 9 Ripasso: May 5, 2023 Ultima modifica: July 10, 2023 8:41 PM Primo Abbozzo: May 15, 2023 9:17 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Classi e OOP Introduzione Per la definizione di classe andare a guardare Object orientation, perÃ² lo ripeto in questa occasione, Ã¨ solamente un modello su cui andare a costruire degli oggetti.\nCapisaldi (!!) (4) ðŸŸ© Incapsulazione Astrazione EreditarietÃ  Dispatch dinamico Costruttori ðŸŸ©- Slide costruttori","title":"Classi OOP"},{"content":"K-Means Neural Gas Esempi in azione: https://www.youtube.com/embed/XtC1M7nrDk0\n","permalink":"https://flecart.github.io/notes/clustering-algorithms/","summary":"K-Means Neural Gas Esempi in azione: https://www.youtube.com/embed/XtC1M7nrDk0","title":"Clustering Algorithms"},{"content":"Ripasso Prox: 40 Ripasso: May 17, 2022 Ultima modifica: March 7, 2023 1:41 PM Primo Abbozzo: November 25, 2021 12:17 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\n7 Hopital , Taylor e Peano 7.1 De Hopital 7.1.1 Lemmi preliminari Questo lemma preliminare era giÃ  presente per la prova del teorema degli zeri\nQuesto lemma Ã¨ molto interessante perchÃ© mette in relazione il finito (le successioni) con l\u0026rsquo;infinito (i reali) In molte dimostrazioni si dÃ  per scontato questo lemma, ma Ã¨ una sottigliezza importante che giustifica l\u0026rsquo;utilizzo di successioni per limiti reali. Ci permette di semplificare molto le dimostrazioni perchÃ© riusciamo a trattare le successioni molto meglio.\n7.1.2 ipotesi Enunciato al finito, finito\nEnunciato, limite al finito, asintoto\nEnunciato, limite destro o sinistro\nEnunciato limite all\u0026rsquo;infinito\nIl fatto che voglio che sia sigma sia la derivata di sigma siano diversi da zero, Ã¨ perchÃ© la conclusione deve avere entrambi diversi da zero.\n7.1.3 Dimostrazione Dimostrazione in slide\nNote sulla dimostrazione\nUtilizzo Cauchy per dire che esiste una successione che mi piace. Utilizzo il lemma delle successioni per dire che la successione trovata con cauchy Ã¨ proprio quello che mi serve Faccio uguale questa cosa di cauchy con la divisione senza le derivate e concludo per una parte. I passi principali sono:\nCercare di esprimere il limite della frazione come il limitie della frazione con input una successione.\nRiscrivere la frazione come la frazione - il punto che vogliamo calcolare (per ipotesi sto sottraendo 0) perchÃ© cosÃ¬ possiamo utilizzare dopo cauchy. Utilizziamo cauchy ed esprimiamo la frazione al punto uno come una divisione fra derivate. Dalla divisione fra derivate in successione utilizziamo il lemma e ci riconduciamo alla continuitÃ . 7.2 Infiniti ed infinitesimi Queste conclusioni si adagiano fortemente sulle conclusioni del teorema di de l\u0026rsquo;Hopital\n7.2.1 Confronto fra infiniti Il teorema di De l\u0026rsquo;Hopital Ã¨ molto utile per descrivere una gerarchia degli infiniti. Possiamo confrontare quale funzione cresce piÃ¹ in fretta di un altro.\nEnunciato\nC\u0026rsquo;Ã¨ anche il caso in L = $\\infty$, in quel caso si dice che Ã¨ di ordine inferiore.\nConclusioni\n7.2.2 Confronto fra infinitesimi Si potrebbe fare la stessa cosa per gli infinitesimi, si otterrebbero risultati opposti, ma il concetto Ã¨ lo stesso si utilizza sempre il concetto di teorema di Hopital.\nDefinizione infinitesimo\nEnunciato\nO-piccolo di funzione Il concetto di O-piccolo riesce a catturare il concetto di errore di misura (piÃ¹ o-piccolo Ã¨ grande, piÃ¹ precisa Ã¨ la mia misura).\nDefinizione Intuizione\nIn modo grossolano, se f Ã¨ infinitesimo di ordine maggiore rispetto al denominatore g, allora f Ã¨ un opiccolo di g.\nIn pratica si dice che una funzione g Ã¨ un o-piccolo di una funzione f se per il punto di cui stiamo calcolando il limite, g Ã¨ un infinitesimo di ordine superiore rispetto a f. (ricolleghiamo con il confronto fra infinitesimi)\nEnunciato 7.3.2 ProprietÃ  algebriche O-piccolo possiede alcune proprietÃ  algebriche di interesse, che sarebbe buona cosa studiare, quindi:\nDerivazione di altri O- e somma\nPotenze\nComposizione\nConstante\n7.3.3 Funzioni di stesso ordine Enunciato e dimostrazione\n7.4 Serie di Taylor L\u0026rsquo;idea principale per le serie di Taylor Ã¨ trasformare le funzioni trascendentali con alcuni polinomi.\nIn modo che alla fine si abbia un limite di rapporto di polinomi che equivalga alla funzione trascendentale, vogliamo una approssimazione della funzione che sia abbastanza precisa.\nsarÃ  alla fine un polinomio infinito!\n7.4.1 Intuizione Vogliamo cercare quale polinomio approssima meglio una funzione per ogni grado. Scopriamo che per una funzione continua Ã¨ la costante f(0) stessa per una funzione continua in questo punto. Formalizzato leggermente meglio questo puÃ² diventare una dimostrazione.\ne si ha che Ã¨ O(1). Faccio lo stesso ragionamento per gradi superiori e mi trovo la serie di taylor, con qualunque approssimazione che mi serva. Consideriamo il caso in cui siamo sul 0, per una funzione continua e derivabile reale.\nEsempio con O(x) Allora sappiamo che $$ \\lim_{ x \\to 0 } \\frac{f(x) - f(0)}{x} = f'(0) \\in \\mathbb{R} $$ Questo implica il fatto che $$ \\lim_{ n \\to 0 } \\frac{f(x) - f(0)}{x} - f'(0) = 0 \\implies \\lim_{ n \\to 0 } \\frac{f(x) - f(0) - f'(0)x}{x} = 0 $$ Dove abbiamo utilizzato la continuitÃ  del limite per somme e sottrazioni. Questo ci dice che tutto quanto sopra Ã¨ un $o(x)$ Ossia si puÃ² riscrivere quanto sopra come $f(x) = f(x) + f'(0)x + o(x)$\nSi puÃ² continuare su su questa scia e approssimare la funzione tramite $o(x^{2})$ e in teoria si puÃ² continuare cosÃ¬ all\u0026rsquo;infinito. Questo non Ã¨ una dimostrazione formale, nemmeno matematica, ma dÃ  la giusta intuizione sul perchÃ© la serie di Taylor funziona.\nEsempio con $O(x^{2})$ Consideriamo per un instante questo limite $$ \\lim_{ x \\to 0 } \\frac{f(x) - f(0) - f'(0) x - a_{1}x^{2}}{x^{2}} $$ Notiamo che sia sopra che sotto Ã¨ continuo, per questo motivo possiamo utilizzare il teorema #7.1 De Hopital da cui ricaviamo $$ \\lim_{ x \\to 0 } \\frac{f'(x) - f'(0) - 2a_{1}x}{2x} $$ Si puÃ² notare che la prima parte Ã¨ un altra derivata, mentre l\u0026rsquo;altra parte Ã¨ un coefficiente, ossia abbiamo $$ \\lim_{ x \\to 0 } \\frac{f'(x) - f'(0)}{2x} - a_{1} = \\frac{1}{2}f''(0) - a_{1} $$ Questo significa che se settiamo il coefficiente in modo adatto possiamo avere un $o(x^{2})$ senza nessun problema! Ossia se $a_{1} = \\frac{1}{2}f''(0)$ vale che l\u0026rsquo;espressione di sopra Ã¨ un $o(x^{2})$ di sopra, per cui possiamo scrivere che\n$$ f(x) \\approx f(0) + f'(0)x + a_{1}x^{2} + o(x^{2}) $$ Con $a_{1}$ il valore di sopra. Applicando ancora Hopital sopra si puÃ² avere il termine con esponente ancora superiore cosÃ¬ via!\n7.4.2 Enunciato Taylor e Peano Nota: si puÃ² analizzare Taylor in una altra forma, che Ã¨ trattata in Massimi minimi multi-variabile#Resto secondo Peano\nEnunciato Taylor Sia $f: (a, b) \\to \\mathbb{R}$ una funzione continua, e sia $0 \\in (a, b)$ Poniamo $f$ derivabile n-volte in $\\bar{x} = 0$\nAllora andiamo a definire il polinomio di taylor in $\\bar{x} = 0$ di grado $\\leq n$ il polinomio $$ T_{n}(x) = \\sum_{j=0}^{n} \\frac{f^{(j)}(0)}{j!}x^{j} $$ Che Ã¨ l\u0026rsquo;unico polinomio di grado $\\leq n$ tale per cui valga $$ f(x) = T_{n}(x) + o(x^{n}) $$ per $x \\to 0$\nEnunciato Peano Questo Ã¨ esattamente il precedente, ma stiamo shiftando il polinomio, permettendo di avere dei valori che non siano necessariamente su 0. Sia $f: (a, b) \\to \\mathbb{R}$ una funzione continua, e sia $\\bar{x} \\in (a, b)$ Poniamo $f$ derivabile n-volte in $\\bar{x}$\nAllora andiamo a definire il polinomio di taylor in $\\bar{x}$ di grado $\\leq n$ il polinomio $$ T_{n}(x) = \\sum_{j=0}^{n} \\frac{f^{(j)}(\\bar{x})}{j!}(x - \\bar{x})^{j} $$ Che Ã¨ l\u0026rsquo;unico polinomio di grado $\\leq n$ tale per cui valga $$ f(x) = T_{n}(x) + o((x - \\bar{x})^{n}) $$ per $x \\to \\bar{x}$\n7.5 Serie di Taylor note 7.5.1 Esponenziale e Logaritmo Dimostrazione espo\nLogaritmo $$ \\ln(1 + x) = \\sum_{i = 1}^{n} \\frac{(-1)^{i - 1}}{i} \\cdot x^{i} + o(x^{n}) $$ con $x \\to 0$.\n7.5.2 Goniometriche Una nota di valore Ã¨ che l\u0026rsquo;espansione del seno ha solamente polinomi dispari, questo Ã¨ in stretta relazione con la disparitÃ  del seno, mentre per il coseno, dato che Ã¨ pari, si hanno solamente polinomi di gradi pari.\nSeno\nCoseno\n!\nBinomiale generalizzato Descrizione\n, Peano/Untitled 26.png]]\nCoseno\n!\nElementi di ripasso Vecchi dubbi Non ti ricordi esattamente le ipotesi (anche la tesi) di hopital (il fatto che deve esistere la frazione delle derivate, non l\u0026rsquo;avevo considerato in ipotesi e data per scontata, 2. il fatto di necessitare della continuitÃ  in tutto il dominio e della derivabilitÃ  tranne nel punto di valutazione. riguardo la tesi mi sono scordato la parte sull\u0026rsquo;esistenza del limite della frazione. fai attenzione nella dimostrazione di Hopital a non farei calcoli dentro al limite che Ã¨ un abuso di notazione. Fai attenzione all\u0026rsquo;eliminazione dell\u0026rsquo;esiste nella dimostrazione di Hopital per caso finito. Dopo piÃ¹ di un anno sembra che taylor sia la cosa piÃ¹ importante in questi appunti.\n11/02/24 Sono ritornato a guardare questo appunto, di nuovo per Taylor lmao, ho riscritto bene l\u0026rsquo;intuizione di dimostrazione.\n","permalink":"https://flecart.github.io/notes/hopital-taylor-peano/","summary":"Ripasso Prox: 40 Ripasso: May 17, 2022 Ultima modifica: March 7, 2023 1:41 PM Primo Abbozzo: November 25, 2021 12:17 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\n7 Hopital , Taylor e Peano 7.1 De Hopital 7.1.1 Lemmi preliminari Questo lemma preliminare era giÃ  presente per la prova del teorema degli zeri\nQuesto lemma Ã¨ molto interessante perchÃ© mette in relazione il finito (le successioni) con l\u0026rsquo;infinito (i reali) In molte dimostrazioni si dÃ  per scontato questo lemma, ma Ã¨ una sottigliezza importante che giustifica l\u0026rsquo;utilizzo di successioni per limiti reali.","title":"Hopital, Taylor, Peano"},{"content":"#statistics\nIntroduzione This is a short introduction to statistical learning, made with the help of the book ISLP (mi sento positivo ad affrontare la lettura di questo libro, ora che sta in python non lo vedo piÃ¹ come un libro solamente per statistici)\nstatistical learning refers to a set of approaches for estimating $f$ .\nUtilizzi del statistical learning Solitamente sono due gli utilizzi Predizione e inferenza. Per predizione intendiamo il miglior modello che possa produrre le Y che ancora non conosciamo. Per inferenza significa il miglior modello f per predire Y che conosciamo.\nNel primo caso la funzione migliore $f$ potrebbe benissimo restare sconosciuta, ci importa solamente che predica con accuratezza, mentre nel secondo caso vorremmo anche conoscere $f$.\nIn un certo senso l\u0026rsquo;inferenza ci permette di calcolare una specie di legge fisica, (Ã¨ incorretto chiamarlo in questo modo, ma credo dia l\u0026rsquo;idea), ossia permette la comprensione del perchÃ© avendo questi input, potrÃ² avere quei output. NOTA: avendo questa comprensione potrei anche fare predizioni su dati che non esistono, credo.\nErrore riducibile e irriducibile Questo Ã¨ un concetto statistico abbastanza nuovo, utile per parlare di stima di modelli statistici. Supponiamo di avere una serie di dati solitamente indicati con $X$ , vogliamo con questi andare a predire la variabile dipendente $Y$. Solitamente andiamo anche ad introdurre un errore rappresentato con $\\varepsilon$ . Questo Ã¨ un errore indipendente da $X$, ossia non possiamo predirlo utilizzando X.\nLa branca dell\u0026rsquo;apprendimento statistico vuole utilizzare X per andare a predire Y. PerÃ² il meglio che puÃ² fare resterebbe sempre solamente una funzione $f$ che abbia quell\u0026rsquo;errore che lo faccia variare. Quell\u0026rsquo;errore potrebbe essere dovuto a informazioni che non conosciamo oppure solamente a cose che non possono essere misurate (elementi che sono principalmente dovuti al caso, che difficilmente avremmo potuto utilizzare per misurarlo)\nFormalizzazione di sopra Tutto si potrebbe formalizzare con questo ragionamento $$ E[Y - \\hat{Y}]^2 = E[(f(X) + \\varepsilon) - \\hat{f}(X)]^2 = [f(X) - \\hat{f}(X)]^2 + var(\\varepsilon) $$ Osservando che X Ã¨ una costante in questo caso, e ci interessa solamente la varianza. Si potrebbe intendere che la prima parte Ã¨ un errore riducibile (puÃ² essere fino a 0), mentre la varianza dell\u0026rsquo;errore Ã¨ parte di errore irriducibile.\nTipologie di modelli Principalmente esistono due tipologie di modelli, proveremo a parlarne estensivamente qui sotto:\nModelli parametrici L\u0026rsquo;inferenza/predizione con questo genere di modelli si fa in due step:\nScelta del modello (lineare? Quadratico? rete neurale? allora architettura della rete) Algoritmo di scelta dei parametri del modello Vedere sul libro pagina 31 per degli esempi. La caratteristica negativa di questo Ã¨ che Ã¨ fortemente dipendente dal nostro modello scelto, che non sempre puÃ² risultare essere la migliore per stimare la funzione che abbiamo:\nThe potential disadvantage of a parametric approach is that the model we choose will usually not match the true unknown form of $f$ .\nModelli non parametrici Non-parametric methods do not make explicit assumptions about the functional form of $f$ . Instead they seek an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly.\nUn esempio di questo genere di modelli potrebbero essere splines, che sono molto piÃ¹ variabili di un modello parametrico\nVantaggio principale sui parametrici by avoiding the assumption of a particular functional form for f , they have the potential to accurately fit a wider range of possible shapes for f .\nSvantaggio principale Dato che non devo imparare solamente dei parametri, ho bisogno di molto piÃ¹ dati affinchÃ© io sia accurato nella predizione\nLessico importante Variabile dipendente e indipendente Predittori, input e output e response Errore riducibile ed irriducibile ","permalink":"https://flecart.github.io/notes/introduction-to-statistical-learning/","summary":"#statistics\nIntroduzione This is a short introduction to statistical learning, made with the help of the book ISLP (mi sento positivo ad affrontare la lettura di questo libro, ora che sta in python non lo vedo piÃ¹ come un libro solamente per statistici)\nstatistical learning refers to a set of approaches for estimating $f$ .\nUtilizzi del statistical learning Solitamente sono due gli utilizzi Predizione e inferenza. Per predizione intendiamo il miglior modello che possa produrre le Y che ancora non conosciamo.","title":"Introduction to statistical learning"},{"content":"Dai video di Abdul Bari\nUltima modifica: January 21, 2022 10:24 AM Primo Abbozzo: January 16, 2022 8:31 AM Studi Personali: No\n0 Introduction Difference algo-prog Here we try to list and discuss the main differences between the algorithm and the program.\nalgo prog Design Implementation Any language program language Hardware/soft independent dependent Analysis Testing Domain knowledge Programming The algorithm step cares about the design of the program. Itâ€™s more of a abstract way of thinking (this is also the cause of the independency from the hardware software and OS), when on the other side the program is the implementation.\nI think you got the idea of why (intuition\u0026hellip;)\nI would summarize this in this way:\nAlgo â†’ top level thinking\nProg â†’ low level implementation.\nCharacteristics of algorithm Input (0 or none) Output (at least 1) Definiteness (the instructions must be precise) Finiteness (we have a finite number of instructions) Effectiveness (he only have the instructions that matter) Analysis of the algorithm Time (1 unit per instruction) Space (n of words used, or variables used) These first two are the most important ones, and most analysed in every contest.\nBut we also have other types of measurement, but they are not always used.\nNetwork bandwidth used CPU registers used Power utilized. Asymptotic analisys There are thre main ways to analyze a function in computer science\n$O, \\Omega, \\Theta$.\nThese can all be defined with limits. (c is bounded by an exist)\n$$ f(n)=O(g(n)) \\iff\\lim_{x\\to +\\infty}\\dfrac{f(x)}{g(x)} \\leq c $$ $$ f(n)=\\Omega(g(n)) \\iff\\lim_{x\\to +\\infty}\\dfrac{f(x)}{g(x)} \\geq c $$ $$ f(n)=\\Theta(g(n)) \\iff\\lim_{x\\to +\\infty}\\dfrac{f(x)}{g(x)} = c $$ Heap Main operations Insertion deletion Heapify priority queue heapsort [no heap] strassens multiplication alg ","permalink":"https://flecart.github.io/notes/algo-from-youtube/","summary":"Dai video di Abdul Bari\nUltima modifica: January 21, 2022 10:24 AM Primo Abbozzo: January 16, 2022 8:31 AM Studi Personali: No\n0 Introduction Difference algo-prog Here we try to list and discuss the main differences between the algorithm and the program.\nalgo prog Design Implementation Any language program language Hardware/soft independent dependent Analysis Testing Domain knowledge Programming The algorithm step cares about the design of the program. Itâ€™s more of a abstract way of thinking (this is also the cause of the independency from the hardware software and OS), when on the other side the program is the implementation.","title":"Algo from Youtube"},{"content":"Ultima modifica: February 25, 2023 2:07 PM Primo Abbozzo: November 9, 2021 3:00 PM Studi Personali: No\nIl debugging Ã¨ un ambito che interessa molto a Lanese perchÃ© Ã¨ molto affine al suo ambito di ricerca.\nCondizioni di correttezza Un programma di si dice corretto quando restituisce il valore voluto per ogni condizione di input\nEsempi di programmi sbagliati Un programma che a volte si pianta e non va piÃ¹. Un programma con cicli infiniti. Testing e verifica Il testing Ã¨ una delle attivitÃ  principali di un programmatore perchÃ© Ã¨ il modo piÃ¹ facile (altrimenti c\u0026rsquo;Ã¨ la dimostrazione logica, anche chiamata verifica, molto costosa) per verificare la correttezza di un programma.\nVerifica Si fa solamente se Ã¨ safety-critical perÄ‡hÃ© Ã¨ molto costosa.\nTipologie di errori Compilazione Questi sono errori che appaiono subito dal compilatore, come mancare di un punto e virgola su c, o una indentazione su python e simili.\nbisogna fare attenzione perchÃ© gli errori da compilazione non sono sempre chiari, per questo avere esperienza e tanti errori serve.\nRuntime Come un input 0 per dividere n/m. La cosa cattiva Ã¨ che spesso non so dove sia l\u0026rsquo;errore.\nLogici i, per questo avere esperienza e tanti errori serve.\nRuntime Come un input 0 per dividere n/m. La cosa cattiva Ã¨ che spesso non so dove sia l\u0026rsquo;errore.\nLogici ","permalink":"https://flecart.github.io/notes/debugging/","summary":"Ultima modifica: February 25, 2023 2:07 PM Primo Abbozzo: November 9, 2021 3:00 PM Studi Personali: No\nIl debugging Ã¨ un ambito che interessa molto a Lanese perchÃ© Ã¨ molto affine al suo ambito di ricerca.\nCondizioni di correttezza Un programma di si dice corretto quando restituisce il valore voluto per ogni condizione di input\nEsempi di programmi sbagliati Un programma che a volte si pianta e non va piÃ¹. Un programma con cicli infiniti.","title":"Debugging"},{"content":"Ripasso Prox: 15 Ripasso: December 22, 2021 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: November 10, 2021 9:33 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nLa deduzione naturale Ã¨ un possibile sistema deduttivo che utilizza il linguaggio naturale per questo motivo piÃ¹ beginner friendly. Lo facciamo prima per la Logica Proposizionale che Ã¨ molto facile\nIl sistema deduttivo Poniamo l\u0026rsquo;esistenza di Assiomi (formule in una certa logica) e regole di inferenza definite sotto. Esempi sono $P \\vdash \\varphi$ se $\\varphi$ Ã¨ un assioma. O altre cose simili con $\\land$ e simili\u0026hellip;\nUna dimostrazione allora Ã¨ una sequenza di $\\varphi_{1}, \\dots, \\varphi_{n}$ dove $\\varphi_{i}$ Ã¨ derivata con le regole di inferenza e $\\varphi_{1}, \\dots, \\varphi_{i - 1}$.\nLa differenza con la deduzione naturale Ã¨ che solitamente non ci sono assiomi\nSintassi Caratteristiche della sintassi (4) Si utilizza una BNF bidimensionale per rappresentare la ramificazione di una dimostrazione in deduzione naturale (cosÃ¬ possiamo capire bene in quale parte del ramo viene utilizzata l\u0026rsquo;ipotesi).\nRadice Ã¨ la conclusione, anche indicata come top. Nodi sono rappresentate da alcune formule Le foglie sono formule scaricate (con parentesi quadre), queste sono ipotesi locali che valgono solo in quel ramo (come l\u0026rsquo;analisi per l\u0026rsquo;or). Le foglie non scaricate rappresentano le ipotesi del problema La ricorsivitÃ  Come caratteristica delle BNF io opero in modo ricorsivo su sotto-alberi piÃ¹ semplici.\nPer ogni albero utilizzo delle regole di eliminazione o di introduzione per collegare gli alberi insieme, ecco che utilizzo le regole di introduzione ed eliminazione per collegare le regole fra di loro e cosÃ¬ faccio la verifica di correttezza della dimostrazione.\nRegole di inferenza Sintassi delle regole di inferenza Doppia lettura (top-down, bottom up)!\nDove al corrispondente del numeratore si hanno le ipotesi necessarie (che nel caso siano 0 si dicono assioma, in modo differente rispetto all\u0026rsquo;utilizzo finora)\nFormula di $\\Gamma$ sono chiamati assioni Regole senza ipotesi sono assiomi Quindi questa definizione di assioma puÃ² avere piÃ¹ denotazioni, (ambigua?) no! perchÃ© Ã¨ un insieme piÃ¹ grande che comprende entrambe le possibilitÃ .\nDevo dimostrare anche la veritÃ  di quelle ipotesi, posso allargare l\u0026rsquo;albero sopra!\nIn modo piÃ¹ generale\nRegole di introduzione ed elimitazione Queste regole sono state per la prima volta utilizzate in Teoria assiomatica degli insiemi per i primi esercizi.\nCome faccio a concludere qualcosa sapendo qualcosa?\nCosa viene ricavata da una conoscenza?\nRegole Bottom up e top down Di solito le dimostrazioni sono presentate come bottom up, perchÃ© Ã¨ considerato piÃ¹ elegante, ma di solito si lavora sulla conclusione nel caso di troppe ipotesi (due letture per BNF)\nCorrettezza di una regola Poi si potrÃ  dimostrare che si avrÃ  conseguenza logica per regole assemblate fra di loro. (ipotesi scaricate, devono essere rappresentate con un implica, ricorda che scaricate vuol dire che hanno ipotesi locali).\nInvertibilitÃ  di una regola Motivo: Ci permette di dire che le regole che stiamo dimostrando saranno poi ancora conseguenze logiche per la nostra tesi finale.\nNon scegliere regole non invertibili se posso ancora utilizzare una regola invertibile Valutare intuitivamente la \u0026ldquo;pericolositÃ \u0026rdquo; di questa regola. (come se fosse un se solo se) (equivalenza logica fra tante formule, mentre di solito Ã¨ una formula sola); Dimostrazione correttezza e invertibilitÃ  di regole classiche 7.3.1 AND âˆ§ L\u0026rsquo;AND intro- corretta e invertibile.(per invertibilitÃ , devo espandere secondo le regole della semantica).\n$$ \\dfrac{A \\,\\,\\, B }{A\\wedge B} $$ Quindi la dimostrazione della regola di introduzione dell\u0026rsquo;and Ã¨ vera, posso sempre spezzare quando mi pare.\nDimostrazione\nAND elim - La regola di eliminazione ci permette di utilizzare una ipotesi a scelta collegate con il connettivo dell\u0026rsquo;and\nRegola di eliminazione classica\nDimostrazione\nNon invertibilitÃ \nFormula di eliminazione piÃ¹ generale\nDimostrazione\nRicorda associativitÃ  a destra di $\\implies$\nNon invertibilitÃ  parziale\nMa si puÃ² vedere che non sia invertibile\n7.3.2 OR âˆ¨ Introduzione\nEnunciato\nCorrettezza\nNon invertibilitÃ \nPerchÃ© Ã¨ invertibile in un caso, e non nell\u0026rsquo;altro utilizzando le regole di eliminazione dell\u0026rsquo;OR ma non Ã¨ ancora conseguenza logica)\nQuesta regola non Ã¨ invertibile! Spesso non va bene utilizzarlo.\nEsempio non-invertibilitÃ .\nConsideriamo l\u0026rsquo;opzione $A \\vee \\neg A$ , quest Ã¨ conseguenza logica in tutti mondi, la dimostrazione Ã¨ molto semplice. quindi $\\Vdash A \\vee \\neg A$\nPerÃ² A / quello di sopra, non Ã¨ vero in tutti i mondi, quindi possiamo dire che le due non sono equivalenti, quindi non Ã¨ invertibile.\nQuindi $\\not\\Vdash A$ e $\\not \\Vdash \\neg A$.\nLa best practice Ã¨ utilizzare le ipotesi, e la top down non vale sempre, bisogna avere piÃ¹ ipotesi\u0026hellip;.\nEliminazione\nIn generale mi devo ridurre a ragionare nei mondi in cui solamente F1 o F2 valgono (un mondo piÃ¹ particolare), e poi ricompongo per dimostrare F3.\nperchÃ© Ã¨ possibile restringersi su un mondo particolare prima di analizzarli? PerchÃ© alla fin fine li sto analizzando tutti, ma in tempi (o rami diversi)\nÃˆ una regola molto molto invertibile, quindi Ã¨ da utilizzare subito!\nEnunciato\nCorrettezza\nInvertibilitÃ  simile a AND\n7.3.3 Bottom e Top Bottom\nEnunciato\nSi puÃ² notare che c\u0026rsquo;Ã¨ l\u0026rsquo;armonia anche qua, non c\u0026rsquo;Ã¨ nessun caso di introduzione e quindi non ho ipotesi nell\u0026rsquo;eliminazione.\nQuesta non Ã¨ una regola invertibile, ossia non Ã¨ vero che $F \\Vdash \\bot$ perchÃ© bot Ã¨ sempre falso.\nTop\nIl Top Ã¨ un assioma, unico assioma in questa sintassi in quanto non ho bisogno di ipotesi per dimostrarlo. (Notare che non Ã¨ una foglia).\nEnunciato\nL\u0026rsquo;eliminazione del top Ã¨ inutile, perchÃ© Ã¨ giÃ  insita l\u0026rsquo;ipotesi in un altro, perÃ² puoi notare che Ã¨ invertibile. infatti $F \\Vdash \\top$\n7.3.4 Implicazione materiale Introduzione\nQuesta regola Ã¨ molto forte, sia corretta sia invertibile, perchÃ© la dimostrazione possiede sia LHS sia RHS le stesse cose quasi\nEnunciato\nDimostrazione invertibilitÃ  e correttezza\n$F_1 \\implies F_2 \\Vdash F_1 \\implies F_2$ ovvia\u0026hellip;.\nEliminazione\nLa cosa strana Ã¨ che in questo caso devo dimostrare anche l\u0026rsquo;ipotesi.\nEcco che questa non Ã¨ invertibile\u0026hellip; Ãˆ la cosa che mi rende difficile la dimostrazione perchÃ© dopo quelle regole invertibili ho queste ipotesi con implicazioni e non Ã¨ sempre ovvio.\nEnunciato\nCorrettezza\nNon invertibilitÃ \n7.3.5 Negazione Questa Ã¨ quello che creerÃ  la necessitÃ  di una altra logica, perchÃ© il not me lo rende complesso..\nSi puÃ² dire che Non F Ã¨ una altra denotazione di questa implicazione: $F \\implies \\bot$ perchÃ© gli unici casi in cui vale questo Ã¨ che le ipotesi siano false.\nIntroduzione\nEnunciato\n$F_1 \\implies \\bot \\Vdash\\neg F_1$\nInvertibilitÃ \nMolto simile a quello sopra, riesco a dimostrare l\u0026rsquo;assurdo\nEliminazione\nEnunciato\nQuando riesco a dimostrare l\u0026rsquo;assurdo posso dimostrare qualunque cosa, la teoria Ã¨ inconsistente.\nQuesto mi elimina il Not, perÃ² mi rende tutto inconsistente.â€¼ï¸ In questo ramo tutto diventa invertibile! â€¼ï¸ Diventa solamente un gioco meccanico.\n7.3.6 RAA Reductium ad abdsurdum Questa regola Ã¨ molto simile all\u0026rsquo;introduzione del not ed Ã¨ necessario per avere la completezza per la deduzione semantica\nEnunciato\nDimostrazione\n7.4 DerivabilitÃ  Intuitivamente\nQueste regole di derivabilitÃ  sono molto utili per stabilire l\u0026rsquo;eguaglianza fra regole diverse (quando una Ã¨ derivabile dall\u0026rsquo;altra e viceversa..\n7.4.1 Dimostrazione per induzione strutturale Intuitivamente:\nDate due insieme delle regole, posso fare la dimostrazione utilizzando le regole con l\u0026rsquo;altro insieme e la dimostrazione Ã¨ uguale.\n!\n7.4.2 DerivabilitÃ  delle eliminazioni di AND Questo teorema e dimostrazione Ã¨ molto utile per stabilire l\u0026rsquo;equaglianza delle due regole, in altre parole ci sta dicendo che le due regole siano identiche.\nEnunciato e dimostrazione\nNOTA: per la seconda parte sto prendendo in esame solamente un sotto-albero di interesse.\n7.5 Armonia delle regole Sembra che il numero delle regole di eliminazione corrisponda con il numero di regole di introduzione per ogni connettivo. (e ognuno viene corrisposto)\nEliminazione ha un caso per ogni caso di introduzione e questa utilizza le regole di introduzione.\nNOTA: questo principio Ã¨ molto utile per guidarci nella creazione di regole\n7.5.1 Armonia OR Slide\n7.5.2 Armonia AND Slide\n7.6 Teorema completezza e correttezza meglio in Connettivi Logici, correttezza, variabili\n7.6.1 Correttezza Enunciato\nIl teorema di correttezza stabilisce la correttezza di tutte le regole date\nNotenotenote\nDimostrazioni di conseguenza logica\nDevi fissa il mondo porre coso giutsto e poi utilizzare la semantica del mondo.\n7.7 Deduzione naturale in logica di primo ordine Possiamo estendere la deduzione naturale con alcune regole di $\\forall, \\exists$ qui are la semantica del mondo.\n7.7 Deduzione naturale in logica di primo ordine Possiamo estendere la deduzione naturale con alcune regole di $\\forall, \\exists$ qui\nRegistro Ripassi Vecchi dubbi Come si dimostra la correttezza e l\u0026rsquo;invertibilita di una regola? il concetto di derivabilitÃ  PerchÃ© la eliminazione della negazione non Ã¨ l\u0026rsquo;introduzione del bottom? il concetto di armonia DA CHIEDERE ","permalink":"https://flecart.github.io/notes/deduzione-naturale/","summary":"Ripasso Prox: 15 Ripasso: December 22, 2021 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: November 10, 2021 9:33 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nLa deduzione naturale Ã¨ un possibile sistema deduttivo che utilizza il linguaggio naturale per questo motivo piÃ¹ beginner friendly. Lo facciamo prima per la Logica Proposizionale che Ã¨ molto facile\nIl sistema deduttivo Poniamo l\u0026rsquo;esistenza di Assiomi (formule in una certa logica) e regole di inferenza definite sotto.","title":"Deduzione naturale"},{"content":"Ripasso Prox: 17 Ripasso: May 27, 2023 Ultima modifica: May 16, 2023 9:53 AM Primo Abbozzo: March 27, 2023 10:58 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Gestione delle eccezioni Introduzione Metodi alternativi di gestione degli errori (3) ðŸŸ© A volte le computazioni falliscono. Potremmo gestirle con i result come accennato in Polimorfismo, perÃ² diventa molto macchinoso fare tutte le funzioni che debbano inoltrare solamente delle results. bisogna trovare un modo piÃ¹ naturale. Ecco che arriva una gestione delle eccezioni direttamente nel linguaggio. Si tratta un sistema di comunicazione degli errori.\nALTRI METODI\nResults, stile monadico, vedi sopra. definire dei valori eccezionali (questo si va spesso in C) Il chiamato dice al chiamante una cosa da chiamare quando fallisce. Diciamo inversione del controllo perchÃ© in questo caso Ã¨ il chiamato che dice cosa fare. Ma rende il codice poco composizionale, quindi difficile da seguire. (Questa Ã¨ la soluzione molto piÃ¹ simile alla gestione effettiva degli errori). Ma nelle eccezioni vere non Ã¨ il chiamato che ritorn al\u0026rsquo;indirizzo da eseguire ma Ã¨ il runtime che decide cosa andare ad eseguire. Questa cosa non interrompe il flusso del calcolo Con le eccezioni vogliamo trasferire il controllo a un gestore delle eccezioni questo gestore solitamente si trova sulla stack (va a risalire tutta la stack di chiamata fino a raggiungere questo gestore).\nDefinizioni di eccezioni ðŸŸ© Una eccezione Ã¨ un modo per poter interrompere la computazione attuale (descrizione di stati invalidi della computazione), in vista di errori semantici come la divisione per zero. Sono proprio dei nomi (!!!), ossia catturati nominalmente duratne la gestione degli errori.\nAlcuni stemp importanti sono la\nDefinizione di errori gestibili, e sollevamento, o raising di questi errori Politiche di gestione degli errori. (come viene trasmesso e il codiche che viene chiamato) Meccanismi di sollevamento di errori Caratteristiche delle eccezioni ðŸŸ© Nomi, le eccezioni hanno nomi e rappresentano quale errore semantico di operazioni, hanno una sintassi precisa Valori, possono contenere certi valori che comunichino qualcosa sulâ€™errore. COSTRUTTI DELLE ECCEZIONI\nSono solitamente due\nUn modo per marcare la porzione di codice protetta Un gestore delle eccezioni, che esegue nel caso sia stato sollevato all\u0026rsquo;interno di tutto il codice protetto una eccezione non gestita. Eccezioni e sottotipaggio ðŸŸ©- Possiamo utilizzare la machinery di Polimorfismo anche in questa fase! Possiamo catturare eccezioni e tutti i sottotipi di una certa eccezione.\nÃˆ anche considerata una bad practice, perchÃ© vorresti catturare una eccezione specifica (piÃ¹ facile da capirne la causa diciamo)\nhttps://stackoverflow.com/questions/2416316/why-is-the-catchexception-almost-always-a-bad-idea\nhttps://stackoverflow.com/questions/6083248/is-it-a-bad-practice-to-catch-throwable\nCATCH Ã¨ un controllo Con subtyping! IN JAVA\nSlide java sottotipaggio\nThrowable Ã¨ un tipo somma di due casi (Error, irrecuperabile) e Exception. Tutte le eccezioni tranne Runtimeexception (e.g. se finisce memoria sulla heap) Ã¨ da gestire.\nImplementazione classica ðŸŸ© Solitamente lâ€™errore viene proprio sollevato.\nOssia se vogliamo gestire un errore in un certo blocco protetto, allora linkiamo questo gestore a questo blocco.\nAlgoritmo per le eccezioni:\nCheck se il blocco attuale ha il gestore corretto (ossia supertipo dellâ€™eccezione che ho) SÃ¬ runna questo codice bindato staticamente al blocco protetto Altrimenti risolleva lâ€™errore andando al record precedente Continua fino ad arrivare al gestore di default Implementazione per ricerca binaria ðŸŸ¨- Questo solitamente per le applicazioni reali Ã¨ piÃ¹ veloce, perchÃ© quando entro in blocco protetto non ho bisogno del leggero overhead in piÃ¹ per darti il gestore.\nPraticamente per ogni singolo blocco io definisco una coppia :\nInizio del codice protetto Puntatore al gestore delle eccezioni Se non ci ho definito niente, c\u0026rsquo;Ã¨ un puntatore di default, che semplicemente risollevi gli errori.\nTutti i blocchi sono tenuti in maniera ordinata, in modo da farci una ricerca binaria se ne ho bisogno. Quindi Ã¨ piÃ¹ lenta di un fattore log(n), perÃ² dato che non ho overhead a entrare, di solito Ã¨ una cosa piÃ¹ veloce della precedente.\nIn Java Tipologie di eccezioni (2) ","permalink":"https://flecart.github.io/notes/gestione-delle-eccezioni/","summary":"Ripasso Prox: 17 Ripasso: May 27, 2023 Ultima modifica: May 16, 2023 9:53 AM Primo Abbozzo: March 27, 2023 10:58 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Gestione delle eccezioni Introduzione Metodi alternativi di gestione degli errori (3) ðŸŸ© A volte le computazioni falliscono. Potremmo gestirle con i result come accennato in Polimorfismo, perÃ² diventa molto macchinoso fare tutte le funzioni che debbano inoltrare solamente delle results. bisogna trovare un modo piÃ¹ naturale.","title":"Gestione delle eccezioni"},{"content":"Ripasso Prox: 21 Ripasso: June 3, 2023 Ultima modifica: May 14, 2023 6:13 PM Primo Abbozzo: March 18, 2023 9:23 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Guardare la parte equivalente in Note Esame che Ã¨ simile.\nLivello di trasporto Si parla di livello logico di trasporto, ma gran parte ne abbiamo giÃ  parlato in Livello applicazione e socket di UDP, TCP e Socket. trasporto end-to-end, nel senso che livello traporto viene visto solamente ad inizio e alla fine, in tutti i nodi intermedi non Ã¨ visto sto pacchetto.\nUDP (3) ðŸŸ©- Slide UDP\nClassico inizio e fine porta del socket. Lunghezza, si puÃ² vedere che massimo Ã¨ 2 alla 16, e poi il checksum per vedere se Ã¨ comunicato bene. 8 byte di header, quindi molto efficiente! Sposto a livello applicazione il check al mancato pacchetto. (esempio DNS) Oppure casi in cui perdere pacchetti non Ã¨ molto importante. CARATTERISTICHE UDP\nNessun controllo del flow, senza handshake, e per questo motivo possiamo dire che non sia connection oriented (l\u0026rsquo;affidabilitÃ  della connessione puÃ² essere spostata al livello superiore) Stateless VelocitÃ  di invio, 8 byte di overhead contro i 20 di TCP Per maggiori informazioni e confronto con TCP (il fatto di connectionless etc) guardare Intro TCP (3) e UPD ðŸŸ©.\nTCP struttura pacchetto ðŸŸ© In cui c\u0026rsquo;Ã¨ molto di piÃ¹.\nTCP segment structure\nLa nota importante oltre le flag, e altre cose Ã¨\nAcknoledgement del pacchetto precedente Ã¨ messo nellâ€™header! Internet checksum ðŸŸ© Slide internet checksum\nStile dellâ€™algoritmo:\nIncolonnati a 16 bit, faccio la somma di tutit i bit. Somma del riporto wraparound. Complemento a uno del risultato precedente Si ricordi che questo Ã¨ un metodo utile per capire se ci sono errori di trasmissione, ma non Ã¨ molto buono per difendersi da attacchi umani.\nCostruzione protocollo di trasporto reliable Vogliamo cercare di costruire un protocollo ground up, cioÃ¨ assumento piano piano, errore per errore e fixare ogni errore.\nAlla fine il protocollo cosÃ¬ creato sarÃ \nAffidabilitÃ  del trasferimento di dati Vorremo creare lâ€™equivalente di un canale di strasferimento affidabile, cosa che non Ã¨ internet, quindi vogliamo aggiungere altre cose per rendere questa interfaccia:\nSlide RDT (Reliable data transfer)\nPermetto di creare interfaccie come\nrdt_send() udt_send() unreliable data transfer, che Ã¨ quello offerto dalla rete. Stessa cosa per il lato di ricezione, ricevo da cosa unreliable, processo e li passo sopra.\nEsempi sono numerazione di pacchetti e resend di pacchetti chei non sono stati ricevuti, questi sono modi per rendere affidabili.\nPasso passo, 3 problemi Resistente alla corruzione dei pacchetti Corruzione dei pacchetti ACK Resistente alla perdita di pacchetti RETE RELIABLE\nSlide rete reliable\nÃˆ la cosa piÃ¹ stupida, si assume subito che sia reliable\nRETE CORRUTTIBILE\nSi utilizza un sistema ACK, NACK per vedere se arriva o meno il pacchetto\nSlide rete corruttibile\nSe dal lato ricevente, viene inviato il messaggio che Ã¨ arrivato sbagliato.\nCORRUZIONE DEI NAK e ACK\nChe succede con lâ€™esempio sopra se si possono corrompere anche ACK e NACK? Facciamo ack e nack sui numeri pacchetto!\nSlide ack e nak\nSENZA NAK\nSlide senza nak\nBasta mandare l\u0026rsquo;ack al pacchetto corretto! Non abbiamo piÃ¹ bisogno che si mandi nak quando arriva il pacchetto brutto.\nPERDITA DI PACCHETTI\nIn questo caso includiamoil timeout.\nSlide timing\nEsempio di rdt3 in azione\nANALISI DELLE PERFORMANCE\nSlide performance rdt3.0\nSi puÃ² notare che l\u0026rsquo;utilizzo della rete Ã¨ pochissimo! 0.027 % di utilizzo in questa analisi.\nDovremo cercare di parallellizzare il processo utilizzato per mandare e riceve\nPipelining (2) ðŸŸ©â€” Ãˆ un metodo per mandare piÃ¹ pacchetti contemporaneamente.\nCi sono due metodologie principalemente, go back N, selective repeat.\nPipelined protocols\nGO BACK N\nSignifica che con gli ultimi n ack sono stati ricdevuti correttamente, quindi col singolo ack, mi dice da dove posso cominciare a ripartire a mandare. Ma manda un sacco di pacchetti, quindi puÃ² congestionare la rete, con il vantaggio che non mi devo memorizzare.\nAutoma Go back N (NON FARE)\nEsempio di GBN\nil destinatario non deve memorizzare nel buffer i pacchetti che giungono fuori sequenza. (risparmio in memoria)\nMaggiore onere alla rete, che deve ritrasmettere alcuni pacchetti anche se vengono ricevuti correttamente.\nSELECTIVE REPEAT\nPerchÃ© ti faccio ripetere in modo selettivo.\nMeno lavoro dei router Overhead maggiore per i RTT per gli ACK, cosa che alla fine rallenta la prestazione della rete. PiÃ¹ memoria per mantenere tempi per tutti i pacchetti. Approfondimento TCP TCP trip time Slides\nSi utilizza una tecnica di media esponenziale presente anche in Scheduler ma qui facciamo anche un safety margin per essere sicuri e molto conservativi parti a 4 deviazioni (quindi molto! affinchÃ© scada deve succedere veramente qualcosa di brutto).\nAck e numeri di sequenza (no) ðŸŸ© Il libro dice che in fase di handshaking vengono stabiliti numeri di sequenza random, questo per evitare il fatto che lo 0 rappresenti una nuova sequenza, se in precedenza si Ã¨ giÃ  connessi.\nPoi cosa, TCP utilizza un ack cumulativo, sul numero di byte, e il numero di sequenza Ã¨ sempre fatto sul numero di byte inviati e ricevuti.\nNOTA: grandezza della finestra pipelining e il numero di sequenza, si osservi che se abbiamo troppi pochi numeri di sequenza, allora potremmo conseguire nellâ€™ambiguitÃ  del fatto che un pacchetto non si puÃ² distinguere se sia un pacchetto nuovo oppure una ripetizione di un vecchio pacchetto.\nla finestra deve avere ampiezza inferiore o uguale alla metÃ  dello spazio dei numeri di sequenza dei protocolli SR. per non incorrere ai problemi di ambiguitÃ . ~libro\nIl resend (2) ðŸŸ© TIMEOUT: Ã¨ molto speciale per il TCP, invece di calcolare il timeout con la formula con lâ€™estimated time, con la media esponenziale e con 4 volte la deviazione standard, viene semplicemente raddoppiato il tempo, ogni volta che scade. Probabilmente si pensa che la rete sia congestionata, quindi si aspetta un pÃ².\nImportante notare che questo ack cumulativo non Ã¨ presente in selective repeat, quindi Ã¨ piÃ¹ simile a GBN, perÃ² allo stesso tempo se scade il timeout, che Ã¨ messo solamente sul base (quindi il pacchetto piÃ¹ vecchio che Ã¨ stato mandato, non su tutti a differenza di SR) non vado a rimandare\nFAST RESEND: Quando ricevo 3 acks con lo stesso numero di sequenza, assumo che Ã¨ stato perchÃ© il paccketto con il numero di base Ã¨ stato perso. Con questa assunzione provo a rimandare il pacchetto di base.\nControllo del flusso (no) ðŸŸ© il mittente non vuole mandare cosÃ¬ tanti bytes da saturare il buffer del ricevente, per questo motivo il ricevente manda in un certo campo dellâ€™header anche lâ€™ampiezza del buffer che puÃ² ancora ricevere, e solitamente il mittente cerca di stare all\u0026rsquo;interno di quel buffer, in modo che la richiesta possa sempre essre elaborata.\nSe il l\u0026rsquo;ampiezza Ã¨ 0 non voglio stopparmi! voglio sempre mandare almeno un singolo byte di dati, altrimenti rischierei una starvation, anche se il ricevente puÃ² ricevere cose.\nControllo della Congestione (!) ðŸŸ¨++ Vengono define tre fasi per il controllo della congestione, le prime due piÃ¹ importanti mentre lâ€™ultima Ã¨ facoltativa diciamo.\nSlow start Questa Ã¨ la fase che abbiamo giÃ  studiato in precedenza, in pratica si parte con un MSS (maximum segment size) e si raddoppia fin quando continuano ad arrivare gli ACK (in pratica aggiungi 1MSS per ack). Quando perdo un pacchetto, o per il timeout o per il triplo ack, allora torno a 1 MSS, e mi setto un massimo numero di pacchetti (la metÃ  di quando Ã¨ successo la perdita) Congestion avoidance Sono in questa fase quando ho raggiunto il numero massimo di pacchetti inviati. Quando sono in questa fase allora aumento di 1/[pacchetti trasmessi] ad ogni ACK, in pratica cresco in modo lineare, molto piÃ¹ lento, fino a quando non perdo di nuovo un pacchetto. Se lo perdo per timeout torno a 1 e sono a slow start, altrimenti alcuni pacchetti sono comunque giunti al destinatario, quindi reiverto in modo molto piÃ¹ soft, in pratica dimezzo la mia window e vado in fast recovery. Fast recovery nella fast recovery aumento di 1 se lâ€™ack Ã¨ per il pacchetto che ho perso, quando arriva lâ€™ack per il segmento perso stesso rientro in quella fase, questo mi fa crescere linearmente e mi permette di partire molto piÃ¹ in fretta. Esempio: se ero a 32 pacchetti, vi vengono 3 ack per pacchetto 1, dimezzo e assumo che il pacchetto 2 sia perso, e aumento di 3 (perchÃ© sono venuti 3 acks), sono a 19, mi arrivano altri ack di 1, aumento di 1, quando arriva il 2 entro in Congestion avoidance. ","permalink":"https://flecart.github.io/notes/livello-di-trasporto/","summary":"Ripasso Prox: 21 Ripasso: June 3, 2023 Ultima modifica: May 14, 2023 6:13 PM Primo Abbozzo: March 18, 2023 9:23 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Guardare la parte equivalente in Note Esame che Ã¨ simile.\nLivello di trasporto Si parla di livello logico di trasporto, ma gran parte ne abbiamo giÃ  parlato in Livello applicazione e socket di UDP, TCP e Socket. trasporto end-to-end, nel senso che livello traporto viene visto solamente ad inizio e alla fine, in tutti i nodi intermedi non Ã¨ visto sto pacchetto.","title":"Livello di trasporto"},{"content":"Ripasso Prox: 60 Ripasso: January 5, 2022 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: September 29, 2021 9:42 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Vecchi Dubbi Assioma di rimpiazzamento e regolaritÃ , capirli meglio 2 Teoria degli insiemi 2.1 Elementi di base 2.1.1 Definizione e caratteristiche Tutto Ã¨ un insieme (su questo si basa la maggior parte della matematica) Efficace nella descrizione degli oggetti (infiniti Ã¨ ez), ma non Ã¨ efficiente nel calcolo in quanto non dÃ  nessun indizio sul\u0026rsquo;implementazione in memoria o sul modo per calcolarlo, c\u0026rsquo;Ã¨ solo una associazione Si puÃ² concludere che per l\u0026rsquo;informatico non serve a molto questa teoria, ma Ã¨ la base per la matematica.\n2.1.2 Teoria Naif Ãˆ la teoria disposta a paradossi (Russel) che afferma che gli insiemi si possono formare liberamente â†’ Assioma di comprensione.\nAbbiamo giÃ  analizzato in Logica meta-linguistica che questo paradosso Ã¨ distruttivo,\nin particolare guardare qui\nOperazioni di base\nl\u0026rsquo;appartenenza Creazione di sottoinsiemi 2.1.3 Diagrammi di Venn Il diagramma di Venn permette la rappresentazione di insiemi finiti\nL\u0026rsquo;unica cosa di ricordare, Ã¨ che non permette nesting di insiemi.\n2.2 Zermelo-Frank Set Theory Questa Ã¨ una possibile teoria assiomatica degli insiemi.\nEnti primitivi\nSono enti di cui non esiste la definizione (perchÃ© serve un punto di partenza).\nIn particolare sono enti primitivi\nAppartenenza Uguaglianza Nella slide c\u0026rsquo;Ã¨ scritto che non vengono definiti, ma poi l\u0026rsquo;assioma di estensionalitÃ  lo definisce, invece estensionalitÃ  definisce solo una relazione Insieme Andiamo ora a definire assiomi, cose ovvie di questa teoria che sia utile per dimostrare altre proprietÃ \n2.2.1 Assioma di EstensionalitÃ  e sottoinsiemi Questo assioma definisce l\u0026rsquo;uguaglianza fra gli insiemi.\nPer ogni X e Y, i due insiemi sono uguali sse hanno gli stessi elementi (un Z che sta sia in X sia in Y, possiamo dire che Z Ã¨ un elemento temporaneo utile per la stesura)\nSottoinsieme\nDefinizione = #define in c++ ossia una sostituzione, una abbreviazione.\nUguale a sopra, ma invece di SSE, utilizziamo un SE.\nSe Z appartiene a X allora appartiene a Y.\nCosa Ã¨\nRelazione fra l\u0026rsquo;ente primitivo uguaglianza con l\u0026rsquo;appartenenza, ma non Ã¨ definito come appartenenza, ente primitivo Ã¨ dato come gli pare.\n2.2.2 Assioma di separazione L\u0026rsquo;assioma di separazione Ã¨ lo strumento utile che hai visto durante la risoluzione del paradosso di Russel.\nQuindi definiamo un insieme Y a seconda di una caratteristica di X. Usiamo sempre un insieme temporaneo Z per definirlo.\nQuindi scriviamo $Y=\\{Z\\in X | P(X) \\}$ ossia esiste un Y definito per elementi Z tale che questo Z appartenga a X e soddisfa una proprietÃ  P(Z). Questo Ã¨ un abuso di notazione, che perÃ² dÃ  il senso, dovresti scrivere sempre in altro modo.\n$$ \\forall X,\\exist Y, \\forall Z, (Z \\in Y \\iff Z \\in X \\wedge Z \\in P(X)) $$ Esempio, L\u0026rsquo;insieme degli studenti biondi Ã¨ definito per gli studenti biondi che siano studenti (X) e che abbiano la proprietÃ  di essere biondi P(Z).\n2.2.3 Assioma dell\u0026rsquo;insieme vuoto e definizione Questo assioma definisce l\u0026rsquo;insieme vuoto e definisce alcune caratteristiche\nL\u0026rsquo;insieme vuoto non ha elementi\n$\\exist X, \\forall Z, Z \\not\\in X$ Ma Ã¨ ridondante perchÃ© Ã¨ sufficiente definirlo con l\u0026rsquo;assioma di separazione in questo modo:\nSto ottenendo l\u0026rsquo;insieme vuoto svuotandolo da un insieme che esiste giÃ , in questo modo:\n$$ \\empty \\coloneqq \\{X \\in Y| false\\} $$ 2.2.4 Definizione di intersezione infinita L\u0026rsquo;intersezione si puÃ² definire come l\u0026rsquo;insieme tale che sia contenuto sia in X sia in Y, quindi utilizzando assioma di separazione di puÃ² fare.\nTeorema di appartenenza a un insieme intersezione\nSi puÃ² dimostrare subito partendo dall\u0026rsquo;assioma di separazione, intendi A come insieme da cui prendi e P(Z) come appartenza a B.\nEstensione a intersezioni infinite\nBasta prendere l\u0026rsquo;intersezione binaria e utilizzare l\u0026rsquo;insieme di ritorno per altri, in modo ricorsivo se potrebbe aiutare.\nQuesto perÃ² non funziona per l\u0026rsquo;intersezione infinita ecco che c\u0026rsquo;Ã¨ il bisogno di definire l\u0026rsquo;intersezione meglio.\nDefinizione di intersezione\nF Ã¨ l\u0026rsquo;insieme tdi tutti gli insiemi da intersecare, se F vuoto lo definisco come vuoto, altrimenti utilizzo un insieme A e interseco sempre per ogni insieme Y!.\n$$ A\\in F,\\{X \\in A\\,|\\,\\forall Y :Y \\in F \\implies X \\in Y\\} $$ $\\bigcap F =$ intersezione dell\u0026rsquo;insieme Insieme di tutti gli elementi da intersecare\nEsempio\n2.2.5 Assioma di unione L\u0026rsquo;assioma dell\u0026rsquo;unione definisce l\u0026rsquo;unione fra insiemi infiniti e la notazione Ã¨ molto simile per l\u0026rsquo;insieme intersezione\n$\\bigcup F$ definito in modo simile\n$$ \\exists A \\, \\forall X, \\{X \\in A\\iff\\,\\exists Y: Y \\in F \\wedge X \\in Y \\} $$ E da questo si puÃ² dimostrare il teorema dell\u0026rsquo;unione binaria che Ã¨ la definizione di unione classica che abbiamo.\n2.2.6 Assioma del singoletto Se c\u0026rsquo;Ã¨ solo un elemento in un insieme allora questo si dice singoletto\n$$ \\forall X,\\exists Y, \\forall Z \\{Z \\in Y \\iff Z = X \\} $$ Si puÃ² utilizzare insieme all\u0026rsquo;unione per relazionarsi all\u0026rsquo;ente primitivo dell\u0026rsquo;appartenenza.\nNOTA:\nl\u0026rsquo;assioma del singoletto a volte Ã¨ ridondante perchÃ© si potrebbe definire in altro modo, in particolare attraverso l\u0026rsquo;assioma di rimpiazzamento\nINSIEME A UNIONE\nPossiamo utilizzare un abuso di notazione di questo genere:\n$$ I = \\{ A_0,A_1 ... A_n\\} := \\{A_0\\} \\cup \\{A_1\\} \\cup ... \\cup \\{A_n\\} $$ Definendo ogni insieme con piÃ¹ elementi tramite l\u0026rsquo;unione dei singoletti dei suoi elementi.\n2.2.7 Definizione dei numeri naturali e caratteristiche Definiamo ogni codifica del numero naturale partendo da $\\empty = 0$ e definendo in modo ricorsivo\n$[N + 1](/notes/n-+-1) = [N](/notes/n) \\bigcup \\{[N](/notes/n)\\}$\nUsiamo la notazione $[\\,\\,](/notes/\\,\\,)$ per le definizioni, una relazione, una implementazione di un concetto astratto\n2.2.8 Assioma dell\u0026rsquo;infinito Questo assioma permette la creazione di un insieme infinito da cui poi si possono creare i numeri, in finiti, unito all\u0026rsquo;assioma potenza si possono creare infiniti ancora piÃ¹ grandi, dato che possiede all\u0026rsquo;interno tutte le codifiche dei numeri naturali, qualcosa di metamatematico. Alcuni matematici pensano che sia una classe.\n$$ \\exists Y(\\empty \\in Y, \\forall N(N\\in Y \\implies N \\cup\\{N\\} \\in Y)) $$ Definisce in modo univoco ogni elemento di N, partendo dagli insiemi, esiste una biunivicitÃ  fra elementi di questo insieme e elementi dei numeri naturali.\nAbusi di notazione\nL\u0026rsquo;insieme infinito cosÃ¬ definito si indica con $\\mathit{N}$\n2.2.9 Assioma dell\u0026rsquo;insieme potenza Questo insieme Ã¨ utile per espandere l\u0026rsquo;infinito ossia creare degli insiemi ancora piÃ¹ grandi.\nÃˆ il primo tra gli assiomi per ora esistenti che puÃ² avere qualcosa di controverso.\n$$ \\forall X, \\exists Y, \\forall Z (Z \\in Y \\implies Z\\subseteq X) $$ Ossia l\u0026rsquo;insieme Y contiene tutti gli insiemi di X.\nAbusi di notazione\nPossiede due abusi di notazione possibili: come\n$2^{\\{1,2\\}} \\,\\text{or} \\,P(x)$\n2.2.10 Assioma di regolaritÃ  o fondazione $$ \\forall A (A \\neq \\empty \\implies \\exists B(B \\in A \\,\\wedge \\not\\exists C(C \\in A \\wedge C \\in B))) $$ Ogni insieme non vuoto ha un elemento dal quale Ã¨ disgiunto.\nFra le conseguenze: nessun insieme contiene (ricorsivamente) se stesso e ha quindi senso cercare di misurare la taglia (chiamata cardinalitÃ ) di un insieme.\nSi chiama di fondazione perchÃ© evita la ricorsione infinita permettendo, quindi, una fine. SarÃ  in seguito su questa fine che si baserÃ  il concetto di cardinalitÃ  di un insieme.\nOssia l\u0026rsquo;insieme A deve possedere per questo assioma un elemento per cui l\u0026rsquo;intersezione sia vuota).\n2.2.11 Assioma di rimpiazzamento Questo Ã¨ un assioma dibattuto, in pratica mi dice che posso costruire un altro insieme a partire da un insieme e una funzione.\nIntuitivamente: lâ€™immagine di un insieme rispetto a una formula che descrive una funzione Ã¨ ancora un insieme.\nIntuitivamente: se A Ã¨ un insieme, quindi Ã¨ abbastanza piccolo, e a ogni elemento ne associo un altro, in una relazione molti-a-uno, quello che ottengo come immagine Ã¨ ancora piccolo.\nIntuizione\nData una funzione che associa elementi fra due insiemi, allora questo assioma stabilisce che l\u0026rsquo;insieme d\u0026rsquo;arrivo, l\u0026rsquo;immagine, esiste come insieme (cioÃ¨ Ã¨ un insieme ben definito\nQuesto assioma Ã¨ necessario per gli infiniti e gestire queste cose, per le cose finite non serve.`\n2.3 Regole di dimostrazione Queste regole sono presentate con maggiore rigore in Deduzione naturale\n2.3.1 Regole di introduzione e eliminazione Eliminazione mi serve per restringere sull\u0026rsquo;ipotesi, un risultato intermedio per avere qualcosa che voglio.\nQuesta eliminazione puÃ² essere utilizzata con $\\forall X. P(X) ||\\implies$\nIntroduzione\n$\\subseteq$\n2.3.2 Abbreviazioni sia x tale che P(X) significa che prendo ogni x tale che valga quello. Probabilmente per dimostrare un certo risultato Q(X).\nDi solito si fa una lunga catena di relazioni da ipotesi che finiscono con un quindi per asserire la tesi.\n2.3.3 Esempi di dimostrazione RiflessivitÃ  di $\\subseteq$, Asimmetria di $\\subseteq$, transivitÃ  di $\\subseteq$\n2.3.4 Dimostrazione per assurdo Si utilizzano le ipotesi per dimostrare una contraddizione, per cui l\u0026rsquo;ipotesi Ã¨ falsa.\nPosso concludere qualunque cosa dopo la dimostrazione per assurdo ex-falso quodlibet abbiamo solamente dimostrato che le ipotesi sono false (quindi se le ipotesi sono binarie, Ã¨ vero l\u0026rsquo;opposto).\nSignifica che una volta giunto ad un assurdo posso dire qualunque cosa, in particolare quello che mi serviva, terminando la dimostrazione.\nL\u0026rsquo;assurdo si ha quando si ha una antinomia, un pÃ² come un paradosso in cui si conclude P e Not P.\nNON P\nsi puÃ² definire non P come P $\\implies$Assurdo\nPoniamo che $P = \\text{true} \\,$ allora $\\bar P \\implies \\text{absurd}$ passando da qualche ragionamento, cosa che chiaramente Ã¨ contro la tesi.\nDimostrazione di ex-falso quodlibet\nIP: $P, \\bar{P}$\nHP: $B$\nessendo vera P, Ã¨ vera l\u0026rsquo;unione $P \\cup B$ partendo da questa ipotesi, e unendola con l\u0026rsquo;ipotesi $\\bar{P}$ si sa che $P$ Ã¨ falso allora $B$ deve essere vera affinchÃ© $P \\cup B$ sia vera. Ecco che da un assurdo si ha qualunque cosa.\n2.4 Relazioni fra insiemi Vedere la pagina di appunti sulle relazioni fra insiemi (classi di equivalenza e simili, con anche le funzioni!) Relazioni fra insiemi\nValutazione: Non fare detour\nUtilizza la logica debole invece di forte, cioÃ¨ utilizzare solamente assiomi consociuti o teoremi dimostrati con gli assiomi e non utilizzando l\u0026rsquo;intuizione. ` :**\nNon fare detour\nUtilizza la logica debole invece di forte, cioÃ¨ utilizzare solamente assiomi consociuti o teoremi dimostrati con gli assiomi e non utilizzando l\u0026rsquo;intuizione. `\n","permalink":"https://flecart.github.io/notes/teoria-assiomatica-degli-insiemi/","summary":"Ripasso Prox: 60 Ripasso: January 5, 2022 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: September 29, 2021 9:42 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Vecchi Dubbi Assioma di rimpiazzamento e regolaritÃ , capirli meglio 2 Teoria degli insiemi 2.1 Elementi di base 2.1.1 Definizione e caratteristiche Tutto Ã¨ un insieme (su questo si basa la maggior parte della matematica) Efficace nella descrizione degli oggetti (infiniti Ã¨ ez), ma non Ã¨ efficiente nel calcolo in quanto non dÃ  nessun indizio sul\u0026rsquo;implementazione in memoria o sul modo per calcolarlo, c\u0026rsquo;Ã¨ solo una associazione Si puÃ² concludere che per l\u0026rsquo;informatico non serve a molto questa teoria, ma Ã¨ la base per la matematica.","title":"Teoria assiomatica degli insiemi"},{"content":"Struttura del DBMS Introduzione ai DBMS Schema riassuntivo #### Operazioni classiche Ci stiamo chiedendo, come facciamo a descrivere i processi che portano alla comprensione della query e della retrieval degli elementi utili? Questo deve fare il DBMS, ossia capace di - Aggiornare tuple - Trovare tuple - Gestire gli accessi - Gestire accessi concorrenti? ### Query processor #### Query compiler (3) ðŸŸ© - Parsing (crea l'albero di derivazione per la nostra query) - Pre-processing (fa check semantici sulla query) - Optimization, si occupa lui di migliorare L'ottimizzazione #### Execution engine ðŸŸ© Esegue l'effettiva computazione per la query, ed Ã¨ il punto d'incontro col resto (indexes, e logging per dire) Esegue il piano di esecuzione che probabilmente un livello superiore ha calcolato Interagisce con tutti gli altri componenti del db (ad esempio Log per transazioni e durabilitÃ , buffer e scheduler delle operazioni prolly). Anche se non so nei dettagli in che modo esegue questo (alla fine roba assembly? che livello di astrazione ha?)\nThe resource manager Compiti del resource manager (2) ðŸŸ©\u0026ndash; La cosa principale che fa questo Ã¨:\nSapere dove siano le informazioni di interessa Sapere come leggerli e restituirli in fretta In questo senso gestisce le risorse, perchÃ© gestisce le informazioni, in questo caso risorsa principale del nostro db.\nIndex file record manager ðŸŸ¨++ Ãˆ la parte del database che conosce le strutture delle tables e sa accedere ai dati, ossia contiene le strutture di dati utili per l\u0026rsquo;accesso a queste tables.\nPerÃ² non so in che modo Ã¨ implementato un index, dovresti guardare in Index, B-trees and hashes.\nBuffer Manager ðŸŸ© Si occupa di memorizzare in modo temporaneo le informazioni necessarie per fare le join e altre operazioni (anche una cache diciamo). ram riservata. Qui sarÃ  presente un nodo piÃ¹ forte e normale tipo! PuÃ² essere molto utile per tenere gli indici, per tabelle piÃ¹ frequentemente accedute! Solitamente 100MB di ram qui!, circa 25k nodi di b-tree anche!\nStorage Manager ðŸŸ© Probabilmente utilizza hash Index, B-trees and hashes per capire quale esatto blocco gli Ã¨ stato richiesto.\nSi occupa di tenere traccia dei blocchi precisi con informazioni nel disco principale (Ã¨ la parte del sistema che si occupa di restituire il blocco di interesse una volta richiesto la chiave).\nOther parts Transaction Manager Permette di fare le transazioni. Logging ðŸŸ©- Come per i filesystem basati su logging, questo Ã¨ un metodo utile per tenere traccia dei cambiamenti effettivamente fatti o meno. vedere Filesystem. Aiuta a creare l\u0026rsquo;atomicitÃ  e la consistenza necessari per ACID.\nCosa fa: Scrive log in RAM, nel buffer manager, e ci sono protocolli per far sÃ¬ che questi vengano correttamente salvati sul disco. Nel caso di problemi, comunica col recovery manager in modo che il database torni indietro in stato consistente.\nConcurrency control Questa parte si occupa della isolation in ACID, cerca di fare sÃ¬ che tutte le operazioni siano eseguite come se fossero isolate uno dall\u0026rsquo;altra, in questo caso si parla di serializzabilitÃ  dell\u0026rsquo;operazione.\nQuesta Ã¨ la parte che ha il controllo sui locks come i Semafori o Monitor per la gestione della concorrenza.\nSchedule ðŸŸ¨ Una sequenza di azioni (read, write, commit, abort) da un** insieme di transazioni**\nIn questo contesto le transazioni sono una cosa primitiva per dire. (esecuzione cronologica).\nSerializzazione ðŸŸ¥+ Questo schedule si puÃ² classificare in completo se prende in esame le operazioni di ogni singola transazione. Seriale se viene eseguita una azione alla volta per ogni transazione (anche se potrei farne di piÃ¹ assieme). Significa che faccio prima tutte le operazioni di una singola transazione, poi della prossima e cosÃ¬ via.\nUno schedule Ã¨ serializzabile, se l\u0026rsquo;effetto finale Ã¨ come di uno schedule completo seriale.\nTipologie di anomalie di concorrenza (4) Una cosa carina Ã¨ che questi processi possono essere intesi come errori di Theory of mind secondo me. Si hanno errori quando una serie fa qualcosa, ma l'altro pensa che lo stato sia di un altro genere. PiÃ¹ in generale questo problema si puÃ² riassumere in phantom anomaly, perchÃ© un oggetto viene cambiato nel momento in cui una altra transazione pensa resti la stessa.\nTransaction isolation levels ðŸŸ¥ Concurrency control methods (3) La prima Ã¨ la piÃ¹ restrittiva, perÃ² ha forti garanzie su serializzabilitÃ  basate su locks, praticamente il concetto principale Ã¨ che una singola risorsa puÃ² essere usata da una transazione alla volta (non Ã¨ totalmente corretto, le read possono essere condivise, ma il concetto resta quello lÃ¬), quindi se Ã¨ concorrente su risorse diverse, non ho problemi Optimistic concurrency control in pratica faccio tutto come se non ci fosse niente, e poi faccio. Timestamping concurrency control, ad ogni transazione Ã¨ associata un timestamp e si utilizza questo per decidere chi va prima. Se l\u0026rsquo;ordine viene violato basta rollback della transazione che lo ha violato. Join methods Nested loop join ðŸŸ© Ãˆ l\u0026rsquo;algoritmo $O(n^{2})$ idiota classico per la comparisons\nSingle loop join ðŸŸ¨++ Viene utilizzato un hash o un tree esterno di una relazione per comparare in fretta e vedere se c\u0026rsquo;Ã¨ l\u0026rsquo;esistenza.\nIn pratica si chiama single loop perchÃ© ciclo solamente sulla struttura esterna\nHash based join ðŸŸ¨+ Usiamo double hash!? Non ho capito come. Prendiamo una relazione, quella relazione la salviamo tutta dentro la hash table (con i rispettivi buckets, che siano linked list o rb-trees). Poi prendiamo l\u0026rsquo;altra relazione, passiamo dalla stessa hash, questa avrÃ  anche lui un bucket, poi su questo bucket ci faccio ricerca lineare per trovare le cose che mi interessano (quindi match su cose piccole). Ãˆ molto simile a single loop, solo che in questo caso la struttura Ã¨ necessariamente un hash per dire.\nSort Merge Join ðŸŸ© L\u0026rsquo;algoritmo lineare di sort merge, utile quando si ha un doppio ordinamento per andare a confrontare per benino i due cosi. (this should be the fastest !?!?! solo per dati generali perÃ², but needs ordering).\n","permalink":"https://flecart.github.io/notes/the-database-management-system/","summary":"Struttura del DBMS Introduzione ai DBMS Schema riassuntivo #### Operazioni classiche Ci stiamo chiedendo, come facciamo a descrivere i processi che portano alla comprensione della query e della retrieval degli elementi utili? Questo deve fare il DBMS, ossia capace di - Aggiornare tuple - Trovare tuple - Gestire gli accessi - Gestire accessi concorrenti? ### Query processor #### Query compiler (3) ðŸŸ© - Parsing (crea l'albero di derivazione per la nostra query) - Pre-processing (fa check semantici sulla query) - Optimization, si occupa lui di migliorare L'ottimizzazione #### Execution engine ðŸŸ© Esegue l'effettiva computazione per la query, ed Ã¨ il punto d'incontro col resto (indexes, e logging per dire) Esegue il piano di esecuzione che probabilmente un livello superiore ha calcolato Interagisce con tutti gli altri componenti del db (ad esempio Log per transazioni e durabilitÃ , buffer e scheduler delle operazioni prolly).","title":"The Database Management System"},{"content":"Sono variazioni possibili equivalenti: â€¢ Nastri addizionali â€¢ Testine addizionali â€¢ Nastri infiniti su entrambi i lati â€¢ Non-determinismo â€¢ Scelta probabilistica â€¢ Scelta quantistica\nTuring con nastri addizionali Questo Ã¨ presente in modo abbastanza facile sul Sipser.\nLa computazione comincia con lâ€™input sul primo nastro, e tutti gli altri nastri vuoti. Macchine di Turing con nastri addizionali In ciascun passo di computazione, ogni testina Ã© nello stesso stato, ma puÃ² essere in una posizione diversa, leggere un simbolo differente, e compiere unâ€™azione diversa. Se si raggiunge uno stato finale, lâ€™output Ã© letto dal primo nastro.\n#### Definizione formalismo ðŸŸ© L'unica differenza formale Ã¨ che questa macchina Ã¨ **parallela** cioÃ¨ ho molte macchine di turing che vanno allo stesso momento $$ \\delta: (Q - H) \\times \\Sigma^{k} \\to Q \\times(\\Sigma \\times \\left\\{ \\to, \\leftarrow \\right\\} )^{k} $$ Il restante delle tuple resta uguale. L'altra osservazione Ã¨ che lo stato esterno Ã¨ **unico**. In un certo senso Ã¨ una **pila con macchina di turing** [Linguaggi liberi e PDA](/notes/linguaggi-liberi-e-pda). Teorema di equivalenza ðŸŸ© Dimostriamo che questo formalismo Ã¨ equivalente con La macchina di Turing. Ãˆ ovvio il caso in cui nastro addizionale -\u0026gt; Turing. Ossia che\nTermina quando il l\u0026rsquo;altro non termina Se termina hanno stesso output. Si puÃ² formalizzare perÃ² alla fine Ã¨ quello.\nL\u0026rsquo;altra freccia Ã¨ provare a simulare con La macchina di Turing tutti i nastri aggiuntivi del nostro multinastro, con un simbolo in piÃ¹ che identifichiamo con $\\#$. Cominciamo (dimostrazione intuitiva): Supponiamo di avere una macchina multi nastro $\\mathcal{M}$, costruiamo con l\u0026rsquo;altra macchina $\\mathcal{M}'$ con singolo nastro che sia equivalente al primo, in questo modo dimostriamo che una TM Ã¨ anche uguale alla versione multi-nastro. Prendiamo $$ \\Sigma' = \\Sigma \\cup \\left\\{ \\# \\right\\} \\cup \\left\\{ \\bar{a} : a \\in \\Sigma \\right\\} $$ Allora I molteplici passi di computazione su molti nastri che sono un singolo passo per la multinastro possono essere simulati sul singolo nastro. La lettere barretta ci permette di mantenere il pointer sul nastro originale. Se c\u0026rsquo;Ã¨ bisogno di spazio in piÃ¹ su un nastro, debbo postare tutto a destra (tanto Ã¨ infinito e posso farlo). (nota che per questo teorema Ã¨ necessario l\u0026rsquo;infinito!!) Alla fine cancello tutto dopo il primo cancelletto e ritorno quello.\nEnumerators Questo Ã¨ un argomento extra non trattato a lezione 3.2 del Sipser viene trattato. Si puÃ² dire che Ã¨ una altra cosa equivalente alla La macchina di Turing. In modo informale, un enumeratore Ã¨ una macchina di turing con una stampante, che puÃ² esser considerato l\u0026rsquo;output della nostra macchina. Poi c\u0026rsquo;Ã¨ un work tape che puÃ² essere utilizzato come cache. Da un punto di vista formale non Ã¨ altro che una macchina di turing con 2 nastri\nMacchine di Turing non deterministiche Descrizione formalismo non deterministico ðŸŸ© L\u0026rsquo;unica differenza con La macchina di Turing, Ã¨ che invece di funzione abbiamo una relazione! Oltre a questo anche lo stato di accettazione, se un qualunque ramo accetta, allora questa macchina accetta.\nIn un certo senso questo non determinismo Ã¨ simile a quanto fatto in Grammatiche Regolari e Linguaggi liberi e PDA. Per il non determinismo. Solo che lÃ¬ il prof. li faceva piÃ¹ formali.\nSulle slides c\u0026rsquo;Ã¨ un esempio di MTnd molto semplice per dimostrare che la primalitÃ  di un numero Ã¨ calcolabile. (idea prendo in modo non deterministico un numero minore di $n$ e calcolo il modulo).\nSketch di dimostrazione di equivalenza ðŸŸ¨++ Supponendo che abbiamo l\u0026rsquo;albero di computazione, posso esplorare con Grafi#BFS tutto l\u0026rsquo;albero di computazione e avere alla fine lo stesso risultato.\nQui c\u0026rsquo;Ã¨ un albero di computazione. (poi probabilmente bisognerÃ  codificare un backtracking) Altre Una altra macchina di Turing di interesse che non trattiamo qui Ã¨ il prefix turing machine, che trattiamo in Kolmogorov complexity.\nMacchine a registri Chiamato anche URM unlimited register machine, Ã¨ un formalismo piÃ¹ simile a come sono fatti i computer moderni perchÃ© utilizzano i regsitri. Definito in (Shepherdson \u0026amp; Sturgis 1963).\nDescrizione Unlimited Register Machine ðŸŸ¨++ Supponiamo di avere $R_{1}, R_{2}, R_{3}, \\dots$ registri, ogni registro ha un numero naturale indicato con $r_{n}$ (contenuto di registro $n$) Se la computazione finisce, questa viene messa in $R_{1}$ (simile a RAX in archietture intel). L\u0026rsquo;input $N^{k}$ Ã¨ messo in tutti i registri in ordine (se non definito sono a 0).\nEsistono un sistema di istruzioni che muovono e modificano le cose dei registri:\nZero $Z(n)$ il registro $n$ Ã¨ messo a 0. Successor $S(n)$ il registro $n$ Ã¨ aumentato a $n$ Move $R(n, m)$ $m$ Ã¨ messo uguale a $n$ (sono registri) Jump $J(n, m, p)$ Salta a istruzione $I_{p}$ se i registri $n$ e $m$ sono uguali. altrimenti ignora istruzione. Ora possiamo definire una specie di ALU che Ã¨ la cosa classica di programma imperativo.\nEnunciato equivalenza ðŸŸ© Vogliamo passare in questo caso a dimostrare la calcolabilitÃ  di funzioni parziali, ossia funzioni $$ \\mathbb{N}^{k} \\to \\mathbb{N} $$ Che possono anche non terminare (in questo caso parziale).\nUna funzione parziale Ã¨ calcolabile in URM sse Ã¨ calcolabile su TM\nIdea TM =\u0026gt; URM ðŸŸ¨ Uso il risultato in #Turing con nastri addizionali, ho tanti nastri che fanno cose:\nFa instruction pointer e punta all\u0026rsquo;istruzione attuale Ha il codice del programma Ha il valore dei registri in notazione unaria (che Ã¨ equivalente), separati da U. Altri registri sono cache. Allora posso usare il contenuto del nastro 1 per trovare l\u0026rsquo;istruzione, poi uso altro per interpretarla ed eseguirla. Alla fine uso il primo valore del terzo nastro per avere il risultato. Per la modifica dei registri posso usare nastri ausiliari.\nIdea TM \u0026lt;= URM ðŸŸ¨ Supponiamo di avere un URM, vogliamo simulare una macchina di turing con la classica tupla $\\Sigma, Q, q_{0}, H, \\delta$\nChiamo un registro TAPE che conterrÃ  i valori presenti su un nastro di Turing. Inoltre dobbiamo ricordarci che questa macchina contiene numeri naturali per questo motivo abbiamo bisogno di una codifica. Scegliamo $\\Sigma = \\left\\{ 0, 1, U \\right\\}$ dove $U$ sta per empty. Allora possiamo usare la notazione in base $3$ per decodificare il numero, assumendo $code(0) = 0$, $code(1) = 1$, $code(U) = 2$.\nPoi introduciamo registri per codificare $\\delta$ la funzione di transizione. Modello WHILE Questo Ã¨ un formalismo piÃ¹ simile a uno di alto livello (quindi programma normale).Descritto in\nKfoury, Moll, Arbib - A programming approach to computability.\nDescrizione del modello WHILE (3) ðŸŸ© Questo Ã¨ simile a quanto descritto per la Semantica di un linguaggio per la parte procedurale. Abbiamo:\nAssegnazione Cicli while seguenziamento Possiamo definirlo in Sintassi e RI strutturali#4.2 Backus-Naur Form Ci sono tre forme di assegnazione, uno zero, uno successivo, uno uguale credo. Non viene fatta la parte della semantica che abbiamo fatto tempo fa a linguaggi.\nDimostrazione equivalenza ðŸŸ© Una funzione (parziale) Ã© computabile da un programma WHILE se e solo se Ã© computabile da una macchina di Turing.\nSi dimostra per induzione strutturale sulla BNF lÃ¬ precedente. I casi base sono i 3 assegnamenti (zero, successore, e predecessore) e il programma vuoto.\nPer il caso base, utilizzo un nastro separato come ho fatto per #Turing con nastri addizionali, su questo ci metto le variabili di interesse. Su questo posso codificare i casi base accennati di sopra.\nPoi caso induttivo Ã¨ while e sequenza di istruzioni. Poi per codificare la sequenza, basta concatenare molte macchine di turing normali, ognuna che codifica l\u0026rsquo;istruzione. Sappiamo che queste esistono per ipotesi induttiva. Per il while possiamo usare due macchine, una per il test, una per il corpo del while e dire che accetta quando esco dal ciclo. Ãˆ interessante osservare come siano uguali questi.\nReferences [1] Shepherdson \u0026amp; Sturgis â€œComputability of Recursive Functionsâ€ Journal of the ACM Vol. 10(2), pp. 217\u0026ndash;255 1963\n","permalink":"https://flecart.github.io/notes/estensioni-di-turing-e-altre-macchine/","summary":"Sono variazioni possibili equivalenti: â€¢ Nastri addizionali â€¢ Testine addizionali â€¢ Nastri infiniti su entrambi i lati â€¢ Non-determinismo â€¢ Scelta probabilistica â€¢ Scelta quantistica\nTuring con nastri addizionali Questo Ã¨ presente in modo abbastanza facile sul Sipser.\nLa computazione comincia con lâ€™input sul primo nastro, e tutti gli altri nastri vuoti. Macchine di Turing con nastri addizionali In ciascun passo di computazione, ogni testina Ã© nello stesso stato, ma puÃ² essere in una posizione diversa, leggere un simbolo differente, e compiere unâ€™azione diversa.","title":"Estensioni di Turing e altre macchine"},{"content":"Ripasso Prox: 30 Ripasso: December 19, 2021 Ultima modifica: December 14, 2021 3:43 PM Primo Abbozzo: October 13, 2021 3:29 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 2 Funzioni 2.1 NecessitÃ  Riutilizzare codice giÃ  scritto\nModuli disgiunti che possono essere scritti anche da persone diverse che lavorino assieme e simili\n2.2 Scope Parentesi per gli scope\nDoppia dichiarazione Ã¨ sbagliata\n2.2.1 Globali 2.2.2 Locale 2.2.3 Procedural Abstraction 2.3 Dichiarazione e chiamata 2.3.1 Definzione A volte anche con heading.\nDobbiamo bene distinguere la dichiarazione e la definizione di funzioni.\nLa definizione e\u0026rsquo; l\u0026rsquo;intestazione con anche il corpo.\nMentre invece la dichiarazione `e solamente l\u0026rsquo; heading.\n2.3.2 Chiamata void e normale CI sono questi due tipi di chaimata, non void e voi\u0026hellip;. per il resto lo sai\n2.3.3 Corpo della funzione Corpo, in cui scrivi le cose\n2.3.4 Il return 2.4 Parametri Passare parametri, lo sai\n2.4.1 Const keyword utilizzato come costante nel corpo della funzione\nNon puo\u0026rsquo; essere modificato.\n2.4.2 reference Si chiama anche alias, o comunque passaggio per referenza, una sinonimia, le cose hanno lo stesso nome.\n2.4.3 value Sono parametri formali, ossia sono una copia del parametro originale\nNamespaces Tenere il codice in orgine inonimia, le cose hanno lo stesso nome.\n2.4.3 value Sono parametri formali, ossia sono una copia del parametro originale\nNamespaces Tenere il codice in orgine\n","permalink":"https://flecart.github.io/notes/funzioni/","summary":"Ripasso Prox: 30 Ripasso: December 19, 2021 Ultima modifica: December 14, 2021 3:43 PM Primo Abbozzo: October 13, 2021 3:29 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 2 Funzioni 2.1 NecessitÃ  Riutilizzare codice giÃ  scritto\nModuli disgiunti che possono essere scritti anche da persone diverse che lavorino assieme e simili\n2.2 Scope Parentesi per gli scope\nDoppia dichiarazione Ã¨ sbagliata\n2.2.1 Globali 2.2.2 Locale 2.2.3 Procedural Abstraction 2.3 Dichiarazione e chiamata 2.","title":"Funzioni"},{"content":"A brief history This field was quite developed in 1970 (started in 1920) when mathematicians had the same problem over and over again and needed a name. But this was only the theory. The practical applications came later. A modern use is in machine learning a statistics.\nForm historical point of view\n1947 simplex method popularized by Dantzig at Stanford Many people in soviet union in the Â´60 worked on this (they already know about he applications!) People in aerospace engineering used these in the \u0026lsquo;60 to balance loads and stuff like that \u0026lsquo;90 people started using it in communications, like control and signal processing. Important Theorems Separating hyperplane theorem Given two non-empty disjoint sets, there exists $a \\neq 0$ such that $$ a^{T}x \\leq b, \\text{ for } x \\in C $$ And $$ a^{T}x \\geq b, \\text{ for } x \\in D $$ We can understand this as separating line!\nSupporting hyperplane theorem Dual theory Minimum and Minimal Generalized Inequalities We now overload the operator $\\leq$ with a new meaning used. The mean inspiration is from a proper cone. We say that given a cone $K$ the generalized inequality (partial order) is defined as this: $$ x \\leq_{K} y \\iff y - x \\in K $$ Similarly the strict partial order is true when $y - x \\in int K$ that is, it is in the interior of the cone (no borders).\nDual cones We define this cones to be, given a cone $K$, the dual is: $$ K^{*} = \\left\\{ y \\mid y^{T}x \\geq 0 , \\text{ for all } x \\in K \\right\\} $$ For definition of cones see Analisi di ConvessitÃ #Convex Cone. It\u0026rsquo;s called self dual when the dual is itself (and example is the first quadrant).\nShur complement TODO\n","permalink":"https://flecart.github.io/notes/introduction-to-convex-optimization/","summary":"A brief history This field was quite developed in 1970 (started in 1920) when mathematicians had the same problem over and over again and needed a name. But this was only the theory. The practical applications came later. A modern use is in machine learning a statistics.\nForm historical point of view\n1947 simplex method popularized by Dantzig at Stanford Many people in soviet union in the Â´60 worked on this (they already know about he applications!","title":"Introduction to Convex Optimization"},{"content":"Ripasso Prox: 30 Ripasso: June 6, 2023 Ultima modifica: May 14, 2023 6:13 PM Primo Abbozzo: March 13, 2023 9:20 AM Studi Personali: No\nElementi di ripasso Teoria dei Tipi Introduzione Definizione ðŸŸ©â€” Un metodo sintattico praticabile per dimostrare l\u0026rsquo;assenza di determinati comportamenti del programma, fatto classificando le unitÃ  sintattiche in base ai tipi di valore che assumono\nVogliamo che fosse praticabile nel senso che effettivamente lo possiamo implementare, cioÃ¨ ci permettono di avere certe tipologie di garanzia. ma ancora Ã¨ una definizione molto ampia. E di solito si puÃ² fare una analisi statica del comportamento del programma.\nUn altro modo per definirlo (questo molto piÃ¹ buono) Ã¨\nCollezioni di valori omogenei e rappresentabili e una serie di operazioni su di esse.\nOssia omogenei nel senso che hanno tutti certe proprietÃ , e rappresentabili perchÃ© effettivamente possiamo metterli in memoria (per esempio non posso avere come tipo i Reali in modo primitivo, perchÃ© non Ã¨ rappresentabile).\nEsecuzione corretta, + ottimizzazione da parte del compilatore. Utilizzo dei tipi (4+) (!!!) ðŸŸ¨â€”- Slide sull\u0026rsquo;utilizzo dei tipi organizzazione concettuale\nSlide astrazione\nSlide correttezza\nSlide implementazione\nProgettazione: posso descrivere in modo concettuale cosa fa il programma e aiutare a verificare la correttezza del programma, â€œseparare logicamente elementi concettualmente diversiâ€ (posso creare tipi per certi concetti e quindi ragionare meglio, pensa sviluppare solo in assembly!) Documentazione: ci danno informazioni in piÃ¹ riguardo il ruolo della variabile nel nostro programma. Una idea bella Ã¨ parlare di tipi come se fossero commenti Astrazione: in fase di implementazione possono aiutare a gestire meglio il nostro progetto, solitamente attraverso interfacce (a questo tipo ho certe operazioni, non ho niente di sotto), ci permette di modulizzare e gestire meglio, ++manutentibilitÃ , ++ comprensibilitÃ  del progetto. Lâ€™astrazione su un concetto di cambia il modo di ragionare riguardo l\u0026rsquo;implementazione, o lâ€™idea sottostante comunque. Correttezza, possiamo utilizzare i tipi per avere errori di programmazione, quindi se faccio qualcosa con un tipo, io mi aspetto di ricevere altro. (ad esempio se mi aspetto che una funzione mi ritorni qualcosa, ma mi ritorna qualcosalâ€™altro o non sempre quel tipo, posso darti errore staticamente parlando). Per cose di refactoring Ã¨ molto comodo, se cambi un tipo e una strtutura vorresti cambiarla anche da altre parti (se lo fai tipo in python Ã¨ molto piÃ¹ difficile per sto motivo che non ha tipi allâ€™esterno). O per la cosa della safety, Ã¨ impossibile sbagliare quando hai un buon sistema dei tipi (ti fa sbagliare in fase di compilazione lel, come Rust). Proprio per questa cosa che hai delle garanzie quando programmi, riesci a predire cosa ti ritorna e quindi predisci il modo con cui si comporta il programma. Possiamo dire che un programma Ã¨ sicuro quando rispetta sempre i vincoli del suo tipo. Per lui C non ha la caratteristica della safety, quindi puoi andare oltre alle limitazioni di utilizzo del singolo tipo (tipo array puoi accedere anche fuori dal suo range, un tipo buono non dovrebbe permettere queste cose), si potrebbe considerare quindi weakly typed, ma Ã¨ una cosa strana Implementazione: possiamo fare certe ottimizzazioni col sistema dei tipi. non servirebbero controlli dinamici per la sicurezza con un buon sistema dei tipi. Per esempio possiamo anche utilizzare offset per accedere in memoria quindi guadagniamo anche da quel punto di vista. Si migliora anche l\u0026rsquo;impatto che si ha sull quantitÃ  di memoria utilizzata, forseâ€¦ non sono sicuro da questo. Tipo theorem provers e simili\nAltre applicazioni\nUn sistema di tipi (e, per estensione, un linguaggio) Ã¨ sicuro relativamente ai tipi (o type safe) quando nessun programma puÃ² violare le distinzioni tra tipi definite in quel linguaggio. Detto in altri termini, un sistema di tipi Ã¨ sicuro quando nessun programma durante l\u0026rsquo;esecuzione puÃ² generare un errore non segnalato che derivi da una violazione di tipo.\nDynamic and static typing ðŸŸ©â€” STATICO\nQuando il controllo dei tipi avviene a livello di struttura del testo. Solitamente queste informazioni sono poi rimosse nel file compilato, almenochÃ© non serva per runnare.\nDato che eventuali errori sono individuati in tempo di compilazione, il prezzo in genere che si paga per un linguaggio statico Ã¨ il tempo di sviluppo del linguaggio! Solitamente un compilatore che abbia static typing e che sia safe richiede molto molto piÃ¹ tempo.\nDINAMICO\nQuando i controlli di tipi Ã¨ fatta a runtime, e quindi bisogna runnarlo per capire cosa runna. Questo aggiunge un leggero overhead, perchÃ© ho bisogno di un descrittore a runtime che contenga le informazioni sul tipo, e ci sia la verifica in questo momento.\nDato che dobbiamo eseguire per trovare un errore di tipo dinamico, questo errore potrebbe essere scoperto solo nella fase finale, quando il nostro prodotto Ã¨ giÃ  in produzione, e ha clienti!\nImportante osservare che la divisione fra dinamico e inferred Ã¨ indipendente al fatto che sia dinamic o static!\nManifest vs Inferred typing ðŸŸ© La differenza fra manifest ed inferred typing riguarda la quantitÃ  di informazioni che il programmatore deve dare al compilatore per creare il sistema dei tipi\nL\u0026rsquo;inferred typing non Ã¨ altro che un typing manifesto automatico, nel senso che il compilatore stesso riesce a capire che tipo stai dichiarando. Queste cose giÃ  esistono in c++ nuovo e anche golang Rust.\nInvece il manifest tiping Ã¨ quando il programmatore va ad annotare ili tipo di tute le variabili.\nTipo estensionali o intensionali ðŸŸ©- Slide estensionali o intensionali\nINTENSIONALE\nQuando gli abitanti del tipo sono descritti secondo un predicato che Ã¨ una proprietÃ  che Ã¨ soddisfatta da tutti gli abitanti.\nSalviamo molta memoria per tipi grossi e ci permette anche di rappresentare (fino a un certo punto i tipi infiniti).\nESTENSIONALE\nQuando si va a listare tutti gli abitanti nel nostro tipo, la stessa cosa che si fa con gli enums\nSistemi di tipi Caratterizzazione di base (4) (!) ðŸŸ¨+ Tipi di base Poter definire nuovi tipi Controllo dei vincoli, che siano statici o dinamici non ci importa, ma ci importa che siano rispettati Computare sui tipi (equivalenza, compatibilitÃ , inferenza dei tipi). Slide sistemi di tipi\nTipi di base ðŸŸ© Sono i valori denotabili del linguaggio. Si dice abitante, una variabile che faccia parte di questo tipo. Cose come float, caratteri interi etc.\nVOID/UNIT, Ã¨ un tipo di base che contiene solamente il singoletto, per questo Ã¨ anche chiamato unit, in java per esempio Ã¨ il NUll, mentre in C Ã¨ il void (che perÃ² ha la differenza che non si puÃ² assegnare, perchÃ© starei assegnando il niente!), e che non si puÃ² assegnare. Solitamente Ã¨ il valore delle funzioni che non ritornano nulla, utilizzato spesso per ritornare il controllo delle funzioni. In C void Ã¨ utilizzato per distinguere procedure e funzioni e rende difficile fare le composizioni (che non so cosa sia), unit Ã¨ per avere ancora funzioni, che deveono per forza avere un codominio non nullo.\nTIPI BOOLEANI\nChe hanno vero o falso come abitanti, e ho tutte le operazioni logiche, come congiunzione disgiunzione negazione etc. La cosa particolare Ã¨ che utilizziamo un byte invece di un bit per rappresentare un bool, perchÃ© per accedere al valore Ã¨ molto veloce se Ã¨ allineato.\nTIPO CARATTERE\nSono i caratteri Unicode, oppure ascii,operazioni classiche sarebbero comparazione, comparazione (perchÃ© câ€™Ã¨ un ordine fra i caratteri nellâ€™encoding, come abbiamo detto in Codifica dei caratteri), e il resto Ã¨ dipendente dal linguaggio.\nTIPI INTERI\nSolitamente spaziano fra $[-2^{r - 1}, 2 ^{r - 1} - 1 ]$hanno tutte le operazioni fra interi come uguaglianza, ordine, tutte le operazioni aritmetiche.\nTIPO REALE\nSono un subset dei reali, in particolare solamente i razionali rappresentabili, hanno stesse operazioni degli interi (importanti per ragioni di compatibilitÃ  e conversione con gli interi!), ricorda che ci sono fixed point or floating point representation. Abbiamo fatto principalmente floating point di IEEE745 in Calcolo di numeri finiti .\nFixed point slide\nTIPO COMPLESSO\nAnche questo, subset dei numeri complessi, stesse operazioni degli interi, con forse qualcosina in piÃ¹.\nENUMS\nQuesto Ã¨ il nostro primo tipo non di base, perchÃ© Ã¨ un costruttore di tipo possiamo infatti dichiarare nuovi tipi, e enums sono un modo per farlo. In pratica si dichiara un nuovo tipo con definizione di abitanti appartenenti a questo.\nIn C non câ€™Ã¨ differenza fra interi e enums, quindi non câ€™Ã¨ una chiara differenziazione dei tipi, quindi difficile andare a checkare la correttezza fra i due.\nTipi composti Come si fa a definire alcuni tipi piÃ¹ complessi, composti utilizzando alcuni tipi primitivi?\nArrays Sono unacollezzione di elementi omogenei indexati da una chiave (questo mapping riesce a dare in un certo senso un ordine) (che non necessariamente devono essere degli interi, credo che su questa scia anche le hashtable sono classificati come tipo array).\nInfatti le mappe sono chiamate associative arrays.\nSi potrebbe considerare il costruttore di tipo, che prende in input un tipo e crea un array di una certra dimensione (quindi fa eccezzioni se provi ad accedere oltre) e crea un altro tipo, che Ã¨ lâ€™array di certa dimensione.\nEsempi di notazioni con array\nProprietÃ  del tipo array\nOrdine di storage degli array (row column major)\nSe la grandezza dellâ€™array Ã¨ conosciuta a tempo di compilazione si puÃ² allocare in stack, altrimenti si mette in heap, e si utilizza un descrittore, chiamato dope vector per accederci sulla heap. Di solito in rust o golang sono gli slice\nEsempio di dope vector\nEcco tutte le informazioni per il descrittore :D, stride ci dice ogni quanto saltare per avere il prossimo elemento.\nCONTROLLO\nUna delle operazioni fondamentali affinchÃ© abbiamo un tipo di array che sia safe Ã¨ il fatto check allâ€™accesso, in modo da evitare out of bounds, Ã¨ la cosa migliore che ho in termini di sicurezza.\nAltre operazioni utili sono assegnamento, confronto\nSets/Insiemi (3) Unici e orderless e omogenei sono gli elementi dei set. Quindi lâ€™unica differenza Ã¨ il fatto che siano unici e quindi siano tutti distinti fra di loro secondo lâ€™operatore di uguaglianza.\nOperazioni importanti sono unione, intersezione, differenza, complemento, etc. tutte le operazioni belle sugli insiemi.\nUn esempio di operazioni fra i set sono unioni (e tutti gli amici degli insiemi) quindi per esempio se provo ad unire due insiemi con gli stessi elementi, restano gli stessi.\nAppartenenza, Unione, intersezione, complemento etcâ€¦ IMPLEMENTAZIONE SETS\nLâ€™implementazione piÃ¹ semplice dei set Ã¨ avere un bitset, che il valore del bit ci dice se lâ€™elemento Ã¨ presente o meno in essa. Ma non funziona per sets che sono molto larghi. Quindi di solito si utilizzano gli hash tables per sti set.\nUn altro modo Ã¨ utilizzare una hashset in pratica ogni valore ha una hash, e questo viene utilizzato per vedere se Ã¨ presente o meno (spesso funzioni fra dominio a un mio)\nUn altro modo per fare set Ã¨ utilizzare un albero binario, come fa C++ in set.\nReference Types NOTA: i puntatori sono abitanti di questi reference types, perÃ² non sono gli unici! (esempio URL, reference alla risorsa. Via di casa, reference alla tua casa).\nSono le reference a qualcosa! Questo permettono di creare strutture di dati ricorsive.\nOperazioni tipiche sono, creazione, check uguaglianza, dereferenziazione. Il pointer Ã¨ lâ€™implementazione piÃ¹ semplice di questo tipo di dato.\nCASI SPECIALI REFERENCE TYPES (3)\nSenza certe tipologie di checks, le references possono causare molti problemi, come le reference wild (quando ho dei pointer non inziializzati e quindi posso avere random della stack)\nPer questi Ã¨ meglio sempre assegnare a Null per evitare questo, se non lo fa giÃ  il linguaggio.\ndangling (quando si riferisce ad elementi giÃ  liberati, o ci sono altre cose). Questo Ã¨ principalmente causato dal fatto che solitamente sono soluzioni basso livello, che interfaccia praticamente direttamente sulla memoria.\nMemory leak, quando sto perdendo memoria, nel senso che non ho piÃ¹ nessuna reference, quando per esempio dislinko un puntatore, senza averla marcata come libera (quindi perdo un sacco di memoria, che non posso piÃ¹ allocare).\nOPERAZIONI CLASSICHE (4)\nSlide reference types\nCreazione di un certo referenze ad un oggetto\nDereferencing, cerco il dato puntato da questa referenza\nEquality, per vedere se Ã¨ uguale la reference\nOPERAZIONI GENERALI CON I REFERENCES.\nVariabile referencing operator, in pratica vorrei che creasse una variabile che abbia come r-value la l-value di una certa variabile (descritto in Valutazione Espressioni), ossia il suo indirizzo o contenitore, la sua reference\nAllocazione e deallocazione dinamica, ma questa non Ã¨ che dovrebbe essere operazione su questo tipo\nPower sets Questo sono i primi tipi che non abbiamo visto in un linguaggio di programmazione, alla fine Ã¨ sempre un Sets/Insiemi, ma con qualche informazione in piÃ¹.\nDefinizione di powerset P, partendo da un set iniziale S.\nQuesto soprattutto Ã¨ un modo molto utile per rappresentare tuple, ossia coppie ordinate, molto naturali con dei powerset.\nOsservazione powerset per due\nCon lâ€™osservazione di sopra abbiamo detto che la tupla definita in quel modo, che segue la definizione di kuratowsky in 3.1.1 Definizione di Kuratowsky, Ã¨ un elemento del powerset del powerset, quello Ã¨ proprio il prodotto cartesiano! Chiachiamo product types, o tipi prodotto come combinazioni una o piÃ¹ strutture (quindi non piÃ¹ omogeneo come prima)\nPAIRS AND TUPLES\nSlide pairs and tuples\nAbbiamo la stessa informazione con gli array (solo che possono non essere omogenei!) abbiamo sempre informazione sulla posizione, e un valore allâ€™interno della posizione. La coppia generalizzata Ã¨ una tupla.\nRECORDS\nSe astraiamo le tuple, aggiungendoci un nome per ogni tipo ad una certa posizione, allora abbiamo i records, che non sono altro che delle strutture.\nQuando andiamo a prendere un elemento stiamo facendo una proiezione monomorfa, perchÃ© da tutto quellâ€™array di elementi stiamo andando a prenderne un singolo.\nPATTERN MATCHING\nQuesto Ã¨ una struttura molto comune nei linguaggi funzionali, ma anche presente in rust. Sono buoni da poter definire allâ€™interno di un tipo prodotto.\nSlide pattern matching\nPraticamente vorremmo fare una partizione completa degli abitanti di un tipo, per questo motivo posso fare una specie di casework completo per gestire in modo esplicito tutti i casi. Questa partizione Ã¨ fatta in modo libero con delle regole :D.\nTIPI RICORSIVI\nQuesti tipi sono definiti per la prima volta grazie ai pairs (quelli con riferimento erano invece delle cose diverse, anche se concettualmente Ã¨ simile). Possiamo definire che questo sia un tipo ricorsivo nel senso che si potrebbe descrivere come un powersets infinito (credo).\nDalla lezione ora mi sembra abbia detto che deve necessariamente avere una reference dello stesso tipo\nSum Types Slide introduttiva sum types\nI tipi di somma ci permettono di avere abitandi di piÃ¹ mondi.\nNellâ€™esempio di sopra gli insiemi sono taggati per non confondere un elemento di un insieme con un altro! anche chiamato or types, choice types, tagged unions, union types, variant types, perchÃ© puÃ² assumere un inabitante a caso fra tutti i tipi che costituiscono questa unione.\nAbbiamo giÃ  visto le ENUMS che fanno cose simili, ossia puÃ² avere abitanti di tipi diversi, quindi stiamo comunque catturando la somma dei tipi. Ãˆ interessante osservare che dal punto di vista teorico prendere un elemento di union implementato per enumerazione Ã¨ simile a tirare fuori da un pacchetto.\nUNION DATATYPES\nCome in C, posso avere le union data types, in cui stessa zona di memoria posso metterci i dati che ho scelto (solo che non mi fa check statico a vedere cosa ci puÃ² stare!!), cioÃ¨ a differenza degli enums, non ho il controllo dellâ€™accesso, decido io come guardarlo.\nRECURSIVE TYPES\nAnche con i sum types posso andare a descrivere i tipi ricorsivi (solamente che alla fine invece di dire che Null Ã¨ un inabidante delle reference, gli dico che Ã¨ un abitante di qualcosâ€™altro!) Questo mi rende molto carina la sua struttura (e mi permette anche pattern matchin senza nessun problema (Ã¨ un modo piÃ¹ sicuro per aprire, dato che posso fare matching).\nSlide recursive types with sum\nFunction types Praticamente sono elementi di $A^B$, con B partenza A arrivo. Lâ€™operazione fondamentale di questi tipi sono lâ€™applicazione.\n","permalink":"https://flecart.github.io/notes/teoria-dei-tipi/","summary":"Ripasso Prox: 30 Ripasso: June 6, 2023 Ultima modifica: May 14, 2023 6:13 PM Primo Abbozzo: March 13, 2023 9:20 AM Studi Personali: No\nElementi di ripasso Teoria dei Tipi Introduzione Definizione ðŸŸ©â€” Un metodo sintattico praticabile per dimostrare l\u0026rsquo;assenza di determinati comportamenti del programma, fatto classificando le unitÃ  sintattiche in base ai tipi di valore che assumono\nVogliamo che fosse praticabile nel senso che effettivamente lo possiamo implementare, cioÃ¨ ci permettono di avere certe tipologie di garanzia.","title":"Teoria dei Tipi"},{"content":"Ripasso: May 14, 2023 Ultima modifica: June 17, 2023 11:54 PM Primo Abbozzo: February 24, 2023 1:33 PM Studi Personali: No\nElementi di ripasso URI Sono stata LA vera invenzione di Berners Lee accennati in Storia del web. Il problema Ã¨ avere un modo per identificare una risorsa in modo univoco sullâ€™internet.\nIntroduzione La risorsa ðŸŸ© Una risorsa Ã¨ qualunque struttura che sia oggetto di scambio tra applicazioni allâ€™interno del World Wide Web.\nOra una risorsa puÃ² essere qualunque cosa, non solamente solo un file! Quindi Ã¨ agnostico rispetto a contenuto oppure metodo di memorizzazione del dato, appare anche in questo ambiente importante vedere quanto siano importanti standard che permettano una comunicazione\nEsempi di risorsa:\nFile di testo Immagine Chiave di Hash Chiave per una query di database Una funzione da chiamare da remoto In pratica qualunque cosa che possa fare il web, e identificabile da un URI si potrebbe chiamare risorsa, Ã¨ un termine molto generale, non definito in modo formale o tecnico.\nSlide\nIn breve Ã¨ risorsa qualunque cosa che possa essere oggetto di scambio in una interazione web.\nURL and URN Gli URI (Uniform Resource Identifier) sono una sintassi usata in WWW per definire i nomi e gli indirizzi di oggetti (risorse) su Internet.\nURL indicano la locazione della risorsa (che il browser riesce ad andare a questa locazione, ma puÃ² essere cambiato dal gestore della risorsa, e quindi puÃ² essere spostato e mai piÃ¹ trovato!), a volte non piace molto questa cosa, e quindi si cerca di creare un URL permanente. Che di solito o Ã¨ fatto per redirezione quando si sposta o Ho un sistema di virtualizzazione di uri fisici (in qui veramente câ€™Ã¨ la risorsa e virtuali (quelli in interfaccia su cui faccio la richiesta).\nURN Ã¨ una etichettazione permanente di una risorsa, Ã¨ PERMANENTE ma ha bisogno di una risoluzione per la sua locazione, per risolvere il problema della locazione nel caso venisse spostata.\nGli URI potremmo definirli come l\u0026rsquo;intersezione fra le due, sia un modo per identificare la locazione (quindi andare ad accederci) sia un modo per etichettarli in modo definitivo (in questo modo sono degli URN).\nCaratteristiche ðŸŸ¨ URI sono un sistema sintattico (focus sul fatto che siano puramente sintattici!!!, non descrivono la semantica (cosa fare per accedere, ma comunicano il protocollo usato per accedere)che possiamo vederlo anche come sistema di 7 livello OSI utilizzato per identificare la risorsa Ã¨ importante quindi che\nTrascrivibili, ossia hanno caratteri limitati, e tutti leggibili da umani. Identificazione, non interazione, avendo solo lâ€™URI non posso fare operazioni sulla risorsa. Gerarchizzazione dei nomi url ha una certa struttura (come i caratteri speciali nellâ€™URL), in questo senso esiste una certa gerarchizzazione dei nomi! (simile a quanto faccia il filesystem). Struttura dellâ€™URI 5 URI = schema : [// authority] path [? query][# fragment]\nPer favorire la trascrivibilitÃ  ci sono certi caratteri scpeciali tenuti apparte (e se servono sono encodati). curi si parla di caratteri per URI.\ncuri = unreserved | reserved | escaped Slide sui caratteri encodati\nPer sapere i caratteri encodati, sarebbe bene tenersi a mente le slides, o comunque la grammatica diciamo!\nURI resolution and dereference (!) Un uri puÃ² essere assoluto oppure una URI reference. Se Ã¨ assoluto allora deve soddisfare tutta la struttura di cui sopra, oppure semplicemente dire il nome del file a seconda di una certa base.\nIn questo caso si parla di URI Reference perchÃ© Ã¨ relativo a un certo dato. resolution: Quando do in input un URI reference e in output mi aspetto una URI completa Dereferencing: quando do in input un URI completo e mi aspetto indietro una risorsa.\nAlcune regole di URI resolution Routing Tipologie di routing (2) Managed Route\nQuesto Ã¨ la forma di gestione degli URI piÃ¹ nuova, in pratica il mapping di gestione delle risorse Ã¨ fatto a livello server. (quindi e.g. in Express posso dire a un certo URL quale risorsa interna corrisponde).\nFile-system route\nQuesto Ã¨ il modo piÃ¹ facile diciamo, praticamente câ€™Ã¨ corrispondenza fra un percorso allâ€™interno del file system allâ€™indirizzo URI.\nQuesto ha problemi di security perchÃ©\nDo informazioni sulla struttura interna del nostro sito Non ho controllo sullâ€™accesso dallâ€™esterno Non Ã¨ molto malleabile se voglio cambiare la struttura URI Rewriting Ãˆ un modo di virtualizzare la URI, una risorsa interna (con uri fisico vero, cioÃ¨ dove sta fisicamente) con un uri virtuale allâ€™esterno, questo Ã¨ quello che farebbe ad esempio mod_rewrite di apache.\nÃˆ particolarmente comodo perchÃ© mi permette di essere piÃ¹ sicuro di informazioni nascoste e di gestire meglio il nome delle risorse esposte a seconda di cosa io abbia internamente, praticamente Ã¨ un sistema managed route.\nLa differenza con URI alias Ã¨ che lâ€™URI vero qui Ã¨ nascosto, e non Ã¨ esposto\nCURIE Compact URI, un nome carino per riferirsi a modi compatti di scrivere gli uri sono nella forma [prefix:curie].\nSlides\nAlcuni protocolli (schema URI) Di questi non ci importa sapere esattamente i dettagli della loro sintassi, ma che esistono e sono degli URI per qualche tipologia di risorsa!\nHTTP e HTTPS HTTP Ã¨ uno dei protocolli piÃ¹ comuni per il WWW. HTTPS Ã¨ la sua forma sicura.\nPer maggiori dettagli riguardo funzionamento del protocollo guardare HTTP e REST\nFile Schema Equivalente ad aprire un file dal browser.\nImportante osservare che non esiste un server che gira con questo schema\nSlide\nData Di solito questo Ã¨ presente nel payload come messaggio di risposta a qualcosa.\nSlide\nFTP Slide\nTentativi di internazionalizzazione CDN una rete fortemente distribuita di server commerciali che collaborano tra loro per distribuire in maniera omogenea contenuti di grande successo senza inutili duplicazioni di occupazione e trasmissione di file.\nin pratica questi sono dei server che fanno caching con praticamente la stessa idea che avresti avuto in Memoria! Una zona di computer che praticamente contiene tutte le librerie piÃ¹ utilizzate, che siano di facile accesso, e che quindi velocizzano il tempo per prendere una risorsa di molto!\nX-WWW-URLENCODED Una estensione al formato URI per HTTP, questo credo sia un modo per evitare di madnare dei form-multipart data che si leggono male, ma con questo si dovrebbe leggere meglio. Altri motivi non mi vengono in mente del perchÃ© sono proprio necessari.\nIRI e IDN IRI Ã¨ un International resource identifier che permette di risolvere risorse identificate da nomi non solo in ASCII 7, senza dover utilizzare url-encoding. Esteso a UTF-32!!!\nIl problema principale Ã¨ che da problemi di aliasing (a cirillica molto simile di a latina, quindi uno potrebbe fare pishing basandosi su questa cosa), questo Ã¨ stato permesso da IDN (Internationalized DomainName) che permette di avere nomi di nominio anche non di soli caratteri latini, utilizza UNICODE ???. Questi sono attacchi via omografi.\nLa visione dei software Le cose online dovrebbero essere accessibili anche ai software, non solo agli umani. Questo e importante per i crawling bots credo, cosÃ¬ riescono a farsi una idea del sito o allo stesso modo queste cose straneâ€¦\nPer berners Lee, che introdusse il Linked Data questo era importante perchÃ© cosÃ¬ un dato poteva essere accessibile anche da applicazioni. affermazioni atomiche minimali\nNome, proprietÃ , Valore (sono in sta forma, come URI perÃ²). Questo Ã¨ quello che fa WIkiDATA!!!\nSlides\nQuesto si collega senza nessun problema all\u0026rsquo;ultima parte trattata nel corso riguardante il Metadati web e web semantico.\nIn cui si vanno a parlare di RDF e simili. (immagine di un web accessibile tanto ai bot quanto agli umani, perchÃ© i dati sono tutti tanto strutturati).\n","permalink":"https://flecart.github.io/notes/uniform-resource-identifier/","summary":"Ripasso: May 14, 2023 Ultima modifica: June 17, 2023 11:54 PM Primo Abbozzo: February 24, 2023 1:33 PM Studi Personali: No\nElementi di ripasso URI Sono stata LA vera invenzione di Berners Lee accennati in Storia del web. Il problema Ã¨ avere un modo per identificare una risorsa in modo univoco sullâ€™internet.\nIntroduzione La risorsa ðŸŸ© Una risorsa Ã¨ qualunque struttura che sia oggetto di scambio tra applicazioni allâ€™interno del World Wide Web.","title":"Uniform Resource Identifier"},{"content":"Check function A volte puÃ² essere molto pesante, perchÃ©\nWhat does check do? Viene utilizzato per introdurre un constraint check per avere sicurezza su un range. Check e innestamenti ðŸŸ©- PuÃ² essere che certe implementazioni non permettano il check innestato, questo Ã¨ una cosa molto pesante, perchÃ© ogni modifica deve andare a rifare la modifica ai subalterni, quindi questo Ã¨ pesante pesante.\nAssertions ðŸŸ©\u0026ndash; Sono dei check fatti al livello dello schema, quindi valgono sempre, e possono essere riutilizzati in table diversi credo. Un altro aspetto Ã¨ che Ã¨ database wide.\ncreate ASSERTION AtLeastOneEmployee check (1 \u0026lt;= (select count(*) from Employee))) View L\u0026rsquo;uso del view ðŸŸ© create view ViewName [(attrlist)] as selectstatement [ with [local | cascaded ] check option] viene utilizzato per prendere dati esistenti, e metterli in una forma utile a una sotto-organizzazione, che vuole informazioni specifiche diciamo.\nCheck: viene utilizzato se update Ã¨ sensato (soddisfa ancora la check). Grouping, posso creare view con informazioni aggregate, e poi posso usare le informazioni aggregate simile a sopra. Cascaded vs local Cascaded significa che ogni modifica e view, viene riflessa su altri schema e view fisici effettivi Local significa Recursive queries ðŸŸ¥+ In questi casi viene proprio definito un approccio ricorsivo (anche se non ricordo benissimo la sintassi) andiamo a definire cose come caso base, e caso induttivo e poi si fa la query in questo modo.\nIn pratica costruisco una view in modo ricorsivo, e su questa posso farci delle query. Un esempio:\nwith recursive Ancestors(Ancestor, Descendant) AS ( select Father, Son from Fatherhood union all select Ancestor, Son from Ancestors, Fatherhood where Descendant = Father ) select * from Ancestors In pratica nel primo select popolo inizialmente la view, poi in modo ricorsivo, prendo gli elementi dentro la view, prendo alcuni elementi dentro son, e aggiungo tutti gli elementi che soddisfano quella condizione.\nOther expressions Coalesce ðŸŸ¥ Ci permette di fare l\u0026rsquo;equivalente del default in alcuni linguaggi di programmazione per me. In pratica restituisce il primo elemento non nullo in una lista, quindi se per caso ho due elementi, e il primo Ã¨ nullabile, allora prende il default il secondo.\nEsempio:\nselect number, coalesce(Mobile, PhoneHome) from Employee Se non esiste mobile, si va su phonehome. Si puÃ² fare una cosa come `coalesce(Dept, \u0026ldquo;None\u0026rdquo;) per mettere il default.\nScalar functions ðŸŸ¨ String Time\ncurrent_date extract(yearExpresison) Esempio: SELECT EXTRACT(YEAR from orderDate) AS orderyear, FROM Orders WHERE DATE(orderDate) = current_date() Casting\nnullif Semantica: ritorna null se la condizione Ã¨ vera.\nÃˆ buono per far tornare Null se un valore assume un certo valore hardcodato, ad esempio se il default Ã¨ \u0026ldquo;Unknown\u0026rdquo; per qualcosa, posso fargli tornare NULL se valore uguale a quella stringa hardcodata.\nEsempio:\nselect Surname, nullif(Dept, \u0026#34;unknown\u0026#34;) from employee Se Ã¨ vera la comparazione, si ritorna Null in automatico\nCase expressions ðŸŸ¨\u0026ndash; ### Transactions #### ACID framework ðŸŸ© - Atomic: o tutto o niente, Ã¨ una transazione atomica - Consistency: tutto deve soddisfare i constraints - Isolation: simile ad atomico, le transazioni non devono influenzarsi fra di loro per tempo. - Durability: non Ã¨ su ram diciamo #### Example in sql for transactions ![ 600](/notes/structured-query-language-1697712948716.jpeg-) Authorization Privileges (6) Questa parte si ricollega in qualche modo con la parte di renzone, vogliamo specificare una risorsa e dire chi puÃ² fare cosa su quella risorsa. La risorsa in questo caso puÃ² essere lettura modifica o eliminazione su una tavola. Posso\nDare permessi (privilegi) Togliere permessi Specificare utenti che hanno permessi Propagazione di privilegi. I privilegi sono esattamente 6, descritti dall\u0026rsquo;immagine sotto Grant privileges grant \u0026lt; Privileges | all privileges \u0026gt; on Resource to Users [ with grant option ] Revoke privileges revoke Privileges on Resource from Users [ restrict | cascade ] Restrict -\u0026gt; non implica anche altri utenti Cascade -\u0026gt; la revoca Ã¨ estesa ad altri utenti anche, una reazione a catena. Privilegi come view RBAC Ãˆ piÃ¹ facile usare il modello chiamato RBAC, ossia definiamo ruoli, una view, e i ruoli possono accedere solamente a certe view. Usare i ruoli Ã¨ un metodo classico, potremmo considerarlo come una astrazione su cosa ogni utente deve fare sul database (quindi le sue operazioni ideali) e da quello andare a descrivere cosa esattamente ha bisogno di poter fare. In questo modo definisco i permessi su questi ruoli ideali invece di andare a farli sui singoli utenti, magari anche ripetendo un sacco di queries.\n","permalink":"https://flecart.github.io/notes/advanced-sql/","summary":"Check function A volte puÃ² essere molto pesante, perchÃ©\nWhat does check do? Viene utilizzato per introdurre un constraint check per avere sicurezza su un range. Check e innestamenti ðŸŸ©- PuÃ² essere che certe implementazioni non permettano il check innestato, questo Ã¨ una cosa molto pesante, perchÃ© ogni modifica deve andare a rifare la modifica ai subalterni, quindi questo Ã¨ pesante pesante.\nAssertions ðŸŸ©\u0026ndash; Sono dei check fatti al livello dello schema, quindi valgono sempre, e possono essere riutilizzati in table diversi credo.","title":"Advanced SQL"},{"content":"Ripasso Prox: 3 Ultima modifica: September 16, 2022 9:37 AM Primo Abbozzo: September 13, 2022 2:53 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: Yes\nNote: Questo corso Ã¨ troppo astratto. PiÃ¹ che probabilitÃ  tratta di teoria della Misura. Quindi affossatoâ€¦\nLink della serie: https://www.youtube.com/watch?v=172m7qVy_FQ\u0026amp;list=PLrb6X_RiBI94b6dzCx-QwM-r0aZpJyPxS\nCampo (di probabilitÃ ) Nota:\n2 e 3 â‡’ 4\n2 e 4 â‡’ 3\nQuindi 3 e 4 sono interscambiabili, e si potrebbe eliminare uno dei due.\nAnche il fatto che il vuoto sia presente in F si puÃ² omettere. combinando 1 e 2 ottengo il vuoto (complementare dellâ€™insieme che prenda tutto).\nNOTA: SIGMA FIELDS se soddisfa il criterio sotto al 4.\nNOTA: per insiemi finiti sigma-f = f\nEsempi:\nSono tutti dei $\\sigma -fields$\nLâ€™ultimo caso Ã¨ difficile da descrivereâ€¦ Devi utilizzare demorgan.\nLemma intersezioni di sigma-fields Ossia da verificare i 3 punti per dire che Ã¨ un sigma field\nSigma fields generated by sets Si puÃ² vedere che questo field sono sempre presenti $\\Omega$ e vuoto. e per il lemma precedente tutti i Sigma-fields che hanno $\\epsilon$ Ã¨ un sigma field.\nDimostrazione costruttiva\nDobbiamo ora dimostrare che sia unico. (si puÃ² dire che lâ€™intersezione sia unica??? se sÃ¬ allora ez).\nEsercizio\nBorel sigma-field NOTA: intersezione di invervalli aperti puÃ² comportare un intervallo semi aperto (eg $1/n$ e -1, questi lâ€™intersezione infinita di questi intervalli Ã¨ $(-1, 0]$\nBorel Field Riusciamo a dare una struttura sul campo di Borel, riuscendo in questo passo a dimostrare che lâ€™insieme cosÃ¬ costruito non Ã¨ altro che lâ€™insieme di Borel.\nSemi-algebra di insiemi Proof\nFinitevely additive measures and semi-algebras Stieltjes (pre_measures) on Borel sets R Main observation:\nMeasure space Examples\nSet of measure functions Example\n3 basic properties of Measures Premeasure, finitely-additive Measures) Motivazione Ãˆ difficile costruire delle misure complete su $\\sigma$ fields, soprattutto se Ã¨ un campo non numerabile. Per questo motivo vorremmo utilizzare nozioni piÃ¹ deboli di misura e da quelle estenderle anche a questi campi, piÃ¹ difficili da trattare. Quindi andiamo a costruire pre-misure e finitely-additive measures. QUesta sezione Ã¨ II, 5.2.1 nel driver del corso su youtube.\nDefinizione: Una coppia $\\Omega, \\mathcal{A}$ Ã¨ uno spazio di pre-misura se $\\mathcal{A}$ Ã¨ un campo su $\\Omega$. (non abbiamo piÃ¹ bisogno che sia un $\\sigma$ campo), solo che sia chiuso sotto unione e differenza.\nUna funzione countably additive (Ossia che valga che $\\left\\{ E_{i} \\right\\}_{i=1}^{\\infty} \\in \\mathcal{A} : \\cup_{i=1}^{\\infty}E_{i} = E \\in \\mathcal{A} \\implies \\mu(E) = \\sum_{i=1}^{\\infty}\\mu(E_{i})$$\\mu: \\mathcal{A} \\to [0, \\infty]$) Ã¨ una premisura Se assumiamo che $\\mu$ sia solamente finitely-additive allora la chiamiamo finitely-additive measure.\nPer fare una pre-misura basta un campo, non un sigma-campo, quindi Ã¨ molto piÃ¹ facile da costruire.\nF-A measures is premeasure iff countably sub-additive Questo permette di passare da finitely-additive measures a pre-misure senza troppi intoppi.\nProof\nStiljes premeasure on borel field Proof\nMeasure extension Theorem Sigma finite\nEsempio quelle di probabilitÃ  che sono sempre finite\nExample non-uniqueness of extensions(not done, ma esistono se non Ã¨ sigma finito)\nCarathÃ©odorÃ½s Extension Cose da provare\nProof\nOuter measures Abbiamo visto alcune proprietÃ  importanti da dover verificare per la dimostrazione che $\\rho*$ sia una misura, queste caratteristiche si possono estendere per qualunque cosa quindi ha senso definire una altra misura in questo senso:\nSu caratheodory\nOgni misura $v$ che estende la premisura $\\mu$ vale che $v \\leq \\mu *\\, su \\, \\sigma(A)$ (largest extension)\nOther OuterMeasure properties with premeasure spaces\n","permalink":"https://flecart.github.io/notes/introduzione-alla-probabilita/","summary":"Ripasso Prox: 3 Ultima modifica: September 16, 2022 9:37 AM Primo Abbozzo: September 13, 2022 2:53 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: Yes\nNote: Questo corso Ã¨ troppo astratto. PiÃ¹ che probabilitÃ  tratta di teoria della Misura. Quindi affossatoâ€¦\nLink della serie: https://www.youtube.com/watch?v=172m7qVy_FQ\u0026amp;list=PLrb6X_RiBI94b6dzCx-QwM-r0aZpJyPxS\nCampo (di probabilitÃ ) Nota:\n2 e 3 â‡’ 4\n2 e 4 â‡’ 3\nQuindi 3 e 4 sono interscambiabili, e si potrebbe eliminare uno dei due.\nAnche il fatto che il vuoto sia presente in F si puÃ² omettere.","title":"Introduzione alla probabilita"},{"content":"Livello trasporto Protocolli classici Introduzione a TCP e UPD Il quarto livello dei protocolli dellâ€™architettura di Internet Ã¨ il livello trasporto (transport), ed Ã¨ basato su due protocolli in particolare: il Transmission Control Protocol (TCP) e lo User Data Protocol (UDP), che possono essere usati in alternativa tra loro.\nQuesto Ã¨ nel genere di *connession oriented e non, il primo, TCP Ã¨ connection oriented, l\u0026rsquo;altro no, questa Ã¨ lâ€™unica differenza fra i due. Questa differenza Ã¨ spiegata in maggior dettaglio qui 0.3.8 Servizi orientati alla connessione e non ðŸŸ¨+\nTCP\nConnection oriented (garantire il ripristino dellâ€™ordinamento dei pacchetti e la ri-trasmissione dei pacchetti perduti) Numero dellâ€™ordine (a cui riceve ack per questo numero) Controllare la velocitÃ  di invio â†’ Finestra scorrevole La parte importante di questo Ã¨ che la congestione si puÃ² allargare a macchia dâ€™olio all\u0026rsquo;interno di internet, e questo Ã¨ una cosa molto brutta! Quindi prova a risolvere gli errori di comunicazione di rete, cercando di garantire una buona trasmissione. Il problema Ã¨ l\u0026rsquo;efficienza, si possono inviare segmenti in piÃ¹ e congestionare la rete.\nSi puÃ² dire che questa Ã¨ la semantica diversa.\nCon la tree-way handshake si apre una connessione socket, quindi una coppia porta IP, per poter comunicare!\nUDP\nÃˆ semplice perchÃ© non fa tutte le cose di TCP (no duplicati, no riordinamento, no checks) Tipo connectionless Socket Slide immagini\nIl protocollo TCP richiede a due dispositivi che intendano comunicare di effettuare preventivamente la configurazione dei parametri del socket TCP, originando in questo modo un canale virtuale di tipo punto a punto tra due socket, ovvero tra due applicazioni di livello superiore alle quali vengono smistati i pacchetti da TCP. Quindi sono degli estremi di comunicazione!\nDef socket\nUn socket Ã¨ un punto di arrivo o partenza (virtuale) dei dati a livello trasporto, dal quale Ã¨ in atto lâ€™invio e la ricezione di pacchetti destinati a unâ€™applicazione, ed equivale a una coppia: (indirizzo IP, numero di porta dellâ€™applicazione). Una volta instaurata la configurazione punto a punto tra due socket, attraverso lo scambio di pacchetti di configurazione, puÃ² iniziare lo scambio dei dati a livello trasporto. In questo senso si dice che Ã¨ un trasporto TCP/IP, perchÃ© prima configurazione per IP poi effettivamente scambio.\nLa richiesta di connessione\nLa connessione viene instaurata con una richiesta di uno dei due host (il client) nei confronti dellâ€™host server.\nIndirizzo IP del server Numero della porta per l\u0026rsquo;applicazione (questo viene verificato dal server se qualche servizio ci Ã¨ aperto, se sÃ¬ risponde, e il client invia la configurazione). Poi iniziano a dialogare e alla fine liberano la porta, Ã¨ una connessione punto a punto!. Quando il server riceve il pacchetto, va a verificare se ha la porta aperta, se tutto va bene manda un messaggio di conferma, e il client invia un pacchetto di configurazione, allora possono cominciare a comunicare.\nWelcoming socket and client sockets\nWelcoming Ã¨ l\u0026rsquo;unico socket di ricezione di un server, che prende tutto e manda al thread corretto.\nClient sockets sono i molteplici sockets che il server utilizza per comunicare con il singolo client, vengono solitamente istanziati grazie al welcoming socket dopo che ho fatto richiesta di connessione.\nControllo della congestione TCP (2) Questa parte ora Ã¨ trattata meglio in Livello di trasporto\nSlide\nSchema\nTCP utilizza un protocollo molto particolare, e a prima vista non intuitivo per gestire la congestione della rete.\nLâ€™idea generale Ã¨ che provo ad aumentare lâ€™invio finchÃ© posso, e quando mi accorgo che inizio a perdere chiudo tutto e ricomincio dal singolo pacchetto.\nCome si Ã¨ detto in precedenza, TCP richiede una conferma per ogni pacchetto inviato. La distanza tra due dispositivi che scambiano pacchetti a livello trasporto puÃ² essere molto significativa. Il tempo per inviare un pacchetto e ottenere la conferma dellâ€™avvenuta ricezione puÃ² quindi diventare dellâ€™ordine dei secondi. Il problema del controllo di flusso dei pacchetti nel protocollo TCP si basa su due scopi apparentemente in contraddizione tra loro.\nÃ¨ quello di saturare il piÃ¹ possibile la rete di pacchetti, inviandoli a un ritmo elevato. Questo favorisce lâ€™utilizzo delle risorse e le prestazioni della rete (si spediscono e si ricevono tanti bit al secondo). Se si decidesse di inviare un pacchetto e aspettare lâ€™arrivo della conferma, la rete sarebbe usata solo in minima percentuale, e si riuscirebbero a spedire solo pochi bit al secondo. Quindi la rete, pur essendo veloce nellâ€™invio dei bit, verrebbe sfruttata al minimo delle potenzialitÃ . Eâ€™ quindi evidente quanto sia opportuno spedire i pacchetti a un ritmo il piÃ¹ veloce possibile. Evitare di saturare la rete occorre evitare che un ritmo di invio troppo elevato possa causare il sorgere della congestione nei router intermedi del cammino dei pacchetti, dal mittente TCP (client) al destinatario TCP (server). Se un router si trova a dover inoltrare troppi pacchetti, provenienti da flussi TCP diversi, i pacchetti si accumulano fino ad andare perduti e la rete va in crisi. In tal caso si deve ricorrere a una tecnica di controllo della congestione. Una forma di congestione puÃ² comparire anche sul destinatario finale, nel caso in cui esso non sia in grado di ricevere i pacchetti inviati troppo velocemente. In tal caso si deve ricorrere a una tecnica di controllo di flusso. Finestra scorrevole Si parla di metodi di congestione, viene trattato meglio in Livello di trasporto Osservando lâ€™esempio, partendo con SW uguale a 1, se la conferma Ã¨ ricevuta, la finestra viene raddoppiata, spedendo due pacchetti al massimo ritmo di invio. Se entrambi i pacchetti vengono confermati, si passa alla finestra di dimensione quattro, inviando quattro pacchetti al massimo ritmo di invio. Se i pacchetti sono confermati si passa a finestra di otto pacchetti. A questo punto, nellâ€™esempio, almeno uno degli otto pacchetti non viene confermato. Si suppone che questo fatto sia dovuto a un router congestionato e quindi si rallenta il ritmo di invio ripartendo dalla finestra minima (pari a uno). Il massimo grado sostenibile di invio per la rete in esame nellâ€™esempio Ã¨ stato quindi ottenuto con finestra pari a quattro.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Livello applicazione e socket/Untitled 6.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Livello applicazione e socket/Untitled 6\u0026quot;\u0026gt; TCP usa un meccanismo per il controllo di flusso, detto a finestra scorrevole (sliding window), e un meccanismo per il controllo della congestione, basato sul dimensionamento della finestra scorrevole. Tutto ciÃ² per cercare il massimo ritmo di spedizione che possa garantire lâ€™inoltro dei pacchetti da parte del router piÃ¹ lento del cammino, e prevenire la saturazione del destinatario finale.\nIdea della sliding window\nLa finestra scorrevole Ã¨ un valore intero, cha parte da un valore minimo (ad esempio il valore uno). Lâ€™idea alla base del controllo di flusso a finestra scorrevole Ã¨ quello di spedire non piÃ¹ di Sliding Window pacchetti consecutivi, a partire dallâ€™ultimo pacchetto non confermato, e quindi attendere la ricezione di una conferma. Un valore di SW uguale a 1 significa che solo un pacchetto puÃ² essere spedito, poi occorre aspettare di ricevere la conferma della ricezione. In questo caso la rete Ã¨ poco utilizzata. Ogni volta che alcuni pacchetti spediti sono confermati, allora Ã¨ possibile spedire i pacchetti successivi mantenendosi entro il limite massimo di SW pacchetti dallâ€™ultimo pacchetto non ancora confermato. Eventuali pacchetti non confermati sono rispediti fino al ricevimento della conferma.\nIl senso di questo meccanismo Ã¨ quello di lasciare in sospeso non piÃ¹ di SW pacchetti, per evitare di saturare il mittente. Questo meccanismo, molto semplificato, realizza il controllo di flusso di TCP. Se i pacchetti vengono confermati, si puÃ² adottare un meccanismo dinamico per accelerare gradualmente il ritmo di invio dei pacchetti, ovvero la dimensione della finestra SW, fino a che non si nota la perdita di almeno un pacchetto tra quelli inviati.\nComportamento a perdita di pacchetti\nSe i pacchetti vanno perduti, TCP assume anche che la causa di ciÃ² sia la presenza di un router intermedio congestionato, e quindi rallenta il ritmo di invio dei pacchetti per dare modo al router congestionato di smaltire i pacchetti accumulati. Tale meccanismo, sommariamente descritto, Ã¨ il meccanismo di controllo della congestione di rete di TCP.\nMultiplexing e Demultiplexing e porte Questi termini non hanno una traduzione diretta con l\u0026rsquo;italiano, la cosa piÃ¹ simile possibile Ã¨ aggregare e disaggregare, perchÃ© da una unica scheda direte arriva tutto, questa cosa deve essere demultiplexata alla porta corretta, e multiplexata all\u0026rsquo;unica scheda di rete che si ha.\nLe well known ports sono di solito minori di 1023.\nLe porte alte sono decise da noi, basta che nell ostess ocomputer non ci sia un conflitto di porte.\nMultiplexing perchÃ© ho molte porte, ma unica scheda di rete, quindi far girare da una unica source tutto il resto. (per il mandante serve0\nDemultiplexing perchÃ© cosÃ¬ posso mandare alla porta corretta, ricevendo\nSlide multiplexing\nIn pratica il server con una singola porta non sarebbe in grado di rispondere a connessioni multiple! Ricorda che socket Ã¨ end-to-end, non saprei a quale client starei parlando.\nSi parla quindi di welcoming socket per il server, e quando si stabilisce la connessione ti dice in quale porta andare sopra per continuare a comunicare.\nEsempio di demux server\nApplicazione Introduzione livello applicazione (non fo) Il livello applicazione dei protocolli di Internet contiene lâ€™implementazione delle funzioni e dei servizi che permettono alle applicazioni di rete in esecuzione sullâ€™host di spedire e ricevere i dati. I protocolli sottostanti di Presentazione e Sessione, previsti dallo Standard ISO/OSI, non sono quasi mai considerati nellâ€™architettura dei protocolli di Internet.\nIl livello Applicazione si appoggia direttamente sul livello trasporto e, in particolare, molte applicazioni che richiedono servizi connection-oriented si basano sul protocollo TCP, attraverso numeri di porta che nel tempo sono diventati standard â€œde factoâ€. Ad esempio, la spedizione e il trasferimento dei messaggi di posta elettronica, basati sul protocollo di livello applicazione Simple Mail Transfer Protocol (SMTP) Ã¨ comunemente associata alla porta di livello applicazione 25. La porta 80 Ã¨ destinata al protocollo di trasferimento di ipertesti HyperText Transfer Protocol (HTTP) alla base del trasferimento delle pagine di siti del World Wide Web.\nAltri esempi di protocolli e servizi che si collocano al livello applicazione sono il protocollo e servizio di Domain Name Service (DNS) e i protocolli IMAP e POP3 per la consegna della posta elettronica. Una dettagliata illustrazione sul mondo dei servizi e protocolli applicativi di Internet sarÃ  oggetto di un modulo apposito\nHTTP1 (non fare) All\u0026rsquo;inizio bisognava aprire connessione per ogni singolo file che bisognava richiedere, quindi molto lento, ora sappiamo riuscire a creare socket di connessione che non si chiudono subito\nMolto bene Ã¨ descritto in HTTP e REST\nDomain Name System \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Livello applicazione e socket/Untitled 9.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Livello applicazione e socket/Untitled 9\u0026quot;\u0026gt; Immagine di spiegazione\nVorremmo avere un metodo molto semplice per umani per poter trovare un sito, ma il livello di rete non li sa gestire, ha bisogno di IP, allora ho bisogno di alcuni server dedicati che mi restituiscono l\u0026rsquo;IP dato un nome di dominio! Questo Ã¨ unico, altrimenti ci sarebbe ambiguitÃ  riguardo al nome. E altra cosa, ci sono i server DNS che sappiano dare lâ€™IP corretto a seguito del DNS.\nProblema\nGli utenti di Internet preferiscono usare nomi mnemonici per identificare le risorse in rete, ad esempio nomi di host appartenenti a una certa rete, oppure indirizzi di e-mail di utenti di una certa rete. Anche le reti, risultano spesso facilmente identificabili attraverso i nomi di dominio della rete. I nomi di dominio hanno quindi lo stesso senso degli indirizzi IP, e infatti vengono assegnati da enti internazionali, come gli indirizzi IP, per evitare confusione e nomi duplicati. Le risorse appartenenti a un dominio possono avere nomi scelti arbitrariamente (ad esempio nomi di host, indirizzi di e-mail) purchÃ¨ non siano duplicati allâ€™interno del dominio stesso. Nomi di risorse duplicati sono ammessi in domini diversi, (ad esempio, pippo@topolinia.it e pippo@paperopoli.com). I nomi di dominio hanno una struttura gerarchica del tipo (nomerisorsa.sottodominio.sottodominio.dominioradice). Ad esempio www.informatica.unibo.it Ã¨ il nome dellâ€™host che agisce da web server per il sottodominio informatica, del sottodominio UniversitÃ  di Bologna, del sottodominio di livello massimo .it (Italia). In realtÃ  il dominio radice del mondo, che esiste implicitamente, non si scrive mai. Tutto ciÃ² Ã¨ comodo ma viola le esigenze del livello rete e dei router che pretendono solo indirizzi IP.\nDNS per risolvere il problema\nPer risolvere il problema, Ã¨ nato il servizio Domain Name System (DNS) che attraverso una gerarchia di server e un protocollo standard per le richieste permette di risolvere lâ€™associazione tra nome della risorsa e indirizzo IP. Ogni host in rete deve conoscere un server DNS al quale inviare le richieste e ogni server DNS deve conoscere almeno un server DNS di livello superiore. I server di livello superiore conoscono un numero sempre maggiore di nomi e relativi indirizzi IP, ma sono sempre meno per motivi di costo.\nLâ€™esempio mostra come viene soddisfatta una richiesta DNS a seconda del punto della rete di server DNS dalla quale parte. Se un server DNS non conosce la risposta passa la richiesta al livello superiore, finchÃ© qualcuno non conosce lâ€™indirizzo IP.\nNote sull\u0026rsquo;affidabilitÃ \nÃˆ una cosa molto brutta tenere un singolo server che possieda questo server DNS, perchÃ© se fallisce nessuno puÃ² piÃ¹ raggiungerlo!. Quindi vogliamo andare a creare una alta ridondanza riguardo questo server DNS.\nReplicare servizi anche in zone differenti (ne basta una su e il servizio apparentemente Ã¨ su, ecco il sistema distribuito!). Iterativo/ricorsivo (!)\niterativo il DNS ti risponde col nuovo dns server da contattare per poter avere una risposta\nRicoversivo quando il DNS stesso va a chiedere, e quindi quando ti risponde ti da giÃ  il risultato corretto.\nQuindi in un caso si pone molto piÃ¹ onere sul client che ha richiesto, nel secondo caso si pone onere sul server DNS. Quindi a seconda di quanto hai bisogno puoi fare lâ€™uno o lâ€™altro direi.\nTyposquatting attack Questo Ã¨ un attacco sui DNS. Sappiamo che questo servizi risolvono testo in IPs che poi vengono utilizzati per mandare le richieste sulla rete. PerÃ² questo approccio Ã¨ attaccabile da domini che hanno codifiche diverse, ma carattere uguale all\u0026rsquo;utilizzatore. In questo modo un utente puÃ² essere ingannato a cliccare su quell\u0026rsquo;url, anche se il domain name originale Ã¨ diverso perchÃ© invece di A scrive Ð, per esempio hex-dump di A Ð Ã¨ 41 20 d0 90 a vediamo chiaramente che la seconda A in cirillico Ã¨ rappresentato da tre bytes, anche se sembrano esattamente essere uguali. Questo puÃ² essere utilizzato e attaccato.\nSulla connessione Riassumento, per poterci connettere sulla rete abbiamo bisogno di queste informazioni e stack di rete qui:\nStack TCP/IP firewall (IP, default router, maschera di rete) DNS DHCP Architetture a livello applicazione Client/server Peer To peer Le applicazioni e i servizi su Internet possono essere realizzati secondo almeno due modalitÃ  architetturali distinte: Architettura Client/Server e architettura Peer to Peer (P2P).\nClient/Server, i Client sono host che spediscono richieste di servizio ai Server. I Server sono i soli host sui quali sono in esecuzione i servizi che permettono di soddisfare le richieste. Un esempio di servizi di tipo Client/Server sono: il servizio DNS, dove ogni host puÃ² agire da client spedendo richieste degli indirizzi IP ai DNS server, oppure il servizio World Wide Web, e il servizio di posta elettronica, entrambi basati su client che chiedono pagine web o spediscono e-mail, e server che mantengono le informazioni o memorizzano le e-mail spedite.\nPeer to Peer (P2P), invece, tutti gli host sono contemporaneamente sia client che server. Ogni host agisce da Server cercando di soddisfare, se possibile, le richieste ricevute da altri host. Ogni host agisce da Client quando spedisce ad altri host le sue richieste, o per conto personale, o per cercare di soddisfare richieste di terzi. Un esempio di servizi P2P sono: i servizi di condivisione dati (file-sharing) basati su protocolli Freenet, Gnutella, Kazaa. Esistono anche servizi ibridi, nei quali esistono server che aiutano solo a trovare piÃ¹ rapidamente gli host P2P migliori per comunicare e implementare servizi P2P (esempio: file-sharing con Napster).\n","permalink":"https://flecart.github.io/notes/livello-applicazione-e-socket/","summary":"Livello trasporto Protocolli classici Introduzione a TCP e UPD Il quarto livello dei protocolli dellâ€™architettura di Internet Ã¨ il livello trasporto (transport), ed Ã¨ basato su due protocolli in particolare: il Transmission Control Protocol (TCP) e lo User Data Protocol (UDP), che possono essere usati in alternativa tra loro.\nQuesto Ã¨ nel genere di *connession oriented e non, il primo, TCP Ã¨ connection oriented, l\u0026rsquo;altro no, questa Ã¨ lâ€™unica differenza fra i due.","title":"Livello applicazione e socket"},{"content":"Word2Vec Paper di riferimento: (Mikolov et al. 2013).\nVideo youtube intuitivo Blog pratico\nÃˆ stato uno dei primi approcci che provano a fare un embedding semantico del significato delle parole. Semplicemente andare a fare Tokenization per andare a encodare le parole non Ã¨ sufficiente, perchÃ© questi non hanno nessun apporto semantico alle parole.\nIn questo caso vogliamo rappresentare una parola tramite vettori. Il vettore alla fine non sarÃ  altro che il layer lineare iniziale per fare all\u0026rsquo;associazione. Poi questo viene utilizzato per fare una cosa simile a un autoencoder Autoencoders. La cosa da notare Ã¨ che il layer iniziale Ã¨ enorme, Ã¨ l\u0026rsquo;intero vocabolario. GiÃ  questi\nPoi si utilizza la Crossentropy per fare backprop.\nNegative sampling Ãˆ un modo per velocizzare il training per word2vec, fare in contemporanea 600k non era feasible al tempo. Seleziona 2-20 parole nel vocabolario che non vogliamo andare a predire. 600k perchÃ© Word2Vec Ã¨ solamente doppio layer lineare, con perÃ² 3kk parole di input e output.\nNon so se lo ho capito bene ma credo faccia sampling di un certo numero di parole alla volta e aggiorna solamente i pesi interessati (quindi k target, e l\u0026rsquo;insieme dei pesi interessati, solamente quelli). Non so perchÃ© si chiami negative sampling se Ã¨ questa l\u0026rsquo;idea sotto.\nTentativo raw di codice non finito # [https://github.com/rahul1728jha/Word2Vec_Implementation/blob/master/Word_2_Vec.ipynb](https://github.com/rahul1728jha/Word2Vec_Implementation/blob/master/Word_2_Vec.ipynb) import re import numpy as np from typing import Literal stop_words = [\u0026#39;i\u0026#39;, \u0026#39;me\u0026#39;, \u0026#39;my\u0026#39;, \u0026#39;myself\u0026#39;, \u0026#39;we\u0026#39;, \u0026#39;our\u0026#39;, \u0026#39;ours\u0026#39;, \u0026#39;ourselves\u0026#39;, \u0026#39;you\u0026#39;, \u0026#34;you\u0026#39;re\u0026#34;, \u0026#34;you\u0026#39;ve\u0026#34;, \u0026#34;you\u0026#39;ll\u0026#34;, \u0026#34;you\u0026#39;d\u0026#34;, \u0026#39;your\u0026#39;, \u0026#39;yours\u0026#39;, \u0026#39;yourself\u0026#39;, \u0026#39;yourselves\u0026#39;, \u0026#39;he\u0026#39;, \u0026#39;him\u0026#39;, \u0026#39;his\u0026#39;, \u0026#39;himself\u0026#39;, \u0026#39;she\u0026#39;, \u0026#34;she\u0026#39;s\u0026#34;, \u0026#39;her\u0026#39;, \u0026#39;hers\u0026#39;, \u0026#39;herself\u0026#39;, \u0026#39;it\u0026#39;, \u0026#34;it\u0026#39;s\u0026#34;, \u0026#39;its\u0026#39;, \u0026#39;itself\u0026#39;, \u0026#39;they\u0026#39;, \u0026#39;them\u0026#39;, \u0026#39;their\u0026#39;, \u0026#39;theirs\u0026#39;, \u0026#39;themselves\u0026#39;, \u0026#39;what\u0026#39;, \u0026#39;which\u0026#39;, \u0026#39;who\u0026#39;, \u0026#39;whom\u0026#39;, \u0026#39;this\u0026#39;, \u0026#39;that\u0026#39;, \u0026#34;that\u0026#39;ll\u0026#34;, \u0026#39;these\u0026#39;, \u0026#39;those\u0026#39;, \u0026#39;am\u0026#39;, \u0026#39;is\u0026#39;, \u0026#39;are\u0026#39;, \u0026#39;was\u0026#39;, \u0026#39;were\u0026#39;, \u0026#39;be\u0026#39;, \u0026#39;been\u0026#39;, \u0026#39;being\u0026#39;, \u0026#39;have\u0026#39;, \u0026#39;has\u0026#39;, \u0026#39;had\u0026#39;, \u0026#39;having\u0026#39;, \u0026#39;do\u0026#39;, \u0026#39;does\u0026#39;, \u0026#39;did\u0026#39;, \u0026#39;doing\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;an\u0026#39;, \u0026#39;the\u0026#39;, \u0026#39;and\u0026#39;, \u0026#39;but\u0026#39;, \u0026#39;if\u0026#39;, \u0026#39;or\u0026#39;, \u0026#39;because\u0026#39;, \u0026#39;as\u0026#39;, \u0026#39;until\u0026#39;, \u0026#39;while\u0026#39;, \u0026#39;of\u0026#39;, \u0026#39;at\u0026#39;, \u0026#39;by\u0026#39;, \u0026#39;for\u0026#39;, \u0026#39;with\u0026#39;, \u0026#39;about\u0026#39;, \u0026#39;against\u0026#39;, \u0026#39;between\u0026#39;, \u0026#39;into\u0026#39;, \u0026#39;through\u0026#39;, \u0026#39;during\u0026#39;, \u0026#39;before\u0026#39;, \u0026#39;after\u0026#39;, \u0026#39;above\u0026#39;, \u0026#39;below\u0026#39;, \u0026#39;to\u0026#39;, \u0026#39;from\u0026#39;, \u0026#39;up\u0026#39;, \u0026#39;down\u0026#39;, \u0026#39;in\u0026#39;, \u0026#39;out\u0026#39;, \u0026#39;on\u0026#39;, \u0026#39;off\u0026#39;, \u0026#39;over\u0026#39;, \u0026#39;under\u0026#39;, \u0026#39;again\u0026#39;, \u0026#39;further\u0026#39;, \u0026#39;then\u0026#39;, \u0026#39;once\u0026#39;, \u0026#39;here\u0026#39;, \u0026#39;there\u0026#39;, \u0026#39;when\u0026#39;, \u0026#39;where\u0026#39;, \u0026#39;why\u0026#39;, \u0026#39;how\u0026#39;, \u0026#39;all\u0026#39;, \u0026#39;any\u0026#39;, \u0026#39;both\u0026#39;, \u0026#39;each\u0026#39;, \u0026#39;few\u0026#39;, \u0026#39;more\u0026#39;, \u0026#39;most\u0026#39;, \u0026#39;other\u0026#39;, \u0026#39;some\u0026#39;, \u0026#39;such\u0026#39;, \u0026#39;no\u0026#39;, \u0026#39;nor\u0026#39;, \u0026#39;not\u0026#39;, \u0026#39;only\u0026#39;, \u0026#39;own\u0026#39;, \u0026#39;same\u0026#39;, \u0026#39;so\u0026#39;, \u0026#39;than\u0026#39;, \u0026#39;too\u0026#39;, \u0026#39;very\u0026#39;, \u0026#39;s\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;can\u0026#39;, \u0026#39;will\u0026#39;, \u0026#39;just\u0026#39;, \u0026#39;don\u0026#39;, \u0026#34;don\u0026#39;t\u0026#34;, \u0026#39;should\u0026#39;, \u0026#34;should\u0026#39;ve\u0026#34;, \u0026#39;now\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;ll\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;re\u0026#39;, \u0026#39;ve\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;ain\u0026#39;, \u0026#39;aren\u0026#39;, \u0026#34;aren\u0026#39;t\u0026#34;, \u0026#39;couldn\u0026#39;, \u0026#34;couldn\u0026#39;t\u0026#34;, \u0026#39;didn\u0026#39;, \u0026#34;didn\u0026#39;t\u0026#34;, \u0026#39;doesn\u0026#39;, \u0026#34;doesn\u0026#39;t\u0026#34;, \u0026#39;hadn\u0026#39;, \u0026#34;hadn\u0026#39;t\u0026#34;, \u0026#39;hasn\u0026#39;, \u0026#34;has\u0026#34;] def get_file_data(stop_word_removal: bool = False): file_contents = [] with open(\u0026#39;jef_archer.txt\u0026#39;) as f: file_contents = f.read() text = [] for val in file_contents.split(\u0026#39;.\u0026#39;): sent = re.findall(\u0026#34;[A-Za-z]+\u0026#34;, val) line = \u0026#39;\u0026#39; for words in sent: if stop_word_removal: if len(words) \u0026gt; 1 and words not in stop_words: line = line + \u0026#39; \u0026#39; + words else: if len(words) \u0026gt; 1 : line = line + \u0026#39; \u0026#39; + words text.append(line) return text def generate_dictinoary_data(text: list[str]): word_to_index= dict() index_to_word = dict() corpus = [] count = 0 vocab_size = 0 for row in text: for word in row.split(): word = word.lower() corpus.append(word) if word_to_index.get(word) == None: word_to_index.update ( {word : count}) index_to_word.update ( {count : word }) count += 1 vocab_size = len(word_to_index) length_of_corpus = len(corpus) return word_to_index,index_to_word,corpus,vocab_size,length_of_corpus def get_one_hot_vectors(target_word: str, context_words: list[str], vocab_size: int, word_to_index: dict[str, int]): #Create an array of size = vocab_size filled with zeros trgt_word_vector = np.zeros(vocab_size) #Get the index of the target_word according to the dictionary word_to_index. #If target_word = best, the index according to the dictionary word_to_index is 0. #So the one hot vector will be [1, 0, 0, 0, 0, 0, 0, 0, 0] index_of_word_dictionary = word_to_index.get(target_word) #Set the index to 1 trgt_word_vector[index_of_word_dictionary] = 1 #Repeat same steps for context_words but in a loop ctxt_word_vector = np.zeros(vocab_size) for word in context_words: index_of_word_dictionary = word_to_index.get(word) ctxt_word_vector[index_of_word_dictionary] = 1 return trgt_word_vector,ctxt_word_vector #Note : Below comments for trgt_word_index, ctxt_word_index are with the above sample text for understanding the code flow def generate_training_data(corpus,window_size,vocab_size,word_to_index,length_of_corpus,sample=None): training_data = [] training_sample_words = [] for i,word in enumerate(corpus): index_target_word = i target_word = word context_words = [] if i == 0: context_words = [corpus[x] for x in range(i + 1 , window_size + 1)] elif i == len(corpus)-1: context_words = [corpus[x] for x in range(length_of_corpus - 2 ,length_of_corpus -2 - window_size , -1 )] else: before_target_word_index = index_target_word - 1 for x in range(before_target_word_index, before_target_word_index - window_size , -1): if x \u0026gt;= 0: context_words.append(corpus[x]) after_target_word_index = index_target_word + 1 for x in range(after_target_word_index, after_target_word_index + window_size): if x \u0026lt; len(corpus): context_words.append(corpus[x]) trgt_word_vector, ctxt_word_vector = get_one_hot_vectors(target_word,context_words,vocab_size,word_to_index) training_data.append([trgt_word_vector, ctxt_word_vector]) if sample is not None: training_sample_words.append([target_word, context_words]) return training_data, training_sample_words def forward_prop(weight_inp_hidden, weight_hidden_output, target_word_vector): hidden_layer = np.dot(weight_inp_hidden.T, target_word_vector) u = np.dot(weight_hidden_output.T, hidden_layer) y_predicted = softmax(u) return y_predicted, hidden_layer, u def softmax(x): e_x = np.exp(x - np.max(x)) return e_x / e_x.sum(axis=0) def calculate_error(y_pred,context_words): total_error = [None] * len(y_pred) index_of_1_in_context_words = {} for index in np.where(context_words == 1)[0]: index_of_1_in_context_words.update ( {index : \u0026#39;yes\u0026#39;} ) number_of_1_in_context_vector = len(index_of_1_in_context_words) for i,value in enumerate(y_pred): if index_of_1_in_context_words.get(i) != None: total_error[i]= (value-1) + ( (number_of_1_in_context_vector -1) * value) else: total_error[i]= (number_of_1_in_context_vector * value) return np.array(total_error) def backward_prop(weight_inp_hidden,weight_hidden_output,total_error, hidden_layer, target_word_vector,learning_rate): dl_weight_inp_hidden = np.outer(target_word_vector, np.dot(weight_hidden_output, total_error.T)) dl_weight_hidden_output = np.outer(hidden_layer, total_error) # Update weights weight_inp_hidden = weight_inp_hidden - (learning_rate * dl_weight_inp_hidden) weight_hidden_output = weight_hidden_output - (learning_rate * dl_weight_hidden_output) return weight_inp_hidden,weight_hidden_output def calculate_loss(u,ctx): sum_1 = 0 for index in np.where(ctx==1)[0]: sum_1 = sum_1 + u[index] sum_1 = -sum_1 sum_2 = len(np.where(ctx==1)[0]) * np.log(np.sum(np.exp(u))) total_loss = sum_1 + sum_2 return total_loss if __name__ == \u0026#34;__main__\u0026#34;: # text = get_file_data(stop_word_removal=\u0026#39;yes\u0026#39;) text = [\u0026#34;Best way to success is to work hard and never give up\u0026#34;] word_to_index,index_to_word,corpus,vocab_size,length_of_corpus = generate_dictinoary_data(text) print(\u0026#39;word_to_index:\u0026#39;,word_to_index) print(\u0026#39;index_to_word:\u0026#39;,index_to_word) print(\u0026#39;corpus:\u0026#39;,corpus) print(\u0026#39;vocab_size:\u0026#39;,vocab_size) print(\u0026#39;length_of_corpus:\u0026#39;,length_of_corpus) GloVe ELMo References [1] Mikolov et al. â€œEfficient Estimation of Word Representations in Vector Spaceâ€ arXiv preprint arXiv:1301.3781 2013\n","permalink":"https://flecart.github.io/notes/word-embeddings/","summary":"Word2Vec Paper di riferimento: (Mikolov et al. 2013).\nVideo youtube intuitivo Blog pratico\nÃˆ stato uno dei primi approcci che provano a fare un embedding semantico del significato delle parole. Semplicemente andare a fare Tokenization per andare a encodare le parole non Ã¨ sufficiente, perchÃ© questi non hanno nessun apporto semantico alle parole.\nIn questo caso vogliamo rappresentare una parola tramite vettori. Il vettore alla fine non sarÃ  altro che il layer lineare iniziale per fare all\u0026rsquo;associazione.","title":"Word Embeddings"},{"content":"Ultima modifica: March 24, 2023 7:35 PM Primo Abbozzo: March 24, 2023 2:23 PM Studi Personali: No\nAmbienti di sviluppo Ambiente di sviluppo Ã¨ diverso rispetto allâ€™ambiente di deploy! bisognare fare delle differenze, sono dell macchine diverse, in questa sezione di documenti andiamo a parlare di norme e modi di lavorare per facilitare il metodo di sviluppo.\nNote di compatibilitÃ  Front-end Le compatibilitÃ , soprattutto per cose browser (quindi front-end) cambiano molto spesso, come fare a trackare queste cose? C\u0026rsquo;Ã¨ un sito molto carino come https://caniuse.com/ .\nLa browser list, Ã¨ utilizzata per specificare unt browser di target per la nostra applicazione, non ho capito bene cosa serve.\nI *polifylli permettonolâ€™esecuzione di codice recente\nGestione versioni Si utilizzano cose come package json, e tools come npm e yarn per gesitire queste dipendenze. Nei file lock ci sono gli hash, ti dice quale specifica versione funziona (praticamente serve per dirti esattamente tutte le cose necessarie per lâ€™ambiente di deploy, per questo lo devi committare! come il go sum). Ãˆ necessario, sennÃ² sono in dependency hell (una dipendenza che aggiunge una dipendenza di altre dipendenze, puÃ² rallentare tutto), non riesco a gestire tutte queste velocemente!\nPoi si dividono in\ndevDependency quando Ã¨ solamente per lo sviluppo come linter, o file cli dependency quando serve per l\u0026rsquo;esecuzione del programma. semantic versioning\nSlide semantic versioning\nCi danno giÃ  informazioni su compatibilitÃ , versioni accettate e cose simili.\nStile Strumenti come esling, prettier, permettono di fare contorllo sullo stile, e anche correggerle in automatico! Queste fanno una analisi statica del codice e riformattano, oppure ti ritornano alcuni pezzi di roba ambigua.\nDi solito conviene perchÃ© rende il codice molto piÃ¹ agibile e comprensibile dal team.\nCose come parentesi, indentazioni, sono importanti, anche ad esempio utilizzare stessi cases.\nType checking Slide typescript\nAbbiamo tutte le garanzie di Teoria dei Tipi! In pratica Ã¨ molto buono utilizzare questo\nTraspiler Ãˆ simile alla compilazione, ma Ã¨ fra linguaggi allo stesso livello (ad esempio versioni diverse di javascript, per essere comprensibile fra versioni browser diversi), mentre compilazione secondo vitali Ã¨ da linguaggi di alto livello a uno di livello inferiore, anche se non credo fosse questa la definizione in Macchine Astratte.\nReact utilizza molto babel, che Ã¨ il traspilatore principale per questo.\nMinifier e obfuscating vogliamo cercare di ridurre caratteri, in modo da minimizzare la grandezza del file di output mantenendone la semantica (quindi cosa faccia). Ci serve per esempio se vogliamo dare un file JS, ma vogliamo limitare la banda, per trasmettere le stesse informazioni.\nWebpack, un bundler che vedremo dopo riesce anche a fare minify.\nQuesta cosa Ã¨ molto diversa rispetto a offuscare!\noffuscare serve per rendere il coidce illeggibile, in modo da rendere piÃ¹ difficile la comprensione del codice, e quindi da farci reverse engineering e scoprire vulnerabilitÃ  e simili ma anche per evitare di copiare l\u0026rsquo;applicaione e replicarlo altrove, anche questi sono fatti in automatico da certe applicazioni.\nRiassunto in breve traspiler minifier, obfuscating e compressione\nBundlers Ci sono molti bundlers il piÃ¹ comune Ã¨ webpack.\nLâ€™obiettivo Ã¨ mettere assieme tutti i moduli js in modo che sia solo 1, quindi molto piÃ¹ efficiente da dare al web.\nAltro Sta facendo una lista di un sacco di tecnologie!!! ðŸ˜±.\nMeglio andare a studiarseli da soli perchÃ© la lista non me ne facio niente, Ã¨ utile perÃ² sapere che esistono.\nDeve continuare dal testing\n","permalink":"https://flecart.github.io/notes/ambienti-di-sviluppo/","summary":"Ultima modifica: March 24, 2023 7:35 PM Primo Abbozzo: March 24, 2023 2:23 PM Studi Personali: No\nAmbienti di sviluppo Ambiente di sviluppo Ã¨ diverso rispetto allâ€™ambiente di deploy! bisognare fare delle differenze, sono dell macchine diverse, in questa sezione di documenti andiamo a parlare di norme e modi di lavorare per facilitare il metodo di sviluppo.\nNote di compatibilitÃ  Front-end Le compatibilitÃ , soprattutto per cose browser (quindi front-end) cambiano molto spesso, come fare a trackare queste cose?","title":"Ambienti di sviluppo"},{"content":" The human ability of making analogies proceeds in such a way as to keep complexity minimal.\nPerchÃ© facciamo questo? PerchÃ© Ã¨ la cosa piÃ¹ semplice da fare! Anche su Vapnik\u0026rsquo;s dimensions Ã¨ simile questa idea!\nOccam razor, Epicuro, con Solomonoff che ha risolto problema dell\u0026rsquo;induzione che Hume pensava di fare con abitudini. Attualmente IQ tests provano a misurare la capacitÃ  di estendere questo.\nAnalogia Studiamo l\u0026rsquo;analogia come oggetto matematico perchÃ© sembra essere una capacitÃ  molto difficile da generalizzare e utilizzare nelle macchine.\nDefinizione di analogia Scrivo $A:B :: C:D$ per dire che esiste una relazione $\\mathcal{R}$ tale per cui valga $R(A,B), R(C,D)$ Questa relazione deve soddisfare certi assiomi come\nProprietÃ  dell\u0026rsquo;analogia IdentitÃ  $$ \\mathcal{A}(A,B,A,B) $$ Simmetria\n$$ \\mathcal{A}(A,B,C,D) \\implies \\mathcal{A}(C, D, A, B) $$ Permutazione centrale\n$$ \\mathcal{A}(A,B,C,D) \\implies \\mathcal{A}(A,C,B,D) $$ Sono tutte proprietÃ  che intuivamente hanno senso quando si parla di analogia.\nEquazione di analogia Scriviamo $$ A:B::C:x $$ L\u0026rsquo;obiettivo Ã¨ trovare un $x$ nel dominio che soddisfa la relazione $\\mathcal{R}$ scelta, che che sia piÃ¹ semplice possibile. Per la semplicitÃ  utilizziamo Kolmogorov complexity quindi scegliamo $$ x = argmin(K(A,B,C,x)) $$ Minimum Description length principle https://truththeory.com/2018/05/07/string-theory-explained-what-is-the-true-nature-of-reality-video/\nPrinciple used to choose models to describe phenomenons of the world in particular:\n$$ M_{0} = argmin_{M}(K(M) + K(D|M)) $$ Che Ã¨ in un certo senso un trade fra overfitting e undefitting classico, solo da un punto di vista di AIT.\nThe best model is neither the simplest one nor the one that offers the best fit with the data, but the model that achieves the best compromise between simplicity and data fitting.\nUniversal Induction Solomonoff usa principle of Multiple explanations (Epicuro, tiene tutte le spiegazioni che sono buone per i dati).\n","permalink":"https://flecart.github.io/notes/model-of-analogies/","summary":"The human ability of making analogies proceeds in such a way as to keep complexity minimal.\nPerchÃ© facciamo questo? PerchÃ© Ã¨ la cosa piÃ¹ semplice da fare! Anche su Vapnik\u0026rsquo;s dimensions Ã¨ simile questa idea!\nOccam razor, Epicuro, con Solomonoff che ha risolto problema dell\u0026rsquo;induzione che Hume pensava di fare con abitudini. Attualmente IQ tests provano a misurare la capacitÃ  di estendere questo.\nAnalogia Studiamo l\u0026rsquo;analogia come oggetto matematico perchÃ© sembra essere una capacitÃ  molto difficile da generalizzare e utilizzare nelle macchine.","title":"Model of Analogies"},{"content":"Ripasso Prox: 50.31 Ripasso: May 18, 2022 Ultima modifica: October 8, 2022 12:09 PM Primo Abbozzo: October 11, 2021 6:08 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso dimostrazione esistenza e unicitÃ  della radice, qui un pÃ² di difficoltÃ  (ti sei totalmente dimenticato del vincolo di voler avere cose maggiore di 0) Ho messo .31 ho fatto 50 l\u0026rsquo;ultima volta anche perÃ² l\u0026rsquo;esame Ã¨ vicino e non avrebbe molto senso rifare dopo\u0026hellip; 2 R e Intervalli 2.1 NecessitÃ  e caratteristiche di R 2.1.1 Radici di N non perfetti e Q $\\sqrt{n} \\in \\mathbb{Q} \\implies n \\text{ Ã¨ quadrato perfetto}$\nFai lemma della divisibilitÃ  fra due numeri\nLemma: Dati $m,n,l$ tali che $MCD(m,l)=1$ e $l | m n$ allora allora $l | n$ Questo si risolve con ragionamenti sui fattori di m e n. Per dimostrare che Ã¨ razionale la radice di solamente una radice perfetta parto da un numero razionale, faccio certi ragionamenti e scoprirÃ² alla fine che il numero deve essere una radice perfetta.\nQuesto teorema si puÃ² ancora estendere con questo:\nEsercizio (dimostrare) 2.1.2 NecessitÃ  di R Per dimostrazione del punto precedente, ci sono un sacco di lacune in quanto la maggior parte delle radici non appartiene a Q. C\u0026rsquo;Ã¨ bisogno di un insieme che operi bene al limite, cosa che con Q non va bene.\nIntuizione di R\nAggiungere a Q tutti i punti di cui mancano. Si dice che R Ã¨ Continuo\nEsempio inefficacia di Q\nIn questo esempio l\u0026rsquo;esistenza di un $sup$ c\u0026rsquo;Ã¨ solo in R perchÃ© in Q la radice di due non Ã¨ presente e quindi non c\u0026rsquo;Ã¨\u0026hellip;\nCaratteristican unica\nSupremum property esiste sempre il limite superiore o inferiore di un insieme ,questo non succede anche per Q.\n2.1.3 Completezza di R $$ \\forall A:A\\neq\\empty \\implies A\\in \\R $$ Si ottiene completando Q con i pezzi mancanti, per farlo si deve introdurre il concetto di ContinuitÃ  â†’ Intervalli\nQuesta proprietÃ  di R Ã¨ molti importante perchÃ© permette di avere sup e inf definiti in seguito qui\nInnumerabilitÃ  di R CardinalitÃ \nSi puÃ² affermare che la cardinalitÃ  di R sia molto maggiore di N, infatti si puÃ² dimostrare che Ã¨ innumerabile grazie\nCantor, si fa la costruzione a tabella e si dimostra che non Ã¨ suriettiva, ovvero che nell\u0026rsquo;intervallo $[0,1[$ esiste un numero che non Ã¨ mai raggiunto da un numero naturale, infatti riesco a costruire un numero che sia diverso in una cifra da tutti i numeri decimali in tabella. Questa Ã¨ la dimostrazione piÃ¹ semplice di Cantor.\nUn altro argomento insiemistico lo puoi trovare qui Relazioni fra insiemi#Diagonalizzazione di Cantor.\n2.1.5 Esistenza unicitÃ  della radice File per pdf di lezione per questa\n$$ \\forall a \\in \\R_+, \\forall n \\in \\N - \\{0\\} ,\\exists !b \\in \\R_+ : b^n = a $$ Si indica con $^n\\sqrt{a} = b$\nUna serie di lemmi utili per la dimostrazione:\nLemmi $x^n \\geq y^n \\implies x \\geq y$ $x^n \\leq y^n \\implies x \\leq y$ $x ^n = y^n \\implies x = y$ $x^n \u003c y \\implies \\exists \\epsilon ,(x + \\epsilon) ^n \u003c y$ $x ^n \u003e y \\implies \\exists\\epsilon (x - \\epsilon)^n \u003e y$ NOTA: per dimostrare i lemmi potrebbe essere molto piÃ¹ semplice provare a dimostrare prima per $n = 2$ e poi estendere da questo e poi passando per n generalizzatot\nSapendo di tutti questi lemmi si puÃ² dimostrare esistenza ed unicitÃ  della radice n-esima.\nPer l\u0026rsquo;unicitÃ  basta utilizzare il lemma numero 3 (che si dimostra utilizzando i lemmi 1 e 2)\nPer dimostrare l\u0026rsquo;esistenza della radice bisogna dimostrare l\u0026rsquo;assurdo che la radice sia minore di quello e maggiore di quello (quello nel senso di 4 e 5)\nPer farlo si parte dalla continuitÃ  di R creando prima un insieme in cui il sup Ã¨ x, e da lÃ¬ dimostrare che Ã¨ assurdo che la radice sia diversa da quello\nDimostrazione:\nSia $A := \\{x \\in \\mathbb{R} \\mid x^2 \\leq b\\}$ devo dimostrare che esiste ed Ã¨ unico la radice a: $a ^2= b$\nAllora pongo per assurdo che non esiste tale radice, quindi devo dimostrare l\u0026rsquo;assurdo per $a ^2 \u003c b \\wedge a ^2 \u003e b$.\nPoniamo $a$ come il sup dell\u0026rsquo;insieme A, cosa che esiste dato che Ã¨ superiormente limitato. (poi usiamo i lemmi 4 e 5)\nCaso 1:\n$a^2 \u003c b \\implies (a + \\epsilon) ^2 \u003c b \\implies a + \\epsilon \\in A \\implies a + \\epsilon \u003c a \\implies absurd$\nCaso 2:\n$a^2 \u003e b \\implies (a - \\epsilon)^2 \u003e b \\implies a - \\epsilon \\not\\in A \\implies a - \\epsilon \\geq a \\implies absurd$\nQuindi esiste la radice.\nPer dimostrare che sia unico mi basta usare il lemma 3\n2.2 Intervalli, Maggioranti ed estremi 2.2.1 Intervalli Intervalli\n2.2.2 Maggioranti o minoranti Un maggiorante (o minorante) Ã¨ un elemento che Ã¨ maggiore (o minore di tutti gli elementi) di un certo insieme.\n2.2.3 Limitatezza Un insieme Ã¨ maggiormente o inferiormente limitato se esiste un maggiorante o un minorante di un insieme.\nSe un insieme Ã¨ sia maggiormente sia inferiormente limitato si dice che Ã¨ limitato\n2.2.4 Estremi (superiori ed inferiori) Un estremo Ã¨ definito in questo modo, che funziona anche per i razionali.\n$$ l = sup X \\iff \\begin{cases} \\forall x \\in X , l \\geq x \\\\ \\forall\\epsilon : \\epsilon \u003e 0,\\exists x \\in X, l-\\epsilon \\leq x \\\\ \\end{cases} $$ l Ã¨ un maggiorante l Ã¨ anche il piÃ¹ piccolo dei minoranti. In modo simile si puÃ² definire la parte inferiore.\nDetto in altre parole il sup Ã¨ il minimo dell\u0026rsquo;intero insieme dei maggioranti, se esiste questo insieme\n2.2.5 Massimi e minimi di insiemi Dato un $x \\in X, x:= _{min} \\forall y: y\\in X \\implies x \\leq y$\nE in modo simile i massimi.\nSi puÃ² mettere in relazione massimi e minimi fra di loro, quindi posso dire che:\nSe esiste il minimo, questo Ã¨ il MASSIMO fra tutti i minoranti.\nPunto di massimo e minimo Questa parte sarÃ  utile per weierstrass.\nPMassimo:\n$f:X \\to\\R$ si dice punto di massimo $x$ se:\n$\\forall x_0 \\in X, f(x) \\geq f(x_0)$\nPMinimo\n$f:X \\to\\R$ si dice punto di massimo $x$ se:\n$\\forall x_0 \\in X, f(x) \\leq f(x_0)$\nðŸ’¡ Stai molto attento a non confondere il punto di massimo assoluto con il massimo assoluto! Uno sta sul dominio, l'altro sul codominio 2.3 Valore assoluto Definizione del valore assoluto $\\lvert a \\rvert = max(a, -a)$ e si puÃ² fare anche una funzione a tratti\n2.3.1 7 ProprietÃ  del valore assoluto $|a| \\geq 0$ $|a| =|-a|$ $-|a| \\leq a \\leq |a|$ $|a + b| \\leq | a| + | b|$ $||a|-|b|| \\leq |a-b|$ Espansione con disuguaglianze con altre cose senza valore assoluto Caratteristiche di R Campo ordinato Ordine totale e completo (completo = con gli infiniti) **(in cui le relazioni di ordine valgono) vedi pp 76 di Foundations of real analisys.\nProprietÃ  archimedea nessun numero in R Ã¨ infinitamente grande Nessun elemento in R Ã¨ infinitamente piccolo (esiste sempre un elemento in Q piÃ¹ piccolo). L\u0026rsquo;insieme R Ã¨ denso e nessun numero in R Ã¨ infinitamente grande Nessun elemento in R Ã¨ infinitamente piccolo (esiste sempre un elemento in Q piÃ¹ piccolo).\n","permalink":"https://flecart.github.io/notes/r-e-intervalli/","summary":"Ripasso Prox: 50.31 Ripasso: May 18, 2022 Ultima modifica: October 8, 2022 12:09 PM Primo Abbozzo: October 11, 2021 6:08 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso dimostrazione esistenza e unicitÃ  della radice, qui un pÃ² di difficoltÃ  (ti sei totalmente dimenticato del vincolo di voler avere cose maggiore di 0) Ho messo .31 ho fatto 50 l\u0026rsquo;ultima volta anche perÃ² l\u0026rsquo;esame Ã¨ vicino e non avrebbe molto senso rifare dopo\u0026hellip; 2 R e Intervalli 2.","title":"R e Intervalli"},{"content":"Abbiamo trattato i modelli classici in Convolutional NN. Con i vecchi files di notion\nIl Kernel I punti interessanti delle immagini sono solamente i punti di cambio solo che attualmente siamo in stato discreto, quindi ci Ã¨ difficile usare una derivata, si usano kernel del tipo: $\\left[ 1, 0, -1 \\right]$, che sarÃ  positivo se cresce verso sinistra, negativo se scende. feature map Sono delle mappe che rappresentano alcune informazioni interessanti della nostra immagine.\nPrincipi di base Nota sulla depth Come viene spiegato in (Cohen et al. 2016) shallow e deep sono equivalenti, ma c\u0026rsquo;Ã¨ una esplosione esponenziale sul numero di neuroni necessari\nCaratteristiche di convoluzionali LocalitÃ , Condivisione, Invarianza per traslazioni LocalitÃ  perchÃ© ho una field of view, che Ã¨ la grandezza del kernel precedente, condivisione perchÃ© i pesi del kernel sono sempre gli stessi. Poi non ho capito perchÃ© il pooling fa invarianza per traslazioni.\nReferences [1] Cohen et al. â€œOn the Expressive Power of Deep Learning: A Tensor Analysisâ€ arXiv preprint arXiv:1509.05009 2016\n","permalink":"https://flecart.github.io/notes/reti-convoluzionali/","summary":"Abbiamo trattato i modelli classici in Convolutional NN. Con i vecchi files di notion\nIl Kernel I punti interessanti delle immagini sono solamente i punti di cambio solo che attualmente siamo in stato discreto, quindi ci Ã¨ difficile usare una derivata, si usano kernel del tipo: $\\left[ 1, 0, -1 \\right]$, che sarÃ  positivo se cresce verso sinistra, negativo se scende. feature map Sono delle mappe che rappresentano alcune informazioni interessanti della nostra immagine.","title":"Reti convoluzionali"},{"content":"Formalizzazione del problema Definizione formale del tiling Consideriamo una tupla $\\langle \\mathcal{T}, t_{0}, H, V \\rangle$\n$\\mathcal{T}$ Ã¨ un insieme di piastrelle. $t_{0} \\in \\mathcal{T}$ Ã¨ la piastrella d\u0026rsquo;origine. $H \\subseteq \\mathcal{T} \\times \\mathcal{T}$ le regole di adiacenza orizzontali. $V \\subseteq \\mathcal{T} \\times \\mathcal{T}$ le regole di adiacenza verticali. L\u0026rsquo;obiettivo Ã¨ vedere se Ã¨ possibile riempire tutto il piano con queste piastrelle, all\u0026rsquo;infinito. Sappiamo giÃ  che non Ã¨ sempre possibile farlo. Ci chiediamo se Ã¨ automatizzabile. Questo problema Ã¨ stato risolto nel 1966, e sembra non essere riconoscibile nemmeno.\nOssia in matematichese definire la funzione $f : \\mathbb{N} \\times \\mathbb{N} \\to \\mathcal{T}$ Con\n$f(1, 1) = t_{0}$ $\\forall n,m \\in \\mathbb{N}, (f(n, m), f(n + 1, m)) \\in V$ $\\forall n,m \\in \\mathbb{N}, (f(n, m), f(n, m+1)) \\in H$ Strategia di dimostrazione Vogliamo ridurlo da $ETH^{-}$ che abbiamo spiegato in Halting Theorem and Reducibility. Questo Ã¨ un linguaggio non riconoscibile, perchÃ© il suo complemento Ã¨ riconoscibile in modo banale.\nQuesta dimostrazione avrÃ  un sacco di punti molto tecnici per dire che una macchina di turing deve essere tradotta in un problema di tiling\u0026hellip;\nDimostrazione inriconoscibilitÃ  del tiling L\u0026rsquo;idea principale Ã¨ che con un tiling posso simulare l\u0026rsquo;esecuzione di una macchina di Turing. E in questo modo riduco il problema a un Halt. PerchÃ© sapere tassellare significa sapere dire quando una macchina di Turing finisce.\nCodifica delle regole dei tiling Posso codificare sia i tile disponibili, sia le regole di adiacenza in questo modo.\nPoi vogliamo codificare ogni casella verticale un singolo step di computazione.\nCella di identitÃ  Questa cella non fa niente. Celle di transizione Possiamo codificare le funzioni di transizione della macchina di Turing. Poi ho ancora le cose che mantengono il simbolo nella cella di arrivo.\n#### Conclusione sse non si ferma la macchina, allora esiste un tiling (che Ã¨ una cosa banale perchÃ© significa che continua all'infinito, e quindi posso mappare tutto). ","permalink":"https://flecart.github.io/notes/tiling-problem/","summary":"Formalizzazione del problema Definizione formale del tiling Consideriamo una tupla $\\langle \\mathcal{T}, t_{0}, H, V \\rangle$\n$\\mathcal{T}$ Ã¨ un insieme di piastrelle. $t_{0} \\in \\mathcal{T}$ Ã¨ la piastrella d\u0026rsquo;origine. $H \\subseteq \\mathcal{T} \\times \\mathcal{T}$ le regole di adiacenza orizzontali. $V \\subseteq \\mathcal{T} \\times \\mathcal{T}$ le regole di adiacenza verticali. L\u0026rsquo;obiettivo Ã¨ vedere se Ã¨ possibile riempire tutto il piano con queste piastrelle, all\u0026rsquo;infinito. Sappiamo giÃ  che non Ã¨ sempre possibile farlo.","title":"Tiling problem"},{"content":"Introduction to tokenization Tokenization is the process of converting normal strings into small little pieces that could be fed into one of our models. It usually comes from a tradition in programming languages, as we can see in Automi e Regexp where we define a specific token to have a known pattern, usually recognized by regular expressions.\nThere have been historically been many approaches to tokenization, let\u0026rsquo;s see a few:\nUn approccio semplice (e non funzionante) Uno dei primi approcci che potrebbe venire in mente per questo problema di divisione delle parole Ã¨ avere delle componenti fisse (ad esempio lettere di alfabeto, o lettere) e utilizzare queste per fare tokenization. CioÃ¨ stiamo mappando parti delle parole in modo greedy, prima arriva meglio Ã¨. Si potrebbe rappresentare in questo modo: Da questo ipynb Subword tokenization A volte conviene dividere una stessa parola in token che siano piÃ¹ piccoli della parola, perchÃ© questi potrebbero essere utilizzati in modo ricorrente in suffissi o prefissi (questo ha senso), perÃ² abbiamo bisogno di algoritmi che facciano questa tokenizzazione. Byte Pair Encoding Viene tratta per benino in ambito NLU (Sennrich et al. 2016)\nAlgoritmo in breve With this approach we use al algorithm similar to this:\nStart with each character as a different symbol (create a set) begin iterate The most frequent pair of symbols is merged into a single symbol. end iteration on n done iterations, or when the set is considered small enough So this is just a small and easy algorithm that we can use to create tokenizations over a single text corpus.\nStudio versione in paper (Credo da (Sennrich et al. 2016)) Un esempio breve in python tratto dal papero stesso:\nimport re, collections def get_stats(vocab): pairs = collections.defaultdict(int) for word, freq in vocab.items(): symbols = word.split() for i in range(len(symbols)-1): pairs[symbols[i],symbols[i+1]] += freq return pairs def merge_vocab(pair, v_in): v_out = {} bigram = re.escape(\u0026#39; \u0026#39;.join(pair)) p = re.compile(r\u0026#39;(?\u0026lt;!\\S)\u0026#39; + bigram + r\u0026#39;(?!\\S)\u0026#39;) for word in v_in: w_out = p.sub(\u0026#39;\u0026#39;.join(pair), word) v_out[w_out] = v_in[word] return v_out vocab = {\u0026#39;l o w \u0026lt;/w\u0026gt;\u0026#39; : 5, \u0026#39;l o w e r \u0026lt;/w\u0026gt;\u0026#39; : 2, \u0026#39;n e w e s t \u0026lt;/w\u0026gt;\u0026#39;:6, \u0026#39;w i d e s t \u0026lt;/w\u0026gt;\u0026#39;:3} num_merges = 10 for i in range(num_merges): pairs = get_stats(vocab) best = max(pairs, key=pairs.get) vocab = merge_vocab(best, vocab) print(best) NOTE: defaultdict Ã¨ solamente un dict normale che ha un default value, in questo caso 0 se non esiste la chiave, e get che ritorna None se non c\u0026rsquo;Ã¨, invece di dare errore.\nVersione di GPT In GPT Ã¨ stato introdotto l\u0026rsquo;idea di creare gruppi di cattura che escludessero suffissi diversi, per esempio \u0026rsquo;s, punteggiature et cetera. Puoi vedere meglio in sezione 2.2 qui (Radford et al. 2019). Esempio del regex pattern Grammatiche Regolari per GPT2 del paper citato:\ngp2pat = re.compile(r\u0026#34;\u0026#34;\u0026#34;\u0026#39;s|\u0026#39;t|\u0026#39;re|\u0026#39;ve|\u0026#39;m|\u0026#39;ll|\u0026#39;d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?! \\S) |\\s+\u0026#34;\u0026#34;\u0026#34;) Durante l\u0026rsquo;allenamento dei GPT sono stati presenti anche tokens speciali come \u0026lt;|endoftext|\u0026gt; tokens speciali per indicare fine documento. Credo sia stata una cosa per facilitare il training effettivo. https://tiktokenizer.vercel.app/ se vuoi vedere.\nReferences [1] Radford et al. â€œLanguage Models Are Unsupervised Multitask Learnersâ€ 2019\n[2] Sennrich et al. â€œNeural Machine Translation of Rare Words with Subword Unitsâ€ arXiv preprint arXiv:1508.07909 2016\n","permalink":"https://flecart.github.io/notes/tokenization/","summary":"Introduction to tokenization Tokenization is the process of converting normal strings into small little pieces that could be fed into one of our models. It usually comes from a tradition in programming languages, as we can see in Automi e Regexp where we define a specific token to have a known pattern, usually recognized by regular expressions.\nThere have been historically been many approaches to tokenization, let\u0026rsquo;s see a few:","title":"Tokenization"},{"content":"Ripasso Prox: 27 Ripasso: June 2, 2022 Ultima modifica: January 4, 2023 9:54 AM Primo Abbozzo: March 22, 2022 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 3 Applicazioni lineari 3.1 Introduzione e definizione Si definisce applicazione lineare una funzione (omomorfica) che preserva la struttura dello spazio vettoriale, ossia vale che\n$$ f:V \\to W, tale che \\\\ f(u + v) = f(u) +f(v)\\\\ f(\\lambda v) = \\lambda f(v) $$ 3.1.1 Conservazione delle combinazioni lineari In particolare le due proprietÃ  delle applicazioni lineari mi preservano le applicazioni lineari, ovvero:\n$f(\\lambda_1 a + \\lambda_2 b) = \\lambda_1 f(a) + \\lambda_2f(b)$ e questo lo puoi estendere a qualunque tipo di vettore\n3.1.2 L\u0026rsquo;elemento neutro L\u0026rsquo;elemento neutro Ã¨ conservato nell\u0026rsquo;applicazione lineare (mappa sempre l\u0026rsquo;elemento neutro di uno all\u0026rsquo;elemento neutro dell\u0026rsquo;insieme di arrivo)\n3.1.3 Esempi Un esempio importante Ã¨ la matrice che mappa da $\\R^n\\to \\R^m$\n3.2 Esiste omomorfismo a insiemi qualunque (chiede) 5.1.7 Dimostrazione\nIl passo piÃ¹ importante Ã¨ definire l\u0026rsquo;applicazione lineare.\nLo definiamo in questo modo:\npreso $v\\in V$, allora in quanto ho una base di $V$, posso dire che\n$v = \\alpha_1v_1 +...+ \\alpha_n v_n$, allora definiamo la nostra funzione $L:V\\to W$ tale che\n$L(v) = \\alpha_1w_1 +...+\\alpha_nw_n$, da notare che i coefficienti sono gli stessi, ma i vettori diversi e abbiamo anche cambiato possibilmente lo spazio\nÃˆ una applicazione:\nfai i calcoli e puoi notare che effettivamente Ã¨ una applicazione lineare.\nCalcoli\nUnicitÃ :\nl\u0026rsquo;unicitÃ  di questa applicazione si puÃ² identificare con l\u0026rsquo;unicitÃ  delle coordinate rispetto alla base, c\u0026rsquo;Ã¨ solo una tale funzione definita in questo modo per ogni vettore.\nMa questa non Ã¨ formale, quindi appiccico la dimostrazione formale: (si utilizza l\u0026rsquo;ipotesi dell\u0026rsquo;unicitÃ  delle coordinate inmodo implicito sctivendo v come combinazione lineare della base)\n3.2.1 Coincidenza su basi La dimostrazione Ã¨ abbastanza ovvia, sappiamo che esiste un unica applicazione lineare su una base e che arriva a W.\n3.2.2 Osservazione sul teorema Questo teorema ci permette di avere delle applicazioni lineari a caso, per qualunque spazio vettoriale, basta avere una base dello spazio iniziale.\n3.2.3 modi di vedere lâ€™applicazione lineare Esistono tre modi per avere la definizione di applicazione lineare.\nClassica definizione F(v) = espressione Una matrice che mi rappresenta l\u0026rsquo;applicazione F(base1) = qualcosa, \u0026hellip; F(basen) = qualcosaltro. 3.3 Teoremi su Ker e Im 3.3.1 Ker F e Im F sono sottospazi Devo dimostrare che questi insiemi siano dei sottospazi.\nIl vettore nullo appartiene a Ker F Poi si dovrebbe dimostrare che siano chiusi per l\u0026rsquo;operazione di somma e prodotto scalare In modo simile a quanto fatto in Spazi vettoriali 3.3.2 SuriettivitÃ  e iniettivitÃ  Enunciato:\nData una applicazione lineare $F: V\\to W$\nSuriettivo sse $Im(F) = W$, questa Ã¨ abbastanza ovvio.\nIniettiva sse $Ker(F) = \\{0\\}$\nDimostrazione\n$\\implies$Supponiamo che sia iniettiva, allora $F(x) = F(y) \\implies x = y$,\nin quanto Ã¨ una applicazione lineare so che $F(0) = 0_w$, quindi supponiamo che $v \\in V |F(v) = 0$ per iniettivitÃ  ho che $v= 0$, quindi l\u0026rsquo;unico elemento di $Ker(F)$ Ã¨ 0.\n$\\impliedby$Supponiamo che $Ker(F) = \\{0 \\}$ supponiamo che $F(x) = F(y)$ per certi $x,y \\in V$,\nvogliamo dimostrare che $x= y$.\nValutiamo $F(x - y) = F(x) - F(y) = 0_w$, ma quindi $x-y = 0_v$ in quanto per ipotesi l\u0026rsquo;unico elemento in Ker(F) Ã¨ 0v e abbiamo dimostrato che (x-y) appartiene a Ker(F), quindi $x = y$.\n3.3.3 Calcolo del nucleo Dato un omomorfismo, l\u0026rsquo;unica cosa che dobbiamo fare Ã¨ risolvere la matrice omogenea associata.\nIn parole migliori\nKer F l\u0026rsquo;insieme delle soluzioni del sistema lineare omogeneo associato ad A, dato A matrice dell\u0026rsquo;applicazione lineare\n3.3.4 Corrispondenza fra base V nellâ€™immagine 5.4.4 (chiede) Dimostrazione\nVogliamo dimostrare una doppia inclusione, perchÃ© Ã¨ questa la definizione dell\u0026rsquo;uguaglianza per un assioma di estensionalitÃ  in Teoria assiomatica degli insiemi.\nCaso $\\implies$, sia $w \\in Im(F)$, allora $\\exists v\\in V, F(v) = w$, dato che abbiamo una base, si ha che $v = \\lambda_1v_1 +...+ \\lambda_nv_n$, allora\n$F(\\lambda_1v_1 +...+ \\lambda_nv_n) = F(\\lambda_1v_1) +...+ F(\\lambda_nv_n) = \\lambda_1F(v_1) +...+ \\lambda_nF(v_n) \\in \\langle F(v_1),...., F(v_n)\\rangle$ e finisco questa freccia.\nCaso $\\impliedby$Questa praticamente Ã¨ uguale alla precedente, oppure, possiamo ricordare che per la 3.1.5 presente in Spazi vettoriali si ha che Ã¨ il piÃ¹ piccolo sottospazio generato da quei elementi. Quindi questa inclusione Ã¨ fatta in modo immediato. Ma anche ripercorrere la dimostrazione al contrario non Ã¨ un problema.\nNote:\nQuesto teorema ci Ã¨ molto utile per calcolare lo spazio generato dell\u0026rsquo;immagine, perchÃ© ci permette di fare una sorta di cambio di base (che non Ã¨ un cambio di base) stiamo solamente prendendo qualcosa di molto simile a una base, ma in un altro spazio vettoriale (non Ã¨ detto che sia una base perÃ²! so solo che genera quello spazio vettoriale).\n3.3.5 Calcolo dell\u0026rsquo;immagine Avendo il teorema precedente, il calcolo del sottospazio dell\u0026rsquo;immagine Ã¨ abbastanza veloce:\nprendo l\u0026rsquo;insieme immagine della base poi faccio gauss in modo diretto su questa. SI puÃ² dimostrare che questo non Ã¨ altro che gauss sulla TRASPOSTA.\n3.4 Teorema della dimensione (!!!chiedissimo) 5.5.1 Questo Ã¨ uno dei teoremi piÃ¹ importanti per tutto il corso di geometria! Vale per qualunque applicazione lineare per spazi vettoriali!\nIdee per la dimostrazione\nA caratteri generali, i passi logici principali per la dimostrazione Ã¨ questa:\nPrendiamo una base di V, e la base per Ker(F). Per il completamento posso completare la base del nucleo in una base di V. Prendo l\u0026rsquo;insieme dei vettori che ho aggiunto al nucleo, voglio dimostrare che la funzione applicata a questi vettori sia in grado di generare l\u0026rsquo;immagine, se questo succede, allora ho finito perchÃ© ho praticamente scomposto la base di V, in una per Ker(F), e una altra per Im L. Dimostro che effettivamente quanto preso Ã¨ una base di Im F cercata, utilizzando la linearitÃ  dell\u0026rsquo;applicazione, e il fatto che l\u0026rsquo;insieme di vettori iniziale era base per V Dimostrazione\n3.4.1 Verifica iniettivitÃ  Mi puÃ² dare in modo quasi immediato nozioni di iniettivitÃ  e suriettivitÃ , se l\u0026rsquo;applicazione lineare ha la dimensione di kernel = 0 allora scopro subito che Ã¨ iniettiva!\nSiano dati due spazi vettoriali tali che $\\dim V \u003e \\dim W$ allora non ho cose iniettive.\nPerchÃ© supponiamo che ci sia tale applicazione lineare, ma al massimo l\u0026rsquo;immagine Ã¨ di dimensione W, quindi la dimensione del Kernel non Ã¨ nulla, per cui ho che non Ã¨ iniettivo per il teorema in link\n3.4.2 Verifica suriettivitÃ  Se la dimensione dell\u0026rsquo;immagine ha la stessa dimensione del codominio, allora ho trovato subito un una base per il codominio! Quindi so subito che Ã¨ suriettiva.\nIn modo simile se ho due spazi vettoriali tali per cui $\\dim V \u003c \\dim W$ allora non ho funzioni suriettive perchÃ© la dimensione di arrivo Ã¨ al massimo V.\n3.5 Isomorfismi 3.5.1 Definizione Ãˆ una applicazione lineare bigettiva\nSI puÃ² dimostrare che se V ha dimensione n, allora Ã¨ isomorfo con $\\R^n$\n3.5.2 Equivalenza delle dimensioni per ISO (!! chiede) Sse due spazi vettoriali sono isomorfi allora hanno la stessa dimensione.\nDimostrazione\n$\\implies$ In quanto Ã¨ un isomorfismo si ha che Ã¨ iniettiva e suriettiva, quindi\ndim V = 0 + dim W quindi hanno la stessa dimensione.\n$\\impliedby$Suppongo che le dimensioni siano le stesse, vogliamo dimostrare che i due insiemi siano isomorfi.\nDate le rispettive basi di V e W, vogliamo costruirci un isomorfismo:\nMi costruisco la funzione e dimostro che Ã¨ suriettiva perchÃ© voglio mandare il vettore base 1 di V al vettore base 1 di W, cosÃ¬ a corrispondere fino alla dimensione Poi uso il teorema delle dimensioni per concludere che la dimensione del nucleo Ã¨ 0, per cui Ã¨ iniettiva. 4 Registro ripassi 09/04 Ti ricordi 0 riguardo alla dimostrazione del teorema della dimensione, ma per il resto Ã¨ ok. 19/04 Tutto ok ï¿½ iniettiva. 4 Registro ripassi 09/04 Ti ricordi 0 riguardo alla dimostrazione del teorema della dimensione, ma per il resto Ã¨ ok. 19/04 Tutto ok ","permalink":"https://flecart.github.io/notes/applicazioni-lineari/","summary":"Ripasso Prox: 27 Ripasso: June 2, 2022 Ultima modifica: January 4, 2023 9:54 AM Primo Abbozzo: March 22, 2022 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 3 Applicazioni lineari 3.1 Introduzione e definizione Si definisce applicazione lineare una funzione (omomorfica) che preserva la struttura dello spazio vettoriale, ossia vale che\n$$ f:V \\to W, tale che \\\\ f(u + v) = f(u) +f(v)\\\\ f(\\lambda v) = \\lambda f(v) $$ 3.","title":"Applicazioni lineari"},{"content":"Ripasso Prox: 70 Ripasso: June 7, 2023 Ultima modifica: June 4, 2023 4:06 PM Primo Abbozzo: October 14, 2022 2:19 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Domande\nAutomi e Regexp Per lâ€™analisi lessicale vogliamo cercare di ricordare le parole legali all\u0026rsquo;interno di questo linguaggio e questo Ã¨ fatto con i linguaggi regolari.\nIntroduzione a analizzatori lessicali Token ðŸŸ© Struttura del token Ã¨ fatto da due parti\nIdentificatore della classe del token Identificatore del valore del token Pattern e lessema ci sono direi boh Pattern e Lessema ðŸŸ© I pattern sono una descrizione generale della forma dei valori di una classe di token.\nLessema Ã¨ una istanza di un particolare pattern\nEsempio di scan\nDi solito viene storato come puntatore alla tabella dei simboli\nEspressioni regolari Definizione ðŸŸ© Slide definizione espressioni regolari\nDisambiguazione della grammatica\nEsempio espressione regolare\nLinguaggio generato da regexp ðŸŸ© Per capire questa parte Ã¨ importante avere in mente le operazioni sui linguaggio definiti in Descrizione linguaggio\nSlide\nLinguaggio regolare ðŸŸ© Definizione linguaggio regolare\nOgni linguaggio finito Ã¨ un linguaggio regolare questo Ã¨ una proposizione che lega fortemente i linguaggi (utilizzati poi veramente per l\u0026rsquo;implementazione) (basta fare lâ€™unione!)\nEsempio linguaggio finito generato da linguaggio regolare\nEsempi di espressioni regolari infiniti\nOltre ai classici operatori definiti in precedena per questa sezione aggiungiamo\nRipetizione-positiva, PossibilitÃ , Elenco\nDefinizioni regolari ðŸŸ©- Le definizioni regolari ci aiutano a creare una struttura del token di cui dobbiamo fare lo scanning.\nIn pratica andiamo a creare delle definizioni che rendono piÃ¹ facile la descrizione di un pattern con regexp.\nSlide\nEsempi\nEquivalenza regexp ðŸŸ© Esempi di equivalenze\nQueste equivalenze non sono sempre facili da dimostrare\nAutomi In questa parte si fa una descrizione molto generale di cosa siano gli automi.\nCaratteristiche (3) ðŸŸ© Slide\nMemoria finita (dato da un numero di stati) Input una stringa da riconoscere Output Ã¨ solamente un singolo bit (si oppure no) Descrizione e funzionamento ðŸŸ© Slide\nDescrizione\nTestina sul primo carattere in input. Su stato q0 Funzionamento\nIl funzionamento dell\u0026rsquo;automa Ã¨ molto semplice, esegue un semplice algoritmo:\nLeggi il carattere attuale, se esiste una transizione etichettata con quanto letto spostati secondo la regola di quel carattere. Dopo aver finito di leggere la stringa, se Ã¨ in uno stato buono restituisci 1, altrimenti 0 Se Ã¨ bloccato in uno stato ritorna 0 Diagrammi di transizione ðŸŸ© I diagrammi di transizione sono utili per definire in modo grafico cosa fa l\u0026rsquo;espressione regolare\nSlide\nAutomi finiti non deterministici (NFA) Definizione (5) ðŸŸ© Slide\nPossiamo definire gli automi non deterministici come una quintupla di\n$$ (\\Sigma, Q, q_0 \\in Q, F \\subseteq Q, \\delta) \\\\ \\delta : Q \\times (\\Sigma \\cup \\varepsilon) \\to P(Q) $$ Albeto dei simboli di input Stati possibili Stato iniziale Stati finali (accettati) Funzioni di transizione, che ha come codominio l\u0026rsquo;insieme delle parti di Q Alla fine, per scopi didattici si utilizza sempre il diagramma di transizione. La differenza principale con gli automi a stati finiti Ã¨ che posso avere lo stesso label di transizione per singolo stato\nCaratteristiche (2) ðŸŸ© Facili da realizzare (esiste quasi una bigezione credo fra NDA ed espressione regolare) Inefficienti (backtracking, e fallibile), principalmente causato dal suo non determinismo Stato finale accettato ðŸŸ© â€” Slide\nQuesto Ã¨ una slide molto importante per definire il concetto di stringa accettata/riconosciuta. Praticamente posso affermare che una stringa Ã¨ riconosciuto da questo automa finito non-deterinistico se anche un solo cammino da q0 a un qualunque stato accettato.\nOltre questo voglio andare a definire in modo formale il concetto di mossa, o cammino in un diagramma di rappresentazione per un automa finito.\nDescrizione istantanea, mossa, cammino, stringa accettata\nIndico che uno stato $q$ Ã¨ raggiungibile da uno stato $s$, con il simbolo $\\vdash$, ossia $s \\vdash v$, questo Ã¨ possibile solo se sto leggendo una stringa che ha come relazione una stringa buona, ma questo pezzo Ã¨ piÃ¹ chiaro negli appunti quindi ti invito di leggere dalÃ¬ con la rappresentazione logica classica.\nLa chiusura riflessiva e transitiva di questo concetto di mossa Ã¨ indicata con $\\vdash ^*_N$, N Ã¨ il nome di questo automa, dovrebbe essere ancora sopra.\nTODO: da definire bene cosa sia la mossa e il cammino!\nLinguaggio riconosciuto da NDA e equivalenza ðŸŸ© Slide\n$$ L[N] = \\{ w \\in \\Sigma^* | \\exists q \\in F, (q_0, w) \\vdash ^*_N (q , \\varepsilon)\\} $$ La parte di sopra Ã¨ la definizione di un linguaggio riconosciuto da un automa, Ã¨ un modo molto compatto per esprire l\u0026rsquo;esistenza di un cammino come sopra.\nInoltre possiamo definire il concetto di equivalenza fra NDA che Ã¨ quando il linguaggio riconosciuto Ã¨ esattamente lo stesso.\nDefinizione di linguaggio riconosciuto con e-closure ðŸŸ¨+ Linguaggio riconosciuto, scritto in modo piÃ¹ elegante, con epsilon closure\nCon la definizione di delta cappuccio possiamo definire che un linguaggio in questo modo:\n$$ w \\in L[N] \\iff \\exists p \\in F : p \\in \\hat{\\delta}(q_0, w) $$ NFA da espressioni regolari (!!!) (duplicato) ðŸŸ© Questo Ã¨ un teorema molto importante per rappresentare una sorta di equivalenza fra linguaggi regolari e NFA.\nEnunciato\nHint dimostrazione\nInduzione strutturale sulla sintassi BNF delle espressioni regolari, andremo a dimostrare che posso comporre NFA che alla fine riescono a riconoscere il linguaggio regolare\nConsigli di studio\nImpararsi i metodi di conversione di ogni parte della sintassi in NFA, poi li componi come dei lego e sei apposto\nDimostrazione\nAutomi finiti deterministici (DFA) Definizione ðŸŸ© Slide\nDifferenze rispetto NDA\nPrincipalmente la definizione Ã¨ uguale agli automi non deterministici lâ€™unica cosa che cambia Ã¨ il delta che ora Ã¨ definito come\n$$ \\delta: Q \\times \\Sigma \\to Q $$ Non câ€™Ã¨ piÃ¹ lâ€™insieme delle parti, magari dopo vediamo come questi automi sono equivalenti, ma câ€™Ã¨ una esplosione esponenziale al momento di conversione da deterministico a non deterministico.\nAlgoritmo creazione DFA da NFA ðŸŸ© Lâ€™algoritmo di creazione\nEsempio di utilizzo dell\u0026rsquo;algoritmo (lezione 6)\ncon $F$ lâ€™insieme degli stati finali della NFA.\nDFA equivalente a NFA (non chiede) ðŸŸ¨ Dimostrazione both, e osservazioni in modo informale\nSlide â†’\nQuesta proposizione si puÃ² vedere dalla definizione\nSlide â†\nC\u0026rsquo;Ã¨ veramente in questo passo una esplosione esponenziale perchÃ© il numero degli stati diventa esponenzialmente tanto.\nDimostrazione, induzione, molto formale.\nEsempio di conversione\nepsilon-closure ðŸŸ© Slide\nAlgoritmo per epsilon-closure\nQuesto concetto di chiusura Epsilon ci racchiude il concetto degli stati raggiungibili in un NFA senza leggere nessun input.\n","permalink":"https://flecart.github.io/notes/automi-e-regexp/","summary":"Ripasso Prox: 70 Ripasso: June 7, 2023 Ultima modifica: June 4, 2023 4:06 PM Primo Abbozzo: October 14, 2022 2:19 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Domande\nAutomi e Regexp Per lâ€™analisi lessicale vogliamo cercare di ricordare le parole legali all\u0026rsquo;interno di questo linguaggio e questo Ã¨ fatto con i linguaggi regolari.\nIntroduzione a analizzatori lessicali Token ðŸŸ© Struttura del token Ã¨ fatto da due parti\nIdentificatore della classe del token Identificatore del valore del token Pattern e lessema ci sono direi boh Pattern e Lessema ðŸŸ© I pattern sono una descrizione generale della forma dei valori di una classe di token.","title":"Automi e Regexp"},{"content":"Ultima modifica: October 17, 2021 10:38 AM Primo Abbozzo: October 16, 2021 5:16 PM Studi Personali: No\nElementi di ripasso 1 Cammini 1.1 Il cammino minimo 1.1.1 Definizione e caratteristiche 1.1.2 Costi negativi Sono cose molto brutte\n1.1.3 Cammino minimo semplice Costruzione di cammini minimi 1.2 Vertici 1.2.1 definizione distanza fra due vertici Costo del cammino minimo che li connette\nCondizione di bellman Albero dei cammini minimi Rilassamento Definizione Si va a vedere dove non funziona la disuguaglianza triangolare, se localmente non funziona ovvero se per esempio succede $D_{xu} + \\omega(u,y) \u003c D_{xy}$ per qualche vertice all\u0026rsquo;interno del grafo, so di per certo che la distanza $D_{xy}$ non Ã¨ una distanza, quindi possiamo riassegnarla in modo che verifichi la disuguaglianza\nBellman ford Questo algoritmo parte definendo tutti i vertici a distanza infinita, riassegna i valori partendo da un vertice prefissato.\nQuesto ragionamento Ã¨ solamente possibile con l\u0026rsquo;osservazione che il cammino Ã¨ minimo se tutti i suoi sottocammini lo sono, quindi mi sto costruendo cammini minimi da zero.\nSto riassegnando valore a tutti gli archi piano piano\u0026hellip;\nRilassamento topologico Bellman-ford con ordinamento Permette di non ripetere l\u0026rsquo;ordinamento di n vertici\nGrafi Aciclici Ordinamento topologico Dijkstra Lemma sull\u0026rsquo;espansione del grafo di esplorazione ordinamento\nPermette di non ripetere l\u0026rsquo;ordinamento di n vertici\nGrafi Aciclici Ordinamento topologico Dijkstra Lemma sull\u0026rsquo;espansione del grafo di esplorazione\n","permalink":"https://flecart.github.io/notes/cammini/","summary":"Ultima modifica: October 17, 2021 10:38 AM Primo Abbozzo: October 16, 2021 5:16 PM Studi Personali: No\nElementi di ripasso 1 Cammini 1.1 Il cammino minimo 1.1.1 Definizione e caratteristiche 1.1.2 Costi negativi Sono cose molto brutte\n1.1.3 Cammino minimo semplice Costruzione di cammini minimi 1.2 Vertici 1.2.1 definizione distanza fra due vertici Costo del cammino minimo che li connette\nCondizione di bellman Albero dei cammini minimi Rilassamento Definizione Si va a vedere dove non funziona la disuguaglianza triangolare, se localmente non funziona ovvero se per esempio succede $D_{xu} + \\omega(u,y) \u003c D_{xy}$ per qualche vertice all\u0026rsquo;interno del grafo, so di per certo che la distanza $D_{xy}$ non Ã¨ una distanza, quindi possiamo riassegnarla in modo che verifichi la disuguaglianza","title":"Cammini"},{"content":"Indexes Trattiamo qui di alcuni metodi che sono utilizzati per costruire indici\nIntroduction to indexes Gli indici sono una struttura di dati aggiuntiva che ci permette di ricercare piÃ¹ in fretta alcuni valori per le queries. In questa sezione proviamo ad approfondire in che modo possono essere costruite e gestite.\nSearch keys ðŸŸ© Sono in breve la cosa che vogliamo andare a cercare. Solitamente sono nella forma \u0026lt;key, label\u0026gt;, che ci permette di trovare in fretta il label, che si potrebbe intendere come il valore che noi stiamo provando a cercare.\nLabels and record identifiers (3) ðŸŸ© Primary vs secondary indexes Ãˆ primary se gli attributi che vengono guardati contengono la chiave primaria della relazione Altrimenti Ã¨ secondary Dense vs sparse indexes ðŸŸ© Dense se per ogni chiave del file esiste una chiave di ricerca. Altrimenti Ã¨ sparsa. Chiaramente per index sparsi abbiamo bisogno di meno spazio per storarli in memoria!\nClustered vs unclustered indexes ðŸŸ©\u0026ndash; Clustered se viene utilizzato l\u0026rsquo;ordine dei labels (eh, non ho capito questo criterio credo.)\nChiaramente se Ã¨ unclustered non abbiamo piÃ¹ i vantaggi della cache, e quindi Ã¨ piÃ¹ lento accedere!\nSequential Index example In pratica dividiamo il file in molti pezzi contigui, e proviamo ad indexarli in modo contiguo, come in figura: Questo metodo Ã¨ denso e clustered per fare indexing, mentre per il fatto che sia primario o meno dipende!?\nB-trees Abbiamo circa 40ms per l\u0026rsquo;accesso al blocco, solitamente di tipo 4k bytes. La osservazione principale Ã¨ che gli algoritmi non lavorano piÃ¹ in RAM, che Ã¨ facile accedere subito (nanosecondi ad accedere), quindi Ã¨ piÃ¹ facile fare algoritmi che tengano in conto questa cosa.. La base di dati ha bisogno di indici, perchÃ© in questo modo utilizzo permette il miglior accesso\nun index Ã¨ interamente di grandezza del blocco. Dipendente da chiavi valori. Un indice un singolo blocco diciamo (quindi abbiamo centinaia di archi) (il costo Ã¨ $\\log_{n}(N)$) con $n$ il branching factor. Con pochi livelli, posso accedere a molte cose! (quindi faccio pochi seek per raggiungere i valori). Indici Sono delle coppie chiavi valori con cui si vanno a cercare\nTipologie di indici (3) B-trees Nodi interi e nodi foglia Abbiamo che Ã¨ un albero con piÃ¹ rami, solitamente largo per non necessitare di piÃ¹ letture per andare a leggere (ricorda che ram Ã¨ circa un milione di volte piÃ¹ veloce!). Praticamente\nInsertion and deletion Quando ho trovato il nodo in cui inserire, e trovando che il nodo Ã¨ pieno, dovrei provare a spezzare, e creare un nuovo nodo genitore e c\u0026rsquo;Ã¨ lo stesso il processo ricorsivo anche sul genitore, se non c\u0026rsquo;Ã¨ spazio continuo a dividere (anche la radice si puÃ² splittare). Vedi slide 30 Lab06 Per la deletion la slide Ã¨ 39.\nC\u0026rsquo;Ã¨ un fattore di riempimento che si dovrebbe andare a considerare, per capire se posso fondere piÃ¹ nodi assieme, in modo che non debbano prendere troppo spazio.\nCome in immagine:\nL\u0026rsquo;algoritmo Ã¨ molto chiaro se visto con le immagini e gli steps, poi in questa occasione non ci interessa analizzarlo.\nNotare: questa Ã¨ una implementazione un po\u0026rsquo; meno efficiente perchÃ© i valori effettivi possono essere presenti solamente sulle foglie, sarebbe piÃ¹ efficiente se si vede che in un nodo intermedio il valore esiste allora esisterÃ  anche sulle foglie per cui si puÃ² giÃ  restituire il risultato. Questo applicativo ha una versione piÃ¹ efficiente: https://www.cs.usfca.edu/~galles/visualization/BTree.html.\nHashes Gli hash sono utili per la ricerca di chiavi uguali tipo per indici oppure per database piccoli (credo) che non hanno bisogno di b-trees.\nStatic Hash ðŸŸ© Per questa tipologia di hash allochiamo uno spazio fisso non estensibile. Data una certa chiave di ricerca, andiamo a prendere il bucket con quel valore. Se Ã¨ giÃ  pieno si possono usare linked list o alberi per memorizzare il valore.\nAnche in questo caso, come per i B-trees, si invita a guardare le slides, oppure disegnare per una comprensione migliore dell\u0026rsquo;argomento.\nExtensive hash ðŸŸ¨+ Elementi di rielievo:\nOgni singolo blocco ha un contatore che indica il numero di bits utilizzati per indexarlo. Abbiamo un blocco intermedio di puntatori che vanno sui singolo blocchi di dati, contiene anche un dato che indica numero di bits per indexare il singolo bucket. L\u0026rsquo;algoritmo di insertion Ã¨ un po\u0026rsquo; piÃ¹ complicato, e differenzia caso in cui il numero di bit per indexare il blocco sia uguale o minore rispetto a quello per i bucket. Anche in questo caso dovresti descrivere l\u0026rsquo;esecuzione dell\u0026rsquo;algoritmo con immagini, aiuta molto.\nL\u0026rsquo;unica cosa negativa Ã¨ il fatto di crescere in modo esponenziale per lo spazio nelle directories in casi proprio avversariali (o comunque molto difficili con una distribuzione normale diciamo).\nLinear Hash In questo caso cresce un blocco alla volta, finchÃ© un certo threshold di record/numbero di buckets viene soddisfatto si resta, altrimenti prova a crescere. Anche in questo caso come static hash, usiamo gli overflow blocks.\nInverted indexes introduzione sul funzionamento Per gestire cose come testo a volte puÃ² risultare utile fare questo genere di index per trovarlo. In pratica, supponiamo di avere n indici, allora possiamo fare una tabella nella forma\nParola -\u0026gt; Doc(posizione) In pratica matcho ogni singola parola con il documento e la posizione all\u0026rsquo;interno del documento che la parola ha, in questo modo posso fare ricerca veloce nelle posizioni in cui la parola compare.\nQuando cerco una stringa esatta posso prendere l\u0026rsquo;intersezione fra i documenti in cui compaiono e restituire solamente quelle\nLinguistic preprocessing Sono metodi per diminuire la verietÃ  delle parole in modo che io abbia bisogno di meno spazio poi per memorizzare l\u0026rsquo;inverted index. Posso fare cose come\nStemming: in cui rimuovo lo stemdella parole, quindi suffissi o prefissi ricorrenti Normalization: ad esempio metto tutto minuscolo. Rimozione stop worlds: perchÃ© sono inutili chÃ© non danno molte informazioni\n","permalink":"https://flecart.github.io/notes/index-b-trees-and-hashes/","summary":"Indexes Trattiamo qui di alcuni metodi che sono utilizzati per costruire indici\nIntroduction to indexes Gli indici sono una struttura di dati aggiuntiva che ci permette di ricercare piÃ¹ in fretta alcuni valori per le queries. In questa sezione proviamo ad approfondire in che modo possono essere costruite e gestite.\nSearch keys ðŸŸ© Sono in breve la cosa che vogliamo andare a cercare. Solitamente sono nella forma \u0026lt;key, label\u0026gt;, che ci permette di trovare in fretta il label, che si potrebbe intendere come il valore che noi stiamo provando a cercare.","title":"Index, B-trees and hashes"},{"content":"Ripasso Prox: 30 Ripasso: December 19, 2021 Ultima modifica: December 14, 2021 3:43 PM Primo Abbozzo: September 22, 2021 11:25 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi da ripassare Processo che porta dal design alla creazione del programma 0 Basi 0.1 Struttura di un calcolatore Input: tastiera, mouse. Output: Schermo, suoni etc Memoria principale e secondaria CPU 0.2 Struttura della memoria Cerca di ricordare di come una informazione Ã¨ messa in memoria e come Ã¨ interpretata, come presentato in\nIntroduzione ad architettura. riguardo il processo FDE.\n0.3 Compilatori e Linker Sapere lo scopo dei compilatori e linker, quindi comprendere il ruolo della CPU, del motivo della necessitÃ  della compilazione e linker\n0.4 Risoluzione di un problema Il processo di risoluzione del problema deve essere diviso in due fasi principali:\nLa fase di design astratta del problema\nLa fase di implementazione con un linguaggio reale del problema.\n0.4.1 Tipologie di errori di programma Ci sono principalmente tre tipologie di errore:\nErrori sintattici come la mancanza di virgolette, di ; missnaming variable e simili Errori run-time come la mancanza di risorse, la divisione per 0 credo Errori logici come algoritmo implementato Ã¨ insufficiente per le proprie necessitÃ  e simili. 0.4.2 Design: Diagrammi di flusso Ãˆ piÃ¹ veloce (salva errori logici, quelli difficili da debuggare) creare prima un design testato dell\u0026rsquo;algoritmo che si va ad implementare. Per farlo di solito ricorrono a diagrammi di flusso per crearsi questo design. logici, quelli difficili da debuggare) creare prima un design testato dell\u0026rsquo;algoritmo che si va ad implementare. Per farlo di solito ricorrono a diagrammi di flusso per crearsi questo design.\n","permalink":"https://flecart.github.io/notes/introduzione-a-programmazione/","summary":"Ripasso Prox: 30 Ripasso: December 19, 2021 Ultima modifica: December 14, 2021 3:43 PM Primo Abbozzo: September 22, 2021 11:25 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi da ripassare Processo che porta dal design alla creazione del programma 0 Basi 0.1 Struttura di un calcolatore Input: tastiera, mouse. Output: Schermo, suoni etc Memoria principale e secondaria CPU 0.2 Struttura della memoria Cerca di ricordare di come una informazione Ã¨ messa in memoria e come Ã¨ interpretata, come presentato in","title":"Introduzione a programmazione"},{"content":"Ripasso Prox: 30 Ripasso: December 24, 2022 Ultima modifica: January 9, 2023 3:28 PM Primo Abbozzo: September 28, 2022 4:34 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nErrore inerente Bisogna cercare di generalizzare il concetto di errore e lo si fa con la norma\nNorma vettoriale Ãˆ una funzione da $f: \\mathbb{R}^n \\to \\mathbb{R}$ indicata con due barrette, questa funzione mi dÃ  un concetto di distanza.\nProprietÃ  della norma Si definisce una norma una funzione che soddisfa queste proprietÃ \n$\\lVert x \\rVert \\geq 0$ per ogni $x \\in \\mathbb{R}^{n}$ $\\lVert x \\rVert = 0 \\iff x = 0$ $\\lVert \\alpha x \\rVert = \\lvert \\alpha \\rvert \\lVert x \\rVert$ per ogni $x \\in \\mathbb{R}^{n}$ e $\\alpha \\in \\mathbb{R}$ Vale la disuguaglianza triangolare, ossia $\\forall x, y \\in \\mathbb{R}^{n}, \\lVert x + y \\rVert \\leq \\lVert x \\rVert + \\lVert y \\rVert$. Norma p ðŸŸ©- $$ (\\sum_{i = 1}^{n}|x_i|^p)^{1/p} $$ Nel caso in cui $p = 2$ si chiama norma euclidea o viva\nNel caso $p = 1$ Ã¨ la distanza di manhattan\nNorma di chebichev ðŸŸ¨ quando ho $p = +\\infty$ Ã¨ definita come $\\max_{1\\leq i \\leq n} |x_i|$ e si indica con $||x||_\\infty$\nEquivalenza fra le norme ðŸŸ© Questo Ã¨ un teorema che ci permette di asserire che piÃ¹ o meno tutte le norme hanno la stessa proprietÃ  di definire il concetto di distanza fra due punti poichÃ©\nSiano $||\\cdot||, ||\\cdot||_x$ due norme differenti, allora $\\exists m, M : m ||\\cdot|| \\leq || \\cdot || _x \\leq M||\\cdot ||$, ma questo vale solo se siamo in un campo finito.\nNorma matriciale ProprietÃ  ðŸŸ© Vogliamo riprendere tutte le propreitÃ  descritte per la norma vettoriale, in piÃ¹ vogliamo andare ad aggiungere un quinto punto ossia\nNorma naturale (o indotte) ðŸŸ¨â€” $$ ||A|| = \\sup_{x \\neq 0} \\dfrac{||Ax||}{||x||} = ||Ay||, y = \\dfrac{x}{||x||} $$ Considero solamente le righe, come se compattassi tutte le colonne in una\n$$ ||A||_\\infty = \\max_{1 \\leq i \\leq m} \\sum_{j = 1}^n|a_{ij}| $$ La norma-1 indotta Ã¨ molto simile, solo che ora compatto sulle colonne\n$$ ||A||_1 = \\max_{j} \\sum_{i = 1}^n|a_{ij}| $$ Norma 2, o norma spettrale:\n$$ ||A||_2 = \\sqrt{\\Lambda(A^TA)} $$ Con $A^TA$ simmetrica e semidefinita positiva. con $\\Lambda$ gli autovalori di $A^TA$\nSe $A$ ha rango massimo allora Ã¨ definita positiva, che Ã¨ il rango qui?\nLe norme dellâ€™identitÃ  in tutte queste cose indotte Ã¨ 1\nNorma di frobenius $$ ||A||_ F = \\sqrt{\\sum_{i = 1}^m \\sum_{j = 1}^n a^2_{ij}} $$ $||I||_F = \\sqrt{n}$\nSlide relazione fra le norme matriciali\nCondizionamento Vogliamo andare a definire il concetto di condizionamento per il sistema lineare.\nOssia vorremmo valutare quanto un piccolo cambiamento della matrice influisca sul risultato finale.\nSlide esempio condizionamento\nChiamiamo come errore inerente la distanza fra il risultato vero e il risultato perturbato. Questo errore dipende fortemente da una natura dei dati in input (che sono mal condizionati)\nMal condizionamento ðŸŸ© si verifica quando a piccoli cambi della matrice di partenza, si ha un grande errore nel risultato (potremmo dire ordini di grandezza diversi, solitamente questo Ã¨ una cosa che non vorremmo che ci fosse)\nE la differenza fra i risultati Ã¨ un errore inerente, che dipende dai dati, ma non dallâ€™algoritmo\nPerturbazione e n-condizionamento ðŸŸ© Vogliamo ora vedere quanto siano grandi gli effetti di una perturbazione su una matrice. si puÃ² dimostrare che\n$$ \\dfrac{||\\Delta x||}{||x||} \\leq k(A) \\dfrac{||\\Delta A|| }{||A||} $$ Con $k(A)$ il numero di condizione della matrice, solamente piÃ¹ Ã¨ grande piÃ¹ l\u0026rsquo;errore viene amplificato., se questo valore Ã¨ sempre maggiore o uguale a 1 Ã¨ non singolare.\n$$ k(A) = ||A||\\cdot||A^{-1}|| \\geq ||AA^{-1}|| = ||I|| = 1 $$ Slide ricavo relazioni condizionamento\n","permalink":"https://flecart.github.io/notes/norme-e-condizionamento/","summary":"Ripasso Prox: 30 Ripasso: December 24, 2022 Ultima modifica: January 9, 2023 3:28 PM Primo Abbozzo: September 28, 2022 4:34 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nErrore inerente Bisogna cercare di generalizzare il concetto di errore e lo si fa con la norma\nNorma vettoriale Ãˆ una funzione da $f: \\mathbb{R}^n \\to \\mathbb{R}$ indicata con due barrette, questa funzione mi dÃ  un concetto di distanza.\nProprietÃ  della norma Si definisce una norma una funzione che soddisfa queste proprietÃ ","title":"Norme e Condizionamento"},{"content":"Ripasso Prox: 40 Ripasso: May 31, 2023 Ultima modifica: May 3, 2023 8:04 AM Primo Abbozzo: February 28, 2023 12:24 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso ProbabilitÃ  condizionata e indipendente Condizionata Definizione ðŸŸ© Andiamo a definire una probabilitÃ  di un evento $A$, condizionata a un evento non nullo $B$, come\n$$ P(A|B) = \\dfrac{P(A\\cap B)}{P(B)} $$ Questo Ã¨ la cosa fondamentale per poter considerare cose come bayes perchÃ© in questo modo abbiamo una certa relazione fra causa ed effetto e anche il contrario! Cosa che ci piace molto molto molto.\nLa definizione di sopra Ã¨ un probabilitÃ  ðŸŸ© Dimostrazione mia\ninanzitutto vediamo che soddisfatta il fatto che $P(A) \\in [0, 1]$, poi possiamo notare che\n$$ P(\\Omega | B) = \\dfrac{P(\\Omega\\cap B)}{P(B)} = P(B) / P(B) = 1 $$ $$ P(\\bigcup A_n | B) = \\dfrac{P(\\bigcup A_i\\cap B)}{P(B)} = \\dfrac{P(\\bigcup (A_i\\cap B))}{P(B)} = \\sum_{i = 1} ^\\infty\\dfrac{P(A_i\\cap B)}{P(B)} $$ Quindi ecco che Ã¨ una probabilitÃ  su Omega!\nLâ€™ultima disuguaglianza vale perchÃ© sto facendo unione di insiemi disgiunti. (che sono disgiunti per ipotesi.\nRegola della catena ðŸŸ© Dimostrazione in libro\nQuesta Ã¨ uno delle proprietÃ  piÃ¹ importanti che abbiamo per la probabilitÃ  Ã¨ molto interessante notare come basta una induzione cosÃ¬ semplice per fare questo\nFormula di disintegrazione o delle probabilitÃ  totali ðŸŸ© Dimostrazione\nQuesto non Ã¨ tanto difficile da dimostrare, bisogna notare che\n$$ B = \\bigcup_i (B \\cap A_i) $$ il che Ã¨ vero perchÃ© $\\forall i, j A_i \\cap A_j = \\empty, \\bigcup A_i = \\Omega$ per ipotesi, e quindi sto facendo una unione disgiunta, si ha per $\\sigma-$additivitÃ  la prima tesi, mentre la seconda tesi Ã¨ derivante dalla definizione di probabiltiÃ  condizionate\nIndipendenza d\u0026rsquo;eventi Introduzione Lâ€™intuizione di maggior rilievo Ã¨ il fatto che non ho nuove informazioni se Ã¨ successo B ossia deve valere che $P(A|B) = P(A)$, oppure che $P(B|A) = P(B)$, dato che vale per entrambi, Ã¨ una proprietÃ  simmetrica.\nha quindi senso andare a definire che due eventi siano indipendenti se vale questa proprietÃ :\n$$ P(A \\cap B) = P(A)P(B) $$ Ãˆ molto importante notare che l\u0026rsquo;indipendenza di a due a due due eventi non implica l\u0026rsquo;indipendenza di 3! (guardare l\u0026rsquo;esempio sul libro)\nEsempio fatto in classe di questo\nSe ho un evento composto da due lanci un dado a 6 faccie, se considero gli eventi:\nAl primo lancio esce un numero dispari Al secondo un numero pari La somma dei due lanci Ã¨ pari. Si puÃ² notare che insieme tutti non possono avvenire, ma se li prendo a due a due sono indipendenti, questo Ã¨ molto curioso come fenomeno!\nInfatti deve essere che valga la proprietÃ  di sopra per ogni singolo sottoinsieme. Ãˆ una cosa molto importante!\nCaso speciale\nNel caso in cui $P(A) = 0$ , oppure vale lâ€™altro, oppure basta che siano $P(A \\cap B) = 0$ ossia siano disgiunti allora secondo la definizione sono indipendenti, anche se logicamente dovrebbero essere dipendenti, dato che uno implica l\u0026rsquo;esclusione dellâ€™altro.\nTh Indipendenza e complementari ðŸŸ¨ Dimostrazione\nDubbio vecchio\nLa dimostrazione Ã¨ un po`strana, per quale motivo per (ii) â†’ (i) Ã¨ necessario utilizzare l\u0026rsquo;induzione? PerchÃ© voglio dimostrarlo per ogni modo in cui posso scegliere un sottoinsieme! Ãˆ molto interessante come con il secondo riesco a dimostrare il tutto.\nRisposta:\nhai capito male la definizione di indipendenza, affinchÃ© sia indipendente, deve essere che lo siano tutti i sottoinsiemi di eventi! Quindi ciÃ² rende la dimostrazioen molto piÃ¹ contorta.\n","permalink":"https://flecart.github.io/notes/probabilita-condizionata-e-indipendenza/","summary":"Ripasso Prox: 40 Ripasso: May 31, 2023 Ultima modifica: May 3, 2023 8:04 AM Primo Abbozzo: February 28, 2023 12:24 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso ProbabilitÃ  condizionata e indipendente Condizionata Definizione ðŸŸ© Andiamo a definire una probabilitÃ  di un evento $A$, condizionata a un evento non nullo $B$, come\n$$ P(A|B) = \\dfrac{P(A\\cap B)}{P(B)} $$ Questo Ã¨ la cosa fondamentale per poter considerare cose come bayes perchÃ© in questo modo abbiamo una certa relazione fra causa ed effetto e anche il contrario!","title":"Probabilita condizionata e indipendenza"},{"content":"Ripasso Prox: 33 Ripasso: June 9, 2023 Ultima modifica: May 10, 2023 9:41 AM Primo Abbozzo: March 8, 2023 10:18 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Scheduler Il suo scopo principale Ã¨ gestire l\u0026rsquo;avvicendamento dei processi. Ad esempio sospendere il processo che chiede I/O. O un sistema time sharing, quando arriva un interrupt sul time.\nSolitamente il nome scheduler Ã¨ solamente un gestore dell\u0026rsquo;avvicendamento, si puÃ² quindi utilizzare per indicare scheduler di altro tipo.\nNote introduttive Diagramma di Gantt Questo Ã¨ il diagramma per presentare lo scheduling, ossia da quando a quando Ã¨ eseguito cosa\nEsempio gantt\nMode switch (link) ðŸŸ© il mode switch Ã¨ il passaggio fra user e kernel e viceversa, di cui abbiamo parlato in Note sullâ€™architettura. si continua con lo stesso processo con permessi maggiori.\nContext switch (4) ðŸŸ© Context switch invece si passa da un processo allâ€™altro, e bisogna salvare lo stato del vecchio processo nel PCB, come descritto in Processi e thread.\nEsempio context switch\nServe un mode switch, fanno cose, un altro mode switch, e stessa sequenza per tornare indietro, sono 2 context swithc qui\nCause del context switch\nSlide descrizione delle cause\nNota che per certe cause Ã¨ necessario fare un context switch in altri casi no.\nVita di un processo ðŸŸ© Si parla di tutti i passaggi fra int\nSistema attesa e interrupt\nPraticamente il processo continua a runnare finchÃ© non lo fermano, con una syscall, con un interrupt di time slice oppure quando fa una syscall bloccante.\nQuando Ã¨ pronto a riprendere viene rimessa nella coda ready, e questa sarÃ  la coda gestita dallo scheduler.\nCatalogazione scheduler Preemptive e non-preemptive ðŸŸ© Slide descrizione preempty non preemptive\nNon-preemptive Ã¨ quando cambio processo solamente se cedo io, processo, il controllo.\nMentre preemptive Ã¨ quando posso cambiare in ogni singolo caso.\nVantaggi dello scheduling cooperativo non richiede alcuni meccanismi hardware come ad esempio timer programmabili Potevi monopolizzare la CPU se programmavi male. Vantaggi dello scheduling preemptive permette di utilizzare al meglio le risorse per questo motivo gli scheduler sono sempre preemptive ora. Le risorse considerate (2) ðŸŸ© Vogliamo ora trovare un modo per decidere in che modo decidere quale processo far partire e quale no.\nSlide scelta dello scheduler\nSistemi batch\nUtilizzo della risorsa CPU, vorremmo che la CPU stia sempre a lavorare. Massimizzare il numero di processi completati, ossia massimizzare il throughput, se ci mette poco lo faccio. Turnaround time, ossia minimizzare il tempo di risposta, da quando il processo Ã¨ sottomesso (issued) a quando Ã¨ completato Sistemi interattivi\nTempo di attesa deve essere minimizzato (il tempo di attesa nella ready queue) Tempo di risposta deve essere minimizzato (vorrei avere feedback molto veloce), almeno non percepibile dallâ€™umano. When a request that is perceived as complex takes a long time, users accept that, but when a request that is perceived as simple takes a long time, users get irritated.\nSistemi real-time\nIl fatto che un processo venga runnato prima di un certo tempo (altrimenti si perdono un pÃ² di dati)\nLibro sui metodi di valutazione dello scheduler\nÃˆ importante questa parte perchÃ© sulle slides vengono valutati solamente turnaround e throughput!\nNOTA: il tempo di utilizzo della CPU Ã¨ lÃ¬ riportata ma non Ã¨ una buona misura!\nAlgoritmi di scheduling (!!) FIFO: First come first served ðŸŸ© Questo Ã¨ l\u0026rsquo;algoritmo piÃ¹ banale, cioÃ¨ appena arriva un processo. Ãˆ una cosa molto semplice da implementare.\nSolitamente non Ã¨ molto veloce, buono per microcontrollori o comunque ambienti molto semplici. Per esempio se ho qualcosa che Ã¨ CPU bound ritarda un sacco tutti quei processi IO bound\nEsempio di processo lento\nAltro esempio con convoy effect\nQuando ho il convoy effect, ho continuamente il process dispendioso che fa ritardare tutti, e ci sono intere zone vuote.\nProcessi CPU bound piccoli vanno dopo CPU bound larghi, Ã¨ una cosa probabilistica, questo motiva la scelta di fare i lavori corti prima.\nShortest Job first ðŸŸ©â€” Slide shortest Job first\nSi puÃ² notare che il tempo di turnaround e il tempo di attesa scendono di molto! ma come sapere quanto tempo ci metteranno ad eseguire? Non si puÃ² sapere a priori.\nSi puÃ² anche dimostrare che Ã¨ la miglior soluzione possibile, perÃ² non Ã¨ possibile capire il cpu burst, posso solamente fare delle approssimazioni, che non sono per forza vere, non Ã¨ possibile implementarle\nMEDIA ESPONENZIALE\nQuesto Ã¨ la media che si utilizza per approssimare, Ã¨ la stessa media per le previsioni meteorologiche, che tengono conto del tempo.\nSlide media esponenziale\nVERSIONE PREEMPTIVE\nPraticamente Ã¨ un shortest remaining time first, che a seconda della predizione, si mette ad eseguire quello col tempo rimanente piÃ¹ piccolo. (nota potrebbe essere negativa la previsione).\nPer la versioen non-preemptive si lascia\nRound robin ðŸŸ© Slide round robin\nQuesta Ã¨ una soluzione pensata per sistemi interattivi, e a seconda del numero di questi processi, Ã¨ possibile definire il quanto di tempo, ossia il massima durata in cui puÃ² rimanere in esecuzione, poi deve essere switchata.\nDeve essere abbastanza corto che il tempo non sia percepibile umanamente, in questo senso sono interattivi.\nQuando Ã¨ in coda si mette in FIFO.\nNon conviene mettere il quanto di tempo troppo piccolo perchÃ© si perderebbe troppo per switchare\nIMPLEMENTAZIONE\nC\u0026rsquo;Ã¨ bisogno di un timer che genera interrupt ogni tot tempo, questo Ã¨ il quanto di tempo per il round robin. Questa Ã¨ proprio una cosa necessaria. per implementarlo.\nQuesto interrupt Ã¨ settato! Nel senso ogni tot tempo da quando lo ho fatto partire.\nEsempio\nScheduling a prioritÃ  ðŸŸ© In questa parte i concetti importanti sono:\nDifferenza prioritÃ  statica e dinamica I metodi per assegnare la prioritÃ  Aging (si implementa in un modo simile ai bit history visti in Paginazione e segmentazione Il sistema classi di prioritÃ  Ãˆ necessario un concetto di prioritÃ , ad esempio se faccio video, non vorrei che sia rallentato da un servizio di posta, il primo ha bisogno di maggiore interattivitÃ , quindi avrei bisogno questo concetto di prioritÃ .\nLa prioritÃ  puÃ² essere statica (che potrebbe fare starvation) o dinamica, per la dinamica si utilizza la tecnica di aging, in cui un processo ha una prioritÃ  naturale, che continua ad essere aumentato man mano resta nella coda di prioritÃ .\nstatica si better for sistemi realtime per raggiungere.\nPossiamo anche fare classi di prioritÃ  diverse e scelta la classe si puÃ² utilizzare la politica .\nQuesta politica Ã¨ molto simile a quello utilizzato nei router in Data Plane.\nServer Interattivi Processi utente FIFO demoni e vuoti FIFO banali Slide prioritÃ  (TODO: approfondire)\nEsempio: https://www.geeksforgeeks.org/multilevel-queue-mlq-cpu-scheduling/\nSISTEMI A REALTIME (non fare) Ci sono certe cose aperiodiche e periodiche. Periodico come reattori nucleari che devono stare a guardare sempre qualcosa (come cose per i reattori nucleari).\nPer periodici come rate monotonic (praticamente a prioritÃ , quelli a frequenza alta sono di alta prioritÃ ) o earliest deadline first.\nSpiegazione di chatGPT\nRate Monotonic Scheduling (RMS): Rate Monotonic Scheduling is a widely used real-time scheduling algorithm. The RMS algorithm is based on priority assignment to periodic tasks, where the task with the shortest period has the highest priority. The scheduling of tasks is done in a way that the higher-priority task always preempt the lower-priority task.\nThe RMS algorithm assumes that the execution time of all tasks is known in advance and that there are no other sources of delay, such as I/O or interrupts. This is known as the \u0026ldquo;static scheduling\u0026rdquo; assumption.\nEarliest Deadline First Scheduling (EDF): Earliest Deadline First (EDF) is another real-time scheduling algorithm. In EDF, each task has a deadline, and the task with the earliest deadline is scheduled first. The deadlines can be either hard (absolute) or soft (flexible). Hard deadlines must be met, while soft deadlines can be missed, but a penalty is incurred for each missed deadline.\nLike RMS, EDF is based on the assumption of static scheduling, which means that the execution time of tasks is known in advance and there are no other sources of delay. EDF can also handle aperiodic tasks, which do not have a fixed period but must be executed within a specified time limit.\nThe key difference between RMS and EDF is that RMS uses a fixed priority assignment based on task period, while EDF assigns priority dynamically based on the task deadline.\nIn summary, both RMS and EDF are real-time scheduling algorithms used to schedule tasks in real-time systems. RMS assigns priority based on the task period, while EDF assigns priority dynamically based on the task deadline.\n","permalink":"https://flecart.github.io/notes/scheduler/","summary":"Ripasso Prox: 33 Ripasso: June 9, 2023 Ultima modifica: May 10, 2023 9:41 AM Primo Abbozzo: March 8, 2023 10:18 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Scheduler Il suo scopo principale Ã¨ gestire l\u0026rsquo;avvicendamento dei processi. Ad esempio sospendere il processo che chiede I/O. O un sistema time sharing, quando arriva un interrupt sul time.\nSolitamente il nome scheduler Ã¨ solamente un gestore dell\u0026rsquo;avvicendamento, si puÃ² quindi utilizzare per indicare scheduler di altro tipo.","title":"Scheduler"},{"content":"Introduction to Time Complexity This note will build upon know techniques of algorithms analysis explained in Notazione Asintotica. We will need big-$O$ notation and $o$ notation. L\u0026rsquo;idea Ã¨ che il problema di decisione Ã¨ decidibile se limito la lunghezza del teorema. Simile al numero di Chaitin, che non Ã¨ computabile, ma Ã¨ approssimabile quanto si vuole. In un certo senso Ã¨ computabile. The general idea is to ask how the function $\\varphi$ that maps the longest $n$ proof to the number of steps of computation behaves.\nRobustness of the notion of time complexity The notion of \u0026ldquo;computational steps\u0026rdquo; used to measure the time complexity varies along\nComputational models definition of computational steps The code of the input and output (not always binary, for example big numbers are not fixed size). Influence of the Computational Model In Complexity Theory the choice of the formal model influences the complexity class of the model! This is different from the argument from computational theory of the Church Turing Thesis, where it asserts that a function is Computable in every computational model. See 7.7 in (Sipser 2012).\nThe Time Complexity Class Definition of the Time Complexity Class Languages that are decidable in $O(t(n))$ time are part of this class, denoted as $TIME(t(n))$. With $t : \\mathbb{N} \\to \\mathbb{R}^{+}$.\nAnother way to understand this is that if a algorithms terminates in at most $t(n)$ steps then it belongs to this class.\nPolynomial Complexity Class The polynomial class $P$ is defined as: $$ P = \\bigcup_{i \\geq 1} TIME(n^{i}) $$ This is defined as the class of the reasonable efficiency programs. NOTE: this is invariant with respect to the chosen coding system (if an algorithm is still in P, then it will remain in P even if you change code scheme).\nPATH is in P We can prove that the language $\\left\\{ \\langle G, s, t \\rangle \\mid G \\text{ is a graph that has a route from } s \\text{ to } t \\right\\}$ is in $P$ class. (Just use Grafi#BFS or Grafi#DFS).\nNOTE: we have worked assuming that the algorithm worked on the nodes, but usually TM work with bits, the thing is that there is a polynomial algo that converts that nodes into binary format, so it is not much of a big deal.\nOverview of problems in $P$ Exponential Complexity Class The exponential class $EXP$ is defined as: $$ EXP = \\bigcup_{i\\geq 1} TIME(2^{n^{i}}) $$ This class is common of the algorithms that use backtracking, for example CSP problems. Or just brute-force search all the branches.\nNon-deterministic Complexity Class Let $N$ be a non-deterministic decider then we have that a problem is in this complexity class, called $NTIME$ if the running time cost $f: \\mathbb{N} \\to \\mathbb{N}$ is bounded by that (longest computational branch). The difference with #Polynomial Complexity Class is that here we consider the length of a single branch, but we explore everything at the same time!\nQuindi\n$$ NP = \\bigcup_{i\\geq 1} NTIME(n^{k}) $$ Clique problem This problem is in NP, find all sub-graphs where all nodes are connected (this set of nodes forms a complete graph).\nWe can prove that the problem is in NP because there is an easy non-deterministic algorithm that computes it.\nNP algorithm Just\nSelect a subset of nodes from $G$. Do it non deterministically. Verify if this subset is a complete graph. If yes add it to the solution set. We can prove that this is correct, and it works, but it is a non deterministic algorithm, so it isn\u0026rsquo;t easily simulated by deterministic algorithms, even though we proved in Estensioni di Turing e altre macchine that from the computability point of view it is the same.\nVerifiable Given input the graph, and a subset, we need to\nFor each node in the subset, check if it is linked to each other. Return the previous truth result. So easy. Verifiability Definition: $A$ is verifiable if exists a TM $M$ such that: $$ w \\in A \\iff \\exists c : M \\text{ accepts } \\langle w, c \\rangle $$ If $M$ is polynomial then we say that this is polynomially verifiable. We can prove that this notion is equivalent for $NP$ complexity classes.\nTh: Verifiability = NP From a philosophical point of view, if a problem is in NP, we can just guess a solution, or just do brute force. There is no classical algorithmical solution that solves it, or a constructive proof for it.\n$\\leftarrow$: let\u0026rsquo;s suppose we have a $M$ that decides non deterministically that language. On input $\\langle w, c \\rangle$ we sun $M(w)$ and if it accepts, return true if the branch is good. ($c$ guides us about what non-deterministic branch to choose).\n$\\to$ : let\u0026rsquo;s assume we have a polynomial verifier, we need to build a TM that decides it non deterministically in polynomial time. choose non deterministically a certificate $c$ the encodes the path of the non-deterministic computation. If this accepts then accept! TODO: fai meglio questa parte\nReferences [1] Sipser â€œIntroduction to the Theory of Computationâ€ Cengage Learning 2012\n","permalink":"https://flecart.github.io/notes/time-complexity/","summary":"Introduction to Time Complexity This note will build upon know techniques of algorithms analysis explained in Notazione Asintotica. We will need big-$O$ notation and $o$ notation. L\u0026rsquo;idea Ã¨ che il problema di decisione Ã¨ decidibile se limito la lunghezza del teorema. Simile al numero di Chaitin, che non Ã¨ computabile, ma Ã¨ approssimabile quanto si vuole. In un certo senso Ã¨ computabile. The general idea is to ask how the function $\\varphi$ that maps the longest $n$ proof to the number of steps of computation behaves.","title":"Time Complexity"},{"content":"Introduzione agli alberi di decisione Setting del problema ðŸŸ©- Spazio delle ipotesi Definizione spazio ipotesi ðŸŸ©\u0026mdash; Per spazio delle ipotesi andiamo a considerare l\u0026rsquo;insieme delle funzioni rappresentabili dal nostro modello. Questo implica che l\u0026rsquo;allenamento ricerca l\u0026rsquo;ipotesi ossia la parametrizzazione ottimale del nostro modello, ottimale in quanto minimizza l\u0026rsquo;errore che viene compiuto nel training set.\nL\u0026rsquo;insieme iniziale si puÃ² anche considerare come inductive bias ossia il restringimento solamente a certe ipotesi e non tutte. Altrimenti abbiamo no free lunch.\nEspressivitÃ  ðŸŸ© In pratica ci andiamo a chiedere\nPer quali $h$ esistono modelli di alberi di decisione? Per tutti Dato un albero per una ipotesi $h$, l\u0026rsquo;albero Ã¨ unico? Se non Ã¨ unico abbiamo una preferenza? Overfitting and underfitting ðŸŸ© Sono dei fenomeni molto comuni nel campo dell\u0026rsquo;apprendimento statistico. Si potrebbe dire in modo intuitivo che:\nUnderfitting quando il modello non Ã¨ ancora stato allenato, quindi possiede un bias molto alto per quanto riguarda la precisione del modello\nOverfitting quando il modello Ã¨ stato allenato troppo, tanto che ha imparato del rumore presente sul training set, questo non permette la generalizzazione sul test set.\nSi potrebbe parlare in modo piÃ¹ formale di overfitting come il verificarsi allo stesso tempo di due condizioni $$ error_{D}(h) \u003e error_{D}(h') $$ $$ error_{train}(h) \u003c error_{train}(h') $$ Ossia ho un errore basso nel training set, ma non riesco a generalizzare sul validation set.\n### Esempio di struttura albero decisionale Vorremmo cercare di modellare alcuni modelli di regressione o classificazione seguendo un albero di decisione come in figura Il problema sarebbe capire come creare l\u0026rsquo;albero in automatico, a seconda di un training set labellato: Input:\n$$ coppie di training set. Output Un ipotesi $h$ che Ã¨ un albero di decisione. Entropia Definizione entropia ðŸŸ© $$ H(X) = - \\sum_{i=1}^{n}P(X = i) \\log_{2}P(X=i) $$ In cui se sono uguali hanno entropia massima, segue il grafico di questo genere\nC\u0026rsquo;Ã¨ un apparato teorico non da poco per questo, perchÃ© Ã¨ stato utilizzato molto nella teoria della comunicazione. Una cosa che riguarda la probabilitÃ  del singolo dato, se Ã¨ sempre uguale ho entropia piÃ¹ alta.\nInformation Gain ðŸŸ¨+ Una definizione che segue l\u0026rsquo;intuizione Ã¨ che la probabilitÃ  dell\u0026rsquo;avvenimento influenzi il concetto di informazione, ossia se un evento compare sempre (tipo il sole che sorge), non ha molto informazione, perchÃ© Ã¨ sempre uguale.\nProbabilitÃ  1 ha zero informazione given two independent events with probabilities p1 and p2 their joint probability is p1p2 but the information acquired is the sum of the informations of the two independent events, so $I(p_{1}p_{2}) = I(p_{1}) + I(p_{2})$ Le due propreitÃ  di sopra giustificano il fatto di definire in modo abbastanza naturale che $$ I(p) = -\\log(p) $$ ProprietÃ  importanti (4) ðŸŸ¨++ Algoritmo di costruzione dell\u0026rsquo;albero Descrizione algoritmo di costruzione ðŸŸ©- Bisogna introdurre il concetto di entropia per poter discriminare, vorremmo cercare il punto che diminuisca di piÃ¹ l\u0026rsquo;entropia.\nRiduzione overfitting Pruning dell\u0026rsquo;albero (2) ðŸŸ©\u0026ndash; Posso fare early stopping, ossia smetto di alllenarmi (ossia di creare altre branch), dopo che ne ho create un tot. Posso fare post-pruning, ossia dopo che ho creato tutto l\u0026rsquo;albero (probabilmente facendo overfitting), mi metto ad eliminare alcune branches di poco conto. Questo si utilizza il validation set per vedere in che modo potare puÃ² influenzare la performance su questo (se migliora allora di fa, lo facciamo in modo greedy) Index di ImpuritÃ  di Gini ðŸŸ©- Questo Ã¨ un indice che Ã¨ stato usato in economia per studiare la disuguaglianza fra le persone, nel nostro caso lo utilizziamo per capire in che modo fare branching con l\u0026rsquo;albero di decisione\nGiniâ€™s impurity measures the probability that a generic element get misclassified according to the current classification (an alternative to entropy).\n$$ I_{G}(F) = \\sum_{i=1}^{m} f_{i}(1 - f_{i}) = \\sum_{i=1}^{m} (f_{i} - f_{i}^{2}) = 1 - \\sum_{i= 1}^{m}f_{i}^{2} $$ Dove $f_{i}$ Ã¨ la frazione del dataset che appartiene ad $i$ Questo Ã¨ quindi un modo alternativo per fare split ad un nodo dell\u0026rsquo;albero.\nRandom forests Vengono costruiti molti alberi e si utilizzano le loro decisioni assieme per avere un risultato finale, questo Ã¨ una tecnica ensemble perchÃ© vengono messe assieme conoscenze di tutti gli alberi.\nEnsemble models ðŸŸ© Ensemble techniques exploits the principle that a large number of relatively uncorrelated models (e.g. trees) operating as a committee will typically outperform any of the individual constituent models.\nMetodi di differenziazione (2) ðŸŸ©\u0026ndash; Chiaramente non abbiamo molto vantaggio se tutti gli alberi che vengono cosÃ¬ creati sono tutti uguali fra di loro, Ã¨ quindi utile utilizzare tecniche che li differenzino fra di loro:\nBagging uso input random. Feature randomness (uso subset di features per predire) Conclusioni Aspetti positivi degli alberi di decisione (4) ðŸŸ©- Molto veloci Non hanno bisogno di grandi quantitÃ  di dati Facile capire perchÃ© viene fatto la decisione (posso plottare le immagini) Adatti sia a problemi continui che discreti Aspetti negativi (3) ðŸŸ©- Molto facile andare in overfitting Esistono molti alberi per lo stesso dataset (instabile con le features e struttura dell\u0026rsquo;albero) Possono diventare molto unbalanced se c\u0026rsquo;Ã¨ qualche predittore forte (andare a guardare questo). Side notes (altro) ","permalink":"https://flecart.github.io/notes/alberi-di-decisione/","summary":"Introduzione agli alberi di decisione Setting del problema ðŸŸ©- Spazio delle ipotesi Definizione spazio ipotesi ðŸŸ©\u0026mdash; Per spazio delle ipotesi andiamo a considerare l\u0026rsquo;insieme delle funzioni rappresentabili dal nostro modello. Questo implica che l\u0026rsquo;allenamento ricerca l\u0026rsquo;ipotesi ossia la parametrizzazione ottimale del nostro modello, ottimale in quanto minimizza l\u0026rsquo;errore che viene compiuto nel training set.\nL\u0026rsquo;insieme iniziale si puÃ² anche considerare come inductive bias ossia il restringimento solamente a certe ipotesi e non tutte.","title":"Alberi di decisione"},{"content":"Introduzione alla corrente elettrica Considerazioni generali Elettroni liberi nei materiali Ricorda che Ã¨ un reticolo cristallino, con un elettrone nell\u0026rsquo;ultimo orbitale poco legato, quindi facilmente ionizzabile, in cui gli elettroni si possono muovere facilmente, e abbiamo che $n \\approx 8.5 \\times 10^{28} \\frac{e^{-}}{m^{3}}$ nel rame Per l\u0026rsquo;argento abbiamo 5.9 con stesso ordine di grandezza.\nVelocitÃ  media elettroni senza campo elettrico ðŸŸ© Se Ã¨ isotropo, gli elettroni si muovo in generale a caso e la velocitÃ  media dipendente dall\u0026rsquo;eccitazione termica (in teoria cinetica dei gas Ã¨ studiata sta cosa). $$ \\vec{v}_{m} = \\sum_{i = 1} ^{N} \\frac{\\vec{v}_{i}}{N} = 0 $$ Analisi che segue i gas: $$ \\frac{1}{2} m_{e} v^{2} = \\frac{3}{2} k T $$ Con $k = 1.38 \\times 10 ^{-23} J / K$ questo da studiare in altro posto\u0026hellip;\nComunque abbiamo che $$ \\vec{V} = \\sqrt{ \\frac{3kT}{m_{e}} } \\approx 1.16\\times 10^{5} \\frac{m}{s} = 116 \\frac{km}{s} $$ Assumendo che $T = 293K$ con la teoria cinetica dei gas classica. Ma probabilmente questa analisi non Ã¨ corretta, perchÃ© serve la meccanica quantistica per spiegare questo (Fermi-Sommerfield, calcola meglio questa parte), con questa otteniamo che Ã¨ ti tipo $1580 \\frac{km}{s}$ che Ã¨ un ordine di grandezza piÃ¹ grande.\nIn assenza di campo sembra assistere a urti anelastici in giro, che vanno a caso e si scontrano con atomi molto piÃ¹ pesanti.\nVelocitÃ  di deriva ðŸŸ© Proviamo a considerare questo esperimento: Sia $\\vec{v}_{i}$ la velocitÃ  di un elettrone prima di un urto, e $\\vec{v}_{i + 1}$ la velocitÃ  dopo un urto. Facciamo finta che in un campo elettrico venga acceso un campo elettrico nell\u0026rsquo;intervallo fra $i$ e $i + 1$, allora sarÃ  sottoposto a una forza\n$$ \\vec{F} = -e\\vec{E} $$ Allora abbiamo che $$ m \\frac{dv}{dt} = -eE \\implies \\vec{v} = -\\frac{e\\vec{E}}{m} t $$ Allora sappiamo che in ogni urto, si avrÃ  in generale sempre una componente verso la direzione del campo (questa Ã¨ la parte che influenza la velocitÃ  di deriva che ricordiamo Ã¨ molto basso). Questo Ã¨ nell\u0026rsquo;ordine di metri all\u0026rsquo;ora.\nAllora provando a riconsiderare la velocitÃ  media:\n$$ \\vec{v}_{media} = \\frac{1}{N}\\sum \\vec{v}_{i} - \\frac{e\\vec{E}}{m}t = -\\frac{e\\vec{E}}{m}t $$ Dato che la velocitÃ  che proviene solamente da agitazione termica Ã¨ 0, e che ogni singola particella Ã¨ soggetta alla stessa forza (si semplifica il numero diciamo per il secondo addendo).\nSimilitudine velocitÃ  di deriva con caduta ðŸŸ¨ Molto brevemente se sottoposti a un campo elettrico, gli elettroni si spostano, ma questa cosa dura molto poco, quindi non era poi utile a utilizzare.\nDopo Alessandro Volta abbiamo un campo elettrico costante all\u0026rsquo;interno di un conduttore. Riusciva a generare una differenza di potenziale costante sui capi dell\u0026rsquo;oggetto. Questo Ã¨ pila, fem, generatore. Allora in questo caso la loro velocitÃ  media Ã¨ diversa da 0, iniziano quindi ad urtare gli urti (elastici) gli atomi, molto casuale, ma in media Ã¨ sempre accelerato verso la direzione del campo. Questo caso sembra simile a quello di un corpo che fa urti con atomi dell\u0026rsquo;atmosfera, non fanno altro che rallentare il moto di caduta libera in quel caso avevamo $$ \\vec{F} = \\vec{P} = m\\vec{g} - \\beta \\vec{v} \\implies \\vec{V}_{lim} = \\frac{m\\vec{g}}{\\beta} = \\text{constant} $$ Anche in questo caso ci sarÃ  una velocitÃ  constante media degli elettroni, quando continuamente cominciano a sbattere.\nNel caso delle correnti si chiama effetto di RESISTENZA ossia l\u0026rsquo;effetto di urti sugli atomi del mezzo conduttore, che rallentano, qui il baricentro delle cariche si sposta all\u0026rsquo;interno del campo, che va in modo costante.\nSuperconduttori ðŸŸ© Sono materiali in cui non c\u0026rsquo;e resistenza, solitamente leghe di metalli rari (boruro di metallo tipo), in cui vicino allo 0 assoluto non hanno resistenza.\nSemiconduttori ðŸŸ© Sono dei dielettrici drogati con aggiunta di ioni che siano in grado di liberare carica, come sali disciolti nell\u0026rsquo;acqua. Hanno una densitÃ  di elettroni molto molto minori rispetto ai conduttori, ma sono sufficienti per condurre La caratteristica principale Ã¨ che hanno molti meno elettroni liberi, ma ne hanno alcuni.\nIntroduzione con definizioni Definizione della corrente ðŸŸ© IntensitÃ  di corrente $$ i = \\lim_{ \\Delta t \\to 0 } \\frac{\\Delta q}{\\Delta t} = \\frac{dq}{dt} $$ Questo si puÃ² mettere in relazione con la densitÃ  di corrente che sarÃ  spiegata subito dopo, abbiamo che\nGrandezza della corrente ðŸŸ© $$ [i] = [Q][T]^{-1} = [A] $$ Ossia $1A = 1C / 1s$ che Ã¨ una quantitÃ  enorme.\nDensitÃ  di corrente Definizione di densitÃ  di corrente ðŸŸ© PerchÃ© la $\\vec{J}$ che Ã¨ definita ha stesso verso del campo elettrico. Ãˆ la quantitÃ  di corrente che attraversa una superficie qualunque, quindi Ã¨ un flusso.\nDefinito come $$ \\vec{J} = ne \\cdot \\vec{v}_{d} $$ Con la velocitÃ  di deriva.\nDensitÃ  di corrente motivazione (!) ðŸŸ© Vogliamo capire, quanta corrente in un intervallo $dt$ attraversa quella superficie? Tutta la carica che sta a distanza $v_{d}dt$ riesce a passare la superficie. abbiamo quindi che il volume Ã¨ $$ d\\tau = v_{d} \\Delta t dS \\cos \\theta $$ in cui $v_{d}\\Delta t$ Ã¨ il parallelepipedo, o comunque la zona di spazio delle cariche che passeranno attraverso la superficie. E allora il numero di elettroni lÃ¬ dentro Ã¨ $n_{e}\\cdot \\tau$ Quindi\n$$ dq = qn_{e} \\cdot d\\tau $$ Con questo possiamo ri-caratterizzare la definizione di corrente:\n$$ i = \\lim_{ \\Delta t \\to 0 } \\frac{\\Delta q}{\\Delta t} = ne v_{d} S \\cos \\theta = ne \\vec{v}_{d} \\cdot \\vec{S} = \\vec{J} \\cdot \\vec{S} $$ che Ã¨ proprio ciÃ² che abbiamo ragionando per first principles.\nPiÃ¹ in generale: $$ i = \\int _{\\Sigma} di = \\int _{\\Sigma} \\vec{J} \\cdot d\\vec{S} $$ E chiamo la nuova grandezza $\\vec{J}$ con lo stesso verso del campo elettrico come densitÃ  di corrente Di valore $\\frac{[A]}{[m]^{2}}$ Quindi la $i$ Ã¨ il flusso all\u0026rsquo;interno di quello, come se fosse acqua in tubo. Dal punto di vista del flusso perÃ² Ã¨ impossibile distinguere fra positivi e negativi, perchÃ© tanto si annullano Questo Ã¨ vero considerando questa semplice osservazione:\n$$ \\vec{J} = nqv $$ $$ \\vec{J} = n (-q) (-v) $$ In ogni caso Ã¨ sempre positivo, quindi possiamo usare la parte positiva come carica giustificato da questo artificio matematico.\nStima densitÃ  di corrente (no impo) Supponiamo di avere un tubo di rame per cui abbiamo $n \\approx 8.5 \\times 10^{28} \\frac{e^{-}}{m^{3}}$, $r = 0.8 mm$ con una corrente $i = 15 A$, consideriamo una superficie perpendicolare. Applichiamo i concetti:\n$$ i = \\int _{\\Sigma} \\vec{J} \\cdot \\vec{dS} = J \\int _{\\Sigma} \\, dS = J \\cdot S = J \\pi r^{2} = nev_{d} \\pi r^{2} \\implies v_{d} = \\frac{i}{neS} $$ Sappiamo che $S \\approx 2 \\times 10^{-6} m^{2}$ e sappiamo che $ne$ Ã¨ la densitÃ  volumetrica di carica, dipendente la carica di conduzione $\\rho$ che Ã¨ il valore di n che abbiamo descritto sopra. $ne = \\rho = 8.5 \\times 10^{28} \\cdot 1.6 \\times 10^{-19} \\approx 13.6 \\times 10^{9} \\frac{C}{m^{3}}$\nSostituendo sopra abbiamo che $v_{d} \\approx 5 \\times 10^{-4} \\frac{m}{s} = 2\\frac{m}{h}$ Quindi due metri all\u0026rsquo;ora, avendo gli elettroni che si muovono a 1k chilometri a secondo, la velocitÃ  di deriva Ã¨ molt lenta, ed Ã¨ corrente. Ma essendo la carica enorme, alla fine ho grandi valori!\nFacendo tutto questo calcolo abbiamo che\nEquazione di continuitÃ  della densitÃ  di corrente (!) ðŸŸ© $$ i = \\int _{\\Sigma} \\vec{J} \\cdot \\vec{S} = -\\frac{dq}{dt} $$ PerchÃ© sto considerando la carica positiva che sta uscendo, quindi dentro sto perdendo carica.\nRegime stazionario si ha quando $i = 0$, quindi non ho carica che gira, nel senso che stessa carica esce, e stessa carica esce durante il circuito.\nContinuitÃ  in forma differenziale ðŸŸ© Questo Ã¨ l\u0026rsquo;equivalente di conservazione di carica per la corrente.\nNoi abbiamo per il teorema della divergenza (vedi Divergenza e Circuitazione) che\n$$ \\oint_{\\Sigma} \\vec{J} \\cdot d\\vec{S} = \\int _{V(\\tau)} \\vec{\\nabla} \\cdot \\vec{J} \\, d\\tau $$ Abbiamo anche per definizione di densitÃ  di flusso che $$ \\frac{dq}{dt} = \\int _{V(\\tau)} \\frac{\\delta\\rho}{\\delta t} \\, d\\tau $$ Quindi ho che $$ \\int _{V(\\tau)} \\frac{\\delta\\rho}{\\delta t} \\, d\\tau = - \\int _{V(\\tau)} \\vec{\\nabla} \\cdot \\vec{J} \\, d\\tau $$ Questa Ã¨ l\u0026rsquo;equazione di continuitÃ  in forma differenziale:\n$$ \\vec{\\nabla} \\cdot \\vec{J} + \\frac{\\delta \\rho}{\\delta t} = 0 $$ ","permalink":"https://flecart.github.io/notes/corrente-elettrica/","summary":"Introduzione alla corrente elettrica Considerazioni generali Elettroni liberi nei materiali Ricorda che Ã¨ un reticolo cristallino, con un elettrone nell\u0026rsquo;ultimo orbitale poco legato, quindi facilmente ionizzabile, in cui gli elettroni si possono muovere facilmente, e abbiamo che $n \\approx 8.5 \\times 10^{28} \\frac{e^{-}}{m^{3}}$ nel rame Per l\u0026rsquo;argento abbiamo 5.9 con stesso ordine di grandezza.\nVelocitÃ  media elettroni senza campo elettrico ðŸŸ© Se Ã¨ isotropo, gli elettroni si muovo in generale a caso e la velocitÃ  media dipendente dall\u0026rsquo;eccitazione termica (in teoria cinetica dei gas Ã¨ studiata sta cosa).","title":"Corrente Elettrica"},{"content":"We have enormous state functions, having a generic approssimation could really help! We want to use a differentiable value function so that we can use gradient descent to optimize it, for example a good way of loss would be $$ J(w) = \\mathbb{E}_\\pi[(V^\\pi(s) - \\hat{V}^\\pi(s;w))^2] $$ The second one is parametrized with $w$. There are two ways (recuperali!) MC policy or Time differential (that is boostrapped, instead the Monte carlo uses a full simulation in order to know what to use). 2\n","permalink":"https://flecart.github.io/notes/function-approximation/","summary":"We have enormous state functions, having a generic approssimation could really help! We want to use a differentiable value function so that we can use gradient descent to optimize it, for example a good way of loss would be $$ J(w) = \\mathbb{E}_\\pi[(V^\\pi(s) - \\hat{V}^\\pi(s;w))^2] $$ The second one is parametrized with $w$. There are two ways (recuperali!) MC policy or Time differential (that is boostrapped, instead the Monte carlo uses a full simulation in order to know what to use).","title":"Function approximation"},{"content":"Ripasso Prox: 40 Ripasso: January 8, 2022 Ultima modifica: October 27, 2022 12:15 PM Primo Abbozzo: September 21, 2021 7:04 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Dubbi vecchi (se ti va rispovera)\nQuale Ã¨ la differenza fra Microarchitettura e il livello assembly? Non vanno entrambi a fare istruzioni eseguite livello macchina? Dici assembly ha bisogno di essere tradotto?\n1. Livelli di astrazione 1.1 Il principio di astrazione/implementazione Astrazione per macchine livello n con linguaggi n.\n1.2 I livelli principali di astrazione Livelli in breve\n1.2.1 Livello 0 Qua Ã¨ utile indagare la\nPorte Logiche in cui si indagano in un modo molto alto il funzionamento di porte\nÃˆ il livello fisico delle porte logiche e dell\u0026rsquo;ingegneria elettrica.\n1.2.2 Livello 1 Link utili potrebbero essere la CPU e storia degli elaboratori\nCircuiti Sequenziali Ossia la Memoria\nla microarchitettura governa il flusso dei dati fra i vari componenti del livello logico digitale\nQuesto Ã¨ il livello della micro-architettura, ossia come i componenti logici interagiscono fra di loro.\n1.2.3 Livello 2 Livello ISA\nLivello ISA, Instruction Set Architecture, che sono le sequenze di 0 e 1 che definiscono una istruzione\nFino a qua (+ anche parte del sistema operativo) Ã¨ il lavoro del system programmers che si devono occupare di cose di questo livello di astrazione, in seguito i linguaggi sono spesso compilati e non interpretati (application programmers).\n1.2.4 Livello 3-4 Ãˆ il sistema operativo, il programma che organizza le risorse per il problema, la memoria virtuale etc.\nLinguaggio assembly.\nSi parla di livello ibrido perchÃ© spesso questo livello utilizza ancora le istruzioni ISA (Quindi assembly tradotto), con semmai in aggiunta alcuni programmi per l\u0026rsquo;esecuzione concorrenziale, gestione della memoria e simili.\nEcco che questi due livelli non si distinguono molto l\u0026rsquo;uno dall\u0026rsquo;altro, Il SO Ã¨ fatto probabilmente in assembly o ISA (ma nessuno lo fa direttamente in codice macchian) in piÃ¹ aggiunge servizi tipici del sistema operativo.\n1.2.5 Livello 5+ Sono i linguaggi utili alla risoluzione dei problemi, come Python, c++, Java, Js, Ts\nLivelli e macchine virtuali Traduzione e interpretazione Spesso linguaggi a livelli superiori non sono direttamente interpretabili da un livello, basso, per questo motivo devono essere tradotte a un linguaggio comprensibile al livello inferiore.\nMacchina virtuale Spasso invece di continuare a pensare come un continuum di traduzioni fra i livelli Ã¨ opportuno pensare a un livello come una macchian virtuale a sÃ© stante. Ossia ogni livello ha una macchina che opera con un metodo a sÃ© stante, diverso da tutti gli altri livelli.\nEsempio di questa struttura\ngni livello ha una macchina che opera con un metodo a sÃ© stante**, diverso da tutti gli altri livelli.\nEsempio di questa struttura\n","permalink":"https://flecart.github.io/notes/introduzione-ad-architettura/","summary":"Ripasso Prox: 40 Ripasso: January 8, 2022 Ultima modifica: October 27, 2022 12:15 PM Primo Abbozzo: September 21, 2021 7:04 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Dubbi vecchi (se ti va rispovera)\nQuale Ã¨ la differenza fra Microarchitettura e il livello assembly? Non vanno entrambi a fare istruzioni eseguite livello macchina? Dici assembly ha bisogno di essere tradotto?\n1. Livelli di astrazione 1.1 Il principio di astrazione/implementazione Astrazione per macchine livello n con linguaggi n.","title":"Introduzione ad architettura"},{"content":"Ripasso Prox: 30 Ripasso: June 1, 2023 Ultima modifica: April 16, 2023 12:33 PM Primo Abbozzo: February 23, 2023 5:13 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Chiedi chiarimenti sul perchÃ© Ã¨ necessario avere stack separati per la gestione di interrupt multipli annidati. Non basterebbe aggiungere sulla stack che ho giÃ ? Poi quando finisco lâ€™interrupt elimino quanto mi ha aggiunto lâ€™ultimo interrupt, e la roba vecchia câ€™Ã¨ ancora. Note sullâ€™architettura Interrupt Descrizione iniziale ðŸŸ© Di interrupt e trap se nâ€™Ã¨ parlato un pÃ² in Livello ISA di architettura, ora andiamo ad approfondire come viene gestito a livello SO.\nUn interrupt Ã¨ un segnale che viene mandato o da un dispositivo hardware (di solito dopo la fine di un processo input output) oppure da software, in questo caso viene chiamato trap che Ã¨ un interrupt software sincrono..\nSlide Interrupt Hardware e software\nQuesti segnali sono utilizzati per indicare eventi che dovrebbero essere gestiti (come end of I/O, divisione per 0, ma anche semplicemente syscall e passare livello kernel).\nIl segnale solitamente implica la interruzione di quanto viene svolto in questo momento, per gestire lâ€™interrupt corrente, e poi tornare allâ€™istruzione precedente. Solitamente perchÃ© potrebbe anche essere che il processo non sia interrompibile, e quindi lâ€™interrupt dovrebbe essere rischedulato.\nPer poter ripristinare lo stato precedente solitamente ci si devono salvare lâ€™immagine dei registri del programma, tutte le informazioni utili a far runnare il processo (di solito messe nelle PCB), e lâ€™istruzione di ritorno.\nQuando ci si ritorna sopra basta mettere nel PC lâ€™indirizzo della istruzione corretta.\nProcedimento classico di gestione interrupt ðŸŸ© Praticamente durante il Ciclo va a fare un check per vedere se il filo dellâ€™interrupt Ã¨ settato, se sÃ¬ carica istruzioni a un certo indirizzo (e si deve salvare lâ€™istruzione attuale).\nMasked se si sta facendo qualcosa che non si puÃ² interrompere, quindi Ã¨ delayed. (quando il processore non puÃ² essere interrotto, ad esempio quando sei in Sezioni Critiche, o quando arrivano interrupt dello stesso tipo, se ogni interrupt ha una stack propria, andrebbe a sovrascrivere).\nSe tutto va bene e non Ã¨ delayed ed esiste un interrupt, ad alto livello fa:\nSospende (in un modo che possa essere ripreso) il processo corrente Salta allâ€™istruzione definito in interrupt vector **(**tabella fissa cosÃ¬ Ã¨ piÃ¹ veloce) Esegue lâ€™interrupt Si ritorna al processo precedente, o altro (scheduling potrebbe far andare in altro processo). Slides passi ad alto livello\nSlides passi a basso livello (!!!)\nFino a qui tutte le operazioni sono HARDWARE. Da ora in poi viene ripreso il ciclo FDE con il controllo dell Interrupt handler.\nTipologie di gestione di interrupt Multipli (2) ðŸŸ© Quando ho interrupt multipli diventa leggermente piÃ¹ difficile gestire questi interrupt. Potrebbero interagire, che succede quando mi arriva un interrupt da device 1 mentre sto runnando lâ€™interrupt handler di device 2???\nDisabilitazione degli interrupt\nQuesta Ã¨ la forma piÃ¹ semplice per la gestione dellâ€™interrupt, in pratica quando sto gestendo un interrupt, li disabilito, in modo che non possa riceverne altri, cosÃ¬ sono sicuro che non posso ricevere nessun altro interrupt. Una soluzione simile per le CS ne abbiamo discusso in Sezioni Critiche\nQuando sto per finire riattivo gli interrupt e cosÃ¬ posso vedere se ce ne erano alcuni pendenti.\nHo alcuni svantaggi come:\nNon ho un concetto di prioritÃ  degli interrupt a questo livello Slide idea di gestione\nAnnidamento degli interrupt\nQuesta Ã¨ la soluzione piÃ¹ moderna, ed Ã¨ anche la piÃ¹ efficiente che permette di\nAvere un concetto di prioritÃ  di interrupts Necessita di stack separati (se gli interrupt utilizzano la stessa stack, potrebbero sovrascriversi alcune informazioni!) quindi piÃ¹ difficile da implementare. Forse ogni interrupt ha una propria stack, se viene stetsso tipo di interrupt sono maskerati! PI/O, or Interrupt based I/O ðŸŸ© PI/O\nIn questo caso la CPU setta tutti i valori utili al controllore del device driver. e poi fa polling per chiedere al driver se ha finito o meno (attraverso un controllo sul registro di stato del driver).\nSe il driver ha finito, la CPU si mette a copiare i dati di output del device alla propria memoria.\nUn chiaro svantaggio Ã¨ che il polling Ã¨ molto inefficiente per la soluzione di questo tipo di problemi.\nInterrupt driven I/O\nQuesta Ã¨ la soluzione moderna, quella piÃ¹ utilizzata, dato che ora Ã¨ il dispositivo driver a comunicare quando un processo I/O Ã¨ stato completato o men, cosÃ¬ la CPU Ã¨ a conoscenza di questo evento e puÃ² comportarsi di conseguenza. (quindi quando gestire lâ€™interrupt, e poi effettivamente runnare il codice corrispondente quando lâ€™interrupt Ã¨ avvenuto).\nMemoria Direct Memory Access ðŸŸ© Per copiare alcuni dati utili per I/O dalla memoria RAM alla memoria del controllore bisognerebbe spendere tanti cicli di clock della CPU, di solito questa Ã¨ una operazione molto lenta.\nDMA ci permette di accedere direttamente alla memoria, quindi il controllore stesso Ã¨ programmato con lâ€™indirizzo su cui andare a prelevare la memoria corretta, sollevando la CPU da questo primo lavoro.\nChiaramente il vantaggio principale di questo metodo Ã¨ la velocitÃ , dato che abbiamo piÃ¹ cicli di clock per la CPU, oltre a questo, crea una interfaccia piÃ¹ facile da gestire, quindi i drivers sono piÃ¹ semplici.\nUno svantaggio Ã¨ la contesa del BUS, che per trasferire câ€™Ã¨ bisogno che il bus sia libero.\nSicurezza\nQuesto Ã¨ un possibile falla di sicurezza, infatti se il codice del controller Ã¨ malevolo potrebbe fare attacchi al sistema di certo tipo.\nSecondo Renzo sarebbe meglio che questo codice fosse open, in modo che sia molto probabile di trovare cose maligne.\nRam ðŸŸ© Ãˆ semplificata da poche istruzioni di accesso, che di solito sono solo LOAD E STORE. (Tutti i dettagli fisici sono astratti, la CPU non si interessa di questi, sono built-in del calcolatore!).\nDi solito (in modi che non so), sono gestiti da MMU.\nNOTA: ci mettono un pÃ² i condensatori a scaricarsi. (possibile recuperare un pÃ² di informazioni se tipo congeli la RAM subito).\nLe ROM esistono ancora, ma sono per cose basilari, come per la parte del boot.\nMemory Mapped I/O ðŸŸ©- Alcune aree di memoria, come quelle del video grafico, sono scritti e letti subito da alcuni driver e sono utilizzati per sapere cosa mostrare sullo schermo per esempio.\nMa dato che 2 componenti (read and write) devono sincronizzarci nella lettura. Questa sincronizzazione di solito Ã¨ fatta a livello hardware.\nDischi e SSD ðŸŸ© Abbiamo spiegato meglio questa parte in Devices OS\nDischi memorizzano in maniera magnetica, e lo fanno in maniera non-volatile, cioÃ¨ possiamo ritrovare i nostri dati.\nSono a accesso diretto, in contrasto con i nastri che erano sequenziali. leggermente accennato in Memoria. E per capire dove leggere e scrivere si devono impostante movimenti di settore del cilindro e testina per leggere il settore corretto. Settore si aspetta che giri, testina si aspetta che si sposti. Ãˆ lento, nellâ€™ordine dei microsecondi.\nOperazioni possibili\nREAD, WRITE e anche Seek (quando vado a spostare la testina da altre parti!)\nSlide\nOsservazioni sulla velocitÃ \nNon ci converrebbe avere uno stesso file messo in posti molto diversi fra di loro allâ€™intenro del disco!\nCose di scheduling in modo da leggere cose che siano vicine. (Ma anche il filesystem, in modo che cose che cose che vengono utilizzate spesso siano vicine, ma questa roba la vedremo dopo)\nSSD, Solid State Disk\nAnche questi sono per cose non volatili.\nSolitamente scrivono ad insieme di blocchi! e lo si fa in cicli di scrittura perchÃ© non scrive ad ogni singola scrittura, ma sono in un buffer, e saranno scritti insieme in tutti in un ciclo di scrittura, questo Ã¨ per rendere piÃ¹ efficiente questa operazione.\nPer ssd a volte tengo la RAM come una cache intermedia per la scrittura.\nGerarchie di memoria ðŸŸ© Slide piramide\nLâ€™altro argomento si parlerebbe di Cache, ma penso sia trattato giÃ  benissimo in 4.2 Memoria Cache\nQuindi guardare lÃ¬, guardare la piramide della memoria il tradeoff velocitÃ  e quantitÃ  di memoria, il costo di accesso (in termini di tempo ed energia).\nSicurezza Il processo\nNon dovrebbe accedere ad aree di memoria a cui non dovrebbe accedere Non dovrebbe accedere direttamente ai dispositivi I/O, altrimenti potrei accedere e modificare qualunque cosa sui driver, e qualunque processo potrebbe farlo. Ãˆ importante garantire la sicurezza anche per lâ€™affidabilitÃ  del sistema, anche per proteggere il programmatore stesso, quando fa qualcosa in modo accidentale, in modo da evitare danni brutti. al sistema\nMode Bit ðŸŸ© nella realtÃ  le protezioni principali sono due, messe a livello hardware\nUn Mode bit che sta a specificare se il CPU Ã¨ in Kernel mode o user mode. Questi metodi sono importanti perchÃ© il modo kernel permette accesso totale controllo totale sulla memoria, sullâ€™IO, mentre user solamente gli indirizzi a lui illegali. Questo metodo permette di entrare in kernel mode in modo controllato, in modo che riesca sempre a gestire questa protezione. Ovviamente il cambio del mode bit Ã¨ privilegiato, un programma normalmente non puÃ² cambiare mode con una singola istruzione, deve passare con system call che sono le interrupt software o trap, con una istruzione specifica per mandare interrupt. Ãˆ l\u0026rsquo;unico modo!. Nota: ovviamente quando il computer parte, in boostrap Ã¨ in modalitÃ  kernel, che appena finisce tornerÃ  in User Mode (Ã¨ il processo INIT!) Una mappatura a indirizzi illegali per il programma, in modo che possa accedere solamente a quello a cui dovrebbe accedere. Protezione memoria ðŸŸ©- Slide protezione Memoria MMU\nQuesto pezzo di hardware ha il ruolo di tradurre indirizzi logici in fisici, e gestire l\u0026rsquo;accesso (ritorna lâ€™errore se non si potrebbe fare).\nÃˆimportante che sia in Hardware perchÃ©:\nDeve essere molto veloce, perchÃ© sono operazioni molto veloci Si potrebbe bypassare e allora avresti accesso a tutta la memoria ugualmente. System call ðŸŸ©- La sistem call Ã¨ una unica istruzione, mediante la quale Ã¨ possibile accedere al kernel mode, in grado di accedere a tutto, utile per la protezione e affidabilitÃ  del sistema, e non permettere programmi di fare tutto.\nEsistono convenzioni di chiamata, perchÃ© si aspetta in un certo registro la presenza di un codice che specifichi la tipologia di system call, poi la sistem call ritornerÃ  il valore corretto in un certo registro.\n","permalink":"https://flecart.github.io/notes/note-sullarchitettura/","summary":"Ripasso Prox: 30 Ripasso: June 1, 2023 Ultima modifica: April 16, 2023 12:33 PM Primo Abbozzo: February 23, 2023 5:13 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Chiedi chiarimenti sul perchÃ© Ã¨ necessario avere stack separati per la gestione di interrupt multipli annidati. Non basterebbe aggiungere sulla stack che ho giÃ ? Poi quando finisco lâ€™interrupt elimino quanto mi ha aggiunto lâ€™ultimo interrupt, e la roba vecchia câ€™Ã¨ ancora. Note sullâ€™architettura Interrupt Descrizione iniziale ðŸŸ© Di interrupt e trap se nâ€™Ã¨ parlato un pÃ² in Livello ISA di architettura, ora andiamo ad approfondire come viene gestito a livello SO.","title":"Note sullâ€™architettura"},{"content":"Introduzione all\u0026rsquo;algebra relazionale Confronto con relazioni matematiche Le relazioni come le intendiamo in database sono leggermente diverse rispetto a quelle presenti per le relazioni matematiche:\nNon conta l\u0026rsquo;ordine Ci sono gli attributi Per il resto se introduciamo questo sistema per tenere conto delle astrazioni, possiamo analizzarle matematicamente, e questo ci fornisce qualche sicurezza in piÃ¹ diciamo.\nDefinition of tuples ðŸŸ© Le relazioni sono esattamente quelle definite in matematica, perÃ² noi aggiungiamo anche gli attributi, in modo da poter considerare l\u0026rsquo;ordine delle colonne non importante.\nPer prendere anche gli attributi possiamo definire cosÃ¬:\nTupla = funzione che associa attributo (una stringa) a un valore del dominio dell\u0026rsquo;attributo, definito da una funzione esterna Relazione Ã¨ un insieme di tuple. Facendo in questo modo ho risolto il problema dell\u0026rsquo;ordine Set operations Possiamo modellare l\u0026rsquo;algebra come se\nUnions Intersections ðŸŸ© Vengono indicati con i simboli classici presenti nella teoria degli insiemi $\\cap ,\\cup$ Questa parte non ho capito perchÃ© deve esistere\u0026hellip; Che scopo ha?\nOperazioni principali Renaming Sintassi e semantica ðŸŸ© Questo Ã¨ un operatore unario.\nIt produces changes on the schema that keep the underlying data un-altered\nDa questa immagine Ã¨ abbastanza intuitivo la sintassi utilizzata. $$ \\rho_{end \\impliedby start} (table) $$ **Semantica:** Un attributo del dataset viene richiamato con altro nome. ### Selection Anche questo Ã¨ un **operatore unario**. #### ProprietÃ  della selection (3) ðŸŸ©- 1. Schema dell'output Ã¨ lo stesso 2. L'output soddisfa un predicato (logico). 3. L'output Ã¨ solamente un subset. **Concatenazione**: $$ \\sigma_{a}(\\sigma_{b}(R)) = \\sigma_{a \\land b }(R) $$ DistributivitÃ  su unione e differenza $$ \\sigma_{a}(R_{1}\\cup R_{2}) = \\sigma_{a}(R_{1}) \\cup \\sigma_{a}(R_{2}) $$ $$ \\sigma_{a}(R_{1} - R_{2}) = \\sigma_{a}(R_{1}) - \\sigma_{a}(R_{2}) $$ Altro con insiemi Possiamo notare che operano proprio come se fossero dei set, nel senso unione per or, intersezione per and, e anche intersezione col contrario con il meno.\nSintassi e semantica ðŸŸ© $$ \\sigma_{predicate}(Relation) $$ Semantica: un insieme che soddisfa le #ProprietÃ  della selection\nProjection Anche questo Ã¨ un unary operator.\nSemantica e sintassi ðŸŸ© $$ \\pi_{attribute}(Relation) $$ Semantica: viene ritornato un insieme con numero tuple della relazione iniziale (o minore per ripetizioni), ma solo con gli attributi di riferimento.\n$$ \\pi_{Y}(r) = \\left\\{ t[Y] | t \\in r \\right\\} $$ Ossia prendo i valori della tupla che corrispondono a quegli attributi, per ogni singola tupla presente in relazione\nCaso ripetizioni ðŸŸ© Questa Ã¨ una cosa da notare, a differenza di Structured Query Language le cose ripetute vengono scartate, si ha unico, in questo caso, perchÃ© qui siamo nel reame degli insiemi\nProprietÃ  di proiezioni ðŸŸ© Idempotenza $$ \\pi_{x}(R) = \\pi_{x}(\\pi_{xy}(R)) $$ Se lo applico piÃ¹ volte (anche con cose leggermente diverse rimane uguale)\nDistributivitÃ  su unione $$ \\pi_{x}(R_{1} \\cup R_{2}) = \\pi_{x}(R_{1}) \\cup \\pi_{x}(R_{2}) $$ Join La join Ã¨ necessaria nel caso vogliamo creare correlazione fra tuple presenti in relazioni diverse fra di loro, mentre con #Projection e #Selection possiamo farlo solamente sulla prima.\nFull and empty joins ðŸŸ© Full -\u0026gt; Every tuple is used (not full is some is used) Empty -\u0026gt; with no outputs Questo Ã¨ direttamente dipendente da quali chiavi abbiamo usato durante la join Types of Joins (2) ðŸŸ©- Natural Joins Siano dati due relazioni $R_{1}(X_{1}), R_{2}(X_{2})$ definisco $$ R_{1} \\bowtie R_{2} = \\left\\{ t \\text{ on } X_{1} \\cup X_{2} | \\exists t_{1} \\in R_{1} \\text{ and } \\exists t_{2} \\in R_{2} \\text{ with } t[X_{1}] = t_{1} \\text{ and } t[X_{2}] = t_{2}\\right\\} $$ Ossia data una tupla nella nuova relazione cosÃ¬ creata, se prendo i attributi appartenenti alla prima relazione avrÃ² che esiste effettivamente uguale per il secondo.\nOuter joins: Che sono le stesse spiegate in Structured Query Language, ossia andiamo a considerare left, right and full $A âŸ• B, A âŸ–B , AâŸ—B$, sono i simboli utilizzati, ma userÃ² sempre $\\bowtie$ con pedice l, r, f per indicarne il tipo, per semplicitÃ  di notazione.\nLa semantica di questi Ã¨ la stessa per SQL, la descriviamo prevemente, sarÃ  left outer, nel caso in cui ho la garanzia che solamente le tuple della relazione 1 ci sarÃ , contrario per right, per il full outer, ho la garanzia che una data tupla finale, sarÃ  presente in almeno uno dei due iniziali, ma non so quale.\nProprietÃ  (2) ðŸŸ© Push selection DistributivitÃ  sull\u0026rsquo;unione $$ R \\bowtie(R_{1} \\cup R_{2}) = (R \\bowtie R_{1}) \\cup(R\\bowtie R_{2}) $$ Theta Join ðŸŸ©- Il theta join viene motivato grazie al fatto che solitamente bisogna sempre rinominare prima di fare una selection, o bisogna fare sempre selection, per questo motivo. Solo che questo Ã¨ possibile fare solo se sono una #Cartesian product, ossia non abbiano attributi in comune.\nLa sintassi ammessa nella condizione sono solamente and e relazioni booleane binarie (minore, maggiore, uguale e combinazione fra questi). Altra cosa necesssaria per la theta join, Ã¨ che non ci siano attributi in comune fra le due relazioni.\nE si puÃ² notare sulle slides che questo Ã¨ molto simile alla natural join dopo renaming espresso in #Types of Joins (2) in precedenza.\nEqui Join ðŸŸ© Quello piÃ¹ interessante sono le equi-join che accade quando ho relazioni di equivalenza, questo si manifesta solamente quando la theta join di sopra Ã¨ fatta da atomi di uguaglianza, questo mi dovrebbe garantire per certo tale proprietÃ .\nCartesian product Si puÃ² considerare come una join naturale su relazioni senza attributi in comune (quindi tutto si puÃ² combinare con tutto!).\nViews Introduzione alle data-views ðŸŸ©- Sono delle rappresentazioni diverse dello stesso genere di data, solitamente utili per fare view diverse (e.g. dipartimento altro avrÃ  necessitÃ  diverse), abbiamo accennato a questa necessitÃ  durante la nostra Introduction to data-bases. Nel caso preciso di SQL ne andiamo a parlare in Advanced SQL.\nNel caso di algebra relazionale, Ã¨ soltanto una specie di dichiarazione di variabile con un altro nome, che specifica quale Ã¨ il risultato della sua query.\nView utilization Questa Ã¨ una cosa classica in informatica, il concetto di astrazione implementazione presente come descritto in Astrazione sul controllo#Significato di astrazione E dividere in questo modo quello che Ã¨ effettivamente memorizzato da quello che l\u0026rsquo;utente deve volere vedere.\nMaterialized views ðŸŸ©\u0026ndash; La differenza con l\u0026rsquo;altra tipologia di view che viene proposta Ã¨ che questa view Ã¨ storata fisicamente sui dispositivi di memorizzazione.\nPros:\nVeloce da leggere (non da creare ogni volta) Cons:\nRidondanza dei dati update deve essere doppio (problemi di coerenza) Non supportati dai DBMS. Virtual views ðŸŸ¨ Al fine di creare la view viene fatto una query sul database. Non so esattamente se questi possono essere fatti sempre o meno.\nView update ðŸŸ© Nel caso di sql possiamo andare a definire due valori local o cascade, con il primo la view non aggiorna le tabelle effettivamente presenti, mentre con cascade sÃ¬. Ma credo non si possa sempre fare e bisogna sempre stare leggermente attenti.\nSome notes on update difficulties Ãˆ molto piÃ¹ difficile updatare la view, perchÃ© questo update deve essere coerente con la versione originale che era esistente! Per questo motivo non tutti gli update sono disponibili per update.\nRelational calculi ðŸŸ¥ Si differenzia leggermente dall\u0026rsquo;al\nIntroduction to relational calculi Alla fine si basano tutti su Logica del Primo ordine, Questo Ã¨ sempre un modo per modellare le relazioni che sono molto comuni nei casi che abbiamo trovato di relational databases, ma invece di utilizzare algebra utilizzano una logica, descritta sotto.\nQuesto Ã¨ molto piÃ¹ vicino all\u0026rsquo;approccio logico, sviluppato durante gli anni 70-80 con knowledge bases in AI.\nGeneral form ðŸŸ¨+ $$ \\left\\{ A_{1}: x_{1}, \\dots A_{k} : x_{k} | f \\right\\} $$ In cui abbiamo\n$f$ che Ã¨ una formula che probabilmente da un booleano per decidere se prenderlo o meno. $A_{i}$ che sono degli attributi $x_{i}$ che sono delle variabili Avremo come output una tupla di $(x_{1}, \\dots x_{n})$ che soddisfano $f$ Esempi: Esistono forme anche leggermente piÃ¹ complicate, ma dobbiamo introdurre gli esistenziali: Esistono anche i de morgan rules che si possono applicare, perchÃ© in pratica Ã¨ logica.\nRelational calculi, considerations Aspetti negativi (2) ðŸŸ¨ Moltissime variabili inutili (troppo verboso scriverci). Presenza di espressioni senza senso e dipendenti dal dominio questo significa che se cambiamo il dominio di definizione cambiamo anche i valori che sono possibilmente denotati (non ho capito perchÃ© questa dovrebbe essere una caratteristica negativa poi). Per risolvere il primo problema si aggiunge una sintassi piÃ¹ compatta, presentata come \u0026ldquo;range declaration syntax\u0026rdquo; (ma non Ã¨ espressivo quanto algebra, in qualche modo si dimostra)\u0026hellip;\nRange declaration syntax ðŸŸ¨ Pagina 78 del libro ne parla meglio, dovrei approfondire quello. #### Indipendenza da dominio ðŸŸ¨ L\u0026rsquo;espressione $$ A_{1} : x_{1} | not R(A_{1} : x_{1}) $$ Ãˆ dipendente dal dominio, perchÃ© prende l\u0026rsquo;insieme degli elementi nel dominio, tali che non sono presenti nella relazione. Abbiamo bisogno di questa proprietÃ  perchÃ© se Ã¨ dipendente dal dominio si potrebbero produrre risultati enormi, che rendono l\u0026rsquo;applicazione pratica nulla.\nEquivalenza con Algebra relazionale ðŸŸ© Si puÃ² dimostrare che se ci limitiamo alle espressioni indipendenti col dominio, i due modelli sono esattamente uguali, ossia possiamo dire che possiamo creare una espressione di algebra, partendo da calcolo, e viceversa.\nLa dimostrazione (che non facciamo) andrÃ  per induzione strutturale, quella che trovi in Logica in Deduzione naturale.\nPossiamo notare che l\u0026rsquo;algebra Ã¨ indipendente dal dominio, perchÃ© lÃ¬ non Ã¨ mai esplicitata la relazione in che dominio sia (abbiamo operazioni chiuse si puÃ² dire).\n","permalink":"https://flecart.github.io/notes/relational-algebra/","summary":"Introduzione all\u0026rsquo;algebra relazionale Confronto con relazioni matematiche Le relazioni come le intendiamo in database sono leggermente diverse rispetto a quelle presenti per le relazioni matematiche:\nNon conta l\u0026rsquo;ordine Ci sono gli attributi Per il resto se introduciamo questo sistema per tenere conto delle astrazioni, possiamo analizzarle matematicamente, e questo ci fornisce qualche sicurezza in piÃ¹ diciamo.\nDefinition of tuples ðŸŸ© Le relazioni sono esattamente quelle definite in matematica, perÃ² noi aggiungiamo anche gli attributi, in modo da poter considerare l\u0026rsquo;ordine delle colonne non importante.","title":"Relational Algebra"},{"content":"Ripasso Prox: 23 Ripasso: December 29, 2021 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: September 22, 2021 9:38 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nTutti i ripassi per scuola\nlogica0.pdf\n0 Introduzione Lo scopo della logica Ã¨\nCorrettezza del ragionamento, anche verificata attraverso algoritmi predittivi. Si svilupperanno linguaggi logici I metodi per la veridicitÃ  di una sentenza. PossibilitÃ  e metodi del ragionamento logico Completezza e non-deducibilitÃ  di alcuni ragionamenti NecessitÃ  di completezza delle ipotesi: piÃ¹ ipotesi = ragionamento valido? Completezza delle tesi, impossibile. Una necessitÃ  della logica Ã¨ Meta-logica:\nLa logica si deve cercare di basare su certe basi, spesso queste non sono certe, perÃ² danno un certo grado di sicurezza â†’ Se la base Ã¨ solida allora tutto il ragionamento di una parte Ã¨ giusta\n0.1 Storia Questo campo di studi Ã¨ nato dopo una necessitÃ  del secolo precedente quando si tentava di dare delle basi solide alla matematica â†’ La matematica (e informatica)si fonda sulla logica.\nGuardare la storia di Russel, Godel.\n0.2 Tipologie di logica 0.3 Processo di ragionamento Slide 18 per esempio di problema risolto con questo processo.\n0.4 Differenze con la matematica La matematica si interessa principalmente sull\u0026rsquo;esistenza di soluzioni, e dimostrazioni, ma non rigorose quanto le dimostraizoni logiche. L\u0026rsquo;informatica applicata classica Ã¨ meno rigorosa, si basa principalmente sui test, anche se un logico puÃ² dimostrare la correttezza di una soluzione informatica.\nInoltre l\u0026rsquo;informatica indaga la possibilitÃ  di implementazione di alcune soluzioni matematiche, cioÃ¨ il modo per calcolare possibili soluzioni, anche con la limitatezza delle risorse.\n0.5 Logica in programmazione 0.5.1 Usi e costi C\u0026rsquo;Ã¨ un altissimo costo per la dimostrazione formale di un programma, secondo i dati Intel c\u0026rsquo;Ã¨ bisogno di circa 10x mesi uomo per creare una dimostrazione assistita di questo genere.\nPer questo genere viene utilizzato solamente in software critico cioÃ¨ il codice che controlla processi che se buggati possono creare ingenti danni economici, come centrali nucleari, smartcard, microprocessori Intel, controlli aereo e simili\n0.5.2 Processo di dimostrazione Definire la specifica del software in modo che possa fare sempre ciÃ² che deve fare Creare la semantica del programma, come il programma Ã¨ eseguito. Formula logica che Ã¨ la descrizione formale del funzionamento del programma. Creare una implicazione fra ciÃ² che il software deve fare secondo la semantica e ciÃ² che veramente fa. Non perdere punti 1 Logica Proposizionale 1.1 Senso e denotazione Sentenza\nDichiarativa quando Ã¨ assertiva, ovvero dichiara una proposizione di veritÃ . Nomi\nPuÃ² avere funzioni denotative e connotative (il senso), spesso questo concerne solamente il problema denotativo Proposizioni\nSono delle sentenze che hanno un chiaro valore di veritÃ  Possono essere atomiche o composte. esso questo concerne solamente il problema denotativo Proposizioni\nSono delle sentenze che hanno un chiaro valore di veritÃ  Possono essere atomiche o composte. ","permalink":"https://flecart.github.io/notes/introduzione-a-logica/","summary":"Ripasso Prox: 23 Ripasso: December 29, 2021 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: September 22, 2021 9:38 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nTutti i ripassi per scuola\nlogica0.pdf\n0 Introduzione Lo scopo della logica Ã¨\nCorrettezza del ragionamento, anche verificata attraverso algoritmi predittivi. Si svilupperanno linguaggi logici I metodi per la veridicitÃ  di una sentenza. PossibilitÃ  e metodi del ragionamento logico Completezza e non-deducibilitÃ  di alcuni ragionamenti NecessitÃ  di completezza delle ipotesi: piÃ¹ ipotesi = ragionamento valido?","title":"Introduzione a Logica"},{"content":"Introduzione elettromagnetismo Note storiche: triboelettricitÃ  Il concetto di campo Ã¨ fondamentale per l\u0026rsquo;elettromagnetismo (vs forza in meccanica) da un punto di vista storico Ã¨ nato tramite l\u0026rsquo;osservazione in fenomeni come lo strofinio fra vetro e pelle, dopo il quale hanno osservato ci fosse una forza nascosta (appunto ombra dal greco di electron). Il vetro si caricava poi abbastanza da poter attrarre carta per esempio. esempio dell\u0026rsquo;esperimento. Se viene fatto invece fra due lastre in vetro invece diventa repulsiva invece che attrattiva. Questo effetto Ã¨ chiamato triboelettricitÃ .\nDimensioni atomo Misure classiche dimensione atomo ðŸŸ¨ Questa Ã¨ una piccolissima sezione per dare l\u0026rsquo;intuizione su quanto sia grande in generale un atomo, confronto fra protone ed elettrone: Forza di gravitÃ  vs elettromagnetico ðŸŸ© TODO: in questa parte viene fatto un confronto fra quanto Ã¨ grande la forza di gravitÃ  contro la forza elettrica in un atomo Fatto da esempio 1.1 pagina 9 del Mazzoldi Abbiamo che la differenza in modulo della forza di gravitÃ  e forza elettrica sia molto differente (circa $10^{39}$ di differenza, quindi troppo per dire.)\nEsperimenti classici Elettroscopio a foglie ðŸŸ© [Video per l'esperimento](https://youtu.be/XXVUuW5F0xU?si=eKnTMxnoIitJdTB_) in cui vengono presentati tre casi (e tre cariche risultanti diverse). avvicinando un oggetto carico, le foglie si separavano, questa Ã¨ una carica indotta dalla presenza di un altro oggetto, allontanando rimaneva poi uguale. Se tocco, caricherÃ² con la stessa carica del mi oggetto (scambio di elettroni) Se scarico a terra, la carica presente sarÃ  l\u0026rsquo;opposta. L\u0026rsquo;angolo di separazione fra le foglie hanno permesso di misurare la carica per la prima volta. (poi probabilmente qualcosa di meccanica per calcolare).\nBilancia a torsione ðŸŸ©- Questo Ã¨ un setting un po\u0026rsquo; piÃ¹ complesso anche se l\u0026rsquo;idea Ã¨ ancora quella presente in Elettroscopio a foglie di misurare un angolo per avere la distanza. video esempio.\nL'unica cosa importante era l'angolo di torsione, da cui si poteva dedurre la forza. Poi la palla blu Ã¨ di metallo, e si puÃ² caricare. Proviamo a considerare il setting: Sappiamo che il momento torcente Ã¨ dato da $\\vec{m} = \\vec{R}\\vec{F}$ e si puÃ² dire che in modulo abbiamo $\\lvert \\vec{m} \\rvert = \\frac{L}{2} \\lvert F \\rvert \\sin \\varphi$ (questo da semplice meccanica), ma poi abbiamo anche che il momento torcente del setting (quello che va in alto Ã¨ solamente $\\lvert \\vec{M} = k \\theta \\rvert$) Quando raggiunge l\u0026rsquo;equilibrio si avrÃ  $$ \\frac{L}{2} \\lvert F \\rvert \\sin \\varphi = k \\theta \\implies \\lvert F \\rvert = \\frac{2k\\theta}{L \\sin \\varphi} $$ Da cui si puÃ² derivare la forza, e quindi sperimentalmente anche i valori di questa carica elettrica.\nLa legge di coulomb Enunciato a parole ðŸŸ© Date due cariche elettriche poste a una distanza $r$, tra di esse esercita una forza che Ã¨ direttamente proporzionale al prodotto delle cariche ed inversamente proporzionale al quadrato della distanza, tale forza Ã¨ diretta fra la congiungente delle cariche elettriche, repulsiva se i segni sono concordi e attrattiva se discordi.\nI risultati di coulomb Grazie al suo lavoro metodico di sperimentazione Ã¨ riuscito ad elaborare la legge che viene presentata subito sopra, Ã¨ riuscito a ridurre il tutto a tre proprietÃ  fondamentali\nla forza Ã¨ diretta sulla congiungente A volte Ã¨ attrattiva, altre volte repulsiva Varia inversamente al quadrato della distanza e direttamente al prodotto (questo Ã¨ riuscito a farlo con palle di metallo che spezzano la carica in due) $$ \\lvert \\vec{F} \\rvert = k \\frac{Q_{0}Q_{1}}{r^{2}} $$ Con questa costante qui che non Ã¨ piÃ¹ adimensionale come nel caso della costante elastica di torsione, ma Ã¨ stato nel tempo scoperto essere dipendente dalla costante dielettrica del vuoto, di cui capiremo un po\u0026rsquo; meglio quando andremo a parlare di dielettrici in seguito. Una analisi dimensionale ci darÃ  che l\u0026rsquo;unitÃ  di misura di quello Ã¨ $\\frac{Nm^{2}}{C^{2}}$.\nCostante dielettrica del vuoto ðŸŸ© Bisogna ricordarsi il valore della costante a memoria! Anche la sua dimensione!\nAltra analisi di cui non so la derivazione si avrÃ  che $$ k = \\frac{1}{4\\pi \\epsilon_{0}} = 8.99 \\cdot 10^{8} N \\frac{m^{2}}{c^{2}} $$ Mentre la $\\epsilon_{0}$ costante dielettrica del vuoto vale $$ \\varepsilon_{0}=8.85 \\cdot 10^{-12}\\frac{C^{2}}{N m^{2}} $$ Sulla carica Come proprietÃ  della materia ProprietÃ  (2) ðŸŸ© La carica Ã¨ una proprietÃ  intrinseca della materia, esattamente come la massa, se consideriamo protoni ed elettroni, questi sono la piÃ¹ piccola unitÃ  di carica possibile.\nCostante, questo significa che se il sistema Ã¨ isolato, la quantitÃ  di carica non cambia mai Invariante fra sistemi di riferimento, se lo guardo da un sistema di riferimento che si muove e non (quindi stiamo parlando di meccanica), questa carica non cambia. Subatomica (no) Si puÃ² dire che un protone e un neutrone Ã¨ formato da quark, anche se non so esattamente cosa siano, puoi trovare una immagine negli appunti di Matti in questo modo:\nCarica protoni ed elettroni ðŸŸ© Stiamo provando a rispondere alla domanda perchÃ© la carica di elettroni e protoni Ã¨ uguale? Proviamo a ragionare per assurdo, assumendo le costanti che conosciamo giÃ  sopra nella sezione sui risultati di coulomb.\nSupponiamo ci sia una differenza di carica fra protoni ed elettroni, anche piccolissima, mettiamo caso sia $1.6 \\cdot 10^{-28}C$, e consideriamo due palle di ferro puro di massa $1Kg$ e raggio $1m$, allora dato che la $\\Delta q \\neq 0$ si avrÃ  una forza, che sarÃ  di $k \\Delta q \\frac{\\Delta q_{2}}{r^{2}}$, considerando che il ferro nella tavola periodica ha $Z=26$ ossia il numero totale di protoni e $A=55$, il numero di massa, avremo che $\\Delta Q = N_{protoni}\\cdot \\Delta q$, e da questo si puÃ² ricavare un valore simile a $0,0455 C$, e considerando che $N_{p} = z \\cdot N_{atomi} = Z \\cdot \\frac{M}{A} N_{a}$ dove l\u0026rsquo;ultimo Ã¨ il numero di avocadro credo, la forza che sarebbe presente sarebbe di circa $1.7 \\cdot 10^{7} N$, e si avrebbe il terzo principio della dinamica, ma sperimentalmente non esiste questa forza\nPrincipio di sovrapposizione Enunciato del principio di sovrapposizione Questo Ã¨ uno dei metodi principali che sarÃ  utilizzato per calcolare il Campo elettrico, dice semplicemente che i vettori della forza di Coulomb si possono semplicemente sommare fra di loro $$ \\frac{1}{4\\pi\\varepsilon_{0}} Q_{p} \\sum_{i=1}^{N} \\frac{q_{i}}{r_{i}^{2}} \\hat{r}_{ip} $$ Questa stessa idea si puÃ² utilizzare senza nessun problema anche nel caso in cui ho volumetti carichi\nDensitÃ  volumetrica di carica ðŸŸ© $$ \\rho(\\vec{r}) = \\lim_{ \\Delta \\tau \\to 0 } \\frac{\\Delta q}{\\Delta \\tau} = \\frac{dq}{d\\tau} \\implies \\rho(\\vec{r}) d\\tau = dq $$ Andando a considerare gli infinitesimi\nDensitÃ  superficiale di carica ðŸŸ© Il concetto Ã¨ uguale al precedente, solo che ora andiamo a considerare una superficie, e non un volume infinitesimale $$ \\rho(\\vec{r}) = \\lim_{ \\Delta s \\to 0 } \\frac{\\Delta q}{\\Delta s} = \\frac{dq}{ds} \\implies \\rho(\\vec{r}) ds = dq $$ DensitÃ  lineare di carica ðŸŸ© Stesso concetto per la lineare, ma anche qui non lo riscrivo perÃ², scrivo perÃ² l\u0026rsquo;equivalente dell #Enunciato del principio di sovrapposizione per piÃ¹ facile comprensione. $$ \\vec{F}_{l} = \\frac{1}{4\\pi \\varepsilon_{0}} Q_{p} \\int _{l} \\frac{\\lambda(\\vec{r})}{\\Delta r^{2}} \\hat{\\Delta}r \\, dl $$ Integrale lineare\n","permalink":"https://flecart.github.io/notes/legge-di-coulomb/","summary":"Introduzione elettromagnetismo Note storiche: triboelettricitÃ  Il concetto di campo Ã¨ fondamentale per l\u0026rsquo;elettromagnetismo (vs forza in meccanica) da un punto di vista storico Ã¨ nato tramite l\u0026rsquo;osservazione in fenomeni come lo strofinio fra vetro e pelle, dopo il quale hanno osservato ci fosse una forza nascosta (appunto ombra dal greco di electron). Il vetro si caricava poi abbastanza da poter attrarre carta per esempio. esempio dell\u0026rsquo;esperimento. Se viene fatto invece fra due lastre in vetro invece diventa repulsiva invece che attrattiva.","title":"Legge di Coulomb"},{"content":"Ripasso Prox: 7 Ultima modifica: December 29, 2022 3:24 PM Primo Abbozzo: August 13, 2022 5:03 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso August 25, 2022\nRappresentazione della conoscenza Questo Ã¨ stato un capitolo molto vasto, che andava in certi punti a toccare la filosofia, la fisica. Un aspetto, quello di codifica delle informazioni reali in un ambiente logico (che per quanto i miei pregiudizi siano, ritengo una cosa molto impossibile, molto limitata e altrettanto impossibile). Si tratta dello studio della logica per rappresentazione di conoscenza.\nFatto sta che mi sembra assurdamente teorico tanto da non aver nessun utilizzo (probabilmente mi sbaglio di grosso), e che sia roba da filosofi.\nCredo che questo capitolo sia sopratuttto importante per i pattern di rappresentazione di certe cose.\nOntologia PuÃ² fare comodo questa pagina di wikipedia,.\nUn ontologia organizza tutto il mondo in una gerarchia di categorie.\nIl libro non fornisce mai una definizione dettagliata di ontologia, definisce solamente il suo scopo, che Ã¨ quello di dare una struttura agli oggetti che possiamo trovare tutti i giorni (cani, gatti, frutta, pomodori) e li mette ognuna in qualche categoria precisa.\nCredo (questa Ã¨ una mia interpretazione che non esiste, o almeno non ho trovato nel libro), che lâ€™ontologia descriva la struttura tutto quanto puÃ² esistere nel mondo creato. Quindi se ti dico Banana, tu puoi subito mettere nel cassetto giusto questo oggetto e averne molte proprietÃ , ma non sono sicuro che sia ciÃ² che intenda il libro Norvig, perÃ² di sicuro propone alcuni modi per rappresentare oggetti come Eventi, tempo, credenze, oggetti fisici, credo siano questi 4 i fulcri del capitolo, come rappresentare queste cose astratte.\nUpper ontology Lâ€™ontologia elevata Ã¨ una rappresentazione grafica di una possibile ontologia. (credo che una ontologia sia piÃ¹ o meno quello che descrive il mondo costruito in quel determinato istante).\nCaratteristiche di un ontologia generale\nApplicabilitÃ **,** dovrebbe essere applicata a qualunque istanziazione concreta di oggetto. RiutilizzabilitÃ , dovrebbe avere in sÃ© concetti abbastanza generati che possono essere utilizzati in piÃ¹ modi (esempio il concetto di tempo lo puoi usare come misurazione della durata, ma anche del costo dellâ€™evento). Ma sembra che sistemi simili non siano stati molto famosi (câ€™Ã¨ un fattore umano che non permette la creazione di ontologie generali).\nCategorie Le categorie sono come degli insiemi grossi che accomunano oggetti con certe proprietÃ . PerÃ² noi stiamo utilizzando la Logica del Primo ordine e quindi una categoria Ã¨ un particolare predicato, che puÃ² essere reificato in un oggetto (ossia invece di tenerti il concetto astratto, definisci tutto quello che serve per poterlo rappresentare, proprio come se fosse una conversione).\nLa cosa bella Ã¨ che esistono sottocategorie, che prendono in AUTOMATICO tutte le proprietÃ  delle proprie super-categorie\nDecomposizione delle categorie Possiamo andare a definire delle partizioni (molto simile a quelle in teoria degli insiemi, anzi direi che il concetto Ã¨ praticamente lo stesso lol).\nDisgiunzione (se non hanno nessun elemento in comune) Decomposizione esaustiva (se la loro unione Ã¨ lâ€™elemento iniziale) Partizione (se a due a due sono disgiunti e vale anche 2). Se sai teoria degli insiemi credo che per questa parte non câ€™Ã¨ nulla da dire\nRappresentazione di oggetti fisici Sono molto importanti le funzione bunchOf, partOf che definiscono un insieme di cose (che possono essere ad esempio 3 mele, o una parte di essa, come la gamba Ã¨ una parte del corpo)\n(poi su part of puoi fare la decomposizione come per le categorie, il concetto credo sia esattamente lo stesso).\nMisurazione Di solito per la misurazione ti tieni una funzione di unitÃ  che restituisce il valore di unitÃ  astratto, questa poi la puoi andare ad eguagliare allâ€™unitÃ  specifiche, come il metro, il pollice, la spanna etc.\nquindi as esempio $lunghezza(L) = metro(1) = pollici(39,3701)$ etc. e questa cosa la fai per tutti. Ãˆ una misurazione piÃ¹ astratta possibile.\nSecondo il libro questo Ã¨ un campo molto sviluppato in fisica quantitativa, anche se Milanese ha cringiato quando lâ€™ho condiviso.\nCategorie naturali Le categorie naturali sono molto difficili da definire con delle regole esatte come stiamo provando con la logica (lâ€™essere umano Ã¨ molto ambiguo a riguardo). Potremmo solo definire qualcosa di tipico e se soddisfa queste proprietÃ  chiamarlo Banana e simili. Comunque questa parte sembra essere stato analizzato per benino da Wittgenstein 1953.\nOggetti I concetti di maggiore importanza da capire degli oggetti Ã¨ che certi oggetti, anche se divisi, mantengono ancora la propria sostanza, un esempio di questo Ã¨ un butto, mentre invece esseri umani non lo sono (una mano o gamba non sono un essere umano, mentre un pezzo di burro Ã¨ ancora burro).\nQuindi differenza fra stuff and things.\nOltre a ciÃ² lâ€™esistenza di proprietÃ  intrinseche ed estrinseche, ossia cose che sopravivivono o meno alla suddivisione\nEventi Le relazioni di maggiore imoprtanza per rappresentare gli eventi sono questi\nSe hai queste proprietÃ  definite, puoi proprio avere un sistema di calcolo degli eventi per descrivere quanto accade durante qualcosa, mentre in passato col fluente potevi solamente descrivere cosa câ€™era prima o dopo\nTempo No comment, questi sono quelle cose di cui hai bisogno per descrivere il tempo (si noti che si utilizza una funzione di misura descritta in precedenza).\nNota dei fluenti con oggetti\nÃˆ difficile che lâ€™oggett Presidente identifichi una certa persona, perchÃ© questa persona cambia nel tempo, quindi teniamo questo come se fosse una classe astratta. E una funzione che prende come input il tempo dâ€™inizio e di fine e una persone e ti dice se Ã¨ vero o falso se questa persona era presidente in questo periodo di tempo.\nLogica modale La logica modale permette la rappresentazione metaconoscitiva ossia la conoscenza del conoscere.\nIntroduce il concetto di operatore modale (che in pratica Ã¨ come se fosse un punto di vista, un frame of reference), che Ã¨ come se restringesse il campo di conoscenza al singolo operatore.\nSemantica\nLa semantica di questa logica cambia totalmente, ora si puÃ² dire che un modello Ã¨ vero, se Ã¨ vero in tutti i mondi accessibili, non tutti i mondi possibili. Un mondo Ã¨ accessibile quando non sa nulla su di essa.\nesempio se so A, allora questo Ã¨ accessibile nel mondo A and not B, ma anche al mondo A and B, e sarebbe vera in entrambi i mondi quindi OK.\nOnniscienza\nIl problema di questa logica Ã¨ che lâ€™agente conosce tutto quello che puÃ² sapere, automaticamente si ricava tutte le inferenze possibili da suo campo di sapere, questo Ã¨ alquanto irrealistico (altrimenti lâ€™essere umano, lol, potrebbe conoscere tutte le conseguenze della matematica per esempio, perchÃ© tanto sono tutte inferenze da basi conosciute, ma Ã¨ chiaro che sia qualcosa di altamente irrealistico.\nSistemi di ragionamento su categorie Network semantici Allâ€™inizio della loro creazione, i network semantici erano in forte discussione con la logica, ma si Ã¨ poi notato a posteriore che non sono altro che la stessa cosa, ma formulati in modo molto differente.\nI network semantici permettono una bella e semplice visualizzazione dei concetti\nEsempio di un network semantico\nQuesti si comportano bene per lâ€™ereditarietÃ  (che puoi andare a sovrascrivere come se stessi lavorando su un OOP). perÃ² ha problemi con la eridarietÃ  molteplice, perchÃ© ci sarebbe ambiguitÃ  se entrambi i genitori condividono una informazione, ma sono contrarie uno dallâ€™altra.\nLogica descrittiva Non Ã¨ altro che una logica di primo ordine semplificata nella verbositÃ , soprattuto per i concetti di almeno n elementi e simili.\nInformazioni di default Spesso torna molto comodo nella semantica del database (in cui Ã¨ a mondo chiuso, tutto quello che non conosci espressamente Ã¨ negato) avere delle informazioni di default in esse, e questo si puÃ² raggiungere principalemtne in due modi ora presentati molto velocemente\nCircoscrizione mah, non lâ€™ho proprio capita\nLogica di default Ovvero se vengono soddisfatte delle premesse, e la conseguenza non Ã¨ assurda, allora conoscerÃ² questa conseguenza.\nEsempietto\nTruth maintenance systems I sistemi come JTMS (Justification-based truth maintenance system) che tengono per tutte le inferenze che hanno una spiegazione ossia le regole usate per inferire questa cosa, quando si aggiorna tale sistema bisogna andare a togliere tutte le regole che hanno questa altra nella spiegazione .\nUn suo amico stretto Ã¨ ATMS(assumption-based truth maintenance system) in cui per colmare lâ€™inesistenza di qualcosa si ha qualche regola di default (credo di stare sbagliando in questo passo) ma comunque non Ã¨ molto importante ed Ã¨ molto probabile che stia semplificando troppo in questa parte\n","permalink":"https://flecart.github.io/notes/rappresentazione-della-conoscenza/","summary":"Ripasso Prox: 7 Ultima modifica: December 29, 2022 3:24 PM Primo Abbozzo: August 13, 2022 5:03 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso August 25, 2022\nRappresentazione della conoscenza Questo Ã¨ stato un capitolo molto vasto, che andava in certi punti a toccare la filosofia, la fisica. Un aspetto, quello di codifica delle informazioni reali in un ambiente logico (che per quanto i miei pregiudizi siano, ritengo una cosa molto impossibile, molto limitata e altrettanto impossibile).","title":"Rappresentazione della conoscenza"},{"content":"Ripasso Prox: 40 Ripasso: May 20, 2023 Ultima modifica: April 10, 2023 2:32 PM Primo Abbozzo: January 26, 2023 10:00 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nReinforcement Learning Introduzione Una delle idee migliori riguardanti questo campo del reinforcement learning Ã¨ il focus sul processo decisionale del singolo agente, condizionato al reward che lâ€™ambiente esterno gli dÃ  (feedback). Il setting classico di questo genere di problemi Ã¨ un caso speciale della caratterizzazione presente in lâ€™intelligenza.\nAbbiamo in questo caso un agente allâ€™interno del suo ambiente. Lâ€™agente Ã¨ in grado di interagire col suo ambiente attraverso alcune azioni ben definite, e lâ€™ambiente restituisce un feedback ad ogni azione. Lâ€™agente si regola di conseguenza, nel tentativo di massimizzare il reward che riceve.\nÃˆ da notare che questa impostazione Ã¨ molto diversa rispetto al machine learning classico, seppur si puÃ² comunque collocare al suo interno. Classifcamente nei modelli di machine learning supervised si cerca di minimizzare un errore con alcuni dataset etichettati, mentre qui non abbiamo nessuna etichetta, mentre nel unsupervised proviamo a trovare alcuni pattern nei dati, mentre qui non cerchiamo nessun pattern. Si potrebbe dire che questo sia un terzo paradigma di machine learning.\nNOTA: questi appunti riassumono concetti dai primi 4 capitoli del Sutton and Barto 2020\nUn problema classico: n-bandit Vedere N-Bandit Problem.\nSetting classico (Model Policy Reward) Quando andiamo a parlare di Reinforcement learning andiamo a considerare un setting classico di agente che interagisce con un ambiente attraverso delle azioni, e lâ€™ambiente che risponde attraverso i reward. Lâ€™agente osserva quindi lo stato (se Ã¨ full-observable vede lo stato esterno, altrimenti partially observable vede solamente parte delle informazioni dello stato dellâ€™ambiente) e insieme al reward percepito prova a eseguire delle altre azioni.\nSono particolarmente importanti quindi 3 parole chiave utili per descrivere una delle 3 frecce in immagine\nModel Il modello dell\u0026rsquo;ambiente lo indichiamo anche come dinamica o sistema di transizione dellâ€™ambiente. nel modello sono definite tutte le distribuzioni di probabilitÃ  che portano uno stato a un altro: $P(s'|s)$, questo possiamo dire, ossia partendo da uno stato s, quanto Ã¨ probabile finire in uno stato sâ€™ ??\nQuesto Ã¨ quello che ci dice il modello.\nPolicy La policy Ã¨ un indicatore delle azioni del singolo agente, ci dice quanto Ã¨ probabile che lâ€™agente esegua una certa azione, dato che sia sopra un certo stato s, lo indichiamo solitamente con $\\pi(a | s)$. Nel caso in cui Ã¨ una policy deterministica, nel senso che a uno stato corrisponde uno e un solo azione, potremmo scrivere qualcosa del tipo $\\pi (s) = a$\nReward Il reward descrive il feedback che lâ€™ambiente ritorna al giocatore una volta che una azione Ã¨ stata eseguita, spesso lo indichiamo in questi modi\n$$ r(s, a) \\\\ r(s, a, s') \\\\ r(s) $$ A seconda di quanto vogliamo esprimere (quindi il reward atteso dopo aver fatto una azione da unc erto stato, il reward atteso dopo aver fatto una azione da un certo stato ed essere arrivati a un certo stao e cosÃ¬ via\nThe Value function Associamo ad ogni stato un reward $r$, si avrÃ  una history ossia una sequenza di $O, A, S$ osservazione dall\u0026rsquo;ambiente, azione fatta e stato presente. Ad ogni stato avrÃ² un reward. quindi $$ v_{i}(S_{j}) = \\mathbf{E} [r_{i} + r_{i + 1} + \\dots | S_{j}] $$ Ossia se io al passo $i$ sono sullo stato $S_{j}$ la value function per quello stato Ã¨ il valore atteso dei rewards tutti successivi. Questo si puÃ² scrivere in maniera piÃ¹ compatta come $$ v_{i}(S_{j}) = \\mathbf{E} [r_{i} + v_{i+1}(S) | S_{j}] $$ Con $S$ uno stato su cui puoi essere al passo successivo.\nAll components are functions:\nPolicies: $\\pi: S \\rightarrow A$ (or to probabilities over A) Value functions: $v: S \\rightarrow R$ Models: $m: S \\rightarrow S$ and/or $r: S \\rightarrow R$ State update: $u: S \\times O \\rightarrow S$ Categorie di agenti Policy - Value categorization Value Based ha solamente value based, la sua policy Ã¨ basata sul suo valore (in modo greedy va a cercare quale sia lo stato con valore maggiore)\nPolicy based Il contrario, non ha value function, ma solamente la policy\nActor Critic Ha entrambi, ha sia policy (l\u0026rsquo;attore) e il critico che cerca di aiutare\nModels Model free Se hanno policy o value, ma non hanno nessun modello sull\u0026rsquo;ambiente in cui sono presenti\nModel based Hanno il modello dell\u0026rsquo;ambiente, e non necessariamente hanno policy o value function.\nPrediction and control Prediction Ã¨ la capacitÃ  di sapere come sarÃ  il futuro Control Ã¨ la capacitÃ  di ottimizzare la propria value function. Solitamente sono molto legati fra di loro.\nMarkov chains Dovrebbe essere approfondito meglio in Markov Chains\nMarkov property ðŸŸ© Uno stato si puÃ² dire di godere della proprietÃ  di markov se, intuitivamente parlando, possiede giÃ  tutte le informazioni necessarie per predire lo stato successivo, ossia, supponiamo di avere la sequenza di stati $(S_n)_{n \\in \\N}$, allora si ha che $P(S_k | S_{k-1}) = P(S_k|S_0S_1...S_{k - 1})$, ossia lo stato attuale in Sk dipende solamente dallo stato precedente.\nNormalmente poche cose nel mondo reale si possono dire puramente Markoviane, perÃ² non si puÃ² negare che Ã¨ un modello molto buono di partenza come modello di decisione.\nma potremmo sempre rendere Markoviano creando una nuova variabile che ci rappresenta tutta la storia (Ã¨ qualcosa che non ho capito molto bene, ma credo si possa fare senza probbi).\nMarkov processes ðŸŸ¨- Possiamo andare a definire un processo markoviano come un insieme di stati e il modello di transizione probabilistico: $(S, P)$, una coppia di stati e tutto il modello di transizione. mi sembra di aver letto che un processo markoviano sia molto buono per studiare i moti browniani in fisica. Praticamente a random abbiamo che ogni punto si puÃ² muovere\nEsempio di processo markoviano\nMarkov Reward Processes (!!!) Quando andiamo a parlare di processo markoviano con reward indichiamo che associamo una funzione valore $V(s)$ che restituisce un certo valore a ogni stato. Di solito questo valore ci Ã¨ ignoto a noi agenti che seguiamo iil modello, quindi diventa un buon problema in questo setting provare a stimare il valore dello stato in seguito a numerose osservazioni. Solitamente non vogliamo considerare tutti i reward con lo stesso peso. Vorremmo avere anche a disposizione un parametro che ci indichi quanto siano importanti i reward subito di ora, e i reward nel futuro. Con questo indichiamo un discount factor $\\gamma$\nUn tale processo viene formalizzato tramite una quadrupla $S, P, R,\\gamma$, con s stati possibili, P il modello di transizoine e R la funzione che ritorna il reward per ogni stato.\nSolitamente viene definito state value function:\n$$ V(s) = \\mathbb{E}[R_t + \\gamma R_{t + 1} + \\gamma^2 R_{t + 2} + ... | s = s _{t}] $$ La parte dentro il valore atteso Ã¨ solitamente indicata con $G_t$.\nMetodi di estimazione della funzione valore:\nAbbiamo abbastanza metodi per stimare il valore della funzione: metodi di sampling, metodi diretti (analitici) e metodi basati su programmazione dinamica.\nRiguardo i metodi di sampling questi sono i piÃ¹ dinamici, nel senso che permettono lâ€™applicazione a piÃ¹ problemi possibili, in generale hanno una precisione che va nellâ€™ordine dell $\\dfrac{1}{\\sqrt {n}}$ anche se non so su quali basi in particolare.\nI metodi diretti sono leggermente piÃ¹ lenti, perchÃ© si tratta di risolvere lâ€™inversa della matrice, cosa che va in $O(n^3)$. Il motivo di questo Ã¨ che possiamo sfruttare la proprietÃ  di V\nOssia possiamo dire che\n$$ V_k(s_t) = \\mathbb{E}[R_t + \\gamma G_{t + 1} | s = s _{t}] = R(s) + \\gamma \\sum_{s'}P(s'|s)V_{k -1}(s') $$ Questa osservazione permette di sviluppare un algoritmo iterativo per stivare il V fino a convergenza (sul perchÃ© converge sicuramente guardare altro, prolly idea degli operatori di bellman puÃ² essere utile)\nAlgoritmo iterativo per valutazione della MRP\nSoluzione analitica:\nUtilizzando la stessa proprietÃ  (solamente ora scritta in modo analitico, possiamo risolverlo come se fosse una matrice\nSoluzione analitica\nMarkov Decision Process Questo Ã¨ molto simile alla MRP, solo che ora introduciamo una policy, ossia una funzione che ci dica quanto Ã¨ probabile compiere una certa azione in un certo stato\n$(S, A, P, R, \\gamma)$, ossia ora abbiamo sia stato, sia azione possibile e la funzione di transizione deve contare entrambi: $P(\\cdot | s, a)$, mentre le reward sono ancora come prima.\nS lâ€™insieme di stati possibili A lâ€™insieme di azioni possibili P probabilitÃ  di raggiungereun certo stato, dato uno stato inizial e una azione R reward di uno stato gamma: decadimento del reward. Ãˆ da notare che se possediamo una policy, allora possiamo ridurci al caso di Markov Reward Process, infatti possiamo dire che\n$$ R^\\pi(s) = \\sum_{a \\in A}\\pi(a | s)R(s) \\\nP^\\pi(s\u0026rsquo;|s) = \\sum_{a \\in A} \\pi(a | s) P(s\u0026rsquo;|s, a) $$\nQuindi data una policy possiamo utilizzare gli argomenti fatti di sopra e riuscire a dare una valutazione di essa\nAlgoritmo iterativo DP per policy evaluation\nPolicy Search Cerchiamo ora la policy migliore possibile da applicare a un MDP, questo Ã¨ il problema del policy control ora che sappiamo come fare policy evalutation Ã¨ il momento giusto per introdurre soluzioni a questo problema.\nUna soluzione naÃ¯ve Ã¨ semplicemente enumerare tutte le policy e utilizzare lâ€™algoritmo di policy evaluation, poi andare a vedere quale sia la migliore. Questo Ã¨ molto dispendioso perchÃ© assumento che posso applicare tutto lâ€™insieme di azioni a tutti gli stati ho potenzialmente $|S|^{|A|}$ policy possibili,, che sono troppi , e troppo brutti.\nÃˆ bene raggiunti questo punto provare a dare alcune definizioni utili.\nDefinitions: state-action-value, optimal value policy Sia $\\pi$ una policy e $V^\\pi$ la evaluation di quella policy, allora possiamo andare a definire la state-action-value function in questo modo:\n$$ Q(s, a) = R(s, a) + \\gamma \\sum_{s'} P(s'|s, a)V^\\pi(s') $$ ossia ci dice piÃ¹ o meno il valore atteso dellâ€™azione a un certo stato!\nPossiamo anche definire la policy migliore:\n$$ \\pi^*(s) = argmax_{\\pi} V^\\pi(s) $$ Ossia Ã¨ la policy che rende massimo il valore in qualunque stato!\nPolicy iteration and his monotonicity Una volta creato una policy iteration, Ã¨ una cosa molto sensata andare a definire una nuova policy $\\pi_{k + 1}$ definita in questo modo:\n$$ \\forall s, \\pi_{k + 1}(s) = argmax_a Q(s, a) $$ Ossia andiamo proprio a crearci una nuova policy, cercando di rendere maggiore possibile il valore atteso a fare una certa azione a uno stato! Riusciremo a dimostrare che $\\forall s, V^{\\pi_{k + 1}}(s) \\geq V^{\\pi_{k}}(s)$\nDimostrazione dal sutton e barto\nlâ€™idea principalmente Ã¨ prendere sempre il massimo volta dopo volta, e dimostrarlo per induzione in praticaâ€¦ Anche non ho capito come formalizzare e non ho capito se posso trarne vantaggi didattici nella formalizzazione di questa merda\nValue Iteration Lâ€™idea di value iteration Ã¨ sostituirla subito, cioÃ¨ non stare a sviluppare fino in fondo la value evaluation, ma aggiornare la policy subito dopo.\nPseudocodice value iteration\nBellman operator Slide Si puÃ² dimostrare che questo operatore Ã¨ una contrazione, quindi value iteration converge qualunque sia il punto di partenza\nCon questo operatore, possiamo anche riscrivere in modo migliore la policy evaluation\nSlide\nProof of contraction of bellman operator\n","permalink":"https://flecart.github.io/notes/reinforcement-learning-a-introduction/","summary":"Ripasso Prox: 40 Ripasso: May 20, 2023 Ultima modifica: April 10, 2023 2:32 PM Primo Abbozzo: January 26, 2023 10:00 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nReinforcement Learning Introduzione Una delle idee migliori riguardanti questo campo del reinforcement learning Ã¨ il focus sul processo decisionale del singolo agente, condizionato al reward che lâ€™ambiente esterno gli dÃ  (feedback). Il setting classico di questo genere di problemi Ã¨ un caso speciale della caratterizzazione presente in lâ€™intelligenza.","title":"Reinforcement Learning, a introduction"},{"content":"Ripasso Prox: 45 Ripasso: December 22, 2021 Ultima modifica: October 27, 2022 12:17 PM Primo Abbozzo: October 15, 2021 12:53 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso la caratteristica che contraddistingue DFF e Latch D Se hai voglia approfondisci la costruzione di una memoria (reale) December 14, 2021 3:43 PM 7 Circuiti sequenziali 7.1 Introduzione 7.1.1 PerchÃ© usarli Sono utili per mantenere delle informazioni nel tempo\n7.1.2 Caratteristiche Hanno feedback cioÃ¨ ci sono degli output che tornano dentro al circuito, quindi Ã¨ molto difficile senza sapere niente cosa succede dentro\nQuesto circuito non Ã¨ combinatorio, che Ã¨ formalizzabile in modo deterministico con l\u0026rsquo;lgebra booleana.\n7.1.3 Il Bit di memoria Questo bit ha due input, un load e un input, se il load Ã¨ attivo comincia a storare, altrimenti l\u0026rsquo;output Ã¨ sempre il bit che ha memoriazzato.\n7.2 Latch 7.2.1 Latch SR Con 0 0, qualunque bit ci sia, rimane sto bit che gira.\n1 1 = reset, 0 0 , NON FARLO\nQuesto Ã¨ uno dei piÃ¹ semplici circuiti non sequenziali. Se l\u0026rsquo;input sono diversi fra di loro, allora sappiamo cosa esce,\nMa nel caso in cui l\u0026rsquo;input Ã¨ 0 0 oppure 1 1 allroa non va bene.\n7.2.2 Latch SR temporizzato e clock Il clock serve per stabilizzare la ram, il clock (voglio prendere solamente dei valori che siano stabili)\n7.2.3 Latch D Questo latch possiede un unico input per impedire che sia possibile che si verifichi\nil caso 1, 1, che non ci piace.\n7.2.4 D-Flip Flop Ãˆ uguale al Latch D ma solo con qualcosa in piÃ¹, dovrebbe sempre tornare in Zero il clock, perÃ² il Not ha un pÃ² di delay, che permette un velocissimo segnale a passare\nQuindi questo circuito carica solamente quando c\u0026rsquo;Ã¨ il clock che gli va, e permette il loading di qualcosa, quindi effettivamente riesce a mantenere il bit in memoria.\nQUesto Ã¨ migliore perchÃ© con il flipflop ho piÃ¹ tempo per far stabilizzare i dati, invece di poter caricare per l\u0026rsquo;intero tempo in cui clock Ã¨ su, posso farlo in un solo piccolo frangente (ma sufficiente)\nHo un intero ciclo di clock per farlo stabilizzare, invece per il latch solo metÃ  (in quanto l\u0026rsquo;altra metÃ  Ã¨ di caricamento)\n7.3 Registri e RAM 7.3.1 Registro Questi il DFF Ã¨ il componente principale per il registro, che messo insieme ad altro Ã¨ in grado di creare la memoria RAM necessaria per far funzionare.\nin\nX\n0\n0\n1\n1\nload\nX\n0\n1\n0\n1\nclock\nNull\nSalita\nSalita\nSalita\nSalita\nout[N]\nMem\nout[N-1]\n0\nout[N-1]\n1\nDa notare che l\u0026rsquo;out vale il valore di in solo nel caso in cui il load Ã¨ 1 e il clock sta permettendo di salvare il dato.\nPer il resto Ã¨ sempre memoria.\n7.3.2 Program counter 7.3.3 chip RAM Il ram Ã¨ costruito da una serie di registri. In Input puÃ² avere il valore in in, l\u0026rsquo;indirizzo in cui si vuole scrivere e un booleano che dice se vogliamo scrivere o no.\nCi saranno demultiplexer che indirizzeranno l\u0026rsquo;in al registro giusto. In out ho solamente l\u0026rsquo;out di questo registro, quindi devo anche filtrare fra l\u0026rsquo;output di tutti gli altri registri in quanto voglio solamente uno.\n7.4 Il microprocessore HACK In questo schema si possono vedere tutti gli elementi principali per il processore HACK, come ALU, program counter, il decoder e simil.\nUna caratteristica principale Ã¨ la ROM di HACK (noi oggi abbiamo solamente una ROM per boostrap, ma invece in HACK deve avere solo ROM per le istruzioni).\noutM Ã¨ il mit della memoria che viene fuori\n7.4.1 Accesso ai dati in memoria S, D, RAM Questa parte si puÃ² considerare un approfondimento di una zona in Memoria.\nParliamo d SRAM e DRAM.\nSRAM si parla di Cache, sono piÃ¹ costose rispetto alle memorie ram dinamiche\nDRAM Ã¨ la memoria principale, fatte con transistor e un condensatore. (contiene una carica per un pÃ² di tempo)\nEcco che allora DRAM ha bisogno di Refresh! In modo che il condensatore venga ricaricato.Questo rallenta anche la velocitÃ  del ram, ma si guadagna in economia\n7.5 Altro Abbiamo fatto anche altro riguardo a questa lezione.\nDa notare principalmente Ã¨ il funzionamento della cache qui di cui abbiamo anche fatto degli esercizi.\nPoi la predizione di pipelining distrutta dai salti nelle istruzioni presentata qui almente Ã¨ il funzionamento della cache qui di cui abbiamo anche fatto degli esercizi.\nPoi la predizione di pipelining distrutta dai salti nelle istruzioni presentata qui\n","permalink":"https://flecart.github.io/notes/circuiti-sequenziali/","summary":"Ripasso Prox: 45 Ripasso: December 22, 2021 Ultima modifica: October 27, 2022 12:17 PM Primo Abbozzo: October 15, 2021 12:53 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso la caratteristica che contraddistingue DFF e Latch D Se hai voglia approfondisci la costruzione di una memoria (reale) December 14, 2021 3:43 PM 7 Circuiti sequenziali 7.1 Introduzione 7.1.1 PerchÃ© usarli Sono utili per mantenere delle informazioni nel tempo\n7.1.2 Caratteristiche Hanno feedback cioÃ¨ ci sono degli output che tornano dentro al circuito, quindi Ã¨ molto difficile senza sapere niente cosa succede dentro","title":"Circuiti Sequenziali"},{"content":"Introduzione ai condensatori Analisi introduttiva condensatori: tubi di flusso ðŸŸ© Consideriamo un **tubo di flusso infinitesimo** come in immagine. abbiamo che $dQ$ Ã¨ la carica totale dentro al cubo. Tale che segua le linee di campo. Il flusso totale sarebbe $$ \\oint_{\\Sigma} \\vec{E} \\cdot d\\vec{s} = \\frac{Q_{T}}{\\varepsilon_{0}} $$ Sappiamo anche che $$ \\vec{E}_{1}d\\vec{s}_{1} + \\vec{E}_{2}d\\vec{s}_{2} = \\frac{dQ_{T}}{\\varepsilon_{0}} $$ Ma scegliamo il cubo di flusso in modo che le superfici siano **perpendicolari al nostro campo**, e cosÃ¬ posso considerare il problema da un puro punto di vista **scalare**. Sapendo che nell'esempio sott il campo non Ã¨ esistente, allora posso scrivere il campo elettrico che va fuori, semplicemente in punto di vista scalare: $$ E_{2} = \\frac{dQ}{\\varepsilon_{0}ds_{2}} $$ esChe Ã¨ molto molto simile alla forma $\\frac{\\sigma}{\\varepsilon_{0}}$. il parametro di nostro interesse in questo esempio (almeno la cosa di nostro interesse) Ã¨ *il concetto di distanza*, se ci allontaniamo dalla nostra superficie, $dS_{2}$ diventa piÃ¹ larga Introduzione ai condensatori ðŸŸ© Poniamo di avere due armature metalliche qualsiasi, che abbiamo cariche uguali ed opposte in segno di una forma qualunque a distanza qualunque, in questo setting teorico. La cosa interessante Ã¨ che suppongo di avere #Induzione completa in questo caso. Ãˆ una necessitÃ  per l\u0026rsquo;analisi dei condensatori.\nPotenziale elettrico e carica ðŸŸ¨+ Proviamo a seguire una linea di campo elettrico per studiare il potenziale elettrico, andiamo quindi a definire un **tubo di flusso**. Per risultato precedente abbiamo che $E_{i} = \\frac{dQ_{i}}{\\varepsilon_{0}dS_{i}}$ $$ V_{A} - V_{B} = \\int _{A}^{B} \\vec{E}_{i} \\, dr_{i} = \\int _{A}^{B} {E}_{i} \\, dr_{i} = \\int _{A}^{B} \\frac{dQ_{i}}{\\varepsilon_{0}dS_{i}}\\, dr_{i} = dQ_{i} \\int _{A}^{B} \\frac{1}{\\varepsilon_{0}dS_{i}}\\, dr_{i} $$ Portando dall\u0026rsquo;altra parte abbiamo $$ dQ_{i} = \\frac{V_{A} - V_{B}}{\\int \\frac{1}{\\varepsilon_{0}dS_{i}}\\, dr_{i} } $$ Poi sommo la carica di tutti i singoli tubettini di flusso, dato che abbiamo induzione completa (che non abbiamo ancora discusso, abbiamo allora che\n$$ Q = \\sum_{i=1}^{N}dQ_{i} = (V_{A} - V_{B})\\sum_{i=1}^{N}\\frac{1}{\\int \\frac{1}{\\varepsilon_{0}dS_{i}}\\, dr_{i} } $$ La cosa importante Ã¨ che dipende solo dalla geometria del nostro sistema, una volta fissata Ã¨ una costante. chiamiamo quella cosa una costante geometrica si puÃ² scrivere che $$ V_{A} - V_{B} = \\frac{Q}{C} \\implies C = \\frac{Q}{\\Delta V} $$ ossia la capacitÃ  del condensatore Ã¨ la carica fratto la differenza di potenziale.\nAnalisi dimensionale capacitÃ  ðŸŸ©- $$ \\left[ C \\right] = \\frac{[Q]}{[V]} =\\left[ Q \\right] / \\left[ ML^{2} T^{-2} Q^{-1} \\right] = \\left[ Q^{2} \\right] \\left[ M^{-1}L^{-2} T^{+2} \\right] = \\left[ F \\right] $$ Massa per velocitÃ  alla seconda per l\u0026rsquo;energia.\nUn Farad, ma essendo una quantitÃ  molto grande, difficile da usare, si utilizza il $1\\mu F$ che sono presenti nei circuiti, ma se ho troppa carica forse Ã¨ difficile da utilizzare (o hanno usi diversi).\nCondensatori piani Consideriamo un classico caso in cui abbiamo due condensatori piani, con la stessa carica, e area $=S$ Approssimazione\nConsideriamo le linee di campo del tutto parallele (campo come se fosse un piano infinito per chiarirci). Facce sono infinite (ma poi nella realtÃ  cambia solamente ai bordi). Campo elettrico in ogni regione ðŸŸ© Si puÃ² notare che Calcolo della direzione\nSinistra: Ã¨ 0 Centro sono $2\\vec{E}_{1} = \\vec{E}$ Destra: Ã¨ 0 Calcolo del modulo: Sappiamo che il campo elettrico per una singola armatura metallica Ã¨ $\\frac{\\sigma}{2 \\varepsilon_{0}}$, in questo caso sono uguali in modulo, e si sommano quindi:\n$$ \\vec{E} = \\frac{\\sigma}{\\varepsilon_{0}} $$ In mezzo ai conduttori. Questa analisi si puÃ² fare con Gauss o semplicemente usando sovrapposizione, dovrebbe venire uguale, nel caso di conduttori infiniti.\nDisposizione superficiale di carica ðŸŸ© Disposizione esterna Nel setting dei condensatori di sopra, possiamo chiederci dove stanno le cariche, si puÃ² dimostrare usando Gauss che sulla superficie esterna Ã¨ nulla. Procedimento:\nPrendi una superficie cilindrica, che parte da dentro e arriva fuori a sinistra della piastra di sinistra. Sai che il campo dentro Ã¨ nullo per induzione elettrostatica Sai che fuori Ã¨ nullo perchÃ© hai supposto che si eliminano i campi (uguali perchÃ© stai assumendo siano infiniti). Quindi per Gauss la carica inclusa dovrÃ  essere nulla in quei punti. Disposizione interna Applico gauss con un cilindro molto simile, con un cerchio dentro (quindi campo nullo per induzione in Conduttori elettrici), ma ora l\u0026rsquo;altra estremitÃ  del cilindrÃ² avrÃ  un qualche valore:\n$$ \\oint_{\\SigmaÂ´} \\vec{E} \\cdot d\\vec{s} = \\frac{Q_{T}''}{\\varepsilon_{0}} \\implies \\oint_{\\Sigma'} \\lvert \\vec{E} \\rvert ds = \\lvert \\vec{E} \\rvert A = \\frac{Q_{T}''}{\\varepsilon_{0}} = \\frac{\\sigma A}{\\varepsilon_{0}} \\implies \\lvert \\vec{E} \\rvert = \\frac{\\sigma}{\\varepsilon_{0}} = \\frac{Q}{\\varepsilon_{0}S} $$ Abbiamo messo $S = A$ come superficie ed area, la stessa cosa in pratica. Quindi la discontinuitÃ  che abbiamo discusso (che non ho ancora scritto) Ã¨ ancora la stessa, solo ridisposta in modo diverso, descritto in Campo elettrico.\nPotenziale elettrico e capacitÃ  ðŸŸ©- Utilizziamo la definizione: $$ \\Delta V = \\int _{A}^{B} \\vec{E} \\, d\\vec{r} = \\lvert \\vec{E} \\rvert \\int _{A}^{B} \\, d\\vec{r} = \\lvert \\vec{E} \\rvert d = \\frac{Qd}{\\varepsilon_{0}S} $$ Una volta ottenuto entrambi posso calcolare la capacitÃ : $$ C = \\frac{Q}{\\Delta V} = \\frac{S\\varepsilon_{0}}{d} $$ E possiamo vedere che sono sempre fattori geometrici.\nCaso piani non infiniti ðŸŸ© Nell\u0026rsquo;analisi soprastante, abbiamo assunto di avere piani metallici infiniti Nel caso reale:\nL\u0026rsquo;approssimazione funziona in mezzo al condensatore Ai bordi il campo inizia a curvare, quindi non Ã¨ come modellizzato di sopra. Disposizioni di condensatori Parallelo ðŸŸ© Analizziamo sempre potenziali e capacitÃ , da un punto di vista totale (vedendolo come un singolo condensatore). Chiamiamo a sinistra 1, a destra 2 **Osservazioni**: 1. Potenziale ai capi dei condensatori Ã¨ uguale, perchÃ© i primi due sopra sono collegati, cosÃ¬ come quelli sotto 2. Si sommano le capacitÃ  (e carica singole), anche perchÃ© Ã¨ *come se aumentassi la superficie*. $$ C_{T} = \\frac{Q_{T}}{\\Delta V} = \\frac{Q_{1} + Q_{2}}{\\Delta V} = C_{1} + C_{2} $$ In un sistema composto da due o piÃ¹ condensatori posti in parallelo, la capacitÃ  totale Ã¨ pari alla somma delle singole capacitÃ .\nIn serie ðŸŸ¨ **Osservazione** 1. Conduttori su E Ã¨ isolato, quindi si *caricheranno solo per induzione*. Analizziamo le differenze di potenziali, allora abbiamo che $$ \\Delta V_{1} = V_{A} - V_{E} = \\frac{Q}{C_{1}} $$ In modo simile per il secondo, noi vogliamo trovare $\\Delta V = V_{A} - V_{B} = \\frac{Q}{C_{T}}$, ma posso usare lo stratagemma matematico e risolvere ciÃ² $$ \\Delta V = V_{A} - V_{B} = (V_{A} - V_{E}) + (V_{E} - V_{B}) = Q\\left( \\frac{1}{C_{1} } + \\frac{1}{C_{2}} \\right) = \\frac{Q}{C_{T}} \\implies \\frac{1}{C_{T}} = \\frac{1}{C_{2}} + \\frac{1}{C_{2}} $$ Possiamo vedere che la capacitÃ  cala, questo Ã¨ spiegato fisicamente perchÃ© la carica Ã¨ distribuita, mentre la superficie rimane sempre lo stesso.\nLa serie fra due o piÃ¹ condensatori ha capacitÃ  totale $C_{T}$ il cui inverso Ã¨ pari alla somma degli inversi delle singole capacitÃ \nEnergia nei condensatori Intuizione sul concetto di energia Partiamo sempre dal concetto di lavoro, Ã¨ equivalente al lavoro usato per caricarlo. anche chiamato autoenergia. L\u0026rsquo;energia di un sistema di cariche che cosa Ã¨? Ã¨ il lavoro esterno compiuto per costruire il sistema, in modo piÃ¹ intuitivo Ã¨ quanto sforzo Ã¨ stato necessario usare per partire dall\u0026rsquo;infinito e portare le particelle e portarle in quel punto. Se Ã¨ repulsiva (quindi energia positiva) io faccio lavoro positivo, altrimenti negativo, questo l\u0026rsquo;hai visto ieri. Se l\u0026rsquo;energia Ã¨ positiva posso estrarre energia da utilizzare, altrimenti no.\nEnergia di Interazione ðŸŸ© L'energia di sistema (o di interazione fra le cariche) Ã¨ calcolato nel modo seguente: La prima carica non fa lavoro perchÃ© il campo Ã¨ nullo inizialmente La seconda carica fa un po\u0026rsquo; di fatica Se cambio l\u0026rsquo;ordine cambia l\u0026rsquo;ordine, ma l\u0026rsquo;equazione finale non cambia. (forse solo segno) $$ U_{12} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R_{12}} = q_{1} V_{21} $$ Calcoliamo l\u0026rsquo;energia necessaria per portare una terza, avremo che $$ U_{23} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{2}q_{3}}{R_{23}} = q_{2}V_{32} = q_{3}V_{23} $$ E si fa lo stesso per $U_{13}$ e poi si summa tutto Quindi in generale: $$ U_{tot} = \\sum_{i \u003c j} ^{N} q_{i}V_{ji} = \\frac{1}{2} \\sum_{i \\neq j} ^{N} q_{i}V_{ij} $$ Probabilmente il segno si deve fare attento. (Nota come semplificazione, sfruttando la sovrapposizione potremmo scrivere la roba di sopra come) $$ U_{tot} = \\frac{1}{2}\\sum_{i = 1}^{N}q_{i}V_{i} $$ Con $V_{i} = \\sum_{j\\neq i}^{N}V_{ij}$\nQuesta forma poi ci deve anche essere di interesse nel momento in cui vogliamo andare oltre al semplice caso discreto, perchÃ© allora possiamo scriverlo come $$ U_{tot} = \\frac{1}{2} \\int _{\\tau} \\rho V \\, d\\tau $$ E la stessa cosa vale per le superfici in pratica posso calcolare l\u0026rsquo;energia totale in ogni configurazione.\nLavoro di carica dei condensatori Primo modo: lavoro punto per punto ðŸŸ¨++ Consideriamo un condensatore, alla prima carica non c\u0026rsquo;Ã¨ lavoro, ma poi si crea un campo elettrico che si prova ad opporre al caricamento (quindi lavoro positivo, forza di Coulomb Ã¨ positivo).\nMan mano che si carica la $\\Delta V(q)$ cambia. Proviamo a vedere la formula superficiale. Lavoro fatto dal campo quando sposto una carica di un piccolissimo tratto. $$ dL' = \\vec{E} \\cdot d\\vec{r} = -dV $$ Lavoro della $\\vec{F}_{C}$ forza di coulomb (quello della forza esterna Ã¨ uguale e contraria). $$ dL = dq\\vec{E} \\cdot d\\vec{r} = -dqdV $$ Calcolando da A a B e sommando tutto abbiamo che (contando che il lavoro esterno deve essere opposto rispetto al nostro campo in considerazione).\n$$ \\Delta L_{E} = \\int _{A}^{B} dqdV = dq \\int _{A}^{B} \\, dV = dq \\Delta V_{q} $$ La differenza di potenziale quando le armature non sono state ancora calcolate, abbiamo che $\\Delta V_{q} = \\frac{q}{C}$ che si puÃ² rimettere sopra, ossia il lavoro fatto nel momento in cui c\u0026rsquo;Ã¨ una piccola forza su una armatura. $$ \\Delta L_{E} = dq \\frac{q}{C} $$ $$ L_{E} = \\int _{0}^{Q} \\Delta L_{E} = \\int _{0}^{Q} \\frac{q}{C} \\, dq = \\frac{1}{2} \\frac{Q^{2}}{C} = \\frac{1}{2} Q \\Delta V = \\frac{1}{2}C \\,\\Delta V^{2} $$ Che Ã¨ esattamente il lavoro fatto per caricare il condensatore\nSecondo modo: energia di interazione ðŸŸ© Posso subito dire che $$ U_{E} = \\frac{1}{2} \\left[ Q_{A} V_{A} + Q_{B}V_{B} \\right] = \\frac{1}{2} \\left[ C(V_{A} - V_{B})V_{A} + C(V_{B} - V_{A})V_{B}\\right] = \\frac{1}{2} C\\, \\Delta V^{2} $$ DensitÃ  di energia ðŸŸ© L\u0026rsquo;energia immagazzinata Ã¨ stata utilizzata per costruire il campo. -\u0026gt; Campo elettrico porta energia! Rinnovabili per questo Ã¨ nice. Abbiamo che $$ U_{E} = \\frac{1}{2} C\\, \\Delta V^{2} \\land C=\\frac{\\varepsilon_{0}S}{d} \\land \\Delta V = Ed \\implies U_{E} = \\frac{1}{2}\\varepsilon_{0}E^{2}(Sd) = \\frac{1}{2}\\varepsilon_{0}E^{2}Volume $$ Questo ci permette di definire il concetto di densitÃ  di energia di un condensatore, dato che abbiamo un volume. $$ u_{e} = \\frac{1}{2}\\varepsilon_{0}E^{2} $$ Questo servirÃ  per il vettore di Poynting in seguito quando faremo il minimo di propagazione. (Base di energia solare, anche la parte di propagazione che ho fatto io, e spiega che si puÃ² ottenere energia dal campo elettrico, costruendo o disfacendone).\nScarica e carica di condensatori Carica del condensatore Setting del problema ðŸŸ© Ci stiamo chiedendo, come varia l\u0026rsquo;intensitÃ  di corrente in un circuito fatto di semplice condensatore e resistenza? In che modo cambia il potenziale? Se ho l\u0026rsquo;intensitÃ  di corrente per un dato momento, allora posso calcolare l\u0026rsquo;intensitÃ  di corrente. Possiamo usare le leggi presenti in Leggi di Ohm e osservare che vale, perchÃ© alla fine il campo esterno Ã¨ ancora conservativo (credo), anche se la corrente varia. $$ \\varepsilon = V_{C} + V_{R} = \\frac{q(t)}{C} + Ri(t)\n$$ In un certo istante specifico $t$, ma notiamo che per definizione, la corrente accumula sul condensatore un valore $i(t) = \\frac{dq(t)}{dt}$ e possiamo sostituire questo dentro e risolvere l\u0026rsquo;equazione differenziale associata.\n$$ \\varepsilon = \\frac{q(t)}{C} + \\frac{Rdq(t)}{dt} $$ Sono equazioni che si risolvono nella forma $Ae^{Bx}$ o qualcosa di simile, infatti possiamo sostituire questo lÃ¬ dentro e ricevere qualcosa cosÃ¬: $$ \\varepsilon = \\frac{A}{C}e^{Bt} + RABe^{Bt} $$ Ma questo non riesco a risolverlo tutto a un tratto: $$ dt\\left( \\varepsilon - \\frac{q(t)}{C} \\right) = dq(t) R \\implies \\frac{dt}{RC} = \\frac{dq(t)}{\\varepsilon C - q(t)} $$ Allora sappiamo che fra l\u0026rsquo;istante 0 in cui metto giÃ¹ l\u0026rsquo;interruttore e il nostro tempo abbiamo: $$ \\int _{0}^{q} \\frac{dq(t)}{-\\varepsilon C + q(t))} = -\\int_{0}^{t} \\frac{dt}{RC} \\implies \\ln\\left( \\frac{-\\varepsilon C + q(t)}{-\\varepsilon C} \\right)=- \\frac{t}{RC} \\implies q(t) = -\\varepsilon C e^{-t/RC} + \\varepsilon C $$ Equazioni per la carica dei condensatori ðŸŸ© Da quanto fatto sopra otteniamo che $$ q(t) = \\varepsilon C(1 - e^{-t/RC}) $$ $$ i(t) = \\frac{\\varepsilon}{R} e^{-t/RC} $$ E poi con questo posso ottenere a cascata tanti altri valori, come la differenza di potenziale sul condensatore, sulla resistenza e simili. $$ V_{c}(t) = \\frac{q(t)}{C} = \\varepsilon(1 - e^{-t/RC}) $$ E posso fare la stessa cosa per la resistenza $$ V_{b}(t) = i(t)R = \\varepsilon e^{-t/RC} $$ Come grafici questi hanno: Note sul tempo di carica ðŸŸ© Nota: il condensatore non si carica mai al valore teorico di carica che puÃ² avere (Ã¨ un asintoto orizzontale). Possiamo considerarlo carico quando Ã¨ tipo 1% del valore nominale, non ho capito esattamente perchÃ© questo, forse Ã¨ una convenzione.\nTempi tipici di carica sono microsecondi perchÃ© di solito Parliamo di micro-Farad e migliaia di Ohm di resistenza.\nSi puÃ² notare risolvendo le equazioni di sopra otteniamo che: 0.95% -\u0026gt; 3$\\tau$ 0.99% -\u0026gt; 4.6$\\tau$ 0.999% -\u0026gt; 7$\\tau$ Per caricare il condensatore.\nPotenza erogata ed assorbita ðŸŸ© Con le equazioni di sopra possiamo anche utilizzare le equazioni di energia spesa, perchÃ© sappiamo che il generatore eroga $$ P_{gen} = \\varepsilon i(t) = \\frac{\\varepsilon^{2}}{R}e^{-t/RC} $$ Mentre la potenza assorbita dalla resistenza Ã¨ di valore: $$ P_{b} = Ri(t)^{2} = \\frac{\\varepsilon^{2}}{R} e^{-2t/RC} $$ E possiamo notare che\n$$ P_{c} = \\frac{Vdq}{dt} = P_{gen} - P_{b} $$ Una altra cosa interessante Ã¨ che il valore del lavoro totale si puÃ² ricalcolare con l\u0026rsquo;energia presente nel condensatore! $$ W_{gen} = \\int_{0}^{\\infty} P_{gen} \\, dt = C\\varepsilon^{2} $$ Allo stesso modo si poteva ottenere $$ W_{gen} = \\int_{0}^{q_{0}}Vdq = Vq = V^{2}C $$ E si puÃ² togliere l\u0026rsquo;energia immagazzinata dal condensatore come $$ W_{c} = \\frac{1}{2}CV^{2} = \\frac{W_{gen}}{2} \\implies W_{r} = W_{c} $$ Scarica del condensatore Setting del problema ðŸŸ© Ho un condensatore completamente carico come in figura Ad un certo punto chiudo l\u0026rsquo;interruttore e inizierÃ  a scorrere della carica, vogliamo capire in che modo varia $q(t)$ e in che modo varia $i(t)$\nEquazioni per la scarica dei condensatori ðŸŸ© In modo simile al precedente possiamo mettere su una equazione differenziale: $$ 0 = \\frac{q(t)}{C} + \\frac{d(q)}{dt}R \\implies -\\frac{dt}{RC} = \\frac{d(q)}{q(t)} $$ E con questo abbiamo in modo del tutto analogo al precedente che $$ \\int_{q_{0}}^{q} \\, \\frac{dq}{q} = -\\int_{0}^{t} \\frac{dt}{RC} \\implies \\ln\\left( \\frac{q}{q_{0}} \\right) = -\\frac{t}{RC} \\implies q(t) = q_{0}e^{-t/RC} $$ E poi si possono fare tutte le altre cose.\nCampo magnetico in condensatore ðŸŸ¨ Guardando Ampere e Faraday se cambia l\u0026rsquo;intensitÃ  del campo elettrico, come succede per questo circuito, abbiamo che si ha una densitÃ  di corrente di spostamento.\nCalcoliamo la circuitazione in una parte del filo (intorno a un punto, in modo classici diciamo) e allora abbiamo $$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{r} = \\mu_{0} i(t) = \\mu_{0} \\int _{\\Sigma(\\Gamma)} \\vec{J} \\cdot d\\vec{s} = \\mu_{0}(\\frac{\\varepsilon}{R} e^{-t/RC}) $$ Questo scegliendo la superficie piÃ¹ semplice che esisteva. Posso perÃ² scegliere una altra superficie che passa dalle facce del condensatore, in questo caso io non ho corrente! Ecco che entra in gioco la correzione di Maxwell, per la corrente di spostamento. E facendo i calcoli si Ã¨ scoperto che la predizione era corretta, e il valore Ã¨ esattamente lo stesso.\n","permalink":"https://flecart.github.io/notes/condensatori-nel-vuoto/","summary":"Introduzione ai condensatori Analisi introduttiva condensatori: tubi di flusso ðŸŸ© Consideriamo un **tubo di flusso infinitesimo** come in immagine. abbiamo che $dQ$ Ã¨ la carica totale dentro al cubo. Tale che segua le linee di campo. Il flusso totale sarebbe $$ \\oint_{\\Sigma} \\vec{E} \\cdot d\\vec{s} = \\frac{Q_{T}}{\\varepsilon_{0}} $$ Sappiamo anche che $$ \\vec{E}_{1}d\\vec{s}_{1} + \\vec{E}_{2}d\\vec{s}_{2} = \\frac{dQ_{T}}{\\varepsilon_{0}} $$ Ma scegliamo il cubo di flusso in modo che le superfici siano **perpendicolari al nostro campo**, e cosÃ¬ posso considerare il problema da un puro punto di vista **scalare**.","title":"Condensatori nel vuoto"},{"content":"Ripasso Prox: 79 Ripasso: June 10, 2023 Ultima modifica: June 4, 2023 3:33 PM Primo Abbozzo: September 27, 2022 12:18 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Domande\nNon sembra che abbia capito molto bene i concetti di pragmatica e linguaggio eseguibile per i linguaggi formali\nDimostrazione numerabilitÃ  delle grammatiche.\nQuesto insieme di appunti riassume gli appunti 1-2-3 del professor Gorrieri.\nDescrizione di un linguaggio Introduzione Per questa parte câ€™Ã¨ un sacco di roba in comune con Tecniche di definizione di semantica (4) ðŸŸ©\nTrattiamo alcune caratteristiche che descrivono ad alto livello un linguaggio di programmazione. Ãˆ da notare che questa parte della spiegazione del linguaggio non Ã¨ limitante al solo linguaggio di programmazione, Ã¨ utile per analizzare tutti i linguaggi (tranne la parte di implementazione)\nSintassi ðŸŸ©- Relazione fra segni. si occupa di decidere quando una frase Ã¨ corretta.\nAspetto lessicale\nIl lessico per una sintassi descrive le parole legali, In un linguaggio naturale il lessico Ã¨ descritto solamente da dizionari. Se un vocabolo non esiste nel lessico di interesse, allora Ã¨ erroneo, poi andremo a descrivere questo aspetto in modo formale\nVedere Scanner in appunti dopo\nAspetto grammaticale\nDescrive la descrizione di frasi corrette a partire dal lessico, puÃ² essere utile in questo passo ricordarsi delle BNF Sintassi e RI strutturali del corso di logica\nPrincipalmente sono delle regole per costruire delle frasi che hanno un senso\nSemantica ðŸŸ© Ossia riguardo il significato di una frase sintatticamente correttaâ†’ relazione fra segni e significato.\nLinguaggio di appartenenza\nUna stessa parola, a seconda della lingua di interpretazione, puÃ² avere significati diversi â†’ FAME (fama, oppure fame?)\nVoglio utilizzare questo linguaggio per calcolare la semantica di questo linguaggio basandomi su qualcosa che giÃ  esiste. (alla fine, per l\u0026rsquo;architettura esistente attuale, saranno sempre 0 e 1 di bits).\nPragmatica ðŸŸ© Si occupa di studiare in quale modo le frase corrette sono utilizzate. Quindi va a rispondere a domande come â€œA cosa serve un costrutto?â€, â€œCome si utilizza il comandoâ€\nInsieme di regole per dare un indirizzo di uso\nEsempio: stile: non usare goto, scopo: questo comando fa quello e questo quindi usalo perâ€¦.\nDato che principalmente la pragmatica non Ã¨ presente al momento della creazione del linguaggio ma si evolve con lâ€™uso di esso, non Ã¨ molto interessante da questo punto di vista (+ sull\u0026rsquo;ingegneria del software).\nUn altro esempio Ã¨ tipo utilizzare lei, invece del tu in contesti formali\nEsiste anche una pragmatica per la semantica Pragmatica\nIl linguaggio eseguibile ðŸŸ¨+ Un linguaggio formale deve soddisfare alcune regole in piÃ¹ rispetto al linguaggio naturale, in particolare â†’ l\u0026rsquo;implementazione.\nEseguire una frase sintatticamente corretta in modo semanticamente corretto.\nQuindi si occupa dell\u0026rsquo;implementazione vera e propria del compilatore o dellâ€™interprete del linguaggio. (In questo corso si faranno solo cenni, dato che non si implementerÃ  tale linguaggio).\nLessico e frasi di un linguaggio Alfabeto lessico e frasi ðŸŸ© Definiamo ora alcune parole fondamentali per poter parlare di linguaggi in modo formale:\nAlfabeto: a non-empty set of symbols/glyphs, typically thought of as representing letters, characters, or digits. (tipicamente finito, ma puÃ² essere anche infinito)\nLessico: un insieme di parole finite formate da lettere dell\u0026rsquo;alfabeto che consideriamo validi\nFrasi: seguenze finite (o countably infinite, non vale per il lessico CREDO) di parole del lessico\nIl linguaggio formale ðŸŸ© Sia $A$ il nostro alfabeto, e $A^0 = \\{ \\varepsilon \\}$, e $A^{n + 1} = A \\cdot A^n$ con dot un operazione di concatenazione, allora L Ã¨ un sottoinsieme solitamente finito di tutte le parole su $A$, ossia\n$L \\subseteq A^*$, $A^* = \\bigcup_{n \\geq 0}A^n$. Questo insieme si puÃ² creare con un insieme di regole, ma anche come elenco Ã¨ corretto.\nEsempi di linguaggi\nNumerabilitÃ  per alfabeti Si puÃ² dimostrare che $A^*$ formato da alfabeti infiniti Ã¨ ancora un infinito numerabile, si utilizza un argomento simile a Cantor spiegato in R e Intervalli e in Relazioni fra insiemi.\nDimostrazione numerabilitÃ  di A-star Questo dimostra che ogni unione di insiemi numerabili Ã¨ numerabile. C\u0026rsquo;Ã¨ una altra dimostrazione molto piÃ¹ semplice rispetto a questa costruzione di funzioni.\nPraticamente numeriamo l\u0026rsquo;alfabeto finito che abbiamo, in ordine $\\sigma_{1} \\sigma_{2}, \\dots, \\sigma_{n}$ Allora questi hanno valore $1, \\dots, n$, poi per le stringhe nella forma $\\sigma_{1}\\sigma_{2}, \\sigma_{1}\\sigma_{3}, \\dots \\sigma_{n}\\sigma_{n}$ li metto anche ora in ordine di indice e inizio a contare da $n + 1$ e cosÃ¬ via. CosÃ¬ so che ogni singola stringa del linguaggio ha un intero associato e posso dire che $A^{*}$ Ã¨ numerabile.\nDefinizioni operazioni di base (6) ðŸŸ© Lunghezza\nViene definita in modo ricorsiva in questo modo:\nSlide\nConcatenazione\nSlide\nDeve soddisfare principalmente 3 proprietÃ \nLa lunghezza della stringa risultante Ã¨ uguale alla somma della lunghezza delle singole stringhe prima parte della stringa risultato Ã¨ uguale alla prima stringa seconda parte della stringa risultato Ã¨ uguale alla seconda stringa Sottostringa, suffisso e prefisso\nSlide\nÃˆ abbastanza banale dai, credo (in pratica posso prendere v in mezzo alla stringa di partenza mettendoci qualcosa prima e dopo\nPotenza n-esima\nSlide\nOssia provo a concatenera sÃ© stesso piÃ¹ volte\nOperazioni di base su linguaggi (6) ðŸŸ© Complemento\nUnione\nIntersezione\nConcatenazione\nQuesto Ã¨ la concatenazione a livello linguaggio, mentre prima era la concatenazione a livello stringa\nPotenza\nChiusura / stella di Kleene / Ripetizione\nRappresentazione del linguaggio (2) ðŸŸ©- Generativo - sintetico\nNon posso rappresentare un alfabeto infinito di caratteri! Ma posso memorizzare le regole che la generano. Per esempio posso memorizzare i numeri naturali con solamente gli assiomi di peano (in particolare mi bastano 2 delle 5 regole di peano\nRiconoscimento - analitico\nSono le stringhe che vengono riconosciute da un automa che vedremo in seguito.\nMa non tutti i linguaggi sono riconoscibili da AUTOMI, resta il finito contabile come limite massimo, il motivo per cui Ã¨ questo Ã¨ perchÃ© le grammatiche sono equipotenti a $\\N$, mentre tutti i linguaggi sono sottoinsieme di $\\R$ e quindi non riesco a detectarlo.\nSlide grandezza di grammatiche ed alfabeti\nGrammatiche e BNF Def grammatica libera (4) ðŸŸ© Ãˆ una quadrupla di\nNon terminali (insieme finito, indicato di lettere maiuscole) Terminali (insieme finito, indicato da lettere minuscole) Simbolo iniziale (simbolo speciale non terminale) Produzioni (ricorda qui che la grammatica libera si puÃ² rappresentare con questa) Backus Naur-Form ðŸŸ© In questa sezione cerchiamo di definire in modo piÃ¹ dettagliato le BNF introdotte nella lezione di logica di Sintassi e RI strutturali trattati in logica.\nSlide esempio di una BNF per palindromi\nStesso precedente, ma scritto tramite la sintassi delle grammatiche\nDefinizione tramite assiomi\nDefinizione in via ricorsiva\nIndichiamo con $L(P)$ il linguaggio generabile a partire da un P, con le regole di inferenza di sopra\nLâ€™unica differenza con le grammatiche libere Ã¨ la sintassi differente per la descrizione di essa (utilizzo delle \u0026lt;\u0026gt;), ma storicamente credo che si siano evolute in modo distinto, e poi si sono accorti che erano la stessa cosa\nDerivazioni (leftmost e rightmost) ðŸŸ©â€” Definizione di derivazione immediata\nSia $G = (NT, T, R, S)$ una grammatica libera da contesto, si dice che $v$ deriva immediatamente da $w$, indicato con $w \\implies v$, quando $\\exists (A \\to z) \\in R$, con $R$ le produzioni e $A \\to z$ una produzione, e $w = xAy$, e $v = xzy$\nIn altre parole posso dire che una stringa Ã¨ derivata in modo immediato da una altra stringa quando posso ricavarla con una singola operazione di una funzione presente in produzione.\nSlide definizione derivazione immediata\nDefinizione derivazione â€œgeneraleâ€\nPosso affermare che da $v$ si deriva $w$ quando esiste una sequenza finita (anche vuota) di derivazioni immediate tali che\n$$ v \\implies w_0 \\implies ... \\implies w $$ Tale cosa Ã¨ riscritta come $v \\Rightarrow^* w$\nSlide Definizione di Derivazione generale (!!!)\nDerivazione left e rightmost\nConcetto di derivazione left e right most\nIl concetto piÃ¹ generale Ã¨ che nel processo di derivazione di una stringa in un linguaggio viene sempre espanso il non terminale piÃ¹ a sinistra.\nCheck appartenenza\nSi puÃ² verificare che una stringa appartiene a un certo linguaggio descritto in modo formale come sopra se si puÃ² creare un albero di derivazione\nEsempio di derivazione\nLinguaggio generato da grammatica ðŸŸ© Data una grammatica $G = (NT, T, R, S)$ a contesto libero definiamo il linguaggio libero $L(G)$ generato dalla grammatica come\n$$ L(G) = \\{ w \\in T^* : S \\Rightarrow ^* w\\} $$ Ossia in parole umane, tutte le stringhe terminali generabili da quella grammatica.\nSlide definizione\nAlberi di derivazione Un albero di derivazione Ã¨ una rappresentazione molto utile per un compilatore per comprendere la struttura interna intermedia. fornisce informazioni semantiche!\nDefinizione albero di derivazione (5) + 1 ðŸŸ¨+ presenta alcune proprietÃ  dellâ€™albero, che Ã¨ invariante rispetto allâ€™albero, questa osservazione ci dÃ  anche un hint per la definizione del concetto di ambiguitÃ  per grammatiche e linguaggi.\nUna altra osservazione importante Ã¨ che possiamo associare un albero di derivazione a ogni Derivazione.\nDefinizione albero di derivazione (5) + 1 ðŸŸ¨+ Vogliamo descrivere la struttura di un albero di derivazione generale\nLa radice Ã¨ il non-terminale iniziale ossia $S$ Tutti i nodi hanno simboli in $NT \\cup T \\cup \\{\\varepsilon \\}$ I nodi interni hanno solo simboli $NT$ Esiste una relazione diretta fra padre e figli definiti da una produzione, piÃ¹ in generale se $A\\in NT$ e $x_1,..., x_n$ sono nodi figli, esiste una produzione $A \\to x_1, ..., x_n$ Se $\\varepsilon$ Ã¨ su un nodo, allora quella Ã¨ una foglia ed esiste la produzione $A \\to \\varepsilon$, con A lâ€™etichetta per il parent Inoltre andiamo a chiamare albero di derivazione COMPLETO se ogni foglia Ã¨ un terminale.\nSlide\nRelazione con derivazione ðŸŸ¨+ Si puÃ² dimostrare che una stringa appartiene a un linguaggio, solo se esiste un albero di derivazione per essa in quel linguaggio, quindi Ã¨ un buon metodo per descrivere la derivabilitÃ  in modo non-ambiguo.\nIdee per la bigezione\nChiaramente se vado Derivazione â†’ Albero Ã¨ una cosa abbastanza ovvia perchÃ© Ã¨ il modo con cui si crea lâ€™albero\nSe vado nella direzione Albero â†’ Derivazione (dx, sx) sto facendo in pratica una DFS che espande sempre il primo a sinistra o primo a destra di non terminali, e ho anche bisogno di una funzione che sia in grado di restituirmi una stringa data dalle foglie, fatto ciÃ² dovrebbe essere easy.\nAlberi sintattici ðŸŸ© Quando abbiamo un albero di derivazione completo, possiamo estrarre lâ€™albero formato dalle foglie, come in figura, per avere un albero che abbia qualche informazione riguardo la semantica di quanto descritto.\nEsempio estrazione albero sintattico\nAlbero di sintassi concreta o Astratta Câ€™Ã¨ una leggera differenza fra sintassi astratta e concreta.\nDi sotto, durante la risoluzione delle ambiguitÃ  facciamo uso delle parentesi per disambiguare, questo utilizzo delle parentesi Ã¨ presente nellâ€™albero di sintassi concreta, anche chiamato parse tree.\nInvece lâ€™albero di sintassi astratta puÃ² essere ambigua, rappresenta una astrazione sulla sintassi concreta del linguaggio e spesso Ã¨ ambigua.\nEmail mandata, in TODO\nAlbero di derivazione\nÃˆ l\u0026rsquo;albero che soddisfa le 6 proprietÃ  presentate (radice Ã¨ il non terminale iniziale, i nodi\ninterni sono etichettati come non terminali, etc..).\nAlbero di sintassi concreta\nÃˆ l\u0026rsquo;albero che rappresenta tutta la sintassi del programma (con anche zucchero sintattico)\nQuesto albero inoltreÂ Ã¨ un albero di derivazioneÂ perchÃ© soddisfa tutte le proprietÃ .\nAlbero di sintassi astrattaÃˆ formato solamente dalle foglie dell\u0026rsquo;albero di sintassi concreta, senza le foglie dovute allozucchero sintattico, quindi non Ã¨ un albero di derivazione perchÃ© non soddisfa le proprietÃ di essa (e.g. nodi interni non terminali) e contiene informazioni semantiche riguardo al programma.\nAmbiguitÃ  Tipologie di ambiguitÃ  (con esempi 2) ðŸŸ©- AmbiguitÃ  nella grammatica\nSi puÃ² dire che una grammatica Ã¨ ambigua se esistono due alberi di derivazione differenti per una stessa stringa.\nEsempio di ambiguitÃ  per alberi di derivazione\nEsempio di grammatica ambigua\n$$ S \\to A | \\varepsilon \\\\ A \\to \\varepsilon $$ Questo linguaggio genera solamente dei vuoti, ma lo puÃ² fare in modi diversi eg:\n$S \\to \\varepsilon$, o $S \\to A \\to \\varepsilon$\nUna altra grammatica che descrive il linguaggi equivalente non Ã¨ perÃ² ambiguo\n$S \\to \\varepsilon$\nAmbiguitÃ  nel linguaggio\nSi puÃ² dire che un linguaggio Ã¨ ambiguo se ogni sua grammatica Ã¨ ambigua.\nEsempio di linguaggio ambiguo\nRisoluzione delle ambiguitÃ  ðŸŸ© In modo simile a quanto trattato in Sintassi e RI strutturali bisogna stabilire:\nOrdine di precedenza degli operatori\nEsempio di problema di precedenza\nAssociativitÃ  sinistra o destra\nEsempio di necessitÃ  di associativitÃ  dx e sx\nParentesi\nQuesto Ã¨ un zucchero sintattico che non ha nessun valore semantico che aiuta a disambiguare la precedenza. (L\u0026rsquo;albero semantico non serve avere le informazioni sulle parentesi) Questo Ã¨ necessario per essere equivalente semanticamente ossia possono generare ora gli stessi alberi semantici Aggiunta parentesi\nGrammatica ambigua:\n$$ S = a|b...|S + S|S\\times S $$ Soluzione ambiguitÃ \n$$ E = E + T | T \\\\ T = A \\times T | A \\\\ A = a|b ...| (E) $$ ","permalink":"https://flecart.github.io/notes/descrizione-linguaggio/","summary":"Ripasso Prox: 79 Ripasso: June 10, 2023 Ultima modifica: June 4, 2023 3:33 PM Primo Abbozzo: September 27, 2022 12:18 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Domande\nNon sembra che abbia capito molto bene i concetti di pragmatica e linguaggio eseguibile per i linguaggi formali\nDimostrazione numerabilitÃ  delle grammatiche.\nQuesto insieme di appunti riassume gli appunti 1-2-3 del professor Gorrieri.\nDescrizione di un linguaggio Introduzione Per questa parte câ€™Ã¨ un sacco di roba in comune con Tecniche di definizione di semantica (4) ðŸŸ©","title":"Descrizione linguaggio"},{"content":"Ripasso Prox: 4 Ripasso: April 30, 2022 Ultima modifica: June 29, 2022 9:42 AM Primo Abbozzo: March 22, 2022 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso 3 Isomorfismi Gli isomorfismi sono delle proprietÃ  fondamentali per stabilire una sorta di equivalenza fra i gruppi. Utilizziamo questi isomorfismi per parlare della stessa cosa ma in modi diversi.\n3.1 Introduzione 3.1.1 Definizione Un gruppo si dice isomorfo rispetto ad un altro gruppo se, in paroloni semplici, esiste una funzione bigettiva tale che preservi l\u0026rsquo;operazione del gruppo.\nIn altre parole\n$$ \\phi:A \\to B,\\phi(ab) = \\phi(a)\\phi(b) $$ 3.1.2 Step di dimostrazione Esiste un modo preciso per dimostrare se due gruppi sono isomorfi. In particolare:\nTrovare la funzione per l\u0026rsquo;isomorfismo Dimostrare che Ã¨ iniettiva Dimostrare che Ã¨ suriettiva Dimostrare che preserva la struttura del gruppo 3.2 Ogni gruppo Ã¨ in isomorfismo con un gruppo di permutazione Questo Ã¨ uno dei teoremi principali per classificare i gruppi\nDimostrazione (left cosets as permutation groups)\n3.2.1 Note storiche su questo teorema Storicamente parlando si Ã¨ iniziati a studiare la teoria dei gruppi dal punto di vista delle permutazioni, questo teorema Ã¨ ciÃ² che ha permesso una maggiore astrazione rispetto al concreto gruppi delle permutazioni, permettendo lo sviluppo di questo campo in modo tale.\n3.3 ProprietÃ  dell\u0026rsquo;isomorfismo sugli elementi Abbiamo una unica slide che riassume tutte le proprietÃ . Non dovrebbe essere molto difficile dimostrare il tutto.\n3.3.1 Preservazione dellâ€™elemento neutro 3.3.2 Preservazione della potenza 3.3.3 Coimplica la commutativitÃ  3.3.4 Coimplica la ciclicitÃ  3.3.5 Stesso ordine 3.3.6 Preservazione del n_sol per equazioni del gruppo 3.3.7 Preservazione dellâ€™ordine degli elementi 3.4 ProprietÃ  dellâ€™isomorfismo sui gruppi 3.4.1 La funzione inversa Ã¨ un isomorfismo 3.4.2 Coimplica abelianitÃ  3.4.3 Coimplica la ciclicitÃ  3.4.4 L\u0026rsquo;immagine di un sottogruppo Ã¨ un sottogruppo (del gruppo di arrivo) 3.5 Automorfismi 3.5.1 Definizione Un automorfismo di gruppo Ã¨ solamente un isomorfismo con una funzione che parte da sÃ© ed arriva a sÃ© stesso.\nUn esempio di automorfismo Ã¨ la permutazione (che mi scambia gli elementi, ma alla fine Ã¨ una funzione da sÃ© in sÃ©).\n3.5.2 Automorfismo interno L\u0026rsquo;automorfismo interno rispetto a un gruppo Ã¨ una specie di congiunzione:\n$G_a(x) = axa^{-1}$ si puÃ² dimostrare che questo Ã¨ effettivamente un isomorfismo.\n3.5.3 Aut(Zn) ha stesso ordine di U(n) Gli unici isomorfismi di Zn a se stesso sono gli elementi che sono coprimi con zn, in quanto solo questi possono generare l\u0026rsquo;intero gruppo (ed essere generatore quindi\u0026hellip;) Questo Ã¨ lo stesso numero di elementi con U(n). Ad alto livello Ã¨ questo Ã¨ il motivo per cui vale questo teorema.\nDimostrazione\n!\n","permalink":"https://flecart.github.io/notes/isomorfismi/","summary":"Ripasso Prox: 4 Ripasso: April 30, 2022 Ultima modifica: June 29, 2022 9:42 AM Primo Abbozzo: March 22, 2022 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso 3 Isomorfismi Gli isomorfismi sono delle proprietÃ  fondamentali per stabilire una sorta di equivalenza fra i gruppi. Utilizziamo questi isomorfismi per parlare della stessa cosa ma in modi diversi.\n3.1 Introduzione 3.1.1 Definizione Un gruppo si dice isomorfo rispetto ad un altro gruppo se, in paroloni semplici, esiste una funzione bigettiva tale che preservi l\u0026rsquo;operazione del gruppo.","title":"Isomorfismi"},{"content":"Ripasso Prox: 70 Ripasso: June 1, 2023 Ultima modifica: April 25, 2023 9:22 AM Primo Abbozzo: February 20, 2023 8:45 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Nomi e Scope I Nomi e oggetti Oggetti denotati e identificatoriðŸŸ© I nomi sono sequenze di caratteri o numeri aka: token alfanumerico (anche IDENTIFICATORE (per token guardare Grammatiche Regolari) utilizzate principalmente come Astrazione sul controllo e sui dati (quindi sono cose molto piÃ¹ facili da ricordare rispetto il suo encoding binario o a indirizzi). Infatti utilizziamo i nomi per evitare di interessarci di informazioni come lâ€™indirizzo di memoria del nostro dato o per creare una interfaccia con visibili solo nome della procedura e parametri.\nI nomi quindi possono essere utilizzati per cose come\nElementi definiti al momento di progettazione del linguaggio: Costanti predefinite operazioni primitive (+, * etc) Tipi di dato primitivi Elementi definiti da utenti Variabili Parametri Indirizzi di memoria. Procedure (le funzioni) Costanti dellâ€™utente tipi dellâ€™utente Bindings (4) ðŸŸ©- Il binding Ã¨ proprio il collegamento che si ha fra il nome e lâ€™oggetto che viene denotato da essa.\nQuesto binding Ã¨ creato in 4 momenti diversi:\nProgettazione del linguaggio In questa fase possono venire definite le cose come elencate sopra Struttura del programma In questa parte viene solamente iniziato il collegamento fra identificatore e variabile identificata (e.s. se identifica una zona di memoria non allocata, non Ã¨ ancora completato il binding), per questo motivo possiamo dire che Ã¨ iniziato il binding delle variabili definite dallâ€™utente ma non Ã¨ stata completata. In fase di compilazione Per esempio in questa fase vengono allocate le variabili statiche (e.g. quelle globali su C/C++), quindi certe variabili effettivamente hanno finito di bindare in questa fase A runtime Per esempio nelle allocazioni dinamiche, oppure allocazione su stack (che comunque Ã¨ runtime), un identificatore come un indirizzo ha finito il binding con lâ€™oggetto denotato solamente in questo momento. Importante a questo punto Ã¨ stabilire il concetto di statico vs dinamico.\nNellâ€™esempio di sopra i primi 3 punti sono parte del binding statico, mentre il quarto Ã¨ dinamico. Questo perchÃ© statico si intendono tutte le associazioni fatte dal compilatore prima dellâ€™esecuzione del programma, mentre dinamico Ã¨ solitamente fatto dalla macchina astratta al momento dellâ€™esecuzione\nLifetime ðŸŸ© Bisogna in questa fase fare una distinzione della vita dellâ€™associazione e vita dellâ€™oggetto denotato.\nIn certi casi si puÃ² avere che la vita dellâ€™associazione Ã¨ minore di quella dellâ€™oggetto denotato, questo puÃ² succedere per esempio quando lâ€™associazione Ã¨ cambiata (quindi distrutta e ricreata in altro modo), anche un cambio di ambiente (e quindi di blocco puÃ² avere lo stesso effetto). (oppure un oggetto passato per riferimento nella chiamata di funzione, la vita del binding allâ€™interno della funzione resta quella)\nIn altri casi puÃ² succedere che la vita dellâ€™oggetto denotato sia minore dellâ€™associazione, questo puÃ² capitare per esempio quando un oggetto allocato dinamicamente sia stato liberato, mentre lâ€™associazione non lo sia, si parla in questo caso di dangling reference.\nAmbiente Ãˆ lâ€™insieme di associazioni fra identificatori e oggetti denotati in un certo momento dellâ€™esecuzione a uno specifico punto.\nIn certi punti di esecuzione del programma puÃ² succedere che uno stesso oggetto Ã¨ denotato da piÃ¹ nomi, in questo caso si dice che i nomi sono degli alias fra di loro.\nTipologie di ambiente (3) ðŸŸ© Facciamo distinzione fra tre tipologie principali di ambiente:\nLocale (quelli creati dal blocco corrente) Non Locale (quelli creati da blocchi superiori (quindi quelli che non sono dichiarati localmente in pratica). Globale (quelli creati nel blocco piÃ¹ sopra possibile, solitamente allâ€™inizio del nostro programma) Blocco piÃ¹ esterno Codice importato Operazioni sullâ€™ambiente (5) ðŸŸ© Dato che lâ€™ambiente Ã¨ lâ€™insieme di associazioni, questo sono anche operazioni sui nomi.\nNaming Quando proprio viene creato un nuovo collegamento con un oggetto. (aka dichiarazione). Unnaming Quando il collegamento viene distrutto Referencing Quando viene utilizzato un nome per accedere a un oggetto (quindi nessuna creazione qui). Attivazione binding Quando il collegamento con un oggetto viene ricreato Disattivazione binding Operazioni sugli oggetti (4) ðŸŸ© Queste operazioni sembrano le classiche che si fanno per i databases:\nAccesso (sola lettura dellâ€™oggetto) Modifica (scrittura sullâ€™oggetto) Creazione Eliminazione dellâ€™oggetto. Da notare la similitudine con il framework CRUD citato in HTTP e REST\nBlocchi Definizione ðŸŸ¨ Un blocco testuale di codice, in cui sono dichiarate localmente delle variabili, che ha un inizio e una fine chiara.\nIn generale si fanno distinzione fra\nBlocchi procedurali (come le funzioni in pratica) Blocchi anonimi (sono blocchi in line che si possono mettere in qualunque posto del codice). PerÃ² a volte Ã¨ meglio creare delle regole specifiche del linguaggio che dipendano dal creatore del linguaggio. non vorremmo ad esempio poter utilizzare la variabile prima che fosse dichiarata. (ma dipende dalla pragmatica del linguaggio (oppure sintattica, dipende comunque da come Ã¨ stato progettato questo linguaggio)).\ne.g.\n{ a = 1; int a; } Questo per molti linguaggi dovrebbe essere un errore, di semantica statica! ma a seconda delle regole sintattiche potrebbe essere corretto (potrebbe essere una a esterna, se esiste).\nUn discorso simile si puÃ² fare per le funzioni, che possono essere visibili o meno prima della dichiarazione o meno. Ma non credo questi dettagli siano troppo importanti, dopo un pÃ² capisci daiâ€¦\nAnnidamento ðŸŸ© Lâ€™annidamento dei blocchi deve soddisfare alcune caratteristiche, per esempio non possono esistere delle intersezioni parziali fra blocchi quindi che siano tipo ABAB (con primo A lâ€™inizio del blocco, e secondo A la fine). In un certo senso la stringa che deve esserci deve essere palindroma.\nVisibilitÃ  ðŸŸ© Una dichiarazione locale ad un blocco Ã¨ visibile in quel blocco e in tutti i blocchi in esso annidati, a meno che non intervenga in tali blocchi una nuova dichiarazione dello stesso nome (che nasconde, o maschera, la precedente)\nQuesto principio di visibilitÃ  puÃ² essere espresso in maniere differenti, ecco cosÃ¬ che si creano lo scoping statico e dinamico.\nRegola di Scope La regola di visibilitÃ  non Ã¨ definita in modo disambiguato, puÃ² essere interpretato in modo differente:\nEsempio\nA seconda di una interpretazione di Scoping, che Ã¨ anche detta regola di visibilitÃ  che Ã¨ qulel enunciata poco sopra, stampa risultati diversi. In questa parte proviamo a fare piÃ¹ chiarezza riguardo questo aspetto qui.\nPer capire bene questa parte sullo scope sarebbe meglio andare a guardare come di solito Ã¨ implementato, questo Ã¨ spiegato in Gestione della memoria\nStatico (3) ðŸŸ© 3 Regole descrivono bene lo scoping statico\nLâ€™ambiente locale ha solamente in sÃ© le dichiarazioni locali del blocco (direi che Ã¨ una convenzione, poi col punto 2 ha piÃ¹ senso questo mini algo, che vai a cercarti te). Se non viene trovato va a cercare nel blocco sopra, fino ad arrivare allo scope globale, se ancora qui non câ€™Ã¨ allora vado nelle built-in, se nemmeno qui câ€™Ã¨ allora errore (algoritmo stupido per fare la ricerca dellâ€™associazione). Per i blocchi con nome, il nome Ã¨ anche presente nello scope sopra (cosÃ¬ posso fare la ricorsione) Da notare che nello scoping statico quello che importa Ã¨ la struttura del nostro programma. Questo ci da alcuni vantaggi:\nFacile comprensione (perchÃ© non dobbiamo eseguire, basta leggere il programma, capire la struttura e sappiamo il binding corretto) VelocitÃ  (il compilatore si puÃ² tenere degli offset per capire quale Ã¨ la variabile corretta a cui accedere). PerÃ² per tenersi lo scoping statico Ã¨ leggermente piÃ¹ difficile perchÃ© non basta una stack, come invece Ã¨ per lo scope dinamico.\nDinamico ðŸŸ© Lo scope dinamico Ã¨ molto piÃ¹ semplice da implementare rispetto lo scope statico, Ã¨ guidato da questa unica regola.\nLâ€™oggetto a cui si riferisce un nome X Ã¨ quella dichiarata piÃ¹ recentemente a run-time, a patto che lâ€™associazione sia ancora attiva.\nQuindi se ci teniamo una stack di blocchi attivi (che poi vengono poppati, lâ€™ultima ad essere poppata Ã¨ il blocco globale, quello principale) Ã¨ molto facile seguire il percorso creazione di tutte le variabili per un blocco, e distruzione quando si esce dal blocco.\nSolitamente lo scope dinamico non viene mai utilizzato. (piÃ¹ lento e meno leggibile, bisognerebbe sempre leggere).\nRidefinizione di variabili globali per funzioni, questo si potrebbe considerare una possibilitÃ  dello scope dinamico di gestire input per variabili globali:\nEsempio in slide\nIl modo corretto per fare questa cosa Ã¨ dichiarare la funzione in modo che accetti come parametro un altro colore.\n","permalink":"https://flecart.github.io/notes/nomi-e-scope/","summary":"Ripasso Prox: 70 Ripasso: June 1, 2023 Ultima modifica: April 25, 2023 9:22 AM Primo Abbozzo: February 20, 2023 8:45 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Nomi e Scope I Nomi e oggetti Oggetti denotati e identificatoriðŸŸ© I nomi sono sequenze di caratteri o numeri aka: token alfanumerico (anche IDENTIFICATORE (per token guardare Grammatiche Regolari) utilizzate principalmente come Astrazione sul controllo e sui dati (quindi sono cose molto piÃ¹ facili da ricordare rispetto il suo encoding binario o a indirizzi).","title":"Nomi e Scope"},{"content":"Ripasso Prox: 31 Ripasso: May 28, 2022 Ultima modifica: April 28, 2022 5:07 PM Primo Abbozzo: February 24, 2022 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nNotazione asintotica Introduzione alla notazione asintotica Cercare di definire il tempo impiegato da una funzione per essere eseguita in termini di DIMENSIONE dell\u0026rsquo;input. **(il numero di bit a livello basso basso)\nMa abbiamo il problema di misura, in quanto dobbiamo considerare delle variabili che siano indipendenti rispetto alla macchina.\nCaratteristiche della notazione Vogliamo considerare una notazione asintotica (che guarda quanto fa il comportamento verso l\u0026rsquo;infinito)\nFunzione di costo Modelli asintotici Abbiamo trattato di o-piccolo e ogrande in Analisi.****\nO-grande Prendiamo due funzioni $f, g : \\mathbb{N} \\to \\mathbb{R}^{+}$ allora definiamo $f(x) = O(g(x))$ se esiste un $n_{0} \\in \\mathbb{N}$ e un $c$ tale che per cui per ogni $n \u003e n_{0}$ si ha che $$ f(n) \\leq c g(n) $$ Ossia: la funzione Ã¨ upper-bounded per numeri molto grandi. Quando vale la versione stretta si puÃ² dire che Ã¨ anche o-piccolo.\nNote interessanti che notazioni come $$ n^{c}, 2^{O(\\log n)}, n^{O(1)} $$ Sono equivalenti.\no-piccolo Usiamo la definizione trattata in Analisi: Theta Omega-grande omega-piccolo Costo e ComplessitÃ  computazionale Definizioni Analisi ammortizzata Introduzione Questa Ã¨ una tecnica che trova il costo medio di un algoritmo. La differenza con il calcolo del costo medio classico Ã¨ che questo calcolo mi trova il costo medio per una sequenza di operazioni mentre il classico mi trova il costo medio per una singola operazione\nCasi di utilizzo Di solito Ã¨ utile utilizzare questo metodo di analisi in queste condizioni\nCaso pessimo non frequente (quindi per dire che nella media un algoritmo Ã¨ molto piÃ¹ efficiente) Semplificare l\u0026rsquo;analisi del caso medio Aggregazione Vogliamo cercare un limite superiore su n operazioni, poi dividere il tutto per n.\nQuesto Ã¨ piÃ¹ utile quando il costo totale Ã¨ conosciuto\nAccantonamenti Questo Ã¨ basato sulla contabilitÃ , ho un certo credito iniziale, posso utilizzare tutto, ma non posso mai andare in negativo.\nQuesto Ã¨ utile quando ci sono diverse operazioni.\nUn esempio di analisi ammortizzata utilizzando gli accantonamenti Ã¨ la doubling and halving in cui 3 monete per ogni operazione di inserimento bastano poi per ricopiare ed espandere o diminuire il tutto a piacere (quindi 3n , si ha un costo costante). menti Ã¨ la doubling and halving in cui 3 monete per ogni operazione di inserimento bastano poi per ricopiare ed espandere o diminuire il tutto a piacere (quindi 3n , si ha un costo costante).\nRegistro Ripassi 14/03/2024 Ripassato per Time Complexity ","permalink":"https://flecart.github.io/notes/notazione-asintotica/","summary":"Ripasso Prox: 31 Ripasso: May 28, 2022 Ultima modifica: April 28, 2022 5:07 PM Primo Abbozzo: February 24, 2022 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nNotazione asintotica Introduzione alla notazione asintotica Cercare di definire il tempo impiegato da una funzione per essere eseguita in termini di DIMENSIONE dell\u0026rsquo;input. **(il numero di bit a livello basso basso)\nMa abbiamo il problema di misura, in quanto dobbiamo considerare delle variabili che siano indipendenti rispetto alla macchina.","title":"Notazione Asintotica"},{"content":"Ultima modifica: January 5, 2023 9:59 AM Primo Abbozzo: January 4, 2023 10:02 AM Studi Personali: No\nReplication and consistency Introduzione Ci sono due vantaggi principali nella replicazione dei dati\nVelocitÃ  Vicinanza geografica (quindi meno tempo ad andare a tornare) Maggiore computazione, quindi avere molti piÃ¹ processori che cercano di offrire lo stesso servizio. AffidabilitÃ  CosÃ¬ se una sede diventa corrotta, posso avere abbondanza, avere una copia da una altra parte, cosÃ¬ non perdo le informazioni! Se una macchina cade in errore, ho altre macchine che lo sostituiscono! Quindi dal punto di vista dellâ€™utente funziona ancora. Ma provare ad avere lo stesso dato in zone diverse porta a grandi problemi riguardo la consistenza! Come facciamo ad avere la garanzia che due cose diverse abbiano la stessa informazione?\nConsistency La nozione di consistenza non Ã¨ che sia definito in modo molto formale, possiamo solo descriverlo in modo molto generale come un contratto fra processo e dati su cui opera. Si puÃ² dire che un processo Ã¨ consistente se fa quello che dovrebbe fare (quindi vago vago descrizione).\nContinuous consistency Questo Ã¨ un modello molto vecchio, caduto in disuso perchÃ© principalemente pone delle interfaccie di difficile implementazione, nel senso che Ã¨ difficile utilizzarle e definirle in casi di applicazione reale (credo un pÃ² come se stessi utilizzando i semafori).\nIl concetto principale Ã¨ di errore assoluto o relativo di inconsistenza (â†’ quando lâ€™inconsistenza supera una certa deviazione, allora si prova a rimediare e ristabilire la consistenza), che andiamo a chiamare il conit. A seconda di quanto conit abbiamo decidiamo o meno se propagare la consistenza. Si nota subito da qui che Ã¨ difficile dare un valore di inconsistenza e quindi andiamo a disuso.\nEsempi di caso dâ€™uso sono i prezzi degli stock. Se variano di poco, non so 0.0001, allora non provo a renderlo consistente ancora (per quanto riguarda la lettura)\nPer maggiori informazioni consultare il capitolo 7 sulla consistenza continua.\nOrdered consistency (2) In questa parte trattiamo un idea presente giÃ  da tempo negli studi di parallelismo e sistemi distribuiti. Lâ€™idea principale Ã¨ che cerchiamo di ordinare la sequenza di lettura e scrittura. Questo sarÃ  la cosa comune ai vari protocolli.\nSequential consistency\nDefinito in Lamport 1979\nThe result of any execution is the same as if the (read and write) operations by all processes on the data store were executed in some sequential order and the operations of each individual process appear in this sequence in the order specified by its program\nIn questa definizione lo vediamo come ci sia il bozzolo dellâ€™idea che il sistema distribuito sia una unica macchina un pochetto sparsa. Abbiamo che tutte le operazioni sono sequenziali, come se stessimo su una macchina! In particolare ci basta che siano in ordine non sappiamo perÃ² quale ordine sia.\nCausal consistency\nQuesto Ã¨ un tipo speciale di sequential consistency, e lâ€™idea principale si basa sul fatto che non ha senso dare un ordine a delle cose indipendenti fra di loro, per esempio se faccio solamente dei read, non ha senso che provi a dare un ordine di lettura, tanto le cose che leggo sono le stesse.\nQuindi avrebbe senso ordinare solo le read che hanno una write che la influenza quindi che sia in qualche modo causato o influenzato dalla write.\nEventual consistency\nClient-centric consistency Questo Ã¨ un modello che abbiamo creato principalmente per i dispositivi mobili. Vogliamo garantire consistenza allâ€™utente anche quando il server non potrebbe essere pienamente consistente. Il motivo di cambiare visuale e ora metterci dal punto di vista dellâ€™utente Ã¨ che non possiamo predire lo spostamento di essa. E per esempio cambiare password in un punto. Spostarsi, e provare a loggare da un altro punto porta a un fallimento, questa non Ã¨ una buona cosa. La client centric consistency prova a risolvere questo problema\nEventual consistency\nOssia prima o poi il dato sarÃ  sincronizzato fra i dispositivi diversi (un giorno? due giorni? prima o poi lo fa!).\nPer molte cose questo ritardo non Ã¨ molto importante, per esempio i DNS.\nRead \u0026amp; write consistencies Monotonic-read consistency\nif a process reads the value of a data item x, any successive read operation on x by the process will always return that same value or a more recent value\nOssia, una volta letto una cosa al tempo t, non posso piÃ¹ leggere cose al tempo \u0026lt; t.\nEsempio: email , non voglio rileggere una email che ho giÃ  letto.\nMonotonic-write consistency\na write operation by a process on a data item x is completed before any successive operation on x by the same process\nOssia se voglio scrivere cose al tempo t, devo aspettare che tutte le write prima di t finiscano per fare qualunque cosa dopo t.\nUpdate del software, devo andare a leggere o scrivere sulla versione piÃ¹ recente.\nRead your writes\nthe effect of a write operation by a process on data item x will always be seen by a successive read operation on x by the same process\nOssia prima scrivo poi leggo.\nEs: password update. (non voglio che una password vecchia sia ancora considerata come valida dopo un cambio).\nWrites follow reads\na write operation by a process on data item x following a previous read operation on x by the same process is guaranteed to take place on the same or a more recent value of x that was read\nOssia quando modifico, lo faccio solo sullâ€™ultimo valore. (cioÃ¨ non posso scrivere su elementi vecchi (aka, non puÃ² succedere che il mio messaggio arrivi prima del messaggio che ho letto, dopo che câ€™Ã¨ stato consistenza))\nReplication Questa Ã¨ una parte complicata.\nPosso replicare non solo i dati ma ANCHE i servizi. E qui sale il problema dellâ€™identitÃ . Come gestire i servizi che fanno esattamente la stessa cosa?\n","permalink":"https://flecart.github.io/notes/replication-and-consistency/","summary":"Ultima modifica: January 5, 2023 9:59 AM Primo Abbozzo: January 4, 2023 10:02 AM Studi Personali: No\nReplication and consistency Introduzione Ci sono due vantaggi principali nella replicazione dei dati\nVelocitÃ  Vicinanza geografica (quindi meno tempo ad andare a tornare) Maggiore computazione, quindi avere molti piÃ¹ processori che cercano di offrire lo stesso servizio. AffidabilitÃ  CosÃ¬ se una sede diventa corrotta, posso avere abbondanza, avere una copia da una altra parte, cosÃ¬ non perdo le informazioni!","title":"Replication and consistency"},{"content":"Ripasso Prox: 12 Ripasso: May 27, 2023 Ultima modifica: May 16, 2023 1:10 PM Primo Abbozzo: April 19, 2023 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Sicurezza OS Introduzione Note generali sulla sicurezza Su tre fronti\nHardware Software human-ware (lol). Una altra tendenza generale Ã¨ che piÃ¹ Ã¨ complessa piÃ¹ Ã¨ insicura. e questo senso di insicurezza cresce in modo maggiore rispetto al lineare.\nCIA properties Ne abbiamo parlato in modo leggermente inverso in Sicurezza delle reti.\nIn questo caso sono\nAvailability Integrity Confidentiality Ãˆ cambiata solamente lâ€™availability, ossia la disponibilitÃ  in confronto alla sicurezza delel reti, in cui câ€™era lâ€™autenticazione.\nAvailability significa la disponibilitÃ  del servizio agli utenti, fare un DDoS per esempio Ã¨ una violazione di questo genere.\nLa cosa difficile Ã¨ garantire tutti e 3.\nVIOLAZIONE NOME\nDisclosure Alteration Denial of service Nel caso dellâ€™autenticazione sarebbe il phishing, furto didentitÃ  diciamo.\nSistema politica e meccanismi ðŸŸ© giÃ  descritta in Architettura software dellâ€™OS. lâ€™idea Ã¨ la stessa, separazione meccanismi e segurie questi meccanismi, solo che siamo in ambito sicurezza ora e non implementazione del kernel.\nCrittografia ðŸŸ© Anche questo Ã¨ stato descritto in Sicurezza delle reti, pubbliche private, simmetriche asimmetriche, DES AES RSA e ora curve elittiche etc. Puoi approfondire in OTP and Stream Ciphers e Asymmetric Cryptography. One-way functions difficili da invertire.\nSimmetrica, in cui sapere la chiave sai tutto.\nTipologie di attacchi ðŸŸ¨ Divisione per attivitÃ  dellâ€™attaccante Per veicolo dell\u0026rsquo;attacco (se da dentro o da fuori) Obiettivi dellâ€™attacco (quindi gravitÃ  della compromissione della macchina diciamo.\nSlides veicoli di attacco (3)\nAttacchi soliti Buffer overflow ðŸŸ© Slides contromisure\nTime of Check Time of use ðŸŸ© Tipo access ha detto, quando non Ã¨ atomico il check e lâ€™utilizzo, nel mezzo il file potrebbe essere cambiato\nTrojan horse ðŸŸ© Slides trojan horse\nEsempi di trojan horses\nVirus e batteri ðŸŸ¨ Slides virus e batteri\nSolitamente questi virus hanno comportamenti classici, e si puÃ² estrarre una firma, questo Ã¨ quello con cui utilizzano antivirus per checkare.\nAutenticazione Memorizzazione password ðŸŸ© SALT\nParlare di etc passwd ed /etc/shadow\nLogin spoofing ðŸŸ© Sniffers ðŸŸ¨+ Challenge based ðŸŸ© Smart card and physical objects ðŸŸ©- PAMðŸŸ¨ Slide PAM\nI campi sono 2/3, si indica per chi si utilizza la policy, poi politiche della policy (se passa o meno o simili) e poi qualcosa di pam da utilizzare\nAutorizzazione Vogliamo dare i permessi alle persone (chi puÃ² fare cosa).\nPrincipi dâ€™autorizzazione (4) ðŸŸ¨- Domini di accesso e ACL ðŸŸ©â€” Definiamo una riga per utente e in questa riga mettiamo tutti i permessi per questo utente.\nSlide Access control list\nExtended ACL Quando nelle acl\nPraticamente ogni posso associare dei permessi aggiuntivi che vanno ad ogni user del singolo gruppo. Poi queste sono passate da delle mask. In pratica mi permette di avere piÃ¹ controllo sui permessi.\nIn linux se viene utilizzato questo câ€™Ã¨ un + alla fine della lista permessi.\nsi utilizzano comandi come getfactl per gestire queste credo.\nCapability ðŸŸ©â€” Câ€™Ã¨ il concetto di capability ossia ogni risorsa deve essere associata una serie di diritti dâ€™accesso.\nSlides capability\nQuando viene mantenuto in lato utente, in pratica viene cifrata con la chiave privata del root, e questo viene sempre verificato. (solitamente nei sistemi distribuiti viene utilizzato questo metodo (posso eliminare la capability)\nMa come eseguire la revoca della capability di questi servizi?\nREVOCA DELLE CAPABILITIES(4) Slides rimozione della capability (4)\nEffective user nad real ðŸŸ©â€” Slide effective and real\nSi possono fare attacchi Toc Tou anche su questi checks (real son oquelli effettivi, dellâ€™utente, mentre effettive sono i permessi utilizzati durante il momento di check).\nMAC and DAC Mac BLP (bell lapadula)\nAccounting Si interessa dei sistemi di logging. Come per esempio il Journal che utilizzano tutti i servizi nel sistema operativo. In Ext4, forse citato in Filesystem viene trattato in breve.\n","permalink":"https://flecart.github.io/notes/sicurezza-os/","summary":"Ripasso Prox: 12 Ripasso: May 27, 2023 Ultima modifica: May 16, 2023 1:10 PM Primo Abbozzo: April 19, 2023 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Sicurezza OS Introduzione Note generali sulla sicurezza Su tre fronti\nHardware Software human-ware (lol). Una altra tendenza generale Ã¨ che piÃ¹ Ã¨ complessa piÃ¹ Ã¨ insicura. e questo senso di insicurezza cresce in modo maggiore rispetto al lineare.\nCIA properties Ne abbiamo parlato in modo leggermente inverso in Sicurezza delle reti.","title":"Sicurezza OS"},{"content":"Ripasso Prox: 40 Ripasso: May 29, 2023 Ultima modifica: April 29, 2023 10:09 AM Primo Abbozzo: June 5, 2022 3:43 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: Yes\nQuesti sono appunti che mi faccio durante lo studio individuale estivo per probabilitÃ  e statistica.\nIntroduzione La probabilitÃ  Termini Esito ed esperimenti aleatorio Lâ€™evento Ã¨ quello che accade, mentre un esperimento aleatorio qualcosa di cui vogliamo andare a misurare la probabilitÃ  diciamo. Esperimento aleatorio: esperimento di cui non conosciamo il risultato con certezza. Esito: risultato dellâ€™esperimento aleatorio\nSpazio campionario ed evento Spazio campionatorio Lo spazio campionatorio Ã¨ l\u0026rsquo;insieme di tutti gli stati possibili per una certa cosa da misurare (ossia di un esperimento aleatorio), gli stati sono talvolta anche chiamati sample points oppure outcomes in modo piÃ¹ semplice.\nEvento Ãˆ un sottoinsieme dello spazio campionatorio. Se qualcosa della cosa che stiamo misurando Ã¨ dentro questo sottoinsieme, all\u0026rsquo;ora diciamo che l\u0026rsquo;evento Ã¨ accaduto altrimenti no.\nNOTA: dato che stiamo parlando di sottoinsiemi, valgono tutte le operazioni di intersezione unione, complementare studiate durante Teoria assiomatica degli insiemi.\nUno spazio di probabilitÃ  di solito Ã¨ definito come $\\Omega, F, P$, con F sigma algebra e P una misura di probabilitÃ , ossia tale per cui $P(\\Omega) = 1,$ Ã¨ additiva, che descriviamo leggermente meglio in seguito. Si puÃ² dire che $P$ sia una funzione dall\u0026rsquo;insieme delle parti di $\\Omega$ ai reali in $[0, 1]$.\nUna cosa particolare da osservare riguardo $P$ Ã¨ che questa probabilitÃ  non Ã¨ osservabile, non riusciamo ad osservare il fatto che il singolo evento abbia una certa probabilitÃ , questa probabilitÃ  Ã¨ qualcosa che nasce dopo un numero molto alto di trials che si susseguono per uno stesso processo stocastico.\nAssiomi sugli eventi Vogliamo cercare di dire cosa Ã¨ un evento su uno spazio campionatorio, possiamo dire che Ã¨ un subset dell\u0026rsquo;insieme delle parti tali per cui:\nse $E$ Ã¨ un evento, anche $E^{c} := \\{x \\in P(\\Omega) : x \\not\\in E)$ Ã¨ un evento L\u0026rsquo;unione infinita di eventi Ã¨ un evento $\\Omega$ Ã¨ un evento. Assiomi della probabilitÃ  Questi assiomi si potrebbero giustificare in modo molto migliore partendo dalla teoria della misura, proverÃ² a dire qualcosa partendo da quella nelle prossime sezioni.\nIntanto enuncio qui in modo molto informale gli assiomi principali che abbiamo.\nAssioma 1 La probabilitÃ  di qualunque evento Ã¨ maggiore di 0 $$ \\forall E \\in \\mathcal{P}(\\Omega), \\mathbb{P}(E) \\in \\mathbb{R}, \\mathbb{P}(E) \\geq 0 $$ Assioma 2 La probabilitÃ  dello spazio campionatorio Ã¨ 1 $$ P(\\Omega) = 1 $$ Assioma 3 la probabilitÃ  Ã¨ additiva per insiemi disgiunti. $$ \\mathbb{P}(\\cup_{i = 1}^{\\infty}E_{i}) = \\sum_{i=1}^{\\infty}\\mathbb{P}(E_{i}) $$ Conseguenze principali degli assiomi (4) Valore dellâ€™insieme vuoto\nPossiamo considerare una successione infinita di elementi vuoti, questi sono tutti disgiunti, e sono anche tutti uguali perchÃ© sono applicati sullo stesso insieme.\nSe fosse diverso da 0 allora sarebbe infinito, ma deve essere compreso fra 0 e 1, quindi deve essere 0.\nUnione disgiunta finita\nBasta andare a considerare una successione con 0, questa Ã¨ infinita, ma i vuoti non danno nessun contributo quindi vale ancora:\n$$ \\mu(\\bigcup^n A_n) = \\mu(\\bigcup^\\infty A_n) = \\sum^\\infty \\mu(A_n) = \\sum^n \\mu(A_n) = $$ Valore dellâ€™inverso\ndeve essere che, basta considerare che $\\Omega = A_n \\cup A_n^c$ e lâ€™unione disgiunta.\n$$ \\mu(A_n) = 1 - \\mu(A_n^c) $$ Monotonia della probabilitÃ \nOssia se vale\n$$ A \\subset B \\implies \\mu(A) \\leq \\mu (B) $$ Principio di inclusione esclusione\nProbabilitÃ  uniforme ðŸŸ© Il primo Ã¨ vero perchÃ©\n$$ \\forall i, n \\cdot P(w_i) = \\sum_{i =1}^n P(\\omega_i) = P(\\bigcup_{i = 1} ^n \\omega_i) = P(\\Omega) = 1 \\implies \\forall i, P(w_i) = 1/n $$ Lâ€™altro Ã¨ la formula di laplace, perchÃ© siano il numero di eventi di A, posso scriverlo come unione di quegli elementi, abbiamo detto che sono n, per questo riesco a ricostruire quel numero.\nProbabilitÃ  discreta Se abbiamo una distribuzione di probabilitÃ , cioÃ¨ una probabilitÃ  definita su tutti gli elementi singoletto, allora possiamo avere una probabilitÃ  discreta, ossia probabilitÃ  ben definita che sia finito o numerabile.\nDefinizione probabilitÃ  discreta ðŸŸ© DensitÃ  discreta\nPer 1.7 si intende che p deve essere compreso fra 0 e 1 e la somma per tutti gli elementi dello spazio campionario deve essere 1\nCaratterizzazione probabilitÃ  discrete ðŸŸ© ContinuitÃ  della probabilitÃ  discreta ðŸŸ¨+ Dimostrazione\nOssia se ho uno spazio di probabilitÃ  allora posso avere delle caratteristiche (brutte secondo lollo) riguardo la continuitÃ  della funzione.\nAnche se per questa parte che non utilizza teoria della misura questo teorema non Ã¨ che sia molto utile.\nComunque per questa parte forse Ã¨ meglio farlo dalla misura definita sulle algebre, che Ã¨ fatta in maniera piÃ¹ generale e ho anche la sigma sub-additivitÃ  all\u0026rsquo;interno, non so, forse piÃ¹ difficile??\nImpostazione classica della teoria della probabilitÃ  (non fare) Spazi di misura e di probabilitÃ  Dico che ho uno spazio misurabile una coppia $(\\Omega, F)$, tale che F sia un insieme di sottoinsiemi di omega, chiamato spazio campionario, e F insieme di eventi. Deve essere che F Ã¨ una sigma algebra, ossia tali per cui siano chiusi per complementazione e per unione contabile.\nSi parla di spazio di misura quando allo spazio misurabile associamo una funzione di misura.\nParliamo di spazio di probabilitÃ  se ho anche una funzione di misura tale per cui $P(\\Omega) = 1$, . Si ricorda che la funzione di misura Ã¨ tale se ha come codominio 0 to infty, e ha vuoto = 0, e che sia sigma additiva.\nContinuitÃ  dallâ€™alto e dal basso. Se ho che la funzione di misura sia finita, allora vale che $A_n \\uparrow A, \\lim_{n \\to \\infty} \\mu(A_n) = \\mu (A)$ , e che\n$\\forall i, i \u003c n, A_i \\subseteq A_n$\nIn modo simile Ã¨ definito la continuitÃ  dal basso, solo che ora sono insiemi uno incluso lâ€™altro. Attualmente non so cosa implichi questo fatto, nÃ© in che modo Ã¨ utilizzata questa continuitÃ â€¦ Forse per Borel Cantelli, ma poi non so cosa farmene di borel cantelliâ€¦\nEvento complementare\nSommatoria finita di eventi disgiunti\nPrincipio di inclusione-esclusione ðŸ•³ï¸\n","permalink":"https://flecart.github.io/notes/spazi-di-probabilita/","summary":"Ripasso Prox: 40 Ripasso: May 29, 2023 Ultima modifica: April 29, 2023 10:09 AM Primo Abbozzo: June 5, 2022 3:43 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: Yes\nQuesti sono appunti che mi faccio durante lo studio individuale estivo per probabilitÃ  e statistica.\nIntroduzione La probabilitÃ  Termini Esito ed esperimenti aleatorio Lâ€™evento Ã¨ quello che accade, mentre un esperimento aleatorio qualcosa di cui vogliamo andare a misurare la probabilitÃ  diciamo. Esperimento aleatorio: esperimento di cui non conosciamo il risultato con certezza.","title":"Spazi di probabilita"},{"content":"Data types Default data types ðŸŸ© I tipi di dati sono\nCarattere numero data tempo intervallo di tempo booleano blob (binario) clob (carattere) Setting custom data types ðŸŸ© Ma possono essere definiti anche tipi di dati custom, la sintassi Ã¨ simile\nCREATE DOMAIN Grade AS SMALLINT DEFAULT NULL CHECK (value \u0026gt;= 18 AND value \u0026lt;= 30) Altering existing domains ðŸŸ© In cui posso mettere anche dei check custom.\nDROP DOMAIN Per cancellare il domain lÃ¬ presente\nE si puÃ² anche cambiare con\nALTER DOMAIN Posso aggiungere o eliminare constraints per esempio.\nPerÃ² a seguito di questo comando, dovrei essere in grado di modificare correttamente i valori con schema cambiato, metterli a default, o metterli a null diciamo.\nData definitions Database Creation ðŸŸ© CREATE DATABASE db_name, che va a creare un database che puÃ² contenere molte tavole, schemi diversi e simili.\nSchema ðŸŸ¨ Ãˆ una descrizione logica di come Ã¨ strutturato l\u0026rsquo;intero database, non Ã¨ da confondere con lo schema di una singola tavola.\nSchema creation Lo schema Ã¨ la specificazione dei domini e delle restrizioni che ogni colonna deve avere per essere integra. In piÃ¹ possono essere definite view diverse o anche authorization.\nCREATE SCHEMA schema_name\nTable La tavola specifica una relazione vuota, che puÃ² seguire o meno uno schema, come definito di sopra.\nCreate table ðŸŸ© Table constraints ðŸŸ© Durante la creazione di una table posso specificare cose come\nTipo (intero, carattere?) Valore di default Constraints (tipo NOT NULL) Reference esterna o chiave di tavola. Deletion and change ðŸŸ© Abbiamo comandi come\nDROP TABLE ALTER TABLE Per eliminare o cambiare lo schema della singola table.\nSolitamente posso modificare singole colonne per sql, aggiungere constraints o dati di default.\nReferential trigger ðŸŸ©- Per le foreign keys posso andare a definire anche una\nAzione che viene eseguito quanto l\u0026rsquo;altra tabella viene Aggiornata Eliminata Azioni permesse sulla table con foreign key Cascade (eliminare o aggiornare di conseguenza) Set null set default no op, che non permette di fare l\u0026rsquo;operazione nemmeno sulla tavola originaria. Indexes ðŸŸ¨- Sono delle strutture di dati che permettono di svolgere certe operazioni in modo piÃ¹ efficiente, cercheremo di distinguere i casi in cui Ã¨ effettivamente utile andare a creare questo indice. Questo solitamente Ã¨ fatto al livello fisico.\nCREATE INDEX idx_surname ON officer (Surname) Creo un indice con nome, su un attributo della table.\nData operations CRUD:\nCreate -\u0026gt; Insert Read -\u0026gt; SELECT Update -\u0026gt; UPDATE Delete -\u0026gt; DELETE (molto rischioso!) Select Le operazioni di select Ã¨ molto simile a proiezione e selezione che sono trattati in Relational Algebra.\nSintassi classica ðŸŸ© SELECT attributes FROM tables and joins [WHERE condition] [GROUP BY attributes] [HAVING conditions] [ORDER BY attributes] Compare: algebra relazionale ðŸŸ© Si possono considerare molte similitudini in Relational Algebra\nSelect and projection $\\pi_{age, height}(\\sigma_{age \u003c 30}(people))$ Select with renaming (projection) Pure select $\\sigma_{age\u003c30}(People)$ Projection without selection $\\pi_{age, height}(people)$ che prende colonne. Da questo si puÃ² notare che SELECT da sola gestisce tre relazioni\nSelect Projection Rename Che sono stati trattati nell\u0026rsquo;algebra relazionale. Possono anche essere estesi ad avere le JOIN usando cose del from. Si potrebbe semplificare affermando\nWHERE = Selection in algebra relazionale SELECT = projection FROM = prodotto cartesiano. Esempio complesso di query con Cartesian product e renaming Like and null values ðŸŸ© Like Ã¨ utilizzato per fare pattern matching sulla stringa. Mentre i null values si possono gestire con sintassi $AGE\\, is \\, NULL$\nJoin Sintassi ðŸŸ¨ precedentemente nella sezione #Select abbiamo utilizzato join delle tables in maniera implicita utilizzando il prodotto cartesiano. Esiste perÃ² anche una istruzione esplicita per dire che vogliamo fare JOIN, molto coerente con la teoria presente in Relational Algebra.\nSELECT ... FROM leftTable [JOIN rightTable ON condition] [WHERE predicate] Esempio di differenza fra JOIN e il prodotto cartesiano con la sintassi di sopra. Inner and outer joins ðŸŸ© La differenza principale fra inner e outer join Ã¨\nInner Dati che non hanno elementi in comune vengono scartati (come quello presente sulla slides di sopra) questo viene anche chiamato natural join. Outer Vengono tenuti anche i dati che non fanno matching in una parte in comune, solitamente questi sono sempre chiamati left o right, ma vedremo dopo esattamente quale sia la semantica LEFT: (right Ã¨ esattamente il contrario) Ritorna sempre il sinistro, ma il destro puÃ² anche essere null FULL: ritorna sinistro se c\u0026rsquo;Ã¨ e destro se c\u0026rsquo;Ã¨.\nRemaining CRUD operations La sintassi di insertion, deletion and update Ã¨ molto piÃ¹ semplice rispetto alla lettura, quindi la mettiamo nella sottosezione.\nInsert ðŸŸ© NOTE: Ã¨ importante l\u0026rsquo;ordine di inserimento!\nINSERT INTO table [attrs] VALUES(vals) | SELECT roba.. Update ðŸŸ© UPDATE TableName SET Attribute = \u0026lt; Expression, select, null or similar \u0026gt; WHERE \u0026lt;cond\u0026gt; Esempi: Delete ðŸŸ© DELETE FROM table [WHERE condition] ### Altre Istruzioni #### Sorting ðŸŸ© Per fare sorting basta aggiungere **ORDER BY** Order by puÃ² essere ascendente o discendente (facile se Ã¨ alfanumerica come attributo). DEFAULT: descending. Union intersection and difference ðŸŸ¨ UNIONE\nUso normale: come in figura Nel caso venga definito ALL, anche se Ã¨ doppio, viene mantenuto. Nel caso di conflitti semantici, utilizzare positional notation, se sono nella stessa posizione vengono messi assieme (il nome dell\u0026rsquo;attributo Ã¨ sempre della prima tavola) DIFFERENZA Si usa except, e poi altre notazioni sono simil ial precedente.\nINTERSEZIONE Si usa intersect come istruzione. (ma Ã¨ meglio usare il where, descritto in #Select, che Ã¨ equivalente).\nIntersection\nNested Queries NOTA: ogni subquery viene eseguita ogni volta per\nCorrectness conditions ðŸŸ© Le queries innestate vengono eseguite per ogni tupla esterna, e sono corrette se quanto viene ritornato Ã¨ coerente con l\u0026rsquo;input del secondo\nSELECT Name, Income FROM People WHERE Name IN (SELECT Father FROM Fatherhood, People WHERE Child=Name AND Income\u0026gt;20) In questo caso IN si aspetta poi un insieme, che Ã¨ quanto ritornato nella subquery, il vantaggio principale di questo approccio Ã¨ la leggibilitÃ ,\nVisibilitÃ  ðŸŸ© Ci sono due note riguardo la visibilitÃ , perchÃ© seguendo una logica simile agli scopes strutturali se sono in scope esterno non posso accedere a quello internamente definito. Mentre la query innestata puÃ² leggere variabili definite esternamente. Chiaramente se hai due nested diverse, non riescono ad avere stesso variabile, segui le stesse regole di scoping definito in linguaggi di programmazione.\nExistance ðŸŸ© Exists Molto intuitivo, se sai un po' di [Logica del Primo ordine](/notes/logica-del-primo-ordine). #### Any and ALL ðŸŸ©--- Sono altri predicati possibili per cose innestate Aggregate functions Gli aggregate consentono di ritornare un valore unico da una lista di dati. Hanno una semantica precisa: Prima fatto tutto, ignorando dell\u0026rsquo;esistenza del groupby, fanno una selezione di tutti gli attributi che sono presenti qui, e poi effettivamente raggruppano. Sul libro atzeni Ã¨ descritto in pagina 123. L\u0026rsquo;aspetto principale da ricordare Ã¨ che attributi in group by sono superset degli attributi di selezione.\nClassical sintax ðŸŸ© La sintassi classica per questo genere di query Ã¨\nAggr([DISTINCT] attribute) Attribute Ã¨ il dominio su cui andare a runnare la funzione di aggregazione.\nSome aggregate functions Count Ritorna semplicemente il numero di elementi dentro la lista Caso interessante da ricordare Ã¨ count NULL values AVG, MAX, MIN ðŸŸ© Sintassi Ã¨ uguale al precedente, poi la semantica Ã¨ un po\u0026rsquo; diversa, ma credo sia chiara dal nome delal fuznione aggregate\nGrouping ðŸŸ© La sintassi classica Ã¨ GROUP BY attributeList.\nSemantica ðŸŸ© Prima esegue la query normale, come se grouping non esistesse. Poi esegue il grouping, e se c\u0026rsquo;Ã¨ un aggregate function, eseguirlo sul singolo gruppo. Questa cosa Ã¨ molto importante da conoscere perchÃ© altrimenti sbagli al query e questo mi era successo in passato, ci ho speso molto tempo. Giustifica anche il motivo per cui devi fare select dell\u0026rsquo;attributo di cui vuoi fare grouping, altrimenti non hai niente da grouppare diciamo! NOTA: aggregate Ã¨ eseguito sul singolo gruppo!\nOther conditions ðŸŸ© Si puÃ² usare HAVING per aggiungere altre condizioni sui gruppi in modo simile a quanto faceva WHERE dentro #Select.\nComportamento con i NULLs Altro Sull\u0026rsquo;esecuzione di SQL ðŸŸ© Ãˆ il DBMS che si occupa di eseguire la query ed ottimizzarla. Avere query corrette e leggibili Ã¨ piÃ¹ importante. Questo descrive anche il perchÃ© sarebbe a volte sensato farle innestate. ","permalink":"https://flecart.github.io/notes/structured-query-language/","summary":"Data types Default data types ðŸŸ© I tipi di dati sono\nCarattere numero data tempo intervallo di tempo booleano blob (binario) clob (carattere) Setting custom data types ðŸŸ© Ma possono essere definiti anche tipi di dati custom, la sintassi Ã¨ simile\nCREATE DOMAIN Grade AS SMALLINT DEFAULT NULL CHECK (value \u0026gt;= 18 AND value \u0026lt;= 30) Altering existing domains ðŸŸ© In cui posso mettere anche dei check custom.\nDROP DOMAIN Per cancellare il domain lÃ¬ presente","title":"Structured Query Language"},{"content":" \u0026ldquo;Information theory must precede probability theory, and not be based on it. By the very essence of this discipline, the foundations of information theory have a finite combinatorial character.\u0026rdquo; Kolmogorov, A. N. (1983).Â Combinatorial foundations of information theory and the calculus of probabilities.\nRussian mathematical surveys,Â 38Â (4), 29-40.\n\u0026ldquo;it is clear that elements requiring an extremely large number of words for their definition should be considered as having an extremely low probability.\u0026rdquo; (Borel E.,Â 1909Â p. 272).\nQuesta sezione si distacca dalla probabilitÃ  classica che abbiamo fatto in questo corso, ma per vicinanza metto qui l\u0026rsquo;appunto.\nPrefix Complexity Definizione $$ K(s) = min_{p}\\left\\{ \\lvert p \\rvert : U_{pr}(p) = s \\right\\} $$ L\u0026rsquo;unica differenza con Kolmogorov complexity Ã¨ che qui usiamo una macchina di turing con prefix codes.\nIntuizione Una macchina che esegue programmi random puÃ² produrre una certa stringa? Definiamo la probabilitÃ  come $$ P(x) = \\sum_{p:U(p)=x} 2^{-l(p)} $$ Che Ã¨ un modo per dire generare in modo random certi programmi. Il valore di sopra Ã¨ simile a $$ P(x) \\approx 2^{-K(x)} $$ Per $K$ vedi Kolmogorov complexity. TODO: cercare di capire perchÃ© limitarsi solamente alla versione piÃ¹ corta.\nPrefix Machine Da Leonid Levin, risolve il problema di termine di interpretazione, perchÃ© prefix codes hanno valore sempre minore di 1 come descritto in Entropy#Krafts Inequality. Se non si escludono, fanno qualcosa di brutto con quel valore di probabilitÃ , perchÃ© la somma di tutti avrebbe superato $1$ e non avrebbe soddisfatto gli assiomi La proprietÃ  principale Ã¨ che non esistono due programmi per questa macchina tale per cui uno sia prefisso di altro.\nSelf delimiting codes Con i prefix codes posso avere delle cose self-delimiting, perchÃ© so quando un codice finisce e posso interpretarlo per la proprietÃ  dei prefissi.\nDefinition of prefix complexity Praticamente per encodare un numero encodiamo la sua lunghezza binaria con un codice e poi concateniamo il numero stesso. Quindi il codice finale avrebbe lunghezza di $$ 2\\log \\log(\\lvert s \\rvert ) + \\lvert s \\rvert $$ Relazione con complessitÃ  normale $$ C(s) + O(1) \\leq K(s) \u003c C(s) + 2\\log(C(s)) + O(1) $$ La prima diseguaglianza sembra essere presa da Kolmogorov complexity#Teorema dell\u0026rsquo;invarianza, mentre la seconda dallo stesso teorema piÃ¹ dal fatto che stiamo usando una macchina di Turing con prefissi.\nAlgorithmic probability Definizione algorithmic probability $$ \\mathbb{P}(x) = \\sum_{p:U(p)=x} 2^{-l(p)} $$ TODO: sarebbe carino provare ad esplorare di piÃ¹ questo topic, perchÃ© mi sembra abbia belle connessioni con resto. Poi un sacco di questo content Ã¨ bloggabile.\n","permalink":"https://flecart.github.io/notes/algorithmic-probability/","summary":"\u0026ldquo;Information theory must precede probability theory, and not be based on it. By the very essence of this discipline, the foundations of information theory have a finite combinatorial character.\u0026rdquo; Kolmogorov, A. N. (1983).Â Combinatorial foundations of information theory and the calculus of probabilities.\nRussian mathematical surveys,Â 38Â (4), 29-40.\n\u0026ldquo;it is clear that elements requiring an extremely large number of words for their definition should be considered as having an extremely low probability.","title":"Algorithmic Probability"},{"content":"Ripasso: May 14, 2023 Ultima modifica: May 6, 2023 6:25 PM Primo Abbozzo: March 30, 2023 4:20 PM Studi Personali: No\nCookies Gli utilizzi piÃ¹ soliti sono per Autenticazione e per Autorizzazione, perchÃ© sono delle informazioni che il server genera e mette al client, come se fossero dei segreti cifrati.\nCookie Questi sono una estensione di netscape, che si appoggiano al protocollo HTTP per implementare certe funzionalitÃ  (soprattutto il fatto di essere stateless, quindi Ã¨ utile per avere informazioni sugli stati su qualcosa.)\nSlide cookie\nVengon utilizzati header specifici per settare il cookie.\nArchitettura dei cookie I cookie sono briciole di informazioni sul client generati dall\u0026rsquo;applicazione server, di seguito nelle slides vedi in che modo funzionano solitamente:\nSlide cookie\nTipologie di coockie Permanenti sono utili soprattutto per mantenere informazioni di **preferenza sugli utenti. Di sessione qui ti diverti a fare cose sulla sicurezza ðŸ˜€. Di terze parti sono utilizzati per decidere che pubblicitÃ  mostrarti, per esempio basandosi sulla history di ricerche. Autenticazione Non ci piacerebbe autenticarci ogni volta a ogni cambio di tab ossia identificare chi stia facendo l\u0026rsquo;acceso alla risorsa come se fosse un riconoscimento, i cookie sono buoni per storare queste informazioni.\nSchemi di autenticazione (3) Se provi ad accedere a una risorsa, il server dovrebbe risponderti con 401 Not authenticated e darti un header WWW-authenticate dandoti informazioni su come autenticarti.\nBASIC\nSlide basic auth\nQuesto manda in pratica tutto in chiaro attraverso l\u0026rsquo;header del client, ovviamente non Ã¨ che sia molto sicuroâ€¦\nQuindi Ã¨ in disuso.\nDIGEST\nSlide digest auth\nIn pratica Ã¨ come il basic, ma invece di mandare la cosa in chiaro si manda hash + nonce, in modo da evitare replay attack come specificato in Sicurezza delle reti.\nAnche qui Ã¨ difficile capire quando la sessione scade.\nBEARER\nIn pratica il server produce qualcosa, un token e poi il client utilizza solo questo per autenticarsi nelle connessioni successive.\nPuÃ² essere utilizzato sia in session sia in token auth\nSession-based authentication Slides session based authentication\nIn pratica al primo collegamento ti metto dei cookie, che sono i cookie di sessioen, che scadono in un certo tempo. Poi per ogni collegamento ti mando anche i cookie di sessione, che danno informazioni di autenticazione.\nQuesto Ã¨ uno schema classico, il server ha il controllo sul tempo e sulla revoca di questa sessione.\nToken-based authentication Slides token based auth\nPraticamente quando la prima volta fai auth io ti rispondo con un token firmato come potrebbe essere Il token JWT.\nQuesto poi viene utilizzato. la cosa bella Ã¨ che utilizzo il server molto meno, nel senso che deve andare a memorizzare molto meno, basta verificare la firma ogni volta.\nIl token JWT Questo l\u0026rsquo;abbiamo utilizzato molto spesso per la parte di cybersec!\nSlide JWT\nContenuto Header Payload e signature\nAltre note: CORS e Caching Introduzione Cross site vulnerability Slide headers CORS\nNon vorremmo avere le javascript esterno non controllato, potrebbero avere codice maligno! Pensa se ti riuscissero a pishare il cookie di sessione.\nPosso mettere nelle options di HTTP scripts permessi\nCORS headers Slide headers per cors\nHTTP Caching (2) Server specified expiration\nSlide server specified expiration\nIn pratica attraverso certe specificazioni dico quando il cache sarÃ  expired.\nHeuristic expiration\nHeuristic expiration\nQuesto perchÃ© spesso\nRisposta dalla cache\nSe Ã¨ non modificata ti mando un codice 304 Not modified altrimenti ti risponso, cosÃ¬ non devo fare due richeiste, una head per veder elast modified e una altra per mandarti la get.\n","permalink":"https://flecart.github.io/notes/cookie-e-autenticazione/","summary":"Ripasso: May 14, 2023 Ultima modifica: May 6, 2023 6:25 PM Primo Abbozzo: March 30, 2023 4:20 PM Studi Personali: No\nCookies Gli utilizzi piÃ¹ soliti sono per Autenticazione e per Autorizzazione, perchÃ© sono delle informazioni che il server genera e mette al client, come se fossero dei segreti cifrati.\nCookie Questi sono una estensione di netscape, che si appoggiano al protocollo HTTP per implementare certe funzionalitÃ  (soprattutto il fatto di essere stateless, quindi Ã¨ utile per avere informazioni sugli stati su qualcosa.","title":"Cookie e autenticazione"},{"content":"Ripasso Prox: 30 Ripasso: May 20, 2023 Ultima modifica: May 14, 2023 5:18 PM Primo Abbozzo: March 10, 2023 12:10 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nIntroduzione Data or Control plane come fanno i router a fare forwarding dei pacchetti? e decidere come mandare? Come fanno a passare. Sono le tabelle di instradamento. Si puÃ² dire di end-to-end perchÃ© solamente il sender e receiver andranno a livello applicazione, e leggeranno le cose (se criptato veramente solo loro riescono a fare questo).\nFunzioni principali Forwarding che in pratica Ã¨ passare il pacchetto al successivo, Ã¨ parte del data plane.\nQuesta Ã¨ una cosa molto semplice, in pratica bisogna capire da una porta di ingresso quale sarÃ  la porta dâ€™uscita del router. Guardando l\u0026rsquo;intestazione del pacchetto. Se non fa match nessuna riga della tabella allora manda nel router di default che avrÃ  un reach maggiore, piÃ¹ probabile che sappia dove mandare.\nRouting invece va a scrivere mappe nel grafico della rete, cioÃ¨ capisce quale sia il percorso piÃ¹ breve all\u0026rsquo;interno della rete, Ã¨ parte del control plane.\nTutta la rete in modo coordinato prova a creare questo piano (me se stesse segnalando se una segnaletica funziona ancora, se la strada va ancora dove dovrebbe andare (e.g. se Ã¨ crollato un ponte dovresti sapere se quella strada non funziona piÃ¹)).\nSolitamente questo Ã¨ fatto con un software chiamato SDN (ma anche un umano potrebbe farle, anche se sarebbe troppo lento).\nRouting control planes La differenza fra i due Ã¨ sostanzialmente architetturale, se ne parla in Architetture a livello applicazione ðŸŸ©.\nPER ROUTER CONTROL PLANE possiamo dire che sia un modo semplice del control plane per stabilire la tabella di instradamento, in pratica listo tutti i collegamenti che ho nella tabella con i loro IP di interesse, quindi se un prefisso matcha quello allora mando lÃ¬. Ãˆ strano che i router siano anche in grado di fare prefisso piÃ¹ lungo per matchare. In questo modo utilizzando un algoirtmo locale, distribuito, posso avere una tabella di istradamento. gli algoritmi locali possono fare scelte non coordinate, dato che puÃ² cambiare nel tempo la situazione, l\u0026rsquo;informazione locale potrebbe non essere del tutto corretta.\nLOGICALLY CENTRALIZED CONTROL PLANE quando c\u0026rsquo;Ã¨ una struttura centrale che contiene tutte le informazioni dei singoli router (o almeno quanto trasmesso), e da lÃ¬ aggiorna le tabelle di instradamento dei singoli router. (Control Agent Ã¨ il singolo router, che trasmette a un controllo remoto). La cosa importante Ã¨ che il cos Remote Contorller Ã¨ conoscente di tutti i dati principali della rete. Questo rende piÃ¹ efficiente, perchÃ© ha tutte le informazioni per fare le decisioni migliori.\nPerÃ² ha bisogno di comunicare fra CA e RC, e se non funziona la comunicazione non avrei comunque le informazioni perfette.\nInoltre deve essere un processo bono, e si dovrebbe capire chi avrebbe la responsabiltiÃ  di pagare il remote controller, i provider? gli utenti finali?\nImmagine semplificazione Data e Control Plane\nService Model I modelli di servizio definiscono le caratteristiche che dovrebbe avere il servizio di trasporto end-to-end dei pacchetti. Alcune caratteristiche potrebbero esser come consegna garantita, o garantita consegna entro certo tempo, oppure il flow dei datagrammi in ordine, minima bandwidth, servizi di sicurezza sul trasporto. Ma queste caratteristiche alla fine non sono comunque mai garantite. Quindi possiamo indire un sistema best-effort, ma non Ã¨ che sia comunque garantito qualcosa, potrei dire che una rete che non Ã¨ in grado di trasportare niente sta facendo il massimo di quanto riesce a fare. Non ci aiuta molto.\nATM (asynchronous transfer model) Ã¨ un servizio che prova a fare questo, cercare di misurare il modello di servizio del trasporto che in una specifico spazio temporale posso darti tutte le risorse, e allora avresti le garanzie dette sopra. E se non riesco a riempire tutto il canale in quel tempo, do lo spazio in piÃ¹ ad altri che non hanno bisogno di quella garanzia.\nCâ€™Ã¨ un Overhead per la quantitÃ  di dati e la lunghezza di header (se header molto lungo, alla fine trasmetto meno percentuale di dati), perÃ² se faccio troppo lungo ci metto di piÃ¹ a mandare, quindi altri pacchetti potrebbero metterci molto di piÃ¹ ad arrivare, e perdere la garanzia sul tempo minimo di arrivare. era 32 o 64, quindi si Ã¨ fatta una scelta politica che Ã¨ 48 byte, e fa schifo perchÃ© non Ã¨ una potenza di 2 e devi fare check leggermente piÃ¹ complicate.\nA noi di solito non serve questa garanzia, noi utenti dico, ma al backbone di internet Ã¨ importante e si sono messi cosÃ¬. Ci sono molti tipologie di ATM come\nconstant bit rate ( voice over Ip, abbiamo biosgno di flusso costante per la voce, vogliamo real time, oppure coso di un reattore nucleare, senza nessuna congestione e con forti garanzie su loss, ordering e timing).\nVariable bit rate, come il video, perchÃ© ha bisongo di un sacchissimo di informazioni, un byte per un pixel bianco e nero, non si puÃ² trasmettere tanta roba..\nAltro che non listo\nSlide garanzie Service Models\nThe Router Router architecture ci sono credo molti modi per implementare la funzione di router, in generale in un singolo ciclo di clock ti riescono a far entrare e far uscire il pacchetto, questo sarebbe il router buono\nQuindi possiamo individuare\nPorte di input Un processore di routing che ti indirizza nell uscita giusta Un sistema di switching fabric per poter mandare l\u0026rsquo;informazione nella porta giusta Porte di uscita Slide sistema di routing\nla parte del processore Ã¨ molto piÃ¹ utilizzato nella parte di Control Plane\nForwarding Il forwarding tratta delle politiche che il processore di routing dovrebbe utilizzare per capire in quale porta di output ti potrebbe mandare\nDestination based forwarding in cui si va a guardare l\u0026rsquo;indirizzo di arrivo e si decide in questo modo come mandarti.\nVediamo un esempio di questa tipologia di forwarding.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Data Plane/Untitled 3.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Data Plane/Untitled 3\u0026quot;\u0026gt; Da notare che sono degli intervalli in questo caso di esempio, ed Ã¨ esattamente come avevamo diviso le subnets in un esercizio passato, in Livello di Rete.\nQuesto Ã¨ il piÃ¹ usato, Ã¨ il longest prefix match. Questo Ã¨ bello perchÃ© si possono indirizzare nelle (TCAMs Ternary content addressable memories, CISCO ha inventato sta tecnologia ed Ã¨ la piÃ¹ forte sul mercato attualmente) che praticamente ti trova in singolo ciclo di clock quello corretto.\nLâ€™algoritmo normale per trovare l\u0026rsquo;indirizzo corretto, sarebbe comunque fatto in $O(n)$, ma se lâ€™hardware riesce a fare in parallelo con tutte le tabelle in un singolo ciclo di clock allora ho un $O(1)$, quindi ez.\nGeneralized forwarding Software defined networking\nGeneralizzato perchÃ© Ã¨ indipendente dal router che facciamo perchÃ© Ã¨ tutto gestito da un controller centralizzato.\nOgni router ha una flow table, la stessa cosa di cui si parla nei IPv6 in Livello di Rete#Datagramma IPv6 . Questa tabella Ã¨ costruita col routing plane centralizzato, descritta dal software. Importante che tutta la rete sia SDN, sennÃ² non funziona questo.\nOpen Flow Slide flow table\nAbbiamo certe regole di gestione del pacchetto che si basa tu match-action. Se câ€™Ã¨ un match sugli header del pacchetto, allora faccio una azione su quel pacchetto. (come drop, forward, modify) e ci permette di fare molta roba, come le IP tables, o il NAT. Il router ora puÃ² assumere molt funzioni diverse.\nAbbiamo anche una priority, mentre nella destination based Ã¨ solamente longest prefix.\nSwitching fabrics Questi switching fabrics lo fanno andare molto molto infretta La prima Ã¨ una memoria, ma Ã¨ molto lento perchÃ© ha bisogno di due copie di memoria. Ognuno puÃ² avere un bus condiviso, si sceglie a livello del sender il bus di arrivo, ma posso far passare solamente un bus alla volta, quindi posso avere un singolo alla volta che passa. La cosa migliore Ã¨ la TRANSFER SWITCH. CosÃ¬ posso far passare in parallelo dei pacchetti, perÃ² Ã¨ la cosa piÃ¹ complessa, perÃ² Ã¨ anche la cosa piÃ¹ efficiente, perchÃ© non devo nÃ© copiare, nÃ© avere collisioni sul bus Ritardi possibili Input Queuing Quando due pacchetti di entrata devono andare sulla stessa uscita. Head of the line blocking, quando ci sono piÃ¹ pacchetti che stanno aspettando, quello avanti Ã¨ bloccato, ma quello dietro potrebbe andare. Slide input queuing\nOutput queuing Ho due cose buffering ossia quanto velocemente la switching fabric copia sui bus di uscita e scheduling che determina l\u0026rsquo;ordine di invio credo.\nPer decidere la quantitÃ  di buffering voluta per avere un certo bandwitdth Ã¨ in slide (una formula precisa): buffering delle uscite meno radice quadrata di quelle di ientrate.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Data Plane/Untitled 9.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Data Plane/Untitled 9\u0026quot;\u0026gt; Se il buffer di uscita diventa pieno, allora comincio a perdere i pacchetti! Posso perderlo secondo certe politiche:\nL\u0026rsquo;ultimo che arriva Cade uno a caso Cado quello con meno prioritÃ  (per fare questo devi fare hardware diverso perchÃ© non basta un semplice hardware). Scheduling dei routers Ci sono certi algoritmi di scheduling banali, come il First Come First served, e poi droppo tutti quelli che stanno fuori, oppure farli droppare a caso.\nPriority scheduling \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Data Plane/Untitled 10.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Data Plane/Untitled 10\u0026quot;\u0026gt; in pratica ho un classificatore, che dice se Ã¨ di prioritÃ  o meno.\nPoi per mandare guardo se c\u0026rsquo;Ã¨ qualcosa di prioritÃ  maggiore, se Ã¨ vuoto provo a mandare quelli minori.\nMa questo puÃ² generare starvation.\nRound robin scheduling Questo non fa starvation.\nIn pratica provo uno per classe ad ogni ciclo.\nWeighted fair queuing Tipo se ho massima priority, ne mando 4, se sono nella seconda ne mano 2, se sono nella terza ne mando 1, quindi esiste ancora la priority e non ho starvation perchÃ© anche nella coda brutta riesco sempre ad andare avanti.\nSul pacchetto IP Livello di Rete#Indirizzo IP\n","permalink":"https://flecart.github.io/notes/data-plane/","summary":"Ripasso Prox: 30 Ripasso: May 20, 2023 Ultima modifica: May 14, 2023 5:18 PM Primo Abbozzo: March 10, 2023 12:10 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nIntroduzione Data or Control plane come fanno i router a fare forwarding dei pacchetti? e decidere come mandare? Come fanno a passare. Sono le tabelle di instradamento. Si puÃ² dire di end-to-end perchÃ© solamente il sender e receiver andranno a livello applicazione, e leggeranno le cose (se criptato veramente solo loro riescono a fare questo).","title":"Data Plane"},{"content":"Ripasso Prox: 10 Ultima modifica: May 6, 2023 5:55 PM Primo Abbozzo: February 16, 2023 3:04 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Introduction: a neuron Questi sono cosettini ispirati dalla struttura dei neuroni nel nostro cervello, ma mi sembra di aver sentito che alla fine non câ€™entrino proprio niente.\nStructure Linear + activation In pratica possiamo dire che un neurone in questa parte di AI Ã¨ una funzione lineare (quindi che non fa altro che $w^Tx + b$ di solito indicata con $z$) ossia moltiplicazione lineare, e poi una funzione non lineare tra 0 e 1 che mi indica o meno se la cosa Ã¨ attivata o meno.\nModel Architecture and parameters (the weights), identify a model.\nTraining network tricks Activation functions Solitamente le funzioni classiche per i network neurali sono sigmoid, tanh, e ReLU. La cosa brutta delle prime due Ã¨ vanishing gradient, perchÃ© se il valore Ã¨ molto grosso o molto piccolo, la derivata Ã¨ molto vicino allo 0, quindi Ã¨ molto difficile aggiornare.\nInvece ReLU si comporta meglio da questo punto di vista, perchÃ© la sua derivata Ã¨ 0 se minore di 0 1 se maggiore.\nInput normalization In un certo senso in questo modo abbiamo un pÃ² di tati che sono Normali gaussiani. Non ho capito ancora perchÃ© normale gaussiana sia una tipologia di dati che ci piace cosÃ¬ tanto. (il motivo che viene dato in lezione Ã¨ che Gradient Descent si comporta molto meglio per loss function che sono gaussiane, perchÃ© la direzione di discesa Ã¨ sempre quella, e non deve zigzagare).\nWeight initialization Ci sono moltissimi modi per inizializzare i Weights, in modo che si eviti il problema di vanishing or exploding gradients. Lâ€™idea Ã¨ comunque tenere i valori vicini a 1 per evitare che esplodino, e inversamente proporzionali a n o funzioni di n, perchÃ© se n Ã¨ molto grosso potrebbe esplodere lo stesso.\nAlcune inizializzazioni famose sono\nXavier He (qualcosa che funziona per Sigmoid, (alcune funzionano a seconda dellâ€™activation function giusta) Câ€™Ã¨ ne sono molte, non so se conviene lavorare sulla inizializzazione, non credo sia comunque buona spesa del tempo a capire queste.\nOptimization Momentum, praticamente un gradient descent che tiene conto delle computazioni passate, e calcola la direzione anche secondo quelle (quindi se vado su e giÃ¹ e a destra sempre nelle iterazioni passate, andrÃ² a destra piÃ¹ spesso diciamo, questa Ã¨ lâ€™intuizione per questa idea).\nUna cosa molto strana Ã¨ che il training delle NN Ã¨ molto stabile. CioÃ¨ vari un pÃ² lâ€™input e non varia molto lâ€™ouput!\nPossibili motivi:\nWeights Loss function Internal redundancy? cioÃ¨ ho troppi parametri e questo lo rende bello.(teoria del prof) Overfitting Slide ways to reduce overfitting 7\nOverfitting Ã¨ il drago del training classico del machine learning, molto simile a dire che la macchina sta allucinando alcuni pattern causati probabilmente dalla varianza dei dati, o anche dal fatto che alcuni casi positivi sono pochiâ€¦\nÃˆ comunque una cosa troppo specifica, perchÃ© significa che la macchina stia quasi imparando a memoria i casi, dovrebbe provare a generalizzare, per farlo deve scordare dettagli non interessanti (che con overfitting puÃ² imparare) e imparare le cose importanti. PerÃ² i computer sono troppo bravi a memorizzare dettagli, a differenza di umani.\nIdea del dropout\nLâ€™idea Ã¨ il fatto che il network deve risolvere il problema, anche se Ã¨ un pÃ² rotto, questo cerca di renderlo piÃ¹ robusto, e sembra funzionare molto bene.\nKullback-Leibler Divergence We want to measure the distance between two distributions, usually from a real distribution and the one we are predicting. Vedere Entropy#Relative Entropy or Kullback-Leibler\nÃˆ una cosa che proviene dalla teoria dellâ€™informazione.\nPer capire questo, Ã¨ molto importante andare a capire cosa sia la cross-entropy e questo Ã¨ un modo abbastanza naturale per capire quanto vicino Ã¨ una distribuzione, solitamente predetta, con quella del training data, si puÃ² comparare molto con log-likelihood loss function, si potrebbe dire che sia un caso particolare la log likelihood.\n","permalink":"https://flecart.github.io/notes/neural-networks/","summary":"Ripasso Prox: 10 Ultima modifica: May 6, 2023 5:55 PM Primo Abbozzo: February 16, 2023 3:04 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Introduction: a neuron Questi sono cosettini ispirati dalla struttura dei neuroni nel nostro cervello, ma mi sembra di aver sentito che alla fine non câ€™entrino proprio niente.\nStructure Linear + activation In pratica possiamo dire che un neurone in questa parte di AI Ã¨ una funzione lineare (quindi che non fa altro che $w^Tx + b$ di solito indicata con $z$) ossia moltiplicazione lineare, e poi una funzione non lineare tra 0 e 1 che mi indica o meno se la cosa Ã¨ attivata o meno.","title":"Neural Networks"},{"content":"Definition of problems Object detection Bisogna trovare all\u0026rsquo;interno dell\u0026rsquo;immagine quali siano gli oggetti presenti, e in piÃ¹ vogliamo sapere dove siano quindi utilizzare una bounding box per caratterizzarli sarebbe buono.\nObject segmentation Ãˆ riuscire a caratterizzare categoria per categoria per singoli pixelsm e per questo motivo potrei riuscire a fare delle image map in cui colorare singoli oggetti in una categoria.\nDatasets Example datasets Pascal VOC 2012 Coco datasets Cityscapes dataset Autogenerated datasets But I don\u0026rsquo;t know much about these datasets Applications Auto drive Campo medico (per segmentazione medica o riconoscimento immagini). reidentificazione. Key posse extimations. U-net Il primo skip connection ci permette di capire bene quali siano i bordi, perchÃ© sappiamo che la convoluzione riesce a prendere bene\nArchitettura di Yolo Downsampling, fare dei mini quadratini, 32 fattori di downsampling, di solito l\u0026rsquo;immagine Ã¨ 416x416 e arriva a 13x13. Ogni neurone fa tre predizioni. Quattro valori per una bounding box (offsettata dal neurone), quanto penso di essere sicuro, e poi dire cosa esattamente sto vedendo. Importante avere la funzione di loss per analizzare bene. Vogliamo avere un singolo neurone, quindi forzo a zero tutti gli altri neuroni. Questo Ã¨ quello che faccio con la funzione maschera per avere solamente la box di interesse. Poi una volta definito questo provo a definire errore di localizzazione e l\u0026rsquo;errore di classificazione. Quello Ã¨ l\u0026rsquo;errore di di localizzazione in cui vogliamo avere la bounding box piÃ¹ corretta. La radice Ã¨ una euristica umana per cercare di favorire il punto principale (ma cambia la loss fra versione all\u0026rsquo;altra).\nUna volta che ho le due loss posso provare a bilanciarle: $$ L = \\lambda_{c}L_{loc} + L_{cls} $$ E le variabili si mettono a mano seconda dell'architettura. Region proposals and single shots Region proposals: (R-CNN, Fast R-CNN, Faster R-CNN).\nIl primo Ã¨ un vecchio metodo per attaccare il problema. In passato si analizzava la texture per capire le regioni con struttura e dove si avevano altre, utilizzato per avere zone di interesse, senza informazioni semantiche a riguardo. una volta capite le regioni di interesse l\u0026rsquo;altra rete prova a fare classificazione e bounding box.\nSingle shots (Yolo, SSD, Retina-net, FPN).\nSi fanno in unica passata indetificazione del luogo e categorizzazione.\nIntersection over Union This is an evaluation metric used to determine if two regions are the same. If this metric is high enough, the better one is kept (better one as more secure and things like that).\nNon-maximum-suppression algorithms ðŸŸ© Ãˆ un modo per trovare le bounding box migliori per un certo argomento. In pratica Ã¨ un algoritmo greedy, che va cosÃ¬:\nSorta tutte le bounding box in ordine decrescente di confidence Prendo la prima come vera Le prossime le elimino se hanno una intersection over union alta, altrimenti le tengo. CosÃ¬ finchÃ© non finiscono tutte le bounding box. ","permalink":"https://flecart.github.io/notes/object-detection-and-segmentation/","summary":"Definition of problems Object detection Bisogna trovare all\u0026rsquo;interno dell\u0026rsquo;immagine quali siano gli oggetti presenti, e in piÃ¹ vogliamo sapere dove siano quindi utilizzare una bounding box per caratterizzarli sarebbe buono.\nObject segmentation Ãˆ riuscire a caratterizzare categoria per categoria per singoli pixelsm e per questo motivo potrei riuscire a fare delle image map in cui colorare singoli oggetti in una categoria.\nDatasets Example datasets Pascal VOC 2012 Coco datasets Cityscapes dataset Autogenerated datasets But I don\u0026rsquo;t know much about these datasets Applications Auto drive Campo medico (per segmentazione medica o riconoscimento immagini).","title":"Object detection and Segmentation"},{"content":"Prendiamo La legge di Ampere-Maxwell $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$ E la legge di Faraday neumann Lenz $$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} $$ Con questi abbiamo le onde elettromagnetiche.\nNel vuoto possiamo dire che non abbiamo densitÃ  di corrente, per questo posso andare nel vuoto, sono due cose che si autosostengono. Sono simmetriche a meno di costante.\nQuesto ci dice che\nPreso un campo elettrico che varia nel tempo (tipo una carica oscillante). Questo mi dice che si genera un campo magnetico prima non esistente Questo campo che varia nel tempo va a creare un altro campo elettrico Quindi abbiamo un processo che continua cosÃ¬ all\u0026rsquo;infinito sostenendosi. In queste due equazioni abbiamo la luce. 2 circuitazioni 2 Leggi di gauss e le 4 equazioni di Maxwell sono in grado di descrivere tutti i fenomeni elettromagnetici.\nNote storiche dei progressi in elettromagnetismo Il risultato curioso il fatto che sembrasse relazionato alla velocitÃ  della luce quella costante. Poi 1885 Hertz dimostra l\u0026rsquo;esistenza delle onde elettromagnetiche (quindi soggetti ai fenomeni delle onde, come l\u0026rsquo;interferenza, e si capisce che sono la stessa cosa con la luce. Una altra cosa curiosa Ã¨ che tutto elettromagnetismo Ã¨ fatto senza sapere l\u0026rsquo;esistenza di elettroni (solo all\u0026rsquo;inizio del \u0026lsquo;900 abbiamo iniziato a comprendere meglio come sono fatti e sono iniziati anche prodotti forti con queste) 1930 Fermi a Roma ha fatto una conferenza per la scoperta dell\u0026rsquo;elettrone da Thompson (Rutherford ha scoperto di piÃ¹ su atomi, il mini sistema planetario), in questa conferenza si studia i neutroni (che non esistevano), e si inizia a comprendere meglio la materia. Strana cosa era che dal nucleo venivano emessi elettroni (questo Ã¨ il decadimento radioattivo? Non si sapeva del neutrone, qui ).\nTeorema di Poynting Setting del problema ðŸŸ© Consideriamo una distribuzione di cariche $dq = \\rho dt$ che dipende dalla posizione $\\rho = \\rho(\\hat{r}t)$, stessa cosa per la velocitÃ  in un campo elettromagnetico costante. Voglio sapere il **lavoro** e **potenza** fatto dai campi sulla carica. Applichiamo la legge di lorentz (ricorda Magnetismo) $$ \\vec{F} = q\\vec{E} + q\\vec{v} \\times \\vec{B} \\implies df = [\\rho \\vec{E} + \\rho \\vec{v}\\times \\vec{B}]d\\tau $$ Questa Ã¨ la forza esercitata sul volumetto $d\\tau$ Sapendo che la potenza Ã¨ relazionata alla forza in modo conosciuto, sappiamo che $$ dW = d\\vec{f} \\cdot \\vec{v} \\implies dW = [\\rho \\vec{E}\\cdot \\vec{v} + \\rho \\vec{v}\\times \\vec{B} \\cdot \\vec{v}]d\\tau $$ Possiamo notare che il campo B non fa lavoro, perchÃ© la forza Ã¨ perpendicolare al percorso (e lo si vede anche in formule, perchÃ© abbiamo un prodotto vettore seguito da uno scalare), da questo abbiamo che $$ dW = \\rho \\vec{E} \\cdot \\vec{v} d\\tau $$ Ora, sapendo che $\\vec{J} = ne\\vec{v} = \\rho \\vec{v}$ (la seconda parte vale perchÃ© $n$ Ã¨ il numero di particelle per unitÃ  di volume, mentre $\\rho$ Ã¨ la carica per unitÃ  di volume e assumendo la cosa corpuscolare Ã¨ solamente la somma) Allora abbiamo $$ dW = \\vec{J} \\cdot \\vec{E} d\\tau $$ Questa Ã¨ la stessa formula, calcolata in modo diverso in Leggi di Ohm quando calcolavamo la potenza\nDerivazione con Ampere e Faraday (tosta) ðŸŸ¨ Usando la legge di Ampere-Maxwell, presente in Ampere e Faraday, possiamo continuare questa esplorazione. $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{d\\tau} \\implies \\vec{E}\\cdot[\\vec{\\nabla} \\times \\vec{B}] = \\mu_{0}\\vec{E}\\cdot\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{d\\tau} \\cdot \\vec{E} \\implies \\vec{J} \\cdot \\vec{E} = \\frac{1}{\\mu_{0}} \\vec{E}\\cdot[\\vec{\\nabla} \\times \\vec{B}] - \\varepsilon_{0} \\frac{\\delta \\vec{E}}{d\\tau} \\cdot \\vec{E} $$ Ora proviamo ad analizzarlo pezzo per pezzo, partiamo dalla parte magnetica e elettrica ðŸŸ¨\n$$ \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) = (\\vec{\\nabla}\\times \\vec{E}) \\cdot \\vec{B} - (\\vec{\\nabla} \\times \\vec{B}) \\cdot \\vec{E} \\implies (\\vec{\\nabla} \\times \\vec{B}) \\cdot \\vec{E} = - \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) + (\\vec{\\nabla}\\times \\vec{E}) \\cdot \\vec{B} $$ Ora utilizziamo la legge di Faraday in Magnetismo in forma differenziale e otteniamo $$\n(\\vec{\\nabla} \\times \\vec{B}) \\cdot \\vec{E} = - \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) + \\left( -\\frac{\\delta \\vec{B}}{d\\tau} \\right) \\cdot \\vec{B} $$ Questo risultato possiamo metterlo nella parte di sopra e cosÃ¬ abbiamo espanso la prima parte (urca quanti calcoli perÃ²)\n$$ W_{\\tau} = \\vec{J} \\cdot \\vec{E} = -\\frac{1}{\\mu_{0}} \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) + \\frac{1}{\\mu_{0}} \\left( -\\frac{\\delta \\vec{B}}{d\\tau} \\right) \\cdot \\vec{B}\n\\varepsilon_{0} \\frac{\\delta \\vec{E}}{d\\tau} \\cdot \\vec{E} $$ Ora dobbiamo fare altre osservazioni strambe: ðŸŸ©- $$ \\frac{\\delta B^{2}}{\\delta t} = \\frac{\\delta}{\\delta t} (\\vec{B} \\cdot \\vec{B}) = \\vec{B} \\cdot \\frac{\\delta}{\\delta t}(\\vec{B}) + \\frac{\\delta}{\\delta t}(\\vec{B}) \\cdot \\vec{B} = 2 \\vec{B} \\frac{\\delta}{\\delta t}\\vec{B} $$ Questo ci permette di sostituire nelle forme di sopra come derivate seconde:\n$$ W_{\\tau} = \\vec{J} \\cdot \\vec{E} = -\\frac{1}{\\mu_{0}} \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) - \\frac{1}{2\\mu_{0}} \\frac{\\delta B^{2}}{dt}\n\\frac{1}{2}\\varepsilon_{0} \\frac{\\delta E^{2}}{dt} $$ Questa Ã¨ la potenza trasferita dai campi elettrici e magnetici a un volumetto $d\\tau$ che si muove con velocitÃ  $v$ nello spazio.\nVogliamo sapere energia totale trasferita da $\\vec{E}$ e $\\vec{B}$ per far questo basterebbe integrare sul nostro volume:\n$$ \\int dW = \\int \\vec{J} \\cdot \\vec{E} , d\\tau = -\\int \\frac{1}{\\mu_{0}} \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) , d\\tau - \\frac{1}{2}\\int \\left( \\frac{1}{\\mu_{0}} \\frac{\\delta B^{2}}{dt}\n\\varepsilon_{0} \\frac{\\delta E^{2}}{dt}\\right) d\\tau $$ Proviamo ad utilizzare il teorema della divergenza perchÃ© gli integrali di volume sono brutti. Da questo sappiamo: $$ -\\int_{\\tau} \\frac{1}{\\mu_{0}} \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) \\, d\\tau = - \\int_{\\Sigma(\\tau)} \\frac{1}{\\mu_{0}}\\cdot (\\vec{E} \\times \\vec{B}) \\, d\\vec{S} $$ Quindi riscrivendo ancora abbiamo: $$ \\int_{\\tau} dW = \\int_{\\tau} \\vec{J} \\cdot \\vec{E} , d\\tau = - \\int_{\\Sigma(\\tau)} \\frac{1}{\\mu_{0}}\\cdot (\\vec{E} \\times \\vec{B}) , d\\vec{S}\n\\frac{1}{2}\\int_{\\tau} \\left( \\frac{1}{\\mu_{0}} \\frac{\\delta B^{2}}{dt} \\varepsilon_{0} \\frac{\\delta E^{2}}{dt}\\right) d\\tau $$ Attenzione: a volte tau Ã¨ usato come tempo a volte come volume (fai attenzione a distinguerli bene) Formulazione e interpretazione finale ðŸŸ¨+ $$ W = - \\int_{\\Sigma(\\tau)} \\frac{1}{\\mu_{0}}\\cdot (\\vec{E} \\times \\vec{B}) , d\\vec{S}\n\\frac{\\delta}{dt}\\int_{\\tau} \\left( \\frac{1}{2\\mu_{0}} B^{2} \\frac{\\varepsilon_{0}}{2} E^{2}\\right) d\\tau $$ Abbiamo due termini che descrivono il trasferimento di energia.\nEnergia trasferita alla distribuzione di carica dai campi $E$ e $B$, ossia abbiamo Il concetto di densitÃ  volumetrica di energia elettromagnetica, quella che abbiamo studiato separatamente in Condensatori nel vuoto e Geometrie di spire (tipicamente sono statici questi campi) $$ du = \\frac{1}{2\\mu_{0}} B^{2} \\frac{1}{2} \\varepsilon_{0}E^{2} $$ Che ha senso (somma di due energie, somma classica)), perchÃ© l\u0026rsquo;energia trasferita Ã¨ uguale al valore dei campi in un certo punto preciso (somma dell\u0026rsquo;energia dei campi E ed B dentro al volume). Si parla di integrale su una superficie chiusa che contiene il volume, e abbiamo un vettore perpendicolare ai campi $E$ e $B$, rappresenta flusso del vettore di Poynting, che Ã¨ una energia proveniente da fuori. (tipicamente sono onde elettromagnetiche, perchÃ© entrano, forniscono energia, ed escono) -\u0026gt; ONDA ELETTROMAGNETICA TRASPORTA ENERGIA. In pratica Ã¨ un Or logico, l\u0026rsquo;energia o Ã¨ presa da dentro, o da fuori, il primo termine Ã¨ il dentro, il secondo Ã¨ il fuori. Concettualmente Ã¨ semplice, la derivazione Ã¨ complessa e utilizza molte cose di algebra e analisi.\nIl vettore di Poynting ðŸŸ© Possiamo definire ora il vettore di Poynting come $$ S' = \\frac{1}{\\mu_{0}} \\vec{E} \\times \\vec{B} $$ in un certo senso Ã¨ una densitÃ  superficiale di potenza elettromagnetica, perchÃ© per avere la potenza devo moltiplicare la superficie. Forse Ã¨ con questo che utilizzo per costruire pannelli solari, Ã¨ l\u0026rsquo;energia che riscalda al sole, che impatta superficie :D.\nEnergia per unitÃ  di tempo e superficie trasportata da una onda.\nQuantitÃ  di moto ðŸŸ© Si puÃ² dimostrare che Ã¨ $$ d\\vec{P} = \\mu_{0}\\varepsilon_{0} \\vec{S}' d\\tau $$ QuantitÃ  di moto per unitÃ  di tempo e volume! Per questo posso far muovere oggetti sparandoci laser!\nNel vuoto Abbiamo che $$ \\vec{\\nabla} \\cdot \\vec{E} = 0 $$ $$ \\vec{\\nabla} \\cdot \\vec{B} = 0 $$ $$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} $$ $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$ Consideriamo $\\vec{\\nabla} \\times \\vec{\\nabla} \\times \\vec{E} = -\\vec{\\nabla} \\times \\frac{\\delta \\vec{B}}{\\delta t}$ Si puÃ² vedere che\n$$ -\\nabla^{2}\\vec{E} = - \\frac{\\delta (\\vec{\\nabla} \\times\\vec{B})}{\\delta t} = -\\mu_{0}\\varepsilon_{0} \\frac{ \\delta^{2}\\vec{E}}{\\delta t^{2}} $$ Che dovrebbe essere una equazione di onda.\nEquazioni di D\u0026rsquo;Alambert ðŸŸ¨- $$ \\nabla^{2}\\vec{E} = \\mu_{0}\\varepsilon_{0}\\frac{ \\delta^{2} \\vec{E}}{\\delta t^{2}} $$ E uguale per il campo magnetico: $$ \\nabla^{2}\\vec{B} = \\mu_{0}\\varepsilon_{0} \\frac{\\delta^{2}\\vec{B}}{\\delta t^{2}} $$ Queste si possono scomporre, e abbiamo equazioni differenziali al secondo grado: $$ \\frac{\\delta^{2}E_{x}}{\\delta x^{2}} + \\frac{\\delta^{2}E_{y}}{\\delta y^{2}} + \\frac{\\delta^{2}E_{z}}{\\delta z^{2}}= \\mu_{0}\\varepsilon_{0}\\frac{ \\delta^{2} \\vec{E}}{\\delta t^{2}} $$ In cui abbiamo anche la velocitÃ  di propagazione delle onde, infatti abbiamo che $$ \\mu_{0}\\varepsilon_{0} = \\frac{1}{v^{2}} \\implies v = \\frac{1}{\\sqrt{ \\varepsilon_{0}\\mu_{0} }} = c $$ Solo alla fine dell'800 si capisce che la luce Ã¨ questo.\nExtra: frontiers Ma ci sono alcuni problemi aperti. In gravitazione ho precessione di Mercurio che metteva sotto problema le predizioni della gravitÃ  di Newton.\nCarica accelerata emette energia (come fa a non collassare nel nucleo?).\nRadiazione corpo nero (problema di conservazione dell\u0026rsquo;energia (catastrofe ultravioletta)).\nNon si sa in quale sistema di riferimento C valga\nEspansione accelera\nNeutrini non hanno massa zero\nGalassia ruota in modo costante, nonostante rallentare.\nEnergia del vuoto predetto male da quantistica.\n","permalink":"https://flecart.github.io/notes/onde-elettromagnetiche/","summary":"Prendiamo La legge di Ampere-Maxwell $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$ E la legge di Faraday neumann Lenz $$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} $$ Con questi abbiamo le onde elettromagnetiche.\nNel vuoto possiamo dire che non abbiamo densitÃ  di corrente, per questo posso andare nel vuoto, sono due cose che si autosostengono. Sono simmetriche a meno di costante.\nQuesto ci dice che","title":"Onde elettromagnetiche"},{"content":"Ripasso Prox: 10 Ripasso: May 23, 2023 Ultima modifica: May 14, 2023 5:20 PM Primo Abbozzo: April 5, 2023 2:24 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Antenne Omnidirezionali Antenne omnidirezionali ðŸŸ© Slides antenne omnidirezionali\nIl senso di omnidirezionale Ã¨ in tutte le direzioni dell\u0026rsquo;antenna (nota: non Ã¨ isotropico, perchÃ© non Ã¨ da un singolo punto).\nin passato era importante andare a guardare la direzione per trovare la polarizzazione migliore. Praticamente irradia a 360 gradi sul piano permedicolare allâ€™antenna.\nEsempio pattern di radiazione\nQuesto genere di antenne sono irrealizzabili la piÃ¹ simile Ã¨ la antenna dipolo dipolo, ma comunque non rispetta le antenne in questo verso diciamo. ricorda i dBi che abbiamo citato in Fisica del Wireless.\nGuadagno passivo in ominidirezionali ðŸŸ© Slide guadagno passivo\nSi puÃ² concentrare l\u0026rsquo;energia nella shape del dipolo. Per esempio se lo faccio piÃ¹ schiacciato, ho un range molto piÃ¹ forte orizzontalmente, ma appena su o appena giÃ¹ perdo segnale.\nMentre al contrario, se ho una forma piÃ¹ arrotondata ho segnale solo se gli sto vicino, ma molta meno importanza stare sopra o sotto.\nEsempio del guadagno passivo e attivo delle antenne\nNOTA: posso avere un guadagno fino a 10 Db quindi 10 volte tanto.\nEd Ã¨ anche per questo motivo che andiamo a misurare lâ€™EIRP e non la potenza che finisce nellâ€™antenna, anche chiamata Intentional radiator Power output.\nPOSIZIONAMENTO DELL ANTENNE\nAndiamo a chiederci in che modo mettere le antenne in modo che piÃ¹ utenti possibili possano usufruire del segnale.\nUna soluzione potrebbe essere inclinare lâ€™antenna:\nSlide inclinazione dellâ€™antenna\nAntenna semidirezionale Semidirezionale (3) ðŸŸ© Questi sono i piÃ¹ comuni, sparano principalmente energia di fronte (quindi metterllo su un muro Ã¨ cosa buona).\nEsempi di antenne omnidirezionali\nDi solito si mettono nel muro (sono panel o patch, che praticamente cambiano di costruzione, ma alla fine hanno la stessa funzione ).\nMentre gli yagi sono sparati nella direzione in cui punta (e mirano alla posizione del ripetitore, perchÃ© da lÃ¬ ricevono meglio.\nbeam width (!!!) Ã¨ un valore che Ã¨ espresso in angoli, e misura quando largo o concentrato il segnale, Ã¨ lo spazio necessario per dimezzare il segnale, partendo dall\u0026rsquo;asse di direzione. Questa concezione ci serve per parlare di antenne altamente concentrate.\nHighly-directional antennas ðŸŸ©- Slide esempio highly dir\nEsempi sono grid e parabolic dish che perdono energia attorno molto molto velocemente, perÃ² se sei nel beam width lo ricevi molto bene (va lontano si possono utilizzare per antenne lungo raggio come satelliti).\nPotrei anche s.ettorializzare la trasmissione: ogni antenna si prende solamente un certo angolo\nLine of Sight ossia la linea raggio dritta fra trasmissione e ricevitore.\nFresnel zone ðŸŸ©â€” Definiamo al centro della line of size come la zona di fresnel, sarebbe meglio metterlo libera da ostacoli. Si concentrano il massimo numero di onde additive quindi se câ€™Ã¨ qualcosa mi toglie molto.\nSlide zona di fresnel\nSe Ã¨ piÃ¹ di 20 percento occupata, allora Ã¨ meglio andare sugli ostacoli (altrimenti non ottengo maggiore ricezione, continuo a perdere energia negli ostacoli e ho inquinamento dei raggi).\nSe non Ã¨ ostruita sto permettendo lâ€™energia ad arrivare con massima efficienza al ricevitore.\nNOTA: la distanza Ã¨ dipendente solo da frequenza e distanza\nfresnel e curvatura terrestre\nSettorializzazione di antenne direzionale (boh) ðŸŸ¥ Si parla di multiplexing spaziale perchÃ© possiamo andare ad utilizzare lo stesso canale, ma in zone diverse perchÃ© il segnale Ã¨ concentrato solamente in quella direzione.\nAzimuth and elevation charts ðŸŸ© Slide azimuth and elevation charts\nQuesto grafico Ã¨ utilizzato per guardare in ogni angolo dell\u0026rsquo;antenna, quanto Ã¨ lâ€™energia che viene trasmessa.\nMentre azimuth gira in orizzontale (quindi visuale dallâ€™alto), elevation gira in modo verticale (quindi visuale da terra diciamo).\nInoltre Ã¨ importante dislocare le antenne in posizioni sparse. CosÃ¬ se ricevo un segnale posso provare a ricavare il segnale originale provando a buttare via il noise. Di questa parte si potrebbe ricollegare allo space multiplexing citato in Tecnologia Wireless\nSe li metto a lambda mezzi, allora almeno una delle due antenne prendono un segnale buono, lâ€™altra potrebbe essere in opposizione (mi sembra comunque un sacco di fisica che ignoriamo qui).\nSotto serve un controllore che riesca ad annullare e scegliere i segnali o gli sfasamenti o annullamenti. (questo controllore dovrebbe rifasare il segnale e rendere il segnale additivo.\nSlide antenna diversity\nBeam forming\nAvendo queste antenne, io riesco a creare un raggio RF, ritardando in modo opportuno certi piatti, e posso mandarlo dove mi pare. (controllo sulla direzione, solamente ritardando le fasi di certe antenne).\nPath loss in free space ðŸŸ¨- Slide path loss\nNotiamo che la perdita di segnale dipende dalla frequenza e dalla distanza â†’ frequenza alta implica segnale perso piÃ¹ in fretta. 36.6 Ã¨ una costante che funziona sulla Terra.\nSi noti che duplicando la distanza, l\u0026rsquo;energia cade 4 volte e questo risultato Ã¨ coerente con questo dato.\nPer vedere se -86 dB Ã¨ sufficiente bisogna guardare la soglia di ricezione del nostro dispositivo. Se il link budget Ã¨ positivo allora si riceve, il nostro obiettivo Ã¨ progettare sistemi a link-budget positivi.\nSi noti che non Ã¨ necessario che questo link-budget sia positivo, significa che sto consumando un sacco di energia.\nSpreco energia nella trasmissione Disturbo trasmissione di altri Vogliamo il minimo link-budget positivo.\nQuesto si chiama system operative margin o valore operativo del sistema.\nIl margine extra Ã¨ chiamato fade margin per resister al path loss, fase, e riflessioni e simili, in generale questo fade margin Ã¨ un +10 fino +20\n","permalink":"https://flecart.github.io/notes/antenne/","summary":"Ripasso Prox: 10 Ripasso: May 23, 2023 Ultima modifica: May 14, 2023 5:20 PM Primo Abbozzo: April 5, 2023 2:24 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Antenne Omnidirezionali Antenne omnidirezionali ðŸŸ© Slides antenne omnidirezionali\nIl senso di omnidirezionale Ã¨ in tutte le direzioni dell\u0026rsquo;antenna (nota: non Ã¨ isotropico, perchÃ© non Ã¨ da un singolo punto).\nin passato era importante andare a guardare la direzione per trovare la polarizzazione migliore.","title":"Antenne"},{"content":"Ripasso Prox: 20 Ripasso: February 9, 2023 Ultima modifica: January 2, 2023 10:14 AM Primo Abbozzo: October 19, 2022 4:17 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Minimi Quadrati Note matematiche introduttive Vettori ortonormali ðŸŸ© Due vettori si dicono ortonormali se $vv^T = ||v|| = 1$ e sono ortogonali, ossia $v_i v^T_j = 0$ con i e j diversi fra di loro\nMatrici ortogonale (4) ðŸŸ©- Matrici si dicono ortonomali se le sue colonne sono vettori sono ortonormali\nMatrici ortonormali sono isometrie, cioÃ¨ mantengono le distanze. Queste matrici sono tutte non singolari e quadrate per definizione La sua inversa Ã¨ ortogonale La sua inversa Ã¨ uguale alla trasposta slide ProprietÃ  matrice ortonormale\nMinimi quadrati lineari Introduzione al problema Sappiamo che non esiste una soluzione esatta per sistemi di equazione lineare che piÃ¹ equazioni che soluzioni. Si puÃ² concludere che la soluzione a questo problema (in slide) esiste sempre ed Ã¨ unica se $k = n$, se Ã¨ minore ci sono infinite soluzioni.\nSlide introduzione\nOssia mi interessa solamente lâ€™ascissa del minimo, ossia\n$\\argmin ||Ax - b||$, cercando la x.\nSoluzione con equazione normale ðŸŸ¨ Questo si puÃ² fare solamente se $k = n$\nTeorema, soddisfacimento delle equazioni normali Ã¨ sufficiente per trovare una soluzione\nIn questo caso esiste una soluzione unica.\nSoluzione equazione normale\nnota ci sono errori sia sulla trasposta che sul gradiente in immagine\nIn breve\nFare il gradiente della funzione ed eguagliarlo a 0, perchÃ© solo se ho 0 ho il punto di minimo di questa funzione convessa della norma\nSingular Value decomposition ðŸŸ© Di solito Ã¨ utilizzata per ridurre lo spazio utilizzato trattenendo la maggiore quantitÃ  di informazione possibile, utilizzata spesso in Principal Component Analys\nEnunciato SVD slide\nImmagine esplicativa\nQuesto Ã¨ qualcosa che si puÃ² applicare a qualunque matrice. Sono di particolare interesse le matrici con numero di colonne maggiore del numero di righe.1\nSlide vecchia\nRelazione valori singolari con AAt ðŸŸ©- Con k ho il numero di numeri non zero che sono il rango della matrice. Questa matrice Ã¨ particolare, la chiamiamo gramiano ed Ã¨ sempre definita positiva.\nSlide\nQuindi i valori singolari che sono gli autovalori della matrice $A^TA$ sono\n$\\geq 0$ $\\in \\R$ se k Ã¨ il rango di $A$, ho k elementi diversi da 0. Il motivo per cui succede quanto sopra Ã¨ perchÃ© Ã¨ come se stessi facendo il cambio di base per trovare una matrice diagonale! Cambio di Base e Autovalori, e non c\u0026rsquo;Ã¨ nessuna relazione altra fra la matrice di A e il valore singolare, deve essere con AAt!\nRelazione molto importante (!!!!!)\nVettori singolari sinistri e destri ðŸŸ© Definiamo in questo modo i vettori associati a $\\sigma_i$ che formano una base ortonormale rispettivamente di $R^m, R^n$. E in particolare sono le colonne delle matrici $U, V$\nNOTA: Ã¨ molto probabile che la relazione sotto che lega vettori singolari sinistri e destri sia errata perchÃ© sulla pagina di wiki u e v sono invertite. Ãˆ piÃ¹ importante il fatto che i vettori singolari sinistri e destri sono rispettivamente autovettori di AAt e AtA.\nSlide\nDecomposizione diadica ðŸŸ¥+ Slide\nIn pratica con la decomposizione a valori singolari, e utilizzando i vettori singolari si puÃ² dimostrare che\n$$ A = U\\Sigma V^T = \\sum_{i=1}^k \\sigma_iu_iv_i^T $$ Espandere questi calcoli Ã¨ abbastanza easy creddo, perchÃ© la matrice di mezzo Ã¨ molto semplice da gestire. Lâ€™intuito per sta parte (che Ã¨ lâ€™unica cosa di cui si Ã¨ preoccupata di spiegare) Ã¨ che Ã¨ utile qui il concetto di un prodotto esterno che po\nRisoluzione minimi quadrati con SVD ðŸŸ¨+ Enunciato teorema\nDimostrazione\nRegressione Polinomiale (!) Abbiamo un insieme di dati, vogliamo creare un algoritmo che stimi la funzione migliore per approssimare i dati.\nSiano dati un insieme di punti $(x_i, y_i)$, sia un polinomio p cosÃ¬ definito\n$p(x) = \\sum_{i =0} ^m c_ix^i$, vogliamo andare a definire per bene i valori dei coefficienti in modo che aderiscano ai dati.\nPer fare questo, in pratica Ã¨ la risoluzione di certi errori.\nIn pratica mi costruisco la matrice di vandermonde per tutti gli input di dati, di n numero di colonne, con n lâ€™esponente massimo del polinomio che voglio andare ad approssimare.\nPoi faccio cose per minimizzare lâ€™errori di questo e lo possono fare con SVD o minimi quadrati (nel cosi in cui il rango fosse giusto).\nImportante per questa parte la matrice di vandermonde.\nPseudo inversa (4) ðŸŸ¥ Slide\nQuesta definizione ci permette di scrivere il problema dei minimi quadrati in modo piÃ¹ clean, infatti la soluzione della SVD diventa\n$x = V\\Sigma^+U^Tb = A^+b$, come se stessi prendendo lâ€™inversa ðŸ˜€, quindi ci permette di semplificare questa notazione.\nSi puÃ² notare che lâ€™inversa possiede tutte le proprietÃ  della pseudoinversa.\nIn soldoni: inverto le matrici di vettori singolari e inverto tutti i valori singolari (prendo iil loro reciproco).\nImportanti sono alcune loro proprietÃ  (hermitiana per AA* e A*A, ossia simmetrica, inversa debole e lâ€™altra boh).\nSecondo la definizione di moore-penrose quelle 4 proprietÃ  sono sufficienti per una pseudoinversa, in questo caso abbiamo la pseudoinversa della SVD, che Ã¨ una cosa leggermente diversa (cioÃ¨ istanziazione specifica della pseudoinversa).\nCondizionamento in LSQ (non fare) Questa sezione ha cose da ricordare a memoria (giÃ  leggermente presentate in precedenza) quindi non ha molto senso dare attenzione a sta roba brutta, imparare poi a memoria il costo dei vari argoritmi bruuh\nVogliamo in questa sezione andare ad indagare quanto influenza il numero di condizione tutte le tecniche che abbiamo introdotto in questo capitolo.\nSlide\nDa ricordarsi di Norme e Condizionamento, che il condizionamento ci dice quanto cambia la soluzione quando cambio i dati (la b)\n","permalink":"https://flecart.github.io/notes/minimi-quadrati/","summary":"Ripasso Prox: 20 Ripasso: February 9, 2023 Ultima modifica: January 2, 2023 10:14 AM Primo Abbozzo: October 19, 2022 4:17 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Minimi Quadrati Note matematiche introduttive Vettori ortonormali ðŸŸ© Due vettori si dicono ortonormali se $vv^T = ||v|| = 1$ e sono ortogonali, ossia $v_i v^T_j = 0$ con i e j diversi fra di loro\nMatrici ortogonale (4) ðŸŸ©- Matrici si dicono ortonomali se le sue colonne sono vettori sono ortonormali","title":"Minimi quadrati"},{"content":"Scalare Scalare e gradiente ðŸŸ© Un campo scalare assegna a ogni punto dello spazio un valore reale, quindi Ã¨ naturalmente rappresentabile tramite una funzione $$ \\varphi(x, y, z) : \\mathbb{R}^{3} \\to \\mathbb{R} $$ Un esempio abbastanza naturale Ã¨ il gradiente del valore scalare che si indica con $$\\vec{\\nabla}\\varphi = ( \\frac{\\delta\\varphi}{\\delta x}, \\frac{\\delta\\varphi}{\\delta y}, \\frac{\\delta\\varphi}{\\delta z}) = \\frac{\\delta\\varphi}{\\delta x} \\hat{i} + \\frac{\\delta\\varphi}{\\delta y} \\hat{j} + \\frac{\\delta\\varphi}{\\delta z} \\hat{k}$$ Se consideriamo il gradiente da solo Ã¨ un campo vettoriale (dice la direzione della derivata multidimensionale).\nGradiente in coordinate polari ðŸŸ¨ Questo Ã¨ un po\u0026rsquo; piÃ¹ difficile da gestire, perÃ² Ã¨ abbastanza facile una volta che si fanno certe osservazioni. Sappiamo che $dV = \\vec{\\nabla} V \\cdot d\\vec{s}$, TODO: finire la dimostrazione, Ã¨ descritta bene a pagina 47 del mazzoldi.\nComunque si finisce con\n$$ \\vec{\\nabla} = \\frac{\\delta}{\\delta r} u_{r} + \\frac{1}{r}\\frac{\\delta}{\\delta \\theta}u_{\\theta} + \\frac{1}{r\\sin \\theta}u_{\\phi} $$ A volte questo puÃ² risultare utile se proviamo a fare cose come calcolare il campo elettrico attraverso il gradiente.\nNOTA: la divergenza perÃ² assume una forma diversa, che non so bene spiegare il motivo in questo momento perÃ².\nGradiente in coordinate cilindriche $$ \\vec{\\nabla} = \\frac{\\delta}{\\delta r} u_{r} + \\frac{1}{r}\\frac{\\delta}{\\delta \\theta}u_{\\theta} + \\frac{\\delta}{\\delta \\phi}u_{\\phi} $$ Vettoriale Superfice di separazione ðŸŸ© Per la definizione di questo, Ã¨ chiaro che il flusso su una superficie di separazione Ã¨ nulla, quindi posso dividere superfici come mi pare internamente, tanto su queste Ã¨ nulla, o posso considerare solamente la superficie piÃ¹ esterna che li racchiude (Ã¨ nulla perchÃ© avrÃ² due versioni uguali e contrarie).\nTODO: scrivere il ragionamento in formule\nIntegrale per un campo: teorema del gradiente ðŸŸ¨++ In analisi abbiamo studiato il teorema di torricelli, ma possiamo estenderlo senza troppa fatica (almeno intuitivamente), nel caso in piÃ¹ dimensioni!\ntorricelli ci dice che (mettere condizioni qui di esistenza integrale) $f(B) - f(A) = \\int _{A}^{B} f'(x) \\, dx$, Poniamo il concetto di differenziale ossia piccolo rettangolino nell\u0026rsquo;integrale di rieman come $df = f'dx$, attraverso questo abuso di notazione, allora diventa molto naturale estenderlo nelle 3 dimensioni come $d\\varphi(x, y, z) = \\vec{\\nabla}\\varphi \\cdot d\\vec{l}$ usando il prodotto scalare, in pratica ho il prodotto scalare amplificato per quello che mi serve. Allora diventa intuitivo che nel caso tridimensionale l\u0026rsquo;integrale sia\n$$ \\varphi(B) - \\varphi(A) = \\int _{A}^{B} \\vec{\\nabla}\\varphi \\cdot d\\vec{l} $$ Ãˆ da notare che nel nostro caso, se abbiamo un campo conservativo, questo integrale Ã¨ dipendente solamente da inizio e fine, non dipende dal percorso, il che implica che il campo Ã¨ conservativo.\nTeorema della divergenza (!!) ðŸŸ©- Dal ragionamento precedente abbiamo capito che potrei dividere la superficie con quante superfici di separazione mi pare, tanto il flusso esterno non cambia, questo mi permette di dividere in tanti volumetti e cercare il flusso con questi volumetti\n$$ \\phi_{s}(\\vec{F}) = \\sum_{i=1}^{N} V_{i} \\frac{\\oint_{\\Sigma} \\vec{F} \\cdot dS_{i}}{V_{i}} $$ Andiamo a chiamare la seconda parte la divergenza di F, e sarÃ  il flusso per unitÃ  di volume, vedremo che questa sarÃ  strettamente vicina al significato di gradiente indicato con nabla. Dato che sto considerando piccolissimi volumi, se la Divergenza Ã¨ positiva, significa che c\u0026rsquo;Ã¨ del flusso che esce da quel punto si dice che sono delle sorgenti, perchÃ© generano campo, e solitamente queste sono punti in cui le linee di campo si incontrano. Quando Ã¨ uguale a 0 non si dovrebbero incontrare\nEnunciato in modo corretto il teorema afferma: $$ \\phi_{S \\text{ chiusa}} = \\oint_{S} \\vec{F} \\cdot d\\vec{s} = \\iiint_{V}(div \\vec{F}) \\, dV = \\iiint_{V} \\vec{\\nabla} \\cdot \\vec{F} \\, dV $$ Che ha il bel risultato di rendere un integrale di superficie (2 dimensioni) come se fosse un integrale di volume. Assumendo il risultato descritto in #Superfice di separazione diventa banale perÃ².\nOsservazione: la divergenza prende in input un campo vettoriale, in output restituisce un campo scalare (che si potrebbe interpretare quasi fosse il modulo del vettore di derivata, con il gradiente ancora scalare).\nOsservazione: questa forma diventa molto piÃ¹ intuitiva se direttamente andiamo a parlare di cubi infinitesimali (Mencuccini spiega per benino sta parte diciamo e arriva subito al risultato, senza passare per il discorso che non ho capito bene sul flusso in una qualunque forma infinitesimale).\nRelazione divergenza e intuizione divergenza (!) ðŸŸ©+ si avrÃ  che $$ \\frac{\\oint_{\\Sigma} \\vec{F} \\cdot dS}{dV} = div \\vec{F} = \\text{per il teorema che verrÃ  dimostrato} = \\vec{\\nabla} \\cdot \\vec{F} $$ A parole: il flusso per unitÃ  di volume del nostro campo Ã¨ uguale al gradiente del campo stesso.\nUn modo molto piÃ¹ semplice per dimostrare questo, assumendo giÃ  di avere fatto la cosa del cubo Ã¨ notare questo $$ d\\phi = \\vec{\\nabla}\\cdot \\vec{E} d\\tau \\implies \\vec{\\nabla}\\cdot \\vec{E} = \\frac{d\\phi}{d\\tau} $$ E nella seconda parte abbiamo esattamente il flusso per cubo infinitesimo.\nHint di dimostrazione Mi definisco un cubo, e poi provo ad analizzare il flusso per ogni 6 lato, provo a porre un cubo infinitesimo, e dovrebbe poi tornare Mencuccini pagina 29 Ã¨ presente, sul Mazzoldi lo trovi a pagina 79.\nCircuitazione Intuizione di circuitazione e th separazione ðŸŸ© In questa parte qui ci chiediamo il flusso lungo una linea CHIUSA. Probabilmente sarÃ  utile per leggi come Lenz o Faraday. Anche in questo caso non ha senso considerare linee di separazione, perchÃ© avendo direzioni diverse si annullano. (guarda #Superfice di separazione descritto in precedenza.\nDefinizione di circuitazione $$ \\Gamma = \\oint_{L} \\vec{F} \\cdot d\\vec{l} $$ Che possiamo notare essere una forma molto molto simile rispetto a quanto definito per il flusso #Flusso di campo vettoriale.\nPosso fare un giochino (esattamente uguale a quello fatto in precedenza per la divergenza), ma lo faccio per piccole superfici, e flusso che gira attorno a quella superficie allora posso andare a definire il rotore\nIl rotore e teorema di stokes ðŸŸ©- Dividiamo tutta la nostra superficie con percorso chiuso in un sacco di piccoli pezzettini: $$ \\Gamma_{L} = \\sum_{i=1}^{N} \\oint_{L_{i}} \\vec{F} \\cdot d\\vec{l_{i}} = \\sum_{i=1}^{N} \\frac{ \\oint_{L_{i}} \\vec{F} \\cdot d\\vec{l_{i}}}{S_{i}} S_{i} $$ Allora definisco rotore questo: $$\\frac{ \\oint_{L_{i}} \\vec{F} \\cdot d\\vec{l_{i}}}{s_{i}} = \\vec{rot} \\vec{F} \\cdot \\hat{n} $$ Che intuitivamente Ã¨ la circuitazione infinitesimale.\nQuesto Ã¨ fatto a pagina 52\nTeorema di stokes Da questo ragionamento possiamo osservare che la circuitazione (che Ã¨ anche il lavoro si potrebbe dire) si puÃ² esprimere come il rotore. $$ \\oint \\vec{F} \\cdot d\\vec{l} = \\iint_{S_{L}} \\vec{rot} \\vec{F} \\cdot \\hat{n} \\, ds $$ Questo Ã¨ il teorema di stokes, e si puÃ² applicare per qualsiasi circuitazione, per qualsiasi superficie che ha come contorno alla fine L.\nRotore dimostrazione ðŸŸ© In questa parte proviamo ad esplorare la relazione che c\u0026rsquo;Ã¨ fra il rotore, come l\u0026rsquo;abbiamo definito di sopra, e la divergenza.\nConsideriamo un problema come in immagine Vogliamo cerca di definire la circuitazione, proviamo ad applicare proprio la definizione, quindi abbiamo che $$ \\oint \\vec{F} \\cdot d\\vec{l} = \\int _{A}^{B}F(x, y_{0}) \\, dx + \\int _{B}^{C}F(x_{0} + \\Delta x, y) \\, dy + \\int _{C}^{D}F(x, y_{0} + \\Delta y) \\, dx + \\int _{D}^{A}F(x_{0}, y) \\, dy $$ Supponiamo che la nostra funzione sia continua, quindi abbiamo che $\\exists c : \\int _{A}^{B}F(x, y_{0}) \\, dx = (B - A)F(c, y_{0}) = \\Delta xF(c, y_{0})$, questa cosa si puÃ² utilizzare per ogni singolo addendo della precedente, e scritto facendo in modo da contare anche le direzioni abbiamo che: $$ \\oint \\vec{F} \\cdot d\\vec{l} = \\Delta x F(\\hat{x}, y_{0}) + \\Delta y F(x_{0} +\\Delta x, \\hat{y}) - \\Delta x F(\\hat{x}, y_{0} + \\Delta y) - \\Delta y F(x_{0}, \\hat{y}) $$ Raccogliendo il delta e facendo tendere sia $x$ che $y$ a 0, possiamo scrivere una cosa del genere: $$ \\Gamma = -\\Delta x \\left[ \\frac{\\delta F_{x}}{\\delta y} \\Delta y \\right] + \\Delta y \\left[ \\frac{\\delta F_{y}}{\\delta x} \\Delta x \\right] \\implies \\Delta x\\Delta y \\left( \\frac{\\delta F_{y}}{\\delta x} - \\frac{\\delta F_{x}}{\\delta y} \\right) $$ Si puÃ² notare che se intendiamo questo come sopra, durante la dimostrazione per il #Teorema di stokes, allora $\\Delta x \\Delta y$ Ã¨ esattamente la superficie, orientata secondo $\\hat{n}$, mentre, proprio per matching dei parametri, il rotore diventa $rot \\vec{F} = \\left( \\frac{\\delta F_{y}}{\\delta x} - \\frac{\\delta F_{x}}{\\delta y} \\right)$ in questo caso, si potrebbe dire da un punto di vista a tre dimensioni, se avessimo il nostro quadratino in piÃ¹ dimensioni allora che\n$$ \\vec{rot}\\vec{F} = \\left( \\frac{\\delta F_{z}}{\\delta y} - \\frac{\\delta F_{y}}{\\delta z} \\right) \\hat{i} + \\left( \\frac{\\delta F_{x}}{\\delta z} - \\frac{\\delta F_{z}}{\\delta x} \\right) \\hat{j} + \\left( \\frac{\\delta F_{y}}{\\delta x} - \\frac{\\delta F_{x}}{\\delta y} \\right) \\hat{z} = \\vec{\\nabla} \\times \\vec{F} $$ Si puÃ² notare che questo Ã¨ strettamente legato al concetto di velocitÃ  angolare.\nDivergenza del rotore (!) ðŸŸ© Una volta espresso il rotore matematicamente come in precedenza (e sapendo anche il suo significato intuitivo di circuitazione per superficie), allora possiamo andare a fare cose interessanti come la divergenza che mi va a creare il rotore, ed Ã¨ molto particolare come i calcoli portano poi alla fine ad affermare che $$ \\oint_{S} (\\vec{\\nabla} \\times \\vec{F}) d\\vec{s} = \\iiint_{V} div (\\vec{\\nabla} \\times \\vec{F}) d\\vec{s} = \\iiint_{V} \\vec{\\nabla} \\cdot (\\vec{\\nabla} \\times \\vec{F}) d\\vec{s} = 0 $$ L\u0026rsquo;ultima uguaglianza lo abbiamo per cauchy, perchÃ© avremo delle derivate seconde, che si eliminano tutte fra di loro\nFisicamente forse mi sta dicendo che il rotore non crea flusso.\nNote sul gradiente Per qualche motivo Ã¨ vero questa cosa:\n$$ dV = \\frac{\\delta V}{\\delta x}dx + \\frac{\\delta V}{\\delta y}dy + \\frac{\\delta V}{\\delta z}dz $$ Questo Ã¨ un risultato ovvio (che non so perchÃ© Ã¨ ovvio, ma chatGPT https://chat.openai.com/share/c40e539d-9dd2-4bf7-b63d-2fc402751929) e altre ricerche sembrano dire questo del teorema del differenziale totale (che sembra se cercato in inglese ha significato giusto, in italiano diverso boh https://en.wikipedia.org/wiki/Total_derivative).\nComunque Ã¨ la base matematica per poter utilizzare il gradiente e scrivere cose come\n$$ dV = \\nabla V \\cdot ds $$ Dove $ds = u_{x}dx + u_{y}dy + u_{z}dz$\n","permalink":"https://flecart.github.io/notes/divergenza-e-circuitazione/","summary":"Scalare Scalare e gradiente ðŸŸ© Un campo scalare assegna a ogni punto dello spazio un valore reale, quindi Ã¨ naturalmente rappresentabile tramite una funzione $$ \\varphi(x, y, z) : \\mathbb{R}^{3} \\to \\mathbb{R} $$ Un esempio abbastanza naturale Ã¨ il gradiente del valore scalare che si indica con $$\\vec{\\nabla}\\varphi = ( \\frac{\\delta\\varphi}{\\delta x}, \\frac{\\delta\\varphi}{\\delta y}, \\frac{\\delta\\varphi}{\\delta z}) = \\frac{\\delta\\varphi}{\\delta x} \\hat{i} + \\frac{\\delta\\varphi}{\\delta y} \\hat{j} + \\frac{\\delta\\varphi}{\\delta z} \\hat{k}$$ Se consideriamo il gradiente da solo Ã¨ un campo vettoriale (dice la direzione della derivata multidimensionale).","title":"Divergenza e Circuitazione"},{"content":"Gran parte di quanto scrivo ora Ã¨ tratto da (Li \u0026amp; VitÃ¡nyi 2019). Chaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni \u0026lsquo;60!\nSolomonoff lo ha trovato sul problema dell\u0026rsquo;induzione all\u0026rsquo;etÃ  di 38 anni, Kolmogorov invece era giÃ  tardi, ha giÃ  trovato gli assiomi della probabilitÃ  e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilitÃ , nel 68 all\u0026rsquo;etÃ  di 19 anni. In AI teorico questo sembra un tema molto importante.\nCi sono degli esempi carini nella compressione di numeri naturali e stringhe binarie in Introduction to Algorithmic Information and Complexity.\nIntuizione Kolmogorov Per quanto ho capito io sulle motivazioni che sono state base alla creazione di questo concetto Ã¨ il concetto che: per descrivere cose complesse c\u0026rsquo;Ã¨ necessitÃ  di piÃ¹ parole. Questa idea molto intuitiva la possiamo tradurre da un punto informatico come il programma piÃ¹ corto per produrre un certo output.\nUn esempio classico Ã¨ una comparazione fra una stringa 01010101010101 contro una altra del tipo 11101111111100101011110000010101. Intuitivamente potremmo dire che la prima stringa sia molto piÃ¹ semplice da descrivere rispetto alla seconda stringa, abbiamo perÃ² bisogno di un modo formale per descrivere questo concetto.\nFormalizzazione Definizione Kolmogorov Definiamo la complessitÃ  di Kolmogorov $K_{L}(\\omega )$ per un certo linguaggio di programmazione $L$ come la minima lunghezza del programma tale per cui se eseguita sulla macchina astratta di $L$ dia come output $\\omega$.\nQuesta definizione si puÃ² riscrivere come $$ C(x) = \\min_{p}\\left\\{ length(p) : U(p) = x \\right\\} $$ Ossia il programma piÃ¹ corto che se eseguito su una macchina di Turing completa ho $x$.\nNOTA: questa definizione seppur meno informale di prima, non Ã¨ ancora quella formalmente accettata, perÃ² fa il suo per trasmettere l\u0026rsquo;idea, vedere il libro [^2] per definizione matematicamente corretta (e anche molto piÃ¹ astrusa)\nComplessitÃ  condizionale\nla complessitÃ  di Kolmogorov condizionale $K_{L}(\\omega | x)$ Ã¨ la lunghezza minima di un programma che prende in input $x$ e produce in output $\\omega$. (si legge proprio come se fosse un qualcosa di condizionato)\nLEMMA Ora diventa chiaro che un programma che stampa una qualunque stringa, sia sufficiente per dare in output, per questo motivo vale che: $$ K(x) \\le \\lvert x \\rvert + c \\tag{1} $$ Dove $c$ Ã¨ una costante per codificare le istruzioni per stampare. PiÃ¹ intuitivamente un programma di questo genere puÃ² stampare il carattere (dimostreremo in seguito, in #Teorema dell\u0026rsquo;invarianza che idea simile vale per ogni linguaggio)\nQuesto lemma giustifica anche la seguente definizione\nStringhe incomprimibili una stringa $\\omega$ si dice incomprimibile nel momento in cui $K(\\omega) = \\lvert \\omega \\rvert + O(1)$\nChe insieme all\u0026rsquo;upper bound di sopra, si avrÃ  che Ã¨ il massimo di complessitÃ  che puÃ² avere.\nKolmogorov condizionato Condizionato $K(A|B)$ significa che diamo alla nostra macchina di turing in input anche $B$ per codificare $A$. Puoi vedere subito che la complessitÃ  di $K(A|A)$ Ã¨ $0$ perchÃ© la macchina di turing puÃ² non fare nulla $\\varepsilon$ Ã¨ il programma diciamo, e avere subito un risultato. Intuitivamente avere qualcosa in piÃ¹ non fa altro che ridurre il codice necessario, quindi possiamo dire che $K(A|B) \\leq K(A)$. E qui si puÃ² creare anche una nozione di indipendenza.\nChain Rule Afferma che per qualunque oggetto vale che $$ K(A|B) \\geq K(A, B) - K(B) $$ Ossia la codifica di entrambi, sia $A$ che $B$ Ã¨ necessariamente minore di codificare prima $B$ e poi usare questa per codificare $A$. Si puÃ² dimostrare ma intuitivamente questa legge sembra parlare in modo chiaro.\nQuesto vale se assumiamo che tutte le parole godano della Prefix Property Bottom-up Parser LR(1)Algorithmic Probability. Se non vale la regola diventa $$ C(s_{1}) \\leq C(s_{2}) + C(s_{1} | s_{2}) + O(\\log(C(s_{2}))) $$ Il motivo di questo $O$ grande strano Ã¨ che\n$\\log(C(s_{2}))$ is the maximal length of the information needed to separate the program that computes $s_{2}$Â from what comes next (as we cannot guarantee that this program is uniquely decodable, contrary to the prefix case).\nMa non lo ho capito ancora bene.\nIncomputabilitÃ  di Kolmogorov Dimostrazione: Supponiamo che sia computabile, allora abbiamo un programma $P$ che calcola il programma minimo. Ora possiamo usare questo programma per trovare una stringa la cui complessitÃ  di Kolmogorov sia piÃ¹ lunga di un certo $n$. Questo si puÃ² fare provando ad aggiungere roba (probabilmente qui mi serve un lemma che dice che Ã¨ crescente stretto e non lasco). Ma la complessitÃ  di questa nuova stringa trovata deve essere uguale alla complessitÃ  di $n$, che gli dÃ² in input! (piÃ¹ costante per la ricerca che ignoro per Kolmogorov). Questo significa che $K(n) \u003e n$ che Ã¨ assurdo perchÃ© $K(n) \\approx \\log_{2}(n)$ che Ã¨ strettamente minore di $n$.\nPossiamo perÃ² approssimare il valore, e per molte cose questo basta!\nKolmogorov complexity is an ideal notion that can be approximated, but that is not computable.\nUn pseudocodice di esempio per computare una cosa piÃ¹ complessa (anche se non ho la dimostrazione che fa quello che deve fare, perchÃ© in teoria credo puÃ² continuare in modo arbitrariamente lungo, solo che la probabilitÃ  che non finisca tende a 0)\ndef MoreComplex(n): i =1 while True: for m in range(2**i): s = bin(m)[2:]Â if cc(s) \u0026gt; n:Â return s i += 1 Teorema dell\u0026rsquo;invarianza Questo Ã¨ un teorema fondamentale (e anche di base) per quanto riguarda la definizione della teoria inerente a questa complessitÃ . Ci permette di affermare che il concetto di complessitÃ  Ã¨ indipendente dal linguaggio di programmazione utilizzato, e ci darÃ  presto anche alcuni risultati interessanti sulla computabilitÃ  di questa funzione (in modo diverso rispetto alle classiche dimostrazioni che si possono trovare in teoria della computabilitÃ ). Quindi questo teorema Ã¨ fondamentale per stabilire l\u0026rsquo;oggettivitÃ  della proprietÃ . CosÃ¬ possiamo dire che Ã¨ una proprietÃ  dell\u0026rsquo;oggetto, non di come lo stai valutando. Quindi non dipende dalla capacitÃ /architettura di chi sta valutando il linguaggio.\nSiano $L$ e $L^{'}$ due linguaggi Turing completi, allora per ogni stringa $\\omega$ si ha che $$K_{L}(\\omega) = K_{L^{'}}(\\omega) + O(1)\\tag{2}$$ Dimostrazione: Essendo $L$ e $L^{'}$ dei linguaggi Turing completi, allora posso scrivere un programma in $L^{'}$ che esegua la macchina astratta di $L$ e quindi mantenga tutta la semantica del linguaggio $L$ (vedere Macchine Astratte per la definizione di interprete).\nAllora si avrÃ  che $$ K_{L^{'}}(w) = K_{L}(\\omega) + |I| \\tag{2.1} $$ ossia il costo per esprimere la complessitÃ  della string $\\omega$ in $L^{'}$ Ã¨ equivalente al costo per esprimere il programma $p$ in $L$, ed eseguirlo con un interprete (che avrÃ  una lunghezza finita, e costante una volta fissato i due linguaggi). L\u0026rsquo;interprete esiste perchÃ© stiamo usando macchine di Turing universali per la descrizione della lunghezza.\nNOTE: Grazie a questa proprietÃ  da ora in poi potremo parlare di $K(\\omega)$ indipendentemente da linguaggio su cui Ã¨ stato scritto, dato che tanto distano di una costante uno dall\u0026rsquo;altro.\nNOTE2: Ãˆ una cosa molto curiosa il fatto che sia dipendente dall\u0026rsquo;osservatore, anche se abbiamo una differenza, perchÃ© cose importanti per qualcuno, sono codificate in modo differente da ognuno. Questo Ã¨ un pensiero molto deep, e l\u0026rsquo;esempio della versione della macchina Ã¨ chiaro.\nEsistenza di stringhe complesse Un risultato importante che sarÃ  utile alla dimostrazione della non computabilitÃ  della funzione di complessitÃ  di Kolmogorov Ã¨ la seguente:\u0026gt; $$ \\forall n \\in \\mathbb{N}, \\exists \\omega : K(w) \\geq n $$ che Ã¨ un risultato che non sembra avere molto senso perchÃ© ci sta dicendo che esistono delle stringhe di complessitÃ  infinita (forse queste stringhe sono quelle non computabili, perchÃ© il programma che lo descrive dovrebbe avere lunghezza infinita).\nDimostrazione: La dimostrazione di questo teorema non Ã¨ altro che una applicazione del pigeonhole principle. In un certo senso salta fuori dalla relazione fra il finito e l\u0026rsquo;infinito, come quelle cose assurde che $2n$ Ã¨ in bigezione con i numeri naturali. Siamo nel mondo di Turing, quindi i programmi saranno anch\u0026rsquo;esse delle stringhe binarie. Consideriamo tutti i programmi di lunghezza zero. Questo produrrÃ  la stringa vuota, ossia la stringa di complessitÃ  zero. Supponiamo ora tutti i programmi di lunghezza uno. Al massimo potremo avere due stringhe con questa complessitÃ . E cosÃ¬ via. Intuitivamente: dato che il numero delle stringhe $\\omega$ che possono esistere sono infinite, anche i la lunghezza dei programmi utilizzati per generare queste stringhe sono infinite, perchÃ© banalmente un programma di lunghezza $n$ puÃ² generare al massimo $2^n$ stringhe diverse, un numero finito, anche se enormemente ampio.\nNon calcolabilitÃ  della funzione di Kolmogorov La funzione di Kolmogorov non Ã¨ calcolabile su un macchina di Turing\nDimostrazione: Supponiamo che esista una macchina di Turing $M$ che prenda in input una stringa $\\omega$ e ritorni $K(\\omega)$. Utilizzeremo il teorema #Esistenza di stringhe complesse\nAllora utilizziamo questa macchina di Turing $M$ per costruirne una altra $M^{'}$ che si comporti in questo modo:\ninput n for each string w in alphabet: do if K(w) \u0026gt;= n: return w done endfor In pratica vado a scorrere tutte le parole nell\u0026rsquo;alfabeto infinito, so che prima o poi troverÃ² una stringa tale per cui $K(w) \\geq n$ perchÃ© ne abbiamo dimostrato l\u0026rsquo;esistenza precedentemente. Questa macchina allora descriverÃ  la stringa $\\omega$ che viene in output, dato l\u0026rsquo;input $n$.\nMa allora abbiamo che $$ n \\leq K(\\omega) \\leq \\lvert \\langle M^{'}, n \\rangle \\rvert + O(1) = O(1) + \\lvert n \\rvert = O(1) + O(\\log(n)) = O(\\log(n)) $$ Ed Ã¨ assurdo perchÃ© afferma che $O(n) \\leq O(\\log(n))$ che sarÃ  vero per $n$ abbastanza alto.\nUpper bound con entropia Kolmogorov si puÃ² vedere come una cosa piÃ¹ generale dell\u0026rsquo;entropia di Shannon Entropy, si puÃ² vedere come una approssimazione di essa perchÃ© basta prendere $L \\approx \\log_{2}\\left( \\frac{1}{p} \\right)$ e si ha l\u0026rsquo;entropia Shannoniana. La cosa carina Ã¨ che Kolmogorov ha senso anche in assenza di frequenze e probabilitÃ .\nCose che non ho capito Per qualche motivo la complessitÃ  di un oggetto scende quando l\u0026rsquo;entropia Ã¨ massima (ah, quando sono tutti uguali le probabilitÃ , la complessitÃ  scende)\nParte vecchia dal libro di complexity Questo Ã¨ il teorema fondamentale di questo campo, che ricordiamo prova a cercare di creare una teoria sulle descrizioni di minima lunghezza per qualcosa, questo dovrebbe essere in grado di risolvere il problema del limite della probabilitÃ , e cose di teoria dell\u0026rsquo;informazione che non ho ancora ben compreso.\nComunque si Ã¨ notato che si puÃ² definire una classe di equivalenza, e fra queste esiste una classe speciale che Ã¨ quello di descrizione minima. Partiamo perÃ² dalla definizione di di complessitÃ  diciamo: $$ C_{f}(x) = min\\{l(p) : f(p) = n(x)\\} $$ $f$ Ã¨ una macchina di turing.\nUna volta definito questo e creato un insieme fisso di macchine o funzioni si puÃ² estendere questo modello in classi di equivalenza, perchÃ© possiamo utilizzare $\\langle n, p \\rangle$ on $n$ l\u0026rsquo;index alla macchina corretta e $p$ il nostro programma (anche se non ho capito perchÃ© si assume che il programma sia comprensibile a qualunque macchina, e non ho capito perchÃ© la funzione la si puÃ² intendere come se fosse una macchina, questa Ã¨ una parte di teorica che mi dovrei recuperare).\nComunque fatto questo, si puÃ² mostrare come data una sequenza contabile di funzioni $\\phi_{1}, \\phi_{2}, \\dots, \\phi_{n}$ allora posso andare a definirmi $\\phi_{n}(p) = \\phi_{0}(\\langle n, p \\rangle)$ anche se non ho capito cosa voglio dire qui, con $\\phi_{0}$ la funzione computata da una macchina di Turing universale $U$ . Indicheremo $$ C_{\\phi_{0}}(x) = C(x) $$ per ogni programma $x$.\nReferences [1] Li \u0026amp; VitÃ¡nyi â€œAn Introduction to Kolmogorov Complexity and Its Applicationsâ€ Springer International Publishing 2019\n","permalink":"https://flecart.github.io/notes/kolmogorov-complexity/","summary":"Gran parte di quanto scrivo ora Ã¨ tratto da (Li \u0026amp; VitÃ¡nyi 2019). Chaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni \u0026lsquo;60!\nSolomonoff lo ha trovato sul problema dell\u0026rsquo;induzione all\u0026rsquo;etÃ  di 38 anni, Kolmogorov invece era giÃ  tardi, ha giÃ  trovato gli assiomi della probabilitÃ  e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilitÃ , nel 68 all\u0026rsquo;etÃ  di 19 anni.","title":"Kolmogorov complexity"},{"content":"Ripasso Prox: 10 Ripasso: May 29, 2023 Ultima modifica: May 19, 2023 10:33 AM Primo Abbozzo: May 8, 2023 9:20 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Object orientation il tipo di dato astratto Introduzione Per questi tipi di dato non ci interessa di sapere cosa ci sia sotto (storato come bit? storato come sabbia boh), ci interessa solamente che abbia quei metodi, che possiamo in un certo senso identificare come la sua capsula, opaca in questo caso.\nQuando si puÃ² andare a modificare solamente attraverso questo metodo potrei dire che sia safe collegato alla Algebra dei tipi, nel senso che vengono soddisfatte sempre le proprietÃ  del tipo.\nCostituenti del ADT (4) (abstract data structure) ðŸŸ¨ Slide ADT\nCi sono principalmente 4 elementi:\nIl nome del tipo di dato astratto Il dato concreto che sta sotto (ad esempio intero Operazioni di creazione ed accesso (che in un certo senso sono simili ai meccanismi di Architettura software dellâ€™OS) confine di astrazione che sono come le interfaccie, o politiche? In pratica credo siano equivlaenti alle cose pubbliche di questa, mentre il punto 3 racchiude anche quelle private. Information hiding ðŸŸ© Slide information hiding\nIl fatto che vogliamo cercare di andare ad operare e prendere da questo tipo di dato astratto solamente attraverso delle interfacce. Per questo motivo si puÃ² dire che stiamo nascondendo cosa c\u0026rsquo;Ã¨ dentro a quella classe.\nSotto questo punto di vista, si dice spesso che la classe Ã¨ come contratto con la superficie, perchÃ© va a soddisfare certe proprietÃ  con chi la utilizza.\nIl fatto che l\u0026rsquo;implementazione effettiva viene nascosta, aiuta alla modularitÃ . Non posso fare assunzioni sullâ€™implementazione effettiva, mi basta che le proprietÃ  dellâ€™interfaccia siano rispettate.\nUn altro aspetto Ã¨ che Ã¨ facile organizzare progetto in moduli a seconda di cosa stiamo rappresentando (prova a tenerti in mente la classica organizzazione in un file per una classe che si fa spesso in java).\nIndipendenza della rappresentanza ðŸŸ© Andiamo ora ad introdurre il concetto di indipendenza della rappresentanza (ossia il fatto che non ci interessa questo tipo di dato astratto da quale tipo concreto Ã¨ rappresentato), un fatto che la caratteristica dellâ€™information hiding ci ha permesso di avere:\nSlide indipendenza\nimplementazioni corrette (ben tipate) dello stesso ADT sono osservabilmente indistinguibili dai consumatori dellâ€™ADT.\nTipi esistenziali ðŸŸ© Questi sono quasi l\u0026rsquo;opposto dei tipi di polimorfismo universale parametrico in Polimorfismo, praticamente Ã¨ un exist invece che un forall, che carina questa relazione.\nSi potrebbe vedere come la rappresentazione di ADT attraverso teoria dei tipi.\nSlide tipi esistenziali\nQuando vado a definire un tipo che soddisfa quella caratteristiche non starei facendo altro che risolvendo il tipo esistenziale da un punto di vista di teoria dei tipi.\nEsempio risoluzione di tipi esistenziali\nOggetti esistenziali ðŸŸ© Slide problema tipi esistenziali\nSlide oggetti esistenziali\nGli oggetti esistenziali mantengono l\u0026rsquo;astrazione del tipo esistenziale, a differenza delle ADT che vanno ad eliminare lâ€™esiste e quindi diventano inoperabili fra di loro, tenendo lâ€™astrazione possiamo andare a cooperare fra istanziazioni diverse di questo oggetto esistenziale. (si porta avanti l\u0026rsquo;interfaccia senza andarlo a risolvere come per ADT)\nUna altra differenza Ã¨ che oggetti fanno una differenza fra stati e metodi, mentre il tipo di dato astratto tiene solamente operazioni e il tipo sotto di esso.\nSlide confronto oggetti esistenziali con abstract data types\nIn breve ADT sono aperti, mentre oggetti sono chiusi e quest\u0026rsquo;ultimo fatto permette di utilizzare tipi con istanziazione anche diversa fra di loro.\nuna differenza rilevante degli oggetti rispetto agli ADT Ã¨ che, poichÃ© ogni oggetto ha la propria rappresentazione interna e implementa le proprie operazioni, un programma puÃ² liberamente mescolare implementazioni diverse dello stesso tipo di oggetto (esistenziale).\nClassi e oggetti Def oggetto ðŸŸ© Oggetto: una capsula che contiene sia dati che operazioni per manipolarli e che fornisce un\u0026rsquo;interfaccia al mondo esterno attraverso la quale Ã¨ possibile accedervi.\nLe operazioni sono anche chiamate metodi. mentre i dati sono chiamati campi dell\u0026rsquo;oggetto.\nDef classe ðŸŸ© Una classe Ã¨ un modello per un insieme di oggetti: stabilisce quali sono i loro dati (quanti, di che tipo, con quale visibilitÃ ) e fissa il nome, la segnatura, la visibilitÃ  e l\u0026rsquo;implementazione dei suoi metodi\nIn modo piÃ¹ intuitivo potremmo andare a dire:\nclasse: Specifica un canovaccio o un modello di implementazione di riferimento che contiene le variabili e i metodi comuni alla stessa classe (da cui il nome) di oggetti.\nImplementazione delle classi (2)ðŸŸ© La definizione dei metodi della classe Ã¨ unica, sono solamente i campi di dati che sono diversi per ogni istanziazione. Come fanno ogni istanziazione ad accedere al metodo corretto allora? Puntatore all\u0026rsquo;unica istanziazione! L\u0026rsquo;immagine sotto puÃ² chiarificare questo concetto:\ndallâ€™altra parte quando dall\u0026rsquo;implementazione mi vado a riferire a this, questo deve derefernziarwsi sulla corretta istanziazione dellâ€™oggetto!\nLo storage, come al solito, puÃ² essere sia a stack sia sulla heap, a seconda dellâ€™implementazione del linguaggio.\nPrincipalmente credo che le osservazioni principali siano due:\nDereferenziare correttamente il this Sapere accedere alle funzioni definite nella classe Prototipi e confronto con classi ðŸŸ¨ Questi sono un pattern che piace tanto a Javascript.\nsi basa sulla possibilitÃ  che gli oggetti deleghino parti della loro implementazione ad altri oggetti.\nCreazione ora si puÃ² fare in due modi, uno il classico Ã¨ new, l\u0026rsquo;altro Ã¨ ex-nihilo andando a definire passo passo tutto (in modo direi estensionale, andando a ricollegarmi con Teoria dei Tipi)\nla differenza principale dei prototipi con le classi Ã¨ la flessibilitÃ  vs sicurezza dato che in js i prototipi possono essere assegnati a runtime, quindi potrebbero anche cambiare (sicuramente cattiva pratica, credo si chiami anche monkey typing).\nNelle classi non possiamo andare a cambiare l\u0026rsquo;implementazione una volta dichiarata.\nSi una possibilitÃ  di fare una delegazione ossia il metodo Ã¨ implementato in modo dinamico e vado a cercare il primo prototipo per quell\u0026rsquo;oggetto. Ãˆ molto flessibile, perchÃ© utilizza duck-typing, molto facile cambiare le cose, solo che dal punto di vista della correttezza e sicurezza Ã¨ un pÃ² piÃ¹ difficile.\n","permalink":"https://flecart.github.io/notes/object-orientation/","summary":"Ripasso Prox: 10 Ripasso: May 29, 2023 Ultima modifica: May 19, 2023 10:33 AM Primo Abbozzo: May 8, 2023 9:20 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Object orientation il tipo di dato astratto Introduzione Per questi tipi di dato non ci interessa di sapere cosa ci sia sotto (storato come bit? storato come sabbia boh), ci interessa solamente che abbia quei metodi, che possiamo in un certo senso identificare come la sua capsula, opaca in questo caso.","title":"Object orientation"},{"content":"Ripasso Prox: 55.81 Ripasso: May 20, 2022 Ultima modifica: October 8, 2022 12:09 PM Primo Abbozzo: October 11, 2021 6:14 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Vecchi dubbi Interrogare sÃ© stessi se abbiamo capito con esattezza il significato di limite, vedere se lo abbiamo imparato a memoria oppure meno, chiedersi del perchÃ© lo si abbia definito in questo modo. 3 Successioni e Limiti 3.1 Successioni $$ \\begin{cases} f: \\mathbb{N} \\to \\mathbb{R} \\\\ n \\to f(n) \\\\ \\{a\\}_{n \\in \\mathbb{N}} \\vee a_n \\end{cases} $$ Ãˆ una funzione che mappa dai naturali ai Reali indicata spesso solamente come $$ \\left\\{ a \\right\\} _{n \\in \\mathbb{N}} $$ 3.1.1 Immagine e successione L\u0026rsquo;immagine di una successione (l\u0026rsquo;insieme dei suoi elementi) non Ã¨ una successione! la successione Ã¨ anche ordinata.\n3.1.2 Limitazioni della successione Come per gli insiemi si puÃ² definire se l\u0026rsquo;insieme Ã¨ limitato superiormente, inferiormente o entrambi, a seconda di come lo definiamo in questo modo possiamo poi farci altri ragionamenti\nPer decidere se esiste questo limite, continui a fare gli stessi ragionamento sul maggiorante e minorante come per gli insiemi.\nSe uniamo l\u0026rsquo;essere superiormente o inferiormente limitato con la monotonia allora possiamo unire questa con il concetto di convergenza a un limite finito.\n3.1.3 Monotonia delle successioni Le successioni possono essere crescenti, descrescenti.\nLa definizione di queste successioni Ã¨ lasciata al lettore.\n3.2 Limiti di successioni 3.2.1 Intuizione Mi posso arrivare a un certo valore di quanto mi pare, del singolo valore che mi pare so che esiste sempre un valore che mi posso avvicinare.\n3.2.2 Limite Convergente Si definisce un limite per x che tende all\u0026rsquo;infinito di una successione $a_ n$ in questo modo:\n$$ L=\\lim_{x\\to\\infty} a_{n}:=\\forall \\epsilon\\in \\R^+, \\exists n_0\\in \\N^*,\\forall n \\in \\N:n \\geq n_0 \\implies |a_n - L| \u003c \\epsilon $$ 3.2.3 Limiti divergenti Ossia per qualunque k, posso andare a cercare un $n_0$ da qui in poi la successione Ã¨ sempre maggiore, posso scegliere come mi pare\n$$ \\infty = \\lim_{ x\\to +\\infty} a_ n:= \\forall k\\in \\R^+, \\exists n_0\\in \\N^*,\\forall n \\in \\N:n \\geq n_0 \\implies a_n \\geq k $$ $$ -\\infty = \\lim_{ x\\to +\\infty} a_ n:= \\forall k\\in \\R^+, \\exists n_0\\in \\N^*,\\forall n \\in \\N:n \\geq n_0 \\implies a_n \\leq k $$ Nota di italiano\nSI puÃ² dire solamente se una successione tende ma non puoi mai dire che il limite tende a qualcosa, perchÃ© il limite Ã¨ definito come un certo valore.\n3.2.4 Limiti finiti Questa definizione di limite di rifÃ  al concetto di intorno, ed Ã¨ un limite valutato su un unico punto 3.2.5 Limiti su successioni monotone !!! Sia data una successione crescente $a_n$, allora $\\lim_{x \\to \\infty} = \\sup \\{a_n | n \\in \\N\\}$\nSimile per successioni decrescenti\nDimostrazione\nDimostriamo ora per il caso decrescente.\nAllora il limite $L$ Ã¨ o finito, o Ã¨ $-\\infty$.\nCaso 1 $L = -\\infty$:\nLa successione non ha un limite inferiore, quindi non esistono dei minoranti per questo insieme, allora $\\forall k \u003e0 \\implies \\exists n_0 : a_{n_0} \u003c k$ allora essendo la successione decrescente abbiamo che $\\forall n : n\\in\\N, n \u003c n_o \\implies a_n \u003c a_{n_0}$ quindi $a_n \u003c k$ per ogni n minore di $n_0$ ciÃ² Ã¨ sufficiente per dimostrare la tesi dell\u0026rsquo;esistenza del limite divergente\nCaso 2 $L$ finito:\ndobbiamo dimostrare che $-\\epsilon \\leq |a_n - L| \\leq \\epsilon \\iff L - \\epsilon \\leq a_n \\leq L + \\epsilon$ ma sappiamo in quanto $L$ Ã¨ un minorante che vale $L - \\epsilon \\leq a_n$, consideriamo ora, $L + \\epsilon$, non essendo un minorante, deve esistere un $a_{n_0} \u003c L + \\epsilon$ allora essendo la successione decrescente abbiamo che $\\forall n : n\\in\\N, n \u003c n_o \\implies a_n \u003c a_{n_0}$ , quindi esiste un $n_0$ tale per per ogni $n$ minore di quello vale la sufficienza per il limite.\n3.3 Algebra dei limiti Ipotesi e tesi di ciÃ²\n3.3.1 Somma limiti finiti Siano $a_n , b_n$ successioni con limite finito $l_1,l_2$, allora il limite di $a_n + b_n$ Ã¨ $l _1 + l_2$.\n$-\\epsilon_a \\leq a_n - l_1 \\leq \\epsilon_a$\nallora $-\\epsilon_b \\leq b_n - l_1 \\leq \\epsilon_b$\nallora $-\\epsilon_a -\\epsilon_b \\leq a_n - l_1 + b_n - l_1\\leq \\epsilon_a +\\epsilon_b$ e ciÃ² finisce la dimostrazione.\n3.3.2 Somma limiti Se usiamo un limite tale che una dei due Ã¨ infinito e hanno lo stesso segno allora abbiamo quello che abbiamo\u0026hellip;. Guarda le slides!\n3.3.3 Prodotto dei limiti finiti 3.3.4 Prodotto di limiti infiniti 3.3.5 Forme indeterminate somma e prodotto e divisione Somma di $+\\infty-\\infty$ oppure il contrario.\n$0 \\cdot \\pm\\infty$\nQualunque divisione fra infiniti .\n3.4 Numero di Nepero 3.4.1 NecessitÃ  per dimostazioni Per dimostrare l\u0026rsquo;esistenza del numero di Nepero come\n$$ \\lim_{n \\to \\infty} (1 + \\dfrac{1}{n})^n = e $$ Devo dimostrare in particolare due cose:\nCrescenza della funzione Limitatezza della funzione (ricorda che per questa proprietÃ  ho che una successione crescente o Ã¨ limitata e ha limite finito o Ã¨ divergente) 3.4.2 La disuguaglianza di Bernoulli La tesi e ipotesi della disuguaglianza di Bernoulli\nDimostrazione:\nSi ha una dimostrazione per induzione\nPB:\n$n = 0 \\implies 1 \\geq 1$ Verificato\nSupponiamo che valga per n, dobbiamo dimostrare che\n$(1 + x) ^{n + 1} \\geq 1 + x + nx$\n$(1 + x) ^{n + 1} \\geq (1 + x)(1 + nx) = 1 + nx + x + nx^2$ ovvio che sia maggiore della parte di destra, per cui Ã¨ dimostrato.\n3.4.3 Crescenza della successione La successione Ã¨ strettamente crescente, con 2 pagine e mezzo di calcoli.\nPrima dimostri che la divisione fra due numeri successivi della sequenza sia $\u003e 1$, poi fai i calcoli, in modo strano, facendo delle mosse anche intelligenti per quanto riguarda togliere e aggiungere degli uno e finisci a dire che vale.\n3.4.4 Limitatezza della successione Questa dimostrazione si dimostra espandendo la definizione con il binomio di Newton, in seguito si devono avere queste seguenti osservazioni interessanti:\nSemplificare $\\dfrac{n(n-1)...(n-k+1)}{n^k}$ dicendo che Ã¨ minore di 1, in quanto tutti i $k$ fattori al numeratore sono minori del denominatore. Semplificare il restante $\\dfrac{1}{k!}$ con le somme telescopiche (usando la disuguaglianza 1/k! â‰¤ della somma telescopica) e dimostrare che Ã¨ finito. Si dimostra quindi che l\u0026rsquo;upper bound Ã¨ 3.\n","permalink":"https://flecart.github.io/notes/successioni/","summary":"Ripasso Prox: 55.81 Ripasso: May 20, 2022 Ultima modifica: October 8, 2022 12:09 PM Primo Abbozzo: October 11, 2021 6:14 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Vecchi dubbi Interrogare sÃ© stessi se abbiamo capito con esattezza il significato di limite, vedere se lo abbiamo imparato a memoria oppure meno, chiedersi del perchÃ© lo si abbia definito in questo modo. 3 Successioni e Limiti 3.1 Successioni $$ \\begin{cases} f: \\mathbb{N} \\to \\mathbb{R} \\\\ n \\to f(n) \\\\ \\{a\\}_{n \\in \\mathbb{N}} \\vee a_n \\end{cases} $$ Ãˆ una funzione che mappa dai naturali ai Reali indicata spesso solamente come $$ \\left\\{ a \\right\\} _{n \\in \\mathbb{N}} $$ 3.","title":"Successioni"},{"content":"Ultima modifica: October 19, 2022 5:05 PM Primo Abbozzo: February 2, 2022 4:31 PM Studi Personali: No\nCerco di riassumere i concetti principali nei video di Benedict Gross presenti sul web (in particolare youtube)\nArgomento Spazi vettoriali Th: generatori di spazi - linearmente indipendenti Dati due insiemi di vettori S e L, con S che spanna nello spazio V e L di vettori in V che siano tutte linearmente indimendenti, allora $|S| \\geq |L|$\nIdee principali\nSono principalmente due le idee principali.\nL appartiene a V e S spazia tutto questo spazio, quindi posso scrivere il vettore L come combinazione lineare con vettori di S. Utilizzo 1 questo per arrivare a una contraddizione sullâ€™indipendenza lineare di L quando S \u0026lt; L Infatti quando questo succede, riesco a trovare una riscrittura di L con S che mi rende L = 0 Utilizzo anche il fatto che quando ho n equazioni e m incognite, se m \u0026gt; n posso trovare una soluzione non banale sempre. Cor: Tutte le basi di V hanno stessa dimensione La dimensione sarebbe il numero di elementi. Non so esattamente come si dimostrare questo.\nCor: Tutti i generatori hanno dimensione maggiore o uguale della base Questa Ã¨ una conseguenza banale del teorema.\nPossia.\nUna cosa che si tiene in conto, molto simile a questo corollario Ã¨ un algoritmo che si usa per dimostrare che se ho un insieme di vettori linearmente dipendenti L che generava uno spazio V, posso togliere vettori finchÃ© non diventa una base.\nCor: Un insieme linearmente indipendente L ha dimensione minore o uguale alla base Questo si puÃ² dimostrare che un insieme linearmente indipendente L si puÃ² espandere per generare lo spazio V aggiungendo un vettore alla volta finchÃ© non ha dimensione della base, e se Ã¨ una base per il corollario 1 deve essere della stessa dimensione.\nTh: rimpiazzamento di basi Th: bigezione fra matrici e trasformazioni lineari Buona bigezione, ma non approfondisco quam non la ho studiata.\nTh: counting theorem Sia f un automorfismo su un vettore\nRelazione con Geometria Quando usiamo come campo i reali, questo ha una relazione intima con la geometria.\nSi ha un gruppo normale con il gruppo ortogonale con il gruppo generale lineare.\nVogliamo mettere un pÃ² di struttura sul campo dei reali in modo che sia utile per i nostri calcoli geometrici.\nGruppo ortogonale Con la coppia ordinata come il prodotto scalare. Bisognerebbe dimostrare (check) che effettivamente questo sia un gruppo, ma non sembra difficile, almeno quando lo fa Benedict Gross.\nDiscrete subgroups Isometria Ã¨ una transformazione che mantiene la distanza di punti. Si puÃ² dimostrare che Ã¨ una composizione fra trasformazione ortogonale (rotazione) e translazione).\nDiscreto di solito significa che un sottogruppo finito di G, non contiene rotazioni o translazioni arbitrariamente piccole (esiste un minimo di rotazione o translazione).\nPossono esistere insieme infiniti!\nPossibili sottogruppi:\nGruppi di translazione. â†’ additive part.\nGruppi di rotazione â†’ point stabilizer part, and linear operation\nGruppi di composizione fra i due, che andiamo a chiamare Reticoli (lattices).\nLemma 1 Intersezione di uno sottospazio di R con L sottogruppo discreto contiene finiti punti di L Se fosse infinito allora possiamo trovare una sottosequenza infinita, per qualcosa di simile a Bolzano Weierstrass (circa compattezza) posso trovare una serie di punti che converge a qualcosa, faccio translazione e allora dimostro che mi posso avvicinare quanto mi pare a 0, cosa che non puÃ² essere nel discreto.\nQuindi ho un insieme finito.\nClassificazione punti possibili Ogni punto nel gruppo, la distanza a due a due Ã¨ maggiore o uguale a epsilon minore che câ€™Ã¨. (gruppo additivo di translazione). Altrimenti si avrebbe una contraddizione, câ€™Ã¨ una distranza minima fra due punti ok?\nL Ã¨ diverso da 0, allora Ã¨ in una riga, o reticolo. (possiamo estendere questo argomento a piÃ¹ dimensioni, ora ragioniamo su 2)\nSe Ã¨ sulla riga, dato che Ã¨ un insieme discreto posso trovare il vettore piÃ¹ vicino allâ€™origine (che Ã¨ per forza nellâ€™origine) la distanza Ã¨ maggiore uguale a epsilon. Allora tutti i punti devono essere multipli di questo. Lâ€™argomento Ã¨ simile allâ€™algoritmo di euclide. (dici che câ€™Ã¨ un resto minore di b e questo deve essere nellâ€™insieme, ma questo non puÃ² essere perchÃ© abbiamo preso giÃ  b come minimo quindi r = 0). Se non Ã¨ sulla riga allora contiene una base (linearmente indipendenti, altrimenti si ha una riga, poi in R2 basta che siano indipendenti per spannare lâ€™intero spazio, quindi due vettori a caso ok?). Siano a, b vettori della base, e b il vettore di modulo minore nella linea bR, uguale per a. Vogliamo dire che questi siano i nostri generatori dello spazio. Consideriamo il parallelogramma formato da questi vettori. Questo parallelogramma contiene un insieme finito di punti di L per Lemma 1. Applichiamo questo algoritmo: rimpiazziamo b di sopra per il punto bâ€™ nel parallelogramma che sia piÃ¹ vicino ad a rispetto a b. allora ho un parallelogramma piÃ¹ piccolo. Continuiamo finchÃ© non ci siano piÃ¹ punti (basterebbe anche applicarlo una sola volta prendendo subito il minimo lol). Abbiamo trovato il parallelogramma minimo e claimmiamo che L = Za + Zb, ovvero mettiamo parallelogrammini in giro per lâ€™intero spazio cosÃ¬ ðŸ™‚. Applichiamo lâ€™argomento euclideo anche qui e concludiamo ciÃ². Lâ€™immagine di Gamma in O(2) preserva L (lattice) Questo pone delle grandi restrizioni sul sottogruppo discreto.\nL = {0} allora ho il gruppo ciclico o dihedrale.\nAltrimenti Gamma puÃ² essere gruppi $L = C_n or D_{2n}, n = \\{1,2,3,4,6\\}$ e quindi sta restringendo molte cose.\nDear Dr __.\nIâ€™m writing this letter to ask the recovery of some of my files on the codespace that got deleted without any forewarning.\nIâ€™m a student at first year of Computer Science in Bologna. I was amazed by the quality of your lessons and I astonished by the power of the codespaces. I began to take notes with it. Every note of the first semester was on this codespace.\nI began to write programs on it and it was so fast! Such a good infrastructure! I began also to write some of my own hobby projects on it. It was fascinating.\nBut, suddenly, everything got deleted. I lost every note. I lost every program. I didnâ€™t expect this would happen and i didnâ€™t make a backup. I lost everything. iâ€™m downhearted from this event.\nSo iâ€™m writing this letter to ask you if itâ€™s possible to recover my files, the files i wrote in a semester of work.\nBest Filippo . ything. iâ€™m downhearted from this event.\nSo iâ€™m writing this letter to ask you if itâ€™s possible to recover my files, the files i wrote in a semester of work.\nBest Filippo .\n","permalink":"https://flecart.github.io/notes/algebra-astratta/","summary":"Ultima modifica: October 19, 2022 5:05 PM Primo Abbozzo: February 2, 2022 4:31 PM Studi Personali: No\nCerco di riassumere i concetti principali nei video di Benedict Gross presenti sul web (in particolare youtube)\nArgomento Spazi vettoriali Th: generatori di spazi - linearmente indipendenti Dati due insiemi di vettori S e L, con S che spanna nello spazio V e L di vettori in V che siano tutte linearmente indimendenti, allora $|S| \\geq |L|$","title":"Algebra astratta"},{"content":"Ripasso Prox: 40 Ripasso: May 30, 2023 Ultima modifica: June 9, 2023 2:56 PM Primo Abbozzo: December 10, 2022 11:39 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Elementi di computabilitÃ  https://virtuale.unibo.it/pluginfile.php/1295166/mod_resource/content/0/Lez18-Gorrieri.pdf\nHalting problem Questo asserisce che non esiste nessun programma che sia in grado di decidere la terminazione di un altro programma\nQuesto Ã¨ un problema che ci Ã¨ interessante perchÃ© vorremmo costruire un compilatore che sia in grado di osservare tutti gli errori possibili del programma. Come vedremo tra poco la risposta sarÃ  negativa.\nDimostrazione tesi ðŸŸ¨++ Supponiamo che questo programma esista, lo chiamiamo check(P) che restituisce 0 se termina 1 se non termina, allora devo poter essere in grado di scrivere un programma di questo genere\nprocess ABSURD(x): if (check(ABSURD(x))): return 0; else: while (true); endprocess Allora se il processo ABSURD con x in input termina, si avrÃ  che non termina e vale anche il contrario. E questo Ã¨ un chiarissimo assurdo. In questo modo troviamo una funzione non calcolabile ed Ã¨ stato uno dei primi episodi storici di non calcolabilitÃ  (Turing 1936) in quello storico paper.\nNOTA: questa sezione non Ã¨ molto formale, Ã¨ utile perÃ² per dare lâ€™intuizione, per andare in modo formale Ã¨ bene andare a guardarsi le slide del prof (câ€™Ã¨ un errore di input di funzioni).\nNon calcolabilitÃ  dellâ€™eguaglianza ðŸŸ¥+ Si puÃ² dimostrare che non esiste un programma che decida se due programmi calcolano la stessa cosa, altrimenti ci potremmo ricondurre a un caso molto simile a quello di sopra.\nDimostrazione\nSe esistesse tale funzione, potrei costruire la funzione che decide se quanto calcolato Ã¨ uguale alla funzione costante 0. Se ho questa funzione allora posso costruire una funzione\nF(P) che prende in input una funzione e un dato, e calcola 0 se converge, e diverge con essa se diverge. Con questa funzione posso costruire la funzione check perchÃ© se converge posso dire con sicurezza che Ã¨ 1, e se diverge posso dire che Ã¨ 0\nCostruzioni del prof. (3) ðŸŸ¨++ Assurdo che esista un programma che mi dica se un programma si stoppi o meno\nQuesta sezione Ã¨ utile se vuoi ripetere quello che dice il prof.\n$$ H(P,x) = \\begin{cases} 1\\, P(x)\\downarrow \\\\ 0 \\, P(x) \\uparrow \\end{cases} $$ $$ K(P) = H(P,P) $$ $$ G(P) = \\begin{cases} 1\\, K(P) = 0 \\\\ \\uparrow, K(P) = 1 \\end{cases} $$ Ma se proviamo a calcolare $G(G)$ vediamo che se $G(G)$, che Ã¨ quello che va a calcolare K, termina, allora non terminerÃ , per come ho costruito G, se non terminerÃ  allora termina per come ho costruito G.\nNessun programma mi puÃ² dire se una funzione calcola una costante o meno ðŸŸ¥\n$$ Z(P) = \\begin{cases} 1, \\forall x, P(x) = 0 \\\\ 0, \\exists x, P(x) \\neq 0 \\end{cases} \\\\ F(P,x) = \\begin{cases} 0, P(x) \\downarrow \\\\ \\uparrow, P(x) \\uparrow \\end{cases} $$ Si noti che entrambe le funzioni di sopra sono calcolabili, allora se vale questo vale che\n$$ K(P) = H(P, P) = Z(F(P,P)) $$ Il trucco non sta altro che sfruttare il fatto che Z termina lo stesso anche se una funzione puÃ² divergere talvolta, senza restituire qualcosa (allora so che non darÃ  mai la costante), ma se funzione normalmente fa sempre 0.\nNessun programma puÃ² dire che due programmi sono equivalenti\n$$ Equiv(P, Q) = \\begin{cases} 1, \\forall x, P(x) = Q(x) \\vee P(x) = \\uparrow = Q(x) \\\\ 0, \\text{altrimenti} \\end{cases} \\\\ Z(P) = Equiv(P, zero) $$ E quindi avrei una funzione che calcoli se una funzione Ã¨ 0.\nDecidibilitÃ  Vedere La macchina di Turing#Problemi di decisione per definizione piÃ¹ adatta e corrente.\nIntroduzione ðŸŸ¨+ DecidibilitÃ  (2)\nDati certi input, devo rispondere con 1 o 0 in tempo finito, questo Ã¨ lâ€™unico output che posso dare. Un esempio di problema di decidibilitÃ  Ã¨ dire se appartiene o meno a un certo insieme.\nUn problema che non Ã¨ decidibile Ã¨ indecidibile.\nSemidecibilitÃ \nQuando in tempo finito riesce a dirmi 1, ma per dire 0 diverge. Un esempio di programma con questa proprietÃ  Ã¨ la funzione check che stavamo sviluppando prima, che dice 1 se converge e 0 se non converge.\nNotare che il caso contrario, quello che per 1 diverge, e per 0 converge, non Ã¨ semidecidibile (il problema della divergenza non Ã¨ semidecidibile).\nEsempi di problemi indecibili ! (5) Se la funzione calcola una costante Se la funzione termina Se la funzione diverge (il suo contrario) Se due programmi sono equivalenti Se esistono errori run-time del programma La macchina di turing Introduzione (6) ðŸŸ© Una macchina di turing puÃ² essere determinata da 6 variabili.\nStati\nAlfabeto in input\nAlfabeto del nastro infinito\nStato iniziale\nstato finale\nFUnzione di stransizione da (stato, simbolo nastro) â†’ (stato, simbolo nastro, spostamento sinistra/destra)\nSlide\nIn modo analogo a quanto fatto in precedenza possiamo andare a definire un alfabeto riconosciuto dalla macchina di turing.\nCalcolabilitÃ  secondo Turing ðŸŸ¨+ Definizione di calcolabilitÃ \nMolto easy, Calcolabile secondo turing se esiste una macchina di turing (quindi definita da quelle 6 cose) che calcola quella funzione\nSlide\nOsservazioni\nSi puÃ² notare che il numero che le funzioni che sono turing calcolabili sono solamente numerabili quindi câ€™Ã¨ una stragrande maggioranza delle funzioni che non possiamo nemmeno andare a calcolare!\nJacopini-BÃ¶hn e lâ€™equivalenza ðŸŸ© Si puÃ² dimostrare che molti formalismi sono turing-completi ossia sono in grado di calcolare esattamente le stesse funzioni della macchina di turing. (basta che il programma abbia tutta la memoria di cui necessita).\nIl teorema di JB ci dice che se un linguaggio di programmazione possiede\nIf-then-else While statements e assegnamento â†’ Turing completo.\nCome conseguenza di questo teorema ci fu, storicamente parlando, uno sviluppo della programmazione strutturata, in cui andiamo solamente a guardare i parametri locali per decidere e capire cosa faccia la funzione.\nTesi di church turing Vedere La macchina di Turing#Tesi di Church-Turing\nSe una funzione puÃ² essere calcolata algoritmicamente in un qualche formalismo allora Ã¨ calcolabile con il formalismo della macchina di turing\nQuesto non Ã¨ un teorema Ã¨ solamente una tesi che Ã¨ riuscita a resistere al tempo, che da grande valore al significato della macchina di turing.\nLa nota informale di questa tesi che non permette ancora un attacco matematico-formale Ã¨ che\nil concetto di algoritmo non Ã¨ ancora stato ben formalizzato, e non si puÃ² applicare per tutti i formalsimo Questa cosa deve essere vera per ogni formalismo, ma come formalizzare il formalismo stesso e poter parlare subito per tutti i formalismi? Note finali (modulo 1) Comparazione fra le macchine ðŸŸ¥ Slide comparazione\nAbbiamo visto che\nMacchina di turing Ã¨ la piÃ¹ generale, utilizza grmamatiche generali (quindi senza vincoli) e calcola cose semidecibili\nPDA, libera, calcola cose decidibili, anche se non sono in grado di dire cose riguardanti ugualgianza boh.\nDFA puÃ² essere utilizzata per modellizzare tante cose come\nVending machine Circuiti logici Find/replace principalmente Ã¨ tutto decibile per questo qua.\n","permalink":"https://flecart.github.io/notes/fondamenti-teorica/","summary":"Ripasso Prox: 40 Ripasso: May 30, 2023 Ultima modifica: June 9, 2023 2:56 PM Primo Abbozzo: December 10, 2022 11:39 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Elementi di computabilitÃ  https://virtuale.unibo.it/pluginfile.php/1295166/mod_resource/content/0/Lez18-Gorrieri.pdf\nHalting problem Questo asserisce che non esiste nessun programma che sia in grado di decidere la terminazione di un altro programma\nQuesto Ã¨ un problema che ci Ã¨ interessante perchÃ© vorremmo costruire un compilatore che sia in grado di osservare tutti gli errori possibili del programma.","title":"Fondamenti teorica"},{"content":"Ripasso: May 14, 2023 Ultima modifica: May 6, 2023 6:25 PM Primo Abbozzo: March 20, 2023 3:16 PM Studi Personali: No\nElementi di ripasso Javascript Obiettivo principale Ã¨ esegurie codice clientside\nUn pÃ² di storia nato allâ€™inizio della prima guerra dei browser (da netscape, explorer Ã¨ in visual basic comunque non compatibile con JS) come il fratellino di java nel senso che runnava ovunque, attualmente Ã¨ ECMAScript, ed Ã¨ la versione migliore. (era pensato per fare microscript!)\nECMAScript quando Ã¨ nato Ã¨ il nucleo a tutte le implementazioni JS eseistenti fino a quel momento (che Ã¨ stato molto caotico!)\nAnche lâ€™unico linguaggio che va sul browser. Typescript sarebbe molto carino ðŸ˜€.\nEsecuzione di JS Client side o Server-side Possiamo eseguire server-side (node) per eseguire codice JS in server side, anche se non ho piÃ¹ questa integrazione con il client (come eventi, e simili).\nOssia lâ€™evento triggera il codice JS corrispondente!\nEsecuzione sincrona o asincrona\nSincrona = caricamento dello script (quando carica, il browser non fa altro! Ãˆ una cosa sincrona, quindi non carica altro HTML e simili).\nAsincrono su eventi DOM o callback di eventi di rete. (esempio chiamata AJAX asincrona, mentre la chiama sincrona Ã¨ molto brutto perchÃ© il server Ã¨ bloccatooo)\nBrevi e veloci per i sincroni! No n2.\nPosizionamento del codice (3) Si puÃ² posizionare inline come il codice css Esempio 1.\nSezione script allâ€™inizio, come style di css Esempio 2.\nFile separato Esempio 3.\nQuesti sono i metodi principali, solitamente si preferisce il terzo metodo per migliore gestione degli script.\nma col terzo metodo si deve fare molta attenzione sul tempo di caricamento dlelo script (che Ã¨ sincrona!)\nCose del linguaggio Cose come oggetti, arrays, somme, comparazioni, JSON, Dati, li hai fatti troppo dai.\nQuesto Ã¨ tutto ecmascript, mentre se andiamo ad interagire con il browser abbiamo altri metodi!.\nInterpolazione (!!) Se esiste una variabile visibile nello scope attuale, allora lo sostituisco nella stringa. Principalmente questo. Per la prima volta l\u0026rsquo;oggetto della computazione sono frammenti di HTML, questo permette di dividere html e JS (anche se non ho capito bene come).\nIIFE ! Queste sono funzioni dichiarate e subito eseguite, sono utili per avere delle variabili private. (con solamente gli oggetti infatti non Ã¨ possibile definire tali variabili.\nClient defined classes Un sacco di robe, non ha senso scriverle, quindi le enumero in modo molto breve qui\nWindow In pratica Ã¨ il tab della pagina di questo istante (sia in lettura sia in scrittura), contiene in sÃ© il documento.\nDocument Sono la rappresentazione in memoria del documento che Ã¨ mostrato (quindi ci sono tutti i nodi che ci importano!\nAjax PROBLEMA: Ogni volta in cui devo cambiare elemento dell\u0026rsquo;interfaccia, non posso fare altro che duplicare la pagina, ossia fare una piena richiesta HTTP con le modifiche, infatti Ã¨ grande cambio di informazioni, nel senso che non mi servirebbe.\nIntroduzione Ajax Slide introduzione La cosa carina che significa anche AIACE ðŸ˜€, ma non câ€™entra niente.\nLâ€™obiettivo Ã¨ caricamenti asincroni per frammenti XML con questo aggiorno la pagina HTML, invece di cambiare da un altro URL.\nOggi XML Ã¨ considerato troppo verboso, in veritÃ  andiamo a scambiare frammenti JSON di cui abbiamo parlato in Alcuni linguaggi di Markup (non impo) ðŸŸ¥+, e sempre in Javascript.\nOra il formato Ã¨ tipo:\ncarico HTML molto vuoto carico applicazione JS anche complessa Lâ€™applicazione fa richieste e popola la pagina in modo attivo Utente fa altra attivitÃ , triggera altre richieste, la pagina cambia. Ecco lâ€™interattivitÃ !\nSlide AJAX\nConfronto architettura scambi HTML e AJAX\nQuando faccio la richiesta, il browser Ã¨ bloccato, poi quando il server finisce il browser riceve tutto, butta via vecchio e comincia a fare le cose nuove. (continuo stop and go)\nNota: browser non si blocca per l\u0026rsquo;utente (script sono molto veloci che non sembra bloccarsi!)\nUn esempio di applicazione AJAX Ã¨ maps.google.com, perchÃ© inizia a caricare secondo attivitÃ  dellâ€™utente, le piastrelle a un certo livello i zoom ðŸ™‚\nStruttura processo ajax (4) Slide processo applicazione Ajax\nCreazione della richiesta\nOn Ready state change chiama la funzione ogni volta che cambia lo stato (che abbiamo detto possono essere 5 valori.\nse Ã¨ 4 la richiesta Ã¨ tornata ed Ã¨ stata elaborata â†’completata:D\nInvio della richiesta (DIFFERENZA POST E GET!!!!)\nGestione della risposta\nVantaggi svantaggi AJAX Importantissimo per AJAX e js!\nNavigazione della pagina non Ã¨ sincronizzato con lo scambio di dati! mentre prima sÃ¬\nSlide vantaggi AJAX\nUsabile, interattiva, senza tempi morti Molto piÃ¹ veloce, per minore numero di pacchetti mandati Chiunque lo implementa :D Slide svantaggi AJAX\nDevo aggiungere step di navigazione di history fittizi per poter andare avanti indietro nella storia! (non lo fa il browser ma lo fa la mia applicazione) si chiama routing Ajax Ã¨ inerentemente non lineare perchÃ© posso cambiare contenuto ovunque, anche mentre il mio sintetizzatore sta leggendo la pagina (per accessibilitÃ  invece serve la linearitÃ ). Lâ€™implementazione puÃ² cambiare da browser a browser, qualcosa potrebbe essere rotto qui e non in un altro browser. Framework Ajax XMLHTTPRequest\nÃˆ la libreria per Ajax, ma Ã¨ molto molto macchinosa! Per questo motivo utiliziamo altro, come JQuery che vedremo dopo.\njQuery\nÃˆ un framework che Ã¨ nato per semplificare tutta la parte macchinosa dellâ€™applicazione AJAX, oggi non Ã¨ piÃ¹ utilizzato perchÃ© le funzionalitÃ  sono giÃ  direttamente presenti sul browser. Ãˆ piÃ¹ per mantenere codice vecchio. Ce ne sarebbero altre ma non le ha descritte\n","permalink":"https://flecart.github.io/notes/javascript/","summary":"Ripasso: May 14, 2023 Ultima modifica: May 6, 2023 6:25 PM Primo Abbozzo: March 20, 2023 3:16 PM Studi Personali: No\nElementi di ripasso Javascript Obiettivo principale Ã¨ esegurie codice clientside\nUn pÃ² di storia nato allâ€™inizio della prima guerra dei browser (da netscape, explorer Ã¨ in visual basic comunque non compatibile con JS) come il fratellino di java nel senso che runnava ovunque, attualmente Ã¨ ECMAScript, ed Ã¨ la versione migliore.","title":"Javascript"},{"content":"Ripasso Prox: 80 Ripasso: June 3, 2023 Ultima modifica: June 4, 2023 3:20 PM Primo Abbozzo: September 23, 2022 1:08 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Domande\nInterpreti\nQuali sono i passi principali del ciclo FDE e cosa fa lâ€™interprete (ciclo FDE)\nImplementazione linguaggio via microprogrammazione o software\nRealizzazione dellâ€™interprete e del compilatore ðŸŸ¥\nMacchine Astratte Definizione ed esempi per macchine astratte ðŸŸ© Una macchina astratta Ã¨ un qualunque insieme di algoritmi e strutture di dati che permettono di memorizzare ed eseguire il linguaggio $L$, quindi una macchina astratta esiste per esguire il proprio linguaggio (inteso come insieme finito di istruzioni primitive che riesce ad comprendere e eseguire).\nSi puÃ² proprio dire che esiste una simbiosi fra macchina e linguaggio. Si potrebbe dire che la macchina fisica Ã¨ soltanto una implementazione FISICA di un linguaggio, ossia una macchina che capisce ed esegue quel linguaggio e che sia solamente un caso particolare della macchina astratta.\nQuesta macchina astratta Ã¨ costituita da una memoria e un interprete.\nCome si potrebbe intuire una singola macchina ha un singolo linguaggio ma un linguaggio puÃ² avere infinite macchine che differiscono per strutture di dati utilizzate nellâ€™implementazione!\nMacchina di von Neumann (esempio)\nUna delle prime macchine astratte, in questo caso molto semplice, con un unico bus centrale, e tante cose di mezzo.\nLinguaggio macchina Una macchina fisica Ã¨ la realizzazione â€œa filiâ€ di un particolare algoritmo che, sfruttando alcune strutture dati, Ã¨ capace di â€œeseguireâ€ programmi scritti in un certo linguaggio, detto il linguaggio macchina\nIn pratica Ã¨ una implementazione ad hardware, come si vedrÃ  dopo.\nPossiamo dire che il linguaggio di una certa macchina astratta Ã¨ il linguaggio compreso da quella macchina!\nInterpreti e compilatori Interprete ðŸŸ© Lâ€™interprete per un linguaggio mantiene la SEMANTICA!\nEsempio di interprete per macchina fisica\nciclo FDE, vedi 3.1.3 Central Control Unit , Ã¨ lâ€™interprete della macchina hardware, ossia\nDecodifica lâ€™istruzione che deve andare ad eseguire Esegue quanto deve eseguire (in questo caso recupera gli operandi, esegue e stora). In generale possiamo astrarre questo ciclo FDE fisico utilizzando questi passaggi un poco piÃ¹ astratti\nElaborazione dei dati primitivi (primitivi = che riesce a rappresentare direttamente in memoria) (es ALU che elabora bits, dato primitivo della macchina fisica) Controllo sequenza delle operazioni (es. salti, sposta PC in macchina fisica, chiamate di funzione) Controllo trasferimento di dati (es copia, move, copia bits fra registri (nella macchina fisica registri come MDR e MAR). Gestione della memoria (es pointers, allocazione, ma anche cache fra CPU e simili, rilocazione degli indirizzi e bla bla bla) Esempio MA dellâ€™hardware\nHa un set istruzioni RISC o CISC eseguibili direttamente dalla parte elettronica\nUna osservazione principale da cui deriva dal concetto di macchina astratta Ã¨ il concetto di gerarchizzazione fra le macchine astratte. Un primo esempio Ã¨ la microprogrammazione\nSlide interpretativa pura\nCompilatore ðŸŸ© Slide compilativa pura\nVantaggi e svantaggi Inteprete-compilatore ðŸŸ©- Vantaggi interpretazione\nImplementazione: Di facile realizzazione rispetto-compilatore Memoria: risparmio in quanto non ho un nuovo programma da memorizzare FlessibilitÃ : facile cambiare comportamento in esecuzione (eg. per debugging) (mentre compilatore perde anche dati di debug, come la struttura dellâ€™informazione) Svantaggi interpretazione\nLentezza, dato che legge ed esegue insieme\nIn breve\nImplementazione Compilativa-interpretativa ðŸŸ© Se l\u0026rsquo;interprete della macchina intermedia Ã¨ sostanzialmente diverso dall\u0026rsquo;in- terprete di $Mo_{Lo}$, diremo che siamo in presenza di un\u0026rsquo;implementazione di tipo interpretativo. Se l\u0026rsquo;interprete della macchina intermedia Ã¨ sostanzialmente uguale all\u0026rsquo; in- terprete di $Mo_{Lo}$ (di cui estende alcune funzionalitÃ ), diremo che siamo in presenza di un\u0026rsquo;implementazione di tipo compilativo. In generale non si utilizza mai una implementazione di tipo interpretativo pura o pura compilativa.\nNella realtÃ  ðŸŸ© Non vengono mai utilizzate soluzioni compilative o interpretative pure, ma si utilizzano sempre cose miste (ad esempio per chiamate input e output si utilizzano chiamate a sistema operativo, che sono solitamente interpretate).\nLa compilazione di solito si utilizza per linguaggi molto simili (Ã¨ questa la difficoltÃ  maggiore per la costruzione di un compilatore), e ci sono alcuni passi che sono simulati (quindi non compilativa pura).\nMentre l\u0026rsquo;interpretazione Ã¨ molto piÃ¹ facile da scrivere (perchÃ© di solito ho subito molte funzionalitÃ  del linguaggio attuale), e capita spesso che il codice iniziale venga compilato in un linguaggio intermedio che sia interpretabile.\nNel pratico esistono linguaggi piÃ¹ interpretati che compilati e anche il contrario, oppure entrambi (esempio pascal).\nSchema di compilazione intermedia classico\nA seconda di quanto il linguaggio della macchina intermedia si avvicini al linguaggio sorgente o macchina possiamo definire le sfumature di linguaggio interpretato o compilato. vedi 20pg libro. (1.2.3)\nImplementazione via Kernel ðŸŸ¨- Facciamo solamente degli accenni a come si fa a creare compilatori o interpretatori\nSi implementa un linguaggio intermedio, il cui compilatore o interprete Ã¨ molto facile da fare $H$.\nPoi si costruiranno compilatori o interpreti che avranno come target questo linguaggio, quindi questo linguaggio sembra un linguaggio intermedio quasi.\nSlides\nBoostrapping ðŸŸ¨+ Implementazione delle macchine astratte Esistono 3 modi principali per realizzare lâ€™implementazione di una macchina astratta:\nImplementazione tramite Hardware Emulazione tramite micro-programmazione (firmware) Interpretazione tramite Software Hardware ðŸŸ© L\u0026rsquo;implementazione hardware Ã¨ spesso\npoco flessibile, dato che capisce solamente questo linguaggio.\nMolto veloce, dato che esegue a livello hardware le sue istruzioni.\nNota influenza linguaggio astratto in linguaggio hardware\nCiÃ² non toglie che vi siano molti casi in cui la struttura della macchina astratta di un linguaggio di alto livello ha influenzato la realizzazÃ¬one di unâ€¢architettura hardware, non nel senso di una diretta realizzazione in hardware della macchina astratta, ma nella scelta di operazioni primitive e strutture dati che permettessero una piÃ¹ semplice e efficiente realizzazione dell\u0026rsquo;interprete del linguaggio di alto livello. Questo Ã¨ il caso, ad esempio, dell\u0026rsquo;architettura del B5500, un computer degli anni \u0026lsquo;60, influenzata dalla struttura del linguaggio ALGOL.\nMicroprogrammazione ðŸŸ©- PuÃ² essere (soprattutto nelle macchine NON-risc) in cui alcune istruzioni non sono esattamente eseguibili dallâ€™hardware, ma lâ€™interprete decodifica lâ€™istruzione in piÃ¹ istruzioni al livello inferiore, ora queste istruzioni sono eseguibili.\nLâ€™interprete del linguaggio di questo livello Ã¨ solitamente scritto in un linguaggio di livello inferiore. Di solito la microprogrammazione Ã¨ fatta a livello firmware. Questa microprogrammazione Ã¨ spesso depositata in una zona di memoria adibita alla sola lettura (ROM).\nCiÃ² permette una flessibilitÃ  maggiore rispetto allâ€™implementazione a livello hardware, e tiene una velocitÃ  maggiore rispetto allâ€™implementazione tramite software (perÃ² resta sempre un linguaggio a basso livello vicino alla macchina).\nMotivo storico della microprogrammazione\nMacchina ospite - software ðŸŸ© Ãˆ possibile implementare tramite software una macchina astratta su una macchina ospite. Ossia una macchina che appunto ospita una macchina astratta con un proprio linguaggio. Solitamente questa macchina con questo linguaggio compila in un linguaggio della macchina ospite, in modo che sia eseguibile. Ecco che da qui si puÃ² vedere una gerarchizzazione.\nmacchina con Linguaggio di alto livello â†’ macchina di altro livello â†’ â€¦ â†’ macchina fisica che esegue.\nMoltissima flessibilitÃ \nVelocitÃ  leggermente minore\nLivello di interpretazione/traduzione in piÃ¹\nEsempio di astrazione solita\n","permalink":"https://flecart.github.io/notes/macchine-astratte/","summary":"Ripasso Prox: 80 Ripasso: June 3, 2023 Ultima modifica: June 4, 2023 3:20 PM Primo Abbozzo: September 23, 2022 1:08 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Domande\nInterpreti\nQuali sono i passi principali del ciclo FDE e cosa fa lâ€™interprete (ciclo FDE)\nImplementazione linguaggio via microprogrammazione o software\nRealizzazione dellâ€™interprete e del compilatore ðŸŸ¥\nMacchine Astratte Definizione ed esempi per macchine astratte ðŸŸ© Una macchina astratta Ã¨ un qualunque insieme di algoritmi e strutture di dati che permettono di memorizzare ed eseguire il linguaggio $L$, quindi una macchina astratta esiste per esguire il proprio linguaggio (inteso come insieme finito di istruzioni primitive che riesce ad comprendere e eseguire).","title":"Macchine Astratte"},{"content":"Ripasso Prox: 75 Ripasso: June 16, 2022 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: November 4, 2021 3:59 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Vecchi dubbi InvertibilitÃ  e derivata dell\u0026rsquo;inversa Fare esercizi e provare derivate particolari. Dimostrazione della formula di mul e div per derivate 5 Derivate 5.1 Geometria introduttiva 5.1.1 Tangente e pendenza Si puÃ² trovare la relazione fra la pendenza della retta e la tangente.\nPossiamo analizzare la retta dal punto di vista analitico, della formula e si puÃ² dimostrare che data una retta nella forma $y = mx + q$ $m$ Ã¨ la pendenza della retta.\n5.1.2 Formula generale delle rette Dati qualunque due punti .$(x_1, y_1), (x_2, y_2)$ possiamo dire che la pendenza Ã¨ esprimibile come\n$\\dfrac{ (y_2 - y_1)}{(x_2 - x_1)}$, possiamo anche creare un fascio di rette che passa per un punto come\n$y - y_0 = m(x - x_0) + q$\n5.1.3 Intuizione tangente Per qualunque funzione, possiamo intuitivamente designare la derivata come se fosse il valore della retta tangente in quel punto al grafico.\n5.2 Definizione 5.2.1 Rapporto incrementale Data una funzione $f(x)$, si dice rapporto incrementale di $f$ in $x_0$ questo valore\n$$ \\dfrac{f(x) - f(x_0)}{x - x_0} $$ 5.2.2 DerivabilitÃ  Allora cerchiamo di minimizzare la distanza fra i due punti che scelgo, allora ho la derivata in questo punto!\n$$ \\exists\\lim_{x \\to x_0} \\dfrac{f(x) - f(x_0)}{x - x_0} \\in \\R = \\dfrac{df(x)}{dx} $$ E si puÃ² scrivere anche in una altra forma analoga: che Ã¨ piÃ¹ comoda da gestire perchÃ© ho qualcosa che tende a 0\n$$ \\exists\\lim_{h \\to 0} \\dfrac{f(x + h) - f(x)}{h} = \\dfrac{df(x)}{dx} $$ Se esiste questo limite, allora la funzione Ã¨ derivabile in quel punto.\nFunzione\nSi dice che una funzione Ã¨ derivabile se lo Ã¨ nel suo dominio.\n(Per gli estremi destri si considera solamente la derivabilitÃ  sinistra, in modo simile anche per gli estremi sinistri)\nSe esiste la derivata in questo punto allora si puÃ² dire che in questo punto esista una tangente geometrica\n5.2.3 DerivabilitÃ  destra e sinistra Si dice che una funzione $f$ Ã¨ derivabile a sinistra (in modo analogo a destra se\n$$ \\exists\\lim_{x \\to x_0^-} \\dfrac{f(x) - f(x_0)}{x - x_0} = \\dfrac{df(x)}{dx} $$ 5.2.4 Condizioni di derivabilitÃ  Dato che la derivata Ã¨ un limite, le condizioni di esistenza sono molto simili alle condizioni di esistenza di un limite. (no sono identtivi)\nSi puÃ² analizzare la derivabilitÃ  delle funzioni utilizzando queste condizioni es:\n$f(x) = |x|$ si scopre che non Ã¨ derivabile perchÃ© a sinistra Ã¨ -1 mentre a destra Ã¨ +1, si dice che Ã¨ un punto angoloso (si scopre che per qualunque punto angoloso, questa non Ã¨ piÃ¹ derivabile)\nBisogna fare perÃ² attenzione perchÃ© non Ã¨ vero che ogni valore assoluto non Ã¨ derivabile perchÃ© ad esempio $x|x|$ Ã¨ derivabile.\n5.3 ProprietÃ  e osservazioni 5.3.1 Proposizione della retta tangente Questa proprosizione collega il concetto di derivata e della tangente.\nSe $f$ Ã¨ derivabile in $x_0 \\in I \\implies \\exists \\text{retta tangente al grafico f in } x_0=x\\\\ \\text{si puÃ² dire che abbia equazione} \\\\ y = f'(x_0)(x - x_0) + f(x_0)$\n5.3.2 Derivate conosciute Derivate\n5.3.3 Algebra delle derivate Si possono utilizzare in modo simile l\u0026rsquo;algebra delle derivate\nEnunciato\nDerivazione qui\n5.3.4 Composizione di funzioni Enunciato\nDimostrazione [qui](https://www.math-linux.com/mathematics/derivative-of-a-function/article/chain-rule-proof-derivative-of-a-composite-function#:~:text=Derivative%20of%20composite%20function%20(g,%C3%97%20v\u0026rsquo;(x)%20.)\n5.3.5 ContinuitÃ  e derivabilitÃ  Si puÃ² dimostrare che se una funzione Ã¨ derivabile in un punto allora Ã¨ continua nel punto stesso.\nx punto di accumulazione\n$$ \\lim_{h \\to 0}\\dfrac{f(x+h) - f(x)}{h} = l \\iff \\lim_{h \\to 0}\\dfrac{1}{h}\\cdot(\\lim_{h \\to 0}f(x+h) - f(x)) = l\\\\ \\iff \\lim_{h \\to 0}f(x+h) = f(x) + l\\lim_{h \\to 0}h = f(x) $$ C\u0026rsquo;Ã¨ anche una cosa dimostrazione molto simile.\nDimostrazione del prof.\n5.3.6 Derivate di inverse Enunciato\n5.4 Derivate di ordine superiori Una funzione potrebbe essere derivabile piÃ¹ di una volta, allora si dice che si puÃ² derivare piÃ¹ volte.\nÃˆ interessante relazionare questo concetto di derivabilitÃ  con il concetto di continuitÃ \n5.4.1 ContinuitÃ  classe C Ãˆ come classificare una funzione in base la sua regolaritÃ , ossia rispetto a quante volte posso fare la derivata e la continutÃ  di classe C Ã¨ un buon modo di formalizzare questo dato.\nContinuitÃ  di classe C\n!\nSi puÃ² notare che una funzione puÃ² essere continua in $C^k$ ma non in $C^{k+1}$. zare questo dato.\nContinuitÃ  di classe C\n!\nSi puÃ² notare che una funzione puÃ² essere continua in $C^k$ ma non in $C^{k+1}$.\n","permalink":"https://flecart.github.io/notes/derivate/","summary":"Ripasso Prox: 75 Ripasso: June 16, 2022 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: November 4, 2021 3:59 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Vecchi dubbi InvertibilitÃ  e derivata dell\u0026rsquo;inversa Fare esercizi e provare derivate particolari. Dimostrazione della formula di mul e div per derivate 5 Derivate 5.1 Geometria introduttiva 5.1.1 Tangente e pendenza Si puÃ² trovare la relazione fra la pendenza della retta e la tangente.","title":"Derivate"},{"content":"Ripasso Prox: 3 Ripasso: May 20, 2022 Ultima modifica: May 19, 2022 12:48 PM Primo Abbozzo: May 3, 2022 11:31 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nRappresentazione e terminologia Operazioni importanti\nDefinizione di grafo Ãˆ un insieme di nodi e di archi. (prendili da insiemi corretti)\nMetodi di rappresentazione Liste di incidenza (In pratica numero tutti gli archi e storo il valore dell\u0026rsquo;arco incidente per ogni nodo)\nListe di adiacenza Classico usato per cp, si storano direttamente pointer a nodi di interesse\nMatrici di adiacenza Se esiste un arco fra due nodi, metto un uno in questa posizione (si puÃ² utilizzare una cosa simile per mantenere il peso di un arco)\nTermini importanti Cammino, cammino semplice, ciclo, ciclo semplice, fortemente e debolmetne connesso. grafo completo, aciclico\nCammino e cammino semplice Ciclo Componente debolmente connessa Grafo completo Grafo aciclico Algoritmi sui grafi Algoritmi di visita BFS DFS Ordinamento topologico Ãˆ una dfs ðŸ˜€Ã¨ utile poi per utilizzare\n`\nComponenti fortemente connesse Ãˆ una relazione di equivalentz la raggiungibilitÃ  (anche per grafi indiretti) e quindi per connessione debole\nSi puÃ² utilizzare l\u0026rsquo;algoritmo di Tarjan (credo si chiami cosi) per le SCC. si fa in m + n\nMinimum Spanning Tree Definizione di MST Un sottografo di un grafo che prenda tutti i vertici, tale per cui la somma del peso degli archi presi sia la minima possibile.\nTaglio di un grafo\nRegole per lâ€™intuizione della sol greedy\nda libro\nKruscal Si utilizza la union find,\nPrim Solo sulla frontiera, si espande usando la regola del taglio\nCammini minimi ProprietÃ  (sottostruttura e esistenza per connettivitÃ ) Se ho un cammino minimo, allora anche un suo sotto cammino a un sottonodo Ã¨ un cammino minimo Se ho un grafo connesso, allora esistono cammini minimi fra due nodi connessi Condizione di Bellman Questa Ã¨ una condizione sul valore della distanza fra i nodi dei grafi:\nSe ho $d_{xy} \\leq d_{xp} + w(p, y)$, ovvero la distanza fra due nodi, Ã¨ sempre minore o uguale alla distanza fra un nodo intermedio e l\u0026rsquo;arco fra questo nodo a y. Ãˆ uguale se Ã¨ il cammino minimo.\nDa questa osservazione di puÃ² definire una condizione di rilassamento di un arco. Gli algoritmi di rilassamento partono da una condizione grossolana, poi approssimano qualcosa sempre meglio, volta dopo volta.\nAlgoritmo di Bellman-ford Il pensiero per ricordarsi questo algoritmo Ã¨ questa osservazione:\nSuppongo di conoscere il cammino minimo da un vertice di partenza e un vertice di arrivo, allora sarebbe facile percorrerlo e conoscerne i costi. Noto che se provo a rilassare ogni singolo arco, allora dovrei aver almeno trovato il costo per il primo nodo del cammino. Continuo a fare cosÃ¬, con rilassamenti successivi finchÃ© non arrivo a uno stadio stabile.\nCerco di rilassare ogni arco finchÃ© qualcosa cambia, se cambia vuol dire che non ho ancora finito tutti i rilassamenti possibili.\nAlgoritmo\nNota:\nQuesto algoritmo Ã¨ buono perchÃ© trova il cammino minimo anche per archi negativi ðŸŒ \nAlgoritmo di Dijkstra Questo algoritmo funziona solamente nel caso in cui non ho archid i peso negativo.\nLemma fondamentale per comprendere Dijkstra\nAlgoritmo in pseudocodice generico\nAlgoritmo in pseudocodice con strutture di dati\nAlgoritmo di Floyd-Warshall Utilizziamo la programmazione dinamica per calcolare tutti i percorsi minimi.\nL\u0026rsquo;idea Ã¨ calcolare ad ogni step, una matrice di percorsi che passano per un certo specifico vertice.\nAlgoritmo in pseudocodice (si puÃ² ottimizzare lo spazio in questo)\n!\n","permalink":"https://flecart.github.io/notes/grafi/","summary":"Ripasso Prox: 3 Ripasso: May 20, 2022 Ultima modifica: May 19, 2022 12:48 PM Primo Abbozzo: May 3, 2022 11:31 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nRappresentazione e terminologia Operazioni importanti\nDefinizione di grafo Ãˆ un insieme di nodi e di archi. (prendili da insiemi corretti)\nMetodi di rappresentazione Liste di incidenza (In pratica numero tutti gli archi e storo il valore dell\u0026rsquo;arco incidente per ogni nodo)\nListe di adiacenza Classico usato per cp, si storano direttamente pointer a nodi di interesse","title":"Grafi"},{"content":"Metodi di registrazione informazione Ci stiamo chiedendo in che modo possiamo registrare attivitÃ  del cervello e quindi cercare di fare decoding delle informazioni presenti Prima parliamo di alcune tecniche non invasive che ci permettono di vedere alcune attivitÃ  presenti nel cervello.\nMetodi macroscopici Functional Magnetic Resonance Imaging Un metodo Ã¨ fMRI. (ci sono cose ) TODO capire come funziona\nElectro-Encephalo-Gram EEG che prende direttamente dai segnali Ma il drawback di entrambi Ã¨ che non registrano attivitÃ  del singolo array.\nMetodi a livello cellulare Electrode arrays Ci permette di registrare voltaggi di singoli neuroni (quindi capire se Ã¨ in spike o meno). Solitamente si mette il tessuto cellulare direttamente su questo strato di elettrodi.\nIn modo simile si puÃ² anche misurare la differenza di potenziale studiata in Campo elettrico, con una pipetta sonda, di solamente qualche micrometro di diametro, in modo da non danneggiare molto la membrana cellulare.\nCalcium Imaging Alcune cellule cambiano colore quando assorbono calcio, e si puÃ² utilizzare questo segnale visivo per capire se sta sparando o meno.\nNeural codes Consideriamo una serie di neuroni su un array di elettrodi a cui Ã¨ sottoposto a uno stimolo visivo. Utilizziamo un raster plot per capire il momento nel tempo in cui sparano, e otteniamo cosÃ¬ un diagramma delle attivazioni di un neurone.\nVogliamo utilizzare un sistema probabilistico per gestire tutto sto rumore di cosÃ¬ tanti neuroni. Una cosa tipo\nQuant\u0026rsquo;Ã¨ la probabilitÃ  che il neurone si attivi dopo questo stimolo? encoding (come viene memorizzato questo input). Quant\u0026rsquo;Ã¨ la probabilitÃ  che il neurone si attivi per questo stimolo? decoding (motivo per cui si Ã¨ attivato diciamo). Cosa interessante, se diamo rumore white a caso preso da una gaussiana, e poi prendiamo le risposte, queste risposte sono disposte in modo gaussiano. Questo sistema con il gaussiano ci permette di trovare la feature ossia le attivazioni precedenti, il pattern diciamo, che contribuisce all\u0026rsquo;attivazione del neurone corrente.\n","permalink":"https://flecart.github.io/notes/analysis-of-neural-codes/","summary":"Metodi di registrazione informazione Ci stiamo chiedendo in che modo possiamo registrare attivitÃ  del cervello e quindi cercare di fare decoding delle informazioni presenti Prima parliamo di alcune tecniche non invasive che ci permettono di vedere alcune attivitÃ  presenti nel cervello.\nMetodi macroscopici Functional Magnetic Resonance Imaging Un metodo Ã¨ fMRI. (ci sono cose ) TODO capire come funziona\nElectro-Encephalo-Gram EEG che prende direttamente dai segnali Ma il drawback di entrambi Ã¨ che non registrano attivitÃ  del singolo array.","title":"Analysis of Neural Codes"},{"content":"Introduction to design patterns Introduzione personale ðŸŸ© I design patterns sono simili a dei plug and play, ossia delle soluzioni che hanno funzionato bene in passato e che sono ora riutilizzati. Solitamente dovrebbe essere una abilitÃ  implicita, cioÃ¨ un buon programmatore Ã¨ in grado di fare senza pensarci, dovrebbe essere automatico. Infatti quando uno fa il design non lo fa esplitamente seguendo un certo modello, ma farlo solitamente risulta utile per guidare il processo.\nDefinizione design pattern ðŸŸ¨++ Descriptions of communicating objects and classes that are customized to solve a general design problem in a particular context\nA Pattern describes a problem which occurs over and over again in our environment, and then describes the core of the solution to that problem, in such a way that you can use this solution a million times over, without ever doing it the same way twice\nCommon OO patterns Singleton ðŸŸ© Questa la sai. Provi a ritornare un oggetto giÃ  inizializzato che vive per tutto il tempo del tuo programma. Ãˆ il singoletto, qualcosa che esiste solamente una volta. Un pattern solito con questo Ã¨ il check dell\u0026rsquo;esistenza del valore statico, e il getter di istanza.\nComposite ðŸŸ© In pratica Ã¨ un albero in cui solamente le foglie sono operazioni. Ã¨ stato utilizzato nelle slides per modellizzare un oggetto composto che deve semplicemente eseguire il codice dei figli (quindi diciamo un qualcosa di mezzo per poter dare in modo chiaro l\u0026rsquo;operazione corretta).\nIterator pattern ðŸŸ¨++ Viene utilizzato per scorrere qualcosa di generico, in C++ per esempio Ã¨ utilizzato in moltissime librerie standard. in Python Ã¨ possibile definire due metodi __next__ e __iter__ e anche in rust Ã¨ molto molto usato questo pattern.\nCreational PerchÃ© creational? (2) ðŸŸ©\u0026ndash; Sono i pattern utilizzati per creare nuovi oggetti in modo sostenibile.\nAstrarre la creazione del singolo oggetto Incapsulamento, quindi voglio limitare l\u0026rsquo;accesso a informazione a solamente certi metodi ben definiti. Builder ðŸŸ¨+ https://refactoring.guru/design-patterns/builder\nIn questo caso abbiamo un director che in pratica orchestra la costruzione dei componenti reali. E singole componenti in cui sono specificati esattamente cosa fare. Ãˆ utile soprattutto quando ho qualcosa di molto complesso da costruire, che puÃ² cambiare in molti modi. Un esempio Ã¨ il build di Zig credo.\nAbstract factory ðŸŸ©\u0026ndash; https://refactoring.guru/design-patterns/abstract-factory\nServe soprattutto come interfaccia comune per andare a creare qualcosa di concreto (nel nostro caso una factory concreta). Ricorda l\u0026rsquo;esempio di sedia, tavoli, e stili diversi! Avere l\u0026rsquo;abstract factory ti permette di utilizzare la stessa interfaccia, quando nel concreto puoi produrre cose diverse. (dal punto di vista del cliente Ã¨ sempre la stessa cosa).\nFactory Method ðŸŸ© https://refactoring.guru/design-patterns/factory-method\nDa un punto di vista intuitivo, questo Ã¨ solamente quando si utilizzano le classi virtuali. In C++ li abbiamo usati, vengono utili soprattutto quando la stessa funzione viene chiamata, la semantica Ã¨ uguale, ma l\u0026rsquo;implementazione cambia a seconda del tizio che la vuole usare tipo. Un esempio Ã¨ la funzione attacco dei mostri, che possono attaccare in molti modi, ma quello che vogliono fare Ã¨ attaccare.\nPrototype Structural Sono utilizzati come interfacce utili per far funzionare delle cose assieme.\nAdapter and Bridge Adapter viene utilizzato per problemi di nome, bridge per nascondere l\u0026rsquo;interfaccia Decorators Sono delle funzioni che ritornano altre funzioni con delle funzionalitÃ  aggiunte (e sono comode) se lo hai visto in python o JS lo conosci senza problemi. Per linguaggi statici tipo C Ã¨ piÃ¹ difficile da mettere.\nProxy pattern Invece di accedere qualcosa in modo diretto usiamo una altra classe od oggetto che si occupa di controllare l\u0026rsquo;accesso, un esempio guardare i permessi, controllare altro, fare log o simili\u0026hellip; Behavioural I patter comportamentali definiscono quali sono le classi di responsabilitÃ  per una classe e una altra, e gli algoritmi da utilizzare.\nVisitor Ãˆ tipo una visita dfs, bfs, prende informazioni in modo strutturato senza cambiarne la struttura. Strategy Ãˆ un pattern che specialmente per librerie di python si vede spessissimo, si utilizza un identificatore e un dispatcher all\u0026rsquo;algoritmo corretto. Chain of responsibility Ãˆ una suddivisione di classi di responsabilitÃ , come se fosse una catena di montaggio. Una cosa comune Ã¨ l\u0026rsquo;albero, e il responsabile diretto Ã¨ il suo parente, che magari deve gestire altro, non lo so. Se in un certo punto un check fallisce, la cosa non continua, ma viene cestinata.\nMediator Mi sembra simile alla reificazione che abbiamo studiato per la prima volta (in logica un po\u0026rsquo; ma di piÃ¹ in) Design del database. ossia invece di avere $N^{2}$ collegamenti, basta avere un punto intermedio di comunicazione e abbassi di una potenza. Ãˆ la potenza del mediatore.\n","permalink":"https://flecart.github.io/notes/design-patterns/","summary":"Introduction to design patterns Introduzione personale ðŸŸ© I design patterns sono simili a dei plug and play, ossia delle soluzioni che hanno funzionato bene in passato e che sono ora riutilizzati. Solitamente dovrebbe essere una abilitÃ  implicita, cioÃ¨ un buon programmatore Ã¨ in grado di fare senza pensarci, dovrebbe essere automatico. Infatti quando uno fa il design non lo fa esplitamente seguendo un certo modello, ma farlo solitamente risulta utile per guidare il processo.","title":"Design patterns"},{"content":"Entropy Questo Ã¨ stato creato da 1948 Shannon in (Shannon 1948). Questa nozione Ã¨ basata sulla nozione di probabilitÃ , perchÃ© le cose rare sono piÃ¹ informative rispetto a qualcosa che accade spesso. Kolmogorov complexity Ã¨ un modo diverso per definire la complessitÃ . Legato Ã¨ Neural Networks#Kullback-Leibler Divergence.\nWe can model the classical view of entropy as the from [^1]\nExpected value of Surprisal which is the uncertainty of a random variable $X$ taking a certain value which is $p(X = x) = P(x)$, but we want to measure it using log-likelihood.\n$$ H(\\cdot) = - \\sum p(x)\\log(p(x)) \\tag{1.1} $$ Ossia, possiamo dire in modo intuitivo quanto sarebbe sorprendente vedere che si avverasse quell\u0026rsquo;evento.\nOppure come descritto da [^2] $$ \\begin{align*} H(X) := E[I(X)] \u0026= \\sum_{i=1}^n P(x_i)I(x_i) \\\\ \u0026= \\sum_{i=1}^n p_i \\log(1/p_i) \\\\ \u0026= -\\sum_{i=1}^n p_i \\log(p_i) \\tag{1.2} \\end{align*} $$ Conditional Entropy $$ H(Y|X) = \\sum_{x \\in \\mathcal{X}}p(x) H(Y|X=x) = \\sum_{x \\in \\mathcal{X}, y \\in \\mathcal{Y}} p(x, y) \\log \\frac{1}{P(y|x)} = \\mathbf{E}\\left[ \\log\\frac{1}{p(Y|X)} \\right] $$ La nozione con il valore atteso Ã¨ la piÃ¹ semplice anche in questo caso.\nChain Rule Una proprietÃ  random Ã¨ $$ H(X, Y) = H(X) + H(X|Y) $$ La dimostrazione Ã¨ abbastanza banale una volta che si conoscono le definizioni\u0026hellip;. La cosa interessante Ã¨ che si puÃ² generale per qualunque numero di variabili aleatorie: $$ H(X_{0}, X_{1}, \\dots, X_{i}) = \\sum_{i}H(X_{i}|X_{i-1}\\dots X_{0}) $$ Upper bound $$ H(X) \\leq \\log \\lvert \\mathcal{X} \\rvert $$ Con $\\mathcal{X}$ l\u0026rsquo;insieme immagine della variabile aleatoria discreta $X$. Importante in questo caso che la nostra variabile sia discreta, altrimenti il teorema provvisto in (Cover \u0026amp; Thomas 2012) 2.6.4 non funziona. Non Ã¨ molto banale l\u0026rsquo;idea di utilizzare la uniforme per modellare il numero di elementi. e usare la positivitÃ  di KL per finire l\u0026rsquo;upper bound.\nEntropy is concave Uso l\u0026rsquo;upper bound e il fatto che KL Ã¨ convesso per dimostrare questa cosa.\nFunctional dependency Se $Y = f(X)$ per qualche funzione, allora $H(Y|X) = H(X|Y) = 0$ si puÃ² risolvere con qualche ragionamento sul supporto di entropia. Interessante vedere che ha una piccola relazione con Normalizzazione dei database#Dipendenze funzionali.\nRelative Entropy or Kullback-Leibler In modo praticamente equivalente possiamo definire una versione condizionata. e si puÃ² applicare anche in questo caso una chain rule $$ DL(P(x, y) \\mid\\mid Q(x, y) = DL(P(x) \\mid\\mid Q(x)) + DL(P(x|y) \\mid\\mid Q(x|y)) $$ KL is positive Ossia per ogni distribuzione $p$ o $q$ si ha che $$ DL(X \\mid\\mid Y) \\geq 0 $$ E ricordandoci che $\\log$ Ã¨ una funzione concava, quindi si puÃ² utilizzare Jensen.\nKL is convex $DL(p\\mid\\mid q)$ Ã¨ convesso sulla coppia $(p, q)$, 2.7.2 di (Cover \u0026amp; Thomas 2012).\nMutual information Questa nozione definisce quanta informazione hanno in comune due variabili aleatorie\nDefinizione $$ I(X;Y) = \\sum_{x}\\sum_{y} p(x, y) \\log\\left( \\frac{p(x, y)}{p(x)p(y)} \\right) = H(X) - H(X|Y) $$ Si puÃ² fare dopo un po\u0026rsquo; di calcoli che qui ho omesso, ma non dovrebbe essere difficile farlo.888\nSi puÃ² intendere la mutual information anche come KL fra le distribuzioni $p(x, y)$ e $p(x)p(y)$ si puÃ² notare che queste due sono uguali quando le due sono indipendenti, che Ã¨ coerente con la nostra nozione che abbiamo dell\u0026rsquo;indipendenza.\nProprietÃ  Sufficient Statistics Possiamo rappresentare il sampling da una certa famiglia di distribuzioni $f_{\\theta}(x)$ , rappresentato da $X$, e una sua statistica a caso (media varianza etc, che credo basti una funzione sul valore) come T, allora possiamo rappresentarlo come una Markov Chains#Catena di 3 variabili $\\theta \\to X \\to T(X)$ E vale il teorema di information processing\n$$ I(\\theta; T(X)) \\leq I(\\theta; X) $$ Si puÃ² chiamare una statistica per $\\theta$ sufficiente se $X$ contiene tutta l\u0026rsquo;informazione di $\\theta$. Non so bene cosa significhi. La cosa importante Ã¨ che la statistica sufficiente preserva la mutua informazione ossia si ha una uguaglianza in quella relazione di sopra. Vedere 2.9 di (Cover \u0026amp; Thomas 2012) per esempi .\nQuesta cosa potrebbe permettere di dire che usando quella statistica io posso dimenticarmi del parametro, perchÃ© riesco a ricavarmelo senza problemi credo\u0026hellip;.\nThe purpose of sufficiency is to demonstrate that statistics that satisfy this property do not discard information about the parameter, and as such, estimators that might be based on a sufficient statistic are in a sense \u0026ldquo;good\u0026rdquo; ones to choose.\nDa https://math.stackexchange.com/questions/1186645/understanding-sufficient-statistic.\nFano\u0026rsquo;s inequality L\u0026quot;idea principale Ã¨ utilizzare una variabile aleatoria per stimarne una altra, usando l\u0026rsquo;entropia condizionale fra le due.\nEnunciato fano Per ogni estimantore $\\hat{X}$ tale per cui $X \\to Y \\to \\hat{X}$ sia una catena di markov, e con $P_{e} = Pr(X \\not= \\hat{X})$ ossia la probabilitÃ  di errore, abbiamo che vale $$ H(P_{e}) + P_{e}\\log \\lvert \\mathcal{X} \\rvert \\geq H(X|\\hat{X}) \\geq H(X|Y) $$ Ci sono forme piÃ¹ deboli che possiamo considerare in un certo senso corollari, ossia che $$ 1 + P_{e} \\log \\lvert \\mathcal{X} \\rvert \\geq H(X|Y) $$ Dimostrazione Fano Questa Ã¨ una bomba da fare. Poi perÃ² ha un sacco di conseguenze non applicabili in modo immediato (cioÃ¨ non ci arrivi subito se non le fai un po\u0026rsquo; prima).\nMaximum Distribution entropy Un problema classico nella teoria dell\u0026rsquo;informazione Ã¨ trovare la distribuzione che massimizzi l\u0026rsquo;entropia (quindi l\u0026rsquo;informazione contenuta credo) dati certe conoscenze a priori, Ossia data una funzione $f$ e certe condizioni che deve rispettare, massimizzare l\u0026rsquo;entropia.\nSI puÃ² dimostrare (lo si puÃ² vedere da una reference di sopra) che la distribuzione che massimizza l\u0026rsquo;entropia, avendo solamente la condizione di probabilitÃ , ossia che $\\sum_{x}p(x) = 1$ Ã¨ la distribuzione uniforme. Mentre se assumo anche media $\\mu$ e varianza $\\sigma^{2}$ allora Ã¨ la gaussiana. In un certo senso possiamo dire che queste distribuzioni sono molto ricche di informazioni.\nCodewords Jensen\u0026rsquo;s Inequality Questo Ã¨ un teorema fondamentale per moltissime cose, e da un certo punto di vista Ã¨ una cosa banale per le cose convesse/concave. Allora, sia data una funzione in $[a, b]$ tale che sia convessa (concava) in questo intervallo, allora vale che $$ f\\left( \\sum_{i} \\lambda_{i} x_{i} \\right) \\leq \\sum_{i}\\lambda_{i}f(x_{i}) $$ Con $\\sum_{i}\\lambda_{i} = 1$. Questa cosa si estende in modo molto semplice a variabili aleatorie e $E$ quando al posto di $\\lambda_{i}$ mettiamo una probabilitÃ  in un punto.\nLa dimostrazione non dovrebbe essere molto difficile. La strategia Ã¨ utilizzare l\u0026rsquo;induzione in modo abbastanza classico. Non so in che modo si estende su funzioni continue, ma quelle sono cose tecniche matematiche non interessantissime.\nLog sum inequality Siano $a_{1}, a_{2}, \\dots a_{n}$ e $b_{1}, b_{2}, \\dots, b_{n}$ numeri non negativi, allora vale che $$ \\sum_{i=1}^{n}a_{i} \\log\\left( \\frac{a_{i}}{b_{i}} \\right) \\geq \\left( \\sum_{i=1}^{n}a_{i} \\right)\\log \\frac{\\left( \\sum_{i=1}^{n} a_{i} \\right)}{\\sum_{i=1}^{n}b_{i}} $$ Con uguaglianza se vale che $\\forall i, \\frac{a_{i}}{b_{i}}= const$\nKrafts Inequality https://en.wikipedia.org/wiki/Kraft%E2%80%93McMillan_inequality Questo teorema interessa cose dei codewords, perchÃ© ci interessano dei set di prefixfree che sono molto piÃ¹ gestibili probabilmente dal punto di vista dell\u0026rsquo;interpretazione. La cosa interessante Ã¨:\nSiano $l_{1}, l_{2}, l_{3}, \\dots, l_{n}$ lunghezze di code-words all\u0026rsquo;interno del nostro alfabeto, allora vale che esistono dei code-words (stringhe binarie) che hanno quelle lunghezze se e solo se viene soddisfatta la proprietÃ  $$ \\sum_{x} 2^{-l(x)} \\leq 1 $$ Il motivo Ã¨ abbastanza semplice, questo si spiega in modo grafico in maniera praticamente immediata quando facciamo il disegno. Si puÃ² vedere dall\u0026rsquo;albero binario corrispondente di un insieme di set binari con prefissi che se un parente Ã¨ scelto (colorato nel disegno), allora nessun discendente puÃ² essere scelto perchÃ© altrimenti avresti un prefisso. Inoltre se colori quelli sopra, significa che al massimo se sommi tutti quei valori otterrai 1 sse hai utilizzato tutti i rami a tua disposizione (meaning, che non puoi scegliere altri code-work, altrimenti perdi la prefix property). Relazione con Kolmogorov 1.11.3 di (Li \u0026amp; VitÃ¡nyi 2019), allora se prendiamo un set di code-words con $L$ il minimo prefix code che possiamo mai avere Ossia $L = \\sum_{x} P(x)l(x)$, con $l$ scelto il minimo possibile. Allora vale che $$ H(P) \\leq L \\leq H(P) + 1 $$ Ossia la lunghezza migliore possibile Ã¨ boundata da valori di entropia. Che Ã¨ una cosa abbastanza forte perchÃ© relaziona come deve essere fatto il code-words, con la complessitÃ  dell\u0026rsquo;informazione che vogliamo andare a utilizzare. La dimostrazione non la facciamo qui, ma Ã¨ fattibile con le tue conoscenze credo, ti serve la Gibbs inequality qui sotto per una freccia\nGibbs Inequality Afferma che l\u0026rsquo;entropia Ã¨ minore rispetto alla cross-entropy di qualunque cosa, ossia $$ \\sum_{x} P(x) \\log\\left( \\frac{1}{P(x)} \\right) \\leq \\sum_{x} P(x) \\log\\left( \\frac{1}{Q(x)} \\right) $$ Qualunque sia l\u0026rsquo;altra distribuzione. Si puÃ² dimostrare in modo abbastanza diretto utilizzando il fatto che la Kullback Leibler divergence, presentato in Neural Networks, Ã¨ sempre positiva o uguale a 0.\nReferences [1] Cover \u0026amp; Thomas â€œElements of Information Theoryâ€ John Wiley \u0026amp; Sons 2012\n[2] Shannon â€œA Mathematical Theory of Communicationâ€ The Bell System Technical Journal Vol. 27, pp. 379\u0026ndash;423, 623\u0026ndash;656 1948\n[3] Li \u0026amp; VitÃ¡nyi â€œAn Introduction to Kolmogorov Complexity and Its Applicationsâ€ Springer International Publishing 2019\n","permalink":"https://flecart.github.io/notes/entropy/","summary":"Entropy Questo Ã¨ stato creato da 1948 Shannon in (Shannon 1948). Questa nozione Ã¨ basata sulla nozione di probabilitÃ , perchÃ© le cose rare sono piÃ¹ informative rispetto a qualcosa che accade spesso. Kolmogorov complexity Ã¨ un modo diverso per definire la complessitÃ . Legato Ã¨ Neural Networks#Kullback-Leibler Divergence.\nWe can model the classical view of entropy as the from [^1]\nExpected value of Surprisal which is the uncertainty of a random variable $X$ taking a certain value which is $p(X = x) = P(x)$, but we want to measure it using log-likelihood.","title":"Entropy"},{"content":"Ripasso Prox: 50 Ripasso: May 27, 2022 Ultima modifica: April 25, 2022 9:17 PM Primo Abbozzo: February 21, 2022 4:24 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 0 Introduzione 0.1 Lâ€™algoritmo Vogliamo cercare di creare algoritmi, ovvero soluzioni a problemi computazionali che non dipendono dal linguaggio di programmazione.\n0.1.1 Definizione Procedura per risolvere un problema in un numero finito di passi (quindi un algoritmo deve finire)\n0.1.2 Origine della parola Il nome \u0026ldquo;algoritmo\u0026rdquo; deriva da un nome di un matematico persiano dell 800 d.c. Muhammad ibn Musa al-Khwarizmi, che latinizzato diventa algorithmi, quindi i latini hanno creato la parola!\nQuesto matematico aveva creato un trattato per studiare il sistema di numerazione arabico che sostituirÃ  quello romano, si chiama Algoritmi de numero Indorum, un sistema piÃ¹ efficiente rispetto al romano.\n0.1.3 Algoritmo vs programma Un algoritmo Ã¨ una cosa differente rispetto al programma, l\u0026rsquo;algoritmo Ã¨ piÃ¹ concentrato sul design (la descrizione dei passi ad alto livello, di solito in pseudo codice che non Ã¨ eseguibile) mentre il programma Ã¨ l\u0026rsquo;implementazione dell\u0026rsquo;algoritmo, che dipende strettamente da un linguaggio di programmazione (che potrebbero esserci aspetti noiosi di implementazione) e dai limiti finiti della macchina, come memoria.\n0.1.4 Esempio massimo comune divisore 0.2 Fibonacci Possiamo trovare molteplici soluzioni per trovare il numero di fibonacci.\n0.2.1 One-shot Esiste la formula matematica per calcolare il numero di fibonacci. Questa la risolve subito, ma ha il problema di avere problemi di precisione in quanto le radici e simili non sono salvati correttamente in memoria.\n0.2.2 Classico algoritmo ricorsivo Algoritmo\nQuesto approccio funziona ma Ã¨ dannatamente lento in quanto ha bisogno di tempo di tempo. (lineare di memoria)\nLa cosa brutta di questo algoritmo Ã¨ che non utilizza il fatto di stare calcolando stesse istanze di quelle. CioÃ¨ non sta riutilizzando calcoli giÃ  fatti\nGiustificazione della linearitÃ  della memoria\nPossiamo osservare da questa rappresentazione dell\u0026rsquo;albero di chiamate che al massimo posso chiamare questa funzione un numero n di volte. (percorso piÃ¹ lungo radice foglia)\nAnalisi temporale\nPer una analisi temporale corretta si cerca di prendere in considerazione alcune operazioni primitive dei computer dato che non possiamo tenere in conto l\u0026rsquo;istruzione codice macchina (che dipende dal compilatore e non funziona nemmeno tenere conto dei secondi che ci mette perchÃ© dipende dalla macchina) Quindi consideriamo solamente operazioni primitive che hanno bisogno di un tempo costante per esse eseguite.\nDimostrazione della relazione temporale\n0.2.3 Classico algoritmo iterativo Algoritmo\nAnalisi spaziale\nStiamo allocando un array lungo n, per cui si ha n item di spazio\nAnalisi temporale\nNel calcolo ha sbagliato a mettere un 3 davanti alla parentesi, dovrebbe essere 2 (ma resta lineare)\n0.2.4 Iterativo ottimizzato in memoria Una osservazione importante Ã¨ che non ci serve tenere in memoria l\u0026rsquo;intero array perchÃ© gli unici elementi che ci interessano sono i vecchi due elementi, quindi possiamo creare una formula iterativa che tenga conto di questo fatto e migliorare l\u0026rsquo;uso della memoria da lineare a costante.\nAlgoritmo\n0.2.5 Soluzione matriciale (mult non ottimizzato) Notiamo che fibonacci puÃ² essere espresso come una potenza della matrice $\\begin{bmatrix} 1 \u0026 1 \\\\ 1 \u0026 0 \\end{bmatrix}$.\nQuesto fatto si puÃ² dimostrare per induzione, una volta fatto possiamo andare ad implementare l\u0026rsquo;algoritmo nuovo. Questo algoritmo dopo una analisi ha stesse proprietÃ  dell\u0026rsquo;algoritmo precedente, perÃ² puÃ² essere migliorato il passo di moltiplicazione matriciale\nAlgoritmo e l\u0026rsquo;analisi di essa\n0.2.6 Matriciale ottimizzato Utilizzando l\u0026rsquo;osservazione accennata sopra, che velocizza la moltiplicazione matriciale di molto, portandolo da n a log n. in pratica l\u0026rsquo;idea Ã¨ cosÃ¬: devo raggiungere n partendo da 1, nella precedente aggiungo 1 finchÃ© non arrivo a n, qui invece moltiplico per sÃ© stessa finchÃ© non ci arrivo quindi faccio una cosa tipo: in pratica possiamo vederla cosÃ¬, guardiamo n in binario, se c\u0026rsquo;Ã¨ un 1 moltiplico per matrice base, se 0 moltiplico per sÃ© stessa. FarÃ² sempre un numero logaritmico di operazioni.\nAlgoritmo helper\nAlgoritmo finale\n0.2.7 Algoritmi a confronto In questa immagine sottostante riusciamo a osservare il grafico sull\u0026rsquo;efficienza dei vari algoritmi.\n0.2.8 Valore in input vs dimensione di input Alla fine sono la stessa cosa.\nSi puÃ² anche analizzare un input in termini di bit necessari per la rappresentazione dellâ€™oggetto. Dipende dallâ€™algoritmo alla fine (per gli algoritmi di crittografia Ã¨ molto piÃ¹ utile analizzare i bit dei numeri\nCosa che non centrano\n$$ f(n) \\in O(g(n)) := \\exists c \\in \\R|\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \\leq c \\\nf(n) \\in \\Omega(g(n)) := \\exists c \\in \\R|\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \\geq c \\ $$ $ f(n) \\in O(g(n)) := \\exists c \\in \\R|\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \\leq c \\\nf(n) \\in \\Omega(g(n)) := \\exists c \\in \\R|\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \\geq c \\ $$\n","permalink":"https://flecart.github.io/notes/introduzione-algoritmi/","summary":"Ripasso Prox: 50 Ripasso: May 27, 2022 Ultima modifica: April 25, 2022 9:17 PM Primo Abbozzo: February 21, 2022 4:24 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 0 Introduzione 0.1 Lâ€™algoritmo Vogliamo cercare di creare algoritmi, ovvero soluzioni a problemi computazionali che non dipendono dal linguaggio di programmazione.\n0.1.1 Definizione Procedura per risolvere un problema in un numero finito di passi (quindi un algoritmo deve finire)\n0.1.2 Origine della parola Il nome \u0026ldquo;algoritmo\u0026rdquo; deriva da un nome di un matematico persiano dell 800 d.","title":"Introduzione algoritmi"},{"content":"Introduzione alle catene di Markov La proprietÃ  di Markov Una sequenza di variabili aleatorie $X_{1}, X_{2}, X_{3}, \\dots$ gode della proprietÃ  di Markov se vale:\n$$ P(X_{n}| X_{n - 1}, X_{n - 2}, \\dots, X_{1}) = P(X_{n}|X_{n-1}) $$ Ossia posso scordarmi tutta la storia precedente, mi interessa solamente lo stato precedente per sapere la probabilitÃ  attuale.\nDa un punto di vista filosofico/fisico, ha senso perchÃ© mi sta dicendo che posso predire lo stato successivo se ho una conoscenza (completa, (lo dico io completo, originariamente non esiste)) del presente.\nLa catena di Markov Ãˆ una successione di variabili aleatorie che possiede la proprietÃ  di Markov. Solitamente lo rappresentiamo a grafi oppure tramite la matrice di transizione. A me piace piÃ¹ la versione a grafi\nCatena di 3 variabili Siano $X, Y, Z$ Ã¨ chiaro che se viene formata la Catena di Markov $X \\to Y \\to Z$ allora deve valere $$ p(x, y, z) = p(x)p(y|x)p(z|y) $$ Altra cosa Ã¨ che deve vare se e solo se $X, Z$ sono indipendenti, dato $Y$ ossia se vale $$ P(x, z|y) = P(x|y)P(z|y) $$ Che dovrebbe essere una conseguenza diretta della parte di sopra. Una altra osservazione Ã¨ che se vale quella catena, vale anche l\u0026rsquo;inversa, ossia $Z \\to Y \\to X$.\nData processing inequality Se abbiamo una catena di Markov $X \\to Y \\to Z$ allora vale che $$ I(X ; Y) \\geq I(X; Z) $$ PerchÃ© una parte di computazione Ã¨ possibile modellarlo con la catena di Markov. E mi sta dicendo che l\u0026rsquo;informazione comune all\u0026rsquo;input $X$ con l\u0026rsquo;output $Y$ o output $Z$ dopo seguente computazione viene sempre meno con piÃ¹ computazione, e anche che non aggiungo informazione con piÃ¹ computazione.\nDimostrazione\nDefinizioni Comuni RaggiungibilitÃ  Il nodo $j$ Ã¨ raggiungibile da un nodo $i$ se esiste un numero di passi $m$, tale per cui $$ P_{ij}^{m} \u003e 0 $$ Molto piÃ¹ facile vedere sta cosa se lo rappresentiamo come un comunissimo grafo.\nClasse di stati Sono un insieme di stati tutti raggiungibili fra di loro (comunque presi due stati all\u0026rsquo;interno della classe, esiste un percorso che parte da uno e finisce sull\u0026rsquo;altro per dire).\nRecurrent vs Transient Ãˆ recurrent se per ogni nodo, tutti i nodi raggiungibili da un nodo $i$ raggiungono anche il nodo $i$ stesso. Transient se non Ã¨ recurrent Alcuni chiamano la recurrent come irreducible come in (Cover \u0026amp; Thomas 2012).\nPeriodic vs Aperiodic Sia $d$ il massimo comune divisore per tutti gli $m$ tali per cui vale $P_{ii}^{m} \u003e 0$ (ossia puÃ² raggiungere sÃ© stesso con probabilitÃ  non nulla), allora Ã¨ periodico se $m \\neq 0$ altrimenti Ã¨ aperiodico.\nErgodic Markov Chain Una catena di markov si dice Ergodico se Ã¨ recurrent e aperiodico.\nPossiamo avere un teoremino carino su queste tipologie di catene, ed Ã¨ piÃ¹ o meno il motivo per cui si chiamano ergodiche, ossia che una particella che segue questa legge prima o poi va a visitare tutti gli stati una volta. Abbiamo come teorema: $$ P^{(M - 1)^{2} + 1}_{ij} \u003e 0 $$ Con $M$ il numero totale di stati, e $ij$ qualunque stato iniziale o finale. Dimostrazione Ã¨ un esercizio\nUnichain Una catena che continiene una singola classe recurrent piÃ¹ alcuni stati transienti\nChapman-Kolmogorov Equation Alla fine Ã¨ una relazione molto semplice, che deriva in modo facile dalle matrici di transizione, dice che Sia $P$ una matrice di transizione per un processo di Markov, allora $$ P^{n + m}_{ij} = \\sum_{k = 0}^{N} P_{ik}^{n} P_{kj}^{m} $$ Ossia posso moltiplicare matrici di transizione assieme per avere la probabilitÃ  di muovermi da uno stato $i$ a uno stato $j$ in $n + m$ passi.\nConvergenza Ha senso pensare che una catena di Markov converga nel proseguire delle transazioni.\nTeorema di convergenza per catene ergodiche Questo Ã¨ un teorema importante.\nConvergenza per unichains ergodiche. Con rewards Vogliamo associare a ogni stato $i$ un reward $r_{i}$ Si puÃ² creare allora una altra variabile aleatoria che prende la variabile aleatoria di Markov $X_{i}$ e lo mappa a un reward. Quello che ci interessano di piÃ¹ sono le expectation dei rewards.\nNoi vogliamo il valore\n$$ E[R(X_{n})| X_{0} = i] = \\sum_{j}r_{j}P_{ij}^{n} $$ E per la proprietÃ  di Markov credo sia la stessa cosa quando non parto da step 0.\nAggregate reward function Questo Ã¨ definito anche come value functionin Reinforcement Learning, a introduction.\n$v_{i}(n) = E[R(X_{m}) + \\dots + R(X_{m + n - 1}) | X_{m} = i]$\nSe la catena Ã¨ convergente, abbiamo che anche il value function Ã¨ convergente a un valore preciso, ed Ã¨:\n$$ g = \\sum \\pi_{j}r_{j} = \\vec{\\pi} \\cdot \\vec{r} $$ Indipendentemente allo stato iniziale (che stupisce molto).\nReferences [1] Cover \u0026amp; Thomas â€œElements of Information Theoryâ€ John Wiley \u0026amp; Sons 2012\n","permalink":"https://flecart.github.io/notes/markov-chains/","summary":"Introduzione alle catene di Markov La proprietÃ  di Markov Una sequenza di variabili aleatorie $X_{1}, X_{2}, X_{3}, \\dots$ gode della proprietÃ  di Markov se vale:\n$$ P(X_{n}| X_{n - 1}, X_{n - 2}, \\dots, X_{1}) = P(X_{n}|X_{n-1}) $$ Ossia posso scordarmi tutta la storia precedente, mi interessa solamente lo stato precedente per sapere la probabilitÃ  attuale.\nDa un punto di vista filosofico/fisico, ha senso perchÃ© mi sta dicendo che posso predire lo stato successivo se ho una conoscenza (completa, (lo dico io completo, originariamente non esiste)) del presente.","title":"Markov Chains"},{"content":"Ripasso Prox: 6 Ripasso: May 18, 2022 Ultima modifica: October 8, 2022 12:07 PM Primo Abbozzo: April 5, 2022 4:23 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso 074179\ngli utilizzi della matrice jacobiana Riguardarsi come la continuitÃ  finisce la dimostrazione di schwarz Rivedere i calcoli e l\u0026rsquo;idea principale per taylor al secondo ordine di coso. Massimi e Minimi multivariabile Matrice Jacobiana Ãˆ un modo per scrivere il gradiente di una funzione quando Ã¨ in una certa forma.\nData una funzione $f: \\R^n \\to \\R^p$\nossia per esempio $x=(x_1,...,x_n) \\to(f_1(x),...,f_p(x))$\nSe le p funzioni di arrivo sono differenziabili, allora la matrice jacobiana Ã¨ definita in questo modo:\n$$J_f(x) = \\begin{pmatrix} \\delta_{x_1} f_1(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{x_n} f_1(x)\\ . \u0026amp; . \u0026amp; . \\ \\delta_{x_1} f_p(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{x_n} f_p(x)\n\\end{pmatrix}$$\nUna matrice con p righe e n colonne, che rappresentano tutte le derivate parziali possibile\nOsservazione\nDa una funzione differenziabile f(r(x)) in modo simile a quanto fatto prima, abbiamo che\n$J_f(r(t)) J_r(t)$ Ã¨ uguale al prodotto scalare!\n$$ (\\delta_1f(r(t)), ..., \\delta_nf(r(t))) \\cdot \\begin{pmatrix} \\delta_{s} r_1(t) \\\\ . \\\\ \\delta_{s} r_n(t) \\end{pmatrix} $$ Ossia Ã¨ proprio $\\delta_t(f(r(t))$ il prodotto scalare, ossia $J_{f \\cdot r}(t)$ e la cosa bella Ã¨ che vale per dimensione qualsiasi. (vedere gli appunti lezione 11, ci dovrebbe essere l\u0026rsquo;enunciato di questo).\nComposizione di funzioni\nSi puÃ² dimostrare che la Jacobiana si comporta bene per le composizione di funzioni ossia:\nE questo vale per funzioni definite per qualunque dimensione.\n$$ J_{g \\cdot f}(v)= J_g(f(v)) J_f(v) $$ Studio del massimo e del minimo In piÃ¹ dimensioni non possiamo piÃ¹ applicare lo studio del segno della derivata come nella prima dimensione, in questo momento abbiamo piÃ¹ derivate, e non abbiamo nemmeno il concetto di funzione crescente. Vogliamo affidarci al concetto delle derivate seconde (concavitÃ  e convessitÃ )\nVedere che $f'(x) = 0 \\land f''(x)\u003e0$ oppure minore. Andremo a generalizzare questa idea.\nCondizione di stazionarietÃ  Andiamo a definire una condizione di stazionarietÃ  a piÃ¹ dimensione, che ci sarÃ  molto utile per trovare il minimo locale (o massimo locale).(Ã¨ anche chiamato fermat, come ti ricordi qui Teoremi Base Analisi)\nsia $f:A \\to \\R, \\bar{x} \\in A$ Ã¨ minimo locale, f Ã¨ differenziabile in xbar, allora si ha che $\\nabla f(\\bar{x}) = 0$\nQuando il gradiente si annulla, quel punto in cui si annulla si chiama punto critico o stazionario.\nLa stazionarietÃ  non permette di distinguere massimi e minimi (valeva anche per R dim 1 Punto di sella\nÃˆ la generalizzazione di un punto di flesso (in cui 2 derivata seconda si annullava).\nsia f una funzione ben definita differenziabile tale che il suo gradiente sia 0 in un punto a. Allora si dice che il punto a Ã¨ di sella se esistono due punti per ogni intorno di a, tali per cui f(x0) \u0026lt; f(a) \u0026lt; f(x1).\nIn pratica mi sta dicendo che comunque io mi avvicini a questo punto, riesco sempre a trovare un punto la cui immagine Ã¨ minore, e riesco sempre a trovare un punto la cui immagine Ã¨ maggiore.\nQuesto Ã¨ la terza possibilitÃ , nel caso questo punto stazionario non sia nÃ© massimo nÃ© minimo.\nNecessarietÃ  della differenziabilitÃ \nAffinchÃ© valga la condizione di stazionarietÃ  devono sempre esistere almeno le derivate parziali in OGNI direzione.\nQuesto Ã¨ utile per le considerazioni dell\u0026rsquo;inverso, in quanto per f(x) = |x| , nel punto 0 non Ã¨ differenziabile, ma Ã¨ un punto di minimo.\nDimostrazione\nSia f ben definita e a un punto di minimo locale, vogliamo dimostrare che ogni derivata parziale in questo punto sia 0. (ovvero che il gradiente sia 0).\nConsideriamo $g(t) = f(a + te_1)$, ovvero incrementato solamente nella direzione 1.\nPoichÃ© f ha minimo in a, ho che per t=0 ho un minimo locale di g (dato che g Ã¨ scritta in funzione di f).\nHo che la derivata di g Ã¨ la derivata parziale di f (per come Ã¨ definita), quindi g Ã¨ differenziabile poichÃ© per ipotesi f Ã¨ differenziabile. Per fermat, in quanto t=0 Ã¨ un punto di minimo, ho che la derivata di g in t = 0 Ã¨ 0, quindi applicando questa idea per ogni direzione ho che l\u0026rsquo;intero gradiente Ã¨ 0.\nDerivata seconda Possiamo derivare parzialmente in piÃ¹ direzioni\nDerivate seconde pure se derivo rispetto alla stessa variabile anche la seconda volta\nDerivate seconde miste se derivo rispetto a una variabile differente.\nMatrice Hessiana Questa matrice contiene tutte le derivate seconde possibili per una certa funzione da Rn a R (sarÃ  di dimensione n x n\n$$ Hf(x) = \\begin{pmatrix} \\delta_{11} f(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{1n} f(x)\\ . \u0026amp; . \u0026amp; . \\ \\delta_{n1} f(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{nn} f(x)\n\\end{pmatrix} $$\nTeorema di Schwarz Sia f una funzione ben definita, con dominio multidimensionale.\nSiano tutte le derivate seconde ben definite.\nAllora $\\forall ij \\in \\{1,..,n\\}, i \\neq j$ si ha che $\\delta_{ij}f = \\delta_{ji}f$, ossia Ã¨ un altro modo per dire che la matrice hessiana Ã¨ simmetrica.\nDimostrazione l\u0026rsquo;idea principale Ã¨ utilizzare qualcosa di simile alla differenziabilitÃ  per continuitÃ  e derivabilitÃ  parziale. Considero $g(h) = f(x + h, y+h) + f(x, y) - f(x + h,y) - f(x, y + h)$\npoi considero $u(t) = f(x + t, y+h) + f(x, y) - f(x + t,y) - f(x, y + h)$ e utilizzando lagrange due volte ottengo che $g(h) = \\delta_{xy}f(x + ah, y + bh)h^2$\nCome usare Lagrange due volte Noto che $u(h) = g(h)$ e che $u(0) = 0$. Per lagrange noto che $u(h) - u(0) = h\\cdot u'(\\theta_1 h)$ con theta da 0 a 1. Facendo la derivata prima di $u$ ottengo che Ã¨ uguale a $\\delta_x f(x + t, y+ h) - \\delta_x f(x + t, y)$ perchÃ© il resto Ã¨ costante in t. Utilizzando di nuovo taylor su questo (su y) ottengo che $$ \\delta_x f(x + t, y+ h) - \\delta_x f(x + t, y) = h \\delta_y(\\delta_x f(x + t, y + \\theta_2 y)) $$ mettendo tutto all\u0026rsquo;inizio, ottengo che $g(h) = u(h) - u(0) = h^2 \\delta_y(\\delta_x f(x + \\theta_1h, y + \\theta_2 h))$ Lo faccio ancora per il simmetrico (cioÃ¨ costruendomi una funzione v(t) che vari a seconda della y e mi trovo che $g(h) = \\delta_{yx}f(x + ah, y + bh)h^2$\nFaccio il limite per h tendente a 0, dividendo per la stessa variabile, e trovo che sono esattamente uguali. cioÃ¨ $\\lim_{h \\to 0} \\dfrac{\\delta_{yx}f(x + ah, y + bh)h^2}{h^2} = \\lim_{h \\to 0} \\delta_{yx}f(x + ah, y + bh)= \\delta_{yx}f(x,y)$ l\u0026rsquo;ultimo uguale Ã¨ giustificabile per la continuitÃ  della funzione f (basta aprire e controllare ðŸ™‚).\nForma Hessiana Conoscendo le forme quadratiche, possiamo andare a definire una forma Hessiana di una funzione di classe $C^{2}$.\nLa forma hessiana di una funzione di class $C^2$ Ã¨ la funzione cosÃ¬ definita:\n$h\\to \\langle Hf(x) h, h\\rangle$\nTaylor di ordine 2 Resto secondo Peano Questa Ã¨ una analisi multivariabile vedere sotto per il caso univariabile col resto espresso in altro modo.\nPossiamo andare a definire una funzione di taylor per funzioni do ordine superiore, lo facciamo utilizzando la matrice hessiana (per definire la derivata seconda ðŸ˜€) Possiamo andare in teoria anche a definire formule di taylor di ordine superiore al 2 ma per questo corso finiamo qui. (probabilmente ci saranno matrici piÃ¹ complicate, e di dimensioni maggiori).\nVogliamo dimostrare che $\\forall v \\in \\R^n$\n$$ f(w + tv) = f(w) + \\langle\\nabla f(w), tv\\rangle + \\dfrac{1}{2}\\langle H(f(w)) tv, tv\\rangle + o(|t^2|), \\\\t \\to 0_v, v\\in Dominio $$ Osservazione paraboloide\nScriviamolo in maltro modo:\n$f(w) = f(v) + \\langle\\nabla f(v), w - v\\rangle + \\dfrac{1}{2}\\langle H(f(v)) w - v, w - v\\rangle + o(|(w - v)^2|), w \\to v$\nQuesta Ã¨ una funzione al secondo ordine in w, Ã¨ un paraboloide in cui possiamo andare a cercare la miglior funzione in questa classe di funzioni quadratiche.\nDimostrazione definiamo $g(t) = f(w + tv)$, la derivata Ã¨ uguale a $g'(t) = \\delta_t f(r(t))$ con $r(t) = w + tv$ che per il teorema della derivata di funzioni composte Ã¨ $\\langle \\nabla f(w + tv), v \\rangle$ Calcoliamo la derivata seconda di questo, ovvero si va ad ottenere: (praticamente sto applicando la 10.4.4 estensivamente.\n$$ \\sum \\delta_t (\\delta_k f) (r(t))v_k = \\sum \\langle(\\nabla\\delta_k f) (r(t)), r'(t)\\rangle v_k \\\\ = \\sum \\langle(\\nabla\\delta_k f) (r(t)), v\\rangle v_k = \\sum\\sum \\delta_j \\delta_k f(r(t) v_jv_k = \\\\ \\langle Hf(r(t))v,v\\rangle $$ In quanto $g: \\R \\to \\R$ possiamo utilizzare taylor classico per affermare che\n$g(t) = g(0) + g'(0) t + \\dfrac{1}{2}g''(0)t^2 + o(t^2)$, che per dimostrazione precedente, sostituendo pezzo per pezzo, si ottiene che\n$f(w + vt) = f(w) + \\langle \\nabla f(w), v \\rangle t + \\dfrac{1}{2}\\langle Hf(w)v,v\\rangle t^2 + o(t^2)$ il che finisce la dimostrazione\nResto secondo Lagrange (univar) Questo Ã¨ equivalente al precedente, col resto secondo Peano.\nSia $f:\\R \\to \\R$ f derivabile due volte, allora\n$\\forall x, \\bar{x} \\in \\R , \\exists c \\in [x, \\bar{x}]$ tale per cui\n$$ f(x) = f(\\bar{x}) + f'(\\bar{x})(x - \\bar{x}) + f''(c) \\dfrac{(x - \\bar{x}) ^2}{2} $$ Note sulla dimostrazione Noto che l\u0026rsquo;unica cosa che cambia Ã¨ la parte finale della somma, quindi vorrei in qualche modo dimostrare che queste due cose siano uguali.\nIo aggiungo e tolgo questo valore : (imprecisato) e riesco a dire la funzione ottenuta Ã¨ un opiccolo per la continuitÃ  della derivata seconda. questo nella direzione lagrange $\\implies$peano\nNon so esattamente cosa stia facendo in questo momento il prof. Quindi la ometto, dico solo che stranamente sta cercando dimostrare che esiste un valore $k \\in R$ tale che\n$f(x) = f(\\bar{x}) + f'(\\bar{x})(x - \\bar{x}) + k{(x - \\bar{x}) ^2}$ e lo dimostra utilizzando Rolle presente in Teoremi Base Analisi costruendosi una funzione che prenda la roba di sopra.\nOssia mi creo $g(\\bar{x}) = f(x) - f(\\bar{x}) -f'(\\bar{x})(x - \\bar{x}) - k{(x - \\bar{x}) ^2}$ In secondo momento calcolandosi il valore della derivata della funzione cosÃ¬ creata si ottengono altri valori.\nNel caso in cui derivata seconda Ã¨ continua Allora posso dimostrare quanto sopra, semplicemente utilizzando la continuitÃ  della derivata seconda, perchÃ© cambiano di poco le due cose.\nResto secondo Lagrange in Rn (multivar) Sia $A \\subseteq \\R^n$ aperto e $f$ di classe $C^2(A)$ ovvero con le derivate seconde continue.\nSia $a, a+h \\in A$ e il segmento $[a, a+h] \\subseteq A$ allora esiste $\\theta \\in (0,1)$ tale che\n$$ f(a + h) = f(a) + \\langle\\nabla f(a), h\\rangle + \\dfrac{1}{2}\\langle H(f(a + \\theta h)) h, h\\rangle $$ Dimostrazione\nconsidero la parametrizzazione data dalla funzione\n$g(t) = f(a + th)$, notiamo che $g(0) = f(a)$ e $g(1) = f(a + h)$ che sono le cose da cui eravamo partiti. se prendiamo $r(t) = a + th$ si ha che $g(t) = f(r(t))$ e allora possiamo utilizzare la derivata di funzioni composte e riscriverla.\nPoi si procede in modo equivalente alla dimostrazione del teorema di lagrange con resto di peano (perÃ² si parte con lagrange con resto lagrange in R).\nPolinomio di Taylor Ãˆ un taylor senza opiccolo, perÃ² di devi andare a cercare l\u0026rsquo;appunto giusto.\nForme quadratiche Queste cose sembrano essere un buon utilizzo della matrice hessiana. Comunque vediamo cosa sono: prendiamo una matrice $A \\in \\R^{n \\times n}$ tale che sia simmetrica, consideriamo una funzione $q_A : \\R ^n \\to \\R$ definita in questo modo : $q_A(h) = \\langle Ah, h\\rangle = h^TAh$. Scopriremo che c\u0026rsquo;Ã¨ una equivalenza (forse isomorfismo) fra un polinomio di grado n e una matrice n per n. Si puÃ² dimostrare che Ã¨ uguale a una forma quadrata questa matrice, questo perchÃ© $\\sum^n_{k,j=1} a_{kj}h_jh_k = \\sum^n_{k=1}a_k h^2_k + 2 \\sum_{ 1\\leq j \u003c k \\leq n} a_{jk} h_j h_k$ ed Ã¨ qualcosa di molto comodo perchÃ© questo non Ã¨ altro che (ricordando che $a_k$ Ã¨ un modo semplice per scrivere $a_{kk}$\n$$ \\langle Ah, h\\rangle = (a_1h_1 + ...+ a_nh_n)^2 $$ Ma questo vale nel caso solo in cui $a_ia_k = a_{ik}$, da ricordare!. Comunque c\u0026rsquo;Ã¨ questa buonissima corrispondenza e ci piace molto.\nSegno della forma quadratica Positivo Se per ogni h diverso da zero la forma quadratica Ã¨ sempre positiva esempio se ho solo numeri sulla diagonale, probabilmente Ã¨ di segno positivo\nNegativo Se per ogni h diverso da zero la forma quadratica Ã¨ sempre negativa\nIndefinita Se esistono due h diversi fra loro per cui la forma della prima Ã¨ minore di 0, la forma della seconda Ã¨ maggiore di zero.\nAltro Ci sono anche altre caratterizzazione della forma quadratica. ad esempio q(h1, h2) = h2^2 non Ã¨ nÃ© indefinita, nÃ© positiva questa Ã¨ semidefinita\nClassificazione del segno n-dimensionale Vogliamo una forma quadratica in Rn, con nâ‰¥3 ora.(fino ad ora abbiamo solamente considerato il caso in cui forma quadratica Ã¨ 2).\nDeterminanti\nMi sono costruito molte sottomatrici.\nLavagna prof\nAutovalori\nTeorema criterio classificazione 2x2 Consideriamo la matrice $$ \\begin{pmatrix} a \u0026 b \\\\ b \u0026 c \\\\ \\end{pmatrix} $$ Allora possiamo individuare i seguenti casi:\nPositivo Una forma quadratica Ã¨ positiva sse $a \u003e 0 \\land ac - b^2 \u003e 0$\nNegativa Una forma quadrata Ã¨ negativa sse $a \u003c 0 \\land ac - b^2 \u003e 0$\nIndefinita sse il determinante Ã¨ negativo., se il determinante Ã¨ 0 si dice che Ã¨ una matrice singolare.\nDimostrazione primo caso vogliamo dimostrare un sse, andiamo per le due frecce. $\\implies$ Se pongo h = (1, 0) ottengo $a \u003e 0$ quindi deve essere cosÃ¬ altrimenti assurdo.\nse pongo h = (h,1) (nota questi due h sono diversi) ottengo $ah ^2 + 2bh + c$ che Ã¨ sempre positivo quando il determinante Ã¨ negativo, quindi verificato\n$\\impliedby$ Se $h_2 = 0$ ottengo $ah^2_1 \u003e 0$ vero perchÃ© a \u0026gt; 0 e ho un quadrato in R\nSe $h_2 \\neq 0$, allora raccogliendo un h2 e ponendo $e = \\dfrac{h1}{h2}$, ottengo\n$q(h) = ae^2 + 2be + c \u003e 0$ (giÃ  diviso per h2 alla seconda), prendendo il determinante ho che Ã¨ $b^2 - ac$ , che Ã¨ sempre minore di 0, quindi sempre vera.\nSemidefinito\nQuando ho il determinante che Ã¨ 0\nCaratteristica positivitÃ  negativitÃ  della Forma Quadratica Possiamo trovare una caratteristica fondante per le matrici positive e negative (sono uguali ma inverse, enunciamole).\nSia $A = A ^t \\in \\mathbb{R} ^{n \\times n}$ allora se $A$ Ã¨ positivo si ha che $\\exists m \u003e 0$\n$\\langle Ah, h\\rangle \\geq m \\lvert h \\rvert^2$\nHint di dimostrazione (osservazione) Questo Ã¨ vero perchÃ© se consideriamo un $h \\neq 0$, possiamo riscrivere l\u0026rsquo;equazione in tesi come $\\langle A \\dfrac{h}{\\lvert h \\rvert}, \\dfrac{h}{\\lvert h \\rvert}\\rangle \\geq m$, che Ã¨ equivalente a dire che comunque prendo un vettore unitario, si ha che la forma quadratica Ã¨ maggiore di un numero m.\nDimostrazione Allora scrivo h con coordinate polari, apro A in dimensione 2 e raccolgo questo $r ^2$. Allora ho in tesi qualcosa di questo tipo $r ^2 f(\\theta) \\geq r^2 m$ e devo dire che esiste questo m. utilizziamo 2 cose per terminare.\n$r^2 f(\\theta) \u003e 0$ in quanto la forma quadratica Ã¨ positiva f Ã¨ una funzione continua, e limitata in $[0, 2\\pi] \\in \\R$, quindi possiamo usare weierstrass per concludere che esiste un minimo. Ã¨ proprio questo il minimo! Concludo dicendo che $r^2 f(\\theta) \\geq r^2 m$ per ogni theta, in particolare il minimo Ã¨ maggiore di 0 in quanto per ipotesi la hessiana Ã¨ positiva, quindi ho finito qui\nDimostrazione con autovalori\nCondizione sufficiente per minimo e massimo e sella Questa cosa ci piace per calcolare i punti di massimi e minimi!\nMassimo Se il gradiente Ã¨ 0 e la hessiana Ã¨ positiva, ho un punto di massimo\nMinimo Grandiente 0 e hessiana negativa, ho un punto di minimo.\nIndefinita Se gradiente Ã¨ 0 e la hessiana Ã¨ indefinita Ã¨ un punto di sella\nDimostrazione (minimo)\nConsideriamo una funzione $f :A \\subseteq \\R^n \\to \\R$ di classe $C^2$ consideriamo un punto $a \\in A$ tale che $\\nabla f(a) = 0$ e so che $Hf(a) \u003e0$. Voglio dimostrare che sia un minimo locale, ovvero che $\\exists \\delta \u003e0$ tale che $f(a + h) \\geq f(a)$ per ogni $h \\in B(0, \\delta)$, ossia $|h| \u003c \\delta$ Espando con taylor, e utilizzo l\u0026rsquo;ipotesi di punto critico e ottengo che $f(a + h) - f(a) = \\dfrac{1}{2} \\langle Hf(a),h,h \\rangle + o(|h^2|)$ voglio dimostrare che per un delta opportuno RHS sia maggiore di 0, se ho questa cosa ho finito, in qualche modo voglio utilizzare la positivitÃ  della matrice hessiana.\nPer il teorema caratterizzante della matrice della forma quadratica, so che $\\exists m \u003e0 \\in \\R :\\langle Hf(a),h,h \\rangle \\geq m \\lvert h^{2} \\rvert, \\forall h \\in \\R^n$ Allora continuando il ragionamento Ottengo che $\\dfrac{1}{2} m \\lvert h^{2} \\rvert+ o(\\lvert h^{2} \\rvert) = \\lvert h^{2} \\rvert(\\dfrac{m}{2} + \\dfrac{o(\\lvert h^{2} \\rvert)}{\\lvert h^{2} \\rvert})$ Ragioniamo ora sull\u0026rsquo;o-piccolo. Allora per definizione di o piccolo, so che posso prendere questa cosa piccola quanto mi pare. In particolare scelgo un intorno in cui questo o piccolo sia compreso fra $m/4$, allora l\u0026rsquo;intorno delta Ã¨ definito da questo momento. Scelto questo intervallo allora finire la dimostrazione Ã¨ veloce, ottengo che $$ f(a + h) - f(a) \\geq |h^2|(m/2 - m/4) \\geq 0 $$ (abbiamo anche dimostrato che dipende da h) perÃ² Ã¨ finito, questa cosa vale per ogni h nell\u0026rsquo;intorno scelto sopra.\nSemidefinita\nNel caso in cui il determinante della hessiana Ã¨ 0, non posso utilizzare i metodi precedenti, quindi in questo caso devo dividere il processo analizzando le derivate parziali.\nCondizione necessaria per minimo e massimo Ãˆ molto simile alla condizione sufficiente, solo Ã¨ abbiamo ora che la hessiana puÃ² anche essere semidefinita positiva.\n","permalink":"https://flecart.github.io/notes/massimi-minimi-multi-variabile/","summary":"Ripasso Prox: 6 Ripasso: May 18, 2022 Ultima modifica: October 8, 2022 12:07 PM Primo Abbozzo: April 5, 2022 4:23 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso 074179\ngli utilizzi della matrice jacobiana Riguardarsi come la continuitÃ  finisce la dimostrazione di schwarz Rivedere i calcoli e l\u0026rsquo;idea principale per taylor al secondo ordine di coso. Massimi e Minimi multivariabile Matrice Jacobiana Ãˆ un modo per scrivere il gradiente di una funzione quando Ã¨ in una certa forma.","title":"Massimi minimi multi-variabile"},{"content":"Introduzione ai processi di Poisson Arrival processes Sia una sequenza di variabili aleatorie $0 \u003c S_{1} \u003c S_{2} \u003c \\dots$ (il fatto che sia positivo significa che per ogni elemento del dominio vale che quell\u0026rsquo;elemento Ã¨ \u0026lt;, non so se mi sono spiegato.) Il fatto che siano crescenti ci permette di metterli in linea, perchÃ© siamo sicuri che $S_{2}$ produrrÃ  un valore maggiore di $S_{1}$.\nIncline a questo c\u0026rsquo;Ã¨ anche il arrival counting process che semplicemente va a contare il numero di arrivi (indicati dagli $S_{i}$). La relazione con l\u0026rsquo;originale Ã¨ abbastanza semplice, e dato da questo evento: $$ \\{S_{n} \\leq t\\} = \\{N(t) \\geq n\\} $$ def: Renewal processes un arrival process in cui inter-arrival times $x_{1}, x_{2}, \\dots$ sono IID.\ndef: Poisson processes Sono renewal processes in cui gli $X_{1}, X_{2}, \\dots$ $F_{X}(x) = 1 - \\exp(-\\lambda x)$, ossia seguono la cumulativa di Poisson.\nProprietÃ  def: Memory-less Variabile aleatoria Ã¨ memory-less se vale. $$ P(X \u003e t + x)= P(X \u003e t) P(X \u003e x) $$ Lo chiamiamo cosÃ¬ perchÃ© assumiamo che non dipende dal tempo passato: $$ P(X \u003e t + x | X \u003e t) = P(X \u003e x) $$ il prof. dice che non ha perso tempo nÃ© guadagnato niente. Perso tempo perchÃ© se vuoi la cosa prima o poi devi entrare in coda.\nSi puÃ² dimostrare che se e solamente se la variabile aleatoria Ã¨ esponenziale allora Ã¨ memory-less.\nTeorema indipendenza di arrival counting and arrival process sketch:\nPrendiamo un tempo $t$\nStationary increment property Se prendiamo un counting process, questo si dice stazionario se la variabile $N(t') - N(t)$ con $t' \u003e t \u003e 0$ ha la stessa distribuzione di $N(t'- t)$ ossia Ã¨ lineare senza costanti. Questo sembra chiaro perchÃ© ci sta dicendo che il numero di arrivi in un lasso di tempo resta sempre lo stesso.\nUn esempio Ã¨ che nel lavoro di Ermanno le sue cose non rispettano la stationary property.\nIndependent property Vale se data una sequenza $0, t_{1}, t_{2}, t_{3}, \\dots$ crescente vale che le distribuzioni $$ N(t_{1}) - N(0), N(t_{2}) - N(t_{1}), \\dots $$ Sono indipendenti fra di loro\nPer il teorema dimostrato sopra si puÃ² dire che la distribuzione di Poisson possieda queste proprietÃ .\nEquivalenze con i processi di Poisson Arrival counting processes Si puÃ² dire che un processo che soddisfa (reference al libro) che sia independent increment e stationary increment sia un processo di poisson\nConditional arrival densities Se so che in un intervallo c\u0026rsquo;Ã¨ un arrivo, allora Ã¨ uniforme la probabilitÃ  di dove sia arrivato (solo che abbiamo una uniforme su un volume molto strano). Questo Ã¨ una cosa che credo sia relazionata con la indipendenza di Poisson per questo genere di processi.\nLa cosa da notare Ã¨ che questa densitÃ  Ã¨ indipendente da $s_{1}, s_{2}, .., s_{n}$.\nsi avrÃ  che $$ f(s_{1}s_{2}\\dots s_{n}|n) = \\frac{n!}{t^{n}} $$ Applicazioni Neuronal firing Da approfondire\nOptical trasmission Da approfondire\n","permalink":"https://flecart.github.io/notes/poisson-processes/","summary":"Introduzione ai processi di Poisson Arrival processes Sia una sequenza di variabili aleatorie $0 \u003c S_{1} \u003c S_{2} \u003c \\dots$ (il fatto che sia positivo significa che per ogni elemento del dominio vale che quell\u0026rsquo;elemento Ã¨ \u0026lt;, non so se mi sono spiegato.) Il fatto che siano crescenti ci permette di metterli in linea, perchÃ© siamo sicuri che $S_{2}$ produrrÃ  un valore maggiore di $S_{1}$.\nIncline a questo c\u0026rsquo;Ã¨ anche il arrival counting process che semplicemente va a contare il numero di arrivi (indicati dagli $S_{i}$).","title":"Poisson processes"},{"content":"Ripasso Prox: 80 Ripasso: June 2, 2023 Ultima modifica: June 7, 2023 2:41 PM Primo Abbozzo: October 1, 2022 10:15 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Domande\nSemantica di un linguaggio Vincoli sintattici contestuali Intro: dipendenze da contesto ðŸŸ© I vincoli sintattici non sono esprimibili tramite BNF perchÃ© dipendono dal contesto, mentre le grammatiche libere sono per definizione libere da contesto, vogliamo quindi trovare una soluzione a questo problema. Vengono usati metodi Ad-Hoc nella fase di analisi semantica del programma.\nGrammatiche dipendenti dal contesto\nQueste grammatiche sono molto piÃ¹ complicate (e lente) rispetto a quelle libere da contesto, quindi Ã¨ poco pratico e non utilizzabile (tempo esponenziale, quindi non finisce mai).\nSemantica statica ðŸŸ© Facciamo differenza fra semantica statica e dinamica con il primo che Ã¨ analizzato nella fase di compilazione del programma, mentre per dinamico Ã¨ analizzato nella fase di run-time, ma Ã¨ una forzatura del nome, perchÃ© storicamente sintassi Ã¨ indicata solamente a grammatica libera, mentre semantica Ã¨ tutto il resto, ma in veritÃ  semantica statica Ã¨ parte di sintassi.\nPrincipalmente questa parte riguarda controlli ad-hoc sul programma durante la compilazione. (ad hoc perchÃ© non Ã¨ vista dallâ€™albero di sintassi).\nSemantica statica def slide\nEsempi di controlli semantica statica\nSempre da tenere in mente che gli errori riportati in questa fase sono riguardanti la sintassi del programma (quindi ad esempio lâ€™utilizzo di variabili non assegnate Ã¨ possibile in C non in Java, questo Ã¨ un controllo di semantica statica che dipende da questa sintassi del programma)\nUtilizzo dellâ€™assegnamento a una variabile Le funzioni sono chiamate col giusto numero di variabili Divisione per zero (guarda esempio sul libro non Ã¨ ben definita questa cosa sul fatto che sia statica o dinamica). Assegnamento di variabili dello stesso tipo. Questi sono esempi di vincoli sintattici contestuali.\nSemantica dinamica (e utilizzi) ðŸŸ©â€” Def semantica dinamica slide\nQuesta semantica Ã¨ un modello matematico utile per ogni architettura! Ãˆ una sorta di specifica che deve descrivere il concetto di correttezza di un programma dal punto di vista semantico. Ãˆ una rappresentazione dellâ€™esecuzione del programma!\nEsempi di utilizzi:\nSlide utilizzi (!!!)\nDimostrazione di proprietÃ  del programma\nSpecifica formale del linguaggio\nImplementazione Ã¨ corretta?\nQuesti utilizzi si possno distinguere se l\u0026rsquo;autore Ã¨ un programmatore, un progettista del linguaggio, un implementatore di un linguaggio. (vedere le slides)\nTecniche di definizione di semantica (4) ðŸŸ© Questa parte descrive la semantica, ma per certi punti ha un sacco di roba in comune con Classical Cyphers\nOperazionale\nSi mostra lâ€™effetto di ogni istruzione durante lâ€™esecuzione, per dare enfasi su questo aspetto dobbiamo avere bene in mente la macchina astratta (registri stati etc..) (o mini automa). In parole povere proviamo a far eseguire su una macchina astratta\nCome calcola? questo Ã¨ quello che andiamo a fare oggi.\nDenotazionale\nSi fa enfasi su cosa va a calcolare (in cui si fa enfasi sulla funzione che viene calcolata).\nPragmatica\nDa ricordare la pragmatica in Pragmatica ðŸŸ© in cui vengono trattati in generale principi per la descrizione di un linguaggio. In piÃ¹ si va a chiedersi sul come utilizzare un costrutto e sullo scopo del singolo comando.\nSi parla di stile di programmazione.\nEsempi di pragmatica\nImplementazione\nSi va a rispondere a domande come\nLâ€™implementazione Ã¨ corretta? (veramente il sorgente e l\u0026rsquo;output implementano la stessa semantica?) Come Ã¨ implementato? Il codice in output Ã¨ efficiente o meno? Le strutture di dati utilizzate sono troppo pesanti o sono ok? Struttura del compilatore Slide struttura del compilatore\nAnalisi lessicale (Scanner) ðŸŸ© Viene generata e riempita una tabella di simboli, questa fase vengono identificati ogni singola parola (o token) che incontra nel nostro programma.\nIn breve fa queste cose\nGenera i token (il lessico ammissibile) Riporta errori se trova token non legali Riempie parzialmente la tabella dei simboli Se qualche parola non Ã¨ valida viene utilizzato un gestore dell\u0026rsquo;errore\nI token sono spesso\nidentificatori Numeri operatori Parentesi Parole riservate Sono usati in questa parte grammatiche regolari espressioni regolari automi NFA DFA\nAnalisi sintattica (Parser) ðŸŸ© In input riceve i token, utilizza la grammatica del linguaggio per verificare se Ã¨ corretto in output restituisce un albero di sintassi astratta del nostro programma. (quindi riporta errori sintattici del nostro programma) e aggiunge informazioni alla tabella dei simboli.\nQuindi in breve\nGenerazione albero di derivazione Report degli errori sintattici (al livello di frase) Sono usati in questa parte grammatiche libere da contesto pushdown automata (DPDA)\nAnalisi semantica ðŸŸ© Controlla se tutta la sintassi libera da contesto sia coerente con la semantica del contesto (quindi verifica tipi, verifica chiamate o moltiplicazioni che abbiano senso o meno)\nIn breve\nControlli di semantica statica (verifica dei tipi, parametri etc) vedi sopra Aggiorna la tabella dei simboli con informazioni sui tipi Espande lâ€™albero con cose sui tipi Codice intermedio ðŸŸ©- Scrive questo codice intermedio piÃ¹ semplice\nSi segue la struttura sintattica, quindi spesso genera del codice molto verboso\nProduce codice molto semplice ,spesso three-address code.\nEsempio di codice intermedio\nOttimizzazione (4) ðŸŸ© Ottimizza il codice nella forma intermedia\nCodice inutile Ã¨ rimosso Ottimizzazioni varie Espansione delle chiamate in linea (inline) Fattorizzazione di sottoespressioni Mettere fuori cicli sottoespressioni che non variano Generazione codice ðŸŸ© Ottimizzazione specifica allâ€™architettura Generazione del codice specifico (quindi a livello del singolo registro, o gestione stack e simili La tabella dei simboli ðŸŸ© Contiene informazioni riguardo tutti i simboli all\u0026rsquo;interno del programma, quindi molto utile nella fasi di analisi.\nQuindi contiene metainformazioni riguardo ai simboli di interesse.\nSemantica Operazionale strutturata The meaning of a program in the strict language is explained in terms of a hypothetical computer which performs the set of actions that constitute the elaboration of that program. (Algol68, Section 2)\nIntro: insiemi di riferimento ðŸŸ¨ Ha un linguaggio definito con la sintassi astratta solita (qualunque stringa Ã¨ parte dellâ€™albero di sintassi valido)\nAgisce principalmente su 3 insiemi\nBooleani Numeri Variabili (simbolici) Con questi dati primitivi definiamo delle espressioni\nSlide\nEspressioni aritmetiche (che agiscono su numeri o variabili) Espressioni booleane Comandi (control flow, gestione memoria, move di variabili) La descrizione di questi insiemi con le BNF sono ambigue ma per l\u0026rsquo;analisi della semantica non ci serve che abbiano un senso vero per questa roba. Non ci interessa di farlo in modo dis-ambiguo ci interessa questa parte solo per la semantica dinamica\nI parser danno in output degli alberi in sintassi astratta\nSistema di transizione (!) ðŸŸ©â€” Slide di definizione\nQuesto sistema di transizione ci Ã¨ utile per descrivere al meglio la semantica.\nÃˆ una tripla $\\Gamma, T, \\to$ dove il primo Ã¨ lâ€™insieme degli stati, il secondo lâ€™insieme degli stati terminali e il terzo una relazione di transizione (che piÃ¹ o meno ci dice in che modo possiamo muoverci allâ€™interno di questi stati).\nIndichiamo con computazione da uno stato $\\gamma_o$ di partenza una seguenza (possibilmente infinita) di transizioni.\nIndichiamo con $\\to^*$ la chiusura riflessiva e transitiva della relazione di transizione.\nInterna sinistra, destra, ed esterne ðŸŸ© Questo concetto di definizione di operazioni interna sinistra,destra ed esterne Ã¨ solamente un metodo che piace al prof per descrivere questo, perÃ² mi sembra che sia praticamente inutile lmao.\nComunque una operazione la descrivi come interna se valuti entrambi gli operandi, sinistra se valuti prima il sinistro e poi il destro e poi viceversa.\nLa definisci come esterna se Ã¨ possibile valutare soltanto lâ€™operatore sinistro (quindi esterna sinistra) o destro.\nOltre IS, esistono anche ID, ES, ED e Interna Parallela = IP (in cui posso utilizzare in modo alternato il destro o sinistro, e quindi mi basta solo sum1 o sum1â€™, quindi questa Ã¨ non-deterministica), perchÃ© posso avere delle derivazioni diverse (ad ogni step posso avere piÃ¹ di un unico assioma da utilizzare!), e potrei anche farli in parallelo.\nSemantica delle espressioni aritmetiche (!) ðŸŸ© Assiomi per le relazioni (3 tipi)\nVar sostituzione con variabile con un numero terminale\nSum1 mi dÃ  una sorta di idea di equivalenza per la somma per alberi che si derivano.\nSum2 mi dÃ  una equivalenza quando la somma Ã¨ su un numero\nSum3 mi dÃ  una equivalenza nella somma nei naturali.\nSub{1,2,3} sono esattamente equivalenti ma per la sottrazione.\nOsservazioni\nLo store non viene mai modificato.\nPer la valutazione si preferisce valutare lâ€™operando piÃ¹ a sinistra. â†’Interna sinistra in modo analogo esiste lâ€™interna destra.\nCostruzione solita, con store\nFunzione di transizione Ã¨ deterministica (non richiesta) ðŸŸ¥ Questa Ã¨ una caratteristica importante della funzione di transizione, si fa uso della ricorsione strutturale presente in 4.6 Ricorsione strutturale.\n$$ y \\to y', y \\to y'' \\implies y' =y'' $$ Ossia ho una sola possibile mossa\nDimostrazione\nEval ðŸŸ© Il fatto che sia deterministica ci permette di definire un concetto di eval tanto Ã¨ unica!\nÃˆ definita con le funzioni di valutazione interne sinistre!\nEssere esterno significa che a volte non valuto tutti gli operandi nella nostra operazione, mentre le interne devono valutare tutte.\nIn generale valgono queste valutazioni\nEquivalenza (!!) ðŸŸ©- Possiamo anche definire un concetto di equivalenza di espressioni come proprietÃ  di questo eval.\nDefinizione di equivalenza per espressioni\nSemantica delle espressioni booleane (!) ðŸŸ© Assiomi per la semantica delle espressioni booleane\nValgono le proprietÃ  per le espressioni aritmetiche\nStore non cambia La relazione Ã¨ deterministica. Semantica dei comandi (statements) (!) ðŸŸ¨+ Assiomi per la semantica dei comandi\nCommenti sugli assiomi\nSkip non faccio niente, lascio la funzione di valutazione esattamente la stessa\nAssign viene fatto uno step di sostituzione (e quindi bisogna anche creare una funzione di sostituzione, ma Ã¨ definita bene in logica in questo blocco 8.1.2 Operazione di sostituzione.\nSeq cerca di far andare avanti la computazione\nIf decide in quale ramo andare, quindi due regole easy\nWhile in modo molto simile, decide se rieseguire il corpo del while oppure andare fuori.\nSi puÃ² notare che anche questa semantica Ã¨ deterministica! In modo simile si puÃ² dimostrare per ricorsione strutturale insieme le altre, dato che Ã¨ deterministica possiamo *definire una funzione exec. che Ã¨ definita solo se Ã¨ terminale\nDivergenza e deadlock sono EQUIVALENTI (Ossia computazione ch enon puÃ² andare avanti e cicli infiniti, non si distinguono con questa semantica, bisogna introdurre delle cose in piÃ¹).\nErrori dinamici (runtime) ðŸŸ¨ Regole di generazione e propagazione dellâ€™errore\nAltre regole per errori (che in un linguaggio solitamente esistono)\nNon determinismo e parallelismo ðŸŸ¨ Non deterministico perchÃ© si puÃ² eseguire in mondi diversi e ritornare cose diverse a seconda di quei mondi.\nParallelismo perchÃ© puÃ² eseguire in contemporanea le istruzioni (in questo senso lâ€™ordine di esecuzione puÃ² essere ben differente).\nSlide\nEsempio di esecuzione non deterministica\n","permalink":"https://flecart.github.io/notes/semantica-di-un-linguaggio/","summary":"Ripasso Prox: 80 Ripasso: June 2, 2023 Ultima modifica: June 7, 2023 2:41 PM Primo Abbozzo: October 1, 2022 10:15 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Domande\nSemantica di un linguaggio Vincoli sintattici contestuali Intro: dipendenze da contesto ðŸŸ© I vincoli sintattici non sono esprimibili tramite BNF perchÃ© dipendono dal contesto, mentre le grammatiche libere sono per definizione libere da contesto, vogliamo quindi trovare una soluzione a questo problema.","title":"Semantica di un linguaggio"},{"content":"Ripasso Prox: 20 Ripasso: June 3, 2022 Ultima modifica: October 19, 2022 5:00 PM Primo Abbozzo: March 31, 2022 11:17 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 4 Sistemi lineari e determinanti 4.1 Sistemi lineari La cosa buona Ã¨ che possiamo analizzare il sistema lineare utilizzando tutti i teoremi che abbiamo sviluppato finora, quindi siamo molto piÃ¹ potenti per attaccare questo problema.\nDefiniamo un sistema lineare cosÃ¬\n$Ax = b$ con A la matrice associata.\n4.1.1 Preimmagine Data una applicazione lineare $F:V \\to W$, allora la controimmagine Ã¨ l\u0026rsquo;insieme dei vettori di V che fanno a finire in quel punto, in matematichese:\n$F^{-1}(w) = \\{v \\in V | F(v) = w\\} \\subseteq V$, un esempio di preimmagine Ã¨ Ker F.\nPossiamo anche definire un concetto di suriettivitÃ  in questo modo:\nUna funzione Ã¨ suriettiva, se per ogni elemento dell\u0026rsquo;immagine, ho un elemento nel dominio, quindi l\u0026rsquo;insieme preimmagine deve essere diverso da vuota\nKer e Imm sono qui\n4.1.2 Relazione preimmagine e immagine e nucleo 6.1.4 (chiede) Fare attenzione a dimostrare la doppia inclusione per l\u0026rsquo;uguale! Stiamo utilizzando sempre l\u0026rsquo;assioma dell\u0026rsquo;estensionalitÃ , ricordatelo!\nDimostrazione\n4.1.3 Rango righe di righe e colonne uguali (6.2.3) !!! Possiamo definire il rango righe come la dimensione dello spazio riga di A\nMentre il rango colonna la dimensione dello spazio colonna (questo Ã¨ ovvio conoscendo i teoremi sulle matrici!, ricorda che con le operazioni di gauss riuscivi a trovare una serie di vettori indipendenti e generatori!)\nDimostrazione\nIl rango colonne, per un teorema precedente che diceva base di uno Ã¨ base anche dell\u0026rsquo;altro, Ã¨ uguale alla dimensione dell\u0026rsquo;immagine, quindi se la dimensione dell\u0026rsquo;immagine Ã¨ uguale al rango righe, ho che i due ranghi sono uguali, allora posso considerare solo un unico rango per la matrice.\nDimostrazione della 5.7.4\nLa dimostrazione di 5.7.4 dovrebbe essere banale, una volta che generalizzi la soluzione di gauss per il nucleo (lo puoi sempre scrivere come spazio generato da n - rr(A) variabili libere per le proprietÃ  credo delle riduzione matriciale di gauss.\n4.1.4 RouchÃ© - Capelli (chiede) Dimostrazione da libro\nDimostrazione (informale)\nLe soluzioni sono le preimmagini della nostra funzione, ha soluzione se la preimmagine di b non`e nulla e per questo deve essere che b deve appartenere al sottospazio generato dalle colonne di a (perchÃ© queste generano l\u0026rsquo;intera immagine) e per la 3.1.8 allora lo spazio colonna di A Ã¨ uguale allo spazio colonna di A con b, allora hanno la stessa dimensione perchÃ© sono uguali, allora i ranghi sono uguali. (4.2.4?)\npreimmagine 0 coimplica b nello spazio immagine\nb nello spazio immagine coimplica generato con e senza b Ã¨ uguale\nquesto coimplica dimensioni uguali quindi finito entrambe le frecce\nPassando per la seconda parte della dimostrazione, sappiamo che l\u0026rsquo;insieme delle soluzioni, ossia la controimmagine, si puÃ² scrivere in questa forma:\n$f^{-1}(w) = \\{ v + z | f(v) = w \\land z \\in ker(f)\\}$\nallora nel caso in cui io abbia che le due matrici siano uguali come al punto 1, posso creare un insieme infinito di soluzioni partendo da questa cosa.\n4.2 Determinanti 4.2.1 Definizione Non abbiamo una definizione diretta del determinante, per cui la definiamo in modo indiretta facendo una lista delle proprietÃ \nVedremo che l\u0026rsquo;inversa di una matrice esiste sse il determinante Ã¨ diverso da 0, ed Ã¨ l\u0026rsquo;aspetto piÃ¹ importante del determinante per la nostra analisi\nSi puÃ² dimostrare (ma non si Ã¨ fatto) che la funzione associata al determinante esiste sempre ed Ã¨ unica.\nProprietÃ  (4)\nLe proprietÃ  1, 2 ci dicono come comportarci rispetto alla somma (distributiva) e la moltiplicazione scalare per singole righe.\nLa proprietÃ  3 ci da un relazione con la combinazione lineare (e quindi dipendenza)\nLa 4 ci permette di calcolare :D\nConseguenze delle proprietÃ  (3)\nLa proprietÃ  3 Ã¨ molto utile per il calcolo, direi che Ã¨ la proprietÃ  piÃ¹ importante per fare i calcoli\nHint di dimostrazione Considero la matrice somma, che per la proprietÃ  1 Ã¨ uguale alla somma dei determinanti di A e B. Allora questa ha due righe uguali, quindi Ã¨ uguale a 0. Riscrivendo la somma si ha la sol. Considero la riga scritta come combinazione lineare come somma di due di determinanti di due matrici. Una di queste avrÃ  due righe uguali, quindi Ã¨ 0. I due determinanti sono uguali. Partendo dalla triangolare inferiore, posso trovare la matrice diagonale con matrici con combinazioni lineari. Teorema di Binet\nQuesta proprietÃ  non si dimostra senza aver considerato la base di dimostrazione con permutazioni.\nPerÃ² dice che se ho due matrici, si ha che il determinante della matrice prodotto Ã¨ uguale al determinante delle singole matrici.\n4.2.2 Metodo savius Per le matrici 3x3, il classico\n4.2.3 Metodo Laplace (ricorsivo) 4.3 L\u0026rsquo;inversa della matrice 4.3.1 Definizione e unicitÃ  L\u0026rsquo;inversa di una matrice $A \\in M_{n\\times n}(\\R)$ Ã¨ una matrice $B$ nello stesso spazio tale che\n$AB = BA = I$.\nQuando si fa il controllo della matrice inversa, dovresti dimostrare che $AB = BA$ che di solito non vale, perÃ² dimostri che l\u0026rsquo;inversa Ã¨ unica quindi ti basterebbe fare un unico controllo\nDimostrazione unicitÃ  dell\u0026rsquo;inversa\nSia $A^{-1}$ l\u0026rsquo;inversa di $A$, supponiamo che esista $B$ che sia l\u0026rsquo;inversa e tale per cui $A^{-1} \\neq B$, allora ho che\n$AB =I \\implies A^{-1}AB = A^{-1}I \\implies I B = A^{-1}I \\implies B = A^{-1}$\n4.3.2 Equivalenza di invertibilitÃ  col determinante (!!) Si puÃ² dimostrare che $A$ Ã¨ invertibile nel caso in cui la determinante Ã¨ diverso da 0.\nDimostrazione\n$\\implies$Se Ã¨ invertibile, il determinante di A Ã¨ diverso da 0.\nPerchÃ© per binet, se $I = AB$ allora $\\det(I) = \\det(AB) = \\det(A)\\det(B)$ se fosse 0 allora sarebbe impossibile, quindi Ã¨ diverso da 0, e posso dire che\n$\\det(B) = \\dfrac{1}{\\det(A)}$\n$\\impliedby$\nDevo dimostrare che se il determinante di A Ã¨ diverso da 0 allora Ã¨ invertibile. Facciamo una dimostrazione costruttiva, cioÃ¨ diciamo qua proprio come Ã¨ fatto la matrice inversa.\nPosso costruire la matrice inversa in questo modo:\n$b_{ij} = \\dfrac{1}{\\det A} \\Gamma_{ji}$ ora devi controllare questa cosa e sei apposto.\n4.3.3 Calcolo dellâ€™inversa con GAUSS SI puÃ² calcolare l\u0026rsquo;inversa di una matrice utilizzando gauss su una matrice del tipo\n$A|I$, fino ad andare ad ottenere la matrice $I|B$ con B la inversa.\nTEOREMONE (!!!!) 7.6.1 Enunciato (11)\nTutte le dimostrazioni fra 1 e 9 compreso sono sono tutte giÃ  state spiegate in precedenza, l\u0026rsquo;unica cosa nuova Ã¨ l\u0026rsquo;equivalenza fra 1 e 10\nDimostrazione (1-10)\nSe dimostro che 1 Ã¨ equivalente a 10, ho dimostrato l\u0026rsquo;equivalenza anche per 1-11 perchÃ© 10 Ã¨ equivalente a 11 per il teorema questo.\nAllora dimostriamo $\\implies$.\nSupponiamo di avere una funzione bigettiva. Allora posso prendere la sua funzione inversa, che esiste per la biiettivitÃ . Considero la matrice associata all\u0026rsquo;inversa, allora posso concludere che $f \\cdot g \\approx AA^-1$ che termina la dimostrazione perchÃ© ho la matrice inversa.\nPossiamo enunciare le equivalenze fra cose riguardo le applicazioni lineari\nNota su composizione di funzioni\nSia A la matrice associata a f e B associata a g.\nAllora si puÃ² dimostrare che la matrice associata a $f \\cdot g$ Ã¨ $AB$, questo si dimostra utilizzando l\u0026rsquo;associativitÃ  della moltiplicazione matriciale.\n","permalink":"https://flecart.github.io/notes/sistemi-lineari-e-determinanti/","summary":"Ripasso Prox: 20 Ripasso: June 3, 2022 Ultima modifica: October 19, 2022 5:00 PM Primo Abbozzo: March 31, 2022 11:17 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 4 Sistemi lineari e determinanti 4.1 Sistemi lineari La cosa buona Ã¨ che possiamo analizzare il sistema lineare utilizzando tutti i teoremi che abbiamo sviluppato finora, quindi siamo molto piÃ¹ potenti per attaccare questo problema.\nDefiniamo un sistema lineare cosÃ¬\n$Ax = b$ con A la matrice associata.","title":"Sistemi Lineari e determinanti"},{"content":"Particelle in campi magnetici Moto in campo magnetico uniforme ðŸŸ© Se abbiamo una particella carica con velocitÃ  uniforme in campo magnetico uniforme, come abbiamo detto in precedenza, una forza centripeta, questo farÃ  curvare la carica, una cosa interessante sarebbe provare a capire raggio di curvatura della nostra carica. Sotto in immagine abbiamo l\u0026rsquo;esempio di curvatura. $$ F = qvB= ma = \\frac{mv^{2}}{r} \\implies r = \\frac{mv^{2}}{qvB} = \\frac{mv}{qB} = \\frac{p}{qB} $$ Dove $p$ Ã¨ la quantitÃ  di moto, quantitÃ  che credo sia relazionata al lavoro ed inerzia, parte di fisica 1 che non ho studiato da piÃ¹ di due anni. Questa stessa relazione, conoscendo il raggio puÃ² essere usata per calcolare il campo magnetico!.\nPossiamo anche avere una velocitÃ  angolare! $$ \\omega = \\frac{v}{r} = \\frac{vqB}{mv} = \\frac{qB}{m} $$ Questo risultato si poteva anche avere osservando che $F = m \\vec{\\omega} \\times \\vec{v}$ E si noterÃ  che il verso Ã¨ opposto al campo magnetico. Quindi: $$ \\vec{\\omega} = -\\frac{q\\vec{B}}{m} $$ Ma questo vale solo classicamente, perchÃ© poi entrano in gioco irradiazioni che fanno perdere energia e anche cose relativistiche se accelero troppo.\nSupponiamo ora che ci sia un certo angolo fra i due allora ho che solamente la parte normale ha forza, avrÃ² un moto elicoidale.\nAngolo generico ðŸŸ© $$ F = qv \\times B = q(\\vec{v}_{n} + \\vec{v}_{p}) \\times \\vec{B} = q\\vec{v}_{n}\\times \\vec{B} $$ Passo dell\u0026rsquo;elica Vogliamo capire quale sia la distanza fra un top di elica e una altra, avremo che questo Ã¨ $$ p = v_{p} T = v_{p} \\frac{2\\pi}{\\omega} = \\frac{2\\pi mv_{p}\\cos \\theta}{qB} $$ Dove $v_{p}$ Ã¨ la velocitÃ  parallela al campo magnetico, e $T$ Ã¨ il periodo che Ã¨ calcolato dalla velocitÃ  angolare. Il coseno serve per prendere la componente corretta credo\u0026hellip;.\nEffetto Hall ðŸŸ© Da studiare bene pagina 230 Mazzoldi. Sia dato un conduttore parallelepipedo, una piccola sottile lastra, che scorre una corrente, allora avremo una forza $$ \\vec{F} = q\\vec{v}_{d} \\times \\vec{B} $$ La forza Ã¨ non-elettrostatica, chiamata forza elettromotore, simile a quello per i circuiti, lo scrivo cosÃ¬: $$ F = qE_{m} = q\\vec{v}_{d}\\times \\vec{B} \\implies E_{m} = v_{d}B $$ Questo fa accumulare carica positiva sopra, che crea un altro campo elettrico statico che prova a bilanciare. Il primo passaggio Ã¨ motivato perchÃ© Ã¨ come se esistesse un campo elettrico fittizio, per spostarlo su. (Ãˆ un campo elettrico generato!).\nQuesto campo elettrico che bilancia si chiama campo elettrico di Hall. Ãˆ utile per capire se i portatori di carica Ã¨ negativo o positivo, forse ha una cosa storica questa cosa. Avremo che $$ \\Delta V_{M} = E_{m} b = v_{d}Bb = b\\vec{J}\\times \\frac{\\vec{B}}{nq} = i \\frac{\\hat{u}}{a}\\times \\frac{\\vec{B}}{nq} \\implies \\Delta V = \\frac{iB}{nqa} $$ Dove $b$ Ã¨ l\u0026rsquo;altezza, e $a$ Ã¨ la width del nostro filo.\nQuesto permette di misurare il campo magnetico ed Ã¨ chiamato sonda di Hall, basta misurare la differenza potenziale presente. Per esempio questo diventa molto utile quando per Magnetismo nella materia andiamo poi a misurare il campo magnetico in buchi, basta mettere questa sonda di Hall.\nSpettrometri di massa Spettrometro di massa di Thomson ðŸŸ© Ho un coso che emette particelle in tutte le direzioni, faccio passare una zona per aumentare energia e poi campo magnetico Abbiamo che $$ \\frac{1}{2}mv^{2} = q\\Delta V \\implies v = \\sqrt{ \\frac{2qV}{m} } $$ Usiamo poi questo valore che ci permette di descrivere la velocitÃ  della particella prima che entrino nel campo magnetico, e otteniamo poi che, considerando l\u0026rsquo;accelerazione centripeta. $$ F = qvB = \\frac{mv^{2}}{r} \\implies r = \\frac{mv}{qB} =\n\\sqrt{ 2 \\frac{m\\Delta V}{qB^{2}} } $$ Questo Ã¨ uno strumento buono per separare **isotopi**, perchÃ© hanno una massa diversa, ma stessa carica. Posso anche definire il rapporto fra i raggi degli isotopi che Ã¨ $$ \\frac{r_{1}}{r_{2}} = \\sqrt{ \\frac{m_{1}}{m_{2}} } $$\nSelettore di velocitÃ  ðŸŸ© Metto in modo che ci sia un condensatore che abbia un certo campo elettrico, e anche che ci sia un campo magnetico, vorrei avere che abbiamo stesso valore, ossia $$ qE = q\\vec{v} \\times \\vec{B} \\implies E = vB $$ Nel nostro setting, questo Ã¨ utile per sapere la velocitÃ  da mettere poi in uno spettrometro di massa e fargli fare un certo giro! Allora abbiamo di nuovo $$ qvB_{0} = \\frac{mv^{2}}{R} \\implies R = \\frac{mv}{qB_{0}} = \\frac{mE}{qBB_{0}} $$ Anche questo posso usarlo per separare isotopi diversi, ma la cosa bella Ã¨ che questo Ã¨ lineare mentre prima avevamo una radice quadrata.\nSpire Setting classico: spira rettangolare ðŸŸ© Prendiamo un campo magnetico costante, e un rettangolo di filo indeformabile (perchÃ© ci sono forze che potrebbero deformarla), in cui c\u0026rsquo;Ã¨ corrente, questo fa girare. Il campo magnetico ha un angolo con la nostra spira. Ossia -\u0026gt; $$ F_{4} = F_{3} = 0, F_{1} = F_{2} = 0 $$ Ossia la spira non trasla, perchÃ© non c\u0026rsquo;Ã¨ accelerazione, non trasla il centro di massa. E questo per qualche motivo ci permette anche di usare qualunque sistema di riferimento, tanto diventerÃ  uguale\u0026hellip;\nI due invece fanno ruotare la spira: $$ M = \\vec{M}_{1} + \\vec{M}_{2} = \\vec{r}_{1}\\times \\vec{F}_{1} + \\vec{r}_{2}\\vec{F}_{2} = \\frac{b}{2}\\sin \\theta F_{1} + \\frac{b}{2} \\sin \\theta F_{2} = bsen\\theta F = b \\sin \\theta iaB = i \\vec{S} \\times \\vec{B} $$ Per i lati su e giÃ¹ abbiamo stessa forza che si annulla, per altri invece abbiamo un momento ora.\nMomento magnetico di spira ðŸŸ© dal risultato precedente sembra sensato definire una nuova variabile: $$ \\vec{m} = i\\vec{S} $$ Il che ci permette di scrivere la relazione di sopra come $$ \\vec{M} = \\vec{m} \\times \\vec{B} $$ Che sta clean. Questo Ã¨ molto simile al valore trovato per il momento nel Dipolo elettrico, in cui abbiamo il momento di dipolo.\nPiccole oscillazioni ðŸŸ¥ usiamo quanto scritto sopra, e valutiamo cosa succede per cose piccole: $$ \\lvert \\vec{M} \\rvert = -mB\\sin \\theta = mB\\theta = I\\dot{\\omega}= I\\ddot{\\theta} $$ E abbiamo che $$ \\ddot{\\theta} + \\omega^{2}\\theta=0 $$ Questo permette di calcolare il campo magnetico, col periodo. La cosa interessante Ã¨ che questo si comporta come un ago magnetico, stesso comportamento.\n","permalink":"https://flecart.github.io/notes/spettrometri-di-massa/","summary":"Particelle in campi magnetici Moto in campo magnetico uniforme ðŸŸ© Se abbiamo una particella carica con velocitÃ  uniforme in campo magnetico uniforme, come abbiamo detto in precedenza, una forza centripeta, questo farÃ  curvare la carica, una cosa interessante sarebbe provare a capire raggio di curvatura della nostra carica. Sotto in immagine abbiamo l\u0026rsquo;esempio di curvatura. $$ F = qvB= ma = \\frac{mv^{2}}{r} \\implies r = \\frac{mv^{2}}{qvB} = \\frac{mv}{qB} = \\frac{p}{qB} $$ Dove $p$ Ã¨ la quantitÃ  di moto, quantitÃ  che credo sia relazionata al lavoro ed inerzia, parte di fisica 1 che non ho studiato da piÃ¹ di due anni.","title":"Spettrometri di massa"},{"content":"Ultima modifica: November 2, 2021 10:50 AM Primo Abbozzo: November 2, 2021 9:22 AM Studi Personali: No\nElementi di ripasso Strutture Caratteristiche La caratteristica principale Ã¨ che le strutture permettono di avere valori eterogenei mentre prima avevamo solo array, ossia valori omogenei, uguali fra di loro.\nQuesto Ã¨ anche il modo solito con cui fare dei database! Teneere roba ordinata\nSintassi Accesso Blablabla\nCopia Si puÃ² copiare un array in modo molto semplice, basta un uguale, mentre invece con gli array non si poteva semplicemente copiare (perchÃ© copiava il pointer) ora a quanto pare copia in automatico.\nðŸ’¡ Si puÃ² fare solo se hanno lo stesso tipo (vale anche per copiare campi Incapsulamento Le classi daranno incapsulamento, mentre le struct no.\nðŸ’¡ Si puÃ² fare solo se hanno lo stesso tipo (vale anche per copiare campi Incapsulamento Le classi daranno incapsulamento, mentre le struct no.\n","permalink":"https://flecart.github.io/notes/strutture/","summary":"Ultima modifica: November 2, 2021 10:50 AM Primo Abbozzo: November 2, 2021 9:22 AM Studi Personali: No\nElementi di ripasso Strutture Caratteristiche La caratteristica principale Ã¨ che le strutture permettono di avere valori eterogenei mentre prima avevamo solo array, ossia valori omogenei, uguali fra di loro.\nQuesto Ã¨ anche il modo solito con cui fare dei database! Teneere roba ordinata\nSintassi Accesso Blablabla\nCopia Si puÃ² copiare un array in modo molto semplice, basta un uguale, mentre invece con gli array non si poteva semplicemente copiare (perchÃ© copiava il pointer) ora a quanto pare copia in automatico.","title":"Strutture"},{"content":"Algebra modulare Assunzioni Andiamo ora ad assumere l\u0026rsquo;esistenza e correttezza di alcune cose di base. (in teoria si possono dimostrare da cose piÃ¹ di base, ma non ho tempo).\nTeorema fondamentale dell\u0026rsquo;algebra Ogni numero intero si fattorizza in modo unico.\nAlgoritmo di Euclide La conseguenza piÃ¹ importante di questo teorema, dovuto ad Euclide Ã¨ che se ho $a, b \\in \\mathbb{Z}$ allora esistono resto e dividendo fra i due. Ossia $\\exists q, p : a\\mid b = qk + p$ per qualche $k$ intero\nDare una occhiata all\u0026rsquo; implementazione potrebbe essere interessante.\nMCD e divisibilitÃ  Se $a \\mid d$ e sono interi allora esiste esiste c tale per cui d = ca. (tutti interi senza restrizioni) mcd fra interi a e b Ã¨ il piÃ¹ grande intero che divide sia a sia b. Osservazione: $mcd(a, 0) = a$\nTeorema di BÃ©zout che dice che esistono r ed s tali che per ogni 2 interi a,b ho che ar + sb = gdc(a,b); E da questo possiamo andare a fare algoritmo di Euclide esteso.\nClassi di resto modulo n Si dicono che $a \\equiv b \\mod n \\iff n | a - b$\nSI indica con $[a]_n = \\{ b \\in \\mathbb{Z} :b \\equiv a \\mod n\\}$ elementi la cui differenza con a Ã¨ divisibile per n\nE indichiamo con $\\mathbb{Z}_n$ come l\u0026rsquo;insieme di tutte le classi di equivalenza ossia $\\{[[a]_n : a \\in \\mathbb{Z}\\}$ ossia insieme quoziente, Relazioni fra insiemi.\nDimostrazione classe di equivalenza RiflessivitÃ \nsi ha che $n | a- a \\iff n | 0$ che Ã¨ vero\nSimmetrica\nse $a \\equiv b \\iff b \\equiv a$ in quanto se $a \\equiv b \\iff n | a - b \\iff n | b - a \\iff b \\equiv a$ (cioÃ¨ basta moltiplicare per qualcosa di negativo, si ha lo stesso risultato\nTransitiva, mi sono rotto\nAllora sappiamo di avere una classe di equivalenza (una partizione su Z in pratica).\nProp equivalenza con resto Sia $a\\in \\mathbb{Z}$ e r il suo resto di divisione per n, allora $a \\equiv r \\mod n$ ossia appartengono alla stessa classe di equivalenza\nProp costituzione dell\u0026rsquo;insieme quoziente Per la proposizione precedente posso trovare proprio come Ã¨ costituito\n$Z_n = \\{[0]_n, [1]_n...,[n-1]_n\\}$\nDimostrazione:\ndimostrare che $\\impliedby$ ossia destra Ã¨ contenuto in sinistra Ã¨ ovvio per definizione di Zn, per dimostrare che $\\implies$si utilizza la proposizione sopra:\nSia $[a]_n \\in \\mathbb{Z}_n$ per proposizione sopra si ha che $[a]_n = [r]_n \\in \\{[0]_n,...,[n - 1]_n\\}$\nPer concludere (se voglio dimostrare nel modo classico utilizzando classe di equivalenza) devo dimostrare che tutte le classi presenti in Zn sono effettivamente distinte.\nPrendo $i,j \\in [0...n-1]$ wlog $i \u003e j$ allora $0 \u003c i - j \\leq i \\leq n- 1$ allora $n \\not | i-j,$ quindi si ha che $i \\not\\equiv j \\mod n$ e questo conclude che Zn ha n elementi\nSomma e prodotto in questa classe La definizione di classe modulo resto in questo modo Ã¨ molto simile alla classica definizione di somma e prodotto (ma non per la divisione, non Ã¨ sempre invertibile).\nE si dimostrano anche\nCommutativitÃ  AssociativitÃ  DistributivitÃ  (entrambe, destro e sinistra) C\u0026rsquo;Ã¨ il neutro per la somma Prop. invertibilitÃ  di una classe Si dice che $[a]_n \\in \\mathbb{Z}_n$ Ã¨ invertibile se esiste $[b]_n \\in \\mathbb{Z}_n : [a][b] = [1]$ (sottinteso indici)\nSi dimostra che Ã¨ invertibile se solo se Ã¨ co-primo col modulo poi (perchÃ© con Euclide esteso riesco a trovarmi l\u0026rsquo;inversa).\nProp. unica soluzione diofantea Ãˆ un corollario della precedente, praticamente dice che se $ax = b, gcd(a,n) = 1$ allora esiste una unica soluzione.\nUn approfondimento Ã¨ presente nella teoria dei gruppi per sta parte (le cose che potrebbero essere interessanti sono i Campi da questo punto di vista). Vedere Gruppi Gruppi ciclici e permutazioni e Gruppi Normali.\n","permalink":"https://flecart.github.io/notes/algebra-modulare/","summary":"Algebra modulare Assunzioni Andiamo ora ad assumere l\u0026rsquo;esistenza e correttezza di alcune cose di base. (in teoria si possono dimostrare da cose piÃ¹ di base, ma non ho tempo).\nTeorema fondamentale dell\u0026rsquo;algebra Ogni numero intero si fattorizza in modo unico.\nAlgoritmo di Euclide La conseguenza piÃ¹ importante di questo teorema, dovuto ad Euclide Ã¨ che se ho $a, b \\in \\mathbb{Z}$ allora esistono resto e dividendo fra i due. Ossia $\\exists q, p : a\\mid b = qk + p$ per qualche $k$ intero","title":"Algebra modulare"},{"content":"Utilizzano blocchi per cifra invece che stream generators.\nDES 56 bit 3DES 56*3 bit di chiave AES che puÃ² andare a 128, 196 o 256 Solitamente i stream ciphers studiati in OTP and Stream Ciphers sono piÃ¹ veloci. Data Encryption Standard 1974 da IBM su commissione di NSA in quel periodo era solamente fatta dalla intelligence, non câ€™era bisogno di comunicazioni per il pubblico in quel periodo.\n1977 - 1998 questo era lo standard per gli stati uniti. best studied cipher in the world! Oggi insicuro, esiste una sua variante 3DES che Ã¨ piÃ¹ sicura, ma comunque rotto C\u0026rsquo;Ã¨ una step di **creazione delle chiavi\nFeistel network Definizione Feistel ðŸŸ© Definiziamo una funzione di feistel $f(L^{i - 1}, R^{i - 1}, K^{i}) \\to L^{i}, R^{i}$ la seguente:\nUno state $u^{i}$ Ã¨ diviso in due parti, che vengono cifrati in questomodo: $$\n\\begin{cases} L^{i} = R^{i - 1}\\ R^{i} = L^{i - 1} \\oplus f(R^{i - 1}, K^{i}) \\end{cases} $$ Dove $f$ Ã¨ una funzione invertibile, se si ha la chiave.\nInvertibilitÃ  di Feistel ðŸŸ© La caratteristica bella Ã¨ che data la chiave questo Ã¨ facilmente invertibile, anche se $f$ potrebbe non esserlo. Infatti la seguente funzione inverte in modo facile $$ \\begin{cases} L^{i - 1} = R^{i} \\oplus f(L^{i}, K^{i})\\\\ R^{i - 1} = L^{i} \\end{cases} $$ Si puÃ² verificare in modo facile che funziona questo.\nFunzionamento DES ðŸŸ© Quindi\nmapping iniziale $IP$ che crea $L^{0}R^{0}$ rounds di Feistel Poi output La decryption Ã¨ simmetrica con la conoscenza della chiave.\n$f$ function in DES ðŸŸ¨ Dove $A$ Ã¨ il 32 bit plaintext e $J$ Ã¨ la chiave.\nLe funzioni $S$ sono tra le piÃ¹ importanti per la sicurezza, perchÃ© resistono a certi tipi di attacchi conosciuti (che se riesco metto in questi appunti qui sotto). Sono in pratica una mappa di 4 bit e 2 bit a un 4 bit. Attacchi a DES ðŸŸ© Gli attacchi maggiori (alcuni lo vengono anche come servizio commerciale) Ã¨ semplicemente bruteforce perchÃ© la chiave di 56 bit usata non Ã¨ che sia molto utile. (In un giorno te o rompe). Gli attacchi con known plaintext esistono, ma usano un insieme di dati non feasible. di $2^{40}$ coppie di plaintext-ciphertext.\nUnicitÃ  della chiave ðŸŸ©- Ãˆ notabile osservare che Ã¨ probabile sia in DES che AES che Ã¨ molto probabile che sia unica la chiave usata per cifrare quello. Questa nota Ã¨ utile per dire che se trovi quella chiave, probabilmente ti funziona anche per altre comunicazioni che utilizzano roba simile.\nAltre versioni di DES In modo semplice per renderlo piÃ¹ sicuro Ã¨ il 3-DES in pratica DES applicato 3 volte, con chiave lunga il triplo, quindi piÃ¹ resistente a bruteforce.\nAttacco a 2-DES ðŸŸ© Vorremmo trovare una coppia di chiavi $k_{1}, k_{2}$ tale che per cui $E(k_{2}, m) = D(k_{1}, c)$ ed Ã¨ possibile con un meet in the middle, che dovrebbe diminuire lo spazio di ricerca. Conseguenza: Mi basta un $2 \\cdot 2^{56}$ non un $2^{112}$ per rompere la chiave con questo attacco. Per questo motivo uso un 3-DES che non permette di fare questo.\nDESX (non impo) Wikipedia.\nConsidero tre chiavi e considero $$ k_{1} \\oplus E(k_{2}, m\\oplus k_{3}) $$ In parole semplici ho due chiavi in piÃ¹ che uso per fare un xor prima di mandarlo in #Data Encryption standard normale. La cosa da notare Ã¨ che non cresce la complessitÃ  di quanto ci si aspetta.\nAdvanced Encryption Standard Note storiche di AES Da un punto di vista storico Ã¨ stata una competizione internazionale 1997 che poi Ã¨ stata standardizzata nel 2000. Una conferenza per questo (in particolare al seconda) Ã¨ stata fatta a Roma, cosa che era curiosa, solitamente non si faceva cosÃ¬). Ãˆ stato scelto in base a\nSicurezza Costo implementazione VelocitÃ  hardware e software. Alla fine Ã¨ un algoritmo molto parallelizzabile. Generazione della chiave ðŸŸ¨- La lunghezza della chiave decide il numero di rounds, rispettivamente 10, 12, 14. In base al fatto che usiamo 128, 192, o 256. Vedere 4.6 di (Stinson 2005). Per l\u0026rsquo;algoritmo. La cosa Ã¨ che avremo una chiave di 16 bytes in output per il numero di rounds.\nFunzionamento del cifrario ðŸŸ¨- Definiamo le operazioni SubBytes (byte-by-byte substitution using an S-box) ShiftRows (a permutation, which cyclically shifts the last three rows in the State) MixColumns (substitution that uses Galois Fields, GF(2^8) arithmetic) Add Round key (bit-by-bit XOR with an expanded key L\u0026rsquo;immagine Ã¨ sbagliata per la grandezza della chiave di input, per il resto Ã¨ ok, buona schematizzazione del funzionamento.\nModes of operation Electronic Code Book (ECB) Il problema principale di questo metodo naÃ¯ve Ã¨ il fatto che posso vedere s e blocchi hanno avuto stesso input, perchÃ© non dipendono dalla posizione.\nQuesto non Ã¨ semantically secure secondo note in OTP and Stream Ciphers#Semantic security (!)\nDeterministic Counter (DETCTR) In pratica creo stream di bytes a blocchi per cifrare Th: questo cipher Ã¨ semanticamente sicuro se la funzione $F$ usata Ã¨ sicura. Ossia ha un buone garanzie teoriche se esiste e trovo tale $F$.\nCipher Block Chaining (CBC) Lo conosci.\nUna nota importante Ã¨ che si puÃ² fare una analisi teorica, e sapere dopo quanti riusi di chiave Ã¨ necessario cambiarla, al fine di mantenere garanzie di sicurezza.\nSe si guarda le slides possiamo avere un risultato, che Ã¨ circa di $2^{48}$ blocchi per CBC. Si puÃ² fare la stessa analisi per #Data Encryption Standard\nNOTA: CBC non Ã¨ sicuro con un choosen plaintext e la capacitÃ  di predire gli IV Come:\nScelgo come mio choosen plaintext $0$ cosÃ¬ ho in pratica la versione criptata di $IV$. Poi mando $m_{0} = IV \\oplus IV_{2}$ e $m_{1} \\neq m_{0}$ , se $c(m_{0})$ Ã¨ uguale al primo, allora ho indovinato il messaggio. Questo chiaramente dÃ  advantage 1 e rompe la definizione (non so quanto praticamente utile) di semantic security. Una possibilitÃ  Ã¨ usare un IV creato dalla cifrazione di un Nonce, cosÃ¬ sei abbastanza sicuro che IV sia sicuro.\nCounter Mode (CTR) molto simile al counter mode per #Electronic Code Book (ECB) perÃ² ora abbiamo IV. Anche in questo caso possiamo usare una nonce based version.\nSubstitution-Permutation Networks (not required for exam) 2 componenti principali Abbiamo un box di sostituzione e un box di permutazione. La stringa iniziale viene divisa in molti blocchi di lunghezza $m$, e in totale avrÃ  lunghezza $lm$. Con padding finale possibile. C\u0026rsquo;Ã¨ un algoritmo abbastanza generale per questo genere di cifrari, che Ã¨ il 4.1 in (Stinson 2005). la cosa carina Ã¨ che queste funzioni alla fine sono molto semplici da implementare, sia in hardware e software. Non so bene su security garantuess\nKey generation and rounds In un unico round, viene encryptato molte volte (un round Ã¨ fra 10-20 cicli di criptazione) si chiamano iterated ciphers, e dalla chiave iniziale vengono generate 16 chiavi, una per ogni round. Questo lo chiamiamo round function e la funzione che genera le chiavi per ogni round sono key schedule.\nPseudo random function Main definition Pseudo random permutation Solamente una pseudorandom-function tale per cui inizio e fine sono le stesse, quindi Ã¨ bigettiva\nSecure PRF TODO:\nReferences [1] Stinson â€œCryptography: Theory and Practice, Third Editionâ€ CRC Press 2005\n","permalink":"https://flecart.github.io/notes/block-ciphers/","summary":"Utilizzano blocchi per cifra invece che stream generators.\nDES 56 bit 3DES 56*3 bit di chiave AES che puÃ² andare a 128, 196 o 256 Solitamente i stream ciphers studiati in OTP and Stream Ciphers sono piÃ¹ veloci. Data Encryption Standard 1974 da IBM su commissione di NSA in quel periodo era solamente fatta dalla intelligence, non câ€™era bisogno di comunicazioni per il pubblico in quel periodo.\n1977 - 1998 questo era lo standard per gli stati uniti.","title":"Block Ciphers"},{"content":"Ripasso Prox: 7 Ripasso: June 1, 2022 Ultima modifica: October 19, 2022 4:59 PM Primo Abbozzo: April 5, 2022 10:40 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso 5 Cambio di base 5.1 Nozioni da avere prima di Cambio di Base Applicazioni lineari La definizione di applicazione lineare La matrice associata L\u0026rsquo;esistenza e unicitÃ  di una applicazione lineare rispetto a una base Le coordinate di un punto rispetto a una base. 5.2 Matrice del CdB e IdentitÃ  Se ho due spazi vettoriali\nIntuizione in R\nLe coordinate dei punti in R sono uguali a V per le basi canoniche, ma questo vale solamente per R, ora vogliamo andare a dire una cosa piÃ¹ forte, il cambio di base\nSe ho una applicazione lineare $F: V \\to W$ e un insieme di basi del dominio e del codominio, allora esiste una matrice $A \\in M_{m \\times n} (\\R)$ tali che vale il cambio di base.\nQuesta matrice me la costruisco mettendo per ogni colonna le coordinate di $F(v_1)$ rispetto alla base del vettore di arrivo.\n$F(v)_{\\beta '} = A v_{\\beta}$ cioÃ¨ le coordinate di v rispetto alla base d arrivo Ã¨ uguale a una matrice (costituita dalle coordinate dell\u0026rsquo;immagine delle basi ) per il vettore coordinate iniziali.\nDal libro\n5.2.1 Matrici associate allâ€™identitÃ  Questa mÌ€atrice sono per applicazioni lineari del tipo $f:V \\to W$, $V = W$ e ele due basi sono l\u0026rsquo;identitÃ . Allora la matrice associata a queste due basi Ã¨ $I_{\\beta \\beta'}$\nSe le due basi sono esattamente le stesse, allora posso dire che Ã¨ la matrice identitÃ , la cosa un pÃ² cambia quando le basi sono diverse.\nOvvero se mando la stessa base, le coordinate non cambiano, quindi riesco a costruirmi abbastanza in fretta la matrice identitÃ .\nOssia $I_{\\beta\\beta} = I$, che Ã¨ uguale rispetto a una base canonica qualunque.\nQuindi la matrice associata a questa Ã¨\n$\\begin{pmatrix} 1 \u0026 0 \\\\ 0 \u0026 1 \\end{pmatrix}$ e simili\n5.2.2 Lâ€™inversa della composta dellâ€™identitÃ  (8.2.2) (!!) Si ha che $I_{eb} = I_{be}^{-1}$, ovvero la matrice identitÃ  per certe basi Ã¨ esattamente l\u0026rsquo;inversa.\nQuesto perchÃ© supponendo che le matrici associate si comportano bene per la moltiplicazione, ho che\n$I_{eb}I_{be} = I_{bb} = I$ ovvero Ã¨ l\u0026rsquo;applicazione identitÃ .\nE bisogna anche verificare l\u0026rsquo;inverso quindi $I_{be}I_{eb} = I_{ee} = I$\n5.2.3 Coordinate di un vettore rispetto a una base non canonica Sia v un vettore nel nostro spazio, e sia b una base di Rn allora si ha che\n$(v)_{\\beta} = I_{\\beta e}^{-1}v$.\nPrendiamo in considerazione la matrice $I_{e\\beta}$, allora\n$id(v)_{\\beta} = I_{e\\beta}(v)_e$ per come abbiamo definito la matrice, ossia riusciamo a calcolarci le coordinate di v nella nuova base, utilizzando il teorema di sopra /\n5.2.4 Composizione fra matrici con basi qualsiasi Posso dimostrare che un fatto dimostrato precedentemente si comporta bene anche con basi qualsiasi.\nOvvero vogliamo dimostrare che date le funzioni $F: A \\to B, G: B\\to C$ con ognuna una base, voglio una matrice associata per la composizione di funzioni si comporti bene. (comunque sÃ¬ si puÃ² dimostrare)\n5.3 Il cambio di base L\u0026rsquo;idea principale di questo cambio di base per applicazioni lineari Ã¨ ricondurci a una base voluta, piÃ¹ comoda per i nostri calcoli, quindi passare da qualcosa in mezzo\nQuindi avremo una applicazione lineare del tipo:\n$A_{\\beta\\beta'} = I_{e'\\beta'} A_{ee'}I_{\\beta e} = I_{\\beta'e'}^{-1} A_{ee'}I_{\\beta e}$ ricordandosi che applico le funzioni a destra per prime.\n(da notare che la la matrice $I_{\\beta e}$ Ã¨ molto semplice da calcolare, perchÃ© l\u0026rsquo;insieme di arrivo Ã¨ canonico, e quindi Ã¨ semplice.\n6 Autovalori e Autovettori Ha senso solamente parlare di autovettori quando si ha una applicazione lineare con stesso dominio e stesso codominio.\nVorremmo trovare una buona matrice che sia diagonale.\n6.1 DiagonalizzabilitÃ  6.1.1 Definizione per funzione e matrice Questo perchÃ© vorrei una base in cui si abbia un matrice diagonale. (quindi probabilmente P Ã¨ una matrice identitÃ ).\nPerchÃ© ci piacciono le matrici diagonali\nSe ho una matrice diagonale, si ha che l\u0026rsquo;applicazione lineare Ã¨ un semplice scaling dei vettori della base.\n6.1.2 Matrici simili Date due matrici in uno spazio vetoriale con le matrici, allora se esiste un P nello stesso spazio tale che $B = P^{-1}AP$ si dicono simili (in pratica fare uno scambio di base).\nOsservazione 1\nPosso dimostrare che la matrice $A_{ee'} \\sim A_{bb'}$ associata a una funzione, sono simili per il teorema del cambio di base di sopra\nOsservazione 2\nLa simile, Ã¨ una relazione di equivalenza (riflessivitÃ , simmetria e transitivitÃ )\n6.1.3 DiagonalizabilitÃ  di una matrice quadrata Si puÃ² dire che una matrice quadrata A Ã¨ diagonalizzabile se Ã¨ simile a una matrice diagonale\n(Anche la definizione di sopra Ã¨ uguale (equivalente).\n6.1.4 Equivalenza della diagonalizzabilitÃ  funzionale e matriciale (9.1.4)(!!!) Si ha che una funzione F e la sua matrice associata.\nAllora F diagonalizzabile SSE la sua matrice associata Ã¨ diagonalizzabile.\nDimostrazione\n$\\implies$Supponiamo che la funzione sia diagonalizzabile, allora ho una base per cui si ha una matrice diagonale.\nA questo punto utilizzo il teorema del cambio di base per costruirmi la P voluta per la diagonalizzabilitÃ  (o avere una matrice simile) e ciÃ² finisce.\n$\\impliedby$ Supponiamo che si abbia una matrice diagonalizzabile, allora abbiamo una matrice P che mi dia una matrice diagonale.\nLemma: le righe di P sono linearmente indipendenti. Si dimostra per il teoremone (lâ€™esistenza dellâ€™inversa, implica che Ã¨ associata a una funzione bigettiva, che implica che le colonne sono indipendenti).\nConsidero le colonne di P, queste sono N vettori indipendenti che fanno quindi span sullo spazio vettoriale Rn. Ma allora P Ã¨ proprio $I_{be}$ con b la base definita dalle colonne!\nE quindi ho trovato la base per la funzione tale che sia diagonale, quindi la funzione Ã¨ diagonalizzabile.\n6.1.5 Condizione di diagonalizzabilitÃ  (!!!!) â­ Si puÃ² dire che una funzione F sia diagonalizzabile sse esiste una base di Rn costituita da autovettori di F\nLa dimensione delle due frecce Ã¨ identica (almeno le tecniche lo sono)\nDimostrazione\n$\\impliedby$Sia una base di Rn costituita da autovettori della F. Allora la matrice associata a questa funzione Ã¨ una matrice diagonale per questa base (bisogna fare un pÃ² di conti).\n$\\implies$Sia b una base tale che la matrice associata alla funzione sia diagonalizzabile, allora ho una base per cui la funzione Ã¨ diagonale. Elimino questo esiste con la base beta, voglio dimostrare che siano autovettori.\n6.2 Calcolo degli autovettori e autovalori 6.2.1 Autovalore 0 e kernel (!) $Ker F \\neq 0_v \\iff F$ ha autovalore $0$\nDimostrazione\n$\\implies$ supponiamo che $v \\neq 0_v, v \\in Ker F$ allora $F(v) = 0\\cdot v = 0$, ossia 0 Ã¨ un autovalore.\n$\\impliedby$Supponiamo che 0 sia un autovalore, allora esiste un autovettore (per definizione diverso da 0) allora esiste un elemento diverso da 0 nel kernel, e quindi non Ã¨ iniettiva per una proposizione precedente\n6.2.2 Polinomio caratteristico Nota: si ha che se ho una matrice n x n il polinomio caratteristico ha grado n.\n6.2.3 Autospazio e Polinomio caratteristico (!!!) L\u0026rsquo;autospazio per un certo autovalore Ã¨ questo insieme\n$V_\\lambda = \\{v \\in \\R^n | F(v) = \\lambda v\\}$, ossia Ã¨ l\u0026rsquo;unione dei autovettori con lo zero.\nProposizione:\n$V_\\lambda = Ker(A - \\lambda I)$, con il kernel della matrice definita come le soluzioni del sistema lineare omogoneo associato ala matrice (che poi Ã¨ uguale al concetto della funzione).\nDimostrazione\n$\\implies$Sappiamo che $V_y$ Ã¨ l\u0026rsquo;insieme degli $x \\in R^n| Ax = \\lambda x$ con A la matrice associata la nostra funzione. Vogliamo dimostrare che se $x \\in V_\\lambda$ allora appartiene al kernel, il che Ã¨ abbastanza ovvio per la proprietÃ  distributiva della moltiplicazione matriciale.\n$\\impliedby$Se si ha un v appartenente al kernel, allora poi si ricava (aggiungendo e sottraendo una parte) che $Ax = \\lambda x$ che Ã¨ proprio la condizione sufficiente per appartenere all\u0026rsquo;autospazio\n6.2.4 Polinomio car per Matrici simili (no chiede) Matrici simili hanno lo stesso polinomio caratteristico, questo si dimostra con distributivitÃ  e associativitÃ  della moltiplicazione matriciale.\nDimo\n$A - \\lambda I = P^{-1}BP - \\lambda I = P^{-1}BP - P^{-1}P\\lambda I = P^{-1}(B - \\lambda I) P$\n6.2.5 Condizione dellâ€™autovalore (!!!) Dimostrazione\n$\\iff$Se $\\lambda$ Ã¨ un autovalore, allora ho un autovettore che appartiene all\u0026rsquo;autospazio relativo.\nVogliamo che l\u0026rsquo;autospazio Ã¨ diverso da 0, questo Ã¨ vero sse il sistema lineare (A - lambdaI)x = 0 ha una soluzione non nulla, allora per il teoremone, questo Ã¨ vero sse il determinante della matrice Ã¨ uguale a 0. quindi sse lambda Ã¨ uno zero della nostra matrice.\n6.3 MolteplicitÃ  e autov{ettori, alori} 6.3.1 Autovalori diverse fanno autovettori indipendenti (no chiede) Si dimostra in modo induttivo, partendo da un unico vettore che Ã¨ necessariamente indipendente, saltando per il passo induttivo e finire.\n6.3.2 MolteplicitÃ  geometrica ed algebrica DOmanda da fare alla marta\nIl fatto che la moltiplicitÃ  geometrica Ã¨ minore o uguale alla molteplicitÃ  geometrica potrebbe essere insito nel polinomio caratteristico.\nPerchÃ© al massimo (Ã¨ da dimostrare) che il grado del polinomio caratteristico Ã¨ N, che Ã¨ anche la dimensione della molteplicitÃ  geometrica???\n6.3.3 MoltiplicitÃ  geometrica â‰¤ MolteplicitÃ  algebrica (no chiede) 6.3.4 DiagonalizzabilitÃ  per somma di M-algebrica (no chiede) Si puÃ² dimostrare che Ã¨ un sse. e deve essere che le molteplicitÃ  algebriche e geometriche siano entrambi uguali.\nDim-libro\n!\n7 Registro ripassi e molteplicitÃ  algebriche e geometriche siano entrambi uguali. Dim-libro\n!\n7 Registro ripassi ","permalink":"https://flecart.github.io/notes/cambio-di-base-e-autovalori/","summary":"Ripasso Prox: 7 Ripasso: June 1, 2022 Ultima modifica: October 19, 2022 4:59 PM Primo Abbozzo: April 5, 2022 10:40 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso 5 Cambio di base 5.1 Nozioni da avere prima di Cambio di Base Applicazioni lineari La definizione di applicazione lineare La matrice associata L\u0026rsquo;esistenza e unicitÃ  di una applicazione lineare rispetto a una base Le coordinate di un punto rispetto a una base.","title":"Cambio di Base e Autovalori"},{"content":"Ripasso Prox: 100 Ripasso: June 1, 2022 Ultima modifica: December 25, 2022 9:29 PM Primo Abbozzo: September 21, 2021 7:04 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi da ripassare Notione di Campo ordinato, ciÃ² che rendere (non importante) La dimostrazione che bigettivitÃ  equivale a invertibilitÃ  1 Insiemi Numerici ðŸ’¡ Questa prima parte degli appunti Ã¨ fortemente mancante 1.1 Insiemistica Tutta Questa prima roba di insiemistica Ã¨ fatta molto meglio nel corso di logica, in particolare in questo documento\nTeoria assiomatica degli insiemi\n1.1.1 Definizione e caratteristiche degli insiemi Definizione di Campo ordinato (operazioni fra certi insiemi, sia per la addizione, per la moltiplicazione e simili) Corpo commutativo\nSono definiti somma e moltiplicazione e proprietÃ  come commutativitÃ , associativitÃ , distributiva, inversi, opposti, zero e nullo\nCampo ordinato\nIn un campo ordinato valgono le due proprietÃ \n$$ x \u003c y \\implies x + z \u003c y + z \\newline z\\geq 0,x \u003c y \\implies x z \u003c yz $$ 1.1.2 Simboli per l\u0026rsquo;insiemistica Per ogni, esiste, and, or, tale che, implicazione, e operazione fra insiemi.\n1.1.3 Operazioni fra gli insiemi Addizione, sottrazione sottoinsiemi, complementari, unione intersezione\n1.1.4 Equipotenza Definizione di equipotenza:\nesiste una funzione bigettiva da un insieme a un altro.\n1.1.5 NumerabilitÃ  di Q e Z Dimostrazione equipotenza di N, Q, Z.\n1.2 Binomiali In seguito si utilizzeranno per calcolare i coefficienti dei monomi a seguito di una espansione.\nLa definizione di binomiale Ã¨ fatta per parti (definita per ora solamente da $N^2 \\rightarrow N$)\n1.2.1 Formula somma di combinazione $\\binom{n-1}{k} + \\binom{n-1}{k-1} =\\binom{n}{k}$\nSi fanno i calcoli e si dimostra.\nDimostrazione lasciata al lettore. Coglione angi, aveva fatto una dimostrazione carina, ora 25/12/22 la sto ricercando le non la trovo. vacca troiaâ€¦\nComunque ora ho ritrovato dalle slides\nDimo ritrovata\nvai a considerare n, e un elemento a caso. Si tratta di prendere k elementi da n.\nAllora questo possiamo scomporlo in due casi, nel caso in cui prendo l\u0026rsquo;elemento a caso e nel caso in cui non lo prendo. Se lo prendo allora vado a cercare k - 1 nel resto, se non lo prendo allora nel resto vado a cercare k. ez.\nQuesta osservazione mi Ã¨ ritornata utile perchÃ© lo studio dei dearrangiamenti fa un ragionamento praticamente uguale, stessa idea, applicata in ambito diverso\n1.2.2 Permutazioni e Combinazioni Li sai dai.\n1.2.3 Binomio per l\u0026rsquo;espansione binomiale se ho una scrittura di questo genere:\n$$ (a + b) ^n $$ So che il grado del polinomio che si forma Ã¨ n, e che per ogni monomio, la somma dei suoi pr\n1.3 Alcune dimostrazioni 1.3.1 Teorema di Pitagora Dimostrazione grafica â†’ V Postulato di Euclide\nDimostrazione lasciata al lettore\n1.3.2 Radici di primi in Q Stesso argomento di radice di 2\nDimostrazione lasciata al lettore\n1.3.3 InfinitÃ  dei numeri primi Argomento di Euclide\nDimostrazione lasciata al lettore mi in Q\nStesso argomento di radice di 2\nDimostrazione lasciata al lettore\n1.3.3 InfinitÃ  dei numeri primi Argomento di Euclide\nDimostrazione lasciata al lettore\n","permalink":"https://flecart.github.io/notes/insiemi-numerici/","summary":"Ripasso Prox: 100 Ripasso: June 1, 2022 Ultima modifica: December 25, 2022 9:29 PM Primo Abbozzo: September 21, 2021 7:04 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi da ripassare Notione di Campo ordinato, ciÃ² che rendere (non importante) La dimostrazione che bigettivitÃ  equivale a invertibilitÃ  1 Insiemi Numerici ðŸ’¡ Questa prima parte degli appunti Ã¨ fortemente mancante 1.1 Insiemistica Tutta Questa prima roba di insiemistica Ã¨ fatta molto meglio nel corso di logica, in particolare in questo documento","title":"Insiemi numerici"},{"content":"Ripasso Prox: 2 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: April 28, 2022 4:19 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso 12 Integrali multipli Andremo ad analizzare integrali di funzioni continue su insiemi semplici (domini normali) .\nIntroduzione Y-semplice e regolaritÃ  Ãˆ un insieme semplice di punti, in pratica, se considero un intervallo limitato e due funzioni definite in questo intervallo tale che una Ã¨ sempre minore dellâ€™altra, lâ€™insieme y-semplice sono i punti compresi fra queste\nDefinizione del libro\nIntuizione integrale Definizione del prof.\nDato un insieme semplice A e una funzione continua $f:A \\to R$ allora Ã¨ ben definito lâ€™integrale\n$$ \\int_Af(x, y) dxdy \\in R $$ Osservazione 1:\nSe integriamo la funzione costante 1 possiamo effettivamente trovare lâ€™area di integrazione.\nChe da un concetto di misura dellâ€™insieme di integrazione\nOsservazione 2:\nLâ€™integrale definisce una sorta di sottografico di una funzione, ma a piÃ¹ dimensioni. (in questo caso con insieme di integrazione di dimensione 2 si ha il volume).\nCalcolo tramite riduzione Definizione del libro\nCerco di fare a fettine i punti, cosÃ¬ mi Ã¨ molto piÃ¹ facile calcolare i punti.\nLavagna del prof. (caso y - semplice)\ncaso x -semplice\nSi puÃ² utilizzare un calcolo in modo equivalente ma sta volta partendo prima dalla x, perchÃ© abbiamo definito lâ€™intervallo in funzione della y\n","permalink":"https://flecart.github.io/notes/integrali-multi-dimensionali/","summary":"Ripasso Prox: 2 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: April 28, 2022 4:19 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso 12 Integrali multipli Andremo ad analizzare integrali di funzioni continue su insiemi semplici (domini normali) .\nIntroduzione Y-semplice e regolaritÃ  Ãˆ un insieme semplice di punti, in pratica, se considero un intervallo limitato e due funzioni definite in questo intervallo tale che una Ã¨ sempre minore dellâ€™altra, lâ€™insieme y-semplice sono i punti compresi fra queste","title":"Integrali multi-dimensionali"},{"content":"Ultima modifica: October 12, 2022 4:39 PM Primo Abbozzo: September 21, 2022 4:15 PM Studi Personali: No\nElementi di ripasso Introduzione Il corso verte su questi in slide:\nPercorso standard per risoluzione problema di calcolo numerico Risoluzione del problema nel continuo (quindi vedere se esiste una soluzione dal punto di vista matematico Utilizzo di un algoritmo di metodi numerici Accuratezza Costo computazionale Condizionamento â†’ Errore inerenti Commenti negativi La conversione in binario e decimale giÃ  fatto in architettura non ripetere! Non si puÃ² arrivare a lezione con metÃ  delle slides saltate, ci vuole un minimo di preparazione prima di venire ad insegnare! Saper fare non significa saper insegnare! Non voglio che legga le slides e basta, ma che aiuti anche gli studenti a comprendere ciÃ² che sta spiegando! parazione prima di venire ad insegnare! Saper fare non significa saper insegnare! Non voglio che legga le slides e basta, ma che aiuti anche gli studenti a comprendere ciÃ² che sta spiegando! ","permalink":"https://flecart.github.io/notes/introduzione-calcolo-numerico/","summary":"Ultima modifica: October 12, 2022 4:39 PM Primo Abbozzo: September 21, 2022 4:15 PM Studi Personali: No\nElementi di ripasso Introduzione Il corso verte su questi in slide:\nPercorso standard per risoluzione problema di calcolo numerico Risoluzione del problema nel continuo (quindi vedere se esiste una soluzione dal punto di vista matematico Utilizzo di un algoritmo di metodi numerici Accuratezza Costo computazionale Condizionamento â†’ Errore inerenti Commenti negativi La conversione in binario e decimale giÃ  fatto in architettura non ripetere!","title":"Introduzione Calcolo numerico"},{"content":"Ripasso Prox: 40 Ultima modifica: April 9, 2023 9:36 AM Primo Abbozzo: September 21, 2022 11:15 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Introduzione a SO Intro Scopi del sistema operativo ðŸŸ© Un sistema operativo Ã¨ una astrazione sul HW che permette di\nGestire lâ€™esecuzione di piÃ¹ programmi assieme (concorrenza), tramite virtualizzazione CPU e Memoria Gestire le risorse (Quindi I/O, RAM, Memoria, Networking) Fornisce una interfaccia di programmazione (API) molto piÃ¹ generale e potente, in grado di astrarre da dettagli di livello basso, vicini allâ€™Hardware (come device drivers). Quindi in breve il SO Ã¨ n programma che crea un ambiente civile per i programmi in cui interagire, e facilita molto il lavoro al programmatore per la sua interfaccia nuova. (si potrebbe dire che sia una macchina virtuale con un suo linguaggio (che Ã¨ lâ€™API) se seguiamo la terminologia di Macchine Astratte)\nVantaggi principali ðŸŸ© Col sistema operativo abbiamo ora una astrazione sullâ€™HWche ci permette di interagire con queste in modo molto piÃ¹ facile (molto molto).\nQuindi\nIndipendenza dallâ€™hardware (i dettagli nascosti sotto le interfacce) ProgrammabilitÃ  e comoditÃ  di Uso per le API che sono presenti. Un buon sistema operativo deve essere quindi semplice per lâ€™utilizzo ed efficiente nellâ€™utilizzo delle risorse che ha disponibili.\nSistemi paralleli â†©ï¸ Sistemi paralleli sono dei sistemi che possono eseguire piÃ¹ istruzioni allo stesso momento (quindi hanno piÃ¹ centri computazionali diciamo.\nTassonomia sulla struttura Questo sono stati citati in CPU e storia degli elaboratori.\nSIMD, come le GPU. MIMD, multicore, quelli che ci sono anche nelle GPU. Tassonomia sulla dimensione Basso parallelismo, quando ho poche CPU potenti. Sistemi massicciamente paralleli, ho tante CPU, anche normali. Tipologie di Coupling Tight quando ho CPU su MEMORIA CONDIVISA\nLoose quando ho CPU su memoria privata, che possano comunque comunicare fra di loro.\nAlcune tipologie di sistemi paralleli Symmetric multiprocessing: quando hanno la stessa struttura di dati per ogni processore.\nQuesto rende piÃ¹ semplice un pÃ² la gestione delle strutture di dati, che sono le stesse.\nAsymmetric multiprocessing quando câ€™Ã¨ un unico processo che dÃ  da fare un compito specifico a certi processi (quindi ho una asimmetria\nSistemi realtime Quando il valore di output dipende non solo dal valore, ma anche dallâ€™istante in cui il valore viene prodotto.\nHard and soft real-time Hard quando puÃ² avere effetti catastrofici, come controllo velivoli o Nucleari.\nSoft quando ho solo disservizi.\nVecchia roba Hardware e Software Il professore fa una distinzione molto strana fra software e hardware (ricorda teatrino dei limoni che ha fatto in classe).\nIn soldoni hardware Ã¨ tutto quello che Ã¨ composto da mero hardware. Il software Ã¨ la conoscenza, qualcosa che si distingue molto facilmente perchÃ© Ã¨ facilmetne copiabile, e distribuibile\nInformazione qualche conoscienza che Ã¨ utile. Ha 3 problemi principali\nElaborazione, che risolve il problema della trasformazione di un informazione in un altra forma che possa risultare utile (es bites in suoni che si possono sentire). Memorizzazione che risolve il problema di trattenimento dellâ€™informazione nel tempo. Comunicazione che risolve il problema di comunicazione dellâ€™informazione in due luoghi diversi (protocolli) Cosa fa un informatico secondo il prof. Studia un problema, da una descrizione della soluzione in modo preciso e dettagliato che un calcolatore si ain grado di eseguire la soluzione (e replica questo pensiero umano).\nSulle graffette esempio che ha fatto il prof riguardo le graffette. Afferma in soldoni che la scuola uccida la creativitÃ  perchÃ© si trovano molti meno modi di utilizzare la creativitÃ , e sembra ch ela causa principale di questo sia la scuola. Ma Ã¨ davvero cosÃ¬???\nA me sembra che sia il processo di crescita normale in cui si impara cosa servno di solito a cosa, quindi si spendono meno risorse per cose comuni. Ãˆ una cosa normale nellâ€™essere umano che una cosa comune sia poco interessante. Ãˆ interessante un modo nuovo e utile del suo utilizzo, ma il raggio di soluzioni Ã¨ vasto. Le cose comuni Ã¨ difficile che servano per soluzioni innovative, senza nessuna base: eg. se voglio fare maetematica non vado certo a considerare una graffetta, ci vorrebbero altri episodi serendipici che possano fare una associazione, cosa direi che non accadrebbe mai\n","permalink":"https://flecart.github.io/notes/introduzione-so/","summary":"Ripasso Prox: 40 Ultima modifica: April 9, 2023 9:36 AM Primo Abbozzo: September 21, 2022 11:15 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Introduzione a SO Intro Scopi del sistema operativo ðŸŸ© Un sistema operativo Ã¨ una astrazione sul HW che permette di\nGestire lâ€™esecuzione di piÃ¹ programmi assieme (concorrenza), tramite virtualizzazione CPU e Memoria Gestire le risorse (Quindi I/O, RAM, Memoria, Networking) Fornisce una interfaccia di programmazione (API) molto piÃ¹ generale e potente, in grado di astrarre da dettagli di livello basso, vicini allâ€™Hardware (come device drivers).","title":"Introduzione SO"},{"content":"Ultima modifica: October 19, 2022 5:05 PM Primo Abbozzo: December 14, 2021 4:36 PM Studi Personali: No\nElementi di ripasso 0 pezzo di introduzione 0.1 Modi di vedere (3) Ci sono principalmente 3 modi di vedere l\u0026rsquo;algebra lineare.\nVisione Colonna, visione riga e visione matriciale\n(La seguente Ã¨ una visione riga)\n$$ 2x - y = 0 \\\\ -x + 2y = 3 $$ Questa cosa si puÃ² rappresentare in forma matriciale in questo modo:\n$$ \\begin{bmatrix} 2 \u0026amp; -1 \\ -1 \u0026amp; 2 \\end{bmatrix} \\begin{bmatrix} x \\ y \\end{bmatrix} = \\begin{bmatrix}\n0 \\ 3 \\end{bmatrix} $$\nSi scrive in maniera carina $Ax = b$\n0.1.1 Visione riga Possiamo rappresentare le soluzioni di ogni riga attraverso un grafico n-dimensionale (quindi funziona finchÃ© non andiamo sopra il 3 grado!)\nVedere sopra\n0.1.2 Visione colonna Questa invece vuole chiedere una combinazione lineare ** che mi possa dare una soluzione.\nes:\n$x\\begin{bmatrix} 2 \\\\ -1\\end{bmatrix} + y \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 3 \\end{bmatrix}$\n0.1.3 Obiettivo finale Vogliamo avere delle soluzioni generali per tutte le matrici (si scoprirÃ  che le matrici invertibili ci piacciono,, si scopriranno generatorie simili\u0026hellip;)\n0.2 Eliminazione e Sostituzione Questo Ã¨ il metodo che viene utilizzato dalla maggior parte dei software per risoluzione di sistemi lineari.\n0.2.1 Algoritmo di Gauss (eliminazione) idea principale: Utilizzare dei pivot (la variabile che vogliamo eliminare nelle altre righe che non puÃ² essere nullo) e sottrarre in tutte le altre righe.\nE poi richiamare in modo ricorsivo sulla sottomatrice n - 1, n - 1 perchÃ© tutto il resto era giÃ  apposto.\nIn questo modo abbiamo ottenuto nella diagonale principale tutti i pivot che ci interessano. Chiamiamo questa nuova matrice equivalente U al posto di A\nCaso di fallimento: Fallisce quando esiste un pivot che sia 0 dopo che sia stato utilizzato l\u0026rsquo;algoritmo per bene (prima provo a scambiare righe). Quando sono tutti 0 per una intera sotto-colonna (sotto-colonna perchÃ© potrei anche trovarmi in un sottocaso, non necessariamente nella prima chiamata).\n0.2.2 Sostituzione Una volta che ho ottenuto la matrice U, posso sostituire fino sopra, perchÃ© nell\u0026rsquo;ultima riga ho una equazione a una unica variabile, poi trovata questa posso metterla sopra, sopra ancora finche\u0026rsquo;non finisce.\n0.3 Tipologie di matrici 0.3.1 Matrici di eliminazione Possiamo definire delle matrici per l\u0026rsquo;eliminazione di parti che ci interessano. e possiamo chiamarli matrici $E_{ij}$ con i righa e j colonna. Da questo potrei creare una unica matrice mi faccia tutta l\u0026rsquo;eliminazione in un passo solo.\nData che la moltiplicazione Ã¨ associativa, posso prima fre le molitplicazioni fra le matrici di eliminazione prima.\n0.3.2 Matrici di permutazione Possiamo vedere che la moltiplicazione fra le matrici Ã¨ fortemente non commutativo. Infatti diamo un occhiata alle matrici per invertire righe e colonne.\ne.g.\n$$ \\begin{bmatrix} 0 \u0026 1 \\\\ 1\u00260 \\end{bmatrix} \\begin{bmatrix} a \u0026 b \\\\ c \u0026 d \\end {bmatrix} = \\begin{bmatrix} c \u0026 d \\\\ a \u0026 b \\end{bmatrix} $$ PerÃ²\n$$\n\\begin{bmatrix} a \u0026amp; b \\ c \u0026amp; d \\end {bmatrix}\\begin{bmatrix} 0 \u0026amp; 1 \\ 1\u0026amp;0 \\end{bmatrix} = \\begin{bmatrix} b \u0026amp; a \\ d \u0026amp; c \\end{bmatrix} $$\nUsando la stessa matrice di permutazione.\n0.3.3 Matrici Inverse La matrice inversa Ã¨ trovare una matrice che moltiplicata alla nostra matrice di interesse ritorni una matrice identitÃ .\n0.4 Moltiplicazione delle matrici 0.4.1 Primo modo( Riga per colonna) Questa Ã¨ la definizione generale della moltiplicazione.\nVogliamo trovare il valore di $C_{34}$ creato da una moltiplicazione fra A e B ovvero Row 3 di A e Column 4 di B, prodotto scalare fra questi due.\n$$ c_{mn} = \\sum_{i=0}^k a_{mi} \\cdot b_{in} $$ Deve essere che il numero di colonne di A = numero di righe in B\nMa possiamo anche moltiplicare intere righe e intere colonne invece di guardare in modo singolo!\n0.4.2 Matrice per colonna Guardiamo le colonne della matrice risultato come combinazioni delle colonne del primo. (come combinarle me lo sta dicendo la colonna del secondo operatore.\n0.4.3 Riga per matrice In modo simile alla matrice per colonna, so che ogni riga della matrice di output Ã¨ una combinazione lineare delle righe in B, che viene definito come fare in A.\n0.4.4 Colonna per riga $$ C = \\sum_{i=0}^k A_i \\cdot B_i $$ Con $A_i$ la colonna i-esima e$B_i$ la riga i esima\n0.4.5 A blocchi Spazi vettoriali (vecchio\n0.5 InvertibilitÃ  delle matrici Le matrici invertibili si chiamano non-singolari.\n0.5.1 Non invertibilitÃ  delle matrici singolari Per quelle singolari, sappiamo che lo spazio delle soluzioni Ã¨ nello sottospazio vettoriale della loro combianzione, che semplicemente puÃ² non avere il punto dell\u0026rsquo;inverso.\nFacciamo una dimostrazione per assurdo, assumiamo che esista un vettore che moltiplicato per questa matrice singolare dia un vettore nullo. Allora sappiamo che $Ax = 0$, se esistesse l\u0026rsquo;inverso allora $A^{-1}Ax = Ix = 0 \\implies x = 0$ assurdo.\n0.5.2 Gauss-Jordan Vogliamo trovare la matrice inversa.\nSpazi vettoriali (vecchio\nEsempio di applicazione\n1 Spazi e sottospazi vettoriali 1.1 Introduzione Possiamo identificare due operazioni principali per i vettori. Sommare e moltiplicarli. Vogliamo definire in modo formale il significato di queste due operazioni in un unico oggetto matematico che chiamiamo spazio vettoriale.\n1.1.1 Intuizione di spazio vettoriale Spazio, la parola spazio ha un significato preciso, Ã¨ un insieme di vettori che abbiano una certa proprietÃ ! Ma lo definiremo meglio fra poco.\nUn sottospazio Ã¨ un sottoinsieme dello spazio vettoriale che sia ancora chiuso nelle operazioni di addizione e moltiplicazione scalare.\nSe ragioniamo in R2 notiamo che questi sono sottospazi:\nR2 Stesso Ogni linea che passa per 0,0 Il vettore nullo (sottospazio banale), o anche chiamato sottospazio Z. Direi anche Q2, perÃ² Ã¨ originato da un insieme ben diverso. 1.2 Spazi generati da una matrice Questa parte sarÃ  trattata forse in piÃ¹ dettaglio sotto.\nQui trattiamo la relazione fra matrice e questi spazi.\n1.2.1 Spazio colonna Esempio di lezione\nSpazi vettoriali (vecchio\nVogliamo avere tutte le combinazioni lineari delle colonne! PerchÃ© altrimenti l\u0026rsquo;operazione di somma o moltiplicazione non sarebbe chiusa!\nIn questo caso viene generato un piano (che passa all\u0026rsquo;origine).\nQuesto spazio Ã¨ molto importante perchÃ© una equazione del tipo\nRISOLVIBILITÃ€\n$Ax = b$ Ã¨ risolvibile solamente nel caso in cui $b \\in C(A)$ perchÃ© puÃ² essere solamente una combinazione lineare di A.\nUna altra condizione necessaria Ã¨ che se una combinazione sulle righe di A dÃ  una riga zero, la stessa combinazione deve produrre un zero nella riga corrispondente in b, altrimenti non Ã¨ possibile risolvere lâ€™equazione lineare.\n1.2.2 Spazio riga (?) In modo analogo rispetto allo spazio colonna posso avere uno spazio riga utilizzando le combinazioni lineari di righe.\n1.2.3 Spazio nullo Questo spazio contiene tutti i vettori x che risolvono l\u0026rsquo;equazione (questo Ã¨ molto simile allo spazio riga\n$Ax = 0, x \\in N(x)$ (con 0 vettore di dimensioni volute).\nQuesto spazio puÃ² essere calcolato.\nÃˆ uguale alle combinazioni lineari delle soluzioni delle colonne della matrice in forma echelon per irga (ovvero a scaletta, ridotta).\nOvvero per ogni colonna libera setto una variabile a 1 e tutte le altre a 0, e lo faccio per tutte le colonne libere. A questo punto ottengo delle soluzioni disgiunte. Per ottenere lo spazio nullo mi basta fare la combinazione lineare di queste.\nForma echelon per riga ridotta\nDopo aver ottenuto la forma di echelon, posso tornare sopra (in questo modo)\nSpazi vettoriali (vecchio\n1.3 RisolvibilitÃ  Ax=b Come giÃ  accennato in questa parte, devono esserci certe condizioni soddisfate sulla matrice b affinche ci sia un sistema lineare soddisfacibile. Trovate due in quel momento.\nSpazi vettoriali (vecchio\nLa soluzione particolare Ã¨ la soluzione ponendo le variabili libere come 0\nQuesto Ã¨ un pattern molto ricorrente in matematica, perchÃ© se ho una soluzione, allora posso aggiugnere tutti i vettori presenti nel N(A), tanto, sto aggiungendo uno zero. In questo modo ottengo tutte le soluzioni possibili. (non abbiamo dimostrato che siano tutte quelle!, ma probabilmente si puÃ² fare).\n1.3.1 r = n \u0026lt; m Quando il grado della matrice Ã¨ uguale al numero delle colonne, allora ho solamente la soluzione particolare (che puÃ² anche non esistere). La forma ridotta a riga di echelon Ã¨ solamente la matrice identitÃ !\n1.3.2 r = m \u0026lt; n In questo caso ogni riga ha un pivot. la cosa bella di questo caso Ã¨ che ogni b Ã¨ risolvibile perchÃ© lâ€™unica restrizione sarebbe stata avere una riga nulla!.\nIl numero di variabili libere Ã¨ uguale a n - r.\n1.3.3 r = m = n Questo Ã¨ il caso piÃ¹ carino. La matrice Ã¨ quadrata. Posso avere ogni b nel caso io abbia ogni pivot. Poi non ho nessuna colonna libera quindi ho una unica soluzione. Poi significa che Ã¨ invertibile â‡’ avere ogni pivot.\n1.3.4 r \u0026lt; m, r \u0026lt; n Ã¨ quando la reduced echelon form Ã¨ una matrice lÃ¬ in figura!\nSpazi vettoriali (vecchio\n1.4 Interdipendenza lineare e base (di vettori) Una intuizione della indipendenza di vettori Ã¨ quando uno non si puÃ² scrivere tramite combinazione lineare con altre.\nQuindi\nVettori $x_0, x_1 ... x_n$ se nessuna combinazione da un vettore zero eccetto la combinazione 0. Ossia $c_0x_0 +... +c_nx_n \\not= 0$\nn \u0026gt; m\nNel caso in cui il numero di colonne Ã¨ maggiore del numero di righe, sono sicuro che i vettori non siano indipendenti in quanto N(A) non Ã¨ solo il vettore nullo.\nquindi posso creare questo teorema (che non so come dimostrare lulz):\n$$ \\text{Dati vettori } v_1, v_2,...,v_n \\text{colonne della matrice }A, \\text{ allora sono indipendenti se }\\\\ N(A) = 0_v $$ 1.4.1 Base Una base per uno spazio Ã¨ una seguenza di vettori $v_1, v_2, v_3...,v_n$ tali che\nSono indipendenti fra di loro Riempiono uno spazio (contiene tutte le combinazioni lineari di quello) Riprende lâ€™idea che Ã¨ il sottoinsieme piÃ¹ piccolo che sia ancora uno sottospazio vettoriale. le basi degli spazi possono essere molti, ma hanno tutti lo stesso numero di vettori! Questo fatto non so come si dimostra. PerÃ² mi sta dando informazioni su quanto Ã¨ grande questo spazio, infatti mi sta dando la DIMENSIONE dello spazio.\nLa dimensione di uno spazio Ã¨ il minimo numero di vettori che vanno a costituire una base per lo spazio in questione.\nQuesta dimensione Ã¨ anche uguale al grado della matrice!\nGrado di una matrice = dimensione di uno spazio, ecco che esiste questa strettissima correlazione fra spazio e matrice!\n1.5 i 4 Sottospazi fondamentali Siano le dimensioni della matrice $A, m\\times n$\nQueste sono gli spazi fondamentali della prima parte di algebra lineare.\nCi chiediamo in particolare quale siano le loro dimensioni, e quale sia la base.\nSpazi vettoriali (vecchio\n1.5.1 Spazio colonna $C(A)$ sarÃ  in $R ^m$\n1.5.2 Spazio nullo $N(A)$ sarÃ  in $R^n$\n1.5.3 Spazio riga Questo spazio si ha tramite la transposizione della matrice, $C(A^T)$ sarÃ  in $R ^n$\n1.5.4 Spazio nullo della transposizione (o sinistro) $N(A^T)$ sarÃ  in $R^m$\nOrtogonalitÃ  Due spazi S e T sono ortogonali quando ogni vettore in S Ã¨ ortogonale con ogni vettore in T. (una condizione necessaria Ã¨ che lâ€™unico vettore in comune sia 0v)\nDue vettori o anche spazi, sono ortogonali quando il loro prodotto scalare Ã¨ 0.\nQuesto Ã¨ stato dimostrando facendo dei ragionamenti sul teorema di pitagora a lezione.\nSpazio riga e spazio nullo Questi due spazi sono ortogonali fra di loro. Si puÃ² dimostrare ma non so esattamente come si fa\u0026hellip;.\nSpazi vettoriali (vecchio\nCome si vede in figura, x Ã¨ ortogonale per ongi riga in quanto il prodo prodotto scalare Ã¨ 0, e abbiamo dimostrato che se il prodotto scalare Ã¨ 0 sono perpendicolari.\nSi puÃ² definire il concetto di complementi ortogonali perchÃ© lo spazio nullo contiene tutti i vettori ortogonali allo spazio riga, non solo alcuni!\nNelle situazioni reali ci sono molti noise. ossia ho un sacco di misure per pochi parametri. Vorrei estrarre in qualche modo le informazioni utili, quindi avere una soluzione molto vicina, anche se non esatta.\nVoglio dimostrare che $N(A^TA) = N(A)$, faremo dopo\nvettori ortonormali Questi vettori saranno la base del nostro spazio (saranno fra le basi piÃ¹ carine!) (i calcoli diventano molto piÃ¹ carini, perchÃ© non vanno in underflow o overflow)\nSpazi vettoriali (vecchio\nProprietÃ  che deve andare a soddisfare.\nSpazi vettoriali (vecchio\nCome si puÃ² vedere il prodotto dÃ  la matrice identitÃ , come se Q fosse una matrice quadrata (dato che transpose per quadrata Ã¨ uguale allâ€™inverso, perÃ² qui Q non deve essere per forza un quadrato).\nLa proprietÃ  che ho lâ€™identitÃ  con quella moltiplicazione, mi semplifica molto la vita dei calcoli, in quanto lâ€™equazione della proiezione diventa\n$x = Q^Tb$, semplicemente, senza avere qualcosa in x.\nGram-Schmidt Questo calcolo (in qualche modo comune con lâ€™eliminazione di Gauss) ci permette di avere dei vettori ortonormali partendo da due vettori a casso.\nGram ha contribuito con un ragionamento molto simile alla proiezione, se abbiamo due vettori, vogliamo trovare in qualche modo la proiezione, quella cosa perpendicolare! (dovrei fare un esempio o dimostrazione, ma sono pigro per scriverlo, spero che iol mio me futuro non mi uccida\u0026hellip;)\nSchmidt ha contruibuito alla normalizzazione delle matrici per averle ortonormali.\nMatrici Proiezioni Posso creare delle matrici che mi calcolano delle proiezioni. Queste sono molto importanti perchÃ© lâ€™equazione piÃ¹ vicina risolvibile sarÃ  una sua proiezione su un piano multidimensionale.\nSpazi vettoriali (vecchio\nLa soluzione per trovare quel punto.\ne si trova che\n$$ x = \\dfrac{a^Tb}{a^Ta}, p = ax, P = pb \\implies P = \\dfrac{aa^T}{a^Ta} \\\n\\text{si nota in seguito anche che }\\ P = P^T \\wedge P^2 = P $$\ne si trova che lo spazio colonna Ã¨ proprio lo spazio che sto cercando\u0026hellip; In poche parole viene qualcosa dimoslto carino\u0026hellip;\nFormule importanti Spazi vettoriali (vecchio o lo spazio che sto cercando\u0026hellip; In poche parole viene qualcosa dimoslto carino\u0026hellip;\nFormule importanti Spazi vettoriali (vecchio\n","permalink":"https://flecart.github.io/notes/spazi-vettoriali-vecchio/","summary":"Ultima modifica: October 19, 2022 5:05 PM Primo Abbozzo: December 14, 2021 4:36 PM Studi Personali: No\nElementi di ripasso 0 pezzo di introduzione 0.1 Modi di vedere (3) Ci sono principalmente 3 modi di vedere l\u0026rsquo;algebra lineare.\nVisione Colonna, visione riga e visione matriciale\n(La seguente Ã¨ una visione riga)\n$$ 2x - y = 0 \\\\ -x + 2y = 3 $$ Questa cosa si puÃ² rappresentare in forma matriciale in questo modo:","title":"Spazi vettoriali (vecchio)"},{"content":"Ripasso Prox: 3 Ultima modifica: December 29, 2022 3:24 PM Primo Abbozzo: August 20, 2022 1:31 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Networks Bayesiani Questi network bayesiani sono proprio dei grafi, che permettono una migliore comprensione delle relazioni causali o diagnostici fra le probabilitÃ \nEsempio rete bayesiana\nNote generali Introduzione alla rete classica Una rete bayesiana ci permette di semplificare di molto il calcolo della full disjoint probability table, rendendola in questo modo\nOssia andiamo a utilizzare una probabilitÃ  locale, o sparsa per fare i conti, cosa che semplifica molto, e quindi velocizza il calcolo. v\nConditional probability table Ogni nodo deve avere anche una tabella per i valori di probabilitÃ  condizionale.\nIl mantello di Markov Il mantello di un nodo nell rete Ã¨ lâ€™insieme dei genitori, dei figli, e dei genitori dei figli, costituisce lâ€™insieme per cui il nodo attuale Ã¨ condizionalmente indipendente da tutti gli altri nodi.\nÃˆ una nozione molto forte questa, che ha implicazioni molto profonde, un esempio Ã¨ Karl Friston che lo usa per fare delle argomentazioni forti sullâ€™origine della vita dalla zuppa primordiale.\nRete con variabili continue In cui servirebbe una base di analisi molto forte e anche di probabilitÃ  e statistica (quindi conoscere anche dal punto di vista matematico cosa sia la distribuzione normale etc).\nInferenza esatta Possiamo andare ad utilizzare le reti per calcolare il valore di probabilitÃ  di un evento, in questa parte si vede come.\nPer enumerazione Si va con la classica definizione di probabilitÃ , andiamo a contare tutto, e ciÃ² ci comporta un tempo esponenziale di calcolo.\nPseudocodice\nEliminazione di variabili Con il metodo precedente, puÃ² succedere che facciamo lo stesso calcolo molteplici volte, questa Ã¨ una chiarissima inefficienza. Si puÃ² risolvere facendo una eliminazione di variabili in modo tale:\nPseudocodice\nAlgoritmi di clustering Lâ€™idea principale di questo Ã¨ raggruppare dei nodi in un nodo piÃ¹ grosso.\nEsempio di clustering\nSampling (inferenza approssimata) ora andiamo ad utilizzare un metodo di monte carlo, che abbiamo visto per la prima volta (se non câ€™Ã¨ Ã¨ perchÃ© sono stato pigro e non lâ€™ho scritto) in Adversarial Search.\nPraticamente andremo a fare sampling di un evento tante volte, e cercheremo di carpirne delle informazioni con cui aggiornare il nostro modello.\nSampling diretto (classico)\nSampling con rifiuto Se non Ã¨ consistente con il modello di probabilitÃ , allora rifiuta un assegnamentoâ€¦\nImportance sampling Simulazione con catene di Markov ","permalink":"https://flecart.github.io/notes/bayesian-networks/","summary":"Ripasso Prox: 3 Ultima modifica: December 29, 2022 3:24 PM Primo Abbozzo: August 20, 2022 1:31 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Networks Bayesiani Questi network bayesiani sono proprio dei grafi, che permettono una migliore comprensione delle relazioni causali o diagnostici fra le probabilitÃ \nEsempio rete bayesiana\nNote generali Introduzione alla rete classica Una rete bayesiana ci permette di semplificare di molto il calcolo della full disjoint probability table, rendendola in questo modo","title":"Bayesian Networks"},{"content":"Introduction Ãˆ una cosa ormai risaputa che c\u0026rsquo;Ã¨ una sorta di trade-off fra la varianza e il bias per una certo modello. Aumentare la varianza del modello certamente ci permetterÃ  di avere un modello che abbia un errore di training molto basso, perÃ² appena vede dei dati nuovi non sarÃ  in grado di generalizzare correttamente. Dall\u0026rsquo;altra parte avere un bias alto significa avere un modello eccessivamente semplice, poco flessibile, che comunque allenato non riesce ad avere una grande accuratezza nÃ© in fase di allenamento, nÃ© di in fase di validazione o di test.\nMathematical decomposition Si puÃ² derivare una decomposizione di questo trade-off da un punto di vista matematico, quanto enunciato Ã¨ dimostrato nel capitolo 8.1.1 delle Note di andrew NG 229 stanford proviamo a descrivere in modo molto leggere questo presente in quelle note in questo luogo. TODO: riscrivere la derivazione, una volta che l\u0026rsquo;hai compresa e capita\nDall\u0026rsquo;espressione matematica, deriviamo che anche nel caso in cui riusciamo ad eliminare del tutto la varianza e il bias, rimarrebbe l\u0026rsquo;errore irriducibile di cui abbiamo parlato in Introduction to statistical learning.\nConsiderazioni generali Questo trade-off Ã¨ nato principalmente nell\u0026rsquo;analisi teorica dei modelli, perÃ² Ã¨ bene tenere in mente la presenza di ciÃ² anche per i modelli reali. Non possiamo calcolare esplicitamente il MSE, perÃ² ci dovrebbe essere. Questa Ã¨ l\u0026rsquo;osservazione principale per asserire che non sempre il modelli piÃ¹ complicato Ã¨ la migliore, abbiamo il no-free-lunch theorem!\n","permalink":"https://flecart.github.io/notes/bias-variance-trade-off/","summary":"Introduction Ãˆ una cosa ormai risaputa che c\u0026rsquo;Ã¨ una sorta di trade-off fra la varianza e il bias per una certo modello. Aumentare la varianza del modello certamente ci permetterÃ  di avere un modello che abbia un errore di training molto basso, perÃ² appena vede dei dati nuovi non sarÃ  in grado di generalizzare correttamente. Dall\u0026rsquo;altra parte avere un bias alto significa avere un modello eccessivamente semplice, poco flessibile, che comunque allenato non riesce ad avere una grande accuratezza nÃ© in fase di allenamento, nÃ© di in fase di validazione o di test.","title":"Bias Variance Trade-off"},{"content":"Ripasso: May 19, 2023 Ultima modifica: June 19, 2023 9:32 PM Primo Abbozzo: March 6, 2023 3:14 PM Studi Personali: No\nElementi di ripasso Cascading Style Sheets Inizialmente HTML era per la presentazione, abbiamo ancora un pÃ² di attributi storici e tag storici per questa parte di presentazione descritto in HTML e Markup.\nIntroduzione Ãˆ un linguaggio indipendente per la descrizione della grafica. La cosa bella Ã¨ iil fatto di essere indipendente, quindi Ã¨ adatto a HTML, a XML e simili.\nUna cosa particolare Ã¨ il cascading quindi il fatto che dichiarazioni piÃ¹ nuove sovrascrivano o espandino dichiarazione vecchie.\nLivelli di CSS (cose storiche)\nSulla sintassi Statements Slide struttura dei statements\nLa sintassi classica di uno statements CSS Ã¨ in\nproprietÃ : valore;\nE il problema per uno sviluppatore Ã¨ conoscere cosa fa una proprietÃ  e che esista ðŸ˜€\nSelettori (!!) Slides selettori\nTipologia del markup e.g. h1 Selettore di classe e.g. .class Selettore di ID e.g. #id Slides selettori 1 pseudo elementi\nFirst letter (utilizzati per il capolettera nei testi vecchi. first Line Before, after sono aree, che normalmente sono vuote, riempibili con content Esempio hover, active e molte altre! https://developer.mozilla.org/en-US/docs/Web/CSS/Pseudo-elements Selettori di prossimitÃ \nFiglio di un elemento Elemento figlio diretto. Successivi Tutti i successivi Selettori di attributi\nSelettori pseudo classi strutturali\nPotrebbero essere classi ma non lo sono davvere le pseudoclassi.\nSelettori pseudoclassi\nQui ci sono molti altr icontenuti https://developer.mozilla.org/en-US/docs/Web/CSS/Pseudo-classes\nTipi di dato Come numero o valori assoluti (e.g. col z index, o se non specifico sono dei pixel che Ã¨ pericolosa perchÃ© cambia da device a device il feeling che si avrÃ , la dim dei pixel cambia!) o misure di lunghezza che sono moltissime per CSS, vedi slide\nSlide per tipi di misura\nE per i colori, come Ã¨ giÃ  stato citato in HTML e Markup :\nSlide tipi di dato per colori\nCanvas e Viewport Il canvas Ãˆ una area di dimensione indefinita che si amplia secondo necessitÃ . Cresce verso destra o verso il basso. Solitamente su screen Ã¨ sempre il pixel l\u0026rsquo;unita principale, ma questo dipende dalla risoluzione degli schermi e grandezza di essi! (anche le stampanti hanno scalabilitÃ  diverse).\noffscreen drawing Ã¨ una strategia per disegnare e mostrarti solamente quando il risultato Ã¨ pronto. Si disegna su coordinate negative, che non sono visibili, e poi quando Ã¨ pronto copiartela in coordinata positivia.\nViewport Ã¨ la parte visibile dello schermo. Solitamente su schermi PC ho una grandezza a piacere, Ã¨ solamente una cosa che interessa principalmente ai cellulari questo viewport. esiste il tag viewport come suggerimento, ma meglio non avere le misure di pixel.\ncasi in cui Ã¨ ok fare pixel:\ndire 0 pixel per dire che non lo voglio mostrare nello schermo dire 1 pixel per avere la cosa piÃ¹ fine che possono avere UnitÃ  di misura di viewport Sono vh e vw che rappresentano la width e height, nel pC Ã¨ la dimensione della finestra, pe ri cellulari Ã¨ sempre lo schermo massimo.\nesistono anche cose come vmin e vmax che sono il piÃ¹ piccolo fra vm e vh, e il massimo, quindi utilizzo questi per sopravvivere al cambio di oreintamento per lo smartphone.\nIl flex Ãˆ la misura dello spazio rimasto nel contenitore. Ãˆ solo una cosa che mi permette di calcolare piÃ¹ velocemente le dimensioni, senza che debba andare io a guardarlo.\nSlide misura del flex\nSistema a scatole (flexbox) Ogni elemento ha una scatola che contiene l\u0026rsquo;elemento, e se un elemento sta all\u0026rsquo;interno allora la scatola esterna conterrÃ  lâ€™elemento al suo interno\nFlussi, display Slide flussi\nPer la nostra concezione occidentale questi flussi corrispondono al nostro modo di scrivere.\nSolitamente se non voglio fare qualcosa di particolare non vado a specificarlo, ogni tag ha giÃ  un suo display proprio.\nElementi della scatola (4) Margine\nBordo\nPadding\nContenuto\nSlide Scatola\nSlide tipografia per la scatola\nFlexbox c\u0026rsquo;Ã¨ moltissima altra roba sul flex box ma per ora non sono citati. Ãˆ molto flessibile e si riesce ad adattare in modo dinamico a molte cose.\nMentre Grid assumeva di avere un coso fisso.\nPosizionamento della scatola Slide Position\nSlide float, left, top, bottom, right\nZ-index\nstatico Ã¨ il default\nAssoluto Ã¨ dipendente dal canvas senza tenere conto del flusso\nRelativo Ã¨ relativo alla sua posizione naturale\nfisso Ã¨ relativo alla viewport.\nsticky resta in viewport quando proviamo ad uscire, altrimenti resta in canvas nella sua naturale.\nOltre position abbiamo anche altre proprietÃ , che puoi esservare in slide.\nOverflow (3) Overflow\nVisible quando tutto il testo di overflow Ã¨ visibile Hidden quando l\u0026rsquo;overflow non si vede ed Ã¨ nascosta. scroll quando Ã¨ scrollabile, e la parte di scroll toglie spazio al testo, e sono diverse nei sistemi operativi ste scrollbar, mentre in smartphone non esistono. Il display Slide display\nFonts famiglia\nPeso e stile\nFonts preesistenti\nDecorazioni e spazi\nAltre proprietÃ  di CSS EreditarietÃ  Display e background non sono ereditati Il resto si eredita sempre. Important Allora quanto caricato non viene modificato da riscritture successive.\nOrdine di cascata Slide ordine di cascata\nslide ordine 2\nNormali: che non sono important.\nElementi di Tipografia (non fare) Introduzione Graphic design Slide riguardo storia del graphic design\nStoricamente era fatta da emanuense che copiava tutto, questo lo sai, poi quando Ã¨ stato inventato la stampa si Ã¨ creato il nuovo mestiere del tipografo, in cui ci sono una serie di caratteri standarizzati che vengono utilizzati come struttura standard.\nDivisi in 3 sezioni principali:\nTipografia Layout (organizzazione della pagina) Organizzazione iconografica (visual art della pagina diciamo) Tipografia La tipografia Ã¨ la disposizione armoniosa di tipi (forme di caratteri precostituite) al fine di creare testo leggibile e piacevole alla vista sulla pagina e sugli schermi digitali. Si distingue dalla calligrafia, che Ã¨ l\u0026rsquo;armoniosa disposizione sulla pagina di caratteri scritti a mano ed individualmente.\nInizialmente era fatto con legno incavato, ma questo si rovinava molto infretta ed era molto difficile da fare. Gutemberg ebbe l\u0026rsquo;idea di farlo in piombo, utilizzando forme ben definite uguali fra di loro.\nQuesto Ã¨ fatto in modo da mantenere un buoon grigio tipografico, ossia equilibrio fr aspazio bianco e stampa in nero.\nFino in questo periodo era molto difficile creare periodici e avere stampa. Questo fino a quando linotype (line of type) che Ã¨ in grado di generare al volo la lettera di piombo dopo un tasto. Ebbe un buon successo, azienda americana. Ecco qui che si possono fare i quotidiani. (il problema Ã¨ che Ã¨ rumoroso, pericoloso per i fumi di piombo e il calore. etc, non Ã¨ una cosa da ufficio).\nMeccanismi fotosensibili\nQuesta Ã¨ una stampa automatica che utilizzano un fenomeno fisico e una carta fotosensibile, questa Ã¨ l\u0026rsquo;industria di stampa a freddo, ossia cold type. E in questo periodo nasce l\u0026rsquo;informatica, e nacque lâ€™idea di controllare automaticamente questo processo con un programma.\nMarkup languages\nQuesti sono linguaggi nati per controllare le macchine per la stampa a freddo, escono linguaggi come GML, oppure POSTSCRIPTS di Adobe, al tempo una piccola startup di Silicon valley, che poi inventa anche i PDF (versione indipendente dallâ€™hardware, semplificato e molto portabile a differenza di postscript). Questo aiuta la crezioen di desktop publishing, quindi facile da stampare una volta disegnato sul computer.\nFont Collezzioni di carattere con un certo stile che si possano disporre in modo armonioso. (solitamente per lettere, punteggiatura e numeri).\nFont family e font type Un font Ã¨ una collezione di forme di caratteri integrate armoniosamente per le necessitÃ  di un documento in stampa\nUn type face (o font-family) Ã¨ uno stile unico di caratteri che viene espanso in molti font di dimensione e peso e stili diversi.\nTipologie di font (5) Solitamente i font sono una arte occidentale, câ€™Ã¨ molta meno teoria per i font delle altre culture.\nSlide tipologie di font\nClassificazione di Font (non farlo) Slide classificazioen francese Vox Atypl\nSlide classificazione Novarese\nLe componenti fondamentali di un font: (tanti modi per valutare!)\nCap Serif or sans serif The strokes Ascender or descenders height or x-height (altezza media delle lettere, di solito la x). Letter spacing or kernel Slide componenti fondamentali\nBisogna fare distinzione fra stili e pesi, solitamente l\u0026rsquo;italico Ã¨ diverso dal normale, non Ã¨ solamente lâ€™obliquo (il normale leggermente inclinato) e posso avere grandezze (aka pesi) diversi che mi vanno a determinare quanto sono bold.\nBlocchi\nSono una organizzazione del testo, che puÃ² essere di tanti tipi.\nCi sono certe cose che i tipografi non piaccino come vedove, caccole di mosca, orfani, rivoli o header separati, bandiere\nColore Cosa che mi ha stupito Ã¨ che l\u0026rsquo;occhio proprio riesce a percepire solamente 3 colori differenti (wavelengths) che poi vengono interpretati in modo differente).\nSlide spazi di colore\nRGB e RGBa Sono una forma di colore additivo con un canale di Alpha. Se metto tutti i colori ho il bianco. Solitamente questo non Ã¨ una cosa lineare.\nSlide RGB\nCYMK Sono dei colori Sottrattivi, quindi aggiungendo tutti ottengo il Nero. Nella pratica il quarto colore Ã¨ necessario, anche se non lo sarebbe nel senso teorico (avrei un marrone strano senza il nero, ).\nSlide CYMK\nPage Layout Un altro componente molto importante del design Ã¨ il layout, ossia una\nPage layout Ã¨ la disposizione aromoniosa degli elementi visuali sulla pagina.\nUn pÃ² di storia Storicamente alcuni elementi come la spessore delle pagine era molto importante (perchÃ© questo implicava la visibilitÃ  o meno del carattere dallâ€™altra parte della pagina.) Una carta di lusso era importante lo spessore, la ruviditÃ .\nAnche lacuni problemi riconducibili ad affiancamento di pagine, che potrebbero dare un altro significato. Quindi importante andare anche a controllare il contenuto intorno.\nAspetti di Page Layout (6) ORIENTAMENTO\nSlide orientamento\nStoricamente i computer sono sempre stati landscape, cosÃ¬ come erano i video del cinema. Con lâ€™arrivo dei cellulari abbiamo cominciato a preferire lâ€™orientamento portrait. A livello naturale circ a 10 pollici câ€™Ã¨ uno switch.\nQuesto Ã¨ importante perchÃ© a seconda del nostro target decidiamo il layout.\nASPECT RATIO\nSlide aspect ratio\nCi dice il rapporto fra altezza e larghezza. E ce ne sono molti di aspect ratio.\nIl quadrato non Ã¨ mai stato utilizzato in editoria, ma solamente in opere dâ€™arte carine. US letter Ã¨ la carta delle stampanti, anche quello per le lettere di mail 4/3 Ã¨ quello dei film, fino ai 2002. 11/8 poi Ã¨ messa bandina nera sopra e sotto per essere adatta a 4/3 Holliwod ISO216 Ã¨ la carta A4 e ha certe proprietÃ  particolari 16/10 Ã¨ il rapporto classico dei computer, molto vicino al rapporto aureo. US Legal Ã¨ una carta un pÃ² piÃ¹ lunga utilizzata nella pubblica amminsitrazione 16/9 sono schermi allungati, utili per TV nuove. Molto bello quando ho dei panorami nei film, quindi schermo cosÃ¬ meglio. 18/9 Per smartphone, perchÃ© per le dita non mi conviene allungarl inellâ€™altro verso, quindi meglio farli lunghi. Altre su ragionamenti simili. DIMENSIONI\nDimensione\nIl fatto che sia radice, Ã¨ molto importante perchÃ© ci permette di duplicare con due fogli. Si parte con A0 che Ã¨ un metro quadro.\nRISOLUZIONE\nSlides risoluzione\nSe siamo ancora in ambiente anglossassone, utilizziamo come unitÃ  di misura il pollice. Normalmente Ã¨ di densitÃ  (importante soprattuto per la stampa digitali), ma attualmente Ã¨ il valore assoluto di pixel nello schermo.\nGRIGLIE DI LAYOUT\nSlides griglie\nLo scopo principale dei Layout Ã¨ allineare in maniera bella. Solitamente il numero bello Ã¨ 12, perchÃ© si possono creare dei bei rapporti, infatti anche twitter boostrap utilizza questo formato.\nUna griglia puÃ² essere densa o con molto spazio, in questo caso si dice che le celle hanno breathing.\nSEZIONE AUREA\nSlides sezione aurea\nÃˆ un rapporto che sembra molto carino.\n","permalink":"https://flecart.github.io/notes/css/","summary":"Ripasso: May 19, 2023 Ultima modifica: June 19, 2023 9:32 PM Primo Abbozzo: March 6, 2023 3:14 PM Studi Personali: No\nElementi di ripasso Cascading Style Sheets Inizialmente HTML era per la presentazione, abbiamo ancora un pÃ² di attributi storici e tag storici per questa parte di presentazione descritto in HTML e Markup.\nIntroduzione Ãˆ un linguaggio indipendente per la descrizione della grafica. La cosa bella Ã¨ iil fatto di essere indipendente, quindi Ã¨ adatto a HTML, a XML e simili.","title":"CSS"},{"content":"Ripasso Prox: 40 Ripasso: June 10, 2023 Ultima modifica: April 22, 2023 11:38 AM Primo Abbozzo: March 2, 2023 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Expressiveness of NN The perceptron Slide summary of working of perceptron\nNote on the bias: it is only useful to move the treshhold where to consider the output to be 1 and where to be 1.\nNow we ask what can be predicted by a perceptron?\nHyperplanes Hyperplanes, because that equation is an hyperplane, so we are sure that we can predict an hyperplane, and that it, and itâ€™s only it. (itâ€™s predicting wheter it can be above or below that line).\nÃˆ molto peculiare che questa struttura predica qualcosa di tanto semplice! Ãˆ solamente quella roba, perchÃ© basta interpretarla come la linea nel piano, si potrebbe forse dire che esiste un isomorfismo fra percettrone e iperpiano in Rn, dove n Ã¨ la dimensione di input!\nLogical operators We can predict NAND operators, because we can create a plane to divide that, but we canâ€™t say the same of XOR operators.\nSlide predicting the NAND\nIf we try to predict XOR, we can see that his graph is\nWe can see that a line canâ€™t be predicting this function, so we can say that perceptron is not COMPLETE. canâ€™t predict every function, and we can say itâ€™s not enough expressive.\nBad thing because for example perceptron canâ€™t be predicting some kind of pixels put in that configuration, if we interpret the preceding image as pixel colors. Itâ€™s useless (gives me no new information) when we have to compare two features, because this implies it is not linear!\nMultiplayer Perceptron With the preceding idea, if we can compose nands, we can compute every logical cirtuit, this is the same idea behing the completeness of MLP, this can compute everything! (even two layers is enough using this NAND analogy!)\nSlide XOR prediction with MLP\nShallow networks are COMPLETE after this argument. (but with deepness we would need less neurons (maybe exponentially less, with an argument based on CNF exponential explosion when they are not so deep)!, so deepness has some advantages).\nContinous case Can we compute a continous function as precisely as we want with a neural network?\nAt the end yes! Even with single hidden layer NN! The argument is based on step function activation (and the ability of sigmoid or other non linear functions to mimic the step function when we have the right weights). We can add or subtract an arbitrarily small function, with a value as small as we want!\nSee this for more information!\nWe should not be surprised by this expressiveness, also a big table of numbers would be able to aproximate quite well some functions, to an arbitrarily precise fascion.\n","permalink":"https://flecart.github.io/notes/expressiveness-of-nn/","summary":"Ripasso Prox: 40 Ripasso: June 10, 2023 Ultima modifica: April 22, 2023 11:38 AM Primo Abbozzo: March 2, 2023 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Expressiveness of NN The perceptron Slide summary of working of perceptron\nNote on the bias: it is only useful to move the treshhold where to consider the output to be 1 and where to be 1.\nNow we ask what can be predicted by a perceptron?","title":"Expressiveness of NN"},{"content":"Ripasso: May 19, 2023 Ultima modifica: May 11, 2023 8:38 PM Primo Abbozzo: May 5, 2023 2:21 PM Studi Personali: No\nMetadati web https://csunibo.github.io/tecnologie-web/lucidi/teoria/23-metadati.pdf https://csunibo.github.io/tecnologie-web/lucidi/teoria/24-a-web-semantico-lod-rdf-json-ld.pdf\ninconfrontabilitÃ  del sapere Stessa informazione in forme diverse Stessa parola per cose diversa. Serializzazione La semantica Ã¨ relegata alle applicazioni che devono decidere in che modo interpretarli, oppure esseri umani.\nPICS Platform for Internet Content Selection vuole cercare di tenere sotto controllo i materiali del film. Ãˆ un sistema di rating. â†’ tanti criteri di classificazione a seconda dei criteri ideologici su cui voglio andare a basarmi.\nClassificare e categorizzare, non`e una cosa centralizzata da parte di un governo. Fonte terza, non Ã¨ nÃ© l\u0026rsquo;usufruitore ne il creatore â†’ metadati = dati sui dati. Metadati Slide medatati\nvantaggi e svantaggi\nTesauri e tassonomie Si parla di gerarchizzazione e di relazione fra parole dello stesso livello\nTassonomia linneo Esempio di tassonomia La cosa che generalizza Esempi di relazioni has_a is_a instance of Classificazione a faccette possibilitÃ  di descrivere un oggetto complesso attraverso un insieme di affermazioni appartenenti ad uno schema fisso di proprietÃ , ciascuna delle quali in grado di usare valori da un apposito tesauro.\nOntologie Vocabolario controllato Organizzato in thesaurus Una ontologia Ã¨ un sistema di classi, descritta da proprietÃ  che hanno valori puri o riferimenti ad istanze di altre classi (credo che questa cosa sia molto simile anche in database o simili).\nCritica alle ontologie\nComplessivamente, sono un approccio costoso, ingessato, non democratico, centralizzato e riduzionistico.\nFolksonomie Semantic web Resource description framework - RDF Sono delle triple soggetto predicato e oggetto, e posso creare degli alberi che sembrano delle tassonomie a riguardo.\nUna cosa interessante Ã¨ che tutto Ã¨ identificato da URI, nomi, predicati e oggetti, a volte ci sono degli elementi vuoti chiamati blank nodes.\nbisogna distinguere questo formato di triple con il formato di serializzazione che Ã¨ la forma in cui sono rappresentati sottostante.\nProblema delle relazioni n-arie Reificazione ðŸŸ¥ La differenza principale con la modellizzazione a relazione n-aria Ã¨ che il blank era il soggetto e tutti erano oggetti di questo, mentre ora ogni cosa puÃ² essere soggetto oppure oggetto. In particolare rdf:statement sub, pred, obj, ci sono sempre queste predicati per la reificazione.\nSlide reificazione\nMa ha un problema per i databases perchÃ© non vengono trovati le relazioni soggetto - predicato - oggetto classici.\nNamed graph Slide named graph\nossia ho sempre delle triple, ma queste sono messe a livello differente.\nSerializzazioni Serializzazione significa dare una sintassi per andare a descrivere le informazioni di rdf in modo che sia possibile metterli in database.\nTurtle RDF/XML JSON-LD Generazione di conoscenza utilizzare il database RDF per andare a generare nuove informazioni Andare a verificare la coerenza delle informazioni che abbiamo giÃ  RDF schema Ãˆ l\u0026rsquo;insieme dei concetti possibili per un certo RDF.\nSlides rdf schema\nWeb Ontology language (OWL) SPARQL ","permalink":"https://flecart.github.io/notes/metadati-web-e-web-semantico/","summary":"Ripasso: May 19, 2023 Ultima modifica: May 11, 2023 8:38 PM Primo Abbozzo: May 5, 2023 2:21 PM Studi Personali: No\nMetadati web https://csunibo.github.io/tecnologie-web/lucidi/teoria/23-metadati.pdf https://csunibo.github.io/tecnologie-web/lucidi/teoria/24-a-web-semantico-lod-rdf-json-ld.pdf\ninconfrontabilitÃ  del sapere Stessa informazione in forme diverse Stessa parola per cose diversa. Serializzazione La semantica Ã¨ relegata alle applicazioni che devono decidere in che modo interpretarli, oppure esseri umani.\nPICS Platform for Internet Content Selection vuole cercare di tenere sotto controllo i materiali del film.","title":"Metadati web e web semantico"},{"content":"Introduzione ai modelli lineari Processi di sviluppo Definizione Lâ€™insieme strutturato di attivitÃ , eventi, documenti e procedure necessari per la costruzione di un sistema software\nCosa viene descritto (4) ðŸŸ© Questo Ã¨ proprio quanto vuole studiare l\u0026rsquo;ingegneria del software -\u0026gt; metodi di sviluppo, in modo da portare i migliori risultati possibile.\nNella formazione classica va a definire 4 concetti (soprattutto utili nel lavoro di gruppo, al fine di comunicare nella maniera piÃ¹ efficace):\nChi fa Cosa viene fatto Quanto la fa Come la fa In breve si vanno a definire l\u0026rsquo;attivitÃ  di persone che collaborano allo sviluppo di un software, informazioni come: In che modo lavorano? Quali sono i ruoli e le responsabilitÃ  di ognuno? Come valutare la qualitÃ  del lavoro? Quali documenti produrre? Ciclo di vita del software ðŸŸ¨ Trattando il software come una entitÃ  viva, sono tutte le parti che partono dalla creazione fino alla sua morte, ossia dismission.\nFasi della vita, da ideazione, sviluppo, rilascio, mantenimento e deprecazione.\nAndiamo a capire quali sono i metodi principali\nAltre note Legge di Conway ðŸŸ¨+ Le organizzazioni che progettano sistemi ne progettano la struttura riproducendo le proprie strutture comunicative (es. lâ€™organigramma)\nRiformulando in qualche modo: l\u0026rsquo;architettura del prodotto finale rispecchierÃ  il modo con cui i creatori hanno comunicato fra di loro. Ossia alcune proprietÃ  del sistema vengono influenzate dal processo di costruzione. Quindi non Ã¨ trasparente questa parte, almeno Ã¨ molto difficile renderlo tale.\nEsempio:\nse 4 team collaborano a costruire un compilatore, la struttura finale sarÃ  su 4 processi in pipeline\nLegge di Brooks Aggiungere personale ad un progetto sw in ritardo lo farÃ  ritardare ancora di piÃ¹\nPerchÃ© in altri campi aggiungere uomini lo fa andare piÃ¹ in fretta, ma nel nostro caso rallenta, perchÃ© dovrÃ  esserci tempo per insegnare le conoscenze necessarie per cominciare.\nSoftware come processo sociale ðŸŸ© Data l\u0026rsquo;osservazione di sopra, Ã¨ chiaro che il processo di sviluppo Ã¨ fortemente influenzato dai processi di comunicazione interni, che sono un aspetto puramente sociale di questa disciplina. Ecco che entra in gioco questo aspetto delle persone e della comunicazione. Dall\u0026rsquo;altro lato, se la costruzione ha un aspetto sociale in sÃ©, anche l\u0026rsquo;effetto ha una parte sociale. Guarda per esempio i social, hanno cambiato radicalmente il nostro modo di comunicazione fra persone. (un esempio sulla slide Ã¨ la banca per esempio)\nModello di processo software (4) (!) ðŸŸ© Insieme di processi software che provano a catturare un punto di vista specifico il processo software\nTODO: approfondire? Sembra molto stupido Esempi di modelli Waterfall ðŸŸ© Questo Ã¨ uno dei modelli di processo piÃ¹ vecchi (ormai in disuso per il software), Ã¨ un processo lineare.\nEsempio sviluppo classico Una osservazione principale Ã¨ che alcuni ruoli sono fermi in certi momenti del waterfall, per esempio lo sviluppatore dovrebbe aspettare di ricevere le specifiche sviluppate dall\u0026rsquo;architetto, che deve sapere ciÃ² che il cliente vuole dal business analyst.\nPositive e negative di waterfall ðŸŸ©- Chiara definizione dei requisiti fino all\u0026rsquo;inizio Feedback solamente finale dal cliente. Fasi bloccanti Il problema principale Ã¨ che il mercato cambia piÃ¹ velocemente dello sviluppo, quindi altra probabilitÃ  che il requisito cambi prima della fine dello sviluppo. Per il software questo non sembra proprio una strategia buona per dire! ","permalink":"https://flecart.github.io/notes/modelli-lineari-di-sviluppo/","summary":"Introduzione ai modelli lineari Processi di sviluppo Definizione Lâ€™insieme strutturato di attivitÃ , eventi, documenti e procedure necessari per la costruzione di un sistema software\nCosa viene descritto (4) ðŸŸ© Questo Ã¨ proprio quanto vuole studiare l\u0026rsquo;ingegneria del software -\u0026gt; metodi di sviluppo, in modo da portare i migliori risultati possibile.\nNella formazione classica va a definire 4 concetti (soprattutto utili nel lavoro di gruppo, al fine di comunicare nella maniera piÃ¹ efficace):","title":"Modelli Lineari di sviluppo"},{"content":"XOR operation Ãˆ una operazione binaria abbastanza semplice perÃ² ci sarÃ  importante per andare ad analizzare dei cifrari di un certo genere. Come il ONE TIME PAD che faremo fra poco in OTP and Stream Ciphers.\nTeorema cifratura con XOR Prendiamo $X$ una variabile aleatoria in $\\left\\{ 0,1 \\right\\}^{n}$ uniforme, sia $Y$ una variabile aleatoria su uno stesso dominio come vogliamo. Tali per cui $X, Y$ siano indipendenti Allora avremo che $C = X \\oplus Y$ Ã¨ una variabile aleatoria uniforme.\nQuesto Ã¨ necessario per la sicurezza di OTP. Dimostrazione: Supponiamo $n=1$ poi credo si possa estendere a $n$ piÃ¹ grande senza troppi problemi: $$ \\mathbb{P}(C=0) = \\mathbb{P}((X,Y) = (0,0)) + \\mathbb{P}((X, Y) =(1,1)) = \\frac{p_{0}}{2} + \\frac{p_{1}}{2} = \\frac{1}{2} $$ Quindi $\\mathbb{P}(C=1) = \\frac{1}{2}$ e si continua provando ad aggiungere parti.\nOne Time Pad Cipher Inventato da Vernam 1917. e 1926 sempre lui, infatti questo Ã¨ il cipher che Ã¨ nella teoria veramente unbreakable! Lo ha chiamato BSS = Binary Symmetric source, vedi: https://cs.ioc.ee/yik/schools/win2006/massey/slides1.pdf\nDescrizione del cipher ðŸŸ© Prendiamo $K, M, C \\in \\left\\{ 1, 0 \\right\\}^{n}$ Allora $$ E(k, m) = k \\oplus m $$ e decrittazione diventa $$ D(k, C) = k \\oplus C $$ La cosa importante Ã¨ che $k$ Ã¨ usato solo una volta, altrimenti ho problemi di sicurezza molto importanti (vedi many-time-pad). Una altra cosa importante Ã¨ che $k$ sia uniforme, che poi usando il teorema di XOR di sopra, possiamo avere massima sicurezza (entropia massima)\nNecessitÃ  del mezzo comunicativo ðŸŸ¨++ Ci sono anche restrizioni sulla generazione e sulla conoscenza della chiave dai due parties che cercano di comunicare! Dimostrazione segretezza perfetta ðŸŸ© Si basa sulla definizione in Classical Cyphers#Security of the Key.\nVogliamo dimostrare $\\mathbb{P}(E(k, m_{0}) = c) = \\mathbb{P}(E(k, m_{1}) = c)$ .\nAllora nel nostro caso abbiamo: $$ \\forall m,c: \\mathbb{P}(E(k, m) = c)] = \\frac{\\#\\text{Chiavi tali per cui } E(k,m) = c}{\\lvert K \\rvert } $$ Va vale il fatto che $\\forall m, c$ $\\#\\left\\{ k \\in K: E(k, m) = c \\right\\} = 1$ Quindi abbiamo la segretezza. (Ã¨ 1 perchÃ© con OTP Ã¨ unica la chiave che viene utilizzata per ottenere quello).\nSvantaggi OTP ðŸŸ© La difficoltÃ  di utilizzo di OTP, nonostante le forti garanzie teoriche Ã¨ dalla lunghezza della chiave. Vedi Classical Cyphers#Security of the Key per maggiori dettagli.\nLa chiave deve avere stessa lunghezza del messaggio (overhead, difficoltÃ  per mandare messaggi lunghi) Distruzione della chiave dopo lâ€™utilizzo (che si fa solo una volta!) La comunicazione della chiave. Per questo motivo non si utilizza per applicazioni commerciali.\nAttacks on OTP Many time pad attack ðŸŸ¨+ Se ho $c_{1} = m_{1} \\oplus PRNG(k)$ e $c_{2} = m_{2} \\oplus PRNG(k)$ Io so che solitamente da $m_{1} \\oplus m_{2}$ riusciamo a ricavare $m_{1}$ e $m_{2}$ per ridondanze del linguaggio TODO: approfondire. Quindi avendo i due ciphertext posso avere il valore sopra, perchÃ© $$ c_{1} \\oplus c_{2} = k \\oplus m_{1} \\oplus k \\oplus m_{2} = m_{1} \\oplus m_{2} $$ Questo Ã¨ stato usato nel verona project (\u0026lsquo;41 - \u0026lsquo;80)\nAmerican National Security Agency decrypted Soviet messages that were transmitted in the 1940s. That was possible because the Soviets reused the keys in the one-time pad scheme.\nNo integritÃ  ðŸŸ© Un attaccante puÃ² cambiare a suo piacimento il valore del plaintext iniziale, questo Ã¨ soprattutto utile se sa bene cosa cambiare, altrimenti un umano probabilmente puÃ² capire che il messaggio Ã¨ senza senso, ma nella teoria Ã¨ giusto, il ricevente non puÃ² capire se il messaggio Ã¨ stato modificato, o originariamente Ã¨ stato mandato cosÃ¬:\nSe attaccante modifica $c$ creando $c^{*} = c \\oplus p$ il ricevente avrÃ  $m \\oplus p$ quindi Ã¨ modificato, e non sa che Ã¨ stato cambiato.\nNOTA particolare Questo attacco Ã¨ particolarmente pericolo quanso\nSi sa la posizione del testo da cambiare Si sa il contenuto del testo cifrato in quella posizione. Se si hanno queste informazioni posso metterci un valore a piacere in quella zona. Questa cosa dovresti riuscire a capire perchÃ© sia cosÃ¬. Ad alto livello ti dico: fai xor con quella parte di testo, cosÃ¬ hai 0 in plaintext, poi rifai xor col tuo messaggio per metterci quello che ti pare. Real-world attacks L\u0026rsquo;unico takeaway Ã¨ non usare chiavi ripetute, che vedi sopra.\nWindows NT PPT (non fare) PerchÃ© veniva ripetuta la chiave sia client che server\nWEP (non fare) IV veniva ripetuta ongi 16M frames, che era presente Le chiavi generate per i vari frame sono molto correlate, perchÃ© cambia solo IV in sequente (dice la prof. che inviava anche in chiaro). Non so esattamente i dettagli ma non dovrebbe essere importante. Stream Ciphers Now we talk about stream ciphers, next about block ciphers, after that asymmetric cipher.., con questra struttura\nIntroduction Motivation and basic stuff ðŸŸ© LSM was first kind of crypto for cellphones, and it was a stream cipher (fast, at least 12 y ago confronted with the other ciphers that existed).\nEncrypting individual bits! when block ciphers encrypt blocks of it. This leads to simple encryption and decryption operations. (this is a big addendum! most of embeeded devices use this because its easy and fast!) The hardware is nice for these cyphers. Standard template of encrypt decrypt (non fare) And we can note itâ€™s an shift cipher (affine cipher) discussed in the Classical Cyphers.\nA note is that the decryption uses the Plus! This is because we are in modulus 2, and a sum is actually a xor operation. (see the logic table of it).\nProof of why the two operations are the same\nSempre dalla tavola logica si puÃ² vedere che uno 0 puÃ² essere criptato 50% a 0 e 50% a1, quindi Ã¨ resistente ad attacchi di analisi delle frequenze (ma questo solo se ho un generatore randomico buono !).\nRandom generators As the security of the scream cipher is dependent on the keys, we need to have a way to generate random keys.\nCategories of random number generators (3) (non fare) Cercare su Randomness per descrizione sul tema.\nTrue Random Number Generators tipically from random physical processes ma non riesco a farlo moltro in fretta\nLancio di dati Rumore Movimento del mouse. Random keyboard types. (e distanza tempo fra di essi). Pseudo-random Number Generators (vorremmo qualcosa di random, ma che possa produrre la stessa sequenza deterministic\nMost of these are not criptografically secure! (are usually predictable, so useless for cryptography). But they satisfy important statistical properties necessary for randomness (and tests) Forma classica di computazione\nCryptographically Secure PRNGs (same as PRNGs, but with unpredictability).\nDefinition of unpredictability\nCioÃ¨ non riesco a predire in che modo la sequenza puÃ² continuare in tempo polinomiale, data una sequenza di bits di output. Definizione PRNG Per la Jocelyne Ã¨ una funzione $\\left\\{ 0, 1 \\right\\}^{s} \\to \\left\\{ 0, 1 \\right\\}^{n}$ in cui $s \\ll n$ in teoria gli algoritmi possono generare cose infinite, ma per quanto ci interessa, vogliamo restringerci solamente a un numero finito di bit in output (che Ã¨ cosa nella pratica abbiamo) Una cosa Ã¨ che l\u0026rsquo;algoritmo che li genera Ã¨ deterministico, compattabile diciamo con Kolmogorov complexity, ma con buoni security guarantees e anche statistiche, vedi Randomness.\nOPT tramite PRNG ðŸŸ© Possiamo usare #One Time Pad Cipher usando i PRNG! CosÃ¬ risolviamo il problema di comunicazione di cose troppo grosse.\nAnalisi sicurezza stream cipher con PRNG Solamente che abbiamo la nota teorica in Classical Cyphers#Security of the Key che non possiamo avere sicurezza se la chiave reale Ã¨ minore rispetto a quella reale.\nStiamo spostando la sicurezza dell\u0026rsquo;OTP sul seed che genera.\nExamples of PRNGs Questi sono stati analizzati tempo fa da Knuth nell\u0026rsquo;art of computer programming.\nLinear Congruential Generator ðŸŸ© abbiamo una sequenza $r_{0} = seed$ e $r_{i+1} = a \\cdot r_{i} + b \\mod p$ Sembra che questa cosa molto semplice abbiamo proprietÃ  statistiche Randomness molto carine, ma molto facile da scoprire.\nglibc random (non impo) $r_{i} = (r_{i - 3} + r_{i - 31}) \\mod 2^{32}$ in cui gli index sono dei singoli bit credo Poi viene ritornato $r_{i} /2$ per qualche motivo\nNota: questo non Ã¨ sicuro perÃ² come generatore!\nSecurity necessities for PRNGs Non predictability (!) Possiamo definire che un PRNG Ã¨ predictable se esiste $i \\in N$ tale per cui avendo la sequenza $x_{0}, x_{1}, \\dots, x_{i}$ esista un algoritmo computabile secondo La macchina di Turing e che sia anche efficiente tale per cui possa calcolare $x_{i+1}, \\dots$. con una probabilitÃ  alta. Se vale questo, e possono trovare l\u0026rsquo;algoritmo che computa questo algoritmo, avrei tutto poi per decifrare, anche se non conosco la chiave iniziale.\nLa prof la definisce cosÃ¬: $\\exists A, \\exists i : 1 \\leq i \\leq n - 1$ tale per cui $$ \\mathbb{P}_{k \\leftarrow K} \\left[ A(G(k)|x_{1},x_{2}, \\dots, x_{i}) = G(k)|x_{i+1}\\right] \\geq \\frac{1}{2} + \\varepsilon $$ con $\\varepsilon = \\frac{1}{2^{30}}$. Quindi se riesce a farlo in modo migliore del random giÃ  diciamo che Ã¨ predictable.\nUna domanda interessante Ã¨ perchÃ© lo si definisce in modo probabilistico.\nStatistical Tests e Advantage Qui viene definito solo come un algoritmo che outputta 0 o 1 dopo che gli diamo la stringa iniziale in input. Note migliori dovrebbero essere in Randomness. Con questo test e la possibilitÃ  di definire una sequenza truly random $r$ possiamo definire il concetto di advantage che in breve Ã¨ quanto bene riusciamo a distinguere la PRNG dal random vero. A me sembra abbastanza inutile questa definizione. PerÃ² puÃ² essere utile per definire che il PRNG non Ã¨ abbastanza simile al random. L\u0026rsquo;algoritmo $A$ Ã¨ spesso chiamato oracolo.\nSecurity with advantage Secondo la prof. questa \u0026ldquo;advantage\u0026rdquo; Ã¨ una misura di quanto il sistema Ã¨ rompibile. Se Ã¨ simile a 1 sono abbastanza sicuro, altrimenti Ã¨ 0.\nA PRNG $G : K \\to \\left\\{ 0, 1 \\right\\}^{n}$ Ã¨ sicuro se per ogni test possibile (e questo Ã¨ giÃ  molto irrealistico) Ã¨ vero che $$ Adv_{PRNG}[A, G] \\leq \\varepsilon $$ dove $\\varepsilon$ Ã¨ molto molto piccolo, negligible si potrebbe dire. Sembra che questo problema si riduca a $P \\not= NP$ per qualche motivo strano. Queste sono definizioni con oracolo perchÃ© assumiamo di avere un $r$ che Ã¨ truly random.\nLa cosa interessante con questa definizione Ã¨ che se Ã¨ sicura, allora non Ã¨ predicibile, e questa conclusione intuitivamente non Ã¨ molto difficile. yao Â´82 sembra dimostrare che c\u0026rsquo;Ã¨ proprio una equivalenza, se non Ã¨ predictable, allora Ã¨ sicuro sotto questa definizione.\nQuesta definizione comunque secondo (Stinson 2005) chapt 6.9 Ã¨ molto difficile da raggiungere, perchÃ© troppo facile da rompere, perchÃ© tratta di leaks di informazione, ma solitamente di molto poco conto.\nSemantic security (!) Why is semantic security important? see here. It relates to the notion \u0026ldquo;no information about hte plaintext from the ciphertext\u0026rdquo;.\nDefinizione semantic security Da https://en.wikipedia.org/wiki/Semantic_security\naÂ semantically secureÂ cryptosystemÂ is one where only negligible information about theÂ plaintextÂ can be feasibly extracted from theÂ ciphertext.\nDa un punto di vista teorico, questo Ã¨ un rilassamento della nozione di Classical Cyphers#Security of the Key, in cui si richiede che siano uguali, in questo setting richiediamo che siano solo vicine le due probabilitÃ . Solo che sembra che sia inutile la nozione per sÃ© quindi introduciamo l\u0026rsquo;esperimento.\nNelle slides si fa un gioco di questo genere:\nChallenger e adversary L\u0026rsquo;avversario invia due messaggi in chiaro, Challenger invia i messaggi cifrati L\u0026rsquo;obiettivo dell\u0026rsquo;avversario Ã¨ identificare quale cyphertext coincide a quale messaggio, se si puÃ² fare, non Ã¨ sicuro secondo la definizione di semantic security di sopra, anche se non so nella pratica quanto sia vero. Questo Ã¨ vero quando #Security with advantage Ã¨ negligible, quindi non si puÃ² fare. Per il prof. Ã¨ leggermente diverso rispetto a questo:\nProbabilitÃ  di associare il ciphertext al corrispettivo plaintext.\nQuesto si puÃ² riassumere in questo: Ossia non Ã¨ in grado di distinguere la funzione fatta con chiave da una funzione a caso nell\u0026rsquo;insieme delle funzioni.\nSemantic security for many-time key Abbiamo ora che la chiave Ã¨ usata piÃ¹ di una volta, quindi abbiamo molte coppie, magari anche qualche plaintext. Infatti puÃ² scegliere quale plaintext avere a suo piacimento, si chiama chosen plaintext.\nOssia puÃ² scegliere quanti messaggi vuole per un certo esperimento\nNonce based-security L\u0026rsquo;idea Ã¨ la stessa di cui abbiamo parlato in Sicurezza delle reti per un protocollo di autenticazione. Un esempio carino di questo Ã¨ in Block Ciphers#Cipher Block Chaining (CBC) per cercare di randomizzare l\u0026rsquo;IV.\nRandomized encryption Sono delle funzioni che ritornano cyphertext in modo probabilistico (non sempre la stessa)\nPractical stream ciphers In questo caso andiamo ad utilizzare un PRNGs, non piÃ¹ truly random, per le ragioni di efficienza di comunicazioneâ€¦\nla chiave sono i valori delle cose affini nel LCG.. (forse anche il seed? boh)\nRC4 cipher Non so bene come Ã¨ stato creato questo algoritmo, probabilmente provato cose a caso??? Questo Ã¨ stato inventato da Ron Rivest, lo stesso che ha inventato l\u0026rsquo;algoritmo di RSA del 1987.\nInizializzazione Usiamo il seed $s$ per inizializzare una permutazione dei primi 256 numeri\nS[i] \u0026lt;- arange(0, 257) s = len S j \u0026lt;- 0 for i \u0026lt;- 0 to 255 do: k \u0026lt;- S[i mod s] j \u0026lt;- (j + S[i] + k) mod 256 swap(s[i], s[j]) Con questo algoritmo in pseudocodice\nGenerazione (non fatta) #### Attacchi ðŸŸ¨ Non segue la definizione di [Classical Cyphers#Security of the Key](/notes/classical-cyphers#security-of-the-key), c'Ã¨ del bias in quanto generato che si puÃ² sfruttare in modo abbastanza semplice, per esempio si puÃ² attaccare WEP che usava questo algoritmo in questo modo. ### Content Scrambling System (non fatto) eStream Cypher Si ha solitamente un nonce in questo caso, lo stesso che abbiamo usato in Sicurezza delle reti. Quindi un valore randomico utilizzato una singola volta\nSalsa 20 Ãˆ un algoritmo moderno di stream cipher, solitamente implementato in hardware per velocitÃ . Prende una chiave 256 bit e un nonce di 64. Utilizza questo per fare un mix di 20 rounds e poi produrre ili bit stream utilizzato per encodare il plaintext iniziale. Questo Ã¨ ancora sicuro, attacchi esistenti non riescono a romperlo totalmente pagina wiki Veloce che fa Mezzo giga al secondo di cifrazione.\nLinear Feedback Shift Registers This is a way to create a stream of bits to xor with the message. This stream is generated with a key. One of the advantages is that itâ€™s low power in hardware.\nShift registers You have to remember flip flops by Circuiti Sequenziali in architecture.\nCoso per storare un singolo bit sincronizzato dal clock del computer. La cosa interessante quando si collegano input e output fra flipflops diversi, Ã¨ che ad ogni ciclo di clock, si ha una specie di onda che shifta tutti i bit! Quando lâ€™output Ã¨ rixorato in certi modi e rimesso allâ€™inizio, ecco che riusciamo ad avere il feedback lineare!\nEsempio di mini Linear feedback Shift register\nEsempio di LFSR generalizzato\nMatematical Description Con p, per dire se Ã¨ 0 o 1 (o aperto o chiuso). E poi in pratica Ã¨ lâ€™operazione di +, o xor.\nWe want to have a LSFR which has a very long period\nPossiamo anche descrivere un LSFR con dei polinomi. In particolare Ã¨ importante sapere\nil numero dei registri Le porte che sono aperte e quelle che sono chiuse. Quindi si puÃ² rappresentare come $$ P(x) = x^{m} + p_{m - 1}x^{m - 1} + \\dots + p_{1}x + p_{0} $$ PerÃ² non so ancora perchÃ© questa rappresentazione del LSFR Ã¨ utile, boh, lasciamo star.\nTheorem on the period of LSFR Lâ€™idea della dimostrazione Ã¨ tipo che gli stati interni della LSFR Ã¨ al massimo $2^m - 1$, quindi al massimo il periodo Ã¨ quello. (non posso avere 0 perchÃ© sennÃ² avrei periodo di 1, che non serve a niente).\nMa non tutti hanno periodo massimo! Forse centrano qualcosa i polinomi ciclotomici, perÃ² sta fuori dalla mia capacitÃ  matematica lol.\nEsempi di LSFR massimi e non\nKnown Plaintext Attacks Il nemico conosce\nTutto il ciphertext il grado dellâ€™LSFR (se non lo sa fa bruteforce, e quindi Ã¨ come se lo sapesse) Conosce i primi 2m bits del plaintext, quindi sa i primi 2m bits generati. Dal plaintext conosciuto, vorremme ricavare tutti i bits successivi di questo stream cipher. (basta ricavare i valori dei p, ora vediamo un metodo per ricavarli).\nDato che possiede 2m bits conosciuti e conosce m, deve risolvere un sistema di m incognite e m equazioni, e questo si fa, quindi cosÃ¬ riesce a ricavare LSFR da queste!\nReferences [1] Stinson â€œCryptography: Theory and Practice, Third Editionâ€ CRC Press 2005\n","permalink":"https://flecart.github.io/notes/otp-and-stream-ciphers/","summary":"XOR operation Ãˆ una operazione binaria abbastanza semplice perÃ² ci sarÃ  importante per andare ad analizzare dei cifrari di un certo genere. Come il ONE TIME PAD che faremo fra poco in OTP and Stream Ciphers.\nTeorema cifratura con XOR Prendiamo $X$ una variabile aleatoria in $\\left\\{ 0,1 \\right\\}^{n}$ uniforme, sia $Y$ una variabile aleatoria su uno stesso dominio come vogliamo. Tali per cui $X, Y$ siano indipendenti Allora avremo che $C = X \\oplus Y$ Ã¨ una variabile aleatoria uniforme.","title":"OTP and Stream Ciphers"},{"content":"Ultima modifica: January 10, 2023 3:09 PM Primo Abbozzo: January 2, 2023 10:36 AM Studi Personali: No\nElementi di ripasso Pre-esame Per la struttura di questo esame, tristemente ci sono un sacco di cose da imparare a memoria, senza averne capito il motivo.\nPer questa ragione metto qui alcune cose importanti per lâ€™esame, che sono probabilmente da imparare a memoria\nNumeri finiti Standard IEEE per 32 e 64 floating point, il formato a 4, dire a memoria i numeri Formula per precisione macchina Norme e condizionamento Definizione del numero di condizionamento per una matrice Norma 1, p-adica, infinito Norma di frobenius Norma indotta (1 e infinito) Norma spettrale Metodi diretti Cholesky, che composizione ha? VelocitÃ  della scomposizione LU VelocitÃ  di inversa VelocitÃ  di Cholesky Cosa Ã¨ una matrice semidefinita o definita positiva Metodi iterativi Jacobi Gauss sidel Condizioni di convergenza Least squares decomposition Cosa produce la scomposizione LSQ Relazione di $\\Sigma$ con gli autovalori di AAt Cosa significa fattore di compressione immagini con SVD Interpolazione Teoremi sullâ€™unicitÃ  ed esistenza Come si costruisce lâ€™unica funzione di interpolazione fatta Teorema del resto dellâ€™interpolazione Nodi di chebicheff Zeri di funzione Condizionamento di un problema sugli zeri lineare ðŸŸ¥ (vedere il video che utilizza praticamente la stessa idea). Test modificato di convergenza per bisezione Condizioni di convergenza globale per approssimazioni successive Condizioni di convergenza locale ipotesi per esistenza ed unicitÃ  del punto fisso. VelocitÃ  di convergenza approssimazioni successive Criteri di convergenza globale di newton ðŸŸ¥ Discesa del gradiente Condizioni sufficienti e necessarie per il minimo (anche nel caso convesso!) Condizioni di minimo per quadratiche convesse (e quindi anche eq. normali!) individuazione della direzione di discesa Condizioni di wolfe, e armijo Come trovare lo step per gradient descent (il mini algo) Criteri di arresto di gradient descent VelocitÃ  di convergenza di gradient descent newton puro. Immagini Discrepanza di morozov Regolarizzazione di tickonov Point spread function ","permalink":"https://flecart.github.io/notes/pre-esame/","summary":"Ultima modifica: January 10, 2023 3:09 PM Primo Abbozzo: January 2, 2023 10:36 AM Studi Personali: No\nElementi di ripasso Pre-esame Per la struttura di questo esame, tristemente ci sono un sacco di cose da imparare a memoria, senza averne capito il motivo.\nPer questa ragione metto qui alcune cose importanti per lâ€™esame, che sono probabilmente da imparare a memoria\nNumeri finiti Standard IEEE per 32 e 64 floating point, il formato a 4, dire a memoria i numeri Formula per precisione macchina Norme e condizionamento Definizione del numero di condizionamento per una matrice Norma 1, p-adica, infinito Norma di frobenius Norma indotta (1 e infinito) Norma spettrale Metodi diretti Cholesky, che composizione ha?","title":"Pre-esame"},{"content":"Questo Ã¨ un tentativo di aggiungere un argomento che non era presente quando abbiamo fatto il corso due anni fa. Inizio la scrittura il 2024-03-03. Questo non Ã¨ stato trattano nel corso, ma Ã¨ importante per molte cose. Quindi introduco questo appunto.\nIntroduzione alle serie Le serie infinite sono dei mostri strani perchÃ© non si comportano spesso come dovrebbero.\nLimit Comparison Test Siano date due Successioni $a_{n}$ e $b_{n}$ sempre positive. Allora se esiste ed Ã¨ finito il limite $$ \\lim_{ n \\to \\infty } \\frac{a_{n}}{b_{n}} = c $$ Si hanno due casi possibili per il valore di $\\sum_{i=1}^{+\\infty}a_{n}$ e di $\\sum_{i=1}^{+\\infty}b_{n}$\nEntrambi convergono a un valore $c$ Entrambi divergono Questo Ã¨ abbastanza intuitivo se pensiamo che l\u0026rsquo;ipotesi ci sta dicendo che al limite le due successioni distano al massimo di un fattore reale. Se divergono, e distano di un fattore reale, anche l\u0026rsquo;altro dovrÃ  divergere, se invece converge, anche l\u0026rsquo;altro dovrÃ  convergere.\nLa dimostrazione credo passa dalla definizione di limite per successioni presente in Successioni#3.2 Limiti di successioni.\n","permalink":"https://flecart.github.io/notes/serie/","summary":"Questo Ã¨ un tentativo di aggiungere un argomento che non era presente quando abbiamo fatto il corso due anni fa. Inizio la scrittura il 2024-03-03. Questo non Ã¨ stato trattano nel corso, ma Ã¨ importante per molte cose. Quindi introduco questo appunto.\nIntroduzione alle serie Le serie infinite sono dei mostri strani perchÃ© non si comportano spesso come dovrebbero.\nLimit Comparison Test Siano date due Successioni $a_{n}$ e $b_{n}$ sempre positive.","title":"Serie"},{"content":"Ultima modifica: September 10, 2022 12:24 PM Primo Abbozzo: August 8, 2022 12:52 PM Studi Personali: No\nEuristiche, capitolo 3.6 del libro intelligenza artificiale Database degli algoritmi Algoritmi da provare\nAlgoritmi da provare\nCose da guardare Null move In chess sembra che una null move heuristics (in pratica fai fare 2 mosse all\u0026rsquo;avversario) sia utile per stabilire il valore di una posizione, si potrebbe fare qualcosa di simile?\nLibri Norvigs\nIntelligenza_artificiale_Un_approccio_moderno_Volume_1_4th_S_Russel.pdf\nArtificial Intelligence - A Modern Approach (3rd Edition).pdf\nForward pruning Ãˆ un modo per eliminare branches di ricerca subito, c\u0026rsquo;Ã¨ un rischio che si elimini una branch bella.\nDa guardare sono:\nBeam search Futility pruning Late move reduction. Papers Euristiche generali\np276-286.pdf\nImplementation of The game and of the AI CHUA HOCK CHUAN 2017 (non interessati, molto basilare la funzione di eval in base a quanti consecutivi)\nTic-tac-toe - Java Game Programming Case Study\nTic-tac-toe AI - Java Game Programming Case Study\nDeveloping a Memory efficient Algorithm for Playing mnk games\nMICS_2016_paper_28.pdf\nViene applicata lâ€™euristica dei maggiori modi di vincere possibili, algoritmo qui proposto non tiene conto delle mosse del nemico (lo dice lui stesso), quindi propone anche un fix subito dopo lol.\nStackoverflow on 10x10 5 game\nMinimax Alpha Beta Pruning Algorithm takes too much time to solve Tic Tac Toe (10x10 board)\nPresenta alcune tecniche generali per migliorare il minimax, ad esempio hashtable per stati giÃ  cercati, cosa che credo funzioni solo per questi casi piccoli, il 50x50 farci la table non credo proprio riescaâ€¦\nSolving 7,7,5\nICG-180061.pdf\nNote su Java Ottimizzazioni su final Vecchi MNKGame simone e la giuglia\nGitHub - Follisim/mnk-game\nQuesto non utilizza thread, quindi sarebbe utile compararlo col nostro â¬‡ï¸\nhttps://github.com/NotXia/unibo-MNKGame\nlineare\nMNKGame2.0/mnkgame at main Â· PasqualeRic/MNKGame2.0\nindeterminati\nGitHub - mattyk0207/progetto-ASD: giocatore virtuale per MNKgame\nalpha beta\nGitHub - Murkrow02/MNKGame\nhttps://github.com/FoxySeta/monkey\nhttps://github.com/specialfish9/LittleMan\nhttps://github.com/giammirove/mnk-game\nhttps://github.com/takenX10/BottargaPlayer\nhttps://github.com/University-Works-Projects/MNKGame\nCon voto 26 questo.\nIdee per minimax forte //github.com/takenX10/BottargaPlayer)\nhttps://github.com/University-Works-Projects/MNKGame\nCon voto 26 questo.\nIdee per minimax forte\n","permalink":"https://flecart.github.io/notes/algoritmi-per-il-progetto/","summary":"Ultima modifica: September 10, 2022 12:24 PM Primo Abbozzo: August 8, 2022 12:52 PM Studi Personali: No\nEuristiche, capitolo 3.6 del libro intelligenza artificiale Database degli algoritmi Algoritmi da provare\nAlgoritmi da provare\nCose da guardare Null move In chess sembra che una null move heuristics (in pratica fai fare 2 mosse all\u0026rsquo;avversario) sia utile per stabilire il valore di una posizione, si potrebbe fare qualcosa di simile?\nLibri Norvigs","title":"Algoritmi per il progetto"},{"content":"Ripasso Prox: 22 Ripasso: June 6, 2023 Ultima modifica: May 23, 2023 10:19 PM Primo Abbozzo: March 1, 2023 10:07 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso In teoria il ripasso era 28 maggio\nArchitettura software dellâ€™OS A seconda dell\u0026rsquo;utilizzatore lâ€™OS puÃ² essere molte cose, come solamente lâ€™interfaccia se sei un programmatore, servizi (se sei un utente, ma gran parte dei servizi sono astratti e l\u0026rsquo;utente ne puÃ² anche essere a non-conoscenza).\nMa se sei un programmatore OS ti interessa capire le componenti principali dellâ€™OS\nSlide componenti OS alto livello\nIntroduzione sui componenti (salto) Questa parte la salto perchÃ© Ã¨ una descrizione molto generale di cosa si occupa Lâ€™os verso drivers, processi, filesystem I/O, quindi non Ã¨ molto importante\nGestione dei processi All\u0026rsquo;interno del SO, il processo Ã¨ rappresentato come un processo control block, che in linux Ã¨ in sched, parte dello scheduler dei processi. Questo Ã¨ importante perchÃ© per esempio per fare una fork, non faccio altro che duplicare questa struttura e settare bene i figli e genitori.\nQuesti sono solitamente messi un un process table o forse una lista per tenerne traccia.\nSlide\nnel parliamo in Processi e thread.\nGestione memoria principale e secondaria Principale\nÃˆ un array temporaneo(nel senso che non Ã¨ mantenuto quando viene spento il PC.), indicizzato singolarmente a differenza del secondario, che Ã¨ indicizzato a blocchi,\nUna parte importante di questa parte Ã¨ la gestione della memoria virtuale. Come allocare pagine di memoria, deallocarle e simili, ne parliamo in Paginazione e segmentazione\nSecondaria\nLa cosa buona Ã¨ che questa memoria Ã¨ permanente, efficienza (ordinare le richieste per non andare qui e lÃ¬ quando si legge! minimizare tempi per seek) e partizionamento e reliability dei dischi sono problemi che interessano questa parte. Abbiamo parlato di raid in Memoria. e di nuovo in Devices OS.\nSlide\nI/O e filesystem Principalmente per IO servono driver per interagire con specifici hardware, e un sistema di comunicazione che spesso sono buffer e cache.\nSlides\nEsiste un file system virtuale che mappa a tutto (quindi alcune cose non esistono realmente sul disco, potrebbe essere una astrazione utilizzata per esempio per comunicare con i devices.\nCi sono molti filesystem, che perÃ² posso gestire in modo differente la forma che hanno sul disco, Ed Ã¨ per questo che possiamo dire che esistono dei filesystem diversi.\nAnche i processi sono files, la cosa figa di questa astrazioen Ã¨ che posso utilizzare gli stessi sistemi di protezione file per processi.\nStruttura dei sistemi Obiettivi di design dei SO (4) ðŸŸ¨ Slide obiettivi nella struttura dei sistemi (4)\nEfficienza\nModularitÃ \nMantenibilitÃ \nEspansibilitÃ \nStruttura del kernel ðŸŸ© Slide riassuntiva\nIl kernel Ã¨ un unico processo, parte da un main che parte da un initialize in cui raccoglie tutte le risorse del sistema, fa partire tutti i device drivers e crea il PCB del primo processo, anche chiamato init, messo poi nella queue dello scheduler come spiegato in Scheduler. Fatta una volta non Ã¨ mai piÃ¹ eseguito quel codice di init.\nLo stato kernel Ã¨ la parte a sinistra dellâ€™immagine, quella parte blu, tutto il giallo, a destra Ã¨ lo stato user.\nScheduler scegliere il processo da eseguire nello user space Il controllo Ã¨ passato al processo user, che puÃ² fare traps (come fork) o fare I/O, a quel punto Ã¨ rimesso a codice kernel. Tipologie di struttura OS (2) ðŸŸ¨++ Solitamente i sistemi sono costruiti in due modi, sistemi semplici senza struttura, che praticamente c\u0026rsquo;Ã¨ una prima versione, e poi viene ammassato roba senza struttura generale, fatti quando servono. Solitamente sono insieme di procedure che si chiamano fra di loro, e ben presto sono andate fuori dal loro ambito di interesse diciamo (fuori dal loro scope)\nEsempi di OS semplici:\nUn esempio Ã¨ free-dos che Ã¨ quanto installato su un computer senza sistema operativo.\nIn modo simile Ã¨ MS-DOS, che Ã¨ stato fatto per i primi personal computer, che non avevano un sistema kernel a livello hardware (non era quindi possibile fare queste protezioni).. In generale in questo ambiente un programma aveva accesso all\u0026rsquo;intera memoria, e poteva mandare in crash tutto.\nStruttura Free-DOS\nUNIX, Ã¨ diviso diviso in due parti in kernel e programmi di sistemi, molto semplice, un kernel monolitico, un unico eseguibile, anche questo fu allâ€™epoca limitato enormemente dal suo hardware, e una serie di programmi di sistema.\nDato che c\u0026rsquo;Ã¨ una separazione, lâ€™utente Ã¨ separato dallâ€™interfaccia dal codice kernel. Ma comunque il codice kernel resta vulnerabile, e potrebbe essere modificato e quindi attaccato, o cumunque vulnerabile a bug, anche colposi, distruttivi.\nStruttura UNIX\nStratificazione OS:\nLa struttura a stati Ã¨ piÃ¹ affidabile dell\u0026rsquo;altra e rende piÃ¹ facile la programmazione di tale sistema, utili, la logica Ã¨ la stessa presentata in Architettura e livelli 1, 2, per la divisione a stack del sistema e dei vantaggi che si hanno con questo tipo di architettura.\nEsemplificazione struttura a strati\nStrutture proposte classiche (non fatte, non importanti)\nQuesti sono rimasti accademici\nMa nella pratica questi strati sono rimasti solamente a livello accademico, perchÃ© crea overhead anche se si guadagnerebbe in manutentibilitÃ  e estensibilitÃ  e gestione, quindi molto meno efficiente, inoltre non erano ben chiare le API fra strati. Oggi c\u0026rsquo;Ã¨ una forma intermedia (non c\u0026rsquo;Ã¨ esattamente la gestione a strati come abbiamo per Web, ma abbiamo una divisione per componenti e responsabilitÃ  delle componenti).\nPolitiche e meccanismi ðŸŸ© La suddifivisione politiche e meccanismi Ã¨ un pattern di software engineering che lo rende molto comodo da gestire.\nInvece che una gestione a strati come per le reti, abbiamo una gestione di politiche e meccanismi ossia abbiamo qualcosa che decide cosa andare a fare e qualcosa che gestisce il come farla.\nEG. un certo modo di memoria allocata per fare qualcosa, quindi indirizzare il sistema verso qualcosa, e MMU che attualmente implementa la decisione politica.\nEsempio Microkernel o MINIX:\nIl kernel Ã¨ visto come il meccanismo quindi le parti di gestione e politica sono fuori dal kernel. Questo rende la struttura del SO molto mantenibile ed estendibile.\nSlide\nEsempio Mac OS â‰¤ 9 / Windows 9x:\nPolitiche e meccanismi sono messi tutti nel kernel, perchÃ© cosÃ¬ imponevo un feeling unico al look and feel suo (obbligato tutti ad avere questi elementi grafici). Questo Ã¨ un problema praticamente di mercato.\nQuesto era brutto perchÃ© la grafica puÃ² mandare in crash tutto il sistema. Anche se i nuovi sistemi non dovrebbero avere questo problema.\nCategorizzazione dei Kernel (3) ðŸŸ¨â€” Monolitici:\nIl kernel Ã¨ un unico programma. Si possono creare moduli che poi vengono caricati. Il problema principale di questo tipo di kernel Ã¨ che se un modulo bugga crolla l\u0026rsquo;intero sistema. Un vantaggio Ã¨ che Ã¨ molto efficiente perchÃ© non deve passare ad astrazioni come per lo stack, basta fare una chiamata di funzione, tanto siamo nello stesso programma. Ed Ã¨ altamente modularizzabile per poter attaccare nuove funzionalitÃ .\nIn breve:\nVantaggi\nEfficienza ModularitÃ  e mantenibilitÃ  (non devo ricompilare tutto, basta runtime). Svantaggio\nUn modulo puÃ² mandare in crash tutto, perchÃ© Ã¨ eseguito nello stesso spazio del kernel.\nSlide\nEsempi sono Linux o BSD.\nMicrokernel:\nLâ€™obiettivo del microkernle Ã¨ isolare solamente le funzionalitÃ  essenziali e tenere solo quelli, tutto il resto interagisce con esso con system call (un esempio Ã¨ il filesystem che potrebbe essere fuori dal kernel, e avrebbe syscall leggermente diverse rispetto a quelle di linux, per aprire un file allora si chiederebbe a questo processo in user space, che poi fa altre richeste per kernel space)\nBisogna fare un messaggio, la syscall diventano Send! Che sarebbe unico modo per raggiungere il processo che offre il servizio che mi serve.\nVantaggi: ðŸŸ¥\nAltissima modularitÃ  e mantenibilitÃ  del sistema e semplice da realizzare Assenza di danni di sistema, perchÃ© moduli e kernel sono eseguiti in spazio differente. Sicuro e affidabile per la divisione (non ho propagazione di errori e guasti) Molto portabile, che ho solo il microkernel. Svantaggio:\nFortemente Inefficienza rispetto al monolitico, che devo fare message passing e comunicazione.\nSlide di comparazione\nKernel Ibridi\nSono dei microkernel modificati, con qualcosa in piÃ¹ forse (aziende per pubblicizzarsi dicevano di avere microkernel, ma con un ibridone, mettendo le cose inefficienti del microkernel dentro il kernel).\nEsempio windows\nCi sono diversi server, che fanno parte di un sottosistema dâ€™ambiente che Ã¨ in grado di emulare certe cose (sono nascoste le syscall reali del sistema cosÃ¬).\nIl codice per un certo ambiente funziona anche nel sottosistema, un esempio Ã¨ un WSL.\nLa parte grafica importante per fare i videogiochi, Ã¨ dentro il kernel, questo ad esempio per MACOS, perchÃ© volevano imporre la grafica simile\nMacchine virtuali Virtualization allows a single computer to host multiple virtual machines, each poten- tially running a completely different operating system.\nÃˆ virtuale nel senso che la macchina virtuale ha la stessa percezione della realtÃ  di una macchina reale. Qualcosa che non Ã¨ la realtÃ  ma appare molto simile ad essa.\nStoricamente parlando le macchine virtuali erano un primo approccio al multitasking.\nLâ€™idea principale Ã¨ creare un sistema che possa apparire al sistema operativo come hardware, in questo modo posso utilizzare un programma per emulare un altro sistema operativo. Ãˆ hypervisor, VMM (virtual machine monitor).\nOvviamente ho uno fortissimo svantaggio in velocitÃ , perchÃ© la simulazione software Ã¨ molto meno efficiente della simulazione hardware. Un collegamento carino Ã¨ con strange loops, una macchina che sia abbastanza espressiva da poter emulare sÃ© stesso.\nAnalisi vantaggi svantaggi ðŸŸ¨ Slide\nPosso avere sistemi operativi differenti sulla stessa macchina o SO, quindi posso sperimentarli senza installarli veramente.\nPosso simulare architetture differenti, e quindi supporre di avere istruzioni differenti di architettura altra!\nSO monotask in sistemi multitask???\nMaggiore sicurezza a bug software, Ã¨ efficienza energetica\nSvantaggi:\nfortemente inefficiente Difficile condividere risorse fra una macchina virtuale o allâ€™altra. Livello processo o sistema ðŸŸ© Le macchine virtuali di cui abbiamo parlato ora virtualizzano solamente lâ€™hardware, cioÃ¨ fa finta di avere un sistema hardware???\nMentre altre macchine virtuali provano a virtualizzare a livello di ABI (application binary interface) (che Ã¨ livello di processo).\nMacchina virtuale a livello di processo (process VM): permette ad un programma di essere eseguito allo stesso modo su qualsiasi piattaforma. Viene eseguita come una normale applicazione allâ€™interno di un SO ospite e supporta un singolo processo. Il suo scopo Ã¨ fornire un ambiente indipendente dalla piattaforma hardware e dal SO ospite. Vengono virtualizzati sia lâ€™hardware che il sistema operativo. Macchina virtuale a livello di sistema (system VM): permette l\u0026rsquo;esecuzione di un completo SO, anche con un ISA diverso da quello della macchina reale. Viene virtualizzato esclusivamente e completamente lâ€™hardware Differenza type 1 and 2 hypervisors\ntype 1 hypervisor and a type 2 hypervisor is that a type 2 makes uses of a host operating system and its file system to create processes, store files, and so on. A type 1 hypervisor has no underlying support and must perform all these functions itself (it runs on the bare metal, come se fosse lui stesso un sistema operativo, Ã¨ infatti un sistema operativo che non fa altro che fare sistemi operativi!)\nQemu ðŸŸ© qemu Ã¨ un traduttore dinamico come se fosse un compilatore fra una architettura in una altra, fatta a runtime (quindi Ã¨ un interprete, tipo 10x piÃ¹ lento rispetto esecuzione normale, ma un ordine di grandezza piÃ¹ veloce rispetto altri emulatori).\nCon qemu posso anche dire al processo emulato di utilizzare il mio stesso kernel, nel caso che condivida l\u0026rsquo;architettura, questo rende la cosa molto piÃ¹ veloce del normale! e.g. KVM (che Ã¨ il nome dellâ€™Hypervisor per linux). Questo Ã¨ anche una tipologia di type-2-hypervisor perchÃ© attingo al kernel della macchina ospite per fare funzionare piÃ¹ in fretta, e non faccio simulazione sistema totale.\nUtile o per runnare programmi per architettura differente (in questo senso program VM), oppure per emulare un sistema operativo dentro un sistema operativo\nComando per caricare una macchina virtuale con qemu e utilizzare KVM\nsenza vga, non starebbe sullo schermo senza quella flag.\nhda gli specifica il file con cui emulare il disco, k il layout del keyboard\nm Ã¨ la memoria ram\nmonitor Ã¨ per poter mandare interrupt dal terminale in cui ho lanciato il mio comando di emulazione.\nQuando installa prima Ã¨ installato nella RAM disk, e poi viene utilizzato per lâ€™installazione vera e propria.\nXEN ðŸŸ© XEN Ã¨ hypervisor livello 1 (SO che permette di fare altri SO virtuali), e utilizzare paravirtualizzazione (si fanno trap and emulate principalmente) , e utilizza una gestione diversa dei drivers che possiede, ossia il Domain0 possiede tutti i drivers fisici (le interazioni con i device le manda alla macchina 0, perchÃ© per restare un sistema operativo semplice non riesce a gestire sistemi operativi).\nParavirtualizzatione\nIn questo caso il SO virtuale Ã¨ a conoscenza che esiste un hypervisor quindi puÃ² fare delle hypercall per eseguire delle istruzioni sensitive, e in generale Ã¨ un approccio piÃ¹ veloce invece della virtualizzazione totale di cui abbiamo parlato prima.\nEsempio di maggiore efficienza\nPer il type 2 hypervisor il SO installato pensa veramente di stare in una macchina sÃ©, quindi fa cose per minimizzare i seek del disco ma in questo caso non deve fare veramente seek, quindi Ã¨ meno efficiente, facendo una assunzione errata.\nSi utilizzano paravirtualizzazione, ossia devices virtuali piÃ¹ efficienti per questa cosa, ed effettivamente non assumo di stare utilizzando device fisici, ma sono a conoscenza di utilizzare device virtuali, e posso fare ottimizzazioni del caso (che non so quali siano forse per il disco non faccio cose strane per il seek ad esempio).\nIl problema Ã¨ che essendo a conoscenza, dovrei fare il mio SO in modo che sia compatibile con le hyper all offerte dall hypervisor\nParametrizzazione SO ðŸŸ© Essendo libero linux, Ã¨ molto comodo poter cambiare alcuni parametri e poi ricompilare il kernel seguendo quei parametri. Tanto Ã¨ tutto open source, quindi si potrebbe fare. Questo permette al kernel di essere molto portabile.\nUna cosa molto importante da capire Ã¨ che il kernel Ã¨ una cosa diversa della distribuzione, il kernel Ã¨ il primo programma che viene caricato dal bootloader e carica il FS e tutto il resto (quindi le cose iniziali), il secondo sono tutte le utility per il kernel che lo rendono utilizzabile da un utente normale.\nComando runnato per la emulazione kernel/distribuzione\nSlide parametrizzazione ++ portabilitÃ  (che deve runnare per hardware differentI)\nIstruzioni di virtualizzazione ðŸŸ¥ Abbiamo aggiunto delle istruzioni di emulazione come VMX ON, VMX OFF, VMLAUNCH, VMRETURN in cui il processore sa di stare emulando, e quindi Ã¨ piÃ¹ veloce perchÃ© esegue l\u0026rsquo;istruzione in altro modo, forse con istruzione nativa. Pagina wiki\nfa pensare di essere in kernel mode, ma non Ã¨ in kernel mode, Ã¨ come se stesse in un livello di priviliegio intermedio.\nVMLAUNCH\nQueste sono quelle principali istruzioni che permettono la virtualizzazioen a livello software, il fatto che rende l\u0026rsquo;esecuzione molto piÃ¹ veloce, quindi invece di simulare tutto sopra il sistema operativo attuale (e syscalls attuali) posso accedere ad istruzioni hardware molto piÃ¹ veloci.\nMemoria Virtuale (non fare) C\u0026rsquo;Ã¨ una MMU del sistema operativo che mappa alla VM fisica, che si deve basare all\u0026rsquo;indirizzo logico, che deve essere risolto dalla MMU reale fino ad avere un indirizzo fisico.\nMINI SCHEMA\n","permalink":"https://flecart.github.io/notes/architettura-software-dellos/","summary":"Ripasso Prox: 22 Ripasso: June 6, 2023 Ultima modifica: May 23, 2023 10:19 PM Primo Abbozzo: March 1, 2023 10:07 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso In teoria il ripasso era 28 maggio\nArchitettura software dellâ€™OS A seconda dell\u0026rsquo;utilizzatore lâ€™OS puÃ² essere molte cose, come solamente lâ€™interfaccia se sei un programmatore, servizi (se sei un utente, ma gran parte dei servizi sono astratti e l\u0026rsquo;utente ne puÃ² anche essere a non-conoscenza).","title":"Architettura software dellâ€™OS"},{"content":"Introduzione a bag of words Faremo una introduzione di applicazione di NaÃ¯ve Bayes applicato alla classificazione di documenti.\nSetting del problema ðŸŸ¨+ Questo Ã¨ una parte che Ã¨ importante nel caso volessimo fare document classification. e simili, In questa brevissima introduzione cerchiamo di calcolare $$ \\theta_{i, \\text{word}, l} = P(X_{i} = \\text{word} | Y = l) $$ Ossia quanto Ã¨ probabile che una parola sia word, che appaia alla posizione i, data la categoria $l$ del documento Assumendo che non dipenda dalla posizione posso solamente contare le parole per documento fregandomene della posizione, questa Ã¨ l\u0026rsquo;idea che ha portato ai primi approcci in questo campo.\nAssumiamo che siano anche indipendenti alla posizione per semplicitÃ , che Ã¨ una assunzione molto forte perchÃ© proviamo a catalogare la classe solamente dalla frequenza delle parole\n$$ \\theta_{i, \\text{word}, l} = \\theta_{\\text{word}, l} $$ Note: assunzioni forti (2) ðŸŸ© PerchÃ© Ã¨ una assunzione molto forte, e irrealistica il fatto che siano:\nIndipendenti dalla posizione indipendenti fra di loro (Ã¨ molto chiaro che certe parole vanno piÃ¹ insieme rispetto ad altri, quindi Ã¨ una assunzione chiaramente false). PerÃ² Ã¨ didattica la cosa che un modello semplice come NaÃ¯ve Bayes possa essere utilizzato per un problema del genere. Forward inference Una volta creato tutta la matrice di pesi e possibilitÃ  (quanto Ã¨ correlato), Per fare una forward inference non faccio altro che fare una dot product perchÃ© usiamo quella come metrica per fare inference.\nInference in breve ðŸŸ¥ Calcolando la $s_{k}$ come in immagine sopra, posso avere una sorta di caratterizzazione del tema/categoria, in ogni singolo documento che ho.\nPoi per fare inferenza vedo il documento attuale Ã¨ piÃ¹ simile rispetto a quale.\nCosine similarity ðŸŸ© Questa Ã¨ una metrica molto utilizzata per dare una idea di somiglianza di vettori.\n","permalink":"https://flecart.github.io/notes/bag-of-words/","summary":"Introduzione a bag of words Faremo una introduzione di applicazione di NaÃ¯ve Bayes applicato alla classificazione di documenti.\nSetting del problema ðŸŸ¨+ Questo Ã¨ una parte che Ã¨ importante nel caso volessimo fare document classification. e simili, In questa brevissima introduzione cerchiamo di calcolare $$ \\theta_{i, \\text{word}, l} = P(X_{i} = \\text{word} | Y = l) $$ Ossia quanto Ã¨ probabile che una parola sia word, che appaia alla posizione i, data la categoria $l$ del documento Assumendo che non dipenda dalla posizione posso solamente contare le parole per documento fregandomene della posizione, questa Ã¨ l\u0026rsquo;idea che ha portato ai primi approcci in questo campo.","title":"Bag of words"},{"content":"In questa nota proviamo a cercare di descrivere bene l\u0026rsquo;analisi degli effetti del linguaggio che possono avere a che fare con theory of mind.\n(Mahowald et al. 2023) Inizia a fare una bella analisi riguardante la differenza di conoscenza sintattica e funzionale del linguaggio. Molte references all\u0026rsquo;aspetto del cervello per quella roba.\nReferences [1] Mahowald et al. â€œDissociating Language and Thought in Large Language Models: A Cognitive Perspectiveâ€ arXiv preprint arXiv:2301.06627 2023\n","permalink":"https://flecart.github.io/notes/effetti-del-linguaggio/","summary":"In questa nota proviamo a cercare di descrivere bene l\u0026rsquo;analisi degli effetti del linguaggio che possono avere a che fare con theory of mind.\n(Mahowald et al. 2023) Inizia a fare una bella analisi riguardante la differenza di conoscenza sintattica e funzionale del linguaggio. Molte references all\u0026rsquo;aspetto del cervello per quella roba.\nReferences [1] Mahowald et al. â€œDissociating Language and Thought in Large Language Models: A Cognitive Perspectiveâ€ arXiv preprint arXiv:2301.","title":"Effetti del linguaggio"},{"content":"Ripasso Prox: 69 Ripasso: May 29, 2023 Ultima modifica: April 25, 2023 9:50 AM Primo Abbozzo: October 28, 2022 12:52 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Domande\nLinguaggi liberi e PDA Introduzione In questa parte del nostro percorso nei linguaggi di programmazione proviamo ad espandere NFA e DFA in modo che possano riconoscere linguaggi come $ww^r | w \\in \\{a, b\\}^*$ , con r maggiore o uguale a zero (r per dire che Ã¨ il contrario di w) (questo linguaggio per il pumping lemma).\nPush-down automata Introduzione automi a pila (7) ðŸŸ© \u0026ndash; Lâ€™idea principale per espandere gli NFA Ã¨ il concetto di stato o memoria, avere quindi una stack o pila puÃ² rendere molto piÃ¹ espressivo queste entitÃ .\nIl prof. definisce automa a pila non deterministico (PDA) questa settupla $(\\Sigma, Q, \\Gamma, \\delta, q_{0}, \\bot, F)$\n$\\Sigma$ l\u0026rsquo;alfabeto finito dei simboli in input $\\Gamma$ l\u0026rsquo;alfabeto dei simboli sulla pila $Q$ l\u0026rsquo;insieme degli stati $\\delta$ transizione, nella forma $\\delta: Q\\times (\\Sigma \\cup \\left\\{ \\varepsilon \\right\\}) \\times \\Gamma \\to \\mathbb{P}(Q \\times \\Gamma^{*})$ $q_{0}$ lo stato iniziale $\\bot \\in \\Gamma$ il simbolo iniziale sulla pila $F \\in Q$ l\u0026rsquo;insieme degli stati finali. Una differenza che fa questo prof. contro La macchina di Turing Ã¨ che lui fa distinzione dei simboli sulla pila, mentre l\u0026rsquo;altro no, una altra differenza Ã¨ che gli stati finali sono esterni nell\u0026rsquo;altro. Ma credo alla fine sia equivalente. Attenzione: lâ€™automa puÃ² leggere qualcosa solo se la sua stack non Ã¨ vuota!\nLa parte intressante dei PDA rispetto agli automi studiati in Automi e Regexp Ã¨ la funzione di transizione, che Ã¨ ora nella forma\n$$ \\delta: Q \\times (\\Sigma \\cup\\{\\varepsilon\\}) \\times \\Gamma \\to P(Q \\times \\Gamma ^*) $$ Esempio hard di PDA Computazione automi a pila ðŸŸ© \u0026ndash; Slide\nEsempio 1\nEsempio 2\nAccettazione della stringa ðŸŸ© La cosa particolare degli automi a pila Ã¨ che accettano la stringa anche quando la pila diventa vuota, non solo quando finisco di leggere e ho uno stato che Ã¨ bello. Ossia detto meglio, posso costruirmi un automa a Pila che accetta la stessa stringa quando la pila diventa vuota, câ€™Ã¨ una sorta di equivalenza fra stato e cose sulla pila.\nSlide\nLa cosa importante da capire per questa parte Ã¨ che si differenziano due metodi di accettazione per la stringa:\nPila vuota Stato finale. In entrambi i casi devo leggere tutto lâ€™input, e poi vado a vadere dove sto. Nel primo caso se ho letto tutto lâ€™input e la pila Ã¨ vuota allora accetto, nel secondo caso se ho letto tutta la stringa e sono in uno stato finale allora vado ad accettare.\nTeorema equivalenza accettazione Vuoto-Stato ðŸŸ© Enunciato\nDimostrazione in slide\nL\u0026rsquo;idea dietro questo teorema Ã¨ molto simile a quanto presente nella conversione fra espressione regolare e NFA, perchÃ© sto andando in modo ricorsivo, supponendo che ho giÃ  un vecchio automa che funzioni, e basta che ci costruisca cose intorno ad essa. (in questo caso simbolo iniziale nuovo e stato finale che piÃ¹ o meno racchiude tutti gli stati finali!\nZ Ã¨ un simbolo stack nel nostro nuovo automa, solo utilizzato per gestire meglio alcune cose con la stack.\nOgni linguaggio Ã¨ libero sse riconosciuto da PDA (chiede)ðŸŸ© Enunciato\nDimostrazione\nDiagramma PDA per â†’\nNota questo non Ã¨ il PDA di cui parlava il prof nelle slides, bisognerebbe condensarlo in un unico stato. Questo qui risolve per stato finale, quello del prof per stack vuota\nNote sulla dimo\nVogliamo dimostrare un sse, in una proviamo a costruire un automa partendo dalle regole della grammatica, (non dimostriamo che lâ€™automa riconosce effettivamente, la costruiamo ebbasta.\nPer lâ€™altra freccia bisogna avere dimostrato prima alcuni lemmi che noi saltiamo per ora.\nProprietÃ  dei linguaggi liberi Unione, Conc, e Kleene ðŸŸ© Dimostrazione\nIn pratica i non terminali e terminali sono uniti assieme, e con qualche produzione in piÃ¹ sullo stato iniziale per gestire le cose.\nIntersezione con linguaggio regolare (chiede per alto voto) ðŸŸ© Questa Ã¨ qualcosa di leggermente piÃ¹ tosta, perÃ² in soldoni sto facendo un bruteforce, e prendendo tutte le combinazioni possibili per cui si possa riconoscere\nTh e dimostrazione\nCon questo teorema Ã¨ spesso utile per dimostrare che un linguaggio non Ã¨ libero.\nInvece non sono chiusi per intersezione i linguaggi liberi\nEsempio di non chiusura\nDa questo dato si puÃ² concludere che non sono chiusi per complemento altrimenti lo sarebbero anche per l\u0026rsquo;intersezione.\nPumping theorem, tosta (!) ðŸŸ¨++ Enunciato\nDimostrazione\nDimostrazione libro sispser (piÃ¹ chiaro)\nLâ€™idea Ã¨ sempre avere cosÃ¬ tanti stati che avrÃ² per forza dei non terminali duplicati. uno sotto lâ€™altro, in una forma ricorsiva, allora prendo il minore e vado a fare ragionamenti lÃ¬.\nClassificazione dei linguaggi Chomsky (5) ðŸŸ¥+ Chomsky, linguista, ha descritto una gerarchia di linguaggi\nCaratterizzazione dei linguaggi\nSulla decidibilitÃ  guardare Fondamenti teorica e La macchina di Turing\nIn questo caso i nuovi sono\nGrammatiche dipendenti dal contesto, in cui una singola produzione puÃ² avere piÃ¹ non-terminali. Grammatiche motonone, le cui produzioni basta che crescano Grammatiche generali, in cui non câ€™Ã¨ nessun vincolo di produzioni Schema generale delle grammatiche ðŸŸ© Per turing, vedere La macchina di Turing.\nGerarchia automi ðŸŸ¨+ In generale si puÃ² estendere dicendo\nAutomi Limitati riconoscono grammatiche dipendenti dal contesto Automi di Turing riconoscono i linguaggi ricorsivi, e sono in grado di enumerare ricorsivamente quelle generali. (anche se Ã¨ semidecidibile, quindi forse non riesce a ricononscerli tutte??) ","permalink":"https://flecart.github.io/notes/linguaggi-liberi-e-pda/","summary":"Ripasso Prox: 69 Ripasso: May 29, 2023 Ultima modifica: April 25, 2023 9:50 AM Primo Abbozzo: October 28, 2022 12:52 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Domande\nLinguaggi liberi e PDA Introduzione In questa parte del nostro percorso nei linguaggi di programmazione proviamo ad espandere NFA e DFA in modo che possano riconoscere linguaggi come $ww^r | w \\in \\{a, b\\}^*$ , con r maggiore o uguale a zero (r per dire che Ã¨ il contrario di w) (questo linguaggio per il pumping lemma).","title":"Linguaggi liberi e PDA"},{"content":"Ripasso Prox: 37 Ripasso: December 31, 2021 Ultima modifica: October 20, 2022 5:12 PM Primo Abbozzo: October 29, 2021 1:21 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Vecchi dubbi Activation record Busy waiting e polling, priorita\u0026rsquo; interrupt 8 ISA livello il livello isa Ã¨ il livallo delle istruzioni\n8.1 Struttura Solitamente le istruzioni sono divise in due parti:\n8.1.1 Opcode e indirizzamento Opcode\nQuesto opcode indica la tipologia di istruzione.\nPer esempio per l\u0026rsquo;architettura HACK Ã¨ il primo bit, che indica se Ã¨ una istruzione C oppure una istruzione A.\nQuesto insieme poi alle altre istruzioni che definiscono cosa deve fare costituiscono OPcode.\nIndirizzamento\nPoi c\u0026rsquo;Ã¨ una sezione che indirizza, cioÃ¨ dice all\u0026rsquo;istruzione cosa deve prendere e dove deve salvare.\n8.2 Indirizzamento 8.2.1 Diretto chiamato un indirizzamento diretto quando l\u0026rsquo;istruzione deve contenere l\u0026rsquo;informazione della memoria su come operare:\nun esempio Ã¨ $inc[5]$ per dire di incrementare il valore all\u0026rsquo;indirizzo 5\n8.2.2 Immediato Ha giÃ  l\u0026rsquo;operando da usare. Quindi nel caso dell\u0026rsquo;architettura HACK, per l\u0026rsquo;istruzione A ho giÃ  quello che devo fare\n8.2.3 Registro diretto Questo Ã¨ l\u0026rsquo;indizzamento solito, si utilizza il nome simbolico per dire su quale registro operare.\nAd esempio:\ninc dx in cui sto direttamente incrementando il registro\n8.2.4 Registro indiretto un esempio di indirizzamento indiretto Ã¨\ninc [dx] in cui sto andando a operare sulla locazione di memoria contenuta in dx.\nQuindi prende la locazione di dx, che puÃ² essere 5 10 o quel che i vuole e poi opera su questo.\nÃˆ molto simile al diretto, ma utilizza i registri\n8.2.5 Indicizzato Per esempio :\ninc [dx + 5] Prendo l\u0026rsquo;indirizzo di dx e ci prendo un offset\nDi solito puÃ² essere utile per activation record, che non so cosa sia, o accedere a certo tipo di strutture.\n8.2.6 con Stack Questa Ã¨ una indicizzazione molto utilizzata, tanto che ci sono dei registri apposta.\nAlcune operazioni solite sono pop e push, e la presenza di un registro sp che mantiene la locazione attuale dello stack (un pointer!)\nAnche questo per activation record\n8.3 Tipologie di istruzioni 8.3.1 Dati da memoria a registro.\nRegistro a registro e simili\n8.3.2 Aritmetico-logiche binarie Quindi somme, divisioni moltiplicazioni sottrazioni.\n8.3.3 Unarie Per esempio shift. (moltiplicazione o div per due)\nDi solito risparmiamo molte istruzioni a livello assembli utilizzando le operazioni unarie.\n8.3.4 Salti Quindi spostamento del PC che contiene l\u0026rsquo;istruction register\n8.3.5 Invocazione procedure In hack queste non esistono, ma esistono per la maggior parte delle altre architetture.\nQuesto salta alla procedura poi fa un return sulla procedure vecchia (si dice chiamata di stack)\nQuindi sono due comandi in piÃ¹ che non esistono per il nostro calcolatore\n8.4 Procedure 8.4.1 Activation record Quando viene chiamata una procedura, si crea un nuovo frame, salvando\nVariabili locali delle nuova chiamata Un puntatore alla vecchia istruzione Quando si ritorna alla istruzione precedente tutta questa roba, questo nuovo frame, viene eliminato.\nEsempio di chiamata di procedure\n8.5 Trap \u0026amp; interrupt Questi due gestiscono errori del programma. NO\n8.5.1 Caratteristiche del trap Questo errore viene chiamato nel caso in cui ci siano accessi non consentiti come\nOpcode non definito (strano, succede solo se codice corrotto o sistema sballato) Un accesso a memoria non consentita Questo Ã¨ gestito dal sistema operativo con un gestore di trap. Quindi togliere il controllo (e ucciderlo) al programma con la forza grazie al sistema operativo.\n8.5.2 Differenze con Interrupt La differenza principale Ã¨ che interrupt Ã¨ chiamato dall\u0026rsquo;esterno e interpretato grazie al sistema opertivo: per esempio il ctrl-c per ucciderei l programma. Questo Ã¨ gestito da interrupt Service Routine - ISR. Si puÃ² dire che sono asincroni mentre le trap sono sincrone.\nEs. quando la lezione Ã¨ interrota da una domanda a cui si vuole rispondere.\n8.5.3 PrioritÃ  dell\u0026rsquo;interrupt La CPU puÃ² scegliere di non seguire gli interrupt, si parla di interrupt mascherati nel caso in cui ci sia un lavoro molto importante (per esempio passare da un thread all\u0026rsquo;altro, qualcosa di strano che non dovrebbe essere interrotto mentre sta operando).\nOppure anche per scegliere delle prioritÃ  se tastiera o disco e simili..\nTipo se il prof non risponde subito alla domanda e dice che lo farÃ  dopo.\n8.5.4 Busy waiting Ãˆ una altra soluzione all\u0026rsquo;interrupt, cioÃ¨ ogni 100 millisecondi il sistema operativo va a guardare se esiste un input umano. Ovviamente Ã¨ molto inefficiente. (in pratica sta aspettando se il disco ha finito per ricominciare a fare le cose normali).\n8.5.5 Polling Ãˆ molto simile al busi waiting, perÃ² invece di non fare nulla e aspettare soltanto quando non va a guardare, fa qualche operazione.\nTipo il prof che chiede se ci sono delle domande. e al busi waiting, perÃ² invece di non fare nulla e aspettare soltanto quando non va a guardare, fa qualche operazione.\nTipo il prof che chiede se ci sono delle domande.\n","permalink":"https://flecart.github.io/notes/livello-isa/","summary":"Ripasso Prox: 37 Ripasso: December 31, 2021 Ultima modifica: October 20, 2022 5:12 PM Primo Abbozzo: October 29, 2021 1:21 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Vecchi dubbi Activation record Busy waiting e polling, priorita\u0026rsquo; interrupt 8 ISA livello il livello isa Ã¨ il livallo delle istruzioni\n8.1 Struttura Solitamente le istruzioni sono divise in due parti:\n8.1.1 Opcode e indirizzamento Opcode\nQuesto opcode indica la tipologia di istruzione.","title":"Livello ISA"},{"content":"Introduzione (idea principale) In breve: essence card ðŸŸ©- Giallo = Prodotto. Metafora staffetta-rugby ðŸŸ© Con altri metodi si fanno produzioni stile staffetta, ossia un membro sta fermo, finchÃ© non ha il testimone e poi si uccide correndo\u0026hellip; Il metodo piÃ¹ utile ispirato a scrum Ã¨ rugby, che tutti si muovo insieme collaborando. Un po\u0026rsquo; di tutto Ã¨ fatto durante lo sprint\nCicli di base (3) ðŸŸ© Planning: in cui vengono scelti i task da eseguire durante questo sprint, solitamente questo viene preso da un subset dei task descritti dal product owner. Execution: questo Ã¨ abbastanza chiaro, si sviluppa. Retrospective and review: in cui vengono identificati i problemi che sono stati incontrati durante lo sviluppo, e modi possibili per risolverli. Lo sprint (3) ðŸŸ©- Una cosa molto importante che aiuterÃ  di gran lunga lo sviluppo Ã¨ la costanza che Si scelgono\nTask READY che vengono fatte Queste vengono spostate in done quando sono fatte E poi vengono testate, questo per tutto il prodotto. Questo lo guarderemo in una sezione successiva.\nRuoli Introduzione in generale ai ruoli (3) ðŸŸ© Product owner: deve rappresentare il cliente e scrivere le features piÃ¹ interessanti per il team, sempre secondo ciÃ² che deve essere utile per il cliente.. Scrum Master deve cercare di eliminare gli ostacoli. Esempio: persone che litigano internamente al team Persone lavorano meno e non portano risultati, e si isola. Developer chi sviluppa. All\u0026rsquo;esterno ci sono gli stakeholders che sono in pratica i clienti, vuole cercare di capire esattamente cosa debba essere fatto.\nIn breve: Dinamiche del team ðŸŸ¨ Auto-organizzazione, ossia il team stesso dovrebbe definire i suoi ruoli TODO: definire questa parte meglio, in che sensi si dovrÃ  auto-organizzare il team? Scrum pillars Scrum team A Scrum team is a group of individuals who work collaboratively to deliver high-quality product increments. The team is typically composed of a Scrum Master, a Product Owner, and Developers. The Scrum Team is cross-functional, self-organizing, and responsible for all product-related activities, including stakeholder collaboration, verification, maintenance, operation, experimentation, research, and development. The team is structured and empowered by the organization to manage their own work, and they work in Sprints at a sustainable pace to improve focus and consistency. The Scrum Team is small enough to remain nimble and large enough to complete significant work within a Sprint, typically consisting of 10 or fewer people. The team is focused on achieving the Product Goal and shares the same Product Backlog and Product Owner. The Scrum Team embodies the principles of transparency, inspection, and adaptation, and is essential for the successful implementation of the Scrum framework in delivering valuable products https://www.visual-paradigm.com/scrum/what-is-scrum-team/ Product Owner Ãˆ il membro del team che si relaziona con gli stakeholders esterni. rappresenta il punto di vista del cliente e deve essere in grado di descrivere il prodotto al team. Dato che Ã¨ il cliente che stabilisce le prioritÃ , dovrebbe gestire le prioritÃ  (massimizza il valore dei rilasci). Dato che Ã¨ la figura che va con i clienti, deve anche essere in grado di recepire i cambiamenti di mercato e comunicarlo per bene al team. Deve sapere cosa prioritizzare per avere prodotto migliore nelle prossime iterazioni seguendo i dati che vengono raccolti durante lo scrum.\nResponsabilitÃ \nProduct Goal. Triangolo di Ferro (3) Scope Cost Time Si tratta di migliorare la qualitÃ  del software restando dentro a questi limiti. Ãˆ anche una cosa che dovrebbe essere per Project Management, ossia quello che il manager deve considerare per fare stime dei progetti e consegnare piÃ¹ qualitÃ . In waterfall Ã¨ lo scopo la dimensione costante, cambiano le altre due.\nEventi scrum Riassunti eventi scrum (!!) (4) ðŸŸ© Planning, in cui si scelgono le cose da fare Review, in cui si analizza quanto bene si Ã¨ fatto Retrospective, in cui si guarda come si potrebbe migliorare Daily Standup, feedback su quanto siamo messi. Sprint planning (2) ðŸŸ© Si tengono in conto vari fattori (vedi immagine), e a seconda di questi vogliamo avere due output\nGOAL, l\u0026rsquo;obiettivo del nostro sprint Planning Chi fa cosa Il backlog presente Planning Poker ðŸŸ© Ãˆ un gioco per stimare il tempo dei task https://planningpokeronline.com/ che Ã¨ molto divertente. Solve il problema di stimare il tempo necessario per fare qualcosa.\nVelocitÃ  sprint ðŸŸ© Si puÃ² intendere come il numero di story point completati, che solitamente Ã¨ dipendente da qualcosa di passato. Questo serve per stimare quanto si riuscirÃ  a fare negli sprint successivi.\nSprint review ðŸŸ© In cui Ã¨ presente una demo del prodotto, con anche magari gli stakeholders Una specie di presentazione e piÃ¹ gente forse :). Quindi si ha un feedback su quanto fatto per il prodotto durante lo sprint.\nSprint retrospective (3) ðŸŸ© Si parla di ciÃ² che\nStart doing (che magari potrebbe aiutare, che prima non si faceva) Stop Doing che magari Ã¨ una cosa tossica da fare, non aiuta, e prende tempo Continue doing se va ancora bene Ãˆ sempre all\u0026rsquo;interno di scrum un modo per vedere se si puÃ² migliorare il modo di lavorare. Artefatti Product backlog ðŸŸ© Qui trattiamo l\u0026rsquo;insieme degli aspetti utili a gestire tutti i task che dovranno essere fatti\nGestione del backlog ðŸŸ© La scelta dei singoli task Ã¨ fatta in maniera volontaria da parte di chi lavora. Il lavoro-board deve essere aggiornato volta volta in cui si continua a starci sopra. User story mapping ðŸŸ© L\u0026rsquo;idea Ã¨ giÃ  dividere task per task, nei sprint corretti.\nEsempi di mapping possibili Burndown chart ðŸŸ© In pratica il numero totale di ore che sarÃ  una stima di quanto fatto.\nCaso ideale: lineare. Sono quindi dei grafici per valutare qualitÃ  del lavoro\nConclusioni Meta-scrum Cause effetti negativi NOTA: questa alla fine non Ã¨ scienza, si fa fatica a fare uno studio comparativo che cerchi di identificare se funziona o meno questo metodo, Ã¨ solamente\nDefinizioni di fatto o finito The DoR outlines the criteria that a specific user story must meet before being considered for estimation or inclusion into a sprint. It describes the characteristics of an effective user story and ensures that the team has a shared understanding of what\u0026rsquo;s needed for a user story to be brought into a sprint. The DoR is optional and is particularly useful when aspects of user stories are impeding progress, leading to stories being rolled into the next sprint. It is focused on user story level characteristics and is changeable based on the team\u0026rsquo;s needs\nThe DoD is a shared understanding among team members of what it means for a product backlog item (PBI) to be considered complete. It applies to all work in the backlog and represents the acceptance criteria for a sprint or release. The DoD outlines the quality standards that a piece of work needs to reach to be releasable. It is essential for ensuring consistent delivery of quality and is often standardized across the company. The DoD is changeable and may need to be adjusted based on the team\u0026rsquo;s needs\nMancanze di supporto Scrum master che non fa il lavoro Cattiva comunicazione di PO Cattiva comunicazione dei desiderata da parte degli stakeholders. ","permalink":"https://flecart.github.io/notes/scrum-method/","summary":"Introduzione (idea principale) In breve: essence card ðŸŸ©- Giallo = Prodotto. Metafora staffetta-rugby ðŸŸ© Con altri metodi si fanno produzioni stile staffetta, ossia un membro sta fermo, finchÃ© non ha il testimone e poi si uccide correndo\u0026hellip; Il metodo piÃ¹ utile ispirato a scrum Ã¨ rugby, che tutti si muovo insieme collaborando. Un po\u0026rsquo; di tutto Ã¨ fatto durante lo sprint\nCicli di base (3) ðŸŸ© Planning: in cui vengono scelti i task da eseguire durante questo sprint, solitamente questo viene preso da un subset dei task descritti dal product owner.","title":"Scrum Method"},{"content":"Ripasso Prox: 20 Ultima modifica: February 1, 2023 4:21 PM Primo Abbozzo: December 30, 2022 9:40 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Syncronous model Introduction Da ricordare il \u0026ldquo;The State Machine Replication (SMR) Problem\u0026rdquo; che Ã¨ importantissimo per comprendere questa parte.\nStoria locale Transazioni al singolo noto Problema del sync fra tutti questi nodi.\nGoal of SMR solution in blockchains Andiamo a considerare alcune proprietÃ  di safety e liveness Programmi Concorrenti\nConsistenza i nodi devono essere daccordo su quale transazione mettere prima e dopo â†’ stessa storia per tutte le transazioni. (con la possibilitÃ  di alcuni nodi che siano indietro, ma solo prefisso!). Liveness che vogliamo dire che tutte le transazioni valide devono essere aggiunte alla fine Assunzioni per sincrono (4) Permissioned, ossia i nodi del nostro modello sono fissi, non possiamo averne di piÃ¹, non possiamo averne di meno e sono conosciuti. Public key infrastructure, Ogni nodo ha una coppia pubblica e privata. Synchronous, esiste una sorta di stato globale, e tutti i nodi condividono questa informazione. 0, 1, â€¦ t. I messaggi sono tutti mandati bene, e arrivano esattamente uno step dopo. (mandato al tempo t, arriva a t + 1). OnestÃ  di tutti i nodi (sarÃ  droppato subito questa assunzione). 4â€™. Una percentuale dei nodi Ã¨ bizantina.\nAltre di base trattate prima\nesistenza di internet Esistenza di crittografia Si puÃ² notare che le ultime due assunzioni sono le stesse piÃ¹ generali definite in Consensus protocols, andremo negli appunti in seguito solamente a rilassare alcune assunzioni di 1 e 2.\nLa 1 Ã¨ stata storicamente molto sensata, dato che era pensata per database che comunicassero fra di loro, e chiaramente quello era un settings piÃ¹ controllato, per blockchain vorremmo anche provare rilassare questo.\nBizantine broadcast problem Questo Ã¨ un problam molto simile a SMR, tanto che si potrÃ  dimostrache che risolvere SMR si puÃ² ridurre a dimostrare BB. Andremo quindi a descrivere questo problema\nFaulty/Bizantine Nodes Alcuni nodi falliscono, anche se non intenzionalmente, per esempio con errori di hardware.\nUn nodo che non Ã¨ onesto (comporta come si dovrebbe comportare) Ã¨ faulty.\nMotivi di errore possibile\nCrash fault (errore del software oppure dellâ€™hardware). Omission fault (in cui la trasmissione di informazione importante Ã¨ fallita, puÃ² essere intenzionale o meno) Bizantine fault (un certo insieme di nodi fa come gli pare) Ãˆ molto importante comprendere questo concetto, dato che sarÃ  di base nellâ€™analisi della costruzione di protocolli che funzionino per BB.\nIn modo intuitivo possiamo intendere un nodo come bizantino sse non si comporta come dovrebbe. E lÃ¬ vengono descritte anche 3 cause per il suo non-comportamento corretto.\nDescrizione del problema Un nodo leader e n - 1 nodi non leader. Il leader ha una informazione privat a $v ^*$ che deve mandare a tutti.\nUna soluzione del problema deve soddisfare queste tre caratteristiche\nValiditÃ  ossia se il nodo sender (leader) Ã¨ onesto, gli altri devono essere daccordo che il messaggio Ã¨ $v^*$ Terminazione non di deve essere deadlock, i nodi devono terminare con qualche risultato. Agreement quando termina, tutti i nodi onesti devono essere dâ€™accordo sullo stesso risultato. SMR si riduce a BB Prenderemo in questa soluzione lâ€™idea presente in Round-Robin leaders, ad avere ad ogni momento un leader.\nAllora dato questo leader, utilizziamo BB con leader = sender, e gli altri nodi per mandare il messaggio privato.\nAllora questo algoritmo possiede sia liveness che consistency. Liveness per stesso motivo di prima, prima o poi un nodo diventa un leader, quindi riesce ad aggiungere la sua informazione privata.\nConsistency perchÃ© perla soluzione di BB, ogni nodo onesto alla fine sarÃ  dâ€™accordo su quanto deve aggiungere alla sua lista privata. In particolare se il leader Ã¨ onesto sarÃ  esattamente quanto mandato dal sender.\nSlides\nAlcune soluzioni Lazy SMR Se ogni nodo non comunicasse, ma aggiungesse alla propria lista privata la transazione, questo non funziona. Non câ€™Ã¨ proprio la consistenza. Non ci si puÃ² aspettare che il nodo esterno, la transazione riesca a richiedere allo stesso tempo a tutti i nodi.\nDa qui concludiamo che i nodi devono comunicare fra di loro (che Ã¨ una cosa molto banale).\nRound-Robin leaders QuestÃ  Ã¨ una idea che ogni nodo diventa leader e si mette a coordinare i nodi a turni, in un certo senso Ã¨ molto simile allâ€™idea presente in Architettura e livelli 1, 2 riguardo le reti ad anello e il passaggio del testimone.\nFunzionamento\nI nodi diventano leader aseconda del tempo globale.\nIl nodo leader manda a tutti gli altri la sua lista, gli altri aggiungeranno al proprio alla fine, allâ€™inizio metto le propria (quindi).\nCorrettezza\nSia consistenza sia liveness vengono soddisfatti. La liveness Ã¨ soddisfatta perchÃ© prima o poi il nodo n sarÃ  il leader, allora avrÃ  lâ€™occasione di aggiungere alla catena i suoi dati privati.\nLa consistenza viene soddisfatta perchÃ© sotto le assunzioni che abbiamo i messaggi vengono mandati e ricevuti esattamente in uno step di tempo, quindi ogni nodo riesce ad aggiungere alla sua lista privata quello che gli Ã¨ di interesse.\nNecessitÃ  dellâ€™onestÃ \nSe un nodo non onesto diventa leader, potrebbe mandare un pÃ² della sua lista ad lacuni nodi e niente ad altro (omission fault) e quindi questo rompe tutta la consistenza! Quindi questo metodo funziona solamente nel caso in cui nessun nodo fallisca. Vorremmo perÃ² resiste anche al fallimento!\nDolev-Strong protocol Lâ€™idea generale di questo protocollo Ã¨ capire se il sender Ã¨ onesto o meno. Se si riesce a capire questa cosa, allora se Ã¨ onesto prendo il suo valore, altrimenti metto bottom sulla mia pila\nConvincing messages Definizione in slide\nThe protocol Quel mandare cose Ã¨ piÃ¹ o meno cercare di capire se il nodo sender ha mandato messaggi contraddittori.\nProof of correctness PKI (Hexagon proof) Pease, Shostak, and Lamport [PSL80], and later the proof was simplified by Fischer, Lynch, and Merritt [FLM85].\nQuesta Ã¨ una dimostrazione molto importante per quanto riguarda questo modello. Mostra che ci sono delle limitazioni pesanti riguardanti il modello. Come si vedrÃ  in seguito anche in Asynchronous model, ci saranno delle limitazioni in praticamente qualunque modello.\nEnunciato Siano n nodi allâ€™interno di un modello a comunicazione sincrona in cui non Ã¨ presente un setting PKI (chiave privata e pubblica), se i nodi bizantini sono $f \\geq n / 3$, allora non Ã¨ possibile avere contemporaneamente terminazione, safety e liveness.\nDimostrazione Dimostreremo solamente il caso in cui n = 3, poi si dovrebbe estendere senza molto sforzo al caso maggiore generico.\nQuesta dimostrazione va a contraddizione. Supponiamo di avere un setting a 6 nodi come in figura\nI nodi F sono i sender, mentre M e L sono le altre cose.\nOra da notare Ã¨ che il procollo puÃ² eseguire su questo sistema, cioÃ¨ anche se era inteso per essere eseguito nel caso $n = 3$, le uniche cose di cui ha bisogno il protocollo Ã¨\nSapere se Ã¨ un sender o meno Il messaggio da inviare se Ã¨ il sender I suoi n - 2 vicini (quindi sapere a chi mandare). Quindi sotto queste assunzioni il protocollo puÃ² eseguire\nAllora andiamo a considerare 3 scenari possibili:\nScenario 1 F bizantino\nSupponiamo di essere in un sistema a 3, con L, M, F, ma F Ã¨ il nodo bizantino. F dato che Ã¨ bizantino puÃ² fare cose arbitrarie, in particolare facciamo finta che simuli i nodi Fâ€™, Mâ€™, Lâ€™, F collegati come di sopra.\nAllora dato che il nosto protocollo deve soddisfare consistenza, ossia tutti i nodi onesti devono finere per essere dâ€™accordo su qualcosa, deve essere che nel sistema lâ€™output di L = M\nScenario 2 L bizantino\nSistema a 3 dato da L, M, e Fâ€™, ma in questo caso ora il nodo M simula i nodi M, L, F, Mâ€™. Per validitÃ  del protocollo deve essere che L Ã¨ d\u0026rsquo;accordo con lâ€™output 1, del sender Fâ€™.\nScenario 3 M bizantino\nSimile al siste a tre nel primo caso, ora L simula L, Fâ€™, Mâ€™, Lâ€™. Quindi per validitÃ  M dÃ  in output F.\nma allora bbiamo un assurdo perchÃ© L dovrebbe essere uguale a M, invece l\u0026rsquo;output Ã¨ diverso. Quindi questo scenario non puÃ² succedere.\n","permalink":"https://flecart.github.io/notes/syncronous-model/","summary":"Ripasso Prox: 20 Ultima modifica: February 1, 2023 4:21 PM Primo Abbozzo: December 30, 2022 9:40 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Syncronous model Introduction Da ricordare il \u0026ldquo;The State Machine Replication (SMR) Problem\u0026rdquo; che Ã¨ importantissimo per comprendere questa parte.\nStoria locale Transazioni al singolo noto Problema del sync fra tutti questi nodi.\nGoal of SMR solution in blockchains Andiamo a considerare alcune proprietÃ  di safety e liveness Programmi Concorrenti","title":"Syncronous model"},{"content":"Ripasso Prox: 24 Ripasso: June 2, 2022 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: March 14, 2022 2:11 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso DImostrare per benino la condizione sufficiente di differenziabilitÃ  perchÃ© probabile che alcuni passaggi non li fai per filo e per segno. 10 Calcolo differenziale 10.1 Derivata parziale La derivata vuole descrivere quanto varia una funzione al variare dell\u0026rsquo;input. Ma ora siamo in piÃ¹ dimensioni, quindi vogliamo descrivere il variare dell\u0026rsquo;input come il variare della distanza euclidea\n$\\dfrac{\\delta f}{\\delta x}(x,y) = \\lim _{h \\to 0} \\dfrac{f(x + h, y) - f(x, y)}{h}$ ovvero sto facendo variare solamente una variabile (la y in questo caso Ã¨ come se fosse una costante!?) Questo Ã¨ un rapporto incrementale su una direzione.\nSe esiste il limite, Ã¨ la derivata parziale rispetto a x.\nIn modo analogo puoi definire una derivata parziale rispetto a y\n10.1.1 Gradiente Se vogliamo considerare allo stesso momento la derivata parziale per ogni componente, possiamo farlo considerando un unico simbolo: (indica il gradiente della funzione).\n$$ \\nabla f(x,y) = (\\delta_xf(x,y), \\delta_y f(x,y)) $$ Se in ogni punto Ã¨ derivabile allora possiamo proprio definire una funzione gradiente di questa, nel modo di sopra.\nQuesta definizione si puÃ² estendere per uno spazio n-dimensionale\n10.1.2 Legame con la continuitÃ  Si ha una relazione molto simile con la derivata a singola dimensione (cazzo non mi ricordo bene la dim????)\n$f:A \\to \\R$ se $f$ Ã¨ derivabile in $x$ allora $f$ Ã¨ continua in $x$ in R normale, ma se a piÃ¹ dimensioni avessimo le derivate parziali non abbiamo la continuitÃ  in quel punto.\nEG $$\\begin{cases} \\dfrac{xy}{x^2 + y^2} \\text{ se diverso dall'origine }\\\\ 0 \\text { altrimenti } \\end{cases}$$ in questo esempio entrambe le derivate parziali in (0,0) esistono, ma non Ã¨ continua in questo punto (tende a +- infinito in questo punto).\nAnalisi della funzione sopra\nSi puÃ² dimostrare che la funzione di sopra ha entrambe le derivate uguali a 0 quando tende a 0. (applicare la definizione di derivata parziale).\nDimostriamo che non Ã¨ continua in (0,0) ovvero esiste una successione che tende a 0, ma non vale la definizione di continuitÃ , ovvero non vale che $f(a_n, b_n) \\to f(0,0) = 0$.\nScegliamo la successione simile: $(a_n,b_n) = (1/n, 1/n)$ che ovviamente tende a 0.\nMa .\n(1/n * 1/n) / (2/(n*n)) != 0 Quindi questa successione tende a 2, mentre dovrebbe tendere a 0. Un caso patologico di continuitÃ , ma che comunque da l\u0026rsquo;idea di questo.\n10.1.3 DerivabilitÃ  e differenziabilitÃ  (intuizione) Si ricordi la definizione di derivata in $\\R$. Derivate.\nSi ricordi anche come si Ã¨ ricavata l\u0026rsquo;approssimazione con serie di taylor e gli o-piccoli in Hopital, Taylor, Peano\nPer descrivere la nozione di derivabilitÃ  vogliamo ricondurci a una formula di Taylor per il primo grado. (perchÃ© nelle derivate parziali sappiamo quando varia in due direzioni, ma mancano informazioni su quanto varia in tutte le direzioni, ed Ã¨ per questo motivo che non ho la continuitÃ ).\nVorrei considerare un limite simile a $f(x + h, y+ h) - f(x, y)$, che possiamo riscrivere in forma vettoriale $f((x + y)+ (h,k)) - f(x,y)$ e ricondurci a una forma di approssimazione con taylor.\nDef o-piccolo a piÃ¹ dimensioni:\n$g: \\mathbb{R}^2 \\to \\mathbb{R}$ si dice che $g(h,k) = o(\\lvert(h,k)\\rvert)$ se ho che $\\lvert g(h,k)\\rvert/ \\lvert (h,k)\\rvert \u003c \\epsilon$ , con $0\u003c \\lvert(h,k)\\rvert \u003c \\delta$ per ogni epsilon maggiore di 0, quindi considero la norma (che mi da una nozione di distanza). Ma i concetto di o-piccolo Ã¨ ancora ben presente.\nPossiamo anche scrivere la stessa definizione utilizzando le successione.\nCome qui Avendo questa nozione di approssimazione per taylor, posso dare una nozione di differenziabilitÃ . In questo modo riesco a dare una nozione di funzione che tende a zero piÃ¹ o meno velocemente della norma. (o potenze di esse).\n10.2 DifferenziabilitÃ  Questa Ã¨ la condizione molto piÃ¹ forte rispetto alla derivata, Ã¨ il concetto che ci permette di avere subito la continuitÃ .\nLa differenza principale con la derivata Ã¨ che qui non consideriamo una unica direzione cerchiamo di prenderle tutte. Andiamo ora a vedere come definire questo fatto.\n10.2.1 La funzione differenziabile Sia $f$ una funzione da $A \\subseteq \\R^2$ aperto da $f: A \\to \\R$. Si dice che la funzione $f$ sia differenziabile se:\nEsistono le derivate parziali per tutte le direzioni. Se vale $$ f((x + h, y + k)) = f((x, y) + (h,k)) = f(x,y) + \\langle\\nabla f(x,y), (h,k)\\rangle + o(\\lvert h,k \\rvert ) $$ Possiamo scrivere questa cosa con una altra notazione equivalente:\n$f(x, y) = f(\\bar{x}, \\bar{y}) +\\langle\\nabla f(x,y), (x - \\bar{x},y - \\bar{y})\\rangle + o((\\mid x - \\bar{x},y - \\bar{y} \\mid)$ con $(x,y) \\to(\\bar{x}, \\bar{y})$\nE questo assomiglia di piÃ¹ rispetto al polinomio di taylor, perchÃ© effettivamente qui si ha lâ€™approssimazione in bella vista.\nAndiamo ora a dare una intuizione sul perchÃ© vogliamo la seconda condizione.\nIntuizione del punto 2\nNon stiamo facendo altro che dare la formula di taylor del primo ordine (vedi Hopital, Taylor, Peano) sul punto (x, y) ma lo stiamo considerando a piÃ¹ dimensioni.\nQuindi, ricordando che lâ€™espansione con le serie di taylor ci permetteva di fare una approssimazione, questa condizione per il punto 2 non Ã¨ altro che una approssimazione al variare in una qualsivoglia direzione.\n10.2.2 Polinomio di taylor del primo ordine $$ T_1(x,y) = f(\\bar{x}, \\bar{y}) +\\langle\\nabla f(x,y), (x - \\bar{x},y - \\bar{y})\\rangle $$ In particolare qui abbiamo una approssimazione dellâ€™equazione tangente a un punto voluto (in R2 un piano, in R1 una retta, in R3 vedi che Ã¨ uno spazio), il punto $(\\bar{x}, \\bar{y}, f(\\bar{x}, \\bar{y}))$\n10.2.3 DifferenziabilitÃ  implica continuitÃ  $f:A \\to \\R$ aperto (perchÃ© cosÃ¬ ho tutti gli intorni e questo mi semplifica prendere successioni a caso)) in R2.\nse f Ã¨ differenziabile in un punto $(a,b) \\implies f \\text{ continua in } (a, b)$\nDobbiamo dimostrare che per ogni successione che tende a (0,0) deve essere che $f(a + h_n, b+ k_n) \\to f(a,b)$ se ho dimostrato questa cosa ho la continuitÃ . Ma per il punto 2 della definizione di differenziabilitÃ  ho che $f(a,b) + \\langle\\nabla f(a,b), (h,k)\\rangle$ ma con h e k tendenti a 0 ho che il prodotto scalare del gradiente di esse Ã¨ tendente a 0 (anche o piccolo lo Ã¨) , quindi ho la continuitÃ .\n10.2.4 Condizione sufficiente di differenziabilitÃ  (!!!) Se le derivate parziali esistono e sono continue (f di classe C1) , f Ã¨ differenziabile in ogni punto\nLa definizione di differenziabilitÃ  non Ã¨ molto maneggevole, per questo motivo ci Ã¨ utile cercare una condizione di differenziabilitÃ  che sia piÃ¹ semplice da calcolare.\nQuesto Ã¨ uno dei teoremi principali della differenziabilitÃ . Collega questo con il concetto di derivata, giÃ  studiata in precedenza in R\nEnunciato\nUna volta definita la funzione di classe C1 possiamo riscrivere questo enunciato in maniera piÃ¹ compatta. Queste funzioni sono tali per cui la derivata parziale in ogni direzione esiste , e questa derivata Ã¨ anche continua (ricorda questa definizione di Classe k)\nLemma preliminare (Lagrange multivariabile)\nUtilizziamo un lemma per dimostrare il punto di sopra.\n$$ f \\in C^1(\\R^2), \\text{ siano } (a,b) \\in \\R^2, h, k \\in \\R \\implies \\exists \\alpha, \\beta \\in (0,1) | \\\\f(a + h, b) - f(a,b) = \\delta_x f(a + \\alpha h, y) h \\\\ f(a, b + k) - f(a,b) = \\delta_y f(a, b + \\beta k) k $$ La dimostrazione Ã¨ analoga per i due punti, quindi lo facciamo solamnete per uno. Per il teorema di lagrange presente nei reali, mi costruisco la funzione $g(x) = f(x, t)$ con un t fissato (notiamo che g Ã¨ continua e derivabile in quanto Ã¨ costituito da f, che per ipotesi Ã¨ continua e derivabile), allora esiste c appartenente al dominio di g tale per cui $g'(c) \\cdot h = g(a + h) - g(a)$ ossia $f(a + h,b) - f(a,b)$. Ecco che appaiono i valori di cui abbiamo bisogno in RHS.\nGuardando LHS abbiamo che\n$$ g'(x) = \\lim_{s \\to 0}\\dfrac{g(x + s) - g(x)}{s} = \\lim_{s \\to 0}\\dfrac{f(x + s, t) - f(x, t)}{s} = \\delta_xf(x) $$ Scrivendo c come prodotto di h e un opportuno $\\alpha$ possiamo dire che $c = a + \\alpha h$ (tanto deve stare in questo intervallo $(a, a +h)$, quindi Ã¨ possibile assumere che ci sia tale alpha compreso da 0 e 1).\nRiscrivendo il tutto per benino abbiamo la nostra tesi.\nDimostrazione\nPer definizione di differenziabilitÃ  devo dimostrare che ciÃ² sia vero.\n$\\langle\\nabla f(a,b), (h,k)\\rangle + o(|h, k|) = f(a + h, b + k) - f(a,b) = f(a + h, b + k) - f( a+h, b) + f(a+h, b) - f(a,b)$\nAggiungendoci e togliendo quel fattore dopo lâ€™ultima equazione, posso mettermi ad utilizzare Lagrange multivariabile (ho per il primo che x Ã¨ la stessa, per il secondo y Ã¨ la stessa).\nAndiamo a utilizzare le derivate parziali allora:\n$f(a + h, b + k) - f( a+h, b) = \\delta_yf(a+h , b+\\beta k)k$\ne in modo simile\n$f(a+h, b) + f(a,b) = \\delta_x f(a + \\alpha h, b) h$\nAllora riscriviamo la equazione iniziale, e vediamo che sia corretta effettivamente:\n$\\langle\\nabla f(a,b), (h,k)\\rangle + o(\\lvert h,k \\rvert) = \\delta_yf(a+h , b+\\beta k)k + \\delta_x f(a + \\alpha h, b) h$\nHo $h\\delta_x f(x,y) + k \\delta _yf(x,y) + o(\\lvert h,k \\rvert)$ dal gradiente. Se riesco a dimostrare questo allora ho finito.\nSe riusciamo a dimostrare $\\delta_x f(a + \\alpha h, b) h = h\\delta_x f(x,y) + o(\\lvert h, k \\rvert)$ allora ho finito (stessa cosa per lâ€™altra).\nLâ€™ultima proposizione Ã¨ equivalente a dire che $\\delta_x f(a + \\alpha h, b) h - h\\delta_x f(a,b) = o(\\lvert h,k \\rvert)$\novvero che (per definizione di o piccolo) quella cosa tenda a 0, ossia che.\n$$ \\lim_{h,k \\to (0,0)} \\dfrac{h}{\\lvert h, k \\rvert} [\\delta_x f(a + \\alpha h, b) - \\delta_x f(a,b)] = 0 $$ $\\dfrac{h}{\\lvert h,k \\rvert} [\\delta_x f(a + \\alpha h, b) - \\delta_x f(a,b)] \\leq [\\delta_x f(a + \\alpha h, b) - \\delta_x f(a,b)]$ per le proprietÃ  della norma.\nOra utilizziamo la continuitÃ  della derivata, che si ha in ipotesi e possiamo concludere che quella differenza.\nConclusione con la continuitÃ  E si puÃ² dimostrare che $a + \\alpha h, b) \\in B(a,b),\\delta)$ E lâ€™ultimo dato Ã¨ vero per ipotesi di continuitÃ .\n10.3 Derivata direzionale Il concetto di derivata direzionale generalizza il concetto di derivata parziale, perchÃ© ora invece di andare in una direzione di una base canonica, andiamo nella direzione di un vettore.\n10.3.1 Definizione Dato $x \\in \\mathbb{R}^n$ e $v\\in \\mathbb{R}^n-\\{0\\}$, consideriamo l\u0026rsquo;insieme $\\{x + tv | t \\in \\mathbb{R}\\}$, abbiamo l\u0026rsquo;insieme di una linea, passante per il nostro punto che abbia la direzione del vettore preso.\nAllora con tutto questo iniziamo la definizione:\n$f:A \\to \\mathbb{R}, (a,b) \\in A$ e dato $v = (v_1, v_2)$ un vettore unitario, allora si ha che la derivata direzionale Ã¨\n$$ \\lim_{t \\to 0} \\dfrac{f((a,b) + tv) - f(a,b)}{t} $$ In pratica stiamo andando in una direzione scelta di v. (da notare infatti che se preso il vettore in una direzione parallela alla base canonica, allora ho le derivate parziali).\nOsservazione 2 Posso creare una funzione ausiliaria, e vedo che la derivata direzionale Ã¨ uguale alla derivata (normale 1-variabile) della funzione ausiliaria: $g(t) = f(a + tv_1, b+ tv_2)$ Si nota che $D(g(t)) = \\lim_{h \\to 0} \\dfrac{g(h) -g(0)}{h} = \\dfrac{f(a + tv_1, b+ tv_2) - f(a, b)}{h}$\n10.3.2 Formula del gradiente (!!!) Presa una funzione differenziabile con dominio opportuno e codominio R2, e un vettore in R2, possiamo definire con precisione la derivata direzionale su questo vettore in particolare Ã¨:\n$\\dfrac{\\delta f}{\\delta v} (a,b) = \\langle \\nabla f(a,b), (v_1,v_2)\\rangle$\nOsservazione\nQuesta Ã¨ una cosa forte, perchÃ© mi dice che se conosco le derivate parziali riesco a trovare il valore della derivata in qualunque direzione. Ma da notare che deve essere differenziabile!.\nDimostrazione $$ f(a + tv_1, b+ tv_2) - f(a, b) = \\langle\\nabla f(a,b), tv\\rangle + o(\\lvert tv \\rvert) $$ Questo vale per la formula di Taylor, noi siamo perÃ² interessati al limite, quindi siamo interessati a questo: $$ \\lim_{t \\to 0} \\dfrac{ \\langle\\nabla f(a,b), tv\\rangle + o(\\lvert tv \\rvert )}{t} $$ Ed Ã¨ abbastanza ovvio che la soluzione di questo limite Ã¨ $\\langle\\nabla f(a,b), v\\rangle$ (basta portare fuori la t e dividerla con la t di sotto), mentre l\u0026rsquo;o-piccolo tende a 0 per definizione di o piccolo. 10.3.3 Direzione massima e minima di crescita (!!) Il problema corrente Ã¨ stabilire la direzione massima di crescita per una funzione differenziabile definita in dominio di dimensione maggiore di 0.\nDato il gradiente (consideriamo questo diverso da 0 perchÃ© nell\u0026rsquo;altro caso Ã¨ qualcosa di abbastanza banale). Se Ã¨ diverso da 0, posso allora normalizzare il vettore (e scriverlo con coordinate polari in un modo simile a quanto fatto in Analisi multi-variabile.\n$$ \\nabla f(a,b) = \\lvert \\nabla f(a,b) \\rvert \\cdot (\\cos\\theta, \\sin \\theta) $$ Ricordiamo per punto sopra che la derivata direzionale Ã¨\n$\\langle \\nabla f(a,b), (v_1,v_2)\\rangle$, (notiamo che v Ã¨ definito come versore, quindi possiamo passare alle cordinate polari anche lÃ¬, allora il valore di questa derivata direzionale Ã¨\n$$ \\langle \\nabla f(a,b), (\\cos\\gamma,\\sin\\gamma)\\rangle = \\lvert \\nabla f(a,b) \\rvert \\cdot \\cos(\\theta - \\gamma) $$ Che Ã¨ massima quanto il valore nel coseno Ã¨ 1 (coseno 0), minima quando Ã¨ 0.\nMa esiste solamente un unico vettore unitario per cui succede, questa Ã¨ la direzione che rende massima la derivata. dunque $\\theta = \\gamma$ e quindi\n$$ v_{max} = \\dfrac{\\nabla f(a,b)}{ \\lvert \\nabla f(a,b) \\rvert } $$ Osservazione:\nAvendo il vettore di direzione per il massimo possiamo calcolare effettivamente il valore della derivata direzionale massima, questa Ã¨ effettivamente uguale al gradiente:\n$$ \\langle \\nabla f(a,b), v_{max})\\rangle = \\mid\\nabla f(a,b)\\mid $$ 10.4 Derivate di curve Consideriamo le curve (anche chiamati cammini in Rn)\nDue funzioni\nScalari da Rn a R Cammini parametrizzati (da un sottoinsieme di ab a Rn) In seguito saranno utili per comprendre gli insiemi di livello di f.\n10.4.1 Cammini I cammini sono una funzione da R a Rn.\nSono utili in fisica per descrivere il concetto di percorso (traiettoia) e simili\nVelocitÃ  di un cammino\npossiamo definire una dimensione di velocitÃ  di un cammino in questo modo:\nNota: non Ã¨ il gradiente, perchÃ© qui la derivata Ã¨ una sola, solo per funzioni differenti.\nQuella derivata (il vettore) Ã¨ velocitÃ  al tempo t.\n10.4.2 Nozioni di fisica(velocitÃ  e accelerazione) VelocitÃ  scalare:\nQuando la derivata Ã¨ nulla in tutti i punti si dice che quel punto della traiettoria Ã¨ un punto singolare\nAccelerazione:\n10.4.3 Taylor per curve Altro\n10.4.4 Derivata lungo una curva (!!) Introduzione intuitiva della derivata\nCome si nota, la curva non Ã¨ detto che sia derivabile, quindi prima la parametriziammo, e poi calcoliamo la derivata della funzione composta, e nientâ€™altro.\n10.4.5 OrtogonalitÃ  del differenziale (!) Dimostrazione veloce veloce\nCalcolo di queste derivate (idea) Se dobbiamo calcolare qualcosa di complesso, tipo\nf una funzione differenziabile, e voglio la derivata di $f(h_1(s),..., h_n(s))$ posso crearmi una funzione di appoggio, che possiamo anche chiamare la parametrizzazione della funzione come\n$r(s) = (h_1(s),...,h_n(s))$ e calcolarmi la derivata di $f(r(s))$ che abbiamo discusso sopra, alla fine avrÃ² qualcosa del tipo\n$\\delta_{e_1}f(r(s))\\delta_s(h_1(s)) + ... + \\delta_{e_n}f(r(s) \\delta_s(h_n(s))$\n","permalink":"https://flecart.github.io/notes/calcolo-differenziale/","summary":"Ripasso Prox: 24 Ripasso: June 2, 2022 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: March 14, 2022 2:11 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso DImostrare per benino la condizione sufficiente di differenziabilitÃ  perchÃ© probabile che alcuni passaggi non li fai per filo e per segno. 10 Calcolo differenziale 10.1 Derivata parziale La derivata vuole descrivere quanto varia una funzione al variare dell\u0026rsquo;input. Ma ora siamo in piÃ¹ dimensioni, quindi vogliamo descrivere il variare dell\u0026rsquo;input come il variare della distanza euclidea","title":"Calcolo differenziale"},{"content":"Ripasso Prox: 37 Ripasso: June 3, 2023 Ultima modifica: June 18, 2023 11:27 PM Primo Abbozzo: February 27, 2023 3:19 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso HTML Markup Introduzione alle funzioni del markup ðŸŸ© La semantica di una parola Ã¨ caratterizzata dalla mia scelta (design sul significato). Non mi dice molto, quindi proviamo a raccontare qualcosa in piÃ¹.\nDefiniamo markup ogni mezzo per rendere esplicita una particolare interpretazione di un testo.\nIn particolare Ã¨ un modo per esplicitare qualche significato. (un pÃ² come la punteggiatura, che da qualche altra informazione oltre le singole parole, rende piÃ¹ chiaro l\u0026rsquo;uso del testo).\nLe informazioni aggiuntive possono essere riguardanti:\nLa struttura del testo La formattazione del testo Relazioni fra parti del testo. Tipologie di Markup (6) ðŸŸ¨+ Puntuazionale\nQuesto Ã¨ un markup che lâ€™autore stesso dÃ . ed Ã¨ fortemente ambiguo!.\nIl markup puntuazionale consiste nellâ€™usare un insieme prefissato di segni per fornire informazioni perlopiÃ¹ sintattiche sul testo.\nPresentazionale\nEffetti grafici per comunicare fine capitolo o altri simili\nSlide\nProcedurale\nQuesto Ã¨ una tipologia di markup che utilizza delle istruzioni per definire la presentazione. (quindi in questa parte ci sono dei comandi!) (esempi credo siano latex o Tex)\nDescrittivo\nVuole descrivere la struttura e la semantica di frammenti di testo. (non Ã¨ procedurale, perchÃ© non gli dico pezzo per pezzo la grafica), io dico se Ã¨ un testo, se Ã¨ una didascalia, in modo simile a quanto fatto qui su Notion.\nReferenziale\nQuando faccio riferimento a cose esterne per risolvere il significato. Di solito fa usi di SIGLE o abbreviazioni di qualcosa\nMetaMarkup\nSe utilizzo un linguaggio per creare un linguaggi di Markup, un esempio Ã¨ Word, perchÃ© con quello utilizzo il linguaggio di markup (descrittivo, su font e simili), anche HTML.\n(6Il metamarkup consiste nel fornire regole di interpretazione del markup e permette di estendere o controllare il significato del markup.\nMetodi di classificazione di markup Standard privato oppure pubblico Se Ã¨ interno o esterno (nel senso se si riferisce al testo interno oppure al testo esterno) binario o leggibile (per dire se Ã¨ piÃ¹ fruibile per le macchine oppure se Ã¨ fatto per essere fruibile per esseri umani) Poi si fa anche una distinzione fra procedurale (latex o troff like) oppure dichiarativi, nel senso che si taggano parti per indicarne l\u0026rsquo;utilizzo (come pe rlâ€™HTML). Alcuni linguaggi di Markup (non impo) ðŸŸ¥+ GROFF TROFF, NROFF\nQuesti sono scritti i linguaggi di markup per i manuali tecnici di Linux.\nTEX e LATEX\nSoftware di impaginazione autoomatica, principalmente per formule matematiche, perchÃ© ci metteva troppo a fare il suo libro che la casa editrice sbagliava le formule. C\u0026rsquo;Ã¨ anche un metafont utilizzato per astrarre la fomra dei caratteriâ€¦ Ãˆ poi turing completo, molto difficile, moltissime keyword. Ãˆ molto difficile quindi Leslie Lamport crea una libreria molto piÃ¹ facile da utilizzare.\nMarkdown\nUna semplificazione molto semplice, con formattazioni ad hoc, utili per testi semplici, senza molta possibilitÃ  di avere cose tipografiche precise.\nJSON e YAML\nJSON (Javascript Object Notation) Ã¨ un formato dati per facilitare lo scambio di dati in internet.\nYAML Ã¨ molto python like, che utilizza spazi come delimitatori (Ã¨ superset di json, quindi capisce anche quello.). Per il resto Ã¨ uguale a JSON, ma ha i commenti.\nXML\nÃˆ un sottoinsieme di SGML, che ha molte piÃ¹ garanzie formali. (infatti definiamo ora con BNF, ed Ã¨ una complessitÃ  assurda!)\nBen forma (puramente sintattico) ValiditÃ  del documento (a seconda delle regole della grammatica cheho definito) Slide documenti ben formali\nSGML ðŸŸ¨- SGML (Standard Generalized Markup Language) Ã¨ uno standard di IBM rilasciato gratis. SGML Ã¨ un meta-linguaggio non proprietario di markup descrittivo. Facilita markup leggibili, generici, strutturali, gerarchici.\nÃˆ una tipologia di markup chiara, leggibile, strutturata, descrittiva e gerarchica, i primi fisici erano molto felici per questo metalinguaggio di markup.\nStruttura di un documento SGML\nDichiarazione SGML DOCTYPE, o dichiarazione dei nomi utilizzabili all\u0026rsquo;interno del documento Istanza del documento Slide\nEsempio SGML\nÃˆ uno dei Markup piÃ¹ importanti perchÃ© possiamo dire che sia il precursore dell\u0026rsquo;HTML\nCostituenti base di SGML\nElementi\nAttributi\nEntitÃ \nPCDATA\nCommenti\nProcessing instructions\nQuesta parte dovrebbe essere molto importante se si parla della parte teorica, perÃ² nella pratica mi sembra che siano in veritÃ  utilizzate pochissimo, sono comuqnue interessanti sapere che esistano\nXML Questo Ã¨ un sottoformato di SGML, ed Ã¨ utilizzato principalmente per fare una verifica formale che tutti i tags dichiarati siano a validi e cose simili.\nSlide XML, strumenti di checks\nUn esempio Ã¨ il tag che non contiene niente, allora Ã¨ nella forma \u0026lt;.../\u0026gt;senza un altro tag che lo chiuda. E poi ci sono tutti i checks per attributi (che devono esere per forza con le virgolette, differentemente rispetto a HTML lasco che potrebbe permetterne anche senza, anche attributi senza niente potrebbe permettere per esempio, questo perchÃ© provano i browser ad accettare tipologie di documenti molto ampi.\nUn pÃ² di storia Ãˆ importante capire un pÃ² di storia per vedere che strano robo abbiamo oggi.\nDue linee di sviluppo, uno Ã¨ uno standard di W3C, l\u0026rsquo;altro Ã¨ il living standard. Ãˆ di fortissimo cambiamento, quindi di difficile definizione! (cambia significato sia di semantica e che di sintassi).\nNel 1997 abbiamo HTML4 che Ã¨ stata considerata la versione finale, per cui un sacchissimo di siti web fino al 2008 sono stati implementato con questo HTML\nTag Soup ðŸŸ© I browser permettono molti tag, senza voler dare errore con l\u0026rsquo;obiettivo di essere comprensivi. Abbiamo quindi un sacco di tags, molti dei quali non sono conformi a nessuno standard. Non abbiamo una correttezza sintattica o semantica dei tags. Abbiamo in pratica troppe eccezioni.\nIl problema allora diventa, quando vogliamo andare a creare un parser per questo genere di html, come andare a crearne uno che riesca a gestire queste tipologie di tags?\nSlide quirks and strict mode\nIn particolare abbiamo con HTML5 una standarizzazione delle regole di parsing quindi possiamo andare ad utilizzare lo strict mode e avere piÃ¹ garanzie sulle pagine.\nXHTML e HTML Le aziende dei webbrowser avevano giÃ  il codice per parsare il HTML brutto, con molti codici, e non volevano creare un nuovo parse per XHTML, molto piÃ¹ formale e che riusciva a garantire piÃ¹ codice (ossia ci sarebbe un modo unico per scrivere del codice corretto!). L\u0026rsquo;hanno proposto ai tizi del W3C che l\u0026rsquo;hanno rifiutato. CosÃ¬ Ã¨ stato creato il working group WHATWG in cui si lavorÃ² a una versione intermedia di HTML, che estese con alcuni tag. Dentro questo gruppo erano giÃ  presenti i maggiori player per i browser come mozilla, microsoft, e poi ci Ã¨ entrato Google assumendo Ian per la creazione di chrome.\nIn questo moto ha vinto HTML5, che viene chiamato solamente HTML e un living standard che viene aggiornato ogni poche settimane.\nQuesto albero che viene creato dal parsing di quel modello Ã¨ utile per la creazione del DOM trattato piÃ¹ sotto.\nHTML Struttura del documento ðŸŸ© Ci deve essere una intestazione DOCTYPE che ci specifica che tipologia di documento stiamo andando a parsare (se non c\u0026rsquo;Ã¨ credo sarebbe sintatticamente invalido ma ciononostante il browser Ã¨ in grato di inferire come intenderlo!)\nhtml che include tutto\nhead che include informazioni generali sul documento\nbody che contiene il contenuto del sito.\nEsempio di file HTML\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt; Document title \u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt; Major Header \u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is a complete paragraph of a document. I write and write until I fill in several lines, since I want to see how it wraps automatically. Surely not a very exciting document.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Did you expect \u0026lt;b\u0026gt;poetry\u0026lt;/b\u0026gt;?\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Here you can see a paragraph \u0026lt;br\u0026gt; split by a \u0026amp;lt;br\u0026amp;gt;\u0026lt;/p\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt; A list of important things to remember: \u0026lt;/p\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Spaces, tabs and returns\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Document type declaration\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Document structure\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Nesting and closing tags\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Elementi inline ðŸŸ© Molti sono stati deprecati (o non li usa nessuno), perchÃ© dovrebbero essere usati CSS per la parte grafica. Solo i, e B sono ancora presenti, o small, perchÃ© sono caratteri tipografici molto comuni!\nEsempi di elementi inline\nElementi di blocco e di lista ðŸŸ© Sono i blocchi classici per rappresentare struttura di headers, di paragrafi, e blocchi generici, o citazoini, autori.\nBlocchi sequono una sequenza di lettura fra le letture!\nesempio:\n, un elemento anonimo, che deve essere totalmente stilato. , la stessa coda del div, che perÃ² non Ã¨ blocco ma INLINE. , â€¦, etc NOTA: whitespace Ã¨ praticamente sempre ignorato, tranne allâ€™interno del tag pre. (esiste white-space: pre, che permette di utilizzare whitespaces\nSlide\nEsempio\nElementi di lista\nSlide\nEsempio elementi lista\nElementi di struttura ðŸŸ© Non vorremmo avere dei div come elementi di struttura, questo non Ã¨ che sia molto chiaro dal punto di vista semantico!\nQuindi introduciamo\nche descrive un qualcosa di annidabile che prende qualcosa di **self-contained** che puÃ² essere utilizzato a sÃ©, e quindi potrei rimuoverla o inserirla senza problemi! Slide tags struttura\nSlide header e footer\nSlide nav\nEsempio confronto HTML 4 / HTML5\nAnchors and images ðŸŸ© Anchors\nPosso metterci un fragment per gli a, questo non camibano niente nella transazione client e server, ma Ã¨ il browser che capisce la locazione dopo aver scaricato tutto.\nSi noti che l\u0026rsquo;attributo name non cambia la visuale del blocco, a differenza di href (che manda fuori).\nSlide anchors\nImmagini\nHa ancora degli attributi altezza e witdt, che rimangono ancora nonostante siano attributi rappresentazionali. PerÃ² precalcola l\u0026rsquo;occupazione dell\u0026rsquo;immagine e quindi il tutto carica piÃ¹ in fretta.\nSlide immagini\nPotrei includerla con una immagine, e specificare height o width (se li includo entrambi avrÃ² resize dellâ€™immagine senza rispettare le proporzioni, se non metto niente avrei lâ€™immagine di grandezza naturale (px original) altrimenti se ne metto sono una avrÃ² una resize che mantenga le dimensioni iniziali).\nsrcset, vogliamo avere tantissime immagini, che si scalino in modo automatico aseconda del device, definisco srcset e delle sizes.\nSlide srcset\n**figure **Ã¨ un tag con un caption in pratica, niente di cheâ€¦\nForm ðŸŸ¨- esistono da sempre, quindi giÃ  dall\u0026rsquo;inizio sembrava che fossero utili per fare applicazioni con un rapporto in clientside.\nCreare una schermata per specificare i dati da passare a una applicazione server-side, per creare punti di raccolta di informazioni, e fare un submit all\u0026rsquo;applicazione server side, chiamata ACTION, .\nSlide struttura di un form\nSolitamente i metodi sono GET o POST, ma vedremo dopo con HTTP questa differenza.\nI widget sono le cose visibili nel form, come **textarea, radio,, input select, *button.\nInteractive forms\nNew input forms\nTags generali ðŸŸ©- Embedding\nobject Ã¨ un tag per oggetti che non sono capibili dal browser naturalmente, infatti bisogna specificare un engine con cui runnarlo.\nQuesto Ã¨ un embedding molto, troppo generale, quindi vogliamo creare i tags per embedding specifici, che rende il tutto piÃ¹ chiaro.\nSlide per tags di embedding\nTabelle\nCose come th per dire table header, or tr per dire table row., td per dire table data., e table per inizializzare le table\nSolitamente Ã¨ composta da tre parti. head, foot, e body, solitamente per questioni di efficienza foot deve essere messo subito dopo le head, perchÃ© ha i numeri piÃ¹ grandi, quindi non devo andare a ricalcolare la grandezza della tabella.\nUna altra cosa interessante per le tabelle Ã¨ che ci sono stiling come attributi (esempio di questo sono colspan, rowspan etc), ma dovrebbe essere di CSS, infatti questo era un modo per farlo prima di CSS.3.\nTipicamente utilizare le tabelle per fare layout Ã¨ una delle cose meno accessibili che esistono! Quindi non ha piÃ¹ nessun senso utilizzare le tabelle di layout. (non utilizzarle, penalizza!).\nDOM Questa parte Ã¨ fatta meglio in Javascript\nDocument object model, lâ€™obiettivo della WHATWG era costruire un parser che potesse aiutare a creare una struttura di dati utile per la creazione di applicazioni, quindi molto piÃ¹ tollerante rispetto a quanto proposto dal W3C e specifiche piÃ¹ rigide come XHTML.\nDocument Object Model, una struttura di dati con alcune funzioni e strutture built in che permettono la facile manipolazione fornisce API. Dovrebbe essere facile creare un DOM da codice HTML cosÃ¬ come il constrario. Ãˆ esattamente quello che si vede sullo schermo!\nâ€œlâ€™importante Ã¨ arrivare ad una struttura dati in memoria unica su cui costruire applicazioni\nDato che deve funzionare per HTML secondo la filosofia piÃ¹ estesa del WHATWG, Ã¨ praticamente la struttura del XHTML ampliata per includere altro, questo permette al codice JS di intervenire direttamente sul DOM.\nStruttura del DOM ðŸŸ© Slide struttura del dom\nCi sono alcune classi fondamentali per poter comprendere il DOM\nDocumento Nodo del DOM Nodo di testo Nodo di elemento Nodo di attributo Poi ci sono molte altre classi, come commendi, Datasection e molti altri che di solito si vedono poco, quelli piÃ¹ importanti sono il Document e i nodi descritti sopra Alcune classi del dom ðŸŸ©â€” Slide DOMNode\nSlide DOMDocument e Selettori\nSolitamente Ã¨ complicato lavorare col DOM vanilla, tanto che l\u0026rsquo;hanno chiamato sadico chi ne Ã¨ stato detrattore.\nSlide DOMElement\nInner e OuterHTML ðŸŸ© Andare a modificare lâ€™HTML Ã¨ molto verboso, utilizzando questi metodi Ã¨ piÃ¹ veloce andare a creare nuovi elementi.\nLâ€™unica differenza fra i due Ã¨ che Outer include anche il contenitore nella modifica, inner Ã¨ solo per il contenuto\nSlide Inner e OuterHTML\nAltre note Whitespaces in HTML ðŸŸ© Whitespace Ã¨ ignorato (soprattutto in elementi strutturali come i table) Whitespace Ã¨ collassato in un unico whitespace in il whitespace Ã¨ mantenuto. Cose saltate Queste cose per completezza le cito, e sono presenti sulle slides, ma le salto per pigrizia\nTipi di dati Attributi globali Attributi data e aria EntitÃ  predefinite PeculiaritÃ  sintattiche Il contenuto dell\u0026rsquo;elemento HEAD ","permalink":"https://flecart.github.io/notes/html-e-markup/","summary":"Ripasso Prox: 37 Ripasso: June 3, 2023 Ultima modifica: June 18, 2023 11:27 PM Primo Abbozzo: February 27, 2023 3:19 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso HTML Markup Introduzione alle funzioni del markup ðŸŸ© La semantica di una parola Ã¨ caratterizzata dalla mia scelta (design sul significato). Non mi dice molto, quindi proviamo a raccontare qualcosa in piÃ¹.\nDefiniamo markup ogni mezzo per rendere esplicita una particolare interpretazione di un testo.","title":"HTML e Markup"},{"content":"Ripasso Prox: 40 Ultima modifica: March 30, 2023 3:39 PM Primo Abbozzo: September 21, 2021 7:10 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi da ripassare Vecchi dubbi Principio di localitÃ  e temporalitÃ  Le tipologie di raid November 29, 2021 9:22 PM 4 Memoria 4.1 Caratteristiche della Memoria La gerarchia della memoria, piÃ¹ si va giÃ¹ piÃ¹ spazio si ha, piÃ¹ Ã¨ lento il caricamento delle informazioni\n4.1.1 Catalogazione della memoria Le tipologie di memoria sono presenti a fianco.\nIn generale piÃ¹ la memoria Ã¨ veloce da riprendere, piÃ¹ Ã¨ costosa da memorizzare (c\u0026rsquo;Ã¨ poco spazio)\n4.1.2 Byte e Word Il libro a pagina 74 parte con la discussione del perchÃ© si Ã¨ preferito evitare la BCD (Binary coded decimal, in cui i numeri da 0 a 9 erano codificato da 4 bit), per questioni di efficienza.\nLa memoria Ã¨, in modo spiccio, una serie di cellette numerate, ognuno puÃ² contenere qualche informazione.\nNacque nel 1960 circa con IBM 360 nacque la definizione di byte.\nWord Ã¨ una seguenza di byte â†’ unitÃ  di dato che non stanno solamente in un singolo indirizzo.\n4.1.3 Endianess Questi termini descrivono l\u0026rsquo;organizzazione dei bytes all\u0026rsquo;interno della memoria. A volte Ã¨ molto conveniente netere i bytes al contrario per facilitÃ  di accesso.\n4.1.4 RAM Abbiamo presentato il funzionamento hardware della RAM nel momento in cui abbiamo descritto il funzionamento di Circuiti Sequenziali come LATCH SR, D, DFF.\n4.1.5 Paginazione - Caricamento Una altra funzione della gerarchia di memoria Ã¨ utilizzare la paginazione, ossia il caricamento di risorse utili nella ram veloce e scaricamento nella memoria secondaria di ciÃ² che non viene utilizzato.\nÃˆ gestito dal sistema operativo.\nSono dei blocchi di data nella memoria principale che vengono caricati nella memoria principale nel momento del bisogno.\nQuindi ci sono proprio degli algoritmi per caricare e scaricare le pagine di memoria dalla memoria principale, gestiti dal sistema operativo.\n4.2 Memoria Cache La cache Ã¨ una zona di memoria condivisa alle CPU, di facile accesso (meno facile in confronto ai registri, ma comunque veloce) ma senza molto spazio.\nÃˆ sempre consultata ** prima di andare nella memoria.\nSe va a cercare un word in memoria, questa viene messa nella cache dopo essere ritrovata.\nUna caratteristica principale della cache Ã¨ che non Ã¨ necessario al programmatore sapere che esiste o meno, Ã¨ solo qualcosa che si interpone in modo TRASPARENTE che puÃ² rispondere subito nel caso possieda una certa informazione.\nMa lâ€™idea di tenere una memoria piÃ¹ veloce intermedia per dati piÃ¹ utili del prossimo futuro Ã¨ una idea che si utilizza anche in altri ambiti (come Disco, accesso messaggi, e simili) e migliora molto la velocitÃ .\n4.2.1 Livelli memoria Cache 4.2.2 Principio di localitÃ  spaziale e temporale Programmi eseguiti vicini nel tempo sono messi in luoghi in memoria vicini\nSi spera di guadagnare tempo in questo modo, cosÃ¬ Ã¨ piÃ¹ facile ritrovare delle informazioni utili quando si eseguono dei comandi vicini nella cache.\nChiaramente se un programma continua a saltare da un indirizzo della memoria a un altro questo principio non ha piÃ¹ senso e la cache servirebbe a poco.\nLocalitÃ  spaziale e temporale\nUn programma naturale di solito utilizza la cache (un programma potrebbe essere progettato in modo che usi 0 cache, ma sarebbe uno spreco di risorse).\nTemporale: la stessa cella viene acceduta a breve distanza di tempo (come Stack)\nSpaziale: celle vicine possono essere prese a breve tempo di distanza. (per esempio accedere ad un array, accesso sequenziale che ha un nome suo di localitÃ  sequenziale)\nÃˆ molto facile che la cache debba accedere alla stessa risorsa in termini brevi di tempo\nLocalitÃ  secondo WIKI\n4.2.3 Efficienza della cache La velocitÃ  d\u0026rsquo;accesso alla cache Ã¨ di granlunga minore rispetto a quello della memoria, di solito il tempo speso per memorizzare qualcosa qui viene sempre recuperato.\nUsiamo un pÃ² di matematica ora per descrivere questa cosa un pochino piÃ¹ rigorosamente:\n$c \u003c\u003c m$ con $c$ il tempo per accedere alla cache e $m$ il tempo per accedere alla memoria.\nAllora si ha che il tempo medio per accedere alle informazioni, tenendo $h$ come hit rate Ã¨ di:\n$$ hc + (1 - h)(c + m) = c + (1-h)m $$ 4.2.4 Cache ad accesso diretto Linee di cache, vanno k mod n, ogni linea di cache di dimensione m. ok? Ãˆ una cosa temporale, a seconda di cosa ci sia ora.\nData: Ã¨ effettivamente il data che sto prendendo\nn Ã¨ il numero di linee di cache (che decide quanto grande sia la cache).\nTag serve per sapere quale blocco sto utilizzando (quindi se 0-31 oppure 65536 e simili)\nValid se Ã¨ un blocco valido, se Ã¨ 0 vuol dire che non Ã¨ roba interessante.\nEsempio di query cache\nTeniamo 5 bit per l\u0026rsquo;indicizzazione dentro i 32 bit di data.\n11 bit per sapere quale linea di cache utilizzare\n16 bit per confrontare con il tag e vedere se Ã¨ giusto oppure no.\nCosÃ¬ riesco a trovare in modo univoco la linea di cache che mi serve.\n4.2.5 Cache hit and miss Si dice che si ha un cache hit oppure cache miss a seconda del caso in cui la cache Ã¨ riuscita a dare la richiesta oppure meno.\nMiss\nRiportare la cache in memoria centrale in quanto potrebbe essere modificata ora, Ã¨ un aggiornamento della roba nella memoria centrale Caricare la nuova memoria. Se perÃ² si tenta di accedere alla cache allo stesso momento, si possono esserci data race e quindi bisognerebbe bloccare l\u0026rsquo;accesso all\u0026rsquo;inizio\nSe vuoi approfondire su algoritmi per la gestione della cache:\nhttps://en.wikipedia.org/wiki/Cache-oblivious_algorithm\ne altro ancora\n4.3 Memoria secondaria Storicamente le velocitÃ  delle CPU si sono sviluppate molto piÃ¹ velocemente rispetto alle memorie secondarie.\n4.3.1 Hard Disk (4) I dischi magnetici oppure Hard disk sono generalmente in tre parti:\nSettore Ã¨ il nome di una traccia specifica di memoria di dimensione fissata. Traccia Ã¨ una sequenza di bit circolari Testina che magnetizza e modifica il contenuto nel disco. Controllore Disco . Ogni settore comincia con un preamble che dovrebbe aiutare a diminuire gli errori di lettura.\nPer dare un senso, circa in un centimetro di Hard Disk ci possono stare parecchi giga di informazioni.\nI dati posso essere messi in due modi:\nStessa densitÃ  per angolo (piÃ¹ rientri piÃ¹ hai i dati in modo compatto) Diverso numero di settori (la parte esterna del disco contiene piÃ¹ settori) Processo di recupero di dati:\nLa CPU dice di andare a recuperare un blocco in un certo indirizzo di memoria La testina gira e va fisicamente a recuperare la zona di memoria 4.3.2 SSD SSD or Solid State drive non hanno nessuna parte che si muove quindi sono meno soliti a rompersi meccanicamente, tutto elettronico.\nStoricamente sono state utilizzate per portatili per resistenza ad urti, ma poi si possono utilizzare anche per altro data la loro velocitÃ  (per minore spazio).\n4.4 RAID https://en.wikipedia.org/wiki/Standard_RAID_levels\nRedundant array of indipendend disks (originariamente inexpensive, per contrapporla a Single Large Expensive Disk ossia SLED, ma poi hanno scoperto che anche RAID costa, LMAO.\n4.4.1 Vantaggi generali Redundant Array of Inexpensive Disks.\nRidurre il gap di efficienza fra CPU e HD Utilizzo di piÃ¹ dischi in contemporanea + lettura di dati FacilitÃ  di correttezza di dati e verifica errori 4.4.2 6 Tipologie di RAID Diminuire di 1 l\u0026rsquo;intera lista, perchÃ© RAID va da 0\nNon redundant data striping (C\u0026rsquo;Ã¨ solo una copia di dati nel disco) VelocitÃ , no info retrieval\nRedundant, c\u0026rsquo;Ã¨ una copia esatta dei RAID e sono entrambi striped\nC\u0026rsquo;Ã¨ bisogno di una grande sincronizzazione in quanto i dati sono divisi fra i dischi a livello bit.\nPossono avere solamente una richiesta, a differenza di RAID 1 che puÃ² gestirne tanti Unico raid mai utilizzato, perÃ² introduce Hamming per la corrrezione!\nUguale al terzo ma c\u0026rsquo;Ã¨ un bit di paritÃ  per controllo errori invece che codice hamming, spesso bit di paritÃ  Ã¨ bastato.\nSolo una richiesta https//en.wikipedia.org/wiki/Parity_bitÂ disk with each color representing the group of blocks in the respectiveÂ parityÂ block (a stripe)](Memoria%20f3746a630031414b935cca93dd06f1ad/Untitled%2010.png)\nA RAIDÂ 4 setup with dedicatedÂ parityÂ disk with each color representing the group of blocks in the respectiveÂ parityÂ block (a stripe)\nRitornano gli stripe, ma stavolta un intero disco Ã¨ utilizzato per verificare che la scrittura Ã¨ stata corretta,\nÃ¨ brutto se vogliamo scriverci Anche questo utilizzato poco Diagram of a RAIDÂ 3 setup of six-byte blocks and twoÂ parityÂ bytes, shown are two blocks of data in different colors.\nRisolve una lentezza del punto 5 distribuendo le sezioni di controllo sui vari dischi.\nhttps//en.wikipedia.org/wiki/Parity_bitÂ block (a stripe). This diagram showsÂ Left AsynchronousÂ layout](Memoria%20f3746a630031414b935cca93dd06f1ad/Untitled%2012.png)\nRAIDÂ 5 layout with each color representing the group of data blocks and associatedÂ parityÂ block (a stripe). This diagram showsÂ Left AsynchronousÂ layout\nNon so quale sia la differenza con il 5, per saperlo vai a leggere i raid su Devices OS. In pratica fault tolerance maggiore.\n4.5 Errori Controllare come sono causati gli errori E tipologie di errori\nQuesta parte Ã¨ scritta molto meglio in Rappresentazione delle informazioni\ndove si parla di hamming distance e correzione errori.\n4.5.1 Cause degli errori Gli errori possono essere causati da:\nRaggi cosmici provenienti dal sole Vibrazioni fisiche 4.5.2 Hamming Distance 4.6 Altri dispositivi 4.6.1 Dischi ottici Un laser va a leggere i pattern di Pit-land e Land-pit, pit-pit presenti sul compact disk.\nI dischi sono sostanzialmente uguali per quanto riguarda l\u0026rsquo;encoding di 1 e 0 ma sono diversi per quanto riguarda il materiale impiegato, il raggio impiegato **lo spazio presente fra le varie linee di informazioni (la compattezza dei bit) e simili.\n4.6.2 Output-Input Per gestire tutti i pixel c\u0026rsquo;Ã¨ la necessitÃ  di avere architetture molto complicate, circa devono fare update di milioni di pixel in decimi di secondo (altrimenti l\u0026rsquo;occhio capisce che c\u0026rsquo;Ã¨ la distanza)\nCore complessi per la gestione di di milioni di Pixel. Linguaggi di programmazione specifici perchÃ© piÃ¹ efficienti della CPU per programmi non grafici e.g. Cuda-C. 4.6.3 Bus per dispositivi sono legati tramite BUS, collegamenti elettrici.\nBUS di dati BUS di indirizzi I bus trasportano piccole quantitÃ  di informazioni. Si possono dividere in sotto-bus.\nI bus si sono evoluti nel tempo, partendo da standard ISA (industry standard architetture) sono state creati moderni bus molto piÃ¹ veloci PCI, PCIe e simili.\nCollegamento con memoria e CPU\nController collega gli attacchi ai dispositivi ai Bus che si collegano all\u0026rsquo;unitÃ  di controllo. (la scrittura sul bus Ã¨ controllata dalla CPU) Altri dispositivi parlano direttamente alla memoria DMA mandano e ricevono degli interrupt. (se non usasse interrupt altra soluzione sarebbe continuamente inviare delle richieste per chiedere se sta ancora andando o meno) Direct Memory Access\nDi questo ne parliamo un pÃ² meglio, anche se alla fine Ã¨ lo stesso concetto in Note sullâ€™architettura\nPer saperne di piÃ¹ su interrupt e trap\nSarebbe molto inefficiente leggere e inviare continuamente, quindi mettiamo un trasferimento RAM â†’ Disco senza passare dalla CPU. Quando finisce il trasferimento il dispositivo invia un Interrupt che viene gestito subito dalla CPU interrompendo il processo corrente, iniziando un interrupt handler che gestisca eventuali errori del dispositivo e informa il sistema operativo che Ã¨ finito il processo di I/O. l processo corrente, iniziando un interrupt handler che gestisca eventuali errori del dispositivo e informa il sistema operativo che Ã¨ finito il processo di I/O.\n","permalink":"https://flecart.github.io/notes/memoria/","summary":"Ripasso Prox: 40 Ultima modifica: March 30, 2023 3:39 PM Primo Abbozzo: September 21, 2021 7:10 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi da ripassare Vecchi dubbi Principio di localitÃ  e temporalitÃ  Le tipologie di raid November 29, 2021 9:22 PM 4 Memoria 4.1 Caratteristiche della Memoria La gerarchia della memoria, piÃ¹ si va giÃ¹ piÃ¹ spazio si ha, piÃ¹ Ã¨ lento il caricamento delle informazioni\n4.1.1 Catalogazione della memoria Le tipologie di memoria sono presenti a fianco.","title":"Memoria"},{"content":"Ripasso Prox: 70 Ripasso: July 22, 2023 Ultima modifica: May 19, 2023 9:25 AM Primo Abbozzo: November 23, 2022 1:32 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Message passing ora abbiamo alcune primitive per passarci i messaggi, vogliamo creare metodo in modo che i processi si possano sincronizzare mandando messaggi.\nla memoria Ã¨ sempre privata.\nPrimitive Send e receive ðŸŸ© Send\nSpedizione del messaggio input deve avere un identificato al processo su cui spedire. Se si vuole espandere si possono avere multicast e broadcasting ma non li studieremo in questo corso.\nReceive\nRicevi messaggi\nTassonomia dei message passing (!)ðŸŸ© Slide\nSincrono\nIn questo caso entrambi send e receive sono bloccanti, quindi non possono andare avanti finchÃ© non Ã¨ mandato e finchÃ© non Ã¨ ricevuto!\nAsincrono\nSimile al precedente, solo che il send non aspetta che il ricevente prenda il messaggio!\nNOTA: non si aspetta che il receiver riceva il messaggio!\nCompletamente asincrono\nnessuno di due aspetta, il receive se nessuno ha inviato non riceve niente!\nThoth proponeva 3, reply receive send, principalmente solo la reply Ã¨ bloccante.\npiÃ¹ o meno tutti gli autori avevano una sintassi diversa per il message passing\nEquivalenza fra sincrono asincrono Si puÃ² vedere che questi due metodi si possono rivelare equivalenti\nSincrono dato quello asincrono ðŸŸ© Slide\nPer bloccare il asendodevo fare un areceive per un ack, cosÃ¬ lo blocco\nNOTA: ed Ã¨ esattamente questo, un ack aggiuntivo che hai fatto allâ€™esame che ti ha fatto perdere tipo 2 punti, stai attento!\nAsincrono dato quello sincrono ðŸŸ©- Slide\nSi vede che il sincrono non Ã¨ espressivo tanto lâ€™asincrono perchÃ© abbiamo bisogno di far uso di un altro processo server.\nProblemi classici ðŸŸ¨ Filosofi a cena Slide\nBasta ricordarsi di fare anche il filosofo mancino e poi siamo apposto! Sarebbe poi la stessa soluzione proposta in Semafori\nProducer consumer Slide\n","permalink":"https://flecart.github.io/notes/message-passing/","summary":"Ripasso Prox: 70 Ripasso: July 22, 2023 Ultima modifica: May 19, 2023 9:25 AM Primo Abbozzo: November 23, 2022 1:32 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Message passing ora abbiamo alcune primitive per passarci i messaggi, vogliamo creare metodo in modo che i processi si possano sincronizzare mandando messaggi.\nla memoria Ã¨ sempre privata.\nPrimitive Send e receive ðŸŸ© Send\nSpedizione del messaggio input deve avere un identificato al processo su cui spedire.","title":"Message Passing"},{"content":"Ripasso Prox: 24 Ripasso: December 29, 2022 Ultima modifica: December 27, 2022 4:53 PM Primo Abbozzo: September 30, 2022 9:34 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Stranamente ho ancora alcuni problemi a ricordarmi i modelli teorici per la modellizzazione di problemi, ma durante la modellizzazione di un problema concreto mi pare facile, semmai qualche esercizio a tempo settimanale puÃ² aiutare per questo. Bisogna fareesercizi pesanti su sta roba, non la sai per niente bene dal lato pratico, che Ã¨ quello che importa per lâ€™esameâ€¦\nProgrammazione lineare Programmazione lineare contiene alcuni algoritmi utili per risolvere certi problemi di ottimizzazione.\nIntroduzione Andiamo in questa sezione a definire un problema di programmazione lineare\nDefinizione ðŸŸ©- Variabili reali che saranno le variabili del nostro problema, sono in numero finito (eg. tutti in Rn) Funzione obiettivo che ci definisce il costo $f: \\R^n \\to \\R$ Vincoli lineari che limitano il dominio delle variabili reali e li mettono in relazione fra di loro Se le variabili appartengono agli interi andiamo a parlare di programmazione lineare intera.\nSlide\nRappresentazione della soluzione si puÃ² formalizzare sempre in questo modo:\n$$ max\\{cx | Ax â‰¤ b\\} : A \\in M_{m\\times n}, c,b \\in M_{n \\times 1} $$ Programmazione lineare intera In modo curioso la programmazione lineare Ã¨ piÃ¹ facile rispetto alla PLI.\nEsempio di modelizzazione\nHa fatto un esempio di modelizzazione di un problema introduttivo in classe, in effetti si deve fare attenzione a moltissime coseâ€¦ (soprattutto costraints impliciti).\nQuantitative rappresentano alcune quantitÃ \nLogiche rappresentano valori binari (di solito utilizzati per modellare lâ€™assegnamento ad un task)\nRelazioni logiche ðŸŸ¨+ Possiamo codificare con relazioni fra variabili logiche il concetto di negazione, implicazione congiuzione e disgiunzione.\nLe variabili $x \\in \\{0, 1\\}$ in questo caso. La cosa interessante Ã¨ che possiamo codificare relazioni logiche con relazioni lineari!\nSlide rappresentazione di relazioni logiche con relazioni lineari\nVincoli di (semi-)assegnamento ðŸŸ© Abbiamo un insieme di $N = \\{1,..., n\\}$ oggetti da assegnare in $V = \\{1,...,m\\}$ luoghi.\nQuesto si puÃ² codificare con una matrice $n \\times m$ e usare una variabile logica per specificare se Ã¨ stato assegnato a quel luogo o meno.\n(Secondo me si potrebbe anche utilizzare un numero per questo, ma magari lâ€™algoritmo utilizzato Ã¨ leggermente diverso, no forse specifica una possibilitÃ  di assegnamento, per questo una matrice Ã¨ una cosa giusta).\nVincoli di semiassegnamento\nOssia ogni oggetto Ã¨ assegnato a un singolo luogo\nSlide semiassegnamento\nVincoli di assegnamento\nOgni oggetto ha un singolo luogo e ogni luogo un oggetto\nSlide assegnamento\nSelezione sottoinsiemi ðŸŸ¨+ Vogliamo selezionare il minimo fra certi sottoinsiemi (non per forza partizioni!)\nFormulazione classica: sia $F = \\{F_1,..., F_m\\}, F_i \\in \\N$, voglia determinare $D \\subseteq F$ tale che abbia il costo minimo fra tutti. Nella selezione di questi sottoinsiemi possiamo considerare insiemi di copertura, di riempimento o di partizione.\nEsempio del costo classico $\\min\\sum x_j c_j$ cioÃ¨ aggiungo il costo con la variabile booleana che decide se lo scelgo o meno, e poi chiamo $a_{ij}$ una matrice che dice se l\u0026rsquo;elemento i Ã¨ in $F_j$\nFormalizzazione classica\nCopertura, riempimento partizione\nVariabili a Valori Discreti ðŸŸ©- Questa parte tratta di valori vincolati a valori reali. (un esempio solito Ã¨ una macchina che Ã¨ stata costruita a lavorare entro voltaggi precisi).\nSi indica per un insieme di valori che una variabile puÃ² assumere. Una rappresentazione classica Ã¨ in silde sotto\nSlide\nMinima QuantitÃ  Positiva Prefissata ðŸŸ¨+ Di solito queste tipologie di variabili rappresentano valori di produzione di una macchina perchÃ© o Ã¨ spenta, rappresentata da uno 0, oppure Ã¨ accesa e presente in un intervallo\nSlide\nFunzione a carico fisso ðŸŸ© Indica costi 0 quando la macchina non Ã¨ in produzione, mentre perÃ² Ã¨ attiva, anche se fa poco, c\u0026rsquo;Ã¨ un carico fisso ossia un costo che c\u0026rsquo;Ã¨ sempre, e poi cresce in modo lineare\nSlide introduttive\nFormalizzazione classica\nRappresentazione del valore assoluto ðŸŸ¨ SI tratta di come rappresentare mediante vincoli la relazione di valore assoluto.\nUn problema con questo metodo Ã¨ che non sempre si riescono a gestire\nAnche gestendolo in questo modo ci sono alcune ambiguitÃ \nSlide, formalizzazione classica e funzione costo\nFunzioni lineari a tratti ðŸŸ¨+ L\u0026rsquo;idea Ã¨ utilizzare una variabile logica che ci dice in quale tratto Ã¨ presente, poi utilizzare la funzione per calcolare il valore corretto.\nIn pratica questa Ã¨ una forma di generalizzazione dei problemi con funzioni a carico fisso, in cui vengono introdotte delle variabili per dire dove sei, e poi utilizzare la funzione di costo del carico fisso.\nQuesto metodo Ã¨ buono perchÃ© posso utilizzarlo per quanti tratti mi pare\nFormalizzazione\nModellizzazione per Problemi noti Problema della fonderia Soluzione fonderia\nProblema pianificazione della produzione Soluzione pianificazione produzione\nProblema dello zaino (!) Soluzione del modello\nAlbero di copertura di costo minimo Soluzione\nProblema del commesso viaggiatore Note sulla path hamiltoniana\nSoluzione modellizzazione\nProblema dellâ€™agenzia matrimoniale (!) Soluzione modellizzazione\nProblema allocazione dei lavori alle macchine (!) Descrizione del problema\nDal libro\nAbbiamo dei lavori che devono essere svolti in questi intervalli : $t_i, t_i + d_i$, che sono certi valori che svolgono qualcosa, vogliamo cercare di massimizzare il numero di cose svolte, avendo un certo numero di macchine. Una macchina puÃ² avere solo un lavoro (o dipendente).\nQuesto Ã¨ un problema di semiassegnamento.\nModellizzazione\nponiamo $x_{ij} = 1$ se il lavoro $i$ Ã¨ svolto dalla macchina $j$, altrimenti 0\nvincoli necessari semi-assegnamento $\\forall i, \\sum_{j = 1} ^mx_{ij} = 1$, ora dobbiamo andare a modellizzare il concetto dellâ€™intervallo.\nQuindi mi definisco un insieme $S(i)$ che contiene tutti i lavori incompatibili a $i$.\nAllora il vincolo diventa $x_{ij} + x_{hj} \\leq 1$ con $h \\in S(i)$, CioÃ¨ vogliamo che una macchina esegua solamente un lavoro, o nessun lavoro. E questo vincolo ci dÃ  il concetto di vincolo.\nOra passo alla discussione della funzione obiettivo, quindi introduco una nuova variabile che mi conta le macchine utilizzate\n$f(obiettivo) = \\sum y_j$, per tutte le macchine, e poi questa $y_j$ Ã¨ maggiore di tutti gli $x_{ij}$ per una macchina j fissata.. CosÃ¬ provo ad utilizzare meno macchine possibili\nSoluzione dal libro\nhttps://www.notion.so\nProblema docente di informatica (!) Questo problema Ã¨ rappresentato nel libro come di minimizzazione del tempo per lavori di macchina a pagina 37 del pdf delle dispense\nDescrizione del problema\nHo $t_1...t_n$ progetti da compilare su $m$ pc, voglio che ci mettano meno tempo possibile.\nModellizzazione\nSia la variabile $x_{ij}$ la variabile logica se il progetto $t_i$ Ã¨ data alla macchina $j$\nSemi-assegnamento al massimo assegno il progetto a una singola macchina\n$\\sum_{j = 1} x_{ij} = 1$. Ora entra la parte difficile, introdurre delle variabili che siano utili per avere questo concetto di tempo.\nSia $y_j = \\sum_i t_i x_{ij}$, questo rappresenta il tempo di utilizzo del singolo PC. Quello che noi dobbiamo minimizzare Ã¨\nMa questo vincolo non Ã¨ lineare, quindi Ã¨ un problema $\\min (\\max Y), Y = \\{y_j : j = 1,...,m\\}$\nQuindi introduco un valore che $z : \\forall j \\sum_i x_{ij} t_i \\leq z$ e provo a minimizzare solamente z, quindi sarÃ  il suo valore piÃ¹ basso. (minimo upper bound)\nProblema assegnamento delle frequenze Soluzione problema assegnamento\nProblema della commesse ðŸŸ¥- Ho n dipendenti, devo evadere m pacchi, un sottoinsieme $D_j$ che indica da chi puÃ² essere eseguito questo pacco j, puÃ² essere da luogo a un ricavo di $r_j$. Un dipendente puÃ² lavorare su un solo pacco per un intervallo di tempo. PuÃ² essere che non tutti i pacchi siano da evadere.\nInizio modello\n$F_j = boh$\n$x_j = 1$ se la commessa j Ã¨ selezionata, altrimenti 0\n$a_{ij}$ boh\n$x_i \\in \\Z, 0 \\leq x_i\\leq1$\n$\\forall i \\sum a_{ij} x_j \\leq 1$\nFunzione obiettivo $\\max \\sum _{j = 1} ^m x_j r_j$\n","permalink":"https://flecart.github.io/notes/modelizzazione/","summary":"Ripasso Prox: 24 Ripasso: December 29, 2022 Ultima modifica: December 27, 2022 4:53 PM Primo Abbozzo: September 30, 2022 9:34 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Stranamente ho ancora alcuni problemi a ricordarmi i modelli teorici per la modellizzazione di problemi, ma durante la modellizzazione di un problema concreto mi pare facile, semmai qualche esercizio a tempo settimanale puÃ² aiutare per questo. Bisogna fareesercizi pesanti su sta roba, non la sai per niente bene dal lato pratico, che Ã¨ quello che importa per lâ€™esameâ€¦","title":"Modelizzazione"},{"content":"This is the classical format that we encounter, it is the format used for relational databases introduced in databases course introduction, introduced in (Codd 1970).\nIntroduzione, i modelli di dati Lista modelli di dati (4) Nel tempo sono stati sviluppati molti modelli di dati:\nRelational Data Model: This is the most common data model and uses tables to represent data. It organizes data into rows and columns, where each row represents a record, and each column represents an attribute of that record. Relationships between data are established through keys.\nEntity-Relationship Model: This model focuses on the relationships between entities, which are objects or concepts, and how they relate to each other. It is often used in the design of databases.\nNoSQL Data Model: NoSQL databases use various data models, such as document, key-value, column-family, or graph, to store and manage data. These models offer more flexibility than the traditional relational model.\nHierarchical and Network Data Models: These older models organize data in a tree or graph structure, which was common in early database systems.\nIn questa sezione andiamo ad analizzare il primo. (anche perchÃ© quello storicamente piÃ¹ rilevante, e ancora (tristemente) piÃ¹ utilizzato).\nAltri modelli come reticolare e gerarchico erano famosi all\u0026rsquo;inizio, ma si Ã¨ scelto di andare sul modello relazionale col tempo\nVantaggi relazionale (Codd 1970) Ã¨ stato un contributo fondamentale, la separazione fra layer logico e fisico Ã¨ stato proprio necessario per fare questi modelli Rappresenta solamente ciÃ² che Ã¨ importante SemplicitÃ  del passaggio per valori. Il modello relazionale We can represent each row of a table as a partial function, in the domain of the headers,\nDomini e attributi Schemi e istanze di relazione e di basi di dati ðŸŸ© Potremmo definire in maniera lasca, che una base di dati a modello relazione Ã¨ un insieme di relazioni, che possono avere schemi diversi. Ad alto livello possiamo dire che uno schema Ã¨ la descrizione matematica dei domini, mentre l\u0026rsquo;istanza Ã¨ una serie di dati che rispettano quello schema. In matematichese possiamo vedere in immagine:\nIntroduzione concetti fondamentali ðŸŸ© In pratica abbiamo $D_{1}, \\dots D_{n}$ domini a cui spesso sono associati dei nomi, chiamati attributi che spiegano l\u0026rsquo;interpretazione di questo dominio, che vengono rappresentati come gli headers o nomi delle colonne. Un campione di questo dataset non Ã¨ altro che un cittadino nell\u0026rsquo;insieme $D_{1} \\times \\dots \\times D_{n}$, in cui non importa nÃ© l\u0026rsquo;ordine dei singoli elementi all\u0026rsquo;interno della tupla, ma non importa per gli elementi fra una tupla e una altra.\nNel caso in cui la posizione degli attributi non Ã¨ importante (quindi posso mischiare una colonna a una altra) si dice che il database Ã¨ non-posizionale Le due colonne scambiate non ci fanno differenza dal punto di vista logico.\nSchemi matematici o relazionali ðŸŸ© In matematica la tupla ha un uso posizionale, nel senso che la posizione al suo interno Ã¨ importante, mentre noi abbiamo dati omogenei per questo motivo definiamo che le tuple sono identificate da attributi diversi fra di loro. Gli attributi sono delle funzioni che mappano a un dominio (es. stringhe, numeri o simili). $$ dom: X \\to D,,,, A \\in X $$ E si puÃ² introdurre una notazione simile per le tuple $t$ su una certa relazione, che permette di prendere il valore di quella tupla, scegliendo una relazione specifica.\nCondizioni necessarie per relazione (3) ðŸŸ© Devono esserci tutti i dati (colonne) per ogni riga.\nQuindi non vengono ammesse NaN Tutte le righe sono elementi diversi (questa non la ho capita bene, perchÃ© necessariamente devono essere tutti diversi?)\nLe tipologie di valori per colonna sono omogenee Domain integrity, Relational Integrity\nChiavi e vincoli Keys and superkeys ðŸŸ© Superkeys Sono il subset degli attributi utili a identificare in modo univoco un sample.\nCandidate Keys Sono il subset minimo di chiavi utilizzati per identificare un record\nPrimary keys sono solo dei candidate keys identificati da un designer.\nPossiamo proprio dare una definizione formale del concetto di chiave, come l\u0026rsquo;insieme di cardinalitÃ  minima degli attributi superchiave.\nCosa succede invece nel momento in cui includiamo la possibilitÃ  che certi valori possano essere nulli nel nostro schema? Chiaramente se una chiave diventa nulla diventa impossibile identificare il valore di essa! Per questo motivo dobbiamo mettere un constraint e dire che non puÃ² esserlo, in questo modo possiamo identificare in modo univoco ogni entry.\nForeign Key and Referential integrity (!) ðŸŸ© Ãˆ un attributo del nostro schema che si riferisce a una primary key esterna. Anche chiamato referential integrity constraint.\nDefinizione:\nfra un insieme di attributi $X$ di una relazione $R_{1}$ e unâ€™altra relazione $R_{2}$ Ã¨ soddisfatto se i valori su $X$ di ciascuna tupla dell\u0026rsquo;istanza di $R_{1}$ compaiono come valori della chiave (primaria) dellâ€™istanza di $R_{2}$\nSe ho una foreign key, non avrebbe senso se il valore a cui si riferisce non esistesse!\nVincoli I vincoli servono per imporre dei limiti tali per cui i dati abbiano un senso nel nostro dominio, possono essere di tipi specifici, come di tupla e in genere sono intra-relazionali, ossia non hanno bisogno di andare su altre relazioni, oppure inter-relazionali, se prendono piÃ¹ relazioni.\nDatabase schema The schema of a relation refers to its logical design, while an instance of the relation refers to its contents at a point in time. The schema of a database and an instance of a database are similarly defined. The schema of a relation in- cludes its attributes, and optionally the types of the attributes and constraints on the relation such as primary and foreign key constraints.\nStandardization Da questa parte trattiamo meglio quando parliamo di forma Normale in seguito Abbiamo detto che il dataset relazionale ha un formato preciso #Condizioni necessarie per relazione (3) espresso in questo punto, ma ci sono alcuni formati comuni che non lo sono, andiamo a vedere come si possono riportare nel formato standard\nUnnesting Per questo riguarda questo un\nPartial information Non sarebbe sensato utilizzare elementi che siano dentro il nostro dominio della colonna per rappresentare un dato che manca. Per questo motivo si utilizza NULL che rappresenta proprio il dato mancante, e il dominio della colonna sarebbe sempre esteso con NULL (almeno chÃ© esplicitamente vietato).\nTypes of Nulls (3) Unknown Inexistant Uninformative Ma nei DBMS non si fa distinzione, quindi si utilizza un unico null type. References [1] Codd â€œA Relational Model of Data for Large Shared Data Banksâ€ Communications of the ACM Vol. 13(6), pp. 377\u0026ndash;387 1970\n","permalink":"https://flecart.github.io/notes/relazional-model/","summary":"This is the classical format that we encounter, it is the format used for relational databases introduced in databases course introduction, introduced in (Codd 1970).\nIntroduzione, i modelli di dati Lista modelli di dati (4) Nel tempo sono stati sviluppati molti modelli di dati:\nRelational Data Model: This is the most common data model and uses tables to represent data. It organizes data into rows and columns, where each row represents a record, and each column represents an attribute of that record.","title":"Relazional Model"},{"content":"Ripasso Prox: 45 Ripasso: June 3, 2022 Ultima modifica: April 30, 2022 10:30 AM Primo Abbozzo: March 7, 2022 4:15 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Nella ricerca nella linked list non hai considerato il caso in cui l\u0026rsquo;input Ã¨ NIL, cosÃ¬ come anche nell\u0026rsquo;inserimento. Nella deletion non hai considerato il singolo elemento in lista. Anche in questo caso l\u0026rsquo;eliminazione in Testa ha dei problemi, non li hai considerati. Non ti ricordi nei dettagli l\u0026rsquo;analisi ammortizzata per La tecnica di halving e doubling Non hai considerato il caso nullo nella bfs 3 Strutture di dati elementari 3.1 Introduzione 3.1.1 Cosa sono Le strutture di dati si interessano solamente di come memorizzare i dati, non necessariamente va a memorizzare un tipo di dato concreto.\nQuindi + sul come - sul cosa.\n3.1.2 Prototipo e implementazione Avevamo introdotto la differenza fra algoritmo e programma all\u0026rsquo;inizio del corso, andiamo ora a definire la differenza fra prototipo e implementazione:\nPrototipo:\nva a fare una descrizione dei metodi che deve avere una determinata struttura di dati. Lo puoi intendere come una specie di interfaccia.\nImplementazione:\nÃˆ la creazione del programma in un determinato linguaggio di programmazione\n3.1.3 Distinzioni generali fra strutture di dati Le strutture di dati vengono distinte principalmente secondo 3 fattori\nLinearitÃ  vs non-linearitÃ  (sequenzialitÃ  degli elementi es std::set, std::unordered_set\nStaticitÃ  vs dinamicitÃ  (es array e vector)\nOmogeneitÃ  vs eterogeneitÃ  ( che tratta dei tipi di dato che sono memorizzabili\n3.2 Dizionario 3.2.1 Prototipo (proprietÃ  caratterizzanti) Questa Ã¨ una struttura di dati astratta composta principalmente da due cose:\nUn insieme di chiavi (uniche) associati a un valore (duplicabili). per questo motivo si puÃ² anche chiamare array associativo\nSi nota che Ã¨ una struttura di dati dinamica, riguardo invece linearitÃ  e non linearitÃ  dipende dall\u0026rsquo;implementazione.\n3.2.2 Operazioni primitive Ricerca(Chiave) restituisce il valore della chiave Inserimento(Chiave, Valore) crea una chiave con quel valore Elimina(Chiave) elimina l\u0026rsquo;elemento con una determinata chiave 3.2.3 Esempio di implementazione su array ordinato Slide\nLe seguenti sono tutte implementazione ad alto livello senza codice\nImplementazione di Search\nImplementazione di Insert\nImplementazione di Delete\nLa cosa importante da osservare Ã¨ la costo asintotico di questa implementazione, ossia l\u0026rsquo;aspetto che varia a seconda dell\u0026rsquo;implementazione.\nRiassunto del costo computazionale di questa implementazione\n3.2.4 Esempio di implementazione su lista concatenata Qui si utilizza una lista concatenata *circolare ** ovvero l\u0026rsquo;ultimo elemento della lista punta al primo, e il precedente del primo punta all\u0026rsquo;ultimo elemento, solo per non avere un null.\nSlide\nImplementazione di insert/delete\nImplementazione di Search\nScorri la lista ordinata, lo hai giÃ  visto molto spesso ðŸ™‚\nRiassunto costo computazionale lista concatenata\nConfronto fra le due implementazioni\nSlide\nIn conclusione abbiamo delle velocitÃ  diverse, per le operazioni che definiscono il dizionario. La scelta dell\u0026rsquo;implementazione migliore dipende dalle necessitÃ  dell\u0026rsquo;algoritmo, cosa che si decide caso per caso.\nUna osservazione Ã¨ che lista Ã¨ dinamica, mentre array ordinato Ã¨ statico.\n3.3 Liste concatenate 3.3.1 Prototipo semplice Una lista concatenata bidirezionale semplice Ã¨ simile a quanto studiato in programmazione, gli estremi sono terminati da dei null.\nEsempio di lista concatenata unidirezionale semplice\nEsempio di lista concatenata bidirezionale semplice\nCircolare\n3.3.2 Prototipo circolare In particolare qui utilizziamo una lista concatenata bidirezionale circolare.\nOgni nodo contiene il valore, una chiave, e due puntatori al precedente e successivo.\nEsempio di lista concatenata circolare\n3.3.3 Operazioni elementari Sono tre le operazioni principali per una lista concatenata\nSearch\nInsert\nDelete\n3.4 Pile 3.4.1 Prototipo Vogliamo avere qualcosa che stori le cose come se fossero una pila di elementi. Quindi vogliamo solamente delle operazioni molto semplici. diciamo che Ã¨ una struttura di dati di tipo LIFO.\nQuesta semplice struttura di stack Ã¨ molto comoda: ha delle applicazioni non da poco:\nrecord delle chiamate operazioni per un editor di testo per scrivere e no. Parentesi per sintax-parsing Operazioni elementari\nVogliamo queste cose che siano entrambe molto veloci (costante\nPUSH(element)\nPOP()\n3.4.2 Confronto due implementazioni Possiamo utilizzare una lista o array (senza considerare l\u0026rsquo;array doubling)\nSlide\nRisposta domanda: perchÃ© lâ€™unica cosa che serve Ã¨ push e pop, non servono altre operazioni da necessitare della doppia concatenazione\nImplementazione statica Slide\nQuesta Ã¨ la classica implementazione. utilizzando l\u0026rsquo;array statico. ma ha il problema che devo allocare uno spazio in memoria che sia sempre quello. Utilizziamo ora una tecnica che utilizza doubling e halving, per avere un array dinamico\nImplementazione dinamica La cosa buona di questo elemento Ã¨ che il costo ammortizzato Ã¨ costante.\nSlide\nAnalisi del costo ammortizzato\nAnalisi del push ammortizzato\nNel libro Ã¨ anche presente una tecnica utilizzando doubling-halving che utilizza l\u0026rsquo;accantonamento, che si potrebbe dire essere piÃ¹ intuitivo.\nAnalisi del pop ammortizzato (accantonamenti)\nNon viene fatto nelle slide, ma Ã¨ presente sul libro, che incollo qui\n3.5 Code 3.5.1 Prototipo La struttura Ã¨ molto simile a quella della stack, ma qui l\u0026rsquo;unica differenza Ã¨ che invece di togliere il primo che ho messo, tolgo l\u0026rsquo;ultimo. Come se fosse una coda ad un bar.First in first out\nScheduling operazioni BFS Operazioni elementari\nEnqueue(element)\nDequeue()\n3.5.2 Confronto implementazioni (array circolari o liste semplici) Slide di confronto ad alto livello\nImplementazione con la array circolare Questa implementazione non Ã¨ presente nel codice java sorgente.\nSlide\n3.6 Alberi Di piÃ¹ inAlberi BST e AVL\nCose importanti per l\u0026rsquo;albero sono:\nNodi Archi (singolo percorso fra un nodo e un altro, questa Ã¨ la differenza principale con i grafi) Poi possiamo identificare anche un ordine sui figli, radicato. **se ho unnodo come radice.\n3.6.1 Prototipo Come un albero binario di ricerca\u0026hellip;\n3.6.2 Operazioni elementari Lo scorrimento di un albero nei 3 modi: pre-ordine, in-ordine, post-ordine utilizzando gli algoritmi come DFS e BFS\n09/03/22 Buona conoscenza a livello teorico dellâ€™argomento, se si ha tempo sarebbe buona cosa anche provare le molte implementazioni proposte (pile, liste, code e dizionari) 12/03/22 Ancora tutto apposto. 30/04/22 Si derei tutto appo, niente di strano od oltremodo complesso, magari le implementazioni, ma non sono importanti da ricordare. onari) \u0026mdash; \u0026mdash; 12/03/22 Ancora tutto apposto. 30/04/22 Si derei tutto appo, niente di strano od oltremodo complesso, magari le implementazioni, ma non sono importanti da ricordare. ","permalink":"https://flecart.github.io/notes/strutture-di-dati-elementari/","summary":"Ripasso Prox: 45 Ripasso: June 3, 2022 Ultima modifica: April 30, 2022 10:30 AM Primo Abbozzo: March 7, 2022 4:15 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Nella ricerca nella linked list non hai considerato il caso in cui l\u0026rsquo;input Ã¨ NIL, cosÃ¬ come anche nell\u0026rsquo;inserimento. Nella deletion non hai considerato il singolo elemento in lista. Anche in questo caso l\u0026rsquo;eliminazione in Testa ha dei problemi, non li hai considerati.","title":"Strutture di dati elementari"},{"content":"Ripasso Prox: 2 Ripasso: April 30, 2022 Ultima modifica: June 29, 2022 9:42 AM Primo Abbozzo: March 23, 2022 10:33 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nClassi laterali Dimostrazione dei lemmi sopra. La cosa interessante di questa parte Ã¨ possiamo usare una classe laterale per partizionare il gruppo iniziale!\nIl teorema di Lagrange Dividere significa che **partiziona** l'insieme iniziale in alcuni insiemi distinti. L'insieme $G:H$ Ã¨ l'insieme che contiene tutti i cosets, credo. Dimostrazione\n|G:H| = |G|/|H| |a| divide |G| Ossia un corollario dopo il teorema di Lagrange. La cosa citata Ã¨ dimostrata in Gruppi ciclici e permutazioni#Criterio $a {i} = a {j}$.\nI gruppi di ordine primo sono ciclici Se ho un gruppo di ordine primo, per il teorema di Lagrange non posso avere sottogruppi propri, perchÃ© lâ€™ordine di questi dovrebbe dividere lâ€™ordine del gruppo di partenza. Per questo motivo ho un unico gruppo. Ossia ogni elemento genera lâ€™intero gruppo\na elevato allâ€™ordine del gruppo Ã¨ uguale ad e Dimostrazione Lâ€™ordine dellâ€™elemento a deve dividere lâ€™ordine di |G| per Lagrange, quindi, in simboli $$ |a| =n, |G| = m, n \\mid m \\implies m = nj, a^{|G|} = a^{nj} = e ^j = e $$ Il piccolo teorema di fermat Dimostrazione\nSolitamente si usa la versione $$ a^{p - 1} = 1 \\mod p $$ E la cosa comoda Ã¨ che $a^{p - 2}$ Ã¨ l\u0026rsquo;inversa di quello.\nTeorema di Eulero Proof. http://www.fen.bilkent.edu.tr/~franz/nt/ch7.pdf.\nQuesta Ã¨ una generalizzazione di #Il piccolo teorema di fermat. Afferma che $\\forall n \\in \\mathbb{N}$ vale che $$ a^{\\varphi(n)} = 1 \\mod n $$ Questo Ã¨ molto piÃ¹ complesso da descrivere e dimostrare. Bisognerebbe per esempio anche definire proprietÃ  della funzione di Eulero.\nClassificazione dei gruppi di ordine 2p SCHIVA STO TEOREMA CHE NON MI SERVE A NUCAZZU\nIdee della dimostrazione\nDividere la discussione con la presenza o meno di elementi di ordine 2p Caso in cuinon ci sono elementi di ordine 2p Dimostrare che esiste almeno un elemento di ordine p, perchÃ© se fossero tutti di ordine 2, riesco a crearmi (in modo creativo) un sottogruppo di ordine 4 a piacere, molto simile al gruppo quaternione. Avendo un sottogruppo di ordine p, questo quozienta lâ€™insieme G per il teorema di lagrange, ho solamente un altro insieme che posso scrivere come elemento_fuori_a * gruppo_generato_da_a_di_ordine_p Dimostro che lâ€™ordine dellâ€™elemento fuori da a deve essere necessariamente di ordine 2. (in qualche modo che non ho compreso) Dimostrazione\nStabilizzatore e orbita Stabilizzatore Orbita !\nTeorema orbita stabilizzatore !\n","permalink":"https://flecart.github.io/notes/teorema-di-lagrange/","summary":"Ripasso Prox: 2 Ripasso: April 30, 2022 Ultima modifica: June 29, 2022 9:42 AM Primo Abbozzo: March 23, 2022 10:33 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nClassi laterali Dimostrazione dei lemmi sopra. La cosa interessante di questa parte Ã¨ possiamo usare una classe laterale per partizionare il gruppo iniziale!\nIl teorema di Lagrange Dividere significa che **partiziona** l'insieme iniziale in alcuni insiemi distinti. L'insieme $G:H$ Ã¨ l'insieme che contiene tutti i cosets, credo.","title":"Teorema di Lagrange"},{"content":"Ultima modifica: March 11, 2023 7:22 PM Primo Abbozzo: March 8, 2023 6:05 PM Studi Personali: No\nElementi di ripasso Training of NN How can we be sure that we can train well our function?\nDataset quality (this cannot be changed in training time) Models and parameters of our model, we can describe it as $L(x, \\theta)$, and we try to minimize this function. Training approaches Random perturn weights, this is ispired by evolution, but itâ€™s slow and not effective (and we can make things worse in many ways) Predict adjustments, usually we can analitically define what is the best way to minimize the loss, so we would like to follow that slope and go down! When we try to learn with the second method we usually follow the direction of a derivative (this is also an idea of gradient descent that we discussed in Metodi di Discesa.\nSo if we have a step function, we canâ€™t learn anything, this is not a good loss. This is the classic gradient descent, but the new thing is that we have optimizers, more on them later.\nThe standard Gradient descent uses the whole dataset to calculate the direction and module of descent. Usually this is quite expensive, why would we need to use all the data when a subset could be enough? And also, why canâ€™t we use the last gradient to know where to go? There are the ideas for the next gradient descent methods.\nStochastic Gradient descent faster More noise Sometimes when we try to escape from the noise, we can add some noise, like having a bigger step function, and we can escape a local minima if we get to.\nMomentum This is the other type of gradient descent, we add a momentum factor something like\n$$ v_{t + 1} = \\mu\\nabla L(x) + \\alpha v_t $$ The first term is the gradient (direction term) the second is the momentum term.\nSlide on momentum\nA different kind of momentum is nesterov momentum that just calculates the gradient from the next point after we applied the momentum, and not before, this should be a little better because we are just going from the gradient direction in an offsetted point, and not changing the gradient with some heuristic, (non mi sono affatto spiegato bene qui, non credo infatti di averlo capito bene sto momentum)\nSlides nesterov\nBackpropagation This is the gradient descent for neural networks.\n","permalink":"https://flecart.github.io/notes/training-a-nn/","summary":"Ultima modifica: March 11, 2023 7:22 PM Primo Abbozzo: March 8, 2023 6:05 PM Studi Personali: No\nElementi di ripasso Training of NN How can we be sure that we can train well our function?\nDataset quality (this cannot be changed in training time) Models and parameters of our model, we can describe it as $L(x, \\theta)$, and we try to minimize this function. Training approaches Random perturn weights, this is ispired by evolution, but itâ€™s slow and not effective (and we can make things worse in many ways) Predict adjustments, usually we can analitically define what is the best way to minimize the loss, so we would like to follow that slope and go down!","title":"Training a NN"},{"content":"Ripasso Prox: 40 Ripasso: May 27, 2023 Ultima modifica: April 17, 2023 12:52 PM Primo Abbozzo: November 22, 2022 1:22 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Domande\nBottom-up Parser -LR(1) Si puÃ² osservare che per il parser costruito in Bottom-up Parser LR(0), non riesce a riconoscere di linguaggi semplici come $L = \\{a, ab\\}$.\nEsempio di quanto detto Parser SLR(1) Questi parser qui utilizzano lâ€™idea del look ahead ampiamente utilizzata in Top-down Parser, per escludere molte produzioni.\nLa s sta per simple, perchÃ© utilizza una idea semplice :D, credo ahah boh.\nRiduzione con follow ðŸŸ© noi vogliamo ridurre solamente se ho follow corretto il terminale finale della stringa.\nQuindi in pratica vado ad aggiungere questa nuova regola per togliere alcune riduzioni senza questo terminale nella tabella.\nEsempio\nalla fine non deve essere solamente per S, deve essere per il follow!, ma sotto nella tabella di parsing ne parliamo un pochino meglio.\nOsservazioni varie (4) ðŸŸ¥+ slide\nÃˆ molto raro che alcune produzioni che hanno la epsilon siano di LR(0), anche se Ã¨ possibile! Libero deterministico + prefix property â†’ LR(0) not LR(0) â†’ libero deterministico + not prefix property or prefix property or not libero deterministico. Finito e LR(0) â†’ prefix property. Se Ã¨ infinito e LR(0) puÃ² non godere della prefix property. Tabella di parsing SLR(1) ðŸŸ¨+ Slide\nPraticamente il riempimento di questa tabella Ã¨ identica a quella del LR(0), solo con il check in piÃ¹ sui follow di S.\nL\u0026rsquo;unica cosa differente Ã¨ che\n$A \\to \\alpha. \\in S, A \\not\\in S',$ allora il reduce si puÃ² fare in $M[s, x] \\iff x \\in Follow(A)$, ossia solo se ho il follow, non devo andare a fare shift!\nMentre per LR(0) lo devo mettere per tutti gli entry!\nParser LR(1) Item LR(1) ðŸŸ©- In questa serie di Item dobbiamo ancora andare ad estendere il concetto di item esposto in [Bottom-up Parser LR(0)](Bottom-up Parser LR(0) 92be8778006943cf99add4d634a3fb1a.md).\nApplicando anche una parte di lookahead, di non terminali\nClosure \u0026amp; goto ðŸŸ© Slide\nLa cosa nuova riguardante questo Ã¨ che devo andare a considerare i first e simili!\nSi l\u0026rsquo;unica cosa in piÃ¹ Ã¨ che devo agigungere ogni cosa riguardante il first.\nIl goto resta esattamente uguale!\nTabella di parsing ðŸŸ¨+ Slide\nL\u0026rsquo;algoritmo di creazione della tabella di parsing mi sembra sia molto simile a quelle precedenti, perÃ² per capire se ho compreso questo concetto sarebbe utile fare qualche esercizio a riguardo! LR(0) ha detto che per forza ce lo mette in esame!\nEsempio di parsing LR(0)\nNucleo dello stato LR 1\nSe rimuovo il look ahead, allora ottengo lo stato dell\u0026rsquo;automa LR(0)! In questo senso potremmo osservare che le transizioni di LR 1 dipendono solo dal nucleo. Questo diventa un hint molto importante per andare a costruire poi un automa LALR.\nLALR (1) Questi automi sono presenti allâ€™orale perÃ² allo scritto non ci sono proprio.\nQuesto Ã¨ una forma di mezzo fra semplicitÃ  di SLR e la selettivitÃ  di LR.\nSi traduce come Look-Ahead Left-reading Right-most derivation 1 lookahead parser\nOsservazioni sulla tabella ðŸŸ¨+ Questo ha una tabella con il nucleo fuso per quelli che hanno le cose uguali, in questo modo cerco di limitare il numero di stati.\nQuesta parte Ã¨ molto simile a quanto fatto per la minimizzazione dei dfa in Automi e Regexp, perchÃ© stiamo andando ad accorpare stati che sono quasi equivalenti, questo col rischio di introdurre alcuni conflitti reduce-reduce che perÃ² non dovrebbero portare a troppi problemi, come andremo presto a vedere.\nEsempio slide entrambi errati\nlezione 16 slide 18\nPossibilitÃ  di conflitti (no shift-reduce dimo) ðŸŸ¨ Slide\nDa questo esempio presente in slide vediamo che una grammatica puÃ² essere LR(1) e non LALR(1), quindi non sono esattamente equivalenti.\nRiassunto di questa lezione 16\nEsempio LR not LALR ðŸŸ¨ Questo Ã¨ un esempio importante solo perchÃ© Ã¨ richiesto nelle domande, altrimenti lâ€™avrei saltato. Comunque basta un pÃ² ricordarsi cose riguardo simmetria della grammatica per costruire quasi ad Hoc un conflitto Reduce-Reduce nella grammatica LALR\nEsempio di conflitto ","permalink":"https://flecart.github.io/notes/bottom-up-parser-lr1/","summary":"Ripasso Prox: 40 Ripasso: May 27, 2023 Ultima modifica: April 17, 2023 12:52 PM Primo Abbozzo: November 22, 2022 1:22 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Domande\nBottom-up Parser -LR(1) Si puÃ² osservare che per il parser costruito in Bottom-up Parser LR(0), non riesce a riconoscere di linguaggi semplici come $L = \\{a, ab\\}$.\nEsempio di quanto detto Parser SLR(1) Questi parser qui utilizzano lâ€™idea del look ahead ampiamente utilizzata in Top-down Parser, per escludere molte produzioni.","title":"Bottom-up Parser LR(1)"},{"content":"Metodi di key exchange\nTrusted Key parties (sono come Certificate authorities studiati in Sicurezza delle reti) Merkle Puzzles DH protocol Trusted Third parties Squared Key problem Un problema abbastanza ovvio Ã¨ che per storare le chiavi di tutti c\u0026rsquo;Ã¨ una necessitÃ  $O(n^{2})$ on $O(n)$ users Se c\u0026rsquo;Ã¨ un trusted key parties il numero delle chiavi si riduce di molto, ritorna ad essere lineare!\nProtocols Toy Exchange protocol ðŸŸ© TTP = Trusted Third party (simile a quanto poi si avrÃ  in Asymmetric Cryptography) Questa Ã¨ la base del servizio di Kerberos! Il servizio di sopra Ã¨ sicuro su Choosen Plaintext, dato che Eve non capisce niente senza le chiavi!\nMerkle Puzzles vogliamo cercare di risolvere problemi di origliamento (eavesdrop, senza modifiche varie sul messaggio. Avversario passivo. Vogliamo farlo senza avere un #Trusted Third parties.\nUn Puzzle ðŸŸ¨\u0026ndash; Prendiamo una stringa lunga 32, e la cifriamo con una chiave Scelta da noi. Questo Ã¨ il puzzle, l\u0026rsquo;avversario ha la chiave, ma riceve tutti e $2^{32}$ messaggi per poter avere la chiave corretta. Vedere slides.\nIl primo crea un puzzle, il secondo risolve un puzzle a caso e manda la coppia $x, k$ che ha trovato, mentre l\u0026rsquo;attaccante non sa quale sia la coppia che ha risolto, e dovrebbe farlo a caso.\nDiffie-Hellman Protocol Introduzione DH ðŸŸ© Questo Ã¨ quello che abbiamo studiato anche a Olycyber quindi Ã¨ piÃ¹ facile. Ãˆ basato su una costruzione matematica molto simile a RSA.\nIn pratica cosÃ¬\nScelgo $p$ primo largo Scelg $g$ Alice sceglie $a$, e manda $g^{a}$ a Bob Bob fa lo stesso con $b$ Il segreto Ã¨ $g^{ab}$ , che Ã¨ difficile da capire con i moduli\u0026hellip; Attacco a DH ðŸŸ© DH Ã¨ insicuro dal punto di vista del Man in the middle. PerchÃ© se uno in mezzo intercetta, puÃ² usare la sua chiave privata al posto di quella dell\u0026rsquo;altro interlocutore. Tanto conosce il valore di $g$ e gli basta questo. ","permalink":"https://flecart.github.io/notes/key-exchange-protocols/","summary":"Metodi di key exchange\nTrusted Key parties (sono come Certificate authorities studiati in Sicurezza delle reti) Merkle Puzzles DH protocol Trusted Third parties Squared Key problem Un problema abbastanza ovvio Ã¨ che per storare le chiavi di tutti c\u0026rsquo;Ã¨ una necessitÃ  $O(n^{2})$ on $O(n)$ users Se c\u0026rsquo;Ã¨ un trusted key parties il numero delle chiavi si riduce di molto, ritorna ad essere lineare!\nProtocols Toy Exchange protocol ðŸŸ© TTP = Trusted Third party (simile a quanto poi si avrÃ  in Asymmetric Cryptography) Questa Ã¨ la base del servizio di Kerberos!","title":"Key Exchange protocols"},{"content":"Ripasso Prox: 7 Ripasso: May 28, 2023 Ultima modifica: May 19, 2023 1:57 PM Primo Abbozzo: April 19, 2023 1:43 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Modulazione del segnale Introduzione Digital modulation ðŸŸ¨ Slide introduzione\nModulazione digitale: prendiamo un dato digitale e trasmesso con un segnale analogico, come le RF.\nASK: amplitude shift keying\nFSK: frequency shift\nPSK: phase shift\nQuesti sono i tre metodi principali, che dipendono dalle caratteristiche dellâ€™onda descritte in Fisica del Wireless.\nTRE CARATTERISTICHE\nPower\nResistenza interferenze. (robustezza)\nANALOG MODULATION\nPer modulare un segnale analogico si utilizzano principalemente AM o FM, amplitude o frequency modulation, raramente si utilizza PM.\nIn AM la frequenza Ã¨ la stessa, ma posso cambiare la ampiezza, in pratica con lâ€™ampiezza provo a ricalcare lâ€™ampiezza dellâ€™onda iniziale (credo che intuitivamente onda radio ha frequenza molto piÃ¹ alta del suono, quindi riesco a descriverlo bene, credo, probabilmente sbaglio).\nModello trasmittente e ricevente ðŸŸ© Struttura trasmittente\nIl primo prova a rappresentare il segnale digitale in un segnale sinusoidale. (probabilmente trasformate here).\nIl secondo blocco prende la codifica in segnale analogico e la trasforma in una onda radio (modulata in un certo modo). (prende in input anche il canale in cui codificare le cose), e questa Ã¨ data allâ€™antenna che genera RF.\nStruttura ricevente\nIl segnale nel frattempo:\nHa perso intensitÃ  PuÃ² avere shift di fase a seconda dei rimbalsi Dal ricevente modula lâ€™onda radio che riceve in un segnale analogico, che ora perÃ² possiede itnerferenze quindi non Ã¨ una onda clean, e prova a fare una interpretazione.\nAlgoritmi di modulazione digitale ASK FSK PSK ðŸŸ© slide ASK e FSK e PSK\nNella parte tagliata câ€™Ã¨ scritot â€œSignal modulation (Shift keying)â€\nASK\nLa tecnica piÃ¹ semplice Ã¨ amplitude shift keying (aka modulazione digitale con amplitude) che non Ã¨ altro che trasmettere onde di frequenza precisa per canale per 1 silezio per 0. (ma come faccio a gestire le interferenze? Non c\u0026rsquo;Ã¨ silenzio in questo modo!) Credo che questo sia molto simile al morse.\nAd esempio se la distanza Ã¨ troppo larga, leggerebbe 0.\nSe il rumore di fondo Ã¨ troppo alto leggerebbe 1. ecco interferenze\nFSK\nIl segnale digitale Ã¨ codificato attraverso la frequenza del valore, per esempio se utilizziamo una metafora fisica, se il segnale Ã¨ rosso ho 1 se viola 0, cambia colore diciamo :).\nQuesto Ã¨ piÃ¹ resistente alle interferenze.\nPSK\nÃˆ piÃ¹ difficile da implementare. Viene mantenuta sia la frequenza sia lâ€™ampiezza.\nRappresentazione del segnale ðŸŸ© Slide rappresentazione\nTre tipologie di grafici, la terza, in cordinate polari Ã¨ la piÃ¹ utilizzata, anche se non ci dice la frequenza (la frequenza Ã¨ quella mantenuta durante la radio carrier nel sistema di modulazione accennato prima). I punti su questo grafico sono chiamati simboli\nNella sconda perdiamo la fase, poco utilizzata.\nNella prima ha praticamente tutte le infomrazioni (la fase perÃ² credo sia solo relativa).\nBinary Phase Shift Keying e QPSK ðŸŸ© Slide BPSK e QPSK\nAbbiamo dato ai simboli del grafico alcuni valori binari, questo ci da un modo per andare a interpretare i segnali seguendo quel grafico.\nQAM and HIerarchical modulation ðŸŸ© Solo che la densitÃ  dei simboli Ã¨ ora ancora maggiore, utilizzo sia intensitÃ  sia fase\nSlide QAM\nHIERARCHICAL MODULATION\nÃˆ una cosa ancora piÃ¹ precisa!\nSlide HM\nSi utilizza un trucco di codifica di utilizzo della nuvola di segnali e una codifica interna!\nQuesot si utilizza anche per mobile video call in modo che la voce sia codificata meglio.\nSlide mobile video call nice\nSpread spectrum techniques Solitamente potremmo utilizzare delle narrowband spectrum, solo che queste sono molto sensibili ad interferenze nella narrowband, per questo motivo si preferisce andare su spread spectrumn e andiamo ora a parlare di alcune tecnologie utilizzate per questo.\nDirect sequence spread spectrum ðŸŸ©- In pratica vado a definire una chipping spectrum che possiede certe proprietÃ  statistiche che vengono interpretate come rumore di sottofondo (non correlate fra di loro) nel caso in cui non si conosca il codice.\nSlide funzionamento del chipping sequence\nLa codifica col chiping sequence non Ã¨ altro che un xor, con il bit che vogliamo inviare e la chipping sequence\nSlide codifica e decodifica del codice\nQuesto processo di xor Ã¨ descritto sotto in Code division multiple access ðŸŸ©. Ãˆ questa tecnologia di code division multiple access. che permette questa trasmsisione su frequenze molto diverse, ed essere comunque ricevuto.\nCode division multiple access ðŸŸ© Fa sÃ¬ che utilizzando chipping sequence poco (preferibilmente niente) correlate fra di loro, il segnale viene interpretato come segnale di sottofondo (white noise) e quindi il ricevitore, come per magia, riesce comunque a comprendere il segnale iniziale.\nEsempio di trasmissioen corretta di CMA\nPraticamente a lato ricevente esiste un integratore che fa la somma e viene utilizzato questo per andare a decidere se Ã¨ un bit 0 oppure 1 (per comoditÃ  solitamente lo 0 viene codificato come se fosse un -1).\nFrequency hopping spread spectrum ðŸŸ© Viene utilizzata l\u0026rsquo;energia per mandare in modo pseudorandomico (secondo il seed, credo ne abbiamo giÃ  parlato in precedenza con la cosa di hedy lamarr).\nSlide FHSS\nPraticamente il segnale Ã¨ unico (cioÃ¨ non Ã¨ disperso su una banda larga di segnale, ma Ã¨ narrowband) comuqnue per chi non conosce il codice sembra rumore di fondo\nSi utilizza host_master come seed\nFast and slow hopping a seconda del numero di bit mandati prima di switchare segnale.\nOrthogonal Frequency Division Multiplexing ðŸŸ© signal transmission technology that separates a single high-speed data stream into multiple sub-carrier signals that are transmitted simultaneously. Each sub-carrier signal uses a different frequency, presenting a unique path for data transfer. By using multiple sub-carriers in a single channel, OFDM technology can transmit data more efficiently and reliably, even in noisy and highly congested RF environments\nAbbiamo pacchetti di dati poco distanziati (quind il bitrate nominale Ã¨ molto alto, tutto viene fatto in parallelo).\nSlide OFDM\nEsempio\nSTRUTTURA\nQuattro carrier sono utilizzati per gestire il canale quindi per dire che il canale non va, bisogna cambiare, rallentare etc. In modo simile ai pacchetti di gestione della congestione nei routers.\nÃˆ molto efficiente dal vista del bandwith (servono 9.76 kilohearz per un sub carrier) e se ho 20 Mhz ho 2048 subcarrier (questo ci fa venire in mente il perchÃ© Ã¨ lungo quella quantitÃ  di band withd :D)\nLa cosa bella Ã¨ anche lâ€™indipendenza con i subcarriers!\n1 milione per ogni subcarrier (basta fare qualche calcolo, tipo massimo di tutti i canali sono circa 3 Gbit per questa tecnologia). questa Ã¨ WiMax\nSlide WiMax\n250k bit per subcarrier che sono comunque 500 Mb su distanza larga.\nFunzionamento di OFDM ðŸŸ¨ Si utilizzano magie matematiche per questa tecnologia, ed Ã¨ molto intelligente :D\nAbbiamo un teorema che ci dice che le funzioni di seno e coseno sono tutte fra diloro ortogonali ossia lâ€™intergrale del segnale Ã¨ sempre 0 sopra il periodo di tutti.\nSlide segnali ortogonali\nQuesto permette di sapere che la somma di tutti gli altri segnali danno somma zero e io so in che modo andare a leggere. In questo senso i segnali interferiscono sÃ¬, ma lo fanno in un modo predicibile che mi permette di ritrovare la informazione iniziale.\nEsempio decodifica\nIntuitivamente le FFT ci permettono di cambiare frame of view, se prima erano tutte compattate sul tempo, ora Ã¨ compattato sulla frequenza, per questo motivo riuscimo a distinguerle per bene (quindip ossiamo distinguere anche il bit trasmesso per il singolo subcarrier)\n20Mhz con 52 subcarrier con 4 pilot e il resto dei dati. e utilizza 250k modulazioni l secondo (questo Ã¨ il massimo!).\nNelle slides c\u0026rsquo;Ã¨ una D, che sta per differential, perchÃ© sta relativo al precedente (non Ã¨ 0, o 180, ma Ã¨ differenza rispetto al precedente credo, ma comunque ha detto che non Ã¨ per niente importante questa cosa. Esistono bits di convoluzione che sono utilizzati per fixare errori di trasmissione.\nESEMPI:\nSlide OFDM\nEsempio per DBPSK: 1 bit per 48 subcarrier, la metÃ  sono utilizzati per dato, l\u0026rsquo;altra per protezione, ho 24 carriers per durata, quindi 24 * 250k bits al secondo che Ã¨ proprio 6kk!\nSe prendo DQPSK allora ho 3/4 per dati, e questo fa tanti calcoli, ma poca roba..\nUna cosa che accade con 64 QAM che invece di fare 1/2 di protezione viene fatto solamente un terzo perchÃ© se raggiungi quel punto vuol dire che il canale Ã¨ giÃ  molto forte.\nE câ€™Ã¨ un programma di controllo che decide quale codifica andarea d utilizzare (tornando indietro se non (riceve gli acks)\nNel caso io abbia bisogno di ancora altri bit potrei aggiungere altri subcarriers (e si puÃ² fare in modo dinamico, si chiama channel bonding. (canali di frequenza arbitraria in base a quanto ne ho bisogno ! esempi di tecnologie che lo utilizzano: 802.11 af ac)\n","permalink":"https://flecart.github.io/notes/modulazione-wireless/","summary":"Ripasso Prox: 7 Ripasso: May 28, 2023 Ultima modifica: May 19, 2023 1:57 PM Primo Abbozzo: April 19, 2023 1:43 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Modulazione del segnale Introduzione Digital modulation ðŸŸ¨ Slide introduzione\nModulazione digitale: prendiamo un dato digitale e trasmesso con un segnale analogico, come le RF.\nASK: amplitude shift keying\nFSK: frequency shift\nPSK: phase shift\nQuesti sono i tre metodi principali, che dipendono dalle caratteristiche dellâ€™onda descritte in Fisica del Wireless.","title":"Modulazione wireless"},{"content":"Introduzione a NaÃ¯ve Bayes Bisognerebbe in primo momento avere benissimo in mente il significato di probabilitÃ  condizionata e la regola di naive Bayes in seguito.\nBayes ad alto livello ðŸŸ© Da un punto di vista intuitivo non Ã¨ altro che predire la cosa che abbiamo visto piÃ¹ spesso in quello spazio Assunzioni principali per naÃ¯ve Bayes ðŸŸ© I sample di input sono condizionalmente indipendenti uno con l\u0026rsquo;altro. Questo permette di utilizzare questa ipotesi $$ P(X_{1}\\dots X_{n} | Y = y_{i}) = \\prod_{i}^{n} P(X_{i} | Y) $$ E permette di rendere la parte di inferenza anche molto semplice perchÃ© per classificare un caso basta prendere label con la probabilitÃ  maggiore. che Ã¨ dato solamente dal numeratore durante la regola di Bayes. Tecnica generativa ðŸŸ© La distinzione fra generativa e discriminativa Ã¨ fatta in Introduction to machine learning. Ossia cerchiamo di capire come si distribuiscono i dati? (ossia prova a capire le probabilitÃ  che abbiano generato questi dati). Mentre in modelli supervisionati classici si potrebbe dire che provano a capire $Y$ assumendo i dati esistenti di training.\nProva a capire $P(X|Y)$ diciamo e poi da questo si puÃ² ricalcolare $P(Y | X)$ grazie alla formula di Bayes una volta capito $P(X)$ e l\u0026rsquo;altro.\n$$ P(Y | X) = \\frac{P(X|Y)P(Y)}{P(X)} $$ Classificazione lineare Bayes ðŸŸ©- Si viene a scoprire che NaÃ¯ve bayes alla fine fa classificazione lineare, che ci dice che Ã¨ un modello molto molto semplice.\nConsideriamo $x_{i}$ e $Y$ booleani (sarÃ  necessario per fare la nostra approssimazione), allora la nostra Naive Bayes classificherebbe 1 sse $$ \\frac{P(Y = 1, X_{1}\\dots X_{n} = \\vec{x})}{P(Y = 0, X_{1}\\dots X_{n} = \\vec{x})} = \\frac{P(Y = 1 | X_{1}\\dots X_{n} = \\vec{x})}{P(Y = 0 | X_{1}\\dots X_{n} = \\vec{x})}\\geq 1 $$ La prima uguaglianza di sopra Ã¨ ottenuta osservando che $P(Y=1, X_{1}, \\dots, X_{n} = \\vec{x}) = P(Y=1 | X_{1}, \\dots, X_{n} = \\vec{x}) \\cdot P(X_{1}, \\dots, X_{n} = \\vec{x})$ E poi semplificando entrambi.\nPossiamo prendere il logaritmo e utilizzare l\u0026rsquo;ipotesi di essere condizionalmente indipendenti e abbiamo $$ \\log \\frac{P(Y=1)}{P(Y=0)} + \\sum_{i} \\log \\frac{P(X_{i} = x_{i} | Y=1)}{P(X_{i} = x_{i} | Y=0)} \\geq 0 $$ E usando un trucco lo facciamo diventare lineare (vedi slide 126)\nNotiamo che una funzione da booleani a booleani si puÃ² approssimare come\n$$ f(x) = x f(1) + (1 - x) f(0) $$ E quindi si puÃ² esprimere l\u0026rsquo;intera seconda somma a sinistra in un modo lineare, in quanto siamo rimasti in setting lineare. Poniamo $$ \\theta_{ik} = P(X_{i} = 1 | Y = y_{k}) $$ Non so in che modo possa essere estesa ad altri casi, ma nel caso booleano funziona Quindi unendo le due cose abbiamo:\n$$ \\sum_{i} \\log \\frac{P(X_{i} = x_{i} | Y=1)}{P(X_{i} = x_{i} | Y=0)} = \\sum_{i}x_{i} \\log \\frac{\\theta_{i1}}{\\theta_{i0}} + \\sum_{i} (1 - x_{i}) \\log \\frac{1 - \\theta_{i1}}{1- \\theta_{i0}} $$ Assumendo che $f(x) = \\log \\frac{P(X_{i} = x | Y=1)}{P(X_{i} = x | Y=0)}$ Vediamo da sopra che Ã¨ lineare.\nCaso continuo Introduzione modellazione nel caso continuo ðŸŸ¨+ Per ora abbiamo sempre assunto che le classi da predire fossero discreti, perÃ² si puÃ² utilizzare anche in un caso continuo, e in questo caso si usa una gaussiana.\nScegliamo una legge gaussiana perchÃ© naturalmente se sommiamo un sacco di distribuzioni, verrÃ  che sarÃ  una gaussiana. Legge dei grandi numeri, quindi Ã¨ una fra le distribuzioni piÃ¹ naturali. Ãˆ la distribuzione con entropia maggiore fra tutte le distribuzioni con data media e varianza. Se si hanno altre informazioni, sarebbe molto piÃ¹ sensato utilizzare una altra distribuzione, ma introdurrebbe un bias di un certo tipo. Metriche TP FP TN FN ðŸŸ©- Questa parte Ã¨ molto importante per sapere quali metriche siano importanti, riguardo\nTrue positives False positives True Negatives False positives E con queste possiamo definire concetti come accuratezza, recall e precisione Inferenza nel caso continuo ðŸŸ©\u0026ndash; Sembra molto simile a una Gaussian Mixture Models, perchÃ© alla fine Ã¨ una interpolazione in un certo senso, solo che Ã¨ motivato in modo diverso. Training nel caso continuo E probabilmente si puÃ² dimostrare, facendo un ragionamento come Maximum Likelihood extimate anche in questo caso. Algoritmo di fitting Si tratta quindi di creare tutti i parametri $\\theta_{ijk}$, anche se in questo momento non sto capendo in che modo Al fine di stimare questo usiamo maximum likelihood extimate. Guardare #Sul MLE sotto per capire in che modo sono stimati.\nStima P(Y) ðŸŸ© Poniamo la cosa piÃ¹ banale, la stima di $P(Y = y_{i})$ Ã¨ solamente la percentuale delle labels che abbiamo, ossia\n$$ \\pi_{i} = P(Y = y_{i}) = \\frac{\\#D(Y = y_{i})}{\\lvert D \\rvert} $$ Utilizziamo $\\pi$ per scrivere in modo piÃ¹ veloce la probabilitÃ  del singolo label.\nStima parametri P(X|Y) ðŸŸ© Anche per questo caso andiamo a fare una cosa alla fine banale che Ã¨ contare il numero dei training samples con quel label $$ \\theta_{ijk} = P(X = x_{ij} | Y = y_{k}) = \\frac{\\#D(X_{i} = x_{i,j} \\cap Y = y_{k})}{\\#D(Y=y_{k})} $$ Edge cases (2) ðŸŸ©- ProbabilitÃ  id zero: Non vogliamo avere che $P(X_{i}|Y) = 0$ perchÃ© produrrebbe sempre nullo (questo succede per esempio per i modelli di testo mi pareva), Ã¨ improbabile che sia 0 perchÃ© noi per ora ci stiamo concentrando su una stima, una cosa che fanno Ã¨ aggiungere sempre almeno un esempio perchÃ© cosÃ¬ non ho una probabilitÃ  nulla per tutto in questo caso.\nCasi non indipendenti Questo Ã¨ molto difficile da gestire, dipende da come abbiamo generato i dati, quindi Ã¨ esterna a questa fase di scelta del modello diciamo. Bayes Ã¨ probabilmente non molto utile in questi casi, perchÃ© questo caso viola l\u0026rsquo;assunzione iniziale, si dovrebbe probabilmente fare preprocessing per cercare di limitare la dipendenza.\nSul Maximum Likelihood estimation Introduzione al problema C\u0026rsquo;Ã¨ una parte teorica molto piÃ¹ interessante per quanto si tratta di maximum likelihood estimation. Andiamo a giustificare il motivo per cui stime molto semplici ed intuitive come quelli presenti in #Stima P(Y) e #Stima parametri P(X Y) possono funzionare. Ci chiediamo in questa istanza quale sia il caso piÃ¹ probabile ossia quello con maximum likelihood\nMLE su bernoulli ðŸŸ© Supponiamo di avere $n$ lanci con una moneta unfair, ossia $p(X) \\neq 0.5$ di avere testa. Date certe osservazioni, quale Ã¨ il valore piÃ¹ probabile di $P(X)$?\nConsideriamo $X^{n}$ la variabile aleatoria che misura il numero di 0 all\u0026rsquo;interno del nostro problema, allora questo segue la legge di Bernoulli.\n$$ P(X^{n} = \\alpha_{0} | \\theta) = \\binom{n}{\\alpha_{0}} \\theta^{\\alpha_{0}} (1 - \\theta)^{n-\\alpha_{0}} $$ Seguendo l\u0026rsquo;idea del piÃ¹ probabile quello che noi stiamo cercando Ã¨\n$$ \\hat{\\theta} = argmax_{\\theta} P(X^{n} = \\alpha_{0} | \\theta) $$ Soluzione problema analitico Prendiamo il logaritmo, che non cambia il nostro massimo, dato che Ã¨ monotona, ma ci semplifica un sacco l\u0026rsquo;analisi\n$$ \\ln(\\theta^{\\alpha} (1- \\theta)^{n - \\alpha }) = \\alpha \\ln \\theta + (n- \\alpha) \\ln(1 - \\theta) $$ Derivando rispetto a $\\theta$ abbiamo che\n$$ \\frac{\\alpha}{\\theta} - \\frac{n - \\alpha}{1- \\theta} = \\frac{\\alpha - \\alpha \\theta - (n - \\alpha) \\theta}{\\theta (1 - \\theta)} $$ che Ã¨ un massimo o un minimo se $$ \\alpha - \\alpha \\theta - (n - \\alpha) \\theta = 0 \\implies \\theta = \\frac{\\alpha}{n} $$ E se ben ricordiamo, $\\alpha$ non era altro che il numero di samples negativi, quindi questo Ã¨ un esempio locale in cui MLE Ã¨ la soluzione ottimale per stimare.\n","permalink":"https://flecart.github.io/notes/na%C3%AFve-bayes/","summary":"Introduzione a NaÃ¯ve Bayes Bisognerebbe in primo momento avere benissimo in mente il significato di probabilitÃ  condizionata e la regola di naive Bayes in seguito.\nBayes ad alto livello ðŸŸ© Da un punto di vista intuitivo non Ã¨ altro che predire la cosa che abbiamo visto piÃ¹ spesso in quello spazio Assunzioni principali per naÃ¯ve Bayes ðŸŸ© I sample di input sono condizionalmente indipendenti uno con l\u0026rsquo;altro. Questo permette di utilizzare questa ipotesi $$ P(X_{1}\\dots X_{n} | Y = y_{i}) = \\prod_{i}^{n} P(X_{i} | Y) $$ E permette di rendere la parte di inferenza anche molto semplice perchÃ© per classificare un caso basta prendere label con la probabilitÃ  maggiore.","title":"NaÃ¯ve Bayes"},{"content":"Ripasso Prox: 36 Ultima modifica: December 29, 2022 3:24 PM Primo Abbozzo: June 30, 2022 2:38 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso September 10, 2022\nMi sono scordato gli stati possibili. Quasi niente sulla ricerca per algoritmi non deterministici e non osservabili. 2 Problemi di ricerca In questa prima parte si tratta di ricerca semplice, ossia si utilizza un modello basato su obiettivi, di struttura atomica, in un ambiente che risulti singolo-agente, episodico, totalmente osservabile, deterministico, statico, discreto, conosciuto.\n2.1 Il problema Vogliamo cercare di enunciare in un modo che possa essere formale, senza nessuna ambiguitÃ  il concetto di problema di ricerca.\n2.1.1 Framework di soluzione Individuiamo 4 fasi principali per un problema di ricerca, questo Ã¨ un framework molto generico.\nFormulazione dell\u0026rsquo;obiettivo (si cerca di individuare l\u0026rsquo;obiettivo della nostra ricerca). Individuazione del problema (in cui si va a trascrivere il problema utilizzando una impostazione formale, solitamente astraendo dettagli non interessanti, il formato Ã¨ descritto subito dopo nella sezione articolazione) Ricerca della soluzione (in cui si cerca una effettiva soluzione per il problema di ricerca, probabilmente Ã¨ la parte piÃ¹ dispendiosa di algoritmica). esecuzione della soluzione (in cui gli attuatori eseguino la soluzione del problema trovato) 2.1.2 Articolazione Vogliamo cercare di formalizzare il problema di ricerca nel modo piÃ¹ chiaro possibile, lo facciamo separando le funzioni e dati necessari per definire tutti gli aspetti di un problema di ricerca:\nStati possibili Stato iniziale Stati obiettivo Funzione di azioni (da quale stato posso muovermi a quale stato) Funzione di costo (il movimento da questo stato a quello quanto mi costa ?) Funzione di transizione (mi muovo da uno stato all\u0026rsquo;altro) 2.1.3 Problemi standarizzati e reali Questi problemi sono standarizzati proprio perchÃ© rappresentano un modello su cui comparare altre soluzioni che verranno in seguito sviluppate. Sono un cardine per vedere l\u0026rsquo;efficienza di una propria soluzione, e simili.\nInvece i problemi reali possono avere una formulazione vaga, che cioÃ¨ Ã¨ dipendente dal contesto, o comunque da ciÃ² che sia necessario al momento.\nEsempi di standard problems:\n15/8 tile problem Knuth factorial problem (partendo da 4, e applicando fattoriale e radici, si puÃ² fare qualunque numero) Esempi problemi reali\nTravelling salesman Chip VSLI 2.2 Note generali 2.2.1 Percorsi ridondanti Possiamo andare a definire un percorso ridondante, ogni percorso per cui se togli una tappa, il costo Ã¨ minore (ricordiamo che in questo libro parliamo sempre di percorsi con un peso positivo), quindi ridondanti sono cicli, o percorsi con qualche tappa in piÃ¹. Si puÃ² considerare come se fosse un concetto piÃ¹ generale di ciclo questo.\nOvviare alle ridondanze\nNon vogliamo trovare percorsi che siano alla fine ridondati, vogliamo in qualche modo ricordare il nostro percorso:\nAvere una tavola che ci dica se abbiamo giÃ  fatto quel percorso o meno Avere una struttura, o formulazione del problema che non abbia questo problema di ridondanze (ad esempio una ricerca tipo-albero) Ovviare solo ai cicli, e non alle ridondanze in generale, come vi adi mezzo. 2.2.2 Valutazione dell\u0026rsquo;algoritmo In generale si valuta l\u0026rsquo;algoritmo secondo le risorse utilizzate, nel caso della ricerca in AI potrebbe essere il costo in soldi e in carburante, oltre alla classica memoria e tempo. Si propongono quindi 4 valori su cui valutare ciÃ²:\nCompletezza (se esiste una soluzione perfetta la trovo sempre? Se non esiste so che non c\u0026rsquo;Ã¨?) OttimalitÃ  del costo della soluzione (es soldi etc). Costo in tempo Costo in memoria Di particolare interesse sarebbe valutare la completezza dell\u0026rsquo;algoritmo.\n2.3 Algoritmi disinformati Pseudocodice best-first-search\n2.3.1 PerchÃ© sono disinformati Chiamiamo questi algoritmi come disinformati perchÃ© non hanno idea di come Ã¨ fatta la struttura del campo di ricerca.\nIn pratica cercano con informazioni fortemente limitate sulla topologia del proprio ambiente.\nDirei che vadano a cercare valutando solamente il costo, o indiscretamente nodi quasi casuali dellâ€™ambiente circostante.\n2.3.2 Carrellata di algos Non mi Ã¨ piaciuto molto questa parte, perchÃ© la maggior parte degli algoritmi esposti Ã¨ presente nel corso di Algoritmi e Strutture fanno all\u0026rsquo;uni.\nBFS DFS Dept-limited dfs Dijkstra/uniform-cost-search Iterative deepening 2.4 Algoritmi informati Questi algoritmi informati sono molto piÃ¹ interessanti rispetto agli algoritmi scorsi, per cui ne diamo piÃ¹ larga discussione\nIl fatto che siano informati ci sta a significare soltanto che utilizzano un euristica per decidere meglio in che modo espandersi.\n2.4.1 Euristiche Bisogna cercare di definire in modo migliore le caratteristiche che ci potrebbero interessare delle euristiche: euristica ammissibile significa che la funzione di euristica Ã¨ sempre minore del costo effettivo.\nConsistente invece Ã¨ in pratica soltanto una forma della disuguaglianza triangolare.\nTrovare un euristica Ã¨ come risolvere una versione piÃ¹ rilassata del problema, questa Ã¨ una delle osservazioni fondamentali per quando si va a trattare di euristiche.\nAltre soluzioni possibili sono Landmarks e pattern databases di cui rispettivamente i primi sono dei punti cardine, in cui si calcola tutto passando prima di quelli (come se mi chiedessi tipo: quanto ci metto se per andare da A a C, passo prima per il landmark B?) prima si calcolano questi landmark e si prendono decisioni in funzione di quanto mi danno ciÃ².\nI pattern databases sono solamente un modo per cercare soluzioni giÃ  precomputate di pattern che ci sono solito. Si Ã¨ utilizzato un pattern database per 8-puzzle e funzionava distintamente bene.\nContours\nCome se fossero dei piano di livello di una montagna, anche per dijkstra si potrebbe disegnare un contour, ci indica in pratica in modo semplice in che modo si sta espandendo lâ€™algoritmo di ricerca.\n2.4.2 Carrellata algoritmi informati quella piÃ¹ bella, usata in tutte le salse Ã¨ lâ€™algoritmo di A* Search, che in pratica Ã¨ un uniform cost search, che invece di utilizzare solamente la funzione costo g(n) che rappresenta quanto effettivamente si paga per raggiungere il nodo n, tiene in considerazione anche una funzione h(n) che cerca di stimare il costo da n a un goal.\nUna variante studiata Ã¨ il greedy-first-search che praticamente tiene in conto solamente dellâ€™euristica, senza la funzione di costo.\nAltre varianti come WEIGHTED A* search applicano un fattore di peso sullâ€™euristica, spesso rendendola non ammissibile o perfino inconsistente (non ho capito bene in che modo lâ€™ammissibilitÃ  e la consistenza modificano le caratteristiche dellâ€™euristica).\nTecniche che tengono molto in conto la memoria\nAltre studiate possono essere la RBFS (Recursive best first search, che Ã¨ simile a un MINIMAX con pruning, ma singolo agente, in pratica si espande sempre il nodo migliore, tenendo in conto il secondo valore migliore tra questi vicini, io continuo ad esplorare in profonditÃ  finchÃ© non mi converrebbe di piÃ¹ cominciare ad esplorare qualcosa a un livello molto meno profondo).\nOppure la SMA* la simple memory A star, che in pratica tiene in considerazione un numero massimo di nodi in memoria, se nel momento in cui va ad espandere lo ha finito, rimuove il nodo piÃ¹ vecchio, tenendo perÃ² un informazione riguardo quando costava esplorare quella via. (questo comunque puÃ² condurre a problemi simili al thrashing, in cui continua a switchare percorsi, restando cosÃ¬ quasi bloccato).\nBEAM SEARCH va in modo molto focalizzato verso una direzione sviluppando solamente i primi k nodi migliori sulla frontiera, invece A* si sviluppa nel suo territorio (quindi ++ sui contorni)\n2.5 Interesse stato finale In questi problemi non ci importa piÃ¹ di avere un percorso che ci porta alla soluzione, ma solamente la soluzione stessa. Non ci conviene piÃ¹ utilizzare gli algoritmi di ricerca presentati al capitolo precedente in Problemi di ricerca. Quindi si sono sviluppati algoritmi che si comportassero bene per massimizzare anche gli obiettivi di questi.\nTermini importanti per parlare di questi ambienti:\nMassimo locale Ridge (che rende algoritmi greedy molto difficili da essere efficienti) Plateau, parti piatte 2.5.1 Hill Climbing Hill Climb in breve (pseudoalgo)\nQuesto Ã¨ uno degli algoritmi piÃ¹ semplici per quanto riguarda la ricerca in questi ambienti, lâ€™idea principale Ã¨ scegliere il migliore fra i propri successori, e seguire quella strada finchÃ© si puÃ² migliorare.\nIl problema principale Ã¨ che questa versione semplice di Hill Climbing si blocca molto facilmente su minimi locali, o piani. Poi lâ€™ambiente di Ridge Ã¨ una cosa di difficilissima navigazione.\nQuindi si sono inventati variazioni che tentavano di risolvere questo problema:\nRandom restart, ricominciare da un punto random, prendendo alla fine la migliore fra tutte Local beam search, in cui si tengono ogni step i k migliori successori fra i k punti iniziali. Stochastic local beam search in cui randomicamente si considerano alcuni nodi anche lontani rispetto a questi, per cercare di sfavorire il fatto che tutti i punti migliori si ammassino su uno stesso punto. Stochastic hill climbing, in cui in cui si seleziona un punto a caso, e lo si segue sempre se Ã¨ migliore, e solo a volte se Ã¨ peggiore Simulated Annealing in cui la probabilitÃ  di scegliere il punto peggiore dallâ€™altra parte scende col tempo, con una funzione che decade esponenzialmente. 2.5.2 Algoritmi genetici Pseudoalgo\nLe caratteristiche generali di un algoritmo genetico sono in breve queste:\nDimensione della popolazione Rappresentazione della stringa genetica in caratteristiche della popolazione Funzione scelta dei n elementi piÃ¹ adatti tra la popolazione Generazione di un figlio da coppie, o singola persona, o anche piÃ¹ persone di queste. (crossover) Mutazione randomica di caratteri cosÃ¬ generati Elitismo o abbattimento di individui non adatti (a volte aiuta a velocizzare il processo). Ripetizione di ciÃ² fino a tempo finito o caratteristiche cercate trovate. La differenza principale con lo stochastic local beam search Ã¨ il momento di generazione di un nodo successore, che in questo caso, in quanto giustificato dalla biologica, o almeno da una forma contorta di biologia perchÃ© io personalmente credo che sia una forma eccessivamente semplificata, nonostante riconosco che Ã¨ un buon punto di partenza) Ã¨ generata da una ricombinazione di piÃ¹ individui.\nSCHEMAS\nSi Ã¨ notato nel tempo (e lo si Ã¨ anche dimostrato) che gli algoritmi genetici hanno un senso solo se pattern vicini codificano informazioni importanti cioÃ¨ se i caratteri vicini non hanno nessuna relazione, Ã¨ totalmente inutile utilizzare un algoritmo genetico.\nPoi si Ã¨ notato che se un pattern specifico aiuta il progenito a sopravvivere, effettivamente Ã¨ probabile che si mandi alla generazione successiva. Ciononostante Ã¨ doveroso tenere a mente che non tutti i pattern necessari vengono trasferiti, e non tutti i pattern inutili vengono eliminati, leggere lâ€™approfondimento in biologia a pagina 136 dellâ€™edizione cartacea che possiedi.\n2.5.3 In ambienti continui Se lâ€™ambiente Ã¨ continuo, Ã¨ di gran lunga di piÃ¹ di interesse matematico. Si puÃ² vedere come un problema di calcolo numerico nella ricerca di un punto di minimo come il Newton-Raphson-method, che si puÃ² estendere anche a piÃ¹ dimensioni.\nOppure si puÃ² vedere come un problema di ottimizzazione-constrained, che si puÃ² risolvere con programmazione lineare, cose che riguardano analisi di superfici convesse. In pratica idee e cose altamente tecniche che non conosco ancora.\nLâ€™idea principale di questa parte comunque resta il fatto che si puÃ² discretizzare lâ€™ambiente continuo, o cercando di aggiornarlo con passi piccoli, delta alla volta, in ogni direzione, o campionando lo spazio, dividendolo in tanti quadrettini lunghi delta, alla fine credo che questi approcci siano equivalenti.\n2.6 non-deterministiche e not-fully observable Introduciamo ora il concetto di belief state ossia una rappresentazione interna degli stati possibili dellâ€™ambiente. Per gli algoritmi presentati in Problemi di ricerca ogni singolo stato esterno corrispondeva lo stato di belief state interno, ossia câ€™era una corrispondenza, invece in questo caso andiamo a rilassare questo assunto, il determinismo, ossia il fatto che a una singola azione vada a corrispondere un singolo stato, ossia andiamo a dire che a singola azione, possono risultare una serie di stati differenti, maggiori di 1.\n2.6.1 And-Or tree (non-det) Con la possibilitÃ  di avere piÃ¹ stati a seguito di una singola azione cerchiamo di dividere cose che sono sotto il controllo dellâ€™agente e cosa non lo Ã¨\nOR-node, Ã¨ una cosa che dipende dallâ€™azione dellâ€™agente AND-node, Ã¨ una cosa che dipende dalla reazione dellâ€™ambiente in seguito ad azioni dellâ€™agente. Avendo questi due tipologie di nodi, possiamo andare a rappresentare lâ€™intero ambiente attraverso un albero, per cui si possono utilizzare gli algoritmi di trasverse di alberi per trovare una soluzione che ora chiamiamo piano condizionale in quanto sarÃ  constituito da un array di azioni, nel caso si Ã¨ andato su un or-node, oppure di if-then, nel caso si stia andando avanti per un and-node.\nNota: soluzioni cicliche\nA volte converrebbe cercare di ragionare sui motivi della non-determinatezza perchÃ© in questo modo sappiamo se una soluzione ciclica, ossia una soluzione che ha per foglie solamente un obiettivo, ma nel suo percorso puÃ² avere anche delle foglie che vadano in loop, sia effettivamente una soluzione: ossia il non-raggiungimento sia dovuto al caso, oppure a una sistematicitÃ  dellâ€™ambiente in cui si Ã¨ presenti.\n2.6.2 OsservabilitÃ  parziale Un aspetto che colpisce Ã¨ che in ambienti in cui lâ€™osservabilitÃ  Ã¨ parziale, si possono ricavare delle informazioni semplicemente muovendosi, non per forza stando ad osservare lâ€™ambiente! diciamo in questo caso che lo stato Ã¨ coerced\nPer ricondurci da tale ambiente a un problema di ricerca trattato in Problemi di ricerca, possiamo fare una cosa molto simile a quanto Ã¨ fatto per Non-deterministic automata convertito a deterministic automata, ossia si ha una esplosione esplonenziale, ma comunque ben definita degli stati e delle funzioni di transizione che li legano.\nRicerca incrementale\nA volte conviene, invece di esplorare tutto insieme, come fa il non-determinismo, causando computazioni impraticabili, di provare a cercare una soluzione in via incrementale, buildando prima una soluzione che funzioni per un nodo, poi per il secondo, cambiando leggermente la soluzione trovata, e poi via.\nSi ha il risultato di trovare una soluzione o una assenza di essa in modo molto veloce.\n2.6.3 Percezione nellâ€™osservabilitÃ  parziale Essendo un ambiente parzialmente osservabile, possiamo dare per scontato che esista una funzione Perceipt(state) che restituisce un insieme di stati osservati. Questa Ã¨ una funzione stretttamente legata allâ€™ambiente in cui agisce lâ€™agente.\nAllora in un ambiente non-deterministico ad osservabilitÃ  parziale dovremmo approfondire la funzione di transizione, che non si puÃ² considerare piÃ¹ lâ€™unione o lâ€™intersezione dellâ€™azione che viene applicata a tutti gli stati, ma qualcosa di meno perchÃ© deve prendere in conto anche la percezione (ad ogni azione corrisponde uno stato che corrisponde subito una percezione).\nLa dividiamo in 3 parti\nPredizione di quello che succede se applico lâ€™azione a (ritorna un insieme di stati possiibili) Percezioni possibili lista delle percezioni possibili per tutti gli stati raggiunti. Aggiornamento degli stati di belief a un sottoinsieme a seconda degli stati raggiunti e delle percezioni possibili. In questo modo si forma sempre un albero di ricerca, di azioni non-deterministiche.\n2.6.4 Ricerca online La ricerca online ci fa avvicinare a come sia lâ€™esplorazione in un mondo vero, in pratica ora lo stato del mondo Ã¨ dinamico, e dipende dalla presenza fisica dellâ€™agente osservatore che non puÃ² piÃ¹ saltare da un nodo o un altro, oltre al fatto che lo stato puÃ² cambiare anche se non sta facendo niente. (câ€™Ã¨ un problema riguardo punti di non ritorno, in cui le azioni sono irreversibili, ma questo lo tratteremo in capitolo seguenti).\nPseudocodice per DFS-online\nLa cosa stupida di questo algoritmo Ã¨ che non conosce le azioni che puÃ² fare in un determinato stato, e potrebbe ripetere azioni che si cancellano fra di loro (es. UP e DOWN uno di seguito allâ€™altro). Le azioni qui dipendono dallo stato in cui si Ã¨ presenti!\nHill Climbing online (LRTA)*\nUn osservazione che si Ã¨ fatto con la DFS Ã¨ che ora si ha un oggetto fisico che si sposta, e non puÃ² fare voli dallâ€™altra parte del labirinto per vedere come si sviluppa quel nodo di ricerca, per questo motivo possiamo affermare che câ€™Ã¨ bisogno di un algoritmo di ricerca locale, questo era HILL CLIMBING!\nMa avevamo discusso in precedenza che si poteva bloccare molto facilmente questo algoritmo! Ma non possiamo piÃ¹ utilizzare random restart, dato che non esiste il teletrasporto, allora utilizziamo il random walk, in modo randomico scegli una direzione e la esplori.\nQuesta cosa adattata con anche una euristica che ti direzioni verso la parte giusta diventa un LRTA\nPseudocodice Learning RealTime A*\nIn pratica riaggiorna lâ€™euristica del costo a seconda delle proprie mosse.\n","permalink":"https://flecart.github.io/notes/problemi-di-ricerca/","summary":"Ripasso Prox: 36 Ultima modifica: December 29, 2022 3:24 PM Primo Abbozzo: June 30, 2022 2:38 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso September 10, 2022\nMi sono scordato gli stati possibili. Quasi niente sulla ricerca per algoritmi non deterministici e non osservabili. 2 Problemi di ricerca In questa prima parte si tratta di ricerca semplice, ossia si utilizza un modello basato su obiettivi, di struttura atomica, in un ambiente che risulti singolo-agente, episodico, totalmente osservabile, deterministico, statico, discreto, conosciuto.","title":"Problemi di ricerca"},{"content":"Ripasso Prox: 45 Ripasso: May 29, 2023 Ultima modifica: April 29, 2023 11:27 AM Primo Abbozzo: March 8, 2023 9:55 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Processi e thread Il processo e la gestione dell\u0026rsquo;esecuzione Ã¨ uno dei compiti principali dei sistemi operativi. Lo vuole fare in maniera efficace ed efficiente, come descritto in Note sullâ€™architettura.\nSlide schema generale tabelle\nProcessi Il process control block Ã¨ la struttura di dati principali da comprendere.\nHa una tabella dei file aperti, che sono dei file descriptor (all\u0026rsquo;interno della propria struttura di dati), riferiti a una tabella dell\u0026rsquo;interno sistema credo, e questi puntano a un VNode che permette di localizzarlo nella memoria secondaria.\nDescrittori di processi (4) ðŸŸ© Ãˆ anche un aspetto dei descrittori dei processi.\nSlide descrittori\nHo bisogno del codice segment code\nUno stack su cui lavorare, quindi memorizzare le cose temporanee\nsegment data per i dati necessari\nIl PCB per gli attributi necessari per disattivare attivare, o comunque descrive tutto il processo.\nIl PCB (3) ðŸŸ¨â€” Qui si parlano di attributi mantenuti nel PCB, sono di fondamentale importanza per il context switch, descritto in Scheduler\ninformazioni di identificazione di processo informazioni di stato del processo informazioni di controllo del processo Sono queste le informazioni principali mantenute.\nIdentificazione del processo\nindice nella tabella dei processi (problema di reincarnazione, se ho un nuovo processo al posto di uno che Ã¨ stato chiuso, allora non potrei riattivare un processo col vecchio pid), cosÃ¬ magari tutte le reference vecchie restano, con lâ€™indice non riesco a farlo, potrebbe essere stato sostituito! numero progressivo che sarebbe il PID, che viene mappato al relativo descrittore, possiamo dire che il PID Ã¨ un identificatore logico! Che poi viene risolto al descrittore vero. Altre identificazioi come utente, gruppo, pid del padre, in modo che possa controllare l\u0026rsquo;accesso e le limitazioni del processo.\nInformazioni di stato del processo\nHo la necessitÃ  di avvicendare i processi, quindi ho bisogno di qualcosa per fermare e riattivare i processi, questa sezione di informazione Ã¨ utile per questa parte.\nÃˆ importante che questi valori sono presenti i valori dellâ€™ultimo salvataggio perchÃ© salvo solo quando devo switchare, se sto runnando non ha senso che utilizzi queste cose.\nContenuto dei registri, normali e speciali (questi vengono persi quando facciamo switch), si potrebbe chiamare come se fosse una istantanea dei registri. La memoria in RAM Ã¨ meglio mantenerla, quindi non andiamo a ricordarlo. informazioni di controllo del processo\nUna lista enorme di cose per il controllo, cioÃ¨ in questa parte câ€™Ã¨ tanta roba!\nScheduling (forse piÃ¹ importante come prioritÃ , tempo di esecuzione etc). Gestione memoria, MMU. Risorse utilizzate (quindi accounting delle risorse) Comunicazione con altri processi. Slides\nStati dei processi (3) ðŸŸ© Possiamo generalizzare lo stato del processo come se avesse principalmente 3 stati:\nRunning, il programma sta runnando senza problemi Waiting, il processo non puÃ² essere eseguito perchÃ© sta aspettando qualcosa, es. un I/O Ready, il processo non Ã¨ eseguito, ma puÃ² essere continuato quando la CPU ha tempo per dedicare ancora tempo a questo. Slide stati processi\nLa cosa carina che sembra essere descrivibile dallo schemini simili agli automi Grammatiche Regolari.\nSolitamente per gestire tutto l\u0026rsquo;insieme dei processi ready, lo si mette in una coda ready, ma esistono anche altre code come disk queue, terminal queue.\nGerarchie di processi ðŸŸ© Ãˆ molto facile fare cose a sua immagine e somiglianza, ci sono molti campi in cui basta fare una copia, e ho la maggior parte delle informazioni che mi interessano.\nSpecifico solo quello che cambio. Questo rende molto facile creare nuovi processi, basta cambiare ciÃ² che Ã¨ diverso!\nSistema gerarchico UNIX\nBound sui processi (2) ðŸŸ© Si puÃ² dire che un processo sia CPU bound, I/O bound, queste sono le cose che interessano poi allo Scheduler per decidere cosa fare.\nil primo, CPU, quando fa calcoli che sono molto lunghi.\nIl secondo I/O, quando fa richieste IO che prendono molto tempo.\nIn generale i processi si possono descrivere come in alternanza continua fra CPU use e richieste IO.\nSlide descrizione bounds processi\nEsempio di CPU e IO bound\nThreads Il processo Ã¨ il titolare delle risorse di elaborazione ma puÃ² eseguire solamente una cosa alla volta. Con i thread possiamo dividere il processo in piÃ¹ linee esecutive che condividono delle risorse.\nQuesta Ã¨ una cosa molto comoda, per esempio quando ho un browser ho bisogno di un altro thread per scaricare in modo contemporaneo piÃ¹ file. Sono piÃ¹ linee di controllo. ma piÃ¹ vantaggioso rispetto a fare processi separati, perchÃ© mi permette la piÃ¹ facile condivisione di risorse. (dovrei mettermi a mandare messaggi anche per cose banali, quindi anche leggero overhead, per copiare molte informazioni Message Passing).\nVantaggi sui processi ðŸŸ©- Condivisione di memoria facile Molto piÃ¹ facile fare context switch di thread che di processi. (puÃ² essere un ordine di grandezza piÃ¹ veloce) FacilitÃ  di scrittura del codice, rispetto a message passing e piÃ¹ processi. I lati negativi sono:\nMolti descrittori Molti context switch Quindi utilizzo leggermente piÃ¹ risorse con i thread.\nInformazioni dei thread (2) ðŸŸ¨â€” ha informazioni parziali rispetto al processo, con cui condividono un sacco di cose, come dati, I/O, e il codice del programma.\nStack separato. Program counter proprio, dato che voglio una storia esecutiva indipendente. (e quindi anche propria copia dei registri). In questo modo sposto il livello di running e waiting al singolo thread.\nKernel e user thread Questo la saltato boh\nPerÃ² ora sono tutte livello kernel e user non viene piÃ¹ utilizzato.\nLa differenza sta nel fatto se il kernel sia a conoscenza o meno dellâ€™esistenza dei threads (se Ã¨ a consocenza per esempio ci puÃ² fare scheduling, mentre altrimenti no, perÃ² se ne Ã¨ a conoscenza deve tutto essere gestito dal kernel, questo in qualche modo rende molto piÃ¹ pesante la gestione).\nRelation threads Anche questi sono stati saltati\n","permalink":"https://flecart.github.io/notes/processi-e-thread/","summary":"Ripasso Prox: 45 Ripasso: May 29, 2023 Ultima modifica: April 29, 2023 11:27 AM Primo Abbozzo: March 8, 2023 9:55 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Processi e thread Il processo e la gestione dell\u0026rsquo;esecuzione Ã¨ uno dei compiti principali dei sistemi operativi. Lo vuole fare in maniera efficace ed efficiente, come descritto in Note sullâ€™architettura.\nSlide schema generale tabelle\nProcessi Il process control block Ã¨ la struttura di dati principali da comprendere.","title":"Processi e thread"},{"content":"Ultima modifica: February 16, 2023 1:26 PM Primo Abbozzo: February 16, 2023 12:57 PM\nIntroduzione ai RNN Vorremmo costruire un modello che fosse in grado di predire delle cose che dipendono da vecchie sequenze (quindi un network che abbia in un qualche senso la memoria di un coso passato).\nRiassunto in slide Formalizzazione del network Stato interno La differenza principale col percettrone Ã¨ la presenza di uno stato interno nascosto, che continua a trasformarsi a seconda degli input, lo chiamiamo interno perchÃ© non Ã¨ dato in output, ma viene se\n!\nSchema classico di update dello stato interno\nIn pratica Ã¨ come se ad ogni step ci siano due output: 1. la nostra predizione, uno lâ€™update del nostro stato interno.\nFunzionamento classico !\nSolitamente lo codifichiamo in modo molto semplice cosÃ¬:\n$$ h_{t} = g(Uh_{t-1} + Wx_{t}) $$ $$ y_{t} = f(Vh_{t}) $$ Dove $U, V, W$ sono matrici di pesi allenabili, e $g, f$ sono funzioni di attivazione (questo Ã¨ leggermente diverso rispetto a quanto in figura qui)\nCodice classico per RNN Cell state:Â The cell state is a vector that is maintained by the LSTM cell and is used to store information over time. Gates:Â LSTMs use three gates to control the flow of information into and out of the cell state: Forget gate:Â The forget gate determines which information from the previous cell state to discard. Input gate:Â The input gate determines which new information to add to the cell state. Output gate:Â The output gate determines which information from the cell state to output. Backpropagation through time (BPTT):Â LSTMs use a variant of BPTT called truncated BPTT to train the network. BPTT is a technique for training recurrent neural networks by unrolling the network through time and calculating the gradients of the loss function with respect to the parameters of the network. Truncated BPTT is a simplified version of BPTT that is more computationally efficient. Training a RNN Questo Ã¨ piÃ¹ o meno il pseudocodice per lâ€™update della RNN\nFar andare per t timestamps, e trovare un loss generale. Utilizzare questo per fare backpropagation. Schematizzazione della backpropagation sul tempo\n!\nTODO: problemi sui gradienti e Long-termi dependence.\nVanishing gradient problem Per exploding gradients la cosa bella Ã¨ una soluzione veloce, come fare gradient clipping (che non so che cazzo sia)\nPer vanishing gradient ho molte piÃ¹ soluzioni possibili\nActivation function Weight initialization Custom gate cells Una cosa buona (quindi tipida di questo RNN sono le gated cells, che riescono a controllare molto meglio il flow dellâ€™informazione).\nProprietÃ  di LSTM\n!\nWord embeddings One-hot embedding\nQuando ho un array tipo di 10k, e il valore di una parola Ã¨ [0, 0â€¦., 1, 0,â€¦ 0] con 1 il suo index giusto.\nLearned embedding\nQuando lasciamo una NN a capire come fare un encoding delle parole, in modo che parole simili abbiano una distanza minore, anche se sarebbe molto meglio avere qualcosa di pratico per sta roba ðŸ˜€\nLimitations of RNN Encoding delle informazioni (che ci potrebbero far perdere certe informazioni molto carine a riguardo) Lentissimo! Non riesco a parallelizzare questa computazione, dato che uno dipende dallâ€™altro! Alla fine non riesco proprio a fare long term memory. ","permalink":"https://flecart.github.io/notes/recurrent-neural-networks/","summary":"Ultima modifica: February 16, 2023 1:26 PM Primo Abbozzo: February 16, 2023 12:57 PM\nIntroduzione ai RNN Vorremmo costruire un modello che fosse in grado di predire delle cose che dipendono da vecchie sequenze (quindi un network che abbia in un qualche senso la memoria di un coso passato).\nRiassunto in slide Formalizzazione del network Stato interno La differenza principale col percettrone Ã¨ la presenza di uno stato interno nascosto, che continua a trasformarsi a seconda degli input, lo chiamiamo interno perchÃ© non Ã¨ dato in output, ma viene se","title":"Recurrent Neural Networks"},{"content":"Introduction to the Rice Theorem Ci sono molti teoremi che non possono essere decisi, vedere Halting Theorem and Reducibility. Qui andiamo a chiederci quale sia l\u0026rsquo;insieme dei problemi decidibili.\nProprietÃ  dei linguaggi TM ðŸŸ© Data una macchina $\\mathcal{M}$ definiamo il suo linguaggio come $$ L_{\\mathcal{M}} = \\left\\{ x \\in \\Sigma^{*}: \\mathcal{M} \\text{ accetta } x \\right\\} $$ Allora con questa definizione di linguaggio possiamo dire che una proprietÃ , ossia una funzione da tutti i $TM$ possibili a $\\left\\{ 0, 1 \\right\\}$ tale per cui se il linguaggio riconosciuto Ã¨ lo stesso, ossia $$ L_{\\mathcal{M}} = L_{\\mathcal{M}'} \\implies P(\\mathcal{M}) = P(\\mathcal{M}') $$ Definiamo questa non triviale se esiste una macchina per cui Ã¨ 0, e una per cui Ã¨ 1 (ossia non Ã¨ costante). Practically this definition is useful when we need to have a difference between the language and the Turing machine that decides that language.\nThree properties of Turing Machines ðŸŸ© Language properties (what language does it decide? This property concerns Rice\u0026rsquo;s Theorem) Structural properties (what are constituents of turing machine?) Algorithmic properties (how is computing) It is important to note that only Language properties concerns Rice\u0026rsquo;s Lemma. Enunciato di Rice Se $P$ Ã¨ una proprietÃ  dei linguaggi TM, allora Ã¨ indecidibile il problema \u0026ldquo;$\\mathcal{M}$ ha la proprietÃ  $P$\u0026rdquo;.\nProof of Rice Without loss of generality, we assume that given a $P$ we have that $P(\\mathcal{M}_{\\varnothing}) = 0$. Then, given the fact that the property is not trivial we have that exists a $\\mathcal{M}$ such that $P(\\mathcal{M}) = 1$. Let\u0026rsquo;s procede by contradiction. Assume that $P$ is decidable. Let\u0026rsquo;s proof that $HALT \\leq P$ where $P$ is the language that knows the same stuff. This proves Rice Theorem by mapping reducibility properties.\nL\u0026rsquo;insieme delle funzioni non decidibili Qui andiamo a dimostrare che la stragrande maggioranza dei linguaggi non sono riconoscibili.\nUnione di insiemi numerabili Ã¨ numerabile ðŸŸ© Vedi Descrizione linguaggio#NumerabilitÃ  per alfabeti per costruzione e dimostrazione. Sarebbe buono saperlo fare da solo. L\u0026rsquo;idea Ã¨ avere un parametro che di dice quanto Ã¨ l\u0026rsquo;esponente dell\u0026rsquo;insieme. E poi andare per sorta di ricorsione.\nL\u0026rsquo;insieme delle TM Ã¨ numerabile. ðŸŸ© Basta vedere che l\u0026rsquo;insieme delle TM Ã¨ un sottoinsieme di $A^{*}$, che Ã¨ numerabile. Questo quando usiamo la codifica binaria, quindi $A = \\left\\{ 0, 1 \\right\\}$.\nL\u0026rsquo;insieme dei linguaggi su alfabeto finito non Ã¨ numerabile ðŸŸ© Possiamo rappresentare un linguaggio su un alfabeto con funzioni indicatrici. Avremmo cosÃ¬ una stringa binaria che ci indica o no se una stringa Ã¨ presente nel linguaggio o meno. Allora posso praticamente usare lo stesso argomento usato in diagonalizzazione di Cantor e avere il risultato.\n","permalink":"https://flecart.github.io/notes/teorema-di-rice/","summary":"Introduction to the Rice Theorem Ci sono molti teoremi che non possono essere decisi, vedere Halting Theorem and Reducibility. Qui andiamo a chiederci quale sia l\u0026rsquo;insieme dei problemi decidibili.\nProprietÃ  dei linguaggi TM ðŸŸ© Data una macchina $\\mathcal{M}$ definiamo il suo linguaggio come $$ L_{\\mathcal{M}} = \\left\\{ x \\in \\Sigma^{*}: \\mathcal{M} \\text{ accetta } x \\right\\} $$ Allora con questa definizione di linguaggio possiamo dire che una proprietÃ , ossia una funzione da tutti i $TM$ possibili a $\\left\\{ 0, 1 \\right\\}$ tale per cui se il linguaggio riconosciuto Ã¨ lo stesso, ossia $$ L_{\\mathcal{M}} = L_{\\mathcal{M}'} \\implies P(\\mathcal{M}) = P(\\mathcal{M}') $$ Definiamo questa non triviale se esiste una macchina per cui Ã¨ 0, e una per cui Ã¨ 1 (ossia non Ã¨ costante).","title":"Teorema di Rice"},{"content":"Ripasso Prox: 5 Ripasso: May 25, 2023 Ultima modifica: May 19, 2023 10:13 AM Primo Abbozzo: May 12, 2023 10:32 AM Studi Personali: No\nElementi di ripasso Wifi 802.11 In questo documento andiamo a parlare dello standard effettivo wifi che possiamo andare a trovare nel mercato.\nPrime slides sono delle liste enormi di tecnologie Wifi e dei loro utilizzi, come ad esempio della rete bluetooth, della rete wifi, del wifi ad ampio raggio e della rete 3G.\nOra comunque sono fuori servizio questo\nService sets Basi service set Ci sono verie devisioni sul service set, ognuna delle quali vanno a dare certe tipologie di servizio.\nNel servizio di base abbiamo cose come SSID che Ã¨ il service set identifier che Ã¨ lâ€™identificatore di rete che Ã¨ sparato nel beacon come descritto in Mac Wifi\nIl SSID viene principalmente utilizzato per annunciare la presenza della rete e permettere agli host di connettersi con questo.\nExtended service set ho una ESS quando ho piÃ¹ BSS che collaborano fra di loro per collaborare, fornendo allâ€™utilizzatore l\u0026rsquo;unica interfaccia. Credo che potrebbe essere spiegato in modo semplice come se fosse multiple AP, che sembrano una unica rete.\nAn ESS is typically used to provide wireless coverage over a larger area, such as in a campus or office building, where multiple access points are needed to cover the entire area. The access points within an ESS communicate with each other to provide seamless wireless coverage and allow users to move from one area to another without losing connectivity.\nUna cosa brutta riguardo il SSID Ã¨ il password di default dei produttori (tsunami per esempio per cisco)\nRogue access points â†’ attacchi di reti lasciti accesi.\n","permalink":"https://flecart.github.io/notes/wifi-802-11/","summary":"Ripasso Prox: 5 Ripasso: May 25, 2023 Ultima modifica: May 19, 2023 10:13 AM Primo Abbozzo: May 12, 2023 10:32 AM Studi Personali: No\nElementi di ripasso Wifi 802.11 In questo documento andiamo a parlare dello standard effettivo wifi che possiamo andare a trovare nel mercato.\nPrime slides sono delle liste enormi di tecnologie Wifi e dei loro utilizzi, come ad esempio della rete bluetooth, della rete wifi, del wifi ad ampio raggio e della rete 3G.","title":"Wifi 802-11"},{"content":"Alberi BST e AVL 4.1 Alberi binari di ricerca (BST) Queste sono delle varianti rispetto all\u0026rsquo;albero, descritto in modo molto sommario sopra (binario perchÃ© ogni nodo ha al massimo due figli, mentre l\u0026rsquo;albero puÃ² averne quanti se ne vuole).\n4.1.1 Introduzione La caratteristica principale dell\u0026rsquo;albero di ricerca Ã¨ una condizione sulle chiavi (che hanno i figli).\nInfatti questo albero binario di ricerca si puÃ² vedere come una implementazione della struttura astratta del dizionario. (che ricordiamo, Ã¨ un struttura in cui a ogni nodo sono presenti due valori, una chiave (tute differenti) e un dato, e sono definite tre operazioni principali, possiamo vederla come interfaccia).\nAl massimo due figli per nodo. (albero binario) Il dizionario, quindi che ogni nodo abbia chiave. I figli di sinistra hanno chiavi minori del genitore, a destra maggiore. 4.1.2 Prototipo Possiamo definire alcune operazioni principali per l\u0026rsquo;albero di ricerca:\nLe tre standard che sono presenti per il dizionario. (search, insert e delete) Max e Min. Predecessor e successor Saltiamo le note di implementazione di questi algoritmi :D perchÃ© sono giÃ  triti e ritriti.\nUna nota su predecessor:\nPer l\u0026rsquo;operazione di delete abbiamo solamente considerato il caso di predecessor quando il nodo da considerare possedeva il figlio giusto.\nMa Ã¨ possibile che non lo abbia, allora Ã¨ molto simile, ma opposto (invece di scendere continuamente a destra, salgo continuamente a sinistra, con continuamente nel senso finchÃ© c\u0026rsquo;Ã¨ ancora il nodo).\n4.2 Alberi AVL Questi sono alberi AVL (il cui nome deriva dal nome dei creatori, come RSA), alberi bilanciati secondo l\u0026rsquo;altezza dei sottonodi. La cosa buona Ã¨ che avendo i bilanciamenti abbiamo un altezza logaritmica. in particolare possiamo dire che questi siano autobilancianti.\nIntroduciamo ora alcuni concetti importanti per comprendere il bilanciamento\n4.2.1 il concetto di bilanciamento Il fattore di bilanciamento\nCerchiamo di considerare un fattore di bilanciamento che si ottiene con\ncon h una funzione che mi ritorna l\u0026rsquo;altezza. (da notare che Ã¨ l\u0026rsquo;altezza, non la funzione).\nE l\u0026rsquo;altezza parte da 0\n$$ \\beta = fattore\\_bilanciamento = h(sinistra) - h(destra) $$ Bilanciato in altezza\nConsideriamo un albero bilanciato in altezza se $|\\beta| \\leq 1$\n4.2.2 Altezza di un albero di fibonacci L\u0026rsquo;albero di fibonacci Ã¨ molto interessante da studiare dal punto di vista dell\u0026rsquo;altezza, infatti possiede il massimo sbilanciamento possibile\nIntuizione dell\u0026rsquo;albero (dalla costruzione puoi dimostrare la sua altezza in modo intuitiva)\nNumero di nodi nell\u0026rsquo;albero di fibonacci\nConclusione sull\u0026rsquo;altezza\n4.2.3 Operazioni elementari (rotazione e altezza) Altezza\nPossiamo definire un algoritmo per definire il fattore di bilanciamento e l\u0026rsquo;altezza di un sotto-albero (da sapere bene, fare attenzione ai casi null)\nAlgoritmo (fattore bilanciamento e update altezza di un nodo)\nOperazione di rotazione\nUna rotazione Ã¨ una operazione elementare di su un albero che mi riposiziona alcuni figli e genitori di un nodo.\nEsempi di rotazione semplice\nPseudocodice della rotazione\n4.2.4 Risoluzione degli sbilanciamenti Possiamo catalogare le possibili tipologie di sbilanciamento in 2 macrogruppi di 2 (sono simmetrici destra e sinistra), questi saranno risolvibili tramite rotazioni, che, come vedremo, hanno la proprietÃ  di diminuire l\u0026rsquo;altezza del nodo di rotazione di 1.\nTipi di sbilanciamento\nSbilanciamento di tipo SS (simmetrico DD)\nSbilanciamento di tipo DS\nPseudocodice per risolvere sbilanciamento\n4.2.5 Note su inserimento e rimozione Queste due operazioni sono le uniche che possono cambiare il bilanciamento dell\u0026rsquo;albero.\nSi puÃ² dimostrare che l\u0026rsquo;inserimento sbilancia al massimo un nodo, per cui una unica rotazione Ã¨ sufficiente per il tutto.\nMentre la rimozione puÃ² sbilanciare tutto il percorso fino la radice come questa operazione:\nEsempio\n","permalink":"https://flecart.github.io/notes/alberi-bst-e-avl/","summary":"Alberi BST e AVL 4.1 Alberi binari di ricerca (BST) Queste sono delle varianti rispetto all\u0026rsquo;albero, descritto in modo molto sommario sopra (binario perchÃ© ogni nodo ha al massimo due figli, mentre l\u0026rsquo;albero puÃ² averne quanti se ne vuole).\n4.1.1 Introduzione La caratteristica principale dell\u0026rsquo;albero di ricerca Ã¨ una condizione sulle chiavi (che hanno i figli).\nInfatti questo albero binario di ricerca si puÃ² vedere come una implementazione della struttura astratta del dizionario.","title":"Alberi BST e AVL"},{"content":"In questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders Blog di riferimento Blog secondario che sembra buono\nIntroduzione agli autoencoders L\u0026rsquo;idea degli autoencoders Ã¨ rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso Ã¨ la compressione con loss. Per cosa intendiamo qualunque tipologia di dato, che puÃ² spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder. Una volta scelta una tipologia di dato, come per gli algoritmi di compressione, valutiamo come buono il modello che riesce a comprimere in modo efficiente e decomprimere in modo fedele rispetto all\u0026rsquo;originale. Abbiamo quindi un trade-off fra spazio latente, che Ã¨ lo spazio in cui sono presenti gli elementi compressi, e la qualitÃ  della ricostruzione. Possiamo infatti osservare che se spazio latente = spazio originale, loss di ricostruzione = 0 perchÃ© basta imparare l\u0026rsquo;identitÃ . In questo senso si puÃ² dire che diventa sensato solo quando lo spazio originale sia minore di qualche fattore rispetto all\u0026rsquo;originale. Quando si ha questo, abbiamo piÃ¹ difficoltÃ  di ricostruzione, e c\u0026rsquo;Ã¨ una leggera perdita in questo senso.\nProprietÃ  interessanti Vogliamo in un certo senso imporre una regolaritÃ  nello spazio latente perchÃ© questo ci permette di esprimere in un modo piÃ¹ coerente da quanto ci attendiamo le cose dello spazio:\nSe prendiamo un punto vicino a un encoding noto, ci aspettiamo che sia simile al punto stesso Se prendiamo un punto del nostro spazio latente ci aspettiamo che dia qualcosa di sensato Rispettivamente queste proprietÃ  sono state chiamate continuitÃ  e completezza.\nVariational Auto-Encoders Intuizione L\u0026rsquo;idea sembra avere uno spazio regolarizzato, ossia un $z \\sim \\mathcal{N}(\\mu, \\sigma^{2}I)$ con $\\sigma$ vettore di dimensione spazio latente e $\\mu$ degli offset che rappresentano media. Quindi il decoder parametrizzato secondo $\\theta$ dovrÃ  essere in una forma dipendente da questa.\nInsieme a questo utilizziamo anche un encoder parametrizzato con $\\phi$ che dovrÃ  darci indicazioni su $z$, per esempio media e varianza.\nSecondo Murphy-1, Questo dovrebbe essere molto simile a un lavoro di uno 95, vedi capitolo su VAE in que libro.\nLa formulazione dei VAE sembra molto simile ai Factor Analysis. Che Ã¨ una caratterizzazione di un certo tipo sia spazio latente che quello normale.\nSetting del problema In questo senso vogliamo cercare di regolarizzare il nostro spazio latente assumendo che $$ p(x | z) \\sim \\mathrm{N}(media, varianza) $$ Ossia i samples della parte condizionata nello spazio latente non sono altro che una media e varianza dipendenti solo dalla parte condizionale, mentre $p(z) = N(0, 1)$ multidimensionale (quindi varianza $I$)\nELBO e derivazione Se assumiamo questo, allora la loss di Kullback-Leibler diventa abbastanza carina, perchÃ© infatti abbiamo che\n$$ KL(q_{x}(z), p(z|x)) = E_{x \\sim q_{x} }(\\log(q_{x}(z))) - E_{x \\sim q_{x}}\\left(\\log( \\frac{p(x, z)}{p(x)}) \\right) $$ $$ = E_{x \\sim q_{x}}(\\log(q_{x}(z))) - E_{x \\sim q_{x}}(\\log(p(x, z))) + E_{z \\sim q_{x}}(\\log(p(x))) = E_{z \\sim q_{x}}(\\log(p(x))) - E_{z \\sim q_{x}}\\left( \\log\\left( \\frac{p(x, z)}{q_{x}(z)} \\right) \\right) $$ Ora le ultime due si chiamano rispettivamente **evidence** e **ELBO** che sta per Evidence Lower Bound Notiamo che la evidence non dipende da $z$, infatti avremmo che $$ E_{z \\sim q_{x}}(p(x)) = \\int {-\\infty}^{+\\infty} q{x}(z) p(x) , dz = p(x) \\int {-\\infty}^{+\\infty} q{x}(z) dz = p(x) $$ Quindi se vogliamo minimizzare la divergenza, ci basta Massimizzare ELBO nel nostro caso.\nEsplicitazione di ELBO Possiamo lavorare ancora di piÃ¹ su ELBO, provando ad esplicitarne alcuni valori, infatti possiamo considerare\n$$ ELBO = E_{z \\sim q_{x}}\\left( \\log\\left( \\frac{p(x, z)}{q_{x}(z)} \\right) \\right) =E_{z \\sim q_{x}}\\left( \\log\\left( p(x|z) \\right) \\right) + E_{z \\sim q_{x}}\\left( \\log\\left( \\frac{p(z)}{q_{x}(z)} \\right) \\right) $$ $$ = E_{z \\sim q_{x}}\\left( \\log\\left( p(x|z) \\right) \\right) - KL(q_{x}(z), p(z)) $$ Ossia abbiamo il secondo termine che prova a regolarizzare la distribuzione $q$ trovata, e il primo termine che Ã¨ un maximum likelihood, simile a quanto trovato per NaÃ¯ve Bayes nel corso di Asperti. Questo Ã¨ la nostra loss per il VAE.\nOra l\u0026rsquo;ultimo passo sarebbe come esplicitare ELBO in modo che possa essere implementato come loss di una net?\nDerivazione della loss per VAE Vedere qui, Ã¨ calcolosa, ma molto carina, e ti permette di impratichirti con gaussiane multivariabili.\nAlla fine si avrÃ  come risultato:\n$$ KL(q_{x}(z), p(z)) = -\\frac{1}{2} \\sum_{j=1}^{J}(1 + \\log \\sigma^{2}_{j} - \\mu^{2}_{j} - \\sigma^{2}_{j}) $$ Derivazione di KL per la loss Vedere https://mr-easy.github.io/2020-04-16-kl-divergence-between-2-gaussian-distributions/. E poi sostituire. Per l\u0026rsquo;expectation della forma quadratica vedere qui https://statproofbook.github.io/P/mean-qf.html.\nAllora, sappiamo che $p(z) = \\mathcal{N}(0, \\mathcal{I})$ quindi ha una forma ben nota, dovremo cercare di fare questa piccolissima derivazione.\n","permalink":"https://flecart.github.io/notes/autoencoders/","summary":"In questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders Blog di riferimento Blog secondario che sembra buono\nIntroduzione agli autoencoders L\u0026rsquo;idea degli autoencoders Ã¨ rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso Ã¨ la compressione con loss. Per cosa intendiamo qualunque tipologia di dato, che puÃ² spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder.","title":"Autoencoders"},{"content":"Tipologie di control plane La control plane Ã¨ la parte al livello di rete che si occupa di riempire le tabelle di istradamento dei router. In questo caso si possono in generare dividere gli algoritmi in due grandi famiglie\nCentralizzati, anche chiamati algoritmi LS( Link state) perchÃ© devono conoscere in che modo sono collegati i router fra di loro. Solitamente le SDN ossia software defined networking di cui abbiamo parlato in Data Plane utilizzano questi metodi, c\u0026rsquo;Ã¨ un server centralizzato (che per ragioni di tolleranza puÃ² anche essere distribuito, perÃ² diciamo che Ã¨ esterno al router la decisione) Distribuiti in cui nessuno ha informazioni complete sulla rete, ma Ã¨ possibile scambiarsi informazioni sui vicini e congiungere cosÃ¬ al percorso piÃ¹ breve. Vengono in questa sede utilizzati algoritmi di distance vector. Possono anche essere statici, ma dato che la topologia della rete Ã¨ spesso dinamica Ã¨ difficile che vengano utilizzati. Sono molto piÃ¹ preferibili gli algoritmi dinamici che vanno ogni tot ad aggiornare le tabelle.\nSi possono anche differenziare secondo la sensibilitÃ  al carico. Anche se gli algoritmi moderni sono insensibili.\nAlgoritmi per Control Plane Link state e Dijkstra Questa Ã¨ la parte piÃ¹ importante per il prof\nCon grafo indiretto ad archi pesati. questo l\u0026rsquo;abbiamo giÃ  studiato in Cammini, ad algoritmi, ed Ã¨ stato fatto bene.\nNOTA: ci potrebbero essere problemi di oscillazione dei percorsi calcolati se utilizziamo solamente il carico come unica metrica per misurare il peso di un nodo. Attualmente il metodo migliore per evitare questo Ã¨ calcolare il percorso migliore in tempi randomici.\nEsempio di oscillazione dei percorsi\nDistance vectors Non hanno visto Bellman ford e distance vector routing, perÃ² sarebbe carino farle TODO: Autonomous systems Definizione AS Alcuni vorrebbero essere in grado di gestire un blocco di router come vogliono loro, ossia vogliono avere una autonomia amministrativa su un insieme di router. Possiamo quindi dividere tutti i router in delle AS, alcune grandi, di primo livello, piÃ¹ piccole, decide lâ€™ISP in che modo gestirsele. (ad ogni AS Ã¨ associato, sembra, un numero). La cosa importante perÃ² Ã¨ che\nTutti i router all\u0026rsquo;interno di una AS eseguono lo stesso protocollo di instradamento. Intra e inter routing Algoritmi di routing a due livelli diversi (BGP Border Gateway protocol per inter, che non chiede, ma sa che esiste. e altri per Intra.)\nIntra sono algoritmi di routing omogenei.\nInter in cui ci interessa solamente capire in che modo si interfaccia in altri sistemi.\nIn pratica non ha fatto niente di control planeâ€¦\nOpen Shortest Path first (intra) OSPF Ã¨ un algoritmo link state che regola il routing all\u0026rsquo;interno di un sistema autonomo. Per il resto non ci importa sapere altro.\nUtilizza Dijkstra I pesi possono essere messi a mano seguendo certi criteri Minimum hop (peso 1) Inversamente proporzionale alla banda (quindi favorire lâ€™utilizzo di connessioni di banda maggiori) Supportano un protocollo a livello IP per scambiarsi informazioni sulla congestione (ogni 30 min tipo) Supportano protocolli per la sicurezza e lâ€™autenticazione (cosÃ¬ possono ripudiare altri router che non possiedano la chiave di sicurezza). Border Gateway Protocol (!) Introduzione al protocollo BGP Border Gateway Protocol Ã¨ uno dei protocolli piÃ¹ importanti insieme a IP. Ãˆ il protocollo che ci permette di comunicare fra AS divers, si puÃ² dire infatti che sia un protocollo inter-AS per questo motivo.\nHa due funzioni principali:\nAnnunciare che un host o un router Ã¨ raggiungibile a tutti gli AS Trovare il percorso piÃ¹ veloce per raggiungere quellâ€™host In generale qui vengono utilizzati algoritmi Distance Vector decentralizzati sui singoli AS.\nPer far questo in generale ci teniamo una coppia (prefisso, interfaccia) ossia il prefisso contiene un range di indirizzi, e interfaccia Ã¨ lâ€™interfaccia del router che possiede quei prefissi.\nAnnuncio presenza In questa fase facciamo distinzione ai messaggi eBGP annunci di messaggi fra router di AS diversi fra di loro e di iBGP annunci fra router degli stessi AS.\nPer dare lâ€™intuizione generale, quando un nuovo router si connette, manda un messaggio iBGP a tutti i router dellâ€™AS, quando il messaggio viene a un router gateway, cosÃ¬ chiamati i router che hanno connessioni con AS diverse, questa manda una eBGP al router dellâ€™altro BGP, con informazioni sulla presenza di x e di come raggiungere x, il processo di ripete finchÃ© non Ã¨ stato recepito da tutte le AS.\nRicerca del percorso piÃ¹ breve (2) Ricordiamo prima che le rotte sono delle coppie (â€percorso fra sistemi autonomiâ€, primo router fuori dall\u0026rsquo;AS attuale).\nUna volta che un sistema autonomo Ã¨ a conoscenza di tutte le rotte verso un certo router puÃ² utilizzare questi due algoritmi:\nHot potato\nQuando provo a uscire piÃ¹ in fretta possibile dall\u0026rsquo;AS attuale. Sfruttando protocolli di intra-routing per sapere dove andare. Selezione delle rotte\nHo delle regole da seguire che eliminano tutte le rotte fino ad avere una singola Preferenza locale (impostata manualmente da un operatore solitamente) Numero minimo di hop minimo costo di intra routing. Identificatori BGP (che non trattiamo) Quindi uno dopo lâ€™altro utilizzo quelle per discriminare le routes e scegliere, quindi al passo 2 saranno rimaste tutte le routes con stessa preferenza locale, al numero 3 ho tutte le routes con stesso numero di hops, al passo 4 ho tutte le routes con stessa preferenza locale, stesso numero di hops, e stesso costo interno.\n","permalink":"https://flecart.github.io/notes/control-plane/","summary":"Tipologie di control plane La control plane Ã¨ la parte al livello di rete che si occupa di riempire le tabelle di istradamento dei router. In questo caso si possono in generare dividere gli algoritmi in due grandi famiglie\nCentralizzati, anche chiamati algoritmi LS( Link state) perchÃ© devono conoscere in che modo sono collegati i router fra di loro. Solitamente le SDN ossia software defined networking di cui abbiamo parlato in Data Plane utilizzano questi metodi, c\u0026rsquo;Ã¨ un server centralizzato (che per ragioni di tolleranza puÃ² anche essere distribuito, perÃ² diciamo che Ã¨ esterno al router la decisione) Distribuiti in cui nessuno ha informazioni complete sulla rete, ma Ã¨ possibile scambiarsi informazioni sui vicini e congiungere cosÃ¬ al percorso piÃ¹ breve.","title":"Control Plane"},{"content":"Ripasso Prox: 18 Ripasso: May 17, 2023 Ultima modifica: May 5, 2023 5:39 PM Primo Abbozzo: March 24, 2023 10:16 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Reti wireless Introduzione Radio ðŸŸ© Slide radio\nAntenna: converte corrente in segnali radiorequenza e viceversa. le segnali radiofrequenza sono onde radio con frequenza diversa per rappresentare 1 o 0. Un altro modo per mandare 1 o 0 sarebbe semplicemente cambiare lâ€™intensitÃ  della onda, mantenendo la stessa frequenza.\nViene utilizzata una variazione di potenziale elettrico per creare il segnale, dovrebbe essere un oscillatore armonico in pratica credo. Creando questo flusso di elettroni, crea anche un campo elettromagnetico a lui ortogonale, questa Ã¨ lâ€™onda radio, che si propaga alla velocitÃ  della luce.\nEssÃ¬ per capire questa parte serve ripassare un pÃ² di fisica, in old_unused_files/flecart-zone/Control Center/Tutte le note di scuola/Onde elettromagnetiche (in realtÃ  câ€™Ã¨ molto poco qui).\nIl prof ha spiegato questo fenomeno in 20 minuti, questo video sembra buono per comprendere questa cosa.\nCaratteristiche dellâ€™onda elettromagnetica (3) ðŸŸ© Lâ€™onda radio utilizzata in wireless Ã¨ solamente un sottotipo delle onde radio.\nFREQUENZA ONDA\nLa relazione fra lunghezza dâ€™onda e frequenza dellâ€™onda con la velocitÃ  dellâ€™onda Ã¨ conosciuta: $v = f\\lambda$ Comunque la frequenza Ã¨ un altra caratterizzazione importante per lâ€™onda.\nSlide frequenza\nNota: questo Ã¨ un range di frequenza! Questo ci permette di creare molti canali con frequenze diverse.\nUn problema molto difficile Ã¨ la scomposizione delle frequenze, cosÃ¬ possiamo isolare i singoli canali. Le onde sono additive, sono tutte messes assieme!\nNOTA: massima efficienza per la creazione di onde Ã¨ quando la lunghezza dellâ€™antenna Ã¨ stessa lunghezza dellâ€™onda radio, ma anche sottomultipli binari sembrano andare bene.\nAMPIEZZA ED INTENSITÃ€\nPoi lâ€™intensitÃ , ossia lâ€™ampiezza dellâ€™onda, Ã¨ lâ€™altro carattere importante\nSlide ampiezza onda\nÃˆ strettamente correlato con lâ€™energia utilizzata per generare lâ€™onda, cioÃ¨ se ho ampiezza maggiore ho speso in generare piÃ¹ energia per generare quellâ€™onda.\nNota: Lâ€™energia dellâ€™onda decade in distanza quadratica, (se voglio raggiungere doppia distanza, devo quadruplicare la potenza) quindi perde energia molto velocemente. In modo intuito il motivo per cui questo succede Ã¨ che lâ€™energia iniziale Ã¨ la stessa, idealmente dopo un certo momento Ã¨ ancora la stessa energia (nel senso che non la perdo), perÃ² Ã¨ dispersa in una area molto maggiore, che si espande quadraticamente con la distanza, ecco che quando andiamo a ricevere stiamo prendendo solamente un pezzo molto piccolo di questa energia iniziale.\nEsempio del panino con la nutella\nQuesto Ã¨ un esempio che il prof. ha fatto in aula, Ã¨ un modo molto visivo per dare lâ€™intuito di questa decadimento di potenza.\nMettiamo caso che prendiamo un cucchiaione di nutella e la spalmiamo sulla fetta. In questo caso la fetta Ã¨ bona, si sente bene la nutella. Mettiamo caso che di nuovo prendiamo il cucchiaione, la mettiamo sulla fetta. E ops, la fetta diventa in un secondo grosso 300km, la nutella Ã¨ sempre la stessa, ed Ã¨ spalmata uniformemente, ora la sento ancora la nutella? Se câ€™Ã¨ anche un muro poi mi perndi anche la nutella quando la fetta si espande! ne ho ancora di meno Ovviamente se diventa troppa poca lâ€™eneergia, poi non riesco a sentire cosa dice! cioÃ¨ non detecto il segnale\nSlide decadenza di potenza\nFASE DELL\u0026rsquo;ONDA\nUna terza caratterizzazione, oltre l\u0026rsquo;ampiezza e la frequenza Ã¨ la fase dellâ€™onda. ossia quanto sono spostate rispetto a un periodo assoluto (questo shift di fase Ã¨ in radianti o gradi)\nUn onda spostata rispetto al riferimento, posso considerarla o in anticipo o in posticipo, la somma delle due perÃ² Ã¨ 360, quindi Ã¨ lo stesso modo di descrivere le due.\nSlide phase shift\nSi hanno problemi con la fase quando questa rimbalza con qualcosa e va a interferire con sÃ© stesso.\nClassificazione zone di segnale (3) ðŸŸ¨+ Andiamo a definire una signal detection limit, ossia il punto da cui dopo non e piu detectabile il segnale, e quindi non comprendo piÃ¹ cosa mi viene comunicato.\nSu quanto definito sopra potremmo definire 3 zone correlata alla distanza fra il sender e il ricevente:\nSlide zone di propagazione segnale\nLa capacitÃ  del ricevente influenza in quale zona stai (come se avessi lâ€™orecchio piÃ¹ fine o meno!)\nTrasmission range quando riesco a comprendere un un errore bitrate molto basso Detection range non si riesce a capire cosa viene trasmesso, ma si nota che si trasmette qualcosa Interference range quando i segnali potrebbero anche non essere rivelati perchÃ© troppo deboli A volte se ho molte sources, un buon metodo potrebbe essere mettere un filtro che filtri un certo tipo di canale, se ascolto sto ascoltanto un certo misto di segnale. (una cosa carina Ã¨ che la radiazione di fondo si mischia con questi ðŸ˜›)\nProblemi della rete wireless (3) ðŸŸ¨- intensitÃ  del segnale che decade in fretta intereferenza con stessa frequenza da sorgenti diversi Interferenza con sÃ© stesso (se percorre distanze diverse, rimbalzando da qui e la, e giunte sfasato! O passare ostacoli?) OSTACOLI! (3)\nDietro l\u0026rsquo;ostacolo faccio fatica ad avere segnale L\u0026rsquo;ostacolo fa rimbalzare lâ€™onda radio Il materiale influenza fortemente questo comportamento dellâ€™onda (anche rifrazione!) Slide ostacoli assorbono\nSlide influenze ostacoli\nIn generale se l\u0026rsquo;onda Ã¨ a bassa frequenza, passa l\u0026rsquo;ostacolo, se Ã¨ alta Ã¨ molto facile che si blocchi.\nQuindi abbiamo un tradeoff di questo tipo:\nOnda bassa frequenza, va lontano, ma contiene poche informazioni al secondo Onda alta frequenza non va lontano, ma tante informazioni! (motivo per cui la cella 5g deve essere per forza piccola) E ci sono alcuni fenomeni come terminale nascosto o fading, sempre per caratteristiche di ostacoli e evanescenza del segnale che interferiscono fra di loro.\nPUNTI CIECHI DELLE ANTENNE (1)\nSe posiziono l\u0026rsquo;antenno in un certo modo, questa non riesce proprio a leggere le onde radio in una certa posizione (a causa della polarizzazione)\nSlide punti ciechi (polarizzazione)\nSe sto allo stesso orientamento dell\u0026rsquo;antenna, riesco a leggere tutto bene le informazioni delle antenne, mentre invece se sto ortogonale non potrei vedere niente. Questa Ã¨ anche chiamata polarizzazione dellâ€™onda.\nSlide polarizzazione (con esempio di foro per intuito)\nLa soluzione a questo problema Ã¨ utilizzare piÃ¹ antenne di diverse orientazioni. Quindi comunque riesco a prendere qualcosa (se lo metto in modo ortogonale, a L, riesco a ricavare il segnale iniziale sempre).\nNOTA: indoor ho i muri che rimbalzano, quindi alla fine comunque mi arriva di direzione giusta, e non ho un problema di sensibilitÃ  tale.\nNOTA2: i satelliti sono fighi, non hanno nessun ostacolo per comunciazione onde radio, forse le nuvole sono il piÃ¹ grande problema, che riescono ad assorbire e riflettere anche qui le onde radio.\nEffetti sull\u0026rsquo;uomo (non fare) ðŸŸ© 300 MHz and 300 GHz sono il range delle microonde, quando il cellulare emette certe onde di quella requenza, allora Ã¨ proprio questo! Solamente di intensitÃ  molto minore. (sono milliwatt contro centinaia di watt), quindi un pÃ² comunque scalda! E attraversa comunque un pÃ² la materia, e scalda lâ€™acqua a questa frequenza.\nhttps://www.fda.gov/radiation-emitting-products/cell-phones/do-cell-phones-pose-health-hazard\napprofondimento carino: vedere come funziona la risonanza, e se questo Ã¨ il fenomeno che fa scaldare lâ€™acqua.\nSlide effetti sull\u0026rsquo;uomo\nCome fanno le onde radio ad arrivare alle auto? Se la cabbia di faraday proprio va a schermare il tutto? Evade molto poco, e quello Ã¨ quello che va nell\u0026rsquo;access point.\nLa trasmissione del segnale Guadagno del segnale (2) ðŸŸ© Si dice guadagno del segnale quando incremento la potenza del segnale, in un certo rapporto in confronto a quanto trasmesso. Si misura in DECIBEL.\nguadagno attivo questo Ã¨ quello che vanno a fare gli amplificatori, che hanno bisogno di energia dall\u0026rsquo;esternom prende le onde in input e utilizza lâ€™energia per rigenerare il segnale, sono quello che fanno i repeaters. guadagno passivo quando non ho bisogno di energia allâ€™esterno. Per esempio Ã¨ cosÃ¬ che funzionano i dischi delle parabole, che riescono a prendere molto segnale, e concentrarla in un unico punto. Perdita di segnale ðŸŸ©- Intenzionale questa Ã¨ utile per gestire lâ€™energia (e.g. far passare 6 ampere in un circuitino sarebbe troppo, quindi trasformo in calore prima di far entrare nel circuito) (oppur esempio un connettore, che riflette in parte e fa passare con intensitÃ  minore, e questo Ã¨ proprio misurabile id dB) ostacoli come acqua. perdita del segnale â€˜non volutaâ€™, dovuta ad ostacoli, ad esempio in caso di nebbia, che rappresenta un ostacolo per le microonde che scaldando le particelle dâ€™acqua di cui Ã¨ composta la nebbia, facendo ridurre lâ€™energia del segnale (e quindi lâ€™ampiezza), riducendo la distanza che puÃ² percorrere il segnale. Slide tipologie di effetti di ostacoli\nMultipath propagation (2) ðŸŸ¨â€” Il segnale puÃ² giungere da molte direzioni, e il segnale ricevuto puÃ² essere in una fomra strana (phase shifted, tre echi meno energetici, parzialmente sovrapposti.\nSlide multipath\nGli effetti principali della multi path sono:\nI segnali possono arrivare in momenti diversi e fare interferenza con sÃ© stesso I segnali possono arrivare phase shiftati. Effects of mobility (non fare?) ðŸŸ¥ Ci sono proprio delle zone in cui il segnale Ã¨ migliore e altre in cui non va per il wifi, in cui cambiano subito questa parte di segnale\nSlide mobilitÃ \nLâ€™effetto principale Ã¨ la variabilitÃ  del segnale quando ci muoviamo, possiamo avere alti e bassi e continuamente ci connettiamo a ripetitori diversi (questo Ã¨ anche un modo per ricostruire il tuo percorso, a seconda di quale dispositivo ti sei connesso vicino).\nCambiano anche distanza dal destinatario e dagli obstacoli.\nVoltage Standing Wave Ratio ðŸŸ¨+ Ãˆ proprio necessario utilizzare la stessa impedenza! Altrimenti diventa molto inefficiente,\nVSWR Ã¨ una perdita del segnale quando l\u0026rsquo;impedenza della sorgente e del ricevente sono diversi fra di loro. C\u0026rsquo;Ã¨ un effetto resistivo quando le correnti si spotano in questo modo, che crea calore. (corrente genera Se il valore di impedenza Ã¨ diverso ho:\nIrregolaritÃ  (anche ritorno di energia), perdita di energia. bruciare delle componenti. Calcolato come rapporto delle impedenze del trasmettitore e ricevente.\nIntentional radiator e regulations ðŸŸ©- Intentional radiator Ã¨ il trasmittitore piÃ¹ cavi e connettori con l\u0026rsquo;antenna\nIntentional radiator Power output: quanitÃ  di energia data all\u0026rsquo;antenna dall\u0026rsquo;intero componente dietro lâ€™antenna, quindi cavi connettori e il generatore (i cavi fanno perdere un pÃ² di energia, in questo senso l\u0026rsquo;antenna non riceve lâ€™energia del trasmettitore come da sorgente, ma quella decaduta dalla corrente.\nSu questo IR Poutput si mettono le regulations, ossia massimo energia a livello antenna, ma si potrebbe fare che l\u0026rsquo;energia che riceve siano dentro i limiti, ma utilizzo una antenna in modo da focalizzare il raggio, rendendolo molto piÃ¹ denso.\nPer questo motivo bisognerebbe mettere il la regolazione non sul power output, che si puÃ² concentrare, ma sul EIRP (Equivalent isotropically radiated power), ossia la potenza radio irradiata dallâ€™antenna con anche gli effetti passivi (ossia concentrati diciamo), una volta che sono al massimo dell Power output.\nMisura della potenza Il WATT ðŸŸ© Quelli che ci interessano sono soprattuto i watt, che sono una misura della potenza, la quantitÃ  di lavoro fatto al secondo.\nIn pratica Ã¨ una misura di\nenergy needed (in a given time unit) to apply a given â€œpressureâ€ to a given â€œamount of chargeâ€, by resulting in a flow of current.\nLe formule classiche sono le leggi di OHM che qui perÃ² saltiamo.\nSlide misura della potenza\nI decibels ðŸŸ© Spesso andare a ragionare in watt Ã¨ molto scomodo, perchÃ© la potenza cade in modo logaritmico (non era quadratico??) dato che Ã¨ logaritmico meglio utilizzare i decibels\nDecibel (dB) measures the logarithmic relative strength between two signals (mW are a linear absolute measure a energy)\nNOTA: Ã¨ molto importante il fatto che i decibels siano relativi!\nSlide sui decibels\nCALCOLO DEI DECIBELS\nSlide\n$$ dB = 10 \\times \\log_{10}(\\dfrac{W_{Receiver}}{W_{Sender}}) $$ Formila inversa:\n$$ W_{receiver} = W_{sender}\\exp(dB \\log(10)/ 10) $$ Esempi di calcolo\nIl vantaggio principale Ã¨ che invece a stare modificare moltiplicazioni e divisioni, sto utilizzando somme e sottrazioni che creano numeri molto piÃ¹ gestibili, (questo Ã¨ sempre isomorfismo prodotto e somma in un certo gruppo credo).\nUna cosa carina Ã¨ che tipo 3 decibels Ã¨ moltiplicare o dividere per 2.\nNormalized decibels dBm ðŸŸ© Praticamente diciamo che $1 mW = 1dBm$\nSlide utili decibells\n$$ P_{dBm} = 10 \\log(P_{mW}) \\\\ P_{mW} = \\exp(P_{dBm} / 10) $$ Con qualche costante messa bene per i logs.\nScala decibells milliwatt\nIsotropic decibels dBi ðŸŸ© I decibels isotropici misurano il guadagno passivo dato dallâ€™architettura dellâ€™antenna confrontandolo con il caso ideale di un antenna isotropica, con efficienza 100%, equiparabile a un dipolo di lunghezza nulla.\nSlides isotropic decibels\ndB-dipole ðŸŸ© Questo Ã¨ solamente un dipole translato di 2.14 se mi ricordo bene, solamente il compare di una antenna dipolo con una isotropica i suppose, quindi non molto di differenza.\n","permalink":"https://flecart.github.io/notes/fisica-del-wireless/","summary":"Ripasso Prox: 18 Ripasso: May 17, 2023 Ultima modifica: May 5, 2023 5:39 PM Primo Abbozzo: March 24, 2023 10:16 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Reti wireless Introduzione Radio ðŸŸ© Slide radio\nAntenna: converte corrente in segnali radiorequenza e viceversa. le segnali radiofrequenza sono onde radio con frequenza diversa per rappresentare 1 o 0. Un altro modo per mandare 1 o 0 sarebbe semplicemente cambiare lâ€™intensitÃ  della onda, mantenendo la stessa frequenza.","title":"Fisica del Wireless"},{"content":"Spire Spira quadrata Questo Ã¨ descritto nell\u0026rsquo;esempio 8.1 del Mazzoldi. Ãˆ stato descritto anche in un esercizio in classe (non Ã¨ importante).\nSpira circolare ðŸŸ© Vedere pagina 245 Vogliamo cercare il valore del campo sull\u0026rsquo;asse della spira circolare. Questo Ã¨ semplice, basta usare la prima di Laplace e trovare l\u0026rsquo;apporto del campo magnetico al centro. Si puÃ² anche pensare come momento magnetico, allora si utilizza sempre lo stesso discorso per la spira quadrata classica e il suo momento.\nProviamo a modellizzare il problema e risolvere ciÃ². Utilizziamo la prima legge di Laplace $$ d\\vec{B} = \\frac{\\mu_{0}i}{4\\pi} d\\vec{l}\\times \\frac{\\hat{r}}{r^{2}} $$ Con le variabili dichiarate come in figura, possiamo scrivere $dl = Rd\\theta$ e che $r^{2} = R^{2} + x^{2}$ E sappiamo che il verso del campo sull\u0026rsquo;asse Ã¨ sempre concorde sullo stesso verso (quindi i contributi si sommano, dobbiamo considerare per ragioni di simmetria solamente quella lungo l\u0026rsquo;asse.)\nAllora abbiamo\n$$ d\\vec{B} = \\frac{\\mu_{0}i}{4\\pi} \\frac{R}{R^{2} + x^{2}} d\\theta $$ E dobbiamo moltiplicare per il coseno di $\\varphi$ per avere la componente lungo l\u0026rsquo;asse: $d\\vec{B}_a = d\\vec{B} \\cdot \\cos \\varphi = d\\vec{B} \\cdot \\frac{R}{r}$ Da cui abbiamo che $$ d\\vec{B}_{a} = \\frac{\\mu_{0}i}{4\\pi} \\frac{R^{2}}{(R^{2} + x^{2})^{3/2}} d\\theta $$ E integrando su tutta la superficie della spira otteniamo\n$$ \\vec{B}_{a}(x) = \\frac{\\mu_{0}i}{4\\pi} \\frac{R^{2}}{(R^{2} + x^{2})^{3/2}} 2\\pi = \\frac{\\mu_{0}i}{2} \\frac{R^{2}}{(R^{2} + x^{2})^{3/2}} $$ Da cui possiamo ricavare il caso specifico in cui $x = 0$, abbiamo il campo al centro della spira\n$$ \\vec{B}_{a}(0) = \\frac{\\mu_{0}i}{2R} $$ Questo risultato ci sarÃ  utile per l\u0026rsquo;analisi del solenoide in seguito.\nMomento magnetico della spira Prova a ricorda quanto fatto per la spira quadrata in Spettrometri di massa. ossia ancora da capire bene (la cosa con l\u0026rsquo;inerzia, e il momento di dipolo, una cosa che dipende solamente dalla struttura) descritta da $i \\cdot S$ ossia dalla corrente e dalla superficie, da cui poi ha senso descrivere un concetto di flusso.\nComponenti del campo magnetico ðŸŸ¥+ Possiamo scriverlo in modo simile a quanto si ha precedentemente con il Dipolo elettrico. Quindi possiamo calcolare le componenti radiali e ad un certo angolo per questa spira, e data la somiglianza con essa sarÃ  esattamente nella stessa forma $$ B = \\frac{\\mu_{0}}{4\\pi} \\frac{m}{r^{3}}(2\\cos \\theta \\hat{r} + \\sin \\theta \\hat{\\theta}) $$ Con componente radiale e trasversa. Pg 254 Mazzoldi\nSolenoide Descrizione del solenoide ðŸŸ© Vogliamo cercare di definire quale sia il campo magnetico presente sull'asse Utilizzando la funzione per la singola spira, abbiamo che basta integrare fra l\u0026rsquo;angolo formato fr ail primo e l\u0026rsquo;ultimo argomento del nostro solenoide, e facendo una cosa del genere dovrebbe venire molto piÃ¹ semplice. La parte difficile qui Ã¨ riscrivere le variabili in funzione delle variabili che abbiamo: $$ \\begin{cases} r \\sin \\phi = R \\\\ x - x_{0} = R \\frac{\\cos\\phi}{\\sin \\phi} \\implies dx = \\frac{Rd\\phi}{\\sin ^{2}\\phi} \\end{cases} $$ Utilizzando queste e l\u0026rsquo;informazione sopra con la spira abbiamo che (utilizzando anche la prima di Laplace credo). $$ dB = \\frac{\\mu_{0}ni}{2} \\sin \\phi d\\phi $$ E integrando questo valore fra $\\phi_{1}$ e $\\phi_{2}$ ci viene una cosa clean, avremo che:\n$$ B =\\frac{\\mu_{0}ni}{2}(\\cos \\phi_{2} - \\cos \\phi_{1}) $$ Mettendo l\u0026rsquo;origine all\u0026rsquo;inizio della spira, e supponendo che la lunghezza della spira sia $d$ otteniamo questo per i valori di sopra e gli angoli di sopra, ma comunque spiega meglio il libro su questo. Campo esterno del solenoide ðŸŸ¨+ Se assumiamo che i raggi siano simili, allora prendiamo due contributi e abbiamo che $B = \\frac{\\mu_{0}i}{4\\pi} (dl_{1} r_{1} \\sin \\theta + dl_{2}r_{2}\\sin(\\pi - \\theta))$ E si elidono, e questo dovrebbe funzionare anche per cose un po\u0026rsquo; a lato!\nAl centro del solenoide ðŸŸ© Bisogna in primo momento scrivere la derivazione di sopra in altro modo, possiamo trovare il valore del campo elettrico al centro del solenoide e otteniamo (vedere 248 Mazzoldi): $$ B_{0} = \\mu_{0}ni \\frac{d}{\\sqrt{ d^{2} + 4R^{2} }} $$ E si puÃ² dimostrare che questo Ã¨ il punto massimo di $B$. E se supponiamo di essere molto molto distanti, con $d \\gg R$ allora avremo che il campo magnetico Ã¨ $$ B_{\\infty} = \\mu_{0}ni $$ E si puÃ² dimostrare che all\u0026rsquo;interno il campo Ã¨ sempre quello, lo stesso, costante. Analisi tramite circuitazione del solenoide ðŸŸ© Possiamo provare ad applicare Ampere Magnetismo per potere sapere quanto valga il valore del campo magnetico. Noi sappiamo che il campo magnetico all\u0026rsquo;interno (da fare ancora) Ã¨ sempre parallelo all\u0026rsquo;asse del solenoide Se mettiamo dentro il quadratino, possiamo notare come la circuitazione sia nulla, perchÃ© la corrente concatenata Ã¨ nulla, per questo motivo ad ogni momento Ã¨ nullo, ed Ã¨ sempre uguale a quello dell\u0026rsquo;a Prendendo questa figura, abbiamo che BC e AD che nada non c\u0026rsquo;Ã¨ niente, perÃ² in questo caso ci dovrÃ  essere un po\u0026rsquo; di circuitazione. Fuori abbiamo detto non c\u0026rsquo;Ã¨ nessun campo, mentre dentro Ã¨ uguale al campo. E si dimostra $$ \\oint Bds = Bh = \\mu_{0}nih = \u003e B = \\mu_{0}ni $$ Potrebbe essere interessante rifare l\u0026rsquo;analisi seguendo la 256, in cui si divide la corrente in circolare e lineare(falla e scrivi qui i risultati come esercizio al prossimo ripasso)\nToroide #### Campo esterno ðŸŸ© Possiamo usare ampere e dire che corrente concatenata Ã¨ nulla e concludere che il campo magnetico Ã¨ nullo. #### Campo magnetico del toroide ðŸŸ© Possiamo fare la sequente analisi: $$ \\oint Bds = \\mu_{0} Ni \\implies B 2\\pi r = \\mu_{0} Ni \\implies B = \\mu_{0} \\frac{Ni}{2\\pi r} $$ Quindi solo se $r$ Ã¨ piccolo si puÃ² assumere che sia uniforme, altrimenti il valore cambia con quel valore. Si puÃ² dire che $$ H = \\frac{Ni}{2\\pi r} $$ Vedere descrizione in Magnetismo nella materia\nToroide pieno ðŸŸ©- Supponiamo ci sia un materiale dentro al toroide, allora so che $$ H = \\frac{Ni}{2\\pi r} $$ Riprendendo il ragionamento di sopra. Poi avendo questo posso sia calcolare B che M.\nTanti fili carichi #### Simmetria su asse y ðŸŸ© Dalla figura 8.35 si puÃ² dire che non abbiamo una componente $y$ , perchÃ© si eliminano. Quindi non abbiamo circuitazione sui pezzi AD e BC, perÃ² abbiamo cose sullo stesso verso ma cose oppose sugli altri versi!\nDiscontinuitÃ  parallela ðŸŸ©- Stiamo sempre considerando una linea carica di correnti come da esempio sopra.\nProviamo ad usare ampere, abbiamo allora: $$ \\oint B ds = \\mu_{0}nhi \\implies 2hB = \\mu_{0}nhi \\implies B = \\frac{\\mu_{0}ni}{2} $$ Abbiamo sempre questo valore per il campo magnetico, ma i versi sono diversi. Questo giustifica anche una discontinuitÃ  della componente parallela, per il campo magnetico, di valore $\\mu_{0}ni$. Conviene talvolta scrivere $ni\\hat{u} = \\vec{J}$ e con $\\hat{u}$ la direzione della corrente, cosÃ¬ posso sapere subito quale sia la direzione diciamo.\nContinuitÃ  perpendicolare ðŸŸ© Prendo sempre il classico cilindro, avrÃ² che $$ \\oint \\vec{B} \\hat{u}_{n} = \\oint \\vec{B}_{1} ds - \\oint \\vec{B}_{2}ds = B_{1\\perp}A_{1} - B_{2\\perp}A_{1} = 0 \\implies B_{1} = B_{2} $$ Flusso concatenato campi magnetici ðŸŸ© Setting delle spire Poniamo di avere due spire. Vorrei sapere il flusso del campo magnetico indotto dentro la seconda superficie.\n$$ \\Phi (\\vec{B}) = \\int_{\\Sigma(\\Gamma_{2})} \\vec{B} \\cdot d\\vec{s} $$ Misurato in Weber, ossia Tesla per metro quadro.\nCalcoliamo il contributo della prima spira utilizzando la prima legge di ampere: $$ d\\vec{B} = \\frac{\\mu_{0}i}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}} $$ Integriamo tutti i contributi:\n$$ \\vec{B}_{1} = \\oint_{\\Gamma_{1}} d\\vec{B}_{1} = \\oint_{\\Gamma_{1}} \\frac{\\mu_{0}i}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}} $$ Quindi per avere il flusso \u0026ldquo;basta\u0026rdquo; fare l\u0026rsquo;integrale di nuovo poi sulla superficie aperta concatenata a quella spira.\nCoefficiente di mutua induzione ðŸŸ© $$ \\Phi_{2} (\\vec{B}_{1}) = \\int _{\\Sigma(\\Gamma_{2})} \\vec{B}_{1} \\, \\vec{dS_{2}} = \\int _{\\Sigma(\\Gamma_{2})} [\\oint_{\\Gamma_{1}} \\frac{\\mu_{0}i}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}}] \\, \\vec{dS_{2}} $$ $$ \\Phi_{2} (\\vec{B}_{1}) = i_{1} \\int _{\\Sigma(\\Gamma_{2})} [\\oint_{\\Gamma_{1}} \\frac{\\mu_{0}}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}}] \\, \\vec{dS_{2}} = i_{1} M_{12} $$ Dove tutto quanto della seconda parte Ã¨ un fattore geometrico dipendente da\nCome sono disposti la prima e seconda superficie lineare I materiali con cui son fatti. Si puÃ² dimostrare che $M_{12} = M_{21} = M$. La dimostrazione dovrebbe venire semplice con Vettore potenziale\nDimostrazione che sono uguali:\nInduttanza Introduzione valore fisico ðŸŸ© Consideriamo l\u0026rsquo;autoinduzione, si puÃ² applicare un concetto simile al precedente e possiamo scrivere che $$ \\Phi(\\vec{B}) = i_{1} \\int _{\\Sigma(\\Gamma_{1})} [\\oint_{\\Gamma_{1}} \\frac{\\mu_{0}}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}}] = i_{1}L $$ Con $L$ l\u0026rsquo;induttanza della sfera, il cui verso della superficie lo intendo orientato secondo la regola della mano destra\nSia questo sia il coefficiente di mutua induzione Ã¨ misurato in $\\frac{W}{A}$. Questo si misura in Henry\nSolitamente l\u0026rsquo;induttanza di un circuito di casa Ã¨ $\\approx 10^{-7} H$.\nInduttanza su solenoide ðŸŸ© Ora consideriamo l\u0026rsquo;induttanza con l\u0026rsquo;auto-flusso, abbiamo: $$ \\Phi(\\vec{B}) = Li $$ E consideriamo il campo magnetico in un solenoide: con $n = \\frac{N}{l}$ e $B_{0} = \\mu_{0}ni$ Allora il flusso in una singola spira Ã¨ (poi calcoliamo per l\u0026rsquo;intero solenoide assumendo che sia costante il campo all\u0026rsquo;interno e poi ci ricaviamo ) $$ \\Phi_{1}(\\vec{B}_{0}) = B_{0}S = \\mu_{0}niS \\implies \\Phi(\\vec{B}_{0}) = NB_{0}S = N\\mu_{0}niS \\implies L = N\\mu_{0}nS = n^{2}\\mu_{0}(Sl) = \\mu_{0}n^{2}V $$ Allora possiamo determinare una induttanza per unitÃ  di volume, che in questo caso Ã¨: $$ \\mu_{0}n^{2} $$ Circuito con induttanza ðŸŸ© PuÃ² essere opportuno confrontare questo circuito con quello trovato in [Condensatori nel vuoto](/notes/condensatori-nel-vuoto) per la carica/scarica. Consideriamo la relazione fra forza elettromotrice e campo magnetico, abbiamo che $$ \\varepsilon_{IND} = -\\frac{d\\Phi(\\vec{B})}{dt} = -\\frac{d(Li)}{dt} $$ Da questo possiamo usare le Leggi di Ohm, in particolare la prima:\n$$ \\varepsilon + \\varepsilon_{IND} = Ri \\implies \\varepsilon = Ri + \\frac{Ldi}{dt} $$ Questo possiamo risolverlo separando le variabili in questo modo: $$ \\frac{\\varepsilon}{R} = i + \\frac{L}{R} \\frac{di}{dt} \\implies -\\frac{L}{R} \\frac{di}{dt} = i- \\frac{\\varepsilon}{R} \\implies \\frac{di}{i - \\frac{\\varepsilon}{R}} = -\\frac{R}{L}dt $$ Quindi ora abbiamo: $$ \\int_{0} ^{i(t)} \\frac{di}{i - \\frac{\\varepsilon}{R}} = -\\frac{R}{L} \\int_{0}^{t} \\, dt \\implies \\ln\\left( \\frac{\\left( i(t) - \\frac{\\varepsilon}{R} \\right)}{-\\frac{\\varepsilon}{R}} \\right) = -\\frac{R}{L} t $$ E l\u0026rsquo;ultimo passo questo ora si puÃ² esprimere come $$ \\frac{\\left( i(t) - \\frac{\\varepsilon}{R} \\right)}{-\\frac{\\varepsilon}{R}} = e^{-\\frac{R}{L} t} \\implies i(t) = \\frac{\\varepsilon}{R} (1 - e^{-\\frac{R}{L} t}) $$ Una corrente con andamento asintotico, con limite $\\frac{\\varepsilon}{R}$ Con un tempo caratteristico stavolta di $\\frac{L}{R}$ Un buon esercizio Ã¨ verificare le dimensioni di questo.\nCon questo valore possiamo andare a calcolare il valore di $\\varepsilon_{IND}$ $$ \\varepsilon_{IND} = -\\varepsilon e ^{- Rt/L} $$ Che va a 0, asintoticamente abbiamo il caso classico\nEnergia dell\u0026rsquo;induttanza ðŸŸ¨++ Facciamo un altro genere di analisi: $$ \\varepsilon = Ri + \\frac{Ldi}{dt} \\implies \\varepsilon idt = Ri^{2}dt + Lidi $$ Abbiamo che il primo termina Ã¨ l\u0026rsquo;energia fornita dalla forza elettromotrice, l\u0026rsquo;energia dissipata per effetto Joule nella resistenza Ã¨ quello con la resistenza, mentre l\u0026rsquo;ultimo Ã¨ l\u0026rsquo;energia immagazzinata dalla induttanza. Allora possiamo dire: $$ dU_{l} = Lidi \\implies U_{l} = \\frac{1}{2}Li^{2} $$ Che confrontasi, molto simile a quanto trovato per il condensatore, in cui abbiamo $\\frac{1}{2}CV^{2}$l\nL\u0026rsquo;energia Ã¨ spesa per la costruzione del campo magnetico dal nulla, mentre per il condensatore Ã¨ stato usato per avere il campo elettrico.\nDensitÃ  energetica dell\u0026rsquo;induttanza ðŸŸ©\u0026ndash; Abbiamo che $$ B = \\mu_{0}ni, L = \\mu_{0} n^{2}(ls) \\implies i = \\frac{B}{\\mu_{0}n} $$ Da cui abbiamo che $$ U_{L} = \\frac{1}{2}Li^{2} = \\frac{1}{2}(\\mu_{0}n^{2} lS) \\frac{B^{2}}{\\mu_{0}^{2}n^{2}} \\implies U_{L} = \\frac{1}{2} \\frac{B^{2}}{\\mu_{0}} (lS) $$ Da questo possiamo definire la densitÃ  energetica magnetica come $$ u_{l} = \\frac{1}{2} \\frac{B^{2}}{\\mu_{0}} $$ E si puÃ² fare la stessa cosa con il vettore di spostamento, in questo caso con la magnetizzazione, che abbiamo studiato in Magnetismo nella materia. $$ u_{l} = \\frac{1}{2} \\mu_{0} H^{2} = \\frac{1}{2 }HB $$ ","permalink":"https://flecart.github.io/notes/geometrie-di-spire/","summary":"Spire Spira quadrata Questo Ã¨ descritto nell\u0026rsquo;esempio 8.1 del Mazzoldi. Ãˆ stato descritto anche in un esercizio in classe (non Ã¨ importante).\nSpira circolare ðŸŸ© Vedere pagina 245 Vogliamo cercare il valore del campo sull\u0026rsquo;asse della spira circolare. Questo Ã¨ semplice, basta usare la prima di Laplace e trovare l\u0026rsquo;apporto del campo magnetico al centro. Si puÃ² anche pensare come momento magnetico, allora si utilizza sempre lo stesso discorso per la spira quadrata classica e il suo momento.","title":"Geometrie di spire"},{"content":"Introduzione Note filosofiche (non impo) Bisogna in primo momento cercare di definire cosa Ã¨ la computazione e cosa Ã¨ un computer. Aristotele faceva la distinzione fra proprietÃ  essenziali e accidentali. Quelle essenziali sono proprie dell\u0026rsquo;oggetto.\nUna sedia puÃ² essere fatta di legno o di metallo, ma questa proprietÃ  Ã¨ accidentale, ovvero, essa rimane una sedia indipendentemente dal materiale di cui Ã¨ fatta.\nSolitamente in matematica si prova ad astrarre (vedi Astrazione sul controllo per nota generale sull\u0026rsquo;astrazione). PerÃ² in questo campo si sono trovati molte concezioni equivalenti. Fino ad arrivare a concepire la tesi di Church-Turing. Il prof. nota che questo Ã¨ strano, perchÃ© in altre discipline si converge in unico modello, mentre qui molte cose sono indifferenti. Questo Ã¨ importante per capire come la concezione di Computer Science si Ã¨ evoluta (Denning 2010).\nNascita della calcolabilitÃ : Turing (curiositÃ ) Al tempo si voleva in matematica trovare un formalismo, un fondamenta logico alla matematica che poteva permettere di dimostrare tutto dalle fondamenta. Il contributo principale, e secondo il prof il lavoro piÃ¹ importante in tutta l\u0026rsquo;informatica era (Turing 1937), che definisce cosa significa calcolare un problema. Questo porta al significato di calcolare un problema. Ãˆ interessante notare come Turing arriva al suo formalismo. Osserva\nL\u0026rsquo;esecuzione di certe regole Un foglio di carta in cui sono lette e scritte dei simboli L\u0026rsquo;azione eseguita dipende dal simbolo precedente Da queste osservazioni iniziali, hanno astratto i dati (ora simboli binari) e le azioni, un set molti semplice. Osservazione: computazione Ã¨ locale.\nLa macchina di Turing Vedere precedente per capire come Ã¨ stata ideata questa macchina di Turing.\nDefinizione matematica ðŸŸ© Ãˆ interessante confrontare questa definizione con Fondamenti teorica#La macchina di turing in cui usiamo un formato leggermente diverso. Nel nostro caso Ã¨ una 5-tupla di\n$\\Sigma$, un alfabeto di simboli finiti, con simbolo speciale per cella vuota $Q$ Un insieme di stati $q_{0} \\in Q$ lo stato iniziale $H \\subseteq Q$ l\u0026rsquo;insieme degli stati finali $\\delta$ la funzione di transizione che soddisfa questo: $$ \\delta : (Q - H) \\times \\Sigma \\to Q\\times \\Sigma \\times \\left\\{ \\to, \\leftarrow \\right\\} $$ La differenza Ã¨ che in questo caso l\u0026rsquo;alfabeto dell\u0026rsquo;input Ã¨ uguale all\u0026rsquo;alfabeto del nastro, ma alla fine cambia poco, basta TODO (capire) secondo me ha sbagliato il prof. tempo fa, perchÃ© l\u0026rsquo;alfabeto di input non Ã¨ mai preso in considerazione nella funzione di transizione boh. Questa sintassi Ã¨ piÃ¹ comprensibile della precedente quindi nice.\nCome per tutti i precedenti automi, anche questi hanno una rappresentazione possibile a diagramma: A lezione abbiamo anche visto esempi di macchine che computano moltiplicazione binaria o addizione binaria.\nProblemi di decisione Definizione problemi di decisione ðŸŸ© Molti problemi si possono codificare attraverso un problema di decisione, ossia un problema in cui abbiamo solamente bisogno di una risposta sÃ¬ o no. Se riusciamo a codificarlo con il linguaggio delle macchine di Turing, allora forse si puÃ² far verificare alla macchina. Si vedrÃ  che molti problemi non vanno.\nSchema di codifica ðŸŸ¨+ Ossia un dato $\\alpha$ sarÃ  descritto con $code(\\alpha) \\in \\Sigma^{*}$. Una nota interessante Ã¨ che con Kolmogorov complexity abbiamo un dato di lunghezza minima, qui vediamo bene il link molto diretto. Questo ha delle proprietÃ :\nÃˆ Iniettiva Vorremmo capire in $\\Sigma^{*}$ quali siano dei codici possibili per un qualche $\\alpha$ nel nostro dominio. Sarebbe carino poter ritrovare $\\alpha$ a partire dal suo codice. Definizione decidibilitÃ  ðŸŸ© Dato un certo linguaggio, supponiamo di avere una macchina di Turing come definita di sopra #La macchina di Turing tale per cui abbia due stati finali $\\left\\{ H, N \\right\\}$, allora diciamo che $\\mathcal{M}$ decide $L$ se vale che\nQuando $x \\in L$ allora $\\mathcal{M}$ accetta $x$, ossia finisce su stato $H$ Quando $x \\not\\in L$ allora $\\mathcal{M}$ rigetta $x$, ossia finisce su stato $N$ Diciamo che un linguaggio $L$ Ã¨ decidibile se una macchina di Turing lo decide. Ora abbiamo formalizzato il significato di decidibilitÃ .\nDefinizione riconoscibilitÃ /semidecibilitÃ  ðŸŸ© Uguale al precedente, con la differenza che quando la stringa non appartiene al linguaggio diverge.\nDiciamo un linguaggio $L$ Ã¨ riconoscibile se una macchina di Turing lo riconosce. Th: DecidibilitÃ  -\u0026gt; RiconoscibilitÃ , Ã¨ facile costruire una tale macchina di Turing partendo da una che la decide, possiamo estendere il caso negativo in questo modo: se raggiungo lo stato negativo allora vado in loop infinito a caso.\nDefinizione non riconoscibilitÃ  Significa che non puÃ² dire in tempo finito nÃ© sÃ¬ nÃ© no. Quindi Ã¨ una cosa ancora piÃ¹ forte rispetto la semidecibilitÃ .\nGerarchia di Chomsky ðŸŸ¨+ Vedere Linguaggi liberi e PDA#Classificazione dei linguaggi alla sezione schema generale delle grammatiche. La cosa da ricordare Ã¨ che TM Ã¨ il modello piÃ¹ generale fra tutti i precedenti modelli di macchine di Turing e automi.\nTesi di Church-Turing Enunciato della tesi ðŸŸ©- Se la soluzione di un dato problema puÃ² essere calcolata attraverso una procedura algoritmica, allora puÃ² essere calcolata da una macchina di Turing. (Alonzo Church)\nAlonzo proponeva una altra teoria di calcolo, Ã¨ stato proponente di lambda calcolo. Quelli che piacevano a Asperti.\nStoricamente sembra vero, perchÃ© sempre prendendo qualcosa che sembra piÃ¹ espressibile, resta alla fine equivalente a turing.\nEsempi di conseguenze:\nMacchine di Turing \u0026lsquo;migliorate\u0026rsquo; (nondeterministiche, probabilistiche, piÃ¹ nastriâ€¦) Macchine a registri Linguaggi di programmazione di alto livello come Python, Java, C, â€¦ (Codice macchina di) computer classici â€¢ Computer quantistici EspressibilitÃ  vs semplicitÃ  e efficienza ðŸŸ© Probabilmente lo abbiamo citato in Fondamenti teorica, il fatto che questo Ã¨ solamente una congettura perchÃ© non Ã¨ possibile codificare tutti i formalismi possibili. Parla di espressibilitÃ  ossia cosa puÃ² essere calcolato, e se questo vale permette di dire che Ã¨ una macchina universale. Infatti non dice nulla su semplicitÃ  o efficienza dell\u0026rsquo;algoritmo (in questa astrazione non ci interesssa).\nGiustificazione valenza di Turing (non impo) La cosa interessante di queste macchine comunque Ã¨ che La macchina di Turing ci permette di formalizzare!\nRigorositÃ  di algoritmo. (anche se non mi sembra buono per esprimere certe forme di calcolo (Denning 2010)). Teoremi di calcolabilitÃ  possono essere estese a qualunque altro formalismo, se vale. Versione rafforzata Questa versione Ã¨ una estensione della tesi di Church-Turing in modo che comprenda la parte in Time Complexity.\nOgni modello di calcolo deterministico sicamente realizzabile puÃ² essere simulato da una TM (deterministica, su nastro singolo) con overhead al piÃ¹ polinomiale.\nChiusura del linguaggio di TM Chiusura sulla decidibilitÃ  ðŸŸ© Complemento: Ã¨ molto semplice decidere sul complemento perchÃ© basta scambiare gli stati finali Unione: basta eseguirlo sul multinastro e comparare l\u0026rsquo;input, vedi Estensioni di Turing e altre macchine. Intersezione: Usi de morgan con i precedenti. Concatenazione: stessa dimostrazione per Grammatiche Regolari, concateni le macchine.\nUn esercizio Ã¨ dettagliare la definizione di queste macchina, in modo simile a quanto facevamo al corso di linguaggi.\nNOTA: ricorda di seguire la struttura della dimostrazione. Se no te la conterÃ  come sbagliata all\u0026rsquo;esame.\nPer la concatenazione Ã¨ un po\u0026rsquo; piÃ¹ difficile del previsto, perchÃ© non so bene dove devo andare a tagliare per la seconda stringa, quindi vado in modo non deterministico sul taglio, cosÃ¬ in pratica faccio tutte le cose possibili.\nChiusura sulla riconoscibilitÃ  ðŸŸ© Complemento: No Unione sÃ¬, stessa cosa precedente. Intersezione: credo basti concatenarli con reset dell\u0026rsquo;input e dire che si accetta se arriva in fondo Concatenazione: sÃ¬ La non chiusura del complemento la trovi in Halting Theorem and Reducibility. PerchÃ© si dimostra che $HALT$ e il suo complementare non sono chiusi, e questo basta per il complemento.\nLa macchina di Turing universale Esempi di macchine universali Sono dei programmi in grado di eseguire altri programmi. Ãˆ una cosa molto particolare dell\u0026rsquo;informatica questa cosa, permetterebbe per esempio di eseguire un programma su se stesso, una cosa ricorsiva (oroboro quasi). Esempi di macchine universali possono essere\nSistemi operativi Stack di hardware che abbiamo, ognuna universale che esegue una sopra l\u0026rsquo;altra. Anche questo Ã¨ stato pensato in (Turing 1937). Una cosa interessante Ã¨ che prima di esso, la macchina era pensata per una unica cosa, dopo Turing si puÃ² usare la stessa macchina per tutti gli algoritmi possibili. Ha introdotto la nozione di programmabilitÃ ! Utilizzare il dato (l\u0026rsquo;algoritmo) come input di sÃ© stesso Ã¨ stato usato da GÃ¶del nella sua dimostrazione famosa. Ha codificato teoremi come numeri, permettendo l\u0026rsquo;uso dell\u0026rsquo;aritmetica stessa.\nDescrizione UTM ðŸŸ© La cosa importante Ã¨ che: \u003e La macchina universale deve avere lo stesso comportamento di $\\mathcal{M}$. Se si ferma, si ferma con stesso output, altrimenti non si ferma.\nCostruzione di UTM ðŸŸ© Codifichiamo simboli che possono apparire nella definizione di $\\delta$, per esempio $\\sigma_{0} = \\cup, \\sigma_{1} = \\leftarrow, \\sigma_{2} = \\to$ e poi in modo simile per ogni simbolo dell\u0026rsquo;alfabeto finito. Poi possiamo codificare in modo unario, per esempio $code(q_{i}) = 111..11$ per $i+1$ volte in totale, in modo simile per $\\sigma_{i}$. Poi uso gli 0 per separare i codici. Quindi posso avere una singola transizione, che Ã¨ una tupla di simbolo in input, stato input, stato output, simbolo output, e movimento. Quindi $$ code(t) = code(q_{i})0code(\\sigma_{n})0code(q_{j})0code(\\sigma(m))0code(\\sigma_{o})0 $$ Poi possiamo separarli con uno 0 in piÃ¹, o contare quanti 0 hai visto. Si puÃ² encodare anche l\u0026rsquo;input, in modo simile $$ code(\\sigma_{1i}...\\sigma_{in}) = 00code(\\sigma_1)0 code(\\sigma_{12}) 0 ... 0 code(\\sigma_{in}). $$ Ãˆ interessante osservare che questo formato $code(\\mathcal{M})code(i)$ Ã¨ una cosa decidibile, perchÃ© Ã¨ un formato che si conosce.\nLettura simboli macchina specifica Interpretazione di essa Poi si puÃ² continuare ad utilizzare il nastro per simulare la macchina stessa. References [1] Denning â€œUbiquity Symposium \u0026lsquo;What Is Computation?\u0026rsquo;: Opening Statementâ€ Ubiquity Vol. 2010, pp. 1880066.1880067 2010\n[2] Turing â€œOn Computable Numbers, with an Application to the Entscheidungsproblemâ€ Proceedings of the London Mathematical Society Vol. s2-42(1), pp. 230\u0026ndash;265 1937\n","permalink":"https://flecart.github.io/notes/la-macchina-di-turing/","summary":"Introduzione Note filosofiche (non impo) Bisogna in primo momento cercare di definire cosa Ã¨ la computazione e cosa Ã¨ un computer. Aristotele faceva la distinzione fra proprietÃ  essenziali e accidentali. Quelle essenziali sono proprie dell\u0026rsquo;oggetto.\nUna sedia puÃ² essere fatta di legno o di metallo, ma questa proprietÃ  Ã¨ accidentale, ovvero, essa rimane una sedia indipendentemente dal materiale di cui Ã¨ fatta.\nSolitamente in matematica si prova ad astrarre (vedi Astrazione sul controllo per nota generale sull\u0026rsquo;astrazione).","title":"La macchina di Turing"},{"content":"Introduzione alla legge di gauss Giustificazione con angoli solidi ðŸŸ¨\u0026ndash; Pagina 69 del Mazzoldi. Vogliamo chiederci quanto sia il flusso in qualunque superficie Da un punto di vista infinitesimo abbiamo che (perchÃ© il flusso Ã¨, intuitivamente, la parte perpendicolare rispetto la superficie che abbiamo) $$ d\\Phi = \\vec{E}\\cdot \\vec{dS} = \\lvert \\vec{E} \\rvert \\lvert \\vec{dS} \\rvert \\cos \\theta = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{1}{r^{2}} ds = \\frac{Q}{4\\pi\\varepsilon}d\\Omega $$ Il secondo passaggio Ã¨ giustificabile andando su coordinate polari considerando l\u0026rsquo;angolo solido di un oggetto quindi non dovrebbe essere un problema.\nDall\u0026rsquo;equazione di sopra abbiamo il flusso che Ã¨ da dentro un punto interno, sommando tutti questi infinitesimi abbiamo che $$ \\Phi = \\int _{\\sum} \\, d\\Phi= \\int _{\\sum} \\frac{Q}{4\\pi\\varepsilon}\\, d\\Omega = \\frac{Q}{4\\pi\\varepsilon}\\int _{\\sum} \\, d\\Omega = \\frac{Q}{4\\pi\\varepsilon} 4\\pi = \\frac{Q}{\\varepsilon} $$ Nota il flusso dipende solamente dalla CARICA, indipendente dalla singola posizione. Enunciato legge di Gauss (linguaggio naturale) ðŸŸ© Il flusso attraverso qualunque superficie chiusa $\\sigma$ eguaglia la somma algebrica delle cariche contenute all\u0026rsquo;interno della superficie comunque esse siano distribuite divisa per ma costante dielettrica del vuoto $\\varepsilon_{0}$\n(praticamente scritto in linguaggio ambiguo naturale quello che viene espresso in formule, niente di piÃ¹ e niente di meno).\nLegge di Gauss in forma integrale ðŸŸ© $$ \\oint_{\\sum} \\vec{E} \\, \\vec{ds} = \\frac{Q}{\\varepsilon_{0}} $$ E se ci sono piÃ¹ cariche, per principio di sovrapposizione posso sommare tutte le cariche sopra, e quindi ho $Q_{T} = \\sum_{i=1}^{N}q_{i}$ questo vale per distribuzione di cariche discrete, se Ã¨ continuo Ã¨ leggermente diversa la cosa (per cose viste precedentemente il contributo delle cariche esterne Ã¨ zero.)\nLegge di Gauss e divergenza ðŸŸ© Guarda il teorema della divergenza dimostrato piÃ¹ generalmente in Divergenza e Circuitazione. Flusso di campo vettoriale su superficie chiusa sigma Ã¨ uguale a qualcosa sulla divergenza\n$$ \\oint_{\\Sigma} \\vec{E} \\, \\vec{d}s= \\int_{V(\\Sigma)} \\vec{\\nabla}\\vec{E} \\, dt $$ In qualche modo posso dire che la densitÃ  di carica sul volume si puÃ² fare senza problemi, Sappiamo sempre per gauss che\n$$ \\frac{1}{\\varepsilon_{0}}\\int _{V(\\sigma)}\\rho \\, dt = \\frac{Q_{T}}{\\varepsilon_{0}} $$ Abbiamo quindi che $$ \\int _{V(\\Sigma)}\\vec{\\nabla}\\vec{E} \\, dt = \\int_{V(\\Sigma)} \\frac{\\rho}{\\varepsilon_{0}} \\, dt \\implies \\vec{\\nabla}\\cdot\\vec{E} = \\frac{\\rho}{\\varepsilon_{0}} $$ Legge di Gauss in forma differenziale (locale) ðŸŸ© Esiste anche una altra forma, che Ã¨ si puÃ² vedere la dimo in Divergenza e Circuitazione riguardo alle motivazioni. $$ \\vec{\\nabla}\\cdot\\vec{E} = \\frac{\\rho}{\\varepsilon_{0}} $$ $\\rho$ Ã¨ la densitÃ  volumetrica di carica.\nChe mi da informazione sul valore del campo sul singolo punto, ossia se in quel punto c\u0026rsquo;Ã¨ il campo.\nOsservazione 1 Ãˆ ovvio osservare che questa forma del teorema di Gauss Ã¨ applicabile solo nei casi in cui la funzione Ã¨ differenziabile ovunque nello spazio, cosa che non Ã¨ mai detto. Se ho un punto di discontinuitÃ , devo usare la forma integrale\nOsservazione 2: questa Ã¨ una forma locale perchÃ© nel caso la densitÃ  cambiasse, questa legge non puÃ² essere utilizzata, non Ã¨ immediato che il campo cambi infatti, perÃ² Ã¨ utile per calcolare il campo nella singola posizione.\nUtilizzi della legge di Gauss Esempio: flusso dipolo ðŸŸ© Essendo che altre parti escono, altre entrano, il flusso totale Ã¨ zero. Questo Ã¨ anche un modo per dimostrare che **non esiste nessuna linea che entra o esce dall'infinito**, andandosi quindi a trattare di induzione completa. Metodi per calcolare il flusso ðŸŸ© sommo tutte le cariche che sono presenti (quanto fatto sopra) Uso Gauss (superficie) Sommo potenziali (gradiente cambiato di segno (recuperare)) Considerazioni sulla legge vs Coulomb ðŸŸ© Questa legge di gauss Ã¨ direttamente dipendente dalla Legge di Coulomb, (probabilmente quello che si vuole dire Ã¨ che da una puoi derivare l\u0026rsquo;altra) e funziona solamente per il fatto che scende in modo inversamente quadrato.\nCaso particolare: campo costante ðŸŸ© Consideriamo il caso in cui il campo Ã¨ costante su tutta la superficie, allora avrei che $$ \\oint_{\\sum}\\lvert \\vec{E} \\rvert ds \\cos \\theta = \\lvert \\vec{E} \\rvert \\oint_{\\sum}ds\\cos \\theta \\implies \\lvert \\vec{E} \\rvert = \\frac{Q_{T}}{\\varepsilon_{0}} \\frac{1}{\\oint_{\\sum}ds\\cos \\theta} $$ Un aspetto particolare Ã¨ che questo integrale $\\oint_{\\sum}ds \\cos \\theta$ Ã¨ semplicemente l\u0026rsquo;area della superficie.\n","permalink":"https://flecart.github.io/notes/legge-di-gauss/","summary":"Introduzione alla legge di gauss Giustificazione con angoli solidi ðŸŸ¨\u0026ndash; Pagina 69 del Mazzoldi. Vogliamo chiederci quanto sia il flusso in qualunque superficie Da un punto di vista infinitesimo abbiamo che (perchÃ© il flusso Ã¨, intuitivamente, la parte perpendicolare rispetto la superficie che abbiamo) $$ d\\Phi = \\vec{E}\\cdot \\vec{dS} = \\lvert \\vec{E} \\rvert \\lvert \\vec{dS} \\rvert \\cos \\theta = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{1}{r^{2}} ds = \\frac{Q}{4\\pi\\varepsilon}d\\Omega $$ Il secondo passaggio Ã¨ giustificabile andando su coordinate polari considerando l\u0026rsquo;angolo solido di un oggetto quindi non dovrebbe essere un problema.","title":"Legge di Gauss"},{"content":"Introduzione alla RandomicitÃ  Questo Ã¨ principalmente basato su (Li \u0026amp; VitÃ¡nyi 2019) Capito 1.9 Sembra che la nozione di random sia alla fine una cosa molto profonda. Per esempio, un caso lampante che le definizioni non funzionano nel caso di numeri trascendenti Ã¨ che catalogano i numeri di $\\pi$ come se fossero casuali, mentre in realtÃ  possono essere trovati mediante procedimenti precisi. Ãˆ una distinzione filosoficamente molto interessante.\nAlla fine sembra ci sia un link molto diretto con la crittografia, si puÃ² vedere (Stinson 2005).\nMinimum description length come probabilitÃ  reale Una altra osservazione Ã¨ che gli assiomi della probabilitÃ  sviluppati da Kolmogorov, che puoi trovare inIntroduzione alla probabilita, sono nella teoria molto belli, ma mancano un framework reale su cui possono essere applicati. Un possibile ipotesi Ã¨ che il sistema sviluppato da Kolmogorov complexity possa essere alla fine il nostro sistema buono per descrivere le cose randomiche, come programmi che generano la stringa voluta.\nVon Mises all\u0026rsquo;inizio del secolo scorso fu uno dei primi che ha studiato questo problema, lui era un frequentista, quindi credeva nel Central Limit Theorem and Law of Large Numbers. Una nota interessante Ã¨ che secondo lui le probabilitÃ  sono cose osservabili, come fenomeni fisici, come Magnetismo. mentre nel corso fatto di Poisson processes il prof. del MIT ha chiaramente detto come le probabilitÃ  a differenza di altri fenomeni, non sono osservabili da sole, ma hanno bisogno di altri eventi (misura sulla collezione, non sul singolo evento). Un po\u0026rsquo; questo fa la distinzione fra Entropy e Kolmogorov complexity, in cui una Ã¨ su cose che hanno frequenza, l\u0026rsquo;altra definibile anche su singoli oggetti.\nMisesâ€“Waldâ€“Church randomness Questo prende in considerazioni solo cose statistiche: Una sequenza $a_{1}, a_{2}, \\dots$ composta di 0 e 1 Ã¨ definita random dal punto di vista di collezione (probabilmente avremo una altra definizione piÃ¹ tardi) se valgono le seguenti condizioni: Sia $f_{n}$ il numero di $1$ nei suoi primi $n$ numeri, allora deve valere che $$ \\lim_{ n \\to \\infty } \\frac{f_{n}}{n} = p, 0\\leq p\\leq 1 $$ Ossia il numero di $1$ deve essere la nostra probabilitÃ  di interesse\nE che valga la place selection rule, anche conosciuta come law of excluded gambling strategy, ossia per qualunque sotto sequenza della nostra sequenza, valga l stesso il limite, e questo limite deve essere lo stesso valore di $p$. La formalizzazione di questa regola Ã¨ un po\u0026rsquo; strana, si vuole avere una funzione computabile parziale $\\phi: \\left\\{ 0, 1 \\right\\}^{n} \\to \\left\\{ 0, 1 \\right\\}$, allora seleziono l\u0026rsquo;indice $n$ se vale $\\phi(a_{1}a_{2}a_{3},\\dots,a_{n-1}) = 1$. Se ho questa proprietÃ  prendo $a_{n}$ nella mia sequenza, poi vado a considerare la sottosequenza $a_{n_{1}}, a_{n_{2}}, \\dots$ e questa vogliamo che converga ancora a $p$ questo dovrebbe essere una necessitÃ  abbastanza forte.\nNo analisi a posteriori Una altra nota negativa Ã¨ che questa definizione non si puÃ² verificare a posteriori, perchÃ© in nessun caso reale abbiamo un limite vero (realtÃ  finita, non riusciamo ad andare all\u0026rsquo;infinito).\nRandom stocastico vs random regolare Un controesempio classico a questa definizione Ã¨ il numero $0,123456789010203040506070809111213141516171819\\dots$ che dovrebbe soddisfare queste proprietÃ , ma chiaramente non Ã¨ per niente random. Si chiama Champernowneâ€™s number. Kolmogorov giustifica questo dicendo questo:\nâ€œIn everyday language we call random those phenomena where we cannot ï¬nd a regularity allowing us to predict precisely their results. Generally speaking, there is no ground to believe that random phenomena should possess any deï¬- nite probability. Therefore, we should distinguish between randomness proper (as absence of any regularity) and stochastic randomness (which is the sub- ject of probability theory). There emerges the problem of ï¬nding reasons for the applicability of the mathematical theory of probability to the real world.â€ [Kolmogorov]\nMartin-LÃ¶f randomness Kolmogorov randomness Randomness tests Vorremmo creare un formalismo che ci permetta di descrivere se una certa stringa Ã¨ random o meno. Utilizziamo l\u0026rsquo;idea da statistica dell\u0026rsquo;elemento tipico che definiamo come un elemento appartenente alla maggioritÃ . Per qualche motivo che non ho capito vuole definire in modo random la cosa che appartiene al confine.\nDefiniamo un insieme $V = \\mathcal{N} \\times S$, e poi una sequenza di $V_{m} = \\left\\{ x : (m, x) \\in V \\right\\}$ tale per cui $V_{m + 1} \\subseteq V_{m}$ allora puoi definire un livello di confidenza $\\varepsilon$ entro il quale considerarlo random, solitamente questo lo mettiamo come valore a $2^{-m}$ non so per quale motivo, probabilmente per il fatto che definisce una sorta di valore lunghezza. Dato un certo $V_{m}$ $$ \\forall n \\in \\mathbb{N},\\sum_{x} \\left\\{ P(x | l(x) = n) : x \\in V_{m} \\right\\} \\leq \\varepsilon $$ Si generalizza scegliendo degli insiemi $V_{m}$ su cui valutare, sul libro ci sono esempi 2.4.1, 2.4.2. Se vale la cosa di sopra vuol dire che il test Ã¨ superato a quel livello. Non so quanto possa essere utile questa def, ma sicuramente Ã¨ qualcosa. In pratic\nReferences [1] Stinson â€œCryptography: Theory and Practice, Third Editionâ€ CRC Press 2005\n[2] Li \u0026amp; VitÃ¡nyi â€œAn Introduction to Kolmogorov Complexity and Its Applicationsâ€ Springer International Publishing 2019\n","permalink":"https://flecart.github.io/notes/randomness/","summary":"Introduzione alla RandomicitÃ  Questo Ã¨ principalmente basato su (Li \u0026amp; VitÃ¡nyi 2019) Capito 1.9 Sembra che la nozione di random sia alla fine una cosa molto profonda. Per esempio, un caso lampante che le definizioni non funzionano nel caso di numeri trascendenti Ã¨ che catalogano i numeri di $\\pi$ come se fossero casuali, mentre in realtÃ  possono essere trovati mediante procedimenti precisi. Ãˆ una distinzione filosoficamente molto interessante.\nAlla fine sembra ci sia un link molto diretto con la crittografia, si puÃ² vedere (Stinson 2005).","title":"Randomness"},{"content":"Ripasso Prox: 75 Ripasso: June 22, 2022 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: November 11, 2021 5:41 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Fare attenzione alla dimostrazione di monotonia (stretta o lasca) nei casi in cui si puÃ² usare lagrange o meno (RIPETO IL FARE ATTENZIONE A STA COSA) Fare attenzione all\u0026rsquo;enunciato di fermat, lo ho invertito Vecchi dubbi Teorema di permanenza del segno (enunciato) DImostrazione del corollario di Lagrange Ripetere le ipotesi del teorema di Fermat Vedere se si ricorda come dimostrare tutti i teoremi Monotonia funzioni!!! 6 Teoremi di analisi 6.1 Definizioni 6.1.1 Massimo minimo relativo (locale) 6.1.2 Massimo minimo assoluto 6.2 Fermat 6.2.1 Ipotesi Enunciato\n6.2.2 Note Un pÃ² intuitivamente, questo teorema ci sta dicendo che il valore della derivata in un punto di massimo oppure di minimo deve essere uguale a 0.\nBisogno fare attenzione che il punto non deve essere sugli estremi perchÃ© la derivata lÃ¬ non Ã¨ definita in modo sufficiente per soddisfare questo teorema.\nDimostrazione\nSono due casi diversi, ma con la stessa logica\nLa permanenza del segno Ã¨ una dimostrazione per assurdo implicita, perchÃ© se si pone che il limite Ã¨ minore di 0 allora per la permanenza del segno per gli X presenti in quell\u0026rsquo;intorno vale che Ã¨ minore o uguale a 0!\nStessa cosa per quell\u0026rsquo;intorno.\n6.3 Rolle 6.3.1 Ipotesi Enunciato\n6.3.2 Note Ricorda l\u0026rsquo;esempio della montagnola per dare l\u0026rsquo;intuizione di questo teorema\nDimostrazione\nUso weierstrass e posso dire che la funzione deve avere tutti i valori nel massimo e nel minimo.\nCi sono due casi, entrambi minimo e massimo sono estremi o uno dei due oppure uno dei due sono dentro l\u0026rsquo;intervallo, se sono dentro posso utilizzare fermat, invece la funzione Ã¨ constante nel primo caso.\n6.4 Lagrange 6.4.1 Ipotesi Enunciato\n6.4.2 Osservazioni Sembra che sia una generalizzazione di Rolle, in veritÃ  Ã¨ come Rolle ma con il piano cartesiano girato, in questo senso possiamo intuire che siano equivalenti, poi si puÃ² anche provare a dimostrare (da Rolle si deriva lagrange e da lagrange si puÃ² derivare rolle).\nDimostrazione\nPer la dimostrazione di questo teorema si vuole in qualche modo utilizzare il teorema di Rolle, quindi sarebbe buona cosa costruirsi una funzione ausiliaria in cui si possa utilizzare il teorema di Rolle.\n6.4.3 Corollario costante Dimostrazione\n6.5 Cauchy 6.5.1 Ipotesi Enunciato\nOsservazione sull\u0026rsquo;ipotesi 3\n6.5.2 Osservazioni La dimostrazione Ã¨ molto simile a Lagrange, in quanto voglio costruirmi una funzione ausiliaria che soddisfi Rolle.\n6.5.3 Legame con le altre funzioni Si puÃ² notare che nel caso in cui la seconda funzione sia uguale alla funzione identitÃ  si puÃ² trovare la funzione di Cauchy senza nessun problema, si puÃ² dire che siano equivalenti\nSi puÃ² quindi dire che i due teoremi sono equivalenti a livello logico in quanto sostanzialmente mi dicono la stessa cosa, in forme diverse (seque dalla coimplicazione delle funzioni).\n6.6 Monotonia funzioni Ora si tende a correlare la crescita di una funzione al segno di una funzione.\nEnunciato\n6.6.1 Nota Bisogna fare attenzione alla dimostrazione inversa.\nPerchÃ© non si puÃ² utilizzare il teorema di Lagrange nello stesso modo con cui si va l\u0026rsquo;implica nella prima direzione. Per la seconda direzione bisogna utilizzare un assurdo con il teorema di permanenza del segno\n6.6.2 Dimostrazioni Freccia in giÃ¹\nFreccia in su\n6.7 Lo studio di funzione 6.7.1 I passi per l\u0026rsquo;analisi: Studio del dominio (Facoltativo) Studio di simmetrie Studio dei limiti sulle frontiere del dominio Studio della monotonia ","permalink":"https://flecart.github.io/notes/teoremi-base-analisi/","summary":"Ripasso Prox: 75 Ripasso: June 22, 2022 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: November 11, 2021 5:41 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Fare attenzione alla dimostrazione di monotonia (stretta o lasca) nei casi in cui si puÃ² usare lagrange o meno (RIPETO IL FARE ATTENZIONE A STA COSA) Fare attenzione all\u0026rsquo;enunciato di fermat, lo ho invertito Vecchi dubbi Teorema di permanenza del segno (enunciato) DImostrazione del corollario di Lagrange Ripetere le ipotesi del teorema di Fermat Vedere se si ricorda come dimostrare tutti i teoremi Monotonia funzioni!","title":"Teoremi Base Analisi"},{"content":"Sembra essere molto simile a Central Limit Theorem and Law of Large Numbers perÃ² per Entropy.\nEnunciato Data una serie di variabili aleatorie $X_{1}, X_{2}, \\dots$ i.i.d. $\\sim p(x)$ se vale che $$ -\\frac{1}{n} \\log p(X_{1}, X_{2}, \\dots, X_{n}) \\to H(X) $$ in probability (la definizione data in Central Limit Theorem and Law of Large Numbers#Convergence in probability).\nDimostrazione Principalmente sorvolata, ma utilizza cose simili a Central Limit Theorem and Law of Large Numbers, e una idea simile a Monte carlo integration per le probabilitÃ .\nTypical sets Questo insieme Ã¨ un oggetto matematico che ha delle proprietÃ  interessanti, viene corretto analizzarlo dopo che si ha AEP, perchÃ© in breve la sua esistenza Ã¨ giustificata da quello. Ãˆ l\u0026rsquo;insieme delle sequenze $(x_{1}, x_{2}, \\dots , x_{n})$ prese da una distribuzione $p(x)$ sempre uguale tale per cui valga $$ 2^{-n(H(X) + \\varepsilon)} \\leq p(x_{1}, x_{2}, \\dots, x_{n}) \\leq 2^{-n(H(X) - \\varepsilon)} $$ Il motivo per cui abbiamo le cose strane all\u0026rsquo;esponente Ã¨ proprio la definizione di convergenza in probabilitÃ  data. (basta che le espandi) Ossia il fatto che $$ P\\left( \\left\\lvert -\\frac{1}{n} \\log p(x_{1}, x_{2}, \\dots, x_{n}) - H(X) \\right\\rvert \u003e \\varepsilon \\right) = 0, n \\to +\\infty $$ Se si espande quanto Ã¨ presente dentro si ottiene quel bound di sopra.\nProprietÃ  Vedi 3.1.2 di (Cover \u0026amp; Thomas 2012).\nIl risultato importante Ã¨ che possiamo rappresentare sequenze di $X^{n}$ in media usando $nH(X)$ bits, senza perdita di informazione.\nReferences [1] Cover \u0026amp; Thomas â€œElements of Information Theoryâ€ John Wiley \u0026amp; Sons 2012\n","permalink":"https://flecart.github.io/notes/asymptotic-equipartition-property/","summary":"Sembra essere molto simile a Central Limit Theorem and Law of Large Numbers perÃ² per Entropy.\nEnunciato Data una serie di variabili aleatorie $X_{1}, X_{2}, \\dots$ i.i.d. $\\sim p(x)$ se vale che $$ -\\frac{1}{n} \\log p(X_{1}, X_{2}, \\dots, X_{n}) \\to H(X) $$ in probability (la definizione data in Central Limit Theorem and Law of Large Numbers#Convergence in probability).\nDimostrazione Principalmente sorvolata, ma utilizza cose simili a Central Limit Theorem and Law of Large Numbers, e una idea simile a Monte carlo integration per le probabilitÃ .","title":"Asymptotic Equipartition Property"},{"content":"Ultima modifica: March 1, 2023 9:52 AM Primo Abbozzo: October 16, 2021 6:09 PM Studi Personali: Yes\nElementi di ripasso 1 Introduzione In questa sezione andiamo ad indagare cosa fa il sistema operativo\nNote Generali 4 Parti di un sistema di calcolo Struttura Memoria Vedi Memoria per il corso di Architettura\nTipologie di SO BimodalitÃ  SO Utente e Kernel\nInterrupt, Trap, System or Supervisor Call System call ðŸŸ©- per maggiori info sui modi di chiamata delle syscall\nSystem call vs chiamate di funzione di libreria? Quali sono le differenze?\nSicurezza. (perchÃ© lâ€™utente non puÃ² accedere a nientâ€™altro che le sue istruzioni e la memoria concessagli, se vuole accedere a qualcosa di fuori deve fare richiesta). Vogliamo creare un accesso mediato con le system call alle risorse, quindi sistema operativo protetto, dato che i processi sono isolati. Operazioni delle syscall\nInput Output e periferiche. Creare e gestire i processi. Gestione dei file e della memoria (tutto Ã¨ un file) Gestione dei segnali Gestione dei processi Cosa Ã¨ un processo CPU parallele ?? Multiprogrammazione BimodalitÃ  CPU Protezione e sicurezza Reti **\nInput Output e periferiche. Creare e gestire i processi. Gestione dei file e della memoria (tutto Ã¨ un file) Gestione dei segnali ","permalink":"https://flecart.github.io/notes/introduzione-sistemi-operativi/","summary":"Ultima modifica: March 1, 2023 9:52 AM Primo Abbozzo: October 16, 2021 6:09 PM Studi Personali: Yes\nElementi di ripasso 1 Introduzione In questa sezione andiamo ad indagare cosa fa il sistema operativo\nNote Generali 4 Parti di un sistema di calcolo Struttura Memoria Vedi Memoria per il corso di Architettura\nTipologie di SO BimodalitÃ  SO Utente e Kernel\nInterrupt, Trap, System or Supervisor Call System call ðŸŸ©- per maggiori info sui modi di chiamata delle syscall","title":"Introduzione sistemi operativi"},{"content":"Ultima modifica: October 19, 2022 5:01 PM Primo Abbozzo: April 25, 2022 12:27 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Ãˆ una cos extra\n20 Pagerank Ãˆ un algoritmo molto utile (base) per il motore di ricerca di Google.\nQuanto Ã¨ importante la pagina Quante frecce partono da una pagina (che ha valore piÃ¹ concentrato con meno voti) Cerchiamo di definire quindi una fuinzione che sia definita con le caratteristiche precedenti:\nLâ€™importanza di una pagina $x_i$ Ã¨ uguale a $\\sum_{x_j \\in L} x_j/n_j$ con $n_j$ il numero di frecce che partono da questa pagina. Questa x da in un certo senso il concetto di autorevolezza di una pagina (che in questo algoritmo di base Ã¨ considerata uguale di partenza per tutti.)0\nLa Matrice che si crea Possiamo creare una matrice dalla uguaglianza fra la sommatoria lÃ¬ sopra. Si puÃ² ancora approfondire sta cosa ðŸ™‚\u0026hellip;\n","permalink":"https://flecart.github.io/notes/l-algoritmo-di-google/","summary":"Ultima modifica: October 19, 2022 5:01 PM Primo Abbozzo: April 25, 2022 12:27 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Ãˆ una cos extra\n20 Pagerank Ãˆ un algoritmo molto utile (base) per il motore di ricerca di Google.\nQuanto Ã¨ importante la pagina Quante frecce partono da una pagina (che ha valore piÃ¹ concentrato con meno voti) Cerchiamo di definire quindi una fuinzione che sia definita con le caratteristiche precedenti:","title":"Lâ€™ algoritmo di Google"},{"content":"Some useful links Main results: https://jblevins.org/notes/accept-reject\nIntuition: https://en.wikipedia.org/wiki/Rejection_sampling\nLa cosa Ã¨ che faccio sampling fra due distribuzioni diverse e devo settare anche un parametro (e a seconda di certe cose diventa molto lento).\nIntroduzione al metodo Vorrei utilizzare una funzione $g$ per generarne una altra, questo Ã¨ il fulcro del concetto. L\u0026rsquo;idea principale Ã¨:\nConosco la funzione densitÃ  della funzione $f$ che voglio andare a generare Riesco a generare seguendo una funzione semplice, la chiamo $g$, candidate density. (che Ã¨ la densitÃ  che utilizzo per calcolare il target che non conosco molto bene). Ma devono esserci due cose:\nDue densitÃ  devono avere lo stesso supporto La funzione $\\frac{f}{g}$ deve essere limitata superiormente. (perchÃ© Ã¨ come l\u0026rsquo;esempio del lago in cui lancio cose dentro per approssimarne il valore). Allora sia $M$ il limite superiore, un buon modo per fare sampling sarÃ  allora $$ U \\leq \\frac{1}{M} \\frac{f(Y)}{g(Y)} $$ Ossia genero $Y$ usando g, e genero $U$ in modo uniforme normale Guardo se viene soddisfatta la funzione di sopra Se sÃ¬ prendo, altrimenti rifiuto e continuo cosÃ¬. Dimostrazione Probability of accepting dato una certa $M$ allora ho probabilitÃ  $\\frac{1}{M}$ di accettare un sample generato in questo modo, vedere dimostrazione su wikipedia. Ma qui diamo una altro valore:\n$$ \\mathbb{P}\\left( U \\leq \\frac{f(Y)}{Mg(Y)} \\right) \\ = \\int_{-\\infty}^{+\\infty} \\int _{-\\infty}^{f(Y)/f(X)M} 1 \\, du g(y) \\, dy $$ Dove abbiamo utilizzato la marginalizzazione sulla distribuzione $Y$, quello si semplifica con: $$ = \\int_{-\\infty}^{+\\infty} \\frac{1}{M} \\frac{f(y)}{g(y)} g(y) \\, dy = \\frac{1}{M} $$ E si ha la soluzione.\nAverage waiting time (!) il valore corretto Ã¨ $c^{-1}$ dove $$ c = \\sup_{x} \\frac{f(x)}{g(x)} $$ Ad intuito questo sarebbe il valore di $M$ migliore, perchÃ© Ã¨ quello con probabilitÃ  migliore per fare sampling, ma non so bene perchÃ© si potrebbe considerare come un concetto di tempo.\nWith Unnormalized density ossia tale per cui l\u0026rsquo;integrale su tutto il supporto non Ã¨ 1, ma un valore $k$, si puÃ² dire che questo algoritmo funziona lo stesso. Il motivo che Ã¨ stato dato Ã¨ che questa costante si puÃ² tirare fuori e messa dentro $M$ e quindi sarebbe come il dato precedente.\nconsideriamo $\\tilde{f}$ e $\\tilde{g}$ tale che entrambi non siano normalizzati, magari con costanti diversi, e supponiamo che anche questi siano limitati su $\\tilde{M}$.\nSi puÃ² vedere che anche in questo caso la probabilitÃ  di acceptation Ã¨ uguale a una costante. di valore $$ \\frac{i}{\\tilde{M} \\cdot k} $$ Dove $k = \\int _{-\\infty}^{+\\infty} f(x) \\, dx$ dato che non Ã¨ normalizzato.\n","permalink":"https://flecart.github.io/notes/accept-reject-algorithm/","summary":"Some useful links Main results: https://jblevins.org/notes/accept-reject\nIntuition: https://en.wikipedia.org/wiki/Rejection_sampling\nLa cosa Ã¨ che faccio sampling fra due distribuzioni diverse e devo settare anche un parametro (e a seconda di certe cose diventa molto lento).\nIntroduzione al metodo Vorrei utilizzare una funzione $g$ per generarne una altra, questo Ã¨ il fulcro del concetto. L\u0026rsquo;idea principale Ã¨:\nConosco la funzione densitÃ  della funzione $f$ che voglio andare a generare Riesco a generare seguendo una funzione semplice, la chiamo $g$, candidate density.","title":"Accept Reject algorithm"},{"content":"Gestione delle risorse Introduzione Definizione classe, fungibilitÃ  Classe di risorse sono un insieme di risorse fra loro equivalenti (nel senso che uno puÃ² rimpiazzare lâ€™uso dell\u0026rsquo;altro), anche detti fungibili.\nStatico o dinamico Anche in economia ci sono tali definizioni! Queste risorse possono essere allocate staticamente o dinamicamente, in modo simile a quanto abbiamo detto in Gestione della memoria.\nStatico quando giÃ  in fase di compilazione del processo, o di avviamento del processo gli dÃ² la memoria, e quella sarÃ  per tutti il tempo della sua vita.\nMentre dinamico quando gli dÃ² cose pezzo per pezzo quando Ã¨ vivo\nTipologia di richieste e risorse (4) (!!!) MULTIPLO O SINGOLO\nSi puÃ² dire che il programma puÃ² chiedere risorse, e le tipologie che puoi richiedere sono multiplo o singole.\nIl significato sembra abbastanza simile:\nSingola per singola classe di risorsa Multipla richiesta per tante classi (la differenza principale Ã¨ lâ€™atomicitÃ  della richiesta, nel secondo caso, faccio singola richiesta per molteplici classi, o li prendo tutti o zero). BLOCCANTE O NON BLOCCANTE\nSi puÃ² anche dividere per richiesta bloccante o meno, e anche questo Ã¨ molto simile a quanto abbiamo fatto in Programmi Concorrenti. Quindi bloccante come le IO, quando mi metto ad aspettare che finisca, oppure la comunicazione sincrona del Message Passing.\nNon bloccante come il send della comunicazione asincrona, ma anche solo una notifica dell mancato svoglimento, come credo faccia il message passing completamente asincrono.\nCONDIVISIBILE O NON-CONDIVISIBILE\nSi puÃ² anche dividere in risorse condivisibli o meno, nel senso che una risorsa possa essere utilizzata da piÃ¹ processi contemporaneamente (come i file di sola lettura (o qualunque cosa di solo lettura, perchÃ© non ho problemi di RW).\nEsempi di non condivisibil sono le cose hardware, processori, stampanti, o anch ele sezioni critiche, versioni software.\nPREEMTABLE O NON-PREEMTABLE\nRisorse preemptable, ossia prelasciabili, quando posso forzare la rimozione della risorsa all\u0026rsquo;utilizzatore.\nuna risorsa si dice prerilasciabile se la funzione di gestione puÃ² sottrarla ad un processo prima che questo l\u0026rsquo;abbia effettivamente rilasciata\novviamente non vorrei che continuasse senza questa risorsa (quindi la stoppo)\nnon posso cambiare lo stato!! nel senso delle preemptable, se glielo tolgo, lui si aspetta di ricevere la risorsa quando torna a runnare allo stesso stato con cui Ã¨ stato tolto! Diciamo Ã¨ come se prendo in prestito un tuo giocattolo a forza e poi te lo distruggo, invece te lo vorrei ridare sano, normale diciamo.\nIl Deadlock GiÃ  studiato molto in precedenza, vorremmo caratterizzare le condizioni necessarie per i deadlock all\u0026rsquo;interno dei sistemi operativi.\nCondizioni necessarie e sufficienti per DL (4) Slide Necessario e sufficiente per Deadlock ! ! Quindi abbiamo caratterizzato con le proprietÃ  dei Deadlock! Quando ho tutte le 4 suddette cose, allora ho deadlock.\nGrafo di Holt Questo Ã¨ un sistema utilizzato per traccare tutte le dipendenze delle risorse, che possono finire a creare deadlock.\nCaratteristiche di grafo di holt\n!\nGrafo di Holt Generale Lo rapresento come classe il quadrato e i puntini come singola risorsa, poi ho altre politiche per fare le frecce\nNote implementative su Holt Come facciamo a rappresentare nella memoria questo sistema? Alla fine Ã¨ un grafo pesato!\nSlide implementazione grafo\n!\nRiduzione di grafo di holt un grafo di Holt si dice riducibile se esiste almeno un nodo processo con solo archi entranti.\nQuesto nodo eventualmente rilascia la risorsa, quindi posso posso riassegnare la risorsa!,\nIn questo modo faccio finta che la risorsa sia giÃ  stata rilasciata.\nRiassegno tutti gli archi del processo riducibile agli altri. (non ci importa quale ordine rilasciare) Completa riducibilitÃ  lo stato non Ã¨ di deadlock se e solo se il grafo di Holt Ã¨ completamente riducibile, ossia quando non ho piÃ¹ archi nel grafo\ni.e. esiste una sequenza di passi di riduzione che elimina tutti gli archi del grafo\nAd intuito quando ho ancora degli archi, vorrÃ  dire che câ€™Ã¨ una attesa circolare, ossia:\nnon tutti i nodi processo hanno tutte le risorse che gli servono Non câ€™Ã¨ modo di acquisire la risorsa perchÃ© anche un altro sta aspettando la stessa cosa In questo senso si crea lâ€™attesa circolare, ed assumendo le altre 3 condizioni di sopra ho deadlock.\nDeadlock detection introduttivo (singola risorsa) Th sola risorsa per classe\nse le risorse sono a richiesta bloccante, non condivisibili e non prerilasciabili, lo stato Ã¨ di deadlock se e solo se il grafo di Holt contiene un ciclo.\nGenero il grafo wait-for (chiusura transitiviva degli archi delle risorsa, cioÃ¨ se ho P che vuole risorsa, e risorsa assegnata a P2, allora ho P to P2), che in pratica mi genera l\u0026rsquo;attesa circolare (la 4 condizoine necessaria che lo rende sufficiente), e esiste il ciclo.\nSlides del th\n!\nEsempi\n!\nPiÃ¹ risorse per classe Questo Ã¨ il caso anche piÃ¹ reale, e ci Ã¨ molto piÃ¹ utile questo caso. Costruiremo questo caso passo per passo con le definizioni che seguono.\nInsieme di raggiungibilitÃ  e Knot ðŸŸ© dato un nodo n, l\u0026rsquo;insieme dei nodi raggiungibili da n viene detto insieme di raggiungibilitÃ  di n (scritto R(n))\nE si puÃ² definire knot molto simile a uno strongly connected component, ma diversa:\nun knot del grafo G Ã¨ il sottoinsieme (non banale) di nodi M tale che per ogni n in M, R(n)=M\nEsempio di knot\n!\nTh deadlock detection con knot Dato un grafo di Holt con una sola richiesta sospesa per processo se le risorse sono a richiesta bloccante, non condivisibili e non pre-rilasciabili, allora il grafo rappresenta uno stato di deadlock se e solo se esiste un knot\nQuindi riusciamo a detectare l\u0026rsquo;esistenza in questo modo!\nAnche se non abbiamo la dimostrazione formale, intuitivamente possiamo dire che se tutti possono raggiugnere tutti, implica l\u0026rsquo;attesa circolare!\nRecovery deadlock (2) Checkpoint e rollback\nL\u0026rsquo;idea Ã¨ molto semplice, praticamente ogni tot si guarda lo stato attuale del progetto, e si tenta di ripartire da lÃ¬, Ã¨ lo stesso concetto del backup (perÃ² si spera che gli effetti dal backup al deadlock, siano effetti di poco costo), e.g. se stampo di nuovo stampa di nuovo, ma non sarebbe buono per cose come la banca.\nTerminazione di processi\nPer certe tipologie di processi Ã¨ molto molto costoso terminarle:\nEsempio centro di ricerca beowulf ci mette 6 mesi a ripartire Terminare in modo brutale puÃ² lasciare risorse in modo invalido. Deadlock prevention Spooling Faccio finta a credere di avere giÃ  la risorsa. Un esempio Ã¨ lo spool di stampa, nel senso che tutti pensano di avere questa risorsa. (questo funziona bene per la stampante perÃ²!)\nNon risolve il problema perchÃ© Ã¨ come spostare il problema in altro punto, e NON SEMPRE APPLICABILE.\nProcess table no Dischi no. PerÃ² se il sistema Ã¨ in grado di gestire una sua coda, come nel caso di una stampante. Questo metodo sembra molto legit.\nRichiesta bloccante o pre-rilascio nel senso che tutto quello che mi serve all\u0026rsquo;inizio, lo richiedo subito, cosÃ¬ non mi blocco mai!\nAd esempio i sistemi a real time, che richiedono proprio allocazione totale.\nIl problema Ã¨ che non Ã¨ sempre possibile fare questo. E poi Ã¨ molto inefficiente perchÃ© se lo tengo per tutto lâ€™utilizzo del nostro programma, ma alla fine solamente un piccolissimo momento lo utilizzo, inefficienza al piÃ¹!\nAttesa Circolare Una soluzione forte per questo Ã¨ l\u0026rsquo;allocazione gerarchica dei processi. In questo modo sicuramente non abbiamo cicli o interdipendenze. Posso solamente richiedere risorse di classi superiori (in modo che non abbia cicli, quindi diciamo che vada solamente a un verso, e non ho mai modi per avere dei knot).\nAnalisi finale allocazione gerarchica, totale Riassunto dei metodi di prevention\n!\nBanchiere, DL avoidance Algoritmo del banchiere ðŸŸ© Dijkstra (1965)\nil nome deriva dal metodo utilizzato da un ipotetico banchiere di provincia che gestisce un gruppo di clienti a cui ha concesso del credito; non tutti i clienti avranno bisogno dello stesso credito simultaneamente\nDescrizione del problema \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Gestione delle risorse/Untitled 14.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Gestione delle risorse/Untitled 14\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Gestione delle risorse/Untitled 15.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Gestione delle risorse/Untitled 15\u0026quot;\u0026gt; Dati in input\n!\nStato safe e unsafe ðŸŸ© Slide stato safe\n!\nDetto in soldoni, lo stato Ã¨ safe quando il credito del tizio che chiede Ã¨ minore di tutti i soldi che possiedo. Se non esiste nessuna sequenza che mi garantisca quella cosa sono unsafe!\nunsafe Ã¨ necessario ma non sufficiente per DEADLOCK.\nBuona sequenza con ni CRESCENTI.\nEsempio di banchiere safe esempio di unsafe !\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Gestione delle risorse/Untitled 22.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Gestione delle risorse/Untitled 22\u0026quot;\u0026gt; Il fatto che sia safe o meno Ã¨ utile per capire se si puÃ² accettare la richiesta o meno!\nBanchiere multi-valuta Dati del banchiere multi-valuta Purtroppo se teniamo come i vettori non possiamo ordinare :(. Quindi vorremmo andare passo passo, e ogni volta aggiungere qualcosa di soddisfacibile.\nTeorema dell\u0026rsquo;algoritmo del banchiere ðŸŸ©â€” Slide algoritmo del banchiere Dimostrazione correttezza Questo mi permette di dire che non importa scegliere qualcosa con logica, se ho una sequenza che va continuerÃ  ad andare sempre! Mi permette di scegliere a caso.\nPerchÃ© non Ã¨ utilizzato Semplicemente tutte le ipotesi dellâ€™algoritmo del banchiere non sono spesso soddisfatte nel momento in cui si prova veramente a metterlo in pratica. Poi gli ingegneri dicono che spesso se un deadlock esiste una volta in 5 anni, per la maggior parte delle applicazioni diventerebbe una cosa tollerabile.\nSi assume che il numero dei processi sia noto allâ€™inizio Si assume che le risorse necessarie al processo siano note Si assume che le risorse saranno sempre quelle (invece si potrebbero rompere a caso) ","permalink":"https://flecart.github.io/notes/gestione-delle-risorse/","summary":"Gestione delle risorse Introduzione Definizione classe, fungibilitÃ  Classe di risorse sono un insieme di risorse fra loro equivalenti (nel senso che uno puÃ² rimpiazzare lâ€™uso dell\u0026rsquo;altro), anche detti fungibili.\nStatico o dinamico Anche in economia ci sono tali definizioni! Queste risorse possono essere allocate staticamente o dinamicamente, in modo simile a quanto abbiamo detto in Gestione della memoria.\nStatico quando giÃ  in fase di compilazione del processo, o di avviamento del processo gli dÃ² la memoria, e quella sarÃ  per tutti il tempo della sua vita.","title":"Gestione delle risorse"},{"content":"Gruppi ciclici e permutazioni Il gruppo ciclico Definizione gruppo ciclico Abbiamo definito in Gruppi per la prima volta il significato di gruppo ciclico generato da un elemento del gruppo, questo insieme si Ã¨ poi dimostrato essere un sottogruppo del gruppo\nUn gruppo $G$ Ã¨ chiamato ciclico se esiste un $a \\in G$ tel per cui $$ G = \\left\\{ a^{n} \\mid n \\in \\mathbb{Z} \\right\\} $$ Dove a Ã¨ chiamato elemento generatore.\nScriviamo $G = \\langle a \\rangle$ per dire che $G$ Ã¨ generato dall\u0026rsquo;elemento $a$. L\u0026rsquo;ordine del gruppo Ã¨ la cardinalitÃ : $$ ord(G) = \\lvert \\langle a \\rangle \\rvert $$ Criterio $a^{i} = a^{j}$ Probabilmente ha qualche relazione con [Teorema di Lagrange](/notes/teorema-di-lagrange). note sull\u0026rsquo;enunciato entrambe le frecce $\\impliedby$ sono abbastanza ovvie.\nRagionando sul primo caso, nel caso in cui Ã¨ infinito, se succedesse che $a^i = a^j \\land i \\neq j$ si avrebbe che l\u0026rsquo;ordine Ã¨ finito, perchÃ© si ripeterebbe ogni tot, quindi dimostri cosÃ¬. Nel secondo caso credo sia cosÃ¬, ma non saprei come formalizzare la cosa.\nDimostrazione Come si puÃ² notare, mi sto riducendo a una classe di resto con l\u0026rsquo;algoritmo di euclide nel secondo caso.\nQuesto Ã¨ un teorema molto importante nei gruppi finiti, soprattutto, perchÃ© mi sta dicendo che ci possiamo sempre ridurre a una classe di resto per l\u0026rsquo;esponente.\nCorollario 1 $\\text{ Per ogni elemento di gruppo A, si ha che: } |A| = |\\langle A\\rangle|$\nCorollario 2\n$a\\in G, |a| = n \\in \\mathbb{N}, k \\in \\mathbb{Z}, a^k = e_g \\implies n \\mid k$\nOsservazione\nQuesto fatto che la moltiplicazione fra due elementi funziona come una addizione fra due elementi in $\\Z_n$ ci fa intuire come sia possibile un isomorfismo fra questi due gruppi.\nInfatti esiste, dimostreremo poi che per ogni gruppo ciclico finito di ordine n esiste un isomorfismo con Zn (credo)\nRelazione fra ordine $n, e$ un $k$ in $\\mathbb{Z}$ e $gcd(n,k)$ Dimostrazione Questo teorema ci Ã¨ molto utile per ridurre il generatore di un gruppo in un altro piÃ¹ gestibile o piÃ¹ semplice da manipolare\nCorollario 1\nIn un gruppo ciclico, l\u0026rsquo;ordine di un elemento divide l\u0026rsquo;ordine del gruppo.\nIn simboli\n$$ a\\in G, |a| =k, |G| = n,\\implies k \\mid n $$ (da notare l\u0026rsquo;ordine opposto dei divide rispetto al corollario 2 del teorema precedente)\nCorollario 2 criterio $\\lvert a_{i} \\rvert = \\lvert a_{j} \\rvert$\nQuesto Ã¨ molto simile al teorema precedente, ma ora stiamo parlando di ordine.\nEnunciato\nDimostrazione\ncorollario 3 Generatori di gruppi ciclici finiti\nQuesto Ã¨ un corollario del corollario ðŸ˜‚. In pratica afferma che\nIl gruppo generato da $\\langle a \\rangle$ Ã¨ uguale a $\\langle a^j \\rangle$ sse $gcd(n, j) = 1$ con n l\u0026rsquo;ordine di a. cosa simile con $|a| = |a^j| \\iff gcd(n,j) = 1$\nE avendo questo possiamo definire con concretezza di generatori del gruppo finito Zk\nCorollario 4 Generatori di Zn\nsia $k \\in \\mathbb{Z}_n$, k Ã¨ un generatore sse $gcd(n,k) = 1$.\nla dimostrazione segue dal fatto che 1 Ã¨ un generatore di Zn, e vogliamo che il gruppo generato da 1 e k sia lo stesso.\nClassificazione di sottogruppi di gruppi ciclici Teorema fondamentale dei gruppi ciclici Dimostrazione Corollario Sottogruppi di Zn\nDal teorema fondamentale dei sottogruppi di gruppi ciclici abbiamo una caratterizzazione precisa dei sottogruppi presenti in Zn, sono in particolare tutti i divisori di n.\nNumero di elementi di un un certo ordine in un gruppo ciclico Dimostrazione\nQuesto Ã¨ anche una dimostrazione per Teorema di Lagrange#Teorema di Eulero.\nCorollario 1 Numero di elementi di ordine d\nEnunciato\nDimostrazione\nGruppi di permutazione Decomposizione in cicli Esiste una sintassi per scrivere le permutazioni con una notazione a cicli. Vogliamo dimostrare ora che questa sintassi Ã¨ sempre possibile (quindi corrisponde a una equivalenza)\nDimostrazione\nLa dimostrazione procede per via costruttiva, proponendo una specie di algoritmo per trovare tutti i cicli fino ad esaurimento di elementi nellâ€™insieme.\nCommutativitÃ  di cicli disgiunti Dimostrazione\nUna volta letta la dimostrazione sembra una cosa ovvia, ma probabilmente lâ€™idea Ã¨ sulla scelta degli elementi iniziali?\nOrdine di una permutazione (scomposizione con ordine di sottocicli) Dimostrazione\nDecomposizione in permutazioni bicicle Dimostrazione\nProposizione\nQuesto lemma si puÃ² estendere a un caso piÃ¹ generale, dove si possono iniziare a distinguere permutazioni pari e dispari. Vedremo che avranno certe proprietÃ  (legate alle matrici poi anche).\nDimostrazione\nParitÃ  e disparitÃ  di 2-cicli Dimostrazione\nLâ€™insieme di permutazioni pari Ã¨ un sottogruppo di Sn Dimostrazione\nSiano a, b due elementi di questo insieme, vogliamo dimostrare che $ab^{-1} \\in S$ notiamo che per il teorema 5.5 $b^{-1}$ deve essere pari, perchÃ© altrimenti avrei che $e = bb^{-1}$ sarebbe scrivibile come un prodotto di permutazioni 2-cicle dispari. Inoltre, chiaramente un prodotto di 2 permutazioni pari Ã¨ ancora pari (basta concatenare queste, che poi al massimo si eliminano a due a due). Ecco il sottogruppo.\nIl gruppo alternante di n ha ordine n! Lâ€™enunciato Ã¨ proprio questo titolo, quindi non lo riporto (sul libro Ã¨ il numero 5.7).\nInvece riporto la definizione di gruppo alternante:\nDimostrazione\nResidui Quadratici Si dice che $x \\in G$ Ã¨ un residuo quadratico nel suo gruppo se ha una radice quadrata in quel gruppo, ossia un $a \\in G$ tale per cui $a^{2} = x$. Questo Ã¨ di particolare interesse per robe di Crypto.\nSimbolo di Legendre Ãˆ il valore $$ x^{(p - 1)/2} $$ E ha delle proprietÃ  carine che non conosco\n","permalink":"https://flecart.github.io/notes/gruppi-ciclici-e-permutazioni/","summary":"Gruppi ciclici e permutazioni Il gruppo ciclico Definizione gruppo ciclico Abbiamo definito in Gruppi per la prima volta il significato di gruppo ciclico generato da un elemento del gruppo, questo insieme si Ã¨ poi dimostrato essere un sottogruppo del gruppo\nUn gruppo $G$ Ã¨ chiamato ciclico se esiste un $a \\in G$ tel per cui $$ G = \\left\\{ a^{n} \\mid n \\in \\mathbb{Z} \\right\\} $$ Dove a Ã¨ chiamato elemento generatore.","title":"Gruppi ciclici e permutazioni"},{"content":"Ripasso Prox: 20 Ripasso: May 17, 2023 Ultima modifica: May 16, 2023 12:49 PM Primo Abbozzo: March 29, 2023 9:50 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Memoria virtuale e Algo rimpiazzamento Memoria virtuale PerchÃ© Ã¨ utile la MV? ðŸŸ¨- I programmi non usano tutta la memoria, ma pensano di averla tutta disponibile dal suo punto di vista. L\u0026rsquo;idea principale Ã¨ che molte zone di memoria sono inutili per lungo tempo, possono essere utilizzati per altro.\ncaricamento codice dinamico Per esempio anche a caricare il codice di un compilatore Ã¨ diviso in fasi, se andiamo a caricare tutto, stiamo utilizzando solo un pezzo piccolo, tanta inefficienza, se una pagina contiene una parte del compilatore potrei caricare in memoria solamente le parti eseguite sul momento, giusto per fare un esempio diciamo. Crescita dei segmenti stack, heap, ad esempio ci permette di far crescere come ci pare la stack, e anche caricare solamente le parti della stack che ci servono, e mantenere la memoria libera per altro. Gestion degli errori. che utilizzerÃ  i dati solamente della parte di gestione di memoria attuale diciamo. Paginazione a richiesta ðŸŸ©â€” Questo Ã¨ un aspetto della cache delle pagine di cui abbiamo giÃ  parlato in Livello OS.\nSlide paginazione a richiesta\nin pratica nella cache Ã¨ presente un bit, chiamato valid bit, che ci dice se la pagina correntemente caricata Ã¨ valida o meno.\nSe non Ã¨ presente una pagina valida, allora chiamiamo trap di page fault, e il pager si occupa di caricare la nuova pagina ed aggiornare la pagina vecchia.\nEsempio di demand paging\nNOTA: la memoria secondaria con questo metodo ha lâ€™intero contenuto, in questo senso la memoria principale Ã¨ utilizzata come se fosse cache.\nEsempio completo con page fault\n*ALGORITMO GENERALE DI DEMAND PAGING\nSlide demand paging\nNOTA: la cosa importante Ã¨ il fatto che invalida subito la pagina scelta da sostituire. Non vorremmo che se un altro processo chieda quella pagina possa ancora scriverci o leggerci (e quindi problemi di concorrenza).\nMemoria di SwapðŸŸ© In realtÃ  quando un intero processo Ã¨ caricato in memoria secondaria, questa parte in memoria secondaria Ã¨ lâ€™area di swap.\nMa questo metodo qui Ã¨ come se fosse uno swap pigro. (se un processo Ã¨ vecchio, nel senso che non utilizza la pagina per tanto tempo, Ã¨ probabile che la sua memoria Ã¨ messa in memoria secondaria).\nil termine swap area per indicare l\u0026rsquo;area del disco utilizzata per ospitare le pagine in memoria secondaria\nAlgoritmi di rimpiazzamento AKA Paginazione.\nObiettivo del rimpiazzamento ðŸŸ©â€” Quando la memoria centrale Ã¨ piena, come si gestisce il processo di rimpiazzamento? In che modo si decide quale sia la pagina da togliere? Su quali basi andare a valutare per fare questa decisione?\nUtilitÃ , nel senso meno utilizzata SarÃ  utilizzata fra piÃ¹ tempo. Minimizzare il numero di page faults possibili. vorremmo evitare di togliere e rimpiazzare subito.\nNUMERO DI FRAME E PAGE FAULTS\nNon Ã¨ che il numero dei frame aumenta implica che il numero di faults sia minore? Ma stranamente non Ã¨ sempre cosÃ¬, gli algoritmi di rimpiazzamento potrebbero fare peggio se hai troppa memoria, per esempio Algoritmi FIFO ðŸŸ©\nQuesto fenomeno Ã¨ proprio studiato, ed Ã¨ conosciuto nel nome di Anomalia di belady ðŸŸ©\nStringa di riferimenti ðŸŸ© Ãˆ la sequenza degl iindirizzi di memoria al quale un processo accede durante la sua esecuzione, (ci importa solamente il numero di pagina!) Questo ci dÃ  un criterio per valutare quanto buona Ã¨ una pagina in memoria\nSlide stringa di riferimenti\nAlgoritmi FIFO ðŸŸ© Questo l\u0026rsquo;abbiamo studiato anche in Scheduler, oppure Data Plane per i routers.\nPraticamente la pagina che dovrÃ  uscire sarÃ  la pagina in memoria da piu`tempo. Ma non Ã¨ detto che la pagina caricata da piÃ¹ tempo sia anche poco utilizzata! potrebbe essere ancora utilizzata!\nEsempio di paginazione fifo\nEsempio paginazione 2 fifo\nEsempio brutto, di maggiori faults con aumento memori\nAnomalia di belady ðŸŸ© Slide anomalia di belady\nUn buon algoritmo di rimpiazzamento dovrebbe essere immune a questa anomalia! PerchÃ© non avrebbe senso che aggiungere memoria renda il sistema piÃ¹ lento!\nIn questo paragrafo: Implementazione a stack parliamo di una condizione sufficiente affinchÃ© non si verifichi questa condizione.\nAlgoritmo MIN ðŸŸ© Questo Ã¨ l\u0026rsquo;algoritmo ottimale, ma utilizza informazioni che non abbiamo giÃ , perchÃ© non sappiamo quando i processi accederanno a cosa. Quindi buon algoritmo in teoria (perchÃ© utilizza informazioni che non abbiamo ancora nel presente), nessun uso ora.\nPerÃ² si puÃ² dimostrare che questo algo genera il minor numero di faults.\nSeleziona come pagina vittima una pagina che non sarÃ  piÃ¹ acceduta o la pagina che verrÃ  acceduta nel futuro piÃ¹ lontano\nÃˆ un buon algoritmo per utilizzare come paragone di altri algoritmi reali, cioÃ¨ questi reali quanto bene fanno rispetto a questo algoritmo perfetto!\nSlide algoritmo MIN\nLeast Frequently usedðŸŸ¨ Slide LFU\nMa solitamente questo, come FIFO, non Ã¨ che venga utilizzata.\nVado a considerare il concetto di frequenza, definita in questo modo: contatore / tempo di permanenza in memoria.\nAlgoritmo di LRU Ne abbiamo parlato anche in architettura, qui: 9.2.4 Algoritmi di paginazione (2).\nseleziona come pagina vittima la pagina che Ã¨ stata usata meno recentemente nel passato\nIn pratica provo a stimare lâ€™utilizzo della pagina in base a quanti accessi abbia fatto in passato.\nEsempio LRU\nImplementazione LRU Come facciamo a capire quanto spesso Ã¨ stato utilizzato una pagina? Non possiamo mica aggiungere il numero di accesso a tutte le risoluzioni MMU, deve essere implementato in hardware stesso, in MMU.\nSlide implementazione MMU\nAccessi in memoria in piÃ¹\nLa MMU dovrebbe tenersi i timestamps e dovrebbe gestire gli overflows\nO(n) per scandire la tabella di frame, e trovare la pagina\nQuindi Ã¨ molto lenta, ma almeno Ã¨ realizzabile.\nIMPLEMENTAZIONE A STACK\nOssia quando accediamo una pagina, la mettiamo sopra la stack. Ma Ã¨ brutto perchÃ© in hardware dovrei aggiornare 6 puntatori, che non dovrebbe essere cosa da niente, per questo non Ã¨ utilizzato.\nLa cosa carina perÃ² Ã¨ che avrei in cima le cose utilizzate in basso quelle meno utilizzate!\nImplementazione a stack Slide definizione di algoritmi a stack\nSi noti che la condizione Ã¨ molto simile a una sufficiente per risolvere la condizione di belady, ci sta dicendo che in pratica: lâ€™insieme delle pagine mantenute in memoria Ã¨ contanuto allo stesso algoritmo con piÃ¹ pagine in memoria!\nÃˆ anche una condizione sufficiente per dire: avere fage faults in meno, non piÃ¹, perchÃ© contiene sempre le stesse pagine con una versione a piÃ¹.\nPer dimostrare che FIFO non Ã¨ a stack, basta un esempio.\nACCENNO DIMOSTRAZIONE LRU Ãˆ STACK\nSi utilizza una dimostrazione costruttiva per induzione (altra tecnica Ã¨ per assurdo). Questo lo facciamo sul tempo.\nPasso base: al tempo 0 la stack Ã¨ vuota, non ci importa quale numero di stack, la memoria resta la stessa. Supponiamo al tempo t-1 che la condizione di stack sia verificata. Ora abbiamo due casi: non câ€™Ã¨ abbstanza spazio, o câ€™Ã¨ ancora spazio: Se câ€™Ã¨ abbastanza spazio, allora non ci cambia per un m numero di frame maggiore Se non câ€™Ã¨ abbastanza spazio, quello minore deve cambiare, dovrÃ  scegliere uno a caso, scegliendone uno a caso allora lâ€™insieme delle pagine Ã¨ ancora incluso. Al passo successivo ancora, lâ€™elemento che esce dovrÃ  essere lo stesso, o comunque offsettato non di tanto credo, in pratica quello grosso elimini cose solamente eliminate giÃ  da quello piccolo!. E questa cosa con LRU lâ€™abbiamo. Non Ã¨ che ho formalizzato molto bene questa parte. Additional reference bit ðŸŸ©- Andiamo ora a parlare di approssimazione di LRU perchÃ© col discorso a stack non Ã¨ proprio fattibile con lâ€™hardware attuale.\nQuando accedo a una pagina, il bit viene messo a 1, inizialmente sono tutte 0, meglio descritta nella slide:\nSlide descrizione reference bit\nbasta fare shift e assegnamento! Quindi easy! Andiamo a prendere la pagina con valore minore poi.\nVARIANTE: SECOND CHANGE ALGO\nSlide second change (storia = 1)\nVengono gestiti come una lista circolare, per questo motivo Ã¨ anche detto algoritmo dellâ€™orologio.\nIn pratica scandisco la lista con questo algo:\nBit a 1? Allora lo metto a 0 e vado avanti Bit a 0? Allora tolgo questa! E sostituisco. Esempio di second change algo\nNon si capisce sto esempio lol\nAllocazione della memoria virtuale Tipologie di allocamento (3) ðŸŸ¨â€” Slide allocazione\nAlgo di allocazione: risponde alla domanda su come allocare i frame per un certo processo. Allocazione globale: permetto di allocare l\u0026rsquo;intero programma (male â†’ thrashing) Allocazione locale: il processo Ã¨ a conoscenza dei propri frame, ma non Ã¨ molto flessibile, di solito fanno meglio quelli globali, Praticamente finâ€™ora abbiamo parlato di metodi per sostituire delle pagine in caso di page faults, ma non abbiamo mai definito in che modo decidiamo quanti frames allocare a un processo, nel momento del bisogno. Allocazione globale e locale sono dei modi per fare questa decisione.\nLocale â†’ implica che posso sostituire solamente i frames del mio processo, in queto senso sono poco flessibile, se qualcunâ€™altro ha piÃ¹ roba che posso sottrarre converrebbe fare quello. Globale â†’ implica che posso sostituire i processi di chissivoglia. Normalmente si utilizzano anche delle euristiche per sapere quante pagine allocare: per esempio se ho troppi page faults, probabilmente il processo ha bisogno di piÃ¹ memoria, se ne ho troppi pochi probabilmente il processo ne ha troppa, e si puÃ² allocare ad altri.\nThrashing ðŸŸ© un processo (o un sistema) si dice che Ã¨ in trashing quando spende piÃ¹ tempo per la paginazione che per l\u0026rsquo;esecuzione\nQuesto Ã¨ quindi un effetto molto brutto! Va a finire che l\u0026rsquo;intero sistema si impalli. rubano le pagine a vicenda, l\u0026rsquo;effetto piÃ¹ classico Ã¨ questo: non riescono a tenere in memoria i frame utili a breve termine (perchÃ¨ altri processi chiedono frame liberi) e quindi generano page fault ogni pochi passi di avanzamento) In pratica quasi ogni operazione Ã¨ un page fault.\nPer evitare questo, massimo 2x memoria virtuale, altrimenti potrei andare in thrashing.\nEsempio di effetto di thrashing\nL\u0026rsquo;efficienza cade di interi ordini di grandezza!\nWorking set ðŸŸ©â€” si definisce working set di finestra Î” l\u0026rsquo;insieme delle pagine accedute nei piÃ¹ recenti Î” riferimenti\nQuesto Ã¨ utile per stimare se il sistema Ã¨ in thrashing. Questo Ã¨ utile per avere un concetto di localitÃ  delle pagine, vogliamo avere una stima delle pagine attualmente utili, e utilizziamo questo per andare a decidere se una pagina Ã¨ ancora utile o meno.\nSlide valutazione working set per thrashing\nSe la somma di tutti i pages di cui ho bisogno nel breve Ã¨ maggiore di piÃ¹ pagine presenti in RAM, allora sicuramente quando questa si riattiva crea page faults! Ecco il criterio per i page faults.\nScelta del delta\nSOLUZIONE PROPOSTA\nBasta sospendere alcuni processi, in modo che alcuni terminino senza andare in troppi page faults, in modo che la somma di tutti working set stiano ancora dentro.\nSlide della soluzione\n","permalink":"https://flecart.github.io/notes/memoria-virtuale/","summary":"Ripasso Prox: 20 Ripasso: May 17, 2023 Ultima modifica: May 16, 2023 12:49 PM Primo Abbozzo: March 29, 2023 9:50 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Memoria virtuale e Algo rimpiazzamento Memoria virtuale PerchÃ© Ã¨ utile la MV? ðŸŸ¨- I programmi non usano tutta la memoria, ma pensano di averla tutta disponibile dal suo punto di vista. L\u0026rsquo;idea principale Ã¨ che molte zone di memoria sono inutili per lungo tempo, possono essere utilizzati per altro.","title":"Memoria virtuale"},{"content":"Ripasso Prox: 40 Ripasso: June 24, 2022 Ultima modifica: May 19, 2022 12:48 PM Primo Abbozzo: February 28, 2022 5:02 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso 2 Relazioni di ricorrenza Iterazione Questo metodo semplicemente consiste di calcolare tutte le operazioni e scriverlo con una notazione asintotica.\nslide\nSostituzione (induzione) slide\nAnalisi della relazione di ricorrenza di fibonacci\nSi puÃ² dimostrare utilizzando l\u0026rsquo;induzione che una relazione di questo tipo\n$$ T(n) = \\begin{cases} O(1) \\\\ T(n-1) + T(n-2) + 1 \\end{cases} $$ Si trova che Ã¨ $O(2^n), \\Omega(2^{n/2})$\nAnalisi finale.\nSi puÃ² creare una stima corretta, utilizzando la formula per il calcolo di fibonacci (che dimostri facendo osservazioni su una funzione generatrice di essa, una serie infinita).\nAlbero di ricorsione slide\nTeorema dellâ€™esperto (master) Questo teorema permette di stabilire subito la stima asintotica per tutte le ricorrenze nella forma\n$T(n) = aT(n/b) + f(n)$ ed Ã¨ diviso in tre casi:\n23/03 Ricordo tutto come se fosse ieri 09/04 Non ti ricordi esattamente tutto (teoricamente albero di ricorsione, ma in pratica non lo so se lo fa) in tre casi: 23/03 Ricordo tutto come se fosse ieri 09/04 Non ti ricordi esattamente tutto (teoricamente albero di ricorsione, ma in pratica non lo so se lo fa) ","permalink":"https://flecart.github.io/notes/relazioni-di-ricorrenza/","summary":"Ripasso Prox: 40 Ripasso: June 24, 2022 Ultima modifica: May 19, 2022 12:48 PM Primo Abbozzo: February 28, 2022 5:02 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso 2 Relazioni di ricorrenza Iterazione Questo metodo semplicemente consiste di calcolare tutte le operazioni e scriverlo con una notazione asintotica.\nslide\nSostituzione (induzione) slide\nAnalisi della relazione di ricorrenza di fibonacci\nSi puÃ² dimostrare utilizzando l\u0026rsquo;induzione che una relazione di questo tipo","title":"Relazioni di Ricorrenza"},{"content":"La cosa che rende il PO diverso rispetto agli sviluppatori Ã¨ la conoscenza delle necessitÃ  del cliente. Questo permette di prioritizzare del task e capire in che modo dovrebbe essere il prodotto finale. In questo modo si crea una vision del prodotto. Pensiamo che il PO debba condividere questa informazione e prendere decisioni di gruppo.\nDomande da fare: La user interface, come sembra il wireframe? Pensavamo di utilizzare i social solamente per i login, pensavate di utilizzare anche per altro durante il gioco? Bassa prioritÃ  (poter condividere i risultati con un post). Vorreste poter selezionare il livello del bot? Quanto sarebbe il massimo livello e quale il minimo? 4. Per kriegspiel la forza Ã¨ massima. Cosa Ã¨ la modalitÃ  \u0026lsquo;mob\u0026rsquo; per giocare (2 descrizione del problema documento progetto). si intende il social che permette di condividere mosse. tutte le persone interessante possono rispondere con tempo un giorno, e la maggioranza determina la risposta. Bassa prioritÃ . Esistono i soci (utenti registrati) e non, cosa puÃ² fare un utente non registrato? E quelli registrati? O definiamo noi? Che genere di commenti deve fare l\u0026rsquo;AI durante la partita? Va bene qualunque commento (anche in giro), commenti interessanti sul contesto). In che modo salvare una partita? Solamente la sequenza delle mosse o possibilitÃ  di riprendere la partita? Non Ã¨ richiesto poter salvare e riprendere nei giochi a informazione incompleta La seconda cosa interessante per l\u0026rsquo;utente? Leaderboard (non per noi, ELO). Cosa deve avere la leaderboard per giochi diversi da bad chess? Legato all\u0026rsquo;ELO questa, il classico. O mobile o web o come ci pare (non Ã¨ importante). No sicurezza, non Ã¨ importante. 50 giocatori max.\n","permalink":"https://flecart.github.io/notes/scelta-del-po/","summary":"La cosa che rende il PO diverso rispetto agli sviluppatori Ã¨ la conoscenza delle necessitÃ  del cliente. Questo permette di prioritizzare del task e capire in che modo dovrebbe essere il prodotto finale. In questo modo si crea una vision del prodotto. Pensiamo che il PO debba condividere questa informazione e prendere decisioni di gruppo.\nDomande da fare: La user interface, come sembra il wireframe? Pensavamo di utilizzare i social solamente per i login, pensavate di utilizzare anche per altro durante il gioco?","title":"Scelta del PO"},{"content":"Ultima modifica: May 6, 2023 5:55 PM Primo Abbozzo: March 18, 2023 9:48 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Convolutional NN Introduction The convolution operator ðŸŸ©- Il prodotto di convoluzione Ã¨ matematicamente molto contorto, anche se nella pratica Ã¨ una cosa molto molto semplice. In pratica voglio calcolare il valore di un pixel in funzione di certi suoi vicini, moltiplicati per un filter che in pratica Ã¨ una matrice di pesi, che definisce un pattern lineare a cui sarei interessato di cercare nellâ€™immagine.\nSlides ed esempi (molto piÃ¹ chiari)\nVedi che per calcolare quellâ€™8 sto facendo cose lineari con tutti pixel intorno ad essa.\nQuesto operatore lâ€™abbiamo giÃ  trattato in modo molto breve in Deblur di immagini.\nSome properties and uses Sappiamo tutti che le immagini non sono altro che arrai di valori in un certo intervallo, che rappresentano lâ€™intensitÃ  dei colori, o solamente del bianco-grigio nel caso delle immagini grigio nere.\nQueste intensitÃ  si potrebbero anche rappresentare come superfici 3d in cui la posizione del pixel identifica x e y, mentre lâ€™intensitÃ  la z, abbiamo quindi proprio delle superfici!, delle montagne, valli fiumi etc. Le cose molto interessanti sono cambi di intensitÃ  improvvisi (con derivata molto alta) ossia i dirupi, le valli, questo cambio improvviso (il cambio di fase come dice Pedro di Master algorithm) Ã¨ classico anche in nautura, Ã¨ la parte con qualche informazione di interesse diciamo.\nTHE IDEA OF DERIVATIVE FOR CHANGES\nSlide finite approssimation of derivative h = 1 perchÃ© siamo in campo discreto (Ã¨ anche il minimo h che possiamo considerare in questo setting), quel filtro quindi ci Ã¨ utile per capire se ci sono dei cambi improvvisi. Questa idea ci permette di costruire il kernel per identificare le linee (visible contours of the image), orizzontali (cambi direzione e avresti verticale). itâ€™s a feature map, of the image to some characteristic of the image. (ti dice se in questa zona Ã¨ presente, non câ€™Ã¨ , o câ€™Ã¨ lâ€™opposto del pattern che cercavi).\nSome architectures Deepwise separable convolution Inception architecture ðŸŸ¨ Andiamo a derfinire un modulo di inception (in cui va a fare in un certo senso scrambling, decomporre e recomporre dati, in che modo vanno ad estrarre delle features io non lo so!).\nComunque questa Ã¨ lâ€™architettura classica, andare ad utilizzare reti convoluzionali e poi operarle con reti deep (alla fine non molto deep) in modo da collegargli insieme.\nEsempio di inception module !\nhttps://www.youtube.com/watch?v=VxhSouuSZDY\u0026amp;ab_channel=Udacity\nResidual layers Residual learning is the main concept of these networks, itâ€™s when we have a direct link with the beginning! In pratica diamo la possibilitÃ  al neurone di scegliere di non modificare o invece sÃ¬ lâ€™input credo, provo a chiedermi se posso avere un valore migliore di quanto ho attualmente con qualche peso.\nStructure of residual layer https://arxiv.org/pdf/1512.03385.pdf\nUsually these links help the network learn (lesser vanishing gradient.\nTransfer learning Slide intuizione transfer learning expected graph with performance with transfer learning\n!\nComunque lâ€™intuizione principale del transfer learning Ã¨ lâ€™idea che i primi layers facciano una sorta di estrazione di features piÃ¹ ad alto livello utili poi ai layers di deep NN. Se questa prima parte lâ€™ho trainata su un corpus enorme, allora gli aspetti che Ã¨ riuscito a generalizzare potrebbero essere utili anche per altro, e quindi utilizzo i pesi trovati in questa rete anche per altro, senza problemi.\nFine tune o finetuning Ã¨ un pÃ² rischioso, faccio un freeze di una parte del network piÃ¹ larga, potrei andare a overfittare e fare cose simili! PerÃ² ha piÃ¹ senso, ci aiuta a rendere lâ€™intera architettura ancora piÃ¹ focussato in quello che vogliamo fare noi (in un certo senso forse dÃ  via alcune generalizzazioni inutili nel nostro dominio)\nTraining of CNN Backpropagation ðŸŸ¨++ We can unroll the input and output layers as a single linear trasformation of a deep network (with weights adjusted accordingly).\nIntuition of unrolling !\nBut how do we unroll?? We can see everything as a matrix with $[input\\_size \\times output\\_size]$ as you can see from the image in the toggle\nSlide convolution matrix of the weights !\nAfter we have modelled this matrix, we can learn using standard backpropagation we have talked about in Neural Networks.\nUn problema per questo metodo Ã¨ la matrice Ã¨ sparsa se input Ã¨ molto largo, e kernel piccolo, avrei un numero di zeri assurdo, quindi nemmeno molto efficiente da memorizzare in questo modo. (perÃ² possiamo computare in modo efficiente, ma questo non lo trattiamo).\nUn altro aspetto di questa matrice Ã¨ la ripetizione shiftata dei pesi, che sono gli stessi in ogni colonna della matrice, ma solamente shiftato. Questo cambia il modo di fare update dei pesi, si utilizza lâ€™update con average pesato. fra le 4 computazioni delle 4 colonne in esempio.\nTransposed convolutions Dopo che ho fatto troppo downsampling con le CNN, vorrei tornare sÃ¹ di dimensione (se per esempio un input Ã¨ unâ€™immagine. Trasposed convolutions ci permettono di tornare su di dimensione. (anche tecniche statistiche credo che funzionino).\nSlide transposed convolutions ! !\nThis technique is called transposed convolution because if we transpose the convolution matrix, we see that we are upscaling the input!. PerÃ² non ho capito in che modo funziona!\nDilated convolutions ðŸŸ© Slide intuizione di questo !\nFacciamo una specie di padding interno sul kernel (non vado a contare certe cose, perÃ² riesco a ingrandire la receptive field del mio network.\nHa piÃ¹ senso fare sta cosa quando sto analizzando HIGH RESOLUTION IMAGE in cui il valore dei pixel cambia molto poco.\nUna differnza con le Transposed convolutions ðŸŸ¥ Ã¨ il fatto che quelle sono fatte sullâ€™input, questa la facciamo su come viene calcolato il kernel.\nSono molto utilizzate in temporal convolution networks, in cui provo a diluire volta per volta lo spazio allâ€™interno del kernel, anche se non so ancora perchÃ© va\nSlide temporal convolution network !\nNormalization layers Why normalization ðŸŸ¥ Slide 2 reasons !\nWhy is normalization a good idea :D?\nSo the quantitative values are comparable from each other (e.g. ages and income) We want the output of the layers to be comparable from each other, the middle outputs are inputs for other layers! We can better control the activation layers. (non vogliamo che faccia come output NaN ðŸ˜Ÿ) Decoupling of the layers. (non dobbiamo andare ad imparare il range di input aspettato, dato che sarÃ  sempre data di stesso tipo) Batch Normalization ðŸŸ¥ This is the most common form of normalization (ma lâ€™idea Ã¨ sempre la stessa, computare varianza e media, e poi sottrarre media e dividere per varianza). La cosa in piÃ¹ Ã¨ che vengono aggiunte delle varianze e una media, per denormalizzare lâ€™output, in modo che abbia la forma dei dati migliore possibile.\nSlide batch normalization ! Other Normalization ðŸŸ¥ Potremmo provare a normalizzare per canale\nSlide normalizations !!\n","permalink":"https://flecart.github.io/notes/convolutional-nn/","summary":"Ultima modifica: May 6, 2023 5:55 PM Primo Abbozzo: March 18, 2023 9:48 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Convolutional NN Introduction The convolution operator ðŸŸ©- Il prodotto di convoluzione Ã¨ matematicamente molto contorto, anche se nella pratica Ã¨ una cosa molto molto semplice. In pratica voglio calcolare il valore di un pixel in funzione di certi suoi vicini, moltiplicati per un filter che in pratica Ã¨ una matrice di pesi, che definisce un pattern lineare a cui sarei interessato di cercare nellâ€™immagine.","title":"Convolutional NN"},{"content":"Ripasso Prox: 15 Ripasso: July 1, 2022 Ultima modifica: July 7, 2022 4:00 PM Primo Abbozzo: March 20, 2022 3:44 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nDefinizione gruppo Qualunque insieme piÃ¹ operazione tale per cui:\nEsistenza dell\u0026rsquo;inverso per ogni elemento Esistenza di un elemento neutro AssociativitÃ . UnicitÃ  dellâ€™elemento neutro Supponiamo di avere un gruppo $G$ e due elementi neutri $e, f$ Allora abbiamo che $ae = a = af$ perÃ² se moltiplichiamo per l\u0026rsquo;inversa abbiamo che $a^{-1}ae = a^{-1}af \\implies e = f$\nUnicitÃ  dellâ€™inverso Supponiamo di avere un gruppo $G$ e due elementi inversi per ogni $a \\in G$ Sia $a$ un elemento e gli inversi $a_{1}$ e $a_{2}$, allora abbiamo: $aa_{1} = e = aa_{2}$ ma se moltiplico a sinistra per l\u0026rsquo;inversa abbiamo\n$a_{1}aa_{1} = a_{1}aa_{2} \\implies ea_{1} = ea_{2} \\implies a_{1} = a_{2}$ Dove abbiamo utilizzato anche l\u0026rsquo;associativitÃ .\nProprietÃ  di cancellazione Ãˆ ovvio se moltiplichiamo per le cose giuste. Lâ€™inverso del prodotto Enunciato: $(ab)^{-1} = b^{-1}a^{-1}$ e per gruppi abeliani abbiamo $(ab)^{-1} = a^{-1}b^{-1}$\nLa dimostrazione Ã¨ molto semplice ed Ã¨ lasciato al visitatore :D\nTest per gruppo Ordine di gruppo e di elemento L\u0026rsquo;ordine di un gruppo Ã¨ la cardinalitÃ  dell\u0026rsquo;insieme, L\u0026rsquo;ordine dell\u0026rsquo;elemento del gruppo Ã¨ la potenza a cui si eleva questo elemento per avere il neutro\nTest unico per il sotto-gruppo $$ \\forall a,b \\in H ,H \\subseteq G, ab^{-1} \\in H \\implies H \\text{ is a subgroup of G} $$ Se vale questa proprietÃ  possiamo giÃ  avere un sottogruppo! Quindi Ã¨ abbastanza comodo!\nDimostrazione:\nAssociativitÃ  si ha per $G$. Se prendo $a, a$ come la coppia abbiamo che $aa^{-1}=e$ appartiene a $H$, quindi c\u0026rsquo;Ã¨ l\u0026rsquo;elemento neutro. Se prendo $e, a$ vedo che $a^{-1} \\in H$. Quindi abbiamo che vale.\nTest doppio per il gruppo Mostrare che sia chiuso rispetto all\u0026rsquo;operazione e ci sia sempre l\u0026rsquo;inverso. Questo in pratica va per la #Definizione gruppo come espresso sopra!\nTest per gruppi finiti Mostrare solamente che sia chiuso per l\u0026rsquo;operazione (nella dimostrazione di deve mostrare che Ã¨ chiuso per l\u0026rsquo;inverso, cosa che si va per il terzo escluso\nSottogruppi Sottogruppi generati da un elemento (ciclico) Dimostrazione Osservazione:\nOgni sottogruppo generato in questo modo Ã¨ abeliano, perchÃ© Ã¨ in isomorfismo con il gruppo additivo Z (si vedrÃ  dopo di questo isomorfismo)\nIl centro di un gruppo Ã¨ un sottogruppo Dimostrazione enunciato in h3\nEsempio: centro di gruppi diedrali\nCentralizzatore di un gruppo Ã¨ un sottogruppo Osservazione: quando il centralizzatore Ã¨ l\u0026rsquo;intero gruppo, l\u0026rsquo;elemento su cui stiamo centralizzando Ã¨ esattamente il centro.\nDimostrazione Analoga alla precedente del centro ","permalink":"https://flecart.github.io/notes/gruppi/","summary":"Ripasso Prox: 15 Ripasso: July 1, 2022 Ultima modifica: July 7, 2022 4:00 PM Primo Abbozzo: March 20, 2022 3:44 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nDefinizione gruppo Qualunque insieme piÃ¹ operazione tale per cui:\nEsistenza dell\u0026rsquo;inverso per ogni elemento Esistenza di un elemento neutro AssociativitÃ . UnicitÃ  dellâ€™elemento neutro Supponiamo di avere un gruppo $G$ e due elementi neutri $e, f$ Allora abbiamo che $ae = a = af$ perÃ² se moltiplichiamo per l\u0026rsquo;inversa abbiamo che $a^{-1}ae = a^{-1}af \\implies e = f$","title":"Gruppi"},{"content":"Ripasso Prox: 40 Ripasso: May 25, 2023 Ultima modifica: April 15, 2023 10:21 PM Primo Abbozzo: March 10, 2023 2:16 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso HTTP e REST HTTP HYPERTEXT-TRANSFER-PROTOCOL\nCaratteristiche principali (3) ðŸŸ¨ Slide caratteristiche\nComunicazioni fra client e server, e quanto sono comunicate le cose si chiude la connessione e ci sono politiche di caching molto bone (tipo con i proxy) Generico: perchÃ© Ã¨ un protocollo utilizzato per caricare moltissime tipologie di risorse! Stateless, ossia non vengono mantenute informazioni su scambi vecchi, in un certo modo ne abbiamo parlato in Sicurezza delle reti quando abbiamo parlato di firewall stateless. Solitamente possiamo intendere questo protocollo come utile per scambiare risorse di cui abbiamo parlato in Uniform Resource Identifier.\nLa connessione ðŸŸ©- Ãˆ importante oggi rendere efficienti le connessioni, al tempo come descritto in Livello applicazione e socket per HTTP, per richiedere ogni risorsa si apriva e si chiudeva una connessione (uno dopo lâ€™altro, senza parallelizzazione).\ncon HTTP2 giÃ  questa cosa era cambiato, possiamo richiedere allo stesso tempo piÃ¹ connessioni, Ã¨ la pipeline. Importante notare che la differenza col multiplexing Ã¨ che nel pipelining ti risponde con lâ€™ordine\nMultiplexing invece utilizza la stessa connessione per chiedere e rispondere piÃ¹ volte (oggi anche piÃ¹ comune). La differenza principale Ã¨ elaborare in ordine diverso rispetto a quanto abbia ricevuto.\nSlide connessioni\nSlide esempio tipologie di richiesta\nCi sono anche altri modi per rendere ancora piÃ¹ veloce il protocollo, un esempio Ã¨ lâ€™operazione PUSH, per esempio quando fai la pagina HTML, il server sai giÃ  che il client vai a richiedere altre risorse di quella pagina, quindi inizia subito a processare le richieste, prima che il client abbia effettivamente chiesto.\nUn altro modo per rendere piÃ¹ veloce la trasmissione Ã¨ la compressione degli header per tutte le richieste e fatte anche in parallelo.\nRichiesta HTTP (5) ðŸŸ© Vogliamo ora andare a parlare della struttura di un pacchetto HTTP affinchÃ© si possa considerare valido. Ci sono 5 campi principali:\nVersione del RFC per HTTP Metodo, tipo PUT, GET etc, ne parliamo sotto. URI, descritto in Uniform Resource Identifier. Header, che si articolano in molti sotto headers (ci sono molti headers) Body della richiesta Slide richiesta HTTP\nRisposta HTTP (4) ðŸŸ© La risposta del server va di 4 campi (cioÃ¨ Ã¨ quello che ti ritorna dopo aver elaborato la tua richiesta)\nStatus code Version HTTP Headers (nota headers sono credo praticamente le stesse della richiesta) Body (in cui effettivamente ci sono le informazioni della risposta) Slide risposta HTTP\nEsempio di risposta HTTP\nStatus codes (5) ðŸŸ© Ci sono 5 campi principali che vanno a descrivere a grandi linee il significato della risposta (in un certo senso Ã¨ come nella richiesta vado a specificare lâ€™azione, gli status codes ti rispondono con informazioni precise riguardanti la tua richeista).\nSlides sugli status codes\nEsempi di status codes\nÃˆ importante andare a utilizzare status codes corretti, per ragioni molto simili a un verbo HTTP corretto, perchÃ© questo aiuta tutti i servizi capire bene lâ€™esito della nostra richiesta, aiuta i meccanismi di caching a capire se cachare o meno.\nHeaders (4) ðŸŸ¥++ Ci sono 4 tipologie principali di headers HTTP, andremo a descriverli ora.\nHEADERS GENERALI\nSlide generali\nSi mandano informazioni come cache, la codifica, la data, il tipo di connessione (se deve restare su o meno).\nHEADERS DI ENTITÃ€\nSlides entitÃ \nSono utili per andare ad interpretare le tipologie di content allâ€™interno del body. In parte questa parte Ã¨ condivisa anche negli headers per il MIME Headers del MIME (2)ðŸŸ¨.\nInfatti in risposta con una risorsa le content-type e lenght son oobbligatori per specificare informazioni sulla risorsa ritornata.\nHEADERS DI RICHIESTA\nSlides richiesta\nSono utili per dare informazioni sul client al server.\nEsempi sono lâ€™host, lâ€™user-agent che sta facendo la richiesta. Per esempio a seconda dello user agent ho dei CSS leggermente differenti!\nHEADERS DI RISPOSTA\nSlides risposta\nMetodi HTTP (!) I metodi HTTP sono presenti allâ€™interno del campo metodo di un pacchetto HTTP, sono anche chiamati verbi HTTP perchÃ© vanno a descrivere cosa bisogna andare a fare sulla risorsa identificata dallâ€™URI.\nSlide esempio di get e POST\nIn teoria tutto puÃ² essere fatto con GEt, ma se utilizzo bene le API avere status codes corretti rende molto piÃ¹ chiaro ed uniforme lâ€™interazione con essa, quindi molto piÃ¹ interoperabile.\nCARATTERISTICHE METHODI HTTP (!!!)\nSono sicurezza e idempotenza. Vorremmo che HTTP sia stateless, quindi vorremmo che non generi cambiamenti dello stato oltre che avere dei logs.\nidempotente quando richieste identitiche hanno stesso risultato.\nGET\nSlide GET 3\nHEAD\nSlide HEAD 3\nPOST\nSlide POST 0\nPUT\nSlide PUT 2\nDELETE\nSlide DELETE 2\nPATCH\nSlide PATCH 0\nla differenza principale con PUT Ã¨ che patch Ã¨ per cambiare parzialmente una risorsa e non sostituirla completamente.\nOPTIONS\nSlide OPTIONS 3\nSlide riassunto caratteristiche\nE poi ce ne sarebbero altre, ma solitamente si utilizzano Get post put e delete perchÃ© sono quelle piÃ¹ consone per il modello CRUD per rest.\nREST REpresentational State Transfer Ã¨ una metodologia di costruzione di API, avevamo giÃ  fatto qualcosa cone tipo protobuf. Ãˆ un modello architetturale, ossia modo per creare applicazioni che sfruttano HTTP che possano essere utilizzati da altre applicazioni il modo piÃ¹ chiaro possibile.\nConnesse sullâ€™ambiente di utilizzo (quindi cose come collezioni, singolo elemento della collezione e simili). Modello CRUD (!) (4) ðŸŸ© Quando ho una collezione di dati vogliamo descrivere le operazioni principali che posso fare su essa:\nCreazione di elemento singolo o di un gruppo Lettura di un individuo o di un gruppo Aggiornamento di dati giÃ  esistenti Eliminazione di dati Slide su CRUD\nImportante notare che questo pattern Ã¨ indipendente da REst, di solito utilizzato per Database, ma possiamo utilizzare lo stesso mecanismo con Rest e le operazioni di HTTP\nOssia URI come identificatore e Richieste HTTP per andare a modificarle.\nUtilizzo CRUD per Metodi HTTP\nEsempio Verbi HTTP con rest\nIn breve REST utilizza URI per identificare la risorsa, e semantica HTTP per andare a richiederla e stabilire la connessione di trasferimento.\nMetodologie URI REST ðŸŸ¨+ Ci sono delle specifiche metodologie per dare senso a un uri che possa essere rest, l\u0026rsquo;idea principale Ã¨ la distinzione fra collezione vs individuo, che implica anche un utilizzo di metodo HTTP diverso. Per distinguere collezioni da individui dobbiamo mettere il plurale e terminare con lo slash (che direi anche sia una cosa molto strana!)\nQueste entitÃ  cosÃ¬ definite possono essere anche gerarchiche, quindi uno impilato sull\u0026rsquo;altro, ma sembra tenere a mente la semplicitÃ  dell\u0026rsquo;interfaccia e della navigazione.\nOpen API Questa parte Ã¨ molto pÃ¬u pratica, andiamo direttamente ad impararla da lÃ¬!\nOpen api Ã¨ una sintassi di solito scritta in YAML presentato molto velocemente in HTML e Markup nella sezione di markup, permette di specificare in modo molto chiarlo l\u0026rsquo;interfaccia di un API, e la creazione della documentazione associata.\nDi solito questo Ã¨ il modello preferito (industry standard) per creare queste cose, rende molto chiara la comunicazione delle api diciamo, per il progetto potrebbe essere un buon metodo per interagire col database? Oppure meglio farci richiesta diretta con un ORM. Credo sia molto simile.\n","permalink":"https://flecart.github.io/notes/http-e-rest/","summary":"Ripasso Prox: 40 Ripasso: May 25, 2023 Ultima modifica: April 15, 2023 10:21 PM Primo Abbozzo: March 10, 2023 2:16 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso HTTP e REST HTTP HYPERTEXT-TRANSFER-PROTOCOL\nCaratteristiche principali (3) ðŸŸ¨ Slide caratteristiche\nComunicazioni fra client e server, e quanto sono comunicate le cose si chiude la connessione e ci sono politiche di caching molto bone (tipo con i proxy) Generico: perchÃ© Ã¨ un protocollo utilizzato per caricare moltissime tipologie di risorse!","title":"HTTP e REST"},{"content":"This is a theory from developmental psychology. It concerns about how a child is learning from a teacher. I discovered this field with (Gweon et al. 2023). But it is quite difficult to know how this could be useful for machines (not enough technical details about how).\nThe main idea is that\nChildrens need to infer about teacher\u0026rsquo;s mental states to learn (I don\u0026rsquo;t know if this is true, but personally I don\u0026rsquo;t think is always true, you can learn with just a book, inferring mental states is not a necessity) Teacher\u0026rsquo;s need to choose the best example. References [1] Gweon et al. â€œSocially Intelligent Machines That Learn from Humans and Help Humans Learnâ€ Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences Vol. 381(2251), pp. 20220048 2023\n","permalink":"https://flecart.github.io/notes/inferential-social-learning/","summary":"This is a theory from developmental psychology. It concerns about how a child is learning from a teacher. I discovered this field with (Gweon et al. 2023). But it is quite difficult to know how this could be useful for machines (not enough technical details about how).\nThe main idea is that\nChildrens need to infer about teacher\u0026rsquo;s mental states to learn (I don\u0026rsquo;t know if this is true, but personally I don\u0026rsquo;t think is always true, you can learn with just a book, inferring mental states is not a necessity) Teacher\u0026rsquo;s need to choose the best example.","title":"Inferential Social Learning"},{"content":"Ripasso Prox: 20 Ripasso: June 4, 2022 Ultima modifica: 11 Marzo, 2024 12:08 PM Primo Abbozzo: March 7, 2022 1:34 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nAnalisi multi-variabile In questo capitolo cerchiamo di andare oltre alla singola dimensione per l\u0026rsquo;analisi.\nIntroduzione\nLo spazio R^n Possiamo definire uno spazio Rn come il prodotto cartesiano fra l\u0026rsquo;insieme R un numero di volte uguale a n $\\mathbb{R} \\times \\mathbb{R} \\times ... \\times\\mathbb{R} = \\mathbb{R}^n$\nAllora un tipico elemento in Rn Ã¨ nella forma $(x_1,...,x_n)$, questo elemento si chiama punto, mentre gli elelmenti in R che costituiscono questo elemento si chiamano componenti.\nOsservazione\nLa maggior parte dei risultati che dimostro nello spazio ordinario (R3) si puÃ² dimostrare per Rn, non andiamo piÃ¹ nel dettaglio perchÃ© i problemi che ho in spazi maggiori sono parte di materiale per analisi 2\nOperazioni definite In modo simile a quanto definito negli Spazi vettoriali abbiamo principalmente due operazioni principali definite (in moto identico a quanto spiegato nell\u0026rsquo;altro documento) che sono:\nl\u0026rsquo;addizione vettoriale la moltiplicazione scalare. In piÃ¹ aggiungiamo una operazione che non Ã¨ presente nel documento degli spazi vettoriali ma che Ã¨ importante in questo momento.\nProdotto scalare euclideo, definito qui sotto Il prodotto scalare euclideo Dati due elementi in Rn, che chiamiamo x e y, rispettivamente di componenti $x_1, ...,x_n$ e $y_1, ...,y_n$\n$$ \\langle x,y\\rangle = x\\cdot y\\coloneqq\\sum_{i=1}^nx_iy_i $$ Possiamo individuare 3 proprietÃ  principali per questo prodotto scalare (nota il significato x,y con parentesi cambia in algebra lineare rispetto a questo. (chiamo in questo caso x primo argomento e y secondo argomento).\nSimmetria, se scambio x con y il risultato resta lo stesso $x\\cdot y = y \\cdot x$ DistributivitÃ  (linearitÃ  del primo argomento) $\\forall x,y,z \\in \\mathbb{R}^n, \\forall \\lambda, \\mu \\in \\mathbb{R} (\\lambda x + \\mu y) \\cdot z = \\lambda(x\\cdot z) + \\mu(y \\cdot z)$ Utilizzando la simmetria puoi dimostrare anche la linearitÃ  per il secondo argomento. PositivitÃ  del riflessivo: $\\forall x \\in \\mathbb{R}^n , x\\cdot x \\geq 0$, e si puÃ² osservare che $x\\cdot x = 0 \\iff x = 0_v$ Prodotto scalare nella forma col coseno\nDato un elemento $x \\in \\mathbb{R}^{2}$, posso dire che $x = \\lvert x \\rvert \\dfrac{x}{\\lvert x \\rvert}$ notiamo che il secondo fattore ha lunghezza 0, quindi possiamo scriverlo tramite una coordinata polare, qualcosa tipo $\\dfrac{x}{\\lvert x \\rvert} = (\\cos \\theta, \\sin \\theta)$. Quindi se prendo un $x \\neq 0$ possiamo dire che $x = (|x|\\cos \\theta, |x| \\sin \\theta), \\theta \\in \\mathbb{R}$\nAllora se prendo due vettori scriviamo cosÃ¬! $$ x \\cdot y = \\lvert x \\rvert \\lvert y \\rvert \\cos \\theta \\cos \\gamma + \\lvert x \\rvert \\lvert y \\rvert\\sin \\theta\\sin \\gamma = \\lvert x \\rvert \\lvert y \\rvert(\\cos(\\theta - \\gamma)) $$ che Ã¨ esattamente la formula che abbiamo visto alle superiori, il prodotto delle singole norme per il coseno dell\u0026rsquo;angolo fra i due.\nOrtogonalitÃ  Si puÃ² definire l\u0026rsquo;ortogonalitÃ  di due vettori a seconda del risultato del loro prodotto scalare $x,y$ perpendicolari $\\implies x \\cdot y = 0$ Da questo si puÃ² notare che il vettore nullo Ã¨ perpendicolare a ogni vettore.\nNorma di un vettore Scopriremo in seguito che la norma Ã¨ strettamente collegata con la lunghezza di un vettore, la definiamo in questo modo:\n$\\lVert x\\rVert = \\sqrt{x\\cdot x} = \\sqrt{x_1^2 + ... + x_n ^2}$\nPuoi notare come questo sia esattamente la distanza.\nProprietÃ \n$|\\lambda|\\lVert x\\rVert = \\lVert\\lambda x\\rVert$ $\\rVert x \\lVert \\geq 0$ e anche l\u0026rsquo;altro con 0, esattamente come per la propreitÃ  3 del prodotto scalare vettoriale Disuguaglianza triangolare $\\lVert x \\cdot y \\rVert \\leq |x| |y|$ Normalizzazione\nPer la proprietÃ  1 possiamo sempre normalizzare un vettore, ovvero moltiplicarlo per un reale tale che la somma dei componenti Ã¨ 1. Per trovare questo valore basta trovare il valore nella norma attuale $\\lambda$ e dividere ogni componente per questo valore. esempio $(3,4)$ noto che la norma Ã¨ 5, quindi questo punto normalizzato Ã¨ $(\\dfrac{3}{5}, \\dfrac{4}{5})$\nIl quadrato della norma cerchiamo di calcolare questo valore $||x + y|| ^2$ Per definizione si ha\n$$ \\lvert x + y \\rvert^ 2 = \\left( \\sqrt{ \\sum_{i=1}^n (x_i + y_i) ^2} \\right)^2 = \\sum_{i=1}^n (x_i + y_i) ^2 = \\sum_{i=1}^n (x_i^2 + 2x_iy_i + y_i^2) = \\lvert x \\rvert ^2 + 2x\\cdot y + \\lvert y \\rvert ^2 $$ Si puÃ² anche dimostrare tramite le propreitÃ  2 del prodotto scalare e l\u0026rsquo;additivitÃ , dimostrare in questo modo per esercizio (oppure chiedere a qualcuno che era in classe).\nOsservazione: Si puÃ² notare che se i due vettori sono perpendicolari si ritrova il teorema di Pitagora in quanto\n$x \\cdot y = 0$\nDisuguaglianza di Cauchy-Schwarz Siano x,y vettori in $\\mathbb{R}^n$, allora vale che\n$\\lvert x \\cdot y\\rvert \\leq \\lvert x \\rvert \\lvert y \\rvert$ dove uguale si ha sse x e y sono dipendenti. Dimostriamolo nel caso in cui n = 2, per n superiori dovrebbe essere analogo, prendiamo due valori come qui, allora ho che $\\lvert x \\cdot y\\rvert = \\lvert \\lvert x \\rvert \\lvert y \\rvert\\cos(\\theta - \\gamma) \\rvert \\leq \\lvert x \\rvert \\lvert y \\rvert$ osservando il coseno, questo Ã¨ sempre compreso fra -1 e 1 quindi Ã¨ ovvio che sia sempre minore. ed Ã¨ ovvio che sono uguali nel momento in cui coseno Ã¨ 0, quindi i due vettori sono dipendenti.\nQuesto poi si puÃ² espandere con spazi Hilbertiani e simili, ma non li conosco bene.\nDimostrazione disuguaglianza triangolare da CS\n$\\lvert x + y \\rvert \\leq \\lvert x \\rvert + \\lvert y \\rvert \\iff \\lvert x\\cdot y\\rvert \\leq \\lvert x \\rvert\\lvert y \\rvert$ fai il prodotto e guarda i calcoli\nProdotto e calcoli $\\lvert x + y \\rvert \\leq \\lvert x \\rvert + \\lvert y \\rvert \\implies \\lvert x + y \\rvert^2 \\leq (\\lvert x \\rvert + \\lvert y \\rvert)^2 \\implies \\lvert x \\rvert^2 + 2x\\cdot y + \\lvert y \\rvert ^2 \\leq \\lvert x \\rvert^2 + 2\\lvert x \\rvert\\lvert y \\rvert + \\lvert y \\rvert^2$ e cancellando opportunamente nell\u0026rsquo;ultimo passaggio, Ã¨ banale la deduzione. Teorema di Pitagora Anche questa Ã¨ una derivazione senza molti problemi in quanto basta la forma del quadrato della norma e il fatto che sono perpendicolari per dire che Ã¨ uguale a 0.\nDistanza fra due punti Possiamo definire la distanza fra due punti come la norma del vettore differenza:\n$Dist(x, y) = \\lVert x - y \\rVert$ (il che ha senso, perchÃ© la differenza mi da un vettore differenza, mentre la norma mi da la lunghezza di questo vettore, ignorando il verso e la direzione, quindi riesco ad ottenere una distanza).\nInsiemi e intorni Intorno sferico Andiamo a definire la nozione di intorno sferico\n$I_r(x)$ Ã¨ l\u0026rsquo;insieme di punti che distano al piÃ¹ r da x, ossia $\\{y \\in \\mathbb{R}^n ,t.c., \\lvert x - y\\rvert \u003c r\\}$\nSi puÃ² notare poi che questa forma dal punto di vista geometrico definisce una sfera in 3 dimensioni, un disco in 2, un intervallo in 1. Analogamente si possono definire i punti di un cerchio con piÃ¹ dimensioni in questo modo.\nInsieme limitato Un insieme $A$ si dice limitato se $\\exists k \u003e 0, k \\in \\mathbb{R},$ $A \\subseteq I_k(0)$. Quindi Ã¨ contenuto all\u0026rsquo;interno di una area ben definita.\nUna funzione che ha dominio fino ad infinito per esempio 1/x non Ã¨ limitato perchÃ© non riesco mai a rinchiuderlo, ma una macchia a caso invece si puÃ² racchiudere.\nInsieme aperto Un insieme si dice aperto se per qualunque punto esiste un contorno abbastanza piccolo che Ã¨ contenuto nell\u0026rsquo;insieme (cosa che non succede per un insieme chiuso, se prendo un punto nel bordo non trovo tale intorno).\nSuccessioni generali Definizione $(x_n)_{k \\in \\mathbb{N}}: x_k \\in \\mathbb{R}^n, \\forall k \\in \\mathbb{N}$ si potrebbe quindi sempre vedere come una funzione che va da $\\mathbb{N} \\to \\mathbb{R}^n$\nConvergenza delle successioni (classica) Una successione converge in un punto in Rn, se ogni suo componente tende alla componente corrispondente del punto di convergenza.\nEs, suppongo che f tenda a un $x_0, y_0$ allora voglio dire che il limite per x tende a x0, anche limite per y tende a y0.\nConvergenza secondo distanza Se si utilizza la convergenza secondo la nozione di stanza, allora questo assume una forma molto simile alla nozione di convergenza per i numeri reali.\n$x_k \\to x \\in \\mathbb{R}^n \\iff \\lvert x_k - x\\rvert \u003c \\epsilon, \\forall \\epsilon \u003e0$ ossia quella distanza tende a 0.\nFunzioni con piÃ¹ variabili Definizione $A\\subseteq \\mathbb{R}^n , B \\subseteq \\mathbb{R}^n, f: A \\to B, ,,Graf(f) = \\{(x, f(x)) \\in A \\times B \\}$ quindi alla fine Ã¨ sempre la classica definizione di insieme, ma con dominio e codominio diversi\n$Im(f) = (f(x) | x \\in A)$\nCategorie di funzioni Funzioni scalari\n$\\mathbb{R}^n \\to \\mathbb{R}$\nFunzioni curve o cammini\n$\\mathbb{R} \\to \\mathbb{R} ^n$\nContinuitÃ  $\\forall (x_k)_{k \\in \\mathbb{N}} x_k \\to x, \\text { si ha che } f(x_k) \\to f(x)$ rispettivamente utilizzando i domini e codominio corretti (questa sarebbe anche una definizione utile per la continuitÃ  normale, ma stiamo utilizzando l\u0026rsquo;equivalenza che ci danno le successioni).\ntutte le funzioni elementari sono continue (come le hai sempre viste)\nPossiamo anche scrivere una funzione di continuitÃ  utilizzando gli intervalli (praticamente uguale a quella classica):\n$f: A \\to B$ Ã¨ continua in $\\bar{x}$ se ho che $\\iff \\forall \\epsilon \u003e 0\\exists \\gamma \u003e0 t.c. \\lvert f(y) - f(\\bar{x}) \\rvert \u003c \\epsilon, \\text { con } x\\in A \\lvert x - \\bar{x} \\rvert \u003c \\gamma$\nOSSERVAZIONI\nsi dimostra che tutti gli insiemi definiti con disuguaglianze strette sono aperti.\novvero $f_1,...f_n$ una successione di funzioni $\\mathbb{R}^n \\to \\mathbb{R}$, continue si ha che $A = \\{x \\in \\mathbb{R}^n \\mid f_1(x) \u003e c_1, ..., f_n(x) \u003e c_n\\}$ si ha che A Ã¨ aperto per questo teorema che non si dimostra nel nostro corso, perÃ² si ha che Ã¨ vero.\nFunzione radiale Una funzione si dice radiale se $f: \\mathbb{R}^2 \\to \\mathbb{R} t.c. \\exists g: [0, +\\infty[ \\to \\mathbb{R}$ tale che $f(x,y) = g(\\lvert x,y\\rvert)$\nIntuizione\nOvvero possiamo dire radiale se possiamo scriverlo solo in funzione dalla sua distanza dall\u0026rsquo;origine (spesso sono superficie di rotazione)\nDi solito Ã¨ comodo avere queste funzioni perchÃ© mi semplificano subito l\u0026rsquo;analisi.\nAltro esempio: $f(x,y) = e ^{-(x^2 + y^2)} \\implies g(t) = e ^{ -t^2}$ che basta disegnare g e poi ruotarlo sull\u0026rsquo;asse delle y.\nInsiemi di livello Dato un insieme $A \\subseteq \\mathbb{R}^2$ e una funzione $f: A \\to \\mathbb{R}$ e dato un punto $b \\in \\mathbb{R}$ allora si dice insieme di livello $b$ di $f$ l\u0026rsquo;insieme $L_b = \\{ (x, y) \\in A \\mid f(x,y) = b\\}$ in pratica Ã¨ la pre-immagine della funzione (come se fosse $f^{-1}$).\nQuindi la stessa cosa in una dimensione, ma col nome diverso, perchÃ© dal punto di vista livello, l\u0026rsquo;insieme di livello Ã¨ come un taglio del dominio verso un certo punto.\nDi solito si trova una curva di livello, una curva lineare che rappresenta questo insieme (percorrendo questo punto, il valore in output resta lo stesso, come se mi stessi muovendo parallelamente a una montagna senza salire e senza scendere.\nPiani I piani sono nella forma $f(x,y) = ax + by + c$, Ã¨ abbastanza ovvio, perchÃ© in R2 rappresenta una retta, se ho una retta ma posso variare z come mi pare, allora ovvio che si ha il piano\u0026hellip;\n","permalink":"https://flecart.github.io/notes/analisi-multi-variabile/","summary":"Ripasso Prox: 20 Ripasso: June 4, 2022 Ultima modifica: 11 Marzo, 2024 12:08 PM Primo Abbozzo: March 7, 2022 1:34 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nAnalisi multi-variabile In questo capitolo cerchiamo di andare oltre alla singola dimensione per l\u0026rsquo;analisi.\nIntroduzione\nLo spazio R^n Possiamo definire uno spazio Rn come il prodotto cartesiano fra l\u0026rsquo;insieme R un numero di volte uguale a n $\\mathbb{R} \\times \\mathbb{R} \\times ... \\times\\mathbb{R} = \\mathbb{R}^n$","title":"Analisi multi-variabile"},{"content":"Ultima modifica: January 4, 2023 9:56 AM Primo Abbozzo: December 26, 2021 11:42 AM Studi Personali: No\nElementi di ripasso 2 Autovalori e Determinanti Determinanti I determinanti sono un numero associato alle matrici quadrate. PiÃ¹ o meno ne sono il riassunto.\nProprietÃ  Le prime 3 sono quelle fondamentali per calcolare il tutto, i numeri dopo il 3 sono alcune conseguenze.\ndet I = 1\nCambiare righe â†’ cambiare il segno della determinante.\n(Importante)\nSe moltiplico una riga per una costante, il determinante Ã¨ moltiplicato per questa costante. Se sommo una costante a una riga, allora il determinante Ã¨ una somma strana\u0026hellip; Immagine di esempio\nSe la matrice ha due righe uguali, il determinante Ã¨ 0, questo Ã¨ derivabile dalla proprietÃ  2.\nSottrarre un multiplo di una riga a una altra riga della matrice produce la stessa determinante. (in pratica sto sottraendo una matrice che ha due righe uguali, la cui determinante Ã¨ 0).\nUna riga di 0 implica che il determinante dellâ€™intera matrice sia 0, questo si puÃ² dimostrare con 3a.\nData una matrice uppertriangular, il determinante Ã¨ la moltiplicazione degli elementi nella diagonale principale. (posso ottenere una matrice diagonale sottraendo allâ€™insÃ¹, e poi posso tirare fuori multipli per riga).\nLâ€™ultima proprietÃ  ci dice come si fa a calcolare il determinante, ossia ridurre in forma U e poi moltiplicare la diagonale. Ez. (da tenere in conto anche possibili cambi di riga).\ndet A = 0 quando A Ã¨ singolare (possiede una riga di 0) e det A â‰  0 quando non lo Ã¨ il determinante del prodotto di due matrici Ã¨ il prodotto delle determinanti delle due matrici, Ã¨ un isomorfismo! Questa proprietÃ  ci dÃ  anche il determinante dellâ€™inverso in modo immediato, questo ci dÃ  anche un modo immediato per trovare lâ€™inversa di una matrice diagonale (basta invertire tutti i numeri ðŸ™‚) e questo Ã¨ anche un motivo per cui se invertibile not 0, altrimenti divido per 0. determinante della transposizione di A Ã¨ uguale al determinante di A, in quanto se ragioniamo nella forma diagonale la transposizione Ã¨ esattamente uguale ad A. Calcolo Possiamo splittare il calcolo della determinante in somme piÃ¹ semplici. Inoltre possiamo notare che un determinante Ã¨ diverso da nullo, per la proprietÃ  8 se non Ã¨ singolare, quindi vogliamo avere un elemento per ogni colonna e riga.\nContinuando questo ragionamento possiamo cercare di riassumere tutto in una unica formula\n$$ \\det A = \\sum_{\\text{n! sums}} P(\\alpha, \\beta, ..., \\omega) a_{1\\alpha} a_{2\\beta}...a_{n\\omega}\\\\ \\{\\alpha,\\beta, ..., \\omega\\} \\in \\text{ Perm of } \\{1,2,3...,n\\}, \\text{ where } A \\text{ is } n \\times n \\\\ P(\\alpha, \\beta, ..., \\omega) =\\begin{cases} 1 \\text{ if it's even permutation } \\\\ -1 \\text{ if it's odd permutation } \\end{cases} $$ Determinante come volume Per esempio se prendiamo una matrice 3x3, possiamo prendere ogni punto identificato da una riga come 3 punti. Questi tre punti riescono ad identificare una scatola. (ogni lato Ã¨ un parallelogramma e il volume del cubo Ã¨ uguale al determinante).\nCofattori I cofattori sono utili per semplificare il calcolo della determinante presentata in precedenza.\nIn altre parole si potrebbe dire che il determinante di una matrice quadrata grossa si potrebbe ridurre come una combinazione lineare di alcune sottomatrici.\nDeterminante con cofattori Quindi il calcolo del determinante si puÃ² riassumere come\n$$ \\det A = \\sum_{i=1}^{n} a_{1i}C_{1i} $$ Inverse con cofattori Si potrebbe notare che questo sia il metodo matematico per lâ€™inverso, mentre le eliminazioni con il metodo di Gauss Jordan Ã¨ il metodo piÃ¹ informatico.\n$$ A^{-1} = \\dfrac{1}{\\det A} C^T $$ Che Ã¨ equivalente nel verificare che\n$$ \\det A \\cdot I = A C^T $$ E questo ha senso, se moltiplico per righe corrispondenti ho la formula sopra per il determinante per riga.\nMentre se lo faccio per tutte le altre righe Ã¨ come se stessi calcolando il determinante con una riga doppia, quindi il determinante Ã¨ 0 per quelle righe.\nSe utilizzo questo risulato, posso derivare la formula di cramer\nRegola di cramer $$ Ax = b \\\\ x = A^{-1}b \\\\ x = \\dfrac{1}{\\det A} C^T b $$ Questo Ã¨ code rimpiazzare la prima colonna della matrice A con b\nQuesto algoritmo Ã¨ lentissimo, costa molto calcolare un determinante.\nAutovettori gli autovettori sono i vettori di Ax che sono nella stessa direzione di x.\nPossiamo scriverlo come $Ax = \\lambda x$ e ho che lambda Ã¨ un autovalore\nSembra che\nLa somma degli autovalori Ã¨ uguale alla somma delle diagonali Una matrice di dimensioni n n ha n autovettori Autovettori e autovalori di proiezione Nellâ€™esempio di una proiezione, un autovettore sarebbe stato xa in quanto sarebbe giÃ  nello spazio colonna in arrivo, quindi non viene proprio modificato.\nMa non solo questi sono degli autovettori, ma anche i vettori che sono perpendicolari (hanno autovalore 0, perchÃ© vengono totalmente distrutti).\nCosÃ¬ abbiamo trovato gli autovalori per una matrice di proiezione che sono 0 e 1\nLa ricerca di autovettori: equazione dellâ€™autovalore Possiamo riscrivere lâ€™equazione in questo modo:\n$$ (A - I\\lambda)x = 0 $$ Quindi stiamo cercando soluzioni nello spazio nullo di una nuova matrice, che Ã¨ interessante solamente se questa matrice Ã¨ singolare, ossia che abbia una determinante uguale a 0\nCerchiamo le soluzioni di $\\det (A - I\\lambda) = 0$ per lambda i una nuova matrice, che Ã¨ interessante solamente se questa matrice Ã¨ singolare, ossia che abbia una determinante uguale a 0\nCerchiamo le soluzioni di $\\det (A - I\\lambda) = 0$ per lambda\n","permalink":"https://flecart.github.io/notes/autovettori-e-determinanti/","summary":"Ultima modifica: January 4, 2023 9:56 AM Primo Abbozzo: December 26, 2021 11:42 AM Studi Personali: No\nElementi di ripasso 2 Autovalori e Determinanti Determinanti I determinanti sono un numero associato alle matrici quadrate. PiÃ¹ o meno ne sono il riassunto.\nProprietÃ  Le prime 3 sono quelle fondamentali per calcolare il tutto, i numeri dopo il 3 sono alcune conseguenze.\ndet I = 1\nCambiare righe â†’ cambiare il segno della determinante.","title":"Autovettori e determinanti"},{"content":"Ripasso Prox: 40 Ripasso: May 14, 2023 Ultima modifica: May 14, 2023 5:18 PM Primo Abbozzo: March 2, 2023 4:19 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nCodifica dei caratteri Sull\u0026rsquo;encoding Introduzione ðŸŸ© Ossia trattiamo metodi per codificare caratteri dei linguaggi umani, come ASCII, UCS e UTF.\nDigitalizzare significa encodarlo in un sistema che possa essere memorizzato su un dispositivo di memorizzazione elettronico. Ovviamente non possiamo mantenere l\u0026rsquo;informazione cosÃ¬ come Ã¨, ma vogliamo memorizzarne una forma equivalente, ma piÃ¹ facile da manipolare dal punto di vista del computer. Creiamo quindi un mapping, o anche isomorfismo tra il valore di mappatura (o encoding), solitamente un valore numerico, tra il singolo valore atomico originale e il numero.\nEsempi di cose atomiche per encoding sono:\nCarattere per le parole Pixel per le immagini Sequenza sinusoidale per FFT per il suono o la musica. Vogliamo creare un mapping non ambiguo, quindi uno standard Ã¨ necessario!.\nSulle differenze linguistiche (non fare) ðŸŸ¨ Ma come fare a creare uno standard che possa essere adatto sia a caratteri arabi, inglesi, cirillici, cinesi coreani o giapponesi?\nSulle caratteristiche linguistiche diverse\nLa scrittura non Ã¨ in grado di rappresentare il suono della lingua in modo univoco per tutti i linguaggi (esempi accenti in certe lingue, come l\u0026rsquo;italiano, oppure il fatto che lâ€™inglese molte pronuncie sono diverse rispetto a quanto si scrive), Danese cambia proprio suono. In ebraico contano solamente le consonenti, le vocali sono solamente un ausilio per la pronuncia.\nArabo ha una forma di corsivo, e la forma del carattere dipende dai caratteri che sono di fianco.\nSecondo ragionamento sulle caratteristiche delle lingue diverse\nOssia puÃ² cambiare proprio la semantica della parola, a seconda della lingua in cui si interpretano gli stessi caratteri. Quasi il linguaggio si potrebbe intendere una funzione di interpretazione semantica , accennato in Logica Proposizionale.\nLa ricerca dello spazio di rappresentazione (3) ðŸŸ©- ci interessano in partioclare tre caratteristiche per trovare lo spazio di rappresentazione per i nostri caratteri (che comunque rientrano nei numeri, e sono tutti in $\\N$).\nSlide\nContiguitÃ  (se ho certi numeri che hanno un certo senso allâ€™interno di un) Raggruppamento logico (se hanno funzioni simili vorremmo che siano ancora vicini) Ordine, vorremmo seguire lâ€™ordine alfabetico per questo encoding. (credo il motivo di questa scelta Ã¨ affinchÃ© sia un pÃ² piÃ¹ naturale!) Altre caratteristiche che fanno parte dell\u0026rsquo;encoding (che Ã¨ una funzione parziale)\nShift: un codice riservato che cambia mappa da adesso in poi. Lo stesso shift o un secondo carattere di shift, puÃ² poi far tornare alla mappa originaria Codici liberi: codici non associati a nessun carattere. La loro presenza in un flusso di dati indica probabilmente un errore di trasmissione. Codici di controllo: codici associati alla trasmissione e non al messaggio. Standard passati Stardard poco utilizzati (non importante) ðŸŸ¥ Baudot\nUna codifica vecchissima, che nessuno usa, e io non ho mai sentito (siamo circa nel 1850).\nEBCDIC\nSlide\nISO 656-1991\nQuesto Ã¨ presente nelle slides ma completamente saltato\nASCII e ISO Latin 1 ðŸŸ©- American Standard Code for Information Interchange.\nSono 7bit utilizzate e uno come bit di paritÃ . Questo mette uno standard fra codifiche fra telescriventi e schede perforate che erano molto presenti all\u0026rsquo;epoca. Ed Ã¨ solamente alfabeto latino inglese.\nORIGINE BACKSPACE DELETE, CR E LF\nNella telescrivente avevo bisogno di backspace, per eliminare un carattere. Nelle schede perforate utilizzavo tutti i buchi presenti per significare che non avevo questo carattere, ecco la delete.\nCarriage return, nella telescrivente avevo una testina che andava avanti a scrivere, e bisognava farlo tornare indietro, e per far girare la testina utilizzavo Line-feed.\nEstensioni custom:\nDopo un pÃ² lâ€™hardware Ã¨ diventato molto affidabile, quindi utilizziamo il bit in piÃ¹ per memorizzare un codice come ci Ã¨ piÃ¹ comodo. sono le Codepage di ASCII, e ognuno si fa una propria versione.\nGreco\nCirillico\nArabo\nMa nessuno di questo Ã¨ standard! L\u0026rsquo;unico forse Ã¨ ISO Latin 1\nCaratteri orientali e testi multilingua ðŸŸ© CODIFICA DEI CARATTERI ORIENTALI\nMa per il cinese non Ã¨ possibile mettere tutto in un singolo byte, Quindi utilizzano due byte qui.\nMa anche con due byte non Ã¨ possibile avere tutti i caratteri nella lingua, per questo motivo metto solamente i caratteri piÃ¹ utilizzati\nCodifiche cinese giapponesi e coreani\nSlide alfabeti CJK\nIL PROBLEMA DEI TESTI MULTILINGUA\nMa cosa succede se ho un testo multilingua? Come faccio a codificarlo in modo disambiguato?\nDichiarazioni esterne (no, sarebbe per lâ€™intero documento, dovrei utilizzare un markup per specificarti lâ€™encoding?? Troppo brutto) Intestazioni interne (sarebbe molto scomodo dover stabilire ogni volta che encoding sia!) Dovrei forse spezzettartelo in troppi modi. Per questo motivo bisognerebbe creare un nuovo encoding, ed Ã¨ questo quello che viene fatto in Unicode.\nUnicode e Universal Transformation Format Unicode e ISO/IEC 10646 (storia) ðŸŸ¨+ UN PO DI STORIA\nQuesti due standard sono nati per fare le stesse due cose, senza sapere che facevano la stessa cosa. (UNICODE Ã¨ sponsorizzato dai produttori di hardware, ISO Ã¨ internazionale ed Ã¨ spinto dalle nazioni estere).\nIl problema principale che vanno a risolvere Ã¨ quello di essere standard unico per tutti i linguaggi, per esempio in questo modo posso scrivere testo in lingua mista senza darmi troppi problemi!\nHanno avuto una difficoltÃ  ad universi quando l\u0026rsquo;uno ha scoperto dellâ€™esistenza dellâ€™altro. Poi sono andati a convergere, ossia sono ancora dâ€™accordo con lâ€™encoding presente.\nCOSA Ãˆ ENCODATO\nCosÃ¬ sono nate UCS-2/4 e UTF-8/16/32 che rappresentando rispettivamente una codifica fissa o variable. Questi sono in grado di rappresentare codici di tutti i codici passati!\n3 categorie di cose encodate\nEsempi di codici encodati\nCon tanto spazio disponibile possiamo anche encodare i linguaggi di star trek e Lord of the ring, perÃ² non potevano includere questi linguaggi in uno standard, comunque Ã¨ possibile encodarli in uno Private Use Area (6400 di base, che sono quelli inizialmente utilizzate per klingon o Lord of ring) e poi 65k liberi.\nSlide\nPrincipi di unicode (10) (troppi, a memoria non va bene)ðŸŸ¥+ In pratica tutti i caratteri di Unicode sono distinti per semantica, caratteri (quindi la sharfes es tedesca o versione greca sono codici diversi), se ho una P in alfabeti diversi hanno codifiche diverse. Non ho cose riguardanti la grafica!.\nla Composizione dinamica Ã¨ una cosa molto cool, per esempio Ã¨ quello che sto utilizzando ora, il fatto che scrivo `e, e mi appare la Ã¨ accentata.\nSlides\nUniversal Coded Character/UNICODE ðŸŸ©- Universal Coded Character same as UCS-2 UCS-4\nIn UCS-4 il primo bit Ã¨ utilizzato per identificare la differenza fra UTF-8 e UCS-4.\nSlide struttura generale\nIl piano 14 Ã¨ in disuso, per tag strani.\nBasic Multilingual Plane (BMP) sono tutti i caratteri nel piano 0, sono quelli piÃ¹ comuni per alfabeti west\nEsempio suddivisione dei piani\nQuesto Ã¨ una cosa svantaggiosa per i caratteri latini che andavano giÃ  bene con un singolo byte per trasmettere, ecco che entra in gioco il UTF.\nUnicode Trasformation Format ðŸŸ©- Ãˆ una forma variabile per la rappresentazione precedente, il motivo principale per cui esiste Ã¨ che per gli americani sarebbe stata una perdita enorme dover aggiugnere quellâ€™overhead inutile nella loro trasmissione, loro con 256 restavano giÃ  bene.\nSlide necessitÃ  di UTF\nSPAZI DI CODIFICA IN UTF\nASCII Ã¨ compatibilissimo per UTF, in 2 byte ho tutti il resto dei caratteri. in 3 byte stanno tutti i caratteri CJK, in 4 byte stanno tutti i caratteri antichi.\nSlide numero di byte necessari per la codifica\nSTRUTTURA DEI CARATTERI UTF\nEssendo questa una codifica variabile non ho possibilitÃ  di predire il numero di caratteri in un file, perchÃ© certi caratteri occuperanno un byte (ASCII normale), mentre altri caratteri occuperanno due byte, come le lettere accentate.\nAllora devo utilizzare un codice per capire se sono allâ€™inizio del blocco o sto continuando, o lo devo droppare (quando ricevo 10, ma non ho nessun blocco iniziato!) (sono gli schemi di 10, 0, e 110 etc..)\nLa cosa importante Ã¨ che ASCII Ã¨ subset diretto di UTF, dato che i caratteri latini sono sempre un singolo byte.\nConfronto UTF e UCS\nAlcuni problemi di trasmissione e conversione Byte order mark ðŸŸ© Utilizzato per risolvere il problema di risolvere se interpretare quanto mandato in Little o big endian.\nUtilizziamo un carattere speciale in unicode, chiamato Zero-Width No-Break Space (ZWNBSP), Il cui codice Ã¨ FEFF per capire se il sistema che mi sta mandando qualcosa Ã¨ in formato little endian oppure big endian, accennato qui (molto importante per l\u0026rsquo;ordinamento!)\nSlide\nUTF-8 vs Latin-1 ðŸŸ© Si possono avere problemi di conversione fra questi due standard (perchÃ© latin 1 utilizza un singolo byte per le cose accentate, mentre utf-8 ne utilizza due).\nSlide problemi comuni di conversione\nContent encoding Escaping ed encoding ðŸŸ© La necessitÃ  di fare encoding o escaping Ã¨ giustificata principalmente dal fatto che certe applicazioni utilizzano certi caratteri come simboli speciali (e quindi non si potrebbe utilizzarli, un esempio Ã¨ lâ€™andare accapo credo).\nIn pratica si utilizzano questi metodi per aggirare quelli\nEscaping\nOssia sostituiamo il carattere proibito con sequenze alternative che corrispondono alla stessa cosa. Ad esempoio \u0026amp;quot rappresentano le virgolette\n3\nEncoding quando utilizzo una sintassi speciale per rappresentare il suo encoding naturale.\nSlides encoding ed escaping\nMIME I Limiti di SMTP (3) SMTP Ã¨ un protocollo molto vecchio, affinchÃ© le necessitÃ  nuove siano retrocompatibili, sono presenti alcuni accorgimenti che vedremo in sto pezzo.\nPrincipalmente questi problemi di endoing e escaping sono nati nellâ€™ambiente del protocollo SMTP, perchÃ©e li câ€™erano alcuni caratteri speciali del protocollo, e potevi mandare solamente ascii 7 bit.\nslides limiti SMTP\nMassimo 1 MB Solo ascii 7 bit Ogni 1000 caratteri ci deve essere un CRLF. Il motivo Ã¨ che queste restrizioni erano presenti nelle RFC iniziali per SMTP, e dato che non possiamo farne nuovi (troppo costo prolly) ci dobbiamo tenere queste cose.\nGuardare internet message format\nSu come funziona SMTP sono accennate in Livello applicazione e socket\nMultipurpose Internet Mail Extensions ðŸŸ© il mime riesce a risolvere questi problemi di limiti di SMTP, riesco a trasformare il tutto in un formato compatibile, e riesco anche a ritrasformarlo indietro!\nSchema protocollo MIME\nIn questo modo riesco a risolvere tutti i problemi di limiti SMTP\nCaratteri ASCII US Le sequenze CRLF E la lunghezza dei messaggi (che viene spezzato) TODO: parlare del multitipo\nHeaders del MIME (2)ðŸŸ¨ Esempio di headers MIME\nDevono essere specificati due campi:\nContent Type (il tipo del dato, con sottotimo e altri parametri utili che viene mandato, per capire poi dal ricevente cosa conviene convocare per capire il messaggio) Content-Transfer encoding, sono modalitÃ  per codificare i dati in modo che possano essere adatti al MIME. Esempi di transfer encoding sono sotto. Quoted Printable and Base 64 ðŸŸ© Esempi di CTE sono quoted-printable, BASE64, nel primo si fanno escaping per caratteri che non sono printabili con un = seguito dal numero corrisopndente al carattere, di solito sono utilizzati solamente per messaggi con poche eccezzioni rispetto ASCII\nSlide Quoted-printable\nBASE64 da leggere BaseSessantaquattro, o BeisSicstiFor, non mix.\nPer BASE Ã¨ tutto tradotto in una codifica byte printabile, ossia si utilizzano 64 caratteri ASCII printabili per codificare 3 byte alla volta, questi 3 byte sono codificati in 4 lettere della mappa precedente, che si noti sono 2alla 6 caratteri.\nSe mi mancano byte alla fine aggiungo del padding, che sono delle = nella parte encodata (il resto sono degli 0 credo).\nSlides base64\n","permalink":"https://flecart.github.io/notes/codifica-dei-caratteri/","summary":"Ripasso Prox: 40 Ripasso: May 14, 2023 Ultima modifica: May 14, 2023 5:18 PM Primo Abbozzo: March 2, 2023 4:19 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nCodifica dei caratteri Sull\u0026rsquo;encoding Introduzione ðŸŸ© Ossia trattiamo metodi per codificare caratteri dei linguaggi umani, come ASCII, UCS e UTF.\nDigitalizzare significa encodarlo in un sistema che possa essere memorizzato su un dispositivo di memorizzazione elettronico. Ovviamente non possiamo mantenere l\u0026rsquo;informazione cosÃ¬ come Ã¨, ma vogliamo memorizzarne una forma equivalente, ma piÃ¹ facile da manipolare dal punto di vista del computer.","title":"Codifica dei caratteri"},{"content":"Ripasso Prox: 5 Ultima modifica: December 29, 2022 3:24 PM Primo Abbozzo: July 11, 2022 11:15 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Non ti ricordi le tecniche di backtracking belle per avere un buon CSP. 3 CSP Problems Costraint Satisfaction Problems.\nDefinizione Caratteristiche Variabili Dominio per ogni variabile Costraints per ogni variabile Queste tre sono elementi che definiscono un problema di soddisfazione delle restrizioni, una soluzione Ã¨ un assegnamento di variabili che soddisfi ogni restrizioone e sia allâ€™interno del dominio\nConsistenza Vogliamo andare a limitare il dominio valutando le consistenze possibili\nConsistenza del punto Si puÃ² dire che un punto sia consistente se le sue variabili possibili non viola nessuna restrizione unaria: eg. se ho N e ho la restrizione n â‰¥ 0, allora avere tutto N Ã¨ inconsistente nel punto.\nConsistenza ad arco Questo tratta delle restrizioni binarie: una coppia di punti si dice che Ã¨ arco consistente se per ogni variabile nel primo dominio esiste sempre una variabile nel secondo dominio che mi soddisfa la restrizione.\nk-consistenze Si puÃ² estendere il concetto della consistenza per avere un numero arbitrario di nodi, questo dovrebbe causa perÃ² un costo del calcolo molto maggiore.\nAC-3 algorithm Questo Ã¨ un algoritmo per forzare la consistenza ad arco, praticamente va di forza bruta a imporre la consistenza su un arco, se i domini vengono aggiornati gli archi vicini vengono rimessi in coda, in modo da essere sicuri che restino ancora consistenti (infatti eliminando certe variabili potrebbero aver perso di consistenza)\nLa ricerca di una soluzione Backtracking Euristiche della scelta dei valori Minimum remaining Values\nvorremmo che la ricerca della variabile non assegnata fallisca il prima possibile, quindi scegliamo la variabile con piÃ¹ vincoli, o meno valori assegnabili.\nLeast constraining value\nSe vogliamo una unica soluzione che soddisfa vogliamo scegliere variabili che hanno meno probabilitÃ  di fallire.\nForward check\nAbbastanza simile ad AC-3, toglie dei valori che non possono esserci??? boh cose simili.\n","permalink":"https://flecart.github.io/notes/csp-problems/","summary":"Ripasso Prox: 5 Ultima modifica: December 29, 2022 3:24 PM Primo Abbozzo: July 11, 2022 11:15 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Non ti ricordi le tecniche di backtracking belle per avere un buon CSP. 3 CSP Problems Costraint Satisfaction Problems.\nDefinizione Caratteristiche Variabili Dominio per ogni variabile Costraints per ogni variabile Queste tre sono elementi che definiscono un problema di soddisfazione delle restrizioni, una soluzione Ã¨ un assegnamento di variabili che soddisfi ogni restrizioone e sia allâ€™interno del dominio","title":"CSP problems"},{"content":"Ultima modifica: February 25, 2023 2:07 PM Primo Abbozzo: October 26, 2021 1:53 PM Studi Personali: No\nElementi di ripasso Componenti di HACK Il nostro computer Ã¨ diviso in tre parti fondamentali. (anche la memoria Ã¨ divisa in tre parti fondamentali.\nMemoria C\u0026rsquo;Ã¨ una sezione per il RAM normale, una sezione per il ram dello schermo e un singolo byte per il keyboard.\nStruttura generale Rom, e poi cose per input output come schermo e keyboard.\nROM Ã¨ un chip builtin in cui sono presenti le istruzioni in sola lettura a differenza di come sono di solito le archittetture dei pc in cui i programmi sono storati e caricati dalla memoria.\nKeyboard Tasto e OS l\u0026rsquo;os Ã¨ intelligente perchÃ© invece di scrivere 18 volte il tasto premuto, lo fa apparire una sola volta allo schermo\nSchermo Ogni byte di un certo indirizzo della ram sono mappati a bit dello schermo\nVirtual Machine Subroutine La nuova innovazione della virtual machine Ã¨ che esistono le subroutine.\nLa chiamata della funzione e la call devono avere entrambi il numero di parametri, questo rende piÃ¹ facile l\u0026rsquo;implementazione in seguito e esistono le subroutine.\nLa chiamata della funzione e la call devono avere entrambi il numero di parametri, questo rende piÃ¹ facile l\u0026rsquo;implementazione in seguito\n","permalink":"https://flecart.github.io/notes/hack/","summary":"Ultima modifica: February 25, 2023 2:07 PM Primo Abbozzo: October 26, 2021 1:53 PM Studi Personali: No\nElementi di ripasso Componenti di HACK Il nostro computer Ã¨ diviso in tre parti fondamentali. (anche la memoria Ã¨ divisa in tre parti fondamentali.\nMemoria C\u0026rsquo;Ã¨ una sezione per il RAM normale, una sezione per il ram dello schermo e un singolo byte per il keyboard.\nStruttura generale Rom, e poi cose per input output come schermo e keyboard.","title":"HACK"},{"content":"How can we transform a uniform into a random variable? It is true that we have $$ F(x) = \\int _{-\\infty}^{x} f(t) \\, dt $$ A volte la densitÃ  non Ã¨ definita, mentre la funzione cumulativa lo Ã¨ , per questo spesso cominciamo a definire partendo dalla definizione.\nSuppose we have a $x \\sim F_{X}(x)$ where $F$ is a cumulative distribution function, same thing, we just need to take the set, normal cumulative distribution function that we saw a lot in other courses. $$ F_{X}(x) = \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^{x} f_{X}(z) \\, dz $$ Generalized inverse Definition We want to have an inverse of the cdf, but i don\u0026rsquo;t know why. By some definition the transformation is still a random variable. The definition of the generalized inverse is: $$ F_{X}^{-1}(u) = inf \\left\\{ x; F_{X}(x) \\geq u \\right\\} $$ This has sense because we know that the inverse is a continuous function (we do or not?). This is useful because when we have a cumulative probability distribution this allows to recreate the original random variable distribution, and it\u0026rsquo;s quite easy to get it in this way.\nProbability Inverse transform Sample from $X$ when it\u0026rsquo;s difficult to sample from that distribution (for example function difficult to calculate?, Difficult to implement function?)\nRequirements:\nI know the functional form of $F_{X}(x)$ $X$ in continuous. For the exam you will be given the cumulative distribution and you need to use this theorem to sample\nTheorem The inverse distribution the cumulative of the uniform distribution is the same for that random variable $$ U \\sim F_{X}(x) \\iff \\mathbb{P}(Y \\leq x) =X $$ Where $Y = F_{X}^{-1}(U)$ this is just the definition of the cumulative function, the catch is the ???\n$F_{X}(u)$ is continuous then it is invertible If $U \\sim Unif(0, 1)$ then the c.d.f is easy, and it\u0026rsquo;s equal to $$ u \\in \\left[ 0, 1 \\right]: F_{U}(u) = \\begin{cases} 0, u \\leq 0 \\\\ u, 0\\leq u\\leq 1 \\\\ 1, u \\leq 1 \\end{cases} $$ And this is easy. This is proved to be the only distribution with this property, that the CDF is an identify $F_{X}(X) = U$ this is also called PIT See here for proof (it\u0026rsquo;s cool) Proof 1 $$ \\mathbb{P}(F_{X}^{-1}(U) \\leq x) = \\mathbb{P}(F_{X}\\left[ F_{X}^{-1}(U) \\right] \\leq F_{X}(x)) = \\mathbb{P}(U \\leq F_{X}(x)) = F_{U}[F_{X}(x)] = F_{X}(x) $$ In the first passage we used that the cumulative distribution function is monotonically increasing, in the second a clear property for the inverse, and at the end we used a property of the cumulative uniform distribution.\nProof 2 Proof of the same fact, so we have: Proof of the point 3. $$ U = F_{U}(u) = \\mathbb{P}(U \\leq u) = \\mathbb{P}(F_{X}(X) \\leq F_{X}(x)) = \\mathbb{P}(F_{X}^{-1}(F_{X}(X)) \\leq F_{X}^{-1}(F_{X}(x)) ) = \\mathbb{P}(X \\leq x) = F_{X}(x) $$ After you have this you can just use the inverse -\u0026gt; $$ F_{X}^{-1}(U) = X $$ So now you can sample.\nExample of application $$ X \\sim Exp(\\lambda = 1) $$ And given $F_{X}(x) = 1 - e^{-x}$, with $x \\in \\mathbb{R}^{+} \\cup \\left\\{ 0 \\right\\}$ Find the value of $X$ random variable.\nSolution example:\n$F_{X}(X) = U$, then set up the equation and solve $$ 1 - e^{-X} = U \\implies e^{-X} = 1 - U \\implies X = -\\log (1 - U) $$ We can notice that $1 - U$ and $U$ are both uniform distribution, so the above is the same as $X = -\\log(U)$ And in this way you get the correct random variable. Now we can sample from the uniform and get the correct result! -\u0026gt; Direct transformation method. With this process we prooved that $-\\log U \\sim Exp(\\lambda = 1)$ Famous function CDF Logistic function This is a function very similar to that used in Logistic Regression. We have $X \\sim \\text{Logistic}(\\mu ; \\beta)$, then $$ F_{X}(x) = \\frac{1}{1 + e^{-(x - \\mu)/\\beta}} $$ Let\u0026rsquo;s make the derivation: $$ U = F_{X}(X) = \\frac{1}{1 + e^{-(X - \\mu)/\\beta}} \\implies 1 + e^{-(X - \\mu)/\\beta} = \\frac{1}{U} \\implies -(X - \\mu)/\\beta = \\log(\\frac{1}{U} - 1) $$ $$ \\implies X = -\\beta \\log\\left( \\frac{1}{U} - 1 \\right) + \\mu $$ Where $\\beta$ and $\\mu$ are parameters of the distribution.\nCauchy distribution How to simulate data from a Cauchy distribution? $$ F_{X}(x) = \\frac{1}{2} + \\frac{1}{\\pi}\\arctan((x - \\mu) / \\sigma) $$ The derivation $$ U = F_{X}(X) = \\frac{1}{2} + \\frac{1}{\\pi}\\arctan((X - \\mu) / \\sigma) \\implies \\tan(\\pi\\left( U - \\frac{1}{2} \\right)) = (X - \\mu)/\\sigma \\implies X = \\sigma \\cdot \\tan(\\pi\\left( U - \\frac{1}{2} \\right)) + \\mu $$ So also in this case we have a way to sample a Cauchy distribution by just manipulating a uniform distribution.\nHow for the Gaussian? $$ \\Phi(x) = \\int _{-\\infty}^{x}f_{X}(z) \\, dz \\int _{-\\infty}^{x} \\frac{1}{\\sqrt{ 2\\pi } \\sigma^{2}} \\exp \\left\\{ - \\frac{(z - \\mu)^{2}}{2\\sigma^{2}} \\right\\} \\, dz $$ Doesn\u0026rsquo;t have a clear evaluation function because it\u0026rsquo;s difficult, in R it uses the Probability inverse transform.\nEmpirical C.D.F The definition is simple:, if we have a i.i.d. sample $$ (X_{1}, \\dots, X_{n}) : \\hat{F}_{X, m}(x) = \\frac{1}{n} \\cdot \\sum_{i = 1}^{n} \\mathbb{1}(X_{i} \\leq x) $$ It\u0026rsquo;s just the sum of all the sampled data that is lower than a certain value! (unbiased, on average, the emprirical cdf we have the right cdf!).\nOther famous distributions Chi squared distribution math exchange\nif we have $X_{i} \\sim Exp(1)$ then it is true that $$ Y = 2 \\sum_{i = 1}^{n}X_{i} \\sim \\chi^{2}_{2n} $$ Where $n$ is the degrees of freedom, bad thing is that this usually just even, so useful for that. (chi square gamma distribution)\n$$ Y = \\beta \\sum_{i= 1}^{n} X_{i} \\sim G(a, \\beta) : a \\in \\mathbb{N}^{*} $$ Which is a Gamma distribution, exponential is special case of gamma? $$ Y = \\frac{\\sum_{i=1}^{a} X_{i}}{\\sum_{i = 1}^{a + b} X_{i}} \\sim Be(a, b) $$ Which is a Beta regression, used for microbiome in the guts, I don\u0026rsquo;t know why.\nTransformation of random variables (no exam) La cosa strana per questi statistici e che non si capisce per quale fine stiamo facendo queste trasformazioni, che non sono molto utili a primo impatto. Nel senso che non so nemmeno quale sia il problema che stiamo provando a risolvere!\nSuppose $X \\sim f_{X}(x)$, and $Z= g(X)$ with $g$ an invertible function, then suppose $Z \\sim f_{Z}(z)$ Then the support of the density is in $X$ , we have that $$ f_{Z}(z) = \\frac{\\delta F_{Z}(z)}{\\delta z} = f_{X}\\left[ g^{-1}(z) \\right] \\cdot \\frac{\\delta g^{-1}(z)}{\\delta z} $$ Non so esattamente cosa mi possa servire questo e non so nemmeno perchÃ© funziona. Dopo: alla fine la dimostrazione di questo Ã¨ molto semplice (io sono un po\u0026rsquo; incapace nelle dimo a quanto pare e tendo ad impararle a memoria) Comunque lo trovi in https://en.wikipedia.org/wiki/Random_variable\nUniform random variable Permette la creazione di uniform tale per cui non siano sempre nel classico 0, 1 $$ U\\sim Unif(0, 1) \\implies f_{U}(u) = \\begin{cases} 0 : u \\not\\in \\left[ 0, 1 \\right] \\\\ 1 : u \\in \\left[ 0, 1 \\right] \\end{cases} $$ Allora la trasformazione sarebbe: $$ X = (b - a)U + a , \\, b \u003e a $$ Then $$ U = \\frac{x - a}{b - a} = g^{-1}(X) \\implies \\frac{\\delta g^{-1}(X)}{\\delta x} = \\frac{1}{b-a} \\implies f_{X}(x) = f_{U} \\left[ \\frac{x- a}{b - a} \\right] \\cdot \\frac{1}{b - a} $$ and we have that $f_{U}$ is in $\\left[ 0, 1 \\right]$ when we need to have $x \\geq a \\land x \\leq b$ in order to have a density different than 0. $$\n$$\nStandard Gaussian $X \\sim N(\\mu, \\sigma^{2})$ then $Z = (X - \\mu) / \\sigma$ . Which is closed under linear transformations! and $X = g^{-1}(Z) = \\sigma \\cdot Z + \\mu$ Then: $$ f_{Z}(z) = f_{X}(\\sigma z + \\mu) \\sigma = \\frac{1}{\\sqrt{ 2\\pi }} \\exp \\left\\{ - \\frac{Z^{2}}{2} \\right\\} $$ Where the first part is the density of a Gaussian\nBox-Muller algorithm (no exam) https://blog.cupcakephysics.com/computational%20physics/2015/05/10/the-box-muller-algorithm.html https://math.nyu.edu/~goodman/teaching/MonteCarlo2005/notes/GaussianSampling.pdf\nThis algorithm is used to produce Gaussian random variables: we have $U_{1}$ and $U_{2}$ that are normal uniform, then we can take $$ X_{1} = \\sqrt{ -2 \\log(U_{1}) } \\cos(2\\pi U_{2}), X_{2} = \\sqrt{ -2 \\log(U_{2}) } \\sin(2\\pi U_{1}), $$ Without any approximation, it is exact for some reason\nMultivariate cases We can use the re-parametrization trick to gen $N(\\mu, \\sigma^{2})$ just multiplying by the variance and add the mean. We are asking if we can do the same even for the multivariate case, how can we get $N_{p}(\\mu, \\Sigma)$ ? Let\u0026rsquo;s take a bi-variate Gaussian for example. It seems like a result that we have that the square root of a matrix is almost the same as a Cholesky decomposition. That will be our sigma. it\u0026rsquo;s always possible because we have a positive definite symmetric matrix for the Sigma. See Algebra lineare numerica for cholesky\nThe discrete case Vogliamo andare a prendere molte probabilitÃ  in questo modo $$ p_{0} = P_{\\theta}(X \\leq 0) , p_{1} = P_{\\theta}(X \\leq 1) e via $$ Ãˆ sempre come conoscere una CDF discreta. Poi prendiamo $$ X = k, p_{k-1} \\leq U \\leq p_{k} $$ e cosÃ¬ facciamo sampling della variabile per le distribuzioni discrete $X$\nAltre cose ","permalink":"https://flecart.github.io/notes/inverse-transform/","summary":"How can we transform a uniform into a random variable? It is true that we have $$ F(x) = \\int _{-\\infty}^{x} f(t) \\, dt $$ A volte la densitÃ  non Ã¨ definita, mentre la funzione cumulativa lo Ã¨ , per questo spesso cominciamo a definire partendo dalla definizione.\nSuppose we have a $x \\sim F_{X}(x)$ where $F$ is a cumulative distribution function, same thing, we just need to take the set, normal cumulative distribution function that we saw a lot in other courses.","title":"Inverse Transform"},{"content":"Ripasso Prox: 80 Ripasso: June 30, 2022 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: October 28, 2021 4:56 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\n4 Limiti Riguardare Successioni per avere primo attacco sui limiti\n4.1 Limiti finiti al finito 4.1.1 Intorno sferico Dato l\u0026rsquo;insieme $\\R$ si definisce l\u0026rsquo;intorno sferico aperto di $x \\in \\R$ di raggio $r \\in \\R$ l\u0026rsquo;insieme $I_r(x) = (x -r, x + r)$ questa nozione Ã¨ molto importante per definire il limite. Lo useremo subito su un punto di accumulazione\n4.1.2 Punto di accumulazione Un punto di accumulazione $x$ di un insieme $A \\subseteq \\R$ Ã¨ un punto tale per cui mi posso avvicinare in modo indefinito in quel punto. Infatti deve $\\forall r \u003e 0 \\in R, \\exists x_ 1 \\in A : x_1 \\in I_r(x) \\wedge x_1 \\not= x$ ossia per cui $A \\cap I_r(x) \\not= \\empty$.\nEcco che se mi avvicino in modo indefinito, possiamo definire per bene il limite tra poco.\n4.1.3 Accumulazione per successioni Un punto si puÃ² definire di accumulazione per una successione $a_n$ se si ha che\n$\\lim_{n\\to\\infty} a_n = x$ con x punto di accumulazione. e $\\forall n \\in \\N, a_n \\not= x$\n4.1.4 Limite finito Questo Ã¨ il limite finito per una funzione\n$$ \\forall \\epsilon \u003e 0, \\exists \\delta \\in\\R: 0\u003c|x-x_0| \u003c \\delta \\implies |f(x) -y| \u003c \\epsilon $$ In pratica comunque prendo un valore vicino al valore y di limite, (quindi sto definendo la mia $\\epsilon$ deve esistere sempre un $\\delta$ tale che valga quella roba.\nLa soluzione tipica per la dimostrare di tale cosa Ã¨ partire dalla tesi e scomporla, trovare che se x appartiene a un certo intervallo continuo allora possono sempre trovare un sottoinsieme di questo intervallo che sia $\\delta$.\n4.2 Teoremi dei limiti 4.2.1 Permanenza del segno Se il limite positivo allora esiste un x per cui f(x) Ã¨ positivo, ma lo dovresti dimostrare (dovrebbe essere ovvio considerando l\u0026rsquo;intorno di $\\delta$ per cui vale $\\varepsilon$\nDimostrazione\n4.2.2 Carabinieri Quando una funzione si possa schiacciare all\u0026rsquo;interno di due altre funzioni ha lo stesso limite. Questo in modo intuitivo ma si potrebbe fare anche molto di piÃ¹\u0026hellip;\n4.2.3 Alcuni limiti notevoli (!) $\\lim_{x\\to0}\\sin(x) = 1$ con i carabinieri per 0 e x\n$\\lim_{x\\to0} \\cos(x) = 0$ con duplicazione e altre osservazioni\n$\\lim_{x\\to0}\\dfrac{sin(x)}{x} = 1$\n$\\lim_{x\\to0} \\dfrac{e^x - 1}{x} = 1$\nQueste sono i limiti notevoli di base per trigonometriche e esponenziali (o logaritmiche)\nEsistono anche alcuni limiti notevoli riguardanti il confronto fra le funzioni polinomiali, esponenziali o fattoriali.\n4.2.4 Dimostrazione perimetro e area cerchio (!) Ti ricordi come si fa la dimostrare il valore dell\u0026rsquo;area e del perimetro del cerchio utilizzando il limit e noto?\n4.3 Limiti finiti all\u0026rsquo;infinito 4.3.1 Definizione Definiamo il limite di una funzione x tende a x_0 Ã¨ uguale a piÃ¹ o meno infinito nel caso in cui:\n$$ \\lim_{x\\to x_0} f(x) = +\\infty \\iff \\forall M \\in \\R, \\exists \\delta : 0\u003c|x-x_0| \u003c \\delta \\implies f(x) \u003eM $$ In modo simile si puÃ² dire per il limite che tende a un valore infinito negativo\n4.3.2 Limiti destri e sinistri Ãˆ molto simile alla definizione normale di limite, ma solo che invece di considerare un intorno completo di x debbo avere una parte, quindi invece di $0 \u003c \\lvert x-x_0 \\rvert\u003c \\delta$ ho che deve essere che $x_0 - \\delta \u003c x \u003c x_0$ per intorni sinistri e in modo simile per intorni destri ho che $x_0 \u003c x \u003c x_0 + \\delta$\nIl resto della definizione Ã¨ tutto uguale.\n4.3.3 Relazione limite e l destro e l sinistro Si potrebbe dimostrare questa proprietÃ :\n$$ \\lim_{x \\rightarrow x_0} f(x)= L \\iff \\begin{cases} \\exists \\displaystyle{\\lim_{x \\to x_0^-}f(x)}, \\exists\\displaystyle{\\lim_{x \\to x_0^+}f(x)}\\\\ \\displaystyle{\\lim_{x \\rightarrow x_0^-}f(x)}=\\displaystyle{\\lim_{x \\rightarrow x_0^+}f(x)}=L \\end{cases} $$ 4.4 Limiti all\u0026rsquo;infinito Si possono trovare 3 casi:\n$\\forall \\varepsilon, \\exists \\delta= \\delta(\\varepsilon) \u003e 0 : \\forall x \\in A : x \u003e \\delta$\n$$ \\lim_{x\\to +\\infty} f(x) = \\begin{cases} l \\iff |f(x) - l| \u0026lt; \\epsilon \\ +\\infty \\\n\\infty \\end{cases} $$ 4.4.1 Esercizi algebra dei limiti 4.4.2 Limiti di polinomi Si dimostra che per limite di x tendente a x0 con la funzione lineare che Ã¨ uguale a x, poi si espande questo con i teoremi di algebra dei limiti e la moltiplicazione con le costanti in modo che il limite dei polinomi sia coincidente con il limite degli addendi moltiplicazioni e simili.\nCon la definizione di limite fatta in seguito si ha che tutti i polinomi sono continui nel proprio dominio naturale.\n4.5 Funzione continua 4.5.1 Definizione $\\forall x_0 \\in A, A \\subseteq \\R$ allora deve essere che\n$x_0 \\not\\in D(A)$ con $D(A)$ l\u0026rsquo;insieme dei punti di accumulazione di A.\n$$ x_0 \\in D(A) \\implies \\lim_{x \\to x_0}f(x) = f(x_0) $$ con il limite definito come prima.\nE si scrive in questo modo $f \\in C(A)$, data una funzione nello spazio di funzione $A^\\R$\nOsservazioni\nLa continuitÃ  di una funzione Ã¨ interessante perchÃ© definisce una regolaritÃ  della funzione.\n(anche se significa anche che possiamo tracciare la funzione senza lasciare la matita dal foglio).\n4.5.2 ContinuitÃ  destra e sinistra Dalla definizione di funzione continua espansa si puÃ² dedurre che\n$$ \\lim_{x \\to x_0}f(x) = f(x_0) \\begin{cases} \\exists\\lim_{x\\to x_0} f(x) \\\\ \\exists\\lim_{x\\to x_0^+} f(x),\\exists\\lim_{x\\to x_0^-} f(x),\\\\ \\lim_{x\\to x_0^+} f(x) = \\lim_{x\\to x_0^-} f(x), = \\lim_{x\\to x_0} f(x) \\end{cases} $$ 4.5.3 ContinuitÃ  per inverse Dimostrazione (non richiesta) Non viene dimostrato ma, se Ã¨ definita una funzione continua per una certa funzione, allora Ã¨ continua anche la sua inversa. Per qualche motivo magico.\nQuesto teorema Ã¨ importante per la dimostrazione della derivabilitÃ  dell\u0026rsquo;inversa (quindi per avere una base per dimostrare la derivabilitÃ  dell\u0026rsquo;inversa\nTeorema degli zeri Lemmi preliminari per THZero Primo (dim)\nEnunciato sia data una successione bn appartenente a $\\R$ sempre positiva o sempre negativa tale che il limite di bn appartiene a $\\R$ allora il limite ha lo stesso segno della successione o Ã¨ nulla.\nSi dimostra per assurdo ponendo il limite il contrario (si apre poi il limite e si sceglie un epsilon carino che mi porti a questa contraddizione).\nSecondo (no dim)\nData una funzione da A a $\\R$, prendiamo x un punto di accumulazione di A tale che f sia continua in questo punto allora. Per ogni successione xn appartenente ad A che converga a x si ha che f(xn) tende a f(x)Â´Â´\n4.6.2 THZero data una funzione continua in [a,b] in R allora se $f(a)f(b) \u003c 0 \\implies \\exists c \\in ]a,b[ : f(c) = 0$\nOssia, in modo intuitivo, dato un rettangolo tagliato da una linea, se prendo due punti nelle due parti, allora se provo a congiungere questi due punti si ha che deve tagliare la linea in almeno un punto.\nDIM\n$$ \\lim a_n = \\lim b_n = c\\\\ f(c) = 0 $$ Bisogna dimostrare queste due cose.\nSi utilizza una divisione diadica in due parti, un algoritmo di costruzione costruttiva.(se l\u0026rsquo;algoritmo finisce Ã¨ banale.\nVoglio costruire due successioni, una sempre negativa una sempre positiva, entrambi devono tendere a 0, cosÃ¬ lo trovo.\nProprietÃ  di queste successioni\nDa queste proprietÃ  ho ottenuto che entrambe le successioni sono limitate e sono crescenti o decrescenti, quindi per dimostrazione precedente esiste un limite che non conosciamo.\nUna cosa molto interessare da considerare Ã¨ la successione\n$a_n - b_n = \\dfrac{a - b}{2^{n-1}}$ che tende a 0. Poi insieme al teorema di convergenza dei limiti.\n$a_n$ si puÃ² dire che Ã¨ una approssimazione dal basso mentre $b_n$ Ã¨ una approssimazione dall\u0026rsquo;alto\nPoi utilizzando il lemma 1 e il lemma 2 si puÃ² concludere che, dato c questo limite che $f(a_n) = f(c) \\leq 0$ e che $f(b_n) = f(c) \\geq 0$ e quindi abbiamo dimostrato che esiste $f(c) = 0$\nCostruttiva â†’ Ho un metodo di approssimazione\n4.6.3 THZero e polinomi Nei polinomi di grado dispari si puÃ² notare che il limite del polinomio che tende a +infinito va a +infinito, uguale il contrario, grazie al thzero si puÃ² concludere che deve avere necessariamente uno zero (si puÃ² dimostrare anche la continuitÃ  di questo! Ãˆ algebra dei limiti)\nOgni polinomio di gradi dispari ha almeno una radice Reale.\n4.7 Weierstrass e Valore intermedio 4.7.1 Weierstrass (Estremi finiti) Studia il concetto di punto di massimo o minimo assoluto qui. In particolare dice che esistono quei due punti per funzioni:\nDominio limitato e chiuso Funzione continua Enunciato\nDimostrazione (non richiesta)\n4.7.2 Weierstrass riformulato Quello che dice in piÃ¹ Ã¨ che l\u0026rsquo;immagine della funzione coincide con il massimo e minimo assoluto.\nSi dovrebbe dimostrare con weiestrass di prima e thzeri.\n$\\forall y \\in codominio, \\text{considero } g(x) = f(x) - y$ e poi utilizzo il teorema degli zeri per dire che esiste un x per cui $g(x) = 0 \\iff f(x) = y$ e quindi ho trovato un x per cui vale.\nEnunciato\n4.7.3 Teorema del valore intermedio enunciato\nLa dimostrazione Ã¨ equivalente a Weierstrass riformulato.\n","permalink":"https://flecart.github.io/notes/limiti/","summary":"Ripasso Prox: 80 Ripasso: June 30, 2022 Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: October 28, 2021 4:56 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\n4 Limiti Riguardare Successioni per avere primo attacco sui limiti\n4.1 Limiti finiti al finito 4.1.1 Intorno sferico Dato l\u0026rsquo;insieme $\\R$ si definisce l\u0026rsquo;intorno sferico aperto di $x \\in \\R$ di raggio $r \\in \\R$ l\u0026rsquo;insieme $I_r(x) = (x -r, x + r)$ questa nozione Ã¨ molto importante per definire il limite.","title":"Limiti"},{"content":"Ripasso Prox: 20 Ripasso: December 14, 2021 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: November 5, 2021 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Vecchi dubbi La funzione semantica vs funzione di interpretazione definizione di conseguenza logica ed equivalenza logica Le 3 caratteristiche della deduzione naturale PerchÃ© un sistema deduttivo Ã¨ sintattico? 6 Logica proposizionale Con la logica proposizionale studiamo le denotazioni che hanno un valore di veritÃ , ovvero deve essere una sentenza assertiva. Studio solamente le connotazioni che hanno una capacitÃ  denotativa, in quanto Ã¨ solo quello ch emi importa.\n6.1 La sintassi Vengono qui definite le produzioni che valgono in ogni singolo mondo.\n$$ F ::= \\top|\\bot|A|B|...|\\not F| F \\wedge F| F \\vee F| F \\implies F $$ Questa Ã¨ la BNF della nostra sintassi.\nLe lettere sono asserzioni, sono sentenze dichiarative a cui posso dare un valore\nConnotazioni atomiche Sono solamente ABCD e le singole lettere che rappresentano le proposizioni.\n6.1.1 Formalizzazione Ovvero il tentativo di esprimere asserzioni attraverso la sintassi della logica proposizionale. Quindi dare un valore logico a frasi come oggi piove, marco Ã¨ bello, marco Ã¨ brutto e simili. Quest Ã¨ importante perchÃ© Ã¨ probabile che all\u0026rsquo;esame ci sia un esercizio di formalizzazione\n6.1.2 Note per attenzione Fare attenzione ai sinonimi e contrari, che devono avere la stessa lettera, non Ã¨ ovvio.\nUna altra cosa su cui fare attenzione sono le connotazioni ovvero modi diversi per dire la stessa denotazione come:\n$A \\implies B$ Ã¨ la denotazione delle connotazioni : A Ã¨ condizione sufficiente di B, B Ã¨ condizione necessaria di A e altro.\n6.2 La semantica La semantica classica associa il valore di veritÃ  per ogni connotazione del linguaggio. Allora si dice che stiamo utilizzando la logica proposizionale classica\nNoi parliamo tutti i giorni con una semantica naturale, principale o intesa sono tutti dei sinonimi Devo partire da alcune premesse filosofiche che mi portano alla logica classica.\n$filosofia \\implies logica \\implies matematica$\nNota di wiki La semantica studia il significato delle parole, quindi ci dice cosa deve significare una connotazione, e possono essere molto diverse: molte semantiche per una stessa sintassi.\nEsempio semantica (interpretazione) in prog Semantica che interpreta la sintassi in termini di tempo: Interpreto i miei costrutti come il tempo che impiega ad eseguire (molto utile per avere una complessitÃ  computazionale (es. if, vado a guardare guardia). Semantica che interpreta la sintassi in termini di memoria occupata. 6.2.1 Dominio di interpretazione, f semantica Dominio di interpretazione sono connotazioni (definite tramite BNF)\nDipende dai mondi in Verita, Teorie, modelli, connotazione, denotazione, ossia si puÃ² interpretare la connotazione in modi diversi a seconda della denotazione in quello specifico mondo\nSi potrebbe dire che ogni mondo possieda una funzione semantica che parte da un dominio di interpretazione e denota queste connotazioni con oggetti precisi in un mondo.\n6.2.2 Enunciati della logica classica TODO: fai una parte a sÃ© per questo\nQuesta logica parla della veritÃ .\nManicheo (visioni estreme)\nSulla falsitÃ  e veritÃ \nOgni enunciato Ã¨ vero o falso (esistono gradi di veritÃ , secondo alcuni, dibattibile ~Fuzziness) Ogni enunciato non puÃ² essere vero o falso allo stesso momento Platoniche\nStaticitÃ  il valore di veritÃ  non muta nel tempo, immutabile. No libero arbitrio o possibilitÃ  di cambiare il proprio futuro (se Ã¨ una veritÃ \u0026hellip;) ah i trip mentali. Determinatezza il valore di veritÃ  Ã¨ sempre determinato (simile al primo aristoteo?) Tutto il futuro Ã¨ predicibile e non si puÃ² fare niente (ma mancano le conoscenze). Utilizzando queste due caratteristiche del valore di veritÃ  possiamo giÃ  fare delle inferenze:\nDifferenza fra veritÃ  e conoscenza La conoscenza non possiede il senso di staticitÃ  e determinatezza (puÃ² cambiare nel tempo (cresce), e non Ã¨ sempre quella) mentre la veritÃ  lo Ã¨\nDifferenza fra veritÃ  e risorse La veritÃ  Ã¨ statica (si puÃ² utilizzare quante volte si vuole), mentre le risorse vengono consumate (esempio cibo, se lo mangio scompare,o almeno non Ã¨ piÃ¹ nella forma attuale).\nCritiche della logica intuizionista Esistono dei mondi non determinati che si possono determinare a seconda dei mondi, non posso avere una veritÃ  statica immutabile.\nNon vale per la conoscenza e mondi non-deterministici\n6.2.3 Booleani e funzione di interpretazione classica Scegliemo di indicare i booloani come 1 â†’ Vero 0 â†’ Falso Per tre motivi principali:\nPosso utilizzare le regole dell\u0026rsquo;algebra in quanto sono dei numeri e possiedono quelle proprietÃ  Non vanno in confuzione con top e bottom per il loro essere dei numeri (altrimenti avrei dovuto distinguere il vero e il falso a livello sintattivo, a livello denotativo e poi latro) Si puÃ² facilmente trovare un intervallo di veritÃ . Interpretazione Si puÃ² definire (funzione di) interpretazione (classica) di un mondo, possibile solamente grazie all\u0026rsquo;esistenza di cui sopra dei boleani, che associa a ogni sentenza del mondo un valore di veritÃ .\nAllora dato che Ã¨ una funzione, possiamo notare che possiede i valori di:\nStaticitÃ , in quanto le funzioni sono solamente quelle e non cambiano Determinatezza per le proprietÃ  delle funzioni, ossia per ogni sentenza del mondo posso associare un valore di veritÃ . 6.2.4 funzione semantica per la logica classica Questo Ã¨ definito tramite BNF e fissa il linguaggio della logica in un mondo preciso.\nNOTA: distingui bene la differenza fra valore semantico e interpretazione in un mondo.\n6.2.5 Tabella di veritÃ  Le tabelle di veritÃ  hanno senso solamente nell\u0026rsquo;ambito della logica classica, in quanto puÃ² solamente rappresentare una logica finita,, quindi la classica non la intuizionistica.\nLe tabelle di veritÃ  sono le stesse viste in Porte Logiche (con una nota particolare sulla implicazione materiale, molto diversa dalla normale relazione di causalitÃ  utilizzata tutti i giorni\nSemantica Tarskiana\nÃˆ una logica che utilizzano i matematici (molto lapalissiana, inutile dal punto di vista di nuove informazioni che la definizione riesce a dare) (Coen critica anche che questo Ã¨ perchÃ© i matematici se ne fregano della logica, di quello che sta sotto la matematica).\nPraticamente utilizza il linguaggio naturale per descrivere la funzione semantica descritta qui sopra, cosa che funziona solamente con la logica classica, e appena si esce da questo reame non ha piÃ¹ senso. Utilizza troppe nozioni meta-linguistiche, tanto che potrebbe dire che meta-linquistica e linguistica siano quasi la stessa cosa\n6.3 Conseguenza logica (formale) Questa Ã¨ la definizione formale di conseguenza logica\n$$ \\Gamma \\Vdash F \\iff \\forall v, (\\forall G \\in \\Gamma, [G](/notes/g)^v = 1) \\implies [F](/notes/f)^v = 1 $$ NOTA 1 questa definizione non Ã¨ computabile, non Ã¨ direttamente studiabile in ambito informatico, allora c\u0026rsquo;Ã¨ bisogno della creazione di un #6.4 Sistemi deduttivi. (In questa definizione stiamo parlando di infiniti (di mondi v e assiomi G, che chiaramente non Ã¨ computabile quindi non Ã¨ possibile prendere decisioni in questo ambito).\nNOTA 2 Intelligenza artificiale forte, che possa sapere tutto, Ã¨ ucciso da questa osservazione, in quanto la computazione non puÃ² arrivare a sapere tutto. (quindi non puÃ² essere un programma\u0026hellip; mmmm).\n6.3.1 Equivalenza logica ovvero la semantica per ogni modello v di una teoria Ã¨ uguale, quindi possiamo dire che valgono per gli stessi mondi. $G \\equiv F \\iff \\forall v, [F](/notes/f)^v = [G](/notes/g)^v$\n6.4 Sistemi deduttivi 6.4.1 Intro Esistono sistemi deduttivi diversi, quella che vediamo noi Ã¨ la deduzione naturale.\nPossono variare per\nSintassi diverse Esigenze diverse Cosa Ã¨ un sistema deduttivo\nIl sistema deduttivo Ã¨ una nozione sintattica **che contiene in sÃ© una prova (dimostrazione) di una proposizione. (sintattico perchÃ© parla di connotazioni, non di denotazione esatta di quello presente sotto).\nDeve quindi utilizzare regole precise per le prove. Ci sono molti modi per fare regole, la piÃ¹ naturale Ã¨ la deduzione naturale.\n6.4.2 Deduzione (3) $\\Gamma \\vdash F$, si legge da $\\Gamma$ deduco $F$, ed Ã¨ una nuova nozione sintattica (prova esplicita tale per cui la sintassi vada, quasi algoritmico). Poi si potrÃ  dire che ogni dimostrazione deve essere una conseguenza logica e il contrario. Dimostrazione Ã¨ un dato!\nDeve esserci una prova esplicita\nÃˆ possibile scrivere una dimostrazione in una qualche sintassi, questo Ã¨ il significato di deduzione.\nSe Ã¨ sintatizzabile (si puÃ² scrivere con una sintassi) si puÃ² trasmettere ecco che si cerca una sintassi per le dimostrazioni.\nDeve essere corretta, ossia $\\Gamma \\vdash F \\implies \\Gamma \\Vdash F$\nDevo definire il motivo per cui le regole di dimostrazione siano giuste (Le varie regole di introduzione e eliminazione. non vale per le logiche espressive ma solo per la classica! Questa nozione Ã¨ dimostrata in quando parliamo di connettivi, anche se utilizza solamente il concetto di induzione strutturale per dimostrarla\u0026hellip;\nCompletezza (non per logiche espressive (?)) $\\forall \\Gamma, F, \\Gamma \\Vdash F \\implies \\Gamma \\vdash F$ vale per logiche semplici, ma esistono dimostrazioni logiche che non saremo mai in grado di dimostrare, in modo simile alla non implementabilitÃ  di funzioni matematiche, utilizzando paradossi.\nQuesta dimostrazione esiste ma Ã¨ molto complessa, lo ha saltato di striscio il prof.\n6.4.3 La deduzione naturale Studieremo la deduzione naturale in Deduzione naturale\n6.6 Definizioni 6.6.1 Tautologia $\\Vdash F$, quando Ã¨ Ã¨ conseguenza logica per tutto. Quindi Ã¨ anche una veritÃ  assoluta perchÃ© non dipende da mondo in esame. (la tabella logica in esame possiede solamente delgi uno).\nNot-tautologia ricorda che il contrario del per ogni Ã¨ l\u0026rsquo;esiste il not!, quindi basta un mondo in cui questa proposizione sia falsa.\n6.6.2 SoddisfacibilitÃ  e non SoddisfacibilitÃ \nSi utilizza lo stesso simbolo $\\exists v,v \\Vdash F \\iff \\llbracket F \\rrbracket ^v = 1$ tale che v sia un mondo\nInsoddisfacibilitÃ \nQuando non esiste nessun mondo, quindi per ogni mondo nno vale la cosa sopra.\n(PiÃ¹ o meno questa proprietÃ  Ã¨\nTaotologicitÃ  (teorema)\nSi puÃ² dimostrare da sopra che una formula Ã¨ tautologica se per ogni mondo vale che la funzione semantica per input quella proprietÃ  si ha 1\nNota: tautologica implica soddisfacibile, quindi devi fare attenzione!\n6.6.3 Conseguenza logica per mondi diversi Ricondursi al concetto di variabile presente in Connettivi Logici, correttezza, variabili\nRagionamento Con questo per trovare una conseguenza logica mi posso ridurre a leggere le tabelle di veritÃ .\nDrawback Le righe totali sono $2 ^n$ per le $n$ variabili totali, m per numeri grossi Non mi dice il perchÃ© sia una conseguenza logica. Quindi sappiamo che esiste ma non si fa mai.\n6.7 Deduzione semantica 6.7.1 Teorema di DS Questo teorema Ã¨ molto importante per dare il senso all\u0026rsquo;implicazione materiale. $$ \\Gamma \\Vdash F \\implies G \\iff \\Gamma, F \\Vdash G $$ Dim Destra Dim Sinistra Nota: dopo aver supposto che $v \\Vdash \\Gamma$, sto utilizzando l\u0026rsquo;eliminazione dell\u0026rsquo;or $F \\vee \\neg F$ per finire la dimostrazione (questa Ã¨ una tautologia).\n6.7.2 Corollario DS La conclusione dovrebbe essere quasi banale grazie al teorema sopra. (Questo mi diche che sono quasi **infinite le tautologie**!) Possiamo trovare cose vere in ogni mondi. 6.7.3 Teoremini $\\Vdash F \\iff \\neg F$ insoddisfacibile $\\Gamma$ Insoddisfacibile sse $\\Gamma\\Vdash \\bot$ e Ã¨ soddisfacibile nel caso in cui non Ã¨ conseguenza logica $\\Gamma \\Vdash F \\iff \\Gamma,\\neg F$, insoddisfacibili.,Gamma finito $\\neg F \\equiv F \\implies \\bot$ ash \\bot$ e Ã¨ soddisfacibile nel caso in cui non Ã¨ conseguenza logica $\\Gamma \\Vdash F \\iff \\Gamma,\\neg F$, insoddisfacibili.,Gamma finito $\\neg F \\equiv F \\implies \\bot$\n","permalink":"https://flecart.github.io/notes/logica-proposizionale/","summary":"Ripasso Prox: 20 Ripasso: December 14, 2021 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: November 5, 2021 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Vecchi dubbi La funzione semantica vs funzione di interpretazione definizione di conseguenza logica ed equivalenza logica Le 3 caratteristiche della deduzione naturale PerchÃ© un sistema deduttivo Ã¨ sintattico? 6 Logica proposizionale Con la logica proposizionale studiamo le denotazioni che hanno un valore di veritÃ , ovvero deve essere una sentenza assertiva.","title":"Logica Proposizionale"},{"content":"Introduzione alla logistic regression Giustificazione del metodo Questo Ã¨ uno dei modelli classici, creati da Minsky qualche decennio fa In questo caso andiamo direttamente a computare il valore di $P(Y|X)$ durante l\u0026rsquo;inferenza, quindi si parla di modello discriminativo, seguendo il modello presente in Introduction to machine learning\nIntroduzione al problema Supponiamo che\n$Y$ siano variabili booleane $X_{i}$ siano variabili continue $X_{i}$ siano indipendenti uno dall\u0026rsquo;altro. $P(X_{i}| Y= k)$ sono modellate tramite distribuzioni gaussiane $\\mathbb{N}(\\mu_{ik}, \\sigma_{i})$ NOTA! la varianza non dipende dalle feature!, questo mi permetterebbe di poi togliere la cosa quadratico dopo, rendendo poi l\u0026rsquo;approssimazione lineare Per esempio se utilizziamo nelle immagini, avrebbe senso normalizzare pixel by pixel, e non image wide con un unico valore, Ã¨ una assunzione, che se funziona dovrebbe poi far andare meglio la regressione logistica! $Y$ Ã¨ una distribuzione bernoulliana. Ci chiediamo come Ã¨ fatto $P(Y|X)$?\nCaratterizzazione di P(Y|X) ðŸŸ¨+ Proviamo a calcolare analiticamente come Ã¨ fatto $P(Y|X)$ usando le assunzioni di sopra Theorem Assunte le cose di sopra si avrÃ  che $$ P(Y=1| X= \\left\u003c x_{1},\\dots, x_{n} \\right\u003e ) = \\frac{1}{1 + \\exp\\left( w_{0} + \\sum_{i} w_{i}x_{i} \\right)} $$ Nella derivazione di sopra si ha che $\\pi = P(Y=1)$ E poi sappiamo che\n$$ \\ln \\frac{P(X_{i} | Y=0)}{P(X_{i} | Y=1)} = \\ln \\frac{e^{-\\frac{(X_{i} - \\mu_{i0})^{2}}{2 \\sigma_{0}^{2}}}}{ e^{-\\frac{(X_{i} - \\mu_{i_{1}})^{2}}{2 \\sigma_{1}^{2}}}} = -\\frac{(X_{i} - \\mu_{i0})^{2}}{2 \\sigma_{i}^{2}} + \\frac{(X_{i} - \\mu_{i1})^{2}}{2 \\sigma_{i}^{2}} $$ E si puÃ² notare che poi abbiamo il risultato di sopra e diventa sensato avere la forma di Sigmoid, che esce in modo molto molto naturale\nDalla parte in blu capiamo che Ã¨ una cosa lineare, perchÃ© se Ã¨ maggiore di zero allora Ã¨ meglio la probabilitÃ  di stare da una parte rispetto all\u0026rsquo;altra.\nFunzione di Sigmoid ðŸŸ© Questo ci dÃ  una motivazione del motivo per cui utilizziamo $$ \\text{ Funzione di sigmoid: }\\sigma(x) = \\frac{1}{1 + e^{-x}} $$ **Derivata** Si puÃ² calcolare che ha una derivata molto molto carina, ma Ã¨ anche il problema per cui esiste **vanishing gradient**. $$ \\sigma'(x) = \\sigma(x) (1 - \\sigma(x)) $$ Quindi diventa vero che $$ P(Y=1|x,w) = \\sigma\\left( w_{0} + \\sum_{i} w_{i}x_{i} \\right) $$ Possiamo scrivere la probabilitÃ  di ogni singolo campione come in figura sotto\nFunzione di loss ðŸŸ© Che sembra una cross-entropy classica, che perÃ² non ha una soluzione analitica, per questo motivo si utilizza **discesa del gradiente**. Ottimizzazione discesa del gradiente Intuizione sul gradiente ðŸŸ© abbiamo alla fine che il gradiente Ã¨\n$$ \\frac{\\delta \\mathcal{L}(w)}{\\delta w_{i}} = \\sum_{l} x^{l}_{i} \\cdot (y^{l} - \\alpha^{l}) $$ PerchÃ© giÃ  $(y - \\alpha)$ sta misurando in un certo senso la differenza (l\u0026rsquo;errore), e il prodotto lo sta legando all\u0026rsquo;input preciso, quindi Ã¨ molto bello quando la formula Ã¨ interpretabile in modo fisico quasi.\nCalcolo del gradiente cross entropy ðŸŸ¨++ $$ a^{l} = \\sigma\\left( w_{0} + \\sum_{i} x_{i}w_{i} \\right) = \\sigma(z) $$ $$ \\sum_{l} \\log P(Y= y^{l} | x ^{l}, w) = \\sum_{l} y^{l}\\log(\\alpha^{l}) + (1- y^{l})(1 - \\log(\\alpha^{l})) $$ Dalla formula di sopra riscritta in altro modo.\nQuesto Ã¨ esattamente poi quanto sarÃ  fatto durante il percettrone, per l'aggiornamento delle variabili in quelle istanze. Fase update del gradiente ðŸŸ© Una volta calcolato che il valore di update Ã¨ analiticamente uguale a $$ \\frac{\\delta \\mathcal{L}(w)}{\\delta w_{i}} = \\sum_{l} (y^{l} - \\alpha^{l}) x^{l} $$ Possiamo usare questa per aggiornare il peso di $w_{i}$\nUpdate step: $$ w_{i} = w_{i} + \\mu \\frac{\\delta \\mathcal{L}(w)}{\\delta w_{i}} $$ A volte viene aggiunto un fattore di regolarizzazione che fa diventare la regola di update come $$ w_{i} = w_{i} + \\mu \\frac{\\delta \\mathcal{L}(w)}{\\delta w_{i}} + \\mu \\lambda|w_{i}| $$ Che implica il fatto che se abbiamo un singolo peso grande, farÃ  molta fatica ad esserci nel regolarizzatore (quindi ho meno varianza fra i pesi diciamo).\n","permalink":"https://flecart.github.io/notes/logistic-regression/","summary":"Introduzione alla logistic regression Giustificazione del metodo Questo Ã¨ uno dei modelli classici, creati da Minsky qualche decennio fa In questo caso andiamo direttamente a computare il valore di $P(Y|X)$ durante l\u0026rsquo;inferenza, quindi si parla di modello discriminativo, seguendo il modello presente in Introduction to machine learning\nIntroduzione al problema Supponiamo che\n$Y$ siano variabili booleane $X_{i}$ siano variabili continue $X_{i}$ siano indipendenti uno dall\u0026rsquo;altro. $P(X_{i}| Y= k)$ sono modellate tramite distribuzioni gaussiane $\\mathbb{N}(\\mu_{ik}, \\sigma_{i})$ NOTA!","title":"Logistic Regression"},{"content":"Metodi altri sono trovare una approssimazione facile da calcolare (simile all\u0026rsquo;approccio del modello surrogato credo). Ma nel nostro caso proviamo a trovare metodi di esplorare lo spazio dei parametri in modo intelligente.\nDeterministic methods Sono utilizzabili quando ci sono delle proprietÃ  come convessitÃ , limitatezza, continuitÃ .\nNewton Raphson method Molte implementazioni in R usano questo metodo, Ã¨\nPerfetto quando $h$ Ã¨ quadratico, e in statistica molti problemi sono quadratici e funziona in modo perfetto Ma in cose non lineari si ha meno performance (perchÃ© l\u0026rsquo;hessiana Ã¨ molto instabile per l\u0026rsquo;inversione, si dice che Ã¨ mal condizionata, e si fa con attenzione.) l\u0026rsquo;unica cosa da sapere secondo me Ã¨\n$$ f(x) = x - H^{-1}\\nabla f(x) $$ Stochastic methods Stochastic search In pratica faccio uniform su tutto il dominio, e tengo il maggiore come la soluzione, solo che\nDifficile da calcolare Soffre di problemi di scaling Ha bisogno che la funzione sia facile da valutare. La caratteristica negativa Ã¨ che spende tempo anche per zone di poco interesse, perchÃ© dÃ  stessa importanza a tutto. Sarebbe buono provare a fare sampling in modo proporzionale al valore di $h(\\theta)$\nMax of function = mode of the distribution, if that is a density! Quindi se faccio sampling usando quella funzione come densitÃ  riesco a trovare il massimo!\nStochastic gradient methods Ãˆ una categoria di algos.\nRandom walk We use the gradients to guide the search. Un esempio Ã¨ solamente fare una cosa cosÃ¬ $$ \\theta_{j+1} = \\theta_{j} + \\varepsilon_{t} $$ In cui $\\varepsilon$ Ã¨ una variabile aleatoria, questo Ã¨ anche una catena di markov. Questo Ã¨ un random walk approach. (che Ã¨ stupido perchÃ© comunque non sto utilizzando nessuna informazione sulla funzione!)\nGradient descent Questo lo sai. Solo che in questo caso viene fatta una sequenza di pesi (non Ã¨ un learning rate)\u0026hellip; Solo che soffre molto facilmente sulla possibilitÃ  di stuck su minima o maxima.\nC\u0026rsquo;Ã¨ anche una versione stocastica, in cui si una una versione approssimata del gradiente (che strano, di solito questa informazione Ã¨ disponibile). (si utilizza la definizione di gradiente in pratica, quindi si usa una variabile random sullo step\u0026hellip;)\n$$ \\nabla h(\\theta) \\approx \\frac{h(\\theta_{j} + \\beta_{j} \\gamma) - h(\\theta_{j} - \\beta_{j} \\gamma)}{2\\beta_{j}} $$ in cui ho di nuovo una sequenza di $\\beta$ che mi definisco io, solo che $\\gamma$ Ã¨ sampling da sfera unitaria, Ã¨ un tentativo di perturbare la discesa, in modo da non essere stuck in minimi o massimi locali.\nPoi l\u0026rsquo;update diventa\n$$ \\theta = \\theta - \\frac{\\alpha_{i}}{2\\beta_{i}} \\nabla h(\\theta)\\gamma $$ Simulated Annealing Boltzmann-Gibbs transform quando proviamo in local search un sampling basato su local search minima.\nWe want to sample a sequence proportional to the time! $\\propto \\frac{\\exp(h(\\theta))}{T}$\nSolitamente per fare questo si fa $$ \\pi_{i}(\\theta) \\propto L(0)^{T} \\pi_{0}(\\theta) $$ Dove $\\pi_{0}$ Ã¨ la distribuzione di densitÃ  iniziale, mentre l\u0026rsquo;altro Ã¨ una costante. questo approccio si chiama prior feedback approach.\nIl tempo possiamo sceglierlo di farlo scendere in molti modi\nLogaritmico Geometrico Metropolis hastings Vogliamo utilizzare la trasformata di boltzmann-gibbs per fare sampling del nuovo valore $\\theta$ seguendo quello.\nAlgo:\nPrendo $y$ da una distribuzione $g$, tale che sia simmetrica per questo motivo utilizzo una gaussiana. (anche questo deve essere scalato col tempo). Poi faccio sampling condizionale: (con probabilitÃ  $p$ posso sommare, con probabilitÃ  $1- p$ rimane la stessa). La cosa in piÃ¹ Ã¨ che mi muovo con probabilitÃ  (la scelta stocastica) Ã¨ la differenza con random walk\u0026hellip; In particolare $p$ non Ã¨ costante ma cambia nel tempo, ed Ã¨ calcolata come: $$ p = min\\left( \\exp\\left( \\frac{\\Delta h}{T} \\right), 1 \\right) $$ Con $h = h(\\theta + y) - h(\\theta)$, una osservazione Ã¨ che se Ã¨ positiva, allora Ã¨ sempre maggiore di 1, quindi mi muovo sempre (qui Ã¨ equivalente a random walk). Altrimenti vorrei essere piÃ¹ conservativo, e restare di piÃ¹ con la stessa posizione. Ma allora continuo a muovermi di meno col tempo. EM Algorithms ","permalink":"https://flecart.github.io/notes/optimization-methods/","summary":"Metodi altri sono trovare una approssimazione facile da calcolare (simile all\u0026rsquo;approccio del modello surrogato credo). Ma nel nostro caso proviamo a trovare metodi di esplorare lo spazio dei parametri in modo intelligente.\nDeterministic methods Sono utilizzabili quando ci sono delle proprietÃ  come convessitÃ , limitatezza, continuitÃ .\nNewton Raphson method Molte implementazioni in R usano questo metodo, Ã¨\nPerfetto quando $h$ Ã¨ quadratico, e in statistica molti problemi sono quadratici e funziona in modo perfetto Ma in cose non lineari si ha meno performance (perchÃ© l\u0026rsquo;hessiana Ã¨ molto instabile per l\u0026rsquo;inversione, si dice che Ã¨ mal condizionata, e si fa con attenzione.","title":"Optimization methods"},{"content":"Ripasso Prox: 120 Ripasso: September 28, 2023 Ultima modifica: May 19, 2023 10:28 AM Primo Abbozzo: October 15, 2022 10:22 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Semafori Introduzione Concetto principale ðŸŸ©- Ãˆ sempre stato introdotto da Dijkstra, 1965 (Cooperating Sequential Processes) utilizzato come strumento di cooperazione semplice\nQuesto Ã¨ un sistema fortemente ispirato dai semafori che regolano gli incroci stradali.\ndue o piÃ¹ processi possono cooperare attraverso semplici segnali, in modo tale che un processo possa essere bloccato in specifici punti del suo programma finchÃ© non riceve un segnale da un altro processo\nPrimitive dei semafori ðŸŸ©- Il semaforo solitamente Ã¨ una variabile intera non negativa.\nV anche chiamao sem_wait.\nDa verhogen utilizzata per rilasciare una risorsa. Di solito Ã¨ implementata aumentando il valore di un semaforo.\nP, anche chiamato sem_post.\nDa proberen per attendere evento o rilascio di una risorsa. Di solito Ã¨ implementata decrementando il valore del semaforo solo se Ã¨ positivo non nullo.\nInvarianti per i semafori (!!!)\nSlide invarianti\nImplementazione classica della CS ðŸŸ© Programma concorrente con semafori per CS\nImplementazione classica di P e V (ricordare da metterle nella CS)\nSi puÃ² notare che tutte le 4 proprietÃ  espresse per la concorrenza sembrano essere soddisfatte.\nOltre a questo bisogna avere una struttura di dati (Queue) che tenga conto dei processi che stanno aspettando la risorsa dietro questo semaforo, in modo da poter ricominciare.\nSi potrebbe in questo caso anche disabilitare l\u0026rsquo;interrupt! PerchÃ© tanto ora non Ã¨ dentro lo scope del programmatore, Ã¨ dentro lo scope del semaforo! Per i multicore si possono utilizzare le soluzioni trattate in parti precedenti.\nVantaggi dei semafori ðŸŸ© Fairness data dalla politica FIFO utilizzata per la struttura di dati della coda\nSlide\nBusy waiting molto minore\nInterleaving controllato? Boh non ho capito il concetto di questa frase\nSemafori binari Descrizione generale ðŸŸ© Sono semafori che possono solamente avere come valore 0 e 1.\nTODO: dire anche cosa succede per lâ€™attesa dei dueâ€¦\nImplementazione ðŸŸ©- Implementazione semaforo binario\nI semafori binari ci garantiscono mutua esclusione\nSemafori binari equiv. semafori normali ðŸŸ© Implementazione dei semafori con semafori binari ðŸŸ©\nImplementazione di semafori binari con semafori ðŸŸ©\nProblemi classici Producer consumer ðŸŸ© Abbiamo due agenti, un programma che produce una risorsa e un agente che la consuma. Questa comunicazione di disponibilitÃ  di un valore avviene attraverso una singola variabile condivisa.\nProprietÃ  importanti\nProducer non puÃ² scrivere la zona di memoria comune prima che il consumer l\u0026rsquo;abbia consumato Consumer non deve leggere due volte la stessa cosa. No deadlock nÃ© starvation In questo caso sono come delle sezioni critiche alternate passing the baton perchÃ© Ã¨ come se passasse il testimone, e vanno avanti in modo alternato.\nSoluzione\nLimited Buffer ðŸŸ© La descrizione del problema Ã¨ molto simile, la differenza Ã¨ che si utilizza un buffer condiviso per lo scambio di informazioni, non una singola variabile, il resto delle proprietÃ  Ã¨ molto simile.\nSoluzione\nOsservazioni personali\nNon c\u0026rsquo;Ã¨ deadlock perchÃ© si bloccherebbero assieme solo se sia empty sia full sono 0, ma questo sarebbe un problema di inizializzazione. Dining philophers ðŸŸ©- Ho 5 filosofi intorno a una tavola che devono acquisire le due bacchette (risorse condivise) per mangiare, altrimenti pensano.\nInvarianti\nResource hierarchy solution\nSoluzione\nIn questa soluzione si crea una gerarchia di prioritÃ  per chi deve acquisire la fork, con una rottura di simmetria per lâ€™ultima.\nIl problema Ã¨ che non Ã¨ libero da starvation.\nPagina wiki\nAltre soluzioni\nOsservazioni personali\nCredo ci sia starvation perchÃ© non c\u0026rsquo;Ã¨ niente che mi garantisca che non ci sia.\nRoba da buttare, riguardo dining\nPseudocodice per il problema dei dining filosophers che utilizza il token, e la struttura ad anello inizializza 5 semafori, solo uno sarÃ  a 1 sarÃ  quello attivo direi. 5 booleani che indicano la disponibilitÃ . inizializzo 5 numeri che identificano il numero delle volte che si ha mangiato Alla fine di ogni ciclo di mangiata viene incrementato il numero, e questo numero viene incrementato solamente da un unico thread, quello di un certo filosofo, quindi non devo metterci il mutex, o forse sÃ¬??. Quindi fra gli attivi voglio solamente chi ha il token e chi puÃ² mangiare. bool done = false; while (!done): waiting_for_token = true, // anche done puÃ² essere utilizzato come waiting for token. [enter CS] if (disponibile left): prendi left if (disponibile right): prendi right waiting_for_token = false; // done = true qui, invece che sotto. make calls to take left and right. else: release left [exit CS] if (has both forks): eat() releaseLeft() signal left is available releaseRight() signal right is available done = true; else: go to sleep (try again lather, if not done)) passtoken to next waiting for token. - somebody is waiting for token if 1. Is not eating 2. Has not finished Quindi ci metto il check booleano sopra. Readers and writers ðŸŸ©- Questo Ã¨ uno dei problemi piÃ¹ importanti, adremo in seguito a sviluppare il concetto di awaiting.\nCi sono due tipi di processi che devono leggere un database. I lettori accedono al database per leggerlo, gli scrittori per scriverlo, fatto Ã¨ che i lettori possono leggere quanto vogliono, quando perÃ² uno ci vuole scrivere, nessun altro ci puÃ² andare a leggere.\nUn solo scrittore, che blocca tutti\nSe nessuno scrive tutti possono leggere.\nInvarianti da rispettare\nSoluzione Readers and Writers con semafori\nStarvation degli scrittori\nQuesta soluzione ha il drawback del fatto che starvation per i scrittori.\nQuesta Ã¨ una soluzione che funziona ma vorremmo trovare un metodo per descrivere tutti i problemi con await, in modo molto clean.\nPrioritÃ  ai scrittori con await framework ðŸŸ¨+ Vogliamo in questa parte trattare di una soluzione che non metta in starvation gli scrittori, ma mette in starvation i lettori in questo caso.\nSlide soluzione\nLa soluzione Ã¨ quasi la stessa, ma si cambia la condizione di entrata per i lettori che sarÃ  quando non c\u0026rsquo;Ã¨ nessun scrittore che sta scrivendo e nemmeno nessuno che sta aspettando di scrivere.\nScegliere quale soluzione utilizzare dipende molto dallâ€™ambiente in cui stiamo, dipende se vogliamo piÃ¹ gente che scriva o piÃ¹ gente che legga (di solito per un database c\u0026rsquo;Ã¨ molta gente ch elegge e poca che scrive).\nProblema del barbiere addormentato Slide\nFramework per semafori Andiamo in questa parte a creare un framework generale per la discussione di problemi con await con i semafori.\nFramework semafori Andrews (4) ðŸŸ¨- Notazione con Await (2) ðŸŸ¨+ Notazione (andrews Await)\nQuindi la sintassi diventa di due parametri in particoalre\nStatement atomico Statemento atomico con await su una condizione booleana. Molto interessante notare che Ã¨ questo ciÃ² che stato implementato con Javascript! Ed Ã¨ una cosa molto clean questo paradigma :D.\nSoluzione readers and writers con await (generale)\nSi noti che questa soluzione Ã¨ equivalente alla soluzione dei semafori, ma Ã¨ scritta in modo molto piÃ¹ clean.\nImplementazione await con semafori ðŸŸ© Note sulle variabili di implementazione\nLe note principali sono i semafori e i waiting.\nImplementazione in slide\ni quadrati sono degli if non deterministici, nel senso che posso riordinarli come mi pare e sarebbe comunque apposto\nSu signal, ci dÃ  un idea di quanti processi possono andare avanti dato un cambiamento di stato.\nLa modifica sul waiting[i]- - non Ã¨ un write non protetto??? No perchÃ© sempre passaggi di testimoni! Siamo sempre in una sezione critica, ma divisa fra piÃ¹ processi grazie a questo meccanismo passing the baton.\nInfatti Ã¨ per questo che possono fare waiting[i]- - senza apparentemente essere in mutua esclusione!.\nNota che sembra interessante Ã¨ che questo baton viene continuamente passato da processo a un altro da signal ad un altro finchÃ© non posso piÃ¹ fare signal.\nNota sui passaggi di testimoni\nLa mutex Ã¨ sempre rilasciata attraverso la tecnica del passing the baton, in qui il mutex Ã¨ rilasciato da processi diversi, si puÃ² espandere su molti processi diversi la mutua esclusioneâ€¦ Cavolo perÃ² credo sia molto difficile sbagliarci qualcosa no? boh.\nReaders and writers con await (!) ðŸŸ¨- Slide soluzione\nSoluzione in singola slide (e con signal ottimizzato)\nConsiderazioni finali (3) ðŸŸ¨ I semafori pongono forti problemi di leggibilitÃ  dato che sono costrutti a basso livello sparsi in mezzo al codice.\nÃˆ possibile inoltre compiere errori stupidi in modo molto facile, come scambiare P o V, omettere Po V.\nE pone un sacco di responsabilitÃ  sul prorammatore che deve gestire lui in modo corretto le risorse e definire gli accessi.\n","permalink":"https://flecart.github.io/notes/semafori/","summary":"Ripasso Prox: 120 Ripasso: September 28, 2023 Ultima modifica: May 19, 2023 10:28 AM Primo Abbozzo: October 15, 2022 10:22 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Semafori Introduzione Concetto principale ðŸŸ©- Ãˆ sempre stato introdotto da Dijkstra, 1965 (Cooperating Sequential Processes) utilizzato come strumento di cooperazione semplice\nQuesto Ã¨ un sistema fortemente ispirato dai semafori che regolano gli incroci stradali.\ndue o piÃ¹ processi possono cooperare attraverso semplici segnali, in modo tale che un processo possa essere bloccato in specifici punti del suo programma finchÃ© non riceve un segnale da un altro processo","title":"Semafori"},{"content":"Ultima modifica: May 17, 2023 3:14 PM Primo Abbozzo: May 17, 2023 1:48 PM Studi Personali: No\nElementi di ripasso VLAN Introduzione Quando abbiamo una switch, ma vogliamo allo stesso momento andare a creare piÃ¹ LAN, allora abbiamo bisogno delle VLAN. Questi switch che hanno delle VLAN si chiamano managed switches\nQueste vlan sono numerate (ricorda lâ€™espericomento cn LUCA!).\nIl problema Sono un protocollo livello 2 (Link-Layer, di collegamento), non vorremmo per esempio che un broadcast di una certa rete vada anche in altre reti che non centrino praticamente nulla, come possiamo vedere in figura.\nEsempio problema di vlan\nImplementazione: porte Posso andare a raggruppare alcune porte come se fossero in una unica network separata rispetto al resto. Posso andare a numerare certe porte e proprio andare a taggarli come se sono parte di una altra rete.\nSi noti che per comincare fra VLAN in switches diverse, bisogna che il pacchetto possieda informazioni riguardo la VLAN in modo che quando viene ricevuto venga correttamente interpretato essere nell vlan corretta.\nVantaggi delle VLAN (3) Formato pacchetto VLAN Ãˆ una estensione del pacchetto livello MAC classico con informazioni riguardo le vlan\nPreable: sincronizzare chi trasmette e chi riceve Dest e source sono gli stessi classici livello 2, quindi con MAC. Multiprotocol Layer switching MPLS Esempio\nData center networks Load balancers Cerca di equalizzare il carico di lavoro di tutti.\n","permalink":"https://flecart.github.io/notes/vlan/","summary":"Ultima modifica: May 17, 2023 3:14 PM Primo Abbozzo: May 17, 2023 1:48 PM Studi Personali: No\nElementi di ripasso VLAN Introduzione Quando abbiamo una switch, ma vogliamo allo stesso momento andare a creare piÃ¹ LAN, allora abbiamo bisogno delle VLAN. Questi switch che hanno delle VLAN si chiamano managed switches\nQueste vlan sono numerate (ricorda lâ€™espericomento cn LUCA!).\nIl problema Sono un protocollo livello 2 (Link-Layer, di collegamento), non vorremmo per esempio che un broadcast di una certa rete vada anche in altre reti che non centrino praticamente nulla, come possiamo vedere in figura.","title":"VLAN"},{"content":"Ripasso Prox: 140 Ripasso: June 1, 2023 Ultima modifica: March 15, 2023 3:01 PM Primo Abbozzo: October 14, 2022 5:49 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 1 Architettura e primi due livelli 0.4 Architettura di rete 0.4.1 PerchÃ© a stack ðŸŸ©- Capire lâ€™architettura significa capire la struttura (lâ€™organizzazione) del nostro app e comprenderne i motivi (i sottoproblemi risolti) che ogni livello prova a risolvere\nLa soluzione che Ã¨ stata individuata, e ha rappresentato uno dei principali cardini del successo delle reti e della nascita di Internet, Ã¨ data dalla separazione delle classi di protocolli in livelli. La struttura dei livelli dei protocolli di rete prende il nome di architettura dei protocolli di rete. Il concetto di architettura dei protocolli, suddivisa in livelli, Ã¨ semplice ed Ã¨ basato su alcune condizioni.\nOgni livello\nSvolge determinate funzioni di gestione dei processi di comunicazione, attraverso uno o piÃ¹ protocolli alternativi. Fornisce un livello di astrazione piÃ¹ elevato della rete di comunicazione sottostante, sfruttando i servizi implementati dai livelli sottostanti. Ha relazioni dirette solo con i livelli immediatamente superiore e inferiore, attraverso richieste e servizi concordati, detti interfaccia del livello In altre parole, i livelli superiori non devono preoccuparsi di risolvere problemi che saranno gestiti e risolti dai livelli inferiori.\nLa cosa migliore per questa struttura Ã¨ che se ho bisogni differenti posso individuare il livello che mi interessa e re-mplementare solo quanto ho bisogno, senza dover cambiare l\u0026rsquo;intera stack.\nEsempio architettura a livelli (fatta dal prof in persona e rubata da altri profzz, lel)\nSi ha un esempio di trasmissione e ricezione delle informazioni tramite questa metafora.\nOgni livello risolvere un problema preciso nella fase di trasmissione dellâ€™informazioneâ€¦\nLa cosa interessante Ã¨ che dal livello di dichiarazione (o app) non si vede tutto il sotto, Ã¨ come se magicamente fosse tradotto e presentato nella lingua corretta! Risolve un grande problema di complessitÃ .\nVantaggi\nRiutilizzabilitÃ  di molti layers, basta cambiare cose di un singolo layer se ho bisogno di fare cose mie. Gli strati paritari si parlano astraendo tutto quanto avviene di sotto. Si potrebbe andare a parlare di encapsulation and data hiding cioÃ¨ tutti i dati di un singolo livello sono isolati a quello e i dati sono solamenti di questo livello. Esposte sono solamente le relazioni, come si parla sopra. (facilita anche il debuggin per singolo LIVELLO)\n0.4.2 Architettura standard (OSI) !!! ðŸŸ© Slide\nLo Standard ISO/OSI RM (International Organization for Standardization (ISO)/Open System Interconnection Reference Model) definisce un insieme di livelli completo e rigoroso per lâ€™architettura dei protocolli di rete, prevedendo un livello per la gestione di ogni problema di comunicazione in rete.\nCiÃ² che si va a standarizzare Ã¨ l\u0026rsquo;interfaccia dei vari livelli. (API)*. Mentre l\u0026rsquo;implementazione di queste funzioni Ã¨ lasciato a piacere, basta che soddisfi quello che deve fare. (Questo Ã¨ ciÃ² che permette la flessibilitÃ  di questra struttura). Lâ€™architettura dei protocolli di rete definita da ISO/OSI RM prevede sette livelli dei protocolli, numerati da 7 a 1 dallâ€™alto al basso.\nil livello fisico si occupa di definire le tecniche di codifica dei dati, la trasmissione e la ricezione dei dati sul mezzo fisico di trasmissione (â†’ Fisica here). livello LLC/MAC si occupa di garantire lâ€™affidabilitÃ  del mezzo di trasmissione e la gestione dellâ€™accesso al mezzo trasmissivo ad accesso multiplo (evitando le collisioni). A questo livello il pacchetto si chiama FRAME. MAC (Media Access Control) Ã¨ sotto. Inserisce gli indirizzi di destinatario e mittente (MAC) (spesso questi indirizzi sono solamente locali, per sapere a chi dare come step intermedio), forniti dal costruttore Decisione di quando trasmette (ad esempio puÃ² chiedere al livello fisico se il canale Ã¨ libero o meno, e gestisce questa cosa col suo protocollo, quindi dilazionare il tempo di trasmissione) LLC (Logical link control) Ã¨ sopra Verifica che non ci siano stati errori di trasmissione delle informazioni ricevute. Dire di inviare lâ€™acknowledgement, se Ã¨ il momento giusto. Gestire pacchetti duplicati. Il livello rete si occupa di frammentare i dati in pacchetti, scrivere gli indirizzi dei destinatari finali e instradare i pacchetti verso i destinatari intermedi del cammino. In questa sezione andiamo oltre alla rete locale, Ã¨ qui che nasce internet vero! Il router Ã¨ un elemento principale di questo. Frammentazione dei pacchetti Indirizzamento IP che servono a dare un identificativo alla scheda di rete in ambito locale per capire in quale direzione trasferire. Il livello trasporto si occupa di garantire i servizi di trasmissione dei pacchetti (orientati alla connessione e non) e del controllo della congestione della rete. Un esempio di protocollo a questo livello Ã¨ il TCP(Trasmission Control Protocol). Che fa i controlli sullâ€™acknowledgement e simili Potrebbe essere ch ealcuni router siano congestionati, quindi che droppino alcuni pacchetti Non Ã¨ una soluzione dire agli altri router di inviare in modo piÃ¹ lento. (Dovrebbe essere il mittente che dovrebbe rallentare nell\u0026rsquo;invio di pacchetti, in modo che non si congestionano nessun nodo). Il livello sessione mantiene e gestisce lo stato attuale del collegamento tra due applicazioni remote. (quindi poter riprendere da un certo stato quando per un certo momento ti sconnetti). Di solito questo Ã¨ gestito dallâ€™applicazione, e non viene implementato. Il livello presentazione risolve eventuali eterogeneitÃ  del formato dei dati tra i nodi della rete. PerchÃ© i formati sono giÃ  leggibili, senza dover interpretare i bit per capire cosa rappresentano. Il livello applicazione fornisce alle applicazioni in esecuzione sul calcolatore i servizi e le primitive di trasmissione e ricezione dei dati. primitive che servono al processo di esecuzione per funzionare. es. funzione per mandare i dati e simli. Qui le funzioni possono essere moooltee 0.4.3 Architettura dei protocolli di internet ðŸŸ© In questa sezione si tratta di come effettivamente quanto dell\u0026rsquo;architettura OSI Ã¨ implementata\nSlide\nLâ€™architettura dei protocolli di Internet, nel senso piÃ¹ comunemente adottato, prevede di fatto lâ€™implementazione di solo cinque livelli dei sette livelli dello Standard ISO/OSI RM. Rimangono spesso esclusi i livelli 5 (sessione) e 6 (presentazione), gli altri livelli sono uguali. Il motivo per cui succede Ã¨ che principalmente questi livelli sono implementati a livello applicazione.\nUn aspetto che si pone in evidenza, Ã¨ il concetto di incapsulamento dei dati tra i livelli implementati. In fase di trasmissione, ogni livello riceve dati dallâ€™alto (dati spediti dallâ€™applicazione) e li inserisce in â€œbuste virtualiâ€ (incapsulamento) ponendo in testa e in coda alcuni dati aggiuntivi, necessari per fornire al livello della controparte ricevente le informazioni utili allâ€™implementazione del protocollo dello stesso livello. In fase di ricezione, ogni livello X riceve dal livello piÃ¹ basso i dati imbustati dallo stesso livello X sul trasmettitore, quindi verifica i dati della busta, agisce in conseguenza alle specifiche fornite nei dati della busta, e passa solo il contenuto della busta ai livelli superiori (decapsulamento). Il livello trasporto spezza i dati dellâ€™applicazione in frammenti e li imbusta, aggiungendo informazioni utili allâ€™ordinamento e al riassemblaggio dei dati ricevuti, oltre che al controllo della congestione della rete.\nIl livello rete frammenta ulteriormente i dati in pacchetti (se sono troppo lunghi), scrive lâ€™indirizzo del destinatario sulla busta, e decide il cammino sul quale inviare il pacchetto a seconda dellâ€™indirizzo di rete del destinatario.\nIl livello MAC/LLC esegue la consegna finale dei dati a dispositivi di una rete locale.\n0.5 Livelli ISO/OSI Livello fisico\nSono a livelli fisico perchÃ© devono avere lo stesso mezzo fisico (eg ethernet solo ethernet!, wifi solo wifi!)\nSegmento di rete ðŸŸ© - Segmento di rete\nun mezzo di trasmissione condiviso con canale ad accesso multiplo, in cui tutte le schede collegate al segmento ricevono quanto trasmesso\nGli indirizzi MAC sono consapevoli dell\u0026rsquo;esistenza di questo mezzo di broadcast, con prima il destinatario, cosÃ¬ lo legge subito.\nCollegarli tutti in un canale broadcast non Ã¨ che sia molto buono\nRischio di collisioni molto alto Perdita di intensitÃ  dei segnali elettrici Principalmente spreco di tempo ed energie. Quindi abbiamo bisogno di modi per creare segmenti per risolvere questi problemi., che facciano cose intelligenti.\nIl segmento di rete Ã¨ importante! Mini rete locale, Ã¨ anche il modo in cui mando il pacchetto al router con source e destination.\nComposizione di segmenti di rete (4) ðŸŸ© Appunti prof di dispositivi per livello 1 e 2\nA questo punto esistono i presupposti per introdurre alcuni dispositivi che possono essere usati per comporre ed estendere una rete locale di calcolatori, unendo segmenti di rete altrimenti separati. Il primo dispositivo Ã¨ il ripetitore (repeater). Siccome i segnali emessi su qualsiasi mezzo fisico si degradano al crescere della distanza percorsa, esiste un limite massimo per la lunghezza di un segmento di rete. Ad esempio, un segmento Ethernet, puÃ² variare dai 100 ai 200 metri. Un repeater Ã¨ un dispositivo che agendo solo a livello fisico, amplifica e rigenera il segnale ricevuto verso un prolungamento del segmento di rete. Mediante un repeater Ã¨ possibile collegare due segmenti di rete aventi la stessa tecnologia a livello MAC, ed estendere la lunghezza dei segmenti di rete locale. Un Hub (che significa perno di una ruota a raggi) Ã¨ un altro dispositivo che agisce solo a livello fisico. Esso realizza il punto centrale di connessione, detto concentratore, dei segmenti di una rete locale con topologia a stella. In pratica si tratta di un ripetitore (repeater) con tante connessioni entranti e uscenti. Un Bridge (ponte) Ã¨ invece un dispositivo che agisce anche da traduttore a livello due (MAC/LLC). Un bridge permette di connettere segmenti di una stessa rete locale ma con tecnologie e MAC diversi tra loro (ad esempio un segmento Ethernet con uno Token Ring). I bridge fanno quindi da traduttori dei frame nei formati richiesti dal livello MAC di ogni segmento connesso al bridge, e provvedono alla trasmissione su segmenti diversi adottando il protocollo MAC opportuno. I Bridge sono dotati della capacitÃ  di filtrare e instradare opportunamente i frame di dati sul segmento opportuno, osservando sui frame le informazioni di indirizzo MAC del dispositivo destinatario. Uno Switch (commutatore) Ã¨ un dispositivo di livello due (MAC/LLC) analogo al bridge. Al contrario del bridge, esso permette di connettere un numero maggiore di segmenti diversi (fino a 10 o 12).\nRepeater\nRipetitori. I segnali trasmessi sul mezzo fisico degradano con la distanza, nella fattispecie lâ€™ethernet degrada dopo circa 200 metri, quindi ogni 200 (o, meglio, 100) metri si aggiunge un ripetitore. Il ripetitore amplifica e rigenera il segnale ricevuto. Il repeater collega due segmenti di rete che hanno la stessa tecnologia MAC; non legge i dati, vede semplicemente che sta arrivando un segnale e lo amplifica e passa oltre. Con lâ€™allungarsi delle distanze chiaramente le trasmissioni impiegano un poâ€™ di tempo in piÃ¹ per viaggiare da mittente e destinatario, quindi nel caso di reti LAN piÃ¹ grandi diventa necessario allungare i tempi di timeout.\nHub\nÃˆ un repeater multiporta. Ãˆ il nodo centrale di una rete a stella. Quando riceve un segnale da una porta lo copia e lo manda a tutti gli altri elementi della rete. Ãˆ usato pochissimo in quanto costa poco meno dello switch, che perÃ² offre piÃ¹ funzionalitÃ  e porte.\nBridge\nhub ripete tutto quanto ha avuto a tutti quanti sono collegati, ma ha il problema grosso delle collisioni\nSwitch\nConnette tecnologie omogenee.\nriesce a filtrare e inviare i frame al segmento giusto. Quindi si comporta come un hub quando non sa dove andare, ma riesce ad ascoltare gli segmenti e vedere se Ã¨ libero, se Ã¨ libero manda, e se torna lâ€™ACK allora aggiorna la propria tabella dei segmenti che mappa il MAC con il segmento corretto.\nAppunti di bianchi\nLavora a livello 2. A differenza del bridge permette di connettere molti piÃ¹ segmenti (oggi gli switch hanno anche 96 porte). Interconnette tecnologie omogenee, non diverse, e filtra i pacchetti da inoltrare a seconda della loro destinazione. Manda i dati in broadcast solo se non sa dovâ€™Ã¨ il destinatario. - Buffered switch: ha un buffer di memoria che ha la funzione di memorizzare tutti i frame che arrivano. Questo siccome la trasmissione deve essere smistata e non Ã¨ automatica, ma segue le regole del protocollo MAC, puÃ² essere necessario che una trasmissione debba attendere il completamento di unâ€™altra precedente.\nBridge\nFunziona come uno switch (quindi lavora a livello 2) ma connette tecnologie a livello locale con MAC protocol diversi (ad es. Ethernet e Wifi). Se riceve trasmissioni da un protocollo (ad es. Ethernet) e deve mandarle ad un altro protocollo (ad es. Wifi) prende il pacchetto, lo smembra e lo ricostruisce in un frame compatibile con lâ€™altro protocollo (i dati cambiano la â€œbusta giallaâ€).\nNote sui primi 2 livelli 0.5.1 Livello fisico ðŸŸ© Slide\nÃˆ il livello della scheda di rete, dei mezzi di trasmissione fisici, codifica e decodifica dei segnali in analogici e digitali.\nImportante in questa parte Ã¨ il concetto di velocitÃ  del mezzo trasmissivo e velocitÃ  di trasmissione.\nLa velocitÃ  di trasmissione dipenda dalla durata del vagone, o della rappresentazione dei dati nel mezzo trasmissivo.\nAppunti prof Livello fisico\nI valori possibili per i dati digitali (bit) del calcolatore sono solo due: i valori 0 e 1. Tali valori devono essere trasmessi o ricevuti sui mezzi di trasmissione delle reti, sotto forma di variazioni di segnali analogici (elettrici, ottici o radio), uno di seguito allâ€™altro. Per questo scopo, i dati digitali devono essere opportunamente codificati o decodificati, in sequenza, da parte della scheda di rete. Lâ€™attivitÃ  di codifica, effettuata in fase di trasmissione, equivale a tradurre i valori dei bit in segnali analogici. Lâ€™attivitÃ  di decodifica, effettuata in fase di ricezione, equivale a tradurre i segnali analogici ricevuti nei valori dei bit. Le tecniche di codifica digitali permettono di ridurre, ma non di escludere completamente, la possibilitÃ  di errori di trasmissione sulla rete. Una nota importante riguarda lâ€™ambiguitÃ  di fondo sul concetto di velocitÃ  della trasmissione dei segnali in rete. Dal punto di vista fisico, tutti i segnali analogici, elettrici, ottici o radio, si propagano praticamente alla stessa velocitÃ , cioÃ¨ alla velocitÃ  della luce, pari a circa 300.000 Km/sec. Non ha quindi senso parlare di bit, oppure di segnali, piÃ¹ veloci di altri. Tuttavia, nellâ€™esempio in figura, un canale A di comunicazione sul quale siano codificati dieci bit al secondo ha una densitÃ  di trasmissione dei bit (detta anche capacitÃ  del canale) pari alla metÃ  della capacitÃ  ottenuta da un canale B, sul quale possano essere codificati venti bit al secondo. I canali a capacitÃ  piÃ¹ elevata, ovvero in grado di trasmettere piÃ¹ bit al secondo, devono tali prestazioni al fatto di usare meno tempo per codificare, ovvero rappresentare il valore del bit sul mezzo trasmissivo, rispetto a canali piÃ¹ â€œlentiâ€. Le migliori tecnologie di rete sono quelle che permettono di codificare i bit nel minor tempo possibile, ottenendo quindi alte capacitÃ  dei canali (ad esempio, miliardi di bit trasmessi al secondo).\nLivello di collegamento ðŸŸ© MAC\nCanale Mac di broadcast\nStruttura e utilizzo dell\u0026rsquo;indirizzo MAC\nPolicies generali per lâ€™arbitraggio del canale per risolvere le collisioni.\nAppunti prof Livello Mac\nAnalizziamo ora lâ€™esempio piÃ¹ semplice per la definizione di una rete di calcolatori a commutazione di pacchetto: un segmento di rete locale. Un segmento di rete locale Ã¨ definito come un mezzo di trasmissione condiviso sul quale sia definito un canale ad accesso multiplo.\nOgni calcolatore si assume dotato della scheda di rete opportuna per il mezzo trasmissivo e i protocolli di codifica utilizzati al livello uno (fisico). Ogni scheda di rete Ã¨ dotata di un identificativo (indirizzo) di livello MAC unico al mondo (assegnato dal costruttore). Ogni trasmissione di un pacchetto di dati (detto frame a questo livello) sul canale ad accesso multiplo Ã¨ ricevuta da tutti i calcolatori la cui scheda di rete sia connessa al canale stesso. Immaginiamo che il dispositivo con indirizzo MAC1 voglia spedire un frame di dati al dispositivo con indirizzo MAC5, e allo stesso tempo il dispositivo di indirizzo MAC4 voglia spedire un frame di dati al dispositivo di indirizzo MAC2.\nNel contesto del canale condiviso, la conoscenza degli indirizzi MAC dei dispositivi mittente e destinatario basta ad effettuare la trasmissione, sul canale comune. Semplificando molto il problema, per ragioni di presentazione, Ã¨ sufficiente aggiungere le informazioni sullâ€™indirizzo MAC del destinatario e del mittente sulla busta di ogni frame, prima di trasmetterlo.\nOgni frame trasmesso sul canale da parte di ogni dispositivo risulta quindi rilevato da tutti gli altri dispositivi, ma viene ricevuto (cioÃ¨ copiato e passato ai livelli superiori) solo se lâ€™indirizzo MAC del destinatario specificato nel frame coincide con lâ€™indirizzo MAC del dispositivo ricevente. Il compito principale dei protocolli di livello 2 (MAC/LLC), oltre allâ€™indirizzamento dei frame trasmessi sul canale condiviso del segmento di rete locale, Ã¨ dato dallâ€™arbitraggio degli accessi al canale. Ossia\nDeterminare i nodi che possono trasmettre Quando possono trasmettere Lâ€™ordine di trasmissione per evitare collisioni LLC\nSlide prof\nControllare se i dati sono corretti, o ricevuti doppi (se doppio o errato faccio finta di non averlo ricevuto).\nMandare acknowledgment (che non succede col broadcast).\nAppunti prof affidabilitÃ  di questo livello (ACKs)\nScopo dei protocolli del livello 2 (MAC/LLC) Ã¨ nascondere ai livelli superiori i dettagli del mezzo fisico, e mostrare il canale condiviso sul segmento di rete locale come se si trattasse di un canale affidabile, senza alcun errore di trasmissione. A tal fine il frame di dati viene delimitato mediante particolari etichette di bit, poste allâ€™inizio e alla fine del frame, e viene arricchito con altri campi di dati utili al protocollo. La trasmissione di un frame procede per tentativi, fino alla ricezione di una conferma (un frame di conferma) da parte del destinatario. Quello qui illustrato Ã¨ solo un meccanismo semplice per realizzare trasmissione affidabile, tra quelli possibili. La figura mostra la sequenza temporale di eventi gestiti dal livello 2 (MAC/LLC) per la trasmissione affidabile di un frame di dati tra due dispositivi sulla stessa rete locale. Il frame di dati viene spedito dal dispositivo con indirizzo MAC1 al dispositivo con indirizzo MAC2 sul mezzo trasmissivo. Il mittente fa partire un timer dopo la trasmissione. Il ricevente MAC2 si accorge che il frame Ã¨ destinato a lui, ma rileva errori sui bit ricevuti, per cui non fa nulla (non passa il frame ai livelli superiori) e non invia la conferma a MAC1. Allo scadere del timer, MAC1 verifica che non ha ricevuto conferma, per cui ripete da capo la trasmissione, e fa ripartire il timer. Questa volta MAC2 riceve correttamente il frame e spedisce a MAC1 un frame di conferma. MAC1 riceve il frame di conferma e solo ora considera terminata con successo la trasmissione del frame. Ai livelli dei protocolli superiori al livello due tutto ciÃ² viene nascosto, e appare solamente la trasmissione corretta del frame sul segmento di rete.\nCollaborazione livelli per affidabilitÃ  (!!)ðŸŸ© Acknowledgement livello 4\nNon Ã¨ sufficiente verificare che funzioni a livello 2, bisogna anche avere un ACK a livello 4 che sia end-to-end, cosÃ¬ so sicuro che tutto il processo passo passo a livello MAC funziona, ossia sono riuscito effettivamente a raggiungere il destinatario.\nQuindi serve questo ack a livelli diversi e tempi diversi (uno fa end-to-end ack, lâ€™altro fa ack ogni step). Ma lâ€™ACK a livello 4 Ã¨ necessario, perchÃ© il mittende deve sapere se sia ricevuto, mentre il livello 2 non sarebbe strettamente necessario, ma Ã¨ molto probabile che vada male qualcosa a livello intermedio, e questo ACK riesce a risolvere problemi a questo livello ritrasmettendo.\nLivello 2 Evitare che un fallimento di singolo frame fallisca lâ€™intera trasmissione a livello piÃ¹ alto (e quindi riuscire a recuperare molto piÃ¹ in fretta se viene perso a questo livello). Livello 4 Informare il mittente che lâ€™informazione Ã¨ stato ricevuto correttamente (quindi end-to-end). Caso di segmento faulty !\nNel caso in cui il livello MAC non riesce proprio a ricevere lâ€™ACK, questo lo comunica al livello di Rete che ha una immagine della sua topologia di rete, e prova a creare un nuovo percorso per arrivare a destinazione. Si vede qua come avere piÃ¹ strare possibili per arrivare alla destinazione sia necessario.\nAlcune tecnologie di rete ðŸŸ© Ethernet\nIl piÃ¹ famoso Ã¨ il protocollo Ethernet che da il nome a una vasta serie di schede di rete che implementano la sua definizione, per lâ€™utilizzo in reti locali basate su mezzo fisico cablato. Lâ€™idea di base di Ethernet, per ridurre le collisioni dei segnali, Ã¨ di adottare il principio dellâ€™ascolto del canale, prima di ogni trasmissione (se vede che Ã¨ occupato, viene rigenerato un tempo di attesa casuale). Se nessuno sta giÃ  trasmettendo, allora la trasmissione puÃ² essere iniziata senza collisione con le trasmissioni in atto. Siccome puÃ² accadere che due schede di rete possano iniziare allo stesso istante le rispettive trasmissioni, occorre trovare una soluzione allâ€™insorgere di possibili collisioni. La scheda di rete trasmittente Ã¨ in grado di rilevare le collisioni in atto durante la trasmissione, e in tal caso interrompe immediatamente il tentativo di trasmissione. Il tentativo verrÃ  tentato da capo, dopo un attesa di tempo casuale, variabile da scheda a scheda.\nWifi\nUna tecnica simile a Ethernet viene adottata nelle reti senza fili (wireless), ad esempio in reti Wi-Fi conformi allo Standard IEEE 802.11. Il problema principale in reti senza fili Ã¨ dato dallâ€™impossibilitÃ  pratica di realizzare la rilevazione di collisioni in atto durante la fase di trasmissione. La tecnica si basa sulla prevenzione delle collisioni, dilazionando nel tempo i tentativi di accesso.\nToken Ring\nIl protocollo Token Ring Ã¨ un protocollo MAC concepito per reti locali con topologia ad anello. Lâ€™accesso Ã¨ regolato per mezzo di un frame speciale, detto Token, che viene passato (trasmesso), come se fosse un â€œtestimoneâ€, ciclicamente tra tutti i dispositivi in rete. Solo chi detiene il token ha diritto di trasmettere sul canale, evitando il rischio di collisione, dopodichÃ© deve trasmettere il token alla stazione successiva nellâ€™anello.\nLa cosa bella di questo Ã¨ che la trasmissione Ã¨ necessariamente senza collisioni dato che parla solo uno alla volta, questo Ã¨ una cosa molto bella.\nUn altra cosa Ã¨ acknowledgement implicito perchÃ© se il messaggio ritorna al mittente uguale, allora Ã¨ OK. Potrei anche costruire comunicazioni a pochi bit, veloci (simili a voice over IP).\nSvantaggio\nNon ho modo di recuperare se\nPerdo il token (questo Ã¨ una cosa molto grave!). Un host va giÃ¹, e viene rotto il link. (unique point of failure!) Note generali\nQueste reti si identificano tutte come best effort perchÃ© possono sempre non funzionare, causa collisioni o interferenze di rete\nEsempio di rete locale Appunti prof di boh\nLa figura mostra un esempio di rete locale composta da diversi segmenti: un segmento con topologia ad anello e protocollo MAC di tipo token ring colorato in rosso e da vari segmenti ethernet, con topologia a stella e a bus, colorati in blu. A sinistra, un calcolatore dotato di dispositivo di rete token ring con indirizzo MAC A Ã¨ connesso a un anello di rete token ring insieme ad altri 3 calcolatori e insieme a un bridge (oppure uno switch) identificato dal colore giallo (per indicare che agisce a livello MAC/LLC) e dalla lettera B sullo schermo. Il bridge B agisce da collegamento e traduttore dei frame tra il segmento token ring (rosso) ed il successivo segmento ethernet (blu). Il bridge B ha quindi due connettori di rete: uno token ring e uno ethernet. Il segmento ethernet del bridge B Ã¨ connesso a un Hub (H) dal quale partono sei segmenti ethernet, di tipo punto a punto, verso altrettanti calcolatori. Uno di questi calcolatori, identificato dalla lettera R Ã¨ un repeater, che propaga e amplifica i segnali verso un successivo segmento ethernet con topologia a bus, sul quale esistono quattro calcolatori. Al termine del bus esiste un nuovo repeater R, che propaga e amplifica i segnali verso un ultimo segmento ethernet con topologia a bus, al quale Ã¨ collegato un calcolatore dotato di scheda ethernet con indirizzo MAC B. Al di sopra dei dispositivi citati viene rappresentato il cammino logico di un frame trasmesso dal calcolatore con MAC A al calcolatore con MAC B, passando per i segmenti, i connettori di rete, e i livelli dei protocolli opportuni. In particolare, il bridge B Ã¨ lâ€™unico elemento nel quale il frame trasmesso sul segmento token ring sale fino al livello 2, per essere tradotto e ritrasmesso sul segmento uscente adottando il nuovo protocollo MAC ethernet. Nei rimanenti dispositivi hub e repeater, i frame sono semplicemente ricevuti e ri-trasmessi sui segmenti uscenti. Se il bridge avesse dovuto connettere piÃ¹ di due segmenti diversi, allora si sarebbe utilizzato uno switch, che svolge lâ€™attivitÃ  del bridge gestendo piÃ¹ interfacce di rete e protocolli. Dovrebbe essere chiaro a questo punto come sia possibile connettere diversi segmenti di rete locale, e gestire la trasmissione di frame di dati tra due dispositivi qualsiasi di una rete locale, semplicemente identificando i dispositivi attraverso il loro indirizzo MAC.\n","permalink":"https://flecart.github.io/notes/architettura-e-livelli-1-2/","summary":"Ripasso Prox: 140 Ripasso: June 1, 2023 Ultima modifica: March 15, 2023 3:01 PM Primo Abbozzo: October 14, 2022 5:49 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 1 Architettura e primi due livelli 0.4 Architettura di rete 0.4.1 PerchÃ© a stack ðŸŸ©- Capire lâ€™architettura significa capire la struttura (lâ€™organizzazione) del nostro app e comprenderne i motivi (i sottoproblemi risolti) che ogni livello prova a risolvere\nLa soluzione che Ã¨ stata individuata, e ha rappresentato uno dei principali cardini del successo delle reti e della nascita di Internet, Ã¨ data dalla separazione delle classi di protocolli in livelli.","title":"Architettura e livelli 1, 2"},{"content":"Ripasso Prox: 40 Ripasso: December 23, 2021 Ultima modifica: February 23, 2023 6:18 PM Primo Abbozzo: September 26, 2021 2:22 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Dubbi vecchi Le tappe principali dell\u0026rsquo;evoluzione del computer fino ai giorni moderni Capire bene la differenza fra CISC e RISC, in particolare il significato di microprogrammazione Capire bene la differenza fra parallelismo livello processore e livello istruzione, SIMD e MIMD Prefetch istruzioni Come funziona la predizione dei salti. December 14, 2021 3:43 PM\n2 Storia 2.1 0: Computer Meccanici dal 1600 a oggi\n2.2 1: Computer a Valvole Principalmente i computer della seconda guerra mondiale\n2.3 2: Computer a Transistor Abbattere i costi\n2.4 3: Circuiti stampati Computazione parallela Multiprogrammazione (Caricamento di piÃ¹ programmi) 2.5 4: VLSI PossibilitÃ  di creare tansissimi transistor\n2.6 5: Computer moderni 2.6.1 Computer Ubiqui 2.6.2 Computer invisibili 2.7 VelocitÃ  di calcolo 2.7.1 Flops and MIPS 3 CPU La struttura moderna degli elaboratori sono basati principalmente sull\u0026rsquo;architettura di Von Neuman, l\u0026rsquo;unica differenza Ã¨ che gli elementi di questa architettura.\n3.1 Struttura e funzione della CPU La CPU si puÃ² dividere in tre parti principali:\nUna unitÃ  di controllo che coordina i processi Registri che immagazzinano temporaneamente piccole quantitÃ  di informazioni ALU che fa i calcoli ordinategli dalla CPU 3.1.1 Registri Principali Program Counter o Instruction Pointer Contiene un pointer all\u0026rsquo;istruzione da eseguire cosÃ¬ lo prende dalla memoria Instruction Register Contiene l\u0026rsquo;istruzione da eseguire Memory Address Register Prende l\u0026rsquo;indirizzo del contenuto interessante dalla memoria Memory Data Register Prende il contenuto dalla memoria Program Status Word Raccoglie lo stato di esecuzione del programma, se fallisce se tutto ok oppure se ci sono errori 3.1.2 ALU Aritmetic Logic Unit, Ã¨ la componente che fa i calcoli.\nPer sapere cosa deve fare, Ã¨ la Control Unit che collega certe vie dai registri all\u0026rsquo;ALU.\nA seconda del genere di architettura puÃ² collegarsi direttamente in memoria (CISC) oppure sempre passando per i registri (solitamente RISC)\n3.1.3 Central Control Unit Il processore che decide cosa fare, se chiedere qualche altro pezzo dalla memoria seguendo il processo FDE Fetch Decode, Execute, oppure Scrivere qualcosa in memoria e cose simili.\n3.2 Filosofie Architetturali Complex Instructions Set Computer and Reduced Instructions Set Computer definiscono delle filosofie di architettura degli elaboratori differenti.\n3.2.1 CISC e microprogrammazione Utilizza una interpretazione che credo sia cosa a cui il prof. ha riferito come microprogrammazione, ovvero una programmazione delle istruzioni a livello molto basso.\nQuesto livello di interpretazione rallentava la macchina, perchÃ© non era direttamente eseguito sull\u0026rsquo;hardware. Inoltre la tendenza ad accedere direttamente la memoria **rendeva questo modello a volte imprevedibile in termini di tempo\nEsempio di microprogramma\nChiaro che se questo interamente fosse considerato una istruzione, ci sarebbe un alto bisogno di cicli di clock (diventarebbe in generale piÃ¹ lento).\n3.2.2 RISC e peculiaritÃ  Una delle peculiaritÃ  principali delle architetture RISC Ã¨ il numero ridotto di istruzioni necessarie (che perÃ² erano molto veloci perchÃ© girava direttamente sull\u0026rsquo;hardware).\nInoltre ha introdotto un sistema load store con cui affacciarsi alla memoria.\n3.2.3 Alcuni confronti La filosofia attuale Ã¨ la RISC, perÃ² a causa della grande presenza di elaboratori CISC, si Ã¨ preferito creare architetture ibride che comprendano entrambi: presenza di istruzioni complesse che vengano eseguite su istruzioni harware di RISC. â†’ Minore ciclo di Clock e quindi maggiore velocitÃ .\nLa differenza principale Ã¨ che CISC possiede istruzioni complesse molte dei quali vanno ad accedere la memoria (la parte lenta del processo) invece la RISC possiede soltanto i comandi load and store per accedere alla memoria, il resto delle istruzioni opera all\u0026rsquo;interno del microprocessore.\n3.3 VelocitÃ  CPU 3.3.1 Clock e Data Path Cycle Il significato di clock Ã¨ spiegato molto meglio nella sezione dei Circuiti Sequenziali\nClock Ã¨ tempo per l\u0026rsquo;istruzione piÃ¹ corta, se fosse ancora piÃ¹ corta Ã¨ molto probabile che la CPU verrebbe indotta in errori molto comuni per cui il computer non funzionerebbe piÃ¹ (un istruzione viene eseguita quando il precedente non Ã¨ ancora finito).\nUna Data Path Cycle Ã¨ l\u0026rsquo;intero processo che comporta lettura dai registri, calcolo e registrazione del risultato\n3.3.2 Aumentare la velocitÃ  Ci sono delle soluzioni per rendere la CPU piÃ¹ veloce:\nMigliori reti elettriche (agli informatici non interessa) Overclocking (per un pÃ²) Memoria cache (spesso in RISC) Multi-core Pipelining Parallelismo Esattamente come una linea di assemblaggio di fabbrica, possiamo definire alcune parti per processi specifici. 3.4 Parallelismo Circa 3-4 volte piÃ¹ veloce e poco costoso per crearlo, in quanto i pezzi sono efficienti, con pipeline di 5 sotto c\u0026rsquo;Ã¨ bisogno di una sola ALU a differenza di 5 per avere funzionalitÃ  simili.\n3.4.1 Pipelining Spesso alcune istruzioni sono ottimizzate in termini di tempo nel caso sia presente la pipeline o meno, per cui Ã¨ interessante poter averlo a mente. Parallelismo livello istruzione\nEsempio:\n5 step.\nCarica l\u0026rsquo;istruzione Interpreta l\u0026rsquo;istruzione Fetch dei dati necessari Esecuzione dopo aver ricevuto i dati Scrittura del risultato. Ogni singola istruzione passa ogni volta secondo questa pipeline, che lavorano in parallelo, velocizzando il CHIP.\n3.4.2 Multicore ~ SIMD \u0026amp; MIMD Ci sono dei computer moderni che contengono molteplici CPU uguali a quanto descritti in 3.1.1\nSIMD\nSingle instruction-stream multiple data-stream *Istruzioni a dati diversi: Tutte le CPU hanno lo stesso stream di dati (magari elaborazione immagini, un qualcosa di ripetitivo su stessa cosa)\nSi guadagna in control unit, unica, fetch unica.\nEsistono anche i processori vettoriali.\nDi solito questo genere di architettura sono utili per istruzioni uguali a dati diversi come l\u0026rsquo;elaborazione di un immagine\nMIMD\nLa differenza dal precedente Ã¨ che l\u0026rsquo;istruction stream Ã¨ multiplo, ma un pÃ² piÃ¹ costoso perchÃ© ci sono molte CPU complete.\nAvere troppe CPU su una memoria condivisa non andrebbe bene, perchÃ© si dovrebbero aspettare. Meglio avere una rete fra CPU per cose grosse.\nCioÃ¨ se collegassi troppe CPU, probabilmente l\u0026rsquo;unico bus andrebbe in stallo perchÃ© tutti cercherebbero ad accedere alla stessa memoria, e le CPU dovrebbero attendersi fra di loro, cosa non buona per la performance.\n3.4.3 Rete di Computer Una soluzione che si solito viene utilizzata dalle grandi aziende o comunque chi possiede le risorse Ã¨ la costruzione di grandi reti di calcolatori che possano operare all\u0026rsquo;unisono, o comunque con certo criterio. Dovrebbero essere un sacco di CPU separate che comunicano con un computer centrale che agisce come da UnitÃ  di Controllo.\nDi solito Multi-core e reti di computer sono conosiderati parallelismo a livello processore\nLe redi di computer sono solitamente facili da costruire ma difficile da programmare, mentre invece un multicore Ã¨ difficile da costruire ma facile da programmare.\nInvece il pipelining Ã¨ considerato un parallelismo a livello istruzione.\n3.4.4 Prefetch-istruzioni Questa cosa Ã¨ molto simile al prefetch della Memoria cache.\nInstruction Fetch Unit sono elementi di Hardware che caricano l\u0026rsquo;istruzione successiva nel momento in cui la presente Ã¨ in esecuzione.\nQuesto avviene perchÃ© il caricamento dell\u0026rsquo;istruzione Ã¨ spesso molto lenta.\nQuesta instruction cache prefecht puÃ² essere implementata a due livelli, Hardware o software.\n3.4.5 Pipeline (e salti) Esempio di pipeline\nL\u0026rsquo;esempio fatto qui Ã¨ giÃ  considerabile come un primo passo di Pipeline, in cui molteplici passi possono essere fatti allo stesso momento dentro la CPU.\nSolamente la prima esecuzione servono 5-7 clock (a differenza delle parti), quindi basta un ciclo di clock per la fase piÃ¹ lunga per essere sicuri, ecco che riusciamo a completare l\u0026rsquo;istruzione in modo molto piÃ¹ veloce.\nSe una singola istruzione dovrebbe fare tutto, saremmo costretti a tenere un clock molto elevato e il computer nel complesso sarebbe molto lento.\nSalti\nSe faccio un salto allora c\u0026rsquo;Ã¨ un buco nel pipeline, ossia cose nel pipeline che non eseguono (perchÃ© devo saltare), cioÃ¨ fetch e decode di certe istruzioni non mi devono servire.\n(ho decodato una istruzione) ma nel frattempo ho giÃ  caricato 4 e 5 che non mi servono!\n3.4.6 Predizione di salti Possiamo utilizzare certe euristiche (ragionamenti caso per caso) per predire alcuni salti.\nSalti all\u0026rsquo;indietro\nSi possono prevedere per cicli while e for dei salti all\u0026rsquo;indietro.\nPer salti incondizionati si puÃ² mettere una instruzione NOP in modo che faccia salti incondizionati senza sprecare istruzioni.\nEsempio data race (read after write)\nAX = 0\nBX = 0\nDX = 0\nAX = DX + 1\nBX = AX - 1\nfetch a decode a, fetch b leggo DX (a) , decode b DX + 1 (a), leggo AX (b) MA STO LEGGENDO TROPPO PRESTO! Quindi devo chiudere AX ed aspettare che AX venga scritto\nA volte, tipico dei processori CISC, si tende a eseguire minicomandi in ordine diverso perchÃ© ritenuti piÃ¹ efficienti, quindi si mischia un pÃ², proprio come intendi per combinatorio e la fai.\nEntra cisc ma esegue risc.\nEsiste una BPUÂ (Branch Prediction Unit), che cerca di predire l\u0026rsquo;esito di un salto, come spiegato in questa pagina di wiki e una BTP (Branch Target Predictor) che controlla le istruzioni nel ramo di arrivo (qui). Questi sono le componenti principali che determinano la predizione dei salti.\nIn alternativa si mettono dei NOP. o di arrivo (qui). Questi sono le componenti principali che determinano la predizione dei salti.\nIn alternativa si mettono dei NOP.\n","permalink":"https://flecart.github.io/notes/cpu-e-storia-degli-elaboratori/","summary":"Ripasso Prox: 40 Ripasso: December 23, 2021 Ultima modifica: February 23, 2023 6:18 PM Primo Abbozzo: September 26, 2021 2:22 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Dubbi vecchi Le tappe principali dell\u0026rsquo;evoluzione del computer fino ai giorni moderni Capire bene la differenza fra CISC e RISC, in particolare il significato di microprogrammazione Capire bene la differenza fra parallelismo livello processore e livello istruzione, SIMD e MIMD Prefetch istruzioni Come funziona la predizione dei salti.","title":"CPU e storia degli elaboratori"},{"content":"Introduzione alla normalizzazione PerchÃ© si normalizza? ðŸŸ© Cercare di aumentare la qualitÃ  del nostro database, perchÃ© praticamente andiamo a risolvere delle anomalie possibili al nostro interno, e questo aiuta per la qualitÃ .\nTipologie di anomalie (!) (4) ðŸŸ¨+ Ridondanze, non vorrei avere la stessa informazione espressa piÃ¹ volte in troppi punti. Update non consistente, quando per aggiornare un singolo valore devo aggiornare moltissime altre tuple dipendenti da essa. Deletion non consistente, la presenza di certe entitÃ  Ã¨ strettamente dipendente da presenza di altri, nell\u0026rsquo;esempio in questione sulle slides, se elimino tutti gli utenti, elimino anche i progetti su cui hanno partecipato, mentre invece dovrebbero essere separati. Insertion, ad esempio se non posso inserire un certa entry finchÃ© una altra proprietÃ  legata (ma per il resto indipendente non Ã¨ stat definita, nell\u0026rsquo;esempio del prof provare ad inserire un lavoratore, ma senza progetto.) Dipendenze funzionali Vogliamo cercare di identificare le dipendenze funzionali e separarle, questo aiuta a creare qualitÃ  nel database La dipendenza funzionale Ã¨ un vincolo di integritÃ  speciale, simile a quello relazionale spiegato in Relazional Model\nDefinizione formale di dipendenza funzionale ðŸŸ© Data una relazione $r$ sullo schema $R(X)$ due sottoinsiemi non vuoti di attributi $Y$ e $Z$ sono detti funzionalmente dipendenti per ogni coppia di tuple $t_{1}$ e $t_{2}$ in $r$ con stessi valori per tutti gli attributi in $Y$ abbiamo che questi hanno gli stessi valori anche su $Z$.\nOsservazioni:\nFunzione, perchÃ© in un certo senso il primo insieme Ã¨ il dominio, e il secondo Ã¨ il codominio, ed Ã¨ come se ci fosse una funzione che li associ. Esistono dipendenze funzionali banali quelli il cui il secondo insieme di attributi Ã¨ un sottoinsieme del primo. Dipendenza funzionale con chiave essendo unica, non abbiamo duplicati di chiave, quindi l\u0026rsquo;implica implicito nella definizione ha sempre l\u0026rsquo;ipotesi falsa, quindi Ã¨ sempre vero (guarda logica per capire il senso della mia frase). Definizione formale Boyce e Codd (!) ðŸŸ© Una relazione $r$\tsi dice in forma normale di Boyce e Codd se per ogni dipendenza funzionale non banale $X \\to A$ definita sulla relazione, $X$ contiene una chiave $K$ di $r$, cioÃ¨ $X$ Ã¨ una super-chiave di $r$\nOssia vogliamo solamente dipendenza funzionali tramite chiavi, e non in altro modo, altrimenti probabilmente avrÃ² una ripetizione.\nDefinizione terza forma normale ðŸŸ¨\u0026ndash; Ãˆ una forma leggermente piÃ¹ rilassata, utile per normalizzare anche quando BC non Ã¨ possibile fare.\nUna relazione $r$ Ã¨ in terza forma normale se per ogni dipendenza funzionale $X \\to Y$ non banale vengono verificate una delle due condizioni:\n$X$ ha una chiave di $r$ ogni attributo di $Y$ appartiene ad almeno una chiave di $r$ Il primo dovrebbe corrispondere a Boyce Codd. Il secondo credo sia nuovo, possiamo dire quindi che sia una estensione, che permette la definizione di normalizzazione essere applicata a piÃ¹ cose. Questa decomposizione Ã¨ sempre possibile, abbiamo un teorema che lo dice.\nMetodi di normalizzazione Decomposizione senza perdita. ðŸŸ© Sia dato un insieme di attributi $X$ e una decomposizione, non partizione, in $X_{1}$ e $X_{2}$, abbiamo che la relazione $r$ si decompone senza perdita su $X_{1}$ e $X_{2}$ quando la join delle due Ã¨ uguale a $r$. ossia: $\\pi_{X_{1}}(r) \\bowtie \\pi_{X_{2}}(r) = r$\nQuesta Ã¨ una necessitÃ  per ricostruire le informazioni iniziali senza nessuna perdita. Si puÃ² notare che talvolta seguendo in modo cielo le dipendenze funzionali che si possono trovare seguendo una via di Boyce and Codd, non Ã¨ sufficiente per mantenere questa proprietÃ  tanto importante.\nPrendiamo un esempio con perdita (perchÃ© vado a ricostruire un esempio con piÃ¹ informazioni): Questa non Ã¨ una cosa che vogliamo!\nUn modo per risolvere questo Ã¨ aggiungere degli attributi fittizi che ci aiutano a discriminare sulle cose che ci servono. Ci fanno da specie di chiave.\nConservazione delle dipendenze ðŸŸ© Questo permette di mantenere i vincoli di integritÃ .\nUna decomposizione preserva la dipendenza se ogni dipendenza funzionale dello schema originale ha attributi che compaiono nello stesso schema, altrimenti non Ã¨ possibile rilevare le dipendenze funzionali (Atzeni, pagina 332)\nCioÃ¨ se spezzo una dipendenza funzionale in tavole diverse, questa proprietÃ  non viene soddisfatta, perchÃ© non sarei piÃ¹ in grado di trackarlo.\nPrendiamo un esempio in cui questa caratteristica si dimostra utile\nNormalizzazione nello schema concettuale ðŸŸ¨\u0026ndash; Possiamo utilizzare questa idea anche nella parte di sviluppo di schemi E-R. Se riconosco a questo livello che c\u0026rsquo;Ã¨ una dipendenza funzionale, questo mi da indicazioni su come continuare lo sviluppo di questo. Nell\u0026rsquo;esempio sulle slides motiva un partizionamento verticale, vedi Database logical design.\n","permalink":"https://flecart.github.io/notes/normalizzazione-dei-database/","summary":"Introduzione alla normalizzazione PerchÃ© si normalizza? ðŸŸ© Cercare di aumentare la qualitÃ  del nostro database, perchÃ© praticamente andiamo a risolvere delle anomalie possibili al nostro interno, e questo aiuta per la qualitÃ .\nTipologie di anomalie (!) (4) ðŸŸ¨+ Ridondanze, non vorrei avere la stessa informazione espressa piÃ¹ volte in troppi punti. Update non consistente, quando per aggiornare un singolo valore devo aggiornare moltissime altre tuple dipendenti da essa. Deletion non consistente, la presenza di certe entitÃ  Ã¨ strettamente dipendente da presenza di altri, nell\u0026rsquo;esempio in questione sulle slides, se elimino tutti gli utenti, elimino anche i progetti su cui hanno partecipato, mentre invece dovrebbero essere separati.","title":"Normalizzazione dei database"},{"content":"Ripasso Prox: 20 Ripasso: May 31, 2023 Ultima modifica: May 14, 2023 4:31 PM Primo Abbozzo: April 4, 2023 10:15 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Polimorfismo Introduzione Monoforfo ðŸŸ© Quando non posso utilizzare un tipo come parametro. Ossia non possiamo definire una funzione generica.\nSlide monomorfismo\nPolimorfismo Polimorfismo, come dice il nome, significa avere tante forme, in questo caso tanti tipi. Ma avere tanti tipi non Ã¨ una cosa ambigua? Questa cosa si risolve solitamente a compile time (facendo checks di sottotipo, oppure dispatch della funzione corretta).\nTipologie di Polimorfismo (3) ðŸŸ© Slide tipologie di monomorfismo\nad-hoc polymorphism questo Ã¨ anche chiamato overloading in cui vado a definire un nuova funzione (con lo stesso nome) che accetti il nuovo tipo di dato.\nsubtype polymorphism\nparametric polymorphism\nAd-hoc (3) ðŸŸ© Slide ad-hoc polimorphism\nQuesto Ã¨ molto simile al tipo somma, solamente fatto da un punto di vista funzionale (i domini devono essere separati).\nIn C sono molto conosciute questa tipologia di polimorfismo. PerÃ² ci sono anche forme comuni, come lâ€™operatori aritmetici.\nLâ€™invocazione Ã¨ anche chiamato dispatch , quando abbiamo risolto lâ€™overloading, ossia abbiamo fatto il dispatch dellâ€™invocazione, allora lâ€™overloading scompare e viene eseguita una specifica funzione. Questa funzione puÃ² essere fatta in modo statico oppure dinamico.\nRiassumento:\nDefinisco stesso nome che prendono tipi diversi Avviene un dispatch statico o dinamico Una volta avvenuto il dispatch, la funzione eseguita Ã¨ univocamente identificata. Statico o dinamico nel dispatch\nDispatch Ã¨ il processo che va a decidere la funzione overloadata da chiamare, questo processo si puÃ² classificare come dinamico se avviene durante il runtime (come solitamente Ã¨ per le interfacce) oppure statico quando avviene e a tempo di compilazione (come solitamente avviene per le funzioni overloaddate).\nDi sottotipo Possiamo andare a dire che un tipo S Ã¨ sottotipo di un tipo T, indicato con $S \u003c: T$, quando S puÃ² essere utilizzato in qualunque occasione al posto di T. Questo Ã¨ anche chiamato come principio di sostitutione di Liskov.\nSetTheory per sottotipi ðŸŸ©â€” Slide polimorfismo di sottotipo\nQuesto concetto lâ€™abbiamo anche accennato in Algebra dei tipi quando abbiamo parlato di coercizione.\npraticamente quando abbiamo un tipo piÃ¹ specifico $S$ che andiamo ad indicare con $S \u003c: T$, allora quando ho S e devo utilizzare T, lo posso fare, questo perchÃ© S contiene tutte le caratteristiche di T.\nSolitamente questa Ã¨ una relazione di preordine ossia riflessiva e transitiva, spesso anche antisimmetrica, quindi Ã¨ spesso un ordine parziale.\nSi puÃ² dire che esiste un rapporto di specificazione (parola da utilizzare nellâ€™orale per bella figura lel) perchÃ© S Ã¨ piÃ¹ specifico di T, in questo senso possiamo utilizzare S in ogni posto in cui câ€™Ã¨ T.\nTipologie di sottotipaggio (2) ðŸŸ© Slides subtyping con records\nPer questa parte possiamo andare a definire un concetto di sottotipaggio per profonditÃ  o per larghezza.\nPer laghezza: basta che il sottotipo abbia molti piÃ¹ campi! in questo senso Dog \u0026lt; Animal, perchÃ© anche dog posso utilizzarlo come un animal, dato che ha tutte le cose di animal. (lâ€™unica differenza col duck typing Ã¨ il fatto che T qui Ã¨ esplicito, mentre nel duck typing non mi importa del tipo, solamente dello stesso utilizzo).\nDifferenza fra duck e width subtyping per chatGPT\nWidth subtyping is a form of subtype polymorphism where a type is considered a subtype of another type if it has at least the same properties and methods as the supertype. This means that a subtype can have more properties and methods than the supertype, but it must at least have all of the ones that are defined in the supertype. This is called \u0026ldquo;width\u0026rdquo; because it is based on the width of the type\u0026rsquo;s interface.\nDuck typing, on the other hand, is a more dynamic approach to type checking where the type of an object is determined by its behavior at runtime rather than its static type. In other words, if it walks like a duck and quacks like a duck, then it must be a duck. This means that two objects with different types can still be treated as if they have the same type if they share the same behavior.\nIn summary, width subtyping is based on the interface of a type and allows for subtype polymorphism, while duck typing is based on the behavior of an object at runtime and allows for more dynamic type checking.\nPer profonditÃ : Quando un campo ha un tipo che sia un sottotipo di un altro. Questo Ã¨ visto molte meno volte, perÃ² si puÃ² fare. Questa ha perÃ² delle particolaritÃ , Ã¨ importante introdurre il concetto di covariante per tipi quando le parti del record mantengono la stessa direzione di sottotipaggio. Quando abbiamo due tipi che sono covarianti, possiamo utilizzarli solo per le letture. In scrittura perÃ² potremmo avere dei campi non inizializzati, quindi non va molto bene. (nell\u0026rsquo;esempio avremmo un animale in output in scrittura, mentre gli abbiamo dato un dog e ci aspettavamo un dog in output). (queste nozioni di covarianza comunque sono sempre in funzione del contesto).\nIn pratica vado a rimpazzare i campi del record con dei sottotipi, questo Ã¨ buono per cose immutabili, for example, you can assign 1.5 to the \u0026lsquo;x\u0026rsquo; field of a real point (a record with two real fields), but you can\u0026rsquo;t do the same to the \u0026lsquo;x\u0026rsquo; field of an integer point (which, however, is a deep subtype of the real point type) because 1.5 is not an integer.\nCovariante e Controvariante e consumo (!!) ðŸŸ¨++ Slide covariante, controvariante e consumi e produzione\nEsempio strano\nQuesta nozione si basa sullâ€™inversione fra produzione e consumazione.\nAvevamo detto che abbiamo una relazione di sottotipo, perchÃ© DogHouse \u0026lt; AnimalHouse quindi sono covarianti rispatto a Dog \u0026lt; Animal House. Ma nella fase di consumo, questo si inverte, quindi si puÃ² dire che siano controvarianti.\nIn breve:\nConsumo (input) â†’ Controvariante Produzione (output) â†’ Covariante Il motivo per cui succede Ã¨ che Dog fn utilizza i campi di Dog, che sono piÃ¹ estesi, posso sostituire a questo consumo anche animal, che utilizza i campi di animal, quindi sono anche presenti in Dog, ecco che il rapporto si inverte\nPossiamo fare un parallelo fra le funzioni di consumo e quelle di produzione.\nSlide esempio covariante e controvariante easy\nSussunzione ðŸŸ¨ Con sussunzione andiamo a parlare di quando possiamo fare lâ€™inferenza di sottotipaggio ossia se Ã¨ vero o meno che un tipo Ã¨ sottotipo di un altro (e quindi possibile utilizzare S al posto di T in qualunque luogo).\nSlide sussunzione metodi\nPossiamo fare la sussunzione in modo estensionale o intensionale quindi o:\nCaratterizzando tutti gli elementi del sottotipo Parlare di predicati e domini. Tipo estensionali o intensionali ðŸŸ©- abbiamo parlato di estensionale o intensionale\nEsempi di sussunzione\nPolimorfismo parametrico Tipi parametrici ðŸŸ© Slide tipi parametrici\nQuando abbiamo delle operazioni anche se non conosciamo esattamente cosa câ€™Ã¨ sotto, perÃ² riguardo la struttura so bene cosa vanno a fare. (un esempio riguardo a questo Ã¨ il sort).\nQuesta parametrizzazione ci permette di definire delle cose per tutti i tipi che possiedono quella funzione (ricorda i tratti di rust), ed Ã¨ per questo che possiamo dire che sia un tipo universale. Questa cosa che vale per tutti ci permette di poter provare dei teoremi aggratis.\nEsempio di teorema for free\nIbridazione con polimorfismo di sottotipo ðŸŸ¨ Slide ibrido con pol di sottotipo\nA volte non vogliamo che la nostra funzione vada per tutti, senza quindi conoscere come Ã¨ fatto sotto, vorremmo avere certe funzioni (quindi un sottotipo del tipo generale), per esempio nei tratti di rust possiamo dire che questa nostra funzione vada per tutte in cui Ã¨ definita una certa funzione/interfaccia/tratto, in questo senso andiamo ad utilizzare un sottotipo\nArray câ€™erano giÃ  allâ€™inizio, lo puoi utilizzare covariante in entrambe le direzioni, mentre altrimenti non ti permetterebbe di utilizzare in entrambe le direzioni (vuole che tu sia prima sicuro se vuoi utilizzarlo come consumer o producer. un buon modo per ricordarsi Ã¨ PECS producer deve estender, mentre consumer deve fare super.\nAbbiamo sempre che Ã¨ safe, nel senso che ritorna sempre un tipo senza bloccarsi (e posso sapere a tempo di compilazione cosa vada a ritornare).\nEsempi di utilizzo di polimorfismo parametrico e di sottotipo Tipi maybe e result ðŸŸ© Questi sono alcuni tipi ispirati alle monadi, solamente capire in che formato sono:\nMaybe: Some + None Result: come le promises di js, possiamo esprimere i risultati di errore e nel caso sia andato tutto bene. ","permalink":"https://flecart.github.io/notes/polimorfismo/","summary":"Ripasso Prox: 20 Ripasso: May 31, 2023 Ultima modifica: May 14, 2023 4:31 PM Primo Abbozzo: April 4, 2023 10:15 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Polimorfismo Introduzione Monoforfo ðŸŸ© Quando non posso utilizzare un tipo come parametro. Ossia non possiamo definire una funzione generica.\nSlide monomorfismo\nPolimorfismo Polimorfismo, come dice il nome, significa avere tante forme, in questo caso tanti tipi. Ma avere tanti tipi non Ã¨ una cosa ambigua?","title":"Polimorfismo"},{"content":"Ripasso Prox: 120 Ripasso: July 1, 2023 Ultima modifica: April 1, 2023 9:03 AM Primo Abbozzo: September 28, 2022 11:20 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\n1 Programmazione concorrente Vorremmo cercare di stabilire una teoria riguardante programmi che vengono eseguiti appunto concorrentemente, senza una esecuzione classica uno dpo lâ€™altro\nEsempio mini-programma rallentamento\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; void test(void *s) { for (int i = 0; i \u0026lt; 10; i++) { printf(\u0026#34;%s\\n\u0026#34;, s); for (int j = 0; j \u0026lt; 100000000; j++); } } int main(int argc, char *argv[]) { pthread_t t1, t2; pthread_create(\u0026amp;t1, NULL, (void *)test, \u0026#34;Uno\u0026#34;); pthread_create(\u0026amp;t2, NULL, (void *)test, \u0026#34;Due\u0026#34;); pthread_join(t1, NULL); pthread_join(t2, NULL); } Example output:\nDue Uno Uno Due Uno Due Due Uno Due Uno Due Uno Due Uno Due Uno Due Uno Due Uno\nEsempio 2 mini-programma rallentamento\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int count = 0; void test(void *s) { for (int i = 0; i \u0026lt; 100000; i++) { count+= 1; } } int main(int argc, char *argv[]) { pthread_t t1, t2; pthread_create(\u0026amp;t1, NULL, test, \u0026#34;Uno\u0026#34;); pthread_create(\u0026amp;t2, NULL, test, \u0026#34;Due\u0026#34;); pthread_join(t1, NULL); pthread_join(t2, NULL); printf(\u0026#34;%d\\n\u0026#34;, count); } Vogliamo creare un modello teorico che riesca a rappresentare il concetto di processi concorrenti, questo Ã¨ il modello concorrente\nProcessi Differenza col programma ðŸŸ© Il programma Ã¨ statico, mentre il programma Ã¨ dinamico. Questo perch\u0026rsquo;e il processo Ã¨ un programma attivo, in esecuzione. Un filo esecutivo, qualcosa che evolve in modo autonomo.\nInvece il programma Ã¨ la sequenza di istruzioni.\nFinite progress ðŸŸ© Ogni processo viene eseguito a velocitÃ  finita non nulla\nDescrizione del processo (3) ðŸŸ© Questa parte Ã¨ descritta meglio in Processi e thread\nPossiamo descrivere lo stato di un processo memorizzando alcuni dati molto precisi, questi sono:\nStato di avanzamento (Istruzione da eseguire e il suo stato) La sua memoria utilizzata (dati, stack e file aperti) Memoria nel processore (i dati nel registro e simili) Concorrenza Concorrenza e dove trovarla\nDefinizioni concorrenza e Race C ðŸŸ© Esecuzione concorrente\nDue processi si dicono in esecuzione concorrente se vengono eseguiti in parallelo (con parallelismo reale o apparente)\nConcorrenza\nUn insieme di notazioni e tecniche per rappresentare e risolvere problemi di esecuzione concorrente.\nRace condition\nSi dice che un sistema di processi multipli presenta una race condition qualora il risultato finale dell\u0026rsquo;esecuzione dipenda dalla temporizzazione con cui vengono eseguiti i processi\nTipologie di concorrenza (3) ðŸŸ© Multiprogramming\nÃˆ un parallelismo apparente perchÃ© la CPU Ã¨ solamente quella, ma esegue tante cose e cosÃ¬ velocemente che sembra star eseguendo in modo parallelo. Si parla infatti di interleaving.\nMultiprocessing\nparallelismo reale perchÃ© effettivamente ho tante CPU, o tanti core in cui far eseguire programmi in modo contemporaneo, in questo caso, come anche nell\u0026rsquo;esempio seguente si parla di overlapping (distanti nello spazio)\nDistributed processing\nParallelismo reale ma a una scala piÃ¹ grande che va oltre al singolo computer dato che ho un sistema di piÃ¹ computer che eseguono piÃ¹ processi\nEsempio di problema di concorrenza ðŸŸ©- Codice slide cattivo\nSuccede un problema molto simile a read after write, che un programma ha uno stato non aggiornato e fa una operazione con informazioni vecchie che sovrascrivono le informazioni nuove.\nEsempio multiprogramming di esecuzione errata\nEsempio multiprocessing di esecuzione errata\nPossiamo andare a cercare le cause di questi problemi, che sono principalmente causati da\nCause principali (comuni a multiproc e multiprog)\nAccesso a memoria condivisa Sconosciuta velocitÃ  di esecuzione del singolo processo. Interazione fra progressi(2)ðŸŸ© Vogliamo cercare di avere alcuni metodi affinchÃ© due processi differenti si possano coordinaree cooperare.\nConoscenza indiretta\nQuando condividono un pezzo di memoria e comunicano in questo modo indiretto.\nConoscenza diretta\nQuando un processo conosce un ID di un altro processo e manda proprio dei messaggi e cose allâ€™altro programma\nProprietÃ  cooperazione (2) ðŸŸ©- ProprietÃ  vogliamo dire una caratteristica che rimane vera per ogni esecuzione del programma, come se fosse un teorema per il programma.\nSafety â†’ Correttezza\nVuol dire che il programma non fa cose cattive (se puÃ² scegliere fra due valori, devono scegliere lo stesso valore).\nun programma non interferisce con un altro.\nLiveness â†’ Terminazione\nOssi ail programma continua ad eseguire rimane vivo e ritorna il suo risultato e fa quello che deve fare (ossia deve arrivare a soluzione).\nUn programma non deve essere interrotto ininterrottamente (ossia non deve continuare all\u0026rsquo;infinito) (possiamo dire che non c\u0026rsquo;Ã¨ starvation in questa parte).\nMutua esclusione, Deadlock e starvation ðŸŸ© l\u0026rsquo;accesso ad una risorsa si dice mutualmente esclusivo se ad ogni istante, al massimo un processo puÃ² accedere a quella risorsa\nDeadlock\nÃˆ un problema che Ã¨ risolto dalla mutua esclusione (in cui due programmi interferiscono fra di loro e causano questo blocco).\nDa vedere lâ€™esempio dei programmi\nEsempio in figura degli incroci\nEsempio programmi\nStarvation\nÃˆ un problema di liveness dato che puÃ² capitare che un processo sia sempre messo davanti a un altro, e quindi un certo programma non verrebbe mai eseguito.\nEsempio coda\nEsempio programmi\nAzioni atomiche ðŸŸ© ProprietÃ :\nIndivisibile O avviene o non avviene niente Nel linguaggio c in particolare, dipende da processore e compilatore (perchÃ© potrebbe utilizzare istruzioni che non si traducono in una singola in codice macchina).\nEsempi atomicitÃ  di istruzioni in C\nParallelismo reale\nquesta azione atomica non interferisce con altri\nAl fine di raggiungere questo obiettivo viene utilizzato un sistema di arbitraggio dei bus. (quindi un processo prende prima dellâ€™altro).\nParallelismo apparente\nil context switch avviene prima o dopo lâ€™azione. Questo Ã¨ possibile perchÃ© lâ€™interrupt Ã¨ sempre runnato prima o dopo quellâ€™azione.\nNote sul C (non importante, + pratica) Inizialmente questo linguaggio Ã¨ nato proprio per scrivere sistemi operativi, non si scrive in assembly perchÃ© questo linguaggio non Ã¨ portabile su macchine diverse.\nCaratteristiche di linguaggio per SO PossibilitÃ  di gestione completa dei dati nella memoria. LeggibilitÃ  di un linguaggio di alto livello https://so.v2.cs.unibo.it/wiki/index.php/Prin_C_ples\nEsempietto boostrap\nEsperimento didattico: portabilitÃ  dei compilatori\nHo un linguaggio di alto livello L, e una macchina fisica M e una macchina intermedia N, vorrei fare un compilatore da L a M.\nAllora ho un compilatore da L a M che gira in N molto scrauso. Mi scrivo il compilatore da L a M che gira in N, lo compilo e ho un compilatore da L a M scritto in M\n","permalink":"https://flecart.github.io/notes/programmi-concorrenti/","summary":"Ripasso Prox: 120 Ripasso: July 1, 2023 Ultima modifica: April 1, 2023 9:03 AM Primo Abbozzo: September 28, 2022 11:20 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\n1 Programmazione concorrente Vorremmo cercare di stabilire una teoria riguardante programmi che vengono eseguiti appunto concorrentemente, senza una esecuzione classica uno dpo lâ€™altro\nEsempio mini-programma rallentamento\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; void test(void *s) { for (int i = 0; i \u0026lt; 10; i++) { printf(\u0026#34;%s\\n\u0026#34;, s); for (int j = 0; j \u0026lt; 100000000; j++); } } int main(int argc, char *argv[]) { pthread_t t1, t2; pthread_create(\u0026amp;t1, NULL, (void *)test, \u0026#34;Uno\u0026#34;); pthread_create(\u0026amp;t2, NULL, (void *)test, \u0026#34;Due\u0026#34;); pthread_join(t1, NULL); pthread_join(t2, NULL); } Example output:","title":"Programmi Concorrenti"},{"content":"Ripasso Prox: 27 Ultima modifica: October 7, 2022 1:25 PM Primo Abbozzo: October 15, 2021 10:35 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Vecchi dubbi Cosa Ã¨ la sintassi I costituenti della BNF (ripassarreeee le tre soluzioi per l\u0026rsquo;ambibuitÃ  definizione di linguaggio Differenza funzioni matematiche ed informatiche Context-free-grammar per AST Cosa significa espandere un non terminale? 4 Sintassi Programmare e dimostrare sono sostanzialmente la stessa attivitÃ  ~Coen\nMa non secondo l\u0026rsquo;industria\u0026hellip;\n4.1 Introduzione 4.1.1 Definizione e necessitÃ  Branca della linguistica, studia creazione di proposizione e il loro collegamento per la creazione di un periodo\nIn seguito la semantica dÃ  un metodo a queste proposizioni in modo che abbiano un senso.\nUtile o necessario per la definizione del linguaggio artificiale 4.1.2 Alfabeto, stringa, linguaggio e grammatica Alfabeto: Insieme non vuoto di simboli (che spesso sono diversi fra di loro)\nStringa seguenza finita (vuoto Ã¨ possibile) di simboli $\\epsilon = \\empty$\nLinguaggio: insieme di stringhe (di qualunque tipo, finito o infinito).\nGrammatica formalismo (un insieme di regole che lo rende finito) che definisce un linguaggio\n4.2 Backus-Naur Form Ora Ã¨ descritto anche in Descrizione linguaggio\nIndicato con BNF\n4.2.1 PerchÃ© BNF Una formalizzazione informatica che permetta l\u0026rsquo;elaborazione di grammatiche â†’ notazione per descrivere grammatiche\nNon Ã¨ l\u0026rsquo;unica ma per gli informatici Ã¨ la migliore.\n4.2.2 Caratteristiche Indichiamo con $(T, NT, X, P)$ rispettivamente\nT = l\u0026rsquo;alfabeto, l\u0026rsquo;insieme di simboli che usiamo\nNT Ã¨ un insieme di simboli diversi da T (insieme non terminale) Sono solamente ausigliari.\nX = qualunque elemento di NT, basta che sia iniziale\nP = simile alla grammatica, sono delle coppie come produzioni: comprendono:\nNon terminali Insieme di stringhe che contengono un pÃ² di tutto ,indicate con $\\omega_n$ Es. $(X, \\{\\omega_1 ...\\omega_n\\})$ Ã¨ una produzione.\nQuindi questi quattro elementi riescono ad identificare in maniera univoca la semantica di un linguaggio.\nCapiremo il senso di questa definizione per l\u0026rsquo;informatica fra poco.\nIndicazione\nSi puÃ² indicare con $X ::= 0|0Y$ e simili, utilizzando solo per produzioni come coppie Ã¨ sufficiente per definire una sintassi BNF.\n4.2.3 Definizione di un linguaggio Di solito fra tutte Ã¨ sufficiente prendere le produzioni per dire un linguaggio.(ha senso supponendo che tutti i simboli della grammatica siano utilizzati)\nImmagine di definizione\nProcesso iterativo che parte dal non terminale e arriva a stringhe finite.\nEsercizio\nDimostrare che 000 non appartiene a questo linguaggio\n4.3 AmbiguitÃ  in BNF 4.3.1 Definizione ambiguitÃ  Se si puÃ² definire in due modi diversi la stessa parola, allora si dice che il linguaggio Ã¨ ambiguo.\n4.3.2 Soluzione ambiguitÃ  (3) Queste non sono sempre necessarie in ogni grammatica, ma sarebbero utili per la comprensione\nOrdine di precedenza per operatori AssociativitÃ  per ogni operatore (cioÃ¨ se l\u0026rsquo;operatore prende solo a destra o da sinistra) Parentesi? CosÃ¬ definisco un ordine di precedenza quindi risolvo le ambiguitÃ , ma non dovrei fare in questo modo.\n4.4 Albero di Sintassi astratta Buona cosa potrebbe essere la pagina di wiki.\nAfferma che questo albero Ã¨ molto utile per il compilatore (cosÃ¬ capisce cosa stiamo provando a fare).\nUn approfondimento possibile per questi alberi Ã¨ la Contex-free-grammar ovvero come evitare l\u0026rsquo;ambiguitÃ  del linguaggio naturale. (simile a BNF).\n4.4.1 Definizione (4) Prima si deve trovare una BNF non ambigua, poi possiamo creare un albero di questo genere.\nDefinizione di albero di sintassi\nDi solito ogni linguaggio di programmazione Ã¨ prima trasformato in un albero di sintassi e in seguito il compilatore elabora su questa cosa.\n4.4.2 RicorsivitÃ : le sottoformule immediate Sono figli diretti, sottoformule immediate generate dal nodo padre.\nEcco una struttura di dati ricorsiva, impareremo a sfruttare questa caratteristica della ricorsione.\nQuesta sottostruttura ricorsiva Ã¨ molto utile perchÃ© so anche come Ã¨ stato ricavato, non solo so se appartiene o meno! PiÃ¹ informazioni! Riusciamo ad assegnare un significato.\nLa cosa bella di questra struttura Ã¨ che possiamo utillizzare la stessa funzione (programma o quel che si voglia chiamarlo) per risolvere il problema su alcuni dati piÃ¹ piccoli (sotto dati).\n4.5 Pseudo-linguaggio funzionale puro non tipato Altolivello- vicino dominio del problema, senza alcuni dettagli di implementazione (che farÃ  da solo).\nBasso livello- vicino al dominio della soluzione ossia tratta alivello vicino al computer.\nTutti questi linguaggi hanno un albero sotto, che cerca di utilizzare questa grammatica formale per capire ciÃ² che Ã¨ scritto.\n4.5.1 Significato del nome Pseudo linguaggio perchÃ© questo linguaggio non esiste realmente, Ã¨ solamente qualcosa di simile, di vicino al un linguaggio reale (meno sintassi diciamo)\nfunzionale si utilizzano funzioni, sia come input, output per memorizzare cose e simili\nPuro senza side effect, senza storare variabili e fare cicli while o for\nNon tipato senza che un compilatore si lamenti di come Ã¨ implementato il tipo, quindi maggiore astrazione anche da questo punto di vista\n4.5.2 Funzioni unarie (3) Le funzioni unarie sono definite da tre parti principali:\nIl nome della funzione Un pattern $\\omega$, di solito una stringa dell\u0026rsquo;alfabeto Variabili â†’ Non terminali Costruttori e simili â†’ terminali costruiti con la gramatica del linguaggio. Corpo, quello che Ã¨ dentro la funzione Chiamate ad altre funzioni Parametri formali e altre costanti Condizioni di control flow 4.5.3 Pattern matching Questa Ã¨ la definizione di matching\nIn modo intuitivo: Match = se $p$ terminale matcha $\\omega$ se partendo da $\\omega$ si puÃ² creare $p$\nChiamate di funzione\nIn questo linguaggio funzionale, andremo ad utilizzare Haskell, la chiamata di funzione avviene per pattern match.\nPasso a sostituire i parametri formali a seconda di cosa matchi, ricostruendo tutto continuando.\n4.5.4 Side effects Questi linguaggi funzionali non devono avere side effects, ossia non devono accedere a locazioni di memoria fuori dal loro scope, o fuori dai propri parametri formali, quindi molto piÃ¹ controllabile.\nMa questo significa che non abbiamo la libertÃ  di allocare memoria e simili.\n4.5.5 Potenza espressiva Noi non possiamo programmare tutto quello che la matematica puÃ² fare.\nMa certe cose si possono fare in un linguaggio e non in un altro. Ma qualunque funzione in qualunque altro linguaggio potrebbe essere espresso nello pseudo-codice attuale (quando questa cosa accade Turing-completezza).\nMa dato che non abbiamo side effect non ci interessa I/O e video o simili.\n4.6 Ricorsione strutturale 4.6.1 Solito ragionamento per ricorsione Come di solito le ricorsioni, se Ã¨ un caso base allora risolvo subito, in modo diretto.\nAltrimenti risolvo ricorsivamente un sotto problema piÃ¹ facile, ma Ã¨ ancora lo stesso problema, ecco perchÃ© strutturale â†’ Hanno la stessa struttura, quindi sto utilizzando la stessa funzione per risolvere lo stesso problema ma per input diversi.\nQuindi risolvo problemi piÃ¹ piccoli e poi le ricompongo alla maniera iniziale.\nStrutture uguali (cioÃ¨ i sottodati devono essere ancora dei tipi dei dati iniziali, se ho in input lista di qualcosa e poi ho totalmente altro non posso fare). Risolvo cosÃ¬ problemi piÃ¹ semplici in modo ricorsivo. 4.6.2 Errori comuni DI solito la ricorsione Ã¨ difficile perchÃ© le persone tendono a cercare di scoprire in che modo sia implementata la ricorsione, cioÃ¨ cercano di comprendere cosa faccia la ricorsione a livello troppo basso.\nChiamate ricorsive non sui sottoproblemi Struttura della ricorsione Ã¨ errata (usando produzioni inesistenti) Mancare di qualche produzione 4.6.3 Esercizi Ricorsione strutturale Questi esercizi sono importanti dato che poi all\u0026rsquo;esame dovrai risolvere qualcosa di simile!\nEs 1\n-- Problema 1: data una lista (di numeri) -- calcolare l\u0026#39;insieme potenza della lista Es 2\n-- Problema 1: data una lista (di numeri) -- calcolare la lista di tutte le permutazioni -- della lista in input -- Es: dato 1:2:3:[], restituire -- (1:2:3:[]):(1:3:2:[]):(2:1:3:[]):(2:3:1:[]): -- (3:1:2:[]):(3:2:1:[]):[] -- Soluzione: per l1 Es 3\nUno tostino come esercizio Ã¨ definire una funzione che ritorni vero se e solo se un elemento compare due volte nell\u0026rsquo;insieme.\nEs 4\nN ::= O | S N\ndove il simbolo terminale O rappresenta lo 0 e il simbolo terminale S, letto \u0026ldquo;successore\u0026rdquo;, dato un numero naturale N forma il numero naturale S N che segue N nella numerazione.\nEsempio: 3 viene rappresentato in base 1 comeÂ S (S (S O)))Â e 5 come S (S (S (S (S O)))).\nNota: la rappresentazione corrisponde al modo con cui i bambini imparano a contare, usando le dita. O Ã¨ il pugno chiuso e ogni S corrispondere ad aggiungere un dito.\nProblema 1: definire per ricorsione strutturale una funzione + sui numeri naturali in base 1 che ne implementi la somma\nEsempio:Â S (S O) + S (S (S O))) = S (S (S (S (S O)))))\nSuggerimento: procedere per ricorsione strutturale sul primo argomento\nProblema 2:\ndefinire per ricorsione strutturale una funzione * sui numeri naturali in base 1 che ne implementi il prodotto\nEsempio: S (S O) * S (S O) = S (S (S (S O))))\nSuggerimento: per implementare il * potete usare il +\nProblema 3:\ndefinire per ricorsione strutturale una funzione ^ sui numeri naturali in base 1 che elevi il primo numero alla potenza indicato dal secondo\nEsempio: S (S O) ^ S (S (S O))) = S (S (S (S (S (S (S (S O))))))))\nSuggerimento: scegliere bene su quale input procedere per ricorsione strutturale\nQuesti dovrebbero essere difficili, se sai risolvere questi, dovresti essere in grado di farlo per tutti.\n4.7 Induzione strutturale Questa Ã¨ una tecnica dimostrativa per dimostrare che una struttura gode di una certa proprietÃ . Ãˆ strettamente legata alla ricorsione perchÃ© la ricorsione Ã¨ il calcolo della soluzione mentre l\u0026rsquo;induzione la dimsotrazione della correttezza.\nQuesta forma di dimostrazione Ã¨ valida per ragioni molto simili alla ricorsione strutturale, perchÃ© ogni passo Ã¨ giustificato dal precedente, di cui il caso base Ã¨ assunto come vero.\nQuindi bisogna prima capire quali siano le differenze fra induzione e strutturale.\n4.7.1 Il procedimento L\u0026rsquo;output deve essere una dimostrazione Si suppone che valga per tutti i sottocasi di questo di input (in pratica uguale alla ricorsione, per tutti gli sottoinput immediati stiamo supponendo che valga) come in matematica puoi affermare che valga per tutti i numeri minori di n come ipotesi induttiva. 4.8 Confronto funzioni mate e info Questo paragrafetto si rifÃ  all\u0026rsquo;iniziale introduzione sui Logica meta-linguistica sui paradossi in matematica e informatica.\n4.8.1 Matematica Rappresentazione Ã¨ fatta con relazioni, sottoinsieme del prodotto cartesiano. Questa Ã¨ inefficiente dal punto di vista del calcolo in quanto non ci da un modo per creare un calcolo. (non posso scorrere perchÃ© le liste restano illimitate).\nSi in questo caso stai pensando alle Relazioni fra insiemi non al modo per calcolarle.\n4.8.2 Informatica Di solito gli algoritmi ragionano in modo simile in basi diverse, that is l\u0026rsquo;efficienza degli algoritmi Ã¨ molto simile in basi diverse, tranne in base 1 che Ã¨ esponenzialmente piÃ¹ grande rispetto alle altre basi.\nEsempio di def. di funzioni somma\nO `+ m = m S n `+ m = S (n `+ m) ----- n +\u0026#39; ) = n n +\u0026#39; S m = S (n +\u0026#39; m) ------ O ``+ m = m S n ``+ m = n ``+ S m ------- n +\u0026#34; O = m n +\u0026#34; S m = S n +\u0026#34; m Queste sono quattro procedure di calcolo per la somma non uguali in quanto calcolano diversamente.\nIl prof. ha detto (non ho capito il motivo) per cui quelli con un singolo apice utilizzano la stack, mentre invece quelli con due apici utilizzano la heap), non ho capito perchÃ©, ma tanto lo spiegherÃ  ad architettura.\n4.8.3 Specifiche di funzioni Possiamo utilizzare le dimostrazioni per induzione strutturale per verificare la correttezza di una funzione.\nPer esempio una funzione di concatenzazione dovrebbe soddisfare questi teoremi\nDi cui il primo mantiene il numero , il secondo appartenenza, il terzo l\u0026rsquo;ordine.\n$|l_1 fl_2| = |l_1| + |l_2|$ $x\\in l_1 \\implies$ $l_1fl_2$ $\\forall n, n \\leq |l1| \\implies$ nth n l1 = nth n (l1@l2) $\\wedge$ $\\forall n, n\\leq |l2| \\implies$ nth n l2 = nth (|l+1| +n) (l1@l2) Se una funzione soddisfa questi teoremi allora possiamo definire in modo rigoroso una funzione.\nFunzioni helper per questo\ncat [] l2 = l2 cat (t:l) l2 = t:cat l l2 length [] = 0 length (n:l) = 1 + length l -- nth n l tira fuori n-elemento di l head [] = [] head (n:l) = n tail [] = [] tail (n:l) = l nth 0 l = head l nth (S n) l = nth n (tail l) nthCorto 0 (t:l) = t nthCorto (S n) (t:l) = nthCorto n l E poi dovrei verificare ogni singola funzione di questo\u0026hellip;\nSpesso nella vita reale non c\u0026rsquo;Ã¨ bisogno di questo, si scriva specifica parziale n) (t:l) = nthCorto n l ```\nE poi dovrei verificare ogni singola funzione di questo... Spesso nella vita reale non c\u0026rsquo;Ã¨ bisogno di questo, si scriva specifica parziale\n","permalink":"https://flecart.github.io/notes/sintassi-e-ri-strutturali/","summary":"Ripasso Prox: 27 Ultima modifica: October 7, 2022 1:25 PM Primo Abbozzo: October 15, 2021 10:35 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Vecchi dubbi Cosa Ã¨ la sintassi I costituenti della BNF (ripassarreeee le tre soluzioi per l\u0026rsquo;ambibuitÃ  definizione di linguaggio Differenza funzioni matematiche ed informatiche Context-free-grammar per AST Cosa significa espandere un non terminale? 4 Sintassi Programmare e dimostrare sono sostanzialmente la stessa attivitÃ  ~Coen\nMa non secondo l\u0026rsquo;industria\u0026hellip;","title":"Sintassi e RI strutturali"},{"content":"Ripasso Prox: 15 Ripasso: December 22, 2021 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: November 19, 2021 8:34 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Dubbi passati Dimostrazione del teorema di invarianza ProprietÃ  dei connettivi logici Dimostrazione della correttezza Dimostrazione delle variabili Teorema di compattezza, cosa Ã¨ 8 Connettivi logici 8.1 Dimostrazione teorema invarianza 8.1.1 Introduzione Basi: Due proposizioni sono equivalenti quando valgono sugli stessi mondi.\nquindi $\\forall v, \\llbracket F \\rrbracket ^v \\equiv \\llbracket G \\rrbracket ^ v$.\nVogliamo dire che dati un buco presente in una proposizione, queste valgono sempre, sono in effetti equivalenti. Il buco la prendo come una variabile proposizionale. (riempire = rimpiazare il buco)\n8.1.2 Operazione di sostituzione Si puÃ² notare che ci sono 4 casi base, mentre le altre 4 sono per ricorsione strutturale.\n8.1.3 Enunciato La funzione di sostituzione ci permette di utilizzare una sostituzione anche nel profondo di un albero di deduzione naturale, perÃ² non Ã¨ accettabile poi in sede d\u0026rsquo;esame utilizzare questo teorema per fare deduzione naturale.\nLa dimostrazione Ã¨ per induzione strutturale abbastanza banale dopo aver definito la sostituzione, ma comunque resta un buon esercizio che dovresti fare.\n8.1.4 Osservazione 8.2 Connettivi logici 8.2.1 Definizione semantica (denotazione) Enunciato\nDalla definizione di connettivo unario si puÃ² dedurre che esistono $2 ^{2^n}$ connettivi possibili ($2^n$ funzioni possibili per scelte dominio e 2 scelte posssibili per codominio.\nEs, per tutte le $2^n$ righe, devo dare in output un numero. Quindi posso dare una funzione che passa tutti 0 per tutte le righe, fino alla righa che da tutti uno per tutte le $2^n$ righe, finendo per avere $2^{2^n}$ funzioni possibili. Dobbiamo ora scegliere il perchÃ© abbiamo scelto questi connettivi fra tutti quelli presenti\n8.2.2 Giustificazione delle scelte Zero: Abbiamo preso tutti i connettivi zeroari, identificano il concetto di giusto o falso.\nUno: abbiamo preso solamente il connetivo not. (uno Ã¨ uguale all\u0026rsquo;input, gli altri due la ignorano, uno la ribalta, per questo abbiamo scelto solo il not).\nBinari questi sono tanti, ma non abbiamo dato una connotazione solo ad alcuni (eliminando tutti quelli banali tipo uguale a input, o inverso di input, o bot e top).\n8.2.3 Riduzione fra connettivi (classico) Questo concetto Ã¨ molto simile al ruolo di equivalenza fra due regole diverse (l\u0026rsquo;eliminazione dell\u0026rsquo;and e e1 e2). in Deduzione naturale.\nDefinizioni\nQui viene introdotto il concetto di funzionalmente completo che abbiamo utilizzato in Porte Logiche.\nE anche il concetto di riduzione indicato con $\\rhd$\nStudiamo quali connettivi sono necessari, scopriamo che nor e nand sono sufficienti, tutto si potrebbe ridurre a questi. Sono completi anche $\\vee, \\wedge, \\neg, \\bot, \\top, \\implies$ ridondante, ma funzionalmente completo\n8.2.4 Motivi della scelta dei connettivi (3) Lista motivi\nPoi c\u0026rsquo;Ã¨ una lunghissima lista di proprietÃ  possibili. Il prof. in classe ha dato l\u0026rsquo;intuizione del conceto di dualitÃ  fra top e bottom e and e or (basta ordinare la retta fra -1 e 0 per verificare che corrispondono, in pratica per la definizione attuale della nostra semnatica si hanno questi valori)\n8.2.5 ProprietÃ  dei connettivi (9) Queste scelte sono \u0026ldquo;funzionalmente complete\u0026rdquo; per la relazione di equivalenza.\nCAIDANA\nProprietÃ \nInfatti grazie a questo si puÃ² creare un teorema di completezza per le regole, ovvero si puÃ² dimostrare che\n$P \\equiv Q$ partendo solamente da queste regole, perÃ² non servono spesso per il calcolo. (a volte queste regole complicano la forma originale perchÃ© la forma di assorbimento di dovrebbe espandere).\nAltre cose sono\nModus barbara e risoluzione.\n8.3 Correttezza e completezza La correttezza la saltiamo, perchÃ© Ã¨ troppo complicato ed enunciata in breve sul teorema di completezza di sopra.\n8.3.1 Correttezza $\\Gamma \\vdash F \\implies \\Gamma \\Vdash F$\nEnunciato piÃ¹ corretto\nLocalmente corrette significa che devono essere delle regole valide (che creano conseguenze logiche).\nOvvero significa che ho una ipotesi che funziona localmente ma non globalmente e lo scrivo come un implica.\nIntuizione\nOgni regola metto in un foglietto diverso (anche l\u0026rsquo;ipotesi scaricata Ã¨ presente di un foglietto sopra).\nVoglio dire che quella regola non Ã¨ una regola scaricata per un foglietto sotto. (viene scaricata solamente da un foglietto sopra.\nDimostrazione\nI Passi principali di dimostrazione\nCaso base A e caso impossibile [A] Ipotesi induttiva: i sotto-alberi sono conseguenza logica di ipotesi globali e ipotesi locali (localmente corrette). Per utilizzo di regole locali so che F Ã¨ conseguenza logica di molti implica. Per il teorema di deduzione semantica trasformo l\u0026rsquo;ipotesi induttiva con implica in RHS e LHS solo ipotesi globali del ramo principale. Unisco con transitivitÃ  della conseguenza logica. 8.3.2 PerchÃ© correttezza piÃ¹ semplice di completezza AffinchÃ© abbia la correttezza, mi bastano delle regole che siano localmente corrette, se invece ho una regola incorretta riesco a derivare bottom da top, e quindi mi creerebbe una teoria inconsistente (tutto che valga).\nVorrei dire che ho tutte le regole per catturare un concetto semantico utilizzando un concetto sintattico (finito). Come faccio a usare una quantitÃ  finita per catturare l\u0026rsquo;infinito? Quindi per le logiche semplici come la logica proposizionale classica si puÃ², per le altre no.\nÃˆ sorprendente che un insieme finito di regole sia sufficiente a dimostrare infinite ipotesi, questo in matematica Ã¨ catturato il concetto di compattezza.\nDue ingredienti\nDevo avere tutte le regole, queste sono sufficienti per dimostrare tutte le conseguenze logiche. Da un insieme finito di regole devo essere in grado di dimostrare tutto. 8.3.3 Completezza in logica classica Non Ã¨ possibile dimostrare queste classiche tautologie RAA, EM\nNel caso due, posso dimostrare A oppure non A per introduzione dell\u0026rsquo;OR. PerÃ² poi non ho niente per continuare, in certi mondi non funziona A, perchÃ© non ho ipotesi, e non ho niente per dimostrare bottom con l\u0026rsquo;introduzione della negazione. Quindi queste non sono dimostrabili.\nMa questi valori sono validi se i valori di veritÃ  sono solamente due! le regole che ho non colgono la dualitÃ  (vero falso) della logica classica. infatti queste si dimostrazione solamente con l\u0026rsquo;introduzione della regola RAA.\nMa l\u0026rsquo;introduzione di questa regola toglie l\u0026rsquo;algoritmicitÃ  della dimostrazione quindi non Ã¨ da fare.\nPer avere dimostrazione della correttezza della regola qui\n8.4 Variabili Definizione funzione Var\nCostruiamo una funzione Variabile definita per ricorsione strutturale che ritorni tutte le variabili esistenti in una formula logica.\nCerchiamo di creare una sintassi che possa essere utilizzabile tutta l\u0026rsquo;infinitÃ  dei mondi.\nRiesco quindi a introdurre il concetto di equivalenza di mondi in funzione di una proposizione.\n8.4.1 Teorema: var(F) finito per ogni F La dimostrazione (intuizione) per induzione strutturale Ã¨ abbastanza easy. Nel caso dei casi finiti dovrei dimostrare che il singoletto e il vuoto sono finiti. Nel caso di parti composte, devo supporre che siano finite per le espansioni, allora l\u0026rsquo;unione di insiemi finiti Ã¨ ovvia\nIn realtÃ  la dimostrazione vera devi formalizzare prima il concetto di finito e non finito, che Ã¨ in teoria degli insiemi, quindi hai bisogno di molte altre cose.\n8.4.2 F in v usa restrizione di v al dominio Var(F) Posso creare una relazione di equivalenza se per ogni X in Var(F) ho che v(X) = v2(X) e ho che i due mondi sono uguali.\nChiamo solamente delle variabili di un mondo?\nDimo\nDimostrazione\nIn pratica sto collassando in una classe di equivalenza con il\nIl fatto che siano finiti mi permette di costruire tabelle di veritÃ .\nNota\nGrazie a questo teorema posso dire che una variabile (proposizione) sia valida in tutti i mondi dipendentemente solamente dal valore di veritÃ  di una variabile al caso base.\nQuesto significa che le proposizioni logiche sono valide per tutti i mondi che soddisfino le precodizioni e non solamente nel mondo specifico! l valore di veritÃ  di una variabile al caso base.\nQuesto significa che le proposizioni logiche sono valide per tutti i mondi che soddisfino le precodizioni e non solamente nel mondo specifico!\n","permalink":"https://flecart.github.io/notes/connettivi-logici-correttezza-variabili/","summary":"Ripasso Prox: 15 Ripasso: December 22, 2021 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: November 19, 2021 8:34 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Dubbi passati Dimostrazione del teorema di invarianza ProprietÃ  dei connettivi logici Dimostrazione della correttezza Dimostrazione delle variabili Teorema di compattezza, cosa Ã¨ 8 Connettivi logici 8.1 Dimostrazione teorema invarianza 8.1.1 Introduzione Basi: Due proposizioni sono equivalenti quando valgono sugli stessi mondi.","title":"Connettivi Logici, correttezza, variabili"},{"content":"Ultima modifica: April 4, 2023 6:19 PM Primo Abbozzo: April 1, 2023 11:11 AM Studi Personali: No\nElementi di ripasso Explainability of CNN Introduction Capire in che modo una rete convoluzionale ci puÃ² dare insight migliori su come funzionano questi networks.\nVisualizzazione dei hidden layers Slide visualization\nPotremmo fissare una immagine anche a caso, e modificare la x in modo che sia piÃ¹ simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa.\nForse questo Ã¨ anche il metodo con cui vengono generate le immagini??\nExamples of extracted patterns\nProbabilmente tutte le CNN vanno quindi a tentare ad estrarre questo genere di patterns dallâ€™immagine iniziale.\nRicreazione di immagini Vogliamo computare la rappresentazione interna dellâ€™immagine, ossia lâ€™attivazione prodotta da una certa immagine, e da questo possiamo sintetizzare una immagine e poi continuare a fare gradient descent su questa per massimizzare. Una volta al minimo dovremmo avere lâ€™immagine migliore per questo layer.\nSlide di esempio\nPer un certo layer non câ€™Ã¨ differenza fra quei 6 immagini\nQuindi prima partivamo da noise, da questo partiamo da una immagine giÃ  e guardiamo in che modo Ã¨ rappresentato in questo layer.\nSlide sulla tecnica di solito utilizzata per queste\nSi puÃ²notare che Ã¨ piÃ¹ difficile recovery dellâ€™immagine nei layers lontani, probabilmente perchÃ© sta creando una specie di astrazione dellâ€™immagine iniziale, quindi lâ€™immagine sarebbe lâ€™immagine dellâ€™astrazione. Riusciamo a visualizzare una astrazione, che sembra una contraddizione.\nInceptionism Style transfer Come facciamo a ricreare una immagine utilizzando lo stile di un certo autore?\nEsempi di risultati con style transfer\nMa come facciamo a catturare un concetto astratto di stile di un certo autore?\nConcetto di stile di un autore Non vogliamo solamente avere un contenuto simile (come abbiamo fatto prima, nei primi layers Ã¨ una cosa abbastanza semplice) vorremmo proprio essere in grado di catturare lo stile dellâ€™artista. Quindi da un punto di vista astratto\nSlides stile autore\nCi interessa la correlazione fra features maps di un certo livello, e quando abbiamo una immagine vogliamo allenare per massimizzare la similitudine con la correlazione fra le feature maps.\nData manifolds perchÃ© facile ingannare le reti Si puÃ² vedere che con le tecniche dello stile si possono ingannare molto facilmente le reti di sopra. Questo Ã¨ perchÃ© fanno delle classificazioni, fanno discriminazione anzichÃ© generazione. Ossia con generazione provo a stimare la probabilitÃ  iniziale che si sia creato la cosa che vogliamo classficiare e con questa probabilitÃ  poi andiamo a fare la predizione.\nInvece nelle tecniche discriminazione vanno solamente a fare una discriminazione di dati, una cosa statistica. (la frontiera puÃ² essere molto diversa rispetto alla funzione che lo ha generata diciamo.\nSeguendo comunque il ragionamento sui manifolds di data possiamo dire che Ã¨ molto improbabile ~0, che generando a caso, sia una immagine sensata. Infatti lo spazio delle immagini Ã¨ enorme, la maggior parte sono ranodm per umani, perÃ² stiamo provando a fare questo un modello di discriminazione (quindi Ã¨ chiaro che molte zone che per noi non hanno senso, sono rappresentate nella rete neurale come categorizzate in un certo modo).\nAutoencoders Vogliamo cercare di cambiare lo spazio in modo che la parte delle immagini sensate sia meglio descrivibile, vogliamo andare in pratica a creare una descrizione compatta di quello che vogliamo analizzare. Con gli autoencoder andremo proprio a comprimere il data manifold e poi lavorare su questa compressione.\nSlide intuizione autoencoder\nQuello che vorremmo fare Ã¨ una funzione identitÃ  per certe cose (dato che sono meno, non possiamo fare altro che perdere altre informazioni, ma vogliamo solamente perdere informazioni che non ci servano).\nPossiblitÃ  della compressione\nLa compressione dovrebbe essere possibile perchÃ© stiamo cercando regolaritÃ  nel data, cosa che ci dovrebbe essere perchÃ© noi umani riusciamo a riconoscere questi pattern, non riusciamo ad insegnarlo ad una macchina. (quando Ã¨ molto random perÃ² non si puÃ² comprimere, stranamente il random Ã¨ la cosa con piÃ¹ informazione in termini di teoria dellâ€™informazione, ma meno informazione per noi umani, che strana questa asimmetria).\nCaratteristiche della compressione\nSlide caratteristiche\nLa cosa di maggior rilievo Ã¨ il fatto del loss, che non riusciamo a fare un reverse che diventi proprio uguale! E poi funziona solamente con data simili (con caratteristiche fortemente correlate fra di loro.\n","permalink":"https://flecart.github.io/notes/explainability-of-cnn/","summary":"Ultima modifica: April 4, 2023 6:19 PM Primo Abbozzo: April 1, 2023 11:11 AM Studi Personali: No\nElementi di ripasso Explainability of CNN Introduction Capire in che modo una rete convoluzionale ci puÃ² dare insight migliori su come funzionano questi networks.\nVisualizzazione dei hidden layers Slide visualization\nPotremmo fissare una immagine anche a caso, e modificare la x in modo che sia piÃ¹ simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa.","title":"Explainability of CNN"},{"content":"Ripasso Prox: 12 Ripasso: December 23, 2021 Ultima modifica: March 23, 2023 2:12 PM Primo Abbozzo: November 15, 2021 2:16 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Vecchi dubbi Come funzionano esattamente gli algoritmi di paginazione? Quali sono i problemi principali della paginazione? Come funziona la MMU (ossia come faccio a trovare un indirizzo reale per ogni indirizzo virtuale?) 9 Livello sistema operativo 9.1 Caratteristiche Il sistema operativo non ha sempre avuto una interfaccia grafica.\n9.1.1 In generale Principalmente Ã¨ un gestore delle risorse come il disco, la CPU, l\u0026rsquo;output e l\u0026rsquo;input.\nÃˆ qualcosa che si infrappone come interfaccia fra le applicazioni e quello che Ã¨ presente sotto.\n9.1.2 Ambiti principali 9.2 Paginazione Al programma non interessa se effettivamente Ã¨ presente in memoria fisica questa quantitÃ  di memoria, si di solito basta sempre.\nCi sono 3 casi:\nse la necessitÃ  di memoria Ã¨ anche superiore alla memoria virtuale esistente allora c\u0026rsquo;Ã¨ l\u0026rsquo;errore out-of-memory Se Ã¨ maggiore della fisica ma minore, dovrÃ  essere gestita dalla paginazione e simili. Se Ã¨ minore della memoria fisica allora tutto ok! Implementazione Slide\n9.2.1 Indirizzi virtuali e paginazione Vogliamo utilizzare tutti i bit per l\u0026rsquo;indirizzamento, anche se questi superano effettivamente la memoria effettiva, questa astrazione permette di facilitare al programma la comprensione di tutto. (ma il programma Ã¨ molto piÃ¹ lento perchÃ© ogni volta doveva ricaricare la pagina di memoria).\n9.2.2 Hit and fault Si ha un page hit se la pagina Ã¨ caricata, altrimenti Ã¨ page fault e si deve ricaricare tutta la memoria per il programma.\n9.2.3 Memory Management Unit Esempio\nQuesto Ã¨ il chip che si differenzia dalla cache. Una pagina virtuale puÃ² essere messo in qualunque pagina reale.\nTabella gestita dal sistema operativo che tiene in memoria le pagine che sono usate e quelle no.\nquindi se Ã¨ 1 (in memoria) si chiama working set.\n9.2.4 Algoritmi di paginazione (2) Ci dicono quale pagina togliere dalla memoria principale per sapere quale rimpiazzare con la nuova pagina.\nI principi che sono presenti per questi algoritmi di paginazione, sono molto simili ai principi della localitÃ  spaziale e temporale presenti per la Cache\nQuelle presentate sono LRU e FIFO, si puÃ² dire che il primo funziona meglio mentre il secondo Ã¨ piÃ¹ veloce, quindi bisogna vedere i tradeoff.\nQuesti algoritmi (in particolare La Least Recently Used Ã¨ utilizzata anche in Memoria per la cache).\n9.2.5 Dirty bit Si aggiunge un bit che ci dice se una pagina Ã¨ stata sporcata o meno (cosÃ¬ possiamo decidere se scrivere in memoria o no).\n9.2.6 Frammentazione interna Non vorremmo sprecare un pezzo del blocco, sprecheremmo mezzo blocco.\nPer ovviare a questo (il fatto di non utilizzare l\u0026rsquo;intero blocco si dice frammentazione interna)\n9.3 Segmentazione 9.3.1 Problemi della paginazione Questa opzione non Ã¨ piÃ¹ presente nella realtÃ , dato che si utilizza sempre la paginazione.\nProblemi della paginazione\nEvitare la frammentazione interna Le pagine sono scollegati dai programmi (potrebbe essere che un array sia scollegato in piÃ¹ pagine, ho mano manovra). Si divide la memoria in segmenti che vengono dati a parti del processo (esempio i/o ) e altro a seconda dello scopo\n9.3.2 In memoria: frammentazione esterna Dato che i segmenti non sono della stessa grandezza, c\u0026rsquo;Ã¨ un pÃ² di complicazione mentre si trattano queste cose. ecco che si ha il fenomeno di frammentazione esterna in questo caso.\nL\u0026rsquo;operazione di compattare la memoria Ã¨ moolto costosa\u0026hellip;\nEsempio\n9.3.3 Scelta del \u0026ldquo;buco\u0026rdquo; (2) Ci sono due modi principali per scegliere la zone in cui mettere il programma\nBest Fit: (ci metto piÃ¹ tempo perchÃ© devo cercare il buco migliore, ma poi trovo quello piÃ¹ economico in cui c\u0026rsquo;Ã¨ meno spazio inusato) First fit: Ã¨ il piÃ¹ veloce perchÃ© metto subito sul primo blocco, perÃ² grande spazio potrebbe essere inutilizzato 9.3.4 Combinazione segmentazione e paginazione Si possono mischiare: una parte per la segmentazione e poi la pagina per il segmento e da questo si raggiunge un blocco.\nEsempio\n9.4 Gestione del linking ! 9.4.1 il file oggetto Ogni file viene compilato assumendo che parta dall\u0026rsquo;indirizzo zero, poi questi vengono riorganizzati con successo da linker\nEsempio 9.4.2 Esempio 9.4.3 La rilocazione La rilocazione per chiamate di funzioni esterne (di sistema Ã¨ semplice), poi bisogna rilocare anche pointers e branches., si utilizza un dizionario di rilocazione.\n9.4.4 Indirizzamento dinamico Viene compilato normalmente, e viene linkato nel momento di esecuzione grazie al sistema operativo\nEsempio\nIndirizzamento dinamico\nViene compilato normalmente, e viene linkato nel momento di esecuzione grazie al sistema operativo\nEsempio\n","permalink":"https://flecart.github.io/notes/livello-os/","summary":"Ripasso Prox: 12 Ripasso: December 23, 2021 Ultima modifica: March 23, 2023 2:12 PM Primo Abbozzo: November 15, 2021 2:16 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Vecchi dubbi Come funzionano esattamente gli algoritmi di paginazione? Quali sono i problemi principali della paginazione? Come funziona la MMU (ossia come faccio a trovare un indirizzo reale per ogni indirizzo virtuale?) 9 Livello sistema operativo 9.1 Caratteristiche Il sistema operativo non ha sempre avuto una interfaccia grafica.","title":"Livello OS"},{"content":"Logica del primo ordine Questa Ã¨ la logica piÃ¹ utilizzata dai matematici\nLimitatezza della logica proposizionale La logica proposizionale classica non Ã¨ in grado di ragionare sull\u0026rsquo;infinito Fino ad ora abbiamo utilizzato una metalogica per giustificare il per ogni e l\u0026rsquo;esiste nelle dimostrazioni fin\u0026rsquo;ora.\nDobbiamo quindi dare una definizione piÃ¹ formale dei quantificatori.\nObiettivo della logica del primo ordine Si puÃ² quindi identificare come l\u0026rsquo;obiettivo della logica di primo ordine l\u0026rsquo;introduzione dei quantificatori dell\u0026rsquo;universale e dell\u0026rsquo;esiste\n## Sintassi In questa sintassi stiamo dividendo in Termini e proposizioni (le proposizioni che si possono trovare nella logica proposizionale classica).\nDefiniamo i termini o vocabolario ossia gli elementi del discorso come $$ t::= x \\mid c \\mid f^{n}(t_{1}, \\dots, t_{n}) $$ Def: Vocabolario Ossia, simboli di relazione n-arie (ossia con $n$ argomenti) $p, q$ etc\u0026hellip; e simboli di funzione $f, g, h$ anche questi n-arie etc\u0026hellip; ricorda la differenza fra funzione e relazione fatta in Relazioni fra insiemi\nDef: Termine Lo facciamo in modo induttivo.\nUna variabile qualunque Ã¨ un termine Poi caso induttivo: se $t_{1}, \\dots, t_{n}$ sono termini, lo Ã¨ anche $f^{n}(t_{1}, \\dots, t_{n})$ NOTA: qui non facciamo uso di relazioni per definire i termini\nDef: Formula o proposizione Anche qua definiamo per induzione:\n$P(t_{1}, \\dots, t_{n})$ Ã¨ un predicato $n-ario$ ed Ã¨ una formula. (un predicato Ã¨ una funzione che mappa in 0, 1) Se $\\varphi, \\phi$ sono formule, lo sono anche tutte le banali cose logiche, quindi $\\varphi \\land \\phi, \\varphi \\lor \\phi, \\varphi \\to \\delta, \\forall x.\\varphi, \\exists x. \\varphi$ Def: Teoria Ãˆ un insieme di formule come definito di sopra, basate su un certo vocabolario fissato. Ãˆ interessante la roba di (Choi 2022) che dice che non Ã¨ possibile usare la logica per problemi real world.\nRiassunto sintassi: Come si puÃ² osservare nella sintassi di logica del primo ordine estende la logica proposizionale classica perchÃ© per P 0 ho le singole proposizioni\nQuindi si divide in un dominio di discorso, ossia l\u0026rsquo;insieme dei termini possibili come costanti e leformule o proposizioni che possiedono un valore di veritÃ .\nPerchÃ© primo ordine Si chiama logica di primo ordine perchÃ© non si possono utilizzare le funzioni sulle variabili nel dominio di discorso.\nQuesta Ã¨ l\u0026rsquo;ultima logica in cui vale ancora la completezza, e la correttezza, nelle logiche superiori non sarÃ  piÃ¹ possibile catturare tramite un concetto sintattico il valore semantico.\nQuesta Ã¨ la logica di primo ordine che basta ai matematici per fare tutto (questo perchÃ© le funzioni dei matematici in realtÃ  sono degli insiemi, non qualcosa che calcola).\nPossibili denotazioni Oggetti ignoti nel dominio Oggetti fissati Connotazioni di denotazioni oggetti Connotazioni di denotazioni di valori di veritÃ  Semantica Questa parte Ã¨ approfondita dopo con mondo ed interpretazione\nBinder I binder sono un concetto fondamentale nell\u0026rsquo;informatica (soprattutto a chi andrÃ  a fare i compilatori). Quindi stiamo astraendo un livello di semantica! Connettivi ancora piÃ¹ astratti.\nI binder legano una variabile e uno scope (Cattura una variabile (o serie di varaibile) in uno scope che viene valutato piÃ¹ e piÃ¹ volte).\nFormula matematica (uno scope nel senso di derivata, integrale sommatoria e simili) I Simboli logici per ogni esiste. Vado a valutare una unica formula all\u0026rsquo;interno di uno scope (e continuo ripetutamente a sostituire e calcolare su tanti valori, e restituisco il risultato sintetizzato).\nShadowing Nei binder non si puÃ² accedere alle variabili esterne se hanno lo stesso nome, si dice shadowing (quello interno nasconde l\u0026rsquo;esterno, quindi fa ombra, nasconde).\nUn esempio Ã¨ ridichiarare un parametro formale in una funzione.\nDiagrammi di legame Sono molto utili per capire le variabili del binder e lo scope di queste variabili\nCose da fare:\nLegare variabile a ogni binder e lo scope Esistono le variabili che non vengono mai legate, si dicono variabili libere queste (come libreria o variabili globali), queste si indicano con una freccia all\u0026rsquo;infinito con il nome Variabili libere Queste variabili non sono modificabili (come provare a cambiare il nome di una funzione di libreria esterna).\nDefinizione per induzione strutturale\nalfa-convertibilitÃ  Si chiama alfa perchÃ© una branca dell\u0026rsquo;informatica che studiava i lambda, cuore del linguaggio di programmazione funzionale. (io lo chiamo anche sostituzione idiota, ma attento che in linguaggi normali c\u0026rsquo;Ã¨ il fenomeno dell\u0026rsquo;opacitÃ  che non ci permette di farlo!)\nSi dice che una serie di formule sono alfa-convertibili se il diagramma di legame creato dalle formule Ã¨ uguale â†’ relazione di equivalenza\nEssendo una relazione di equivalenza possiamo lavorare su una classe di equivalenza, quindi sarebbe bene ragionare al livello di insieme quoziente delle formule.\nEsempi\nNell\u0026rsquo;esempio in giallo, la Z fa shadowing, ha cambiato una variabile che in primo momento apparteneva a uno scope esterno.\nSostituzione in logica primo ordine Praticamente questa nozione ci dice che una funzione ha lo stesso output anche se quello che ci va dentro Ã¨ una variabile con un nome diverso. Questa nozione ha una certa similitudine con la funzione di sostituzione, in quanto entrambi parlano di invarianza sulla sostituzione di variabili.\nLa differenza principale Ã¨ che questa parla di binder mentre quella di prima parla di stesso valore di veritÃ  di una proposizione.\nPossiamo allora definire una funzione di sostituzione anche per la logica del primo ordine che faccia attenzione anche ai diagrammi di flusso e i binder\nSostituzione\nMondo o interpretazione Non Ã¨ piÃ¹ sufficiente avere un mondo indicato solamente come una v, ma Ã¨ necessaria una coppia ordinata: (A, l) dove A Ã¨ l\u0026rsquo;insieme non vuoto di denotazioni, mentre l Ã¨ simile alla vecchia funzione semantica v, perÃ² associa degli elementi in A altri elementi in A, non dice niente sulle connotazioni.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Logica del Primo ordine/Untitled 9.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Logica del Primo ordine/Untitled 9\u0026quot;\u0026gt; Def: Modello Questo Ã¨ anche chiamato mondo in questo caso.\nUn simbolo non ha significato finchÃ© non ne diamo uno, questo Ã¨ la parte della semantica, che vuole cercare di dare senso al mondo. Uno stesso simbolo puÃ² avere diverse interpretazioni (diversa semantica) in modelli diversi\nDato un vocabolario $(f_{1}, \\dots, f_{j}, p_{1},\\dots, p_{i})$ un modello Ã¨\nUn insieme $U$ Le funzioni $f_{1}^{U},\\dots, f_{j}^{U}$ e similmente definite $p$ tali per cui se $f_{1}$ ha arietÃ  n, allora $f_{1}^{U} : U^{n} \\to U$, ossia Ã¨ una relazione n-aria. Per $p_{1}$ si ha che $p_{1}^{U} \\subseteq U^{n}$. Def: Interpretazione Con un insieme $V$ possiamo definire interpretazione una funzione $I: V \\to U$ con $U$ l\u0026rsquo;insieme del modello definito #Def Modello. Solitamente questo Ã¨ definito in modo induttivo.\nNozione semantica di per ogni ed esiste Esempi di formalizzazione sintattica errata\nPer esempio: elefante Ã¨ una connotazione, mentre la denotazione Ã¨ quell\u0026rsquo;animale in carne ed ossa, non posso manipolare delle denotazioni in questo caso, quindi non avrebbe senso utilizzarlo.\nNel secondo caso sto testando molte piÃ¹ cose (connotazioni sono molti di piÃ¹ rispetto alle denotazioni in quanto esistono i sinonimi)\nL\u0026rsquo;idea principale Ã¨ tenersi una lista (una mappa) che associ nomi (connettivi) e denotazioni del mondo, questa Ã¨ l\u0026rsquo;ambiente indicata con la lettere csi.\nSemantica della logica primo ordine La funzione di interpretazione va per ricorsione strutturale in tutte le sotto-formule, per cui basta definirlo nell\u0026rsquo;insieme dei termini e la ho per tutto il modello.\nRicorsione strutturale Conseguenza logica in Primo ordine Dobbiamo prendere in questo caso considerazione della definizione piÃ¹ complessa del mondo (ricordarsi che nelle logiche di ordine superiore Ã¨ proprio questa ulteriore complessitÃ  che non permette di avere una completezza).\nQuindi dobbiamo tenere conto del significato di (A, l), $\\xi$.\nDef: VeritÃ  Possiamo definire che una proposizione Ã¨ vera se: $$ U, I \\models P(t_{1}, \\dots, t_{n}) \\text{ se } \\langle I(t_{1}), \\dots, I(t_{n}) \\rangle \\in P_{I}^{U} $$ ossia se il termine usando tutta l\u0026rsquo;interpretazione presente Ã¨ dentro il nostro modello. Ãˆ un modo leggermente differente per sopra Si puÃ² continuare a definirlo per tutti i quantificatori: $$ U, I \\models \\varphi \\land \\phi \\text{ se } U, I \\models \\varphi \\land U, I \\models \\phi $$ $$ U, I \\models \\varphi \\lor \\phi \\text{ se } U, I \\models \\varphi \\lor U, I \\models \\phi $$ $$ U, I \\models \\neg \\varphi \\text{ se } U, I \\not \\models \\varphi $$ $$ U, I \\models \\exists x. \\varphi \\text{ se esiste } \\alpha \\in U \\mid U, I\\left[ x \\to \\alpha \\right] \\models \\varphi $$ $$ U, I \\models \\forall x. \\varphi \\text{ se per ogni } \\alpha \\in U \\mid U, I\\left[ x \\to \\alpha \\right] \\models \\varphi $$ NOTA: se andiamo a considerare una formula chiusa, ci basta il modello, perchÃ© l\u0026rsquo;interpretazione Ã¨ utile quando andiamo a trattare formule libere.\nProprietÃ  esiste e per ogni Queste proprietÃ  espandono la lista CAIDANA delle proprietÃ  presenti in Connettivi Logici, correttezza, variabili.\nCompletezza debole Slide\nCommutativitÃ  e non chiaramente se Sono gli stessi x e y in due per ogni es $\\forall A, \\forall B$ questo Ã¨ uguale a dire $\\forall B, \\forall A$, stessa cosa per l\u0026rsquo;esiste.\nMa il senso della frase cambia nel caso in cui abbia un per ogni e in seguito un esiste.\nSemidistributivitÃ  In certi casi (non per tutti) posso spostare (addirittura eliminare!) i quantificatori\n### De morgan Equivalenze notevoli Deduzione naturale In questa sezione di appunto andiamo ad indagare le regole della deduzione naturale per la logica di primo ordine, per questo motivo linko la deduzione naturale in ambito proposizionale Deduzione naturale\nVogliamo utilizzare delle cosa uguali a meno di alfa conversione.\nIntroduzione Per ogni Forma generale\nAttento che Y non deve affatto appartenere alle variabili libere delle foglie!\nQuesto mi dice che devo utilizzare solamente solamente una variabile che non Ã¨ stata giÃ  presa (quindi libera, data dall\u0026rsquo;esterno)\nSuggerimento: per non sbagliare mai ti basterebbe prendere una variabile mai presa prima.\n/to\nCorrettezza ed invertibilitÃ  intuizionista\nCorrettezza classica\nIo sintatticamente ci metto y e il mondo mi risponde xi y. Ora l\u0026rsquo;ambiente xi mi dice che x vale xi di y e quindi Ã¨ la stessa. Ma lo devo dimostrare per induzione strutturale.\nInvertibilitÃ  classica\nEliminazione per ogni Forma generale\nDovrei passare per la formula piÃ¹ complessa a volte! A volte Ã¨ piÃ¹ semplice dimostrare il generale che il particolare perchÃ© possiedo induzione strutturale e simili.\nCorrettezza intuizionista e classica\nAnche da questo possiamo sapere che non possiamo andare a cercare tutte le variabili, sono infiniti! L\u0026rsquo;algoritmo non concluderebbe mai.\nIntroduzione Esiste Questa dimostrazione Ã¨ praticamente uguale all\u0026rsquo;eliminazione del per ogni, mentre l\u0026rsquo;eliminazione Ã¨ simile all\u0026rsquo;introduzione\nForma generale\nEliminazione dell\u0026rsquo;esiste In questa forma io non ho nessuna informazione sulla x, non posso prendere una x che Ã¨ giÃ  stata utilizzata nella conclusione C oppure nelle foglie.\nDeve essere una variabile libera!, non deve avere nessuna altra ipotesi presa da altro.\nForma generale\nCompletezza ed incompletezza di Godel Angelo was here 18/10/22, and 20/03/24 too! Primo teorema Enunciato\nGamma voglio identificare un singolo mondo.\nSe contiene l\u0026rsquo;aritmetica ho i numeri la somma i prodotti e simili. Se gamma Ã¨ consistente (quindi interessante, sennÃ² tutto e dimostrabile, Ã¨ anche un modo per dire che non ho piÃ¹ mondi). Allora non posso filtrare in maniera da tenerne solamente uno. il gamma deve tenere anche dei mondi in piÃ¹.\nQuindi quando gamma parla di artimetica non si puÃ² filtrare fino a un singolo mondo.\nQuindi qualunque aritmetica prendo, non posso mai filtrare fino a singolo mondo!\nÃ¨ una incompletezza di Gamma, ma non Ã¨ una incompletezza delle regole!\nAbbozzo\nÃˆ una delle prime assolute codifiche!\nbigezione fra formule ed alberi, e la sintassi dimostrazione e poi utilizza il paradosso del mentitore (io mento) crea un numero che dice che non Ã¨ dimostrabile, quindi fonde livello e metalivello per cui non puÃ² nÃ© essere dimostrabile nÃ© essere indimostrabile (altrimenti sarebbe inconsistente). Entrambe sono false\nIo sono dimostrabile se e solo se io non sono dimostrabile, quindi entrambe devono essere false.\nUno dei teoremi piÃ¹ storpiati dai divulgatori scientifici. Ma allo stesso tempo Ã¨ uno dei teoremi piÃ¹ profondi della logica.\nSe abbiamo abbastanza ipotesi da poter identificare solamente un singolo mondo, allora vale il concetto di terzo escluso, quindi o vale F conseguenza logica del mondo oppure not F Ã¨ conseguenza logica\n(nel caso contrario posso avere sia non G sia G non sono conseguenze logiche di piÃ¹ mondi).\nGodel trova la P, perÃ² quel singolo P Ã¨ ben conosciuto, non Ã¨ molto interessante.\nQuesto Ã¨ stato introdotto per la prima volta in Incompletezza nella logica del primo ordine. Ãˆ importante qui conoscere sia la\nSintassi della logica del primo ordine. Semantica della logica del primo ordine. Panoramica della dimostrazione Supponiamo di avere una logica del primo ordine ben definita sintatticamente. Consideriamo l\u0026rsquo;insieme $\\mathbb{N}, +, \\times$ Definiamo la prima teoria dell\u0026rsquo;altro di $(\\mathbb{N}, + , \\times)$ in questo modo $Th(\\mathbb{N}, +, \\times) = \\left\\{ \\varphi \\mid \\varphi \\text{ Ã¨ una formula vera della logica del primo ordine su } (\\mathbb{N}, +, \\times) \\right\\}$ Il nostro obiettivo Ã¨ dimostrare che $ETH$ Ã¨ riducibile tramite mappatura a questo insieme. Vedere Halting Theorem and Reducibility].\nCuriositÃ : La teoria $Th(\\mathbb{N}, +)$ Ã¨ decidibile, ma Ã¨ meno espressiva rispetto all\u0026rsquo;altra teoria aritmetica. Questo Ã¨ chiamato aritmetica di Presburger. E per l\u0026rsquo;analisi aritmetica Ã¨ piuttosto importante dal punto di vista computazionale.\nDimostrazione dell\u0026rsquo;Incompletezza Dato un vocabolario arbitrario e una teoria su quel vocabolario, l\u0026rsquo;insieme $\\left\\{ \\varphi \\mid \\varphi \\in T \\text{ ed Ã¨ valido} \\right\\}$ non Ã¨ un insieme decidibile. Questo approccio Ã¨ piÃ¹ computazionale.\nSupponiamo di avere una macchina di Turing che decide sopra, vogliamo ridurre il linguaggio $ETH$ su questo.\nCodifica della Macchina di Turing Vedere La macchina di Turing per definizione di TM. Andremo a codificare il comportamento di una macchina di Turing utilizzando la logica di primo ordine. E poi dato che questa codifica Ã¨ possibile si puÃ² dire che non Ã¨ decidibile quel problema. Il processo che usiamo Ã¨ chiamato gÃ¶delizzazione perchÃ© andiamo ad utilizzare codifiche per risolvere questo problema.\nConsideriamo questo vocabolario:\nSimboli di funzione sono $O^{0}, S^{1}, P^{1}$ che sono il 0, il successore e il precedessore. Simboli di relazione $head(n,m)$ se al passo $n$ Ã¨ sulla cella $m$ $state(n, m)$ se al passo $n$ Ã¨ sullo stato $q_{m}$ $cell_{i}(n, m)$ se al passo $n$ la cella $i$ contiene $m$ Poi diamo gli assiomi di peano al nostro sistema logico, poi codifichiamo con le relazioni questa affermazione: \u0026ldquo;Al passo $0$ la cella Ã¨ $1$ , lo stato Ã¨ $q_{0}$ e tutte le celle sono vuote.\u0026rdquo; abbiamo che $$ state(0, 0) \\land head(0, 1) \\land \\forall y(\\neg head(0, 0) \\land \\neg head(0, S(S(y)))) $$ Qui vediamo come la logica Ã¨ molto molto verbosa, sostanzialmente inutile per applicazioni molto piÃ¹ pratiche.\nPoi possiamo codificare la caratteristica della macchina di Turing principale ossia che \u0026ldquo;Ad ogni passo la macchina Ã¨ solo in uno stato, testina su una unica cella, che contiene al piÃ¹ un simbolo\u0026rdquo; Molto molto verboso scriverlo in modo logico anche questo. Poi possiamo andare a definire anche le regole di transizione e la regola dello stato finale, una volta fatto questo abbiamo codificato interamente una TM con le formule di Turing. RiconoscibilitÃ  di un sistema deduttivo Vedi Deduzione naturale#Il sistema deduttivo, dato questo sistema deduttivo, vogliamo che\nÃˆ corretta, ossia $P \\vdash \\varphi \\implies \\varphi \\text{ Ã¨ corretta}$ sound, se lo dimostro allora Ã¨ vero. L\u0026rsquo;insieme $\\left\\{ \\langle \\varphi, \\pi \\rangle \\mid \\pi \\text{ Ã¨ una dimostrazione di } \\varphi \\right\\}$ Ã¨ un insieme decidibile Possiamo subito dire che l\u0026rsquo;insieme $$ \\left\\{ \\varphi \\mid \\varphi \\in T \\land P \\vdash \\varphi \\right\\} $$ Ãˆ riconoscibile, data una teoria $T$ e un sistema deduttivo come sopra. Basta usare la schematizzazione di sopra, ed enumerare tutte le dimostrazioni per vedere se risolve questo. Potrebbe non finire, ma se Ã¨ valido mi fermo!\nIndecibilitÃ  di un sistema aritmetico Usando la costruzione di sopra possiamo vedere che chiaramente abbiamo fatto la riduzione $ETH \\leq Th(\\mathbb{N}, +, \\times)$ quindi non Ã¨ decidibile. Ossia non esiste un metodo algoritmico (sistema deduttivo) che ci dice se una data formula Ã¨ nel sistema. La codifica Ã¨ piÃ¹ complicata, perÃ² Ã¨ possibile.\nProposizioni indimostrabili Questo Ã¨ il secondo teorema di GÃ¶del, che ci dice che esistono formule che in nessun sistema deduttivo sono dimostrabili.\nOssia: $\\exists \\varphi \\in Th(\\mathbb{N}, +, \\times) \\mid \\forall P \\not\\vdash \\varphi$ Esiste una formula nella teoria dei numeri naturali tale per cui non esiste nessun sistema deduttivo che lo dimostri.\nSupponiamo per assurdo che tale proposizione esiste, allora abbiamo un sistema deduttivo che lo prova. Ma vogliamo dire che se vale questa proprietÃ  $Th(\\mathbb{N}, + , \\times)$ Ã¨ decidibile, contraddicendo #IndecibilitÃ  di un sistema aritmetico.\nL\u0026rsquo;algoritmo per deciderlo Ã¨ abbastanza semplice:\nUso una TM non deterministica che ci permette di verificare in parallelo se $P \\vdash \\varphi$ oppure se $P \\vdash \\neg \\varphi$, per ipotesi sappiamo che esiste una prova per $\\varphi$ o $\\neg\\varphi$. Tanto so che $P$ esiste per ipotesi. A seconda se sia vera $\\varphi$ o $\\neg\\varphi$ possiamo rispondere sÃ¬ o no, e quindi decidere il termine. Fine. Secondo teorema di incompletezza Questo ha un apporto molto maggiore, molto importante, la base dell\u0026rsquo;informatica.\nEnunciato\nNon riesco mai a concludere la consitenza della logica, dovrei rimettermi al metalivello continuamente, senza finire mai.\nNon possiamo mai essere sicuri della consistenza di una teoria, e alla fin fine la logica, la matematica si puÃ² paragonare alla religione da questo punto di vista. Noi non siamo sicuri che sia vero. Serve l\u0026rsquo;atto di fede. a di una teoria**, e alla fin fine la logica, la matematica si puÃ² paragonare alla religione da questo punto di vista. Noi non siamo sicuri che sia vero. Serve l\u0026rsquo;atto di fede.\nRegistro Ripassi Vecchi dubbi Definizione per induzione strutturale delle variaibli libere Cosa sono le due funzioni n-arie definite nella sintassi? Riguardare registrazione 09/12 (10 minuti iniziali in cui riassume tutta la logica del primo ordine) i nomi tecnici per dire termini e proposizioni Ancora da definire Le proprietÃ  delle equivalenze logiche notevoli Quali sono le equivalenze notevoli del per ogni e dell\u0026rsquo;esiste? Rivedere sostituzione in logica di primo ordine Registrazione 16/12 per prove di sostituzione o dim con primo ordine. Ripasso Prox: 4 Ripasso: December 14, 2021 Ultima modifica: October 18, 2022 6:01 PM Primo Abbozzo: December 1, 2021 9:56 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nReferences [1] Choi â€œThe Curious Case of Commonsense Intelligenceâ€ Daedalus Vol. 151(2), pp. 139\u0026ndash;155 2022\n","permalink":"https://flecart.github.io/notes/logica-del-primo-ordine/","summary":"Logica del primo ordine Questa Ã¨ la logica piÃ¹ utilizzata dai matematici\nLimitatezza della logica proposizionale La logica proposizionale classica non Ã¨ in grado di ragionare sull\u0026rsquo;infinito Fino ad ora abbiamo utilizzato una metalogica per giustificare il per ogni e l\u0026rsquo;esiste nelle dimostrazioni fin\u0026rsquo;ora.\nDobbiamo quindi dare una definizione piÃ¹ formale dei quantificatori.\nObiettivo della logica del primo ordine Si puÃ² quindi identificare come l\u0026rsquo;obiettivo della logica di primo ordine l\u0026rsquo;introduzione dei quantificatori dell\u0026rsquo;universale e dell\u0026rsquo;esiste","title":"Logica del Primo ordine"},{"content":"This note is just useful to classify some classical views of mind theories\nMentalism Si basa sull\u0026rsquo;idealismo Hegeliano Questo lo citiamo ma non ne parliamo proprio\nAttribute theory In cui sÃ¬ Ã¨ materialista, ma c\u0026rsquo;Ã¨ qualcosina in piÃ¹ che non ho ben capito.\nDualism In cui si pensa che esistono due componenti indipendenti (nel senso che uno puÃ² vivere senza l\u0026rsquo;altro).\nCartesian dualism Quello di Cartesio e della ghiandola pineale\nBundle dualism PiÃ¹ legato a Hume.\nInterazionismo e parallelismo (Armstrong 2022) pagina 10.\nMaterialism Behaviourism to have a mind is simply to behave physically in a certain way, or to have tendencies to behave physically in a certain way.\nIn un certo senso questo credo sia il punto di vista condiviso da (Turing 1950) quando ha ideato il suo bel test.\nCentral-state theory Mental states are identified with physical states of the organism that has the mind, in particular, with states of the brain or central nervous system\nSembra che nei circoli filosofici ci fosse un grande dubbio sulla mente vista come materialistica. Mentre in altro (Textbook of Psychology Saunders 1958) Ã¨ totalmente normale questo punto di vista Anche secondo Emanuele LaMalfa sto punto di vista sembra essere normale. Una cosa brutta dei filosofi Ã¨ che sembra veramente che scrivano troppo di nulla\u0026hellip;\nCritica:\nCentral-state Materialism holds that when we are aware of our mental states what we are aware of are mere physical states of our brain. But we are certainly not aware of the mental states as states of the brain.\nA me sembra in un certo senso simile a quanto detto da (Hofstadter 2007) in cui i singoli elementi fisici di per sÃ© non hanno nessun significato, solo quando vengono accorpati assieme, diventano dei symballein per cui cominciano ad avere senso. Noi abbiamo una percezione dei symballein nel nostro cervello, non degli stati fisici, che costituiscono questi simboli.\nIdentity theory Biezione fra cervello e mente in pratica, una versione di central state thery.\nOther Perception perception is nothing but the acquiring of true or false beliefs concerning the current state of the organismâ€™s body and environment.\nnon credo proprio, mi sembra stai confondendo l\u0026rsquo;atto di percepire e l\u0026rsquo;atto di elaborare le percezioni\u0026hellip;\nReferences [1] Armstrong â€œA Materialist Theory of the Mindâ€ Taylor \u0026amp; Francis 2022\n[2] Turing â€œI.â€”COMPUTING MACHINERY AND INTELLIGENCEâ€ Mind Vol. LIX(236), pp. 433\u0026ndash;460 1950\n[3] Hofstadter â€œI Am a Strange Loopâ€ Basic Books 2007\n","permalink":"https://flecart.github.io/notes/map-of-mind-theories/","summary":"This note is just useful to classify some classical views of mind theories\nMentalism Si basa sull\u0026rsquo;idealismo Hegeliano Questo lo citiamo ma non ne parliamo proprio\nAttribute theory In cui sÃ¬ Ã¨ materialista, ma c\u0026rsquo;Ã¨ qualcosina in piÃ¹ che non ho ben capito.\nDualism In cui si pensa che esistono due componenti indipendenti (nel senso che uno puÃ² vivere senza l\u0026rsquo;altro).\nCartesian dualism Quello di Cartesio e della ghiandola pineale","title":"Map of Mind Theories"},{"content":"Ripasso Prox: 65 Ripasso: June 21, 2023 Ultima modifica: June 9, 2023 12:53 PM Primo Abbozzo: November 8, 2022 1:48 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Domande\nSemplificazione grammatiche Gestione del non determinismo Il modo piÃ¹ facile per gestire il non determinsmo Ã¨ semplificare le grammatiche quindi andiamo a vedere metodi per fare ciÃ².\nSemplificazione grammatiche (5) Slide\nNo produzioni del tipo $A \\to \\varepsilon$ per bottom up (altrimenti va allâ€™infinito!) No produzioni unitarie, cosÃ¬ evito cicli in cui da A derivo sÃ© stesso. No simboli inutili No ricorsione sinistra (divergenza per top-down) Fattorizzazione della grammatica Eliminazione delel produzioni nulle Vogliamo creare un algoritmo utile ad eliminare le produzioni che non ci piacciono.\nFormalizzazione algo obiettivo !\nInsieme dei simboli annullabili ðŸŸ© Vogliamo con questa parte definire in modo formale l\u0026rsquo;insieme dei non terminali che portano a produzioni di quel genere\nSlide definizione simboli annullabili !\nOssia una annullabilitÃ  in n passi, e andiamo ad indagare tutti i simboli che soddisfano queste cose.\nNOTA: nello step induttivo, un simbolo Ã¨ annulable solo se lâ€™intera produzione Ã¨ annullabile (quindi tutte le cose in output.\nUna cosa del tipo $A \\to BC$ Ã¨ annullabile solo se lo sono entrambi (sia B che C).\nDerivazione grammatica annullabilitÃ  ðŸŸ© Slide\nSlide esempio\nIntuizione\nIn pratica vado ad eliminare i non terminali in tutti i modi possibili, e vado ad eliminare quelle che poi vanno ad eliminare. In pratica mi vado a tenere tutte le configurazioni che posso attenere, annullando quello che si puÃ² annullare.\nFaccio questa cosa per tutti!\nNota sul vuoto\nSe vogliamo che il nuovo linguaggio possa accettare il vuoto, allora basta aggiungere al non terminale iniziale la produzione dle tipo $S \\to \\varepsilon$, ma questo Ã¨ presente solo al primo!.\nProduzioni unitarie Vorremmo evitare le produzioni unitarie che portano a cicli perchÃ© altrimenti avrei dei cicli infiniti che non sono molto buoni per il parsing.\nDefinizioni utili\nCoppie unitarie ðŸŸ© Slide\nIn pratica Ã¨ come se definissi una operazion per le coppie unitarie, e la chiudo per riflessivitÃ  e transitivitÃ .\nAlgoritmo di eliminazione ðŸŸ© Algoritmo per eliminare coppie unitarie\nPer la creazione della nuova grammatica, quello che faccio non Ã¨ altro che filtrare quelle che mi portano a coppie unitarie.\nOltre a questo faccio una copiaâ€¦ Se guardi lâ€™esempio comunque lo vedi un pÃ² meglio\nEsempio\nRimozione di simboli inutili Def generatore e raggiungibilitÃ  (2) ðŸŸ© In questa sezione andiamo a definire alcuni concetti utili a definire l\u0026rsquo;inutilitÃ  di alcuni simboli\nSlide !\nCosÃ¬ andiamo a definire come simbolo utile simbolo generatore e raggiungibile.\nCosÃ¬ andiamo a racchiudere il concetto di simbolo che non genera nulla, come inutle\nEsempio in slide !\nCalcolo dei simboli generatori ðŸŸ©- Slide !\nOssia se da un simbolo ricavo qualcosa che Ã¨ un generatore, allora questo Ã¨ un generatore!\nE posso creare un algoritmo ricorsivo che genera questi simboli, partendo dai terminali che sono sempre dei generatori\nCalcolo dei simboli raggiungibili ðŸŸ¨++ Slide\nIn pratica mi calcolo, ancora qui in modo ricorsivo, tutti i strumenti raggiungibili dal nodo di start, con qualcosa di simile a una dfs (aggiungo ai raggiungibili ogni non terminale figlio, e comincio ad esplorare questo non terminale).\nWrap-up (chiede) ðŸŸ¨+ Enunciato e dimostrazione\nLâ€™algoritmo Ã¨ molto semplice, Ã¨ costituito da due passi fondamentali:\nElimino tutti i simboli che non sono generatori Rimuovo tutti i simboli non raggiungibili Nota sullâ€™ordine\nÃˆ importante eseguire le operazioni in questo ordine, altrimenti capita come in slide\nEsempio importanza di ordine\nEsempio piÃ¹ tosto di applicazione di questo\nEliminazione rico sinistre Rico sinistre immediate ðŸŸ¨ Slide\nL\u0026rsquo;idea Ã¨ spaccare la ricorsione sinistra in una altra produzione e un nuovo non terminale fittizzio che vado ad utilizzare come non terminale di supporto.\nEsempio di risoluzione\nPosso considerare queste immediate, quando non ho dei cicli chiari nelle ricorsioni sinistre, sotto proviamo a creare un algoritmo per risolvere ricorsioni sinistre con cicli.\nRico sinistre non-immediate ðŸŸ¥+ Esempio di non-immediato\nAlgoritmo di risoluzione O(n2)\nIn pratica provo a sostituire tutto quanto posso in modo greedy.\nEsempio di applicazione\nEsempio applicazione con tutto finora\nFattorizzazione ðŸŸ© Slide problema generale\nLâ€™intuizione per sta parte Ã¨ raccogliere le cose in comune. Lâ€™algoritmo non va a far altro che guardare i prefissi, e prendere il piÃ¹ lungo per ogni non terminale.\nAlgoritmo per fattorizzazione\nesempio di applicazione\nForme normali Chomsky ðŸŸ©â€” Slide\nQuesta ci piace, perchÃ© le produzioni o sono di\nSIngolo terminale Doppio non terminale. Si puÃ² notare che questa forma Ã¨ sia libera da epsilon sia sia libera da coppie unitarie.\nE si puÃ² sempre trovare una grammatica in questa forma, questa cosa ci piace.\nGreibach ðŸŸ© Slide\nAnche questa si puÃ² sempre fare, ed Ã¨ una forma che ci piace perchÃ© non abbiamo derivazione ricorsive sinistre brutte che ci distruggono tutto.\n","permalink":"https://flecart.github.io/notes/semplificazione-grammatiche/","summary":"Ripasso Prox: 65 Ripasso: June 21, 2023 Ultima modifica: June 9, 2023 12:53 PM Primo Abbozzo: November 8, 2022 1:48 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Domande\nSemplificazione grammatiche Gestione del non determinismo Il modo piÃ¹ facile per gestire il non determinsmo Ã¨ semplificare le grammatiche quindi andiamo a vedere metodi per fare ciÃ².\nSemplificazione grammatiche (5) Slide\nNo produzioni del tipo $A \\to \\varepsilon$ per bottom up (altrimenti va allâ€™infinito!","title":"Semplificazione grammatiche"},{"content":"Ripasso Prox: 46 Ripasso: May 27, 2023 Ultima modifica: May 6, 2023 12:48 PM Primo Abbozzo: March 20, 2023 10:46 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Astrazione sul controllo Significato di astrazione L\u0026rsquo;astrazione Ã¨ una cosa fondamentale nell\u0026rsquo;informatica, lâ€™abbiamo visto anche nella prima lezione in assoluto per architettura, il sistema a strati di Architettura e livelli 1, 2 reti e simili.\nIl principali metodi sono astrazioni sul controllo e sui dati sui dati stiamo cominciando a parlarne in Teoria dei Tipi.\nLe astrazioni sono utili a nascondere dettagli per qualche fenomeno o simile (ricorda l\u0026rsquo;esempio della mappa, che non Ã¨ il territorio Ã¨ una astrazione su essa, che contiene ancora informazioni utili). Vogliamo quindi concentrarci su quanto ci interessa\nuna cosa che a noi Ã¨ molto interessante Ã¨ la astrazione funzionale\nAstrazione funzionale ðŸŸ© Vogliamo creare una associazione fra funzione e procedura, ossia esporre solamente cose come intestazione della funzione, parametri e valore di ritorno per descrivere una funzione, la implementazione non ci interessa.\nSi puÃ² ben notare che meno la funzione interagire con lâ€™ambiente non locale, ossia piÃ¹ Ã¨ indipendente, ha meno side effect, meglio Ã¨ fatta sta astrazione.\nComunicazione con lâ€™ambiente (3) ðŸŸ© la comunicazione con lâ€™ambiente puÃ² avvenire mediante tre metodi principali.\nParametri Ambiente no nlocali Il valore di ritorno Formali e attuali e 3 comunicazione ðŸŸ© Nella dichiarazione di funzione si parla di parametri formali, nel senso che sono delle variabili legate, se rinominate correttamente attraverso funzioni definite in Logica si puÃ² cambiare nome.\nUn parametro attuale Ã¨ quello effettivamente mandato, che si fa mediante la chiamata di funzione.\nSlide formali e attuali\nAnche il flusso di informazione puÃ² essere diviso in piÃ¹ modi.\nin entrata (come il passaggio per valore) In uscita (boh, si assegna il valore ebbasta, senza leggerle). In entrata e uscita (come le reference) Passaggio di parametri Passaggio per valore ðŸŸ© Questo Ã¨ il classico passaggio di funzione che abbiamo in C.\nViene calcolato il valore (r-value)\nil valore viene messo sulla pila, quindi come se fosse una variabile locale.\nDistruzione quando si ritorna dalla funzione\nMolto costoso per dati grossi perchÃ© devo fare la copia\nnon ho modo di comunicare usando quella variabile direttamente al parametro.\nSlide per passaggio valore\nla cosa carina Ã¨ che Ã¨ una copia, non ho trasmissione delle informazioni.\nPassaggio per riferimento ðŸŸ© In questo caso passo il riferimento, o l-valore dellâ€™oggetto, quindi la sua locazione o riferimento. (in java in pratica Ã¨ un riferimento perchÃ© si utilizza la reference model come descritto in Valutazione Espressioni.\nSlide passaggio per riferimento\nSlide riassunto valore e riferimento\nUn concetto qui importante Ã¨ la trasparenza referenziale, nel senso che non ci importa di come Ã¨ stato chiamato, tanto Ã¨ una copia (per il passaggio per vlaore) quindi riesco ad avere quanto mi interessa. (questo non vale per reference, perchÃ© dipende da con cosa lo ho chiamato!)\nCome fare un passaggio con semantica semplice come il passaggio di valore e senza problemi di aliasing come reference, e con anche comunicazione.\nEsempio di problema di aliasing\nPassaggio per costante ðŸŸ© VALORE NON MODIFICABILE\nSolo in una direzione, solo che non si puÃ² modificare. Ãˆ come un passaggio per valore, solo che si potrebbe implementare per riferimento per ragioni di efficienza. Ma comunque dipende dallâ€™implementazione della macchina astratta.\nPassaggio per risultato ðŸŸ© Questo Ã¨ il duale del passaggio per valore, perchÃ© alla chiamata di funzione assegno la funzione a questa variabile (alla fine assegno il valore del formale al parametro attuale), quindi Ã¨ molto utile per trasmettere valore dalla procedura al main.\nOssia ho una copia del valore formale *(aka valore attuale) al parametro attuale, ma lo ho solo alla fine della funzione.\nSlide passaggio per risultato\nPassaggio per valore risultato ðŸŸ© Questo permette il passaggio in entrambe le direzioni (si fa la copia e si assegna alla fine). Alcuni linguaggi implementano questa cosa attraverso la reference, sempre per il concetto che Ã¨ molto piÃ¹ efficiente tenere le reference, solo che c\u0026rsquo;Ã¨ il problema di aliasing, quando mando la stessa reference.\nEsempio di valorerisultato differente da reference\nPassaggio per Nome (!) ðŸŸ© In pratica sostituisco il nome del parametro attuale al posto del parametro formale, senza cattura.\nuna chiamata alla procedura P Ã¨ la stessa cosa che eseguire il corpo di P dopo aver sostituito i parametri attuali al posto dei parametri formali\nSi puÃ² notare come se fosse la macro espansione in assembly (di cui credo le macro di C sono molto simili)\nEsempi di cose del passaggio per nome\nPROBLEMI DI SCOPING\nSlide scopes\nQuesto sarÃ  il problema che permetterÃ  il passaggio dellâ€™ambiente molto utilizzato per le variabili di ordine superiore come le funzioni.\nIIMPLEMENTAZIONE DEL PASSAGGIO PER NOME\nLâ€™implementazione di questo passaggio Ã¨ molto interessante, perchÃ© dovrei passare anche lâ€™ambiente iniziale affincheâ€™tutta lâ€™espressione abbia senso! lâ€™operazione fondamentale Ã¨ lo scoping.\nSlide implementazione per nome\nSolitamente Ã¨ molto costoso perchÃ© per valutare devo sempre andare in un ambiente diverso dall\u0026rsquo;attuale, poi anche dal fatto che il valore Ã¨ rivalutato ad ogni occorrenza!\n","permalink":"https://flecart.github.io/notes/astrazione-sul-controllo/","summary":"Ripasso Prox: 46 Ripasso: May 27, 2023 Ultima modifica: May 6, 2023 12:48 PM Primo Abbozzo: March 20, 2023 10:46 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Astrazione sul controllo Significato di astrazione L\u0026rsquo;astrazione Ã¨ una cosa fondamentale nell\u0026rsquo;informatica, lâ€™abbiamo visto anche nella prima lezione in assoluto per architettura, il sistema a strati di Architettura e livelli 1, 2 reti e simili.\nIl principali metodi sono astrazioni sul controllo e sui dati sui dati stiamo cominciando a parlarne in Teoria dei Tipi.","title":"Astrazione sul controllo"},{"content":"Ripasso Prox: 25 Ripasso: December 24, 2022 Ultima modifica: January 2, 2023 3:24 PM Primo Abbozzo: October 27, 2022 11:31 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nRisoluzione di equazioni non lineari.pdf\nPer trovare i zeri di una funzione continua non lineare non esistono alcuni metodi diretti che ci portano subito a una soluzione. Per questo motivo andremo ad analizzare molteplici pasis iterativi per trovare i zeri di una funzione.\nLa discussione di convergenza di ordine p Ã¨ stata giÃ  discussa qui Note introduttive convergenza e iterazione , per quanto riguarda i metodi iterativi per risolvere sistemi di equazioni lineari\nGlobale e local Ricordiamo di Norme e Condizionamento, in cui il condizoinamento era piÃ¹ o meno una stima di quanto cambia la soluzione quando cambia brevemente l\u0026rsquo;input. Ma ora vogliamo estendere il concetto per equazioni non lineari.\nSlide dimo (non chiede) espsilon Ã¨ una perturbazione gestita da una funzione h Cose da ricordare\nSe Ã¨ uno zero con moltiplicitÃ  maggiore di 1 Ã¨ sempre mal condizionato Altrimenti Ã¨ nell\u0026rsquo;ordine dellâ€™inversa della derivata calcolata in quel punto Slide di questa ultima roba\nMetodo di bisezione Introduzione al metodo di bisezione Questo metodo funziona per funzione continua in un intervallo e $f(a)f(b) \u003c 0$, per il teorema degli zeri esiste una soluzione, allora dobbiamo andare ad iterare lâ€™argomento fin quando non abbiamo una stima abbastanza precisa del punto.\nSlide\nIn pratica va a dimezzare sempre ad ogni iterazione lâ€™intervallo in cui puÃ² essere presente il nostro numero.\nConvergenza e Costo Una cosa bella di questo, in confronto ai metodi per equazioni lineari Ã¨ che posso stimare il numero di iterazioni\nSlides\nIl costo di questo metodo dipende dalla funzione che bisogna essere calcolata ad ogni iterazione, ma al massimo facciamo un numero di iterazioni logaritmico rispetto al nostro intervallo, quindi qualcosa del tipo\n$$ O(\\log(b - a) \\times O(f)) $$ Talvolta puÃ² succedere che Ã¨ sempre costante la variabile in mezzo, quindi non posso diminuire di piÃ¹ lâ€™intervallo, vedi esempio in toggle\nImprecisione floating point, e non convergenza\nPer risolvere questo aggiungo eps dellâ€™intervallo, in modo da rilassare la cosa, ed evitare che rimanga bloccato.\nEsempio blocco se non uso questo\na = 98.5, 98.6 =b e epsilon = 0.004, precisione macchina Ã¨ 0.01 / 2 (da 1/2 beta t - 1)\nQuindi si ferma se 0.004 + 0.01/2 * 98.6 = 0.004 + 0.986 / 2 quindi effettivamente si dovrebbe fermare. perchÃ© la differenza Ã¨ minore di 0.5 tipo.\nNote sulla implementazione (2) Si preferisce di calcolare il punto medio in questa forma\n$a + (b -a)/2$, invece che $(a + b)/ 2$ per limitare gli errori.\nEsempio di questo vantaggio\n0.983, 0.984, F(10, 3, -5, 5)\nLa somma Ã¨ 1.967, che normalizzato troncato Ã¨ 0.196 1e1,, diviso diventa 0.980, oppure 0.985 se arrotondo al piÃ¹ vicino, in ogni caso Ã¨ errato. Mentre con lâ€™altro metodo ottenevo\n0.983 + (0.001 = 0.1 1e-2), 0.05 1e-2 = 0.5 1e-3 la somma Ã¨ 0.9835, che Ã¨ 0.983 quindi Ã¨ ancora dentro lâ€™intervallo.\nOltre a questo introduco la funzione sign e non lo calcolo il prodotto ella funzione, quindi vado a considerare\n$sign(f(a)) sign(f(b)) \u003c0$\nAnalisi dei punti fissi Slide idea\nIdea dagli appunti pisani In pratica andiamo a dire che Ã¨ piÃ¹ facile trovare punti fissi Invece di trovare uno zero per f, cerco di trovare uno zero per la funzione di g equivalente, tale che sia un punto fisso. Probabilmente perchÃ© Ã¨ piÃ¹ facile trovare dei punti fissi ed Ã¨ per questo che vado a cercarlo. La funzione $\\Phi(x)$ di supporto Ã¨ maggiore di 0.\nBanach fixed-point theorem - Wikipedia\nQuello sopra Ã¨ il teorema principale utile a giustificare lâ€™esistenza del punto fisso, e anche dellâ€™unicitÃ . Chiaramente non sappiamo cosa siano gli spazi metrici, e costa troppo in termini di tempo provare a capire il motivo.\nTi basti sapere che la funzione deve essere:\nContinua in [a, b] Una contrazione, ossia soddisfare questa relazione: $|g(a) - g(b)| \\leq L|a - b|$ Esistenza del punto fisso La funzione deve essere continua La funzione deve essere una contrazione nellâ€™intervallo prestabilito. Lâ€™immagine deve essere contenuta al dominio, altrimenti non posso utilizzare lâ€™immagine come input. Enunciato\nNota; questo teorema Ã¨ abbastanza importante (e anche tosto se si vuole far bene), lo puoi trovare in questa pagina di wiki\nNota: derivabilitÃ  e contrazione: Se il modulo della derivata Ã¨ minore di 1 allora Ã¨ una contrazione! (non il perchÃ© ti basta ricordare sta cosa lel). Un altra nota Ã¨ che se sono soddisfatte quelle due cose, si puÃ² dimostrare che converge sempre! TODO: velocitÃ  di convergenza? Criteri di convergenza??\nConvergenza delle contrazioni Molto simile al teorema di esistenza e di unicitÃ , questo invece stabilisce la convergenza, ed Ã¨ sufficiente che la funzione sia una contrazione per ogni punto in un intorno del punto fisso.\nSlide CioÃ¨ Ã¨ fatta su una variazione su applicazione successive, e sul valore della funzione che deve essere abbastanza vicina allo 0.\nOppure si puÃ² fare su errori relativi oppure frazione del massimo della funzione. Ad ogni modo Ã¨ a seconda di tolleranze prefissate.\nIn ogni modo con questo vogliamo cercare di\nVedere che la nostra funzione abbia raggiunto un valore vicino allo zero. Vedere quanto varia ancora la soluzione proposta, non vorremmo che variasse ancora tanto. Slide\nTi basti sapere che Ã¨ lineare, sul perchÃ© non lo so. Ma Ã¨ lineare lel.\nMetodo di Newton (delle tangenti) Ãˆ molto simile al metodo delle approssimazioni successive, ma in questo caso vogliamo utilizzare la derivata, come funzione ausiliaria. Vogliamo cercare di riassegnare la x a seconda di dove tenda a 0.\nDa notare che Ã¨ una convergenza quadratica quindi molto veloce! Solo che si spende il tempo per calcolare la funzione due volte per sÃ© stessa e la derivata\nalla fine si avrÃ  una successione nella forma\n$$ x_{n + 1} = x_n - \\dfrac{f(x_n)}{f'(x_n)} $$ Note velocitÃ  di convergenza Caso lineare (metodo approssimazioni classico)\nCaso convergenza quadratica\nPer il metodo di newton, la convergenza Ã¨ quadratica!\nCondizioni di convergenza locale (3) Significa che riesce a trovare il minimo locale per la funzione\nSlide Condizioni di convergenza globale Significa che riesce sempre a trovare il minimo globale della funzione, come vedremo ci sono un sacco di condizioni restringenti (poi con\nSlide Convergono anche tutte le variazioni possibili, sempre con a e b opposti (ma in modo diverso), e derivata seconda fatta in modo diverso\nSe la derivata seconda Ã¨ minore o ugualedi 0, parto da quello alto, altrimenti, da quello basso (non ho capito bene la 4 condizione boh).\nTODO: Capire enunciati di questo\n08/11/22 Enunciati piÃ¹ o meno bene, dovrei semmai approfondire con dim o, Newton sembra essere particolarmente interessanteâ€¦ 14/11/22 Boh, okey. 02/12/22 Boh okey x2 02/01/22 Dovrei farmi un po meglio le condizioni, ma piÃ¹ o meno ci sono ancora ","permalink":"https://flecart.github.io/notes/equazioni-non-lineari/","summary":"Ripasso Prox: 25 Ripasso: December 24, 2022 Ultima modifica: January 2, 2023 3:24 PM Primo Abbozzo: October 27, 2022 11:31 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nRisoluzione di equazioni non lineari.pdf\nPer trovare i zeri di una funzione continua non lineare non esistono alcuni metodi diretti che ci portano subito a una soluzione. Per questo motivo andremo ad analizzare molteplici pasis iterativi per trovare i zeri di una funzione.\nLa discussione di convergenza di ordine p Ã¨ stata giÃ  discussa qui Note introduttive convergenza e iterazione , per quanto riguarda i metodi iterativi per risolvere sistemi di equazioni lineari","title":"Equazioni non lineari"},{"content":"1 Introduzione Lâ€™intelligenza artificiale Ã¨ un campo in velocissima espansione, con giÃ  un mercato enorme di un trillion dollars.\nInoltre il suo campo di studi spazia da moltissimi campi, Ã¨ per questo che quasi potresti considerarla universale.\n1.1 Lâ€™intelligenza artificiale 1.1.1 Cosa Ã¨ (2) Nel tempo si Ã¨ cercato di definire con esattessa cosa sia lâ€™intelligenza artificiale. In generare si Ã¨ basato su alcuni parametri cardine ossia:\nLa capacitÃ  di replicare attivitÃ  umane / la capacitÃ  di applicare attivitÃ  razionali La capacitÃ  di ragionare / il comportamento intelligente Su questi due binomi sono stati fatti dei modelli, andiamo ora a scoprire in che senso lâ€™intelligenza artificiale Ã¨ intelligente.\n1.1.2 Modelli generali Tra i modelli presenti quello di maggiore interesse nel tempo Ã¨ stato lâ€™ultimo, per il resto vanno a toccare molti campi che sono un pÃ² fuori dalle competenze dellâ€™informatico. (credo)\nAgire umanamente\nCome il test di turing, definisce lâ€™intelligenza artificiale come un software che riesce ad emulare il comportamento umano, talmente che non riusciresti a riconoscerlo.\nMa i ricercatori hanno preferito cercare di capire cosa Ã¨ lâ€™intelligenza in sÃ©, invece di cercare di emulare quella umana.\nPensare umanamente\nQuesto modello ha un campo molto fiorente nelle scienze cognitive, attraverso scan delle immagini, o comunque una conoscenza approfondita in primo luogo della stessa conoscenza umana, vogliamo cercare di costruire un intelligenza artificiale che ne emuli le capacitÃ  (pensiero interiore, psicologia etc).\nPensare logico\nQuesto Ã¨ stato uno dei primi metodi per costruire un software che si potesse considerare intelligente. Si basa sugli sviluppi della logica come campo di studi: ossia la possibilitÃ  di costruire software che siano in grado di dimostrare tutto il possibile.\nOppure utilizzando una analisi probabilistica, per analizzare la realtÃ .\nAgire logico\nLâ€™immagine dellâ€™agente Ã¨ stato il metodo piÃ¹ florido nella storia dellâ€™intelligenza artificiale nel momento in cui se ne voleva costruire una. Tanto che lâ€™obiettivo della costruzione di un ente che potesse agire in modo logico in un ambiente si potrebbe considerare come se fosse un modello standard per la costruzione di un intelligenza artificiale.\nUn problema perÃ² sorge: allineamento dei valori: a volte fare la cosa logicamente piÃ¹ corretta non Ã¨ la migliore soluzione, esempio se lâ€™obiettivo fosse vincere a tutti i costi una partita a scacchi, lâ€™agente, con la possibilitÃ  di agire sull\u0026rsquo;ambiente circostante, potrebbe compiere azioni che solitamente considereremmo ingiuste, al solo scopo di raggiungere questo obiettivo! â†’ vorremmo costruire qualche agente che sia in grado di portare un beneficio provato (dimostrato).\n1.2 Lâ€™agente Definiamo in modo molto generale, lâ€™agente come qualcosa che possiede attuatori e percettori per interagire e percepire lâ€™ambiente (che puÃ² essere molto vario).\nUn concetto importante Ã¨ che lâ€™agente puÃ² basare il suo output attraverso solamente ciÃ² che ha percepito (dall\u0026rsquo;inizio fino al tempo corrente) quindi potremmo considerare lâ€™esistenza di una funzione agente che mappa sequenza input â†’ azione. e lâ€™implementazione di essa.\n1.2.1 La razionalitÃ  Vogliamo cercare di dare una definizione di razionalitÃ  in qualunque agente, e si puÃ² formalizzare in questo modo: PEAS FRAMEWORK (performance, env, actuators, sensors)\nUna funzione di performance Lâ€™insieme delle conoscenze a priori sul mondo Lâ€™insieme delle azioni possibili sul mondo La sequenza di percepimento Con questi 4 oggetti, definiamo che lâ€™agente Ã¨ intelligente se la funzione che prende in input la sequenza di percezione e le conoscenze sul mondo, dia in output lâ€™azione che massimizza la performance.\nLa misura della performance\nIl modo migliore che abbiamo per misurare la performance Ã¨ sulle conseguenze che ha sull\u0026rsquo;ambiente. Quindi valutare se lâ€™effetto che ha Ã¨ positivo (sempre in funzione alla positivitÃ  descritta da chi ha progettato lâ€™agente) o negativo.\nUna nota: Ã¨ importante costruire la performance secondo gli effetti sull\u0026rsquo;ambiente, e non secondo il modo con cui si dovrebbe comportare lâ€™agente!\nMa non Ã¨ detto che sia il modo migliore per fare ciÃ², Ã¨ un problema piÃ¹ filosofico (quello sugli effetti uguali, ma uno sta basso e fa sempre, mentre lâ€™altro Ã¨ molto efficiente a momenti e per il resto del tempo sta proprio fermo).\nOnniscienza ed autonomia\nNon possiamo avere un agente che sappia tutto, bisogna tarare la performance su questa osservazione: lâ€™azione scelta non deve essere la migliore possibile in assoluto (altrimenti lâ€™agente dovrebbe sapere tutto) ma dovrebbe essere la migliore azione in guadagno atteso.\nQuesto comporta la migliore decisione che possa massimizzare scelte future (come raccolta delle informazioni si spende un pÃ² di tempo per raccogliere piÃ¹ informazioni sullâ€™ambiente) oppure lâ€™azione stessa nel caso si abbia giÃ  conoscenza sullâ€™ambiente.\nÃˆ da notare che il caso in cui si ha una totale conoscenza sullâ€™ambiente a priori (caso anche di alcune specie di animali come lowly dung beetle o sphex wasp) toglie di autonomia (ossia la capacitÃ  di agire a seconda di input ambientali e non solo secondo conoscenze a priori) allâ€™agente, e potrebbe non dare le soluzioni volute (in questi casi lâ€™agente agisce soltanto, perchÃ© pensa di sapere giÃ  tutto).\n1.2.2 Lâ€™ambiente Ci sono una moltitudine di variabili che possono risultare utili per classificare un ambiente tra cui:\nDeterminismo-nondeterminismo o stocastico OsservabilitÃ  parziale-totale singolo-multi agente episodico - sequenziale (si basa o no su eventi passati?) statico o dinamico (o semidinamico) (lâ€™ambiente puÃ² cambiare quando lâ€™agente pensa sul da farsi?) discreto o continuo (gli stati sono infiniti o finiti?) conosciuto o sconosciuto (i risultati delle azioni sono conosciute a priori, come se fossero leggi della fisica). Per esempio, il progetto mnk-game Ã¨ un ambiente che Ã¨ Determinista, totalmente osservabile, agente multiplo, sequenziale, statico, discreto e conosciuto.\nQuesti direi sono i 7 cardini che definiscono ad alto livello un ambiente.\n1.3 Tipologie di agente In questa parte vengono descritti le tipologie di agente a cui si Ã¨ pensato. Parlando in generale Ã¨ come se fossero dei modelli che vengono costruiti uno sopra lâ€™altro, in senso crescente, fino ad arrivare allâ€™agente che apprende come modello finale (correntemente piÃ¹ gettonato).\nI modelli qui presentati sono molto astratti, utili per semplicitÃ  e chiarezza, ma non ci aiuta in alcun modo per capire come implementare tale modello, tutti gli agenti qui presentati saranno di questo tipo\n1.3.1 Basati su riflessi Lâ€™agente che si basa sui riflessi Ã¨ il piÃ¹ semplice degli agenti che possono essere presenti. Come dice il nome si basa sul concetto di riflesso molto simile al riflesso umano, come sbattere le ciglia, scattare via da una fonte di calore simili azioni.\nSi tratta di un agente che agisce sulla singola percezione e trova lâ€™azione corrispondente a seguito di questa. Le percezioni passate non interessano proprio, sa giÃ  agire subito dalla percezione presente.\nCaratteristiche di questo agente:\nStaticitÃ  nelle azioni, esegue solo ciÃ² per cui Ã¨ programmato, quasi fosse un if-then agent, infatti dovremmo parlare di regole di condizione-azione\nNecessitÃ  di osservabilitÃ  totale, altrimenti Ã¨ difficile che faccia lâ€™azione piÃ¹ intelligente\nModello in breve\n1.3.2 Basati su modelli Questo modello si puÃ² considerare una espansione al modello precedente. Si cerca piano piano di rendere lâ€™agente piÃ¹ flessibile, e non soltanto qualcosa di programmato, come se fosse un singolo algoritmo:\nOra lâ€™agente possiede un modello interno del mondo, che Ã¨ cambiato a seconda della percezione nel momento. Quindi lâ€™azione ora non Ã¨ presa solamente secondo la percezione attuale, ma anche secondo il modello del mondo, e la percezione attuale.\nCaratteristiche\nFunzione di transizione del modello, che serve per aggiornare il modello interno del mondo a seconda dei cambiamenti percepiti Funzione di sensore, che traduce le informazioni percepite in funzione dello stato del mondo (es. se ho la telecamera sporca di acqua per la pioggia, lâ€™input sarÃ  un pÃ² diverso) Quindi maggiore flessibilitÃ  in confronto alla precedente.\nModello in breve\n1.3.3 Basati su obiettivi Lâ€™ulteriore espansione di questo agente rispetto alla precedente Ã¨ che ora il modello tiene conto anche delle possibili conseguenze future delle proprie azioni in funzione del raggiungimento o meno del proprio obiettivo\nCaratteristiche\nEsistenza di un obiettivo ben dichiarato proprio (che condiziona la funzione di valutazione) PossibilitÃ  di rimpiazzare lâ€™obiettivo precedente con uno simile (flessibilitÃ ) Aggiornamenti su conseguenze delle proprie azioni sullo stato del raggiungimento per lâ€™obiettivo Modello in breve\n1.3.4 Basati su utility cerca di valutare se Ã¨ una conseguenza buona o cattiva, a seconda di una propria funzione di valutazione che cerchi di rispettare il meglio possibile la funzione di valutazione dellâ€™ambiente in cui Ã¨ presente.\nÃˆ buono in caso ci possano essere degli obiettivi che si eliminano uno a vicenda, Ã¨ buono per trovare i tradeoff **comune in molte situazioni (es. voglio arrivare piÃ¹ in fretta possibile, ma non voglio investire persone).\nCaratteristiche\nUna funzione di valutazione che cerca di massimizzare il valore atteso della propria azione. Modello in breve\n1.3.5 Basati su apprendimento Al fine di avere un agente flessibile che possa adattarsi in ambienti anche molto differenti fra di loro, vorremmo creare un metodo per cui lâ€™agente possa imparare dai propri errori. Questo modello si prefissa lâ€™obiettivo di creare un framework generale per un agente che impara.\nCaratteristiche:\nCritico: cerca di valutare le azioni prese dallâ€™agente e pone consigli su cosa cambiare Elemento apprendimento: che cambia lo stato di conoscenza interna dellâ€™agente in modo che possa prendere decisioni migliori, grazie al feedback del critico generatore di problemi che propone nuovi problemi/esperimenti che possono migliorare altri tratti dellâ€™agente. Modello in breve\nLâ€™agente vecchio Ã¨ interamente raccolto nel performance element\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/lâ€™intelligenza/Untitled 6.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/lâ€™intelligenza/Untitled 6\u0026quot;\u0026gt; ","permalink":"https://flecart.github.io/notes/lintelligenza/","summary":"1 Introduzione Lâ€™intelligenza artificiale Ã¨ un campo in velocissima espansione, con giÃ  un mercato enorme di un trillion dollars.\nInoltre il suo campo di studi spazia da moltissimi campi, Ã¨ per questo che quasi potresti considerarla universale.\n1.1 Lâ€™intelligenza artificiale 1.1.1 Cosa Ã¨ (2) Nel tempo si Ã¨ cercato di definire con esattessa cosa sia lâ€™intelligenza artificiale. In generare si Ã¨ basato su alcuni parametri cardine ossia:\nLa capacitÃ  di replicare attivitÃ  umane / la capacitÃ  di applicare attivitÃ  razionali La capacitÃ  di ragionare / il comportamento intelligente Su questi due binomi sono stati fatti dei modelli, andiamo ora a scoprire in che senso lâ€™intelligenza artificiale Ã¨ intelligente.","title":"lâ€™intelligenza"},{"content":"Gli argomenti della lezione 31 Ottobre sono circa da pagina 164 fino a 185 del mazzoldi.\nLeggi di Ohm Introduzione microscopica ðŸŸ© Sappiamo che $$ \\vec{J} = -n e \\vec{v}_{d} ne^{2} t \\frac{\\vec{E}}{m} $$ Vedi analisi della velocitÃ  di deriva col modello del 1900 in Corrente Elettrica.\nDove abbiamo utilizzato la definizione di densitÃ  di corrente e la velocitÃ  fra collisioni ed altre Questo Ã¨ una motivazione per considerare la densitÃ  di corrente come se fosse nello stesso verso.\nDa questo notiamo che dipende solamente dal materiale perchÃ© abbiamo $t$ che Ã¨ il tempo che intercorre fra collisione uno e due, mentre $n$ Ã¨ la densitÃ  di elettroni per unitÃ  di volume, anche questo dipendente dal materiale, poi $e$ ed $m$ sono costanti universali.\nPossiamo rispondere a questo assumendo un parametro dipendente dal mezzo, e la regola diventa allora: $$ \\vec{J} = \\sigma \\vec{E} $$ Dove $\\sigma$ Ã¨ il tensore di conducibilitÃ  elettrica Questo si puÃ² riscrivere anche in $$ \\vec{E} = \\rho \\vec{J} $$ Dove $\\rho$ Ã¨ la resistivitÃ , e si ha $\\rho = \\frac{1}{\\sigma}$\nNota: c\u0026rsquo;Ã¨ qualcosa con i semiconduttori o cose drogate, che puoi scomporre la parte di sopra con cariche negative o positive, questa cosa Ã¨ da approfondire sul libro, perchÃ© non la ho capita oggi a lezione Vedi 6.7 mazzoldi c\u0026rsquo;Ã¨ scritto.\nPotenza e densitÃ  elettrica ðŸŸ©\u0026ndash; Chiamiamo $P_{\\tau}$ come la potenza per unitÃ  di volume, che ricordiamo la derivata del lavoro per il tempo. Ricordando che $P = \\frac{dW}{dt} = \\frac{\\vec{F}ds}{dt} = \\vec{F} \\cdot \\vec{v}$\n$$ P_{\\tau} = nP = n\\vec{F}\\cdot \\vec{v}_{d} = ne\\vec{v}_{d} \\cdot \\vec{E} = \\vec{J} \\cdot \\vec{E} $$ Si puÃ² riscrivere con la legge di Ohm, e abbiamo che $$ P_{\\tau} = \\vec{J} \\cdot \\vec{E} = \\sigma E^{2} = \\rho J^{2} $$ Resistenza nei fili ðŸŸ© Consideriamo un cilindro (che sarÃ  il nostro filo) con superficie $S$ verticale e lunghezza $L$, consideriamo due lati $A$ e un lato $B$ Assumiamo di avere una batteria che crea un campo costante: Allora abbiamo: $$ V_{A} - V_{B} = \\int _{A}^{B}\\vec{E} \\, d\\vec{l} = EL $$ Abbiamo che che $$ I = \\int \\vec{J} \\cdot d\\vec{s} = J S \\implies J = \\frac{I}{S} $$ Ora usiamo la relazione fra campo elettrico e densitÃ  di corrente, e otteniamo che\n$$ V_{A} - V_{B} = \\rho J L = \\rho L \\frac{I}{S} = \\frac{\\rho L}{S} I = R I \\implies V = RI $$ Chiamo la resistenza questo valore $$ R = \\frac{\\rho L}{S} $$ PerchÃ© dipende solamente dalla geometria del filo che abbiamo preso. Possiamo definire anche lo stesso concetto per conduttori non lineari (quindi forme a piacere) Per questo si puÃ² generalizzare con $$ R = \\int _{A}^{B} \\frac{\\rho}{\\Sigma} \\, dl $$ Seguendo quanto c\u0026rsquo;Ã¨ in immagine.\nQuando abbiamo ai capi di un conduttore una differenza di un volt, si ottiene una corrente di un ampere, e questo Ã¨ l\u0026rsquo;ampere.\nLegge di Ohm della conduzione elettrica ðŸŸ¨++ Vedi mazzoldi pagina 170. $$ \\sigma = \\frac{ne^{2}\\tau_{+}}{m_{+}} + { \\frac{ne^{2}\\tau_{-}}{m_{-}}} $$ Ãˆ semplicemente un modello vecchio in cui andiamo a distinguere i portatori di carica negativa e positiva con delle masse diverse (e quindi velocitÃ  di deriva diversa). Per il resto resta la stessa derivazione di sopra.\nLa legge in question (legge di Ohm della conduzione elettrica) Ã¨: $$ \\vec{J} = \\sigma \\vec{E} $$ Dove la densitÃ  di corrente Ã¨ relazionata al campo elettrico generato solamente da variabili fisiche riguardanti la composizione del metallo e costanti elementari come massa di portatori di carica.\nIl regime stazionario ðŸŸ© Che ha senso solo in regime stazionario ossia in cui il campo elettrico non varia, ed Ã¨ costante. Un altro modo per dirlo Ã¨ che in ogni punto passa sempre la stessa corrente quindi il flusso del $\\vec{J}$ Ã¨ 0. Ossia $$ \\oint \\vec{J} d\\vec{S} = 0 $$ $$ \\vec{\\nabla} \\cdot \\vec{J} = 0 $$ ResistivitÃ  e temperatura ðŸŸ¨+ Intuitivamente se aumenta l\u0026rsquo;agitazione termica, aumenta la resistivitÃ  perchÃ© c\u0026rsquo;Ã¨ piÃ¹ agitazione, quindi piÃ¹ incontri, si ha una legge del tipo:\n$$ \\rho = \\rho_{20}(1 + \\alpha \\Delta T) $$ Il grafico Ã¨ piatto fino a un certo punto, poi va su in modo lineare. Nei semiconduttori il coefficiente Ã¨ negativo.\nSupponiamo di avere una forma cilindrica a piacere, abbiamo che $$ dP = P_{\\tau} \\Sigma dh \\rho J^{2} \\Sigma dh = \\frac{\\rho i^{2}}{\\Sigma}dh \\implies P = \\int , dP = \\int _{\\tau} \\frac{\\rho i^{2}}{\\Sigma} , dh = I^{2} \\int _{\\tau} \\frac{\\rho}{\\Sigma} , dh = RI^{2} $$ integrando questo riesco a trovare la **potenza dissipata in conduttore** Si puÃ² fare anche in altro modo partendo con la potenza $$ P = \\frac{dW}{dt} = \\frac{Vdq}{dt} = \\frac{Vidt}{dt} = VI $$\nE si puÃ² scrivere anche come $$ P = \\frac{V^{2}}{R} $$ Noi paghiamo in $W = RI^{2}t$ che sono ikilowattora. il riscaldamento si chiama effetto Joule.\nLegge di Ohm generalizzata ðŸŸ© Per ogni ramo dovrei mettere la differenza di potenziale piÃ¹ tutte le forze elettromotrici meno tutte le cadute. Si scrive: $$ V_{A} -V_{B} + \\Sigma_{k}\\varepsilon_{k} = R_{T}i $$ Questa Ã¨ un caso generale della legge di Kirchhoff alle maglie descritta dopo\nPotenza per unitÃ  di volume ðŸŸ© Vedi Mazzoldi pagina 170 $$ P_{\\tau} = nP = \\rho J^{2} = \\sigma E^{2} $$ Questo si puÃ² riscrivere come $$ P_{\\tau} = \\vec{J} \\cdot \\vec{E} $$ L\u0026rsquo;abbiamo ricavato anche in Magnetismo parlando di Poynting, in qui possiamo relazionarlo utilizzando le equazioni di Maxwell anche col campo magnetico.\nResistori in serie e parallelo Una cosa da notare Ã¨ che saldare assieme Ã¨ una altra resistenza non considerata, comunque Ã¨ piccola, quindi approssimiamo che ciÃ² che Ã¨ filo non la valutiamo, Ã¨ trascurabile. Una cosa importante da notare Ã¨ che in questi casi Ã¨ utile utilizzare resistenze di valore simile altrimenti in serie prevarrÃ  la resistenza grossa, in quella parallela la resistenza piccola.\nSerie ðŸŸ© L\u0026rsquo;osservazione principale per spiegare questo Ã¨ il fatto che la corrente che passa Ã¨ la stessa Abbiamo $V_{A} - V_{B} = iR_{1}$ e $V_{B} - V_{C} = iR_{2}$\nQuindi: $$ iR_{eq} = V_{A} - V_{C} = R_{1}i + R_{2}i $$ Anche la potenza Ã¨ semplicemente una cosa lineare!\nParallelo ðŸŸ© In questo caso la differenza di potenziale Ã¨ la stessa dato che $V_{A} - V_{B}$ Ã¨ un valore condiviso, in questo caso la corrente si dividere in modo inversamente proporzionale alla resistenza. Quindi abbiamo\nSia $V = V_{A} - V_{B}$, allora $V = i_{1}R_{1}$ e che $V = i_{2}R_{2}$, quindi\n$$ i = \\frac{V}{R_{1}} + \\frac{V}{R_{2}} \\implies \\frac{1}{R_{eq}} = \\frac{1}{R_{1}} + \\frac{1}{R_{2}} $$ Che Ã¨ esattamente il contrario di quanto abbiamo visto nei Condensatori nel vuoto per quanto riguarda i circuiti. Riguardo la potenza si comporta bene lo stesso, seguendo questa relazione.\nGeneratori di FEM Introduzione ai generatori FEM Def forza elettromotrice ðŸŸ© si basano sul concetto introdotto molto tempo fa: $$ \\varepsilon = \\oint_{\\Sigma} \\vec{E} d\\vec{l} $$ Ed Ã¨ qualcosa che permette di scorrere la corrente per tanto tempo. Un condensatore non sarebbe buono perchÃ© si scarica. Ãˆ presente nel circuito un campo elettrico che non Ã¨ conservativo, diverso rispetto a quello costante che viene sentito all\u0026rsquo;interno del circuito! Dato che applicando le leggi di sopra non c\u0026rsquo;Ã¨ la circuitazione nulla.\nQuesto Ã¨ un caso in non valgono le leggi conservative che abbiamo studiato per un mese e mezzo, trattate in Campo elettrico nella sezione elettromotrice.\nDerivazione forza elettromotrice ðŸŸ©- Esiste una *piccola corrente interna del generatore* Allora il nostro generatore produrrÃ  una forza uguale a $$ W = Pt = i^{2}(R + r) t $$ O in altro modo: $$ W = \\varepsilon q = \\varepsilon i t $$ Questo Ã¨ valido perchÃ© $$ P = \\frac{dU}{dt} = \\frac{dqV}{dt} = iV $$ Quindi abbiamo una relazione sulla potenza spesa da un circuito in relazione alla variazione di differenza di potenziale elettrico. Messi insieme queste due equazioni abbiamo: $$ \\varepsilon = (R + r) i $$ Che notiamo Ã¨ lo stesso valore per la differenza di potenziale elettrico per un circuito semplice\nCampo elettrico elettromotore ðŸŸ¨+ Trattato a pagina 181 del Mazzoldi\nDentro ai poli il campo elettrico Ã¨ opposto rispetto a quello del campo elettrico esterno! Il capo interno Ã¨ il **campo elettrico elettromotore** che non Ã¨ conservativo, siamo fuori dall'elettrostatica. $E^{*}$ Ã¨ solamente il campo interno. Abbiamo allora\n$$ \\varepsilon = \\oint_{\\vec{E}} d\\vec{l} = \\int _{A}^{B} \\vec{E}_{esterno} \\, d\\vec{l} + \\int _{B}^{A} \\vec{E}_{\\text{interno}}+\\vec{E}_{conservativa} \\, d\\vec{l} $$ Il primo Ã¨ elettrostatico, quindi sappiamo che rimane solamente zero (con anche il suo apporto all\u0026rsquo;interno della fem), quindi abbiamo che\n$$ \\varepsilon = \\int _{B}^{A} \\vec{E}_{\\text{interno}} \\, d\\vec{l} $$ Quindi internamente abbiamo un campo $E = E^{*} + E_{el}$ mentre all\u0026rsquo;esterno c\u0026rsquo;Ã¨ solamente il campo statico.\nMisura fem ðŸŸ© Nel caso in cui $i = 0$ Ã¨ molto semplice, basta prendere la differenza di potenziale ai due capi: $V_{A} - V_{B} = \\varepsilon$ e sappiamo che il campo elettrico all\u0026rsquo;interno della fem Ã¨ 0 Ossia $E^{*} + E_{el} = 0$\nA differenza se c\u0026rsquo;Ã¨ corrente avremo dei risultati diversi.\nRamo Definizione ðŸŸ©\u0026ndash; Una parte di filo, parte del circuito fra piÃ¹ nodi, in cui circola una certa corrente.\nPrima legge di Kirchhoff ai nodi ðŸŸ© La somma algebrica delle correnti che confluiscono in un nodo Ã¨ nullo\nLa corrente che entra Ã¨ uguale a quello che esce\n$$ \\Sigma_{k}i_{k} = 0 $$ Ãˆ causa del principio di conservazione della carica, espressa alla fine in modo diverso.\nSeconda legge di Kirchhoff alle maglie ðŸŸ© La somma algebrica delle f.e.m. presenti nei rami della maglia Ã¨ uguale alla somma algebrica dei prodotti $R_{k}i_{k}$\n$$ \\Sigma_{k}R_{k}i_{k} = \\Sigma_{k}\\varepsilon_{k} $$ Questo vale solo se il ramo Ã¨ chiuso, altrimenti bisogna aggiungere in RHS una componente per la differenza di potenziale in quei due punti.\n","permalink":"https://flecart.github.io/notes/leggi-di-ohm/","summary":"Gli argomenti della lezione 31 Ottobre sono circa da pagina 164 fino a 185 del mazzoldi.\nLeggi di Ohm Introduzione microscopica ðŸŸ© Sappiamo che $$ \\vec{J} = -n e \\vec{v}_{d} ne^{2} t \\frac{\\vec{E}}{m} $$ Vedi analisi della velocitÃ  di deriva col modello del 1900 in Corrente Elettrica.\nDove abbiamo utilizzato la definizione di densitÃ  di corrente e la velocitÃ  fra collisioni ed altre Questo Ã¨ una motivazione per considerare la densitÃ  di corrente come se fosse nello stesso verso.","title":"Leggi di Ohm"},{"content":"Ripasso Prox: 3 Ripasso: December 28, 2022 Ultima modifica: December 27, 2022 5:07 PM Primo Abbozzo: December 5, 2022 10:02 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Simplesso e branch n bound Algoritmo del simplesso Ricerca della direzione migliore Ricerca dello step Pseudocodice Slide\nB sono gli indici di partenza, poi questi vengono aggiornati\nIn riga 5 vado a checkare se ho direzioni di crescita possibili, se Ã¨ tutto positivo non ne ho.\nin riga 6, si sceglie il piÃ¹ piccol per evitare loop.\nL\u0026rsquo;idea in generale va in questo modo\nCerco di trovare il duale e confrontarlo con la x attuale Se sono uguali, allora ho trovato lâ€™ottimo ed esco Altrimenti cerco una direzione di crescita che sia anche ammissibile Continuo fino a trovare un vertice, se ho il vertice allora mi muovo lÃ¬ e riapplico, altrimenti Ã¨ illimitata, se non esiste un vertice. Correttezza Slide\n**\nInvarianti (3)\nqueste invarianti vengono mantenute per tutto il corso dell\u0026rsquo;algoritmo\nLa scelta della direzione di crescita\nNOTA: il vettore $u_h$ Ã¨ un versore utilizzato per selezionare la direzione che ci interessa (quindi 0 in tutto e 1 nella parte che ci interessa!).\nLa parte in cui dobbiamo stare attenti nella scelta della direzione di crescitÃ  Ã¨ restare nella zona delle soluzioni ammissibili.\nComplessitÃ  Slide\nFare una analisi in modo rigoroso non riusciamo a farlo, piÃ¹ o meno ora restiamo con l\u0026rsquo;intuizione che al massimo ogni singolo vertice Ã¨ visitato una volta quindi teniamo il bound su questo.\nsi tratterebbe quindi di prendere fra tutti gli $m$ restrizioni possibili, dobbiamo andare a prendere $n$ elementi, con questo il numero di variabili.\nquindi $m \\choose n$.\nNella pratica Ã¨ molto veloce poi ha un runtime nel costo medio polinomiale, ma per fare questa analisi abbiamo bisogno di altri strumenti, molto avanzati.\nBranch and bound non si puÃ² applicare l\u0026rsquo;algoritmo del simplesso per vincoli interi, questo sembra quasi paradossale ma Ã¨ cosÃ¬. il motivo Ã¨ che il simplesso gira sui vertici delle rette, cosa che non puÃ² essere intera, e non abbiamo un modo banale per trovare la parte intera piÃ¹ vicina!.\nIntuizione Slide\nProviamo a rilassare il problema chiedendo che anche i vincoli non interi siano buoni. Spesso questa cosa non Ã¨ buona, quindi utilizziamo una partition per andare a ritrovare una cosa intera.\nIn pratica, cerco la soluzione non intera utilizzando Simplesso o altri algoritmi che mi diano dei risultati boni. Poi se Ã¨ intera ritorno, altrimenti aggiungo due vincoli interi, creandomi due sottoproblemi, e me li vado ad esplorare in questo modoâ€¦\nPseudocodice Slide\nSi basa sullâ€™applicare in modo continuo un algoritmo per la risoluzione della programmazione lineare non intera, e cercare con una sorta di divide e conquer una soluzione che sia intera.\nCorrettezza Slide\nComplessitÃ  Slide\nEsponenziale, bisogna andare ad utilizzare il simplesso come subroutine molte volte, anche se magari si puÃ² velocizzare di molto come subroutine, resta comunque almeno della complessitÃ  del simplesso.\n","permalink":"https://flecart.github.io/notes/simplesso-e-bb/","summary":"Ripasso Prox: 3 Ripasso: December 28, 2022 Ultima modifica: December 27, 2022 5:07 PM Primo Abbozzo: December 5, 2022 10:02 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Simplesso e branch n bound Algoritmo del simplesso Ricerca della direzione migliore Ricerca dello step Pseudocodice Slide\nB sono gli indici di partenza, poi questi vengono aggiornati\nIn riga 5 vado a checkare se ho direzioni di crescita possibili, se Ã¨ tutto positivo non ne ho.","title":"Simplesso e B\u0026B"},{"content":"Ultima modifica: February 24, 2023 2:04 PM Primo Abbozzo: February 24, 2023 1:33 PM Studi Personali: No\nUn pÃ² di storia Guerre dei browser Prima guerra ~1995\nFra netscape, una forma di rete (?) che poi viene ripresa da firefox da Mozilla, dopo che Ã¨ stato mandato in bancarotta da Microsoft (che ha ancora con IE una grandissima fetta del mercato in questo primo periodo).\nSecondo periodo di guerra ~2010\nQuando arriva chrome, che vuole creare un browser che risolva tutti i problemi per creare integrazioni sui browser di altre aziende), mentre IE ha perso interesse per nuove features, che in questo periodo sono capi del proprio mercato.\nSu questa logica, partendo dal 2009, Chrome acquista una fetta del mercato grossa nel 2012. M$ prova a controbattere con Edge nel 2015, ma ormai Ã¨ un pÃ² tardi (ora rientra con bing tipo).\nIn questa parte viene anche introdotto un ciclo di bug-fix veloce, si chiama rapid release\nW3C and HTML Cose strane su brevettiâ€¦ Non volevano permettere modifiche dal loro standard HTML Ã¨ un living standard, non esiste piÃ¹ un modo per definire se fosse coerente allo standard o meno.\nLock-in technologico e sviluppatori come utenti Vogliono creare un ambiente di sviluppo facile, e cercare di attirare alcuni sviluppatori, in modo che questi siano bloccati sui loro framework! (infatti costa imparare un nuovo framework, principalmente nuovo tempo, anche chiamao sunk cost).\n","permalink":"https://flecart.github.io/notes/storia-del-web/","summary":"Ultima modifica: February 24, 2023 2:04 PM Primo Abbozzo: February 24, 2023 1:33 PM Studi Personali: No\nUn pÃ² di storia Guerre dei browser Prima guerra ~1995\nFra netscape, una forma di rete (?) che poi viene ripresa da firefox da Mozilla, dopo che Ã¨ stato mandato in bancarotta da Microsoft (che ha ancora con IE una grandissima fetta del mercato in questo primo periodo).\nSecondo periodo di guerra ~2010","title":"Storia del web"},{"content":"Public Key Encryption We now define a formally what is a public key encryption\nFormal definition of Public Key Encryption We define a 3-tuple formed as follows: $(G, E, D)$ where\n$G$ is the generator for the private and public keys, from now on identified as $(pk, sk)$ (public key and secret key) $E$ the encryption algorithm, that takes the $pk$ and the message in input $D$ the decryption algorithm, that takes the $sk$ and the cyphertext in input. Now is this definition useful? i don\u0026rsquo;t think so! We can\u0026rsquo;t create theorems for it, too general I suppose. Is it clear? yes! I think this is the usefulness of maths in many occasions, it delivers some complex information in a concise and understandable manner.\nSome observations about Public Key Encryption Semantic security to Eavesdropping This is the same as explained in Advantage security explained in a previous section. We defined the advantage as the ability of the attacker to distinguish the original message. This is still exactly the same, see that section. (the only difference is that here we use public key encryption) Resistance against Many Time Pads We know that in the symmetric context in Block Ciphers and OTP and Stream Ciphers, it is often not secure to use the symmetric key to many times. (This is clearly true when we are talking about the OTP cipher).\nBut in the context of Asymmetric keys this notion is not true as the key is public, this key can be used as many times as the attacker wants. So he can reuse the key, while the cipher should still remain secure!\nTrapdoor functions Definition of Trapdoor functions This is a triple $G, F, F^{-1}$ very similar to the previous one (indeed it\u0026rsquo;s kinda the same definition) The only difference is that $F^{-1}$ is the inverse.\nSecure Trapdoor Functions ðŸŸ¨- NOTE: direct use of $F$ and $F^{-1}$ to encrypt and decrypt using the created keys is not secure.\nA trapdoor is secure if it\u0026rsquo;s difficult to invert without the knowledge of $sk$. See image Creating a PKE from Trapdoors ðŸŸ¨\u0026ndash; One Way Hash Algorithms These are different from Hash tables which is a datastructure!\nWe can see that One-Way hashes are a trapdors with $pk = sk$. Usually it is a function that takes a input of arbitrary length and outputs a limited string with some important properties.\nProperties of One Way Hash Algorithms ðŸŸ©- Easy to Evaluate: The hashing algorithm should be fast Hard to Reverse: There is no feasible algorithm to \u0026ldquo;reverse\u0026rdquo; a hash value, That is, given any hash value $h$, it is computationally infeasible to find any document $m$ such that $H(m) = h$. Hard to find Collisions: There is no feasible algorithm to find two or more input documents which are hashed into the same condensed output, That is, it is computationally infeasible to find any two documents $m_{2}, m_{2}$ such that $H(m_{1})= H(m_{2})$. Although, theoretical requirements say there are many many collisions. But the difficult thing is tampering, that is add some strings, make some modifications of the original messages such that that hash matches with others. A small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value RSA Cryptosystem Definition of the trapdoor function We define $F: \\mathbb{Z}^{*}_{\\mathbb{N}} \\to \\mathbb{Z}^{*}_{\\mathbb{N}}$ as $RSA(x) = x^{e}$ where $e$ is the public key generated by the key generation function and $N = pq$ is the private key, where $p, q$ are big primes.\nThen using Euler\u0026rsquo;s theorem we know how to compute $d$ such that $x^{ed} =x \\mod N$ where $d$ is the inverse modulo that, this is how we decrypt. How do we compute $d$? We use euler\u0026rsquo;s theorem, and find this $e\\cdot d = 1 \\mod \\varphi(N)$. and $e$ should be invertible with it is coprime with $N$ (true by construction).\nSecurity Analysis of RSA NOTE: normal RSA as defined above is not secure.\nSimple semantic security attack on RSA I can get back to the original message with a small effort. The percentage of success is high enough not to be negligible.\n#### Advantage notation for RSA We want the possibility to compute the $e$ root modulo $N$ to be small, and using the notion of advantage developed in [OTP and Stream Ciphers#Security with advantage](/notes/otp-and-stream-ciphers#security-with-advantage) we write $$ Pr\\left[ A(N, e, y) = y ^{1/e} \\right] \u003c \\varepsilon $$ Where $\\varepsilon$ is very small, **negligible** so to say, and $A$ is the $F$ trapdoor function used for RSA. Wiener\u0026rsquo;s attack (non fatto) This section is not useful for the exam, just for personal knowledge! If the private keys have certain properties, there exists some attacks, one example is the Wiener\u0026rsquo;s attack Low public exponent attack ðŸŸ© Usually minimum that is used is 3. If 2 then the inverse is not guaranteed because $mcd(2, (p - 1) ( q - 1)) \\neq 1$ .\nThis is a stupid attack. Then the exponent is small enough, and it is not able to wrap the module, then the root is quite easy to achieve. This is why the recommended value is big, usually = $2^{16} + 1 = 65537$.\nUsually this is used to speed up encryption, it easier to compute. Other variants, like Elgamal have almost same time to encrypt and decrypt.\nComparison with symmetric keys AES key size RSA modulus size 80 bit 1024 bits 128 bits 3072 bits 256 bits 15360 bits We observe that RSA needs a lot more bits to ensure the same security! Side channel attacks these attacks do not directly attack the cipher, but the infrastructure or computing that it uses.\nTiming attack Can leak $d$ secret key by tracking the compute time. (Kocher 1997)\nPower attack Can leak $d$ by tracking power usage. (Kocher 1999)\nFaults attack Errors can leak $d$ somehow (don\u0026rsquo;t know!) (BDL 1997). In questa fase viene leakato il valore di $p$ che permette di ricostruire la chiave privata.\nKey generation ### Variations #### Elgamal Find $g$ and $p$ such that $g$ is primitive root modulo $p$. Some strange properties here. This means that $\\forall a, \\exists k : g^{k} = a \\mod p$. This is inspired from the [Key Exchange protocols#Diffie-Hellman Protocol](/notes/key-exchange-protocols#diffie-hellman-protocol). Then the first person chooses $a \\in \\left[ 0, p - 2 \\right]$ randomly and calculates $A = g^{a} \\mod p$ and the tuple $(p , g, A)$ is then considered as the public key. When someone wants to send a message $m$, he/she does this: Chooses a $b$ in exact manner as before. Computes $c = A^{b}m \\mod p$ and sends this c. The receiver computes the inverse for this exponent, and then inverts $g^{b} \\mod p$ to calculate the original message $m$. Notes on security -\u0026gt; Discrete log problem. Efficiency -\u0026gt; No, ciphertext needs that public key to be sent, which is usually long and expensive to calculate compared to AES.\nRabin cryptosystem we create $p,q$ such that their modulus $4$ is 3, probably for some nice properties I don\u0026rsquo;t know of\u0026hellip; The advantage is that his security is prooved. Calculate $n = pq$ and this is the public key. When somebody wants to communicate, he just calculates\n$$ c = m^{2} \\mod n $$ And sends this, probably with this setting the properties of $p, q$ make that invertible, but not sure why. If you are curious try to understand why is this valid.\nDigital signatures The main idea is to cipher with the private key, so that it can be verifiable using the public. It was cited in Sicurezza delle reti times before. To overcome the burden to encrypt the whole text, usually only an hash is encrypted.\nAdvantages of Digital signatures Unforgeable Un-deniable by the signatory (if you have signed it, it was you!) Universally verifiable (everybody can verify it) Every doc\u0026rsquo;s signature is different. ","permalink":"https://flecart.github.io/notes/asymmetric-cryptography/","summary":"Public Key Encryption We now define a formally what is a public key encryption\nFormal definition of Public Key Encryption We define a 3-tuple formed as follows: $(G, E, D)$ where\n$G$ is the generator for the private and public keys, from now on identified as $(pk, sk)$ (public key and secret key) $E$ the encryption algorithm, that takes the $pk$ and the message in input $D$ the decryption algorithm, that takes the $sk$ and the cyphertext in input.","title":"Asymmetric Cryptography"},{"content":"Basi di dati Cosa Ã¨ un database? (2) ðŸŸ© Si potrebbe intendere come un insieme di dati strutturato, utili per certi obiettivi di enterprise, aziende pubbliche o simili (uno delle necessitÃ  che la rivoluzione informatica ha piÃ¹ contribuito diciamo.)\nUn altro significato piÃ¹ importante Ã¨\nUn insieme di dati gestito da un Database Management System\nTristemente con questa definizione anche excel Ã¨ un DBMS\u0026hellip;\nSolitamente sono utilizzati per gestire grandi quantitÃ  di dati.\nIl sistema informativo ðŸŸ© Componente di una istituzione\nSi potrebbe dire che sia una base utile alle organizzazioni per gestire l\u0026rsquo;informazione, questi sistemi erano giÃ  presenti molto prima rispetto alla creazione dei sistemi dell\u0026rsquo;informazione moderni, per esempio registri e tavole venivano utilizzate in questo senso, ossia come sistemi per registrare alcuni strumenti utili per il nostro enterprise. Quindi storicamente c\u0026rsquo;Ã¨ molta necessitÃ , Ã¨ solamente con la rivoluzione storica che abbiamo nuove cose.\nNecessitÃ  dell\u0026rsquo;informazione ðŸŸ¨++ Ci sono alcuni aspetti che possiamo dire molto comuni quando mettiamo mano ai dati e sono tipo:\nCollezionare i dati Filtrare i dati e memorizzarli elaborare i dati Restituire e visualizzare i dati Database Management System Caratteristiche generali dei DBMS (5) ðŸŸ© Le slides affermano che i dati in questione devono essere:\nGrandi dimensioni (righe) Persistenti Condivisi efficienti efficaci Io aggiungerei anche strutturati perchÃ© se sono dati non strutturati Ã¨ difficile che vengano messi in un DBMS. Comunque commentiamo ora pezzo per pezzo il motivo per cui abbiamo bisogno di queste caratteristiche per i DBMS:\nGrandi dimensioni perchÃ© vogliamo che sia efficiente anche su questi (soprattutto su questi, quando tengono dati di tante cose rimanendo comunque organizzati diciamo) Terabyte e terabyte di data secondo le slides (500 TB per dati scientifici :O) Persistenti perchÃ© non avremmo bisogno di un database se tutto rimanesse in RAM\u0026hellip; I dati sono piÃ¹ longevi dei computer che li ospitano diciamo. CosÃ¬ abbiamo un unico punto di sicurezza in cui molte persone possono affidarsi per avere una fonte di veritÃ  diciamo (questo forse ne parlava in the manga introduction to databases) Efficienti si parla da solo, dato che vogliamo che sia effettivo a prendere i dati non vorremmo aspettare tanto Efficace perchÃ© deve fare il suo lavoro di renderci la vita piÃ¹ facile nella gestione dei documenti e dei dati :) Altro Comparazione con File System ðŸŸ©\u0026ndash; Sembra che anche i file-system siano in grado di svolgere il lavoro di DBMS, infatti potremmo vedere il DBMS come un file-system allargato, con piÃ¹ funzionalitÃ . Infatti possiamo anche in questo caso tenere un file-system distribuito, e affidarci ad esso per\ngestire una grandissima mole di dati (perdiamo sulle garanzie di integritÃ ), gestione dell\u0026rsquo;accesso (e quindi di privacy), pone interfaccia per accedere velocemente al supporto fisico sottostante. Diciamo che fa bene il suo lavoro. (efficace) In un certo senso si puÃ² paragonare a tenere i dati su excel, funziona, perÃ² non Ã¨ il massimo, non si hanno garanzie che si vorrebbero avere, i check automatizzati diciamo.\nCol database abbiamo\ngaranzie in piÃ¹ su uniformitÃ  e relazione dei dati con un Data Model velocitÃ  di accesso a query classiche Non limitazione ad aprire e chiudere file (prende o l\u0026rsquo;intero file o niente col file system) Architettura ANSI/SPARC (3) ðŸŸ© Schema logico descrive come dovrebbero essere i dati ossia la struttura logica dei dati Schema interno come sono rappresentati i dati, potremmo dire l\u0026rsquo;implementazione del livello logico dei dati. Schema esterno che a volte Ã¨ chiamata anche view, ossia come gli utenti hanno bisogno di vedere i dati La cosa interessante di questa parte, Ã¨ che vorremmo che i dati siano indipendenti (sia il fisico dal logico, sia il logico dall\u0026rsquo;esterno) rispetto a come sono rappresentati, una idea molto importante introdotta per la prima volta da (Codd 1970).\nCredo anche sia la stessa idea, che sta alla base del processo di astrazioni comunissimo in informatica Ã¨ l\u0026rsquo;idea di interfaccia, un qualcosa che espone solamente la parte logica di quale sarÃ  l\u0026rsquo;effetto dell\u0026rsquo;operazione, ma ne nascone le operazioni effettive, che chiamiamo interne. Per i database forse questa cosa era nuova.\nTipologie di modelli logici (5) ðŸŸ¨+ Nel tempo sono stati creati molti modelli possibili dello strato logico del database Una lista di modelli presenti Ã¨\nGerarchici Grafo (network based) relazionali Object Oriented XML-based Quello studiato in questo corso Ã¨ il modello relazionale di database management\nProblemi classici (2) ðŸŸ¨\u0026ndash; Ridondanza e coerenza per questo Sync dei valori che possono essere presenti in macchine anche molto distanti Availability Ãˆ un grande problema se un database va giÃ¹\u0026hellip; Privacy e gestione dei permessi, perchÃ© dato che sono shared, non vogliamo perÃ² che uno possa accedere a dati di altri. TODO Caratteristiche dei dati (3) vogliamo che i dati all\u0026rsquo;interno dei DBMS soddisfino certe desiderata al fine di garantire il buon servizio:\nPrivacy Reliability Availability E parte di queste desiderata sono le stesse che abbiamo anche richiesto all\u0026rsquo;interno di Sicurezza OS quando abbiamo parlato degli attacchi che era possibile fare ad un sistema informativo. Per gestire la reliability ossia la tolleranza a fallimenti hardware e software, e la possibilitÃ  di garantire anche la ridondanza si utilizzano le transazioni\nTransactions (3) (non fare) Questa parte Ã¨ trattata leggermente meglio quando andiamo a parlare di SQL transactions in Structured Query Language Anche in Advanced SQL\nAtomiche Concorrenti Permanenti Le facciamo per benino in The Database Management System\nPros and cons Pros (5) ðŸŸ¨+ Ãˆ necessario, molto piÃ¹ efficiente nel caso quella stessa informazione venga utilizzata anche da dipartimenti diversi Ãˆ chiara la comunicazione e la struttura, che Ã¨ sempre una fonte di veritÃ  vabbÃ© ovvio Questo Ã¨ molto importante, ci sono stati un sacco di danni che ci sono stati a causa di inconsistenza, come nei file di excel Questo Ã¨ ancora una delle radici presenti nell\u0026rsquo;informatica, l\u0026rsquo;indipendenza del software dall\u0026rsquo;implementazione concreta dei dati, oppure dalla rappresentazione hardware. Cons (2) ðŸŸ© Io aggiungerei anche il livello di astrazione (quindi magari tempo di implementazione delle cose) in piÃ¹, che poi si riguadagna indietro con la facilitÃ  di gestione dell\u0026rsquo;infrastruttura\nC\u0026rsquo;Ã¨ un grande overhead per mettere su un DBMS questo Ã¨ ovvio come con. Basi di dati attive Finora i database \u0026ldquo;passivi\u0026rdquo; non fanno niente finchÃ© non c\u0026rsquo;Ã¨ interazione con query o richiesta.\nIl comportamento reattivo ðŸŸ© In sql ci sono dei checks a reference di integritÃ , che vengono attivati su update o deletions. La capacitÃ  di reagire ad eventi Ã¨ importante.\nEvent-Condition-Action (ECA) ðŸŸ© Questo Ã¨ il costrutto principale dei database attivi, devono essere in grado di reagire ad eventi in modo reattivo.\nQuindi possiamo dire che il database Ã¨ attivo quando esistono dei triggers, regole che vengono eseguite in un certo momento.\nOracle Ã¨ stato uno dei primi che si Ã¨ accorto di questa necessitÃ  (infatti Ã¨ anche l\u0026rsquo;azienda che ha fatto questo, e l\u0026rsquo;ha chiamato stored procedures) PerÃ² aspetti negativi sono:\nLinguaggio procedurale (impendance mismatch con SQL) Non standarizzato Trigger, granularitÃ  e modalitÃ  ðŸŸ© Esiste un comando SQL, nella DDL, che mi permette di definire in modo esplicito i trigger.\nGranularitÃ :\nTupla (attivazione per ogni tupla) Operazione, a singola operazione ModalitÃ :\nImmediato Dilazionato. Questi si possono rappresentare anche con semantica differente. References [1] Codd â€œA Relational Model of Data for Large Shared Data Banksâ€ Communications of the ACM Vol. 13(6), pp. 377\u0026ndash;387 1970\n","permalink":"https://flecart.github.io/notes/introduction-to-data-bases/","summary":"Basi di dati Cosa Ã¨ un database? (2) ðŸŸ© Si potrebbe intendere come un insieme di dati strutturato, utili per certi obiettivi di enterprise, aziende pubbliche o simili (uno delle necessitÃ  che la rivoluzione informatica ha piÃ¹ contribuito diciamo.)\nUn altro significato piÃ¹ importante Ã¨\nUn insieme di dati gestito da un Database Management System\nTristemente con questa definizione anche excel Ã¨ un DBMS\u0026hellip;\nSolitamente sono utilizzati per gestire grandi quantitÃ  di dati.","title":"Introduction to data-bases"},{"content":"Dato che il software sta diventando sempre piÃ¹ diffuso, diventa sempre piÃ¹ importante andare a definire delle metriche che possano garantirne la qualitÃ , ossia la non frequenza di errori o bug che possono in qualche modo limitarne la qualitÃ .\nError, Fault and Failure Secondo la definizione esatta data da IEEE, questi tre termini hanno un significato ben specifico, molto diverso.\nError, sono comportamenti non previsti da un comportamento dell\u0026rsquo;utente, oppure il programmatore capisce male le specifiche. Fault sono i bugs, degli errori nel codice che creano un comportamento non previsto Failure, sono comportamenti non previsti da specifiche, che crea un guasto e non permette il funzionamento QualitÃ  del software Rating and Ranking Il rating Ã¨ l\u0026rsquo;assegnazione di un punteggio assoluto di qualitÃ  riguardo al prodotto.\nRanking Ã¨ comparazione fra un prodotto rispetto all\u0026rsquo;altro per\nCondizioni necessarie (4) QualitÃ  interna ed esterna Ci sono quei principi utili possono essere categorizzati in attributi\noperativi di manutenzione (modificabilitÃ ) adattabilitÃ , ossia se il software puÃ² essere usato in ambienti diversi. Goal Question Metric Principi di qualitÃ  (3) Gli obiettivi del prodotto devono essere chiare Metriche di qualitÃ  per sapere cosa esattamente andare a misurare Le domande per vedere se un certo obiettivo Ã¨ stato raggiunto, da quanto ho capito Ã¨ un check midpoint per avere feedback, nello stesso modo per cui fatto in Modelli AGILE Tre livelli di analisi Obiettivi Domande Metriche per valutare domande Esempio: Verifica e validazione Verifica = quanto viene implementato bene la specifica, che Ã¨ anche ciÃ² che deve essere testato in automatico o manualmente. a seconda del formato puÃ² essere ispezione (manuale) o testing.\nValidazione = accettazione da parte del cliente.\nAspetti da testare Una idea molto presente in questo Ã¨ la copertura ossia il programma dovrebbe funzionare a seconda del branch, dei moduli, in questo senso dovrebbe esserci una copertura piÃ¹ ampia possibile.\nBlack and white box testing Il primo quando non si ha accesso al codice sorgente, ma si testa solametne la specifica come puÃ² essere una user story\nWhite box quando abbiamo visibilitÃ  sul sorgente (ad esempio match diretto sul codice di ritorno, o fare i mocks).\nComplessitÃ  ciclomatica di McCabe Cerca di calcolare quanto sia affidabile un software, ed Ã¨ fatto sul diagramma di flusso. cc si calcola come $$ cc(G) = e - n + 2 \\cdot G $$ G sono sottografi sconnessi. $e$ sono gli archi, $n$ sono i nodi. cosÃ¬ viene definito un valore di complessitÃ  ciclomatico, e ci dice il numero di test che bisogna avere per essere abbastanza sicuri.\nE il diagramma di fllusso Ã¨ calcolabile, quindi si puÃ² sempre fare, come rule of thumb se la complessitÃ  Ã¨ alta, il rischio Ã¨ alto.\nManutenzione del software Tipologie di correzione (3) Perfettiva Per migliorare, ci sono nuove funzionalitÃ  tipo 1/2 sono questi Correttiva, circa 1/4 dei cambi. Adattiva Per ambiente che cambia Esiste anche uno standard IEEE per gestire questo cambiamento.\nI costi nella manutenzione Personale instabile Progettisti non responsabili (bisogna rendere i progettisti) Inesperienza dei progettisti Il software vecchio. ","permalink":"https://flecart.github.io/notes/la-qualit%C3%A0-del-software/","summary":"Dato che il software sta diventando sempre piÃ¹ diffuso, diventa sempre piÃ¹ importante andare a definire delle metriche che possano garantirne la qualitÃ , ossia la non frequenza di errori o bug che possono in qualche modo limitarne la qualitÃ .\nError, Fault and Failure Secondo la definizione esatta data da IEEE, questi tre termini hanno un significato ben specifico, molto diverso.\nError, sono comportamenti non previsti da un comportamento dell\u0026rsquo;utente, oppure il programmatore capisce male le specifiche.","title":"La qualitÃ  del software"},{"content":"Ripasso Prox: 70 Ripasso: May 26, 2023 Ultima modifica: June 9, 2023 3:22 PM Primo Abbozzo: November 29, 2022 12:35 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso LR(k) e YACC LR(k) Grammatiche LR(k) ðŸŸ© Anche in questo caso proviamo a generalizzare il concetto dei pirmi k caratteri, in modo da generalizzare in qualche senso il concetto di LR(k), quindi andiamo a modificare la closure considerando ora first k\nPer ricordarti come si calcolava first k, andare a guardare Top-down Parser\nil problema che poi diventa pratico riguardo questo Ã¨ l\u0026rsquo;impossibilitÃ  di gestire stringhe lunghezza k che sono una assurditÃ  (esponenziale per la lunghezza)\nGrammatiche SLR(k) ðŸŸ© Uguale a SLR(k), ma possiamo andare a fare il reduce solamente quando il nostro terminale di interesse appartiene al follow k!\nGrammatiche LALR(k)ðŸŸ¨+ Questo Ã¨ esattamente identico a LALR, si va a considerare il concetto di nucleo, e questo concetto di nucleo Ã¨ uguale al precedente speigato in Bottom-up Parser -LR(1)\nClassificazione dei linguaggi Gerarchia generale ðŸŸ¨ Da qui si puÃ² creare una semplicissima gerarchia dei parser, che si possono riassumere in\n$$ \\forall k, SLR(k) \\subset LALR(k) \\subset LR(k) $$ E oltre questo inclusioni per ogni k, rispetto al k minore e la non inclusione. Questo riassume il tutto. Con qualche intersezione con LL k\nNote sulla classificazione (!!) ðŸŸ¨ Ãˆ molto piÃ¹ facile classificare un linguaggio invece che grammatica potrei avere delle grammatiche che non siano LL(k), mentre il linguaggio che genera lo Ã¨\nEsiste grammatica non ambigua non deterministica!\nQuesto Ã¨ il punto motivatore per cui andiamo a concentrarci sui linguaggi invece che sulle grammatiche, ci possono essere delle miriadi di grammatiche per uno stesso linguaggio e il fatto che possano anche non essere deterministiche non ci aiuta molto in questa analisi:\n$$ S \\to aSa | bSb|\\varepsilon $$ Si puÃ² vedere subito il conflitto shift reduce al primo passo, persino con un parser LR(1).\nTeoremi sulla classificazione dei linguaggi\nImportante l\u0026rsquo;equivalenza del fatto che $LL(k) \\equiv SLR(1)$, qualunque sia k! posso andare a costruire una grammatica equivalente che sia in grado di fare ciÃ². (credo valga anche LR(k) = SLR(1), dato che Ã¨ un sse per entrambi riguardo linguaggi liberi deterministici).\nUna altra nota interessante Ã¨ che tutte le gramamtiche che sono SLR(1) oppure LR(k) allora sono non-ambigue e deterministiche. la cosa importante di queste proposizione Ã¨ che ambiguitÃ  â†’ impossibile LR o LL!\nGli SLR(1) ci piacciono in modo particolare ðŸ™‚, hanno una grandissima capacitÃ  espressiva ma Ã¨ probabile che la grammatica che Ã¨ riconosciuta da questo sia estremamente complessa e difficile da modellizzare diciamo, per questo motivo conviene utilizzare grammatiche LR k con k alto, se mi crea un parser piÃ¹ carino.\nProprietÃ  di (non) chiusura (3)ðŸŸ©- Le osservazioni di maggior rilievo riguardo questo sono\nUnione di linguaggi LL 1 puÃ² non essere LL 1 Union edi linguaggi LR 0 puÃ² non essere LR 0 Concatenazione di LL 1 puÃ² non essere LL 1 Quindi un sacco di nozioni negative!\nYACC In modo simile a quanto presentato per Lex in Lex/Flex e Yacc. Yacc Ã¨ l\u0026rsquo;equivalente utilizzato per i Parser.\nCollaborazione con LEX Solitamente YACC non Ã¨ impiegato da solo, ma in stretta collaborazione col LEX.\nInfatti esistono delle funzioni yylex() e la variabile yylval che sono spesso utilizzate per gestire il tempo di lettura diciamo.\nyylex - chiedi il prossimo token yylval - puntatore nella tabella dei simboli dellâ€™ultimo lessema.\nDescrizione input e output ðŸŸ¨ Prende un programma in questo linguaggio yacc, in cui Ã¨ presente la descrizione della grammatica libera che si vuole andare a riconoscere, e dÃ  in output un programma che sia in grado di riconoscere quella grammatica\nQuesto programma puÃ² essere compilato, e poi sarÃ  in grado di ricevere in input alcuni token e crearci un albero di derivazione.\n(ma alla fine dipende lâ€™uso che vogliamo andare a farci:\nSe vogliamo creare un interprete, possiamo dare la valutazione dellâ€™albero Se vogliamo andare a creare un compilatore potrebbe essere codice intermedio oppure lâ€™albero di derivazione. (questa roba Ã¨ descritta in azione semantica del matching.) In realtÃ \nCome abbiamo detto nel documento precedente, yacc lavora in strettissimo contatto con il lexer, al quale chiede di volta in volta altri token ogni volta in cui ne ha bisogno, quindi chiede sul momento!\nCondivisione di variabili!\nStruttura di un file Yacc (4) https://www.ibm.com/docs/en/aix/7.1?topic=information-example-program-lex-yacc-programs\nPrologo (defines) Definizioni (token o operatori) Regole con azioni semantiche Funzioni ausiliarie (utilizzate in azioni semantiche spesso). Esempio di un file YACC Sintassi regole e funzioni ausiliarie Le regole sono proprio nella forma\nnonterm: corpo1 â†’ azione semantica\ncorpo2 â†’ azion sem 2â€¦ etcâ€¦ molto simile a quanto faceva lex.\nRiguardo alle funzioni ausiliarie di solito Ã¨ compilato insieme a lex, e linkati assieme, altrimenti se non câ€™Ã¨ viene generato in automatico un yylex().\nAzione semantica Ãˆ la parte di codice eseguito una volta che si Ã¨ trovato un altro pezzo dellâ€™albero (ricorda che vanno in contemmporanea).\nQuesto potrebbe dare un valore semantico diverso a seconda del metodo che stiamo andando ad utilizzare diciamo.\nAlbero sintattico Valutazione Codice intermedio. Default risoluzione conflitti Slide Come prima regola per la risoluzione dei conflitti si considera lâ€™associativitÃ  degli operatori, poi lâ€™ordine di dichiarazione (precedenza) se non sbaglio lâ€™operatore dichiarato piÃ¹ tardi ha la precedenza su quelli dichiarati prima.\nSe ci sono ancora delle ambiguitÃ  dopo queste dichiarazioni allora si va alla risoluzione di default.\nSe ci sono alcune forme di conflitti shift/reduce o reduce/reduce vengono risolti in questo modo:\nShift-reduce viene sempre risolto in favore alla shift\nReduce reduce viene risolto col reduce listato prima (quindi una forma di precedenza).\n","permalink":"https://flecart.github.io/notes/lrk-e-yacc/","summary":"Ripasso Prox: 70 Ripasso: May 26, 2023 Ultima modifica: June 9, 2023 3:22 PM Primo Abbozzo: November 29, 2022 12:35 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso LR(k) e YACC LR(k) Grammatiche LR(k) ðŸŸ© Anche in questo caso proviamo a generalizzare il concetto dei pirmi k caratteri, in modo da generalizzare in qualche senso il concetto di LR(k), quindi andiamo a modificare la closure considerando ora first k","title":"LR(k) e YACC"},{"content":"Ripasso Prox: 13 Ripasso: December 23, 2022 Ultima modifica: January 3, 2023 11:12 AM Primo Abbozzo: November 3, 2022 11:53 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Metodi di discesa Intro Generali sui metodi di discesa Vogliamo creare algoritmi che riescano a trovare i punti di minimo delle funzioni non vincolate.\nIn generale si trova un punto stazionario (condizioni necessarie) ma non Ã¨ garantito lo stato ottimo.\nCondizioni di arresto classiche (2) ðŸŸ©- Slide\nDifferenza fra due iterati Ã¨ minore a una tolleranza, in modo simile a quanto fatto in Equazioni non lineari sulla tolleranza per il metodo delle approssimazioni I criteri di arresto sono i sempre classici\nNumero di iterazioni superate Tolleranza sullâ€™obiettivo ossia gradiente = 0 per il punto di stazionarietÃ . Idea principale dei metodi di discesa ðŸŸ© Slide\nTrovare una direzione di discesa Aggiornare x in modo da andare in quella direzione di un passo fissato. direzione di ricerca e lunghezza del passo sono due nuovi termini di interesse per questa roba Ottimizzazione non vincolata (non studiare) In pratica questa parte Ã¨ un ripasso molto veloce di 2 mesi di analisi 2â€¦ E poi ovviamente fatti molto male!\nGuarda Massimi minimi multi-variabile. In pratica ottimizzazione Ã¨ trovare il massimo o il minimo di una funzioneâ€¦\nDiscesa Condizione per direzione di discesaðŸŸ©- Slide\nSi puÃ² osservare che io stia proprio scendendo, in questo senso vado a cercare qualcosa che sia uguale a 0.\nInterpretazione geometrica della condizione di discesa\nSe forma angolo ottuso con il gradiente Ã¨ OK!\nE guardare le curve di livello Ã¨ una cosa molto buona.\nAlgoritmo generale di GDðŸŸ© Slide\nSi puÃ² notare che la scelta del passo Ã¨ la parte critica di questo algoritmo. Scegliere un alpha fisso non garantisce la convergenza, devono essere soddisfatte certe proprietÃ .\nRicerca dellâ€™alpha Scelta della alpha (linea esatta)ðŸŸ©- Definizione di funzione dipendente da alpha\nVado a scegliere lâ€™alpha in modo tale che assuma il valore piÃ¹ piccolo possibile, significa minimizzare questa funzione di alpha.\nSolitamente si utilizza quando f Ã¨ in forma quadratica, per resto spesso non si utilizza (perchÃ© la f si calcola in modo molto veloce, di solito Ã¨ molto lento. dimostrato converge! punto minimo o massimo boh.\nlinea inesatta ðŸŸ¨+ Slide\nQuindi inesatta perchÃ© devo trovare l\u0026rsquo;insieme di alpha buoni, non quell preciso\nCondizioni di wolfe ðŸŸ¨- Slide\nMinore, inoltre minore di qualcosina..\nArmijo e backtrackingðŸŸ¨ Intro a backtracking\nbacktracking\nLâ€™algoritmo\nNOTA: bisgona anche mettere una condizione di maxit, se si esce per quella allora Ã¨ perchÃ© non si puÃ² trovare! (molto probabilmente)\nCondizioni di ottimalitÃ  Definizione ðŸŸ© Quando sono in un minimo locale o globale per la nostra funzione.\nAndiamo a definire una condizione di ottimalitÃ  di primo secondo oordine perchÃ© andiamo a guardare le derivata\nCondizione necessaria e sufficiente al primo e secondo ordine ðŸŸ© Primo ordine\nQuesto non Ã¨ altro che il teorema di fermat del secondo ordine che puoi trovare qui 11.1.2 Condizione di stazionarietÃ  (fermat) !!!\nSlide\nNon esiste una condizione sufficiente al primo ordine\nSecondo ordine\nQuesto Ã¨ il modo con cui trovavamo i punti di minimo, Ã¨ anche una condizione sufficiente se Ã¨ definita positiva\nOttimalitÃ  per funzioni convesse ! ðŸŸ© Funzioni quadratiche Questo tipo di funzioni ci piace molto perchÃ© sono convesse e le funzioni convesse sono facili da analizzare per sta robba.\nQuadratiche convesse ðŸŸ¥ Slide\nCon $Q$ matrice simmetrica\nCon $q$ convessa se la matrice Ã¨ semidefinita positiva, e convessa stretta se Ã¨ definita positiva.\nQuesta funzione ci puÃ² essere utile per la risoluzione dei Minimi quadrati. Quando mi calcolavo la norma quadrata per quel problema, avevo una funzione quadratica convessa (quasi, credo che il termine noto non fa male)!\nSoluzioni eq. normali Slide\nCon la roba di sopra dimostro anche che una soluzione ottima (ricorda che Ã¨ ottima anche una soluzione locale) esiste sempre.\nMetodo di newton puro Lâ€™unica cosa che cambia nello step di newton Ã¨ che la direzione di discesa Ã¨ calcolata in modo differente, in particolare possiamo vedere che lo step sia:\n$p_k = H(x_k) ^{-1} \\nabla f(x_k)$, le ragioni sono sconosciute, e non Ã¨ conveniente in termini di tempo provare a capire questo. lo step Ã¨ sempre di 1.\nLa velocitÃ  di convegenza Ã¨ quadratica come nel caso descritto per newton in Equazioni non lineari. Ripasso (roba di analisi) Derivata parziale Guardare Calcolo differenziale.\nMa Ã¨ una roba troppo base sta roba ðŸ˜‘\nHessiana Questa matrice ci da informazioni sulle derivate seconde\nMatrice simmetrica derivata ij, prima derivo su i, poi su j Ricordarsi il teorema di schwarz, che Ã¨ sufficiente per dimostrare che la matrice Ã¨ simmetrica\nJacobiana Questa ci da informazioni sulle derivate prime per tutti i modi possibili!\n$f: \\R^n \\to \\R^m$, $J(f) : \\R^n \\to \\R^{m\\times n}$\nIn particolare sulle righe ho tutte le derivate parziali possibili Sulle colonne ho la derivata fatta su tutte le funzioni possibili Analogo minimimo massimo Se ho il massimo e voglio il minimo, basta costruirsi la funzione swappata\n$$ \\argmax f(x) = \\argmin - f(x) $$ Teorema sulle funzioni differenziabili Calcolo differenziale Spiega bene questo teorema, con\nSe le derivate parziali esistono e sono continue, allora la funzione si dice differenziabile con continuitÃ  C.\nPunti di minimo locali e globali Globale\nQuando Ã¨ minimo per tutto il dominio.\nLocale\nSe Ã¨ un punto di minimo globale con dominio ridotto ad un intorno (basta che esista un interno).\nFunzioni convesse Questa parte Ã¨ trattata in analisi in ConvessitÃ  (cenni)\nSlides\n!\nSlide\n!\n","permalink":"https://flecart.github.io/notes/metodi-di-discesa/","summary":"Ripasso Prox: 13 Ripasso: December 23, 2022 Ultima modifica: January 3, 2023 11:12 AM Primo Abbozzo: November 3, 2022 11:53 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Metodi di discesa Intro Generali sui metodi di discesa Vogliamo creare algoritmi che riescano a trovare i punti di minimo delle funzioni non vincolate.\nIn generale si trova un punto stazionario (condizioni necessarie) ma non Ã¨ garantito lo stato ottimo.\nCondizioni di arresto classiche (2) ðŸŸ©- Slide","title":"Metodi di Discesa"},{"content":"Ripasso Prox: 6 Ripasso: December 23, 2021 Ultima modifica: September 30, 2022 3:20 PM Primo Abbozzo: November 26, 2021 9:35 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Vecchi dubbi quali sono stati gli scopi della logica intuizionista? Gli effetti della compattezza 9 Semantica intuizionista Tutte le slides\nslides10_202021.pdf\nMolto importante questo documento per avere chiara la differenza fra la logica intuizionista e la Logica Proposizionale classica.\nQuesta logica intuizionista non si preoccupa del noumeno platonico, ma solo di una prova reale.\nIntroduzione:\nwikipedia\n9 11 Scopi di intuizionista (3) Semantica dell\u0026rsquo;evidenza â†’ costruzione della prova Semantica della conoscenza diretta = conoscenza diretta Semantica della calcolabilitÃ  = programma, algoritmo della soluzione 9.1 Invenzione o scoperta La semantica intuizionista vede la matematica come una creazione (e questa cosa interessa molto all\u0026rsquo;informatico perchÃ© Ã¨ una prova., mentre la semantica classica vede la matematica come una scoperta\nCaratteristica principale della logica intuizionista\nEsempio il paradosso di Banach-tarksi non Ã¨ calcolabile (nessuno ha duplicato una sfera doro diciamo :) )\nSeziono la sfera in 3 parti e faccio movimenti rigidi (non deformo, posso rotare, trasportare) e dimostro che da questi movimenti rigidi ottengo due sfere con lo stesso volume e con gli stessi punti.\n9.1.1 Evidenza indiretta e diretta Nelle due logiche il significato di esistenza Ã¨ differente.\nClassica: l\u0026rsquo;esistenza, ma non so esattamente che numero sia Intuizionista: l\u0026rsquo;elemento che soddisfa, riesco proprio a trovare l\u0026rsquo;elemento tale che mi soddisfi le mie proprietÃ . NOTA: il fatto che esista una prova intuizionista mi permette di avere un algoritmo per tirare fuori un elemento che me lo soddisfi, mentre dalla prova classica no.\n9.1.2 Effetti dimostrazione per assurdo Questo metodo di dimostrazione non Ã¨ stato ben accettato nell\u0026rsquo;epoca in cui Ã¨ stato creato perchÃ© non permetteva il buon calcolo:\nNo calcolo Molto utile per dimostrare teoremi che non si potevano dimostrare in modo intuizionistico Molto veloce perchÃ© rende le dimensioni delle prove minori (ma perchÃ© fa meno lavoro!) 9.2 Enunciati e semantiche della logica intuizionista Algoritmo l\u0026rsquo;evidenza diretta Ã¨ necessaria per la determinazione del valore di veritÃ  Il valore di veritÃ  Ã¨ potenzialmente determinabile (ossia puÃ² diventare fissata dopo un pÃ² di tempo), ci deve essere una algoritmo o che non esista. Enunciato ed esempi\nAnalizzando la prima proposizione, per la logica classica dovrei avere un valore di veritÃ  fissato, invece sono in un mondo indeterminato.\nPer i numeri, l\u0026rsquo;algoritmo non riuscirebbe mai a finire a comparare due numeri periodici e non riuscirebbe a dare un risultato in tempo finito.\nMentre l\u0026rsquo;ultimo esempio Ã¨ stato dimostrato in Logica meta-linguistica\nDa questi si posso ricavare due semantiche:\n9.2.1 Semantica di Kripke La caratteristica principale di questa semantica Ã¨ che le proposizioni possono avere un range da [0,1].\nE che queste denotazioni possono evolvere da 0 a 1 col tempo. Bisogna quindi avere una funzione semantica che possa trattenere il tempo.\n0 Ã¨ ignoto 1 Ã¨ vero e questi valori evolvono.\nQuesti valori sono dei valori di conoscenza ma non veritÃ , e non algoritmico!\nEnunciato\n9.2.2 Altro Si tratterÃ  anche della semantica di Brouwer-Heyting-Kolmogorov subito dopo\n9.3 Semantica di Brouwer-Heyting-Kolmogorov 9.3.1 Introduzione Data una formula F, la sua denotazione Ã¨ l\u0026rsquo;insieme delle prove esplicite (algoritmi) che risolvono quella formula.\nQuesta semantica Ã¨ molto utile per l\u0026rsquo;informatico perchÃ© le formule sono descrizioni di problemi e l\u0026rsquo;altro soluzione.\nosservazioni:\nQuesta semantica Ã¨ molto utile per comporre delle soluzioni (grazie ai connettivi). L\u0026rsquo;insieme vuoto Ã¨ l\u0026rsquo;inesistenza di soluzioni algoritmiche (che potrebbe essere non piÃ¹ vuoto in futuro).\nQui ha senso introdurre il concetto di dedicibilitÃ  ovvero la possibilitÃ  di costruire un algoritmo che me lo risolva.\n9.3.2 Enunciato e definizione semantica Enunciato\nDefinizione semantica\n9.3.3 Nota sul VOID: con void in c starei restituendo la stellina (valore vero), ovvero sto restituendo sempre una sequenza giusta (eliminazione del top Ã¨ inutile quindi non ci faccio caso).\n9.3.4 EM e RAA in semantica intuizionista Queste dimostrazioni valide in logica classica non hanno piÃ¹ senso in questo caso\nEsempio\n9.3.5 Correttezza e completezza Potrebbe essere un buon esempio confrontare la correttezza e completezza intuizionistica con quella classica.\nSlide\nCompletezza forte e debole\nSlide\nAbbozzo di ragionamento per queste completezza\nUn algoritmo in un tempo finito non puÃ² analizzare un input infinito, quindi non potrebbe dimostrarlo un algoritmo. Esiste perÃ² una dimostrazione classica.\n9.3.6 Conclusioni Questa semantica si puÃ² evolvere nel tempo (trovando nuovi algoritmi che mi risolvano il problema)\nSi ha una completezza debole per logiche senza RAA\nSe ho una prova intuizionista riesco a costruire un algoritmo che mi risolvi un problema\nEM non ha molto senso qua, se fosse una tautologia sarebbe un risultato molto forte\nSlide\n9.3.7 La negazione Le formule negate non hanno informazione al loro interno.\nPartiamo dalla regola del not, ovvero per dimostrare nonF devo dimostrare che F implica l\u0026rsquo;assurdo.\nOvvero devo dire che ci sia una funzione che parta da F e che arrivi a nulla.\nLe soluzioni possibili sono solamente vuoto e singoletto di vuoto (in altri termini possiamo dire che abbiamo 0 e 1). chiaramente queste funzioni non sono affatto utili per cui non esiste un algoritmo che mi da cose utili.\nNegare due volte Ã¨ equivalente a distruggere una informazione (devi fare una tabellina con la regola per vedere che c\u0026rsquo;Ã¨ questo)\nnotF Stato di F notnotF singoletto vuoto Uguale a Vuoto vuoto vuoto Diverso da vuoto singoletto vuoto perchÃ© nonF mi puÃ² dare solamente due output, mi ha distrutto tutto l\u0026rsquo;algoritmo iniziale!\nDimostrare che non esiste significa dire che non esiste informazione.\nProva a dimostrare queste:\n$$ \\neg(F_1 \\vee F_2) \\Vdash \\neg F_1 \\wedge \\neg F_2 $$ Mentre per quello sopra invertito (invertendo or e and di sopra) non Ã¨ intuizionista, perchÃ© l\u0026rsquo;output ha piÃ¹ informazioni per qualche motivo strano.\n9.4 Teorema di compattezza Questo teorema Ã¨ una conseguenza molto utile della proprietÃ  di completezza, come in slide:\nEnunciato e dimostrazione del teorema\nQuesto teorema Ã¨ molto forte, perchÃ© se ho un insieme infinito di filtri, vuol dire che ho bisogno solamente di limiti finiti. E il fatto che l\u0026rsquo;infinito si possa ridurre al finito Ã¨ un fatto sorprendente.\n9.4.1 Conseguenze della compattezza (4) La cosa che era sorpredente della compattezza in questi casi Ã¨ la possibilitÃ  di ritrovare in un caso infinito un caso finito da cui Ã¨ possibile poter ricavare la cosa voluta!.\nConseguenze\n9.4.2 Fallimento della compattezza per logiche complesse (3) Slide\nze\n\u0026lt;img src=\u0026quot;/images/notes/Semantica intuizionista/Untitled 12.png\u0026quot; alt=\u0026quot;Semantica intuizionista/Untitled 12\u0026quot;\u0026gt; 9.4.2 Fallimento della compattezza per logiche complesse (3) Slide\n","permalink":"https://flecart.github.io/notes/semantica-intuizionista/","summary":"Ripasso Prox: 6 Ripasso: December 23, 2021 Ultima modifica: September 30, 2022 3:20 PM Primo Abbozzo: November 26, 2021 9:35 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Vecchi dubbi quali sono stati gli scopi della logica intuizionista? Gli effetti della compattezza 9 Semantica intuizionista Tutte le slides\nslides10_202021.pdf\nMolto importante questo documento per avere chiara la differenza fra la logica intuizionista e la Logica Proposizionale classica.\nQuesta logica intuizionista non si preoccupa del noumeno platonico, ma solo di una prova reale.","title":"Semantica intuizionista"},{"content":"Ripasso Prox: 80 Ripasso: May 21, 2023 Ultima modifica: March 12, 2023 10:00 AM Primo Abbozzo: October 8, 2022 11:30 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso 2 Sezioni Critiche Introduzione La parte di un programma che utilizza una o piÃ¹ risorse condivise viene detta sezione critica (critical section, o CS)\nAndiamo in questa altra parte a valutare certe soluzioni:\nProgramma dâ€™esempio ðŸŸ© Vorremmo garantire che a = b invariante. (espressione logica verificata nell\u0026rsquo;esecuzione di questo programma). quindi una coerenza di uno prima dell\u0026rsquo;altro vogliamo.\nNon funziona lasciare la gestione dell\u0026rsquo;invarianza al sistema operativo o al compilatore perchÃ© manca questa informazione (quindi non abbiamo potere per la gestione dellâ€™ordine in questo caso.\nRequisiti per le CS (5) ðŸŸ©â€”â€” Vogliamo ora cercare di listare le proprietÃ  delle critical sections in modo teorico, per implementare un programma che riesca ad implementare la critical section.\nSlide requisiti\nSafety:\nMutua esclusione, solo uno all\u0026rsquo;interno della CS No deadlocks Liveness:\nUn processo fuori dalla CS non dovrebbe ritardare lâ€™entrata di un altro programma Un processo eventualmente deve entrarci Altro:\nNessun processo puÃ² terminare in una critical section (secondo me perchÃ© si porterebbe la risorsa critica con sÃ©, nel senso che nessun altro programam puÃ² utilizzarlo, suppongo. Questo si puÃ² associare al principio 4 di Liveness. Algoritmo di Dekker Listo qua in breve le idee principali che daranno vita allâ€™algoritmo\nTurni per disambiguare chi puÃ² entrare e chi vuole entrare Booleani per esprimere il concetto di voler entrare. Dare la precedenza allâ€™altro. Soluzioni provate e non funzionanti ðŸŸ©- (prolly non richiede) Soluzione 1 (busy waiting esterno con i turni)\nNon Ã¨ buona perchÃ© viola il principio 3 del non rallentamento. PuÃ² succedere che nessuno Ã¨ dentro la sezione critica, ma uno non ci puÃ² entrare finchÃ© lâ€™altro non ci entra ed esce (ma puÃ² essere che lâ€™altro sia molto piÃ¹ lento!)\nSoluzione 2 (busy waiting esterno con 2 booleani)\nIl problema Ã¨ che possono entrambi entrare nella soluzione critica, quindi non Ã¨ mutex e quindi non Ã¨ una soluzione\nSoluzione 3 (2 booleani, assegnamento prima)\nPuÃ² accadere un deadlock, viola principio 4\nSoluzione 4 (livelook, assegnamenti nel busy waiting)\nPuÃ² accadere starvation in questo problema nel requisito 4, ossia uno non entra mai.\nlâ€™algoritmo ðŸŸ¨ Questo Ã¨ un algoritmo che funziona per implementare le sezioni critiche.\nAndremo in questa parte a considerare moltissime soluzioni che non soddisfano i requisiti esplicitati precedentemente, fino a raggiungere lâ€™algoritmo di dekker. (Questo Ã¨ proprio il processo seguito da Dijkstra nel raggiungimento della soluzione!)\nAlgoritmo di Dekker\nDimostrazione correttezza di Dekker ðŸŸ©- Mutua esclusione\nMutua esclusione\nIn pratica si riduce che in un certo momento deve esserci un momenti in cui uno Ã¨ nella critical section, e il valore di need associato deve essere falso. CiÃ² Ã¨ impossibile, devo essere eseguite entrambe le istruzioni di uscita!\nAssenza di deadlock\nSlide\nAssenza di ritardi\nSlide\nAssenza di starvation\nSlide\nAlgoritmo di Peterson Descrizione dellâ€™algoritmo ðŸŸ©â€” Slide\nAlgortitmo generalizzato ðŸŸ¥ Slide peterson generalizzato (non so perchÃ© funzioni, comunque il prof. lo ha saltato).\nTODO: se vuoi fare bene questo pezzo sarebbe anche Peterson\nÃˆ una cosa molto piÃ¹ compatta rispetto Dekker, e l\u0026rsquo;idea principale Ã¨ che il turno Ã¨ stabilito prima di entrare nel while\nDimostrazione correttezza di Peterson ðŸŸ© Mutua esclusione\nSlide\nAssenza deadlock\nSlide\nÃˆ quasi ovvio perchÃ© turn non puÃ² avere due variabili diverse\nAssenza di ritardi\nSlide\nAssenza di starvation\nSlide\nSoluzioni hardware PerchÃ© Ã¨ meglio di software (3) ðŸŸ¨- Si preferirebbero delle soluzioni hardware perchÃ© tutte le soluzioni software fanno utilizzo di busy waiting che Ã¨ molto dispendioso.\nDispendioso dal punto di vista della CPU per il busy waiting Difficile da implementare senza bug (difficile da testare) Gestione delle responsabilitÃ  a livello software (cosa che non si vuole) Disabilitazione interrupt (2) ðŸŸ© CosÃ¬ non posso passare ad un altro processo all\u0026rsquo;inizio di una sezione critica. (ma c\u0026rsquo;Ã¨ il problema dei multicore perchÃ© dovrei disabilitarlo per tutti!).\nCi sono altri motivi per cui questa Ã¨ una brutta soluzione:\nLasciare la gestione degli interrupt ai programmi perchÃ© agisce sull\u0026rsquo;intera macchina, ma non dovrebbe avere questo diritto. Multicore dovrebbero essere sincronizzati su questo aspetto (quindi difficoltÃ  di parallelizzazione). Quindi non posso essere interrotto Non funziona su multicore perchÃ© anche se li disabilito su entrambi, puÃ² esser che due processi lavorano sempre con la stessa sezione critica Test \u0026amp; set (spin lock) ðŸŸ©- Lâ€™hardware ha delle istruzioni in piÃ¹ che aiutano a creare lâ€™implementazione per le sezioni critiche.\nProgramma con test e set\nDimostrazione di correttezza (senza starvation)\nOltre a questo si puÃ² implementare con altre istruzioni atomiche come fetch and set, compare and swap.\nCS con swap e divisione ðŸŸ©- Protocollo entrata con swap\nlock = 0; do { v = 1; swap(v, lock); } while(v); Chiaramente posso entrare quando lock Ã¨ 0, altrimenti lock Ã¨ sempre 1.\nProtocollo entrata con divisione\nlock = 2 do v = \u0026lt; lock /= 2 \u0026gt; while (v != 1) Con questo abbiamo raggiunto una notevole semplificazione nella programmazione (ed anche della generalizzazione di questa soluzione), ma non sono risolti i problemi di starvation nÃ© busy waiting, ancora fortemente inefficiente.\n","permalink":"https://flecart.github.io/notes/sezioni-critiche/","summary":"Ripasso Prox: 80 Ripasso: May 21, 2023 Ultima modifica: March 12, 2023 10:00 AM Primo Abbozzo: October 8, 2022 11:30 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso 2 Sezioni Critiche Introduzione La parte di un programma che utilizza una o piÃ¹ risorse condivise viene detta sezione critica (critical section, o CS)\nAndiamo in questa altra parte a valutare certe soluzioni:\nProgramma dâ€™esempio ðŸŸ© Vorremmo garantire che a = b invariante.","title":"Sezioni Critiche"},{"content":"Ripasso Prox: 23 Ripasso: May 17, 2023 Ultima modifica: May 1, 2023 10:58 AM Primo Abbozzo: March 1, 2023 1:10 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Sicurezza delle reti Introduzione Obiettivi della sicurezza (!!!) ðŸŸ© Vogliamo creare delle reti che abbiamo certe garanzie di sicurezza, soprattutto:\nConfidenzialitÃ , non vorremmo che il nostro messaggio sia intercettabile e leggibili da persone intermedie IntegritÃ : non vogliamo che messaggi possano essere cambiati senza intervento del sender Autenticazione: vorremmo sapere con chi stiamo parlando, e vorremmo essere sicuri che non stiano mentendo sullâ€™identitÃ . Sicurezza operativa: vorremmo essere in grado di poter continuare a fornire il servizio (quindi non sia possibile dossare, o installare malware che modifichino il comportamento del servizio). Questi principi possono essere messe in pratica con specifiche politiche nella fase di invio dei messaggi, implementate nei vari livelli o firewall per poter identificare tentativi di intrusione.\nCome vengono raggiunti questi obiettivi\nVedremo in seguito che il primo obiettivo viene raggiunto senza molti problemi utilizzando la crittografia, mentre le altre due con le funzioni di hashing. Il quarto con la creazione di protocolli solidi.\nUn principio di sicurezza ðŸŸ© La sicurezza del messaggio non dovrebbe essere basato sullâ€™algoritmo utilizzato per codificare, ma solamente sullâ€™utilizzo della chiave.\nIl primo Ã¨ molto facile da recuperare, o farci reverse engineering, ne abbiamo parlato qui in breve On security of cipher ðŸŸ©. Classical Cyphers#On security of cipher\nTipologie di attacchi (!!) ðŸŸ¨ Se Ã¨ possibile lâ€™attaccante puÃ² avere moltissimi vettori di attacchi che possono incrinare i principi di sicurezza che abbiamo enunciato sopra\neavesdrop: spiare la conversazione (eventualmente rubando password e dati) Impersonation: impersonare un altro soggetto (o la macchina di un soggetto). Hijacking dirottare una sessione in corso, quindi controllare le richieste che fai, magari ti mando su una copia di paypal falsa, o Denial of service: negare il servizio agli utenti legittimi, questo sulla sicurezza operativa. Crittografia La crittografia diventa una delle tecnologie chiave per poter garantire i principi di sicurezza.\nAlcune tipologie di cifrari simmetrici ðŸŸ© Approfonditi in Block Ciphers che solitamente sono utiizzati negli scambi di messaggi simemtrici. Elenco qui alcuni cifrari classici:\nCifrario monoalfabetico (sostituzione) (come codice cesare, in cui cÂ´Ã¨ una mappatura per ogni singola lettera ad altra lettera). Cifrario polialfabetico (in cui la cifrazione dipende anche dalla posizione). Cifrario a blocchi, come DES, AES etc. Importante diventa anche lâ€™hashing, che serve un sacco per poter mantenere lâ€™integritÃ  del messaggio.\nIl problema principale di questo metodo Ã¨ lo scambio delle chiavi, che dovrebbe essere sicura anche questa parte. Ma solitamente cifrari asimmetrici come RSA risolvono questa parte.\nLa soluzione ottima per questo metodo Ã¨ utilizzare un sistema a chiave pubblica PKI per scambiarsi la chiave privata con cui continuare le transazioni da lÃ¬ in poi.\nTipologie di attacco ðŸŸ© i principali metodi di attacco sono\nCiphertext only attack:\nForza bruta, in cui cerco la chiave Statistical analysis attack (per cercare alcuni pattern che possono esistere per rompere il cifrario). Oltre a questi ho anche classici attacchi col plain text: chosen-plaintext attack, known plaintext attack, questi mi permettono un pÃ² piÃ¹ informazioni.\nChiavi di sessione e RSA ðŸŸ© Si Ã¨ parlato di questo ambito per abbastanza, ma non la ritengo molto interessante quindi non la metto, Ã¨ perÃ² molto importante, ma credo tu sappia come funzioni quindi non la scrivo.\nSemmai due note sulle chiavi di sessione, Ã¨ molto semplice, in pratica dato che RSA Ã¨ molto piÃ¹ lento e costoso (in termini di energia) dei cifrari a chiave simmetrica utilizzo RSA per scambiarmi la chiave con cui faccio la crittazione simmetrica, questa Ã¨ la chiave di sessione.\nda notare che la combinazione di Cifrari simmetrici e asimmetrici riescono a dare forti garanzie (non assolute, perchÃ© i cifrari possono essere comunque rotti) di confidenzialitÃ  fra le persone.\nAutenticazione Protocollo di autenticazione ðŸŸ© Il libro prova a costruire passo passo un protocollo di autenticazione (cioÃ¨ una serie di passaggi che finiscono per riuscire ad asserire l\u0026rsquo;identitÃ  con cui si stia comunicando).\nProtocolli di autenticazione passo passo\nDato che lo scambio di password Ã¨ sempre vulnerabile a playback attack. Ci costruiamo un segreto temporaneo, la nonce, che Ã¨ una mini specie di challenge utilizzata per convincere dell\u0026rsquo;identitÃ . Se provo a rimandare la nonce criptata con una chiave privata, allora potrei dire che sono ALICE.\nE dato che la nonce Ã¨ unica, non Ã¨ vulnerabile a playback attack.\nUltimo protocollo con NONCE e PKI\nR Ã¨ la nonce\nNel nuovo sistema con la nonce e il sistema chiave pubblica e chiave privata Ã¨ ancora vulnerabile a MITM. Dato che Eve puÃ² sempre mettersi in mezzo, e praticamente avere in chiaro tutti i collegamenti, dovremmo cercare di identificare in qualche modo la chiave pubblica della identitÃ  giusta. (devo prendere la chiave pubblica da un servizio fidato, queste sono le certification autorities, CA).\nCertificate authorities ðŸŸ© Sono dei servizi utili ad identificare l\u0026rsquo;identitÃ  di una persona, e sono in grado di giustificare la corrispondenza della chiave pubblica con una certa identitÃ . Generano per te la chiave pubblica E privata.\nOvviamente la sicurezza dipende dai processi di autenticazione di questa CA (potrebbe chiederti la carta d\u0026rsquo;identitÃ , o latre informazioni simili), che potrebbe essere vulnerabile anchâ€™essa. (nella storia sono anche stati hackerati, quindi hanno molte coppie di chiavi messe a gente falsa).\nSlide CA\nIntegritÃ  del messaggio ðŸŸ© Potremmo utilizzare il PKI, per firmare con la nostra chiave privata (e poi CA per trovare la chiave pubblica per poter verificare il messaggio) in questo modo il nostro interlocutore Ã¨ sicuro dellâ€™integritÃ  del nostro messaggio e dellâ€™autenticitÃ  di chi me lo sta mandando (con le CA).\nSe poi si fa la stessa cosa mandando un messaggio giÃ  cifrato, allora ho anche segretezza, senza nessun problema!\nMa poi, dato che Ã¨ molto costoso firmare un messaggio tanto lungo, solitamente si firma solamente l\u0026rsquo;hash del messaggi originale, quindi rende molto piÃ¹ efficiente il protocollo. ma anche il fatto che in questo modo posso firmare messaggi molto corti! Ho sempre un codice della stessa linguaggio.\nSlide integritÃ  e autenticitÃ \nFunzione di hashing ðŸŸ© Ci sono un sacco di caratteristiche che dovrebbero tutte le funzioni di hashing soddisfare\nUn digest fisso, di una certa lunghezza. Pre-image collision, dovrebbe essere difficile trovare un altro messaggio con lo stesso hash. Una proprietÃ  che dovrei soddisfare Ã¨ il fatto che se cambio un bit di input cambi di molto l\u0026rsquo;output, ossia ci sia pochissima correlazione fra input e output! (certamente cose lineari non ci piacciono) Esempio di hash brutto Internet checksum\nUn esempio di hash brutto Ã¨ l\u0026rsquo;internet checksum perchÃ© Ã¨ molto facile poter creare una collisione!\nÃˆ in grado di rilevare solamente errori idioti (quelli fatti senza l\u0026rsquo;intelligenza di un EvE che prova a cambiarti i bit, ma sono abbastanza random!)\nProtocollo Mail sicura ðŸŸ© Slide protocollo MAIL\nPraticamente generiamo una chiave simmetrica, poi se vogliamo firmarla e metterci un coso di integritÃ  MAC possiamo farlo, cifriamo con chiave pubblica di bob presa da CA la nostra chiave e mandiamo il pacco con Messaggio privato, magari firmato, e chiave criptata.\nBob riceve e riesce a ricavare tutto quanto possibile per verificare lâ€™integritÃ  del messaggio e comprendere il messaggio!\nProtocollo SSL Se rendiamo il socket sicuro, rendiamo sicuro tutto quello che c\u0026rsquo;Ã¨ sotto, quindi dal livello 4 in giÃ¹, vedi Architettura e livelli 1, 2 per dettagli sulla stack. In questo modo le applicazioni possono decidere se utilizzare o meno questo protocollo, dato che Ã¨ sotto di essa.\nSlide presentazione ssl\nImplementazione Toy-SSL ðŸŸ¨+ Utilizzando il sistema presentato sopra riescono a cambiare un segreto (come una chiave condivisa per comunicare, ma sarÃ  un robo per creare un set di chiavi, o il vettore di inizializzazione)\nIl set di chiavi sono utilizzati per invio direzionale e verifica di integritÃ  direzionale (quindi sono 4 chiavi). Che sono generate dalla Master Key scambiata dalla prima fase.\nSlide SSL\nCARATTERISTICHE PACCHETTI SSL ðŸŸ¥\nDurante il trasferimento dei dati vogliamo avere anche altre caratteristiche che aiutino a mantenere la sicurezza di questo protocollo:\nNumerazione per evitare che eve duplichi pacchetti o simili. Verifica di integritÃ  ha un proprio hash MAC (hashato Ã¨ anche la numerazione a livello SSL). Slide record and sequence numbers\nCOMMON ATTACKS\nReorder attack, utilizzo le sequence numbers per numerare i records, cosÃ¬ sono sicuro che non puÃ² riordinare dato che non possiede le chiavi\nReplay attack riutilizzo anche in questo momento le nonce\nTruncation attack vogliamo anche avere un modo per terminare in modo sicuro la comunicazione, cioÃ¨ non dovremmo permettere a Eve di terminare la comunicazione per noi. Per fare questo mettiamo anche una parte tipologia di messaggio in ogni MAC. (importante il fatto che Ã¨ su due versi la chisura!)\nImplementazione SSL (skip) Questo Ã¨ uguale al toy SSL alla fineâ€¦ Solo con qualche accorgimento in piÃ¹, non Ã¨ importante sta parte\nhandshake Ã¨ leggermente piÃ¹ complicato, câ€™Ã¨ anche una fase di autenticazione dell\u0026rsquo;utente e scelta dellâ€™algoritmo crittografico asimmetrico. Alla fine mando anche MAC di tutti i messaggi di handshake per prevenire tampering, come lâ€™eliminazione degli algoritmi piÃ¹ forti per poter provare a bruteforcare meglio. RECORD FORMAT\nin questo modo si chiamano i pacchetti di SSL, contengono cose simili a quanto abbiamo descritto per il toy SSL\nSlides format record:\nLa cosa particolare Ã¨ che i dati e il mac sono entrambi criptati con la chiave simmetrica che abbiamo derivato prima, in modo simile a quanto fatto dal toy-SSL.\nIPsec Questo Ã¨ un protocollo di sicurezza a livello Rete e non piÃ¹ a livello socket!\nPerchÃ© vorremmo avere sicurezza a questo livello? Ãˆ una cosa troppo comune da dover mettere a livello superiore (ma solitamente viene messa a questo livello per la sicurezza, quindi non Ã¨ implementata ovunque per dire).\nÃˆ una cosa molto utile per implementare cose come i VPN di aziende. Solitamente solo per questo, in altro non Ã¨ implementato perchÃ© Ã¨ troppo complesso, per poco di guadagno.\nEsempio: Nota l\u0026rsquo;imbustamento e imbustamento Ã¨ fatto nei router nell\u0026rsquo;esempio qui, ma puÃ² essre fatto anche di computer.\nIn qualche modo, che non ho capito, lo puoi vedere come se fosse la stessa rete, perchÃ© lâ€™IP locale Ã¨ messo nell\u0026rsquo;IP sec credo, anche se non sono molto sicuro\nGaranzie IPsec \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 21.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 21\u0026quot;\u0026gt; IntegritÃ  ConfidenzialitÃ  Autenticazione dellâ€™origine (credo perchÃ© conoscono solamente la chiave della VPN) Replay attack non funziona Con Jocelyn vengono aggiunti anche altre due\nAccess control Integrity La cosa bella di applicare la sicurezza a questo livello Ã¨ che diventa trasparente rispetto agli utilizzi da utenti non bene addestrati o applicazioni che la ignorano. In ogni caso ho le garanzie di sopra.\nTunnelling mode (2) ðŸŸ© Tunneling mode Routers IPsec aware, quando sono i routers che mettono su il protocollo Questo metodo solitamente viene utilizzato per reti VPN, perchÃ© Ã¨ il router che si occupa di decriptare ed inoltrare a livello rete locale. Transport mode Host IPsec-aware, in modo che siano solamente gli host che siano aware, mentre i routers non sanno niente, e si comportano in modo normale in questo modo, secondo una connessione IP. In questo caso viene cryptato solo il payload, viene utilizzato in host-host\nSecurity Headers - Service Models Sembra end-to-end, che dovrebbe essere una garanzia a livello trasporto, dato che alla fine solamente gli utenti finali dovrebbero ricevere il messaggio. Possono essere Authentication header oppure Encapsulation Security Protocol, la prima non fornisce la confidenzialitÃ , mentre la seconda anche la confidenzialitÃ . Questa Ã¨ praticamente la differenza principale.\nIl primo ha il vantaggio che utilizzi meno energie perchÃ© non devi metterti a cifrare (lâ€™altro Ã¨ sicuro con chi sta parlando, per esempio uno streaming puÃ² far uso di AH, dato che non ho bisogno di cifrare il tutto). Ãˆ la versione piÃ¹ comune Tunnel mode con confidenzialitÃ  per gli usi in VPN. In entrambi i metodi esiste un sequence number che viene utilizzato per evitare replay attacks. In entrambi c\u0026rsquo;Ã¨ un hash per l\u0026rsquo;integritÃ .\nSecurity Association (4)ðŸŸ¨+ Prima di mettermi a scambiare messaggi, devo essere sicuro con chi sto parlando, quindi vogliamo andare a creare una security association, scambio di chiavi e algoritmi di criptazione comune, solo da una direzione verso l\u0026rsquo;altra.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 25.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 25\u0026quot;\u0026gt; Security association parameters Uses usually three parameters\nSecurity Parameter Index (32 bit) Ã¨ un identificatore della SA. IP destination e sorgente Identifier of the security protocol (ESP or AH). Altre chiavi di codifica e decodifica. Security Association Database Posso anche creare un database di SA questo si chiama SAD\nCâ€™Ã¨ una security associazione fra tunnel e ogni host\nSlides su SAD\nCose che vengon ostorate qui sono:\nIdentificatore di SA, SPI Chiavi di cifratura e algo di cifratura Interfaccia di inizio e arrivo della SA MAC e chiave di MAC IPsec Datagram ðŸŸ¨ Si noti che anche il pacchetto di livello trasporto Ã¨ cifrato, quindi anche l\u0026rsquo;indirizzo di porta e l\u0026rsquo;indirizzo IP finale dovrÃ  essere cifrato\nIl modo con cui queste vengono programmate Ã¨ attraverso alcune regole del router (che controllano se il datagramma va verso certi host, oppure parte da certi host e simili).\nKey Determination Protocol Quello che viene usato in questo caso Ã¨ chiamato IKEv2. Che Ã¨ una versione di Diffie-Hellman in Key Exchange protocols. Ma risolve i problemi di Man in the middle, autenticando le due parti. E risolve anche problemi di denial of service dovuti al costo di computazione di diffie-hellman. Per il problema di flooding usano delle specie di cookie autenticati, che sono creati da chi vuole comunicare (firmati da questi diciamo). Poi usano un cifrario a chiave asymmetric come curve ellittiche o RSA\nFirewalls Vogliamo cercare di filtrare quello che entra dall\u0026rsquo;esterno. mentre in generale ci fidiamo di quello che Ã¨ presente allâ€™interno del firewall (quindi se riesco a controllare una macchina che sia dentro avrei pieno accesso).\nObiettivi dei Firewalls ðŸŸ¨- Lâ€™obiettimo principale dei Firewalls Ã¨ proteggere da attacchi esterni, esempi di attacchi potrebbero essere\nVorrei evitare DoS, ossia permettere senza problemi di aprire delle porte TCP senza andare a chiuderne una. Non devo permettere la modifica arbitraria dei dati (che hanno conseguenze penali credo) Permettere lâ€™accesso solamente a utenti autenticati Per fare ciÃ² possono avere a disposizione tre tipologie di firewalls, quelly che iltrato senza avere uno stato quelli con uno stato, ma anche le application gateways (che controllano il contenuto di quello che esce e quello che entra).\nSlide obiettivi\nAccess control List ðŸŸ¨+ \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 29.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 29\u0026quot;\u0026gt; In sede diversa, questa strategia Ã¨ stata analizzata anche in analisi delle autorizzazioni nei sistemi operativi. Vedi Sicurezza OS. Vogliamo permettere certe cose, e negarne altre. La ACL Ã¨ solamente una lista di regole di permessi e negazioni, con specificazione di source, address, protocollo, porta di arrivo e di partenza e flagâ€¦\nCon queste regole posso implementare senza problemi il Stateless filtering\nStateless/Stateful Packet filtering ðŸŸ© Alcuni pacchetti vengono droppati quando ci sono certe informazioni all\u0026rsquo;interno del pacchetto.\nInformazione come Source e destination IP\nPort numbers for TCP or UDP\nICMP messages\nSyn and Ack bits, and maybe more\nSlides Stateless packet filtering\nMore examples of these Quando una cosa non ha molto senso da sola, e ha bisogno di tenere conto dello stato della connessione allora abbiamo bisogno di utilizzare uno stateful packet filtering in cui si monitora la storia della connessione TCP una volta che la connessione Ã¨ stata aperta.\nApplication gateway and IDS ðŸŸ© Fanno a vedere il contenuto, e gli header dei pacchetti che provengono dall\u0026rsquo;interno. TODO meglio, il prof ha saltato.\nIntrusion detection systems /turn\nVogliamo cercare di capire se siamo sotto attacco, quindi se qualcuno fa port scanning, oppure packet filtering pesante da certe cose, oppure provare a vedere se il contenuto del pacchetto potrebbe essere dannoso.\nDemilitarized ðŸŸ© https://doubleoctopus.com/security-wiki/network-architecture/demilitarized-zone/\nin pratica Ã¨ possiamo considerarla come una rete di appoggio per accedere a una rete untrusted esterna, come Internet.\nSolitamente in questa DMZ ci mettiamo cose come Email, web servers e cose simili. Ãˆ una zona quarantinata, cioÃ¨ per interagire col network interno si passa di nuovo d aun firewall, questo per garantire maggiore protezione della roba interna, solitamente molto piÃ¹ importante.\n","permalink":"https://flecart.github.io/notes/sicurezza-delle-reti/","summary":"Ripasso Prox: 23 Ripasso: May 17, 2023 Ultima modifica: May 1, 2023 10:58 AM Primo Abbozzo: March 1, 2023 1:10 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Sicurezza delle reti Introduzione Obiettivi della sicurezza (!!!) ðŸŸ© Vogliamo creare delle reti che abbiamo certe garanzie di sicurezza, soprattutto:\nConfidenzialitÃ , non vorremmo che il nostro messaggio sia intercettabile e leggibili da persone intermedie IntegritÃ : non vogliamo che messaggi possano essere cambiati senza intervento del sender Autenticazione: vorremmo sapere con chi stiamo parlando, e vorremmo essere sicuri che non stiano mentendo sullâ€™identitÃ .","title":"Sicurezza delle reti"},{"content":"Ripasso Prox: 20 Ripasso: May 19, 2022 Ultima modifica: April 30, 2022 10:54 AM Primo Abbozzo: March 22, 2022 11:41 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\n5 Tabelle di Hash 5.1 Introduzione 5.1.1 Prototipo Vogliamo implementare le operazioni del prototipo dizionario presentato in Strutture di dati elementari, e vogliamo fare solo queste 3 ma molto bene.\nInsert O(1) Delete O(1) Search in O(1) La struttura dati di hash riesce a fare bene queste singole operazioni\nSi vedrÃ  che l\u0026rsquo;array modificato Ã¨ il modo migliore per avere questo hash, solo generalizzando un modo per indicizzarlo che non saranno numeri (indici).\nNoteremo che in media hanno operazioni costanti queste tabelle di hash (nel caso peggiore sempre lineare).\n5.1.2 Esempi di utilizzi soliti Nei compilatori di solito Ã¨ molto utilizzato per mantenere in memoria il mapping con le variabili e simili\n5.1.3 Tabelle ad indirizzamento diretto Queste tabelle di hash sono altresÃ¬ chiamate array, in quanto il numero di chiavi utilizzate Ã¨ esattamente uguale al numero di chiavi presente nel nostro universo di chiavi.\nMa per uso pratico questo sarebbe improponibile, in quanto vorremmo avere come chiavi anche stringhe, ma il numero di chiavi esploderebbe in maniera esponenziale e un utilizzo di memoria esponenziale non Ã¨ buona\u0026hellip;\nTempo O(1)\nSpazio O(n) con n il numero di chiavi nell\u0026rsquo;universo.\n5.1.4 Tabelle di hash (idea) Idea vorremmo in qualche modo trasformare un elemento nel nostro insieme di chiavi possibili in un elemento appartenente solamente al nostro spazio di chiavi utilizzate.\nCioÃ¨ ridurre senza collisione (ovvero per input diversi, ottengo uno stesso output) una chiave nell\u0026rsquo;universo piÃ¹ esteso in un numero utilizzabile.\nSlide\nIn questo modo riduco lo spazio utilizzato solamente a O(K) dove K sono le chiavi effettivamente utilizzate, deciso da caso a caso.\nRiassunto della ricetta dell\u0026rsquo;hashing\nRiassunto:\nFunzione di hash che mi riduca le chiavi dell\u0026rsquo;universo totale all\u0026rsquo;insieme delle chiavi utilizzate Queste devono essere veloci nel calcolo Minimizzare le collisioni Implementazione concreta come puÃ² essere un vettore di una certa dimensione, che contenga effettivamente il valore dell\u0026rsquo;hash in quella zona. (possibile anche ridimensionamento) 5.2 Le chiavi Le chiavi sono uno strumento principale per comprendere le tabelle di hash. Sono il modo con cui troviamo il nostro valore e sarebbe bene cercare di definirlo in un modo piÃ¹ formale\n5.2.1 Universo delle chiavi e insieme chiavi effettive Definiamo un insieme astratto di tutte le chiavi possibili Definiamo le chiavi effettive il sottoinsieme dell\u0026rsquo;universo delle chiavi, che contiene le chiavi effettivamente utilizzate in un momento Esempio\n5.2.2 Caratteristiche delle chiavi per le funzioni di hashing Le chiavi devono essere distribuite in maniera uniforme (questo Ã¨ il caso migliore per evitare il piÃ¹ possibile delle collisioni) Le chiavi devono essere sempre positive o nulle La prima assunzione Ã¨ necessaria per l\u0026rsquo;analisi della nostra funzione di hash. Semplifica abbastanza direi.\n5.3 La funzione di hash Cerchiamo qui di definire alcune proprietÃ  di una buona funzione di hash.\n5.3.1 Distribuzione uniforme semplice Se soddisfa questa proprietÃ , ho una buona probabilitÃ  che io stia distribuendo i valori presenti in modo uniforme nel nostro spazio delle chiavi utilizzate (questo perÃ² non implica l\u0026rsquo;assenza o minimizzazione di collisioni!)\nSlide\nÃˆ difficile dimostrare o calcolare la distribuzione di probabilitÃ  di una funzione di hash.\nPerÃ² dall\u0026rsquo;altra parte sono sicuro se prendessi una chiave a caso in un intervallo di mia scelta allora ho finito, ho dimostrato che sono distribuite in modo uniforme.\n5.3.2 Costo computazionale costante Deve essere abbastanza semplice da avere un costo costante nel suo calcolo, altrimenti l\u0026rsquo;intera tabella avrebbe il costo di questa funzione, rallentando l\u0026rsquo;intera tabella.\n5.3.3 Esempi di funzioni di hash (4)!!! Rappresentazione della stringa in intero:\nEsempio in slide\nQuesto metodo cresce insieme alla lunghezza della stringa, quindi di solito non Ã¨ una buona cosa farla in questo modo.\nVantaggio: posso rappresentare qualunque cosa che si puÃ² rappresentare sul calcolatore\nSvantaggio: lo spazio cresce in funzione alla grandezza dell\u0026rsquo;input.\nRiduzione in modulo (divisione)\nEsempio in slide\nNella slide sono mostrati anche vantaggi e svantaggi di questo metodo. (principalmente perchÃ© se il modulo Ã¨ preso brutto, ignora gran parte delle informazioni, quindi ottengo un hash che non mi rappresenta totalmente questo numero)\ncostante m descrive la funzione di hash in modo molto importante! (anche l\u0026rsquo;uniformitÃ )\nMetodo della moltiplicazione\nVogliamo introdurre maggiore scombinamento dell\u0026rsquo;input, questo si puÃ² fare moltiplicando il valore di hash per qualcosa.\nEsempio in slide\nCostante C descrive l\u0026rsquo;uniformitÃ  di distribuzione\nMetodo codifica algebrica\nIn slide\nRiguardo al calcolo di questa codifica esiste il metodo di horner che permette la computazione di questo hash in maniera lineare rispetto all\u0026rsquo;input.\nRegola di Horner\n5.4 Soluzione delle collisioni Slide\nVogliamo trovare un sistema per risolvere le collisioni, che sono molto piÃ¹ frequenti del solito per\nConcatenazione Una volta presente una collisione lo si inserisce nella lista concatenata presente in quella locazione. Questa lista in posizione precisa la chiamo lista di trabocco.\nAnalisi del concatenamento (ottimo e pessimo)\nAnalisi nel caso medio\nUna volta definito questo fattore di carico riesco a dimostrare il costo per la ricerca con successo e senza successo, e si ha che entrambi hanno costo\n$\\Theta(1 + \\alpha)$\nIndirizzamento aperto L\u0026rsquo;inserimento viene messo nel prossimo slot aperto.\nSlide\nL\u0026rsquo;idea principale Ã¨ quella dellâ€™ispezione.\nLa funzione di hash Ã¨ estesa con un altra funzione di ispezione che visita gli indici di una tabella permutata in modo sempre che sia visitata ogni cella una singola volta.\nPseudocodice per insert, search e delete\nL\u0026rsquo;idea principale Ã¨ mettere nella cella in cui si elimina un valore deleted per marcare la cancellazione, cosÃ¬ search continua a cercare dopo invece di fermarsi, subito (come se avessi perso la testa in un linked list).\nAnalisi:\nPeggiore: devo percorre l\u0026rsquo;intero array per inserire, eliminare o cercare, quindi O(n)\nMedio: dipende dall\u0026rsquo;ispezione, quindi andiamo ora ad analizzare l\u0026rsquo;ispezione.\nAssunzioni\nTeoremi su ricerca ad indirizzamento aperto\nStrategie di ispezione per lâ€™hashing aperto (3) Ispezione lineare\nÃ¨ in una forma\n$h(k,i) = (h'(k) + i) \\mod n$\nContinua a guardare la cella successiva se quella precedente Ã¨ occupata.\nProblema del clustering primario (vicino)\nPraticamente Ã¨ abbastanza probabile che ci siano un sacco di sequenze vicine essere occupate (mentre altre sono basse). Ãˆ un fenomeno che non si vuole avere!\nToglie l\u0026rsquo;uniformitÃ  di occupazione! cosa che non va bene.\nEsempio di clustering\nCome si vede, le celle di hash 3 sono inframezzate molto! creando quella lunghissima linea di cellette occupate.\nAnalisi del costo medio (differente negli altri due casi esposti qui)\nIspezione quadratica\n$h(k, i) = h'(k) + c_1i + c_2i^2 \\mod n$\nAnche questo metodo di ispezione crea un clustering, che perÃ² Ã¨ secondario, ossia creano collezioni di celle lontano rispetto alla cella trovata.\nClustering secondario\nComunque questo tipo di clustering Ã¨ migliore rispetto al clustering primario\nDoppio hashing\n$h(k, i) = h_1(k) + ih_2(k) \\mod n$\nSlide\nEsempio\n","permalink":"https://flecart.github.io/notes/tabelle-di-hash/","summary":"Ripasso Prox: 20 Ripasso: May 19, 2022 Ultima modifica: April 30, 2022 10:54 AM Primo Abbozzo: March 22, 2022 11:41 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\n5 Tabelle di Hash 5.1 Introduzione 5.1.1 Prototipo Vogliamo implementare le operazioni del prototipo dizionario presentato in Strutture di dati elementari, e vogliamo fare solo queste 3 ma molto bene.\nInsert O(1) Delete O(1) Search in O(1) La struttura dati di hash riesce a fare bene queste singole operazioni","title":"Tabelle di hash"},{"content":"Ripasso Prox: 23 Ripasso: May 15, 2022 Ultima modifica: April 30, 2022 10:35 AM Primo Abbozzo: March 25, 2022 9:34 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 6 Algoritmi di Ordinamento 6.1 Introduzione 6.1.1 Lâ€™importanza del topic Gli algoritmi di ordinamento sono molto di base per la comprensione dell\u0026rsquo;ampio raggio degli algoritmi. Utilizzano l\u0026rsquo;analisi, introducono tecniche di risoluzione dei problemi computazionali come greedy, divide et impera e simile. Permettono un primo uso di astrazioni e l\u0026rsquo;analisi di sottoproblemi.\n6.1.2 Il problema Il problema Ã¨ trovare una permutazione di un insieme di numeri iniziali tale per cui tale insieme di numeri si ordinato:\nQuesto si puÃ² fare con qualunque collezione confrontabile fra di loro.\nSlide\nLoco: non vengono utilizzati array di appoggio, per esempio un quicksort sarÃ  di in loco, mentre mergesort no.\nStabile: se due elementi hanno la stessa chiave, questi compaiono con lo stesso ordine nell\u0026rsquo;array ordinato, per esempio radix sort Ã¨ stabile, merge sort Ã¨ stabile.\n6.2 Algoritmi incrementali Si possono dire incrementali algoritmi che si dimostrano in \u0026ldquo;maniera greedy\u0026rdquo;, ossia creano un sottoaray ordinato k, e al prossimo passo provano a creare un array k + 1.\n6.2.1 Selection sort Si trova l\u0026rsquo;elemento piÃ¹ piccolo all\u0026rsquo;interno di $(k+1,n)$ e lo si swappa con quello in posizione k + 1, si continua cosÃ¬ fino a quando l\u0026rsquo;array non sia ordinato. NO stabile (spara dall\u0026rsquo;altra parte l\u0026rsquo;elemento con cui swappa).\nUna proprietÃ  che possiede selection ma non insertion Ã¨ che:\n$\\forall e \\in (1,k), \\forall b \\in (k + 1, n), e ","permalink":"https://flecart.github.io/notes/algoritmi-di-ordinamento/","summary":"Ripasso Prox: 23 Ripasso: May 15, 2022 Ultima modifica: April 30, 2022 10:35 AM Primo Abbozzo: March 25, 2022 9:34 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 6 Algoritmi di Ordinamento 6.1 Introduzione 6.1.1 Lâ€™importanza del topic Gli algoritmi di ordinamento sono molto di base per la comprensione dell\u0026rsquo;ampio raggio degli algoritmi. Utilizzano l\u0026rsquo;analisi, introducono tecniche di risoluzione dei problemi computazionali come greedy, divide et impera e simile. Permettono un primo uso di astrazioni e l\u0026rsquo;analisi di sottoproblemi.","title":"Algoritmi di ordinamento"},{"content":"Introduzione al design logico Conoscenze sul carico dell\u0026rsquo;applicazione, ossia se ha piÃ¹ read rispetto a writes per esempio, sono dei priors in pratica Un design concettuale spiegato in precedenza. E si avrÃ  in output un design logico con anche un po\u0026rsquo; di documentazione. bisogna in questa fase valutare la performance principalmente su indicatori, ossia una operazione quante istanze visiterÃ ? Invece di garanzie sul numero di transazioni al secondo.\nIndicatori visti (2) Costo di una operazione: viene valutato in termini di numero di occorrenze di entitÃ  e associazioni che mediamente vanno visitate per rispondere a una operazione sulla base dÃ¬ dati; questa schematizzazione Ã¨ molto forte e, pur nelle semplici valutazioni che svilupperemo, sarÃ  talvolta necessario riferirci a un criterio piÃ¹ fine; Occupazione di memoria: viene valutato in termini dello spazio di memoria (misurato per esempio in numero di byte) necessario per memorizzare i dati descritti dallo schema.\nI volumi sono un concetto importante, sono una stima di quante entries dovranno avere, e serve per avere una idea di come progettare quella cosa. Bisogna utilizzare questi indicatori per valutare in che modo progettare la ristrutturazione e la logica.\nNOTA: C\u0026rsquo;Ã¨ un modo molto piÃ¹ complicato per fare questa analisi, ma per questo corso Ã¨ ok valutare solo queste.\nMetodi di ristrutturazione E-R Redundancies analysis Per la ridondanza bisogna fare una analisi di efficienza per capire se Ã¨ buono o meno lasciare la ridondanza.\nTipologie di ridondanze (4) ðŸŸ¨+ Per il prof Ã¨ importante due cose:\nAttributi derivabili\nAssociazioni derivabili\nAttributi derivabili da cose della stessa entitÃ \nAttributi derivabili da altri\nattributi derivabili da conteggio\nAssociazioni derivabili dalla composizione di altre associazioni in presenza di cicli\nEsempi: Nell\u0026rsquo;ultimo esempio, basta fare la join per avere quella informazione, un ciclo implica una ridondanza in pratica.\nGeneralizations deletion We need to delete the generalizations because in ER explained in Design del database the generalizations are not possible. A common way to fix this is embed children in the parent or something very similar.\nExample of deletion of generalization (3) ðŸŸ©- In un caso abbiamo che il genitore prende tutti i campi. Oppure elimina il genitore e metti due relazioni Oppure crea relazioni col genitore Ma come fare a scegliere la versione corretta? Vogliamo prendere la soluzione che ci permette di minimizzare il numero di accessi, come per esempio se sappiamo che figli e genitori vengono acceduti insieme, ha senso usare la freccia in basso a sinistra! Partitioning or grouping of entities Se una stessa entitÃ  ha due attributi molto diverti, ossia c\u0026rsquo;Ã¨ solamente un accesso per uno, invece che per tutti, potrebbe avere senso dividerli. In modo simile se ho due entitÃ  che vengono spesso accedute assieme potrebbe essere una cosa sensata accorparli assieme.\nL\u0026rsquo;obiettivo Ã¨ sempre efficienza degli accessi.\nPartizionamento verticale o orizzontale ðŸŸ©- Possiamo fare partizionamento in verticale o in orizzontale Verticale quando spezziamo una entitÃ  in due e le relazioniamo (utile quando accediamo solamente certe cose della tavola).\nOrizzontale quando ad esempio provo a dividere correnti e passati (dividere la stessa relazione in piÃ¹ forme!). ### Identifying the primary keys (non fare) Questo passo Ã¨ chiaramente il passo necessario per utilizzare E-R nel nostro caso. Informazioni necessarie Le chiavi primarie in certi contesti possono essere complessi! E anche utili per identificare, non ho capito bene l\u0026rsquo;esempio del ferramenta fatto in classe (una nota Ã¨ che i ferramenta si fanno codici enormi e complessi come chiavi ed Ã¨ una brutta pratica probabilmente). Notare che saranno usate spesso, quindi non farle grosseeee! La cosa semplice Ã¨ creare codici identificativi, invece di avere chiavi complesse.\nTraduzione in schema logico Tradurre relazioni ðŸŸ© Questa tabella riassume praticamente tutto. (303 Atzeni) La singola relazione ðŸŸ© Una volta che abbiamo una relazione in E-R possiamo creare una tavola anche per questa parte! L\u0026rsquo;importante quando facciamo questo, bisogna encodare una referential integrity constraint che Ã¨ la cosa bella della tabella.\nLa nota Ã¨ che aggiungere la constraint non Ã¨ sufficiente per tenere in considerazione vincoli di cardinalitÃ . Anche se Ã¨ n-aria si puÃ² modellizzare senza troppi problemi!\n#### Relazioni ricorsive ðŸŸ© La seconda tabella modella la parte ricorsiva (in teoria le due chiavi foreign dovrebbero essere code e code, ma il nome Ã¨ migliore in questo modo per esprimere questa relazione) Merge di relazioni A volte puÃ² essere utile unire relazione con l\u0026rsquo;entitÃ , succede spesso per relazioni unarie da una parte, perchÃ© cosÃ¬ faccio enforcing del 1. Ãˆ una cosa principalmente pratica, di difficile formalizzazione, ma deve passare l\u0026rsquo;idea diciamo.\n","permalink":"https://flecart.github.io/notes/database-logical-design/","summary":"Introduzione al design logico Conoscenze sul carico dell\u0026rsquo;applicazione, ossia se ha piÃ¹ read rispetto a writes per esempio, sono dei priors in pratica Un design concettuale spiegato in precedenza. E si avrÃ  in output un design logico con anche un po\u0026rsquo; di documentazione. bisogna in questa fase valutare la performance principalmente su indicatori, ossia una operazione quante istanze visiterÃ ? Invece di garanzie sul numero di transazioni al secondo.\nIndicatori visti (2) Costo di una operazione: viene valutato in termini di numero di occorrenze di entitÃ  e associazioni che mediamente vanno visitate per rispondere a una operazione sulla base dÃ¬ dati; questa schematizzazione Ã¨ molto forte e, pur nelle semplici valutazioni che svilupperemo, sarÃ  talvolta necessario riferirci a un criterio piÃ¹ fine; Occupazione di memoria: viene valutato in termini dello spazio di memoria (misurato per esempio in numero di byte) necessario per memorizzare i dati descritti dallo schema.","title":"Database logical design"},{"content":"Ripasso Prox: 12 Ripasso: May 19, 2023 Ultima modifica: May 11, 2023 9:12 PM Primo Abbozzo: April 11, 2023 6:54 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Filesystem Introduzione PerchÃ© filesystem? ðŸŸ¨++ Questa Ã¨ l\u0026rsquo;idea presa dall\u0026rsquo;archivio, come se fosse un ufficio che deve tenere delle pratiche ordinate in cartelle e cartelloni.\nLâ€™utilizzo principale Ã¨ dare un interfaccia comune di accesso ai dispotitivi. perchÃ© dispositivi diversi hanno sotto modi di accedere diversi, questa interfaccia facilizza molto l\u0026rsquo;accesso.\nInformazioni dei files (5+) ðŸŸ¨ Il file Ã¨ lâ€™unitÃ  logica di memorizzazione. il formato che c\u0026rsquo;Ã¨ dentro Ã¨ gestito dallâ€™applicazione, non dal filesystem!\nSlide attributi di file\nCi sono un sacco di informazioni memorizzate nei file (un sacco di metadata anche)\nNome Data e ora di accesso o modifica Informazioni sullâ€™ownership e protezione di accesso. Dimensione del file TIpo del file Categorizzazione dei files (3) ðŸŸ©- Tipi di files\nPossiamo andare a distinguere i files a seconda del\nContenuto (se contiene codice oggetto, se contiene dati o informazioni) Struttura, se sono plain text sequenze di bytes, oppure dati strutturati come database., e possono anche essere un albero**.** UNIX: files speciali (blocchi o caratteri), pipes, oltre ai classici files e directories. NOTA: ci sono molte cose che sono viste come files, in unix tutto Ã¨ un file :D. Sono identificati da una coppia di numeri che identificano il device driver Files in sistemi operativi comuni ðŸŸ© I files sono nati con la metafora dellâ€™ufficio:\nArchivi di informazione, che vanno aperti e richiusi (messi nella loro collocazione corretta) Ãˆ utile conoscere il tipo di file per capire quale utilizzo andiamo a fare di essa.\nCâ€™Ã¨ un tradeoff, se ho tanti tipi di files, il sistema operativo diventa molto piÃ¹ complesso, se ho troppi pochi potrebbero essere troppo generali.\nSlide tradeoff tipologie di files\nTecniche di identificazione dei file (3) ðŸŸ© Slide riconoscimento dei files\nGeneralmente ci sono 3 modi per riconoscere il tipo di files:\nMagic numbers Attributo tipo del filesystem estensione. Rispettivamente queste tecniche sono utilizzate in:\nWin (estensioni) Mac, informazioni aggiuntive sui files Unix, il magic number allâ€™inizio dei files Slide metodi di riconoscimento nei sistemi di riconoscimento\nUnix riconosce solamente gli eseguibili, in questo senso Ã¨ minimalista.\nCol magic number riesce anche a riconoscere lâ€™architettura target dellâ€™eseguibile.\nMac OS ha un codice identificativo per un programma che ha creato il file o la risorsa.\nWindows guarda l\u0026rsquo;estensione. che solitamente sempre da 3 caratteri. (inizilamente il nome del file aveva solo 8 caratteri.\nMetodi di accesso comuni (3) Slide metodi di accesso\nseguenziale\ndiretto\nindicizzato\nUno di particolare interesse Ã¨ INDICIZZATO, che si usa spesso per i databases:\nSlide metodo di accesso ad indice\nOperazioni sui files ðŸŸ¨ Slide lista delle operazioni\nLâ€™apertura Ã¨ una operazione molto costosa, bisogna\nTrovare i files Capire se si hanno i permessi corretti per poter leggere, o scrivere sul file. Questo si collega molto bene con la metafora dellâ€™ufficio e con lâ€™archivio. Se ne ho bisogno vado a prendere dallâ€™archivio e la apro se mi serve. Una volta finito lo si rimette apposto.\nNote sullâ€™apertura e chiusura dei files\nDirectories Introduzione alle directories ðŸŸ¨ Slide directories\nÃˆ quindi un file speciale che contiene le informazioni di accesso per la gestione dei files al suo interno.\nA seconda dellâ€™implementazione possono essere degli array lineari oppure degli hashtable. (si pensi a quanto possano essere grandi le directories, se uso una lista diventa molto lento, se invece si sa giÃ  che sia piccola si perde del tempo a fare lâ€™hash).\nInformazioni nelle directories (2) ðŸŸ¨ Slide informazioni delle directories\nSono contenuti i-nodes, che sono degli indici per andare a comprendere la struttura dei files.\nMa puÃ² cambiare, questo Ã¨ un fatto implementativo, potrebbe benissimo anche essere messo nelle entries della directory.\nUNIX â†’ messe negli i-node\nMSDOS â†’ messe nelle dir entries.\nLunghezza dei nomi ðŸŸ¨ Introduzione al problema della lunghezza dei nomi\nAnche qui facciamo distinzione fra nomi a lunghezza variabile e nomi fissi, MSDOS al tempo utilizzava nomi fissi con necessariamente estensioni a tre caratteri.\nMetodi per nomi a lunghezza variabile\nIl metodo a Ã¨ preferita, perchÃ© nel secondo devo leggere in fondo per trovare il nome del file\nDirectories a grafo aciclico I files, possono avere piÃ¹ nomi, in questo senso non ho piÃ¹ un albero ma un grafo.\nSlide struttura grafo aciclico\nSemantica di coerenza ðŸŸ¥ Dato che i sistemi moderni sono maggiormente tutti multitasking, vogliamo andare a specificare quando una modifica di un file puÃ² essere vista da un altro processo.\nimmediato: questa Ã¨ la semantica che viene utilizzata anche nei sistemi UNIX, una modifica Ã¨ subito vista da altri programmi. Bisogna chiedersi ora come si faccia ad implementare una cosa di questo genere.\nAFS: Ã¨ un esempio di file system interplanetario, in cui non era possibile fare una semantica imemdiata (i dati erano sparsi in mezzo al mondo). semantica di coerenza delle sessioni Ã¨ il nome di questo. ossia il file veniva modificato quando il file era chiuso. Questo era necessario perchÃ© ogni write dovevano rendere traffico sulla rete, era troppa questa sincronizzazione e troppo traffico direi.\nLa struttura Inode Allocazione Master Boot Record ðŸŸ¨+ Slide MBR\nQuesto Ã¨ il classico modo di fare partizioni, e si possono fare al massimo 4 partizioni.\nPraticamente Ã¨ una prima sezione del disco, che contiene una piccola tavola di partizioni, indice alla partizione attiva e informazioni per fare il boot, poi individua la sezione della partizione col boot, ed esegue quello per caricare il sistema operativo.\nÃˆ utile soprattutto per creare delle aree logiche diverse in cui possono esserci diverse informazioni.\n(altro Ã¨ global partitioning table anche GPT, che permette piÃ¹ partizioni)\nStruttura di una partizione (5) ðŸŸ©â€” Slide struttura partizione\nSlide spiegazione sezioni logiche della partizione\nUn boot block che c\u0026rsquo;Ã¨ sempre Superblock contiene informazioni per mount, ad esempio Ã¨ qui che si accorge se Ã¨ stato unmounted o mounted correttamente Alcune cose per gestire spazio libero ed occupato Directory root e poi il filesystem Ã¨ gestito come pare a seconda dei filesystem Allocazione contiguaðŸŸ©â€” Slide allocazione contigua\nSlide svantaggi allocazione contigua\nContigua nel senso che lo metto nel blocco di memoria contiguo libero.\nQuesto Ã¨ lâ€™implementazione piÃ¹ veloce, facile da indicizzare.\nIl problema principale Ã¨ che Ã¨ statico, per esempio non posso allargare il file giallo, si dovrebbe andare a cercare un blocco abbastanza largo per storare questo. Questo Ã¨ il problema principale.\nInfatti se ho un filesystem si sola lettura viene utilizzato questa tipologia di allocazione ISO9660\nAllocazione concatenata ðŸŸ¨ Slide allocazione concatenata\nSlide vantaggi svantaggi\nIn pratica in ogni blocco di dati abbiamo un indice per il prossimo (perÃ² Ã¨ lento perchÃ© sono molto sparsi, perchÃ© devo fare seek e i file vanno in molti posti, per questo dovrei lanciare defrags molto spesso, ma almeno i file possono crescere ed essere modificati liberamente)\nSVANTAGGI:\nAccesso inefficiente (posso solo inziare dall\u0026rsquo;inizio a scandire, non posso fare un offset) Ã¨ che i puntatori possono avere un grosso overhead per blocchi di dati piccoli. (e anche l\u0026rsquo;assunzione che il blocco di dati non Ã¨ piÃ¹ una potenza di due). Seek di file, che vengono dispersi per utto il disco Per limitare la frammentazione dei file e l\u0026rsquo;overhead posso utilizzare cluster\nSlide cluster blocchi\nAllocazione a File Allocation Table (FAT) ðŸŸ¨+ Slide FAT\nSlide svantaggi e vantaggi\nIn pratica ho una tabella apparte che mi dice in che modi i blocchi sono concatenati, in questo modo tolgo lâ€™overhead ai blocchi stessi e posso gestirmi apparte sti puntatori.\nSarebbe lento un accesso in piÃ¹ alla tabella fat, ma di solito questa viene caricata in RAM come se fosse una cache, quindi Ã¨ molto piÃ¹ veloce. (se poi il blocco Ã¨ grosso si dovrebbe perdere molto di meno).\nSarebbe lenta perchÃ© il disco dovrebbe andare avanti indietro ogni volta per accedere al blocco successivo.\nAllocazione indicizzata ðŸŸ¨++ Slide allocazione indicizzata\nIn pratica ho un blocco di dati che contiene solamente i blocchi di dati del file, questo permette un accesso diretto molto veloce. PerÃ² non posso avere una lunghezza a piacere del file, perchÃ© il numero di indici in un blocco di dati Ã¨ limitato (prima aveva dimensione a piacere).\nSlide svantaggi vantaggi2\nSOLUZIONE ALLA LIMITAZIONE INDICI:\nConcatenazione blocchi indici\nSlide soluzione concatenazione\nPerÃ² con questa soluzione torno ai problemi di accesso diretto lento e frammentazione delle allocazioni precedenti (â†’ prestazione degrada linearmente con i blocchi)\nMultilivello\nIndice multilivello\nQuesta cosa si puÃ² rendere ricorsiva, la prestazione degrada logaritmicamente, molto poco abbiamo una sorta di albero here.\nGestione dello spazio libero Bitmap Slide allocazione bitmap\nSlide vantaggi svantaggi\nHo praticamente una bitmap con un bit per ogni cluster, per indicare se Ã¨ libero occupato, una soluzioen simile Ã¨ anche utilizzata in Bitmap ðŸŸ© parlando di allocazione di pagine in RAM.\nLista concatenata Slide lista concatenata\nSlide svantaggi\nProblemi di frammetazione grossi, dato che i blocchi libero possono praticamente stare ovunque.\nAnche questo metodo l\u0026rsquo;abbiamo descritto in Paginazione e segmentazione, abbiamo anche una lista di bloccchi liberi per la FAT. ne abbiamo parlato anche in Gestione della memoria per la HEAP, gli algoritmi alla fine sono gli stessi.\nConfronto cluster dati e spazio utilizzato Slide confronto cluster e spazio\nNotiamo che dopo un certo punto se abbiamo un blocco di dati troppo grosso il disco lo utilizziamo poco ma il rate dei dati Ã¨ molto bello. Quindi se ho dati grossi ho buona roba.\nIn UNIX Multilivello in unix. Ci sono tanti file piccoli e pochi grandi, quelli grandi possono essere anche molto annidati con lâ€™allocazione indicizzata multilivello. I file piccoli sono molto veloci di accedere, sono praticamente subito accessibil\nSlide Allocaizone multilivello e unix\nLink hard e soft Slide link hard\nPer sistemi FAT questi non sono possibili solitamente. in unix Ã¨ identificato dallâ€™inode, se due cose indicano lo stesso inode ecco che posso creare un link, Ã¨ come se avessi due files per lo stesso inode.\nLa cancellazione logica Ã¨ proprio chiamata unlink, quando lâ€™ultimo nome del file Ã¨ tolto allora il file Ã¨ stato cancellato.\nIl soft link Ã¨ un file, il so capisce che Ã¨ un link, ma non si riferisce allo stesso inode.\nCurare e prevenire ðŸŸ¥ Curare il filesystem significa riportare lo stato del filesystem in uno stato coerente, ma non abbiamo garanzie riguardo che i files siano stati tutti salvati correttamente\nil check Ã¨ uno scan completo di tutto il filesystem\nSlide curare fsck\nPraticamente l\u0026rsquo;eseguibile fsck si va a ricostruire lâ€™albero degl inode, se non c\u0026rsquo;Ã¨ nessuna reference la mette nei lost and found, riporta tutti gli errori di block size e path names.\nPer filesystems che prevengono ,come ext3, prova a vedere tutto come una transazione, quindi va a registrare le operazioni riguardo il filesystem in un singolo file. Dopo ciÃ² si mette a farlo. Ã¨ idempotente.\nSlide transazioni\nConcatenata /h3\nFAT\n","permalink":"https://flecart.github.io/notes/filesystem/","summary":"Ripasso Prox: 12 Ripasso: May 19, 2023 Ultima modifica: May 11, 2023 9:12 PM Primo Abbozzo: April 11, 2023 6:54 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ—ðŸŒ‘ Studi Personali: No\nElementi di ripasso Filesystem Introduzione PerchÃ© filesystem? ðŸŸ¨++ Questa Ã¨ l\u0026rsquo;idea presa dall\u0026rsquo;archivio, come se fosse un ufficio che deve tenere delle pratiche ordinate in cartelle e cartelloni.\nLâ€™utilizzo principale Ã¨ dare un interfaccia comune di accesso ai dispotitivi. perchÃ© dispositivi diversi hanno sotto modi di accedere diversi, questa interfaccia facilizza molto l\u0026rsquo;accesso.","title":"Filesystem"},{"content":"Ripasso Prox: 30 Ripasso: May 18, 2023 Ultima modifica: April 22, 2023 11:23 AM Primo Abbozzo: March 25, 2023 11:49 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Fn Ordine superiore Questa parte Ã¨ strettamente collegata conl a parte di Astrazione sul controllo.\nSi parla di passare le funzioni come dati. e quindi possono essere passati come se fossero dei parametri.\nun linguaggio di programmazione Ã¨ di ordine superiore qualora ammetta funzioni sia come parametro che come risultato di altre funzioni.\nLa parte molto simile alla precedente Ã¨ il fatto di valutare la funzione nell\u0026rsquo;ambiente iniziale, quindi bisogna utilizzare un sistema simile a quello del passaggio per nome.\nDeep and shallow binding ðŸŸ© Esempio di passaggio di funzione\nSi noti che questa distinzione fra scope statico e dinamico Ã¨ indipendente da queste regole di shallow e deep binding, queste regole qui ci dicono quale ambiente scegliere per la valutazione, mentre le altre ci dicono in che modo percorrere le catene, se andare per catena dinamica o statica.\nDEEP BINDING\nIn questo caso viene associato alla funzione la x presente al momento di creazione del binding. Nellâ€™esempio di sopra la x in riga 11. se ho scope dinamico, invece quello a riga 2 se ho scope statico\nSHALLOW BINDING\nIn questo caso lâ€™ultimo binding possibile, quando sono proprio dentro la funzione (quindi la x attiva in quellâ€™ambiente). Nellâ€™esempio di sopra la x in riga 5. Quindi si valuta la funzione al momento della chiamata.\nImplementazione del shallow binding ðŸŸ© Questa Ã¨ l\u0026rsquo;implementazione semplice, praticamente uguale allo scope dinamico in Nomi e Scope. Quindi cerco lâ€™ultima istanza presente fra tutte quelle presenti (se voglio scope statico, risalgo catena statica, altrimenti risalgo catena dinamica). Esattamente come si faceva per lo scope dinamico, infatti si potrebbe dire che Ã¨ piÃ¹ naturale utilizzare scope dinamico con questo, anche se si potrebbe senza problemi utilizzare scope statico!.\nQuesto perchÃ© lâ€™ultima presente era quella ancora presente nellâ€™ambiente di chiamata!\nImplementazione del deep binding ðŸŸ© Abbiamo detto che vogliamo valutare il deep binding seguendo la sua struttura (in questo caso statico, oppure nello scope di chiamata, in quel caso dinamico).\nQuesto Ã¨ easy, si segue direttamente lo stesso sistema fatto per il nome e per la catena statica, passando una coppia (funzione, ambiente) chiamata chiusura della funzione, la funzione sarÃ  il puntatore al codice, mentre l\u0026rsquo;ambiente Ã¨ determinato cosÃ¬:\nSTATICO\nIn questo caso devo mettere nel puntatore dâ€™ambiente in cui la nostra funzione Ã¨ dichiarata, questo si puÃ² avere a tempo di compilazione, perchÃ© conosco il livello di annidamento della funzione, e anche al momento della creazione del binding, quindi utilizzo un sistema simile in Nomi e Scope. (quindi scorrere la catena statica con la differenza che conosco, oppure display).\nDINAMICO\nIn questo caso basta mettere l\u0026rsquo;ambiente in cui metto creo il binding fra parametro formale e attuale.\nIl caso del C ðŸŸ© In C non abbiamo cose come i lambda, non abbiamo quindi problemi di risoluzione di ambienti, perchÃ© tanto non posso dichiarare funzioni in ambienti non locali.\nSemplicemente in C tutte le funzioni passate come parametro vengono risolte nell\u0026rsquo;ambiente globale. Non c\u0026rsquo;Ã¨ proprio la necessitÃ  di utilizzare la catena statica! Tutto risolto a compile-time.\nFunzioni come ritorno di funzione ðŸŸ© Quello che viene ritornato Ã¨ una chiusura, ma come valutare una chiusura in un ambiente che Ã¨ giÃ  scomparso :O ?? Scomparso nel senso che non lâ€™avremmo piÃ¹ sulla stack sto ambiente! Non possiamo fare altro che utilizzare un ambinete illimitato di vita. E dare la responsabilitÃ  al garbace collector l\u0026rsquo;onere di liberare questo ambiente.\n","permalink":"https://flecart.github.io/notes/fn-ordine-superiore/","summary":"Ripasso Prox: 30 Ripasso: May 18, 2023 Ultima modifica: April 22, 2023 11:23 AM Primo Abbozzo: March 25, 2023 11:49 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Fn Ordine superiore Questa parte Ã¨ strettamente collegata conl a parte di Astrazione sul controllo.\nSi parla di passare le funzioni come dati. e quindi possono essere passati come se fossero dei parametri.\nun linguaggio di programmazione Ã¨ di ordine superiore qualora ammetta funzioni sia come parametro che come risultato di altre funzioni.","title":"Fn Ordine superiore"},{"content":"Ripasso Prox: 10 Ripasso: May 20, 2023 Ultima modifica: May 11, 2023 8:17 PM Primo Abbozzo: April 17, 2023 11:10 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Garbage Collection On dangling pointers Tombstones ðŸŸ© Slides tombstones\nQuando alloco, alloco anche una tombstone, e tutti i riferimenti passano per quella. (quindi ho due dereference per lâ€™accesso) quando vado a deallocare segno la tombstone come RIP, NULL.\nDopo molto tempo ho il problema del cimitero che diventa molto grande. Anche se non punta piÃ¹ a niente, il cimitero.\nKeys and locks ðŸŸ© Un pÃ² di overhead in piÃ¹ dal punto di vista della memoria, che Ã¨ doppio\nOn GC Reference counting ðŸŸ© Quando alloco, mi tengo anche un contatore di riferimenti, ossia puntatori che fanno riferimento a questo blocco. Quando arriva a zero dealloco. Questo Ã¨ una variabile privata del GC, non Ã¨ accessibile da nessuna parte dallâ€™esterno.\nCome fare per riferimenti ricorsivi? Se avessimo due elementi che si puntano fra di loro ma non sono accessibili tramite stack?\nCon questa tecnica non Ã¨ possibile risolverlo bisogna utilizzare il metodo successivo.\nMark and sweep ðŸŸ© Slide tecnica mark and sweep\nDefinito in due parti:\nFase di detection, in cui parto marcando tutto, poi se riesco a raggiungerlo tolgo il mark. remotion vado a rimuovere tutti quelli marcati (alla fine Ã¨ la stessa cosa marcare non marcare, basta invertire), in questo modo riconosco tutti i pezzi i memoria non raggiungibili e so cosa andare a togliere. Svantaggio principale:\nNon so quando andare a fare mark and sweep:\nOgni tot tempo Quando finisco la memoria (ogni tot memoria). Quando fa GC devo fermare il programma (stop the world) perchÃ© non ha senso che inserisco cose quando vado a marcare (pensala come modify list quando ci scorri). Per sistemi realtype non funziona proprio, perchÃ© non posso permettermi di bloccare la computazione. Implementazione: invesione dei puntatori ðŸŸ¨+ Come facciamo ad implementare questa tecnica quando magari Ã¨ invocata solamente quando ho finito lo spazio? Non possiamo utilizzare la stack, perchÃ© la memoria Ã¨ finita.\nSi utilizza la tecnica di inversione dei puntatori:\nSlide inversione dei puntatori\nStop and copy Slide tecnica stop and copy\nLa heap Ã¨ divisa in due regioni differenti, quando una Ã¨ piena (credo) copio tutto nell\u0026rsquo;altra zona. Questo Ã¨ buono quando ho pochi blocchi ancora buoni, perchÃ© ci metterei molto meno a spostare e emttere nellâ€™altra.y\nBorrow checking (non fatto) Questa Ã¨ la cosa nuova introdotta da Rust.\nOwnership Lifetimes ","permalink":"https://flecart.github.io/notes/garbage-collection/","summary":"Ripasso Prox: 10 Ripasso: May 20, 2023 Ultima modifica: May 11, 2023 8:17 PM Primo Abbozzo: April 17, 2023 11:10 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Garbage Collection On dangling pointers Tombstones ðŸŸ© Slides tombstones\nQuando alloco, alloco anche una tombstone, e tutti i riferimenti passano per quella. (quindi ho due dereference per lâ€™accesso) quando vado a deallocare segno la tombstone come RIP, NULL.\nDopo molto tempo ho il problema del cimitero che diventa molto grande.","title":"Garbage Collection"},{"content":"Halting theorem Questo Ã¨ un problema fondamentale, che abbiamo trattato anche in Fondamenti teorica#Halting problem, ma qui lo ritrattiamo, perchÃ© cosÃ¬ lo rifacciamo per bene. In parte Ã¨ stato trattato anche al corso di Logica.\nEnunciato Halting theorem Questo Ã¨ molto simile a quanto presente sul (Sipser 2012). Ossia consideriamo il linguaggio $$ HALT = \\left\\{ \\langle x, y \\rangle : y = code(M),M \\text{ si ferma su } x\\right\\} $$ Dimostrazione Halting theorem La parte del sÃ¬ Ã¨ facile perchÃ© basta eseguirlo e vedere che si ferma (quindi abbiamo una La macchina di Turing#La macchina di Turing universale. Se si ferma appartiene al linguaggio, altrimenti Ã¨ la parte in cui diverge.\nDimostrazione non decidibilitÃ  Supponiamo sia decidibile e dimostriamo l\u0026rsquo;assurdo. Se esiste una macchina $f$ tale per cui decida quel linguaggio, $$ \\begin{cases} f(g, y) = 1, g(y) \\downarrow\\\\ \\\\ f(g, y) = 0, g(y) \\uparrow \\end{cases} $$ allora possiamo usare questa macchina per costruire un $h$ tale che per cui $$ \\begin{cases} h(g) = 1, f(g, g) = 0 \\\\ \\\\ h(g) = \\uparrow, f(g, g) = 1 \\end{cases} $$ Allora la computazione della funzione $h(h)$ genera un assurdo.\nIl motivo Ã¨ che $h(h) = 1 \\iff f(h, h) = 0 \\iff h(h) = \\uparrow$ Questa cosa dovrebbe essere riscritta in modo $code$ per essere comprensibile da macchine di Turing.\nOpposto di Halting theorem Ossia vogliamo riconoscere il linguaggio $$ HALT^{-} = \\left\\{ \\langle x, y \\rangle : y \\not= code(M) \\cup y=code(M) \\cap M \\text{ non si ferma su } x\\right\\} $$ Si puÃ² dimostrare che questo problema non Ã¨ nemmeno riconoscibile da nessuno!\nDimostrazione complemento di halting theorem Si ragiona anche qui per assurdo, se fosse riconoscibile, avremmo che Halting theorem principale sarebbe riconoscibile.\nMapping reducibility Definizione mapping reducibility Un linguaggio $L'$ Ã¨ riducibile a un altro linguaggio $L$ se esiste una funzione computabile totale $f : \\Sigma^{*} \\to \\Sigma^{*}$ tale che valga $$ x \\in L' \\iff f(x) \\in L $$ E si scrive che $L' \\leq L$ Ossia posso mappare qualunque parola in $L'$ in una stringa in $L$. Ãˆ molto importante che sia computabile, perchÃ© Ã¨ un modo di dire che non stiamo barando nella dimostrazione, e mi appoggio soltanto all\u0026rsquo;espressivitÃ  dei due linguaggi.\nProprietÃ  di decidibilitÃ  basilari Se $L$ Ã¨ decidibile, allora $\\forall L': L'\\leq L$ Ã¨ decidibile. Se $L'$ Ã¨ indecidibile allora lo Ã¨ anche $\\forall L: L' \\leq L$ perchÃ© altrimenti si avrebbe un assurdo Se $L$ Ã¨ decidibile e $L'$ no allora $L' \\not \\leq L$ altrimenti assurdo per il primo punto. Ogni linguaggio decidibile Ã¨ semplice Ossia se $L'$ Ã¨ decidibile allora per ogni $L$ tale che $L \\neq \\emptyset$ e $L \\neq \\Sigma^{*}$ Si ha che $$ L' \\leq L $$ Dimostrazione: Dato che $L'$ Ã¨ decidibile, esiste $g(x), \\forall x \\in \\Sigma^{*}$ tale che decide se $x$ appartiene o meno a quel linguaggio. Dato che $L$ Ã¨ finito, esiste un $\\omega$ che non appartiene e un altro $v$ che appartiene. Allora costruisco la funzione $f$ cosÃ¬:\nRunno $g$, se appartiene, mappo a $v$ Se non appartiene mappo a $\\omega$. Ez. IndecidibilitÃ  su nastro vuoto NOTA: in ogni caso devo vedere se il codice della macchina Ã¨ valido.\nDefinendo il linguaggio $$ ETH = \\left\\{ x \\in \\Sigma^{*}: x = code(\\mathcal{M}) \\text{ e } \\mathcal{M} \\text{ si ferma su } \\varepsilon \\right\\} $$ Per dimostrare ciÃ² basta dimostrare che $HALT \\leq ETH$ Ossia dobbiamo costruire una funzione che mappa ogni stringa di $HALT$ in una di $ETH$. Questo Ã¨ molto semplice, solo definire qualche dettaglio (non banale) IndicibilitÃ  ogni input Definiamo il linguaggio $$ FL = \\left\\{ x \\in \\Sigma^{*} : x = code(\\mathcal{M}) \\text{ e } \\mathcal{M} \\text{ ferma su ogni input} \\right\\} $$ Anche questo si puÃ² dimostrare in maniera simile al precedente, con una mapping reduction. Questo Ã¨ anche piÃ¹ semplice: Per ogni input $\\langle \\mathcal{M}, x \\rangle$ costruisco la seguente macchina\nLa macchina nuova prende un input $y$, la ignora per il momento, e simula $\\langle \\mathcal{M}, x \\rangle$. Se termina (e quindi appartiene a $HALT$) allora termino anche io ignorando l\u0026rsquo;input. Altrimenti divergo, e quindi non appartengo. Questa nuova macchina Ã¨ bona. Quindi funziona l\u0026rsquo;indicibilitÃ . Equivalence problem decidability $$ EQ = \\left\\{ \\langle y, x \\rangle \\in \\Sigma^{*} \\times \\Sigma^{*} : x = code(\\mathcal{M}), y = code(\\mathcal{M'}) \\text{ e } \\mathcal{M}, \\mathcal{M'} \\text{ hanno la stessa funzione parziale} \\right\\} $$ Anche in questo caso proviamo a ridurci al caso $FL$. Sempre come prima, per input $\\langle \\mathcal{M}\\rangle$ mi costruisco questa macchina Equivalence problem recognizability Il linguaggio del problema di equivalenza non Ã¨ nemmeno riconoscibile. Per fare ciÃ² devo ridurre $HALT^{-}$ a questo EQ. Dimostro la riduzione $HALT \\iff EQ^{-}$\nNota sulla gerarchia Cosa curiosa Ã¨ che $HALT$ Ã¨ il suo opposto non sono comparabili. Mentre ci aspetteremmo che HALT sia piÃ¹ semplice. Una altra cosa curiosa Ã¨ che EQ non Ã¨ riconoscibile, e nemmeno il suo opposto lo Ã¨. z\nTuring riducibilitÃ  Definizione di oracolo ðŸŸ© Dato un linguaggio $L$ e una stringa $x$, l\u0026rsquo;oracolo mi dice in tempo finito se $x \\in L$.\nDefinizione Turing-riducibilitÃ  ðŸŸ© Dato un $L'$ , questo Ã¨ Turing riducibile a $L$, quindi $L' \\leq_{TM} L$, se dato un oracolo per $L$ possiamo decidere $L'$\nMapping reducibility =\u0026gt; Turing-riducibilitÃ  ðŸŸ©- Possiamo dimostrare in modo semplice che con Turing-riducibilitÃ  $HALT$ Ã¨ riducibile a $HALT^{-}$. Senza problemi. Mentre non posso farlo con Mapping reducibility.\nReferences [1] Sipser â€œIntroduction to the Theory of Computationâ€ Cengage Learning 2012\n","permalink":"https://flecart.github.io/notes/halting-theorem-and-reducibility/","summary":"Halting theorem Questo Ã¨ un problema fondamentale, che abbiamo trattato anche in Fondamenti teorica#Halting problem, ma qui lo ritrattiamo, perchÃ© cosÃ¬ lo rifacciamo per bene. In parte Ã¨ stato trattato anche al corso di Logica.\nEnunciato Halting theorem Questo Ã¨ molto simile a quanto presente sul (Sipser 2012). Ossia consideriamo il linguaggio $$ HALT = \\left\\{ \\langle x, y \\rangle : y = code(M),M \\text{ si ferma su } x\\right\\} $$ Dimostrazione Halting theorem La parte del sÃ¬ Ã¨ facile perchÃ© basta eseguirlo e vedere che si ferma (quindi abbiamo una La macchina di Turing#La macchina di Turing universale.","title":"Halting Theorem and Reducibility"},{"content":"Ripasso Prox: 70 Ripasso: June 10, 2023 Ultima modifica: April 1, 2023 9:09 AM Primo Abbozzo: November 9, 2022 11:31 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Monitor Questo Ã¨ un modo di piÃ¹ alto livello per creare programmazione concorrente.\nIntroduzione Questo costrutto per la programmazione concorrente, prende molto dalla programmazione agli oggetti, abbiamo delle variabili presenti al monitor, private solamente accessibili ad essa, tramite procedure che sono mutex automaticamente!\nElementi costituenti ðŸŸ© Dati locali Sequenza di inizializzazione Procedure di entrata Appena provo a chiamare una procedura, questa Ã¨ fatta giÃ  in mutua esclusione!.\nE possono modificare dati locali solo tramite chiamate a sue procedure\nCose in slide\nVariabili di condizione ðŸŸ© Queste sono variabili utilizzate per sincronizzare lâ€™accesso,\nStrutture classiche\nPolitica del signal urgent (!) ðŸŸ© Slide\nLâ€™idea Ã¨ molto simile a quanto fatto per i signal presenti in Semafori, se qualcuno Ã¨ in attesa, dai subito il bastone a lui, altrimenti non fai niente.\nQuesta Ã¨ la politica di signalling che viene usata implicitamente in esame.\nAltre politiche di signalling (3) ðŸŸ¨ Slide\nDifferenze con semafori (3) ðŸŸ©- Slide\nSembrano simili la Wait e la signal con P e la V, ma sono cose totalmente diverse!!!!.\nSignal non ha nessun effetto se non ci sono processi in attesa, mentre V memorizza sempre Wait Ã¨ sempre bloccante! mentre P noâ€¦ Il processo risvegliato Ã¨ sempre eseguito per primo! (signal urgent). Implementazione dei semafori con monitor ðŸŸ© Slide\nÃˆ una implementazione molto facile! Per questo motivo ci piace abbastanza ðŸ˜€\nImplementazione monitor con semafori ðŸŸ¨+ Slide\nProblemi classici con monitor Readers and writers ðŸŸ¨+ la parte difficile di questa parte Ã¨ scrivere bene le invarianti, quindi Ã¨ molto piÃ¹ facile scrivere una soluzione una volta che si sa.\nDriver code\nReaderWriter controller\nVersione senza starvation !!!\nProducer and consumers ðŸŸ© Soluzione producer and consumers\nBuffer limitato ðŸŸ© Sol\nQuesta soluzione con i semafori Ã¨ molto piÃ¹ clean rispetto a quello dei semafori!\nbasta andare a verificare che le invarianti siano soddisfatte, riguardanti la possibilitÃ  di scrittura e la possiblitÃ  di lettura.\nFilosofi a cena Sol\nDriver code, dal punto di vista del filosofo\nWithout deadlock\nWithout deadlock, all destri!\nSoluzione con chopsticks\nuna cosa molto bella Ã¨ che che non Ã¨ deadlock nemmeno se sono tutti destri! il motivo Ã¨ che l\u0026rsquo;accesso Ã¨ sempre in mutua esclusione, il primo che va a prenderli Ã¨ buona roba.\nUlteriori delucidazioni su questa roba\nSupponiamo per assurdo che ci sia deadlock per la versione in cui i filosofi sono tutti destri. Supponiamo che siamo al filosofo $i$, questo prende la sua bacchetta, e deve aspettare la bacchetta successiva, fino a creare il ciclo. fino a qui abbiamo enunciato quello che deve succedere affinchÃ© ci sia deadlock. Ma questo non puÃ² succedere perchÃ© ogni filosofo guarda da solo se puÃ² prenderlo o meno (mi sembra che questa soluzione sia un poco meno efficiente rispetto a quello con i semafori, perchÃ© solamente un filosofo puÃ² prendereâ€¦)\n","permalink":"https://flecart.github.io/notes/monitor/","summary":"Ripasso Prox: 70 Ripasso: June 10, 2023 Ultima modifica: April 1, 2023 9:09 AM Primo Abbozzo: November 9, 2022 11:31 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Monitor Questo Ã¨ un modo di piÃ¹ alto livello per creare programmazione concorrente.\nIntroduzione Questo costrutto per la programmazione concorrente, prende molto dalla programmazione agli oggetti, abbiamo delle variabili presenti al monitor, private solamente accessibili ad essa, tramite procedure che sono mutex automaticamente!","title":"Monitor"},{"content":"Ultima modifica: January 3, 2023 3:59 PM Primo Abbozzo: January 3, 2023 3:58 PM Studi Personali: No\nElementi di ripasso Argomento https://groups.csail.mit.edu/tds/papers/Lynch/jacm88.pdf\n","permalink":"https://flecart.github.io/notes/partially-synchronous-model/","summary":"Ultima modifica: January 3, 2023 3:59 PM Primo Abbozzo: January 3, 2023 3:58 PM Studi Personali: No\nElementi di ripasso Argomento https://groups.csail.mit.edu/tds/papers/Lynch/jacm88.pdf","title":"Partially synchronous model"},{"content":"Ripasso Prox: 6 Ripasso: December 31, 2022 Ultima modifica: December 27, 2022 10:37 AM Primo Abbozzo: November 25, 2022 8:55 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nProgrammazione lineare Vogliamo cercare di restare nel nostro spazio delle soluzioni ammissibili, senza dover stare ad esplorare tutto, vogliamo andare a concentrarci su una parte specifica di essa. Vogliamo utilizzare una struttura fondamentale per i problemi di programmazione lineare, che Ã¨ quello con cui vogliamo andare a fare. Il fatto Ã¨ che spostandoci leggermente da un punto tra le soluzioni, possiamo gestire in modo molto semplice il modo con cui si sposta la retta dei valori.\nQuesto Ã¨ possiamo ridurci a considerare i vertici del poliedro che si costruisce, quindi andiamo in questa prima parte a definire alcune nozioni matematiche utili a mettere in gioco questa intuizione\nNozioni preliminari Vocabolario di base Iperpiano L\u0026rsquo;insieme delle soluzioni di equazioni in\n$$ \\left\\{ x \\in \\mathbb{R}^{n} \\mid a^{T}x = b, a \\neq 0 \\right\\} $$ E si puÃ² dimostrare che questo Ã¨ un insieme affine, quindi Ã¨ una linea. Questi piani sono anche convessi perchÃ© prendiamo tutti i punti ðŸ¤ .\nSemispazio $$ \\left\\{ x \\in \\mathbb{R}^{n} \\mid a^{T}x \\geq b, a \\neq 0 \\right\\} $$ Lo spazio Ã¨ diviso fra zone in cui Ã¨ maggiore e altre in cui Ã¨ minore. Questi non sono affini ma sono solo convessi (perchÃ© limitati in certe zone)\nPalla euclidea $$ B(x_{c}, r) = \\left\\{ x \\mid \\lvert x - x_{c} \\rvert _{2} \\leq r \\right\\} = \\left\\{ x _{c} + ru \\mid \\lvert u \\rvert _{2} \\leq 1 \\right\\} $$ Dove $r$ Ã¨ chiamato raggio.\nEllissoide Ãˆ un insieme formato in questo modo $$ \\left\\{ x \\mid (x - x_{c})^{T} P^{-1} (x - x_{c}) \\leq 1 \\right\\} $$ Quindi Ã¨ una forma quadratica quelle saltate in algebra. Nella pratica Ã¨ una palla, un po\u0026rsquo; allungata in certe direzioni descritte da $P$, che Ã¨ una matrice simmetrica definita positiva. ossia nell\u0026rsquo;insieme $S_{++}$ Si scrive anche a volte come $$ \\left\\{ x_{c} + Au \\mid \\lvert u \\rvert _{2} \\leq 1 \\right\\} $$ Poliedro Ãˆ una intersezione di un numero finito di $m$ semispazi come definiti di sopra inoltre non vogliamo che da nessuna parte si estenda all\u0026rsquo;infinito, quindi vogliamo che valga $$ \\left\\{ x \\mid Ax \\leq b \\right\\} $$ Per qualche valore di $A$ e $b$.\nUn poliedro Ã¨ una qualunque intersezione di semispazi (anche vuota, ma non Ã¨ molto interessante un poliedro vuoto), ed Ã¨ un insieme sempre convesso perchÃ© lâ€™intersezione di cose convesse Ã¨ ancora convesso.\nLâ€™amico del poliedro che deve essere per forza finito Ã¨ il politopo. (che Ã¨ la versione non bounded, ma alcuni autori utilizzano una definizione opposta, ma comunque non Ã¨ molto importante).)\nFacce ðŸŸ¨ Formalmente:\nPreso un poliedro, andiamo a definire una sua faccia, un insieme di punti che soddisfano queste caratteristiche:\nGiace direttamente su una o piÃ¹ condizioni Giace dentro il poliedro (quindi ogni punto della faccia Ã¨ un punto del poliedro anche!) Che matematicamente si possono andare a caratterizzare in questo modo: sia $I$ lâ€™insieme degli indici delle condizioni della matrice del poliedro che andiamo a prendere, e $\\bar{I}$ il suo complementare, allora\n$$ P_I = \\{x: A_Ix=b_I \\wedge A_{\\bar{I}}x \\leq b_{\\bar{I}} \\} $$ Intuitivamente L\u0026rsquo;intuizione per questa parte Ã¨ prendere un sottoinsieme che ci piace riguardante la nostra matrice, quella cosa corrisponderÃ  a una faccia del nostro poliedro.\nnozioni sulla dimensione della matrice finale Ã¨ molto buona, ci puÃ² dare un concetto di dimensione della faccia che andiamo a prendere. Per fare un esempio, se riusciamo ad avere una faccia di dimensione n, Ã¨ un singolo punto, quindi Ã¨ un vertice!\nin generale, come dicono le dispense vale la relazione sul fatto che\nE` possibile verificare che una faccia determinata da una matrice AI di rango k ha dimensione n âˆ’ k o inferiore, pagina 8 dispense 3.\nSpigoli e vertici e soluzioni base ðŸŸ© Una sottomatrice di dimensione n, Ã¨ un vertice!.\nUna sottomatrice di dimensione n - 1 Ã¨ uno spigolo!.\nQuesto sarÃ  il nostro spazio di ricerca quelli sui vertifici!\nSoluzione di base\nParlano dei vertici e lo fanno attraverso il concetto di invertibilitÃ . Una soluzione di base non Ã¨ detto che faccia parte del poliedro che stiamo andando a considerare! Vogliamo andare a considerare delle basi ammissibili ossia che sono anche all\u0026rsquo;interno del poliedro (un esempio ez. Ã¨ il vertice).\nMatrice di base, ammissibilitÃ  o non della base.\nVincoli attivi ðŸŸ¨+ I vincoli attivi sono vincoli del nostro problema che vengono soddisfatte come uguaglianze. Questa Ã¨ una cosa di interesse, per ragioni che mi sono ancora oscure.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Programmazione lineare/Untitled 2.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Programmazione lineare/Untitled 2\u0026quot;\u0026gt; Di importanza perÃ² Ã¨ la notazione $$ I(x) = \\{ i | A_ix = b_i\\} $$ Questa notazione piÃ¹ o meno ci dice quante righe della matrice sto andando poi a contare\nCose convesse Trattate un po\u0026rsquo; meglio in Analisi di ConvessitÃ .\nInviluppi convessi ðŸŸ© Queste cose ci sono molto utili, vanno simili al concetto di Base e dimensione, cercare di riassumere un insieme di punti illimitato con alcuni punti cardine limitati. In questo caso considero l\u0026rsquo;insieme , $X = \\{x_1, ..., x_n\\}$\n$$ conv(X) = \\{ \\sum _{i = 0} \\lambda_ix_i | \\sum_{i = 0} \\lambda_i = 1 \\land \\lambda_i \\geq 0\\} $$ Questo insieme ci Ã¨ sufficiente per avere un politopo, per il caso infinito dovremmo andare sui coni.\nPer ora basta avere un intuizione per questo. Riusciamo a costruire in questo modo tutti i spigoli che uniscono i nostri punti di vertice, e partendo da questi possiamo andare a costruire lâ€™intero politopo, ma la dimostrazione formale non la andiamo a dare.\nConi convessi See Analisi di ConvessitÃ #Convex Cone. Il concetto di cono convesso ci aiuta a costruire il caso infinito, considerando alcune operazioni di prolungamento e somma\n$x,y \\in C, \\lambda, \\beta \\in \\mathbb{R} \\implies \\lambda x + \\beta y \\in C$\nPossiamo provare a generalizzare questo concetto utilizzando la somma fra tutti i possibili\n$V = \\{ v_1, ... v_n\\}$\n$$ cono(V) = \\{ \\sum _{i = 1} \\lambda_i v_i | \\lambda_i \\in \\mathbb{R} ^+\\} $$ Teorema di Motzkin o di decomposizione (!) ðŸŸ¨+ Slide\nQuesto Ã¨ un teorema molto importante perchÃ© teorema caratterizzante dei poliedri!\nIntuizione\nPiÃ¹ o meno questo teorema ci dice che tutti i poliedri possono essere ridotti a un insieme di punti di partenza, che quasi vanno a formare una base (nel caso del politopo sono solamente questi punti di base, il cono che andiamo a considerare Ã¨ vuoto!) e poi poter estenderli in una direzione utilizzando il cono!\nDifferenza dimensione motzkin e vincoli\nLâ€™utilizzo piÃ¹ importante di questo teorema Ã¨ che possiamo caratterizzare i poliedri in modo molto piÃ¹ semplice, differentemente a quanto fatto con i vincoli lineari, perchÃ© quelli hanno unâ€™esplosione esponenziale per quanto riguarda il numero di vertici. (nota importnate Ã¨ che i vertici non si calcolano in modo molto veloce fra i vertici e i vincoli lineari!).\nVertici â†’ exp\nVincoli â†’ lin.\nQuesta differenza di crescita non ci piace proprio! Non ci piace andare a cercare il numero di vertici se questi vertici crescono in modo esponenziale!\nTh esistenza dellâ€™ottimo finito (!!) ðŸŸ¨++ Enunciato\nDimostrazione\nQuesto teorema lega in modo molto forte la parte di cono convesso con la soluzione del nostro problema lineare!\nossia possiamo avere soluzione solo se il cono non si espande verso l\u0026rsquo;infinito positivo, se succede, la soluzione ottimale Ã¨ infinito, altrimenti possiamo andare a scartare il contributo negativo del cono, e tenerci solamente il contributo dato dalla inviluppo convesso.\nTeoria della dualitÃ  Ãˆ una branca dell\u0026rsquo;algebra lineare che ci permette di semplificare tutti i concetti.\nIntro dualitÃ ðŸŸ© Slide\nSi fa una sorta di trasposta alla matrice di A.\ny Ã¨ pari al numero di righe di A\nLa trasformazione al duale Ã¨ molto facile, ed Ã¨ abbastanza intuitiva una volta che capiamo che vogliamo andare a fare lâ€™upper bound.\nDualitÃ  asimmetrica ðŸŸ¥+ Teorema debole di dualitÃ  ðŸŸ© Slide\nQui c\u0026rsquo;Ã¨ una cosa simile a quanto fatto in MCMF, il cui massimo di x Ã¨ boundato dal minimo del suo duale, in Tarjan e MCMF.\nCorollari di dualitÃ  (2) ðŸŸ© Slide\nil fatto che ci sia un bound a x, implica che se x Ã¨ illimitato, non posso avere il bound! Abbiamo una condizione di ottimalitÃ  delle soluzioni trovate! Def Direzioni ammissibili Vogliamo trovare un modo per muoverci e trovare ancora una direzione ottimale!\nDef:\nun vettore $\\varepsilon \\in \\R ^n$ Ã¨ una direzione ammissibile se esiste $\\bar{\\lambda} \u003e 0$ tale che $x(\\lambda) = x + \\lambda \\varepsilon$, per ogni $\\lambda \\in 0...\\bar{\\lambda}$\nIntuizione\nOssia se possiamo spostarci di almeno un pÃ² verso la direzione che vogliamo!\nDef direzione di crescita Possiamo considerare una direzione di crescita\n$**\\lambda \\iff cx(\\lambda) = c \\bar{x} + \\lambda c\\varepsilon \u003e c \\bar{x} \\iff c\\varepsilon \u003e 0**$\nLa cosa interessante Ã¨ che una direzione di crescita cresce indipendentemente dal punto, questo Ã¨ una proprietÃ  molto forte della programmazione lineare!\nQuesti due concetti sono molto utili perchÃ© una volta che abbiamo una direzione ammissibile e di crescita allora si puÃ² verificare che si puÃ² migliorare ancora la soluzione di x.\nSuff e nec per direzione ammissibile Slide\nL\u0026rsquo;idea principale per questa dimostrazione Ã¨ sui vincoli attivi, differenziare se una riga Ã¨ un vincolo attivo o meno. Se lo Ã¨ allora voglio che sia minore, altrimeni basta scegliere un intorno sufficientemente piccolo perchÃ© il vincolo Ã¨ stretto.\nDa notare che se non Ã¨ un vincolo attivo allora ho una disuguaglianza stretta allora posso andare ad utilizzare cose di analisi\nOttimalitÃ  del punto Dato un punto $x$ ammissibile, questo punto Ã¨ ottimo sse non ci sono direzioni di crescita ammisibile\nIntuizione sulla dimo\nâ†’ se Ã¨ giÃ  ottimo allora se esistessa una direzione di crescita, si potrebbe far crescere ancora il nostro punto di ottimo, violando lâ€™ipotesi di ottimalitÃ \nâ†Se non ho direzioni di crescita, supponendo per assurdo che non sia ottimo abbiamo allora possiamo trovare una direzione di crescita ammissibile, creando un assurdo, questa direzione la andiamo a trovare prendendo un punto ottimo e creando il vettore da questo punto a quello nostro iniziale.\nDimostrazione dispense\n!\n","permalink":"https://flecart.github.io/notes/programmazione-lineare/","summary":"Ripasso Prox: 6 Ripasso: December 31, 2022 Ultima modifica: December 27, 2022 10:37 AM Primo Abbozzo: November 25, 2022 8:55 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nProgrammazione lineare Vogliamo cercare di restare nel nostro spazio delle soluzioni ammissibili, senza dover stare ad esplorare tutto, vogliamo andare a concentrarci su una parte specifica di essa. Vogliamo utilizzare una struttura fondamentale per i problemi di programmazione lineare, che Ã¨ quello con cui vogliamo andare a fare.","title":"Programmazione lineare"},{"content":"Ripasso Prox: 30 Ripasso: May 30, 2022 Ultima modifica: October 19, 2022 5:02 PM Primo Abbozzo: March 12, 2022 11:51 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Tutte le proprietÃ  della basi, caratterizzazione delle dimensioni. 2 Basi e Dimensione 2.1 Basi 2.1.1 Definizione Un insieme di vettori $v_1,...,v_n$ sono basi di uno spazio vettoriale $V$ se sono soddisfatte queste proprietÃ \n$V = \\langle v_1,...,v_n\\rangle$ $v_1,...,v_n$ sono linearmente indipendenti Dalla proprietÃ  2 potremmo anche dire che Ã¨ il minimo insieme di vettori necessario per avere questa base.\nFinitamente generato\nSe l\u0026rsquo;insieme dei vettori nella base Ã¨ finito allora posso dire che Ã¨ finitamente generato\nMa possiamo trovare anche spazi che non sono finitamente generati come $\\R[x]$ che non hanno un numero finito di basi (perchÃ© dipende dal grado dei polinomi che puÃ² essere infinito).\nNota: base dello spazio vettoriale banale\nLa base dello spazio banale Ã¨ l\u0026rsquo;insieme vuoto!, se fosse il vettore 0, per definizione posso trovare un coefficiente diverso da 0 tale che sia zero. eg $1\\cdot 0_v = 0$ quindi non Ã¨ linearmente indipendente.\nNota sulla seguente carrellata di proposizioni\nLe seguenti proposizioni parlando della possibilitÃ  di generare le basi partendo da vettori linearmente indipendenti e aggiungendo fino a generare, o partendo da vettori che generano e togliendo finchÃ© non hai una base.\nDa questa idea generale si possono ricavare molte osservazioni, che sono elencate dalle proposizioni seguenti\n2.1.2 Minimali e massimali Si dice che una proprietÃ  Ã¨ minimale per un insieme, se ogni sottoinsieme proprio possiede piÃ¹ la proprietÃ \nE si dice che Ã¨ massimale se per ogni sovrainsieme proprio, questo insieme perde la proprietÃ \n2.1.3 Prop 4.1.4 Teorema caratterizzazione delle basi Questo teorema Ã¨ equivalente alla definizione data di base, solo che esprime il concetto utilizzando i minimali e massimali.\nEnunciato\nSi dice che un insieme di vettori $v_1, ..., v_n$ Ã¨ una base per uno spazio vettoriale sse:\nL\u0026rsquo;insieme massimale di vettori linearmente indipendenti Minimale di vettori generatori (cioÃ¨ se ne tolgo uno non genera piÃ¹, allora riesco a concludere che sono indipendenti) giÃ  vista nella 4.2.1 Si puÃ² notare come sia strettamente collegato alla 4.2.2\nIdee per la dimostrazione\nCaso 2$\\impliedby$Se mi prendo un insieme minimale di generatori, mi basta dimostrare che siano indipendenti per sapere che sia una base.\nSupponiamo per assurdo che siano dipendenti. Allora esiste un vettore linearmente dipendente, e quindi esprimibile come combinazione lineare di altri vettori 3.2.4, ma se Ã¨ una combinazione lineare allora non Ã¨ piÃ¹ l\u0026rsquo;insieme minimale di generatori (cioÃ¨ questo vettore non ha contributi sullo spazio) Ã¨ il teorema 3.1.8 qed.\nCaso 1 $\\impliedby$Se ho un insieme massimale di vettori linearmente indipendenti, voglio dimostrare che genera V.\nAllora per massimalitÃ  appena aggiungo un vettore, ho un insieme di vettori linearmente dipendenti, allora mi posso trovare una combinazione lineare con coefficienti non nulli tali che la combinazione sia 0.\nquindi $\\lambda_1v_1 + ...+ \\lambda_nv_n + \\beta w = 0$, e per qualunque vettore $\\omega$ so che $\\beta \\neq 0$ perchÃ© altrimenti si ha l\u0026rsquo;assurdo in quanto i vettori $v_1, ..., v_n$ sarebbero dipendenti. Se Ã¨ diverso da 0 allora posso esprimerlo come combinazione lineare di altro, quindi riesco ad ottenere l\u0026rsquo;intero spazio.\n2.1.4 Prop. creazione di base da vettori generatori Questo teorema ci permette di ricavare una base partendo da un insieme di vettori che generino l\u0026rsquo;intero spazio vettoriale. L\u0026rsquo;idea principale Ã¨ che possiamo trovare dei vettori che sono combinazioni lineari di altro e continuare a toglierli finchÃ© non trovo la base.\nEnunciato\nSia $v_1... v_n$ un insieme che genera $V$, allora un sottoinsieme di questi vettori generatori sono una base per $V$.\nDimostrazione\nSe i vettori sono linearmente indipendenti allora ho la base, se sono dipendenti allora sia $\\omega$ il vettore dipendente, allora si puÃ² scrivere come combinazione lineare per la 3.2.4, e per la proposizione 3.1.8 lo spazio generato da tali vettori Ã¨ esattamente lo stesso.\nPosso continuare con questo argomento finchÃ© non ottengo la base o non ci sono piÃ¹ vettori. (nel caso in cui Ã¨ lo spazio nullo).\nNota\nSi puÃ² fare anche il contrario, da un insieme di vettori linearmente indipendenti posso aggiungere vettori fino a quanto non creo una base, l\u0026rsquo;algoritmo Ã¨ molto simile, ma al contrario.\n2.1.5 prop 4.2.1 Teorema del completamento Enunciato\nDa una base $v_1,..., v_n$ e un insieme di vettori linearmente indipendenti $\\omega_1, ..., \\omega_m$ appartenenti allo stesso spazio allora so che $m \\leq n$, inoltre Ã¨ possibile aggiungere vettori a $\\omega$ in modo che sia una base, questa base ha la stessa cardinalitÃ  della base si sopra\nDimostrazione (non richiesta)\nSi utilizza la proposizione precedente al contrario probabilmente.\n2.2 Dimensione Il concetto di dimensione Ã¨ strettamente correlato con il concetto di base. Possiamo intendere la dimensione come il minimo insieme di coordinate necessarie per creare lâ€™intero spazio (questa Ã¨ una definizione che câ€™Ã¨ anche nel teorema di caratterizzazione delle basi). PerchÃ© alla fine saranno le coordinate che ci interessano.\n2.2.1 prop. 4.2.2 Basi hanno stessa dimensione DIMENSIONE (chiede) C\u0026rsquo;Ã¨ il teorema del completamento\nEnunciato\nDato uno spazio vettoriale finitamente generato, allora tutte le sue basi hanno la stessa cardinalitÃ , questo numero di chiama dimensione dello spazio vettoriale, ed Ã¨ una proprietÃ  caratterizzante di essa.\nDimostrazione\nMeglio una dimostrazione cosÃ¬: in quanto b1 Ã¨ base e b2 Ã¨ linearmente indipendente ho (per completamento) che $n \\geq m$, in quanto b2 Ã¨ base e b1 linearmente indipendente ho che $n \\leq m$, quindi $n = m$\n2.2.2 Basi canoniche Ci sono certe basi che sono particolarmente interessanti, le chiamiamo basi canoniche, e sono definite come\n$e_i = \\{0...0_{i-1},1,0_{i + 1},..., 0_n\\}$ ovvero ho un 1 alla n esima posizione\n2.2.3 prop 4.2.4 relazioni fra dimensioni Dato uno spazio vettoriale $W$e un suo sotto spazio $V$ si ha\n$dim(V) \\leq dim(W)$ $dim(V) = dim(W) \\iff V=W$ Dimostrazione\nCaso 1 Sia m la dimensione di $V$ allora la sua base ha m vettori che sono linearmente indipendenti. Questi vettori sono anche presenti in $W$, che poniamo abbia dimensione n, allora per il teorema del completamento ho che $m \\leq n$\nCaso 2 $\\impliedby$ questa freccia Ã¨ ovvia, se sono la stessa cosa hanno la stessa dimensione\nCaso 2 $\\implies$\nscambiare W e V in questa dimostrazione\n2.2.4 prop 4.2.6 Dimensione, base, lin ind, e generazione (3)! Enunciato\n3 to 1\nse ho un insieme di vettori che generano uno spazio allora posso togliere vettori fino a quando ho una base (ossia sono linearmente indipendenti). Ma per la dimensione ho che devo avere necessariamente n vettori, quindi un insieme di n vettori linearmente indipendenti Ã¨ giÃ  una base.\n2 to 1\nL\u0026rsquo;argomento presente qui Ã¨ uguale alla superiore 4.2.4 (quindi dire per il completamento che posso espandere e ottenere una base) Anzi potresti direttamente utilizzare questa per dimostrare sto punto\n2.2.5 Coordinate di un punto in uno spazio vettoriale Sia data una base per uno spazio vettoriale $v_1, ..., v_n$, allora ho che posso scrivere qualunque vettore $\\omega$ nello spazio in un unico modo, moltiplicando per corrispondenti fattori. Questi fattori sono unici.\nDimostrazione unicitÃ \n2.3 Algoritmo di gauss rivisitato 2.3.1 A.G non cambia sottospazio riga (non richiesta) L\u0026rsquo;intuizione per questo Ã¨ abbastanza ovvio, sto solamente applicando combinazioni lineari fra le righe, quindi sto sempre prendendo vettori che appartengono a questo spazio, non le sto modificando, questo giustificherebbe anche il motivo per cui l\u0026rsquo;algoritmo di gauss Ã¨ utile.\nDimostrazione\nla proposizione da utilizzare Ã¨ lo span che non cambia se aggiungo e tolgo una combinazione lineare\n2.3.2 Indipendenza delle righe non nulle Dimostrazione non fatta.\n3 Registro ripassi 12/03/ Qualche difficoltÃ  a dimostrare tutte le frecce per il teorema di caratterizzazione delle basi. 20/03 Tutto senza quasi nessuna difficoltÃ . 30/04 Tutto Ok lche difficoltÃ  a dimostrare tutte le frecce per il teorema di caratterizzazione delle basi. \u0026mdash; \u0026mdash; 20/03 Tutto senza quasi nessuna difficoltÃ . 30/04 Tutto Ok ","permalink":"https://flecart.github.io/notes/base-e-dimensione/","summary":"Ripasso Prox: 30 Ripasso: May 30, 2022 Ultima modifica: October 19, 2022 5:02 PM Primo Abbozzo: March 12, 2022 11:51 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Tutte le proprietÃ  della basi, caratterizzazione delle dimensioni. 2 Basi e Dimensione 2.1 Basi 2.1.1 Definizione Un insieme di vettori $v_1,...,v_n$ sono basi di uno spazio vettoriale $V$ se sono soddisfatte queste proprietÃ \n$V = \\langle v_1,...,v_n\\rangle$ $v_1,...,v_n$ sono linearmente indipendenti Dalla proprietÃ  2 potremmo anche dire che Ã¨ il minimo insieme di vettori necessario per avere questa base.","title":"Base e dimensione"},{"content":"Ripasso Prox: 7 Ultima modifica: January 27, 2023 2:29 PM Primo Abbozzo: December 29, 2022 3:49 PM Studi Personali: No\nElementi di ripasso Consensus protocols Introduzione Vogliamo tenere in modo sincronizzato alcune macchine, questo Ã¨ il nostro obiettivo. Questo Ã¨ un problema abbastanza difficileâ€¦ Come tenere in sinc se ci sono alcuni nodi maligni o la rete che non Ã¨ bona?\nAssunzioni principali (2) Esiste internet Esiste Crittografia Queste sono le assunzioni che non saranno mai rilassate per lâ€™intero corso, diciamo che sono la nostra base su cui possiamo andare a costruire la base per il nostro studio.\nDigital signature scheme Vorremmo avere un sistema per firmare alcuni documenti online, e possiamo dividere questa cosa in tre passi fondamentali\nQuesta roba esiste da molto tempo, dagli anni 80 o prima.\nAlgoritmi per digital signature (3) Una cosa importante Ã¨ che questi algoritmi di signature son oefficienti.\nGenerazione della chiave\nDeve essere nella forma $s \\to (pk, sk)$, ossia seed per public e secret key.\nFirma con la chiave\nDovrÃ  essere una funzione nella forma $msg + sk \\to msg + sig$. Da notare Ã¨ che la signature Ã¨ dipendente dal contenuto. Ma non possiamo utilizzarlo in questi ambienti elettronici perchÃ© Ã¨ troppo facile copiare ed incollare una forma. Deve essere per forza che dipenda\nDallâ€™identitÃ  di chi firma Da cosa vuole dire il firmatario. Verifica della chiave\n$msg + sig + pk \\to bool$, per capire se questa firma Ã¨ valida o meno, deve solamente dirmi questo valore booleano. In particolare la chiave Ã¨ pubblica quindi ognuno puÃ² venire a verificare un messaggio, ma puÃ² firmare solamente chi possiede la chiave privata.\nSicurezza (3 assunzioni) Lâ€™assunzione principale della sigurezza delle firme digitali Ã¨\nIdeal signatures: Se non conosci la chiave privata â‡’ non posso mai generare la coppia msg + sig corretta\nDelle volte Ã¨ possibile rompere questa cosa (e.g. con brute force se ci metto abbastanza poco per farlo). PerÃ² noi assumeremo che valga questo. E ha bisogno di risorse infinite per poter bruteforcare tutto se ha solamente quello come unica soluzione. Quindi una altra assunzione Ã¨ che lâ€™avversario ha risorse finite, polinomiali.\nAssunzione di complessitÃ  vogliamo che non ci siano algoritmi efficienti per risolvere qualcosa in modo molto veloce\nThe State Machine Replication (SMR) Problem Intuizione al problema Prendiamo uno state machine, in modo simile a quanto fatto in Linguaggi di programmazione, che ad ogni input e output cambia lo stato interno. Uno state machine puÃ² essere un database, ma puÃ² essere anche tutto lâ€™ambiente delle blockchain (e.g. mandare currency cambia lo stato) o un Automi e Regexp.\nLa replica Ã¨ necessaria per la performance, in modo che ci siano piÃ¹ macchine uguali che rendano lo stesso servizio. Ma se ho tante macchine che fanno la stessa cosa, devo in qualche modo farci il sync, ed ecco il problema che nasce dai database, il problema dei sync write e read. Per noi la replicazione Ã¨ lo stato della macchina gigante della blockchain.\nNel contesto di blockchain\nAvremo una lista di transazioni, che sono niente altro che delle richieste a un certo nodo di fare qualcosa, e si stora la storia delle transazioni, Ã¨ molto importate che lâ€™ordine sia consistente. Il problema del consenso diventa quindi provare a sincronizzare la transazioni, che nota, non devo essere money! Basta richieste.\nConsistency Questa Ã¨ la proprietÃ  che tutti i nodi sono dâ€™accordo sulla storia, permettendo la possibilitÃ  che qualche nodo sia indietro (ma devono essere dâ€™accordo su quella parte comune!)\nLiveness e Safety queste sono le stesse proprietÃ  descritte in Programmi Concorrenti. Con la liveness vogliamo che non ci siano deadlocks, e blocchi con la stessa logica â†’ alla fine il nodo dovrÃ  essere aggiunto!\n","permalink":"https://flecart.github.io/notes/consensus-protocols/","summary":"Ripasso Prox: 7 Ultima modifica: January 27, 2023 2:29 PM Primo Abbozzo: December 29, 2022 3:49 PM Studi Personali: No\nElementi di ripasso Consensus protocols Introduzione Vogliamo tenere in modo sincronizzato alcune macchine, questo Ã¨ il nostro obiettivo. Questo Ã¨ un problema abbastanza difficileâ€¦ Come tenere in sinc se ci sono alcuni nodi maligni o la rete che non Ã¨ bona?\nAssunzioni principali (2) Esiste internet Esiste Crittografia Queste sono le assunzioni che non saranno mai rilassate per lâ€™intero corso, diciamo che sono la nostra base su cui possiamo andare a costruire la base per il nostro studio.","title":"Consensus protocols"},{"content":"Ultima modifica: March 1, 2023 9:51 AM Primo Abbozzo: November 10, 2022 3:23 PM Studi Personali: No\nElementi di ripasso Argomento Execs execve runna e sostituisce\nl Ã¨ per list (credo variabili p adiche, invece che array terminato\nMemoria Brk mappo gli indirizzi fisici con gli indirizzi logici.\ndata ci stanno sopra un pochettino alla fine.\nheap sta in basso, mentre stack cresce a ritroso!!!\nCi stanno cose tipo la variabile globale. (lo stack cresce dallindirizzo massimo!)\nFiles Si traduce come pratica in itlaiano! Quando aperto con permessi che ci servono, andiamo a scrivere con certi modi.\ndup,\nIn passato si faceva differenza fra create e open perchÃ© una era per creare i file, lâ€™altra per aprire file giÃ  esistenti, ma alla fine\ncreate = open con O_CREAT | O_TRUNC | O_WRONLY\nDevices ioctl che â€¦ boh e fcntl,\nmount.\nmap carichiamo cose in memoria virtuale( quindi gli sembra di avere tutta la memoria disponibile) e si sfrutta il meccnaismo di risoluzione die questi address\nPoll In Linux, the poll system call is used to determine the status of a file descriptor, such as whether it is ready to be read or written to. The poll structure is used to specify the file descriptor(s) to be monitored and the events (such as availability of data to be read) to be checked for. The poll call returns a list of pollfd structures, each of which contains information about a file descriptor and the events that have occurred on that file descriptor.\nfd_set\nNote syscall Vedere System call ðŸŸ©- per note leggermente piÃ¹ approfondite sul processo di syscall.\nSettono alcune variabili nei registri e poi manda interrupt di syscall, e il kernel esegue la syscall adatta e restituisce sempre in un registro specifico il valore di ritorno. I parametri sono sempre 6 (non so perchÃ© sono sempre 6). Di solito se ritorna il valore -1 Ã¨ errore.\nFork permette di distinguere lâ€™esecuzione del figlio o del padre a seconda del valore di ritorno (il padre ha True, che Ã¨ il valore del pid, mentre per il figlio Ã¨ false.\n","permalink":"https://flecart.github.io/notes/sistem-programming/","summary":"Ultima modifica: March 1, 2023 9:51 AM Primo Abbozzo: November 10, 2022 3:23 PM Studi Personali: No\nElementi di ripasso Argomento Execs execve runna e sostituisce\nl Ã¨ per list (credo variabili p adiche, invece che array terminato\nMemoria Brk mappo gli indirizzi fisici con gli indirizzi logici.\ndata ci stanno sopra un pochettino alla fine.\nheap sta in basso, mentre stack cresce a ritroso!!!\nCi stanno cose tipo la variabile globale.","title":"Sistem programming"},{"content":"Ripasso Prox: 25 Ultima modifica: January 27, 2023 3:48 PM Primo Abbozzo: December 29, 2022 3:26 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Introduzione Blockchain stack Vogliamo andare ora a descrivere la stack delle blockchain, in modo simile a quanto fatto con le internet, perchÃ© anche qui possiamo organizzarlo a stack!\nNota: le astrazioni fra questi layer non sono definiti bene come osi osint.\nLayer - 0 Internet Internet (semi-reliable point-to-point communication) and cryptography (specifically, cryptographic hash functions and secure digital signatures).\nLayer - 1 Consensus Ci concentreremo sui protocolli di questo per la maggior parte di quanto faremo! Bitcoin, Ethereum sono tutti a questo livello.\nLayer - 2 Scaling layer Strano lol, cerca di rendere il livello 1 piÃ¹ efficiente. Le funzionalitÃ  sono le stesse, ma vorremmo che sia molto piÃ¹ veloce, probabilmetne Ã¨ un livello temporaneo che scomparirÃ  in futuro, ma per ora si fa molta ricerca su questo.\nLayer - 3 application Che tratta di smart contracts e applicazioni utente. Easy su questa roba, troppa roba, quindi la possiamo ignorare, perchÃ© non andremo a fare cose a questo livello.\nWhy itâ€™s new Computing paradigm Big programmable computer that lives on the sky! Owned by all users!\nOpen access computer! Global computational platform wo. Something with a very high potentiality!\nNot digital money! I soldi sono solamente un mezzo nuovo mezzo di scambio per questa robba. Ad esempio se utilizzi tropper risorse a questo computer, Ã¨ giusto che paghi lâ€™energia per runnare quello di cui hai bisogno!\nPrinciples over protocols Vogliamo andare ad individuare alcuniprincipi belli ** e vedere come vengono applicati sui protocolli!\n","permalink":"https://flecart.github.io/notes/introduzione-a-blockchain/","summary":"Ripasso Prox: 25 Ultima modifica: January 27, 2023 3:48 PM Primo Abbozzo: December 29, 2022 3:26 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Introduzione Blockchain stack Vogliamo andare ora a descrivere la stack delle blockchain, in modo simile a quanto fatto con le internet, perchÃ© anche qui possiamo organizzarlo a stack!\nNota: le astrazioni fra questi layer non sono definiti bene come osi osint.\nLayer - 0 Internet Internet (semi-reliable point-to-point communication) and cryptography (specifically, cryptographic hash functions and secure digital signatures).","title":"Introduzione a blockchain"},{"content":"Introduzione ai campi magnetici Introduzione storica (non impo) ðŸŸ© Il magnetismo Ã¨ stato in primi osservato e documentato da Greci, che hanno osservato che materiali metallici come ferro, questo Ã¨ successo in magnesia, una penisola dell\u0026rsquo;Asia minore, mentre elettro era piÃ¹ sull\u0026rsquo;ambra, che credo fosse il nome dato a quel materiale.\nUna cosa nota era che se vicino a un materiale magnetico, venivano create linee con materiale ferroso all\u0026rsquo;estremitÃ  (limatura magnetica).\nUna altra cosa, conosciuta dai cinesi, era che un materiale magnetico si orientava sempre sullo stesso verso, per cui possiamo chiamare polo magnetico sulla barretta. E si chiamavano poli nord e sud geografici. Si puÃ² paragonare a un Dipolo elettrico. E permette di analizzarlo come se fosse una carica magnetica. abbiamo quindi un dipolo magnetico, almeno matematicamente analizzabile in questo modo.\nSperimentalmente si Ã¨ osservato che *poli stesso segno si respingevano e di valore opposto si attraevano in modo simile a quanto succedeva per Legge di Coulomb. Solo che in questo caso non ha senso parlare di unitÃ  di carica che la genera diciamo. C\u0026rsquo;Ã¨ la teoria del monopolo ma poi quella non so quanto sia effettivamente vero.\nFino al 1800 questo Ã¨ quanto si sapeva, dopo si ebbe uno studio sistematico, permesso da un progresso tecnologico (forse direi ingegneristico), grazie alla pila di Alessandro Volta, con l\u0026rsquo;inizio dello studio dei circuiti. Con lo studio dell\u0026rsquo;interazione del campo magnetico ed elettrico si hanno i bei risultati :).\nCampo magnetico terrestre ðŸŸ© La terra si comporta come un magnete gigante :D. E creerÃ  momenti di dipolo per i magnetini presenti sulla superficie. ma nota: il polo sud geografico, in realtÃ  Ã¨ il polo nord magnetico! E anche il contrario. Esiste anche una versione periodica (non definita), ogni qualche milioni di anni. Si nota da come si sono solidificati i magma nel tempo (si solidificherÃ  in un certo modo). La teoria piÃ¹ buona Ã¨ che ci sono delle specie di dinamo all\u0026rsquo;interno della Terra che generano il campo. Il monopolo magnetico ðŸŸ© Se esistesse il monopolo magnetico potremmo definirlo in modo simile a Coulomb, vedi Legge di Coulomb: $$ \\lvert \\vec{F} \\rvert = k_{m} \\frac{C_{m}^{1}C_{m}^{2}}{r^{2}} $$ Per il Dipolo elettrico Ã¨ facile questo, basta prendere il dipolo e separarlo! Come si fa per il monopolo? Se taglio una calamita in due, avrÃ² due nuove calamite, questa caratteristica continua anche a livello atomico -\u0026gt; non esistono monopoli magnetici secondo questa scia La ricerca del monopolo magnetico Ã¨ molto sentita, perchÃ© il modello standard prevede l\u0026rsquo;esistenza di questi monopoli perÃ² sperimentalmente non sono stati rilevati ancora. Questa cosa motiva che la legge simile a Coulomb Ã¨ abbastanza inutile. NOTA: essendo la legge sperimentalmente sempre inversamente proporzionale a $r^{2}$ si puÃ² utilizzare la Legge di Gauss. Condizione necessaria per far funzionare la dimostrazione con angoli solidi.\nL\u0026rsquo;induzione magnetica e dipolo magnetico ðŸŸ© Partendo da conoscenze presenti per il Dipolo elettrico possiamo andare a definire il campo magnetico come la linea individuata dai dipoli magnetici, perchÃ© i dipoli si allineeranno in qualche modo quando sono dentro un campo magnetico. Con la convenzione che entra in sud ed esce in nord. In un certo senso il sud Ã¨ equivalente al - del dipolo elettrico e il nord al +.\nQuesto Ã¨ il campo di induzione magnetica chiamato $\\vec{B}$\nFigure descrittive di quanto detto sul campo magnetico, in ordine vediamo i campi, molto simili a quelli che si possono trovare per il dipolo, e l\u0026rsquo;allineamento di dipoli . Si puÃ² anche avere un ferro di cavallo per avere un campo uniforme. Campo solenoidale ðŸŸ© Essendo il monopolo magnetico non esistente, c\u0026rsquo;Ã¨ ancora una proprietÃ  simile alla Legge di Gauss anche nel nostro caso, ma la somma totale Ã¨ sempre nullo (perchÃ© se divido un dipolo ho un altro dipolo). $$ \\oint_{\\Sigma}\\vec{B} \\cdot \\vec{s} = \\frac{M_{tot}}{k} = 0 $$ Che Ã¨ la definizione di un campo solenoidale, ossia sempre 0 per qualunque superficie.\nQuindi immediatamente possiamo usare il teorema della divergenza -\u0026gt; Divergenza e Circuitazione e otteniamo $$ \\vec{\\nabla} \\cdot \\vec{B} = 0 $$ Ãˆ anche chiamata la seconda legge di Maxwell.\nRiguardo alla circuitazione, basta prendere un percorso sulla stessa linea (il campo Ã¨ sempre sullo stesso verso, anche fra i poli (cosa che invece per dipoli elettrici non Ã¨ vero)), Ã¨ diverso da zero, quindi il campo che abbiamo non Ã¨ conservativo, questo Ã¨ sempre vero per campi solenoidali. Questo Ã¨ quanto si sapeva all\u0026rsquo;inizio del 800, fine 700.\nCi dice che non ci sono monopoli magnetici, perchÃ© Ã¨ una parte della materia (Ã¨ il singolo atomo che Ã¨ un dipolo, per questo si distrugge tutto), i dipoli non sono altro che correnti elettriche in materiali!\nDa approfondire: In Diamagnetici Ã¨ Larmor in Magnetismo nella materia. In paramagnetici Ã¨ corrente intrinseco In ferromagnetici Ã¨ lo spin degli elettroni\nEsperimenti storici Facciamo una carrellata fra esperimenti storici che hanno relazionato correnti e cambi magnetici e hanno contribuito a una migliore comprensione del motivo per cui abbiamo certi fenomeni. Attorno al 1820 questi esperimenti, poi nel 1865 Maxwell enuncia le leggi, in poco tempo conosciamo del tutto tutti i fenomeni di elettromagnetismo classico.\nEsperimenti di Oersted ðŸŸ© Un filo percorso da corrente genera un campo magnetico\nQuesto Ã¨ un primo collegamento col campo elettrico! Come fanno cariche che si muovono a creare campo elettrico?\nOersted ha messo un magnete vicino a un filo. E ha osservato che se si chiude lo switch del circuito, l\u0026rsquo;ago magnetico gira. Esperimenti di Faraday ðŸŸ©- Faraday ha poi l\u0026rsquo;intuizione che un magnete piÃ¹ magnete Ã¨ in grado di influenzare la corrente, vede che se non c\u0026rsquo;Ã¨ corrente Ã¨ tutto ok, non succede niente, se perÃ² ci fa scorrere corrente, vede una forza perpendicolare al filo.\nUn filo percorso da corrente si comporta come un magnete\nOssia il filo Ã¨ in grado di attrarre il magnete.\nEsperimenti di Ampere ðŸŸ© Ampere ha avuto l\u0026rsquo;intuizione che puÃ² trattare fili come magneti, quindi due fili con corrente vicina dovrebbero essere soggette a forza, ed Ã¨ effettivamente ciÃ² che nota. E nota anche quanto presente in immagine: se sono verso diverso sono repulsive, altrimenti attrattive. Questo veramente sembra motivare l\u0026rsquo;utilizzo del filo per studiare il campo magnetico. il vantaggio di usare questo Ã¨ che\nFacilitÃ  di costruzione rispetto alla calamita La geometria del filo Ã¨ sotto mio controllo L\u0026rsquo;intensitÃ  di corrente Ã¨ modulabile, quindi posso definire l\u0026rsquo;intensitÃ  del campo nei magneti. Seconda legge di Laplace e Esperimento ðŸŸ© Definiamo l\u0026rsquo;esperimento come segue, una sbarretta metallica libera di scorrere fra le due e due supporti sopra, sotto abbiamo una batteria. Ci metto un dinamometro, e cosÃ¬ ho la misura della forza esercitata sulla sbarretta metallica mi serve per misurare la forza del campo magnetico. Nel nostro sistema avremo che la barretta ha lunghezza $d\\vec{l}$, e una corrente che sale e scende (proprio come circuito) Le osservazioni sono:\n$\\lvert d\\vec{F} \\rvert \\propto i \\lvert d\\vec{l} \\rvert$ $d\\vec{F} \\perp d\\vec{l}$ $\\lvert d\\vec{F} \\rvert = f(\\theta)$, dove $\\theta$ Ã¨ l\u0026rsquo;orientazione nello spazio di $d\\vec{l}$, e ho sempre un angolo in cui Ã¨ 0, che quello uscente dal piano credo. Allora cosÃ¬ ho definito l\u0026rsquo;interazione del campo $\\vec{B}$ con un filo percorso da corrente $i$. allora abbiamo con le osservazioni di sopra possiamo dire Seconda legge di Laplace: $$ d\\vec{F} = id\\vec{l} \\times \\vec{B} = i\\lvert d\\vec{l} \\rvert \\lvert \\vec{B} \\rvert \\sin \\theta $$ Questo permette ricavare il modulo della forza di B. Posso anche misurare la direzione con l\u0026rsquo;angolo. Questo Ã¨ utile per dare la definizione del campo magnetico. Probabilmente la forza Ã¨ sulla nuvola di elettroni o portatori di carica dentro al filo quando si muovono. Questo motiva chiedersi quanto sia la forza sul singolo elettrone che si muove:\nCampo magnetico Anche qui vale il principio di sovrapposizione! vedi Campo elettrico.\nAnalisi forza su cariche in movimento ðŸŸ©- Dall\u0026rsquo;esperimento di Laplace abbiamo modo di derivare la forza esercitata sul singolo elettrone in movimento $$ d\\vec{F} = \\vec{J} \\cdot d\\vec{S} \\cdot d\\vec{l} \\land \\vec{B} $$ Ho che $J$ e $dS$ hanno stessa direzione e verso per costruzione, e sarebbe bene prendere stesso verso anche per la lunghezza, mi permette di scrivere $dS$ e $dl$ stesso verso, quindi Ã¨ solamente uno scalare, e posso spostarlo in giro nel prodotto vettoriale:\n$$ d\\vec{F} = \\vec{J} \\land \\vec{B} (d\\vec{s} \\cdot d\\vec{l}) = \\vec{J} \\land \\vec{B} d\\tau $$ Quindi ora abbiamo la forza in funzione al volume, ma io conosco il volume e conosco $J$ quindi abbiamo: $$ d\\vec{F} = nq\\vec{v}_{d} \\land \\vec{B} d\\tau $$ Ma ricordiamo da Corrente Elettrica che $n$ Ã¨ il numero di cariche per unitÃ  di volume, ma abbiamo l\u0026rsquo;unitÃ  di volume, quindi $n d\\tau = N$ il numero totale di elettroni in uno spazio molto piccolo $dl$!, quindi abbiamo che\n$$ d\\vec{F} = dNq\\vec{v}_{d} \\land \\vec{B} $$ Questa Ã¨ relazione diretta fra chi si muove dentro e la quantitÃ  di forza che ho! Questa Ã¨ la su un segmento di filo infinitesimale!\nForza di Lorentz ðŸŸ© Abbiamo che la forza esercitata su una singola carica Ã¨ uguale a: $$ \\vec{F} = q\\vec{v} \\land \\vec{B} $$ $$ \\lvert \\vec{F} \\rvert = \\lvert q \\rvert \\lvert \\vec{v} \\rvert \\lvert \\vec{B} \\rvert \\sin \\theta $$ E la forza totale Ã¨ la somma di tutte queste particelle in una sezione di filo!. La nota importante Ã¨ che una forza perpendicolare alla direzione della velocitÃ , quindi Ã¨ una forza centripeta che implica che non puÃ² cambiare il modulo della forza di $v$. puÃ² solo cambiare la direzione, il che implica che non fa lavoro!.\n-\u0026gt; La forza di Lorentz non Ã¨ posizionale, quindi non ha senso chiedersi se Ã¨ conservativa, perchÃ© tanto lavoro Ã¨ sempre 0.\n-\u0026gt; Ãˆ una forza media sul portatore di carica, perchÃ© non posso andare a misurare il singolo portatore, da un punto di vista qualitativo la forza di Laplace Ã¨ molto meglio!\nQuesto ci permette di definire una nuova unitÃ , che Ã¨ il Tesla, ossia quanto campo magnetico per avere 1N di forza su una singola particella di $q$\nForza di Lorentz generalizzata ðŸŸ© possiamo generalizzare la Forza di Lorentz per una forza su una carica, dovuta ai due campi: $$ \\vec{F} = q\\vec{E} + q\\vec{v} \\land \\vec{B} $$ Se ho due cariche che stanno ferme, tutta la teoria sviluppata in elettrostatica funziona ancora! Se una delle due, invece, si muove c\u0026rsquo;Ã¨ solo elettrostatica ancora\nSistema di due cariche Se entrambe si muovono ho entrambe le forze\nIntroduzione al problema ðŸŸ© Una cosa strana Ã¨ che dipende dal sistema di riferimento perchÃ© la velocitÃ  puÃ² cambiare col sistema. Ãˆ un hint sulla correlazione fra i due campi. Come si puÃ² risolvere questo? Se ho due cariche ferme, ma io mi muovo, allora per me loro si muovono entrambe, e dal mio punto di vista sono soggette anche di forza magnetica sulle cariche.\nQuindi succede che per una carica ho sia forza elettrica, e anche in questo caso una forza magnetica opposta! Mentre per il filo si vede sempre non cambiando anche sistema di riferimento!\nAnalisi della forza caso per caso ðŸŸ¨- Proviamo ad analizzare secondo due sistemi di riferimento, una in cui il sistema Ã¨ solidale con le due cariche, una altra con riferimento inerziale, con velocitÃ  $v$ lungo asse $x$. Per il principio di relativitÃ  di galileo, dovrei osservare la stessa cosa, vediamo nei due cosa si vede.\nO: Agisce solamente la forza di coulomb. $$ \\vec{F} = q_{1}\\vec{E}_{2} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R_{2}} \\hat{d} $$ $O'$: dal mio sistema di riferimento, le due cariche si muovono con velocitÃ  $-v$ verso la parte opposta. $$ \\vec{v}_{1} = \\vec{v}_{2} = -v $$ Allora per la forza di Lorentz abbiamo: $$ \\vec{F}' = q_{1}\\vec{E}_{2} + q_{1}\\vec{v}_{1} \\times \\vec{B}_{2} $$ Quindi abbiamo un campo magnetico generato dal movimento dell\u0026rsquo;altra carica in piÃ¹.\nProviamo a guardare il campo magnetico generato, possiamo usare la relazione del campo magnetico generato da singola carica e abbiamo: $$ \\vec{B}_{2} = \\mu_{0} \\frac{q_{2}}{4\\pi} \\frac{ \\vec{v}_{2} \\times\\hat{r}}{r^{2}} = \\mu_{0} \\frac{q_{2}}{4\\pi} \\frac{ \\vec{v}_{2} \\times -\\hat{k}}{r^{2}} \\implies \\vec{F} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R^{2}} \\hat{d} + \\frac{1}{4\\pi\\varepsilon_{0}} q_{1} v \\cdot \\mu_{0}\\varepsilon_{0} \\frac{q_{2} v \\cdot (-\\hat{d})}{R^{2}} $$ in cui la direzione Ã¨ dentro il foglio, per il campo magnetico. Raccogliendo l\u0026rsquo;ultima abbiamo\n$$ \\vec{F} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R^{2}} [1 - \\varepsilon_{0} \\mu_{0} v^{2}] \\hat{d} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R^{2}} \\left[ 1 - \\frac{v^{2}}{c^{2}} \\right] \\hat{d} $$ Questo Ã¨ vero perchÃ© per velocitÃ  molto piccole Ã¨ simile al normale, ma la cosa strana si ha quando cominciamo ad avvicinarci alla velocitÃ  della luce, perchÃ© lÃ¬ cambia! Abbiamo forze diverse in due sistemi di riferimento inerziali!\nCorrelazione E e B per relativitÃ  galileiana ðŸŸ¨- Proviamo a utilizzare la relativitÃ  galileiana (che Ã¨ una legge prima presente, e affinchÃ© valga i campi elettrici e magnetici devono essere correlati), per questo ragionamento deve essere necessariamente che le due forze siano uguali, ma allora abbiamo questo risultato: $$ \\vec{F}' = \\vec{F} \\implies q_{1}\\vec{E}_{2} = q_{1}\\vec{E}_{2}' + q_{1}\\vec{v}_{1} \\times \\vec{B}_{2}' \\implies \\vec{E}_{2} = \\vec{E}_{2}' + \\vec{v}_{1} \\times \\vec{B}_{2}' $$ Ossia che il campo elettrico cambi a seconda del sistema di riferimento, e la stessa cosa per il campo magnetico. Proviamo a capire in che modo cambiano questi a a seconda del sistema di riferimento. Questo lega strettamente i valori di $E$ e $B$ in due sistemi di riferimento inerziali. Possiamo fare la stessa cosa per i campi magnetici $$ \\vec{B}_{2} = 0 = \\vec{B}_{2}' - \\frac{1}{c^{2}} \\vec{v} \\times \\vec{E}_{2}' $$ Cosa che si deriva utilizzando la relazione campo magnetico ed elettrico. Fino al 1905 si Ã¨ convinti di questo.\nCorrelazione E e B per relativitÃ  ristretta (non fare). La forza tridimensionale non Ã¨ un invariante relativistico, ma la forza che conta anche il tempo. (per quella relativitÃ  non c\u0026rsquo;Ã¨ problema che la forza vari).\nLa teoria di Einstein afferma che: $$ \\begin{cases} F_{x}' = F_{x} \\\\ F_{y}' = F_{y} \\sqrt{ 1 - \\frac{v^{2}}{c^{2}} } \\\\ F_{z}' = F_{z} \\sqrt{ 1 - \\frac{v^{2}}{c^{2}} } \\end{cases} $$ Nel momento in cui la velocitÃ  Ã¨ lungo $x$, quindi la forza cambia secondo la radice. Ma nell\u0026rsquo;analisi di sopra non abbiamo il rapporto con la radice, ma velocitÃ  senza radice, come mai? Anche qui $E$ ha dipendenze con $B$, ma le relazioni sono diverse.\nE sono (li ha dati cosÃ¬ il prof. senza giustificarli): $$ \\begin{cases} E_{x}' = E_{x} \\\\ E_{y}' = \\gamma [E_{y} - v B_{z}] \\\\ E_{z}' = \\gamma [ E_{y} + v B_{z}] \\\\ B_{x}' = B_{x}' \\\\ B_{y}' = \\gamma [B_{y} + \\frac{v}{c^{2} }E_{z} ] \\\\ B_{z}' = \\gamma \\left[ B_{z} - \\frac{v}{c^{2}} E_{y} \\right] \\end{cases} $$ Dove $\\gamma = \\frac{1}{\\sqrt{ 1 - \\frac{v^{2}}{c^{2}}} }$ Applicando queste trasformazioni nel nostro sistema a due cariche abbiamo che\n$$ E_{y}' = \\gamma E_{y} = \\frac{\\gamma}{4\\pi\\varepsilon_{0}} \\frac{q_{2}q_{1}}{R^{2}} $$ E che $$ B_{z}' = \\frac{\\gamma v}{c^{2}} E_{y} $$ E possiamo sostituirli dentro la legge generale di Lorentz per la forza finale, che Ã¨ simile a quella versione di Galileo, un po\u0026rsquo; differente\n$$ F' = q_{1}\\gamma E_{y} + q_{1}v \\frac{\\gamma v}{c^{2}} E_{y} = \\gamma q_{1} E_{y}\\left( 1 + \\frac{v^{2}}{c^{2}}\\right) = q_{1}E_{y} \\sqrt{ 1 + \\frac{v^{2}}{c^{2}} } $$ Questo valore Ã¨ proprio il valore predetto come trasformazione secondo la relativitÃ ?\nPrima legge di Laplace Prima legge di Laplace ðŸŸ© Vogliamo sapere esattamente quale sia il valore del campo magnetico generato da un filo. Il piccolo tratto di energia sarÃ  di valore $$ d\\vec{B} = \\frac{\\mu_{0}i}{4\\pi} \\frac{d\\vec{l} \\times \\hat{r}}{ r^{2}} $$ Questa Ã¨ la **prima legge di Laplace**. Osservazioni:\nPerpendicolare sempre a l e r, quindi al piano del nostro disegno Permette di capire quale sia il modulo del campo magnetico, e si nota che cade su $\\frac{1}{r^{2}}$ che Ã¨ la cosa che permette l\u0026rsquo;utilizzo della legge di gauss per i monopoli magnetici Sulla congiungente della retta dl, il valore del campo magnetico Ã¨ 0! PermeabilitÃ  magnetica del vuoto ðŸŸ© Il valore di $\\mu_{0}$ verrÃ  trovato sperimentalmente, e sarÃ : $$ \\text{permeabilitÃ  magnetica del vuoto}: \\mu_{0} = 4\\pi \\times 10 ^{7} \\, \\frac{Tm}{A} $$ Scoperta direi in modo simile a quanto fatto per permeabilitÃ  elettrica nel vuoto! Per Legge di Coulomb\nIl valore del campo magnetico e la forza di un altro filo definiscono il comportamento qualitativo per i campi magnetici!\nCampo magnetico totale ðŸŸ© Per trovare il valore basta sommare tutti i contributi!\n$$ \\vec{B} = \\int _{Filo} d\\vec{B} = \\int _{Filo} \\frac{\\mu_{0}i}{4\\pi} \\frac{d\\vec{l} \\times\\hat{r}}{r^{2}} $$ In modo simile a quanto fatto in Campo elettrico, se siamo in regime stazionario, la $i$ puÃ² essere portata fuori dall\u0026rsquo;integrale\nCampo magnetico da singola carica ðŸŸ¨+ La definizione precedente, con il $4\\pi$ ci permette anche di scrivere in una forma carica utilizzando la densitÃ  di corrente Corrente Elettrica. $$ id\\vec{l} = \\vec{J} \\cdot d\\vec{s} d\\vec{l} = \\vec{J} \\cdot d\\tau = nq\\vec{v}_{d} d\\tau = Nq\\vec{v}_{d} $$ Quindi ha un valore generato dal totale di cariche in movimento in un unitÃ  di volume infinitesimo. Questa osservazione ci permette di scrivere la seconda legge in relazione alla velocitÃ  di deriva: E isolare anche il campo magnetico per singola carica!\n$$ \\vec{B} = \\frac{\\mu_{0}q}{4\\pi} \\frac{\\vec{v}_{d} \\times\\hat{r}}{r^{2}} $$ Da qui osserviamo che se si muovono piÃ¹ in fretta allora il campo magnetico va piÃ¹ in fretta! E sappiamo che la velocitÃ  Ã¨ dipendente dal campo elettrico da cui sono sottoposti.\nLegame col campo elettrico ðŸŸ¨+ Dalla formula di sopra possiamo trovare la relazione col campo elettrico ponendo che $$ \\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q\\hat{r}}{r^{2}} \\implies \\frac{q}{r^{3}} = \\vec{E} 4\\pi\\varepsilon_{0} $$ E questo valore si puÃ² sostituire sopra, e diventa $$ \\vec{B} = \\frac{\\mu_{0}\\vec{v}_{d}}{4\\pi} \\times \\vec{E} 4\\pi\\varepsilon_{0} = \\mu_{0}\\varepsilon_{0} \\vec{v}_{d} \\times \\vec{E} = \\frac{1}{c^{2}} \\vec{v}_{d} \\times \\vec{E} $$ E la relazione stupenda Ã¨ con la velocitÃ  della luce, e si nota come queste sono veramente costanti fondamentali dell\u0026rsquo;universo!? Ãˆ da notare perÃ² che questo vale solo per valori della velocitÃ  tali per cui siano molto minori rispetto alla velocitÃ  della luce. (regimi non relativistici).\n","permalink":"https://flecart.github.io/notes/magnetismo/","summary":"Introduzione ai campi magnetici Introduzione storica (non impo) ðŸŸ© Il magnetismo Ã¨ stato in primi osservato e documentato da Greci, che hanno osservato che materiali metallici come ferro, questo Ã¨ successo in magnesia, una penisola dell\u0026rsquo;Asia minore, mentre elettro era piÃ¹ sull\u0026rsquo;ambra, che credo fosse il nome dato a quel materiale.\nUna cosa nota era che se vicino a un materiale magnetico, venivano create linee con materiale ferroso all\u0026rsquo;estremitÃ  (limatura magnetica).","title":"Magnetismo"},{"content":"Ultima modifica: May 1, 2023 10:37 AM Primo Abbozzo: April 30, 2023 5:06 PM Studi Personali: No\nElementi di ripasso 2022-06-10 Es 3 (sicurezza) Testo [15] Alice spedisce a Bob un messaggio M1 molto grande con la sola garanzia di non ripudiabilitÃ  (ovvero Alice non potrÃ  mai dimostrare di avere spedito un messaggio diverso da quello ricevuto da Bob), ma non serve privacy (tutti possono leggere M1). Bob in seguito risponde ad Alice con un messaggio m2 molto piccolo del quale deve essere perÃ² data garanzia di mittente (solo Bob puÃ² averlo spedito), di privacy (nessuno oltre ad Alice puÃ² leggerlo) e non Replay (ovvero Alice deve accettarlo una volta sola da Bob). Come puÃ² essere realizzato lo schema di cifratura di costo minimo (minimo calcolo e massima efficienza) che garantisca tutti e solo i requisiti richiesti? Spiegare.\nSoluzione proposta Supponiamo di avere un sistema di cifratura a chiavi pubblica per Bob ha chiavi pubbliche presenti in CA (per evitare Man in the middle).\nPer garantire la non ripudiabilitÃ  del messaggio grande di Alice, alice vuole firmare con la propria chiave privata il messaggio molto grande che si vuole mandare, ma non puÃ² cifrare il messaggio intero perchÃ© Ã¨ grande, quindi calcola lâ€™hash del messaggio, insieme a questo manda anche una Nonce, questo servirÃ  per favorire il non replay.\nAllo stesso tempo se Eve Conoscesse sia il messaggio sia lâ€™hash sarebbe troppo semplice provare a fare tampering del messaggio, per questo motivo Alice oltre semplicemente a mandare lâ€™hash crea una chiave simmetrica, cifra lâ€™hash del messaggio e la nonce con questa chiave simmetrica, cifra la chiave simmetrica con la chiave pubblica di Bob presa da un CA, e manda questo pacchetto:\nMessaggio in chiaro Cifratura_pubblica_generata(H_A- (hash(messaggio)) + Nonce) Cifratura con chiave_bob_ca(chiave_pubblica). QUESTA SOLUZIONE Ãˆ ERRATA PERCHÃ‰ NON SERVE CHIAVE PUBBLICA, DATO CHE BASTA NON RIPUDIABILITÃ€!\nIn quanto bob deve spedire un messaggio molto piccolo, gli basta direttamente creare $H_B^- (Message)$, per avere la garanzia del mittente, per privacy puÃ² cifrare tutto con la chiave simmetrica ricevuta da alice, e per non replay insieme al messaggio mette la nonce.\nVerifica intanto con hash e chiave pubblica di alice presa da CA che sia stata effettivamente alice e che abbia scritto quel messaggio (due condizioni necessarie per non ripudiabilitÃ )\nE manda un pacchetto\n$H_S(H_B^-(Message) + Nonce)$ Alice decifrerÃ  con la chiave simmetrica generata da lei e la chiave pubblica presa da CA, verificherÃ  che la Nonce effettivamente corrisiponde a quella mandata da lei, e decifrererÃ  il messaggio.\nEs 7 wifi Testo Soluzione proposta Se abbiamo un fade margin di 10 o 20 anche in periodi di nebbia dovremmo comunicare correttamente, quindi obiettivo buono sarebbe avere una RF che raggiunga il ricevitore a -82dBm.\nAllora, calcoliamo la caduat di segnale pari alla distanza:\n36.6 + 20 * log(1900) + 20 * log(5) = 116 decibel.\n// Trova lâ€™errore qui sotto (câ€™Ã¨ un errore che direi che sia abbastanza greve (ed Ã¨ anche stupido) e poi altro errore stupido nella conversione ðŸ˜€\nQuindi deve essere x - 116 + 7+ 7 + 97 = 15 â‡’ x = 102 + 97 = 102 + 97 = 199 dBm = 199 mW.\nSi Ã¨ possibile se la zona di fresnel resta libera, perderei circa 6dB di potenza (pari a una caduta del segnale di 4 volte , ma riuscirebbe a ricevere ugualmente)\nDalla formula il 100 per cento della zona di fresnel Ã¨\n72.2 * sqrt(5 / 4 * 1.9) = 58.56 feet = 58.56 * 30.5 cm = 1786 cm = 17.86 metri.\nEs 8 (wifi) Testo Soluzione proposta (sembra completamente sbagliata) Non ha senso parlare di anticipo o ritardo di fase, si puÃ² dire che la differenza di fase sia 90 gradi. Non ha senso parlare di anticipo o ritardo perchÃ© il segnale potrebbe essere visto come in anticipo di 90 gradi e allo stesso tempo ritardo di 270, come il contrario. Non ho abbastanza informazioni per dire se Ã¨ in anticipo o ritardo di 90, ma Ã¨ uno dei due casi.\nUna differenza di fase di 180 sarebbe distruttiva, di 0 sarebbe costruttiva, quindi ne sÃ¬ ne nÃ² perchÃ© Ã¨ a metÃ .\nLa buona comunicazione dipende anche dalla sensibilitÃ  del ricevitore oltre alla potenza del segnale iniziale, possiamo calcolare quanta energia sia arrivata al ricevitore:\nRicordiamo che F Ã¨ in Megaherz e D in miglia\nLoss = 36.6 * (20 * log_10(37.5)) + (20 * log_10(29 * 0.000621371)) = maggiore di 1000, non credo che il segnale arriverÃ  mai con quella frequenza. quindi nessuna delle precedenti.\n","permalink":"https://flecart.github.io/notes/reti-preparazione-esami/","summary":"Ultima modifica: May 1, 2023 10:37 AM Primo Abbozzo: April 30, 2023 5:06 PM Studi Personali: No\nElementi di ripasso 2022-06-10 Es 3 (sicurezza) Testo [15] Alice spedisce a Bob un messaggio M1 molto grande con la sola garanzia di non ripudiabilitÃ  (ovvero Alice non potrÃ  mai dimostrare di avere spedito un messaggio diverso da quello ricevuto da Bob), ma non serve privacy (tutti possono leggere M1). Bob in seguito risponde ad Alice con un messaggio m2 molto piccolo del quale deve essere perÃ² data garanzia di mittente (solo Bob puÃ² averlo spedito), di privacy (nessuno oltre ad Alice puÃ² leggerlo) e non Replay (ovvero Alice deve accettarlo una volta sola da Bob).","title":"Reti Preparazione Esami"},{"content":"First time we talked about this was in Sicurezza delle reti#Protocollo SSL\nSSL Secure socket Layer\nPrinciples Session It\u0026rsquo;s an association (probably something similar to SA in Sicurezza delle reti). That connects the client to the server. Defines the cryptographic parameters to allow the communication.\nStuff for session:\nSession identifier: generated by the server to identify an active or resumable session. Peer certificate: X 509v3 certificate. Compression method: algorithm used to compress the data before encryption. Cipher spec: encryption and hash algorithm, including hash size. Master secret: 48 byte secret shared between the client and server. Is resumable: indicates if the session can be used to initiate new connections. Connection ServerÂ andÂ client:Â random chosenÂ forÂ eachÂ connection. Server write MAC secret: shared key used to computeMAC onÂ dataÂ sentÂ by theÂ server.\nClientÂ writeÂ MACÂ secret:Â sameÂ asÂ aboveÂ forÂ theÂ clientServerÂ writeÂ key:Â sharedÂ keyÂ usedÂ byÂ encryptionÂ whenserverÂ sendsÂ data.\nClientÂ writeÂ key:Â sameÂ asÂ aboveÂ forÂ theÂ client.InitializationÂ vector:Â initializationÂ vectorsÂ requiredÂ byencryption.\nSequenceÂ numbers:Â bothÂ serverÂ andÂ clientÂ maintain suchÂ aÂ counterÂ toÂ preventÂ replay,Â cycleÂ is $2^{64} - 1$\nThe SSL record Alerts They are two bytes used for error/warning information.\nTLS handshake protocol TLS stands for\nThis works at the process layer to ensure security from the protocol perspective. It\u0026rsquo;s more granular because it is out of the ISO/OSI stack.\nProperties Two of the tree principles in Secury Principles and Tor#Security principles are done with this. Integrity and Confidentiality. Auth is implemented at the application layer.\nExchange of keys It\u0026rsquo;s important, TLS uses a symmetric key to communicate after communication is enstablished.\nExchange protocol Just use common exchange protocols!\nDiffie Hellman RSA And variations are some examples\nAuthenticity of certificates CA\u0026rsquo;s are used to exchange the security keys securely. This is the default, historically there have been some attacks on this method\nOther options could be just self sign the certificate and exchange that signed thing (needs other things, like manual operations to validate and trust it).\n","permalink":"https://flecart.github.io/notes/tls-ssl-protocol/","summary":"First time we talked about this was in Sicurezza delle reti#Protocollo SSL\nSSL Secure socket Layer\nPrinciples Session It\u0026rsquo;s an association (probably something similar to SA in Sicurezza delle reti). That connects the client to the server. Defines the cryptographic parameters to allow the communication.\nStuff for session:\nSession identifier: generated by the server to identify an active or resumable session. Peer certificate: X 509v3 certificate. Compression method: algorithm used to compress the data before encryption.","title":"TLS-SSL protocol"},{"content":"Cosa Ã¨ UML Ã¨ un linguaggio di modelling (molto vecchio) ma ancora di continua evoluzione, da un punto di vista storico Ã¨ nato insieme ai concetti di Object Oriented Programming che ora Ã¨ molto presente all\u0026rsquo;interno dell\u0026rsquo;industria, descritto bene in Classi OOP, anche se in questa occasione sviluppata in maniera molto piÃ¹ intuitiva (grafica).\nPerchÃ© serve ðŸŸ© Per cercare di comunicare quanto necessario riguardo struttura e dinamicitÃ  dell\u0026rsquo;architettura.\nStruttura di UML Structural Diagram ðŸŸ¨++ These diagrams focus on representing the static structure of a system. They help depict the components, classes, objects, and their relationships in a system. Some common structural diagrams in UML include:\nClass Diagram: Shows the classes in a system and their relationships, attributes, and methods. Object Diagram: Represents instances of classes and their relationships at a specific point in time. Component Diagram: Illustrates the physical components of a system and their dependencies. Package Diagram: Organizes classes and other elements into packages to show their relationships. Behavioral diagrams (4) ðŸŸ©\u0026ndash; These diagrams focus on illustrating the dynamic aspects of a system, including how it behaves and interacts over time. They are used to model the interactions between objects, the flow of control, and the system\u0026rsquo;s behavior. Common behavioral diagrams in UML include:\nUse Case Diagram: Depicts the interactions between actors (users or external systems) and the system to achieve specific goals or functions. Sequence Diagram: Shows the chronological sequence of messages exchanged between objects over time. Statechart Diagram: Represents the various states an object or system can be in and how it transitions between those states. Activity Diagram: Describes the flow of activities or processes within a system. Main relationships Queste sono anche chiamate le freccie, ossia le tipologie di relazioni che possono esistere fra entitÃ  diverse.\nLe relazioni esistenti Association: An association is a basic relationship that represents a link between two or more classes or objects. It indicates that instances of one class are related to instances of another class. In a graph context, you can think of associations as edges connecting nodes in a graph. Associations can have multiplicities to specify how many instances are involved in the relationship (e.g., one-to-one, one-to-many).\nAggregation: Aggregation is a specialized form of association that represents a whole-part relationship. It indicates that one class (the whole) is composed of or contains instances of another class (the part). In a graph, aggregation can be seen as a hierarchical relationship, where nodes at one level represent composite objects made up of nodes at another level. Esempio di aggregazione: Composition: Composition is a stronger form of aggregation, indicating a strict ownership relationship. It means that the whole class has exclusive responsibility for the existence and lifetime of its parts. In a graph, composition is similar to aggregation but with a stronger emphasis on the containment of parts within the whole.\nInheritance (Generalization): Inheritance, represented by a solid arrow with an open triangle, signifies an \u0026ldquo;is-a\u0026rdquo; relationship. It is used to model the inheritance hierarchy in object-oriented programming, where one class (the subclass or derived class) inherits attributes and methods from another class (the superclass or base class). In graph terms, it represents a hierarchy, with edges pointing from subclasses to their superclass.\nRealization (Interface Implementation): Realization is used to show that a class or component implements a specific interface or fulfills a particular contract. It indicates a relationship between a classifier and an interface. In graph theory, this can be seen as a form of dependency or connection between nodes representing classes and interfaces.\nDependency: Dependency is a relationship that indicates that one element relies on another element. It can be used to represent various forms of relationships, such as method dependencies, parameter dependencies, or simple associations between classes. In a graph, dependencies are akin to edges indicating connections or reliance between nodes.\nStructural diagrams Class diagrams Descrivo in che modo le varia classi sono relazionati fra di loro (ad esempi con l\u0026rsquo;albero di ereditarietÃ )\nTypes of behavioral diagrams (5) Use cases (!) ðŸŸ¨+ Structure of use case diagrams A use case is a concept in software engineering and system design that describes a specific interaction or set of interactions between a system (usually software) and its external actors\nGoal-Oriented: Use cases are centered around achieving specific goals or objectives. Each use case represents a particular task, process, or scenario that an external actor wants to accomplish using the system. Actor: An actor is any external entity that interacts with the system. Actors can be users, other software systems, hardware devices, or any external entity that initiates a use case. Actors are defined based on their roles and responsibilities in the system. Flow of Events: A use case typically includes a description of the main flow of events, which outlines the steps or interactions involved in achieving the desired goal. It can also include alternative or exceptional flows to cover various scenarios. Preconditions and Post-conditions: Use cases may specify conditions that must be met before the use case can be initiated (preconditions) and the state of the system after the use case has been successfully completed (post-conditions). (ossia ciÃ² che abbiamo bisogno, e ciÃ² per rendere deterministico questo processo). Quindi Ã¨ utilizzato per modellare in che modo chi usa dovrebbe interagire con il nostro sistema, e ciÃ² che il nostro sistema ha bisogno per funzionare.\nEsempio: More on actors Use case modelling and diagrams ðŸŸ¥ Use Case Diagrams: Use cases are often visualized using diagrams called use case diagrams. These diagrams show the relationships between actors and use cases, helping to provide a high-level overview of the system\u0026rsquo;s functionality. Use Case Modeling: Use case modeling is a technique used during the early stages of system design to identify and define the various use cases that the system will support. It helps in understanding and documenting user requirements and system behavior. State-chart diagrams Notazione sugli stati (4) ðŸŸ¨+ #### Notazione delle transizioni ðŸŸ©- In modo simile agli automi a stato finito, definisco gli stati (in questo caso aggiungo anche una semantica per gli stati, e poi una possibile transizione all'interno di quelli). PerchÃ© utilizzare state-chart ðŸŸ© Descrizione di cambi di stato, in modo a simile a quanto si farebbe per automata per esempio. Descrizione di campi statici presenti negli oggetti per esempio. Ãˆ contrapposto con gli interaction diagrams che racconta in che modo cose differenti comunicano fra di loro, questo state-chart Ã¨ utilizzato per definire in modo statico se succede cosa, cosa cambia. Esempi di state diagrams In pratica Ã¨ un grafico piÃ¹ rilassato di Deterministic Finite Automata [Grammatiche Regolari](/notes/grammatiche-regolari) Si puÃ² usare anche in modo innestato come in seguito Activity diagrams Cosa descrivono le activity diagrams ðŸŸ© Workflows, ossia in che modo il sistema agisce, ad alto livello per poter a Parallelizzazione, se devono essere eseguite piÃ¹ cose allo stesso tempo, Ã¨ molto comodo. Sincronizzazione, quindi anche per logica con async ha senso Sequence diagrams Interaction diagrams Cercano di modellare in che modo comunicano fra l\u0026rsquo;uno e l\u0026rsquo;altro, serve per fare cose complesse Un esempio sono i sequence diagrams\nPerchÃ© sequence diagrams? ðŸŸ© Shows object interactions arranged in time sequence\nUn esempio di utilizzo comune Ã¨ per i protocolli, dato che il tempo Ã¨ importante Ã¨ molto facile comunicare esattamente cosa viene scambiato. Quindi utile per rappresentare in che modo chi chiama cosa nel tempo. Altro esempio, un po\u0026rsquo; piÃ¹ complesso Descrizione della struttura ðŸŸ© In alto abbiamo degli oggetti oppure degli agenti differenti, poi col tempo questi oggetti diversi scambiano messaggi, in questo caso Ã¨ chiara sequenza dei messaggi, che Ã¨ il vantaggio principale di questi diagrammi.\nAsincroni Sincroni Non bloccanti, esattamente gli stessi che abbiamo visto in sistemi Collaboration diagrams Descrizione collaboration diagrams ðŸŸ© Uguale ai sequence diagrams, ma esprime messaggi possibili fra una classe e una altra e non esprime il tempo durante una singola comunicazione.\nUn altro aspetto Ã¨ che la sequenza dei messaggi Ã¨ identificata da numeri\nConfronto con i diagrammi di sequenza ðŸŸ© Facile vedere messaggi che vengono scambiati da enti differenti, quindi organizzazioni diciamo. Si perde perÃ² informazione sul tempo Per il resto Ã¨ molto simile rispetto ai #Sequence diagrams perchÃ© anche in questo caso si scambiano messaggi, solo che non Ã¨ ben definito il tempo. (viene marcato con un numerino).\nUn esempio: ","permalink":"https://flecart.github.io/notes/unified-modeling-language/","summary":"Cosa Ã¨ UML Ã¨ un linguaggio di modelling (molto vecchio) ma ancora di continua evoluzione, da un punto di vista storico Ã¨ nato insieme ai concetti di Object Oriented Programming che ora Ã¨ molto presente all\u0026rsquo;interno dell\u0026rsquo;industria, descritto bene in Classi OOP, anche se in questa occasione sviluppata in maniera molto piÃ¹ intuitiva (grafica).\nPerchÃ© serve ðŸŸ© Per cercare di comunicare quanto necessario riguardo struttura e dinamicitÃ  dell\u0026rsquo;architettura.\nStruttura di UML Structural Diagram ðŸŸ¨++ These diagrams focus on representing the static structure of a system.","title":"Unified Modeling Language"},{"content":"Introduzione al vettore potenziale Definizione vettore potenziale ðŸŸ© Possiamo sempre scrivere il campo $\\vec{B}$ come $$ \\vec{B} = \\vec{\\nabla} \\times \\vec{A} $$ Con un campo vettoriale a caso $\\vec{A}$, vedremo che questo campo avrÃ  qualche utilitÃ  per fare i calcoli.\nPossiamo notare che soddisfa la proprietÃ  dell campo solenoidale citato in Magnetismo, infatti\n$$ \\vec{\\nabla} \\cdot \\vec{B} = \\vec{\\nabla} \\cdot (\\vec{\\nabla} \\times \\vec{A}) = 0 $$ PerchÃ© sappiamo che la divergenza del rotore (questo operatore dico) Ã¨ sempre nullo per ragioni di Cauchy, se ne parla in Divergenza e Circuitazione.\nUnicitÃ  del campo ðŸŸ© Proviamo ad analizzarlo matematicamente, ci stiamo chiedendo, Ã¨ unica?\nLo Ã¨ a meno di un gradiente di una funzione scalare\nDefiniamo $$ \\vec{A}' = \\vec{A} + \\vec{\\nabla}F $$ Abbiamo:\n$$ \\vec{\\nabla} \\times \\vec{A}' = \\vec{\\nabla} \\times \\vec{A} + \\vec{\\nabla} \\times (\\vec{\\nabla}F) = \\vec{\\nabla} \\times \\vec{A} + 0 $$ Dove il gradiente di $F$, si ricorda Ã¨ vettoriale, ed Ã¨ utilizzato per rappresentare un vettore qualunque, basta che esista $F$ che lo generi, che lo abbiamo in ipotesi.\nSimile con il potenziale, che Ã¨ una funzione definita a meno di una costante perchÃ© possiamo mettere un punto (che scegliamo noi) in un certo punto, o potenziale del sistema che sono contati in quella costante, ne parliamo in Campo elettrico. (in questo capo la nostra costante Ã¨ un vettore in un certo senso :P)\nScelta del campo A ðŸŸ© Per la divergenza abbiamo invece:\n$$ \\vec{\\nabla} \\cdot \\vec{A}' = \\vec{\\nabla} \\cdot(\\vec{A} + \\vec{\\nabla}F) = \\vec{\\nabla} \\cdot \\vec{A} + \\nabla^{2}F $$ Lo scalare $F$ lo posso scegliere io, e mi puÃ² semplificare molti conti (si dovrebbe dimostrare che questo $F$ che me lo annulli esista sempre, probabilmente Ã¨ vero). Allora possiamo scegliere come il campo $A$ vettore potenziale tale per qui valnga $$ \\vec{\\nabla} \\cdot \\vec{A} = 0 $$ Per qualche motivo questa cosa vale solo nel caso stazionario (con $\\vec{J}$ stabile).\nComoditÃ  del vettore potenziale Ampere Max-well con vettore potenziale ðŸŸ© Abbiamo quindi\n$$ \\vec{\\nabla} \\times (\\vec{\\nabla} \\times \\vec{A}) = \\mu_{0}\\vec{J} $$ Questa espressione si puÃ² semplificare tenendo conto che $a\\times b\\times c = b (a \\cdot c) - (a\\cdot b) c$ Da cui abbiamo:\n$$ \\vec{\\nabla} \\cdot (\\vec{\\nabla} \\cdot \\vec{A}) - (\\vec{\\nabla} \\cdot \\vec{\\nabla})\\vec{A} = \\mu_{0}\\vec{J} $$ Utilizzando l\u0026rsquo;approssimazione sopra presente abbiamo ancora un laplaciano per rappresentare questa legge, in modo simile a quanto presente al differenziale potenziale per la quantitÃ  di carica. $$ \\nabla^{2}\\vec{A} = -\\mu_{0}\\vec{J} $$ Possiamo notare che $A$ ha la stessa direzione della corrente! seguendo la soluzione dell\u0026rsquo;equazione di Poisson per campo elettrico abbiamo che\n$$ A(x, y, z) = \\frac{\\mu_{0}}{4\\pi} \\int _{\\Sigma} \\frac{J(x', y', z')\\, dx'dy'dz'}{\\sqrt{ (x - x')^{2} + (y - y')^{2} + (z - z') ^{2} }} $$ Se applichiamo questo su un filo allora diventa in un certo senso: $$ \\vec{A} = \\frac{\\mu_{0}}{4\\pi} \\int \\frac{\\vec{J} d\\Sigma \\, dl}{r} = \\frac{\\mu_{0}}{4\\pi} \\int \\frac{i \\, dl}{r} $$ Quindi quantitÃ  di corrente lungo un certo tratto di filo!\nFaraday con vettore potenziale ðŸŸ©\u0026ndash; $$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} = \\frac{\\delta (\\vec{\\nabla} \\times \\vec{A})}{\\delta t} $$ E abbiamo:\n$$ \\vec{\\nabla} \\times \\left( \\vec{E} + \\frac{\\delta \\vec{A}}{\\delta t} \\right) = 0 $$ Quindi abbiamo che vale:\n$$ \\vec{E} = -\\frac{\\delta A}{\\delta t} \\implies \\vec{\\nabla}V = \\frac{\\delta A}{\\delta t} $$ Circuitazione del vettore potenziale ðŸŸ© Consideriamo il flusso del vettore su una superficie\n$$ \\int_{\\Sigma} \\vec{B} \\hat{u}_{n} \\, ds = \\int_{\\Sigma} \\vec{\\nabla} \\times \\vec{A} \\hat{u}_{n} \\, ds = \\int_{\\Gamma(\\Sigma)} \\vec{A} \\cdot\\, d\\vec{l} $$ Dove l\u0026rsquo;ultima vale per Stokes in Divergenza e Circuitazione, quindi possiamo calcolare il flusso su un campo andando a considerare la circuitazione del potenziale vettore!\nEsempi di applicazione Studio del vettore potenziale in un solenoide ðŸŸ© Possiamo poi scoprire che $$ \\vec{A} = B \\frac{r}{2} \\hat{u}_{c} $$ Quando $r$ Ã¨ minore del raggio del solenoide, se Ã¨ maggiore abbiamo $$ \\vec{A} = B \\frac{R^{2}}{2r} \\hat{u} $$ ","permalink":"https://flecart.github.io/notes/vettore-potenziale/","summary":"Introduzione al vettore potenziale Definizione vettore potenziale ðŸŸ© Possiamo sempre scrivere il campo $\\vec{B}$ come $$ \\vec{B} = \\vec{\\nabla} \\times \\vec{A} $$ Con un campo vettoriale a caso $\\vec{A}$, vedremo che questo campo avrÃ  qualche utilitÃ  per fare i calcoli.\nPossiamo notare che soddisfa la proprietÃ  dell campo solenoidale citato in Magnetismo, infatti\n$$ \\vec{\\nabla} \\cdot \\vec{B} = \\vec{\\nabla} \\cdot (\\vec{\\nabla} \\times \\vec{A}) = 0 $$ PerchÃ© sappiamo che la divergenza del rotore (questo operatore dico) Ã¨ sempre nullo per ragioni di Cauchy, se ne parla in Divergenza e Circuitazione.","title":"Vettore potenziale"},{"content":"Ripasso Prox: 5 Ultima modifica: November 18, 2022 10:09 AM Primo Abbozzo: November 15, 2022 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Wireshark Questo documento sono appunti riguardanti strumenti di sniffing di wireshark.\nstrumento passivo che ascolta ebbasta tutti i pacchetti che puÃ² (ovviamente puÃ² solo se riceve il segnale fisicoâ€¦, quindi se uno switch non mi invia proprio il segnale, non c\u0026rsquo;Ã¨ comunque modo per me di sniffare il pacchetto, ma se invece Ã¨ un hub, allora sentirei tutto.)\n","permalink":"https://flecart.github.io/notes/wireshark/","summary":"Ripasso Prox: 5 Ultima modifica: November 18, 2022 10:09 AM Primo Abbozzo: November 15, 2022 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Wireshark Questo documento sono appunti riguardanti strumenti di sniffing di wireshark.\nstrumento passivo che ascolta ebbasta tutti i pacchetti che puÃ² (ovviamente puÃ² solo se riceve il segnale fisicoâ€¦, quindi se uno switch non mi invia proprio il segnale, non c\u0026rsquo;Ã¨ comunque modo per me di sniffare il pacchetto, ma se invece Ã¨ un hub, allora sentirei tutto.","title":"Wireshark"},{"content":"Ripasso Prox: 60 Ripasso: May 23, 2023 Ultima modifica: June 11, 2023 3:00 PM Primo Abbozzo: November 11, 2022 3:47 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Domande\nTop-down Parser Top-down Algoritmo di parsing ðŸŸ© Slide\nQuesto si potrebbe considerare come algoritmo classico di parsing con non determinismo. (vado avanti, ed esploro tutto, senza look ahead).\nEsempio di esecuzione\nCommenti efficienza di sopra ðŸŸ© Ãˆ molto inefficiente, in particolare si potrebbe trovare una compessitÃ  esponenziale del tipo\n$O(b^{|w|})$, con b il massimo numero di produzioni. (la produzione maggiore la espando sempre!)\nSlide\nSi puÃ² rendere molto piÃ¹ efficiente con un valore di lookahead.\nFirst e Follow Utilizzeremo il simbolo $ per segnalare la fine di una stringa, cosÃ¬ puÃ² godere della prefix property, che Ã¨ una cosa fondamentale per le DPDA, vedi Linguaggi Deterministici e DPDA.\nFirst intro ðŸŸ© Slide\nIn pratica Ã¨ un insieme che contiene i primi caratteri possibili per tutti! (ad ochio attento si puÃ² notare quanto sia importante per il lookahead, andiamo in pratica a considerare le produzioni che abbiano il simbolo di lookahead).\nEsempio di uso e in-uso di first\nCalcolo del first ðŸŸ© Interessante in questa parte lâ€™utilizzo dellâ€™insieme dei simboli annullabili che abbiamo descritto in Semplificazione grammatiche., sembra sia legata molto al first\nSlide\nLâ€™intuizione di maggior rilievo per questo algoritmo Ã¨ che in quel modo si sta facendo un or , unione fra tutti i simboli che sono annullabili.\nQuesto algoritmo si puÃ² estendere in modo quasi banale ai non terminali che non sono annullabili (perchÃ© basta prendere il primo carattere\nSlide che descrive per simboli non annullabili\nEsempi del calcolo del first\nFollow intro ðŸŸ©â€” Slide\nQuindi un terminale appartiene a follow terminale se puÃ² comparire dopo\nUna cosa particolare di questa definizione Ã¨ il terminale $.\nA volte ci puÃ² interessare sapere cosa viene dopo un non terminale annullabile cosÃ¬ possiamo decidere di annullarlo e tenere il prossimo.\nMini esempio\nCalcolo del follow ðŸŸ© Slide algo\nDa notare che per calcolare questa funzione abbiamo bisogno del first!\nEsempio 1\nEsempio 2\nGrammatiche LL(1) Tabella di parsing intro LL(1) ðŸŸ© Definizione\nHo una tabella che mappa (NT, T) â†’ produzione.\nIn pratica una tabella di parsing ci dÃ  una idea del modo in cui comportarci per ogni singolo input e ogni terminale, Ã¨ quindi fondamentale per capire in che modo espandersiâ€¦\nOssia se ho un NT sulla stack e vedo con lookahead 1 un terminale, allora provo a capire con quale produzione posso espandere.\nAlgoritmo per riempimento tabella ðŸŸ© Algoritmo calcolo della tabella\nSe il first di qualcosa che voglio mettere Ã¨ noto, allora Ã¨ easyâ€¦\nAltrimenti la metto per lâ€™intera riga.\nTh sui LL(1) (chiede molto) ðŸŸ© Definizione di grammatica LL(1)\nEnunciato e dimo\nLa dimostrazione di questo Ã¨ molti dalla costruzione della tabella di parsing. (in particolare l\u0026rsquo;unici modi che ci importano per dimostrare se un linguaggio Ã¨ LL(1) Ã¨ questo oppure la costruzione della tabella d parsing).\nEsempio grammatica in forma sopra\nEsempio 2\nParser LL(1) ! ðŸŸ© Slide Algo pseudocodice\nLâ€™idea Ã¨ principalmente di utilizzare la tabella di parsing per capire quale produzione utilizzare quando ho un non terminale!\nQuanto ho terminali li poppo dalla pila (se non posso poppare ritorno errore) Quando ho non-terminali vado a guardare nella tabella, se non ho niente fallisco Alla fine se ho svuotato la pila e letto tutto sono molto felice. Esempio di parsing 1\nEsempio 2\nesempio 3\nTh. ling regolare â†’ generabile da LL(1) ðŸŸ¨- Dalla lezione 14 (credo)\nCon i teoremi espressi in Grammatiche Regolari, posso trasformare lâ€™espressione regolare in DFA e poi il dfa minimo in grammatica regolare da questo posso creare la grammatica LL1, vogliamo ora dire che possiamo sempre farlo (nel toggle câ€™Ã¨ il piccolo algoritmino utilizzato per creare la grammatica).\nDimo\nMini lemma:\nOgni grammatica regolare con solo produzioni $V \\implies aW$ e produzioni epsilon Ã¨ una grammatica LL(1)\nIl motivo Ã¨ che i first di ogni produzione di un non terminale sono diversi fra di loro, perchÃ© sono tutti parte dellâ€™alfabeto e sono unici. E i follow sono sempre stringa terminale, quindi per il teorema di caratterizzazione dei linguaggi LL(1), questo Ã¨ un linguaggio LL(k).\nSi puÃ² verificare che questo Ã¨ il tipo di grammatica che si estrae da un automa minimo, quindi il teorema Ã¨ soddisfatto.\nGrammatiche LL(k) Generalizzazione first follow e tabella ðŸŸ©- Slide\nIntuizione\nOra il first ha la concezione dei **primi k **, lettere che possono essere anche minori di k, nel caso in cui io abbia giÃ  una stringa terminale. Ma non posso avere minore di K se non Ã¨ terminale!!!!\nAllo stesso modo follow k sono i primi k caratteri che possono seguire il nostro non terminale.\nLa tabella Ã¨ generata esattamente nello stesso modo**,* solo che bisogna fare un pÃ² di attenzione alle colonne, che ora possono essere di dimensione molto maggiore rispetto alla dimensione dellâ€™alfabeto (potenze di esse, almeno potenzialmente, poi nella pratica io mi metto a storare quello che mi serve.\nEsempio di utilizzo di first e follow generali\nTeoremi (4) su LL(k) ðŸŸ¨ Slide\nQuesti teoremi ci danno una forte relazione fra\ngrammatica ambigua â†’ non Ã¨ LL(k) con questa anche la sua contronominale ricorsiva sinistra â†’ non LL(k) essere LL(k) â†’ essere un linguaggio libero deterministico â†’ Non ambigua esiste L deterministico tale che non ci sia G di class LL(k) (quindi i linguaggi LL(k) non bastano per avere tutti i linguaggi deterministici! Gerarchia classi di linguaggi LL(k) ðŸŸ© Slide\nQuello che si puÃ² osservare Ã¨ che ogni classe di linguaggio con k maggiore include quella con k minore. Il motivo intuitivo che non Ã¨ presente nella slide Ã¨ tipo: se posso riconoscerlo guardando una lettera piÃ¹ avanti, lo posso ancora fare guardandone 2 o piÃ¹â€¦\nSi puÃ² notare che non tutti i linguaggi liberi deterministici sono riconosciuti da linguaggi LL(k), si puÃ² osservare l\u0026rsquo;esempio di sotto.\nLibero det not implies LL(k) ðŸŸ¨+ esempio Incompletezza dei linguagg LL(1)\nIn questo caso Ã¨ solamente enunciato che non si puÃ² modellare la grammatica cosÃ¬ trovata per renderla di classe LL(k).\nPerÃ² intuitivamente si puÃ² capire che avrei bisogni di un k infinito per poter scegliere fra le due produzioni, riesco sempre a trovare un k che non funzioniâ€¦\nEsercizio a caso\n","permalink":"https://flecart.github.io/notes/top-down-parser/","summary":"Ripasso Prox: 60 Ripasso: May 23, 2023 Ultima modifica: June 11, 2023 3:00 PM Primo Abbozzo: November 11, 2022 3:47 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Domande\nTop-down Parser Top-down Algoritmo di parsing ðŸŸ© Slide\nQuesto si potrebbe considerare come algoritmo classico di parsing con non determinismo. (vado avanti, ed esploro tutto, senza look ahead).\nEsempio di esecuzione\nCommenti efficienza di sopra ðŸŸ© Ãˆ molto inefficiente, in particolare si potrebbe trovare una compessitÃ  esponenziale del tipo","title":"Top-down Parser"},{"content":"Ripasso Prox: 17 Ripasso: December 22, 2021 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: November 3, 2021 9:14 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Vecchi dubbi\nripassare da inconsistenza in poi. Modello Ã¨ una funzione semantica?\n5 VeritÃ  e conseguenza Logica Questa Ã¨ una necessitÃ  per stabilire il significato di una sintassi definiti.\n5.1 VeritÃ  e RealtÃ  La veritÃ  ha solamente senso quando lo si relaziona con un mondo sensibile, ossia il mondo che si puÃ² percepire con i nostri sensi.\n5.1.1 VeritÃ  parametrica e assoluta Se un esperimento Ã¨ ripetibile all\u0026rsquo;interno del mondo sensibili allora questa Ã¨ considerata come una veritÃ  parametrica, ossia dipende da uno stato del mondo sensibile.\nveritÃ  assoluta come le costanti della fisica.\n5.1.2 Scienze pure e scienze molli La differenza fra queste due Ã¨ che le scienze pure non stanno parlando del mondo sensibile, ma crea un mondo a sÃ©, astratto, in cui ha senso tutto ciÃ² che viene detto riguardo a questo mondo preciso. Anche l\u0026rsquo;informatica Ã¨ teorica.\nMa cosa Ã¨ la veritÃ  senza il mondo sensibile? L\u0026rsquo;esempio che abbiamo fatto prima non funziona piÃ¹.\nLe scienze molli descrivono la realtÃ  sensibile mentre le scienze pure descrivono un mondo astratto inesistente nella realtÃ . (quindi fisica non Ã¨ pura, secondo questo).\n5.1.3 Teoria matematica Ãˆ come una storia descritta prima: insieme di sentenze,connotazioni.\nEnti primitivi di un mondo Assiomi che valgono in certi mondi ðŸ’¡ Gli assiomi sono come le leggi fisiche di un mondo fantastico: descrivono delle regole che valgono in un mondo preciso, e quindi si possono derivare delle conseguenze e le interazioni fra queste. 5.1.4 Modello matematico Interpretare i concetti primitivi in modo che valgano tutti gli assiomi, questo Ã¨ il modello.\nQuindi il modello matematico Ã¨ una interpretazione degli enti primiti e edegli assiomi del mondo!\nNon Ã¨ definito a priori ma si dÃ  il senso\nEsempio in classe\nPer esempio il mondo con i numeri colorati, quella relazione resta la stessa, posso colorare come mi pare, allora la prima proposizione della slide sono falsi\nEsempio teoria e modello\n5.2 Il mondo Il mondo Ã¨ una descrizione completa delle caratteristiche e regole del mondo (quindi oggetti, leggi e simili). Ovviamente questa Ã¨ solamente una descrizione ipotetica in quanto non possiamo conoscere tutto di un mondo (non conosciamo tutto nemmeno nel mondo in cui viviamo).\nUn assioma Ã¨ valido solamente in alcuni mondi precisi, spesso ci interessa indagare solamente quei mondi. (Ãˆ utile indagare solamente un mondo in cui quel determinato assioma valga o meno.)\nIl concetto di veritÃ  non ha senso come concetto a sÃ© stante in quanto dipende dal mondo in cui la proposizione Ã¨ valutata\nLe teorie e i modelli matematici hanno senso solamente se interpretati in un mondo particolare. Da soli no. Una proposizione ha un concetto di veritÃ  solamente se ha poi senso all\u0026rsquo;interno del mondo.\n5.2.1 Conseguenza logica Data una teoria T(un insieme di sentenze) si dice conseguenza logica F di T quando F vale per tutti i modelli di T, ovvero in tutti i mondi in cui valgono le sentenze della teoria.\nDue cose:\nVera per tutti i modelli T Vera in tutti i mondi in cui le ipotesi G1 G2 etc Ã¨ vero, ossia tutti gli assiomi sono veri. Miniriassunto\nCon gli assiomi sto filtrando nei mondi in cui questi assiomi siano veri, quindi prendiamo solamente mondi in cui siano veri questi assiomi, con questi assiomi e enti primitivi creiamo un mondo. Allora poi possiamo avere una semantica, un modo di interpretare che Ã¨ il modello e da qua possiamo avere proposizioni e conseguenze logiche\nDetto in altri modi\nGli assiomi creano dei sottomondi in cui esse valgono (sto filtrando sui mondi).\nF (un insieme di modelli matematici) Ã¨ una conseguenza logica di T se vale in tutti i mondi in cui valgono tutte le ipotesi (assiomi) (sentenze) G1 G2 etc\u0026hellip; di T\nNota: piÃ¹ ipotesi che ho, piÃ¹ sto restringendo nell\u0026rsquo;insieme dei mondi, quindi avrÃ² piÃ¹ conseguenze logiche, quindi diventa una cosa piÃ¹ interessante.\n5.2.2 Equivalenza logica Due sentenze sono dette equivalenti se sono soddisfatte esattamente dagli stessi mondi. (ossia filtrano sugli stessi mondi) (assiomi rindondanti uno con l\u0026rsquo;altro)\nRelazione di equivalenza per equivalenza logica\nConsidera solamente i mondi in cui valgono\nNel secondo caso nella slide ho come ipotesi che entrambi hanno gli stessi mondi cin cui valgono, allora Ã¨ ovvio che si ha il contrario\nIn modo simile si ha per il terzo caso\n5.3 Valutazione della teoria Quando Ã¨ interessante?\nNon ha senso chiedersi se un assioma Ã¨ vero o falso, nemmeno se Ã¨ giusto o falso, ha solamente senso chiedersi se Ã¨ vero o falso in un mondo preciso. Vale allora la teoria di consistenza\n5.3.1 Inconsistenza di una teoria Una teoria Ã¨ inconsistente quando non ammette nessun modello. (ossia non ammette nessuna interpretazione degli enti primitivi in modo che valgano tutti gli assiomi)\nSi puÃ² anche dire che l\u0026rsquo;assurdo Ã¨ conseguenza logica di una teoria inconsistente, quindi Ã¨ tutto vero, tutto vero per assurdo!?\nCi sono troppi vincoli, quindi sto parlando di niente (ho un insieme vuoto di modelli e quindi sto parlando del vuoto) (tutto Ã¨ conseguenza logica in questo caso)\nQuesto vale anche il contrario, perÃ² non Ã¨ dimostrabile in modo semplice anche l\u0026rsquo;altra freccia.\nQuindi se Ã¨ falso questo, allora ho almeno un mondo in cui tutto ciÃ² che ho Ã¨ vero! Quindi che sia consistente! (e poi la cosa bella sarebbe cercare le applicazioni pratiche di queste cose)\nLa Logica studia la conseguenza logica! Introduzione a Logica\n5.3.2 Interpretazione Si puÃ² considerare interpretazione una funzione semantica che per ogni connotazione associa una unica denotazione, considerato un oggetto di un mondo preciso. (enti primitivi sono connotazioni di un mondo, considerati connotazioni atomiche).\nLa funzione di interpretazione Ã¨ descritta meglio in Logica Proposizionale\nLe connotazioni sono interpretate come denotazioni del mondo.\nPoi ci sono funzioni del mondo e simboli del mondo.\nDi solito le connotazioni composte sono ottenute da connotazioni atomiche (denotazioni del mondo) combinate tramite connettivi logici.\n5.4 Connotazione denotazione In informatica sono sintassi e semantica. SarÃ  ciÃ² che mi serve per evitare l\u0026rsquo;uso meta-linguistico, invarianza per sostituzione Ã¨ il primo teorema che serve per questo\n5.4.1 Intuizione iniziale In linguistica la connotazione Ã¨ il significato psicologico di una parola, mentre la denotazione Ã¨ la prima cosa che di solito di dÃ  il dizionario, ossia cosa Ã¨ detto effettivamente.\nIn breve: (â†’ indica il significato in informatica)\nConnotazione: ciÃ² che voglio comunicare, come voglio cominciare (per la logica i messaggi subliminali non sono utili) â†’ Sintassi il modo in cui lo sto dicendo Denotazione cosa Ã¨ detto â†’ Semantica ciÃ² che voglio dire, anche considerabile come l\u0026rsquo;oggetto che viene considerato in questo mondo. Nel caso dell\u0026rsquo;informatica l\u0026rsquo;uso metalinguistico Ã¨ parlare sulle connotazioni\n5.4.2 Teorema Invarianza delle denotazioni Data un qualunque contesto (un buco di una frase) e una connotazione, se sostituita con una altra connotazione, le denotazioni delle frasi restano le stesse allora quelle due connotazioni sono equivalenti.\nPossiamo utilizzare il test di invarianza per vedere se qualcosa Ã¨ metalinguistico o meno.\nSe due connotazioni che possiedono la stessa denotazione hanno output diversi per certi contesti allora questo fa uso metalingusitico\nFondamentale per l\u0026rsquo;uso metalinguistico\n5.4.3 Connettivi logici Intro Per maggiore precisione sui connettivi logici guardare Connettivi Logici, correttezza, variabili\nAbbiamo bisogno di tenere certe cose fisse in modo da tenere un ordine generale fra i mondi. Questi sono i connettivi logici che hanno lo stesso senso ovunque.\nPossono essere\nBinari\nUnari\n0-ari\nE poi quantificatori come esiste e per ogni in modo da tenere un ordine generale fra i mondi. Questi sono i connettivi logici che hanno lo stesso senso ovunque.\nPossono essere\nBinari\nUnari\n0-ari\nE poi quantificatori come esiste e per ogni\n","permalink":"https://flecart.github.io/notes/verita-teorie-modelli-connotazione-denotazione/","summary":"Ripasso Prox: 17 Ripasso: December 22, 2021 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: November 3, 2021 9:14 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso Vecchi dubbi\nripassare da inconsistenza in poi. Modello Ã¨ una funzione semantica?\n5 VeritÃ  e conseguenza Logica Questa Ã¨ una necessitÃ  per stabilire il significato di una sintassi definiti.\n5.1 VeritÃ  e RealtÃ  La veritÃ  ha solamente senso quando lo si relaziona con un mondo sensibile, ossia il mondo che si puÃ² percepire con i nostri sensi.","title":"Verita, Teorie, modelli, connotazione, denotazione"},{"content":"La memoria e l\u0026rsquo;apprendimento Breve classificazione Basata sulla consapevolezza Basata sul tempo Basata sulla funzione Importanza della dimensione temporale Memoria a breve termine Memoria a lungo termine Anatomia della memoria nel cervello Il caso di H. M. ","permalink":"https://flecart.github.io/notes/memory-of-the-brain/","summary":"La memoria e l\u0026rsquo;apprendimento Breve classificazione Basata sulla consapevolezza Basata sul tempo Basata sulla funzione Importanza della dimensione temporale Memoria a breve termine Memoria a lungo termine Anatomia della memoria nel cervello Il caso di H. M. ","title":"Memory of the Brain"},{"content":"Ripasso Prox: 12 Ripasso: January 5, 2023 Ultima modifica: December 27, 2022 4:55 PM Primo Abbozzo: November 14, 2022 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Algo di grafi Questa sezione la tengo separata rispetto agli altri per favorire lo studio, cosÃ¬ questa roba nuova la ripasso piÃ¹ spesso, in seguito si puÃ² accorpare.\nGoldberg Tarjan/Push-relabel Questo algoritmo Ã¨ importante perchÃ© introduce ragionamenti sul minimo locale che possa alla fine essere ricomposto come soluzione globale.\nQuesta lezione youtube lo spiega da Dio\nPreflusso ðŸŸ© Slide\nLa parte nuova di questa cosa Ã¨ che i vincoli di bilanciamento possono diventare una disuguaglianza. (cioÃ¨ quello che arriva Ã¨ di piÃ¹ rispetto quanto va fuori.\nAndiamo inoltre a definire un concetto di attivitÃ  del nodo, ossia il fatto o meno che abbia un eccesso di flusso in entrata (e che quindi io abbia cose da mandare fuori ancora).\nPush forward e backward ðŸŸ© Slide\nVogliamo utilizzare un algoritmo locale che sposti il flusso in avanti oppure allâ€™indietro, questi sono gli unici modi per spostare flussi in giro.\nPseudocodice ðŸŸ¨+ Slide\nSi noti che Ã¨ presente un sistema di etichettatura utilizzato per tenere sotto controllo il costo\nNOTA ERRORE: Devono tornare a 5 invece che a 6\nLâ€™etichettatura ðŸŸ©- Lâ€™etichettatura per questo algoritmo Ã¨ fondamentale. Lo utilizziamo principalmente per evitare che ci siano push che poi vadano a ciclo, cosa molto brutta dato che non finirebbe mai lâ€™algoritmo.\nSi fa una etichettatura iniziale in questo modo:\nSparo al massimo tutti gli archi che partono da S. Metto N lâ€™altezza di S, e 0 tutto il resto. In questo modo vengono soddisfatte queste INVARIANTI:\nil Label per S Ã¨ sempre N il label per L Ã¨ sempre 0 Esiste un arco nel grafo residuo fra v, w solo se $h(v) \\leq h(w) + 1$ Noi vorremmo pushare solamente se ho una relazione del tipo $h(v) = h(w) + 1$, ossia esattamente piÃ¹ alto di 1.\nAnalisi del costo ðŸŸ©+ Slide\nSul perchÃ© sia vero non lo presenta, bisogna fare un approfondimento a riguardo.\nSe si sceglie il nodo di altezza massima si avrÃ  alla fine un costo di $O(N^3)$.\nFlusso di costo minimo algoritmi simili a ford fulkelson non sono molto buoni per trovare la migliore soluzione per questo, vorremmo andare a cercare il pseudoflusso del costo minimo!\nPseudoflusso ðŸŸ© Slide\nIntuitivamente sto prendendo qualunque flusso che soddisfi i vincoli di capacitÃ , ma che non Ã¨ sufficiente per soddisfare i vincoli di bilanciamento sui nodi.\nNodi di eccesso e difetto e sbilanciamento compressivo ðŸŸ© Slide\nCon la nozione di pseudoflusso Ã¨ utile fare questa differenza.\n$O_x$ i nodi con eccesso di flusso quindi $e$ positivo, ciÃ² che entra Ã¨ di piÃ¹\n$D_x$ il contrario. ciÃ² che esce Ã¨ di piÃ¹.\nQuesti sono molto importanti, perchÃ© vorremmo far partire ed arrivare flusso dai nodi O ai nodi D, in modo da renderli bilanciati. E poi vorremmo avere il percorso di costo minimo.\nCammini aumentanti ðŸŸ©- Slide\nIn sta parte viene esteso il concetto di cammino aumentante introdotto in precedenza per introdurre il costo di un cammino aumentante.\nUna cosa in piÃ¹ Ã¨ che si puÃ² partizionare lâ€™insieme degli archi nel cammino. Questa cosa sarÃ  utile per calcolare il costo\nCosto dei cammini aumentanti ðŸŸ© Slide calcolo costo cammino aumentante\nQuesto Ã¨ un concetto nuovo rispetto a quello passato perchÃ© prima non si faceva caso ai costi, invece ora sÃ¬.\nTh struttura equivalenza dei pseudoflussi (!!) ðŸŸ© Enunciato\nNota, inizio e fine dei cammini\nÃˆ un teorema molto forte, dati due pseudoflussi qualunque, possiamo legare questi due con un numero di cammini aumentanti!\nLa dimostrazione non si fa ðŸ˜€.\nDimostrazione in dispensa\nTh struttura del pseudoflusso minimo (!) ðŸŸ©- Enunciato e dimostrazione\nHint per â†\nConsideriamo il nostro pseudoflusso, per ipotesi non Ã¨ minimale, allora esiste un altro pseudoflusso di costo minore con gli stessi vettori di sbilanciamento, allora per il teorema precedente puÃ² essere applicato, posso trasformare uno nellâ€™altro.\nLa parte difficile da qui Ã¨ trovare il ciclo con costo negativo. Per sapere questo bisogna fare un pÃ² meglio il teorema precedente, infatti si puÃ² dire che tutti i percorsi sono dei cicli!\nQuindi il pseudoflusso di costo minimo Ã¨ strettamente legato all\u0026rsquo;esistenza di cicli aumentanti di costo negativo!. Quindi vogliamo andare a togliere questi cicli, se riesco a togliergli tutti allora possono trovare il pseudoflusso minimale.\nNOTA: si ricordi che gli pseudoflussi si possono confrontare fra di solo solo se hanno gli stessi sbilanciamenti!.\nTh pseudoflusso minimo con aggiornamenti (!!!) ðŸŸ© Enunciato e dimo\nhint a dimostrazione\nDobbiamo prendere il cammino aumentante di costo minimo e poi anche il flusso di costo minimo! Questi due sono gli ingredienti fondamentali per questo teorema qui.\nE sÃ¬ tal cred, sta roba Ã¨ nell\u0026rsquo;enunciato\nDimostrazione\nCome mai quella relazione riguardo i theta? PerchÃ© altrimenti avrei che lo sbilanciamento fra start-finish sarebbe diverso.\nQuesto Ã¨ il teorema principale che ci garantisce lâ€™invariante! Riusciamo a mantenere lo pseudoflusso di costo minimo in seguito alle operazioni di update con i cammini aumentanti!\nQuindi si puÃ² costruire un algoritmo che utilizza questa proprietÃ \nTrova un pseudoflusso minimo fra tutti quelli con lo stesso vettore di sbilanciamento Aggirona finchÃ© c\u0026rsquo;Ã¨ cammino aumentante Quando non posso piÃ¹ aggiornare ho finito, ho il pseudoflusso di costo minimo, e di flusso massimo. Algoritmo cammini minimi successivi Pseudocodice algo ðŸŸ©â€” Per avere uno pseudoflusso minimale basta non avere cicli di costo negativo, vedremo fra poco come far ciÃ².\nDa notare che ora lâ€™aggiornamento tengo conto anche del minimo fra inizio e arrivo! Ricordo che il mio obiettivo Ã¨ risolvere gli sbilanciamenti\nCorrettezza e terminazione ðŸŸ©â€” Slide\nQuindi se termina allora Ã¨ corretto per i teoremi precedenti. Riguardo la terminazione riesco a fare ragionamenti sulla capacitÃ  del flusso, che posso dire che Ã¨ sempre intero, e diminuisci almeno di uno, quindi se andiamo a fare un bound sullo sbilanciamento iniziale riusciamo a fare una stima sul numero di iterazioni necessarie per finire.\nComplessitÃ  ðŸŸ© Slide\nQuesto dipende fortemente dipende dallo sbilanciamento iniziale e dal tempo per trovare il cammino minimo (eg. bellman ford).\nAlgoritmo eliminazione cicli negativi Questo Ã¨ un altro algoritmo utilizzato per trovare il flusso minore, l\u0026rsquo;obiettivo Ã¨ trovare un qualunque flusso ammissibile, e poi togliere tutti i cicli negativi che trovo, in questo modo so per teorema precedente che il flusso che ho trovato Ã¨ il minore possibile.\nSe non sbaglio questo algoritmo Ã¨ acnhe chiamato algoritmo del ciclo di klein e ha complessitÃ  pseudopolinomiale di $O(m^2nCU)$ dove C Ã¨ la capacitÃ  massima e U il costo massimo. Il ragionamento per questa complessitÃ  Ã¨ che mi costa mn per Bellman ford per trovare il ciclo, e lo faccio diminuendo al massimo mCU volte (che Ã¨ il lower bound per il costo minimo).\nCostruzione flusso ammissibile ðŸŸ© Vogliamo costruire un qualunque flusso ammissibile, e vogliamo cambiarlo in modo che essa abbia anche il costo minimo.\nRisolvere il problema di maximum flux, in questo modo ho un flusso ammissibile di flusso massimo Poi vado a cercare i cicli negativi, questi non cambiano nessun bilanciamento, e abbassano solamente il costo. So che il minimo costo sarÃ  quello che non avrÃ  cicli di costo negativo. In questo modo Ho trovato la migliore soluzione.\nPseudocodice ðŸŸ© Slide\nAnalisi del costo e correttezza ðŸŸ© Slide\nil bound per il numero di iterazioni Ã¨ molto banale, in pratica vado a considerare il massimo costo possibile, so che almeno diminuisce di 1 ad ogni iterazione, piÃ¹ un costo di bellman ford per trovare i cicli. costo:\n$$ O(NA) \\cdot O(Auc) = O(NA^2uc) $$ ","permalink":"https://flecart.github.io/notes/tarjan-e-mcmf/","summary":"Ripasso Prox: 12 Ripasso: January 5, 2023 Ultima modifica: December 27, 2022 4:55 PM Primo Abbozzo: November 14, 2022 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Algo di grafi Questa sezione la tengo separata rispetto agli altri per favorire lo studio, cosÃ¬ questa roba nuova la ripasso piÃ¹ spesso, in seguito si puÃ² accorpare.\nGoldberg Tarjan/Push-relabel Questo algoritmo Ã¨ importante perchÃ© introduce ragionamenti sul minimo locale che possa alla fine essere ricomposto come soluzione globale.","title":"Tarjan e MCMF"},{"content":"Ripasso Prox: 40 Ripasso: May 31, 2023 Ultima modifica: May 29, 2023 3:58 PM Primo Abbozzo: March 6, 2023 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Espressioni, Comandi, Ricorsione Espressioni Con espressione intendiamo una entitÃ  sintattica, che una volta valutata ritornerÃ  un valore, oppure non termina, in questo caso si dice che la espressione Ã¨ INDEFINITA.\nQuesta Ã¨ una definizione Ã¨ leggermente ambigua dato che non abbiamo una definizione precisa di valutazoine, che Ã¨ fortemente dipendente dalla macchina astratta in cui viene eseguito.\nNotazioni (sintassi possibili) (3) ðŸŸ© Notazione infissa\nQuesta Ã¨ la notazione classica matematica, per cose tipo $a -b$, in cui l\u0026rsquo;operando sta nel mezzo degli operatori.\nAbbiamo il vantaggio di famigliaritÃ  e semplicitÃ  della istruzione, ma perdiamo con ambiguitÃ  di precendenza degli operatori e associativitÃ  degli operatori, cioÃ¨ non sempre sappiamo se una espressione ha precedenza con lâ€™altra, per esempio una espressione del tipo x == y and y == 1d in un certo linguaggio and ha una precedenza, e quindi farebbe perdere di senso all\u0026rsquo;espressione.\nProblemi di precedenza abbiamo per cose come $1 - 1 -1$, che a seconda se facciamo prima il primo - o il secondo meno possiamo avere dei risultati differenti.\nQuindi se utilizziamo una notazione infissa, guadagniamo di semplicitÃ  e famigliaritÃ , e perdiamo in complessitÃ  della valutazione, che per essere eseguita vorremmo creare un albero di valutazione, che spesso si deriva dall\u0026rsquo;albero di derivazione dopo il parser.\nNotazione prefissa (polacca)\nSono scritture come questo: $+ \\, a\\,b$, in qui scriviamo prima il + e poi gli operandi.\nÃˆ una cosa molto comoda perchÃ© non abbiamo la necessitÃ  di specificare precedenze nÃ© parentesi, ma basta sapere l\u0026rsquo;arietÃ  del nostro operatore per poter valutare l\u0026rsquo;espressione.\nNotazione postfissa (polacca inversa)\nQuesta Ã¨ uguale alla precedente, ma al contrario, quindi abbiamo cose come $a\\, b\\,+$, Ã¨ anche piÃ¹ semplice da valutare, ma in generale molto semplice.\nPrefissa matematica e di cambridge\ncome f(a, b), oppure (f a b) per cambridge\nInterpretazione dellâ€™albero\nSi potrebbe interpretare la notazione infissa, prefissa o postfissa come una visita dellâ€™albero di valutazione.\nsimmetrica = visita infissa prefissa = visita prefissa (anticipata) (provo a valutare lâ€™operatore e poi vado giÃ¹) Postfissa = visita postfissa (valuta dopo aver eseguito sinistra e destra) Semantica ðŸŸ© Con la semantica andiamo ad indicare il processo di valutazione di una espressione. Abbiamo detto prima che per la notazione infissa Ã¨ piÃ¹ complicata, infatti dovremmo andare a creare un albero di valutazione, creato dall\u0026rsquo;albero di derivazione (che quando compiliamo col parser Ã¨ facile da creare dalle foglie).\nInvece se proviamo a valutare con la notazione prefissa, questa Ã¨ una cosa molto piÃ¹ semplice, perchÃ© basta una singola scansione che va con questo algoritmo:\nSe Ã¨ un operatore inizializzo un counter e torno a leggere Se vedo un operando pusho in pila e decremento il counter. Se counter Ã¨ 0 faccio l\u0026rsquo;operazione e metto in stack, se Ã¨ diverso da 0 torno a leggere Se Ã¨ postfissa allora Ã¨ ancora piÃ¹ semplice, se ho un operando pusho in pila, se ho un operatore prelevo quanto mi serve ed eseguo e pusho in pila il risultato.\nOrdine di valutazione delle sottoespressioni (4) ðŸŸ©â€” Matematicamente parlando non sarebbe molto importante andare a considerare lâ€™ordine di valutazione, perÃ² in questo caso diventa molto importante perchÃ© lâ€™ordine stesso potrebbe incidere sul risultato dell\u0026rsquo;espressione, un esempio Ã¨ quando una espressione implica un side effect.\nSide effect (come potrebbe essere la chiamata di una funzione con side effect mentre valutiamo l\u0026rsquo;espressione!)\nPossibilitÃ  di overfow per aritmetica finita eg. (INT_MAX - 10 + 5) vs (INT_MAX + 5 - 10)\nCorto circuito e operatori non definiti.\nPer esempio una scrittura del tipo (p â‰  NULL) \u0026amp;\u0026amp; (p.next == 1)sarebbe un errore in pascal, perchÃ© fa una esecuzione eager, cioÃ¨ valuta tutto prima di valutare qualcosa, mentre in C se Ã¨ null torno subito, questo si dice corto circuito perchÃ© non vado a valutare tutto. Efficienza, l\u0026rsquo;ordine di valutazione puÃ² anche cambiare lâ€™efficienza dellâ€™esecuzione, ad esempio inizializzando un accesso in memoria, e poi andare a fare altre operazioni che non avevano bisogno di accesso. PerchÃ© nellâ€™esempio di sotto Ã¨ probabile che aa non sia ancora disponibile, quindi conveniva fare cd prima di andare sullâ€™altro, che deve attendere.\nEsempio a= vettore[i]; b = a*a + c*d In questa sede quindi Ã¨ importante fare differenza fra\nComandi Definizione di comandi ðŸŸ© Per comando intendiamo una entitÃ  sintattica che quando valutata non necessariamente ritorna un valore, inoltre potrebbe fare un effetto collaterale. (NOTA: anche le espressioni possono avere effetto collaterale)\nDa questa definizione non sembra ci sia una differenza chiara con lâ€™espressione. perÃ² concettualmente dovremmo tenerci in mente che un comando Ã¨ qualcosa di utile per cambiare lo stato del programma, ossia alla fine del comando ho uno stato differente, quindi ho avuto un side effect, mentre una espressione Ã¨ qualcosa che idealmente non dovrebbe avere side-effect, ma alla fine ritorna sempre un valore.\nUn esempio di side-effect del comando puÃ² essere la stampa a schermo, che avrÃ² cambiato la zona memory mapped come descritto in Note sullâ€™architettura.\nStato computazione = valore di tutte le variabili nel programma in un certo momento (oppure memoria, boh), va a modificare questo lÂ´effetto collaterale.\nVariabili (2) ðŸŸ© Ãˆ importante tenere a mente che le variabili sono diverse rispetto a quelle definite in matematica, lÃ¬ sono incognite che possono assumere valori in un certo insieme che non sono modificabili.\nInvece in informatica per le variabili abbiamo due modi principale di interpretazione, una reference model e l\u0026rsquo;altra come variabili modificabili\nIl primo modo intende la variabile come una reference a una zona di memoria in cui veramente Ã¨ presente il dato che ho, quindi come se fosse un puntatore (senza possibilitÃ  di modifica) (solitamente messo nella heap). Quindi la variabile denota il riferimento, alla variabile, non il contenitore al valore.\nIl secondo modo intende le variabili proprio per il valore che possiedono, quindi come contenitore o locazione di memoria che contiene qualcosa che puÃ² cambiare nel tempo. Sembra molto simile, ma nel secondo modo vado a riferirmi al valore, che Ã¨ proprio in quella zona, mentre nel primo caso Ã¨ un puntatore ad una altra zona.\nAltri modelli\nSlide altri modelli di variabile\nNei linguaggi funzionali, come le variabili matematiche, che una volta assegnata non Ã¨ piÃ¹ modificabile un valore. O modificabili in un certo senso nei linguaggi logici.\nAssegnamento ðŸŸ© Solitamente l\u0026rsquo;assegnamento ha una forma exp1 assignmentOp exp2a ed Ã¨ importante andare a distinguere l-value e r-value.\nl-value Ã¨ l\u0026rsquo;indirizzo di memoria (quindi denota una locazione) in cui si dovrÃ  andare a scrivere la r-value, che solitamente puÃ² essere la locazione se utilizzo la reference model (e quindi in pratica sposto il pointer in questo modello), o proprio una copia del valore se utilizzo lâ€™altra interpretazione, quella delle variabili modificabili, in questo caso indica (un valore che puÃ² essere contenuto)\nSolitamente questa istruzione produce un side effect (quindi si puÃ² notare che il side effect sia un necessario), dato che il valore della variabile Ã¨ stato modificato, e solitamente non ritiorna nessun valore (tranne in C che ritorna sempre una variabile, perchÃ© credo che lâ€™assegnamento Ã¨ visto come se fosse una espressione).\nIMPLICAZIONI IMPORTANTI PER SIDE EFFECT.\nÃˆ importante tenere a mente la possibilitÃ  di side effect, perchÃ© se provo a fare una cosa come a[f(x)] = a[f(x)] + 1 Questo potrebbe dare risultati differenti a seconda del fatto che io abbia side effect o meno. Sarebbe meglio fare cose come j = f(x); a[j] = a[j] + 1\nGli operatori come += e quelli della stessa famiglia sono utili a ovviare a questo side effect dovuto allâ€™esempio di prima, ecco una loro utilitÃ  ðŸ˜€, non Ã¨ solo un modo compatto lel.\nControllo della sequenza Ambiente e memoria (3) (ni) ðŸŸ¨â€” Slide ambiente e memoria\nSolitamente una associazione del tipo f: nome -\u0026gt; Valore Non Ã¨ sufficiente perchÃ© non posso esprimere che un assegnamento per reference cambi i valori per entrambi (secondo questo modello dovrebbe cambiarlo solo per il singolo nome!).\nSolitamente andiamo a definire 3 modelli di valore:\nValori denotabili da variabili Valori memorizzabili in locazioni di memoria Valori esprimibili come risultati di espressione. All\u0026rsquo;interno del nostro linguaggio imperativo imperativo abbiamo bisogno delle prime due, mentre in un linugaggio funzionale solamente il primo che associa valori a variabili.\nInfatti per utilizzare l-value vogliamo andare a modificare il valore associato alla variabile. mentre per accedere al r-value dobbiamo andare a prendere il contenitore, quindi dovremmo prima accedere alla locazione, e poi dalla locazione andare a riprenderci il valore.\nPoi il fatto che la l-value cambi anche il valore in memoria Ã¨ una altra cosa credoâ€¦ Non lo ho capito dovrei chiederlo. Questa parte non ha molto senso, e non Ã¨ importante posso saltare perÃ² tenere a mente che esistono quelle 3 cose.\nComandi sequenziali ðŸŸ© Sono comandi come\n; Ossia il singolo comando sequenziali begin ... end Che sono i comandi a blocchi anche indicati con {} in C goto Che Ã¨ ora in disuso ma in passato era molto importante. Il goto ha avuto una fortissima discussione negli anni 1970 con Dijkstra. Si basava sull\u0026rsquo;idea di assembly e labels che permettevano di fare salti a piacere.\nIl goto ha la stessa espressivitÃ  di un programma senza di esso (th di BÃ¶hn Jacopini) Il goto rende il codice difficilmente leggibile, quindi non permette la facile manutenzione. (si pensi a un goto per uscire da un loop 100 righe dopo, non Ã¨ piÃ¹ strutturata la lettura diciamo). Come posso interpretare il fatto di goto che salta all\u0026rsquo;interno di un blocco? Come gestire RdA?? Sarebbe buono utilizzarlo come break e continue, ma ci sono giÃ  quei comandiâ€¦ Produce spaghetti code (che crea proprio un grafo a forma di spaghetti se seguiamo il flusso di controllo del programma) Viola il concetto della programmazione strutturata, di cui tratteremo in software engineering l\u0026rsquo;anno prossimo. Slides programmazione strutturata\nCondizionali (2) ðŸŸ© if Bexp then Cl e1se C2 Semmai potremmo dire che ci siano qualche ambiguitÃ  quando ho qualche if annidato senza delimitatori. Per la valutazione di questi if Ã¨ importante tenere a mente che esiste il short-circuit per rendere piÃ¹ efficiente la cosa.\nCase la cosa bella Ã¨ che ho un jumping table, quindi rende tutte le operazioni di controllo e salto leggermente piÃ¹ efficienti.\nVelocitÃ  per la jumping table (faccio solo 2 salti, invece in if-then else Ã¨ lineare nel numero di if annidati). Chiarezza del costrutto. Slide case\nEsempio di Jumping table\nIterativi (2) ðŸŸ© I comandi iterativi sono necessari per la turing completezza del linguaggio\nIterazione indeterminata\nSono comandi come while o repeat ... until oppure il do while. Ed Ã¨ indeterminata perchÃ© prima dell\u0026rsquo;esecuzione non so esattamente quante iterazioni andrÃ² a fare. dal punto della macchina fisica Ã¨ molto facile implementarlo, dato che basta un salto con un check, piÃ¹ facile da implementare di un for.\nCon, if, ass, while ho giÃ  un linguaggio turning completo! Esattamente come Ã¨ descritto in Fondamenti teorica.\nIterazione determinata\nQueste sono tutte le iterazioni in cui conosciamo a priori il numero di iterazioni da compiere (a runtime, prima di cominciare l\u0026rsquo;esecuzione del comando), per esempio for e foreach . Di solito credo che nell\u0026rsquo;implementazione si puÃ² calcolare il numero di iterazioni\nSi puÃ² osservare che la iterazione determinata sia meno espressiva dellâ€™iterazione indeterminata, perÃ² da un punto di vista pragmatico Ã¨ molto utile perchÃ© mi compatta tutta la struttura che esisteva per lâ€™iterazione indeterminata.\nMeno espressiva perchÃ© non posso computare programmi come\n$$ f(x) = \\begin{cases} x \\text{ se Ã¨ pari} \\\\ \\uparrow \\text{ altrimenti }\\end{cases} $$ Se ho iterazione determinata non riesco a divergere.\nfor {exp1; expz; exp3) comando Ã¨ la sintassi di C, ma nota che qui non Ã¨ determinata! perchÃ© posso modificare il valore dellâ€™indice e anche del controllo, quindi in pratica Ã¨ equivalente allâ€™iterazione determinata (posso renderlo indeterminato modificando lâ€™indice all\u0026rsquo;interno).\nNOTE DI IMPLEMENTAZIONE\nÃˆ importante capire che in questo caso esiste il vincolo di semantica statica, che il fine e il valore del passo non dovrebbero essere modificati (cosa che non vale in C, per questo non Ã¨ il for settato bene).\nCome fare ad implementare il passo? Se Ã¨ negativo? Proco a costruire il concetto di iteration counter definito come segue:\n$$ ic = \\lfloor \\dfrac{fine - inizio + passo}{passo}\\rfloor $$ +passo perchÃ© il fine Ã¨ incluso nella iterazione, per questo aggiungo 1.\nRicorsione Definizioni induttive ðŸŸ© Una cosa cosa molto interessante Ã¨ che se possediamo una funzione da $g: \\N \\times A \\to A$, e abbiamo una funzione $f: \\N \\to A$, e un qualunque valore $a \\in A$, allora posto\n$$ f(0) = a \\\\ f(n + 1) = g(n, f(n)) $$ f Ã¨ univocamente determinata per tutti i valori del dominio. Basta che g sia una funzione totale.\nCredo che questa definizione della funzione f, sfrutti la struttura dei numeri naturali (la stessa struttura su cui si basa il principio di induzione). Studieremo queste definizioni in maggior dettaglio in informatica teorica.\nIn modo simile una funzione ricorsiva Ã¨ simile a questa, Ã¨ definita in termini di funzioni precedenti giÃ  definite. Nonostante ciÃ² ci possono essere dei casi in cui Ã¨ calcolabile, ma si discosta un pÃ² dalle definizioni matematiche.\nCasi in cui ciÃ² si discosta\nSi puÃ² dimostrare, cosa che non facciamo in questa sede che ricorsione Ã¨ equivalente alla iterazione. Nonostante ciÃ² in alcune implementazioni, in particolare l\u0026rsquo;implementazione standard della ricorsione, questo porti a forti inefficienze. Analizzeremo solamente la tail recursion come ottimizzazione possibile.\nTail recursion ðŸŸ©- Una chiamata di g in f di si dice â€œchiamata in codaâ€ (o tail call) se f restituisce il valore restituito da g senza ulteriore computazione.\nQuando faccio una chiamata ricorsiva alla fine, prima di ritornare dalla funzione, allora posso ottimizzare tutto il discorso che abbiamo fatto sugli RdA in Nomi e Scope, perchÃ© non avrei bisogno di allocare un nuovo RdA, mi basta lo spazio attuale!\nÃˆ una cosa molto particolare perchÃ© con questo riesco a implementare la ricorsione con memoria statica! Un singolo RdA.\nTail recursion si ha quando lâ€™ultima istruzione di ritorno non possiede computazioni aggiuntive, avendo questa proprietÃ , la chiamata della funzione puÃ² essere posta in modo che sovrascriva tutti i parametri, le variabili locali, con l\u0026rsquo;indirizzo di ritorno e il valore di ritorno le stesse della funzione chaiamante.\nIn pratica invece di far crescere continuamente la stack, posso fare in modo di utilizzare lo stesso record scrivendoci i nuovi parametri, un risparmio di memoria non da niente!\n","permalink":"https://flecart.github.io/notes/valutazione-espressioni/","summary":"Ripasso Prox: 40 Ripasso: May 31, 2023 Ultima modifica: May 29, 2023 3:58 PM Primo Abbozzo: March 6, 2023 9:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nElementi di ripasso Espressioni, Comandi, Ricorsione Espressioni Con espressione intendiamo una entitÃ  sintattica, che una volta valutata ritornerÃ  un valore, oppure non termina, in questo caso si dice che la espressione Ã¨ INDEFINITA.\nQuesta Ã¨ una definizione Ã¨ leggermente ambigua dato che non abbiamo una definizione precisa di valutazoine, che Ã¨ fortemente dipendente dalla macchina astratta in cui viene eseguito.","title":"Valutazione Espressioni"},{"content":"Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: June 2, 2022 10:53 AM Studi Personali: No\nElementi di ripasso Preparazione Parte 1 introduzione ai reali NumerabilitÃ  di Q Relazione 5 postulato con th pitagora se ml = n gcd(m,n) = 1, allora n divide l, non ti ricordi proprio. (dimostrazione se n non Ã¨ quadrato perfetto allora la sua radice non appartiene ai Q). (questo si puÃ² estendere anche n come numero razionale con ragionamento simile e non solo n come naturale, non te lo ricordavi al 100 per cento) Surplus: costruzione die numeri Reali con roba di Dedekind Non sapevi enunciare in modo completo la proprietÃ  di completezza dei Reali Cose sbagliate in sta parte Non hai utilizzato il lemma per la dimostrazione della numerabilitÃ , quindi la dimo Ã¨ sbagliata Non ti ricordavi proprio la relazione Successioni e limiti Le successioni monotone hanno sempre un limite (o divergono o convergono, mentre potrebbe essere per certe successioni che nÃ© divergono nÃ© convergono) rifare la dimo di nepero convergenza, forse sbagli qualcosa funzioni varie Dimostrazione della formula della somma dei coseni e dei seni Dimostrazione limite noto del seno ContinuitÃ  Definizione di funzione continua\nDimostrazione continuitÃ  di funzioni seno, coseno e tangente\nDimostrazione teorema degli zeri (imprecisione sull\u0026rsquo;esistenza del limite per le due)\nTeorema di Cauchy nei Teoremi Base Analisi\nHopital sbagli ancora lâ€™enunciato\nSeconda parte Polinomio derivabile ma non continua\nTaylor con resto secondo Lagrange Dimostrazione di Taylor generalizzato Caratterizzazione convessitÃ  ","permalink":"https://flecart.github.io/notes/preparazione-allorale/","summary":"Ultima modifica: October 8, 2022 12:08 PM Primo Abbozzo: June 2, 2022 10:53 AM Studi Personali: No\nElementi di ripasso Preparazione Parte 1 introduzione ai reali NumerabilitÃ  di Q Relazione 5 postulato con th pitagora se ml = n gcd(m,n) = 1, allora n divide l, non ti ricordi proprio. (dimostrazione se n non Ã¨ quadrato perfetto allora la sua radice non appartiene ai Q). (questo si puÃ² estendere anche n come numero razionale con ragionamento simile e non solo n come naturale, non te lo ricordavi al 100 per cento) Surplus: costruzione die numeri Reali con roba di Dedekind Non sapevi enunciare in modo completo la proprietÃ  di completezza dei Reali Cose sbagliate in sta parte Non hai utilizzato il lemma per la dimostrazione della numerabilitÃ , quindi la dimo Ã¨ sbagliata Non ti ricordavi proprio la relazione Successioni e limiti Le successioni monotone hanno sempre un limite (o divergono o convergono, mentre potrebbe essere per certe successioni che nÃ© divergono nÃ© convergono) rifare la dimo di nepero convergenza, forse sbagli qualcosa funzioni varie Dimostrazione della formula della somma dei coseni e dei seni Dimostrazione limite noto del seno ContinuitÃ  Definizione di funzione continua","title":"Preparazione allâ€™orale"},{"content":"Quick introduction Si assume che la descrizione piÃ¹ intelligente di un qualcosa Ã¨ la stringa piÃ¹ corta che descrive quella, un po\u0026rsquo; forse Ã¨ arbitrario, perchÃ© minore complessitÃ , non Ã¨ detto che sia direttamente relazionata con la difficoltÃ  di descriverla.\nNel caso di AIT, diciamo che una cosa random non Ã¨ compressibile, altrimenti posso scriverla in modo piÃ¹ compatto. Ãˆ importante stabilire che l\u0026rsquo;alfabeto che abbiamo per rappresentare qualcosa Ã¨ fissato a priori. Qualunque cosa che possiamo codare si puÃ² analizzare da questo punto di vista della complessitÃ .\nThe complexity of an object is assessed by finding\ntheÂ shortest among the available binary descriptions\nof that object.\nQuesta cosa permette di descrivere la complessitÃ  di un oggetto in modo assoluto (cioÃ¨ a sÃ© stante, mentre la entropia)\nInformation is what is left when any redundant data is thrown away.\nSi basa sulla ipotesi che se tolgo qualcosa comincio a non capirci piÃ¹ diciamo di quella cosa, quindi Ã¨ tutto importante di quella stringa.\nSimple is frequent\nÃˆ una assunzione che si ha su AIT, perÃ² in natura non Ã¨ sempre vero, perchÃ© un sasso lungo puÃ² essere semplice per noi da comprendere, perÃ² resta una cosa rara da trovare per dire. Bisogna capire bene che cosa questa metrica mi sta misurando! La cosa Ã¨ che stranamente questa legge empirica sembra vera sul web! Words are optimally stored in memory according to the frequency of the use. PerÃ² non ci dice come avviene questo processo di aggiornamento della capacitÃ  della mente di fronte all\u0026rsquo;adattarsi a questi dati.\nRelative complexity Complexity of objects in different environments can vary, we say that this is a conditioned complexity: Un esempio banale: Prendiamo un insieme ordinato di elementi, allora posso rappresentare univocamente l\u0026rsquo;elemento tramite la rappresentazione del suo indice. Questo permette di semplificare molto la descrizione di quell\u0026rsquo;oggetto, ma comunque descriverlo nella sua interessa conoscendo il prior.\nWhen an object can be retrieved from a list,\nits complexity within the list can be estimated\nby the length of the binary representation of its rank.\nUpper bound con complexity When an object belongs to a set of size $N$,\nits complexity in that set cannot exceedÂ $\\log_{2}(N)$\nPer utilizzare l\u0026rsquo;indexing di una lista, mi basta poter essere in grado di codificare il numero piÃ¹ alto presente, quindi la grandezza dell\u0026rsquo;insieme per descrivere l\u0026rsquo;elemento, per questo motivo posso affermare la frase di sopra. Questo bound mi permette di descrivere la complessitÃ  di oggetti senza ordine.\nRappresentazione dei Numeri interi Con la rappresentazione normale binaria dei numeri, possiamo avere necessitÃ  di $$ \\lceil \\log_{2}(n + 1) \\rceil $$ Usiamo il $+1$ per risolvere il problema col logaritmo di 0, questa comunque Ã¨ una buona misura. Solo che non Ã¨ il codice minimo, possiamo prendere il codice $\\lceil \\log_{2}(n + 3) - 1 \\rceil$ come un codice migliore, perchÃ© possiamo togliere 1 perchÃ© iniziamo a contare con la cifra 1. Possiamo prefixare qualcosa per scegliere il metodo di codifica. Per esempio un numero $90000$ si puÃ² encodare come $9$ con $4$ per encodare l\u0026rsquo;esponente del 10. Ma spendiamo il bit per indexare il metodo di codifica.\nIn generale per rappresentare cose non numeri, si possono utilizzare strutture che rappresentano univocamente quell\u0026rsquo;oggetto e poi usare la complessitÃ  su queste strutture. Non Ã¨ chiaro sempre come utilizzare queste strutture.\nQuasi-continuous complexity In questa parte analizziamo come varia la lunghezza di descrizione per i numeri, notiamo che segue piÃ¹ o meno la curva logaritmica, con i drops previsti per i numeri rotondi, come da intuizione (lo schema di coding presentato ha questa proprietÃ ).\nPer dire che Ã¨ una funzione quasi continua scriviamo $$ \\lvert C(n + h) - C(n) \\rvert \\leq f(\\lvert h \\rvert ) + O(1) $$ Mentre sappiamo che per una funzione continua quello dovrebbe essere 0.\nGenerati da questo codice CompressibilitÃ  di stringhe binarie Un risultato che consegue dalla limitatezza di stringhe di bassa lunghezza abbiamo che:\nSe dati un insieme di tutte le stringhe binarie lunghe $N$, volessimo contrarre la descrizione di almeno $k$, avremmo che solo $\\frac{1}{2^{k - 1}}$ delle $2^{N}$ stringhe iniziali possono essere compresse per $k$ o piÃ¹ digits.\nDimostrazione: La quantitÃ  di stringhe disponibili per la rappresentazione sono $$ \\sum_{i=k}^{N} 2^{N - i} = 2^{N - k + 1} - 1 $$ E approssimando abbiamo che $$ \\frac{2^{N - k + 1}}{2^{N}} = \\frac{1}{2^{k - 1}} $$ E questo Ã¨ un valore che decresce in modo esponenziale, per questo le stringhe compressibili di molto sono veramente veramente poche.\nUna cosa interessante Ã¨ che per qualunque compressore $Z$ che si possa creare, se prendiamo sequenze binarie $N$ almeno una non Ã¨ compressibile.\nExpanding compressors Una osservazione banale ci dice che se il compressore Ã¨ una funzione con stesso dominio e codominio, e che sia iniettiva affinchÃ© sia univocamente decodabile, allora certe stringhe vengono espande invece che compresse! Solitamente nella pratica l\u0026rsquo;espansione succede perchÃ© il compressore aggiunge dei markers per dire che Ã¨ stato compresso.\nQuesto ci dice che il compressor non deve comprimere sempre, ma solamente comprimere in modo dipendente dal contesto secondo me.\nZipf\u0026rsquo;s Law Elaborato insieme a un altro tizio che si chiama Condon relaziona la frequenza di una parola nel linguaggio con il rank, ossia un dizionario che ordina le parole per frequenza d\u0026rsquo;uso. https://babel.hathitrust.org/cgi/pt?id=mdp.39015008729983\u0026amp;view=1up\u0026amp;seq=7 Il contributo di Zips Ã¨ una spiegazione di questo fenomeno empirico dato da Condon.\nEnunciato di Zipf $$ r_{f}(w) \\approx \\frac{c}{f(w)} $$ dove $f(w)$ Ã¨ la frequenza della parola, e $r_{f}(w)$ Ã¨ il suo rank, con una costante a caso $c$.\nThis means that the 10thÂ most frequent word is 10 times more frequent than the 100thÂ most frequent word, which is itself 10 times more frequent than the 1000thÂ most frequent word, which is itself 10 times more frequent than the 10Â 000thÂ most frequent word, and so on\nSembra che questa legge valga per molte lingue, non solo l\u0026rsquo;inglese.\nMinimize effort and time to find the right word to use. Questa Ã¨ la spiegazione a questo fenomeno.\nCorrispondenza sulla complessitÃ  dei codici Complexity of the meaning = complexity of word Complexity is related to the frequency of the word Questo spiega anche cose sulla ripetizione spaziata in (Brown et al. 2014). E ha senso, cose che vediamo piÃ¹ spesso ci appaiono come semplici, cose che vediamo singola volta sono abbastanza complesse, la relazione sulla complessitÃ  sembra essere fortemente legata alla frequenza della parola. Che bella idea.\nNormalized information distance Basato su (Li et al. 2004).\nFor any pair of objects, NID determines what is common to them, and only keeps their difference to measure the distance that separates them.\nCalcolo del NID Misurare la differenza di informazione attraverso il Kolmogorov Condizionato quindi $max[K(x|y), K(y|x)]$ il max ci aiuta a rendere la distanza simmetrica. Normalizzare la differenza di informazione, perchÃ© vogliamo una nota relativa di questa misura. $max(K(x), K(y))$ che rappresenta la massima complessitÃ  di entrambi gli oggetti che vogliamo confrontare. Usare Kolmogorov complexity#Chain Rule cosicchÃ© possiamo riscrivere il numeratore. In questo modo otteniamo (a volte definito con la prima parte) $$ NCD(x, y) = \\frac{K(x, y) - min[K(x), K(y)]}{max(K(x), K(y))} $$ $$ NCD(x, y) = \\frac{max[K(x|y), K(y|x)]}{max(K(x), K(y))} $$ Questo non Ã¨ computabile perchÃ© $K$ non Ã¨ computabile, ma possiamo stimarlo con un compressore reale. La cosa triste Ã¨ che il compressore non prende in considerazione la semantica. Per la semantica Ã¨ interessante usare la (Cilibrasi \u0026amp; Vitanyi 2007), usando google per stimare la distanza. e questa la chiama la Normalized Google Distance.\nUniversal distance Questo Ã¨ lavoro di Charles Bennet in 1998. (information Dista) $$ \\forall D; \\forall x, y: D_{U}(x, y) \u003c D(x, y) + C_{D} $$ Questo: $max[K(x|y), K(y|x)]$ Ã¨ una distanza universale. Che Ã¨ una cosa molto interessante.\nReferences [1] Brown et al. â€œMake It Stick: The Science of Successful Learningâ€ Harvard University Press 2014\n[2] Cilibrasi \u0026amp; Vitanyi â€œThe Google Similarity Distanceâ€ arXiv preprint arXiv:cs/0412098 2007\n[3] Li et al. â€œThe Similarity Metricâ€ IEEE Transactions on Information Theory Vol. 50(12), pp. 3250\u0026ndash;3264 2004\n","permalink":"https://flecart.github.io/notes/introduction-to-algorithmic-information-and-complexity/","summary":"Quick introduction Si assume che la descrizione piÃ¹ intelligente di un qualcosa Ã¨ la stringa piÃ¹ corta che descrive quella, un po\u0026rsquo; forse Ã¨ arbitrario, perchÃ© minore complessitÃ , non Ã¨ detto che sia direttamente relazionata con la difficoltÃ  di descriverla.\nNel caso di AIT, diciamo che una cosa random non Ã¨ compressibile, altrimenti posso scriverla in modo piÃ¹ compatto. Ãˆ importante stabilire che l\u0026rsquo;alfabeto che abbiamo per rappresentare qualcosa Ã¨ fissato a priori.","title":"Introduction to Algorithmic Information and Complexity"},{"content":"Ultima modifica: September 30, 2022 3:20 PM Primo Abbozzo: December 23, 2021 4:43 PM Studi Personali: No\nElementi di ripasso PerchÃ© la riduzione allâ€™assurdo crea cosÃ¬ tanti problemi alla logica intuizionista? Esercizi per induzione strutturale Concetti da ripassare Fare un esercizio di dimostrazione teoria degli insiemi con relazioni e funzioni in Relazioni fra insiemi Concetti da NON fare se NON fai lâ€™orale Paradossi presentati in Logica meta-linguistica assiomi di regolaritÃ  o fondazione e rimpiazzamento in Teoria assiomatica degli insiemi Studiare le relazioni con lâ€™infinito in Relazioni fra insiemi come Hilbert, diagonalizzazione, aleph, Cantor Costruzione di R. Pseudo linguaggio non tipato, il significato di sintassi, BNF (e induzioni) in Sintassi e RI strutturali Il fatto che puoi utilizzare la stessa proposizione in mondi diversi, basta che utilizzino le stesse variabili e siano le stesse proposizoni in 10.4 Connettivi Logici, correttezza, variabili La dimostrazione e il significato del teorema di invarianza Connettivi Logici, correttezza, variabili il significato della compattezza in Connettivi Logici, correttezza, variabili Nozione di invertibilitÃ , armonia, derivabilitÃ  in Deduzione naturale Significato della compattezza in Semantica intuizionista Non lo chiedera probabilmente allo scritto, ma se si vuole fare anche le logiche intuizioniste Semantica intuizionista la compattezza in Semantica intuizionista Non lo chiedera probabilmente allo scritto, ma se si vuole fare anche le logiche intuizioniste Semantica intuizionista ","permalink":"https://flecart.github.io/notes/preparazione-esame-logica/","summary":"Ultima modifica: September 30, 2022 3:20 PM Primo Abbozzo: December 23, 2021 4:43 PM Studi Personali: No\nElementi di ripasso PerchÃ© la riduzione allâ€™assurdo crea cosÃ¬ tanti problemi alla logica intuizionista? Esercizi per induzione strutturale Concetti da ripassare Fare un esercizio di dimostrazione teoria degli insiemi con relazioni e funzioni in Relazioni fra insiemi Concetti da NON fare se NON fai lâ€™orale Paradossi presentati in Logica meta-linguistica assiomi di regolaritÃ  o fondazione e rimpiazzamento in Teoria assiomatica degli insiemi Studiare le relazioni con lâ€™infinito in Relazioni fra insiemi come Hilbert, diagonalizzazione, aleph, Cantor Costruzione di R.","title":"Preparazione esame logica"},{"content":"Ripasso: June 8, 2023 Ultima modifica: May 7, 2023 2:30 PM Primo Abbozzo: April 17, 2023 4:11 PM Studi Personali: No\nElementi di ripasso AccessibilitÃ  Ci chiediamo come facciamo a rendere sistemi informatici accessibili a persone attraverso certe tecnologie.\nSlide esempi di disabilitÃ \nÃˆ meglio renderlo accessibile perchÃ© Ã¨ illegale (nel senso che stai facendo una discriminazione verso un certo insieme di persone).\nWGAC Queste sono alcuni principi di accessibilitÃ , basati su 4 principi fondamentali\n4 principi del WGAC POUR per facilitÃ  di ricordarsi\nPerceivable (che ci siano le informazioni necessarie per l\u0026rsquo;accessibilitÃ ) Operable Understandable Robus Linguaggio Il tag del linguaggio Ã¨ utilizzato per sapere in che accento leggere e dare gli ordini.\nImmagini C\u0026rsquo;Ã¨ una distinzione fra immagini decorative e non decorative, quelle decorative sono funzioni estetiche che vengono ignorate dai lettori. (si lasca la alt vuota).\nIntestazioni Dovremmo annidare solamente dei h2 in h1 e non viceversa!\nTabella Form Wrapping label Ã¨ un metodo Altrimenti ci metto un for (quindi label for) ","permalink":"https://flecart.github.io/notes/accessibilit%C3%A0/","summary":"Ripasso: June 8, 2023 Ultima modifica: May 7, 2023 2:30 PM Primo Abbozzo: April 17, 2023 4:11 PM Studi Personali: No\nElementi di ripasso AccessibilitÃ  Ci chiediamo come facciamo a rendere sistemi informatici accessibili a persone attraverso certe tecnologie.\nSlide esempi di disabilitÃ \nÃˆ meglio renderlo accessibile perchÃ© Ã¨ illegale (nel senso che stai facendo una discriminazione verso un certo insieme di persone).\nWGAC Queste sono alcuni principi di accessibilitÃ , basati su 4 principi fondamentali","title":"AccessibilitÃ "},{"content":"introduzione ai dielettrici Esperimenti metalli e dielettrici ðŸŸ© Verso gli anni del 1840 Faraday ha fatto molti sistematici esperimenti per scoprire come si comportava il potenziale e il campo elettrico di fronte a certi materiali. Sono stati principalmente posti delle sostanza (conduttrici o meno) in mezzo a lastre di condensatori, e hanno misurato come cambiava il potenziale elettrico fra le due lastre (che si puÃ² vedere attraverso il modo con cui cambiano sull\u0026rsquo;elettroscopio). CosÃ¬ ha scoperto che $$ V_{s} = (h - s) E_{0} $$ Questo Ã¨ vero perchÃ© semplicemente in mezzo al conduttore il campo elettrico Ã¨ nullo, come spiegato in Conduttori elettrici, quindi durante l\u0026rsquo;integrale, il percorso Ã¨ semplicemente minore, esattamente di quella quantitÃ .\nNel caso di condensatore con spessore $h$ e materiale conduttore di spessore $s$ in mezzo. Ma questo non succedeva se metteva materiali isolanti! In questi il potenziale cadeva piÃ¹ lentamente rispetto al metallo, ma comunque cadeva di un po\u0026rsquo;, in modo lineare fino a riempire l\u0026rsquo;intero spazio. Il potenziale in questo ultimo stadio lo chiamiamo $V_{k}$ e sperimentalmente hanno notato che vale sempre $$ k = \\frac{V_{0}}{V_{k}} \u003c 1 $$ Costante dielettrica relativa ðŸŸ© Questa quantitÃ  non Ã¨ molto importante, forse semplifica i conti ma Ã¨ utile a descrivere il nuovo campo elettrico, perchÃ© se si assume di avere un campo uniforme allora abbiamo: $$ E_{k} = \\frac{V_{k}}{h} = \\frac{V_{0}}{kh} = \\frac{E_{0}}{k} = \\frac{\\sigma_{0}}{k\\varepsilon_{0}} = \\frac{\\sigma_{k}}{\\varepsilon_{0}} = \\frac{\\sigma_{0}}{\\varepsilon} $$ L\u0026rsquo;ultimo valore possiamo scriverlo come se avessimo una carica intermedia, saltando i calcoli (un esercizio che trovi nel Mazzoldi p/128) Abbiamo che $$ E_{k} = \\frac{\\sigma_{0}}{\\varepsilon_{0}} - \\frac{\\sigma_{p}}{\\varepsilon_{0}} $$ Con $$ \\sigma_{p} = \\frac{k - 1}{k} \\sigma_{0} $$ E si potrebbe definire anche $$ \\sigma_{k} = \\sigma_{0} - \\sigma_{p} = \\frac{\\sigma_{0}}{k} $$ Qui si puÃ² giocare un po\u0026rsquo; senza nessun problema!\nL\u0026rsquo;equazione del nuovo campo elettrico Ã¨ utile per avere una intuizione, Ã¨ come se esistesse un campo contrario creato dal dielettrico, che ne affievolisce l\u0026rsquo;intensitÃ , questo sarÃ  spiegato meglio dopo, esisteranno seriamente queste cariche!\nCostante dielettrica assoluta del dielettrico ðŸŸ© Si trova che le relazioni di sopra funzionano per condensatori rotondi, piani, di qualunque forma, basta che siano condensatori (quindi ci sia l\u0026rsquo;induzione completa e abbiano stessa carica). Infatti abbiamo anche cose come $$ C_{p} = \\frac{q}{V_{p}} = \\frac{qk}{V_{0}} = k C_{0} $$ Ma andando a definire la nuova costante dielettrica abbiamo: $$ \\text{costante dielettrica assoluta del dielettrico: }\\varepsilon = k\\varepsilon_{0} $$ Che Ã¨ il nostro nuovo valore! Per i condensatori piani abbiamo $$ C_{p} = kC_{0} = k \\varepsilon_{0} \\frac{S}{d} = \\frac{\\varepsilon S}{d} $$ E notiamo che cambia solamente il valore di dielettrico, Ã¨ ancora molto clean la relazione.\nSecondo me non ha senso questa parte e possiamo soltanto dire che la capacitÃ  cresce col dielettrico\nPolarizzazione del dielettrico Polarizzazione per deformazione/elettronica ðŸŸ¨+ Questa polarizzazione si spiega a un **livello atomico** perchÃ© intuitivamente si puÃ² dire che il punto medio delle cariche elettriche positive (nucleo) e negative (nube di elettroni) quando viene sottoposto a un campo elettrico si spostano, per cercare di bilanciare la piccola forza applicata dal campo elettrico, quindi Ã¨ un valore direttamente proporzionale al valore del campo elettrico, In questo caso: $$ \\vec{p}_{e} = Ze\\vec{x} $$ Con x il vettore della congiungente, $Z$ numero atomico $e$ la carica basilare dell'elettrone. Da quanto studiato in [Dipolo elettrico](/notes/dipolo-elettrico), quando ho un momento, c'Ã¨ un campo indotto. Insieme a questo, i mini dipoli si orientano sul verso del campo elettrico.\nPolarizzazione per orientamento (non fatta) Questo viene usato per discutere a livello molecolare come avviene la polarizzazione. Se prendo molecole polari, come l\u0026rsquo;acqua, si avrÃ  che piÃ¹ Ã¨ sottoposta a campo intenso, piÃ¹ in media i dipoli saranno orientati sul campo, infatti se non lo sono allora ci sarÃ  un momento di dipolo che proverÃ  a riportarli in quello stato, come studiato in Dipolo elettrico nella sezione dei momenti di dipolo.\nLa differenza col precedente Ã¨ che questo Ã¨ solamente un effetto di media!\nSuscettibilitÃ  elettrica (!) Definizione di suscettibilitÃ  elettrica ðŸŸ© Andiamo a chiamare la quantitÃ  $$ \\text{ suscettivitÃ  dielettrica: } \\chi = k - 1 = \\frac{V_{k}}{V_{0}} - 1 $$ Andiamo a definire un valore $P$ che spiega quanto dipolo creato dal campo, ed Ã¨ in pratica momento di dipolo per unitÃ  di volume. Solitamente assume questa forma: $$\nP = \\varepsilon_{0}\\chi E $$ Se un dielettrico soddisfa questa relazione (solitamente Ã¨ omogeneo) si dice che sia dielettrico lineare, solitamente materiali amorfi (senza forma), dotati di isometria spaziale, nei cristalli in genere questo non succede.\nDimostrazione valore ðŸŸ¨ NOTA: nell'immagine ho sbagliato a disegnare il verso dei singoli atomi allungati. Assumiamo di immergere un dielettrico in un campo elettrico uniforme, allora abbiamo che $$ \\sigma_{p} = nq\\delta $$ PerchÃ© in pratica $n = \\frac{\\Delta N}{\\Delta \\tau}$ Ã¨ la densitÃ  atomica (numeri di atomi per unitÃ  di volume), io con la relazione di sopra sto anche moltiplicando per la lunghezza del tratto considerato, quindi $n\\delta$ rappresenta numero di atomi nella superficie (dato che $n$ Ã¨ il numero di atomi per volume, moltiplicando per una lunghezza ho la densitÃ  superficiale), e $q$ gli do la carica, dimensionalmente torna l\u0026rsquo;idea. Ogni atomo ha $q$ di carica a causa della polarizzazione.\nMa allo stesso tempo il momento di dipolo di un singolo atomo Ã¨ $\\vec{p} = q\\vec{\\delta}$, e cosÃ¬ che definisco il momento di dipolo per unitÃ  di volume come $\\vec{P} = nq\\vec{\\delta}$ (sul libro Ã¨ presentato come $\\vec{P} = n \u003c \\vec{p}\u003e$) allora abbiamo che $$ \\sigma_{p} = \\lvert \\vec{P} \\rvert $$ Nel caso piÃ¹ generale (in immagine) in cui il campo elettrico non Ã¨ perpendicolare al piano del dielettrico si ha $$ \\sigma_{p} = \\vec{P} \\cdot \\hat{n} $$ Applicando questo su una formula di sopra abbiamo: $$ E = \\frac{\\sigma_{0} - \\sigma_{p}}{\\varepsilon_{0}} = \\frac{\\sigma_{0} - \\lvert \\vec{P} \\rvert}{\\varepsilon_{0}} \\implies P = \\sigma_{0} - \\varepsilon_{0}E = kE\\varepsilon_{0} - \\varepsilon_{0} E = \\varepsilon_{0}E(k - 1) = \\varepsilon_{0}E\\chi $$ Valore tensoriale ðŸŸ© Solitamente per materiali non isotropi Ã¨ un tensore, quindi lo abbiamo in una forma del genere $$ \\begin{pmatrix} P_{x} \\ P_{y} \\ P_{z}\n\\end{pmatrix} \\begin{pmatrix} \\chi_{11} \u0026amp; \\chi_{12} \u0026amp; \\chi_{13} \\ \\chi_{21} \u0026amp; \\chi_{22} \u0026amp; \\chi_{23} \\ \\chi_{31} \u0026amp; \\chi_{32} \u0026amp; \\chi_{33} \\\n\\end{pmatrix} \\cdot \\begin{pmatrix} E_{x} \\ E_{y} \\ E_{z} \\end{pmatrix} $$ Ma per qualche motivo che non conosco $\\chi$ Ã¨ una **matrice simmetrica reale** questo implica che Ã¨ diagonalizzabile per cui esiste una base di autovalori, che permette di riscrivere la matrice di sopra come $$ \\begin{pmatrix} P_{x} \\ P_{y} \\ P_{z} \\end{pmatrix} \\begin{pmatrix} \\chi_{11}\u0026rsquo; \u0026amp; 0 \u0026amp; 0 \\ 0 \u0026amp; \\chi_{22}\u0026rsquo; \u0026amp; 0 \\ 0 \u0026amp; 0 \u0026amp; \\chi_{33}' \\end{pmatrix} \\cdot \\begin{pmatrix} E_{x} \\ E_{y} \\ E_{z} \\end{pmatrix} $$ Che Ã¨ anche piÃ¹ veloce da calcolare. La base di autovalori si chiama anche asse ottico\nPolarizzazione in materiali non omogenei Caso dipolo omogeneo ðŸŸ© Questo Ã¨ come il caso di flusso esterno in una superficie qualunque. Presa una qualunque superficie $\\Sigma$, abbiamo che: $$ \\Delta Q = \\oint_{\\Sigma} \\vec{P} \\cdot d\\vec{s} = 0 $$ Si puÃ² dire che Ã¨ uguale a zero perchÃ© il flusso esce ed entra, per lo stesso valore.\nCaso dipolo non omogeneo ðŸŸ© sia $\\Delta Q'$ la carica rimasta internamente al volume, dato che il dielettrico Ã¨ neutro abbiamo che Ã¨ uguale ed opposta a quella rimasta all\u0026rsquo;esterno, che chiamiamo $\\Delta Q$ Quindi abbiamo che $$ \\Delta Q = \\oint_{\\Sigma}\\vec{P} d\\vec{s} = \\int _{V(\\tau)} \\vec{\\nabla} \\cdot\\vec{P} \\, d\\tau $$ Dove abbiamo utilizzato il teorema della divergenza spiegato in Divergenza e Circuitazione Allora, motivati dal fatto che internamente $Q' = \\int _{V(\\tau)} \\rho \\, d\\tau$ Possiamo definire $$ \\vec{\\nabla} \\cdot \\vec{P} = - \\rho_{i} $$ Ossia la divergenza del momento di dipolo per unitÃ  di volume Ã¨ uguale a meno densitÃ  di volume elettrico indotto internamente.\nEquazioni di Gauss rivisitate ðŸŸ© Possiamo ora aggiornare le equazioni di gauss andando a contare gli effetti del dipolo in modo esplicito, abbiamo che\nForma divergente Forma integrale $\\vec{\\nabla} \\cdot \\vec{E} = \\frac{\\rho}{\\varepsilon_{0}}$ $\\oint_{\\Sigma} \\vec{E} \\cdot d\\vec{s}$ $\\vec{\\nabla} \\times \\vec{E} = 0$ $\\oint_{\\Gamma} \\vec{E} \\cdot d\\vec{s} = 0$ $\\vec{\\nabla} \\cdot \\vec{P} = -\\rho_{p}$ $\\oint_{\\Sigma} \\vec{P} \\cdot d\\vec{s} = Q_{p}$ $\\vec{\\nabla} \\cdot \\vec{D} = \\rho_{\\text{libero}}$ $\\oint_{\\Sigma} \\vec{D} \\cdot d\\vec{s} = Q_{L}$ Andiamo ad osservare la forma divergente di Gauss, abbiamo che $\\rho = \\rho_{libero} + \\rho_{pol}$ ossia della carica libera piÃ¹ quella indotta da polarizzazione, approfondendo quello deriviamo: $$ \\vec{\\nabla} \\cdot \\vec{E} = \\frac{\\rho_{libero}}{\\varepsilon_{0}} + \\frac{\\rho_{pol}}{\\varepsilon_{0}} \\implies \\varepsilon_{0} \\vec{\\nabla} \\cdot \\vec{E} = \\rho_{libero} - \\vec{\\nabla} \\cdot \\vec{P} \\implies \\vec{\\nabla}(\\varepsilon_{0} \\vec{E} + \\vec{P}) = \\rho_{libero} $$ Vettore di spostamento elettrico/induzione dielettrica ðŸŸ© Il vettore che abbiamo trovato poco sopra ha un significato speciale, proviamo ad analizzare proprietÃ  di $$ \\vec{D} = \\varepsilon_{0}\\vec{E} + \\vec{P} = \\varepsilon_{0}(\\vec{E} + \\chi \\vec{E}) = k\\vec{E}\\varepsilon_{0} = \\varepsilon \\vec{E} $$ Con questo poi possiamo ri-caratterizzare il vettore di momento di dipolo come $$ \\vec{P} = \\frac{k-1}{k} \\vec{D} $$ Possiamo notare che il vettore di spostamento non Ã¨ altro che il campo elettrico per un dielettrico differente.\nChe saranno una conseguenza diretta delle equazioni di sopra: $$ \\vec{\\nabla} \\cdot \\vec{D} = \\rho_{libero} $$ $$ \\oint_{\\Sigma} \\vec{D} \\cdot d\\vec{s} = Q_{L} $$ Ossia questo Ã¨ un valore che dipende solamente dalla carica LIBERA, per questo vettore di spostamento posso ignorare il valore di polarizzazione indotta.\nDiscontinuitÃ  nei dielettrici Sappiamo che le componenti tangenti vengono conservate passando da una superficie all\u0026rsquo;altra (vedi Campo elettrico), e anche le discontinuitÃ  per componenti perpendicolari. Ora vogliamo vedere se vale la stessa cosa nei dielettrici, quando abbiamo solamente cariche di polarizzazione, ed entrambi valgono ancora (ma la sigma nel secondo caso Ã¨ di polarizzazione)\nDiscontinuitÃ  superficiale ðŸŸ©\u0026ndash; $$ \\oint_{\\Sigma}\\vec{E} d\\vec{s} = \\frac{Q_{T}}{\\varepsilon_{0}} \\implies \\Delta E_{\\perp} = \\frac{\\sigma_{p}}{\\varepsilon_{0}} $$ Da quanto fatto col vettore di spostamento avrebbe senso vedere cosa succede in quel caso. dato che dipende solamente da cariche libere abbiamo che\n$$ \\oint_{\\Sigma}\\vec{D} d\\vec{s} = Q_{Libero} = 0 $$ Quindi il vettore di spostamento per il dielettrico Ã¨ ancora costante, non varia diciamo passando da una superficie all\u0026rsquo;altra, quindi Ã¨ continua.\nAndiamo a fare la stessa analisi in immagine, assumendo che $dh \\to 0$ quindi non abbiamo flusso verticale $$ \\vec{D}_{1}d\\vec{S}_{1} + \\vec{D}_{2}d\\vec{S}_{2} = 0 \\implies \\vec{D}_{1}\\cos \\theta_{1} + \\vec{D}_{2} \\cos \\theta_{2} = 0 \\implies D_{1}\\cos \\theta_{1} - D_{2} \\cos \\theta_{2} = 0 $$ Quindi $$ \\Delta D_{N} = 0 $$ Legge di Snell revisited ðŸŸ©\u0026ndash; Una volte descritte le equazioni di continuitÃ  ricavare questo Ã¨ molto semplice, poi Ã¨ molto molto simile (opposto) a quanto fatto per Magnetismo nella materia per la continuitÃ  dei campi magnetici nel passare su superfici con correnti.\nSappiamo che $E_{\\parallel}^{1} = E_{\\parallel}^{2}$, che $E_{\\perp}^{1} = E_{\\perp}^{2}$ e che $D_{\\perp}^{1} = D_{\\perp}^{2}$ E che $\\vec{D} = \\varepsilon_{0}k\\vec{E}$ Da quello sappiamo che $$ \\varepsilon_{0} k_{1} E^{1}_{\\perp} = \\varepsilon_{0}k_{2}E_{\\perp}^{2} $$ Riscrivendo le relazioni precedenti abbiamo: $$ \\begin{cases} E_{1}\\sin \\theta_{1} = E_{2}\\sin \\theta_{2} \\\\ k_{1}E_{1}\\cos \\theta_{1} = k_{2}E_{2} \\cos \\theta_{2} \\end{cases} \\implies \\frac{\\tan \\theta_{1}}{k_{1}} = \\frac{\\tan \\theta_{2}}{k_{2}} \\implies \\frac{k_{2}}{k_{1}} = \\frac{\\tan \\theta_{2}}{\\tan \\theta_{1}} $$ Quindi so esattamente in che modo il modulo e la direzione di $E$ cambia all\u0026rsquo;interno della superficie di separazione dei mezzi. Quindi se passo da superficie con $k_{2}$ piÃ¹ alto i raggi tendono verso l\u0026rsquo;esterno (angolo piÃ¹ grande), e stessa cosa al contrario. NOTA: il modulo del campo elettrico cambia sempre. NOTA-2: basta guardare le linee di campo per sapere se il materiale Ã¨ conduttore o meno (perchÃ© per il conduttore cambia le linee di campo anche all\u0026rsquo;esterno).\nEnergia nei condensatori con dielettrico (!) Derivazione con dielettrico ðŸŸ©\u0026ndash; Sappiamo che l\u0026rsquo;energia totale Ã¨ ancora $$ U_{e} = \\frac{1}{2} CV^{2} = \\frac{1}{2} \\frac{\\varepsilon S}{d} V_{k}^{2} = \\frac{1}{2} \\varepsilon S E_{k}^{2}d = \\frac{1}{2}\\varepsilon E_{k}^{2} (Sd) = u_{e} \\cdot \\text{ Volume} $$ Solo che Ã¨ da considerare la $E_{k}$ presente con il dielettrico che Ã¨ uguale a $\\frac{E_{0}}{k}$ Possiamo calcolarlo anche in altro modo: $$ U = \\frac{1}{2} \\frac{Q^{2}}{C} = \\frac{1}{2} (\\sigma S)^{2} \\cdot \\frac{d}{\\varepsilon S} = \\frac{1}{2} \\varepsilon\\frac{\\sigma^{2}}{\\varepsilon^{2}} \\cdot Sd \\frac{1}{2}\\varepsilon E^{2} \\cdot Sd $$ E viene ugualmente come prima\nCon vettore di spostamento ðŸŸ© abbiamo, considerando che $\\vec{D} = \\varepsilon \\vec{E}$, vale per dielettrico isotropo, ma per quello anisotropo, in cui non sono piÃ¹ paralleli come si fa?\n$$ u_{E} = \\frac{1}{2} \\varepsilon E^{2}_{k} = \\frac{1}{2} \\frac{D^{2}}{\\varepsilon} $$ A paritÃ  di campo elettrico, spendo molta quantitÃ  di energia in piÃ¹ per caricarlo.\nMateriale anisotropo ðŸŸ©\u0026ndash; $$ u_{E} = \\frac{1}{2}\\varepsilon E^{2} = \\frac{1}{2} \\vec{E} \\cdot \\vec{D} $$ PerchÃ© devo contare la parte parallela.\n","permalink":"https://flecart.github.io/notes/condensatori-con-dielettrici/","summary":"introduzione ai dielettrici Esperimenti metalli e dielettrici ðŸŸ© Verso gli anni del 1840 Faraday ha fatto molti sistematici esperimenti per scoprire come si comportava il potenziale e il campo elettrico di fronte a certi materiali. Sono stati principalmente posti delle sostanza (conduttrici o meno) in mezzo a lastre di condensatori, e hanno misurato come cambiava il potenziale elettrico fra le due lastre (che si puÃ² vedere attraverso il modo con cui cambiano sull\u0026rsquo;elettroscopio).","title":"Condensatori con dielettrici"},{"content":"Processo design del database Il design Some design steps (3) (non impo) How to gather requirements? ðŸŸ¨+ Come si puÃ² raccogliere i dati degli utilizzatori?\nparlare col il personale che dovrÃ  utilizzare questi sistemi Documentazione esistente Interview di persone che dovrÃ  utilizzare queste risorse O Moduli per fare sampling Top-down approach La cosa brutta Ã¨ che questi requisiti non possono essere standardizzati, ci sono molte necessitÃ , molto diverse fra i loro, quindi Ã¨ utile andare a parlare con gli esperti e capire cosa abbiano bisogno per i dati. Consiglio del prof. Ã¨ partire dai senior e poi scendere, perchÃ© quelli in alto hanno un punto di vista piÃ¹ ampio ma con meno dettagli diciamo.\nHow to ask the requirements Ãˆ molto facile non capire un interlocutore, basta usare il gergo specifico di quell\u0026rsquo;ambito. Anche i maranza per esempio hanno il proprio gergo che non Ã¨ comprensibile. Bisogna chiedere cosa hai bisogno, secondo le necessitÃ  soprattutto! Esempi possono semplificare un sacco. Una cosa molto importante Ã¨ mantenere il linguaggio semplice e fare le domande giuste (dividere le domande funzionali con le domande di dati utili da memorizzare). Ãˆ difficile sapere cosa Ã¨ importante mantenere per una istituzione. Solitamente se usano un gergo specifico Ã¨ bene provare a comprendere cosa significhi la parola specifica. Un bias comune Ã¨ che le persone tendono a parlare di problemi recenti, che non potrebbero riflettere le necessitÃ  a lungo termine per i dati.\nUn glossario dei termini Ã¨ molto importante per stabilire il significato in quel contesto.\nHow to create entities and relations? (4) ##### Storicizzazione (!) PuÃ² essere fatta in due modi, o con due relazioni, oppure con una generalizzazione. Metodi di modellazione Top down ðŸŸ© Parto dai requisiti e provo a raffinarli passo passo fino ad avere uno schema finale Bottom up ðŸŸ© Parto dalle specifiche e costruisco i singoli componenti fino ad arrivare a schemi collegati assieme Inside out ðŸŸ© Parto da un requisito chiaro, che costruisco e poi inizio a costruire gli altri secondo quando bene ho capito sono relazionati.\nSteps per design concettuale Per il prof. si puÃ² passare al design logico subito se si Ã¨ molto bravi, perÃ² il suo consiglio Ã¨ sempre partire da alto livello e poi andare a definire tutte le relazioni. Entity-Relationship model Introduction to modeling phases The conceptual modelling phase ðŸŸ© It\u0026rsquo;s a data representation is independent from the system, but it\u0026rsquo;s useful to show how are the different entities connected to each other.\nQuesta Ã¨ la prima fase del processo di design di un database, nasce principalmente da una inefficacy of the relational structure (too much information), quindi si vuole usare come via di alto livello per analizzare la struttura!\nVisual documentation that is useful for docs. Other modelling phases (2) ðŸŸ© Logico, ne parliamo in Database logical design e poi il fisico non viene trattato in questo corso, e dovrebbe essere bene astratto.\nEntity Definition of entity ðŸŸ© An entity represents a class of \u0026ldquo;objects\u0026rdquo; sharing common properties, but still having an autonomous existence. It is clearly heavily linked to the concept of object in OOP (see Classi OOP), that is the framework where the ER model was born.\nEntity identifier, internal ðŸŸ© NOTA: queste non sono chiavi! Si chiamano in modo diverso! It could be an internal identifier formed by the attributes of the single relationship, or external if it is identified by some kind of relationship. External identifier ðŸŸ© #### Generalization and specialization ðŸŸ© One entity $E$ could be composed by many components $E_{1}, E_{2}, \\dots E_{N}$, this is a **generalization** relationship, the inverse is a a specialization. There are also some properties to consider: - Every property in $E_{i}$ is used in some way in $E$ - Every instance of $E_{i}$ is an instance of $E$ too. Types of generalization (2) ðŸŸ© It could be total/partial or disjoint/Overlapped. It is total if the parent is totally composed by the child entities, otherwise it\u0026rsquo;s partial. A total relationship has a full arrow, while a partial has an outlined arrow as pointer.\nIt is disjoint if the children doesn\u0026rsquo;t have anything in common (property-wise) and overlapped otherwise.\nData dictionary (3) ðŸŸ© The data dictionary is a quick way to represent the conceptual model, some examples are given down there. There are also some non-expressible constraints that in the example is not reported, but are the cardinality or other types of constraints that the model has. Relationships Definition of relationships ðŸŸ© A relationship is a connection between two or more entity types. Usually is given a name to the relationship, that summarizes his semantic meaning. Singular nouns are preferred.\nExample of relationship: Arity of relationship ðŸŸ© A relationship is not limited to connect two entity types, it can connect more, and this value defines the arity of the relationship. In each case the relationship is represented as a tuple, that is unique, meaning that more instances of the same type could not exist: You can\u0026rsquo;t have the same tuple within the relationship.\nRelationship promotion to entity ðŸŸ© Sometimes a relationship is not enough to model some constraints, in these cases it is useful to use an entity instead.\nExample: Cardinality of relationship ðŸŸ©\u0026ndash; This is different from the arity. It\u0026rsquo;s a constraint that defines the minimum and maximum value that a relationship can have. There is a convention to use $N$ if we don\u0026rsquo;t have an upper limit\nTypes of relationship cardinality (3) ðŸŸ© The classical classification is\nMany-to-many One to many 1 to 1 It\u0026rsquo;s clear what they mean, it\u0026rsquo;s a cardinality relation, for example current_spouse relationship is a 1-1 in the modern society, schools frequented could be one to many, the exams taken by a student in the course entity is a many to many.\nAttributes Definition of attributes ðŸŸ© Sono proprietÃ  o di entitÃ  o associazioni, che assumono valori da un certo dominio\nComposite attributes ðŸŸ© They are used to group together different attributes to the same class or relationship. This is useful if different attributes share the same semantic meaning.\nIn the example in the image it\u0026rsquo;s the address. Cardinality of attributes ðŸŸ© It is possible to define a cardinality for single attributes, because an employee could have more phone numbers, or the driving licence is optional (not everybody has it!)\n","permalink":"https://flecart.github.io/notes/design-del-database/","summary":"Processo design del database Il design Some design steps (3) (non impo) How to gather requirements? ðŸŸ¨+ Come si puÃ² raccogliere i dati degli utilizzatori?\nparlare col il personale che dovrÃ  utilizzare questi sistemi Documentazione esistente Interview di persone che dovrÃ  utilizzare queste risorse O Moduli per fare sampling Top-down approach La cosa brutta Ã¨ che questi requisiti non possono essere standardizzati, ci sono molte necessitÃ , molto diverse fra i loro, quindi Ã¨ utile andare a parlare con gli esperti e capire cosa abbiano bisogno per i dati.","title":"Design del database"},{"content":"Questo problema Ã¨ stato trattato in modo un po\u0026rsquo; piÃ¹ semplificato (nel caso in cui la carica era esattamente a metÃ  in Campo elettrico#Dipolo elettrico). Questo problema Ã¨ stato storico, utilizzato per analizzare l\u0026rsquo;atomo.\nPotenziale del dipolo elettrico ðŸŸ©\u0026ndash; Per il principio di sovrapposizione possiamo affermare che $$ V(P) = V_{r^{+}} + V_{r^{-}} = \\frac{q}{4\\pi\\varepsilon_{0}}\\left( \\frac{1}{r^{+}} - \\frac{1}{r^{-}} \\right) $$ Ora possiamo fare certe approssimazioni, supponendo che $r \\gg a$ con $r$ la congiungente fra il centro del dipolo e il nostro punto e $a$ la distanza fra le cariche, possiamo affermare che $$ r^{+} - r^{-} = -a \\cos \\theta $$ Sappiamo che l\u0026rsquo;angolo Ã¨ lo stesso (piÃ¹ o meno), perchÃ© sappiamo che i due reggi sono ora paralleli (come assunsione di semplificazione) Inoltre abbiamo che $r^{+}r^{-} = r^{2}$ perchÃ© il punto Ã¨ molto lontano allora possiamo affermare che $$ \\left( \\frac{1}{r^{+}} - \\frac{1}{r^{-}} \\right) = \\frac{a\\cos \\theta}{r^{2}} $$ a $$ V(P) = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{qa\\cos \\theta}{r^{2}} = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P\\cos \\theta}{r^{2}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{\\vec{P}\\cdot \\hat{r}}{r^{2}} $$ Direttamente proporzionale al momento di tipolo Inversamente proporzionale al quadrato del raggio. Campo elettrico nel dipolo Abbiamo che Ã¨ uguale a $$ \\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}} \\vec{P} \\cdot \\frac{\\hat{r}}{r^{3}} $$ Per trovare questo basta calcolare $$ \\vec{E} = -\\vec{\\nabla} V $$ Componente parallela ðŸŸ© Basta osservare che $$ \\vec{E} = - \\vec{\\nabla}V = -\\frac{\\delta V}{\\delta x}\\hat{i} -\\frac{\\delta V}{\\delta y}\\hat{j} -\\frac{\\delta V}{\\delta z}\\hat{k} $$ Sappiamo che $\\vec{P} = P\\hat{k}$ e $\\vec{r} = x\\hat{i} + y \\hat{j} + z \\hat{k}$ allora abbiamo che $\\vec{P} \\cdot \\vec{r} = Pz$ Poi abbiamo che $z = r \\cos \\theta$\nUna volta esplicitato abbiamo che $$ E_{z} = - \\frac{\\delta V}{\\delta z} = -\\frac{\\delta}{\\delta z} \\left[ \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Pz}{(x^{2} + y^{2} + z^{2})^{3/2}} \\right] = -\\frac{P}{4\\pi\\varepsilon_{0}}\\left[ \\frac{1}{(x^{2} + y^{2} + z^{2})^{3/2}} + z \\left( -\\frac{3}{2} \\right) \\frac{2z}{(x^{2} + y^{2} + z^{2})^{5/2}} \\right] $$ $$ = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P}{r^{3}}\\left[ \\frac{3z^{2}}{r^{2}} - 1 \\right] = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P}{r^{3}}\\left[ \\frac{3r^{2} \\cos ^{2} \\theta}{r^{2}} - 1 \\right] = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P}{r^{3}}\\left[ 3 \\cos ^{2} \\theta - 1 \\right] $$ Nota : $E_{z} = E_{\\parallel}$ dato che Ã¨ parallela al dipolo.\nComponente perpendicolare ðŸŸ¨+ $$ E_{\\perp} = \\sqrt{ E_{x}^{2} + E_{y} ^{2} } $$ Calcoliamo $E_{x}$ che si puÃ² scoprire che Ã¨ simmetrico rispetto $y$ $$ E_{x} = - \\frac{\\delta V}{\\delta x} = \\frac{\\delta}{\\delta x} \\left[ \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Pz}{(x^{2} + y^{2} + z^{2})^{3/2}} \\right] = -\\frac{Pz}{4\\pi\\varepsilon_{0}}\\left[ -\\frac{3}{2} \\frac{2x}{r^{5}} \\right] = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{3xPz}{r^{5}} $$ e in modo equivalente con $y$ $$ E_{y} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{3yPz}{r^{5}} $$ In questo modo otteniamo che $$ E_{\\perp} = \\frac{3}{4\\pi\\varepsilon_{0}} \\frac{Pz}{r^{5}}\\sqrt{ y^{2} + x^{2} } = \\frac{3}{4\\pi\\varepsilon_{0}} \\frac{P}{r^{5}}r\\sin \\theta \\, r\\cos \\theta = \\frac{3}{4\\pi\\varepsilon_{0}} \\frac{P}{r^{3}}\\sin \\theta \\, \\cos \\theta $$ Passaggi sopra sono giustificati perchÃ© $\\sqrt{ y^{2} + x^{2}} = r \\sin \\theta$ e anche che $z = r\\cos \\theta$ Che ha senso perchÃ© c\u0026rsquo;Ã¨ simmetria circolare su quel piano. E vale praticamente per ogni punto nello spazio.\nAnalisi dei risultati (non fare) $\\theta=0$ abbiamo che $E_{\\perp} = 0$ e rimane solamente $$E_{\\parallel} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{2P}{r^{3}} $$ Quindi Ã¨ positivo, il campo.\n$\\theta=90$ questo Ã¨ il caso trattato precedentemente. Abbiamo ancora che $E_{\\perp} = 0$ e che $$ E_{\\perp} = -\\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P}{r^{3}} $$ Che Ã¨ coerente col risultato che abbiamo calcolato tempo fa.\nEsercizio: In quale angolo si annulla $E_{\\parallel}$ (analiticamente, basta l\u0026rsquo;angolo che annulla $3 \\cos ^{2} \\theta - 1$) Che Ã¨ uguale a 54.71 gradi. Domanda: perchÃ© si annulla in qu\nCon coordinate polari ðŸŸ¥ Vedere 58 del Mazzoldi avremo che $$ E = \\frac{p}{4\\pi\\varepsilon_{0}r^{3}}(2\\cos \\theta \\hat{r}+ \\sin \\theta \\hat{\\theta}) $$ Si puÃ² riscrivere anche il momento di dipolo in coordinate polari, e questo permette una scrittura ancora piÃ¹ clean, in cui risalta che Ã¨ la componente radiale del momento di dipolo la parte di interesse nella relazione:\nPerchÃ© possiamo riscrivere il momento di dipolo in coordinate polari e usare quello: $$ \\vec{p} = p\\cos \\theta \\hat{r} - \\sin \\theta \\hat{\\theta} $$ Se si riesce a riscriverlo in questa forma, la cosa diventa molto clean, posso trovare le componenti asse e piano mediano del dipolo subito, plug and play diciamo. Infatti avremo che $$\\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}r^{3}}(3p\\cos \\theta \\hat{r} - \\vec{p} )$$ Dipolo immerso in campo elettrico NOTA: Posso assumere il valore di $\\vec{E}$ come costante sulle due cariche perchÃ© tanto varia molto molto poco. Anche se non ho capito esattamente il ragionamento.\nSupponiamo che la carica negativa sia posta su $\\vec{r}$ quindi il sistema di riferimento Ã¨ qualunque e che $r \\gg a$. Energia potenziale del dipolo ðŸŸ© Usando esattamente il metodo trattato in Condensatori nel vuoto, basta applicare $$ U(P) = qV(\\vec{r} + \\vec{a}) - qV(\\vec{r}) = q\\left[ V(x + a_{x}, y + a_{y}, z + a_{z}) - V(x, y, z) \\right] $$ Si puÃ² notare che con l\u0026rsquo;assunzione $r \\gg a$ Ã¨ infinitesimo quindi Ã¨ un differenziale di V Quindi $$ U(P) = q \\, dV(x, y, z) $$ Applicando il teorema che $$ dV = \\frac{\\delta V}{\\delta x}dx + \\frac{\\delta V}{\\delta y}dy + \\frac{\\delta V}{\\delta z}dz = \\frac{\\delta V}{\\delta x}a_{x} + \\frac{\\delta V}{\\delta y}a_{y} + \\frac{\\delta V}{\\delta z}a_{z} =-E_{x}a_{x} -E_{y}a_{y} -E_{z}a_{z} $$ Quindi abbiamo che $$ U(P) = q(-E_{x}a_{x} -E_{y}a_{y} -E_{z}a_{z}) = - P_{x}E_x - P_{y}E_y - P_{z}E_z = -\\vec{P} \\cdot \\vec{E} = - PE\\cos \\theta $$ Mentre 0 allora l\u0026rsquo;energia Ã¨ minima (se Ã¨ minima allora Ã¨ stabile in meccanica poi, seguendo questa giustificazione, allora diventa stabile quando $\\theta = 0 deg$ quindi tende a stare parallelo al campo. L\u0026rsquo;equilibrio Ã¨ instabile se Ã¨ diverso da 0 gradi. Stabile se Ã¨ 0\nMomento di dipolo ðŸŸ© $$ \\vec{F}_{T} = q\\vec{E}_{+} - q\\vec{E}_{-} = 0 \\iff \\vec{E}_{+} =\\vec{E}_{-} = \\vec{E} $$ Per qualche motivo, il momento puÃ² essere calcolato rispetto a qualunque sistema di riferimento $$ \\vec{M}_{T} = \\vec{r}_{+}\\times \\vec{F}_{+} + \\vec{r}_{-}\\times \\vec{F}_{-} = \\vec{r}_{+}\\times q\\vec{E} - \\vec{r}_{-}\\times q\\vec{E} = (\\vec{r}_{+} - \\vec{r}_{-})\\times q\\vec{E} = \\vec{a} \\times q\\vec{E} = \\vec{P} \\times \\vec{E} $$ Quindi abbiamo che $$ \\lvert \\vec{M}_{T} \\rvert = PE\\sin \\theta $$ Questo Ã¨ coerente con i valori di equilibrio instabile e stabile presenti per l\u0026rsquo;energia. Ossia possiamo scrivere: $$ \\vec{M} = \\vec{P} \\times \\vec{E} $$ Distribuzione di carica Prendiamo una distribuzione di carica qualunque nello spazio, di dimensione $d$ massima #### Momento di dipolo elettrico del sistema #### Potenziale di sistema ðŸŸ¨+ Abbiamo che $\\vec{r} = \\vec{r}_{i} + \\vec{d}_{i}$, allora posso assumere che $\\vec{r}$ e $\\vec{r}_{i}$ siano paralleli e dire che $$ r_{i} = r - d_{i}\\cos \\theta_{i} = r - \\vec{d}_{i} \\cdot \\hat{r} $$ E con questo possiamo semplificare molte cose, ma guardiamo: $$ V(P) = \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}}{r_{i}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}}{r - \\vec{d}_{i}\\hat{r}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}(r + \\vec{d}_{i}\\hat{r})}{r^{2} - d_{i}^{2}} \\approx \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}(r + \\vec{d}_{i}\\hat{r})}{r^{2}} $$ Per concludere definisco $\\vec{P} = \\sum_{i=1}^{N}q_{i}\\vec{d}_{i}$ questo Ã¨ il momento di dipolo elettrico del sistema, perchÃ© sto semplicemente sommando il dipolo di tutte le singole cariche.\n$$ V(P) = \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}}{r} + \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}\\vec{d}_{i}\\hat{r}}{r^{2}} \\frac{Q}{4\\pi\\varepsilon_{0}r} + \\frac{\\vec{P} \\cdot \\hat{r}}{4\\pi\\varepsilon_{0}r^{2}} $$ Il primo di questi si chiama termine di monopolo $V_{0}$, mentre il secondo Ã¨ il termine di dipolo $V_{DP}$. Il primo spiega Potenziale con sÃ© stesso al centro, indipendente dalla distribuzione. Come se stessi ammassando tutta la carica in un punto e calcolando il potenziale lÃ¬. Il secondo termine mi dÃ  informazioni del potenziale al variare della distribuzione di carica. (concettualmente dice prof. Zoccoli che questo Ã¨ equivalente alla torque nei corpi rigidi, che concentri tutta la massa sull\u0026rsquo;asse per calcolare la torque)\nConseguenza importante: Anche un atomo neutro puÃ² generare un campo elettrico nello spazio, che Ã¨ dato dal termine di dipolo\nMonopolo vs Dipolo grandezza ðŸŸ©\u0026ndash; Abbiamo con una approssimazione che $$ \\lvert \\vec{P} \\rvert = \\left\\lvert \\sum_{i} q_{i}\\vec{d}_{i} \\right\\rvert \\approx \\left\\lvert \\sum_{i} q_{i} \\right\\rvert d = Qd $$ Se usiamo questa approssimazione allora abbiamo che $$ \\frac{V_{DP}}{V_{O}} = \\frac{Qd}{4\\pi\\varepsilon_{0}r^{2}} \\frac{4\\pi\\varepsilon_{0}r}{Q} = \\frac{d}{r} \\ll 1 $$ Ma nel caso in cui Ã¨ neutro, allora l\u0026rsquo;unico campo che c\u0026rsquo;Ã¨ Ã¨ il termine di dipolo! Quindi bisogna contare per avere il campo.\nTermine dipolo nullo ðŸŸ© Abbiamo che $$ Q_{T} = 0 = Q_{+} + Q_{-} = \\sum_{i}\\lvert q_{i}^{+} \\rvert - \\sum_{i}\\lvert q_{i}^{-} \\rvert $$ Allora abbiamo che $$ \\vec{P} = \\sum_{i}^{N}q_{i}\\vec{a}_{i} = \\sum_{i}^{N}\\lvert q_{i}^{+} \\rvert \\vec{d}_{i}^{+} - \\sum_{i}^{N} \\lvert q_{i}^{-} \\rvert \\vec{d}_{i}^{-} $$ Simile alla media pesata di tutte le masse per la massa totale, mi trovo ora qui il centro di massa per le cariche, lo faccio per positive e negative in modo separato. $$ \\vec{d}^{+} = \\frac{1}{Q}\\sum_{i=1}^{N} \\lvert q_{i}^{+} \\rvert \\vec{d}_{i}^{+} $$ Esattamente la stessa cosa per $\\vec{d}^{-}$. Scritto in questo modo abbiamo che $$ \\vec{P} = Q\\vec{d}^{+} - Q\\vec{d}^{-} = Q(\\vec{d}^{+} - \\vec{d}^{-}) = Q\\vec{\\delta} $$ Ossia il termine di dipolo si puÃ² riassumere come differenza del centro fra le cariche positive e negative. Se non hanno stesso centro allora ho un campo elettrico (questo Ã¨ coerente col caso classico di dipolo a due cariche!). E questo Ã¨ vero sempre! Ã¨ anche il motivo per cui l\u0026rsquo;acqua Ã¨ carica, perchÃ© ha un momento di dipolo!\n","permalink":"https://flecart.github.io/notes/dipolo-elettrico/","summary":"Questo problema Ã¨ stato trattato in modo un po\u0026rsquo; piÃ¹ semplificato (nel caso in cui la carica era esattamente a metÃ  in Campo elettrico#Dipolo elettrico). Questo problema Ã¨ stato storico, utilizzato per analizzare l\u0026rsquo;atomo.\nPotenziale del dipolo elettrico ðŸŸ©\u0026ndash; Per il principio di sovrapposizione possiamo affermare che $$ V(P) = V_{r^{+}} + V_{r^{-}} = \\frac{q}{4\\pi\\varepsilon_{0}}\\left( \\frac{1}{r^{+}} - \\frac{1}{r^{-}} \\right) $$ Ora possiamo fare certe approssimazioni, supponendo che $r \\gg a$ con $r$ la congiungente fra il centro del dipolo e il nostro punto e $a$ la distanza fra le cariche, possiamo affermare che $$ r^{+} - r^{-} = -a \\cos \\theta $$ Sappiamo che l\u0026rsquo;angolo Ã¨ lo stesso (piÃ¹ o meno), perchÃ© sappiamo che i due reggi sono ora paralleli (come assunsione di semplificazione) Inoltre abbiamo che $r^{+}r^{-} = r^{2}$ perchÃ© il punto Ã¨ molto lontano allora possiamo affermare che $$ \\left( \\frac{1}{r^{+}} - \\frac{1}{r^{-}} \\right) = \\frac{a\\cos \\theta}{r^{2}} $$ a $$ V(P) = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{qa\\cos \\theta}{r^{2}} = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P\\cos \\theta}{r^{2}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{\\vec{P}\\cdot \\hat{r}}{r^{2}} $$ Direttamente proporzionale al momento di tipolo Inversamente proporzionale al quadrato del raggio.","title":"Dipolo elettrico"},{"content":"This small note sections tries to fix 5 important concepts in software engineering\nSub-system and modules ðŸŸ© We need to differentiate from sub-system, which is a part of a system that tries to achieve some objective, and a module, which is more language specific way of saying imported file, or set of functions or classes.\nInformation hiding ðŸŸ© This is a very important principle present in object oriented programming. Within this philosophy we should be able to access only public methods or data, this allows the construction of abstractions that allow us to think at a higher level.\nA good think about this is that changing implementation doesn\u0026rsquo;t change the interface, this allows lower level of coupling within the system.\nCoupling Meaning of coupling ðŸŸ© Two methods are said to be highly coupled when every change to one of them, needs the other one to be changed too! Clearly if we have a highly coupled system refactoring is a hell of a nightmare. Low coupling provides independency, creating a easier to maintain software.\nCoupling sources (7) ðŸŸ© There are many coupling sources, here is a not definitive list:\nFunction or method calling Data coupling, for example the prop drilling hell present in react, where you have to pass other data to other data on an indefinite chain. Hereditary coupling, where you have too long chain of sub-classes. OS-coupling, where you don\u0026rsquo;t have an equivalent function for other OSes Common coupling:, e.g. global variables, config files, that are used by many files. Content coupling: happens when the #Information hiding is not implemented, an other module directly sees internal data-structure of another module, implying a very bad implementation!. Cohesion ðŸŸ© Cohesion is a concept that similarly to Memoria#4.2 Memoria Cache, with the location principle, common functions should be grouped together, the best thing that could happen is the functional cohesion, where code that tries to implement the same abstraction tries to be together, another one is content cohesion, where code that needs same input structure is close.\nA bad example is random ordering, where code with no shared meaning stays together.\nSimplicity ðŸŸ© This is also one of the main pillars of Software engineering. In this case it is advised not to generalize too early, probably You aren\u0026rsquo;t gonna need it.\nWhen we are talking about methods instead, you should follow the principles explained in clean code, so keep the names descriptive, keep the public methods small and precise, use small functions, and keep code smell low (avoid duplicates for example).\n","permalink":"https://flecart.github.io/notes/general-swe-principles/","summary":"This small note sections tries to fix 5 important concepts in software engineering\nSub-system and modules ðŸŸ© We need to differentiate from sub-system, which is a part of a system that tries to achieve some objective, and a module, which is more language specific way of saying imported file, or set of functions or classes.\nInformation hiding ðŸŸ© This is a very important principle present in object oriented programming. Within this philosophy we should be able to access only public methods or data, this allows the construction of abstractions that allow us to think at a higher level.","title":"General SWE principles"},{"content":"Analisi macroscopica Setting dell\u0026rsquo;esperimento ðŸŸ© Provare a guardare 269 del Mazzoldi. (227 per la defivazione della forza.) Si puÃ² dimostrare che $$ \\vec{F} = -\\vec{\\nabla} \\cdot U \\implies F = -\\vec{\\nabla}(\\vec{m} \\cdot \\vec{B}) = \\pm m \\frac{dB}{dx} $$ La prima relazione si deriva da definizione di lavoro e forza. (esteso al caso di una forza applicata su spira che non Ã¨ banale, facciamola brevemente).\nSappiamo che $U = - m \\cdot B$, quindi Ã¨ vero che $dW = -dU = i d \\Phi (B)$ e poi utilizzando una proprietÃ  del gradiente in Divergenza e Circuitazione abbiamo $$ Fds = dW = -dU = i \\nabla \\Phi(B) ds \\implies F = i\\nabla \\Phi(B) = m \\cdot \\nabla B = -\\nabla U $$ La cosa da notare Ã¨ che per campi uniformi abbiamo che si puÃ² definire il lavoro.\nComunque questo esperimento Ã¨ stato importante per dire che se metto un materiale nella bobina, a volte viene attratta, altre volte respinta, quindi faceva pensare che esiste qualcosa nel materiale che induceva queste cose.\nMagnetizzazione ðŸŸ© Considerando la forza per unitÃ  di volume si puÃ² introdurre la densitÃ  del momento magnetico, anche chiamata magnetizzazione.\n$$ M = \\frac{m}{\\tau} $$ Campo magnetico in materiali Possiamo misurare il campo magnetico tramite una sonda di Hall, e otteniamo se il solenoide Ã¨ immerso in un campo magnetico abbiamo: $$ \\frac{B}{B_{0}} = k_{m} $$ Simile a quanto abbiamo fatto in Condensatori con dielettrici.\nPermeabilitÃ  magnetica relativa ðŸŸ© $$ \\mu = \\mu_{0} k_{m} $$ In modo simile a quanto fatto per la costante dielettrica.\nInterpretazione correnti Amperiane ðŸŸ© Quindi vengono create delle sorte di correnti sul nostro materiale quando questa viene sommersa in un certo campo magnetico, che hanno modulo $$ \\vec{B}_{m} = \\mu_{0}\\chi_{m}ni $$ Vedere pagina 272 del Mazzoldi. Ed effettivamente ci sono delle correnti cosÃ¬ indotte su questo materiale. Si potranno studiare da un punto di vista microscopico dopo.\nSuscettivitÃ  magnetica ðŸŸ© Ci dice quanto Ã¨ cambiato il campo magnetico passando di mezzo, e quindi abbiamo: $$ \\chi_{m } = k_{m } - 1 $$ Classificazione di sostanze magnetiche Diamagnetiche ðŸŸ© Se $k_{m} \u003c 1$ Ossia le correnti amperiane hanno verso opposto.\nparamagnetiche ðŸŸ© Se $k_{m} \u003e 1$. In cui si ha anche una dipendenza con la temperatura. A temperatura normale questo sono piccolissime\nFerromagnetiche ðŸŸ© Quando la differenza Ã¨ tipo $10^{3}$, ed Ã¨ una relazione non lineare.\nConsiderazioni microscopiche Analisi del momento angolare Questa analisi Ã¨ verso pagine 234 del Mencuccini, da fare un po\u0026rsquo; meglio.\nProviamo a considerare il modello di Rutherford (credo), in cui abbiamo un atomo centrale e poi roba (elettroni) che ci girano attorno.\nConsiderando un singolo elettrone abbiamo, che il momento angolare (credo si chiami cosÃ¬, da controllare) Ã¨ $$ \\vec{L} = \\vec{r} \\times m\\vec{v}_{e} \\implies L = rm v_{e} $$ Dove $v_{e}$ Ã¨ la velocitÃ  dell\u0026rsquo;elettrone e anche $m$ Ã¨ la massa dell\u0026rsquo;elettrone. Inoltre sappiamo, per definizione che $m = i\\pi r^{2} = -\\frac{evr}{2}$ Dove abbiamo preso $i = -\\frac{e}{T} = -\\frac{ev}{2\\pi r}$ Combinando le equazioni del momento magnetico e della corrente elettrica si ha $$ \\vec{m}= -\\frac{er}{2} \\left( \\frac{\\vec{L}}{rm} \\right) = -\\frac{e}{2m} \\vec{L} $$ Dove si ha una chiara relazione fra momento magnetico (quella cosa necessaria per magnetizzazione) direttamente nel nucleo di un atomo.\nMagnetone di Bohr Seguendo il modello di Sommerfield-Bohr in cui il momento angolare viene quantizzato, esiste anche un momento magnetico intrinseco dovuto allo spin dell\u0026rsquo;elettrone, che segue praticamente la stessa legge di sopra: $$ \\mu_{e} = \\frac{e}{2m} \\hbar $$ dove lo spin Ã¨ uguale a $\\lvert S \\rvert = \\frac{1}{2}\\hbar$ Questa costante trovata di sopra Ã¨ detta magnetone di Bohr che Ã¨ da notare opposta al momento magnetico precedente. Infatti nella maggior parte dei materiali questo si cancella, mentre in alcuni materiali non succede, e abbiamo il paramagnetismo.\nModello diamagnetismo In questo modello si assume che non ci sia momento magnetico intrinseco degli atomi, si puÃ² dimostrare che abbiamo un moto di precessione:\nAbbiamo\n$$ \\vec{M} = \\vec{m} \\times \\vec{B} = -\\frac{e}{2m} \\vec{L} \\times \\vec{B} $$ E che $$ M = \\frac{dL}{dt} = \\vec{\\omega_{L}} \\times \\vec{L} \\implies \\vec{\\omega_{L}} = \\frac{e}{2m}\\vec{B} $$ Dove il secondo Ã¨ una velocitÃ  angolare indotta dal campo magnetico che implica un moto di precessione. Questa Ã¨ la precessione di Larmor.\nQuesta precessione di Larmor induce una corrente uguale a: $$ \\Delta i = -\\frac{e}{T_{L}} = -\\frac{e}{2\\pi}\\omega_{L} = -\\frac{e^{2}}{4\\pi m}B $$ Che induce un momento magnetico $$ \\Delta m = i\\pi r^{2} = -\\frac{e^{2}r^{2}}{4m}B $$ Ora conviene analizzare questo dato da un punto di vista mean field theory e assumere un raggio medio perchÃ© non conosciamo il valore di $r$ nell\u0026rsquo;orbita di precessione nemmeno il verso rispetto al campo magnetico esterno. Quindi prendiamo una media, assumiamo una simmetria sferica $x^{2} + y^{2} + z^{2} = r^{2}$ che che i tre assi siano equamente equiprobabili, quindi $x^{2} = y^{2} = z^{2} = \\frac{r^{2}}{3}$\nCon questo abbiamo che il raggio medio sulla stessa orbita dell\u0026rsquo;elettrone (piano xy) diventa ora $r_{i}^{2} = x^{2} + y^{2} = \\frac{2}{3} r^{2}$ Se messo dentro lÃ¬ sopra abbiamo ora\n$$ \\Delta m = -e^{2} \\frac{r^{2}}{6m} B $$ E nel caso ci siano piÃ¹ elettroni prendiamo un raggio medio, e si avrÃ  lo stesso valore.\nApproccio in classe non compreso (non fare) Possiamo da questo ricavare la velocitÃ  angolare di cui troviamo il valore sia $$ \\omega_{0} = \\frac{v}{r} = \\frac{L}{r^{2}m_{e}} $$ Poi notiamo che $\\vec{m} \\parallel \\vec{L}$ perchÃ© entrambi perpendicolari alla nostra spira-elettrone. abbiamo poi che $$ i = -\\frac{e}{T}, \\vec{m}_{0} = -\\frac{e}{T} \\pi r^{2} \\hat{u}_{n}, v = \\omega r, L = r m_{e} \\omega r = m_{e} \\omega r^{2} $$ Poi abbiamo anche che: $$ T = \\frac{2\\pi}{\\omega} = \\frac{2\\pi}{L} r^{2}m_{e} $$ Utilizzando quanto avevamo ricavato prima sulla velocitÃ  angolare dell\u0026rsquo;elettrone.\nQuesto si puÃ² mettere dentro al momento magnetico $$ \\vec{m}_{0} = i \\Sigma = -\\frac{e \\vec{L}}{2m_{e}} $$ Nel momento in cui una sostanza Ã¨ in un campo magnetico, sarÃ  generata una corrente che si oppone, e si avrÃ  una forza repulsiva, questo c\u0026rsquo;Ã¨ sempre in tutto.\nOgni atomo crea un momento magnetico all\u0026rsquo;interno del suo atomo.\nAltre cose, abbiamo che\n$$ \\vec{M} = i\\vec{S} \\times \\vec{B} = \\vec{\\omega_{L}} \\times \\vec{L} $$ Noi dovremmo essere in grado di sapere quanto sia la corrente e la superficie e in questo modo dovrei riuscire a ricavare omega.\nLe sostanze diamagnetiche vengono solo respinte. (??)\n$$ \\vec{m}_{L} = -\\frac{e^{2}}{6m_{e}} \\left( \\sum_{i=1}^{z} r_{i}^{2} \\vec{B} \\right) $$ Facciamo una altra analisi, fra la frequenza di Larbor e quella originale, Larbor Ã¨. Poi sapendo che $T_{0} = 1.5 \\cdot 10^{-16}s$ e abbiamo che la massa Ã¨ $9.1 \\cdot 10^{-31} kg$. $$ \\omega_{L} = \\frac{eB}{2m_{e}} $$ E vorremmo chiederci se la frequenza di Larbor sia maggiore o minore rispetto a quella iniziale. E si scopre in qualche modo che se $B \\ll 5 \\times 10^{5} T$ si avrÃ  che il periodo di Larbor Ã¨ molto piccolo rispetto a quello iniziale. E nella realtÃ  max 100 tesla, e non si riesce a raggiungere.\nTutta la parte sopra dovrebbe essere fatta prima pagina 274 del mazzoldi.\nLarmor ðŸŸ¨\u0026ndash; Quando proviamo a definire il momento angolare, tramite una velocitÃ  angolare e inerzia, introduciamo la velocitÃ  angolare di Larbor\n$$ \\vec{M} = \\vec{\\omega}_{L} \\times \\vec{L} $$ Questo si puÃ² mettere in relazione con $$ \\vec{M} = \\vec{m}_{0} \\times \\vec{B} = \\vec{\\omega}_{L} \\times \\vec{L} $$ E troviamo il risultato $$ \\omega_{L} = \\frac{eB}{2m_{e}} $$ Con questo possiamo andare a definire un momento di Larmor.\nOssia: $$ m_{L} = i_{L}S_{L} = -\\frac{e}{T_{L}} S_{L} $$ E abbiamo che $$ T_{L} = \\frac{2\\pi}{\\omega_{L}} \\implies \\frac{4\\pi m_{e}}{eB} $$ E questo si puÃ² sostituire si sopra e otteniamo che il momento di Larbor Ã¨:\nPrecessione di Larmor ðŸŸ¨\u0026ndash; Abbiamo detto che abbiamo un fattore di momento angolare che Ã¨ dipendente dal campo magnetico, per questo motivo possiamo spiegare l\u0026rsquo;effetto del campo magnetico nel creare correnti (in questo caso l\u0026rsquo;elettrone che si muove).\nMomento magnetico per unitÃ  di volume ðŸŸ©\u0026ndash; momento magnetico per unitÃ  di volume Ã¨ uguale al momento magnetico del nostro atomo per il numero di atomi per unitÃ  di volume, e abbiamo un valore di magnetizzazione che Ã¨ in pratica una corrente amperiana. In formule: $$ \\vec{M} = \\frac{\\Delta \\vec{m}}{\\Delta \\tau}, \\Delta \\vec{m} = n $$ Con N il numero di atomi per unitÃ  di volume e $\\vec{m}$ il momento magnetico per unitÃ  di volume.\n$\\vec{M}$ descritto sopra Ã¨ il momento magnetico per unitÃ  di volume, chiamato anche MAGNETIZZAZIONE.\nConsideriamo ora un cilindro con un certo momento magnetico. Per un certo principio di equivalenza di Ampere, possiamo dire che il momento magnetico\u0026hellip; (vedere pagina 275 Mazzoldi).\n$$ dm = di_{m}dS\\hat{u} = M dSdz\\hat{u} \\implies di_{m} = Mdz $$ Ma tutte le correnti interne si elideranno, e questo sarÃ  equivalente a un circuito esterno (una spira per dire), questo motiva anche l'utilizzo del solenoide, perchÃ© sembra simile a questo setting. Vedere [Geometrie di spire](/notes/geometrie-di-spire). allora: $$ i_{m} = \\int \\, di_{m} = \\int M \\, dz = Mh $$ Possiamo definire il concetto di densitÃ  lineare di corrente amperiana come $j$ $$ j_{m} = \\frac{i}{h} = \\lvert M \\rvert = \\vec{M} \\times \\hat{u} $$ Caso Magnetizzazione non uniforme ðŸŸ¨\u0026ndash; Questo rende la cosa un po\u0026rsquo; piÃ¹ compelssa perchÃ© le correnti amperiane non si cancellano. Consideriamo il setting in figura: abbiamo che $$ di_{1} - di_{2} = (M_{z} - M'_{z})dz = -\\frac{\\delta M_{z}}{dx} dxdz $$ CosÃ¬ abbiamo la corrente che scorre lungo $y$ nel disegno di sopra, ma ho un contributo lungo $y$ anche dal cubo di una altra direzione! Si puÃ² ripetere la stessa cosa, su una direzione diversa. $$ di_{3} - di_{4} = (M'_{x} - M_{x})dx = \\frac{\\delta M_{x}}{\\delta z}dzdx $$ E possiamo considerare ora il valore totale:\n$$ di = di_{1} - di_{2} + di_{3} - di_{4} = \\left( \\frac{\\delta M_{x}}{\\delta z} - \\frac{\\delta M_{z}}{\\delta x} \\right) dxdz $$ E si puÃ² estendere questo concetto il rotore facendo praticamente la stessa cosa anche per altri e abbiamo:\n$$ j = \\vec{\\nabla} \\times \\vec{M} $$ dove $j$ Ã¨ la densitÃ  lineare di corrente.\nIn forma integrale abbiamo: $$ \\oint_{\\Gamma} \\vec{M} d\\vec{l} = i_{m} $$ Equazioni del campo magnetico revisited ðŸŸ©- abbiamo che $$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{l} = \\mu_{0} (i_{c} + i_{m}) = \\mu_{0}i_{c} + \\mu_{0} \\oint_{\\Gamma} \\vec{M} \\cdot d\\vec{l} $$ Dove aggiungiamo anche la corrente di ampere oltre la corrente concatenata.\nPortando dall\u0026rsquo;altra parte abbiamo: $$ \\oint_{\\Gamma} (\\vec{B} - \\mu_{0} \\vec{M}) \\cdot d\\vec{l} = \\mu_{0}i_{c} $$ E dividendo per $\\mu_{0}$ si ha\n$$ \\oint_{\\Gamma} \\left( \\frac{\\vec{B}}{\\mu_{0}} -\\vec{M} \\right) \\cdot d\\vec{l} = i_{c} $$ In cui abbiamo una altra sorgente del campo magnetico che Ã¨ dipendente dal materiale presente al campo magnetico.\nForma divergente ðŸŸ© $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}(\\vec{J} + \\vec{J}{M}) = \\mu{0}(\\vec{J}_{c} + \\vec{\\nabla} \\times \\vec{M}) \\vec{\\nabla} \\times (\\vec{B} - \\mu_{0} \\vec{M}) = \\mu_{0} \\vec{J}_{c} $$\nCampo di magnetizzante ðŸŸ©- In modo simile al campo di induzione elettrica o vettore di spostamento, Ã¨ sensato definire una nuova dimensione $$ \\vec{H} = \\frac{\\vec{B}}{\\mu_{0}} - \\vec{M} $$ In modo simile a quanto fatto in Condensatori con dielettrici in cui definiamo il vettore di spostamento, la cosa carina Ã¨ che: $$ \\vec{\\nabla} \\times \\vec{H} = \\vec{J}_{c} $$ E $$ \\oint_{\\Gamma} \\vec{H} d\\vec{l} = i_{c} $$ Dimensione Ampere su Metro, la stessa del vettore di magnetizzazione.\nRelazioni M, H, B ðŸŸ©\u0026ndash; VALGONO SOLO PER MATERIALI NON FERROMAGNETICI!\nE abbiamo anche la relazione: $$ \\vec{M} = \\chi_{m} \\vec{H} $$ Poi abbiamo anche $$ \\vec{B} = \\mu_{0} (\\vec{H} + \\vec{M}) = \\mu_{0}(1 + \\chi_{m}) \\vec{H} = \\mu \\vec{H} $$ Si ha anche la stessa relazione fra M e B rispetto a quello vecchio!\n$$ \\vec{M} = \\frac{k - 1}{k} \\vec{B} $$ DiscontinuitÃ  nelle superfici magnetizzate ðŸŸ¨++ Consideriamo il campo magnetico in due mezzi, queste saranno sottoposte a correnti amperiane diverse. Applichiamo il classico cilindro sulla superficie di separazione. Avremo allora che $$ 0 = \\oint_{\\Sigma}\\vec{B} \\cdot \\hat{u}_{N} dS = B_{1}\\cdot \\cos \\theta_{1} dS - B_{2} \\cdot \\cos \\theta_{2} dS \\implies B_{1} \\cos \\theta_{1} = B_{2}\\cos \\theta_{2} $$ Ossia abbiamo che c\u0026rsquo;Ã¨ una continuitÃ  della componente normale. Questo possiamo dire che $$ k_{1} H_{1 \\perp} = k_{2} H_{2\\perp} $$ E possiamo dire che la componente $H$ Ã¨ discontinua.\nCambiamo setting, consideriamo un rettangolino di altezza infinitesima (anche questa stessa idea). Allora abbiamo che $$ i_{c} = 0 = \\oint_{\\Gamma} H\\cdot dS = H_{1}h - H_{2}h \\implies H_{1} = H_{2} $$ Quindi non abbiamo discontinuita per la componente tangente. Abbiamo quindi: $$ H_{1} \\sin \\theta_{1} = H_{2} \\sin \\theta_{2} $$ Abbiamo quindi che c\u0026rsquo;Ã¨ una discontinuitÃ  per il campo magnetico e il suo valore Ã¨: $$ \\frac{B_{1 \\parallel}}{k_{1}} = \\frac{B_{2\\parallel}}{k_{2}} $$ calcoliamo il modulo di $B_{2}$ in funzione di $B_{1}$ che mi serve per calcolare il rapporto:\n$$ B_{2}^{2} = B_{1}^{2} \\cos ^{2} \\theta_{1} + B_{1}^{2} \\frac{\\cos ^{2}\\theta_{1}}{\\cos ^{2} \\theta_{2}} $$ Scriviamo in modo chiaro le componenti normali e non per $H$ Allora abbiamo che\n$$ H_{1t} = H_{2t} $$ E $$ k_{1}H_{1n} = k_{2}H_{2n} $$ E allora abbiamo:\n$$ \\frac{\\tan \\theta_{2}}{\\mu_{2}} = \\frac{H_{2t}}{\\mu_{2}H_{2n}} = \\frac{H_{1t}}{\\mu_{1}H_{1n}} = \\frac{\\tan \\theta_{1}}{\\mu_{1}} $$ Quindi abbiamo che $$ \\frac{\\tan \\theta_{1}}{\\tan \\theta_{2}} = \\frac{\\mu_{1}}{\\mu_{2}} = \\frac{k_{1}}{k_{2}} $$ Schermi magnetici ðŸŸ© Pensiamo di avere un materiale ferromagnetico, e facciamo finta che abbiamo campo magnetico entrante. Per questa relazione abbiamo che probabilmente per ogni angolo, questo sarÃ  deflesso in modo praticamente parallelo alla superficie. E se c\u0026rsquo;Ã¨ un buco, allora non ci passa praticamente campo magnetico, e possiamo costruire schermi magnetici in questo modo. Quindi se il materiale del conduttore Ã¨ fatto di roba ferromagnetica, questa scherma sia campo magnetico che elettrico.\nMateriale ferromagnetico Certi materiali si magnetizzano velocemente quando si mettono vicino a campi magnetici forti\nConsideriamo un toroide, uguale a quello descritto in Geometrie di spire, abbiamo che quando mettiamo un materiale, $H$ non cambia, perchÃ© dipende solo da correnti concatenate.\nMagnetizzazione in funzione di H ðŸŸ© Lo **stato vergine** Ã¨ lo stato iniziale del materiale. POi si ha la **curva di prima magnetizzazione** che Ã¨ la curva $a$ in figura. Per **magnetizzazione residua** si indica il valore di $M_{sat}$ quando $H = 0$ dopo aver salito la prima curva $a$. Abbiamo questo grafico (che poi si spiega con teorie quantistiche), che se aumento la corrente oltre un certo punto la magnetizzazione non aumenta. Questo si chiama magnetizzazione di saturazione. La cosa particolare Ã¨ che dopo che sono state magnetizzate, questi sono magneti permanenti. Si parla di campo coercitivo quando abbiamo un campo che fa diventare 0 la magnetizzazione.\nCiclo di isteresi di smagnetizzazione: In pratica devo fargli fare tanti giri (senza portarlo a saturazione!)\nCiclo di isteresi ðŸŸ© Ãˆ il grafico che abbiamo visto di sopra, in cui il materiale va su e giÃ¹. e si potrebbero anche definire concetti come permeabilitÃ  differenziale che mi rappresenta come cambia in fretta se seconda dell\u0026rsquo;induzione magnetica\n$$ \\mu_{d} = \\frac{dB}{dH} $$ Ãˆ un diagramma di stato questo ciclo, in un certo senso come quelli descritti da Unified Modeling Language.\nUna altra osservazione Ã¨ che posso avere tutti i punti all\u0026rsquo;interno del ciclo, ed Ã¨ per questo che posso smagnetizzare un magnete. Il metodo Ã¨ accende e spegnere in un certo modo $H$.\nMateriali duri e dolci ðŸŸ© Dolci sono usati solamente negli elettromagneti, perchÃ© sono facili da magnetizzare. Quelli duri sono difficili da magnetizzare, e hanno solitamente un ciclo di isteresi molto lungo.\nSeconda legge di curie (non importante) ðŸŸ¨++ Questa Ã¨ la relazione per materiali dolci, e lega la temperatura con la suscettibilitÃ  magnetica ()\n$$ \\chi_{m} (T - T_{c}))/\\rho = C $$ dove $\\rho$ Ã¨ la densitÃ  della sostanza.\nDomini di Weiss ðŸŸ¨\u0026ndash; Trattato pagina 316 del Mazzoldi:\nPossiamo caratterizzare alcuni domini magnetici ($~10^{5}$ atomi per il prof, per il libro circa $10^{11}$ atomi, sono regioni di circa 0.001 picometri., che ha senso perchÃ© i ferromagnetici sono questo fattore piÃ¹ grandi rispetto agli altri., e poi vanno ad influenzare ed ingrandire, capire da Heisemberg (ma per il prof. difficili).\nUna cosa strana Ã¨ che $H$ dentro a un solenoide Ã¨ verso giÃ¹ all\u0026rsquo;interno, perchÃ© abbiamo che \u0026hellip; boh non ho capito perÃ² la cosa strana era che era direzione opposta.\nSolenoide infinitamente lungo: non abbiamo vettore H perchÃ© la circuitazione Ã¨ sempre 0. ","permalink":"https://flecart.github.io/notes/magnetismo-nella-materia/","summary":"Analisi macroscopica Setting dell\u0026rsquo;esperimento ðŸŸ© Provare a guardare 269 del Mazzoldi. (227 per la defivazione della forza.) Si puÃ² dimostrare che $$ \\vec{F} = -\\vec{\\nabla} \\cdot U \\implies F = -\\vec{\\nabla}(\\vec{m} \\cdot \\vec{B}) = \\pm m \\frac{dB}{dx} $$ La prima relazione si deriva da definizione di lavoro e forza. (esteso al caso di una forza applicata su spira che non Ã¨ banale, facciamola brevemente).\nSappiamo che $U = - m \\cdot B$, quindi Ã¨ vero che $dW = -dU = i d \\Phi (B)$ e poi utilizzando una proprietÃ  del gradiente in Divergenza e Circuitazione abbiamo $$ Fds = dW = -dU = i \\nabla \\Phi(B) ds \\implies F = i\\nabla \\Phi(B) = m \\cdot \\nabla B = -\\nabla U $$ La cosa da notare Ã¨ che per campi uniformi abbiamo che si puÃ² definire il lavoro.","title":"Magnetismo nella materia"},{"content":"Ultima modifica: April 16, 2023 4:23 PM Primo Abbozzo: April 8, 2023 9:34 AM Studi Personali: No\nElementi di ripasso Object Detection Introduction Semantic segmentation Vorremo trovare regioni che corrispondano a categorie diverse. E dividere in questo modo lâ€™immagine secondo zone di informazione.\nObject detection Vogliamo trovare il piÃ¹ piccolo box che vada a contenere lâ€™oggetto. Questo Ã¨ fatto con il bounding box.\nIn questo caso la funzione di loss Ã¨ un pÃ² piÃ¹ difficile da definire, si utilizza la funzione intersection over union con le aree, in pratica la percentuale di immagine comune diciamo.\nDeep object detection (2) Region proposals\nQuesta Ã¨ una versione che prova a catturare le regioni di interesse allâ€™interno della nostra immagine. (piÃ¹ o meno non sa cosa sia lâ€™oggetto, ma sa che câ€™Ã¨ qualcosa in quella zona). Poi questa regione di interesse Ã¨ passata in un secondo step che va a riconoscere cosa Ã¨ presente in quella immagine. (la regione di interesse era presente anche prima di CNN).\nSIngle shots\nQuesti sono piÃ¹ veloci dei precedenti, quindi sono buoni per applicazioni real time.\nYOLO You Only Look Once intro https://pjreddie.com/darknet/yolo/\nhttps://towardsdatascience.com/yolo-v4-or-yolo-v5-or-pp-yolo-dad8e40f7109\nProva a trovare il bounding box con la predizione con una singola passata! CNN per individuare i boxes, poi algoritmicamente per cancellare i boxes.\nMain Idea FUNZIONAMENTO\nFa delle predizioni, che sono dei bounding box con dei labels (espressi attraverso una probabilitÃ ).\nDopo avevi un certo numero di neuroni dopo aver fatto downsampling (queste hanno visisione solamente di una zona limitata dellâ€™immagine).\nLâ€™idea principale Ã¨ allenare il singolo neurone a riconoscere lâ€™oggetto (wtf hoooow). E ignorare tutti i resti dei neuroni (si fa con una mask in qualche modo).\nOutput format Slide formato dellâ€™output\nSi deve tenere molte informazioni (i punti, lo score, e un valore di score per tutte le classi).\nSolitamente si parte da un anchor box di dimensioni fisse (width e height). I valori di ritorno sono un displacement dal centro in entrambe le direzioni e un fattore di deformazione per ogni direzione.\nLoss function Localization loss function\nLa loss di localizzazione non Ã¨ altro che una differenza\nNota: câ€™Ã¨ una binary map, che che Ã¨ in una cella e 0 in tutto il resto (questo per dire che il neurone vuole predire solamente quello che gli sta intorno, il resto lo ignora tutto).\nClassification loss\n!\n","permalink":"https://flecart.github.io/notes/object-detection/","summary":"Ultima modifica: April 16, 2023 4:23 PM Primo Abbozzo: April 8, 2023 9:34 AM Studi Personali: No\nElementi di ripasso Object Detection Introduction Semantic segmentation Vorremo trovare regioni che corrispondano a categorie diverse. E dividere in questo modo lâ€™immagine secondo zone di informazione.\nObject detection Vogliamo trovare il piÃ¹ piccolo box che vada a contenere lâ€™oggetto. Questo Ã¨ fatto con il bounding box.\nIn questo caso la funzione di loss Ã¨ un pÃ² piÃ¹ difficile da definire, si utilizza la funzione intersection over union con le aree, in pratica la percentuale di immagine comune diciamo.","title":"Object Detection"},{"content":"(Schulman et al. 2017) Ã¨ uno degli articoli principali che praticamente hanno dato via al campo. Anche questo Ã¨ buono per Policy gradients:\nhttps://lilianweng.github.io/posts/2018-04-08-policy-gradient/\nIntroduzione a PPO References [1] Schulman et al. â€œProximal Policy Optimization Algorithmsâ€ arXiv preprint arXiv:1707.06347 2017\n","permalink":"https://flecart.github.io/notes/proximal-policy-optimization/","summary":"(Schulman et al. 2017) Ã¨ uno degli articoli principali che praticamente hanno dato via al campo. Anche questo Ã¨ buono per Policy gradients:\nhttps://lilianweng.github.io/posts/2018-04-08-policy-gradient/\nIntroduzione a PPO References [1] Schulman et al. â€œProximal Policy Optimization Algorithmsâ€ arXiv preprint arXiv:1707.06347 2017","title":"Proximal Policy Optimization"},{"content":"Ultima modifica: May 13, 2023 4:44 PM Primo Abbozzo: January 14, 2023 11:55 AM Studi Personali: No\nLog esercizi fatti Data, compito, C1 fatto? c2 fatto?\n2022.09.06 [http://www.cs.unibo.it/~renzo/so/compiti/2022.09.06.tot.pdf] (36 KB) X X 2022.07.20 [http://www.cs.unibo.it/~renzo/so/compiti/2022.07.20.tot.pdf] (36 KB) X X (non me lo ricordo) 2022.06.21 [http://www.cs.unibo.it/~renzo/so/compiti/2022.06.21.tot.pdf] (40 KB) X X X 2022.06.01 [http://www.cs.unibo.it/~renzo/so/compiti/2022.06.01.tot.pdf] (36 KB) X X 2022.02.14 [http://www.cs.unibo.it/~renzo/so/compiti/2022.02.14.tot.pdf] (40 KB) X X 2022.01.17 [http://www.cs.unibo.it/~renzo/so/compiti/2022.01.17.tot.pdf] (36 KB) X X X X 2021.09.15 [http://www.cs.unibo.it/~renzo/so/compiti/2021.09.15.tot.pdf] (52 KB) X X 2021.07.21 [http://www.cs.unibo.it/~renzo/so/compiti/2021.07.21.tot.pdf] (52 KB) X-gio N 2021.06.23 [http://www.cs.unibo.it/~renzo/so/compiti/2021.06.23.tot.pdf] (44 KB) X X 2021.05.26 [http://www.cs.unibo.it/~renzo/so/compiti/2021.05.26.tot.pdf] (40 KB) X-tempo X X X 2020.02.20 [http://www.cs.unibo.it/~renzo/so/compiti/2020.02.20.tot.pdf] (40 KB) easy X X X 2020.01.15 [http://www.cs.unibo.it/~renzo/so/compiti/2020.01.15.tot.pdf] (40 KB) X X-gio X X 2019.09.13 [http://www.cs.unibo.it/~renzo/so/compiti/2019.09.13.tot.pdf] (44 KB) X X 2019.07.15 [http://www.cs.unibo.it/~renzo/so/compiti/2019.07.15.tot.pdf] (44 KB) X 2019.06.18 [http://www.cs.unibo.it/~renzo/so/compiti/2019.06.18.tot.pdf] (48 KB) 2019.05.18 [http://www.cs.unibo.it/~renzo/so/compiti/2019.05.18.tot.pdf] (36 KB) 2019.02.14 [http://www.cs.unibo.it/~renzo/so/compiti/2019.02.14.tot.pdf] (40 KB) 2019.01.15 [http://www.cs.unibo.it/~renzo/so/compiti/2019.01.15.tot.pdf] (48 KB) X X 2018.09.19 [http://www.cs.unibo.it/~renzo/so/compiti/2018.09.19.tot.pdf] (60 KB) 2018.07.17 [http://www.cs.unibo.it/~renzo/so/compiti/2018.07.17.tot.pdf] (44 KB) X X 2018.06.21 [http://www.cs.unibo.it/~renzo/so/compiti/2018.06.21.tot.pdf] (52 KB) 2018.05.28 [http://www.cs.unibo.it/~renzo/so/compiti/2018.05.28.tot.pdf] (48 KB) X X 2018.02.12 [http://www.cs.unibo.it/~renzo/so/compiti/2018.02.12.tot.pdf] (44 KB) X X 2018.01.22 [http://www.cs.unibo.it/~renzo/so/compiti/2018.01.22.tot.pdf] (52 KB) 2017.09.11 [http://www.cs.unibo.it/~renzo/so/compiti/2017.09.11.tot.pdf] (52 KB) 2017.07.17 [http://www.cs.unibo.it/~renzo/so/compiti/2017.07.17.tot.pdf] (48 KB) 2017.06.19 [http://www.cs.unibo.it/~renzo/so/compiti/2017.06.19.tot.pdf] (48 KB) X X 2017.05.29 X so/compiti/2017.07.17.tot.pdf] (48 KB) 2017.06.19 [http://www.cs.unibo.it/~renzo/so/compiti/2017.06.19.tot.pdf] (48 KB) X X 2017.05.29 X ","permalink":"https://flecart.github.io/notes/log-degli-esercizi/","summary":"Ultima modifica: May 13, 2023 4:44 PM Primo Abbozzo: January 14, 2023 11:55 AM Studi Personali: No\nLog esercizi fatti Data, compito, C1 fatto? c2 fatto?\n2022.09.06 [http://www.cs.unibo.it/~renzo/so/compiti/2022.09.06.tot.pdf] (36 KB) X X 2022.07.20 [http://www.cs.unibo.it/~renzo/so/compiti/2022.07.20.tot.pdf] (36 KB) X X (non me lo ricordo) 2022.06.21 [http://www.cs.unibo.it/~renzo/so/compiti/2022.06.21.tot.pdf] (40 KB) X X X 2022.06.01 [http://www.cs.unibo.it/~renzo/so/compiti/2022.06.01.tot.pdf] (36 KB) X X 2022.02.14 [http://www.cs.unibo.it/~renzo/so/compiti/2022.02.14.tot.pdf] (40 KB) X X 2022.01.17 [http://www.cs.unibo.it/~renzo/so/compiti/2022.01.17.tot.pdf] (36 KB) X X X X 2021.09.15 [http://www.","title":"Log degli esercizi"},{"content":"Project, product management, project management Bisogna capire queste definizioni. Vedere https://dynamik.vercel.app/ingegneria-del-software/lucidi/13-gestione-del-progetto.pdf?from=informatica, slide 5 per definizione\nProgetto: inizia e finisce in tempo preciso. Ãˆ importante comunque ricordare gli steps principali per il progetto ossia ideazione, creazione, mantenimento, rilascio, e poi morte, questo in genere Ã¨ per qualunque progetto.\nProject Manager Compiti principali (costi e risorse) Vedere se il progetto Ã¨ fattibile Allocare risorse Monitorare come sta andando. (preventivo e consuntivo). Work Breakdown structure Descrizione WBS Ãˆ una suddivisione del progetto in piccoli sottoparti che si possono gestire in modo autonomo.\nA Work Breakdown Structure (WBS) is a hierarchical decomposition of a project into phases, deliverables, and work packages. It is a visual representation that helps project managers and teams organize and define the scope of work required to complete a project. The WBS breaks down the project into smaller, more manageable components, making it easier to plan, execute, and control.\nhttps://chat.openai.com/share/1d74fa24-d198-4c17-9fbe-1c8cc93333d4\nSi puÃ² rappresentare con un grafico di Gantt (vedi Scheduler#Diagramma di Gantt). PerchÃ© cosÃ¬ so quando ogni singola attivitÃ  inizia e finisce.\nMilestone e percorso critico Debito tecnico Il debito tecnico Ã¨ una stima del costo di futuro sforzo addizionale causato da una soluzione prematura adottata oggi pur di consegnare un prodotto con qualche valore (lo sforzo futuro andrÃ  ripagato con gli interessi)\nIl costo di versioni successive, Ã¨ costo in debito tecnico, per questo motivo Ã¨ maggiore. E si dovrebbe dare valore prima.\nMisura dei costi di sviluppo Misura nel software costo e valore del software Valore Ã¨ sul ricavo -\u0026gt; numero di utenti * ricavo medio. Mentre il costo del software e tempo persona.\nPer stimare il costo usiamo 4 cose:\nCosto hardware Costo sviluppo del software Costo risorse umane Durata del progetto. Metodi generici di stima (4) Design-to-cost nel senso che chi Ã¨ in industria fa prodotto tailored al costo. L\u0026rsquo;ultima Ã¨ funzionale\nLinee di codice (fisiche e logiche) Fisiche sono quelle effettivamente presenti nel codice, invece le linee logiche sono quelle che contengono istruzioni base (per base intendo quelli C like). Se si riesce a fare una stima dell\u0026rsquo;architettura del progetto, e poi delle linee logiche necessarie per fare questo sviluppo, possiamo tenere conto di una media di numeri giornalieri, e possiamo calcolare cose come costo totale del software avendo una media per riga. Chiaramente mi sembra che questa stima sia fortemente imprecisa.\nVantaggi e svantaggi di LOC La cosa carina di questo metodo Ã¨ che Ã¨ facile da fare. Poi abbiamo metriche derivate molto semplici da intendere come:\nBugs per kLoC. la produttivitÃ  Ã¨ una cosa molto facile. Il costo per linea di codice Sono certe metriche che potrebbero servire lato business, perÃ² sono abbastanza senza senso per quanto riguarda features date al cliente. Mi sembra il caso in cui una metrica puÃ² diventare facilmente l\u0026rsquo;oggetto (massimizzare per cosa sbagliata dico), e non una linea guida PerÃ²\ndipende dal linguaggio quasi nessuna correlazione con la qualitÃ  del software (quindi produce bloatware per dire), non viene prodotto software conciso o efficiente. Non tiene conto della complessitÃ , certe istruzioni possono fare un sacco di cose, a seconda del livello di astrazione. Non possiamo distinguere bene le linee logiche con quelle fisiche, non abbiamo un metodo per contarle per dire. Function point Idea principale del metodo Lâ€™analisi Function Point enumera le funzionalitÃ  di un sistema dal punto di vista utente\nElaborata da un certo Dr. Allan Albrecht in 1979, sono il numero di features fatte, che l\u0026rsquo;utente puÃ² utilizzare (e questa stima mi piace molto di piÃ¹ rispetto a quello di linee di codice). Cerchiamo di analizzare il software tramite le funzionalitÃ  nuove che possono venire offerte.\nL\u0026rsquo;idea Ã¨ partire da quello che Ã¨ necessario all cliente, quelli che chiamiamo functional requirements trattati a Requisiti e backlog del software. Insieme a questi sono collegati i non functional requirements che sono features necessarie a sviluppatori, e non utenti.\nUFC e TFC Ufc Ã¨ Unadjusted Function Count che Ã¨ la somma semplice di tutte le funzionalitÃ  su tutti i lati in cui potrebebro essere necessitÃ  di function points.\nCocomo e modelli di costo Non fatti.\n","permalink":"https://flecart.github.io/notes/project-management/","summary":"Project, product management, project management Bisogna capire queste definizioni. Vedere https://dynamik.vercel.app/ingegneria-del-software/lucidi/13-gestione-del-progetto.pdf?from=informatica, slide 5 per definizione\nProgetto: inizia e finisce in tempo preciso. Ãˆ importante comunque ricordare gli steps principali per il progetto ossia ideazione, creazione, mantenimento, rilascio, e poi morte, questo in genere Ã¨ per qualunque progetto.\nProject Manager Compiti principali (costi e risorse) Vedere se il progetto Ã¨ fattibile Allocare risorse Monitorare come sta andando. (preventivo e consuntivo). Work Breakdown structure Descrizione WBS Ãˆ una suddivisione del progetto in piccoli sottoparti che si possono gestire in modo autonomo.","title":"Project Management"},{"content":"Ultima modifica: February 25, 2023 2:07 PM Primo Abbozzo: December 29, 2021 12:42 PM Studi Personali: No\nRappresentazione delle informazioni Mini-quiz Cosa Ã¨ una codifica posizionale? Darne degli esempi Codificare -189 in 9 bit utilizzando modulo o segno, complemento a 1 a 2 e in eccesso Cosa sono underflow e overflow per la codifica dei floating point? PerchÃ© i floating point hanno questa imprecisione mentre la codifica di interi no? Come sono codificati i caratteri nei calcolatori? Quali sono le cause piÃ¹ comuni per errori di trasmissione? Cosa sono i codici correttori? Cosa Ã¨ la distanza di hamming? Giustificare il motivo per cui Ã¨ necessaria una distanza di hamming di almento k + 1 per trovare k errori e 2k + 1 per correggere k errori. Cosa Ã¨ il bit di paritÃ ? In che modo Ã¨ utilizzato nel codice di hamming? Ãˆ stato ricevuto un codice 1000110100110 Analizzarlo usando il codice di hamming Soluzioni scarne Un sistema di numerazioneÂ posizionaleÂ Ã¨ un sistema di numerazione in cui i simboli (cifre) usati per scrivere i numeri assumono valori diversi a seconda della posizione che occupano nella notazione. (wiki :D). Quindi Ã¨ il sistema di numerazione comune. La base cambia il formato. Comunemente Ã¨ utilizzato base 10 perchÃ© gli esseri umani hanno cominciato a contare con le proprie 10 dita, mentre base 2 per i calcolatori. 189 = 128 + 61 = altro+ 32 + 29 = altro + 16 + 13 = altro + 8 + 5 = altro + 4 + 1 1011 1101, se utilizziamo la codifica a segno, Ã¨ negativo quindi ci metto un 1 1 1011 1101 per il complemento a 1, cambio ogni bit. 1001000010 Per il complemento a 2 sommo 1 al complemento a 1 1001000011 Per la codifica in eccesso devo codificare -189 + 256 = 67 = 64 + 2 = 1 = 001000011 Underflow e overflow esistono a causa della natura dei floating point. Infatti i floating point sono costituiti da tre parti: un bit per il segno, un insieme di bit per lâ€™esponente e una mantissa per una parte decimale. Quindi un floating point Ã¨ sempre memorizzato secondo la notazione scientifica e.g. 0.756 * 10e7, ma invece di essere in base 10 Ã¨ in base 2. Se lâ€™esponente Ã¨ eccessivamente alto o eccessivamente basso puÃ² occorrere che la parte dellâ€™esponente non sia sufficiente a mantenere questa informazione. Inoltre ci possono essere delle frazioni che non possano essere esprimibili in modo discreto (per esempio numeri periodici in base 2) e che quindi comportano un imprecisione nella mantissa. Questi errori sono ben piÃ¹ visibili con un alto valore assoluto di un esponente. 4. Anche i caratteri sono codificati come se fossero dei numeri. La codifica principale Ã¨ la codifica ASCII. Ma potendo codificare solo una quantitÃ  molto limitata di caratteri (un centinaio), ultimamente si Ã¨ passati alla codifica unicode che possiede 2 byte invece che 1. Esiste anche una codifica UTF-8 che Ã¨ dinamica dal punto di vista dei byte utilizzati: invece che sempre 2 byte puÃ² averne da 1 a 4. 5. Interferenze di trasmissione, raggi cosmici, disturbi fisici dellâ€™apparecchio di trasmissione. 6. I codici correttori sono codici che possiedono una quantitÃ  sovrabbondante di informazioni in modo che, nel caso in cui ci sia stato un errore di trasmissione, sia possibile ricavare il messaggio originale. 7. La distanza di hamming fra due numeri Ã¨ uguale al numero di 1 rimasti dopo lo xor fra questi due. Per un insieme di numeri, Ã¨ la distanza minima che esiste fra ogni coppia di numeri dellâ€™insieme 8. Difficile 9. Il bit di paritÃ  di un codice Ã¨ 1 se ci sono pari numeri di 1, 0 altrimenti. Ãˆ altresÃ¬ riassumibile come lo xor fra tutti i bit del codice. Nel codice di hamming Ã¨ utilizzato per tenere conto di alcuni bit in certe posizioni. Lâ€™applicazione nel prossimo esercizio spiega meglio di come sto tentando di fare ora. 10. 1000110100110\n! di alcuni bit in certe posizioni. Lâ€™applicazione nel prossimo esercizio spiega meglio di come sto tentando di fare ora. 10. 1000110100110\n!\n","permalink":"https://flecart.github.io/notes/quizzes/","summary":"Ultima modifica: February 25, 2023 2:07 PM Primo Abbozzo: December 29, 2021 12:42 PM Studi Personali: No\nRappresentazione delle informazioni Mini-quiz Cosa Ã¨ una codifica posizionale? Darne degli esempi Codificare -189 in 9 bit utilizzando modulo o segno, complemento a 1 a 2 e in eccesso Cosa sono underflow e overflow per la codifica dei floating point? PerchÃ© i floating point hanno questa imprecisione mentre la codifica di interi no? Come sono codificati i caratteri nei calcolatori?","title":"Quizzes"},{"content":"Ripasso Prox: 5 Ultima modifica: December 29, 2022 3:24 PM Primo Abbozzo: July 30, 2022 4:16 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Agenti Logici Introduzione Nozioni base Questi sono le parole chiave di questo capitolo, ci permettono di parlare con chiarezza riguardo lâ€™agente logico.\nSentence\nKnowledge Base\nAxiom\nInference\nbackground knowledge\nKnowledge representation language\nKnowledge level\nImplementation level\nEsempio generale di agente logico\nLogica proposizionale Sintassi del linguaggio Descrivere la BNF della logica proposizionale.\nper sapere cosa sia la BNF di questo Ã¨ molto piÃ¹ facile rifarsi agli appunti di logica presi durante lâ€™anno di corso 2021/2022 Logica Proposizionale.\nDeduzione o derivazione Abbiamo ora un algoritmo (stupido) di verifica sul fatto se valga o meno $KB \\vDash \\alpha$, ovvero vogliamo sapere se alpha si puÃ² derivare dal nostro modello\nAlgoritmo di derivazione\nInferenza â†’ (sound and complete inference methods) Risoluzione La risoluzione Ã¨ una operazione che si puÃ² avere fra due clausole, come se fosse una regola di derivazione, come vedremo ci sta molto comodo, anche se non lâ€™abbiamo mai fatta a lezione.\nIn breve:\nConsiste di eliminare qualche caso banale negli OR e.g. se ho a or b or c, e ho anche not a, allora posso dedurre b or c.\nSono interessanti soprattutto perchÃ© Ã¨ una operazione completa, cioÃ¨ che Ã¨ in grado di derivare tutto il derivabile (quindi se gli dai 2 clausole random, $\\alpha, \\beta$ riesce sempre a determinare se vale o meno $\\alpha \\vDash \\beta$.\noltre a ciÃ² sono anche sound, ossia quello che deducono Ã¨ corretto (non fanno mai teoremi sbagliati).\nPerchÃ© funziona\nIn pratica prova a dimostrare che not tesiâ†’ assurdo. e questa Ã¨ gestibile perchÃ© Ã¨ in forma congiuntiva normale, che permette di utilizzare la risoluzione\nAlgoritmo per la risoluzione\nCheck del modello Modelli di inferenza Conjunctive Normal Form Quando abbiamo delle clausole, ossia delle disgiunzioni di letterali, possiamo cercare di trasformare questa nella sua forma congiuntiva normale. Questo Ã¨ possibile perchÃ© ogni proposizione si puÃ² ridurre a And e Or.\nBNF della CNF\nAndare a vedere questo per un algoritmo che utilizzi questa forma per runnare.\nForward Chaining Horn Clauses Una horn clause Ã¨ una proposizione composta di and, in cui al messimo un singolo valore Ã¨ vero.\nSi Ã¨ scoperto che esiste un algoritmo molto efficiente per checkare se una proposizione Ã¨ vera in un modello (che eseguen in O(n))\nIn pratica Ã¨ una cosa molto simile in And-or search presentato in Problemi di ricerca.\nAlgoritmo in breve\nPraticamente Ã¨ una BFS che prende come queue iniziale tutte le proposizioni atomiche che sono date per vere.\nUna volta poppati questi vanno a diminuire il conteggio degli implica che lo hanno come ipotesi. Se il singolo implica ha questo counter del numero di ipotesi necessarie che va a 0, allora si hanno nuove ipotesi.\nDa notare che questo funziona solamente per HORN CLAUSES perchÃ© ci fa molto comodo avere un unico effetto derivato da una serie di di ipotesi in AND iniziali.\nAlgoritmo\nAgente logico Frame problem Conclusione Creazione di Plan con SAT solvers IncapacitÃ  della logica proposizionale col tempo ","permalink":"https://flecart.github.io/notes/agente-logico/","summary":"Ripasso Prox: 5 Ultima modifica: December 29, 2022 3:24 PM Primo Abbozzo: July 30, 2022 4:16 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Agenti Logici Introduzione Nozioni base Questi sono le parole chiave di questo capitolo, ci permettono di parlare con chiarezza riguardo lâ€™agente logico.\nSentence\nKnowledge Base\nAxiom\nInference\nbackground knowledge\nKnowledge representation language\nKnowledge level\nImplementation level\nEsempio generale di agente logico\nLogica proposizionale Sintassi del linguaggio Descrivere la BNF della logica proposizionale.","title":"Agente Logico"},{"content":"Ripasso Prox: 60 Ripasso: December 19, 2021 Ultima modifica: December 14, 2021 3:43 PM Primo Abbozzo: October 3, 2021 10:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 1 Variabili ed espressioni 1.1 Identificatori e dichiarazioni 1.1.1 Il nome simbolico/simbolico e fisico Nome simbolico: nome leggibile da esseri umani diverso dal nome numerico con cui se lo ricorda il computer\nðŸ’¡ Fai attenzione alle possibili variabili per il nome simbolico! Attenzione\n1.1.2 Dichiarazione dei nomi esempio:\nint n; Quello che il programma fa sotto Ã¨ creare memoria per la variabile.\n1.2 Tipi di dato Ricordarsi che\n1.2.1 Int 4 bytes in memoria\nHa operazioni come basiche somme sottrazioni, moltiplicazioni e divisioni\nComparazione\nil resto %\n1.2.2 Double 8 bytes in memoria\nSono molto utili nelle applicazioni scientifiche\nStesse operazioni per int ma senza il resto\noperazioni di libreria. Cast Imprecisione di double\n1.2.3 Bool VeritÃ \u0026hellip;\n1.2.4 Char stora un carattere, puÃ² essere ragruppato in array\n1.2.5 const Non si puÃ² modificare.\n1.3 Espressioni e Type safety 1.3.1 Espressioni Una espressione Ã¨ una operazione che ritorna un valore dato.\npuÃ² essere di 4 tipi:\nespressioni\nE la precedenza Ã¨ dato da valori di precedenza\u0026hellip;\n1.3.2 Type safety Bisogna utilizzare una entitÃ  in accordo al tipo.\nQuindi:\nDichiarare variabie Usare operazioni predefinite della variabile. Leggere eventuali errori del compilatore per sapere di errori. 1.4 Input/output 1.4.1 Input L\u0026rsquo;operatore di input Ã¨\ncin \u0026gt;\u0026gt; n; Con le \u0026raquo; doppie freccie verso destra per dire che sto mettendo dentro n;\n1.4.2 Output cout \u0026lt;\u0026lt; n; Per dire sto mettendo dentro cout il valore n cosÃ¬ me lo printa. freccie verso destra per dire che sto mettendo dentro n;\n1.4.2 Output cout \u0026lt;\u0026lt; n; Per dire sto mettendo dentro cout il valore n cosÃ¬ me lo printa.\n","permalink":"https://flecart.github.io/notes/basi/","summary":"Ripasso Prox: 60 Ripasso: December 19, 2021 Ultima modifica: December 14, 2021 3:43 PM Primo Abbozzo: October 3, 2021 10:19 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 1 Variabili ed espressioni 1.1 Identificatori e dichiarazioni 1.1.1 Il nome simbolico/simbolico e fisico Nome simbolico: nome leggibile da esseri umani diverso dal nome numerico con cui se lo ricorda il computer\nðŸ’¡ Fai attenzione alle possibili variabili per il nome simbolico!","title":"Basi"},{"content":"Ripasso Prox: 30 Ripasso: December 19, 2021 Ultima modifica: December 14, 2021 3:43 PM Primo Abbozzo: October 5, 2021 11:42 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 2 Iteratori 2.1 While 2.1.1 Guardia 2.1.1 Corpo del ciclo 2.1.3 Variabile di controllo 2.2 While, for, do bruh i Personali: No\nElementi di ripasso 2 Iteratori 2.1 While 2.1.1 Guardia 2.1.1 Corpo del ciclo 2.1.3 Variabile di controllo 2.2 While, for, do bruh\n","permalink":"https://flecart.github.io/notes/cicli-iterativi/","summary":"Ripasso Prox: 30 Ripasso: December 19, 2021 Ultima modifica: December 14, 2021 3:43 PM Primo Abbozzo: October 5, 2021 11:42 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ• Studi Personali: No\nElementi di ripasso 2 Iteratori 2.1 While 2.1.1 Guardia 2.1.1 Corpo del ciclo 2.1.3 Variabile di controllo 2.2 While, for, do bruh i Personali: No\nElementi di ripasso 2 Iteratori 2.1 While 2.1.1 Guardia 2.1.1 Corpo del ciclo 2.1.3 Variabile di controllo 2.2 While, for, do bruh","title":"Cicli iterativi"},{"content":"Lempel-Ziv-Welch Algorithm Introduzione sul funzionamento Primo scan con un dizionario indexato dei singoli caratteri Poi viene cercato di raggruppare caratteri a coppie. Se una coppia Ã¨ giÃ  presente nel dizionario, allora aggiungo al dizionario una cosa piÃ¹ lunga e metto un code diverso Esempio di sopra. La cosa carina Ã¨ che il dizionario si puÃ² ricostruire in fase di decoding.\nTutti gli altri, tipo zip, gzip, png si basano poi su questa idea. Per certi versi la cosa di raggruppare Ã¨ simile a Byte pair encoding.\nHuffman Codes Questa parte probabilmente Ã¨ stata anche trattata in modo molto breve al corso di algoritmi. Basato sul paper di 1952 \u0026ldquo;A method for the construction of minimum redundancy codes\u0026rdquo;. Di Huffman L\u0026rsquo;idea principale Ã¨ creare un albero di codifica in modo che le cose frequenti siano in cima, ossia hanno un codice molto breve, mentre cose lunghe abbiano codici piÃ¹ lunghi.\nIl codice di Huffman Ã¨ un algoritmo che nella media ha compressione migliore lossless. Ossia si ha $L^{*}(C_{huffman}) \\leq L(C)$ per qualunque altro carattere. Ha anche relazioni con le prefix strings, ne si parla di piÃ¹ in Entropy.\nAssumiamo che ogni carattere abbiano una frequenza.\nAlgoritmo di Huffman Creo una lista ordinata dalla frequenza Inizio ad assegnare codici a questa lista volta per volta partendo dai piÃ¹ bassi Inserisco in cima creando nuovi nodi (che reinserisco) volta per volta sempre prendendo il piÃ¹ basso di frequenza Si crea un prefix-code in questo modo che si puÃ² utilizzare a piacere. Una volta creato questo albero, posso usarlo per codificare e anche decodificare. \u0026#34;\u0026#34;\u0026#34; Huffman code generator -- after [https://stackoverflow.com/questions/11587044/how-can-i-create-a-tree-for-huffman-encoding-and-decoding](https://stackoverflow.com/questions/11587044/how-can-i-create-a-tree-for-huffman-encoding-and-decoding) \u0026#34;\u0026#34;\u0026#34; GRAPHIMAGE = \u0026#39;HuffmanGraph\u0026#39; # for Huffman tree display. SOURCETXT = \u0026#39;texts/English.txt\u0026#39; # for statistics ###################################### # Huffman coding # ##################### ######## def assign_code (nodes, label, result, prefix = \u0026#39;\u0026#39;): childs = nodes[label] tree = {} if len(childs) == 2: tree[\u0026#39;0\u0026#39;] = assign_code (nodes, childs [0], result, prefix+\u0026#39;0\u0026#39;) tree[\u0026#39;1\u0026#39;] = assign_code (nodes, childs [1], result, prefix+\u0026#39;1\u0026#39;) return tree else: result[label] = prefix return label def Huffman_code(_vals): vals = _vals.copy() nodes = {} for n in vals: # leafs initialization nodes [n] = [] while len (vals) \u0026gt; 1: # binary tree creation s_vals = sorted (vals.items (), key-lambda x:x[1]) al = s_vals[0][0] a2 = s_vals[1][0] vals[al+a2] = vals.pop(al) + vals.pop(a2) nodes [al+a2] = [al, a2] code = {} root = al+a2 tree = {} tree = assign_code (nodes, root, code) # assignment of the code for the given binary tree return code, tree ","permalink":"https://flecart.github.io/notes/compression-algorithms/","summary":"Lempel-Ziv-Welch Algorithm Introduzione sul funzionamento Primo scan con un dizionario indexato dei singoli caratteri Poi viene cercato di raggruppare caratteri a coppie. Se una coppia Ã¨ giÃ  presente nel dizionario, allora aggiungo al dizionario una cosa piÃ¹ lunga e metto un code diverso Esempio di sopra. La cosa carina Ã¨ che il dizionario si puÃ² ricostruire in fase di decoding.\nTutti gli altri, tipo zip, gzip, png si basano poi su questa idea.","title":"Compression Algorithms"},{"content":"Impostazione del problema Supponiamo di stare giocando a n slot machine contemporaneamente. Queste macchine hanno internamente un valore di reward che non conosciamo. Ad ogni step possiamo scegliere una singola macchina e andare a tirare la sua leva. Riceviamo il valore del reward nascosto con un pÃ² di rumore. Vogliamo capire nel lungo quale sia la strategia che possa dare migliore reward medio possibile.\nQuesto Ã¨ un semplice problema, ma lo possiamo considerare un fulcro molto importante per poter comprendere il problema del reinforcement learning.\nThe mathematical model Supponiamo che $\\{ \\mathcal{R}_{a} | a \\in \\mathcal{A}\\}$ dove $a$ Ã¨ l\u0026rsquo;index per una certa macchina, assumiamo che ogni slot machine abbia un certo reward non conosciuto dall\u0026rsquo;agente. $a$ Ã¨ l\u0026rsquo;azione, ossia su quale slot machine possiamo andare a giocare. L\u0026rsquo;obiettivo Ã¨ massimizzare il reward sul tempo, assumendo che $R_{t}$ sia il reward al tempo $t$. Per farlo abbiamo bisogno di trovare una policy. Teniamo sempre le definizioni di action value, optimal value.\nDef: Regret, action value and optimal value Action value $q(a) = E[R_t | A_t = a]$\nOptimal value $V = \\max_a q(a)$\nRegret Ossia rappresenta quanto potremmo fare meglio. $$ \\Delta_{a} = v_{*} - q(a) $$ Total regret $$ L_{t} = \\sum_{n=1}^{t} \\Delta_{A_{n}} $$ Ossia tutti i regrets per l\u0026rsquo;azione del tempo\nSoluzioni classiche Accenno soluzioni (vecchio, da riguardare) I metodi presentati sono\nOptimistic initial value Mean-reward UCB choice Mean-reward\nVogliamo cercare di capire quale sia il valore nascosto all\u0026rsquo;interno di questi cosi. Possiamo supporre di avere un valore di default per ogni slot machine. Poi la strategia seguirÃ  questo pseudo codice\ndef make_choice( extimate_r, # /*array of extimates*/, epsilon # /* exploration-exploitation balance */ ): x = random_sample from 0 to 1 // uniform distribution if (x \u0026lt;= epsilon): // explore idx = random choice x from all r else: idx = argmax(extimate_r); return idx; Dopo aver fatto la scelta, cercheremo di aggiornare il valore del reward seguendo proprio la media, quindi\n$R_k = (r_k + \\dfrac{1}{(k -1)} R_{k - 1}) / k$, con rk il reward attuale e quella il nuovo robo, anche se solitamente questa formula la si troverÃ  scritta in questo modo, perchÃ© piÃ¹ carina\n$$ R_k = R_{k - 1} + \\dfrac{1}{k}( r_k - R_{k - 1}) $$ Questo Ã¨ il classico reinforcement learning per sta roba. UCB cambia solo nella selezione dellâ€™indice da esplorare, che lo fa con la formula dipendente dal numero di esplorazioni fatte su questo, sugli altri nodi e simili.\nmentre il optimistic initial value Ã¨ molto particolare, si assegna un valore molto ottimistico, poi 0 al valore epsilon per lâ€™esplorazione, poi piano piano tutte le mosse scendono di valore, fin quando non diventano realistiche.\nGreedy solutions Estimate of the average $$ Q_t(a) = \\frac{\\sum_{n=1}^t I(A_n = a) R_n}{\\sum_{n=1}^t I(A_n = a)} $$ Questo si puÃ² fare anche in modo incrementale:\n$$ Q_{t}(A_{t})) = Q_{t- 1} (A_{t} + \\alpha_{t}(R_{t} - Q_{t - 1} (A_{t}))) $$ Dove l\u0026rsquo;ultima parte Ã¨ un errore. e $\\alpha_{t} = \\frac{1}{N_{t}(A_{t})}$\nGreedy solution La parte greedy prende solamente l\u0026rsquo;azione che massimizza il valore atteso per l\u0026rsquo;azione. Quindi $$ A_{t} = arg\\max_{a} Q_{t}(a) $$ Il problema Ã¨ che questo non esplora. Potrebbe trovare il minimo e restare in quello perchÃ© la sua stima Ã¨ quella.\nEpsilon greedy solution La epsilon greedy prova a risolvere questo, tenendo una probabilitÃ  di esplorare. Uniform $\\varepsilon$, e con questa probabilitÃ  si fa qualcosa random, e in questo modo si aggiorna il resto. $$ \\pi_{t}(a) = \\begin{cases} (1 - e) + \\frac{e}{|A|} \u0026 \\text{if } Q(a) = \\max_b Q(b) \\\\ \\\\ \\frac{\\varepsilon}{\\lvert \\mathcal{A} \\rvert } \u0026 \\text{otherwise} \\end{cases} $$ Questo dovrebbe essere l\u0026rsquo;algoritmo utilizzato per Atari. Problema Ã¨ che continua ad esplorare anche se ha raggiunto convergenza buona della stima\nGradient Based Policy search Action preferences proviamo a stimare $$ \\pi(a) = \\frac{e^{H_{t}(a)}}{\\sum_{b} e^{H_{t}(b)}} $$ Utile per avere distribuzioni di probabilitÃ . Vogliamo trovare action preferences per policies migliori. Questo ci permette di utilizzare gradient ascent per migliorare il $\\pi$.\nAbbiamo quindi $$ \\theta_{t + 1} = \\theta_{t} + \\alpha \\nabla_{\\theta}\\mathbf{E}[R_{t} | \\pi_{\\theta_{t}}] $$ E ci permette di fare gradient ascent. Abbiamo un problema di come fare sample.\nUsiamo (Williams 1992). Chiamato anche Reinforce. Da quello e da questo punto della lezione deriviamo $$ \\nabla_{\\theta}\\mathbf{E}[R_{t}|\\theta] = \\nabla_{\\theta}\\mathbf{E}[R_{t}\\nabla_{\\theta}\\log \\pi_{\\theta}(A_{t})] $$ E si puÃ² fare classico gradient ascent con la parte dentro all\u0026rsquo;argomento.\nProviamo avere questo algoritmo per action preferences $$ H_{t+1}(a) = H_{t}(a) + \\alpha R_{T} \\frac{\\delta \\log\\pi_{t}(A_{t})}{\\delta H_{t}(a)} = H_{t}(a) + \\alpha R_{t} (\\mathbb{1}(a = A_{t}) - \\pi_{t}(a)) $$ Ãˆ un esercizio provare a derivare questo cosa.\nThe upper confidence bound L\u0026rsquo;idea Ã¨\nSelezionare se l\u0026rsquo;azione Ã¨ big reward Selezionare se l\u0026rsquo;azione non Ã¨ ancora stata esplorata abbastanza Quindi come per il precedente, che vogliamo esplorare ancora, con la differenza che perÃ² vorremmo diminuire la possibilitÃ  nel caso fosse esplorata abbastanza\nL\u0026rsquo;algoritmo sembra poi molto simile ai greedy, solo che abbiamo una funzione di UCB in piÃ¹. Logarithmic regret as upperbound! (Auer et al 2002 questa roba).\nHoeffding\u0026rsquo;s Inequality How wrong is our extimate? Consider $X_{1}, X_{2}, \\dots, X_{n}$ variabili randomiche in 0, 1 con una certa media. rappresenteranno il nostro reward, e assumiamo che $\\bar{X}$ ma media fino a $n$, in un certo senso simile ai bounds che stavamo studiando in Central Limit Theorem and Law of Large Numbers. La differenza con Markov e Chebicheff Ã¨ che qui scende in modo esponenziale.\n$$ p\\left(\\overline{X}_{n}+u\\leq\\mu\\right)\\leq\\,e^{-2n u^{2}} $$ Questo Ã¨ un caso particolare in cui $b = 1, a = 0$ e funziona.\nPossiamo utilizzare questo teorema con $R_{t}$, infatti possiamo vedere che $$ p(Q_{t}(a) + U_{t}(a) \\leq q(a)) \\leq \\exp(-2N_{t}(a) U_{t}(a)^{2}) $$ E vale per qualche motivo strano anche con la - $$ p(Q_{t}(a) - U_{t}(a) \\geq q(a)) \\leq \\exp(-2N_{t}(a) U_{t}(a)^{2}) $$ Questo teorema giustifica perchÃ© vogliamo scegliere il bound come questo valore:\n$$ U_{t}(a) = \\sqrt{ \\frac{-\\log p}{ 2N_{t}(a)} } $$ $p$ possiamo stimarlo come il numero di volte che prendiamo quel valore nella nostra ricerca, quindi $p = \\frac{1}{t}$ . Questo Ã¨ la spiegazione teorica del perchÃ© il branch di esplorazione che abbiamo fatto durante il primo anno per il progetto di algoritmi funziona.\nLai and Robbins on Regret growth $$ \\lim_{ t \\to \\infty } L_{t} \\geq \\log t \\sum_{a| \\Delta_{a}} \\frac{\\Delta_{a}}{KL(\\mathcal{R}_{a} \\mid\\mid \\mathcal{R}_{a^{*}})} $$ Ossia il total regret Ã¨ bounded sotto almeno logaritmica-mente! Quindi se riesco a boundarlo sopra ho la cosa tight.\nDerivation of the algorithm Consideriamo $L_{t}$ che Ã¨ il total regret numero di volte che selezioniamo l\u0026rsquo;azione, per il regret atteso. $$ L_{t} = \\sum_{a} N_{t}(a) \\Delta_{a} $$ E vorremmo che questa cosa sia il piÃ¹ basso possibile affinchÃ© possa risultare utile. Supponiamo che sia bounded. Ossia che per ogni $a = a^{*}$ valga $N_{t}(a) \\Delta_{a} \\leq x_{a} \\log t$ .\nVorremmo trovare con una versione di UCB, che ci serve per selezionare l\u0026rsquo;azione.\nOra prendiamo $m \\leq t$ allora dovrebbe valere che $N_{m}(a) \\Delta_{a} \\leq x_{a} \\log m \\leq x_{a} \\log t$\nProbability Matching and Thompson sampling Vogliamo scegliere l\u0026rsquo;azione che possa sembrare la migliore secondo la nostra credenza: $$ \\pi_{t}(a) = p\\left(q(a) = \\max_{a'}q(a') | \\mathcal{H}_{t - 1}\\right) $$ Per calcolare questo si puÃ² utilizzare Thompson sampling.\nSample $Q_{t}(a) ~~~ p_{t}q(a)$ Seleziona l\u0026rsquo;azione che massimizza $Q_{t}(a)$ per ogni $a$ all\u0026rsquo;interno di $\\mathcal{A}$. Questo si avvicina al limite teorico ottimo, quindi nice. Ma il problema Ã¨ che non sono scalabili questi algoritmi. References [1] Williams â€œSimple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learningâ€ Machine Learning Vol. 8(3), pp. 229\u0026ndash;256 1992\n","permalink":"https://flecart.github.io/notes/n-bandit-problem/","summary":"Impostazione del problema Supponiamo di stare giocando a n slot machine contemporaneamente. Queste macchine hanno internamente un valore di reward che non conosciamo. Ad ogni step possiamo scegliere una singola macchina e andare a tirare la sua leva. Riceviamo il valore del reward nascosto con un pÃ² di rumore. Vogliamo capire nel lungo quale sia la strategia che possa dare migliore reward medio possibile.\nQuesto Ã¨ un semplice problema, ma lo possiamo considerare un fulcro molto importante per poter comprendere il problema del reinforcement learning.","title":"N-Bandit Problem"},{"content":"Ripasso Prox: 70 Ripasso: June 25, 2023 Ultima modifica: June 9, 2023 2:56 PM Primo Abbozzo: November 18, 2022 2:52 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Domande\nBottom up parser Descrivo ora alcune domande utili per ripasso:\nQuali sono schematicmente quali sono le operazioni migliori per un parser top-down? Cosa Ã¨ un prefisso viabile? Quali sono i conflitti possibli, e come risolverliâ€¦ Non sai nemmeno definire inmodo formale cosa sia un item Bottom up Intro shift-reduce e LR ðŸŸ© Slide\nIn breve:\nShift = simbolo terminale messo nella stack Riduzione utilizzando una produzione LR = dettura da Sinistra, creazione della stringa da destra (derivazione rightmost) Algoritmo classico ðŸŸ¨+ Quello che credo che intendevo per questo algoritmo classico Ã¨ quello non deterministico, nel senso che prova a fare backtracking, finchÃ© non ha finito tutte le possibilitÃ , oppure trova la derivazione giusta.\nSlide\nQuesto Ã¨ esattamente lo stesso presentato alla fine di Linguaggi Deterministici e DPDA\nEsempio\nIl drawback classico di queste tipologie di parser Ã¨ che câ€™Ã¨ un enorme non determinismo causato dai conflitti shift-reduce e reduce-reduce, che non hanno una lettura immediata, andremo quindi in seguito a creare metodi che possano disambiguare ciÃ².\nIl parser LR Struttura di un parser LR ðŸŸ¨++ Slide schematizzazione\nIn figura sono descritte tutte le componenti del parser in modo molto schematico.\nComponenti importanti sono\nDFA e stack degli stati del DFA Pila dei simboli Tabella di parsing Algoritmo alto livello di parsing ðŸŸ© Mosse di parser LR deterministico\nOssia le operazioni che puÃ² fare il parser\nAlgoritmo in pseudocodice\nEsempio di parsing LR\nNota, spesso Ã¨ molto comodo fare una grammatica aumentata in questo modo\nIl DFA degli stati pare quindi fondamentale per la costruzione della tabella di parsing, in seguito andremo a costruire dei metodi automatici utili a far questo.\nQuesto Ã¨ un DFA con alcuni modi di tornare indietro.\nÃˆ bene quindi andare prima a fondare una teoria solida per questa roba, la crazione dellâ€™automa canonico per il parsing LR.\nPrefisso viabile I prefissi viabili sono un modo per risolvere il non determinismo di un parser classico bottom up, ci permette di capire in modo univoco se andare a fare shift e reduce col sistema degli handle.\nPer poter controllare bene i prefissi viabili utilizziamo una tabella di parsing per controllare lo stato dellâ€™handle.\nIntroduzione al perchÃ© (informale, non fare) ðŸŸ© Slide\nLâ€™idea Ã¨ far in modo che in cima alla pila ci sia solamente qualcosa che possa essere un prefisso di una produzione se non lo puÃ² esere si puÃ² concludere chiaramente che non sia possibile!\nPer controllare questi prefissi utilizzeremo di nuovo una tabella di parsing, ma con altra logica sotto.\nDefinizione ðŸŸ¨ â€” Slide sui prefissi viabili.\nInformalmente: una sequenza $\\in (T \\cup NT)^*$ che puÃ² apparire sulla pila del parser bottom up per una configurazione che accetta lâ€™input.\nDa notare differenza della definizione per stringa e per gramamtica.\nPer stringa Ã¨ qualunque stringa che puÃ² apparire sulla pila, al momento di una computazione che va a buon fine Per grammatica, invece, andiamo a considerare le derivazioni destre. In questa parte si introducono anche concetti come prefisso viabile completo e handle. **(non credo sia importante questa definizione la salto). Gli handle sono di interesse perchÃ© appena li abbiamo siamo sicuri che vogliamo andare a fare una reduce, vorremmo trovare un modo per farceli comparire sti handle quando ne ho bisogno!\nNOTA: la derivazione deve essere rightmost almeno nella definizione, anche se non ho ben capito per quale motivo deve essere cosi`.\nTh. prefissi variabili di G libera sono un linguaggio regolare ðŸŸ© Slide\nQuesto teorema ci Ã¨ molto utile per continuare la nostra costruzione del parser, perchÃ© ora possiamo utilizzare questo DFA di supporto generato dal linguaggio regolare dei prefissi variabili per decidere cosa fare:\nSe Ã¨ completo faccio reduce Se non lo Ã¨ faccio shift Se non Ã¨ nemmeno un prefisso variabile sono in errore, perchÃ© mai ci potrÃ² fare una reduce, questo per definizione di prefisso variabile. Abbiamo cosÃ¬ discusso su vantaggi che questo teorema ci puÃ² dare, ma non abbiamo ancora dato un modo per dimostrare questo teorema, lo dimostreremo in seguito, con la costruzione degli item e un DFA per esse. e poi sappiamo che i DFA sono anchâ€™esse equivalenti a un linguaggio regolare.\nShift e reduce sullo stato del DFA ðŸŸ© In questa minisezione andiamo a trattare in che modo potremmo codificare il DFA in modo efficiente, in modo da non rifare ad ogni shift e reduce il ricalcolo dellâ€™intera stringa!\nSlide\nQuindi per lo shift molto easy, basta che ricomincio dallo stato vecchio.\nPer il reduce invece mi serve poter tornare indietro! il modo piÃ¹ semplice per fare questo Ã¨ tenersi uno stack degli stati, in modo che possa tornare indietro in modo lineare (poi quindi credo che lâ€™algoritmo sarÃ  lineare nei nodi dellâ€™albero in questo modo).\nAutoma canonico Lâ€™automa canonico per il parser LR(0) Ã¨ un DFA utilizzato per decidere se fare reduce oppure shift. (quindi vede se prefisso viabile Ã¨ completo o meno).\nItem LR(0) ðŸŸ© Lâ€™item Ã¨ un costituente del DFA di supporto per il nostro DFA\nSlide\nIn pratica apro la produzione che ho, in un sacco di produzioni che contengono un punto, questo punto mi indica piÃ¹ o meno quanto Ã¨ presente sulla stack.\nIntro Costruzione NFA dei prefissi ðŸŸ¨â€” Slide\nLâ€™idea per questo algoritmo Ã¨ utilizzata per gestire la grammatica aumentata degli item!.\nAvanzamento dellâ€™item, in questo caso avanzo semplicemente il punto (vado in stato corrispondente con punto in piÃ¹!) Letttura di un altro simbolo, collegamento epsilon a questâ€™altro punto. Esempio\nClos e Goto ðŸŸ©- Slide algo\nQuesti due algoritmi codificano in pseudocodice i concetti precedenti.\nClos, Ã¨ utilizzato per lettura di un altro collegamento epsilon, dato che va a checkare tutte le produzioni con quel coso in piÃ¹, simula tutto il raggiungibile senza leggere in un certo senso. Goto Ã¨ per avanzare il punto, quindi mi crea tutte le produzioni con avanzamento del punto, e le chiude, specificatamente alle produzioni in una certa forma. simula una lettura in un certo senso. Queste saranno delle funzioni di supporto per la costruzione dell\u0026rsquo;automa canonico di riferimento, cosÃ¬ non dovremo passare all\u0026rsquo;algoritmo esponenziale per la costruzione del DFA, lâ€™automa canonico.\nCostruzione dellâ€™automa canonico ðŸŸ¨ Slide algo\nQuesto algoritmo parte dal NFA dei prefissi viabili, e utilizza Goto e Clos per trovare il NFA in modo molto efficiente!\nEsempio 1\nEsempio 2\nTabella di parsing LR ðŸŸ© Slide, descrizione generale, molto simile a LL\nCostruzione tabella per LR(0)\nEsempio tabella di parsing\nEsempio 2\n","permalink":"https://flecart.github.io/notes/bottom-up-parser-lr0/","summary":"Ripasso Prox: 70 Ripasso: June 25, 2023 Ultima modifica: June 9, 2023 2:56 PM Primo Abbozzo: November 18, 2022 2:52 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Domande\nBottom up parser Descrivo ora alcune domande utili per ripasso:\nQuali sono schematicmente quali sono le operazioni migliori per un parser top-down? Cosa Ã¨ un prefisso viabile? Quali sono i conflitti possibli, e come risolverliâ€¦ Non sai nemmeno definire inmodo formale cosa sia un item Bottom up Intro shift-reduce e LR ðŸŸ© Slide","title":"Bottom-up Parser LR(0)"},{"content":"Ripasso Prox: 50 Ripasso: June 14, 2023 Ultima modifica: May 13, 2023 11:59 PM Primo Abbozzo: October 12, 2022 9:50 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nReti di Reti Le parti importanti per questo sono Data Plane e Control Plane (che ha saltato quasi tutto, ma almeno dijkstra lo dovresti fare bene)\nIntroduzione (puoi skippare ðŸŸ©) La puoi skipppare perchÃ© tratta in modo molto generare parti che saranno trattati in modo piÃ¹ approfondito in seguito. La parte importante forse Ã¨ il riassunto di cosa faccia questo livello.\nDiscussione rete locale globale Slide\nNo, non Ã¨ possible creare una connessione globale utilizzando le tecnologie locali, come hub, switch e simili, perchÃ© causerebbe flooding e impedirebbe scalabilitÃ  e crescita dinamica che Ã¨ classica della rete\nSe i milioni di calcolatori oggi connessi a Internet fossero tutti organizzati secondo i protocolli e gli schemi visti finora per le reti locali, la comunicazione tra due calcolatori su Internet richiederebbe di passare per migliaia di calcolatori intermedi, switch, bridge, segmenti di rete, ognuno dei quali aggiungerebbe ritardi di gestione, complessitÃ , rischi di errore. Il problema dellâ€™instradamento dei frame (routing), ovvero il decidere da che parte o su che segmento deve essere inoltrato un frame per raggiungere il destinatario finale, richiederebbe in ogni dispositivo una lista completa (tabella di instradamento) di tutti gli indirizzi MAC dei dispositivi nel mondo, con a fianco lâ€™indicazione della direzione di inoltro. Ovviamente questo limiterebbe in modo critico la scalabilitÃ  e la crescita di Internet. Inoltre causerebbe flooding perchÃ© praticamente ogni pacchetto di ogni computer rete di internet dovrebbe passare da ogni computer.\nUna soluzione semplice consiste nellâ€™elezione di un rappresentante per ogni rete locale X (e indichiamo con la rete sotto di essa come dominio di rete locale) (il router di X), incaricato di ricevere tutti i pacchetti dati destinati a uno dei calcolatori della rete locale (es. mac1 di X, mac2 di X, ecc.). Ricevuti i pacchetti destinati alla rete locale, il router potrebbe occuparsi di recapitare alla rete locale i pacchetti, come se si trattasse di un frame a livello MAC/LLC destinato allâ€™indirizzo MAC del destinatario. Allo stesso modo, ogni router dovrebbe farsi carico di inoltrare tutti i pacchetti uscenti dalla propria rete locale, verso i router delle reti di destinazione. Per rispettare le direttive dettate dallo standard ISO/OSI, il livello di indirizzamento e la gestione dellâ€™instradamento dei pacchetti tra i router vengono gestiti al terzo livello (rete) della gerarchia dei protocolli di Internet.\nPer ciÃ² che riguarda i router, tuttavia, lo scambio diretto tra router di pacchetti destinati alle rispettive reti locali potrebbe ridurre molto la complessitÃ  dellâ€™instradamento. I router comunicano quindi attraverso collegamenti dati molto veloci, dette dorsali (backbone). Ogni router deve ricordare in una tabella di instradamento (forwarding table) solo quale sia il primo router intermedio per raggiungere ogni altro router. La visione del sistema al terzo livello (Rete) da parte dei router Ã¨ quindi simile alla visione che appare a destra nella figura. Si nota come tutti i dettagli delle reti locali siano di fatto nascosti dai router a questo livello.\nIl router deve avere una mappa fra gli indirizzi IP e i mac!\nObiettivi generali del livello (6) (!) ðŸŸ¥+ Sintassi\nStruttura gerarchica fra dominio e host (per facilitare lâ€™invio) Busta a livello arancione, terzo livello. Semantica\nFrammentazione dei dati Questa parte non Ã¨ piÃ¹ esistente per gli IPv6, perchÃ© Ã¨ un overhead in piÃ¹ che non si vuole dare ai router Si occupa solamente di inviare. Un motivo per cui succede Ã¨ lâ€™efficienza, tenere in memoria questa cosa Ã¨ molto costosa. I router devono solamente tritare pacchetti! Forwarding dei pacchetti, inoltramento dei pacchetti O ricezione del pacchetto se Ã¨ giusto. Non si occupa di affidabilitÃ  del trasporto (di cui si occupa il livello mac e trasporto) Hardware (operazionale credo)\nDispositivi fisici di questo livello, come i router (quindi tabelle di instradamento e protocollo di instradamento e aggiornamento) Protocollo di rete Slide1\nSlide2\nIn questa parte iniziamo ad analizzare il concetto di rete globale, ossia non Ã¨ piÃ¹ locale!\nIl livello rete di Internet si basa sul protocollo IP (Internet Protocol). Il protocollo IP definisce un nuovo schema di indirizzamento globale e gerarchico, che permette di identificare univocamente tutti i dispositivi di rete e allo stesso tempo la loro rete locale di appartenenza. Gli indirizzi usati permettono di identificare intere reti locali come un riferimento singolo nella gestione dellâ€™instradamento dei pacchetti. Questo fatto semplifica molto la visione della rete che appare al livello Rete. Al protocollo IP, si possono associare protocolli di instradamento dei pacchetti dal mittente al destinatario finale (forwarding), originando servizi di trasmissione a pacchetto di tipo connectionless. Il protocollo IP richiede lâ€™adozione di nuovi dispositivi amministratori dellâ€™inoltro dei pacchetti a livello Rete, detti router.\nRouter I router sono forniti di tabelle di instradamento che illustrano la topologia della rete vista al livello dei router stessi (quindi non Ã¨ necessario conoscere gli indirizzi dei calcolatori di una LAN al di fuori della LAN stessa. I router devono implementare protocolli di aggiornamento delle tabelle di instradamento (detti protocolli di routing). Ulteriore compito dei router Ã¨ la gestione della frammentazione dei dati da spedire nei pacchetti, e la creazione della busta di livello rete con gli indirizzi del router mittente e destinatario di ogni pacchetto inoltrato.\nSono improntate alla efficienza! Principalmente Ã¨ solo hardware che Ã¨ in grado di far arrivare e partire un pacchetto a ogni ciclo di clock.\nNon self-similar ðŸŸ© Si Ã¨ tentato di cercare di predire i dati futuri pensando a quanti dati ho ora. Ma si Ã¨ scoperto che non Ã¨ proprio possibile, perchÃ© ci sono dei burst di richieste, dipendenti dalle richieste delle singole applicazione, per questo motivo sembra che sia un sistema caotico (esempio della farfalla). Principalmente perchÃ© questo Ã¨ dipendente dai media (es. youtube).\nIndirizzo IP Gli indirizzi IP sono una nuova specie di indirizzi rispetto al MAC, necessari per il Protocollo omonimo;\nHeader IP ðŸŸ¨++ Slide del formato IP\nQuesto Ã¨ il bellissimo pacchetto di livello trasporto ðŸ™‚. NOTA: vedi che contiene il pacchetto dello stato superiore.\nVersion sono 4 bit per la versione. Dimensione dell\u0026rsquo;header in byte (che il campo options lo rendere variabile). Il campo Type of Service, o TOS, definisce il valore di prioritÃ , di cui abbiamo parlato Scheduling dei routers (3+) ðŸŸ©. Che Ã¨ principalmente utilizzato in internet due (basta un router che non lo sia e fa droppare le garanzie). (solitamente Ã¨ ignorato). 16 bit per la lunghezza, quindi al massimo posso mandare 65k nel payload. Lâ€™identificazion di 16 + cose bits Ã¨ per capire la targa, meglio per la frammentazione (quel sistema per spezzattare file lunghi e inviarli a pezzetti), sono ricomposti a destinazione, il router lo ignora ðŸ™‚, l\u0026rsquo;ultimo ha flag a 0, e offset piÃ¹ lungo Time to live Ã¨ una cosa che viene decrementata ad ogni router e viene dropatto il pacchetto se vado a 0 Upper layer Ã¨ il protocollo di livello 4 da utilizzare. Per verificare se non ci sono stati errori di trasmissione. (Che Ã¨ molto facile da manipolare, perÃ² buono per errori a caso di trasmissione). Alcune opzioni tipo la rotta da prendere (tipo i router da visitare), itmestamp, La cosa Ã¨ che questa parte Ã¨ variabile.\nC\u0026rsquo;Ã¨ un overhead di 40 bytes!.\nFrammentazione e Reassembly ðŸŸ© Per questa parte concetti importanti da comprendere sono:\nPerchÃ© si fa frammetnazione (MTU) e perchÃ© si riassembla solamente alla fine. Campi dellâ€™header IP utili alla frammentazione e perchÃ© vengono utilizzati. Non ha molto senso fare reassembly in mezzo, perchÃ© il pacchetto potrebbe fare una altra strada, sono indipendenti una volta spediti.\npoi si potrebbero fare fragmentation anche in un router intermedio, si potrebbero fare fragmentation ancora dopo! Frammentazione Ã¨ necessaria se il pacchetto Ã¨ piÃ¹ grande del MTU Maximum Transfer Unit.\nSlide esempio di fragmentazione\nStruttura IPv4 ðŸŸ© Un indirizzo IPv4 Ã¨ un valore espresso su 32 bit (4 Byte), e puÃ² essere espresso anche come sequenza di 4 valori decimali, separati da punto. Ogni valore decimale puÃ² essere compreso tra i valori 0 e 255. Un esempio di indirizzo IP valido Ã¨ (130.136.250.1).\nOgni indirizzo IP Ã¨ sempre composto da due parti:\nnumero della rete IP alla quale appartiene la scheda (network number), numero dellâ€™interfaccia di rete (host number) allâ€™interno della rete IP. Esistono dei numeri speciali per ogni rete:\nHost tutti 0 e tutti 1\nTutti 0 â†’ indica la rete stessa Tutti 1 â†’ indica lâ€™indirizzo di broadcast Datagramma IPv6 Slide IPv6\nIL nextheader dice il protocollo che sta sopra, stesso di upper level di sopra\nIl campo priority Ã¨ siile al Type of service, ci da la prioritÃ  del flusso di dati Flow label identifica il flusso di dati (infatti non câ€™Ã¨ la frammentazione), anche se non Ã¨ ben definito il concetto di flusso. Hop limit Ã¨ la stessa cosa del time to live. Flow label (questo Ã¨ molto importante!, se il flusso identifica una comunicazione, non ho bisogno di indirizzi sorgente, finale, porta etc., per questo motivo posso compattare le informazioni!) Struttura delle reti UnivocitÃ  e statico/dinamico ðŸŸ© Slide\nEsempio slide\nAttualmente usati si riferiscono al protocollo IP versione 4, (IPv4). Un indirizzo IP viene associato a una e una sola (univoca) interfaccia di rete (scheda di rete). Potrebbe essere contemporaneamente identificato da piÃ¹ di un indirizzo IP nel caso in cui ci siano piÃ¹ interfaccie di rete (e piÃ¹ MAC). Se lâ€™associazione univoca tra indirizzo MAC dellâ€™interfaccia di rete e lâ€™indirizzo IP rimane sempre lo stesso, allora si parla di IP statico. In caso contrario, se puÃ² cambiare lâ€™associazione MAC-IP a seconda di vari fattori, si parla di IP dinamico. (cambio da dove mi connetto!).\nQuando Ã¨ statico Ã¨ utile quando stiamo ad offrire dei servizi, cosÃ¬ non devo fare aggiornamenti, i computer sanno che strada devono fare per raggiungere un certo computer.\nClassi di rete ðŸŸ© Sono definite tre classi di reti IP, che si differenziano sulla base del numero massimo di host supportabili. Il valore dellâ€™indirizzo IP determina la classe della rete: A,B,C (vedere figura).\nLe reti di classe A sono al massimo 126 e ognuna puÃ² contenere fino a oltre 16 milioni di host. Per le reti di classe A, il byte di indirizzo piÃ¹ significativo (a sinistra) ha sempre il primo bit uguale a zero, e puÃ² assumere i valori da 1 a 126 (network number) rispetto ai 128 valori possibili. I tre byte rimanenti possono assumere oltre 16 milioni di combinazioni, ognuna associabile a un host della rete. 0XXXXXXX.xxxxxxxx.xxxxxxxx.xxxxxxxx\nUna nota particolare Ã¨ l\u0026rsquo;indirizzo 127 che Ã¨ un indirizzo di loopback perchÃ© fa finta di uscire, e poi allâ€™ultimo rientra. Questo indirizzo Ã¨ utile per testare protocolli di rete.\nLe reti di classe B sono al massimo 16.382 e ognuna puÃ² contenere fino a oltre 64.000 host. Per le reti di classe B, il network number Ã¨ dato dai due byte di indirizzo piÃ¹ significativi (a sinistra), che hanno sempre i primi due bit uguali alla coppia (uno,zero). I network number di classe B possono assumere i valori da 128.0. a 191.255. I due byte rimanenti (host number) possono assumere oltre 64.000 combinazioni, ognuna associabile a un host della rete.\nforma di 10XXXXXX.XXXXXXXX.xxxxxxxx.xxxxxxxx\nLe reti di classe C sono oltre 2 milioni, e ognuna puÃ² contenere fino a 254 host. Per le reti di classe C, i tre byte di indirizzo piÃ¹ significativi (a sinistra) rappresentano il network number, e hanno sempre i primi tre bit uguali alla terna (uno,uno,zero). I network number di classe C possono assumere i valori da 192.0.0 a 223.255.255. Il byte rimanente (host number) puÃ² assumere 254 combinazioni utili, su 256 possibili, ognuna associabile a un host della rete.\n110XXXXX.XXXXXXXX.XXXXXXXX.xxxxxxxx\nConvenzione lâ€™ultimo IP disponibile per lâ€™Host di solito Ã¨ dato al Router.\nSottoreti e netmask !!! (3) ðŸŸ© Slide\nLa figura mostra a sinistra uno schema gerarchico di strutturazione di una rete di classe B. A partire dallâ€™alto troviamo il router principale (default router) della rete 130.136, il cui indirizzo IP Ã¨ nellâ€™esempio 130.136.0.254. Alla rete 130.136 appartengono anche tre router subordinati, con IP 130.136.1.254, 130.136.2.254, 130.136.3.254 rispettivamente amministratori delle sottoreti (130.136.1.), (130.136.2.) e (130.136.3.).\nNetmask\nIl Netmask identifica nelle zone in cui Ã¨ settato 1 l\u0026rsquo;indirizzo di rete e sottorete, dove Ã¨ 0 lâ€™indirizzo di host. Quindi ci dice Ã¬l modo con cui si interpreta un byte di rete. Obbligatoriamente deve essere in questa forma ($1^n0^m: n + m = 32$ se vogliamo utilizzare una sintassi piÃ¹ famigliare da Linguaggi di programmazione).\nIl concetto di creare sottoreti si puÃ² riassumere in frazionare lâ€™host in altre due parti che rappresentano lâ€™indirizzo di sottorete e lâ€™host. Queste sono nuove componenti logiche.\nFacendo questa operazione abbiamo $nreti \\times(nhost - 1)$, mentre prima era $nhostgrosso$. Alla fine se si svolge questo calcolo sono stesso numero di host, (magari perdo nreti numero di host per i router, perÃ² la ho gerarchizzata meglio).\nEsiste una notazione molto piÃ¹ carina per i netmask che Ã¨ il CIDR (Classless Interdomain ROuting) in pratica stai dicendo quanti bit sono messi a 1\nCreazione sottoreti\nIn questo modo Ã¨ possibile creare una gerarchia di sottoreti, ognuna delle quali Ã¨ amministrata da un router (il default router). Esempio: data la rete di classe B 130.136. per semplicitÃ  decidiamo di considerare possibili 256 sottoreti: netmask 255.255.255.0.\nIl numero della sottorete Ã¨ quindi fornito dai primi tre byte dellâ€™indirizzo IP, es. 130.136.1. Ã¨ la sottorete 1, 130.136.2. Ã¨ la sottorete 2, mentre ad esempio 130.136.1.22 Ã¨ lâ€™host 22 della sottorete 1, 130.136.3.48 Ã¨ lâ€™host 48 della sottorete 3, e cosÃ¬ via. (quindi un router sottorete ora prende IP del genere 130.136.1.254, perchÃ© indica la sottorete 1 della rete di classe B che si possiede).\nPer istruire ogni router subordinato sulla dimensione e sullâ€™interpretazione degli indirizzi IP da amministrare, ogni router subordinato deve essere fornito di una maschera di rete (netmask), evidenziata a destra.\nElementi fondamentali per il Protocollo IP\nSenza questi tre elementi il protocollo IP non funziona proprio. Quindi Ã¨ la prima cosa da fare per configurarlo.\nMaschera di rete Indirizzo IP Indirizzo default di router (il primo router sopra la gerarchia, che Ã¨ a chi mandare quando non so a chi mandare). (puÃ² essere che con dispositivi stupidi abbiamo solamente lâ€™indirizzo del router). La maschera di rete serve per capire\nNetmask\nIn particolare rileviamo qui 2 funzionalitÃ  principali per questo netmask:\nDire quanti subnet esistono, oltre alla rete principale Far sapere allâ€™host a quale rete appartiene Ãˆ quindi una quantitÃ  fondamentale per configurare la regte\nClassless Inter Domain Routing ðŸŸ© Questo nuovo modo per fare netmask (nuovo rispetto gli anni 80) Ã¨ un modo per avere tagli di rete piÃ¹ efficienti, nel senso che se prima la C non bastava, ti davano una B( Renzone a unibo ha avuto in questo modo una classe B). Ora possono avere molta piÃ¹ disponibilitÃ  per i tagli negli indirizzi di rete. Questa cosa permette anche un concetto di supernetting. (in cui ho un insieme condiguo di classi piÃ¹ piccole, e cosÃ¬ mi creo una rete maggiore, piÃ¹ grosso delle classi, cosÃ¬ ho maggiore dinamicitÃ ).\nEsempio forwarding dei Pacchetti\nSlide\nSlide esempio\nLa figura mostra un esempio di instradamento su rete IP. Esistono tre router Ry, Rz e Rk rispettivamente amministratori delle reti (140.217.), (190.89.), e (130.136.). Il router Ry Ã¨ connesso a Rz, e Rz Ã¨ connesso a Rk. Tale informazione risulta dalle tabelle di instradamento di Ry, Rz, Rk. La rete del router Ry include due sottoreti (140.217.1.) e (140.217.2), amministrate dai rispettivi default router 140.217.1.254 e 140.217.2.254 . La rete del router Rk include tre sottoreti (130.136.1.), (130.136.2.) e (130.136.3.), amministrate dai rispettivi default router 130.136.1.254, 130.136.2.254 e 130.136.3.254 . Un pacchetto IP spedito dallâ€™host 140.217.2.10 allâ€™host 130.136.2.33 deve compiere il seguente tragitto: passa per il default router di sottorete 140.217.2.254 che, notando che il destinatario non appartiene alla sottorete, lo inoltra al default router del livello superiore di rete: 140.217.0.254. Il default router di rete controlla la propria tabella di forwarding e scopre che per raggiungere la destinazione il pacchetto deve essere inoltrato al router intermedio 190.89.0.254. Il router intermedio riceve il pacchetto, verifica la propria tabella di forwarding, scopre che il prossimo destinatario intermedio Ã¨ il router 130.136.0.254, al quale inoltra il pacchetto. Il router 130.136.2.254 riceve il pacchetto e verifica che appartiene alla propria rete, inoltrando quindi il pacchetto internamente. Il router di sottorete 130.136.2.254 riceve il pacchetto e scopre che appartiene alla propria sottorete, inoltrando il pacchetto internamente. Finalmente, lâ€™host 130.136.2.33 riceve il pacchetto a lui destinato. Si possono notare alcuni aspetti importanti: malgrado il numero elevato di host che potrebbero essere parte del sistema considerato, il processo di instradamento permane molto semplice, composto da piccole e semplici operazioni di base. Le tabelle di instradamento sono limitate agli elementi che agiscono allo stesso livello, e quindi l**â€™instradamento Ã¨ gerarchico**.\nRouting ðŸŸ¨ Si parlerÃ  molto meglio del routing in Data Plane e Control Plane\nSlide\nIl problema del routing puÃ² essere definito come il problema di mantenere lâ€™aggiornamento delle tabelle di forwarding in tutti i router della rete. Questo problema puÃ² essere a volte molto complesso, a causa di frequenti modifiche forzate dei cammini per i pacchetti in rete. Le cause di tali modifiche possono essere dovute a molti fattori, ad esempio: la mobilitÃ  degli host in reti senza fili, guasti di mezzi trasmissivi, interruzione delle linee, guasti di router, nuove politiche e accordi per lo scambio dei dati tra gestori di dorsali e sistemi autonomi.\nUn sistema autonomo (AS) Ã¨ sinonimo di una grossa rete, o una collezione di reti, soggetta a una comune politica di amministrazione. Gli accordi commerciali tra gestori di AS possono modificare i cammini consentiti per lo scambio dei pacchetti di dati. Per realizzare un parallelo intuitivo, gli AS si comportano come nazioni che permettano o meno il passaggio di pacchetti, analoghi a voli aerei, sul loro suolo nazionale. Ogni volta che si verifica uno dei problemi citati, esistono router che hanno indicazioni errate nelle loro tabelle di forwarding. Tutto ciÃ² puÃ² causare la perdita di pacchetti, oppure puÃ² determinare un disordine nellâ€™arrivo di pacchetti che hanno seguito strade diverse. Ecco quindi una causa del servizio connectionless ottenuto dal livello rete basato solo sul protocollo IP. I router hanno bisogno di aggiornare al piÃ¹ presto le loro tabelle, per evitare malfunzionamenti del servizio.\nIn pratica fanno lo stesso modo per decidere dove mandare, cioÃ¨ hanno lo stesso protocollo, ma dato che si trovano in parti diverse avranno poi tabelle di instradamento diverse.\nla Core network Ã¨ molto veloce nel trovare il percorso giusto (Ã¨ molto piÃ¹ fisso, e sa piÃ¹ o meno dove mandare le cose).\nI protocolli di routing hanno la funzione di richiedere e scambiare informazioni per trovare cammini alternativi (idealmente il cammino migliore tra le possibili alternative), tra mittenti e destinatari dei pacchetti, e consentire quindi lâ€™aggiornamento delle tabelle di forwarding. A puro titolo informativo, si citano alcune sigle di protocolli di routing adottati in Internet: Routing Information Protocol (RIP), Open Shortest Path First (OSPF), Border Gateway protocol (BGP). Questi algoritmi sono tutti utilizzati in locale. La cosa brutta Ã¨ che il cammino ottimo cambia nel tempo (anche nellâ€™ordine dei secondi), quindi gli algoritmi si devono abituare dinamicamente a questi nuovi dati.\nNote sistemi distribuiti o centralizzati\nIl centralizzato Ã¨ bello perchÃ© Ã¨ chiaro a chi chiedere per andare poi a mandare il pacchetto dove si vuole, il problema Ã¨ che se il nodo centrale fallisce, cade l\u0026rsquo;intera rete.\nDistribuito Ã¨ bello perchÃ© risolve il problema del single point of failure perÃ² dallâ€™altra parte ogni nodo non ha una visione globale quindi non puÃ² fare altro che andare a massimizzare localmente, che spesso non Ã¨ la cosa migliore.\nWikipedia sui sistemi autonomi\nLink, in pratica singola autoritÃ  amministrativa Ã¨ la parola chiave.\nProtocolli basati su IP Protocollo ICMP (6) ðŸŸ¨+ Slide\nICMP (Internet Control Message Protocol) Ã¨ un protocollo standard definito per supportare i messaggi di controllo per la gestione della rete al livello 3. ICMP viene usato da semplici host, da router e persino da gateway (router speciali con ulteriori funzioni) per scambiare informazioni utili alla gestione del livello Rete. Le informazioni scambiate sono trasferite sotto forma di pacchetti IP. Utile per stabilire una sintomatologia dei problemi di reti.\nAlcuni esempi di messaggi ICMP che possono essere scambiati indicano, ad esempio:\nsituazioni di rete di destinazione irraggiungibile (possibile sintomo di problemi di routing, o di rottura di un router). In questo caso puÃ² convenire andare a cercare il problema di rete, che puÃ² essere fisico, e fixarlo in questo modo rete di destinazione sconosciuta (possibile sintomo di indirizzo IP di rete male specificato) In questo caso il router non sa a chi mandare, quindi alcuni fix sono 1. aggiornare tabelle di instradamento, o provare altre strade. Ossia nessuno conosce lâ€™indirizzo della rete locale host di destinazione non raggiungibile (possibile sintomo che lâ€™host sia spento o il cavo di connessione sia male collegato). Questo Ã¨ un problema che non ci riguarda, quindi probabile che lâ€™host si sia sconesso. Per questo significa che la rete Ã¨ conosciuta!, quindi problema di rete locale!. host di destinazione sconosciuto (possibile sintomo di host number delâ€™indirizzo IP male specificato, malgrado la rete indicata esista e sia raggiungibile). problemi con indirizzo IP protocollo richiesto non disponibile (sintomo di un tentativo di dialogo tra dispositivi male configurati, che non forniscono i servizi richiesti). (come se stessi provando ad accedere a un servizio in una porta sbagliata, o versione IP sbagliata o simili). ricerca di cammino alternativo (puÃ² essere usato per risolvere i problemi di routing). Anche chi riceve il messaggio, puÃ² rispondere in modo preinpostato a quelle richieste. (e dato che Ã¨ preimpostato non c\u0026rsquo;Ã¨ bisogno di avere un frame grosso!).\nApplicazioni su ICMP (2) ðŸŸ© Slide\nLe applicazioni sono utilizzate solitamente per la verifica delle cause o del semplice sospetto di problemi di rete. Lâ€™applicazione PING permette di testare la connessione tra due host: eseguendo il comando â€œping \u0026lt;indirizzo IP di host2â€ da un host1 qualsiasi (mittente) connesso in rete, lâ€™applicazione invia una richiesta ICMP di eco, alla quale lâ€™host2 indicato risponde con una risposta ICMP (eco della richiesta). Dopo lâ€™invio della richiesta, host1 fa partire un timer. In caso di successo, viene calcolato il tempo di andata e ritorno dei pacchetti (durata o Round Trip Time, RTT), mentre in caso di insuccesso viene indicato che il timer per la richiesta inviata Ã¨ scaduto senza ottenere risposta (secondo esempio della prima figura). Al termine dei tentativi, viene mostrato un elenco di statistiche sul numero di richieste andate a buon fine e i tempi medi stimati di andata e ritorno dei pacchetti.\nLâ€™applicazione Traceroute (tracert) permette di verificare la lista di tutti i router attraversati da una richiesta ICMP inviata da host1 a host2. Il comando â€œtracert â€ eseguito da host1, causa lâ€™invio di una sequenza di richieste ICMP verso host2, per le quali viene fissato il numero massimo di router da attraversare (numero di passaggi o tempo di vita, TTL), a valori crescenti da 1 in poi. Ogni router a distanza TTL risponde con un messaggio ICMP di errore (tempo di vita scaduto) attraverso il quale Ã¨ possibile risalire al suo indirizzo IP (ognuno mostrato su righe successive).\nProtocollo ARP e RARP ðŸŸ© Slide\nSlide immagine\nIl protocollo Address Resolution Protocol (ARP) aiuta a gestire lâ€™associazione tra indirizzo IP di un dispositivo a livello rete e il suo indirizzo MAC a livello MAC/LLC . Quando un router riceve un pacchetto a livello IP destinato alla sua sottorete (es. 130.136.2.33) esso verifica se a tale IP risulti o meno associato un indirizzo MAC. In caso contrario, il router spedisce sui segmenti della rete locale un frame in broadcast (cioÃ¨ ricevuto da tutti i dispositivi) contenente il codice di richiesta ARP, e lâ€™indirizzo IP del destinatario del pacchetto. Tutti i riceventi vanno a confrontare, e se matcha risponde.\nIntuiviamente\nTale frame equivale quindi al rivolgere a tutti i dispositivi la domanda: â€œquale indirizzo MAC ha il dispositivo corrispondente al seguente indirizzo IPâ€? Il dispositivo in questione, se esiste, risponde con un frame indirizzato allâ€™indirizzo MAC del router, contenente il codice di risposta ARP, e con allegato lâ€™indirizzo MAC richiesto. A questo punto il router puÃ² quindi preparare e spedire la busta di livello MAC/LLC, indirizzata al MAC del dispositivo destinatario del pacchetto IP, contenente il pacchetto IP incapsulato allâ€™interno. Il destinatario riceve il frame e risponde con il frame di conferma per il sottolivello LLC.\nQuando Ã¨ risposto possiamo andare a mappare lâ€™IP con il MAC locale. Chi ha il MAC corrispondente puÃ² rispondere col proprio IP.\nEsiste anche una versione analoga del protocollo ARP, detta Reverse-ARP, che risponde alla domanda: â€œquale indirizzo IP corrisponde al dispositivo con questo indirizzo MACâ€?. PuÃ² essere utile ad esempio se mi arriva un pacchetto a un IP nella mia sottorete, ma non so a quale host Ã¨ destinato.\nProtocolo DHCP ðŸŸ©- Slide\nSlide di immagine\nQuesto protocollo Ã¨ utilizzato per assegnare un IP in modo dinamico. porta 67, unico all\u0026rsquo;interno della rete, chi non ha un servizio lÃ¬ aperto droppa il messaggio.\nIntroduzione: assegnazione IP\nI numeri di rete delle classi A, B e C, ovvero la parte sinistra degli indirizzi IP vengono assegnati da enti internazionali quali RIPE, ICANN, ARIN, APNIC a enti, aziende, consorzi e imprese che ne fanno richiesta motivata. Un problema molto piÃ¹ pratico riguarda il modo in cui un nuovo dispositivo che venga connesso a una rete esistente, veda associare al proprio indirizzo MAC un indirizzo IP della rete stessa. Il numero di rete o di sottorete viene automaticamente determinato dallâ€™appartenenza alla rete, ovvero alla presenza al di sotto del dominio di gestione di un router.\nSoluzioni La prima, ovvia alternativa (molto usata) Ã¨ quella di avere un amministratore di rete che assegna manualmente uno dei numeri di host disponibili al nuovo indirizzo MAC. In questo modo lâ€™associazione indirizzo MAC e indirizzo IP puÃ² essere mantenuta per un tempo indeterminato, e quindi si considera lâ€™indirizzo IP come statico.\nLa seconda alternativa, molto usata in reti senza fili, in reti locali e nei collegamenti domestici a Internet Service Provider (ISP) via Modem o ADSL consiste nellâ€™utilizzare un server per Dynamic Host Configuration Protocol (DHCP). Il server DHCP Ã¨ dotato di una lista di numeri di host liberi per la sottorete amministrata, che provvede ad associare su richiesta agli indirizzi MAC dei dispositivi che lo richiedono. Tale associazione dipende spesso dalla disponibilitÃ  degli indirizzi giÃ  assegnati in precedenza, quindi allo stesso indirizzo MAC possono essere associati di volta in volta indirizzi IP diversi, e si parla in questo caso di indirizzi IP dinamici. Eâ€™ possibile configurare attraverso DHCP anche altri parametri di rete, come la maschera di rete, il defaul router e il server DNS (che vedremo dopo). Il servizio DHCP equivale spesso al concetto di rete â€œplug and playâ€, ovvero rete in cui basta connettere il dispositivo al medium e non câ€™Ã¨ bisogno di nessuna configurazione manuale aggiuntiva. Ãˆ questo Ã¨ quasi un must per le reti wireless! Sarebbe improponibile che ci fosse un sistemista ad assegnare un indirizzo IP per ogni dispositivo che si connette!\nIn breve:\nHost che assegna IP a chi lo richiede Gestione degli IP liberi e associazione ai MAC Questa Ã¨ chiaramente una forma di indirizzamento dinamico discusso in UnivocitÃ  e statico/dinamico ðŸŸ© Ogni tot di tempo Ã¨ fatto un ping se la macchina risponde Ã¨ ancora lÃ¬, altrimenti libera lâ€™IP.\nMAGGIORE DETTAGLIO 4passi\nSlides\nÃˆ importante avere 4 passi, perchÃ© lâ€™HOST deve rispondere con la scelta del DHCP, nel caso in una sottorete ci siano molto DHCP.\nma Non esiste nessuna autenticazione, quindi Ã¨ molto fragile ad attacchi (uno si potrebbe impersonare a DHCP senza problemi). I primi due passaggi sono facoltativi, ma lo rendono piÃ¹ solido contro possibilitÃ  di avere 2 DHCP server.\nNOTA: comuqnue non Ã¨ un protocollo per dare IP a dispositivi mobili che si spostino.\nIPv6 e tunnelling ðŸŸ© Slide\nhttps://www.notion.so\nImmagine\nNella figura viene mostrato come sia possibile spedire pacchetti IPv6 tra due router IPv6 passando per cammini che includono router IPv4, attraverso il tunnelling IPv6 in IPv4. Il pacchetto IPv6 viene incapsulato dai ogni router IPv4 in pacchetti IPv4, in modo da poter essere instradato lungo la rete di router IPv4. Uscito dal tunnel IPv4 il pacchetto IPv6 prosegue il suo inoltro fino alla destinazione IPv6 finale.\nIl motivo principale della necessitÃ  di IPv6 Ã¨ la necessitÃ  di altri indirizzi IP. IPv6 perchÃ© hanno tentato di fare un IPv5 in molti modi ma sono caduti in disuso.\nNon c\u0026rsquo;Ã¨ frammentazione, con IPv6, mentre IPv4 ha bisognoâ€¦ questo toglie il lavoro del router, e quindi rende tutto piÃ¹ veloce.\nDal 1990 Ã¨ stato avviato un progetto di definizione e sviluppo di una nuova versione del protocollo IPv4, denominato versione IPv6. In seguito allâ€™esplosione del collegamento di calcolatori in rete, e quindi dellâ€™utilizzo di indirizzi e reti IP, le proiezioni mostrano che al ritmo attuale gli indirizzi IPv4 saranno esauriti nel decennio 2008-2018. Brevemente, le caratteristiche salienti di IPv6 vanno nella direzione di ovviare a questo problema, oltre a migliorare alcuni aspetti di IPv4. La caratteristica fondamentale di IPv6 Ã¨ la definizione di nuovi indirizzi IPv6 composti da 128 bit (16 byte), cioÃ¨ ben quattro volte la dimensione degli indirizzi IPv4. Questo incredibile numero di indirizzi potrebbe consentire di avere circa 15000 indirizzi IPv6 per dispositivi diversi su ogni metro quadrato di superficie dellâ€™intero pianeta, oceani inclusi.\nSono inoltre stati ridefiniti i campi che costituiscono la busta dei pacchetti di livello IPv4, aggiungendo ad esempio parametri per la gestione di flussi di pacchetti IP con diversi livelli di prioritÃ . Purtroppo la definizione di IPv6 nella maggioranza dei casi non permette di continuare a usare i vecchi router IPv4, e quindi non Ã¨ compatibile con lâ€™attuale struttura di Internet.\nTunnelling\nIl tunnelling Ã¨ fondamentale per la compatibilitÃ  fra IPV4 e IPv6\nLa sperimentazione e lo sviluppo di IPv6 sta procedendo su reti IPv6 separate, che possono in certi casi integrarsi alle reti IPv4 usando la tecnica del tunnelling dei pacchetti IPv6 in IPv4. Quindi wrappo con un pacchetto IPv4 i router che capiscono solo IPv4.\nSi chiama tunnelling perchÃ© il wrap ci assomiglia tanto!\nNAT Cose vecchie Confronto col MAC L\u0026rsquo;indirizzo Internet Protocol Ã¨ il protocollo internet a livello 3 piÃ¹ utile per la comunicazione fra reti locali diverse. Una delle caratteristiche che la contraddistingue dal MAC Ã¨ il fatto che sia gerarchico, ossia c\u0026rsquo;Ã¨ una sorta di indirizzo generale, indirizzo specifico e indirizzo della rete locale!. Oltre al fatto che Ã¨ gerarchico non Ã¨ univoco, perchÃ© puÃ² succedere molto spesso che viene riassegnato.\nCaratteristiche IP (3) Globale perchÃ© non esiste rete connessa ad Internet che non abbia indirizzo IP; Strutturato perchÃ© Ã¨ diviso in due parti, una per lâ€™indirizzo della rete locale e lâ€™altro per lâ€™indirizzo della scheda di rete interna alla rete locale; Gerarchico perchÃ© appunto le due parti di indirizzo sono in ordine gerarchico (rete locale \u0026gt; scheda di rete). Indirizzamento IP Se succede che due IP sono uguali, questo succede solamente a rete locale perchÃ© anche la prima parte dellâ€™IP deve essere uguale, quindi se ne accorge il Router e risolve questo.\nStaticitÃ  e dinamicitÃ \nStatico â†’ IP associato a MAC\nDinamico â†’ IP che cambia, quindi Ã¨ piÃ¹ difficile\nClassi di rete Dividiamo lâ€™IP in 3 classi principali A, B, C a seconda di quanti IP riescono a supportare\nClasse A\nIl bit piÃ¹ significativo Ã¨ 0. Quindi la prima sezione va da 1 a 126, perchÃ© 0 Ã¨ utilizzato per lâ€™identificazione. Sono quelle piÃ¹ prezione perchÃ© possono avere piÃ¹ host ($2^{24}$ host).\nClasse B\nHanno i primi due bit come valore 10. e vanno da 128 a 191,\nClasse C\nRouter I router ricevono pacchetti e guardano la parte di rete locale, se matcha Ã¨ OK, viene inoltrato ad altri router della rete locale per smistare ulteriormente, altrimenti inoltra ad altri router in altre reti, attraverso i collegamenti chiamati dorsali.\nTabelle e protocollo di instradamento Queste sono tabelle che hanno un utilizzo molto simile a quanto utilizzato per lo switch, che mappa una porta a un indirizzo MAC. In questo caso mappa la tolopogia di rete (che non so in che modo sia intesa questa mappa). Di solito il router Ã¨ collegato a un solo altro router che viene chiamato default gateway.\nIl protocollo, invece, si occupa di aggiornare questa tabella secondo le occorrenza (TODO, non so su quali regole).\nProtocollo di routing Questo protocollo che si occupa di trovare il percorso piÃ¹ breve, e di frammentare il messaggio originale in pacchetti piÃ¹ piccoli, ma senza fare controlli su un arrivo corretto di queste informazioni. Quind fa una scelta per capire che strada fare\nCIDR Classless Inter Domain Routing Si utilizza una scrittura molto compatta per\n","permalink":"https://flecart.github.io/notes/livello-di-rete/","summary":"Ripasso Prox: 50 Ripasso: June 14, 2023 Ultima modifica: May 13, 2023 11:59 PM Primo Abbozzo: October 12, 2022 9:50 AM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ— Studi Personali: No\nReti di Reti Le parti importanti per questo sono Data Plane e Control Plane (che ha saltato quasi tutto, ma almeno dijkstra lo dovresti fare bene)\nIntroduzione (puoi skippare ðŸŸ©) La puoi skipppare perchÃ© tratta in modo molto generare parti che saranno trattati in modo piÃ¹ approfondito in seguito.","title":"Livello di Rete"},{"content":"Ultima modifica: June 21, 2023 9:07 PM Primo Abbozzo: June 17, 2023 11:59 PM Studi Personali: No\nURI Cosa sono? Per cosa vengono utilizzati? Che differenza c\u0026rsquo;Ã¨ fra URL e URN? sintassi dellâ€™URI Alcuni esempi di schema (e relativo utilizzo e sintassi per lâ€™URI) IRI e IDN, cosa sono? Cosa sono i CURIE? Cosa Ã¨ URL Ref e come viene risolto Cosa Ã¨ uri resolution, e cosa uri dereference? Cosa Ã¨ LOD? Cosa Ã¨ managed route? e filesystem route? Character and content encoding Character Quali sono le codifiche maggiormente utilizzate? Cosa sono ZWNBSP e BOM? Cosa sono Carriage Return Line Feed, PerchÃ© ci sono Delete e Canc? Quali sono le differenze principali fra UTF 8 e latin 1? Cosa sono utf 8, 16, e 32? Cosa Ã¨ UCS? PerchÃ© si fa differenza fra ucs 2 e 4? Cosa sono i piani? E i gruppi in UCS? Quali sono le difficoltÃ  maggiori per creare un encoding riguardanti un ampio spettro di linguaggi. Esistono alcuni principi per la creazione di encoding, per esempio continuitÃ , ordine e raggruppamento. Spiegarli. Cosa sono i codici di controllo? Cosa sono i caratteri shift? in UTF-8? Quanti caratteri necessari sono per encodare caratteri latini, antichi, cinesi, o greci, accentati? Content Cosa Ã¨ il content encoding? PerchÃ© Ã¨ necessario? Cosa Ã¨ il protocollo SMTP? PerchÃ© Ã¨ importante in questo contesto? Quali sono le limitazioni principali per SMTP? PerchÃ© Ã¨ importante conoscere queste limitazioni? Cosa Ã¨ il MIME? in che modo vado oltre le limitazioni del SMTP in questo modo? Quali sono i due headers che MIME ha introdotto? cosa sono base64 e quoted printable? PerchÃ© ne parliamo nel contesto dei MIME? CSS Introduzione 1ï¸âƒ£ Cosa Ã¨ la tipografia? 0ï¸âƒ£ Fare una breve storia della tipografia. 2ï¸âƒ£ Cosa Ã¨ un font famili e un type face? 0ï¸âƒ£ Un esempio di classificazione di fonts. Quali sono alcune cattive pratiche sui blocchi? Qual Ã¨ la differenza fra spazi di colore additivi e sottrattivi? Un esempio reale di questi colori? CSS C\u0026rsquo;Ã¨ molto poco di teorico in questa parte, come per HTML direi di saltarlo.\nJavascript Su ajax quali sono gli stati di ajax principali? Come si fa una richiesta ajax? PerchÃ© si Ã¨ introdotto ajax? quali sono i vantaggi principalli di questa tecnologia? PerchÃ© Ã¨ stata soppiantata, perchÃ© non si utilizza piÃ¹? Sintassi avanzata Questa parte Ã¨ importante perchÃ© la puÃ² chiedere nellâ€™esame nuovo (cioÃ¨ leggere e comprendere delle cose astruse di javascript).\ndifferenza fra function expression e function statement. Quali sono i valori falsy e truthy in js? Fai proprio lâ€™elenco. (che brutto linguaggio) cosa Ã¨ il this in javascript? Cosa Ã¨ una IIFE? In che modo si possono creare oggetti in variabile privata in ecmascript 2015? https://www.fabiovitali.it/TW/2023/UmmaGramma/ Altro Cookies e JWT In che modo i cookies differiscono rispetto al JWT? PerchÃ© cookie opachi? Quali sono i 3 schema di autenticazione piÃ¹ comuni? Come funzionano? HTTP Quando si dice che un metodo HTTP Ã¨ safe? Quando Ã¨ idempotente? Fare esempi. Cosa sono method e action in un form? Cosa sono e qual Ã¨ la differenza fra pipelining e multiplexing? Che vantaggio c\u0026rsquo;Ã¨ ad utilizzare queste? ando Ã¨ idempotente? Fare esempi. Cosa sono method e action in un form? Cosa sono e qual Ã¨ la differenza fra pipelining e multiplexing? Che vantaggio c\u0026rsquo;Ã¨ ad utilizzare queste? ","permalink":"https://flecart.github.io/notes/preparazione-esame/","summary":"Ultima modifica: June 21, 2023 9:07 PM Primo Abbozzo: June 17, 2023 11:59 PM Studi Personali: No\nURI Cosa sono? Per cosa vengono utilizzati? Che differenza c\u0026rsquo;Ã¨ fra URL e URN? sintassi dellâ€™URI Alcuni esempi di schema (e relativo utilizzo e sintassi per lâ€™URI) IRI e IDN, cosa sono? Cosa sono i CURIE? Cosa Ã¨ URL Ref e come viene risolto Cosa Ã¨ uri resolution, e cosa uri dereference? Cosa Ã¨ LOD?","title":"Preparazione Esame"},{"content":"Ripasso Prox: 10 Ripasso: May 21, 2023 Ultima modifica: May 14, 2023 5:18 PM Primo Abbozzo: April 12, 2023 3:02 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Tecnologia Wireless Introduzione Spettro del wireless networks (skip) Slide spettro Wirelesss networks\nQuesto solamente la classica differenziazione fra radio, visibile, raggi x raggi gamma etcetera.\nSe andiamo a guardare le onde radio, quelle che ci interessano, se ho frequenza alta ho densitÃ  di frequenza alta, se ho frequenza bassa ho alta capacitÃ  di suparamento di ostacoli.\nISM Ã¨ una banda da 2 a 5.0 GHz e c\u0026rsquo;Ã¨ tutto il WiFi, bluetooth. (anche wifi a 5 ghz.\nGSM prima rete cellulare a 900, poi 1800 nella seconda versione.\nDivisione statica delle frequenze\nAvre una frequenza comprata Ã¨ una miniera d\u0026rsquo;oro, attualmente il prof sta facendo della ricerca su come andare a\nTrasmissione via wireless : bandwidth (!) ðŸŸ© Slide bandwidth\nSolitamente Ã¨ una ampiezza di frequenza ossia quando Ã¨ grande un insieme di frequenza (questa Ã¨ anche la definizione formale da utilizzare). PerÃ² Ã¨ erroneamente utilizzata anche per descrivere il numero di bits trasmessi (che Ã¨ il bitrate nominale), Ã¨ un errore voluto perchÃ© solitamente se hai una bandwidth maggiore riesci a trasmettere piÃ¹ dati.\nNotare che la velocitÃ  del segnale Ã¨ sempre la stessa che Ã¨ quella della radiofrquenza (quella della luce), Ã¨ solamente l\u0026rsquo;alternarsi di quelle scatolette di colore diverso (codifica diversa).\nSe il segnale Ã¨ piÃ¹ lungo allora Ã¨ piÃ¹ facile andare ad interpretare se Ã¨ uno 0 oppure Ã¨ uno 1, diciamo che c\u0026rsquo;Ã¨ il tradeoff sulla reliability del segnale credo, anche se Ã¨ principalmente limitato dalla capacitÃ  del ricevente\ndef: connettivitÃ  di link ðŸŸ© Slides connettivitÃ \nIl primo Ã¨ una partizione, poi unidirezionali e bidirezionali.\nNota: solamente sui link direzionali possiamo andare a definire un link simmetrico o asimmetrico.\nLe parole principali sono:\nUnidirezionale Bidirezionale Partizione. Tipologie di wireless Slide introduzione alle tecnologie wireless\nNarrowband system ðŸŸ© Slide narrowband system\nÃˆ un frequenza molto piccola in cui si puÃ² comunicare (statica diciamo).\nProblemi di privacy perchÃ© mi posso connettere alla frequenza e ascoltare quanto viene mandato. Problemi di interferenza se voglio comunicare su questa frequenza con canali diversi Frequency Hopping ðŸŸ© Slide frequency hopping\nPossiamo utilizzare pseudogeneratori per andare a saltare in modo pseudorandom in spettri di frequenza diversi.\nAbbiamo bisogno di una sincronizzazione di questi salti, quindi un clock comune sarebbe molto comodo. (perÃ² dellâ€™hardware per filtri per quelle frequenze ci dovrebbe essere).\nQuesto era soprattuttto un modo per trasmettere nel tentativo di non essere ascoltati. In questo senso di hop, Ã¨ protetto by design.\nCURIOSITA: inventata da una attrice di hollywood, Hedy Lamarr (perchÃ© il suo canto andava fuori sinc lol) donato poi senza brevetto per salvare i soldati americani.\nDirect sequence spread spectrum ðŸŸ¨ Ne parliamo un pÃ² meglio in Modulazione wireless\nSlide direct sequence spread spectrum\nOssia mando il segnale encodato su tutto lo spettro con un chipping code. E qui si puÃ² riutilizzare la metafora del vagone e del treno, nel senso che se Ã¨ lungo allora riconosco meglio il valore del bit encodato con quella forma.\nIn un certo senso Ã¨ anche sicura rispetto al narrowband, perchÃ© devi conoscere il pattern del chip code per poterlo decodificare correttamente. (vari interlocutori avrebbero un codice non correlata fra di loro, cioÃ¨ la comunciazione sovrapposta sembra una interferenza casuale) Questo ci permette di riestrarre da molte comunicazioni la nostra comunicazione iniziale.\nIn breve sembra che questa forma di trasmissione sia quella piÃ¹ affidabile per errori (anche la natura in modo naturale puÃ² dare interferenze)\nNote sulle generazioni (skip) 1G era solamente come codifica della voce, la differenza principale con la 2G Ã¨ con la digitalizzazione, con 2G possiamo trasmettere megabytes, perÃ² era pagato per la durata di trasmissione (era telefonare per trasmettere bits lol, perÃ² era lenta, quindi pagava tanto, questa parte l\u0026rsquo;abbiamo accennata in Introduzione a reti, dato che la banda era occupata per tempo).\nCon 2.5G andiamo a sfruttare il tempo libero delle altre comunicazioni, ecco la differenza fra commutazione a pacchetto rispetto a commutazione a circuito\n3G era bono 1Mbit si pensava risolveva tutto.\nInfrastruttura wifi Struttura WWAN WMAN ðŸŸ¨- C\u0026rsquo;Ã¨ il problema di scoprire access points, e connettersi ai access point e anche predire il movimento delle persone per prevenire il collegamento alla rete.\nUn altro problema Ã¨ tipo il cambio dellâ€™indirizzo IP ad ogni cambio di rete connettendoci ad access point diverso, per questo motivo si utilizza una forma mobile di IPv4 per mantenere lo stesso IP (se cambiasse sempre allora non potrei sostenere video o simili quando mi sposto).\nGeostazionario: che gira insieme alla terra, quindi lâ€™abbiamo costantemente sopra la nostra testa questo satellite.\nWLAN Queste sono delle reti ad hoc peer to peer, senza infrastruttura, sono solamente dei nodi che si trovano nella stessa stanza!\nNon abbiamo costi di gestione e manutenzione se siamo senza infrastruttura e possiamo comunicare localmente senza problemi\nBridges with wires Solitamente potremmo avere un access point che sia dual stack con due interfacci una che va in wireless, lâ€™altra in wire, a livello 3 posso fare delle bridging functions,\nSvantaggi wireless ðŸŸ¨â€” Location tracking Ã¨ la cosa di piÃ¹ rilievo riguardo a questo, e anche la cosa piÃ¹ figa perchÃ© lâ€™informazione per trackare le persone ci sarebbe ðŸ˜€\nMultiplexing wireless Slide multiplexing\nDa cui vediamo che abbiamo 4 modi per fare multiplexing dello stesso segnale\nCodice Frequenza del sengale Tempo (non credo abbiamo molto controllo suq uesto lol) E spazio Vogliamo rendere non ambiguo la trasmissione, piÃ¹ dispositivi che utilizzino la stessa risorsa (mezzo di trasmissione di RF diciamo).\nFrequency ðŸŸ© Slide frequenza\nLe energie di canali diversi dovrebbero essere separate, se comunque si vada ad invadere, il filtro dovrebbe essere sufficiente per ignorare gli altri canali, oppure possiamo separare di piÃ¹ le frequenze, questi spazi vuoti sono spazi di guardia\nUn altro lato negativo Ã¨ che il canale Ã¨ occupato, quindi quando c\u0026rsquo;Ã¨ una asimmetria rispetto al modo in cui Ã¨ occupato, allora c\u0026rsquo;Ã¨ uno spreco.\nTime multiplexing ðŸŸ© Slide time multiplex\nSi va in round robin in pratica, câ€™Ã¨ uno spazio di guardia nel tempo. Che Ã¨ uno spreco.\ne câ€™Ã¨ bisongo di sincronizzazione tra i mezzi trasmissivi molto forte. Il vantaggio principale Ã¨ che posso fare una trasmissione molto densa. (va diciamo a burst, quindi anche questo Ã¨ uno svantaggio).\nTime and frequency multiplexing ðŸŸ© Slide time and frequency\nViene utilizzato in GSM wifi. (Ã¨ il provider che fornisce per ogni collegamento il seme per la gene), anche per quesot motivo era una comunicazione per tempo. (pagare telefonate per comunicare 9600 bit al secondo avevano di bitrate, costava molto).\nServe coordinamento preciso:\nMappa dei salti deve essere conosciuto Doppio spazio di guardia, sia per tempo sia per frequenze. (quindi anche qui utilizziamo molto spreco! Code multiplexing ðŸŸ© La magia del CDMA in Modulazione wireless\nSlide code multiplexing\nQuesto sembra molto antiintuitivo, come facciamo ad utilizzare lo stesso canale per comunicare informazioni differenti?\nUtilizzo un codice che mi permette di riestrarre! Che figa la cosa che si puÃ² riestrarre dal caos.\nbandwidth efficient ossia maggior bitrate con la minore banda. dal punto di vista dellâ€™user Ã¨ piÃ¹ lento (singolarmente piÃ¹ lento, ma complessivamente di maggiore utilizzo). Un pÃ² di computazione in piÃ¹ per ricevere e mandare. Space multiplexing ðŸŸ©- Slide space multiplexing\nOssia posizioniamo le nostre antenne in zone differenti. (abbiamo tipo tiling problem) (5G prova a ridurre al minimo lâ€™area del segnale)\n","permalink":"https://flecart.github.io/notes/tecnologia-wireless/","summary":"Ripasso Prox: 10 Ripasso: May 21, 2023 Ultima modifica: May 14, 2023 5:18 PM Primo Abbozzo: April 12, 2023 3:02 PM Stato: ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ•ðŸŒ‘ Studi Personali: No\nElementi di ripasso Tecnologia Wireless Introduzione Spettro del wireless networks (skip) Slide spettro Wirelesss networks\nQuesto solamente la classica differenziazione fra radio, visibile, raggi x raggi gamma etcetera.\nSe andiamo a guardare le onde radio, quelle che ci interessano, se ho frequenza alta ho densitÃ  di frequenza alta, se ho frequenza bassa ho alta capacitÃ  di suparamento di ostacoli.","title":"Tecnologia Wireless"},{"content":"Ripasso Prox: 21 Ripasso: January 1, 2023 Ultima modifica: January 2, 2023 10:49 AM Primo Abbozzo: October 26, 2022 4:45 PM Stato: ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Interpolazione Vogliamo in questa sezione andare ad indagare la costruzione di funzioni che passano in tutti i punti che vogliamo, appunto interpolare. La funzione Ã¨ molto simile alla regressione trattata in Minimi quadrati (con il metodo della regressione, chiamato anche approssimazione ai minimi quadrati).\nQuindi mentre la precedente voleva andare a minimizzare l\u0026rsquo;errore, questo attuale va a creare proprio da 0 la funzione che ci passa sempre.\nIntroduzione Andremo a creare una funzione f tale che per ogni x in input si abbia esattamente la y in output\nMetodi di interpolazione (3) ðŸŸ© In questo corso utilizzeremo solmanete l\u0026rsquo;interpolatore polinomiale!\nInterpolazione polinomiale Enunciato e unicitÃ  ðŸŸ© Enunciato Da notare che il grado della funzione Ã¨ esattamente il numero delle y.\nDimostrazione dellâ€™unicitÃ  Polinomi di Lagrange e costruzione ðŸŸ© Costruzione del polinomio di interpolazione In soldoni, mi sto costruendo molteplici funzioni che nel mio punto assumono il valore che voglio e in tutti gli altri punti sono nulli. Costruisco n funzioni per gli n input e li sommo assieme. Questa funzione qui mi basta per interpolare il tutto.\nImportante in questa sezione capire cosa Ã¨ la notazione.\n$\\varphi_k(x_i)$ Ã¨ il polinomio di lagrange che per xi, con i = k Ã¨ 1, altrimenti Ã¨ 0.\nIn particolare Ã¨ costruito in questo modo:\n$$ \\varphi_k(x) = \\prod^n_{j =0, j\\neq k} \\frac{x - x_j}{x_k - x_j}, \\forall k \\in \\{0, ..., n\\} $$ $\\Pi_n(x)$ Ã¨ la funzione di interpolazione costruita come\n$$ \\Pi_n(x) = \\sum_{i = 1}^n y_i \\varphi_i(x) $$ Teorema del resto d\u0026rsquo;interpolazione ðŸŸ¥ Slide della prof Note e osservazioni Faccio finta di prendere i punti da una funzione giÃ  esistente e voglio in questo caso cercare di valutare quanto buona sia lâ€™interpolazione.\nla funzione piÃ¹ a destra mi dÃ  una stima dell\u0026rsquo;errore della funzione di interpolazione.\nEsempio funzione di runge Questa funzione mostra come con lâ€™aumentare del grado del polinomio, la precisione del polinomio di interpolazione non aumenta, anzi diminuisce! Lâ€™errore cresce con piÃ¹ punti.\nAd intuito la funzione dâ€™interpolazione oscilla, se ho un insieme di punti equidistanti non gli sto dando spazio per oscillare indietro.\nEsempio grafico runge Nodi di chebicheff ðŸŸ¥ Questo Ã¨ un modo intelligente per prendere i nodi, in modo che si risolva il problema dellâ€™equidistanza e dando al poliminio spazio (non so poi perchÃ© dargli spazio risolva ciÃ²).\nCon n â†’ inf, lâ€™errore tende a zero! Quindi la convergenza dellâ€™interpolazione DIPENDE DAI PUNTI scelti. (questo chiaramente non va sui dati random che troviamo in ambiente, quindi Ã¨ molto inutile il metodo dellâ€™interpolazione per altra roba, inoltre staremmo seguendo il rumore dei dati).\nSlide nodi di chebicheff-Gauss-Lobatto\nInterpolazione a tratti ðŸŸ© Dato che non ci conviene di interpolare troppi punti vogliamo spezzare lâ€™interpolazione a tratti! E inoltre per avere una regolaritÃ  impongo uguaglianza delle derivate 1 e 2 evitando spigoli nelel funzioni finali.\nMa questo Ã¨ quanto ci vuole insegnare a riguardo la prof. quindi mi fermo in questo punto per questi appunti.\n","permalink":"https://flecart.github.io/notes/interpolazione/","summary":"Ripasso Prox: 21 Ripasso: January 1, 2023 Ultima modifica: January 2, 2023 10:49 AM Primo Abbozzo: October 26, 2022 4:45 PM Stato: ðŸŒ•ðŸŒ‘ðŸŒ‘ðŸŒ‘ðŸŒ‘ Studi Personali: No\nElementi di ripasso Interpolazione Vogliamo in questa sezione andare ad indagare la costruzione di funzioni che passano in tutti i punti che vogliamo, appunto interpolare. La funzione Ã¨ molto simile alla regressione trattata in Minimi quadrati (con il metodo della regressione, chiamato anche approssimazione ai minimi quadrati).","title":"Interpolazione"}]