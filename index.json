[{"content":"This is my first blog post. I\u0026rsquo;s the first time I\u0026rsquo;m writing something that would be published on my personal web-page. Programmers are used to write hello world programs as first line when they first approach a new language. It\u0026rsquo;s been a long tradition. This is something similar for me in this moment as I write this.\nI\u0026rsquo;m writing the first blog post in my website, I still have no idea of what I will be talking about in the next posts, they will probably be some thoughts and ideas of things i learn along the way, likely related to tech or University.\nAnyway I aim to write some high-quality content, something the other people would consider as valuable. This first post is just useful to test the functionalities and looks of this small platform.\nSee you in the next posts.\nUPDATE\nI still haven¬¥t got in the habit to write blog post in a regular manner, but i think now i have an activity that could help me to learn more about my fields of interest and also write more on my blog!\nI think that a two-week study of whatever subject I\u0026rsquo;m interested in and write a post for a week in which i explain what I have learned and my own thoughts about it could be a nice idea\nI\u0026rsquo;ll update this when I have more ideas about this.\n","permalink":"https://flecart.github.io/hello-world/","summary":"First blog post","title":"Hello World"},{"content":"Some useful links Main results: https://jblevins.org/notes/accept-reject\nIntuition: https://en.wikipedia.org/wiki/Rejection_sampling\nLa cosa √® che faccio sampling fra due distribuzioni diverse e devo settare anche un parametro (e a seconda di certe cose diventa molto lento).\nIntroduzione al metodo Vorrei utilizzare una funzione $g$ per generarne una altra, questo √® il fulcro del concetto. L\u0026rsquo;idea principale √®:\nConosco la funzione densit√† della funzione $f$ che voglio andare a generare Riesco a generare seguendo una funzione semplice, la chiamo $g$, candidate density. (che √® la densit√† che utilizzo per calcolare il target che non conosco molto bene). Ma devono esserci due cose:\nDue densit√† devono avere lo stesso supporto La funzione $\\frac{f}{g}$ deve essere limitata superiormente. (perch√© √® come l\u0026rsquo;esempio del lago in cui lancio cose dentro per approssimarne il valore). Allora sia $M$ il limite superiore, un buon modo per fare sampling sar√† allora $$ U \\leq \\frac{1}{M} \\frac{f(Y)}{g(Y)} $$ Ossia genero $Y$ usando g, e genero $U$ in modo uniforme normale Guardo se viene soddisfatta la funzione di sopra Se s√¨ prendo, altrimenti rifiuto e continuo cos√¨. Dimostrazione Probability of accepting dato una certa $M$ allora ho probabilit√† $\\frac{1}{M}$ di accettare un sample generato in questo modo, vedere dimostrazione su wikipedia. Ma qui diamo una altro valore:\n$$ \\mathbb{P}\\left( U \\leq \\frac{f(Y)}{Mg(Y)} \\right) \\ = \\int_{-\\infty}^{+\\infty} \\int _{-\\infty}^{f(Y)/f(X)M} 1 \\, du g(y) \\, dy $$$$ = \\int_{-\\infty}^{+\\infty} \\frac{1}{M} \\frac{f(y)}{g(y)} g(y) \\, dy = \\frac{1}{M} $$ E si ha la soluzione.\nAverage waiting time (!) $$ c = \\sup_{x} \\frac{f(x)}{g(x)} $$ Ad intuito questo sarebbe il valore di $M$ migliore, perch√© √® quello con probabilit√† migliore per fare sampling, ma non so bene perch√© si potrebbe considerare come un concetto di tempo.\nWith Unnormalized density ossia tale per cui l\u0026rsquo;integrale su tutto il supporto non √® 1, ma un valore $k$, si pu√≤ dire che questo algoritmo funziona lo stesso. Il motivo che √® stato dato √® che questa costante si pu√≤ tirare fuori e messa dentro $M$ e quindi sarebbe come il dato precedente.\nconsideriamo $\\tilde{f}$ e $\\tilde{g}$ tale che entrambi non siano normalizzati, magari con costanti diversi, e supponiamo che anche questi siano limitati su $\\tilde{M}$.\n$$ \\frac{i}{\\tilde{M} \\cdot k} $$ Dove $k = \\int _{-\\infty}^{+\\infty} f(x) \\, dx$ dato che non √® normalizzato.\n","permalink":"https://flecart.github.io/notes/accept-reject-algorithm/","summary":"\u003ch4 id=\"some-useful-links\"\u003eSome useful links\u003c/h4\u003e\n\u003cp\u003eMain results: \u003ca href=\"https://jblevins.org/notes/accept-reject\"\u003ehttps://jblevins.org/notes/accept-reject\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eIntuition: \u003ca href=\"https://en.wikipedia.org/wiki/Rejection_sampling\"\u003ehttps://en.wikipedia.org/wiki/Rejection_sampling\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eLa cosa √® che faccio sampling fra due distribuzioni diverse e devo settare anche un parametro (e a seconda di certe cose diventa molto lento).\u003c/p\u003e\n\u003ch4 id=\"introduzione-al-metodo\"\u003eIntroduzione al metodo\u003c/h4\u003e\n\u003cp\u003eVorrei utilizzare una funzione $g$ per generarne una altra, questo √® il fulcro del concetto.\nL\u0026rsquo;idea principale √®:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eConosco la funzione densit√† della funzione $f$ che voglio andare a generare\u003c/li\u003e\n\u003cli\u003eRiesco a generare seguendo una funzione semplice, la chiamo $g$, \u003cstrong\u003ecandidate density\u003c/strong\u003e. (che √® la densit√† che utilizzo per calcolare il target che non conosco molto bene).\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eMa devono esserci due cose:\u003c/p\u003e","title":"Accept Reject algorithm"},{"content":"Ci chiediamo come facciamo a rendere sistemi informatici accessibili a persone attraverso certe tecnologie.\nSlide esempi di disabilit√†\n√à meglio renderlo accessibile perch√© √® illegale (nel senso che stai facendo una discriminazione verso un certo insieme di persone).\nWGAC Queste sono alcuni principi di accessibilit√†, basati su 4 principi fondamentali\n4 principi del WGAC POUR per facilit√† di ricordarsi\nPerceivable (che ci siano le informazioni necessarie per l\u0026rsquo;accessibilit√†) Operable Understandable Robus Linguaggio Il tag del linguaggio √® utilizzato per sapere in che accento leggere e dare gli ordini.\nImmagini C\u0026rsquo;√® una distinzione fra immagini decorative e non decorative, quelle decorative sono funzioni estetiche che vengono ignorate dai lettori. (si lasca la alt vuota).\nIntestazioni Dovremmo annidare solamente dei h2 in h1 e non viceversa!\nTabella Form Wrapping label √® un metodo Altrimenti ci metto un for (quindi label for) ","permalink":"https://flecart.github.io/notes/accessibilit%C3%A0/","summary":"\u003cp\u003eCi chiediamo come facciamo a rendere sistemi informatici accessibili a persone attraverso certe tecnologie.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide esempi di disabilit√†\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Accessibilit√†/Untitled.png\" alt=\"image/universita/ex-notion/Accessibilit√†/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e√à meglio renderlo accessibile perch√© √® illegale (nel senso che stai facendo una discriminazione verso un certo insieme di persone).\u003c/p\u003e\n\u003ch2 id=\"wgac\"\u003eWGAC\u003c/h2\u003e\n\u003cp\u003eQueste sono alcuni principi di accessibilit√†, basati su 4 principi fondamentali\u003c/p\u003e\n\u003ch3 id=\"4-principi-del-wgac\"\u003e4 principi del WGAC\u003c/h3\u003e\n\u003cp\u003ePOUR per facilit√† di ricordarsi\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ePerceivable (che ci siano le informazioni necessarie per l\u0026rsquo;accessibilit√†)\u003c/li\u003e\n\u003cli\u003eOperable\u003c/li\u003e\n\u003cli\u003eUnderstandable\u003c/li\u003e\n\u003cli\u003eRobus\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"linguaggio\"\u003eLinguaggio\u003c/h3\u003e\n\u003cp\u003eIl tag del linguaggio √® utilizzato per sapere in che accento leggere e dare gli ordini.\u003c/p\u003e","title":"Accessibilit√†"},{"content":"Active Learning concerns methods to decide how to sample the most useful information in a specific domain; how can you select the best sample for an unknown model? Gathering data is very costly, we would like to create some principled manner to choose the best data point to humanly label in order to have the best model.\nIn this setting, we are interested in the concept of usefulness of information. One of our main goals is to reduce uncertainty, thus, Entropy-based (mutual information) methods are often used. For example, we can use active learning to choose what samples needs to be labelled in order to have highest accuracy on the trained model, when labelling is costly.\nSetting Given a safe exploration space $S$, an interesting space $A$ and all possible space $\\mathcal{X}$ and a dataset $\\left\\{ (x_{i}, y_{i}) \\right\\} \\subseteq S \\times \\mathbb{R}$ we want to find the best points that we would like to sample in $S$ to maximize the information we can get about $A$.\nSo we want to collect the most representative sample under constrained budgeting.\nWe can divide the setting in Active Learning as solving two problems:\nQuantifying the concept of utility of a sample. Finding the best sample to select. Utility of samples üü© $$ I(X; Y) = \\underbrace{H(X)}_{ \\begin{align} \\text{Uncertainty of } X \\\\ \\text{ before observing Y} \\end{align}}- \\underbrace{H(X \\mid Y)}_{\\text{ After observing } Y} $$Information Gain in Linear Regression üü©\u0026ndash; This measures the gain of adding $x$ to the set $A$ for a certain function $F$.\n$$ \\begin{align} I(X, Y) \u0026= H(Y) - H(Y \\mid X) \\\\ \u0026= \\frac{1}{2} \\log ( (2\\pi e)^{d}\\text{det}(\\Sigma + \\sigma^{2}_{n}I)) - \\frac{1}{2} \\log ( (2\\pi e)^{d}\\text{det}(\\sigma^{2}_{n}I)) \\\\ \u0026= \\frac{1}{2} \\log (\\lvert I + \\sigma_{n}^{-2}\\Sigma \\rvert) \\end{align} $$ Where $X \\sim \\mathcal{N}(x; \\mu, \\Sigma)$ and $Y = X + \\varepsilon, \\varepsilon \\sim\\mathcal{N}(\\varepsilon; 0, \\sigma^{2}_{n}I)$.\nMarginal Gain üü© $$ \\Delta_{F}(x \\mid A) = F(A \\cup \\left\\{ x \\right\\}) - F(A) $$$$ F(A) = \\forall y \\in A, f = y + \\varepsilon:I(f; y ) $$ Which is a mutual information for a lot a lot of points. Instead of writing the for all we can write $I(f_{\\mathcal{A}}; y_{A})$.\nThere is a nice property of this Marginal Gain: $$ \\begin{align} F(A \\cup \\left{ x \\right}) - F(A) \u0026amp;= I(f_{A \\cup \\left{ x \\right}} ; y_{A \\cup \\left{ x \\right} }) - I(f_{\\mathcal{A}} ; y_{A}) \\ \u0026amp;= I(f_{A \\cup \\left{ x \\right}} ; y_{A \\cup \\left{ x \\right} }) - I(f_{\\mathcal{A} \\cup \\left{ x \\right} } ; y_{A}) \u0026amp;\\text{ As } f_{x} \\perp y_{A} \\mid f_{A}\\ \u0026amp;= I(f_{A \\cup \\left{ x \\right} };y_{x} \\mid y_{A} ) \u0026amp;\\text{ By chain rule of }I \\ \u0026amp;= I(f_{x}; y_{x} \\mid y_{A}) \u0026amp; \\text{ As } f_{A} \\perp y_{x} \\mid f_{x} \\ \u0026amp;= H(y_{x} \\mid y_{A}) - H(y_{x} \\mid f_{x}, y_{A}) \\ \u0026amp;= H(y_{x} \\mid y_{A}) - H(\\varepsilon) \\ \\end{align}\n$$ This relation will be quite important for the proof of submodularity of mutual information.\nSubmodularity of Mutual Information üü©\u0026ndash; $$ F(A \\cup \\left\\{ x \\right\\}) - F(A) \\geq F(B \\cup \\left\\{ x \\right\\}) - F(B) $$$$ \\Delta_{F}(x \\mid A) \\geq \\Delta_{F}(x \\mid B) $$ This property just says that the gain of adding a point to a small set is higher than adding it to a bigger set.\n$$ \\begin{align} \\Delta_{F}(x \\mid A) \u0026= H(y_{x} \\mid y_{A}) - H(\\varepsilon) \\\\ \u0026\\leq H(y_{x} \\mid y_{B}) - H(\\varepsilon) \u0026\\text{ By monotonicity of } H \\\\ \u0026= \\Delta_{F}(x \\mid B) \\end{align} $$ Which ends the proof $\\square$.\nSubmodularity means no synergy üü© $$ I(f_{x}; y_{x}; y_{B - A} \\mid y_{A}) \\geq 0 $$$$ \\begin{align} I(f_{x}; y_{x}; y_{B - A} \\mid y_{A}) \u0026= I(f_{x}; y_{x} \\mid y_{A}) - I(f_{x}; y_{x} \\mid y_{B}) \\\\ \u0026= H(f_{x} \\mid y_{A}) - H(f_{x} \\mid y_{x}, y_{A}) - H(f_{x} \\mid y_{B}) + H(f_{x} \\mid y_{x}, y_{B}) \\\\ \u0026= H(f_{x} \\mid y_{A}) - H(f_{x} \\mid y_{x}) - H(f_{x} \\mid y_{B}) + H(f_{x} \\mid y_{x}) \\\\ \u0026= H(f_{x} \\mid y_{A}) - H(f_{x} \\mid y_{B}) \\\\ \u0026\\geq 0 \\text{ By monotonicy of } H \\end{align} $$Monotonicity of Information üü© $$ \\begin{align} I(A; Y) \u0026= H(Y) - H(Y \\mid A) \\\\ \u0026\\leq H(Y) - H(Y \\mid B) \u0026\\text{By monotonicity of } H\\\\ \u0026= I(B; Y) \\end{align} $$Greedy optimization Uncertainty Sampling üü© $$ x_{t + 1} = \\arg\\max_{x \\in \\mathcal{X}} I(f_{x}; y_{x} \\mid y_{S_{t}}) $$ Where $S_{t}$ are the point chosen until timestep $t$.\n$$ x_{t + 1} = \\arg\\max_{x \\in \\mathcal{X}} \\frac{1}{2}\\log \\left( 1 + \\frac{\\sigma^{2}_{t}(x)}{\\sigma^{2}_{n}} \\right)= \\arg\\max_{x \\in \\mathcal{X}} \\sigma_{t}^{2}(x) $$ Where we assumed the noise to be homoscedastic.\n$$ \\begin{align} I(f_{x}; y_{x}) \u0026= H(y_{x}) - H(y_{x} \\mid f_{x}) \\\\ \u0026= \\frac{1}{2} \\log (2\\pi e \\sigma^{2}_{n} + 2\\pi e \\sigma^{2}_{t}(x)) -\\frac{1}{2} \\log (2\\pi e \\sigma^{2}_{n}) \\\\ \u0026= \\frac{1}{2} \\log \\left( 1 + \\frac{\\sigma^{2}_{t}(x)}{\\sigma^{2}_{n}} \\right) \\end{align} $$Drawbacks of Uncertainty Sampling üü© In heteroscedastic settings, what we should minimize is actually the ratio between the epistemic uncertainty and the aleatoric uncertainty, always choosing for the maximum epistemic uncertainty is not guaranteed to be the most informative choice. But with greedy, we can\u0026rsquo;t distinguish them cleanly (for some reason I didn\u0026rsquo;t understood). In the homoskedastic setting, however, it is quite good.\nGreedy mutual information optimization üü© The main idea is to find the point $x$ in our safe space that maximizes mutual information with the interesting space $A$. This solution has been called Information Transductive learning by the AML professor, not sure that this name is correct.\n$$ x_{n} = \\arg \\max_{x \\in S} I(f_{\\mathcal{A}}; y_{x} \\mid \\mathcal{D}_{n - 1}) $$ Phrased in another manner, we would like to know how the uncertainty about our target function $f$ diminishes when we get to know about $y$.\n$$ \\arg\\max_{x \\in D} I(f_{\\mathcal{A}}; y_{x + D_{n - 1}} ) - I(f_{\\mathcal{A}}; y_{D_{n - 1}}) $$ With some simple calculation we find that this objective is exactly the above objective. This is also the marginal gain that we described above.\nIf we assume that $f$ is a Gaussian Processes then the mutual information is interpretable as minimizing general posterior variance:\n$$ \\begin{align} x_{n} \u0026 = \\arg \\max_{x \\in S} I(f_{\\mathcal{A}}; y_{x} \\mid \\mathcal{D}_{n - 1}) \\\\ \u0026 = \\arg \\max_{x \\in S} H(f_{\\mathcal{A}} \\mid \\mathcal{D}_{n - 1}) - H(f_{\\mathcal{A}} \\mid y_{x}, \\mathcal{D}_{n - 1}) \\\\ \\\\ \u0026 = \\arg \\max_{x \\in S} \\frac{1}{2} \\log \\left( 2 \\pi e \\sigma_{f_{\\mathcal{A}} \\mid \\mathcal{D}_{n - 1}}^{2} \\right) - \\frac{1}{2} \\log \\left( 2 \\pi e \\sigma_{f_{\\mathcal{A}} \\mid y_{x}, \\mathcal{D}_{n - 1}}^{2} \\right) \\\\ \\\\ \u0026 = \\arg \\min_{x \\in S} \\frac{1}{2} \\log \\left( \\frac{\\sigma_{f_{\\mathcal{A}} \\mid y_{x}, \\mathcal{D}_{n - 1}}^{2}}{\\sigma_{f_{\\mathcal{A}} \\mid \\mathcal{D}_{n - 1}}^{2}} \\right) \\\\ \\\\ \u0026 = \\arg \\min_{x \\in S} \\sigma_{f_{\\mathcal{A}} \\mid y_{x}, \\mathcal{D}_{n - 1}}^{2} \\end{align} $$It\u0026rsquo;s easy to interpret: we just want to sample the point were the uncertainty is maximized!\nGreedy optimization bounds üü© $$ F(S_{T}) \\geq \\left( 1 - \\frac{1}{e} \\right) \\max_{T } F(T) $$ Using the notation for mutual information introduced above. This says that greedy uncertainty sampling is at least $1 - 1/e$ of the optimal solution, which is near optimal. The important theoretical step for this is the submodularity of mutual information. We will not provide that here.\n$$ \\begin{align} F(S^{*}) \u0026\\leq F(S^{*} \\cup S_{T}) \u0026\\text{ by Monotonicity} \\\\ \u0026= F(S_{T}) + \\sum_{i = 1}^{n} \\Delta_{F}(x_{i} \\mid S_{T} \\cup x_{j \u003c i}) \\\\ \u0026\\leq F(S_{T}) + \\sum_{i = 1}^{n} \\Delta_{F}(x_{i} \\mid S_{T} ) \u0026\\text{ By Submodularity} \\\\ \u0026 \\leq F(S_{T}) + n \\cdot \\arg\\max_{x \\in \\mathcal{X}} \\Delta_{F}(x \\mid S_{T}) \\\\ \u0026 = F(S_{T}) + n \\cdot (F(S_{T + 1}) - F(S_{T})) \u0026\\text{ By definiiton of Greedy} \\\\ \\end{align} $$ Then if we set $\\delta _t = F(S^{*}) - F(S_{t})$ we can do some standard algebraic manipulation manipulation and get the result.\nTypes of optimal design üü®\u0026ndash; What we have done so far has been intensively studied in the field of optimal design. This field is interested on how to conduct the most informative experiment. There are many different manners to choose the sampling point. These include\nd-optimal: which attempts to reduce the determinant of the posterior covariance function. a-optimal: minimizes the trace of the posterior covariance matrix. e-optimal: attempts to minimize the maximum eigenvalue of the posterior covariance matrix. All these can be interpreted geometrically as doing operations on the uncertainty ellipsoid. Active Learning for classification The starting Idea: Label Entropy üü®++ $$ x_{n+1} = \\arg \\max_{x \\in S} H(y_{x}\\mid x_{1:n}, y_{1:n}) $$ But often, this usually leads to sampling points close to the decision boundary (that is where the uncertainty of the labels are higher!). Similar to the case where we have heteroskedastic noise, the entropy at these points could be higher just because of the aleatoric noise, aka label noise. We would like to come up with a more informed approach.\nInformative sampling for classification üü®++ This is also called BALD (Bayesian Active Learning by Disagreement). Here we distinguish the aleatoric and epistemic noise by adding another random variable $\\theta$ that represents the epistemic noise. Then we build upon basically the same ideas as the section on Regression in #Greedy optimization.\n$$ \\begin{align} x_{n+1} \u0026amp;= \\arg \\max_{x \\in S} I(\\theta; y_{x}\\mid x_{1:t}, y_{1:t}) \\ \u0026amp;= \\arg \\max_{x \\in S} H(y_{x} \\mid x_{1:t}, y_{1:t}) - H(y_{x} \\mid x_{1:t}, y_{1:t},\\theta) \\ \u0026amp;= \\arg \\max_{x \\in S} H(y_{x} \\mid x_{1:t}, y_{1:t}) - \\mathbb{E}{\\theta \\mid x{1:t}, y_{1:t}} \\left[ H(y_{x} \\mid \\theta) \\right] \\ \\end{align}\n$$ We can use approximate inference, like Variational Inference or Monte Carlo Methods to obtain approximations of the above. Entropy of the average prediction versus average entropy of the predictions given a trained model. The first term looks for points were all models are uncertain, the second term can be interpreted as a regularizer (similar to aleatoric uncertainty considerations somehow), and penalizes points where the model is uncertain, and steers for more confident points where the model disagrees with the label. Intuitively, the second part is the aleatoric uncertainty which is the average uncertainty for all models.\nThis is some code to play with on a notebook.\n$$ I[\\mathbf{y}, \\theta \\mid \\mathbf{x}, \\mathcal{D}] = H[\\mathbf{y} \\mid \\mathbf{x}, \\mathcal{D}] - \\mathbb{E}_{p(\\theta \\mid \\mathcal{D})} [H[\\mathbf{y} \\mid \\mathbf{x}, \\theta]] $$ The important thing to understand is that these methods select the most informative samples from the unlabeled pool, i.e., samples for which the model\u0026rsquo;s predictions are most uncertain due to disagreement across its posterior. The new data point that we are trying to sample is not known in advance.\nAcquisition functions In this case we would like to find some point with a certain property, which is usually local. For example, we might be interested to find the maximum of a certain function. The ideas here could be applied also to the search of other points, given the assumptions hold.\nSee Bayesian Optimization.\nInformation Transductive learning This is an idea of (H√ºbotter et al. 2024), part of his master\u0026rsquo;s thesis at ETH with Andreas Krause. The presentation of this part is a not perfectly clear, but probably is not quite important for the exam.\nIntroduction to the Problem üü© The main problem is how to sample in dangerous environments, where the cost of sampling may be high. We would need to define a safe zone in these contexts. With this setting, the space where you can have sample points is inherently different from the testing and evaluation points. We would like to find the maximum of an unknown stochastic process $f^{*}$, while respecting some safety constraints. We can choose a set of points $x_{1}, \\dots, x_{n} \\in \\mathcal{X}$ but we don\u0026rsquo;t want these to be outside the safe area $S := \\left\\{ x \\in \\mathcal{X} \\mid g(x) \\geq 0 \\right\\}$ where $g$ is the safety function. For each point that we choose, we observe the label value $y_{1}, \\dots y_{n}$ and the safety value $z_{1}, \\dots z_{n}$. We have thus identified three unknown that we would like to take into account, $f, g, S$. Fitting a Gaussian Processes on the dataset $(x_{i}, z_{i})_{i \u003c n}$, we can produce two function that represent our confidence over the safety function $g$ and the safety set $S$. We consider the function $S_{l} = \\left\\{ x \\mid l_{g}(x) \\geq 0 \\right\\}$ where $l$ paired with its upper bound counter part has $95\\%$ confidence bound of the safety function. In this manner, if we sample inside this set, we are almost sure that we are always sampling inside the safe zone, given our model is well-calibrated (see Bayesian neural networks).\nTransductive Learning Solution üü©\u0026ndash; Then we sample inside this space for the function $f$ where its higher than the most conservative estimate, in formulas, our target space is $A = \\left\\{ x \\in S_{u} \\mid u_{f}(x) \\geq \\max_{x \\in S_{l}} l_{f}(x) \\right\\}$. A graphical representation is probably clearer in the presentation. After we define the safe space and the target space, we could plug in optimization methods, for example the greedy one we explained before.\n$$ x_{n+1} = \\arg \\max_{x \\in S_{l}} I(f_{\\mathcal{A}}; y_{x} \\mid \\mathcal{D}_{n - 1}) $$Batch Active Learning With this, we present the algorithm introduced in (Yehuda et al. 2022).\nGeneralization error for 1-NN üü®\u0026ndash; $$ \\mathop{\\mathbb{E}}[\\hat{f}(x) \\neq f(x)] \\leq P(x \\not\\in C) + P(x \\in C_{wrong}) $$ Where $C_{wrong}$ is the set of points labelled wrongly. We note that $P(x \\not \\in C) = 1 - P(C(L, \\delta))$ which is the probability of a point not present in our covering set, while $x \\in C_{wrong}$ is the probability of a point in the covering set being wrongly classified. The paper defines the first value to be the high budged case as it can be swiftly lowered by just sampling more points, while in low budget that variable is not controllable, so one would like to reduce the second term. ProbCover attempts to fix the second term.\nThe objective function üü© $$ \\arg\\max _{L \\subseteq \\mathcal{X}, \\lvert L \\rvert = b} P(\\bigcup_{x \\in L} B(x, \\delta) ) $$ For a fixed $\\delta$, we would like to find the best set of points of size $b$ such that it is probably covered by the balls situated in that point. The paper shows that this problem is NP hard. The second problem is that we don\u0026rsquo;t know the prior distribution of $x$, so it\u0026rsquo;s hard to make an estimate of that (we can use the empirical distribution).\nDuality with Coreset üü© $$ \\delta(x) = \\min \\left\\{ \\delta \\in R_{+} : P(\\bigcup_{x \\in L}B(x, \\delta)) = 1 \\right\\} $$ Meaning: find best ball range, such that all the points are covered by the balls of that range. This is a loose dual problem to the one we have seen before. In the above problem: we try to fix the ball radius, and find the point that can minimize the coverage.\nProbCover From my understanding, ProbCover tells you how to sample the points that have the maximum coverage for a certain space, independently of the model that you will use. This is motivated by the observation that if we fix the $\\delta$ of the ball covers that we would like to use, then the upper bound of the probability of the error is fixed.\nThe simple algorithm is just maximizing the points that have most neighbors inside its circle. This has some theoretical motivations. The main results you should remember are the following:\nThe probability of impure balls in the coverage is upper bounded by the probability of impure balls in the whole sample space. The generalization error $\\mathbb{E}[\\hat{f}(x) \\neq f(x)]$ is upper bounded by the probability of the uncovered space and the wrongly classified points inside the covered space. If we fix a $\\delta$, which is the radius of a Ball, then we just need to maximize coverage, which could be done by the following algorithm in the image, which just maximizes for most points in the ball. References [1] Yehuda et al. ‚ÄúActive Learning Through a Covering Lens‚Äù 2022\n[2] H√ºbotter et al. ‚ÄúTransductive Active Learning: Theory and Applications‚Äù 2024\n","permalink":"https://flecart.github.io/notes/active-learning/","summary":"\u003cp\u003eActive Learning concerns methods to decide how to sample the most useful information in a specific domain; how can you select the best sample for an unknown model?\nGathering data is very costly, we would like to create some principled manner to choose the best data point to humanly label in order to have the best model.\u003c/p\u003e\n\u003cp\u003eIn this setting, we are interested in the concept of \u003cstrong\u003eusefulness of information\u003c/strong\u003e. One of our main goals is to \u003cem\u003ereduce uncertainty\u003c/em\u003e, thus, \u003ca href=\"/notes/entropy/\"\u003eEntropy\u003c/a\u003e-based (mutual information) methods are often used.\nFor example, we can use active learning to choose what samples needs to be labelled in order to have highest accuracy on the trained model, when labelling is costly.\u003c/p\u003e","title":"Active Learning"},{"content":"Check function A volte pu√≤ essere molto pesante, perch√©\nWhat does check do? Viene utilizzato per introdurre un constraint check per avere sicurezza su un range. Check e innestamenti üü©- Pu√≤ essere che certe implementazioni non permettano il check innestato, questo √® una cosa molto pesante, perch√© ogni modifica deve andare a rifare la modifica ai subalterni, quindi questo √® pesante pesante.\nAssertions üü©\u0026ndash; Sono dei check fatti al livello dello schema, quindi valgono sempre, e possono essere riutilizzati in table diversi credo. Un altro aspetto √® che √® database wide.\ncreate ASSERTION AtLeastOneEmployee check (1 \u0026lt;= (select count(*) from Employee))) View L\u0026rsquo;uso del view üü© create view ViewName [(attrlist)] as selectstatement [ with [local | cascaded ] check option] viene utilizzato per prendere dati esistenti, e metterli in una forma utile a una sotto-organizzazione, che vuole informazioni specifiche diciamo.\nCheck: viene utilizzato se update √® sensato (soddisfa ancora la check). Grouping, posso creare view con informazioni aggregate, e poi posso usare le informazioni aggregate simile a sopra. Cascaded vs local Cascaded significa che ogni modifica e view, viene riflessa su altri schema e view fisici effettivi Local significa Recursive queries üü•+ In questi casi viene proprio definito un approccio ricorsivo (anche se non ricordo benissimo la sintassi) andiamo a definire cose come caso base, e caso induttivo e poi si fa la query in questo modo.\nIn pratica costruisco una view in modo ricorsivo, e su questa posso farci delle query. Un esempio:\nwith recursive Ancestors(Ancestor, Descendant) AS ( select Father, Son from Fatherhood union all select Ancestor, Son from Ancestors, Fatherhood where Descendant = Father ) select * from Ancestors In pratica nel primo select popolo inizialmente la view, poi in modo ricorsivo, prendo gli elementi dentro la view, prendo alcuni elementi dentro son, e aggiungo tutti gli elementi che soddisfano quella condizione.\nOther expressions Coalesce üü• Ci permette di fare l\u0026rsquo;equivalente del default in alcuni linguaggi di programmazione per me. In pratica restituisce il primo elemento non nullo in una lista, quindi se per caso ho due elementi, e il primo √® nullable, allora prende il default il secondo.\nEsempio:\nselect number, coalesce(Mobile, PhoneHome) from Employee Se non esiste mobile, si va su phonehome. Si pu√≤ fare una cosa come `coalesce(Dept, \u0026ldquo;None\u0026rdquo;) per mettere il default.\nScalar functions üü® String Time\ncurrent_date extract(yearExpresison) Esempio: SELECT EXTRACT(YEAR from orderDate) AS orderyear, FROM Orders WHERE DATE(orderDate) = current_date() Casting\nnullif Semantica: ritorna null se la condizione √® vera.\n√à buono per far tornare Null se un valore assume un certo valore hardcodato, ad esempio se il default √® \u0026ldquo;Unknown\u0026rdquo; per qualcosa, posso fargli tornare NULL se valore uguale a quella stringa hardcodata.\nEsempio:\nselect Surname, nullif(Dept, \u0026#34;unknown\u0026#34;) from employee Se √® vera la comparazione, si ritorna Null in automatico\nCase expressions üü®\u0026ndash; ### Transactions #### ACID framework üü© - Atomic: o tutto o niente, √® una transazione atomica - Consistency: tutto deve soddisfare i constraints - Isolation: simile ad atomico, le transazioni non devono influenzarsi fra di loro per tempo. - Durability: non √® su ram diciamo, quindi quanto viene modificato viene mantenuto in memoria. Example in sql for transactions Authorization Privileges (6) Questa parte si ricollega in qualche modo con la parte di renzone, vogliamo specificare una risorsa e dire chi pu√≤ fare cosa su quella risorsa. La risorsa in questo caso pu√≤ essere lettura modifica o eliminazione su una tavola. Posso\nDare permessi (privilegi) Togliere permessi Specificare utenti che hanno permessi Propagazione di privilegi. I privilegi sono esattamente 6, descritti dall\u0026rsquo;immagine sotto Grant privileges grant \u0026lt; Privileges | all privileges \u0026gt; on Resource to Users [ with grant option ] Revoke privileges revoke Privileges on Resource from Users [ restrict | cascade ] Restrict -\u0026gt; non implica anche altri utenti Cascade -\u0026gt; la revoca √® estesa ad altri utenti anche, una reazione a catena. Privilegi come view RBAC √à pi√π facile usare il modello chiamato RBAC, ossia definiamo ruoli, una view, e i ruoli possono accedere solamente a certe view. Usare i ruoli √® un metodo classico, potremmo considerarlo come una astrazione su cosa ogni utente deve fare sul database (quindi le sue operazioni ideali) e da quello andare a descrivere cosa esattamente ha bisogno di poter fare. In questo modo definisco i permessi su questi ruoli ideali invece di andare a farli sui singoli utenti, magari anche ripetendo un sacco di queries.\n","permalink":"https://flecart.github.io/notes/advanced-sql/","summary":"\u003ch3 id=\"check-function\"\u003eCheck function\u003c/h3\u003e\n\u003cp\u003eA volte pu√≤ essere molto pesante, perch√©\u003c/p\u003e\n\u003ch4 id=\"what-does-check-do\"\u003eWhat does check do?\u003c/h4\u003e\n\u003cp\u003eViene utilizzato per introdurre un \u003cstrong\u003econstraint\u003c/strong\u003e check per avere sicurezza su un range.\n\u003cimg src=\"/images/notes/Structured Query Language-1697711487638.jpeg\" alt=\"Structured Query Language-1697711487638\"\u003e\u003c/p\u003e\n\u003ch4 id=\"check-e-innestamenti--\"\u003eCheck e innestamenti üü©-\u003c/h4\u003e\n\u003cp\u003ePu√≤ essere che certe implementazioni non permettano il check innestato, questo √® una cosa molto pesante, perch√© ogni modifica deve andare a \u003cstrong\u003erifare la modifica ai subalterni\u003c/strong\u003e, quindi questo √® pesante pesante.\u003c/p\u003e\n\u003ch4 id=\"assertions---\"\u003eAssertions üü©\u0026ndash;\u003c/h4\u003e\n\u003cp\u003eSono dei \u003cstrong\u003echeck\u003c/strong\u003e fatti al \u003cstrong\u003elivello dello schema\u003c/strong\u003e, quindi valgono sempre, e possono essere riutilizzati in table diversi credo.\nUn altro aspetto √® che √® \u003cstrong\u003edatabase wide\u003c/strong\u003e.\u003c/p\u003e","title":"Advanced SQL"},{"content":"Introduzione Nozioni base Questi sono le parole chiave di questo capitolo, ci permettono di parlare con chiarezza riguardo l‚Äôagente logico.\nSentence\nKnowledge Base\nAxiom\nInference\nbackground knowledge\nKnowledge representation language\nKnowledge level\nImplementation level\nEsempio generale di agente logico\nLogica proposizionale Sintassi del linguaggio Descrivere la BNF della logica proposizionale.\nper sapere cosa sia la BNF di questo √® molto pi√π facile rifarsi agli appunti di logica presi durante l‚Äôanno di corso 2021/2022 Logica Proposizionale.\nDeduzione o derivazione Abbiamo ora un algoritmo (stupido) di verifica sul fatto se valga o meno $KB \\vDash \\alpha$, ovvero vogliamo sapere se alpha si pu√≤ derivare dal nostro modello\nAlgoritmo di derivazione\nInferenza ‚Üí (sound and complete inference methods) Risoluzione La risoluzione √® una operazione che si pu√≤ avere fra due clausole, come se fosse una regola di derivazione, come vedremo ci sta molto comodo, anche se non l‚Äôabbiamo mai fatta a lezione.\nIn breve:\nConsiste di eliminare qualche caso banale negli OR e.g. se ho a or b or c, e ho anche not a, allora posso dedurre b or c.\nSono interessanti soprattutto perch√© √® una operazione completa, cio√® che √® in grado di derivare tutto il derivabile (quindi se gli dai 2 clausole random, $\\alpha, \\beta$ riesce sempre a determinare se vale o meno $\\alpha \\vDash \\beta$.\noltre a ci√≤ sono anche sound, ossia quello che deducono √® corretto (non fanno mai teoremi sbagliati).\nPerch√© funziona\nIn pratica prova a dimostrare che not tesi‚Üí assurdo. e questa √® gestibile perch√© √® in forma congiuntiva normale, che permette di utilizzare la risoluzione\nAlgoritmo per la risoluzione\nCheck del modello Modelli di inferenza Conjunctive Normal Form Quando abbiamo delle clausole, ossia delle disgiunzioni di letterali, possiamo cercare di trasformare questa nella sua forma congiuntiva normale. Questo √® possibile perch√© ogni proposizione si pu√≤ ridurre a And e Or.\nBNF della CNF\nAndare a vedere questo per un algoritmo che utilizzi questa forma per runnare.\nForward Chaining Horn Clauses Una horn clause √® una proposizione composta di and, in cui al messimo un singolo valore √® vero.\nSi √® scoperto che esiste un algoritmo molto efficiente per checkare se una proposizione √® vera in un modello (che eseguen in O(n))\nIn pratica √® una cosa molto simile in And-or search presentato in Problemi di ricerca.\nAlgoritmo in breve\nPraticamente √® una BFS che prende come queue iniziale tutte le proposizioni atomiche che sono date per vere.\nUna volta poppati questi vanno a diminuire il conteggio degli implica che lo hanno come ipotesi. Se il singolo implica ha questo counter del numero di ipotesi necessarie che va a 0, allora si hanno nuove ipotesi.\nDa notare che questo funziona solamente per HORN CLAUSES perch√© ci fa molto comodo avere un unico effetto derivato da una serie di di ipotesi in AND iniziali.\nAlgoritmo\nAgente logico Frame problem Conclusione Creazione di Plan con SAT solvers Incapacit√† della logica proposizionale col tempo ","permalink":"https://flecart.github.io/notes/agente-logico/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"nozioni-base\"\u003eNozioni base\u003c/h3\u003e\n\u003cp\u003eQuesti sono le parole chiave di questo capitolo, ci permettono di parlare con chiarezza riguardo l‚Äôagente logico.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSentence\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eKnowledge Base\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAxiom\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eInference\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ebackground knowledge\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eKnowledge representation language\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eKnowledge level\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eImplementation level\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eEsempio generale di agente logico\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Agente Logico/Untitled.png\" alt=\"image/universita/ex-notion/Agente Logico/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"logica-proposizionale\"\u003eLogica proposizionale\u003c/h2\u003e\n\u003ch3 id=\"sintassi-del-linguaggio\"\u003eSintassi del linguaggio\u003c/h3\u003e\n\u003cp\u003eDescrivere la BNF della logica proposizionale.\u003c/p\u003e\n\u003cp\u003eper sapere cosa sia la BNF di questo √® molto pi√π facile rifarsi agli appunti di logica presi durante l‚Äôanno di corso 2021/2022 \u003ca href=\"/notes/logica-proposizionale/\"\u003eLogica Proposizionale\u003c/a\u003e.\u003c/p\u003e","title":"Agente Logico"},{"content":"Alberi BST e AVL 4.1 Alberi binari di ricerca (BST) Queste sono delle varianti rispetto all\u0026rsquo;albero, descritto in modo molto sommario sopra (binario perch√© ogni nodo ha al massimo due figli, mentre l\u0026rsquo;albero pu√≤ averne quanti se ne vuole).\n4.1.1 Introduzione La caratteristica principale dell\u0026rsquo;albero di ricerca √® una condizione sulle chiavi (che hanno i figli).\nInfatti questo albero binario di ricerca si pu√≤ vedere come una implementazione della struttura astratta del dizionario. (che ricordiamo, √® un struttura in cui a ogni nodo sono presenti due valori, una chiave (tute differenti) e un dato, e sono definite tre operazioni principali, possiamo vederla come interfaccia).\nAl massimo due figli per nodo. (albero binario) Il dizionario, quindi che ogni nodo abbia chiave. I figli di sinistra hanno chiavi minori del genitore, a destra maggiore. 4.1.2 Prototipo Possiamo definire alcune operazioni principali per l\u0026rsquo;albero di ricerca:\nLe tre standard che sono presenti per il dizionario. (search, insert e delete) Max e Min. Predecessor e successor Saltiamo le note di implementazione di questi algoritmi :D perch√© sono gi√† triti e ritriti.\nUna nota su predecessor:\nPer l\u0026rsquo;operazione di delete abbiamo solamente considerato il caso di predecessor quando il nodo da considerare possedeva il figlio giusto.\nMa √® possibile che non lo abbia, allora √® molto simile, ma opposto (invece di scendere continuamente a destra, salgo continuamente a sinistra, con continuamente nel senso finch√© c\u0026rsquo;√® ancora il nodo).\n4.2 Alberi AVL Questi sono alberi AVL (il cui nome deriva dal nome dei creatori, come RSA), alberi bilanciati secondo l\u0026rsquo;altezza dei sottonodi. La cosa buona √® che avendo i bilanciamenti abbiamo un altezza logaritmica. in particolare possiamo dire che questi siano autobilancianti.\nIntroduciamo ora alcuni concetti importanti per comprendere il bilanciamento\n4.2.1 il concetto di bilanciamento Il fattore di bilanciamento\nCerchiamo di considerare un fattore di bilanciamento che si ottiene con\ncon h una funzione che mi ritorna l\u0026rsquo;altezza. (da notare che √® l\u0026rsquo;altezza, non la funzione).\nE l\u0026rsquo;altezza parte da 0\n$$ \\beta = fattore\\_bilanciamento = h(sinistra) - h(destra) $$Bilanciato in altezza\nConsideriamo un albero bilanciato in altezza se $|\\beta| \\leq 1$\n4.2.2 Altezza di un albero di fibonacci L\u0026rsquo;albero di fibonacci √® molto interessante da studiare dal punto di vista dell\u0026rsquo;altezza, infatti possiede il massimo sbilanciamento possibile\nIntuizione dell\u0026rsquo;albero (dalla costruzione puoi dimostrare la sua altezza in modo intuitiva)\nNumero di nodi nell\u0026rsquo;albero di fibonacci\nConclusione sull\u0026rsquo;altezza\n4.2.3 Operazioni elementari (rotazione e altezza) Altezza\nPossiamo definire un algoritmo per definire il fattore di bilanciamento e l\u0026rsquo;altezza di un sotto-albero (da sapere bene, fare attenzione ai casi null)\nAlgoritmo (fattore bilanciamento e update altezza di un nodo)\nOperazione di rotazione\nUna rotazione √® una operazione elementare di su un albero che mi riposiziona alcuni figli e genitori di un nodo.\nEsempi di rotazione semplice\nPseudocodice della rotazione\n4.2.4 Risoluzione degli sbilanciamenti Possiamo catalogare le possibili tipologie di sbilanciamento in 2 macrogruppi di 2 (sono simmetrici destra e sinistra), questi saranno risolvibili tramite rotazioni, che, come vedremo, hanno la propriet√† di diminuire l\u0026rsquo;altezza del nodo di rotazione di 1.\nTipi di sbilanciamento\nSbilanciamento di tipo SS (simmetrico DD)\nSbilanciamento di tipo DS\nPseudocodice per risolvere sbilanciamento\n4.2.5 Note su inserimento e rimozione Queste due operazioni sono le uniche che possono cambiare il bilanciamento dell\u0026rsquo;albero.\nSi pu√≤ dimostrare che l\u0026rsquo;inserimento sbilancia al massimo un nodo, per cui una unica rotazione √® sufficiente per il tutto.\nMentre la rimozione pu√≤ sbilanciare tutto il percorso fino la radice come questa operazione:\nEsempio\n","permalink":"https://flecart.github.io/notes/alberi-bst-e-avl/","summary":"\u003ch1 id=\"alberi-bst-e-avl\"\u003eAlberi BST e AVL\u003c/h1\u003e\n\u003ch2 id=\"41-alberi-binari-di-ricerca-bst\"\u003e4.1 Alberi binari di ricerca (BST)\u003c/h2\u003e\n\u003cp\u003eQueste sono delle varianti rispetto all\u0026rsquo;albero, descritto in modo molto sommario sopra (binario perch√© ogni nodo ha al massimo due figli, mentre l\u0026rsquo;albero pu√≤ averne quanti se ne vuole).\u003c/p\u003e\n\u003ch3 id=\"411-introduzione\"\u003e4.1.1 Introduzione\u003c/h3\u003e\n\u003cp\u003eLa caratteristica principale dell\u0026rsquo;albero di ricerca √® una condizione sulle chiavi (che hanno i figli).\u003c/p\u003e\n\u003cp\u003eInfatti questo albero binario di ricerca si pu√≤ vedere come una implementazione della struttura astratta del dizionario. (che ricordiamo, √® un struttura in cui a ogni nodo sono presenti due valori, una chiave (tute differenti) e un dato, e sono definite tre operazioni principali, possiamo vederla come interfaccia).\u003c/p\u003e","title":"Alberi BST e AVL"},{"content":"Introduzione agli alberi di decisione Setting del problema üü©- Spazio delle ipotesi Definizione spazio ipotesi üü©\u0026mdash; Per spazio delle ipotesi andiamo a considerare l\u0026rsquo;insieme delle funzioni rappresentabili dal nostro modello. Questo implica che l\u0026rsquo;allenamento ricerca l\u0026rsquo;ipotesi ossia la parametrizzazione ottimale del nostro modello, ottimale in quanto minimizza l\u0026rsquo;errore che viene compiuto nel training set.\nL\u0026rsquo;insieme iniziale si pu√≤ anche considerare come inductive bias ossia il restringimento solamente a certe ipotesi e non tutte. Altrimenti abbiamo no free lunch.\nEspressivit√† üü© In pratica ci andiamo a chiedere\nPer quali $h$ esistono modelli di alberi di decisione? Per tutti Dato un albero per una ipotesi $h$, l\u0026rsquo;albero √® unico? Se non √® unico abbiamo una preferenza? Overfitting and underfitting üü© Sono dei fenomeni molto comuni nel campo dell\u0026rsquo;apprendimento statistico. Si potrebbe dire in modo intuitivo che:\nUnderfitting quando il modello non √® ancora stato allenato, quindi possiede un bias molto alto per quanto riguarda la precisione del modello\nOverfitting quando il modello √® stato allenato troppo, tanto che ha imparato del rumore presente sul training set, questo non permette la generalizzazione sul test set.\n$$ error_{D}(h) \u003e error_{D}(h') $$$$ error_{train}(h) \u003c error_{train}(h') $$ Ossia ho un errore basso nel training set, ma non riesco a generalizzare sul validation set.\n### Esempio di struttura albero decisionale Vorremmo cercare di modellare alcuni modelli di regressione o classificazione seguendo un albero di decisione come in figura Il problema sarebbe capire come creare l\u0026rsquo;albero in automatico, a seconda di un training set labellato: Input:\n$$ coppie di training set. Output Un ipotesi $h$ che √® un albero di decisione. Entropia Definizione entropia üü© $$ H(X) = - \\sum_{i=1}^{n}P(X = i) \\log_{2}P(X=i) $$ In cui se sono uguali hanno entropia massima, segue il grafico di questo genere\nC\u0026rsquo;√® un apparato teorico non da poco per questo, perch√© √® stato utilizzato molto nella teoria della comunicazione. Una cosa che riguarda la probabilit√† del singolo dato, se √® sempre uguale ho entropia pi√π alta.\nInformation Gain üü®+ Una definizione che segue l\u0026rsquo;intuizione √® che la probabilit√† dell\u0026rsquo;avvenimento influenzi il concetto di informazione, ossia se un evento compare sempre (tipo il sole che sorge), non ha molto informazione, perch√© √® sempre uguale.\nProbabilit√† 1 ha zero informazione given two independent events with probabilities p1 and p2 their joint probability is p1p2 but the information acquired is the sum of the informations of the two independent events, so $I(p_{1}p_{2}) = I(p_{1}) + I(p_{2})$ Le due propreit√† di sopra giustificano il fatto di definire in modo abbastanza naturale che $$ I(p) = -\\log(p) $$ Propriet√† importanti (4) üü®++ Algoritmo di costruzione dell\u0026rsquo;albero Descrizione algoritmo di costruzione üü©- Bisogna introdurre il concetto di entropia per poter discriminare, vorremmo cercare il punto che diminuisca di pi√π l\u0026rsquo;entropia.\nRiduzione overfitting Pruning dell\u0026rsquo;albero (2) üü©\u0026ndash; Posso fare early stopping, ossia smetto di alllenarmi (ossia di creare altre branch), dopo che ne ho create un tot. Posso fare post-pruning, ossia dopo che ho creato tutto l\u0026rsquo;albero (probabilmente facendo overfitting), mi metto ad eliminare alcune branches di poco conto. Questo si utilizza il validation set per vedere in che modo potare pu√≤ influenzare la performance su questo (se migliora allora di fa, lo facciamo in modo greedy) Index di Impurit√† di Gini üü©- Questo √® un indice che √® stato usato in economia per studiare la disuguaglianza fra le persone, nel nostro caso lo utilizziamo per capire in che modo fare branching con l\u0026rsquo;albero di decisione\nGini‚Äôs impurity measures the probability that a generic element get misclassified according to the current classification (an alternative to entropy).\n$$ I_{G}(F) = \\sum_{i=1}^{m} f_{i}(1 - f_{i}) = \\sum_{i=1}^{m} (f_{i} - f_{i}^{2}) = 1 - \\sum_{i= 1}^{m}f_{i}^{2} $$ Dove $f_{i}$ √® la frazione del dataset che appartiene ad $i$ Questo √® quindi un modo alternativo per fare split ad un nodo dell\u0026rsquo;albero.\nRandom forests Vengono costruiti molti alberi e si utilizzano le loro decisioni assieme per avere un risultato finale, questo √® una tecnica ensemble perch√© vengono messe assieme conoscenze di tutti gli alberi.\nEnsemble models üü© Ensemble techniques exploits the principle that a large number of relatively uncorrelated models (e.g. trees) operating as a committee will typically outperform any of the individual constituent models.\nMetodi di differenziazione (2) üü©\u0026ndash; Chiaramente non abbiamo molto vantaggio se tutti gli alberi che vengono cos√¨ creati sono tutti uguali fra di loro, √® quindi utile utilizzare tecniche che li differenzino fra di loro:\nBagging uso input random. Feature randomness (uso subset di features per predire) Conclusioni Aspetti positivi degli alberi di decisione (4) üü©- Molto veloci Non hanno bisogno di grandi quantit√† di dati Facile capire perch√© viene fatto la decisione (posso plottare le immagini) Adatti sia a problemi continui che discreti Aspetti negativi (3) üü©- Molto facile andare in overfitting Esistono molti alberi per lo stesso dataset (instabile con le features e struttura dell\u0026rsquo;albero) Possono diventare molto unbalanced se c\u0026rsquo;√® qualche predittore forte (andare a guardare questo). Side notes (altro) ","permalink":"https://flecart.github.io/notes/alberi-di-decisione/","summary":"\u003ch2 id=\"introduzione-agli-alberi-di-decisione\"\u003eIntroduzione agli alberi di decisione\u003c/h2\u003e\n\u003ch3 id=\"setting-del-problema--\"\u003eSetting del problema üü©-\u003c/h3\u003e\n\u003cimg src=\"/images/notes/Alberi di decisione-1696950382366.jpeg\" width=\"576\" alt=\"Alberi di decisione-1696950382366\"\u003e\n\u003ch3 id=\"spazio-delle-ipotesi\"\u003eSpazio delle ipotesi\u003c/h3\u003e\n\u003ch4 id=\"definizione-spazio-ipotesi----\"\u003eDefinizione spazio ipotesi üü©\u0026mdash;\u003c/h4\u003e\n\u003cp\u003ePer spazio delle ipotesi andiamo a considerare l\u0026rsquo;insieme delle \u003cem\u003efunzioni rappresentabili dal nostro modello\u003c/em\u003e.\nQuesto implica che \u003cstrong\u003el\u0026rsquo;allenamento ricerca l\u0026rsquo;ipotesi\u003c/strong\u003e ossia la parametrizzazione \u003cem\u003eottimale\u003c/em\u003e del nostro modello, ottimale in quanto \u003cem\u003eminimizza\u003c/em\u003e l\u0026rsquo;errore che viene compiuto nel training set.\u003c/p\u003e\n\u003cp\u003eL\u0026rsquo;insieme iniziale si pu√≤ anche considerare come \u003cstrong\u003einductive bias\u003c/strong\u003e ossia il restringimento solamente a certe ipotesi e non tutte. Altrimenti abbiamo no free lunch.\u003c/p\u003e","title":"Alberi di decisione"},{"content":" Equivalenza dei tipi (2) üü© Quando possiamo dire che due tipi siano uguali? Solitamente vengono utilizzati due metodi:\nEquivalenza Nominale Quando un nuono tipo introduce un nuovo nome diverso fra tutti i presenti. Credo cos√¨ vada golang. Quindi in questo caso si pu√≤ dire che un tipo √® equivalente solamente a s√© stesso.\nVogliamo fare in questo modo perch√© se definiamo un nuovo tipo solitamente dovrebbe avere funzioni diverse, quindi √® giusto che sia diverso da uqello iniziale.\nEquivalenza di struttura Ossia quando tutte le operazioni, strutture e sottoelementi sono uguali possiamo andare a definire una equivalenza di struttura. (vado anche di pi√π a guardare come vengo utilizzati, a tempo di compilazione).\nIn un modo forse pi√π intuitivo possiamo dire che abbiamo una equivalenza di struttura quando tutti i campi all‚Äôinterno della struttura sono gli stessi.\nPossiamo anche utilizzare una forma pi√π lasca (molto ispirata dal duck typing) chaichiamo questa la compatibilit√† di tipo).\nDuck typing e confronto equivalenza Questo √® molto simile a quanto si fa in duck typing in slide\nSlide duck typing\nIf it walks like a duck, and it quacks like a duck, then it must be a duck. ~a duck\nSlide confronto fra i tipi di equivalenza\nIn pratica possiamo dire che l‚Äôequivalenza nominale porta vantaggi rispetto a quello strutturale.\nNotazione molto pi√π chiara per tipi ricorsivi. Di solito si utilizza una cosa di messo, tipo una parte nominale per dichiarare, e poi fare un controllo strutturale in secondo momento. Controllo del sottotipaggio √® molto pi√π semplice dal punto di vista nominale. Compatibilit√† dei tipi (3) Diciamo che il tipo T √® compatibile con il tipo s, se un valore di tipo T √® ammesso in un qualsiasi contesto in cui sarebbe richiesto un valore di tipo s.\nQuesto √® abbastanza naturale, la compatibilit√† essendo anche simmetrica, sussume anche un ordine parziale (riflessivo e transitivo) su questo possiamo andare ad avere tipi compatibili con l‚Äôiniziale (quindi convertibili, o se parli con set theory li puoi vedere uguali).\nSlide compatibilit√† dei tipi\nQuando ho queste propriet√†:\nAbitanti di un tipo sono anche abitanti di tipo2 (ad esempio in rust andiamo a definire le traits sulle structs). Ci sono le stesse operazioni Conversioni canoniche, o arbitrarie. Allora potrei prendere il primo tipo e considerarlo come del secondo, in questo senso posso dire che sono dei tipi compatibili fra di loro.\nConversione di tipi Pu√≤ essere silente o espicito, se il silente non √® controlalto potrebbe dare dei bugs.\nImportante sottolineare la differenza fra conversione sintattica che in pratica √® solamente una interpretazione diversa della zona di memoria (stessa grandezza credo) oppure proprio da una funzione che applichi questa conversione.\nQuando faccio una conversioen diretta sto facendo una coercizione, ossia una conversione diretta seguendo un certo modo, anche detto marshalling).\nType inference Type inference\nSlide type inference\nQuando con il parsing riesco ad accumulare informazioni irguardo un certo tipo o operazione, quindi riesco ad assegnare un tipo senza che sia stato specificato in modo esplicito.\nAlla fine vado a risolvere una specie di equazioni con i tipi. Se non √® possibile avere abbastanza informazioni per escludere tutto si ritorna un errore. (semmai con una proposta di segnatura, o signature)\nAlgoritmo di unificazione \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Algebra dei tipi/Untitled 8.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Algebra dei tipi/Untitled 8\u0026quot;\u0026gt; ","permalink":"https://flecart.github.io/notes/algebra-dei-tipi/","summary":"\u003cimg src=\"/images/notes/image/universita/ex-notion/Algebra dei tipi/Untitled.png\" alt=\"image/universita/ex-notion/Algebra dei tipi/Untitled\"\u003e\n\u003ch3 id=\"equivalenza-dei-tipi-2-\"\u003eEquivalenza dei tipi (2) üü©\u003c/h3\u003e\n\u003cp\u003eQuando possiamo dire che due tipi siano uguali? Solitamente vengono utilizzati due metodi:\u003c/p\u003e\n\u003ch4 id=\"equivalenza-nominale\"\u003eEquivalenza Nominale\u003c/h4\u003e\n\u003cp\u003eQuando un nuono tipo introduce un nuovo nome diverso fra tutti i presenti. Credo cos√¨ vada golang.\nQuindi in questo caso si pu√≤ dire che un tipo \u003cstrong\u003e√® equivalente solamente a s√© stesso\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eVogliamo fare in questo modo perch√© se definiamo un nuovo tipo solitamente dovrebbe avere funzioni diverse, quindi √® giusto che sia diverso da uqello iniziale.\u003c/p\u003e","title":"Algebra dei tipi"},{"content":"In questa sezione andiamo ad indagare metodi di scomposizione, iterativi e non. Ci sono molte matrici importanti per questa parte che dovremmo prendere confidenza.\nImmagini Lab 2 images\nMetodo di gauss Vogliamo cercare un metodo per calcolare soluzioni a sistemi di equazione del genere:\n$Ax = b$, classico. Supponiamo che questo sistema abbia una soluzione.\nIl nostro obiettivo sarebbe scomporre la matrice $A = LU$ come prodotto di due matrici Lower triangular e Upper triangular.\nAlgoritmo per matrici Upper e lower triangular üü© Nel caso io abbia una matrice Lower o Upper triangular, i sistemi nella forma $Lx=b$ sono risolvibili con un algoritmo abbastanza banale che qui non riporto (sostituzioni via via‚Ä¶)\nIl costo √® di $O(n^2)$ e non ti scordare il /2 perch√© a lei piace\nScomposizione A = LU üü© Questo √® un algoritmo che necessita di una osservazione abbastanza difficile:\nNoto che durante l\u0026rsquo;applicazione dell‚Äôalgoritmo di gauss, per creare il pivot su una colonna, √® esattamente come se moltiplicassi per una (matrice identit√† + fattori per la colonna di interesse).\nCome in esempio\nSi pu√≤ notare inoltre che che l‚Äôinverso di L1 √® in una forma molto bella, esattamente la stessa con numeri invertiti!, inoltre la moltiplicazione fra Ln √® anch‚Äôessa in una forma molto carina!!! Facilita molto il prodotto. In questo modo mi creo una matrice L, in cui √® molto facile invertire.\ncosto $O(n^3/3)$ per la fattorizzazione LU e poi n2 due volte per risolvere L e U\nScomposizione con permutazione üü© Ogni tanto potrebbe capitare che ci sia il bisogno di permutare, altrimenti non ho nessuna soluzione, da notare che questo √® un passo all\u0026rsquo;interno dell‚Äôalgoritmo di gauss.\nInoltre scegliere il maggiore dovrebbe aiutare ad eliminare mini-errorini dovuti all‚Äôimprecisione della somma floating point.\nAlgoritmo\nForma finale scomposizioni üü© Se utilizziamo una sorta di pivoting parziale ossia per ridurre gli errori scegliamo il massimo della colonna (come del resto fa l‚Äôalgoritmo di sopra) allora non abbiamo bisogno di permutare colonne), se vogliamo invece un pivoting totale allora dobbiamo permutare le colonne e la matrice diventa qualcosa del tipo\n$A = QLUP$ con Q le permutazioni su riga, e P quelle su colonna (quelle su colonna non √® che ci importa molto, perch√© basta moltiplicare per $P^T$, ossia la sua inversa per x e si risolvono problemi di questo genere‚Ä¶ dato che alla fine $PP^T = I$\nMetodo di Cholesky üü© Se prendo una matrice A simmetrica definita positiva (ricorda analisi per questo), allora con questo metodo riesco a riscriverla nella forma $A = LL^T$, e so che la matrice L triangolare inferiore non √® singolare perch√© ho tutti gli autovalori positivi.\nQuesto metodo costa $O(n^3/6)$ leggermente pi√π veloce della fattorizzazione di Gauss.\nUna volta fatto la scomposizione poi va subito\n$Ly = b, L^Tx = y$ e si risolve, sul come funziona l\u0026rsquo;algoritmo, per ora ci importa solamente che √® pi√π veloce.\nSe non √® simmetrico o non √® definita positiva il programma crasha.\nMetodo di Schur $$ A = QBQ^{-1} $$ Dove $Q$ √® una matrice di cambio di base. Questa cosa non si pu√≤ fare sempre quando vogliamo che $B$ sia diagonale, per√≤ la decomposizione di Schur ci d√† qualche nota in pi√π riguardo a questo, usando per√≤ matrici upper triangular\nEnunciato di Schur $$ A = BTB^{-1} $$NOTE: se $A$ √® una matrice normale, allora $T$ √® diagonale. Normale quando vale $AA^{*} = A^{*}A$. Con $A^{*}$ la trasposta coniugata della matrice $A$.\nIdee generali per la dimostrazione di Schur In pratica per un teorema dell\u0026rsquo;algebra (quello fondamentale) si ha che $T$, dato che √® quadrata, ha almeno un autovettore, allora prendi questo autovettore, usi il teorema di estensione per creare una base, e scomponi con questo. Questo ti creer√† una matrice a blocchi grossi $2\\times2$ in cui quello in basso a destra √® ancora quadrato con suo sottospazio. Continui cos√¨ finch√© non finisce tutto e resta una matrice upper triangular. Nella reference ci√≤ √® descritto molto bene da un punto di vista intuitivo. La cosa carina con le $T$ √® che per esempio √® spesso pi√π facile elevarli alla potenza, non quanto le diagonali, ma pi√π semplice.\nMatrici semi-definite o definite positive Se prendo un qualunque vettore e vale\n$$ x^TAx \\geq 0 $$Oppure avendo autovalori sempre positivi sono maggiore di 0, si pu√≤ vedere che √® equivalente. Certi autori richiedono anche che la matrice $A$ sia simmetrica.\nGuarda Massimi minimi multi-variabile nella sezione forme quadratiche per questo.\nMetodi iterativi Sono buoni perch√© l\u0026rsquo;errore di questi √® molto pi√π alto, ma spesso molto pi√π veloce, mentre per i metodi diretti √® esattamente il contrario (errore basso, alta complessit√†).\nIn modo molto generale, possiamo definire un metodo iterativo come una funzione $G$ applicata all\u0026rsquo;input stesso: $x_n = G(x_{n - 1})$\nNote introduttive convergenza e iterazione Questa sotto √® la definizione di convergenza ad $\\alpha$ con ordine $p \\geq 1$\nSpesso la convergenza √® fissata da una condizione di arresto (che pu√≤ essere dipendente anche dal numero di iterazioni. Possiamo definire C = fattore di convergenza quando $p = 1$, perch√© pi√π √® piccolo pi√π converge in fretta. C\u0026rsquo;√® anche una relazione simile fra i p, pi√π √® grande, in questo caso, pi√π velocemente converge.\nMetodi iterativi stazionari Idee Generali üü© Questi sono nella forma $x _{k +1} = Hx_k + d_k$ Poi scriverlo come una differenza di matrici in particolare vorre $A = M - N$ , dove $M$ sia non singolare (e possibilmente facilmente invertibile). Se ci√≤ √® possibile allora\n$Ax = b \\implies Mx - Nx = b \\implies x = M^{-1}Nx + M^{-1}b \\implies x = Tx + c$\nUna volta avuto questa matrice $T$ possiamo riutilizzarla per ogni iterazione di successione!\nAvremo che $x_k = Tx_{k - 1} + c$, e si ha che $x* = \\lim x_k$ deve essere che\n$$ x* = Tx* + c $$E vorremmo che questo metodo converga per ogni input quindi potrei mettere un x_0 a casissimo\nUna cosa non espressa durante la lezione √® che $N = M - A$ quindi\n$$ M^{-1}N = M^{-1}(M - A) = I - M^{-1}A $$Che ci permette di scrivere la stessa cosa sente fare utilizzo della matrice $N$ e secondo me √® pi√π clean. Questa cosa √® presente nel libro.\nCondizione necessaria e sufficiente di convergenza üü© Teorema sulla condizione di convergenza:\nQuesto risultato si pu√≤ connettere col raggio spettrale e si pu√≤ concludere che converge sse\n$$ \\rho(T) \u003c 1 $$ Metodo di Jacobi üü© Sia $D$ la parte diagonale di $A$, allora l‚Äôiterazione in questa forma converge e si chiama metodo di jacobi\n$$ x_{k + 1} = (I -D^{-1}A)x_k + D^{-1}b $$Nota: attento che la prof non ha insegnato in questo modo! Quindi probabilmente se te la chiede diglielo nella forma che le piace,\n$M = D, N = E + F$\nMetodo Gauss-Seidel üü© Si ricorda che $A = D - E - F$ in modo molto strano di scriverlo‚Ä¶\nSi fa uso della matrice Lower con anche la diagonale, per il resto √® esattamente uguale a tutto il resto per i metodi iterativi., quindi\n$$ M = D - E, N = F $$Condizioni di convergenza per Jacobi e Gauss-Seidel üü• Per comprendere questa parte √® importante il concetto di matrice con diagonale dominante. In parole umane deve essere che ogni elemento sulla matrice deve essere maggiore della somma di tutto quanto non stia sulla diagonale maggiore.\nSlide condizioni\nNota questi sono in pratica da imparare a memoria, ma non me ne ricordo!\nGradiente coniugato Questo √® un metodo di arresto molto misterioso, direi di cacharla ü§ë.\nMetodi di cui non ha parlato Metodo SOR Metodi di Rilassamento Metodi di Krylov ","permalink":"https://flecart.github.io/notes/algebra-lineare-numerica/","summary":"\u003cp\u003eIn questa sezione andiamo ad indagare metodi di \u003cstrong\u003escomposizione\u003c/strong\u003e, iterativi e non. Ci sono molte matrici importanti per questa parte che dovremmo prendere confidenza.\u003c/p\u003e\n\u003ch4 id=\"immagini\"\u003eImmagini\u003c/h4\u003e\n\u003cp\u003eLab 2 images\u003c/p\u003e\n\u003ch2 id=\"metodo-di-gauss\"\u003eMetodo di gauss\u003c/h2\u003e\n\u003cp\u003eVogliamo cercare un metodo per calcolare soluzioni a sistemi di equazione del genere:\u003c/p\u003e\n\u003cp\u003e$Ax = b$, classico. Supponiamo che questo sistema abbia una soluzione.\u003c/p\u003e\n\u003cp\u003eIl nostro obiettivo sarebbe scomporre la matrice $A = LU$\ncome prodotto di due matrici Lower triangular e Upper triangular.\u003c/p\u003e","title":"Algebra lineare numerica"},{"content":"Strutture algebriche Differenza matematica e informatica Una osservazione per quanto riguarda la logica intuizionista √® che sta a met√† fra matematica e informatica perch√© la dimostrazione intuizionista possiede in s√© un algoritmo e una struttura di dati.\nInfatti di solito l\u0026rsquo;informatico scrive senza fare la dimostrazione dell\u0026rsquo;algoritmo mentre il matematico scrive la dimostrazione senza fare l\u0026rsquo;algoritmo (inoltre pu√≤ definire degli enti ed oggetti che non siano rappresentabili come dati in quanto possono essere infiniti.\nUn opinione personale √® che l\u0026rsquo;informatica √® pi√π pratica, e limitata in quanto non pu√≤ estendersi al ragionamento infinito ma deve essere limitata al calcolo. Questo √® si molto pi√π utile ma molto meno creativo. Si pu√≤ attaccare per√≤ il problema in questi modi!\nOsservazioni generali La matematica utilizza questi metodi da molto tempo prima dell\u0026rsquo;esistenza di una macchina di calcolo.\nI concetti generali di matematica che si sono sviluppati nei secoli sono astrazioni e generalizzazioni. (non esiste ancora una base simile in informatica, e.g. le classi di java hanno proprio degli errori logici al suo interno, anche se non so esattamente quali, ma Coen dice di s√¨)\nAstrazione e generalizzazione Tesi di Church-Turing Vedere La macchina di Turing#Tesi di Church-Turing Guarda Questa tesi (non √® un teorema) definisce il significato di espressivit√† di un linguaggio di programmazione.\nIn altre parole deve avere:\nUn modo di ciclare branching (if condition) E numeri Ma quindi i linguaggi di programmazione non cambiano per capacit√† di calcolo, bens√¨ nella capacit√† di astrazione e generalizzazione.\nAssiomi di Peano Vedere https://it.wikipedia.org/wiki/Assiomi_di_Peano Sono i classici assiomi che caratterizzano i numeri naturali\nEsiste $0$, questo √® facile basta definirlo nel termine (vedi Logica del Primo ordine Esiste la funzione successore I successori si comportano bene ossia $\\forall x \\forall y ((S(x) = S(y)) \\implies x = y)$ Non esiste il predecessore di $0$ ossia $\\neg \\exists x \\mid S(x) = 0$ Esiste sempre il successore se non √® zero, $\\forall x \\mid \\neg(x = 0) \\to \\exists y: S(y) = x$ Wiki prende questo passo leggermente diverso, ma forse il concetto √® esattamente lo stesso. Astrazione Vedere note come Astrazione sul controllo per altri generi di astrazione, comunque √® una cosa molto importante per informatica e scienze.\nAlcune caratteristiche le trascuro perch√© sono accessorie (dipendono dall\u0026rsquo;implementazione, dal caso specifico), questo mi permetti cambiare una implementazione trattenendo aspetti degli oggetti che mi interessino. esempio di astrazione √® il quozientamento perch√© in questa operazione trattenevo solamente gli aspetti che mi interessavano buttando via tutto il resto. (il quozientamento non esiste in programmazione per la sua incapacit√† di gestire l\u0026rsquo;infinito)\nEsempio implementazione e astrazione di numeri naturali\nL\u0026rsquo;implementazione posso farla in molti modi, qui ne sono rappresentati due.\nMentre il concetto astratto sono le regole che mi definiscono l\u0026rsquo;ente (in questo caso gli assiomi di peano, il fatto che devo avere uno Zero una successione e l\u0026rsquo;insieme generali dei numeri naturali, un elemento appartiene a questo insieme solamente se √® uguale allo zero oppure √® un successore di un numero di questo insieme. S deve essere iniettiva. E nessun successore √® uguale allo zero).\nEsempio implementazione e astrazione liste di interi\nGeneralizzazione Quindi vorrei che una caratteristica in un caso particolare sia vero anche in molti altri casi!\nBenefici di ci√≤ (4) Struttura algebrica L\u0026rsquo;elemento neutro (generalizzazione di essa) Si una generalizzazione esiste ed √® questa:\nQueste generalizzazioni sono utili nel caso mi creino una teoria utile da studiare dal punto di vista astratto (cos√¨ posso scoprire altre propriet√†).\nSe questa teoria √® utile per comprendere concetti pi√π bassi (dal punto di vista di livelli di astrazione) allora posso dire che queste sono teorie informative.\nDefinizione struttura algebrica Il magma √® il concetto fondamentale per una struttura algebrica come in definizione.\nChiamiamo magma perch√© non √® ancora solidificato, qualcosa di abbastanza astratto. Dopo avere introdotto questi concetti astratti posso studiarle! Posso studiare una cosa che ho creato, mi piace sta scienza, perch√© chi ha creato qualcosa non sa a priori bene cosa ha creato.\nProdotto cartesiano in left unital magma Nell\u0026rsquo;esempio C √® un prodotto cartesiano di R per questo motivo riesco a dirlo da questa generalizzazione!\nMorfismi Il morfismo mi permette di preservare alcune propriet√† che perdo in astrazione\u0026rsquo;s trasformazione (un esempio √® la perdita della struttura di numeri quando lo rappresento con un LUM (Left Unital Magma)\nQuesto concetto √® importante anche in informatica perch√© vuol dire che posso prima applicare la funzione sulla somma di implementazioni oppure applicarli singolarmente.\nIsomorfismo L\u0026rsquo;isomorfismo √® simile a un morfismo a due parti (in cui vale questa relazione in entrambe le parti) quindi funzione bigettiva in cui anche l\u0026rsquo;inverso sia un morfismo. Questa cosa mi dice che esiste una certa corrispondenza fra strutture algebriche.\nEnunciato ed esempio\n","permalink":"https://flecart.github.io/notes/algebra-logica/","summary":"\u003ch1 id=\"strutture-algebriche\"\u003eStrutture algebriche\u003c/h1\u003e\n\u003ch2 id=\"differenza-matematica-e-informatica\"\u003eDifferenza matematica e informatica\u003c/h2\u003e\n\u003cp\u003eUna osservazione per quanto riguarda la logica intuizionista √® che sta a met√† fra matematica e informatica perch√© la \u003cem\u003edimostrazione intuizionista possiede in s√© un algoritmo e una struttura di dati.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eInfatti di solito l\u0026rsquo;informatico scrive senza fare la dimostrazione dell\u0026rsquo;algoritmo mentre il matematico scrive la dimostrazione senza fare l\u0026rsquo;algoritmo (inoltre pu√≤ definire degli enti ed oggetti che non siano rappresentabili come dati in quanto possono essere infiniti.\u003c/p\u003e","title":"Algebra Logica"},{"content":"Algebra modulare Assunzioni Andiamo ora ad assumere l\u0026rsquo;esistenza e correttezza di alcune cose di base. (in teoria si possono dimostrare da cose pi√π di base, ma non ho tempo).\nTeorema fondamentale dell\u0026rsquo;algebra Ogni numero intero si fattorizza in modo unico.\nAlgoritmo di Euclide La conseguenza pi√π importante di questo teorema, dovuto ad Euclide √® che se ho $a, b \\in \\mathbb{Z}$ allora esistono resto e dividendo fra i due. Ossia $\\exists q, p : a\\mid b = qk + p$ per qualche $k$ intero\nDare una occhiata all\u0026rsquo; implementazione potrebbe essere interessante.\nMCD e divisibilit√† Se $a \\mid d$ e sono interi allora esiste esiste c tale per cui d = ca. (tutti interi senza restrizioni) mcd fra interi a e b √® il pi√π grande intero che divide sia a sia b. Osservazione: $mcd(a, 0) = a$\nTeorema di B√©zout che dice che esistono r ed s tali che per ogni 2 interi a,b ho che ar + sb = gdc(a,b); E da questo possiamo andare a fare algoritmo di Euclide esteso.\nClassi di resto modulo n Si dicono che $a \\equiv b \\mod n \\iff n | a - b$\nSI indica con $[a]_n = \\{ b \\in \\mathbb{Z} :b \\equiv a \\mod n\\}$ elementi la cui differenza con a √® divisibile per n\nE indichiamo con $\\mathbb{Z}_n$ come l\u0026rsquo;insieme di tutte le classi di equivalenza ossia $\\{[[a]_n : a \\in \\mathbb{Z}\\}$ ossia insieme quoziente, Relazioni fra insiemi.\nDimostrazione classe di equivalenza Riflessivit√†\nsi ha che $n | a- a \\iff n | 0$ che √® vero\nSimmetrica\nse $a \\equiv b \\iff b \\equiv a$ in quanto se $a \\equiv b \\iff n | a - b \\iff n | b - a \\iff b \\equiv a$ (cio√® basta moltiplicare per qualcosa di negativo, si ha lo stesso risultato\nTransitiva, mi sono rotto\nAllora sappiamo di avere una classe di equivalenza (una partizione su Z in pratica).\nProp equivalenza con resto Sia $a\\in \\mathbb{Z}$ e r il suo resto di divisione per n, allora $a \\equiv r \\mod n$ ossia appartengono alla stessa classe di equivalenza\nProp costituzione dell\u0026rsquo;insieme quoziente Per la proposizione precedente posso trovare proprio come √® costituito\n$Z_n = \\{[0]_n, [1]_n...,[n-1]_n\\}$\nDimostrazione:\ndimostrare che $\\impliedby$ ossia destra √® contenuto in sinistra √® ovvio per definizione di Zn, per dimostrare che $\\implies$si utilizza la proposizione sopra:\nSia $[a]_n \\in \\mathbb{Z}_n$ per proposizione sopra si ha che $[a]_n = [r]_n \\in \\{[0]_n,...,[n - 1]_n\\}$\nPer concludere (se voglio dimostrare nel modo classico utilizzando classe di equivalenza) devo dimostrare che tutte le classi presenti in Zn sono effettivamente distinte.\nPrendo $i,j \\in [0...n-1]$ wlog $i \u003e j$ allora $0 \u003c i - j \\leq i \\leq n- 1$ allora $n \\not | i-j,$ quindi si ha che $i \\not\\equiv j \\mod n$ e questo conclude che Zn ha n elementi\nSomma e prodotto in questa classe La definizione di classe modulo resto in questo modo √® molto simile alla classica definizione di somma e prodotto (ma non per la divisione, non √® sempre invertibile).\nE si dimostrano anche\nCommutativit√† Associativit√† Distributivit√† (entrambe, destro e sinistra) C\u0026rsquo;√® il neutro per la somma Prop. invertibilit√† di una classe Si dice che $[a]_n \\in \\mathbb{Z}_n$ √® invertibile se esiste $[b]_n \\in \\mathbb{Z}_n : [a][b] = [1]$ (sottinteso indici)\nSi dimostra che √® invertibile se solo se √® co-primo col modulo poi (perch√© con Euclide esteso riesco a trovarmi l\u0026rsquo;inversa).\nProp. unica soluzione diofantea √à un corollario della precedente, praticamente dice che se $ax = b, gcd(a,n) = 1$ allora esiste una unica soluzione.\nUn approfondimento √® presente nella teoria dei gruppi per sta parte (le cose che potrebbero essere interessanti sono i Campi da questo punto di vista). Vedere Gruppi Gruppi ciclici e permutazioni e Gruppi Normali.\n","permalink":"https://flecart.github.io/notes/algebra-modulare/","summary":"\u003ch1 id=\"algebra-modulare\"\u003eAlgebra modulare\u003c/h1\u003e\n\u003ch2 id=\"assunzioni\"\u003eAssunzioni\u003c/h2\u003e\n\u003cp\u003eAndiamo ora ad assumere  l\u0026rsquo;esistenza e correttezza di alcune cose di base. (in teoria si possono dimostrare da cose pi√π di base, ma non ho tempo).\u003c/p\u003e\n\u003ch3 id=\"teorema-fondamentale-dellalgebra\"\u003eTeorema fondamentale dell\u0026rsquo;algebra\u003c/h3\u003e\n\u003cp\u003eOgni numero intero si fattorizza in modo unico.\u003c/p\u003e\n\u003ch3 id=\"algoritmo-di-euclide\"\u003eAlgoritmo di Euclide\u003c/h3\u003e\n\u003cp\u003eLa conseguenza pi√π importante di questo teorema, dovuto ad Euclide √® che\nse ho $a, b \\in \\mathbb{Z}$ allora esistono resto e dividendo fra i due. Ossia\n$\\exists q, p : a\\mid b = qk + p$ per qualche $k$ intero\u003c/p\u003e","title":"Algebra modulare"},{"content":" \u0026ldquo;Information theory must precede probability theory, and not be based on it. By the very essence of this discipline, the foundations of information theory have a finite combinatorial character.\u0026rdquo; Kolmogorov, A. N. (1983).¬†Combinatorial foundations of information theory and the calculus of probabilities.\nRussian mathematical surveys,¬†38¬†(4), 29-40.\n\u0026ldquo;it is clear that elements requiring an extremely large number of words for their definition should be considered as having an extremely low probability.\u0026rdquo; (Borel E.,¬†1909¬†p. 272).\nQuesta sezione si distacca dalla probabilit√† classica che abbiamo fatto in questo corso, ma per vicinanza metto qui l\u0026rsquo;appunto.\nPrefix Complexity Definizione $$ K(s) = min_{p}\\left\\{ \\lvert p \\rvert : U_{pr}(p) = s \\right\\} $$ L\u0026rsquo;unica differenza con Kolmogorov complexity √® che qui usiamo una macchina di turing con prefix codes.\nIntuizione $$ P(x) = \\sum_{p:U(p)=x} 2^{-l(p)} $$$$ P(x) \\approx 2^{-K(x)} $$Per $K$ vedi Kolmogorov complexity. TODO: cercare di capire perch√© limitarsi solamente alla versione pi√π corta.\nPrefix Machine Da Leonid Levin, risolve il problema di termine di interpretazione, perch√© prefix codes hanno valore sempre minore di 1 come descritto in Entropy#Krafts Inequality. Se non si escludono, fanno qualcosa di brutto con quel valore di probabilit√†, perch√© la somma di tutti avrebbe superato $1$ e non avrebbe soddisfatto gli assiomi La propriet√† principale √® che non esistono due programmi per questa macchina tale per cui uno sia prefisso di altro.\nSelf delimiting codes Con i prefix codes posso avere delle cose self-delimiting, perch√© so quando un codice finisce e posso interpretarlo per la propriet√† dei prefissi.\nOne example of self-delimiting code is the Gamma Code. Where there are ones to mark the length of the next sequence. You don\u0026rsquo;t need fixed length bytes in these cases. See wiki for more information.\nDefinition of prefix complexity Praticamente per encodare un numero encodiamo la sua lunghezza binaria con un codice e poi concateniamo il numero stesso. $$ 2\\log \\log(\\lvert s \\rvert ) + \\lvert s \\rvert $$Relazione con complessit√† normale $$ C(s) + O(1) \\leq K(s) \u003c C(s) + 2\\log(C(s)) + O(1) $$ La prima diseguaglianza sembra essere presa da Kolmogorov complexity#Teorema dell\u0026rsquo;invarianza, mentre la seconda dallo stesso teorema pi√π dal fatto che stiamo usando una macchina di Turing con prefissi.\nAlgorithmic probability Definizione algorithmic probability $$ \\mathbb{P}(x) = \\sum_{p:U(p)=x} 2^{-l(p)} $$ TODO: sarebbe carino provare ad esplorare di pi√π questo topic, perch√© mi sembra abbia belle connessioni con resto. Poi un sacco di questo content √® bloggabile.\n","permalink":"https://flecart.github.io/notes/algorithmic-probability/","summary":"\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003e\u0026ldquo;Information theory must precede probability theory, and not be based on it. By the very essence of this discipline, the foundations of information theory have a finite combinatorial character.\u0026rdquo;\u003c/em\u003e  Kolmogorov, A. N. (1983).¬†\u003ca href=\"http://rainbow.ldeo.columbia.edu/~alexeyk/Papers/Kolmogorov1983.pdf\"\u003eCombinatorial foundations of information theory and the calculus of probabilities\u003c/a\u003e.\u003cbr\u003e\n\u003cem\u003eRussian mathematical surveys\u003c/em\u003e,¬†\u003cem\u003e38\u003c/em\u003e¬†(4), 29-40.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003e\u0026ldquo;it is clear that elements requiring an extremely large number of words for their definition should be considered as having an extremely low probability.\u0026rdquo;\u003c/em\u003e (Borel E.,¬†\u003ca href=\"https://link.springer.com/content/pdf/10.1007/BF03019651.pdf\"\u003e1909\u003c/a\u003e¬†p. 272).\u003c/p\u003e","title":"Algorithmic Probability"},{"content":"6.1 Introduzione 6.1.1 L‚Äôimportanza del topic Gli algoritmi di ordinamento sono molto di base per la comprensione dell\u0026rsquo;ampio raggio degli algoritmi. Utilizzano l\u0026rsquo;analisi, introducono tecniche di risoluzione dei problemi computazionali come greedy, divide et impera e simile. Permettono un primo uso di astrazioni e l\u0026rsquo;analisi di sottoproblemi.\n6.1.2 Il problema Il problema √® trovare una permutazione di un insieme di numeri iniziali tale per cui tale insieme di numeri si ordinato:\nQuesto si pu√≤ fare con qualunque collezione confrontabile fra di loro.\nSlide\nLoco: non vengono utilizzati array di appoggio, per esempio un quicksort sar√† di in loco, mentre mergesort no.\nStabile: se due elementi hanno la stessa chiave, questi compaiono con lo stesso ordine nell\u0026rsquo;array ordinato, per esempio radix sort √® stabile, merge sort √® stabile.\n6.2 Algoritmi incrementali Si possono dire incrementali algoritmi che si dimostrano in \u0026ldquo;maniera greedy\u0026rdquo;, ossia creano un sottoaray ordinato k, e al prossimo passo provano a creare un array k + 1.\n6.2.1 Selection sort Si trova l\u0026rsquo;elemento pi√π piccolo all\u0026rsquo;interno di $(k+1,n)$ e lo si swappa con quello in posizione k + 1, si continua cos√¨ fino a quando l\u0026rsquo;array non sia ordinato. NO stabile (spara dall\u0026rsquo;altra parte l\u0026rsquo;elemento con cui swappa).\nUna propriet√† che possiede selection ma non insertion √® che:\n$\\forall e \\in (1,k), \\forall b \\in (k + 1, n), e ","permalink":"https://flecart.github.io/notes/algoritmi-di-ordinamento/","summary":"\u003ch2 id=\"61-introduzione\"\u003e6.1 Introduzione\u003c/h2\u003e\n\u003ch3 id=\"611-limportanza-del-topic\"\u003e6.1.1 L‚Äôimportanza del topic\u003c/h3\u003e\n\u003cp\u003eGli algoritmi di ordinamento sono molto di base per la comprensione dell\u0026rsquo;ampio raggio degli algoritmi. Utilizzano l\u0026rsquo;analisi, introducono tecniche di risoluzione dei problemi computazionali come greedy, divide et impera e simile. Permettono un primo uso di astrazioni e l\u0026rsquo;analisi di sottoproblemi.\u003c/p\u003e\n\u003ch3 id=\"612-il-problema\"\u003e6.1.2 Il problema\u003c/h3\u003e\n\u003cp\u003eIl problema √® trovare una permutazione di un insieme di numeri iniziali tale per cui tale insieme di numeri si ordinato:\u003c/p\u003e","title":"Algoritmi di ordinamento"},{"content":"Ambienti di sviluppo Ambiente di sviluppo √® diverso rispetto all‚Äôambiente di deploy! bisognare fare delle differenze, sono dell macchine diverse, in questa sezione di documenti andiamo a parlare di norme e modi di lavorare per facilitare il metodo di sviluppo.\nNote di compatibilit√† Front-end Le compatibilit√†, soprattutto per cose browser (quindi front-end) cambiano molto spesso, come fare a trackare queste cose? C\u0026rsquo;√® un sito molto carino come https://caniuse.com/ .\nLa browser list, √® utilizzata per specificare unt browser di target per la nostra applicazione, non ho capito bene cosa serve.\nI *polifylli permettonol‚Äôesecuzione di codice recente\nGestione versioni Si utilizzano cose come package json, e tools come npm e yarn per gesitire queste dipendenze. Nei file lock ci sono gli hash, ti dice quale specifica versione funziona (praticamente serve per dirti esattamente tutte le cose necessarie per l‚Äôambiente di deploy, per questo lo devi committare! come il go sum). √à necessario, senn√≤ sono in dependency hell (una dipendenza che aggiunge una dipendenza di altre dipendenze, pu√≤ rallentare tutto), non riesco a gestire tutte queste velocemente!\nPoi si dividono in\ndevDependency quando √® solamente per lo sviluppo come linter, o file cli dependency quando serve per l\u0026rsquo;esecuzione del programma. semantic versioning\nSlide semantic versioning\nCi danno gi√† informazioni su compatibilit√†, versioni accettate e cose simili.\nStile Strumenti come esling, prettier, permettono di fare contorllo sullo stile, e anche correggerle in automatico! Queste fanno una analisi statica del codice e riformattano, oppure ti ritornano alcuni pezzi di roba ambigua.\nDi solito conviene perch√© rende il codice molto pi√π agibile e comprensibile dal team.\nCose come parentesi, indentazioni, sono importanti, anche ad esempio utilizzare stessi cases.\nType checking Slide typescript\nAbbiamo tutte le garanzie di Teoria dei Tipi! In pratica √® molto buono utilizzare questo\nTraspiler √à simile alla compilazione, ma √® fra linguaggi allo stesso livello (ad esempio versioni diverse di javascript, per essere comprensibile fra versioni browser diversi), mentre compilazione secondo vitali √® da linguaggi di alto livello a uno di livello inferiore, anche se non credo fosse questa la definizione in Macchine Astratte.\nReact utilizza molto babel, che √® il traspilatore principale per questo.\nMinifier e obfuscating vogliamo cercare di ridurre caratteri, in modo da minimizzare la grandezza del file di output mantenendone la semantica (quindi cosa faccia). Ci serve per esempio se vogliamo dare un file JS, ma vogliamo limitare la banda, per trasmettere le stesse informazioni.\nWebpack, un bundler che vedremo dopo riesce anche a fare minify.\nQuesta cosa √® molto diversa rispetto a offuscare!\noffuscare serve per rendere il coidce illeggibile, in modo da rendere pi√π difficile la comprensione del codice, e quindi da farci reverse engineering e scoprire vulnerabilit√† e simili ma anche per evitare di copiare l\u0026rsquo;applicaione e replicarlo altrove, anche questi sono fatti in automatico da certe applicazioni.\nRiassunto in breve traspiler minifier, obfuscating e compressione\nBundlers Ci sono molti bundlers il pi√π comune √® webpack.\nL‚Äôobiettivo √® mettere assieme tutti i moduli js in modo che sia solo 1, quindi molto pi√π efficiente da dare al web.\nAltro Sta facendo una lista di un sacco di tecnologie!!! üò±.\nMeglio andare a studiarseli da soli perch√© la lista non me ne facio niente, √® utile per√≤ sapere che esistono.\nDeve continuare dal testing\n","permalink":"https://flecart.github.io/notes/ambienti-di-sviluppo/","summary":"\u003ch1 id=\"ambienti-di-sviluppo\"\u003eAmbienti di sviluppo\u003c/h1\u003e\n\u003cp\u003eAmbiente di sviluppo √® diverso rispetto all‚Äôambiente di deploy! bisognare fare delle differenze, sono dell macchine diverse, in questa sezione di documenti andiamo a parlare di norme e modi di lavorare per facilitare il metodo di sviluppo.\u003c/p\u003e\n\u003ch2 id=\"note-di-compatibilit√†\"\u003eNote di compatibilit√†\u003c/h2\u003e\n\u003ch3 id=\"front-end\"\u003eFront-end\u003c/h3\u003e\n\u003cp\u003eLe compatibilit√†, soprattutto per cose browser (quindi front-end) cambiano molto spesso, come fare a trackare queste cose? C\u0026rsquo;√® un sito molto carino come \u003ca href=\"https://caniuse.com/\"\u003ehttps://caniuse.com/\u003c/a\u003e .\u003c/p\u003e\n\u003cp\u003eLa \u003cstrong\u003ebrowser list\u003c/strong\u003e, √® utilizzata per specificare unt browser di target per la nostra applicazione, non ho capito bene cosa serve.\u003c/p\u003e","title":"Ambienti di sviluppo"},{"content":"Relazioni con fili - Ampere Legge di Biot-Savart/Formalizzazione esperienza di Ampere üü© Poniamo che ho due fili in cui scorra della corrente, voglia capire la forza per unit√† di lunghezza del filo uno su due e viceversa.\nSo che entrambi generano campo magnetico So che il campo magnetico induce forza su correnti in movimento. Supponiamo che la loro distanza sia $D$, allora avremo che: Per la prima legge so: $$ d\\vec{B} = \\mu_{0}i d\\vec{l} \\times \\frac{\\hat{r}}{4\\pi r^{2}} $$ da questo posso calcolare il campo magnetico totale, in un modo simile a quanto fatto in precedenza per il campo elettrico (solo che in questo caso abbiamo il prodotto seno, quindi l\u0026rsquo;angolo che conviene scegliere √® un po\u0026rsquo; diverso), e una volta che ho questo posso usare la seconda legge per avere la forza, questo √® il piano. $$ \\vec{B} = \\int _{Filo} \\frac{\\mu_{0}i}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}} = \\hat{k} \\frac{\\mu i}{4\\pi} \\int_{-\\frac{\\pi}{2}}^{+\\pi/2} \\frac{dl}{r^{2}} \\sin \\theta $$$$ r\\sin \\theta = D \\implies r = \\frac{D}{\\sin \\theta} $$$$ \\frac{D}{l} = \\tan \\theta \\implies l = \\frac{D}{\\tan \\theta} \\implies dl = D \\frac{d\\theta}{\\sin ^{2}\\theta} $$$$ \\lvert \\vec{B} \\rvert = \\frac{\\mu_{0}i}{4\\pi} \\int _{\\pi}^{0} \\frac{\\sin \\theta}{D} d\\theta \\, dx = \\frac{\\mu_{0}i}{4\\pi D} (-\\cos \\theta) ^{0}_{\\pi} = \\frac{\\mu_{0}i}{2\\pi D} $$ Da qui abbiamo ottenuto la legge di Biot Savart. Qui notiamo che il campo magnetico circola intorno al filo (√® tangente al campo magnetico in questo caso, molto simile). Possiamo utilizzare questo per calcolare la forza applicata in un tratto di filo:\n$$ d\\vec{F} = i_{2}d\\vec{l} \\times (-\\vec{k})\\frac{\\mu i_{1}}{2\\pi D} $$$$ d\\vec{F} = \\frac{i_{1}i_{2}}{2\\pi D} d\\vec{l} \\implies \\vec{F} = \\frac{i_{1}i_{2}L}{2\\pi D} $$ Questo vale perch√© abbiamo considerato fili infiniti rettilinei. Per la terza legge della dinamica la forza esercitata da due su uno √® la stessa, invertita per√≤, e questo conferma anche quanto sperimentalmente trovato con l\u0026rsquo;esperienza di ampere\nDefinizioni di dimensioni üü© L\u0026rsquo;ampere posso definirlo in questo modo: corrente percorsa in due fili paralleli nel momenti in cui la distanza √® un singolo metro, e la lunghezza √® un metro e ho una forza uguale a $2\\times 10^{-7} N$ . Questo poi mi permette di definire il Coulomb in termini di corrente. √à una definizione utile per anche avere in automatico il valore di $\\mu_{0}$ (quindi molto artificiale secondo me).\nOsservazioni\nLinee chiuse del campo $\\vec{B}$ il flusso √® nullo, perch√© le linee sono chiuse (questo √® coerente con Gauss) Posso usare la regola della mano destra per sapere la direzione del campo magnetico Posso calcolare la circuitazione del campo magnetico generato da una corrente Posso calcolare la circuitazione, e scelgo una circonferenza chiusa:\nCircuitazione del campo magnetico (!) üü© $$ \\oint_{\\Gamma} \\vec{B}d\\vec{r} = \\oint_{\\gamma} \\frac{\\mu_{0}i}{2\\pi} \\frac{dr}{R} = \\frac{\\mu_{0}i}{2\\pi} \\frac{1}{R} \\oint_{\\gamma} dr = \\frac{\\mu_{0}i}{2\\pi} \\frac{1}{R} 2\\pi R = \\mu_{0}i $$ Ossia dipende dalla corrente. La stessa relazione vale anche se scelgo un percorso spezzato! perch√© se scelgo il raggio, in quel caso la circuitazione √® nulla, perch√© √® perpendicolare alla direzione del campo! Il motivo √® perch√© come sopra i raggi si semplificano, e rimane solamente l\u0026rsquo;angolo, che si semplificher√† alla fine.\nProviamo a formalizzare questo discorso, poniamo di avere due circonferenze concentriche che rappresentano la direzione del nostro campo magnetico, poniamo che il tratto sul $R_{1}$ sia di $\\theta_{1}$ e il tratto su $R_{2}$ sia di $\\theta_{2}$ , e che $\\theta_{1} + \\theta_{2} = 2\\pi$, abbiamo allora che\n$$ \\oint_{\\Gamma} \\vec{B} d\\vec{r} = \\frac{\\mu_{0}i}{2\\pi} \\left( \\frac{1}{R_{1}} \\theta_{1}R_{1} + \\frac{1}{R_{2}} \\theta_{2}R_{2} \\right) = \\mu_{0}i $$ Questo discorso ha delle similitudini con l\u0026rsquo;analisi del Potenziale elettrico in Campo elettrico. Anche l√¨ spezzettavamo, e concludevamo conservativit√† per cose radiali.\nLegge di Ampere üü© La circuitazione di $\\vec{B}$ lungo una qualsiasi linea chiusa Gamma, √® pari all\u0026rsquo;intensit√† di corrente complessiva concatenata alla linea chiusa moltiplicata per la permeabilit√† magnetica del vuoto\nQuesto √® motivato da quanto fatto sopra per la circuitazione del campo magnetico, solo che quando l\u0026rsquo;abbiamo derivato l\u0026rsquo;abbiamo fatto per un filo rettilineo uniforme.\nIn un certo senso questa legge √® simile a Legge di Gauss perch√© consideriamo solamente le correnti dentro alla nostra circuitazione (come per gauss si considerava solamente le cariche all\u0026rsquo;interno).\nCorrente concatenata (!!) üü© $$ i = \\int _{\\Sigma} \\vec{J} \\cdot d\\vec{s} $$$$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{r} = \\mu_{0} \\int _{\\Sigma(\\Gamma)} \\vec{J} \\cdot d\\vec{s} $$Ampere in forma differenziale üü© Guardare Divergenza e Circuitazione, √® il teorema di Stokes quello che utilizziamo:\n$$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{r} = \\int _{\\Sigma(\\Gamma)} \\vec{\\nabla} \\times \\vec{B} \\cdot d\\vec{s}= \\mu_{0} \\int _{\\Sigma(\\Gamma)} \\vec{J} \\cdot d\\vec{s} $$$$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} $$ Da cui abbiamo ancora che $B$ non √® conservativo, e quindi non ha senso chiedersi del lavoro fatto dal campo.\nTerza legge di Maxwell (Ampere-Maxwell) üü© $$ \\begin{cases} \\vec{\\nabla} \\cdot \\vec{J} + \\frac{\\delta \\rho}{\\delta t} = 0 \\\\ \\vec{\\nabla} \\cdot \\vec{E} = \\frac{\\rho}{\\varepsilon_{0}} \\implies \\rho = \\varepsilon_{0} \\vec{\\nabla}\\cdot \\vec{E} \\end{cases} \\implies $$$$ \\implies \\vec{\\nabla} \\cdot \\vec{J} = -\\left( \\varepsilon_{0} \\vec{\\nabla} \\frac{\\delta \\vec{E}}{dt} \\right) \\implies \\vec{\\nabla}\\left( \\vec{J} + \\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} \\right) = 0 $$ Questa legge vale non solo per il caso stazionario (esteso). In $J$ sono presenti le correnti concatenate, ma anche quelle atomiche (le correnti di magnetizzazione esplorate in Magnetismo nella materia).\nDa questo possiamo ricavare la altra legge di Maxwell (inizialmente non considerato dalla Royal Academy, sar√† utilizzabile solo per correnti non stazionarie)\n$$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$$$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{r} = \\mu_{0} \\int _{\\Sigma(\\Gamma)} \\vec{J} \\cdot d\\vec{s} + \\mu_{0}\\varepsilon_{0} \\frac{d\\left( \\int _{\\Sigma(\\Gamma)} \\vec{E} \\, ds \\right)}{dt} $$Questo √® fondamentale! Perch√© basta far variare il campo elettrico e questo crea un campo magnetico!\nSono quattro equazioni differenziali a derivate parziali (stessa cosa per il campo elettrico), e con questo si pu√≤ risolvere tutto.\nDensit√† di corrente di spostamento üü© $$ \\vec{J}_{s} = \\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$ Guardare Condensatori nel vuoto per il ragionamento sul condizionatore e corrente di spostamento. Si chiama corrente perch√© ha le stesse dimensioni delle correnti.\nUna nota interessante √® vedere questo come viene derivato: Partendo dalla equazione di continuit√† della corrente, abbiamo che\n$$ \\vec{\\nabla} \\cdot \\vec{J} = - \\frac{\\delta \\rho}{\\delta t} = -\\frac{\\delta}{\\delta t} (\\varepsilon_{0} \\vec{\\nabla} \\cdot \\vec{E}) \\implies \\vec{\\nabla} \\cdot \\left( \\vec{J} + \\frac{\\delta}{\\delta t} (\\varepsilon_{0} \\vec{E}) \\right) = 0 $$ E dato che sommo anche quello √® una densit√†, e la chiamo densit√† di corrente di spostamento.\nCampi magnetici non stazionari Questi possono indurre una forza elettromotrice. Faraday ha indagato questa possibilit√† e attraverso molti esperimenti si cerca di verificare questo.\nEsperimento di Faraday per campi magnetici non stazionari üü® 1. Magnete statico: Ha messo prima una calamita su un circuito, ma questo non genera corrente 2. Magnete in estrazione: genera una corrente che nel solenoide (comunque spira) ha un campo magnetico attrattivo 3. Magnete in inserimento: campo magnetico repulsivo generato dalla corrente Osservazioni:\nLa corrente √® pi√π grande quanto √® pi√π grande la velocit√† v Quando la calamita √® dentro al solenoide, non si ha corrente Si ha una forza opposta al movimento Viene generata corrente Invertendo i poli si ha la stessa cosa (solo con verso della corrente opposta). Questi risultati sono uguali quando si usa un circuito affacciato al primo (ci sono esattamente le stesse cose di prima). -\u0026gt; Un flusso variabile pu√≤ generare forza elettromotrice.\nQuarta legge di Maxwell (Faraday-Neumann-Lenz) üü© $$ \\varepsilon_{IND} = -\\frac{d\\Phi(\\vec{B})}{dt} \\implies \\oint_{\\Gamma} \\vec{E} \\cdot \\vec{r} = -\\frac{d\\Phi(\\vec{B})}{dt} = - \\frac{d}{dt} \\left( \\int _{\\Sigma(\\Gamma))} \\vec{B} \\cdot d\\vec{s} \\, \\right) $$$$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} $$ In cui ho una informazione puntuale.\nEnunciato in modo matematico da Ampere, e attraverso testo da Faraday. Che √® in pratica il risultato sperimentale osservato precedentemente.\nA volte il fatto che √® opposto si dice che sia grazie agli esperimenti di Lenz. ed √® necessaria per la conservazione dell\u0026rsquo;energia. L\u0026rsquo;orientazione della superficie $\\Sigma$ √® data dalla regola della mano destra (e quindi decide il verso).\nPossiamo individuare tre casi in cui la variazione non √® nulla, li andiamo a discutere uno a uno.\n$B = f(t)$ $\\theta = \\theta(t)$ $\\Sigma = \\Sigma(t)$ Angolo variabile nel tempo üü© $$ \\Phi(\\vec{B}) = \\int _{\\Sigma} \\vec{B} \\cdot \\, d \\vec{s} = BS \\cos \\theta(t) \\implies \\varepsilon_{IND} = BS \\sin \\theta \\omega $$ Qui abbiamo una corrente alternata. √à interessante notare che abbiamo corrente alternata anche se non c\u0026rsquo;√® nessuna forza elettromotrice.\nFlusso variabile nel tempo üü© Supponiamo di avere un circuito in parallelo con una corrente che cambia intensit√†, cos√¨ ho un flusso distante.\n$$ \\varepsilon_{IND} = -d \\frac{\\Phi(\\vec{B})}{dt} = i_{I}R $$ Con $R$ la resistenza del circuito e $i_{I}$ la corrente indotta. Per il verso della superficie √® uguale, si fa una assunzione sul verso della corrente e poi si avr√† il verso della corrente vera come segno.\ncalcoliamo il flusso allora:\n$$ \\Phi(\\vec{B}) = \\int _{\\Sigma} \\lvert \\vec{B} \\rvert \\, d\\vec{S} = \\int _{\\Sigma} \\frac{\\mu_{0}i}{2\\pi r}\\, \\vec{dS} = \\frac{\\mu_{0}i}{2\\pi} \\int_{D}^{D+L} \\frac{1}{r}L\\, dr = \\frac{\\mu_{0}iL}{2\\pi} \\ln\\left( \\frac{D+L}{D} \\right) $$$$ \\frac{d\\Phi(\\vec{B})}{dt} = \\frac{\\mu_{0}L}{2\\pi} \\ln\\left( \\frac{D+L}{D} \\right)k $$ Con questo poi posso descrivere la FEM indotta e quindi avere la direzione della corrente\nArea variabile nel tempo üü© Consideriamo un circuito con una barra che si muove di velocit√† costante, in questo senso varia l'area, e un campo magnetico uscente costante, sappiamo che $A = x_{0} + vt$ Allora $$ \\Phi(\\vec{B}) = \\oint_{\\Sigma} \\lvert \\vec{B} \\rvert d\\vec{S} = -BS(t) $$ Abbiamo allora che $$ \\varepsilon_{IND} = BLv $$ Notiamo che abbiamo bisogno di una forza per continuare a tenerlo La forza che viene applicata √®\n$$ \\vec{F} = i_{I}lB \\hat{r} = \\frac{BLv}{R} LB = \\frac{B^{2}L^{2}v}{R} $$ Per avere velocit√† costante, bisogna avere una forza che annulli questo, in modo che sia inerziale.\nBarra in movimento üü© Da questo esperimento proveremo che correnti vengono generati anche nel vuoto. Consideriamo una barretta che si muove in un campo magnetico costante. Allora abbiamo che deve valere $$ qvB = qE_{IND} \\implies E_{IND} = vB $$ E sapendo che in questo caso semplice abbiamo $$ \\Delta V = \\int_{\\Gamma}\\vec{E} d\\vec{l} = El $$ $$ \\Delta V = vBl $$ Questa √® la differenza di potenziale generata all\u0026rsquo;interno. Abbiamo una giustificazione che la forza elettromotrice √® generata dalla forza di Lorentz, e questo funziona anche nello spazio vuoto. E solitamente questo non √® conservativo (se √® indotto non √® statico solitamente, perch√© ci sar√† qualcosa che varia).\nVogliamo cercare di ricavare una equazione di conservazione dell\u0026rsquo;energia in elettromagnetismo classico\n","permalink":"https://flecart.github.io/notes/ampere-e-faraday/","summary":"\u003ch3 id=\"relazioni-con-fili---ampere\"\u003eRelazioni con fili - Ampere\u003c/h3\u003e\n\u003ch4 id=\"legge-di-biot-savartformalizzazione-esperienza-di-ampere-\"\u003eLegge di Biot-Savart/Formalizzazione esperienza di Ampere üü©\u003c/h4\u003e\n\u003cp\u003ePoniamo che ho due fili in cui scorra della corrente, voglia capire la forza per unit√† di lunghezza del filo uno su due e viceversa.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSo che entrambi generano campo magnetico\u003c/li\u003e\n\u003cli\u003eSo che il campo magnetico induce forza su correnti in movimento.\nSupponiamo che la loro distanza sia $D$, allora avremo che:\nPer la prima legge so:\n$$\nd\\vec{B} = \\mu_{0}i d\\vec{l} \\times \\frac{\\hat{r}}{4\\pi r^{2}}\n$$\nda questo posso calcolare il campo magnetico totale, in un modo simile a quanto fatto in precedenza per il campo elettrico  (solo che in questo caso abbiamo il prodotto seno, quindi l\u0026rsquo;angolo che conviene scegliere √® un po\u0026rsquo; diverso), e una volta che ho questo posso usare la seconda legge per avere la forza, questo √® il piano.\n\u003cimg src=\"/images/notes/Magnetismo-1700471121392.jpeg\" alt=\"Magnetismo-1700471121392\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n$$\n\\vec{B} = \\int _{Filo} \\frac{\\mu_{0}i}{4\\pi}  d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}}\n= \\hat{k} \\frac{\\mu i}{4\\pi} \\int_{-\\frac{\\pi}{2}}^{+\\pi/2} \\frac{dl}{r^{2}} \\sin \\theta\n$$$$\nr\\sin \\theta = D \\implies r = \\frac{D}{\\sin \\theta}\n$$$$\n\\frac{D}{l} = \\tan \\theta \\implies l = \\frac{D}{\\tan \\theta} \\implies dl = D \\frac{d\\theta}{\\sin ^{2}\\theta}\n$$$$\n\\lvert \\vec{B} \\rvert = \\frac{\\mu_{0}i}{4\\pi} \\int _{\\pi}^{0} \\frac{\\sin \\theta}{D} d\\theta \\, dx \n= \\frac{\\mu_{0}i}{4\\pi D} (-\\cos \\theta) ^{0}_{\\pi} = \\frac{\\mu_{0}i}{2\\pi D} \n$$\u003cp\u003e\nDa qui abbiamo ottenuto la legge di \u003cstrong\u003eBiot Savart\u003c/strong\u003e.\nQui notiamo che il campo magnetico circola intorno al filo (√® tangente al campo magnetico in questo caso, molto simile).\n\u003cimg src=\"/images/notes/Magnetismo-1700472671563.jpeg\" alt=\"Magnetismo-1700472671563\"\u003e\u003c/p\u003e","title":"Ampere e Faraday"},{"content":"Questo argomento √® stato trattato durante dopo la discussione dei Massimi minimi multi-variabile, per√≤ √® stato ripreso anche nella forma R to R, quindi credo necessiti di un foglio a parte.\nAffine set Lines $$ x = \\theta x_{1} + (1 - \\theta)x_{2} $$ This is a parametrization of the line Example:\nDef: affine set A combination where the coefficients add up to 1. We can say that this set is unique given two points.\nExample: solution of $\\left\\{ x \\mid Ax = b \\right\\}$ is an affine set (easy to prove). It can be proven that every affine set is a solution of such set of algorithms\nConvex sets It\u0026rsquo;s an affine set, where $0 \\leq \\theta \\leq 1$. Sometimes it\u0026rsquo;s written like $\\left[ x_{1}, x_{2} \\right]$. Sometimes this is called a convex combination of the two values.\nEvery element of the set sees each other clearly, this is the intuitive notion of the convex sets Convex combination Given $x_{1}, x_{2}, \\dots, x_{k}$ then a convex combination is (sometimes called mixture, or weighted average, or expectation)\n$$ x = \\theta_{1}x_{1} + \\dots + \\theta_{n}x_{n} $$ Where $\\theta_{1} + \\dots + \\theta_{n} = 1, \\theta_{i} \\geq 0$\nConvex Hull It\u0026rsquo;s the convex combination of all points in $S$. (so it\u0026rsquo;s defined by the borders usually). It can be viewed as the Smallest convex set that contains a set of points!\nConvex Cone $$ x = \\theta_{1}x_{1} + \\theta_{2}x_{2} $$Proper:\nClosed (contains borders) Has an interior (some point in the middle of the borders). Doesn\u0026rsquo;t contain lines (pointed) It\u0026rsquo;s convex Norm Cone $$ \\left\\{ (x, t) \\mid \\lVert x \\rVert \\leq t \\right\\} $$ Also known as Lorentz cone (probably used for things related to relativity).\nPositive Semidefinite Cone Let $S^{n}$ be the set of symmetric matrices with $n$ elements, of dimension $\\frac{(n + 1)n}{2}$. $S^{n}_{++}$ denotes the positive definite set, with one $+$ indicating semidefinite. Sub-level set $f: \\mathbb{R}^{n} \\to \\mathbb{R}$ such that:\n$$ C_{\\alpha} = \\left\\{ x \\in dom f \\mid f(x) \\leq \\alpha \\right\\} $$ It\u0026rsquo;s a function that it\u0026rsquo;s the best limited to a certain value $\\alpha \\in \\mathbb{R}$\n$$ S_{\\alpha} = \\left\\{ x \\in dom f \\mid f(x) = \\alpha \\right\\} $$Epigraph of function $$ epi f = \\left\\{ (x , t) \\in \\mathbb{R}^{n + 1} \\mid x \\in dom f, f(x) \\leq t \\right\\} $$it\u0026rsquo;s the part of the function that is bigger or equal to the function.\nRelation with convex functions the function $f$ is convex iff $epi f$ is a convex set. So if $f$ creates a convex set above it, we can say it\u0026rsquo;s convex, this is a bridge between functions and geometry.\nConvessit√† e Concavit√† Definizione di convessit√† $$ f(\\theta x + (1 - \\theta)y) \\leq \\theta f(x) + (1 - \\theta) f(y) $$ Concavo se $-f$ √® convesso\nL\u0026rsquo;approccio seguente √® quella fatta in analisi, ma √® abbastanza brutta. √à convessa se la derivata seconda √® diversa da 0, ma non √® una buona definizione perch√© non √® direttamente relazionata con la concavit√†.\nPossiamo definire la funzione secondo le tangenti, potremmo dire che la retta tangente sia sempre minore del grafico, in altro modo √® una forma di tailor!\n$f: A \\to R$ tale che f sia derivabile, allora se prendo un intervallo $(a,b) \\subseteq A$ posso dire che la funzione √® convessa in questo intervallo se $\\forall x,k \\in (a,b)$ ottengo che\n$f(x) \\geq f(k) + f'(k)(x -k) = T_1(x)$\nDefinizione vera Non vorremmo avere una definizione che dipenda dall\u0026rsquo;esistenza della derivata, quindi sia f una funzione ben definita, allora √® convessa sse $\\exists m$ nel dominio per cui valga che $f(x) \\geq f(y) + m(x - y)$\nOppure:\nDefinizione secondo libro (con i segmenti)\nAllora cerchiamo una definizione migliore:\nsia $f : \\mathbb{R}^n \\to \\mathbb{R}$ allora questa funzione si dice convessa sse $\\forall t \\in [0,1]$ si ha che\n$\\forall a,b \\in \\R^n: f(tb + (1 - t)a) \\leq t f(b) + (1-t) f(a)$ se vale con $\u003c$ posso dire che √® strettamente convessa.\nIntuizione:\nComunque prenda un punto all\u0026rsquo;interno di un intervallo ho che la funzione valutata in questo punto √® minore della somma della congiungente di questi due punti.\nConditions of convex functions Convex function to a line Consider $g(t) = f(x + tv)$ where the domain of $g$ are the $t$ such that $x + vt$ are in the domain of $f$. Then $f \\text{ is convex } \\iff g \\text{ is convex}$\nFirst-order condition in $\\mathbb{R}$ Questo √® un risultato molto simile a quanto ottenuto con le funzioni crescenti e la loro derivata prima, che si pu√≤ trovare in Teoremi Base Analisi.\nEnunciato Sia una funzione $f: \\mathbb{R} \\to \\mathbb{R}$, allora $f$ √® convessa sse la sua derivata prima √® $\u003e0$.\nLa dimostrazione √® abbastanza diretta quindi la si omette. (per√≤ la dovresti fare lo stesso perch√© √® importante).\nHintini di dimostrazione $\\implies$ Supponiamo che f sia convessa, allora vale quella formula in definizione, voglio dimostrare che la derivata sia crescente. (scrivo quella definizione due volte e ottengo qualcosa del tipo $0 \\geq$ intervallo * (intervallo funzione, e si pu√≤ risolvere senza molti problemi ottenendo il voluto, bisogna fare soprattutto attenzione a come definisci questi indici se vuoi andare a farlo in modo formale. $\\impliedby$ Supponiamo che la derivata sia crescente, allora poi vado ad utilizzare lagrange (due volte, prima con un intervallo x y tale che $x \u003c y$ e poi il contrario) fatto questo utilizzo la crescenza della derivata per concludere Corollario Possiamo utilizzare il risultato sopra per concludere che una funzione √® convessa sse la derivata seconda √® maggiore uguale a 0 (si possono utilizzare i teoremi riguardante le relazioni fra derivate e crescenza per questa).\nSegmento in Rn e convessit√† di punti Dati due punti in $\\mathbb{R}^n$ si pu√≤ individuare il segmento in due punti $x, y$ come l\u0026rsquo;insieme costituito da\n$\\{x + t (y - x) | t \\in [0,1]\\} = [x, y]$\nSI pu√≤ verificare che che √® uguale alla linea che li collega, in particolare √® una retta parametrica. Avendo questa definizione di segmento, posso andare a definire l\u0026rsquo;insieme convesso per Rn!.\nConvessit√† di un insieme di punti\nUn insieme di punti si dice convesso se $\\forall a, b \\in A \\subseteq \\mathbb{R}^n, [a,b] \\subseteq A$ (e la definizione di insieme concavo non esiste, potremmo dire non convesso, ma non che sia concavo).\nAvendo questo si pu√≤ dimostrare che l\u0026rsquo;intersezione di semipiani √® convesso.\nFirst-order condition in $\\mathbb{R}^{n}$ Possiamo allargare la definizione di funzione convessa che abbiamo dato poco fa in modo che ora sia buona anche a funzioni di pi√π variabili.\nf una funzione continua e differenziabile ovunque, allora √® convessa sse $\\forall a,b \\in A$ si ha che\n$f(a) \\geq f(b) + \\nabla f(b)^{T}(a - b)$ e per parlare di funzione concava basta rovesciare la disuguaglianza.\nQuesta formula da l\u0026rsquo;idea che la funzione deve essere sempre sopra al piano tangente per ogni punto! Si pu√≤ vedere come primo ordine Taylor approx ad un certo punto.\nNotiamo che se $b$ √® un punto di minimo, allora per fermat abbiamo che $\\nabla f(b) = 0$, questa √® una propriet√† locale che ci permette di avere una condizione globale: ossia abbiamo $\\forall a, b: f(a) \\geq f(b)$.\nSecond-order condition in $\\mathbb{R}^{n}$ sia $A \\subseteq \\mathbb{R}^n$ che sia aperto e convesso, sia $f\\in C^2(A) \\to \\mathbb{R}$ allora $f$ √® convessa su A $\\iff$ $Hf(x) \\geq 0, \\forall x \\in A$.\nNon √® definito ora il concetto di crescenza per un gradiente, o vettore, quindi vogliamo passare prima sul gradiente. Una funzione √® convessa sse la matrice hessiana √® semi-definita positiva. Sia la espansione di taylor come l\u0026rsquo;abbiamo definita prima (con resto secondo Lagrange). Pu√≤ essere utile dare un occhiata al teorema di Lagrange al secondo ordine a pi√π dimensioni prima\n$f(w + vt) = f(w) + \\langle \\nabla f(w), v \\rangle t + \\dfrac{1}{2}\\langle Hf(c)v,v\\rangle t^2$\nDimostrazione $\\impliedby$ Dato che $\\dfrac{1}{2}\\langle Hf(c)v,v\\rangle t^2 \\geq 0$ posso conclude la convessit√† (ossia la disuguaglianza appare abbastanza in fretta) $\\implies$ Assumiamo ora la convessit√†, vogliamo dimostrare che la hessiana sia semidefinita positiva. Per l\u0026rsquo;espansione di taylor ho che $f(a + h) = f(a) + \\langle\\nabla f(a), h\\rangle + \\dfrac{1}{2}\\langle H(f(a + \\theta h)) h, h\\rangle$ definendo a, h e theta correttamente. Per la convessit√† ho che $f(a + h) \\geq f(a) + \\langle\\nabla f(a), h \\rangle$ e questo vale $\\forall h : a + h \\in A$ Ma allora so che $\\dfrac{1}{2}\\langle H(f(a + \\theta h)) h, h\\rangle \\geq 0$ (perch√© altrimenti ci sarebbe un valore in input per cui nonvale la condizione di convessit√†.\nDevo dimostrare che $v \\in \\mathbb{R}^n \\neq 0 : a + v \\in A$, $\\langle H(f(a)) v, v\\rangle \\geq 0$, scelgo una successione in questo modo: $h_k = 1/k \\cdot v$ che tende a 0 per k che tende a infinito. Definito in questo modo ho che c\u0026rsquo;√® un theta per cui valga $\\dfrac{1}{2}\\langle H(f(a + \\theta v/k)) v/k, v/k\\rangle \\geq 0 \\iff \\dfrac{1}{2}\\langle H(f(a + \\theta v/k)) v, v\\rangle \\geq 0$ arrivato a questo punto mando k all\u0026rsquo;infintio e utilizzo\nPer continuit√† ho che il limite $\\lim_{k \\to \\infty}$ √® uguale a $\\langle H(f(a)) v, v\\rangle$ la permanenza del segno per concludere il voluto (se ogni elemento della successione √® maggiore di 0 allora anche il limite a cui sta tendendo √® maggiore di 0)\nSome properties Monotone slope property $$ s_{f, x}(t) = \\frac{f(x + td) - f(x)}{b} $$ As $t$ increases the slope increases. The intuition of the proof is easy, just take two slopes and see that by convexity the point of the lower slope is under the slope of the higher derivative.\nTh: $s(t)$ is monotonically non-decreasing.\nDirectional derivatives $$ f'(x;d) \u003e \\lim_{ t \\to 0 } \\frac{f(x + td) - f(x)}{t} $$ This definition is cool because convex functions always have directional derivatives, even if the original function is not derivable.\nStrong Convexity $$ f(y) \\geq f(x) + \\langle \\nabla f(x) , y - x \\rangle + \\frac{\\mu}{2}\\lVert x - y \\rVert ^{2} $$Per qualche motivo avendo questa propriet√† possiamo sviluppare Metodi di Discesa migliori che utilizzino anche questa informazione.\nHow to know if a set is convex Definition application Try to prove the #Convex combination theorem. Aka, $\\forall x_{1}, x_{2} \\in C, 0 \\leq \\theta \\leq 1 \\implies \\theta x_{1} + (1 - \\theta)x_{2} \\in C$ But this is the last resort, not advised by prof. Stephen Boyd\nComposition of convex-preserving operations If we can create the $C$ by using this composition we can still have a convex set!\nIntersection is convex The intersection of convex sets is convex\nThis is easily provable.\nExample of interesting case: Consider $p(t) = x_{1}\\cos t + \\dots + x_{n}\\cos nt$ The set $\\left\\{ x \\in \\mathbb{R}^{n} \\mid \\lvert p(t) \\rvert \\leq 1 : t \\in \\left[ 0, \\frac{\\pi}{3} \\right] \\right\\}$ is convex. (It\u0026rsquo;s easy to show that this is an intersection of slabs (see lecture 2, the idea is beautiful, although not formally defined or proved, but it seems intuitive!))\nAffine functions are convex preserving Affine functions preserve convex sets\nIf we apply an affine function (that is just linear function + $b$) aka : $f(x) = Ax + b$. Because the inverse of affine is affine (if it exist), also the inverse of affine functions are inverse. This is easy to prove too.\nPerspective functions are convex preserving $P : \\mathbb{R}^{n + 1} \\to \\mathbb{R}^{n}$ is a perspective function (lower dimensional!)\nFor example a function is $P(x, t) = \\frac{x}{t}$\nImages and inverse images of convex sets under perspective are convex\nNot sure why is it true.\nAffine-fractional functions are convex preserving $$ f(x) = \\frac{Ax + b}{c^{T}x + d} $$ Example of these functions are mapping from 3D in computer geometry to flat camera views.\nTeoremi importanti Jensen Questo √® uno dei teoremi legati alla convessit√† (concavit√† pi√π usati in assoluto). Una applicazione classica √® per il il valore atteso, analizzato in Variabili aleatorie e simili. La cosa carina √® che lui non l\u0026rsquo;ha inventato, ma ha detto che tipo 14 tizi stavano usando sta cosa, senza chiamarla per nessun nome, quindi l\u0026rsquo;ha popolarizzato.\n$$ f(\\lambda a + (1 - \\lambda)b) \\leq \\lambda f(a) + (1 - \\lambda) f(b) $$ Questa √® la formulazione semplice, ma si pu√≤ estendere per qualunque combinazione convessa dell\u0026rsquo;input (per combinazione convessa di $a_{1}, a_{2}, \\dots, a_{n}$ intendo $a_{1}\\lambda_{1} + \\dots + a_{n}\\lambda_{n}$ dei parametri $\\lambda_{1}, \\lambda_{2}, \\dots, \\lambda_{n}$ tale per cui $\\sum_{i=1}^{n}\\lambda_{i} = 1$).\nNon so bene la dimostrazione, ma l\u0026rsquo;intuizione √® abbastanza semplice in due variabili, se combini due punti su una retta sopra la funzione, questa sar√† maggiore del valore che ricevi combinando gli input, dato che √® convessa √® una funzione ad $U$.\nJensen for quasi convex functions $$ f(\\lambda a + (1 - \\lambda)b) \\leq \\max (f(a), f(b)) $$Convexity preserving operations Pointwise Supremum If we take the max of some convex functions, this max is convex. (It\u0026rsquo;s intuitive if we see the max as the intersection of the epi sets of the functions!) In maths:, given convex functions\n$$ g(x) = \\inf_{y \\in C} f(x, y) $$ Is convex, sometimes called partial minimization. (partial maximization is convex too!). This could be used to prove something about shur\u0026rsquo;s complement but I don\u0026rsquo;t remember it.\nComposition of scalar functions Given $f : \\mathbb{R}^{n} \\to \\mathbb{R}$ and $h : \\mathbb{R} \\to \\mathbb{R}$ then the function $f = h(g(x))$ is convex if $g$ and $h$ is and $\\hbar$ is nondecreasing. Also if $g$ is concave and $\\hbar$ is nonincreasing.\nA good way to remember this is proving it for $n=1$ and it\u0026rsquo;s differentiable so you can get it back.\nThis argument is extendable to multiple dimensions, the same conditions hold, just for different indexes.\nGiven $g: \\mathbb{R}^{n} \\to \\mathbb{R}^{k}$ and $h: \\mathbb{R}^{k} \\to \\mathbb{R}$ Then $f(x) = h(g(x)) = h(g_{1}(x), \\dots, g_{k}(x))$ is convex is\n$g_{i}$ is convex, $h$ is convex and $\\hbar$ is nondecreasing in each argument $g_{i}$ is concave, $h$ is convex and $\\hbar$ is nonincreasing in each argument. Easy to prove something like $\\sum -\\log(x_{i})$ is convex. This is a more general test than the others.\nPerspective functions $$ g(x, t) = tf(x / t) $$ Where the domain of $g$ is $\\left[ (x , t) \\mid x / t \\in dom f, t \u003e 0 \\right]$\nIf a function $f$ is convex, so is it\u0026rsquo;s perspective!\nConjugate function This is also known as the Legendre Transform in physics, take a look at it here.\n$$ f^{*}(y) = \\sup_{x \\in dom f} (y^{T}x - f(x)) $$And this function is convex, even if $f$ is not! The intuition is that this is the supremum of an affine function, so it should be more intuitive that that is linear! Usually when we are talking about conjugates, we expect that the conjugate of the conjugate is the original thing. In this case, it not true. In this case it\u0026rsquo;s the convex envelope, but it\u0026rsquo;s not important here.\nQuasi-convex function $f$ quasi convex if $dom f$ sub-level sets are convex for all $\\alpha$. (remember the sub-level sets are the parts in the domain such that are less than a value). Remember that a level set is a set of the points in the function domain such that are below a certain threshold $\\alpha \\in \\mathbb{R}$. When we say that this set is convex we say that the set is connected (doesn\u0026rsquo;t have gaps between them).\nThe intuition is that if the function goes below a certain threshold, it does it only once in the whole domain.\nConvex representation of quasi-convex If $f$ is quasi convex, there exists a $\\phi$ what is convex in the domain of $f$, when you fix $t$ you can do some interesting stuff.\nSo:\n$\\phi_{t}(x)$ is convex for fixed $t$. $f_{0}(x) \\leq t \\iff \\phi_{t}(x) \\leq 0$. You can do binary search on the $t$ which is better and then solve a convex function. TODO: try to understand this better.\n","permalink":"https://flecart.github.io/notes/analisi-di-convessit%C3%A0/","summary":"\u003cp\u003eQuesto argomento √® stato trattato durante dopo la discussione dei \u003ca href=\"/notes/massimi-minimi-multi-variabile/\"\u003eMassimi minimi multi-variabile\u003c/a\u003e, per√≤ √® stato ripreso anche nella forma R to R, quindi credo necessiti di un foglio a parte.\u003c/p\u003e\n\u003ch3 id=\"affine-set\"\u003eAffine set\u003c/h3\u003e\n\u003ch4 id=\"lines\"\u003eLines\u003c/h4\u003e\n$$\nx = \\theta x_{1} + (1 - \\theta)x_{2}\n$$\u003cp\u003e\nThis is a parametrization of the line\nExample:\u003c/p\u003e\n\u003ch4 id=\"def-affine-set\"\u003eDef: affine set\u003c/h4\u003e\n\u003cp\u003eA combination where the coefficients \u003cstrong\u003eadd up to\u003c/strong\u003e 1.\nWe can say that this set is unique given two points.\u003c/p\u003e","title":"Analisi di Convessit√†"},{"content":"In questo capitolo cerchiamo di andare oltre alla singola dimensione per l\u0026rsquo;analisi.\nLo spazio $\\mathbb{R}^{n}$ Possiamo definire uno spazio Rn come il prodotto cartesiano fra l\u0026rsquo;insieme R un numero di volte uguale a n $\\mathbb{R} \\times \\mathbb{R} \\times ... \\times\\mathbb{R} = \\mathbb{R}^n$\nAllora un tipico elemento in Rn √® nella forma $(x_1,...,x_n)$, questo elemento si chiama punto, mentre gli elelmenti in R che costituiscono questo elemento si chiamano componenti.\nOsservazione La maggior parte dei risultati che dimostro nello spazio ordinario (R3) si pu√≤ dimostrare per Rn, non andiamo pi√π nel dettaglio perch√© i problemi che ho in spazi maggiori sono parte di materiale per analisi 2\nOperazioni definite In modo simile a quanto definito negli Spazi vettoriali abbiamo principalmente due operazioni principali definite (in moto identico a quanto spiegato nell\u0026rsquo;altro documento) che sono:\nl\u0026rsquo;addizione vettoriale la moltiplicazione scalare. In pi√π aggiungiamo una operazione che non √® presente nel documento degli spazi vettoriali ma che √® importante in questo momento.\nProdotto scalare euclideo, definito qui sotto Il prodotto scalare euclideo Dati due elementi in Rn, che chiamiamo x e y, rispettivamente di componenti $x_1, ...,x_n$ e $y_1, ...,y_n$\n$$ \\langle x,y\\rangle = x\\cdot y\\coloneqq\\sum_{i=1}^nx_iy_i $$Possiamo individuare 3 propriet√† principali per questo prodotto scalare (nota il significato x,y con parentesi cambia in algebra lineare rispetto a questo. (chiamo in questo caso x primo argomento e y secondo argomento).\nSimmetria, se scambio x con y il risultato resta lo stesso $x\\cdot y = y \\cdot x$ Distributivit√† (linearit√† del primo argomento) $\\forall x,y,z \\in \\mathbb{R}^n, \\forall \\lambda, \\mu \\in \\mathbb{R} (\\lambda x + \\mu y) \\cdot z = \\lambda(x\\cdot z) + \\mu(y \\cdot z)$ Utilizzando la simmetria puoi dimostrare anche la linearit√† per il secondo argomento. Positivit√† del riflessivo: $\\forall x \\in \\mathbb{R}^n , x\\cdot x \\geq 0$, e si pu√≤ osservare che $x\\cdot x = 0 \\iff x = 0_v$ Prodotto scalare nella forma col coseno\nDato un elemento $x \\in \\mathbb{R}^{2}$, posso dire che $x = \\lvert x \\rvert \\dfrac{x}{\\lvert x \\rvert}$ notiamo che il secondo fattore ha lunghezza 0, quindi possiamo scriverlo tramite una coordinata polare, qualcosa tipo $\\dfrac{x}{\\lvert x \\rvert} = (\\cos \\theta, \\sin \\theta)$. Quindi se prendo un $x \\neq 0$ possiamo dire che $x = (|x|\\cos \\theta, |x| \\sin \\theta), \\theta \\in \\mathbb{R}$\n$$ x \\cdot y = \\lvert x \\rvert \\lvert y \\rvert \\cos \\theta \\cos \\gamma + \\lvert x \\rvert \\lvert y \\rvert\\sin \\theta\\sin \\gamma = \\lvert x \\rvert \\lvert y \\rvert(\\cos(\\theta - \\gamma)) $$che √® esattamente la formula che abbiamo visto alle superiori, il prodotto delle singole norme per il coseno dell\u0026rsquo;angolo fra i due.\nOrtogonalit√† Si pu√≤ definire l\u0026rsquo;ortogonalit√† di due vettori a seconda del risultato del loro prodotto scalare $x,y$ perpendicolari $\\implies x \\cdot y = 0$ Da questo si pu√≤ notare che il vettore nullo √® perpendicolare a ogni vettore.\nNorma di un vettore Scopriremo in seguito che la norma √® strettamente collegata con la lunghezza di un vettore, la definiamo in questo modo:\n$\\lVert x\\rVert = \\sqrt{x\\cdot x} = \\sqrt{x_1^2 + ... + x_n ^2}$\nPuoi notare come questo sia esattamente la distanza.\nPropriet√†\n$|\\lambda|\\lVert x\\rVert = \\lVert\\lambda x\\rVert$ $\\rVert x \\lVert \\geq 0$ e anche l\u0026rsquo;altro con 0, esattamente come per la propreit√† 3 del prodotto scalare vettoriale Disuguaglianza triangolare $\\lVert x \\cdot y \\rVert \\leq |x| |y|$ Normalizzazione\nPer la propriet√† 1 possiamo sempre normalizzare un vettore, ovvero moltiplicarlo per un reale tale che la somma dei componenti √® 1. Per trovare questo valore basta trovare il valore nella norma attuale $\\lambda$ e dividere ogni componente per questo valore. esempio $(3,4)$ noto che la norma √® 5, quindi questo punto normalizzato √® $(\\dfrac{3}{5}, \\dfrac{4}{5})$\nIl quadrato della norma cerchiamo di calcolare questo valore $||x + y|| ^2$ Per definizione si ha\n$$ \\lvert x + y \\rvert^ 2 = \\left( \\sqrt{ \\sum_{i=1}^n (x_i + y_i) ^2} \\right)^2 = \\sum_{i=1}^n (x_i + y_i) ^2 = \\sum_{i=1}^n (x_i^2 + 2x_iy_i + y_i^2) = \\lvert x \\rvert ^2 + 2x\\cdot y + \\lvert y \\rvert ^2 $$Si pu√≤ anche dimostrare tramite le propreit√† 2 del prodotto scalare e l\u0026rsquo;additivit√†, dimostrare in questo modo per esercizio (oppure chiedere a qualcuno che era in classe).\nOsservazione: Si pu√≤ notare che se i due vettori sono perpendicolari si ritrova il teorema di Pitagora in quanto\n$x \\cdot y = 0$\nDisuguaglianza di Cauchy-Schwarz Trattiamo meglio la versione in Cauchy-Schwarz Inequality Siano x,y vettori in $\\mathbb{R}^n$, allora vale che\n$\\lvert x \\cdot y\\rvert \\leq \\lvert x \\rvert \\lvert y \\rvert$ dove uguale si ha sse x e y sono dipendenti. Dimostriamolo nel caso in cui n = 2, per n superiori dovrebbe essere analogo, prendiamo due valori come qui, allora ho che $\\lvert x \\cdot y\\rvert = \\lvert \\lvert x \\rvert \\lvert y \\rvert\\cos(\\theta - \\gamma) \\rvert \\leq \\lvert x \\rvert \\lvert y \\rvert$ osservando il coseno, questo √® sempre compreso fra -1 e 1 quindi √® ovvio che sia sempre minore. ed √® ovvio che sono uguali nel momento in cui coseno √® 0, quindi i due vettori sono dipendenti.\nQuesto poi si pu√≤ espandere con spazi Hilbertiani e simili, ma non li conosco bene.\nDimostrazione disuguaglianza triangolare da CS\n$\\lvert x + y \\rvert \\leq \\lvert x \\rvert + \\lvert y \\rvert \\iff \\lvert x\\cdot y\\rvert \\leq \\lvert x \\rvert\\lvert y \\rvert$ fai il prodotto e guarda i calcoli\nProdotto e calcoli $\\lvert x + y \\rvert \\leq \\lvert x \\rvert + \\lvert y \\rvert \\implies \\lvert x + y \\rvert^2 \\leq (\\lvert x \\rvert + \\lvert y \\rvert)^2 \\implies \\lvert x \\rvert^2 + 2x\\cdot y + \\lvert y \\rvert ^2 \\leq \\lvert x \\rvert^2 + 2\\lvert x \\rvert\\lvert y \\rvert + \\lvert y \\rvert^2$ e cancellando opportunamente nell\u0026rsquo;ultimo passaggio, √® banale la deduzione. Teorema di Pitagora Anche questa √® una derivazione senza molti problemi in quanto basta la forma del quadrato della norma e il fatto che sono perpendicolari per dire che √® uguale a 0.\nDistanza fra due punti Possiamo definire la distanza fra due punti come la norma del vettore differenza:\n$Dist(x, y) = \\lVert x - y \\rVert$ (il che ha senso, perch√© la differenza mi da un vettore differenza, mentre la norma mi da la lunghezza di questo vettore, ignorando il verso e la direzione, quindi riesco ad ottenere una distanza).\nInsiemi e intorni Intorno sferico Andiamo a definire la nozione di intorno sferico\n$I_r(x)$ √® l\u0026rsquo;insieme di punti che distano al pi√π r da x, ossia $\\{y \\in \\mathbb{R}^n ,t.c., \\lvert x - y\\rvert \u003c r\\}$\nSi pu√≤ notare poi che questa forma dal punto di vista geometrico definisce una sfera in 3 dimensioni, un disco in 2, un intervallo in 1. Analogamente si possono definire i punti di un cerchio con pi√π dimensioni in questo modo.\nInsieme limitato Un insieme $A$ si dice limitato se $\\exists k \u003e 0, k \\in \\mathbb{R},$ $A \\subseteq I_k(0)$. Quindi √® contenuto all\u0026rsquo;interno di una area ben definita.\nUna funzione che ha dominio fino ad infinito per esempio 1/x non √® limitato perch√© non riesco mai a rinchiuderlo, ma una macchia a caso invece si pu√≤ racchiudere.\nInsieme aperto Un insieme si dice aperto se per qualunque punto esiste un contorno abbastanza piccolo che √® contenuto nell\u0026rsquo;insieme (cosa che non succede per un insieme chiuso, se prendo un punto nel bordo non trovo tale intorno).\nSuccessioni generali Definizione $(x_n)_{k \\in \\mathbb{N}}: x_k \\in \\mathbb{R}^n, \\forall k \\in \\mathbb{N}$ si potrebbe quindi sempre vedere come una funzione che va da $\\mathbb{N} \\to \\mathbb{R}^n$\nConvergenza delle successioni (classica) Una successione converge in un punto in Rn, se ogni suo componente tende alla componente corrispondente del punto di convergenza.\nEs, suppongo che f tenda a un $x_0, y_0$ allora voglio dire che il limite per x tende a x0, anche limite per y tende a y0.\nConvergenza secondo distanza Se si utilizza la convergenza secondo la nozione di stanza, allora questo assume una forma molto simile alla nozione di convergenza per i numeri reali.\n$x_k \\to x \\in \\mathbb{R}^n \\iff \\lvert x_k - x\\rvert \u003c \\epsilon, \\forall \\epsilon \u003e0$ ossia quella distanza tende a 0.\nFunzioni con pi√π variabili Definizione $A\\subseteq \\mathbb{R}^n , B \\subseteq \\mathbb{R}^n, f: A \\to B, ,,Graf(f) = \\{(x, f(x)) \\in A \\times B \\}$ quindi alla fine √® sempre la classica definizione di insieme, ma con dominio e codominio diversi\n$Im(f) = (f(x) | x \\in A)$\nCategorie di funzioni Funzioni scalari $\\mathbb{R}^n \\to \\mathbb{R}$\nFunzioni curve o cammini $\\mathbb{R} \\to \\mathbb{R} ^n$\nContinuit√† $\\forall (x_k)_{k \\in \\mathbb{N}} x_k \\to x, \\text { si ha che } f(x_k) \\to f(x)$ rispettivamente utilizzando i domini e codominio corretti (questa sarebbe anche una definizione utile per la continuit√† normale, ma stiamo utilizzando l\u0026rsquo;equivalenza che ci danno le successioni).\ntutte le funzioni elementari sono continue (come le hai sempre viste)\nPossiamo anche scrivere una funzione di continuit√† utilizzando gli intervalli (praticamente uguale a quella classica):\n$f: A \\to B$ √® continua in $\\bar{x}$ se ho che $\\iff \\forall \\epsilon \u003e 0\\exists \\gamma \u003e0 t.c. \\lvert f(y) - f(\\bar{x}) \\rvert \u003c \\epsilon, \\text { con } x\\in A \\lvert x - \\bar{x} \\rvert \u003c \\gamma$\nOSSERVAZIONI\nsi dimostra che tutti gli insiemi definiti con disuguaglianze strette sono aperti.\novvero $f_1,...f_n$ una successione di funzioni $\\mathbb{R}^n \\to \\mathbb{R}$, continue si ha che $A = \\{x \\in \\mathbb{R}^n \\mid f_1(x) \u003e c_1, ..., f_n(x) \u003e c_n\\}$ si ha che A √® aperto per questo teorema che non si dimostra nel nostro corso, per√≤ si ha che √® vero.\nFunzione radiale Una funzione si dice radiale se $f: \\mathbb{R}^2 \\to \\mathbb{R} t.c. \\exists g: [0, +\\infty[ \\to \\mathbb{R}$ tale che $f(x,y) = g(\\lvert x,y\\rvert)$\nIntuizione\nOvvero possiamo dire radiale se possiamo scriverlo solo in funzione dalla sua distanza dall\u0026rsquo;origine (spesso sono superficie di rotazione)\nDi solito √® comodo avere queste funzioni perch√© mi semplificano subito l\u0026rsquo;analisi.\nAltro esempio: $f(x,y) = e ^{-(x^2 + y^2)} \\implies g(t) = e ^{ -t^2}$ che basta disegnare g e poi ruotarlo sull\u0026rsquo;asse delle y.\nInsiemi di livello Dato un insieme $A \\subseteq \\mathbb{R}^2$ e una funzione $f: A \\to \\mathbb{R}$ e dato un punto $b \\in \\mathbb{R}$ allora si dice insieme di livello $b$ di $f$ l\u0026rsquo;insieme $L_b = \\{ (x, y) \\in A \\mid f(x,y) = b\\}$ in pratica √® la pre-immagine della funzione (come se fosse $f^{-1}$).\nQuindi la stessa cosa in una dimensione, ma col nome diverso, perch√© dal punto di vista livello, l\u0026rsquo;insieme di livello √® come un taglio del dominio verso un certo punto.\nDi solito si trova una curva di livello, una curva lineare che rappresenta questo insieme (percorrendo questo punto, il valore in output resta lo stesso, come se mi stessi muovendo parallelamente a una montagna senza salire e senza scendere.\nPiani I piani sono nella forma $f(x,y) = ax + by + c$, √® abbastanza ovvio, perch√© in R2 rappresenta una retta, se ho una retta ma posso variare z come mi pare, allora ovvio che si ha il piano\u0026hellip;\n","permalink":"https://flecart.github.io/notes/analisi-multi-variabile/","summary":"\u003cp\u003eIn questo capitolo cerchiamo di andare oltre alla singola dimensione per l\u0026rsquo;analisi.\u003c/p\u003e\n\u003ch3 id=\"lo-spazio-mathbbrn\"\u003eLo spazio $\\mathbb{R}^{n}$\u003c/h3\u003e\n\u003cp\u003ePossiamo definire uno spazio \u003cstrong\u003eRn\u003c/strong\u003e come il prodotto cartesiano fra l\u0026rsquo;insieme R un numero di volte uguale a n $\\mathbb{R} \\times \\mathbb{R} \\times ... \\times\\mathbb{R} = \\mathbb{R}^n$\u003c/p\u003e\n\u003cp\u003eAllora \u003cstrong\u003eun tipico elemento\u003c/strong\u003e in Rn √® nella forma $(x_1,...,x_n)$, questo elemento si chiama punto, mentre gli elelmenti in R che costituiscono questo elemento si chiamano componenti.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOsservazione\u003c/strong\u003e\nLa maggior parte dei risultati che dimostro nello \u003cstrong\u003espazio ordinario (R3)\u003c/strong\u003e si pu√≤ dimostrare per Rn, non andiamo pi√π nel dettaglio perch√© i problemi che ho in spazi maggiori sono parte di materiale per analisi 2\u003c/p\u003e","title":"Analisi multi-variabile"},{"content":"Metodi di registrazione informazione Ci stiamo chiedendo in che modo possiamo registrare attivit√† del cervello e quindi cercare di fare decoding delle informazioni presenti Prima parliamo di alcune tecniche non invasive che ci permettono di vedere alcune attivit√† presenti nel cervello.\nMetodi macroscopici Functional Magnetic Resonance Imaging Un metodo √® fMRI. (ci sono cose ) TODO capire come funziona\nElectro-Encephalo-Gram EEG che prende direttamente dai segnali Ma il drawback di entrambi √® che non registrano attivit√† del singolo array.\nMetodi a livello cellulare Electrode arrays Ci permette di registrare voltaggi di singoli neuroni (quindi capire se √® in spike o meno). Solitamente si mette il tessuto cellulare direttamente su questo strato di elettrodi.\nIn modo simile si pu√≤ anche misurare la differenza di potenziale studiata in Campo elettrico, con una pipetta sonda, di solamente qualche micrometro di diametro, in modo da non danneggiare molto la membrana cellulare.\nCalcium Imaging Alcune cellule cambiano colore quando assorbono calcio, e si pu√≤ utilizzare questo segnale visivo per capire se sta sparando o meno.\nNeural codes Consideriamo una serie di neuroni su un array di elettrodi a cui √® sottoposto a uno stimolo visivo. Utilizziamo un raster plot per capire il momento nel tempo in cui sparano, e otteniamo cos√¨ un diagramma delle attivazioni di un neurone.\nVogliamo utilizzare un sistema probabilistico per gestire tutto sto rumore di cos√¨ tanti neuroni. Una cosa tipo\nQuant\u0026rsquo;√® la probabilit√† che il neurone si attivi dopo questo stimolo? encoding (come viene memorizzato questo input). Quant\u0026rsquo;√® la probabilit√† che il neurone si attivi per questo stimolo? decoding (motivo per cui si √® attivato diciamo). Cosa interessante, se diamo rumore white a caso preso da una gaussiana, e poi prendiamo le risposte, queste risposte sono disposte in modo gaussiano. Questo sistema con il gaussiano ci permette di trovare la feature ossia le attivazioni precedenti, il pattern diciamo, che contribuisce all\u0026rsquo;attivazione del neurone corrente.\n","permalink":"https://flecart.github.io/notes/analysis-of-neural-codes/","summary":"\u003ch2 id=\"metodi-di-registrazione-informazione\"\u003eMetodi di registrazione informazione\u003c/h2\u003e\n\u003cp\u003eCi stiamo chiedendo in che modo possiamo registrare attivit√† del cervello e quindi cercare di fare decoding delle informazioni presenti\nPrima parliamo di alcune tecniche non invasive che ci permettono di vedere alcune attivit√† presenti nel cervello.\u003c/p\u003e\n\u003ch3 id=\"metodi-macroscopici\"\u003eMetodi macroscopici\u003c/h3\u003e\n\u003ch4 id=\"functional-magnetic-resonance-imaging\"\u003eFunctional Magnetic Resonance Imaging\u003c/h4\u003e\n\u003cp\u003eUn metodo √® \u003cstrong\u003efMRI\u003c/strong\u003e. (ci sono cose ) TODO capire come funziona\u003c/p\u003e\n\u003ch4 id=\"electro-encephalo-gram\"\u003eElectro-Encephalo-Gram\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003eEEG\u003c/strong\u003e che prende direttamente dai segnali\nMa il drawback di entrambi √® che \u003cstrong\u003enon registrano attivit√† del singolo array\u003c/strong\u003e.\u003c/p\u003e","title":"Analysis of Neural Codes"},{"content":"Anomaly detection is a problem in machine learning that is of a big interest in industry. For example a bank needs to identify problems in transactions, doctors need it to see illness, or suspicious behaviors for law (no Orwell here). The main difference between this and classification is that here we have no classes.\nSetting of the problem Let\u0026rsquo;s say we have a set $X = \\left\\{ x_{1}, \\dots, x_{n} \\right\\} \\subseteq \\mathcal{N} \\subseteq \\mathcal{X} = \\mathbb{R}^{d}$ We say this set is the normal set, and $X$ are our samples but it\u0026rsquo;s quite complex, so we need an approximation to say whether if a set is normal or not. We need a function $\\phi : \\mathcal{X} \\to \\left\\{ 0, 1 \\right\\}$ with $\\phi(x) = 1 \\iff x \\not \\in \\mathcal{N}$.\nWe want to project this high dimensional space to a low dimensional space and the use mixture of Gaussians. For some reason (you need to understand this fact, it\u0026rsquo;s important) if you project high dimensional random variables to a low dimension one, this resembles Gaussians, and it\u0026rsquo;s a sign of losing information. Projection Pursuit measures the non-Gaussianity in low dimension space, this tells us that in high dimension there is for sure a structure which might be interesting. After we have fitted this Gaussian, we can have an anomaly score.\nStandard approach The standard pipeline for this kind of problem is\nDimensionality reduction Clustering approach to determine the probability of the various data points Variance tells us something about informativeness. We need to maximize the variance when we project. We also need to choose the correct abstraction, we need to have a trade-off between tractability and fidelity. We need to choose the function $\\pi : \\mathbb{R}^{D} \\to \\mathbb{R}^{d}$ with $d \\ll D$. An easy way to maximize variance id Principal Component Analysis$. After we had this, we need to use Clustering algorithm to fit the gaussians.\n","permalink":"https://flecart.github.io/notes/anomaly-detection/","summary":"\u003cp\u003eAnomaly detection is a problem in machine learning that is of a big interest in industry. For example a bank needs to identify problems in transactions, doctors need it to see illness, or suspicious behaviors for law (no Orwell here).\nThe main difference between this and classification is that here we have no classes.\u003c/p\u003e\n\u003ch4 id=\"setting-of-the-problem\"\u003eSetting of the problem\u003c/h4\u003e\n\u003cp\u003eLet\u0026rsquo;s say we have a set $X = \\left\\{ x_{1}, \\dots, x_{n} \\right\\} \\subseteq \\mathcal{N} \\subseteq \\mathcal{X} = \\mathbb{R}^{d}$  We say this set is the normal set, and $X$ are our samples but it\u0026rsquo;s quite complex, so we need an approximation to say whether if a set is normal or not.\nWe need a function $\\phi : \\mathcal{X} \\to \\left\\{ 0, 1 \\right\\}$ with $\\phi(x) = 1 \\iff x \\not \\in \\mathcal{N}$.\u003c/p\u003e","title":"Anomaly Detection"},{"content":"Omnidirezionali Antenne omnidirezionali üü© Slides antenne omnidirezionali\nIl senso di omnidirezionale √® in tutte le direzioni dell\u0026rsquo;antenna (nota: non √® isotropico, perch√© non √® da un singolo punto).\nin passato era importante andare a guardare la direzione per trovare la polarizzazione migliore. Praticamente irradia a 360 gradi sul piano permedicolare all‚Äôantenna.\nEsempio pattern di radiazione\nQuesto genere di antenne sono irrealizzabili la pi√π simile √® la antenna dipolo dipolo, ma comunque non rispetta le antenne in questo verso diciamo. ricorda i dBi che abbiamo citato in Fisica del Wireless.\nGuadagno passivo in ominidirezionali üü© Slide guadagno passivo\nSi pu√≤ concentrare l\u0026rsquo;energia nella shape del dipolo. Per esempio se lo faccio pi√π schiacciato, ho un range molto pi√π forte orizzontalmente, ma appena su o appena gi√π perdo segnale.\nMentre al contrario, se ho una forma pi√π arrotondata ho segnale solo se gli sto vicino, ma molta meno importanza stare sopra o sotto.\nEsempio del guadagno passivo e attivo delle antenne\nNOTA: posso avere un guadagno fino a 10 Db quindi 10 volte tanto.\nEd √® anche per questo motivo che andiamo a misurare l‚ÄôEIRP e non la potenza che finisce nell‚Äôantenna, anche chiamata Intentional radiator Power output.\nPOSIZIONAMENTO DELL ANTENNE\nAndiamo a chiederci in che modo mettere le antenne in modo che pi√π utenti possibili possano usufruire del segnale.\nUna soluzione potrebbe essere inclinare l‚Äôantenna:\nSlide inclinazione dell‚Äôantenna\nAntenna semidirezionale Semidirezionale (3) üü© Questi sono i pi√π comuni, sparano principalmente energia di fronte (quindi metterllo su un muro √® cosa buona).\nEsempi di antenne omnidirezionali\nDi solito si mettono nel muro (sono panel o patch, che praticamente cambiano di costruzione, ma alla fine hanno la stessa funzione ).\nMentre gli yagi sono sparati nella direzione in cui punta (e mirano alla posizione del ripetitore, perch√© da l√¨ ricevono meglio.\nbeam width (!!!) √® un valore che √® espresso in angoli, e misura quando largo o concentrato il segnale, √® lo spazio necessario per dimezzare il segnale, partendo dall\u0026rsquo;asse di direzione. Questa concezione ci serve per parlare di antenne altamente concentrate.\nHighly-directional antennas üü©- Slide esempio highly dir\nEsempi sono grid e parabolic dish che perdono energia attorno molto molto velocemente, per√≤ se sei nel beam width lo ricevi molto bene (va lontano si possono utilizzare per antenne lungo raggio come satelliti).\nPotrei anche s.ettorializzare la trasmissione: ogni antenna si prende solamente un certo angolo\nLine of Sight ossia la linea raggio dritta fra trasmissione e ricevitore.\nFresnel zone üü©‚Äî Definiamo al centro della line of size come la zona di fresnel, sarebbe meglio metterlo libera da ostacoli. Si concentrano il massimo numero di onde additive quindi se c‚Äô√® qualcosa mi toglie molto.\nSlide zona di fresnel\nSe √® pi√π di 20 percento occupata, allora √® meglio andare sugli ostacoli (altrimenti non ottengo maggiore ricezione, continuo a perdere energia negli ostacoli e ho inquinamento dei raggi).\nSe non √® ostruita sto permettendo l‚Äôenergia ad arrivare con massima efficienza al ricevitore.\nNOTA: la distanza √® dipendente solo da frequenza e distanza\nfresnel e curvatura terrestre\nSettorializzazione di antenne direzionale (boh) üü• Si parla di multiplexing spaziale perch√© possiamo andare ad utilizzare lo stesso canale, ma in zone diverse perch√© il segnale √® concentrato solamente in quella direzione.\nAzimuth and elevation charts üü© Slide azimuth and elevation charts\nQuesto grafico √® utilizzato per guardare in ogni angolo dell\u0026rsquo;antenna, quanto √® l‚Äôenergia che viene trasmessa.\nMentre azimuth gira in orizzontale (quindi visuale dall‚Äôalto), elevation gira in modo verticale (quindi visuale da terra diciamo).\nInoltre √® importante dislocare le antenne in posizioni sparse. Cos√¨ se ricevo un segnale posso provare a ricavare il segnale originale provando a buttare via il noise. Di questa parte si potrebbe ricollegare allo space multiplexing citato in Tecnologia Wireless\nSe li metto a lambda mezzi, allora almeno una delle due antenne prendono un segnale buono, l‚Äôaltra potrebbe essere in opposizione (mi sembra comunque un sacco di fisica che ignoriamo qui).\nSotto serve un controllore che riesca ad annullare e scegliere i segnali o gli sfasamenti o annullamenti. (questo controllore dovrebbe rifasare il segnale e rendere il segnale additivo.\nSlide antenna diversity\nBeam forming\nAvendo queste antenne, io riesco a creare un raggio RF, ritardando in modo opportuno certi piatti, e posso mandarlo dove mi pare. (controllo sulla direzione, solamente ritardando le fasi di certe antenne).\nPath loss in free space üü®- Slide path loss\nNotiamo che la perdita di segnale dipende dalla frequenza e dalla distanza ‚Üí frequenza alta implica segnale perso pi√π in fretta. 36.6 √® una costante che funziona sulla Terra.\nSi noti che duplicando la distanza, l\u0026rsquo;energia cade 4 volte e questo risultato √® coerente con questo dato.\nPer vedere se -86 dB √® sufficiente bisogna guardare la soglia di ricezione del nostro dispositivo. Se il link budget √® positivo allora si riceve, il nostro obiettivo √® progettare sistemi a link-budget positivi.\nSi noti che non √® necessario che questo link-budget sia positivo, significa che sto consumando un sacco di energia.\nSpreco energia nella trasmissione Disturbo trasmissione di altri Vogliamo il minimo link-budget positivo.\nQuesto si chiama system operative margin o valore operativo del sistema.\nIl margine extra √® chiamato fade margin per resister al path loss, fase, e riflessioni e simili, in generale questo fade margin √® un +10 fino +20\n","permalink":"https://flecart.github.io/notes/antenne/","summary":"\u003ch2 id=\"omnidirezionali\"\u003eOmnidirezionali\u003c/h2\u003e\n\u003ch3 id=\"antenne-omnidirezionali-\"\u003eAntenne omnidirezionali üü©\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlides antenne omnidirezionali\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Antenne/Untitled.png\" alt=\"image/universita/ex-notion/Antenne/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIl senso di omnidirezionale √® in tutte le direzioni dell\u0026rsquo;antenna (nota: non √® isotropico, perch√© non √® da un singolo punto).\u003c/p\u003e\n\u003cp\u003ein passato era importante andare a guardare la direzione per trovare la polarizzazione migliore. Praticamente irradia a 360 gradi sul piano permedicolare all‚Äôantenna.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eEsempio pattern di radiazione\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Antenne/Untitled 1.png\" alt=\"image/universita/ex-notion/Antenne/Untitled 1\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eQuesto genere di antenne sono \u003cstrong\u003eirrealizzabili\u003c/strong\u003e la pi√π simile √® la antenna dipolo dipolo, ma comunque non rispetta le antenne in questo verso diciamo. ricorda i dBi che abbiamo citato in \u003ca href=\"/notes/fisica-del-wireless/\"\u003eFisica del Wireless\u003c/a\u003e.\u003c/p\u003e","title":"Antenne"},{"content":"This is a new framework that is faster than MapReduce (See Massive Parallel Processing). It is written in Scala and has a more functional approach to programming. Spark extends the previous MapReduce framework to a generic distributed dataflow, properly modeled as a DAG. There are other benefits of using Spark instead of the Map reduce Framework:\nSpark processes data in memory, avoiding the disk I/O overhead of MapReduce, making it significantly faster. Spark uses a DAG to optimize the entire workflow, reducing data shuffling and stage count. But MapReduce sometimes has its advantages:\nUltra-large datasets that do not fit in memory: For massive datasets that don‚Äôt fit even across a large Spark cluster‚Äôs memory, MapReduce‚Äôs disk-based processing can be more manageable. Strict fault tolerance requirements: MapReduce‚Äôs fault tolerance mechanism is very robust, as it writes intermediate results to HDFS, which may be preferred in environments where data recovery is critical. Low hardware resources: Spark requires more memory and computational resources than MapReduce, so in resource-constrained environments, MapReduce may be a more practical choice. Resilient Distributed Datasets RDDs are the main innovation in this section. The idea, presented (Zaharia et al. 2012), is that keeping the data in memory, when possible, gives an order of magnitude performance increase. See Performance at Large Scales for comparison of the speed of access in various memories.\nUsually, they are seen as Dataframes with a specific schema.\nRDDs fault tolerance üü© Previous methods implemented fault tolerance by saving and persisting the intermediate data that could be produced during the computation. RDDs save the lineage (transformations graph), somewhat akin to a DAG that we often see for machine learning methods like Backpropagation.\nRDD memorization üü© We can keep RDD mainly in three forms:\nDeserialized in memory data: fastest access Serialized in memory: slower access, but less memory Disk: slowest access, but more space (this is often used when RDDs cannot fit into the main memory). Resilient distributed datasets\u0026rsquo; Lifecycle üü© Resilient distributed datasets (RDD) are the unit data blocks of Apache Spark. These blocks are created, transformed and written back into the disk.\nResilient means that they remain in memory or on disk on a ‚Äúbest effort‚Äù basis, and can be recomputed if need be. Distributed means that, just like the collections of key-value pairs in MapReduce, they are partitioned and spread over multiple machines.\nRDDs can be anything, not just Key-value pairs as in MapReduce.\nCreation üü© The RDD is created by fetching the used data from the disk or somewhere else. These RDDs can also be so large that cannot fit on a single machine. Spark automatically infers the schema from discovering the JSON Lines file. This adds a static performance cost, but then allows for sql queries inside spark!\nTransformation üü© Instead of just MapReduce, apache spark introduces the notion of transformations. There are hundreds of possible transformations that can be composed like a blocks of LEGO.\nExample of some possible transformations\nFilter (basically a selection on possible values) Map (this can implement a projection for example, it takes a row (single item) and returns some function of it). flatMap (this is a map, but flattens the output of the map, which could be a list). distinct (maps some items evaluated as the same to a single value). sample (take some random items from the start values). join: put a tuple grouping by key value. subtractByKey: binary operation that returns the keys in the first operand that do not appear for the second. Some can also be binary operations, for example:\nunion Cartesian product There are also some possible transformations that are specifically tailored for key-value pairs. reduceByKey: this implements the reduce phase of the map reduce framework. We could also just drop the keys or values as a transformation. groupByKey: all key-values with the same key are grouped together. sortByKey: we can sort by key. We can keep the key and also map the corresponding values. Action üü© Actions make the transformation permanent. Usually Apache emplyes lazy evaluation: the transformations are not executed until the action is called. Sometimes we say data is materialized when it is actually computed and stored on the machines (which happens only when the action is triggered).\nExample of actions are:\nCollect (just collects all the RDDs and flushes them on the client machine). Count (example count by key, or count how many times a value occurs). It is possible to count also by value, somehow this action uses a lot of memory, and if we have too many distinct values, it is possible that the task fails because of memory overflow. Take (return first $n$ values) Top (return last $n$ values). takeSample, similar as before, but samples randomly soem actions. saveAsTextFile, saves the whole RDD in a Cloud Storage service, e.g. S3. lookup (returns one key-value that matches the key). Because there is some time for setup, the first execution time is usually larger.\nPhysical Architecture Narrow dependency transformations üü© In this case, the computation depends only on a single value. Which means, this could be easily parallelized. So, if the data is spread over different machines, all narrow dependencies could be executed in parallel, following this diagram: This is the equivalent of a memory and CPU slot when we were talking about MapReduce. If we have more Tasks than slots, then the faster slots usually get assigned more tasks (this usually improves the latency), so that we can have as few as idle computers as possible. Within a slot, tasks are executed sequentially. We could also split the slots inside a single node, by assigning them different number of cores.\nThe opposite of narrow dependency is called a wide dependency. A stage is a sequential lineage of narrow dependency transformations. This is to clearly distinguish them with the shuffling stage which is often a bottleneck of the system.\nChains of narrow dependencies üü© the physical calls of the underlying map/filter/etc functions are directly chained on each input value to directly produce the corresponding final, output value, meaning that the intermediate RDDs are not even materialized anywhere and exist purely logically. From ({fourny} 2024).\nCommunication over the network is usually not efficient. If we have a sequence of narrow dependency transformations, usually every transformation is done on a chain on the same machine, meaning the intermediate steps of the RDD usually are not even materialized, but we just do subsequent function calls! This chain is called a stage, which is a computation step that can occur sequentially on a single machine without materializing the intermediate RDDs.\nSubmitting a spark task We can set some hyperparameters for spark to know how many resources it needs (for example executors, or memory), and the code for the task that needs to be executed.\nThis is called spark-submit.\nWide dependency transformations üü© These types of tasks need some shuffling, corresponding to the communication step of the MapReduce framework. In these cases, we can have a DAG describing all the transformations of the tasks, and one can have a topological order on the execution.\nFor clusters, the stages are usually in sequential.\nOptimization methods Pinning a RDD üü© If a RDD is used in many successive RDDs, we can pin this in memory, and forgetting all the old RDDs so that we can be efficient in applying these new operations. Example of pinning from the course slides.\nThis is often also called checkpointing. This is often not worthwhile when we have just Narrow dependency transformations, as usually the bottleneck is the shuffling. We would spend a lot more memory to safe a little bit of time.\nPrepartitioning üü©\u0026ndash; This is an optimization method that enables us to prevent shuffling.\nIf, however, Spark knows that the data is already located where it should be, then shuffling is not needed. A simple example is when data is sorted before being grouped with the same keys as for sorting: then, Spark has the knowledge that the groups are already consistent with their physical location, and that no additional shuffling is needed between sorting and grouping.\nFor example, if we have blocks that are sorted across blocks, but not inside, even if I would normally require shuffling, in this case we do not need that. There are some ways to explicitly defined the partitions in Spark.\nSpark SQL For normal SQL, you should take a look at Structured Query Language. Spark usually converts the JSON or CSV into a dataframe, which can also be converted back to RDD if needed.\nExplodeüü© Some operations of SQL only exist within spark. For example explode, which is also called lateral view. Allows to have first normal form by expanding the nested data (e.g. arrays) to have more values.\nIts effect is that the rows are duplicated into as many rows as items in the array, and one particular item of the array is placed on each duplicated row in the corresponding column.\nDistributing and Clustering üü•++ Spark SQL also allows for different grouping information. Sort operation in Spark happens only locally.\nThe DISTRIBUTE BY clause forces a repartition by putting all rows with the same value (for the specified field(s)) into the same new partition.\nCluster is just mapping by key, and having all the same keys in the same machine. Note that these operations are against the principle of data independence proposed by Codd.\nIn Spark SQL, the DISTRIBUTE BY clause is used to control the physical distribution of the data across different nodes of the cluster. When you use this clause, it forces a repartition of the data such that all rows that have the same values for the specified columns are grouped into the same partition. This is especially useful when you anticipate subsequent operations that benefit from this specific distribution, like certain JOIN operations or SORT BY operations within partitions.\nFor example, consider the following query:\nSELECT first_name, last_name FROM persons WHERE age \u0026gt;= 65 GROUP BY country HAVING COUNT(*) \u0026gt;= 1000 DISTRIBUTE BY country; In this scenario, the¬†DISTRIBUTE BY country¬†clause ensures that all rows with the same¬†country¬†are brought together into the same partition. This can be beneficial for performance, especially in large-scale data processing, as it minimizes the amount of data shuffled across the network during subsequent operations that might need to group or join data by the¬†country¬†field.\nShuffling operationsüü®\u0026ndash; Remember that shuffles are usually the bottleneck of our transformations. We need to remember this! Some examples are group by or order by operations. Examples of operations that need shuffling are:\nreduceByKey or Group by key and similars Joins distinct operations References [1] {fourny} ‚ÄúThe Big Data Textbook‚Äù 2024\n[2] Zaharia et al. ‚ÄúResilient Distributed Datasets: A Fault-Tolerant Abstraction for in-Memory Cluster Computing‚Äù USENIX Association 2012\n","permalink":"https://flecart.github.io/notes/apache-spark/","summary":"\u003cp\u003eThis is a new framework that is faster than MapReduce (See \u003ca href=\"/notes/massive-parallel-processing/\"\u003eMassive Parallel Processing\u003c/a\u003e). It is written in Scala and has a more functional approach to programming.\nSpark extends the previous MapReduce framework to a generic distributed dataflow, properly modeled as a DAG.\nThere are other benefits of using Spark instead of the Map reduce Framework:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSpark processes data in memory, avoiding the disk I/O overhead of MapReduce, making it significantly faster.\u003c/li\u003e\n\u003cli\u003eSpark uses a DAG to optimize the entire workflow, reducing data shuffling and stage count.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBut MapReduce sometimes has its advantages:\u003c/p\u003e","title":"Apache Spark"},{"content":"3.1 Introduzione e definizione Si definisce applicazione lineare una funzione (omomorfica) che preserva la struttura dello spazio vettoriale, ossia vale che\n$$ f:V \\to W, \\text{ tale che } \\\\ f(u + v) = f(u) +f(v)\\\\, f(\\lambda v) = \\lambda f(v) $$ Vengono mantenute alcune caratteristiche principali. In modo simile si possono definire omomorfismi per tutte le altre strutture algebriche, la cosa importante √® che lo spazio d\u0026rsquo;arrivo possieda ancora tutte le stesse operazioni.\n3.1.1 Conservazione delle combinazioni lineari In particolare le due propriet√† delle applicazioni lineari mi preservano le applicazioni lineari, ovvero:\n$f(\\lambda_1 a + \\lambda_2 b) = \\lambda_1 f(a) + \\lambda_2f(b)$ e questo lo puoi estendere a qualunque tipo di vettore\n3.1.2 L\u0026rsquo;elemento neutro L\u0026rsquo;elemento neutro √® conservato nell\u0026rsquo;applicazione lineare (mappa sempre l\u0026rsquo;elemento neutro di uno all\u0026rsquo;elemento neutro dell\u0026rsquo;insieme di arrivo)\n3.1.3 Esempi Un esempio importante √® la matrice che mappa da $\\mathbb{R}^n\\to \\mathbb{R}^m$\n3.2 Esiste omomorfismo a insiemi qualunque 5.1.7 sul libro.\nDimostrazione Il passo pi√π importante √® definire l\u0026rsquo;applicazione lineare. Lo definiamo in questo modo: preso $v\\in V$, allora in quanto ho una base di $V$, posso dire che $v = \\alpha_1v_1 +...+ \\alpha_n v_n$, allora definiamo la nostra funzione $L:V\\to W$ tale che $L(v) = \\alpha_1w_1 +...+\\alpha_nw_n$, da notare che i coefficienti sono gli stessi, ma i vettori diversi e abbiamo anche cambiato possibilmente lo spazio\n√à una applicazione: fai i calcoli e puoi notare che effettivamente √® una applicazione lineare.\nCalcoli Unicit√†: l\u0026rsquo;unicit√† di questa applicazione si pu√≤ identificare con l\u0026rsquo;unicit√† delle coordinate rispetto alla base, c\u0026rsquo;√® solo una tale funzione definita in questo modo per ogni vettore. Ma questa non √® formale, quindi appiccico la dimostrazione formale: (si utilizza l\u0026rsquo;ipotesi dell\u0026rsquo;unicit√† delle coordinate inmodo implicito sctivendo v come combinazione lineare della base) Corollario: Coincidenza su basi La dimostrazione √® abbastanza ovvia, sappiamo che esiste un unica applicazione lineare su una base e che arriva a W.\nQuesto teorema ci permette di avere delle applicazioni lineari a piacere, per qualunque spazio vettoriale, basta avere una base dello spazio iniziale.\nmodi di vedere l‚Äôapplicazione lineare Esistono tre modi per avere la definizione di applicazione lineare.\nClassica definizione F(v) = espressione Una matrice che mi rappresenta l\u0026rsquo;applicazione F(base1) = qualcosa, \u0026hellip; F(basen) = qualcosaltro. 3.3 Teoremi su Ker e Im 3.3.1 Kernel e Immagine sono sottospazi Devo dimostrare che questi insiemi siano dei sottospazi.\nIl vettore nullo appartiene a $\\text{Ker }f$ Poi si dovrebbe dimostrare che siano chiusi per l\u0026rsquo;operazione di somma e prodotto scalare, anche questo √® semplice. In modo simile a quanto fatto in Spazi vettoriali 3.3.2 Suriettivit√† e iniettivit√† Enunciato:\nData una applicazione lineare $F: V\\to W$\nSuriettivo sse $Im(F) = W$, questa √® abbastanza ovvio.\nIniettiva sse $Ker(F) = \\{0\\}$\nDimostrazione\n$\\implies$Supponiamo che sia iniettiva, allora $F(x) = F(y) \\implies x = y$,\nin quanto √® una applicazione lineare so che $F(0) = 0_w$, quindi supponiamo che $v \\in V |F(v) = 0$ per iniettivit√† ho che $v= 0$, quindi l\u0026rsquo;unico elemento di $Ker(F)$ √® 0.\n$\\impliedby$Supponiamo che $Ker(F) = \\{0 \\}$ supponiamo che $F(x) = F(y)$ per certi $x,y \\in V$,\nvogliamo dimostrare che $x= y$.\nValutiamo $F(x - y) = F(x) - F(y) = 0_w$, ma quindi $x-y = 0_v$ in quanto per ipotesi l\u0026rsquo;unico elemento in Ker(F) √® 0v e abbiamo dimostrato che (x-y) appartiene a Ker(F), quindi $x = y$.\n3.3.3 Calcolo del nucleo Dato un omomorfismo, l\u0026rsquo;unica cosa che dobbiamo fare √® risolvere la matrice omogenea associata. In parole migliori\nKer F √® l\u0026rsquo;insieme delle soluzioni del sistema lineare omogeneo associato ad A, dato A matrice dell\u0026rsquo;applicazione lineare\nQuesto dato si pu√≤ utilizzare per calcolarne poi la dimensione, usando riduzione di Gauss\n3.3.4 Corrispondenza fra base V nell‚Äôimmagine Teorema 5.4.4. Dimostrazione corrispondenza Vogliamo dimostrare una doppia inclusione, perch√© √® questa la definizione dell\u0026rsquo;uguaglianza per un assioma di estensionalit√† in Teoria assiomatica degli insiemi.\nCaso $\\implies$, sia $w \\in Im(F)$, allora $\\exists v\\in V, F(v) = w$, dato che abbiamo una base, si ha che $v = \\lambda_1v_1 +...+ \\lambda_nv_n$, allora\n$F(\\lambda_1v_1 +...+ \\lambda_nv_n) = F(\\lambda_1v_1) +...+ F(\\lambda_nv_n) = \\lambda_1F(v_1) +...+ \\lambda_nF(v_n) \\in \\langle F(v_1),...., F(v_n)\\rangle$ e finisco questa freccia.\nCaso $\\impliedby$Questa praticamente √® uguale alla precedente, oppure, possiamo ricordare che per la 3.1.5 presente in Spazi vettoriali si ha che √® il pi√π piccolo sottospazio generato da quei elementi. Quindi questa inclusione √® fatta in modo immediato. Ma anche ripercorrere la dimostrazione al contrario non √® un problema.\nNote: Questo teorema ci √® molto utile per calcolare lo spazio generato dell\u0026rsquo;immagine, perch√© ci permette di fare una sorta di cambio di base (che non √® un cambio di base) stiamo solamente prendendo qualcosa di molto simile a una base, ma in un altro spazio vettoriale (non √® detto che sia una base per√≤! so solo che genera quello spazio vettoriale).\n3.3.5 Calcolo dell\u0026rsquo;immagine Avendo il teorema precedente, il calcolo del sottospazio dell\u0026rsquo;immagine √® abbastanza veloce:\nprendo l\u0026rsquo;insieme immagine della base poi faccio gauss in modo diretto su questa. SI pu√≤ dimostrare che questo non √® altro che gauss sulla TRASPOSTA.\nTeorema della dimensione In immagine √® la 5.5.1 Questo √® uno dei teoremi pi√π importanti per tutto il corso di geometria! Vale per qualunque applicazione lineare per spazi vettoriali!\nIdee per la dimostrazione\nA caratteri generali, i passi logici principali per la dimostrazione √® questa:\nPrendiamo una base di V, e la base per Ker(F). Per il completamento posso completare la base del nucleo in una base di V. Prendo l\u0026rsquo;insieme dei vettori che ho aggiunto al nucleo, voglio dimostrare che la funzione applicata a questi vettori sia in grado di generare l\u0026rsquo;immagine, se questo succede, allora ho finito perch√© ho praticamente scomposto la base di V, in una per Ker(F), e una altra per Im L. Dimostro che effettivamente quanto preso √® una base di Im F cercata, utilizzando la linearit√† dell\u0026rsquo;applicazione, e il fatto che l\u0026rsquo;insieme di vettori iniziale era base per V Dimostrazione\n3.4.1 Verifica iniettivit√† Mi pu√≤ dare in modo quasi immediato nozioni di iniettivit√† e suriettivit√†, se l\u0026rsquo;applicazione lineare ha la dimensione di kernel = 0 allora scopro subito che √® iniettiva!\nSiano dati due spazi vettoriali tali che $\\dim V \u003e \\dim W$ allora non ho cose iniettive.\nPerch√© supponiamo che ci sia tale applicazione lineare, ma al massimo l\u0026rsquo;immagine √® di dimensione W, quindi la dimensione del Kernel non √® nulla, per cui ho che non √® iniettivo per il teorema in link\n3.4.2 Verifica suriettivit√† Se la dimensione dell\u0026rsquo;immagine ha la stessa dimensione del codominio, allora ho trovato subito un una base per il codominio! Quindi so subito che √® suriettiva.\nIn modo simile se ho due spazi vettoriali tali per cui $\\dim V \u003c \\dim W$ allora non ho funzioni suriettive perch√© la dimensione di arrivo √® al massimo V.\n3.5 Isomorfismi 3.5.1 Definizione √à una applicazione lineare bigettiva\nSI pu√≤ dimostrare che se V ha dimensione n, allora √® isomorfo con $\\mathbb{R}^n$\n3.5.2 Equivalenza delle dimensioni per ISO (!! chiede) Sse due spazi vettoriali sono isomorfi allora hanno la stessa dimensione.\nDimostrazione\n$\\implies$ In quanto √® un isomorfismo si ha che √® iniettiva e suriettiva, quindi\ndim V = 0 + dim W quindi hanno la stessa dimensione.\n$\\impliedby$Suppongo che le dimensioni siano le stesse, vogliamo dimostrare che i due insiemi siano isomorfi.\nDate le rispettive basi di V e W, vogliamo costruirci un isomorfismo:\nMi costruisco la funzione e dimostro che √® suriettiva perch√© voglio mandare il vettore base 1 di V al vettore base 1 di W, cos√¨ a corrispondere fino alla dimensione Poi uso il teorema delle dimensioni per concludere che la dimensione del nucleo √® 0, per cui √® iniettiva. ","permalink":"https://flecart.github.io/notes/applicazioni-lineari/","summary":"\u003ch2 id=\"31-introduzione-e-definizione\"\u003e3.1 Introduzione e definizione\u003c/h2\u003e\n\u003cp\u003eSi definisce applicazione lineare una funzione (omomorfica) che preserva la struttura dello spazio vettoriale, ossia vale che\u003c/p\u003e\n$$\nf:V \\to W, \\text{ tale che } \\\\\nf(u + v) = f(u) +f(v)\\\\,\nf(\\lambda v) = \\lambda f(v)\n$$\u003cp\u003e\nVengono mantenute alcune caratteristiche principali.\nIn modo simile si possono definire omomorfismi per tutte le altre strutture algebriche, la cosa importante √® che lo spazio d\u0026rsquo;arrivo possieda ancora tutte le stesse operazioni.\u003c/p\u003e","title":"Applicazioni lineari"},{"content":"Perch√© a stack üü©- Capire l‚Äôarchitettura significa capire la struttura (l‚Äôorganizzazione) del nostro app e comprenderne i motivi (i sottoproblemi risolti) che ogni livello prova a risolvere\nLa soluzione che √® stata individuata, e ha rappresentato uno dei principali cardini del successo delle reti e della nascita di Internet, √® data dalla separazione delle classi di protocolli in livelli. La struttura dei livelli dei protocolli di rete prende il nome di architettura dei protocolli di rete. Il concetto di architettura dei protocolli, suddivisa in livelli, √® semplice ed √® basato su alcune condizioni.\nOgni livello\nSvolge determinate funzioni di gestione dei processi di comunicazione, attraverso uno o pi√π protocolli alternativi. Fornisce un livello di astrazione pi√π elevato della rete di comunicazione sottostante, sfruttando i servizi implementati dai livelli sottostanti. Ha relazioni dirette solo con i livelli immediatamente superiore e inferiore, attraverso richieste e servizi concordati, detti interfaccia del livello In altre parole, i livelli superiori non devono preoccuparsi di risolvere problemi che saranno gestiti e risolti dai livelli inferiori.\nLa cosa migliore per questa struttura √® che se ho bisogni differenti posso individuare il livello che mi interessa e re-mplementare solo quanto ho bisogno, senza dover cambiare l\u0026rsquo;intera stack.\nEsempio architettura a livelli (fatta dal prof in persona e rubata da altri profzz, lel)\nSi ha un esempio di trasmissione e ricezione delle informazioni tramite questa metafora.\nOgni livello risolvere un problema preciso nella fase di trasmissione dell‚Äôinformazione‚Ä¶\nLa cosa interessante √® che dal livello di dichiarazione (o app) non si vede tutto il sotto, √® come se magicamente fosse tradotto e presentato nella lingua corretta! Risolve un grande problema di complessit√†.\nVantaggi\nRiutilizzabilit√† di molti layers, basta cambiare cose di un singolo layer se ho bisogno di fare cose mie. Gli strati paritari si parlano astraendo tutto quanto avviene di sotto. Si potrebbe andare a parlare di encapsulation and data hiding cio√® tutti i dati di un singolo livello sono isolati a quello e i dati sono solamenti di questo livello. Esposte sono solamente le relazioni, come si parla sopra. (facilita anche il debuggin per singolo LIVELLO)\nArchitettura standard (OSI) !!! üü© \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Architettura e livelli 1, 2/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Architettura e livelli 1, 2/Untitled 1\u0026quot;\u0026gt; Lo Standard ISO/OSI RM (International Organization for Standardization (ISO)/Open System Interconnection Reference Model) definisce un insieme di livelli completo e rigoroso per l‚Äôarchitettura dei protocolli di rete, prevedendo un livello per la gestione di ogni problema di comunicazione in rete.\nCi√≤ che si va a standarizzare √® l\u0026rsquo;interfaccia dei vari livelli. (API)*. Mentre l\u0026rsquo;implementazione di queste funzioni √® lasciato a piacere, basta che soddisfi quello che deve fare. (Questo √® ci√≤ che permette la flessibilit√† di questra struttura). L‚Äôarchitettura dei protocolli di rete definita da ISO/OSI RM prevede sette livelli dei protocolli, numerati da 7 a 1 dall‚Äôalto al basso.\nil livello fisico si occupa di definire le tecniche di codifica dei dati, la trasmissione e la ricezione dei dati sul mezzo fisico di trasmissione (‚Üí Fisica here). livello LLC/MAC si occupa di garantire l‚Äôaffidabilit√† del mezzo di trasmissione e la gestione dell‚Äôaccesso al mezzo trasmissivo ad accesso multiplo (evitando le collisioni). A questo livello il pacchetto si chiama FRAME. MAC (Media Access Control) √® sotto. Inserisce gli indirizzi di destinatario e mittente (MAC) (spesso questi indirizzi sono solamente locali, per sapere a chi dare come step intermedio), forniti dal costruttore Decisione di quando trasmette (ad esempio pu√≤ chiedere al livello fisico se il canale √® libero o meno, e gestisce questa cosa col suo protocollo, quindi dilazionare il tempo di trasmissione) LLC (Logical link control) √® sopra Verifica che non ci siano stati errori di trasmissione delle informazioni ricevute. Dire di inviare l‚Äôacknowledgement, se √® il momento giusto. Gestire pacchetti duplicati. Il livello rete si occupa di frammentare i dati in pacchetti, scrivere gli indirizzi dei destinatari finali e instradare i pacchetti verso i destinatari intermedi del cammino. In questa sezione andiamo oltre alla rete locale, √® qui che nasce internet vero! Il router √® un elemento principale di questo. Frammentazione dei pacchetti Indirizzamento IP che servono a dare un identificativo alla scheda di rete in ambito locale per capire in quale direzione trasferire. Il livello trasporto si occupa di garantire i servizi di trasmissione dei pacchetti (orientati alla connessione e non) e del controllo della congestione della rete. Un esempio di protocollo a questo livello √® il TCP(Trasmission Control Protocol). Che fa i controlli sull‚Äôacknowledgement e simili Potrebbe essere ch ealcuni router siano congestionati, quindi che droppino alcuni pacchetti Non √® una soluzione dire agli altri router di inviare in modo pi√π lento. (Dovrebbe essere il mittente che dovrebbe rallentare nell\u0026rsquo;invio di pacchetti, in modo che non si congestionano nessun nodo). Il livello sessione mantiene e gestisce lo stato attuale del collegamento tra due applicazioni remote. (quindi poter riprendere da un certo stato quando per un certo momento ti sconnetti). Di solito questo √® gestito dall‚Äôapplicazione, e non viene implementato. Il livello presentazione risolve eventuali eterogeneit√† del formato dei dati tra i nodi della rete. Perch√© i formati sono gi√† leggibili, senza dover interpretare i bit per capire cosa rappresentano. Il livello applicazione fornisce alle applicazioni in esecuzione sul calcolatore i servizi e le primitive di trasmissione e ricezione dei dati. primitive che servono al processo di esecuzione per funzionare. es. funzione per mandare i dati e simli. Qui le funzioni possono essere moooltee Architettura dei protocolli di internet üü© In questa sezione si tratta di come effettivamente quanto dell\u0026rsquo;architettura OSI √® implementata\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Architettura e livelli 1, 2/Untitled 2.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Architettura e livelli 1, 2/Untitled 2\u0026quot;\u0026gt; L‚Äôarchitettura dei protocolli di Internet, nel senso pi√π comunemente adottato, prevede di fatto l‚Äôimplementazione di solo cinque livelli dei sette livelli dello Standard ISO/OSI RM. Rimangono spesso esclusi i livelli 5 (sessione) e 6 (presentazione), gli altri livelli sono uguali. Il motivo per cui succede √® che principalmente questi livelli sono implementati a livello applicazione.\nUn aspetto che si pone in evidenza, √® il concetto di incapsulamento dei dati tra i livelli implementati. In fase di trasmissione, ogni livello riceve dati dall‚Äôalto (dati spediti dall‚Äôapplicazione) e li inserisce in ‚Äúbuste virtuali‚Äù (incapsulamento) ponendo in testa e in coda alcuni dati aggiuntivi, necessari per fornire al livello della controparte ricevente le informazioni utili all‚Äôimplementazione del protocollo dello stesso livello. In fase di ricezione, ogni livello X riceve dal livello pi√π basso i dati imbustati dallo stesso livello X sul trasmettitore, quindi verifica i dati della busta, agisce in conseguenza alle specifiche fornite nei dati della busta, e passa solo il contenuto della busta ai livelli superiori (decapsulamento). Il livello trasporto spezza i dati dell‚Äôapplicazione in frammenti e li imbusta, aggiungendo informazioni utili all‚Äôordinamento e al riassemblaggio dei dati ricevuti, oltre che al controllo della congestione della rete.\nIl livello rete frammenta ulteriormente i dati in pacchetti (se sono troppo lunghi), scrive l‚Äôindirizzo del destinatario sulla busta, e decide il cammino sul quale inviare il pacchetto a seconda dell‚Äôindirizzo di rete del destinatario.\nIl livello MAC/LLC esegue la consegna finale dei dati a dispositivi di una rete locale.\nLivelli ISO/OSI Livello fisico\nSono a livelli fisico perch√© devono avere lo stesso mezzo fisico (eg ethernet solo ethernet!, wifi solo wifi!)\nSegmento di rete üü© - Segmento di rete\nun mezzo di trasmissione condiviso con canale ad accesso multiplo, in cui tutte le schede collegate al segmento ricevono quanto trasmesso\nGli indirizzi MAC sono consapevoli dell\u0026rsquo;esistenza di questo mezzo di broadcast, con prima il destinatario, cos√¨ lo legge subito.\nCollegarli tutti in un canale broadcast non √® che sia molto buono\nRischio di collisioni molto alto Perdita di intensit√† dei segnali elettrici Principalmente spreco di tempo ed energie. Quindi abbiamo bisogno di modi per creare segmenti per risolvere questi problemi., che facciano cose intelligenti.\nIl segmento di rete √® importante! Mini rete locale, √® anche il modo in cui mando il pacchetto al router con source e destination.\nComposizione di segmenti di rete (4) üü© Appunti prof di dispositivi per livello 1 e 2\nA questo punto esistono i presupposti per introdurre alcuni dispositivi che possono essere usati per comporre ed estendere una rete locale di calcolatori, unendo segmenti di rete altrimenti separati. Il primo dispositivo √® il ripetitore (repeater). Siccome i segnali emessi su qualsiasi mezzo fisico si degradano al crescere della distanza percorsa, esiste un limite massimo per la lunghezza di un segmento di rete. Ad esempio, un segmento Ethernet, pu√≤ variare dai 100 ai 200 metri. Un repeater √® un dispositivo che agendo solo a livello fisico, amplifica e rigenera il segnale ricevuto verso un prolungamento del segmento di rete. Mediante un repeater √® possibile collegare due segmenti di rete aventi la stessa tecnologia a livello MAC, ed estendere la lunghezza dei segmenti di rete locale. Un Hub (che significa perno di una ruota a raggi) √® un altro dispositivo che agisce solo a livello fisico. Esso realizza il punto centrale di connessione, detto concentratore, dei segmenti di una rete locale con topologia a stella. In pratica si tratta di un ripetitore (repeater) con tante connessioni entranti e uscenti. Un Bridge (ponte) √® invece un dispositivo che agisce anche da traduttore a livello due (MAC/LLC). Un bridge permette di connettere segmenti di una stessa rete locale ma con tecnologie e MAC diversi tra loro (ad esempio un segmento Ethernet con uno Token Ring). I bridge fanno quindi da traduttori dei frame nei formati richiesti dal livello MAC di ogni segmento connesso al bridge, e provvedono alla trasmissione su segmenti diversi adottando il protocollo MAC opportuno. I Bridge sono dotati della capacit√† di filtrare e instradare opportunamente i frame di dati sul segmento opportuno, osservando sui frame le informazioni di indirizzo MAC del dispositivo destinatario. Uno Switch (commutatore) √® un dispositivo di livello due (MAC/LLC) analogo al bridge. Al contrario del bridge, esso permette di connettere un numero maggiore di segmenti diversi (fino a 10 o 12).\nRepeater\nRipetitori. I segnali trasmessi sul mezzo fisico degradano con la distanza, nella fattispecie l‚Äôethernet degrada dopo circa 200 metri, quindi ogni 200 (o, meglio, 100) metri si aggiunge un ripetitore. Il ripetitore amplifica e rigenera il segnale ricevuto. Il repeater collega due segmenti di rete che hanno la stessa tecnologia MAC; non legge i dati, vede semplicemente che sta arrivando un segnale e lo amplifica e passa oltre. Con l‚Äôallungarsi delle distanze chiaramente le trasmissioni impiegano un po‚Äô di tempo in pi√π per viaggiare da mittente e destinatario, quindi nel caso di reti LAN pi√π grandi diventa necessario allungare i tempi di timeout.\nHub\n√à un repeater multiporta. √à il nodo centrale di una rete a stella. Quando riceve un segnale da una porta lo copia e lo manda a tutti gli altri elementi della rete. √à usato pochissimo in quanto costa poco meno dello switch, che per√≤ offre pi√π funzionalit√† e porte.\nBridge\nhub ripete tutto quanto ha avuto a tutti quanti sono collegati, ma ha il problema grosso delle collisioni\nSwitch\nConnette tecnologie omogenee.\nriesce a filtrare e inviare i frame al segmento giusto. Quindi si comporta come un hub quando non sa dove andare, ma riesce ad ascoltare gli segmenti e vedere se √® libero, se √® libero manda, e se torna l‚ÄôACK allora aggiorna la propria tabella dei segmenti che mappa il MAC con il segmento corretto.\nAppunti di bianchi\nLavora a livello 2. A differenza del bridge permette di connettere molti pi√π segmenti (oggi gli switch hanno anche 96 porte). Interconnette tecnologie omogenee, non diverse, e filtra i pacchetti da inoltrare a seconda della loro destinazione. Manda i dati in broadcast solo se non sa dov‚Äô√® il destinatario. - Buffered switch: ha un buffer di memoria che ha la funzione di memorizzare tutti i frame che arrivano. Questo siccome la trasmissione deve essere smistata e non √® automatica, ma segue le regole del protocollo MAC, pu√≤ essere necessario che una trasmissione debba attendere il completamento di un‚Äôaltra precedente.\nBridge\nFunziona come uno switch (quindi lavora a livello 2) ma connette tecnologie a livello locale con MAC protocol diversi (ad es. Ethernet e Wifi). Se riceve trasmissioni da un protocollo (ad es. Ethernet) e deve mandarle ad un altro protocollo (ad es. Wifi) prende il pacchetto, lo smembra e lo ricostruisce in un frame compatibile con l‚Äôaltro protocollo (i dati cambiano la ‚Äúbusta gialla‚Äù).\nNote sui primi 2 livelli Livello fisico üü© √à il livello della scheda di rete, dei mezzi di trasmissione fisici, codifica e decodifica dei segnali in analogici e digitali.\nImportante in questa parte √® il concetto di velocit√† del mezzo trasmissivo e velocit√† di trasmissione.\nLa velocit√† di trasmissione dipenda dalla durata del vagone, o della rappresentazione dei dati nel mezzo trasmissivo.\nAppunti prof Livello fisico I valori possibili per i dati digitali (bit) del calcolatore sono solo due: i valori 0 e 1. Tali valori devono essere trasmessi o ricevuti sui mezzi di trasmissione delle reti, sotto forma di variazioni di segnali analogici (elettrici, ottici o radio), uno di seguito all‚Äôaltro. Per questo scopo, i dati digitali devono essere opportunamente codificati o decodificati, in sequenza, da parte della scheda di rete. L‚Äôattivit√† di codifica, effettuata in fase di trasmissione, equivale a tradurre i valori dei bit in segnali analogici. L‚Äôattivit√† di decodifica, effettuata in fase di ricezione, equivale a tradurre i segnali analogici ricevuti nei valori dei bit. Le tecniche di codifica digitali permettono di ridurre, ma non di escludere completamente, la possibilit√† di errori di trasmissione sulla rete. Una nota importante riguarda l‚Äôambiguit√† di fondo sul concetto di velocit√† della trasmissione dei segnali in rete. Dal punto di vista fisico, tutti i segnali analogici, elettrici, ottici o radio, si propagano praticamente alla stessa velocit√†, cio√® alla velocit√† della luce, pari a circa 300.000 Km/sec. Non ha quindi senso parlare di bit, oppure di segnali, pi√π veloci di altri. Tuttavia, nell‚Äôesempio in figura, un canale A di comunicazione sul quale siano codificati dieci bit al secondo ha una densit√† di trasmissione dei bit (detta anche capacit√† del canale) pari alla met√† della capacit√† ottenuta da un canale B, sul quale possano essere codificati venti bit al secondo. I canali a capacit√† pi√π elevata, ovvero in grado di trasmettere pi√π bit al secondo, devono tali prestazioni al fatto di usare meno tempo per codificare, ovvero rappresentare il valore del bit sul mezzo trasmissivo, rispetto a canali pi√π ‚Äúlenti‚Äù. Le migliori tecnologie di rete sono quelle che permettono di codificare i bit nel minor tempo possibile, ottenendo quindi alte capacit√† dei canali (ad esempio, miliardi di bit trasmessi al secondo). Livello di collegamento üü© MAC\nCanale Mac di broadcast\nStruttura e utilizzo dell\u0026rsquo;indirizzo MAC\nPolicies generali per l‚Äôarbitraggio del canale per risolvere le collisioni.\nAppunti prof Livello Mac\nAnalizziamo ora l‚Äôesempio pi√π semplice per la definizione di una rete di calcolatori a commutazione di pacchetto: un segmento di rete locale. Un segmento di rete locale √® definito come un mezzo di trasmissione condiviso sul quale sia definito un canale ad accesso multiplo.\nOgni calcolatore si assume dotato della scheda di rete opportuna per il mezzo trasmissivo e i protocolli di codifica utilizzati al livello uno (fisico). Ogni scheda di rete √® dotata di un identificativo (indirizzo) di livello MAC unico al mondo (assegnato dal costruttore). Ogni trasmissione di un pacchetto di dati (detto frame a questo livello) sul canale ad accesso multiplo √® ricevuta da tutti i calcolatori la cui scheda di rete sia connessa al canale stesso. Immaginiamo che il dispositivo con indirizzo MAC1 voglia spedire un frame di dati al dispositivo con indirizzo MAC5, e allo stesso tempo il dispositivo di indirizzo MAC4 voglia spedire un frame di dati al dispositivo di indirizzo MAC2.\nNel contesto del canale condiviso, la conoscenza degli indirizzi MAC dei dispositivi mittente e destinatario basta ad effettuare la trasmissione, sul canale comune. Semplificando molto il problema, per ragioni di presentazione, √® sufficiente aggiungere le informazioni sull‚Äôindirizzo MAC del destinatario e del mittente sulla busta di ogni frame, prima di trasmetterlo.\nOgni frame trasmesso sul canale da parte di ogni dispositivo risulta quindi rilevato da tutti gli altri dispositivi, ma viene ricevuto (cio√® copiato e passato ai livelli superiori) solo se l‚Äôindirizzo MAC del destinatario specificato nel frame coincide con l‚Äôindirizzo MAC del dispositivo ricevente. Il compito principale dei protocolli di livello 2 (MAC/LLC), oltre all‚Äôindirizzamento dei frame trasmessi sul canale condiviso del segmento di rete locale, √® dato dall‚Äôarbitraggio degli accessi al canale. Ossia\nDeterminare i nodi che possono trasmettre Quando possono trasmettere L‚Äôordine di trasmissione per evitare collisioni LLC\nControllare se i dati sono corretti, o ricevuti doppi (se doppio o errato faccio finta di non averlo ricevuto). Mandare acknowledgment (che non succede col broadcast). Appunti prof affidabilit√† di questo livello (ACKs) Scopo dei protocolli del livello 2 (MAC/LLC) √® nascondere ai livelli superiori i dettagli del mezzo fisico, e mostrare il canale condiviso sul segmento di rete locale come se si trattasse di un canale affidabile, senza alcun errore di trasmissione. A tal fine il frame di dati viene delimitato mediante particolari etichette di bit, poste all‚Äôinizio e alla fine del frame, e viene arricchito con altri campi di dati utili al protocollo. La trasmissione di un frame procede per tentativi, fino alla ricezione di una conferma (un frame di conferma) da parte del destinatario. Quello qui illustrato √® solo un meccanismo semplice per realizzare trasmissione affidabile, tra quelli possibili. La figura mostra la sequenza temporale di eventi gestiti dal livello 2 (MAC/LLC) per la trasmissione affidabile di un frame di dati tra due dispositivi sulla stessa rete locale. Il frame di dati viene spedito dal dispositivo con indirizzo MAC1 al dispositivo con indirizzo MAC2 sul mezzo trasmissivo. Il mittente fa partire un timer dopo la trasmissione. Il ricevente MAC2 si accorge che il frame √® destinato a lui, ma rileva errori sui bit ricevuti, per cui non fa nulla (non passa il frame ai livelli superiori) e non invia la conferma a MAC1. Allo scadere del timer, MAC1 verifica che non ha ricevuto conferma, per cui ripete da capo la trasmissione, e fa ripartire il timer. Questa volta MAC2 riceve correttamente il frame e spedisce a MAC1 un frame di conferma. MAC1 riceve il frame di conferma e solo ora considera terminata con successo la trasmissione del frame. Ai livelli dei protocolli superiori al livello due tutto ci√≤ viene nascosto, e appare solamente la trasmissione corretta del frame sul segmento di rete. Collaborazione livelli per affidabilit√† (!!)üü© Acknowledgement livello 4\nNon √® sufficiente verificare che funzioni a livello 2, bisogna anche avere un ACK a livello 4 che sia end-to-end, cos√¨ so sicuro che tutto il processo passo passo a livello MAC funziona, ossia sono riuscito effettivamente a raggiungere il destinatario.\nQuindi serve questo ack a livelli diversi e tempi diversi (uno fa end-to-end ack, l‚Äôaltro fa ack ogni step). Ma l‚ÄôACK a livello 4 √® necessario, perch√© il mittende deve sapere se sia ricevuto, mentre il livello 2 non sarebbe strettamente necessario, ma √® molto probabile che vada male qualcosa a livello intermedio, e questo ACK riesce a risolvere problemi a questo livello ritrasmettendo.\nLivello 2 Evitare che un fallimento di singolo frame fallisca l‚Äôintera trasmissione a livello pi√π alto (e quindi riuscire a recuperare molto pi√π in fretta se viene perso a questo livello). Livello 4 Informare il mittente che l‚Äôinformazione √® stato ricevuto correttamente (quindi end-to-end). Caso di segmento faulty !\nNel caso in cui il livello MAC non riesce proprio a ricevere l‚ÄôACK, questo lo comunica al livello di Rete che ha una immagine della sua topologia di rete, e prova a creare un nuovo percorso per arrivare a destinazione. Si vede qua come avere pi√π strare possibili per arrivare alla destinazione sia necessario.\nAlcune tecnologie di rete üü© Ethernet Il pi√π famoso √® il protocollo Ethernet che da il nome a una vasta serie di schede di rete che implementano la sua definizione, per l‚Äôutilizzo in reti locali basate su mezzo fisico cablato. L‚Äôidea di base di Ethernet, per ridurre le collisioni dei segnali, √® di adottare il principio dell‚Äôascolto del canale, prima di ogni trasmissione (se vede che √® occupato, viene rigenerato un tempo di attesa casuale). Se nessuno sta gi√† trasmettendo, allora la trasmissione pu√≤ essere iniziata senza collisione con le trasmissioni in atto. Siccome pu√≤ accadere che due schede di rete possano iniziare allo stesso istante le rispettive trasmissioni, occorre trovare una soluzione all‚Äôinsorgere di possibili collisioni. La scheda di rete trasmittente √® in grado di rilevare le collisioni in atto durante la trasmissione, e in tal caso interrompe immediatamente il tentativo di trasmissione. Il tentativo verr√† tentato da capo, dopo un attesa di tempo casuale, variabile da scheda a scheda.\nWifi Una tecnica simile a Ethernet viene adottata nelle reti senza fili (wireless), ad esempio in reti Wi-Fi conformi allo Standard IEEE 802.11. Il problema principale in reti senza fili √® dato dall‚Äôimpossibilit√† pratica di realizzare la rilevazione di collisioni in atto durante la fase di trasmissione. La tecnica si basa sulla prevenzione delle collisioni, dilazionando nel tempo i tentativi di accesso.\nToken Ring Il protocollo Token Ring √® un protocollo MAC concepito per reti locali con topologia ad anello. L‚Äôaccesso √® regolato per mezzo di un frame speciale, detto Token, che viene passato (trasmesso), come se fosse un ‚Äútestimone‚Äù, ciclicamente tra tutti i dispositivi in rete. Solo chi detiene il token ha diritto di trasmettere sul canale, evitando il rischio di collisione, dopodich√© deve trasmettere il token alla stazione successiva nell‚Äôanello.\nLa cosa bella di questo √® che la trasmissione √® necessariamente senza collisioni dato che parla solo uno alla volta, questo √® una cosa molto bella.\nUn altra cosa √® acknowledgement implicito perch√© se il messaggio ritorna al mittente uguale, allora √® OK. Potrei anche costruire comunicazioni a pochi bit, veloci (simili a voice over IP).\nSvantaggio\nNon ho modo di recuperare se\nPerdo il token (questo √® una cosa molto grave!). Un host va gi√π, e viene rotto il link. (unique point of failure!) Note generali\nQueste reti si identificano tutte come best effort perch√© possono sempre non funzionare, causa collisioni o interferenze di rete\nEsempio di rete locale Appunti prof di boh La figura mostra un esempio di rete locale composta da diversi segmenti: un segmento con topologia ad anello e protocollo MAC di tipo token ring colorato in rosso e da vari segmenti ethernet, con topologia a stella e a bus, colorati in blu. A sinistra, un calcolatore dotato di dispositivo di rete token ring con indirizzo MAC A √® connesso a un anello di rete token ring insieme ad altri 3 calcolatori e insieme a un bridge (oppure uno switch) identificato dal colore giallo (per indicare che agisce a livello MAC/LLC) e dalla lettera B sullo schermo. Il bridge B agisce da collegamento e traduttore dei frame tra il segmento token ring (rosso) ed il successivo segmento ethernet (blu). Il bridge B ha quindi due connettori di rete: uno token ring e uno ethernet. Il segmento ethernet del bridge B √® connesso a un Hub (H) dal quale partono sei segmenti ethernet, di tipo punto a punto, verso altrettanti calcolatori. Uno di questi calcolatori, identificato dalla lettera R √® un repeater, che propaga e amplifica i segnali verso un successivo segmento ethernet con topologia a bus, sul quale esistono quattro calcolatori. Al termine del bus esiste un nuovo repeater R, che propaga e amplifica i segnali verso un ultimo segmento ethernet con topologia a bus, al quale √® collegato un calcolatore dotato di scheda ethernet con indirizzo MAC B. Al di sopra dei dispositivi citati viene rappresentato il cammino logico di un frame trasmesso dal calcolatore con MAC A al calcolatore con MAC B, passando per i segmenti, i connettori di rete, e i livelli dei protocolli opportuni. In particolare, il bridge B √® l‚Äôunico elemento nel quale il frame trasmesso sul segmento token ring sale fino al livello 2, per essere tradotto e ritrasmesso sul segmento uscente adottando il nuovo protocollo MAC ethernet. Nei rimanenti dispositivi hub e repeater, i frame sono semplicemente ricevuti e ri-trasmessi sui segmenti uscenti. Se il bridge avesse dovuto connettere pi√π di due segmenti diversi, allora si sarebbe utilizzato uno switch, che svolge l‚Äôattivit√† del bridge gestendo pi√π interfacce di rete e protocolli. Dovrebbe essere chiaro a questo punto come sia possibile connettere diversi segmenti di rete locale, e gestire la trasmissione di frame di dati tra due dispositivi qualsiasi di una rete locale, semplicemente identificando i dispositivi attraverso il loro indirizzo MAC. ","permalink":"https://flecart.github.io/notes/architettura-e-livelli-1-2/","summary":"\u003ch3 id=\"perch√©-a-stack--\"\u003ePerch√© a stack üü©-\u003c/h3\u003e\n\u003cp\u003eCapire l‚Äôarchitettura significa capire la struttura (l‚Äôorganizzazione) del nostro app e comprenderne i motivi (i sottoproblemi risolti) che ogni livello prova a risolvere\u003c/p\u003e\n\u003cp\u003eLa soluzione che √® stata individuata, e ha rappresentato uno dei principali cardini del successo delle reti e della nascita di Internet, √® data dalla separazione delle classi di protocolli in livelli. La struttura dei livelli dei protocolli di rete prende il nome di architettura dei protocolli di rete.\nIl concetto di architettura dei protocolli, suddivisa in livelli, √® semplice ed √® basato su alcune condizioni.\u003c/p\u003e","title":"Architettura e livelli 1, 2"},{"content":"A seconda dell\u0026rsquo;utilizzatore l‚ÄôOS pu√≤ essere molte cose, come solamente l‚Äôinterfaccia se sei un programmatore, servizi (se sei un utente, ma gran parte dei servizi sono astratti e l\u0026rsquo;utente ne pu√≤ anche essere a non-conoscenza).\nMa se sei un programmatore OS ti interessa capire le componenti principali dell‚ÄôOS\nSlide componenti OS alto livello Introduzione sui componenti (salto) Questa parte la salto perch√© √® una descrizione molto generale di cosa si occupa L‚Äôos verso drivers, processi, filesystem I/O, quindi non √® molto importante\nGestione dei processi All\u0026rsquo;interno del SO, il processo √® rappresentato come un processo control block, che in linux √® in sched, parte dello scheduler dei processi. Questo √® importante perch√© per esempio per fare una fork, non faccio altro che duplicare questa struttura e settare bene i figli e genitori.\nQuesti sono solitamente messi un un process table o forse una lista per tenerne traccia.\nSlide\nnel parliamo in Processi e thread.\nGestione memoria principale e secondaria Principale\n√à un array temporaneo(nel senso che non √® mantenuto quando viene spento il PC.), indicizzato singolarmente a differenza del secondario, che √® indicizzato a blocchi,\nUna parte importante di questa parte √® la gestione della memoria virtuale. Come allocare pagine di memoria, deallocarle e simili, ne parliamo in Paginazione e segmentazione\nSecondaria\nLa cosa buona √® che questa memoria √® permanente, efficienza (ordinare le richieste per non andare qui e l√¨ quando si legge! minimizare tempi per seek) e partizionamento e reliability dei dischi sono problemi che interessano questa parte. Abbiamo parlato di raid in Memoria. e di nuovo in Devices OS.\nSlide\nI/O e filesystem Principalmente per IO servono driver per interagire con specifici hardware, e un sistema di comunicazione che spesso sono buffer e cache.\nSlides\nEsiste un file system virtuale che mappa a tutto (quindi alcune cose non esistono realmente sul disco, potrebbe essere una astrazione utilizzata per esempio per comunicare con i devices.\nCi sono molti filesystem, che per√≤ posso gestire in modo differente la forma che hanno sul disco, Ed √® per questo che possiamo dire che esistono dei filesystem diversi.\nAnche i processi sono files, la cosa figa di questa astrazioen √® che posso utilizzare gli stessi sistemi di protezione file per processi.\nStruttura dei sistemi Obiettivi di design dei SO (4) üü® Slide obiettivi nella struttura dei sistemi (4)\nEfficienza\nModularit√†\nMantenibilit√†\nEspansibilit√†\nStruttura del kernel üü© Slide riassuntiva\nIl kernel √® un unico processo, parte da un main che parte da un initialize in cui raccoglie tutte le risorse del sistema, fa partire tutti i device drivers e crea il PCB del primo processo, anche chiamato init, messo poi nella queue dello scheduler come spiegato in Scheduler. Fatta una volta non √® mai pi√π eseguito quel codice di init.\nLo stato kernel √® la parte a sinistra dell‚Äôimmagine, quella parte blu, tutto il giallo, a destra √® lo stato user.\nScheduler scegliere il processo da eseguire nello user space Il controllo √® passato al processo user, che pu√≤ fare traps (come fork) o fare I/O, a quel punto √® rimesso a codice kernel. Tipologie di struttura OS (2) üü®++ Solitamente i sistemi sono costruiti in due modi, sistemi semplici senza struttura, che praticamente c\u0026rsquo;√® una prima versione, e poi viene ammassato roba senza struttura generale, fatti quando servono. Solitamente sono insieme di procedure che si chiamano fra di loro, e ben presto sono andate fuori dal loro ambito di interesse diciamo (fuori dal loro scope)\nEsempi di OS semplici:\nUn esempio √® free-dos che √® quanto installato su un computer senza sistema operativo.\nIn modo simile √® MS-DOS, che √® stato fatto per i primi personal computer, che non avevano un sistema kernel a livello hardware (non era quindi possibile fare queste protezioni).. In generale in questo ambiente un programma aveva accesso all\u0026rsquo;intera memoria, e poteva mandare in crash tutto.\nStruttura Free-DOS\nUNIX, √® diviso diviso in due parti in kernel e programmi di sistemi, molto semplice, un kernel monolitico, un unico eseguibile, anche questo fu all‚Äôepoca limitato enormemente dal suo hardware, e una serie di programmi di sistema.\nDato che c\u0026rsquo;√® una separazione, l‚Äôutente √® separato dall‚Äôinterfaccia dal codice kernel. Ma comunque il codice kernel resta vulnerabile, e potrebbe essere modificato e quindi attaccato, o cumunque vulnerabile a bug, anche colposi, distruttivi.\nStruttura UNIX\nStratificazione OS:\nLa struttura a stati √® pi√π affidabile dell\u0026rsquo;altra e rende pi√π facile la programmazione di tale sistema, utili, la logica √® la stessa presentata in Architettura e livelli 1, 2, per la divisione a stack del sistema e dei vantaggi che si hanno con questo tipo di architettura.\nEsemplificazione struttura a strati\nStrutture proposte classiche (non fatte, non importanti)\nQuesti sono rimasti accademici\nMa nella pratica questi strati sono rimasti solamente a livello accademico, perch√© crea overhead anche se si guadagnerebbe in manutentibilit√† e estensibilit√† e gestione, quindi molto meno efficiente, inoltre non erano ben chiare le API fra strati. Oggi c\u0026rsquo;√® una forma intermedia (non c\u0026rsquo;√® esattamente la gestione a strati come abbiamo per Web, ma abbiamo una divisione per componenti e responsabilit√† delle componenti).\nPolitiche e meccanismi üü© La suddifivisione politiche e meccanismi √® un pattern di software engineering che lo rende molto comodo da gestire.\nInvece che una gestione a strati come per le reti, abbiamo una gestione di politiche e meccanismi ossia abbiamo qualcosa che decide cosa andare a fare e qualcosa che gestisce il come farla.\nEG. un certo modo di memoria allocata per fare qualcosa, quindi indirizzare il sistema verso qualcosa, e MMU che attualmente implementa la decisione politica.\nEsempio Microkernel o MINIX:\nIl kernel √® visto come il meccanismo quindi le parti di gestione e politica sono fuori dal kernel. Questo rende la struttura del SO molto mantenibile ed estendibile.\nSlide\nEsempio Mac OS ‚â§ 9 / Windows 9x:\nPolitiche e meccanismi sono messi tutti nel kernel, perch√© cos√¨ imponevo un feeling unico al look and feel suo (obbligato tutti ad avere questi elementi grafici). Questo √® un problema praticamente di mercato.\nQuesto era brutto perch√© la grafica pu√≤ mandare in crash tutto il sistema. Anche se i nuovi sistemi non dovrebbero avere questo problema.\nCategorizzazione dei Kernel (3) üü®‚Äî Monolitici:\nIl kernel √® un unico programma. Si possono creare moduli che poi vengono caricati. Il problema principale di questo tipo di kernel √® che se un modulo bugga crolla l\u0026rsquo;intero sistema. Un vantaggio √® che √® molto efficiente perch√© non deve passare ad astrazioni come per lo stack, basta fare una chiamata di funzione, tanto siamo nello stesso programma. Ed √® altamente modularizzabile per poter attaccare nuove funzionalit√†.\nIn breve:\nVantaggi\nEfficienza Modularit√† e mantenibilit√† (non devo ricompilare tutto, basta runtime). Svantaggio\nUn modulo pu√≤ mandare in crash tutto, perch√© √® eseguito nello stesso spazio del kernel.\nSlide\nEsempi sono Linux o BSD.\nMicrokernel:\nL‚Äôobiettivo del microkernle √® isolare solamente le funzionalit√† essenziali e tenere solo quelli, tutto il resto interagisce con esso con system call (un esempio √® il filesystem che potrebbe essere fuori dal kernel, e avrebbe syscall leggermente diverse rispetto a quelle di linux, per aprire un file allora si chiederebbe a questo processo in user space, che poi fa altre richeste per kernel space)\nBisogna fare un messaggio, la syscall diventano Send! Che sarebbe unico modo per raggiungere il processo che offre il servizio che mi serve.\nVantaggi: üü•\nAltissima modularit√† e mantenibilit√† del sistema e semplice da realizzare Assenza di danni di sistema, perch√© moduli e kernel sono eseguiti in spazio differente. Sicuro e affidabile per la divisione (non ho propagazione di errori e guasti) Molto portabile, che ho solo il microkernel. Svantaggio:\nFortemente Inefficienza rispetto al monolitico, che devo fare message passing e comunicazione.\nSlide di comparazione\nKernel Ibridi\nSono dei microkernel modificati, con qualcosa in pi√π forse (aziende per pubblicizzarsi dicevano di avere microkernel, ma con un ibridone, mettendo le cose inefficienti del microkernel dentro il kernel).\nEsempio windows\nCi sono diversi server, che fanno parte di un sottosistema d‚Äôambiente che √® in grado di emulare certe cose (sono nascoste le syscall reali del sistema cos√¨).\nIl codice per un certo ambiente funziona anche nel sottosistema, un esempio √® un WSL.\nLa parte grafica importante per fare i videogiochi, √® dentro il kernel, questo ad esempio per MACOS, perch√© volevano imporre la grafica simile\nMacchine virtuali Virtualization allows a single computer to host multiple virtual machines, each poten- tially running a completely different operating system.\n√à virtuale nel senso che la macchina virtuale ha la stessa percezione della realt√† di una macchina reale. Qualcosa che non √® la realt√† ma appare molto simile ad essa.\nStoricamente parlando le macchine virtuali erano un primo approccio al multitasking.\nL‚Äôidea principale √® creare un sistema che possa apparire al sistema operativo come hardware, in questo modo posso utilizzare un programma per emulare un altro sistema operativo. √à hypervisor, VMM (virtual machine monitor).\nOvviamente ho uno fortissimo svantaggio in velocit√†, perch√© la simulazione software √® molto meno efficiente della simulazione hardware. Un collegamento carino √® con strange loops, una macchina che sia abbastanza espressiva da poter emulare s√© stesso.\nAnalisi vantaggi svantaggi üü® Posso avere sistemi operativi differenti sulla stessa macchina o SO, quindi posso sperimentarli senza installarli veramente. Posso simulare architetture differenti, e quindi supporre di avere istruzioni differenti di architettura altra! SO monotask in sistemi multitask??? Maggiore sicurezza a bug software, √® efficienza energetica Svantaggi:\nfortemente inefficiente Difficile condividere risorse fra una macchina virtuale o all‚Äôaltra. Livello processo o sistema üü© Le macchine virtuali di cui abbiamo parlato ora virtualizzano solamente l‚Äôhardware, cio√® fa finta di avere un sistema hardware???\nMentre altre macchine virtuali provano a virtualizzare a livello di ABI (application binary interface) (che √® livello di processo).\nMacchina virtuale a livello di processo (process VM): permette ad un programma di essere eseguito allo stesso modo su qualsiasi piattaforma. Viene eseguita come una normale applicazione all\u0026rsquo;interno di un SO ospite e supporta un singolo processo. Il suo scopo √® fornire un ambiente indipendente dalla piattaforma hardware e dal SO ospite. Vengono virtualizzati sia l‚Äôhardware che il sistema operativo. Macchina virtuale a livello di sistema (system VM): permette l\u0026rsquo;esecuzione di un completo SO, anche con un ISA diverso da quello della macchina reale. Viene virtualizzato esclusivamente e completamente l‚Äôhardware Differenza type 1 and 2 hypervisors type 1 hypervisor and a type 2 hypervisor is that a type 2 makes uses of a host operating system and its file system to create processes, store files, and so on. A type 1 hypervisor has no underlying support and must perform all these functions itself (it runs on the bare metal, come se fosse lui stesso un sistema operativo, √® infatti un sistema operativo che non fa altro che fare sistemi operativi!)\nQemu üü© qemu √® un traduttore dinamico come se fosse un compilatore fra una architettura in una altra, fatta a runtime (quindi √® un interprete, tipo 10x pi√π lento rispetto esecuzione normale, ma un ordine di grandezza pi√π veloce rispetto altri emulatori).\nCon qemu posso anche dire al processo emulato di utilizzare il mio stesso kernel, nel caso che condivida l\u0026rsquo;architettura, questo rende la cosa molto pi√π veloce del normale! e.g. KVM (che √® il nome dell‚ÄôHypervisor per linux). Questo √® anche una tipologia di type-2-hypervisor perch√© attingo al kernel della macchina ospite per fare funzionare pi√π in fretta, e non faccio simulazione sistema totale.\nUtile o per runnare programmi per architettura differente (in questo senso program VM), oppure per emulare un sistema operativo dentro un sistema operativo\nComando per caricare una macchina virtuale con qemu e utilizzare KVM senza vga, non starebbe sullo schermo senza quella flag. hda gli specifica il file con cui emulare il disco, k il layout del keyboard m √® la memoria ram monitor √® per poter mandare interrupt dal terminale in cui ho lanciato il mio comando di emulazione. Quando installa prima √® installato nella RAM disk, e poi viene utilizzato per l‚Äôinstallazione vera e propria.\nXEN üü© XEN √® hypervisor livello 1 (SO che permette di fare altri SO virtuali), e utilizzare paravirtualizzazione (si fanno trap and emulate principalmente) , e utilizza una gestione diversa dei drivers che possiede, ossia il Domain0 possiede tutti i drivers fisici (le interazioni con i device le manda alla macchina 0, perch√© per restare un sistema operativo semplice non riesce a gestire sistemi operativi).\nParavirtualizzatione\nIn questo caso il SO virtuale √® a conoscenza che esiste un hypervisor quindi pu√≤ fare delle hypercall per eseguire delle istruzioni sensitive, e in generale √® un approccio pi√π veloce invece della virtualizzazione totale di cui abbiamo parlato prima.\nEsempio di maggiore efficienza\nPer il type 2 hypervisor il SO installato pensa veramente di stare in una macchina s√©, quindi fa cose per minimizzare i seek del disco ma in questo caso non deve fare veramente seek, quindi √® meno efficiente, facendo una assunzione errata.\nSi utilizzano paravirtualizzazione, ossia devices virtuali pi√π efficienti per questa cosa, ed effettivamente non assumo di stare utilizzando device fisici, ma sono a conoscenza di utilizzare device virtuali, e posso fare ottimizzazioni del caso (che non so quali siano forse per il disco non faccio cose strane per il seek ad esempio).\nIl problema √® che essendo a conoscenza, dovrei fare il mio SO in modo che sia compatibile con le hyper all offerte dall hypervisor\nParametrizzazione SO üü© Essendo libero linux, √® molto comodo poter cambiare alcuni parametri e poi ricompilare il kernel seguendo quei parametri. Tanto √® tutto open source, quindi si potrebbe fare. Questo permette al kernel di essere molto portabile.\nUna cosa molto importante da capire √® che il kernel √® una cosa diversa della distribuzione, il kernel √® il primo programma che viene caricato dal bootloader e carica il FS e tutto il resto (quindi le cose iniziali), il secondo sono tutte le utility per il kernel che lo rendono utilizzabile da un utente normale.\nComando runnato per la emulazione kernel/distribuzione\nSlide parametrizzazione ++ portabilit√† (che deve runnare per hardware differentI)\nIstruzioni di virtualizzazione üü• Abbiamo aggiunto delle istruzioni di emulazione come VMX ON, VMX OFF, VMLAUNCH, VMRETURN in cui il processore sa di stare emulando, e quindi √® pi√π veloce perch√© esegue l\u0026rsquo;istruzione in altro modo, forse con istruzione nativa. Pagina wiki\nfa pensare di essere in kernel mode, ma non √® in kernel mode, √® come se stesse in un livello di priviliegio intermedio.\nVMLAUNCH\nQueste sono quelle principali istruzioni che permettono la virtualizzazioen a livello software, il fatto che rende l\u0026rsquo;esecuzione molto pi√π veloce, quindi invece di simulare tutto sopra il sistema operativo attuale (e syscalls attuali) posso accedere ad istruzioni hardware molto pi√π veloci.\nMemoria Virtuale (non fare) C\u0026rsquo;√® una MMU del sistema operativo che mappa alla VM fisica, che si deve basare all\u0026rsquo;indirizzo logico, che deve essere risolto dalla MMU reale fino ad avere un indirizzo fisico.\nMINI SCHEMA\n","permalink":"https://flecart.github.io/notes/architettura-software-del-os/","summary":"\u003cp\u003eA seconda dell\u0026rsquo;utilizzatore l‚ÄôOS pu√≤ essere molte cose, come solamente l‚Äôinterfaccia se sei un programmatore, servizi (se sei un utente, ma gran parte dei servizi sono astratti e l\u0026rsquo;utente ne pu√≤ anche essere a non-conoscenza).\u003c/p\u003e\n\u003cp\u003eMa se sei un programmatore OS ti interessa capire le componenti principali dell‚ÄôOS\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSlide componenti OS alto livello\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Architettura software del OS/Untitled.png\" alt=\"image/universita/ex-notion/Architettura software del OS/Untitled\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"introduzione-sui-componenti-salto\"\u003eIntroduzione sui componenti (salto)\u003c/h2\u003e\n\u003cp\u003eQuesta parte la salto perch√© √® una descrizione molto generale di cosa si occupa L‚Äôos verso drivers, processi, filesystem I/O, quindi non √® molto importante\u003c/p\u003e","title":"Architettura software del OS"},{"content":"Significato di astrazione L\u0026rsquo;astrazione √® una cosa fondamentale nell\u0026rsquo;informatica, l‚Äôabbiamo visto anche nella prima lezione in assoluto per architettura, il sistema a strati di Architettura e livelli 1, 2 reti e simili.\nIl principali metodi sono astrazioni sul controllo e sui dati sui dati stiamo cominciando a parlarne in Teoria dei Tipi.\nLe astrazioni sono utili a nascondere dettagli per qualche fenomeno o simile (ricorda l\u0026rsquo;esempio della mappa, che non √® il territorio √® una astrazione su essa, che contiene ancora informazioni utili). Vogliamo quindi concentrarci su quanto ci interessa\nuna cosa che a noi √® molto interessante √® la astrazione funzionale\nAstrazione funzionale üü© Vogliamo creare una associazione fra funzione e procedura, ossia esporre solamente cose come intestazione della funzione, parametri e valore di ritorno per descrivere una funzione, la implementazione non ci interessa.\nSi pu√≤ ben notare che meno la funzione interagire con l‚Äôambiente non locale, ossia pi√π √® indipendente, ha meno side effect, meglio √® fatta sta astrazione.\nComunicazione con l‚Äôambiente (3) üü© la comunicazione con l‚Äôambiente pu√≤ avvenire mediante tre metodi principali.\nParametri Ambiente no nlocali Il valore di ritorno Formali e attuali e 3 comunicazione üü© Nella dichiarazione di funzione si parla di parametri formali, nel senso che sono delle variabili legate, se rinominate correttamente attraverso funzioni definite in Logica si pu√≤ cambiare nome.\nUn parametro attuale √® quello effettivamente mandato, che si fa mediante la chiamata di funzione.\nSlide formali e attuali\nAnche il flusso di informazione pu√≤ essere diviso in pi√π modi.\nin entrata (come il passaggio per valore) In uscita (boh, si assegna il valore ebbasta, senza leggerle). In entrata e uscita (come le reference) Passaggio di parametri Passaggio per valore üü© Questo √® il classico passaggio di funzione che abbiamo in C.\nViene calcolato il valore (r-value)\nil valore viene messo sulla pila, quindi come se fosse una variabile locale.\nDistruzione quando si ritorna dalla funzione\nMolto costoso per dati grossi perch√© devo fare la copia\nnon ho modo di comunicare usando quella variabile direttamente al parametro.\nSlide per passaggio valore\nla cosa carina √® che √® una copia, non ho trasmissione delle informazioni.\nPassaggio per riferimento üü© In questo caso passo il riferimento, o l-valore dell‚Äôoggetto, quindi la sua locazione o riferimento. (in java in pratica √® un riferimento perch√© si utilizza la reference model come descritto in Valutazione Espressioni.\nSlide passaggio per riferimento\nSlide riassunto valore e riferimento\nUn concetto qui importante √® la trasparenza referenziale, nel senso che non ci importa di come √® stato chiamato, tanto √® una copia (per il passaggio per vlaore) quindi riesco ad avere quanto mi interessa. (questo non vale per reference, perch√© dipende da con cosa lo ho chiamato!)\nCome fare un passaggio con semantica semplice come il passaggio di valore e senza problemi di aliasing come reference, e con anche comunicazione.\nEsempio di problema di aliasing\nPassaggio per costante üü© VALORE NON MODIFICABILE\nSolo in una direzione, solo che non si pu√≤ modificare. √à come un passaggio per valore, solo che si potrebbe implementare per riferimento per ragioni di efficienza. Ma comunque dipende dall‚Äôimplementazione della macchina astratta.\nPassaggio per risultato üü© Questo √® il duale del passaggio per valore, perch√© alla chiamata di funzione assegno la funzione a questa variabile (alla fine assegno il valore del formale al parametro attuale), quindi √® molto utile per trasmettere valore dalla procedura al main.\nOssia ho una copia del valore formale *(aka valore attuale) al parametro attuale, ma lo ho solo alla fine della funzione.\nSlide passaggio per risultato\nPassaggio per valore risultato üü© Questo permette il passaggio in entrambe le direzioni (si fa la copia e si assegna alla fine). Alcuni linguaggi implementano questa cosa attraverso la reference, sempre per il concetto che √® molto pi√π efficiente tenere le reference, solo che c\u0026rsquo;√® il problema di aliasing, quando mando la stessa reference.\nEsempio di valorerisultato differente da reference\nPassaggio per Nome (!) üü© In pratica sostituisco il nome del parametro attuale al posto del parametro formale, senza cattura.\nuna chiamata alla procedura P √® la stessa cosa che eseguire il corpo di P dopo aver sostituito i parametri attuali al posto dei parametri formali\nSi pu√≤ notare come se fosse la macro espansione in assembly (di cui credo le macro di C sono molto simili)\nEsempi di cose del passaggio per nome\nPROBLEMI DI SCOPING\nSlide scopes\nQuesto sar√† il problema che permetter√† il passaggio dell‚Äôambiente molto utilizzato per le variabili di ordine superiore come le funzioni.\nIIMPLEMENTAZIONE DEL PASSAGGIO PER NOME\nL‚Äôimplementazione di questo passaggio √® molto interessante, perch√© dovrei passare anche l‚Äôambiente iniziale affinche‚Äôtutta l‚Äôespressione abbia senso! l‚Äôoperazione fondamentale √® lo scoping.\nSlide implementazione per nome\nSolitamente √® molto costoso perch√© per valutare devo sempre andare in un ambiente diverso dall\u0026rsquo;attuale, poi anche dal fatto che il valore √® rivalutato ad ogni occorrenza!\n","permalink":"https://flecart.github.io/notes/astrazione-sul-controllo/","summary":"\u003ch2 id=\"significato-di-astrazione\"\u003eSignificato di astrazione\u003c/h2\u003e\n\u003cp\u003eL\u0026rsquo;astrazione √® una cosa fondamentale nell\u0026rsquo;informatica, l‚Äôabbiamo visto anche nella prima lezione in assoluto per architettura, il sistema a strati di \u003ca href=\"/notes/architettura-e-livelli-1-2/\"\u003eArchitettura e livelli 1, 2\u003c/a\u003e reti e simili.\u003c/p\u003e\n\u003cp\u003eIl principali metodi sono \u003cstrong\u003eastrazioni sul controllo e sui dati\u003c/strong\u003e sui dati stiamo cominciando a parlarne in \u003ca href=\"/notes/teoria-dei-tipi/\"\u003eTeoria dei Tipi\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eLe astrazioni sono utili a \u003cstrong\u003enascondere dettagli\u003c/strong\u003e per qualche fenomeno o simile (ricorda l\u0026rsquo;esempio della mappa, che non √® il territorio √® una astrazione su essa, che contiene ancora informazioni utili). Vogliamo quindi \u003cstrong\u003econcentrarci su quanto ci interessa\u003c/strong\u003e\u003c/p\u003e","title":"Astrazione sul controllo"},{"content":"Public Key Encryption We now define a formally what is a public key encryption\nFormal definition of Public Key Encryption We define a 3-tuple formed as follows: $(G, E, D)$ where\n$G$ is the generator for the private and public keys, from now on identified as $(pk, sk)$ (public key and secret key) $E(pk, m)$ the encryption algorithm, that takes the $pk$ and the message in input $D(sk, c)$ the decryption algorithm, that takes the $sk$ and the ciphertext in input. Now is this definition useful? i don\u0026rsquo;t think so! We can\u0026rsquo;t create theorems for it, too general I suppose. Is it clear? yes! I think this is the usefulness of maths in many occasions, it delivers some complex information in a concise and understandable manner.\nSome observations about Public Key Encryption Semantic security to Eavesdropping This is the same as explained in Advantage security explained in a previous section. We defined the advantage as the ability of the attacker to distinguish the original message. This is still exactly the same, see that section. (the only difference is that here we use public key encryption) Resistance against Many Time Pads We know that in the symmetric context in Block Ciphers and OTP and Stream Ciphers, it is often not secure to use the symmetric key to many times. (This is clearly true when we are talking about the OTP cipher).\nBut in the context of Asymmetric keys this notion is not true as the key is public, this key can be used as many times as the attacker wants. So he can reuse the key, while the cipher should still remain secure!\nSharing a key It\u0026rsquo;s easy to share a key using this encryption scheme. Just send the secret key with the public key of this cipher!\nTrapdoor functions Definition of Trapdoor functions Trapdoor is generic function from $X \\to Y$. This is a triple $G, F, F^{-1}$ very similar to the previous one (indeed it\u0026rsquo;s kinda the same definition) The only difference is that $F^{-1}$ is the inverse. This function is one-way, meaning it\u0026rsquo;s difficult to invert. And has a trapdoor meaning that by knowing the secret $sk$ it is easy to do so. $F(pk, \\cdot)$ defines public encryption function, the other equivalent is the decryption.\nSecure Trapdoor Functionsüü©\u0026ndash; NOTE: direct use of $F$ and $F^{-1}$ to encrypt and decrypt using the created keys is not semantically secure. But I don\u0026rsquo;t know why.\nA trapdoor is secure if it\u0026rsquo;s difficult to invert without the knowledge of $sk$. (It\u0026rsquo;s difficult to invert the $x$) See image Creating a PKE from Trapdoorsüü®+ One Way Hash Algorithms These are different from Hash tables which is a datastructure!\nWe can see that One-Way hashes are a trapdors with $pk = sk$. Usually it is a function that takes a input of arbitrary length and outputs a limited string with some important properties.\nProperties of One Way Hash Algorithmsüü©- Easy to Evaluate: The hashing algorithm should be fast Hard to Reverse: There is no feasible algorithm to \u0026ldquo;reverse\u0026rdquo; a hash value, That is, given any hash value $h$, it is computationally infeasible to find any document $m$ such that $H(m) = h$. Hard to find Collisions: There is no feasible algorithm to find two or more input documents which are hashed into the same condensed output, That is, it is computationally infeasible to find any two documents $m_{2}, m_{2}$ such that $H(m_{1})= H(m_{2})$. Although, theoretical requirements say there are many many collisions. But the difficult thing is tampering, that is add some strings, make some modifications of the original messages such that that hash matches with others. A small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value RSA Cryptosystem Definition of the trapdoor function We define $F: \\mathbb{Z}^{*}_{\\mathbb{N}} \\to \\mathbb{Z}^{*}_{\\mathbb{N}}$ as $RSA(x) = x^{e}$ where $e$ is the public key generated by the key generation function and $N = pq$ is the private key, where $p, q$ are big primes.\nThen using Euler\u0026rsquo;s theorem we know how to compute $d$ such that $x^{ed} =x \\mod N$ where $d$ is the inverse modulo that, this is how we decrypt. How do we compute $d$? We use euler\u0026rsquo;s theorem, and find this $e\\cdot d = 1 \\mod \\varphi(N)$. and $e$ should be invertible with it is coprime with $N$ (true by construction).\nRSA with trapdoors A secure implementation of RSA uses trapdoor functions like this: $x \\sim X$ this is the secret, we generate $y = RSA(x, e)$ with this, and encrypt the message with $k = H(x)$ and $c = H_{s}(k, m)$ and send $y$. The decryption step is similar to that presented to trapdoor functions.\nSecurity Analysis of RSA NOTE: normal RSA as defined above is not secure, the main reason is that it is deterministic, so we can have semantic security breaches.\nSimple semantic security attack on RSA I can get back to the original message with a small effort. The percentage of success is high enough not to be negligible. We have a $2^{40}$ attach on $2^{64}$ long messages.\n#### Advantage notation for RSA We want the possibility to compute the $e$ root modulo $N$ to be small, and using the notion of advantage developed in [OTP and Stream Ciphers#Security with advantage](/notes/otp-and-stream-ciphers#security-with-advantage) we write $$ Pr\\left[ A(N, e, y) = y ^{1/e} \\right] \u003c \\varepsilon $$ Where $\\varepsilon$ is very small, **negligible** so to say, and $A$ is the $F$ trapdoor function used for RSA. This is the problem of the discrete logarithm, usually true. Wiener\u0026rsquo;s attack (non fatto) This section is not useful for the exam, just for personal knowledge! If the private keys have certain properties, there exists some attacks, one example is the Wiener\u0026rsquo;s attack, for example if the private key is too small. The concept is that this makes the search space quite small.\nLow public exponent attack üü© Usually minimum that is used is 3. If 2 then the inverse is not guaranteed because $mcd(2, (p - 1) ( q - 1)) \\neq 1$ .\nThis is a stupid attack. Then the exponent is small enough, and it is not able to wrap the module, then the root is quite easy to achieve. This is why the recommended value is big, usually = $2^{16} + 1 = 65537$.\nUsually this is used to speed up encryption, it easier to compute. Other variants, like Elgamal have almost same time to encrypt and decrypt.\nThe reduction problem In order to prove that the best solution is to factor n we should prove that Efficient algorithm for e\u0026rsquo;th roots mod $N$ implies having efficient algorithm for factoring $N$. There is some evidence that says this reduction exists (BV'98) but it is still an open problem. But as far as we know this is actually a hard problem.\nComparison with symmetric keys AES key size RSA modulus size 80 bit 1024 bits 128 bits 3072 bits 256 bits 15360 bits We observe that RSA needs a lot more bits to ensure the same security! Side channel attacks these attacks do not directly attack the cipher, but the infrastructure or computing that it uses.\nTiming attack Can leak $d$ secret key by tracking the compute time. (Kocher 1997)\nPower attack Can leak $d$ by tracking power usage. (Kocher 1999) Needs access to physical data.\nFaults attack Errors can leak $d$ somehow (don\u0026rsquo;t know!) (BDL 1997). In questa fase viene leakato il valore di $p$ che permette di ricostruire la chiave privata.\nKey generation First when you startup the entropy of $p$ is not so much, so it happens if two different firewalls generate a key, they are probably the same. So if you take the GCD of these, it is probable that they are the same. They factored 0.4% of all public https keys in this way. Which is a good number. This says that it is **crucial to add randomness before generating keys**. Variations Elgamalüü®- Find $g$ and $p$ such that $g$ is primitive root modulo $p$. Some strange properties here. This means that $\\forall a, \\exists k : g^{k} = a \\mod p$. This is inspired from the Key Exchange protocols#Diffie-Hellman Protocol. Then the first person chooses $a \\in \\left[ 0, p - 2 \\right]$ randomly and calculates $A = g^{a} \\mod p$ and the tuple $(p , g, A)$ is then considered as the public key. The interesting thing is that this algo is randomized, if you want to communicate with someone, you choose a key randomly first.\n$B = g^{b} \\mod p$ $c = A^{b}m \\mod p$ Ciphertext is $(B, c)$ La decrittazione √® diversa. Calcolo $x = p - 1 - a$ e poi posso usare questo per decrittare, facendo $m = B^{x}c \\mod p$\nEsiste anche una versione per fare l\u0026rsquo;exchange, ma di questa non ne abbiamo parlato\nNotes on security -\u0026gt; Discrete log problem. Efficiency -\u0026gt; No, ciphertext needs that public key to be sent, which is usually long and expensive to calculate compared to AES.\nRabin cripto-systemüü® we create $p,q$ such that their modulus $4$ is 3, probably for some nice properties I don\u0026rsquo;t know of\u0026hellip; The advantage is that his security is proved. Calculate $n = pq$ and this is the public key. When somebody wants to communicate, he just calculates\n$$ c = m^{2} \\mod n $$ And sends this, probably with this setting the properties of $p, q$ make that invertible, but not sure why. If you are curious try to understand why is this valid. It has some nice theoretical properties. Its difficulty is proven to be the same as integer factorization, not known for RSA.\nDigital signatures The main idea is to cipher with the private key, so that it can be verifiable using the public. It was cited in Sicurezza delle reti times before. To overcome the burden to encrypt the whole text, usually only an hash is encrypted.\nAdvantages of Digital signatures Unforgeable Un-deniable by the signatory (if you have signed it, it was you!) Universally verifiable (everybody can verify it) Every doc\u0026rsquo;s signature is different, or very sensible to little changes. ","permalink":"https://flecart.github.io/notes/asymmetric-cryptography/","summary":"\u003ch2 id=\"public-key-encryption\"\u003ePublic Key Encryption\u003c/h2\u003e\n\u003cp\u003eWe now define a formally what is a  public key encryption\u003c/p\u003e\n\u003ch3 id=\"formal-definition-of-public-key-encryption\"\u003eFormal definition of Public Key Encryption\u003c/h3\u003e\n\u003cp\u003eWe define a 3-tuple formed as follows: $(G, E, D)$ where\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$G$ is the generator for the private and public keys, from now on identified as $(pk, sk)$ (public key and secret key)\u003c/li\u003e\n\u003cli\u003e$E(pk, m)$ the encryption algorithm, that takes the $pk$ and the message in input\u003c/li\u003e\n\u003cli\u003e$D(sk, c)$ the decryption algorithm, that takes the $sk$ and the ciphertext in input.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNow is this definition useful? i don\u0026rsquo;t think so! We can\u0026rsquo;t create theorems for it, too general I suppose. Is it clear? yes! I think this is the usefulness of maths in many occasions, it delivers some complex information in a concise and understandable manner.\u003c/p\u003e","title":"Asymmetric Cryptography"},{"content":"Sembra essere molto simile a Central Limit Theorem and Law of Large Numbers per√≤ per Entropy. This is also called Shannon\u0026rsquo;s source coding theorem see here\nEnunciato AEP $$ -\\frac{1}{n} \\log p(X_{1}, X_{2}, \\dots, X_{n}) \\to H(X) $$ in probability (la definizione data in Central Limit Theorem and Law of Large Numbers#Convergence in probability).\nUn modo alternativo per enunciarla √® cos√¨, segue il metodo in (MacKay 2003).\n$$ \\left\\lvert \\frac{1}{N} H_{\\delta}(X^{N}) - H(x) \\right\\rvert \\leq \\varepsilon $$Ossia a grandi linee: dato una variabile aleatoria $X$ e $N$ estrazioni della stessa, possiamo comprimere questa sequenza in $NH(X)$.\nDimostrazione Principalmente sorvolata, ma utilizza cose simili a Central Limit Theorem and Law of Large Numbers, e una idea simile a Monte Carlo Methods per le probabilit√†. In realt√† nella prima formulazione √® un concetto molto semplice il motivo per cui funziona.\n$$ -\\frac{1}{n} \\log p(X_{1}, \\dots, X_{n}) = -\\frac{1}{n} \\sum_{i=1}^{n}\\log p(X_{i}) \\to -\\mathbf{E}[\\log p(X)] = H(X) $$ La cosa principale da comprendere √® come ci pu√≤ essere questo fenomeno con convergenza in probabilit√†, che √® una nozione pi√π che altro tecnica per questo discorso.\nTypical sets Elements in the typical set have roughly the same probability.\n$$ 2^{-n(H(X) + \\varepsilon)} \\leq p(x_{1}, x_{2}, \\dots, x_{n}) \\leq 2^{-n(H(X) - \\varepsilon)} $$$$ P\\left( \\left\\lvert -\\frac{1}{n} \\log p(x_{1}, x_{2}, \\dots, x_{n}) - H(X) \\right\\rvert \u003e \\varepsilon \\right) = 0, n \\to +\\infty $$ Se si espande quanto √® presente dentro si ottiene quel bound di sopra.\nPropriet√† Vedi 3.1.2 di (Cover \u0026amp; Thomas 2012).\nIl risultato importante √® che possiamo rappresentare sequenze di $X^{n}$ in media usando $nH(X)$ bits, senza perdita di informazione.\nReferences [1] Cover \u0026amp; Thomas ‚ÄúElements of Information Theory‚Äù John Wiley \u0026amp; Sons 2012\n[2] MacKay ‚ÄúInformation Theory, Inference and Learning Algorithms‚Äù Cambridge University Press 2003\n","permalink":"https://flecart.github.io/notes/asymptotic-equipartition-property/","summary":"\u003cp\u003eSembra essere molto simile a \u003ca href=\"/notes/central-limit-theorem-and-law-of-large-numbers/\"\u003eCentral Limit Theorem and Law of Large Numbers\u003c/a\u003e per√≤ per \u003ca href=\"/notes/entropy/\"\u003eEntropy\u003c/a\u003e.\nThis is also called \u003cstrong\u003eShannon\u0026rsquo;s source coding theorem\u003c/strong\u003e see \u003ca href=\"https://www.youtube.com/watch?v=0SxJl5G2bp0\u0026amp;list=PLruBu5BI5n4aFpG32iMbdWoRVAA-Vcso6\u0026amp;index=3\u0026amp;ab_channel=JakobFoerster\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"enunciato-aep\"\u003eEnunciato AEP\u003c/h3\u003e\n$$\n-\\frac{1}{n} \\log p(X_{1}, X_{2}, \\dots, X_{n}) \\to H(X)\n$$\u003cp\u003e\nin probability (la definizione data in \u003ca href=\"/notes/central-limit-theorem-and-law-of-large-numbers/#convergence-in-probability\"\u003eCentral Limit Theorem and Law of Large Numbers#Convergence in probability\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003eUn modo alternativo per enunciarla √® cos√¨, segue il metodo in (MacKay 2003).\u003c/p\u003e\n$$\n\\left\\lvert  \\frac{1}{N} H_{\\delta}(X^{N}) - H(x)  \\right\\rvert \\leq \\varepsilon\n$$\u003cp\u003eOssia a grandi linee: dato una variabile aleatoria $X$ e $N$ estrazioni della stessa, possiamo comprimere questa sequenza in $NH(X)$.\u003c/p\u003e","title":"Asymptotic Equipartition Property"},{"content":"In questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders Blog di riferimento Blog secondario che sembra buono\nIntroduzione agli autoencoders L\u0026rsquo;idea degli autoencoders √® rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso √® la compressione con loss. Per cosa intendiamo qualunque tipologia di dato, che pu√≤ spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder. Una volta scelta una tipologia di dato, come per gli algoritmi di compressione, valutiamo come buono il modello che riesce a comprimere in modo efficiente e decomprimere in modo fedele rispetto all\u0026rsquo;originale. Abbiamo quindi un trade-off fra spazio latente, che √® lo spazio in cui sono presenti gli elementi compressi, e la qualit√† della ricostruzione. Possiamo infatti osservare che se spazio latente = spazio originale, loss di ricostruzione = 0 perch√© basta imparare l\u0026rsquo;identit√†. In questo senso si pu√≤ dire che diventa sensato solo quando lo spazio originale sia minore di qualche fattore rispetto all\u0026rsquo;originale. Quando si ha questo, abbiamo pi√π difficolt√† di ricostruzione, e c\u0026rsquo;√® una leggera perdita in questo senso.\nThree desiderata üü®\u0026ndash; Informative: it should be possible to reconstruct the original image. Disentangle: features inside the representation space should be cleanly separated. Robust: if the input is similar, then we would like the representation to be close (somewhat similar to the notion of continuity. Representativeness: if we take some points in the encoding, we would like this to have some corresponding value in the original space. (Somewhat similar to completeness) First Ideas This idea was from Lisker 1988. We would like the encoding and the original input space to share more information as possible: if $Z = \\text{enc}(X)$ then we would like to maximize the mutual information between $Z$ and $X$, $\\arg\\max_{\\theta} I(X ; enc_{\\theta}(X))$. This is also called the Infomax principle.\nThe drawback is that this method does not produce disentangled neither robust representations.\n$$ \\frac{1}{n} \\sum_{i \\leq n} \\mathop{\\mathbb{E}}_{Z \\mid x_{i}} \\left[ \\log p(x_{i} \\mid Z) \\right] $$Autoencoders Simple Linear Encoders The simplest form of an autoencoder is a linear encoder, where the encoding function is a linear transformation and the decoding function is the transpose of the encoding function. In this simple linear case, one can prove that the optimal encoding function is the principal component analysis (PCA) of the data. See Principal Component Analysis. So if we have a simple three layer autoencoder deep neural networks, one can say it computes the PCA of the original data. The same cannot be said for multi-linear neural networks.\nVariational Autoencoders Intuizione L\u0026rsquo;idea sembra avere uno spazio regolarizzato, ossia un $z \\sim \\mathcal{N}(\\mu, \\sigma^{2}I)$ con $\\sigma$ vettore di dimensione spazio latente e $\\mu$ degli offset che rappresentano media. Quindi il decoder parametrizzato secondo $\\theta$ dovr√† essere in una forma dipendente da questa. Questo √® un prior che segue un approccio di genere generativo.\nInsieme a questo utilizziamo anche un encoder parametrizzato con $\\phi$ che dovr√† darci indicazioni su $z$, per esempio media e varianza.\nSecondo Murphy-1, Questo dovrebbe essere molto simile a un lavoro di uno 95, vedi capitolo su VAE in que libro. La formulazione dei VAE sembra molto simile ai Factor Analysis. Che √® una caratterizzazione di un certo tipo sia spazio latente che quello normale.\nGeneral framework Quello che andiamo a fare √® computare una rappresentazione $p_{\\theta}(z \\mid x)$ dove $z$ √® il nostro spazio latente con un certo prior (questo √® un posterior), e poi rigenerare con un $p_{\\theta'}(x \\mid z)$ che √® la nostra likelihood.\nSetting del problema $$ p(x | z) \\sim \\mathrm{N}(media, varianza) $$ Ossia i samples della parte condizionata nello spazio latente non sono altro che una media e varianza dipendenti solo dalla parte condizionale, mentre $p(z) = N(0, 1)$ multidimensionale (quindi varianza $I$)\nELBO e derivazione Per trattare ELBO, andare a rivedersi le note inVariational Inference. Se assumiamo questo, allora la loss di Kullback-Leibler diventa abbastanza carina, perch√© infatti abbiamo che\n$$ KL(q_{x}(z), p(z|x)) = E_{x \\sim q_{x} }(\\log(q_{x}(z))) - E_{x \\sim q_{x}}\\left(\\log( \\frac{p(x, z)}{p(x)}) \\right) $$ $$$$ Ora le ultime due si chiamano rispettivamente **evidence** e **ELBO** che sta per Evidence Lower Bound Notiamo che la evidence non dipende da $z$, infatti avremmo che $$ E_{z \\sim q_{x}}(p(x)) = \\int {-\\infty}^{+\\infty} q{x}(z) p(x) , dz = p(x) \\int {-\\infty}^{+\\infty} q{x}(z) dz = p(x) $$ Quindi se vogliamo minimizzare la divergenza, ci basta Massimizzare ELBO nel nostro caso.\nEsplicitazione di ELBO Possiamo lavorare ancora di pi√π su ELBO, provando ad esplicitarne alcuni valori, infatti possiamo considerare\n$$ ELBO = E_{z \\sim q_{x}}\\left( \\log\\left( \\frac{p(x, z)}{q_{x}(z)} \\right) \\right) =E_{z \\sim q_{x}}\\left( \\log\\left( p(x|z) \\right) \\right) + E_{z \\sim q_{x}}\\left( \\log\\left( \\frac{p(z)}{q_{x}(z)} \\right) \\right) $$$$ = E_{z \\sim q_{x}}\\left( \\log\\left( p(x|z) \\right) \\right) - KL(q_{x}(z), p(z)) $$Ossia abbiamo il secondo termine che prova a regolarizzare la distribuzione $q$ trovata, e il primo termine che √® un maximum likelihood, simile a quanto trovato per Na√Øve Bayes nel corso di Asperti. Questo √® la nostra loss per il VAE.\nOra l\u0026rsquo;ultimo passo sarebbe come esplicitare ELBO in modo che possa essere implementato come loss di una net?\nDerivazione della loss per VAE Vedere qui, √® calcolosa, ma molto carina, e ti permette di impratichirti con gaussiane multi-variabili.\nAlla fine si avr√† come risultato:\n$$ KL(q_{x}(z), p(z)) = -\\frac{1}{2} \\sum_{j=1}^{J}(1 + \\log \\sigma^{2}_{j} - \\mu^{2}_{j} - \\sigma^{2}_{j}) $$ Derivazione di KL per la loss vedere Gaussians\nPer l\u0026rsquo;expectation della forma quadratica vedere qui https://statproofbook.github.io/P/mean-qf.html.\nAllora, sappiamo che $p(z) = \\mathcal{N}(0, \\mathcal{I})$ quindi ha una forma ben nota, dovremo cercare di fare questa piccolissima derivazione.\nTraining di VAE Una volta ben definito la loss di ricostruzione e la loss di regolarizzazione, possiamo procedere con l\u0026rsquo;addestramento del modello allenando sia l\u0026rsquo;encoder che il decoder assieme.\n","permalink":"https://flecart.github.io/notes/autoencoders/","summary":"\u003cp\u003eIn questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders\n\u003ca href=\"https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73\"\u003eBlog di riferimento\u003c/a\u003e\n\u003ca href=\"https://mbernste.github.io/posts/vae/\"\u003eBlog secondario che sembra buono\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"introduzione-agli-autoencoders\"\u003eIntroduzione agli autoencoders\u003c/h3\u003e\n\u003cp\u003eL\u0026rsquo;idea degli autoencoders √® rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso √® la compressione con loss. Per cosa intendiamo qualunque tipologia di dato, che pu√≤ spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder.\nUna volta scelta una tipologia di dato, come per gli algoritmi di compressione, valutiamo come buono il modello che riesce a comprimere in modo efficiente e decomprimere in modo fedele rispetto all\u0026rsquo;originale.\nAbbiamo quindi un trade-off fra spazio latente, che √® lo spazio in cui sono presenti gli elementi compressi, e la qualit√† della ricostruzione.\nPossiamo infatti osservare che se \u003cstrong\u003espazio latente = spazio originale, loss di ricostruzione = 0\u003c/strong\u003e perch√© basta imparare l\u0026rsquo;identit√†. In questo senso si pu√≤ dire che diventa sensato solo quando lo spazio originale sia minore di qualche fattore rispetto all\u0026rsquo;originale. Quando si ha questo, abbiamo pi√π difficolt√† di ricostruzione, e c\u0026rsquo;√® una leggera perdita in questo senso.\u003c/p\u003e","title":"Autoencoders"},{"content":"Per l‚Äôanalisi lessicale vogliamo cercare di ricordare le parole legali all\u0026rsquo;interno di questo linguaggio e questo √® fatto con i linguaggi regolari.\nIntroduzione a analizzatori lessicali Token üü© Struttura del token √® fatto da due parti\nIdentificatore della classe del token Identificatore del valore del token Pattern e lessema ci sono direi boh Pattern e Lessema üü© I pattern sono una descrizione generale della forma dei valori di una classe di token.\nLessema √® una istanza di un particolare pattern\nEsempio di scan\nDi solito viene storato come puntatore alla tabella dei simboli\nEspressioni regolari Definizione üü© Slide definizione espressioni regolari\nDisambiguazione della grammatica\nEsempio espressione regolare\nLinguaggio generato da regexp üü© Per capire questa parte √® importante avere in mente le operazioni sui linguaggio definiti in Descrizione linguaggio\nSlide\nLinguaggio regolare üü© Definizione linguaggio regolare\nOgni linguaggio finito √® un linguaggio regolare questo √® una proposizione che lega fortemente i linguaggi (utilizzati poi veramente per l\u0026rsquo;implementazione) (basta fare l‚Äôunione!)\nEsempio linguaggio finito generato da linguaggio regolare\nEsempi di espressioni regolari infiniti\nOltre ai classici operatori definiti in precedena per questa sezione aggiungiamo\nRipetizione-positiva, Possibilit√†, Elenco\nDefinizioni regolari üü©- Le definizioni regolari ci aiutano a creare una struttura del token di cui dobbiamo fare lo scanning.\nIn pratica andiamo a creare delle definizioni che rendono pi√π facile la descrizione di un pattern con regexp.\nSlide\nEsempi\nEquivalenza regexp üü© Esempi di equivalenze\nQueste equivalenze non sono sempre facili da dimostrare\nAutomi In questa parte si fa una descrizione molto generale di cosa siano gli automi.\nCaratteristiche (3) üü© Slide\nMemoria finita (dato da un numero di stati) Input una stringa da riconoscere Output √® solamente un singolo bit (si oppure no) Descrizione e funzionamento üü© Slide\nDescrizione\nTestina sul primo carattere in input. Su stato q0 Funzionamento\nIl funzionamento dell\u0026rsquo;automa √® molto semplice, esegue un semplice algoritmo:\nLeggi il carattere attuale, se esiste una transizione etichettata con quanto letto spostati secondo la regola di quel carattere. Dopo aver finito di leggere la stringa, se √® in uno stato buono restituisci 1, altrimenti 0 Se √® bloccato in uno stato ritorna 0 Diagrammi di transizione üü© I diagrammi di transizione sono utili per definire in modo grafico cosa fa l\u0026rsquo;espressione regolare\nSlide\nAutomi finiti non deterministici (NFA) Definizione (5) üü© Slide\nPossiamo definire gli automi non deterministici come una quintupla di\n$$ (\\Sigma, Q, q_0 \\in Q, F \\subseteq Q, \\delta) \\\\ \\delta : Q \\times (\\Sigma \\cup \\varepsilon) \\to P(Q) $$ Albeto dei simboli di input Stati possibili Stato iniziale Stati finali (accettati) Funzioni di transizione, che ha come codominio l\u0026rsquo;insieme delle parti di Q Alla fine, per scopi didattici si utilizza sempre il diagramma di transizione. La differenza principale con gli automi a stati finiti √® che posso avere lo stesso label di transizione per singolo stato\nCaratteristiche (2) üü© Facili da realizzare (esiste quasi una bigezione credo fra NDA ed espressione regolare) Inefficienti (backtracking, e fallibile), principalmente causato dal suo non determinismo Stato finale accettato üü© ‚Äî Slide\nQuesto √® una slide molto importante per definire il concetto di stringa accettata/riconosciuta. Praticamente posso affermare che una stringa √® riconosciuto da questo automa finito non-deterinistico se anche un solo cammino da q0 a un qualunque stato accettato.\nOltre questo voglio andare a definire in modo formale il concetto di mossa, o cammino in un diagramma di rappresentazione per un automa finito.\nDescrizione istantanea, mossa, cammino, stringa accettata\nIndico che uno stato $q$ √® raggiungibile da uno stato $s$, con il simbolo $\\vdash$, ossia $s \\vdash v$, questo √® possibile solo se sto leggendo una stringa che ha come relazione una stringa buona, ma questo pezzo √® pi√π chiaro negli appunti quindi ti invito di leggere dal√¨ con la rappresentazione logica classica.\nLa chiusura riflessiva e transitiva di questo concetto di mossa √® indicata con $\\vdash ^*_N$, N √® il nome di questo automa, dovrebbe essere ancora sopra.\nTODO: da definire bene cosa sia la mossa e il cammino!\nLinguaggio riconosciuto da NDA e equivalenza üü© Slide\n$$ L[N] = \\{ w \\in \\Sigma^* | \\exists q \\in F, (q_0, w) \\vdash ^*_N (q , \\varepsilon)\\} $$La parte di sopra √® la definizione di un linguaggio riconosciuto da un automa, √® un modo molto compatto per esprire l\u0026rsquo;esistenza di un cammino come sopra.\nInoltre possiamo definire il concetto di equivalenza fra NDA che √® quando il linguaggio riconosciuto √® esattamente lo stesso.\nDefinizione di linguaggio riconosciuto con e-closure üü®+ Linguaggio riconosciuto, scritto in modo pi√π elegante, con epsilon closure\nCon la definizione di delta cappuccio possiamo definire che un linguaggio in questo modo:\n$$ w \\in L[N] \\iff \\exists p \\in F : p \\in \\hat{\\delta}(q_0, w) $$NFA da espressioni regolari (!!!) (duplicato) üü© Questo √® un teorema molto importante per rappresentare una sorta di equivalenza fra linguaggi regolari e NFA.\nEnunciato\nHint dimostrazione\nInduzione strutturale sulla sintassi BNF delle espressioni regolari, andremo a dimostrare che posso comporre NFA che alla fine riescono a riconoscere il linguaggio regolare\nConsigli di studio\nImpararsi i metodi di conversione di ogni parte della sintassi in NFA, poi li componi come dei lego e sei apposto\nDimostrazione\nAutomi finiti deterministici (DFA) Definizione üü© Slide\nDifferenze rispetto NDA\nPrincipalmente la definizione √® uguale agli automi non deterministici l‚Äôunica cosa che cambia √® il delta che ora √® definito come\n$$ \\delta: Q \\times \\Sigma \\to Q $$Non c‚Äô√® pi√π l‚Äôinsieme delle parti, magari dopo vediamo come questi automi sono equivalenti, ma c‚Äô√® una esplosione esponenziale al momento di conversione da deterministico a non deterministico.\nAlgoritmo creazione DFA da NFA üü© L‚Äôalgoritmo di creazione\nEsempio di utilizzo dell\u0026rsquo;algoritmo (lezione 6)\ncon $F$ l‚Äôinsieme degli stati finali della NFA.\nDFA equivalente a NFA (non chiede) üü® Dimostrazione both, e osservazioni in modo informale\nSlide ‚Üí\nQuesta proposizione si pu√≤ vedere dalla definizione\nSlide ‚Üê\nC\u0026rsquo;√® veramente in questo passo una esplosione esponenziale perch√© il numero degli stati diventa esponenzialmente tanto.\nDimostrazione, induzione, molto formale.\nEsempio di conversione\nepsilon-closure üü© Slide\nAlgoritmo per epsilon-closure\nQuesto concetto di chiusura Epsilon ci racchiude il concetto degli stati raggiungibili in un NFA senza leggere nessun input.\n","permalink":"https://flecart.github.io/notes/automi-e-regexp/","summary":"\u003cp\u003ePer l‚Äôanalisi lessicale vogliamo cercare di ricordare le \u003cstrong\u003eparole legali\u003c/strong\u003e all\u0026rsquo;interno di questo linguaggio e questo √® fatto con i linguaggi regolari.\u003c/p\u003e\n\u003ch2 id=\"introduzione-a-analizzatori-lessicali\"\u003eIntroduzione a analizzatori lessicali\u003c/h2\u003e\n\u003ch3 id=\"token-\"\u003eToken üü©\u003c/h3\u003e\n\u003cp\u003eStruttura del token √® fatto da due parti\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIdentificatore della classe del token\u003c/li\u003e\n\u003cli\u003eIdentificatore del valore del token\u003c/li\u003e\n\u003cli\u003ePattern e lessema ci sono direi boh\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"pattern-e-lessema-\"\u003ePattern e Lessema üü©\u003c/h3\u003e\n\u003cp\u003eI pattern sono una descrizione generale della forma dei valori di una classe di token.\u003c/p\u003e","title":"Automi e Regexp"},{"content":"Ha senso solamente parlare di autovettori quando si ha una applicazione lineare con stesso dominio e stesso codominio.\nVorremmo trovare una buona matrice che sia diagonale.\n6.1 Diagonalizzabilit√† 6.1.1 Definizione per funzione e matrice Questo perch√© vorrei una base in cui si abbia un matrice diagonale. (quindi probabilmente P √® una matrice identit√†).\nPerch√© ci piacciono le matrici diagonali\nSe ho una matrice diagonale, si ha che l\u0026rsquo;applicazione lineare √® un semplice scaling dei vettori della base.\n6.1.2 Matrici simili Date due matrici in uno spazio vetoriale con le matrici, allora se esiste un P nello stesso spazio tale che $B = P^{-1}AP$ si dicono simili (in pratica fare uno scambio di base).\nOsservazione 1\nPosso dimostrare che la matrice $A_{ee'} \\sim A_{bb'}$ associata a una funzione, sono simili per il teorema del cambio di base di sopra\nOsservazione 2\nLa simile, √® una relazione di equivalenza (riflessivit√†, simmetria e transitivit√†)\n6.1.3 Diagonalizabilit√† di una matrice quadrata Si pu√≤ dire che una matrice quadrata A √® diagonalizzabile se √® simile a una matrice diagonale\n(Anche la definizione di sopra √® uguale (equivalente).\n6.1.4 Equivalenza della diagonalizzabilit√† funzionale e matriciale (9.1.4)(!!!) Si ha che una funzione F e la sua matrice associata.\nAllora F diagonalizzabile SSE la sua matrice associata √® diagonalizzabile.\nDimostrazione\n$\\implies$Supponiamo che la funzione sia diagonalizzabile, allora ho una base per cui si ha una matrice diagonale.\nA questo punto utilizzo il teorema del cambio di base per costruirmi la P voluta per la diagonalizzabilit√† (o avere una matrice simile) e ci√≤ finisce.\n$\\impliedby$ Supponiamo che si abbia una matrice diagonalizzabile, allora abbiamo una matrice P che mi dia una matrice diagonale.\nLemma: le righe di P sono linearmente indipendenti. Si dimostra per il teoremone (l‚Äôesistenza dell‚Äôinversa, implica che √® associata a una funzione bigettiva, che implica che le colonne sono indipendenti).\nConsidero le colonne di P, queste sono N vettori indipendenti che fanno quindi span sullo spazio vettoriale Rn. Ma allora P √® proprio $I_{be}$ con b la base definita dalle colonne!\nE quindi ho trovato la base per la funzione tale che sia diagonale, quindi la funzione √® diagonalizzabile.\n6.1.5 Condizione di diagonalizzabilit√† (!!!!) ‚≠ê Si pu√≤ dire che una funzione F sia diagonalizzabile sse esiste una base di Rn costituita da autovettori di F\nLa dimensione delle due frecce √® identica (almeno le tecniche lo sono)\nDimostrazione\n$\\impliedby$Sia una base di Rn costituita da autovettori della F. Allora la matrice associata a questa funzione √® una matrice diagonale per questa base (bisogna fare un p√≤ di conti).\n$\\implies$Sia b una base tale che la matrice associata alla funzione sia diagonalizzabile, allora ho una base per cui la funzione √® diagonale. Elimino questo esiste con la base beta, voglio dimostrare che siano autovettori.\n6.2 Calcolo degli autovettori e autovalori 6.2.1 Autovalore 0 e kernel (!) $Ker F \\neq 0_v \\iff F$ ha autovalore $0$\nDimostrazione\n$\\implies$ supponiamo che $v \\neq 0_v, v \\in Ker F$ allora $F(v) = 0\\cdot v = 0$, ossia 0 √® un autovalore.\n$\\impliedby$Supponiamo che 0 sia un autovalore, allora esiste un autovettore (per definizione diverso da 0) allora esiste un elemento diverso da 0 nel kernel, e quindi non √® iniettiva per una proposizione precedente\n6.2.2 Polinomio caratteristico Nota: si ha che se ho una matrice n x n il polinomio caratteristico ha grado n.\n6.2.3 Autospazio e Polinomio caratteristico (!!!) L\u0026rsquo;autospazio per un certo autovalore √® questo insieme\n$V_\\lambda = \\{v \\in \\R^n | F(v) = \\lambda v\\}$, ossia √® l\u0026rsquo;unione dei autovettori con lo zero.\nProposizione:\n$V_\\lambda = Ker(A - \\lambda I)$, con il kernel della matrice definita come le soluzioni del sistema lineare omogoneo associato ala matrice (che poi √® uguale al concetto della funzione).\nDimostrazione\n$\\implies$Sappiamo che $V_y$ √® l\u0026rsquo;insieme degli $x \\in R^n| Ax = \\lambda x$ con A la matrice associata la nostra funzione. Vogliamo dimostrare che se $x \\in V_\\lambda$ allora appartiene al kernel, il che √® abbastanza ovvio per la propriet√† distributiva della moltiplicazione matriciale.\n$\\impliedby$Se si ha un v appartenente al kernel, allora poi si ricava (aggiungendo e sottraendo una parte) che $Ax = \\lambda x$ che √® proprio la condizione sufficiente per appartenere all\u0026rsquo;autospazio\n6.2.4 Polinomio car per Matrici simili (no chiede) Matrici simili hanno lo stesso polinomio caratteristico, questo si dimostra con distributivit√† e associativit√† della moltiplicazione matriciale.\nDimo\n$A - \\lambda I = P^{-1}BP - \\lambda I = P^{-1}BP - P^{-1}P\\lambda I = P^{-1}(B - \\lambda I) P$\n6.2.5 Condizione dell‚Äôautovalore (!!!) Dimostrazione\n$\\iff$Se $\\lambda$ √® un autovalore, allora ho un autovettore che appartiene all\u0026rsquo;autospazio relativo.\nVogliamo che l\u0026rsquo;autospazio √® diverso da 0, questo √® vero sse il sistema lineare (A - lambdaI)x = 0 ha una soluzione non nulla, allora per il teoremone, questo √® vero sse il determinante della matrice √® uguale a 0. quindi sse lambda √® uno zero della nostra matrice.\n6.3 Molteplicit√† e autov{ettori, alori} 6.3.1 Autovalori diverse fanno autovettori indipendenti (no chiede) Si dimostra in modo induttivo, partendo da un unico vettore che √® necessariamente indipendente, saltando per il passo induttivo e finire.\n6.3.2 Molteplicit√† geometrica ed algebrica DOmanda da fare alla marta\nIl fatto che la moltiplicit√† geometrica √® minore o uguale alla molteplicit√† geometrica potrebbe essere insito nel polinomio caratteristico.\nPerch√© al massimo (√® da dimostrare) che il grado del polinomio caratteristico √® N, che √® anche la dimensione della molteplicit√† geometrica???\n6.3.3 Moltiplicit√† geometrica ‚â§ Molteplicit√† algebrica (no chiede) 6.3.4 Diagonalizzabilit√† per somma di M-algebrica (no chiede) Si pu√≤ dimostrare che √® un sse. e deve essere che le molteplicit√† algebriche e geometriche siano entrambi uguali.\nDim-libro\n!\nAutovettori gli autovettori sono i vettori di Ax che sono nella stessa direzione di x.\nPossiamo scriverlo come $Ax = \\lambda x$ e ho che lambda √® un autovalore\nSembra che\nLa somma degli autovalori √® uguale alla somma delle diagonali Una matrice di dimensioni n n ha n autovettori Autovettori e autovalori di proiezione Nell\u0026rsquo;esempio di una proiezione, un autovettore sarebbe stato $x_{a}$ in quanto sarebbe gi√† nello spazio colonna in arrivo, quindi non viene proprio modificato.\nMa non solo questi sono degli autovettori, ma anche i vettori che sono perpendicolari (hanno autovalore 0, perch√© vengono totalmente distrutti).\nCos√¨ abbiamo trovato gli autovalori per una matrice di proiezione che sono 0 e 1\nLa ricerca di autovettori: equazione dell‚Äôautovalore Possiamo riscrivere l‚Äôequazione in questo modo:\n$$ (A - I\\lambda)x = 0 $$Quindi stiamo cercando soluzioni nello spazio nullo di una nuova matrice, che √® interessante solamente se questa matrice √® singolare, ossia che abbia una determinante uguale a 0\nCerchiamo le soluzioni di $\\det (A - I\\lambda) = 0$ per lambda i una nuova matrice, che √® interessante solamente se questa matrice √® singolare, ossia che abbia una determinante uguale a 0\nCerchiamo le soluzioni di $\\det (A - I\\lambda) = 0$ per lambda\nThis theorem is also sometimes called the Caley-Hamilton Theorem. See this chatgpt response.\nGershgorin Circle Theorem $$ D_{i} = \\left\\{ z \\in \\mathbb{C} : \\lvert z - a_{ii} \\rvert \\leq \\sum_{j \\neq i} \\lvert a_{ij} \\rvert \\right\\} $$ The eigenvalues then lie within the union of these discs.\nProof of the Theorem $$ \\begin{align} \\lambda x_{i} = \\sum_{j = 1}^{n}A_{ij}x_{j} \u0026\\implies (\\lambda - A_{ii})x_{i} = \\sum_{j \\neq i}A_{ij}x_{j} \\\\ \u0026\\implies \\lvert \\lambda - A_{ii} \\rvert \\lvert x_{i} \\rvert \\leq \\sum_{j \\neq i} \\lvert A_{ij} \\rvert \\lvert x_{j} \\rvert \\\\ \\text{Pick } i = \\arg \\max_{i} \\lvert x_{i} \\rvert \u0026\\implies \\lvert \\lambda - A_{ii} \\rvert \\leq \\sum_{j \\neq i} \\lvert A_{ij} \\rvert \\end{align} $$ We have exactly the Gershgorin disc, which finishes the proof $\\square$.\nSome trivia on the theorem The theorem becomes useful if the circles have some nice bounds:\nIf every circle does not touch the zero, then we know that the matrix is invertible, because there is no zero eigenvalue. If every circle has positive points, and the matrix is symmetric, then it is easy to see that the matrix is positive definite. Bounds on the maximum eigenvalue can be found by looking at the maximum distance from the diagonal. Same thing with the minimum eigenvalue. ","permalink":"https://flecart.github.io/notes/autovalori-e-autovettori/","summary":"\u003cp\u003eHa senso solamente parlare di autovettori quando si ha una \u003cstrong\u003eapplicazione lineare con stesso dominio e stesso codominio.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eVorremmo trovare una buona matrice che sia diagonale.\u003c/p\u003e\n\u003ch2 id=\"61-diagonalizzabilit√†\"\u003e6.1 Diagonalizzabilit√†\u003c/h2\u003e\n\u003ch3 id=\"611-definizione-per-funzione-e-matrice\"\u003e6.1.1 Definizione per funzione e matrice\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Cambio di Base e Autovalori/Untitled 3.png\" alt=\"image/universita/ex-notion/Cambio di Base e Autovalori/Untitled 3\"\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Cambio di Base e Autovalori/Untitled 4.png\" alt=\"image/universita/ex-notion/Cambio di Base e Autovalori/Untitled 4\"\u003e\n\u003cp\u003eQuesto perch√© vorrei una base in cui si abbia un matrice diagonale. (quindi probabilmente P √® una matrice identit√†).\u003c/p\u003e","title":"Autovalori e Autovettori"},{"content":"Backpropagation is perhaps the most important algorithm of the 21st century. It is used everywhere in machine learning and is also connected to computing marginal distributions. This is why all machine learning scientists and data scientists should understand this algorithm very well. An important observation is that this algorithm is linear: the time complexity is the same as the forward pass. Derivatives are unexpectedly cheap to calculate. This took a lot of time to discover. See colah\u0026rsquo;s blog. Karpathy has a nice resource for this topic too!\nA Brief History of Backpropagation Backpropagation builds on some backbone ideas in mathematics and computer science.\nBuilding blocks of backpropagation go back a long time\nThe chain rule (Leibniz, 1676; L\u0026rsquo;H√¥pital, 1696) Dynamic Programming (DP, Bellman, 1957) Minimisation of errors through gradient descent (Cauchy 1847, Hadamard, 1908) in the parameter space of complex, nonlinear, differentiable, multi-stage, NN-related systems (Kelley 1960; Bryson, 1961; Bryson and Denham, 1961; Pontryagin et al., 1961, \u0026hellip;)\nExplicit, efficient error backpropagation (BP) in arbitrary, discrete, possibly sparsely connected, NN-like networks apparently was first described in 1970 by Finnish master student Seppo Linnainmaa\nOne of the first NN-specific applications of efficient BP was described by Werbos (1982)\nRumelhart, Hinton and William, 1986 significantly contributed to the popularization of BP for NNs as computers became faster. We also list this resource, it is a quite nice view on backpropagation as an optimization problem. But if you just study for the exams, probably this is not necessary.\nThe problem setting $$ \\min_{\\theta} \\sum_{(x, y) \\in \\mathcal{D}} \\mathcal{L}(f(x ; \\theta), y) $$ A common tool is gradient descent but we need to compute the gradients for this algorithm. The astounding fact is that the speed of computing the gradients is same as a forward pass. In optimization classes computing the gradients is given for granted, while the algorithm itself is not trivial.\nIn the old times people would calculate the gradients by hand for every parameter. We need automatic differentiation and we will explain here how does it work.\nAutomatic Differentiation We will use a specific type of automatic differentiation, called reverse-mode. This is not all automatic because we need to know\nHow to decompose the whole function in easy parts Need to know the differential of the simple primitive functions that we use compute the forward pass. We can summarize the whole thing with this theorem: Reverse-mode automatic differentiation can compute the gradient of $f$ in the same time complexity as computing $f$\nThis will be a constructive theorem. First refresh some basis of analysis, see for example Limiti, Derivate, Hopital, Taylor, Peano, Calcolo differenziale, e Jacobians, and some notes about Computer Science i.e. Notazione Asintotica.\nHypergraph TODO: see (Huang 2008) for discussion on hypergraphs in NLP.\nComputational graphs üü® A composite function is a function composed by a series of (nonlinear) functions. Hypergraph is a graph that allows hyperedges, which is a edge that branches into more than one node, or two edges that merge into one, so it allows to have more than one source or more than one target, in normal graphs we only have single source and single targets for an edge. In the graph, the squares are hyperedges, the order of the input nodes usually matters (for example for the division operator).\nFor example the $+$ is a hyper-edge with two parents. We need hyper edges because we need a kind of ordering.\n$$ \\frac{ \\partial y }{ \\partial x } = \\sum_{p \\in \\mathcal{P(i, j)}} \\prod_{(k, l) \\in p} \\frac{ \\partial z_{l} }{ \\partial z_{k} } $$ Meaning we need to find all paths from $i$ to $j$ and then use the chain rule to compute the gradient contribution for this path. And this algorithm is exponential in time complexity.\nThe forward pass üü© We can write the forward pass of this algorithm in the following way: The backward pass üü©\u0026ndash; The optimal accumulation problem is NP-hard. This problem has some similarities with the backward pass.\nWe just to the backward pass, this example is explanatory: You can see that the derivative of $g$ to intermediate point is stored when doing the backpropagation part, and this makes it easy to propagate back step by step.\nWe can write the algorithm mathematically Bauer Paths üü®\u0026ndash; Bauer\u0026rsquo;s formula is a chain rule but for a graph! Given a function $f: \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$ for input $x_{j}$ and output $y_{j}$ we have that\n$$ \\frac{ \\partial y_{i} }{ \\partial x_{j} } = \\sum_{p \\in \\mathcal{P}(j, i)} \\prod_{(k, l) \\in p} \\frac{ \\partial z_{l} }{ \\partial z_{k} } $$Where $\\mathcal{P(j, i)}$ is the set of all paths from $j \\to i$ and $(k, l)$ are the individual edges. Every path in this formula is called Bauer Path.\nThe following is an example: .\nWe have many of the paths are re-used! This is also why dynamic programming is important at this stage. Weird but interesting thing is that there is a link between factoring polynomials and dynamic programming, but I did not understand why.\nTypes of Differentiation There are other types of automatic differentiation. In this section we will briefly present two of the most known aside auto-grad.\nNumerical differentiation üü© $$ \\frac{ \\partial f(x, y, z) }{ \\partial z } \\approx \\frac{f(x, y, z + h) - f(x, y, z)}{h} $$Symbolic differentiation üü©- This is what is done by engines like wolphram alpha, it computes the real derivative of the expression, but this is inefficient because in some cases there is repeated computation when the same expression compares in different parts. I don\u0026rsquo;t know how exactly is done by automatic differentiation, but probably you as a programmer need to write the function in some specific way.\nSupplementary notes With this notion of gradient flow, one can try to generalize this notion and create works like this (Du et al. 2023). Where the only thing needed is to have a semi-ring and then you can use the same algorithm for some interpretability analysis or similar.\nA simple exercise We will attempt to use backpropagation for the following function so that we can understand a little bit more about this algorithm:\n$$ f(x, y, z, v) = \\exp(y ^{-x} - \\log(z)) + (y - z)^{2} \\cdot \\log(v) $$$$ \\begin{array} \\\\ \\frac{ \\partial f }{ \\partial x } = \\exp(y^{-x} - \\log(z)) \\cdot e^{-x \\log y} (-\\log y) \\\\ \\frac{ \\partial f }{ \\partial y } = \\exp(y^{-x} - \\log(z)) \\cdot e^{-x \\log y} (-x / y) + 2(y - z) \\log(v) \\\\ \\frac{ \\partial f }{ \\partial z } = \\exp(y^{-x} - \\log(z)) / (-z) - 2(y - z) \\log(v) \\\\ \\frac{ \\partial f }{ \\partial v } = 0 + \\frac{(y - z)^{2}}{v} \\end{array} $$ We can observe that with the symbolic method a lot of computation is repeated in the $\\exp$ thing.\nThis is an example of the computational graph (forward in red and backward in blue, it has a small mistake when computing the backwards for the exponential function) Check the original excalidraw here.\nAn algorithm for k-th order gradients $$ \\nabla^{2}f = \\begin{bmatrix} \\nabla (e_{1}^{T} \\nabla f(x)) \\\\ \\vdots \\\\ \\nabla (e_{n}^{T} \\nabla f(x)) \\end{bmatrix} $$ This is a handy relation, that could be extended also to the $k-th$ order case. We need $\\mathcal{O(m)}$ operations to compute the gradient for a single component, we just unfold the computation graph (we take the last backward used for the gradient, as another forward component) and do the same for every component. This algorithm runs in $\\mathcal{O(n \\cdot m)}$. It\u0026rsquo;s easy to prove by induction that if we apply the same algorithm, in order to compute the $k$ order algorithm it will take $\\mathcal{O}(n^{k - 1}m)$ time.\nReferences [1] Huang ‚ÄúAdvanced Dynamic Programming in Semiring and Hypergraph Frameworks‚Äù Coling 2008 Organizing Committee 2008\n[2] Du et al. ‚ÄúGeneralizing Backpropagation for Gradient-Based Interpretability‚Äù 2023\n","permalink":"https://flecart.github.io/notes/backpropagation/","summary":"\u003cp\u003eBackpropagation is perhaps the most important algorithm of the 21st century. It is used everywhere in machine learning and is also connected to computing marginal distributions. This is why all machine learning scientists and data scientists should understand this algorithm very well.\nAn important observation is that this algorithm is \u003cstrong\u003elinear\u003c/strong\u003e: the time complexity is the same as the forward pass. Derivatives are unexpectedly cheap to calculate. This took a lot of time to discover. See \u003ca href=\"https://colah.github.io/posts/2015-08-Backprop/\"\u003ecolah\u0026rsquo;s blog\u003c/a\u003e.\n\u003ca href=\"https://youtu.be/VMj-3S1tku0?si=wRCObFw7woZTwU56\"\u003eKarpathy\u003c/a\u003e has a nice resource for this topic too!\u003c/p\u003e","title":"Backpropagation"},{"content":"Bag of words only takes into account the count of the words inside a document, ignoring all the syntax and boundaries. This method is very common for email classifications techniques. We can say bag of words can be some sort of pooling, it\u0026rsquo;s similar to the computer vision analogue. It\u0026rsquo;s difficult to say what is the best method (also a reason why people say NLP is difficult to teach).\nIntroduction to bag of words Faremo una introduzione di applicazione di Na√Øve Bayes applicato alla classificazione di documenti. Setting del problema üü®+ $$ \\theta_{i, \\text{word}, l} = P(X_{i} = \\text{word} | Y = l) $$ Ossia quanto √® probabile che una parola sia word, che appaia alla posizione i, data la categoria $l$ del documento Assumendo che non dipenda dalla posizione posso solamente contare le parole per documento fregandomene della posizione, questa √® l\u0026rsquo;idea che ha portato ai primi approcci in questo campo.\nAssumiamo che siano anche indipendenti alla posizione per semplicit√†, che √® una assunzione molto forte perch√© proviamo a catalogare la classe solamente dalla frequenza delle parole\n$$ \\theta_{i, \\text{word}, l} = \\theta_{\\text{word}, l} $$Note: assunzioni forti (2) üü© Perch√© √® una assunzione molto forte, e irrealistica il fatto che siano:\nIndipendenti dalla posizione indipendenti fra di loro (√® molto chiaro che certe parole vanno pi√π insieme rispetto ad altri, quindi √® una assunzione chiaramente false). Per√≤ √® didattica la cosa che un modello semplice come Na√Øve Bayes possa essere utilizzato per un problema del genere. Forward inference Una volta creato tutta la matrice di pesi e possibilit√† (quanto √® correlato), Per fare una forward inference non faccio altro che fare una dot product perch√© usiamo quella come metrica per fare inference.\nInference in breve üü• Calcolando la $s_{k}$ come in immagine sopra, posso avere una sorta di caratterizzazione del tema/categoria, in ogni singolo documento che ho.\nPoi per fare inferenza vedo il documento attuale √® pi√π simile rispetto a quale.\nCosine similarity üü© Questa √® una metrica molto utilizzata per dare una idea di somiglianza di vettori.\n","permalink":"https://flecart.github.io/notes/bag-of-words/","summary":"\u003cp\u003eBag of words only takes into account the \u003cstrong\u003ecount\u003c/strong\u003e of the words inside a document, ignoring all the syntax and boundaries. This method is very common for email classifications techniques.\nWe can say bag of words can be some sort of \u003cstrong\u003epooling\u003c/strong\u003e, it\u0026rsquo;s similar to the computer vision analogue.\nIt\u0026rsquo;s difficult to say what is the best method (also a reason why people say NLP is difficult to teach).\u003c/p\u003e\n\u003ch3 id=\"introduction-to-bag-of-words\"\u003eIntroduction to bag of words\u003c/h3\u003e\n\u003cp\u003eFaremo una introduzione di applicazione di \u003ca href=\"/notes/na%C3%AFve-bayes/\"\u003eNa√Øve Bayes\u003c/a\u003e applicato alla classificazione di documenti.\n\u003cimg src=\"/images/notes/Bag of words-20240907182135341.webp\" alt=\"Bag of words-20240907182135341\"\u003e\u003c/p\u003e","title":"Bag of words"},{"content":"What are Banach Spaces? A Banach space is a complete normed vector space, meaning that every Cauchy sequence in the space converges to a limit within the space. See Spazi vettoriali for the formal definition.\nExamples of Banach Spaces In this section, we list some examples of the most common Banach Spaces\n$\\ell^p$ Spaces (Sequence Spaces)\nDefined as: $$ \\ell^p = \\left\\{ (x_n)_{n\\in \\mathbb{N}} \\mid \\sum_{n=1}^{\\infty} |x_n|^p \u003c \\infty \\right\\}, \\quad 1 \\leq p \u003c \\infty $$ The norm is given by: $$ \\|x\\|_p = \\left( \\sum_{n=1}^{\\infty} |x_n|^p \\right)^{1/p} $$ When $p = \\infty$, we define: $$ \\ell^\\infty = \\left\\{ (x_n)_{n\\in \\mathbb{N}} \\mid \\sup_n |x_n| \u003c \\infty \\right\\} $$ with the norm $\\|x\\|_{\\infty} = \\sup_n |x_n|$. These spaces are Banach under their respective norms. $L^p$ Spaces (Function Spaces)\nGiven a measure space $(X, \\Sigma, \\mu)$, the space $L^p(X)$ consists of measurable functions $f: X \\to \\mathbb{R}$ (or $\\mathbb{C}$) such that: $$ \\|f\\|_p = \\left( \\int_X |f(x)|^p d\\mu(x) \\right)^{1/p} \u003c \\infty, \\quad 1 \\leq p \u003c \\infty. $$ When $p = \\infty$, the norm is: $$ \\|f\\|_{\\infty} = \\text{ess sup} |f(x)|. $$ These are Banach spaces when equipped with their respective norms. $C([a,b])$ (Space of Continuous Functions)\nThe space of continuous functions on a closed interval $[a,b]$ with the supremum norm: $$ \\|f\\|_{\\infty} = \\sup_{x \\in [a,b]} |f(x)| $$ This is a Banach space because uniform limits of continuous functions are continuous. Sobolev Spaces $W^{k,p}(\\Omega)$\nThese spaces generalize $L^p$ spaces by incorporating weak derivatives up to order $k$, with norms: $$ \\|u\\|_{W^{k,p}} = \\sum_{|\\alpha| \\leq k} \\|\\partial^\\alpha u\\|_p. $$ They play a crucial role in PDEs and functional analysis. The Space of Bounded Linear Operators $B(X, Y)$\nGiven two Banach spaces $X$ and $Y$, the space of bounded linear operators from $X$ to $Y$, denoted $B(X, Y)$, with the operator norm: $$ \\|T\\| = \\sup_{\\|x\\|\\leq 1} \\|T(x)\\| $$ This forms a Banach space. ","permalink":"https://flecart.github.io/notes/banach-spaces/","summary":"\u003ch3 id=\"what-are-banach-spaces\"\u003eWhat are Banach Spaces?\u003c/h3\u003e\n\u003cp\u003eA \u003cstrong\u003eBanach space\u003c/strong\u003e is a complete normed vector space, meaning that every Cauchy sequence in the space converges to a limit within the space.\nSee \u003ca href=\"/notes/spazi-vettoriali/\"\u003eSpazi vettoriali\u003c/a\u003e for the formal definition.\u003c/p\u003e\n\u003ch3 id=\"examples-of-banach-spaces\"\u003eExamples of Banach Spaces\u003c/h3\u003e\n\u003cp\u003eIn this section, we list some examples of the most common Banach Spaces\u003c/p\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e$\\ell^p$ Spaces (Sequence Spaces)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDefined as:\n$$\n     \\ell^p = \\left\\{ (x_n)_{n\\in \\mathbb{N}} \\mid \\sum_{n=1}^{\\infty} |x_n|^p \u003c \\infty \\right\\}, \\quad 1 \\leq p \u003c \\infty\n     $$\u003c/li\u003e\n\u003cli\u003eThe norm is given by:\n$$\n     \\|x\\|_p = \\left( \\sum_{n=1}^{\\infty} |x_n|^p \\right)^{1/p}\n     $$\u003c/li\u003e\n\u003cli\u003eWhen $p = \\infty$, we define:\n$$\n     \\ell^\\infty = \\left\\{ (x_n)_{n\\in \\mathbb{N}} \\mid \\sup_n |x_n| \u003c \\infty \\right\\}\n     $$\nwith the norm $\\|x\\|_{\\infty} = \\sup_n |x_n|$.\u003c/li\u003e\n\u003cli\u003eThese spaces are Banach under their respective norms.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e$L^p$ Spaces (Function Spaces)\u003c/strong\u003e\u003c/p\u003e","title":"Banach Spaces"},{"content":"2.1 Basi 2.1.1 Definizione Un insieme di vettori $v_1,...,v_n$ sono basi di uno spazio vettoriale $V$ se sono soddisfatte queste propriet√†\n$V = \\langle v_1,...,v_n\\rangle$ $v_1,...,v_n$ sono linearmente indipendenti Dalla propriet√† 2 potremmo anche dire che √® il minimo insieme di vettori necessario per avere questa base.\nFinitamente generato\nSe l\u0026rsquo;insieme dei vettori nella base √® finito allora posso dire che √® finitamente generato\nMa possiamo trovare anche spazi che non sono finitamente generati come $\\R[x]$ che non hanno un numero finito di basi (perch√© dipende dal grado dei polinomi che pu√≤ essere infinito).\nNota: base dello spazio vettoriale banale\nLa base dello spazio banale √® l\u0026rsquo;insieme vuoto!, se fosse il vettore 0, per definizione posso trovare un coefficiente diverso da 0 tale che sia zero. eg $1\\cdot 0_v = 0$ quindi non √® linearmente indipendente.\nNota sulla seguente carrellata di proposizioni\nLe seguenti proposizioni parlando della possibilit√† di generare le basi partendo da vettori linearmente indipendenti e aggiungendo fino a generare, o partendo da vettori che generano e togliendo finch√© non hai una base.\nDa questa idea generale si possono ricavare molte osservazioni, che sono elencate dalle proposizioni seguenti\n2.1.2 Minimali e massimali Si dice che una propriet√† √® minimale per un insieme, se ogni sottoinsieme proprio possiede pi√π la propriet√†\nE si dice che √® massimale se per ogni sovrainsieme proprio, questo insieme perde la propriet√†\n2.1.3 Prop 4.1.4 Teorema caratterizzazione delle basi Questo teorema √® equivalente alla definizione data di base, solo che esprime il concetto utilizzando i minimali e massimali.\nEnunciato\nSi dice che un insieme di vettori $v_1, ..., v_n$ √® una base per uno spazio vettoriale sse:\nL\u0026rsquo;insieme massimale di vettori linearmente indipendenti Minimale di vettori generatori (cio√® se ne tolgo uno non genera pi√π, allora riesco a concludere che sono indipendenti) gi√† vista nella 4.2.1 Si pu√≤ notare come sia strettamente collegato alla 4.2.2\nIdee per la dimostrazione\nCaso 2$\\impliedby$Se mi prendo un insieme minimale di generatori, mi basta dimostrare che siano indipendenti per sapere che sia una base.\nSupponiamo per assurdo che siano dipendenti. Allora esiste un vettore linearmente dipendente, e quindi esprimibile come combinazione lineare di altri vettori 3.2.4, ma se √® una combinazione lineare allora non √® pi√π l\u0026rsquo;insieme minimale di generatori (cio√® questo vettore non ha contributi sullo spazio) √® il teorema 3.1.8 qed.\nCaso 1 $\\impliedby$Se ho un insieme massimale di vettori linearmente indipendenti, voglio dimostrare che genera V.\nAllora per massimalit√† appena aggiungo un vettore, ho un insieme di vettori linearmente dipendenti, allora mi posso trovare una combinazione lineare con coefficienti non nulli tali che la combinazione sia 0.\nquindi $\\lambda_1v_1 + ...+ \\lambda_nv_n + \\beta w = 0$, e per qualunque vettore $\\omega$ so che $\\beta \\neq 0$ perch√© altrimenti si ha l\u0026rsquo;assurdo in quanto i vettori $v_1, ..., v_n$ sarebbero dipendenti. Se √® diverso da 0 allora posso esprimerlo come combinazione lineare di altro, quindi riesco ad ottenere l\u0026rsquo;intero spazio.\n2.1.4 Prop. creazione di base da vettori generatori Questo teorema ci permette di ricavare una base partendo da un insieme di vettori che generino l\u0026rsquo;intero spazio vettoriale. L\u0026rsquo;idea principale √® che possiamo trovare dei vettori che sono combinazioni lineari di altro e continuare a toglierli finch√© non trovo la base.\nEnunciato\nSia $v_1... v_n$ un insieme che genera $V$, allora un sottoinsieme di questi vettori generatori sono una base per $V$.\nDimostrazione\nSe i vettori sono linearmente indipendenti allora ho la base, se sono dipendenti allora sia $\\omega$ il vettore dipendente, allora si pu√≤ scrivere come combinazione lineare per la 3.2.4, e per la proposizione 3.1.8 lo spazio generato da tali vettori √® esattamente lo stesso.\nPosso continuare con questo argomento finch√© non ottengo la base o non ci sono pi√π vettori. (nel caso in cui √® lo spazio nullo).\nNota\nSi pu√≤ fare anche il contrario, da un insieme di vettori linearmente indipendenti posso aggiungere vettori fino a quanto non creo una base, l\u0026rsquo;algoritmo √® molto simile, ma al contrario.\n2.1.5 prop 4.2.1 Teorema del completamento Enunciato\nDa una base $v_1,..., v_n$ e un insieme di vettori linearmente indipendenti $\\omega_1, ..., \\omega_m$ appartenenti allo stesso spazio allora so che $m \\leq n$, inoltre √® possibile aggiungere vettori a $\\omega$ in modo che sia una base, questa base ha la stessa cardinalit√† della base si sopra\nDimostrazione (non richiesta)\nSi utilizza la proposizione precedente al contrario probabilmente.\n2.2 Dimensione Il concetto di dimensione √® strettamente correlato con il concetto di base. Possiamo intendere la dimensione come il minimo insieme di coordinate necessarie per creare l‚Äôintero spazio (questa √® una definizione che c‚Äô√® anche nel teorema di caratterizzazione delle basi). Perch√© alla fine saranno le coordinate che ci interessano.\n2.2.1 prop. 4.2.2 Basi hanno stessa dimensione DIMENSIONE (chiede) C\u0026rsquo;√® il teorema del completamento\nEnunciato\nDato uno spazio vettoriale finitamente generato, allora tutte le sue basi hanno la stessa cardinalit√†, questo numero di chiama dimensione dello spazio vettoriale, ed √® una propriet√† caratterizzante di essa.\nDimostrazione\nMeglio una dimostrazione cos√¨: in quanto b1 √® base e b2 √® linearmente indipendente ho (per completamento) che $n \\geq m$, in quanto b2 √® base e b1 linearmente indipendente ho che $n \\leq m$, quindi $n = m$\n2.2.2 Basi canoniche Ci sono certe basi che sono particolarmente interessanti, le chiamiamo basi canoniche, e sono definite come\n$e_i = \\{0...0_{i-1},1,0_{i + 1},..., 0_n\\}$ ovvero ho un 1 alla n esima posizione\n2.2.3 prop 4.2.4 relazioni fra dimensioni Dato uno spazio vettoriale $W$e un suo sotto spazio $V$ si ha\n$dim(V) \\leq dim(W)$ $dim(V) = dim(W) \\iff V=W$ Dimostrazione\nCaso 1 Sia m la dimensione di $V$ allora la sua base ha m vettori che sono linearmente indipendenti. Questi vettori sono anche presenti in $W$, che poniamo abbia dimensione n, allora per il teorema del completamento ho che $m \\leq n$\nCaso 2 $\\impliedby$ questa freccia √® ovvia, se sono la stessa cosa hanno la stessa dimensione\nCaso 2 $\\implies$\nscambiare W e V in questa dimostrazione\n2.2.4 prop 4.2.6 Dimensione, base, lin ind, e generazione (3)! Enunciato\n3 to 1\nse ho un insieme di vettori che generano uno spazio allora posso togliere vettori fino a quando ho una base (ossia sono linearmente indipendenti). Ma per la dimensione ho che devo avere necessariamente n vettori, quindi un insieme di n vettori linearmente indipendenti √® gi√† una base.\n2 to 1\nL\u0026rsquo;argomento presente qui √® uguale alla superiore 4.2.4 (quindi dire per il completamento che posso espandere e ottenere una base) Anzi potresti direttamente utilizzare questa per dimostrare sto punto\n2.2.5 Coordinate di un punto in uno spazio vettoriale Sia data una base per uno spazio vettoriale $v_1, ..., v_n$, allora ho che posso scrivere qualunque vettore $\\omega$ nello spazio in un unico modo, moltiplicando per corrispondenti fattori. Questi fattori sono unici.\nDimostrazione unicit√†\n2.3 Algoritmo di gauss rivisitato 2.3.1 A.G non cambia sottospazio riga (non richiesta) L\u0026rsquo;intuizione per questo √® abbastanza ovvio, sto solamente applicando combinazioni lineari fra le righe, quindi sto sempre prendendo vettori che appartengono a questo spazio, non le sto modificando, questo giustificherebbe anche il motivo per cui l\u0026rsquo;algoritmo di gauss √® utile.\nDimostrazione\nla proposizione da utilizzare √® lo span che non cambia se aggiungo e tolgo una combinazione lineare\n2.3.2 Indipendenza delle righe non nulle Dimostrazione non fatta.\n","permalink":"https://flecart.github.io/notes/base-e-dimensione/","summary":"\u003ch2 id=\"21-basi\"\u003e2.1 Basi\u003c/h2\u003e\n\u003ch3 id=\"211-definizione\"\u003e2.1.1 Definizione\u003c/h3\u003e\n\u003cp\u003eUn insieme di vettori $v_1,...,v_n$ sono basi di uno spazio vettoriale $V$ se sono soddisfatte queste propriet√†\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e$V = \\langle v_1,...,v_n\\rangle$\u003c/li\u003e\n\u003cli\u003e$v_1,...,v_n$ sono linearmente indipendenti\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eDalla propriet√† 2 potremmo anche dire che √® il minimo insieme di vettori necessario per avere questa base.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFinitamente generato\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eSe l\u0026rsquo;insieme dei vettori nella base √® finito allora posso dire che √® finitamente generato\u003c/p\u003e\n\u003cp\u003eMa possiamo trovare anche spazi che non sono finitamente generati come $\\R[x]$ che non hanno un numero finito di basi (perch√© dipende dal grado dei polinomi che pu√≤ essere infinito).\u003c/p\u003e","title":"Base e dimensione"},{"content":"Bayesian Information Criterion (BIC) The Bayesian Information Criterion (BIC) is a model selection criterion that helps compare different statistical models while penalizing model complexity. It is rooted in Bayesian probability theory but is commonly used even in frequentist settings.\nMathematically Precise Definition For a statistical model $M$ with $k$ parameters fitted to a dataset $\\mathcal{D} = \\{x_1, x_2, \\dots, x_n\\}$, the BIC is defined as:\n$$ \\text{BIC} = -2 \\cdot \\ln \\hat{L} + k \\cdot \\ln(n) $$where:\n$\\hat{L}$ is the maximum likelihood of the model, i.e., $\\hat{L} = P(\\mathcal{D} \\mid \\hat{\\theta}, M)$, where $\\hat{\\theta}$ are the maximum likelihood estimates (MLE) of the parameters. $k$ is the number of free parameters in the model. $n$ is the number of observations in the dataset. Interpretation Likelihood Component (\\(-2 \\ln \\hat{L}\\)):\nMeasures the fit of the model. A higher likelihood (or lower \\(-2 \\ln \\hat{L}\\)) indicates the model explains the data well. Penalty Term (\\(k \\ln n\\)):\nPenalizes model complexity. More parameters (\\(k\\)) increase the penalty, preventing overfitting. The penalty grows with $\\ln(n)$, meaning as the dataset size increases, the cost of adding parameters increases more slowly. Model Selection Criterion:\nLower BIC values indicate a more preferred model. It balances goodness of fit and model simplicity: the best model explains the data well without unnecessary complexity. Derivation of BIC The BIC is derived from approximating the Bayesian model evidence under certain assumptions. Here\u0026rsquo;s a step-by-step derivation:\nBayesian Model Selection: In Bayesian statistics, model selection is based on the posterior probability of a model $M$ given data $\\mathcal{D}$:\n$$ P(M \\mid \\mathcal{D}) \\propto P(\\mathcal{D} | M) P(M) $$where:\n$P(\\mathcal{D} | M)$ is the marginal likelihood or model evidence: $$ P(\\mathcal{D} | M) = \\int P(\\mathcal{D} | \\theta, M) P(\\theta \\mid M) \\, d\\theta $$ Laplace Approximation of Marginal Likelihood: When $n$ is large, we can approximate the integral using Laplace\u0026rsquo;s method around the MLE $\\hat{\\theta}$.\nThe likelihood $P(\\mathcal{D} \\mid \\theta, M)$ is sharply peaked around $\\hat{\\theta}$. The approximation gives: $$ P(\\mathcal{D} \\mid M) \\approx P(\\mathcal{D} \\mid \\hat{\\theta}, M) \\cdot \\left( \\frac{(2\\pi)^{k/2}}{ \\lvert I_{n}(\\hat{\\theta}) \\rvert ^{1/2}} \\right) \\cdot P(\\hat{\\theta} \\mid M) $$ where $I(\\hat{\\theta})$ is the Fisher information, see Parametric Modeling for its definition. Log Transformation and Simplification: Taking the logarithm and ignoring constants not dependent on $n$:\n$$ \\ln P(\\mathcal{D} \\mid M) \\approx \\ln P(\\mathcal{D} \\mid \\hat{\\theta}, M) - \\frac{k}{2} \\ln(n) $$ Formulating BIC: Multiplying both sides by \\(-2\\) (for consistency with the likelihood ratio test framework):\n$$ -2 \\ln P(\\mathcal{D} \\mid M) \\approx -2 \\ln P(\\mathcal{D} \\mid \\hat{\\theta}, M) + k \\ln(n) $$The right-hand side is precisely the BIC formula:\n$$ \\text{BIC} = -2 \\ln \\hat{L} + k \\ln(n) $$ Assumptions Behind BIC Large Sample Size ($n \\to \\infty$): The Laplace approximation assumes that the sample size is large enough for the likelihood to be sharply peaked. Regularity Conditions: The likelihood function must be well-behaved (differentiable, unimodal, etc.). Model Correctness: One of the candidate models is assumed to be the true model (though in practice, this is often violated). Comparison to Other Criteria $$ \\text{AIC} = -2 \\ln \\hat{L} + 2k $$ AIC penalizes complexity less harshly than BIC. AIC is more suitable for predictive performance, while BIC is more conservative and often better at identifying the \u0026ldquo;true\u0026rdquo; model. BIC vs AIC:\nBIC tends to prefer simpler models as $n$ increases, due to the $\\ln(n)$ term. AIC is asymptotically efficient (minimizes prediction error), while BIC is consistent (selects the true model as $n \\to \\infty$). How to use the BIC In practice: 11. Fit candidate models to the data. 12. Compute the BIC for each model. 13. Select the model with the lowest BIC.\nBIC is widely used in fields like machine learning, econometrics, and statistical modeling, where balancing fit and complexity is critical.\n","permalink":"https://flecart.github.io/notes/bayesian-information-criterion/","summary":"\u003ch3 id=\"bayesian-information-criterion-bic\"\u003e\u003cstrong\u003eBayesian Information Criterion (BIC)\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eThe \u003cstrong\u003eBayesian Information Criterion (BIC)\u003c/strong\u003e is a model selection criterion that helps compare different statistical models while penalizing model complexity. It is rooted in Bayesian probability theory but is commonly used even in frequentist settings.\u003c/p\u003e\n\u003ch3 id=\"mathematically-precise-definition\"\u003e\u003cstrong\u003eMathematically Precise Definition\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eFor a statistical model $M$ with $k$ parameters fitted to a dataset $\\mathcal{D} = \\{x_1, x_2, \\dots, x_n\\}$, the BIC is defined as:\u003c/p\u003e\n$$\n\\text{BIC} = -2 \\cdot \\ln \\hat{L} + k \\cdot \\ln(n)\n$$\u003cp\u003ewhere:\u003c/p\u003e","title":"Bayesian Information Criterion"},{"content":"We have a prior $p(\\text{model})$, we have a posterior $p(\\text{model} \\mid \\text{data})$, a likelihood $p(\\text{data} \\mid \\text{model})$ and $p(\\text{data})$ is called the evidence.\nClassical Linear regression $$ y = w^{T}x + \\varepsilon $$ Where $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{n}^{2}I)$ and it\u0026rsquo;s the irreducible noise, an error that cannot be eliminated by any model in the model class, this is also called aleatoric uncertainty. One could write this as follows: $y \\sim \\mathcal{N}(w^{T}x, \\sigma^{2}_{n}I)$ and it\u0026rsquo;s the exact same thing as the previous, so if we look for the MLE estimate now we get\n$$ \\hat{w}_{\\text{MLE}} = \\arg \\max_{w \\in \\mathbb{R}^{d}} \\sum_{i = 1}^{N} \\log p (y_{i} \\mid x_{i}, w) = \\arg \\min_{w \\in \\mathbb{R}^{d}} (y - w^{T}x)^{2} $$ And this result is quite nice, because we just discovered that with this assumptions the best model for classical linear regression, the minimizer for the ordinary least squares problem, gives the same result with the maximum likelihood estimator.\n$$ \\mathcal{O}(d^{2}N + d^{3}) $$ Where $d$ is the dimensionality of the input and $n$ the number of samples. Using the closed formula approach. Usually the Gradient Descent method might be a little faster. It costs $\\mathcal{O(nd)}$ per iteration.\nRidge Regression Before diving into this section, you should know Ridge Regression quite well.\nMaximum a posteriori estimate leads to Ridge Regression üü© $$ p(y_{i} \\mid w_{i}x_{i}) = \\mathcal{N}(y_{i}; w^{T}x_{i}, \\sigma^{2}_{n}) $$ Which is the same as saying that $y_{i} = w^{T}x_{i} + \\varepsilon_{i}$ where $\\varepsilon_{i} \\sim \\mathcal{N}(0, \\sigma^{2}_{n})$.\n$$ p(w \\mid x_{1:n}, y_{1:n}) = \\frac{1}{z} p(w \\mid x_{1:n}) p(y_{1:n} \\mid w_{i},x_{1:n}) $$ And $z = \\int p(w) p(y_{1:n} \\mid w_{i}, x_{1:n}) \\, dw$.\nNow let\u0026rsquo;s expand everything: we will have:\n$$ \\frac{1}{z} \\cdot \\frac{1}{z_{p}} \\exp\\left( -\\frac{1}{2\\sigma^{2}_{p}} \\lVert w \\rVert ^{2}_{2} \\right) \\cdot \\frac{1}{z_{l}} \\prod_{i = 1}^{n} \\exp\\left( -\\frac{1}{2\\sigma_{n}^{2}} (y_{i} - w^{T}x_{i})^{2} \\right) $$$$ = \\frac{1}{z'} \\exp\\left( -\\left[ \\frac{1}{2\\sigma^{2}_{p} }\\lVert w \\rVert^{2}_{2} + \\frac{1}{2\\sigma^{2}_{n}} \\sum_{i = 1}^{n} (y_{i} - w^{T}x_{i})^{2} \\right] \\right) $$ Now we do Max. a posteriori (MAP) estimate for $\\hat{w}$ and we get this: $$\n\\begin{align} \\hat{w} = \\arg\\max_{w} \\log p(w \\mid x_{1:n}y_{1:n}) \\ \\ = \\arg \\max_{w} \\log p(y_{1:n} \\mid x_{1:n}, w) + \\log p(w)\\ = \\arg \\min_{w} \\sum_{i = 1}^{k} (y_{i} - w^{T}x_{i})^{2} + \\frac{\\sigma_{n}^{2}}{\\sigma^{2}{p}} \\lVert w \\rVert ^{2}{2} \\end{align} $$ Which we note is the same as Ridge regression with $\\lambda = \\frac{\\sigma_{n}^{2}}{\\sigma^{2}_{p}}$. So with those Gaussian assumptions we just go back to a standard regression case! Remember that if $\\lambda = 0$ we don\u0026rsquo;t have basically a regularizer, if $\\lambda$ is high we practically don\u0026rsquo;t care much about the data (if noise is high we want to regularize, but if the prior variance is small we regularize more)\nThe MAP estimate simply collapses all mass of the posterior around its mode. This can be harmful when we are highly unsure about the best model, e.g., because we have observed insufficient data.\nThis why usually bayesian methods are preferred in other times.\n$$ p(w) = \\prod_{i = 1}^{d} \\frac{\\sigma^{2}_{p}}{4 \\sigma^{2}_{n}} \\exp\\left( -\\frac{\\sigma^{2}_{p}}{2\\sigma^{2}_{n}} \\lvert w_{i} \\rvert \\right) $$ No clue how to derive it though. I took this from slide 12 here (you need eth credentials to access the resource).\nPosterior is Gaussian üü© $$ p(w \\mid x_{1:n}, y_{1:n}) = \\frac{1}{z'} \\exp\\left( -\\left[ \\frac{1}{2\\sigma^{2}_{p} }\\lVert w \\rVert^{2}_{2} + \\frac{1}{2\\sigma^{2}_{n}} \\sum_{i = 1}^{n} (y_{i} - w^{T}x_{i})^{2} \\right] \\right) $$$$ \\begin{array} \\\\ \\bar{\\Sigma} = \\left( \\frac{1}{\\sigma_{n}^{2}} X^{T}X + \\frac{1}{\\sigma_{p}^{2}}I \\right)^{-1} = \\sigma_{n}^{2}\\left( X^{T}X + \\frac{\\sigma^{2}_{n}}{\\sigma_{p}^{2}} I \\right) ^{-1} \\\\ \\bar{\\mu} = \\frac{1}{\\sigma_{n}^{2}} \\bar{\\Sigma} X^{T}y = (X^{T}X + \\lambda I)^{-1} X^{T}y \\end{array} $$ Where $\\lambda$ is as before, and this is the link with linear regression! This form is nice as it allows to have some confidence intervals over the parameters.\nInference Inference in Bayesian Linear Regression üü®++ $$ p(y^{*} \\mid x^{*} x_{1:n} y_{1:n}) = \\int p(y^{*}, w \\mid x^{*}, x_{1:n} ,y_{1:n}) \\, dw = \\int p(y^{*} \\mid w ,x^{*}) p(w \\mid x_{1:n} y_{1:n}) \\, dw $$$$ p(f^{*} \\mid x^{*}, x_{1:n}, y_{1:n}) = \\mathcal{N}(f^{*}; \\bar{\\mu} ^{T}x^{*} , x^{*T}\\bar{\\Sigma}x^{*}) $$ And assuming $y^{*} = f^{*} + \\varepsilon$ we have sum of Gaussian is Gaussian so we have $$ p(y^{} \\mid x^{}, x_{1:n}, y_{1:n}) =\n\\int p(y^{} \\mid w ,x^{}) p(w \\mid x_{1:n} y_{1:n}) , dw =\\mathcal{N}(y^{}; \\bar{\\mu}^{T} x^{}, x^{T}\\bar{\\Sigma}x^{} + \\sigma^{2}_{n}I) $$ So compared to ridge regression, the Bayesian linear regression has a variance term that is added. Here we are using all possible models, weighted by their probability. Conceptually bayesian is better than MLE.\nIt is possible to see later with the law of total variance, the decomposition of the inference variance into epistemic and aleatoric variance.\nRelation between BLR and Ridge Regression üü© Ridge regression can be viewed as approximating the full posterior by placing all mass on its mode (also other models can be seen similarly, one example is MLE, analyzed in Parametric Modeling).\nSo it\u0026rsquo;s a nice approximation: $$ \\begin{align}\np(y^{} \\mid x^{}, x_{1:n}, y_{1:n}) =\n$$ Remember that for delta direct distribution we have $$ \\mathbb{E}[f(x)] = \\int f(x) \\delta_{x\u0026rsquo;}(x) , dx = f(x\u0026rsquo;) $$\nEpistemic and aleatoric uncertainty üü© We now start a philosophical discussion on epistemic and aleatoric uncertainty.\nEpistemic uncertainty: Uncertainty about the model due to the lack of data Aleatoric uncertainty: Irreducible noise The $x^{*T}\\bar{\\Sigma}x^{*}$ is the epistemic uncertainty about $f^{*}$ while the $\\sigma^{2}_{n}$ factor is the noise/uncertainty about $y^{*}$ given $f^{*}$, meaning we need to change $f^{*}$, or hypothesis class if we want to lower this uncertainty I think (not sure though).\nThe law of total variance can give another intuition about the decomposition between epistemic and aleatoric uncertainty:\n$$ Var(y \\mid x) = \\text{ aleatoric } + \\text{ epistemic } = \\mathbb{E}_{\\theta}\\left[ \\text{Var}_{y}(y \\mid x, \\theta) \\right] + \\text{Var}_{\\theta}(\\mathbb{E}_{y}[y \\mid x, \\theta]) $$Choosing hyper-parameters üü© We would like a manner to compute the values of $\\sigma^{2}_{n}$ and $\\sigma^{2}_{p}$. Covariance of the prior and variance of the noise need to be chosen before we can apply these methods. One way is just finding $\\lambda = \\frac{\\sigma^{2}_{n}}{\\sigma^{2}_{p}}$ with cross-validation, then estimate the variance from data and get the prior variance in this manner.\nThen it\u0026rsquo;s possible to have graphical models for bayesian linear regression.\nRecursive bayesian updates üü® $$ p^{(j)} (w) := p(w \\mid y_{1: j}), p^{(0)}(w) = p(w) $$$$ p^{(j)}(w) = p( w \\mid y_{1: j}) = \\frac{1}{z} p(w) \\cdot p(y_{1} \\mid w) \\dots p(y_{j} \\mid w) = \\frac{1}{z} \\left( z \\cdot p^{(j - 1)}(w) \\right) p(y_{j} \\mid w) = f(p^{(j - 1)}(w), y_{j}) $$So we would just need to integrate the new information given by $y_{j}$ and then use the previous knowledge. The recursive updates are also the reason why the Dirichlet is a nice prior for multinomials, see Dirichlet Processes.\nExample: Bayesian Update for a Coin toss We can see how the posterior changes with the number of coin flips. We will use a Beta prior for the Bernoulli likelihood, this is a conjugate prior so we can compute the posterior in closed form.\nimport numpy as np import matplotlib.pyplot as plt from scipy.stats import beta # Initialize parameters for the Beta prior alpha_prior = 1 # Prior \u0026#34;successes\u0026#34; (e.g., heads) beta_prior = 1 # Prior \u0026#34;failures\u0026#34; (e.g., tails) # Simulated coin flips (1 = heads, 0 = tails) np.random.seed(42) # For reproducibility coin_flips = np.random.choice([0, 1], size=100, p=[0.7, 0.3]) # Unfair coin: 70% tails, 30% heads # Function to plot the Beta distribution def plot_beta(alpha, beta_val, flip_num): x = np.linspace(0, 1, 1000) y = beta.pdf(x, alpha, beta_val) plt.plot(x, y, label=f\u0026#34;After {flip_num} flips (Œ±={alpha}, Œ≤={beta_val})\u0026#34;) plt.xlabel(\u0026#34;Probability of Heads (p)\u0026#34;) plt.ylabel(\u0026#34;Density\u0026#34;) plt.title(\u0026#34;Online Bayesian Update of Beta Distribution\u0026#34;) plt.legend() # Create a figure for the updates plt.figure(figsize=(10, 6)) # Perform Bayesian updates after each coin flip for i, flip in enumerate(coin_flips): # Update the Beta prior with the Bernoulli likelihood alpha_prior += flip # Increment alpha if heads (flip=1) beta_prior += 1 - flip # Increment beta if tails (flip=0) # Plot the updated distribution every few flips if i in {0, 4, 9, 19, 99}: # Plot at these specific flips plot_beta(alpha_prior, beta_prior, i + 1) # Show the final plot plt.grid(alpha=0.3) plt.show() Online Bayesian regression This section concerns in building a bayesian regression algorithm whose memory does not grow with the number of samples. It can be conceived as a filtering process, composed of two phased: conditioning (updating over the priors) and prediction.\n$$ p(w \\mid X, y) = \\mathcal{N}(w; (X^{T}X +\\sigma_{n}^{2}I)^{-1}X^{T}y, (\\sigma^{-2}_{n}X^{T}X + I)^{-1}) $$ Assuming $\\sigma_{p}^{2} = 1$.\n$$ X^{(t)} = \\begin{bmatrix} x_{1}^{T} \\\\ \\vdots \\\\ x_{t}^{T} \\end{bmatrix} \\in \\mathbb{R}^{t \\times d} \\,\\,\\, Y^{(t)} = \\begin{bmatrix} y_{1} \\\\ \\vdots \\\\ y_{t} \\end{bmatrix} \\in \\mathbb{R}^{t \\times 1} $$$$ X^{(t + 1)T}Y^{(t+1)} = \\sum_{i = 1}^{t} x_{i}y_{i} + x_{t + 1}y_{t + 1} = X^{(t)}Y^{(t)} + x_{t + 1}y_{t + 1} $$$$ X^{(t + 1)T} X^{(t+ 1)} = \\begin{pmatrix} x_{1} , \\dots x_{t} \\end{pmatrix} \\cdot \\begin{pmatrix} x_{1} \\\\ \\vdots \\\\ x_{t} \\end{pmatrix} = \\sum_{i = 1}^{t} x_{i}x_{i}^{T} + x_{t + 1}x_{t + 1}^{T} = X^{(t)T}X^{(t)} + x_{t+1}x_{t + 1}^{T} $$ This allows to compute the parameters in a way that the memory requirement is constant and does not grow as $\\mathcal{O(t)}$.\n$$ (A + uv^{T})^{-1} = A^{-1} - \\frac{A^{-1}uv^{T}A^{-1}}{1 + v^{T}A^{-1}u} $$And we can interpret the value $X^{(t)T}X^{(t)} + \\sigma_{n}^{2}I$ as our $A$ and the $x_{t+1}x_{t + 1}^{T}$ as our two vectors. In this manner we just need to compute matrix multiplications which bring down the complexity to $\\mathcal{O}(d^{2})$.\nThis is all for analysis in the online bayesian setting.\nLogistic regression case üü® $$ P(y \\mid x, w) = Ber(y; \\sigma(w^{T}x)) $$ Where $\\sigma$ is the Sigmoid function which gives an idea of confidence of a prediction.\nRelation with dimensionality üü© $$ f(x) = \\sum_{i = 1}^{N} w_{i} \\phi_{i}(x) $$$$ \\phi = [1, x_{1}, \\dots, x_{d}, x_{1}^{2}, .. x_{2}^{2}, x_{1}x_{2}, \\dots, x_{1}x_{2}\\dots x_{d}] $$$$ \\lvert \\phi \\rvert = \\begin{pmatrix} d + m \\\\ d \\end{pmatrix}$$The kernel trick üü© We first want to replace the problem using inner products then we want to replace inner products using kernels. If we are able to do this, then we can compute inner products in feature space quite efficiently. For example if $\\phi(x) = [\\text{ all monomials up to } m \\text{ variables} ]$ then we can compute $\\phi(x)^{T}\\phi(x)$ by just computing $(1 + x^{T}x)^{m}$. This is quite important to understand well. See Kernel Methods for more. This leads us in an attempt to kernelize the bayesian linear regression.\nFunction view In the previous sections we have derived the Bayesian Linear Regression based on priors on the weights and likelihoods. It is possible to derive something very similar by just observing inputs and outputs, so having a distribution on the space of the functions. This part builds the fundamental ideas that will be later needed for Gaussian Processes so it is quite important to understand this quite well.\n$$ f \\mid X \\sim \\mathcal{N}(\\Phi \\mathbb{E}[w], \\Phi\\mathbb{E}[w]\\Phi^{T}) = \\mathcal{N}(0, \\sigma^{2}_{p}\\Phi\\Phi^{T}) $$With this formulation the feature map is implicit in the choice of the Kernel.\nPredictions in function view üü®\u0026ndash; $$ \\bar{\\Phi} = \\begin{bmatrix} \\Phi \\\\ \\phi(x^{*})^{T} \\end{bmatrix}, \\, \\bar{y} =\\begin{bmatrix} y \\\\ y^{*} \\end{bmatrix}, \\bar{f} = \\begin{bmatrix} f \\\\ f^{*} \\end{bmatrix} $$$$ \\hat{y}\\mid X, x^{*} \\sim \\mathcal{N}(0, \\bar{K} + \\sigma^{2}_{n}I) $$","permalink":"https://flecart.github.io/notes/bayesian-linear-regression/","summary":"\u003cp\u003eWe have a prior $p(\\text{model})$, we have a posterior $p(\\text{model} \\mid \\text{data})$, a likelihood $p(\\text{data} \\mid \\text{model})$ and $p(\\text{data})$ is called the \u003cem\u003eevidence\u003c/em\u003e.\u003c/p\u003e\n\u003ch4 id=\"classical-linear-regression\"\u003eClassical Linear regression\u003c/h4\u003e\n$$\ny = w^{T}x + \\varepsilon\n$$\u003cp\u003e\nWhere $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{n}^{2}I)$ and it\u0026rsquo;s the irreducible noise, an error that cannot be eliminated by any model in the model class, this is also called \u003cstrong\u003ealeatoric uncertainty\u003c/strong\u003e.\nOne could write this as follows: $y \\sim \\mathcal{N}(w^{T}x, \\sigma^{2}_{n}I)$ and it\u0026rsquo;s the exact same thing as the previous, so if we look for the MLE estimate now we get\u003c/p\u003e","title":"Bayesian Linear Regression"},{"content":"Questi network bayesiani sono proprio dei grafi, che permettono una migliore comprensione delle relazioni causali o diagnostici fra le probabilit√†\nEsempio rete bayesiana\nNote generali Introduzione alla rete classica Una rete bayesiana ci permette di semplificare di molto il calcolo della full disjoint probability table, rendendola in questo modo\nOssia andiamo a utilizzare una probabilit√† locale, o sparsa per fare i conti, cosa che semplifica molto, e quindi velocizza il calcolo. v\nConditional probability table Ogni nodo deve avere anche una tabella per i valori di probabilit√† condizionale.\nIl mantello di Markov Il mantello di un nodo nell rete √® l‚Äôinsieme dei genitori, dei figli, e dei genitori dei figli, costituisce l‚Äôinsieme per cui il nodo attuale √® condizionalmente indipendente da tutti gli altri nodi.\n√à una nozione molto forte questa, che ha implicazioni molto profonde, un esempio √® Karl Friston che lo usa per fare delle argomentazioni forti sull‚Äôorigine della vita dalla zuppa primordiale.\nRete con variabili continue In cui servirebbe una base di analisi molto forte e anche di probabilit√† e statistica (quindi conoscere anche dal punto di vista matematico cosa sia la distribuzione normale etc).\nInferenza esatta Possiamo andare ad utilizzare le reti per calcolare il valore di probabilit√† di un evento, in questa parte si vede come.\nPer enumerazione Si va con la classica definizione di probabilit√†, andiamo a contare tutto, e ci√≤ ci comporta un tempo esponenziale di calcolo.\n$$ P(X \\mid e) = \\alpha P(X, e) = \\alpha \\sum_{y} P(X, e, y) $$ Pseudocodice\nEliminazione di variabili Con il metodo precedente, pu√≤ succedere che facciamo lo stesso calcolo molteplici volte, questa √® una chiarissima inefficienza. Si pu√≤ risolvere facendo una eliminazione di variabili in modo tale:\nPseudocodice\nAlgoritmi di clustering L‚Äôidea principale di questo √® raggruppare dei nodi in un nodo pi√π grosso.\nSampling (inferenza approssimata) ora andiamo ad utilizzare un metodo di monte carlo, che abbiamo visto per la prima volta (se non c‚Äô√® √® perch√© sono stato pigro e non l‚Äôho scritto) in Adversarial Search.\nPraticamente andremo a fare sampling di un evento tante volte, e cercheremo di carpirne delle informazioni con cui aggiornare il nostro modello.\nSampling diretto It\u0026rsquo;s the classical sampling method.\nSampling con rifiuto Accept Reject algorithm explains this algorithm in a better manner\nImportance sampling Monte Carlo Methods there is a section about monte carlo integration\nSimulazione con catene di Markov ","permalink":"https://flecart.github.io/notes/bayesian-networks/","summary":"\u003cp\u003eQuesti network bayesiani sono proprio dei grafi, che permettono una migliore comprensione delle relazioni causali o diagnostici fra le probabilit√†\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eEsempio rete bayesiana\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Bayesian Networks/Untitled.png\" alt=\"image/universita/ex-notion/Bayesian Networks/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"note-generali\"\u003eNote generali\u003c/h2\u003e\n\u003ch3 id=\"introduzione-alla-rete-classica\"\u003eIntroduzione alla rete classica\u003c/h3\u003e\n\u003cp\u003eUna rete bayesiana ci permette di semplificare di molto il calcolo della full disjoint probability table, rendendola in questo modo\u003c/p\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Bayesian Networks/Untitled 1.png\" alt=\"image/universita/ex-notion/Bayesian Networks/Untitled 1\"\u003e\n\u003cp\u003eOssia andiamo a utilizzare una \u003cstrong\u003eprobabilit√† locale, o sparsa\u003c/strong\u003e per fare i conti, cosa che semplifica molto, e quindi velocizza il calcolo. v\u003c/p\u003e","title":"Bayesian Networks"},{"content":"Robbins-Moro Algorithm The Algorithm $$ w_{n+1} = w_{n} - \\alpha_{n} \\Delta w_{n} $$For example with $\\alpha_{0} \u003e \\alpha_{1} \u003e \\dots \u003e \\alpha_{n} \\dots$, and $\\alpha_{t} = \\frac{1}{t}$ they satisfy the condition (in practice we use a constant $\\alpha$, but we lose the convergence guarantee by Robbins Moro). More generally, the Robbins-Moro conditions re:\n$\\sum_{n} \\alpha_{n} = \\infty$ $\\sum_{n} \\alpha_{n}^{2} \u003c \\infty$ Then the algorithm is guaranteed to converge to the best answer. One nice thing about this, is that we don\u0026rsquo;t need gradients. But often we use gradient versions (stochastic gradient descent and similar), using auto-grad, see Backpropagation. But learning with gradients brings some drawbacks:\nWe have no quantification of the uncertainty. We are usually overconfident in our predictions (adversarial examples, and poor generalization to domain shifts). Convergence Proof $$ \\mathop{\\mathbb{E}}[g(X, \\theta)] = 0 $$And $g$ is our smooth and well-behaved function.\nWe updated our theta iteratively based on the above rule: $\\theta_{t + 1} = \\theta_{t} - \\alpha_{t}g(X, \\theta_{t})$. Then look at this:https://chatgpt.com/share/677e4cdb-4c60-8009-b57d-49ce8efeda5a (should be verified).\nBayesian Neural Networks The Idea The idea here is the same as the one applied to Bayesian neural networks: define a prior of the weights and likelihood and define a posterior over the weights. But the nature of the model makes it quite difficult, if not impossible to have a closed-form solution for the posterior.\nA simple model We want to predict the weights of a given model with some bounds on certainty about them. One thing is that we have always used linear models for this, but we can also use neural networks or more complex models. Usually, in some datasets also the variance changes with the input; this is called heteroskedastic noise. This justifies models in the following form:\n$$ p(y \\mid \\boldsymbol{x}, \\theta) = \\mathcal{N}(u; f_{1}(\\boldsymbol{x}, \\theta), \\exp(f_{2}(\\boldsymbol{x}, \\theta))) $$ where $f_{1}$ and $f_{2}$ are neural networks and $\\theta$ are the weights of the neural network. We use neural networks to predict mean and variance. We use the $\\exp$ function to ensure that the variance is always positive.\nFrom a practical point of view, this machinery is quite good at estimating variance in regions where data is present (same thing in heteroskedastic settings!), while it is overconfident in zones without data, often collapsing the variance.\nMap estimate for bayesian NN üü®\u0026ndash; Assume a prior $p(\\theta) \\sim \\mathcal{N}(\\theta; 0, \\lambda^{-1})$ and the above parametrization of the likelihood function, let\u0026rsquo;s derive the posterior distribution, that is $p(\\theta \\mid y, \\boldsymbol{x})$.\nWe notice that while in the Bayesian Linear Regression the normalization constant is disregarded, here it is dependent on the $\\theta$, so we need to consider it. We can pay higher variance cost to minimize the error in the quadratic term.\n$$ \\hat{\\theta} = \\arg\\min_{\\theta} - \\underbrace{\\log p(\\theta)}_{\\lambda \\lVert \\theta \\rVert ^{2}_{2}} - \\sum_{i = 1}^{n} \\log p(y_{i} \\mid x_{i}, \\theta) $$$$ \\begin{align} \\log p(y_{i} \\mid x_{i}, \\theta) \u0026= \\log \\mathcal{N}(y_{i}; \\mu(x_{i}, \\theta), \\sigma^{2}(x_{i}, \\theta))) \\\\ \u0026 = -\\frac{1}{2} \\log 2\\pi \\sigma^{2}(x_{i}, \\theta) - \\frac{1}{2\\sigma^{2}(x_{i}, \\theta)} (y_{i} - \\mu(x_{i}, \\theta))^{2} \\\\ \u0026 = -\\frac{1}{2} \\log 2\\pi - \\frac{1}{2} \\log \\sigma^{2}(x_{i}, \\theta) - \\frac{1}{2\\sigma^{2}(x_{i}, \\theta)} (y_{i} - \\mu(x_{i}, \\theta))^{2} \\\\ \u0026= \\underbrace{-\\frac{1}{2} \\log 2\\pi}_{\\text{const}} -\\frac{1}{2}\\left[ \\log \\sigma^{2}(x_{i}, \\theta) + \\frac{ (y_{i} - \\mu(x_{i}, \\theta))^{2} }{\\sigma^{2}(x_{i}, \\theta)}\\right] \\end{align} $$ Here you observe that the likelihood is maximized by having high variance (plus penalty) or having correct estimates. Then adding the prior is just a regularizing term that corresponds to weight decay (a good exercise is to prove this part).\nThe Classification Case: TODO: minute 22 of part 2.\nPrediction with Bayesian Neural Networks We see that prediction is just averaging over the predictions of different networks sampled from the approximate distribution that we derived from the variational inference of the weights. Some formalization could help in clearing this out.\n$$ \\begin{align} p(y^{} \\mid x^{}, x_{1:n}, y_{1:n}) \u0026amp; = \\int p(y^{} \\mid x^{}, \\theta) p(\\theta \\mid x_{1:n}, y_{1:n}) d\\theta \\ \u0026amp; = \\mathbb{E}{\\theta \\sim p(\\cdot \\mid x{1:n}, y_{1:n})} [p(y^{} \\mid x^{}, \\theta)]) \\ \\text{Using Variational Inf.}\u0026amp; \\approx \\mathbb{E}{{\\theta \\sim q(\\theta)}} [p(y^{} \\mid x^{}, \\theta)] \\\n\\text{Monte Carlo }\u0026amp; \\approx \\frac{1}{S} \\sum_{s = 1}^{S} p(y^{} \\mid x^{}, \\theta_{s}) \\end{align} $$ The variational is usually the approximation that is introducing the most errors.\nApproximating with Gaussians üü•+ Training Using the variational method, usually we parametrize with Gaussians. See Variational Inference. We usually use the ELBO to minimize the difference between the variational approximation and the true distribution.\n$$ \\log p(D) \\geq \\max_{q \\in \\mathcal{Q}} ELBO(q) = \\max_{q \\in \\mathcal{Q}} \\mathbb{E}_{q(\\theta)} [\\log p(D, \\theta) - \\log q(\\theta)] $$$$ \\begin{align} ELBO(q) \u0026= \\mathbb{E}_{q(\\theta)} [\\log p(D, \\theta) - \\log q(\\theta)] \\\\ \u0026= \\mathbb{E}_{\\varepsilon \\sim \\mathcal{N}(0, 1)} [\\log p(D, \\theta + \\sigma \\varepsilon)] - KL(q \\mid p) \\\\ \u0026 = \\mathbb{E}_{\\varepsilon \\sim \\mathcal{N}(0, 1)} [\\log p(D, \\theta + \\sigma \\varepsilon)] - \\frac{1}{2}\\log \\lvert \\Sigma \\rvert - \\frac{D}{2} \\log 2\\pi e \\end{align} $$This is known as Bayes by backprop (2015), and is parameterized with a diagonal covariance Gaussian.\nThis is used to learn the covariance matrix and mean of the variational family. After, we can do inference in the following manner:\nInference $$ \\begin{align} p(y^{*} \\mid x^{*}, x_{1:n}, y_{1:n})\u0026= \\int p(y^{*} \\mid x^{*}, \\theta) p(\\theta \\mid x_{1:n}, y_{1:n}) d\\theta \\\\ \u0026\\approx \\int p(y^{*} \\mid x^{*}, \\theta) q(\\theta) d\\theta \\\\ \u0026\\approx \\frac{1}{S} \\sum_{s = 1}^{S} p(y^{*} \\mid x^{*}, \\theta_{s}) \\\\ \u0026= \\frac{1}{S} \\sum_{s = 1}^{S} \\mathcal{N}(y^{*}; f(x^{*}, \\theta_{s}), \\exp(g(x^{*}, \\theta_{s}))) \\end{align} $$ Intuitively, variational inference in Bayesian neural networks can be interpreted as averaging the predictions of multiple neural networks drawn according to the variational posterior $q$\nUnpacking uncertainties $$ \\begin{align} \\text{Var}[y^{*} \\mid x^{*}, x_{1:n}, y_{1:n}] \u0026= \\underbrace{\\mathbb{E}_{q(\\theta)}[\\text{Var}[y^{*} \\mid x^{*}, \\theta]]}_{\\text{Aleatoric}} + \\underbrace{\\text{Var}_{q(\\theta)}[\\mathbb{E}[y^{*} \\mid x^{*}, \\theta]] }_{\\text{Epistemic}} \\\\ \u0026\\approx \\frac{1}{m} \\sum_{s = 1}^{m} \\exp(g(x^{*}, \\theta_{s})) + \\frac{1}{m - 1} \\sum_{s = 1}^{m} (\\mu(x^{*}, \\theta_{s}) - \\bar{\\mu})^{2} \\end{align} $$ Where $\\bar{\\mu} = \\frac{1}{m} \\sum_{s = 1}^{m} \\mu(x^{*}, \\theta_{s})$.\nBayes by Backprop üü® This section covers the idea of one quite influential paper (Blundell et al. 2015).\nImage from the paper.This is the whole idea introduced in this document, but for historical reasons, it is due to treat it here. One of the main innovations introduced is the use of a derivative friendly method to compute an approximation for the variational lower bound principle.\nIn this work, they propose a generalization of the reparametrization trick, the same one used for training variational autoencoders (see Autoencoders)\n$$ \\frac{\\partial}{\\partial \\theta} \\mathbb{E}_{q(\\mathbf{w}|\\theta)}[f(\\mathbf{w}, \\theta)] = \\mathbb{E}_{q(\\epsilon)} \\left[ \\frac{\\partial f}{\\partial \\mathbf{w}} \\frac{\\partial \\mathbf{w}}{\\partial \\theta} + \\frac{\\partial f}{\\partial \\theta} \\right]. $$$$ \\frac{\\partial}{\\partial \\mu} \\mathbb{E}_{q(\\mathbf{w}|\\theta)}[f(\\mathbf{w}, \\theta)] = \\mathbb{E}_{q(\\epsilon)} \\left[ \\frac{\\partial f}{\\partial \\mathbf{w}} 1 + \\frac{\\partial f}{\\partial \\mu} \\right]. $$$$ \\frac{\\partial}{\\partial \\sigma} \\mathbb{E}_{q(\\mathbf{w}|\\theta)}[f(\\mathbf{w}, \\theta)] = \\mathbb{E}_{q(\\epsilon)} \\left[ \\frac{\\partial f}{\\partial \\mathbf{w}}\\varepsilon + \\frac{\\partial f}{\\partial sigm} \\right]. $$ For the variance.\nDisadvantages of Bayes by Backprop üü®++ Increased Computation: BBB requires sampling from the posterior distribution of weights during both training and inference, which significantly increases computational overhead compared to standard neural networks. Slower Convergence: The need to approximate the posterior distribution can lead to slower convergence during training. Gradient Estimation: The gradients of the variational lower bound (ELBO) with respect to the parameters of the variational distribution can have high variance, making optimization challenging. Variational Approximation: BBB relies on variational inference to approximate the true posterior distribution. This approximation can be inaccurate, especially if the chosen variational family is not flexible enough to capture the true posterior. With Laplace Approximation $$ \\log p(\\mathcal{D}, \\theta) \\approx \\log p (\\mathcal{D}, \\hat{\\theta}) + \\frac{1}{2} (\\theta - \\hat{\\theta})^{T} H(\\theta - \\hat{\\theta}) $$$$ p(\\mathcal{D}) = p(\\mathcal{D}, \\hat{\\theta}) (2\\pi)^{D/2} \\lvert -H_{\\theta} \\rvert ^{-1/2} $$The problem is often the Hessian, which could be unstable, or difficult to approximate. For this reason usually we use low-rank matrices, diagonal matrices, or other approximations.\nDropout as Variational Inference Dropout and dropconnect can be seen as a special case of variational inference. It can been seen as if we are working with a probability distribution of different networks, which can be recalled as a special case of the one we have discussed above.\nThe Variational Family üü®\u0026ndash; $$ q(\\theta \\mid \\lambda) = \\prod_{j} q_{j}(\\theta_{j} \\mid \\lambda_{j}) $$ Where $q_{j}(\\theta \\mid \\lambda)) = p\\delta_{0}(\\theta_{j}) + (1 - p) \\delta_{\\lambda_{j}}(\\theta_{j})$ a mixture of Dirac deltas: with a certain probability $1- p$ we keep the weight, or set it to zero. Optimizing the network with dropout can be seen as optimizing the ELBO with respect of this variational family.\nInference with Dropout üü© One thing is using dropout during prediction to obtain uncertainty estimates. This is called Monte Carlo Dropout. The idea is very simple: keep the dropout during inference and sample from the network multiple times. The average of the predictions is the final prediction, and the variance is the uncertainty estimate.\nDeep Ensembles The Idea We train $m$ different models from a bootstrapped dataset and then just average their prediction. This is the main idea of doing Ensembles.\nWe can also extend the probabilistic case to classification. In this case we just add a noise in the softmax layer to have some variability.\nInference With this method we train different models on different data (maybe bootstrapped data, see Cross Validation and Model Selection). Then we just average the predictions of the different models. This is a very simple way to obtain uncertainty estimates, which allows to approximate the bayesian inference method.\n$$ \\begin{align} p(y^{*} \\mid x^{*}, x_{1:n}, y_{1:n}) \u0026= \\int p(y^{*} \\mid x^{*}, \\theta) p(\\theta \\mid x_{1:n}, y_{1:n}) d\\theta \\\\ \u0026= \\mathop{\\mathbb{E}}_{\\theta \\sim p(\\cdot \\mid x_{1:n}, y_{1:n})} [p(y^{*} \\mid x^{*}, \\theta)] \\\\ \u0026\\approx \\frac{1}{m} \\sum_{s = 1}^{m} p(y^{*} \\mid x^{*}, \\theta_{s}) \\end{align} $$Markov Chain Monte Carlo The MCMC idea We would like here to sample from the posterior distribution of the weights using MCMC (somewhat similar to the SGLD method), and then use the samples to make predictions. This is a very general method, but it\u0026rsquo;s computationally expensive.\nThese methods explained in Monte Carlo Methods are exactly the same here, you can use these to sample from the posterior and then use the same tricks in #Inference (remember the Ergodic theorem) and #Unpacking uncertainties.\nOften methods like SGLD or SG-HMC are used as they use stochastic gradients of a loss function, which can be obtained using automatic differentiation.\nThe key idea is just to sample $m$ values of the parameters and then use those values to make predictions.\nKey Challenges üü•++ There are two main challenges with these methods:\nStoring the weights (usually to expensive). One way to circumvent this problem is to keep some snapshots or keeping some running averages (see next section). One idea is subsampling: we store some intermediate weights or predictions and use those for the final inference. Burn in period is too costly. Running averages $$ \\mu \\leftarrow \\frac{1}{T + 1} (T \\mu + \\theta) $$$$ \\sigma^{2} \\leftarrow \\frac{1}{T + 1} (T \\sigma^{2} + \\theta^{T}\\theta) $$Outlook: Other methods Stein Variational Gradient Descent $$ \\theta_{i} \\leftarrow \\theta_{i} + \\frac{\\epsilon}{n} \\sum_{j = 1}^{n} k(\\theta_{i}, \\theta_{j}) (\\nabla_{\\theta_{j}} \\log p(\\theta_{j} \\mid \\mathcal{D}) - \\nabla_{\\theta_{j}}k(\\theta_{j}, \\theta_{i})) $$ I have no idea why we use this update rule, but it should be minimizing a certain divergence between the two distributions. TODO: understand this part.\nCalibration What is Calibration? üü© Well calibrated models have a similar accuracy to the confidence of their predictions. This is a very important property for many applications, especially in medical fields. For example, if a model is well calibrated, if it is secure on a prediction, it can leave the burden from the doctors, who would just manually check the hard ones.\nExpected Calibration Error üü©\u0026ndash; $$ \\mathbb{E}_{p \\sim \\hat{P}} [\\lvert \\mathbb{P}(\\hat{Y} = Y \\mid \\hat{P} = p) - p \\rvert ] = 0 $$$$ \\mathbb{P}(\\hat{Y} = y \\mid \\hat{P} = p) = p $$$$ \\text{acc}(b) = \\frac{1}{N_{b}} \\sum_{i \\in b} \\mathbb{I}(\\hat{Y}_{i} = Y_{i}) $$$$ \\text{conf}(b) = \\frac{1}{N_{b}} \\sum_{i \\in b} \\hat{P}_{i} $$$$ \\text{ECE} = \\sum_{b = 1}^{m} \\frac{N_{b}}{N} \\lvert \\text{acc}(b) - \\text{conf}(b) \\rvert $$$$ \\text{MCE} = \\max_{b} \\lvert \\text{acc}(b) - \\text{conf}(b) \\rvert $$Reliability Diagrams üü© We group the predictions of the model into bins based on their confidence. Then we plot the average confidence score against the accuracy of the model in that bin. If the model is well calibrated, this plot should be a diagonal line.\nTechniques for improving calibration Temperature Scaling There are many techniques to improve calibration. One of the most used is temperature scaling. This is just a scaling of the logits of the model.\nPlatt Scaling Another technique is Platt scaling. This is a logistic regression on the model\u0026rsquo;s output logits, interpretable as confidence scores.\nReferences [1] Blundell et al. ‚ÄúWeight Uncertainty in Neural Networks‚Äù 2015\n[2] Maddox et al. ‚ÄúA Simple Baseline for Bayesian Uncertainty in Deep Learning‚Äù 2019\n","permalink":"https://flecart.github.io/notes/bayesian-neural-networks/","summary":"\u003ch3 id=\"robbins-moro-algorithm\"\u003eRobbins-Moro Algorithm\u003c/h3\u003e\n\u003ch4 id=\"the-algorithm\"\u003eThe Algorithm\u003c/h4\u003e\n$$\nw_{n+1} = w_{n} - \\alpha_{n} \\Delta w_{n}\n$$\u003cp\u003eFor example with $\\alpha_{0} \u003e \\alpha_{1} \u003e \\dots \u003e \\alpha_{n} \\dots$, and $\\alpha_{t} = \\frac{1}{t}$ they satisfy the condition (in practice we use a constant $\\alpha$, but we lose the convergence guarantee by Robbins Moro).\nMore generally, the Robbins-Moro conditions re:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e$\\sum_{n} \\alpha_{n} = \\infty$\u003c/li\u003e\n\u003cli\u003e$\\sum_{n} \\alpha_{n}^{2} \u003c \\infty$\nThen the algorithm is guaranteed to converge to the best answer.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eOne nice thing about this, is that we \u003cstrong\u003edon\u0026rsquo;t need gradients\u003c/strong\u003e.\nBut often we use gradient versions (stochastic gradient descent and similar), using auto-grad, see \u003ca href=\"/notes/backpropagation/\"\u003eBackpropagation\u003c/a\u003e.\nBut learning with gradients brings some drawbacks:\u003c/p\u003e","title":"Bayesian neural networks"},{"content":"While Active Learning looks for the most informative points to recover a true underlying function, Bayesian Optimization is just interested to find the maximum of that function. In Bayesian Optimization, we ask for the best way to find sequentially a set of points $x_{1}, \\dots, x_{n}$ to find $\\max_{x \\in \\mathcal{X}} f(x)$ for a certain unknown function $f$. This is what the whole thing is about.\nDefinitions First we will introduce some useful definitions in this context. These were also somewhat introduced in N-Bandit Problem, which is one of the classical optimization problems we can find in the literature.\nWe suppose there is an underlying function $f$, but we are only observing some noised estimates $y = f + \\varepsilon$ where $\\varepsilon$ is usually modeled as Gaussian noise.\nAt each time step we can choose some $x_{t}$, then the reward is $y_{t} = f(x_{t}) + \\varepsilon_{t}$. We would like to maximize the cumulative reward $\\sum_{t=1}^{n} y_{t}$.\nRegret üü© $$ R_{n} = \\sum_{t=1}^{n} f(x^{*}) - f(x_{t}) $$$$ \\lim_{n \\to \\infty} \\frac{R_{n}}{n} = 0 $$Intuitively, it says that if we explore enough, then we will always get the best possible choice.\nRegret and maximum of the function $$ \\lim_{ n \\to \\infty } f(x_{n}) = \\max_{x} f(x) \\iff \\lim_{ n \\to \\infty } \\frac{R_{n}}{n} = 0 $$Proof:\nUsing Ces√†ro Mean we quickly verify the $\\implies$ direction. For the inverse we see the following:\n$$ \\begin{align} \\lim_{ n \\to \\infty } \\frac{R_{n}}{n} \u0026= \\lim_{ n \\to \\infty } \\frac{\\left( \\sum_{t = 1}^{n} \\max_{x} f(x) - f(x_{t}) \\right)}{n} \\\\ \u0026= \\max_{x}f(x) - \\lim_{ n \\to \\infty } \\frac{1}{n} \\sum_{t = 1}^{n}f(x_{t}) \\\\ \u0026\\implies \\lim_{ n \\to \\infty } \\frac{1}{n} \\sum_{t = 1}^{n}f(x_{t}) = \\max_{x} f(x) \\end{align} $$ Then it follows from the other direction of the Ces√†ro mean.\nExploration and Exploitation üü© This setting naturally leads to the exploration-exploitation tradeoff. We can either choose to explore new regions of the input space, or exploit the regions we have already visited. It\u0026rsquo;s easy to observe that both greedy strategies that only exploit the current best guess and strategies that only explore new regions are not optimal, meaning they will yield not sub-linear regrets.\nOptimization Techniques A standard Idea üü© In the rest of the section, we will assume that the $f$ function is a Gaussian Process. Then one greedy way to solve this optimization problem is the following algorithm\nInitialize a $f \\sim GP(\\mu_{0}, k_{0})$. For $t = 1, \\dots, n$ do Find the point $x_{t} = \\arg\\max_{x \\in \\mathcal{X}} f(x)$. Observe the reward $y_{t} = f(x_{t}) + \\varepsilon_{t}$. Update the GP with the new observation. On the need of Calibrated Models üü© The most important of the following models is the GP-UCB acquisition function that heavily relies on the calibration assumption. Recall Bayesian neural networks for a refresh on calibration. Intuitively, only in the case of calibrated models, the confidence bounds given by the GP relates to the accuracy of the prediction. If a model is not calibrated, the confidence doesn\u0026rsquo;t tell you anything on the accuracy of the prediction.\n$$ \\forall t \\geq 1, \\forall x \\in \\mathcal{X} : f^{*}(x) \\in \\mathcal{C}_{t}(x) = [\\mu_{t}(x) - \\beta_{t}\\sigma_{t}(x), \\mu_{t}(x) + \\beta_{t}\\sigma_{t}(x)] $$ Which is the confidence interval defined by the GP-UCB algorithm.\nBound over confidence intervals $$ \\beta_{t}(\\delta) \\in \\mathcal{O}(\\sqrt{ \\log(\\lvert \\mathcal{X} \\rvert t / \\delta ) }) $$Entropy Search TODO:\nThis method expands the d-optimality criteria, by looking for the point that gives the maximal information on the point we are looking for. There is a chicken and egg problem here, as the point itself.\nGP-UCB The idea Image taken from slides of the PAI course ETH 2024. Optimism in the face of uncertainty\nWe just want to pick the point that maximizes our upper confidence bound in the posterior of the Gaussian Processes. The green region are the possible regions that we would like to sample from, as their upper confidence is higher than our lower bound. This idea is recurring in this setting.\nIf the model is well calibrated, then the uncertainty regions are coherent with what actually returns the underlying function. This motivates why we can safely ignore the zones on our input where the maximum is less than the minimum value of the variance. We are sure, due to calibration, that those zones do not contain our maximum with high confidence.\nUCB Picking principle üü© $$ x_{t} = \\arg\\max_{x \\in D} \\mu_{t - 1}(x) + \\beta_{t - 1} \\sigma_{t - 1}(x) $$ Where $\\mu_{t - 1}(x)$ is the mean of the GP at the point $x$ and $\\sigma_{t - 1}(x)$ is the standard deviation. $\\beta_{t - 1}$ is a parameter that we can tune to have more or less exploration. This should select the point that maximizes the upper confidence bound in the GP.\nWe observe that if $\\forall t,\\beta_{t - 1} = 0$ then the algorithm is purely exploitative, while if $\\beta_{t - 1} = \\infty$ then the algorithm is purely esplorative, and it\u0026rsquo;s equivalent to uncertainty sampling presented in Active Learning.\nThe point can be found using standard one dimensional optimization techniques (e.g. random sampling or similars).\nConvergence Bound on GP-UCP üü®\u0026ndash; $$ \\frac{1}{T} \\sum_{t = 1}^{T} (f(x^{*}) - f(x_{t})) = \\mathcal{O}\\left( \\sqrt{\\frac{\\gamma_{T}}{T}} \\right) $$ The maximum information gain determines the regret, often indicated as $\\gamma_{T}$, sometimes as $\\max_{S \\leq T} I(f; y_{S})$. This sets the rate at which we get information. Due to submodularity of mutual information we can show that $\\gamma_{T}$ can at most grow linearly with $T$.\nI have no idea why this is true. These are the bounds for different kernels in the GP The nice thing is that with all these kernels, we have guarantees that the regret is sub-linear, so we get the best possible solution.\n$$ r_{t} \\leq 2 \\beta_{t} \\sigma_{t}(x_{t}) $$ And using the GP informational result from Active Learning we have: $$ \\begin{align} \\frac{1}{T} R^{2}{T} \u0026amp;\\leq \\sum{t = 1}^{T}r_{t}^{2} \\text{ Cauchy-Schwarz} \\ \u0026amp;\\leq 4 \\beta_{t}^{2} \\sum_{t = 1}^{T} \\sigma_{t}^{2}(x_{t}) \\ \u0026amp;= 4 \\sigma_{n}^{2} \\beta_{t}^{2} \\sum_{t = 1}^{T} \\frac{\\sigma^{2}{t}(x{t})}{\\sigma^{2}{n}} \\ \u0026amp;\\leq 4C \\sigma{n}^{2} \\beta_{t}^{2} \\sum_{t = 1}^{T} \\log \\left( 1 + \\frac{\\sigma^{2}{t}(x{t})}{\\sigma^{2}{n}} \\right) \\ \u0026amp;= 4C \\sigma{n}^{2} \\beta_{t}^{2} I(f_{T}; y_{T}) \\in \\mathcal{O}(\\beta^{2}{T}\\gamma{T})\n\\end{align} $$\nGrowth rate of information gain üü®- There is a clean intuition for the following graph: if the function is continuous, smooth so to say, then knowing the value of one point gives lots of insights to the value of the next point. Which means we need fewer point to get a good estimate of the function (this is why the slope of the function is low). If we have quite independent samples, then we need more points to get a good estimate of the function. This is why it has a linear growth rate: every point gives you about the same information. Note that this happens only for white noise, so probably it is not a much interesting case.\nChoosing the point Usually the acquisition function is non-convex, so we need some methods to compute that maximum.\nLow dimensionality: we can use lipschitz optimization. High dimensionality: we can use gradient descent. Probability Improvement The PI Idea üü© \u0026ndash; $$ I_{t}(x) = (f(x) - \\hat{f}_{t})_{+} $$ Where $\\hat{f}$ is the current maximum. Then the point that is going to be picked is the point that maximizes the probability of having an improvement:\n$$ x_{t + 1} = \\arg \\max_{x \\in \\mathcal{X}} \\mathbb{P}(f(x) \u003e \\hat{f}_{t} \\mid x_{1:t}, y_{1:t}) = \\arg \\max_{x \\in \\mathcal{X}} \\Phi \\left( \\frac{\\mu_{t}(x) - \\hat{f}_{t}}{\\sigma_{t}(x)} \\right) $$We observe that this algorithm is a little biased towards exploration as it prefers large means with low variances.\nExpected Improvement $$ x_{t + 1} \\arg \\max_{x \\in \\mathcal{X}}\\mathop{\\mathbb{E}}[I_{t}(x) \\mid x_{1:t}, y_{1:t}] $$ It can be proven that Expected Improvement has the same regret bound as UCB. One drawback of this method, is that the optimization objective is usually flat, which makes it more difficult to optimize.\nThompson Sampling Thompson Sampling Method üü©\u0026ndash; $$ f_{t + 1} \\sim p( \\cdot \\mid x_{1:t}, y_{1:t}) $$ And the find the new point as the maximum of this function $x_{t + 1} = \\arg\\max_{x \\in \\mathcal{X}} f_{t + 1}(x)$. In this case, we are leveraging the randomness of $f$ to trade between exploitation and exploration. Similar bounds to UCB can be established also for Thompson.\nInformation Directed Sampling Regret Information Ratio üü® $$ \\Psi_{t}(x) = \\frac{\\Delta(x)^{2}}{I_{t}(x)} $$ Where $\\Delta(x) = \\max_{x'}f^{*}(x') - f^{*}(x)$ and $I_{t}$ is a function that captures the information gain (doesn\u0026rsquo;t need to be the same as the one for probability improvement).\nRegret Bound for ID üü• $$ R_{T} \\leq \\sqrt{\\sum_{t = 1}^{ T}I_{t - 1}(x_{t}) \\cdot \\sum_{t = 1}^{T} \\Psi_{t - 1}(x_{t}) } $$ID Algorithm üü• $$ \\hat{\\Delta}_{t}(x) = \\max_{x'\\in \\mathcal{X}} u_{t}(x') - l_{t}(x) $$ Where $u$ and $l$ are respectively, the upper and lower bound for a calibrated model.\n$$ x_{t + 1} = \\arg \\min _{x \\in \\mathcal{X}} \\left( \\frac{\\hat{\\Delta}_{t}(x)^{2}}{I_{t}(x)} \\right) $$A common problem üü®++ One common problem with these methods is the kernel. How could we choose the correct kernel and its hyper-parameters? We are using these kernels to select the data itself, which could be quite biased; phrased in another manner: we are dependently selecting points based on the model (which is a good thing, but also the main drawback!) Another problem is getting calibrated models in this setting where you continuously select points. And often, datasets in this domain are quite small.\nCommon approaches to this problem are:\nImposing priors on the kernel parameters. Occasionally selecting random points. ","permalink":"https://flecart.github.io/notes/bayesian-optimization/","summary":"\u003cp\u003eWhile \u003ca href=\"/notes/active-learning/\"\u003eActive Learning\u003c/a\u003e looks for the most informative points to recover a \u003cem\u003etrue\u003c/em\u003e underlying function, Bayesian Optimization is just interested to find the maximum of that function.\nIn Bayesian Optimization, we ask for the best way to find \u003cem\u003esequentially\u003c/em\u003e a set of points $x_{1}, \\dots, x_{n}$ to find $\\max_{x \\in \\mathcal{X}} f(x)$ for a certain unknown function $f$. This is what the whole thing is about.\u003c/p\u003e\n\u003ch3 id=\"definitions\"\u003eDefinitions\u003c/h3\u003e\n\u003cp\u003eFirst we will introduce some useful definitions in this context. These were also somewhat introduced in N-Bandit Problem, which is one of the classical optimization problems we can find in the literature.\u003c/p\u003e","title":"Bayesian Optimization"},{"content":"The beta distribution The beta distribution is a powerful tool for modeling probabilities and proportions between 0 and 1. Here\u0026rsquo;s a structured intuition to grasp its essence:\nCore Concept The beta distribution, defined on $[0, 1]$, is parameterized by two shape parameters: Œ± (alpha) and Œ≤ (beta). These parameters dictate the distribution‚Äôs shape, allowing it to flexibly represent beliefs about probabilities, rates, or proportions.\nKey Intuitions a. \u0026ldquo;Pseudo-Counts\u0026rdquo; Interpretation Œ± acts like \u0026ldquo;successes\u0026rdquo; and Œ≤ like \u0026ldquo;failures\u0026rdquo; in a hypothetical experiment. Example: If you use Beta(5, 3), it‚Äôs as if you‚Äôve observed 5 successes and 3 failures before seeing actual data. After observing x real successes and y real failures, the posterior becomes Beta(Œ±+x, Œ≤+y). This makes beta the conjugate prior for the binomial distribution (bernoulli process). b. Shape Flexibility Uniform distribution: When Œ± = Œ≤ = 1, all values in [0, 1] are equally likely. Bell-shaped: When Œ±, Œ≤ \u0026gt; 1, the distribution peaks at mode = (Œ±-1)/(Œ±+Œ≤-2). Symmetric if Œ± = Œ≤ (e.g., Beta(5, 5) is centered at 0.5). U-shaped: When Œ±, Œ≤ \u0026lt; 1, density spikes at 0 and 1 (useful for modeling polarization, meaning we believe the model to only produce values at 0 or 1, not in the middle.). Skewed: If Œ± \u0026gt; Œ≤, skewed toward 1; if Œ≤ \u0026gt; Œ±, skewed toward 0. c. Moments Mean: $Œ±/(Œ±+Œ≤)$ ‚Äì your \u0026ldquo;expected\u0026rdquo; probability of success. Variance: $Œ±Œ≤ / [(Œ±+Œ≤)¬≤(Œ±+Œ≤+1)]$ ‚Äì decreases as Œ± and Œ≤ grow (more confidence). $$ \\text{Mode} = \\frac{\\alpha - 1}{\\alpha + \\beta - 2} $$The mathematical model $$ \\text{Beta} (x \\mid a, b) = \\frac{1}{B(a, b)} \\cdot x^{a -1 }(1 - x)^{b - 1} $$ Where $B(a, b) = \\Gamma(a) \\Gamma(b) / \\Gamma( + b)$ And $\\Gamma(t) = \\int_{0}^{\\infty}e^{-x}x^{t - 1} \\, dx$\nVisualization \u0026amp; Parameter Tuning Mean and Variance Control:\nTo design a beta distribution with mean Œº and variance œÉ¬≤, solve: Œ± = Œº(Œº(1‚àíŒº)/œÉ¬≤ ‚àí 1) Œ≤ = (1‚àíŒº)(Œº(1‚àíŒº)/œÉ¬≤ ‚àí 1)\nExample: For Œº = 0.5, œÉ¬≤ = 0.01, use Beta(12, 12). Dirichlet Distribution The Dirichlet Distribution is a generalization of the Beta distribution.\nA mathematical definition $$ \\text{Dir}(\\rho_{1}, \\dots \\rho_{k};\\alpha_{1}, \\dots, \\alpha_{k}) = \\frac{1}{B(\\alpha)} \\prod_{i = 1}^{k} \\rho_{i}^{\\alpha_{i} - 1} $$$$ \\Gamma(x) = \\int_{0}^{\\infty} t^{x - 1} e^{-t} dt $$ And it is has the nice property of $\\Gamma(x + 1) = x \\Gamma(x)$ and $\\Gamma(1) = 1$, this is why we can see this distribution as a generalization of the factorial. The important thing to note about this distribution is that it is the conjugate prior of the multinomial distribution. See here. So, if we have a multinomial distribution with a Dirichlet prior, then the posterior is also a Dirichlet distribution. This allows us to sort of update our prior with the data we have, which is a nice property for bayesian inference. You can learn more about prior updates in Bayesian Linear Regression.\nDP effectively defines a conjugate prior for arbitrary measurable spaces.\nThe following sections have content brought to you by (Murphy 2012).\nComputing the posterior Recall the multinomial distribution is $p(\\mathcal{D}|\\theta) = \\prod_{k=1}^K \\theta_k^{N_k}$\nThen we see that the Dirichlet is the conjugate prior for this distribution, so the posterior is: $$ % Posterior proportionality \\begin{align} p(\\theta|\\mathcal{D}) \u0026amp;\\propto p(\\mathcal{D}|\\theta)p(\\theta) \\\n% Posterior calculation \u0026amp;\\propto \\prod_{k=1}^K \\theta_k^{N_k} \\theta_k^{\\alpha_k-1} = \\prod_{k=1}^K \\theta_k^{\\alpha_k+N_k-1} \\\n\u0026amp;= \\text{Dir}(\\theta|\\alpha_1 + N_1,\\ldots,\\alpha_K + N_K) \\end{align} $$ Which is the correct Posterior.\nThe Mode of the distribution Using Lagrange Multipliers, we can find that the mode of the Dirichlet distribution is:\n$$ \\hat{\\theta}_{k} = \\frac{N_{k}+\\alpha_{k} - 1}{N+\\sum_{i=1}^{K} \\alpha_{i} - K} $$ Where $K$ is the number of clusters, $N$ is the number of new samples after running the multinomial process. We notice that its form is quite nice when we set the uniform prior $\\forall k \\in K, \\alpha_{k} = 1$.\nThe Posterior predictive $$ \\begin{align} p(X = j|\\mathcal{D}) \u0026amp;= \\int p(X = j|\\theta)p(\\theta|\\mathcal{D})d\\theta \\\n\u0026amp;= \\int p(X = j|\\theta_j)\\left[\\int p(\\theta_{-j},\\theta_j|\\mathcal{D})d\\theta_{-j}\\right] d\\theta_j \\\n\u0026amp;= \\int \\theta_jp(\\theta_j|\\mathcal{D})d\\theta_j = \\mathbb{E}[\\theta_j|\\mathcal{D}] = \\frac{\\alpha_j + N_j}{\\sum_k(\\alpha_k + N_k)} = \\frac{\\alpha_j + N_j}{\\sum_{k}\\alpha_{k} + N}\n\\end{align} $$ We notice that this is a form of Bayesian Smoothing.\nReferences [1] Murphy ‚ÄúMachine Learning: A Probabilistic Perspective‚Äù 2012\n","permalink":"https://flecart.github.io/notes/beta-and-dirichlet-distributions/","summary":"\u003ch1 id=\"the-beta-distribution\"\u003eThe beta distribution\u003c/h1\u003e\n\u003cp\u003eThe beta distribution is a powerful tool for modeling probabilities and proportions between 0 and 1. Here\u0026rsquo;s a structured intuition to grasp its essence:\u003c/p\u003e\n\u003ch3 id=\"core-concept\"\u003eCore Concept\u003c/h3\u003e\n\u003cp\u003eThe beta distribution, defined on $[0, 1]$, is parameterized by two shape parameters: \u003cstrong\u003eŒ± (alpha)\u003c/strong\u003e and \u003cstrong\u003eŒ≤ (beta)\u003c/strong\u003e. These parameters dictate the distribution‚Äôs shape, allowing it to flexibly represent beliefs about probabilities, rates, or proportions.\u003c/p\u003e\n\u003ch3 id=\"key-intuitions\"\u003eKey Intuitions\u003c/h3\u003e\n\u003ch4 id=\"a-pseudo-counts-interpretation\"\u003e\u003cstrong\u003ea. \u0026ldquo;Pseudo-Counts\u0026rdquo; Interpretation\u003c/strong\u003e\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eŒ±\u003c/strong\u003e acts like \u0026ldquo;successes\u0026rdquo; and \u003cstrong\u003eŒ≤\u003c/strong\u003e like \u0026ldquo;failures\u0026rdquo; in a hypothetical experiment.\n\u003cul\u003e\n\u003cli\u003eExample: If you use \u003cstrong\u003eBeta(5, 3)\u003c/strong\u003e, it‚Äôs as if you‚Äôve observed \u003cstrong\u003e5 successes\u003c/strong\u003e and \u003cstrong\u003e3 failures\u003c/strong\u003e \u003cem\u003ebefore seeing actual data\u003c/em\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eAfter observing \u003cstrong\u003ex real successes\u003c/strong\u003e and \u003cstrong\u003ey real failures\u003c/strong\u003e, the posterior becomes \u003cstrong\u003eBeta(Œ±+x, Œ≤+y)\u003c/strong\u003e. This makes beta the \u003cstrong\u003econjugate prior\u003c/strong\u003e for the binomial distribution (bernoulli process).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"b-shape-flexibility\"\u003e\u003cstrong\u003eb. Shape Flexibility\u003c/strong\u003e\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eUniform distribution\u003c/strong\u003e: When \u003cstrong\u003eŒ± = Œ≤ = 1\u003c/strong\u003e, all values in [0, 1] are equally likely.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBell-shaped\u003c/strong\u003e: When \u003cstrong\u003eŒ±, Œ≤ \u0026gt; 1\u003c/strong\u003e, the distribution peaks at \u003cstrong\u003emode = (Œ±-1)/(Œ±+Œ≤-2)\u003c/strong\u003e.\n\u003cul\u003e\n\u003cli\u003eSymmetric if \u003cstrong\u003eŒ± = Œ≤\u003c/strong\u003e (e.g., \u003cstrong\u003eBeta(5, 5)\u003c/strong\u003e is centered at 0.5).\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eU-shaped\u003c/strong\u003e: When \u003cstrong\u003eŒ±, Œ≤ \u0026lt; 1\u003c/strong\u003e, density spikes at 0 and 1 (useful for modeling polarization, meaning we believe the model to only produce values at 0 or 1, not in the middle.).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSkewed\u003c/strong\u003e: If \u003cstrong\u003eŒ± \u0026gt; Œ≤\u003c/strong\u003e, skewed toward 1; if \u003cstrong\u003eŒ≤ \u0026gt; Œ±\u003c/strong\u003e, skewed toward 0.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"c-moments\"\u003e\u003cstrong\u003ec. Moments\u003c/strong\u003e\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMean\u003c/strong\u003e: $Œ±/(Œ±+Œ≤)$ ‚Äì your \u0026ldquo;expected\u0026rdquo; probability of success.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVariance\u003c/strong\u003e: $Œ±Œ≤ / [(Œ±+Œ≤)¬≤(Œ±+Œ≤+1)]$ ‚Äì decreases as \u003cstrong\u003eŒ±\u003c/strong\u003e and \u003cstrong\u003eŒ≤\u003c/strong\u003e grow (more confidence).\u003c/li\u003e\n\u003c/ul\u003e\n$$\n\\text{Mode} = \\frac{\\alpha - 1}{\\alpha + \\beta - 2}\n$$\u003ch3 id=\"the-mathematical-model\"\u003eThe mathematical model\u003c/h3\u003e\n$$\n\\text{Beta} (x \\mid a, b) = \\frac{1}{B(a, b)} \\cdot x^{a -1 }(1 - x)^{b - 1}\n$$\u003cp\u003e\nWhere $B(a, b) = \\Gamma(a) \\Gamma(b) / \\Gamma( + b)$\nAnd $\\Gamma(t) = \\int_{0}^{\\infty}e^{-x}x^{t - 1} \\, dx$\u003c/p\u003e","title":"Beta and Dirichlet Distributions"},{"content":"This note should be considered deprecated. There is not much about Bias Variance Trade-off, and its quite random and old. For a correct derivation for this, you should consider looking at Linear Regression methods.\nIntroduction √à una cosa ormai risaputa che c\u0026rsquo;√® una sorta di trade-off fra la varianza e il bias per una certo modello. Aumentare la varianza del modello certamente ci permetter√† di avere un modello che abbia un errore di training molto basso, per√≤ appena vede dei dati nuovi non sar√† in grado di generalizzare correttamente. Dall\u0026rsquo;altra parte avere un bias alto significa avere un modello eccessivamente semplice, poco flessibile, che comunque allenato non riesce ad avere una grande accuratezza n√© in fase di allenamento, n√© di in fase di validazione o di test.\nMathematical decomposition $$ \\mathcal{L}(\\theta) = \\mathbb{E}_{(x, y) \\sim \\mathcal{D}} [(y - h_{\\theta}(x))^{2}] $$ Assumiamo che in $y$ ci sia presente del rumore causato dalla misurazione, e che la famiglia di funzioni descritta da $h$ riesca a modellare la distribuzione reale, questo ci motiva a descrivere $y = h_{\\theta^{*}} + \\varepsilon$ dove $\\varepsilon$ √® l\u0026rsquo;errore intrinseco data dalla misurazione e $\\theta^{*}$ √® la parametrizzazione migliore esistente.\nAllora abbiamo: $$ MSE(x) = \\mathbb{E}[(y - h_{\\theta}(x))^{2}] = \\mathbb{E}[(h_{\\theta^{*} }+ \\varepsilon - h_{\\theta}(x))^{2}] \\mathbb{E}[\\varepsilon^{2}] + \\mathbb{E}[(h_{\\theta^{*}}(x) - h_{\\theta}(x))^{2}] $$\n$$ MSE(x) = \\sigma^{2} + \\text{ bias}^{2} + \\text{ variance} $$ Dove $\\text{ bias} = h_{\\theta^{*}}(x) - h_{avg}(x)$ e la varianza uguale ad altro.\nDall\u0026rsquo;espressione matematica, deriviamo che anche nel caso in cui riusciamo ad eliminare del tutto la varianza e il bias, rimarrebbe l\u0026rsquo;errore irriducibile di cui abbiamo parlato in Introduction to statistical learning.\nConsiderazioni generali Questo trade-off √® nato principalmente nell\u0026rsquo;analisi teorica dei modelli, per√≤ √® bene tenere in mente la presenza di ci√≤ anche per i modelli reali. Non possiamo calcolare esplicitamente il MSE, per√≤ ci dovrebbe essere. Questa √® l\u0026rsquo;osservazione principale per asserire che non sempre il modelli pi√π complicato √® la migliore, abbiamo il no-free-lunch theorem!\nStatistical learning framework Introduction to the problem We will introduce the most common statistical learning framework. There will be a lot of new words to learn for this setting. We will have\nA classifier $h : \\mathcal{ X} \\to \\left\\{ 0, 1 \\right\\}$ mapping our data to a label, taken from a set $\\mathcal{H}$ of all possible hypothesis. Then pairs $(x, y)$ which are training examples and our dataset. A dataset $S_{in} = \\left( (x_{1}, y_{1}), \\dots, (x_{m}, y_{m}) \\right)$ our learning algorithm will be identified as an $\\mathcal{A} : \\text{ training sequence } \\to \\text{ classifier }$. So our training algorithm will output a classifier, which we call it in this manner: $h = A(S_{in})$ and we would like this to be correct, which means that $h(x) = y$. for most of our examples. We will briefly introduce also a simple error measure for this theory. There will be mainly two approaches, one based on statistics the other one based on game theory. We will briefly touch both of them. The statistical approach has been mainly explored by the famous Vapnik, then explored by Valiant. We point to (Shalev-Shwartz \u0026amp; Ben-David 2014) as a good resource for the statistical learning approach. $$ l_{D}(h) = P(h(X) \\not = Y) $$ Which is just the probability that our classifier is wrong.\nWe call the realizable case this $\\inf_{h \\in \\mathcal{H}} l_{D}(h) = 0$ Sometimes is interesting to try to characterize the expected loss, i.e. the value $\\mathbb{E}_{A}[l_{D}(A(S_{m}))]$. We define the optimal risk to be $\\inf_{h \\in \\mathcal{H}} l_{D}(h)$.\nWe define the excess risk to be $E_{m} (A, \\mathcal{H}) = \\sup_{D} (\\mathbb{E}\\left[ l_{D} (A(S_{m}))\\right] - \\inf_{h \\in \\mathcal{H}} l_{D}(h))$ We would like to minimize this, because this is the worst case scenario for a certain algorithm $A$. We say that the set of hypothesis $\\mathcal{H}$ is learnable if $E_{m}(\\mathcal{H}) = \\inf_{A} E_{m}(A, \\mathcal{H}) \\to 0$. as $m \\to \\infty$ (i think $m$ is number of training cases??)\nWe call the empirical risk minimizer to be $\\text{ erm}_{\\mathcal{H}} (S)$ to be classifier $\\mathcal{H}$ that minimizes classification mistakes on $S$. Now that we have these definitions we can ask some questions.\nIs $\\mathcal{H}$ learnable? How can we minimize the excess risk? how can we learn $\\mathcal{H}$ fast? Learnability We now try to further define the problem\nReferences [1] Shalev-Shwartz \u0026amp; Ben-David ‚ÄúUnderstanding Machine Learning: From Theory to Algorithms‚Äù Cambridge University Press 2014\n","permalink":"https://flecart.github.io/notes/bias-variance-trade-off/","summary":"\u003cp\u003eThis note should be considered deprecated.\nThere is not much about Bias Variance Trade-off, and its quite random and old. For a correct derivation for this, you should consider looking at \u003ca href=\"/notes/linear-regression-methods/\"\u003eLinear Regression methods\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e√à una cosa ormai risaputa che c\u0026rsquo;√® una sorta di trade-off fra la varianza e il bias per una certo modello. Aumentare la varianza del modello certamente ci permetter√† di avere un modello che abbia un errore di training molto basso, per√≤ appena vede dei dati nuovi non sar√† in grado di generalizzare correttamente.\nDall\u0026rsquo;altra parte avere un bias alto significa avere un modello eccessivamente semplice, poco flessibile, che comunque allenato non riesce ad avere una grande accuratezza n√© in fase di allenamento, n√© di in fase di validazione o di test.\u003c/p\u003e","title":"Bias Variance Trade-off"},{"content":"Utilizzano blocchi per cifra invece che stream generators. $n$ bits in input and $m$ bits in output generally a key is expanded into multiple keys, one for each rounds, and applied to a round function that iterates on the $m$.\nDES 56 bit 3DES 56*3 bit di chiave AES che pu√≤ andare a 128, 196 o 256 Solitamente i stream ciphers studiati in OTP and Stream Ciphers sono pi√π veloci. Cipher Speed MB/sec RC4 126 Salsa20 643 Sosemanuk 727 AES 13 3DES 109 Data Encryption Standard - 1974 da IBM su commissione di NSA (Horst Feistel designed Lucifer at IBM in early 1970) - 1976 DES is federal standard with key-len 56 bits and block-len 64 bits. in quel periodo era solamente fatta dalla intelligence, non c‚Äôera bisogno di comunicazioni per il pubblico in quel periodo.\n1977 - 1998 questo era lo standard per gli stati uniti. best studied cipher in the world! Oggi insicuro, esiste una sua variante 3DES che √® pi√π sicura, ma comunque rotto 1997 DES broken by brute force. 2000 AES replaces DES. C\u0026rsquo;√® una step di **creazione delle chiavi\nFeistel network ##### Definizione Feistel üü© Definiamo una funzione di Feistel $f(L^{i - 1}, R^{i - 1}, K^{i}) \\to L^{i}, R^{i}$ la seguente: Uno state $u^{i}$ √® diviso in due parti, che vengono cifrati in questo modo: $$\n\\begin{cases} L^{i} = R^{i - 1}\\ R^{i} = L^{i - 1} \\oplus f^{i}(R^{i - 1}, K^{i}) \\end{cases} $$ Dove $f$ √® una funzione invertibile, se si ha la chiave.\nInvertibilit√† di Feistelüü© $$ \\begin{cases} L^{i - 1} = R^{i} \\oplus f^{i}(L^{i}, K^{i})\\\\ R^{i - 1} = L^{i} \\end{cases} $$ Si pu√≤ verificare in modo facile che funziona questo.\nThe $f$ functions are only used in inverse order. AES does not use those.\nTheoretical result: Suppose we have a $f: K \\times \\left\\{ 0, 1 \\right\\}^{n} \\to \\left\\{ 0, 1 \\right\\}^{n}$ then a 3-round Feistel using the same $f$ at each step $F: K^{3}\\times \\left\\{ 0, 1 \\right\\}^{2n} \\to \\left\\{ 0, 1 \\right\\}^{2n}$ is a secure $PRP$ so the security is dependent on the $f$ function, which makes sense to use this function.\nFunzionamento DESüü© Quindi\nmapping iniziale $IP$ che crea $L^{0}R^{0}$ rounds di Feistel Poi output La decryption √® simmetrica con la conoscenza della chiave.\n$f$ function in DESüü® Dove $A$ √® il 32 bit plain-text e $J$ √® la chiave di $48$ bits.\nLe funzioni $S$ sono tra le pi√π importanti per la sicurezza, perch√© resistono a certi tipi di attacchi conosciuti (che se riesco metto in questi appunti qui sotto). Sono in pratica una mappa di 4 bit e 2 bit a un 4 bit: functions $S: \\left\\{ 0, 1 \\right\\}^{6} \\to \\left\\{ 0, 1 \\right\\}^{4}$. These tables are built following some design principles: **Not linear**: $$ DES(k, m_{1}) \\oplus DES(k, m_{2}) = B \\begin{bmatrix} m_{1} \\\\ k \\end{bmatrix}\\oplus B \\begin{bmatrix} m_{2} \\\\ k \\end{bmatrix}= B\\begin{bmatrix} m_{1} \\oplus m_{2} \\\\ k \\oplus k \\end{bmatrix} $$ Another theoretical result is that if DES is linear most of the time, it would be possible to break it.\nAttacchi a DESüü© Gli attacchi maggiori (alcuni lo vengono anche come servizio commerciale) √® semplicemente bruteforce perch√© la chiave di 56 bit usata non √® che sia molto utile. (In un giorno te o rompe). Gli attacchi con known plaintext esistono, ma usano un insieme di dati non feasible. di $2^{40}$ coppie di plaintext-ciphertext.\nUnicit√† della chiaveüü©- √à notabile osservare che √® probabile sia in DES che AES che √® molto probabile che sia unica la chiave usata per cifrare quello. Questa nota √® utile per dire che se trovi quella chiave, probabilmente ti funziona anche per altre comunicazioni che utilizzano roba simile.\n$$ DES:\\pi_{1},\\dots \\pi_{56} \\times \\left\\{ 0, 1 \\right\\}^{64} \\to \\left\\{ 0, 1 \\right\\}^{64} $$$$ \\mathbb{P} \\left[ \\exists k' \\neq k : c = DES(k, m) = DES(k', m) \\right] \\leq \\sum_{k' \\in \\left\\{ 0, 1 \\right\\}^{56}} \\mathbb{P}\\left[ DES(k, m) = DES(k', m) \\right] = 2^{56}\\frac{1}{2^{64}} = \\frac{1}{256} $$ Which means that the probability of having a key different from $k$ such that the encryption is the same is $1 / 256$.\nIf you do the same math for two messages we have $1 - 1 / 2^{71}$. Same thing is true for AES. This means that having one or two input pairs is enough for finding the real key.\nAltre versioni di DES Attacco a 2-DESüü© Vorremmo trovare una coppia di chiavi $k_{1}, k_{2}$ tale che per cui $E(k_{2}, m) = D(k_{1}, c)$ ed √® possibile con un meet in the middle, che dovrebbe diminuire lo spazio di ricerca. Conseguenza: Mi basta un $\u003c 2^{63}$ e space $2^{56}$ non un $2^{112}$ per rompere la chiave con questo attacco. Per questo motivo uso un 3-DES che non permette di fare questo. Ma per essere possibile questo attacco ha bisogno della coppia $M, C$ reale. Usato su 3DES abbiamo $2^{118}$ ma da una parte abbiamo il doppio.\nDESX (non impo) Wikipedia, this is not standardized, but should resist more against meet in the middle attacks. Ha key len of $184$. (Best attach is $2^{120}$.)\n$$ k_{1} \\oplus E(k_{2}, m\\oplus k_{3}) $$ In parole semplici ho due chiavi in pi√π che uso per fare un xor prima di mandarlo in #Data Encryption standard normale. La cosa da notare √® che non cresce la complessit√† di quanto ci si aspetta.\n3-DES In modo semplice per renderlo pi√π sicuro √® il 3-DES in pratica DES applicato 3 volte, con chiave lunga il triplo, quindi pi√π resistente a brute-force.\n$$ 3E(k_{1},k_{2},k_{3}, m) = E(k_{1}, D(k_{2}, E(k_{3}, m))) $$ We add a decryption because we can implement $DES$ if we want. 3 times slower. Keysize is $2^{168}$. But attach in time $2^{118}$ is present, so 3DES is usually considered secure.\nAdvanced Encryption Standard It\u0026rsquo;s a substitution permutation network.\nNote storiche di AES Da un punto di vista storico √® stata una competizione internazionale 1997 che poi √® stata standardizzata nel 2000. Una conferenza per questo (in particolare al seconda) √® stata fatta a Roma, cosa che era curiosa, solitamente non si faceva cos√¨). √à stato scelto in base a\nSicurezza Costo implementazione Velocit√† hardware e software. (DES troppo lento e insicuro) Alla fine √® un algoritmo molto parallelizzabile. Generazione della chiaveüü®- La lunghezza della chiave decide il numero di rounds, rispettivamente 10, 12, 14. In base al fatto che usiamo 128, 192, o 256. Vedere 4.6 di (Stinson 2005). Per l\u0026rsquo;algoritmo. La cosa √® che avremo una chiave di 16 bytes in output per il numero di rounds.\nFunzionamento del cifrarioüü©- Definiamo le operazioni (inizio con 16 bytes (blocco da 128 bits)) SubBytes (byte-by-byte substitution using an S-box) ShiftRows (a permutation, which cyclically shifts the last three rows in the State) MixColumns (substitution that uses Galois Fields, GF(2^8) arithmetic) Add Round key (bit-by-bit XOR with an expanded key\nSuboperations: $$ \\forall i,j : A_{k+1}[i, j] = S[A_{k}[i,j]] $$ Con $k$ lo step.\nMix Column is a linear transformation done independently (like $\\oplus$ xor operations and similar).\nCode-size vs performance Those tables can be compressed with a code that produces that. This has trade-offs for code-size and performance, but it can be allowed to be easily stored and implemented in embedded systems (like 8-bit wrist watches).\nModes of operation Electronic Code Book (ECB) Il problema principale di questo metodo na√Øve √® il fatto che posso vedere s e blocchi hanno avuto stesso input, perch√© non dipendono dalla posizione.\nQuesto non √® semantically secure secondo note in OTP and Stream Ciphers#Semantic security (!)\nDeterministic Counter (DETCTR) In pratica creo stream di bytes a blocchi per cifrare Th: questo cipher √® semanticamente sicuro se la funzione $F$ usata √® sicura. Ossia ha un buone garanzie teoriche se esiste e trovo tale $F$.\nCipher Block Chaining (CBC) Lo conosci.\nUna nota importante √® che si pu√≤ fare una analisi teorica, e sapere dopo quanti riusi di chiave √® necessario cambiarla, al fine di mantenere garanzie di sicurezza.\nSe si guarda le slides possiamo avere un risultato, che √® circa di $2^{48}$ blocchi per CBC. Si pu√≤ fare la stessa analisi per #Data Encryption Standard (per DES √® di circa $2^{12}$ (se ho pi√π di $2^{48}$ blocchi))\nNOTA: CBC non √® sicuro con un chosen plaintext se ho la capacit√† di predire gli IV Come:\nScelgo come mio chosen-plaintext $0$ cos√¨ ho in pratica la versione criptata di $IV$. Poi mando $m_{0} = IV \\oplus IV_{2}$ e $m_{1} \\neq m_{0}$ , se $c(m_{0})$ √® uguale al primo, allora ho indovinato il messaggio. Questo chiaramente d√† advantage 1 e rompe la definizione di semantic security. Diventa sicuro solamente se $IV$ √® abbastanza randomico.\nUna possibilit√† √® usare un IV creato dalla cifrazione di un Nonce, cos√¨ sei abbastanza sicuro che IV sia sicuro.\nCounter Mode (CTR) molto simile al counter mode per #Electronic Code Book (ECB) per√≤ ora abbiamo IV. Anche in questo caso possiamo usare una nonce based version. Per nonce-CTR abbiamo un $2^{64}$ di usage blocks (solitamente pi√π sicuro, e anche pi√π veloce, quindi verr√† pi√π utilizzato). Substitution-Permutation Networks (not required for exam) 2 componenti principali Abbiamo un box di sostituzione e un box di permutazione. La stringa iniziale viene divisa in molti blocchi di lunghezza $m$, e in totale avr√† lunghezza $lm$. Con padding finale possibile. C\u0026rsquo;√® un algoritmo abbastanza generale per questo genere di cifrari, che √® il 4.1 in (Stinson 2005). la cosa carina √® che queste funzioni alla fine sono molto semplici da implementare, sia in hardware e software. Non so bene su security garantuess\nKey generation and rounds In un unico round, viene encryptato molte volte (un round √® fra 10-20 cicli di criptazione) si chiamano iterated ciphers, e dalla chiave iniziale vengono generate 16 chiavi, una per ogni round. Questo lo chiamiamo round function e la funzione che genera le chiavi per ogni round sono key schedule.\nPseudo random function Main definition $$ F: K \\times X \\to Y $$ That has an efficient algorithm to evaluate this function. We say that this is random because we are considering three spaces of random variables (so the output should be a probability distribution over possible values!?)\nPseudo random permutation Solamente una pseudorandom-function tale per cui inizio e fine sono le stesse, quindi √® bigettiva\n$$ E: K \\times X \\to X $$ Such that\n$E$ is easy to evaluate $E$ is one-to-one $E$ is easily invertible, a function $D: K \\times X \\to X$ that is invertible knowing the key. Secure Pseudo random functions Consider the set of all functions to $X \\to Y$ as $Funs\\left[ X, Y \\right]$ of size $Y^{X}$. Consider $S_{F} = \\left\\{ F(k, \\cdot) \\text{ s.t. } k \\in K \\right\\} \\subseteq Funs\\left[ X, Y \\right]$, which has the size of the $K$ keyspace\nWe say that PRF is secure if a random function in $Funs\\left[ X, Y \\right]$ is not distinguishable (with statistical tests or similar) from $S_{F}$. This is the similar idea from previous definitions of security (advantage with statistical tests, semantic security OTP and Stream Ciphers#Security necessities for PRNGs), if this is true it means an adversary has not knowledge of the original.\nFormal definition of secure PRF We define experiments in a way similar for semantic security. $b \\in \\left\\{ 0, 1 \\right\\}^{}$ we say that if $b=0$ then a PRF is sent. if $b= 1$ is sent a truly random function from $Funs$. We say that this is secure if the adversary doesn\u0026rsquo;t have any advantage.\nSame thing for $PRP$.\nPRF -\u0026gt; PRG Let\u0026rsquo;s take a valid $PRF$ $F: K \\times \\left\\{ 0,1 \\right\\}^{n} \\to \\left\\{ 0, 1 \\right\\}^{n}$we want to show that we can generate a $G: K \\to \\left\\{ 0, 1 \\right\\}^{nt}$\n$$ G(k) = F(k, 0) \\mid \\dots \\mid F(k, t) $$ This is easily parallelizable. Output of the generation of the truly random function is indistinguishable from output of pseudo-random thanks to security.\nReferences [1] Stinson ‚ÄúCryptography: Theory and Practice, Third Edition‚Äù CRC Press 2005\n","permalink":"https://flecart.github.io/notes/block-ciphers/","summary":"\u003cp\u003eUtilizzano blocchi per cifra invece che stream generators. $n$ bits in input and $m$ bits in output generally a key is \u003cstrong\u003eexpanded\u003c/strong\u003e into multiple keys, one for each rounds, and applied to a \u003cem\u003eround function\u003c/em\u003e that iterates on the $m$.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDES 56 bit\u003c/li\u003e\n\u003cli\u003e3DES 56*3 bit di chiave\u003c/li\u003e\n\u003cli\u003eAES che pu√≤ andare a 128, 196 o 256\nSolitamente i stream ciphers studiati in \u003ca href=\"/notes/otp-and-stream-ciphers/\"\u003eOTP and Stream Ciphers\u003c/a\u003e sono pi√π veloci.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCipher\u003c/th\u003e\n          \u003cth\u003eSpeed MB/sec\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eRC4\u003c/td\u003e\n          \u003ctd\u003e126\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSalsa20\u003c/td\u003e\n          \u003ctd\u003e643\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSosemanuk\u003c/td\u003e\n          \u003ctd\u003e727\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eAES\u003c/td\u003e\n          \u003ctd\u003e13\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e3DES\u003c/td\u003e\n          \u003ctd\u003e109\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"data-encryption-standard\"\u003eData Encryption Standard\u003c/h3\u003e\n\u003cimg src=\"/images/notes/Block Ciphers-20240525101348320.webp\" alt=\"Block Ciphers-20240525101348320\"\u003e\n- 1974 da IBM su commissione di NSA (Horst Feistel designed Lucifer at IBM in early 1970)\n- 1976 DES is federal standard with key-len 56 bits and block-len 64 bits.\n\u003cp\u003ein quel periodo era solamente fatta dalla intelligence, non c‚Äôera bisogno di comunicazioni per il pubblico in quel periodo.\u003c/p\u003e","title":"Block Ciphers"},{"content":"How Bloom Filters Work A Bloom filter is a space-efficient probabilistic data structure used to test whether an element is possibly in a set or definitely not in a set. It allows for false positives but never false negatives.\nOne example of application is the membership query in Wide Column Storage, HBase. They make document lookup faster by completely skipping some HFiles.\nStructure and Initialization A Bloom filter consists of:\nA bit array of size $m$, initialized to all 0s. $k$ independent hash functions, each mapping an input element to one of the $m$ positions in the bit array. Common operations Insertion of an Element To insert an element $x$:\nCompute $k$ hash values: $h_1(x), h_2(x), ..., h_k(x)$. Set the corresponding bits in the bit array to 1. Example:\nIf $h_1(x) = 3$, $h_2(x) = 7$, and $h_3(x) = 11$, the bits at positions 3, 7, and 11 are set to 1.\nMembership Query To check if an element $y$ is in the Bloom filter:\nCompute the $k$ hash values: $h_1(y), h_2(y), ..., h_k(y)$. If all corresponding bits in the bit array are 1, then: The element is possibly in the set (but could be a false positive). If any bit is 0, then: The element is definitely not in the set. Interesting properties False Positives \u0026amp; No False Negatives A false positive occurs when all $k$ hash positions of $y$ are already set to 1 due to previous insertions, even though $y$ was never inserted. A false negative never occurs because an inserted element always sets its corresponding bits, ensuring it will always be recognized as ‚Äúpossibly in the set.‚Äù Deletion Issue Standard Bloom filters do not support deletions because clearing a bit might remove information from multiple elements. A variation, called a Counting Bloom Filter, uses counters instead of bits to track the number of insertions at each position. ","permalink":"https://flecart.github.io/notes/bloom-filters/","summary":"\u003ch3 id=\"how-bloom-filters-work\"\u003e\u003cstrong\u003eHow Bloom Filters Work\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eA \u003cstrong\u003eBloom filter\u003c/strong\u003e is a space-efficient probabilistic data structure used to test whether an element is \u003cstrong\u003epossibly in a set\u003c/strong\u003e or \u003cstrong\u003edefinitely not in a set\u003c/strong\u003e. It allows for false positives but never false negatives.\u003c/p\u003e\n\u003cp\u003eOne example of application is the membership query in \u003ca href=\"/notes/wide-column-storage/\"\u003eWide Column Storage\u003c/a\u003e, HBase. They make document lookup faster by completely skipping some HFiles.\u003c/p\u003e\n\u003ch3 id=\"structure-and-initialization\"\u003eStructure and Initialization\u003c/h3\u003e\n\u003cp\u003eA Bloom filter consists of:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA \u003cstrong\u003ebit array\u003c/strong\u003e of size $m$, initialized to all \u003cstrong\u003e0s\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003e$k$ independent \u003cstrong\u003ehash functions\u003c/strong\u003e, each mapping an input element to one of the $m$ positions in the bit array.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"common-operations\"\u003eCommon operations\u003c/h2\u003e\n\u003ch3 id=\"insertion-of-an-element\"\u003eInsertion of an Element\u003c/h3\u003e\n\u003cp\u003eTo insert an element $x$:\u003c/p\u003e","title":"Bloom Filters"},{"content":"Descrivo ora alcune domande utili per ripasso:\nQuali sono schematicmente quali sono le operazioni migliori per un parser top-down? Cosa √® un prefisso viabile? Quali sono i conflitti possibli, e come risolverli‚Ä¶ Non sai nemmeno definire inmodo formale cosa sia un item Bottom up Intro shift-reduce e LR üü© Slide\nIn breve:\nShift = simbolo terminale messo nella stack Riduzione utilizzando una produzione LR = dettura da Sinistra, creazione della stringa da destra (derivazione rightmost) Algoritmo classico üü®+ Quello che credo che intendevo per questo algoritmo classico √® quello non deterministico, nel senso che prova a fare backtracking, finch√© non ha finito tutte le possibilit√†, oppure trova la derivazione giusta.\nSlide\nQuesto √® esattamente lo stesso presentato alla fine di Linguaggi Deterministici e DPDA\nEsempio\nIl drawback classico di queste tipologie di parser √® che c‚Äô√® un enorme non determinismo causato dai conflitti shift-reduce e reduce-reduce, che non hanno una lettura immediata, andremo quindi in seguito a creare metodi che possano disambiguare ci√≤.\nIl parser LR Struttura di un parser LR üü®++ Slide schematizzazione\nIn figura sono descritte tutte le componenti del parser in modo molto schematico.\nComponenti importanti sono\nDFA e stack degli stati del DFA Pila dei simboli Tabella di parsing Algoritmo alto livello di parsing üü© Mosse di parser LR deterministico\nOssia le operazioni che pu√≤ fare il parser\nAlgoritmo in pseudocodice\nEsempio di parsing LR\nNota, spesso √® molto comodo fare una grammatica aumentata in questo modo\nIl DFA degli stati pare quindi fondamentale per la costruzione della tabella di parsing, in seguito andremo a costruire dei metodi automatici utili a far questo.\nQuesto √® un DFA con alcuni modi di tornare indietro.\n√à bene quindi andare prima a fondare una teoria solida per questa roba, la crazione dell‚Äôautoma canonico per il parsing LR.\nPrefisso viabile I prefissi viabili sono un modo per risolvere il non determinismo di un parser classico bottom up, ci permette di capire in modo univoco se andare a fare shift e reduce col sistema degli handle.\nPer poter controllare bene i prefissi viabili utilizziamo una tabella di parsing per controllare lo stato dell‚Äôhandle.\nIntroduzione al perch√© (informale, non fare) üü© Slide\nL‚Äôidea √® far in modo che in cima alla pila ci sia solamente qualcosa che possa essere un prefisso di una produzione se non lo pu√≤ esere si pu√≤ concludere chiaramente che non sia possibile!\nPer controllare questi prefissi utilizzeremo di nuovo una tabella di parsing, ma con altra logica sotto.\nDefinizione üü® ‚Äî Slide sui prefissi viabili.\nInformalmente: una sequenza $\\in (T \\cup NT)^*$ che pu√≤ apparire sulla pila del parser bottom up per una configurazione che accetta l‚Äôinput.\nDa notare differenza della definizione per stringa e per gramamtica.\nPer stringa √® qualunque stringa che pu√≤ apparire sulla pila, al momento di una computazione che va a buon fine Per grammatica, invece, andiamo a considerare le derivazioni destre. In questa parte si introducono anche concetti come prefisso viabile completo e handle. **(non credo sia importante questa definizione la salto). Gli handle sono di interesse perch√© appena li abbiamo siamo sicuri che vogliamo andare a fare una reduce, vorremmo trovare un modo per farceli comparire sti handle quando ne ho bisogno!\nNOTA: la derivazione deve essere rightmost almeno nella definizione, anche se non ho ben capito per quale motivo deve essere cosi`.\nTh. prefissi variabili di G libera sono un linguaggio regolare üü© Slide\nQuesto teorema ci √® molto utile per continuare la nostra costruzione del parser, perch√© ora possiamo utilizzare questo DFA di supporto generato dal linguaggio regolare dei prefissi variabili per decidere cosa fare:\nSe √® completo faccio reduce Se non lo √® faccio shift Se non √® nemmeno un prefisso variabile sono in errore, perch√© mai ci potr√≤ fare una reduce, questo per definizione di prefisso variabile. Abbiamo cos√¨ discusso su vantaggi che questo teorema ci pu√≤ dare, ma non abbiamo ancora dato un modo per dimostrare questo teorema, lo dimostreremo in seguito, con la costruzione degli item e un DFA per esse. e poi sappiamo che i DFA sono anch‚Äôesse equivalenti a un linguaggio regolare.\nShift e reduce sullo stato del DFA üü© In questa minisezione andiamo a trattare in che modo potremmo codificare il DFA in modo efficiente, in modo da non rifare ad ogni shift e reduce il ricalcolo dell‚Äôintera stringa!\nSlide\nQuindi per lo shift molto easy, basta che ricomincio dallo stato vecchio.\nPer il reduce invece mi serve poter tornare indietro! il modo pi√π semplice per fare questo √® tenersi uno stack degli stati, in modo che possa tornare indietro in modo lineare (poi quindi credo che l‚Äôalgoritmo sar√† lineare nei nodi dell‚Äôalbero in questo modo).\nAutoma canonico L‚Äôautoma canonico per il parser LR(0) √® un DFA utilizzato per decidere se fare reduce oppure shift. (quindi vede se prefisso viabile √® completo o meno).\nItem LR(0) üü© L‚Äôitem √® un costituente del DFA di supporto per il nostro DFA\nSlide\nIn pratica apro la produzione che ho, in un sacco di produzioni che contengono un punto, questo punto mi indica pi√π o meno quanto √® presente sulla stack.\nIntro Costruzione NFA dei prefissi üü®‚Äî Slide\nL‚Äôidea per questo algoritmo √® utilizzata per gestire la grammatica aumentata degli item!.\nAvanzamento dell‚Äôitem, in questo caso avanzo semplicemente il punto (vado in stato corrispondente con punto in pi√π!) Letttura di un altro simbolo, collegamento epsilon a quest‚Äôaltro punto. Esempio\nClos e Goto üü©- Slide algo\nQuesti due algoritmi codificano in pseudocodice i concetti precedenti.\nClos, √® utilizzato per lettura di un altro collegamento epsilon, dato che va a checkare tutte le produzioni con quel coso in pi√π, simula tutto il raggiungibile senza leggere in un certo senso. Goto √® per avanzare il punto, quindi mi crea tutte le produzioni con avanzamento del punto, e le chiude, specificatamente alle produzioni in una certa forma. simula una lettura in un certo senso. Queste saranno delle funzioni di supporto per la costruzione dell\u0026rsquo;automa canonico di riferimento, cos√¨ non dovremo passare all\u0026rsquo;algoritmo esponenziale per la costruzione del DFA, l‚Äôautoma canonico.\nCostruzione dell‚Äôautoma canonico üü® Slide algo\nQuesto algoritmo parte dal NFA dei prefissi viabili, e utilizza Goto e Clos per trovare il NFA in modo molto efficiente!\nEsempio 1\nEsempio 2\nTabella di parsing LR üü© Slide, descrizione generale, molto simile a LL\nCostruzione tabella per LR(0)\nEsempio tabella di parsing\nEsempio 2\n","permalink":"https://flecart.github.io/notes/bottom-up-parser-lr0/","summary":"\u003cp\u003eDescrivo ora alcune domande utili per ripasso:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eQuali sono schematicmente quali sono le operazioni migliori per un parser top-down?\u003c/li\u003e\n\u003cli\u003eCosa √® un prefisso viabile?\u003c/li\u003e\n\u003cli\u003eQuali sono i conflitti possibli, e come risolverli‚Ä¶\u003c/li\u003e\n\u003cli\u003eNon sai nemmeno definire inmodo formale cosa sia un item\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"bottom-up\"\u003eBottom up\u003c/h2\u003e\n\u003ch3 id=\"intro-shift-reduce-e-lr-\"\u003eIntro shift-reduce e LR üü©\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Bottom-up Parser LR(0)/Untitled 1.png\" alt=\"image/universita/ex-notion/Bottom-up Parser LR(0)/Untitled 1\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn breve:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eShift = simbolo terminale messo nella stack\u003c/li\u003e\n\u003cli\u003eRiduzione utilizzando una produzione\u003c/li\u003e\n\u003cli\u003eLR = dettura da Sinistra, creazione della stringa da destra (derivazione rightmost)\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"algoritmo-classico-\"\u003eAlgoritmo classico üü®+\u003c/h3\u003e\n\u003cp\u003eQuello che credo che intendevo per questo algoritmo classico √® quello non deterministico, nel senso che prova a fare backtracking, finch√© non ha finito tutte le possibilit√†, oppure trova la derivazione giusta.\u003c/p\u003e","title":"Bottom-up Parser LR(0)"},{"content":"Si pu√≤ osservare che per il parser costruito in Bottom-up Parser LR(0), non riesce a riconoscere di linguaggi semplici come $L = \\{a, ab\\}$.\nEsempio di quanto detto Parser SLR(1) Questi parser qui utilizzano l‚Äôidea del look ahead ampiamente utilizzata in Top-down Parser, per escludere molte produzioni.\nLa s sta per simple, perch√© utilizza una idea semplice :D, credo ahah boh.\nRiduzione con follow üü© noi vogliamo ridurre solamente se ho follow corretto il terminale finale della stringa.\nQuindi in pratica vado ad aggiungere questa nuova regola per togliere alcune riduzioni senza questo terminale nella tabella.\nEsempio\nalla fine non deve essere solamente per S, deve essere per il follow!, ma sotto nella tabella di parsing ne parliamo un pochino meglio.\nOsservazioni varie (4) üü•+ slide\n√à molto raro che alcune produzioni che hanno la epsilon siano di LR(0), anche se √® possibile! Libero deterministico + prefix property ‚Üí LR(0) not LR(0) ‚Üí libero deterministico + not prefix property or prefix property or not libero deterministico. Finito e LR(0) ‚Üí prefix property. Se √® infinito e LR(0) pu√≤ non godere della prefix property. Tabella di parsing SLR(1) üü®+ Slide\nPraticamente il riempimento di questa tabella √® identica a quella del LR(0), solo con il check in pi√π sui follow di S.\nL\u0026rsquo;unica cosa differente √® che\n$A \\to \\alpha. \\in S, A \\not\\in S',$ allora il reduce si pu√≤ fare in $M[s, x] \\iff x \\in Follow(A)$, ossia solo se ho il follow, non devo andare a fare shift!\nMentre per LR(0) lo devo mettere per tutti gli entry!\nParser LR(1) Item LR(1) üü©- In questa serie di Item dobbiamo ancora andare ad estendere il concetto di item esposto in [Bottom-up Parser LR(0)](Bottom-up Parser LR(0) 92be8778006943cf99add4d634a3fb1a.md).\nApplicando anche una parte di lookahead, di non terminali\nClosure \u0026amp; goto üü© Slide\nLa cosa nuova riguardante questo √® che devo andare a considerare i first e simili!\nSi l\u0026rsquo;unica cosa in pi√π √® che devo agigungere ogni cosa riguardante il first.\nIl goto resta esattamente uguale!\nTabella di parsing üü®+ Slide\nL\u0026rsquo;algoritmo di creazione della tabella di parsing mi sembra sia molto simile a quelle precedenti, per√≤ per capire se ho compreso questo concetto sarebbe utile fare qualche esercizio a riguardo! LR(0) ha detto che per forza ce lo mette in esame!\nEsempio di parsing LR(0)\nNucleo dello stato LR 1\nSe rimuovo il look ahead, allora ottengo lo stato dell\u0026rsquo;automa LR(0)! In questo senso potremmo osservare che le transizioni di LR 1 dipendono solo dal nucleo. Questo diventa un hint molto importante per andare a costruire poi un automa LALR.\nLALR (1) Questi automi sono presenti all‚Äôorale per√≤ allo scritto non ci sono proprio.\nQuesto √® una forma di mezzo fra semplicit√† di SLR e la selettivit√† di LR.\nSi traduce come Look-Ahead Left-reading Right-most derivation 1 lookahead parser\nOsservazioni sulla tabella üü®+ Questo ha una tabella con il nucleo fuso per quelli che hanno le cose uguali, in questo modo cerco di limitare il numero di stati.\nQuesta parte √® molto simile a quanto fatto per la minimizzazione dei dfa in Automi e Regexp, perch√© stiamo andando ad accorpare stati che sono quasi equivalenti, questo col rischio di introdurre alcuni conflitti reduce-reduce che per√≤ non dovrebbero portare a troppi problemi, come andremo presto a vedere.\nEsempio slide entrambi errati\nlezione 16 slide 18\nPossibilit√† di conflitti (no shift-reduce dimo) üü® Slide\nDa questo esempio presente in slide vediamo che una grammatica pu√≤ essere LR(1) e non LALR(1), quindi non sono esattamente equivalenti.\nRiassunto di questa lezione 16\nEsempio LR not LALR üü® Questo √® un esempio importante solo perch√© √® richiesto nelle domande, altrimenti l‚Äôavrei saltato. Comunque basta un p√≤ ricordarsi cose riguardo simmetria della grammatica per costruire quasi ad Hoc un conflitto Reduce-Reduce nella grammatica LALR\nEsempio di conflitto ","permalink":"https://flecart.github.io/notes/bottom-up-parser-lr1/","summary":"\u003cp\u003eSi pu√≤ osservare che per il parser costruito in \u003ca href=\"/notes/bottom-up-parser-lr0/\"\u003eBottom-up Parser LR(0)\u003c/a\u003e, non riesce a riconoscere di linguaggi semplici come $L = \\{a, ab\\}$.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEsempio di quanto detto\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Bottom-up Parser -LR(1)/Untitled 1.png\" alt=\"image/universita/ex-notion/Bottom-up Parser -LR(1)/Untitled 1\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"parser-slr1\"\u003eParser SLR(1)\u003c/h2\u003e\n\u003cp\u003eQuesti parser qui utilizzano l‚Äôidea del look ahead ampiamente utilizzata in \u003ca href=\"/notes/top-down-parser/\"\u003eTop-down Parser\u003c/a\u003e, per escludere molte produzioni.\u003c/p\u003e\n\u003cp\u003eLa s sta per \u003cstrong\u003esimple\u003c/strong\u003e, perch√© utilizza una idea semplice :D, credo ahah boh.\u003c/p\u003e\n\u003ch3 id=\"riduzione-con-follow-\"\u003eRiduzione con follow üü©\u003c/h3\u003e\n\u003cp\u003enoi vogliamo \u003cstrong\u003eridurre solamente se ho follow\u003c/strong\u003e corretto il terminale finale della stringa.\u003c/p\u003e","title":"Bottom-up Parser LR(1)"},{"content":"1 Calcolo dei numeri finiti Il calcolo √® numerico perch√© si differenzia rispetto a un calcolo normale perch√© √® finito.\n1.1 Errore nei calcoli 1.1.1 Tipologie di errore (5) üü© Errore di misura, dovuto alle imperfezioni dello strumento di misura dei dati del problema. Errore di troncamento, quando un procedimento infinito viene realizzato come procedimento finito. (esempio: calcolo del valore di una funzione tramite sviluppo in serie, perch√© dato che l‚Äôalgoritmo deve essere finito, devo prima o poi interrompere il calcolo, ecco qui l‚Äôerrore). Errore inerente, dovuto al fatto che i dati di un problema non sono in una forma buona diciamo Errore di rappresentazione (simil troncamento) non sempre appartengono all‚Äôinsieme $\\mathbb{F}$ dei numeri rappresentabili e quindi vengono approssimati. Errore algoritmico, dovuto al propagarsi degli errori di arrotondamento sulle singole operazioni in un procedimento complesso. 1.1.2 Misura dell‚Äôaccuratezza üü© Anche per l‚Äôaccuratezza di una misura utilizziamo degli errori (questi tipi di errori li hai anche studiati in fisica durante il liceo).\nErrore assoluto $|stimato - expected|$ di solito ha poco valore perch√© dipende dal contesto, molto pi√π importante il relativo Errore relativo $E_a /expected$ questo molto buono, ed √® in pratica simile all‚Äôerrore percentuale Questo errore mi riesce effettivamente a dare un concetto di precisione del calcolo. Errore percentuale in pratica √® l‚Äôerrore percentuale $\\cdot 100\\%$ 1.2 Rappresentazione dei numeri üü©- Gli argomenti presentati in questa sezione sono gi√† stati trattati in modo anche pratico nel corso di Architettura degli elaboratori in Rappresentazione delle informazioni, qui andremo ad approfondire di pi√π da un punto di vista matematico.\n1.2.1 Numeri interi üü© Questa parte √® totalmente omessa perch√© presente in Rappresentazione delle informazioni\nLa stessa parte, sempre presente l√¨, tratta dell‚Äôalgoritmo di conversione dei numeri interi in binario e decimale\n1.2.2 Numeri reali üü© Slide per la rappresentazioni.\nLa prima cifra deve essere diversa da 0 per garantire unicit√† al numero.\nEsercizio: ricava la formula che rappresenta ogni numero reale in una base qualunque.\n1.3 Sistema floating point üü© 1.3.1 Rappresentazione matematica dell‚Äôinsieme üü© Slide\nl‚Äôinsieme\n$$ \\mathbb{F}(\\beta, t, L, U) = \\{0\\} \\cup \\{x \\in \\R = sign(x) \\beta ^p \\sum_{i = 1}^t d_i \\beta^{-i}\\}\\\\ 0 \\leq d_i \u003c \\beta, i \\in \\N_+, d_1 \\neq 0, L \\leq p \\leq U $$descrive tutti i numeri nella retta reale che sono rappresentabili secondo il sistema floating point\nQuesto insieme $\\mathbb{F}$ √® finito, non continuo.\n1.3.2 Rappresentazione del numero nel calcolatore üü© Se il numero che vogliamo rappresentare √® nell‚Äôinsieme, allora √® facile, prendiamo quel numero Altrimenti si utilizza un troncamento o arrotondamento della mantissa al numero di $\\mathbb{F}$ pi√π adatto, vediamo come agiscono questi due metodi. Notiamo che questo caso succede quando $\\exists i \u003e t : d_i \\neq 0$.\nTroncamento rappresento tutto il numero fino a $t$ e poi ignoro il resto. Un altro modo per vedere il troncamento √® che arrotonda sempre al ribasso, mai dopo, prende il numero di $\\mathbb{F}$ pi√π vicino e minore del numero che vogliamo convertire.\nArrotondamento simile al troncamento, ma arrotonda. Che si conosca non c‚Äô√® un coso hardware che lo faccia (o comunque implementa questo algo:https://stackoverflow.com/questions/4572556/concise-way-to-implement-round-in-c)\n1.3.3 Breve discussione sui parametri üü© $\\beta$, descrive la base di rappresentazione del nostro insieme $t$, descrive il numero di cifre utilizzate per la rappresentazione, principalmente influiscono sulla precisione (densit√† dei numeri nell‚Äôintervallo, vedi sezione sequente). $U$ descrive il upper bound per la caratteristica (esponente alla base) $L$ uguale a $U$ ma √® un lower bound.\nQuindi $U, L$ descrivono il range di rappresetnazione per il nostro insieme di rappresentazione\n1.3.4 Densit√† dei numeri üü© Slide\nSi pu√≤ notare che col metodo di rappresentazione esposto sopra si possono individuare informazioni sulla dispersione dei numeri nella retta.\nIn ogni intervallo di lunghezza $[\\beta ^p, \\beta^{p + 1}]$ ho $(\\beta - 1)\\beta^{t- 1}$ numeri, distanziati in maniera uguale una dall‚Äôaltra (solo in questo intervallo), appena salgo di intervallo, l‚Äôintervallo cresce. Questo √® anch eun motivo dell‚Äôunderflow, in cui quando sono troppo vicino allo zero, l‚Äôintervallo √® troppo piccolo. (credo, √® da rivedere questa cosa).\nIl motivo di questi numeri √® perch√© ho $\\beta - 1$ numero di modi per scegliere il primo numero (che deve essere diverso da nullo) e il restanti cifre della mantissa come li voglio\n1.3.5 Standard IEEE üü®+ Slide descrizione dei floating points per lo standard IEEE\nIn pi√π sono riservati alcuni numeri per $+0, -0, +\\infty, -\\infty$. e NaN (esempio quando faccio 0 * inf ho un NaN)\nNota questi valori non sono codificabili nella forma che √® presente in slide, per√≤ lei li vuole cos√¨ quindi impara a memoria per l\u0026rsquo;esame saddo.\n1.3.6 Errore di rappresentazione ed errore di macchina üü©- Con double $\\approx 10^{-16}$, con float $\\approx 10^{-7}$\nDefinizione simile di epsilon, ma nell‚Äôaltro verso üü® TODO: chiedere se le due definizioni sono equivalenti pg 50 pdf introduzione al calcolo numerico\neps √® il pi√π piccolo numero macchina positivo tale che $eps + 1 \u003e 1$, in pratica √® il pi√π piccolo numero che √® arrotondato al pi√π piccolo numero rappresentabile da $\\mathbb{F}$.\nPer il calcolo dell‚Äôeps per il valore dell‚Äôerrore macchina ti puoi rifare a questo post machine epsilon value for IEEE double precision standard alternative proof using relative error\nLa prof ha sbagliato in questa parte, ha copiato il valore di epsilon per l‚Äôarrotondamento con normalizzazione che parte da 1, quindi il valore corretto di epsilon dovrebbe essere $\\varepsilon_{mach} = \\dfrac{1}{2}\\beta ^ {1-t}$. Anche la pagina di wiki spiega bene questa parte di dimostrazione dell‚Äôerrore macchina\n1.4 Aritmetica floating point 1.4.1 Definizione di funzione üü© √® una funzione $\\circ : F \\times F \\to F$, ma pu√≤ succedere che una operazione che prende due operandi da F e F non sia ancora in F, e quindi c\u0026rsquo;√® bisogno di arrotondarlo ad F, causando un errore di\n$$ | \\dfrac{x \\circ y - x \\cdot y}{x \\cdot y} | \u003c \\epsilon $$Il valore √® sempre minore perch√© epsilon √® il maggior errore possibile per singola operazione\nPropagazione dell‚Äôerrore üü© Il processo di propagazioen dell‚Äôerrore √® molto difficile da tenere in considerazione, quindi ci limitiamo a considerare alcuni casi tipici di errori inerenti nell‚Äôoperazione di somma e sottrazione:\nNOTA: per questa parte $\\varepsilon$ √® definito come il pi√π grande numero tale che $1 + \\varepsilon = 1$, che √® quasi equivalente all\u0026rsquo;altro.\nSomma di due numeri con esponente molto differente, perch√© finisce che il computer non ha abbastanza bit in mantissa per rappresentare il risultato, e quindi deve andarea troncare. Questo incide principalemente su bit di poco significanza. $(1 + \\varepsilon) + (1 + \\varepsilon) = 1 + 1 = 2$, cos√¨ abbiamo perso $2\\varepsilon)$ Differenza fra numeri molto simili, questo incide su bit di grande signfiicanza: Esempio: ( $(1 + \\varepsilon) - (1 - \\varepsilon) = 0$ abbiamo perso $2\\varepsilon$, ma questo √® un errore relativo direi pi√π grosso, credo. Importanti sono l‚Äôesempio presente nelle slides epr il calcolo del numero di nepero\n","permalink":"https://flecart.github.io/notes/calcolo-di-numeri-finiti/","summary":"\u003ch1 id=\"1-calcolo-dei-numeri-finiti\"\u003e1 Calcolo dei numeri finiti\u003c/h1\u003e\n\u003cp\u003eIl calcolo √® numerico perch√© si differenzia rispetto a un calcolo normale perch√© √® \u003cem\u003efinito\u003c/em\u003e.\u003c/p\u003e\n\u003ch2 id=\"11-errore-nei-calcoli\"\u003e1.1 Errore nei calcoli\u003c/h2\u003e\n\u003ch3 id=\"111-tipologie-di-errore-5-\"\u003e1.1.1 Tipologie di errore (5) üü©\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eErrore di misura\u003c/strong\u003e, dovuto alle imperfezioni dello strumento di misura dei dati del problema.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eErrore di troncamento\u003c/strong\u003e, quando un procedimento infinito viene realizzato come procedimento finito. (esempio: calcolo del valore di una funzione tramite sviluppo in serie, perch√© dato che l‚Äôalgoritmo deve essere finito, devo prima o poi interrompere il calcolo, ecco qui l‚Äôerrore).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eErrore inerente\u003c/strong\u003e, dovuto al fatto che i dati di un problema non sono in una forma buona diciamo\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eErrore di rappresentazione (simil troncamento)\u003c/strong\u003e non sempre appartengono all‚Äôinsieme $\\mathbb{F}$ dei numeri rappresentabili e quindi vengono approssimati.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eErrore algoritmico\u003c/strong\u003e, dovuto al \u003cem\u003epropagarsi\u003c/em\u003e degli errori di arrotondamento sulle singole operazioni in un procedimento complesso.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"112-misura-dellaccuratezza-\"\u003e1.1.2 Misura dell‚Äôaccuratezza üü©\u003c/h3\u003e\n\u003cp\u003eAnche per l‚Äôaccuratezza di una misura utilizziamo degli errori (questi tipi di errori li hai anche studiati in fisica durante il liceo).\u003c/p\u003e","title":"Calcolo di numeri finiti"},{"content":"10.1 Derivata parziale La derivata vuole descrivere quanto varia una funzione al variare dell\u0026rsquo;input. Ma ora siamo in pi√π dimensioni, quindi vogliamo descrivere il variare dell\u0026rsquo;input come il variare della distanza euclidea\n$\\dfrac{\\delta f}{\\delta x}(x,y) = \\lim _{h \\to 0} \\dfrac{f(x + h, y) - f(x, y)}{h}$ ovvero sto facendo variare solamente una variabile (la y in questo caso √® come se fosse una costante!?) Questo √® un rapporto incrementale su una direzione.\nSe esiste il limite, √® la derivata parziale rispetto a x.\nIn modo analogo puoi definire una derivata parziale rispetto a y\n10.1.1 Gradiente Se vogliamo considerare allo stesso momento la derivata parziale per ogni componente, possiamo farlo considerando un unico simbolo: (indica il gradiente della funzione).\n$$ \\nabla f(x,y) = (\\delta_xf(x,y), \\delta_y f(x,y)) $$Se in ogni punto √® derivabile allora possiamo proprio definire una funzione gradiente di questa, nel modo di sopra.\nQuesta definizione si pu√≤ estendere per uno spazio n-dimensionale\n10.1.2 Legame con la continuit√† Si ha una relazione molto simile con la derivata a singola dimensione (cazzo non mi ricordo bene la dim????)\n$f:A \\to \\R$ se $f$ √® derivabile in $x$ allora $f$ √® continua in $x$ in R normale, ma se a pi√π dimensioni avessimo le derivate parziali non abbiamo la continuit√† in quel punto.\n$$\\begin{cases} \\dfrac{xy}{x^2 + y^2} \\text{ se diverso dall'origine }\\\\ 0 \\text { altrimenti } \\end{cases}$$in questo esempio entrambe le derivate parziali in (0,0) esistono, ma non √® continua in questo punto (tende a +- infinito in questo punto).\nAnalisi della funzione sopra\nSi pu√≤ dimostrare che la funzione di sopra ha entrambe le derivate uguali a 0 quando tende a 0. (applicare la definizione di derivata parziale).\nDimostriamo che non √® continua in (0,0) ovvero esiste una successione che tende a 0, ma non vale la definizione di continuit√†, ovvero non vale che $f(a_n, b_n) \\to f(0,0) = 0$.\nScegliamo la successione simile: $(a_n,b_n) = (1/n, 1/n)$ che ovviamente tende a 0.\nMa .\n(1/n * 1/n) / (2/(n*n)) != 0 Quindi questa successione tende a 2, mentre dovrebbe tendere a 0. Un caso patologico di continuit√†, ma che comunque da l\u0026rsquo;idea di questo.\n10.1.3 Derivabilit√† e differenziabilit√† (intuizione) Si ricordi la definizione di derivata in $\\R$. Derivate.\nSi ricordi anche come si √® ricavata l\u0026rsquo;approssimazione con serie di taylor e gli o-piccoli in Hopital, Taylor, Peano\nPer descrivere la nozione di derivabilit√† vogliamo ricondurci a una formula di Taylor per il primo grado. (perch√© nelle derivate parziali sappiamo quando varia in due direzioni, ma mancano informazioni su quanto varia in tutte le direzioni, ed √® per questo motivo che non ho la continuit√†).\nVorrei considerare un limite simile a $f(x + h, y+ h) - f(x, y)$, che possiamo riscrivere in forma vettoriale $f((x + y)+ (h,k)) - f(x,y)$ e ricondurci a una forma di approssimazione con taylor.\nDef o-piccolo a pi√π dimensioni:\n$g: \\mathbb{R}^2 \\to \\mathbb{R}$ si dice che $g(h,k) = o(\\lvert(h,k)\\rvert)$ se ho che $\\lvert g(h,k)\\rvert/ \\lvert (h,k)\\rvert \u003c \\epsilon$ , con $0\u003c \\lvert(h,k)\\rvert \u003c \\delta$ per ogni epsilon maggiore di 0, quindi considero la norma (che mi da una nozione di distanza). Ma i concetto di o-piccolo √® ancora ben presente.\nPossiamo anche scrivere la stessa definizione utilizzando le successione.\nCome qui Avendo questa nozione di approssimazione per taylor, posso dare una nozione di differenziabilit√†. In questo modo riesco a dare una nozione di funzione che tende a zero pi√π o meno velocemente della norma. (o potenze di esse).\n10.2 Differenziabilit√† Questa √® la condizione molto pi√π forte rispetto alla derivata, √® il concetto che ci permette di avere subito la continuit√†.\nLa differenza principale con la derivata √® che qui non consideriamo una unica direzione cerchiamo di prenderle tutte. Andiamo ora a vedere come definire questo fatto.\n10.2.1 La funzione differenziabile Sia $f$ una funzione da $A \\subseteq \\mathbb{R}^2$ aperto da $f: A \\to \\mathbb{R}$. Si dice che la funzione $f$ sia differenziabile se:\nEsistono le derivate parziali per tutte le direzioni. Se vale $$ f((x + h, y + k)) = f((x, y) + (h,k)) = f(x,y) + \\langle\\nabla f(x,y), (h,k)\\rangle + o(\\lvert h,k \\rvert ) $$Possiamo scrivere questa cosa con una altra notazione equivalente:\n$f(x, y) = f(\\bar{x}, \\bar{y}) +\\langle\\nabla f(x,y), (x - \\bar{x},y - \\bar{y})\\rangle + o((\\mid x - \\bar{x},y - \\bar{y} \\mid)$ con $(x,y) \\to(\\bar{x}, \\bar{y})$\nE questo assomiglia di pi√π rispetto al polinomio di taylor, perch√© effettivamente qui si ha l‚Äôapprossimazione in bella vista.\nAndiamo ora a dare una intuizione sul perch√© vogliamo la seconda condizione.\nIntuizione del punto 2\nNon stiamo facendo altro che dare la formula di Taylor del primo ordine (vedi Hopital, Taylor, Peano) sul punto (x, y) ma lo stiamo considerando a pi√π dimensioni.\nQuindi, ricordando che l‚Äôespansione con le serie di taylor ci permetteva di fare una approssimazione, questa condizione per il punto 2 non √® altro che una approssimazione al variare in una qualsivoglia direzione.\n10.2.2 Polinomio di taylor del primo ordine $$ T_1(x,y) = f(\\bar{x}, \\bar{y}) +\\langle\\nabla f(x,y), (x - \\bar{x},y - \\bar{y})\\rangle $$In particolare qui abbiamo una approssimazione dell‚Äôequazione tangente a un punto voluto (in R2 un piano, in R1 una retta, in R3 vedi che √® uno spazio), il punto $(\\bar{x}, \\bar{y}, f(\\bar{x}, \\bar{y}))$\n10.2.3 Differenziabilit√† implica continuit√† $f:A \\to \\mathbb{R}$ aperto (perch√© cos√¨ ho tutti gli intorni e questo mi semplifica prendere successioni a caso)) in $R^{2}$.\nse f √® differenziabile in un punto $(a,b) \\implies f \\text{ continua in } (a, b)$\nDobbiamo dimostrare che per ogni successione che tende a (0,0) deve essere che $f(a + h_n, b+ k_n) \\to f(a,b)$ se ho dimostrato questa cosa ho la continuit√†. Ma per il punto 2 della definizione di differenziabilit√† ho che $f(a,b) + \\langle\\nabla f(a,b), (h,k)\\rangle$ ma con h e k tendenti a 0 ho che il prodotto scalare del gradiente di esse √® tendente a 0 (anche o piccolo lo √®) , quindi ho la continuit√†.\n10.2.4 Condizione sufficiente di differenziabilit√† (!!!) Se le derivate parziali esistono e sono continue (f di classe C1) , f √® differenziabile in ogni punto\nLa definizione di differenziabilit√† non √® molto maneggevole, per questo motivo ci √® utile cercare una condizione di differenziabilit√† che sia pi√π semplice da calcolare.\nQuesto √® uno dei teoremi principali della differenziabilit√†. Collega questo con il concetto di derivata, gi√† studiata in precedenza in R\nEnunciato\nUna volta definita la funzione di classe C1 possiamo riscrivere questo enunciato in maniera pi√π compatta. Queste funzioni sono tali per cui la derivata parziale in ogni direzione esiste , e questa derivata √® anche continua (ricorda questa definizione di Classe k)\nLemma preliminare (Lagrange multivariabile)\nUtilizziamo un lemma per dimostrare il punto di sopra.\n$$ f \\in C^1(\\R^2), \\text{ siano } (a,b) \\in \\R^2, h, k \\in \\R \\implies \\exists \\alpha, \\beta \\in (0,1) | \\\\f(a + h, b) - f(a,b) = \\delta_x f(a + \\alpha h, y) h \\\\ f(a, b + k) - f(a,b) = \\delta_y f(a, b + \\beta k) k $$La dimostrazione √® analoga per i due punti, quindi lo facciamo solamnete per uno. Per il teorema di lagrange presente nei reali, mi costruisco la funzione $g(x) = f(x, t)$ con un t fissato (notiamo che g √® continua e derivabile in quanto √® costituito da f, che per ipotesi √® continua e derivabile), allora esiste c appartenente al dominio di g tale per cui $g'(c) \\cdot h = g(a + h) - g(a)$ ossia $f(a + h,b) - f(a,b)$. Ecco che appaiono i valori di cui abbiamo bisogno in RHS.\nGuardando LHS abbiamo che\n$$ g'(x) = \\lim_{s \\to 0}\\dfrac{g(x + s) - g(x)}{s} = \\lim_{s \\to 0}\\dfrac{f(x + s, t) - f(x, t)}{s} = \\delta_xf(x) $$Scrivendo c come prodotto di h e un opportuno $\\alpha$ possiamo dire che $c = a + \\alpha h$ (tanto deve stare in questo intervallo $(a, a +h)$, quindi √® possibile assumere che ci sia tale alpha compreso da 0 e 1).\nRiscrivendo il tutto per benino abbiamo la nostra tesi.\nDimostrazione\nPer definizione di differenziabilit√† devo dimostrare che ci√≤ sia vero.\n$\\langle\\nabla f(a,b), (h,k)\\rangle + o(|h, k|) = f(a + h, b + k) - f(a,b) = f(a + h, b + k) - f( a+h, b) + f(a+h, b) - f(a,b)$\nAggiungendoci e togliendo quel fattore dopo l‚Äôultima equazione, posso mettermi ad utilizzare Lagrange multivariabile (ho per il primo che x √® la stessa, per il secondo y √® la stessa).\nAndiamo a utilizzare le derivate parziali allora:\n$f(a + h, b + k) - f( a+h, b) = \\delta_yf(a+h , b+\\beta k)k$\ne in modo simile\n$f(a+h, b) + f(a,b) = \\delta_x f(a + \\alpha h, b) h$\nAllora riscriviamo la equazione iniziale, e vediamo che sia corretta effettivamente:\n$\\langle\\nabla f(a,b), (h,k)\\rangle + o(\\lvert h,k \\rvert) = \\delta_yf(a+h , b+\\beta k)k + \\delta_x f(a + \\alpha h, b) h$\nHo $h\\delta_x f(x,y) + k \\delta _yf(x,y) + o(\\lvert h,k \\rvert)$ dal gradiente. Se riesco a dimostrare questo allora ho finito.\nSe riusciamo a dimostrare $\\delta_x f(a + \\alpha h, b) h = h\\delta_x f(x,y) + o(\\lvert h, k \\rvert)$ allora ho finito (stessa cosa per l‚Äôaltra).\nL‚Äôultima proposizione √® equivalente a dire che $\\delta_x f(a + \\alpha h, b) h - h\\delta_x f(a,b) = o(\\lvert h,k \\rvert)$\novvero che (per definizione di o piccolo) quella cosa tenda a 0, ossia che.\n$$ \\lim_{h,k \\to (0,0)} \\dfrac{h}{\\lvert h, k \\rvert} [\\delta_x f(a + \\alpha h, b) - \\delta_x f(a,b)] = 0 $$$\\dfrac{h}{\\lvert h,k \\rvert} [\\delta_x f(a + \\alpha h, b) - \\delta_x f(a,b)] \\leq [\\delta_x f(a + \\alpha h, b) - \\delta_x f(a,b)]$ per le propriet√† della norma.\nOra utilizziamo la continuit√† della derivata, che si ha in ipotesi e possiamo concludere che quella differenza.\nConclusione con la continuit√† E si pu√≤ dimostrare che $a + \\alpha h, b) \\in B(a,b),\\delta)$ E l‚Äôultimo dato √® vero per ipotesi di continuit√†.\n10.3 Derivata direzionale Il concetto di derivata direzionale generalizza il concetto di derivata parziale, perch√© ora invece di andare in una direzione di una base canonica, andiamo nella direzione di un vettore.\n10.3.1 Definizione Dato $x \\in \\mathbb{R}^n$ e $v\\in \\mathbb{R}^n-\\{0\\}$, consideriamo l\u0026rsquo;insieme $\\{x + tv | t \\in \\mathbb{R}\\}$, abbiamo l\u0026rsquo;insieme di una linea, passante per il nostro punto che abbia la direzione del vettore preso.\nAllora con tutto questo iniziamo la definizione:\n$f:A \\to \\mathbb{R}, (a,b) \\in A$ e dato $v = (v_1, v_2)$ un vettore unitario, allora si ha che la derivata direzionale √®\n$$ \\lim_{t \\to 0} \\dfrac{f((a,b) + tv) - f(a,b)}{t} $$In pratica stiamo andando in una direzione scelta di v. (da notare infatti che se preso il vettore in una direzione parallela alla base canonica, allora ho le derivate parziali).\nOsservazione 2 Posso creare una funzione ausiliaria, e vedo che la derivata direzionale √® uguale alla derivata (normale 1-variabile) della funzione ausiliaria: $g(t) = f(a + tv_1, b+ tv_2)$ Si nota che $D(g(t)) = \\lim_{h \\to 0} \\dfrac{g(h) -g(0)}{h} = \\dfrac{f(a + tv_1, b+ tv_2) - f(a, b)}{h}$\n10.3.2 Formula del gradiente (!!!) Presa una funzione differenziabile con dominio opportuno e codominio R2, e un vettore in R2, possiamo definire con precisione la derivata direzionale su questo vettore in particolare √®:\n$\\dfrac{\\delta f}{\\delta v} (a,b) = \\langle \\nabla f(a,b), (v_1,v_2)\\rangle$\nOsservazione\nQuesta √® una cosa forte, perch√© mi dice che se conosco le derivate parziali riesco a trovare il valore della derivata in qualunque direzione. Ma da notare che deve essere differenziabile!.\nDimostrazione $$ f(a + tv_1, b+ tv_2) - f(a, b) = \\langle\\nabla f(a,b), tv\\rangle + o(\\lvert tv \\rvert) $$ Questo vale per la formula di Taylor, noi siamo per√≤ interessati al limite, quindi siamo interessati a questo: $$ \\lim_{t \\to 0} \\dfrac{ \\langle\\nabla f(a,b), tv\\rangle + o(\\lvert tv \\rvert )}{t} $$ Ed √® abbastanza ovvio che la soluzione di questo limite √® $\\langle\\nabla f(a,b), v\\rangle$ (basta portare fuori la t e dividerla con la t di sotto), mentre l\u0026rsquo;o-piccolo tende a 0 per definizione di o piccolo. 10.3.3 Direzione massima e minima di crescita (!!) Il problema corrente √® stabilire la direzione massima di crescita per una funzione differenziabile definita in dominio di dimensione maggiore di 0.\nDato il gradiente (consideriamo questo diverso da 0 perch√© nell\u0026rsquo;altro caso √® qualcosa di abbastanza banale). Se √® diverso da 0, posso allora normalizzare il vettore (e scriverlo con coordinate polari in un modo simile a quanto fatto in Analisi multi-variabile.\n$$ \\nabla f(a,b) = \\lvert \\nabla f(a,b) \\rvert \\cdot (\\cos\\theta, \\sin \\theta) $$Ricordiamo per punto sopra che la derivata direzionale √®\n$\\langle \\nabla f(a,b), (v_1,v_2)\\rangle$, (notiamo che v √® definito come versore, quindi possiamo passare alle cordinate polari anche l√¨, allora il valore di questa derivata direzionale √®\n$$ \\langle \\nabla f(a,b), (\\cos\\gamma,\\sin\\gamma)\\rangle = \\lvert \\nabla f(a,b) \\rvert \\cdot \\cos(\\theta - \\gamma) $$Che √® massima quanto il valore nel coseno √® 1 (coseno 0), minima quando √® 0.\nMa esiste solamente un unico vettore unitario per cui succede, questa √® la direzione che rende massima la derivata. dunque $\\theta = \\gamma$ e quindi\n$$ v_{max} = \\dfrac{\\nabla f(a,b)}{ \\lvert \\nabla f(a,b) \\rvert } $$Osservazione:\nAvendo il vettore di direzione per il massimo possiamo calcolare effettivamente il valore della derivata direzionale massima, questa √® effettivamente uguale al gradiente:\n$$ \\langle \\nabla f(a,b), v_{max})\\rangle = \\mid\\nabla f(a,b)\\mid $$10.4 Derivate di curve Consideriamo le curve (anche chiamati cammini in Rn)\nDue funzioni\nScalari da Rn a R Cammini parametrizzati (da un sottoinsieme di ab a Rn) In seguito saranno utili per comprendre gli insiemi di livello di f.\n10.4.1 Cammini I cammini sono una funzione da R a Rn.\nSono utili in fisica per descrivere il concetto di percorso (traiettoia) e simili\nVelocit√† di un cammino\npossiamo definire una dimensione di velocit√† di un cammino in questo modo:\nNota: non √® il gradiente, perch√© qui la derivata √® una sola, solo per funzioni differenti.\nQuella derivata (il vettore) √® velocit√† al tempo t.\n10.4.2 Nozioni di fisica (velocit√† e accelerazione) Velocit√† scalare:\nQuando la derivata √® nulla in tutti i punti si dice che quel punto della traiettoria √® un punto singolare\nAccelerazione:\n10.4.3 Taylor per curve Altro\n10.4.4 Derivata lungo una curva (!!) Introduzione intuitiva della derivata\nCome si nota, la curva non √® detto che sia derivabile, quindi prima la parametriziammo, e poi calcoliamo la derivata della funzione composta, e nient‚Äôaltro.\n10.4.5 Ortogonalit√† del differenziale (!) Dimostrazione veloce veloce\nCalcolo di queste derivate (idea) Se dobbiamo calcolare qualcosa di complesso, tipo\nf una funzione differenziabile, e voglio la derivata di $f(h_1(s),..., h_n(s))$ posso crearmi una funzione di appoggio, che possiamo anche chiamare la parametrizzazione della funzione come\n$r(s) = (h_1(s),...,h_n(s))$ e calcolarmi la derivata di $f(r(s))$ che abbiamo discusso sopra, alla fine avr√≤ qualcosa del tipo\n$\\delta_{e_1}f(r(s))\\delta_s(h_1(s)) + ... + \\delta_{e_n}f(r(s) \\delta_s(h_n(s))$\n","permalink":"https://flecart.github.io/notes/calcolo-differenziale/","summary":"\u003ch2 id=\"101-derivata-parziale\"\u003e10.1 Derivata parziale\u003c/h2\u003e\n\u003cp\u003eLa derivata vuole descrivere quanto varia una funzione al variare dell\u0026rsquo;input. Ma ora siamo in pi√π dimensioni, quindi vogliamo descrivere il variare dell\u0026rsquo;input come il variare della distanza euclidea\u003c/p\u003e\n\u003cp\u003e$\\dfrac{\\delta f}{\\delta x}(x,y) = \\lim _{h \\to 0} \\dfrac{f(x + h, y) - f(x, y)}{h}$ ovvero sto facendo variare solamente una variabile (la y in questo caso √® come se fosse una costante!?) Questo √® un \u003cstrong\u003erapporto incrementale su una direzione\u003c/strong\u003e.\u003c/p\u003e","title":"Calcolo differenziale"},{"content":"Nozioni da avere prima di Cambio di Base Applicazioni lineari La definizione di applicazione lineare La matrice associata L\u0026rsquo;esistenza e unicit√† di una applicazione lineare rispetto a una base Le coordinate di un punto rispetto a una base. Matrice del Cambio di Base Se ho due spazi vettoriali\nIntuizione in $R$ Le coordinate dei punti in $R$ sono uguali a $V$ per le basi canoniche, ma questo vale solamente per $R$, ora vogliamo andare a dire una cosa pi√π forte, il cambio di base Poi sar√† importantissimo questa nozione, applicazione di base in ML √® Principal Component Analysis. Se ho una applicazione lineare $F: V \\to W$ e un insieme di basi del dominio e del codominio, allora esiste una matrice $A \\in M_{m \\times n} (\\mathbb{R})$ tali che vale il cambio di base.\nQuesta matrice me la costruisco mettendo per ogni colonna le coordinate di $F(v_1)$ rispetto alla base del vettore di arrivo.\n$F(v)_{\\beta '} = A v_{\\beta}$ cio√® le coordinate di v rispetto alla base d arrivo √® uguale a una matrice (costituita dalle coordinate dell\u0026rsquo;immagine delle basi ) per il vettore coordinate iniziali.\nDal libro\n5.2.1 Matrici associate all‚Äôidentit√† Questa mÃÄatrice sono per applicazioni lineari del tipo $f:V \\to W$, $V = W$ e ele due basi sono l\u0026rsquo;identit√†. Allora la matrice associata a queste due basi √® $I_{\\beta \\beta'}$\nSe le due basi sono esattamente le stesse, allora posso dire che √® la matrice identit√†, la cosa un p√≤ cambia quando le basi sono diverse.\nOvvero se mando la stessa base, le coordinate non cambiano, quindi riesco a costruirmi abbastanza in fretta la matrice identit√†.\nOssia $I_{\\beta\\beta} = I$, che √® uguale rispetto a una base canonica qualunque.\n$$ \\begin{pmatrix} 1 \u0026 0 \\\\ 0 \u0026 1 \\end{pmatrix} $$ e simili\n5.2.2 L‚Äôinversa della composta dell‚Äôidentit√† Nel libro della prof questa √® la proposizione (8.2.2), ed √® molto importante\nSi ha che $I_{eb} = I_{be}^{-1}$, ovvero la matrice identit√† per certe basi √® esattamente l\u0026rsquo;inversa. Questo perch√© supponendo che le matrici associate si comportano bene per la moltiplicazione, ho che $I_{eb}I_{be} = I_{bb} = I$ ovvero √® l\u0026rsquo;applicazione identit√†. E bisogna anche verificare l\u0026rsquo;inverso quindi $I_{be}I_{eb} = I_{ee} = I$\n5.2.3 Coordinate di un vettore rispetto a una base non canonica Sia v un vettore nel nostro spazio, e sia b una base di Rn allora si ha che\n$(v)_{\\beta} = I_{\\beta e}^{-1}v$.\nPrendiamo in considerazione la matrice $I_{e\\beta}$, allora\n$id(v)_{\\beta} = I_{e\\beta}(v)_e$ per come abbiamo definito la matrice, ossia riusciamo a calcolarci le coordinate di v nella nuova base, utilizzando il teorema di sopra /\n5.2.4 Composizione fra matrici con basi qualsiasi Posso dimostrare che un fatto dimostrato precedentemente si comporta bene anche con basi qualsiasi.\nOvvero vogliamo dimostrare che date le funzioni $F: A \\to B, G: B\\to C$ con ognuna una base, voglio una matrice associata per la composizione di funzioni si comporti bene. (comunque s√¨ si pu√≤ dimostrare)\n5.3 Il cambio di base L\u0026rsquo;idea principale di questo cambio di base per applicazioni lineari √® ricondurci a una base voluta, pi√π comoda per i nostri calcoli, quindi passare da qualcosa in mezzo\nQuindi avremo una applicazione lineare del tipo:\n$A_{\\beta\\beta'} = I_{e'\\beta'} A_{ee'}I_{\\beta e} = I_{\\beta'e'}^{-1} A_{ee'}I_{\\beta e}$ ricordandosi che applico le funzioni a destra per prime.\n(da notare che la la matrice $I_{\\beta e}$ √® molto semplice da calcolare, perch√© l\u0026rsquo;insieme di arrivo √® canonico, e quindi √® semplice.\nAutovalori e Autovettori Moved to Autovalori e Autovettori the 19th of July 2024.\n","permalink":"https://flecart.github.io/notes/cambio-di-base/","summary":"\u003ch2 id=\"nozioni-da-avere-prima-di-cambio-di-base\"\u003eNozioni da avere prima di Cambio di Base\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"/notes/applicazioni-lineari/\"\u003eApplicazioni lineari\u003c/a\u003e\n\u003col\u003e\n\u003cli\u003eLa definizione di applicazione lineare\u003c/li\u003e\n\u003cli\u003eLa matrice associata\u003c/li\u003e\n\u003cli\u003eL\u0026rsquo;esistenza e unicit√† di una applicazione lineare rispetto a una base\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eLe coordinate di un punto rispetto a una base.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"matrice-del-cambio-di-base\"\u003eMatrice del Cambio di Base\u003c/h2\u003e\n\u003cp\u003eSe ho due spazi vettoriali\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIntuizione in $R$\nLe coordinate dei punti in $R$ sono uguali a $V$ per le basi canoniche, ma questo vale solamente per $R$, ora vogliamo andare a dire una cosa pi√π forte, il cambio di base\nPoi sar√† importantissimo questa nozione, applicazione di base in ML √® Principal Component Analysis.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eSe ho una applicazione lineare $F: V \\to W$ e un insieme di basi del dominio e del codominio, allora esiste una matrice $A \\in M_{m \\times n} (\\mathbb{R})$ tali che vale il cambio di base.\u003c/p\u003e","title":"Cambio di Base"},{"content":"1.1 Il cammino minimo 1.1.1 Definizione e caratteristiche 1.1.2 Costi negativi Sono cose molto brutte\n1.1.3 Cammino minimo semplice Costruzione di cammini minimi 1.2 Vertici 1.2.1 definizione distanza fra due vertici Costo del cammino minimo che li connette\nCondizione di bellman Albero dei cammini minimi Rilassamento Definizione Si va a vedere dove non funziona la disuguaglianza triangolare, se localmente non funziona ovvero se per esempio succede $D_{xu} + \\omega(u,y) \u003c D_{xy}$ per qualche vertice all\u0026rsquo;interno del grafo, so di per certo che la distanza $D_{xy}$ non √® una distanza, quindi possiamo riassegnarla in modo che verifichi la disuguaglianza\nBellman ford Questo algoritmo parte definendo tutti i vertici a distanza infinita, riassegna i valori partendo da un vertice prefissato.\nQuesto ragionamento √® solamente possibile con l\u0026rsquo;osservazione che il cammino √® minimo se tutti i suoi sottocammini lo sono, quindi mi sto costruendo cammini minimi da zero.\nSto riassegnando valore a tutti gli archi piano piano\u0026hellip;\nRilassamento topologico Bellman-ford con ordinamento Permette di non ripetere l\u0026rsquo;ordinamento di n vertici\nGrafi Aciclici Ordinamento topologico Dijkstra Lemma sull\u0026rsquo;espansione del grafo di esplorazione ordinamento\nPermette di non ripetere l\u0026rsquo;ordinamento di n vertici\nGrafi Aciclici Ordinamento topologico Dijkstra Lemma sull\u0026rsquo;espansione del grafo di esplorazione\n","permalink":"https://flecart.github.io/notes/cammini/","summary":"\u003ch2 id=\"11-il-cammino-minimo\"\u003e1.1 Il cammino minimo\u003c/h2\u003e\n\u003ch3 id=\"111-definizione-e-caratteristiche\"\u003e1.1.1 Definizione e caratteristiche\u003c/h3\u003e\n\u003ch3 id=\"112-costi-negativi\"\u003e1.1.2 Costi negativi\u003c/h3\u003e\n\u003cp\u003eSono cose molto brutte\u003c/p\u003e\n\u003ch3 id=\"113-cammino-minimo-semplice\"\u003e1.1.3 Cammino minimo semplice\u003c/h3\u003e\n\u003ch3 id=\"costruzione-di-cammini-minimi\"\u003eCostruzione di cammini minimi\u003c/h3\u003e\n\u003ch2 id=\"12-vertici\"\u003e1.2 Vertici\u003c/h2\u003e\n\u003ch3 id=\"121-definizione-distanza-fra-due-vertici\"\u003e1.2.1 definizione distanza fra due vertici\u003c/h3\u003e\n\u003cp\u003eCosto del cammino minimo che li connette\u003c/p\u003e\n\u003ch3 id=\"condizione-di-bellman\"\u003eCondizione di bellman\u003c/h3\u003e\n\u003ch3 id=\"albero-dei-cammini-minimi\"\u003eAlbero dei cammini minimi\u003c/h3\u003e\n\u003ch2 id=\"rilassamento\"\u003eRilassamento\u003c/h2\u003e\n\u003ch3 id=\"definizione\"\u003eDefinizione\u003c/h3\u003e\n\u003cp\u003eSi va a vedere dove non funziona la disuguaglianza triangolare, se localmente non funziona ovvero se per esempio succede $D_{xu} + \\omega(u,y) \u003c D_{xy}$ per qualche vertice all\u0026rsquo;interno del grafo, so di per certo che la distanza $D_{xy}$ non √® una distanza, quindi possiamo riassegnarla in modo che verifichi la disuguaglianza\u003c/p\u003e","title":"Cammini"},{"content":"Introduzione Intuizione del campo elettrostatico Elettrostatico vs elettrodinamico üü© Andiamo a chiamare elettrostatico perch√© nel nostro caso non si sta muovendo nessuna carica all\u0026rsquo;itnerno di questo campo.\nPropriet√† del campo elettrostatico (5) üü® Le linee di forza in ogni punto dello spazio sono tangenti e concorde al campo in quel punto; le linee di forza si addensano dove l\u0026rsquo;intensit√† del campo e maggiore; le linee di forza non si incrociano mai, in quanto in ogni punto il campo √® definito univocamente e non pu√≤ avere due direzioni distinte. le linee di forza hanno origine dalle cariche positive e terminano sul cariche negative; qualora ci siano solo cariche dello stesso segno le linee di forza si chiudono all\u0026rsquo; infinito; nel caso di cariche di segno opposto, ma eguali in modulo, tutte le linee the partono dalle cariche positive si chiudono su quelle negative (induzione completa), alcune passando eventualmente per l\u0026rsquo;infinito; se invece le cariche non sono eguali in modulo, alcune linee terminano o provengono dall\u0026rsquo; infinito. Carica esploratrice üü© √à anche chiamata carica di prova, √® una carica fittizia messa per esplorare la struttura del campo elettrico in un certo spazio\n$$ \\vec{E}(\\vec{r}) = \\lim_{ q \\to 0 } \\frac{\\vec{F}}{q} $$ in questo caso $q$ √® una carica di prova, talmente piccola che non varia il campo, utilizzato per sondare il valore del campo in un certo punto. Da un punto di vista intuitivo, costruiamo la linea passo passo, a tratti infinitesimi, e componiamo tutto lo spazio con queste.\nCampo come grandezza üü© Il campo elettrico √® proprio una grandezza fisica (ossia una propriet√† misurabile di un oggetto non √® solo una cosa comoda matematicamente), che √® solitamente utilizzata per conoscere la forza applicata dal campo elettrico in un certo punto. √à una caratteristica dello spazio e una carica √® in grado di modificare questo aspetto.\nSi rappresentano uscenti se positiva, entrante se negativa Definizione di campo elettrico üü© $$ \\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q}{R^{2}} \\hat{R} $$ Dove $Q$ √® la sorgente di carica, si pu√≤ usare il principio di sovrapposizione anche in questo caso\nFlusso di campo vettoriale üü© Dato un certo campo vettoriale, il flusso studia la relazione fra questi e una superficie a scelta. Intuitivamente si potrebbe dire quante linee di campo attraversano quella superficie.\n$$ \\phi_{S}(\\vec{F}) = \\iint_{S} \\vec{F} \\cdot d\\vec{s} = \\iint_{S} \\vec{F} \\cdot \\hat{n} \\, ds $$ Con $\\hat{n}$ indicato per marcare che deve essere orientato e perpendicolare alla superficie considerata. Esempio di vettori normali alla superficie, nel nostro esempio il valore di $\\hat{n}$.\nCampo tangenziale e parallelo üü© Questa parte la devo ancora scrivere per bene, in breve andiamo a trattare della discontinuit√† del flusso di fronte a una superficie carica, e il fatto che la circuitazione parallela √® 0. La discontinuit√† √® trattata a pagina 79 del Mazzoldi.\nQuesta parte serve per spiegare alcune propriet√† del campo nei materiali conduttori trattata in Conduttori elettrici. $$ \\Delta \\vec{E}_{\\parallel} = 0 $$ Questo √® necessario per poter spiegare la rifrazione nei mezzi, vedi Condensatori con dielettrici.\nProblemi classici Dipolo elettrico Fatto (molto) meglio in Dipolo elettrico\nIntroduzione al problema del dipolo elettrico üü© Questo sar√† uno dei nostri primi problemi (e probabilmente anche fra le pi√π semplici che ci permetteranno di analizzare il campo). Abbiamo due cariche (stessa carica assoluta), una positiva e una negativa, vogliamo andare a capire come √® fatto il campo elettrico attorno a queste cariche.\nModellizzazione del problema dipolo elettrico üü®+ $$ \\vec{E}_{tot} = \\vec{E}_{+} + \\vec{E}_{-} = \\frac{Q}{4\\pi \\varepsilon_{0}}\\left( \\frac{\\hat{R}_{+}}{R^{2}_{+}} + \\frac{\\hat{R}_{-}}{R^{2}_{-}} \\right) $$$$ \\vec{E}_{tot} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q}{R^{3}}\\left( \\left( y \\hat{j} - \\frac{d}{2} \\hat{k} \\right) - \\left( y \\hat{j} + \\frac{d}{2} \\hat{k} \\right) \\right) = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q}{R^{3}} (-d \\hat{k}) $$Il valore $-d Q\\hat{k}$ avr√† un significato speciale, sar√† il momento di dipolo\nIl momento di dipolo (2) üü© Direttamente proporzionale fra $d$, la distanza fra le cariche e $q$ la quantit√† di carica delle due. Mi da informazioni sulla geometria e sulla carica del sistema Per questo √® comodo poter analizzare un caso cos√¨ semplificato di dipolo\nDistribuzione di carica uniforme lineare infinita Questa sar√† la nostra seconda applicazione del concetto di campo e di sovrapposizione che conosciamo\nIntroduzione problema carica uniforme lineare üü© Abbiamo sull'asse $Z$ una distribuzione uniforme lineare, vogliamo cercare di capire come √® fatto il campo in questo caso #### Modellizzazione problema carica uniforme lineare infinita üü© Consideriamo un punto $P$ come in figura, sia dato un piccolissimo contributo di campo $d \\vec{E}$, vogliamo cercare di capire come √® fatto questo contributo per l'intera linea lineare. Possiamo fare una osservazione di simmetria e affermare che la componente $z$ si elimina (ad ogni carica corrisponde una uguale e contraria)., mentre la componente $x$, quella che esce o entra dal piano √® inesistente per come √® fatto il sistema $$ E_{y} = \\int \\lvert d\\vec{E} \\rvert \\cos \\theta = \\frac{\\lambda}{4\\pi\\varepsilon_{0}} \\int _{-\\infty}^{+\\infty} \\frac{dz}{r^{2}} \\cos \\theta $$$$ dz = r' \\, \\frac{ d \\tan\\theta}{d\\theta} $$ Perch√© cos√¨ abbiamo espresso totalmente l\u0026rsquo;altezza in funzione dell\u0026rsquo;angolo, √® un trick che √® stato usato molto spesso quindi √® molto importante che te lo impari.\n$$ \\int _{-\\infty}^{+\\infty} \\frac{dz}{r^{2}} \\cos \\theta = \\int _{-\\frac{\\pi}{2}}^{+\\frac{\\pi}{2}} \\frac{\\cos\\theta}{r'}d\\theta $$$$ E_{y} = \\frac{1}{2\\pi\\varepsilon_{0}} \\frac{\\lambda}{r'} $$Osservazione variare campo elettrico al variare dei problemi visti üü© Un osservazione interessante √® che il campo elettrico √®\nSingola carica -\u0026gt; $\\frac{1}{r^{2}}$ Dipolo elettrico -\u0026gt; $\\frac{1}{r^{3}}$ Lineare -\u0026gt; $\\frac{1}{r}$ Miscellanea: problemi semplici Flusso in una sfera üü© Questa √® una semplicissima applicazione della definizione di flusso. Consideriamo una sfera, poniamo il sistema di riferimento al centro di questa sfera, ci chiediamo quanto √® il flusso del campo radiale che varia come $\\vec{F} = k \\vec{r}, \\vec{r} = (x, y , z)$?\n$$ \\phi_{s}(\\vec{F}) = \\oint \\vec{F} \\cdot d\\vec{s} = \\iint k \\vec{r} \\cdot d\\vec{s} = kr \\iint ds =4\\pi r^{3}k $$Potenziale elettrostatico Mosso in Potenziale Elettrostatico il 18 Febbraio 2025.\n","permalink":"https://flecart.github.io/notes/campo-elettrico/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"intuizione-del-campo-elettrostatico\"\u003eIntuizione del campo elettrostatico\u003c/h3\u003e\n\u003ch4 id=\"elettrostatico-vs-elettrodinamico-\"\u003eElettrostatico vs elettrodinamico üü©\u003c/h4\u003e\n\u003cp\u003eAndiamo a chiamare \u003cstrong\u003eelettrostatico\u003c/strong\u003e perch√© nel nostro caso non si sta muovendo nessuna carica all\u0026rsquo;itnerno di questo campo.\u003c/p\u003e\n\u003ch4 id=\"propriet√†-del-campo-elettrostatico-5-\"\u003ePropriet√† del campo elettrostatico (5) üü®\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003eLe linee di forza in ogni punto dello spazio sono tangenti e concorde al campo in quel punto;\u003c/li\u003e\n\u003cli\u003ele linee di forza si addensano dove l\u0026rsquo;intensit√† del campo e maggiore;\u003c/li\u003e\n\u003cli\u003ele linee di forza non si incrociano mai, in quanto in ogni punto il campo √® definito univocamente e non pu√≤ avere due direzioni distinte.\u003c/li\u003e\n\u003cli\u003ele linee di forza hanno origine dalle cariche positive e terminano sul cariche negative; qualora ci siano solo cariche dello stesso segno le linee di forza si chiudono all\u0026rsquo; infinito;\u003c/li\u003e\n\u003cli\u003enel caso di cariche di segno opposto, ma eguali in modulo, tutte le linee the partono dalle cariche positive si chiudono su quelle negative (\u003cstrong\u003einduzione completa\u003c/strong\u003e), alcune passando eventualmente per l\u0026rsquo;infinito; se invece le cariche non sono eguali in modulo, alcune linee terminano o provengono dall\u0026rsquo; infinito.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4 id=\"carica-esploratrice-\"\u003eCarica esploratrice üü©\u003c/h4\u003e\n\u003cp\u003e√à anche chiamata \u003cstrong\u003ecarica di prova\u003c/strong\u003e, √® una carica \u003cem\u003efittizia\u003c/em\u003e messa per esplorare la \u003cstrong\u003estruttura del campo elettrico\u003c/strong\u003e in un certo spazio\u003c/p\u003e","title":"Campo elettrico"},{"content":"This note briefly states and proves one of the most famous inequalities in geometry/analysis.\nTheorem Statement $$ \\left( \\sum_{i = 1}^{n} x_{i}y_{i} \\right) ^{2} \\leq \\left( \\sum_{i= 1}^{n} x^{2}_{i} \\right) \\left( \\sum_{i = 1}^{n} y^{2}_{i} \\right) $$$$ \\lvert \\langle u, v \\rangle \\rvert ^{2} \\leq \\langle u, u \\rangle \\cdot \\langle v, v \\rangle $$ with $u = \\left( x_{1}, \\dots, x_{n} \\right)$ and $v = \\left( y_{1}, \\dots, y_{n} \\right)$ and the $\\langle \\cdot, \\cdot \\rangle$ operator is the inner product. We have equality if and only if $u$ and $v$ are linearly dependent (this one is easy to prove if seen from the vectorial view).\nThere are many possible proofs, but the easy one is just doing some counts:\nProof: direct counts This is the most stupid proof possible, just expand every possible count!\nFrom the hypothesis, we have that\n$$ \\sum_{i = 1}^{n}(x^{2}_{i}y^{2}_{i}) + \\sum_{i \\neq j}^{n} (x_{i}y_{i}x_{j}y_{j}) \\leq \\sum_{i = 1}^{n}(x^{2}_{i}y^{2}_{i}) + \\sum_{i \\neq j}^{n} (x_{i}^{2}y^{2}_{j}) $$$$ \\sum_{i \\neq j}^{n} (x_{i}y_{i}x_{j}y_{j}) = 2\\sum_{i \u003c j}^{n} (x_{i}y_{i}x_{j}y_{j}) \\leq^{?} \\sum_{i \\neq j}^{n} (x_{i}^{2}y^{2}_{j}) $$$$ \\left( x_{i}y_{j} - x_{j}y_{i} \\right) ^{2} \\geq 0 \\implies x^{2}_{i}y^{2}_{j} + x^{2}_{j}y^{2}_{i} - 2x_{i}y_{i}x_{j}y_{j} \\geq 0 \\implies x^{2}_{i}y^{2}_{j} + x^{2}_{j}y^{2}_{i} \\geq 2x_{i}y_{i}x_{j}y_{j} $$ And when you sum up for all the couples $(i, j)$ you get the above inequality. This also tells you why it\u0026rsquo;s easy to check if $x_{i} = \\lambda y_{i}$ for some $\\lambda \\in \\mathbb{R}$ then the above sum is 0, so we have equality.\nDrawback: this proof works only on a specific inner product, general proof shouldn\u0026rsquo;t assume something about the product, but you get the gist of why it does work in this case anyway.\nProof: general approach Let\u0026rsquo;s consider the function $f(t) = \\lVert u - tv \\rVert^{2}$, we observe that $\\forall t \\in \\mathbb{R}$ we have that $f(t) \\geq 0$. Now let\u0026rsquo;s expand this product\n$$ f(t) = \\langle u - tv, u - tv \\rangle = \\langle u, u \\rangle - 2t \\langle u, v \\rangle + t^{2} \\langle v, v \\rangle = t^{2} \\lVert v^{2} \\rVert - 2 \\langle u, v \\rangle t + \\lVert u^{2} \\rVert $$Now we use high school knowledge, as the function is always non-negative and it\u0026rsquo;s a simple $\\mathbb{R} \\to \\mathbb{R}$ function, we know that the discriminant should be non-positive, which means $b^{2} - 4ac \\leq 0$, let\u0026rsquo;s impose this condition on the function and we\u0026rsquo;ll have that:\n$$ 4\\lvert \\langle u, v \\rangle \\rvert ^{2} - 4 \\lVert v^{2} \\rVert \\lVert u^{2} \\rVert \\leq 0 \\implies \\lvert \\langle u, v \\rangle \\rvert ^{2} \\leq \\langle u, u \\rangle \\cdot \\langle v, v \\rangle $$ Which ends the proof $\\square$.\nApplications In this section I would like to list some known applications of this inequality. The inequality is a classical one, so one should expect many applications. I will try to expand this section when I see some during my studies.\nCovariance-Variance relations $$ Cov(X, Y)^{2} \\leq Var(X) Var(Y) $$$$\\rho_{X, Y} = \\frac{Cov(X, Y)}{\\sqrt{ Var(X) Var(Y) }}$$$$\\mathbb{E}_{x, y}[XY]^{2} \\leq \\mathbb{E}_{x}[X^{2}]\\mathbb{E}_{y}[Y^{2}]$$ In order to apply this, you just need to see that the expectation operator can be viewed as a inner product on the space of random variables, so let\u0026rsquo;s prove this first: Let\u0026rsquo;s consider a probability space $(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ the sample space, $\\mathcal{F}$ the sigma algebra and $\\mathbb{P}$ the probability measure on this space, let\u0026rsquo;s also define $X, Y$ to be random variables, i.e. functions from $\\Omega$ to $\\mathbb{R}$. In order to prove that the expectation operator is a inner product we need to check three conditions:\nLinearity Symmetry Positive definiteness They should be all trivial to verify, so we move on. Now that we have this link, it\u0026rsquo;s easy to prove the original construct with covariance and variance: we just need to substitute the correct variables.\n","permalink":"https://flecart.github.io/notes/cauchy-schwarz-inequality/","summary":"\u003cp\u003eThis note briefly states and proves one of the most famous inequalities in geometry/analysis.\u003c/p\u003e\n\u003ch3 id=\"theorem-statement\"\u003eTheorem Statement\u003c/h3\u003e\n$$\n\\left( \\sum_{i = 1}^{n} x_{i}y_{i} \\right) ^{2} \\leq \\left( \\sum_{i= 1}^{n} x^{2}_{i} \\right)  \\left( \\sum_{i = 1}^{n} y^{2}_{i} \\right)\n$$$$\n\\lvert \\langle u, v \\rangle  \\rvert ^{2} \\leq \\langle u, u \\rangle  \\cdot \\langle v, v \\rangle \n$$\u003cp\u003e\nwith $u = \\left( x_{1}, \\dots, x_{n} \\right)$ and  $v = \\left( y_{1}, \\dots, y_{n} \\right)$  and the $\\langle \\cdot, \\cdot \\rangle$ operator is the \u003ca href=\"/notes/inner-product-spaces/\"\u003einner product\u003c/a\u003e.\nWe have equality if and only if $u$ and $v$ are linearly dependent (this one is easy to prove if seen from the vectorial view).\u003c/p\u003e","title":"Cauchy-Schwarz Inequality"},{"content":"Bounds Markov Bound $$ P(X \\geq y) \\leq \\frac{E[X]}{y} $$$$ yP(X \\geq y) = y\\int _{x =y}^{+\\infty} f(x) \\, dx \\leq \\int _{x=y}^{+\\infty} x f(x) \\, d \\leq \\int _{-\\infty}^{+\\infty}xf(x) \\, d = E[X] $$ Il che finisce la dimostrazione.\nChebychev Bound $$ P(\\lvert x - E[X] \\rvert \\geq y) \\leq \\frac{\\sigma^{2}}{y^{2}} $$ E in pratica dice che all\u0026rsquo;infinito viene tutto compattata sul valore atteso La dimostrazione √® abbastanza semplice, si sostituisce $(x - E[X])^{2}$ su $X$ di Markov e $\\varepsilon^{2}$ a $y$ e poi si dovrebbe gi√† avere il risultato\nChernoff Bound $$ P(Z \\geq t) \\leq \\inf_{s \u003e 0} e^{-st} M_{Z}(s) = \\inf_{s \u003e 0} e^{-st} E[e^{sZ}] $$Moments of random variable $$ M_{X}(\\lambda) = E[\\exp(\\lambda X)] $$$$ e^{tX} = 1 + tX + \\frac{t^{2}X^{2}}{2!} + \\frac{t^{3}X^{3}}{3!} + \\dots $$ Quindi per esempio se volessimo il primo momento, prendiamo la derivata rispetto a $t$e settiamo $t=0$, perch√© la cosa molto bella √® che i coefficienti si cancellano tutti, e l\u0026rsquo;unico termine che rimane senza $t$ √® il momento cercato, per questo motivo estraiamo easy i momenti.\nDimostrazione Chernoff\u0026rsquo;s Bound $$ P(Z \\geq t) \\leq \\inf_{s \u003e 0} e^{-st} M_{Z}(s) = \\inf_{s \u003e 0} e^{-st} E[e^{sZ}] $$ Guardandolo dall\u0026rsquo;altro in basso non ho idea del perch√© valga.\n$$ P(Z \\geq t) = P(e^{sZ} \\geq e^{st}) \\leq \\frac{E[e^{sZ}]}{e^{st}} $$ Dove $s$ √® qualunque $s \u003e 0$ perch√© per quello la funzione resta crescente, e quindi la dimostrazione vale ancora. La cosa interessante di questo bound √® che la probabilit√† che succeda scende in modo esponenziale.\nHoeffding\u0026rsquo;s Inequality $$ P(\\lvert S_{n} - \\mathbf{E}[S_{n}] \\rvert \\geq t) \\leq 2e^{-2t^{2}/\\sum(b_{i} - a_{i})^{2} } $$ Questo ci dice quanto velocemente la media converge nel valore atteso che ci aspettiamo per la legge dei grandi numeri.\nSimpler form $$ P(\\lvert S_{n} - \\mathbf{E}[S_{n}] \\rvert \\geq t) \\leq 2e^{-2Nt^{2}/C^{2} } $$Ci permette di avere un bound su accuratezza in funzione del numero di samples che andiamo a prendere.\nLa dimostrazione di questo mi sembra abbastanza tecnica, c\u0026rsquo;√® bisogno di guardare https://web.eecs.umich.edu/~cscott/past_courses/eecs598w14/notes/03_hoeffding.pdf Oppure https://cs229.stanford.edu/extra-notes/hoeffding.pdf.\nNon ho bene capito l\u0026rsquo;utilit√† se non nel caso Bernoulliano in cui sembra si semplifichi abbastanza questo.\nThis inequality has been proven quite useful. See Provably Approximately Correct Learning, Tabular Reinforcement Learning.\nHoeffding\u0026rsquo;s Lemma $$ \\mathbb{E}[e^{sX}] \\leq \\exp \\left( {\\frac{s^{2}(b - a)^{2}}{8}} \\right) $$Proof of Hoeffding\u0026rsquo;s Inequality TODO.\nLaw of Large numbers Weak Law La dimostrazione di questo √® molto semplice, basta avere Chebicheff\nQuesta √® l\u0026rsquo;intuizione di quanto presente nell WLLN Abbiamo mean square convergence.\nAbbiamo che vale:\n$$ \\mathbb{P}\\left( \\left( \\frac{S_{n} - n\\bar{X}}{n} \\right)^{2} \u003e y \\right) \\leq \\frac{\\sigma^{2}_{X}}{ny} $$ E poi settando $y = \\varepsilon^{2}$ si pu√≤ avere il risultato. Nella forma corretta. Vedere capitolo 1.5 in questo.\n$$ \\lim_{ n \\to \\infty } E \\left[ \\left( \\frac{S_{n}}{n} - \\bar{X} \\right)^{2} \\right] = 0 $$ In questo senso possiamo dire che la successione $S_{n}$ arriver√† sempre alla media.\nRicordiamo che $S_{n} = X_{1} + X_{2} + \\dots + X_{n}$. Dove tutte le variabili $X_{i}$ sono IID con media $\\bar{X}$ e varianza $\\sigma^{2}$.\nWeak law without finite variance $$ \\lim_{ n \\to \\infty } \\mathbb{P}\\left( \\mid \\frac{S_{n}}{n} - E[X]\\mid \u003e \\varepsilon \\right) = 0 $$ Teorema 1.5.3 nelle note. Questa √® la convergenza in probabilit√† della serie di variabili aleatorie. Con strumenti pi√π avanzati √® possibile dimostrare anche la convergenza con probabilit√† 1 anche in casi di varianza infinita. Questa √® l\u0026rsquo;unica differenza con la versione Strong della legge dei grandi numeri.\nConvergence types We need a lot of care when defining the notions of convergence for probability distributions because the same ideas that applied to the real numbers do not apply here anymore. For example, in calculus if we have a sequence $x_{1},\\dots,x_{n}\\dots$ such that $\\forall i \\in \\mathbb{N}, x_{i} = x$ for a certain $x$ it\u0026rsquo;s clear that $\\lim_{ n \\to \\infty }x_{n} = x$, by that definition. The same does not apply if we take a sequence of normally distributed random values $X_{1}, \\dots, X_{n}\\dots$, this does not converge to the distribution $X \\sim\\mathcal{N}(0, 1)$ in the classical sense, because we can\u0026rsquo;t directly compare them. For instance $P(X_{n} = X) = 0$ because both are continuous random variables, and the probability of it is always zero for the integral has zero length. This is why it\u0026rsquo;s important to distinguish various types of convergence in probability.\nConvergence in distribution $$ \\lim_{ n \\to \\infty } F_{Z_{n}}(z) = F_{Z}(z) $$$$ Z_{n} = \\frac{S_{n} -n\\bar{X}}{\\sigma \\sqrt{ n }} $$ Converge alla normale, 0, 1 gaussiana. Un altro esempio √® la weak law of large numbers, in cui $\\frac{S_{n}}{n}$ converge a $\\bar{X}$.\nConvergence in probability $$ \\lim_{ n \\to \\infty } P(\\mid Z_{n} - Z\\mid \u003e \\varepsilon) = 0 $$ So we care about the value of the single probability. Vale anche qui l\u0026rsquo;esempio della WLLN.\nConvergence in mean square $$ \\lim_{ n \\to \\infty } E[(Z_{n} - Z)^{2}] = 0 $$ La nota √® che Mean Square -\u0026gt; Convergence probability -\u0026gt; Convergence in distribution. This is usually useful just to prove the convergence in probability.\nConvergence almost everywhere (Il prof. lo chiama with probability 1 e secondo lui serve sapere measure theory per poter comprendere la definizione originale).\nDefiniamo una sequenza $Z_{1}, Z_{2}, \\dots$ e $\\Omega$ il suo spazio campionatorio e sia $Z$ una altra variabile aleatoria, allora la sequenza converge con probabilit√† 1 se vale\n$$ \\mathbb{P}(\\{\\omega \\in \\Omega : \\lim_{ n \\to \\infty }Z_{n}(\\omega) = Z(\\omega) \\}) = 1 $$ Ossia, per definizione di variabile aleatoria $Z_{n}(\\omega)$ √® un valore reale, queste sequenze di numeri reali a volte convergono, se convergono vogliamo che il valore sia esattamente $Z(\\omega)$. Quello che vogliamo dire con questo √® che la probabilit√† degli elementi dello spazio campionatorio che creano sequenze che convergono √® uguale a 1.\nCentral Limit Theorem By Lindeberg-L√©vy. It is possible to estimate the distribution of the average of the random variable.\nThe Bernoulli Case The theorem $$ \\lim_{ n \\to \\infty } \\left[ \\mathbb{P}\\left( \\frac{S_{n} - n\\bar{X}}{\\sqrt{ n }\\sigma} \\leq y \\right)\\right] = \\int_{-\\infty}^{y} \\frac{1}{\\sqrt{ 2\\pi }} \\exp\\left( -\\frac{x^{2}}{2} \\right) \\, dx $$$$ Z_{i} = \\frac{S_{i} - n\\bar{X}}{\\sqrt{i} \\sigma} $$ Converger√† alla gaussiana normale. √à un motivo per cui √® una distribuzione molto importante.\n$$ \\sqrt{ n } (\\bar{X} - \\mu) \\overset{d}\\to \\mathcal{N}(0, \\sigma^{2}) $$ La cosa importante da ricordare √® che per distribuzioni con varianza finita avremo una distribuzione normale con varianza zero e concentrata sulla media, mentre per distribuzioni con varianza infinita avremo una distribuzione anche l√¨ con heavy-tail (che √® il motivo per cui ha varianza infinita), il che significa che avremo una altra distribuzione con varianza infinita.\n","permalink":"https://flecart.github.io/notes/central-limit-theorem-and-law-of-large-numbers/","summary":"\u003ch2 id=\"bounds\"\u003eBounds\u003c/h2\u003e\n\u003ch3 id=\"markov-bound\"\u003eMarkov Bound\u003c/h3\u003e\n$$\nP(X \\geq y) \\leq \\frac{E[X]}{y}\n$$$$\nyP(X \\geq y) = y\\int _{x =y}^{+\\infty} f(x) \\, dx \\leq \\int _{x=y}^{+\\infty} x f(x) \\, d \\leq \\int _{-\\infty}^{+\\infty}xf(x) \\, d = E[X]  \n$$\u003cp\u003e\nIl che finisce la dimostrazione.\u003c/p\u003e\n\u003ch3 id=\"chebychev-bound\"\u003eChebychev Bound\u003c/h3\u003e\n$$\nP(\\lvert x - E[X] \\rvert  \\geq y) \\leq \\frac{\\sigma^{2}}{y^{2}}\n$$\u003cp\u003e\nE in pratica dice che all\u0026rsquo;infinito viene tutto compattata sul valore atteso\nLa dimostrazione √® abbastanza semplice, si sostituisce $(x - E[X])^{2}$ su $X$ di Markov e $\\varepsilon^{2}$ a $y$ e poi si dovrebbe gi√† avere il risultato\u003c/p\u003e","title":"Central Limit Theorem and Law of Large Numbers"},{"content":"7.1 Introduzione 7.1.1 Perch√© usarli Sono utili per mantenere delle informazioni nel tempo\n7.1.2 Caratteristiche Hanno feedback cio√® ci sono degli output che tornano dentro al circuito, quindi √® molto difficile senza sapere niente cosa succede dentro\nQuesto circuito non √® combinatorio, che √® formalizzabile in modo deterministico con l\u0026rsquo;lgebra booleana.\n7.1.3 Il Bit di memoria Questo bit ha due input, un load e un input, se il load √® attivo comincia a storare, altrimenti l\u0026rsquo;output √® sempre il bit che ha memoriazzato.\n7.2 Latch 7.2.1 Latch SR Con 0 0, qualunque bit ci sia, rimane sto bit che gira.\n1 1 = reset, 0 0 , NON FARLO\nQuesto √® uno dei pi√π semplici circuiti non sequenziali. Se l\u0026rsquo;input sono diversi fra di loro, allora sappiamo cosa esce,\nMa nel caso in cui l\u0026rsquo;input √® 0 0 oppure 1 1 allroa non va bene.\n7.2.2 Latch SR temporizzato e clock Il clock serve per stabilizzare la ram, il clock (voglio prendere solamente dei valori che siano stabili)\n7.2.3 Latch D Questo latch possiede un unico input per impedire che sia possibile che si verifichi\nil caso 1, 1, che non ci piace.\n7.2.4 D-Flip Flop √à uguale al Latch D ma solo con qualcosa in pi√π, dovrebbe sempre tornare in Zero il clock, per√≤ il Not ha un p√≤ di delay, che permette un velocissimo segnale a passare\nQuindi questo circuito carica solamente quando c\u0026rsquo;√® il clock che gli va, e permette il loading di qualcosa, quindi effettivamente riesce a mantenere il bit in memoria.\nQUesto √® migliore perch√© con il flipflop ho pi√π tempo per far stabilizzare i dati, invece di poter caricare per l\u0026rsquo;intero tempo in cui clock √® su, posso farlo in un solo piccolo frangente (ma sufficiente)\nHo un intero ciclo di clock per farlo stabilizzare, invece per il latch solo met√† (in quanto l\u0026rsquo;altra met√† √® di caricamento)\n7.3 Registri e RAM 7.3.1 Registro Questi il DFF √® il componente principale per il registro, che messo insieme ad altro √® in grado di creare la memoria RAM necessaria per far funzionare.\nin\nX\n0\n0\n1\n1\nload\nX\n0\n1\n0\n1\nclock\nNull\nSalita\nSalita\nSalita\nSalita\nout[N]\nMem\nout[N-1]\n0\nout[N-1]\n1\nDa notare che l\u0026rsquo;out vale il valore di in solo nel caso in cui il load √® 1 e il clock sta permettendo di salvare il dato.\nPer il resto √® sempre memoria.\n7.3.2 Program counter 7.3.3 chip RAM Il ram √® costruito da una serie di registri. In Input pu√≤ avere il valore in in, l\u0026rsquo;indirizzo in cui si vuole scrivere e un booleano che dice se vogliamo scrivere o no.\nCi saranno demultiplexer che indirizzeranno l\u0026rsquo;in al registro giusto. In out ho solamente l\u0026rsquo;out di questo registro, quindi devo anche filtrare fra l\u0026rsquo;output di tutti gli altri registri in quanto voglio solamente uno.\n7.4 Il microprocessore HACK In questo schema si possono vedere tutti gli elementi principali per il processore HACK, come ALU, program counter, il decoder e simil.\nUna caratteristica principale √® la ROM di HACK (noi oggi abbiamo solamente una ROM per boostrap, ma invece in HACK deve avere solo ROM per le istruzioni).\noutM √® il mit della memoria che viene fuori\n7.4.1 Accesso ai dati in memoria S, D, RAM Questa parte si pu√≤ considerare un approfondimento di una zona in Memoria.\nParliamo d SRAM e DRAM.\nSRAM si parla di Cache, sono pi√π costose rispetto alle memorie ram dinamiche\nDRAM √® la memoria principale, fatte con transistor e un condensatore. (contiene una carica per un p√≤ di tempo)\nEcco che allora DRAM ha bisogno di Refresh! In modo che il condensatore venga ricaricato.Questo rallenta anche la velocit√† del ram, ma si guadagna in economia\n7.5 Altro Abbiamo fatto anche altro riguardo a questa lezione.\nDa notare principalmente √® il funzionamento della cache qui di cui abbiamo anche fatto degli esercizi.\nPoi la predizione di pipelining distrutta dai salti nelle istruzioni presentata qui almente √® il funzionamento della cache qui di cui abbiamo anche fatto degli esercizi.\nPoi la predizione di pipelining distrutta dai salti nelle istruzioni presentata qui\n","permalink":"https://flecart.github.io/notes/circuiti-sequenziali/","summary":"\u003ch2 id=\"71-introduzione\"\u003e7.1 Introduzione\u003c/h2\u003e\n\u003ch3 id=\"711-perch√©-usarli\"\u003e7.1.1 Perch√© usarli\u003c/h3\u003e\n\u003cp\u003eSono utili per mantenere delle informazioni nel tempo\u003c/p\u003e\n\u003ch3 id=\"712-caratteristiche\"\u003e7.1.2 Caratteristiche\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eHanno feedback\u003c/strong\u003e cio√® ci sono degli output che tornano dentro al circuito, quindi √® molto difficile senza sapere niente cosa succede dentro\u003c/p\u003e\n\u003cp\u003eQuesto circuito non √® combinatorio, che √® formalizzabile in modo deterministico con l\u0026rsquo;lgebra booleana.\u003c/p\u003e\n\u003ch3 id=\"713-il-bit-di-memoria\"\u003e7.1.3 Il Bit di memoria\u003c/h3\u003e\n\u003cp\u003eQuesto bit ha due input, un load e un input, se il load √® attivo comincia a storare, altrimenti l\u0026rsquo;output √® sempre il bit che ha memoriazzato.\u003c/p\u003e","title":"Circuiti Sequenziali"},{"content":"Introduzione a OOP Per la definizione di classe andare a guardare Object orientation, per√≤ lo ripeto in questa occasione, √® solamente un modello su cui andare a costruire degli oggetti.\nCapisaldiüü© Incapsulazione Astrazione Ereditariet√† Dispatch dinamico Costruttori üü©- Il costruttore √® un codice utilizzato per inizializzare correttamente lo stato interno. Le regole sono le stesse dei metodi sovraccaricati (dinamica per la chiamata, statica per il numero dei parametri che prende in input).\nIncapsulazione Carat incapsulazione üü© ossia la distinzione fra pubblico e privato, il fatto che posso decidere quanto nascondere e quanto esporre. All\u0026rsquo;esterno sono esposte solamente le interfacce che sono solitamente pubblici.\nSolamente le cose dichiarate come pubbliche sono esposte, mentre tutto lo stato interno √® nascosto e non √® accessibile all\u0026rsquo;esterno.\nSottotipi (liskov) üü© Questo √® il principio di sostituzione di liskov, che in pratica ci dice che se S √® sottotipo di T, allora posso utilizzare S in qualunque posto di T.\nSe utilizizmao una notazione matematica, allora se ho unap ropriet√† per un oggetto in T allora questa propriet√† vale anche per un oggetto in S.\nDifferenza tipo e classe üü© C\u0026rsquo;√® una differenza fra struttura delle operazioni (quindi il tipo, cosa prendo e cosa ritorno) con l‚Äôimplementazione effettiva delle funzioni, i check per privati e pubblici (implementati dalle classi). Quando dichiariamo alla classe √® come se dichiarassimo allo stesso momento una interfaccia per essa.\nconsideriamo la definizione di una classe come accompagnata da una definizione implicita di un\u0026rsquo;interfaccia della vista pubblica di quella classe.\nIn questo senso la classe diventa un elemento nel nostro sistema dei tipi.\nAstrazione (!) üü© La nozione di astrazione √® strettamente legata all\u0026rsquo;interfaccia implicita che la classe induce.\nL‚Äôastrazione di permette di andare ad elaborare con alcuni concetti che nativamente non esistono, per esempio non esiste nativamente il tipo Euro, ma pu√≤ essere implementata attraverso il tipo concreto degli interi. Le classi forniscono delle interfacce che permettono una modifica controllata dell‚Äôoggetto che viene rappresentato, questo √® il significato di astrazione.\nle interfacce ci permettono di fornire ai clienti una descrizione del \u0026ldquo;contratto\u0026rdquo; che i nostri oggetti promettono di soddisfare, senza costringerci a fornire la loro effettiva implementazione.\nossia descrive ci√≤ che prende in input, ci√≤ che deve andare a ritornare. senza dire esattamente come √® implementata quella logica.\nClassi astratte üü© Sono una via di mezzo fra interfaccia e classe nel senso che possono lasciare delle funzioni non implementate\nEreditariet√† Sottotipaggio ed ereditariet√† (2) Ci sono due keyworks principali quando andiamo a parlare di sottotipaggoi ed ereditariet√†, sono extends and implements.\nExtends: prende anche i metodi (proprio l\u0026rsquo;implementazione) di tutti metodi e gli stati del genitore. Doppia operazione: Relazione di sottotipaggio col tipo da cui estende Prendere tutti i metodi dichiarati sono presenti ora anche qui. Implements: crea l\u0026rsquo;implementazione dell‚Äôinterfaccia astratta. C\u0026rsquo;√® una leggera differenza fra queste keywords se utilizzate per interfacce oppure per classi. Credo l\u0026rsquo;unica cosa che cambia √® che per extends nelle classi mi porto dietro anche stati e funzioni e anche i vincoli di incapsulamento.\nIn breve: sottotipi parlano di operazioni, e manipolazione i interfacce fre la varie classi, mentre l‚Äôereditariet√† va a parlare di metodi che possono essere utilizzate o meno.\nDifferenza principale fra sottotipaggio ed ereditariet√†\nShadowing Come gestire i casi di ereditariet√† in cui una stessa variabile √® stata dichiarata con esattamente lo stesso nome?\nRegole di scoping statico! In pratica il parent √® visto come uno scope pi√π esterno, e si risolve in questo modo.\nOverriding dei metodi Coerentemente al principio di astrazione, posso cambiare il contenuto (quindi la semantica) di una funzione senza cambiarne la signature, sulla stessa logica posso reimplementare un metodo in un child class.\nUna differenza tra l\u0026rsquo;overriding dei metodi e lo shadowing delle variabili √® che il primo √® risolto dinamicamente, mentre il secondo √® risolto staticamente.\nModificatori di visibilit√† (2) Ci sono dei modi per andare a modificare la visibilit√† durante le relazioni di ereditariet√† fra le classi, queste son ooil packaged e protected\npackaged: se sei un figlio allora puoi vedere i metodi privati (tutto lo stesso pacchetto pu√≤ vedere questi metodi. Protected: tutte le sottoclassi, anche in moduli diversi possono utilizzare le funzioni ereditate protected, solo che l\u0026rsquo;esterno non pu√≤ comunque andare ad accederci. Tipi intersezione Questi tipi intersezione prendono in input due classi e creano una classe che abbia entrambe le caratteristiche delle due classi. Sono diverse dai tipi unione, perch√© questi tipi unione possono essere o uno o l‚Äôaltro, nel senso che non sono entrambi in contemporanea!.\nIn un certo senso sono concatenati questi valori. Una cosa interessante √® che il grafico delle inheritance √® un DAG\nEreditariet√† multipla problemi: diamante Slide introduzione dei problemi di ereditariet√† (2 sol)\nQuesta implementazione ha molti problemi quando eredito due cose che hanno una intersezione, come per esempio un metodo con lo stesso nome. Allora come si risolve questo problema?\nIl problema principale √® la diamond of death\nDynamic dispatch Early and late binding Late: quando ho l‚Äôoggetto io vado a cercare l‚Äôoggetto, se lo trovo allora lo eseguo, se non c‚Äô√® allora continuo la ricerca finch√© non lo trovo, allora do errore: √® una cosa molto simile al prototyping.\nEarly: Utilizza infomrazioni statiche per risolvere l‚Äôambiguit√†, questo dovrebbe farlo C per esempio.\nMetodi statici Niente ci vieta di andare a definire dei metodi statici che vengono risolti in modo statico.\nImplementazione degli oggetti (link) SI potrebbe tenere una lista linkata fra tutte le ereditariet√†, solo che diventa una cosa molto lenta, perch√© potrebbero esserci molti accessi: vado a cercare fino al top se ci sia o meno questo metodo per una certa classe.\nEarly and late binding Accesso via offset: per accedere allo stato, faccio in modo molto simile alle struct, che in pratica vanno a calcolare offset rispetto a qualcosa, il calcolo dell‚Äôoffset per il singolo stato √® molto veloce, una cosa leggermente pi√π complicata √® la ricerca del metodo corretto, se questo √® stato sovrascritto o simile. (fa ricerca lineare, va su finch√© non trova il metodo.\nCHIAMATA DEL METODO\nNon solo vogliamo andare a creare uno stack frame, variabili locali e parametri abbiamo in pi√π anche le variabili di istanza! Semplicemente prende il this e ci applica l‚Äôoffset per prendere le informazioni, le slides lo fanno molto pi√π complicato.\nVtables(!!) Ogni oggetto ha un puntatore alla propria vtable della propria classe, con gi√† tutti i puntatori alle funzioni corrette per le funzioni.\nSlides ereditariet√†\nDovrebbe funzionare solamente per ereditariet√† singola, non so per la multipla come funziona questa della vtable.\nClasse base fragile C‚Äô√® il problema della composizionalit√†, nel senso che non possiamo andare a compilarli in modo diverso, se cambiamo una classe padre, allora bisogna andare a ricompilare tutti childs, √® un problema di ingegneria del software questo.\nType parameter erasure In Java fragile Ci sono alcuni metodi per andare a gestire il problema della classe fragile. Come gestire questo problema quando l\u0026rsquo;intera classe √® stata compilata a s√© stante. Viene risolto a caricamento e la prima reference viene risolta e sostituita al codice di ricerca col riferimento al codice effettivo.\n","permalink":"https://flecart.github.io/notes/classi-oop/","summary":"\u003ch2 id=\"introduzione-a-oop\"\u003eIntroduzione a OOP\u003c/h2\u003e\n\u003cp\u003ePer la definizione di classe andare a guardare \u003ca href=\"/notes/object-orientation/\"\u003eObject orientation\u003c/a\u003e, per√≤ lo ripeto in questa occasione, √® solamente un modello su cui andare a costruire degli oggetti.\u003c/p\u003e\n\u003ch3 id=\"capisaldi\"\u003eCapisaldiüü©\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eIncapsulazione\u003c/li\u003e\n\u003cli\u003eAstrazione\u003c/li\u003e\n\u003cli\u003eEreditariet√†\u003c/li\u003e\n\u003cli\u003eDispatch dinamico\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"costruttori--\"\u003eCostruttori üü©-\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Classi OOP/Untitled.png\" alt=\"image/universita/ex-notion/Classi OOP/Untitled\"\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Classi OOP/Untitled 1.png\" alt=\"image/universita/ex-notion/Classi OOP/Untitled 1\"\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Classi OOP/Untitled 2.png\" alt=\"image/universita/ex-notion/Classi OOP/Untitled 2\"\u003e\n\u003cp\u003eIl costruttore √® un codice utilizzato per \u003cstrong\u003einizializzare correttamente lo stato\u003c/strong\u003e interno. Le regole sono le stesse dei metodi sovraccaricati (dinamica per la chiamata, statica per il numero dei parametri che prende in input).\u003c/p\u003e","title":"Classi OOP"},{"content":"Introduzione a Crittografia al corso di crittografia di Christof Paar su Youtube, con aggiunte del corso Unibo.\nClassifications and definitions Classification nowadays as many many applications like, and it‚Äôs a increasing important field\nCryptology (2) üü© La branca comunemente riferita come crittografia √® divisa principalmente in due campi crittografia e cryptanalysis in cui una cerca di creare nuovi metodi per cifrare i messaggi, e l‚Äôaltro prova ad attaccare questi messaggi ritrovando il messaggio originale.\nRelazione con Sicurezza informatica üü© Questo campo si pu√≤ considerare una piccola branca della sicurezza informatica, che √® praticamente necessaria per la sicurezza, per√≤ allo stesso tempo non pu√≤ essere utilizzata da sola, ha bisogno anche di sistemi operativi sicuri, hardware sicuro etc‚Ä¶\nCryptography üü© Questo √® quello che ci interessa, ed √® ci√≤ che il corso tratta.\nSymmetrical ciphers Asymmetrical ciphers Protocols Classification of cryptoattacks 3 üü©- We define attack vector as a possible way to attack a cipher\nClassical Cryptanalisys Bruteforce Analytical attacks (Properties of the Cipher, useful to decrypt it) Social engineering (like a people that gives you the key) (phishing) Implementation attacks (Attack hardware to discover key) Side channel analysis (eg. power consumption related to the key). Ovviamente questi sono molto diversi rispetto ai reali (nella vita reale ci sono molti attack vectors), secondo la Jocelyne, sembra che crypto sembra una scienza perch√© definisci metodi di risoluzione di errore per singolo attack vector, che puoi dimostrare come solido, ma nella vita reale credo che hai bisogno che sia valido per ogni tipologia di attacco (ne basta una per distruggerti e ritrovare la chiave diciamo).\nSymmetric cryptography Vogliamo cercare di trovare un modo di comunicare attraverso un canale di comunicazione insicuro, questo √® il problema principale di questa critografia.\nCanali insicuri possono essere per esempio\nInternet Wifi Setting classico del problema di comunicazione\nAllora introduco uno step di criptazione e decrittazione fra il pirmo e l‚Äôultimo comunicante.\nQuesto √® un scenario leggermente pi√π generale, in cui nel mezzo c'√® un attaccante, solitamente un *eve* o altro che ha accesso a $c$ e prova a decrittare. On security of cipher One important note is that the security of the cipher is not enough to mantain a security of the algorithm. But experience says it‚Äôs not! (Ma nonostante questo √® stato fatto per centinaia e centinaia di anni, ora sappiamo che √® cosa stupida).\nAnd a bad thing about this is that there is no clear way to know if a cipher is secure or not, usually what is done is that the algorithm is made public and if nobody knows how to break it is considered secure.\nAnd it‚Äôs very easy to build something that is breakable!!!\nKerckhoffs‚Äô Principle 1883 Enunciato kerckhoff üü©- This is the most important principle of the course!\nA cryptosystem should be secure even if the attacker (oscar in this case) knows all the details about the system, with the exception of the secret key.\nHow can we make sense of this? This is counterintuitive. Maybe because in the past there were like two keys, the key and the algorithm itself, seems like that this setting didn‚Äôt help to have a better security. But historically speaking, this principle seems to hold.\nSubstitution cipher Vedere #Affine and Caesar Cipher per definizione formale.\nThis was one of the oldest ciphers in history. (Old and stupid ciphers by the Professor).\nHistorical ciphers Operates on letters (solitamente delle permutazioni) Replace ever plaintext letter by a fixed ciphertext letter, this was the main idea. Examples\nCaesar Cipher, replace with a shift (bruteforce easy attack! The keyspace is very small) Function that replaces each letterwith another letter with bijective. bruteforce, it‚Äôs too big for a braindead bruteforce to attack this function. 26! Frequency attack because in the language the letters are not equally distributed! And this works. (when the most frequent letter is discovered a big part of ciphertext is found!) And a bad thing is that same letter to same letter (frequency attack)!!!! Attacco di frequenza üü© In teoria la chiave √® una permutazione (nel caso di vigenere, quindi avremmo $26! \\approx 2^{88}$ di keysize, per√≤ un attacco di frequenza √® troppo forte per questo genere di cifrari. Fatto per la prima volta da Al-Kindi 800 AD.\nAttacco brute-force üü© $$ D(C, k_{i}) = M $$ Ossia la chiave che usando $D$ abbiamo il plaintext. Solitamente questo valore non si pu√≤ calcolare, perch√© avremmo bisogno di $M$, quindi abbiamo il problema dei falsi positivi all\u0026rsquo;interno del nostro spazio di interesse. (vedere sezione 5.2 di (Paar \u0026amp; Pelzl 2010))\nVigen√®re Cipher Esempio intuitive Vigen√®re üü© Tentativo formalizzazione üü© Consideriamo una chiave $k = (k_{1}, k_{2}, \\dots, k_{l})$ Ognuno equivalente al shift presente in cesare #Affine and Caesar Cipher. Ripetiamo la chiave pi√π volte e cifriamo col shift cipher corrispondente ogni lettera. Questo fa nascere l\u0026rsquo;idea dei rotori senza problemi!\nAttacco a Vigen√®re üü© Guess the length of the key l using some methods Divide the cyphertext into l shift cipher encryptions Use frequency analysis on each shift cipher √à una specie di algoritmo, e si riutilizza la vulnerabilit√† presente sui shift ciphers normali. L\u0026rsquo;attacco a frequenza diventa pi√π difficile rispetto a Cesare, ma ancora possibile (molti ciphers indipendenti). Per il primo steps un plaintext attack √® facilissimo per esempio! Qualcuno ha fatto la domanda su come scoprire la lunghezza chiave alla prof. La prof non sa come attaccarlo, e ha detto solo bruteforce su lunghezza. Poi ha citato un caso di plain-text senza chiamarlo plain-text. Ma √® stata molto vaga. Bad. Ha detto anche entrare nel sistema per trovarlo\u0026hellip; lol.\nRotor machines Main idea of rotors üü®- Queste macchine sono nate principalmente nel secolo scorso, da queste idee\nMultiple rounds of substitution, encryption consists of mapping a letter many times ‚óã M Mechanical/electrical wiring to automate the encryption/decryption process La meccanizzazione √® stata risolta dal punto di vista del red team da Turing, che ha dato un contributo fondamentale (Turing 1950).\nEsempi storici di rotor machines I moderni simili sono DES e AES, li tratteremo un po' pi√π avanti. ### Security of the Key Note sulla lunghezza della chiave (non fare) Andiamo in questa parte a misurare la sicurezza di una chiave di fronte agli attacchi. Una prima nota molto importante √® il fatto che questa misura della lunghezza ha senso solamente quando si parla di bruteforce, infatti la lunghezza della chiave non pu√≤ difendere contro side-channel oppure frequency-attacks.\nLa lunghezza della chiave per cifrari simmetrici e asimmetrici cambia. Segretezza perfettaüü©- $$ \\mathbb{P}(E(k, m_{0}) = c) = \\mathbb{P}(E(k, m_{1}) = c) $$Detto in altre parole, se ho un certo cipher-text, ho la stessa probabilit√† di avere qualunque messaggio possibile di una certa lunghezza rispetto al messaggio iniziale. Quando succede questo there are no computational assumptions about the attacker, this is why this is also called unconditional security or perfect security.\nIl cyphertext potrebbe essere qualunque messaggio!, cio√® non posso attaccare il $c$ sapendo solo $c$ con la segretezza perfetta. Altri autori come Stinson definisco tale per cui $P(E|M) = P(E)$. Attualmente non mi √® chiaro se le due definizioni sono equivalenti.\nL\u0026rsquo;idea √® limitare qualunque informazione che si pu√≤ trovare dalla chiave come\nNon posso ritrovare la chiave dai processi di $E$ e $D$ Non posso ritrovare il plain-text da cipher-text. Se abbiamo questa propriet√† non posso fare ciphertext only attack, in altre parole, nessuna informazione da ciphertext only, perch√© viene eliminato tutto Una definizione equivalente sembra essere: dato un $M$ deve essere che $\\forall e \\in E, P(e|M) = P(e) \\not = 0$ qui Questo significa che il $e$ √® indipendente da M quando non si conosce la chiave, nel senso che non riesci prendere nessuna informazione (se inverti con Bayes dovresti avere stesso valore). Si pu√≤ dimostrare che la seconda definizione, pi√π l\u0026rsquo;ipotesi che $\\lvert K \\rvert = \\lvert P \\rvert = \\lvert C \\rvert$ √® equivalente alla prima (il contrario dovrebbe essere facile!?).\nSegretezza perfetta e lunghezza chiaveüü®+ Si pu√≤ dimostrare che per avere segretezza perfetta √® necessario avere\n$$ \\lvert K \\rvert \\geq \\lvert M \\rvert $$ Questa propriet√† rende cifrari come OTP molto difficili da usare nella pratica, perch√© non riusciamo a comunicare questo valore, che tra l\u0026rsquo;altro dovrebbe essere utilizzato una singola volta.\nProof: https://cs.ioc.ee/yik/schools/win2006/massey/slides1.pdf Dove $H$ √® l\u0026rsquo;informazione Shannon. quindi $H(P) = \\sum_{x} P(x)\\log\\left( \\frac{1}{P(x)} \\right)$, e la lunghezza √® strettamente dipendente dall\u0026rsquo;entropia. Questo Shannon lo ha dimostrato nel 1949.\nUna altra dimo √® su (Stinson 2005) 3.3, abbastanza ez.\nUnconditional security üü© La nota importante √® il fatto che sia infinito, anche se ho il tempo dell‚Äôuniverso o maggiore non posso mai rompere un cifrario sicuro incondizionalmente. (molti cifrari sicuri nella pratica quindi non sono sicuri sequendo questa definizione). Questo dovrebbe essere equivalente alla definizione di sopra si segretezza perfetta.\nCome vedremo c‚Äô√® un cifrario teoricamente sicuro, ma nella pratica di poco utilizzo\nAffine and Caesar Cipher Definizione shift cipher üü© Sono definizioni 1.4.3 presenti su (Paar \u0026amp; Pelzl 2010). Shift Cipher\n$$ e_{k}(x) \\equiv x + k, \\mod 26 $$$$ d_{k}(y) = y - k \\mod 26 $$Definizione affine cipher üü© $$ e_{k}(x) = y \\equiv a\\cdot x + b \\mod 26 $$$$ d_{k}(y) = x \\equiv a^{-1}\\cdot(y - b) \\mod 26 $$ Con la restrizione del fatto che affinch√© $a$ sia invertibile dobbiamo avere $gcd(a, 26) = 1$\nAritmetica modulare Guardare Algebra modulare, perch√© √® praticamente quella stessa roba, molto importante crittografia, ma andiamo a trattare in un altro modo\nSul modulo üü© Il resto non √® unico! ci possono essere molte cose che soddisfano quelle cose Il resto si pu√≤ considerare una classe di equivalenza. Anelli üü© Un anello √® un insieme di elementi su cui sono definite certe propriet√† di interesse.\nEsiste somma e prodotto e sono chiusi. E ci sono molte altre cose‚Ä¶ L‚Äôinverso non ci deve stare\nReferences [1] Stinson ‚ÄúCryptography: Theory and Practice, Third Edition‚Äù CRC Press 2005\n[2] Turing ‚ÄúI.‚ÄîCOMPUTING MACHINERY AND INTELLIGENCE‚Äù Mind Vol. LIX(236), pp. 433\u0026ndash;460 1950\n[3] Paar \u0026amp; Pelzl ‚ÄúUnderstanding Cryptography: A Textbook for Students and Practitioners‚Äù Springer 2010\n","permalink":"https://flecart.github.io/notes/classical-cyphers/","summary":"\u003ch1 id=\"introduzione-a-crittografia\"\u003eIntroduzione a Crittografia\u003c/h1\u003e\n\u003cp\u003eal corso di crittografia di Christof Paar su Youtube, con aggiunte del corso Unibo.\u003c/p\u003e\n\u003ch2 id=\"classifications-and-definitions\"\u003eClassifications and definitions\u003c/h2\u003e\n\u003cp\u003eClassification nowadays as many many applications like, and it‚Äôs a increasing important field\u003c/p\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Introduzione/Untitled.png\" alt=\"image/universita/ex-notion/Introduzione/Untitled\"\u003e\n\u003ch3 id=\"cryptology-2-\"\u003eCryptology (2) üü©\u003c/h3\u003e\n\u003cp\u003eLa branca comunemente riferita come crittografia √® divisa principalmente in due campi \u003cstrong\u003ecrittografia e cryptanalysis\u003c/strong\u003e in cui una cerca di creare nuovi metodi per cifrare i messaggi, e l‚Äôaltro prova ad attaccare questi messaggi ritrovando il messaggio originale.\u003c/p\u003e","title":"Classical Cyphers"},{"content":"Cloud Computing: An Overview Key Players in the Cloud Industry The cloud computing market is dominated by several major providers, often referred to as the \u0026ldquo;Big Seven\u0026rdquo;:\nAmazon Web Services (AWS): The largest provider, offering a comprehensive suite of cloud services. Microsoft Azure: Known for deep integration with enterprise systems and hybrid cloud solutions. Google Cloud Platform (GCP): Excels in data analytics, AI/ML, and Kubernetes-based solutions. IBM Cloud: Focuses on hybrid cloud and enterprise-grade AI. Oracle Cloud: Specializes in database solutions and enterprise applications. Alibaba Cloud: The leading provider in Asia, offering services similar to AWS. Salesforce: A major player in SaaS, particularly for CRM and business applications.\nThese providers collectively control the majority of the global cloud infrastructure market, enabling scalable and on-demand computing resources for businesses worldwide. Capital and Operational Expenses in the Cloud Cloud computing transforms traditional IT cost structures by shifting expenses from capital expenditures (CapEx), such as purchasing servers and data centers, to operational expenditures (OpEx), where users pay only for the resources they consume.\nEconomic Advantages of the Cloud Increased Resource Utilization: Cloud providers optimize hardware usage by sharing resources across multiple users (multitenancy), reducing idle capacity. Pay-as-You-Go Model: Organizations avoid upfront investments, paying instead for compute power, storage, and services as needed. Scalability: Costs align dynamically with demand, eliminating over-provisioning. Key Insight:\nThe cloud improves efficiency by enabling resource sharing. From the provider‚Äôs perspective, resource utilization increases significantly. For users, costs are proportional to actual usage, fostering financial flexibility.\nToday\u0026rsquo;s platforms are highly inefficient from this point of view. (most of the resources are not used!).\nCloud Service Models Cloud offerings are categorized into four primary service models, each providing distinct levels of abstraction and management responsibility.\nTraditional methods On-premises: The traditional model where organizations own and manage their infrastructure. Colocation: Organizations rent space in a data center and manage their hardware. Hosting. Then cloud came and made the system administration part much more easier for administrators, who do not need to worry about the hardware anymore. This was also the beauty of abstractions. Now, in the second part of the cloud evolution, as described in (Schleier-Smith et al. 2021), is innovating how developers work: they don\u0026rsquo;t need to care about scaling and managing the infrastructure anymore, they just need to care about the code.\nInfrastructure as a Service (IaaS) Definition: IaaS provides virtualized computing resources over the internet, allowing users to rent fundamental infrastructure components.\nFeatures:\nVirtual Machines (VMs): Securely isolated partitions of physical servers, enabled by hypervisor-based virtualization. Deployment Options: Shared VMs: Cost-effective, multitenant environments. Dedicated Servers: Virtualized but not shared (single-tenant). Bare Metal Servers: Physical servers without virtualization. Use Case: Ideal for organizations needing full control over their software stack but lacking physical hardware. We pay by the minute. Security Considerations:\nUsers rely on the provider‚Äôs implementation of isolation, hardware security, and virtualization integrity. This aligns with the shared responsibility model, where providers secure the infrastructure, while users protect their data and applications.\nExamples:\nAWS EC2 (Elastic Compute Cloud) Microsoft Azure Virtual Machines Google Compute Engine Platform as a Service (PaaS) Definition: PaaS delivers a managed environment for developing, testing, and deploying applications, abstracting underlying infrastructure.\nFeatures:\nPreconfigured middleware (e.g., databases, load balancers, autoscalers). Streamlined deployment pipelines and DevOps tools (distributed caches). Automatic scaling and resource management. Use Case: Reduces development overhead by handling infrastructure management, allowing teams to focus on coding and innovation, instead of managing infrastructure.\nExamples:\nAWS Elastic Beanstalk Google App Engine Heroku Software as a Service (SaaS) Definition: SaaS delivers fully functional applications over the internet, managed entirely by the provider.\nFeatures:\nUsers interact solely with the application interface. No maintenance or infrastructure management required. Often subscription-based. The user just inputs the data, does not need to write software. Examples:\nMicrosoft Office 365 Google Workspace (Gmail, Drive) Salesforce CRM Snowflake (cloud data warehousing) Simple comparison of Service Models Model Control Management Use Case IaaS High (OS \u0026amp; apps) User-managed Custom infrastructure needs PaaS Medium (apps) Provider-managed Streamlined app development SaaS Low (configuration) Fully managed Ready-to-use software FaaS Minimal (code) Fully automated Event-driven, short-lived tasks Serverless computing We hide the hardware, but we also hide the backend!\nThe future evolution of serverless computing, and in our view of cloud computing, will be guided by efforts to provide abstractions that simplify cloud programming. (Schleier-Smith et al. 2021).\nFunctions as a Service (FaaS) / Serverless Computing Definition: FaaS allows users to deploy event-driven, stateless functions without managing servers.\nFeatures:\nEvent Triggers: Functions execute in response to events (e.g., file uploads, API calls). Millisecond Billing: Costs are based on execution time and memory used. Automatic Scaling: Instances spin up/down seamlessly with demand. Advantages:\nEliminates server provisioning and capacity planning from the developer/user. Ideal for parallelizable tasks (e.g., video encoding, data processing). Very fine granularity of billing. Use Cases:\nSmall highly parallelizable functions triggered by events. Real-time data processing Microservices architecture Batch jobs (e.g., compiling code, running unit tests, compressing or decompressing videos). Examples:\nAWS Lambda Azure Functions Google Cloud Functions Sometimes we can see these as a supercomputer on demand. Advantages and Disadvantages of Serverless Computing Advantages:\nEasy to use (just add a single function + trigger) Scalable (automatic scaling, very robust to bursts) Cost-effective (pay only for execution time) Limitations:\nStateless No connection between each other or states between each other (we don\u0026rsquo;t have IPs between each other) E.g. if we need to use Massive Parallel Processing frameworks, we write to a shared location. Limited resources (execution time, bandwidth, memory etc). Difficulty in efficiently scheduling and running the lambdas The provider has little info about application characteristics to optimize scheduling In (Schleier-Smith et al. 2021) the authors propose that the developers themselves could add hints for the cloud provider to know which kind of communication patterns are more prevalent in that application. The cloud provider could develop technologies of static code analysis to infer the main communication patterns of the program. There are no general serverless platforms, against serverful classical platforms. (For some uses, serverless is too slow or inefficient). Providing FaaS There are three main challenges that are against securely hosting these services:\nFine-Grained functions -\u0026gt; densely packaged functions Isolate functions from one to another Functions usually cannot communicate with each other. Fixed resources are allocated to the functions. We should be able to spin up the resources quickly (today on the order of hundreds of milliseconds) See next section for warm and cold starts. Warm and Cold starts üü®\u0026ndash; Lambdas cannot execute out of the blue:\nBoot function sandboxes Fetch function codes Application runtimes And then execute. The first three parts are the cold start where a lot of the stuff needs to be downloaded and configured. The hot start is just keeping around the sandboxes, and the required dependencies and then execute the lambdas. But it has the problem that this is consuming memory. Microsoft has seen that hot starts need on average 16x more memory compared to cold starts, over 100 function runs.\nFirecracker Firecracker ((Agache et al. 2020)) is a lightweight, open-source Virtual Machine Monitor (VMM) designed to run microVMs with minimal overhead. Developed by AWS for services like AWS Lambda and AWS Fargate, Firecracker is optimized for secure, fast-booting, and resource-efficient virtualization. It uses KVM (Kernel-based Virtual Machine) and provides strong isolation while maintaining near-native performance. Alternatives at the time excluded security with minimal overhead.\nKey features include:\nMicroVMs: Lightweight VMs with a minimal memory and CPU footprint. Fast Boot Times: Can start microVMs in milliseconds. Security: Implements strong isolation with seccomp filters and a minimal attack surface. API-Driven: Exposes a REST API for managing microVMs programmatically. Optimized for Serverless: Used in AWS Lambda and Fargate to run function-based workloads efficiently. it offers memory overhead of less than 5MB per container, boots to application code in less than 125ms, and allows creation of up to 150 MicroVMs per second per host.\nIt\u0026rsquo;s particularly suited for multi-tenant workloads, sandboxing, and container alternatives where lightweight VMs provide better isolation than traditional containers.\nOther Latency - Capacity - Bandwidth In this section we explore the relationship between latency, bandwidth and capacity with different methods of storage. Remote memory is faster than local disk! Disk accesses are usually so slow, on the order of milliseconds! Bandwidth bottlenecks Speed of most common operations Resource allocation We have first explored some methods in Massive Parallel Processing.\nWe need to take into consideration some important key factors:\nRequirements change quite often. Fewer configurations so that they are easier to manage. Constant power budget Uncorrelated Resource usages The difficult part to handle is that the usage of CPU and Disk are uncorrelated, at least their relation is not simply linear or inversely linear. The main implication of this is: it is difficult to have a balanced resource usage -\u0026gt; sunk cost: we have resources that we are not using, but we are paying for.\n80% of servers have less than 20% of utilization, or similar numbers (most of computers have not so much utilization). Sometimes big events are present (see twitter crash in 2009), and in this case the resources are used, but these events are very very sparse. Another notable uncorrelation is the utilization and the power usage! This was quite not intuitive: old servers consumed 60% of the max power usage even at 0 utilization!\nDisaggregated resource pools Instead of having fixed allocation to various applications, we can have a logical layer that says that we have a specific pool of each kind of resource and then try to allocate them independently. The idea is that by decoupling the resources, it is easier to allocate them.\nTotal cost of ownership Better using hardware, leads to better performance at the same cost! So this is important to solve to keep costs of operating datacenters low. To compute the cost of ownership we need to take into account:\nCapital expense in buying hardware (big part 61%) Energy and cooling to keep it going Networking costs Other (like maintenance, cost of capital, amortized cost of building etc.) People that operate the building (security, technicians). Software We usually divide software in different tiers. Here‚Äôs a more structured, textbook-style version of your notes:\nMain Layers In modern software architecture, systems are commonly structured into three primary layers, closely resembling the architecture described by (Calder et al. 2011):\nPresentation Layer ‚Äì This layer is responsible for the user interface and user experience. It handles input from users and displays the processed data in an understandable manner. Application Layer ‚Äì Sometimes referred to as the business logic layer, this component processes data, executes operations, and enforces business rules. It serves as an intermediary between the presentation and data layers. Data Layer ‚Äì This layer is dedicated to data storage and retrieval. It communicates with databases or other storage systems to ensure data persistence and integrity. These layers interact with each other in a structured manner to maintain modularity and separation of concerns. However, increasing the number of levels of indirection can help solve certain system design challenges, such as scalability or maintainability. On the other hand, excessive layering introduces overhead, making the system more complex to maintain and potentially reducing its performance.\nTypes of Tiers Software architectures have evolved over time to address scalability, maintainability, and efficiency. The following outlines the major transitions in architectural paradigms:\n1-Tier (Monolithic Architecture) A single system that integrates all components into a single unit. Simple to develop and manage since there are no inter-process or network communication overheads. Lacks scalability, as increasing demand requires vertical scaling (adding more resources to a single server). 2-Tier Architecture (Client-Server Model) Introduced API-based communication through remote procedure calls (RPC). Standardized API interfaces, often implemented via REST APIs over HTTP. More complex than monolithic systems due to the need for synchronization between client and server. Prone to compatibility issues, as both client and server must adhere to the same API specifications. We need to have an interface, as we have a separation between client and server. There is no communication with one server and another (so difficult to coordinate and synchronize the servers). 3-Tier Architecture (Middleware-Based Systems) Introduced an intermediary middleware layer that processes business logic independently of the client and data layers. (level of indirection, this is also the root of microservice architecture) Enabled better scalability by distributing workload across multiple servers. Served as the foundation for micro-services architectures, where different services operate independently and communicate via lightweight protocols such as HTTP or message queues. Performance evaluation Understand why a system behaves in the way it does Common errors in performance evaluation Bugs in the benchmarking code (difficult to spot, as they just product erroneous measures, instead of faulting irrecoverably) Making educated guesses instead of actually measuring the performance that is object of the discourse. Often these results are simply not true. One easy way is checking for inconsistencies. Not measuring everything. This leads to superficial measurements. Another effect that this often leads is confimation bias of the original hypothesis, if we measure only that thing. One way to fix this is measuring at a lower level, or measuring in different manners. References [1] Schleier-Smith et al. ‚ÄúWhat Serverless Computing Is and Should Become: The next Phase of Cloud Computing‚Äù Communications of the ACM Vol. 64(5), pp. 76\u0026ndash;84 2021\n[2] Agache et al. ‚ÄúFirecracker: Lightweight Virtualization for Serverless Applications‚Äù 17th {{USENIX Symposium}} on {{Networked Systems Design}} and {{Implementation}} ({{NSDI}} 20) 2020\n[3] Calder et al. ‚ÄúWindows Azure Storage: A Highly Available Cloud Storage Service with Strong Consistency‚Äù ACM 2011\n","permalink":"https://flecart.github.io/notes/cloud-computing-services/","summary":"\u003ch2 id=\"cloud-computing-an-overview\"\u003eCloud Computing: An Overview\u003c/h2\u003e\n\u003ch4 id=\"key-players-in-the-cloud-industry\"\u003eKey Players in the Cloud Industry\u003c/h4\u003e\n\u003cp\u003eThe cloud computing market is dominated by several major providers, often referred to as the \u0026ldquo;Big Seven\u0026rdquo;:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eAmazon Web Services (AWS)\u003c/strong\u003e: The largest provider, offering a comprehensive suite of cloud services.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMicrosoft Azure\u003c/strong\u003e: Known for deep integration with enterprise systems and hybrid cloud solutions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGoogle Cloud Platform (GCP)\u003c/strong\u003e: Excels in data analytics, AI/ML, and Kubernetes-based solutions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIBM Cloud\u003c/strong\u003e: Focuses on hybrid cloud and enterprise-grade AI.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOracle Cloud\u003c/strong\u003e: Specializes in database solutions and enterprise applications.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAlibaba Cloud\u003c/strong\u003e: The leading provider in Asia, offering services similar to AWS.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSalesforce\u003c/strong\u003e: A major player in SaaS, particularly for CRM and business applications.\u003cbr\u003e\nThese providers collectively control the majority of the global cloud infrastructure market, enabling scalable and on-demand computing resources for businesses worldwide.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"capital-and-operational-expenses-in-the-cloud\"\u003eCapital and Operational Expenses in the Cloud\u003c/h3\u003e\n\u003cp\u003eCloud computing transforms traditional IT cost structures by shifting expenses from \u003cstrong\u003ecapital expenditures (CapEx)\u003c/strong\u003e, such as purchasing servers and data centers, to \u003cstrong\u003eoperational expenditures (OpEx)\u003c/strong\u003e, where users pay only for the resources they consume.\u003c/p\u003e","title":"Cloud Computing Services"},{"content":"Object Stores Object storage design principles üü®++ We don\u0026rsquo;t want the hierarchy that is common in Filesystems, so we need to simplify that and have these four principles:\nBlack-box objects Flat and global key-value model (trivial model, easy to access, without the need to trasverse a file hierarchy). Flexible metadata Commodity hardware (the battery idea of Tesla until 2017). Object storage usages üü© Object storage are useful to store things that are usually read-intensive. Some examples are\nStatic websites Images, Videos or video chunks Big files that are usually only to read (e.g. datasets). Service Level Agreements (4) üü®++ We will talk now about Service Level Agreements which are important to understand the contract part of using cloud services. So, if a company does not satisfy these requirements, one can sue them for breach of contract.\nScalability We have 100 buckets per account that could be extended on request.\nDurability We lose 1 in a $10^{11}$ objects during a year (which is 99.999999999% of durability), which is quite strong (so there is still a possibility that the object is lost). This is useful for the lawyers because they can offer a guarantee. If this is not respected then people can sue them.\nAvailability We have an availability of 99.99% which means maximum of 1h for a year. Usually it\u0026rsquo;s useful to remember the percentages of availability:\n99% 4 days/year\n99.9% 9 hours/year\n99.99% 53 minutes/year\n99.999% 6 minutes/year\n99.9999% 32 seconds/year\n99.99999% 4 seconds/year\nResponse time Legally it\u0026rsquo;s hard to guarantee average speeds, so what they do is actually count the times where the service is guaranteed to be below a certain threshold! So they guarantee that in $99.9\\%$ of the cases they have a response lower than $300 ms$, in other cases its higher. However, as it is usually difficult to satisfy a latency requirements which is often geographically dependent answer, S3 offers guarantees based on system throughput, which is how many reads and writes it can handle without any problem. Amazon S3 Amazon used to sell books, then they started to rent cloud services because they had too many machines that most of the time they were not using. This was a big win from an economical point of view. They created amazon web services. Now they are selling these abstractions: Amazon S3 stands for simple storage service.\nS3 Document Identification üü© With S3 every document is identified by a bucket id and a object id, which could be maximum 5 TB (probably physical constraints of the file), it is only possible to upload an object in a single chunk if it is less than 5 GB. The buckets can uniquely identify that in the world. The maximum amount of buckets that a user can have is 100 by default, while the maximum number of objects is unlimited, they can handle billions of objects without problems.\nWe don\u0026rsquo;t know how S3 works underneath, they have not published it.\nStorage Classes üü®++ The cost of the storage service changes with the frequency of the access. For example\nAmazon Glacier has a very high latency (hours to get the files), but its cost is quite low. This should be used for example for backups! With these applications we don\u0026rsquo;t care if the answer is in seconds. Hours is fine. Standard with infrequent access: we have a cost of retrieving, with less availability Standard: it\u0026rsquo;s just the standard S3 structure. Accessing a resource üü© We use Uniform Resource Identifier to identify the resource we want to access, and the usually send a REST request to modify, delete or get it.\nThis is an example of a S3 bucket [http://bucket.s3.amazonaws.com/object-name](http://bucket.s3.amazonaws.com/object-name`) (if you want to access the bucket, just remove the object identifier!). We can have operations like PUT, GET, DELETE for Buckets and objects.\nUsage Examples üü© Most common usage of buckets is storing read intensive data, like static websites or dataset shards (which then become useful for systems like MapReduce or Spark). The performance is nice, the professor reports about 300ms for the website to load. Usually you can see a hierarchy on the UI for such systems, but that is just for interface, under the hood, we just have a flat key-value store.\nIt is common to place a content delivery network (CDN) service on top of the storage bucket of a website in order to accelerate and cache these files at multiple places on the planet.\nAzure Blob Storage In this section we will describe the service provided by Azure cloud on cloud storage.\nTo store seemingly limitless amounts of data for any duration of time and pay only what is being used. WAS provides cloud storage in the form of Blobs (user files), Tables (structured storage) and Queues (message delivery). WAS claims to satisfy strong consistency, high availability and partition tolerance all at the same time; ie. all of CAP.\nAzure Document Identification üü©\u0026ndash; Azure blob storage needs 3 id to identify a document:\nAccount Container (bucket equivalent), which is sometimes called partition in literature. Blob (document id equivalent) 195 GB for an Append Blob to 190.7 TB for a Block Blob. The maximum storage size is different! Location Service üü• Withing Azure, there are three main regions: US, Europe, and Asia, each one of these has at least a datacenter with multiple storage stamps and one or more building. This is used to optimize the latency of the service. Each one of this has the so called Location Service which handles:\nStorage stamps monitoring (managing) Account namespace across all stamps Allocation of accounts to storage stamps and monitoring for disaster recovery. Load balancing across storage stamps. Itself is distributed across regions for disaster recovery. Location Service manages all the storage stamps and the account names- pace and assignment of accounts across the stamps. Itself distributed and redun- dant, performs disaster recovery and load balancing by updating DNS entries to the respective exposed VIPs (Virtual IP) of the assigned stamp.\nFabric Controller üü• The Windows Azure Fabric Controller is a resource provisioning and management layer that provides resource allocation, deployment/upgrade, and management for cloud services on the Windows Azure platform.\nIt has a role similar to the ResourceManager in Yarn, see Massive Parallel Processing.\nStream Layer üü• Partition Layer üü• The partition layer is made of two main components:\nThe partition manager Responsible for keeping track of and splitting the massive Object Tables into RangePartitions and assigning each RangePartition to a Partition Server to serve access to the objects.\nA partition server is responsible for serving requests to a set of RangePartitions assigned to it by the PM.\nThis is somewhat similar to what is done in Wide Column Storage for region servers.\nObject APIs üü® And we can divide the files into blocks which support a higher size.\nBlocks are for data. Maximum size of 50k 4GB blocks, about 190.7 TB. Append are for logs because they are optimized to append stuff, of maximum size of 195 GB. Which corresponds to 50k 4MB blocks. Page are for in memory virtual machines maximum size of 8 terabytes. Stamps üü©\u0026ndash; Azure Blob Storage is organized into the so called storage stamps. These stamps are 10-20 racks with 18 storage nodes each (maximum storage for a stamp is about 30PB of data). Usually kept below 80% data (if not they\u0026rsquo;ll have a warning), else they could buy more storage or move data elsewhere.\nReplication (2) üü© They have two types of replications:\nIntra-stamp: which is synchronous way of replicating (immediately replicated). Inter-stamp: asynchronously replicating to other stamps. Regions (2) üü©\u0026ndash; As with AWS, they have regions to optimize for latency and be resistant to natural catastrophes. The latency part is intuitive: if a data center is physically closer to you, then it\u0026rsquo;s more probable that the data will be served faster. Natural catastrophes are mitigated by having the data in different regions, so if one is destroyed, then the data is still safe.\nKey-value stores S3 is far more slower than typical database systems to store and query the data. In the order of hundreds of 100ms against 1-9ms for key-value stores. So two orders of difference! Too high latency for some uses!.\nKey value stores (aka associative arrays, we use map data structure) solve this problem and can be adapted to be used as a database system, the cost is that the type of objects we can store is far smaller, in the order of few hundreds of kilobytes.\nCharacteristics of Key-value stores üü® This is designed for performance and scalability, but it gives up consistency for eventual consistency. This is usually a simpler version, but it doesn\u0026rsquo;t have the same features as more complex data storage systems, as relational database management systems.\nUsually these are used for shopping carts for a very large online shop, another is for storing likes and comments on social media\nDesign principles of Key-value stores (4) :üü®+ Incremental stability New nodes can join the system at any time, and nodes can leave the system at any time, sometimes gracefully, sometimes in a sudden crash. But we don\u0026rsquo;t need to have too many nodes to crash, which is not the scope of our course.\nSymmetry No node is particular in any way, the nodes are similar to one and another. They run the same code.\nDecentralization There is no leader or orchestrator in the network. Note that symmetric protocols could elect a leader nonetheless, while in this case we have the strict requirement not to have a leader.\nHeterogeneity the nodes may have different CPU power, amounts of memory, etc.\nComparison With ObjectStorage Limitations compared to S3 and Azure Blob Storage üü© Yet, this brings some drawbacks: We have the values to be far smaller, about 400kb of data (this is what Dynamo does) and we cannot store metadata It has a simplified APIs that just supports get, put or delete the document, with a given key or value (in reality there is also a context variable). This is why they are often more suitable for real-time data, simplicity and speed.\nWhat are Contexes? These values are the state of the updates for every node, this is used to merge the vector clocks in case of need. Providing a context to get or put, allows the key-value store to correctly update the context so that later in case of partitions, it could be exactly solved.\nCommon Usage Patterns Particular usages are for example shopping carts, likes and comments on social media, and so on.\nOne of the typical use cases for a key-value store is storing shopping carts for a very large online shop, another is for storing likes and comments on social media.\nbest seller lists, shopping carts, customer preferences, session management, sales rank, and product catalog, from (DeCandia et al. 2007).\nChord protocol The amazon paper (DeCandia et al. 2007) describes this system.\nThis is based on a distributed hashing protocol. We use hashes because they have some properties to be robust against failures of some kind, which I have not understood.\nWith this protocol, every node has an ID. For example a code in $2^{128}$ (Dynamo indeed uses 128 bytes). If we have a key $k$ this is assigned to a position on the ring. Then from this position we follow the ring clockwise until we find a node, this node should handle the value of this key.\nConsistent Hashing The ring structure of the Chord protocol is called consistent hashing. It has been designed to minimize the amount of transfer of data in distributed systems that join and leave frequently. See Tabelle di hash for a primer of how hashing works.\nOther systems use this type of hashing, like the CassandraDB or CDN services. It acts as an automatic load balancing system.\nThe principle advantage of consistent hashing is that departure or arrival of a node only affects its immediate neighbors and other nodes remain unaffected.\nJoin, Leave and Crash üü© When a node joins, the should take the responsibility of part of the data in front of him in a clockwise fashion. When a node leaves, it should give responsibility of part of the data to the node in front of him. Clearly this is not possible when we have a crash, this is why we need redundancy, which is easily done by having 2-range redundancy, but it can be set to any value.\nOne thing that should be noted with the updates is how it handles the replication: only single node modifies, but after it propagates the update to the replicas and receives acks. Then you use vector clocks to choose the highest update number. A nice parallel with vector clocks is the parallel between these and the Newtonian physics vs Structure of spacetime and different timelines.\nReads on Dinamo üü®\u0026ndash; A client periodically picks a random Dynamo node and downloads its current view of Dynamo membership state. Using this information the client can determine which set of nodes form the preference list for any given key.\nA preference list is just a map of each object and the node that is currently storing that object. With the classical Chord protocol the so called finger tables where used where you could employ binary search to find the node that is responsible for the key. With finger tables, each node knows what the following nodes to the power of two have, so that the search could be employed.\nEvery time a node wants to look up a key¬†$k$, it will pass the query to the closest successor or predecessor (depending on the finger table) of¬†$k$¬†in its finger table (the \u0026ldquo;largest\u0026rdquo; one on the circle whose ID is smaller than¬†$k$), until a node finds out the key is stored in its immediate successor.\nProbably this approach has been dismissed because it is a little bit more burgeoning to update the finger table on joins or leaves, and preference lists are a better practical solution.\nThis is called the client driven approach, and from their tests, it seems twice as fast as the server driven approach.\nPreference lists üü© This solves the problem of finding the actual node that has the data we are querying for. It is just a table with a key -\u0026gt; and nodes that have it. We have distributed algorithms that make the nodes agree on this preference list which is just knowing what machine is responsible for what interval range. For each key range, the first node on the list is called the coordinator node, it this fails, the random node that has gotten request attempt to contact every node until one answers. $R$ is the minimum number of nodes from which the value needs to be retrieved for it to be considered consistent. $W$ is the minimum number of nodes for which an ack should be received to consider it towards a successful read. We have the theoretical necessity that $R + W \u003e N$ to set up a quorum system, whose acknowledgement is based on the majority of notes that have accepted a certain modification. Sometimes the system is also configured to values less than $N$ for a better latency, which is configurable by the developer.\nTuning the values for $R$ and $W$ scale the performance stability of reads and writes. For example read-intensive applications, would prefer to have $R=1$ and $W=N$ so that it is fast to read, but could potentially read some inconsistent data. The most common configuration is $N=3, R=2, W=2$ for Dynamo.\nAdvantages and disadvantages üü®+ Pros:\nHighly scalable Robust to failure (because we replicate data with the ones in front of us). Self-organizing. I don\u0026rsquo;t know if the above properties are exclusive, but they are nice Cons:\nOnly lookup, no search (obvious) No data-integrity (we don\u0026rsquo;t have a way to check for integrity constraints) Security issues (Need to understand this) Virtual Nodes üü© Two problems arise with the Chord protocol: there could be large gaps in the Circle and the underlying machines could have different hardware proposals. The idea is to have some nodes take other nodes in a way proportional to its hardware. In this manner, if a node has more resources, it has more nodes, which implies it is expected to handle more data (which is fine because it has more resources).\nCAP Theorem Statement of CAP üü© We can only have two of the following properties:\nConsistency (doesn\u0026rsquo;t depend on the machine that answers to your request). Availability (it should answer something). Partition tolerance (the system continues to function even if the network linking its machines is occasionally partitioned.) We don\u0026rsquo;t have ACID anymore (see Advanced SQL) in the case of Big Data. So now we have 3 possible scenarios, which correspond to the 3 couples that is possible to have with these properties.\nFor example, let\u0026rsquo;s say we have a partition of the network then we have two cases: not available until the network is connected again, but we still have the same data. Or we have two parts that answer differently (this is usually called eventual consistency, because after the network is connected then it will return to the consistent state), but are still available to the users.\nWhen network partitions happen we need to choose what property we want to keep, so we have three possible cases: CP, CA or AP. Services like Dynamo Key value store (see Cloud Storage#Key-value stores) choose AP and thus have eventual consistency.\nVector Clocks üü®\u0026ndash; Sometimes when we have a network partition we lose the linear timing of the system and so we have directed acyclic graphs\nWe have vectors for updates by different nodes. The merge is done by a certain node and updates the vector again.\nThe merge happens in the following manner: just choose the maximum value for each resource that has been modified. This grants consistency, but could lose some data.\nPACELC Theorem üü©\u0026ndash; PACELC is a generalization of the CAP theorem. The acronym PACELC stands for:\nP: Partition tolerance (as in the CAP theorem). A: Availability. C: Consistency. E: Else. L: Latency. C: Consistency. PACELC integrates the latency in normal running cases. We can tradeoff between being low latency but accepting some inconsistencies, or being consistent with a little higher latency.\nReferences [1] DeCandia et al. ‚ÄúDynamo: Amazon\u0026rsquo;s Highly Available Key-Value Store‚Äù ACM SIGOPS Operating Systems Review Vol. 41(6), pp. 205\u0026ndash;220 2007\n","permalink":"https://flecart.github.io/notes/cloud-storage/","summary":"\u003ch2 id=\"object-stores\"\u003eObject Stores\u003c/h2\u003e\n\u003ch4 id=\"object-storage-design-principles-\"\u003eObject storage design principles üü®++\u003c/h4\u003e\n\u003cp\u003eWe don\u0026rsquo;t want the hierarchy that is common in \u003ca href=\"/notes/filesystem/\"\u003eFilesystem\u003c/a\u003es, so we need to simplify that and have these four principles:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eBlack-box objects\u003c/li\u003e\n\u003cli\u003eFlat and global \u003cstrong\u003ekey-value\u003c/strong\u003e model (trivial model, easy to access, without the need to trasverse a file hierarchy).\u003c/li\u003e\n\u003cli\u003eFlexible \u003cstrong\u003emetadata\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eCommodity hardware (the battery idea of Tesla until 2017).\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4 id=\"object-storage-usages-\"\u003eObject storage usages üü©\u003c/h4\u003e\n\u003cp\u003eObject storage are useful to store things that are usually read-intensive. Some examples are\u003c/p\u003e","title":"Cloud Storage"},{"content":"Gaussian Mixture Models This set takes inspiration from chapter 9.2 of (Bishop 2006). We assume that the reader already knows quite well what is a Gaussian mixture model and we will just restate the models here. We will discuss the problem of estimating the best possible parameters (so, this is a density estimation problem) when the data is generated by a mixture of Gaussians.\n$$ \\mathcal{N}(x \\mid \\mu, \\Sigma) = \\frac{1}{\\sqrt{ 2\\pi }} \\frac{1}{\\lvert \\Sigma \\rvert^{1/2} } \\exp \\left( -\\frac{1}{2} (x - \\mu)^{T} \\Sigma^{-1}(x - \\mu) \\right) $$Problem statement üü© $$ p(z) = \\prod_{i = 1}^{k} \\pi_{i}^{z_{i}} $$ Because we know that $z$ is a $k$ dimensional vector that has a single digit indicating which Gaussian was chosen.\nThe Maximum Likelihood problem üü©\u0026ndash; $$ \\min_{\\pi, \\mu, \\Sigma} \\log p(X \\mid \\pi, \\mu, \\Sigma) = \\sum_{n = 1}^{N} \\log \\left\\{ \\sum_{i = 1}^{K} \\pi_{i} \\mathcal{N}(x_{n} \\mid \\mu_{k}, \\Sigma_{k}) \\right\\} $$$$ \\Theta = \\left\\{ \\pi_{k}, \\mu_{k}, \\Sigma_{k} : k \\leq K \\right\\} $$$$ \\mathcal{N}(x_{n} \\mid x_{n}, \\mu_{i}, \\sigma_{i}) = \\frac{1}{\\sqrt{ 2\\pi } \\sigma_{_{i}}} $$ If we have a single point, and $\\sigma_{i} \\to 0$ which is reasonable because we have a single point on the mean, then this value explodes and makes the whole log-likelihood to go to infinity. This is a case we don\u0026rsquo;t want to explore. There are some methods that try to solve this problem. But in this setting we don\u0026rsquo;t want to explore this, and focus on the expectation maximization algorithm.\nIdeas for the solution üü® $$ \\log p(X, Z) = \\sum_{n = 1}^{N}\\log \\left\\{ \\pi_{z} \\mathcal{N}(x_{n} \\mid \\mu_{z}, \\Sigma_{z}) \\right\\} = \\sum_{n = 1}^{N} (\\log \\pi_{z} + \\log\\mathcal{N}(x_{n} \\mid \\mu_{z}, \\Sigma_{z})) $$$$ \\log p(X) = \\mathbb{E}_{Z \\sim q} \\left[ \\log \\frac{P(X, Z)}{P(Z \\mid X)} \\right] $$ Using product rule and using the expectation to get rid of the $Z$.\nThe interesting part comes when we multiply and divide by $q(Z)$ then we can decompose it further into two parts:\n$$ \\log p(X) = \\mathbb{E}_{Z \\sim q} \\left[ \\log \\frac{P(X, Z)}{q(Z)} \\right] + \\mathbb{E}_{Z \\sim q} \\left[ \\log \\frac{q(Z)}{P(Z \\mid X)} \\right] = M(q, \\theta) + E(q, \\theta) $$ We note that $E$ is a Kullback-Leibler divergence so it\u0026rsquo;s always positive, and we have $\\log p(X) \\geq M(q, \\theta)$.\nAnother fundamental operation is that we can find the parameters of $q$ such that $E$ is null, because we know that if two distributions are the same then the divergence is null. We can compute this because we know the values of the posterior.\nThe expectation-maximization algorithm üü©\u0026ndash; Dempster et al., 1977; McLachlan and Krishnan, 1997 are useful references for this method.\nThe algorithm in brief goes as follows:\nSet an initial value $\\theta^{(0)}$ for values $t=1,2,\\dots$ Set $q^{*}$ such that $E(q, \\theta^{t - 1}) = 0$, which is just minimizing this value. Set $\\theta$ to the max of $M(q^{*}, \\theta)$. By adequately changing parameters for $p(X, Z)$ which is tractable. From a more high level view:\nCompute the posterior $\\gamma$ Compute the best mean, variance and priors with the formula above and update them Repeat until convergence. It is guaranteed that the likelihood is increasing, but we might be stuck on local maxima and similar things.\nConvergence of EM This is just a bounded optimization problem, after which you use the convergence theorem in Successioni which asserts that the limit for bounded monotone sequences always exists and is Unique.\nWe know that $\\log p(X) = M(q, \\theta) + E(q, \\theta)$, after the $E$ step, the corresponding Kullback-Leibler divergence is 0, so we have $\\log p(X) = M(q', \\theta)$ where $q'$ is the updated variational estimator.\nThen, if we set $\\theta^{'} = \\arg\\max_{\\theta} \\log p(X) = \\arg\\max_{\\theta} M(q', \\theta)$, we have the following equations:\n$$ \\log p_{\\theta'}(X) \\geq M(q', \\theta') \\geq M(q', \\theta) = \\log p_{\\theta}(X) $$ Which is a increasing sequence. The upper bound is trivial, by axiomatic definition of $p$.\nThe importance of the class If you assume to know the class for which the point $x$ is part of, then the problems becomes actually quite easy. This is the original problem that concerns k-means too! We don\u0026rsquo;t know a priori which class has been used to generate the point $x$, so taking the expected value accounting for each possibility makes this usually quite hard.\n$$ q(z = i) = p(z \\mid x_{n}) = \\frac{p(x_{n}, z)}{p(x_{n})} = \\frac{\\pi_{i}\\mathcal{N}(x_{n} \\mid \\mu_{i}, \\Sigma_{i})}{\\sum_{j} \\pi_{j}\\mathcal{N}(x_{n} \\mid \\mu_{j}, \\Sigma_{j})} = \\gamma(z_{ni}) $$The Loss Function It is possible to define a loss function with respect to the parameters $\\pi, \\Sigma, \\mu$ after the variational posterior has been fitted in the $E$ step.\n$$ \\gamma(z_{nk}) = p(z_{j} \\mid x_{n}) = \\frac{p (x_{n} \\mid z_{j}) p(z_{j})}{\\sum_{i} p(x_{n} \\mid z_{i}) p(z_{i})} = \\frac{\\pi_{j} \\mathcal{N}(x_{n} \\mid \\mu_{j}, \\Sigma_{j})}{\\sum_{i} \\pi_{i} \\mathcal{N}(x_{n} \\mid \\mu_{i}, \\Sigma_{i})} $$$$ \\begin{align} \\mathcal{L}(\\pi, \\Sigma, \\mu) = \\sum_{n = 1}^{N} \\sum_{k = 1}^{K} \\gamma(z_{nk}) (\\log \\lvert \\Sigma_{k} \\rvert + \\frac{1}{2} (x_{n} - \\mu_{k})^{T} \\Sigma^{-1}_{k} (x_{n} - \\mu_{k}) - \\log \\pi_{k}) \\end{align} $$Then you can derive this loss to get the best mean, Sigma and $\\pi$. This follows (Murphy 2012), but I am not sure I modified it correctly.\nDeriving the expected mean üü®++ Then we continue with the maximization step, which is finding the best variables under this new variational family.\nFirst we want to do some multivariable analysis in order to derive some conditions of the minima, for this reason we take the derivative with respect to $\\mu_{k}$ of the loss equation, and we derive that\n$$ \\begin{align} \\frac{ \\partial \\log p(x) }{ \\partial \\mu_{k} }\u0026amp;= \\sum_{n = 1}^{N}\\frac{\\pi_{k}\\mathcal{N}(x_{n} \\mid \\mu_{k}, \\Sigma_{k})}{\\sum_{j} \\pi_{j} \\mathcal{N} (x_{n} \\mid \\mu_{j}, \\Sigma_{j})} \\cdot \\left( -\\frac{1}{2} \\right) \\frac{ \\partial (x_{n} - \\mu_{k})^{T} \\Sigma^{-1}{k}(x{n} - \\mu_{k}) }{ \\partial \\mu_{k} } \\ \u0026amp;\\implies- \\sum_{n = 1}^{N} \\frac{\\pi_{k}\\mathcal{N}(x_{n} \\mid \\mu_{k}, \\Sigma_{k})}{\\sum_{j} \\pi_{j} \\mathcal{N} (x_{n} \\mid \\mu_{j}, \\Sigma_{j})} \\Sigma^{-1}{k} (x{n} - \\mu_{k}) = 0\\ \u0026amp;\\implies - \\sum_{n = 1}^{N} \\gamma(z_{nk})\\Sigma^{-1}{k}(x{n} - \\mu_{k}) = 0 \\ \u0026amp;\\implies \\sum_{n = 1}^{N} \\gamma(z_{nk})(x_{n} - \\mu_{k}) = 0 \\ \u0026amp;\\implies \\mu_{k} = \\frac{1}{N_{k}} \\sum_{n = 1}^{N} \\gamma(z_{nk}) x_{n}\n\\end{align} $$\nWhere $N_{k} = \\sum_{n = 1}^{N} \\gamma(z_{nk})$\nwe can interpret $N_{k}$ to be the number of points generated by the Gaussian $k$, and the internal part is just the weighted average of the points generated by $k$! This gives an easy interpretation of the mean of the expectation part of this algorithm.\nDeriving the expected deviation $$ \\Sigma_{k} = \\frac{1}{N_{k}} \\sum_{n = 1}^{N} \\gamma(z_{nk})(x_{n} - \\mu_{k})(x_{n} -\\mu_{k})^{T} $$Selecting the number of Clusters You can check this in chapter 25.2 There is a problem at the beginning, even before you can apply the EM algorithm to estimate the probability, we need to choose the hyperparameter $k$ for the number of the classes that we are assuming to exist. We need a way to find a solution to find $k$ that could be more principled than just searching over the possible $k$ in a bruteforce manner.\nWith the stick breaking idea, we assume to have and infinite number of clusters. Then we will have some realizations of the clusters. We have the result that with $N \\to \\infty$ we will have a realization of every cluster. Having a realization means we have one member of $x$ that is part of this class.\nWe discover how to select this with the following section, where we delve into Dirichlet processes.\nK-Means The problem üü© $$ c : \\mathbb{R}^{d} \\to \\left\\{ 1, \\dots, k \\right\\} $$ That assigns each point some unique label.\n$$ R(c, \\mathcal{Y}) = \\sum_{i = 1}^{N} \\lVert x_{i} - \\mu_{c(x)} \\rVert ^{2} $$The Algorithm üü© References [1] Murphy ‚ÄúMachine Learning: A Probabilistic Perspective‚Äù 2012\n[2] Bishop ‚ÄúPattern Recognition and Machine Learning‚Äù Springer 2006\n","permalink":"https://flecart.github.io/notes/clustering/","summary":"\u003ch3 id=\"gaussian-mixture-models\"\u003eGaussian Mixture Models\u003c/h3\u003e\n\u003cp\u003eThis set takes inspiration from chapter 9.2 of (Bishop 2006).\nWe assume that the reader already knows quite well what is a \u003ca href=\"/notes/gaussian-mixture-models\"\u003eGaussian mixture model\u003c/a\u003e and we will just restate the models here. We will discuss the problem of estimating the best possible parameters (so, this is a density estimation problem) when the data is generated by a mixture of Gaussians.\u003c/p\u003e\n$$\n\\mathcal{N}(x \\mid \\mu, \\Sigma) = \\frac{1}{\\sqrt{ 2\\pi }} \\frac{1}{\\lvert \\Sigma \\rvert^{1/2}  } \\exp \\left( -\\frac{1}{2} (x - \\mu)^{T} \\Sigma^{-1}(x - \\mu) \\right) \n$$\u003ch4 id=\"problem-statement-\"\u003eProblem statement üü©\u003c/h4\u003e\n$$\np(z) = \\prod_{i = 1}^{k} \\pi_{i}^{z_{i}}\n$$\u003cp\u003e\nBecause we know that $z$ is a $k$ dimensional vector that has a single digit indicating which Gaussian was chosen.\u003c/p\u003e","title":"Clustering"},{"content":"Introduzione sull\u0026rsquo;encoding Ossia trattiamo metodi per codificare caratteri dei linguaggi umani, come ASCII, UCS e UTF.\nDigitalizzare significa encodarlo in un sistema che possa essere memorizzato su un dispositivo di memorizzazione elettronico. Ovviamente non possiamo mantenere l\u0026rsquo;informazione cos√¨ come √®, ma vogliamo memorizzarne una forma equivalente, ma pi√π facile da manipolare dal punto di vista del computer. Creiamo quindi un mapping, o anche isomorfismo tra il valore di mappatura (o encoding), solitamente un valore numerico, tra il singolo valore atomico originale e il numero.\nEsempi di cose atomiche per encoding sono:\nCarattere per le parole Pixel per le immagini Sequenza sinusoidale per FFT per il suono o la musica. Vogliamo creare un mapping non ambiguo, quindi uno standard √® necessario!.\nSulle differenze linguistiche üü® (non fare) Ma come fare a creare uno standard che possa essere adatto sia a caratteri arabi, inglesi, cirillici, cinesi coreani o giapponesi?\nSulle caratteristiche linguistiche diverse La scrittura non √® in grado di rappresentare il suono della lingua in modo univoco per tutti i linguaggi (esempi accenti in certe lingue, come l\u0026rsquo;italiano, oppure il fatto che l‚Äôinglese molte pronuncie sono diverse rispetto a quanto si scrive), Danese cambia proprio suono. In ebraico contano solamente le consonenti, le vocali sono solamente un ausilio per la pronuncia.\nArabo ha una forma di corsivo, e la forma del carattere dipende dai caratteri che sono di fianco.\nSecondo ragionamento sulle caratteristiche delle lingue diverse\nOssia pu√≤ cambiare proprio la semantica della parola, a seconda della lingua in cui si interpretano gli stessi caratteri. Quasi il linguaggio si potrebbe intendere una funzione di interpretazione semantica , accennato in Logica Proposizionale.\nLa ricerca dello spazio di rappresentazione (3) üü©- ci interessano in partioclare tre caratteristiche per trovare lo spazio di rappresentazione per i nostri caratteri (che comunque rientrano nei numeri, e sono tutti in $\\N$).\nSlide\nContiguit√† (se ho certi numeri che hanno un certo senso all‚Äôinterno di un) Raggruppamento logico (se hanno funzioni simili vorremmo che siano ancora vicini) Ordine, vorremmo seguire l‚Äôordine alfabetico per questo encoding. (credo il motivo di questa scelta √® affinch√© sia un p√≤ pi√π naturale!) Altre caratteristiche che fanno parte dell\u0026rsquo;encoding (che √® una funzione parziale)\nShift: un codice riservato che cambia mappa da adesso in poi. Lo stesso shift o un secondo carattere di shift, pu√≤ poi far tornare alla mappa originaria Codici liberi: codici non associati a nessun carattere. La loro presenza in un flusso di dati indica probabilmente un errore di trasmissione. Codici di controllo: codici associati alla trasmissione e non al messaggio. Standard passati Stardard poco utilizzati (non importante) üü• Baudot\nUna codifica vecchissima, che nessuno usa, e io non ho mai sentito (siamo circa nel 1850).\nEBCDIC\nSlide\nISO 656-1991\nQuesto √® presente nelle slides ma completamente saltato\nASCII e ISO Latin 1 üü© Questi codici esistono, ma solitamente non sono compatibili con altre lingue. Per questo motivo affinch√© il codice sia compatibile con il mondo √® molto meglio che sia utilizzato UTF-8 di default. Fare la transizione di questa codifica solitamente √® costosa\nAmerican Standard Code for Information Interchange Sono 7bit utilizzate e uno come bit di parit√†. Questo mette uno standard fra codifiche fra telescriventi e schede perforate che erano molto presenti all\u0026rsquo;epoca. Ed √® solamente alfabeto latino inglese.\nOrigine Backspace Delete, CR e LF Nella telescrivente avevo bisogno di backspace, per eliminare un carattere. Nelle schede perforate utilizzavo tutti i buchi presenti per significare che non avevo questo carattere, ecco la delete.\nCarriage return, nella telescrivente avevo una testina che andava avanti a scrivere, e bisognava farlo tornare indietro, e per far girare la testina utilizzavo Line-feed.\nEstensioni custom Dopo un po\u0026rsquo; l‚Äôhardware √® diventato molto affidabile, quindi utilizziamo il bit in pi√π per memorizzare un codice come ci √® pi√π comodo. sono le Codepage di ASCII, e ognuno si fa una propria versione.\nGreco\nCirillico\nArabo\nMa nessuno di questo √® standard! L\u0026rsquo;unico forse √® ISO Latin 1\nCaratteri orientali e testi multilingua üü© Codifica dei Caratteri Orientali Ma per il cinese non √® possibile mettere tutto in un singolo byte, Quindi utilizzano due byte qui.\nMa anche con due byte non √® possibile avere tutti i caratteri nella lingua, per questo motivo metto solamente i caratteri pi√π utilizzati\nCodifiche cinese giapponesi e coreani\nSlide alfabeti CJK\nIL PROBLEMA DEI TESTI MULTILINGUA\nMa cosa succede se ho un testo multilingua? Come faccio a codificarlo in modo disambiguato?\nDichiarazioni esterne (no, sarebbe per l‚Äôintero documento, dovrei utilizzare un markup per specificarti l‚Äôencoding?? Troppo brutto) Intestazioni interne (sarebbe molto scomodo dover stabilire ogni volta che encoding sia!) Dovrei forse spezzettartelo in troppi modi. Per questo motivo bisognerebbe creare un nuovo encoding, ed √® questo quello che viene fatto in Unicode.\nUnicode e Universal Transformation Format Unicode e ISO/IEC 10646 (storia) üü®+ UN PO DI STORIA Questi due standard sono nati per fare le stesse due cose, senza sapere che facevano la stessa cosa. (UNICODE √® sponsorizzato dai produttori di hardware, ISO √® internazionale ed √® spinto dalle nazioni estere).\nIl problema principale che vanno a risolvere √® quello di essere standard unico per tutti i linguaggi, per esempio in questo modo posso scrivere testo in lingua mista senza darmi troppi problemi!\nHanno avuto una difficolt√† ad universi quando l\u0026rsquo;uno ha scoperto dell‚Äôesistenza dell‚Äôaltro. Poi sono andati a convergere, ossia sono ancora d‚Äôaccordo con l‚Äôencoding presente.\nCOSA √à ENCODATO Cos√¨ sono nate UCS-2/4 e UTF-8/16/32 che rappresentando rispettivamente una codifica fissa o variable. Questi sono in grado di rappresentare codici di tutti i codici passati!\n3 categorie di cose encodate\nEsempi di codici encodati\nCon tanto spazio disponibile possiamo anche encodare i linguaggi di star trek e Lord of the ring, per√≤ non potevano includere questi linguaggi in uno standard, comunque √® possibile encodarli in uno Private Use Area (6400 di base, che sono quelli inizialmente utilizzate per klingon o Lord of ring) e poi 65k liberi.\nSlide\nPrincipi di unicode (10)üü•+ Sono troppi, a memoria non va bene ricordarseli cos√¨.\nIn pratica tutti i caratteri di Unicode sono distinti per semantica, caratteri (quindi la sharfes es tedesca o versione greca sono codici diversi), se ho una P in alfabeti diversi hanno codifiche diverse. Non ho cose riguardanti la grafica!.\nla Composizione dinamica √® una cosa molto cool, per esempio √® quello che sto utilizzando ora, il fatto che scrivo `e, e mi appare la √® accentata.\nSlides\nUniversal Coded Character/UNICODE üü©- Universal Coded Character same as UCS-2 UCS-4\nIn UCS-4 il primo bit √® utilizzato per identificare la differenza fra UTF-8 e UCS-4.\nSlide struttura generale\nIl piano 14 √® in disuso, per tag strani.\nBasic Multilingual Plane (BMP) sono tutti i caratteri nel piano 0, sono quelli pi√π comuni per alfabeti west\nEsempio suddivisione dei piani\nQuesto √® una cosa svantaggiosa per i caratteri latini che andavano gi√† bene con un singolo byte per trasmettere, ecco che entra in gioco il UTF.\nUnicode Trasformation Format üü©- Anche conosciuto come UTF-8. √à una forma variabile per la rappresentazione precedente, il motivo principale per cui esiste √® che per gli americani sarebbe stata una perdita enorme dover aggiungere quell‚Äôoverhead inutile nella loro trasmissione, loro con 256 restavano gi√† bene.\nSlide necessit√† di UTF\nSpazi di codifica in UTF ASCII √® compatibilissimo per UTF, in 2 byte ho tutti il resto dei caratteri. in 3 byte stanno tutti i caratteri CJK, in 4 byte stanno tutti i caratteri antichi.\nSlide numero di byte necessari per la codifica\nStruttura dei caratteri in UTF Essendo questa una codifica variabile non ho possibilit√† di predire il numero di caratteri in un file, perch√© certi caratteri occuperanno un byte (ASCII normale), mentre altri caratteri occuperanno due byte, come le lettere accentate.\nAllora devo utilizzare un codice per capire se sono all‚Äôinizio del blocco o sto continuando, o lo devo droppare (quando ricevo 10, ma non ho nessun blocco iniziato!) (sono gli schemi di 10, 0, e 110 etc..)\nLa cosa importante √® che ASCII √® subset diretto di UTF, dato che i caratteri latini sono sempre un singolo byte.\nConfronto UTF e UCS\nAlcuni problemi di trasmissione e conversione Byte order mark üü© Utilizzato per risolvere il problema di risolvere se interpretare quanto mandato in Little o big endian.\nUtilizziamo un carattere speciale in unicode, chiamato Zero-Width No-Break Space (ZWNBSP), Il cui codice √® FEFF per capire se il sistema che mi sta mandando qualcosa √® in formato little endian oppure big endian, accennato qui (molto importante per l\u0026rsquo;ordinamento!)\nSlide\nUTF-8 vs Latin-1 üü© Si possono avere problemi di conversione fra questi due standard (perch√© latin 1 utilizza un singolo byte per le cose accentate, mentre utf-8 ne utilizza due).\nSlide problemi comuni di conversione\nContent encoding Escaping ed encoding üü© La necessit√† di fare encoding o escaping √® giustificata principalmente dal fatto che certe applicazioni utilizzano certi caratteri come simboli speciali (e quindi non si potrebbe utilizzarli, un esempio √® l‚Äôandare accapo credo).\nIn pratica si utilizzano questi metodi per aggirare quelli\nEscaping Ossia sostituiamo il carattere proibito con sequenze alternative che corrispondono alla stessa cosa. Ad esempoio \u0026amp;quot rappresentano le virgolette\nEncoding Encoding quando utilizzo una sintassi speciale per rappresentare il suo encoding naturale.\nMIME I Limiti di SMTP (3) SMTP √® un protocollo molto vecchio, affinch√© le necessit√† nuove siano retrocompatibili, sono presenti alcuni accorgimenti che vedremo in sto pezzo.\nPrincipalmente questi problemi di endoing e escaping sono nati nell‚Äôambiente del protocollo SMTP, perch√©e li c‚Äôerano alcuni caratteri speciali del protocollo, e potevi mandare solamente ascii 7 bit.\nslides limiti SMTP\nMassimo 1 MB Solo ascii 7 bit Ogni 1000 caratteri ci deve essere un CRLF. Il motivo √® che queste restrizioni erano presenti nelle RFC iniziali per SMTP, e dato che non possiamo farne nuovi (troppo costo prolly) ci dobbiamo tenere queste cose.\nGuardare internet message format\nSu come funziona SMTP sono accennate in Livello applicazione e socket\nMultipurpose Internet Mail Extensions üü© il mime riesce a risolvere questi problemi di limiti di SMTP, riesco a trasformare il tutto in un formato compatibile, e riesco anche a ritrasformarlo indietro!\nSchema protocollo MIME\nIn questo modo riesco a risolvere tutti i problemi di limiti SMTP\nCaratteri ASCII US Le sequenze CRLF E la lunghezza dei messaggi (che viene spezzato) TODO: parlare del multitipo\nHeaders del MIME (2)üü® Esempio di headers MIME\nDevono essere specificati due campi:\nContent Type (il tipo del dato, con sottotimo e altri parametri utili che viene mandato, per capire poi dal ricevente cosa conviene convocare per capire il messaggio) Content-Transfer encoding, sono modalit√† per codificare i dati in modo che possano essere adatti al MIME. Esempi di transfer encoding sono sotto. Quoted Printable and Base 64 üü© Esempi di CTE sono quoted-printable, BASE64, nel primo si fanno escaping per caratteri che non sono printabili con un = seguito dal numero corrisopndente al carattere, di solito sono utilizzati solamente per messaggi con poche eccezzioni rispetto ASCII\nSlide Quoted-printable\nBASE64 da leggere BaseSessantaquattro, o BeisSicstiFor, non mix.\nPer BASE √® tutto tradotto in una codifica byte printabile, ossia si utilizzano 64 caratteri ASCII printabili per codificare 3 byte alla volta, questi 3 byte sono codificati in 4 lettere della mappa precedente, che si noti sono 2alla 6 caratteri.\nSe mi mancano byte alla fine aggiungo del padding, che sono delle = nella parte encodata (il resto sono degli 0 credo).\nSlides base64\n","permalink":"https://flecart.github.io/notes/codifica-dei-caratteri/","summary":"\u003ch3 id=\"introduzione-sullencoding\"\u003eIntroduzione sull\u0026rsquo;encoding\u003c/h3\u003e\n\u003cp\u003eOssia trattiamo metodi per codificare caratteri dei linguaggi umani, come ASCII, UCS e UTF.\u003c/p\u003e\n\u003cp\u003eDigitalizzare significa encodarlo in un sistema che possa essere memorizzato su un dispositivo di memorizzazione elettronico. Ovviamente non possiamo mantenere l\u0026rsquo;informazione cos√¨ come √®, ma vogliamo memorizzarne una forma equivalente, ma pi√π facile da manipolare dal punto di vista del computer. Creiamo quindi un mapping, o anche isomorfismo tra il valore di mappatura (o encoding), solitamente un valore numerico, tra il singolo valore atomico originale e il numero.\u003c/p\u003e","title":"Codifica dei caratteri"},{"content":"This note is useful to gather in a single place the description of some common problems in CS and their theoretical implications explained in other notes.\nThe Clique problem Description of the problem This problem is in NP, find all sub-graphs where all nodes are connected (this set of nodes forms a complete graph).\nWe can prove that the problem is in NP because there is an easy non-deterministic algorithm that computes it. See Time and Space Complexity#Clique problem for details of this proof.\nA little more formally: Given a graph $\\langle G, E \\rangle$ we say that the solver for the clique problem returns a list of nodes $N \\subseteq G$ such that that is a complete graph. A subset of this problem is when we need cliques of $k$ nodes. So the problem is to return these $k$ nodes if they exist (or just say they don\u0026rsquo;t ).\nThe SAT problem SAT stands for SATisfiability.\nBackground notions Boolean formulas We define a language with variables and their negations. Logical and and or operations. Then we assign all possible values to the variables and see their end values after passing to the polynomial problem. But this explodes exponentially. Sometimes the boolean formula is in Logica Proposizionale, another time using Logica del Primo ordine.\nThird conjunct normal form If we have only OR operations, that is a clause. Then we say it is in conjunct normal form if these clauses are linked with AND operations. It\u0026rsquo;s third when the clauses have exactly tree variables.\nWhy is this problem important Many historical approaches used this problem to think about satisfiability. This problem is also important in constraint programming. TODO: add links in the future when it happens.\nDefinition of 3-SAT problem Given a third conjunct normal form, find assignments such that it satisfies the boolean formula.\n3-SAT $\\leq_{P}$ CLIQUE We prove using the notion of Cook-Levin and Savitch#Poly-reduction that 3-sat is reducible polynomially to clique.\nIn order to do this we need to transform the problem into graph format, and graph format to assignments.\nConversion strategyüü© For every clause we defines 3 nodes. Then we link every node in this way:\nIf in same clause, don\u0026rsquo;t link If in other link, link only if it\u0026rsquo;s not your negation. Example:\nWe can prove that this conversion is polynomial (clear, you can write the algo and prove it üí†).\nWhy does the conversion work? Now, if the 3-SAT formula is satisfiable, then at least one node for each clause is true. We select a single true node for each clause, and this brings us the clique. By construction, this is a complete sub-graph. So this reduction works. Why does it work? Because as we have $k$ clauses, we have selected a node from each clause, and we know that each node is connected to each other node, because if not that wouldn\u0026rsquo;t be satisfied (by construction there is a link with other node $\\iff$ the node is in other triplet $\\land$ it\u0026rsquo;s not himself negated).\nWe now have a graph, let\u0026rsquo;s suppose we have a clique, then the 3-SAT is satisfiable because of similar arguments above (just assign true to those variables).\nTrue quantified Boolean formula Also called TQBF, it is defines as follows:\n$$ TQBF = \\left\\{ \\langle F \\rangle \\mid F \\text{ is a true boolean statement } \\right\\} $$ Where statement is a boolean formula were the values are all bounded. This problem is important for Time and Space Complexity analysis.\nTQBF is PSPACE-complete Remember that a problem is PSPACE complete if it is in PSPACE and every other PSPACE languages can be poly-reduced to this language.\nTQBF is in PSPACE This technique is something similar to Sintassi e RI strutturali technique.\nIf there are no quantifiers, evaluate the statements, and if it is true accept, else reject. If we have a format like $F = \\exists x.G$ Then enumerate all: evaluate the truthfulness given $x = 1$, and then with $x = 0$ if one of them is true then return true. If we have a format like $F = \\forall x. G$ then evaluate both $x= 1$ and $x = 0$ and if both true return true. This is a recursive algorithm, and it is $O(m)$ where $m$ are the terms (max $m$ recursive passes, every recursive pass has at most a single term memorized). $\\square$. TQBF is PSPACE-hard This is difficult to grasp. Go to see (Sipser 2012) Chapter 8.3 pp. 340.\nThe idea is to convert the computation of the TM that decides the given language $L$ using some formulas like $\\phi_{c_{1}, c_{2}, t}$ which means that this is true if it\u0026rsquo;s possible to go from $c_{1}$ to $c_{2}$ in at most $t$ steps. In this setting $c_{1}$ and $c_{2}$ are different configurations of the Turing Machine.\nThe proof is by induction:\nIf $t=1$ then $c_{1}=c_{2}$ or it\u0026rsquo;s possible to go into $c_{2}$ using a single step. This is verifiable using the windows argument in the Cook-Levin theorem. Else it\u0026rsquo;s a little bit more difficult. It\u0026rsquo;s easy to verify it ü§†. $$ F_{c, c', t} = \\exists m_{1} \\forall(c_{3}, c_{4}) \\in \\left\\{ (c, m_{1}), (m_{1}, c') \\right\\} F_{c_{3}, c_{4}, \\frac{t}{2}} $$ Given this inductive formulation, we can observe that we add only $O(n^{k})$ quantifiers in the recursive proof. So the formula has $\\log (2^{dn^{k}})$ induction steps which is $O(n^{k})$. So this problem is PSPACE-hard. Two player games It is possible to prove that every two player zero-sum game like chess or Go, that uses a minimax tree search strategy can be expressed into a TQBF problem like this (informally): For every move of the opponent, exists one of my moves such that for every move of the opponent \u0026hellip;. -\u0026gt; I win. This is a TQBF statement.\nThe Tiling Problem Formalizzazione del problema Definizione formale del tiling Consideriamo una tupla $\\langle \\mathcal{T}, t_{0}, H, V \\rangle$\n$\\mathcal{T}$ √® un insieme di piastrelle. $t_{0} \\in \\mathcal{T}$ √® la piastrella d\u0026rsquo;origine. $H \\subseteq \\mathcal{T} \\times \\mathcal{T}$ le regole di adiacenza orizzontali. $V \\subseteq \\mathcal{T} \\times \\mathcal{T}$ le regole di adiacenza verticali. L\u0026rsquo;obiettivo √® vedere se √® possibile riempire tutto il piano con queste piastrelle, all\u0026rsquo;infinito. Sappiamo gi√† che non √® sempre possibile farlo. Ci chiediamo se √® automatizzabile. Questo problema √® stato risolto nel 1966, e sembra non essere riconoscibile nemmeno.\nOssia in matematichese definire la funzione $f : \\mathbb{N} \\times \\mathbb{N} \\to \\mathcal{T}$ Con\n$f(1, 1) = t_{0}$ $\\forall n,m \\in \\mathbb{N}, (f(n, m), f(n + 1, m)) \\in V$ $\\forall n,m \\in \\mathbb{N}, (f(n, m), f(n, m+1)) \\in H$ Strategia di dimostrazione Vogliamo ridurlo da $ETH^{-}$ che abbiamo spiegato in Halting Theorem and Reducibility. Questo √® un linguaggio non riconoscibile, perch√© il suo complemento √® riconoscibile in modo banale.\nQuesta dimostrazione avr√† un sacco di punti molto tecnici per dire che una macchina di turing deve essere tradotta in un problema di tiling\u0026hellip;\nDimostrazione irriconoscibilit√† del tiling L\u0026rsquo;idea principale √® che con un tiling posso simulare l\u0026rsquo;esecuzione di una macchina di Turing. E in questo modo riduco il problema a un Halt. Perch√© sapere tassellare significa sapere dire quando una macchina di Turing finisce.\nCodifica delle regole dei tiling Posso codificare sia i tile disponibili, sia le regole di adiacenza in questo modo.\nPoi vogliamo codificare ogni casella verticale un singolo step di computazione.\nCella di identit√† Questa cella non fa niente. Celle di transizione Possiamo codificare le funzioni di transizione della macchina di Turing. Poi ho ancora le cose che mantengono il simbolo nella cella di arrivo.\nConclusione sse non si ferma la macchina, allora esiste un tiling (che √® una cosa banale perch√© significa che continua all\u0026rsquo;infinito, e quindi posso mappare tutto).\nReferences [1] Sipser ‚ÄúIntroduction to the Theory of Computation‚Äù Cengage Learning 2012\n","permalink":"https://flecart.github.io/notes/common-problems-in-theoretical-cs/","summary":"\u003cp\u003eThis note is useful to gather in a single place the description of some common problems in CS and their theoretical implications explained in other notes.\u003c/p\u003e\n\u003ch2 id=\"the-clique-problem\"\u003eThe Clique problem\u003c/h2\u003e\n\u003ch3 id=\"description-of-the-problem\"\u003eDescription of the problem\u003c/h3\u003e\n\u003cp\u003eThis problem is in NP, find all sub-graphs where all nodes are connected (this set of nodes forms a complete graph).\u003c/p\u003e\n\u003cp\u003eWe can prove that the problem is in NP because there is an easy non-deterministic algorithm that computes it.\nSee \u003ca href=\"/notes/time-and-space-complexity/#clique-problem\"\u003eTime and Space Complexity#Clique problem\u003c/a\u003e for details of this proof.\u003c/p\u003e","title":"Common problems in Theoretical CS"},{"content":"Intractable problems are solvable in principle, but in reality they require so much time or space that there no physical computers that can solve them in reasonable time. We would like to define a clear hierarchy of these set of problems.\nSpace Hierarchies Def: Space constructible We say that a function $f: \\mathbb{N} \\to \\mathbb{N}$ such that $f(n) \\geq O(\\log n)$ is space constructible if there exists a function from $1^{n} \\to \\langle f(n) \\rangle$ is $O(f(n))$ space complexity.\nIntuitively, it is just a function that is computable in a specifically limited space. But at the moment I don\u0026rsquo;t know why is this important.\nSpace hierarchy theorem For any space constructible function $f: \\mathbb{N} \\to \\mathbb{N}$ there exists a language $A$ decidable in $O(f(n))$ but not in $o(f(n))$ space.\nProof of the theorem The proof is quite convoluted, and has some technical details that are quite ad-hoc to make things work. I personally think this is quite useless, and the hypothesis is quite intuitive with standard understanding. Nonetheless, we should need to understand the argument.\nDefine this algorithm: D = ‚ÄúOn input $w$:\nLet n be the length of $w$. Compute $f(n)$ using space constructibility and mark off this much tape. If later stages ever attempt to use more, reject . If w is not of the form $\\langle M \\rangle 10 ^{*}$ for some TM M , reject . Simulate M on w while counting the number of steps used in the simulation. If the count ever exceeds $2^{f(n)}$, reject . If M accepts, reject . If M rejects, accept .‚Äù Then the language defined as $\\left\\{ \\omega : D \\text{ accepts } \\omega \\right\\}$ is the language we want in the statement.\nMain consequence of Hierarchy theorem For all $k, j$ such that $k \u003c j$ we have that\n$$ SPACE(n^{k}) \\subset SPACE(n^{j}) $$ NOTE: contained, and not equal!\n$$ SPACE(f(x)) \\subset SPACE(g(x)) $$ Other: PSPACE is in EXPSPACE\nWhy is this concept useful? This allows us to categorize problems is different and not equal complexity classes. In my own opinion this is probably caused by human need to make order in this meaningless caos. I don\u0026rsquo;t know effective practical applications of this theory. But we need to be grounded on real problems, those are the ones driving innovation.\nTime Hierarchies Def: Time constructible This is the same as #Def Space constructible.\nWe say that a function $f: \\mathbb{N} \\to \\mathbb{N}$ such that $f(n) \\geq O(n\\log n)$ is time constructible if there exists a function from $1^{n} \\to \\langle f(n) \\rangle$ is $O(f(n))$ Time complexity.\nTime hierarchy theorem This theorem is analogous to the space complexity counter-part, with a small formality of simulating the given Turing machine.\nFor any time constructible function $f: \\mathbb{N} \\to \\mathbb{N}$ there exists a language $A$ decidable in $O(f(n))$ but not in $o\\left( \\frac{f(n)}{\\log f(n)} \\right)$ time.\n","permalink":"https://flecart.github.io/notes/complexity-hierarchies/","summary":"\u003cp\u003eIntractable problems are solvable in principle, but in reality they require so much time or space that there no physical computers that can solve them in reasonable time.\nWe would like to define a clear hierarchy of these set of problems.\u003c/p\u003e\n\u003ch2 id=\"space-hierarchies\"\u003eSpace Hierarchies\u003c/h2\u003e\n\u003ch3 id=\"def-space-constructible\"\u003eDef: Space constructible\u003c/h3\u003e\n\u003cp\u003eWe say that a function $f: \\mathbb{N} \\to \\mathbb{N}$ such that $f(n) \\geq O(\\log n)$ is space constructible if there exists a function from $1^{n} \\to \\langle f(n) \\rangle$ is $O(f(n))$ \u003ca href=\"/notes/time-and-space-complexity/\"\u003espace complexity\u003c/a\u003e.\u003c/p\u003e","title":"Complexity Hierarchies"},{"content":"Lempel-Ziv-Welch Algorithm Introduzione sul funzionamento Primo scan con un dizionario indexato dei singoli caratteri Poi viene cercato di raggruppare caratteri a coppie. Se una coppia √® gi√† presente nel dizionario, allora aggiungo al dizionario una cosa pi√π lunga e metto un code diverso Esempio di sopra. La cosa carina √® che il dizionario si pu√≤ ricostruire in fase di decoding.\nTutti gli altri, tipo zip, gzip, png si basano poi su questa idea. Per certi versi la cosa di raggruppare √® simile a Byte pair encoding.\nHuffman Codes Questa parte probabilmente √® stata anche trattata in modo molto breve al corso di algoritmi. Basato sul paper di 1952 \u0026ldquo;A method for the construction of minimum redundancy codes\u0026rdquo;. Di Huffman L\u0026rsquo;idea principale √® creare un albero di codifica in modo che le cose frequenti siano in cima, ossia hanno un codice molto breve, mentre cose lunghe abbiano codici pi√π lunghi.\nIl codice di Huffman √® un algoritmo che nella media ha compressione migliore lossless. Ossia si ha $L^{*}(C_{huffman}) \\leq L(C)$ per qualunque altro carattere. Ha anche relazioni con le prefix strings, ne si parla di pi√π in Entropy, e ci sono note molto interessanti su questo algoritmo. Si pu√≤ dimostrare che √® algoritmo di compressione lossless migliore. Che √® una cosa affascinante.\nAssumiamo che ogni carattere abbiano una frequenza.\nAlgoritmo di Huffman Creo una lista ordinata dalla frequenza Inizio ad assegnare codici a questa lista volta per volta partendo dai pi√π bassi Inserisco in cima creando nuovi nodi (che reinserisco) volta per volta sempre prendendo il pi√π basso di frequenza Si crea un prefix-code in questo modo che si pu√≤ utilizzare a piacere. Una volta creato questo albero, posso usarlo per codificare e anche decodificare. \u0026#34;\u0026#34;\u0026#34; Huffman code generator -- after [https://stackoverflow.com/questions/11587044/how-can-i-create-a-tree-for-huffman-encoding-and-decoding](https://stackoverflow.com/questions/11587044/how-can-i-create-a-tree-for-huffman-encoding-and-decoding) \u0026#34;\u0026#34;\u0026#34; GRAPHIMAGE = \u0026#39;HuffmanGraph\u0026#39; # for Huffman tree display. SOURCETXT = \u0026#39;texts/English.txt\u0026#39; # for statistics ###################################### # Huffman coding # ##################### ######## def assign_code (nodes, label, result, prefix = \u0026#39;\u0026#39;): childs = nodes[label] tree = {} if len(childs) == 2: tree[\u0026#39;0\u0026#39;] = assign_code(nodes, childs[0], result, prefix+\u0026#39;0\u0026#39;) tree[\u0026#39;1\u0026#39;] = assign_code(nodes, childs[1], result, prefix+\u0026#39;1\u0026#39;) return tree else: result[label] = prefix return label def huffman_code(_vals): vals = _vals.copy() nodes = {} for n in vals: # leafs initialization nodes [n] = [] while len (vals) \u0026gt; 1: # binary tree creation s_vals = sorted(vals.items(), key=lambda x:x[1]) al = s_vals[0][0] a2 = s_vals[1][0] vals[al + a2] = vals.pop(al) + vals.pop(a2) nodes[al + a2] = [al, a2] code = {} root = al+a2 tree = {} tree = assign_code (nodes, root, code) # assignment of the code for the given binary tree return code, tree Proof of Optimality Given an alphabet $\\Sigma$ and a set of words $\\Omega \\subseteq \\mathbb{P}(\\Sigma)$. Assuming $p(\\omega_{1})$ is the probability of word $\\omega_{1}$ in the corpus, and $l(\\omega_{1})$ is it\u0026rsquo;s length (that are elements of the alphabet that compose it), we need to prove that $L = \\sum_{i} p(\\omega_{i}) l(\\omega_{i})$ produced by the Huffman coding algorithm is the minimum possible.\nObservations (informal):\nHuffman already produces strings such that $p_{i} \\geq p_{j} \\implies l_{i} \\geq l_{j}$, this could be deduced by the construction of the tree. I think it is provable that Huffman produces always complete codes. If the code is complete, gain is expected code length is possible only by switching assignments to the labels, or push some down and others up, preferring some. But from point 1 we know that this is already optimal. This concludes high-level reasoning. ","permalink":"https://flecart.github.io/notes/compression-algorithms/","summary":"\u003ch3 id=\"lempel-ziv-welch-algorithm\"\u003eLempel-Ziv-Welch Algorithm\u003c/h3\u003e\n\u003ch4 id=\"introduzione-sul-funzionamento\"\u003eIntroduzione sul funzionamento\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003ePrimo scan con un dizionario indexato dei singoli caratteri\u003c/li\u003e\n\u003cli\u003ePoi viene cercato di raggruppare caratteri a coppie.\u003c/li\u003e\n\u003cli\u003eSe una coppia √® gi√† presente nel dizionario, allora aggiungo al dizionario una cosa pi√π lunga e metto un code diverso\u003c/li\u003e\n\u003cli\u003e\n\u003cimg src=\"/images/notes/Introduction to Algorithmic Information and Complexity-20240217115716857.webp\" alt=\"Introduction to Algorithmic Information and Complexity-20240217115716857\"\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eEsempio di sopra.\nLa cosa carina √® che il dizionario si pu√≤ ricostruire in fase di decoding.\u003c/p\u003e","title":"Compression Algorithms"},{"content":"introduzione ai dielettrici Esperimenti metalli e dielettrici üü© $$ V_{s} = (h - s) E_{0} $$ Questo √® vero perch√© semplicemente in mezzo al conduttore il campo elettrico √® nullo, come spiegato in Conduttori elettrici, quindi durante l\u0026rsquo;integrale, il percorso √® semplicemente minore, esattamente di quella quantit√†.\n$$ k = \\frac{V_{0}}{V_{k}} \u003c 1 $$Costante dielettrica relativa üü© $$ E_{k} = \\frac{V_{k}}{h} = \\frac{V_{0}}{kh} = \\frac{E_{0}}{k} = \\frac{\\sigma_{0}}{k\\varepsilon_{0}} = \\frac{\\sigma_{k}}{\\varepsilon_{0}} = \\frac{\\sigma_{0}}{\\varepsilon} $$$$ E_{k} = \\frac{\\sigma_{0}}{\\varepsilon_{0}} - \\frac{\\sigma_{p}}{\\varepsilon_{0}} $$$$ \\sigma_{p} = \\frac{k - 1}{k} \\sigma_{0} $$$$ \\sigma_{k} = \\sigma_{0} - \\sigma_{p} = \\frac{\\sigma_{0}}{k} $$ Qui si pu√≤ giocare un po\u0026rsquo; senza nessun problema!\nL\u0026rsquo;equazione del nuovo campo elettrico √® utile per avere una intuizione, √® come se esistesse un campo contrario creato dal dielettrico, che ne affievolisce l\u0026rsquo;intensit√†, questo sar√† spiegato meglio dopo, esisteranno seriamente queste cariche!\nCostante dielettrica assoluta del dielettrico üü© $$ C_{p} = \\frac{q}{V_{p}} = \\frac{qk}{V_{0}} = k C_{0} $$$$ \\text{costante dielettrica assoluta del dielettrico: }\\varepsilon = k\\varepsilon_{0} $$$$ C_{p} = kC_{0} = k \\varepsilon_{0} \\frac{S}{d} = \\frac{\\varepsilon S}{d} $$ E notiamo che cambia solamente il valore di dielettrico, √® ancora molto clean la relazione.\nSecondo me non ha senso questa parte e possiamo soltanto dire che la capacit√† cresce col dielettrico\nPolarizzazione del dielettrico Polarizzazione per deformazione/elettronica üü®+ Questa polarizzazione si spiega a un **livello atomico** perch√© intuitivamente si pu√≤ dire che il punto medio delle cariche elettriche positive (nucleo) e negative (nube di elettroni) quando viene sottoposto a un campo elettrico si spostano, per cercare di bilanciare la piccola forza applicata dal campo elettrico, quindi √® un valore direttamente proporzionale al valore del campo elettrico, In questo caso: $$ \\vec{p}_{e} = Ze\\vec{x} $$ Con x il vettore della congiungente, $Z$ numero atomico $e$ la carica basilare dell'elettrone. Da quanto studiato in [Dipolo elettrico](/notes/dipolo-elettrico), quando ho un momento, c'√® un campo indotto. Insieme a questo, i mini dipoli si orientano sul verso del campo elettrico.\nPolarizzazione per orientamento (non fatta) Questo viene usato per discutere a livello molecolare come avviene la polarizzazione. Se prendo molecole polari, come l\u0026rsquo;acqua, si avr√† che pi√π √® sottoposta a campo intenso, pi√π in media i dipoli saranno orientati sul campo, infatti se non lo sono allora ci sar√† un momento di dipolo che prover√† a riportarli in quello stato, come studiato in Dipolo elettrico nella sezione dei momenti di dipolo.\nLa differenza col precedente √® che questo √® solamente un effetto di media!\nSuscettibilit√† elettrica (!) Definizione di suscettibilit√† elettrica üü© $$ \\text{ suscettivit√† dielettrica: } \\chi = k - 1 = \\frac{V_{k}}{V_{0}} - 1 $$Andiamo a definire un valore $P$ che spiega quanto dipolo creato dal campo, ed √® in pratica momento di dipolo per unit√† di volume. Solitamente assume questa forma: $$\nP = \\varepsilon_{0}\\chi E $$ Se un dielettrico soddisfa questa relazione (solitamente √® omogeneo) si dice che sia dielettrico lineare, solitamente materiali amorfi (senza forma), dotati di isometria spaziale, nei cristalli in genere questo non succede.\nDimostrazione valore üü® NOTA: nell'immagine ho sbagliato a disegnare il verso dei singoli atomi allungati. $$ \\sigma_{p} = nq\\delta $$ Perch√© in pratica $n = \\frac{\\Delta N}{\\Delta \\tau}$ √® la densit√† atomica (numeri di atomi per unit√† di volume), io con la relazione di sopra sto anche moltiplicando per la lunghezza del tratto considerato, quindi $n\\delta$ rappresenta numero di atomi nella superficie (dato che $n$ √® il numero di atomi per volume, moltiplicando per una lunghezza ho la densit√† superficiale), e $q$ gli do la carica, dimensionalmente torna l\u0026rsquo;idea. Ogni atomo ha $q$ di carica a causa della polarizzazione.\n$$ \\sigma_{p} = \\lvert \\vec{P} \\rvert $$$$ \\sigma_{p} = \\vec{P} \\cdot \\hat{n} $$$$ E = \\frac{\\sigma_{0} - \\sigma_{p}}{\\varepsilon_{0}} = \\frac{\\sigma_{0} - \\lvert \\vec{P} \\rvert}{\\varepsilon_{0}} \\implies P = \\sigma_{0} - \\varepsilon_{0}E = kE\\varepsilon_{0} - \\varepsilon_{0} E = \\varepsilon_{0}E(k - 1) = \\varepsilon_{0}E\\chi $$Valore tensoriale üü© Solitamente per materiali non isotropi √® un tensore, quindi lo abbiamo in una forma del genere $$ \\begin{pmatrix} P_{x} \\ P_{y} \\ P_{z}\n\\end{pmatrix} \\begin{pmatrix} \\chi_{11} \u0026amp; \\chi_{12} \u0026amp; \\chi_{13} \\ \\chi_{21} \u0026amp; \\chi_{22} \u0026amp; \\chi_{23} \\ \\chi_{31} \u0026amp; \\chi_{32} \u0026amp; \\chi_{33} \\\n\\end{pmatrix} \\cdot \\begin{pmatrix} E_{x} \\ E_{y} \\ E_{z} \\end{pmatrix} $$ Ma per qualche motivo che non conosco $\\chi$ √® una **matrice simmetrica reale** questo implica che √® diagonalizzabile per cui esiste una base di autovalori, che permette di riscrivere la matrice di sopra come $$ \\begin{pmatrix} P_{x} \\ P_{y} \\ P_{z} \\end{pmatrix} \\begin{pmatrix} \\chi_{11}\u0026rsquo; \u0026amp; 0 \u0026amp; 0 \\ 0 \u0026amp; \\chi_{22}\u0026rsquo; \u0026amp; 0 \\ 0 \u0026amp; 0 \u0026amp; \\chi_{33}' \\end{pmatrix} \\cdot \\begin{pmatrix} E_{x} \\ E_{y} \\ E_{z} \\end{pmatrix} $$ Che √® anche pi√π veloce da calcolare. La base di autovalori si chiama anche asse ottico\nPolarizzazione in materiali non omogenei Caso dipolo omogeneo üü© $$ \\Delta Q = \\oint_{\\Sigma} \\vec{P} \\cdot d\\vec{s} = 0 $$ Si pu√≤ dire che √® uguale a zero perch√© il flusso esce ed entra, per lo stesso valore.\nCaso dipolo non omogeneo üü© $$ \\Delta Q = \\oint_{\\Sigma}\\vec{P} d\\vec{s} = \\int _{V(\\tau)} \\vec{\\nabla} \\cdot\\vec{P} \\, d\\tau $$$$ \\vec{\\nabla} \\cdot \\vec{P} = - \\rho_{i} $$ Ossia la divergenza del momento di dipolo per unit√† di volume √® uguale a meno densit√† di volume elettrico indotto internamente.\nEquazioni di Gauss rivisitate üü© Possiamo ora aggiornare le equazioni di gauss andando a contare gli effetti del dipolo in modo esplicito, abbiamo che\nForma divergente Forma integrale $\\vec{\\nabla} \\cdot \\vec{E} = \\frac{\\rho}{\\varepsilon_{0}}$ $\\oint_{\\Sigma} \\vec{E} \\cdot d\\vec{s}$ $\\vec{\\nabla} \\times \\vec{E} = 0$ $\\oint_{\\Gamma} \\vec{E} \\cdot d\\vec{s} = 0$ $\\vec{\\nabla} \\cdot \\vec{P} = -\\rho_{p}$ $\\oint_{\\Sigma} \\vec{P} \\cdot d\\vec{s} = Q_{p}$ $\\vec{\\nabla} \\cdot \\vec{D} = \\rho_{\\text{libero}}$ $\\oint_{\\Sigma} \\vec{D} \\cdot d\\vec{s} = Q_{L}$ $$ \\vec{\\nabla} \\cdot \\vec{E} = \\frac{\\rho_{libero}}{\\varepsilon_{0}} + \\frac{\\rho_{pol}}{\\varepsilon_{0}} \\implies \\varepsilon_{0} \\vec{\\nabla} \\cdot \\vec{E} = \\rho_{libero} - \\vec{\\nabla} \\cdot \\vec{P} \\implies \\vec{\\nabla}(\\varepsilon_{0} \\vec{E} + \\vec{P}) = \\rho_{libero} $$Vettore di spostamento elettrico/induzione dielettrica üü© $$ \\vec{D} = \\varepsilon_{0}\\vec{E} + \\vec{P} = \\varepsilon_{0}(\\vec{E} + \\chi \\vec{E}) = k\\vec{E}\\varepsilon_{0} = \\varepsilon \\vec{E} $$$$ \\vec{P} = \\frac{k-1}{k} \\vec{D} $$ Possiamo notare che il vettore di spostamento non √® altro che il campo elettrico per un dielettrico differente.\n$$ \\vec{\\nabla} \\cdot \\vec{D} = \\rho_{libero} $$$$ \\oint_{\\Sigma} \\vec{D} \\cdot d\\vec{s} = Q_{L} $$ Ossia questo √® un valore che dipende solamente dalla carica LIBERA, per questo vettore di spostamento posso ignorare il valore di polarizzazione indotta.\nDiscontinuit√† nei dielettrici Sappiamo che le componenti tangenti vengono conservate passando da una superficie all\u0026rsquo;altra (vedi Campo elettrico), e anche le discontinuit√† per componenti perpendicolari. Ora vogliamo vedere se vale la stessa cosa nei dielettrici, quando abbiamo solamente cariche di polarizzazione, ed entrambi valgono ancora (ma la sigma nel secondo caso √® di polarizzazione)\nDiscontinuit√† superficiale üü©\u0026ndash; $$ \\oint_{\\Sigma}\\vec{E} d\\vec{s} = \\frac{Q_{T}}{\\varepsilon_{0}} \\implies \\Delta E_{\\perp} = \\frac{\\sigma_{p}}{\\varepsilon_{0}} $$ Da quanto fatto col vettore di spostamento avrebbe senso vedere cosa succede in quel caso. dato che dipende solamente da cariche libere abbiamo che\n$$ \\oint_{\\Sigma}\\vec{D} d\\vec{s} = Q_{Libero} = 0 $$ Quindi il vettore di spostamento per il dielettrico √® ancora costante, non varia diciamo passando da una superficie all\u0026rsquo;altra, quindi √® continua.\n$$ \\vec{D}_{1}d\\vec{S}_{1} + \\vec{D}_{2}d\\vec{S}_{2} = 0 \\implies \\vec{D}_{1}\\cos \\theta_{1} + \\vec{D}_{2} \\cos \\theta_{2} = 0 \\implies D_{1}\\cos \\theta_{1} - D_{2} \\cos \\theta_{2} = 0 $$$$ \\Delta D_{N} = 0 $$Legge di Snell revisited üü©\u0026ndash; Una volte descritte le equazioni di continuit√† ricavare questo √® molto semplice, poi √® molto molto simile (opposto) a quanto fatto per Magnetismo nella materia per la continuit√† dei campi magnetici nel passare su superfici con correnti.\nSappiamo che $E_{\\parallel}^{1} = E_{\\parallel}^{2}$, che $E_{\\perp}^{1} = E_{\\perp}^{2}$ e che $D_{\\perp}^{1} = D_{\\perp}^{2}$ E che $\\vec{D} = \\varepsilon_{0}k\\vec{E}$ Da quello sappiamo che $$ \\varepsilon_{0} k_{1} E^{1}_{\\perp} = \\varepsilon_{0}k_{2}E_{\\perp}^{2} $$$$ \\begin{cases} E_{1}\\sin \\theta_{1} = E_{2}\\sin \\theta_{2} \\\\ k_{1}E_{1}\\cos \\theta_{1} = k_{2}E_{2} \\cos \\theta_{2} \\end{cases} \\implies \\frac{\\tan \\theta_{1}}{k_{1}} = \\frac{\\tan \\theta_{2}}{k_{2}} \\implies \\frac{k_{2}}{k_{1}} = \\frac{\\tan \\theta_{2}}{\\tan \\theta_{1}} $$ Quindi so esattamente in che modo il modulo e la direzione di $E$ cambia all\u0026rsquo;interno della superficie di separazione dei mezzi. Quindi se passo da superficie con $k_{2}$ pi√π alto i raggi tendono verso l\u0026rsquo;esterno (angolo pi√π grande), e stessa cosa al contrario. NOTA: il modulo del campo elettrico cambia sempre. NOTA-2: basta guardare le linee di campo per sapere se il materiale √® conduttore o meno (perch√© per il conduttore cambia le linee di campo anche all\u0026rsquo;esterno).\nEnergia nei condensatori con dielettrico (!) Derivazione con dielettrico üü©\u0026ndash; Sappiamo che l\u0026rsquo;energia totale √® ancora $$ U_{e} = \\frac{1}{2} CV^{2} = \\frac{1}{2} \\frac{\\varepsilon S}{d} V_{k}^{2} = \\frac{1}{2} \\varepsilon S E_{k}^{2}d = \\frac{1}{2}\\varepsilon E_{k}^{2} (Sd) = u_{e} \\cdot \\text{ Volume} $$ Solo che √® da considerare la $E_{k}$ presente con il dielettrico che √® uguale a $\\frac{E_{0}}{k}$ Possiamo calcolarlo anche in altro modo: $$ U = \\frac{1}{2} \\frac{Q^{2}}{C} = \\frac{1}{2} (\\sigma S)^{2} \\cdot \\frac{d}{\\varepsilon S} = \\frac{1}{2} \\varepsilon\\frac{\\sigma^{2}}{\\varepsilon^{2}} \\cdot Sd \\frac{1}{2}\\varepsilon E^{2} \\cdot Sd $$ E viene ugualmente come prima\nCon vettore di spostamento üü© abbiamo, considerando che $\\vec{D} = \\varepsilon \\vec{E}$, vale per dielettrico isotropo, ma per quello anisotropo, in cui non sono pi√π paralleli come si fa?\n$$ u_{E} = \\frac{1}{2} \\varepsilon E^{2}_{k} = \\frac{1}{2} \\frac{D^{2}}{\\varepsilon} $$A parit√† di campo elettrico, spendo molta quantit√† di energia in pi√π per caricarlo.\nMateriale anisotropo üü©\u0026ndash; $$ u_{E} = \\frac{1}{2}\\varepsilon E^{2} = \\frac{1}{2} \\vec{E} \\cdot \\vec{D} $$ Perch√© devo contare la parte parallela.\n","permalink":"https://flecart.github.io/notes/condensatori-con-dielettrici/","summary":"\u003ch3 id=\"introduzione-ai-dielettrici\"\u003eintroduzione ai dielettrici\u003c/h3\u003e\n\u003ch4 id=\"esperimenti-metalli-e-dielettrici-\"\u003eEsperimenti metalli e dielettrici üü©\u003c/h4\u003e\n$$\nV_{s} = (h - s) E_{0}\n$$\u003cp\u003e\nQuesto √® vero perch√© semplicemente in mezzo al conduttore il campo elettrico √® nullo, come spiegato in \u003ca href=\"/notes/conduttori-elettrici/\"\u003eConduttori elettrici\u003c/a\u003e, quindi durante l\u0026rsquo;integrale, il percorso √® semplicemente minore, esattamente di quella quantit√†.\u003c/p\u003e\n$$\nk = \\frac{V_{0}}{V_{k}} \u003c 1\n$$\u003ch4 id=\"costante-dielettrica-relativa-\"\u003eCostante dielettrica relativa üü©\u003c/h4\u003e\n$$\nE_{k} = \\frac{V_{k}}{h} = \\frac{V_{0}}{kh} = \\frac{E_{0}}{k} = \\frac{\\sigma_{0}}{k\\varepsilon_{0}} = \\frac{\\sigma_{k}}{\\varepsilon_{0}} = \\frac{\\sigma_{0}}{\\varepsilon}\n$$$$\nE_{k} = \\frac{\\sigma_{0}}{\\varepsilon_{0}} - \\frac{\\sigma_{p}}{\\varepsilon_{0}}\n$$$$\n\\sigma_{p} = \\frac{k - 1}{k} \\sigma_{0}\n$$$$\n\\sigma_{k} = \\sigma_{0} - \\sigma_{p} = \\frac{\\sigma_{0}}{k}\n$$\u003cp\u003e\nQui si pu√≤ giocare un po\u0026rsquo; senza nessun problema!\u003c/p\u003e","title":"Condensatori con dielettrici"},{"content":"Introduzione ai condensatori Analisi introduttiva condensatori: tubi di flusso üü© Consideriamo un **tubo di flusso infinitesimo** come in immagine. abbiamo che $dQ$ √® la carica totale dentro al cubo. Tale che segua le linee di campo. Il flusso totale sarebbe $$ \\oint_{\\Sigma} \\vec{E} \\cdot d\\vec{s} = \\frac{Q_{T}}{\\varepsilon_{0}} $$ Sappiamo anche che $$ \\vec{E}_{1}d\\vec{s}_{1} + \\vec{E}_{2}d\\vec{s}_{2} = \\frac{dQ_{T}}{\\varepsilon_{0}} $$ Ma scegliamo il cubo di flusso in modo che le superfici siano **perpendicolari al nostro campo**, e cos√¨ posso considerare il problema da un puro punto di vista **scalare**. Sapendo che nell'esempio sott il campo non √® esistente, allora posso scrivere il campo elettrico che va fuori, semplicemente in punto di vista scalare: $$ E_{2} = \\frac{dQ}{\\varepsilon_{0}ds_{2}} $$ esChe √® molto molto simile alla forma $\\frac{\\sigma}{\\varepsilon_{0}}$. il parametro di nostro interesse in questo esempio (almeno la cosa di nostro interesse) √® *il concetto di distanza*, se ci allontaniamo dalla nostra superficie, $dS_{2}$ diventa pi√π larga Introduzione ai condensatori üü© Poniamo di avere due armature metalliche qualsiasi, che abbiamo cariche uguali ed opposte in segno di una forma qualunque a distanza qualunque, in questo setting teorico. La cosa interessante √® che suppongo di avere #Induzione completa in questo caso. √à una necessit√† per l\u0026rsquo;analisi dei condensatori.\nPotenziale elettrico e carica üü®+ Proviamo a seguire una linea di campo elettrico per studiare il potenziale elettrico, andiamo quindi a definire un **tubo di flusso**. Per risultato precedente abbiamo che $E_{i} = \\frac{dQ_{i}}{\\varepsilon_{0}dS_{i}}$ $$ V_{A} - V_{B} = \\int _{A}^{B} \\vec{E}_{i} \\, dr_{i} = \\int _{A}^{B} {E}_{i} \\, dr_{i} = \\int _{A}^{B} \\frac{dQ_{i}}{\\varepsilon_{0}dS_{i}}\\, dr_{i} = dQ_{i} \\int _{A}^{B} \\frac{1}{\\varepsilon_{0}dS_{i}}\\, dr_{i} $$$$ dQ_{i} = \\frac{V_{A} - V_{B}}{\\int \\frac{1}{\\varepsilon_{0}dS_{i}}\\, dr_{i} } $$ Poi sommo la carica di tutti i singoli tubettini di flusso, dato che abbiamo induzione completa (che non abbiamo ancora discusso, abbiamo allora che\n$$ Q = \\sum_{i=1}^{N}dQ_{i} = (V_{A} - V_{B})\\sum_{i=1}^{N}\\frac{1}{\\int \\frac{1}{\\varepsilon_{0}dS_{i}}\\, dr_{i} } $$$$ V_{A} - V_{B} = \\frac{Q}{C} \\implies C = \\frac{Q}{\\Delta V} $$ ossia la capacit√† del condensatore √® la carica fratto la differenza di potenziale.\nAnalisi dimensionale capacit√† üü©- $$ \\left[ C \\right] = \\frac{[Q]}{[V]} =\\left[ Q \\right] / \\left[ ML^{2} T^{-2} Q^{-1} \\right] = \\left[ Q^{2} \\right] \\left[ M^{-1}L^{-2} T^{+2} \\right] = \\left[ F \\right] $$ Massa per velocit√† alla seconda per l\u0026rsquo;energia.\nUn Farad, ma essendo una quantit√† molto grande, difficile da usare, si utilizza il $1\\mu F$ che sono presenti nei circuiti, ma se ho troppa carica forse √® difficile da utilizzare (o hanno usi diversi).\nCondensatori piani Consideriamo un classico caso in cui abbiamo due condensatori piani, con la stessa carica, e area $=S$ Approssimazione\nConsideriamo le linee di campo del tutto parallele (campo come se fosse un piano infinito per chiarirci). Facce sono infinite (ma poi nella realt√† cambia solamente ai bordi). Campo elettrico in ogni regione üü© Si pu√≤ notare che Calcolo della direzione\nSinistra: √® 0 Centro sono $2\\vec{E}_{1} = \\vec{E}$ Destra: √® 0 Calcolo del modulo: Sappiamo che il campo elettrico per una singola armatura metallica √® $\\frac{\\sigma}{2 \\varepsilon_{0}}$, in questo caso sono uguali in modulo, e si sommano quindi:\n$$ \\vec{E} = \\frac{\\sigma}{\\varepsilon_{0}} $$ In mezzo ai conduttori. Questa analisi si pu√≤ fare con Gauss o semplicemente usando sovrapposizione, dovrebbe venire uguale, nel caso di conduttori infiniti.\nDisposizione superficiale di carica üü© Disposizione esterna Nel setting dei condensatori di sopra, possiamo chiederci dove stanno le cariche, si pu√≤ dimostrare usando Gauss che sulla superficie esterna √® nulla. Procedimento:\nPrendi una superficie cilindrica, che parte da dentro e arriva fuori a sinistra della piastra di sinistra. Sai che il campo dentro √® nullo per induzione elettrostatica Sai che fuori √® nullo perch√© hai supposto che si eliminano i campi (uguali perch√© stai assumendo siano infiniti). Quindi per Gauss la carica inclusa dovr√† essere nulla in quei punti. Disposizione interna Applico gauss con un cilindro molto simile, con un cerchio dentro (quindi campo nullo per induzione in Conduttori elettrici), ma ora l\u0026rsquo;altra estremit√† del cilindr√≤ avr√† un qualche valore:\n$$ \\oint_{\\Sigma¬¥} \\vec{E} \\cdot d\\vec{s} = \\frac{Q_{T}''}{\\varepsilon_{0}} \\implies \\oint_{\\Sigma'} \\lvert \\vec{E} \\rvert ds = \\lvert \\vec{E} \\rvert A = \\frac{Q_{T}''}{\\varepsilon_{0}} = \\frac{\\sigma A}{\\varepsilon_{0}} \\implies \\lvert \\vec{E} \\rvert = \\frac{\\sigma}{\\varepsilon_{0}} = \\frac{Q}{\\varepsilon_{0}S} $$ Abbiamo messo $S = A$ come superficie ed area, la stessa cosa in pratica. Quindi la discontinuit√† che abbiamo discusso (che non ho ancora scritto) √® ancora la stessa, solo ridisposta in modo diverso, descritto in Campo elettrico.\nPotenziale elettrico e capacit√† üü©- $$ \\Delta V = \\int _{A}^{B} \\vec{E} \\, d\\vec{r} = \\lvert \\vec{E} \\rvert \\int _{A}^{B} \\, d\\vec{r} = \\lvert \\vec{E} \\rvert d = \\frac{Qd}{\\varepsilon_{0}S} $$$$ C = \\frac{Q}{\\Delta V} = \\frac{S\\varepsilon_{0}}{d} $$ E possiamo vedere che sono sempre fattori geometrici.\nCaso piani non infiniti üü© Nell\u0026rsquo;analisi soprastante, abbiamo assunto di avere piani metallici infiniti Nel caso reale:\nL\u0026rsquo;approssimazione funziona in mezzo al condensatore Ai bordi il campo inizia a curvare, quindi non √® come modellizzato di sopra. Disposizioni di condensatori Parallelo üü© Analizziamo sempre potenziali e capacit√†, da un punto di vista totale (vedendolo come un singolo condensatore). Chiamiamo a sinistra 1, a destra 2 **Osservazioni**: 1. Potenziale ai capi dei condensatori √® uguale, perch√© i primi due sopra sono collegati, cos√¨ come quelli sotto 2. Si sommano le capacit√† (e carica singole), anche perch√© √® *come se aumentassi la superficie*. $$ C_{T} = \\frac{Q_{T}}{\\Delta V} = \\frac{Q_{1} + Q_{2}}{\\Delta V} = C_{1} + C_{2} $$ In un sistema composto da due o pi√π condensatori posti in parallelo, la capacit√† totale √® pari alla somma delle singole capacit√†.\nIn serie üü® **Osservazione** 1. Conduttori su E √® isolato, quindi si *caricheranno solo per induzione*. Analizziamo le differenze di potenziali, allora abbiamo che $$ \\Delta V_{1} = V_{A} - V_{E} = \\frac{Q}{C_{1}} $$ In modo simile per il secondo, noi vogliamo trovare $\\Delta V = V_{A} - V_{B} = \\frac{Q}{C_{T}}$, ma posso usare lo stratagemma matematico e risolvere ci√≤ $$ \\Delta V = V_{A} - V_{B} = (V_{A} - V_{E}) + (V_{E} - V_{B}) = Q\\left( \\frac{1}{C_{1} } + \\frac{1}{C_{2}} \\right) = \\frac{Q}{C_{T}} \\implies \\frac{1}{C_{T}} = \\frac{1}{C_{2}} + \\frac{1}{C_{2}} $$ Possiamo vedere che la capacit√† cala, questo √® spiegato fisicamente perch√© la carica √® distribuita, mentre la superficie rimane sempre lo stesso.\nLa serie fra due o pi√π condensatori ha capacit√† totale $C_{T}$ il cui inverso √® pari alla somma degli inversi delle singole capacit√†\nEnergia nei condensatori Intuizione sul concetto di energia Partiamo sempre dal concetto di lavoro, √® equivalente al lavoro usato per caricarlo. anche chiamato autoenergia. L\u0026rsquo;energia di un sistema di cariche che cosa √®? √® il lavoro esterno compiuto per costruire il sistema, in modo pi√π intuitivo √® quanto sforzo √® stato necessario usare per partire dall\u0026rsquo;infinito e portare le particelle e portarle in quel punto. Se √® repulsiva (quindi energia positiva) io faccio lavoro positivo, altrimenti negativo, questo l\u0026rsquo;hai visto ieri. Se l\u0026rsquo;energia √® positiva posso estrarre energia da utilizzare, altrimenti no.\nEnergia di Interazione üü© L'energia di sistema (o di interazione fra le cariche) √® calcolato nel modo seguente: La prima carica non fa lavoro perch√© il campo √® nullo inizialmente La seconda carica fa un po\u0026rsquo; di fatica Se cambio l\u0026rsquo;ordine cambia l\u0026rsquo;ordine, ma l\u0026rsquo;equazione finale non cambia. (forse solo segno) $$ U_{12} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R_{12}} = q_{1} V_{21} $$ Calcoliamo l\u0026rsquo;energia necessaria per portare una terza, avremo che $$ U_{23} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{2}q_{3}}{R_{23}} = q_{2}V_{32} = q_{3}V_{23} $$ E si fa lo stesso per $U_{13}$ e poi si summa tutto Quindi in generale: $$ U_{tot} = \\sum_{i \u003c j} ^{N} q_{i}V_{ji} = \\frac{1}{2} \\sum_{i \\neq j} ^{N} q_{i}V_{ij} $$$$ U_{tot} = \\frac{1}{2}\\sum_{i = 1}^{N}q_{i}V_{i} $$ Con $V_{i} = \\sum_{j\\neq i}^{N}V_{ij}$\n$$ U_{tot} = \\frac{1}{2} \\int _{\\tau} \\rho V \\, d\\tau $$ E la stessa cosa vale per le superfici in pratica posso calcolare l\u0026rsquo;energia totale in ogni configurazione.\nLavoro di carica dei condensatori Primo modo: lavoro punto per punto üü®++ Consideriamo un condensatore, alla prima carica non c\u0026rsquo;√® lavoro, ma poi si crea un campo elettrico che si prova ad opporre al caricamento (quindi lavoro positivo, forza di Coulomb √® positivo).\n$$ dL' = \\vec{E} \\cdot d\\vec{r} = -dV $$$$ dL = dq\\vec{E} \\cdot d\\vec{r} = -dqdV $$Calcolando da A a B e sommando tutto abbiamo che (contando che il lavoro esterno deve essere opposto rispetto al nostro campo in considerazione).\n$$ \\Delta L_{E} = \\int _{A}^{B} dqdV = dq \\int _{A}^{B} \\, dV = dq \\Delta V_{q} $$$$ \\Delta L_{E} = dq \\frac{q}{C} $$$$ L_{E} = \\int _{0}^{Q} \\Delta L_{E} = \\int _{0}^{Q} \\frac{q}{C} \\, dq = \\frac{1}{2} \\frac{Q^{2}}{C} = \\frac{1}{2} Q \\Delta V = \\frac{1}{2}C \\,\\Delta V^{2} $$ Che √® esattamente il lavoro fatto per caricare il condensatore\nSecondo modo: energia di interazione üü© $$ U_{E} = \\frac{1}{2} \\left[ Q_{A} V_{A} + Q_{B}V_{B} \\right] = \\frac{1}{2} \\left[ C(V_{A} - V_{B})V_{A} + C(V_{B} - V_{A})V_{B}\\right] = \\frac{1}{2} C\\, \\Delta V^{2} $$Densit√† di energia üü© $$ U_{E} = \\frac{1}{2} C\\, \\Delta V^{2} \\land C=\\frac{\\varepsilon_{0}S}{d} \\land \\Delta V = Ed \\implies U_{E} = \\frac{1}{2}\\varepsilon_{0}E^{2}(Sd) = \\frac{1}{2}\\varepsilon_{0}E^{2}Volume $$$$ u_{e} = \\frac{1}{2}\\varepsilon_{0}E^{2} $$ Questo servir√† per il vettore di Poynting in seguito quando faremo il minimo di propagazione. (Base di energia solare, anche la parte di propagazione che ho fatto io, e spiega che si pu√≤ ottenere energia dal campo elettrico, costruendo o disfacendone).\nScarica e carica di condensatori Carica del condensatore Setting del problema üü© Ci stiamo chiedendo, come varia l\u0026rsquo;intensit√† di corrente in un circuito fatto di semplice condensatore e resistenza? In che modo cambia il potenziale? Se ho l\u0026rsquo;intensit√† di corrente per un dato momento, allora posso calcolare l\u0026rsquo;intensit√† di corrente. Possiamo usare le leggi presenti in Leggi di Ohm e osservare che vale, perch√© alla fine il campo esterno √® ancora conservativo (credo), anche se la corrente varia. $$ \\varepsilon = V_{C} + V_{R} = \\frac{q(t)}{C} + Ri(t)\n$$ In un certo istante specifico $t$, ma notiamo che per definizione, la corrente accumula sul condensatore un valore $i(t) = \\frac{dq(t)}{dt}$ e possiamo sostituire questo dentro e risolvere l\u0026rsquo;equazione differenziale associata.\n$$ \\varepsilon = \\frac{q(t)}{C} + \\frac{Rdq(t)}{dt} $$$$ \\varepsilon = \\frac{A}{C}e^{Bt} + RABe^{Bt} $$$$ dt\\left( \\varepsilon - \\frac{q(t)}{C} \\right) = dq(t) R \\implies \\frac{dt}{RC} = \\frac{dq(t)}{\\varepsilon C - q(t)} $$$$ \\int _{0}^{q} \\frac{dq(t)}{-\\varepsilon C + q(t))} = -\\int_{0}^{t} \\frac{dt}{RC} \\implies \\ln\\left( \\frac{-\\varepsilon C + q(t)}{-\\varepsilon C} \\right)=- \\frac{t}{RC} \\implies q(t) = -\\varepsilon C e^{-t/RC} + \\varepsilon C $$Equazioni per la carica dei condensatori üü© $$ q(t) = \\varepsilon C(1 - e^{-t/RC}) $$$$ i(t) = \\frac{\\varepsilon}{R} e^{-t/RC} $$$$ V_{c}(t) = \\frac{q(t)}{C} = \\varepsilon(1 - e^{-t/RC}) $$$$ V_{b}(t) = i(t)R = \\varepsilon e^{-t/RC} $$ Come grafici questi hanno: Note sul tempo di carica üü© Nota: il condensatore non si carica mai al valore teorico di carica che pu√≤ avere (√® un asintoto orizzontale). Possiamo considerarlo carico quando √® tipo 1% del valore nominale, non ho capito esattamente perch√© questo, forse √® una convenzione.\nTempi tipici di carica sono microsecondi perch√© di solito Parliamo di micro-Farad e migliaia di Ohm di resistenza.\nSi pu√≤ notare risolvendo le equazioni di sopra otteniamo che: 0.95% -\u0026gt; 3$\\tau$ 0.99% -\u0026gt; 4.6$\\tau$ 0.999% -\u0026gt; 7$\\tau$ Per caricare il condensatore.\nPotenza erogata ed assorbita üü© $$ P_{gen} = \\varepsilon i(t) = \\frac{\\varepsilon^{2}}{R}e^{-t/RC} $$$$ P_{b} = Ri(t)^{2} = \\frac{\\varepsilon^{2}}{R} e^{-2t/RC} $$$$ P_{c} = \\frac{Vdq}{dt} = P_{gen} - P_{b} $$$$ W_{gen} = \\int_{0}^{\\infty} P_{gen} \\, dt = C\\varepsilon^{2} $$$$ W_{gen} = \\int_{0}^{q_{0}}Vdq = Vq = V^{2}C $$$$ W_{c} = \\frac{1}{2}CV^{2} = \\frac{W_{gen}}{2} \\implies W_{r} = W_{c} $$Scarica del condensatore Setting del problema üü© Ho un condensatore completamente carico come in figura Ad un certo punto chiudo l\u0026rsquo;interruttore e inizier√† a scorrere della carica, vogliamo capire in che modo varia $q(t)$ e in che modo varia $i(t)$\nEquazioni per la scarica dei condensatori üü© $$ 0 = \\frac{q(t)}{C} + \\frac{d(q)}{dt}R \\implies -\\frac{dt}{RC} = \\frac{d(q)}{q(t)} $$$$ \\int_{q_{0}}^{q} \\, \\frac{dq}{q} = -\\int_{0}^{t} \\frac{dt}{RC} \\implies \\ln\\left( \\frac{q}{q_{0}} \\right) = -\\frac{t}{RC} \\implies q(t) = q_{0}e^{-t/RC} $$ E poi si possono fare tutte le altre cose.\nCampo magnetico in condensatore üü® Guardando Ampere e Faraday se cambia l\u0026rsquo;intensit√† del campo elettrico, come succede per questo circuito, abbiamo che si ha una densit√† di corrente di spostamento.\n$$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{r} = \\mu_{0} i(t) = \\mu_{0} \\int _{\\Sigma(\\Gamma)} \\vec{J} \\cdot d\\vec{s} = \\mu_{0}(\\frac{\\varepsilon}{R} e^{-t/RC}) $$ Questo scegliendo la superficie pi√π semplice che esisteva. Posso per√≤ scegliere una altra superficie che passa dalle facce del condensatore, in questo caso io non ho corrente! Ecco che entra in gioco la correzione di Maxwell, per la corrente di spostamento. E facendo i calcoli si √® scoperto che la predizione era corretta, e il valore √® esattamente lo stesso.\n","permalink":"https://flecart.github.io/notes/condensatori-nel-vuoto/","summary":"\u003ch3 id=\"introduzione-ai-condensatori\"\u003eIntroduzione ai condensatori\u003c/h3\u003e\n\u003ch4 id=\"analisi-introduttiva-condensatori-tubi-di-flusso-\"\u003eAnalisi introduttiva condensatori: tubi di flusso üü©\u003c/h4\u003e\n\u003cimg src=\"/images/notes/Materiali e campo elettrico-1697456372758.jpeg\" alt=\"Materiali e campo elettrico-1697456372758\"\u003e\nConsideriamo un **tubo di flusso infinitesimo** come in immagine. abbiamo che  $dQ$ √® la carica totale dentro al cubo. Tale che segua le linee di campo.\nIl flusso totale sarebbe\n$$\n\\oint_{\\Sigma} \\vec{E} \\cdot d\\vec{s} = \\frac{Q_{T}}{\\varepsilon_{0}}\n$$\nSappiamo anche che\n$$\n\\vec{E}_{1}d\\vec{s}_{1} + \\vec{E}_{2}d\\vec{s}_{2} = \\frac{dQ_{T}}{\\varepsilon_{0}}\n$$\nMa scegliamo il cubo di flusso in modo che le superfici siano **perpendicolari al nostro campo**, e cos√¨ posso considerare il problema da un puro punto di vista **scalare**.\nSapendo che nell'esempio sott il campo non √® esistente, allora posso scrivere il campo elettrico che va fuori, semplicemente in punto di vista scalare:\n$$\nE_{2} = \\frac{dQ}{\\varepsilon_{0}ds_{2}}\n$$\nesChe √® molto molto simile alla forma $\\frac{\\sigma}{\\varepsilon_{0}}$.\nil parametro di nostro interesse in questo esempio (almeno la cosa di nostro interesse) √® *il concetto di distanza*, se ci allontaniamo dalla nostra superficie, $dS_{2}$ diventa pi√π larga\n\u003ch4 id=\"introduzione-ai-condensatori-\"\u003eIntroduzione ai condensatori üü©\u003c/h4\u003e\n\u003cp\u003ePoniamo di avere due armature metalliche qualsiasi, che abbiamo \u003cstrong\u003ecariche uguali ed opposte in segno\u003c/strong\u003e di una forma qualunque a distanza qualunque, in questo setting teorico.\nLa cosa interessante √® che suppongo di avere \u003ca href=\"/notes/condensatori-nel-vuoto/#induzione-completa\"\u003e#Induzione completa\u003c/a\u003e in questo caso.\n√à una necessit√† per l\u0026rsquo;analisi dei condensatori.\u003c/p\u003e","title":"Condensatori nel vuoto"},{"content":"Campo elettrico nei materiali Se prendiamo un conduttore, gli elettroni in questi materiali sono liberi, significa che sono liberi di muoversi come vogliono, si pu√≤ dire che \u0026ldquo;vadano in giro\u0026rdquo; (per esempio questo vale per il rame).\nil reticolo cristallino √® al struttura regolare che √® comune nei materiali, in cui gli atomi sono sempre a distanza costante (o comunque a pattern regolari) uno dall\u0026rsquo;altro $r$ per esempio.\nCampo e materiali (6) Schermatura del campo (!) üü© Quando un materiale conduttore √® sottoposto a un campo elettrico *gli elettroni si mettono in modo da schermare il campo esterno, in modo tale da raggiungere un equilibrio. Se andiamo a chiamare $\\vec{E}_{i}$ il campo elettrico indotto dentro il materiale, allora avremo che\n$$ 0 = \\vec{F}_{0} = e(\\vec{E}_{i} + \\vec{E}) \\implies\\vec{E}_{i} = -\\vec{E} $$L\u0026rsquo;osservazione principale che porta a questo risultato √® il fatto che nel primo momento c\u0026rsquo;√® uno spostamento di carica. Questo √® l\u0026rsquo;unico risultato sperimentale che abbiamo. Le cariche sono ferme all\u0026rsquo;interno del conduttore.\nMa questa carica da dove origina? Dove sono posizionate? Sono sulla superficie o anche dentro il materiale?\nCariche non sono dentro al conduttore (!) üü© In ogni punto interno al conduttore, all\u0026rsquo;equilibrio la carica elettrica √® nulla, come avveniva in assenza del campo elettrico.\nQuesto implica che da dentro il conduttore non cambia niente.\nSi pu√≤ dimostrare con la divergenza, praticamente che la densit√† di carica volumetrica resta nulla, perch√© il campo elettrico totale √® ancora nullo.\n$$ \\vec{\\nabla} \\cdot\\vec{E}_{T} = \\frac{\\rho}{\\varepsilon_{0}} \\land \\vec{E}_{T} = 0 \\implies \\rho=0 $$ Si pu√≤ anche dimostrare usando Legge di Gauss per i campi elettrici Cariche si spostano in superficie üü© Lo spostamento di cariche elettriche determinato dal campo elettrico esterno all\u0026rsquo;equilibrio si risolve in un ri-arrangiamento di carica che interessa solo la superficie del conduttore\nLa componente tangente non esiste sulla superficie, perch√© altrimenti le cariche si muoverebbero, invece la componente normale esiste sigma su $\\varepsilon_{0}$, Nel caso di cariche positiva c\u0026rsquo;√® proprio una forza sempre normale alla superficie, che spinge cariche fuori, in presenza di campo elettrico\n$$ dV = \\nabla V \\cdot ds = -\\vec{E} \\cdot ds $$ Sappiamo che per una componente tangenziale su superficie equipotenziale la variazione di $V$ √® nulla, quindi non esiste nessuna componente tangenziale, solamente quella normale. Possiamo anche scrivere\n$$ \\nabla V = \\frac{dV}{dn} $$ dove $\\hat{n}$ √® il vettore normale alla superficie equipotenziale\nSe √® negativa √® esattamente il contrario\nInfluenza sul campo elettrico üü© Dato un conduttore immerso in un campo elettrico esterno, all\u0026rsquo;equilibrio, altera le linee di campo anche all\u0026rsquo;esterno del conduttore. Il cambiamento delle linee di campo dipende dalla geometria del conduttore. Le linee di campo sulla superficie del conduttore sono normali e hanno modulo $\\frac{\\sigma}{\\varepsilon_{0}}$\nQuesto implica -\u0026gt; cambio del campo elettrico. L\u0026rsquo;induzione elettrostatica cambia il campo elettrico esterno, perch√© serve per schermare all\u0026rsquo;esterno. Quindi basta anche un conduttore neutro per cambiare il campo esterno 2. Un altro modo per cambia il campo √® introdurre nuove cariche.\nQuesto √® anche un modo per testare la conduttivit√† di un materiale, le linee di campo DEVONO essere 90 gradi ad entrare\nSuperficie equipotenziale come conduttore üü© La superficie del conduttore √® equipotenziale, cos√¨ come l\u0026rsquo;interno\nPer avere questo risultato vedere sotto #Potenziale sulla superficie.\nCampo elettrico in geometria cava üü© Se un conduttore cavo viene immerso in un campo elettrico esterno, all\u0026rsquo;equilibrio, il campo elettrico all\u0026rsquo;interno della cavit√† √® nullo e non vi sono cariche elettriche indotte sulla superficie della cavit√†\nPoniamo che la nostra geometria abbia un buco, √® corretto che certe cariche si mettono sulla superficie della nostra geometria?\nSe proviamo a considerare Gauss una superficie che comprende tutta la superficie, la carica totale della nostra superficie √® 0, ma non mi d√† informazioni su come sono messe le cariche, stessa cosa probabilmente per la divergenza utilizzato in questo caso.\n$$ \\oint_{\\Gamma}\\vec{E} \\cdot d\\vec{r} = 0 = \\int _{A}^{B} \\vec{E} \\, d\\vec{r} + \\int _{B}^{A} \\vec{E} \\, d\\vec{r} = \\int _{A}^{B} \\vec{E} \\, d\\vec{r} $$ Questo perch√© la forza √® conservativa, prendo una circuitazione che si muova SULLA linea di campo e si chiuda dentro al conduttore. (l\u0026rsquo;integrale dentro il conduttore √® nullo perch√© il campo stesso √® nullo.)\nMentre nel buco il campo √® normale, quindi avremmo che\n$$ \\int _{A}^{B} \\vec{E} \\, d\\vec{r} = \\int _{A}^{B} \\lvert \\vec{E} \\rvert \\, dr \\cos 0 \\neq 0, \\text{ nel caso in cui il campo sia presente} $$Quindi $\\vec{E} = 0$, questo √® il principio di schermatura, se abbiamo qualcosa di conduttore, non passa. Negli ascensori se varia troppo in fretta, non viene fermato, perch√© gli elettroni ci mettono un po\u0026rsquo; a rimettersi in sesto. Un altro motivo √® che non √® puramente metallica (conduttrice) questo ascensore. Altri fenomeni Singola Carica elettrica in geometria cava üü© Le cariche si sposteranno, e cercheranno anche in questo caso di schermare. Se considero una superficie che li rinchiude, in questo caso avr√≤ un campo elettrico. $$ \\oint_{\\Sigma} \\vec{E} d\\vec{s} = \\frac{Q_{T}}{\\varepsilon_{0}} = \\frac{1}{\\varepsilon_{0}} (Q + Q_{I}) = 0 \\implies Q_{I} = Q $$ Ossia la carica sulla superficie √® **esattamente uguale alla carica nel buco**, per questo motivo scherma, il motivo per cui fa 0 √® perch√© direttamente sulla superficie $$ \\oint_{\\Sigma} \\vec{E} d\\vec{s} = \\frac{1}{\\varepsilon_{0}} (Q + Q_{C}) = \\frac{Q}{\\varepsilon_{0}} $$ Perch√© la carica del conduttore √® neutra, per ipotesi non era carica. $Q_{C} = Q_{I} + Q_{E}$ ossia carica interna (sul buco interno e sul buco esterno), ma in questo caso allora posso concludere che $Q_{E} = -Q_{I} = Q$, ossia sia una superficie esterna, sia la superficie interna vengono influenzate da questa carica.\nInduzione completa üü© Fenomeno descritto in precedenza √® **l'induzione completa** come fenomeno. Nel caso in cui **tutte le linee di campo** entrano nel conduttore. In un certo senso se stai fuori dal materiale conduttore, √® come se lasciasse passare il campo senza problemi (se sto molto lontano **sembra singola carica**) (invece di renderlo radiale, sto cambiando leggermente la\\ direzione del campo *sulla superficie* se sto vicino). **Il campo interno non viene schermato** Materiale conduttore carico üü© Supponiamo di avere un materiale conduttore carico, anche in assenza di campo elettrico. Nel caso precedente avevamo analizzato il caso di un conduttore neutro in campo elettrico, la differenza qui √® che √® il conduttore stesso che √® carico\nPosso avere esattamente le stesse propriet√† dette prima per conduttore immerso in campo elettrico\nLe cariche sono ferme Potenziale elettrico √® costante La carica elettrica dentro il conduttore √® 0 campo elettrico √® normale sulla superficie ed √® $\\frac{\\sigma}{\\varepsilon_{0}}$ Le cariche sono sulla superficie (si provano e repellere il pi√π possibile). Se il conduttore √® cavo allora le cariche restano su quella esterna. Una altra applicazione √® il parafulmine perch√© la carica si distribuisce sempre all\u0026rsquo;esterno.\nDistribuzione di carica e densit√† superficiale in conduttori connessi üü©\u0026mdash; Supponiamo di avere due sfere connesse da un filo conduttore (quindi la carica √® libera di connettersi), ci andiamo a chiedere che se metto $Q$ in questo sistema, in che modo si distribuisce? Io so che $R_{1} = 2R_{2}$ Noi sappiamo che il **potenziale sulla superficie** √® uguale, i due potenziali devono essere uguali anche nel nostro caso (altrimenti forse non √® bilanciato) $$ V(1) = V(2) \\implies \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q_{1}}{2R_{2}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q_{2}}{R_{2}} \\implies \\frac{Q_{1}}{Q_{2}} = \\frac{R_{1}}{R_{2}} \\implies Q_{1} = 2Q_{2} $$ Dove abbiamo definito che $$ V(1) = V(R_{1}) - V(\\infty) = V(R_{1}) = \\int _{R_{1}}^{\\infty} \\vec{E}\\, d\\vec{r} = \\int _{R_{1}} ^{\\infty} \\lvert \\vec{E} \\rvert \\, dr = \\int _{R_{1}} ^{\\infty} \\frac{Q}{4\\pi\\varepsilon_{0}} \\frac{1}{ r^{2}} \\, dr = \\frac{Q}{4\\pi\\varepsilon_{0}} -\\frac{1}{r} | _{R_{1}}^{\\infty} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q}{R_{1}} $$ **Densit√† superficiale:** $$ \\sigma = \\frac{Q}{S} = \\frac{Q}{4\\pi R^{2}} \\implies Q_{1} = \\sigma_{1} 4\\pi R_{1}^{2} $$$$ \\frac{\\sigma_{1}4\\pi R_{1}^{2}}{ \\sigma_{2} 4\\pi R_{2}^{2}} = \\frac{Q_{1}}{Q_{2}} = \\frac{R_{1}}{R_{2}} \\implies \\frac{\\sigma_{1}}{\\sigma_{2}} = \\frac{R_{2}}{R_{1}} $$In cui la densit√† superficiale √® maggiore! Questo spiega anche i casi in cui pi√π √® piccola la superficie, la densit√† superficiale √® maggiore, e questo spiega il motivo per cui nei temporali non piace stare in cose sottili. Se il raggio di curvatura √® piccola, la carica sar√† molto pi√π densa. (punta = raggio di curvatura infinitesimo). Sembra in qualche modo questo concetto una naturale ottimizzazione che segue lola voronoi perch√© se una cosa √® appuntita, cambia in fretta, ha bisogno di pi√π punti per essere descritta, sembra che in modo naturale avviene anche in questo caso :).\nQuesta cosa funziona anche per la Terra stessa, e si potrebbe considerare come quantit√† infinita di carica, ed √® questo il significato di mettere a terra (si pu√≤ scaricare a terra carica in eccesso).\nPotenziale nei conduttori in equilibrio Potenziale interno al conduttore üü© Si pu√≤ dimostrare, senza molta difficolt√† che il potenziale √® sempre 0 all\u0026rsquo;interno del conduttore.\n$$ \\Delta V = V(A) - V(B) = \\int _{A}^{B}\\vec{E} \\cdot \\, d\\vec{r} = 0 $$ Perch√© il campo elettrico √® 0. -\nPotenziale sulla superficie üü© $$ \\Delta V = V(C) - V(D) = \\int _{C}^{D} \\vec{E} \\, d\\vec{r} = 0 $$","permalink":"https://flecart.github.io/notes/conduttori-elettrici/","summary":"\u003ch2 id=\"campo-elettrico-nei-materiali\"\u003eCampo elettrico nei materiali\u003c/h2\u003e\n\u003cp\u003eSe prendiamo un \u003cstrong\u003econduttore\u003c/strong\u003e, gli elettroni in questi materiali sono liberi, significa che sono liberi di muoversi come vogliono, si pu√≤ dire che \u0026ldquo;vadano in giro\u0026rdquo; (per esempio questo vale per il rame).\u003c/p\u003e\n\u003cp\u003eil \u003cstrong\u003ereticolo cristallino\u003c/strong\u003e √® al struttura regolare che √® comune nei materiali, in cui gli atomi sono sempre a distanza costante (o comunque a pattern regolari) uno dall\u0026rsquo;altro $r$ per esempio.\u003c/p\u003e\n\u003ch3 id=\"campo-e-materiali-6\"\u003eCampo e materiali (6)\u003c/h3\u003e\n\u003ch4 id=\"schermatura-del-campo--\"\u003eSchermatura del campo (!) üü©\u003c/h4\u003e\n\u003cp\u003eQuando un materiale conduttore √® sottoposto a un campo elettrico *gli elettroni si mettono in modo da \u003cstrong\u003eschermare\u003c/strong\u003e il campo esterno, in modo tale da raggiungere un equilibrio.\n\u003cimg src=\"/images/notes/Campo elettrico-1696921500696.jpeg\" alt=\"Campo elettrico-1696921500696\"\u003e\u003c/p\u003e","title":"Conduttori elettrici"},{"content":"8.1 Dimostrazione teorema invarianza 8.1.1 Introduzione Basi: Due proposizioni sono equivalenti quando valgono sugli stessi mondi.\nquindi $\\forall v, \\llbracket F \\rrbracket ^v \\equiv \\llbracket G \\rrbracket ^ v$.\nVogliamo dire che dati un buco presente in una proposizione, queste valgono sempre, sono in effetti equivalenti. Il buco la prendo come una variabile proposizionale. (riempire = rimpiazzare il buco)\n8.1.2 Operazione di sostituzione Si pu√≤ notare che ci sono 4 casi base, mentre le altre 4 sono per ricorsione strutturale.\n8.1.3 Enunciato La funzione di sostituzione ci permette di utilizzare una sostituzione anche nel profondo di un albero di deduzione naturale, per√≤ non √® accettabile poi in sede d\u0026rsquo;esame utilizzare questo teorema per fare deduzione naturale.\nLa dimostrazione √® per induzione strutturale abbastanza banale dopo aver definito la sostituzione, ma comunque resta un buon esercizio che dovresti fare.\n8.1.4 Osservazione 8.2 Connettivi logici 8.2.1 Definizione semantica (denotazione) Enunciato\nDalla definizione di connettivo unario si pu√≤ dedurre che esistono $2 ^{2^n}$ connettivi possibili ($2^n$ funzioni possibili per scelte dominio e 2 scelte posssibili per codominio.\nEs, per tutte le $2^n$ righe, devo dare in output un numero. Quindi posso dare una funzione che passa tutti 0 per tutte le righe, fino alla righa che da tutti uno per tutte le $2^n$ righe, finendo per avere $2^{2^n}$ funzioni possibili. Dobbiamo ora scegliere il perch√© abbiamo scelto questi connettivi fra tutti quelli presenti\n8.2.2 Giustificazione delle scelte Zero: Abbiamo preso tutti i connettivi zeroari, identificano il concetto di giusto o falso.\nUno: abbiamo preso solamente il connetivo not. (uno √® uguale all\u0026rsquo;input, gli altri due la ignorano, uno la ribalta, per questo abbiamo scelto solo il not).\nBinari questi sono tanti, ma non abbiamo dato una connotazione solo ad alcuni (eliminando tutti quelli banali tipo uguale a input, o inverso di input, o bot e top).\n8.2.3 Riduzione fra connettivi (classico) Questo concetto √® molto simile al ruolo di equivalenza fra due regole diverse (l\u0026rsquo;eliminazione dell\u0026rsquo;and e e1 e2). in Deduzione naturale.\nDefinizioni\nQui viene introdotto il concetto di funzionalmente completo che abbiamo utilizzato in Porte Logiche.\nE anche il concetto di riduzione indicato con $\\rhd$\nStudiamo quali connettivi sono necessari, scopriamo che nor e nand sono sufficienti, tutto si potrebbe ridurre a questi. Sono completi anche $\\vee, \\wedge, \\neg, \\bot, \\top, \\implies$ ridondante, ma funzionalmente completo\n8.2.4 Motivi della scelta dei connettivi (3) Lista motivi\nPoi c\u0026rsquo;√® una lunghissima lista di propriet√† possibili. Il prof. in classe ha dato l\u0026rsquo;intuizione del conceto di dualit√† fra top e bottom e and e or (basta ordinare la retta fra -1 e 0 per verificare che corrispondono, in pratica per la definizione attuale della nostra semnatica si hanno questi valori)\n8.2.5 Propriet√† dei connettivi (9) Queste scelte sono \u0026ldquo;funzionalmente complete\u0026rdquo; per la relazione di equivalenza.\ncaidana per ricordartelo. \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Connettivi Logici, correttezza, variabili/Untitled 6.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Connettivi Logici, correttezza, variabili/Untitled 6\u0026quot;\u0026gt; Infatti grazie a questo si pu√≤ creare un teorema di completezza per le regole, ovvero si pu√≤ dimostrare che\n$P \\equiv Q$ partendo solamente da queste regole, per√≤ non servono spesso per il calcolo. (a volte queste regole complicano la forma originale perch√© la forma di assorbimento di dovrebbe espandere).\nAltre cose sono\nModus barbara e risoluzione.\n8.3 Correttezza e completezza La correttezza la saltiamo, perch√© √® troppo complicato ed enunciata in breve sul teorema di completezza di sopra.\n8.3.1 Correttezza $\\Gamma \\vdash F \\implies \\Gamma \\Vdash F$\nEnunciato pi√π corretto\nLocalmente corrette significa che devono essere delle regole valide (che creano conseguenze logiche).\nOvvero significa che ho una ipotesi che funziona localmente ma non globalmente e lo scrivo come un implica.\nIntuizione\nOgni regola metto in un foglietto diverso (anche l\u0026rsquo;ipotesi scaricata √® presente di un foglietto sopra).\nVoglio dire che quella regola non √® una regola scaricata per un foglietto sotto. (viene scaricata solamente da un foglietto sopra.\nDimostrazione\nI Passi principali di dimostrazione\nCaso base A e caso impossibile [A] Ipotesi induttiva: i sotto-alberi sono conseguenza logica di ipotesi globali e ipotesi locali (localmente corrette). Per utilizzo di regole locali so che F √® conseguenza logica di molti implica. Per il teorema di deduzione semantica trasformo l\u0026rsquo;ipotesi induttiva con implica in RHS e LHS solo ipotesi globali del ramo principale. Unisco con transitivit√† della conseguenza logica. 8.3.2 Perch√© correttezza pi√π semplice di completezza Affinch√© abbia la correttezza, mi bastano delle regole che siano localmente corrette, se invece ho una regola incorretta riesco a derivare bottom da top, e quindi mi creerebbe una teoria inconsistente (tutto che valga).\nVorrei dire che ho tutte le regole per catturare un concetto semantico utilizzando un concetto sintattico (finito). Come faccio a usare una quantit√† finita per catturare l\u0026rsquo;infinito? Quindi per le logiche semplici come la logica proposizionale classica si pu√≤, per le altre no.\n√à sorprendente che un insieme finito di regole sia sufficiente a dimostrare infinite ipotesi, questo in matematica √® catturato il concetto di compattezza.\nDue ingredienti\nDevo avere tutte le regole, queste sono sufficienti per dimostrare tutte le conseguenze logiche. Da un insieme finito di regole devo essere in grado di dimostrare tutto. 8.3.3 Completezza in logica classica Non √® possibile dimostrare queste classiche tautologie RAA, EM\nNel caso due, posso dimostrare A oppure non A per introduzione dell\u0026rsquo;OR. Per√≤ poi non ho niente per continuare, in certi mondi non funziona A, perch√© non ho ipotesi, e non ho niente per dimostrare bottom con l\u0026rsquo;introduzione della negazione. Quindi queste non sono dimostrabili.\nMa questi valori sono validi se i valori di verit√† sono solamente due! le regole che ho non colgono la dualit√† (vero falso) della logica classica. infatti queste si dimostrazione solamente con l\u0026rsquo;introduzione della regola RAA.\nMa l\u0026rsquo;introduzione di questa regola toglie l\u0026rsquo;algoritmicit√† della dimostrazione quindi non √® da fare.\nPer avere dimostrazione della correttezza della regola qui\n8.4 Variabili Definizione funzione Var\nCostruiamo una funzione Variabile definita per ricorsione strutturale che ritorni tutte le variabili esistenti in una formula logica.\nCerchiamo di creare una sintassi che possa essere utilizzabile tutta l\u0026rsquo;infinit√† dei mondi.\nRiesco quindi a introdurre il concetto di equivalenza di mondi in funzione di una proposizione.\n8.4.1 Teorema: var(F) finito per ogni F La dimostrazione (intuizione) per induzione strutturale √® abbastanza easy. Nel caso dei casi finiti dovrei dimostrare che il singoletto e il vuoto sono finiti. Nel caso di parti composte, devo supporre che siano finite per le espansioni, allora l\u0026rsquo;unione di insiemi finiti √® ovvia\nIn realt√† la dimostrazione vera devi formalizzare prima il concetto di finito e non finito, che √® in teoria degli insiemi, quindi hai bisogno di molte altre cose.\n8.4.2 F in v usa restrizione di v al dominio Var(F) Posso creare una relazione di equivalenza se per ogni X in Var(F) ho che v(X) = v2(X) e ho che i due mondi sono uguali.\nChiamo solamente delle variabili di un mondo?\nDimo\nDimostrazione\nIn pratica sto collassando in una classe di equivalenza con il\nIl fatto che siano finiti mi permette di costruire tabelle di verit√†.\nNota\nGrazie a questo teorema posso dire che una variabile (proposizione) sia valida in tutti i mondi dipendentemente solamente dal valore di verit√† di una variabile al caso base.\nQuesto significa che le proposizioni logiche sono valide per tutti i mondi che soddisfino le precodizioni e non solamente nel mondo specifico! l valore di verit√† di una variabile al caso base.\nQuesto significa che le proposizioni logiche sono valide per tutti i mondi che soddisfino le precodizioni e non solamente nel mondo specifico!\n","permalink":"https://flecart.github.io/notes/connettivi-logici-correttezza-variabili/","summary":"\u003ch2 id=\"81-dimostrazione-teorema-invarianza\"\u003e8.1 Dimostrazione teorema invarianza\u003c/h2\u003e\n\u003ch3 id=\"811-introduzione\"\u003e8.1.1 Introduzione\u003c/h3\u003e\n\u003cp\u003eBasi: Due proposizioni sono equivalenti quando valgono sugli stessi mondi.\u003c/p\u003e\n\u003cp\u003equindi $\\forall v, \\llbracket F \\rrbracket ^v \\equiv \\llbracket G \\rrbracket ^ v$.\u003c/p\u003e\n\u003cp\u003eVogliamo dire che dati un buco presente in una proposizione, queste valgono sempre, sono in effetti equivalenti. Il buco la prendo come una variabile proposizionale.  (riempire = rimpiazzare il buco)\u003c/p\u003e\n\u003ch3 id=\"812-operazione-di-sostituzione\"\u003e8.1.2 Operazione di sostituzione\u003c/h3\u003e\n\u003cp\u003eSi pu√≤ notare che ci sono 4 casi base, mentre le altre 4 sono per ricorsione strutturale.\u003c/p\u003e","title":"Connettivi Logici, correttezza, variabili"},{"content":"Introduzione Vogliamo tenere in modo sincronizzato alcune macchine, questo √® il nostro obiettivo. Questo √® un problema abbastanza difficile‚Ä¶ Come tenere in sync se ci sono alcuni nodi maligni o la rete che non √® bona?\nAssunzioni principali (2) Esiste internet Esiste Crittografia Queste sono le assunzioni che non saranno mai rilassate per l‚Äôintero corso, diciamo che sono la nostra base su cui possiamo andare a costruire la base per il nostro studio.\nDigital signature scheme Vorremmo avere un sistema per firmare alcuni documenti online, e possiamo dividere questa cosa in tre passi fondamentali\nQuesta roba esiste da molto tempo, dagli anni 80 o prima.\nAlgoritmi per digital signature Una cosa importante √® che questi algoritmi di signature sono efficienti.\nGenerazione della chiave Deve essere nella forma $s \\to (pk, sk)$, ossia seed per public e secret key.\nFirma con la chiave Dovr√† essere una funzione nella forma $msg + sk \\to msg + sig$. Da notare √® che la signature √® dipendente dal contenuto. Ma non possiamo utilizzarlo in questi ambienti elettronici perch√© √® troppo facile copiare ed incollare una forma. Deve essere per forza che dipenda\nDall\u0026rsquo;identit√† di chi firma Da cosa vuole dire il firmatario. Verifica della chiave $msg + sig + pk \\to bool$, per capire se questa firma √® valida o meno, deve solamente dirmi questo valore booleano. In particolare la chiave √® pubblica quindi ognuno pu√≤ venire a verificare un messaggio, ma pu√≤ firmare solamente chi possiede la chiave privata.\nSicurezza (3 assunzioni) L‚Äôassunzione principale della sicurezza delle firme digitali √®\nIdeal signatures: Se non conosci la chiave privata ‚áí non posso mai generare la coppia msg + sig corretta\nDelle volte √® possibile rompere questa cosa (e.g. con brute force se ci metto abbastanza poco per farlo). Per√≤ noi assumeremo che valga questo. E ha bisogno di risorse infinite per poter usare bruteforce tutto se ha solamente quello come unica soluzione. Quindi una altra assunzione √® che l‚Äôavversario ha risorse finite, polinomiali.\nAssunzione di complessit√† vogliamo che non ci siano algoritmi efficienti per risolvere qualcosa in modo molto veloce\nThe State Machine Replication (SMR) Problem Intuizione al problema Prendiamo uno state machine, in modo simile a quanto fatto in Grammatiche Regolari, che ad ogni input e output cambia lo stato interno. Uno state machine pu√≤ essere un database, ma pu√≤ essere anche tutto l‚Äôambiente delle blockchain (e.g. mandare currency cambia lo stato) o un Automi e Regexp.\nLa replica √® necessaria per la performance, in modo che ci siano pi√π macchine uguali che rendano lo stesso servizio. Ma se ho tante macchine che fanno la stessa cosa, devo in qualche modo farci il sync, ed ecco il problema che nasce dai database, il problema dei sync write e read. Per noi la replicazione √® lo stato della macchina gigante della blockchain.\nNel contesto di blockchain\nAvremo una lista di transazioni, che sono niente altro che delle richieste a un certo nodo di fare qualcosa, e si registra la storia delle transazioni, √® molto importate che l‚Äôordine sia consistente. Il problema del consenso diventa quindi provare a sincronizzare la transazioni, che nota, non devo essere money! Basta richieste.\nConsistency Questa √® la propriet√† che tutti i nodi sono d‚Äôaccordo sulla storia, permettendo la possibilit√† che qualche nodo sia indietro (ma devono essere d‚Äôaccordo su quella parte comune!)\nLiveness e Safety Queste sono le stesse propriet√† descritte in Programmi Concorrenti. Con la liveness vogliamo che non ci siano deadlocks, e blocchi con la stessa logica ‚Üí alla fine il nodo dovr√† essere aggiunto!\n","permalink":"https://flecart.github.io/notes/consensus-protocols/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003cp\u003eVogliamo tenere in modo sincronizzato alcune macchine, questo √® il nostro obiettivo. Questo √® un problema abbastanza difficile‚Ä¶ Come tenere in sync se ci sono alcuni nodi maligni o la rete che non √® bona?\u003c/p\u003e\n\u003ch3 id=\"assunzioni-principali-2\"\u003eAssunzioni principali (2)\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eEsiste internet\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEsiste Crittografia\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eQueste sono le assunzioni che non saranno mai rilassate per l‚Äôintero corso, diciamo che sono la nostra base su cui possiamo andare a costruire la base per il nostro studio.\u003c/p\u003e","title":"Consensus protocols"},{"content":"Tipologie di control plane La control plane √® la parte al livello di rete che si occupa di riempire le tabelle di istradamento dei router. In questo caso si possono in generare dividere gli algoritmi in due grandi famiglie\nCentralizzati, anche chiamati algoritmi LS( Link state) perch√© devono conoscere in che modo sono collegati i router fra di loro. Solitamente le SDN ossia software defined networking di cui abbiamo parlato in Data Plane utilizzano questi metodi, c\u0026rsquo;√® un server centralizzato (che per ragioni di tolleranza pu√≤ anche essere distribuito, per√≤ diciamo che √® esterno al router la decisione) Distribuiti in cui nessuno ha informazioni complete sulla rete, ma √® possibile scambiarsi informazioni sui vicini e congiungere cos√¨ al percorso pi√π breve. Vengono in questa sede utilizzati algoritmi di distance vector. Possono anche essere statici, ma dato che la topologia della rete √® spesso dinamica √® difficile che vengano utilizzati. Sono molto pi√π preferibili gli algoritmi dinamici che vanno ogni tot ad aggiornare le tabelle.\nSi possono anche differenziare secondo la sensibilit√† al carico. Anche se gli algoritmi moderni sono insensibili.\nAlgoritmi per Control Plane Link state e Dijkstra Questa √® la parte pi√π importante per il prof\nCon grafo indiretto ad archi pesati. questo l\u0026rsquo;abbiamo gi√† studiato in Cammini, ad algoritmi, ed √® stato fatto bene.\nNOTA: ci potrebbero essere problemi di oscillazione dei percorsi calcolati se utilizziamo solamente il carico come unica metrica per misurare il peso di un nodo. Attualmente il metodo migliore per evitare questo √® calcolare il percorso migliore in tempi randomici.\nEsempio di oscillazione dei percorsi\nDistance vectors Non hanno visto Bellman ford e distance vector routing, per√≤ sarebbe carino farle TODO: Autonomous systems Definizione AS Alcuni vorrebbero essere in grado di gestire un blocco di router come vogliono loro, ossia vogliono avere una autonomia amministrativa su un insieme di router. Possiamo quindi dividere tutti i router in delle AS, alcune grandi, di primo livello, pi√π piccole, decide l‚ÄôISP in che modo gestirsele. (ad ogni AS √® associato, sembra, un numero). La cosa importante per√≤ √® che\nTutti i router all\u0026rsquo;interno di una AS eseguono lo stesso protocollo di instradamento. Intra e inter routing Algoritmi di routing a due livelli diversi (BGP Border Gateway protocol per inter, che non chiede, ma sa che esiste. e altri per Intra.)\nIntra sono algoritmi di routing omogenei.\nInter in cui ci interessa solamente capire in che modo si interfaccia in altri sistemi.\nIn pratica non ha fatto niente di control plane‚Ä¶\nOpen Shortest Path first (intra) OSPF √® un algoritmo link state che regola il routing all\u0026rsquo;interno di un sistema autonomo. Per il resto non ci importa sapere altro.\nUtilizza Dijkstra I pesi possono essere messi a mano seguendo certi criteri Minimum hop (peso 1) Inversamente proporzionale alla banda (quindi favorire l‚Äôutilizzo di connessioni di banda maggiori) Supportano un protocollo a livello IP per scambiarsi informazioni sulla congestione (ogni 30 min tipo) Supportano protocolli per la sicurezza e l‚Äôautenticazione (cos√¨ possono ripudiare altri router che non possiedano la chiave di sicurezza). Border Gateway Protocol (!) Introduzione al protocollo BGP Border Gateway Protocol √® uno dei protocolli pi√π importanti insieme a IP. √à il protocollo che ci permette di comunicare fra AS divers, si pu√≤ dire infatti che sia un protocollo inter-AS per questo motivo.\nHa due funzioni principali:\nAnnunciare che un host o un router √® raggiungibile a tutti gli AS Trovare il percorso pi√π veloce per raggiungere quell‚Äôhost In generale qui vengono utilizzati algoritmi Distance Vector decentralizzati sui singoli AS.\nPer far questo in generale ci teniamo una coppia (prefisso, interfaccia) ossia il prefisso contiene un range di indirizzi, e interfaccia √® l‚Äôinterfaccia del router che possiede quei prefissi.\nAnnuncio presenza In questa fase facciamo distinzione ai messaggi eBGP annunci di messaggi fra router di AS diversi fra di loro e di iBGP annunci fra router degli stessi AS.\nPer dare l‚Äôintuizione generale, quando un nuovo router si connette, manda un messaggio iBGP a tutti i router dell‚ÄôAS, quando il messaggio viene a un router gateway, cos√¨ chiamati i router che hanno connessioni con AS diverse, questa manda una eBGP al router dell‚Äôaltro BGP, con informazioni sulla presenza di x e di come raggiungere x, il processo di ripete finch√© non √® stato recepito da tutte le AS.\nRicerca del percorso pi√π breve (2) Ricordiamo prima che le rotte sono delle coppie (‚Äùpercorso fra sistemi autonomi‚Äù, primo router fuori dall\u0026rsquo;AS attuale).\nUna volta che un sistema autonomo √® a conoscenza di tutte le rotte verso un certo router pu√≤ utilizzare questi due algoritmi:\nHot potato\nQuando provo a uscire pi√π in fretta possibile dall\u0026rsquo;AS attuale. Sfruttando protocolli di intra-routing per sapere dove andare. Selezione delle rotte\nHo delle regole da seguire che eliminano tutte le rotte fino ad avere una singola Preferenza locale (impostata manualmente da un operatore solitamente) Numero minimo di hop minimo costo di intra routing. Identificatori BGP (che non trattiamo) Quindi uno dopo l‚Äôaltro utilizzo quelle per discriminare le routes e scegliere, quindi al passo 2 saranno rimaste tutte le routes con stessa preferenza locale, al numero 3 ho tutte le routes con stesso numero di hops, al passo 4 ho tutte le routes con stessa preferenza locale, stesso numero di hops, e stesso costo interno.\n","permalink":"https://flecart.github.io/notes/control-plane/","summary":"\u003ch3 id=\"tipologie-di-control-plane\"\u003eTipologie di control plane\u003c/h3\u003e\n\u003cp\u003eLa control plane √® la parte al livello di rete che si occupa di \u003cstrong\u003eriempire le tabelle di istradamento dei router\u003c/strong\u003e. In questo caso si possono in generare dividere gli algoritmi in due grandi famiglie\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eCentralizzati\u003c/strong\u003e, anche chiamati \u003cstrong\u003ealgoritmi LS( Link state)\u003c/strong\u003e perch√© devono conoscere in che modo sono collegati i router fra di loro. Solitamente le \u003cstrong\u003eSDN\u003c/strong\u003e ossia software defined networking di cui abbiamo parlato in \u003ca href=\"/notes/data-plane/\"\u003eData Plane\u003c/a\u003e utilizzano questi metodi, c\u0026rsquo;√® un server centralizzato (che per ragioni di tolleranza pu√≤ anche essere distribuito, per√≤ diciamo che √® esterno al router la decisione)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDistribuiti\u003c/strong\u003e in cui nessuno ha informazioni complete sulla rete, ma √® possibile scambiarsi informazioni sui vicini e congiungere cos√¨ al percorso pi√π breve. Vengono in questa sede utilizzati algoritmi di \u003cstrong\u003edistance vector\u003c/strong\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePossono anche essere \u003cstrong\u003estatici\u003c/strong\u003e, ma dato che la topologia della rete √® spesso dinamica √® difficile che vengano utilizzati. Sono molto pi√π preferibili gli algoritmi dinamici che vanno ogni tot ad aggiornare le tabelle.\u003c/p\u003e","title":"Control Plane"},{"content":"Introduction to convolutional NN The convolution operator üü©- Il prodotto di convoluzione √® matematicamente molto contorto, anche se nella pratica √® una cosa molto molto semplice. In pratica voglio calcolare il valore di un pixel in funzione di certi suoi vicini, moltiplicati per un filter che in pratica √® una matrice di pesi, che definisce un pattern lineare a cui sarei interessato di cercare nell‚Äôimmagine.\nSlides ed esempi (molto pi√π chiaril)\nVedi che per calcolare quell‚Äô8 sto facendo cose lineari con tutti pixel intorno ad essa.\nQuesto operatore l‚Äôabbiamo gi√† trattato in modo molto breve in Deblur di immagini.\nSome properties and uses Sappiamo tutti che le immagini non sono altro che arrai di valori in un certo intervallo, che rappresentano l‚Äôintensit√† dei colori, o solamente del bianco-grigio nel caso delle immagini grigio nere.\nQueste intensit√† si potrebbero anche rappresentare come superfici 3d in cui la posizione del pixel identifica x e y, mentre l‚Äôintensit√† la z, abbiamo quindi proprio delle superfici!, delle montagne, valli fiumi etc. Le cose molto interessanti sono cambi di intensit√† improvvisi (con derivata molto alta) ossia i dirupi, le valli, questo cambio improvviso (il cambio di fase come dice Pedro di Master algorithm) √® classico anche in nautura, √® la parte con qualche informazione di interesse diciamo.\nTHE IDEA OF DERIVATIVE FOR CHANGES\nSlide finite approssimation of derivative h = 1 perch√© siamo in campo discreto (√® anche il minimo h che possiamo considerare in questo setting), quel filtro quindi ci √® utile per capire se ci sono dei cambi improvvisi. Questa idea ci permette di costruire il kernel per identificare le linee (visible contours of the image), orizzontali (cambi direzione e avresti verticale). it‚Äôs a feature map, of the image to some characteristic of the image. (ti dice se in questa zona √® presente, non c‚Äô√® , o c‚Äô√® l‚Äôopposto del pattern che cercavi).\nSome architectures Deepwise separable convolution Inception architecture üü® Andiamo a derfinire un modulo di inception (in cui va a fare in un certo senso scrambling, decomporre e recomporre dati, in che modo vanno ad estrarre delle features io non lo so!).\nComunque questa √® l‚Äôarchitettura classica, andare ad utilizzare reti convoluzionali e poi operarle con reti deep (alla fine non molto deep) in modo da collegargli insieme.\nEsempio di inception module !\nhttps://www.youtube.com/watch?v=VxhSouuSZDY\u0026amp;ab_channel=Udacity\nResidual layers Residual learning is the main concept of these networks, it‚Äôs when we have a direct link with the beginning! In pratica diamo la possibilit√† al neurone di scegliere di non modificare o invece s√¨ l‚Äôinput credo, provo a chiedermi se posso avere un valore migliore di quanto ho attualmente con qualche peso.\nStructure of residual layer https://arxiv.org/pdf/1512.03385.pdf\nUsually these links help the network learn (lesser vanishing gradient.\nShattered Gradients Most gradient descent methods assume to have a smooth gradient. This is not true anymore with very deep layers. Adding residual layers help ease this problem.\nSmoother Error Surfaces Introducing the residual layer helps in having smoother residual layers: Transfer learning Slide intuizione transfer learning expected graph with performance with transfer learning\n!\nComunque l‚Äôintuizione principale del transfer learning √® l‚Äôidea che i primi layers facciano una sorta di estrazione di features pi√π ad alto livello utili poi ai layers di deep NN. Se questa prima parte l‚Äôho trainata su un corpus enorme, allora gli aspetti che √® riuscito a generalizzare potrebbero essere utili anche per altro, e quindi utilizzo i pesi trovati in questa rete anche per altro, senza problemi.\nFine tune o finetuning √® un p√≤ rischioso, faccio un freeze di una parte del network pi√π larga, potrei andare a overfittare e fare cose simili! Per√≤ ha pi√π senso, ci aiuta a rendere l‚Äôintera architettura ancora pi√π focussato in quello che vogliamo fare noi (in un certo senso forse d√† via alcune generalizzazioni inutili nel nostro dominio)\nTraining of CNN Backpropagation of CNNs üü®++ We can unroll the input and output layers as a single linear trasformation of a deep network (with weights adjusted accordingly).\nIntuition of unrolling !\nBut how do we unroll?? We can see everything as a matrix with $[input\\_size \\times output\\_size]$ as you can see from the image in the toggle\nSlide convolution matrix of the weights !\nAfter we have modelled this matrix, we can learn using standard backpropagation we have talked about in Neural Networks.\nUn problema per questo metodo √® la matrice √® sparsa se input √® molto largo, e kernel piccolo, avrei un numero di zeri assurdo, quindi nemmeno molto efficiente da memorizzare in questo modo. (per√≤ possiamo computare in modo efficiente, ma questo non lo trattiamo).\nUn altro aspetto di questa matrice √® la ripetizione shiftata dei pesi, che sono gli stessi in ogni colonna della matrice, ma solamente shiftato. Questo cambia il modo di fare update dei pesi, si utilizza l‚Äôupdate con average pesato. fra le 4 computazioni delle 4 colonne in esempio.\nTransposed convolutions Dopo che ho fatto troppo downsampling con le CNN, vorrei tornare s√π di dimensione (se per esempio un input √® un‚Äôimmagine. Trasposed convolutions ci permettono di tornare su di dimensione. (anche tecniche statistiche credo che funzionino).\nSlide transposed convolutions ! !\nThis technique is called transposed convolution because if we transpose the convolution matrix, we see that we are upscaling the input!. Per√≤ non ho capito in che modo funziona!\nDilated convolutions üü© Slide intuizione di questo !\nFacciamo una specie di padding interno sul kernel (non vado a contare certe cose, per√≤ riesco a ingrandire la receptive field del mio network.\nHa pi√π senso fare sta cosa quando sto analizzando HIGH RESOLUTION IMAGE in cui il valore dei pixel cambia molto poco.\nUna differenza con le Transposed convolutions üü• √® il fatto che quelle sono fatte sull‚Äôinput, questa la facciamo su come viene calcolato il kernel.\nSono molto utilizzate in temporal convolution networks, in cui provo a diluire volta per volta lo spazio all‚Äôinterno del kernel, anche se non so ancora perch√© va\nSlide temporal convolution network !\nNormalization layers Why normalization üü• Slide 2 reasons !\nWhy is normalization a good idea :D?\nSo the quantitative values are comparable from each other (e.g. ages and income) We want the output of the layers to be comparable from each other, the middle outputs are inputs for other layers! We can better control the activation layers. (non vogliamo che faccia come output NaN üòü) Decoupling of the layers. (non dobbiamo andare ad imparare il range di input aspettato, dato che sar√† sempre data di stesso tipo) Batch Normalization üü• This is the most common form of normalization (ma l‚Äôidea √® sempre la stessa, computare varianza e media, e poi sottrarre media e dividere per varianza). La cosa in pi√π √® che vengono aggiunte delle varianze e una media, per denormalizzare l‚Äôoutput, in modo che abbia la forma dei dati migliore possibile.\nSlide batch normalization ! Other Normalization üü• Potremmo provare a normalizzare per canale\nSlide normalizations !!\n","permalink":"https://flecart.github.io/notes/convolutional-nn/","summary":"\u003ch2 id=\"introduction-to-convolutional-nn\"\u003eIntroduction to convolutional NN\u003c/h2\u003e\n\u003ch3 id=\"the-convolution-operator--\"\u003eThe convolution operator üü©-\u003c/h3\u003e\n\u003cp\u003eIl prodotto di convoluzione √® matematicamente molto contorto, anche se nella pratica √® una cosa molto molto semplice. In pratica voglio calcolare il valore di un pixel in funzione di certi suoi vicini, moltiplicati per un \u003cstrong\u003efilter\u003c/strong\u003e che in pratica √® una matrice di pesi, che definisce un pattern lineare a cui sarei interessato di cercare nell‚Äôimmagine.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlides ed esempi (molto pi√π chiaril)\u003c/p\u003e","title":"Convolutional NN"},{"content":"Cook Levin theorem is important because says that in 1971 if $SAT \\in P$ then $NP = P$. We will start with this idea to define the concept of NP-completeness. Let\u0026rsquo;s start with the basics.\nPoly-reduction Def: poly-reductionüü© $$ x \\in L' \\iff f(x) \\in L $$ This is very similar to the Halting Theorem and Reducibility#Mapping reducibility. The difference is that it needs to be polynomially-bounded, so to say, it is efficient function.\nTh: $L' \\leq_{p} L \\land L \\in P \\implies L' \\in P$üü© This theorem says that if we can reduce with a polynomially bounded function to a class of language in $P$ then we have automatically another language in $P$.\nProof: If $L \\in P$ there exists a $g$ that decides it in poly-time. If $L' \\leq _p L$ then exists $TM$ that polynomially computes a language into $L$, calculating $f$. Then we build this machine:\nGiven $x \\in L'$ in input, we say $g(f(x))$ decides that language. And we know that composition of polynomial functions is polynomial. So that function is polynomial and we proved it.\nTh: $L \\in P \\implies L^{-} \\leq_{p} L$üü© Given a $\\omega$ let\u0026rsquo;s run the decider to know whether if $\\omega \\in L$. If we know this then we know if $\\omega \\in L'$ or not just by inverting the last result. Now let\u0026rsquo;s build the converter, which works in constant time. Take two words $\\omega_{1}, \\omega_{2}$ such that $\\omega_{1} \\in L \\land \\omega_{2} \\not \\in L$ then if $\\omega \\in L' \\implies f(\\omega) = \\omega_{1}$ and if $\\omega \\not \\in L' \\implies f(\\omega) = \\omega_{2}$ this ends the proof. $f$ works in polynomial time thanks to the fact that $L \\in P$.\nCook-Levin Theorem Def: NP-completenessüü© We say that a $L$ is NP-complete if it is in $NP$ and every other $L'$ is reducible in $NP$ using #Poly-reduction.\nDef: NP-hardüü© $L$ is NP-hard if every $L'$ in $NP$ in reducible to it using #Poly-reduction. We don\u0026rsquo;t need that it is in $NP$.\nTMSATüü® $$ TMSAT = \\left\\{ \\langle x, w, s,t \\rangle \\mid x = code(M) \\text{ and } M \\text{ accepts } \\langle w, c \\rangle \\right\\} $$ With other constraints of the length of the input and the time of the computation.\nAs this is a verifier we can prove that this language is $NP-complete$ but it is useless, because it says nothing on the class of problems.\nProblem statementüü© We want to prove that $SAT \\in NP-complete$ This is what Cook-Levin states.\nthis would imply that every other problem in $NP$ can be reduced into SAT, for example clique which is in NP, so we prove that $P = NP$\nProof of Cook-Levin SAT is in NPüü© This is quite easy, just non-deterministically take an assignment. If any of these assignments accept, then accept. We can say that SAT is easily verifiable.\nSAT is NP-hardüü®- This is the difficult part. The idea is to create a representation of the computation of the Turing Machine of whatever algorithm. So we create a tableau that represents the computation, and we want to translate this tableau as a satisfiability problem. We know that this tableau is finite because the problem is in $NP$.\n$$ F_{w} := F_{cell} \\land F_{start} \\land F_{move} \\land F_{accept} $$ And we want to say that this is satisfiable $\\iff$ exists a tableau as defined above such that accepts $\\iff$ a computation on $w$ of the machine $M$ accepts it.\n$$ \\left\\{ x _{i, j, s} \\mid (i, j) \\in n^{k} \\times n^{k} ,s \\in Q \\cup \\Sigma \\cup \\left\\{ \\# \\right\\} \\right\\} $$$$ F_{start} = x_{1, 1, \\#} \\land x_{1, 2, q_{0}} \\land \\\\ x_{1,3, w_{1}} \\land x_{1, 4, w_{2}} \\land \\dots \\land x_{1, n + 2, w_{n}} \\land \\\\ x_{1, n + 3, \\textvisiblespace} \\land \\dots \\land x_{1, n^{k} - 1, \\textvisiblespace x_{1, n^{k}, \\#}} $$ It means that the initial configuration is that of the Turing machine.\n$$ F_{cell} = \\bigwedge_{1 \\leq i, j \\leq n ^{k}} \\left[ (\\bigvee_{s \\in C} x_{i, j , s}) \\land (\\bigwedge_{s, t \\in C, s\\neq t} (\\bar{x}_{i, j, s} \\lor \\bar{x}_{i,j,t})) \\right] $$In natural language: Exists at least a $s$ that is true, and other are false, for every cell in the tableau. That means that for every single cell, we have something like $x_{1, 2, a}$ which is true.\n$$ F_{accept} = \\bigvee_{1 \\leq i, j \\leq n^{k}} x_{i,j, T} $$Then we need to define the $F_{move}$ function, which is the last formula we would need to define! As we only need to know how the state moves, we just need windows of 3.\nExamples: $$ F_{move} = \\bigwedge_{1 ","permalink":"https://flecart.github.io/notes/cook-levin-and-savitch/","summary":"\u003cp\u003eCook Levin theorem is important because says that in 1971 if $SAT \\in P$ then $NP = P$. We will start with this idea to define the concept of \u003cstrong\u003eNP-completeness\u003c/strong\u003e. Let\u0026rsquo;s start with the basics.\u003c/p\u003e\n\u003ch3 id=\"poly-reduction\"\u003ePoly-reduction\u003c/h3\u003e\n\u003ch4 id=\"def-poly-reduction\"\u003eDef: poly-reductionüü©\u003c/h4\u003e\n$$\nx \\in L' \\iff f(x) \\in L\n$$\u003cp\u003e\nThis is very similar to the \u003ca href=\"/notes/halting-theorem-and-reducibility/#mapping-reducibility\"\u003eHalting Theorem and Reducibility#Mapping reducibility\u003c/a\u003e.\nThe difference is that it needs to be \u003cem\u003epolynomially-bounded\u003c/em\u003e, so to say, it is efficient function.\u003c/p\u003e","title":"Cook-Levin and Savitch"},{"content":"Cookies Gli utilizzi pi√π soliti sono per Autenticazione e per Autorizzazione, perch√© sono delle informazioni che il server genera e mette al client, come se fossero dei segreti cifrati.\nCookie Questi sono una estensione di netscape, che si appoggiano al protocollo HTTP per implementare certe funzionalit√† (soprattutto il fatto di essere stateless, quindi √® utile per avere informazioni sugli stati su qualcosa.)\nSlide cookie\nVengon utilizzati header specifici per settare il cookie.\nArchitettura dei cookie I cookie sono briciole di informazioni sul client generati dall\u0026rsquo;applicazione server, di seguito nelle slides vedi in che modo funzionano solitamente:\nSlide cookie\nTipologie di coockie Permanenti sono utili soprattutto per mantenere informazioni di **preferenza sugli utenti. Di sessione qui ti diverti a fare cose sulla sicurezza üòÄ. Di terze parti sono utilizzati per decidere che pubblicit√† mostrarti, per esempio basandosi sulla history di ricerche. Autenticazione Non ci piacerebbe autenticarci ogni volta a ogni cambio di tab ossia identificare chi stia facendo l\u0026rsquo;acceso alla risorsa come se fosse un riconoscimento, i cookie sono buoni per storare queste informazioni.\nSchemi di autenticazione (3) Se provi ad accedere a una risorsa, il server dovrebbe risponderti con 401 Not authenticated e darti un header WWW-authenticate dandoti informazioni su come autenticarti.\nBASIC\nSlide basic auth\nQuesto manda in pratica tutto in chiaro attraverso l\u0026rsquo;header del client, ovviamente non √® che sia molto sicuro‚Ä¶\nQuindi √® in disuso.\nDIGEST\nSlide digest auth\nIn pratica √® come il basic, ma invece di mandare la cosa in chiaro si manda hash + nonce, in modo da evitare replay attack come specificato in Sicurezza delle reti.\nAnche qui √® difficile capire quando la sessione scade.\nBEARER\nIn pratica il server produce qualcosa, un token e poi il client utilizza solo questo per autenticarsi nelle connessioni successive.\nPu√≤ essere utilizzato sia in session sia in token auth\nSession-based authentication Slides session based authentication\nIn pratica al primo collegamento ti metto dei cookie, che sono i cookie di sessioen, che scadono in un certo tempo. Poi per ogni collegamento ti mando anche i cookie di sessione, che danno informazioni di autenticazione.\nQuesto √® uno schema classico, il server ha il controllo sul tempo e sulla revoca di questa sessione.\nToken-based authentication Slides token based auth\nPraticamente quando la prima volta fai auth io ti rispondo con un token firmato come potrebbe essere Il token JWT.\nQuesto poi viene utilizzato. la cosa bella √® che utilizzo il server molto meno, nel senso che deve andare a memorizzare molto meno, basta verificare la firma ogni volta.\nIl token JWT Questo l\u0026rsquo;abbiamo utilizzato molto spesso per la parte di cybersec!\nSlide JWT\nContenuto Header Payload e signature\nAltre note: CORS e Caching Introduzione Cross site vulnerability Slide headers CORS\nNon vorremmo avere le javascript esterno non controllato, potrebbero avere codice maligno! Pensa se ti riuscissero a pishare il cookie di sessione.\nPosso mettere nelle options di HTTP scripts permessi\nCORS headers Slide headers per cors\nHTTP Caching (2) Server specified expiration\nSlide server specified expiration\nIn pratica attraverso certe specificazioni dico quando il cache sar√† expired.\nHeuristic expiration\nHeuristic expiration\nQuesto perch√© spesso\nRisposta dalla cache\nSe √® non modificata ti mando un codice 304 Not modified altrimenti ti risponso, cos√¨ non devo fare due richeiste, una head per veder elast modified e una altra per mandarti la get.\n","permalink":"https://flecart.github.io/notes/cookie-e-autenticazione/","summary":"\u003ch1 id=\"cookies\"\u003eCookies\u003c/h1\u003e\n\u003cp\u003eGli utilizzi pi√π soliti sono per Autenticazione e per  Autorizzazione, perch√© sono delle informazioni che il server genera e mette al client, come se fossero dei segreti cifrati.\u003c/p\u003e\n\u003ch2 id=\"cookie\"\u003eCookie\u003c/h2\u003e\n\u003cp\u003eQuesti sono una estensione di netscape, che si appoggiano al protocollo HTTP per implementare certe funzionalit√† (soprattutto il fatto di essere \u003cstrong\u003estateless\u003c/strong\u003e, quindi √® utile per avere informazioni sugli stati su qualcosa.)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide cookie\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Cookie e autenticazione/Untitled.png\" alt=\"image/universita/ex-notion/Cookie e autenticazione/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eVengon utilizzati header specifici per settare il cookie.\u003c/p\u003e","title":"Cookie e autenticazione"},{"content":"Introduzione alla corrente elettrica Considerazioni generali Elettroni liberi nei materiali Ricorda che √® un reticolo cristallino, con un elettrone nell\u0026rsquo;ultimo orbitale poco legato, quindi facilmente ionizzabile, in cui gli elettroni si possono muovere facilmente, e abbiamo che $n \\approx 8.5 \\times 10^{28} \\frac{e^{-}}{m^{3}}$ nel rame Per l\u0026rsquo;argento abbiamo 5.9 con stesso ordine di grandezza.\nVelocit√† media elettroni senza campo elettrico üü© $$ \\vec{v}_{m} = \\sum_{i = 1} ^{N} \\frac{\\vec{v}_{i}}{N} = 0 $$$$ \\frac{1}{2} m_{e} v^{2} = \\frac{3}{2} k T $$ Con $k = 1.38 \\times 10 ^{-23} J / K$ questo da studiare in altro posto\u0026hellip;\n$$ \\vec{V} = \\sqrt{ \\frac{3kT}{m_{e}} } \\approx 1.16\\times 10^{5} \\frac{m}{s} = 116 \\frac{km}{s} $$ Assumendo che $T = 293K$ con la teoria cinetica dei gas classica. Ma probabilmente questa analisi non √® corretta, perch√© serve la meccanica quantistica per spiegare questo (Fermi-Sommerfield, calcola meglio questa parte), con questa otteniamo che √® ti tipo $1580 \\frac{km}{s}$ che √® un ordine di grandezza pi√π grande.\nIn assenza di campo sembra assistere a urti anelastici in giro, che vanno a caso e si scontrano con atomi molto pi√π pesanti.\nVelocit√† di deriva üü© Proviamo a considerare questo esperimento: Sia $\\vec{v}_{i}$ la velocit√† di un elettrone prima di un urto, e $\\vec{v}_{i + 1}$ la velocit√† dopo un urto. Facciamo finta che in un campo elettrico venga acceso un campo elettrico nell\u0026rsquo;intervallo fra $i$ e $i + 1$, allora sar√† sottoposto a una forza\n$$ \\vec{F} = -e\\vec{E} $$$$ m \\frac{dv}{dt} = -eE \\implies \\vec{v} = -\\frac{e\\vec{E}}{m} t $$ Allora sappiamo che in ogni urto, si avr√† in generale sempre una componente verso la direzione del campo (questa √® la parte che influenza la velocit√† di deriva che ricordiamo √® molto basso). Questo √® nell\u0026rsquo;ordine di metri all\u0026rsquo;ora.\nAllora provando a riconsiderare la velocit√† media:\n$$ \\vec{v}_{media} = \\frac{1}{N}\\sum \\vec{v}_{i} - \\frac{e\\vec{E}}{m}t = -\\frac{e\\vec{E}}{m}t $$ Dato che la velocit√† che proviene solamente da agitazione termica √® 0, e che ogni singola particella √® soggetta alla stessa forza (si semplifica il numero diciamo per il secondo addendo).\nSimilitudine velocit√† di deriva con caduta üü® Molto brevemente se sottoposti a un campo elettrico, gli elettroni si spostano, ma questa cosa dura molto poco, quindi non era poi utile a utilizzare.\n$$ \\vec{F} = \\vec{P} = m\\vec{g} - \\beta \\vec{v} \\implies \\vec{V}_{lim} = \\frac{m\\vec{g}}{\\beta} = \\text{constant} $$ Anche in questo caso ci sar√† una velocit√† constante media degli elettroni, quando continuamente cominciano a sbattere.\nNel caso delle correnti si chiama effetto di RESISTENZA ossia l\u0026rsquo;effetto di urti sugli atomi del mezzo conduttore, che rallentano, qui il baricentro delle cariche si sposta all\u0026rsquo;interno del campo, che va in modo costante.\nSuperconduttori üü© Sono materiali in cui non c\u0026rsquo;e resistenza, solitamente leghe di metalli rari (boruro di metallo tipo), in cui vicino allo 0 assoluto non hanno resistenza.\nSemiconduttori üü© Sono dei dielettrici drogati con aggiunta di ioni che siano in grado di liberare carica, come sali disciolti nell\u0026rsquo;acqua. Hanno una densit√† di elettroni molto molto minori rispetto ai conduttori, ma sono sufficienti per condurre La caratteristica principale √® che hanno molti meno elettroni liberi, ma ne hanno alcuni.\nIntroduzione con definizioni Definizione della corrente üü© $$ i = \\lim_{ \\Delta t \\to 0 } \\frac{\\Delta q}{\\Delta t} = \\frac{dq}{dt} $$ Questo si pu√≤ mettere in relazione con la densit√† di corrente che sar√† spiegata subito dopo, abbiamo che\nGrandezza della corrente üü© $$ [i] = [Q][T]^{-1} = [A] $$ Ossia $1A = 1C / 1s$ che √® una quantit√† enorme.\nDensit√† di corrente Definizione di densit√† di corrente üü© Perch√© la $\\vec{J}$ che √® definita ha stesso verso del campo elettrico. √à la quantit√† di corrente che attraversa una superficie qualunque, quindi √® un flusso.\n$$ \\vec{J} = ne \\cdot \\vec{v}_{d} $$ Con la velocit√† di deriva.\nDensit√† di corrente motivazione (!) üü© Vogliamo capire, quanta corrente in un intervallo $dt$ attraversa quella superficie? Tutta la carica che sta a distanza $v_{d}dt$ riesce a passare la superficie. abbiamo quindi che il volume √® $$ d\\tau = v_{d} \\Delta t dS \\cos \\theta $$ in cui $v_{d}\\Delta t$ √® il parallelepipedo, o comunque la zona di spazio delle cariche che passeranno attraverso la superficie. E allora il numero di elettroni l√¨ dentro √® $n_{e}\\cdot \\tau$ Quindi\n$$ dq = qn_{e} \\cdot d\\tau $$ Con questo possiamo ri-caratterizzare la definizione di corrente:\n$$ i = \\lim_{ \\Delta t \\to 0 } \\frac{\\Delta q}{\\Delta t} = ne v_{d} S \\cos \\theta = ne \\vec{v}_{d} \\cdot \\vec{S} = \\vec{J} \\cdot \\vec{S} $$ che √® proprio ci√≤ che abbiamo ragionando per first principles.\n$$ i = \\int _{\\Sigma} di = \\int _{\\Sigma} \\vec{J} \\cdot d\\vec{S} $$E chiamo la nuova grandezza $\\vec{J}$ con lo stesso verso del campo elettrico come densit√† di corrente Di valore $\\frac{[A]}{[m]^{2}}$ Quindi la $i$ √® il flusso all\u0026rsquo;interno di quello, come se fosse acqua in tubo. Dal punto di vista del flusso per√≤ √® impossibile distinguere fra positivi e negativi, perch√© tanto si annullano Questo √® vero considerando questa semplice osservazione:\n$$ \\vec{J} = nqv $$$$ \\vec{J} = n (-q) (-v) $$ In ogni caso √® sempre positivo, quindi possiamo usare la parte positiva come carica giustificato da questo artificio matematico.\nStima densit√† di corrente (no impo) Supponiamo di avere un tubo di rame per cui abbiamo $n \\approx 8.5 \\times 10^{28} \\frac{e^{-}}{m^{3}}$, $r = 0.8 mm$ con una corrente $i = 15 A$, consideriamo una superficie perpendicolare. Applichiamo i concetti:\n$$ i = \\int _{\\Sigma} \\vec{J} \\cdot \\vec{dS} = J \\int _{\\Sigma} \\, dS = J \\cdot S = J \\pi r^{2} = nev_{d} \\pi r^{2} \\implies v_{d} = \\frac{i}{neS} $$ Sappiamo che $S \\approx 2 \\times 10^{-6} m^{2}$ e sappiamo che $ne$ √® la densit√† volumetrica di carica, dipendente la carica di conduzione $\\rho$ che √® il valore di n che abbiamo descritto sopra. $ne = \\rho = 8.5 \\times 10^{28} \\cdot 1.6 \\times 10^{-19} \\approx 13.6 \\times 10^{9} \\frac{C}{m^{3}}$\nSostituendo sopra abbiamo che $v_{d} \\approx 5 \\times 10^{-4} \\frac{m}{s} = 2\\frac{m}{h}$ Quindi due metri all\u0026rsquo;ora, avendo gli elettroni che si muovono a 1k chilometri a secondo, la velocit√† di deriva √® molt lenta, ed √® corrente. Ma essendo la carica enorme, alla fine ho grandi valori!\nFacendo tutto questo calcolo abbiamo che\nEquazione di continuit√† della densit√† di corrente (!) üü© $$ i = \\int _{\\Sigma} \\vec{J} \\cdot \\vec{S} = -\\frac{dq}{dt} $$ Perch√© sto considerando la carica positiva che sta uscendo, quindi dentro sto perdendo carica.\nRegime stazionario si ha quando $i = 0$, quindi non ho carica che gira, nel senso che stessa carica esce, e stessa carica esce durante il circuito.\nContinuit√† in forma differenziale üü© Questo √® l\u0026rsquo;equivalente di conservazione di carica per la corrente.\nNoi abbiamo per il teorema della divergenza (vedi Divergenza e Circuitazione) che\n$$ \\oint_{\\Sigma} \\vec{J} \\cdot d\\vec{S} = \\int _{V(\\tau)} \\vec{\\nabla} \\cdot \\vec{J} \\, d\\tau $$$$ \\frac{dq}{dt} = \\int _{V(\\tau)} \\frac{\\delta\\rho}{\\delta t} \\, d\\tau $$$$ \\int _{V(\\tau)} \\frac{\\delta\\rho}{\\delta t} \\, d\\tau = - \\int _{V(\\tau)} \\vec{\\nabla} \\cdot \\vec{J} \\, d\\tau $$ Questa √® l\u0026rsquo;equazione di continuit√† in forma differenziale:\n$$ \\vec{\\nabla} \\cdot \\vec{J} + \\frac{\\delta \\rho}{\\delta t} = 0 $$","permalink":"https://flecart.github.io/notes/corrente-elettrica/","summary":"\u003ch2 id=\"introduzione-alla-corrente-elettrica\"\u003eIntroduzione alla corrente elettrica\u003c/h2\u003e\n\u003ch3 id=\"considerazioni-generali\"\u003eConsiderazioni generali\u003c/h3\u003e\n\u003ch4 id=\"elettroni-liberi-nei-materiali\"\u003eElettroni liberi nei materiali\u003c/h4\u003e\n\u003cp\u003eRicorda che √® un \u003cstrong\u003ereticolo cristallino\u003c/strong\u003e, con un elettrone nell\u0026rsquo;ultimo orbitale poco legato, quindi facilmente ionizzabile, in cui gli elettroni si possono muovere facilmente, e abbiamo che $n \\approx 8.5 \\times 10^{28} \\frac{e^{-}}{m^{3}}$ nel rame\nPer l\u0026rsquo;argento abbiamo 5.9 con stesso ordine di grandezza.\u003c/p\u003e\n\u003ch4 id=\"velocit√†-media-elettroni-senza-campo-elettrico-\"\u003eVelocit√† media elettroni senza campo elettrico üü©\u003c/h4\u003e\n$$\n\\vec{v}_{m} = \\sum_{i = 1} ^{N} \\frac{\\vec{v}_{i}}{N} = 0\n$$$$\n\\frac{1}{2}  m_{e} v^{2} = \\frac{3}{2} k T\n$$\u003cp\u003e\nCon $k = 1.38 \\times 10 ^{-23} J / K$ questo da studiare in altro posto\u0026hellip;\u003c/p\u003e","title":"Corrente Elettrica"},{"content":"Definizione Caratteristiche Variabili Dominio per ogni variabile Costraints per ogni variabile Queste tre sono elementi che definiscono un problema di soddisfazione delle restrizioni, una soluzione √® un assegnamento di variabili che soddisfi ogni restrizioone e sia all‚Äôinterno del dominio\nConsistenza Vogliamo andare a limitare il dominio valutando le consistenze possibili\nConsistenza del punto Si pu√≤ dire che un punto sia consistente se le sue variabili possibili non viola nessuna restrizione unaria: eg. se ho N e ho la restrizione n ‚â• 0, allora avere tutto N √® inconsistente nel punto.\nConsistenza ad arco Questo tratta delle restrizioni binarie: una coppia di punti si dice che √® arco consistente se per ogni variabile nel primo dominio esiste sempre una variabile nel secondo dominio che mi soddisfa la restrizione.\nk-consistenze Si pu√≤ estendere il concetto della consistenza per avere un numero arbitrario di nodi, questo dovrebbe causa per√≤ un costo del calcolo molto maggiore.\nAC-3 algorithm Questo √® un algoritmo per forzare la consistenza ad arco, praticamente va di forza bruta a imporre la consistenza su un arco, se i domini vengono aggiornati gli archi vicini vengono rimessi in coda, in modo da essere sicuri che restino ancora consistenti (infatti eliminando certe variabili potrebbero aver perso di consistenza)\nLa ricerca di una soluzione Backtracking Euristiche della scelta dei valori Minimum remaining Values\nvorremmo che la ricerca della variabile non assegnata fallisca il prima possibile, quindi scegliamo la variabile con pi√π vincoli, o meno valori assegnabili.\nLeast constraining value\nSe vogliamo una unica soluzione che soddisfa vogliamo scegliere variabili che hanno meno probabilit√† di fallire.\nForward check\nAbbastanza simile ad AC-3, toglie dei valori che non possono esserci??? boh cose simili.\n","permalink":"https://flecart.github.io/notes/costraint-satisfaction-problems/","summary":"\u003ch2 id=\"definizione\"\u003eDefinizione\u003c/h2\u003e\n\u003ch3 id=\"caratteristiche\"\u003eCaratteristiche\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eVariabili\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDominio\u003c/strong\u003e per ogni variabile\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCostraints\u003c/strong\u003e per ogni variabile\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eQueste tre sono elementi che definiscono un problema di soddisfazione delle restrizioni, una soluzione √® un assegnamento di variabili che \u003cstrong\u003esoddisfi\u003c/strong\u003e ogni restrizioone e sia all‚Äôinterno del dominio\u003c/p\u003e\n\u003ch2 id=\"consistenza\"\u003eConsistenza\u003c/h2\u003e\n\u003cp\u003eVogliamo andare a limitare il dominio valutando le consistenze possibili\u003c/p\u003e\n\u003ch3 id=\"consistenza-del-punto\"\u003eConsistenza del punto\u003c/h3\u003e\n\u003cp\u003eSi pu√≤ dire che un punto sia consistente se le sue variabili possibili non viola nessuna restrizione unaria: eg. se ho N e ho la restrizione n ‚â• 0, allora avere tutto N √® inconsistente nel punto.\u003c/p\u003e","title":"Costraint Satisfaction Problems"},{"content":" Machine learning cannot distinguish between causal and environment features.\nShortcut learning Often we observe shortcut learning: the model learns some dataset dependent shortcuts (e.g. the machine that was used to take the X-ray) to make inference, but this is very brittle, and is not usually able to generalize.\nShortcut learning happens when there are correlations in the test set between causal and non-causal features. Our object of interest should be the main focus, not the environment around, in most of the cases. For example, a camel in a grass land should still be recognized as a camel, not a cow. One solution could be engineering invariant representations which are independent of the environment. So having a kind of encoder that creates these representations.\nCounterfactual Invariance Counterfactual invariance is a formal framework to define the variables that influence and do not influence the output of a model under certain contexts (i.e. downstream tasks that you could have). It has been introduced in (Veitch et al. 2021) for text perturbations originally.\nA first notion of counterfactual invariance üü© Suppose we have a function $f : \\mathcal{X} \\to \\mathcal{Y}$. Let\u0026rsquo;s define a counterfactual for a random variable $X$. Let\u0026rsquo;s say $W$ is a random variable that represents our non-causal features, e.g. our background. We say $X(\\omega)$ is the result of $X$ when $W=\\omega$, so we force the background to be some specific thing. We would like to formalize the following idea: the outcome of $X$ should be only dependent on $X$, not on $\\omega$.\nWe say $f$ is counterfactually invariant if the following holds: $f(X(\\omega)) = f(X(\\omega'))$ for any $\\omega, \\omega' \\in W$. How does this happen in practice? Ideally we would like to train any counterfactual, but this is practically impossible (too many resources to get camels into Himalaya to create this counterfactual! Additionally, we have too many possible background environments!)\nCausal Graphs The main advantage of using causal graphs is the intuitive understanding of the relations between the variables. Furthermore, these graph relations could be used to define algorithms for inference that exploit their structure. So we say: causal graphs are both interpretable and useful inference models. We now explore some desiderata that is clearly understood in terms of causal graphs: to correctly formalize the notion of counterfactual invariance.\nCausal Graphs üü© In causal scenarios our input features $X$ indeed have a causal relation with $Y$\nSuppose we want to classify cancer and we have three features, $X = (location, CO_{2}, smoke)$, where location is $\\mathbb{R}^{2}$, $CO_{2}\\in \\mathbb{R}$, and $smoke$ is a boolean is our $Y$, or categorical, $W = city$. We can build a causal graph of possible relations between the variables. In the above image $X^{\\perp}_{Y}$ is the set of variables that do not influence $Y$, and $X_{W \\\u0026 Y}$ is the set of variables that influence both $W$ and $Y$. And $X_{W}^{\\perp}$ is the set of variables that are not influenced by $W$ but do influence $Y$.\nAnti-Causal üü© Let\u0026rsquo;s consider another scenario anti-causal scenario, where we want to predict celiac disease, we have stomach ache, fatigue and income as features. Our background variable would be the Job. In these kinds of scenarios, our output random variables $Y$ have a causal relationship with the features in $X$. Whys of non-causal relations üü®++ We can say that two are the main causes of non-causal associations in causal graphs:\nConfounding variables: existence of another random variable U that could affect both of the variables of our interest. Selection bias: We have a variable S that filters the dataset based on the features that we want. Where $X$ are the input features , $Y$ are the output, and $W$ is the environment. In this whole set of note we will keep this nomenclature. An example of selection bias is studying the success of jobs, but you just sample from people on LinkedIn. Formally, we say we have a selection bias if all our samples have a selection criteria $S = 1$. If we want to account both for confounding variables and selection bias, we say our samples satisfy\n$$ P(X, Y, Z) = \\int P(X, Y, Z, u \\mid S = 1) \\, du $$$$ Y \\perp X \\mid W, X_{W}^{\\perp} $$ That is: we can predict $Y$ by only using features that do not depend on $W$. This is a easy way to define spuriousness.\nSimpson\u0026rsquo;s Paradox üü©\u0026ndash; We give the intuition on this paradox with a simple example. Let\u0026rsquo;s say we have treatment A and B, we would like to know which treatment is better. We sent 350 to A and 350 to B. Let\u0026rsquo;s say we observe that with treatment A $78\\%$ recovered, with B $83\\%$ recovered. Seems treatment B is better. But in the case we have another variable, e.g. the severity of the illness, the view could be far more different! These are called confounding variables. When designing an experiment we should keep also this in mind.\nSimpson\u0026rsquo;s paradox occurs due to confounding variables that influence both the group formation and the variables being studied. The decision whether to use treatment $A$ or $B$ should be based on causal considerations for Judea Pearl: different causal structures could arise for the same data, see (Pearl 2009) Chapter 6.1.3.\n$$ \\begin{align} P(E \\mid C) \u003e P(E \\mid C^{c}) \\\\ P(E \\mid C, F) \u003c P(E \\mid C^{c}, F) \\\\ P(E \\mid C, F^{c}) \u003c P(E \\mid C^{c}, F^{c}) \\end{align} $$A formal definition for counterfactual invariance üü® Intuitively a model $f$ is counterfactually invariant if it only depends on $X_{W}^{\\perp}$ which are the features independent on the background (the cow in the example before). The following has been proven by Veitch in (Veitch et al. 2021), this should be still an active area of research.\nFor an estimator $f$ to be counterfactually invariant we need:\nAnti-causal scenario $f(X) \\perp W \\mid Y$ Causal scenario without selection (possibly confounded) $f(X) \\perp W$ Causal scenario with selection we need $f(X) \\perp W \\mid Y$ as long as $(X_{W \\\u0026 Y}, X_{Y}^{\\perp})$ do not influence $Y$, i.e. we have $Y \\perp X \\mid X_{W}^{\\perp}, W$ . Therefore, connecting to the intuitive notion of counterfactual invariance we would like to have $f(X) \\mid W = w, Y=y$ to have the same distribution as $f(X) \\mid W = w', Y= y$ for any $w, w'$. It is\nV-structures üü© This is called d-separation. $$ p(A, C \\mid B) = P(A \\mid B)p(C \\mid B) $$A V structure is a Markov chain in this form $A \\to B \\leftarrow C$: if i know B, then $A, C$ are related to each other.\n$$ P(A, C \\mid B) = P(C \\mid B) \\frac{P(B \\mid A)P(A)}{P(B)} = P(C \\mid B) P(A\\mid B) $$One thing that has not been said about collisions, is that we need every child of it to be not observed (this is what the pyramid below that means).\nSimilarity Metrics If we have two $X$ that represent the same idea but in different backgrounds, we would like their two representations to be somewhat similar. This brings the need to create some sort of a metric to measure their similarity. This section attempts to build upon this idea. This seems to be one of the seminal papers on the idea.\nChecking the difference üü© $$ \\begin{align} \\{ x_{1}, \\dots, x_{n} \\} \\sim p^{*} \\\\ \\{ y_{1}', \\dots, y_{n}' \\} \\sim q^{*} \\end{align} $$ We would like to quantify the sameness between these two distributions. Note that they share the sample space and the Sigma algebra on that.\n$$ p^{*}(x) \\neq q^{*}(x) \\implies\\mathbb{E}_{p^{*}}[\\mathbb{1}_{A}(x)]]\\neq \\mathbb{E}_{q^{*}}[\\mathbb{1}_{A}(x)]] $$$$ \\exists f \\in C(x) : \\mathbb{E}_{p^{*}}[f(x)] \\neq \\mathbb{E}_{q^{*}}[f(x)] $$ So checking the difference is the same as computing the expectation of the approximation of the indicator function. This has been formally proven by Dudley (2002) lemma 9.3.2 (they have proved something stronger).\nComparison with KL Divergence This section was generated by GPT.\nFeature MMD KL Divergence Requires explicit densities No Yes Symmetry Symmetric Asymmetric Support mismatch Well-defined Can be infinite Computational feasibility Efficient for empirical samples Challenging for high-dimensional data Robustness to noise Robust Sensitive MMD is ideal in situations where:\nYou only have empirical samples of the distributions. The distributions are high-dimensional and nonparametric. A symmetric or support-insensitive measure is needed. Maximum Mean Discrepancy üü© $$ MMD(\\mathcal{F}, \\mathcal{X}, \\mathcal{Y}) = \\sup_{f \\in \\mathcal{F}} \\left| \\mathop{\\mathbb{E}}_{x \\sim p}[f(x)] - \\mathop{\\mathbb{E}}_{y \\sim q}[f(y)] \\right| $$ Where $\\mathcal{F}$ is a set of functions that are bounded and continuous. The MMD is a metric that measures the difference between two distributions (M√ºller 1997). The bad thing is that it is difficult to compute: the space of the functions is quite large. In this discussion we will restrict ourselves to the unit sphere of universal RKHS, see Kernel Methods for that. One interpretation of this set is the polynomials whose coefficients squared is 1.\nRiesz Representation Space üü© Applying a bounded linear operator in a Hilbert\u0026rsquo;s Space, then the operator can be represented as a inner product with a function in the space. This is the Riesz Representation Theorem in short! The main usage is moving from the functional realm to an algebraic realm. So we have a strong connection between functional analysis and algebra!\n$$ L(u) = \\langle u, v \\rangle $$$$ \\mathbb{E}_{\\mathcal{X}}[f(x)] = \\beta_{f}^{T}\\mu_{\\mathcal{X}} $$Algebraic Maximum Mean Discrepancy üü®++ We will use Riesz representation theorem and the above MMD to come up with an algebraic version of it that should be easier to compute. By Riesz theorem, computing $f(x)$ is the same as computing the inner product with $\\phi(x) \\in RKHS$ where $\\phi$ is from a family of functions in the RKHS (See Kernel Methods). We express this version of MMD in the following way (Lemma by Borgwardt et al. 2006):\n$$ \\begin{align} MMD^{2}(\\mathcal{F}, \\mathcal{X}, \\mathcal{Y}) \u0026= \\left[ \\sup_{\\lVert f \\rVert _{\\mathcal{H}} \\leq 1} (\\mathop{\\mathbb{E}}_{p}[f(x)] - \\mathop{\\mathbb{E}}_{q}[f(y)] \\right]^{2} \\\\ \\text{Using Riesz Th. }\u0026= \\left[ \\sup_{\\lVert f \\rVert _{\\mathcal{H}} \\leq 1} (\\mathop{\\mathbb{E}}_{p}[\\langle \\phi(x), f \\rangle_{\\mathcal{H}}] - \\mathop{\\mathbb{E}}_{q}[\\langle \\phi(y), f \\rangle_{\\mathcal{H}}] \\right]^{2} \\\\ \\text{Using linearity of expectation} \u0026= \\left[ \\sup_{\\lVert f \\rVert _{\\mathcal{H}} \\leq 1} \\langle \\mu_{\\mathcal{X}} - \\mu_{\\mathcal{Y}}, f \\rangle_{\\mathcal{H}} \\right]^{2} = \\sup_{\\lVert f \\rVert _{\\mathcal{H}} \\leq 1}\\left[ \\langle \\mu_{\\mathcal{X}} - \\mu_{\\mathcal{Y}}, f \\rangle_{\\mathcal{H}} \\right]^{2} \\\\ \\text{Using Chauchy Schwarz} \u0026= \\sup_{\\lVert f \\rVert _{\\mathcal{H}} \\leq 1}\\lVert \\mu_{\\mathcal{X}} - \\mu_{\\mathcal{Y}} \\rVert^{2}_{\\mathcal{H}}\\lVert f \\rVert _{\\mathcal{H}}^{2} = \\lVert \\mu_{\\mathcal{X}} - \\mu_{\\mathcal{Y}} \\rVert^{2}_{\\mathcal{H}} \\\\ \u0026= \\langle \\mu_{p}, \\mu_{p} \\rangle_{\\mathcal{H}} + \\langle \\mu_{q}, \\mu_{q} \\rangle_{\\mathcal{H}} - 2\\langle \\mu_{p}, \\mu_{q} \\rangle_{\\mathcal{H}} \\\\ \u0026= \\mathop{\\mathbb{E}}_{p}[k(x, x')] + \\mathop{\\mathbb{E}}_{q}[k(y, y')] - 2\\mathop{\\mathbb{E}}_{p, q}[k(x, y)] \\end{align} $$$$ \\mathop{\\mathbb{E}}_{x, x' \\sim p}[k(x, x')] \\approx \\frac{1}{n^{2}} \\sum_{i, j} k(x_{i}, x_{j}) $$ And the last two are also compute accordingly.\nReferences [1] Veitch et al. ‚ÄúCounterfactual Invariance to Spurious Correlations in Text Classification‚Äù Curran Associates, Inc. 2021\n[2] Pearl ‚ÄúCausality‚Äù Cambridge University Press 2009\n","permalink":"https://flecart.github.io/notes/counterfactual-invariance/","summary":"\u003cblockquote\u003e\n\u003cp\u003eMachine learning cannot distinguish between causal and environment features.\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch4 id=\"shortcut-learning\"\u003eShortcut learning\u003c/h4\u003e\n\u003cp\u003eOften we observe \u003cstrong\u003eshortcut learning\u003c/strong\u003e: the model learns some dataset dependent shortcuts (e.g. the machine that was used to take the X-ray) to make inference, but this is very brittle, and is not usually able to generalize.\u003c/p\u003e\n\u003cp\u003eShortcut learning happens when there are correlations in the test set between causal and non-causal features. Our object of interest should be the main focus, not the environment around, in most of the cases. For example, a camel in a grass land should still be recognized as a camel, not a cow.\nOne solution could be engineering \u003cstrong\u003einvariant representations\u003c/strong\u003e which are independent of the environment. So having a kind of encoder that creates these representations.\u003c/p\u003e","title":"Counterfactual Invariance"},{"content":"2 Storia 2.1 0: Computer Meccanici dal 1600 a oggi\n2.2 1: Computer a Valvole Principalmente i computer della seconda guerra mondiale\n2.3 2: Computer a Transistor Abbattere i costi\n2.4 3: Circuiti stampati Computazione parallela Multiprogrammazione (Caricamento di pi√π programmi) 2.5 4: VLSI Possibilit√† di creare tansissimi transistor\n2.6 5: Computer moderni 2.6.1 Computer Ubiqui 2.6.2 Computer invisibili 2.7 Velocit√† di calcolo 2.7.1 Flops and MIPS 3 CPU La struttura moderna degli elaboratori sono basati principalmente sull\u0026rsquo;architettura di Von Neuman, l\u0026rsquo;unica differenza √® che gli elementi di questa architettura.\n3.1 Struttura e funzione della CPU La CPU si pu√≤ dividere in tre parti principali:\nUna unit√† di controllo che coordina i processi Registri che immagazzinano temporaneamente piccole quantit√† di informazioni ALU che fa i calcoli ordinategli dalla CPU 3.1.1 Registri Principali Program Counter o Instruction Pointer Contiene un pointer all\u0026rsquo;istruzione da eseguire cos√¨ lo prende dalla memoria Instruction Register Contiene l\u0026rsquo;istruzione da eseguire Memory Address Register Prende l\u0026rsquo;indirizzo del contenuto interessante dalla memoria Memory Data Register Prende il contenuto dalla memoria Program Status Word Raccoglie lo stato di esecuzione del programma, se fallisce se tutto ok oppure se ci sono errori 3.1.2 ALU Aritmetic Logic Unit, √® la componente che fa i calcoli.\nPer sapere cosa deve fare, √® la Control Unit che collega certe vie dai registri all\u0026rsquo;ALU.\nA seconda del genere di architettura pu√≤ collegarsi direttamente in memoria (CISC) oppure sempre passando per i registri (solitamente RISC)\n3.1.3 Central Control Unit Il processore che decide cosa fare, se chiedere qualche altro pezzo dalla memoria seguendo il processo FDE Fetch Decode, Execute, oppure Scrivere qualcosa in memoria e cose simili.\n3.2 Filosofie Architetturali Complex Instructions Set Computer and Reduced Instructions Set Computer definiscono delle filosofie di architettura degli elaboratori differenti.\n3.2.1 CISC e microprogrammazione Utilizza una interpretazione che credo sia cosa a cui il prof. ha riferito come microprogrammazione, ovvero una programmazione delle istruzioni a livello molto basso.\nQuesto livello di interpretazione rallentava la macchina, perch√© non era direttamente eseguito sull\u0026rsquo;hardware. Inoltre la tendenza ad accedere direttamente la memoria **rendeva questo modello a volte imprevedibile in termini di tempo\nEsempio di microprogramma\nChiaro che se questo interamente fosse considerato una istruzione, ci sarebbe un alto bisogno di cicli di clock (diventarebbe in generale pi√π lento).\n3.2.2 RISC e peculiarit√† Una delle peculiarit√† principali delle architetture RISC √® il numero ridotto di istruzioni necessarie (che per√≤ erano molto veloci perch√© girava direttamente sull\u0026rsquo;hardware).\nInoltre ha introdotto un sistema load store con cui affacciarsi alla memoria.\n3.2.3 Alcuni confronti La filosofia attuale √® la RISC, per√≤ a causa della grande presenza di elaboratori CISC, si √® preferito creare architetture ibride che comprendano entrambi: presenza di istruzioni complesse che vengano eseguite su istruzioni harware di RISC. ‚Üí Minore ciclo di Clock e quindi maggiore velocit√†.\nLa differenza principale √® che CISC possiede istruzioni complesse molte dei quali vanno ad accedere la memoria (la parte lenta del processo) invece la RISC possiede soltanto i comandi load and store per accedere alla memoria, il resto delle istruzioni opera all\u0026rsquo;interno del microprocessore.\n3.3 Velocit√† CPU 3.3.1 Clock e Data Path Cycle Il significato di clock √® spiegato molto meglio nella sezione dei Circuiti Sequenziali\nClock √® tempo per l\u0026rsquo;istruzione pi√π corta, se fosse ancora pi√π corta √® molto probabile che la CPU verrebbe indotta in errori molto comuni per cui il computer non funzionerebbe pi√π (un istruzione viene eseguita quando il precedente non √® ancora finito).\nUna Data Path Cycle √® l\u0026rsquo;intero processo che comporta lettura dai registri, calcolo e registrazione del risultato\n3.3.2 Aumentare la velocit√† Ci sono delle soluzioni per rendere la CPU pi√π veloce:\nMigliori reti elettriche (agli informatici non interessa) Overclocking (per un p√≤) Memoria cache (spesso in RISC) Multi-core Pipelining Parallelismo Esattamente come una linea di assemblaggio di fabbrica, possiamo definire alcune parti per processi specifici. 3.4 Parallelismo Circa 3-4 volte pi√π veloce e poco costoso per crearlo, in quanto i pezzi sono efficienti, con pipeline di 5 sotto c\u0026rsquo;√® bisogno di una sola ALU a differenza di 5 per avere funzionalit√† simili.\n3.4.1 Pipelining Spesso alcune istruzioni sono ottimizzate in termini di tempo nel caso sia presente la pipeline o meno, per cui √® interessante poter averlo a mente. Parallelismo livello istruzione\nEsempio:\n5 step.\nCarica l\u0026rsquo;istruzione Interpreta l\u0026rsquo;istruzione Fetch dei dati necessari Esecuzione dopo aver ricevuto i dati Scrittura del risultato. Ogni singola istruzione passa ogni volta secondo questa pipeline, che lavorano in parallelo, velocizzando il CHIP.\n3.4.2 Multicore ~ SIMD \u0026amp; MIMD Ci sono dei computer moderni che contengono molteplici CPU uguali a quanto descritti in 3.1.1\nSIMD\nSingle instruction-stream multiple data-stream *Istruzioni a dati diversi: Tutte le CPU hanno lo stesso stream di dati (magari elaborazione immagini, un qualcosa di ripetitivo su stessa cosa)\nSi guadagna in control unit, unica, fetch unica.\nEsistono anche i processori vettoriali.\nDi solito questo genere di architettura sono utili per istruzioni uguali a dati diversi come l\u0026rsquo;elaborazione di un immagine\nMIMD\nLa differenza dal precedente √® che l\u0026rsquo;istruction stream √® multiplo, ma un p√≤ pi√π costoso perch√© ci sono molte CPU complete.\nAvere troppe CPU su una memoria condivisa non andrebbe bene, perch√© si dovrebbero aspettare. Meglio avere una rete fra CPU per cose grosse.\nCio√® se collegassi troppe CPU, probabilmente l\u0026rsquo;unico bus andrebbe in stallo perch√© tutti cercherebbero ad accedere alla stessa memoria, e le CPU dovrebbero attendersi fra di loro, cosa non buona per la performance.\n3.4.3 Rete di Computer Una soluzione che si solito viene utilizzata dalle grandi aziende o comunque chi possiede le risorse √® la costruzione di grandi reti di calcolatori che possano operare all\u0026rsquo;unisono, o comunque con certo criterio. Dovrebbero essere un sacco di CPU separate che comunicano con un computer centrale che agisce come da Unit√† di Controllo.\nDi solito Multi-core e reti di computer sono conosiderati parallelismo a livello processore\nLe redi di computer sono solitamente facili da costruire ma difficile da programmare, mentre invece un multicore √® difficile da costruire ma facile da programmare.\nInvece il pipelining √® considerato un parallelismo a livello istruzione.\n3.4.4 Prefetch-istruzioni Questa cosa √® molto simile al prefetch della Memoria cache.\nInstruction Fetch Unit sono elementi di Hardware che caricano l\u0026rsquo;istruzione successiva nel momento in cui la presente √® in esecuzione.\nQuesto avviene perch√© il caricamento dell\u0026rsquo;istruzione √® spesso molto lenta.\nQuesta instruction cache prefecht pu√≤ essere implementata a due livelli, Hardware o software.\n3.4.5 Pipeline (e salti) Esempio di pipeline\nL\u0026rsquo;esempio fatto qui √® gi√† considerabile come un primo passo di Pipeline, in cui molteplici passi possono essere fatti allo stesso momento dentro la CPU.\nSolamente la prima esecuzione servono 5-7 clock (a differenza delle parti), quindi basta un ciclo di clock per la fase pi√π lunga per essere sicuri, ecco che riusciamo a completare l\u0026rsquo;istruzione in modo molto pi√π veloce.\nSe una singola istruzione dovrebbe fare tutto, saremmo costretti a tenere un clock molto elevato e il computer nel complesso sarebbe molto lento.\nSalti\nSe faccio un salto allora c\u0026rsquo;√® un buco nel pipeline, ossia cose nel pipeline che non eseguono (perch√© devo saltare), cio√® fetch e decode di certe istruzioni non mi devono servire.\n(ho decodato una istruzione) ma nel frattempo ho gi√† caricato 4 e 5 che non mi servono!\n3.4.6 Predizione di salti Possiamo utilizzare certe euristiche (ragionamenti caso per caso) per predire alcuni salti.\nSalti all\u0026rsquo;indietro\nSi possono prevedere per cicli while e for dei salti all\u0026rsquo;indietro.\nPer salti incondizionati si pu√≤ mettere una instruzione NOP in modo che faccia salti incondizionati senza sprecare istruzioni.\nEsempio data race (read after write)\nAX = 0\nBX = 0\nDX = 0\nAX = DX + 1\nBX = AX - 1\nfetch a decode a, fetch b leggo DX (a) , decode b DX + 1 (a), leggo AX (b) MA STO LEGGENDO TROPPO PRESTO! Quindi devo chiudere AX ed aspettare che AX venga scritto\nA volte, tipico dei processori CISC, si tende a eseguire minicomandi in ordine diverso perch√© ritenuti pi√π efficienti, quindi si mischia un p√≤, proprio come intendi per combinatorio e la fai.\nEntra cisc ma esegue risc.\nEsiste una BPU¬†(Branch Prediction Unit), che cerca di predire l\u0026rsquo;esito di un salto, come spiegato in questa pagina di wiki e una BTP (Branch Target Predictor) che controlla le istruzioni nel ramo di arrivo (qui). Questi sono le componenti principali che determinano la predizione dei salti.\nIn alternativa si mettono dei NOP. o di arrivo (qui). Questi sono le componenti principali che determinano la predizione dei salti.\nIn alternativa si mettono dei NOP.\n","permalink":"https://flecart.github.io/notes/cpu-e-storia-degli-elaboratori/","summary":"\u003ch1 id=\"2-storia\"\u003e2 Storia\u003c/h1\u003e\n\u003ch2 id=\"21-0-computer-meccanici\"\u003e2.1 0: Computer Meccanici\u003c/h2\u003e\n\u003cp\u003edal 1600 a oggi\u003c/p\u003e\n\u003ch2 id=\"22-1-computer-a-valvole\"\u003e2.2 1: Computer a Valvole\u003c/h2\u003e\n\u003cp\u003ePrincipalmente i computer della seconda guerra mondiale\u003c/p\u003e\n\u003ch2 id=\"23-2-computer-a-transistor\"\u003e2.3 2: Computer a Transistor\u003c/h2\u003e\n\u003cp\u003eAbbattere i costi\u003c/p\u003e\n\u003ch2 id=\"24-3-circuiti-stampati\"\u003e2.4 3: Circuiti stampati\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eComputazione parallela\u003c/li\u003e\n\u003cli\u003eMultiprogrammazione (Caricamento di pi√π programmi)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"25-4-vlsi\"\u003e2.5 4: VLSI\u003c/h2\u003e\n\u003cp\u003ePossibilit√† di creare tansissimi transistor\u003c/p\u003e\n\u003ch2 id=\"26-5-computer-moderni\"\u003e2.6 5: Computer moderni\u003c/h2\u003e\n\u003ch3 id=\"261-computer-ubiqui\"\u003e2.6.1 Computer Ubiqui\u003c/h3\u003e\n\u003ch3 id=\"262-computer-invisibili\"\u003e2.6.2 Computer invisibili\u003c/h3\u003e\n\u003ch2 id=\"27-velocit√†-di-calcolo\"\u003e2.7 Velocit√† di calcolo\u003c/h2\u003e\n\u003ch3 id=\"271-flops-and-mips\"\u003e2.7.1 Flops and MIPS\u003c/h3\u003e\n\u003ch1 id=\"3-cpu\"\u003e3 CPU\u003c/h1\u003e\n\u003cp\u003eLa struttura moderna degli elaboratori sono basati principalmente sull\u0026rsquo;\u003cstrong\u003earchitettura di Von Neuman,\u003c/strong\u003e l\u0026rsquo;unica differenza √® che gli elementi di questa architettura.\u003c/p\u003e","title":"CPU e storia degli elaboratori"},{"content":"There is a big difference between the empirical score and the expected score; in the beginning, we had said something about this in Introduction to Advanced Machine Learning. We will develop more methods to better comprehend this fundamental principles.\nHow can we estimate the expected risk of a particular estimator or algorithm? We can use the cross-validation method. This method is used to estimate the expected risk of a model, and it is a fundamental method in machine learning.\nValidation methods Cross-Validation Cross validation is one of the oldest and most popular methods to validate our model parameters. The following slide summarizes the main idea of the cross-validation method. With this method we divide our dataset into $S$ buckets and use $S-1$ of those buckets to train and the rest to validate. If $S = N$ where $N$ is the size of the dataset this is usually called leave-one-out cross-validation. As with this method one needs to have $S-1$ training, this method is usually considered to be computationally expensive for the algorithms that need a lot of time to train.\nBootstrap The bootstrap method is a resampling method that can be used to estimate the distribution of a statistic. The idea is to resample from the dataset with replacement and then calculate the statistic of interest. (Has the advantage of using the whole dataset instead of part of it, as Cross validation does) This process is repeated many times to estimate the distribution of the statistic. The bootstrap method is useful when the distribution of the statistic is unknown or when the sample size is small.\nTODO: probability of one sample appearing in the bootsrap samples.\nEach sample in bootstrap has a probability of appearing of $1 - (1 - \\frac{1}{N})^{N} \\approx 1 - e^{-1} \\approx 0.632$. Taking this into account, we would need to rethink the computation of the risk splitting it into two cases: Risk = probability that sample is in the task $\\times$ risk in this case + probability of not being in the sample $\\times$ risk in this case. This can be rewritten as:\n$$ \\text{Risk} = 0.632 \\times \\text{Risk}_{included} + 0.368 \\times \\text{Risk}_{excluded} $$$$ \\text{Risk}_{included} = \\frac{1}{N} \\frac{1}{B} \\sum_{b = 1}^{B} \\sum_{i = 1}^{N} L(\\theta_{b}, x_{i}, y_{i}) $$$$ \\text{Risk}_{excluded} = \\frac{1}{B} \\sum_{b = 1}^{B} \\frac{1}{C^{-b}} \\sum_{i \\in C^{-b}} L(\\theta_{b}, x_{i}, y_{i}) $$Hypothesis Testing Hypothesis testing is like a legal trial. We assume someone is innocent unless the evidence strongly suggests that he is guilty. In (Wasserman 2004).\nThis seems to be a good resource for p-values.\nP-values üü• We use p-values when we have a clear definition of the kinds of hypothesis that we are going to test. This value is useful if we want to compare two hypothesis: one that is the default safe assumption, and the other that is the surprising possible discovery. Usually we partition the parameter space $\\Theta$ in two disjoint sets $\\Theta_{0}$ and $\\Theta_{1}$, where $\\Theta_{0} \\cap \\Theta_{1} = \\emptyset$ and $\\Theta_{0} \\cup \\Theta_{1} = \\Theta$. Then we have the null hypothesis $H_{0}$ and the alternative hypothesis $H_{1}$. We want to find a rejection region $R$ such that if the observed data falls in $R$ we reject the null hypothesis, otherwise we accept it.\n$$ R_{c} = \\left\\{ x \\mid T(x) \\geq c \\right\\} $$ Where $c$ is called the critical value and $T$ is the test statistic.\n$$ \\text{p-value} = \\inf \\left\\{ \\alpha : T(X^{n}) \\in R_{\\alpha} \\right\\} $$ where $R_{\\alpha}$ is the rejection region of size $\\alpha$. So the P-value tells us how likely are we to accept $H_{0}$, if it\u0026rsquo;s small we are likely to reject it, if it\u0026rsquo;s large we are likely to accept it. In practice, we often set the $\\alpha$ value to be 0.05 as one does not have access to the real distribution of the data. So the p-value just tells us the probability of the null hypothesis to be true. Murphy highlights some questions regarding the validity of that statistics in section 6.6.2 of (Murphy 2012).\nTypes of error üü®\u0026ndash; Type I error: Rejecting the null hypothesis when it is true. Type II error: Accepting the null hypothesis when it is false. Type I error is usually much more serious than Type II error. It could lead to unintended actions that attempt to leverage on the false information, thus bringing demise. If we want are obliged to choose between one of those errors, one would prefer the Type II error. This is why we only accept the alternative hypothesis when there is strong evidence for it.\n$$ \\text{p-value} = P(\\text{observed data} | \\text{null hypothesis}) $$ Size and Power function $$ \\beta(\\theta) = \\mathbb{P}_{\\theta}(X \\in R) $$ So, the power function is the probability of rejection and is more related to Type II errors.\n$$ \\alpha = \\sup_{\\theta \\in \\Theta_{0}} \\beta(\\theta) $$ We say that a test has significance level $\\alpha$ if its size is less or equal to $\\alpha$. Usually the value that is picked is 0.05, but this is just tradition, the value is completely arbitrary.\nWald Test The wald test is defined as\n$$ W = \\frac{\\hat{\\theta} - \\theta_{0}}{\\text{se}} \\sim N(0,1) $$Given a size $\\alpha$ we reject if $\\lvert W \\rvert \u003e z_{\\alpha / 2}$ where $z_{\\alpha / 2}$ is the $\\alpha / 2$ quantile of the standard normal distribution.\n$$ \\text{p-value} = 2 \\min \\left( P(W \u003c w), P(W \u003e w) \\right) $$ References [1] Murphy ‚ÄúMachine Learning: A Probabilistic Perspective‚Äù 2012\n[2] Wasserman ‚ÄúAll of Statistics: A Concise Course in Statistical Inference‚Äù Springer Science \u0026amp; Business Media 2004\n","permalink":"https://flecart.github.io/notes/cross-validation-and-model-selection/","summary":"\u003cp\u003eThere is a big difference between the empirical score and the expected score; in the beginning, we had said something about this in \u003ca href=\"/notes/introduction-to-advanced-machine-learning/\"\u003eIntroduction to Advanced Machine Learning\u003c/a\u003e. We will develop more methods to better comprehend this fundamental principles.\u003c/p\u003e\n\u003cp\u003eHow can we estimate the expected risk of a particular estimator or algorithm? We can use the \u003cstrong\u003ecross-validation\u003c/strong\u003e method. This method is used to estimate the expected risk of a model, and it is a fundamental method in machine learning.\u003c/p\u003e","title":"Cross Validation and Model Selection"},{"content":"Cascading Style Sheets Inizialmente HTML era per la presentazione, abbiamo ancora un p√≤ di attributi storici e tag storici per questa parte di presentazione descritto in Markup.\nIntroduzione √à un linguaggio indipendente per la descrizione della grafica. La cosa bella √® iil fatto di essere indipendente, quindi √® adatto a HTML, a XML e simili.\nUna cosa particolare √® il cascading quindi il fatto che dichiarazioni pi√π nuove sovrascrivano o espandino dichiarazione vecchie.\nLivelli di CSS (cose storiche)\nSulla sintassi Statements Slide struttura dei statements\nLa sintassi classica di uno statements CSS √® in\npropriet√†: valore;\nE il problema per uno sviluppatore √® conoscere cosa fa una propriet√† e che esista üòÄ\nSelettori (!!) Slides selettori\nTipologia del markup e.g. h1 Selettore di classe e.g. .class Selettore di ID e.g. #id Slides selettori 1 pseudo elementi\nFirst letter (utilizzati per il capolettera nei testi vecchi. first Line Before, after sono aree, che normalmente sono vuote, riempibili con content Esempio hover, active e molte altre! https://developer.mozilla.org/en-US/docs/Web/CSS/Pseudo-elements Selettori di prossimit√†\nFiglio di un elemento Elemento figlio diretto. Successivi Tutti i successivi Selettori di attributi\nSelettori pseudo classi strutturali\nPotrebbero essere classi ma non lo sono davvere le pseudoclassi.\nSelettori pseudoclassi\nQui ci sono molti altr icontenuti https://developer.mozilla.org/en-US/docs/Web/CSS/Pseudo-classes\nTipi di dato Come numero o valori assoluti (e.g. col z index, o se non specifico sono dei pixel che √® pericolosa perch√© cambia da device a device il feeling che si avr√†, la dim dei pixel cambia!) o misure di lunghezza che sono moltissime per CSS, vedi slide\nSlide per tipi di misura\nE per i colori, come √® gi√† stato citato in Markup :\nSlide tipi di dato per colori\nCanvas e Viewport Il canvas √à una area di dimensione indefinita che si amplia secondo necessit√†. Cresce verso destra o verso il basso. Solitamente su screen √® sempre il pixel l\u0026rsquo;unita principale, ma questo dipende dalla risoluzione degli schermi e grandezza di essi! (anche le stampanti hanno scalabilit√† diverse).\noffscreen drawing √® una strategia per disegnare e mostrarti solamente quando il risultato √® pronto. Si disegna su coordinate negative, che non sono visibili, e poi quando √® pronto copiartela in coordinata positivia.\nViewport √® la parte visibile dello schermo. Solitamente su schermi PC ho una grandezza a piacere, √® solamente una cosa che interessa principalmente ai cellulari questo viewport. esiste il tag viewport come suggerimento, ma meglio non avere le misure di pixel.\ncasi in cui √® ok fare pixel:\ndire 0 pixel per dire che non lo voglio mostrare nello schermo dire 1 pixel per avere la cosa pi√π fine che possono avere Unit√† di misura di viewport Sono vh e vw che rappresentano la width e height, nel pC √® la dimensione della finestra, pe ri cellulari √® sempre lo schermo massimo.\nesistono anche cose come vmin e vmax che sono il pi√π piccolo fra vm e vh, e il massimo, quindi utilizzo questi per sopravvivere al cambio di oreintamento per lo smartphone.\nIl flex √à la misura dello spazio rimasto nel contenitore. √à solo una cosa che mi permette di calcolare pi√π velocemente le dimensioni, senza che debba andare io a guardarlo.\nSlide misura del flex\nSistema a scatole (flexbox) Ogni elemento ha una scatola che contiene l\u0026rsquo;elemento, e se un elemento sta all\u0026rsquo;interno allora la scatola esterna conterr√† l‚Äôelemento al suo interno\nFlussi, display Slide flussi\nPer la nostra concezione occidentale questi flussi corrispondono al nostro modo di scrivere.\nSolitamente se non voglio fare qualcosa di particolare non vado a specificarlo, ogni tag ha gi√† un suo display proprio.\nElementi della scatola (4) Margine\nBordo\nPadding\nContenuto\nSlide Scatola\nSlide tipografia per la scatola\nFlexbox c\u0026rsquo;√® moltissima altra roba sul flex box ma per ora non sono citati. √à molto flessibile e si riesce ad adattare in modo dinamico a molte cose.\nMentre Grid assumeva di avere un coso fisso.\nPosizionamento della scatola Slide Position\nSlide float, left, top, bottom, right\nZ-index\nstatico √® il default\nAssoluto √® dipendente dal canvas senza tenere conto del flusso\nRelativo √® relativo alla sua posizione naturale\nfisso √® relativo alla viewport.\nsticky resta in viewport quando proviamo ad uscire, altrimenti resta in canvas nella sua naturale.\nOltre position abbiamo anche altre propriet√†, che puoi esservare in slide.\nOverflow (3) Overflow\nVisible quando tutto il testo di overflow √® visibile Hidden quando l\u0026rsquo;overflow non si vede ed √® nascosta. scroll quando √® scrollabile, e la parte di scroll toglie spazio al testo, e sono diverse nei sistemi operativi ste scrollbar, mentre in smartphone non esistono. Il display Slide display\nFonts famiglia\nPeso e stile\nFonts preesistenti\nDecorazioni e spazi\nAltre propriet√† di CSS Ereditariet√† Display e background non sono ereditati Il resto si eredita sempre. Important Allora quanto caricato non viene modificato da riscritture successive.\nOrdine di cascata Slide ordine di cascata\nslide ordine 2\nNormali: che non sono important.\nElementi di Tipografia (non fare) Introduzione Graphic design Slide riguardo storia del graphic design\nStoricamente era fatta da emanuense che copiava tutto, questo lo sai, poi quando √® stato inventato la stampa si √® creato il nuovo mestiere del tipografo, in cui ci sono una serie di caratteri standarizzati che vengono utilizzati come struttura standard.\nDivisi in 3 sezioni principali:\nTipografia Layout (organizzazione della pagina) Organizzazione iconografica (visual art della pagina diciamo) Tipografia La tipografia √® la disposizione armoniosa di tipi (forme di caratteri precostituite) al fine di creare testo leggibile e piacevole alla vista sulla pagina e sugli schermi digitali. Si distingue dalla calligrafia, che √® l\u0026rsquo;armoniosa disposizione sulla pagina di caratteri scritti a mano ed individualmente.\nInizialmente era fatto con legno incavato, ma questo si rovinava molto infretta ed era molto difficile da fare. Gutemberg ebbe l\u0026rsquo;idea di farlo in piombo, utilizzando forme ben definite uguali fra di loro.\nQuesto √® fatto in modo da mantenere un buoon grigio tipografico, ossia equilibrio fr aspazio bianco e stampa in nero.\nFino in questo periodo era molto difficile creare periodici e avere stampa. Questo fino a quando linotype (line of type) che √® in grado di generare al volo la lettera di piombo dopo un tasto. Ebbe un buon successo, azienda americana. Ecco qui che si possono fare i quotidiani. (il problema √® che √® rumoroso, pericoloso per i fumi di piombo e il calore. etc, non √® una cosa da ufficio).\nMeccanismi fotosensibili\nQuesta √® una stampa automatica che utilizzano un fenomeno fisico e una carta fotosensibile, questa √® l\u0026rsquo;industria di stampa a freddo, ossia cold type. E in questo periodo nasce l\u0026rsquo;informatica, e nacque l‚Äôidea di controllare automaticamente questo processo con un programma.\nMarkup languages\nQuesti sono linguaggi nati per controllare le macchine per la stampa a freddo, escono linguaggi come GML, oppure POSTSCRIPTS di Adobe, al tempo una piccola startup di Silicon valley, che poi inventa anche i PDF (versione indipendente dall‚Äôhardware, semplificato e molto portabile a differenza di postscript). Questo aiuta la crezioen di desktop publishing, quindi facile da stampare una volta disegnato sul computer.\nFont Collezzioni di carattere con un certo stile che si possano disporre in modo armonioso. (solitamente per lettere, punteggiatura e numeri).\nFont family e font type Un font √® una collezione di forme di caratteri integrate armoniosamente per le necessit√† di un documento in stampa\nUn type face (o font-family) √® uno stile unico di caratteri che viene espanso in molti font di dimensione e peso e stili diversi.\nTipologie di font (5) Solitamente i font sono una arte occidentale, c‚Äô√® molta meno teoria per i font delle altre culture.\nSlide tipologie di font\nClassificazione di Font (non farlo) Slide classificazioen francese Vox Atypl\nSlide classificazione Novarese\nLe componenti fondamentali di un font: (tanti modi per valutare!)\nCap Serif or sans serif The strokes Ascender or descenders height or x-height (altezza media delle lettere, di solito la x). Letter spacing or kernel Slide componenti fondamentali\nBisogna fare distinzione fra stili e pesi, solitamente l\u0026rsquo;italico √® diverso dal normale, non √® solamente l‚Äôobliquo (il normale leggermente inclinato) e posso avere grandezze (aka pesi) diversi che mi vanno a determinare quanto sono bold.\nBlocchi\nSono una organizzazione del testo, che pu√≤ essere di tanti tipi.\nCi sono certe cose che i tipografi non piaccino come vedove, caccole di mosca, orfani, rivoli o header separati, bandiere\nColore Cosa che mi ha stupito √® che l\u0026rsquo;occhio proprio riesce a percepire solamente 3 colori differenti (wavelengths) che poi vengono interpretati in modo differente).\nSlide spazi di colore\nRGB e RGBa Sono una forma di colore additivo con un canale di Alpha. Se metto tutti i colori ho il bianco. Solitamente questo non √® una cosa lineare.\nSlide RGB\nCYMK Sono dei colori Sottrattivi, quindi aggiungendo tutti ottengo il Nero. Nella pratica il quarto colore √® necessario, anche se non lo sarebbe nel senso teorico (avrei un marrone strano senza il nero, ).\nSlide CYMK\nPage Layout Un altro componente molto importante del design √® il layout, ossia una\nPage layout √® la disposizione aromoniosa degli elementi visuali sulla pagina.\nUn p√≤ di storia Storicamente alcuni elementi come la spessore delle pagine era molto importante (perch√© questo implicava la visibilit√† o meno del carattere dall‚Äôaltra parte della pagina.) Una carta di lusso era importante lo spessore, la ruvidit√†.\nAnche lacuni problemi riconducibili ad affiancamento di pagine, che potrebbero dare un altro significato. Quindi importante andare anche a controllare il contenuto intorno.\nAspetti di Page Layout (6) ORIENTAMENTO\nSlide orientamento\nStoricamente i computer sono sempre stati landscape, cos√¨ come erano i video del cinema. Con l‚Äôarrivo dei cellulari abbiamo cominciato a preferire l‚Äôorientamento portrait. A livello naturale circ a 10 pollici c‚Äô√® uno switch.\nQuesto √® importante perch√© a seconda del nostro target decidiamo il layout.\nASPECT RATIO\nSlide aspect ratio\nCi dice il rapporto fra altezza e larghezza. E ce ne sono molti di aspect ratio.\nIl quadrato non √® mai stato utilizzato in editoria, ma solamente in opere d‚Äôarte carine. US letter √® la carta delle stampanti, anche quello per le lettere di mail 4/3 √® quello dei film, fino ai 2002. 11/8 poi √® messa bandina nera sopra e sotto per essere adatta a 4/3 Holliwod ISO216 √® la carta A4 e ha certe propriet√† particolari 16/10 √® il rapporto classico dei computer, molto vicino al rapporto aureo. US Legal √® una carta un p√≤ pi√π lunga utilizzata nella pubblica amminsitrazione 16/9 sono schermi allungati, utili per TV nuove. Molto bello quando ho dei panorami nei film, quindi schermo cos√¨ meglio. 18/9 Per smartphone, perch√© per le dita non mi conviene allungarl inell‚Äôaltro verso, quindi meglio farli lunghi. Altre su ragionamenti simili. DIMENSIONI\nDimensione\nIl fatto che sia radice, √® molto importante perch√© ci permette di duplicare con due fogli. Si parte con A0 che √® un metro quadro.\nRISOLUZIONE\nSlides risoluzione\nSe siamo ancora in ambiente anglossassone, utilizziamo come unit√† di misura il pollice. Normalmente √® di densit√† (importante soprattuto per la stampa digitali), ma attualmente √® il valore assoluto di pixel nello schermo.\nGRIGLIE DI LAYOUT\nSlides griglie\nLo scopo principale dei Layout √® allineare in maniera bella. Solitamente il numero bello √® 12, perch√© si possono creare dei bei rapporti, infatti anche twitter boostrap utilizza questo formato.\nUna griglia pu√≤ essere densa o con molto spazio, in questo caso si dice che le celle hanno breathing.\nSEZIONE AUREA\nSlides sezione aurea\n√à un rapporto che sembra molto carino.\n","permalink":"https://flecart.github.io/notes/css/","summary":"\u003ch1 id=\"cascading-style-sheets\"\u003eCascading Style Sheets\u003c/h1\u003e\n\u003cp\u003eInizialmente HTML era per la presentazione, abbiamo ancora un p√≤ di attributi storici e tag storici per questa parte di presentazione descritto in \u003ca href=\"/notes/markup/\"\u003eMarkup\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003cp\u003e√à un linguaggio \u003cstrong\u003eindipendente\u003c/strong\u003e per la descrizione della grafica. La cosa bella √® iil fatto di essere indipendente, quindi √® adatto a HTML, a XML e simili.\u003c/p\u003e\n\u003cp\u003eUna cosa particolare √® il \u003cstrong\u003ecascading\u003c/strong\u003e quindi il fatto che dichiarazioni pi√π nuove sovrascrivano o espandino dichiarazione vecchie.\u003c/p\u003e","title":"CSS"},{"content":"Data Cubes is a data format especially useful for heavy reads. It has been popularized in business environments where the main use for data was to make reports (many reads). This also links with the OLAP (Online Analytical Processing) vs OLTP (Online Transaction Processing) concepts, where one is optimized for reads and the other for writes.\nThe main driver behind data cubes was business intelligence. While traditional relational database systems are focused on the day-to-day business of a company and record keeping (with customers placing or- ders, inventories kept up to date, etc), business intelligence is focused on the production of high-level reports for supporting C-level executives in making informed decisions.\nThe Data Model We basically have some dimensions that index the data (which can be more than three in the image), and we have some information for each. The important part is that they are **dense** meaning we usually have information for every entry. Fact Tables Clearly this model can be decomposed into a relational table, which is called fact table in this context. For example, the following is a $2\\times 2\\times 2$ cube: Operations Slicing üü®\u0026ndash; We just take a subset of the cube, for example, we can take all the data for a specific value of one of the dimensions. This should be the equivalent of a projection, we only care about specific values. Equivalent of a selection on the fact table.\nDefinition: Slicing is the process of selecting a specific slice (subset) of the data cube by fixing a value for one or more dimensions. It reduces the dimensionality of the cube by keeping certain dimensions constant and viewing the data along the remaining dimensions. Example: Consider a data cube with dimensions: Time, Product, and Location. Slicing might involve selecting data for a specific Time (e.g., January 2025) to analyze sales across Product and Location dimensions. Dicers üü®\u0026ndash; If we slice in a way such that we only have (1,2,3)-dimensions left, then we have a nice way to represent that information in 2D table. This is what dicing means, it is a slice plus a nice organization in an human readable manner of the information.\nDefinition: Dicing is similar to slicing but involves selecting a sub-cube by specifying a range or set of values for multiple dimensions. This operation creates a smaller cube with more refined data. Example: Using the same data cube, dicing could involve selecting sales data for the Time range (e.g., January to March 2025), specific Products (e.g., Laptops and Tablets), and Locations (e.g., Zurich and Milan). Hierarchies We can have hierarchies in the dimensions, for example, we can have a hierarchy of time (year, month, day).\nDefinition: Hierarchies define levels of granularity within a dimension and facilitate roll-up and drill-down operations. A hierarchy organizes data within a dimension into a tree-like structure, enabling movement between detailed and summarized views. Example: For the Location dimension, a hierarchy might be: City ‚Üí Country ‚Üí Continent. For the Time dimension, a hierarchy might be: Day ‚Üí Month ‚Üí Quarter ‚Üí Year. Significance: Hierarchies are essential for summarization, enabling roll-up (aggregation to higher levels) and drill-down (exploration to lower levels). Roll-Up Definition: Roll-up is the process of aggregating data along a dimension hierarchy, moving from more detailed data to summarized or higher-level data. This typically involves grouping data and applying aggregation functions such as sum, average, or count. Example: In the same data cube, rolling up along the Location hierarchy might aggregate sales data from cities (e.g., Zurich, Milan) into countries (e.g., Switzerland, Italy) or continents (e.g., Europe). Similarly, rolling up along Time might aggregate daily data into monthly or yearly data. Implementation In this section we will present how data cubes are usually implemented.\nROLAP ROLAP is the storage of the data cube in a relational database. This is done by having a fact table and multiple dimension tables.\nPivoting We can pivot the data cube to have a 2D table, which is useful for visualization. The easiest example is when we have a column in a table to be an enum, then we can explode this column into multiple columns, one for each value of the enum. This is called Pivoting. The reverse process is called unpivoting.\nSatellite Tables These are tables that contain information about the dimensions. The main table just contains the keys to these tables, the full information is in the satellite tables and can be recovered with joins. If the satellited tables are also normalized (see Structured Query Language) we derive the snowflake schema (if not, is called star schema).\nQuerying Cube Data TODO: (the main problem is doing with multiple aggregates).\nMOLAP In this case the support for cubes is implemented from scratch. We will not cover this method. MOLAP stands for Multidimensional OLAP. They also have a special query language called MDX (Multi Dimensional Expressions).\n","permalink":"https://flecart.github.io/notes/data-cubes/","summary":"\u003cp\u003eData Cubes is a data format especially useful for heavy reads. It has been popularized in business environments where the main use for data was to make reports (many reads).\nThis also links with the OLAP (Online Analytical Processing) vs OLTP (Online Transaction Processing) concepts, where one is optimized for reads and the other for writes.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe main driver behind data cubes was business intelligence. While\ntraditional relational database systems are focused on the day-to-day\nbusiness of a company and record keeping (with customers placing or-\nders, inventories kept up to date, etc), business intelligence is focused on\nthe production of high-level reports for supporting C-level executives\nin making informed decisions.\u003c/p\u003e","title":"Data Cubes"},{"content":" A data model is an abstract view over the data that hides the way it is stored physically.\nThe same idea from (Codd 1970) This is why we should not modify data directly, but pass though some abstraction that maintain the properties of that specific data model.\nData Models Tree view üü© We can view all JSON and XML data, as presented in Markup, as trees. This structure is usually quite evident, as it is inherent in their design. Converting from the tree structure to a memory model is known as serialization, while the reverse process is called parsing.\nA key distinction lies in edge labeling for JSON models and node labeling for XML models. Additionally, XML accessors are bidirectional, meaning they include a parent pointer, whereas JSON lacks this feature.\nXML Information Set This is how actually is stored in memory when the XML file is parsed into memory. It\u0026rsquo;s also quite easy to implement after a standard programming course. There are many other parts of the information set, but we will not cover them in the current course (e.g. Namespaces, comments, are not covered.)\nDocument Information Item üü© The document information item is the root node of the three view; the first element of XML file should be always present even if the doctype declaration is not present, this is the children of this information item.\nElement Information Item üü© This is just the element tag, as it is explained briefly in Markup. Parents could be the root document item, or other information items. It can have attributes, children and the local name (the name of the tag).\nAttribute Information Item üü© Here we have a key (called local name), the value, and the parent, which is the element that owns this attribute.\nText Information Item üü© We just have the text value and the owner for this element.\nValidation Even with a well-formed JSON or XML document, the structure can still be quite disorganized. Imagine a document where values are scattered haphazardly. Our goal should be to impose some order on these documents by providing them with an abstract model of the data. We say that a JSON or XML document adheres to a model when it is correctly validated against that model. In this section, we will explore specific validation modes available for JSON and XML. Usually this validation step is done after the file has been correctly parsed into the memory.\nThere are some advantages in validation, one is the processing speed. With normalized data, we can use some specific data structures tailored to process that format, and store it more efficiently.\nAtomic Types We need to remember that there are some default atomic types for the data model, which are different from the 4 atomic types present in the well-formedness of JSONs.\nStrings Numbers Booleans Null values Dates and times (you need to be careful about month - day division, number of days is dependent of year and months) Time intervals Binary These atomic types are usually common everywhere, but the names could vary. The following is a table that summarizes the various names for different technologies Lexical and Value space üü© All atomic types have in common that they have a logical value space and a lexical value space. The logical value space corresponds to the actual logical abstraction of the type (e.g., a mathematical set of integers), while the lexical value space corresponds to the representation of logical values in a textual format (such as the decimal, or binary, or hexadecimal representation of an integer).\nSo the Value Space is what it wants to represent, while the lexical space is what is actually stored. For example, an image could be stored using base64 encoding.\nStatic and Dynamic schemas üü© Dynamic schemas allow for more flexibility, while static schemas are more rigid. The former are more common in JSON, while XML schemas are just static. For example dynamic schemas can allow for keys that are not defined in the schema if the additionalProperties is set to true.\nJSON Validation There are some specific types in JSON, and we need to know them well. One of the most famous validation frameworks with JSON is JSound (developed at ETH for teaching purposes), you should know the syntax very well for the scope of the course. See slides, for example here. Another checker could be JSON Schema, which is standardized by the W3C.\nStructured Types In this case, there are no additional types beyond the standard array and map values typically found in JSON. The only distinction is that we might need to impose a cardinality constraint.\nThen there are many many ways to describe a requirement for the data model some common ways you need to keep in mind are\nCardinality: How many times a specific element can appear. Requiring presence of a key Open and closed object types (difference between JSound and JSON schema). Primary key constraints, null and present values. (In jsound we have special characters ?, = and @) Any values Type unions and intersections, negation, exclusive. Example of JSON Validation Let\u0026rsquo;s say we want to build a schema for:\n{ \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;age\u0026#34;: 30, \u0026#34;email\u0026#34;: \u0026#34;john.doe@example.com\u0026#34;, \u0026#34;isEmployee\u0026#34;: true, \u0026#34;skills\u0026#34;: [\u0026#34;JavaScript\u0026#34;, \u0026#34;Python\u0026#34;, \u0026#34;SQL\u0026#34;], \u0026#34;address\u0026#34;: { \u0026#34;street\u0026#34;: \u0026#34;123 Main St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Zurich\u0026#34;, \u0026#34;postalCode\u0026#34;: \u0026#34;8000\u0026#34; }, \u0026#34;projects\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;E-commerce Website\u0026#34;, \u0026#34;durationMonths\u0026#34;: 6 }, { \u0026#34;title\u0026#34;: \u0026#34;AI Chatbot\u0026#34;, \u0026#34;durationMonths\u0026#34;: 4 } ] } Then a possible schema would be:\n{ \u0026#34;$schema\u0026#34;: \u0026#34;[http://json-schema.org/draft-07/schema#\u0026#34;,](http://json-schema.org/draft-07/schema#\u0026#34;,) \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;minLength\u0026#34;: 1, \u0026#34;description\u0026#34;: \u0026#34;The full name of the person.\u0026#34; }, \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;, \u0026#34;minimum\u0026#34;: 18, \u0026#34;maximum\u0026#34;: 65, \u0026#34;description\u0026#34;: \u0026#34;Age must be between 18 and 65.\u0026#34; }, \u0026#34;email\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;email\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;A valid email address.\u0026#34; }, \u0026#34;isEmployee\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Whether the person is an employee or not.\u0026#34; }, \u0026#34;skills\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;minItems\u0026#34;: 1, \u0026#34;uniqueItems\u0026#34;: true, \u0026#34;description\u0026#34;: \u0026#34;A list of unique skills.\u0026#34; }, \u0026#34;address\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;street\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;city\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;Zurich\u0026#34;, \u0026#34;Geneva\u0026#34;, \u0026#34;Basel\u0026#34;], \u0026#34;description\u0026#34;: \u0026#34;City must be one of Zurich, Geneva, or Basel.\u0026#34; }, \u0026#34;postalCode\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;pattern\u0026#34;: \u0026#34;^[0-9]{4}$\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;A 4-digit postal code.\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;street\u0026#34;, \u0026#34;city\u0026#34;, \u0026#34;postalCode\u0026#34;], \u0026#34;description\u0026#34;: \u0026#34;Address details.\u0026#34; }, \u0026#34;projects\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;durationMonths\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;, \u0026#34;minimum\u0026#34;: 1, \u0026#34;description\u0026#34;: \u0026#34;Project duration must be at least 1 month.\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;title\u0026#34;, \u0026#34;durationMonths\u0026#34;], \u0026#34;description\u0026#34;: \u0026#34;Details of projects.\u0026#34; }, \u0026#34;minItems\u0026#34;: 1, \u0026#34;description\u0026#34;: \u0026#34;A list of projects.\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;name\u0026#34;, \u0026#34;age\u0026#34;, \u0026#34;email\u0026#34;, \u0026#34;isEmployee\u0026#34;, \u0026#34;skills\u0026#34;, \u0026#34;address\u0026#34;], \u0026#34;additionalProperties\u0026#34;: false } XML Validation XML Schema is one of the most famouse ways to validate XMLs. This is an example of a XML schema\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;xs:schema xmlns:xs=\u0026#34;[http://www.w3.org/2001/XMLSchema\u0026#34;\u0026gt;](http://www.w3.org/2001/XMLSchema\u0026#34;\u0026gt;) \u0026lt;xs:element name=\u0026#34;foo\u0026#34; type=\u0026#34;xs:string\u0026#34;/\u0026gt; \u0026lt;/xs:schema\u0026gt; We see that they are inside a namespace, then we have special tags for elements, types and attributes.\nWe can also control the number of times an element appears in the document.\nXML Types Here are some types taken from the Book.\nStrings: xs:string, xs:anyURI (for strings containing a URI); Numbers: xs:decimal, xs:integer, xs:float, xs:double, xs:long, xs:int, xs:short, xs:byte, xs:negativeInteger, xs:positiveInteger, xs:nonNegativeInteger, xs:nonPositiveInteger, xs:unsignedByte, xs:unsignedShort, xs:unsignedInt, xs:unsignedLong; Dates and times: xs:date, xs:time, xs:dateTime, xs:gYearMonth, xs:gYear, xs:gMonth, xs:gDay, xs:gMonthDay, xs:dateTimeStamp; Time intervals: xs:duration, xs:yearMonthDuration, xs:dayTimeDuration; Binary types: xs:hexBinary, xs:base64Binary Booleans: xs:boolean Nulls: does not exist as a type in XML Schema (JSON specific). Normally one can also define custom atomic types! In this case we use keywords like xs:simpleType and xs:restriction or xs:complexType for more complex types (nested elements or sequences).\nFacets An XML facet refers to a constraint or rule applied to XML data types, particularly in XML Schema (XSD), to define specific properties or restrictions for elements or attributes within an XML document. Facets are used to specify conditions such as length, value ranges, patterns, and other constraints on the data stored in an XML document.\nFacets are often associated with simple types in XML Schema and help enforce validation rules for the values of elements or attributes. For example, you can use facets to ensure that an element contains a number within a specific range or a string that matches a particular pattern.\nExample of XML validation \u0026lt;Library\u0026gt; \u0026lt;Book isbn=\u0026#34;978-3-16-148410-0\u0026#34;\u0026gt; \u0026lt;Title\u0026gt;Effective Java\u0026lt;/Title\u0026gt; \u0026lt;Author\u0026gt;Joshua Bloch\u0026lt;/Author\u0026gt; \u0026lt;Year\u0026gt;2018\u0026lt;/Year\u0026gt; \u0026lt;Genre\u0026gt;Programming\u0026lt;/Genre\u0026gt; \u0026lt;/Book\u0026gt; \u0026lt;Book isbn=\u0026#34;978-1-118-06333-2\u0026#34;\u0026gt; \u0026lt;Title\u0026gt;Clean Code\u0026lt;/Title\u0026gt; \u0026lt;Author\u0026gt;Robert C. Martin\u0026lt;/Author\u0026gt; \u0026lt;Year\u0026gt;2008\u0026lt;/Year\u0026gt; \u0026lt;Genre\u0026gt;Programming\u0026lt;/Genre\u0026gt; \u0026lt;/Book\u0026gt; \u0026lt;Member id=\u0026#34;101\u0026#34;\u0026gt; \u0026lt;Name\u0026gt;John Doe\u0026lt;/Name\u0026gt; \u0026lt;Email\u0026gt;john.doe@example.com\u0026lt;/Email\u0026gt; \u0026lt;PhoneNumber\u0026gt;+1234567890\u0026lt;/PhoneNumber\u0026gt; \u0026lt;/Member\u0026gt; \u0026lt;Member id=\u0026#34;102\u0026#34;\u0026gt; \u0026lt;Name\u0026gt;Jane Smith\u0026lt;/Name\u0026gt; \u0026lt;Email\u0026gt;jane.smith@example.com\u0026lt;/Email\u0026gt; \u0026lt;/Member\u0026gt; \u0026lt;/Library\u0026gt; A possible schema would be:\n\u0026lt;xs:schema xmlns:xs=\u0026#34;[http://www.w3.org/2001/XMLSchema\u0026#34;](http://www.w3.org/2001/XMLSchema\u0026#34;) elementFormDefault=\u0026#34;qualified\u0026#34;\u0026gt; \u0026lt;!-- Root Element --\u0026gt; \u0026lt;xs:element name=\u0026#34;Library\u0026#34;\u0026gt; \u0026lt;xs:complexType\u0026gt; \u0026lt;xs:sequence\u0026gt; \u0026lt;xs:element name=\u0026#34;Book\u0026#34; maxOccurs=\u0026#34;unbounded\u0026#34; minOccurs=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;xs:complexType\u0026gt; \u0026lt;xs:sequence\u0026gt; \u0026lt;xs:element name=\u0026#34;Title\u0026#34; type=\u0026#34;xs:string\u0026#34; /\u0026gt; \u0026lt;xs:element name=\u0026#34;Author\u0026#34; type=\u0026#34;xs:string\u0026#34; /\u0026gt; \u0026lt;xs:element name=\u0026#34;Year\u0026#34; type=\u0026#34;xs:gYear\u0026#34; /\u0026gt; \u0026lt;xs:element name=\u0026#34;Genre\u0026#34;\u0026gt; \u0026lt;xs:simpleType\u0026gt; \u0026lt;xs:restriction base=\u0026#34;xs:string\u0026#34;\u0026gt; \u0026lt;xs:enumeration value=\u0026#34;Programming\u0026#34; /\u0026gt; \u0026lt;xs:enumeration value=\u0026#34;Fiction\u0026#34; /\u0026gt; \u0026lt;xs:enumeration value=\u0026#34;Non-Fiction\u0026#34; /\u0026gt; \u0026lt;xs:enumeration value=\u0026#34;Science\u0026#34; /\u0026gt; \u0026lt;/xs:restriction\u0026gt; \u0026lt;/xs:simpleType\u0026gt; \u0026lt;/xs:element\u0026gt; \u0026lt;/xs:sequence\u0026gt; \u0026lt;xs:attribute name=\u0026#34;isbn\u0026#34; type=\u0026#34;xs:string\u0026#34; use=\u0026#34;required\u0026#34; /\u0026gt; \u0026lt;/xs:complexType\u0026gt; \u0026lt;/xs:element\u0026gt; \u0026lt;xs:element name=\u0026#34;Member\u0026#34; maxOccurs=\u0026#34;unbounded\u0026#34; minOccurs=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;xs:complexType\u0026gt; \u0026lt;xs:sequence\u0026gt; \u0026lt;xs:element name=\u0026#34;Name\u0026#34; type=\u0026#34;xs:string\u0026#34; /\u0026gt; \u0026lt;xs:element name=\u0026#34;Email\u0026#34; type=\u0026#34;xs:string\u0026#34;\u0026gt; \u0026lt;xs:annotation\u0026gt; \u0026lt;xs:documentation\u0026gt;Email should be unique\u0026lt;/xs:documentation\u0026gt; \u0026lt;/xs:annotation\u0026gt; \u0026lt;/xs:element\u0026gt; \u0026lt;xs:element name=\u0026#34;PhoneNumber\u0026#34; type=\u0026#34;xs:string\u0026#34; minOccurs=\u0026#34;0\u0026#34; /\u0026gt; \u0026lt;/xs:sequence\u0026gt; \u0026lt;xs:attribute name=\u0026#34;id\u0026#34; type=\u0026#34;xs:ID\u0026#34; use=\u0026#34;required\u0026#34; /\u0026gt; \u0026lt;/xs:complexType\u0026gt; \u0026lt;/xs:element\u0026gt; \u0026lt;/xs:sequence\u0026gt; \u0026lt;/xs:complexType\u0026gt; \u0026lt;/xs:element\u0026gt; \u0026lt;!-- Unique Constraints --\u0026gt; \u0026lt;xs:unique name=\u0026#34;uniqueEmail\u0026#34;\u0026gt; \u0026lt;xs:selector xpath=\u0026#34;Member\u0026#34; /\u0026gt; \u0026lt;xs:field xpath=\u0026#34;Email\u0026#34; /\u0026gt; \u0026lt;/xs:unique\u0026gt; \u0026lt;!-- Referential Integrity --\u0026gt; \u0026lt;xs:key name=\u0026#34;memberIDKey\u0026#34;\u0026gt; \u0026lt;xs:selector xpath=\u0026#34;Member\u0026#34; /\u0026gt; \u0026lt;xs:field xpath=\u0026#34;@id\u0026#34; /\u0026gt; \u0026lt;/xs:key\u0026gt; \u0026lt;/xs:schema\u0026gt; Dataframes What are data frames? üü© Data frames are a generalization of (normalized) relational tables allowing for (organized and structured) nestedness.\nDataframes are a way to represent data in a tabular way, with rows and columns. So we can interpret Dataframes as whatever data model we want, the main requirement is that it is valid against a certain schema that we define. Additional requirements are\nSchemas should not be valid for additional fields. Schemas should not allow \u0026ldquo;any\u0026rdquo; values, but some specific types (e.g. strings, int, booleans etc.). So we have some homogeneous data. A relational database is a dataframe, but the inverse is not necessarily true (dataframes can violate atomic integrity for example). Two Advantages üü© Some formats are highly optimized for storing, e.g. Parquet, Avro, Root, Google‚Äôs protocol buffers. We gain space and time efficiency. As we have homogeneous rows, we can have more efficient look-ups by skipping entire rows. We can also have compression and columnar storage.\nParquet is called that way because the data is stored in a columnar fashion, grouping all the values (across objects) together when they are associated with the same key, which might remind you of the parquet floor of your living room.\nThe performance efficiency comes from optimization of the storage and the ability to read only the necessary columns for a specific query -\u0026gt; we store only column names once, instead of doing it in every field, while with JSON for instance, one would need to repeat the key many many times. Another advantage, is the constant size for a single row, that allows direct look-ups row per row, instead of using linear search.\nHomogeneous vs Heterogeneous üü© Homogeneous are collections of documents that all follow the same data model, with the rules of typing allowed for dataframes, while heterogeneous doesn\u0026rsquo;t have this rules. Another important difference is knowing how to classify for flat and nested structures. Usually, if the data is Heterogeneous enough, then Dataframes are much more better.\nClassification of data formats üü•++ We have three main categories of data formats:\nBinary: e.g. Parquet, Avro, ORC, Protocol Buffers (not CSV, JSON, XML, YAML) Nestedness: e.g. JSON, XML, Parquet, Avro (not CSV) Schema: if they need a valid data frame, e.g. Avro, Protocol Buffers, XML Schema, JSON Schema (not CSV, JSON or YAML) Columnar Storage üü®\u0026ndash; Dataframes are more efficient compared to Wide Column Storage in some aspects because the keys only need to be described once, allowing us to store them efficiently. Another reason: if we only need a single column in our Apache Spark task then we could only fetch the needed column and ignore the others. In apache spark, the dataframes are stored as an internal dataframe type.\nIf we store nested dataframes in a relational database. This is much more difficult to process both for humans and machines. Machines need to parse again the stored string into a the correct format. Human\u0026rsquo;s need to write some weird SQL code for lateral views with explode operators.\nReferences [1] Codd ‚ÄúA Relational Model of Data for Large Shared Data Banks‚Äù Communications of the ACM Vol. 13(6), pp. 377\u0026ndash;387 1970\n","permalink":"https://flecart.github.io/notes/data-models-and-validation/","summary":"\u003cblockquote\u003e\n\u003cp\u003eA data model is an abstract view over the data that hides the way it is stored physically.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eThe same idea from \u003ca href=\"https://dl.acm.org/doi/10.1145/362384.362685\"\u003e(Codd 1970)\u003c/a\u003e\nThis is why we should not modify data directly, but pass though some abstraction that maintain the properties of that specific data model.\u003c/p\u003e\n\u003ch2 id=\"data-models\"\u003eData Models\u003c/h2\u003e\n\u003ch4 id=\"tree-view-\"\u003eTree view üü©\u003c/h4\u003e\n\u003cp\u003eWe can view all JSON and XML data, as presented in \u003ca href=\"/notes/markup/\"\u003eMarkup\u003c/a\u003e, as \u003cstrong\u003etrees\u003c/strong\u003e. This structure is usually quite evident, as it is inherent in their design. Converting from the tree structure to a memory model is known as serialization, while the reverse process is called \u003cstrong\u003eparsing\u003c/strong\u003e.\u003c/p\u003e","title":"Data Models and Validation"},{"content":"Introduzione Data or Control plane come fanno i router a fare forwarding dei pacchetti? e decidere come mandare? Come fanno a passare. Sono le tabelle di instradamento. Si pu√≤ dire di end-to-end perch√© solamente il sender e receiver andranno a livello applicazione, e leggeranno le cose (se criptato veramente solo loro riescono a fare questo).\nFunzioni principali Forwarding che in pratica √® passare il pacchetto al successivo, √® parte del data plane.\nQuesta √® una cosa molto semplice, in pratica bisogna capire da una porta di ingresso quale sar√† la porta d‚Äôuscita del router. Guardando l\u0026rsquo;intestazione del pacchetto. Se non fa match nessuna riga della tabella allora manda nel router di default che avr√† un reach maggiore, pi√π probabile che sappia dove mandare.\nRouting invece va a scrivere mappe nel grafico della rete, cio√® capisce quale sia il percorso pi√π breve all\u0026rsquo;interno della rete, √® parte del control plane.\nTutta la rete in modo coordinato prova a creare questo piano (me se stesse segnalando se una segnaletica funziona ancora, se la strada va ancora dove dovrebbe andare (e.g. se √® crollato un ponte dovresti sapere se quella strada non funziona pi√π)).\nSolitamente questo √® fatto con un software chiamato SDN (ma anche un umano potrebbe farle, anche se sarebbe troppo lento).\nRouting control planes La differenza fra i due √® sostanzialmente architetturale, se ne parla in Architetture a livello applicazione üü©.\nPER ROUTER CONTROL PLANE possiamo dire che sia un modo semplice del control plane per stabilire la tabella di instradamento, in pratica listo tutti i collegamenti che ho nella tabella con i loro IP di interesse, quindi se un prefisso matcha quello allora mando l√¨. √à strano che i router siano anche in grado di fare prefisso pi√π lungo per matchare. In questo modo utilizzando un algoirtmo locale, distribuito, posso avere una tabella di istradamento. gli algoritmi locali possono fare scelte non coordinate, dato che pu√≤ cambiare nel tempo la situazione, l\u0026rsquo;informazione locale potrebbe non essere del tutto corretta.\nLOGICALLY CENTRALIZED CONTROL PLANE quando c\u0026rsquo;√® una struttura centrale che contiene tutte le informazioni dei singoli router (o almeno quanto trasmesso), e da l√¨ aggiorna le tabelle di instradamento dei singoli router. (Control Agent √® il singolo router, che trasmette a un controllo remoto). La cosa importante √® che il cos Remote Contorller √® conoscente di tutti i dati principali della rete. Questo rende pi√π efficiente, perch√© ha tutte le informazioni per fare le decisioni migliori.\nPer√≤ ha bisogno di comunicare fra CA e RC, e se non funziona la comunicazione non avrei comunque le informazioni perfette.\nInoltre deve essere un processo bono, e si dovrebbe capire chi avrebbe la responsabilti√† di pagare il remote controller, i provider? gli utenti finali?\nImmagine semplificazione Data e Control Plane\nService Model I modelli di servizio definiscono le caratteristiche che dovrebbe avere il servizio di trasporto end-to-end dei pacchetti. Alcune caratteristiche potrebbero esser come consegna garantita, o garantita consegna entro certo tempo, oppure il flow dei datagrammi in ordine, minima bandwidth, servizi di sicurezza sul trasporto. Ma queste caratteristiche alla fine non sono comunque mai garantite. Quindi possiamo indire un sistema best-effort, ma non √® che sia comunque garantito qualcosa, potrei dire che una rete che non √® in grado di trasportare niente sta facendo il massimo di quanto riesce a fare. Non ci aiuta molto.\nATM (asynchronous transfer model) √® un servizio che prova a fare questo, cercare di misurare il modello di servizio del trasporto che in una specifico spazio temporale posso darti tutte le risorse, e allora avresti le garanzie dette sopra. E se non riesco a riempire tutto il canale in quel tempo, do lo spazio in pi√π ad altri che non hanno bisogno di quella garanzia.\nC‚Äô√® un Overhead per la quantit√† di dati e la lunghezza di header (se header molto lungo, alla fine trasmetto meno percentuale di dati), per√≤ se faccio troppo lungo ci metto di pi√π a mandare, quindi altri pacchetti potrebbero metterci molto di pi√π ad arrivare, e perdere la garanzia sul tempo minimo di arrivare. era 32 o 64, quindi si √® fatta una scelta politica che √® 48 byte, e fa schifo perch√© non √® una potenza di 2 e devi fare check leggermente pi√π complicate.\nA noi di solito non serve questa garanzia, noi utenti dico, ma al backbone di internet √® importante e si sono messi cos√¨. Ci sono molti tipologie di ATM come\nconstant bit rate ( voice over Ip, abbiamo biosgno di flusso costante per la voce, vogliamo real time, oppure coso di un reattore nucleare, senza nessuna congestione e con forti garanzie su loss, ordering e timing).\nVariable bit rate, come il video, perch√© ha bisongo di un sacchissimo di informazioni, un byte per un pixel bianco e nero, non si pu√≤ trasmettere tanta roba..\nAltro che non listo\nSlide garanzie Service Models\nThe Router Router architecture ci sono credo molti modi per implementare la funzione di router, in generale in un singolo ciclo di clock ti riescono a far entrare e far uscire il pacchetto, questo sarebbe il router buono\nQuindi possiamo individuare\nPorte di input Un processore di routing che ti indirizza nell uscita giusta Un sistema di switching fabric per poter mandare l\u0026rsquo;informazione nella porta giusta Porte di uscita Slide sistema di routing\nla parte del processore √® molto pi√π utilizzato nella parte di Control Plane\nForwarding Il forwarding tratta delle politiche che il processore di routing dovrebbe utilizzare per capire in quale porta di output ti potrebbe mandare\nDestination based forwarding in cui si va a guardare l\u0026rsquo;indirizzo di arrivo e si decide in questo modo come mandarti.\nVediamo un esempio di questa tipologia di forwarding.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Data Plane/Untitled 3.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Data Plane/Untitled 3\u0026quot;\u0026gt; Da notare che sono degli intervalli in questo caso di esempio, ed √® esattamente come avevamo diviso le subnets in un esercizio passato, in Livello di Rete.\nQuesto √® il pi√π usato, √® il longest prefix match. Questo √® bello perch√© si possono indirizzare nelle (TCAMs Ternary content addressable memories, CISCO ha inventato sta tecnologia ed √® la pi√π forte sul mercato attualmente) che praticamente ti trova in singolo ciclo di clock quello corretto.\nL‚Äôalgoritmo normale per trovare l\u0026rsquo;indirizzo corretto, sarebbe comunque fatto in $O(n)$, ma se l‚Äôhardware riesce a fare in parallelo con tutte le tabelle in un singolo ciclo di clock allora ho un $O(1)$, quindi ez.\nGeneralized forwarding Software defined networking\nGeneralizzato perch√© √® indipendente dal router che facciamo perch√© √® tutto gestito da un controller centralizzato.\nOgni router ha una flow table, la stessa cosa di cui si parla nei IPv6 in Livello di Rete#Datagramma IPv6 . Questa tabella √® costruita col routing plane centralizzato, descritta dal software. Importante che tutta la rete sia SDN, senn√≤ non funziona questo.\nOpen Flow Slide flow table\nAbbiamo certe regole di gestione del pacchetto che si basa tu match-action. Se c‚Äô√® un match sugli header del pacchetto, allora faccio una azione su quel pacchetto. (come drop, forward, modify) e ci permette di fare molta roba, come le IP tables, o il NAT. Il router ora pu√≤ assumere molt funzioni diverse.\nAbbiamo anche una priority, mentre nella destination based √® solamente longest prefix.\nSwitching fabrics Questi switching fabrics lo fanno andare molto molto infretta La prima √® una memoria, ma √® molto lento perch√© ha bisogno di due copie di memoria. Ognuno pu√≤ avere un bus condiviso, si sceglie a livello del sender il bus di arrivo, ma posso far passare solamente un bus alla volta, quindi posso avere un singolo alla volta che passa. La cosa migliore √® la TRANSFER SWITCH. Cos√¨ posso far passare in parallelo dei pacchetti, per√≤ √® la cosa pi√π complessa, per√≤ √® anche la cosa pi√π efficiente, perch√© non devo n√© copiare, n√© avere collisioni sul bus Ritardi possibili Input Queuing Quando due pacchetti di entrata devono andare sulla stessa uscita. Head of the line blocking, quando ci sono pi√π pacchetti che stanno aspettando, quello avanti √® bloccato, ma quello dietro potrebbe andare. Slide input queuing\nOutput queuing Ho due cose buffering ossia quanto velocemente la switching fabric copia sui bus di uscita e scheduling che determina l\u0026rsquo;ordine di invio credo.\nPer decidere la quantit√† di buffering voluta per avere un certo bandwitdth √® in slide (una formula precisa): buffering delle uscite meno radice quadrata di quelle di ientrate.\nSe il buffer di uscita diventa pieno, allora comincio a perdere i pacchetti! Posso perderlo secondo certe politiche:\nL\u0026rsquo;ultimo che arriva Cade uno a caso Cado quello con meno priorit√† (per fare questo devi fare hardware diverso perch√© non basta un semplice hardware). Scheduling dei routers Ci sono certi algoritmi di scheduling banali, come il First Come First served, e poi droppo tutti quelli che stanno fuori, oppure farli droppare a caso.\nPriority scheduling in pratica ho un classificatore, che dice se √® di priorit√† o meno. Poi per mandare guardo se c\u0026rsquo;√® qualcosa di priorit√† maggiore, se √® vuoto provo a mandare quelli minori. Ma questo pu√≤ generare starvation.\nRound robin scheduling Questo non fa starvation.\nIn pratica provo uno per classe ad ogni ciclo.\nWeighted fair queuing Tipo se ho massima priority, ne mando 4, se sono nella seconda ne mano 2, se sono nella terza ne mando 1, quindi esiste ancora la priority e non ho starvation perch√© anche nella coda brutta riesco sempre ad andare avanti.\nSul pacchetto IP Livello di Rete#Indirizzo IP\n","permalink":"https://flecart.github.io/notes/data-plane/","summary":"\u003ch2 id=\"introduzione-data-or-control-plane\"\u003eIntroduzione Data or Control plane\u003c/h2\u003e\n\u003cp\u003ecome fanno i router a fare forwarding dei pacchetti? e decidere come mandare? Come fanno a passare. Sono le tabelle di instradamento. Si pu√≤ dire di \u003cstrong\u003eend-to-end\u003c/strong\u003e perch√© solamente il sender e receiver andranno a livello applicazione, e leggeranno le cose (se criptato veramente solo loro riescono a fare questo).\u003c/p\u003e\n\u003ch3 id=\"funzioni-principali\"\u003eFunzioni principali\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eForwarding\u003c/strong\u003e che in pratica √® passare il pacchetto al successivo, √® parte del data plane.\u003c/p\u003e","title":"Data Plane"},{"content":"Introduzione al design logico Conoscenze sul carico dell\u0026rsquo;applicazione, ossia se ha pi√π read rispetto a writes per esempio, sono dei priors in pratica Un design concettuale spiegato in precedenza. E si avr√† in output un design logico con anche un po\u0026rsquo; di documentazione. bisogna in questa fase valutare la performance principalmente su indicatori, ossia una operazione quante istanze visiter√†? Invece di garanzie sul numero di transazioni al secondo.\nIndicatori visti (2) Costo di una operazione: viene valutato in termini di numero di occorrenze di entit√† e associazioni che mediamente vanno visitate per rispondere a una operazione sulla base d√¨ dati; questa schematizzazione √® molto forte e, pur nelle semplici valutazioni che svilupperemo, sar√† talvolta necessario riferirci a un criterio pi√π fine; Occupazione di memoria: viene valutato in termini dello spazio di memoria (misurato per esempio in numero di byte) necessario per memorizzare i dati descritti dallo schema.\nI volumi sono un concetto importante, sono una stima di quante entries dovranno avere, e serve per avere una idea di come progettare quella cosa. Bisogna utilizzare questi indicatori per valutare in che modo progettare la ristrutturazione e la logica.\nNOTA: C\u0026rsquo;√® un modo molto pi√π complicato per fare questa analisi, ma per questo corso √® ok valutare solo queste.\nMetodi di ristrutturazione E-R Redundancies analysis Per la ridondanza bisogna fare una analisi di efficienza per capire se √® buono o meno lasciare la ridondanza.\nTipologie di ridondanze (4) üü®+ Per il prof √® importante due cose:\nAttributi derivabili\nAssociazioni derivabili\nAttributi derivabili da cose della stessa entit√†\nAttributi derivabili da altri\nattributi derivabili da conteggio\nAssociazioni derivabili dalla composizione di altre associazioni in presenza di cicli\nEsempi: Nell\u0026rsquo;ultimo esempio, basta fare la join per avere quella informazione, un ciclo implica una ridondanza in pratica.\nGeneralizations deletion We need to delete the generalizations because in ER explained in Design del database the generalizations are not possible. A common way to fix this is embed children in the parent or something very similar.\nExample of deletion of generalization (3) üü©- In un caso abbiamo che il genitore prende tutti i campi. Oppure elimina il genitore e metti due relazioni Oppure crea relazioni col genitore Ma come fare a scegliere la versione corretta? Vogliamo prendere la soluzione che ci permette di minimizzare il numero di accessi, come per esempio se sappiamo che figli e genitori vengono acceduti insieme, ha senso usare la freccia in basso a sinistra! Partitioning or grouping of entities Se una stessa entit√† ha due attributi molto diverti, ossia c\u0026rsquo;√® solamente un accesso per uno, invece che per tutti, potrebbe avere senso dividerli. In modo simile se ho due entit√† che vengono spesso accedute assieme potrebbe essere una cosa sensata accorparli assieme.\nL\u0026rsquo;obiettivo √® sempre efficienza degli accessi.\nPartizionamento verticale o orizzontale üü©- Possiamo fare partizionamento in verticale o in orizzontale Verticale quando spezziamo una entit√† in due e le relazioniamo (utile quando accediamo solamente certe cose della tavola).\nOrizzontale quando ad esempio provo a dividere correnti e passati (dividere la stessa relazione in pi√π forme!). ### Identifying the primary keys (non fare) Questo passo √® chiaramente il passo necessario per utilizzare E-R nel nostro caso. Informazioni necessarie Le chiavi primarie in certi contesti possono essere complessi! E anche utili per identificare, non ho capito bene l\u0026rsquo;esempio del ferramenta fatto in classe (una nota √® che i ferramenta si fanno codici enormi e complessi come chiavi ed √® una brutta pratica probabilmente). Notare che saranno usate spesso, quindi non farle grosseeee! La cosa semplice √® creare codici identificativi, invece di avere chiavi complesse.\nTraduzione in schema logico Tradurre relazioni üü© Questa tabella riassume praticamente tutto. (303 Atzeni) La singola relazione üü© Una volta che abbiamo una relazione in E-R possiamo creare una tavola anche per questa parte! L\u0026rsquo;importante quando facciamo questo, bisogna encodare una referential integrity constraint che √® la cosa bella della tabella.\nLa nota √® che aggiungere la constraint non √® sufficiente per tenere in considerazione vincoli di cardinalit√†. Anche se √® n-aria si pu√≤ modellizzare senza troppi problemi!\n#### Relazioni ricorsive üü© La seconda tabella modella la parte ricorsiva (in teoria le due chiavi foreign dovrebbero essere code e code, ma il nome √® migliore in questo modo per esprimere questa relazione) Merge di relazioni A volte pu√≤ essere utile unire relazione con l\u0026rsquo;entit√†, succede spesso per relazioni unarie da una parte, perch√© cos√¨ faccio enforcing del 1. √à una cosa principalmente pratica, di difficile formalizzazione, ma deve passare l\u0026rsquo;idea diciamo.\n","permalink":"https://flecart.github.io/notes/database-logical-design/","summary":"\u003ch3 id=\"introduzione-al-design-logico\"\u003eIntroduzione al design logico\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eConoscenze sul carico dell\u0026rsquo;applicazione, ossia se ha pi√π read rispetto a writes per esempio, sono dei priors in pratica\u003c/li\u003e\n\u003cli\u003eUn design concettuale spiegato in precedenza.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eE si avr√† in output un design logico con anche un po\u0026rsquo; di documentazione.\n\u003cimg src=\"/images/notes/Database logical design-1700046979267.jpeg\" alt=\"Database logical design-1700046979267\"\u003e\u003c/p\u003e\n\u003cp\u003ebisogna in questa fase \u003cstrong\u003evalutare la performance\u003c/strong\u003e principalmente su \u003cem\u003eindicatori\u003c/em\u003e, ossia una operazione quante istanze visiter√†? Invece di garanzie sul numero di transazioni al secondo.\u003c/p\u003e","title":"Database logical design"},{"content":"Origini di sfocatura \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Immagini/Untitled.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Immagini/Untitled\u0026quot;\u0026gt; Rumore causata da problemi fisici che sono errori di lettura del segnale analogico Questo si indica anche come errore gaussiano bianco e si pu√≤ considerare additivo. Rumore causato dalla digitalizzazione, quindi dalla discretizzazione di essa. Slide formalizzazione errori per sfocatura\nPoint spread function Un unico pixel bianco sembra influenzare il suo ambiente nero, come in immagine\nVorremmo utilizzare delle funzioni ce siano in grado di approssimare questa funzione.\nFunzioni solitamente utilizzate per approssimare e risultati\nConvoluzioni Questa cosa lo avevo gi√† studiato credo per CNN, in AI. La prof lo scrive in modo molto incomprensibile, ma √® la stessa cosa‚Ä¶ Che cosa triste..\nSlides\nRicostruzione immagini Ossia cerco di identificare le cause del blur, e da quello provo a tornare indietro\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Immagini/Untitled 7.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Immagini/Untitled 7\u0026quot;\u0026gt; Da tenere in mente il fatto che A √® mal condizionata!. Vogliamo quindi introdurre alcuni metodi di regolarizzazione in modo da far diventare pi√π gestibile questo problema. (quindi vorremmo avere una matrice equivalente che sia pi√π gestibile).\nTODO: vedere perch√© minimi quadrati √® mal condizionato.\nRegolarizzazione Andiamo ad utilizzare un funzionale di regolarizzazione con un parametro che mi indica quanto √® influenza la funzione finale.\nRegolarizzazione Tiknohov e Morozov Slide riassuntiva\nDi solito come funzione phi di x metto l‚Äôidentit√† e come lambda un valore che scelgo provando tante cose e prendendo alla fine il pi√π grande che mi soddisfa\ne √® l‚Äôerrore causato dal blur\nSi pu√≤ saltare la regolarizzazione con le altre norme üíÄ perch√© alla prof non piace, saddo.\nPeak signal to Noise Ratio Quanto pi√π il valore √® alto pi√π l‚Äôimmagine √® buona, questo √® un buon parametro per valutare che la funzione di approssimazione sia buona.\n","permalink":"https://flecart.github.io/notes/deblur-di-immagini/","summary":"\u003ch3 id=\"origini-di-sfocatura\"\u003eOrigini di sfocatura\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Immagini/Untitled.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Immagini/Untitled\u0026quot;\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003col\u003e\n\u003cli\u003eRumore causata da problemi fisici che sono \u003cstrong\u003eerrori di lettura\u003c/strong\u003e del segnale analogico Questo si indica anche come errore gaussiano bianco e si pu√≤ considerare \u003cem\u003eadditivo\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eRumore causato dalla digitalizzazione, quindi dalla discretizzazione di essa.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide formalizzazione errori per sfocatura\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Immagini/Untitled 1.png\" alt=\"image/universita/ex-notion/Immagini/Untitled 1\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"point-spread-function\"\u003ePoint spread function\u003c/h3\u003e\n\u003cp\u003eUn unico pixel bianco sembra influenzare il suo ambiente nero, come in immagine\u003c/p\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Immagini/Untitled 2.png\" alt=\"image/universita/ex-notion/Immagini/Untitled 2\"\u003e\n\u003cp\u003eVorremmo utilizzare delle funzioni ce siano in grado di approssimare questa funzione.\u003c/p\u003e","title":"Deblur di immagini"},{"content":"La deduzione naturale √® un possibile sistema deduttivo che utilizza il linguaggio naturale per questo motivo pi√π beginner friendly. Lo facciamo prima per la Logica Proposizionale che √® molto facile\nIl sistema deduttivo Poniamo l\u0026rsquo;esistenza di Assiomi (formule in una certa logica) e regole di inferenza definite sotto. Esempi sono $P \\vdash \\varphi$ se $\\varphi$ √® un assioma. O altre cose simili con $\\land$ e simili\u0026hellip;\nUna dimostrazione allora √® una sequenza di $\\varphi_{1}, \\dots, \\varphi_{n}$ dove $\\varphi_{i}$ √® derivata con le regole di inferenza e $\\varphi_{1}, \\dots, \\varphi_{i - 1}$.\nLa differenza con la deduzione naturale √® che solitamente non ci sono assiomi\nSintassi Caratteristiche della sintassi (4) Si utilizza una BNF bidimensionale per rappresentare la ramificazione di una dimostrazione in deduzione naturale (cos√¨ possiamo capire bene in quale parte del ramo viene utilizzata l\u0026rsquo;ipotesi).\nRadice √® la conclusione, anche indicata come top. Nodi sono rappresentate da alcune formule Le foglie sono formule scaricate (con parentesi quadre), queste sono ipotesi locali che valgono solo in quel ramo (come l\u0026rsquo;analisi per l\u0026rsquo;or). Le foglie non scaricate rappresentano le ipotesi del problema La ricorsivit√† Come caratteristica delle BNF io opero in modo ricorsivo su sotto-alberi pi√π semplici.\nPer ogni albero utilizzo delle regole di eliminazione o di introduzione per collegare gli alberi insieme, ecco che utilizzo le regole di introduzione ed eliminazione per collegare le regole fra di loro e cos√¨ faccio la verifica di correttezza della dimostrazione.\nRegole di inferenza Sintassi delle regole di inferenza Doppia lettura (top-down, bottom up)!\nDove al corrispondente del numeratore si hanno le ipotesi necessarie (che nel caso siano 0 si dicono assioma, in modo differente rispetto all\u0026rsquo;utilizzo finora)\nFormula di $\\Gamma$ sono chiamati assioni Regole senza ipotesi sono assiomi Quindi questa definizione di assioma pu√≤ avere pi√π denotazioni, (ambigua?) no! perch√© √® un insieme pi√π grande che comprende entrambe le possibilit√†.\nDevo dimostrare anche la verit√† di quelle ipotesi, posso allargare l\u0026rsquo;albero sopra!\nIn modo pi√π generale\nRegole di introduzione ed elimitazione Queste regole sono state per la prima volta utilizzate in Teoria assiomatica degli insiemi per i primi esercizi.\nCome faccio a concludere qualcosa sapendo qualcosa?\nCosa viene ricavata da una conoscenza?\nRegole Bottom up e top down Di solito le dimostrazioni sono presentate come bottom up, perch√© √® considerato pi√π elegante, ma di solito si lavora sulla conclusione nel caso di troppe ipotesi (due letture per BNF)\nCorrettezza di una regola Poi si potr√† dimostrare che si avr√† conseguenza logica per regole assemblate fra di loro. (ipotesi scaricate, devono essere rappresentate con un implica, ricorda che scaricate vuol dire che hanno ipotesi locali).\nInvertibilit√† di una regola Motivo: Ci permette di dire che le regole che stiamo dimostrando saranno poi ancora conseguenze logiche per la nostra tesi finale.\nNon scegliere regole non invertibili se posso ancora utilizzare una regola invertibile Valutare intuitivamente la \u0026ldquo;pericolosit√†\u0026rdquo; di questa regola. (come se fosse un se solo se) (equivalenza logica fra tante formule, mentre di solito √® una formula sola); Dimostrazione correttezza e invertibilit√† di regole classiche 7.3.1 AND ‚àß L\u0026rsquo;AND intro- corretta e invertibile.(per invertibilit√†, devo espandere secondo le regole della semantica).\n$$ \\dfrac{A \\,\\,\\, B }{A\\wedge B} $$Quindi la dimostrazione della regola di introduzione dell\u0026rsquo;and √® vera, posso sempre spezzare quando mi pare.\nDimostrazione\nAND elim - La regola di eliminazione ci permette di utilizzare una ipotesi a scelta collegate con il connettivo dell\u0026rsquo;and\nRegola di eliminazione classica\nDimostrazione\nNon invertibilit√†\nFormula di eliminazione pi√π generale\nDimostrazione\nRicorda associativit√† a destra di $\\implies$\nNon invertibilit√† parziale\nMa si pu√≤ vedere che non sia invertibile\n7.3.2 OR ‚à® Introduzione\nEnunciato\nCorrettezza\nNon invertibilit√†\nPerch√© √® invertibile in un caso, e non nell\u0026rsquo;altro utilizzando le regole di eliminazione dell\u0026rsquo;OR ma non √® ancora conseguenza logica)\nQuesta regola non √® invertibile! Spesso non va bene utilizzarlo.\nEsempio non-invertibilit√†.\nConsideriamo l\u0026rsquo;opzione $A \\vee \\neg A$ , quest √® conseguenza logica in tutti mondi, la dimostrazione √® molto semplice. quindi $\\Vdash A \\vee \\neg A$\nPer√≤ A / quello di sopra, non √® vero in tutti i mondi, quindi possiamo dire che le due non sono equivalenti, quindi non √® invertibile.\nQuindi $\\not\\Vdash A$ e $\\not \\Vdash \\neg A$.\nLa best practice √® utilizzare le ipotesi, e la top down non vale sempre, bisogna avere pi√π ipotesi\u0026hellip;.\nEliminazione\nIn generale mi devo ridurre a ragionare nei mondi in cui solamente F1 o F2 valgono (un mondo pi√π particolare), e poi ricompongo per dimostrare F3.\nperch√© √® possibile restringersi su un mondo particolare prima di analizzarli? Perch√© alla fin fine li sto analizzando tutti, ma in tempi (o rami diversi)\n√à una regola molto molto invertibile, quindi √® da utilizzare subito!\nEnunciato\nCorrettezza\nInvertibilit√† simile a AND\n7.3.3 Bottom e Top Bottom\nEnunciato\nSi pu√≤ notare che c\u0026rsquo;√® l\u0026rsquo;armonia anche qua, non c\u0026rsquo;√® nessun caso di introduzione e quindi non ho ipotesi nell\u0026rsquo;eliminazione.\nQuesta non √® una regola invertibile, ossia non √® vero che $F \\Vdash \\bot$ perch√© bot √® sempre falso.\nTop\nIl Top √® un assioma, unico assioma in questa sintassi in quanto non ho bisogno di ipotesi per dimostrarlo. (Notare che non √® una foglia).\nEnunciato\nL\u0026rsquo;eliminazione del top √® inutile, perch√© √® gi√† insita l\u0026rsquo;ipotesi in un altro, per√≤ puoi notare che √® invertibile. infatti $F \\Vdash \\top$\n7.3.4 Implicazione materiale Introduzione\nQuesta regola √® molto forte, sia corretta sia invertibile, perch√© la dimostrazione possiede sia LHS sia RHS le stesse cose quasi\nEnunciato\nDimostrazione invertibilit√† e correttezza\n$F_1 \\implies F_2 \\Vdash F_1 \\implies F_2$ ovvia\u0026hellip;.\nEliminazione\nLa cosa strana √® che in questo caso devo dimostrare anche l\u0026rsquo;ipotesi.\nEcco che questa non √® invertibile\u0026hellip; √à la cosa che mi rende difficile la dimostrazione perch√© dopo quelle regole invertibili ho queste ipotesi con implicazioni e non √® sempre ovvio.\nEnunciato\nCorrettezza\nNon invertibilit√†\n7.3.5 Negazione Questa √® quello che creer√† la necessit√† di una altra logica, perch√© il not me lo rende complesso..\nSi pu√≤ dire che Non F √® una altra denotazione di questa implicazione: $F \\implies \\bot$ perch√© gli unici casi in cui vale questo √® che le ipotesi siano false.\nIntroduzione\nEnunciato\n$F_1 \\implies \\bot \\Vdash\\neg F_1$\nInvertibilit√†\nMolto simile a quello sopra, riesco a dimostrare l\u0026rsquo;assurdo\nEliminazione\nEnunciato\nQuando riesco a dimostrare l\u0026rsquo;assurdo posso dimostrare qualunque cosa, la teoria √® inconsistente.\nQuesto mi elimina il Not, per√≤ mi rende tutto inconsistente.‚ÄºÔ∏è In questo ramo tutto diventa invertibile! ‚ÄºÔ∏è Diventa solamente un gioco meccanico.\n7.3.6 RAA Reductium ad abdsurdum Questa regola √® molto simile all\u0026rsquo;introduzione del not ed √® necessario per avere la completezza per la deduzione semantica\nEnunciato\nDimostrazione\n7.4 Derivabilit√† Intuitivamente\nQueste regole di derivabilit√† sono molto utili per stabilire l\u0026rsquo;eguaglianza fra regole diverse (quando una √® derivabile dall\u0026rsquo;altra e viceversa..\n7.4.1 Dimostrazione per induzione strutturale Intuitivamente:\nDate due insieme delle regole, posso fare la dimostrazione utilizzando le regole con l\u0026rsquo;altro insieme e la dimostrazione √® uguale.\n!\n7.4.2 Derivabilit√† delle eliminazioni di AND Questo teorema e dimostrazione √® molto utile per stabilire l\u0026rsquo;equaglianza delle due regole, in altre parole ci sta dicendo che le due regole siano identiche.\nEnunciato e dimostrazione\nNOTA: per la seconda parte sto prendendo in esame solamente un sotto-albero di interesse.\n7.5 Armonia delle regole Sembra che il numero delle regole di eliminazione corrisponda con il numero di regole di introduzione per ogni connettivo. (e ognuno viene corrisposto)\nEliminazione ha un caso per ogni caso di introduzione e questa utilizza le regole di introduzione.\nNOTA: questo principio √® molto utile per guidarci nella creazione di regole\n7.5.1 Armonia OR Slide\n7.5.2 Armonia AND Slide\n7.6 Teorema completezza e correttezza meglio in Connettivi Logici, correttezza, variabili\n7.6.1 Correttezza Enunciato\nIl teorema di correttezza stabilisce la correttezza di tutte le regole date\nNotenotenote\nDimostrazioni di conseguenza logica\nDevi fissa il mondo porre coso giutsto e poi utilizzare la semantica del mondo.\n7.7 Deduzione naturale in logica di primo ordine Possiamo estendere la deduzione naturale con alcune regole di $\\forall, \\exists$ qui are la semantica del mondo.\n7.7 Deduzione naturale in logica di primo ordine Possiamo estendere la deduzione naturale con alcune regole di $\\forall, \\exists$ qui\nRegistro Ripassi Vecchi dubbi Come si dimostra la correttezza e l\u0026rsquo;invertibilita di una regola? il concetto di derivabilit√† Perch√© la eliminazione della negazione non √® l\u0026rsquo;introduzione del bottom? il concetto di armonia DA CHIEDERE Ripasso Prox: 15 Ripasso: December 22, 2021 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: November 10, 2021 9:33 AM Stato: üåïüåïüåïüåïüåï Studi Personali: No\n","permalink":"https://flecart.github.io/notes/deduzione-naturale/","summary":"\u003cp\u003eLa deduzione naturale √® un possibile sistema deduttivo che utilizza il linguaggio naturale per questo motivo pi√π beginner friendly. Lo facciamo prima per la \u003ca href=\"/notes/logica-proposizionale/\"\u003eLogica Proposizionale\u003c/a\u003e che √® molto facile\u003c/p\u003e\n\u003ch2 id=\"il-sistema-deduttivo\"\u003eIl sistema deduttivo\u003c/h2\u003e\n\u003cp\u003ePoniamo l\u0026rsquo;esistenza di Assiomi (formule in una certa logica) e \u003ca href=\"/notes/deduzione-naturale/#regole-di-inferenza\"\u003eregole di inferenza\u003c/a\u003e definite sotto.\nEsempi sono $P \\vdash \\varphi$ se $\\varphi$ √® un assioma. O altre cose simili con $\\land$ e simili\u0026hellip;\u003c/p\u003e\n\u003cp\u003eUna \u003cstrong\u003edimostrazione\u003c/strong\u003e allora √® una sequenza di $\\varphi_{1}, \\dots, \\varphi_{n}$ dove $\\varphi_{i}$ √® derivata con le regole di inferenza e $\\varphi_{1}, \\dots, \\varphi_{i - 1}$.\u003c/p\u003e","title":"Deduzione naturale"},{"content":"This set of note is still in TODO\nDependency Grammar has been much bigger in Europe compared to USA, where Chomsky\u0026rsquo;s grammars ruled. One of the main developers of this theory is Lucien Tesni√®re (1959):\n‚ÄúThe sentence is an organized whole, the constituent elements of which are words. Every word that belongs to a sentence ceases by itself to be isolated as in the dictionary. Between the word and its neighbors, the mind perceives connections, the totality of which forms the structure of the sentence. The structural connections establish dependency relations between the words. Each connection in principle unites a superior term and an inferior term. The superior term receives the name governor (head). The inferior term receives the name subordinate (dependent).‚Äù ~Lucien Tesni√®re\nThis grammars defines binary relations between words. These relations are labelled. Dependency parsing is just having a tree representation of these relations. We can view dependency parsing as another way of understanding syntax in language.\nDependency Trees Definitions Let\u0026rsquo;s say all words in a sentences are nodes of a graph, plus a root node. A dependency tree is a directed spanning tree in the graph\nAll non-root nodes have exactly one incoming edge No cycles Only 1 outgoing edge from the root Types of Dependency Trees We have two main kinds of trees\nNon-projective dependency trees: when they have some overlapping arcs, then it\u0026rsquo;s a non-projective dependency tree Projective dependency trees. they do not have overlapping arcs. From Parse Trees to Dependency Trees We covered parse trees in Probabilistic Parsing. There is a way to convert parse trees into dependency trees in a quick manner: Collin\u0026rsquo;s head rules\nCollin\u0026rsquo;s head rules See here. Usually when we have a parse tree, only one relation is linguistically plasible. Collin\u0026rsquo;s head rules just describe which one is plausible. For example, if we have adjective and noun, usually the noun is the head of the noun phrase.\n(Image from Course Slides, NLP ETH2024) On the left we have a standard constituency tree, on the right, we have every non terminal labelled using Collin's head rules. Constituency trees are Projective Dependency Trees The title of this section quickly follows from the fact that syntactic constituents are contiguous, which implies we won\u0026rsquo;t have any crossings (somehow, I did not clearly understood this). So, if we have a projective dependency tree, we can easily build a probabilistic model for it following the machinery built in the previous chapter, in Probabilistic Parsing (CKY and similar dynamic programming based algorithms). Next, we will consider how we can build models for non-projective dependency trees.\nDeconding Dependency Trees We would like to find the most probable dependency tree among all the possible graphs we could have. This is a daunting task because the possible tree we could have is exponential, in the order of $\\mathcal{O}(N^{N})$ where $N$ is the length of our sentence.\nKirchhoff\u0026rsquo;s Matrix-Tree Theorem In this section we explore methods to compute the probability distribution over non-projective dependency trees.\nCounting spanning trees Given a Degree Matrix $D$ and the adjacency matrix $A$, we build the Laplacian Matrix $L = D - A$. We can compute the number of spanning trees of a graph by computing the determinant of the Laplacian Matrix. Remember that the determinant is computable in $\\mathcal{O}(n^{3})$ time, so we can find the count in this amount of time.\nExtending to root nodes This is a contribution from Koo 2007. We modify the Laplacian Matrix to include the root node. TODO. The weird thing is that we just need to substitute the first row with the scores of the roots. And it will work. In the paper there are the details of the equivalency. A good thing would be spending one hour actually undersanding why the determinant of the following matrix does the job\n$$ L_{ij} = \\begin{cases} \\rho_{j} \u0026amp; \\text{if } i = 1 \\\nD_{ij} \u0026amp; \\text{if } i \\neq j \\ \\sum_{i\u0026rsquo; = 1, i\u0026rsquo; \\neq j}^{N} D_{i\u0026rsquo;j} \u0026amp; \\text{if } i = j \\end{cases} $$ There $D_{ij}$ is the score of the edge between $i$ and $j$, and $\\rho_{j}$ is the score of the edge between the root and $j$. Chu-Liu-Edmonds Algorithm See this resource, it is well made and has also an implementation in python with some visualizations.\n","permalink":"https://flecart.github.io/notes/dependency-parsing/","summary":"\u003cp\u003eThis set of note is still in TODO\u003c/p\u003e\n\u003cp\u003eDependency Grammar has been much bigger in Europe compared to USA, where Chomsky\u0026rsquo;s grammars ruled. One of the main developers of this theory is Lucien Tesni√®re (1959):\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e‚ÄúThe sentence is an organized whole, the constituent elements of which are words. Every word that\nbelongs to a sentence ceases by itself to be isolated as in the dictionary. Between the word and its neighbors, the mind perceives connections, the totality of which forms the structure of the sentence.\nThe structural connections establish dependency relations between the words. Each connection in principle unites a superior term and an inferior term. The superior term receives the name governor (head). The inferior term receives the name subordinate (dependent).‚Äù ~\u003cem\u003eLucien Tesni√®re\u003c/em\u003e\u003c/p\u003e","title":"Dependency Parsing"},{"content":"Geometria introduttiva Tangente e pendenza Si pu√≤ trovare la relazione fra la pendenza della retta e la tangente.\nPossiamo analizzare la retta dal punto di vista analitico, della formula e si pu√≤ dimostrare che data una retta nella forma $y = mx + q$ $m$ √® la pendenza della retta.\nFormula generale delle rette Dati qualunque due punti .$(x_1, y_1), (x_2, y_2)$ possiamo dire che la pendenza √® esprimibile come\n$\\dfrac{ (y_2 - y_1)}{(x_2 - x_1)}$, possiamo anche creare un fascio di rette che passa per un punto come\n$y - y_0 = m(x - x_0) + q$\nIntuizione tangente Per qualunque funzione, possiamo intuitivamente designare la derivata come se fosse il valore della retta tangente in quel punto al grafico.\nDefinizione Rapporto incrementale Data una funzione $f(x)$, si dice rapporto incrementale di $f$ in $x_0$ questo valore\n$$ \\dfrac{f(x) - f(x_0)}{x - x_0} $$Derivabilit√† Allora cerchiamo di minimizzare la distanza fra i due punti che scelgo, allora ho la derivata in questo punto!\n$$ \\exists\\lim_{x \\to x_0} \\dfrac{f(x) - f(x_0)}{x - x_0} \\in \\mathbb{R} = \\dfrac{df(x)}{dx} $$E si pu√≤ scrivere anche in una altra forma analoga: che √® pi√π comoda da gestire perch√© ho qualcosa che tende a 0\n$$ \\exists\\lim_{h \\to 0} \\dfrac{f(x + h) - f(x)}{h} = \\dfrac{df(x)}{dx} $$Se esiste questo limite, allora la funzione √® derivabile in quel punto.\nFunzione Si dice che una funzione √® derivabile se lo √® nel suo dominio. (Per gli estremi destri si considera solamente la derivabilit√† sinistra, in modo simile anche per gli estremi sinistri) Se esiste la derivata in questo punto allora si pu√≤ dire che in questo punto esista una tangente geometrica\nDerivabilit√† destra e sinistra Si dice che una funzione $f$ √® derivabile a sinistra (in modo analogo a destra se\n$$ \\exists\\lim_{x \\to x_0^-} \\dfrac{f(x) - f(x_0)}{x - x_0} = \\dfrac{df(x)}{dx} $$Condizioni di derivabilit√† Dato che la derivata √® un limite, le condizioni di esistenza sono molto simili alle condizioni di esistenza di un limite.\nSi pu√≤ analizzare la derivabilit√† delle funzioni utilizzando queste condizioni es:\n$f(x) = |x|$ si scopre che non √® derivabile perch√© a sinistra √® -1 mentre a destra √® +1, si dice che √® un punto angoloso (si scopre che per qualunque punto angoloso, questa non √® pi√π derivabile)\nBisogna fare per√≤ attenzione perch√© non √® vero che ogni valore assoluto non √® derivabile perch√© ad esempio $x|x|$ √® derivabile.\nPropriet√† e osservazioni Proposizione della retta tangente Questa proposizione collega il concetto di derivata e della tangente.\nSe $f$ √® derivabile in $x_0 \\in I \\implies \\exists \\text{retta tangente al grafico f in } x_0=x\\\\ \\text{si pu√≤ dire che abbia equazione} \\\\ y = f'(x_0)(x - x_0) + f(x_0)$\nDerivate note Algebra delle derivate Si possono utilizzare in modo simile l\u0026rsquo;algebra delle derivate\nDerivazione qui\nComposizione di funzioni Dimostrazione [qui](https://www.math-linux.com/mathematics/derivative-of-a-function/article/chain-rule-proof-derivative-of-a-composite-function#:~:text=Derivative%20of%20composite%20function%20(g,%C3%97%20v\u0026rsquo;(x)%20.)\nContinuit√† e derivabilit√† Si pu√≤ dimostrare che se una funzione √® derivabile in un punto allora √® continua nel punto stesso.\nx punto di accumulazione\n$$ \\lim_{h \\to 0}\\dfrac{f(x+h) - f(x)}{h} = l \\iff \\lim_{h \\to 0}\\dfrac{1}{h}\\cdot(\\lim_{h \\to 0}f(x+h) - f(x)) = l\\\\ \\iff \\lim_{h \\to 0}f(x+h) = f(x) + l\\lim_{h \\to 0}h = f(x) $$C\u0026rsquo;√® anche una cosa dimostrazione molto simile.\nDimostrazione del prof.\nDerivate di inverse Enunciato\nDerivate di ordine superiori Una funzione potrebbe essere derivabile pi√π di una volta, allora si dice che si pu√≤ derivare pi√π volte.\n√à interessante relazionare questo concetto di derivabilit√† con il concetto di continuit√†\nContinuit√† classe C √à come classificare una funzione in base la sua regolarit√†, ossia rispetto a quante volte posso fare la derivata e la continut√† di classe C √® un buon modo di formalizzare questo dato.\nContinuit√† di classe C\n!\nSi pu√≤ notare che una funzione pu√≤ essere continua in $C^k$ ma non in $C^{k+1}$. zare questo dato.\nContinuit√† di classe C\n!\nSi pu√≤ notare che una funzione pu√≤ essere continua in $C^k$ ma non in $C^{k+1}$.\n","permalink":"https://flecart.github.io/notes/derivate/","summary":"\u003ch2 id=\"geometria-introduttiva\"\u003eGeometria introduttiva\u003c/h2\u003e\n\u003ch3 id=\"tangente-e-pendenza\"\u003eTangente e pendenza\u003c/h3\u003e\n\u003cp\u003eSi pu√≤ trovare la relazione fra la pendenza della retta e la tangente.\u003c/p\u003e\n\u003cp\u003ePossiamo analizzare la retta dal punto di vista analitico, della formula e si pu√≤ dimostrare che data una retta nella forma $y = mx + q$ $m$ √® la pendenza della retta.\u003c/p\u003e\n\u003ch3 id=\"formula-generale-delle-rette\"\u003eFormula generale delle rette\u003c/h3\u003e\n\u003cp\u003eDati qualunque due punti .$(x_1, y_1), (x_2, y_2)$ possiamo dire che la pendenza √® esprimibile come\u003c/p\u003e","title":"Derivate"},{"content":"Introduzione Per questa parte c‚Äô√® un sacco di roba in comune con Tecniche di definizione di semantica (4) üü©\nTrattiamo alcune caratteristiche che descrivono ad alto livello un linguaggio di programmazione. √à da notare che questa parte della spiegazione del linguaggio non √® limitante al solo linguaggio di programmazione, √® utile per analizzare tutti i linguaggi (tranne la parte di implementazione)\nSintassi üü©- Relazione fra segni. si occupa di decidere quando una frase √® corretta.\nAspetto lessicale\nIl lessico per una sintassi descrive le parole legali, In un linguaggio naturale il lessico √® descritto solamente da dizionari. Se un vocabolo non esiste nel lessico di interesse, allora √® erroneo, poi andremo a descrivere questo aspetto in modo formale\nVedere Scanner in appunti dopo\nAspetto grammaticale\nDescrive la descrizione di frasi corrette a partire dal lessico, pu√≤ essere utile in questo passo ricordarsi delle BNF Sintassi e RI strutturali del corso di logica\nPrincipalmente sono delle regole per costruire delle frasi che hanno un senso\nSemantica üü© Ossia riguardo il significato di una frase sintatticamente corretta‚Üí relazione fra segni e significato.\nLinguaggio di appartenenza\nUna stessa parola, a seconda della lingua di interpretazione, pu√≤ avere significati diversi ‚Üí FAME (fama, oppure fame?)\nVoglio utilizzare questo linguaggio per calcolare la semantica di questo linguaggio basandomi su qualcosa che gi√† esiste. (alla fine, per l\u0026rsquo;architettura esistente attuale, saranno sempre 0 e 1 di bits).\nPragmatica üü© Si occupa di studiare in quale modo le frase corrette sono utilizzate. Quindi va a rispondere a domande come ‚ÄúA cosa serve un costrutto?‚Äù, ‚ÄúCome si utilizza il comando‚Äù\nInsieme di regole per dare un indirizzo di uso\nEsempio: stile: non usare goto, scopo: questo comando fa quello e questo quindi usalo per‚Ä¶.\nDato che principalmente la pragmatica non √® presente al momento della creazione del linguaggio ma si evolve con l‚Äôuso di esso, non √® molto interessante da questo punto di vista (+ sull\u0026rsquo;ingegneria del software).\nUn altro esempio √® tipo utilizzare lei, invece del tu in contesti formali\nEsiste anche una pragmatica per la semantica Pragmatica\nIl linguaggio eseguibile üü®+ Un linguaggio formale deve soddisfare alcune regole in pi√π rispetto al linguaggio naturale, in particolare ‚Üí l\u0026rsquo;implementazione.\nEseguire una frase sintatticamente corretta in modo semanticamente corretto.\nQuindi si occupa dell\u0026rsquo;implementazione vera e propria del compilatore o dell‚Äôinterprete del linguaggio. (In questo corso si faranno solo cenni, dato che non si implementer√† tale linguaggio).\nLessico e frasi di un linguaggio Alfabeto lessico e frasi üü© Definiamo ora alcune parole fondamentali per poter parlare di linguaggi in modo formale:\nAlfabeto: a non-empty set of symbols/glyphs, typically thought of as representing letters, characters, or digits. (tipicamente finito, ma pu√≤ essere anche infinito)\nLessico: un insieme di parole finite formate da lettere dell\u0026rsquo;alfabeto che consideriamo validi\nFrasi: seguenze finite (o countably infinite, non vale per il lessico CREDO) di parole del lessico\nIl linguaggio formale üü© Sia $A$ il nostro alfabeto, e $A^0 = \\{ \\varepsilon \\}$, e $A^{n + 1} = A \\cdot A^n$ con dot un operazione di concatenazione, allora L √® un sottoinsieme solitamente finito di tutte le parole su $A$, ossia\n$L \\subseteq A^*$, $A^* = \\bigcup_{n \\geq 0}A^n$. Questo insieme si pu√≤ creare con un insieme di regole, ma anche come elenco √® corretto.\nEsempi di linguaggi\nNumerabilit√† per alfabeti Si pu√≤ dimostrare che $A^*$ formato da alfabeti infiniti √® ancora un infinito numerabile, si utilizza un argomento simile a Cantor spiegato in R e Intervalli e in Relazioni fra insiemi.\nDimostrazione numerabilit√† di A-star Questo dimostra che ogni unione di insiemi numerabili √® numerabile. C\u0026rsquo;√® una altra dimostrazione molto pi√π semplice rispetto a questa costruzione di funzioni.\nPraticamente numeriamo l\u0026rsquo;alfabeto finito che abbiamo, in ordine $\\sigma_{1} \\sigma_{2}, \\dots, \\sigma_{n}$ Allora questi hanno valore $1, \\dots, n$, poi per le stringhe nella forma $\\sigma_{1}\\sigma_{2}, \\sigma_{1}\\sigma_{3}, \\dots \\sigma_{n}\\sigma_{n}$ li metto anche ora in ordine di indice e inizio a contare da $n + 1$ e cos√¨ via. Cos√¨ so che ogni singola stringa del linguaggio ha un intero associato e posso dire che $A^{*}$ √® numerabile.\nDefinizioni operazioni di base (6) üü© Lunghezza\nViene definita in modo ricorsiva in questo modo:\nSlide\nConcatenazione\nSlide\nDeve soddisfare principalmente 3 propriet√†\nLa lunghezza della stringa risultante √® uguale alla somma della lunghezza delle singole stringhe prima parte della stringa risultato √® uguale alla prima stringa seconda parte della stringa risultato √® uguale alla seconda stringa Sottostringa, suffisso e prefisso\nSlide\n√à abbastanza banale dai, credo (in pratica posso prendere v in mezzo alla stringa di partenza mettendoci qualcosa prima e dopo\nPotenza n-esima\nSlide\nOssia provo a concatenera s√© stesso pi√π volte\nOperazioni di base su linguaggi (6) üü© Complemento\nUnione\nIntersezione\nConcatenazione\nQuesto √® la concatenazione a livello linguaggio, mentre prima era la concatenazione a livello stringa\nPotenza\nChiusura / stella di Kleene / Ripetizione\nRappresentazione del linguaggio (2) üü©- Generativo - sintetico\nNon posso rappresentare un alfabeto infinito di caratteri! Ma posso memorizzare le regole che la generano. Per esempio posso memorizzare i numeri naturali con solamente gli assiomi di peano (in particolare mi bastano 2 delle 5 regole di peano\nRiconoscimento - analitico\nSono le stringhe che vengono riconosciute da un automa che vedremo in seguito.\nMa non tutti i linguaggi sono riconoscibili da AUTOMI, resta il finito contabile come limite massimo, il motivo per cui √® questo √® perch√© le grammatiche sono equipotenti a $\\N$, mentre tutti i linguaggi sono sottoinsieme di $\\R$ e quindi non riesco a detectarlo.\nSlide grandezza di grammatiche ed alfabeti\nGrammatiche e BNF Def grammatica libera (4) üü© √à una quadrupla di\nNon terminali (insieme finito, indicato di lettere maiuscole) Terminali (insieme finito, indicato da lettere minuscole) Simbolo iniziale (simbolo speciale non terminale) Produzioni (ricorda qui che la grammatica libera si pu√≤ rappresentare con questa) Questa viene descritta in mood pi√π formale in Linguaggi liberi e PDA. Backus Naur-Form üü© In questa sezione cerchiamo di definire in modo pi√π dettagliato le BNF introdotte nella lezione di logica di Sintassi e RI strutturali trattati in logica.\nSlide esempio di una BNF per palindromi\nStesso precedente, ma scritto tramite la sintassi delle grammatiche\nDefinizione tramite assiomi\nDefinizione in via ricorsiva\nIndichiamo con $L(P)$ il linguaggio generabile a partire da un P, con le regole di inferenza di sopra\nL‚Äôunica differenza con le grammatiche libere √® la sintassi differente per la descrizione di essa (utilizzo delle \u0026lt;\u0026gt;), ma storicamente credo che si siano evolute in modo distinto, e poi si sono accorti che erano la stessa cosa\nDerivazioni (leftmost e rightmost) üü©‚Äî Definizione di derivazione immediata\nSia $G = (NT, T, R, S)$ una grammatica libera da contesto, si dice che $v$ deriva immediatamente da $w$, indicato con $w \\implies v$, quando $\\exists (A \\to z) \\in R$, con $R$ le produzioni e $A \\to z$ una produzione, e $w = xAy$, e $v = xzy$\nIn altre parole posso dire che una stringa √® derivata in modo immediato da una altra stringa quando posso ricavarla con una singola operazione di una funzione presente in produzione.\nSlide definizione derivazione immediata\nDefinizione derivazione ‚Äúgenerale‚Äù\nPosso affermare che da $v$ si deriva $w$ quando esiste una sequenza finita (anche vuota) di derivazioni immediate tali che\n$$ v \\implies w_0 \\implies ... \\implies w $$Tale cosa √® riscritta come $v \\Rightarrow^* w$\nSlide Definizione di Derivazione generale (!!!)\nDerivazione left e rightmost\nConcetto di derivazione left e right most\nIl concetto pi√π generale √® che nel processo di derivazione di una stringa in un linguaggio viene sempre espanso il non terminale pi√π a sinistra.\nCheck appartenenza\nSi pu√≤ verificare che una stringa appartiene a un certo linguaggio descritto in modo formale come sopra se si pu√≤ creare un albero di derivazione\nEsempio di derivazione\nLinguaggio generato da grammatica üü© Data una grammatica $G = (NT, T, R, S)$ a contesto libero definiamo il linguaggio libero $L(G)$ generato dalla grammatica come\n$$ L(G) = \\{ w \\in T^* : S \\Rightarrow ^* w\\} $$Ossia in parole umane, tutte le stringhe terminali generabili da quella grammatica.\nSlide definizione\nAlberi di derivazione Un albero di derivazione √® una rappresentazione molto utile per un compilatore per comprendere la struttura interna intermedia. fornisce informazioni semantiche!\nDefinizione albero di derivazione (5) + 1 üü®+ presenta alcune propriet√† dell‚Äôalbero, che √® invariante rispetto all‚Äôalbero, questa osservazione ci d√† anche un hint per la definizione del concetto di ambiguit√† per grammatiche e linguaggi.\nUna altra osservazione importante √® che possiamo associare un albero di derivazione a ogni Derivazione.\nDefinizione albero di derivazione (5) + 1 üü®+ Vogliamo descrivere la struttura di un albero di derivazione generale\nLa radice √® il non-terminale iniziale ossia $S$ Tutti i nodi hanno simboli in $NT \\cup T \\cup \\{\\varepsilon \\}$ I nodi interni hanno solo simboli $NT$ Esiste una relazione diretta fra padre e figli definiti da una produzione, pi√π in generale se $A\\in NT$ e $x_1,..., x_n$ sono nodi figli, esiste una produzione $A \\to x_1, ..., x_n$ Se $\\varepsilon$ √® su un nodo, allora quella √® una foglia ed esiste la produzione $A \\to \\varepsilon$, con A l‚Äôetichetta per il parent Inoltre andiamo a chiamare albero di derivazione COMPLETO se ogni foglia √® un terminale.\nSlide\nRelazione con derivazione üü®+ Si pu√≤ dimostrare che una stringa appartiene a un linguaggio, solo se esiste un albero di derivazione per essa in quel linguaggio, quindi √® un buon metodo per descrivere la derivabilit√† in modo non-ambiguo.\nIdee per la bigezione\nChiaramente se vado Derivazione ‚Üí Albero √® una cosa abbastanza ovvia perch√© √® il modo con cui si crea l‚Äôalbero\nSe vado nella direzione Albero ‚Üí Derivazione (dx, sx) sto facendo in pratica una DFS che espande sempre il primo a sinistra o primo a destra di non terminali, e ho anche bisogno di una funzione che sia in grado di restituirmi una stringa data dalle foglie, fatto ci√≤ dovrebbe essere easy.\nAlberi sintattici üü© Quando abbiamo un albero di derivazione completo, possiamo estrarre l‚Äôalbero formato dalle foglie, come in figura, per avere un albero che abbia qualche informazione riguardo la semantica di quanto descritto.\nEsempio estrazione albero sintattico\nAlbero di sintassi concreta o Astratta C‚Äô√® una leggera differenza fra sintassi astratta e concreta.\nDi sotto, durante la risoluzione delle ambiguit√† facciamo uso delle parentesi per disambiguare, questo utilizzo delle parentesi √® presente nell‚Äôalbero di sintassi concreta, anche chiamato parse tree.\nInvece l‚Äôalbero di sintassi astratta pu√≤ essere ambigua, rappresenta una astrazione sulla sintassi concreta del linguaggio e spesso √® ambigua.\nEmail mandata, in TODO\nAlbero di derivazione\n√à l\u0026rsquo;albero che soddisfa le 6 propriet√† presentate (radice √® il non terminale iniziale, i nodi\ninterni sono etichettati come non terminali, etc..).\nAlbero di sintassi concreta\n√à l\u0026rsquo;albero che rappresenta tutta la sintassi del programma (con anche zucchero sintattico)\nQuesto albero inoltre¬†√® un albero di derivazione¬†perch√© soddisfa tutte le propriet√†.\nAlbero di sintassi astratta√à formato solamente dalle foglie dell\u0026rsquo;albero di sintassi concreta, senza le foglie dovute allozucchero sintattico, quindi non √® un albero di derivazione perch√© non soddisfa le propriet√†di essa (e.g. nodi interni non terminali) e contiene informazioni semantiche riguardo al programma.\nAmbiguit√† Tipologie di ambiguit√† (con esempi 2) üü©- Ambiguit√† nella grammatica\nSi pu√≤ dire che una grammatica √® ambigua se esistono due alberi di derivazione differenti per una stessa stringa.\nEsempio di ambiguit√† per alberi di derivazione\nEsempio di grammatica ambigua\n$$ S \\to A | \\varepsilon \\\\ A \\to \\varepsilon $$Questo linguaggio genera solamente dei vuoti, ma lo pu√≤ fare in modi diversi eg:\n$S \\to \\varepsilon$, o $S \\to A \\to \\varepsilon$\nUna altra grammatica che descrive il linguaggi equivalente non √® per√≤ ambiguo\n$S \\to \\varepsilon$\nAmbiguit√† nel linguaggio\nSi pu√≤ dire che un linguaggio √® ambiguo se ogni sua grammatica √® ambigua.\nEsempio di linguaggio ambiguo\nRisoluzione delle ambiguit√† üü© In modo simile a quanto trattato in Sintassi e RI strutturali bisogna stabilire:\nOrdine di precedenza degli operatori\nEsempio di problema di precedenza\nAssociativit√† sinistra o destra\nEsempio di necessit√† di associativit√† dx e sx\nParentesi\nQuesto √® un zucchero sintattico che non ha nessun valore semantico che aiuta a disambiguare la precedenza. (L\u0026rsquo;albero semantico non serve avere le informazioni sulle parentesi) Questo √® necessario per essere equivalente semanticamente ossia possono generare ora gli stessi alberi semantici Aggiunta parentesi\nGrammatica ambigua:\n$$ S = a|b...|S + S|S\\times S $$Soluzione ambiguit√†\n$$ E = E + T | T \\\\ T = A \\times T | A \\\\ A = a|b ...| (E) $$","permalink":"https://flecart.github.io/notes/descrizione-linguaggio/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003cp\u003ePer questa parte c‚Äô√® un sacco di roba in comune con \u003ca href=\"/notes/tecniche-di-definizione-di-semantica-%284%29-%F0%9F%9F%A9\"\u003eTecniche di definizione di semantica (4) üü©\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTrattiamo alcune caratteristiche che descrivono ad alto livello un linguaggio di programmazione. √à da notare che questa parte della spiegazione del linguaggio non √® limitante al solo linguaggio di programmazione, √® utile per analizzare tutti i linguaggi (tranne la parte di implementazione)\u003c/p\u003e\n\u003ch3 id=\"sintassi--\"\u003eSintassi üü©-\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eRelazione fra segni\u003c/em\u003e. si occupa di decidere quando una frase √® corretta.\u003c/p\u003e","title":"Descrizione linguaggio"},{"content":"Processo design del database Il design Some design steps (3) (non impo) How to gather requirements? üü®+ Come si pu√≤ raccogliere i dati degli utilizzatori?\nparlare col il personale che dovr√† utilizzare questi sistemi Documentazione esistente Interview di persone che dovr√† utilizzare queste risorse O Moduli per fare sampling Top-down approach La cosa brutta √® che questi requisiti non possono essere standardizzati, ci sono molte necessit√†, molto diverse fra i loro, quindi √® utile andare a parlare con gli esperti e capire cosa abbiano bisogno per i dati. Consiglio del prof. √® partire dai senior e poi scendere, perch√© quelli in alto hanno un punto di vista pi√π ampio ma con meno dettagli diciamo.\nHow to ask the requirements √à molto facile non capire un interlocutore, basta usare il gergo specifico di quell\u0026rsquo;ambito. Anche i maranza per esempio hanno il proprio gergo che non √® comprensibile. Bisogna chiedere cosa hai bisogno, secondo le necessit√† soprattutto! Esempi possono semplificare un sacco. Una cosa molto importante √® mantenere il linguaggio semplice e fare le domande giuste (dividere le domande funzionali con le domande di dati utili da memorizzare). √à difficile sapere cosa √® importante mantenere per una istituzione. Solitamente se usano un gergo specifico √® bene provare a comprendere cosa significhi la parola specifica. Un bias comune √® che le persone tendono a parlare di problemi recenti, che non potrebbero riflettere le necessit√† a lungo termine per i dati.\nUn glossario dei termini √® molto importante per stabilire il significato in quel contesto.\nHow to create entities and relations? (4) ##### Storicizzazione (!) Pu√≤ essere fatta in due modi, o con due relazioni, oppure con una generalizzazione. Metodi di modellazione Top down üü© Parto dai requisiti e provo a raffinarli passo passo fino ad avere uno schema finale Bottom up üü© Parto dalle specifiche e costruisco i singoli componenti fino ad arrivare a schemi collegati assieme Inside out üü© Parto da un requisito chiaro, che costruisco e poi inizio a costruire gli altri secondo quando bene ho capito sono relazionati.\nSteps per design concettuale Per il prof. si pu√≤ passare al design logico subito se si √® molto bravi, per√≤ il suo consiglio √® sempre partire da alto livello e poi andare a definire tutte le relazioni. Entity-Relationship model Introduction to modeling phases The conceptual modelling phase üü© It\u0026rsquo;s a data representation is independent from the system, but it\u0026rsquo;s useful to show how are the different entities connected to each other.\nQuesta √® la prima fase del processo di design di un database, nasce principalmente da una inefficacy of the relational structure (too much information), quindi si vuole usare come via di alto livello per analizzare la struttura!\nVisual documentation that is useful for docs. Other modelling phases (2) üü© Logico, ne parliamo in Database logical design e poi il fisico non viene trattato in questo corso, e dovrebbe essere bene astratto.\nEntity Definition of entity üü© An entity represents a class of \u0026ldquo;objects\u0026rdquo; sharing common properties, but still having an autonomous existence. It is clearly heavily linked to the concept of object in OOP (see Classi OOP), that is the framework where the ER model was born.\nEntity identifier, internal üü© NOTA: queste non sono chiavi! Si chiamano in modo diverso! It could be an internal identifier formed by the attributes of the single relationship, or external if it is identified by some kind of relationship. External identifier üü© #### Generalization and specialization üü© One entity $E$ could be composed by many components $E_{1}, E_{2}, \\dots E_{N}$, this is a **generalization** relationship, the inverse is a a specialization. There are also some properties to consider: - Every property in $E_{i}$ is used in some way in $E$ - Every instance of $E_{i}$ is an instance of $E$ too. Types of generalization (2) üü© It could be total/partial or disjoint/Overlapped. It is total if the parent is totally composed by the child entities, otherwise it\u0026rsquo;s partial. A total relationship has a full arrow, while a partial has an outlined arrow as pointer.\nIt is disjoint if the children doesn\u0026rsquo;t have anything in common (property-wise) and overlapped otherwise.\nData dictionary (3) üü© The data dictionary is a quick way to represent the conceptual model, some examples are given down there. There are also some non-expressible constraints that in the example is not reported, but are the cardinality or other types of constraints that the model has. Relationships Definition of relationships üü© A relationship is a connection between two or more entity types. Usually is given a name to the relationship, that summarizes his semantic meaning. Singular nouns are preferred.\nExample of relationship: Arity of relationship üü© A relationship is not limited to connect two entity types, it can connect more, and this value defines the arity of the relationship. In each case the relationship is represented as a tuple, that is unique, meaning that more instances of the same type could not exist: You can\u0026rsquo;t have the same tuple within the relationship.\nRelationship promotion to entity üü© Sometimes a relationship is not enough to model some constraints, in these cases it is useful to use an entity instead.\nExample: Cardinality of relationship üü©\u0026ndash; This is different from the arity. It\u0026rsquo;s a constraint that defines the minimum and maximum value that a relationship can have. There is a convention to use $N$ if we don\u0026rsquo;t have an upper limit\nTypes of relationship cardinality (3) üü© The classical classification is\nMany-to-many One to many 1 to 1 It\u0026rsquo;s clear what they mean, it\u0026rsquo;s a cardinality relation, for example current_spouse relationship is a 1-1 in the modern society, schools frequented could be one to many, the exams taken by a student in the course entity is a many to many.\nAttributes Definition of attributes üü© Sono propriet√† o di entit√† o associazioni, che assumono valori da un certo dominio\nComposite attributes üü© They are used to group together different attributes to the same class or relationship. This is useful if different attributes share the same semantic meaning.\nIn the example in the image it\u0026rsquo;s the address. Cardinality of attributes üü© It is possible to define a cardinality for single attributes, because an employee could have more phone numbers, or the driving licence is optional (not everybody has it!)\n","permalink":"https://flecart.github.io/notes/design-del-database/","summary":"\u003ch3 id=\"processo-design-del-database\"\u003eProcesso design del database\u003c/h3\u003e\n\u003ch4 id=\"il-design\"\u003eIl design\u003c/h4\u003e\n\u003ch4 id=\"some-design-steps-3-non-impo\"\u003eSome design steps (3) (non impo)\u003c/h4\u003e\n\u003ch5 id=\"how-to-gather-requirements-\"\u003eHow to gather requirements? üü®+\u003c/h5\u003e\n\u003cp\u003eCome si pu√≤ raccogliere i dati degli utilizzatori?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eparlare col il personale che dovr√† utilizzare questi sistemi\u003c/li\u003e\n\u003cli\u003eDocumentazione esistente\u003c/li\u003e\n\u003cli\u003eInterview di persone che dovr√† utilizzare queste risorse\u003c/li\u003e\n\u003cli\u003eO Moduli per fare sampling\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"top-down-approach\"\u003eTop-down approach\u003c/h5\u003e\n\u003cp\u003eLa cosa brutta √® che questi requisiti non possono essere standardizzati, ci sono molte necessit√†, molto diverse fra i loro, quindi √® utile andare a parlare con gli esperti e capire cosa abbiano bisogno per i dati.\nConsiglio del prof. √® partire dai senior e poi scendere, perch√© quelli in alto hanno un punto di vista \u003cem\u003epi√π ampio ma con meno dettagli\u003c/em\u003e diciamo.\u003c/p\u003e","title":"Design del database"},{"content":"Introduction to design patterns Introduzione personale üü© I design patterns sono simili a dei plug and play, ossia delle soluzioni che hanno funzionato bene in passato e che sono ora riutilizzati. Solitamente dovrebbe essere una abilit√† implicita, cio√® un buon programmatore √® in grado di fare senza pensarci, dovrebbe essere automatico. Infatti quando uno fa il design non lo fa esplitamente seguendo un certo modello, ma farlo solitamente risulta utile per guidare il processo.\nDefinizione design pattern üü®++ Descriptions of communicating objects and classes that are customized to solve a general design problem in a particular context\nA Pattern describes a problem which occurs over and over again in our environment, and then describes the core of the solution to that problem, in such a way that you can use this solution a million times over, without ever doing it the same way twice\nCommon OO patterns Singleton üü© Questa la sai. Provi a ritornare un oggetto gi√† inizializzato che vive per tutto il tempo del tuo programma. √à il singoletto, qualcosa che esiste solamente una volta. Un pattern solito con questo √® il check dell\u0026rsquo;esistenza del valore statico, e il getter di istanza.\nComposite üü© In pratica √® un albero in cui solamente le foglie sono operazioni. √® stato utilizzato nelle slides per modellizzare un oggetto composto che deve semplicemente eseguire il codice dei figli (quindi diciamo un qualcosa di mezzo per poter dare in modo chiaro l\u0026rsquo;operazione corretta).\nIterator pattern üü®++ Viene utilizzato per scorrere qualcosa di generico, in C++ per esempio √® utilizzato in moltissime librerie standard. in Python √® possibile definire due metodi __next__ e __iter__ e anche in rust √® molto molto usato questo pattern.\nCreational Perch√© creational? (2) üü©\u0026ndash; Sono i pattern utilizzati per creare nuovi oggetti in modo sostenibile.\nAstrarre la creazione del singolo oggetto Incapsulamento, quindi voglio limitare l\u0026rsquo;accesso a informazione a solamente certi metodi ben definiti. Builder üü®+ https://refactoring.guru/design-patterns/builder\nIn questo caso abbiamo un director che in pratica orchestra la costruzione dei componenti reali. E singole componenti in cui sono specificati esattamente cosa fare. √à utile soprattutto quando ho qualcosa di molto complesso da costruire, che pu√≤ cambiare in molti modi. Un esempio √® il build di Zig credo.\nAbstract factory üü©\u0026ndash; https://refactoring.guru/design-patterns/abstract-factory\nServe soprattutto come interfaccia comune per andare a creare qualcosa di concreto (nel nostro caso una factory concreta). Ricorda l\u0026rsquo;esempio di sedia, tavoli, e stili diversi! Avere l\u0026rsquo;abstract factory ti permette di utilizzare la stessa interfaccia, quando nel concreto puoi produrre cose diverse. (dal punto di vista del cliente √® sempre la stessa cosa).\nFactory Method üü© https://refactoring.guru/design-patterns/factory-method\nDa un punto di vista intuitivo, questo √® solamente quando si utilizzano le classi virtuali. In C++ li abbiamo usati, vengono utili soprattutto quando la stessa funzione viene chiamata, la semantica √® uguale, ma l\u0026rsquo;implementazione cambia a seconda del tizio che la vuole usare tipo. Un esempio √® la funzione attacco dei mostri, che possono attaccare in molti modi, ma quello che vogliono fare √® attaccare.\nPrototype Structural Sono utilizzati come interfacce utili per far funzionare delle cose assieme.\nAdapter and Bridge Adapter viene utilizzato per problemi di nome, bridge per nascondere l\u0026rsquo;interfaccia Decorators Sono delle funzioni che ritornano altre funzioni con delle funzionalit√† aggiunte (e sono comode) se lo hai visto in python o JS lo conosci senza problemi. Per linguaggi statici tipo C √® pi√π difficile da mettere.\nProxy pattern Invece di accedere qualcosa in modo diretto usiamo una altra classe od oggetto che si occupa di controllare l\u0026rsquo;accesso, un esempio guardare i permessi, controllare altro, fare log o simili\u0026hellip; Behavioural I patter comportamentali definiscono quali sono le classi di responsabilit√† per una classe e una altra, e gli algoritmi da utilizzare.\nVisitor √à tipo una visita dfs, bfs, prende informazioni in modo strutturato senza cambiarne la struttura. Strategy √à un pattern che specialmente per librerie di python si vede spessissimo, si utilizza un identificatore e un dispatcher all\u0026rsquo;algoritmo corretto. Chain of responsibility √à una suddivisione di classi di responsabilit√†, come se fosse una catena di montaggio. Una cosa comune √® l\u0026rsquo;albero, e il responsabile diretto √® il suo parente, che magari deve gestire altro, non lo so. Se in un certo punto un check fallisce, la cosa non continua, ma viene cestinata.\nMediator Mi sembra simile alla reificazione che abbiamo studiato per la prima volta (in logica un po\u0026rsquo; ma di pi√π in) Design del database. ossia invece di avere $N^{2}$ collegamenti, basta avere un punto intermedio di comunicazione e abbassi di una potenza. √à la potenza del mediatore.\n","permalink":"https://flecart.github.io/notes/design-patterns/","summary":"\u003ch3 id=\"introduction-to-design-patterns\"\u003eIntroduction to design patterns\u003c/h3\u003e\n\u003ch4 id=\"introduzione-personale-\"\u003eIntroduzione personale üü©\u003c/h4\u003e\n\u003cp\u003eI design patterns sono simili a dei \u003cem\u003eplug and play\u003c/em\u003e, ossia delle \u003cstrong\u003esoluzioni che hanno funzionato bene\u003c/strong\u003e in passato e che sono ora riutilizzati.\nSolitamente dovrebbe essere una \u003cstrong\u003eabilit√† implicita\u003c/strong\u003e, cio√® un buon programmatore √® in grado di fare senza pensarci, dovrebbe essere automatico. Infatti quando uno fa il design non lo fa esplitamente seguendo un certo modello, ma farlo solitamente risulta utile per guidare il processo.\u003c/p\u003e","title":"Design patterns"},{"content":"Determinanti I determinanti sono un numero associato alle matrici quadrate. Pi√π o meno ne sono il riassunto.\nPropriet√† Le prime 3 sono quelle fondamentali per calcolare il tutto, i numeri dopo il 3 sono alcune conseguenze.\ndet I = 1\nCambiare righe ‚Üí cambiare il segno della determinante.\n(Importante)\nSe moltiplico una riga per una costante, il determinante √® moltiplicato per questa costante. Se sommo una costante a una riga, allora il determinante √® una somma strana\u0026hellip; Immagine di esempio\nSe la matrice ha due righe uguali, il determinante √® 0, questo √® derivabile dalla propriet√† 2.\nSottrarre un multiplo di una riga a una altra riga della matrice produce la stessa determinante. (in pratica sto sottraendo una matrice che ha due righe uguali, la cui determinante √® 0).\nUna riga di 0 implica che il determinante dell‚Äôintera matrice sia 0, questo si pu√≤ dimostrare con 3a.\nData una matrice uppertriangular, il determinante √® la moltiplicazione degli elementi nella diagonale principale. (posso ottenere una matrice diagonale sottraendo all‚Äôins√π, e poi posso tirare fuori multipli per riga).\nL‚Äôultima propriet√† ci dice come si fa a calcolare il determinante, ossia ridurre in forma U e poi moltiplicare la diagonale. Ez. (da tenere in conto anche possibili cambi di riga).\ndet A = 0 quando A √® singolare (possiede una riga di 0) e det A ‚â† 0 quando non lo √® il determinante del prodotto di due matrici √® il prodotto delle determinanti delle due matrici, √® un isomorfismo! Questa propriet√† ci d√† anche il determinante dell‚Äôinverso in modo immediato, questo ci d√† anche un modo immediato per trovare l‚Äôinversa di una matrice diagonale (basta invertire tutti i numeri üôÇ) e questo √® anche un motivo per cui se invertibile not 0, altrimenti divido per 0. determinante della transposizione di A √® uguale al determinante di A, in quanto se ragioniamo nella forma diagonale la transposizione √® esattamente uguale ad A. Calcolo Possiamo splittare il calcolo della determinante in somme pi√π semplici. Inoltre possiamo notare che un determinante √® diverso da nullo, per la propriet√† 8 se non √® singolare, quindi vogliamo avere un elemento per ogni colonna e riga.\nContinuando questo ragionamento possiamo cercare di riassumere tutto in una unica formula\n$$ \\det A = \\sum_{\\text{n! sums}} P(\\alpha, \\beta, ..., \\omega) a_{1\\alpha} a_{2\\beta}...a_{n\\omega}\\\\ \\{\\alpha,\\beta, ..., \\omega\\} \\in \\text{ Perm of } \\{1,2,3...,n\\}, \\text{ where } A \\text{ is } n \\times n \\\\ P(\\alpha, \\beta, ..., \\omega) =\\begin{cases} 1 \\text{ if it's even permutation } \\\\ -1 \\text{ if it's odd permutation } \\end{cases} $$Determinante come volume Per esempio se prendiamo una matrice 3x3, possiamo prendere ogni punto identificato da una riga come 3 punti. Questi tre punti riescono ad identificare una scatola. (ogni lato √® un parallelogramma e il volume del cubo √® uguale al determinante).\nCofattori I cofattori sono utili per semplificare il calcolo della determinante presentata in precedenza.\nIn altre parole si potrebbe dire che il determinante di una matrice quadrata grossa si potrebbe ridurre come una combinazione lineare di alcune sottomatrici.\nDeterminante con cofattori Quindi il calcolo del determinante si pu√≤ riassumere come\n$$ \\det A = \\sum_{i=1}^{n} a_{1i}C_{1i} $$Inverse con cofattori Si potrebbe notare che questo sia il metodo matematico per l‚Äôinverso, mentre le eliminazioni con il metodo di Gauss Jordan √® il metodo pi√π informatico.\n$$ A^{-1} = \\dfrac{1}{\\det A} C^T $$Che √® equivalente nel verificare che\n$$ \\det A \\cdot I = A C^T $$E questo ha senso, se moltiplico per righe corrispondenti ho la formula sopra per il determinante per riga.\nMentre se lo faccio per tutte le altre righe √® come se stessi calcolando il determinante con una riga doppia, quindi il determinante √® 0 per quelle righe.\nSe utilizzo questo risulato, posso derivare la formula di cramer\nRegola di cramer $$ Ax = b \\\\ x = A^{-1}b \\\\ x = \\dfrac{1}{\\det A} C^T b $$Questo √® code rimpiazzare la prima colonna della matrice A con b\nQuesto algoritmo √® lentissimo, costa molto calcolare un determinante.\nAutovettori Moved to Autovalori e Autovettori the 19th of July 2024.\n","permalink":"https://flecart.github.io/notes/determinanti/","summary":"\u003ch2 id=\"determinanti\"\u003eDeterminanti\u003c/h2\u003e\n\u003cp\u003eI determinanti sono un numero associato alle matrici quadrate. Pi√π o meno ne sono il riassunto.\u003c/p\u003e\n\u003ch3 id=\"propriet√†\"\u003ePropriet√†\u003c/h3\u003e\n\u003cp\u003eLe prime 3 sono quelle fondamentali per calcolare il tutto, i numeri dopo il 3 sono alcune conseguenze.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003edet I = 1\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCambiare righe ‚Üí cambiare il segno della determinante.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e(Importante)\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSe moltiplico una riga per una costante, il determinante √® moltiplicato per questa costante.\u003c/li\u003e\n\u003cli\u003eSe sommo una costante a una riga, allora il determinante √® una somma strana\u0026hellip;\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eImmagine di esempio\u003c/p\u003e","title":"Determinanti"},{"content":"Devices Categorizzazione (6)üü®- Trasferimento dei dati Accesso al device sinfonia del trasferimento condivisone fra processi Velocit√† del trasferimento I/O direction (scrittura o lettura) Vediamo che molte caratteristiche sono riguardo il trasferimento\nSlide categorizzazione I/O\nBlocchi o caratteri üü©- Slide devices blocchi o caratteri\nTecniche di gestione devices (4) üü®- Buffering Possiamo mettere un buffer per favorire la comunicazione fra i devices. la cosa migliore che fa √® creare maggiore efficienza. Un altro motivo √® la velocit√† diversa di consumo.\nAnche le schede audio, in cui viene riempito un buffer e poi l‚Äôaudio viene suonato da questo (differenza consumer e producer), anche per questo motivo √® difficile sincronizzare dispositivi differenti (se hanno buffer distinti).\nCache Invece la cache √® trasparente pe ril programma, e rende il tutto pi√π veloce. La differenza maggiore con il buffering √® che qui viene mantenuta una copia, non una istanza dell‚Äôinformazione.\nSpooling Gia trattato per le stampanti in Gestione delle risorse\nScheduling I/O Storage area network üü© Il vantaggio principale √® resilienza del server, che ho il device in altra parte. (non ho iil tight coupling fra server e disco in questo modo, prima se si rompe qualunque, si rompe il servizio).\nOra se si rompe un server, ci sar√† un altro server che sostituisce, se si rompe un storage array, ci sar√† ridondanza, e altro storage ti risponderebbe. Si vede che questa parte √® strettamente collegata con cose fatte in Reti di Calcolatori\nMemoria secondaria Solid State Drive üü®+ Un sacco di vantaggi come\nVelocit√† di accesso Meno consumo energetico Meno fragilit√† Velocit√† di lettura √® molto veloce. Poche scritture (comuqnue tante) comunque limitati cicli di scrittura. Uniforme velocit√† in tutto il disco (questo rende l\u0026rsquo;accesso veloce :D). Non andiamo ad approfondire sugli algoritmi di scheduling per le scritture a banco, trattiamo meglio gli HDD.\nHard Disk Drive üü®+ Soffrono molto i terremoti perch√© la testina √® vicina al disco e non soffrono problemi di pressione.\nDevo avere:\nTestine settore giusto La traccia desiderata si muova e mi dia le cose giuste Questo mi crea 3 parametri per valutare questo accesso\nVelocit√† di rotazione, Tempo di seek o di cambiare cilindro**, velocit√† di trasferimento**.\nSolitamente il tempo pi√π lungo √® per il cilindro, poi devo andare alla sezione, e andare alla testina corretta.\nIn generale sul disco:\nOssia solitamente mezzo giro, + tempo cambio\nVALUTAZIONE TEMPO DI ACCESSO\nSlide tempi di accesso per dischi\nIn media 100 giri al secondo, quindi tipo 5 ms per andare a trovare la testina corretta, potrebbe essere 2.5 se √® il doppio o 1, ma l‚Äôordine di grandezza resta questo per il ritardo.\nRAID Introduzione ai Redundant Array of Indipendent Disks I RAID ne abbiamo parlato in Memoria. Come facciamo a stare su alla velocit√† del processore se questa va a crescere in modo esponenziale? Parallelizzazione della ricerca!. Ecco perch√© ci serve raid (oltre alla ridondanza quindi pi√π sicuro). E possono anche fallire. ‚Üí ammette recovery.\nE una altra cosa bella dei raid √® che sono hot-swappable cio√® li puoi sostituire anche quando stanno runnando.\nSlide RAID\nlivello 0 (striping) üü© I dati vengono messi su pi√π dischi. Viene utilizzato per applicazioni in cui serve velocit√†, senza interesse di perdita di dati. Ad esempio in dipartimento ci mettono copie di SO per aggiornare il sistema operativo.\nUTILIZZI:\nper grandi trasferimenti di dati, efficiente, in particolare se la quantit√† di dati richiesta √® relativamente grande rispetto alla dimensione degli strip\nper un gran numero di richieste indipendenti efficiente, in particolare se la quantit√† di dati richiesta √® paragonabile alla dimensione degli strip\nSlide RAID 0\nhttps://www.notion.so\nLivello 1 (mirroring) üü© Ci sono 2n dischi e met√† sono delle copie esatte.\nSlide RAID 1\nIn questo caso la scrittura √® pi√π lenta della lettura.\nTollera un singolo guasto al massimo, o pi√π dischi differenti (non devono essere le due copie diciamo). Si dice fault tolerance livello 1.\nLivello 4 üü© Slide introduzione raid livello 4\nUtilizzo un intero disco solamente per la parit√† su un disco. cos√¨ se si rompe un disco riesco a ricostruire le informazioni di quel disco.\nNon √® efficiente perch√© se cambio un dato devo andare sempre a fare due write su dischi diversi. E poi continuo sempre a scrivere sullo stesso disco! Quindi fai finta 4 write contemporanei, per aggiornare gli altri dischi! Per questo c\u0026rsquo;√® il bottleneck\nLivello 5 üü© Slide intuizione raid livello 5\nSe c\u0026rsquo;√® un disco rotto si rallenta, ma non si perdono dei dati! √® il funzionamento degradato dei raid.\nNon ho problemi di bottleneck, e ho ancora la velocit√† del livello 1\nLivello 6 üü®++ Slide raid livello 6\nhttp://www.cs.unibo.it/~renzo/doc/p245-blaum\nQuesto √® per cose sicure, riesce a tollerare livello 2 fino a due dischi rotti.\nOvviamente √® una parit√† diversa, in modo che riesco ad avere pi√π fault tolerance.\nSi utilizza un XOR in diagonale e questo sembra funzionare, anche se non ho capito perch√©.\nIntuizione mia\nIn pratica qualunque modo prendi due dischi non di check (se uno √® un disco di check √® molto ez).\nAllora puoi fare questo:\nRecovery dei dischi in alto a sinistra e in basso a destra, questi si possono recoverare solamente con i bits diagonali, quindi posso gi√† farlo. Utilizzo questi strips recuperati e utilizzo quelli orizzontali per recuperare l‚Äôaltro della stessa row, poi utilizzo diagonale per recuperare quelli corrispondenti in row diverse e continuo cos√¨ e riesco a recuperare tutto., Sarebbe molto utile fare un esempio per mostrare questo, ma spero che il me futuro quando legge questo riesca a ricordarsi l‚Äôesempio su carta.\nAlgoritmi per HHD First Come First Served üü© Questo √® un algoritmo fair, nel senso che eseguo a seconda di quanto viene, questo non general starvation. Per√≤ non minimizza il numero di seek, quindi in generale √® pi√π lento. Se invece facciamo in batch, in gruppo di richeiste alla volta sarebbe molto pi√π semplice!\nQuesta √® l\u0026rsquo;idea del prossimo algoritmo\nShortest Seek Time First üü© seleziona la richieste che prevede il minor spostamento della testina dalla posizione corrente\npu√≤ provocare starvation, quando arrivano tante vicine, non visito mai quelle lontane!\nQuindi non abbiamo fairness, e non c‚Äô√® una buona velocit√† di risposta per le richieste agli estremi.\nLook - Algoritmo dell‚Äôascensore üü© Praticamente vado avanti indietro, e quando arrivo alla fine torno indietro, continuo cos√¨ a soddisfare le richieste.\nIl tempo medio di accesso non √® omogeneo, le tracce centrali sono accesse pi√π spesso.\nEsempio ascensore\nDISCUSSIONE DI IMPLEMENTAZIONE\nSi utilizzano due code. Una coda a scendere e una coda a salire.\nPotrei creare starvation quando mi arrivano richieste sullo stesso cilindro, quindi quando succede devo mettere la richiesta nell\u0026rsquo;altra coda.\nImplementazione delle due code\nC-Look üü®++ √à molto simile all\u0026rsquo;algoritmo dell‚Äôascensore, ma solo che quando arrivo alla fine torno all‚Äôinizio.\nNon ho ancora capito in quali casi pu√≤ essere utile.\nSlide esempio C-Look\n","permalink":"https://flecart.github.io/notes/devices-os/","summary":"\u003ch2 id=\"devices\"\u003eDevices\u003c/h2\u003e\n\u003ch3 id=\"categorizzazione-6-\"\u003eCategorizzazione (6)üü®-\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eTrasferimento dei dati\u003c/li\u003e\n\u003cli\u003eAccesso al device\u003c/li\u003e\n\u003cli\u003esinfonia del trasferimento\u003c/li\u003e\n\u003cli\u003econdivisone fra processi\u003c/li\u003e\n\u003cli\u003eVelocit√† del trasferimento\u003c/li\u003e\n\u003cli\u003eI/O direction (scrittura o lettura)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eVediamo che molte caratteristiche sono riguardo il trasferimento\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide categorizzazione I/O\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Devices OS/Untitled.png\" alt=\"image/universita/ex-notion/Devices OS/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"blocchi-o-caratteri--\"\u003eBlocchi o caratteri üü©-\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide devices blocchi o caratteri\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Devices OS/Untitled 1.png\" alt=\"image/universita/ex-notion/Devices OS/Untitled 1\"\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Devices OS/Untitled 2.png\" alt=\"image/universita/ex-notion/Devices OS/Untitled 2\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"tecniche-di-gestione-devices-4--\"\u003eTecniche di gestione devices (4) üü®-\u003c/h3\u003e\n\u003ch4 id=\"buffering\"\u003eBuffering\u003c/h4\u003e\n\u003cp\u003ePossiamo mettere un buffer per favorire la comunicazione fra i devices. la cosa migliore che fa √® creare maggiore efficienza. Un altro motivo √® la \u003cstrong\u003evelocit√† diversa di consumo\u003c/strong\u003e.\u003c/p\u003e","title":"Devices OS"},{"content":"Diffusion is a physical process that models random motion, first analyzed by Brown when studying pollen grains in water. In this section, we will first analyze a simplified 1-dimensional version, and then delve into diffusion models for images, the ones closest to (Ho et al. 2020).\nThe Diffusion Process This note follows original Einstein\u0026rsquo;s presentation, here we have a simplified version.\nLet\u0026rsquo;s suppose we have a particle at $t = 0$ at some position $i$. We have a probability of jumping to the left of $p$ to right of $q$, the rest is staying at the same position.\nConcentrationüü®- We would like to know the concentration of particles after a number of fixed steps at a certain position. Then we would like to know the same thing if we extend the idea to a certain number of starting particles at the beginning. Let\u0026rsquo;s call this concentration $C_{i}(t)$. Then the number of particles at a certain time step and position is $n_{i}(t) = Nc_{i}(t)$\nMarkov Process üü® $$ C_{i}(t + 1) = C_{i - 1}(t)q + C_{i + 1}(t)p + (1 - q - p) C_{i}(t) $$$$ \\begin{align} C_{i}(t + 1) - C_{i}(t) \u0026= C_{i - 1}(t)q + C_{i + 1}(t)p + (1 - q - p) C_{i}(t) - C_{i}(t) \\\\ \u0026= q(C_{i - 1}(t) - C_{i}(t)) + p(C_{i + 1}(t) - C_{i}(t)) \\\\ \u0026= p C_{i + 1}(t) - (p + q)C_{i}(t) + qC_{i - 1}(t) \\\\ \u0026= \\frac{p - q}{2} (C_{i + 1}(t) - C_{i - 1}(t)) + \\frac{p + q}{2}(C_{i + 1}(t) - 2C_{i}(t) + C_{i - 1}(t)) \\end{align} $$ From the Markov Process we can have the master equation, from which we take the Fokker Plank equation. Somehow, we can interpret the temporal difference as the sum of a first derivative and of a second derivative. The first derivative tells us a preferred direction of diffusion (drift) the second tells us how fast it is (diffusion).\nGoing into continuous time üü•++ Let\u0026rsquo;s assume we have an update time of $\\Delta t$ (so smaller time deltas imply more frequent updates). We say $\\tau$ is the time scale of the system (measure of time in the system), we define $\\tau$ such that $\\tau / \\Delta t$ is the number of the updates for one Markov Step as before. More intuitively, the characteristic time $\\tau$ tells us the system needs that amount of time to have a single change, while $\\Delta t$ tells us how frequently we are going to check the system, this is the reason why we need to check the system $\\frac{\\tau}{\\Delta t}$ times to observe a change.\n$$ C_{i}(t + \\Delta t) - C_{i}(t) = \\frac{p' - q'}{2} (C_{i + 1}(t) - C_{i - 1}(t)) + \\frac{p' + q'}{2}(C_{i + 1}(t) - 2C_{i}(t) + C_{i - 1}(t)) $$$$ \\tau \\frac{d}{dt} C_{i}(t) = \\frac{p - q}{2} (C_{i + 1}(t) - C_{i - 1}(t)) + \\frac{p + q}{2}(C_{i + 1}(t) - 2C_{i}(t) + C_{i - 1}(t)) $$ This is the master equation. Having a continuous time just changes the probability of jumping, this is the relation that allows us to have continuous updates (so if we don\u0026rsquo;t have a full time, we have just a fraction of the probability of jumping). This should be the master equation for a diffusion process.\nContinuous Space üü®\u0026ndash; Here, we apply a rescaling on the form $i \\pm 1 \\to x \\pm \\Delta x$. To simplify the calculations, we further assume that there is no Drift, meaning $p = q = \\tilde{D}$. Now, we have steps of size $\\delta$ made of small steps of $\\Delta x$ in time $\\tau$\n$$ C(x+\\Delta x,t) - 2\\,C(x,t) + C(x-\\Delta x,t) = (\\Delta x)^2\\,\\frac{\\partial^2 C}{\\partial x^2}(x,t) + O(D^{4}) $$We do another re-scaling of the probability $p'' = p ( \\delta / \\Delta x )^{2}$ which is motivated by our double derivative in the second part, then rewriting everything we get the continuous space equation. Then we get\n$$ \\begin{align} \\\\ \\tau \\frac{d}{dt} C_{i}(t) \u0026= \\frac{p - q}{2} (C_{i + 1}(t) - C_{i - 1}(t)) + \\frac{p'' + q''}{2}(C_{i + 1}(t) - 2C_{i}(t) + C_{i - 1}(t)) \\\\ \u0026= \\underbrace{\\frac{p - q}{2}}_{p = q = \\tilde{D} \\implies p-q = 0}(C_{i + 1}(t) - C_{i - 1}(t)) + \\delta^{2}\\frac{p + q}{2}\\frac{(C_{i + 1}(t) - 2C_{i}(t) + C_{i - 1}(t))}{\\Delta x^{2}} \\\\ \u0026\\implies\\frac{ \\partial }{ \\partial t } C(x, t) = D \\frac{ \\partial^{2} }{ \\partial x^{2} } C(x, t), \\text{ With } D = \\frac{ \\delta^{2} \\tilde{D}}{ 2 \\tau } \\end{align} $$When $\\tilde{D} = \\frac{1}{ 2}$ we have Einstein\u0026rsquo;s diffusion. Where $D$ is our diffusion coefficient. We do a Fourier transform in space and we get an ordinary differential equation in time, which is solvable. Take a look for the next section.\nWe can prove that the mean squared displacement (variance) grows linearly with time.\nSolution for the diffusion process $$ C(x, t) = \\frac{1}{\\sqrt{ \\pi 4 D t }} e^{-x^{2} / 4Dt} $$$$ F(k, t) = \\int e^{-ikx}f(x, t) \\, dx $$$$ f(x, t) = \\int e^{ikx}F(k, t) \\, dk $$$$ \\begin{align} \\frac{d}{dt} \\int e^{-ikx}C(x, t) \\, dx = D \\int e^{-ikx} \\frac{ \\partial^{2} }{ \\partial x^{2} } C(x, t) \\, dx \\\\ \\frac{d}{dt} F(k, t) = -Dk^{2}F(k, t) \\end{align} $$ Where the right hand side is derived through a double integration by parts.\nFokker Planck Equation $$ \\frac{ \\partial }{ \\partial t } f(x, t) = - \\frac{ \\partial }{ \\partial x }\\underbrace{ (A(x, t)f(x, t))}_{\\substack{\\text{Drift Term with} \\\\ \\text{Force } A(x, t)}} + \\frac{ \\partial^{2} }{ \\partial x^{2} } \\underbrace{(B(x, t)f(x, t))}_{\\substack{\\text{Diffusion Term with} \\\\ \\text{parameter } B(x, t)}} $$The Ornstein Uhlenbeck Process is a solution to the Fokker Planck equation with $A(x, t) = - \\gamma x$ and $B(x, t) = \\sigma^{2}$, where $\\gamma$ and $\\sigma$ are constants. Its SDE has the form $dx = - \\gamma x dt + \\sigma dW$.\nBut this is not quite important for the analysis of diffusion models, but keep in mind that the root of the theory originated from physics!\nIntroduction to Diffusion Models The Forward Encoder What is the link to Autoencoders? Noise Schedule $$ z_{t} = \\sqrt{ 1 - \\beta_{t} } z_{t - 1} + \\sqrt{\\beta_{t}} \\epsilon_{t}$$ And $z_{0} = x$ where $\\forall t, 0 \u003c \\beta_{t} \u003c 1$ and $\\epsilon_{t} \\sim \\mathcal{N}(0, I)$. So now we have $z_{t} \\sim \\mathcal{N}(z_{t}; \\sqrt{ 1 - \\beta_{t} }z_{t - 1}, \\beta_{t}I)$ If we suppose $z_{t - 1}$ is a Gaussian random variable with mean $\\mu_{t - 1}$ and variance $\\Sigma_{t - 1}^{2}$ then we observe that in the limit it converges to a Gaussian with mean $0$ and variance $I$, given noises. This choice is made with the idea that if we can invert the process, then generating a new sample from the data manifold is just sampling from the normal Gaussian and then applying the inverse noise transformation many many times.\n$$ z_{t} = \\sqrt{ \\alpha_{t} } z_{0} + \\sqrt{1 - \\alpha_{t}} \\epsilon $$ Where $\\alpha_{t} = \\prod_{i = 1}^{t} (1 - \\beta_{i})$, this is possible as we are matching the mean and variance of the resulting distribution. Now we can write $z_{t} \\sim \\mathcal{N}(z_{t}; \\sqrt{ \\alpha_{t} } z_{0}, (1 - \\alpha_{t})I)$.\nDiffusion Kernel Write the close form Why is this usually useful? Closed reverse conditional distribution We will use now the same tricks present in Bayesian Linear Regression for computing closed forms of Gaussian distributions.\n$$ q(z_{t - 1} \\mid z_{t}, x) = \\frac{q(z_{t} \\mid z_{t - 1}, x) q(z_{t - 1} \\mid x)}{q(z_{t} \\mid x)} $$ Now observe: the denominator is just a normalization constant that does not depend over $z_{t - 1}$, and $q(z_{t} \\mid z_{t - 1}, x) = q(z_{t} \\mid z_{t - 1})$ by Markov Property (see Markov Chains), now we can play with the Gaussians and derive the closed form of the distribution. Let\u0026rsquo;s take a deep look inside the $\\exp$ after we have done the product. As with Bayesian Linear Regression, we would like to rewrite it in the form $x^{T}\\Sigma^{-1}x - 2 \\mu^{T}\\Sigma^{-1}x + \\text{ const}$ as we know that the product still resembles a Gaussian, and needs to be normalized.\n$$ \\begin{align} \\log q(z_{t - 1} \\mid z_{t}, x) \u0026 \\propto (z_{t - 1} - \\sqrt{ a_{t - 1} }x)^{T} \\frac{1}{1 - \\alpha_{t - 1}} (z_{t - 1} - \\sqrt{ a_{t - 1} }x) + (z_{t} - \\sqrt{ 1 - \\beta_{t} }z_{t - 1})^{T} \\frac{1}{\\beta_{t}} (z_{t} - \\sqrt{ 1 - \\beta_{t} }z_{t - 1}) \\\\ \u0026 = \\frac{1}{1 - \\alpha_{t - 1}} z_{t - 1}^{T}z_{t - 1} - 2 \\frac{1}{1 - \\alpha_{t - 1}} z_{t - 1}^{T}\\sqrt{ a_{t - 1} }x- 2 \\frac{1}{\\beta_{t}} z_{t}^{T}\\sqrt{ 1 - \\beta_{t} }z_{t - 1} + \\frac{1}{\\beta_{t}} z_{t - 1}^{T}z_{t - 1} + \\text{const} \\\\ \u0026= z^{T}_{t - 1}\\left( \\frac{1}{ 1 - \\alpha_{t - 1}} + \\frac{1 - \\beta_{t}}{\\beta_{t}} \\right) z_{t - 1} - 2 z^{T}_{t - 1} \\left( \\frac{ \\sqrt{ a_{t - 1} }}{1 - \\alpha_{t - 1}}x + \\frac{\\sqrt{ 1 - \\beta_{t} }}{\\beta_{t}} z_{t} \\right) + \\text{const} \\end{align} $$$$ \\sigma_{t - 1}^{2} = \\left( \\frac{1}{ 1 - \\alpha_{t - 1}} + \\frac{1 - \\beta_{t}}{\\beta_{t}} \\right)^{-1} = \\frac{\\beta_{t}(1 - \\alpha_{t - 1})}{1 - \\alpha_{t}} $$$$ \\begin{align} \\mu_{t - 1} = m(x, z_{t})\u0026= \\sigma_{t - 1}^{2} \\left( \\frac{1}{1 - \\alpha_{t - 1}} \\sqrt{ a_{t - 1} }x + \\frac{\\sqrt{ 1 - \\beta_{t} }}{\\beta_{t}}z_{t} \\right) \\\\ \u0026= \\frac{\\beta_{t}(1 - \\alpha_{t - 1})}{1 - \\alpha_{t}} \\left( \\frac{1}{1 - \\alpha_{t - 1}} \\sqrt{ a_{t - 1} }x +\\frac{\\sqrt{ 1 - \\beta_{t} }}{\\beta_{t}}z_{t} \\right) \\\\ \u0026= \\frac{\\beta_{t}}{1 - \\alpha_{t}} \\sqrt{ a_{t - 1} }x + \\frac{ \\sqrt{ 1 - \\beta_{t} }}{1 - \\alpha_{t}} (1 - \\alpha_{t- 1})z_{t} \\end{align} $$$$ x = \\frac{1}{\\sqrt{ \\alpha_{t} }} z_{t} - \\frac{\\sqrt{1 - \\alpha_{t}}}{\\sqrt{ \\alpha_{t} }} \\epsilon $$$$ \\mu_{t - 1} = \\frac{1}{\\sqrt{ 1 - \\beta_{t} }} \\left( z_{t} - \\frac{\\beta_{t}}{\\sqrt{ 1 - \\alpha_{t} }}\\varepsilon_{t} \\right) $$ We will observe in a successive section how this form could be useful to train the reverse decoder.\nThe Reverse Decoder Using small variance schedules üü© We show now briefly that having small variance schedules then we can prove that the distribution $q(z_{t - 1}\\mid z_{t}) \\approx \\mathcal{N}(z_{t- 1}; z_{t},\\beta_{t}I)$.\n$$ q(\\mathbf{z}_{t-1} | \\mathbf{z}_t) = \\frac{q(\\mathbf{z}_t | \\mathbf{z}_{t-1}) q(\\mathbf{z}_{t-1})}{q(\\mathbf{z}_t)}. $$ Then take the log and expand Taylor to the second element to correct the mean and variance elements for the first one.\n$\\log q(\\mathbf{z}_{t-1}) \\approx \\log q(\\mathbf{z}_t) + (\\mathbf{z}_{t-1} - \\mathbf{z}_t)^\\top \\nabla_{\\mathbf{z}_{t-1}} \\log q(\\mathbf{z}_t) + \\frac{1}{2} (\\mathbf{z}_{t-1} - \\mathbf{z}_t)^\\top \\nabla^2_{\\mathbf{z}_{t-1}} \\log q(\\mathbf{z}_t) (\\mathbf{z}_{t-1} - \\mathbf{z}_t).$\nThe Loss Function üü®\u0026ndash; We will use ideas from Variational Inference. We will attempt to approximate the real inverse distribution $p$ with one of the variational family of Gaussians $q$, and maximize for the ELBO (see linked note for details).\nWe will see that the loss function is the following: $$ \\mathcal{L}(w) = \\mathbb{E}{q} \\left[ \\sum{t = 2}^{T} \\ln \\frac{p(z_{t - 1} \\mid z_{t}, w)}{q(z_{t - 1} \\mid z_{t}, w)} + \\ln p(x \\mid z_{1}, w) \\right]\n$$\nThis can be rewritten in a form closer to Variational Autoencoders, studied in Autoencoders, where we have a reconstruction term with a consistency term.\n$$ \\mathcal{L}(w) = -\\sum_{t = 1}^{T} \\lVert g(\\sqrt{ a_{t} }x + \\sqrt{ 1 - \\alpha_{t} }\\varepsilon_{t}, w, t) - \\varepsilon_{t} \\rVert ^{2} $$ Where $g$ is the neural network that we are using to approximate the reverse conditional distribution. And $t = 1$ is the special condition for the reconstruction term, and the rest is the consistency term, all in one in this case.\nTraining the Decoder Sampling from the diffusion References [1] Ho et al. ‚ÄúDenoising Diffusion Probabilistic Models‚Äù 2020\n","permalink":"https://flecart.github.io/notes/diffusion-models/","summary":"\u003cp\u003eDiffusion is a physical process that models random motion, first analyzed by Brown when studying pollen grains in water. In this section, we will first analyze a simplified 1-dimensional version, and then delve into diffusion models for images, the ones closest to \u003ca href=\"http://arxiv.org/abs/2006.11239\"\u003e(Ho et al. 2020)\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id=\"the-diffusion-process\"\u003eThe Diffusion Process\u003c/h3\u003e\n\u003cp\u003eThis \u003ca href=\"https://arxiv.org/pdf/cond-mat/0701242\"\u003enote\u003c/a\u003e follows original Einstein\u0026rsquo;s presentation, here we have a simplified version.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s suppose we have a particle at $t = 0$ at some position $i$. We have a probability of jumping to the left of $p$ to right of $q$, the rest is staying at the same position.\u003c/p\u003e","title":"Diffusion Models"},{"content":"Questo problema √® stato trattato in modo un po\u0026rsquo; pi√π semplificato (nel caso in cui la carica era esattamente a met√† in Campo elettrico#Dipolo elettrico). Questo problema √® stato storico, utilizzato per analizzare l\u0026rsquo;atomo.\nPotenziale del dipolo elettrico üü©\u0026ndash; $$ V(P) = V_{r^{+}} + V_{r^{-}} = \\frac{q}{4\\pi\\varepsilon_{0}}\\left( \\frac{1}{r^{+}} - \\frac{1}{r^{-}} \\right) $$$$ r^{+} - r^{-} = -a \\cos \\theta $$$$ \\left( \\frac{1}{r^{+}} - \\frac{1}{r^{-}} \\right) = \\frac{a\\cos \\theta}{r^{2}} $$$$ V(P) = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{qa\\cos \\theta}{r^{2}} = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P\\cos \\theta}{r^{2}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{\\vec{P}\\cdot \\hat{r}}{r^{2}} $$ Direttamente proporzionale al momento di tipolo Inversamente proporzionale al quadrato del raggio. Campo elettrico nel dipolo $$ \\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}} \\vec{P} \\cdot \\frac{\\hat{r}}{r^{3}} $$$$ \\vec{E} = -\\vec{\\nabla} V $$Componente parallela üü© $$ \\vec{E} = - \\vec{\\nabla}V = -\\frac{\\delta V}{\\delta x}\\hat{i} -\\frac{\\delta V}{\\delta y}\\hat{j} -\\frac{\\delta V}{\\delta z}\\hat{k} $$ Sappiamo che $\\vec{P} = P\\hat{k}$ e $\\vec{r} = x\\hat{i} + y \\hat{j} + z \\hat{k}$ allora abbiamo che $\\vec{P} \\cdot \\vec{r} = Pz$ Poi abbiamo che $z = r \\cos \\theta$\n$$ E_{z} = - \\frac{\\delta V}{\\delta z} = -\\frac{\\delta}{\\delta z} \\left[ \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Pz}{(x^{2} + y^{2} + z^{2})^{3/2}} \\right] = -\\frac{P}{4\\pi\\varepsilon_{0}}\\left[ \\frac{1}{(x^{2} + y^{2} + z^{2})^{3/2}} + z \\left( -\\frac{3}{2} \\right) \\frac{2z}{(x^{2} + y^{2} + z^{2})^{5/2}} \\right] $$$$ = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P}{r^{3}}\\left[ \\frac{3z^{2}}{r^{2}} - 1 \\right] = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P}{r^{3}}\\left[ \\frac{3r^{2} \\cos ^{2} \\theta}{r^{2}} - 1 \\right] = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P}{r^{3}}\\left[ 3 \\cos ^{2} \\theta - 1 \\right] $$ Nota : $E_{z} = E_{\\parallel}$ dato che √® parallela al dipolo.\nComponente perpendicolare üü®+ $$ E_{\\perp} = \\sqrt{ E_{x}^{2} + E_{y} ^{2} } $$$$ E_{x} = - \\frac{\\delta V}{\\delta x} = \\frac{\\delta}{\\delta x} \\left[ \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Pz}{(x^{2} + y^{2} + z^{2})^{3/2}} \\right] = -\\frac{Pz}{4\\pi\\varepsilon_{0}}\\left[ -\\frac{3}{2} \\frac{2x}{r^{5}} \\right] = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{3xPz}{r^{5}} $$$$ E_{y} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{3yPz}{r^{5}} $$$$ E_{\\perp} = \\frac{3}{4\\pi\\varepsilon_{0}} \\frac{Pz}{r^{5}}\\sqrt{ y^{2} + x^{2} } = \\frac{3}{4\\pi\\varepsilon_{0}} \\frac{P}{r^{5}}r\\sin \\theta \\, r\\cos \\theta = \\frac{3}{4\\pi\\varepsilon_{0}} \\frac{P}{r^{3}}\\sin \\theta \\, \\cos \\theta $$ Passaggi sopra sono giustificati perch√© $\\sqrt{ y^{2} + x^{2}} = r \\sin \\theta$ e anche che $z = r\\cos \\theta$ Che ha senso perch√© c\u0026rsquo;√® simmetria circolare su quel piano. E vale praticamente per ogni punto nello spazio.\nAnalisi dei risultati (non fare) $$E_{\\parallel} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{2P}{r^{3}} $$ Quindi √® positivo, il campo.\n$$ E_{\\perp} = -\\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P}{r^{3}} $$ Che √® coerente col risultato che abbiamo calcolato tempo fa.\nEsercizio: In quale angolo si annulla $E_{\\parallel}$ (analiticamente, basta l\u0026rsquo;angolo che annulla $3 \\cos ^{2} \\theta - 1$) Che √® uguale a 54.71 gradi. Domanda: perch√© si annulla in qu\nCon coordinate polari üü• $$ E = \\frac{p}{4\\pi\\varepsilon_{0}r^{3}}(2\\cos \\theta \\hat{r}+ \\sin \\theta \\hat{\\theta}) $$Si pu√≤ riscrivere anche il momento di dipolo in coordinate polari, e questo permette una scrittura ancora pi√π clean, in cui risalta che √® la componente radiale del momento di dipolo la parte di interesse nella relazione:\n$$ \\vec{p} = p\\cos \\theta \\hat{r} - \\sin \\theta \\hat{\\theta} $$$$\\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}r^{3}}(3p\\cos \\theta \\hat{r} - \\vec{p} )$$Dipolo immerso in campo elettrico NOTA: Posso assumere il valore di $\\vec{E}$ come costante sulle due cariche perch√© tanto varia molto molto poco. Anche se non ho capito esattamente il ragionamento.\nSupponiamo che la carica negativa sia posta su $\\vec{r}$ quindi il sistema di riferimento √® qualunque e che $r \\gg a$. Energia potenziale del dipolo üü© $$ U(P) = qV(\\vec{r} + \\vec{a}) - qV(\\vec{r}) = q\\left[ V(x + a_{x}, y + a_{y}, z + a_{z}) - V(x, y, z) \\right] $$$$ U(P) = q \\, dV(x, y, z) $$$$ dV = \\frac{\\delta V}{\\delta x}dx + \\frac{\\delta V}{\\delta y}dy + \\frac{\\delta V}{\\delta z}dz = \\frac{\\delta V}{\\delta x}a_{x} + \\frac{\\delta V}{\\delta y}a_{y} + \\frac{\\delta V}{\\delta z}a_{z} =-E_{x}a_{x} -E_{y}a_{y} -E_{z}a_{z} $$$$ U(P) = q(-E_{x}a_{x} -E_{y}a_{y} -E_{z}a_{z}) = - P_{x}E_x - P_{y}E_y - P_{z}E_z = -\\vec{P} \\cdot \\vec{E} = - PE\\cos \\theta $$ Mentre 0 allora l\u0026rsquo;energia √® minima (se √® minima allora √® stabile in meccanica poi, seguendo questa giustificazione, allora diventa stabile quando $\\theta = 0 deg$ quindi tende a stare parallelo al campo. L\u0026rsquo;equilibrio √® instabile se √® diverso da 0 gradi. Stabile se √® 0\nMomento di dipolo üü© $$ \\vec{F}_{T} = q\\vec{E}_{+} - q\\vec{E}_{-} = 0 \\iff \\vec{E}_{+} =\\vec{E}_{-} = \\vec{E} $$$$ \\vec{M}_{T} = \\vec{r}_{+}\\times \\vec{F}_{+} + \\vec{r}_{-}\\times \\vec{F}_{-} = \\vec{r}_{+}\\times q\\vec{E} - \\vec{r}_{-}\\times q\\vec{E} = (\\vec{r}_{+} - \\vec{r}_{-})\\times q\\vec{E} = \\vec{a} \\times q\\vec{E} = \\vec{P} \\times \\vec{E} $$$$ \\lvert \\vec{M}_{T} \\rvert = PE\\sin \\theta $$$$ \\vec{M} = \\vec{P} \\times \\vec{E} $$Distribuzione di carica Prendiamo una distribuzione di carica qualunque nello spazio, di dimensione $d$ massima #### Momento di dipolo elettrico del sistema #### Potenziale di sistema üü®+ Abbiamo che $\\vec{r} = \\vec{r}_{i} + \\vec{d}_{i}$, allora posso assumere che $\\vec{r}$ e $\\vec{r}_{i}$ siano paralleli e dire che $$ r_{i} = r - d_{i}\\cos \\theta_{i} = r - \\vec{d}_{i} \\cdot \\hat{r} $$ E con questo possiamo semplificare molte cose, ma guardiamo: $$ V(P) = \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}}{r_{i}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}}{r - \\vec{d}_{i}\\hat{r}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}(r + \\vec{d}_{i}\\hat{r})}{r^{2} - d_{i}^{2}} \\approx \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}(r + \\vec{d}_{i}\\hat{r})}{r^{2}} $$ Per concludere definisco $\\vec{P} = \\sum_{i=1}^{N}q_{i}\\vec{d}_{i}$ questo √® il momento di dipolo elettrico del sistema, perch√© sto semplicemente sommando il dipolo di tutte le singole cariche.\n$$ V(P) = \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}}{r} + \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}\\vec{d}_{i}\\hat{r}}{r^{2}} \\frac{Q}{4\\pi\\varepsilon_{0}r} + \\frac{\\vec{P} \\cdot \\hat{r}}{4\\pi\\varepsilon_{0}r^{2}} $$ Il primo di questi si chiama termine di monopolo $V_{0}$, mentre il secondo √® il termine di dipolo $V_{DP}$. Il primo spiega Potenziale con s√© stesso al centro, indipendente dalla distribuzione. Come se stessi ammassando tutta la carica in un punto e calcolando il potenziale l√¨. Il secondo termine mi d√† informazioni del potenziale al variare della distribuzione di carica. (concettualmente dice prof. Zoccoli che questo √® equivalente alla torque nei corpi rigidi, che concentri tutta la massa sull\u0026rsquo;asse per calcolare la torque)\nConseguenza importante: Anche un atomo neutro pu√≤ generare un campo elettrico nello spazio, che √® dato dal termine di dipolo\nMonopolo vs Dipolo grandezza üü©\u0026ndash; $$ \\lvert \\vec{P} \\rvert = \\left\\lvert \\sum_{i} q_{i}\\vec{d}_{i} \\right\\rvert \\approx \\left\\lvert \\sum_{i} q_{i} \\right\\rvert d = Qd $$$$ \\frac{V_{DP}}{V_{O}} = \\frac{Qd}{4\\pi\\varepsilon_{0}r^{2}} \\frac{4\\pi\\varepsilon_{0}r}{Q} = \\frac{d}{r} \\ll 1 $$ Ma nel caso in cui √® neutro, allora l\u0026rsquo;unico campo che c\u0026rsquo;√® √® il termine di dipolo! Quindi bisogna contare per avere il campo.\nTermine dipolo nullo üü© $$ Q_{T} = 0 = Q_{+} + Q_{-} = \\sum_{i}\\lvert q_{i}^{+} \\rvert - \\sum_{i}\\lvert q_{i}^{-} \\rvert $$$$ \\vec{P} = \\sum_{i}^{N}q_{i}\\vec{a}_{i} = \\sum_{i}^{N}\\lvert q_{i}^{+} \\rvert \\vec{d}_{i}^{+} - \\sum_{i}^{N} \\lvert q_{i}^{-} \\rvert \\vec{d}_{i}^{-} $$$$ \\vec{d}^{+} = \\frac{1}{Q}\\sum_{i=1}^{N} \\lvert q_{i}^{+} \\rvert \\vec{d}_{i}^{+} $$$$ \\vec{P} = Q\\vec{d}^{+} - Q\\vec{d}^{-} = Q(\\vec{d}^{+} - \\vec{d}^{-}) = Q\\vec{\\delta} $$ Ossia il termine di dipolo si pu√≤ riassumere come differenza del centro fra le cariche positive e negative. Se non hanno stesso centro allora ho un campo elettrico (questo √® coerente col caso classico di dipolo a due cariche!). E questo √® vero sempre! √® anche il motivo per cui l\u0026rsquo;acqua √® carica, perch√© ha un momento di dipolo!\n","permalink":"https://flecart.github.io/notes/dipolo-elettrico/","summary":"\u003cp\u003eQuesto problema √® stato trattato in modo un po\u0026rsquo; pi√π semplificato (nel caso in cui la carica era esattamente a met√† in \u003ca href=\"/notes/campo-elettrico/#dipolo-elettrico\"\u003eCampo elettrico#Dipolo elettrico\u003c/a\u003e).\nQuesto problema √® stato storico, utilizzato per analizzare l\u0026rsquo;atomo.\u003c/p\u003e\n\u003ch3 id=\"potenziale-del-dipolo-elettrico---\"\u003ePotenziale del dipolo elettrico üü©\u0026ndash;\u003c/h3\u003e\n\u003cimg src=\"/images/notes/Momento di dipolo-1698054569445.jpeg\" alt=\"Momento di dipolo-1698054569445\"\u003e\n$$\nV(P) = V_{r^{+}} + V_{r^{-}} = \\frac{q}{4\\pi\\varepsilon_{0}}\\left( \\frac{1}{r^{+}} - \\frac{1}{r^{-}} \\right)\n$$$$\nr^{+} - r^{-} = -a \\cos \\theta\n$$$$\n\\left( \\frac{1}{r^{+}} - \\frac{1}{r^{-}} \\right) = \\frac{a\\cos \\theta}{r^{2}}\n$$$$\nV(P) \n= \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{qa\\cos \\theta}{r^{2}}\n= \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P\\cos \\theta}{r^{2}}\n= \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{\\vec{P}\\cdot \\hat{r}}{r^{2}}\n$$\u003col\u003e\n\u003cli\u003eDirettamente proporzionale al momento di tipolo\u003c/li\u003e\n\u003cli\u003eInversamente proporzionale al quadrato del raggio.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"campo-elettrico-nel-dipolo\"\u003eCampo elettrico nel dipolo\u003c/h3\u003e\n$$\n\\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}} \\vec{P} \\cdot \\frac{\\hat{r}}{r^{3}}\n$$$$\n\\vec{E} = -\\vec{\\nabla} V\n$$\u003ch4 id=\"componente-parallela-\"\u003eComponente parallela üü©\u003c/h4\u003e\n$$\n\\vec{E} = - \\vec{\\nabla}V = -\\frac{\\delta V}{\\delta x}\\hat{i}  -\\frac{\\delta V}{\\delta y}\\hat{j} -\\frac{\\delta V}{\\delta z}\\hat{k}\n$$\u003cp\u003e\nSappiamo che $\\vec{P} = P\\hat{k}$ e $\\vec{r} = x\\hat{i} + y \\hat{j} + z \\hat{k}$ allora abbiamo che $\\vec{P} \\cdot \\vec{r} = Pz$\nPoi abbiamo che $z = r \\cos \\theta$\u003c/p\u003e","title":"Dipolo elettrico"},{"content":"The DP (Dirichlet Processes) is part of family of models called non-parametric models. Non parametric models concern learning models with potentially infinite number of parameters. One of the classical application is unsupervised techniques like clustering. Intuitively, clustering concerns in finding compact subsets of data, i.e. finding groups of points in the space that are particularly close by some measure.\nThe Dirichlet Process See Beta and Dirichlet Distributions for the definition and intuition of these two distributions. One quite important thing that Dirichlet allows to do is the ability of assigning an ever growing number of clusters to data. This models are thus quite flexible to change and growth.\nDefinition of the process $$ G \\sim DP(\\alpha, H) $$$$ G(\\Theta_{1}), G(\\Theta_{2}), \\dots \\sim \\text{Dir}(\\alpha H(\\Theta_{1}), \\alpha H(\\Theta_{2}), \\dots) $$ So they are jointly distributed as a Dirichlet distribution. And $H$ is called the base measure and $\\alpha$ is called the concentration parameter.\nThe base measure $H$ represents our prior belief about the distribution of the data. $\\alpha$ is called concentration parameter: $\\alpha$ is small, the resulting distributions tend to concentrate on fewer clusters, effectively encouraging sparsity. Conversely, a larger $\\alpha$ allows for a richer, more diverse set of clusters.\nChoosing number of Clusters Dirichlet processes are related to finding the best number of clusters (See Clustering). It is a non-parametric way (meaning it can grow with the data) to find that number.\nStick Breaking üü®++ We have dome something similar to $GP$ in Gaussian Processes: the difference is sequential sampling compared to sampling all of the points at once using the difficult multivariate distribution.\nWe would like to sample $(\\rho_{1}, \\dots, \\rho_{k}) \\sim \\text{Dir}(\\alpha_{1}, \\dots, \\alpha_{k})$. So now we just sample the first $\\rho_{1}$ and then sample the second conditioned on the first observation (So we have a beta distribution now) and so on, until we finish the possible clusters.\nImage from the slides. Griffiths-Engen-McCloskey distribution üü®++ This distribution is just a generalization of the stick breaking process. We write $\\rho \\sim GEM(\\alpha)$ which means breaking according the distribution $\\text{Beta}(1, \\alpha)$. if alpha is smaller then the stick is longer. So we can interpret the parameter $\\alpha$ as some sort of variable of the remaining stick length.\nUsing the above image, we can define the stick breaking patterns using constant values $1, \\alpha$, which correspond to GEM distribution, a dirichlet process with concentration measure $\\alpha$ and base measure $H$.\nDe Finetti\u0026rsquo;s theorem üü®\u0026ndash; $$ p(X_{1}, \\dots, X_{n}) = p(X_{\\sigma(1)}, \\dots, X_{\\sigma(n)}) $$ with $\\sigma$ a permutation of the set $\\{1, \\dots, n\\}$.\n$$ p(X_{1}, \\dots, X_{n}) = \\int \\left( \\prod_{i = 1}^{n} p(x_{i} \\mid G) \\right) \\, dG $$ Which means we can decompose the infinite exchangeable sequence into independent conditional random variables.\nIn the context of CRP and Urns, this property allows us to count the probability of ending into a specific number of clusters, each with some number of elements.\nClassical Combinatorial problems The Chinese Restaurant Process üü®++ We have some customers (observations) $x^{(i)}$ assigned to some clusters $k$. Then we have the Matthew effect: more people in a table makes it more probable to seat there. Or some probability to create a new table $\\propto \\alpha$.\n$$ p(\\tau = k \\mid \\tau_{1}, \\dots, \\tau_{n}) = \\begin{cases} \\frac{\\lVert \\tau \\rVert}{n + \\alpha} \u0026 \\text{ if } \\tau \\in \\mathcal{P} \\\\ \\frac{\\alpha}{n + \\alpha} \u0026 \\text{otherwise} \\end{cases} $$$$ P(\\mathcal{P}) = \\frac{\\alpha^{\\lvert P \\rvert }}{\\alpha^{(n)}} \\prod_{\\tau \\in \\mathcal{P}} (\\lvert \\tau \\rvert - 1)! $$ We can do this because it is order and labeling-independent. With this model, we can show that the expected number of table is in the order of $\\mathcal{O}(\\alpha \\log(N))$ In economy, this effect is called rich get richer because more popular cluster are able to attract more points into it.\nRate of increase of the number of tables üü® $$ \\mathbb{E}[K_{n} - K_{n - 1}] = \\mathbb{E}[\\mathbb{1}_{n}] = \\frac{\\alpha}{n + \\alpha} $$$$ \\mathbb{E}[K_{n}] = O( \\alpha \\log(n)) $$ This is a simple consequence of the bound of the harmonic series. See Serie.\nP√≥lya Urns üü© We have urns with colored balls that can be drawn at random. If a ball is drawn it is doubled and put both back into the Urn. We can prove that this is equivalent to the Chinese Restaurant Process, given a finite number of clusters (colors). The important part is that this is exchangeable.\nHoppe Urn üü© This is a variation of the P√≥lya\u0026rsquo;s urn. Here we have a special ball that when it\u0026rsquo;s picked it is put back into the urn but also a new color is put back! Then this model is exactly the same as the Chinese Restaurant Process. It should be a nice exercise to prove this.\nWe can interpret the random variable $G$ in De Finetti\u0026rsquo;s theorem as a single sample from the an underlying Dirichlet Process. After we have sampled this (which is a prior, it is like we are sampling hyperparameters), then we use CRP to assign the points to the clusters.\nThe DP Mixture Model The model üü® We have the probability of the clusters\n$\\rho = (\\rho_{1}, \\dots) \\sim GEM(\\alpha)$ and alpha is chosen appropriately with some validation. $\\mu_{k} \\sim \\mathcal{N}(\\mu_{0}, \\sigma_{0}^{2})$ are the centers of the clusters. We draw some assignments to the clusters with a categorical distribution based on $\\rho$. We call these $z_{i}$. We points $x_{i} \\sim \\mathcal{N}(\\mu_{i}, \\sigma^{2})$, based on the above cluster parameters. The easy way to remember this model is with a graphical model: $\\alpha \\to \\rho \\to z, \\mu \\to H, (z, H) \\to x$\nFitting a learner üü• EM (see Clustering) are difficult to use for non-parametric models. We will use Gibbs Sampling introduced in Monte Carlo Methods.\n$$ p(z_{i} =k \\mid z_{-i}, \\boldsymbol{x}, \\alpha, \\boldsymbol{\\mu}) \\propto p(z_{i} \\mid z_{-i}, \\alpha) \\cdot p(x_{i} \\mid \\boldsymbol{z}, \\boldsymbol{x}_{-i}, \\boldsymbol{\\mu}) $$ And then we have the probabilities in the image.\nCode Example just run it on a Notebook. I noticed that if we initialize the code with all classes assigned to a single cluster, the model seems to fail to learn that there are other classes, this is probably because the rich get richer effect is not enough to explore the space of the clusters. If we initialize the code with a random assignment on the maximum number of clusters, then it doesn\u0026rsquo;t seem to be able to eliminate clusters correctly. It is quite probable that we would need to tune for the $\\alpha$ value, but it is probably quite time consuming to find one.\nA More Detailed Walk-Through üü®\u0026ndash; Let‚Äôs outline the steps more algorithmically:\nInitialization:\nInitialize the cluster assignments $z_i$ arbitrarily (for example, each data point in its own cluster or by some heuristic). For each unique cluster, initialize the parameter $\\theta_k$ by drawing from $G_0$ or by using an initial estimate from the assigned data. Gibbs Sampling Loop: For each iteration, and for each data point $y_i$: a. Remove $y_i$ from its current cluster:\nAdjust the counts $n_{-i,k}$ for the cluster $k$ that $y_i$ belonged to. If this removal makes the cluster empty, remove the cluster altogether. b. Compute assignment probabilities:\nFor each existing cluster $k$: $$ p_k \\propto n_{-i,k} \\, f(y_i \\mid \\theta_k). $$ For a new cluster: $$ p_{\\text{new}} \\propto \\alpha \\, m(y_i), \\quad \\text{where } m(y_i)=\\int f(y_i \\mid \\theta) \\, dG_0(\\theta) $$ is the marginal likelihood for $y_i$ under the base measure. c. Sample a new assignment for $y_i$ from the discrete distribution defined by $\\{p_k, p_{\\text{new}}\\}$. d. If a new cluster is chosen: Draw a new parameter $\\theta_{\\text{new}}$ from the posterior given $y_i$ (or directly from $G_0$ if you wish to assign it prior to any data update). e. Update Cluster Parameters:\nFor each cluster $k$, sample $$ \\theta_k \\sim p(\\theta_k \\mid \\{y_i : z_i = k\\}). $$ Convergence and Inference: After a sufficient number of iterations, the samples of $\\{z_i\\}$ and $\\{\\theta_k\\}$ represent draws from the posterior distribution of the DP mixture model. You can then estimate cluster structures, predictive densities, or other quantities of interest.\nDrawbacks of Dirichlet We provide here a summary of the main drawbacks of the Dirichlet Process:\nCategory Drawback Growth Assumptions Logarithmic growth may not fit real-world data Cluster Size Bias Overemphasis on large clusters; poor handling of outliers Hyperparameter Sensitivity Choice of $\\alpha$ and $G_{0}$ (Base Measure)‚Äã affects clustering Inference Complexity MCMC/Variational methods are computationally expensive Exchangeability Assumption Fails for temporally or spatially structured data Expressiveness Limited ability to handle complex or hierarchical data relationships Scalability Standard DP methods struggle with large datasets Task Restriction Primarily a clustering tool, requiring extensions for other tasks We observe that the main points are the exchangeability assumption, the growth assumptions (in real life some clusters may grow linearly or exponentially), and the scalability.\n","permalink":"https://flecart.github.io/notes/dirichlet-processes/","summary":"\u003cp\u003eThe DP (Dirichlet Processes) is part of family of models called \u003cstrong\u003enon-parametric\u003c/strong\u003e models.\nNon parametric models concern learning models with potentially infinite number of parameters.\nOne of the classical application is unsupervised techniques like clustering.\nIntuitively, clustering concerns in finding \u003cem\u003ecompact subsets\u003c/em\u003e of data, i.e. finding groups of points in the space that are particularly close by some measure.\u003c/p\u003e\n\u003ch3 id=\"the-dirichlet-process\"\u003eThe Dirichlet Process\u003c/h3\u003e\n\u003cp\u003eSee \u003ca href=\"/notes/beta-and-dirichlet-distributions/\"\u003eBeta and Dirichlet Distributions\u003c/a\u003e for the definition and intuition of these two distributions.\nOne quite important thing that Dirichlet allows to do is the ability of assigning an ever growing number of clusters to data. This models are thus quite flexible to change and growth.\u003c/p\u003e","title":"Dirichlet Processes"},{"content":"We want to know how to handle systems that have a large number of data. In previous lesson we have discovered how to quickly access and make Scalable systems with huge dimensions, see Cloud Storage. Object storage could store billions of files, we want to handle millions of petabyte files.\nDesigning DFSs The Use Case Remember that the size of the files where heavily limited for Cloud Storage. The physical limitation was due to the limited size of a single hard disk, which was usually in the order of the Terabytes. Here, we would like to easily store petabytes of data in a single file, for example big datasets. Another feature that should be easily supported is highly concurrent access to the filesystem, last but not least being able to set up permissions in the system.\nDesiderata of distributed file systems üü© In this case we have a Filesystem. In 2004 google created his own FS. With hundreds or thousands of machines the systems are practically guaranteed to fail. This leads to a requirement of\nfault tolerance We need to detect these errors so we need monitoring and error detection we would like the system to be self-regulatory and have the ability of automatic recovery Efficiency in operations üü®\u0026ndash; HDFS is designed primarily for write-once, read-many access patterns typical of big data processing workloads. We will later see that MapReduce works quite well with this methods.\nWe want to be efficient in\nScanning the file Appending information to file atomically So that we can have a temporary place for intermediate data or sensors or logs. This needs to be very efficient for appends. Immutability is ok in this case. Latency should not be the bottleneck (with plenty of small files we are losing a lot of files to lookup) but throughput should be the bottleneck. This is why the Distributed File System that we will be studying is optimized for high-throughput data processing rather than low-latency access to small files.\nHadoop Primarily:\n‚Ä¢ Distributed File System (HDFS)\n‚Ä¢ MapReduce\n‚Ä¢ Wide column store (HBase)\nStarting form 188 in 2006 when the filesystem has been developed, now it should handle more about 100k files, about 600PB of data!\nWe will start first by looking at the logical model and then to the physical model, following Codd\u0026rsquo;s data independence idea (Codd 1970).\nThe logical model In this case we have a file hierarchy. And we have block storage (also called chunk, split, shard, partition) instead of unstructured object storage we studied in Cloud Storage#Object Stores, which are seen as a single big object. These documents have a far larger block size, usually of 64-128MB. We have 64 for Google and 128 for Hadoop. In Hadoop, blocks are files, so we don\u0026rsquo;t have fragmentation on the filesystem. This is because on a network cable having many files takes more time than a single bigger file, because of the latency. of file disk seeks. There are also other reasons it might be advantageous having this block size:\nLimit metadata on NameNode about every block Client need to interact less with the NameNode. Limit the number of TCP connections that the Client would need to open for each data block on the datanodes. Just few persistent TCPs are ok. See Livello di trasporto for TCP. The architecture üü© With HDFS we have a centralized architecture where we have a main node, called Coordinator, Primary, Leader, NameNode and then secondary nodes called Worker, Secondary, Follower, DataNodes.\nWhen we have a file, we split it into chunks and store it multiple times (3) into different machines. RAID is redundant in this case, so we won\u0026rsquo;t use it, see Devices OS#RAID for more information.\nThe physical model Structure of the NameNode üü® Mapping of file -\u0026gt; Block. Block -\u0026gt; Locations on nodes. State of the blocks (corrupted updated). and permissions. ACL information and filesystem information. More in particular:\nthe file namespace, that is, the hierarchy of directory names and file names, as well as any access control (ACL) information similar to Unix-based systems. a mapping from each file to the list of its blocks. Each block, in this list, is represented with a 64-bit identifier; the content of the blocks is not on the NameNode. Blocks are local files. to the locations of its replicas, that is, the list of the DataNodes that store a copy of this block. The NameNode never initiates connection with the DataNode. It can just answer to DataNodes\u0026rsquo; heartbeats.\nStructure of the DataNode üü©\u0026ndash; One important fact that the DataNode has to handle are the heartbeats. These are small communications that the DataNode sends to the NameNode that serve mainly two roles:\nLiveness: to make known that everything is all right, that the node is still alive and running (peculiar observation is that also human communication frequency has something related to this), If no hearthbeat is receaved in 10 minutes (Shvachko et al. 2010), then the node is considered dead. Occasionally, contain information about storage of blocks, like the ACKs for successful storage. It can also contain notification of block corruptions, so that the namenode knows it can add it to the list of nodes that contain that block. This is usually done once every 3 seconds but can be configured. Along side this pattern, the DataNode also sends every six hours (configurable) a full report of every block that it contains. Another responsibility of the DataNode is the replication pipeline. When it receives a file, it should replicate it to the other nodes.\nThe file systems operations Read üü© The client asks the NameNode for the blocks and DataNodes. The NameNode answers with the list of each block of the file and the DataNodes that store it ordered from distance to the client. Then the client asks the DataNodes for the files, which is usually a stream of bytes. It downloads every block in turn. It is informative to think about the interaction between HBase and HDFS. [\u0026hellip;] Who is the client here? The RegionServer, which does co-habit with a DataNode. [\u0026hellip;] This makes accessing the KeyValues in future reads by the RegionServer extremely efficient, because the RegionServer can read the data locally¬†without communicating with the NameNode: this is known as short-circuiting in HDFS.\nWrite üü© This operations is a little bit more complex and needs many machines to be organized with each other:\nThe client first locks the file that he\u0026rsquo;s writing. The client asks the NameNode for each block a series of DataNodes with which he can initialize connection. Then client instructs the given DataNodes to create the replication pipeline Then client sends the block and waits for acks by the DataNodes (only this part is syncronous for the client I think). This is done for every block of the file, when it\u0026rsquo;s finished the client tells the NameNode to release the lock. After a bit of time the NameNode should receive information about correct storage by the DataNodes, and checks if every replica is ok, and gives ACK to the client. and it is finished\u0026hellip; Then if one gets corrupted the NameNode automatically regulates the replicas Replication strategy üü©\u0026ndash; Blocks are replicated with some general guidelines in mind. There is first a notion of distance from nodes that is defined by a physical connection distance:\n2: if the two nodes are in the same rack 4: if they are in different racks There is a general guideline that each node should have at maximum a single replica, and each rack should have at maximum two replicas. Usually the node that processes the request stores a version, then it stores replicas in two nodes in a rack different from the one that is processing the current version. The number of replicas to store is handled by a parameter called replication factor.\nUsually the replication is node in this manner:\nIn the same node that receives the request On two different nodes on another rack The fourth, if present, is on a random node. The reason why two replicas are usually not put on the same node, is that it would become too concentrated.\nHigh Availability One clear pain point of the current design is the single point of failure of the system: if a NameNode corrupts the data or fails irrecoverably, then the whole system would become unusable. One clearly wants to prevent this from happens. This leads to the idea of logs and namespace files.\nSnapshots üü© If the NameNode crashes, then everything could be lost, the whole cluster would be useless because we don\u0026rsquo;t have a way to recover the mappings between the block ids and the files. For this reason a snapshot (namespace file), which contains all the relevant information for a NameNode to work, is usually created and stored on some persistent storage or backed using Cloud Storage options.\nLogs üü© We also need to balance the creation of snapshots and the number of updates. It would be quite infeasible to create a whole new snapshot after every update, yet at the same time we need to track every change to avoid to lose any.. This brings up the use of logs for every change, that act as a diff file for every single change that has not been saved in the snapshot (when we need to restore, we reapply every single registered change in order to return back to the same state, it usually takes 30 minutes to restore from a crash).\nCheckpointing üü© When a merge happens this is called a checkpoint, which happens in a periodical fashion. (or could also be manually triggered). The merge is usually done by another node, called phantom node who merges the logs. If the phantom node is configured to take over the main node in case of failure, this is the StandbyNode, explored in a later section.\nThe snapshot and the logs is usually stored externally in a NAS or something similar (e.g. AWS Glacier, latency is OK for backups)\nSpecial NameNodes StandBy NameNodes üü©\u0026ndash; These NameNodes just keep the namespace file updated and up to date without interfering with the main NameNode. Their existence is for high availability of the service, making the system a little more reliable. They do not process write or reads. They just keep reading the edit log and updating the namespace file and the current state of the mappings.\nThere are also other proposals for merging the logs to the snapshot, so that it would not take half an hour to restart the NameNode in the case of a crash, these are called standby NameNodes that keep track of the current mappings between block ids and files.\nUsually these types of NameNodes also receive heartbeats by the NameNodes.\nObserver NameNode üü®++ This is very similar to the standby NameNode, but just handles the Read Request. Clients can connect to the Observer NameNode to know what blocks to read but not write. This is the main different with the StandBy NameNodes: they accept requests, but only reads.\nFederated HDFS üü•\u0026ndash; In these case there are several NameNodes that run at the same time. Each of them has the responsibility for different directories in the filesystem hierarchy. The workload is spread into different nodes. I don\u0026rsquo;t know what happens when a NameNode fails and you cannot access some directories anymore.\nComparison with GFS üü© GFS is another distributed filesystem. The main difference is that the terms are different:\nNameNode - Master DataNode - Chunkserver Block - Chunk FS Image - Checkpoint image Edit log - Operation log Another difference is that the block size is smaller for GFS, in this case 64MB.\nReferences [1] Shvachko et al. ‚ÄúThe Hadoop Distributed File System‚Äù 2010 {{IEEE}} 26th {{Symposium}} on {{Mass Storage Systems}} and {{Technologies}} ({{MSST}}) 2010\n[2] Codd ‚ÄúA Relational Model of Data for Large Shared Data Banks‚Äù Communications of the ACM Vol. 13(6), pp. 377\u0026ndash;387 1970\n","permalink":"https://flecart.github.io/notes/distributed-file-systems/","summary":"\u003cp\u003eWe want to know how to handle systems that have a large number of data. In previous lesson we have discovered how to quickly access and make Scalable systems with huge dimensions, see \u003ca href=\"/notes/cloud-storage/\"\u003eCloud Storage\u003c/a\u003e. Object storage could store billions of files, we want to handle millions of petabyte files.\u003c/p\u003e\n\u003ch3 id=\"designing-dfss\"\u003eDesigning DFSs\u003c/h3\u003e\n\u003ch4 id=\"the-use-case\"\u003eThe Use Case\u003c/h4\u003e\n\u003cp\u003eRemember that the size of the files where heavily limited for \u003ca href=\"/notes/cloud-storage/\"\u003eCloud Storage\u003c/a\u003e. The physical limitation was due to the limited size of a single hard disk, which was usually in the order of the Terabytes.\nHere, we would like to easily store \u003cem\u003epetabytes\u003c/em\u003e of data in a single file, for example \u003cstrong\u003ebig datasets\u003c/strong\u003e.\nAnother feature that should be easily supported is \u003cstrong\u003ehighly concurrent access\u003c/strong\u003e to the filesystem, last but not least being able to set up permissions in the system.\u003c/p\u003e","title":"Distributed file systems"},{"content":"Scalare Scalare e gradiente üü© $$ \\varphi(x, y, z) : \\mathbb{R}^{3} \\to \\mathbb{R} $$$$\\vec{\\nabla}\\varphi = ( \\frac{\\delta\\varphi}{\\delta x}, \\frac{\\delta\\varphi}{\\delta y}, \\frac{\\delta\\varphi}{\\delta z}) = \\frac{\\delta\\varphi}{\\delta x} \\hat{i} + \\frac{\\delta\\varphi}{\\delta y} \\hat{j} + \\frac{\\delta\\varphi}{\\delta z} \\hat{k}$$ Se consideriamo il gradiente da solo √® un campo vettoriale (dice la direzione della derivata multidimensionale).\nGradiente in coordinate polari üü® Questo √® un po\u0026rsquo; pi√π difficile da gestire, per√≤ √® abbastanza facile una volta che si fanno certe osservazioni. Sappiamo che $dV = \\vec{\\nabla} V \\cdot d\\vec{s}$, TODO: finire la dimostrazione, √® descritta bene a pagina 47 del mazzoldi.\nComunque si finisce con\n$$ \\vec{\\nabla} = \\frac{\\delta}{\\delta r} u_{r} + \\frac{1}{r}\\frac{\\delta}{\\delta \\theta}u_{\\theta} + \\frac{1}{r\\sin \\theta}u_{\\phi} $$ A volte questo pu√≤ risultare utile se proviamo a fare cose come calcolare il campo elettrico attraverso il gradiente.\nNOTA: la divergenza per√≤ assume una forma diversa, che non so bene spiegare il motivo in questo momento per√≤.\nGradiente in coordinate cilindriche $$ \\vec{\\nabla} = \\frac{\\delta}{\\delta r} u_{r} + \\frac{1}{r}\\frac{\\delta}{\\delta \\theta}u_{\\theta} + \\frac{\\delta}{\\delta \\phi}u_{\\phi} $$Vettoriale Superfice di separazione üü© Per la definizione di questo, √® chiaro che il flusso su una superficie di separazione √® nulla, quindi posso dividere superfici come mi pare internamente, tanto su queste √® nulla, o posso considerare solamente la superficie pi√π esterna che li racchiude (√® nulla perch√© avr√≤ due versioni uguali e contrarie).\nTODO: scrivere il ragionamento in formule\nIntegrale per un campo: teorema del gradiente üü®++ In analisi abbiamo studiato il teorema di torricelli, ma possiamo estenderlo senza troppa fatica (almeno intuitivamente), nel caso in pi√π dimensioni!\ntorricelli ci dice che (mettere condizioni qui di esistenza integrale) $f(B) - f(A) = \\int _{A}^{B} f'(x) \\, dx$, Poniamo il concetto di differenziale ossia piccolo rettangolino nell\u0026rsquo;integrale di rieman come $df = f'dx$, attraverso questo abuso di notazione, allora diventa molto naturale estenderlo nelle 3 dimensioni come $d\\varphi(x, y, z) = \\vec{\\nabla}\\varphi \\cdot d\\vec{l}$ usando il prodotto scalare, in pratica ho il prodotto scalare amplificato per quello che mi serve. Allora diventa intuitivo che nel caso tridimensionale l\u0026rsquo;integrale sia\n$$ \\varphi(B) - \\varphi(A) = \\int _{A}^{B} \\vec{\\nabla}\\varphi \\cdot d\\vec{l} $$√à da notare che nel nostro caso, se abbiamo un campo conservativo, questo integrale √® dipendente solamente da inizio e fine, non dipende dal percorso, il che implica che il campo √® conservativo.\nTeorema della divergenza (!!) üü©- Dal ragionamento precedente abbiamo capito che potrei dividere la superficie con quante superfici di separazione mi pare, tanto il flusso esterno non cambia, questo mi permette di dividere in tanti volumetti e cercare il flusso con questi volumetti\n$$ \\phi_{s}(\\vec{F}) = \\sum_{i=1}^{N} V_{i} \\frac{\\oint_{\\Sigma} \\vec{F} \\cdot dS_{i}}{V_{i}} $$ Andiamo a chiamare la seconda parte la divergenza di F, e sar√† il flusso per unit√† di volume, vedremo che questa sar√† strettamente vicina al significato di gradiente indicato con nabla. Dato che sto considerando piccolissimi volumi, se la Divergenza √® positiva, significa che c\u0026rsquo;√® del flusso che esce da quel punto si dice che sono delle sorgenti, perch√© generano campo, e solitamente queste sono punti in cui le linee di campo si incontrano. Quando √® uguale a 0 non si dovrebbero incontrare\n$$ \\phi_{S \\text{ chiusa}} = \\oint_{S} \\vec{F} \\cdot d\\vec{s} = \\iiint_{V}(div \\vec{F}) \\, dV = \\iiint_{V} \\vec{\\nabla} \\cdot \\vec{F} \\, dV $$ Che ha il bel risultato di rendere un integrale di superficie (2 dimensioni) come se fosse un integrale di volume. Assumendo il risultato descritto in #Superfice di separazione diventa banale per√≤.\nOsservazione: la divergenza prende in input un campo vettoriale, in output restituisce un campo scalare (che si potrebbe interpretare quasi fosse il modulo del vettore di derivata, con il gradiente ancora scalare).\nOsservazione: questa forma diventa molto pi√π intuitiva se direttamente andiamo a parlare di cubi infinitesimali (Mencuccini spiega per benino sta parte diciamo e arriva subito al risultato, senza passare per il discorso che non ho capito bene sul flusso in una qualunque forma infinitesimale).\nRelazione divergenza e intuizione divergenza (!) üü©+ $$ \\frac{\\oint_{\\Sigma} \\vec{F} \\cdot dS}{dV} = div \\vec{F} = \\text{per il teorema che verr√† dimostrato} = \\vec{\\nabla} \\cdot \\vec{F} $$ A parole: il flusso per unit√† di volume del nostro campo √® uguale al gradiente del campo stesso.\n$$ d\\phi = \\vec{\\nabla}\\cdot \\vec{E} d\\tau \\implies \\vec{\\nabla}\\cdot \\vec{E} = \\frac{d\\phi}{d\\tau} $$ E nella seconda parte abbiamo esattamente il flusso per cubo infinitesimo.\nHint di dimostrazione Mi definisco un cubo, e poi provo ad analizzare il flusso per ogni 6 lato, provo a porre un cubo infinitesimo, e dovrebbe poi tornare Mencuccini pagina 29 √® presente, sul Mazzoldi lo trovi a pagina 79.\nCircuitazione Intuizione di circuitazione e th separazione üü© In questa parte qui ci chiediamo il flusso lungo una linea CHIUSA. Probabilmente sar√† utile per leggi come Lenz o Faraday. Anche in questo caso non ha senso considerare linee di separazione, perch√© avendo direzioni diverse si annullano. (guarda #Superfice di separazione descritto in precedenza.\nDefinizione di circuitazione $$ \\Gamma = \\oint_{L} \\vec{F} \\cdot d\\vec{l} $$ Che possiamo notare essere una forma molto molto simile rispetto a quanto definito per il flusso #Flusso di campo vettoriale.\nPosso fare un giochino (esattamente uguale a quello fatto in precedenza per la divergenza), ma lo faccio per piccole superfici, e flusso che gira attorno a quella superficie allora posso andare a definire il rotore\nIl rotore e teorema di stokes üü©- $$ \\Gamma_{L} = \\sum_{i=1}^{N} \\oint_{L_{i}} \\vec{F} \\cdot d\\vec{l_{i}} = \\sum_{i=1}^{N} \\frac{ \\oint_{L_{i}} \\vec{F} \\cdot d\\vec{l_{i}}}{S_{i}} S_{i} $$$$\\frac{ \\oint_{L_{i}} \\vec{F} \\cdot d\\vec{l_{i}}}{s_{i}} = \\vec{rot} \\vec{F} \\cdot \\hat{n} $$Che intuitivamente √® la circuitazione infinitesimale.\nQuesto √® fatto a pagina 52\nTeorema di stokes $$ \\oint \\vec{F} \\cdot d\\vec{l} = \\iint_{S_{L}} \\vec{rot} \\vec{F} \\cdot \\hat{n} \\, ds $$ Questo √® il teorema di stokes, e si pu√≤ applicare per qualsiasi circuitazione, per qualsiasi superficie che ha come contorno alla fine L.\nRotore dimostrazione üü© In questa parte proviamo ad esplorare la relazione che c\u0026rsquo;√® fra il rotore, come l\u0026rsquo;abbiamo definito di sopra, e la divergenza.\n$$ \\oint \\vec{F} \\cdot d\\vec{l} = \\int _{A}^{B}F(x, y_{0}) \\, dx + \\int _{B}^{C}F(x_{0} + \\Delta x, y) \\, dy + \\int _{C}^{D}F(x, y_{0} + \\Delta y) \\, dx + \\int _{D}^{A}F(x_{0}, y) \\, dy $$$$ \\oint \\vec{F} \\cdot d\\vec{l} = \\Delta x F(\\hat{x}, y_{0}) + \\Delta y F(x_{0} +\\Delta x, \\hat{y}) - \\Delta x F(\\hat{x}, y_{0} + \\Delta y) - \\Delta y F(x_{0}, \\hat{y}) $$$$ \\Gamma = -\\Delta x \\left[ \\frac{\\delta F_{x}}{\\delta y} \\Delta y \\right] + \\Delta y \\left[ \\frac{\\delta F_{y}}{\\delta x} \\Delta x \\right] \\implies \\Delta x\\Delta y \\left( \\frac{\\delta F_{y}}{\\delta x} - \\frac{\\delta F_{x}}{\\delta y} \\right) $$ Si pu√≤ notare che se intendiamo questo come sopra, durante la dimostrazione per il #Teorema di stokes, allora $\\Delta x \\Delta y$ √® esattamente la superficie, orientata secondo $\\hat{n}$, mentre, proprio per matching dei parametri, il rotore diventa $rot \\vec{F} = \\left( \\frac{\\delta F_{y}}{\\delta x} - \\frac{\\delta F_{x}}{\\delta y} \\right)$ in questo caso, si potrebbe dire da un punto di vista a tre dimensioni, se avessimo il nostro quadratino in pi√π dimensioni allora che\n$$ \\vec{rot}\\vec{F} = \\left( \\frac{\\delta F_{z}}{\\delta y} - \\frac{\\delta F_{y}}{\\delta z} \\right) \\hat{i} + \\left( \\frac{\\delta F_{x}}{\\delta z} - \\frac{\\delta F_{z}}{\\delta x} \\right) \\hat{j} + \\left( \\frac{\\delta F_{y}}{\\delta x} - \\frac{\\delta F_{x}}{\\delta y} \\right) \\hat{z} = \\vec{\\nabla} \\times \\vec{F} $$Si pu√≤ notare che questo √® strettamente legato al concetto di velocit√† angolare.\nDivergenza del rotore (!) üü© $$ \\oint_{S} (\\vec{\\nabla} \\times \\vec{F}) d\\vec{s} = \\iiint_{V} div (\\vec{\\nabla} \\times \\vec{F}) d\\vec{s} = \\iiint_{V} \\vec{\\nabla} \\cdot (\\vec{\\nabla} \\times \\vec{F}) d\\vec{s} = 0 $$ L\u0026rsquo;ultima uguaglianza lo abbiamo per cauchy, perch√© avremo delle derivate seconde, che si eliminano tutte fra di loro\nFisicamente forse mi sta dicendo che il rotore non crea flusso.\nNote sul gradiente Per qualche motivo √® vero questa cosa:\n$$ dV = \\frac{\\delta V}{\\delta x}dx + \\frac{\\delta V}{\\delta y}dy + \\frac{\\delta V}{\\delta z}dz $$Questo √® un risultato ovvio (che non so perch√© √® ovvio, ma chatGPT https://chat.openai.com/share/c40e539d-9dd2-4bf7-b63d-2fc402751929) e altre ricerche sembrano dire questo del teorema del differenziale totale (che sembra se cercato in inglese ha significato giusto, in italiano diverso boh https://en.wikipedia.org/wiki/Total_derivative).\nComunque √® la base matematica per poter utilizzare il gradiente e scrivere cose come\n$$ dV = \\nabla V \\cdot ds $$ Dove $ds = u_{x}dx + u_{y}dy + u_{z}dz$\n","permalink":"https://flecart.github.io/notes/divergenza-e-circuitazione/","summary":"\u003ch3 id=\"scalare\"\u003eScalare\u003c/h3\u003e\n\u003ch4 id=\"scalare-e-gradiente-\"\u003eScalare e gradiente üü©\u003c/h4\u003e\n$$\n\\varphi(x, y, z) : \\mathbb{R}^{3} \\to \\mathbb{R}\n$$$$\\vec{\\nabla}\\varphi = ( \\frac{\\delta\\varphi}{\\delta x}, \\frac{\\delta\\varphi}{\\delta y}, \\frac{\\delta\\varphi}{\\delta z}) =  \\frac{\\delta\\varphi}{\\delta x} \\hat{i} +  \\frac{\\delta\\varphi}{\\delta y} \\hat{j} + \\frac{\\delta\\varphi}{\\delta z} \\hat{k}$$\u003cp\u003e\nSe consideriamo il gradiente da solo √® un campo vettoriale (dice la direzione della derivata multidimensionale).\u003c/p\u003e\n\u003ch4 id=\"gradiente-in-coordinate-polari-\"\u003eGradiente in coordinate polari üü®\u003c/h4\u003e\n\u003cp\u003eQuesto √® un po\u0026rsquo; pi√π difficile da gestire, per√≤ √® abbastanza facile una volta che si fanno certe osservazioni.\nSappiamo che $dV  = \\vec{\\nabla} V \\cdot d\\vec{s}$, TODO: finire la dimostrazione, √® descritta bene a pagina 47 del mazzoldi.\u003c/p\u003e","title":"Divergenza e Circuitazione"},{"content":"p\u0026gt; Document stores provide a native database management system for semi-structured data. Document stores also scale to Gigabytes or Terabytes of data, and typically millions or billions of records (a record being a JSON object or an XML document).\nIntroduction to Document Stores A document store, unlike a data lake, manages the data directly and the users do not see the physical layout.\nUnlike data lakes, using document stores prevent us from breaking data independence and reading the data file directly: it offers an automatic manager service for semi-structured data that we need to throw and read quickly.\nIn this case, we would like an efficient manner to store documents, as original relational databases did, while offering a relaxed version of the integrity properties.\nThe documents in a document store are organized into collections. Each collection can have millions or billions of documents, while each single document weighs no more than 16 MB. Collections need not to have a schema, but could.\nOn the need of an unstructured document manager üü© In some cases, it is quite easy to convert a tree given in XML or JSON format into a structured format. The problems comes when we have nestedness. For these kind of documents, sometimes is possible to insert them using different tables. Sometimes is possible to insert into relational databases heterogeneous data too. But we need to insert a lot of NULL to make up for the heterogeneity. This creates the kind of impendance mismatch, the difference between the format of data we would like to have, between what we actually store, that adds up a load. In this context, document stores like MongoDB comes naturally into play.\nSize of the documents üü®++ a collection can have millions or billions of documents, while each single document weighs no more than 16 MB\nThis is why document stores can scale up to Gigabytes or terabytes of data. Somewhat similar to HDFS, where each block size had maximum of 128 megabytes. The size limit, is quite close to the limit set by Wide Column Storage of 10 MB.\nEnforcing Schemas üü© Document stores leverage the so called schema on read pattern: the schema is enforced when the data is read, not when it is written. This is a relaxed, more flexible, version of the schema on write pattern, that is used in relational databases. In document stores, the schema is often discovered.\noffer query functionality to find out which keys appear in the data, what kind of value is associated with each key, etc; or even functionality that directly infers a schema\nMongoDB MongoDB is one of the most famous document storage engines. This database management system is more comparable to standard database management systems where ETL is the standard, instead of read from file paradigms like Hadoop or Spark.\nThe Architecture Replication üü®++ If we store petabytes of data, replication is a necessary feature. In MongoDB the collections are partitioned into shards, and each partition has a Replica Set. Each replica set has a primary server and a set of secondary servers. The primary server is the one that accepts write operations, while the secondary servers replicate the data from the primary server. Usually a MongoDBcluster has not many machines.\nWhen writing to the primary servery, a simple optimization is the following: clients may wait only for a certain number of acknowledgements by the second server. Then the other replicas can continue asynchronously. This is for making it faster for the user. This is somewhat similar to the $R$ parameter in Dynamo Cloud Storage#Key-value stores.\nThe main difference with systems like HDFS is that here we have a series of nodes with exactly the same data, while in HDFS, it is quite improbable, as the blocks are replicated independently.\nPhysical Storage üü©\u0026ndash; Documents in MongoDB are usually stored in BSON format, an equivalent method to JSON (see Markup) but in binary format as it is usually more efficient.\nIndices While Spark would look at all the data in parallel to find a single point data for a certain query, the main advantage with ETL (so MongoDBs) is by having the possibility of creating indexes. With indexes we can look data quite faster. We have studied something similar for relational database in Index, B-trees and hashes\nTypes of indices üü© There are mainly two types of indices, hash and B-trees. , both have been extensively studied in this node Index, B-trees and hashes, and it\u0026rsquo;s exactly the same.\nDrawbacks of hash indices\nCannot answer for range queries. Space requirement for collisions. The upside is that this indices are quite fast. If no collisions then it is $\\mathcal{O}(1)$ While B-trees are slower, they can answer range queries. The complexity is $\\mathcal{O}(\\log_{n}(N))$ where $n$ is the branching factor.\nDefault indices üü© MongoDB creates by default a hash indice for the primary key _id.\nBenefiting queries üü© Certain queries can benefit quite more by having indices:\nPoint queries (hash makes this quite fast, while trees make this logarithmic). Range queries Creating an Index üü© If we want a tree index\ndb.collection.createIndex({\u0026#34;field\u0026#34;: 1}) Else:\ndb.collection.createIndex({\u0026#34;field\u0026#34;: \u0026#34;hash\u0026#34;}) Post-filtering üü• If we have a query with some keys that have an index, others that do not have an index MongoDB will first look for the indexed keys, and then post-filter the rest of the keys, making the query faster anyways. Under the hood, it creates many plans, estimates the cost of every plan and then executes one.\nThis is particularly needed for indexes that have more than one index. It is important to remember how the indexes are made!\nOperations Similarly to HTML APIs, MongoDB offers CRUD operations. It is important to know the syntax of these operations.\nRead operations üü® For example:\ndb.collection.find({ \u0026#34;field\u0026#34;: \u0026#34;value\u0026#34;, $or: [ {\u0026#34;field2\u0026#34;: \u0026#34;value2\u0026#34;}, {\u0026#34;field3\u0026#34;: \u0026#34;value3\u0026#34;} ], \u0026#34;field4\u0026#34;: {$gte: 10}, \u0026#34;field5.subfield\u0026#34;: \u0026#34;value4\u0026#34; }).project({field: 1}).sort({\u0026#34;field\u0026#34;: 1}).skip(10).limit(10) We filter the collection by the field value, and we project only the field we are interested in. Having AND conjunctions is easy, just put in the object. Fields that start with \u0026ldquo;$\u0026rdquo; are treated by MongoDB differently. And can encode different operations. Other dollar operations are\n$or, $in, $nin $gte $lt And similar.\nThe Above proejction operator just works for cursors, in our case, the projection is often found inside the find function, as a second argument.\nWe can index into arrays and objects using dot notation inside the find query.\nTo query nested structures we need to use the dot syntax. If we don\u0026rsquo;t do it that way and add a dictionary in the place of value4 instead, it will match exactly the dictionary.\nAggregate queries üü®\u0026ndash; Aggregation query\ndb.collection.aggregate([ {$match: {\u0026#34;field\u0026#34;: \u0026#34;value\u0026#34;}}, {$group: {_id: \u0026#34;$field\u0026#34;, \u0026#34;count\u0026#34;: {$sum: 1}}}, {$sort: {\u0026#34;count\u0026#34;: -1}}, {$limit: 10} ]) Which is very similar to a Spark RDD pipeline.\nInsertion, Update and Delete üü© Insertion is quite straighforward: insertOne:\ndb.collection.insertOne({\u0026#34;field\u0026#34;: \u0026#34;value\u0026#34;}) insertMany:\ndb.collection.insertMany([{\u0026#34;field\u0026#34;: \u0026#34;value\u0026#34;}, {\u0026#34;field\u0026#34;: \u0026#34;value2\u0026#34;}]) There are the same equivalent for update and delete operations.\nThen we attempt to create indices for the most common query searches. It often depends on the query code and the website traffic (if it\u0026rsquo;s a database for a website). But you don\u0026rsquo;t have advantage if you can\u0026rsquo;t fit the indices in the random access memory. Another disadvantage is a slower update: we need to update the index for every update on the table. Just 2ms for a single lookup! Which is much faster than HDFS and Spark.\n","permalink":"https://flecart.github.io/notes/document-stores/","summary":"\u003cp\u003ep\u0026gt; Document stores provide a native database management system for \u003cstrong\u003esemi-structured\u003c/strong\u003e data. Document stores also scale to Gigabytes or Terabytes of data, and typically millions or billions of records (a record being a JSON object or an XML document).\u003c/p\u003e\n\u003ch3 id=\"introduction-to-document-stores\"\u003eIntroduction to Document Stores\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA document store, unlike a data lake, manages the data \u003cem\u003edirectly\u003c/em\u003e and the users do not see the physical layout.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eUnlike data lakes, using document stores prevent us from breaking data independence and reading the data file directly: it offers an automatic manager service for \u003cstrong\u003esemi-structured\u003c/strong\u003e data that we need to throw and read quickly.\u003c/p\u003e","title":"Document Stores"},{"content":"√à una branca dell\u0026rsquo;algebra lineare che ci permette di semplificare tutti i concetti.\nIntro dualit√†üü© \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Programmazione lineare/Untitled 8.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Programmazione lineare/Untitled 8\u0026quot;\u0026gt; Si fa una sorta di trasposta alla matrice di A. y √® pari al numero di righe di A La trasformazione al duale √® molto facile, ed √® abbastanza intuitiva una volta che capiamo che vogliamo andare a fare l‚Äôupper bound.\nDualit√† asimmetrica üü•+ Teorema debole di dualit√† üü© Slide\nQui c\u0026rsquo;√® una cosa simile a quanto fatto in MCMF, il cui massimo di x √® boundato dal minimo del suo duale, in Tarjan e MCMF.\nCorollari di dualit√† (2) üü© Slide\nil fatto che ci sia un bound a x, implica che se x √® illimitato, non posso avere il bound! Abbiamo una condizione di ottimalit√† delle soluzioni trovate! Def Direzioni ammissibili Vogliamo trovare un modo per muoverci e trovare ancora una direzione ottimale!\nDef: un vettore $\\varepsilon \\in \\mathbb{R} ^n$ √® una direzione ammissibile se esiste $\\bar{\\lambda} \u003e 0$ tale che $x(\\lambda) = x + \\lambda \\varepsilon$, per ogni $\\lambda \\in 0...\\bar{\\lambda}$\nIntuizione Ossia se possiamo spostarci di almeno un p√≤ verso la direzione che vogliamo!\nDef direzione di crescita Possiamo considerare una direzione di crescita $\\lambda \\iff cx(\\lambda) = c \\bar{x} + \\lambda c\\varepsilon \u003e c \\bar{x} \\iff c\\varepsilon \u003e 0$\nLa cosa interessante √® che una direzione di crescita cresce indipendentemente dal punto, questo √® una propriet√† molto forte della programmazione lineare! Questi due concetti sono molto utili perch√© una volta che abbiamo una direzione ammissibile e di crescita allora si pu√≤ verificare che si pu√≤ migliorare ancora la soluzione di x.\nSuff e nec per direzione ammissibile Slide L\u0026rsquo;idea principale per questa dimostrazione √® sui vincoli attivi, differenziare se una riga √® un vincolo attivo o meno. Se lo √® allora voglio che sia minore, altrimeni basta scegliere un intorno sufficientemente piccolo perch√© il vincolo √® stretto.\nDa notare che se non √® un vincolo attivo allora ho una disuguaglianza stretta allora posso andare ad utilizzare cose di analisi\nOttimalit√† del punto Dato un punto $x$ ammissibile, questo punto √® ottimo sse non ci sono direzioni di crescita ammisibile\nIntuizione sulla dimo\n‚Üí se √® gi√† ottimo allora se esistessa una direzione di crescita, si potrebbe far crescere ancora il nostro punto di ottimo, violando l‚Äôipotesi di ottimalit√†\n‚ÜêSe non ho direzioni di crescita, supponendo per assurdo che non sia ottimo abbiamo allora possiamo trovare una direzione di crescita ammissibile, creando un assurdo, questa direzione la andiamo a trovare prendendo un punto ottimo e creando il vettore da questo punto a quello nostro iniziale.\nDimostrazione dispense\n!\nLegendre Transform This is also known as Conjugate function in Analisi di Convessit√†#Conjugate function.\n$$ g(p) = \\sup_{p} \\left( px - f(x) \\right) $$This is used in Lagrangian Mechanics for the Eulero Lagrange, and one can see that its dual is the Hamiltonian Mechanics (but need to verify wait).\nThis has an easy geometrical interpretation, is just the maximum distance between the family of the lines through origin to a point of the function that is under the line. First image is the intuition of the Legendre transform (the straight line and the convex shape), the second image represents how an angle is converted to a segment thanks to this transform.\nWe note that $p = f'(x)$ because that is an extremum, this will be useful when we prove the involutivity.\nExamples of Legendre transforms One can see that $f(x) = x^{2}$ has $g(p) = \\frac{1}{4}p^{2}$ as dual. $f(x) = \\frac{mx^{2}}{2}$ has as dual $g(p) = \\frac{p^{2}}{2m}$ $f(x) = \\frac{x^{\\alpha}}{\\alpha}$ has as dual $g(p) = \\frac{p^{\\beta}}{\\beta}$ where $\\frac{1}{\\alpha} + \\frac{1}{\\beta} = 1$.\nYou got the Idea.\nInvolutive property The involutive property asserts that applying the Legendre transform twice gives back the original function.\nIf we set $G(x, p) = xp - g(p)$ we have by definition of $g(p)$ that $G(x, p) = f(x)$, we still need to prove that this is the maximum possible, so that we know that this is indeed the transform.\nWe can have an easy interpretation of reapplying this operator: we can observe that $xp$ is the line passing through the origin, and $g(p)$ is the distance to a point of the $f(x)$ and we know that this point is tangent. It is easy to observe that this point is exactly the $y$ of the point of $f(x)$ for a fixed $x$.\nYoung Duality We say the $f, g$ that are one the Legendre Transform of the other are duals following Young\u0026rsquo;s definition. We have that $F(x, p) = px - f(x) \\leq g(p)$ because $g(p)$ is the supremum. This follows that $px \\leq f(x) +g(p)$ in any case.\nAM-GM application We can prove the classical AM-GM inequality in this way, by setting $f(x) = \\frac{x^{2}}{2}$ and $g(p) = \\frac{p^{2}}{2}$ we have that $px \\leq \\frac{x^{2}}{2} + \\frac{p^{2}}{2}$.\n$$ px \\leq \\frac{x^{\\alpha}}{\\alpha} + \\frac{p^{\\beta}}{\\beta} $$ Where $\\frac{1}{\\alpha} + \\frac{1}{\\beta} = 1$ is valid.\nMulti-variable Legendre $$ F(\\vec{p}, x(\\vec{p})) = max_{x}F(\\vec{p}, \\vec{x}), F(\\vec{p}, \\vec{x}) = (\\vec{p}\\cdot \\vec{x} ) - f(\\vec{x}), \\vec{p} = \\frac{ \\partial f }{ \\partial \\vec{x} } $$ Every result of the above is still valid in this case.\nCoincidence of specific points We can prove that given $f(x)$ and his Legendre transform $g(p)$ then we have that $f(x) = g(p)$, which has a geometrical interpretation that $f(x)$ divides the straight line with a fixed $x$ from the $y=0$ to $y=px$ in half.\n$$ \\frac{ \\partial f }{ \\partial x } x = 2f $$$$ g(p(x)) = px - f(x) = \\frac{ \\partial f }{ \\partial x } x - f = 2f(x) - f(x) = f(x) $$ This will allow us to prove some relation between Lagrangian Mechanics and Hamiltonian Mechanics. In particular that $H = p\\dot{q} - L = 2T - (T - U) = T + U$.\nThe Lagrangian Moved to Lagrange Multipliers.\n","permalink":"https://flecart.github.io/notes/duality-theory/","summary":"\u003cp\u003e√à una branca dell\u0026rsquo;algebra lineare che ci permette di semplificare tutti i concetti.\u003c/p\u003e\n\u003ch2 id=\"intro-dualit√†\"\u003eIntro dualit√†üü©\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Programmazione lineare/Untitled 8.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Programmazione lineare/Untitled 8\u0026quot;\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eSi fa una sorta di trasposta alla matrice di A.\u003c/li\u003e\n\u003cli\u003ey √® pari al numero di righe di A\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLa trasformazione al duale √® molto facile, ed √® abbastanza intuitiva una volta che capiamo che vogliamo andare a fare l‚Äôupper bound.\u003c/p\u003e\n\u003ch3 id=\"dualit√†-asimmetrica-\"\u003eDualit√† asimmetrica üü•+\u003c/h3\u003e\n\u003ch3 id=\"teorema-debole-di-dualit√†-\"\u003eTeorema debole di dualit√† üü©\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide\u003c/p\u003e","title":"Duality Theory"},{"content":"The idea of ensemble methods goes back to Sir Francis Galton. In 787, he noted that although not every single person got the right value, the average estimate of a crowd of people predicted quite well.\nThe main idea of ensemble methods is to combine relatively weak classifiers into a highly accurate predictor.\nThe motivation for boosting was a procedure that combines the outputs of many ‚Äúweak‚Äù classifiers to produce a powerful ‚Äúcommittee.‚Äù\nIn Buhmann\u0026rsquo;s optinion, somehow this is also why democracy works well. But it won\u0026rsquo;t work anymore if too many individuals are correlated with each other.\nSome properties of Ensembles Variance of Ensembles üü©\u0026ndash; Consider a set of estimators $f_{1}, f_{2} \\dots, f_{n}$ and their average $\\hat{f}(x) = \\frac{1}{N} \\sum_{i = 1}^{N}f_{i}(x)$\nThen the bias of the average is the same as the average of the biases, which implies if originally the estimators are unbiased, then the average is unbiased too!\n$$ \\begin{align} \\mathop{\\mathbb{E}}[\\hat{f}(x)] \u0026= \\frac{1}{N}\\mathop{\\mathbb{E}}\\left[ \\sum_{i = 1}^{N}f_{i}(x) \\right] \\\\ \u0026= \\frac{1}{N}\\sum_{i = 1}^{N}\\mathop{\\mathbb{E}}[f_{i}(x)] \\\\ \u0026= \\mathop{\\mathbb{E}}[f_{i}(x)] \\end{align} $$But if we look at the variance, then we see that the variance decreases if the estimators are uncorrelated with each other! This leads to more correct estimates.\n$$ \\begin{align} \\text{Var}[\\hat{f}(x)] \u0026= \\text{Var}\\left[ \\frac{1}{N}\\sum_{i = 1}^{N}f_{i}(x) \\right] \\\\ \u0026= \\frac{1}{N^{2}}\\sum_{i = 1}^{N}\\text{Var}[f_{i}(x)] + \\frac{1}{N^{2}}\\sum_{i \\neq j}\\text{Cov}[f_{i}(x), f_{j}(x)] \\\\ \u0026\\approx \\frac{1}{N}\\text{Var}[f(x)] \\end{align} $$ In reality, the predictors are often correlated, which is why the variance of the ensemble is not as low as we would like.\nAdvantages of Ensembles Usually weak classifiers are easy to train (the only thing we need is to be better than random).\nData randomization in the spirit of Bootstrap captures statistical dependencies between alternative hypotheses. -\u0026gt; The classifier ensemble encodes uncertainty intervals in the hypothesis class (output space).\nBagging In this whole section we will assume that the classifiers output $\\left\\{ -1, 1 \\right\\}$. The idea of bagging (Breiman 1996) is producing a diverse set of classifiers using Bootstrapped samples (or other methods to induce diversity in the classifiers). And then keep the prediction as the average of the predicted values by each classifier. This technique is known also as committee methods.\nBagging Classifiers üü© The basic idea of this method is quite easy, and builds upon bootstrap, introduced in Cross Validation and Model Selection. Set $B$ the number of classifiers to train. Then do the following: For $B$ times:\nSample with replacement the training set (this is the bootstrap part) Train a classifier $C_{b}$ on this sample Output the sum the predictions of the classifiers and take the sign as the classification result. This setting only works for the binary classification problem, and it is slightly biased in case the number of the classifiers is odd. Compare and Bag üü© This method has a very similar idea to the previous one. But are training two different ensembles and selecting based on the performance of the validation set. Random Forests The Idea üü© This method leverages on Decision Trees to build a forest of them. The idea is to create enough different classifiers so that we can build upon the observation on the variance of ensembles. Diversifying the models üü© Ways to diversify the trees are:\nTrain them on different bootstrapped samples At each split, just consider a subset $p$ of features (Typically the square root). Use different splitting criteria (Gini index, Entropy, Misclassification). There could be other methods that we are not considering here.\nBoosting The main difference between boosting and bagging methods is that here the classifiers are trained in sequence.\nAdaBoost algorithm üü®++ The main idea of AdaBoost, which has been a breakthrough in the field of statistical learning, is to train a sequence of classifiers, each of which focuses on the examples that the previous classifiers have misclassified. If a sample has been misclassified in a previous attempt, it will have a higher weight in the next classifier. It is implemented in the following way:\nCurious choices are for the $\\alpha$ and how we scaled the weights. These will be discussed in the next section.\nA philosophical similarity Adaboost is just a collection of simple algorithmic steps which could be interpreted as some optimization objective in the larger scheme of things. This has some commonalities with some philosophical view from Wolphram in (Wolfram 2002).\nForward Stagewise Additive Modeling üü®++ Forward Stagewise additive modeling focus on building a sequence of classifiers, each of which try to solve for the residual of the previous ones. The algorithm is the following:\nInitialize $f_{0}(x) = 0$ For $m = 1, \\dots, M$: Compute the residuals $r_{im} = y_{i} - f_{m-1}(x_{i})$ Fit a classifier to the residuals $r_{im}$, call it $h_{m}(x)$ Choose a step size $\\gamma_{m}$ by solving the optimization problem The above three steps can be summarized as finding $$\\arg \\min_{\\gamma_{m}, h_{m}} \\sum_{i = 1}^{N} L(y_{i}, f_{m - 1}(x_{i}) + \\gamma_{m}h_{m}(x_{i}))$$ Update the model $f_{m}(x) = f_{m-1}(x) + \\gamma_{m}h_{m}(x)$ $h_{m}$ are also called basis functions. In this setting, they are the classifiers interesting to us. Adaboost\u0026rsquo;s energy function üü•++ $$ L(y, f(x)) = \\exp(-yf(x)) $$ This has some slight resemblance to Log Linear Models.\n$$ \\sum_{m = 1}^{N} \\exp(-y_{i}f_{m - 1}(x) - y_{i}\\gamma_{m}h_{m}(x_{i})) = \\sum_{m =1}^{N} w_{m} \\exp(-y_{i}\\gamma_{m}h_{m}(x_{i})) $$$$ (-e^{-\\gamma_{m}} + e^{\\gamma_{m}})\\sum_{i = 1}^{N} w_{i}^{(m)}\\mathbb{1}(h_{m}(x_{i}) \\neq y_{i}) + e^{-\\gamma_{m}}\\sum_{i = 1}^{N} w_{i}^{(m)} $$$$ \\gamma_{m} = \\frac{1}{2} \\log \\frac{1 - \\text{error}_{m}}{\\text{error}_{m}} $$$$ \\text{error}_{m} = \\frac{\\sum_{i = 1}^{N} w_{i}^{(m)}\\mathbb{1}(h_{m}(x_{i}) \\neq y_{i})}{\\sum_{i = 1}^{N} w_{i}^{(m)}} $$$$ w_{i}^{(m + 1)} = w_{i}^{(m)}\\exp(-\\gamma_{m}y_{i}h_{m}(x_{i})) $$$$ -y_{i}h_{m}(x_{i}) = 2\\mathbb{1}(h_{m}(x_{i}) \\neq y_{i}) - 1 $$$$ w_{i}^{(m + 1)} = w_{i}^{(m)}\\exp(\\gamma_{m})\\exp(-2\\gamma_{m}\\mathbb{1}(h_{m}(x_{i}) \\neq y_{i})) $$ We note that the term $\\exp(\\gamma_{m})$ is a constant, this can be dropped when calculating the error as it is insignificant for the weighted average. Now we have Adaboost\u0026rsquo;s weight update rule in the classification setting.\nIs the exponential a Good Loss? From(Bishop 2006): We observe that the misclassification error for the exponential loss grows exponentially for negatives, which could be sign of a high sensitivity to outliers. Another note on the exponential loss: it cannot be interpreted as log likelihood of some well defined probability distribution.\nAnother drawback of the exponential loss compared to a cross-entropy loss is the extension to multi-class classification: while with cross entropy it\u0026rsquo;s easy, with the exponential loss there is no straightforward manner to extend it to multi-class classification.\n$$ \\log p(y \\mid x) = \\log \\prod p_{i}^{y_{i}} = \\sum y_{i}\\log p_{i} $$$$ \\mathcal{L}(f(x), y) = \\log(1 + \\exp(-yf(x))) $$ Used for Linear Classification, as the underlying probability is different.\n$$ \\max(0, 1 - yf(x)) $$ Used from Support Vector Machines\nAdaboost and Logistic Regression üü© $$ f^{*}(x) = \\arg\\min_{f(x)} \\mathbb{E}_{y \\mid x} \\exp(-yf(x)) = \\frac{1}{2} \\log \\frac{P(y = 1 \\mid x)}{P(y = -1 \\mid x)} $$The proof is quite straightforward: $$ \\begin{align} \\mathop{\\mathbb{E}}{y \\mid x} \\exp(-yf(x)) \u0026amp;= P(y = 1 \\mid x)\\exp(-f(x)) + P(y = -1 \\mid x)\\exp(f(x)) \\ \u0026amp;\\implies \\frac{\\partial}{\\partial f(x)} \\mathop{\\mathbb{E}}{y \\mid x} \\exp(-yf(x)) = 0 \\ \u0026amp;\\implies -P(y = 1 \\mid x)\\exp(-f(x)) + P(y = -1 \\mid x)\\exp(f(x)) = 0 \\ \u0026amp;\\implies \\frac{P(y = 1 \\mid x)}{P(y = -1 \\mid x)} = \\exp(2f(x)) \\ \u0026amp;\\implies f(x) = \\frac{1}{2} \\log \\frac{P(y = 1 \\mid x)}{P(y = -1 \\mid x)} \\end{align}\n$$\n$$ P(y = 1 \\mid x) = \\frac{1}{1 + \\exp(-2f^{*}(x))} $$ This is also close to the sigmoid function! Remember that this is why in Logistic Regression, Sigmoid is a good choice for the loss function.\nReferences [1] Wolfram ‚ÄúA New Kind of Science‚Äù Wolfram Media 2002\n[2] Bishop ‚ÄúPattern Recognition and Machine Learning‚Äù Springer 2006\n","permalink":"https://flecart.github.io/notes/ensemble-methods/","summary":"\u003cp\u003eThe idea of ensemble methods goes back to Sir Francis Galton. In 787, he noted that although not every single person got the right value, the average estimate of a crowd of people predicted quite well.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe main idea of ensemble methods is to combine relatively weak classifiers into a highly accurate predictor.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe motivation for boosting was a procedure that combines the outputs of many ‚Äúweak‚Äù classifiers to produce a powerful ‚Äúcommittee.‚Äù\u003c/p\u003e","title":"Ensemble Methods"},{"content":"Questo √® stato creato da 1948 Shannon in (Shannon 1948). Questa nozione √® basata sulla nozione di probabilit√†, perch√© le cose rare sono pi√π informative rispetto a qualcosa che accade spesso.\nIntroduction to Entropy The Shannon Information Content $$ h(x = a_{i}) = \\log_{2}\\frac{1}{P(x = a_{i})} $$ We will see that the entropy is a weighted average of the information, so the expected information content in a distribution.\nKolmogorov complexity √® un modo diverso per definire la complessit√†. Legato √® Neural Networks#Kullback-Leibler Divergence.\nWe can model the classical view of entropy as the from [^1]\nExpected value of Surprisal which is the uncertainty of a random variable $X$ taking a certain value which is $p(X = x) = P(x)$, but we want to measure it using log-likelihood.\n$$ H(\\mathcal{X}) = - \\sum_{x \\in \\mathcal{X}, P_{\\mathcal{X}}(x) \u003e 0} p(x)\\log(p(x)) \\tag{1.1} $$ Ossia, possiamo dire in modo intuitivo quanto sarebbe sorprendente vedere che si avverasse quell\u0026rsquo;evento.\nThis is the graph for the binary case: $$ H(\\mathcal{X}) = p\\log \\frac{1}{p} + (1- p) \\log \\frac{1}{1 - p} $$ $$ \\begin{align*} H(X) := E[I(X)] \u0026= \\sum_{i=1}^n P(x_i)I(x_i) \\\\ \u0026= \\sum_{i=1}^n p_i \\log(1/p_i) \\\\ \u0026= -\\sum_{i=1}^n p_i \\log(p_i) \\tag{1.2} \\end{align*} $$Axiomatic Approach to Entropy We can define the entropy as the only function that satisfies the following properties (the function is commonly called surprise):\n$H(X) \\geq 0$ for every discrete r.v. which is related to the code length, which we don\u0026rsquo;t want to be negative $H(X, Y) = H(X) + H(Y)$ when $X, Y$ are independent random variables. $H(X) \\text{ is maximal }$ when $X \\sim Unif(0, 1)$ this concept is related to hard to guess the results. $$ H(X) = - \\sum_{x \\in \\mathcal{X}} p(x) \\log p(x) $$Properties of the entropy One observation is that labels don\u0026rsquo;t matter, we just need the probability vector and don\u0026rsquo;t care about what it represents.\nThe entropy is always positive. It\u0026rsquo;s easy to prove because all probabilities are $0 \u003c p \\leq 1$ so every term in the sum is positive because log in that interval is also positive.\nAxiomatic approach One could derive the entropy from an axiomatic point of view, with the idea of Surprise We just need three requirements: Given a probability space $\\Omega, \\mathcal{A}, \\mathbb{P}$ , then the surprise of an even $E \\subseteq \\mathcal{A}$ is equal to a function $S([\\mathbb{P}(E)])$ which satisfies the following properties:\n$S(1) = 0$ $S$ is continuous $S$ is monotonic decreasing, meaning that if $p \u003e q$ then $S(p) \u003c S(q)$ $S$ is additive, meaning that $S(pq) = S(p) + S(q)$ when $p, q$ are independent. $$ S(p) = - \\log(p) $$ The entropy is just the expected value of the surprise.\nChain Rule $$ H(X, Y) = H(X) + H(X|Y) $$$$ H(X_{0}, X_{1}, \\dots, X_{i}) = \\sum_{i}H(X_{i}|X_{i-1}\\dots X_{0}) $$Upper bound $$ H(X) \\leq \\log \\lvert \\mathcal{X} \\rvert $$ Con $\\mathcal{X}$ l\u0026rsquo;insieme immagine della variabile aleatoria discreta $X$. Importante in questo caso che la nostra variabile sia discreta, altrimenti il teorema provvisto in (Cover \u0026amp; Thomas 2012) 2.6.4 non funziona. Non √® molto banale l\u0026rsquo;idea di utilizzare la uniforme per modellare il numero di elementi. e usare la positivit√† di KL per finire l\u0026rsquo;upper bound.\n$$ P_{X}(x) = \\frac{1}{\\lvert \\mathcal{X} \\rvert } $$$$ \\sum P_{X}(x) \\log \\frac{1}{P_{X}(x)} = \\log \\frac{1}{P_{X}(x)} = \\log \\lvert X \\rvert $$$$ \\sum P_{X}(x) \\log \\frac{P_{X}(x)}{\\frac{1}{\\lvert \\mathcal{X} \\rvert }} = \\sum P_{X} \\log P(x) + \\sum P_{X}(x) \\log \\lvert \\mathcal{X} \\rvert = \\log \\lvert \\mathcal{X} \\rvert - H(X) $$$$ \\log \\lvert \\mathcal{X} \\rvert - H(X) \\geq 0 $$ Which ends the proof.\nEntropy is concave Uso l\u0026rsquo;upper bound e il fatto che KL √® convesso per dimostrare questa cosa.\nFunctional dependency Non fare Se $Y = f(X)$ per qualche funzione, allora $H(Y|X) = H(X|Y) = 0$ si pu√≤ risolvere con qualche ragionamento sul supporto di entropia. Interessante vedere che ha una piccola relazione con Normalizzazione dei database#Dipendenze funzionali.\nMonotonicity of Entropy $$ H(X) \\geq H(X \\mid Y) $$ It is also called the principle Information never hurts meaning you are never more uncertain about a random variable when you have more information about it.\n$$ H(X) - H(X \\mid Y) = \\sum P(x) \\log P(x) - \\sum P(x, y) \\log P(x \\mid y) = \\sum P(x, y) \\log \\frac{P(x, y)}{P(x)} \\underbrace{\\geq}_{\\text{Jensen}} 0 $$ This is also the reason why mutual information is always positive.\nTypes of entropy Conditional Entropy $$ H(Y|X) = \\sum_{x \\in \\mathcal{X}}p(x) H(Y|X=x) = \\sum_{x \\in \\mathcal{X}, y \\in \\mathcal{Y}} p(x, y) \\log \\frac{1}{P(y|x)} = \\mathbf{E}\\left[ \\log\\frac{1}{p(Y|X)} \\right] $$ La nozione con il valore atteso √® la pi√π semplice anche in questo caso.\nconditional entropy corresponds to the expected remaining uncertainty in $Y$ after we observe $X$\n$$ H(Y \\mid X) = \\mathbb{E}_{(x, y) \\sim p(x, y)}\\left[ \\log \\frac{1}{p(y \\mid x)} \\right] $$Joint Entropy $$ H(X, Y) = - \\sum_{x, y} p(x, y) \\log p(x, y) $$$$ H(X, Y) = H(X) + H(Y \\mid X) = H(Y) + H(X \\mid Y) $$Relative Entropy or Kullback-Leibler Let\u0026rsquo;s take $\\lvert \\mathcal{X} \\rvert \u003c \\infty$, and take distributions P, Q, $\\mathcal{X} \\to \\mathbb{R}$ such that $p(x) \\geq 0 \\forall x \\in \\mathcal{X}$ and the sum is 1, same thing for $Q$, then we define the Kullback-Leibler Divergence between those distributions to be\n$$ D(P \\mid \\mid Q) = \\sum_{x \\in \\mathcal{X}} P(x) \\log \\frac{P(x)}{Q(x)} $$ We need to define some corner cases:\nIf $P(x) = 0$ and $Q$ is anything then its 0 If $\\exists \\xi \\in \\mathcal{X}$ such that $P(\\xi) \u003e 0$ and $Q(\\xi) = 0$ =\u0026gt; $D(P \\mid \\mid Q) = + \\infty$. If $P \\ll Q$ then $D(P \\mid \\mid Q) \u003c \\infty$ (I did not understand why) This has some relations with the entropy, we can use some log properties and have the following result:\n$$ D(P \\mid \\mid Q) = - H(P) - \\sum P(x) \\log Q(x) $$ The second addendum can be called cross-entropy.\nIn modo praticamente equivalente possiamo definire una versione condizionata. e si pu√≤ applicare anche in questo caso una chain rule\n$$ DL(P(x, y) \\mid\\mid Q(x, y) = DL(P(x) \\mid\\mid Q(x)) + DL(P(x|y) \\mid\\mid Q(x|y)) $$Relative entropy is not a distance not a metric, so its incorrect to say it is a distance, but for practical purposes it seems to work well: if the Relative entropy is small also the probability vectors are small.\nKL is positive or null $$ DL(P \\mid\\mid Q) \\geq 0 $$ Con uguaglianza se hanno esattamente la stessa distribuzione. We have that $D(P \\mid \\mid Q) = 0 \\iff P = Q$ .\nE ricordandoci che $\\log$ √® una funzione concava, quindi si pu√≤ utilizzare Jensen. Lo dimostriamo ora in breve. Sappiamo che la funzione $-\\log(x) = \\log\\left( \\frac{1}{x} \\right)$ √® una funzione convessa, perch√© il negativo di una funzione concava, che √® il logaritmo.\nAllora consideriamo $\\frac{1}{u} = \\frac{Q(x)}{P(x)}$ che √® la parte dentro al logaritmo perch√© cos√¨ possiamo usare Jensen Allora comunque abbiamo\n$$ \\sum_{x} P(x) \\log\\left( \\frac{Q(x)}{P(x)} \\right) \\geq \\log\\left( \\sum_{x} P(x) \\cdot \\frac{Q(x)}{P(x)} \\right) = \\log(1) = 0 $$$$ D_{KL}(P \\mid \\mid Q) \\geq 0 $$ In modo facile.\nKL is convex $DL(p\\mid\\mid q)$ √® convesso sulla coppia $(p, q)$, 2.7.2 di (Cover \u0026amp; Thomas 2012). Anche sula 2.26 di McKay √® buono, anche se non esattamente parla di questo.\nMutual information Questa nozione definisce quanta informazione hanno in comune due variabili aleatorie\nDefinizione $$ I(X;Y) = \\sum_{x}\\sum_{y} p(x, y) \\log\\left( \\frac{p(x, y)}{p(x)p(y)} \\right) = H(X) - H(X|Y) $$ Si pu√≤ fare dopo un po\u0026rsquo; di calcoli che qui ho omesso, ma non dovrebbe essere difficile farlo.888\nSi pu√≤ intendere la mutual information anche come KL fra le distribuzioni $p(x, y)$ e $p(x)p(y)$ si pu√≤ notare che queste due sono uguali quando le due sono indipendenti, che √® coerente con la nostra nozione che abbiamo dell\u0026rsquo;indipendenza.\nPropriet√† Another property: $$ I(X; Y\\mid Z) = I(X ; Y, Z) - I(X ; Z) $$ Redundancy and Synergy üü® $$ I(X;Y;Z) = I(X;Y) - I(X;Y\\mid Z) $$ Then synergy between $Y$ and $Z$ is present when the interaction information is negative, and redundant when its positive. This is because, intuitively, if it is negative it means $Z$ can provide more information with $Y$ about $Z$, else, they both have some information about $X$ which is probably not enough.\nExample: Independent Variable in MI We see that if $Y \\mid X \\perp Z$ then $I(X;Z) = I(X, Y; Z)$ this means then that the relation between $Y$ and $Z$ is neither redundant or synergic\n$$ \\begin{align} I(X, Y; Z) \u0026= \\mathbb{E}\\left[ \\log \\frac{P(X, Y, Z)}{P(X, Y) P(Z)} \\right] \\\\ \u0026= \\mathbb{E}\\left[ \\log \\frac{P(X, Z)}{P(X) P(Z)} \\right] + \\mathbb{E}\\left[ \\log \\frac{P(Y \\mid X, Z)}{P(Y \\mid X)} \\right] \\\\ \u0026= I(X; Z) + \\mathbb{E}\\left[ \\log \\frac{P(Y \\mid X, Z)}{P(Y \\mid X)} \\right] \\\\ \u0026= I(X; Z) \\end{align} $$ Where in the last step we used the fact that $Y \\perp Z \\mid X \\implies P(Y \\mid X, Z) = P(Y \\mid X)$.\nThis means that if the independence condition is satified, then we can add random variables as we like without changing the mutual information.\nSufficient Statistics Possiamo rappresentare il sampling da una certa famiglia di distribuzioni $f_{\\theta}(x)$ , rappresentato da $X$, e una sua statistica a caso (media varianza etc, che credo basti una funzione sul valore) come T, allora possiamo rappresentarlo come una Markov Chains#Catena di 3 variabili $\\theta \\to X \\to T(X)$ E vale il teorema di information processing\n$$ I(\\theta; T(X)) \\leq I(\\theta; X) $$ Si pu√≤ chiamare una statistica per $\\theta$ sufficiente se $X$ contiene tutta l\u0026rsquo;informazione di $\\theta$. Non so bene cosa significhi. La cosa importante √® che la statistica sufficiente preserva la mutua informazione ossia si ha una uguaglianza in quella relazione di sopra. Vedere 2.9 di (Cover \u0026amp; Thomas 2012) per esempi .\nQuesta cosa potrebbe permettere di dire che usando quella statistica io posso dimenticarmi del parametro, perch√© riesco a ricavarmelo senza problemi credo\u0026hellip;.\nThe purpose of sufficiency is to demonstrate that statistics that satisfy this property do not discard information about the parameter, and as such, estimators that might be based on a sufficient statistic are in a sense \u0026ldquo;good\u0026rdquo; ones to choose.\nDa https://math.stackexchange.com/questions/1186645/understanding-sufficient-statistic. Sufficient statistics also have a quite nice relationship with The Exponential Family.\nFano\u0026rsquo;s inequality L\u0026quot;idea principale √® utilizzare una variabile aleatoria per stimarne una altra, usando l\u0026rsquo;entropia condizionale fra le due.\nEnunciato fano $$ H(P_{e}) + P_{e}\\log \\lvert \\mathcal{X} \\rvert \\geq H(X|\\hat{X}) \\geq H(X|Y) $$$$ 1 + P_{e} \\log \\lvert \\mathcal{X} \\rvert \\geq H(X|Y) $$Dimostrazione Fano Questa √® una bomba da fare. Poi per√≤ ha un sacco di conseguenze non applicabili in modo immediato (cio√® non ci arrivi subito se non le fai un po\u0026rsquo; prima).\nMaximum Distribution entropy Un problema classico nella teoria dell\u0026rsquo;informazione √® trovare la distribuzione che massimizzi l\u0026rsquo;entropia (quindi l\u0026rsquo;informazione contenuta credo) dati certe conoscenze a priori, Ossia data una funzione $f$ e certe condizioni che deve rispettare, massimizzare l\u0026rsquo;entropia.\nSI pu√≤ dimostrare (lo si pu√≤ vedere da una reference di sopra) che la distribuzione che massimizza l\u0026rsquo;entropia, avendo solamente la condizione di probabilit√†, ossia che $\\sum_{x}p(x) = 1$ √® la distribuzione uniforme. Mentre se assumo anche media $\\mu$ e varianza $\\sigma^{2}$ allora √® la gaussiana (dimostrato in Maximum Entropy Principle. In un certo senso possiamo dire che queste distribuzioni sono molto ricche di informazioni.\nCodewords Jensen\u0026rsquo;s Inequality $$ f\\left( \\sum_{i} \\lambda_{i} x_{i} \\right) \\leq \\sum_{i}\\lambda_{i}f(x_{i}) $$ Con $\\sum_{i}\\lambda_{i} = 1$. Questa cosa si estende in modo molto semplice a variabili aleatorie e $E$ quando al posto di $\\lambda_{i}$ mettiamo una probabilit√† in un punto.\nLa dimostrazione non dovrebbe essere molto difficile. La strategia √® utilizzare l\u0026rsquo;induzione in modo abbastanza classico. Non so in che modo si estende su funzioni continue, ma quelle sono cose tecniche matematiche non interessantissime.\nLog sum inequality $$ \\sum_{i=1}^{n}a_{i} \\log\\left( \\frac{a_{i}}{b_{i}} \\right) \\geq \\left( \\sum_{i=1}^{n}a_{i} \\right)\\log \\frac{\\left( \\sum_{i=1}^{n} a_{i} \\right)}{\\sum_{i=1}^{n}b_{i}} $$ Con uguaglianza se vale che $\\forall i, \\frac{a_{i}}{b_{i}}= const$\nKrafts Inequality https://en.wikipedia.org/wiki/Kraft%E2%80%93McMillan_inequality Questo teorema interessa cose dei codewords, perch√© ci interessano dei set di prefixfree che sono molto pi√π gestibili probabilmente dal punto di vista dell\u0026rsquo;interpretazione. La cosa interessante √®:\n$$ \\sum_{x} 2^{-l(x)} \\leq 1 $$Il motivo √® abbastanza semplice, questo si spiega in modo grafico in maniera praticamente immediata quando facciamo il disegno. Si pu√≤ vedere dall\u0026rsquo;albero binario corrispondente di un insieme di set binari con prefissi che se un parente √® scelto (colorato nel disegno), allora nessun discendente pu√≤ essere scelto perch√© altrimenti avresti un prefisso. Inoltre se colori quelli sopra, significa che al massimo se sommi tutti quei valori otterrai 1 sse hai utilizzato tutti i rami a tua disposizione (meaning, che non puoi scegliere altri code-work, altrimenti perdi la prefix property). Source coding theorem for symbol codes $$ H(P) \\leq L \\leq H(P) + 1 $$ Ossia la lunghezza migliore possibile √® boundata da valori di entropia. Che √® una cosa abbastanza forte perch√© relaziona come deve essere fatto il code-words, con la complessit√† dell\u0026rsquo;informazione che vogliamo andare a utilizzare. La dimostrazione non la facciamo qui, ma √® fattibile con le tue conoscenze credo, ti serve la Gibbs inequality qui sotto per una freccia\n$$ L = \\sum_{x} p(x) l(x) = \\sum_{x} \\left( p(x) \\log\\left( \\frac{1}{q(x)} \\right) \\right) \\geq \\sum_{x}p(x) \\log\\left( \\frac{1}{p(x)} \\right) =H(x) $$Dove abbiamo usato anche l\u0026rsquo;ineguaglianza di Gibbs #Gibbs Inequality e il fatto che vale #Krafts Inequality.\n$$ l_{i} = \\lceil -\\log_{2}(p_{i}) \\rceil $$$$ L = \\sum_{x} p(x) l(x) = \\sum_{x} p(x) \\lceil -\\log_{2}(p_{x}) \\rceil \\leq \\sum_{x}p(x) \\left( \\log_{2}\\left( \\frac{1}{p(x)}\\right) +1 \\right) = H(x) + 1 $$ Una nota interessante √® questo teorema ci permette di definire un concetto di efficienza di rappresentazione. Tutto quanto dato da KL divergence √® una specie di inefficienza.\n$$ L = H(x) + D_{KL}(P \\mid \\mid Q) $$ Con $Q$ la probabilit√† associata alle singole codewords, assumendo che siano uniformi e simili per dire.\nGibbs Inequality $$ \\sum_{x} P(x) \\log\\left( \\frac{1}{P(x)} \\right) \\leq \\sum_{x} P(x) \\log\\left( \\frac{1}{Q(x)} \\right) $$ Qualunque sia l\u0026rsquo;altra distribuzione. Si pu√≤ dimostrare in modo abbastanza diretto utilizzando il fatto che la Kullback Leibler divergence, presentato in Neural Networks, √® sempre positiva o uguale a 0. Infatti la parte di sopra si pu√≤ riscrivere come\n$$ -\\sum_{x} P(x) \\log\\left( \\frac{P(x)}{Q(x)} \\right) = D_{KL}(P \\mid \\mid Q) $$References [1] Cover \u0026amp; Thomas ‚ÄúElements of Information Theory‚Äù John Wiley \u0026amp; Sons 2012\n[2] Shannon ‚ÄúA Mathematical Theory of Communication‚Äù The Bell System Technical Journal Vol. 27, pp. 379\u0026ndash;423, 623\u0026ndash;656 1948\n[3] Li \u0026amp; Vit√°nyi ‚ÄúAn Introduction to Kolmogorov Complexity and Its Applications‚Äù Springer International Publishing 2019\n","permalink":"https://flecart.github.io/notes/entropy/","summary":"\u003cp\u003eQuesto √® stato creato da 1948 Shannon in \u003ca href=\"https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf\"\u003e(Shannon 1948)\u003c/a\u003e. Questa nozione √® basata sulla nozione di probabilit√†, perch√© le cose rare sono pi√π informative rispetto a qualcosa che accade spesso.\u003c/p\u003e\n\u003ch3 id=\"introduction-to-entropy\"\u003eIntroduction to Entropy\u003c/h3\u003e\n\u003ch4 id=\"the-shannon-information-content\"\u003eThe Shannon Information Content\u003c/h4\u003e\n$$\nh(x = a_{i}) = \\log_{2}\\frac{1}{P(x = a_{i})}\n$$\u003cp\u003e\nWe will see that the entropy is a weighted average of the information, so the expected information content in a distribution.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"/notes/kolmogorov-complexity/\"\u003eKolmogorov complexity\u003c/a\u003e √® un modo diverso per definire la complessit√†.\nLegato √® \u003ca href=\"/notes/neural-networks/#kullback-leibler-divergence\"\u003eNeural Networks#Kullback-Leibler Divergence\u003c/a\u003e.\u003c/p\u003e","title":"Entropy"},{"content":"Per trovare i zeri di una funzione continua non lineare non esistono alcuni metodi diretti che ci portano subito a una soluzione. Per questo motivo andremo ad analizzare molteplici pasis iterativi per trovare i zeri di una funzione.\nLa discussione di convergenza di ordine p √® stata gi√† discussa nelle note introduttive convergenza e iterazione, per quanto riguarda i metodi iterativi per risolvere sistemi di equazioni lineari\nGlobale e local Ricordiamo di Norme e Condizionamento, in cui il condizionamento era pi√π o meno una stima di quanto cambia la soluzione quando cambia brevemente l\u0026rsquo;input. Ma ora vogliamo estendere il concetto per equazioni non lineari.\nSlide dimo espsilon √® una perturbazione gestita da una funzione h Cose da ricordare\nSe √® uno zero con moltiplicit√† maggiore di 1 √® sempre mal condizionato Altrimenti √® nell\u0026rsquo;ordine dell‚Äôinversa della derivata calcolata in quel punto Slide di questa ultima roba\nMetodo di bisezione Introduzione al metodo di bisezione Questo metodo funziona per funzione continua in un intervallo e $f(a)f(b) \u003c 0$, per il teorema degli zeri esiste una soluzione, allora dobbiamo andare ad iterare l‚Äôargomento fin quando non abbiamo una stima abbastanza precisa del punto.\nSlide\nIn pratica va a dimezzare sempre ad ogni iterazione l‚Äôintervallo in cui pu√≤ essere presente il nostro numero.\nConvergenza e Costo Una cosa bella di questo, in confronto ai metodi per equazioni lineari √® che posso stimare il numero di iterazioni\nSlides\nIl costo di questo metodo dipende dalla funzione che bisogna essere calcolata ad ogni iterazione, ma al massimo facciamo un numero di iterazioni logaritmico rispetto al nostro intervallo, quindi qualcosa del tipo\n$$ O(\\log(b - a) \\times O(f)) $$Talvolta pu√≤ succedere che √® sempre costante la variabile in mezzo, quindi non posso diminuire di pi√π l‚Äôintervallo, vedi esempio in toggle\nImprecisione floating point, e non convergenza\nPer risolvere questo aggiungo eps dell‚Äôintervallo, in modo da rilassare la cosa, ed evitare che rimanga bloccato.\nEsempio blocco se non uso questo\na = 98.5, 98.6 =b e epsilon = 0.004, precisione macchina √® 0.01 / 2 (da 1/2 beta t - 1)\nQuindi si ferma se 0.004 + 0.01/2 * 98.6 = 0.004 + 0.986 / 2 quindi effettivamente si dovrebbe fermare. perch√© la differenza √® minore di 0.5 tipo.\nNote sulla implementazione (2) Si preferisce di calcolare il punto medio in questa forma\n$a + (b -a)/2$, invece che $(a + b)/ 2$ per limitare gli errori.\nEsempio di questo vantaggio 0.983, 0.984, F(10, 3, -5, 5) La somma √® 1.967, che normalizzato troncato √® 0.196 1e1,, diviso diventa 0.980, oppure 0.985 se arrotondo al pi√π vicino, in ogni caso √® errato. Mentre con l‚Äôaltro metodo ottenevo 0.983 + (0.001 = 0.1 1e-2), 0.05 1e-2 = 0.5 1e-3 la somma √® 0.9835, che √® 0.983 quindi √® ancora dentro l‚Äôintervallo. Oltre a questo introduco la funzione sign e non lo calcolo il prodotto ella funzione, quindi vado a considerare\n$sign(f(a)) sign(f(b)) \u003c0$\nAnalisi dei punti fissi Slide idea\nIdea dagli appunti pisani In pratica andiamo a dire che √® pi√π facile trovare punti fissi Invece di trovare uno zero per f, cerco di trovare uno zero per la funzione di g equivalente, tale che sia un punto fisso. Probabilmente perch√© √® pi√π facile trovare dei punti fissi ed √® per questo che vado a cercarlo. La funzione $\\Phi(x)$ di supporto √® maggiore di 0.\nBanach fixed-point theorem - Wikipedia or see Banach Fixed Point Theorem.\nQuello sopra √® il teorema principale utile a giustificare l‚Äôesistenza del punto fisso, e anche dell‚Äôunicit√†. Ti basti sapere che la funzione deve essere:\nContinua in \\[a, b\\] Una contrazione, ossia soddisfare questa relazione: $|g(a) - g(b)| \\leq L|a - b|$ Esistenza del punto fisso La funzione deve essere continua La funzione deve essere una contrazione nell‚Äôintervallo prestabilito. L‚Äôimmagine deve essere contenuta al dominio, altrimenti non posso utilizzare l‚Äôimmagine come input. Enunciato\nNota; questo teorema √® abbastanza importante (e anche tosto se si vuole far bene), lo puoi trovare in questa pagina di wiki\nNota: derivabilit√† e contrazione: Se il modulo della derivata √® minore di 1 allora √® una contrazione! (non il perch√© ti basta ricordare sta cosa lel). Un altra nota √® che se sono soddisfatte quelle due cose, si pu√≤ dimostrare che converge sempre! TODO: velocit√† di convergenza? Criteri di convergenza??\nL-Smoothness $$\\lVert \\nabla f(x) - \\nabla f(y) \\rVert \\leq L \\lvert x - y \\rvert$$ E questo ha qualcosa a che fare con il gradient flow che √® la formalizzazione continua di questo.\n$$ \\forall x, y: f(y) \\leq f(x) + \\langle \\nabla f(x), y- x \\rangle + \\frac{L}{2} \\lvert x - y \\rvert ^{2} $$E si potrebbe utilizzare una cosa simile per avere la garanzia di una discesa. Possiamo scendere tramite\n$$ f(x') \\leq f(x) - \\alpha\\left( 1 - \\frac{\\alpha}{2} L \\right) \\lVert \\nabla f(x) \\rVert ^{2} $$ Se scegliamo $\\alpha = \\frac{1}{L}$ allora la costante di discesa sar√† $\\frac{1}{2L}$\nConvergenza delle contrazioni Molto simile al teorema di esistenza e di unicit√†, questo invece stabilisce la convergenza, ed √® sufficiente che la funzione sia una contrazione per ogni punto in un intorno del punto fisso.\nSlide Cio√® √® fatta su una variazione su applicazione successive, e sul valore della funzione che deve essere abbastanza vicina allo 0.\nOppure si pu√≤ fare su errori relativi oppure frazione del massimo della funzione. Ad ogni modo √® a seconda di tolleranze prefissate.\nIn ogni modo con questo vogliamo cercare di\nVedere che la nostra funzione abbia raggiunto un valore vicino allo zero. Vedere quanto varia ancora la soluzione proposta, non vorremmo che variasse ancora tanto. Slide\nTi basti sapere che √® lineare, sul perch√© non lo so. Ma √® lineare lel.\nMetodo di Newton (delle tangenti) √à molto simile al metodo delle approssimazioni successive, ma in questo caso vogliamo utilizzare la derivata, come funzione ausiliaria. Vogliamo cercare di riassegnare la x a seconda di dove tenda a 0.\nDa notare che √® una convergenza quadratica quindi molto veloce! Solo che si spende il tempo per calcolare la funzione due volte per s√© stessa e la derivata\nIdea sul metodo Alla fine si avr√† una successione nella forma\n$$ x_{n + 1} = x_n - \\dfrac{f(x_n)}{f'(x_n)} $$$$ f(x) \\approx f(x_n) + f'(x_n)(x - x_n) \\implies 0 \\approx f(x_n) + f'(x_n)(x - x_n) $$ By rearranging the terms we have the formula above.\nNote velocit√† di convergenza Caso lineare (metodo approssimazioni classico)\nCaso convergenza quadratica\nPer il metodo di newton, la convergenza √® quadratica!\nDimostrazione velocit√† di convergenza $$ \\lvert x_{n + 1} - \\alpha \\rvert \\leq C \\lvert x_{n} - \\alpha \\rvert ^{2} $$ Per qualche $C \u003e 0$. Da un certo punto di vista questo risultato ricorder√† tutti risultati di convergenza studiati in Markov Processes.\nPer dimostrazione vedere Wikipedia.\nCondizioni di convergenza locale (3) Significa che riesce a trovare il minimo locale per la funzione\nSlide Condizioni di convergenza globale Significa che riesce sempre a trovare il minimo globale della funzione, come vedremo ci sono un sacco di condizioni restringenti (poi con\nConvergono anche tutte le variazioni possibili, sempre con a e b opposti (ma in modo diverso), e derivata seconda fatta in modo diverso\nSe la derivata seconda √® minore o ugualedi 0, parto da quello alto, altrimenti, da quello basso (non ho capito bene la 4 condizione boh).\nTODO: Capire enunciati di questo\nMetodo di Newton in Ottimizzazione Se l\u0026rsquo;obiettivo, invece di trovare uno zero di funzione, diventa minimizzare o massimizzare la funzione, allora l\u0026rsquo;obiettivo cambia!\nQui √® esposto il metodo bene nel caso multidimensionale e sar√† il punto di riferimento per questa sottosezione.\nIdea di ottimizzazione Anche in questo caso dovremo passare per l\u0026rsquo;espansione di Taylor, per√≤ non potremo fare uso della derivata prima al denominatore perch√© quando saremo abbastanza vicino al punto che cerchiamo, l\u0026rsquo;update sar√† praticamente nullo.\n$$ f(\\vec{w} + \\vec{s}) \\approx f(\\vec{w}) + \\nabla f(\\vec{w}) \\cdot \\vec{s} + \\frac{1}{2} \\vec{s}^T \\nabla^2 f(\\vec{w}) \\vec{s} $$$$ \\arg\\min_{\\vec{s}} \\left( \\nabla f(\\vec{w}) \\cdot \\vec{s} + \\frac{1}{2} \\vec{s}^T \\nabla^2 f(\\vec{w}) \\vec{s} \\right) \\implies \\nabla f(\\vec{w}) + \\nabla^2 f(\\vec{w}) \\vec{s} = 0 \\implies \\vec{s} = - \\frac{\\nabla f(\\vec{w})}{\\nabla^2f(\\vec{w})} $$$$ x_{t + 1} = x_{t} - \\nabla^2 f(x_t)^{-1} \\nabla f(x_t) = x_{t} - H^{-1} \\nabla f(x_t) $$","permalink":"https://flecart.github.io/notes/equazioni-non-lineari/","summary":"\u003cp\u003ePer trovare i zeri di una funzione continua non lineare \u003cstrong\u003enon esistono\u003c/strong\u003e alcuni metodi diretti che ci portano subito a una soluzione. Per questo motivo andremo ad analizzare molteplici pasis iterativi per trovare i zeri di una funzione.\u003c/p\u003e\n\u003cp\u003eLa discussione di convergenza di ordine p √® stata gi√† discussa nelle note introduttive convergenza e iterazione, per quanto riguarda i metodi iterativi per risolvere sistemi di equazioni lineari\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGlobale e local\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Equazioni non lineari/Untitled.png\" alt=\"image/universita/ex-notion/Equazioni non lineari/Untitled\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eRicordiamo di  \u003ca href=\"/notes/norme-e-condizionamento/\"\u003eNorme e Condizionamento\u003c/a\u003e, in cui il condizionamento era pi√π o meno una stima di quanto cambia la soluzione quando cambia brevemente l\u0026rsquo;input. Ma ora vogliamo estendere il concetto per equazioni non lineari.\u003c/p\u003e","title":"Equazioni non lineari"},{"content":"Sono variazioni possibili equivalenti: ‚Ä¢ Nastri addizionali ‚Ä¢ Testine addizionali ‚Ä¢ Nastri infiniti su entrambi i lati ‚Ä¢ Non-determinismo ‚Ä¢ Scelta probabilistica ‚Ä¢ Scelta quantistica Si pu√≤ dire che la definizione di TM √® stata robusta nella storia perch√© tantissimi formalismi che intuitivamente sembrano essere molto diversi rispetto alla TM alla fine possono essere dimostrate essere equivalenti.\nTuring con nastri addizionali Questo √® presente in modo abbastanza facile sul Sipser.\nLa computazione comincia con l‚Äôinput sul primo nastro, e tutti gli altri nastri vuoti. Macchine di Turing con nastri addizionali In ciascun passo di computazione, ogni testina √© nello stesso stato, ma pu√≤ essere in una posizione diversa, leggere un simbolo differente, e compiere un‚Äôazione diversa. Se si raggiunge uno stato finale, l‚Äôoutput √© letto dal primo nastro.\n#### Definizione formalismo üü© L'unica differenza formale √® che questa macchina √® **parallela** cio√® ho molte macchine di turing che vanno allo stesso momento $$ \\delta: (Q - H) \\times \\Sigma^{k} \\to Q \\times(\\Sigma \\times \\left\\{ \\to, \\leftarrow \\right\\} )^{k} $$ Il restante delle tuple resta uguale. L'altra osservazione √® che lo stato esterno √® **unico**. In un certo senso √® una **pila con macchina di turing** [Linguaggi liberi e PDA](/notes/linguaggi-liberi-e-pda). Teorema di equivalenza üü© Dimostriamo che questo formalismo √® equivalente con La macchina di Turing. √à ovvio il caso in cui nastro addizionale -\u0026gt; Turing. Ossia che\nTermina quando il l\u0026rsquo;altro non termina Se termina hanno stesso output. Si pu√≤ formalizzare per√≤ alla fine √® quello.\n$$ \\Sigma' = \\Sigma \\cup \\left\\{ \\# \\right\\} \\cup \\left\\{ \\bar{a} : a \\in \\Sigma \\right\\} $$ Allora I molteplici passi di computazione su molti nastri che sono un singolo passo per la multinastro possono essere simulati sul singolo nastro. La lettere barretta ci permette di mantenere il pointer sul nastro originale. Se c\u0026rsquo;√® bisogno di spazio in pi√π su un nastro, debbo postare tutto a destra (tanto √® infinito e posso farlo). (nota che per questo teorema √® necessario l\u0026rsquo;infinito!!) Alla fine cancello tutto dopo il primo cancelletto e ritorno quello.\nEnumerators Questo √® un argomento extra non trattato a lezione 3.2 del Sipser viene trattato. Si pu√≤ dire che √® una altra cosa equivalente alla La macchina di Turing. In modo informale, un enumeratore √® una macchina di turing con una stampante, che pu√≤ esser considerato l\u0026rsquo;output della nostra macchina. Poi c\u0026rsquo;√® un work tape che pu√≤ essere utilizzato come cache. Da un punto di vista formale non √® altro che una macchina di turing con 2 nastri\nMacchine di Turing non deterministiche Descrizione formalismo non deterministico üü© $$ \\delta: ((Q - H) \\times \\Sigma) \\times (Q \\times\\Sigma \\times \\left\\{ \\to, \\leftarrow \\right\\} ) $$$$ \\delta: ((Q - H) \\times \\Sigma) \\to \\mathbb{P}(Q \\times\\Sigma \\times \\left\\{ \\to, \\leftarrow \\right\\} ) $$In un certo senso questo non determinismo √® simile a quanto fatto in Grammatiche Regolari e Linguaggi liberi e PDA. Per il non determinismo. Solo che l√¨ il prof. li faceva pi√π formali.\nSulle slides c\u0026rsquo;√® un esempio di NMT molto semplice per dimostrare che la primalit√† di un numero √® calcolabile. (idea prendo in modo non deterministico un numero minore di $n$ e calcolo il modulo).\nSketch di dimostrazione di equivalenza üü®++ Supponendo che abbiamo l\u0026rsquo;albero di computazione, posso esplorare con Grafi#BFS tutto l\u0026rsquo;albero di computazione e avere alla fine lo stesso risultato.\nQui c\u0026rsquo;√® un albero di computazione. (poi probabilmente bisogner√† codificare un backtracking) Altre Una altra macchina di Turing di interesse che non trattiamo qui √® il prefix turing machine, che trattiamo in Kolmogorov complexity.\nMacchine a registri Chiamato anche URM unlimited register machine, √® un formalismo pi√π simile a come sono fatti i computer moderni perch√© utilizzano i regsitri. Definito in (Shepherdson \u0026amp; Sturgis 1963).\nDescrizione Unlimited Register Machineüü®++ Supponiamo di avere $R_{1}, R_{2}, R_{3}, \\dots$ registri, ogni registro ha un numero naturale indicato con $r_{n}$ (contenuto di registro $n$) Se la computazione finisce, questa viene messa in $R_{1}$ (simile a RAX in archietture intel). L\u0026rsquo;input $N^{k}$ √® messo in tutti i registri in ordine (se non definito sono a 0).\nEsistono un sistema di istruzioni che muovono e modificano le cose dei registri:\nZero $Z(n)$ il registro $n$ √® messo a 0. Successor $S(n)$ il registro $n$ √® aumentato a $n$ Move $R(n, m)$ $m$ √® messo uguale a $n$ (sono registri) Jump $J(n, m, p)$ Salta a istruzione $I_{p}$ se i registri $n$ e $m$ sono uguali. altrimenti ignora istruzione. Ora possiamo definire una specie di ALU che √® la cosa classica di programma imperativo.\nEnunciato equivalenza üü© $$ \\mathbb{N}^{k} \\to \\mathbb{N} $$ Che possono anche non terminare (in questo caso parziale).\nUna funzione parziale √® calcolabile in URM sse √® calcolabile su TM\nIdea TM =\u0026gt; URM üü® Uso il risultato in #Turing con nastri addizionali, ho tanti nastri che fanno cose:\nFa instruction pointer e punta all\u0026rsquo;istruzione attuale Ha il codice del programma Ha il valore dei registri in notazione unaria (che √® equivalente), separati da U. Altri registri sono cache. Allora posso usare il contenuto del nastro 1 per trovare l\u0026rsquo;istruzione, poi uso altro per interpretarla ed eseguirla. Alla fine uso il primo valore del terzo nastro per avere il risultato. Per la modifica dei registri posso usare nastri ausiliari.\nIdea TM \u0026lt;= URM üü® Supponiamo di avere un URM, vogliamo simulare una macchina di turing con la classica tupla $\\Sigma, Q, q_{0}, H, \\delta$\nChiamo un registro TAPE che conterr√† i valori presenti su un nastro di Turing. Inoltre dobbiamo ricordarci che questa macchina contiene numeri naturali per questo motivo abbiamo bisogno di una codifica. Scegliamo $\\Sigma = \\left\\{ 0, 1, U \\right\\}$ dove $U$ sta per empty, nel caso in cui l\u0026rsquo;alfabeto sia diverso da questo, la dimostrazione dovr√† essere equivalente. Allora possiamo usare la notazione in base $3$ per decodificare il numero, assumendo $code(0) = 0$, $code(1) = 1$, $code(U) = 2$.\nPoi introduciamo registri per codificare $\\delta$ la funzione di transizione. Modello WHILE Questo √® un formalismo pi√π simile a uno di alto livello (quindi programma normale).Descritto in\nKfoury, Moll, Arbib - A programming approach to computability.\nDescrizione del modello WHILE(3)üü© Questo √® simile a quanto descritto per la Semantica di un linguaggio per la parte procedurale. Abbiamo:\nAssegnazione Cicli while seguenziamento Possiamo definirlo in Sintassi e RI strutturali#4.2 Backus-Naur Form Ci sono tre forme di assegnazione, uno zero, uno successivo, uno uguale credo. Non viene fatta la parte della semantica che abbiamo fatto tempo fa a linguaggi.\nDimostrazione equivalenza üü© Una funzione (parziale) √© computabile da un programma WHILE se e solo se √© computabile da una macchina di Turing.\nSi dimostra per induzione strutturale sulla BNF l√¨ precedente. I casi base sono i 3 assegnamenti (zero, successore, e predecessore) e il programma vuoto.\nPer il caso base, utilizzo un nastro separato come ho fatto per #Turing con nastri addizionali, su questo ci metto le variabili di interesse. Su questo posso codificare i casi base accennati di sopra.\nPoi caso induttivo √® while e sequenza di istruzioni. Poi per codificare la sequenza, basta concatenare molte macchine di turing normali, ognuna che codifica l\u0026rsquo;istruzione. Sappiamo che queste esistono per ipotesi induttiva. Per il while possiamo usare due macchine, una per il test, una per il corpo del while e dire che accetta quando esco dal ciclo. √à interessante osservare come siano uguali questi.\nReferences [1] Shepherdson \u0026amp; Sturgis ‚ÄúComputability of Recursive Functions‚Äù Journal of the ACM Vol. 10(2), pp. 217\u0026ndash;255 1963\n","permalink":"https://flecart.github.io/notes/estensioni-di-turing-e-altre-macchine/","summary":"\u003cp\u003eSono variazioni possibili equivalenti:\n‚Ä¢ Nastri addizionali ‚Ä¢ Testine addizionali ‚Ä¢ Nastri infiniti su entrambi i lati ‚Ä¢ Non-determinismo ‚Ä¢ Scelta probabilistica ‚Ä¢ Scelta quantistica\nSi pu√≤ dire che la definizione di TM √® stata \u003cstrong\u003erobusta\u003c/strong\u003e nella storia perch√© tantissimi formalismi che intuitivamente sembrano essere molto diversi rispetto alla TM alla fine possono essere dimostrate essere equivalenti.\u003c/p\u003e\n\u003ch3 id=\"turing-con-nastri-addizionali\"\u003eTuring con nastri addizionali\u003c/h3\u003e\n\u003cp\u003eQuesto √® presente in modo abbastanza facile sul Sipser.\u003c/p\u003e","title":"Estensioni di Turing e altre macchine"},{"content":"Introduction Capire in che modo una rete convoluzionale ci pu√≤ dare insight migliori su come funzionano questi networks.\nVisualizzazione dei hidden layers Slide visualization\nPotremmo fissare una immagine anche a caso, e modificare la x in modo che sia pi√π simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa.\nForse questo √® anche il metodo con cui vengono generate le immagini??\nExamples of extracted patterns\nProbabilmente tutte le CNN vanno quindi a tentare ad estrarre questo genere di patterns dall‚Äôimmagine iniziale.\nRicreazione di immagini Vogliamo computare la rappresentazione interna dell‚Äôimmagine, ossia l‚Äôattivazione prodotta da una certa immagine, e da questo possiamo sintetizzare una immagine e poi continuare a fare gradient descent su questa per massimizzare. Una volta al minimo dovremmo avere l‚Äôimmagine migliore per questo layer.\nSlide di esempio\nPer un certo layer non c‚Äô√® differenza fra quei 6 immagini\nQuindi prima partivamo da noise, da questo partiamo da una immagine gi√† e guardiamo in che modo √® rappresentato in questo layer.\nSlide sulla tecnica di solito utilizzata per queste\nSi pu√≤notare che √® pi√π difficile recovery dell‚Äôimmagine nei layers lontani, probabilmente perch√© sta creando una specie di astrazione dell‚Äôimmagine iniziale, quindi l‚Äôimmagine sarebbe l‚Äôimmagine dell‚Äôastrazione. Riusciamo a visualizzare una astrazione, che sembra una contraddizione.\nInceptionism Style transfer Come facciamo a ricreare una immagine utilizzando lo stile di un certo autore?\nEsempi di risultati con style transfer\nMa come facciamo a catturare un concetto astratto di stile di un certo autore?\nConcetto di stile di un autore Non vogliamo solamente avere un contenuto simile (come abbiamo fatto prima, nei primi layers √® una cosa abbastanza semplice) vorremmo proprio essere in grado di catturare lo stile dell‚Äôartista. Quindi da un punto di vista astratto\nSlides stile autore\nCi interessa la correlazione fra features maps di un certo livello, e quando abbiamo una immagine vogliamo allenare per massimizzare la similitudine con la correlazione fra le feature maps.\nData manifolds perch√© facile ingannare le reti Si pu√≤ vedere che con le tecniche dello stile si possono ingannare molto facilmente le reti di sopra. Questo √® perch√© fanno delle classificazioni, fanno discriminazione anzich√© generazione. Ossia con generazione provo a stimare la probabilit√† iniziale che si sia creato la cosa che vogliamo classficiare e con questa probabilit√† poi andiamo a fare la predizione.\nInvece nelle tecniche discriminazione vanno solamente a fare una discriminazione di dati, una cosa statistica. (la frontiera pu√≤ essere molto diversa rispetto alla funzione che lo ha generata diciamo.\nSeguendo comunque il ragionamento sui manifolds di data possiamo dire che √® molto improbabile ~0, che generando a caso, sia una immagine sensata. Infatti lo spazio delle immagini √® enorme, la maggior parte sono ranodm per umani, per√≤ stiamo provando a fare questo un modello di discriminazione (quindi √® chiaro che molte zone che per noi non hanno senso, sono rappresentate nella rete neurale come categorizzate in un certo modo).\nAutoencoders Vogliamo cercare di cambiare lo spazio in modo che la parte delle immagini sensate sia meglio descrivibile, vogliamo andare in pratica a creare una descrizione compatta di quello che vogliamo analizzare. Con gli autoencoder andremo proprio a comprimere il data manifold e poi lavorare su questa compressione.\nSlide intuizione autoencoder\nQuello che vorremmo fare √® una funzione identit√† per certe cose (dato che sono meno, non possiamo fare altro che perdere altre informazioni, ma vogliamo solamente perdere informazioni che non ci servano).\nPossiblit√† della compressione\nLa compressione dovrebbe essere possibile perch√© stiamo cercando regolarit√† nel data, cosa che ci dovrebbe essere perch√© noi umani riusciamo a riconoscere questi pattern, non riusciamo ad insegnarlo ad una macchina. (quando √® molto random per√≤ non si pu√≤ comprimere, stranamente il random √® la cosa con pi√π informazione in termini di teoria dell‚Äôinformazione, ma meno informazione per noi umani, che strana questa asimmetria).\nCaratteristiche della compressione\nSlide caratteristiche\nLa cosa di maggior rilievo √® il fatto del loss, che non riusciamo a fare un reverse che diventi proprio uguale! E poi funziona solamente con data simili (con caratteristiche fortemente correlate fra di loro.\n","permalink":"https://flecart.github.io/notes/explainability-of-cnn/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eCapire in che modo una rete convoluzionale ci pu√≤ dare insight migliori su come funzionano questi networks.\u003c/p\u003e\n\u003ch3 id=\"visualizzazione-dei-hidden-layers\"\u003eVisualizzazione dei hidden layers\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide visualization\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Explainability of CNN/Untitled.png\" alt=\"image/universita/ex-notion/Explainability of CNN/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePotremmo fissare una immagine anche a caso, e modificare la x in modo che sia pi√π simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa.\u003c/p\u003e","title":"Explainability of CNN"},{"content":"The perceptron Slide summary of working of perceptron\nNote on the bias: it is only useful to move the treshhold where to consider the output to be 1 and where to be 1.\nNow we ask what can be predicted by a perceptron?\nWe can see the update rule of the perceptron:\n$$ \\begin{cases} w = w + \\alpha x \\\\ b = b + \\alpha \\end{cases} $$$$ \\alpha = \\begin{cases} 0 \u0026 \\Theta(x \\theta + b) = y \\\\ -1 \u0026 \\Theta(x \\theta + b) \u003e y \\\\ 1 \u0026 \\Theta(x \\theta + b) \u003c y \\end{cases} $$Linearly separability necessity Hyperplanes, because that equation is an hyperplane, so we are sure that we can predict an hyperplane, and that it, and it‚Äôs only it. (it‚Äôs predicting wheter it can be above or below that line). So the perceptron is correct only if the data is linearly separable!\n√à molto peculiare che questa struttura predica qualcosa di tanto semplice! √à solamente quella roba, perch√© basta interpretarla come la linea nel piano, si potrebbe forse dire che esiste un isomorfismo fra percettrone e iperpiano in Rn, dove n √® la dimensione di input!\nNovikoff\u0026rsquo;s Theorem Initialized at zero, the perceptron converges in at most $\\lfloor \\gamma^{-2} \\rfloor$ update steps on any $\\gamma-$separable sample.\nNo gradient information needed! We have an error bound on the test! Number of iterations may be much larger (I don\u0026rsquo;t know why) Finite convergence Learning logical operators We can predict NAND operators, because we can create a plane to divide that, but we can‚Äôt say the same of XOR operators.\nPredicting the NAND operator \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Expressiveness of NN/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Expressiveness of NN/Untitled 1\u0026quot;\u0026gt; The XOR problem If we try to predict XOR, we can see that his graph is\nWe can see that a line can‚Äôt be predicting this function, so we can say that perceptron is not COMPLETE. can‚Äôt predict every function, and we can say it‚Äôs not enough expressive.\nBad thing because for example perceptron can‚Äôt be predicting some kind of pixels put in that configuration, if we interpret the preceding image as pixel colors. It‚Äôs useless (gives me no new information) when we have to compare two features, because this implies it is not linear!\nThis problem is historically very important because it has influenced the first AI winter. They were surprised that it couldn\u0026rsquo;t even learn this easy function.\nMultiplayer Perceptron With the preceding idea, if we can compose nands, we can compute every logical cirtuit, this is the same idea behing the completeness of MLP, this can compute everything! (even two layers is enough using this NAND analogy!)\nSlide XOR prediction with MLP\nShallow networks are COMPLETE after this argument. (but with deepness we would need less neurons (maybe exponentially less, with an argument based on CNF exponential explosion when they are not so deep)!, so deepness has some advantages).\nContinous case Can we compute a continous function as precisely as we want with a neural network?\nAt the end yes! Even with single hidden layer NN! The argument is based on step function activation (and the ability of sigmoid or other non linear functions to mimic the step function when we have the right weights). We can add or subtract an arbitrarily small function, with a value as small as we want!\nSee this for more information!\nWe should not be surprised by this expressiveness, also a big table of numbers would be able to aproximate quite well some functions, to an arbitrarily precise fascion.\n","permalink":"https://flecart.github.io/notes/expressiveness-of-nn/","summary":"\u003ch2 id=\"the-perceptron\"\u003eThe perceptron\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide summary of working of perceptron\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Expressiveness of NN/Untitled.png\" alt=\"image/universita/ex-notion/Expressiveness of NN/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eNote on the bias\u003c/strong\u003e: it is only useful to move the treshhold where to consider the output to be 1 and where to be 1.\u003c/p\u003e\n\u003cp\u003eNow we ask what can be predicted by a perceptron?\u003c/p\u003e\n\u003cp\u003eWe can see the update rule of the perceptron:\u003c/p\u003e\n$$\n\\begin{cases}\nw = w + \\alpha x  \\\\\nb = b + \\alpha\n\\end{cases}\n$$$$\n\\alpha = \\begin{cases}\n0  \u0026  \\Theta(x \\theta + b) = y \\\\\n-1  \u0026  \\Theta(x \\theta + b) \u003e y \\\\\n1  \u0026  \\Theta(x \\theta + b) \u003c y \n\\end{cases}\n$$\u003ch4 id=\"linearly-separability-necessity\"\u003eLinearly separability necessity\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003eHyperplanes\u003c/strong\u003e, because that equation is an hyperplane, so we are sure that we can predict an hyperplane, and that it, and it‚Äôs only it. (it‚Äôs predicting wheter it can be above or below that line).\nSo the perceptron is correct \u003cstrong\u003eonly if the data is linearly separable\u003c/strong\u003e!\u003c/p\u003e","title":"Expressiveness of NN"},{"content":"Fatou\u0026rsquo;s lemma is a fundamental result in measure theory that deals with the relationship between limits and integrals of sequences of non-negative measurable functions. See the wikipedia page for further info.\nStatement of Fatou\u0026rsquo;s Lemma Let $(f_n)$ be a sequence of non-negative measurable functions on a measure space $(X,\\mu)$. Then:\n$$\\int \\liminf_{n \\to \\infty} f_n \\,d\\mu \\leq \\liminf_{n \\to \\infty} \\int f_n \\,d\\mu$$In words, this means that the integral of the limit inferior of a sequence of functions is less than or equal to the limit inferior of their integrals.\nPreliminaries $$\\liminf_{n \\to \\infty} f_n(x) = \\sup_{n \\geq 1} \\inf_{k \\geq n} f_k(x)$$First, let\u0026rsquo;s understand what we want liminf to capture. Informally, the liminf should be the \u0026ldquo;lowest value that the sequence eventually stays above.\u0026rdquo;\nLet\u0026rsquo;s break this down:\nFor a fixed $n$, consider $\\inf_{k \\geq n} f_k(x)$ This represents the lowest value the sequence takes from position $n$ onwards.\nNow, why do we take $\\sup_{n \\geq 1}$ of these infimums? Let\u0026rsquo;s see with an example:\n$$1, 0, 2, 0, 3, 0, 4, 0, 5, 0, ...$$Let\u0026rsquo;s compute $\\inf_{k \\geq n} f_k(x)$ for different $n$:\nFor $n = 1$: $\\inf\\{1,0,2,0,3,0,...\\} = 0$ For $n = 2$: $\\inf\\{0,2,0,3,0,...\\} = 0$ For $n = 3$: $\\inf\\{2,0,3,0,...\\} = 0$ And so on\u0026hellip; Notice that no matter how far out we go, there will always be zeros, so each infimum is 0.\n$$0, 0, 1, 1, 1, ...$$Here:\nFor $n = 1$: $\\inf\\{0,0,1,1,1,...\\} = 0$ For $n = 2$: $\\inf\\{0,1,1,1,...\\} = 0$ For $n = 3$: $\\inf\\{1,1,1,...\\} = 1$ For $n = 4$: $\\inf\\{1,1,...\\} = 1$ By taking $\\sup_{n \\geq 1}$ of these infimums, we capture the value that the sequence eventually stays above (1 in this case).\nThe key insights are:\n$\\inf_{k \\geq n} f_k(x)$ gives us a lower bound for all terms from position $n$ onwards As $n$ increases, these lower bounds might increase (they can\u0026rsquo;t decrease, as we\u0026rsquo;re looking at a subset of the previous terms) Taking the supremum of all these lower bounds gives us the highest lower bound that\u0026rsquo;s valid \u0026ldquo;eventually\u0026rdquo; This is exactly what we want liminf to be: the highest value that eventually serves as a lower bound for the sequence.\n$$\\liminf_{n \\to \\infty} f_n(x) = \\lim_{n \\to \\infty} \\inf\\{f_k(x): k \\geq n\\}$$Proof:\nLet\u0026rsquo;s denote $a_n = \\inf\\{f_k(x): k \\geq n\\}$ for fixed $x$. We need to prove:\n$$\\liminf_{n \\to \\infty} f_n(x) = \\lim_{n \\to \\infty} a_n$$$$ \\liminf_{n \\to \\infty} f_n(x) = \\sup_{n \\geq 1} \\inf_{k \\geq n} f_k(x) $$ Now, let\u0026rsquo;s prove both inequalities:\n$$a_m = \\inf\\{f_k(x): k \\geq m\\} \\geq \\inf\\{f_k(x): k \\geq n\\} = a_n$$ This is because we\u0026rsquo;re taking the infimum over a smaller set.\n$$\\lim_{n \\to \\infty} a_n = \\sup_{n \\geq 1} a_n$$ $$\\lim_{n \\to \\infty} a_n = \\sup_{n \\geq 1} \\inf_{k \\geq n} f_k(x)$$ And this is exactly the definition of $\\liminf_{n \\to \\infty} f_n(x)$\n$$\\liminf_{n \\to \\infty} f_n(x) = \\sup_{n \\geq 1} \\inf_{k \\geq n} f_k(x) = \\lim_{n \\to \\infty} \\inf\\{f_k(x): k \\geq n\\}$$The key insight here is that $(a_n)$ being increasing means its limit exists and equals its supremum. This increasing property comes from taking infimums over progressively smaller sets as $n$ increases.\nProof We first start from the lemma above.\nFor each $n$, define $g_n(x) = \\inf\\{f_k(x): k \\geq n\\}$ Note that $g_n(x) \\leq f_n(x)$ for all $x$ and $n$\nThe sequence $(g_n)$ is increasing: For any $m \u003e n$, $g_m(x) = \\inf\\{f_k(x): k \\geq m\\} \\geq \\inf\\{f_k(x): k \\geq n\\} = g_n(x)$\n$$\\liminf_{n \\to \\infty} f_n(x) = \\lim_{n \\to \\infty} g_n(x)$$ $$\\int \\liminf_{n \\to \\infty} f_n \\,d\\mu = \\int \\lim_{n \\to \\infty} g_n \\,d\\mu = \\lim_{n \\to \\infty} \\int g_n \\,d\\mu$$ $$\\int g_n \\,d\\mu \\leq \\int f_n \\,d\\mu$$ (because $g_n(x) \\leq f_n(x)$ for all $x$, and the integral preserves inequalities)\n$$\\lim_{n \\to \\infty} \\int g_n \\,d\\mu \\leq \\liminf_{n \\to \\infty} \\int f_n \\,d\\mu$$ $$\\int \\liminf_{n \\to \\infty} f_n \\,d\\mu = \\lim_{n \\to \\infty} \\int g_n \\,d\\mu \\leq \\liminf_{n \\to \\infty} \\int f_n \\,d\\mu$$ This completes the proof.\nKey Intuition The lemma essentially states that when taking limits of integrals, you can\u0026rsquo;t \u0026ldquo;lose\u0026rdquo; area in the limit. The integral of the limit inferior provides a lower bound for the limit inferior of the integrals.\n","permalink":"https://flecart.github.io/notes/fatous-lemma/","summary":"\u003cp\u003eFatou\u0026rsquo;s lemma is a fundamental result in measure theory that deals with the relationship between limits and integrals of sequences of non-negative measurable functions.\nSee the \u003ca href=\"https://en.wikipedia.org/wiki/Fatou%27s_lemma\"\u003ewikipedia\u003c/a\u003e page for further info.\u003c/p\u003e\n\u003ch3 id=\"statement-of-fatous-lemma\"\u003eStatement of Fatou\u0026rsquo;s Lemma\u003c/h3\u003e\n\u003cp\u003eLet $(f_n)$ be a sequence of non-negative measurable functions on a measure space $(X,\\mu)$. Then:\u003c/p\u003e\n$$\\int \\liminf_{n \\to \\infty} f_n \\,d\\mu \\leq \\liminf_{n \\to \\infty} \\int f_n \\,d\\mu$$\u003cp\u003eIn words, this means that the integral of the limit inferior of a sequence of functions is less than or equal to the limit inferior of their integrals.\u003c/p\u003e","title":"Fatou's Lemma"},{"content":"Perch√© filesystem? Questa √® l\u0026rsquo;idea presa dall\u0026rsquo;archivio, come se fosse un ufficio che deve tenere delle pratiche ordinate in cartelle e cartelloni.\nL‚Äôutilizzo principale √® dare un interfaccia comune di accesso ai dispositivi. perch√© dispositivi diversi hanno sotto modi di accedere diversi, questa interfaccia facilita molto l\u0026rsquo;accesso.\nInformazioni dei files (5+) üü® Il file √® l‚Äôunit√† logica di memorizzazione. il formato che c\u0026rsquo;√® dentro √® gestito dall\u0026rsquo;applicazione, non dal file system!\nLista degli attributi \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Filesystem/Untitled.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Filesystem/Untitled\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Filesystem/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Filesystem/Untitled 1\u0026quot;\u0026gt; Ci sono un sacco di informazioni memorizzate nei file (un sacco di metadata anche)\nNome Data e ora di accesso o modifica Informazioni sull\u0026rsquo;ownership e protezione di accesso. Dimensione del file TIpo del file Categorizzazione dei files (3) üü©- Tipi di files\nPossiamo andare a distinguere i files a seconda del\nContenuto (se contiene codice oggetto, se contiene dati o informazioni) Struttura, se sono plain text sequenze di bytes, oppure dati strutturati come database., e possono anche essere un albero**.** UNIX: files speciali (blocchi o caratteri), pipes, oltre ai classici files e directories. NOTA: ci sono molte cose che sono viste come files, in unix tutto √® un file :D. Sono identificati da una coppia di numeri che identificano il device driver Files in sistemi operativi comuni üü© I files sono nati con la metafora dell‚Äôufficio:\nArchivi di informazione, che vanno aperti e richiusi (messi nella loro collocazione corretta) √à utile conoscere il tipo di file per capire quale utilizzo andiamo a fare di essa.\nC‚Äô√® un tradeoff, se ho tanti tipi di files, il sistema operativo diventa molto pi√π complesso, se ho troppi pochi potrebbero essere troppo generali.\nSlide tradeoff tipologie di files\nTecniche di identificazione dei file (3) üü© Generalmente ci sono 3 modi per riconoscere il tipo di files:\nMagic numbers Attributo tipo del filesystem estensione. Rispettivamente queste tecniche sono utilizzate in:\nWin (estensioni) Mac, informazioni aggiuntive sui files Unix, il magic number all‚Äôinizio dei files Slide metodi di riconoscimento nei sistemi di riconoscimento\nUnix riconosce solamente gli eseguibili, in questo senso √® minimalista.\nCol magic number riesce anche a riconoscere l‚Äôarchitettura target dell‚Äôeseguibile.\nMac OS ha un codice identificativo per un programma che ha creato il file o la risorsa.\nWindows guarda l\u0026rsquo;estensione. che solitamente sempre da 3 caratteri. (inizilamente il nome del file aveva solo 8 caratteri.\nMetodi di accesso comuni (3) Slide metodi di accesso\nseguenziale\ndiretto\nindicizzato\nUno di particolare interesse √® INDICIZZATO, che si usa spesso per i databases:\nSlide metodo di accesso ad indice\nOperazioni sui files üü® Slide lista delle operazioni\nL‚Äôapertura √® una operazione molto costosa, bisogna\nTrovare i files Capire se si hanno i permessi corretti per poter leggere, o scrivere sul file. Questo si collega molto bene con la metafora dell‚Äôufficio e con l‚Äôarchivio. Se ne ho bisogno vado a prendere dall‚Äôarchivio e la apro se mi serve. Una volta finito lo si rimette apposto.\nNote sull‚Äôapertura e chiusura dei files\nDirectories Introduzione alle directories üü® \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Filesystem/Untitled 10.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Filesystem/Untitled 10\u0026quot;\u0026gt; √à quindi un file speciale che contiene le informazioni di accesso per la gestione dei files al suo interno.\nA seconda dell‚Äôimplementazione possono essere degli array lineari oppure degli hashtable. (si pensi a quanto possano essere grandi le directories, se uso una lista diventa molto lento, se invece si sa gi√† che sia piccola si perde del tempo a fare l‚Äôhash).\nInformazioni nelle directories (2) üü® Slide informazioni delle directories\nSono contenuti i-nodes, che sono degli indici per andare a comprendere la struttura dei files.\nMa pu√≤ cambiare, questo √® un fatto implementativo, potrebbe benissimo anche essere messo nelle entries della directory.\nUNIX ‚Üí messe negli i-node\nMSDOS ‚Üí messe nelle dir entries.\nLunghezza dei nomi üü® Introduzione al problema della lunghezza dei nomi Anche qui facciamo distinzione fra nomi a lunghezza variabile e nomi fissi, MSDOS al tempo utilizzava nomi fissi con necessariamente estensioni a tre caratteri.\nMetodi per nomi a lunghezza variabile Il metodo a √® preferita, perch√© nel secondo devo leggere in fondo per trovare il nome del file Directories a grafo aciclico I files, possono avere pi√π nomi, in questo senso non ho pi√π un albero ma un grafo.\nSlide struttura grafo aciclico Semantica di coerenza üü• Dato che i sistemi moderni sono maggiormente tutti multitasking, vogliamo andare a specificare quando una modifica di un file pu√≤ essere vista da un altro processo.\nimmediato: questa √® la semantica che viene utilizzata anche nei sistemi UNIX, una modifica √® subito vista da altri programmi. Bisogna chiedersi ora come si faccia ad implementare una cosa di questo genere.\nAFS: √® un esempio di file system interplanetario, in cui non era possibile fare una semantica imemdiata (i dati erano sparsi in mezzo al mondo). semantica di coerenza delle sessioni √® il nome di questo. ossia il file veniva modificato quando il file era chiuso. Questo era necessario perch√© ogni write dovevano rendere traffico sulla rete, era troppa questa sincronizzazione e troppo traffico direi.\nLa struttura Inode Allocazione Master Boot Record üü®+ Slide MBR\nQuesto √® il classico modo di fare partizioni, e si possono fare al massimo 4 partizioni.\nPraticamente √® una prima sezione del disco, che contiene una piccola tavola di partizioni, indice alla partizione attiva e informazioni per fare il boot, poi individua la sezione della partizione col boot, ed esegue quello per caricare il sistema operativo.\n√à utile soprattutto per creare delle aree logiche diverse in cui possono esserci diverse informazioni.\n(altro √® global partitioning table anche GPT, che permette pi√π partizioni)\nStruttura di una partizione (5) üü©‚Äî \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Filesystem/Untitled 16.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Filesystem/Untitled 16\u0026quot;\u0026gt; Slide spiegazione sezioni logiche della partizione\nUn boot block che c\u0026rsquo;√® sempre Superblock contiene informazioni per mount, ad esempio √® qui che si accorge se √® stato unmounted o mounted correttamente Alcune cose per gestire spazio libero ed occupato Directory root e poi il filesystem √® gestito come pare a seconda dei filesystem Allocazione contiguaüü© Slide allocazione contigua Slide svantaggi allocazione contigua Contigua nel senso che lo metto nel blocco di memoria contiguo libero.\nQuesto √® l‚Äôimplementazione pi√π veloce, facile da indicizzare.\nIl problema principale √® che √® statico, per esempio non posso allargare il file giallo, si dovrebbe andare a cercare un blocco abbastanza largo per storare questo. Questo √® il problema principale.\nInfatti se ho un filesystem si sola lettura viene utilizzato questa tipologia di allocazione ISO9660\nAllocazione concatenata üü® Slide allocazione concatenata Slide vantaggi svantaggi\nIn pratica in ogni blocco di dati abbiamo un indice per il prossimo (per√≤ √® lento perch√© sono molto sparsi, perch√© devo fare seek e i file vanno in molti posti, per questo dovrei lanciare defrags molto spesso, ma almeno i file possono crescere ed essere modificati liberamente)\nSVANTAGGI:\nAccesso inefficiente (posso solo inziare dall\u0026rsquo;inizio a scandire, non posso fare un offset) √® che i puntatori possono avere un grosso overhead per blocchi di dati piccoli. (e anche l\u0026rsquo;assunzione che il blocco di dati non √® pi√π una potenza di due). Seek di file, che vengono dispersi per utto il disco Per limitare la frammentazione dei file e l\u0026rsquo;overhead posso utilizzare cluster\nSlide cluster blocchi\nAllocazione a File Allocation Table (FAT) üü®+ Slide FAT Slide svantaggi e vantaggi\nIn pratica ho una tabella apparte che mi dice in che modi i blocchi sono concatenati, in questo modo tolgo l‚Äôoverhead ai blocchi stessi e posso gestirmi apparte sti puntatori.\nSarebbe lento un accesso in pi√π alla tabella fat, ma di solito questa viene caricata in RAM come se fosse una cache, quindi √® molto pi√π veloce. (se poi il blocco √® grosso si dovrebbe perdere molto di meno).\nSarebbe lenta perch√© il disco dovrebbe andare avanti indietro ogni volta per accedere al blocco successivo.\nAllocazione indicizzata üü®++ Slide allocazione indicizzata\nIn pratica ho un blocco di dati che contiene solamente i blocchi di dati del file, questo permette un accesso diretto molto veloce. Per√≤ non posso avere una lunghezza a piacere del file, perch√© il numero di indici in un blocco di dati √® limitato (prima aveva dimensione a piacere).\nSlide svantaggi vantaggi2\nSOLUZIONE ALLA LIMITAZIONE INDICI:\nConcatenazione blocchi indici\nSlide soluzione concatenazione\nPer√≤ con questa soluzione torno ai problemi di accesso diretto lento e frammentazione delle allocazioni precedenti (‚Üí prestazione degrada linearmente con i blocchi)\nMultilivello\nIndice multilivello\nQuesta cosa si pu√≤ rendere ricorsiva, la prestazione degrada logaritmicamente, molto poco abbiamo una sorta di albero here.\nGestione dello spazio libero Bitmap Slide allocazione bitmap\nHo praticamente una bitmap con un bit per ogni cluster, per indicare se √® libero occupato, una soluzioen simile √® anche utilizzata in Bitmap üü© parlando di allocazione di pagine in RAM.\nLista concatenata Slide lista concatenata\nProblemi di frammetazione grossi, dato che i blocchi libero possono praticamente stare ovunque.\nAnche questo metodo l\u0026rsquo;abbiamo descritto in Paginazione e segmentazione, abbiamo anche una lista di bloccchi liberi per la FAT. ne abbiamo parlato anche in Gestione della memoria per la HEAP, gli algoritmi alla fine sono gli stessi.\nConfronto cluster dati e spazio utilizzato Notiamo che dopo un certo punto se abbiamo un blocco di dati troppo grosso il disco lo utilizziamo poco ma il rate dei dati √® molto bello. Quindi se ho dati grossi ho buona roba.\nIn UNIX Multi-livello in unix. Ci sono tanti file piccoli e pochi grandi, quelli grandi possono essere anche molto annidati con l‚Äôallocazione indicizzata multilivello. I file piccoli sono molto veloci di accedere, sono praticamente subito accessibile\nLink hard e soft Per sistemi FAT questi non sono possibili solitamente. in unix √® identificato dall‚Äôinode, se due cose indicano lo stesso inode ecco che posso creare un link, √® come se avessi due files per lo stesso inode.\nLa cancellazione logica √® proprio chiamata unlink, quando l‚Äôultimo nome del file √® tolto allora il file √® stato cancellato.\nIl soft link √® un file, il so capisce che √® un link, ma non si riferisce allo stesso inode.\nCurare e prevenireüü• Curare il filesystem significa riportare lo stato del filesystem in uno stato coerente, ma non abbiamo garanzie riguardo che i files siano stati tutti salvati correttamente\nil check √® uno scan completo di tutto il filesystem\nSlide curare fsck\nPraticamente l\u0026rsquo;eseguibile fsck si va a ricostruire l‚Äôalbero degl inode, se non c\u0026rsquo;√® nessuna reference la mette nei lost and found, riporta tutti gli errori di block size e path names.\nPer filesystems che prevengono ,come ext3, prova a vedere tutto come una transazione, quindi va a registrare le operazioni riguardo il filesystem in un singolo file. Dopo ci√≤ si mette a farlo. √® idempotente.\nSlide transazioni\nConcatenata FAT\n","permalink":"https://flecart.github.io/notes/filesystem/","summary":"\u003ch3 id=\"perch√©-filesystem\"\u003ePerch√© filesystem?\u003c/h3\u003e\n\u003cp\u003eQuesta √® l\u0026rsquo;idea presa dall\u0026rsquo;archivio, come se fosse un ufficio che deve tenere delle pratiche ordinate in cartelle e cartelloni.\u003c/p\u003e\n\u003cp\u003eL‚Äôutilizzo principale √® dare un \u003cstrong\u003einterfaccia comune di accesso ai dispositivi.\u003c/strong\u003e perch√© dispositivi diversi hanno sotto modi di accedere diversi, questa interfaccia facilita molto l\u0026rsquo;accesso.\u003c/p\u003e\n\u003ch3 id=\"informazioni-dei-files-5-\"\u003eInformazioni dei files (5+) üü®\u003c/h3\u003e\n\u003cp\u003eIl file √® \u003cstrong\u003el‚Äôunit√† logica di memorizzazione\u003c/strong\u003e. il formato che c\u0026rsquo;√® dentro √® gestito dall\u0026rsquo;applicazione, non dal file system!\u003c/p\u003e","title":"Filesystem"},{"content":"A simple motivation Fisher\u0026rsquo;s Linear Discriminant is a simple idea used to linearly classify our data. The image above, taken from (Bishop 2006), is the summary of the idea. We clearly see that if we first project using the direction of maximum variance (See Principal Component Analysis) then the data is not linearly separable, but if we take other notions into consideration, then the idea becomes much more cleaner.\nA first approach üü®- $$ m_{j} = \\frac{1}{N_{j}}\\sum_{i : y_{i} = j} x_{i} $$$$ \\arg\\max_{w} w^{T}(m_{2} - m_{1}) + \\lambda (\\lVert w \\rVert _{2}^{2} - 1) $$ Then we find a solution $w \\propto (m_{2} - m_{1})$.\nBut the problem with this formulation is that we could have some strong overlap in the projected domain, due to non diagonal covariances in the class distribution. We would also like to minimize the within class variance during the projection, so that we can better separate the two values.\nAdding inter-class variance $$ s_{i}^{2} = \\sum_{n \\in \\mathcal{C}_{i}} (w^{T}x_{n} - w^{T}m_{n})^{2} $$ We simply compute the inter-class variance and divide, getting the Fisher discriminant\n$$ J(w) = \\frac{w^{T}(m_{2} - m_{1})^{2}w}{s_{1}^{2} + s_{2}^{2}} = \\frac{w^{T}S_{B}w}{w^{T}S_{I}w} $$ The lower part is the sum of the within class variances, while the upper part is the between class covariance.\nNow, if we do some calculus we find that the best solution is $w \\propto S^{-1}_{w}(m_{2} - m_{1})$\nCode example Code example nicely produced by Claude. Checked by Human.\nimport numpy as np import matplotlib.pyplot as plt class FisherLDA: def __init__(self, n_components=1): \u0026#34;\u0026#34;\u0026#34; Initialize Fisher\u0026#39;s Linear Discriminant Analysis Parameters: n_components (int): Number of components to keep (usually 1 for binary classification) \u0026#34;\u0026#34;\u0026#34; self.n_components = n_components self.w = None # Projection vector def fit(self, X, y): \u0026#34;\u0026#34;\u0026#34; Fit the LDA model according to Fisher\u0026#39;s criterion Parameters: X: array-like of shape (n_samples, n_features) y: array-like of shape (n_samples,) - Class labels \u0026#34;\u0026#34;\u0026#34; # Split data by class X0 = X[y == 0] X1 = X[y == 1] # Calculate class means mean0 = np.mean(X0, axis=0) mean1 = np.mean(X1, axis=0) # Calculate within-class scatter matrix Sw S0 = np.zeros((X.shape[1], X.shape[1])) S1 = np.zeros((X.shape[1], X.shape[1])) for x in X0: x = x.reshape(-1, 1) S0 += (x - mean0.reshape(-1, 1)) @ (x - mean0.reshape(-1, 1)).T for x in X1: x = x.reshape(-1, 1) S1 += (x - mean1.reshape(-1, 1)) @ (x - mean1.reshape(-1, 1)).T Sw = S0 + S1 # Calculate between-class scatter matrix Sb mean_diff = (mean1 - mean0).reshape(-1, 1) Sb = mean_diff @ mean_diff.T # Calculate optimal projection vector w # w ‚àù Sw^(-1)(Œº1 - Œº0) try: self.w = np.linalg.inv(Sw) @ (mean1 - mean0) # Normalize the projection vector self.w = self.w / np.linalg.norm(self.w) except np.linalg.LinAlgError: # If Sw is singular, use pseudoinverse self.w = np.linalg.pinv(Sw) @ (mean1 - mean0) self.w = self.w / np.linalg.norm(self.w) return self def transform(self, X): \u0026#34;\u0026#34;\u0026#34; Project the data onto the most discriminative direction Parameters: X: array-like of shape (n_samples, n_features) Returns: X_transformed: array-like of shape (n_samples, n_components) \u0026#34;\u0026#34;\u0026#34; return X @ self.w # Demonstration if __name__ == \u0026#34;__main__\u0026#34;: # Generate sample data np.random.seed(42) n_samples = 100 # Class 0 mean0 = [0, 0] cov0 = [[1, 0.5], [0.5, 1]] X0 = np.random.multivariate_normal(mean0, cov0, n_samples) # Class 1 mean1 = [2, 2] cov1 = [[1, 0.5], [0.5, 1]] X1 = np.random.multivariate_normal(mean1, cov1, n_samples) # Combine data X = np.vstack([X0, X1]) y = np.hstack([np.zeros(n_samples), np.ones(n_samples)]) # Fit LDA lda = FisherLDA() lda.fit(X, y) # Transform data X_transformed = lda.transform(X) # Plotting plt.figure(figsize=(12, 5)) # Original data plt.subplot(121) plt.scatter(X0[:, 0], X0[:, 1], label=\u0026#39;Class 0\u0026#39;) plt.scatter(X1[:, 0], X1[:, 1], label=\u0026#39;Class 1\u0026#39;) plt.arrow(0, 0, lda.w[0], lda.w[1], color=\u0026#39;r\u0026#39;, width=0.05, label=\u0026#39;Projection direction\u0026#39;) plt.xlabel(\u0026#39;Feature 1\u0026#39;) plt.ylabel(\u0026#39;Feature 2\u0026#39;) plt.title(\u0026#39;Original 2D Data with LDA Direction\u0026#39;) plt.legend() # Projected data plt.subplot(122) plt.hist(X_transformed[y == 0], bins=20, alpha=0.5, label=\u0026#39;Class 0\u0026#39;) plt.hist(X_transformed[y == 1], bins=20, alpha=0.5, label=\u0026#39;Class 1\u0026#39;) plt.xlabel(\u0026#39;Projected Values\u0026#39;) plt.ylabel(\u0026#39;Frequency\u0026#39;) plt.title(\u0026#39;Projected Data on Fisher Direction\u0026#39;) plt.legend() plt.tight_layout() plt.show() References [1] Bishop ‚ÄúPattern Recognition and Machine Learning‚Äù Springer 2006\n","permalink":"https://flecart.github.io/notes/fishers-linear-discriminant/","summary":"\u003ch4 id=\"a-simple-motivation\"\u003eA simple motivation\u003c/h4\u003e\n\u003cp\u003eFisher\u0026rsquo;s Linear Discriminant is a simple idea used to linearly classify our data.\n\u003cimg src=\"/images/notes/Fisher's Linear Discriminant-20241031125847321.webp\" alt=\"Fisher's Linear Discriminant-20241031125847321\"\u003e\u003c/p\u003e\n\u003cp\u003eThe image above, taken from (Bishop 2006), is the summary of the idea.  We clearly see that if we first project using the direction of maximum variance (See Principal Component Analysis) then the data is not linearly separable, but if we take other notions into consideration, then the idea becomes much more cleaner.\u003c/p\u003e","title":"Fisher's Linear Discriminant"},{"content":"Introduzione Radio üü© \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Fisica del Wireless/Untitled.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Fisica del Wireless/Untitled\u0026quot;\u0026gt; Antenna: converte corrente in segnali radiorequenza e viceversa. le segnali radiofrequenza sono onde radio con frequenza diversa per rappresentare 1 o 0. Un altro modo per mandare 1 o 0 sarebbe semplicemente cambiare l‚Äôintensit√† della onda, mantenendo la stessa frequenza.\nViene utilizzata una variazione di potenziale elettrico per creare il segnale, dovrebbe essere un oscillatore armonico in pratica credo. Creando questo flusso di elettroni, crea anche un campo elettromagnetico a lui ortogonale, questa √® l‚Äôonda radio, che si propaga alla velocit√† della luce.\nEss√¨ per capire questa parte serve ripassare un p√≤ di fisica, in Onde elettromagnetiche scuola (in realt√† c‚Äô√® molto poco qui).\nIl prof ha spiegato questo fenomeno in 20 minuti, questo video sembra buono per comprendere questa cosa.\nCaratteristiche dell‚Äôonda elettromagnetica (3) üü© L‚Äôonda radio utilizzata in wireless √® solamente un sottotipo delle onde radio.\nFrequenza onda La relazione fra lunghezza d‚Äôonda e frequenza dell‚Äôonda con la velocit√† dell‚Äôonda √® conosciuta: $v = f\\lambda$ Comunque la frequenza √® un altra caratterizzazione importante per l‚Äôonda.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Fisica del Wireless/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Fisica del Wireless/Untitled 1\u0026quot;\u0026gt; Nota: questo √® un range di frequenza! Questo ci permette di creare molti canali con frequenze diverse.\nUn problema molto difficile √® la scomposizione delle frequenze, cos√¨ possiamo isolare i singoli canali. Le onde sono additive, sono tutte messes assieme!\nNOTA: massima efficienza per la creazione di onde √® quando la lunghezza dell‚Äôantenna √® stessa lunghezza dell‚Äôonda radio, ma anche sottomultipli binari sembrano andare bene.\nAmpiezza Poi l‚Äôintensit√†, ossia l‚Äôampiezza dell‚Äôonda, √® l‚Äôaltro carattere importante\n√à strettamente correlato con l‚Äôenergia utilizzata per generare l‚Äôonda, cio√® se ho ampiezza maggiore ho speso in generare pi√π energia per generare quell‚Äôonda.\nNota: L‚Äôenergia dell‚Äôonda decade in distanza quadratica, (se voglio raggiungere doppia distanza, devo quadruplicare la potenza) quindi perde energia molto velocemente. In modo intuito il motivo per cui questo succede √® che l‚Äôenergia iniziale √® la stessa, idealmente dopo un certo momento √® ancora la stessa energia (nel senso che non la perdo), per√≤ √® dispersa in una area molto maggiore, che si espande quadraticamente con la distanza, ecco che quando andiamo a ricevere stiamo prendendo solamente un pezzo molto piccolo di questa energia iniziale.\nEsempio del panino con la nutella\nQuesto √® un esempio che il prof. ha fatto in aula, √® un modo molto visivo per dare l‚Äôintuito di questa decadimento di potenza.\nMettiamo caso che prendiamo un cucchiaione di nutella e la spalmiamo sulla fetta. In questo caso la fetta √® bona, si sente bene la nutella. Mettiamo caso che di nuovo prendiamo il cucchiaione, la mettiamo sulla fetta. E ops, la fetta diventa in un secondo grosso 300km, la nutella √® sempre la stessa, ed √® spalmata uniformemente, ora la sento ancora la nutella? Se c‚Äô√® anche un muro poi mi perndi anche la nutella quando la fetta si espande! ne ho ancora di meno Ovviamente se diventa troppa poca l‚Äôeneergia, poi non riesco a sentire cosa dice! cio√® non detecto il segnale\nSlide decadenza di potenza Fase dell\u0026rsquo;onda Una terza caratterizzazione, oltre l\u0026rsquo;ampiezza e la frequenza √® la fase dell‚Äôonda. ossia quanto sono spostate rispetto a un periodo assoluto (questo shift di fase √® in radianti o gradi)\nUn onda spostata rispetto al riferimento, posso considerarla o in anticipo o in posticipo, la somma delle due per√≤ √® 360, quindi √® lo stesso modo di descrivere le due.\nSlide phase shift\nSi hanno problemi con la fase quando questa rimbalza con qualcosa e va a interferire con s√© stesso.\nClassificazione zone di segnale (3) üü®+ Andiamo a definire una signal detection limit, ossia il punto da cui dopo non e piu detectabile il segnale, e quindi non comprendo pi√π cosa mi viene comunicato.\nSu quanto definito sopra potremmo definire 3 zone correlata alla distanza fra il sender e il ricevente:\nSlide zone di propagazione segnale\nLa capacit√† del ricevente influenza in quale zona stai (come se avessi l‚Äôorecchio pi√π fine o meno!)\nTrasmission range quando riesco a comprendere un un errore bitrate molto basso Detection range non si riesce a capire cosa viene trasmesso, ma si nota che si trasmette qualcosa Interference range quando i segnali potrebbero anche non essere rivelati perch√© troppo deboli A volte se ho molte sources, un buon metodo potrebbe essere mettere un filtro che filtri un certo tipo di canale, se ascolto sto ascoltanto un certo misto di segnale. (una cosa carina √® che la radiazione di fondo si mischia con questi üòõ)\nProblemi della rete wireless (3) üü®- intensit√† del segnale che decade in fretta intereferenza con stessa frequenza da sorgenti diversi Interferenza con s√© stesso (se percorre distanze diverse, rimbalzando da qui e la, e giunte sfasato! O passare ostacoli?) Ostacoli(3) Dietro l\u0026rsquo;ostacolo faccio fatica ad avere segnale L\u0026rsquo;ostacolo fa rimbalzare l‚Äôonda radio Il materiale influenza fortemente questo comportamento dell‚Äôonda (anche rifrazione!) Slide ostacoli assorbono\nSlide influenze ostacoli\nIn generale se l\u0026rsquo;onda √® a bassa frequenza, passa l\u0026rsquo;ostacolo, se √® alta √® molto facile che si blocchi.\nQuindi abbiamo un tradeoff di questo tipo:\nOnda bassa frequenza, va lontano, ma contiene poche informazioni al secondo Onda alta frequenza non va lontano, ma tante informazioni! (motivo per cui la cella 5g deve essere per forza piccola) E ci sono alcuni fenomeni come terminale nascosto o fading, sempre per caratteristiche di ostacoli e evanescenza del segnale che interferiscono fra di loro.\nPUNTI CIECHI DELLE ANTENNE (1)\nSe posiziono l\u0026rsquo;antenno in un certo modo, questa non riesce proprio a leggere le onde radio in una certa posizione (a causa della polarizzazione)\nSlide punti ciechi (polarizzazione)\nSe sto allo stesso orientamento dell\u0026rsquo;antenna, riesco a leggere tutto bene le informazioni delle antenne, mentre invece se sto ortogonale non potrei vedere niente. Questa √® anche chiamata polarizzazione dell‚Äôonda.\nSlide polarizzazione (con esempio di foro per intuito)\nLa soluzione a questo problema √® utilizzare pi√π antenne di diverse orientazioni. Quindi comunque riesco a prendere qualcosa (se lo metto in modo ortogonale, a L, riesco a ricavare il segnale iniziale sempre).\nNOTA: indoor ho i muri che rimbalzano, quindi alla fine comunque mi arriva di direzione giusta, e non ho un problema di sensibilit√† tale.\nNOTA2: i satelliti sono fighi, non hanno nessun ostacolo per comunciazione onde radio, forse le nuvole sono il pi√π grande problema, che riescono ad assorbire e riflettere anche qui le onde radio.\nEffetti sull\u0026rsquo;uomo (non fare) üü© 300 MHz and 300 GHz sono il range delle microonde, quando il cellulare emette certe onde di quella requenza, allora √® proprio questo! Solamente di intensit√† molto minore. (sono milliwatt contro centinaia di watt), quindi un p√≤ comunque scalda! E attraversa comunque un p√≤ la materia, e scalda l‚Äôacqua a questa frequenza.\nhttps://www.fda.gov/radiation-emitting-products/cell-phones/do-cell-phones-pose-health-hazard\napprofondimento carino: vedere come funziona la risonanza, e se questo √® il fenomeno che fa scaldare l‚Äôacqua.\nSlide effetti sull\u0026rsquo;uomo\nCome fanno le onde radio ad arrivare alle auto? Se la cabbia di faraday proprio va a schermare il tutto? Evade molto poco, e quello √® quello che va nell\u0026rsquo;access point.\nLa trasmissione del segnale Guadagno del segnale (2) üü© Si dice guadagno del segnale quando incremento la potenza del segnale, in un certo rapporto in confronto a quanto trasmesso. Si misura in DECIBEL.\nguadagno attivo questo √® quello che vanno a fare gli amplificatori, che hanno bisogno di energia dall\u0026rsquo;esternom prende le onde in input e utilizza l‚Äôenergia per rigenerare il segnale, sono quello che fanno i repeaters. guadagno passivo quando non ho bisogno di energia all‚Äôesterno. Per esempio √® cos√¨ che funzionano i dischi delle parabole, che riescono a prendere molto segnale, e concentrarla in un unico punto. Perdita di segnale üü©- Intenzionale questa √® utile per gestire l‚Äôenergia (e.g. far passare 6 ampere in un circuitino sarebbe troppo, quindi trasformo in calore prima di far entrare nel circuito) (oppur esempio un connettore, che riflette in parte e fa passare con intensit√† minore, e questo √® proprio misurabile id dB) ostacoli come acqua. perdita del segnale ‚Äònon voluta‚Äô, dovuta ad ostacoli, ad esempio in caso di nebbia, che rappresenta un ostacolo per le microonde che scaldando le particelle d‚Äôacqua di cui √® composta la nebbia, facendo ridurre l‚Äôenergia del segnale (e quindi l‚Äôampiezza), riducendo la distanza che pu√≤ percorrere il segnale. Slide tipologie di effetti di ostacoli\nMultipath propagation (2) üü®‚Äî Il segnale pu√≤ giungere da molte direzioni, e il segnale ricevuto pu√≤ essere in una fomra strana (phase shifted, tre echi meno energetici, parzialmente sovrapposti.\nGli effetti principali della multi path sono:\nI segnali possono arrivare in momenti diversi e fare interferenza con s√© stesso I segnali possono arrivare phase shiftati. Effects of mobility (non fare?) üü• Ci sono proprio delle zone in cui il segnale √® migliore e altre in cui non va per il wifi, in cui cambiano subito questa parte di segnale\nSlide mobilit√†\nL‚Äôeffetto principale √® la variabilit√† del segnale quando ci muoviamo, possiamo avere alti e bassi e continuamente ci connettiamo a ripetitori diversi (questo √® anche un modo per ricostruire il tuo percorso, a seconda di quale dispositivo ti sei connesso vicino).\nCambiano anche distanza dal destinatario e dagli obstacoli.\nVoltage Standing Wave Ratio üü®+ √à proprio necessario utilizzare la stessa impedenza! Altrimenti diventa molto inefficiente,\nVSWR √® una perdita del segnale quando l\u0026rsquo;impedenza della sorgente e del ricevente sono diversi fra di loro. C\u0026rsquo;√® un effetto resistivo quando le correnti si spotano in questo modo, che crea calore. (corrente genera Se il valore di impedenza √® diverso ho:\nIrregolarit√† (anche ritorno di energia), perdita di energia. bruciare delle componenti. Calcolato come rapporto delle impedenze del trasmettitore e ricevente.\nIntentional radiator e regulations üü©- Intentional radiator √® il trasmittitore pi√π cavi e connettori con l\u0026rsquo;antenna\nIntentional radiator Power output: quanit√† di energia data all\u0026rsquo;antenna dall\u0026rsquo;intero componente dietro l‚Äôantenna, quindi cavi connettori e il generatore (i cavi fanno perdere un p√≤ di energia, in questo senso l\u0026rsquo;antenna non riceve l‚Äôenergia del trasmettitore come da sorgente, ma quella decaduta dalla corrente.\nSu questo IR Poutput si mettono le regulations, ossia massimo energia a livello antenna, ma si potrebbe fare che l\u0026rsquo;energia che riceve siano dentro i limiti, ma utilizzo una antenna in modo da focalizzare il raggio, rendendolo molto pi√π denso.\nPer questo motivo bisognerebbe mettere il la regolazione non sul power output, che si pu√≤ concentrare, ma sul EIRP (Equivalent isotropically radiated power), ossia la potenza radio irradiata dall‚Äôantenna con anche gli effetti passivi (ossia concentrati diciamo), una volta che sono al massimo dell Power output.\nMisura della potenza Il WATT üü© Quelli che ci interessano sono soprattuto i watt, che sono una misura della potenza, la quantit√† di lavoro fatto al secondo.\nIn pratica √® una misura di\nenergy needed (in a given time unit) to apply a given ‚Äúpressure‚Äù to a given ‚Äúamount of charge‚Äù, by resulting in a flow of current.\nLe formule classiche sono le leggi di OHM che qui per√≤ saltiamo.\nSlide misura della potenza\nI decibels üü© Spesso andare a ragionare in watt √® molto scomodo, perch√© la potenza cade in modo logaritmico (non era quadratico??) dato che √® logaritmico meglio utilizzare i decibels\nDecibel (dB) measures the logarithmic relative strength between two signals (mW are a linear absolute measure a energy)\nNOTA: √® molto importante il fatto che i decibels siano relativi!\nSlide sui decibels\nCalcolo dei decibels $$ dB = 10 \\times \\log_{10}(\\dfrac{W_{Receiver}}{W_{Sender}}) $$Formula inversa:\n$$ W_{receiver} = W_{sender}\\exp(dB \\log(10)/ 10) $$ Esempi di calcolo Il vantaggio principale √® che invece a stare modificare moltiplicazioni e divisioni, sto utilizzando somme e sottrazioni che creano numeri molto pi√π gestibili, (questo √® sempre isomorfismo prodotto e somma in un certo gruppo credo).\nUna cosa carina √® che tipo 3 decibels √® moltiplicare o dividere per 2.\nNormalized decibels dBm üü© Praticamente diciamo che $1 mW = 1dBm$ $$ P_{dBm} = 10 \\log(P_{mW}) \\\\ P_{mW} = \\exp(P_{dBm} / 10) $$Con qualche costante messa bene per i logs.\nScala decibels milliwatt\nIsotropic decibels dBi üü© I decibels isotropici misurano il guadagno passivo dato dall‚Äôarchitettura dell‚Äôantenna confrontandolo con il caso ideale di un antenna isotropica, con efficienza 100%, equiparabile a un dipolo di lunghezza nulla.\nSlides isotropic decibels\ndB-dipole üü© Questo √® solamente un dipole translato di 2.14 se mi ricordo bene, solamente il compare di una antenna dipolo con una isotropica i suppose, quindi non molto di differenza.\n","permalink":"https://flecart.github.io/notes/fisica-del-wireless/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"radio-\"\u003eRadio üü©\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Fisica del Wireless/Untitled.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Fisica del Wireless/Untitled\u0026quot;\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAntenna: converte corrente in segnali radiorequenza e viceversa. le segnali radiofrequenza sono onde radio con frequenza diversa per rappresentare 1 o 0. Un altro modo per mandare 1 o 0 sarebbe semplicemente cambiare l‚Äôintensit√† della onda, mantenendo la stessa frequenza.\u003c/p\u003e\n\u003cp\u003eViene utilizzata una variazione di potenziale elettrico per creare il segnale, dovrebbe essere un oscillatore armonico in pratica credo.\nCreando questo flusso di elettroni, crea anche un campo elettromagnetico a lui ortogonale, questa √® l‚Äôonda radio, che si propaga alla velocit√† della luce.\u003c/p\u003e","title":"Fisica del Wireless"},{"content":"Questa parte √® strettamente collegata conl a parte di Astrazione sul controllo.\nSi parla di passare le funzioni come dati. e quindi possono essere passati come se fossero dei parametri.\nun linguaggio di programmazione √® di ordine superiore qualora ammetta funzioni sia come parametro che come risultato di altre funzioni.\nLa parte molto simile alla precedente √® il fatto di valutare la funzione nell\u0026rsquo;ambiente iniziale, quindi bisogna utilizzare un sistema simile a quello del passaggio per nome.\nDeep and shallow binding Esempio di passaggio di funzione\nSi noti che questa distinzione fra scope statico e dinamico √® indipendente da queste regole di shallow e deep binding, queste regole qui ci dicono quale ambiente scegliere per la valutazione, mentre le altre ci dicono in che modo percorrere le catene, se andare per catena dinamica o statica.\nDeep Binding In questo caso viene associato alla funzione la x presente al momento di creazione del binding. Nell‚Äôesempio di sopra la x in riga 11. se ho scope dinamico, invece quello a riga 2 se ho scope statico\nShallow Binding In questo caso l‚Äôultimo binding possibile, quando sono proprio dentro la funzione (quindi la x attiva in quell‚Äôambiente). Nell‚Äôesempio di sopra la x in riga 5. Quindi si valuta la funzione al momento della chiamata.\nImplementazione del shallow binding Questa √® l\u0026rsquo;implementazione semplice, praticamente uguale allo scope dinamico in Nomi e Scope. Quindi cerco l‚Äôultima istanza presente fra tutte quelle presenti (se voglio scope statico, risalgo catena statica, altrimenti risalgo catena dinamica). Esattamente come si faceva per lo scope dinamico, infatti si potrebbe dire che √® pi√π naturale utilizzare scope dinamico con questo, anche se si potrebbe senza problemi utilizzare scope statico!.\nQuesto perch√© l‚Äôultima presente era quella ancora presente nell\u0026rsquo;ambiente di chiamata!\nImplementazione del deep binding Abbiamo detto che vogliamo valutare il deep binding seguendo la sua struttura (in questo caso statico, oppure nello scope di chiamata, in quel caso dinamico).\nQuesto √® easy, si segue direttamente lo stesso sistema fatto per il nome e per la catena statica, passando una coppia (funzione, ambiente) chiamata chiusura della funzione, la funzione sar√† il puntatore al codice, mentre l\u0026rsquo;ambiente √® determinato cos√¨:\nStatico In questo caso devo mettere nel puntatore d‚Äôambiente in cui la nostra funzione √® dichiarata, questo si pu√≤ avere a tempo di compilazione, perch√© conosco il livello di annidamento della funzione, e anche al momento della creazione del binding, quindi utilizzo un sistema simile in Nomi e Scope. (quindi scorrere la catena statica con la differenza che conosco, oppure display).\nDinamico In questo caso basta mettere l\u0026rsquo;ambiente in cui metto creo il binding fra parametro formale e attuale.\nIl caso del C In C non abbiamo cose come i lambda, non abbiamo quindi problemi di risoluzione di ambienti, perch√© tanto non posso dichiarare funzioni in ambienti non locali.\nSemplicemente in C tutte le funzioni passate come parametro vengono risolte nell\u0026rsquo;ambiente globale. Non c\u0026rsquo;√® proprio la necessit√† di utilizzare la catena statica! Tutto risolto a compile-time.\nFunzioni come ritorno di funzione Quello che viene ritornato √® una chiusura, ma come valutare una chiusura in un ambiente che √® gi√† scomparso üòµ ?? Scomparso nel senso che non l‚Äôavremmo pi√π sulla stack sto ambiente! Non possiamo fare altro che utilizzare un ambinete illimitato di vita. E dare la responsabilit√† al garbace collector l\u0026rsquo;onere di liberare questo ambiente.\n","permalink":"https://flecart.github.io/notes/fn-ordine-superiore/","summary":"\u003cp\u003eQuesta parte √® strettamente collegata conl a parte di \u003ca href=\"/notes/astrazione-sul-controllo/\"\u003eAstrazione sul controllo\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSi parla di \u003cstrong\u003epassare le funzioni come dati\u003c/strong\u003e. e quindi possono essere passati come se fossero dei parametri.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eun linguaggio di programmazione √® di ordine superiore qualora\nammetta funzioni sia come parametro che come risultato di altre funzioni.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eLa parte molto simile alla precedente √® il fatto di \u003cstrong\u003evalutare\u003c/strong\u003e la funzione nell\u0026rsquo;ambiente iniziale, quindi bisogna utilizzare un sistema simile a quello del passaggio per nome.\u003c/p\u003e","title":"Fn Ordine superiore"},{"content":"https://virtuale.unibo.it/pluginfile.php/1295166/mod_resource/content/0/Lez18-Gorrieri.pdf\nHalting problem Questo asserisce che non esiste nessun programma che sia in grado di decidere la terminazione di un altro programma\nQuesto √® un problema che ci √® interessante perch√© vorremmo costruire un compilatore che sia in grado di osservare tutti gli errori possibili del programma. Come vedremo tra poco la risposta sar√† negativa.\nDimostrazione tesi üü®++ Supponiamo che questo programma esista, lo chiamiamo check(P) che restituisce 0 se termina 1 se non termina, allora devo poter essere in grado di scrivere un programma di questo genere\nprocess ABSURD(x): if (check(ABSURD(x))): return 0; else: while (true); endprocess Allora se il processo ABSURD con x in input termina, si avr√† che non termina e vale anche il contrario. E questo √® un chiarissimo assurdo. In questo modo troviamo una funzione non calcolabile ed √® stato uno dei primi episodi storici di non calcolabilit√† (Turing 1936) in quello storico paper.\nNOTA: questa sezione non √® molto formale, √® utile per√≤ per dare l‚Äôintuizione, per andare in modo formale √® bene andare a guardarsi le slide del prof (c‚Äô√® un errore di input di funzioni).\nNon calcolabilit√† dell‚Äôeguaglianza üü•+ Si pu√≤ dimostrare che non esiste un programma che decida se due programmi calcolano la stessa cosa, altrimenti ci potremmo ricondurre a un caso molto simile a quello di sopra.\nDimostrazione\nSe esistesse tale funzione, potrei costruire la funzione che decide se quanto calcolato √® uguale alla funzione costante 0. Se ho questa funzione allora posso costruire una funzione\nF(P) che prende in input una funzione e un dato, e calcola 0 se converge, e diverge con essa se diverge. Con questa funzione posso costruire la funzione check perch√© se converge posso dire con sicurezza che √® 1, e se diverge posso dire che √® 0\nCostruzioni del prof. (3) üü®++ Assurdo che esista un programma che mi dica se un programma si stoppi o meno\nQuesta sezione √® utile se vuoi ripetere quello che dice il prof.\n$$ H(P,x) = \\begin{cases} 1\\, P(x)\\downarrow \\\\ 0 \\, P(x) \\uparrow \\end{cases} $$$$ K(P) = H(P,P) $$$$ G(P) = \\begin{cases} 1\\, K(P) = 0 \\\\ \\uparrow, K(P) = 1 \\end{cases} $$Ma se proviamo a calcolare $G(G)$ vediamo che se $G(G)$, che √® quello che va a calcolare K, termina, allora non terminer√†, per come ho costruito G, se non terminer√† allora termina per come ho costruito G.\nNessun programma mi pu√≤ dire se una funzione calcola una costante o meno üü•\n$$ Z(P) = \\begin{cases} 1, \\forall x, P(x) = 0 \\\\ 0, \\exists x, P(x) \\neq 0 \\end{cases} \\\\ F(P,x) = \\begin{cases} 0, P(x) \\downarrow \\\\ \\uparrow, P(x) \\uparrow \\end{cases} $$Si noti che entrambe le funzioni di sopra sono calcolabili, allora se vale questo vale che\n$$ K(P) = H(P, P) = Z(F(P,P)) $$Il trucco non sta altro che sfruttare il fatto che Z termina lo stesso anche se una funzione pu√≤ divergere talvolta, senza restituire qualcosa (allora so che non dar√† mai la costante), ma se funzione normalmente fa sempre 0.\nNessun programma pu√≤ dire che due programmi sono equivalenti\n$$ Equiv(P, Q) = \\begin{cases} 1, \\forall x, P(x) = Q(x) \\vee P(x) = \\uparrow = Q(x) \\\\ 0, \\text{altrimenti} \\end{cases} \\\\ Z(P) = Equiv(P, zero) $$E quindi avrei una funzione che calcoli se una funzione √® 0.\nDecidibilit√† Vedere La macchina di Turing#Problemi di decisione per definizione pi√π adatta e corrente.\nIntroduzione üü®+ Decidibilit√† (2)\nDati certi input, devo rispondere con 1 o 0 in tempo finito, questo √® l‚Äôunico output che posso dare. Un esempio di problema di decidibilit√† √® dire se appartiene o meno a un certo insieme.\nUn problema che non √® decidibile √® indecidibile.\nSemidecibilit√†\nQuando in tempo finito riesce a dirmi 1, ma per dire 0 diverge. Un esempio di programma con questa propriet√† √® la funzione check che stavamo sviluppando prima, che dice 1 se converge e 0 se non converge.\nNotare che il caso contrario, quello che per 1 diverge, e per 0 converge, non √® semidecidibile (il problema della divergenza non √® semidecidibile).\nEsempi di problemi indecibili ! (5) Se la funzione calcola una costante Se la funzione termina Se la funzione diverge (il suo contrario) Se due programmi sono equivalenti Se esistono errori run-time del programma La macchina di turing Introduzione (6) üü© Una macchina di turing pu√≤ essere determinata da 6 variabili.\nStati\nAlfabeto in input\nAlfabeto del nastro infinito\nStato iniziale\nstato finale\nFUnzione di stransizione da (stato, simbolo nastro) ‚Üí (stato, simbolo nastro, spostamento sinistra/destra)\nSlide\nIn modo analogo a quanto fatto in precedenza possiamo andare a definire un alfabeto riconosciuto dalla macchina di turing.\nCalcolabilit√† secondo Turing üü®+ Definizione di calcolabilit√†\nMolto easy, Calcolabile secondo turing se esiste una macchina di turing (quindi definita da quelle 6 cose) che calcola quella funzione\nSlide\nOsservazioni\nSi pu√≤ notare che il numero che le funzioni che sono turing calcolabili sono solamente numerabili quindi c‚Äô√® una stragrande maggioranza delle funzioni che non possiamo nemmeno andare a calcolare!\nJacopini-B√∂hn e l‚Äôequivalenza üü© Si pu√≤ dimostrare che molti formalismi sono turing-completi ossia sono in grado di calcolare esattamente le stesse funzioni della macchina di turing. (basta che il programma abbia tutta la memoria di cui necessita).\nIl teorema di JB ci dice che se un linguaggio di programmazione possiede\nIf-then-else While statements e assegnamento ‚Üí Turing completo.\nCome conseguenza di questo teorema ci fu, storicamente parlando, uno sviluppo della programmazione strutturata, in cui andiamo solamente a guardare i parametri locali per decidere e capire cosa faccia la funzione.\nTesi di church turing Vedere La macchina di Turing#Tesi di Church-Turing\nSe una funzione pu√≤ essere calcolata algoritmicamente in un qualche formalismo allora √® calcolabile con il formalismo della macchina di turing\nQuesto non √® un teorema √® solamente una tesi che √® riuscita a resistere al tempo, che da grande valore al significato della macchina di turing.\nLa nota informale di questa tesi che non permette ancora un attacco matematico-formale √® che\nil concetto di algoritmo non √® ancora stato ben formalizzato, e non si pu√≤ applicare per tutti i formalsimo Questa cosa deve essere vera per ogni formalismo, ma come formalizzare il formalismo stesso e poter parlare subito per tutti i formalismi? Note finali Comparazione fra le macchine üü• Slide comparazione\nAbbiamo visto che\nMacchina di turing √® la pi√π generale, utilizza grmamatiche generali (quindi senza vincoli) e calcola cose semidecibili\nPDA, libera, calcola cose decidibili, anche se non sono in grado di dire cose riguardanti ugualgianza boh.\nDFA pu√≤ essere utilizzata per modellizzare tante cose come\nVending machine Circuiti logici Find/replace principalmente √® tutto decibile per questo qua.\n","permalink":"https://flecart.github.io/notes/fondamenti-teorica/","summary":"\u003cp\u003e\u003ca href=\"https://virtuale.unibo.it/pluginfile.php/1295166/mod_resource/content/0/Lez18-Gorrieri.pdf\"\u003ehttps://virtuale.unibo.it/pluginfile.php/1295166/mod_resource/content/0/Lez18-Gorrieri.pdf\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"halting-problem\"\u003eHalting problem\u003c/h2\u003e\n\u003cp\u003eQuesto asserisce che \u003cstrong\u003enon esiste nessun programma che sia in grado di decidere la terminazione di un altro programma\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eQuesto √® un problema che ci √® interessante perch√© vorremmo costruire un compilatore che  sia in grado di osservare \u003cstrong\u003etutti gli errori possibili\u003c/strong\u003e del programma. Come vedremo tra poco la risposta sar√† negativa.\u003c/p\u003e\n\u003ch3 id=\"dimostrazione-tesi-\"\u003eDimostrazione tesi üü®++\u003c/h3\u003e\n\u003cp\u003eSupponiamo che questo programma esista, lo chiamiamo \u003ccode\u003echeck(P)\u003c/code\u003e che restituisce 0 se termina 1 se non termina, allora devo poter essere in grado di scrivere un programma di questo genere\u003c/p\u003e","title":"Fondamenti teorica"},{"content":"Intuition $$ \\frac{1}{\\sqrt{ 2\\pi }}, \\frac{\\cos(kx)}{\\sqrt{ \\pi }}, \\frac{\\sin(kx)}{\\sqrt{ \\pi }}, \\dots $$$$ \\int_{0}^{2\\pi} (\\sin (kx))^{2} \\, dx = \\int_{0}^{2\\pi} (\\cos(kx))^{2} \\, dx = \\pi $$$$ \\int_{0}^{2\\pi}\\sin(kx)\\sin(hx) \\, dx = \\int_{0}^{2\\pi}\\cos(kx)\\cos(hx) \\, dx = 0 $$$$ \\int_{0}^{2\\pi}\\sin(kx)\\cos(hx) \\, dx = \\int_{0}^{2\\pi} \\sin(kx) \\, dx = \\int_{0}^{2\\pi}\\cos(hx) \\, dx = 0 $$Proofs of the relations In this section we quickly prove why the above equations hold. First we all agree that $\\int_{0}^{2\\pi} \\sin(kx) \\, dx = \\int_{0}^{2\\pi} \\cos(hx) \\, dx = 0$ because their period divides $2\\pi$ and the sum of the area of a period is clearly 0. Or we can explicitly find the primitive and solve\n$$ \\int_{0}^{2\\pi} \\sin(kx) \\, dx = -\\frac{1}{k} \\cos(kx) \\bigg\\vert_{0}^{2\\pi} = 0 - 0 $$ Equivalently the other part with the cosine.\nFor the other relations we need to remember some trigonometric identities:\n$$ \\int_{0}^{2\\pi} \\sin(kx) \\cos(hx) \\, dx = \\frac{1}{2} \\left[ \\int_{0}^{2\\pi} \\sin((k + h)x) \\, d + \\int_{0}^{2\\pi}\\sin((k - h)x) \\, dx \\right] $$$$ = = \\frac{1}{2}\\left[ \\frac{-1}{k + h} \\cos((k + h)x)\\bigg\\vert_{0}^{2\\pi} + \\frac{-1}{k - h} \\cos((k - h)x) \\bigg\\vert_{0}^{2\\pi} \\right] = \\frac{1}{2} (0 + 0) $$$$ \\sin x \\cdot \\sin y = \\frac{1}{2}\\left[ \\cos(x - y) - \\cos(x + y) \\right] $$$$ \\cos x \\cdot \\cos y = \\frac{1}{2} \\left[ \\cos(x - y) + \\cos(x + y) \\right] $$And then you can prove every relation.\nFourier Series $$ S_{n}f = \\sum_{i=0}^{2n} \\langle f, e_{i} \\rangle e_{i} $$$$ S_{n}f(x) = \\left( \\int_{0}^{2n} \\frac{1}{\\sqrt{ 2\\pi }} f(t) \\, dt \\right) \\frac{1}{\\sqrt{ 2\\pi }} + \\sum_{k=1}^{n} \\left[ \\left( \\int_{0}^{2n} \\frac{\\cos(kt)}{\\sqrt{ \\pi }} f(t) \\, dt \\right) \\frac{\\cos(kx)}{\\sqrt{ \\pi }} + \\left( \\int_{0}^{2\\pi} \\frac{\\sin(kt)}{\\sqrt{ \\pi }}f(t) \\, dt \\right) \\frac{\\sin(kx)}{\\sqrt{ \\pi }} \\right] $$$$ S_{n}f(x) = \\frac{1}{2}a_{0} + \\sum_{k=1}^{n}(a_{k}\\cos(kx) + b_{k}\\sin(kx)) $$ With $a_{k} = \\frac{1}{\\pi}\\int_{0}^{2\\pi} f(t) \\cos (kt) \\, dt$ and $b$ equivalently. these $a, b$ are called Fourier coefficients of $f$. We call $S_{n}f(x)$ nth Fourier sum\n$$ S_{n}f(x) = \\sum_{n = -N}^{N}C_{n}e^{i 2\\pi xn/p} $$Properties of the Fourier Series Norm of the Fourier Series $$ \\lVert S_{n} f \\rVert ^{2} = \\pi \\left[ \\frac{a_{0}^{2}}{2} + \\sum_{k = 1}^{n} (a_{k}^{2} + b_{k}^{2}) \\right] $$$$ \\lVert S_{n}f \\rVert^{2} = \\int_{0}^{2\\pi} \\lvert S_{n}f \\rvert ^{2} \\, dx $$ And then it is far easier to derive.\nThe Fourier transform We used this to solve a differential equation in Diffusion Models.\nThe transformations $$ F(k, t) = \\int e^{-i2\\pi kx}f(x, t) \\, dx $$$$ f(x, t) = \\int e^{i2\\pi kx}F(k, t) \\, dk $$","permalink":"https://flecart.github.io/notes/fourier-series/","summary":"\u003ch2 id=\"intuition\"\u003eIntuition\u003c/h2\u003e\n$$\n\\frac{1}{\\sqrt{ 2\\pi }}, \\frac{\\cos(kx)}{\\sqrt{ \\pi }}, \\frac{\\sin(kx)}{\\sqrt{ \\pi }}, \\dots\n$$$$\n\\int_{0}^{2\\pi} (\\sin (kx))^{2} \\, dx  = \\int_{0}^{2\\pi} (\\cos(kx))^{2} \\, dx  = \\pi\n$$$$\n\\int_{0}^{2\\pi}\\sin(kx)\\sin(hx) \\, dx = \\int_{0}^{2\\pi}\\cos(kx)\\cos(hx) \\, dx = 0\n$$$$\n\\int_{0}^{2\\pi}\\sin(kx)\\cos(hx) \\, dx = \\int_{0}^{2\\pi} \\sin(kx) \\, dx = \\int_{0}^{2\\pi}\\cos(hx) \\, dx = 0   \n$$\u003ch3 id=\"proofs-of-the-relations\"\u003eProofs of the relations\u003c/h3\u003e\n\u003cp\u003eIn this section we quickly prove why the above equations hold.\nFirst we all agree that $\\int_{0}^{2\\pi} \\sin(kx) \\, dx = \\int_{0}^{2\\pi} \\cos(hx) \\, dx = 0$ because their period divides $2\\pi$ and the sum of the area of a period is clearly 0. Or we can explicitly find the primitive and solve\u003c/p\u003e","title":"Fourier Series"},{"content":"On dangling pointers Tombstones üü© Slides tombstones\nQuando alloco, alloco anche una tombstone, e tutti i riferimenti passano per quella. (quindi ho due dereference per l‚Äôaccesso) quando vado a deallocare segno la tombstone come RIP, NULL.\nDopo molto tempo ho il problema del cimitero che diventa molto grande. Anche se non punta pi√π a niente, il cimitero.\nKeys and locks üü© Un p√≤ di overhead in pi√π dal punto di vista della memoria, che √® doppio\nOn GC Reference counting üü© Quando alloco, mi tengo anche un contatore di riferimenti, ossia puntatori che fanno riferimento a questo blocco. Quando arriva a zero dealloco. Questo √® una variabile privata del GC, non √® accessibile da nessuna parte dall‚Äôesterno.\nCome fare per riferimenti ricorsivi? Se avessimo due elementi che si puntano fra di loro ma non sono accessibili tramite stack?\nCon questa tecnica non √® possibile risolverlo bisogna utilizzare il metodo successivo.\nMark and sweep üü© Slide tecnica mark and sweep\nDefinito in due parti:\nFase di detection, in cui parto marcando tutto, poi se riesco a raggiungerlo tolgo il mark. remotion vado a rimuovere tutti quelli marcati (alla fine √® la stessa cosa marcare non marcare, basta invertire), in questo modo riconosco tutti i pezzi i memoria non raggiungibili e so cosa andare a togliere. Svantaggio principale:\nNon so quando andare a fare mark and sweep:\nOgni tot tempo Quando finisco la memoria (ogni tot memoria). Quando fa GC devo fermare il programma (stop the world) perch√© non ha senso che inserisco cose quando vado a marcare (pensala come modify list quando ci scorri). Per sistemi realtype non funziona proprio, perch√© non posso permettermi di bloccare la computazione. Implementazione: invesione dei puntatori üü®+ Come facciamo ad implementare questa tecnica quando magari √® invocata solamente quando ho finito lo spazio? Non possiamo utilizzare la stack, perch√© la memoria √® finita.\nSi utilizza la tecnica di inversione dei puntatori:\nSlide inversione dei puntatori\nStop and copy Slide tecnica stop and copy\nLa heap √® divisa in due regioni differenti, quando una √® piena (credo) copio tutto nell\u0026rsquo;altra zona. Questo √® buono quando ho pochi blocchi ancora buoni, perch√© ci metterei molto meno a spostare e emttere nell‚Äôaltra.y\nBorrow checking (non fatto) Questa √® la cosa nuova introdotta da Rust.\nOwnership Lifetimes ","permalink":"https://flecart.github.io/notes/garbage-collection/","summary":"\u003ch2 id=\"on-dangling-pointers\"\u003eOn dangling pointers\u003c/h2\u003e\n\u003ch3 id=\"tombstones-\"\u003eTombstones üü©\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlides tombstones\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Garbage Collection/Untitled.png\" alt=\"image/universita/ex-notion/Garbage Collection/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eQuando alloco, alloco anche una tombstone, e tutti i riferimenti passano per quella. (quindi ho due dereference per l‚Äôaccesso) quando vado a deallocare segno la tombstone come RIP, NULL.\u003c/p\u003e\n\u003cp\u003eDopo molto tempo ho il problema del cimitero che diventa molto grande. Anche se non punta pi√π a niente, il cimitero.\u003c/p\u003e\n\u003ch3 id=\"keys-and-locks-\"\u003eKeys and locks üü©\u003c/h3\u003e\n\u003cp\u003eUn p√≤ di overhead in pi√π dal punto di vista della memoria, che √® doppio\u003c/p\u003e","title":"Garbage Collection"},{"content":"Gaussian processes can be viewed through a Bayesian lens of the function space: rather than sampling over individual data points, we are now sampling over entire functions. They extend the idea of bayesian linear regression by introducing an infinite number of feature functions for the input XXX.\nIn geostatistics, Gaussian processes are referred to as kriging regressions, and many other models, such as Kalman Filters or radial basis function networks, can be understood as special cases of Gaussian processes. In this framework, certain functions are more likely than others, and we aim to model this probability distribution.\nGaussian processes retain epistemic uncertainty, meaning we are still modeling what we don\u0026rsquo;t know about the function, while remaining tractable. Essentially, they provide a normal distribution over functions.\nIf we index this infinite dimensional Gaussian, thanks to the properties of Gaussians with marginalization, we still have another Gaussian. We need a way to parametrize now. In this case we do it using a covariance function $k(x, x') = \\text{Cov} (f(x), f(x'))$\nThis seems a quite nice resource on the topic.\nFormal definition of Gaussian Process A Gaussian process is an infinite set of random variables such that any finite number of them are jointly Gaussian.\nThe informal ideas is that we use the probability of the joints, given by our training dataset, to do some inference.\n$$ K_{A A} = \\begin{pmatrix} k(x_{1}, x_{1}), \\dots, k(x_{1}, k_{m}) \\\\ \\vdots \\\\ k(x_{m}, x_{1}), \\dots, k(x_{m}, k_{m}) \\end{pmatrix} \\text{ and } \\mu_A = \\begin{pmatrix} \\mu(x_{1}) \\\\ \\vdots \\\\ \\mu(x_{m}) \\end{pmatrix} $$$k : X \\times X \\to \\mathbb{R}$ is called the covariance (kernel) function and $\\mu : X \\to \\mathbb{R}$ is called the mean function. We write $f \\sim GP(\\mu, k)$ and define $f(x) := f_{x}$ See Kernel Methods for more about kernels.\nInference for Gaussian Processes üü© Inference is easy if you understand the conditional Gaussian distribution, see Gaussians. You already have the old points defined, you just need to get the conditioned Gaussian on the previous data points.\n$$ \\bar{f} = \\begin{bmatrix} y \\\\ f* \\end{bmatrix}, \\, \\bar{\\Sigma} =\\begin{bmatrix} \\Sigma_{AA} + \\sigma_{n}^{2}I \u0026 k(x^{*}, A)^{T} \\\\ k(x^{*}, A) \u0026 k(x^{*}, x^{*}) \\end{bmatrix}, \\mu = \\begin{bmatrix} \\mu_{A} \\\\ \\mu_{f^{*}} \\end{bmatrix} $$ We just use the conditional Gaussian to have that our wanted distribution $f^{*} \\mid f$ has the following distribution:\n$$ \\begin{cases} \\mu = \\mu_{f^{*}} + k(x^{*}, A)^{T}(\\Sigma_{AA} + \\sigma^{2}_{n}I)^{-1}(A - \\mu_{A}) \\\\ \\Sigma = k(x^{*}, x^{*}) - k(x^{*}, A)^{T}(\\Sigma_{AA} + \\sigma_{n}^{2}I)^{-1}k(x^{*}, A) \\end{cases} $$ And then you just sample with this, which we will solve in the next section. Where $k(x^{*}, A) = \\left[ k(x^{*}, x_{1}), \\dots,k(x^{*}, x_{n}) \\right]$\nIf we have only the GP prior then the mean $\\mu_{f^{*}} = 0$, this is often a convention because the prior mean is only used to compute the posterior mean, and can be easily added back in. One note: the posterior mean depends on the observations $y$ while the variance does not.\nSampling for Gaussian Processes Standard Gaussian Sampling üü©\u0026ndash; $$ \\begin{array} \\\\ f_{1:n} \\sim \\mathcal{N}(\\mu_{f}, K_{f}) \\\\ \\end{array} $$Forward Sampling üü© $$ \\begin{array} \\\\ f_{1} \\sim p(f_{1}) \\\\ f_{2} \\sim p(f_{2} \\mid f_{1}) \\\\ \\vdots \\\\ f_{n} \\sim p(f_{n} \\mid f_{1:n-1}) \\end{array} $$ But we need to compute the matrix inverse in this case, which also takes $\\mathcal{O}(n^{3})$.\nLearning Gaussians Processes Kernel optimization üü®++ Once we have chosen a Kernel, we would like to find the best Hyper-parameters for our problem. Take a look at the Kernel Methods for possible Kernels. We want to optimize the following equation: $$ \\begin{align} \\ \\hat{\\theta_{MLE}} \u0026amp;= \\arg \\max_{\\theta} p(y_{\\text{train} }\\mid x_{\\text{train}}, \\theta) \\\n\u0026amp;= \\arg \\max_{\\theta} \\int p(y_{\\text{train}} \\mid f, x_{\\text{train}}, \\theta)p(f \\mid \\theta) , df \\ \u0026amp;= \\arg \\max_{\\theta} \\int p(y_{1:n} \\mid f_{1:n}, x_{1:n}, \\theta)p(f_{1:n} \\mid \\theta) , df \\ \u0026amp;= \\arg \\max_{\\theta} \\int \\prod_{i = 1}^{n} \\mathcal{N}(y_{i} \\mid f_{i}; 0, \\sigma^{2}{n} )\\mathcal{N}(f{1:n} ; 0, K_{f}(\\theta)) df \\ \u0026amp;= \\arg \\max_{\\theta} \\mathcal{N}(y_{1:n} ; 0, K_{y}(\\theta)) \\ \u0026amp;= \\arg \\max_{\\theta} \\frac{1}{\\sqrt{ (2\\pi)^{n} \\lvert K_{y}(\\theta) \\rvert }}\\exp\\left( - \\frac{1}{2} y_{1:n}^{T} K^{-1}{y}(\\theta) y{1:n} \\right) , \\end{align}\n$$ Now let's take the negative log and we will get: $$$$ Where $$$$ And $$ K_{y}(\\theta) = K_{f}(\\theta) + \\sigma^{2}_{n}I $$\n$$ \\frac{ \\partial \\log p(y_{1:n} \\mid x_{1:n}, \\theta) }{ \\partial \\theta_{j} } = \\frac{1}{2} \\text{tr}\\left( (\\alpha \\alpha^{T} - K^{-1}_{y, \\theta}) \\frac{ \\partial K_{y, \\theta} }{ \\partial \\theta_{j}} \\right) $$ With $\\alpha = K_{y, \\theta}^{-1}y$, you just need some formulas from Multi Variable Derivatives. Now let\u0026rsquo;s take some time to analyze what we good after all of this derivation: The quadratic form is interpretable as the likelihood, or the goodness of the fit. While the log of the Kernel matrix is the volume of the possible prediction, which is kinda the prior. Minimizing the above loss with gradient methods or similars can give us the best kernel parameters.\nWe can also obtain a Map Estimate if we place a prior on the kernel parameters $p(\\theta)$.\nHyper-priors üü©\u0026ndash; Another way to optimize is using hyper-priors. Basically, we assume the priors have parameters too, and we try to optimize over those parameters. Usually a good way to choose kernels is posterior agreement. Given the data, we would like to make the probability of the given data as high as possible. This is very important but I have not understood this well\nApproximating GPs Leaning a Gaussian Process is usually quite slow. We will introduce some local methods for faster approximation, and a technique introduced in Rahimi, Recht NeurIPs 2007, it is a general algorithm for simplifying stationary kernels.\nLocal methods üü© One way is only use points such that satisfy $\\lvert k(x, x') \\rvert \\geq \\tau$, the idea is that point that are far away usually have not such a great influence. This is still expensive if there are too many points close. Basically we can restrict ourselves to a subset of the Covariance matrix, as most other points will be set to $0$. This method essentially cuts off the tails of the distribution.\nKernel function approximation üü© $$ k(x, x') \\approx \\phi(x)^{T}\\phi(x') $$ Such that $\\phi(x) \\in \\mathbb{R}^{m}$, and $m$ is a much smaller dimensionality (easier to compute). Then it\u0026rsquo;s just GP with a linear kernel, or a Bayesian linear regression.\nFourier Features üü®++ We make use of Bochner\u0026rsquo;s theorem which states that a Kernel is a valid Mercer Kernel if its Fourier transform $p(\\omega)$ is non-negative (which implies it is a valid probability distribution). When $p$ is a valid function, it is called spectral density.\n$$ k(x, x') = k(x - x') = \\int _{\\mathbb{R}^{d}} p(\\omega) e^{j\\omega^{T}(x - x')} \\, d\\omega = \\mathbb{E}_{\\omega, b}[z_{\\omega, b}(x) \\cdot z_{\\omega, b}(x')] $$ Where $\\omega \\sim p(\\omega), b \\sim U([0, 2\\pi])$, and define $z_{\\omega, b}(x) = \\sqrt{ 2 } \\cos(\\omega^{T}x + b)$ where we are reinterpreting the integral as an expectation, one can show that these two are equivalent. The important thing to note here is that we have an unbiased approximator for some Kernel, given we have its spectral density.\n$$ \\mathbb{E}_{\\omega, b}[z_{\\omega, b}(x) \\cdot z_{\\omega, b}(x')] = \\frac{1}{m} \\sum_{i = 1}^{m} z_{\\omega, b}(x) \\cdot z_{\\omega, b}(x') = z(x)^{T}z(x) $$ Where $z(x) = \\frac{1}{\\sqrt{ m }}[z_{\\omega_{1, b_{1}}}(x), \\dots, z_{\\omega_{m, b_{m}}}(x)]$ Now we have an explicit random feature map, where $m$ works as a parameter for quality of the approximation.\nOne can also have some error analysis, telling you how close is the approximation to the original kernel. The theoretical thing is that this approximates the kernel function uniformly well, we use uniform convergence in this setting, which we don\u0026rsquo;t know exactly what this is.\nOne nice thing to see is that one can prove BLR with fourier features is equivalent to GP with a stationary kernel.\nUniform Convergence of Fourier Features üü• $$ \\begin{align} \\mathbb{P}( \\lvert k(x, x') - z(x)^{T}z(x') \\rvert \u003e \\varepsilon) \\\\ \\leq2^{8} \\left( \\frac{\\mathop{\\mathbb{E}}_{w \\sim p}[w^{T}w]D_{\\mathcal{M}}}{\\varepsilon} \\right)^{2} \\exp \\left( -\\frac{m\\varepsilon^{2}}{8 (d + 2)} \\right) \\end{align} $$ Where we observe that the decay of the error is exponential in the number of Fourier features $m$\nProof: We first observe that $z(x)^{T}z(x)$ is shift invariant as the function that it attempts to approximate is. Then you can define some function $f(x, x') = k(x, x') - z(x)^{T}z(x')$ and then we can define the function solely using the difference $\\Delta = x - x'$.\n$$ \\mathbb{P}(\\lvert f(\\Delta) \\rvert \u003e \\varepsilon ) \\leq \\exp\\left( - m \\varepsilon^{2}\\right) $$ Where we note that $0 \\leq z(x)^{T}z(x) \\leq 2$\nTODO: finish, this proof is hard\u0026hellip;\nInducing points üü®+ Introduced in (Quinonero-Candela and Rasmussen, 2005), we want to summarize the points of the training set into the inducing points, and then use these points for inference.\nThen the original Gaussian can be recovered in this manner:\n$$ p(f^{*}, f) = \\int p(f^{*}, f, u) \\, du = \\int p(f^{*} \\mid u)p(f \\mid u)p(u) \\, du $$ Recall that $f^{*}$ and $f$ are conditionally independen. The values $p(f^{*} \\mid u)$ and $p(f \\mid u)$ are respectively called testing conditional and training conditional.\nThus, the time complexity is cubic in the number of inducing points, but only linear in the number of data points.\nBecause we need to invert the matrix for the inducing point, but we don\u0026rsquo;t need to invert the matrix for the training points.\n","permalink":"https://flecart.github.io/notes/gaussian-processes/","summary":"\u003cp\u003eGaussian processes can be viewed through a Bayesian lens of the function space: rather than sampling over individual data points, we are now sampling over entire functions. They extend the idea of \u003ca href=\"/notes/bayesian-linear-regression/\"\u003ebayesian linear regression\u003c/a\u003e by introducing an infinite number of feature functions for the input XXX.\u003c/p\u003e\n\u003cp\u003eIn geostatistics, Gaussian processes are referred to as \u003cem\u003ekriging\u003c/em\u003e regressions, and many other models, such as \u003ca href=\"/notes/kalman-filters/\"\u003eKalman Filters\u003c/a\u003e or radial basis function networks, can be understood as special cases of Gaussian processes. In this framework, certain functions are more likely than others, and we aim to model this probability distribution.\u003c/p\u003e","title":"Gaussian Processes"},{"content":"Gaussians are one of the most important family of probability distributions. They arise naturally in the law of large numbers and have some nice properties that we will briefly present and prove here in this note. They are also quite common for Gaussian Processes and the Clustering algorithm. They have also something to say about Maximum Entropy Principle. The best thing if you want to learn this part actually well is section 2.3 of (Bishop 2006), so go there my friend :)\nThe Density Function $$ \\mathcal{N}(\\mu, \\sigma) = \\frac{1}{\\sqrt{ 2\\pi } \\sigma} \\exp\\left( -\\frac{(x - \\mu)^{2}}{2\\sigma^{2}} \\right) $$$$ \\mathcal{N}(\\mu, \\Sigma) = \\frac{1}{(2\\pi )^{d/2}\\sqrt{ \\lvert \\Sigma \\rvert } } \\exp\\left( -\\frac{1}{2} (x - \\mu)^{T} \\Sigma^{-1} (x - \\mu) \\right) $$ Where $d$ is the dimensionality for the multidimensional Gaussian.\nIntegral is 1 üü•++ We now prove that the integral of the Gaussian PDF is 1, this is a requirements needed to be considered a probability distribution function.\n$$ I = \\int_{-\\infty}^{\\infty} \\exp( - x^{2}) \\, dx = \\sqrt{ \\pi } $$$$ \\begin{align} \\\\ I^{2} \u0026 = \\int_{-\\infty}^{\\infty} \\exp( - x^{2} - y^{2}) \\, dx dy \\\\ \u0026 = \\int_{0}^{2\\pi} \\int_{0}^{\\infty} r\\exp( - r^{2}) \\, dr d\\theta \\\\ \u0026 = 2\\pi \\cdot \\left( -\\frac{1}{2} \\right) \\int_{0}^{\\infty} -2r\\exp( - r^{2}) \\, dr \\\\ \u0026 = -\\frac{2\\pi}{2} \\exp(-r^{2}) \\bigg\\vert_{0}^{\\infty} = \\pi \\\\ \u0026 \\implies I = \\sqrt{ \\pi } \\end{align} $$Note that in the second step we changed variables: This is quite interesting. If we do the same derivation with $\\exp\\left( - \\frac{(x - \\mu)^{2}}{2\\sigma^{2}} \\right)$, first doing a change of variables $y = (x - \\mu)$ where we have $dy = dx$, then doing another change of variables $z = \\frac{y}{\\sqrt{ 2 \\sigma^{2} }}$ where we get $\\sqrt{ 2\\sigma^{2} }dz = dy$ now we have the same integral, plus an added constant multiplicative term. So we have\n$$ \\int _{-\\infty}^{\\infty} \\exp\\left( -\\frac{(x - \\mu)^{2}}{2\\sigma^{2}} \\right) \\, dx = \\sqrt{ 2\\sigma^{2} } \\int _{-\\infty}^{\\infty} \\exp(-z^{2})\\, dz = \\sqrt{ 2\\pi \\sigma^{2}} $$ Which finishes the derivation of the normalizing term.\nError Function üü®\u0026ndash; $$ \\text{erf}(x) = \\frac{2}{\\sqrt{ \\pi }} \\int_{0}^{x} \\exp(-t^{2}) \\, dt $$$$ \\text{erf}(x) = \\frac{1}{\\sqrt{ \\pi }} \\int_{-x}^{x} \\exp(-t^{2}) \\, dt $$ We observe that the limit $x \\to +\\infty$ is 1, and that $x \\to -\\infty$ is -1.\n$$ \\text{erf}\\left( \\frac{x}{\\sqrt{ 2 }} \\right) = 2\\Phi(x) - 1 $$$$ \\text{erf}(-x) = -\\text{erf}(x) $$Some properties of Gaussians The conditional Gaussian If we have $X,Y$ which are jointly Gaussian, then the distribution $p(X = x \\mid Y = y)$ is a gaussian with the following mean and variance:\n$$ \\mu_{X \\mid Y = y} = \\mu_{X} + \\Sigma_{XY} \\Sigma_{YY}^{-1}(y - \\mu_{Y}) $$$$ \\Sigma_{X \\mid Y} = \\Sigma_{XX} - \\Sigma_{XY} \\Sigma^{-1}_{YY} \\Sigma_{YX} $$The proof is presented in section 2.3 of (Bishop 2006)\nProduct of Gaussians are Gaussian üü®++ This is a little more difficult to detail, see this chatgpt response. It\u0026rsquo;s just an Unnormalized Gaussian.\nMarginals are Gaussians üü® One can prove that any finite marginals of Gaussians are still multivariate Gaussians.\n$$ p(A, B) = \\begin{bmatrix} A \\\\ B \\end{bmatrix} \\sim \\mathcal{N}(\\mu, \\Sigma) $$$$ \\mu = \\begin{bmatrix} \\mu_{A} \\\\ \\mu_{B} \\end{bmatrix}, \\Sigma = \\begin{bmatrix} \\Sigma_{AA} \u0026 \\Sigma_{AB} \\\\ \\Sigma_{BA} \u0026 \\Sigma_{BB} \\end{bmatrix} $$$$ \\Sigma^{-1} = V = \\begin{bmatrix} V_{11} \u0026 V_{12} \\\\ V_{21} \u0026 V_{22} \\end{bmatrix} = \\begin{bmatrix} I \u0026 V_{12}V_{22}^{-1} \\\\ 0 \u0026 I \\end{bmatrix} \\cdot \\begin{bmatrix} V_{11} - V_{12}V_{22}^{-1}V_{21} \u0026 0 \\\\ 0 \u0026 V_{22} \\end{bmatrix} \\cdot \\begin{bmatrix} I \u0026 0 \\\\ V_{22}^{-1}V_{21} \u0026 I \\end{bmatrix} $$ Then the inverse $(ABC)^{-1} = C^{-1}B^{-1}A^{-1}$ which is equal to: $$ V^{-1} =\n\\begin{bmatrix} I \u0026amp; 0 \\\nV_{22}^{-1}V_{21} \u0026amp; I \\end{bmatrix} \\cdot \\begin{bmatrix} (V_{11} - V_{12}V_{22}^{-1}V_{21})^{-1} \u0026amp; 0 \\ 0 \u0026amp; V_{22}^{-1} \\end{bmatrix} \\cdot\\begin{bmatrix} I \u0026amp; -V_{12}V_{22}^{-1} \\ 0 \u0026amp; I \\end{bmatrix} = \\begin{bmatrix} (V_{11} - V_{12}V_{22}^{-1}V_{21})^{-1} \u0026amp; -\\Sigma_{11}V_{12}V_{22}^{-1} \\ -\\Sigma_{11}V_{22}^{-1}V_{22} \u0026amp; V_{22}^{-1}(V_{12}V_{22}^{-1}V_{21}\\Sigma_{11} + 1) \\end{bmatrix} $$ One can note now with the inverse thing that $V_{22} = (\\Sigma_{22} - \\Sigma_{21}\\Sigma^{-1}_{11}\\Sigma_{12})^{-1}$ This allows to write $V_{12}$ nicely as $$ \\Sigma_{12} = -\\Sigma_{11}V_{12}V_{22}^{-1} \\implies V_{12} = -\\Sigma_{11}\\Sigma_{12}^{-1} V_{22}^{-1} =-\\Sigma_{11}\\Sigma_{12}^{-1} (\\Sigma_{22} - \\Sigma_{21}\\Sigma^{-1}{11}\\Sigma{12} $$ Because then it is easily invertible and one can observe that $\\Sigma_{11} = (V_{11} - V_{12}V_{22}^{-1}V_{21})^{-1}$, this is used for the marginalization calculation. One can find in this manner that $$ A \\sim \\mathcal{N}(\\mu_{A}, \\Sigma_{AA}) $$ And that $$ B \\mid A \\sim \\mathcal{N}(\\mu_{B} - V_{BB}^{-1}V_{AB} (A - \\mu_{A}), V_{BB}) $$ If you are a student ad ETH watch [this](https://video.ethz.ch/lectures/d-infk/2024/autumn/263-5210-00L/0d924ef2-af34-4cb1-96cb-ba9a63c1f15b.html) for the derivation, minute 46. Rewriting with the above properties for $V_{BB}$ and $V_{AB}$ we obtain: $$ B \\mid A \\sim \\mathcal{N}(\\mu_{B} + \\Sigma_{21}\\Sigma_{11}^{-1}(A - \\mu_{A}),\\Sigma_{22} - \\Sigma_{21}\\Sigma^{-1}{11}\\Sigma{12}) $$ Which is a ok form, but very very long to derive. Gaussian characteristic function üü®++ Characteristic functions are sometimes useful to prove that two distributions are the same as each other. One can prove that the characteristic function for Gaussians is\n$$ \\mathbb{E}[\\exp(itX)] = \\exp\\left( \\mu it - \\frac{1}{2} t^{T} \\Sigma t \\right) $$$$ \\mathbb{E}[\\exp(itX)] = \\int _{-\\infty}^{\\infty} \\frac{1}{\\sqrt{ 2\\pi } \\sigma} \\exp\\left( -\\frac{(x - \\mu)^{2}}{2\\sigma^{2}} + itx \\right) \\, dx $$$$ \\begin{align} \\\\ \\int _{-\\infty}^{\\infty} \\frac{1}{\\sqrt{ 2\\pi } \\sigma} \\exp\\left( -\\frac{(x - \\mu)^{2}}{2\\sigma^{2}} + itx \\right) \\, dx \\\\ = \\int _{-\\infty}^{\\infty} \\frac{1}{\\sqrt{ 2\\pi } \\sigma} \\exp\\left( -\\frac{(x - (\\mu + \\sigma^{2}it))^{2} - 2\\mu it\\sigma^{2} + \\sigma^{4}t^{2} }{2\\sigma^{2}} \\right) \\, dx \\\\ = \\exp\\left( \\mu it - \\frac{1}{2} \\sigma^{2}t^{2} \\right) \\cdot \\int _{-\\infty}^{\\infty} \\frac{1}{\\sqrt{ 2\\pi } \\sigma} \\exp\\left( -\\frac{(x - (\\mu + \\sigma^{2}it))^{2} }{2\\sigma^{2}} \\right) \\, dx \\\\ = \\exp\\left( \\mu it - \\frac{1}{2} \\sigma^{2}t^{2} \\right) \\end{align} $$Sum Gaussians are Gaussian üü© This is easily provable, if we have $X \\sim \\mathcal{N}(\\mu_{X}, \\Sigma_{X})$ and a compatible distribution $Y \\sim \\mathcal{N}(\\mu_{Y}, \\Sigma_{Y})$ then we have that the distribution $X +Y = \\mathcal{N} (\\mu_{X} + \\mu_{Y}, \\Sigma_{X} + \\Sigma_{Y})$ The proof should use characteristic functions in the line of linear Gaussians.\n$$ \\begin{align} \\mathbb{E}[\\exp(it (X + Y))] = \\\\ \u0026= \\mathbb{E}[\\exp(itX)]\\mathbb{E}[\\exp(itY)] \\\\ \u0026= \\exp\\left( \\mu_{X} it - \\frac{1}{2} t^{T} \\Sigma_{X} t \\right) \\exp\\left( \\mu_{Y} it - \\frac{1}{2} t^{T} \\Sigma_{Y} t \\right) \\\\ \u0026= \\exp\\left( (\\mu_{X} + \\mu_{Y}) it - \\frac{1}{2} t^{T} (\\Sigma_{X} + \\Sigma_{Y}) t \\right) \\end{align} $$ Which finishes the proof. One can also extend this result to every linear combination of Gaussians.\nProperties to remember üü© Compact representation of high dimensional joint distributions: instead of using $2^{n}$ variables we just need $n^{2}$, this is why Gaussian Processes are analytically handy. Closed form inference (I think about the Conjugacy of itself, this is because Gaussians are in the The Exponential Family.) Confidence Intervals Gaussians are a nice distribution. We have listed many of its properties by now. But one of the most over-utilized feature is the ease in computing $1 - \\alpha$ confidence intervals where $\\alpha$ is called significance level: meaning we want to find the interval where our prediction lies there with $1 - \\alpha$ probability. This is usually easy to compute with $z$ tables. The Standard Error of a Gaussian is $\\frac{\\sigma}{\\sqrt{ n }}$ and is related to the square root of the mean variance.\n$$ \\bar{x} \\pm z \\cdot SE $$ Where $\\bar{x}$ is the expected value for our prediction.\nInformation theoretic properties Entropy of a Gaussian distribution üü© We compute here the Entropy of a Univariate Gaussian distribution $\\mathcal{N}(x; \\mu, \\sigma^{2})$. So we need to compute the following value:\n$$ \\begin{align} \\int p(x) \\log \\frac{1}{p(x)} , dx \u0026amp;= -\\int \\frac{1}{\\sqrt{ 2\\pi \\sigma^{2} }} \\exp\\left( -\\frac{(x - \\mu)^{2}}{2\\sigma^{2}} \\right) \\cdot \\left( -\\frac{1}{2} \\log(2\\pi \\sigma^{2}) -\\frac{1}{2\\sigma^{2}}(x - \\mu)^{2} \\right) , dx \\ \u0026amp;= \\frac{1}{2}\\log(2\\pi \\sigma^{2}) +\\frac{1}{2\\sigma^{2}} \\mathbb{E}_{x} [(x - \\mu)^{2}] \\ \u0026amp;= \\frac{1}{2}\\log(2\\pi \\sigma^{2}) + \\frac{1}{2} \\ \u0026amp;= \\frac{1}{2} \\log(2\\pi \\sigma^{2}e) \\end{align}\n$$ With just the above proof one can prove that Gaussians are the distributions with maximum entropy for a given mean and variance. See Maximum Entropy Principle.\n$$ \\begin{align} \\mathbb{E}_{x \\sim p}[-\\log p(x)] \u0026 = \\mathbb{E}_{x \\sim p}\\left[ \\frac{d}{2} \\log(2\\pi ) + \\log \\det \\Sigma + \\frac{1}{2}(x - \\mu)^{T}\\Sigma^{-1}(x - \\mu) \\right] \\\\ \u0026 = \\frac{d}{2} \\log(2\\pi ) + \\log \\det \\Sigma + \\frac{1}{2} \\mathbb{E}_{x \\sim p}[(x - \\mu)^{T}\\Sigma^{-1}(x - \\mu)] \\\\ \u0026 =\\frac{d}{2}(1 + \\log(2\\pi)) + \\log \\det \\Sigma \\\\ \u0026= \\frac{d}{2} \\log(2\\pi e) + \\log \\det \\Sigma \\\\ \u0026= \\frac{1}{2} \\log((2\\pi e)^{d} \\lvert \\Sigma \\rvert ) \\end{align} $$ Where in the last step we used this equality: $$ \\begin{align} \\mathbb{E}{x \\sim p}[(x - \\mu)^{T}\\Sigma^{-1}(x - \\mu)] \u0026amp; = \\mathbb{E}{x \\sim p}[\\text{tr}((x - \\mu)^{T}\\Sigma^{-1}(x - \\mu))] \u0026amp; \\text{ trace of real number}\\\n\u0026amp; = \\mathbb{E}{x \\sim p}[\\text{tr} (\\Sigma^{-1}(x - \\mu)(x - \\mu)^{T})] \u0026amp; \\text{ eq. 16 Matrix Cookbook} \\ \u0026amp; = \\text{tr}(\\mathbb{E}{x \\sim p}[\\Sigma^{-1}(x - \\mu)^{T}(x - \\mu)]) \u0026amp; \\text{ linearity of trace} \\ \u0026amp; = \\text{tr}(\\Sigma^{-1} \\mathbb{E}_{x \\sim p}[(x - \\mu)(x - \\mu)^{T}]) \u0026amp; \\text{ linearity of expectation} \\ \u0026amp; = \\text{tr}(\\Sigma^{-1} \\Sigma) \u0026amp; \\text{ definition of covariance} \\ \u0026amp; = d \u0026amp; \\text{ trace of identity matrix} \\ \\end{align} $$ The Matrix Cookbook refers to this resource.\nMutual information of Gaussians Suppose we have a Gaussian $X \\sim \\mathcal{N}(\\mu, \\Sigma)$ and $Y = X + \\varepsilon, \\varepsilon\\sim \\mathcal{N}(0, \\sigma^{2}_{n}I)$ TODO\n$$ I(X, Y) = \\frac{1}{2} \\log\\lvert I + \\sigma^{-2}_{n}\\Sigma \\rvert $$General KL divergence between Gaussians $$ KL(p \\mid \\mid q) = \\frac{1}{2} \\left( \\log \\frac{\\lvert \\Sigma_{q} \\rvert}{\\lvert \\Sigma_{p} \\rvert} - d + tr(\\Sigma_{q}^{-1}\\Sigma_{p}) + (\\mu_{q} - \\mu_{p})^{T}\\Sigma_{q}^{-1}(\\mu_{q} - \\mu_{p}) \\right) $$This is a good resource for a proof.\nForward KL One can prove that the forward KL divergence between two Gaussians defined as $p \\sim \\mathcal{N}(\\mu_{1}, diag\\left\\{ \\sigma^{2}_{1}, \\dots, \\sigma^{2}_{d} \\right\\})$ and $q = \\mathcal{N}(0, 1)$ is given by:\n$$ KL(p \\mid \\mid q) = \\frac{1}{2} \\sum_{i = 1}^{d} \\left( \\sigma_{i}^{2} + \\mu_{i}^{2} - \\log \\sigma_{i}^{2} - 1 \\right) $$ Let‚Äôs interpret this. The $\\mu$ term works to pull the mean toward zero. The $\\sigma$ term introduces a penalty for high variance values, while the $\\log \\sigma^2$ term imposes a cost for low values of $\\sigma$. This forward KL is what is used for Autoencoders.\nReverse KL $$ KL(q \\mid \\mid p) = \\frac{1}{2} \\sum_{i = 1}^{d} \\left( \\frac{\\mu_{i}^{2}}{\\sigma_{i}^{2}} + \\sigma_{i}^{-2} + \\log \\sigma_{i}^{2} - 1 \\right) $$References [1] Bishop ‚ÄúPattern Recognition and Machine Learning‚Äù Springer 2006\n","permalink":"https://flecart.github.io/notes/gaussians/","summary":"\u003cp\u003eGaussians are one of the most important family of probability distributions.\nThey arise naturally in the \u003ca href=\"/notes/central-limit-theorem-and-law-of-large-numbers/\"\u003elaw of large numbers\u003c/a\u003e and have some nice properties that we will briefly present and prove here in this note. They are also quite common for \u003ca href=\"/notes/gaussian-processes/\"\u003eGaussian Processes\u003c/a\u003e and the \u003ca href=\"/notes/clustering/\"\u003eClustering\u003c/a\u003e algorithm. They have also something to say about \u003ca href=\"/notes/maximum-entropy-principle/\"\u003eMaximum Entropy Principle\u003c/a\u003e.\nThe best thing if you want to learn this part actually well is section 2.3 of (Bishop 2006), so go there my friend :)\u003c/p\u003e","title":"Gaussians"},{"content":"This small note sections tries to fix 5 important concepts in software engineering\nSub-system and modules üü© We need to differentiate from sub-system, which is a part of a system that tries to achieve some objective, and a module, which is more language specific way of saying imported file, or set of functions or classes.\nInformation hiding üü© This is a very important principle present in object oriented programming. Within this philosophy we should be able to access only public methods or data, this allows the construction of abstractions that allow us to think at a higher level.\nA good think about this is that changing implementation doesn\u0026rsquo;t change the interface, this allows lower level of coupling within the system.\nCoupling Meaning of coupling üü© Two methods are said to be highly coupled when every change to one of them, needs the other one to be changed too! Clearly if we have a highly coupled system refactoring is a hell of a nightmare. Low coupling provides independency, creating a easier to maintain software.\nCoupling sources (7) üü© There are many coupling sources, here is a not definitive list:\nFunction or method calling Data coupling, for example the prop drilling hell present in react, where you have to pass other data to other data on an indefinite chain. Hereditary coupling, where you have too long chain of sub-classes. OS-coupling, where you don\u0026rsquo;t have an equivalent function for other OSes Common coupling:, e.g. global variables, config files, that are used by many files. Content coupling: happens when the #Information hiding is not implemented, an other module directly sees internal data-structure of another module, implying a very bad implementation!. Cohesion üü© Cohesion is a concept that similarly to Memoria#4.2 Memoria Cache, with the location principle, common functions should be grouped together, the best thing that could happen is the functional cohesion, where code that tries to implement the same abstraction tries to be together, another one is content cohesion, where code that needs same input structure is close.\nA bad example is random ordering, where code with no shared meaning stays together.\nSimplicity üü© This is also one of the main pillars of Software engineering. In this case it is advised not to generalize too early, probably You aren\u0026rsquo;t gonna need it.\nWhen we are talking about methods instead, you should follow the principles explained in clean code, so keep the names descriptive, keep the public methods small and precise, use small functions, and keep code smell low (avoid duplicates for example).\n","permalink":"https://flecart.github.io/notes/general-swe-principles/","summary":"\u003cp\u003eThis small note sections tries to fix 5 important concepts in software engineering\u003c/p\u003e\n\u003ch3 id=\"sub-system-and-modules-\"\u003eSub-system and modules üü©\u003c/h3\u003e\n\u003cp\u003eWe need to differentiate from sub-system, which is a part of a system that tries to achieve some objective, and a \u003cstrong\u003emodule\u003c/strong\u003e, which is more \u003cem\u003elanguage specific\u003c/em\u003e way of saying imported file, or set of functions or classes.\u003c/p\u003e\n\u003ch3 id=\"information-hiding-\"\u003eInformation hiding üü©\u003c/h3\u003e\n\u003cp\u003eThis is a very important principle present in \u003ca href=\"/notes/classi-oop-\"\u003eobject oriented programming\u003c/a\u003e.\nWithin this philosophy we should \u003cstrong\u003ebe able to access only public\u003c/strong\u003e methods or data, this allows the construction of \u003cem\u003eabstractions\u003c/em\u003e that allow us to think at a higher level.\u003c/p\u003e","title":"General SWE principles"},{"content":"Spire Spira quadrata Questo √® descritto nell\u0026rsquo;esempio 8.1 del Mazzoldi. √à stato descritto anche in un esercizio in classe (non √® importante).\nSpira circolare üü© Vedere pagina 245 Vogliamo cercare il valore del campo sull\u0026rsquo;asse della spira circolare. Questo √® semplice, basta usare la prima di Laplace e trovare l\u0026rsquo;apporto del campo magnetico al centro. Si pu√≤ anche pensare come momento magnetico, allora si utilizza sempre lo stesso discorso per la spira quadrata classica e il suo momento.\n$$ d\\vec{B} = \\frac{\\mu_{0}i}{4\\pi} d\\vec{l}\\times \\frac{\\hat{r}}{r^{2}} $$ Con le variabili dichiarate come in figura, possiamo scrivere $dl = Rd\\theta$ e che $r^{2} = R^{2} + x^{2}$ E sappiamo che il verso del campo sull\u0026rsquo;asse √® sempre concorde sullo stesso verso (quindi i contributi si sommano, dobbiamo considerare per ragioni di simmetria solamente quella lungo l\u0026rsquo;asse.)\nAllora abbiamo\n$$ d\\vec{B} = \\frac{\\mu_{0}i}{4\\pi} \\frac{R}{R^{2} + x^{2}} d\\theta $$$$ d\\vec{B}_{a} = \\frac{\\mu_{0}i}{4\\pi} \\frac{R^{2}}{(R^{2} + x^{2})^{3/2}} d\\theta $$E integrando su tutta la superficie della spira otteniamo\n$$ \\vec{B}_{a}(x) = \\frac{\\mu_{0}i}{4\\pi} \\frac{R^{2}}{(R^{2} + x^{2})^{3/2}} 2\\pi = \\frac{\\mu_{0}i}{2} \\frac{R^{2}}{(R^{2} + x^{2})^{3/2}} $$Da cui possiamo ricavare il caso specifico in cui $x = 0$, abbiamo il campo al centro della spira\n$$ \\vec{B}_{a}(0) = \\frac{\\mu_{0}i}{2R} $$Questo risultato ci sar√† utile per l\u0026rsquo;analisi del solenoide in seguito.\nMomento magnetico della spira Prova a ricorda quanto fatto per la spira quadrata in Spettrometri di massa. ossia ancora da capire bene (la cosa con l\u0026rsquo;inerzia, e il momento di dipolo, una cosa che dipende solamente dalla struttura) descritta da $i \\cdot S$ ossia dalla corrente e dalla superficie, da cui poi ha senso descrivere un concetto di flusso.\nComponenti del campo magnetico üü•+ $$ B = \\frac{\\mu_{0}}{4\\pi} \\frac{m}{r^{3}}(2\\cos \\theta \\hat{r} + \\sin \\theta \\hat{\\theta}) $$ Con componente radiale e trasversa. Pg 254 Mazzoldi\nSolenoide Descrizione del solenoide üü© Vogliamo cercare di definire quale sia il campo magnetico presente sull'asse $$ \\begin{cases} r \\sin \\phi = R \\\\ x - x_{0} = R \\frac{\\cos\\phi}{\\sin \\phi} \\implies dx = \\frac{Rd\\phi}{\\sin ^{2}\\phi} \\end{cases} $$$$ dB = \\frac{\\mu_{0}ni}{2} \\sin \\phi d\\phi $$ E integrando questo valore fra $\\phi_{1}$ e $\\phi_{2}$ ci viene una cosa clean, avremo che:\n$$ B =\\frac{\\mu_{0}ni}{2}(\\cos \\phi_{2} - \\cos \\phi_{1}) $$ Mettendo l\u0026rsquo;origine all\u0026rsquo;inizio della spira, e supponendo che la lunghezza della spira sia $d$ otteniamo questo per i valori di sopra e gli angoli di sopra, ma comunque spiega meglio il libro su questo. Campo esterno del solenoide üü®+ Se assumiamo che i raggi siano simili, allora prendiamo due contributi e abbiamo che $B = \\frac{\\mu_{0}i}{4\\pi} (dl_{1} r_{1} \\sin \\theta + dl_{2}r_{2}\\sin(\\pi - \\theta))$ E si elidono, e questo dovrebbe funzionare anche per cose un po\u0026rsquo; a lato!\nAl centro del solenoide üü© $$ B_{0} = \\mu_{0}ni \\frac{d}{\\sqrt{ d^{2} + 4R^{2} }} $$$$ B_{\\infty} = \\mu_{0}ni $$ E si pu√≤ dimostrare che all\u0026rsquo;interno il campo √® sempre quello, lo stesso, costante. Analisi tramite circuitazione del solenoide üü© $$ \\oint Bds = Bh = \\mu_{0}nih = \u003e B = \\mu_{0}ni $$ Potrebbe essere interessante rifare l\u0026rsquo;analisi seguendo la 256, in cui si divide la corrente in circolare e lineare(falla e scrivi qui i risultati come esercizio al prossimo ripasso)\nToroide #### Campo esterno üü© Possiamo usare ampere e dire che corrente concatenata √® nulla e concludere che il campo magnetico √® nullo. #### Campo magnetico del toroide üü© Possiamo fare la sequente analisi: $$ \\oint Bds = \\mu_{0} Ni \\implies B 2\\pi r = \\mu_{0} Ni \\implies B = \\mu_{0} \\frac{Ni}{2\\pi r} $$ Quindi solo se $r$ √® piccolo si pu√≤ assumere che sia uniforme, altrimenti il valore cambia con quel valore. $$ H = \\frac{Ni}{2\\pi r} $$ Vedere descrizione in Magnetismo nella materia\nToroide pieno üü©- $$ H = \\frac{Ni}{2\\pi r} $$ Riprendendo il ragionamento di sopra. Poi avendo questo posso sia calcolare B che M.\nTanti fili carichi #### Simmetria su asse y üü© Dalla figura 8.35 si pu√≤ dire che non abbiamo una componente $y$ , perch√© si eliminano. Quindi non abbiamo circuitazione sui pezzi AD e BC, per√≤ abbiamo cose sullo stesso verso ma cose oppose sugli altri versi!\nDiscontinuit√† parallela üü©- Stiamo sempre considerando una linea carica di correnti come da esempio sopra.\n$$ \\oint B ds = \\mu_{0}nhi \\implies 2hB = \\mu_{0}nhi \\implies B = \\frac{\\mu_{0}ni}{2} $$ Abbiamo sempre questo valore per il campo magnetico, ma i versi sono diversi. Questo giustifica anche una discontinuit√† della componente parallela, per il campo magnetico, di valore $\\mu_{0}ni$. Conviene talvolta scrivere $ni\\hat{u} = \\vec{J}$ e con $\\hat{u}$ la direzione della corrente, cos√¨ posso sapere subito quale sia la direzione diciamo.\nContinuit√† perpendicolare üü© $$ \\oint \\vec{B} \\hat{u}_{n} = \\oint \\vec{B}_{1} ds - \\oint \\vec{B}_{2}ds = B_{1\\perp}A_{1} - B_{2\\perp}A_{1} = 0 \\implies B_{1} = B_{2} $$Flusso concatenato campi magnetici üü© Setting delle spire Poniamo di avere due spire. Vorrei sapere il flusso del campo magnetico indotto dentro la seconda superficie.\n$$ \\Phi (\\vec{B}) = \\int_{\\Sigma(\\Gamma_{2})} \\vec{B} \\cdot d\\vec{s} $$ Misurato in Weber, ossia Tesla per metro quadro.\n$$ d\\vec{B} = \\frac{\\mu_{0}i}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}} $$ Integriamo tutti i contributi:\n$$ \\vec{B}_{1} = \\oint_{\\Gamma_{1}} d\\vec{B}_{1} = \\oint_{\\Gamma_{1}} \\frac{\\mu_{0}i}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}} $$ Quindi per avere il flusso \u0026ldquo;basta\u0026rdquo; fare l\u0026rsquo;integrale di nuovo poi sulla superficie aperta concatenata a quella spira.\nCoefficiente di mutua induzione üü© $$ \\Phi_{2} (\\vec{B}_{1}) = \\int _{\\Sigma(\\Gamma_{2})} \\vec{B}_{1} \\, \\vec{dS_{2}} = \\int _{\\Sigma(\\Gamma_{2})} [\\oint_{\\Gamma_{1}} \\frac{\\mu_{0}i}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}}] \\, \\vec{dS_{2}} $$$$ \\Phi_{2} (\\vec{B}_{1}) = i_{1} \\int _{\\Sigma(\\Gamma_{2})} [\\oint_{\\Gamma_{1}} \\frac{\\mu_{0}}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}}] \\, \\vec{dS_{2}} = i_{1} M_{12} $$ Dove tutto quanto della seconda parte √® un fattore geometrico dipendente da\nCome sono disposti la prima e seconda superficie lineare I materiali con cui son fatti. Si pu√≤ dimostrare che $M_{12} = M_{21} = M$. La dimostrazione dovrebbe venire semplice con Vettore potenziale\nDimostrazione che sono uguali:\nInduttanza Introduzione valore fisico üü© $$ \\Phi(\\vec{B}) = i_{1} \\int _{\\Sigma(\\Gamma_{1})} [\\oint_{\\Gamma_{1}} \\frac{\\mu_{0}}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}}] = i_{1}L $$ Con $L$ l\u0026rsquo;induttanza della sfera, il cui verso della superficie lo intendo orientato secondo la regola della mano destra\nSia questo sia il coefficiente di mutua induzione √® misurato in $\\frac{W}{A}$. Questo si misura in Henry\nSolitamente l\u0026rsquo;induttanza di un circuito di casa √® $\\approx 10^{-7} H$.\nInduttanza su solenoide üü© $$ \\Phi(\\vec{B}) = Li $$$$ \\Phi_{1}(\\vec{B}_{0}) = B_{0}S = \\mu_{0}niS \\implies \\Phi(\\vec{B}_{0}) = NB_{0}S = N\\mu_{0}niS \\implies L = N\\mu_{0}nS = n^{2}\\mu_{0}(Sl) = \\mu_{0}n^{2}V $$$$ \\mu_{0}n^{2} $$Circuito con induttanza üü© Pu√≤ essere opportuno confrontare questo circuito con quello trovato in [Condensatori nel vuoto](/notes/condensatori-nel-vuoto) per la carica/scarica. $$ \\varepsilon_{IND} = -\\frac{d\\Phi(\\vec{B})}{dt} = -\\frac{d(Li)}{dt} $$ Da questo possiamo usare le Leggi di Ohm, in particolare la prima:\n$$ \\varepsilon + \\varepsilon_{IND} = Ri \\implies \\varepsilon = Ri + \\frac{Ldi}{dt} $$$$ \\frac{\\varepsilon}{R} = i + \\frac{L}{R} \\frac{di}{dt} \\implies -\\frac{L}{R} \\frac{di}{dt} = i- \\frac{\\varepsilon}{R} \\implies \\frac{di}{i - \\frac{\\varepsilon}{R}} = -\\frac{R}{L}dt $$$$ \\int_{0} ^{i(t)} \\frac{di}{i - \\frac{\\varepsilon}{R}} = -\\frac{R}{L} \\int_{0}^{t} \\, dt \\implies \\ln\\left( \\frac{\\left( i(t) - \\frac{\\varepsilon}{R} \\right)}{-\\frac{\\varepsilon}{R}} \\right) = -\\frac{R}{L} t $$$$ \\frac{\\left( i(t) - \\frac{\\varepsilon}{R} \\right)}{-\\frac{\\varepsilon}{R}} = e^{-\\frac{R}{L} t} \\implies i(t) = \\frac{\\varepsilon}{R} (1 - e^{-\\frac{R}{L} t}) $$ Una corrente con andamento asintotico, con limite $\\frac{\\varepsilon}{R}$ Con un tempo caratteristico stavolta di $\\frac{L}{R}$ Un buon esercizio √® verificare le dimensioni di questo.\n$$ \\varepsilon_{IND} = -\\varepsilon e ^{- Rt/L} $$ Che va a 0, asintoticamente abbiamo il caso classico\nEnergia dell\u0026rsquo;induttanza üü®++ $$ \\varepsilon = Ri + \\frac{Ldi}{dt} \\implies \\varepsilon idt = Ri^{2}dt + Lidi $$$$ dU_{l} = Lidi \\implies U_{l} = \\frac{1}{2}Li^{2} $$ Che confrontasi, molto simile a quanto trovato per il condensatore, in cui abbiamo $\\frac{1}{2}CV^{2}$l\nL\u0026rsquo;energia √® spesa per la costruzione del campo magnetico dal nulla, mentre per il condensatore √® stato usato per avere il campo elettrico.\nDensit√† energetica dell\u0026rsquo;induttanza üü©\u0026ndash; $$ B = \\mu_{0}ni, L = \\mu_{0} n^{2}(ls) \\implies i = \\frac{B}{\\mu_{0}n} $$$$ U_{L} = \\frac{1}{2}Li^{2} = \\frac{1}{2}(\\mu_{0}n^{2} lS) \\frac{B^{2}}{\\mu_{0}^{2}n^{2}} \\implies U_{L} = \\frac{1}{2} \\frac{B^{2}}{\\mu_{0}} (lS) $$$$ u_{l} = \\frac{1}{2} \\frac{B^{2}}{\\mu_{0}} $$$$ u_{l} = \\frac{1}{2} \\mu_{0} H^{2} = \\frac{1}{2 }HB $$","permalink":"https://flecart.github.io/notes/geometrie-di-spire/","summary":"\u003ch3 id=\"spire\"\u003eSpire\u003c/h3\u003e\n\u003ch4 id=\"spira-quadrata\"\u003eSpira quadrata\u003c/h4\u003e\n\u003cp\u003eQuesto √® descritto nell\u0026rsquo;esempio 8.1 del Mazzoldi.\n√à stato descritto anche in un esercizio in classe (non √® importante).\u003c/p\u003e\n\u003ch4 id=\"spira-circolare-\"\u003eSpira circolare üü©\u003c/h4\u003e\n\u003cp\u003eVedere pagina 245\nVogliamo cercare il valore del campo sull\u0026rsquo;asse della spira circolare.\n\u003cimg src=\"/images/notes/Geometrie di spire-1704296692075.jpeg\" width=\"500\" alt=\"Geometrie di spire-1704296692075\"\u003e\nQuesto √® semplice, basta usare la prima di Laplace e trovare l\u0026rsquo;apporto del campo magnetico al centro.\nSi pu√≤ anche pensare come momento magnetico, allora si utilizza sempre lo stesso discorso per la spira quadrata classica e il suo momento.\u003c/p\u003e","title":"Geometrie di spire"},{"content":"Memoria statica Elementi in memoria statica (4) üü©- Variabili globali Istruzioni macchina Costanti (Variabili locali, paramentri e ritorno di funzione?) Le primi tre elementi descritti di sopra sono sicuramente presenti dopo la fase di compilazione, infatti sono allocati dal compilatore in una zona presente nell‚Äôeseguibile (un esempio √® il READONLY per le stringhe in C).\nQuindi se vogliamo\nAvere funzioni ricorsive Potere allocare e deallocare variabili in modo dinamico Abbiamo bisogno di far uso di Pila o Heap, che riescano a cresere e restringersi in modo dinamico.\nImplementazione di funzioni statiche üü© Si potrebbe anche utilizzare la memoria statica per implementare le funzioni, ma questo ha il fortissimo drawback che non permette la ricorsione in quanto stiamo assumento che in ogni momento di esecuzione la funzione √® chiamata una singola volta. (ho un unico indirizzo di memoria per l\u0026rsquo;indirizzo di ritorno.\nInfatti se chiamassimo in modo ricorsivo questa funzione, perderemmo alcuni valori, come l\u0026rsquo;indirizzo di ritorno, il valore di ritorno precedente, e porterebbe in uno stato invalido.\nOltre a questo avremmo un elevato uso della memoria nel caso in cui il numero di chiamate di funzioni sia in media minore del numero di dichiarazioni di funzione (avremmo un sacco di funzioni inutilizzate).\nSlide di quanto memorizzato per la funzione statica\nFigura 7.1 Gestione della memoria statica. per le funzioni\nSull\u0026rsquo;efficienza\nSolitamente se utilizziamo questo metodo il compilatore solitamente √® in grado di accedere a delle variabili utilizzando un OFFSET senza dover stare a fare risoluzione di nomi simbolici (una volta che abbiamo un frame o RdA, possiamo calcolare la posizione della variabile locale, o parametro attraverso l‚Äôoffset sul base pointer, che qui √® anche chiamato puntatore di RdA). Qualcosina in pi√π forse c\u0026rsquo;√® da fare sulle variabili non locali\nUn altra ottimizzazione √® memorizzare i risultati intermedi su REGISTRI invece che utilizzare la stack. In generale ci sono moltissimi modi di ottimizzare, quindi non andiamo a parlare di questo.\nGestione della pila La pila √® la struttura pi√π comoda per la gestione dei blocchi di codice, che come abbiamo descritto in Nomi e Scope, devono essere LIFO, ossia il blocco pi√π annidato deve finire prima di uscire. Questo √® il motivo per cui possiamo giustificare la gestione della pila. Ecco che si giustifica l\u0026rsquo;idea di creazione della pila di sistema.* Che √® in grado di stabilire le posizioni delle variabili locale, dei parametri attraverso un Offset rispetto al base pointer del frame.\nRecord di attivazione di blocchi (3) üü© Ne abbiamo accennato in 8.4.1 Activation record, parlando anche l√¨ dei record di attivazione, in questo momento andremo a parlarne in modo pi√π approfondito.\nOra parliamo brevemente di record attivazione di blocchi, per questi quando entriamo in un nuovo blocco vogliamo creare spazio per queste cose:\nVariabili intermedie (per storare calcolo intermedio) Variabili locali nuove Catena dinamica che mi dice in quale blocco sono, ed √® utilizzato per eliminare tutto il nuovo spazio allocato in questo blocco. Esempio:\nFigura 7 .3 Allocazione del record di attivazione per I blocchi A e B nell\u0026rsquo;Esempio 7.2.\nRecord di attivazione per funzioni (7) üü© Questi record di attivazione, anche chiamate RdA in modo abbreviato hanno lo stesso concetto per i record di attivazione per i blocchi, ma devono avere qualche informazione in pi√π per indirizzo di ritorno e modo di ritornare la variabile di output.\nTutti i 3 punti per i RdA dei blocchi Catena statica per gli scope (che attualmente non so in che modo venga utilizzata) Indirizzo di ritorno, per il program counter Indirizzo per il Valore di ritorno I parametri di chiamata della funzione. Figura 7.7 Struttura del record di attivazione per una procedura.\nGestione della pila a runtime (!!!) üü®++ In questa parte andiamo a parlare di alcune istruzioni che sono utili per implementare questo sistema di RdA in un linguaggio classico.\nAndiamo a parlare di sequenza di chiamata per l\u0026rsquo;insieme di procedure che deve eseguire il chiamante prima di entrare nel blocco della funzioen chiamata, e una sequenza di ritorno per uscire dal blocco, poi di prologo e epilogo per l‚Äôuscita. ora nel pezzo sequente andiamo a descrivere alcune istruzioni da eseguire per entrare ed uscire da un blocco di RdA di una funzione.\nQuesta divisione √® necessaria perch√© alcune cose possono essere fatte solo dal chiamante, e altre solo dal chiamato!\nChiamata di funzione\nQuesta parte interessa la parte di sequenza di chiamata e il prologo della funzione.\nAllocazione dello spazio necessario nella stack (per parametri, variabili locali, e risultati intermedi, e catene statiche e dinamiche). Passare i parametri (di solito copiati nella nuova RdA) Aggiornare il puntatore di RdA al nuovo, in C di solito √® il base pointer, anche chiamato frame pointer. Salvare quanto necessario dai registri (e.g. il chiamante deve settare l‚Äôindirizzo di ritorno della funzione). Salvare il PC precedente, e settare il nuovo PC. Eseguire codice di inizializzazione specifico del linguaggio, se c\u0026rsquo;√® (anche in C mi pare ci fossero alcune istruzioni, di solito erano nel prologo, come dei push rbp). Ritorno del controllo al programma chiamante\nRipristinare i valori dei registri precedenti. Risettare il PC precedente Copiare il valore di ritorno nell\u0026rsquo;indirizzo giusto ripristinare il puntatore di RdA Deallocare la parte della stack che non utilizziamo pi√π. Esecuzione di codice di uscita. Gestione della heap Per la heap non √® possibile utilizzare stack perch√© in questo caso l\u0026rsquo;utilizzo non soddisfa la propriet√† LIFO tipida della stack, posso freeare una cosa anche prima di una cosa allocata dopo diciamo. Bisogna quindi creare un metodo di gestione dinamica della memoria differente.\nQuesto √® solamente una zona contigua di memoria diversa dalla stack, in cui possiamo allocare e deallocare dinamicamente cose, non c‚Äôentra niente con la struttura di dati!\nDimensione fissa üü© Questa √® l\u0026rsquo;implementazione della heap pi√π semplice, in pratica divido tutto il mio array disponibile in blocchi liberi disponibili.\nQuando vado ad allocare un blocco, vado a togliere questo blocco e metterlo a disposizione al chiamante, a chi ha allocato il blocco, e tolgo questo blocco dai liberi, ora la lista dei liberi punter√† al prossimo blocco libero.\nQuando vado a deallocare il blocco non faccio altro che marcare come libero il blocco, reinserendolo nella lista dei liberi.\nDimensione variabile üü©- Questa √® una soluzione molto pi√π bella per quanto riguarda la soluzione della frammentazione interna, ossia quanta parte di memoria ho ancora inutilizzato, se ho richiesto un blocco (e.g. prima se avevo blocchi da 256, anche se volevo un singolo byte, mi dava un blocco da 256 e gran parte della memoria sarebbe stata sprecata per allocazione dinamica.)\nOra vorrei dividere tutta la memoria che ho secondo una certa logica, solitamente si pu√≤ dividere in due modi di gestire questa cosa:\nHeap dimensione variabile a liste multiple\nQuesta √® una gestione della lista in cui ho pi√π liste di una certa grandezza, i sistemi principali sono a buddy system o fibonacci heap. Discuteremo solamente il primo sistema, il secondo sistema √® molto simile, con una leggera efficienza in pi√π perch√© utilizzando i numeri di fibonacci si ha minore frammentazione interna**.**\nAllora se richiedo un blocco di grandezza n, vado a cercare il blocco libero nella lista di k, con grandezza pi√π grande di n (in buddy system le liste sono tutte di grandezze di potenze di due).\nSe trovo una lista allora alloco e restituisco. Se invece non c\u0026rsquo;√®, allora vado a cercare nelle liste pi√π grosse se c\u0026rsquo;√®. Se lo trovo, allora lo spezzo a met√†, creando i buddies, uno lo aggiungo alla lista dei liberi della lista precedente, l\u0026rsquo;altra la restituisco come blocco allocato.\nin fase di deallocazione vado a controllare se ho dei buddies spezzati, se esistono e sono liberi allora li ricompongo e li metto nella lista grossa originale, altrimenti rimane nella lista libera pi√π piccola!\nHeap a singola lista üü© Anche in questo caso possiamo avere dei problemi di frammentazione quando allochiamo e deallochiamo gli elementi della lista libera che possediamo, ne abbiamo parlato sempre in architettura quando abbiamo accennato alla paginazione: 9.3.2 In memoria: frammentazione esterna. Infatti anche qui possiamo andare a parlare di politiche di first and best FIT. Questi sono entrambi metodi di inserimento lineare, il primo favorisce il tempo, il secondo l‚Äôefficienza in memoria.\nCon questo sistema ho un blocco di spazio UNICO disponibile. Quindi se chiedo n, posso effettivamente allocarti un blocco grosso n, senza nessuna frammentazione. Questo posso continuare finch√© non finisco la memoria. Quando la finisco potrei gestirla in due modi praticamente.\nLista dei liberi\nIn questo caso quando faccio free faccio append di tutti i blocchi deallocati alla lista dei liberi. Posso inserire controlli che quando ho due blocchi contigui nei liberi li compatto assieme. Questo √® la compattazione parziale.\nPoi quando finisco la memoria utilizzo direttamente la lista dei liberi per allocare nuovi blocchi, questo pu√≤ portare al problema di frammentazione interna o esterna. Ci metto in tempo lineare ad allocare. (oppure posso tenere i blocchi ordinati, se utilizzo alberi ordinati allora log(n) per tirare via ed inserire.) Ma in generale ci sono molti modi per gestire questa struttura di dati.\nCompattazione della memoria libera\nQuando finisco la memoria, risolvo la frammentazione esterna rimettendo assieme tutti i blocchi allocati, e poi posso continuare l\u0026rsquo;algoritmo di sopra, allocando esattamente quando mi richiede.\nIl problema di questo metodo √® che difficilmente posso spostare le cose, che √® una precondizione per poter utilizzare questo metodo.\nImplementazione delle regole di scope Abbiamo parlato per la prima volta di scope in Nomi e Scope.\nScope statico üü© Per implementare lo scope statico vogliamo utilizzare la catena statica presente all\u0026rsquo;interno del record di attivazione per poter risalire al blocco giusto.\nIn particolare dividiamo in due casi, il caso in cui il nome chiamato sia presente nell\u0026rsquo;ambiente locale del chiamante, e il caso in cui non lo sia. Questo √® importante perch√© nella fase di sequenza di chiamata dovrebbe essere il lavoro del chiamante per impostare il puntatore di catena statica del chiamato. Notare che in questa sezione utilizziamo nomi come chiamante chiamato, ma il chiamato potrebbe anche essere riferimento al nome di una variabile, il concetto di risalita √® comune.\nCaso presente nell‚Äôambiente locale\nQuesto √® il caso semplice, so che la catena statica deve puntare al chiamante, quindi basta inserirla nel record di attivazione del chiamato!\nCaso non presente\nQuesto √® una cosa leggermente pi√π complessa, se io so che il chiamato √® a livello di annidamento statico n (per tenersi queste informazioni probabilmente si utilizzano informazioni di annidamento e di ambienti locale, che sono comunque presenti nella struttura (statica), e quindi le posso calcolare al momento di compilazione)), e il chiamante a livello di m, devo percorrere k = m - n, livelli per trovare il puntatore di catena statica del chiamato e settarlo puntatore di catena statica del nuovo RdA che mi ritrovo dopo aver risalito di k sulla catena statica.\nQuesto lo so perch√© dato che il chiamato √® esterno, so che √® presente nell‚Äôambiente non locale, quindi non pu√≤ che essere a livello di annidamento inferiore, quindi risalire la catena statica √® corretto.\nChiaramente √® una cosa molto inefficiente fare k dereferenziazioni di pointer per arrivare fino al punto che mi interessa, vedremo subito dopo un metodo per velocizzare questo sistema di scope statico.\nEsempio funzionamento\n!\nFigura 7.14 Catena statica per la struttura precedente e la sequenza di chiamate A, B, C, D, E, C.\nstatico: Il display üü© Vogliamo trovare un metodo pi√π veloce per settare il RdA nel campo della catena statica, tanto che possiamo ridurre a k dereferenziazioni a solamente un numero costante piccolo (2, ma poi il problema precedente non √® brutto dato che il numero di annidamenti per linguaggi reali sta molto piccolo in generale, di solito 3).\nAllora un modo per fare questo √® tenersi un altro array, che contenga un puntatore a seconda del livello di annidamento!\nIdea: tenersi una struttura ausiliaria che viene aggiornato ad ogni cambio di ambiente che contenga il puntatore alla struttura statica di riferimento a ogni livello. (chiaramente il livello massimo si annidamento, va a determinare la lunghezza del display).\nDue accessi, uno nel display per trovare il RdA corretto, l\u0026rsquo;altro accesso per trovare l‚Äôindex della variabile locale corretta.\nFunzionamento generale\nSia m il livello di annidamento del chiamato, allora salvo il valore che c\u0026rsquo;era prima, perch√© il display sar√† comune a tutti i livelli diversi da m.\nQuando ritorno ripristino il vecchio valore, in questo senso il display contiene tutte le RdA statiche a seconda del livello di annidamento, e posso utilizzare questo per capire il puntatore di catena statica.\nEsempio display\n!\nFigura 7.15 Display per la struttura di Figura 7.13 e la sequenza di chiamate A,' B, C, D, E, C.\nScope dinamico: La ricerca per nome üü© Questa √® la soluzione pi√π lenta che potrebbe esistere, che √® quella della ricerca per nome negli RdA, in pratica risalgo i record fin quando non lo trovo o lo trovo.\nUn problema diventa andare ad attivare o disattivare le variabili a seconda del fatto di averlo gi√† visto o meno, e dello scope.\nSlide descrive questo metodo\nScope dinamico lista associazioni üü© Una cosa banale √® tenersi una lista di associazioni globale, chiamata A-list (che viene usato in lisp) che si tiene conto di tutte le associazioni attive. Un entrare e uscire da un certo ambiente non si tratta altro che andare a manipolare questa lista globale di associazioni.\nCercare un valore dell‚Äôassociazione a runtime non sarebbe altro che andare a scorrersi la lista fino a trovare il simbolo di mio interesse, alla prima occorrenza, perch√© quella √® la pi√π recente.\nEntro in nuovo ambiente non faccio altro che aggiungere nella A-list i valori locali\nEsco dall‚Äôambiente non faccio altro che poppare i valori locali\nRicerca simboli non faccio che scorrere tutta la A-list per trovare il valore corretto.\nChiaramente questo runtime non √® che sia molto invitante (nella pratica per√≤ √® sufficiente, anche se non avrei comunque una efficienza di C), quindi vorremmo trovare anche metodi migliori per implementare lo scope dinamico.\nUn altro metodo comparabile per inefficienza √® scorrersi le RdA finch√© non troviamo il simbolo di nostro interesse..\nSvantaggi\nDevo memorizzare i nomi in momento di esecuzione, per poter ritrovare l\u0026rsquo;istanza. Lentezza ad accedere valori globali, che sono in cima alla lista. Entrambi questi svantaggi sono risolti con la CRT esposta nella squenza successiva.\nCentral Referencing environment Table üü© Durante l\u0026rsquo;esecuzione e durante le entrate in ogni ambiente locale, posso tenermi un array di tutti i simboli che posso avere (oppure una hastable). Questo mi permette di accedere al simbolo in tempo costante, e se a tempo di compilazione conosco tutte le variabili a mia disposizione, poi mi basta accedere con offset, e non mi serve sapere il nome originario! (se invece non √® nota bisogna utilizzare la hastable).\nIn questo modo ho un leggere overhead in pi√π per uscire ed entrare in un blocco. Perch√© devo aggiornare l\u0026rsquo;array globale di liste, per√≤ mi implementa in modo semplice questo scope dinamico.\nPer tenere conto dei valori vecchi abbiamo principalmente due metodi:\nTenersi la stack degli elementi nascosti che viene ripristinata quando usciamo dal blocco (quindi √® temporaneo per tenere i vecchi valori) Lista dei vecchi valori, ossia ogni elemento si tiene una lista, che possiamo interpretarla come stack per ogni valore, che contiene i vecchi valori, in testa solamente il valore pi√π recente. Esempio stack elementi nascosti\nEsempio lista vecchi valori\n","permalink":"https://flecart.github.io/notes/gestione-della-memoria/","summary":"\u003ch2 id=\"memoria-statica\"\u003eMemoria statica\u003c/h2\u003e\n\u003ch3 id=\"elementi-in-memoria-statica-4--\"\u003eElementi in memoria statica (4) üü©-\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eVariabili globali\u003c/li\u003e\n\u003cli\u003eIstruzioni macchina\u003c/li\u003e\n\u003cli\u003eCostanti\u003c/li\u003e\n\u003cli\u003e(Variabili locali, paramentri e ritorno di funzione?)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLe primi tre elementi descritti di sopra sono sicuramente presenti dopo la fase di compilazione, infatti sono allocati dal compilatore in una zona presente nell‚Äôeseguibile (un esempio √® il READONLY per le stringhe in C).\u003c/p\u003e\n\u003cp\u003eQuindi se vogliamo\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAvere funzioni ricorsive\u003c/li\u003e\n\u003cli\u003ePotere allocare e deallocare variabili in modo dinamico\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAbbiamo bisogno di far uso di Pila o Heap, che riescano a cresere e restringersi in modo dinamico.\u003c/p\u003e","title":"Gestione della memoria"},{"content":"Introduzione Metodi alternativi di gestione degli errori (3) üü© A volte le computazioni falliscono. Potremmo gestirle con i result come accennato in Polimorfismo, per√≤ diventa molto macchinoso fare tutte le funzioni che debbano inoltrare solamente delle results. bisogna trovare un modo pi√π naturale. Ecco che arriva una gestione delle eccezioni direttamente nel linguaggio. Si tratta un sistema di comunicazione degli errori.\nALTRI METODI\nResults, stile monadico, vedi sopra. definire dei valori eccezionali (questo si va spesso in C) Il chiamato dice al chiamante una cosa da chiamare quando fallisce. Diciamo inversione del controllo perch√© in questo caso √® il chiamato che dice cosa fare. Ma rende il codice poco composizionale, quindi difficile da seguire. (Questa √® la soluzione molto pi√π simile alla gestione effettiva degli errori). Ma nelle eccezioni vere non √® il chiamato che ritorn al\u0026rsquo;indirizzo da eseguire ma √® il runtime che decide cosa andare ad eseguire. Questa cosa non interrompe il flusso del calcolo Con le eccezioni vogliamo trasferire il controllo a un gestore delle eccezioni questo gestore solitamente si trova sulla stack (va a risalire tutta la stack di chiamata fino a raggiungere questo gestore).\nDefinizioni di eccezioni üü© Una eccezione √® un modo per poter interrompere la computazione attuale (descrizione di stati invalidi della computazione), in vista di errori semantici come la divisione per zero. Sono proprio dei nomi (!!!), ossia catturati nominalmente duratne la gestione degli errori.\nAlcuni stemp importanti sono la\nDefinizione di errori gestibili, e sollevamento, o raising di questi errori Politiche di gestione degli errori. (come viene trasmesso e il codiche che viene chiamato) Meccanismi di sollevamento di errori Caratteristiche delle eccezioni üü© Nomi, le eccezioni hanno nomi e rappresentano quale errore semantico di operazioni, hanno una sintassi precisa Valori, possono contenere certi valori che comunichino qualcosa sul‚Äôerrore. COSTRUTTI DELLE ECCEZIONI\nSono solitamente due\nUn modo per marcare la porzione di codice protetta Un gestore delle eccezioni, che esegue nel caso sia stato sollevato all\u0026rsquo;interno di tutto il codice protetto una eccezione non gestita. Eccezioni e sottotipaggio üü©- Possiamo utilizzare la machinery di Polimorfismo anche in questa fase! Possiamo catturare eccezioni e tutti i sottotipi di una certa eccezione.\n√à anche considerata una bad practice, perch√© vorresti catturare una eccezione specifica (pi√π facile da capirne la causa diciamo)\nhttps://stackoverflow.com/questions/2416316/why-is-the-catchexception-almost-always-a-bad-idea\nhttps://stackoverflow.com/questions/6083248/is-it-a-bad-practice-to-catch-throwable\nCATCH √® un controllo Con subtyping! IN JAVA\nSlide java sottotipaggio\nThrowable √® un tipo somma di due casi (Error, irrecuperabile) e Exception. Tutte le eccezioni tranne Runtimeexception (e.g. se finisce memoria sulla heap) √® da gestire.\nImplementazione classica üü© Solitamente l‚Äôerrore viene proprio sollevato.\nOssia se vogliamo gestire un errore in un certo blocco protetto, allora linkiamo questo gestore a questo blocco.\nAlgoritmo per le eccezioni:\nCheck se il blocco attuale ha il gestore corretto (ossia supertipo dell‚Äôeccezione che ho) S√¨ runna questo codice bindato staticamente al blocco protetto Altrimenti risolleva l‚Äôerrore andando al record precedente Continua fino ad arrivare al gestore di default Implementazione per ricerca binaria üü®- Questo solitamente per le applicazioni reali √® pi√π veloce, perch√© quando entro in blocco protetto non ho bisogno del leggero overhead in pi√π per darti il gestore.\nPraticamente per ogni singolo blocco io definisco una coppia :\nInizio del codice protetto Puntatore al gestore delle eccezioni Se non ci ho definito niente, c\u0026rsquo;√® un puntatore di default, che semplicemente risollevi gli errori.\nTutti i blocchi sono tenuti in maniera ordinata, in modo da farci una ricerca binaria se ne ho bisogno. Quindi √® pi√π lenta di un fattore log(n), per√≤ dato che non ho overhead a entrare, di solito √® una cosa pi√π veloce della precedente.\nIn Java Tipologie di eccezioni (2) ","permalink":"https://flecart.github.io/notes/gestione-delle-eccezioni/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"metodi-alternativi-di-gestione-degli-errori-3-\"\u003eMetodi alternativi di gestione degli errori (3) üü©\u003c/h3\u003e\n\u003cp\u003eA volte le computazioni falliscono. Potremmo gestirle con i result come accennato in \u003ca href=\"/notes/polimorfismo/\"\u003ePolimorfismo\u003c/a\u003e, per√≤ diventa molto macchinoso fare tutte le funzioni che debbano inoltrare solamente delle results. bisogna trovare un modo pi√π naturale. Ecco che arriva una gestione delle eccezioni direttamente nel linguaggio. Si tratta un sistema di comunicazione degli errori.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eALTRI METODI\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eResults, stile monadico, vedi sopra.\u003c/li\u003e\n\u003cli\u003edefinire dei valori eccezionali (questo si va spesso in C)\u003c/li\u003e\n\u003cli\u003eIl chiamato dice al chiamante una cosa da chiamare quando fallisce. Diciamo \u003cstrong\u003einversione del controllo\u003c/strong\u003e perch√© in questo caso √® il chiamato che dice cosa fare. Ma rende il codice poco composizionale, quindi difficile da seguire.\n(Questa √® la soluzione molto pi√π simile alla gestione effettiva degli errori). Ma nelle eccezioni vere non √® il chiamato che ritorn al\u0026rsquo;indirizzo da eseguire ma √® il runtime che decide cosa andare ad eseguire. Questa cosa non interrompe il flusso del calcolo\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCon le eccezioni vogliamo \u003cstrong\u003etrasferire il controllo a un gestore delle eccezioni\u003c/strong\u003e questo gestore solitamente si trova sulla stack (va a risalire tutta la stack di chiamata fino a raggiungere questo gestore).\u003c/p\u003e","title":"Gestione delle eccezioni"},{"content":"Gestione delle risorse Introduzione Definizione classe, fungibilit√† Classe di risorse sono un insieme di risorse fra loro equivalenti (nel senso che uno pu√≤ rimpiazzare l‚Äôuso dell\u0026rsquo;altro), anche detti fungibili.\nStatico o dinamico Anche in economia ci sono tali definizioni! Queste risorse possono essere allocate staticamente o dinamicamente, in modo simile a quanto abbiamo detto in Gestione della memoria.\nStatico quando gi√† in fase di compilazione del processo, o di avviamento del processo gli d√≤ la memoria, e quella sar√† per tutti il tempo della sua vita.\nMentre dinamico quando gli d√≤ cose pezzo per pezzo quando √® vivo\nTipologia di richieste e risorse (4) (!!!) MULTIPLO O SINGOLO Si pu√≤ dire che il programma pu√≤ chiedere risorse, e le tipologie che puoi richiedere sono multiplo o singole.\nIl significato sembra abbastanza simile:\nSingola per singola classe di risorsa Multipla richiesta per tante classi (la differenza principale √® l‚Äôatomicit√† della richiesta, nel secondo caso, faccio singola richiesta per molteplici classi, o li prendo tutti o zero). BLOCCANTE O NON BLOCCANTE Si pu√≤ anche dividere per richiesta bloccante o meno, e anche questo √® molto simile a quanto abbiamo fatto in Programmi Concorrenti. Quindi bloccante come le IO, quando mi metto ad aspettare che finisca, oppure la comunicazione sincrona del Message Passing.\nNon bloccante come il send della comunicazione asincrona, ma anche solo una notifica dell mancato svolgimento, come credo faccia il message passing completamente asincrono.\nCONDIVISIBILE O NON-CONDIVISIBILE Si pu√≤ anche dividere in risorse condivisibli o meno, nel senso che una risorsa possa essere utilizzata da pi√π processi contemporaneamente (come i file di sola lettura (o qualunque cosa di solo lettura, perch√© non ho problemi di RW).\nEsempi di non condivisibil sono le cose hardware, processori, stampanti, o anch ele sezioni critiche, versioni software.\nPREEMTABLE O NON-PREEMTABLE Risorse preemptable, ossia prelasciabili, quando posso forzare la rimozione della risorsa all\u0026rsquo;utilizzatore.\nuna risorsa si dice prerilasciabile se la funzione di gestione pu√≤ sottrarla ad un processo prima che questo l\u0026rsquo;abbia effettivamente rilasciata\novviamente non vorrei che continuasse senza questa risorsa (quindi la stoppo)\nNon posso cambiare lo stato!! nel senso delle preemptable, se glielo tolgo, lui si aspetta di ricevere la risorsa quando torna a runnare allo stesso stato con cui √® stato tolto! Diciamo √® come se prendo in prestito un tuo giocattolo a forza e poi te lo distruggo, invece te lo vorrei ridare sano, normale diciamo.\nIl Deadlock Gi√† studiato molto in precedenza, vorremmo caratterizzare le condizioni necessarie per i deadlock all\u0026rsquo;interno dei sistemi operativi.\nCondizioni necessarie e sufficienti per DL (4) Quindi abbiamo caratterizzato con le propriet√† dei Deadlock! Quando ho tutte le 4 suddette cose, allora ho deadlock.\nGrafo di Holt Questo √® un sistema utilizzato per tracciare tutte le dipendenze delle risorse, che possono finire a creare deadlock.\nCaratteristiche di grafo di Holt Grafo di Holt Generale Lo rappresento come classe il quadrato e i puntini come singola risorsa, poi ho altre politiche per fare le frecce\nNote implementative su Holt Come facciamo a rappresentare nella memoria questo sistema? Alla fine √® un grafo pesato! Riduzione di grafo di holt un grafo di Holt si dice riducibile se esiste almeno un nodo processo con solo archi entranti.\nQuesto nodo eventualmente rilascia la risorsa, quindi posso posso riassegnare la risorsa!,\nIn questo modo faccio finta che la risorsa sia gi√† stata rilasciata.\nRiassegno tutti gli archi del processo riducibile agli altri. (non ci importa quale ordine rilasciare) Completa riducibilit√† lo stato non √® di deadlock se e solo se il grafo di Holt √® completamente riducibile, ossia quando non ho pi√π archi nel grafo\ni.e. esiste una sequenza di passi di riduzione che elimina tutti gli archi del grafo Ad intuito quando ho ancora degli archi, vorr√† dire che c‚Äô√® una attesa circolare, ossia:\nnon tutti i nodi processo hanno tutte le risorse che gli servono Non c‚Äô√® modo di acquisire la risorsa perch√© anche un altro sta aspettando la stessa cosa In questo senso si crea l‚Äôattesa circolare, ed assumendo le altre 3 condizioni di sopra ho deadlock.\nDeadlock detection introduttivo (singola risorsa) Th sola risorsa per classe\nse le risorse sono a richiesta bloccante, non condivisibili e non prerilasciabili, lo stato √® di deadlock se e solo se il grafo di Holt contiene un ciclo.\nGenero il grafo wait-for (chiusura transitiviva degli archi delle risorsa, cio√® se ho P che vuole risorsa, e risorsa assegnata a P2, allora ho P to P2), che in pratica mi genera l\u0026rsquo;attesa circolare (la 4 condizoine necessaria che lo rende sufficiente), e esiste il ciclo.\nSlides del th Esempi Pi√π risorse per classe Questo √® il caso anche pi√π reale, e ci √® molto pi√π utile questo caso. Costruiremo questo caso passo per passo con le definizioni che seguono.\nInsieme di raggiungibilit√† e Knot üü© dato un nodo n, l\u0026rsquo;insieme dei nodi raggiungibili da n viene detto insieme di raggiungibilit√† di n (scritto R(n))\nE si pu√≤ definire knot molto simile a uno strongly connected component, ma diversa:\nun knot del grafo G √® il sottoinsieme (non banale) di nodi $M$ tale che per ogni $n \\in M \\to R(n) = M$\nIn pratica tutti possono raggiungere tutti all\u0026rsquo;interno del Knot.\nEsempio di knot Th deadlock detection con knot Dato un grafo di Holt con una sola richiesta sospesa per processo se le risorse sono a richiesta bloccante, non condivisibili e non pre-rilasciabili, allora il grafo rappresenta uno stato di deadlock se e solo se esiste un knot\nQuindi riusciamo a detectare l\u0026rsquo;esistenza in questo modo!\nAnche se non abbiamo la dimostrazione formale, intuitivamente possiamo dire che se tutti possono raggiugnere tutti, implica l\u0026rsquo;attesa circolare!\nRecovery deadlock (2) Checkpoint e rollback L\u0026rsquo;idea √® molto semplice, praticamente ogni tot si guarda lo stato attuale del progetto, e si tenta di ripartire da l√¨, √® lo stesso concetto del backup (per√≤ si spera che gli effetti dal backup al deadlock, siano effetti di poco costo), e.g. se stampo di nuovo stampa di nuovo, ma non sarebbe buono per cose come la banca.\nTerminazione dei processi Per certe tipologie di processi √® molto molto costoso terminarle:\nEsempio centro di ricerca beowulf ci mette 6 mesi a ripartire Terminare in modo brutale pu√≤ lasciare risorse in modo invalido. Deadlock prevention Spooling Faccio finta a credere di avere gi√† la risorsa. Un esempio √® lo spool di stampa, nel senso che tutti pensano di avere questa risorsa. (questo funziona bene per la stampante per√≤!)\nNon risolve il problema perch√© √® come spostare il problema in altro punto, e NON SEMPRE APPLICABILE.\nProcess table no Dischi no. Per√≤ se il sistema √® in grado di gestire una sua coda, come nel caso di una stampante. Questo metodo sembra molto legit.\nRichiesta bloccante o pre-rilascio nel senso che tutto quello che mi serve all\u0026rsquo;inizio, lo richiedo subito, cos√¨ non mi blocco mai!\nAd esempio i sistemi a real time, che richiedono proprio allocazione totale.\nIl problema √® che non √® sempre possibile fare questo. E poi √® molto inefficiente perch√© se lo tengo per tutto l‚Äôutilizzo del nostro programma, ma alla fine solamente un piccolissimo momento lo utilizzo, inefficienza al pi√π!\nAttesa Circolare Una soluzione forte per questo √® l\u0026rsquo;allocazione gerarchica dei processi. In questo modo sicuramente non abbiamo cicli o interdipendenze. Posso solamente richiedere risorse di classi superiori (in modo che non abbia cicli, quindi diciamo che vada solamente a un verso, e non ho mai modi per avere dei knot).\nAnalisi finale allocazione gerarchica, totale Riassunto dei metodi di prevention Banchiere, DL avoidance Algoritmo del banchiere üü© Dijkstra (1965)\nil nome deriva dal metodo utilizzato da un ipotetico banchiere di provincia che gestisce un gruppo di clienti a cui ha concesso del credito; non tutti i clienti avranno bisogno dello stesso credito simultaneamente\nDescrizione del problema \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Gestione delle risorse/Untitled 14.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Gestione delle risorse/Untitled 14\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Gestione delle risorse/Untitled 15.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Gestione delle risorse/Untitled 15\u0026quot;\u0026gt; Dati in input Stato safe e unsafe üü© Slide stato safe Detto in soldoni, lo stato √® safe quando il credito del tizio che chiede √® minore di tutti i soldi che possiedo. Se non esiste nessuna sequenza che mi garantisca quella cosa sono unsafe!\nunsafe √® necessario ma non sufficiente per DEADLOCK.\nBuona sequenza con ni CRESCENTI.\nEsempio di banchiere safe esempio di unsafe \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Gestione delle risorse/Untitled 22.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Gestione delle risorse/Untitled 22\u0026quot;\u0026gt; Il fatto che sia safe o meno √® utile per capire se si pu√≤ accettare la richiesta o meno!\nBanchiere multi-valuta Dati del banchiere multi-valuta Purtroppo se teniamo come i vettori non possiamo ordinare :(. Quindi vorremmo andare passo passo, e ogni volta aggiungere qualcosa di soddisfacibile.\nTeorema dell\u0026rsquo;algoritmo del banchiere üü©‚Äî Slide algoritmo del banchiere Dimostrazione correttezza Questo mi permette di dire che non importa scegliere qualcosa con logica, se ho una sequenza che va continuer√† ad andare sempre! Mi permette di scegliere a caso.\nPerch√© non √® utilizzato Semplicemente tutte le ipotesi dell‚Äôalgoritmo del banchiere non sono spesso soddisfatte nel momento in cui si prova veramente a metterlo in pratica. Poi gli ingegneri dicono che spesso se un deadlock esiste una volta in 5 anni, per la maggior parte delle applicazioni diventerebbe una cosa tollerabile.\nSi assume che il numero dei processi sia noto all‚Äôinizio Si assume che le risorse necessarie al processo siano note Si assume che le risorse saranno sempre quelle (invece si potrebbero rompere a caso) ","permalink":"https://flecart.github.io/notes/gestione-delle-risorse/","summary":"\u003ch1 id=\"gestione-delle-risorse\"\u003eGestione delle risorse\u003c/h1\u003e\n\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"definizione-classe-fungibilit√†\"\u003eDefinizione classe, fungibilit√†\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eClasse di risorse\u003c/strong\u003e sono un insieme di risorse fra loro equivalenti (nel senso che uno pu√≤ rimpiazzare l‚Äôuso dell\u0026rsquo;altro), anche detti fungibili.\u003c/p\u003e\n\u003ch3 id=\"statico-o-dinamico\"\u003eStatico o dinamico\u003c/h3\u003e\n\u003cp\u003eAnche in economia ci sono tali definizioni! Queste risorse possono essere allocate staticamente o dinamicamente, in modo simile a quanto abbiamo detto in \u003ca href=\"/notes/gestione-della-memoria/\"\u003eGestione della memoria\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eStatico quando gi√† in fase di compilazione del processo, o di avviamento del processo gli d√≤ la memoria, e quella sar√† per tutti il tempo della sua vita.\u003c/p\u003e","title":"Gestione delle risorse"},{"content":"Dependable systems Introduzione Possiamo individuare alcune propriet√† dei sistemi distribuiti. Per√≤ non siamo riusciti a renderli logicamente validi. Sono ancora un p√≤ misti di linguaggio naturale e della sua ambiguit√†! Comunque possiamo ridurci per guardare quanto un sistema sia affidabile a guardare poche sue caratteristiche precise.\nCaratteristiche fondamentali (4) Queste propriet√† sono pensate naturalmente caratterizzanti dei sistemi. In particolare dovrebbero essere tutti misurabili.\nAvailability\nChe risponde nell‚Äôistante in cui fai una richiesta.\nReliability\nReliable quando non crasha quando comincia a runnare.\nSafety\nNiente di catastrofico avviene, ossia qualcosa da cui non si pu√≤ tornare indietro. Vorrei riuscire a riprendere l‚Äôesecuzione dopo i crash.\nMaintanability\nQuanto √® facile risolvere i problemi quando succedono i problemi.\nFaults Definiamo concetti come errori, faults, system failure. Rispettivamente sono definiti come\nErrore: √® uno stato del sistema che ha causato il comportamento inaspettato faults: cosa che ha causato lo stato d‚Äôerrore. system failure: quando non si comporta come secondo le specifiche. Noi vorremmo avere un modo per controllare i faults. Quindi sistemi che riescano a prevedere, rimuovere e prevenire faults.\nClassificazione dei faults\nSorts of faults (tempo)\nObiettivi dei sistemi distribuiti Possiamo andare ad individuare alcuni principi cardine nella costruzione dei sistemi distribuiti\nTrasparenza Vogliamo che la distanza fisica della locazione del server non sia percepibile, quindi l‚Äôesperienza del sistema distribuito sia come nascosto. Possiamo andare ad individuare molti (probabilmente troppe) tipologie di trasparenza, e non tutte possono essere facilmente garantite (non tutte poi dovrebbero essere garantite secondo me)\nOpenness Per aprirsi alla non-predittibilit√† dell‚Äôambiente in cui presente, il sistema deve essere in grado di cambiare componenti, accettarne dei nuovi, e sapere comunicare con questi. Per questo motivo chiamiamo un sistema distribuito OPEN.\nChiaramente un linguaggio comune per cui parlarsi deve esistere. Diventano quindi importanti le IDL (interface definition Languages) linguaggi nati proprio per definire solamente delle interfacce di comunicazione. (++ sijntassi del protocollo, un buon esempio pu√≤ essere protobuf).\nScalabilit√† Come pu√≤ scalare il nostro sistema distribuito. Di solito pu√≤ scalare verticalmente oppure orrizzontalmente. Per verticale diciamo comprare una macchina pi√π potente. Per orizzontale diciamo comprare pi√π macchine.\nUn problema per la scalabilit√†, molto legata alla trasparenza √® mascherare la latency di comunicazione.\nAvailability Pi√π o meno questo dovrebbe essere il vantaggio dei sistemi distribuiti, che essendo replicati, √® molto probabile che siano tutti ON. Questo concetto dell‚Äôavailability comunque racchiude il concetto di quanto spesso ti risponde alle tue richieste.\nTipologie di sistemi distribuiti Distributed computing systems Questi sono i sistemi principalmente devoti al calcolo scientifico. (Quindi utilizzo di protocolli come Beowulf, che permettono un calcolo molto veloce e coordinato in Rete LAN, utile a fare calcoli molto simili.\nQueste cose si dividono in cluster, e grid. Il primo fa cose molto simili fra di loro. Il secondo pu√≤ fare anche cose diverse (mi pare, non ne sono sicuro).\nIl cluster possiede stesso sistema operativo e sono solitamente messi nella stessa zona, collegati a una LAN molto veloce. Di solito √® questo il modo con cui si costruisce un supercomputer, perch√© √® la cosa pi√π economica ammassare tanti computer insieme che lavorino bene per avere potenza di calcolo superiore.\nEsempio cluster beowulf\nInvece i Grid sono utili per connettere aree amministrative diverse. Quindi boh‚Ä¶ Forse connessione fra uni diverse, filesystem condiviso?? buo.\nDistributed information systems Storicamente √® stato presente un fortissimo bisogno di coordinare i basi di dati di dipartimenti anche molto diversi affinch√© non ci sia una ripetizione inutile di dati che possa andare a causare una burocrazia molto elevata. C‚Äô√® stato quindi bisogno di creare un sistema di middleware condiviso a tutti i basi di dati che provava a rendere consistente tutte le basi di dati diverse.\nPervasive systems Attualmente tutte le persone possiedono dispositivi di calcolo, quindi √® importante dare risalto anche a questo modello di sistema distribuito.\nPrincipalmente i metodi per questa parte la dividiamo in 2 parti:\nSensori che inviano costantemente dati (overhead network e il server che li deve processare) Sensori che hanno un processore locale, e dati locale, che rispondono in modo coerente (come se fossere un unico sistema) quando sono chiesti da una query Paxos Paxos √® un protocollo utile per risolvere il problema di Bizantine agreement, creato da Lamport nel 1998. per BA guardare Syncronous model.\nL‚Äôidea √® dividire il processo di agreement in due fasi. Una priomise e un commit.\nPoi andiamo a definire alcuni agenti principali in questo protocollo. Dei proposers,acceptors, quorum.** I primi propongono, gli altri accettano. Quando √® stato raggiunto un quorum, allora si va alla seconda fase, quella di commit o accettazione, se √® rifiutato si torna a prima, altrimenti si va al commit. Pu√≤ esserci livelock?\n","permalink":"https://flecart.github.io/notes/goals-of-distributed-systems/","summary":"\u003ch1 id=\"dependable-systems\"\u003eDependable systems\u003c/h1\u003e\n\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003cp\u003ePossiamo individuare alcune propriet√† dei sistemi distribuiti. Per√≤ non siamo riusciti a renderli logicamente validi. Sono ancora un p√≤ misti di linguaggio naturale e della sua ambiguit√†!\nComunque possiamo ridurci per guardare quanto un sistema sia affidabile a guardare poche sue caratteristiche precise.\u003c/p\u003e\n\u003ch3 id=\"caratteristiche-fondamentali-4\"\u003eCaratteristiche fondamentali (4)\u003c/h3\u003e\n\u003cp\u003eQueste propriet√† sono pensate naturalmente caratterizzanti dei sistemi. In particolare dovrebbero essere tutti misurabili.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAvailability\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eChe risponde nell‚Äôistante in cui fai una richiesta.\u003c/p\u003e","title":"Goals of Distributed systems"},{"content":"Rappresentazione e terminologia Operazioni importanti\nDefinizione di grafo √à un insieme di nodi e di archi. (prendili da insiemi corretti)\nMetodi di rappresentazione Liste di incidenza In pratica numero tutti gli archi e storo il valore dell\u0026rsquo;arco incidente per ogni nodo. Diventa una tabella con una parte i nodi e l\u0026rsquo;altra gli archi. Avr√≤ dei valori -1 e 1 che marcano partenza e arrivo. La cosa carina di questo metodo √® che pu√≤ essere generalizzata anche per Ipergrafi, in cui gli archi possono avere pi√π di una partenza o arrivo. Solitamente √® memorizzato come una lista, quindi esattamente nodo partenza e arrivo per ogni edge.\nListe di adiacenza Classico usato per Competitive, si memorizzano direttamente pointer a nodi di interesse. Quindi abbiamo una forma del genere: Nodo -\u0026gt; lista dei nodi a cui √® collegato.\nMatrici di adiacenza Se esiste un arco fra due nodi, metto un uno in questa posizione (si pu√≤ utilizzare una cosa simile per mantenere il peso di un arco)\nTermini importanti Cammino, cammino semplice, ciclo, ciclo semplice, fortemente e debolmetne connesso. grafo completo, aciclico\nCammino e cammino semplice Ciclo Componente debolmente connessa Grafo completo Grafo aciclico Algoritmi sui grafi Algoritmi di visita BFS DFS Ordinamento topologico √à una dfs üòÄ√® utile poi per utilizzare\n`\nComponenti fortemente connesse √à una relazione di equivalentz la raggiungibilit√† (anche per grafi indiretti) e quindi per connessione debole\nSi pu√≤ utilizzare l\u0026rsquo;algoritmo di Tarjan (credo si chiami cosi) per le SCC. si fa in m + n\nMinimum Spanning Tree Definizione di MST Un sottografo di un grafo che prenda tutti i vertici, tale per cui la somma del peso degli archi presi sia la minima possibile.\nTaglio di un grafo\nRegole per l‚Äôintuizione della sol greedy\nda libro\nKruscal Si utilizza la union find,\nPrim Solo sulla frontiera, si espande usando la regola del taglio\nCammini minimi Propriet√† (sottostruttura e esistenza per connettivit√†) Se ho un cammino minimo, allora anche un suo sotto cammino a un sottonodo √® un cammino minimo Se ho un grafo connesso, allora esistono cammini minimi fra due nodi connessi Condizione di Bellman Questa √® una condizione sul valore della distanza fra i nodi dei grafi:\nSe ho $d_{xy} \\leq d_{xp} + w(p, y)$, ovvero la distanza fra due nodi, √® sempre minore o uguale alla distanza fra un nodo intermedio e l\u0026rsquo;arco fra questo nodo a y. √à uguale se √® il cammino minimo.\nDa questa osservazione di pu√≤ definire una condizione di rilassamento di un arco. Gli algoritmi di rilassamento partono da una condizione grossolana, poi approssimano qualcosa sempre meglio, volta dopo volta.\nAlgoritmo di Bellman-ford Il pensiero per ricordarsi questo algoritmo √® questa osservazione:\nSuppongo di conoscere il cammino minimo da un vertice di partenza e un vertice di arrivo, allora sarebbe facile percorrerlo e conoscerne i costi. Noto che se provo a rilassare ogni singolo arco, allora dovrei aver almeno trovato il costo per il primo nodo del cammino. Continuo a fare cos√¨, con rilassamenti successivi finch√© non arrivo a uno stadio stabile.\nCerco di rilassare ogni arco finch√© qualcosa cambia, se cambia vuol dire che non ho ancora finito tutti i rilassamenti possibili.\nAlgoritmo\nNota:\nQuesto algoritmo √® buono perch√© trova il cammino minimo anche per archi negativi üå†\nAlgoritmo di Dijkstra Questo algoritmo funziona solamente nel caso in cui non ho archid i peso negativo.\nLemma fondamentale per comprendere Dijkstra\nAlgoritmo in pseudocodice generico\nAlgoritmo in pseudocodice con strutture di dati\nAlgoritmo di Floyd-Warshall Utilizziamo la programmazione dinamica per calcolare tutti i percorsi minimi. L\u0026rsquo;idea √® calcolare ad ogni step, una matrice di percorsi che passano per un certo specifico vertice.\nAlgoritmo in pseudocodice (si pu√≤ ottimizzare lo spazio in questo) Dopo Part of Speech Tagging e Transliteration systems si pu√≤ tradurre questo algoritmo come programmazione dinamica su grafi su un semi-anello artico.\n","permalink":"https://flecart.github.io/notes/grafi/","summary":"\u003ch2 id=\"rappresentazione-e-terminologia\"\u003eRappresentazione e terminologia\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eOperazioni importanti\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Grafi/Untitled.png\" alt=\"image/universita/ex-notion/Grafi/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"definizione-di-grafo\"\u003eDefinizione di grafo\u003c/h3\u003e\n\u003cp\u003e√à un insieme di nodi e di archi. (prendili da insiemi corretti)\u003c/p\u003e\n\u003ch3 id=\"metodi-di-rappresentazione\"\u003eMetodi di rappresentazione\u003c/h3\u003e\n\u003ch4 id=\"liste-di-incidenza\"\u003eListe di incidenza\u003c/h4\u003e\n\u003cp\u003eIn pratica numero tutti gli archi e storo il valore dell\u0026rsquo;arco incidente per ogni nodo.\nDiventa una tabella con una parte i nodi e l\u0026rsquo;altra gli archi. Avr√≤ dei valori -1 e 1 che marcano partenza e arrivo.\nLa cosa carina di questo metodo √® che pu√≤ essere generalizzata anche per Ipergrafi, in cui gli archi possono avere pi√π di una partenza o arrivo.\nSolitamente √® memorizzato come una lista, quindi esattamente nodo partenza e arrivo per ogni edge.\u003c/p\u003e","title":"Grafi"},{"content":"Introduzione Definizione grammatica regolare üü© Definizione\nIn pratica posso avere solamente come terminali a, oppure un suffisso a su un non terminale.\nQueste grammatiche sono interessanti perch√© √® molto facile costruire un automa che sia in grado di riconoscere questo linguaggio.\nSeguendo una definizione pi√π lasca possono anche accettare dei nonterminali epsilon\nEspressione regolare a NFA üü© Questa sezione √® anche presente in Automi e Regexp, per√≤ √® riportata qui cos√¨ c‚Äô√® l‚Äôinsieme di tutte le cose in un unico posto.\nEnunciato\nDimostrazione\nMi creo un automa che riconosce in modo ricorsivo (per tutte le produzioni della grammatica delle regexp\nGuarda lezione 7\nDa grammatica regolare a NFA (!) üü© In modo simile a quanto si fa per la dimostrazione per espressioni regolari rappresentabili come NFA anche questa √® cos√¨\nDimostrazione\nDa DFA a grammatica regolare üü© Questo √® anche conosciuto come algorithmo di Kleene.\nDimostrazione\nGrammatica regolare a linguaggio regolare üü© Dimostrazione molto informale\nPraticamente l\u0026rsquo;idea principale √® fare rimpiazzamenti ricorsivi finch√© non lo ho in una forma bella.\nRiassunto tutte le equivalenze NFA, DFA, grammatiche ed espressioni.\nRiassunto delle equivalenze üü©- C‚Äô√® una precisa domanda che chiede di discutere in modo generale le equivalenze, quindi metto anche questo doc.\nSlide\nCostruzione dello scanner Introduzione üü© Slide\nPer fare questa cosa rientra il problema di creazione della DFA da NFA pi√π piccola possibile!.\nNon so come si faccia, ma almeno ora sai che esiste questo problema.\nAd intuito possiamo andare ad affermare che un automa √® minimo quando non ci sono due stati equivalenti ossia, sempre ad intuito, non li possono compattare in uno, quindi non ho ridondanza di stati.\nEsempio di minimizzazione\nEquivalenza ed indistiguibilit√† (di stati) üü© Slide\nOssia se due stati sono in grado di riconoscere esattamente lo stesso linguaggio, sono equivalenti. Ma ogni stringa del linguaggio √® una cosa difficile da gestire, per questo motivo provo a dimostrare che non siano equivalenti, ossia lo stato di accettazione per una stessa stringa sia diversa partendo dalla stringa vuota\nSlide strategia\nProvo a togliere tutti\nFamiglia di relazioni (5) üü©- Slide\nIn pratica sto andando a guardare se lo stato finale √® lo stesso o meno, partendo dalla stringa nulla, poi andando avanti a costruire altre, e continuando a togliere se lo stato finale ora √® diverso.\nQuesta √® una relazione di equivalenza.\nPropriet√†\nDimo propriet√† 4, se non cambia ho finito üü® Ossia se non tolgo pi√π coppie in un passo, allora il mio algoritmo dovr√† essere finito.\nDimostrazione\nEsempio di applicazione dell‚Äôalgoritmo di minimizzazione\nMinimizzazione In questa parte andremo a trattare definizioni e algoritmi utili a minimizzare un automa DFA (nel senso di meno stati possibili).\nAlgoritmo degli stati equivalenti üü© Algos\nPraticamente vado a marcare per tutte le cose possibili (partendo dalla relazione 0). Vado a marcare se non appartengono alla stessa relazione di equivalenza (ossia sono diversi). E se i percorsi pi√π lunghi finiscono su altre celle gi√† occupate, allora marco anche questo, con un segno diverso, per dire che non sono equivalenti per un certo percorso pi√π lungo.\nDimostrazione correttezza algoritmo üü®+ Enunciato di terminazione e correttezza dell‚Äôalgoritmo\nDimostrazione di sopra\nTerminazione √® dipendente dalla propriet√† 4 a 5, cio√® che se non cambia a un passo, allora non cambia a nessun passo, e la 5 che mi dice che ad ogni passo ne marco almeno uno (e questi sono numeri finiti).\nDistinguibilit√† se la casella marcata allora esiste un percorso che termina in modo diverso da uno rispetto all\u0026rsquo;altro, in altro termine esiste una stringa che √® riconosciuta da uno ma non √® riconosciuta da un altro! (ma se lo ho marcato in questo modo allora √® ovvio che succeda questo!).\nAutoma minimo (4) üü© Questa definizione tratta le caratteristiche formali di un automa minimo costruito da un DFA valido.\n(minimizzare gli stati, la funzione di transizione e gli stati accettati).\nIn pratica nello stesso stato dell‚Äôautoma minimo ci metto tutti gli stati equivalenti ad essa, in questo senso di minimo!\nDefinizione\nProbabilmente in questo passo intendevo sono 3 le cose nuove differenti\nStati possibili devono essere gli equivalenti fra tutti. Transizioni √® ora fatto su stati equivalenti Stato iniziale √® la classe di equivalenza sullo stato iniziale Gli stati accettati sono le classi si equivalenza sugli stati finali.. Alfabeto √® lo stesso. Equivalenza automa minimo e originale (non chiede) üü®‚Äî Slide linguaggio riconosciuto √® lo stesso, ed √® anche il minimo\nDimostrazione\nIn pratica per dimostrare il minimo suppongo che esista un automa con ancora meno stati, questi due (il minimo nuovo e il minimo costruito) devono riuscire a riconoscere esattamente le stesse cose, ma essendo questo con ancora meno, deve essere che il minimo costruito abbia due stati equivalenti, cosa che non pu√≤ succedere col nostro algoritmo\nLex/Flex e Yacc Questi sono analizzatori lessicali che prendono in input un file di definizioni regolari e restituisce un programma in C che riesca a riconoscere questi automi\nDiagramma semplificativo di quanto fa\nStruttura di file Lex (3) üü© Slide riassunto\nDichiarazioni\nPraticamente in sta parte ci sono le definizioni regolari che abbiamo discusso pi√π sopra nello stesso documento che ci rende la scrittura di espressioni regolari molto pi√π semplice\nRegole\nQui definisci tutte le espressioni regolari che ti servono. Definite in schema di\nPattern ‚Üí azione\nOssia se un pattern √® riconosciuto, esegui una azione.\nFunzioni ausiliarie\nNel caso in cui le azione sono tropp complesse una serie di funzioni ausiliare possono essere molto utili\nFunzionamento di Lex (4) üü®+ In questa parte descriviamo brevemente le regole che il lex utilizza per decidere cosa fare.\nMatcha seguendo le regole A parit√† di matching diversa, sceglie quello il matching pi√π lungo A parit√† di lunghezza di matching, sceglie quello listato prima Se non matcha, viene dato in output la stringa inalterata Esistono funzioni per gestire i match, la stringa matchata, la lunghezza della stringa matchata (yytext e yylenght) Esistono funzioni per matchare di pi√π o di meno, come yymore e yyless. Yacc üü© A differenza di Lex, Yacc si occupa di generare la sintassi.\nQuesto √® un analizzatore sintattico, quindi sar√† trattato nel dettaglio in un capitolo successivo. Per ora basta capire che i processi di scanning e parsing sono eseguiti pi√π o meno in parallelo, √® il parser che chiede ogni volta il token, evitando di avere in memoria rappresentazioni differenti della stessa cosa.\nyylval sono variabili comuni che permettono di scambiare informazioni.\nyylex() √® cchiamato da yacc nel momento di richiesta di lessemi\nPumping Lemma (!!!) üü© Enunciato\nDimostrazione\nNegazione del pumping lemma\nPropriet√† dei linguaggi regolari (5) üü© unione concatenazione stella di Kleene Complemento Intersezione Dimostrazione\n","permalink":"https://flecart.github.io/notes/grammatiche-regolari/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"definizione-grammatica-regolare-\"\u003eDefinizione grammatica regolare üü©\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eDefinizione\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Grammatiche Regolari/Untitled 1.png\" alt=\"image/universita/ex-notion/Grammatiche Regolari/Untitled 1\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn pratica posso avere solamente come terminali a, oppure un suffisso a su un non terminale.\u003c/p\u003e\n\u003cp\u003eQueste grammatiche sono interessanti perch√© √® molto facile costruire un automa che sia in grado di riconoscere questo linguaggio.\u003c/p\u003e\n\u003cp\u003eSeguendo una definizione pi√π \u003cem\u003elasca\u003c/em\u003e possono anche accettare dei nonterminali \u003cstrong\u003eepsilon\u003c/strong\u003e\u003c/p\u003e\n\u003ch3 id=\"espressione-regolare-a-nfa-\"\u003eEspressione regolare a NFA üü©\u003c/h3\u003e\n\u003cp\u003eQuesta sezione √® anche presente in \u003ca href=\"/notes/automi-e-regexp/\"\u003eAutomi e Regexp\u003c/a\u003e, per√≤ √® riportata qui cos√¨ c‚Äô√® l‚Äôinsieme di tutte le cose in un unico posto.\u003c/p\u003e","title":"Grammatiche Regolari"},{"content":"We have first cited the graph data model in the Introduction to Big Data note. Until now, we have explored many aspects of relational data bases, but now we are changing the data model completely. The main reason driving this discussion are the limitations of classical relational databases: queries like traversal of a high number of relationships, reverse traversal requiring also indexing foreign keys (need double index! Index only work in one direction for relationship traversal, i.e. if you need both direction you should build an index both for the forward key and backward key), looking for patterns in the relationships, are especially expensive when using normal databases. We have improved over the problem of joining with relational database using Document Stores with three data structure, but these cannot have cycles. We call index-free adjacency: we use physical memory pointers to store the graph.\nGraph Data Models Graph databases are more generic than standard relational databases. One of the main use cases that it attempts to solve is the cost of joins in standard relational databases, the problem that Wide Column Storage was attempting to solve too!\nDesign objectives Graphs are variegate: it is not feasible to think of a single data model that can fit all the possible use cases. For this reason, we list here many choices of possible models and properties of databases that should be considered when designing a database.\nRead or Write intensive: we have discussed in Introduction to Big Data that it is important to consider if the load is read or write intensive (OLAP or OLTP). Local or distributed: it is important to consider if the data is stored in a single machine or in many machines. Native or non-native: if the database is native, it means that it is designed to store graphs, otherwise it is non-native (perhaps the underlying layer has a different data model). Triple Stores üü© This data model is commonly known as RDF (Resource Description Framework), which is W3C standard. It is a simple model that consists of triples, which are made of a subject, a predicate and an object (note: these are all labels, not properties!). The subject is the entity, the predicate is the property and the object is the value of the property. This is a very simple model, but it is not very efficient for querying. We have explored this model in Metadati web e web semantico. This kind of graph data model is usually very easy to implement with relational databases with tables made of three columns.\nIn triple stores, not all labels are compatible to subject object or properties.\nSubject Property Object IRI üü© üü© üü© Literal\nüü• üü• üü© Blank Node üü© üü• üü© Labeled property graph model üü© This is the most natural model for us Computer Scientists. We take the classical notion of Graphs (See Grafi). And extend it with properties and labels. Properties are flat-maps in nodes and edges. Each property is a map from strings to values that represents a certain property of the node or edge. Labels are some strings attached to nodes, they are commonly called types. There is no limit for the number of labels and properties for each.\nEach node and each edge can be associated with a map from strings to values, which represents its properties. So we can have as many properties as we would like for nodes and edges.\nLabels can be seen as table names, nodes as records, and properties as the attribute values for the records. Labels can be stores as properties, this is what Triple Store people could argue.\nIn a¬†labeled property graph, nodes can have one or more labels and zero or more properties, edges are directed and have exactly one label(s) and zero or more properties.\nMeaning: Every node and edge is labelled!\nNeo4j The nodes in a query that map to specific real nodes are called anchors/bound nodes as they anchor the query to real nodes.\nGraph databases maintain fast query times even when storing vast amounts of data. Learning to trust our graph database is important when learning to structure our graphs without denormalizing them.\nData Types These are the classical types.\nNeo4j type JSONiq/JSound/XML Schema type STRING\nBOOLEAN\nINTEGER\nFLOAT\nNULL\nDATE\nTIME\nDATETIME\nZONED DATETIME\nZONED TIME\nLOCAL DATETIME\nLOCAL TIME\nDURATION\nLIST string\nboolean\nlong\ndouble\nnull\ndate\ntime\ndateTime\ndateTimeStamp\ntime (time zone mandatory)\ndateTime (no time zone)\ntime (no time zone)\nduration\narray But we have some extensions for graph types too! Point for (GIS) data types Paths Nodes Edges. Operations With Clause üü© This is very similar to the functional let clause in Querying Denormalized Data. Example:\nWITH 1 as x RETURN x + 1 Set Clause This used to add some labels to the nodes:\nMATCH (a {y:1}) WHERE a.x=1 or a.x=8 SET a: yourRook MATCH (a {y:1}) WHERE a.x=2 or a.x=7 SET a: yourKnight MATCH (a {y:1}) WHERE a.x=3 or a.x=6 SET a: yourBishop MATCH (a {a.x:4, y:8}) SET a: theirKing UNWIND Clause This is used to transform a list into a table. It is very similar to the for loop in JSONiq:\nUNWIND [1, 2, 3] as x RETURN x + 1 UNWIND range(1, 8) AS y UNWIND range(1, 8) AS x CREATE (:Field {x: x, y:y}) MATCH Clause üü© This is the most powerful clause in Cypher. It can used to traverse the graph. It is a quite natural way to find for patterns in a graph database\nMATCH (n:Person)-[:KNOWS]-\u0026gt;(m) RETURN n, m CREATE Clause üü© This is used to create nodes and relationships in the graph. It is quite similar to the INSERT statement in SQL.\nCREATE (einstein:Scientist {name: \u0026#34;Albert Einstein\u0026#34;}), (tesla:Scientist {name: \u0026#34;Nikola Tesla\u0026#34;}), (einstein)-[:KNOWS]-\u0026gt;(tesla) MERGE Clause üü© This is used to create a node if it does not exist, otherwise it returns it. It is similar to the UPSERT statement in SQL.\nMATCH (n:Person {name: \u0026#34;Albert Einstein\u0026#34;}) MERGE (n)-[:KNOWS]-\u0026gt;(tesla:Scientist {name: \u0026#34;Nikola Tesla\u0026#34;}) MATCH (a: Field), (b: Field) WHERE (a.x=b.x OR a.y=b.y) AND (a\u0026lt;\u0026gt;b) MERGE (a)-[:rook]-\u0026gt;(b) Standards üü• Two main standards:\nSQL/PGQ (we use relational query like, but extend it with graph queries, one simple use case is PostgresSQL with Graph extension) GQL (Graph Query Language) Mainly people have agreed on these two possible query standards. Physical Architecture Neo4j can handle graphs with tens of billions of nodes, relationships, and properties. Apparently it could handle the Facebook graph.\nSharding üü®\u0026ndash; We would like to be able to store graph data on different machines, but this is difficult when we have links between different data on another place! This was a difficult problem but has been solved in recent years. Very recently so to say.\nGraph in memory üü®\u0026ndash; We store the nodes, relationships , properties and labels separately on the disk. But when the database is up, everything is stored in the memory (index-free adjacency map). Usually using adjacency lists (doubly linked lists on the edges for each node).\nStores üü®+ There exists a store for nodes, relationships, properties, and labels. Storing the data for example for nodes and properties separately makes the underlying model slightly different from the view exposed to the user, however this greatly increases traversal performance.\nStores for nodes, for example have a size of exactly 9 bytes.\nFirst byte: usage data next four: ID of the relationship connected for the node next five: ID of the first property for the node Final byte is for future use. Resource Description Framework See Metadati web e web semantico for a comparison on this topic. RDFs stores every possible property or label as a tuple of three. These are directional and are called:\nSubject Predicate Object. All of these are identified by URI or some literals or blank nodes (see the linked resource for cases where we have blank nodes, it has to do with reification, which is an added problem due to the model\u0026rsquo;s simplicity). URI can be used in each of these three parts, this is very important because it allows to create a tree of data that looks like a taxonomy. Literals can be used for the object part, and they are the values of the properties. Blank nodes are used for the subject or object part, and they are used to represent the absence of it, but not on the relation.\nThree Syntaxes RDF/XML Turtle JSON-LD See Metadati web e web semantico, they are the most common syntaxes to represent semantic web. ","permalink":"https://flecart.github.io/notes/graph-databases/","summary":"\u003cp\u003eWe have first cited the graph data model in the \u003ca href=\"/notes/introduction-to-big-data/\"\u003eIntroduction to Big Data\u003c/a\u003e note.\nUntil now, we have explored many aspects of relational data bases, but now we are changing the data model completely. The main reason driving this discussion are the limitations of classical relational databases: queries like traversal of a high number of relationships, reverse traversal requiring\nalso indexing foreign keys (need double index! Index only work in one direction for relationship traversal, i.e. if you need both direction you should build an index both for the forward key and backward key), looking for patterns in the relationships, are especially expensive when using normal databases.\nWe have improved over the problem of joining with relational database using \u003ca href=\"/notes/document-stores/\"\u003eDocument Stores\u003c/a\u003e with three data structure, but these \u003cem\u003ecannot\u003c/em\u003e have cycles.\nWe call \u003cem\u003eindex-free adjacency\u003c/em\u003e: we use physical memory pointers to store the graph.\u003c/p\u003e","title":"Graph Databases"},{"content":"Definizione gruppo Qualunque insieme pi√π operazione tale per cui:\nEsistenza dell\u0026rsquo;inverso per ogni elemento $\\forall g \\in G, \\exists g^{-1} \\in G : gg^{-1} = e$ Esistenza di un elemento neutro $\\exists e \\in G: \\forall g \\in G, eg = g$ Associativit√†: $(gh)f = g(hf)$ Closure: $\\forall g, h \\in G \\implies gh \\in G$ Unicit√† dell‚Äôelemento neutro Supponiamo di avere un gruppo $G$ e due elementi neutri $e, f$ Allora abbiamo che $ae = a = af$ per√≤ se moltiplichiamo per l\u0026rsquo;inversa abbiamo che $a^{-1}ae = a^{-1}af \\implies e = f$\nUnicit√† dell‚Äôinverso Supponiamo di avere un gruppo $G$ e due elementi inversi per ogni $a \\in G$ Sia $a$ un elemento e gli inversi $a_{1}$ e $a_{2}$, allora abbiamo: $aa_{1} = e = aa_{2}$ ma se moltiplico a sinistra per l\u0026rsquo;inversa abbiamo\n$a_{1}aa_{1} = a_{1}aa_{2} \\implies ea_{1} = ea_{2} \\implies a_{1} = a_{2}$ Dove abbiamo utilizzato anche l\u0026rsquo;associativit√†.\nPropriet√† di cancellazione √à ovvio se moltiplichiamo per le cose giuste. L‚Äôinverso del prodotto Enunciato: $(ab)^{-1} = b^{-1}a^{-1}$ e per gruppi abeliani abbiamo $(ab)^{-1} = a^{-1}b^{-1}$\nLa dimostrazione √® molto semplice ed √® lasciato al visitatore :D\nTest per gruppo Ordine di gruppo e di elemento L\u0026rsquo;ordine di un gruppo √® la cardinalit√† dell\u0026rsquo;insieme, L\u0026rsquo;ordine dell\u0026rsquo;elemento del gruppo √® la potenza a cui si eleva questo elemento per avere il neutro\nTest unico per il sotto-gruppo $$ \\forall a,b \\in H ,H \\subseteq G, ab^{-1} \\in H \\implies H \\text{ is a subgroup of G} $$ Se vale questa propriet√† possiamo gi√† avere un sottogruppo! Quindi √® abbastanza comodo!\nDimostrazione:\nAssociativit√† si ha per $G$. Se prendo $a, a$ come la coppia abbiamo che $aa^{-1}=e$ appartiene a $H$, quindi c\u0026rsquo;√® l\u0026rsquo;elemento neutro. Se prendo $e, a$ vedo che $a^{-1} \\in H$. Quindi abbiamo che vale.\nTest doppio per il gruppo Mostrare che sia chiuso rispetto all\u0026rsquo;operazione e ci sia sempre l\u0026rsquo;inverso. Questo in pratica va per la #Definizione gruppo come espresso sopra!\nTest per gruppi finiti Mostrare solamente che sia chiuso per l\u0026rsquo;operazione (nella dimostrazione di deve mostrare che √® chiuso per l\u0026rsquo;inverso, cosa che si va per il terzo escluso\nSottogruppi Sottogruppi generati da un elemento (ciclico) Dimostrazione Osservazione:\nOgni sottogruppo generato in questo modo √® abeliano, perch√© √® in isomorfismo con il gruppo additivo Z (si vedr√† dopo di questo isomorfismo)\nIl centro di un gruppo √® un sottogruppo Dimostrazione enunciato in h3\nEsempio: centro di gruppi diedrali\nCentralizzatore di un gruppo √® un sottogruppo Osservazione: quando il centralizzatore √® l\u0026rsquo;intero gruppo, l\u0026rsquo;elemento su cui stiamo centralizzando √® esattamente il centro.\nDimostrazione Analoga alla precedente del centro Group actions Intuitively, a group action modifies a set, without changing some interesting property (structure preserving).\nIt is a function $\\alpha: G\\times \\Omega \\to \\Omega$ of group $G$ acting on set $\\Omega$ that satisfies this relation:\n$\\alpha(g, \\alpha(h, u)) = \\alpha(gh, u)$ meaning if i apply an action, then another action, is the same as applying the composition of the action. This is called compatibility. $\\alpha(e, u) = u$ has a identity application. For brevity we will omit the $\\alpha$ and $\\alpha(gh, u)$ will be written as $(gh)u$. $\\Omega$ acting on $X(\\Omega, C)$ follows that $(gx)(u) = x(g^{-1}u)$ why is this true?\n","permalink":"https://flecart.github.io/notes/gruppi/","summary":"\u003ch2 id=\"definizione-gruppo\"\u003eDefinizione gruppo\u003c/h2\u003e\n\u003cp\u003eQualunque insieme pi√π operazione tale per cui:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eEsistenza dell\u0026rsquo;inverso per ogni elemento $\\forall g \\in G, \\exists g^{-1} \\in G : gg^{-1} = e$\u003c/li\u003e\n\u003cli\u003eEsistenza di un elemento neutro $\\exists e \\in G: \\forall g \\in G, eg = g$\u003c/li\u003e\n\u003cli\u003eAssociativit√†: $(gh)f = g(hf)$\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eClosure\u003c/strong\u003e: $\\forall g, h \\in G \\implies gh \\in G$\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"unicit√†-dellelemento-neutro\"\u003eUnicit√† dell‚Äôelemento neutro\u003c/h3\u003e\n\u003cp\u003eSupponiamo di avere un gruppo $G$ e due elementi neutri $e, f$\nAllora abbiamo che\n$ae = a = af$ per√≤ se moltiplichiamo per l\u0026rsquo;inversa abbiamo che\n$a^{-1}ae = a^{-1}af \\implies e = f$\u003c/p\u003e","title":"Gruppi"},{"content":"Gruppi ciclici e permutazioni Il gruppo ciclico Definizione gruppo ciclico Abbiamo definito in Gruppi per la prima volta il significato di gruppo ciclico generato da un elemento del gruppo, questo insieme si √® poi dimostrato essere un sottogruppo del gruppo\n$$ G = \\left\\{ a^{n} \\mid n \\in \\mathbb{Z} \\right\\} $$ Dove a √® chiamato elemento generatore.\n$$ ord(G) = \\lvert \\langle a \\rangle \\rvert $$Criterio $a^{i} = a^{j}$ Probabilmente ha qualche relazione con [Teorema di Lagrange](/notes/teorema-di-lagrange). note sull\u0026rsquo;enunciato entrambe le frecce $\\impliedby$ sono abbastanza ovvie.\nRagionando sul primo caso, nel caso in cui √® infinito, se succedesse che $a^i = a^j \\land i \\neq j$ si avrebbe che l\u0026rsquo;ordine √® finito, perch√© si ripeterebbe ogni tot, quindi dimostri cos√¨. Nel secondo caso credo sia cos√¨, ma non saprei come formalizzare la cosa.\nDimostrazione Come si pu√≤ notare, mi sto riducendo a una classe di resto con l\u0026rsquo;algoritmo di euclide nel secondo caso.\nQuesto √® un teorema molto importante nei gruppi finiti, soprattutto, perch√© mi sta dicendo che ci possiamo sempre ridurre a una classe di resto per l\u0026rsquo;esponente.\nCorollario 1 $\\text{ Per ogni elemento di gruppo A, si ha che: } |A| = |\\langle A\\rangle|$\nCorollario 2\n$a\\in G, |a| = n \\in \\mathbb{N}, k \\in \\mathbb{Z}, a^k = e_g \\implies n \\mid k$\nOsservazione\nQuesto fatto che la moltiplicazione fra due elementi funziona come una addizione fra due elementi in $\\Z_n$ ci fa intuire come sia possibile un isomorfismo fra questi due gruppi.\nInfatti esiste, dimostreremo poi che per ogni gruppo ciclico finito di ordine n esiste un isomorfismo con Zn (credo)\nRelazione fra ordine $n, e$ un $k$ in $\\mathbb{Z}$ e $gcd(n,k)$ Dimostrazione Questo teorema ci √® molto utile per ridurre il generatore di un gruppo in un altro pi√π gestibile o pi√π semplice da manipolare\nCorollario 1\nIn un gruppo ciclico, l\u0026rsquo;ordine di un elemento divide l\u0026rsquo;ordine del gruppo.\nIn simboli\n$$ a\\in G, |a| =k, |G| = n,\\implies k \\mid n $$(da notare l\u0026rsquo;ordine opposto dei divide rispetto al corollario 2 del teorema precedente)\nCorollario 2 criterio $\\lvert a_{i} \\rvert = \\lvert a_{j} \\rvert$\nQuesto √® molto simile al teorema precedente, ma ora stiamo parlando di ordine.\nEnunciato\nDimostrazione\ncorollario 3 Generatori di gruppi ciclici finiti\nQuesto √® un corollario del corollario üòÇ. In pratica afferma che\nIl gruppo generato da $\\langle a \\rangle$ √® uguale a $\\langle a^j \\rangle$ sse $gcd(n, j) = 1$ con n l\u0026rsquo;ordine di a. cosa simile con $|a| = |a^j| \\iff gcd(n,j) = 1$\nE avendo questo possiamo definire con concretezza di generatori del gruppo finito Zk\nCorollario 4 Generatori di Zn\nsia $k \\in \\mathbb{Z}_n$, k √® un generatore sse $gcd(n,k) = 1$.\nla dimostrazione segue dal fatto che 1 √® un generatore di Zn, e vogliamo che il gruppo generato da 1 e k sia lo stesso.\nClassificazione di sottogruppi di gruppi ciclici Teorema fondamentale dei gruppi ciclici Dimostrazione Corollario Sottogruppi di Zn\nDal teorema fondamentale dei sottogruppi di gruppi ciclici abbiamo una caratterizzazione precisa dei sottogruppi presenti in Zn, sono in particolare tutti i divisori di n.\nNumero di elementi di un un certo ordine in un gruppo ciclico Dimostrazione\nQuesto √® anche una dimostrazione per Teorema di Lagrange#Teorema di Eulero.\nCorollario 1 Numero di elementi di ordine d\nEnunciato\nDimostrazione\nGruppi di permutazione Decomposizione in cicli Esiste una sintassi per scrivere le permutazioni con una notazione a cicli. Vogliamo dimostrare ora che questa sintassi √® sempre possibile (quindi corrisponde a una equivalenza)\nDimostrazione\nLa dimostrazione procede per via costruttiva, proponendo una specie di algoritmo per trovare tutti i cicli fino ad esaurimento di elementi nell‚Äôinsieme.\nCommutativit√† di cicli disgiunti Dimostrazione\nUna volta letta la dimostrazione sembra una cosa ovvia, ma probabilmente l‚Äôidea √® sulla scelta degli elementi iniziali?\nOrdine di una permutazione (scomposizione con ordine di sottocicli) Dimostrazione\nDecomposizione in permutazioni bicicle Dimostrazione\nProposizione\nQuesto lemma si pu√≤ estendere a un caso pi√π generale, dove si possono iniziare a distinguere permutazioni pari e dispari. Vedremo che avranno certe propriet√† (legate alle matrici poi anche).\nDimostrazione\nParit√† e disparit√† di 2-cicli Dimostrazione\nL‚Äôinsieme di permutazioni pari √® un sottogruppo di Sn Dimostrazione\nSiano a, b due elementi di questo insieme, vogliamo dimostrare che $ab^{-1} \\in S$ notiamo che per il teorema 5.5 $b^{-1}$ deve essere pari, perch√© altrimenti avrei che $e = bb^{-1}$ sarebbe scrivibile come un prodotto di permutazioni 2-cicle dispari. Inoltre, chiaramente un prodotto di 2 permutazioni pari √® ancora pari (basta concatenare queste, che poi al massimo si eliminano a due a due). Ecco il sottogruppo.\nIl gruppo alternante di n ha ordine n! L‚Äôenunciato √® proprio questo titolo, quindi non lo riporto (sul libro √® il numero 5.7).\nInvece riporto la definizione di gruppo alternante:\nDimostrazione\nResidui Quadratici Si dice che $x \\in G$ √® un residuo quadratico nel suo gruppo se ha una radice quadrata in quel gruppo, ossia un $a \\in G$ tale per cui $a^{2} = x$. Questo √® di particolare interesse per robe di crittografia come per Asymmetric Cryptography.\nSimbolo di Legendre $$ x^{(p - 1)/2} $$√à strettamente legata ai residui quadratici\nSe $x \\in Z_{p}$ √® un residuo quadratico allora $x^{(p-1)/2} \\equiv 1 \\mod p$. Computing modulo e-roots is as difficult as factorization.\n","permalink":"https://flecart.github.io/notes/gruppi-ciclici-e-permutazioni/","summary":"\u003ch1 id=\"gruppi-ciclici-e-permutazioni\"\u003eGruppi ciclici e permutazioni\u003c/h1\u003e\n\u003ch2 id=\"il-gruppo-ciclico\"\u003eIl gruppo ciclico\u003c/h2\u003e\n\u003ch3 id=\"definizione-gruppo-ciclico\"\u003eDefinizione gruppo ciclico\u003c/h3\u003e\n\u003cp\u003eAbbiamo definito in \u003ca href=\"/notes/gruppi/\"\u003eGruppi\u003c/a\u003e per la prima volta il significato di gruppo ciclico generato da un elemento del gruppo, questo insieme si √® poi dimostrato essere un sottogruppo del gruppo\u003c/p\u003e\n$$\nG = \\left\\{ a^{n} \\mid n \\in \\mathbb{Z} \\right\\} \n$$\u003cp\u003e\nDove \u003cstrong\u003ea\u003c/strong\u003e √® chiamato \u003cstrong\u003eelemento generatore\u003c/strong\u003e.\u003c/p\u003e\n$$\nord(G) = \\lvert \\langle a \\rangle  \\rvert \n$$\u003ch3 id=\"criterio-ai--aj\"\u003eCriterio $a^{i} = a^{j}$\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Gruppi ciclici e permutazioni/Untitled 1.png\" alt=\"image/universita/ex-notion/Gruppi ciclici e permutazioni/Untitled 1\"\u003e\nProbabilmente ha qualche relazione con [Teorema di Lagrange](/notes/teorema-di-lagrange).\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003enote sull\u0026rsquo;enunciato\nentrambe le frecce $\\impliedby$ sono abbastanza ovvie.\u003c/p\u003e","title":"Gruppi ciclici e permutazioni"},{"content":"Introduzione Definizione normalit√† Test del sottogruppo normale Dimostrazione\nIl gruppo quoziente L‚Äôimportanza del gruppo normale √® che quando esso vale, possiamo avere il gurppo fattore\nDimostrazione\n!\n","permalink":"https://flecart.github.io/notes/gruppi-normali/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"definizione-normalit√†\"\u003eDefinizione normalit√†\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Gruppi Normali/Untitled.png\" alt=\"image/universita/ex-notion/Gruppi Normali/Untitled\"\u003e\n\u003ch3 id=\"test-del-sottogruppo-normale\"\u003eTest del sottogruppo normale\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Gruppi Normali/Untitled 1.png\" alt=\"image/universita/ex-notion/Gruppi Normali/Untitled 1\"\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eDimostrazione\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Gruppi Normali/Untitled 2.png\" alt=\"image/universita/ex-notion/Gruppi Normali/Untitled 2\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"il-gruppo-quoziente\"\u003eIl gruppo quoziente\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Gruppi Normali/Untitled 3.png\" alt=\"image/universita/ex-notion/Gruppi Normali/Untitled 3\"\u003e\n\u003cp\u003eL‚Äôimportanza del gruppo normale √® che quando esso vale, possiamo avere il gurppo fattore\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eDimostrazione\u003c/p\u003e\n\u003cp\u003e!\u003cimg src=\"/images/notes/image/universita/ex-notion/Gruppi Normali/Untitled 4.png\" alt=\"image/universita/ex-notion/Gruppi Normali/Untitled 4\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","title":"Gruppi Normali"},{"content":"Halting theorem Questo √® un problema fondamentale, che abbiamo trattato anche in Fondamenti teorica#Halting problem, ma qui lo ritrattiamo, perch√© cos√¨ lo rifacciamo per bene. In parte √® stato trattato anche al corso di Logica.\nEnunciato Halting theoremüü© $$ HALT = \\left\\{ \\langle x, y \\rangle \\in \\Sigma^{*} \\times \\Sigma^{*}: x = code(M),M \\text{ si ferma su } x\\right\\} $$Dimostrazione Halting theoremüü© La parte del s√¨ √® facile perch√© basta eseguirlo e vedere che si ferma (quindi abbiamo una La macchina di Turing#La macchina di Turing universale. Se si ferma appartiene al linguaggio, altrimenti √® la parte in cui diverge.\n$$ \\begin{cases} f(g, y) = 1, g(y) \\downarrow\\\\ \\\\ f(g, y) = 0, g(y) \\uparrow \\end{cases} $$$$ \\begin{cases} h(g) = 1, f(g, g) = 0 \\\\ \\\\ h(g) = \\uparrow, f(g, g) = 1 \\end{cases} $$ Allora la computazione della funzione $h(h)$ genera un assurdo.\nIl motivo √® che $h(h) = 1 \\iff f(h, h) = 0 \\iff h(h) = \\uparrow$ Questa cosa dovrebbe essere riscritta in modo $code$ per essere comprensibile da macchine di Turing.\nOpposto di Halting theoremüü© $$ HALT^{-} = \\left\\{ \\langle x, y \\rangle : x \\not= code(M) \\cup x=code(M) \\cap M \\text{ non si ferma su } x\\right\\} $$ Si pu√≤ dimostrare che questo problema non √® nemmeno riconoscibile da nessuno!\nDimostrazione complemento di halting theoremüü© Si ragiona anche qui per assurdo, se fosse riconoscibile, avremmo che Halting theorem principale sarebbe riconoscibile.\nMapping reducibility Definizione mapping reducibilityüü© $$ x \\in L' \\iff f(x) \\in L $$ E si scrive che $L' \\leq L$ Ossia posso mappare qualunque parola in $L'$ in una stringa in $L$. √à molto importante che sia computabile, perch√© √® un modo di dire che non stiamo barando nella dimostrazione, e mi appoggio soltanto all\u0026rsquo;espressivit√† dei due linguaggi.\nPropriet√† di decidibilit√† basilariüü© Se $L$ √® decidibile, allora $\\forall L': L'\\leq L$ √® decidibile. Se $L'$ √® indecidibile allora lo √® anche $\\forall L: L' \\leq L$ perch√© altrimenti si avrebbe un assurdo Se $L$ √® decidibile e $L'$ no allora $L' \\not \\leq L$ altrimenti assurdo per il primo punto. Ogni linguaggio decidibile √® sempliceüü®+ $$ L' \\leq L $$ In altre parole, possiamo dire che i linguaggi decidibili sono mapping reducibili a qualunque altro linguaggio non banale, quindi sono le pi√π semplici esistenti in altre parole.\nDimostrazione: Dato che $L'$ √® decidibile, esiste $g(x), \\forall x \\in \\Sigma^{*}$ tale che decide se $x$ appartiene o meno a quel linguaggio. Dato che $L$ √® finito, esiste un $\\omega$ che non appartiene e un altro $v$ che appartiene. Allora costruisco la funzione $f$ cos√¨:\nRunno $g$, se appartiene, mappo a $v$ Se non appartiene mappo a $\\omega$. Ez. Indecidibilit√† su nastro vuotoüü© NOTA: in ogni caso devo vedere se il codice della macchina √® valido.\n$$ ETH = \\left\\{ x \\in \\Sigma^{*}: x = code(\\mathcal{M}) \\text{ e } \\mathcal{M} \\text{ si ferma su } \\varepsilon \\right\\} $$ Per dimostrare ci√≤ basta dimostrare che $HALT \\leq ETH$ Ossia dobbiamo costruire una funzione che mappa ogni stringa di $HALT$ in una di $ETH$. Questo √® molto semplice, solo definire qualche dettaglio (non banale) Indicibilit√† ogni inputüü© $$ FL = \\left\\{ x \\in \\Sigma^{*} : x = code(\\mathcal{M}) \\text{ e } \\mathcal{M} \\text{ ferma su ogni input} \\right\\} $$ Anche questo si pu√≤ dimostrare in maniera simile al precedente, con una mapping reduction. Questo √® anche pi√π semplice: Se $\\mathcal{M}$ non √® il codice di nessuna macchina ritorno quello. Altrimenti: Per ogni input $\\langle \\mathcal{M}, x \\rangle$ costruisco la seguente macchina\nLa macchina nuova prende un input $y$, la ignora per il momento, e simula $\\langle \\mathcal{M}, x \\rangle$. Se termina (e quindi appartiene a $HALT$) allora termino anche io ignorando l\u0026rsquo;input. Altrimenti divergo, e quindi non appartengo. Questa nuova macchina √® bona. Quindi funziona l\u0026rsquo;indicibilit√† $$ \\langle y, x \\rangle \\in HALT \\iff \\text{ macchina si ferma su }x \\iff \\mathcal{M}_{\\mathcal{M}, x} \\text{ si ferma sempre} \\iff f(\\langle y,x \\rangle ) = code(\\mathcal{M}_{\\mathcal{M}, x}) \\in FL $$Equivalence problem decidability $$ EQ = \\left\\{ \\langle y, x \\rangle \\in \\Sigma^{*} \\times \\Sigma^{*} : x = code(\\mathcal{M}), y = code(\\mathcal{M'}) \\text{ e } \\mathcal{M}, \\mathcal{M'} \\text{ hanno la stessa funzione parziale} \\right\\} $$ Anche in questo caso proviamo a ridurci al caso $FL$. Sempre come prima, per input $\\langle \\mathcal{M}\\rangle$ mi costruisco questa macchina La correttezza di questo √® un po\u0026rsquo; pi√π fine, per√≤ √® giusto. Vedere qui.\nEquivalence problem recognizabilityüü®+ Il linguaggio del problema di equivalenza non √® nemmeno riconoscibile. Per fare ci√≤ devo ridurre $HALT^{-}$ a questo EQ. Dimostro la riduzione $HALT \\implies EQ^{-}$\nNota sulla gerarchia Cosa curiosa √® che $HALT$ √® il suo opposto non sono comparabili. Mentre ci aspetteremmo che HALT sia pi√π semplice. Una altra cosa curiosa √® che EQ non √® riconoscibile, e nemmeno il suo opposto lo √®. Quindi EQ non √® nemmeno semi-decidibile. Turing riducibilit√† Definizione di oracoloüü© Dato un linguaggio $L$ e una stringa $x$, l\u0026rsquo;oracolo mi dice in tempo finito se $x \\in L$.\nDefinizione Turing-riducibilit√†üü© Dato un $L'$ , questo √® Turing riducibile a $L$, quindi $L' \\leq_{TM} L$, se dato un oracolo per $L$ possiamo decidere $L'$\nMapping reducibility =\u0026gt; Turing-riducibilit√†üü© Possiamo dimostrare in modo semplice che con Turing-riducibilit√† $HALT$ √® riducibile a $HALT^{-}$. Senza problemi. Mentre non posso farlo con Mapping reducibility. Questo mi dice che Turing riducibilit√† √® una propriet√† pi√π forte della mapping reducibility, anche se non √® propriamente una dimostrazione di questa propriet√†.\nBaker-Gill-Soloway (1975) Questa sezione √® solamente una nota filosofica, ma di poco conto per l\u0026rsquo;esame.\nPrendiamo una macchina di Turing con oracolo, ossia possiamo chiedere se una stringa √® parte dell\u0026rsquo;oracolo in tempo costante (come se fosse un dizionario con accesso diretto).\nEsistono oracoli $O, O'$ tali per cui $P = NP$ con una macchina di Turing che usi il primo oracolo, e anche che $P \\neq NP$ usando il secondo oracolo. Questo teorema dice che la tecnica di diagonalizzazione di Cantor non pu√≤ essere usata per risolvere NP = P. Questo dato √® inutile per la maggior parte delle cose attuali credo. Oppure TM non sono buoni per risolvere questo problema (ha fatto nascere la branca con i circuiti booleani, non fatta qui).\nReferences [1] Sipser ‚ÄúIntroduction to the Theory of Computation‚Äù Cengage Learning 2012\n","permalink":"https://flecart.github.io/notes/halting-theorem-and-reducibility/","summary":"\u003ch3 id=\"halting-theorem\"\u003eHalting theorem\u003c/h3\u003e\n\u003cp\u003eQuesto √® un problema fondamentale, che abbiamo trattato anche in \u003ca href=\"/notes/fondamenti-teorica/#halting-problem\"\u003eFondamenti teorica#Halting problem\u003c/a\u003e, ma qui lo ritrattiamo, perch√© cos√¨ lo rifacciamo per bene. In parte √® stato trattato anche al corso di Logica.\u003c/p\u003e\n\u003ch4 id=\"enunciato-halting-theorem\"\u003eEnunciato Halting theoremüü©\u003c/h4\u003e\n$$\nHALT = \\left\\{ \\langle x, y \\rangle \\in \\Sigma^{*} \\times \\Sigma^{*}: x = code(M),M \\text{ si ferma su } x\\right\\}\n$$\u003ch4 id=\"dimostrazione-halting-theorem\"\u003eDimostrazione Halting theoremüü©\u003c/h4\u003e\n\u003cp\u003eLa parte del s√¨ √® facile perch√© basta eseguirlo e vedere che si ferma (quindi abbiamo una \u003ca href=\"/notes/la-macchina-di-turing/#la-macchina-di-turing-universale\"\u003eLa macchina di Turing#La macchina di Turing universale\u003c/a\u003e. Se si ferma appartiene al linguaggio, altrimenti √® la parte in cui diverge.\u003c/p\u003e","title":"Halting Theorem and Reducibility"},{"content":"7.1 De Hopital 7.1.1 Lemmi preliminari Questo lemma preliminare era gi√† presente per la prova del teorema degli zeri\nQuesto lemma √® molto interessante perch√© mette in relazione il finito (le successioni) con l\u0026rsquo;infinito (i reali) In molte dimostrazioni si d√† per scontato questo lemma, ma √® una sottigliezza importante che giustifica l\u0026rsquo;utilizzo di successioni per limiti reali. Ci permette di semplificare molto le dimostrazioni perch√© riusciamo a trattare le successioni molto meglio.\n7.1.2 ipotesi Enunciato al finito, finito\nEnunciato, limite al finito, asintoto\nEnunciato, limite destro o sinistro\nEnunciato limite all\u0026rsquo;infinito\nIl fatto che voglio che sia sigma sia la derivata di sigma siano diversi da zero, √® perch√© la conclusione deve avere entrambi diversi da zero.\n7.1.3 Dimostrazione Dimostrazione in slide\nNote sulla dimostrazione\nUtilizzo Cauchy per dire che esiste una successione che mi piace. Utilizzo il lemma delle successioni per dire che la successione trovata con cauchy √® proprio quello che mi serve Faccio uguale questa cosa di cauchy con la divisione senza le derivate e concludo per una parte. I passi principali sono:\nCercare di esprimere il limite della frazione come il limitie della frazione con input una successione.\nRiscrivere la frazione come la frazione - il punto che vogliamo calcolare (per ipotesi sto sottraendo 0) perch√© cos√¨ possiamo utilizzare dopo cauchy. Utilizziamo cauchy ed esprimiamo la frazione al punto uno come una divisione fra derivate. Dalla divisione fra derivate in successione utilizziamo il lemma e ci riconduciamo alla continuit√†. 7.2 Infiniti ed infinitesimi Queste conclusioni si adagiano fortemente sulle conclusioni del teorema di de l\u0026rsquo;Hopital\n7.2.1 Confronto fra infiniti Il teorema di De l\u0026rsquo;Hopital √® molto utile per descrivere una gerarchia degli infiniti. Possiamo confrontare quale funzione cresce pi√π in fretta di un altro.\nEnunciato\nC\u0026rsquo;√® anche il caso in L = $\\infty$, in quel caso si dice che √® di ordine inferiore.\nConclusioni\n7.2.2 Confronto fra infinitesimi Si potrebbe fare la stessa cosa per gli infinitesimi, si otterrebbero risultati opposti, ma il concetto √® lo stesso si utilizza sempre il concetto di teorema di Hopital.\nDefinizione infinitesimo\nEnunciato\nO-piccolo di funzione Il concetto di O-piccolo riesce a catturare il concetto di errore di misura (pi√π o-piccolo √® grande, pi√π precisa √® la mia misura).\nDefinizione Intuizione\nIn modo grossolano, se f √® infinitesimo di ordine maggiore rispetto al denominatore g, allora f √® un opiccolo di g.\nIn pratica si dice che una funzione g √® un o-piccolo di una funzione f se per il punto di cui stiamo calcolando il limite, g √® un infinitesimo di ordine superiore rispetto a f. (ricolleghiamo con il confronto fra infinitesimi)\n7.3.2 Propriet√† algebriche O-piccolo possiede alcune propriet√† algebriche di interesse, che sarebbe buona cosa studiare, quindi:\nDerivazione di altri O- e somma\nPotenze\nComposizione\nConstante\n7.3.3 Funzioni di stesso ordine Enunciato e dimostrazione\n7.4 Serie di Taylor L\u0026rsquo;idea principale per le serie di Taylor √® trasformare le funzioni trascendentali con alcuni polinomi.\nIn modo che alla fine si abbia un limite di rapporto di polinomi che equivalga alla funzione trascendentale, vogliamo una approssimazione della funzione che sia abbastanza precisa.\nsar√† alla fine un polinomio infinito!\n7.4.1 Intuizione Vogliamo cercare quale polinomio approssima meglio una funzione per ogni grado. Scopriamo che per una funzione continua √® la costante f(0) stessa per una funzione continua in questo punto. Formalizzato leggermente meglio questo pu√≤ diventare una dimostrazione.\ne si ha che √® O(1). Faccio lo stesso ragionamento per gradi superiori e mi trovo la serie di taylor, con qualunque approssimazione che mi serva. Consideriamo il caso in cui siamo sul 0, per una funzione continua e derivabile reale.\n$$ \\lim_{ x \\to 0 } \\frac{f(x) - f(0)}{x} = f'(0) \\in \\mathbb{R} $$$$ \\lim_{ n \\to 0 } \\frac{f(x) - f(0)}{x} - f'(0) = 0 \\implies \\lim_{ n \\to 0 } \\frac{f(x) - f(0) - f'(0)x}{x} = 0 $$ Dove abbiamo utilizzato la continuit√† del limite per somme e sottrazioni. Questo ci dice che tutto quanto sopra √® un $o(x)$ Ossia si pu√≤ riscrivere quanto sopra come $f(x) = f(x) + f'(0)x + o(x)$\nSi pu√≤ continuare su su questa scia e approssimare la funzione tramite $o(x^{2})$ e in teoria si pu√≤ continuare cos√¨ all\u0026rsquo;infinito. Questo non √® una dimostrazione formale, nemmeno matematica, ma d√† la giusta intuizione sul perch√© la serie di Taylor funziona.\n$$ \\lim_{ x \\to 0 } \\frac{f(x) - f(0) - f'(0) x - a_{1}x^{2}}{x^{2}} $$$$ \\lim_{ x \\to 0 } \\frac{f'(x) - f'(0) - 2a_{1}x}{2x} $$$$ \\lim_{ x \\to 0 } \\frac{f'(x) - f'(0)}{2x} - a_{1} = \\frac{1}{2}f''(0) - a_{1} $$ Questo significa che se settiamo il coefficiente in modo adatto possiamo avere un $o(x^{2})$ senza nessun problema! Ossia se $a_{1} = \\frac{1}{2}f''(0)$ vale che l\u0026rsquo;espressione di sopra √® un $o(x^{2})$ di sopra, per cui possiamo scrivere che\n$$ f(x) \\approx f(0) + f'(0)x + a_{1}x^{2} + o(x^{2}) $$ Con $a_{1}$ il valore di sopra. Applicando ancora Hopital sopra si pu√≤ avere il termine con esponente ancora superiore cos√¨ via!\n7.4.2 Enunciato Taylor e Peano Nota: si pu√≤ analizzare Taylor in una altra forma, che √® trattata in Massimi minimi multi-variabile#Resto secondo Peano\nEnunciato Taylor Sia $f: (a, b) \\to \\mathbb{R}$ una funzione continua, e sia $0 \\in (a, b)$ Poniamo $f$ derivabile n-volte in $\\bar{x} = 0$\n$$ T_{n}(x) = \\sum_{j=0}^{n} \\frac{f^{(j)}(0)}{j!}x^{j} $$$$ f(x) = T_{n}(x) + o(x^{n}) $$ per $x \\to 0$\nEnunciato Peano Questo √® esattamente il precedente, ma stiamo shiftando il polinomio, permettendo di avere dei valori che non siano necessariamente su 0. Sia $f: (a, b) \\to \\mathbb{R}$ una funzione continua, e sia $\\bar{x} \\in (a, b)$ Poniamo $f$ derivabile n-volte in $\\bar{x}$\n$$ T_{n}(x) = \\sum_{j=0}^{n} \\frac{f^{(j)}(\\bar{x})}{j!}(x - \\bar{x})^{j} $$$$ f(x) = T_{n}(x) + o((x - \\bar{x})^{n}) $$ per $x \\to \\bar{x}$\nSerie di Taylor note 7.5.1 Esponenziale e Logaritmo Dimostrazione espo\nLogaritmo $$ \\ln(1 + x) = \\sum_{i = 1}^{n} \\frac{(-1)^{i - 1}}{i} \\cdot x^{i} + o(x^{n}) $$ con $x \\to 0$.\n7.5.2 Goniometriche Una nota di valore √® che l\u0026rsquo;espansione del seno ha solamente polinomi dispari, questo √® in stretta relazione con la disparit√† del seno, mentre per il coseno, dato che √® pari, si hanno solamente polinomi di gradi pari.\nSeno\nCoseno\n!\nBinomiale generalizzato Descrizione\n, Peano/Untitled 26.png]]\nCoseno\n!\n$$ \\cos t t = \\sum_{k = 0}^{n} (-1)^{k} \\frac{t^{2k}}{(2k)!} + o(t^{2m}) $$","permalink":"https://flecart.github.io/notes/hopital-taylor-peano/","summary":"\u003ch2 id=\"71-de-hopital\"\u003e7.1 De Hopital\u003c/h2\u003e\n\u003ch3 id=\"711-lemmi-preliminari\"\u003e7.1.1 Lemmi preliminari\u003c/h3\u003e\n\u003cp\u003eQuesto lemma preliminare era gi√† presente per la prova del \u003ca href=\"/notes/limiti/#teorema-degli-zeri\"\u003eteorema degli zeri\u003c/a\u003e\u003c/p\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Hopital, Taylor, Peano/Untitled.png\" alt=\"image/universita/ex-notion/Hopital, Taylor, Peano/Untitled\"\u003e\n\u003cp\u003eQuesto lemma √® molto interessante perch√© mette in relazione il finito (le successioni) con l\u0026rsquo;infinito (i reali)\nIn molte dimostrazioni si d√† per scontato questo lemma, ma √® una sottigliezza importante che giustifica l\u0026rsquo;utilizzo di successioni per limiti reali.\nCi permette di semplificare molto le dimostrazioni perch√© riusciamo a trattare le successioni molto meglio.\u003c/p\u003e","title":"Hopital, Taylor, Peano"},{"content":"Un p√≤ di storia √à importante capire un p√≤ di storia per vedere che strano robo abbiamo oggi. Due linee di sviluppo, uno √® uno standard di W3C, l\u0026rsquo;altro √® il living standard. √à di fortissimo cambiamento, quindi di difficile definizione! (cambia significato sia di semantica e che di sintassi).\nNel 1997 abbiamo HTML4 che √® stata considerata la versione finale, per cui un sacchissimo di siti web fino al 2008 sono stati implementato con questo HTML\nTag Soup üü© I browser permettono molti tag, senza voler dare errore con l\u0026rsquo;obiettivo di essere comprensivi. Abbiamo quindi un sacco di tags, molti dei quali non sono conformi a nessuno standard. Non abbiamo una correttezza sintattica o semantica dei tags. Abbiamo in pratica troppe eccezioni. Solitamente si √® strict quando si scrive e permissivi quando si legge.\nIl problema allora diventa, quando vogliamo andare a creare un parser per questo genere di html, come andare a crearne uno che riesca a gestire queste tipologie di tags?\nSlide quirks and strict mode\nIn particolare abbiamo con HTML5 una standarizzazione delle regole di parsing quindi possiamo andare ad utilizzare lo strict mode e avere pi√π garanzie sulle pagine.\nXHTML e HTML Le aziende dei webbrowser avevano gi√† il codice per parsare il HTML brutto, con molti codici, e non volevano creare un nuovo parse per XHTML, molto pi√π formale e che riusciva a garantire pi√π codice (ossia ci sarebbe un modo unico per scrivere del codice corretto!). L\u0026rsquo;hanno proposto ai tizi del W3C che l\u0026rsquo;hanno rifiutato. Cos√¨ √® stato creato il working group WHATWG in cui si lavor√≤ a una versione intermedia di HTML, che estese con alcuni tag. Dentro questo gruppo erano gi√† presenti i maggiori player per i browser come mozilla, microsoft, e poi ci √® entrato Google assumendo Ian per la creazione di chrome.\nIn questo moto ha vinto HTML5, che viene chiamato solamente HTML e un living standard che viene aggiornato ogni poche settimane.\nQuesto albero che viene creato dal parsing di quel modello √® utile per la creazione del DOM trattato pi√π sotto.\nHTML Struttura del documento üü© Ci deve essere una intestazione DOCTYPE che ci specifica che tipologia di documento stiamo andando a parsare (se non c\u0026rsquo;√® credo sarebbe sintatticamente invalido ma ciononostante il browser √® in grato di inferire come intenderlo!)\nhtml che include tutto\nhead che include informazioni generali sul documento\nbody che contiene il contenuto del sito.\nEsempio di file HTML\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt; Document title \u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt; Major Header \u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is a complete paragraph of a document. I write and write until I fill in several lines, since I want to see how it wraps automatically. Surely not a very exciting document.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Did you expect \u0026lt;b\u0026gt;poetry\u0026lt;/b\u0026gt;?\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Here you can see a paragraph \u0026lt;br\u0026gt; split by a \u0026amp;lt;br\u0026amp;gt;\u0026lt;/p\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt; A list of important things to remember: \u0026lt;/p\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Spaces, tabs and returns\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Document type declaration\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Document structure\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Nesting and closing tags\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Elementi inline üü© Molti sono stati deprecati (o non li usa nessuno), perch√© dovrebbero essere usati CSS per la parte grafica. Solo i, e B sono ancora presenti, o small, perch√© sono caratteri tipografici molto comuni!\nEsempi di elementi inline\nElementi di blocco e di lista üü© Sono i blocchi classici per rappresentare struttura di headers, di paragrafi, e blocchi generici, o citazoini, autori.\nBlocchi seguono una sequenza di lettura fra le letture!\nesempio:\ndiv\u0026gt;, un elemento anonimo, che deve essere totalmente stilato. span\u0026gt;, la stessa coda del div, che per√≤ non √® blocco ma INLINE. h1\u0026gt;, h2\u0026gt; ‚Ä¶, h6\u0026gt; etc NOTA: whitespace √® praticamente sempre ignorato, tranne all‚Äôinterno del tag pre. (esiste white-space: pre, che permette di utilizzare whitespaces\nSlide\nEsempio\nElementi di lista\nSlide\nEsempio elementi lista\nElementi di struttura üü© Non vorremmo avere dei div come elementi di struttura, questo non √® che sia molto chiaro dal punto di vista semantico!\nQuindi introduciamo\nsection\u0026gt; che descrive un qualcosa di annidabile\narticle\u0026gt; che prende qualcosa di self-contained che pu√≤ essere utilizzato a s√©, e quindi potrei rimuoverla o inserirla senza problemi!\nSlide tags struttura\nSlide header e footer\nSlide nav\nEsempio confronto HTML 4 / HTML5\nAnchors and images üü© Anchors\nPosso metterci un fragment per gli a, questo non camibano niente nella transazione client e server, ma √® il browser che capisce la locazione dopo aver scaricato tutto.\nSi noti che l\u0026rsquo;attributo name non cambia la visuale del blocco, a differenza di href (che manda fuori).\nSlide anchors\nImmagini\nHa ancora degli attributi altezza e witdt, che rimangono ancora nonostante siano attributi rappresentazionali. Per√≤ precalcola l\u0026rsquo;occupazione dell\u0026rsquo;immagine e quindi il tutto carica pi√π in fretta.\nSlide immagini\nPotrei includerla con una immagine, e specificare height o width (se li includo entrambi avr√≤ resize dell‚Äôimmagine senza rispettare le proporzioni, se non metto niente avrei l‚Äôimmagine di grandezza naturale (px original) altrimenti se ne metto sono una avr√≤ una resize che mantenga le dimensioni iniziali).\nsrcset, vogliamo avere tantissime immagini, che si scalino in modo automatico aseconda del device, definisco srcset e delle sizes.\nSlide srcset\n**figure **√® un tag con un caption in pratica, niente di che‚Ä¶\nForm üü®- esistono da sempre, quindi gi√† dall\u0026rsquo;inizio sembrava che fossero utili per fare applicazioni con un rapporto in clientside.\nCreare una schermata per specificare i dati da passare a una applicazione server-side, per creare punti di raccolta di informazioni, e fare un submit all\u0026rsquo;applicazione server side, chiamata ACTION, .\nSlide struttura di un form\nSolitamente i metodi sono GET o POST, ma vedremo dopo con HTTP questa differenza.\nI widget sono le cose visibili nel form, come **textarea, radio,, input select, *button.\nInteractive forms\nNew input forms\nTags generali üü©- Embedding\nobject √® un tag per oggetti che non sono capibili dal browser naturalmente, infatti bisogna specificare un engine con cui runnarlo.\nQuesto √® un embedding molto, troppo generale, quindi vogliamo creare i tags per embedding specifici, che rende il tutto pi√π chiaro.\nSlide per tags di embedding\nTabelle\nCose come th per dire table header, or tr per dire table row., td per dire table data., e table per inizializzare le table\nSolitamente √® composta da tre parti. head, foot, e body, solitamente per questioni di efficienza foot deve essere messo subito dopo le head, perch√© ha i numeri pi√π grandi, quindi non devo andare a ricalcolare la grandezza della tabella.\nUna altra cosa interessante per le tabelle √® che ci sono stiling come attributi (esempio di questo sono colspan, rowspan etc), ma dovrebbe essere di CSS, infatti questo era un modo per farlo prima di CSS.3.\nTipicamente utilizare le tabelle per fare layout √® una delle cose meno accessibili che esistono! Quindi non ha pi√π nessun senso utilizzare le tabelle di layout. (non utilizzarle, penalizza!).\nDOM Questa parte √® fatta meglio in Javascript\nDocument object model, l‚Äôobiettivo della WHATWG era costruire un parser che potesse aiutare a creare una struttura di dati utile per la creazione di applicazioni, quindi molto pi√π tollerante rispetto a quanto proposto dal W3C e specifiche pi√π rigide come XHTML.\nDocument Object Model, una struttura di dati con alcune funzioni e strutture built in che permettono la facile manipolazione fornisce API. Dovrebbe essere facile creare un DOM da codice HTML cos√¨ come il constrario. √à esattamente quello che si vede sullo schermo!\n‚Äúl‚Äôimportante √® arrivare ad una struttura dati in memoria unica su cui costruire applicazioni\nDato che deve funzionare per HTML secondo la filosofia pi√π estesa del WHATWG, √® praticamente la struttura del XHTML ampliata per includere altro, questo permette al codice JS di intervenire direttamente sul DOM.\nStruttura del DOM üü© Slide struttura del dom\nCi sono alcune classi fondamentali per poter comprendere il DOM\nDocumento Nodo del DOM Nodo di testo Nodo di elemento Nodo di attributo Poi ci sono molte altre classi, come commendi, Datasection e molti altri che di solito si vedono poco, quelli pi√π importanti sono il Document e i nodi descritti sopra Alcune classi del dom üü©‚Äî Slide DOMNode\nSlide DOMDocument e Selettori\nSolitamente √® complicato lavorare col DOM vanilla, tanto che l\u0026rsquo;hanno chiamato sadico chi ne √® stato detrattore.\nSlide DOMElement\nInner e OuterHTML üü© Andare a modificare l‚ÄôHTML √® molto verboso, utilizzando questi metodi √® pi√π veloce andare a creare nuovi elementi.\nL‚Äôunica differenza fra i due √® che Outer include anche il contenitore nella modifica, inner √® solo per il contenuto\nSlide Inner e OuterHTML\nAltre note Whitespaces in HTML üü© Whitespace √® ignorato (soprattutto in elementi strutturali come i table) Whitespace √® collassato in un unico whitespace in pre\u0026gt; il whitespace √® mantenuto. ","permalink":"https://flecart.github.io/notes/html/","summary":"\u003ch2 id=\"un-p√≤-di-storia\"\u003eUn p√≤ di storia\u003c/h2\u003e\n\u003cp\u003e√à importante capire un p√≤ di storia per vedere che strano robo abbiamo oggi.\nDue linee di sviluppo, uno √® uno standard di W3C, l\u0026rsquo;altro √® il living standard. √à di fortissimo cambiamento, quindi di difficile definizione! (cambia significato sia di semantica e che di sintassi).\u003c/p\u003e\n\u003cp\u003eNel 1997 abbiamo HTML4 che √® stata considerata la versione finale, per cui un sacchissimo di siti web fino al 2008 sono stati implementato con questo HTML\u003c/p\u003e","title":"HTML"},{"content":"HTTP is the acronym for HyperText Transfer Protocol.\nCaratteristiche principali (3) Comunicazioni fra client e server, e quanto sono comunicate le cose si chiude la connessione e ci sono politiche di caching molto bone (tipo con i proxy) Generico: perch√© √® un protocollo utilizzato per caricare moltissime tipologie di risorse! Stateless, ossia non vengono mantenute informazioni su scambi vecchi, in un certo modo ne abbiamo parlato in Sicurezza delle reti quando abbiamo parlato di firewall stateless. Solitamente possiamo intendere questo protocollo come utile per scambiare risorse di cui abbiamo parlato in Uniform Resource Identifier.\nLa connessione üü©- √à importante oggi rendere efficienti le connessioni, al tempo come descritto in Livello applicazione e socket per HTTP, per richiedere ogni risorsa si apriva e si chiudeva una connessione (uno dopo l‚Äôaltro, senza parallelizzazione).\ncon HTTP2 gi√† questa cosa era cambiato, possiamo richiedere allo stesso tempo pi√π connessioni, √® la pipeline. Importante notare che la differenza col multiplexing √® che nel pipelining ti risponde con l‚Äôordine\nMultiplexing invece utilizza la stessa connessione per chiedere e rispondere pi√π volte (oggi anche pi√π comune). La differenza principale √® elaborare in ordine diverso rispetto a quanto abbia ricevuto.\nSlide esempio tipologie di richiesta\nCi sono anche altri modi per rendere ancora pi√π veloce il protocollo, un esempio √® l‚Äôoperazione PUSH, per esempio quando fai la pagina HTML, il server sai gi√† che il client vai a richiedere altre risorse di quella pagina, quindi inizia subito a processare le richieste, prima che il client abbia effettivamente chiesto.\nUn altro modo per rendere pi√π veloce la trasmissione √® la compressione degli header per tutte le richieste e fatte anche in parallelo.\nRichiesta HTTP (5) üü© Vogliamo ora andare a parlare della struttura di un pacchetto HTTP affinch√© si possa considerare valido. Ci sono 5 campi principali:\nVersione del RFC per HTTP Metodo, tipo PUT, GET etc, ne parliamo sotto. URI, descritto in Uniform Resource Identifier. Header, che si articolano in molti sotto headers (ci sono molti headers) Body della richiesta Slide richiesta HTTP\nRisposta HTTP (4) üü© La risposta del server va di 4 campi (cio√® √® quello che ti ritorna dopo aver elaborato la tua richiesta)\nStatus code Version HTTP Headers (nota headers sono credo praticamente le stesse della richiesta) Body (in cui effettivamente ci sono le informazioni della risposta) Slide risposta HTTP\nEsempio di risposta HTTP\nStatus codes üü©\u0026ndash; Ci sono 5 campi principali che vanno a descrivere a grandi linee il significato della risposta (in un certo senso √® come nella richiesta vado a specificare l‚Äôazione, gli status codes ti rispondono con informazioni precise riguardanti la tua richeista).\nSlides sugli status codes\nEsempi di status codes\nTra questi aggiungerei anche il 204 no content.\n√à importante andare a utilizzare status codes corretti, per ragioni molto simili a un verbo HTTP corretto, perch√© questo aiuta tutti i servizi capire bene l‚Äôesito della nostra richiesta, aiuta i meccanismi di caching a capire se cachare o meno.\nHeaders üü® Ci sono 4 tipologie principali di headers HTTP, andremo a descriverli ora.\nHeaders generali Slide generali\nSi mandano informazioni come cache, la codifica, la data, il tipo di connessione (se deve restare su o meno).\nHeaders di entit√† Slides entit√†\nSono utili per andare ad interpretare le tipologie di content all‚Äôinterno del body. In parte questa parte √® condivisa anche negli headers per il MIME Headers del MIME (2)üü®.\nInfatti in risposta con una risorsa le content-type e lenght son oobbligatori per specificare informazioni sulla risorsa ritornata.\nHeaders di richiesta Slides richiesta\nSono utili per dare informazioni sul client al server.\nEsempi sono l‚Äôhost, l‚Äôuser-agent che sta facendo la richiesta. Per esempio a seconda dello user agent ho dei CSS leggermente differenti!\nHeaders di risposta Slides risposta\nMetodi HTTP (!) I metodi HTTP sono presenti all‚Äôinterno del campo metodo di un pacchetto HTTP, sono anche chiamati verbi HTTP perch√© vanno a descrivere cosa bisogna andare a fare sulla risorsa identificata dall‚ÄôURI.\nSlide esempio di get e POST\nIn teoria tutto pu√≤ essere fatto con GEt, ma se utilizzo bene le API avere status codes corretti rende molto pi√π chiaro ed uniforme l‚Äôinterazione con essa, quindi molto pi√π interoperabile.\nSicurezza e idempotenza üü© Sicurezza e idempotenza due propriet√† che i metodi HTTP possono avere. Vorremmo che HTTP sia stateless, quindi vorremmo che non generi cambiamenti dello stato oltre che avere dei logs.\nUna richiesta √® idempotente quando richieste identiche hanno stesso risultato.\nSicuro quando non viene alterato lo stato del server dopo la richiesta.\nE poi ce ne sarebbero altre, ma solitamente si utilizzano Get post put e delete perch√© sono quelle pi√π consone per il modello CRUD per rest.\nGET HEAD POST For professor Ghislain just use post when you don\u0026rsquo;t know what to use. This is the worst because it has side-effects, it\u0026rsquo;s not idempotent as the other operations.\nSlide POST 0\nPUT Slide PUT 2\nDELETE A get should return a 404 after a delete.\nSlide DELETE 2\nPATCH la differenza principale con PUT √® che patch √® per cambiare parzialmente una risorsa e non sostituirla completamente.\nOPTIONS REST REpresentational State Transfer √® una metodologia di costruzione di API, avevamo gi√† fatto qualcosa cone tipo protobuf. √à un modello architetturale, ossia modo per creare applicazioni che sfruttano HTTP che possano essere utilizzati da altre applicazioni il modo pi√π chiaro possibile.\nConnesse sull‚Äôambiente di utilizzo (quindi cose come collezioni, singolo elemento della collezione e simili). Si pu√≤ vedere come un metodo indipendente dal linguaggio utilizzata per comunicare fra un servizio o un altro. Molto importante identificare Uniform Resource Identifier della risorsa che vogliamo andare ad accedere.\nModello CRUD (!) (4) üü© Quando ho una collezione di dati vogliamo descrivere le operazioni principali che posso fare su essa:\nCreazione di elemento singolo o di un gruppo Lettura di un individuo o di un gruppo Aggiornamento di dati gi√† esistenti Eliminazione di dati Slide su CRUD\nImportante notare che questo pattern √® indipendente da REst, di solito utilizzato per Database, ma possiamo utilizzare lo stesso mecanismo con Rest e le operazioni di HTTP\nOssia URI come identificatore e Richieste HTTP per andare a modificarle.\nUtilizzo CRUD per Metodi HTTP\nEsempio Verbi HTTP con rest\nIn breve REST utilizza URI per identificare la risorsa, e semantica HTTP per andare a richiederla e stabilire la connessione di trasferimento.\nMetodologie URI REST üü®+ Ci sono delle specifiche metodologie per dare senso a un uri che possa essere rest, l\u0026rsquo;idea principale √® la distinzione fra collezione vs individuo, che implica anche un utilizzo di metodo HTTP diverso. Per distinguere collezioni da individui dobbiamo mettere il plurale e terminare con lo slash (che direi anche sia una cosa molto strana!)\nQueste entit√† cos√¨ definite possono essere anche gerarchiche, quindi uno impilato sull\u0026rsquo;altro, ma sembra tenere a mente la semplicit√† dell\u0026rsquo;interfaccia e della navigazione.\nOpen API Questa parte √® molto p√¨u pratica, andiamo direttamente ad impararla da l√¨!\nOpen api √® una sintassi di solito scritta in YAML presentato molto velocemente in Markup nella sezione di markup, permette di specificare in modo molto chiarlo l\u0026rsquo;interfaccia di un API, e la creazione della documentazione associata.\nDi solito questo √® il modello preferito (industry standard) per creare queste cose, rende molto chiara la comunicazione delle api diciamo, per il progetto potrebbe essere un buon metodo per interagire col database? Oppure meglio farci richiesta diretta con un ORM. Credo sia molto simile.\n","permalink":"https://flecart.github.io/notes/http-e-rest/","summary":"\u003cp\u003eHTTP is the acronym for HyperText Transfer Protocol.\u003c/p\u003e\n\u003ch3 id=\"caratteristiche-principali-3\"\u003eCaratteristiche principali (3)\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/HTTP e REST/Untitled.png\" alt=\"image/universita/ex-notion/HTTP e REST/Untitled\"\u003e\n\u003col\u003e\n\u003cli\u003eComunicazioni fra client e server, e quanto sono comunicate le cose si chiude la connessione e ci sono politiche di caching molto bone (tipo con i proxy)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGenerico\u003c/strong\u003e: perch√© √® un protocollo utilizzato per caricare moltissime tipologie di risorse!\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStateless\u003c/strong\u003e, ossia non vengono mantenute informazioni su scambi vecchi, in un certo modo ne abbiamo parlato in \u003ca href=\"/notes/sicurezza-delle-reti/\"\u003eSicurezza delle reti\u003c/a\u003e quando abbiamo parlato di firewall stateless.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eSolitamente possiamo intendere questo protocollo come utile per \u003cstrong\u003escambiare risorse\u003c/strong\u003e di cui abbiamo parlato in \u003ca href=\"/notes/uniform-resource-identifier/\"\u003eUniform Resource Identifier\u003c/a\u003e.\u003c/p\u003e","title":"HTTP e REST"},{"content":"Indexes Trattiamo qui di alcuni metodi che sono utilizzati per costruire indici\nIntroduction to indexes Gli indici sono una struttura di dati aggiuntiva che ci permette di ricercare pi√π in fretta alcuni valori per le queries. In questa sezione proviamo ad approfondire in che modo possono essere costruite e gestite.\nSearch keys üü© Sono in breve la cosa che vogliamo andare a cercare. Solitamente sono nella forma \u0026lt;key, label\u0026gt;, che ci permette di trovare in fretta il label, che si potrebbe intendere come il valore che noi stiamo provando a cercare.\nLabels and record identifiers (3) üü© Primary vs secondary indexes √à primary se gli attributi che vengono guardati contengono la chiave primaria della relazione Altrimenti √® secondary Dense vs sparse indexes üü© Dense se per ogni chiave del file esiste una chiave di ricerca. Altrimenti √® sparsa. Chiaramente per index sparsi abbiamo bisogno di meno spazio per storarli in memoria!\nClustered vs unclustered indexes üü©\u0026ndash; Clustered se viene utilizzato l\u0026rsquo;ordine dei labels (eh, non ho capito questo criterio credo.)\nChiaramente se √® unclustered non abbiamo pi√π i vantaggi della cache, e quindi √® pi√π lento accedere!\nSequential Index example In pratica dividiamo il file in molti pezzi contigui, e proviamo ad indexarli in modo contiguo, come in figura: Questo metodo √® denso e clustered per fare indexing, mentre per il fatto che sia primario o meno dipende!?\nB-trees La differenza fra B-trees e B+-trees √® che il primo pu√≤ tenere valori anche nei nodi intermedi, mentre il secondo tiene valori solamente nelle foglie.\nAbbiamo circa 40ms per l\u0026rsquo;accesso al blocco, solitamente di tipo 4k bytes. La osservazione principale √® che gli algoritmi non lavorano pi√π in RAM, che √® facile accedere subito (nanosecondi ad accedere), quindi √® pi√π facile fare algoritmi che tengano in conto questa cosa.. La base di dati ha bisogno di indici, perch√© in questo modo utilizzo permette il miglior accesso\nun index √® interamente di grandezza del blocco. Dipendente da chiavi valori. Un indice un singolo blocco diciamo (quindi abbiamo centinaia di archi) (il costo √® $\\log_{n}(N)$) con $n$ il branching factor. Con pochi livelli, posso accedere a molte cose! (quindi faccio pochi seek per raggiungere i valori). B-trees Nodi interi e nodi foglia Abbiamo che √® un albero con pi√π rami, solitamente largo per non necessitare di pi√π letture per andare a leggere (ricorda che ram √® circa un milione di volte pi√π veloce!). Praticamente\nInsertion and deletion Quando ho trovato il nodo in cui inserire, e trovando che il nodo √® pieno, dovrei provare a spezzare, e creare un nuovo nodo genitore e c\u0026rsquo;√® lo stesso il processo ricorsivo anche sul genitore, se non c\u0026rsquo;√® spazio continuo a dividere (anche la radice si pu√≤ splittare). Vedi slide 30 Lab06 Per la deletion la slide √® 39.\nC\u0026rsquo;√® un fattore di riempimento che si dovrebbe andare a considerare, per capire se posso fondere pi√π nodi assieme, in modo che non debbano prendere troppo spazio.\nCome in immagine:\nL\u0026rsquo;algoritmo √® molto chiaro se visto con le immagini e gli steps, poi in questa occasione non ci interessa analizzarlo.\nNotare: questa √® una implementazione un po\u0026rsquo; meno efficiente perch√© i valori effettivi possono essere presenti solamente sulle foglie, sarebbe pi√π efficiente se si vede che in un nodo intermedio il valore esiste allora esister√† anche sulle foglie per cui si pu√≤ gi√† restituire il risultato. Questo applicativo ha una versione pi√π efficiente: https://www.cs.usfca.edu/~galles/visualization/BTree.html.\nHashes Gli hash sono utili per la ricerca di chiavi uguali tipo per indici oppure per database piccoli (credo) che non hanno bisogno di b-trees.\nStatic Hash üü© Per questa tipologia di hash allochiamo uno spazio fisso non estensibile. Data una certa chiave di ricerca, andiamo a prendere il bucket con quel valore. Se √® gi√† pieno si possono usare linked list o alberi per memorizzare il valore.\nAnche in questo caso, come per i B-trees, si invita a guardare le slides, oppure disegnare per una comprensione migliore dell\u0026rsquo;argomento.\nExtensive hash üü®+ Elementi di rilievo:\nOgni singolo blocco ha un contatore che indica il numero di bits utilizzati per indexarlo. Abbiamo un blocco intermedio di puntatori che vanno sui singolo blocchi di dati, contiene anche un dato che indica numero di bits per indexare il singolo bucket. L\u0026rsquo;algoritmo di insertion √® un po\u0026rsquo; pi√π complicato, e differenzia caso in cui il numero di bit per indexare il blocco sia uguale o minore rispetto a quello per i bucket. Anche in questo caso dovresti descrivere l\u0026rsquo;esecuzione dell\u0026rsquo;algoritmo con immagini, aiuta molto.\nL\u0026rsquo;unica cosa negativa √® il fatto di crescere in modo esponenziale per lo spazio nelle directories in casi proprio avversariali (o comunque molto difficili con una distribuzione normale diciamo).\nLinear Hash In questo caso cresce un blocco alla volta, finch√© un certo threshold di record/numbero di buckets viene soddisfatto si resta, altrimenti prova a crescere. Anche in questo caso come static hash, usiamo gli overflow blocks.\nInverted indexes introduzione sul funzionamento Per gestire cose come testo a volte pu√≤ risultare utile fare questo genere di index per trovarlo. In pratica, supponiamo di avere n indici, allora possiamo fare una tabella nella forma\nParola -\u0026gt; Doc(posizione) In pratica, se ho un match per ogni singola parola con il documento e la posizione all\u0026rsquo;interno del documento che la parola ha, in questo modo posso fare ricerca veloce nelle posizioni in cui la parola compare.\nQuando cerco una stringa esatta posso prendere l\u0026rsquo;intersezione fra i documenti in cui compaiono e restituire solamente quelle\nLinguistic preprocessing Sono metodi per diminuire la variet√† delle parole in modo che io abbia bisogno di meno spazio poi per memorizzare l\u0026rsquo;inverted index. Posso fare cose come\nStemming: in cui rimuovo lo stemdella parole, quindi suffissi o prefissi ricorrenti Normalization: ad esempio metto tutto minuscolo. Rimozione stop worlds: perch√© sono inutili ch√© non danno molte informazioni\n","permalink":"https://flecart.github.io/notes/index-b-trees-and-hashes/","summary":"\u003ch2 id=\"indexes\"\u003eIndexes\u003c/h2\u003e\n\u003cp\u003eTrattiamo qui di alcuni metodi che sono utilizzati per costruire indici\u003c/p\u003e\n\u003ch3 id=\"introduction-to-indexes\"\u003eIntroduction to indexes\u003c/h3\u003e\n\u003cp\u003eGli indici sono una struttura di dati aggiuntiva che ci permette di ricercare pi√π in fretta alcuni valori per le queries. In questa sezione proviamo ad approfondire in che modo possono essere costruite e gestite.\u003c/p\u003e\n\u003ch4 id=\"search-keys-\"\u003eSearch keys üü©\u003c/h4\u003e\n\u003cp\u003eSono in breve la cosa che vogliamo andare a cercare. Solitamente sono nella forma\n\u003cstrong\u003e\u0026lt;key, label\u0026gt;\u003c/strong\u003e, che ci permette di trovare in fretta il label, che si potrebbe intendere come il valore che noi stiamo provando a cercare.\u003c/p\u003e","title":"Index, B-trees and hashes"},{"content":"This set of notes tries to fix what I haven\u0026rsquo;t learned in 2021 course in algebra. It\u0026rsquo;s about inner product spaces. A good online reference on the topic is wilkinson.\nDefinitions Inner product space We define the vector space $V$ to be a inner product space, if we define a inner product operator ($\\langle \\cdot, \\cdot \\rangle : V \\times V \\to R$) such that the following are valid:\nIt is linear on both arguments: $$ \\langle \\alpha x_{1} + \\beta x_{2}, y \\rangle = \\alpha \\langle x_{1}, y \\rangle + \\beta \\langle x_{2}, y \\rangle $$ It is a symmetric operator: $\\langle x, y \\rangle = \\langle y, x \\rangle$ It is positive definite that is we have $\\forall x \\in V: \\langle x, x \\rangle \\geq 0$ with equality only if $x = \\boldsymbol{0}$ An example of such operator is the classical cosine distance which is just the angle, or euclidean distance. Also all $p-\\text{norms}$ are inner products.\nOrthogonal matrixes and vectors We define two vectors $u, v$ to be orthogonal if $\\lVert u \\rVert = \\lVert v \\rVert = 1$ and if $\\langle u, v \\rangle = 0$ with respect to some inner product (clearly if we use euclidean distance, this is not much interesting, but it is for the angle).\n$$ QQ^{T} = Q^{T}Q = \\boldsymbol{1}_{n} $$ Where bold 1 is the unit vector. By this definition and the uniqueness of the inverse we conclude that it is orthonormal if and only if $Q^{T} = Q^{-1}$. We observe that $q_{i}^{T}q_{j} = \\delta_{ij}$ (see Kronecker Delta).\nOnly square matrices can have inverse $$ tr(\\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 \\dots \u0026 a_{1n} \\\\ \\dots \\\\ a_{n 1} \u0026 \\dots \u0026 \\dots \u0026 a_{n n} \\end{bmatrix}) = \\sum_{i = 1}^{n} a_{ii} $$ This is easy to prove, so we left it to the reader (Hint: just expand the product).\nWith this in mind we can prove that if $Q$ is a $n \\times p$ matrix, it does not have an inverse by looking at its trace.\nProjections $$ P^{2} = P $$ Now let\u0026rsquo;s study its Image and Kernel. Let\u0026rsquo;s define $U = \\text{Im}(P)$ and $V = \\text{ Ker}(P)$, and say $P: W \\to W$.\nAt the end, I don\u0026rsquo;t think this is definition is so useful because I usually don\u0026rsquo;t want the kind of applications from $n \\times n$ usually it\u0026rsquo;s more a dimensionality reduction, useful for Principal Component Analysis.\nProperties of projections Every vector of the projection can be written as sum of kernel and image $$ w = Iw = (I - P)w + Pw $$ Which is a vector in kernel and one in the image. This is a general property of the projections, it seems.\n$(I - P)$ is a projection matrix $$ (I - P)^{2} = (I-P)^{T}(I-P) = (I-P) - (P- P^{2}) = I - P $$ Another way is just observing that this projection is very similar to $P$ because they just switch the image and the kernel. $\\text{Im}(I - P) = V = \\text{Ker}(P)$ and $\\text{Ker}(I - P) = U = \\text{Im}(P)$\nOrthogonal Subspaces $$ U^{\\perp} = \\left\\{ w \\in W \\mid \\langle w, u \\rangle = 0, \\forall u \\in U \\right\\} $$ This is important especially for the following theorem\nOrthogonal subspace decomposition $$ \\text{dim}(U) + \\text{ dim}(U^{\\perp}) = \\text{dim}(W) = n $$ Which is very similar to the kernel and image decomposition in Applicazioni lineari. (And you also have the motivation up there). This is trivial to prove when you know how to build the linear application from $W \\text{ to } U$. Let\u0026rsquo;s build it in this way: Consider $B = \\left\\{ v_{1}, \\dots, v_{n} \\right\\}$ to be the basis for $W$, then build $A$ with every row, the coordinates of the vector in $U$. When we have that $U^{\\perp} = \\left\\{ x =(x_{1}, \\dots, x_{n} \\mid Ax = 0) \\right\\}$ which is just the Kernel of the application, using the dimensionality theorem we finish.\nOrthogonal projections Def: Projection $$ \\text{ minimizes the value } \\lVert w - u \\rVert $$ Which means we want to approximate the value of that vector well. We observe that the perpendicular vectors in this space is exactly the kernel of a possible projection! We have proven before that every vector is just a simple, not weighted sum of kernel and image. i.e. if $P$ is the projection matrix, with Kernel and Image defined as above, we can write every $w \\in W$ as a sum $u + v$ such that one is from the kernel and the other is from the image. We also notice that\nThe projection matrix $$ P_{u} = A(A^{T}A)^{-1}A^{T} $$ With $A$ the matrix with the coordinates in $W$ of the basis of $U$ on each column. The proof is not so difficult. But it has close connections with the MSE error and least squares estimation explained in Minimi quadrati and Linear Regression methods.\n","permalink":"https://flecart.github.io/notes/inner-product-spaces/","summary":"\u003cp\u003eThis set of notes tries to fix what I haven\u0026rsquo;t learned in 2021 course in algebra. It\u0026rsquo;s about inner product spaces.\nA good online reference on the topic is \u003ca href=\"https://rich-d-wilkinson.github.io/MATH3030/2.3-linalg-innerprod.html\"\u003ewilkinson\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"definitions\"\u003eDefinitions\u003c/h2\u003e\n\u003ch3 id=\"inner-product-space\"\u003eInner product space\u003c/h3\u003e\n\u003cp\u003eWe define the \u003ca href=\"/notes/spazi-vettoriali/\"\u003evector space\u003c/a\u003e $V$ to be a inner product space, if we define a inner product operator ($\\langle \\cdot, \\cdot \\rangle : V \\times V \\to R$) such that the following are valid:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eIt is linear on both arguments:\n$$\n\\langle \\alpha x_{1} + \\beta x_{2}, y \\rangle = \\alpha \\langle x_{1}, y \\rangle  + \\beta \\langle x_{2}, y \\rangle \n$$\u003c/li\u003e\n\u003cli\u003eIt is a \u003cstrong\u003esymmetric operator\u003c/strong\u003e: $\\langle x, y \\rangle = \\langle y, x \\rangle$\u003c/li\u003e\n\u003cli\u003eIt is \u003cstrong\u003epositive definite\u003c/strong\u003e that is we have $\\forall x \\in V: \\langle x, x \\rangle \\geq 0$ with equality only if $x = \\boldsymbol{0}$\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAn example of such operator is the classical \u003cstrong\u003ecosine distance\u003c/strong\u003e which is just the angle, or \u003cstrong\u003eeuclidean distance\u003c/strong\u003e. Also all $p-\\text{norms}$ are inner products.\u003c/p\u003e","title":"Inner product spaces"},{"content":" üí° Questa prima parte degli appunti √® fortemente mancante 1.1 Insiemistica Tutta Questa prima roba di insiemistica √® fatta molto meglio nel corso di logica, in particolare in questo documento\nTeoria assiomatica degli insiemi\n1.1.1 Definizione e caratteristiche degli insiemi Definizione di Campo ordinato (operazioni fra certi insiemi, sia per la addizione, per la moltiplicazione e simili) Corpo commutativo\nSono definiti somma e moltiplicazione e propriet√† come commutativit√†, associativit√†, distributiva, inversi, opposti, zero e nullo\nCampo ordinato\nIn un campo ordinato valgono le due propriet√†\n$$ x \u003c y \\implies x + z \u003c y + z \\newline z\\geq 0,x \u003c y \\implies x z \u003c yz $$1.1.2 Simboli per l\u0026rsquo;insiemistica Per ogni, esiste, and, or, tale che, implicazione, e operazione fra insiemi.\n1.1.3 Operazioni fra gli insiemi Addizione, sottrazione sottoinsiemi, complementari, unione intersezione\n1.1.4 Equipotenza Definizione di equipotenza:\nesiste una funzione bigettiva da un insieme a un altro.\n1.1.5 Numerabilit√† di Q e Z Dimostrazione equipotenza di N, Q, Z.\n1.2 Binomiali In seguito si utilizzeranno per calcolare i coefficienti dei monomi a seguito di una espansione.\nLa definizione di binomiale √® fatta per parti (definita per ora solamente da $N^2 \\rightarrow N$)\n1.2.1 Formula somma di combinazione $\\binom{n-1}{k} + \\binom{n-1}{k-1} =\\binom{n}{k}$\nSi fanno i calcoli e si dimostra.\nDimostrazione lasciata al lettore. Coglione angi, aveva fatto una dimostrazione carina, ora 25/12/22 la sto ricercando le non la trovo. vacca troia‚Ä¶\nComunque ora ho ritrovato dalle slides\nDimo ritrovata\nvai a considerare n, e un elemento a caso. Si tratta di prendere k elementi da n.\nAllora questo possiamo scomporlo in due casi, nel caso in cui prendo l\u0026rsquo;elemento a caso e nel caso in cui non lo prendo. Se lo prendo allora vado a cercare k - 1 nel resto, se non lo prendo allora nel resto vado a cercare k. ez.\nQuesta osservazione mi √® ritornata utile perch√© lo studio dei dearrangiamenti fa un ragionamento praticamente uguale, stessa idea, applicata in ambito diverso\n1.2.2 Permutazioni e Combinazioni Li sai dai.\n1.2.3 Binomio per l\u0026rsquo;espansione binomiale se ho una scrittura di questo genere:\n$$ (a + b) ^n $$So che il grado del polinomio che si forma √® n, e che per ogni monomio, la somma dei suoi pr\n1.3 Alcune dimostrazioni 1.3.1 Teorema di Pitagora Dimostrazione grafica ‚Üí V Postulato di Euclide\nDimostrazione lasciata al lettore\n1.3.2 Radici di primi in Q Stesso argomento di radice di 2\nDimostrazione lasciata al lettore\n1.3.3 Infinit√† dei numeri primi Argomento di Euclide\nDimostrazione lasciata al lettore mi in Q\nStesso argomento di radice di 2\nDimostrazione lasciata al lettore\n1.3.3 Infinit√† dei numeri primi Argomento di Euclide\nDimostrazione lasciata al lettore\n","permalink":"https://flecart.github.io/notes/insiemi-numerici/","summary":"\u003caside\u003e\nüí° Questa prima parte degli appunti √® fortemente mancante\n\u003c/aside\u003e\n\u003ch2 id=\"11-insiemistica\"\u003e1.1 Insiemistica\u003c/h2\u003e\n\u003cp\u003eTutta Questa prima roba di insiemistica √® fatta molto meglio nel corso di logica, in particolare in questo documento\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"/notes/teoria-assiomatica-degli-insiemi/\"\u003eTeoria assiomatica degli insiemi\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"111-definizione-e-caratteristiche-degli-insiemi\"\u003e1.1.1 Definizione e caratteristiche degli insiemi\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eDefinizione di Campo ordinato (operazioni fra certi insiemi, sia per la addizione, per la moltiplicazione e simili)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eCorpo commutativo\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eSono definiti somma e moltiplicazione e propriet√† come commutativit√†, associativit√†, distributiva, inversi, opposti, zero e nullo\u003c/p\u003e","title":"Insiemi numerici"},{"content":"8.1 Introduzione 8.1.1 Il problema che risolve Vogliamo cercare di creare un metodo matematico che sia utile per calcolare area di qualunque curva.\nL\u0026rsquo;idea principale per risolvere questo problema √® approssimare l\u0026rsquo;area, lo facciamo utilizzando rettangoli, la formalizzazione sar√† molto aiutata dal limite.\n8.1.2 Sottografico di funzione $$ A = \\{ (x,y) \\in \\mathbb{R}^2 | x \\in D(f(x)), 0\\leq y \\leq f(x)\\} $$Praticamente sto prendendo tutti in punti positivi sotto al grafico.\n8.2 Somma di Riemann La somma di riemann sta alla base della definizione di integrale.\n8.2.1 Intuizione a rettangoli Vorremmo cercare di approssimare l\u0026rsquo;area del grafico utilizzando un sacco di rettangoli di stessa ampiezza\n8.2.2 Definizione (formula) Diviso l\u0026rsquo;intervallo di interesse, che chiamiamo $[a,b]$ con n intervalli di stessa lunghezza, e presa in questi $\\xi_k$ n punti a caso per ogni intervallo, allora consideriamo la somma di Riemann:\n$$ h = \\dfrac{b- a}{n},\\\\ S = \\sum_{i=1}^nf(\\xi_i) \\cdot h $$8.3 Integrale di Riemann 8.3.1 Criterio di integrabilit√† secondo Riemann Se una funzione √® continua su un certo intervallo, allora √® integrabile secondo Riemann qui\nDimostrazione (Non richiesta) Servono teoremi che non hai mai fatto tipo heine borel etc. 8.3.2 Osservazioni su questo integrale $\\int_a^af(x) = 0$ perch√© si pu√≤ notare che l\u0026rsquo;ampiezza del rettangolo √® 0, quindi sto sommando uno 0. Nel caso di funzione costante\u0026hellip;. bah non lo scrivo nemmeno perch√© se ragioni sulla somma di Riemann √® abbastanza banale. 8.3.3 Propriet√† dell‚Äôintegrale Linearit√† (se ho f, g continue sullo stesso intervallo, allora l\u0026rsquo;integrale della funzione somma √® uguale alla somma degli integrali singoli). (posso anche moltiplicare per un fattore e considerare la funzione fattore * f, o fattore * g).\nAdditivit√†, posso dividere l\u0026rsquo;intervallo su cui sto integrando come la somma di due intervalli che coprono tutto l\u0026rsquo;intervallo iniziale\nConvenzione: se b\u0026lt;a e ho un integrale tipo cos√¨ $\\int^b_a = -\\int^a_b$, ovvero cambio il segno. Questa convenzione mi permette di scriverlo per ogni punto (basta che sia continuo).\nMonotonia, (se ho due funzioni definite in un intervallo in cui entrambe sono continue tali che f \u0026lt; g, allora anche l\u0026rsquo;integrale possiede questa disuguaglianza).\n8.3.4 Teorema della media integrale In modo simile alla media finita, in cui andiamo a dividere il numero di addendi per il valore della somma totale, possiamo andare a definire una media anche per gli integrali.\nPartiamo dalla somma di Riemann, per poi andare dalla media integrale:\n$$ \\text{INTUIZIONE: }S_n = \\sum^n_{k=1} f(\\xi_k)\\dfrac{b-a}{n} \\implies \\dfrac{S_n}{b-a} = \\dfrac{\\sum^n_{k=1}f(\\xi_k)}{n} $$$$ f:[a,b] \\to \\mathbb{R} \\text{ continua }\\\\ \\exists c \\in [a,b] \\, t.c. \\,\\\\ \\dfrac{1}{b-a} \\int_a^bf(x)dx = f(c) $$ Dimostrazione: Si utilizza il teorema del valore intermedio (vedi Limiti): qui in passato $\\exists x_0, x_1 \\in [a,b]$, questi sono scelti in modo tale per cui $f(x_0) = min, f(x_1) = max$ che √® effettivamente ci√≤ che dice weierstrass per l\u0026rsquo;estremo valore, poi utilizziamo la definizione di funzione per diree che esitono anche tali x0 e x1, per ricordarci delle loro propriet√† li chiamiamo m e M sotto. $$ \\begin{align} \\exists m, M \\in [a,b]\\text{ che diano massimo e minimo per weierstrass, ovvero che:} \\ f(m) \\leq f(x) \\leq f(M) , \\forall x \\in [a,b] \\text{ utilizziamo la monotonia dlel\u0026rsquo;integrale} \\ \\int_a^b f(m)dx \\leq \\int_a^b f(x)dx \\leq \\int_a^b f(M)dx ,\\\\text{ noto che alcuni sono costanti, allora} \\ f(m)(b-a) \\leq \\int_a^b f(x)dx \\leq f(M)(b-a) \\implies f(m) \\leq \\dfrac{1}{b-a} \\int_a^b f(x)dx \\leq f(M) \\end{align} $$\nArrivati all'ultimo passo allora possiamo dire che esiste un tale c, grazie al teorema del valore intermedio. Mini riassunto del valore intermedio (che serve qui)\nUna funzione continua su un intervallo per Weierstrass possiede un minimo e un massimo, grazie al teorema degli zeri possiamo costruirci una funzione tale per cui si annulli per qualunque punto all\u0026rsquo;interno di questo intervallo. Cio√® possiamo concludere che\n$\\forall y \\in [m,M], \\exists c \\in [a,b] | f(c) = y$\n8.4 Primitiva e f integrale 8.4.1 La primitiva Una primitiva F di una funzione f √® una funzione definita nello stesso intervallo tale per cui per tutti i valori si ha che F\u0026rsquo;(x) = f(x).\n8.4.2 Unicit√† della primitiva La funzione primitiva √® unica a meno di una costante, in un intervallo ben definito. Possiamo osservare che esistono infinite primitive aggiungendo costanti.\nMa si pu√≤ dire che questa funzione √® unica in quanto:\nDimostrazione\nSiano f e g primitive di una funzione a. Allora consideriamo la funzione h definita come f - g. √® chiaro che la sua derivata √® a - a, quindi 0, quindi la sua derivata √® sempre 0.\nPer una conseguenza del teorema di lagrange ho che h deve essere una constante. Per cui si ha la relazione f = g + C. e abbiamo trovato che le funzioni primitive sono tutte a meno di costante\nI capitoli sotto sono probabilmente utili per altre cose dopo\n8.4.3 La funzione integrale Sia f una funzione continua definita su un certo intervallo. sia c un punto in questo intervallo, allora posso avere una funzione I tale che\n$$ I_c(x) = \\int^x_cf(t)dt $$Ovvero sto prendendo tutta l\u0026rsquo;area da un punto a un punto di input di variabile per una certa funzione. chiamo c punto base.\n8.4.4 Osservazione sulla funzione integrale (fondamentale 1) Sia $f$ continua su $(a_0, b_0)$ sia $c \\in (a_0, b_0)$ allora $\\forall x \\in (a_0, b_0)$ ho che $I_c'(x) = f(x)$\nAccenno di dimostrazione mia\nvogliamo f(x) continua e definita in un intervallo.\nLa funzione integrale sar√† fondamentale poi per il calcolo integrale. Possiamo relazionarla strettamente con la funzione primitiva, in quanto se fosse una primitiva, sarebbe uguale a un integrale che ci piace. Proviamo a giustificare questa cosa, proviamo a prenderne la sua derivata:\n$$ \\dfrac{I_c(x) - I_c(x_0)}{x - x_0} = \\dfrac{\\int^x_cf(x)dx - \\int^{x_0}_c f(x)dx}{x - x_0} = \\dfrac{\\int_{x_0}^xf(x)dx}{x - x_0} $$E questa ultima cosa esiste, ed √® compresa fra il massimo e il minimo della funzione f(x) per il teorema della media integrale.\nNon siamo stati abbastanza formali per la dimostrazione di esistenza della derivata. Vogliamo dire che\n$$ \\lim_{x \\to x_0}\\dfrac{\\int_{x_0}^xf(x)dx}{x - x_0} = f(x) $$Andiamo a dividere la dimostrazione di questo limite in limite destro e limite sinistro.\nVogliamo creare una successione (perch√© l\u0026rsquo;equivalente √® una cosa reale, si pu√≤ dimostrare).\nPer media integrale diciamo che $\\exists c, x_0 \\leq c \\leq x : f(c) = \\dfrac{\\int_{x_0}^xf(x)dx}{x - x_0}$ , riusciamo quindi per ogni succesione xn che tende a x0 trovare una successione cn che tenda a x0 per carabinieri, quindi esiste questo limite ed √® uguale a f(x), si fa la stessa cosa con l\u0026rsquo;altro.\nDimostrazione nelle note del prof\n8.4.5 Tutte le funzioni integrali di f differiscono per una costante Una cosa molto simile alle funzioni primitive! basta svolgere i calcoli in modo simile alla funzione integrale con c diversi üôÇ e ottengo che la loro differenza √® sempre una costante! Questo mi fa pensare che potrebbe essere una primitiva! E infatti per 8.4.4 lo √®\n8.4.6 Teorema di Torricelli (fondamentale del calcolo integrale) Enunciato\nData una funzione f definita in un intervallo aperto in R continua, e una altra funzione primitiva della prima F, allora si ha\n$\\int^b_af(x)dx = F(b) - F(a)$\nDimostrazione mia\nSia c un numero reale a Caso, sia $I_c(x)$ la funzione integrale relativa a $f$, per dimostrazione precedente ho che $I_c(x)$ √® una primitiva di $f$, allora per l\u0026rsquo;unicit√† della primitiva a meno di costante ho che $I_c(b) - I_c(a) = F(b) - F(a)$ (tolto costanti e simili)\n8.4.7 Fondamentale del calcolo generalizzato Enunciato\nSia $f: I\\to\\R \\text{ continua}\\\\ h: \\R \\to I \\text{ derivabile}$, vogliamo calcolare l\u0026rsquo;integrale di sopra. e sia $A_c(x)$ la funzione integrale\nAllora vale che $D(A(h(x)) = D(\\int_c^{h(x)}f(t)dt) = f(h(x))h'(x)$\nVorrei dimostrare in questo teorema la possibilit√† di valutare l\u0026rsquo;integrale con una altra variabile.\nad esempio come calcolare\n$$ \\int_c^{g(x)}f(x)dx $$E vogliamo ricondurci a funzioni integrali normali.\nInnanzitutto proviamo a ricordare alcuni risultati passati (derivata di funzione composta e il fondamentale).\nRisultati passati utili ora\nSia I un intervallo di R, sia $I_c(x) = \\int _c^xf(t)dt$ per il teorema fondamentale ho che $I_c'(x) = f(x)$ in ogni punto.\nConsidero ora $H_c(x) = \\int_x^cf(x)dt$, questo, grazie alla convenzione sugli integrali √® uguale a $-I_c(x)$\nDimostrazione\nPrendiamo l\u0026rsquo;integrale\n$$ \\forall z \\in I, I_c(z) = \\int_c^zf(t)dt $$Allora se semplicemente sostituisco h(x) a z, allora sto facendo questo\n$I_c(h(x)) = \\int _c^{h(x)}f(t)dt$, che non √® altro che una funzione composta.\nProviamo allora a prenderne la derivata, che per il teorema fondamentale del calcolo integrale √® f(x). Quindi\n$$ f(x) = I_c'(x) \\text{ dal teorema fondamentale} \\\\ D(I_c(h(x)) = h'(x)I_c'(h(x)) \\text{ dalla derivata di f composta} \\\\ h'(x)I_c'(h(x)) = h'(x)f(h(x)) \\text{ sostituendo} $$ 8.4.8 Integrale generalizzato (Integrale funzioni con discontinuit√†) !! Possiamo andare a definire un intervallo di integrazione infinito, come $0, +\\infty$, basta definirlo con un limite.\nse esiste il limite (altrimenti non √® definito) e si definisce in modo analogo per il infinito negativo.\n$$ \\lim_{z\\to+\\infty} \\int^z_af(x)dx = \\int^{+\\infty}_a f(x)dx $$8.5 Calcolo di integrali 8.5.1 Tabella degli integrali Sono pigro per scrivere tutti\n8.5.2 Funzioni composte siano due funzioni componibili (quindi dominio codominio compatibili).\nLa primitiva di una funzione\n$$ g \\cdot f = \\int g'(f(x))f'(x) $$8.5.3 Integrazione per parti notiamo che\n$D(F(x)g(x)) = f(x)g(x) + F(x)g'(x)$\nSe prendiamo ora l\u0026rsquo;integrale da entrambe le parti e giriamo un p√≤ di cose riusciamo a trovare l\u0026rsquo;integrale che cerchiamo, in questo senso\n$$ \\int f(x)g(x) = F(x)g(x) - \\int F(x)g'(x) $$Questo √® dimostrabile grazie al teorema fondamentale, che dice qualcosa a riguardo la derivata di una primitiva √® la funzione integranda di un integrale.\nAlcune funzioni classiche che si fanno per parti\n$f(x) = xe^x$\n$f(x) = ln(x)$\n$x^n \\arctan(x)$\n8.5.4 Sostituzione (cambio di variabile) Un p√≤ di teoria:\nsia h una funzione doppiamente derivabile da I in J, e f una funzione continua da J a R, allora, dati alpha e beta in I, si ha questa relazione:\n$$ \\int_{h(\\alpha)}^{h(\\beta)}f(x)dx = \\int_\\alpha^\\beta f(h(t))h'(t)dt $$La dimostrazione si ha con il teorema fondamentale dell\u0026rsquo;integrale generalizzato, pi√π precisamenta guardare il toggle sotto.\ndimostrazione\nVogliamo dimostrare che una funzione integranda in\nSiano F, G due funzioni da I a R, voglio dimostrare che\n$F(z) = \\int_{h(\\alpha)}^{h(z)} f(x)dx, G(z) = \\int_\\alpha^z f(h(x))h'(x)dx$ queste due siano uguali\nCerco di dimostrare che abbiano la stessa derivata (per cui le funzioni originali distano al massimo di una costante) e che siano uguali in un punto (per cui sono uguali ovunque).\nL\u0026rsquo;ultima tesi si fa in modo immediato perch√© sto provando ad integrale in un unico punti, quindi sono entrambe 0.\n$G'(z) = f(h(z))h'(z)$ per la prima versione del teorema fondamentale del calcolo\n$F'(z) = f(h(z))h'(z)$ per la dimostrazione precedente in questo passo, quindi sono la stessa funzione.\nQuesto termina la dimostrazione\nesempio (sostituendo con t^2)\n$$ \\int e^{\\sqrt{x}}dx = 2e^{\\sqrt{x}}(\\sqrt{x} - 1) + c $$","permalink":"https://flecart.github.io/notes/integrali/","summary":"\u003ch2 id=\"81-introduzione\"\u003e8.1 Introduzione\u003c/h2\u003e\n\u003ch3 id=\"811-il-problema-che-risolve\"\u003e8.1.1 Il problema che risolve\u003c/h3\u003e\n\u003cp\u003eVogliamo cercare di creare un metodo matematico che sia utile per calcolare area di qualunque curva.\u003c/p\u003e\n\u003cp\u003eL\u0026rsquo;idea principale per risolvere questo problema √® approssimare l\u0026rsquo;area, lo facciamo utilizzando rettangoli, la formalizzazione sar√† molto aiutata dal limite.\u003c/p\u003e\n\u003ch3 id=\"812-sottografico-di-funzione\"\u003e8.1.2 Sottografico di funzione\u003c/h3\u003e\n$$\nA = \\{ (x,y) \\in \\mathbb{R}^2 | x \\in D(f(x)), 0\\leq y \\leq f(x)\\}\n$$\u003cp\u003ePraticamente sto prendendo tutti in punti positivi sotto al grafico.\u003c/p\u003e","title":"Integrali"},{"content":"Andremo ad analizzare integrali di funzioni continue su insiemi semplici (domini normali) .\nIntroduzione Y-semplice e regolarit√† √à un insieme semplice di punti, in pratica, se considero un intervallo limitato e due funzioni definite in questo intervallo tale che una √® sempre minore dell‚Äôaltra, l‚Äôinsieme y-semplice sono i punti compresi fra queste\nDefinizione del libro Intuizione integrale Definizione del prof. Dato un insieme semplice A e una funzione continua $f:A \\to R$ allora √® ben definito l‚Äôintegrale $$ \\int_Af(x, y) dxdy \\in R $$ Osservazione 1:\nSe integriamo la funzione costante 1 possiamo effettivamente trovare l‚Äôarea di integrazione.\nChe da un concetto di misura dell‚Äôinsieme di integrazione\nOsservazione 2:\nL‚Äôintegrale definisce una sorta di sottografico di una funzione, ma a pi√π dimensioni. (in questo caso con insieme di integrazione di dimensione 2 si ha il volume).\nCalcolo tramite riduzione Definizione del libro\nCerco di fare a fettine i punti, cos√¨ mi √® molto pi√π facile calcolare i punti.\nLavagna del prof. (caso y - semplice)\ncaso x -semplice\nSi pu√≤ utilizzare un calcolo in modo equivalente ma sta volta partendo prima dalla x, perch√© abbiamo definito l‚Äôintervallo in funzione della y\n","permalink":"https://flecart.github.io/notes/integrali-multi-dimensionali/","summary":"\u003cp\u003eAndremo ad analizzare integrali di funzioni continue su \u003cstrong\u003einsiemi semplici (domini normali\u003c/strong\u003e) .\u003c/p\u003e\n\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"y-semplice-e-regolarit√†\"\u003e\u003cstrong\u003eY-semplice e regolarit√†\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e√à un insieme semplice di punti, in pratica, se considero un intervallo limitato e due funzioni definite in questo intervallo tale che una √® sempre minore dell‚Äôaltra, l‚Äôinsieme y-semplice sono i punti compresi fra queste\u003c/p\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Integrali multi-dimensionali/Untitled.png\" alt=\"image/universita/ex-notion/Integrali multi-dimensionali/Untitled\"\u003e\n\u003cul\u003e\n\u003cli\u003eDefinizione del libro\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Integrali multi-dimensionali/Untitled 1.png\" alt=\"image/universita/ex-notion/Integrali multi-dimensionali/Untitled 1\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"intuizione-integrale\"\u003eIntuizione integrale\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eDefinizione del prof.\nDato un insieme semplice A e una funzione continua $f:A \\to R$ allora √® ben definito l‚Äôintegrale\n$$\n    \\int_Af(x, y) dxdy \\in R\n    $$\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eOsservazione 1:\u003c/strong\u003e\u003c/p\u003e","title":"Integrali multi-dimensionali"},{"content":"Most of times the pattern of proving and verifying it is like this $prove \\to verify$, that is: there is an entity that generates the solution, andPo then another that tries to verify it. But more expressive algorithms could be possible if there is interaction between the two entities, ones that try to prove it, and others try to verify it. From some point of view, this is similar from what AlphaGo does when searching, there is a part that guides the search, another that actually searches for it. Or the modern alpha geometry in modern times.\nDeterministic Interactive Theorem-provers Def: deterministic interactive theorem provers $$ a_{1} = V(x), a_{2} = P(x, a_{1}), \\dots, a_{2i + 1} = V(x, a_{1}, \\dots, a_{2i}), a_{2i + 2} = P(x, a_{1}, \\dots, a_{2i + 1}) $$$$ out^{k}_{V}\\langle V, P \\rangle (x) \\in \\left\\{ 0, 1 \\right\\} \\text{ as the output of the k-round interactive proof} $$Languages in $dIP(k)$ Given a language $L$ we say that it is in $dIP(k)$ if in $k$ rounds we have:\nCompleteness: that is there exists a prover that produces a correct result for a given verifier, if the solution is correct. Correctness: if a solution is correct, every interactive proof gives a false result. $$ x \\in L \\to \\exists P: out^{k}_{V}\\langle V, P \\rangle = 1 $$$$ x \\not\\in L \\to \\forall P : out^{k}_{V}\\langle V, P \\rangle = 0 $$$$ dIP = \\bigcup_{k \\geq 1} dIP(k) $$3SAT in $dIP$ This can be prooven quite easily. But I am tired to write this down. But the takeaway is the following: This follows that $dIP = NP$, which essentially says that you don\u0026rsquo;t have any advantage using this method.\nProbabilistic Interactive Theorem-Provers The definition is very similar to the above. Note: interactive theorem provers, intuitively, seem to be very similar to a conversation between two agents, that try to work together to reach to a solution.\n","permalink":"https://flecart.github.io/notes/interactive-theorem-provers/","summary":"\u003cp\u003eMost of times the pattern of proving and verifying it is like this $prove \\to verify$, that is: there is an entity that generates the solution, andPo then another that tries to verify it.\nBut more expressive algorithms could be possible if there is \u003cstrong\u003einteraction\u003c/strong\u003e between the two entities, ones that try to prove it, and others try to verify it.\nFrom some point of view, this is similar from what AlphaGo does when searching, there is a part that guides the search, another that actually searches for it. Or the modern \u003ca href=\"https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/\"\u003ealpha geometry\u003c/a\u003e in modern times.\u003c/p\u003e","title":"Interactive Theorem Provers"},{"content":"Vogliamo in questa sezione andare ad indagare la costruzione di funzioni che passano in tutti i punti che vogliamo, appunto interpolare. La funzione √® molto simile alla regressione trattata in Minimi quadrati (con il metodo della regressione, chiamato anche approssimazione ai minimi quadrati).\nQuindi mentre la precedente voleva andare a minimizzare l\u0026rsquo;errore, questo attuale va a creare proprio da 0 la funzione che ci passa sempre.\nIntroduzione Andremo a creare una funzione f tale che per ogni x in input si abbia esattamente la y in output\nMetodi di interpolazione (3)üü© In questo corso utilizzeremo solmanete l\u0026rsquo;interpolatore polinomiale!\nInterpolazione polinomiale Enunciato e unicit√†üü© Enunciato Da notare che il grado della funzione √® esattamente il numero delle y.\nDimostrazione dell‚Äôunicit√† Polinomi di Lagrange e costruzioneüü© Costruzione del polinomio di interpolazione In soldoni, mi sto costruendo molteplici funzioni che nel mio punto assumono il valore che voglio e in tutti gli altri punti sono nulli. Costruisco n funzioni per gli n input e li sommo assieme. Questa funzione qui mi basta per interpolare il tutto.\nImportante in questa sezione capire cosa √® la notazione.\n$\\varphi_k(x_i)$ √® il polinomio di lagrange che per xi, con i = k √® 1, altrimenti √® 0.\nIn particolare √® costruito in questo modo:\n$$ \\varphi_k(x) = \\prod^n_{j =0, j\\neq k} \\frac{x - x_j}{x_k - x_j}, \\forall k \\in \\{0, ..., n\\} $$$\\Pi_n(x)$ √® la funzione di interpolazione costruita come\n$$ \\Pi_n(x) = \\sum_{i = 1}^n y_i \\varphi_i(x) $$Teorema del resto d\u0026rsquo;interpolazioneüü• Slide della prof Note e osservazioni Faccio finta di prendere i punti da una funzione gi√† esistente e voglio in questo caso cercare di valutare quanto buona sia l‚Äôinterpolazione.\nla funzione pi√π a destra mi d√† una stima dell\u0026rsquo;errore della funzione di interpolazione.\nEsempio funzione di runge Questa funzione mostra come con l‚Äôaumentare del grado del polinomio, la precisione del polinomio di interpolazione non aumenta, anzi diminuisce! L‚Äôerrore cresce con pi√π punti.\nAd intuito la funzione d‚Äôinterpolazione oscilla, se ho un insieme di punti equidistanti non gli sto dando spazio per oscillare indietro.\nEsempio grafico runge Nodi di chebicheffüü• Questo √® un modo intelligente per prendere i nodi, in modo che si risolva il problema dell‚Äôequidistanza e dando al poliminio spazio (non so poi perch√© dargli spazio risolva ci√≤).\nCon n ‚Üí inf, l‚Äôerrore tende a zero! Quindi la convergenza dell‚Äôinterpolazione DIPENDE DAI PUNTI scelti. (questo chiaramente non va sui dati random che troviamo in ambiente, quindi √® molto inutile il metodo dell‚Äôinterpolazione per altra roba, inoltre staremmo seguendo il rumore dei dati).\nSlide nodi di chebicheff-Gauss-Lobatto\nInterpolazione a tratti üü© Dato che non ci conviene di interpolare troppi punti vogliamo spezzare l‚Äôinterpolazione a tratti! E inoltre per avere una regolarit√† impongo uguaglianza delle derivate 1 e 2 evitando spigoli nelel funzioni finali.\nMa questo √® quanto ci vuole insegnare a riguardo la prof. quindi mi fermo in questo punto per questi appunti.\n","permalink":"https://flecart.github.io/notes/interpolazione/","summary":"\u003cp\u003eVogliamo in questa sezione andare ad indagare la costruzione di funzioni che passano in tutti i punti che vogliamo, appunto interpolare. La funzione √® molto simile alla regressione trattata in \u003ca href=\"/notes/minimi-quadrati/\"\u003eMinimi quadrati\u003c/a\u003e (con il metodo della regressione, chiamato anche approssimazione ai minimi quadrati).\u003c/p\u003e\n\u003cp\u003eQuindi mentre la precedente voleva andare a minimizzare l\u0026rsquo;errore, questo attuale va a creare proprio da 0 la funzione che ci passa sempre.\u003c/p\u003e\n\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003cp\u003eAndremo a creare una funzione f tale che per ogni x in input si abbia \u003cstrong\u003eesattamente\u003c/strong\u003e la y in output\u003c/p\u003e","title":"Interpolazione"},{"content":"Introduction to the course Machine learning offers a new way of thinking about reality: rather than attempting to directly capture a fragment of reality, as many traditional sciences have done, we elevate to the meta-level and strive to create an automated method for capturing it.\nThis first lesson will be more philosophical in nature. We are witnessing a paradigm shift in the sense described by Thomas Kuhn in his theory of scientific revolutions. But what drives such a shift, and how does it unfold?\nA theory which clearly could fail in the light of the data but gives you good hypothesis, that tells you something about reality, because reality is a deviation from complete randomness. Joachim Buhmann\nThe paradigm shift An interesting observation is that in the past 100 years, we‚Äôve seen more progress in the field of computer science than in the previous 5000 years. This is due to the availability of vast amounts of data, an increase in the number of scientists, and our development in line with Kurzweil‚Äôs theory of exponential growth.\nWhen comparing the human brain to computers, one excels in creativity, while the other possesses far greater storage capacity. This creates a trade-off between creativity and storage. Humans rely on abstraction to comprehend specific aspects in their pursuit of knowledge. Data structures, such as trees, help us retain the essential elements for the tasks at hand.\nComputers, however, face no such constraints and can store data in any manner they prefer. While humans can creatively build connections, often in surprising ways, machines lack this level of creativity. That said, we still don‚Äôt have a precise definition for creativity‚Äîit‚Äôs not simply, as Steve Jobs suggested, the act of linking different ideas. Computers are good at density estimation, but their ability to generate truly creative insights remains limited.\nBuhmann says that models are good at reproducing the probability distribution that the input data has. But what we care as humans is the wisdom, e.g. what you can do with this information, as introduced in Introduction to Big Data.\nSome Epistemology In principle, epistemology tells you how to extract knowledge from data, from this point of view it can be seen as the precursor of modern information retrieval systems. This tells you something about methods of derivation. The first of which is deduction (Euclid, Hilbert\u0026rsquo;s Grundlagen der geometrie, David Mumford for bayesian reasoning and image processing, but this person is still living). Deduction allows us to create facts by starting with the core principles of our thinking. Later induction was born (philosophically created by Bacon), where you create theory from data, and it\u0026rsquo;s a little bit more machine learning like. The former goes by logic, the latter by intuition (but could be wrong, and it\u0026rsquo;s not formalized), now modeled by statistics and it is what machine learning does. Machine learning just does induction. These two processes of reasoning can be modeled as computational processes. And this allows us to create nice machines that are able to achieve these :D. This was first proposed by Leibniz, who though that thinking is achieved by computing. We can say from some point of view that Leibniz was one of the first theoretical computer scientists. He also invented the binary system.\nWe use digital data because we can control it:\nEfficient to manage Discover models test and simulate hypotheses Find solutions The last three points can perhaps be called intelligence. For Joachim M. Buhmann (the prof.), it\u0026rsquo;s impossible to understand the models, and this can be motivated to the limited storage capacity of our brains, so the attempt of interpretability (i.e. correctly understanding exactly what is happening, the law) is just a bias in the history of science for us humans. While if we understand interpretability as a way to summarize useful information, visualizing it, then it is ok.\nReality is a deviation from randomness. Theories that could fail, but do not in light of the data, are the valid ones. Theories that do not tell you anything, that are always true, are useless.\nA new meaning for Algorithm Classically we considered algorithms as a way to process data, efficiently, now we want to treat them as a relation between data and decisions. At the end, the decisions are what is important for us humans. Algorithm\u0026rsquo;s makes it easier for us. Classically we have studied a concept of complexity of runtime, memory, or energy, but we have not have a clear theory of abstraction or robustness. In our case, we have a probability distribution going in, and another going out. But modelling them as random variables, it\u0026rsquo;s difficult to have a clear definition of correctness. We would also further argue that the correctness of the decision is not a clear science, it is more connected to one\u0026rsquo;s specific values and thus we go into ethics.\nFor Prof. Buhmann a fundamental ability of intelligence is being able to do counterfactual reasoning and planning. So being able to simulate the future, and be able to plan the today\u0026rsquo;s action in order to change the future. This is similar to (Choi 2022) and abductive reasoning by Choi.\nEvery law is a social experiment on a not understood population\nWhen Buhmann tried to say that nobody exactly understands everything, but a correct level of abstraction is often enough (i.e. chemical processes of the combustion engine)\nStudying algorithms is the most complicated part of mathematics when mathematics becomes concrete. 29 September 2023 Joachim M. Buhmann, minute 5.44 in ETHz AML lesson\nHe said that Kolmogorov Complexity is Shannon\u0026rsquo;s Theory for Random variables?? What does it even mean?\nNoise is your friend because it prevents you to make a statement so precise that you cannot compute it\nNoise is an indicator that you can\u0026rsquo;t solve your job.\nFramework for learning algorithms Introductory ideas Buhmann argues that all machine learning can be summarized by this simple idea:\nMachine learning is getting rid of information that doesn\u0026rsquo;t help you to act.\nThe Machine learning pipeline $$ P^{\\mathcal{A}} (\\theta \\mid X) $$$$\\text{ data } X \\to \\text{ Algorithm } \\to \\text{ hypothesis } \\theta$$ And also humans can be part of the algorithm part. The hypothesis can be interpreted as the cause, or the most probable thing that has generated our data. In machine learning context they are the parameters. Usually the hypothesis space is much more smaller compared than the data space. This is also why sometimes we say machine learning is some sort of compression.\nRisk and Gibbs distribution $$ \\mathbb{P}^{\\mathcal{A}} (\\text{hypothesis} \\mid \\text{data}) = \\frac{1}{Z} \\exp(- \\beta \\text{ risk} (\\text{hypothesis, data})) $$ This is some sort of parametrization of the posterior function (it\u0026rsquo;s a partial ordering of our hypothesis space, which allows us to optimize for it). And it\u0026rsquo;s the same as Log Linear Models studied in NLP.\nThe Gibbs distribution is also known as the Boltzmann distribution in statistical mechanics.\nData generation We want to have a theory used to validate learning algorithms $\\mathcal{A}$, which admits stochastic data as input.\nWe define the data to be observations of some experiment of some genre. Mathematically we write $e \\in \\varepsilon \\to \\mathcal{X}$ , $e \\to \\mathcal{X}(e)$. Meaning: we have an experiment that contributes to the data $\\mathcal{X}$. We define a hypothesis class $\\mathcal{C}$ where possible hypothesis are located. We use these hypothesis to interpret the dataset $\\mathcal{X}$.\nAn example against MLE estimation $$ \\begin{cases} p(H) = 0.6 \\\\ p(T) = 0.4 \\end{cases} $$ We want to say, what is the most probable sequence in a $1000$ trials? The answer is easy, its all Heads! But we know that this is very very improbable! The most likely sequence is not what its observed, usually, and this seems like a paradox, and its a strong argument against MLE methods. The best possible sequence (aka the MLE\u0026rsquo;s output) is not always the best for modelling our experiment. We want to minimize risk while maximizing the probability. I still have not wholly understood this example.\nDirections on algorithm design We can broadly categorize the categories of algorithms by how much humans know about the problem.\nWe can now divide algorithms in three macro categories, based on human-expertise\nClassical algos: humans are able to solve this problems, and are also able to specify those kinds of problems in a logical way This is classical algorithm design engineering Supervised algos: humans are able to solve these kinds of problems, but don\u0026rsquo;t know how to formalize their logic. This is classical supervised learning algorithm Unsupervised and self-play: humans are not able to solve these problem good enough, this gave rise to alpha fold, alpha go and stuff similar to this. This is autonomous self play, for example (Jumper et al. 2021). Unsupervised learning. Some definitions A definition of Data Science We say that data science studies the algorithms $\\mathcal{A}$ that map the data $\\mathcal{X}$ to the space of possible hypothesis $\\mathcal{C}$.\nStatistics usually studies the distribution of $\\mathcal{X}$ data science studies the mappings. Physics and Mathematics, and other sciences study the space of possible hypothesis.\nWe would say that data science is attempting to learn a function from data to hypothesis. The hypothesis is our interpretation of the reality. We write $f: \\mathcal{X} \\to \\mathcal{Y}$.\nConditional expected risk $$ \\mathcal{R}(f, X) = \\int _{\\mathcal{Y}} \\mathcal{L}(Y, f(X)) P(Y \\mid X) \\, dY $$$$ \\mathbb{E}_{x \\sim \\mathcal{X}} \\left[ \\mathcal{R}(f, X) \\right] $$$$ \\hat{R}(\\hat{f}, \\mathcal{Z}^{\\text{train}}) = \\frac{1}{n} \\sum_{i = 1}^{N} \\mathcal{L}(Y_{i}, \\hat{f}(X_{i})) $$$$ \\mathbb{P}\\left( \\lVert \\hat{R}(\\hat{f}, \\mathcal{Z}^{\\text{test}}) - \\mathbb{E}_{x \\sim \\mathcal{X}} \\left[ \\mathcal{\\hat{R}}(\\hat{f}, X) \\right] \\rVert \u003e \\varepsilon \\right) $$What is Data? Encyclopedia Britannica: Association of numbers with physical quantities and natural phenomena by comparing an unknown quantity with a known quantity of the same kind.\nMeasurements by sensors, factual information, numbers. It\u0026rsquo;s not very clear, I would say any numbers that can help you do some interesting inferences in some world (it has to affect some entities (i.e. humans))\nWhat are features? But we can\u0026rsquo;t use this data directly so we use features of data, that could be arbitrary transformations of the initial data (edges, corners, etc\u0026hellip;).\nTypes of data Measurements üü® We say that we have a world of $R$ objects, and we do observations about these objects. We say $X$ is a measurement (so a data point) where we have a function $X : \\mathcal{O}^{(1)} \\times \\dots \\times \\mathcal{O}^{(R)} \\to \\mathbb{K}$ Choosing a representation of the data is one of the most important parts of machine learning applications. The sample space is the mathematical space where the measurements are represented.\nFour types of data üü® Feature vectors: $X: \\mathcal{O} \\to \\mathbb{R}^{d}$ Categorical data $X : \\mathcal{O} \\to \\mathbb{R}^{d} \\times \\left\\{ 1, \\dots, k \\right\\}$ Regression data $X : \\mathcal{O} \\to \\mathbb{R}^{d} \\times \\mathbb{R}$ Proximity data $X : \\mathcal{O} \\times \\mathcal{O} \\to \\mathbb{R}$\nThis division should be pretty intuitive. See the slides for some real examples. Scales Nominal or Categorical scales Example: binary $\\mathcal{X} = \\left\\{ 0, 1 \\right\\}$, or some nominal categories (sweet, sour etc)\nQuantitative scales We can divide these scales as interval scales for fahrenheit temperature scale. The important information is between the values, so scale and translation invariant. Ratio scale: the information is the difference with a focal point, for example Kelvin temperature scale Absolute scales where we the important is absolute thing (grade scale ahah).\nBuhmann believes humans are only good in relative scale judgement, when they try to do absolute scaling, they can bias negatively or positively. This is why he believes grades should be relative.\nDesiderata for Data Science In this section we would like to describe what exactly is a good data science algorithm.\nHypothesis consistency The most important requirement is: If $x$ and $x'$ are drawn from the same distribution (one is usually called the experiment, the other is called the control), then $\\mathbb{P}^{\\mathcal{A}}(c \\mid x) \\approx \\mathbb{P}^{\\mathcal{A}}(c\\mid x')$ meaning the probability of the hypothesis should be similar.\nWe can call this control experiment and interpret $x$ as training data and $x'$ as test data or control in this setting. But we need to take some care about this statement:\nWe want similar inputs to have similar hypothesis We want dissimilar inputs to have dissimilar hypothesis If we only had requirement 1, then always outputting the same thing could solve our problem, but more variability is more useful, so we also consider dissimilar hypothesis :). $$ \\arg \\max_{\\mathbb{P}^{\\mathcal{A}}} \\mathbb{E}_{x, x'} \\log \\sum_{\\theta} \\frac{\\mathbb{P}^{\\mathcal{A}}(\\theta \\mid x)}{\\mathbb{P}^{\\mathcal{A}}(\\theta)} \\mathbb{P}^{\\mathcal{A} } (\\theta \\mid x') $$ The best thing is that the two probabilities have a high value in the points were we care. Under-fitting is having low probabilities everywhere, over-fitting is having high spikes, the best is in the middle: see this image: TODO put the image here. This is also called posterior agreement, we will deepen these ideas later in #Log posterior agreement.\nThe classical problem When starting to model a problem, we Computer Scientists that have to work on data have to decide the format of the data that we want to use. We want a way to evaluate this problem, discover when it\u0026rsquo;s a good model or not. Usually the trade-off is between the expected classification error, while trying to maximize the generalization ability. We don\u0026rsquo;t have the true expected error, so we use a proxy, the empirical error we can find during the experiments.\n$$ R(f, X) = \\int _{\\mathcal{Y}} P(Y \\mid X) Q(Y, f(X)) \\, dY $$$$ \\mathbf{E}_{x}\\left[ R(f, X) \\right] = \\int _{\\mathcal{X}} \\int _{\\mathcal{Y}} P(X, Y) Q(Y, f(X)) \\, dY \\, dX $$$$ \\mathbb{P} \\left( \\lvert \\hat{R}(\\hat{f}, Z^{test}) - \\mathbf{E}_{X} \\left[ R(\\hat{f}, X) \\right] \\rvert \u003e \\varepsilon \\right) = \\,? $$ Where $\\hat{f}$ is the best hypothesis for our training data, and $\\hat{R}$ is the loss for the test data. We need to have some statistics over this value. k-splitting is a good way to have these statistics.\nWhen we want to mathematically characterize this, we need to keep in mind topology, Inner product spaces, Spazi vettoriali, and Spazi di probabilita.\nLog posterior agreement This section is not exam material (but üü®\u0026ndash;), did not understand this part quite well, the takeaway are following:\nRobust bounds on correctness of ML systems can be achieved (noisy bounds) We care about out-of-distribution generalization and fixed entropy of our hypothesis space. There are algorithms to efficiently minimize the cost (aka risk, hamiltonian) of out-of-distribution inputs. We want a way to measure how well similar distributions induce similar hypothesis. (this is sort of a soundness property). $$ \\mathbf{E}_{x, x'} \\log \\sum_{c \\in \\mathcal{C}}p(c \\mid x) \\frac{p(c \\mid x')}{p(c)} $$$$ \\mathbf{E}_{x'} p(c \\mid x') = \\int p(x') p(c \\mid x') \\, dx' = \\int p(x', c) \\, dx' = p(c) $$ It\u0026rsquo;s just marginalization.\n$$ \\mathbf{E}_{x, x'} \\log \\mathbf{E}_{c \\mid x} \\frac{p(c \\mid x')}{p(c)} \\leq -\\mathbf{E}_{x, x'} \\mathbf{E}_{c \\mid x} \\log \\frac{p(c \\mid x')}{p(c)} = -\\mathbf{E}_{x, x'} \\mathbf{E}_{c \\mid x'}\\log p(c \\mid x') + \\mathbf{E}_{c} \\log p(c) $$ Now we can do some interpretation: The first part is out of sample description length of the hypothesis $c$ given $x$ the second one is minus the entropy of $\\mathcal{C}$.\nWe want a way to describe the quality of an hypothesis (stats people call it risk, physics people call it Hamiltonian) is a function $\\mathcal{R} : \\mathcal{X} \\times \\mathcal{C} \\to \\mathbb{R}$.\n$$ p(c \\mid x) = \\frac{\\exp(- \\beta \\mathcal{R}(x, c))}{\\sum_{c'} \\exp(- \\beta \\mathcal{R}(x, c'))} $$$$ p(c \\mid x) = e^{-\\beta (\\mathcal{R}(x, c) - F(x))} $$ Where $F(x) = - \\frac{1}{\\beta} \\log \\sum_{c'}e^{-\\beta\\mathcal{R(x, c'})}$.\nWe can plug this back into the upper bound (so we can try to minimize the upper bound)\n$$ -\\mathbf{E}_{x, x'} \\mathbf{E}_{c \\mid x'} \\left( -\\beta \\mathcal{R}(x', c) + \\beta F(x')\\right) + \\mathbf{E}_{c} \\log p(c) $$$$ \\min_{\\beta, \\mathcal{R}} \\left\\{ \\mathbf{E}_{c} \\mathbf{E}_{x'} \\left( \\beta \\mathcal{R}(x', c) - \\beta E_{x} F(x') \\right) - \\text{ entropy}(c) \\right\\} $$ I have not understood exactly why we are doing this.\nReferences [1] Vapnik ‚ÄúEstimation of Dependences Based on Empirical Data‚Äù Springer 2006\n[2] Choi ‚ÄúThe Curious Case of Commonsense Intelligence‚Äù Daedalus Vol. 151(2), pp. 139\u0026ndash;155 2022\n[3] Jumper et al. ‚ÄúHighly Accurate Protein Structure Prediction with AlphaFold‚Äù Nature Vol. 596(7873), pp. 583\u0026ndash;589 2021\n","permalink":"https://flecart.github.io/notes/introduction-to-advanced-machine-learning/","summary":"\u003ch2 id=\"introduction-to-the-course\"\u003eIntroduction to the course\u003c/h2\u003e\n\u003cp\u003eMachine learning offers a new way of thinking about reality: rather than attempting to directly capture a fragment of reality, as many traditional sciences have done, we elevate to the meta-level and strive to create an automated method for capturing it.\u003c/p\u003e\n\u003cp\u003eThis first lesson will be more philosophical in nature. We are witnessing a \u003cstrong\u003eparadigm shift\u003c/strong\u003e in the sense described by Thomas Kuhn in his theory of scientific revolutions. But what drives such a shift, and how does it unfold?\u003c/p\u003e","title":"Introduction to Advanced Machine Learning"},{"content":"Quick introduction Si assume che la descrizione pi√π intelligente di un qualcosa √® la stringa pi√π corta che descrive quella, un po\u0026rsquo; forse √® arbitrario, perch√© minore complessit√†, non √® detto che sia direttamente relazionata con la difficolt√† di descriverla.\nNel caso di AIT, diciamo che una cosa random non √® compressibile, altrimenti posso scriverla in modo pi√π compatto. √à importante stabilire che l\u0026rsquo;alfabeto che abbiamo per rappresentare qualcosa √® fissato a priori. Qualunque cosa che possiamo codare si pu√≤ analizzare da questo punto di vista della complessit√†.\nThe complexity of an object is assessed by finding\nthe¬†shortest among the available binary descriptions\nof that object.\nQuesta cosa permette di descrivere la complessit√† di un oggetto in modo assoluto (cio√® a s√© stante, mentre la entropia)\nInformation is what is left when any redundant data is thrown away.\nSi basa sulla ipotesi che se tolgo qualcosa comincio a non capirci pi√π diciamo di quella cosa, quindi √® tutto importante di quella stringa.\nSimple is frequent\n√à una assunzione che si ha su AIT, per√≤ in natura non √® sempre vero, perch√© un sasso lungo pu√≤ essere semplice per noi da comprendere, per√≤ resta una cosa rara da trovare per dire. Bisogna capire bene che cosa questa metrica mi sta misurando! La cosa √® che stranamente questa legge empirica sembra vera sul web! Words are optimally stored in memory according to the frequency of the use. Per√≤ non ci dice come avviene questo processo di aggiornamento della capacit√† della mente di fronte all\u0026rsquo;adattarsi a questi dati.\nRelative complexity Complexity of objects in different environments can vary, we say that this is a conditioned complexity: Un esempio banale: Prendiamo un insieme ordinato di elementi, allora posso rappresentare univocamente l\u0026rsquo;elemento tramite la rappresentazione del suo indice. Questo permette di semplificare molto la descrizione di quell\u0026rsquo;oggetto, ma comunque descriverlo nella sua interessa conoscendo il prior.\nWhen an object can be retrieved from a list,\nits complexity within the list can be estimated\nby the length of the binary representation of its rank.\nUpper bound con complexity When an object belongs to a set of size $N$,\nits complexity in that set cannot exceed¬†$\\log_{2}(N)$\nPer utilizzare l\u0026rsquo;indexing di una lista, mi basta poter essere in grado di codificare il numero pi√π alto presente, quindi la grandezza dell\u0026rsquo;insieme per descrivere l\u0026rsquo;elemento, per questo motivo posso affermare la frase di sopra. Questo bound mi permette di descrivere la complessit√† di oggetti senza ordine.\nRappresentazione dei Numeri interi $$ \\lceil \\log_{2}(n + 1) \\rceil $$ Usiamo il $+1$ per risolvere il problema col logaritmo di 0, questa comunque √® una buona misura. Solo che non √® il codice minimo, possiamo prendere il codice $\\lceil \\log_{2}(n + 3) - 1 \\rceil$ come un codice migliore, perch√© possiamo togliere 1 perch√© iniziamo a contare con la cifra 1. Possiamo prefixare qualcosa per scegliere il metodo di codifica. Per esempio un numero $90000$ si pu√≤ encodare come $9$ con $4$ per encodare l\u0026rsquo;esponente del 10. Ma spendiamo il bit per indexare il metodo di codifica.\nIn generale per rappresentare cose non numeri, si possono utilizzare strutture che rappresentano univocamente quell\u0026rsquo;oggetto e poi usare la complessit√† su queste strutture. Non √® chiaro sempre come utilizzare queste strutture.\nQuasi-continuous complexity In questa parte analizziamo come varia la lunghezza di descrizione per i numeri, notiamo che segue pi√π o meno la curva logaritmica, con i drops previsti per i numeri rotondi, come da intuizione (lo schema di coding presentato ha questa propriet√†).\n$$ \\lvert C(n + h) - C(n) \\rvert \\leq f(\\lvert h \\rvert ) + O(1) $$ Mentre sappiamo che per una funzione continua quello dovrebbe essere 0.\nGenerati da questo codice Compressibilit√† di stringhe binarie Un risultato che consegue dalla limitatezza di stringhe di bassa lunghezza abbiamo che:\nSe dati un insieme di tutte le stringhe binarie lunghe $N$, volessimo contrarre la descrizione di almeno $k$, avremmo che solo $\\frac{1}{2^{k - 1}}$ delle $2^{N}$ stringhe iniziali possono essere compresse per $k$ o pi√π digits.\n$$ \\sum_{i=k}^{N} 2^{N - i} = 2^{N - k + 1} - 1 $$$$ \\frac{2^{N - k + 1}}{2^{N}} = \\frac{1}{2^{k - 1}} $$ E questo √® un valore che decresce in modo esponenziale, per questo le stringhe compressibili di molto sono veramente veramente poche.\nUna cosa interessante √® che per qualunque compressore $Z$ che si possa creare, se prendiamo sequenze binarie $N$ almeno una non √® compressibile.\nExpanding compressors Una osservazione banale ci dice che se il compressore √® una funzione con stesso dominio e codominio, e che sia iniettiva affinch√© sia univocamente decodabile, allora certe stringhe vengono espande invece che compresse! Solitamente nella pratica l\u0026rsquo;espansione succede perch√© il compressore aggiunge dei markers per dire che √® stato compresso.\nQuesto ci dice che il compressor non deve comprimere sempre, ma solamente comprimere in modo dipendente dal contesto secondo me.\nZipf\u0026rsquo;s Law Elaborato insieme a un altro tizio che si chiama Condon relaziona la frequenza di una parola nel linguaggio con il rank, ossia un dizionario che ordina le parole per frequenza d\u0026rsquo;uso. https://babel.hathitrust.org/cgi/pt?id=mdp.39015008729983\u0026amp;view=1up\u0026amp;seq=7 Il contributo di Zips √® una spiegazione di questo fenomeno empirico dato da Condon.\nEnunciato di Zipf $$ r_{f}(w) \\approx \\frac{c}{f(w)} $$ dove $f(w)$ √® la frequenza della parola, e $r_{f}(w)$ √® il suo rank, con una costante a caso $c$.\nThis means that the 10th¬†most frequent word is 10 times more frequent than the 100th¬†most frequent word, which is itself 10 times more frequent than the 1000th¬†most frequent word, which is itself 10 times more frequent than the 10¬†000th¬†most frequent word, and so on\nSembra che questa legge valga per molte lingue, non solo l\u0026rsquo;inglese.\nMinimize effort and time to find the right word to use. Questa √® la spiegazione a questo fenomeno.\nCorrispondenza sulla complessit√† dei codici Complexity of the meaning = complexity of word Complexity is related to the frequency of the word Questo spiega anche cose sulla ripetizione spaziata in (Brown et al. 2014). E ha senso, cose che vediamo pi√π spesso ci appaiono come semplici, cose che vediamo singola volta sono abbastanza complesse, la relazione sulla complessit√† sembra essere fortemente legata alla frequenza della parola. Che bella idea.\nNormalized information distance Basato su (Li et al. 2004).\nFor any pair of objects, NID determines what is common to them, and only keeps their difference to measure the distance that separates them.\nCalcolo del NID Misurare la differenza di informazione attraverso il Kolmogorov Condizionato quindi $max[K(x|y), K(y|x)]$ il max ci aiuta a rendere la distanza simmetrica. Normalizzare la differenza di informazione, perch√© vogliamo una nota relativa di questa misura. $max(K(x), K(y))$ che rappresenta la massima complessit√† di entrambi gli oggetti che vogliamo confrontare. Usare Kolmogorov complexity#Chain Rule cosicch√© possiamo riscrivere il numeratore. $$ NCD(x, y) = \\frac{K(x, y) - min[K(x), K(y)]}{max(K(x), K(y))} $$$$ NCD(x, y) = \\frac{max[K(x|y), K(y|x)]}{max(K(x), K(y))} $$Questo non √® computabile perch√© $K$ non √® computabile, ma possiamo stimarlo con un compressore reale. La cosa triste √® che il compressore non prende in considerazione la semantica. Per la semantica √® interessante usare la (Cilibrasi \u0026amp; Vitanyi 2007), usando google per stimare la distanza. e questa la chiama la Normalized Google Distance.\nUniversal distance $$ \\forall D; \\forall x, y: D_{U}(x, y) \u003c D(x, y) + C_{D} $$ Questo: $max[K(x|y), K(y|x)]$ √® una distanza universale. Che √® una cosa molto interessante.\nReferences [1] Li et al. ‚ÄúThe Similarity Metric‚Äù IEEE Transactions on Information Theory Vol. 50(12), pp. 3250\u0026ndash;3264 2004\n[2] Cilibrasi \u0026amp; Vitanyi ‚ÄúThe Google Similarity Distance‚Äù 2007\n[3] Brown et al. ‚ÄúMake It Stick: The Science of Successful Learning‚Äù Harvard University Press 2014\n","permalink":"https://flecart.github.io/notes/introduction-to-algorithmic-information-and-complexity/","summary":"\u003ch3 id=\"quick-introduction\"\u003eQuick introduction\u003c/h3\u003e\n\u003cp\u003eSi assume che la descrizione pi√π \u003cem\u003eintelligente\u003c/em\u003e di un qualcosa √® la stringa \u003cstrong\u003epi√π corta\u003c/strong\u003e che descrive quella, un po\u0026rsquo; forse √® arbitrario, perch√© minore complessit√†, non √® detto che sia direttamente relazionata con la difficolt√† di descriverla.\u003c/p\u003e\n\u003cp\u003eNel caso di AIT, diciamo che una cosa random non √® compressibile, altrimenti posso scriverla in modo pi√π compatto. √à importante stabilire che l\u0026rsquo;alfabeto che abbiamo per rappresentare qualcosa √® fissato a priori.\n\u003cem\u003eQualunque cosa che possiamo codare\u003c/em\u003e si pu√≤ analizzare da questo punto di vista della complessit√†.\u003c/p\u003e","title":"Introduction to Algorithmic Information and Complexity"},{"content":"Data Science is similar to physics: it attemps to create theories of realities based on some formalism that another science brings. For physics it was mathematics, for data science it is computer science. Data has grown expeditiously in these last years and has reached a distance that in metres is the distance to Jupiter. The galaxy is in the order of magnitude of 400 Yottametres, which has $3 \\cdot 8$ zeros following after it. So quite a lot. We don\u0026rsquo;t know if the magnitude of the data will grow this fast but certainly we need to be able to face this case.\nEarly versions Small History of Information systems üü®++ We can pinpoint three main historical developments of information systems that coincide with some revolutions in human history. 0. First humans just stored their information in the brains. The stories, culture was mainly transmitted orally from person to person. This was similar to the point made in (Harari 2024) by professor Harari: this allowed humans to create networks of information that created large scale alliances.\nHumans invent writing: first the people needed some storage for economical transactions, this created the need to have some durable tables were to store this information. Humans invent the printing press: Gutemberg\u0026rsquo;s innovation allowed information storage and duplication to be much more cheaper compared to the historical manual copying and writing. This empowered ideas like the christian religion to spread even further and have much higher impact. Invention of the silicon based processors. This innovation enabled further storage and processing, and ultra-fast communication, having another deep effect on humanity as a whole. 20k Ishango Bone is one of the first. 250 BC there was a library of Alexandria. With physical books it was very difficult to get some higher level trends. Now we can just analyze hundreds, and millions of documents in a very fast manner.\nCodd\u0026rsquo;s Data Independence üü© Edgar Codd suggested that a usable database management system should hide all the physical complexity from the user and expose instead a simple, clean model.\nSee (Codd 1970). The other important contribution in the paper is the suggestion to use tables, which gave birth to the relational languages and algebra.\nAs in Architettura e livelli 1, 2, the data systems are divided into inter-operating levels, that communicate with each other using interfaces. This makes easy to update the underlying level without the upper one noticing.\nDatabase management systems A database management system stack can be viewed as a¬†four-layer stack:\nA logical query language with which the user can query data; A logical model for the data; A physical compute layer that processes the query on an instance of the model; A physical storage layer where the data is physically stored. Evaluating an Information system Velocity üü© For the velocity we care about the capacity, throughput and latency. Capacity is how much you can store, throughput is how fast can you read, and latency is how much you have to wait until the first byte of data. Some of the first devices in 1956 had capacities of 5MB $(1.7m \\times 1.5m)$, throughput of 12.5kB/s and latencies of 600ms. Now in 2024 it has capacities of 26TB $(14.7cm \\times 2.6cm)$, throughput of 261MB/s and latencies of 4ms.\nThe important thing to observe is that\nCapacity has exploded very fast, more than one million orders of magnitude! Also throughput has increased, by only by about 4 orders of magnitude Latency has not advanced much. The important consideration is that if we want to process the same amount of data, it\u0026rsquo;s much more important to parallelize so that we can read faster.\nVolume üü©- How big should data be to be considered to be part of big data? We need first to learn something about the scales :D and orders of magnitude!. Those should be learned by hearth\nKilo - 1000 Mega - 1.000.000 Giga - 1.000.000.000 Tera - 1.000.000.000.000 Peta - 1.000.000.000.000.000 Exa - 1.000.000.000.000.000.000 Zetta - 1.000.000.000.000.000.000.000 Yotta - 1..000.000.000.000.000.000.000.000 Ronna - 1.000.000.000.000.000.000.000.000.000 Quetta - 1.000.000.000.000.000.000.000.000.000.000 When we go on the other side we have\nMilli Micro nano Pico femto atto zepto yocto All by hearth! The threshold for big data is currently the Peta because it can\u0026rsquo;t be stored in a single computer.\nVariety üü© Data could have different shapes, it\u0026rsquo;s important for the exam that you learn these shapes by hearth:\nGraphs Cubes Unstructured (Text is a often cited example of this). Trees Tables A definition of Big Data üü© Big Data is a portfolio of technologies that were designed to store, manage and analyze data that is too large to fit on a single machine while accommodating for the issue of growing discrepancy between capacity, throughput and latency.\nThis has some links with the definition of data, information, knowledge and wisdom, that you can find here.\nUsage examples üü©\u0026ndash; There are some real life companies and environments where storing many many gigabytes of data everyday is the most common thing ever: for example\nCERN produces 50PB of data every year, and most of these data needs to be analyzed, see Massive Parallel Processing. Sloan Digital Sky Survey (SDSS) which attempts to map every part of the sky produces 200 GB of data every day. It has the most detailed 3D map of the sky Also biology DNA can be seen as a data storage device. Reading and Writing intensive systems üü© These are called respectively OLAP (Online Analytical Processing) and OLTP (Online Transaction Processing for the write intensive. This has been explained in a more detailed manner in Data Cubes.\nTechniques for Big Data We appoint two as the main techniques used to handle big amounts of data. Many of these arise due to the ever growing amount of data in modern times:\nParallelization: if we have many many processors, it\u0026rsquo;s easy to read many pages at the same time. This is what is leveraged in Massive Parallel Processing. Batch Processing: due to the discrepancy between throughput and latency, it\u0026rsquo;s often better to read a lot of data at the same time, and then process it in a batch. This is also leveraged in systems like MapReduce introduced in Massive Parallel Processing. Paradigms of data storage ETL framework üü© This is the classical database approach: We load the data in the database and let the underlying system handle it. This method needs some added cost in extracting, transforming and loading the data that we have stored previously in an optimized format so that it can be used for views, or else.\nData Lakes üü© We usually refer to Data Lakes when we store our data with Distributed file systems or using Cloud Storage: cheap ways to dump the data without caring about the possibility of modifying them.\nWe typically store data in the filesystem, where it is viewed simply as files. This approach works well when we only need to read the data. It\u0026rsquo;s often referred to as in situ storage because there is no need to extract the data first. However, the drawback arises when we need to modify the data, as it can lead to numerous inconsistencies.\nAnother significant limitation of filesystems is that they cannot scale to manage billions of files efficiently.\nThis is what the professors in the first database course says Filesystem: are not the perfect technology to handle this type of load, see Introduction to databases.\nScaling principles Usually the best thing is to make things work in a single computer, then it\u0026rsquo;s cheaper to scale horizontally, and then to scale vertically, adding better hardware.\nCurrent Limits When A relational table grows too much, a single system could have difficulty in handling it. Common limits nowadays are:\nMillions of rows Cloud Storage, Distributed file systems, Massive Parallel Processing, usually handle well data with lots of rows (samples, with the same columns) More than 256 columns, we usually use Wide Column Storage. With a lot of nested data. We use Document Stores, like MongoDB, where the Markup is quite important. There are also problems for file-systems:\nDifficulty on collaborating on the same file with the same Filesystem Doesn\u0026rsquo;t scale over billions of files, standard filesystems are not designed to handle so much data. Scaling vertically üü© There are two ways of scaling, scaling vertically or horizontally. Scaling Up concerns in building better machines, building better algorithms and being more efficient with what exactly we have.\nScaling horizontally üü©\u0026ndash; Scaling horizontally is the simple idea of adding more things, it could be more computers, more ram, more disk, more CPUs. But these have some physical limits that we should need to keep track of.\nThere is a physical limit of number of computers in a data-center (1k to 100k which seems to be the hard limit constrained by energy and cooling requirements). Z√ºrich\u0026rsquo;s datacenter consumes as much energy as an airport. And we have about 1-200 cores in a single computer of a datacenter.\nWe also have a limit for RAM and local storage. Respectively about 0.016-24TB of RAM and 1-30TB of storage. Its unthinkable that the RAM memory has the same order of magnitude of local storage. This is because in memory databases are becoming more common (they are usually faster, lower latency).\nWe also have a bandwidth of 1-200Gbit/s for a single server on an Ethernet cable.\nWe have standardized rack units for every server (or storage if the module is just for storage), storage and routers, they are usually connected together by switches and similar networking thingies. Usually we have 1-4 rack units for a server\nType Range Computers in Data Center 1k-100k (100k hard limit for electricity designs) Cores in a Single computer 200 RAM 0.016-24TB Network Bandwidth 1-200 Gbit Racks per server (module) 1-4 HDD Storage 26TB Throughput 261MB/s Latency 4 ms Analysis of bottlenecks üü© We already have said that a way to improve on the possible bottlenecks of our systems is having better code: using our resources in a better manner. The easier way is choosing to buy more resources. Important bottlenecks in our context are CPU, Memory, RAM, and network. We can know if have one of these bottlenecks by monitoring the real-time resource usages.\nDisk-IO -\u0026gt; MapReduce and Spark, or using Parquet instead of JSON can\nIn fact, you should always first try to improve your code before scaling out. The vast majority of data processing use cases fit on a single machine, and you can save a lot of money as well as get a faster system by squeezing the data on a machine (possibly compressed) and writing very efficient code.\nFor example, an easy way to address a memory bottlenecks is to analyze the classes that are instantiated many many times, but their fields are not often used, or have repeated information. Scaling up should be the last resource!.\nFor CPU, we should pay attention to the places we are doing so much class hierarchy, type checking, useless loops, overridden methods (they have to dynamically retrieve the function!) And too many method calls that are not easily inlinable.\nFor DIsk-IO, we use better formats, or compression, and parallel processing frameworks.\nFor Network, try to get rid of data that doesn\u0026rsquo;t need to be transmitted, and put it in a nicer format so that it is easier to compress it! (This is called Push Down). And use batch processing.\nEvolution of the data stack We have 10 layers, instead of the 7 Architettura e livelli 1, 2 of the ISO OSI layers of the networking. We will rebuild the whole datastack and understand how every layer works together with one another to handle the big data.\nWe will link for each part some important nodes regarding those\nStorage: Cloud Storage, Wide Column Storage, Distributed file systems Encoding and Syntax: Markup Data models and Validation: Data Models and Validation Processing: Massive Parallel Processing References [1] Codd ‚ÄúA Relational Model of Data for Large Shared Data Banks‚Äù Communications of the ACM Vol. 13(6), pp. 377\u0026ndash;387 1970\n[2] Harari ‚ÄúNexus: A Brief History of Information Networks from the Stone Age to AI‚Äù Random House 2024\n","permalink":"https://flecart.github.io/notes/introduction-to-big-data/","summary":"\u003cp\u003eData Science is similar to physics: it attemps to create theories of realities based on some formalism that another science brings. For physics it was mathematics, for data science it is computer science.\nData has grown expeditiously in these last years and has reached a distance that in metres is the distance to Jupiter. The galaxy is in the order of magnitude of 400 Yottametres, which has $3 \\cdot 8$ zeros following after it. So quite a lot. We don\u0026rsquo;t know if the magnitude of the data will grow this fast but certainly we need to be able to face this case.\u003c/p\u003e","title":"Introduction to Big Data"},{"content":"What is it for Estimation Sampling generate numbers from any distribution! (distributions are important in statistics). Density Cumulative distribution (and others similar). Optimization how to find computationally the min and max of functions. Generating?\nRandom (difficile anche filosoficamente definire cosa significa questo). Molto importante perch√© si assume in Comp stats che abbiamo il random vero, e questa assunzione che non vale pu√≤ rompere cose. And independent Sample proportion Average of something (example of the lake cannonball).\nFiga la possibilit√† di fare sampling secondo una distribuzione, partendo dalla $U$.\nLista delle nozioni Generalized inverse definition.\nFai la dimostrazione della generalized inverse transform (non dovrebbe essere tanto difficile, una volta che enunci quanto importante dovrebbe andare liscio).\nCosa dice la inverse transform? Perch√© possiamo partire dalla distribuzione uniforme?\nIn che modo √® relazionato la distribuzione $\\exp$ con chi squared, gamma e beta distribution?\nGeneralized transform formula (not in the exam, serve per avere le densit√† e non la CDF) üü•, non ho proprio capito perch√© funziona, in questo corso si impara solo ad imparare a memoria ed applicare queste cose.\nCome fare sampling fra distribuzioni discrete (che √® la soluzione idiota).\nSampling discrete from long tail distributions.\nExplain and use the accept reject method.\nProbabilit√† di accettazione, sia normalizzato che non normalizzato.\nFare gli esercizi a fine capitolo due per accept reject. (registrazione 7 primi 50 minuti parlano di questo).\nGuardare meglio l\u0026rsquo;esempio 3.4 per l\u0026rsquo;importance sampling (e la roba dei tail sampling).\nMinuto 52 Lecture 11, ci sono gli esercizi dispari del capitolo 3.\nFino a Lecture 12 minuto 48 ci sono altri esercizi.\nCose pratiche Essere in grado di implementare grafico e calcolare i valori per la inverse (esattamente quelli). ","permalink":"https://flecart.github.io/notes/introduction-to-computational-statistics/","summary":"\u003ch3 id=\"what-is-it-for\"\u003eWhat is it for\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eEstimation\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSampling\u003c/strong\u003e generate numbers from \u003cem\u003eany\u003c/em\u003e distribution! (distributions are important in statistics).\n\u003col\u003e\n\u003cli\u003eDensity\u003c/li\u003e\n\u003cli\u003eCumulative distribution (and others similar).\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOptimization\u003c/strong\u003e how to find computationally the min and max of functions.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eGenerating?\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRandom (difficile anche filosoficamente definire cosa significa questo).\n\u003col\u003e\n\u003cli\u003eMolto importante perch√© si assume in Comp stats che abbiamo il random vero, e questa assunzione che non vale pu√≤ rompere cose.\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eAnd independent\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4 id=\"sample-proportion\"\u003eSample proportion\u003c/h4\u003e\n\u003cp\u003eAverage of something (example of the lake cannonball).\u003c/p\u003e","title":"Introduction to computational statistics"},{"content":"Basi di dati Cosa √® un database? (2) üü© Si potrebbe intendere come un insieme di dati strutturato, utili per certi obiettivi di enterprise, aziende pubbliche o simili (uno delle necessit√† che la rivoluzione informatica ha pi√π contribuito diciamo.)\nUn altro significato pi√π importante √®\nUn insieme di dati gestito da un Database Management System\nTristemente con questa definizione anche excel √® un DBMS\u0026hellip;\nSolitamente sono utilizzati per gestire grandi quantit√† di dati.\nIl sistema informativo üü© Componente di una istituzione\nSi potrebbe dire che sia una base utile alle organizzazioni per gestire l\u0026rsquo;informazione, questi sistemi erano gi√† presenti molto prima rispetto alla creazione dei sistemi dell\u0026rsquo;informazione moderni, per esempio registri e tavole venivano utilizzate in questo senso, ossia come sistemi per registrare alcuni strumenti utili per il nostro enterprise. Quindi storicamente c\u0026rsquo;√® molta necessit√†, √® solamente con la rivoluzione storica che abbiamo nuove cose.\nNecessit√† dell\u0026rsquo;informazione üü®++ Ci sono alcuni aspetti che possiamo dire molto comuni quando mettiamo mano ai dati e sono tipo:\nCollezionare i dati Filtrare i dati e memorizzarli elaborare i dati Restituire e visualizzare i dati Database Management System Caratteristiche generali dei DBMS (5) üü© Le slides affermano che i dati in questione devono essere:\nGrandi dimensioni (righe) Persistenti Condivisi efficienti efficaci Io aggiungerei anche strutturati perch√© se sono dati non strutturati √® difficile che vengano messi in un DBMS. Comunque commentiamo ora pezzo per pezzo il motivo per cui abbiamo bisogno di queste caratteristiche per i DBMS:\nGrandi dimensioni perch√© vogliamo che sia efficiente anche su questi (soprattutto su questi, quando tengono dati di tante cose rimanendo comunque organizzati diciamo) Terabyte e terabyte di data secondo le slides (500 TB per dati scientifici :O) Persistenti perch√© non avremmo bisogno di un database se tutto rimanesse in RAM\u0026hellip; I dati sono pi√π longevi dei computer che li ospitano diciamo. Cos√¨ abbiamo un unico punto di sicurezza in cui molte persone possono affidarsi per avere una fonte di verit√† diciamo (questo forse ne parlava in the manga introduction to databases) Efficienti si parla da solo, dato che vogliamo che sia effettivo a prendere i dati non vorremmo aspettare tanto Efficace perch√© deve fare il suo lavoro di renderci la vita pi√π facile nella gestione dei documenti e dei dati :) Altro Comparazione con File System üü©\u0026ndash; Sembra che anche i file-system siano in grado di svolgere il lavoro di DBMS, infatti potremmo vedere il DBMS come un file-system allargato, con pi√π funzionalit√†. Infatti possiamo anche in questo caso tenere un file-system distribuito, e affidarci ad esso per\ngestire una grandissima mole di dati (perdiamo sulle garanzie di integrit√†), gestione dell\u0026rsquo;accesso (e quindi di privacy), pone interfaccia per accedere velocemente al supporto fisico sottostante. Diciamo che fa bene il suo lavoro. (efficace) In un certo senso si pu√≤ paragonare a tenere i dati su excel, funziona, per√≤ non √® il massimo, non si hanno garanzie che si vorrebbero avere, i check automatizzati diciamo.\nCol database abbiamo\ngaranzie in pi√π su uniformit√† e relazione dei dati con un Data Model velocit√† di accesso a query classiche Non limitazione ad aprire e chiudere file (prende o l\u0026rsquo;intero file o niente col file system) Alla fine questo √® fatto, si chiama data lake guarda Cloud Storage.\nArchitettura ANSI/SPARC (3) üü© Schema logico descrive come dovrebbero essere i dati ossia la struttura logica dei dati Schema interno come sono rappresentati i dati, potremmo dire l\u0026rsquo;implementazione del livello logico dei dati. Schema esterno che a volte √® chiamata anche view, ossia come gli utenti hanno bisogno di vedere i dati La cosa interessante di questa parte, √® che vorremmo che i dati siano indipendenti (sia il fisico dal logico, sia il logico dall\u0026rsquo;esterno) rispetto a come sono rappresentati, una idea molto importante introdotta per la prima volta da (Codd 1970).\nCredo anche sia la stessa idea, che sta alla base del processo di astrazioni comunissimo in informatica √® l\u0026rsquo;idea di interfaccia, un qualcosa che espone solamente la parte logica di quale sar√† l\u0026rsquo;effetto dell\u0026rsquo;operazione, ma ne nascone le operazioni effettive, che chiamiamo interne. Per i database forse questa cosa era nuova.\nTipologie di modelli logici (5) üü®+ Nel tempo sono stati creati molti modelli possibili dello strato logico del database Una lista di modelli presenti √®\nGerarchici Grafo (network based) relazionali Object Oriented XML-based Quello studiato in questo corso √® il modello relazionale di database management\nProblemi classici (2) üü®\u0026ndash; Ridondanza e coerenza per questo Sync dei valori che possono essere presenti in macchine anche molto distanti Availability √à un grande problema se un database va gi√π\u0026hellip; Privacy e gestione dei permessi, perch√© dato che sono shared, non vogliamo per√≤ che uno possa accedere a dati di altri. TODO Caratteristiche dei dati (3) vogliamo che i dati all\u0026rsquo;interno dei DBMS soddisfino certe desiderata al fine di garantire il buon servizio:\nPrivacy Reliability Availability E parte di queste desiderata sono le stesse che abbiamo anche richiesto all\u0026rsquo;interno di Sicurezza OS quando abbiamo parlato degli attacchi che era possibile fare ad un sistema informativo. Per gestire la reliability ossia la tolleranza a fallimenti hardware e software, e la possibilit√† di garantire anche la ridondanza si utilizzano le transazioni\nTransactions (3) (non fare) Questa parte √® trattata leggermente meglio quando andiamo a parlare di SQL transactions in Structured Query Language Anche in Advanced SQL\nAtomiche Concorrenti Permanenti Le facciamo per benino in The Database Management System\nPros and cons Pros (5) üü®+ √à necessario, molto pi√π efficiente nel caso quella stessa informazione venga utilizzata anche da dipartimenti diversi √à chiara la comunicazione e la struttura, che √® sempre una fonte di verit√† vabb√© ovvio Questo √® molto importante, ci sono stati un sacco di danni che ci sono stati a causa di inconsistenza, come nei file di excel Questo √® ancora una delle radici presenti nell\u0026rsquo;informatica, l\u0026rsquo;indipendenza del software dall\u0026rsquo;implementazione concreta dei dati, oppure dalla rappresentazione hardware. Cons (2) üü© Io aggiungerei anche il livello di astrazione (quindi magari tempo di implementazione delle cose) in pi√π, che poi si riguadagna indietro con la facilit√† di gestione dell\u0026rsquo;infrastruttura\nC\u0026rsquo;√® un grande overhead per mettere su un DBMS questo √® ovvio come con. Basi di dati attive Finora i database \u0026ldquo;passivi\u0026rdquo; non fanno niente finch√© non c\u0026rsquo;√® interazione con query o richiesta.\nIl comportamento reattivo üü© In sql ci sono dei checks a reference di integrit√†, che vengono attivati su update o deletions. La capacit√† di reagire ad eventi √® importante.\nEvent-Condition-Action (ECA) üü© Questo √® il costrutto principale dei database attivi, devono essere in grado di reagire ad eventi in modo reattivo.\nQuindi possiamo dire che il database √® attivo quando esistono dei triggers, regole che vengono eseguite in un certo momento.\nOracle √® stato uno dei primi che si √® accorto di questa necessit√† (infatti √® anche l\u0026rsquo;azienda che ha fatto questo, e l\u0026rsquo;ha chiamato stored procedures) Per√≤ aspetti negativi sono:\nLinguaggio procedurale (impendance mismatch con SQL) Non standarizzato Trigger, granularit√† e modalit√† üü© Esiste un comando SQL, nella DDL, che mi permette di definire in modo esplicito i trigger.\nGranularit√†:\nTupla (attivazione per ogni tupla) Operazione, a singola operazione Modalit√†:\nImmediato Dilazionato. Questi si possono rappresentare anche con semantica differente. References [1] Codd ‚ÄúA Relational Model of Data for Large Shared Data Banks‚Äù Communications of the ACM Vol. 13(6), pp. 377\u0026ndash;387 1970\n","permalink":"https://flecart.github.io/notes/introduction-to-databases/","summary":"\u003ch2 id=\"basi-di-dati\"\u003eBasi di dati\u003c/h2\u003e\n\u003ch3 id=\"cosa-√®-un-database-2-\"\u003eCosa √® un database? (2) üü©\u003c/h3\u003e\n\u003cp\u003eSi potrebbe intendere come un \u003cstrong\u003einsieme\u003c/strong\u003e di dati \u003cstrong\u003estrutturato\u003c/strong\u003e, \u003cem\u003eutili\u003c/em\u003e per certi obiettivi di enterprise, aziende pubbliche o simili (uno delle necessit√† che la rivoluzione informatica ha pi√π contribuito diciamo.)\u003c/p\u003e\n\u003cp\u003eUn altro significato pi√π importante √®\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eUn insieme di dati gestito da un Database Management System\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eTristemente con questa definizione anche excel √® un DBMS\u0026hellip;\u003c/p\u003e\n\u003cp\u003eSolitamente sono utilizzati per gestire \u003cstrong\u003egrandi quantit√† di dati\u003c/strong\u003e.\u003c/p\u003e","title":"Introduction to databases"},{"content":"Financial Markets Uses of Financial Markets In this section, we answer the question of what financial markets are for.\nRaising capital Equity and Dept: Equity is ownership in a company, while debt is a loan. (there is also a mezzanine). Price discovery: The process of determining the price of an asset in the marketplace. Liquidity: pooling people together to have an ease of access to these assets. Risk management: Managing the risk of the assets. Risks could be: inflation (uncertainty on the value of the money), interest rate (uncertainty on the value of the money), credit risk (uncertainty on the value of the money), market risk (uncertainty on the value of the money), etc. This allows hedging risks. They have a role in economic growth (this is economic theory, we won\u0026rsquo;t delve into this). The Shareholders of the market Investors: People that provide capital to governments and companies in exchange of bonds or stocks Intermediaries: organizations that facilitate these kinds of exchanges Market data providers: we can see these as intermediaries that sell data about markets (they usually sell licenses, for example Bloomberg does this). Issuers: organizations that sell financial assets. Regulators: ensure the market is fair and is working properly (usually government agencies that create the rules). For example, it is quite difficult to get into the market, from a regulatory point of view. Collateral and Over-Collateralization Collateral refers to assets or property that a borrower pledges to a lender as security for a loan. If the borrower fails to repay, the lender has the right to seize or sell the collateral to recover the outstanding debt.\nOvercollaterization: Definition: Over-collateralization occurs when a borrower provides collateral exceeding the required amount. For instance, if the collateral requirement is 150%, the borrower must pledge assets worth 150% of the loan amount.\nRisk Mitigation: Adds an extra layer of protection for lenders or investors, reducing the risk of losses in case of default. Enhanced Creditworthiness: Improves the borrower‚Äôs credit profile, making the transaction more attractive to lenders and investors. Market Volatility Protection: Serves as a buffer against fluctuations in collateral value due to market volatility. Key Dangers in Financial Markets The financial market is exposed to various risks that can impact investors, institutions, and the overall system. These risks include:\nSystemic Risks ‚Äì Risks that affect the entire financial system rather than individual institutions. These can stem from market volatility, geopolitical events, or regulatory changes, potentially leading to widespread disruptions. Market Risks ‚Äì The risk of losses due to fluctuations in market conditions, such as changes in interest rates, exchange rates, or commodity prices. Credit Risks ‚Äì The possibility of default by borrowers or debt issuers, often driven by financial distress, economic downturns, or declining creditworthiness. Operational Risks ‚Äì Losses resulting from internal failures within financial institutions, including fraud, human errors, or system malfunctions. Liquidity Risks ‚Äì The risk that investors cannot buy or sell assets at fair market value due to a lack of market liquidity, potentially causing losses or a decline in portfolio value. Cybersecurity Risks ‚Äì As financial markets rely increasingly on technology, cyber threats such as data breaches, financial theft, and market disruptions pose significant challenges. Given the wide range of vulnerabilities, both investors and financial institutions must implement effective risk management strategies to safeguard their assets and ensure the stability of the broader financial system.\nDavid Graeber\u0026rsquo;s Critique of Financial Markets David Graeber, renowned anthropologist, activist, and author, was a vocal critic of the financial markets and their role in the global economy. He argued that financial systems were key drivers of inequality and instability in the world economy.\nDisconnection from the Real Economy: Graeber believed that financial markets had become detached from productive economic activity. They now focused more on profit generation for themselves rather than supporting the broader economy. Prioritizing Financiers Over Stakeholders: According to Graeber, the interests of financiers and speculators increasingly overshadowed those of workers, consumers, and other crucial stakeholders. Complexity and Risk: He argued that financial activities had become so complex that no one fully understood the risks or potential consequences, contributing to instability and unpredictability. Graeber emphasized the need for a more democratic and accountable financial system to address these systemic issues.\nMarket Makers and Their Role in Liquidity Market makers are specialized entities that enhance market liquidity by continuously quoting both buy and sell prices for specific securities. Their primary function is to ensure a liquid market by maintaining active bid and ask orders.\nKey Functions of Market Makers Liquidity Provision: Market makers stand ready to buy and sell assets at publicly quoted prices, ensuring that traders always have a counter-party available. Bid-Ask Spread: They profit from the difference between the bid price (buying price) and ask price (selling price), capturing the spread as compensation for providing liquidity. Price Stability: By consistently participating in trades, market makers help reduce price volatility and narrow the bid-ask spread, facilitating smoother transactions. Reducing Market Impact: They absorb large trades, preventing significant price fluctuations‚Äîan essential function for institutional investors executing high-volume transactions. Key assumptions of Markets (1) Rational Expectations: Based on perfect information ‚Ä¢ Economic actors will not make systematic mistakes in predicting the future (risks) ‚Ä¢ Everyone uses the ¬´right¬ª model for forecasting ‚Ä¢ The future can be inferred from the past and present (2) Efficient Financial Market Theory: Asset prices represent the best possible estimates of the risks attached to them ‚Ä¢ The risk characteristics from financial markets can be inferred from mathematical analysis. ‚Ä¢ Market discipline can be used as an efficient tool in constraining harmful risk taking. Markets are self-correcting.\nDecentralized Finance A definition of DeFi Decentralized finance (DeFi) generally refers to an open, permissionless and highly interoperable protocol stack built on public smart contract platforms.\nThree important parts of this definition:\nOpen and permissionless Interoperable protocol stack Public smart contracts (it has a coding part) Regulators have not generally been able to define this legally. The main effect is to get rid of intermediaries, so that it is more close to the people and the voters.\nThe Promises of DeFi (Decentralized Finance) DeFi, short for Decentralized Finance, holds great promise in transforming the financial ecosystem by offering innovative, inclusive, and efficient solutions. The core promises of DeFi include:\nInclusivity and Access Promise: DeFi aims to provide financial services to individuals globally, including those who are unbanked or underbanked. By leveraging blockchain technology, DeFi has the potential to bridge the gap between traditional financial systems and individuals who lack access to banking services, enabling greater financial inclusion.\nPermissionless Innovation Promise: DeFi platforms are typically open-source and permissionless, allowing developers to create and deploy financial applications without requiring approval from centralized authorities. This fosters rapid innovation, enabling the creation of diverse financial products that can cater to the specific needs of different users.\nFinancial Empowerment Promise: DeFi empowers individuals by giving them greater control over their financial assets. Users hold the private keys to their funds, allowing them to engage in financial activities without needing traditional intermediaries such as banks or brokers. This self-sovereignty enhances financial independence.\nTransparency Promise: Blockchain technology, the backbone of DeFi, provides transparency by allowing users to trace transactions on a public ledger. This transparency fosters trust and accountability within the financial system, as all activities are verifiable and cannot easily be altered or manipulated.\nReduced Costs Promise: By eliminating intermediaries and automating processes with smart contracts, DeFi has the potential to significantly reduce transaction costs. This applies to various financial services, including remittances, loans, and trading, making financial transactions more affordable and efficient.\nInteroperability Promise: DeFi platforms are built on open and interoperable blockchain networks, enabling different DeFi applications to seamlessly integrate with one another. This interconnectivity helps create a more efficient, cohesive financial ecosystem that can adapt and grow in a flexible manner.\nDecentralized Identity and Privacy Promise: DeFi can utilize decentralized identity solutions, which enhance user privacy and reduce reliance on centralized entities for identity verification. This means users can have greater control over their personal information and decide who can access it, promoting privacy and security.\nLiquidity Provision Promise: DeFi platforms often operate with decentralized exchanges and liquidity pools, allowing users to provide liquidity and earn returns. This creates new opportunities for individuals to participate in the financial ecosystem and earn passive income, contributing to market liquidity.\nThese promises reflect the transformative potential of DeFi, making financial services more inclusive, efficient, and user-centered. However, while DeFi offers these advantages, it also faces challenges and risks that need to be carefully managed as the ecosystem evolves.\nCentralized vs Decentralized Centralized Finance (CeFi) Decentralized Finance (DeFi) Custody Regulated financial intermediaries Self-custody or based on smart contracts Transaction Execution and Settlement Regulated financial intermediaries Via smart contracts Settlement Payment and settlement usually after execution of the trade \u0026ldquo;Atomic\u0026rdquo; settlement (immediate execution and settlement) Governance Financial services provider, trading venue, and/or regulator Software code (\u0026ldquo;code is law\u0026rdquo;), governance token holders Identity KYC (Know Your Customer) requirements necessitate identification Pseudonymization (anonymity in transactions) Collateral Full collateralization not necessary Overcollateralization (greater collateral than required) Cross Interaction Restricted Interoperability with applications on the same blockchain (settlement layer) The execution times are much faster in DeFi compared to standard finance (seconds instead of days). This is why CeFi was looking at ways to do it faster. Why Overcollaterization?\nMost assets in DeFi are volatile (so overcollaterization gives you security on this). Other way is incentivizing honest behaviour from the other one (more secure). Be more secure against an unknown person. The intermediary Intermediary was a main thing about trust. The main problem with DeFi that it was (perhaps) able to solve is the problem of anarchist trust, how can you trust without an institution or intermediary\nIn traditional finance, intermediaries like banks and brokers ensure trust by validating transactions, providing accountability, and managing risks. However, in decentralized finance (DeFi), intermediaries are removed, creating the challenge of \u0026ldquo;anarchist trust\u0026rdquo;, how can participants trust each other without a central authority? DeFi addresses this by using blockchain technology, where transactions are recorded on a transparent, immutable ledger, ensuring security and accountability. Additionally, smart contracts automate transactions, enforcing agreements without the need for intermediaries, and providing trust through decentralized, algorithmic mechanisms. This shift allows individuals to engage in financial activities directly, relying on technology rather than centralized institutions to guarantee outcomes.\nSelected Topics in Private Law: DeFi and Swiss Law Parties of the Contract Under Swiss law, a valid contract requires mutual agreement between two parties, which can also include legal entities. For a contract to exist in the context of decentralized finance (DeFi), there must be identifiable parties behind the smart contract. Without a clear, individualizable person or legal entity, no contract can be concluded, as DeFi platforms often operate without traditional intermediaries or explicit identities.\nClaim Possibility Financial harm in DeFi transactions is protected under specific circumstances, including fraud and hacking (e.g., stealing financial assets). However, if a financial loss occurs due to a program error, Swiss law typically does not grant the right to claim compensation. On the other hand, claims for unjust treatment may be pursued, especially when large sums of money are transferred without an explicit or formal contract.\nContractual Claims in DeFi When it comes to contractual claims in the context of DeFi applications, there are certain prerequisites for concluding a contract:\nResponsibility of a party: In traditional contract law, there must be identifiable contracting parties. In DeFi, this is disputed because of the anonymity and pseudonymity inherent in blockchain systems. Without an individual or legal entity behind the smart contract, some argue there is no valid contract. This is why it is often needed to have a physical person or organization for a smart contract to be legally binding. Software usage is not a declaration of intent and is not usually legally binding contract (while taking a bus is).\nTort Claims and Liability Regarding tort claims, liability for damages in DeFi transactions must be based on a violation of protective legal norms, especially those that apply in property law and criminal law. In cases of pecuniary damage, the violation of a legal norm would be necessary for a tort claim to succeed.\nfinancial harms are protected only under certain cases Fraud Hacking (stealing financial assets) If program is error, financial harm is lost in the court. Unjust treatment claim is possible (a lot of money transferred without contract, but one party would need to have suffered significant hram). Unjust Enrichment Claims Unjust enrichment claims, particularly the recovery of financial advantages obtained without a legal basis (referred to as \u0026ldquo;Leistungskondiktion\u0026rdquo;), are generally not applicable in the DeFi ecosystem. This is due to the concept of \u0026ldquo;code is law,\u0026rdquo; which implies that the smart contract‚Äôs terms are automatically executed as intended, with little room for legal recourse. However, there could still be cases where a claim for unjust enrichment might apply if the conditions of the contract are deemed invalid under Swiss law.\nResponsible Courts in Private International Law In the realm of private international law, determining the appropriate court to hear a case, known as jurisdiction. is essential for resolving cross-border disputes. The Swiss Private International Law Act (PILA) provides a comprehensive framework for establishing jurisdiction in such matters.\nChoosing the Jurisdiction: Under Swiss law, parties to a contract have the autonomy to select the jurisdiction that will govern any disputes arising from their agreement. This is facilitated by the PILA, which allows for the designation of a specific court or jurisdiction in the contract itself. However, this freedom is subject to certain limitations, especially when one of the parties is a consumer.\nConsumer Protection: Swiss law offers enhanced protection to consumers to prevent them from being disadvantaged in legal disputes. According to Article 114 of the PILA, a consumer cannot waive their right to sue in their domicile. This means that even if a contract specifies a different jurisdiction, the consumer retains the right to initiate legal proceedings in their home country. Additionally, actions initiated by the supplier can only be brought in the consumer\u0026rsquo;s domicile, ensuring that consumers are not compelled to litigate in a foreign jurisdiction.\n","permalink":"https://flecart.github.io/notes/introduction-to-decentralized-finance/","summary":"\u003ch2 id=\"financial-markets\"\u003eFinancial Markets\u003c/h2\u003e\n\u003ch4 id=\"uses-of-financial-markets\"\u003eUses of Financial Markets\u003c/h4\u003e\n\u003cp\u003eIn this section, we answer the question of what financial markets are for.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRaising capital\u003c/li\u003e\n\u003cli\u003eEquity and Dept: Equity is ownership in a company, while debt is a loan. (there is also a mezzanine).\u003c/li\u003e\n\u003cli\u003ePrice discovery: The process of determining the price of an asset in the marketplace.\u003c/li\u003e\n\u003cli\u003eLiquidity: pooling people together to have an ease of access to these assets.\u003c/li\u003e\n\u003cli\u003eRisk management: Managing the risk of the assets.\n\u003cul\u003e\n\u003cli\u003eRisks could be: inflation (uncertainty on the value of the money), interest rate (uncertainty on the value of the money), credit risk (uncertainty on the value of the money), market risk (uncertainty on the value of the money), etc.\u003c/li\u003e\n\u003cli\u003eThis allows hedging risks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eThey have a role in economic growth (this is economic theory, we won\u0026rsquo;t delve into this).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"the-shareholders-of-the-market\"\u003eThe Shareholders of the market\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eInvestors\u003c/strong\u003e: People that provide capital to governments and companies in exchange of bonds or stocks\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIntermediaries\u003c/strong\u003e: organizations that facilitate these kinds of exchanges\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMarket data providers\u003c/strong\u003e: we can see these as intermediaries that sell data about markets (they usually sell licenses, for example Bloomberg does this).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIssuers\u003c/strong\u003e: organizations that sell financial assets.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRegulators\u003c/strong\u003e: ensure the market is fair and is working properly (usually government agencies that create the rules).\n\u003cul\u003e\n\u003cli\u003eFor example, it is quite difficult to get into the market, from a regulatory point of view.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"collateral-and-over-collateralization\"\u003eCollateral and Over-Collateralization\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eCollateral\u003c/strong\u003e refers to assets or property that a borrower pledges to a lender as security for a loan. If the borrower fails to repay, the lender has the right to seize or sell the collateral to recover the outstanding debt.\u003c/p\u003e","title":"Introduction to Decentralized Finance"},{"content":"The course will be more about the the quantization, talking about lossless and lossy compression (how many bits will be needed to describe something? This is not a CS course so it will not be so much algorithmically focused course), then we will talk about channel and capacity and DMC things. Most of the things explained in the Lapidoth course will be theoretical there will be some heavy maths.\nThe professor starts with some mathy definitions (not very important, just that the $\\mathbb{E}[ \\cdot]$ needs a domain to be defined, so notations like $\\mathbb{E}[x]$ do not make sense, while $\\mathbb{E}[g(x)]$ do make sense because $g(x) : \\mathcal{X} \\to \\mathbb{R}$).\nThen we start to define the Entropy so go there :)\nBlock diagram of a communications system This is the classical diagram, we will see in this course most of the lossy and lossless quantization part and the channel capacity, so not much! But still some work!","permalink":"https://flecart.github.io/notes/introduction-to-information-theory/","summary":"\u003cp\u003eThe course will be more about the the quantization, talking about lossless and lossy compression (how many bits will be needed to describe something? This is not a CS course so it will not be so much algorithmically focused course), then we will talk about channel and capacity and DMC things.\nMost of the things explained in the Lapidoth course will be theoretical there will be some heavy maths.\u003c/p\u003e\n\u003cp\u003eThe professor starts with some mathy definitions (not very important, just that the $\\mathbb{E}[ \\cdot]$ needs a domain to be defined, so notations like $\\mathbb{E}[x]$ do not make sense, while $\\mathbb{E}[g(x)]$ do make sense because $g(x) : \\mathcal{X} \\to \\mathbb{R}$).\u003c/p\u003e","title":"Introduction to Information Theory"},{"content":"The landscape of NLP was very different in the beginning of the field.\n\u0026ldquo;But it must be recognized that the notion \u0026lsquo;probability of a sentence\u0026rsquo; is an entirely useless one, under any known interpretation of this term 1968 p 53. Noam Chomsky.\nProbability was not seen very well (Chomsky has said many wrong things indeed), and linguists were considered useless. Recently deep learning and computational papers are ubiquitous in major conferences in linguistics, e.g. ACL.\nOne of the main aims of linguistics is understanding the structure of human language. How are we able to speak it so naturally, when we are not able to formally describe it? Other natural phenomenon are clearly described, but not language. And another thing is that nobody exposes these idea to young people during middle or high school! Even if it\u0026rsquo;s so ubiquitous. In Prof. Cotterell\u0026rsquo;s opinion, Linguistics is a science, even if it\u0026rsquo;s catalogued in humanities. Mathematics is very useful to study language (this is not very intuitive). For Cotterell, linguistics can be as formal as physics from a mathematical point of view. A weird thing is that linguistics PhD people usually have no college-math experience, and this is as if you are starting a physics PhD without any maths, in Cotterell\u0026rsquo;s point of view. The main difference is that the maths of linguistics is mostly discrete.\nChomsky proposed the idea of competence and performance. (Similar thing explained in (Mahowald et al. 2023)).\nCompetence asserts that there is a true grammar for a language. We have those grammars for programming languages, but we don\u0026rsquo;t clearly know for human languages. This is much studied especially for the study of compilers. And Chomsky 1943 McCullochs paper for perceptrons invented finite-state automata in the same paper!?!? The whole objective is trying to build this function that says yes or no for a syntactical correct sentence.\nPerformance is studied by psycholinguistists. They want to know how humans produce language. But humans usually don\u0026rsquo;t use the competence to produce their sentences.\nWhat is NLP? A set of methods and algorithms for making natural languages accessible to computers.\nE.g. autocorrect, grammarly, machine translation, question answering, many many things, so a quite broad field.\nWhat is linguistics? Linguistics studies properties of languages. Computational linguistics uses techniques from computer science to study language. This is the main difference with NLP. In NLP computers are central, in computational linguistics they are aiding devices.\nReferences [1] Mahowald et al. ‚ÄúDissociating Language and Thought in Large Language Models: A Cognitive Perspective‚Äù 2023\n","permalink":"https://flecart.github.io/notes/introduction-to-natural-language-processing/","summary":"\u003cp\u003eThe landscape of NLP was very different in the beginning of the field.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;But it must be recognized that the notion \u0026lsquo;probability of a sentence\u0026rsquo; is an entirely useless one, under any known interpretation of this term 1968 p 53. \u003cem\u003eNoam Chomsky\u003c/em\u003e.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eProbability was not seen very well (Chomsky has said many wrong things indeed), and linguists were considered useless. Recently deep learning and computational papers are ubiquitous in major conferences in linguistics, e.g. ACL.\u003c/p\u003e","title":"Introduction to Natural Language Processing"},{"content":"What is a neural system? A neural system is an intricately organized network of specialized cells‚Äîprimarily neurons, along with a variety of supportive glial cells‚Äîthat processes and transmits information via electrical and chemical signals. In biological organisms, such systems underpin the entire nervous system, coordinating functions that range from basic reflexes to the complex interplay of perception, thought, and behavior. Early studies in neurobiology revealed that even simple neural circuits can generate coordinated responses, while modern neuroscience has shown that vast, hierarchically structured networks (such as the central and peripheral nervous systems) are responsible for the rich tapestry of animal behavior and cognition\nTypes of functions Sensory systems represent information about the state of the organism and its environment. Motor systems organize and generate actions. Associational systems link the sensory and motor sides of the nervous system.\nThe Gene look. At the beginning, scientists attempted to look for details of what made humans what we are, what made us intelligent. One clear indicator that influences that is the generic code.\nWorm has around 20k genes. Drosophila around 15k Mouse 27k Humans 35k Most of the genes are expressed in the developing and living brain. Neither the size of the brain. Another possibility is the ratio between the size of the brain and the body size. Another possible parameter is the density of the neural connections.\nTODO: continue on this, very superficial until now.\nThe postgenomic era One of the most promising dividends of sequencing the human genome has been the realization that one or a few genes, when altered (mutated), can begin to explain some aspects of neurological and psychiatric diseases.\n","permalink":"https://flecart.github.io/notes/introduction-to-neural-sytems/","summary":"\u003ch4 id=\"what-is-a-neural-system\"\u003eWhat is a neural system?\u003c/h4\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA neural system is an intricately organized network of specialized cells‚Äîprimarily neurons, along with a variety of supportive glial cells‚Äîthat processes and transmits information via electrical and chemical signals. In biological organisms, such systems underpin the entire nervous system, coordinating functions that range from basic reflexes to the complex interplay of perception, thought, and behavior. Early studies in neurobiology revealed that even simple neural circuits can generate coordinated responses, while modern neuroscience has shown that vast, hierarchically structured networks (such as the central and peripheral nervous systems) are responsible for the rich tapestry of animal behavior and cognition\u003c/p\u003e","title":"Introduction to Neural Sytems"},{"content":"Introduzione This is a short introduction to statistical learning, made with the help of the book (James et al. 2023).\nstatistical learning refers to a set of approaches for estimating $f$ .\nUtilizzi del statistical learning Solitamente sono due gli utilizzi Predizione e inferenza. Per predizione intendiamo il miglior modello che possa produrre le Y che ancora non conosciamo. Per inferenza significa il miglior modello f per predire Y che conosciamo.\nNel primo caso la funzione migliore $f$ potrebbe benissimo restare sconosciuta, ci importa solamente che predica con accuratezza, mentre nel secondo caso vorremmo anche conoscere $f$.\nIn un certo senso l\u0026rsquo;inferenza ci permette di calcolare una specie di legge fisica, (√® incorretto chiamarlo in questo modo, ma credo dia l\u0026rsquo;idea), ossia permette la comprensione del perch√© avendo questi input, potr√≤ avere quei output. NOTA: avendo questa comprensione potrei anche fare predizioni su dati che non esistono, credo.\nErrore riducibile e irriducibile Questo √® un concetto statistico abbastanza nuovo, utile per parlare di stima di modelli statistici. Supponiamo di avere una serie di dati solitamente indicati con $X$ , vogliamo con questi andare a predire la variabile dipendente $Y$. Solitamente andiamo anche ad introdurre un errore rappresentato con $\\varepsilon$ . Questo √® un errore indipendente da $X$, ossia non possiamo predirlo utilizzando X.\nLa branca dell\u0026rsquo;apprendimento statistico vuole utilizzare X per andare a predire Y. Per√≤ il meglio che pu√≤ fare resterebbe sempre solamente una funzione $f$ che abbia quell\u0026rsquo;errore che lo faccia variare. Quell\u0026rsquo;errore potrebbe essere dovuto a informazioni che non conosciamo oppure solamente a cose che non possono essere misurate (elementi che sono principalmente dovuti al caso, che difficilmente avremmo potuto utilizzare per misurarlo)\nFormalizzazione di sopra $$ E[Y - \\hat{Y}]^2 = E[(f(X) + \\varepsilon) - \\hat{f}(X)]^2 = [f(X) - \\hat{f}(X)]^2 + var(\\varepsilon) = \\text{ bias }^{2} + var(\\varepsilon) $$ Osservando che X √® una costante in questo caso, e ci interessa solamente la varianza. Si potrebbe intendere che la prima parte √® un errore riducibile (pu√≤ essere fino a 0), mentre la varianza dell\u0026rsquo;errore √® parte di errore irriducibile.\nTipologie di modelli Principalmente esistono due tipologie di modelli, proveremo a parlarne estensivamente qui sotto:\nModelli parametrici L\u0026rsquo;inferenza/predizione con questo genere di modelli si fa in due step:\nScelta del modello (lineare? Quadratico? rete neurale? allora architettura della rete) Algoritmo di scelta dei parametri del modello Vedere sul libro pagina 31 per degli esempi. La caratteristica negativa di questo √® che √® fortemente dipendente dal nostro modello scelto, che non sempre pu√≤ risultare essere la migliore per stimare la funzione che abbiamo:\nThe potential disadvantage of a parametric approach is that the model we choose will usually not match the true unknown form of $f$ .\nModelli non parametrici Non-parametric methods do not make explicit assumptions about the functional form of $f$ . Instead they seek an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly.\nUn esempio di questo genere di modelli potrebbero essere splines, che sono molto pi√π variabili di un modello parametrico\nVantaggio principale sui parametrici by avoiding the assumption of a particular functional form for f , they have the potential to accurately fit a wider range of possible shapes for f .\nSvantaggio principale Dato che non devo imparare solamente dei parametri, ho bisogno di molto pi√π dati affinch√© io sia accurato nella predizione\nReferences [1] James et al. ‚ÄúAn Introduction to Statistical Learning: With Applications in Python‚Äù Springer International Publishing 2023\n","permalink":"https://flecart.github.io/notes/introduction-to-statistical-learning/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003cp\u003eThis is a short introduction to statistical learning, made with the help of the book \u003ca href=\"https://link.springer.com/10.1007/978-3-031-38747-0\"\u003e(James et al. 2023)\u003c/a\u003e.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003estatistical learning refers to a set of approaches for estimating $f$ .\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch3 id=\"utilizzi-del-statistical-learning\"\u003eUtilizzi del statistical learning\u003c/h3\u003e\n\u003cp\u003eSolitamente sono due gli utilizzi \u003cstrong\u003ePredizione\u003c/strong\u003e e \u003cstrong\u003einferenza\u003c/strong\u003e. Per predizione intendiamo il miglior modello che possa produrre le Y che ancora non conosciamo.\nPer inferenza significa il miglior modello f per predire Y che conosciamo.\u003c/p\u003e","title":"Introduction to statistical learning"},{"content":"This small note is an introduction to Topology that follows the introductory arguments of (Armstrong 2013).\nEuler\u0026rsquo;s Theorem We will start our journey in topology following a classical example in the history of Mathematics the relation:\n$$ v - e + f = 2 $$ Valid for classical Polyhedrons.\nBasic definitions Polyhedron It\u0026rsquo;s a collection of plane polygons (see Programmazione lineare#Poliedro) such that:\nEvery polygon shares each of its edges with exactly another polygon We have vertexes that can be shared by many polygons. Informally we have a piece of surface with a vertex. Theorem statement If we have a Polygon $P$ such that\nAny two vertices of $P$ are connected through a path in the edges. (connected principle) Any loop on $P$ made of its vertices made of straight line segments (we don\u0026rsquo;t need to pass through the edges) separates $P$ in two pieces. (informally if we cut there then the surface does not separate completely). Then we have $v - e + f = 2$, where $v$ are the number of vertices, $e$ the number of edges and $f$ the number of faces. The two conditions above are justified by the counter example observations: . Which clearly do not follow the theorem\nSimple proof Here, I will just sketch the general proof (there will be some interesting observation, but that is left for later). We know that vertices + edges are just a graph, and for every graph there is a easy way to find a tree $T$ with all of the graph nodes. By a property of the trees, we know that every tree has $v - e = 1$, easily provable with induction on the number of nodes. The we construct some sort of a dual tree which we call $\\Gamma$ built in this way.\nVertices are random points on every face of $P$ Two vertices are connected if their corresponding faces share an edge, and this edge does not belong to $T$. It can be proven that $\\Gamma$ is indeed a tree, thanks to the 2 initial hypothesis, and then we know that $$ v - e + f = v(T) - \\left[ e(T) + e(\\Gamma)\\right] - v(\\Gamma) = \\left[ v(T) - e(T) \\right] + \\left[ v(\\Gamma) - e(\\Gamma) \\right] = 1 + 1 = 2 $$ The beautiful observation about this proof, is that every polygon that satisfies those hypothesis can be divided in two parts, which imply it is topologically equivalent to split a sphere (this is why it\u0026rsquo;s 2!) Which means that it is just a deformed sphere from the faces point of view.\nLegendre\u0026rsquo;s Proof Before we can understand this proof, we need to understand how to calculate the area of a spherical polygon which is just a polygon mapped to the surface of a unit sphere.\nSpherical Polygon Area $$ \\sum_{i = 1}^{k} \\alpha_{i} + 2\\pi - n\\pi $$ This value is known as the excess in spherical geometry, and one can prove that the area is equal to $A = E\\cdot R^{2}$ where $R$ is the radius of the sphere. This is also known as Girard\u0026rsquo;s theorem.\nProof: If you have Girard\u0026rsquo;s theorem (advised to check the link for a visualization), useful for simple triangles, then it\u0026rsquo;s easy to recompose everything and have that theorem, in this case we will just prove Girard\u0026rsquo;s theorem:\n$$ 2\\pi : \\alpha = 4\\pi : \\text{ Area} \\implies \\text{Area} = 2\\alpha $$$$ 2(2\\alpha + 2\\beta + 2\\gamma) = 4\\pi + 2A + 2A \\implies A = \\alpha + \\beta + \\gamma - \\pi = E $$ The proof So now we know that a specific spherical polygon\u0026rsquo;s area is $\\sum_{i = 1}^{k} \\alpha_{i} - (2 - n) \\pi$ We now sum over all the polygons and we obtain $2\\pi v - 2n\\pi e + 2\\pi f = 4\\pi$ where $v$ is the number of vertices, $e$ of edges and $f$ faces, that is the number of polygons. This is true because every vertex at the end is counted as $2\\pi$ in radians, and every edge is counted twice, and we are summing $f$ polygons so we have the last term. Simplifying the $2\\pi$ we obtain $v - e + f = 2$ which is the Euler\u0026rsquo;s theorem. This is a nice proof, and quite easy after you know the Spherical Polygon area lemma.\nReferences [1] Armstrong ‚ÄúBasic Topology‚Äù Springer Science \u0026amp; Business Media 2013\n","permalink":"https://flecart.github.io/notes/introduction-to-topology/","summary":"\u003cp\u003eThis small note is an introduction to Topology that follows the introductory arguments of (Armstrong 2013).\u003c/p\u003e\n\u003ch2 id=\"eulers-theorem\"\u003eEuler\u0026rsquo;s Theorem\u003c/h2\u003e\n\u003cp\u003eWe will start our journey in topology following a classical example in the history of Mathematics the relation:\u003c/p\u003e\n$$\nv - e + f = 2\n$$\u003cp\u003e\nValid for classical Polyhedrons.\u003c/p\u003e\n\u003ch3 id=\"basic-definitions\"\u003eBasic definitions\u003c/h3\u003e\n\u003ch4 id=\"polyhedron\"\u003ePolyhedron\u003c/h4\u003e\n\u003cp\u003eIt\u0026rsquo;s a collection of \u003cem\u003eplane polygons\u003c/em\u003e (see \u003ca href=\"/notes/programmazione-lineare/#poliedro\"\u003eProgrammazione lineare#Poliedro\u003c/a\u003e) such that:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eEvery polygon shares each of its edges with exactly another polygon\u003c/li\u003e\n\u003cli\u003eWe have vertexes that can be shared by many polygons.\nInformally we have a \u003cstrong\u003epiece of surface\u003c/strong\u003e with a vertex.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"theorem-statement\"\u003eTheorem statement\u003c/h3\u003e\n\u003cp\u003eIf we have a Polygon $P$ such that\u003c/p\u003e","title":"Introduction to Topology"},{"content":"Blockchain stack Vogliamo andare ora a descrivere la stack delle blockchain, in modo simile a quanto fatto con le internet, perch√© anche qui possiamo organizzarlo a stack!\nNota: le astrazioni fra questi layer non sono definiti bene come osi osint.\nLayer - 0 Internet Internet (semi-reliable point-to-point communication) and cryptography (specifically, cryptographic hash functions and secure digital signatures).\nLayer - 1 Consensus Ci concentreremo sui protocolli di questo per la maggior parte di quanto faremo! Bitcoin, Ethereum sono tutti a questo livello.\nLayer - 2 Scaling layer Strano lol, cerca di rendere il livello 1 pi√π efficiente. Le funzionalit√† sono le stesse, ma vorremmo che sia molto pi√π veloce, probabilmetne √® un livello temporaneo che scomparir√† in futuro, ma per ora si fa molta ricerca su questo.\nLayer - 3 application Che tratta di smart contracts e applicazioni utente. Easy su questa roba, troppa roba, quindi la possiamo ignorare, perch√© non andremo a fare cose a questo livello.\nWhy it‚Äôs new Computing paradigm Big programmable computer that lives on the sky! Owned by all users!\nOpen access computer! Global computational platform wo. Something with a very high potentiality!\nNot digital money! I soldi sono solamente un mezzo nuovo mezzo di scambio per questa robba. Ad esempio se utilizzi tropper risorse a questo computer, √® giusto che paghi l‚Äôenergia per runnare quello di cui hai bisogno!\nPrinciples over protocols Vogliamo andare ad individuare alcuniprincipi belli ** e vedere come vengono applicati sui protocolli!\n","permalink":"https://flecart.github.io/notes/introduzione-a-blockchain/","summary":"\u003ch2 id=\"blockchain-stack\"\u003eBlockchain stack\u003c/h2\u003e\n\u003cp\u003eVogliamo andare ora a descrivere la stack delle blockchain, in modo simile a quanto fatto con le internet, perch√© anche qui possiamo organizzarlo a stack!\u003c/p\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Introduzione a blockchain/Untitled.png\" alt=\"image/universita/ex-notion/Introduzione a blockchain/Untitled\"\u003e\n\u003cp\u003eNota: le astrazioni fra questi layer non sono definiti bene come osi osint.\u003c/p\u003e\n\u003ch3 id=\"layer---0-internet\"\u003eLayer - 0 Internet\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eInternet (semi-reliable point-to-point communication) and cryptography (specifically, cryptographic hash functions and secure digital signatures).\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch3 id=\"layer---1-consensus\"\u003eLayer - 1 Consensus\u003c/h3\u003e\n\u003cp\u003eCi concentreremo sui protocolli di questo per la maggior parte di quanto faremo! Bitcoin, Ethereum sono tutti a questo livello.\u003c/p\u003e","title":"Introduzione a blockchain"},{"content":"Lo scopo della logica √®\nCorrettezza del ragionamento, anche verificata attraverso algoritmi predittivi. Si svilupperanno linguaggi logici I metodi per la veridicit√† di una sentenza. Possibilit√† e metodi del ragionamento logico Completezza e non-deducibilit√† di alcuni ragionamenti Necessit√† di completezza delle ipotesi: pi√π ipotesi = ragionamento valido? Completezza delle tesi, impossibile. Una necessit√† della logica √® Meta-logica:\nLa logica si deve cercare di basare su certe basi, spesso queste non sono certe, per√≤ danno un certo grado di sicurezza ‚Üí Se la base √® solida allora tutto il ragionamento di una parte √® giusta\n0.1 Storia Questo campo di studi √® nato dopo una necessit√† del secolo precedente quando si tentava di dare delle basi solide alla matematica ‚Üí La matematica (e informatica)si fonda sulla logica.\nGuardare la storia di Russel, Godel.\n0.2 Tipologie di logica 0.3 Processo di ragionamento Slide 18 per esempio di problema risolto con questo processo.\n0.4 Differenze con la matematica La matematica si interessa principalmente sull\u0026rsquo;esistenza di soluzioni, e dimostrazioni, ma non rigorose quanto le dimostraizoni logiche. L\u0026rsquo;informatica applicata classica √® meno rigorosa, si basa principalmente sui test, anche se un logico pu√≤ dimostrare la correttezza di una soluzione informatica.\nInoltre l\u0026rsquo;informatica indaga la possibilit√† di implementazione di alcune soluzioni matematiche, cio√® il modo per calcolare possibili soluzioni, anche con la limitatezza delle risorse.\n0.5 Logica in programmazione 0.5.1 Usi e costi C\u0026rsquo;√® un altissimo costo per la dimostrazione formale di un programma, secondo i dati Intel c\u0026rsquo;√® bisogno di circa 10x mesi uomo per creare una dimostrazione assistita di questo genere.\nPer questo genere viene utilizzato solamente in software critico cio√® il codice che controlla processi che se buggati possono creare ingenti danni economici, come centrali nucleari, smartcard, microprocessori Intel, controlli aereo e simili\n0.5.2 Processo di dimostrazione Definire la specifica del software in modo che possa fare sempre ci√≤ che deve fare Creare la semantica del programma, come il programma √® eseguito. Formula logica che √® la descrizione formale del funzionamento del programma. Creare una implicazione fra ci√≤ che il software deve fare secondo la semantica e ci√≤ che veramente fa. Non perdere punti 1 Logica Proposizionale 1.1 Senso e denotazione Sentenza\nDichiarativa quando √® assertiva, ovvero dichiara una proposizione di verit√†. Nomi\nPu√≤ avere funzioni denotative e connotative (il senso), spesso questo concerne solamente il problema denotativo Proposizioni\nSono delle sentenze che hanno un chiaro valore di verit√† Possono essere atomiche o composte. esso questo concerne solamente il problema denotativo Proposizioni\nSono delle sentenze che hanno un chiaro valore di verit√† Possono essere atomiche o composte. ","permalink":"https://flecart.github.io/notes/introduzione-a-logica/","summary":"\u003cp\u003eLo scopo della logica √®\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eCorrettezza\u003c/strong\u003e del ragionamento, anche verificata attraverso algoritmi predittivi.\n\u003cul\u003e\n\u003cli\u003eSi svilupperanno linguaggi logici\u003c/li\u003e\n\u003cli\u003eI metodi per la veridicit√† di una sentenza.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePossibilit√†\u003c/strong\u003e e metodi del ragionamento logico\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCompletezza e non-deducibilit√†\u003c/strong\u003e di alcuni ragionamenti\n\u003cul\u003e\n\u003cli\u003eNecessit√† di completezza delle ipotesi: pi√π ipotesi = ragionamento valido?\u003c/li\u003e\n\u003cli\u003eCompletezza delle tesi, impossibile.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUna necessit√† della logica √® Meta-logica:\u003c/p\u003e\n\u003cp\u003eLa logica si deve cercare di basare su certe basi, spesso queste non sono certe, per√≤ danno un certo grado di sicurezza ‚Üí Se la base √® solida allora tutto il ragionamento di una parte √® giusta\u003c/p\u003e","title":"Introduzione a Logica"},{"content":"L‚Äôottimizzazione combinatoria √® un altro nome per la ricerca operativa. √à uno strumento utile a prendere le decisioni migliori, fatto sta che √® anche molto utile al machine learning e si potrebbe dire che ne sia una base, questa √® una cosa molto buona.\nRicerca operativa Questo √® un campo a forte impatto economico perch√© prova a minimizzare i costi e massimizzare i profitti.\nSteps üü©, üü® Individuazione del problema (almeno riconoscere che ci sia un problema) Raccoglimento dei dati Modellizzazione del problema Ricerca di una soluzione Analisi dei risultati della soluzione La ricerca operativa si interessa principalmente degli step 3 e 4, nonostante gli steps non sempre vengono eseguiti in maniera lineare, ma c‚Äô√® un ciclo di feedback a riguardo.\nModelli (3) üü© Un modello √® una descrizione astratta, e scritta nel linguaggio della matematica, della parte di realt√† utile al processo decisionale\nGiochi\nCi sono una serie di agenti in un ambiente con alcune regole precise, i risultati sono visti come causati dall\u0026rsquo;interazione fra gli agenti. (Abbastanza recente, presente nel secolo scorso)\nEquilibrio Strategia sono due concetti molto interessanti per questo tipo di modellizzazione.\nSimulazioni\nSi cerca di capire cosa succede facendo una simulazione, √® certo che la possibilit√† di generare numeri casuali √® fondamentale in questo passo. Eg metodi monte-carlo\nAnalitici\nQuesti sono i modelli interessanti alla ricerca operativa perch√© tratta in modo matematico il modello, cercando il minimo o massimo di una funzione (si vede qui che ci sarebbe biosgno dianalisi, fa strano che non lo abbia messo nei prerequisiti).\nSono fedeli al problema, e devono essere astratti.\nUn problema Un problema non √® nient‚Äôaltro che una domanda, espressa in termini generali, ma la cui risposta dipende da un certo numero di parametri e variabili.\nQuindi possiamo affermare che un problema di ricerca operativa venga descritta tramite:\nParametri e variabili che sono in gioco Quanto la soluzione deve soddisfare per essere valida Sembra un p√≤ come se fosse un problema di CSP\nParametri e variabili üü© √à importantissimo fare una distinzione fra parametri e variabili.\nVariabile √® un valore ignoto che vorremmo trovare, spesso in funzione di parametri. Parametri sono valori, che possono essere conosciuti o meno, che supponiamo essere conosciute. eg. $ax^2 + bx + c=d$ i parametri sono $a,b,c,d$ e la variabile √® solo $x$, perch√© noi vorremmo trovare x in funzione dei parametri.\nIstanza di un problema üü© Con la definizione di parametri √® variabili si fa una distinzione fra una istanza di un problema, oppure il problema in senso generale. Quando i parametri non sono pi√π simbolici, allora √® una istanza, perch√© effettivamente ora possiamo andare a calcolare la soluzione.\nQuindi una sostituzione di tutti i parametri simbolici, con valori reali (probabilmetne ottenuti da osservazione, da dati) si ha una istanza di una soluzione.\nAmmissibilit√† delle soluzioni üü© Vogliamo cercare ora di definire da un punto di vista matematico cosa sia l\u0026rsquo;insieme delle soluzioni ammissibili.\nOssia, vorremmo trovare gli $x$, le variabili prese in un campo grande, come pu√≤ essere $\\R$. Quindi un primo step √® trovare l‚Äôinsieme delle soluzioni in funzione dei parametri.\nLe variabili che soddisfano tutti i costraints sono $x \\in \\mathbb{F}_p \\subseteq \\mathbb{G}$., con G un insieme in cui vivono le variabili.\nLe variabili $x \\in \\mathbb{G} - \\mathbb{F}$ sono non ammissibili.\nFunzione obiettivo !! üü© √à una misura di una bont√† della soluzione. spesso definita come $c_p : \\mathbb{F}_p \\to \\R$, ossia dalle soluzioni ammissibili ai Reali. Vorremmo cercare di minimizzare o massimizzare la soluzione a questo problema con questa funzione di valutazione o obiettivo. Si pu√≤ vedere molto facilmente che il problema di massimo √® equivalente al problema di minimo invertendo.\nSoluzione ottima √® il valore di $x \\in \\mathbb{F}_p : x = min \\{c_p(y) : y \\in \\mathbb{y}_p \\}$, definiremo questa x come $Z_p = x$\nValore ottimo √® $c_p(x) \\in \\mathbb{F}_p$ con $x$ il valore di sopra.\nCatalogazione dei problemi Ottimizzazione, decisione e certificato üü© Problema di ottimizzazione\nVogliamo trovare il minimo in qualcosa. Ma questo di solito √® un problema molto difficile perch√© bisogna prima trovare le soluzioni possibili, e poi bisogna anche trovare la migliore fra queste soluzioni possibili\nProblema di decisione\nSi tratta di cercare una soluzione $g: g \\in \\mathbb{F}_p$\nProblema di certificato\nVogliamo cercare di verificare se una soluzione √® nell\u0026rsquo;insieme che ci piaccia.\nsi tratta di verificare che se data $g$ si ha che $g \\in \\mathbb{F}_p$\nConversione da certificazione e ottimizzazione üü® Possiamo dire che un problema di certificazione dare dei valori fissati, quelli che ci piacciono sono di valore basso, in questo modo converto subito il valori che ci piacciono in questo caso come soluzioni del problema di ottimizzazione:\n$c_p(x) = 0 : x \\in F_p$, $c_p(x) = 1: x \\not\\in F_p$\nPossiamo anche convertire un problema di ottimizzazione in un problema decisionale, se conosciamo il costo ottimo √® semplice formalizzarlo, altrimenti si fa $\\leq k$ un valore fisso scelto\nSlide\nTipi di soluzione ai problemi üü©- Vuoto\nNon c\u0026rsquo;√® nessuna soluzione, faremo finta che il costo per implementare la soluzione a questo problema sia infinito\n$Z_p = \\infty$\nIllimitato (inferiormente o superiormente)\nOssia ho troppe soluzioni ammissibili,e possono prendere sempre una soluzione che abbia un costo minore:\nIn questo caso posso dire che $Z_p = -\\infty$ nel caso di un problema di minimizzazione.\nDi solito sono problemi artificiosi, nel mondo reale non succede quasi mai, anch emeno volte del vuoto.\nOttimo Finito, soluzione ottima non finita\nNel caso in cui esiste un costo finito, ma non esiste nel nostro insieme di partenza una soluzione che abbia questo costo\nesempio:\n$\\inf \\{ x \\in \\R : x \u003e 0\\}$, il minimo √® in 0, ma nessuno ci arriva.\nAd esempio utilizzare delle relazioni lasche evita questo problema.\nOttimo finito e soluzione finita\nCaso che ci piace\nAlgoritmi esatti e euristici üü©-, üü® Ossia descriviamo l‚Äôalgoritmo esatto e sappiamo che in output sar√† la soluzione perfetta, solo che la maggior parte dei casi √® troppo lento.\nL‚Äôalgoritmo euristico deve restituire un valore che sia simile al valore ottimo, quindi spesso √® molto pi√π efficiente. Possiamo in questo caso definire un concetto di approssimazione inferiore e superiore\nLa qualit√† dell‚Äôalgoritmo euristico si pu√≤ misurare col concetto di errore, quindi sia $R_p(g)$ l‚Äôerrore relativo rispetto al valore ottimo per questo problema, allora si pu√≤ dire che l‚Äôalgoritmo √® $\\varepsilon$-approssimato quando produce soluzioni $g :$ $R_p(g) \\leq \\varepsilon$\nRilassamenti üü©, üü® Vogliamo cercare di applicare le soluzioni del problema per permettere l‚Äôesistenza di algoritmi di complessit√† inferiori ( e per i problemi di minimo provare ad approssimare al ribasso, in modo tale che la soluzione ottima reale non √® meno della soluzione trovata\nSlide\nLa nota principale √® quando la soluzione del problema rilassato √® esattamente uguale al problema iniziale, in questo caso posso concludere di aver gi√† trovato la soluzione ottimale per il problema iniziale.\n","permalink":"https://flecart.github.io/notes/introduzione-a-ottimizzazione-combinatoria/","summary":"\u003cp\u003eL‚Äôottimizzazione combinatoria √® un altro nome per la ricerca operativa. √à uno \u003cstrong\u003estrumento\u003c/strong\u003e utile a prendere le decisioni migliori, fatto sta che √® anche molto utile al machine learning e si potrebbe dire che ne sia una base, questa √® una cosa molto buona.\u003c/p\u003e\n\u003ch2 id=\"ricerca-operativa\"\u003eRicerca operativa\u003c/h2\u003e\n\u003cp\u003eQuesto √® un campo a \u003cstrong\u003eforte impatto economico\u003c/strong\u003e perch√© prova a minimizzare i costi e massimizzare i profitti.\u003c/p\u003e\n\u003ch3 id=\"steps--\"\u003eSteps üü©, üü®\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eIndividuazione del problema (almeno riconoscere che ci sia un problema)\u003c/li\u003e\n\u003cli\u003eRaccoglimento dei dati\u003c/li\u003e\n\u003cli\u003eModellizzazione del problema\u003c/li\u003e\n\u003cli\u003eRicerca di una soluzione\u003c/li\u003e\n\u003cli\u003eAnalisi dei risultati della soluzione\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eLa ricerca operativa si interessa principalmente degli step 3 e 4, nonostante gli steps non sempre vengono eseguiti in maniera lineare, ma c‚Äô√® un ciclo di feedback a riguardo.\u003c/p\u003e","title":"Introduzione a ottimizzazione Combinatoria"},{"content":"Questa nota raccoglie note introduttive al corso di reti dei calcolatori fatto all\u0026rsquo;universit√† di Bologna.\n0.1.1 Definizione di rete di calcolatori (2) üü©- I requisiti sono principalmente 2\nEssere autonomi nel calcolo (capacit√† di eseguire dei programmi) Essere interconnessi (capacit√† di ricevere ed inviare dei segnali) Gli scopi sono principalmente per la comunicazione fra utenti o calcolatori.\nNon-esempi\nRete telefonica, non sono autonomi Rete televisiva Esempi\nSmartphones con wi-fi WWW E-mail Una rete di calcolatori √® un insieme di dispositivi autonomi, cio√® in grado di eseguire e svolgere autonomamente i compiti programmati di calcolo e di comunicazione, interconnessi tra loro da supporti fisici alla trasmissione di segnali. Non sono considerate reti di calcolatori, ad esempio, n√© le reti di comunicazione telefonica (i cui terminali telefonici non sono dispositivi autonomi), n√© le reti di distribuzione televisiva (in quanto i televisori non sono dispositivi autonomi in grado di comunicare informazione). Nel prosieguo della presentazione, con il generico termine di ‚Äúrete‚Äù o ‚Äúrete di comunicazione‚Äù intenderemo implicitamente solo le reti di calcolatori elettronici. Con l‚Äôavvento dei calcolatori elettronici, e con la loro diffusione tra comunit√† sempre pi√π grandi di utenti, √® emersa l‚Äôesigenza e l‚Äôutilit√† di fornire un supporto alla comunicazione tra utenti, attraverso l‚Äôuso del calcolatore, supportando innovativi servizi di comunicazione per l‚Äôutente, quali ad esempio il World Wide Web e la posta elettronica. In tempi pi√π recenti si sono sviluppati ulteriormente i sistemi di rete includendo Internet of Things (IoT), reti senza fili (Wireless), ecc. Le necessit√† di comunicare e condividere informazione sono tra i principali motivi che favoriscono la nascita e lo sviluppo di reti di calcolatori. La fruizione dell‚Äôinformazione contenuta in questo corso rappresenta un esempio. Un ulteriore aspetto che ha favorito la nascita e la diffusione delle reti di calcolatori √® legato alla possibilit√† di condividere dispositivi costosi, altrimenti sotto-utilizzati, come ad esempio stampanti o capienti dispositivi di memorizzazione dei dati, e la possibilit√† di accedere e lavorare sui dati di un calcolatore, senza doversi spostare fisicamente sul calcolatore stesso. Una rete di calcolatori pu√≤ consentire di eseguire calcoli complessi in parallelo e in maniera distribuita, aumentando le prestazioni per l‚Äôottenimento dei risultati. In tal senso, le reti rendono possibile la scalabilit√† dei sistemi di comunicazione e di calcolo: il numero di dispositivi usati, e l‚Äôinvestimento relativo, possono essere dimensionati dinamicamente in funzione delle richieste di servizio. In tempi recenti, le reti sono utilizzate in particolare per supportare la comunicazione utente, secondo svariate forme e applicazioni, oppure per supportare la comunicazione diretta tra dispositivi pervasivi e mobili (es. Internet of Things, Wireless Networks), ecc\n0.1.2 Classificazione delle reti (5 principali) üü© Una prima classificazione delle reti di calcolatori si basa sulla dimensione delle reti stesse. Non esiste in generale un criterio ben definito per tale classificazione, ma ci si basa su considerazioni generali, riguardanti la dimensione dell‚Äôarea di copertura geografica della rete, ovvero l‚Äôarea entro la quale possano esistere dispositivi connessi.\nLe reti personali (PAN) sono reti di comunicazione per connettere dispositivi vicini tra loro, ad esempio sul corpo di una persona o entro una stanza. Un esempio potrebbe essere dato dalla connessione di due dispositivi indossabili, sensori e smartphone, oppure calcolatori, una stampante e un agenda elettronica. Le reti personali sono di solito finanziate e gestite dal singolo utente che le utilizza.\nLe reti locali (LAN) sono molto spesso reti gestite e mantenute da organizzazioni, universit√†, enti o aziende. Esse connettono calcolatori nel raggio di qualche centinaio di metri, ad esempio su interi edifici o campus universitari. Ad esempio, la rete delle aule del Dipartimento.\nLe reti metropolitane (MAN) hanno connessioni in un raggio dell‚Äôordine delle decine di chilometri, e possono connettere intere aree urbane. Esse sono mantenute e gestite da fornitori di servizi di comunicazione (provider) e gestori di servizi telefonici.\nLe reti geografiche (WAN) sono reti in grado di coprire distanze internazionali e addirittura planetarie. Tali reti sono mantenute e gestite da enti nazionali e internazionali, oppure da grossi enti o gestori delle comunicazioni. L‚Äôorganizzazione e la struttura di tali reti pu√≤ essere molto complessa, e pu√≤ risultare composta da diverse parti, e da diverse tecnologie, eterogenee e integrate (ad esempio, molte reti collegate tra loro con tecnologie cablate o in fibra, fino a reti basate su comunicazione satellitare senza fili).\nInternet (inter-networking, ossia comunicazione di rete fra rete diverse) √® una rete di reti, composta da molte reti diverse connesse tra loro, integrate grazie a un insieme di regole comuni: i protocolli della rete Internet.\nAlcuni esempi PAN Anche reti all‚Äôinterno del corpo stesso! (es. per autenticazione). (qualcosa che passa da un pezzo del corpo a un altro pezzo). (molto piccola) LAN Alma-wifi (wireless) ‚Üí WLAN MAN Alma-wifi, perch√© ce in molte parti della citt√† (diffusa con ripetitori, che all‚Äôinsieme hanno una rete metropolitana). NOTA: MAN (e pi√π in generale le reti) si possono espandere componendo reti pi√π piccole NOTA: la grandezza della rete influenza i problemi che la rete deve risolvere. WAN Internet C‚Äô√® un problema di comunicazione, come connettere tutti i calcolatori del mondo??? 0.1.3 Evoluzione e costi della rete (storia, non richiesta) üü® Slide\nLo sviluppo delle reti di calcolatori, che ha permesso la nascita di Internet, non sarebbe stato possibile senza una distribuzione dei costi di realizzazione e gestione delle infrastrutture tra molte entit√†.\nUn p√≤ di storia Storicamente, la prima rete di Internet nasce da un esperimento nel 1969, connettendo solo 4 calcolatori di 4 universit√† americane (con linee di telefoni!).\nDa allora molte entit√† hanno dato il loro contributo per lo sviluppo e la diffusione delle reti di calcolatori. All‚Äôinizio del 2003 Internet contava oltre 172 milioni di calcolatori (fonte Internet Software Consortium). Gi√† nel 2017 si parla di oltre 4 miliardi di dispositivi connessi (anche se non tutti connessi allo stesso momento). Entro 5-7 anni si raggiungeranno i 60 miliardi di dispositivi connessi, realizzando l‚Äôavvento dell‚ÄôInternet of Things.\nPoi si √® sviluppata (dal primo esperimento, si racconta che HELL sia stato il primo messaggio, poi c\u0026rsquo;√® stato un system crash) grazie ad ingesti investimenti militari, poi aziende private. Queste aziende private poi rivendono al cliente finale.\nSui costi Per quello che riguarda i costi, la realizzazione, mantenimento e gestione dell‚Äôinfrastruttura di una rete molto ampia richiede investimenti economici elevati, che possono essere maggiori a seconda del grado di avanzamento delle tecnologie e delle prestazioni richieste.\nCosti MAN e WAN Alcune delle infrastrutture principali delle reti estese MAN e WAN (e di Internet) hanno costi affrontabili solo attraverso un consistente investimento e una pianificazione delle ricadute commerciali da parte di consorzi o fornitori di servizi di comunicazione nazionali e multinazionali.\nCosti LAN Tuttavia, la maggior percentuale del complesso delle infrastrutture di rete che compongono Internet risultano essere mantenute e gestite capillarmente da piccoli gestori e piccoli gruppi, con investimenti relativamente modesti per la realizzazione di piccole reti locali (LAN). L‚Äôintegrazione di un insieme molto vasto di reti grandi e soprattutto piccole reti locali, eterogenee e distribuite su tutto il pianeta, ha permesso la crescita incrementale, il successo commerciale e la esplosiva diffusione delle reti su scala globale, fino a Internet.\nCosti utente finale L‚Äôutente delle reti paga tipicamente per i servizi di trasmissione offerti dalle reti, con tariffe che possono essere basate sul tempo di collegamento, sulla quantit√† di dati.\n0.1.4 Valutazione prestazioni della rete (2) üü© Per ci√≤ che riguarda le prestazioni delle reti di calcolatori, l‚Äôutente √® principalmente interessato a due indici: la capacit√† di trasmissione (impropriamente detta velocit√† della rete) e il ritardo del collegamento di rete.\nLa capacit√† di trasmissione si misura sulla base della quantit√† di dati che √® possibile comunicare in un secondo mediante la rete. I dati digitali del calcolatore si misurano in bit o in byte (gruppi di 8 bit), e di conseguenza l‚Äôunit√† di misura usata tipicamente per misurare la capacit√† di trasmissione dei dati di una rete √® il numero di bit oppure di byte trasmessi al secondo (bit/sec, byte/sec). Spesso si usano i prefissi Kilo (K) per le migliaia, Mega (M) per i milioni e Giga (G) per i miliardi di bit o byte al secondo, Tera (T) per le migliaia di miliardi, ecc. (esempio Kbit/sec, Kbyte/sec). Il ritardo del collegamento di rete indica il tempo necessario ai dati per transitare dal mittente al destinatario finale sulla rete. I fattori del ritardo (non solo questi): la distanza fisica del collegamento i tempi necessari alla gestione delle regole dei processi di comunicazione in rete (protocolli) che i dati devono subire durante il loro tragitto. (che pu√≤ essere anche fisico letterale: eg. aereo o furgone, invece che fibra o reti, questo √® un protocollo üôÇ). Variazione del ritardo (es. coda per furgoni, congestione delle linee e simili) Jitter (su quale sia meglio, dipende sempre dagli utilizzi ‚Üí Streaming? o semplice scaricare? a seconda di quanto ci serve √® meglio la rete blu o rossa) Ovviamente sono da preferire reti dotate di basso ritardo, in quanto ci√≤ favorisce la rapidit√† e l‚Äôinterattivit√† del processo di comunicazione. Per fare un parallelo intuitivo, pensando alle reti come a tubi che trasportano bit, la capacit√† di trasmissione equivale al diametro del tubo, mentre il ritardo equivale al tempo che i bit impiegano ad attraversare una serie di tubi in tutta la loro lunghezza.\n0.2 Componenti della rete Introduzione generali dei componenti principali üü©- Slide\nEsempi di pezzi di rete\nLa connessione di un calcolatore a una rete di calcolatori richiede un insieme essenziale di componenti, hardware e software, in aggiunta al calcolatore elettronico di base.\nL‚Äôelemento primario da aggiungere al calcolatore √® il dispositivo (o scheda) di rete: si tratta di un dispositivo hardware di comunicazione, fisicamente collegato al calcolatore, in grado di codificare e trasmettere, oppure ricevere e decodificare i dati inviati dal calcolatore alla rete, e dalla rete al calcolatore.\n0.2.1 Mezzo fisico di trasmissioneüü© sono supporti fisici alla propagazione e trasmissione di segnali, quali cavi o fili elettrici, fibre ottiche, o semplicemente lo spazio tridimensionale nel quale si propagano le onde radio. Tali mezzi di trasmissione realizzano l‚Äôinfrastruttura fisica della rete. Il costo di realizzazione dell‚Äôinfrastruttura di rete rappresenta spesso un fattore rilevante e critico per la diffusione e l‚Äôimplementazione di reti di calcolatori.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Introduzione a reti/Untitled 8.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Introduzione a reti/Untitled 8\u0026quot;\u0026gt; Esempi mezzi di trasmissione\nIl mezzo di trasmissione √® l‚Äôelemento fisico che supporta la propagazione dei segnali trasmessi tra i dispositivi della rete. Ne abbiamo parlato anche nella sezione dispositivi di rete Le connessioni di rete possono essere realizzate mediante tre mezzi di trasmissione diversi:\ncavi conduttori fibre ottiche connessioni senza fili. I cavi di materiale conduttore (cavetti, doppino intrecciato o cavo coassiale), sono in grado di propagare segnali elettrici, cio√® variazioni di tensione e corrente elettrica. Questi mezzi fisici sono i pi√π utilizzati nelle reti locali, e nelle brevi distanze, per il loro buon rapporto tra costo e prestazioni. Oggi tale mezzo trasmissivo √® in grado di supportare trasmissioni dati con una capacit√† dell‚Äôordine del miliardo di bit al secondo (1-2 Gbit/sec).\nLa tecnologia a fibre ottiche √® tecnologicamente avanzata, e si basa sulla trasmissione di segnali ottici, cio√® di luce, vincolata all‚Äôinterno di una sottile fibra di vetro purissimo. La fibra √® sottile come un capello, √® elastica ed √® protetta da una guaina esterna per facilitare il suo impiego. Il costo della fibra non √® molto elevato, tuttavia la fibra √® molto delicata per quanto riguarda la connessione degli estremi (giunzione) e questo influisce molto sui costi di distribuzione e di realizzazione dell‚Äôinfrastruttura di rete. La capacit√† di una fibra ottica pu√≤ arrivare oggi a qualche decina di migliaia di miliardi di bit al secondo (oltre 10000 Gbit/sec).\nOnde elettromagnetiche e dalla loro propagazione nello spazio. Esempi in tal senso sono forniti dalle onde radio e dalla luce infrarossa. Tali tecnologie vengono dette senza fili (wireless). Le reti senza fili sono molto interessanti, e la loro diffusione √® oggi esplosiva, in quanto permettono la mobilit√† dei dispositivi e degli utenti. La capacit√† dei collegamenti senza fili pu√≤ arrivare oggi a qualche decina di milioni di bit al secondo (1- 54 Mbit/sec). Il limite della tecnologia senza fili √® dato dalla vulnerabilit√† del segnale rispetto ad errori e interferenza dei segnali, e dai limiti fisici della propagazione dei segnali. Due dispositivi possono essere connessi senza fili solo se rimangono entro un limite di distanza $d$ che dipende dalla potenza del segnale radio emesso dal trasmettitore, e da eventuali ostacoli intermedi per il segnale. Inoltre non √® precisa, nel senso che non si riesce in modo effettivo ad isolare la direzione di arrivo (la destination e sorgente non sono isolate). Vedere Onde elettromagnetiche per spiegazione sul funzionamento fisico.\nCollisione √® un problema molto comune per\nOgni rete pu√≤ essere realizzata attraverso un singolo mezzo fisico di trasmissione, oppure attraverso la composizione di mezzi fisici eterogenei.\nCanali, vedi canali di comunicazione, dividono spesso il mezzo di comunicazione. (si potrebbe infatti dire che il singolo mezzo di comunicazione abbia un fascio di canali)\n0.2.2 Dispositivo o scheda di rete üü© √® semplicemente un‚Äôinterfaccia standard presente sul dispositivo di rete, per il collegamento del dispositivo di rete al mezzo di trasmissione. Esistono vari connettori, diversi a seconda del tipo di tecnologia impiegata per la rete di comunicazione. I connettori possono avere varie forme, e tipicamente permettono il collegamento solo quando le tecnologie dei dispositivi di rete, dei protocolli di gestione, e dei mezzi di trasmissione sono tra loro compatibili. I dispositivi di rete sono amministrati da componenti software del sistema operativo, e devono rispettare un insieme di regole standard per la gestione dei processi di comunicazione, definite dai protocolli di rete. Le schede di rete permettono la comunicazione in rete tra calcolatori diversi, attraverso i vari mezzi di trasmissione illustrati, avviene mediante dispositivi interni o periferiche esterne del calcolatore. Queste schede sono collegate al calcolatore attraverso un‚Äôinterfaccia di collegamento del calcolatore: su tale interfaccia transitano i dati (bit di informazione) da trasmettere in rete, oppure ricevuti dalla rete.\nLa scheda di rete si occupa inoltre di trasformare i bit di informazione in segnali trasmissibili sul mezzo di trasmissione della rete e viceversa: tali trasformazioni si chiamano codifica e decodifica dei dati. Un connettore di rete pone direttamente in contatto la scheda di rete con il mezzo di trasmissione per l‚Äôinvio e ricezione dei segnali in rete.\nIn sintesi, la funzione della scheda di rete √® quella di memorizzare temporaneamente, codificare, decodificare, trasmettere e ricevere i dati da e verso il mezzo di trasmissione (cio√® la rete) o il calcolatore.\nIdentificazione della scheda di rete Il tipo della scheda di rete viene identificato a seconda del mezzo trasmissivo, e soprattutto a seconda dei protocolli di comunicazione utilizzati per la codifica, e per la trasmissione dei dati in rete. Per le reti locali (LAN) basate su mezzo di trasmissione cablato, le tecnologie pi√π diffuse sono chiamate con il nome del protocollo di comunicazione primario: ad esempio Ethernet, nelle varianti a 10, 100 Mbit/sec (Fast Ethernet) e 1000 Mbit/sec (Gigabit Ethernet).\nPer le reti LAN senza fili (WLAN), le schede di rete pi√π diffuse sono denominate Wi-Fi (da 11 a 54 Mbit/sec), e Bluetooth (da 1 a 2 Mbit/sec). Ogni scheda di rete, per permettere di essere identificata univocamente nel contesto di una rete locale, dispone dalla sua costruzione di un indirizzo univoco (unico) a livello mondiale, non modificabile, detto indirizzo MAC (Medium Access Control), spesso questa scheda di rete √® specifica per il mezo trasmissivo!. Tali indirizzi vengono assegnati dai costruttori delle schede, per evitare che si possano originare indirizzi MAC duplicati. (spesso hai moltissime informazioni riguardo al modello della scheda di rete e del produttore solo guardando questo).\nIl MAC si occupa anche di evitare le collisioni (come non lo so).\n0.2.3 Protocolli di rete üü© I protocolli di rete sono un insieme di regole, univocamente definite, per garantire la compatibilit√† e la corretta configurazione e gestione delle fasi della comunicazione tra i dispositivi di rete.\nSlide (la parte sull‚Äôarchitettura presente in slide √® trattata in Architettura e livelli 1, 2\nLe regole che governano i processi di comunicazione in rete, tra dispositivi e sistemi eterogenei\nPerch√© √® necessario: La necessit√† di accordarsi su regole e servizi comuni per la comunicazione di rete ha lo scopo di permettere una completa compatibilit√† e supporto alla comunicazione su sistemi, tecnologie e dispositivi eterogenei.\nAl fine di far ci√≤ definiscono delle regole semantiche (processi) e sintattiche (struttura pacchetto) formali.\nI protocolli definiscono aspetti e regole semantiche sulla sequenza dei messaggi, e regole sintattiche sul formato dei messaggi scambiati durante la comunicazione. La definizione dei protocolli di rete deve prevedere e supportare diverse finalit√† di comunicazione.\nNon ha quindi senso definire un protocollo rigido, ma ha senso definire classi di protocolli, deputate a svolgere e gestire determinate funzioni della comunicazione. Tali classi di protocolli, opportunamente organizzate, permettono di semplificare la gestione della rete, ma √® necessario definire in modo non ambiguo le relazioni tra le classi di protocolli (ovvero quale protocollo si occupa di gestire un certo problema? Come avviene il dialogo tra protocolli?)\n0.3 Struttura della rete 0.3.1 Strutture della connessione di rete (4) üü© \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Introduzione a reti/Untitled 12.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Introduzione a reti/Untitled 12\u0026quot;\u0026gt; Un collegamento o connessione fisica di rete √® fornita da un mezzo di trasmissione (ad esempio un cavo, una fibra ottica oppure lo spazio per la propagazione di onde radio) che sia condiviso tra due o pi√π dispositivi ad esso collegati, e che permetta il trasferimento di segnali, e quindi informazione, tra i dispositivi stessi.\nUn‚Äôinfrastruttura di rete rappresenta l‚Äôinsieme dei collegamenti o connessioni fisiche esistenti tra tutti i dispositivi di una rete.\nLa comunicazione tra una coppia qualsiasi di calcolatori in rete, detti nodi (oppure host) della rete, √® possibile se esiste un collegamento diretto tra i nodi, oppure se esiste una sequenza di collegamenti, detta cammino, che permetta la comunicazione dei segnali passando per eventuali nodi e collegamenti intermedi.\nClassi di strutture di connessione della rete. (4)\nLe connessioni di rete punto a punto, come nell‚Äôesempio (a), sono connessioni che possono essere instaurate tra una coppia di calcolatori, senza coinvolgerne altri. Esse rappresentano il caso pi√π semplice di infrastruttura di rete, e sono semplici da gestire. Reti completamente connesse: Le connessioni di rete multiple permettono di connettere contemporaneamente un dispositivo a molti altri dispositivi. Nell‚Äôesempio (b) viene mostrata una infrastruttura di rete nella quale ogni nodo √® connesso attraverso un linea dedicata ad ogni altro nodo. Questa infrastruttura di rete viene detta completamente connessa, ed √® molto ridondante: infatti esistono molti cammini, oltre al collegamento diretto, per connettere ogni coppia di nodi passando per nodi intermedi. Una simile infrastruttura di rete si pu√≤ ritenere a volte troppo complessa e costosa. Ad esempio, sarebbe impensabile disporre di una connessione dedicata (cio√® un filo diretto) da ogni calcolatore ad ogni altro calcolatore sulle reti mondiali. Reti parzialmente connesse: Nell‚Äôesempio c, malgrado il ridotto numero di collegamenti rispetto al caso b, √® comunque possibile per ogni dispositivo trasferire segnali, cio√® comunicare, verso ogni altro dispositivo. In altre parole esiste un cammino, attraverso le connessioni disponibili, per trasferire informazione tra ogni coppia di dispositivi della rete.Nella rete (c) esiste per√≤ un fattore di rischio: in seguito a un guasto di una connessione, potrebbe risultare un insieme di componenti separato da tutti gli altri, detto ‚Äúpartizione‚Äù della rete (esempio d). Le partizioni della rete limitano il grado di comunicazione possibile, e possono essere dovute a cause fisiche (guasti fisici della connessione) oppure a cause che dipendono da cattive applicazioni delle regole di utilizzo (ovvero dei protocolli, che vedremo in seguito). 0.3.2 Topologia di rete üü© Slide\nTopologie di rete sono i diversi schemi di connessione sono possibili per creare le infrastrutture di rete\nTopologia per PAN e locali LAN: Topologia ad anello (esempio a) √® basata sull‚Äôorganizzazione delle connessioni tra i dispositivi, in modo da creare un anello chiuso. Ogni componente pu√≤ comunicare con ogni altro componente inviando i segnali attraverso la sequenza di connessioni in senso orario o antiorario. La topologia a stella (esempio b) prevede un componente centrale direttamente connesso a tutti gli altri. Ogni componente periferico pu√≤ comunicare con ogni altro componente periferico passando attraverso il componente centrale. La topologia a bus (esempio c) prevede che ogni componente abbia una connessione verso un bus condiviso (cio√® una connessione condivisa da tutti). Questo tipo di connessione permette di introdurre una delle problematiche fondamentali che saranno trattate in seguito: la gestione dell‚Äôaccesso al bus, ovvero il decidere chi possa trasmettere tra tutti i possibili dispositivi, per evitare sovrapposizioni delle trasmissioni. La topologia ad albero (esempio d) prevede un‚Äôorganizzazione gerarchica delle connessioni. Se pensiamo all‚Äôanalogia con un albero genealogico, esiste un dispositivo (nonno) che connette direttamente due o pi√π dispositivi (figli), ognuno dei quali a sua volta connette direttamente un numero variabile di dispositivi (nipoti), e cos√¨ via.\nMano a mano che le reti pi√π piccole vengono collegate tra loro e organizzate in strutture di rete pi√π grandi, la topologia della rete globale pu√≤ diventare incredibilmente complessa, e quindi uno schema topologico generalizzato non √® quasi mai applicabile. In questo caso si parla di rete con topologia a grafo complesso, oppure a maglia. In tali topologie a grafo, possono essere presenti cammini multipli che connettono coppie di nodi, dando luogo a possibili alternative per la connessione dei dispositivi. Questo fatto pu√≤ ridurre il rischio di incorrere in partizioni della rete, in quanto un certo grado di ridondanza dei cammini di connessione permette di aggirare i collegamenti soggetti a eventuali guasti.\n0.3.3 I due generali üü© √à possibile implementare una comunicazione sicura in un ambiente che possa fallire, anzi con un nemico che voglia far fallire questo?\nFai finta che A = 3, B = 3, e C = 5, ma A e B sono separati, √® possibile avere una comunicazione per attaccare insieme? Se A o B attaccano da soli verrebbero ammazzati.\nSemplificazione del problema dei due generali\nCome si manda il messaggio in modo sicuro? Se si manda il singolo messaggio, senza aspettare nessuna risposta, allora √® molto insicuro (per niente sicuro) che il messaggio sia arrivato.\nPer questo motivo si aspetta un acknowledgment, e un altro acknowledgment dall‚Äôaltra parte ‚Üí SYN/ACK protocol √® simile.\nMa facendo in questo modo non si √® mai sicuri che l‚Äôaltro abbia ricevuto il messaggio. La rete a due √® fallibile, e questo √® dimostrato.\n0.3.4 Reti commutazione a circuito üü© Slide\nNelle reti a commutazione di circuito, i dati vengono trasmessi tra un mittente e un destinatario finale agli estremi di un cammino end-to-end (circuito) di canali di comunicazione punto a punto. Il circuito viene negoziato e prenotato, attraverso opportune procedure (come avviene quando si digita un numero per una chiamata telefonica). Una volta identificati e ottenuti i canali che collegano mittente e destinatario, la comunicazione dati pu√≤ avvenire anche come un‚Äôunica sequenza di bit, senza interruzioni.\nVantaggi\nNon c‚Äô√® bisogno di dichiarare periodicamente chi sia il mittente e il destinatario dei dati, in quanto entrambi sono fissati al momento della creazione del circuito riservato (riservato = prenotato da qualcuno). Ridotto ritardo di trasmissione per i dati, in quanto ogni nodo intermedio ha gi√† disponibile il canale libero uscente sul quale inviare immediatamente i dati ricevuti sul canale entrante, dal mittente fino al destinatario finale. Svantaggi\nUtilizzo basso dei canali del circuito Quantit√† dei dati da trasmettere non √® grande I dati arrivano a gruppi, intervallati da tempi di vuoto. Inefficienza di utilizzo delle risorse del circuito nei casi sopraelencati (il canale resta tutto occupato). Pagato a tempo! Un p√≤ di tempo in pi√π per prenotare il percorso all‚Äôinizio. 0.3.5 Reti commutazione a pacchetto üü© Slides\nLa maggior parte delle reti per trasmissione dati digitali, inclusa la rete di reti globale Internet, sono di questo tipo.\nCome funziona\nI dati digitali vengono suddivisi in pacchetti separati, e vengono trasmessi su canali ad accesso multiplo (broadcast, non per forza deve essere punto a punto ). Per consentire la corretta ricezione dei dati, √® per√≤ necessario includere in ogni pacchetto l‚Äôinformazione sull‚Äôidentit√† del rispettivo mittente e soprattutto del destinatario. Si attua in questo modo la condivisione di un canale unico per diversi flussi di pacchetti appartenenti a diversi mittenti e destinatari. Componendo in serie una sequenza di canali broadcast a commutazione di pacchetto, i nodi ricevitori devono di volta in volta farsi carico di verificare se il pacchetto sia giunto a destinazione o, in caso contrario, possono provvedere all‚Äôinoltro del pacchetto ricevuto sul successivo canale broadcast.\nSvantaggi\nRitardo per la comunicazione dei dati tra mittente e destinatario (pi√π lenti dovuto all‚Äôesigenza di iterare pi√π volte la ricezione e l‚Äôinoltro di pacchetti su canali broadcast in sequenza. Maggiore rischio di collisione dei pacchetti (perdita di pacchetti) A causa dei jitter, i pacchetti possono arrivare in ordine diverso(perdita di ordine ‚Üí riordinamento) Se utilizzo il broadcast, serve il mittente e il destinatario Vantaggi\nmaggiore utilizzo dei canali ad accesso multiplo, e quindi alla possibilit√† di tariffare la comunicazione in base ai dati trasmessi, e non in base al tempo necessario. 0.3.6 Canali di comunicazione della rete üü© Slide\nBisogna dire che √® una virtualizzazione sul mezzo di comunicazione, ossia si utilizza il mezzo di comunicazione come se avesse alcuni canali diversi (che non interferiscono fra di loro) quindi possiamo riutilizzare la stessa risorsa fisica!\nDa riallacciarsi con mezzi di comunicazione per capire come sono implementate fisicamente i canali di comunicazione.\nI canali punto a punto si basano sull‚Äôaccordo tra un mittente e un destinatario riguardante la definizione del canale da usare (in figura equivale al colore). Solo due dispositivi possono usare il canale di tipo punto a punto a loro riservato. Possiamo creare un canale logico da un singolo mezzo trasmissivo (eg una frequenza diversa, che possono essere filtrate). Il problema principale di questo √® che √® fisso, ossia posso comunicare solamente con un unico computer, senza poter cambiare il destinatario, direi che abbia pi√π problemi nel momento di wiring.\nI canali ad accesso multiplo (broadcast) sono canali sui quali tutti possono trasmettere e dove tutti ricevono le trasmissioni di altri (chiaramente il problema di collissione √® molto alto). Half duplex o uno trasmette o uno riceve mentre i Full-duplex possono trasmettere e ricevere contemporaneamente. Spesso per queste reti c\u0026rsquo;√® un master e dei slave che gestiscono.\nEthernet risolve questo problema senza fare utilizzo di un master, utilizza un sistema di ___ (non mi ricordo, √® comunque una race condition) lo risolve con un sistema di counter interno dopo il quale, se √® ancora vuoto il canale di comunicazione broadcast, prova a fare la comunciazione.\n0.3.7 Problema delle collisioni su canali multiple üü® Un problema per i canali ad accesso multiplo √® legato alla possibile collisione di segnali appartenenti allo stesso canale di comunicazione. Se due trasmissioni di segnali si sovrappongono nel tempo sullo stesso canale di comunicazione, l‚Äôeffetto sui segnali pu√≤ essere distruttivo e l‚Äôesito della comunicazione pu√≤ essere nullo. Intuitivamente, se due dispositivi trasmettono i loro segnali contemporaneamente, nessuno ricevitore sar√† in grado di capire quali bit di informazione siano stati trasmessi.\nIl problema delle collisioni √® molto critico, e determina l‚Äôesigenza di arbitraggio nell‚Äôaccesso al canale: chi trasmette e quando? Il problema dell‚Äôarbitraggio pu√≤ essere banale su canali punto a punto, dove mittente e destinatario possono definire semplici leggi (cio√® protocolli di gestione della comunicazione) per evitare le collisioni: ad esempio, trasmetto io, poi trasmetti tu. In canali condivisi ad accesso multiplo (broadcast) il problema risulta invece molto complesso, in quanto occorre definire leggi non ambigue, in grado di regolare gli accessi da parte di molti utenti, evitando le collisioni.\nIl problema principale delle collisioni √® che fanno perdere tempo o infomazioni (se il nostro protocollo non le gestisce).\nUtilizzo\nDi solito √® uguale a $capacit√† \\cdot overhead$, ad esempio se trasmetto 100 bit e solo 1 un bit √® di informazione, questo √® l\u0026rsquo;utilizzo del protocollo. Questo va a misurare efficienza di informazioni di questo protocollo.\n0.3.8 Servizi orientati alla connessione e non üü®+ Slide\nI servizi orientati alla connessione (connection-oriented) garantiscono che la spedizione di pacchetti di dati tra mittente e destinatario sia equivalente a una trasmissione affidabile e corretta. In altre parole, essi implementano una serie di operazioni attraverso le quali tutti i pacchetti perduti saranno ritrasmessi, e correttamente ordinati, fino a ricostruire esattamente tutta l‚Äôinformazione trasmessa. L‚Äôimplementazione di tale tipo di servizi potrebbe essere basata sulla definizione di vari protocolli alternativi. Ad esempio, potrebbe essere definito un cammino riservato unico per i pacchetti. Intuitivamente, ci√≤ equivarrebbe a un circuito virtuale per l‚Äôinvio dei pacchetti. Un altro modo per ottenere tale servizio potrebbe essere basato sulla numerazione dei pacchetti inviati, sul riordino dei pacchetti ricevuti e sulla richiesta di ri-trasmissione dei pacchetti perduti.\nIn breve questo risolve un problema di:\nRiordinamento dei pacchetti\nSoluzione riordinamento\nBasta numerare i pacchetti e poi far riordinare dal destinatario, questo √® un problema molto facile da risolvere\nReinvio dei pacchetti perduti\nSoluzione reinvio\nBisogna che il destinatario mandi degli acknowledgements. Anche questi possono essere persi.\nProblema tempo da aspettare prima di reinviare il pacchetto Pacchetto duplicato quando si perde l\u0026rsquo;acknowledgement o ci mette troppo. I servizi non orientati alla connessione (connectionless) non si preoccupano di garantire l‚Äôordine corretto dei pacchetti inviati e nemmeno la ricezione di tutti i pacchetti. Tale servizio √® simile all‚Äôinvio dei pacchetti in modo analogo a una sequenza di lettere attraverso la posta ordinaria.\nNon ci importa l\u0026rsquo;ordine di arrivo n√© per forza alcuni buchi.\nQuesto √® come sono le reti normali, normalmente sono connectionless, con un protocollo in pi√π sono connection-oriented.\nIn modo molto veloce si potrebbe dire che i servizi non orientati alla connessione non garantiscono nulla.\n","permalink":"https://flecart.github.io/notes/introduzione-a-reti/","summary":"\u003cp\u003eQuesta nota raccoglie note introduttive al corso di reti dei calcolatori fatto all\u0026rsquo;universit√† di Bologna.\u003c/p\u003e\n\u003ch3 id=\"011-definizione-di-rete-di-calcolatori-2--\"\u003e0.1.1 Definizione di rete di calcolatori (2) üü©-\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Introduzione a reti/Untitled.png\" alt=\"image/universita/ex-notion/Introduzione a reti/Untitled\"\u003e\n\u003cp\u003eI requisiti sono principalmente 2\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eEssere autonomi nel calcolo (capacit√† di eseguire dei programmi)\u003c/li\u003e\n\u003cli\u003eEssere interconnessi (capacit√† di ricevere ed inviare dei segnali)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eGli scopi sono principalmente per la comunicazione fra utenti o calcolatori.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNon-esempi\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRete telefonica, \u003cem\u003enon sono autonomi\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003eRete televisiva\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003eEsempi\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSmartphones con wi-fi\u003c/li\u003e\n\u003cli\u003eWWW\u003c/li\u003e\n\u003cli\u003eE-mail\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eUna rete di calcolatori √® un insieme di dispositivi autonomi, cio√® in grado di eseguire e svolgere autonomamente i compiti programmati di calcolo e di comunicazione, interconnessi tra loro da supporti fisici alla trasmissione di segnali. Non sono considerate reti di calcolatori, ad esempio, n√© le reti di comunicazione telefonica (i cui terminali telefonici non sono dispositivi autonomi), n√© le reti di distribuzione televisiva (in quanto i televisori non sono dispositivi autonomi in grado di comunicare informazione).\nNel prosieguo della presentazione, con il generico termine di ‚Äúrete‚Äù o ‚Äúrete di comunicazione‚Äù intenderemo implicitamente solo le reti di calcolatori elettronici.\nCon l‚Äôavvento dei calcolatori elettronici, e con la loro diffusione tra comunit√† sempre pi√π grandi di utenti, √® emersa l‚Äôesigenza e l‚Äôutilit√† di fornire un supporto alla comunicazione tra utenti, attraverso l‚Äôuso del calcolatore, supportando innovativi servizi di comunicazione per l‚Äôutente, quali ad esempio il World Wide Web e la posta elettronica. In tempi pi√π recenti si sono sviluppati ulteriormente i sistemi di rete includendo Internet of Things (IoT), reti senza fili (Wireless), ecc.\nLe necessit√† di comunicare e condividere informazione sono tra i principali motivi che favoriscono la nascita e lo sviluppo di reti di calcolatori. La fruizione dell‚Äôinformazione contenuta in questo corso rappresenta un esempio.\nUn ulteriore aspetto che ha favorito la nascita e la diffusione delle reti di calcolatori √® legato alla possibilit√† di condividere dispositivi costosi, altrimenti sotto-utilizzati, come ad esempio stampanti o capienti dispositivi di memorizzazione dei dati, e la possibilit√† di accedere e lavorare sui dati di un calcolatore, senza doversi spostare fisicamente sul calcolatore stesso.\nUna rete di calcolatori pu√≤ consentire di eseguire calcoli complessi in parallelo e in maniera distribuita, aumentando le prestazioni per l‚Äôottenimento dei risultati. In tal senso, le reti rendono possibile la scalabilit√† dei sistemi di comunicazione e di calcolo: il numero di dispositivi usati, e l‚Äôinvestimento relativo, possono essere dimensionati dinamicamente in funzione delle\nrichieste di servizio. In tempi recenti, le reti sono utilizzate in particolare per supportare la comunicazione utente, secondo svariate forme e applicazioni, oppure per supportare la comunicazione diretta tra dispositivi pervasivi e mobili (es. Internet of Things, Wireless Networks), ecc\u003c/p\u003e","title":"Introduzione a reti"},{"content":"1.1 Il principio di astrazione/implementazione Astrazione per macchine livello n con linguaggi n.\n1.2 I livelli principali di astrazione Livelli in breve\n1.2.1 Livello 0 Qua √® utile indagare la\nPorte Logiche in cui si indagano in un modo molto alto il funzionamento di porte\n√à il livello fisico delle porte logiche e dell\u0026rsquo;ingegneria elettrica.\n1.2.2 Livello 1 Link utili potrebbero essere la CPU e storia degli elaboratori\nCircuiti Sequenziali Ossia la Memoria\nla microarchitettura governa il flusso dei dati fra i vari componenti del livello logico digitale\nQuesto √® il livello della micro-architettura, ossia come i componenti logici interagiscono fra di loro.\n1.2.3 Livello 2 Livello ISA\nLivello ISA, Instruction Set Architecture, che sono le sequenze di 0 e 1 che definiscono una istruzione\nFino a qua (+ anche parte del sistema operativo) √® il lavoro del system programmers che si devono occupare di cose di questo livello di astrazione, in seguito i linguaggi sono spesso compilati e non interpretati (application programmers).\n1.2.4 Livello 3-4 √à il sistema operativo, il programma che organizza le risorse per il problema, la memoria virtuale etc.\nLinguaggio assembly.\nSi parla di livello ibrido perch√© spesso questo livello utilizza ancora le istruzioni ISA (Quindi assembly tradotto), con semmai in aggiunta alcuni programmi per l\u0026rsquo;esecuzione concorrenziale, gestione della memoria e simili.\nEcco che questi due livelli non si distinguono molto l\u0026rsquo;uno dall\u0026rsquo;altro, Il SO √® fatto probabilmente in assembly o ISA (ma nessuno lo fa direttamente in codice macchian) in pi√π aggiunge servizi tipici del sistema operativo.\n1.2.5 Livello 5+ Sono i linguaggi utili alla risoluzione dei problemi, come Python, c++, Java, Js, Ts\nLivelli e macchine virtuali Traduzione e interpretazione Spesso linguaggi a livelli superiori non sono direttamente interpretabili da un livello, basso, per questo motivo devono essere tradotte a un linguaggio comprensibile al livello inferiore.\nMacchina virtuale Spasso invece di continuare a pensare come un continuum di traduzioni fra i livelli √® opportuno pensare a un livello come una macchian virtuale a s√© stante. Ossia ogni livello ha una macchina che opera con un metodo a s√© stante, diverso da tutti gli altri livelli.\nEsempio di questa struttura\ngni livello ha una macchina che opera con un metodo a s√© stante**, diverso da tutti gli altri livelli.\nEsempio di questa struttura\n","permalink":"https://flecart.github.io/notes/introduzione-ad-architettura/","summary":"\u003ch3 id=\"11-il-principio-di-astrazioneimplementazione\"\u003e1.1 Il principio di astrazione/implementazione\u003c/h3\u003e\n\u003cp\u003eAstrazione per macchine livello n con linguaggi n.\u003c/p\u003e\n\u003ch2 id=\"12-i-livelli-principali-di-astrazione\"\u003e1.2 I livelli principali di astrazione\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eLivelli in breve\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Introduzione ad architettura/Untitled.png\" alt=\"image/universita/ex-notion/Introduzione ad architettura/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"121-livello-0\"\u003e1.2.1 Livello 0\u003c/h3\u003e\n\u003cp\u003eQua √® utile indagare la\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"/notes/porte-logiche/\"\u003ePorte Logiche\u003c/a\u003e in cui si indagano in un modo molto alto il funzionamento di porte\u003c/p\u003e\n\u003cp\u003e√à il livello fisico delle porte logiche e dell\u0026rsquo;ingegneria elettrica.\u003c/p\u003e\n\u003ch3 id=\"122-livello-1\"\u003e1.2.2 Livello 1\u003c/h3\u003e\n\u003cp\u003eLink utili potrebbero essere la\n\u003ca href=\"/notes/cpu-e-storia-degli-elaboratori/\"\u003eCPU e storia degli elaboratori\u003c/a\u003e\u003c/p\u003e","title":"Introduzione ad architettura"},{"content":"Tutta sta parte si fa in modo formale in Sistemi Lineari e determinanti, quindi potresti saltarla totalmente\nEquazioni lineari L\u0026rsquo;obiettivo dell\u0026rsquo;algebra lineare √® risolvere n equazioni con n sconosciuti di primo grado. Cosa che ci riesce con grandissimo successo! Andiamo ora a definire meglio cosa √® una equazione lineare\nDefinizione Una equazione lineare √® una equazione a coefficienti appartenenti a un certo campo (che pu√≤ essere R) e incognite il cui grado √® 1 e che siano indipendenti:\nes.\n$$ a_1x_1 + a_2x_2 +...+a_nx_n=b $$lo puoi considerare come una equazione lineare, mentre cose come\n$$ \\begin{cases} x^2 = 2 \\\\ xy = 2 \\\\ \\end{cases} $$Non lo sono.\nEquivalenza e compatibilit√† Equivalenza: due sistemi sono equivalenti quanto hanno le stesse soluzioni\nCompatibilit√†: Un sistema si dice compatibile quando ammette soluzioni\nSoluzione di una equazione lineare Una soluzione di una equazione lineare a n variabili, √® una n-tupla di valori ordinati che soddisfano l\u0026rsquo;equazione. La cosa che ci interesser√† sar√† la soluzione di un sistema di equazioni lineari ovvero tante equazioni lineari che vogliono essere tutte soddisfatte allo stesso momento.\nPropriet√† dell‚Äôuguaglianza √à molto importante per comprendere le equazioni comprendere le due propriet√† dell\u0026rsquo;uguaglianza che si studiano di solito alle medie.\nSono due, una per la somma e una per la moltiplicazione scalare.\nSomma: Data una eguaglianza a = b, questa √® uguale sse per ogni c, c + a = c + b. Moltiplicazione scalare: Data una eguaglianza a = b, questa √® uguale sse per ogni c si ha ca = cb (la prof ha tolto il caso in c = 0) Le matrici Definizione Potremmo definire la matrice solamente come una tabella che contiene dei numeri, a volte nemmeno si d√† il nome di tabella, ma solamente come una collezione indicizzata di coefficienti.\npotresti definire matrice cos√¨ $M = (a_{ij})_{nm}$\nIn genere una matrice di dimensione nxm si scrive in notazione sul campo su cui √® definito, per esempio\n$M_{n \\times m}(\\R)$, se √® quadrata di solito si sottindende l\u0026rsquo;altra dimensione e si scrive $M_n(\\R)$.\nVettori riga e colonna Si potrebbero definire dei vettori riga e colonna a seconda delle dimensioni della matrice: di dimensione $1\\times n$ sono vettori riga di dimensione $n\\times_{1}$ sono vettori colonna Questi vettori sono importanti poi per scomporre la matrice, quindi ora basta tenerli a mente\nCostruzione della somma e prodotto scalare Possiamo sempre fare la somma di due matrici con le stesse dimensioni definite sullo stesso campo.\nSomma Infatti se prendiamo A e B , la matrice somma C √® la matrice costituita dalla somma elemento per elemento (somma per indici corrispondenti).\nScalare Per il prodotto scalare moltiplichiamo ogni elemento della matrice per quel coefficiente.\nProdotto matriciale Questo prodotto fra matrici √® pi√π complessa rispetto alla somma e il prodotto. (√à utile perch√© le matrici rappresentano una trasformazione nello spazio, questo prodotto rappresenta la composizione fra le funzioni che rappresentano).\nTratto da wikipedia\nQuindi vogliamo avere che il numero delle colonne del primo sia uguale al numero delle righe del secondo. Questo √® soddisfatta questa condizione possiamo sempre fare la moltiplicazione. Lo facciamo cos√¨, consideriamo il risultato fra il prodotto del vettore riga i con il vettore colonna j, questo √® un prodotto scalare, che mi restituir√† un unico numero, questo √® il valore di $c_{ij}$\nPropriet√†:\nSi pu√≤ dimostrare che il prodotto fra matrici gode della propriet√†\nAssociativa Distributiva Non √® commutativa!\nTransposizione Si pu√≤ definire una matrice trasposta, bisogna scambiare gli indici associati. Es:\n$(A^T)_{ij} = (A)_{ji}$ con i, j gli indici della matrice\nMatrici a scala Matrice a scala: Si ha quando considerando il primo elemento non nullo partendo da sinistra, sotto di questo sta uno 0, e eementi a sinistra di questo sono nulli ( o niente), partendo a contare dall\u0026rsquo;alto.\nMatrice associata a un sistema Si pu√≤ associare una matrice a ogni sistema lineare, come in figura.\nDal libro\nNotare il significato di matrice completa o incompleta presente nella slides\nCostruendo la matrice associata completa, dobbiamo distinguere fra la matrice delle incognite, dei coefficienti e dei termini noti\nPivot e RR Pivot: per ogni riga, il primo valore da sinistra per cui non √® nullo, √® il valore di pivot\nRango righe: il rango righe di una matrice a scala √® il numero di pivot totale, si indica spesso con $rr_a()$ questo determina anche una dimensione dello spazio vettoriale o simili, li vedi in Spazi vettoriali\nRisolvere una matrice a scala Quando ho una matrice a scala diventa molto semplice risolvere il sistema per sostituzione.\nRiesco subito a determinare se la matrice ha soluzione finita, infinita e simili. (√® una cosa pratica quindi non ti metto appunti qui).\nPer avere in generale un feeling generale su questo:\n$rr(A) = rr(A|b)$ una sola soluzione $rr(A) \u003c rr(A|b)$ impossibile $rr(A) \u003e rr(A|b)$ infinite soluzioni con certe variabili libere Operazioni elementari (3) Possiamo agire sul sistema (e quindi anche sulla matrice associata al sistema) con certe operazioni che mi cambiano la matrice ma non cambiano la soluzione del sistema\nScambio posizione riga di due equazioni Moltiplicazione per un numero reale diverso da 0 (deriva dalle propriet√† dell\u0026rsquo;uguaglianza descritto in precedenza) Sommare (o sottrarre) una riga all\u0026rsquo;altra. (quindi unendola alla 2 posso farlo con una riga scalata) Trasformazione in matrice a scala Data una matrice normale possiamo sempre trasformalo in matrice a scala\nUna volta ottenuta questa matrice possiamo andare ad analizzarla con il rango righe come sopra\nSistema omogeneo Un sistema di equazioni si dice omogeneo quando i termini noti sono tutti 0. Questo sistema ha sempre almeno una soluzione la soluzione banale tutti 0.\n","permalink":"https://flecart.github.io/notes/introduzione-algebra/","summary":"\u003cp\u003eTutta sta parte si fa in modo formale in \u003ca href=\"/notes/sistemi-lineari-e-determinanti/\"\u003eSistemi Lineari e determinanti\u003c/a\u003e, quindi potresti saltarla totalmente\u003c/p\u003e\n\u003ch2 id=\"equazioni-lineari\"\u003eEquazioni lineari\u003c/h2\u003e\n\u003cp\u003eL\u0026rsquo;obiettivo dell\u0026rsquo;algebra lineare √® risolvere n equazioni con n sconosciuti di primo grado.\nCosa che ci riesce con grandissimo successo! Andiamo ora a definire meglio cosa √® una equazione lineare\u003c/p\u003e\n\u003ch3 id=\"definizione\"\u003eDefinizione\u003c/h3\u003e\n\u003cp\u003eUna equazione lineare √® una equazione a coefficienti appartenenti a un certo campo (che pu√≤ essere R) e incognite il cui grado √® 1 e che siano indipendenti:\u003c/p\u003e","title":"Introduzione algebra"},{"content":"0 Introduzione 0.1 L‚Äôalgoritmo Vogliamo cercare di creare algoritmi, ovvero soluzioni a problemi computazionali che non dipendono dal linguaggio di programmazione.\n0.1.1 Definizione Procedura per risolvere un problema in un numero finito di passi (quindi un algoritmo deve finire)\n0.1.2 Origine della parola Il nome \u0026ldquo;algoritmo\u0026rdquo; deriva da un nome di un matematico persiano dell 800 d.c. Muhammad ibn Musa al-Khwarizmi, che latinizzato diventa algorithmi, quindi i latini hanno creato la parola!\nQuesto matematico aveva creato un trattato per studiare il sistema di numerazione arabico che sostituir√† quello romano, si chiama Algoritmi de numero Indorum, un sistema pi√π efficiente rispetto al romano.\n0.1.3 Algoritmo vs programma Un algoritmo √® una cosa differente rispetto al programma, l\u0026rsquo;algoritmo √® pi√π concentrato sul design (la descrizione dei passi ad alto livello, di solito in pseudo codice che non √® eseguibile) mentre il programma √® l\u0026rsquo;implementazione dell\u0026rsquo;algoritmo, che dipende strettamente da un linguaggio di programmazione (che potrebbero esserci aspetti noiosi di implementazione) e dai limiti finiti della macchina, come memoria.\n0.1.4 Esempio massimo comune divisore 0.2 Fibonacci Possiamo trovare molteplici soluzioni per trovare il numero di fibonacci.\n0.2.1 One-shot Esiste la formula matematica per calcolare il numero di fibonacci. Questa la risolve subito, ma ha il problema di avere problemi di precisione in quanto le radici e simili non sono salvati correttamente in memoria.\n0.2.2 Classico algoritmo ricorsivo Algoritmo\nQuesto approccio funziona ma √® dannatamente lento in quanto ha bisogno di tempo di tempo. (lineare di memoria)\nLa cosa brutta di questo algoritmo √® che non utilizza il fatto di stare calcolando stesse istanze di quelle. Cio√® non sta riutilizzando calcoli gi√† fatti\nGiustificazione della linearit√† della memoria\nPossiamo osservare da questa rappresentazione dell\u0026rsquo;albero di chiamate che al massimo posso chiamare questa funzione un numero n di volte. (percorso pi√π lungo radice foglia)\nAnalisi temporale\nPer una analisi temporale corretta si cerca di prendere in considerazione alcune operazioni primitive dei computer dato che non possiamo tenere in conto l\u0026rsquo;istruzione codice macchina (che dipende dal compilatore e non funziona nemmeno tenere conto dei secondi che ci mette perch√© dipende dalla macchina) Quindi consideriamo solamente operazioni primitive che hanno bisogno di un tempo costante per esse eseguite.\nDimostrazione della relazione temporale\n0.2.3 Classico algoritmo iterativo Algoritmo\nAnalisi spaziale\nStiamo allocando un array lungo n, per cui si ha n item di spazio\nAnalisi temporale\nNel calcolo ha sbagliato a mettere un 3 davanti alla parentesi, dovrebbe essere 2 (ma resta lineare)\n0.2.4 Iterativo ottimizzato in memoria Una osservazione importante √® che non ci serve tenere in memoria l\u0026rsquo;intero array perch√© gli unici elementi che ci interessano sono i vecchi due elementi, quindi possiamo creare una formula iterativa che tenga conto di questo fatto e migliorare l\u0026rsquo;uso della memoria da lineare a costante.\nAlgoritmo\n0.2.5 Soluzione matriciale (mult non ottimizzato) Notiamo che fibonacci pu√≤ essere espresso come una potenza della matrice $\\begin{bmatrix} 1 \u0026 1 \\\\ 1 \u0026 0 \\end{bmatrix}$.\nQuesto fatto si pu√≤ dimostrare per induzione, una volta fatto possiamo andare ad implementare l\u0026rsquo;algoritmo nuovo. Questo algoritmo dopo una analisi ha stesse propriet√† dell\u0026rsquo;algoritmo precedente, per√≤ pu√≤ essere migliorato il passo di moltiplicazione matriciale\nAlgoritmo e l\u0026rsquo;analisi di essa\n0.2.6 Matriciale ottimizzato Utilizzando l\u0026rsquo;osservazione accennata sopra, che velocizza la moltiplicazione matriciale di molto, portandolo da n a log n. in pratica l\u0026rsquo;idea √® cos√¨: devo raggiungere n partendo da 1, nella precedente aggiungo 1 finch√© non arrivo a n, qui invece moltiplico per s√© stessa finch√© non ci arrivo quindi faccio una cosa tipo: in pratica possiamo vederla cos√¨, guardiamo n in binario, se c\u0026rsquo;√® un 1 moltiplico per matrice base, se 0 moltiplico per s√© stessa. Far√≤ sempre un numero logaritmico di operazioni.\nAlgoritmo helper\nAlgoritmo finale\n0.2.7 Algoritmi a confronto In questa immagine sottostante riusciamo a osservare il grafico sull\u0026rsquo;efficienza dei vari algoritmi.\n0.2.8 Valore in input vs dimensione di input Alla fine sono la stessa cosa.\nSi pu√≤ anche analizzare un input in termini di bit necessari per la rappresentazione dell‚Äôoggetto. Dipende dall‚Äôalgoritmo alla fine (per gli algoritmi di crittografia √® molto pi√π utile analizzare i bit dei numeri\nCosa che non centrano\n$$ f(n) \\in O(g(n)) := \\exists c \\in \\R|\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \\leq c \\\nf(n) \\in \\Omega(g(n)) := \\exists c \\in \\R|\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \\geq c \\ $$ $ f(n) \\in O(g(n)) := \\exists c \\in \\R|\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \\leq c \\\nf(n) \\in \\Omega(g(n)) := \\exists c \\in \\R|\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \\geq c \\ $$\n","permalink":"https://flecart.github.io/notes/introduzione-algoritmi/","summary":"\u003ch1 id=\"0-introduzione\"\u003e0 Introduzione\u003c/h1\u003e\n\u003ch2 id=\"01-lalgoritmo\"\u003e0.1 L‚Äôalgoritmo\u003c/h2\u003e\n\u003cp\u003eVogliamo cercare di creare algoritmi, ovvero soluzioni a problemi computazionali che \u003cstrong\u003enon dipendono dal linguaggio\u003c/strong\u003e di programmazione.\u003c/p\u003e\n\u003ch3 id=\"011-definizione\"\u003e0.1.1 Definizione\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eProcedura per risolvere un problema in un numero \u003cstrong\u003efinito\u003c/strong\u003e di passi (quindi un algoritmo deve finire)\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch3 id=\"012-origine-della-parola\"\u003e0.1.2 Origine della parola\u003c/h3\u003e\n\u003cp\u003eIl nome \u0026ldquo;algoritmo\u0026rdquo; deriva da un nome di un matematico persiano dell 800 d.c. \u003cem\u003eMuhammad ibn Musa al-Khwarizmi\u003c/em\u003e, che latinizzato diventa \u003cem\u003ealgorithmi\u003c/em\u003e, quindi i latini hanno creato la parola!\u003c/p\u003e","title":"Introduzione algoritmi"},{"content":"Note: Questo corso √® troppo astratto. Pi√π che probabilit√† tratta di teoria della Misura. Quindi affossato‚Ä¶\nLink della serie: https://www.youtube.com/watch?v=172m7qVy_FQ\u0026amp;list=PLrb6X_RiBI94b6dzCx-QwM-r0aZpJyPxS\nCampo (di probabilit√†) Nota:\n2 e 3 ‚áí 4\n2 e 4 ‚áí 3\nQuindi 3 e 4 sono interscambiabili, e si potrebbe eliminare uno dei due.\nAnche il fatto che il vuoto sia presente in F si pu√≤ omettere. combinando 1 e 2 ottengo il vuoto (complementare dell‚Äôinsieme che prenda tutto).\nNOTA: SIGMA FIELDS se soddisfa il criterio sotto al 4.\nNOTA: per insiemi finiti sigma-f = f\nEsempi:\nSono tutti dei $\\sigma -fields$\nL‚Äôultimo caso √® difficile da descrivere‚Ä¶ Devi utilizzare demorgan.\nLemma intersezioni di sigma-fields Ossia da verificare i 3 punti per dire che √® un sigma field\nSigma fields generated by sets Si pu√≤ vedere che questo field sono sempre presenti $\\Omega$ e vuoto. e per il lemma precedente tutti i Sigma-fields che hanno $\\epsilon$ √® un sigma field.\nDimostrazione costruttiva\nDobbiamo ora dimostrare che sia unico. (si pu√≤ dire che l‚Äôintersezione sia unica??? se s√¨ allora ez).\nEsercizio\nBorel sigma-field NOTA: intersezione di invervalli aperti pu√≤ comportare un intervallo semi aperto (eg $1/n$ e -1, questi l‚Äôintersezione infinita di questi intervalli √® $(-1, 0]$\nBorel Field Riusciamo a dare una struttura sul campo di Borel, riuscendo in questo passo a dimostrare che l‚Äôinsieme cos√¨ costruito non √® altro che l‚Äôinsieme di Borel.\nSemi-algebra di insiemi Proof\nFinitevely additive measures and semi-algebras Stieltjes (pre_measures) on Borel sets R Main observation:\nMeasure space Examples\nSet of measure functions Example\n3 basic properties of Measures Premeasure, finitely-additive Measures) Motivazione √à difficile costruire delle misure complete su $\\sigma$ fields, soprattutto se √® un campo non numerabile. Per questo motivo vorremmo utilizzare nozioni pi√π deboli di misura e da quelle estenderle anche a questi campi, pi√π difficili da trattare. Quindi andiamo a costruire pre-misure e finitely-additive measures. QUesta sezione √® II, 5.2.1 nel driver del corso su youtube.\nDefinizione: Una coppia $\\Omega, \\mathcal{A}$ √® uno spazio di pre-misura se $\\mathcal{A}$ √® un campo su $\\Omega$. (non abbiamo pi√π bisogno che sia un $\\sigma$ campo), solo che sia chiuso sotto unione e differenza.\nUna funzione countably additive (Ossia che valga che $\\left\\{ E_{i} \\right\\}_{i=1}^{\\infty} \\in \\mathcal{A} : \\cup_{i=1}^{\\infty}E_{i} = E \\in \\mathcal{A} \\implies \\mu(E) = \\sum_{i=1}^{\\infty}\\mu(E_{i})$$\\mu: \\mathcal{A} \\to [0, \\infty]$) √® una premisura Se assumiamo che $\\mu$ sia solamente finitely-additive allora la chiamiamo finitely-additive measure.\nPer fare una pre-misura basta un campo, non un sigma-campo, quindi √® molto pi√π facile da costruire.\nF-A measures is premeasure iff countably sub-additive Questo permette di passare da finitely-additive measures a pre-misure senza troppi intoppi.\nProof\nStiljes premeasure on borel field Proof\nMeasure extension Theorem Sigma finite\nEsempio quelle di probabilit√† che sono sempre finite\nExample non-uniqueness of extensions(not done, ma esistono se non √® sigma finito)\nCarath√©odor√Ωs Extension Cose da provare\nProof\nOuter measures Abbiamo visto alcune propriet√† importanti da dover verificare per la dimostrazione che $\\rho*$ sia una misura, queste caratteristiche si possono estendere per qualunque cosa quindi ha senso definire una altra misura in questo senso:\nSu caratheodory\nOgni misura $v$ che estende la premisura $\\mu$ vale che $v \\leq \\mu *\\, su \\, \\sigma(A)$ (largest extension)\nOther OuterMeasure properties with premeasure spaces\n","permalink":"https://flecart.github.io/notes/introduzione-alla-probabilita/","summary":"\u003ch1 id=\"note\"\u003eNote:\u003c/h1\u003e\n\u003cp\u003eQuesto corso √® troppo astratto. Pi√π che probabilit√† tratta di teoria della Misura. Quindi affossato‚Ä¶\u003c/p\u003e\n\u003cp\u003eLink della serie: \u003ca href=\"https://www.youtube.com/watch?v=172m7qVy_FQ\u0026amp;list=PLrb6X_RiBI94b6dzCx-QwM-r0aZpJyPxS\"\u003ehttps://www.youtube.com/watch?v=172m7qVy_FQ\u0026amp;list=PLrb6X_RiBI94b6dzCx-QwM-r0aZpJyPxS\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"campo-di-probabilit√†\"\u003eCampo (di probabilit√†)\u003c/h1\u003e\n\u003cimg src=\"/images/notes/Introduzione alla probabilit√†/Untitled.png\" alt=\"Introduzione alla probabilit√†/Untitled\"\u003e\n\u003cp\u003eNota:\u003c/p\u003e\n\u003cp\u003e2 e 3 ‚áí 4\u003c/p\u003e\n\u003cp\u003e2 e 4 ‚áí 3\u003c/p\u003e\n\u003cp\u003eQuindi 3 e 4 sono interscambiabili, e si potrebbe eliminare uno dei due.\u003c/p\u003e\n\u003cp\u003eAnche il fatto che il vuoto sia presente in F si pu√≤ omettere. combinando 1 e 2 ottengo il vuoto (complementare dell‚Äôinsieme che prenda tutto).\u003c/p\u003e","title":"Introduzione alla probabilita"},{"content":"Scopi del sistema operativo üü© Un sistema operativo √® una astrazione sul HW che permette di\nGestire l‚Äôesecuzione di pi√π programmi assieme (concorrenza), tramite virtualizzazione CPU e Memoria Gestire le risorse (Quindi I/O, RAM, Memoria, Networking) Fornisce una interfaccia di programmazione (API) molto pi√π generale e potente, in grado di astrarre da dettagli di livello basso, vicini all‚ÄôHardware (come device drivers). Quindi in breve il SO √® n programma che crea un ambiente civile per i programmi in cui interagire, e facilita molto il lavoro al programmatore per la sua interfaccia nuova. (si potrebbe dire che sia una macchina virtuale con un suo linguaggio (che √® l‚ÄôAPI) se seguiamo la terminologia di Macchine Astratte)\nVantaggi principali üü© Col sistema operativo abbiamo ora una astrazione sull‚ÄôHWche ci permette di interagire con queste in modo molto pi√π facile (molto molto).\nQuindi\nIndipendenza dall‚Äôhardware (i dettagli nascosti sotto le interfacce) Programmabilit√† e comodit√† di Uso per le API che sono presenti. Un buon sistema operativo deve essere quindi semplice per l‚Äôutilizzo ed efficiente nell‚Äôutilizzo delle risorse che ha disponibili.\nSistemi paralleli ‚Ü©Ô∏è Sistemi paralleli sono dei sistemi che possono eseguire pi√π istruzioni allo stesso momento (quindi hanno pi√π centri computazionali diciamo.\nTassonomia sulla struttura Questo sono stati citati in CPU e storia degli elaboratori.\nSIMD, come le GPU. MIMD, multicore, quelli che ci sono anche nelle GPU. Tassonomia sulla dimensione Basso parallelismo, quando ho poche CPU potenti. Sistemi massicciamente paralleli, ho tante CPU, anche normali. Tipologie di Coupling Tight quando ho CPU su MEMORIA CONDIVISA\nLoose quando ho CPU su memoria privata, che possano comunque comunicare fra di loro.\nAlcune tipologie di sistemi paralleli Symmetric multiprocessing: quando hanno la stessa struttura di dati per ogni processore.\nQuesto rende pi√π semplice un p√≤ la gestione delle strutture di dati, che sono le stesse.\nAsymmetric multiprocessing quando c‚Äô√® un unico processo che d√† da fare un compito specifico a certi processi (quindi ho una asimmetria\nSistemi realtime Quando il valore di output dipende non solo dal valore, ma anche dall‚Äôistante in cui il valore viene prodotto.\nHard and soft real-time Hard quando pu√≤ avere effetti catastrofici, come controllo velivoli o Nucleari.\nSoft quando ho solo disservizi.\nVecchia roba Hardware e Software Il professore fa una distinzione molto strana fra software e hardware (ricorda teatrino dei limoni che ha fatto in classe).\nIn soldoni hardware √® tutto quello che √® composto da mero hardware. Il software √® la conoscenza, qualcosa che si distingue molto facilmente perch√© √® facilmetne copiabile, e distribuibile\nInformazione qualche conoscienza che √® utile. Ha 3 problemi principali\nElaborazione, che risolve il problema della trasformazione di un informazione in un altra forma che possa risultare utile (es bites in suoni che si possono sentire). Memorizzazione che risolve il problema di trattenimento dell‚Äôinformazione nel tempo. Comunicazione che risolve il problema di comunicazione dell‚Äôinformazione in due luoghi diversi (protocolli) Cosa fa un informatico secondo il prof. Studia un problema, da una descrizione della soluzione in modo preciso e dettagliato che un calcolatore si ain grado di eseguire la soluzione (e replica questo pensiero umano).\nSulle graffette esempio che ha fatto il prof riguardo le graffette. Afferma in soldoni che la scuola uccida la creativit√† perch√© si trovano molti meno modi di utilizzare la creativit√†, e sembra ch ela causa principale di questo sia la scuola. Ma √® davvero cos√¨???\nA me sembra che sia il processo di crescita normale in cui si impara cosa servno di solito a cosa, quindi si spendono meno risorse per cose comuni. √à una cosa normale nell‚Äôessere umano che una cosa comune sia poco interessante. √à interessante un modo nuovo e utile del suo utilizzo, ma il raggio di soluzioni √® vasto. Le cose comuni √® difficile che servano per soluzioni innovative, senza nessuna base: eg. se voglio fare maetematica non vado certo a considerare una graffetta, ci vorrebbero altri episodi serendipici che possano fare una associazione, cosa direi che non accadrebbe mai\n","permalink":"https://flecart.github.io/notes/introduzione-so/","summary":"\u003ch3 id=\"scopi-del-sistema-operativo-\"\u003eScopi del sistema operativo üü©\u003c/h3\u003e\n\u003cp\u003eUn sistema operativo √® una \u003cstrong\u003eastrazione sul HW\u003c/strong\u003e che permette di\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGestire l‚Äôesecuzione di pi√π programmi assieme (concorrenza), tramite virtualizzazione CPU e Memoria\u003c/li\u003e\n\u003cli\u003eGestire le risorse (Quindi I/O, RAM, Memoria, Networking)\u003c/li\u003e\n\u003cli\u003eFornisce una interfaccia di programmazione (API) molto pi√π generale e potente, in grado di astrarre da dettagli di livello basso, vicini all‚ÄôHardware (come device drivers).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eQuindi in breve il SO √® n \u003cstrong\u003eprogramma\u003c/strong\u003e che crea un ambiente civile per i programmi in cui interagire, e facilita molto il lavoro al programmatore per la sua interfaccia nuova. (si potrebbe dire che sia una macchina virtuale con un suo linguaggio (che √® l‚ÄôAPI) se seguiamo la terminologia di \u003ca href=\"/notes/macchine-astratte/\"\u003eMacchine Astratte\u003c/a\u003e)\u003c/p\u003e","title":"Introduzione SO"},{"content":"NOTE: this is an old set of note, and it is of quite bad quality, it should be completely rewritten.\n$$ F(x) = \\int _{-\\infty}^{x} f(t) \\, dt $$ A volte la densit√† non √® definita, mentre la funzione cumulativa lo √® , per questo spesso cominciamo a definire partendo dalla definizione.\n$$ F_{X}(x) = \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^{x} f_{X}(z) \\, dz $$Generalized inverse This is known as the universality of the uniform, every invertible CDF can be written with respect to the uniform distribution.\nDefinition $$ F_{X}^{-1}(u) = inf \\left\\{ x; F_{X}(x) \\geq u \\right\\} $$ This has sense because we know that the inverse is a continuous function (we do or not?). This is useful because when we have a cumulative probability distribution this allows to recreate the original random variable distribution, and it\u0026rsquo;s quite easy to get it in this way.\nProbability Inverse transform Sample from $X$ when it\u0026rsquo;s difficult to sample from that distribution (for example function difficult to calculate?, Difficult to implement function?)\nRequirements:\nI know the functional form of $F_{X}(x)$ $X$ in continuous. For the exam you will be given the cumulative distribution and you need to use this theorem to sample\nTheorem $$ U \\sim F_{X}(x) \\iff \\mathbb{P}(Y \\leq x) =X $$ Where $Y = F_{X}^{-1}(U)$ this is just the definition of the cumulative function, the catch is the ???\n$F_{X}(u)$ is continuous then it is invertible If $U \\sim Unif(0, 1)$ then the c.d.f is easy, and it\u0026rsquo;s equal to $$ u \\in \\left[ 0, 1 \\right]: F_{U}(u) = \\begin{cases} 0, u \\leq 0 \\\\ u, 0\\leq u\\leq 1 \\\\ 1, u \\leq 1 \\end{cases} $$ And this is easy. This is proved to be the only distribution with this property, that the CDF is an identify $F_{X}(X) = U$ this is also called PIT See here for proof (it\u0026rsquo;s cool) Proof 1 $$ \\mathbb{P}(F_{X}^{-1}(U) \\leq x) = \\mathbb{P}(F_{X}\\left[ F_{X}^{-1}(U) \\right] \\leq F_{X}(x)) = \\mathbb{P}(U \\leq F_{X}(x)) = F_{U}[F_{X}(x)] = F_{X}(x) $$ In the first passage we used that the cumulative distribution function is monotonically increasing, in the second a clear property for the inverse, and at the end we used a property of the cumulative uniform distribution.\nProof 2 $$ U = F_{U}(u) = \\mathbb{P}(U \\leq u) = \\mathbb{P}(F_{X}(X) \\leq F_{X}(x)) = \\mathbb{P}(F_{X}^{-1}(F_{X}(X)) \\leq F_{X}^{-1}(F_{X}(x)) ) = \\mathbb{P}(X \\leq x) = F_{X}(x) $$$$ F_{X}^{-1}(U) = X $$ So now you can sample.\nMain Proof $$ p(y) = p(x) \\left| \\frac{\\delta x}{\\delta y} \\right| $$$$ p(y) = p(x) \\left| \\frac{\\delta x}{\\delta y} \\right| = 1 \\left| \\frac{\\delta x}{\\delta y} \\right| = \\left\\lvert \\frac{ \\partial h(y) }{ \\partial y } \\right\\rvert = \\lvert p(y) \\rvert = p(y) $$ This implies if we use the reverse transformation for $h$, we can effectively sample $y$ starting from the uniform distribution $x$. This needs two main ingredients:\nThe function $h$ must be invertible The function $h$ must exist and be well behaved, i.e. must be continuous Example of application $$ X \\sim Exp(\\lambda = 1) $$ And given $F_{X}(x) = 1 - e^{-x}$, with $x \\in \\mathbb{R}^{+} \\cup \\left\\{ 0 \\right\\}$ Find the value of $X$ random variable.\nSolution example:\n$F_{X}(X) = U$, then set up the equation and solve $$ 1 - e^{-X} = U \\implies e^{-X} = 1 - U \\implies X = -\\log (1 - U) $$ We can notice that $1 - U$ and $U$ are both uniform distribution, so the above is the same as $X = -\\log(U)$ And in this way you get the correct random variable. Now we can sample from the uniform and get the correct result! -\u0026gt; Direct transformation method. With this process we prooved that $-\\log U \\sim Exp(\\lambda = 1)$ Famous function CDF Logistic function $$ F_{X}(x) = \\frac{1}{1 + e^{-(x - \\mu)/\\beta}} $$$$ U = F_{X}(X) = \\frac{1}{1 + e^{-(X - \\mu)/\\beta}} \\implies 1 + e^{-(X - \\mu)/\\beta} = \\frac{1}{U} \\implies -(X - \\mu)/\\beta = \\log(\\frac{1}{U} - 1) $$$$ \\implies X = -\\beta \\log\\left( \\frac{1}{U} - 1 \\right) + \\mu $$ Where $\\beta$ and $\\mu$ are parameters of the distribution.\nCauchy distribution $$ F_{X}(x) = \\frac{1}{2} + \\frac{1}{\\pi}\\arctan((x - \\mu) / \\sigma) $$$$ U = F_{X}(X) = \\frac{1}{2} + \\frac{1}{\\pi}\\arctan((X - \\mu) / \\sigma) \\implies \\tan(\\pi\\left( U - \\frac{1}{2} \\right)) = (X - \\mu)/\\sigma \\implies X = \\sigma \\cdot \\tan(\\pi\\left( U - \\frac{1}{2} \\right)) + \\mu $$ So also in this case we have a way to sample a Cauchy distribution by just manipulating a uniform distribution.\n$$ \\Phi(x) = \\int _{-\\infty}^{x}f_{X}(z) \\, dz \\int _{-\\infty}^{x} \\frac{1}{\\sqrt{ 2\\pi } \\sigma^{2}} \\exp \\left\\{ - \\frac{(z - \\mu)^{2}}{2\\sigma^{2}} \\right\\} \\, dz $$ Doesn\u0026rsquo;t have a clear evaluation function because it\u0026rsquo;s difficult, in R it uses the Probability inverse transform.\nEmpirical C.D.F $$ (X_{1}, \\dots, X_{n}) : \\hat{F}_{X, m}(x) = \\frac{1}{n} \\cdot \\sum_{i = 1}^{n} \\mathbb{1}(X_{i} \\leq x) $$ It\u0026rsquo;s just the sum of all the sampled data that is lower than a certain value! (unbiased, on average, the emprirical cdf we have the right cdf!).\nOther famous distributions Chi squared distribution math exchange\n$$ Y = 2 \\sum_{i = 1}^{n}X_{i} \\sim \\chi^{2}_{2n} $$ Where $n$ is the degrees of freedom, bad thing is that this usually just even, so useful for that. (chi square gamma distribution)\n$$ Y = \\beta \\sum_{i= 1}^{n} X_{i} \\sim G(a, \\beta) : a \\in \\mathbb{N}^{*} $$$$ Y = \\frac{\\sum_{i=1}^{a} X_{i}}{\\sum_{i = 1}^{a + b} X_{i}} \\sim Be(a, b) $$ Which is a Beta regression, used for microbiome in the guts, I don\u0026rsquo;t know why.\nTransformation of random variables (no exam) La cosa strana per questi statistici e che non si capisce per quale fine stiamo facendo queste trasformazioni, che non sono molto utili a primo impatto. Nel senso che non so nemmeno quale sia il problema che stiamo provando a risolvere!\n$$ f_{Z}(z) = \\frac{\\delta F_{Z}(z)}{\\delta z} = f_{X}\\left[ g^{-1}(z) \\right] \\cdot \\frac{\\delta g^{-1}(z)}{\\delta z} $$ Non so esattamente cosa mi possa servire questo e non so nemmeno perch√© funziona. Dopo: alla fine la dimostrazione di questo √® molto semplice (io sono un po\u0026rsquo; incapace nelle dimo a quanto pare e tendo ad impararle a memoria) Comunque lo trovi in https://en.wikipedia.org/wiki/Random_variable\nUniform random variable $$ U\\sim Unif(0, 1) \\implies f_{U}(u) = \\begin{cases} 0 : u \\not\\in \\left[ 0, 1 \\right] \\\\ 1 : u \\in \\left[ 0, 1 \\right] \\end{cases} $$$$ X = (b - a)U + a , \\, b \u003e a $$$$ U = \\frac{x - a}{b - a} = g^{-1}(X) \\implies \\frac{\\delta g^{-1}(X)}{\\delta x} = \\frac{1}{b-a} \\implies f_{X}(x) = f_{U} \\left[ \\frac{x- a}{b - a} \\right] \\cdot \\frac{1}{b - a} $$ and we have that $f_{U}$ is in $\\left[ 0, 1 \\right]$ when we need to have $x \\geq a \\land x \\leq b$ in order to have a density different than 0. $$\n$$\nStandard Gaussian $$ f_{Z}(z) = f_{X}(\\sigma z + \\mu) \\sigma = \\frac{1}{\\sqrt{ 2\\pi }} \\exp \\left\\{ - \\frac{Z^{2}}{2} \\right\\} $$ Where the first part is the density of a Gaussian\nBox-Muller algorithm This is one resource. This is another. Also (Bishop \u0026amp; Bishop 2024) section 14.1.2 presents this.\n$$ X_{1} = \\sqrt{ -2 \\log(U_{1}) } \\cos(2\\pi U_{2}), X_{2} = \\sqrt{ -2 \\log(U_{2}) } \\sin(2\\pi U_{1}), $$ Without any approximation, it is exact for some reason\nMultivariate cases We can use the re-parametrization trick to gen $N(\\mu, \\sigma^{2})$ just multiplying by the variance and add the mean. We are asking if we can do the same even for the multivariate case, how can we get $N_{p}(\\mu, \\Sigma)$ ? Let\u0026rsquo;s take a bi-variate Gaussian for example. It seems like a result that we have that the square root of a matrix is almost the same as a Cholesky decomposition. That will be our sigma. it\u0026rsquo;s always possible because we have a positive definite symmetric matrix for the Sigma. See Algebra lineare numerica for cholesky\nThe discrete case $$ p_{0} = P_{\\theta}(X \\leq 0) , p_{1} = P_{\\theta}(X \\leq 1) e via $$$$ X = k, p_{k-1} \\leq U \\leq p_{k} $$ e cos√¨ facciamo sampling della variabile per le distribuzioni discrete $X$\nReferences [1] Bishop \u0026amp; Bishop ‚ÄúDeep Learning: Foundations and Concepts‚Äù Springer International Publishing 2024\n","permalink":"https://flecart.github.io/notes/inverse-transform/","summary":"\u003cp\u003eNOTE: this is an old set of note, and it is of quite bad quality, it should be completely rewritten.\u003c/p\u003e\n$$\nF(x) = \\int _{-\\infty}^{x} f(t) \\, dt \n$$\u003cp\u003e\nA volte la densit√† non √® definita, mentre la funzione cumulativa lo √® , per questo spesso cominciamo a definire partendo dalla definizione.\u003c/p\u003e\n$$\nF_{X}(x) = \\mathbb{P}(X \\leq x)\n= \\int_{-\\infty}^{x} f_{X}(z) \\, dz\n$$\u003ch3 id=\"generalized-inverse\"\u003eGeneralized inverse\u003c/h3\u003e\n\u003cp\u003eThis is known as the \u003cem\u003euniversality of the uniform\u003c/em\u003e, every invertible CDF can be written with respect to the uniform distribution.\u003c/p\u003e","title":"Inverse Transform"},{"content":"Questo √® un protocollo di sicurezza a livello Rete e non pi√π a livello socket!\nPerch√© vorremmo avere sicurezza a questo livello? √à una cosa troppo comune da dover mettere a livello superiore (ma solitamente viene messa a questo livello per la sicurezza, quindi non √® implementata ovunque per dire), quindi IPsec vuole facilitare l\u0026rsquo;implementazione dei principi CIA a un livello pi√π basso, in modo che sia flessibile e customization.\nVirtual Private Networks Virtual because it doesn\u0026rsquo;t exist, it is built upon real network and private because only you can have access.\n√à una cosa molto utile per implementare cose come i VPN di aziende. Solitamente solo per questo, in altro non √® implementato perch√© √® troppo complesso, per poco di guadagno.\nNota l\u0026rsquo;imbustamento e imbustamento √® fatto nei router nell\u0026rsquo;esempio qui, ma pu√≤ essre fatto anche di computer.\nIn qualche modo, che non ho capito, lo puoi vedere come se fosse la stessa rete, perch√© l‚ÄôIP locale √® messo nell\u0026rsquo;IP sec credo, anche se non sono molto sicuro\nTypes of VPN architectures Gateway to gateway Host-to gateway Host to host The names are self esplicative.\nGaranzie IPsec Tutte le caratteristiche della CIA in questo caso vengono soddisfatte, a livello subito sopra quello di rete (quindi garanzia molto buona :D) Vedi Theoretical Notions of Security, l\u0026rsquo;unica cosa non fatta a questo livello √® implementazione dell\u0026rsquo;autenticazione dell\u0026rsquo;utente, abbiamo solo sull\u0026rsquo;origine, quindi necessitiamo qualcosa di pi√π per farlo a livello dell\u0026rsquo;utente.\nIntegrit√† dei dati Confidenzialit√† Autenticazione dell‚Äôorigine (credo perch√© conoscono solamente la chiave della VPN) Prevenzione dei replay attack Con Jocelyn vengono aggiunti anche altre due\nAccess control (quindi chi pu√≤ accedere a cosa) La cosa bella di applicare la sicurezza a questo livello √® che diventa trasparente rispetto agli utilizzi da utenti non bene addestrati o applicazioni che la ignorano. In ogni caso ho le garanzie di sopra.\nTunnelling mode (2) üü© Tunneling mode Routers IPsec aware, quando sono i routers che mettono su il protocollo Questo metodo solitamente viene utilizzato per reti VPN, perch√© √® il router che si occupa di decriptare ed inoltrare a livello rete locale. Tunnel Mode SA: Protects the entire IP packet by encapsulating it within a new IP packet. Transport mode Host IPsec-aware, in modo che siano solamente gli host che siano aware, mentre i routers non sanno niente, e si comportano in modo normale in questo modo, secondo una connessione IP. Transport Mode SA: Protects the payload of IP packets, leaving the IP header intact. In questo caso viene cryptato solo il payload, viene utilizzato in host-host Security Headers - Service Models Sembra end-to-end, che dovrebbe essere una garanzia a livello trasporto, dato che alla fine solamente gli utenti finali dovrebbero ricevere il messaggio. Possono essere Authentication header (AH) oppure Encapsulation Security Protocol (ESP), la prima non fornisce la confidenzialit√†, mentre la seconda anche la confidenzialit√†. Questa √® praticamente la differenza principale.\nAH ha il vantaggio che utilizzi meno energie perch√© non devi metterti a cifrare (ESP √® sicuro con chi sta parlando, per esempio uno streaming pu√≤ far uso di AH, dato che non ho bisogno di cifrare il tutto). √à la versione pi√π comune Tunnel mode con confidenzialit√† per gli usi in VPN. In entrambi i metodi esiste un sequence number che viene utilizzato per evitare replay attacks. In entrambi c\u0026rsquo;√® un hash per l\u0026rsquo;integrit√†.\nSecurity Association(4)üü®+ Security Association (SA): A set of parameters that define the security services and mechanisms for protecting communication between two network entities. Purpose: Establishes shared security attributes to secure data exchange, ensuring confidentiality, integrity, and authenticity. Prima di mettermi a scambiare messaggi, devo essere sicuro con chi sto parlando, quindi vogliamo andare a creare una security association, scambio di chiavi e algoritmi di criptazione comune, solo da una direzione verso l\u0026rsquo;altra. I due parametri SPI e l\u0026rsquo;IP di destinazione identificano una SA in modo univoco. Poi ci sono parametri che vanno ad identificare cose come tipologia di cifrario utilizzato, o tipologia di algoritmo utilizzato per l\u0026rsquo;integrit√†. Tutte le associations dovrebbero usare sequence numbers per evitare replay attacks.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 25.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 25\u0026quot;\u0026gt; Security association parameters Uses usually three parameters\nSecurity Parameter Index (32 bit) √® un identificatore della SA. IP destination e sorgente Identifier of the security protocol (ESP or AH). Altre chiavi di codifica e decodifica. Security Association Database Posso anche creare un database di SA questo si chiama SAD\nC‚Äô√® una security associazione fra tunnel e ogni host\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 26.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 26\u0026quot;\u0026gt; Cose che vengono memorizzate qui sono:\nIdentificatore di SA, SPI Chiavi di cifratura e algo di cifratura Interfaccia di inizio e arrivo della SA MAC e chiave di MAC Establishing a SA This is somewhat similar to SSL, because they first need to negotiate security parameters.\nInitiation: A request is made to establish a secure communication channel. Negotiation: Parameters such as encryption methods and keys are negotiated (e.g., via IKE). Creation: An SA is created with the agreed-upon parameters and stored in the SAD. Maintenance: SAs are monitored and periodically re-negotiated before expiration. IPsec Datagram üü® Si noti che anche il pacchetto di livello trasporto √® cifrato, quindi anche l\u0026rsquo;indirizzo di porta e l\u0026rsquo;indirizzo IP finale dovr√† essere cifrato\nIl modo con cui queste vengono programmate √® attraverso alcune regole del router (che controllano se il datagramma va verso certi host, oppure parte da certi host e simili).\nKey Determination Protocol Quello che viene usato in questo caso √® chiamato IKEv2. Che √® una versione di Diffie-Hellman in Key Exchange protocols. Ma risolve i problemi di Man in the middle, autenticando le due parti. E risolve anche problemi di denial of service dovuti al costo di computazione di diffie-hellman. Per il problema di flooding usano delle specie di cookie autenticati, che sono creati da chi vuole comunicare (firmati da questi diciamo). Poi usano un cifrario a chiave asymmetric come curve ellittiche o RSA\nIKEv2 Questo √® un protocollo di scambio chiavi, per certi versi simile a Diffie Hellman spiegato in Key Exchange protocols.\nAbbiamo sempre Alice e Bob, rispettivamente chiave privata $a, b$ con gruppo $g$, primo $p$, e modulo messo d\u0026rsquo;accordo. Poi si scambiano come da consuetudine $g^{a} \\mod p, N_{a}$ da $A \\to B$ e uguale e contrario da $B \\to A$. La chiave segreta sar√† $K = f(g^{ab} \\mod p, N_{a}, N_{b}$ e poi altra roba di integrit√† che non ho capito. Dovrei descriverlo meglio.\nIKE contenders Photuris SKIP ISAKMP TODO: approfondisci cosa sono queste. Why IPsec is not used Complexity in its setup (una cosa √® spesso √® molto lento perch√© richiede molti scambi, ha un overhead grosso). Bad compatibility with NAT (needs to know IP-port pair to route the packet) Application level security is often easier to implement ","permalink":"https://flecart.github.io/notes/ipsec-protocol/","summary":"\u003cp\u003eQuesto √® un protocollo di sicurezza a livello Rete e non pi√π a livello socket!\u003c/p\u003e\n\u003cp\u003ePerch√© vorremmo avere sicurezza a questo livello? √à una cosa troppo comune da dover mettere a livello superiore (ma solitamente viene messa a questo livello per la sicurezza, quindi non √® implementata ovunque per dire), quindi IPsec vuole facilitare l\u0026rsquo;implementazione dei principi CIA a un livello pi√π basso, in modo che sia flessibile e customization.\u003c/p\u003e","title":"IPSec protocol"},{"content":"Gli isomorfismi sono delle propriet√† fondamentali per stabilire una sorta di equivalenza fra i gruppi. Utilizziamo questi isomorfismi per parlare della stessa cosa ma in modi diversi.\n3.1 Introduzione 3.1.1 Definizione Un gruppo si dice isomorfo rispetto ad un altro gruppo se, in paroloni semplici, esiste una funzione bigettiva tale che preservi l\u0026rsquo;operazione del gruppo.\nIn altre parole\n$$ \\phi:A \\to B,\\phi(ab) = \\phi(a)\\phi(b) $$3.1.2 Step di dimostrazione Esiste un modo preciso per dimostrare se due gruppi sono isomorfi. In particolare:\nTrovare la funzione per l\u0026rsquo;isomorfismo Dimostrare che √® iniettiva Dimostrare che √® suriettiva Dimostrare che preserva la struttura del gruppo 3.2 Ogni gruppo √® in isomorfismo con un gruppo di permutazione Questo √® uno dei teoremi principali per classificare i gruppi\nDimostrazione (left cosets as permutation groups)\n3.2.1 Note storiche su questo teorema Storicamente parlando si √® iniziati a studiare la teoria dei gruppi dal punto di vista delle permutazioni, questo teorema √® ci√≤ che ha permesso una maggiore astrazione rispetto al concreto gruppi delle permutazioni, permettendo lo sviluppo di questo campo in modo tale.\n3.3 Propriet√† dell\u0026rsquo;isomorfismo sugli elementi Abbiamo una unica slide che riassume tutte le propriet√†. Non dovrebbe essere molto difficile dimostrare il tutto.\n3.3.1 Preservazione dell‚Äôelemento neutro 3.3.2 Preservazione della potenza 3.3.3 Coimplica la commutativit√† 3.3.4 Coimplica la ciclicit√† 3.3.5 Stesso ordine 3.3.6 Preservazione del n_sol per equazioni del gruppo 3.3.7 Preservazione dell‚Äôordine degli elementi 3.4 Propriet√† dell‚Äôisomorfismo sui gruppi 3.4.1 La funzione inversa √® un isomorfismo 3.4.2 Coimplica abelianit√† 3.4.3 Coimplica la ciclicit√† 3.4.4 L\u0026rsquo;immagine di un sottogruppo √® un sottogruppo (del gruppo di arrivo) 3.5 Automorfismi 3.5.1 Definizione Un automorfismo di gruppo √® solamente un isomorfismo con una funzione che parte da s√© ed arriva a s√© stesso.\nUn esempio di automorfismo √® la permutazione (che mi scambia gli elementi, ma alla fine √® una funzione da s√© in s√©).\n3.5.2 Automorfismo interno L\u0026rsquo;automorfismo interno rispetto a un gruppo √® una specie di congiunzione:\n$G_a(x) = axa^{-1}$ si pu√≤ dimostrare che questo √® effettivamente un isomorfismo.\n3.5.3 Aut(Zn) ha stesso ordine di U(n) Gli unici isomorfismi di Zn a se stesso sono gli elementi che sono coprimi con zn, in quanto solo questi possono generare l\u0026rsquo;intero gruppo (ed essere generatore quindi\u0026hellip;) Questo √® lo stesso numero di elementi con U(n). Ad alto livello √® questo √® il motivo per cui vale questo teorema.\nDimostrazione\n!\n","permalink":"https://flecart.github.io/notes/isomorfismi/","summary":"\u003cp\u003eGli isomorfismi sono delle propriet√† fondamentali per stabilire una sorta di equivalenza fra i gruppi. Utilizziamo questi isomorfismi per parlare della stessa cosa ma in modi diversi.\u003c/p\u003e\n\u003ch2 id=\"31-introduzione\"\u003e3.1 Introduzione\u003c/h2\u003e\n\u003ch3 id=\"311-definizione\"\u003e3.1.1 Definizione\u003c/h3\u003e\n\u003cp\u003eUn gruppo si dice isomorfo rispetto ad un altro gruppo se, in paroloni semplici, esiste una funzione bigettiva tale che preservi l\u0026rsquo;operazione del gruppo.\u003c/p\u003e\n\u003cp\u003eIn altre parole\u003c/p\u003e\n$$\n\\phi:A \\to B,\\phi(ab) = \\phi(a)\\phi(b)\n$$\u003ch3 id=\"312-step-di-dimostrazione\"\u003e3.1.2 Step di dimostrazione\u003c/h3\u003e\n\u003cp\u003eEsiste un modo preciso per dimostrare se due gruppi sono isomorfi. In particolare:\u003c/p\u003e","title":"Isomorfismi"},{"content":"Javascript Obiettivo principale √® esegurie codice clientside\nUn p√≤ di storia nato all‚Äôinizio della prima guerra dei browser (da netscape, explorer √® in visual basic comunque non compatibile con JS) come il fratellino di java nel senso che runnava ovunque, attualmente √® ECMAScript, ed √® la versione migliore. (era pensato per fare microscript!)\nECMAScript quando √® nato √® il nucleo a tutte le implementazioni JS eseistenti fino a quel momento (che √® stato molto caotico!)\nAnche l‚Äôunico linguaggio che va sul browser. Typescript sarebbe molto carino üòÄ.\nEsecuzione di JS Client side o Server-side Possiamo eseguire server-side (node) per eseguire codice JS in server side, anche se non ho pi√π questa integrazione con il client (come eventi, e simili).\nOssia l‚Äôevento triggera il codice JS corrispondente!\nEsecuzione sincrona o asincrona\nSincrona = caricamento dello script (quando carica, il browser non fa altro! √à una cosa sincrona, quindi non carica altro HTML e simili).\nAsincrono su eventi DOM o callback di eventi di rete. (esempio chiamata AJAX asincrona, mentre la chiama sincrona √® molto brutto perch√© il server √® bloccatooo)\nBrevi e veloci per i sincroni! No n2.\nPosizionamento del codice (3) Si pu√≤ posizionare inline come il codice css Esempio 1.\nSezione script all‚Äôinizio, come style di css Esempio 2.\nFile separato Esempio 3.\nQuesti sono i metodi principali, solitamente si preferisce il terzo metodo per migliore gestione degli script.\nma col terzo metodo si deve fare molta attenzione sul tempo di caricamento dlelo script (che √® sincrona!)\nCose del linguaggio Cose come oggetti, arrays, somme, comparazioni, JSON, Dati, li hai fatti troppo dai.\nQuesto √® tutto ecmascript, mentre se andiamo ad interagire con il browser abbiamo altri metodi!.\nInterpolazione (!!) Se esiste una variabile visibile nello scope attuale, allora lo sostituisco nella stringa. Principalmente questo. Per la prima volta l\u0026rsquo;oggetto della computazione sono frammenti di HTML, questo permette di dividere html e JS (anche se non ho capito bene come).\nIIFE ! Queste sono funzioni dichiarate e subito eseguite, sono utili per avere delle variabili private. (con solamente gli oggetti infatti non √® possibile definire tali variabili.\nClient defined classes Un sacco di robe, non ha senso scriverle, quindi le enumero in modo molto breve qui\nWindow In pratica √® il tab della pagina di questo istante (sia in lettura sia in scrittura), contiene in s√© il documento.\nDocument Sono la rappresentazione in memoria del documento che √® mostrato (quindi ci sono tutti i nodi che ci importano!\nAjax PROBLEMA: Ogni volta in cui devo cambiare elemento dell\u0026rsquo;interfaccia, non posso fare altro che duplicare la pagina, ossia fare una piena richiesta HTTP con le modifiche, infatti √® grande cambio di informazioni, nel senso che non mi servirebbe.\nIntroduzione Ajax Slide introduzione La cosa carina che significa anche AIACE üòÄ, ma non c‚Äôentra niente.\nL‚Äôobiettivo √® caricamenti asincroni per frammenti XML con questo aggiorno la pagina HTML, invece di cambiare da un altro URL.\nOggi XML √® considerato troppo verboso, in verit√† andiamo a scambiare frammenti JSON di cui abbiamo parlato in Alcuni linguaggi di Markup (non impo) üü•+, e sempre in Javascript.\nOra il formato √® tipo:\ncarico HTML molto vuoto carico applicazione JS anche complessa L‚Äôapplicazione fa richieste e popola la pagina in modo attivo Utente fa altra attivit√†, triggera altre richieste, la pagina cambia. Ecco l‚Äôinterattivit√†!\nSlide AJAX\nConfronto architettura scambi HTML e AJAX\nQuando faccio la richiesta, il browser √® bloccato, poi quando il server finisce il browser riceve tutto, butta via vecchio e comincia a fare le cose nuove. (continuo stop and go)\nNota: browser non si blocca per l\u0026rsquo;utente (script sono molto veloci che non sembra bloccarsi!)\nUn esempio di applicazione AJAX √® maps.google.com, perch√© inizia a caricare secondo attivit√† dell‚Äôutente, le piastrelle a un certo livello i zoom üôÇ\nStruttura processo ajax (4) Slide processo applicazione Ajax\nCreazione della richiesta\nOn Ready state change chiama la funzione ogni volta che cambia lo stato (che abbiamo detto possono essere 5 valori.\nse √® 4 la richiesta √® tornata ed √® stata elaborata ‚Üícompletata:D\nInvio della richiesta (DIFFERENZA POST E GET!!!!)\nGestione della risposta\nVantaggi svantaggi AJAX Importantissimo per AJAX e js!\nNavigazione della pagina non √® sincronizzato con lo scambio di dati! mentre prima s√¨\nSlide vantaggi AJAX\nUsabile, interattiva, senza tempi morti Molto pi√π veloce, per minore numero di pacchetti mandati Chiunque lo implementa :D Slide svantaggi AJAX\nDevo aggiungere step di navigazione di history fittizi per poter andare avanti indietro nella storia! (non lo fa il browser ma lo fa la mia applicazione) si chiama routing Ajax √® inerentemente non lineare perch√© posso cambiare contenuto ovunque, anche mentre il mio sintetizzatore sta leggendo la pagina (per accessibilit√† invece serve la linearit√†). L‚Äôimplementazione pu√≤ cambiare da browser a browser, qualcosa potrebbe essere rotto qui e non in un altro browser. Framework Ajax XMLHTTPRequest\n√à la libreria per Ajax, ma √® molto molto macchinosa! Per questo motivo utiliziamo altro, come JQuery che vedremo dopo.\njQuery\n√à un framework che √® nato per semplificare tutta la parte macchinosa dell‚Äôapplicazione AJAX, oggi non √® pi√π utilizzato perch√© le funzionalit√† sono gi√† direttamente presenti sul browser. √à pi√π per mantenere codice vecchio. Ce ne sarebbero altre ma non le ha descritte\n","permalink":"https://flecart.github.io/notes/javascript/","summary":"\u003ch1 id=\"javascript\"\u003eJavascript\u003c/h1\u003e\n\u003cp\u003eObiettivo principale √® esegurie codice clientside\u003c/p\u003e\n\u003ch2 id=\"un-p√≤-di-storia\"\u003eUn p√≤ di storia\u003c/h2\u003e\n\u003cp\u003enato all‚Äôinizio della prima guerra dei browser (da netscape, explorer √® in visual basic comunque non compatibile con JS) come il fratellino di java nel senso che runnava ovunque, attualmente √® ECMAScript, ed √® la versione migliore. (era pensato per fare microscript!)\u003c/p\u003e\n\u003cp\u003eECMAScript quando √® nato √® il nucleo a tutte le implementazioni JS eseistenti fino a quel momento (che √® stato molto caotico!)\u003c/p\u003e","title":"Javascript"},{"content":"Questo documento √® totalmente concentrato sull\u0026rsquo;analisi del problema della selezione del k-esimo elemento.\n7.1 Introduzione al problema Dato un array di elementi vogliamo cercare di trovare un modo efficiente per selezionare il k-esimo elemento, ossia un elemento che sia maggiore di k-1 elementi\n7.1.1 Note sull\u0026rsquo;utilizzo Questo algoritmo √® utile per esempio per sapere cosa displayare in una pagina di ricerca, perch√© per esempio posso avere blocchi di tanta roba 140k, mentre ovviamente posso selezionare solamente un blocco ristretto.\nEs: mostrare i primi k in ordine di rilevanza!\n7.2 Prime soluzioni Notiamo che possiamo riadattare le soluzioni ai problemi di ordinamento per trovare il k-esimo elemento.\n7.2.1 Selezione del minimo Questo √® un algoritmo che va a modificare il selection sort (utilizzando la stessa idea per creare un subarray crescente).\nSlide\nFaccio k cicli per trovare i k minimi per circa n volte, anche se l\u0026rsquo;analisi esatta √® data da questa sommatoria, che √® qualcosa di simile, ma non esattamente quello.\n$\\sum_{i = n - k + 1} ^{n} i$\n7.2.2 HeapSelect Io utilizzo una heap per trovare i k-esimi minimi, praticamente sto facendo un heap sort, ma con l\u0026rsquo;altra heap, e sto espellendo piccoli elementi uno alla volta..\nSlide\nPiccole note sul costo (funziona se ordini inferiori!)\n7.2.3 QuickSelect Un primo approccio potrebbe essere utile cercare di ordinare l\u0026rsquo;array con questo e prendere il k-esimo elemento.\nPoi noto che posso sfruttare il divide e conquer di qucksort per sapere quanti elementi sono minori di k! ho principalmente 3 casi:\nPseudoalgo mio (molto a parole) ho esattamente k - 1 elementi minori di x nel primo insieme dopo il partition, quindi ritorno x. Ho meno elementi di k - 1 minori di x dopo il partition, quindi vado a cercare il k esimo in questo insieme qui. Ho pi√π elementi di k - 1 minori di x dopo il partition, vado a cercare l\u0026rsquo;offset corretto nell\u0026rsquo;altro insieme.\nPseudocodice di slide\nPseudocodice bandiera nazionale che serve qui\nAnalisi nel caso ottimo e pessimo (e medio)\nL\u0026rsquo;ottimo e pessimo √® abbastanza facile perch√© si riconduce esattamente all\u0026rsquo;analisi di quicksort\nIn pratica O(n) nel caso migliore (perch√© ora ho una chiamata ricorsiva in meno)\nO(n2) nel caso peggiore perch√© √® identico a quicksort.\nIl caso medio √® un p√≤ pi√π difficile da analizzare, dimostreremo che √® in O(n). vediamo perch√©\nAnalisi medio\nSupponiamo che scegliamo sempre la partizione sfavorevole (quindi da n/2 a n), allora la relazione di ricorrenza (supponendo distribuzione uniforme semplice di queste possibilit√†) ho\nPosso dimostrare utilizzando la sostituzione questo. fine\n8 Priority-Queue √à di solito implementata con la Heap. Iniziamo a fare una descrizione di questa strututra\nAltre implementazioni che per√≤ non sono richieste ma interessanti Binomial Heap fibo-heap 8.1 Introduzione Questa struttura di dati sar√† utile in seguito per algoritmi di grafi come Dijstra o Prim per il MST.\nQuesta struttura come la Heap (anche fattibile con fibo-heap o heap binomiali!), manterr√† il minimo, non √® esattamente FIFO o LIFO come stack e queue\n8.1.1 Interfaccia della struttura Insertion (log n) Deletion (log n) Creation (n) Slide delle operazioni\n8.1.2 Esempi di utilizzi Base per altri algoritmi (come Dijstra o Prim) Processing di pacchetti per il routing Qualunque posto in cui c\u0026rsquo;√® bisogno di processare secondo un certo ordine 8.2 D-heap La differena con la heap normale √® che questo √® un albero che abbia d-rami.\nSlide di descrizione\n8.2.1 Altezza e Memorizzazione Lemma altezza della heap\nQuesta dimostrazione sull\u0026rsquo;altezza dell\u0026rsquo;heap √® molto simile a tutti gli alberi binari. Come gli alberi binari possiamo memorizzarli facendo un offset sulla cella attuale!\nMemorizzazione della d-heap\nOperazioni helper importanti:\nSono molto utilizzate per le operazioni di delete, insertion e simili.\nMuovi alto e muovi basso\n8.2.2 Sunto dei costi e note L\u0026rsquo;unica operazione che pu√≤ essere complessa √® la deletion, in cui bisogna contemplare anche il bubble up (viene eseguito solo una volta questa oppure bubble down).\nRiassunto in slide\n9 Union-Find 9.1 Introduzione Questa struttura di dati ci sar√† utile per gestire insiemi disgiunti\n9.1.1 Interfaccia della struttura Vedere se due elementi appartengono allo stesso insieme trovare il rappresentante Unire degli insiemi Slide interfaccia\nOgni insieme √® indicato da uno e un solo rappresentante, un suo elemento che fa finta di essere l\u0026rsquo;insieme stesso. Questa √® l\u0026rsquo;idea pi√π importante per comprendere la rappresentazione di questa struttura di dati.\n9.1.2 Intuizione sull‚Äôutilizzo Ho un insieme di ingredienti che siano tutti separati, vorrei unirli con magari un certo ordine, creando delle nuove cose. E continuare a vedere se li ho gi√† uniti o meno.\nAlla fine vedo l\u0026rsquo;unione degli elementi in questo modo\nEsempio di problema risolto con DSU\nSlide possibili implementazione (trattati subito dopo\n9.2 QuickFind Find in tempo costante e union in tempo lineare (possibile ammortizzare a tempo costante) 9.2.1 Metodi di rappresentazione (only lista) Un insieme √® rappresentato tramite un albero di altezza UNO.\nQuesto √® possibile tramite una lista concatenata, in cui ogni nodo punta sempre al nodo rappresentante.\nSlide rappresentazione tramite liste\nCi aggiungo io che si pu√≤ utilizzare anche un semplice array e l\u0026rsquo;index come un pointer per creare tale struttura.\n9.2.2 Union e sunto delle operazioni L\u0026rsquo;union di due insiemi √® una sovrascrittura del pointer del rappresentante dell\u0026rsquo;insieme che viene unito, come si pu√≤ intuire nell\u0026rsquo;esempio di union.\nIl find √® immediato, perch√© deve risalire di solamente un arco.\nEsempio di operazione di union\nRiassunto delle operazioni\n9.2.3 Euristica del peso (!!) Voglio cercare di limitare il tempo di unione di due insiemi.\nL\u0026rsquo;idea √® unire l\u0026rsquo;insieme con meno figli a quello con di pi√π. mi mantengo questa informazione sulla radice dell\u0026rsquo;albero.\nSlide dell\u0026rsquo;idea\nCosto di Union\nIl tempo resta lineare, per√≤ √® almeno dimezzato l\u0026rsquo;upper bound del tempo necessario per fare questa operazione.\nCosto ammortizzato\nPosso osservare che per la propriet√† sopra, se una foglia cambia radice l\u0026rsquo;insieme di arrivo √® grande almeno il doppio dell\u0026rsquo;insieme precedente, questa propriet√† mi permette di concludere che al massimo posso swappare log n volte.\nQuesto ragionamento mi permette di concludere un costo ammortizzato per questa operazione di union\nAnalisi union ammortizzato\nNotiamo che al massimo, in una union, $n/2$ elementi possono cambiare parente Quindi il caso pessimo di union in questo modo resta in $O(n)$, ma possiamo fare di meglio.\nNota: dopo n - 1 union, sto facendo union con se stesso, che non ha senso, quindi resto con n - 1, che √® il caso pessimo d union).\n9.3 QuickUnion √à una altra rappresentazione dell\u0026rsquo;union find, in cui √® presente una foresta (uguale alla precedente, ma in questo caso posso avere anche altezza superiore a 1!)\n9.3.1 Introduzione alla struttura e implementazione (array) Slide sulla struttura\nSlide di rappresentazione dell\u0026rsquo;array\nSi utilizza il parent vector!\n9.3.2 Find e sunto delle operazioni Per union basta infatti prendere la radice del primo insieme e farla puntare alla radice dell\u0026rsquo;insieme in cui si vuole unire, invece che farlo puntare a s√© stesso (fa questa ultima cosa perch√© era la radice)\nSlide di riassunto\n9.3.3 Euristica del rank (!!) Voglio cercare di limitare il tempo di ricerca del rappresentante. L\u0026rsquo;idea √® nel momento di fare l\u0026rsquo;union, lo faccio scegliendo di unire l\u0026rsquo;elemento con rank minore (ovvero con altezza dell\u0026rsquo;albero minore) con quello maggiore.\nAnalisi caso pessimo\nUpper bound rank di x (dim)\nLa dimostrazione √® abbastanza noiosa, basta che tengo in considerazione i tre casi: quando rank(a) = rank(b), quando √® minore, e quando √® maggiore, sapendo l\u0026rsquo;ipotesi induttiva, non dovrebbe essere tanto difficile concludere quanto voluto.\n(se ho una limitazione superiore all\u0026rsquo;altezza dell\u0026rsquo;albero allora √® chiaro che il find √® in log n.\nIn questo modo riesco proprio a creare un upper bound logaritmico al find, a differenza del costo ammortizzato di questo con l\u0026rsquo;euristica del peso in quickfind.\n","permalink":"https://flecart.github.io/notes/k-esimo-priority-q-dsu/","summary":"\u003cp\u003eQuesto documento √® totalmente concentrato sull\u0026rsquo;analisi del problema della selezione del k-esimo elemento.\u003c/p\u003e\n\u003ch2 id=\"71-introduzione-al-problema\"\u003e7.1 Introduzione al problema\u003c/h2\u003e\n\u003cp\u003eDato un array di elementi vogliamo cercare di trovare un modo efficiente per selezionare il k-esimo elemento, ossia un elemento che sia maggiore di k-1 elementi\u003c/p\u003e\n\u003ch3 id=\"711-note-sullutilizzo\"\u003e7.1.1 Note sull\u0026rsquo;utilizzo\u003c/h3\u003e\n\u003cp\u003eQuesto algoritmo √® utile per esempio per sapere cosa displayare in una pagina di ricerca, perch√© per esempio posso avere blocchi di tanta roba 140k, mentre ovviamente posso selezionare solamente un blocco ristretto.\u003c/p\u003e","title":"k-esimo priority-q DSU"},{"content":"Here is a historical treatment on the topic: https://jwmi.github.io/ASM/6-KalmanFilter.pdf. Kalman Filters are defined as follows:\nWe start with a variable $X_{0} \\sim \\mathcal{N}(\\mu, \\Sigma)$, then we have a motion model and a sensor model:\n$$ \\begin{cases} X_{t + 1} = FX_{t} + \\varepsilon_{t} \u0026 F \\in \\mathbb{R}^{d\\times d}, \\varepsilon_{t} \\sim \\mathcal{N}(0, \\Sigma_{x})\\\\ Y_{t} = HX_{t} + \\eta_{t} \u0026 H \\in \\mathbb{R}^{m \\times d}, \\eta_{t} \\sim \\mathcal{N}(0, \\Sigma_{y}) \\end{cases} $$Inference is just doing things with the Gaussians. One can interpret the $Y$ to be the observations and $X$ to be the underlying beliefs about a certain state. We see that the Kalman Filters satisfy the Markov Property, see Markov Chains. These independence properties allow a easy characterization of the joint distribution for Kalman Filters:\n$$ p(x_{1:t}, y_{1:t}) = p(x_{1}) p(y_{1} \\mid x_{1}) \\prod_{i = 2}^{t} p(x_{i} \\mid x_{i - 1}) p(y_{i} \\mid x_{i}) $$One can also observe that the classic Bayesian Linear Regression is a special case of Kalman Filters.\nKalman Inference Kalman Gain In the exercise session we have discussed about the Kalman gain\n$$ K_{t+1} = \\frac{\\sigma^{2}_{x} + \\sigma_{t}^{2}}{\\sigma^{2}_{x} + \\sigma^{2}_{y} + \\sigma_{t}^{2}} $$$$ \\begin{align} \\\\ \\mu_{t + 1} \u0026= \\mu_{t} + K_{t + 1}(y_{t + 1} - \\mu_{t}) \\\\ \\sigma^{2}_{t + 1} \u0026= (1 - K_{t+1})(\\sigma^{2}_{t} + \\sigma^{2}_{x}) \\end{align} $$ The updates are somewhat similar to RL reinforcement methods studied in RL Function Approximation, they are a convex update with the new value and the old value.\nSo this value tells us how likely are we to trust the new observation, if the value is high (close to one) the new observation has usually a high impact, else it is lower.\nInterpretation of the Kalman Gain We also notice that if the uncertainty about the observation is high, then the Kalman Gain is much lower, and closer to 0, this is because probably we cannot trust the update much. If else the uncertainty about the hidden status update is high, then the Kalman Gain is a little bit higher, and closer to 1, this is because we trust more the hidden status than the observation.\nProof Sketch We will prove the case where $F, H = I$.\nIt goes as follow, first assume recursively that the value of $X_{t} \\mid y_{1:t} \\sim \\mathcal{N}(\\mu_{t}, \\sigma_{t}^{2})$\n$$ p(x_{t + 1} \\mid y_{1:t+1}) = \\frac{p(y_{t + 1} \\mid x_{t + 1}) p(x_{t + 1} \\mid y_{1:t})}{Z} $$$$ p(y_{t +1}\\mid x_{t + 1}) = \\frac{1}{Z'} \\exp\\left( -\\frac{1}{2} \\frac{(y_{t + 1} - x_{t + 1})^{2}}{\\sigma^{2}_{y}} \\right) $$$$ p(x_{t + 1} \\mid y_{1:t}) = \\int p(x_{t + 1} \\mid x_{t}) p(x_{t} \\mid y_{1:t}) dx_{t} \\approx \\mathcal{N}(\\mu_{t}, \\sigma^{2}_{t} + \\sigma^{2}_{x}) $$Then putting everything together one can have the solution above.\nGeneral Case In the general case the Kalman Update is as follows:\n$$ \\begin{cases} \\mu_{t + 1} = F\\mu_{t} + K_{t + 1}(y_{t + 1} - HF\\mu_{t}) \\\\ \\sigma^{2}_{t + 1} = (I - K_{t + 1}H)(F\\Sigma_{t}F^{T} + \\Sigma_{x}) \\end{cases} $$","permalink":"https://flecart.github.io/notes/kalman-filters/","summary":"\u003cp\u003eHere is a historical treatment on the topic: \u003ca href=\"https://jwmi.github.io/ASM/6-KalmanFilter.pdf.\"\u003ehttps://jwmi.github.io/ASM/6-KalmanFilter.pdf.\u003c/a\u003e\nKalman Filters are defined as follows:\u003c/p\u003e\n\u003cp\u003eWe start with a variable $X_{0} \\sim \\mathcal{N}(\\mu, \\Sigma)$, then we have a \u003cem\u003emotion model\u003c/em\u003e and a \u003cem\u003esensor model\u003c/em\u003e:\u003c/p\u003e\n$$\n\\begin{cases}\nX_{t + 1} = FX_{t} + \\varepsilon_{t}  \u0026  F \\in \\mathbb{R}^{d\\times d}, \\varepsilon_{t} \\sim \\mathcal{N}(0, \\Sigma_{x})\\\\\nY_{t} = HX_{t} + \\eta_{t}  \u0026  H \\in \\mathbb{R}^{m \\times d}, \\eta_{t} \\sim \\mathcal{N}(0, \\Sigma_{y})\n\\end{cases}\n$$\u003cp\u003eInference is just doing things with the \u003ca href=\"/notes/gaussians/\"\u003eGaussians\u003c/a\u003e.\nOne can interpret the $Y$ to be the observations and $X$ to be the underlying beliefs about a certain state.\nWe see that the Kalman Filters satisfy the \u003cem\u003eMarkov Property\u003c/em\u003e, see \u003ca href=\"/notes/markov-chains/\"\u003eMarkov Chains\u003c/a\u003e.\nThese independence properties allow a easy characterization of the joint distribution for Kalman Filters:\u003c/p\u003e","title":"Kalman Filters"},{"content":"As we will briefly see, Kernels will have an important role in many machine learning applications. In this note we will get to know what are Kernels and why are they useful. Intuitively they measure the similarity between two input points. So if they are close the kernel should be big, else it should be small.\nWe briefly state the requirements of a Kernel, then we will argue with a simple example why they are useful.\nKernel Function requirements Every function $k$ must be\nSymmetric: $\\forall x, x' \\in \\mathbb{X}$ we have $k(x, x') = k(x', x)$ Positive definiteness For all $A$ we have $K_{A A}$ is positive definite. (it\u0026rsquo;s not clear the interpretation of the negative similarity) This function encodes information about the correlation. If a kernel satisfies those, it is called a Mercer kernel. Mercer has proven that these two conditions are necessary and sufficient for a function to be considered a kernel. If we have linear kernel, then we have bayesian linear regression. They are exactly the same thing. Another nice thing about kernels is that we can create new kernels by linearly combining them. Choosing kernels (or building them) is somewhat interpretable as choosing the correct prior for our functions.\nA motivating example Recall, we can use linear regression to learn non linear features, we just need some feature map.\nFeature maps -\u0026gt; Curse of dimensionality It is possible to include in linear regression settings, also monomials of greater order, and then use the same old algorithms to derive their value. But in doing so, one quickly gets into dimensionality problems: if we have $d$ variables, then the order of the feature map to all polynomials of order $m$ will be $\\mathcal{O}(d^{m})$, which is often quite prohibitive. We need a simple method not to store everything.\nSimple linear regression $$ \\theta_{\\text{new}} = \\theta - \\alpha \\sum_{i = 1}^{N} (y^{(i)} - \\theta^{T}\\phi(x^{(i)}))\\phi( x^{(i)}) $$ Normally we would need to explicitly compute the product every single time, but we know that if the feature map is too large this would be infeasible.\nBut if we note that $\\theta$ could be written by a linear combination of the features, then this problem will solve itself! Let\u0026rsquo;s say there are some $\\beta_{1}, \\dots, \\beta_{n}$ such that $\\theta_{0} = \\sum_{i = 1}^{N} \\beta_{i}\\phi(x^{(i)})$. It can be shown by induction that the new $\\theta$ updated using gradient descent will always be a linear combination. With this in mind, we just need to store a number that grows with $N$, not with the number of features $n$. But then we can rewrite the update rule in the following way:\n$$ \\theta_{new} = \\sum_{i = 1}^{N} \\beta_{i}\\phi(x^{(i)}) - \\alpha \\sum_{i = 1}^{N} (y^{(i)} - ( \\sum_{j = 1}^{N} \\beta_{j}\\phi(x^{(j)}))\\phi(x^{(i)}))\\phi( x^{(i)}) = \\sum_{i = 1}^{N} \\left( \\beta_{i} - \\alpha (y^{(i)} - ( \\sum_{j = 1}^{N} \\beta_{j}\\phi(x^{(j)})^{T})\\phi(x^{(i)}) \\right) \\phi(x^{(i)}) $$$$ \\beta_{i} := \\beta_{i} - \\alpha (y^{(i)} - \\sum_{j = 1}^{N} \\beta_{j}\\phi(x^{(j)})^{T}\\phi(x^{(i)}) $$$$ \\langle \\phi(x), \\phi(z) \\rangle = 1 + \\langle x, z \\rangle + \\langle x, z \\rangle ^{2} $$$$ \\beta := \\beta - \\alpha (y - K\\beta) $$ which $K$ our $n \\times n$ matrix of the features such that $K_{ij} = K(\\phi(x^{(i)}), \\phi(x^{(j)}))$.\nSome takeaways From the above example, one can observe the kernel trick doing its job and bringing down the computational cost related to our optimization problem. This can be done in many other problems, and its quite a general idea. We need to highlight two main observations making this framework tractable:\nThe kernel trick allows to compute optimizations with feature functions without explicitly computing them. If the feature space had dimension $e$ which could be infinitely dimensional, exponential on the number of terms $d$ et cetera, the optimization still takes take $N$, the number of samples. It is efficient to compute a single entry of the kernel matrix, often the complexity is just $d$, instead of being $e$. (this is often because we just need to compute the product $x^{T}z$ and then apply this value, the best way to understand this is to work out some examples). Building new Kernels üü® After we have a valid kernel matrix, we can compose them in some ways, while retaining the properties that suffice to make them kernels. We report the methods listed in (Bishop 2006) Chapter 6: Logarithms would be nice, but we lose the positive definiteness because small eigenvalues are mapped to negative values.\nChoosing the best kernel parameters üü© $$ \\hat{f}_{i} = \\arg \\max_{f} p(y_{\\text{train}}\\mid f, \\theta_{i}, x_{\\text{train}}) p(f \\mid \\theta_{i}) $$ Then pick $\\hat{\\theta} =\\arg \\max_{\\theta_{i}} p(y_{\\text{vol} }\\mid \\hat{f}_{i}, \\theta_{i}, x_{\\text{val}})$. This method still collapses the uncertainty in f into a point estimate. But we want to keep the uncertainty.\n$$ \\hat{\\theta_{MLE}} = \\arg \\max_{\\theta} p(y_{\\text{train} }\\mid x_{\\text{train}}, \\theta) = \\int p(y_{\\text{train}} \\mid f, x_{\\text{train}}, \\theta)p(f \\mid \\theta) \\, df $$ The $p(f \\mid \\theta)$ is the prior, the other is the likelihood. The delighful observation on this MLE observation is that it naturally prevents underfitting or overfitting the model. This is often called Bayesian model selection.\nThis table attempts to give an intuitive understanding of what is explained here.\nLikelihood Prior $H$ is simple, underfitting Small for most $f$ Large for some $f$ (concentrated), small for most $f$. $H$ is complex, overfitting Large for some $f$, small for most. Small for most $f$, more distributed. Just right ok ok So in the overfitting case we are spreading the values too much, in the underfitting case, the likelihood is always small so the summation should be small too, this is why usually it is just right.\nIntuitively: We are attempting to characterize the space of the functions given certain parameters. We are asking: what is the priori probability of having that function if we are given some parameters? If we overfit, we say that is unlikely that the function is random, so the prior is small (there is a high number of functions to choose from). If we underfit, then it is the inverse.\nLittle notes on Kernel Engineering Kernels should be designed for some specific characteristics of the data. So if you know a dataset has a certain invariance, then you should use kernels that have that invariance. For example if you have periodic data, you should use periodic kernels. Else: that periodicity aspect would be hardly obtainable.\nSome famous Kernels Sometimes is important to recognize famous kernel families because then you can compose them together, and easily recognize if some other function is a kernel or not.\nLinear kernel üü© This is one of the simplest kernels, which is just $k(x, y) = x^{T}y$, with $x, y \\in\\mathbb{R}^{d}$. A simple example of linear kernel, is the view of Gaussian Processes as a generalization of Bayesian Linear Regression with linear kernel.\nRadial Basis Kernel $$ k(x_{i}, x_{j}; l, \\sigma) = \\sigma\\exp\\left( -\\frac{1}{2l} \\lVert x_{i} - x_{j} \\rVert_{2}^{2} \\right) $$ They are similar to the Gaussians probability distribution function, but we don\u0026rsquo;t need to normalize in this case. This has one of the most natural interpretations of kernels as a distance similarity functions.\nThis family is both stationary and isotropic kernels, because they are translation invariant and depend only on the second norm. The $l$ parameter is called length scale and determines how much the function can vary. Usually high value means the function is more sensitive to old data, which implies it varies less.\n$$ p(\\omega) = (2\\pi)^{-d/2} \\exp\\left( - \\frac{\\lVert \\omega \\rVert_{2}^{2}}{2} \\right) $$ Which is just the standard Gaussian distribution in d dimensions, this is why sometimes the radial basis kernel is called Gaussian Kernel.\nRBF as infinite polinomials (Hard version) $$ \\psi(x) = \\sum_{j_{1}, \\dots, j_{d} \\in \\mathbb{N}} \\beta_{j_{1}, \\dots j_{d}} x_{1}^{j_{1}} \\cdot \\dots \\cdot x^{j_{d}}_{d} = \\beta^{T}\\varphi(x) $$$$ \\varphi_{j_{1},\\dots j_{d}}(x) = \\exp\\left( -\\frac{1}{2} \\lVert x \\rVert_{2}^{2} \\right) \\frac{x_{1}^{j_{1}} \\cdot \\dots \\cdot x^{j_{d}}_{d}}{\\sqrt{ j_{1}! \\dots j_{d}! }} \\implies \\varphi(x)^{T}\\varphi(x') = \\exp\\left( - \\frac{\\lVert x - x'\\rVert_{2}^{2}}{2} \\right) $$$$ \\sum_{\\alpha \\in \\mathbb{N}^{d}} \\frac{x^{\\alpha}(x')^\\alpha}{\\alpha!} = \\exp(x^{T}x') $$$$ \\exp(x) = \\sum_{i = 1}^{\\infty} \\frac{x^{d}}{d!} $$ And it\u0026rsquo;s also a nice exercise to prove that.\nRBF as infinite polinomials üü®++ $$ \\begin{align} \\phi(x) = \\begin{bmatrix} \\phi_{0}(x) \\\\ \\phi_{1}(x) \\\\ \\vdots \\end{bmatrix} \u0026\u0026 \\phi_{j}(x) = \\exp\\left( -\\frac{1}{2}x^{2} \\right) \\frac{x^{j}}{\\sqrt{j!}} \\\\ \\end{align} $$$$ \\begin{align} \\phi(x)^{T}\\phi(x') \u0026= \\sum_{j = 0}^{\\infty} \\exp\\left( -\\frac{1}{2}x^{2} \\right) \\frac{x^{j}}{\\sqrt{j!}} \\exp\\left( -\\frac{1}{2}x'^{2} \\right) \\frac{x'^{j}}{\\sqrt{j!}} \\\\ \u0026= \\sum_{j = 0}^{\\infty} \\exp\\left( -\\frac{1}{2}x^{2} -\\frac{1}{2}x'^{2} \\right) \\frac{x^{j}x'^{j}}{j!} \\\\ \u0026= \\exp\\left( -\\frac{1}{2}x^{2} -\\frac{1}{2}x'^{2} \\right) \\sum_{j = 0}^{\\infty} \\frac{(xx')^{j}}{j!} \\\\ \u0026= \\exp\\left( -\\frac{1}{2}x^{2} -\\frac{1}{2}x'^{2} \\right) \\exp(xx') \u0026\\text{Taylor expansion of} \\exp \\\\ \u0026= \\exp\\left( -\\frac{1}{2}x^{2} -\\frac{1}{2}x'^{2} + xx' \\right) \\\\ \u0026= \\exp\\left( -\\frac{1}{2}(x - x')^{2} \\right) \\\\ \\end{align} $$ Which ends the proof $\\square$.\nSpectral Density In this section we compute the spectral density for the RBF kernel, this is useful for the Fourier features in Gaussian Processes.\n$$ \\begin{align} p(\\omega) \u0026= \\int k(x, x') \\cdot \\exp(-i \\omega^{T}(x - x'))\\, d(x - x') \\\\ \u0026=\\int \\exp\\left( -\\frac{1}{2l}(x - x')^{2} \\right) \\exp(-i \\omega^{T}(x - x'))\\, d(x - x') \\\\ \u0026= \\int \\exp\\left( -\\frac{\\lVert x \\rVert_{2} ^{2}}{2l} -i \\omega^{T}x \\right)\\, dx \\\\ \u0026= (2l^{2}\\pi)^{d/2} \\exp\\left( -\\frac{l^{2}\\lVert \\omega \\rVert_{2}^{2}}{2} \\right) \\end{align} $$ In the last part we completed the square by adding and removing $(ilw^{T})^{2} / 2$\nExponential Kernel $$ k(x_{i}, x_{j} ; l) = \\exp\\left( - \\frac{1}{l} \\lvert x_{i} - x_{j} \\rvert \\right) $$ They are also called Ornstein-Uhlenbeck Kernels or Laplace Kernels.\nMat√©rn Kernels These kernels have a quite weird form:\n$$ k(x_{i}, x_{j}; v, \\ell) = \\frac{2^{1 - v}}{\\Gamma(v)} \\left( \\frac{\\sqrt{ 2v }}{\\ell} \\lVert x_{i} - x_{j} \\rVert_{2} \\right)^{v} K_{v} \\left( \\frac{\\sqrt{ 2v }}{\\ell} \\lVert x_{i} - x_{j} \\rVert_{2} \\right) $$ I currently do not know what are these used for. But it is $\\lceil v \\rceil - 1$ times differentiable.\nPeriodic Kernels $$ k(x, x') = \\sigma^{2} \\exp \\left( - \\frac{\\left( 2\\sin ^{2}\\left( \\frac{\\pi \\lVert x' - x \\rVert }{p} \\right) \\right)}{l^{2}} \\right) $$Reproducing Kernel Hilbert space Definition of RKHS üü© $$ \\mathcal{H}_{k}(\\mathcal{X}) = \\left\\{ f(x) = \\sum_{i = 1}^{n} \\alpha_{i}k(x, x_{i}) :n \\in \\mathbb{N}, x_{i} \\in \\mathcal{X} , \\alpha_{i} \\in \\mathbb{R}\\right\\} $$$$ \\langle f, g \\rangle_{k} = \\sum_{i = 1}^{n}\\sum_{j = 1}^{n '}\\alpha_{i}\\alpha'_{j} k(x_{i}, x'_{j}) $$$$ \\lVert f \\rVert _{k} = \\sqrt{ \\langle f, f \\rangle _{k} } $$The Reducing Property üü©\u0026ndash; $$ f(x) = \\langle f(\\cdot), k(x, \\cdot) \\rangle _{k} $$ Meaning a simple evaluation of the function can be understood as a inner product between itself and a kernel.\n$$ f(x) = \\sum_{i = 1}^{n} \\alpha_{1} k(x, x') = \\sum_{i = 1}^{n} \\alpha_{1} \\langle k(\\cdot, x), k(\\cdot, x') \\rangle_{k} = \\langle \\sum_{i = 1}^{n} \\alpha_{1}k(\\cdot, x), k(\\cdot, x') \\rangle_{k} = \\langle f(\\cdot), k(x, \\cdot) \\rangle _{k} $$ $\\square$\nNorm as a measure of smoothness üü® $$ \\lvert f(x) - f(y) \\rvert \\leq \\lVert f \\rVert _{k} \\lVert k(x, \\cdot) - k(y, \\cdot) \\rVert _{k} $$$$ \\lvert\\langle f, k(x, \\cdot) - k(y, \\cdot) \\rangle \\rvert^{2} \\leq \\langle f, f \\rangle \\cdot \\langle k(x, \\cdot) - k(y, \\cdot), k(x, \\cdot) - k(y, \\cdot) \\rangle $$$$ \\langle f, k(x, \\cdot) - k(y, \\cdot) \\rangle = \\sum_{i = 1}^{n} \\alpha_{i} (k(x, x_{i}) - k(y, x_{i})) = f(x) - f(y) $$ Then taking the square root has the desired output.\nThe Representer Theorem $$ \\hat{f} \\in \\arg \\min_{f} l(f, D) + \\lambda \\lVert f \\rVert ^{2}_{k} $$$$ \\hat{f}(x) = \\alpha^{T} k_{x, A} $$ Where $A$ are all points in the Dataset without the labels. Something similar to this, the Riesz representation theorem, will be used in Counterfactual Invariance for the MMD computation.\nReferences [1] Bishop ‚ÄúPattern Recognition and Machine Learning‚Äù Springer 2006\n","permalink":"https://flecart.github.io/notes/kernel-methods/","summary":"\u003cp\u003eAs we will briefly see, Kernels will have an important role in many machine learning applications. In this note we will get to know what are Kernels and why are they useful. Intuitively they measure the \u003cstrong\u003esimilarity\u003c/strong\u003e between two input points. So if they are close the kernel should be big, else it should be small.\u003c/p\u003e\n\u003cp\u003eWe briefly state the requirements of a Kernel, then we will argue with a simple example why they are useful.\u003c/p\u003e","title":"Kernel Methods"},{"content":"Metodi di key exchange\nTrusted Key parties (sono come Certificate authorities studiati in Sicurezza delle reti) Merkle Puzzles DH protocol Trusted Third parties Squared Key problem Un problema abbastanza ovvio √® che per storare le chiavi di tutti c\u0026rsquo;√® una necessit√† $O(n^{2})$ on $O(n)$ users Se c\u0026rsquo;√® un trusted key parties il numero delle chiavi si riduce di molto, ritorna ad essere lineare!\nProtocols Toy Exchange protocolüü© TTP = Trusted Third party (simile a quanto poi si avr√† in Asymmetric Cryptography) Questa √® la base del servizio di Kerberos! Il servizio di sopra √® sicuro su Choosen plaintext, dato che Eve non capisce niente senza le chiavi!\nQuindi in pratica vengono scambiate due cose, un ticket e la chiave segreta, creati da TTP che sa creare segreti e conosce singole chiavi di tutte.\nAssumendo CPA security l\u0026rsquo;attaccante non pu√≤ sapere niente su $k_{AB}$, che sembra roba random. Problema:\nTTP √® il single node of failure se viene compromesso tutto viene compromesso, √® un obiettivo troppo Juicy. Pu√≤ essere soggetto a replay attacks senza problemi (ad esempio rimandando quanto mandato da Alice (es. se √® stato comprato qualcosa, se si ripete tutto si compra di nuovo, questo √® un danno)). La cosa carina √® che usa solo chiavi simmetriche, niente di nuovo rispetto Classical Cyphers, OTP and Stream Ciphers, Block Ciphers. Merkle Puzzles vogliamo cercare di risolvere problemi di origliamento (eavesdrop, senza modifiche varie sul messaggio. Avversario passivo. Vogliamo farlo senza avere un #Trusted Third parties, ma vogliamo usare solamente symmetric crypto. La cosa √® che questo √® possibile, ma molto inefficiente per cui inutili nella pratica.\nThe puzzle protocol Suppose we have $E(k, m)$ with $k \\in \\left\\{ 0, 1 \\right\\}^{128}$. Define $E(P, message)$ and $P = 0^{96} \\mid b_{1}\\dots b_{32}$, and a $x_{i} \\in \\left\\{ 0, 1 \\right\\}^{128}$and we want to find $P$ back by some sort of brute-force.\nAlice:\nCreates $2^{32}$ puzzles by creating $E(0^{96} \\mid P_{i}, \\text{ \"Puzzle \\#}x_{i} \\text{\"} \\mid k_{i})$ Sends every puzzle to Bob Bob: Chooses a puzzle randomly and tries to solve it (try all possible $P_{i}$), when the first part matches, the puzzle is solved Send $x_{j}$ to Alice Alice: Check what puzzle was chosen, then $k_{j}$ is the shared key. Quadratic Gap Alice and Bob to $O(n)$ work to create and solve a single puzzle. An attacker would need to break all the $2^{32}$ keys, so it is $O(n^{2})$ cost, which is $2^{64}$.\nTo increase the security, they should make $n$ bigger, but it would be very very slower. The nice idea is that participant has linear time, while the attacker needs squared time. It is called quadratic gap. We don¬¥t know if quadratic gap is the best gap we can do, but intuition says so.\nDiffie-Hellman Protocol In this case we have a exponential gap between participant and attacker.\nIntroduzione DH üü© Questo √® quello che abbiamo studiato anche a Olycyber quindi √® pi√π facile. √à basato su una costruzione matematica molto simile a RSA.\nIn pratica cos√¨\nScelgo $p$ primo largo Scelgo $g$ Alice sceglie $a$, e manda $g^{a}$ a Bob Bob fa lo stesso con $b$ Il segreto √® $g^{ab}$ , che √® difficile da capire con i moduli, faremo una analisi di sicurezza in seguito. Best algorithm for attacking this is $\\exp (O(\\sqrt[3]{ n})$, it is the Generalize Field Sieve (with a very high constant, like 80), not explained here here.\nDifficulty comparison Simmetric cipher DH Elliptic Curve 80 bits 1024 bits 160 bits 128 bits 3072 bits (in reality about 2048) 256 bits 256 bits 15360 bits 512 bits Attacco a DH üü© DH √® insicuro dal punto di vista del Man in the middle. Perch√© se uno in mezzo intercetta, pu√≤ usare la sua chiave privata al posto di quella dell\u0026rsquo;altro interlocutore. Tanto conosce il valore di $g$ e gli basta questo. ","permalink":"https://flecart.github.io/notes/key-exchange-protocols/","summary":"\u003cp\u003eMetodi di key exchange\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTrusted Key parties (sono come Certificate authorities studiati in \u003ca href=\"/notes/sicurezza-delle-reti/\"\u003eSicurezza delle reti\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eMerkle Puzzles\u003c/li\u003e\n\u003cli\u003eDH protocol\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"trusted-third-parties\"\u003eTrusted Third parties\u003c/h2\u003e\n\u003ch3 id=\"squared-key-problem\"\u003eSquared Key problem\u003c/h3\u003e\n\u003cp\u003eUn problema abbastanza ovvio √® che per storare le chiavi di tutti c\u0026rsquo;√® una necessit√† $O(n^{2})$ on $O(n)$ users\nSe c\u0026rsquo;√® un trusted key parties il numero delle chiavi si riduce di molto, ritorna ad essere lineare!\u003c/p\u003e\n\u003ch3 id=\"protocols\"\u003eProtocols\u003c/h3\u003e\n\u003ch4 id=\"toy-exchange-protocol\"\u003eToy Exchange protocolüü©\u003c/h4\u003e\n\u003cp\u003eTTP = Trusted Third party (simile a quanto poi si avr√† in \u003ca href=\"/notes/asymmetric-cryptography/\"\u003eAsymmetric Cryptography\u003c/a\u003e)\n\u003cimg src=\"/images/notes/Key Exchange protocols-20240312110014411.webp\" alt=\"Key Exchange protocols-20240312110014411\"\u003e\u003c/p\u003e","title":"Key Exchange protocols"},{"content":"Gran parte di quanto scrivo ora √® tratto da (Li \u0026amp; Vit√°nyi 2019). Chaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni \u0026lsquo;60!\nSolomonoff lo ha trovato sul problema dell\u0026rsquo;induzione all\u0026rsquo;et√† di 38 anni, Kolmogorov invece era gi√† tardi, ha gi√† trovato gli assiomi della probabilit√† e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilit√†, nel 68 all\u0026rsquo;et√† di 19 anni. In AI teorico questo sembra un tema molto importante.\nCi sono degli esempi carini nella compressione di numeri naturali e stringhe binarie in Introduction to Algorithmic Information and Complexity.\nIntuizione Kolmogorov Per quanto ho capito io sulle motivazioni che sono state base alla creazione di questo concetto √® il concetto che: per descrivere cose complesse c\u0026rsquo;√® necessit√† di pi√π parole. Questa idea molto intuitiva la possiamo tradurre da un punto informatico come il programma pi√π corto per produrre un certo output.\nUn esempio classico √® una comparazione fra una stringa 01010101010101 contro una altra del tipo 11101111111100101011110000010101. Intuitivamente potremmo dire che la prima stringa sia molto pi√π semplice da descrivere rispetto alla seconda stringa, abbiamo per√≤ bisogno di un modo formale per descrivere questo concetto.\nFormalizzazione Definizione Kolmogorov Definiamo la complessit√† di Kolmogorov $K_{L}(\\omega )$ per un certo linguaggio di programmazione $L$ come la minima lunghezza del programma tale per cui se eseguita sulla macchina astratta di $L$ dia come output $\\omega$.\n$$ C(x) = \\min_{p}\\left\\{ length(p) : U(p) = x \\right\\} $$ Ossia il programma pi√π corto che se eseguito su una macchina di Turing completa ho $x$.\nNOTA: questa definizione seppur meno informale di prima, non √® ancora quella formalmente accettata, per√≤ fa il suo per trasmettere l\u0026rsquo;idea, vedere il libro [^2] per definizione matematicamente corretta (e anche molto pi√π astrusa)\nComplessit√† condizionale\nla complessit√† di Kolmogorov condizionale $K_{L}(\\omega | x)$ √® la lunghezza minima di un programma che prende in input $x$ e produce in output $\\omega$. (si legge proprio come se fosse un qualcosa di condizionato)\n$$ K(x) \\le \\lvert x \\rvert + c \\tag{1} $$ Dove $c$ √® una costante per codificare le istruzioni per stampare. Pi√π intuitivamente un programma di questo genere pu√≤ stampare il carattere (dimostreremo in seguito, in #Teorema dell\u0026rsquo;invarianza che idea simile vale per ogni linguaggio)\nQuesto lemma giustifica anche la seguente definizione\nStringhe incomprimibili una stringa $\\omega$ si dice incomprimibile nel momento in cui $K(\\omega) = \\lvert \\omega \\rvert + O(1)$\nChe insieme all\u0026rsquo;upper bound di sopra, si avr√† che √® il massimo di complessit√† che pu√≤ avere.\nKolmogorov condizionato Condizionato $K(A|B)$ significa che diamo alla nostra macchina di turing in input anche $B$ per codificare $A$. Puoi vedere subito che la complessit√† di $K(A|A)$ √® $0$ perch√© la macchina di turing pu√≤ non fare nulla $\\varepsilon$ √® il programma diciamo, e avere subito un risultato. Intuitivamente avere qualcosa in pi√π non fa altro che ridurre il codice necessario, quindi possiamo dire che $K(A|B) \\leq K(A)$. E qui si pu√≤ creare anche una nozione di indipendenza.\nChain Rule $$ K(A|B) \\geq K(A, B) - K(B) $$ Ossia la codifica di entrambi, sia $A$ che $B$ √® necessariamente minore di codificare prima $B$ e poi usare questa per codificare $A$. Si pu√≤ dimostrare ma intuitivamente questa legge sembra parlare in modo chiaro.\n$$ C(s_{1}) \\leq C(s_{2}) + C(s_{1} | s_{2}) + O(\\log(C(s_{2}))) $$ Il motivo di questo $O$ grande strano √® che\n$\\log(C(s_{2}))$ is the maximal length of the information needed to separate the program that computes $s_{2}$¬†from what comes next (as we cannot guarantee that this program is uniquely decodable, contrary to the prefix case).\nMa non lo ho capito ancora bene.\nIncomputabilit√† di Kolmogorov Dimostrazione: Supponiamo che sia computabile, allora abbiamo un programma $P$ che calcola il programma minimo. Ora possiamo usare questo programma per trovare una stringa la cui complessit√† di Kolmogorov sia pi√π lunga di un certo $n$. Questo si pu√≤ fare provando ad aggiungere roba (probabilmente qui mi serve un lemma che dice che √® crescente stretto e non lasco). Ma la complessit√† di questa nuova stringa trovata deve essere uguale alla complessit√† di $n$, che gli d√≤ in input! (pi√π costante per la ricerca che ignoro per Kolmogorov). Questo significa che $K(n) \u003e n$ che √® assurdo perch√© $K(n) \\approx \\log_{2}(n)$ che √® strettamente minore di $n$.\nPossiamo per√≤ approssimare il valore, e per molte cose questo basta!\nKolmogorov complexity is an ideal notion that can be approximated, but that is not computable.\nUn pseudocodice di esempio per computare una cosa pi√π complessa (anche se non ho la dimostrazione che fa quello che deve fare, perch√© in teoria credo pu√≤ continuare in modo arbitrariamente lungo, solo che la probabilit√† che non finisca tende a 0)\ndef MoreComplex(n): i =1 while True: for m in range(2**i): s = bin(m)[2:]¬†if cc(s) \u0026gt; n:¬†return s i += 1 Teorema dell\u0026rsquo;invarianza Questo √® un teorema fondamentale (e anche di base) per quanto riguarda la definizione della teoria inerente a questa complessit√†. Ci permette di affermare che il concetto di complessit√† √® indipendente dal linguaggio di programmazione utilizzato, e ci dar√† presto anche alcuni risultati interessanti sulla computabilit√† di questa funzione (in modo diverso rispetto alle classiche dimostrazioni che si possono trovare in teoria della computabilit√†). Quindi questo teorema √® fondamentale per stabilire l\u0026rsquo;oggettivit√† della propriet√†. Cos√¨ possiamo dire che √® una propriet√† dell\u0026rsquo;oggetto, non di come lo stai valutando. Quindi non dipende dalla capacit√†/architettura di chi sta valutando il linguaggio.\n$$K_{L}(\\omega) = K_{L^{'}}(\\omega) + O(1)\\tag{2}$$ $$ K_{L^{'}}(w) = K_{L}(\\omega) + |I| \\tag{2.1} $$ ossia il costo per esprimere la complessit√† della string $\\omega$ in $L^{'}$ √® equivalente al costo per esprimere il programma $p$ in $L$, ed eseguirlo con un interprete (che avr√† una lunghezza finita, e costante una volta fissato i due linguaggi). L\u0026rsquo;interprete esiste perch√© stiamo usando macchine di Turing universali per la descrizione della lunghezza.\nNOTE: Grazie a questa propriet√† da ora in poi potremo parlare di $K(\\omega)$ indipendentemente da linguaggio su cui √® stato scritto, dato che tanto distano di una costante uno dall\u0026rsquo;altro.\nNOTE2: √à una cosa molto curiosa il fatto che sia dipendente dall\u0026rsquo;osservatore, anche se abbiamo una differenza, perch√© cose importanti per qualcuno, sono codificate in modo differente da ognuno. Questo √® un pensiero molto deep, e l\u0026rsquo;esempio della versione della macchina √® chiaro.\nEsistenza di stringhe complesse $$ \\forall n \\in \\mathbb{N}, \\exists \\omega : K(w) \\geq n $$che √® un risultato che non sembra avere molto senso perch√© ci sta dicendo che esistono delle stringhe di complessit√† infinita (forse queste stringhe sono quelle non computabili, perch√© il programma che lo descrive dovrebbe avere lunghezza infinita).\nDimostrazione: La dimostrazione di questo teorema non √® altro che una applicazione del pigeonhole principle. In un certo senso salta fuori dalla relazione fra il finito e l\u0026rsquo;infinito, come quelle cose assurde che $2n$ √® in bigezione con i numeri naturali. Siamo nel mondo di Turing, quindi i programmi saranno anch\u0026rsquo;esse delle stringhe binarie. Consideriamo tutti i programmi di lunghezza zero. Questo produrr√† la stringa vuota, ossia la stringa di complessit√† zero. Supponiamo ora tutti i programmi di lunghezza uno. Al massimo potremo avere due stringhe con questa complessit√†. E cos√¨ via. Intuitivamente: dato che il numero delle stringhe $\\omega$ che possono esistere sono infinite, anche i la lunghezza dei programmi utilizzati per generare queste stringhe sono infinite, perch√© banalmente un programma di lunghezza $n$ pu√≤ generare al massimo $2^n$ stringhe diverse, un numero finito, anche se enormemente ampio.\nNon calcolabilit√† della funzione di Kolmogorov La funzione di Kolmogorov non √® calcolabile su un macchina di Turing\nDimostrazione: Supponiamo che esista una macchina di Turing $M$ che prenda in input una stringa $\\omega$ e ritorni $K(\\omega)$. Utilizzeremo il teorema #Esistenza di stringhe complesse\nAllora utilizziamo questa macchina di Turing $M$ per costruirne una altra $M^{'}$ che si comporti in questo modo:\ninput n for each string w in alphabet: do if K(w) \u0026gt;= n: return w done endfor In pratica vado a scorrere tutte le parole nell\u0026rsquo;alfabeto infinito, so che prima o poi trover√≤ una stringa tale per cui $K(w) \\geq n$ perch√© ne abbiamo dimostrato l\u0026rsquo;esistenza precedentemente. Questa macchina allora descriver√† la stringa $\\omega$ che viene in output, dato l\u0026rsquo;input $n$.\n$$ n \\leq K(\\omega) \\leq \\lvert \\langle M^{'}, n \\rangle \\rvert + O(1) = O(1) + \\lvert n \\rvert = O(1) + O(\\log(n)) = O(\\log(n)) $$Ed √® assurdo perch√© afferma che $O(n) \\leq O(\\log(n))$ che sar√† vero per $n$ abbastanza alto.\nUpper bound con entropia Kolmogorov si pu√≤ vedere come una cosa pi√π generale dell\u0026rsquo;entropia di Shannon Entropy, si pu√≤ vedere come una approssimazione di essa perch√© basta prendere $L \\approx \\log_{2}\\left( \\frac{1}{p} \\right)$ e si ha l\u0026rsquo;entropia Shannoniana. La cosa carina √® che Kolmogorov ha senso anche in assenza di frequenze e probabilit√†.\nCose che non ho capito Per qualche motivo la complessit√† di un oggetto scende quando l\u0026rsquo;entropia √® massima (ah, quando sono tutti uguali le probabilit√†, la complessit√† scende)\nParte vecchia dal libro di complexity Questo √® il teorema fondamentale di questo campo, che ricordiamo prova a cercare di creare una teoria sulle descrizioni di minima lunghezza per qualcosa, questo dovrebbe essere in grado di risolvere il problema del limite della probabilit√†, e cose di teoria dell\u0026rsquo;informazione che non ho ancora ben compreso.\n$$ C_{f}(x) = min\\{l(p) : f(p) = n(x)\\} $$ $f$ √® una macchina di turing.\nUna volta definito questo e creato un insieme fisso di macchine o funzioni si pu√≤ estendere questo modello in classi di equivalenza, perch√© possiamo utilizzare $\\langle n, p \\rangle$ on $n$ l\u0026rsquo;index alla macchina corretta e $p$ il nostro programma (anche se non ho capito perch√© si assume che il programma sia comprensibile a qualunque macchina, e non ho capito perch√© la funzione la si pu√≤ intendere come se fosse una macchina, questa √® una parte di teorica che mi dovrei recuperare).\n$$ C_{\\phi_{0}}(x) = C(x) $$ per ogni programma $x$.\nReferences [1] Li \u0026amp; Vit√°nyi ‚ÄúAn Introduction to Kolmogorov Complexity and Its Applications‚Äù Springer International Publishing 2019\n","permalink":"https://flecart.github.io/notes/kolmogorov-complexity/","summary":"\u003cp\u003eGran parte di quanto scrivo ora √® tratto da \u003ca href=\"http://link.springer.com/10.1007/978-3-030-11298-1\"\u003e(Li \u0026amp; Vit√°nyi 2019)\u003c/a\u003e.\nChaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni \u0026lsquo;60!\u003c/p\u003e\n\u003cp\u003eSolomonoff lo ha trovato sul problema dell\u0026rsquo;induzione all\u0026rsquo;et√† di 38 anni, Kolmogorov invece era gi√† tardi, ha gi√† trovato gli assiomi della probabilit√† e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilit√†, nel 68 all\u0026rsquo;et√† di 19 anni.\nIn AI teorico questo sembra un tema molto importante.\u003c/p\u003e","title":"Kolmogorov complexity"},{"content":"Questi appunti sono stati scritti leggendo il (Russell \u0026amp; Norvig 2009).\n1 Introduzione L‚Äôintelligenza artificiale √® un campo in velocissima espansione, con gi√† un mercato enorme di un trillion dollars.\nInoltre il suo campo di studi spazia da moltissimi campi, √® per questo che quasi potresti considerarla universale.\n1.1 L‚Äôintelligenza artificiale 1.1.1 Cosa √® (2) Nel tempo si √® cercato di definire con esattezza cosa sia l‚Äôintelligenza artificiale. In generare si √® basato su alcuni parametri cardine ossia:\nLa capacit√† di replicare attivit√† umane / la capacit√† di applicare attivit√† razionali La capacit√† di ragionare / il comportamento intelligente Su questi due binomi sono stati fatti dei modelli, andiamo ora a scoprire in che senso l‚Äôintelligenza artificiale √® intelligente.\n1.1.2 Modelli generali Tra i modelli presenti quello di maggiore interesse nel tempo √® stato l‚Äôultimo, per il resto vanno a toccare molti campi che sono un p√≤ fuori dalle competenze dell‚Äôinformatico. (credo)\nAgire umanamente Come il test di turing, definisce l‚Äôintelligenza artificiale come un software che riesce ad emulare il comportamento umano, talmente che non riusciresti a riconoscerlo.\nMa i ricercatori hanno preferito cercare di capire cosa √® l‚Äôintelligenza in s√©, invece di cercare di emulare quella umana.\nPensare umanamente Questo modello ha un campo molto fiorente nelle scienze cognitive, attraverso scan delle immagini, o comunque una conoscenza approfondita in primo luogo della stessa conoscenza umana, vogliamo cercare di costruire un intelligenza artificiale che ne emuli le capacit√† (pensiero interiore, psicologia etc).\nPensare logico Questo √® stato uno dei primi metodi per costruire un software che si potesse considerare intelligente. Si basa sugli sviluppi della logica come campo di studi: ossia la possibilit√† di costruire software che siano in grado di dimostrare tutto il possibile.\nOppure utilizzando una analisi probabilistica, per analizzare la realt√†.\nAgire logico L‚Äôimmagine dell‚Äôagente √® stato il metodo pi√π florido nella storia dell‚Äôintelligenza artificiale nel momento in cui se ne voleva costruire una. Tanto che l‚Äôobiettivo della costruzione di un ente che potesse agire in modo logico in un ambiente si potrebbe considerare come se fosse un modello standard per la costruzione di un intelligenza artificiale.\nUn problema per√≤ sorge: allineamento dei valori: a volte fare la cosa logicamente pi√π corretta non √® la migliore soluzione, esempio se l‚Äôobiettivo fosse vincere a tutti i costi una partita a scacchi, l‚Äôagente, con la possibilit√† di agire sull\u0026rsquo;ambiente circostante, potrebbe compiere azioni che solitamente considereremmo ingiuste, al solo scopo di raggiungere questo obiettivo! ‚Üí vorremmo costruire qualche agente che sia in grado di portare un beneficio provato (dimostrato).\n1.2 L‚Äôagente Definiamo in modo molto generale, l‚Äôagente come qualcosa che possiede attuatori e percettori per interagire e percepire l‚Äôambiente (che pu√≤ essere molto vario).\nUn concetto importante √® che l‚Äôagente pu√≤ basare il suo output attraverso solamente ci√≤ che ha percepito (dall\u0026rsquo;inizio fino al tempo corrente) quindi potremmo considerare l‚Äôesistenza di una funzione agente che mappa sequenza input ‚Üí azione. e l‚Äôimplementazione di essa.\n1.2.1 La razionalit√† Vogliamo cercare di dare una definizione di razionalit√† in qualunque agente, e si pu√≤ formalizzare in questo modo: PEAS FRAMEWORK (performance, environment, actuators, sensors)\nUna funzione di performance L‚Äôinsieme delle conoscenze a priori sul mondo L‚Äôinsieme delle azioni possibili sul mondo La sequenza di percezione Con questi 4 oggetti, definiamo che l‚Äôagente √® intelligente se la funzione che prende in input la sequenza di percezione e le conoscenze sul mondo, dia in output l‚Äôazione che massimizza la performance.\nLa misura della performance Il modo migliore che abbiamo per misurare la performance √® sulle conseguenze che ha sull\u0026rsquo;ambiente. Quindi valutare se l‚Äôeffetto che ha √® positivo (sempre in funzione alla positivit√† descritta da chi ha progettato l‚Äôagente) o negativo.\nUna nota: √® importante costruire la performance secondo gli effetti sull\u0026rsquo;ambiente, e non secondo il modo con cui si dovrebbe comportare l‚Äôagente!\nMa non √® detto che sia il modo migliore per fare ci√≤, √® un problema pi√π filosofico (quello sugli effetti uguali, ma uno sta basso e fa sempre, mentre l‚Äôaltro √® molto efficiente a momenti e per il resto del tempo sta proprio fermo).\nOnniscienza ed autonomia Non possiamo avere un agente che sappia tutto, bisogna tarare la performance su questa osservazione: l‚Äôazione scelta non deve essere la migliore possibile in assoluto (altrimenti l‚Äôagente dovrebbe sapere tutto) ma dovrebbe essere la migliore azione in guadagno atteso.\nQuesto comporta la migliore decisione che possa massimizzare scelte future (come raccolta delle informazioni si spende un p√≤ di tempo per raccogliere pi√π informazioni sull‚Äôambiente) oppure l‚Äôazione stessa nel caso si abbia gi√† conoscenza sull‚Äôambiente.\n√à da notare che il caso in cui si ha una totale conoscenza sull‚Äôambiente a priori (caso anche di alcune specie di animali come lowly dung beetle o sphex wasp) toglie di autonomia (ossia la capacit√† di agire a seconda di input ambientali e non solo secondo conoscenze a priori) all‚Äôagente, e potrebbe non dare le soluzioni volute (in questi casi l‚Äôagente agisce soltanto, perch√© pensa di sapere gi√† tutto).\n1.2.2 L‚Äôambiente Ci sono una moltitudine di variabili che possono risultare utili per classificare un ambiente tra cui:\nDeterminismo-nondeterminismo o stocastico Osservabilit√† parziale-totale singolo-multi agente episodico - sequenziale (si basa o no su eventi passati?) statico o dinamico (o semidinamico) (l‚Äôambiente pu√≤ cambiare quando l‚Äôagente pensa sul da farsi?) discreto o continuo (gli stati sono infiniti o finiti?) conosciuto o sconosciuto (i risultati delle azioni sono conosciute a priori, come se fossero leggi della fisica). Per esempio, il progetto mnk-game √® un ambiente che √® Determinista, totalmente osservabile, agente multiplo, sequenziale, statico, discreto e conosciuto.\nQuesti direi sono i 7 cardini che definiscono ad alto livello un ambiente.\n1.3 Tipologie di agente In questa parte vengono descritti le tipologie di agente a cui si √® pensato. Parlando in generale √® come se fossero dei modelli che vengono costruiti uno sopra l‚Äôaltro, in senso crescente, fino ad arrivare all‚Äôagente che apprende come modello finale (correntemente pi√π gettonato).\nI modelli qui presentati sono molto astratti, utili per semplicit√† e chiarezza, ma non ci aiuta in alcun modo per capire come implementare tale modello, tutti gli agenti qui presentati saranno di questo tipo\n1.3.1 Basati su riflessi L‚Äôagente che si basa sui riflessi √® il pi√π semplice degli agenti che possono essere presenti. Come dice il nome si basa sul concetto di riflesso molto simile al riflesso umano, come sbattere le ciglia, scattare via da una fonte di calore simili azioni.\nSi tratta di un agente che agisce sulla singola percezione e trova l‚Äôazione corrispondente a seguito di questa. Le percezioni passate non interessano proprio, sa gi√† agire subito dalla percezione presente.\nCaratteristiche di questo agente:\nStaticit√† nelle azioni, esegue solo ci√≤ per cui √® programmato, quasi fosse un if-then agent, infatti dovremmo parlare di regole di condizione-azione\nNecessit√† di osservabilit√† totale, altrimenti √® difficile che faccia l‚Äôazione pi√π intelligente\nModello in breve\n1.3.2 Basati su modelli Questo modello si pu√≤ considerare una espansione al modello precedente. Si cerca piano piano di rendere l‚Äôagente pi√π flessibile, e non soltanto qualcosa di programmato, come se fosse un singolo algoritmo:\nOra l‚Äôagente possiede un modello interno del mondo, che √® cambiato a seconda della percezione nel momento. Quindi l‚Äôazione ora non √® presa solamente secondo la percezione attuale, ma anche secondo il modello del mondo, e la percezione attuale.\nCaratteristiche\nFunzione di transizione del modello, che serve per aggiornare il modello interno del mondo a seconda dei cambiamenti percepiti Funzione di sensore, che traduce le informazioni percepite in funzione dello stato del mondo (es. se ho la telecamera sporca di acqua per la pioggia, l‚Äôinput sar√† un p√≤ diverso) Quindi maggiore flessibilit√† in confronto alla precedente.\nModello in breve\n1.3.3 Basati su obiettivi L‚Äôulteriore espansione di questo agente rispetto alla precedente √® che ora il modello tiene conto anche delle possibili conseguenze future delle proprie azioni in funzione del raggiungimento o meno del proprio obiettivo\nCaratteristiche\nEsistenza di un obiettivo ben dichiarato proprio (che condiziona la funzione di valutazione) Possibilit√† di rimpiazzare l‚Äôobiettivo precedente con uno simile (flessibilit√†) Aggiornamenti su conseguenze delle proprie azioni sullo stato del raggiungimento per l‚Äôobiettivo Modello in breve\n1.3.4 Basati su utility cerca di valutare se √® una conseguenza buona o cattiva, a seconda di una propria funzione di valutazione che cerchi di rispettare il meglio possibile la funzione di valutazione dell‚Äôambiente in cui √® presente.\n√à buono in caso ci possano essere degli obiettivi che si eliminano uno a vicenda, √® buono per trovare i tradeoff **comune in molte situazioni (es. voglio arrivare pi√π in fretta possibile, ma non voglio investire persone).\nCaratteristiche\nUna funzione di valutazione che cerca di massimizzare il valore atteso della propria azione. Modello in breve\n1.3.5 Basati su apprendimento Al fine di avere un agente flessibile che possa adattarsi in ambienti anche molto differenti fra di loro, vorremmo creare un metodo per cui l‚Äôagente possa imparare dai propri errori. Questo modello si prefissa l‚Äôobiettivo di creare un framework generale per un agente che impara.\nCaratteristiche:\nCritico: cerca di valutare le azioni prese dall‚Äôagente e pone consigli su cosa cambiare Elemento apprendimento: che cambia lo stato di conoscenza interna dell‚Äôagente in modo che possa prendere decisioni migliori, grazie al feedback del critico generatore di problemi che propone nuovi problemi/esperimenti che possono migliorare altri tratti dell‚Äôagente. Modello in breve\nL‚Äôagente vecchio √® interamente raccolto nel performance element\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/l‚Äôintelligenza/Untitled 6.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/l‚Äôintelligenza/Untitled 6\u0026quot;\u0026gt; References [1] Russell \u0026amp; Norvig ‚ÄúArtificial Intelligence: A Modern Approach‚Äù Prentice Hall Press 2009\n","permalink":"https://flecart.github.io/notes/lintelligenza/","summary":"\u003cp\u003eQuesti appunti sono stati scritti leggendo il (Russell \u0026amp; Norvig 2009).\u003c/p\u003e\n\u003ch1 id=\"1-introduzione\"\u003e1 Introduzione\u003c/h1\u003e\n\u003cp\u003eL‚Äôintelligenza artificiale √® un campo in velocissima espansione, con gi√† un mercato enorme di un trillion dollars.\u003c/p\u003e\n\u003cp\u003eInoltre il suo campo di studi spazia da moltissimi campi, √® per questo che quasi potresti considerarla \u003cstrong\u003euniversale\u003c/strong\u003e.\u003c/p\u003e\n\u003ch2 id=\"11-lintelligenza-artificiale\"\u003e1.1 L‚Äôintelligenza artificiale\u003c/h2\u003e\n\u003ch3 id=\"111-cosa-√®-2\"\u003e1.1.1 Cosa √® (2)\u003c/h3\u003e\n\u003cp\u003eNel tempo si √® cercato di definire con esattezza cosa sia l‚Äôintelligenza artificiale. In generare si √® basato su alcuni parametri cardine ossia:\u003c/p\u003e","title":"l‚Äôintelligenza"},{"content":"Introduzione Note filosofiche (non impo) Bisogna in primo momento cercare di definire cosa √® la computazione e cosa √® un computer. Aristotele faceva la distinzione fra propriet√† essenziali e accidentali. Quelle essenziali sono proprie dell\u0026rsquo;oggetto.\nUna sedia pu√≤ essere fatta di legno o di metallo, ma questa propriet√† √® accidentale, ovvero, essa rimane una sedia indipendentemente dal materiale di cui √® fatta.\nSolitamente in matematica si prova ad astrarre (vedi Astrazione sul controllo per nota generale sull\u0026rsquo;astrazione). Per√≤ in questo campo si sono trovati molte concezioni equivalenti. Fino ad arrivare a concepire la tesi di Church-Turing. Il prof. nota che questo √® strano, perch√© in altre discipline si converge in unico modello, mentre qui molte cose sono indifferenti. Questo √® importante per capire come la concezione di Computer Science si √® evoluta (Denning 2010).\nNascita della calcolabilit√†: Turing (curiosit√†) Al tempo si voleva in matematica trovare un formalismo, un fondamenta logico alla matematica che poteva permettere di dimostrare tutto dalle fondamenta. Il contributo principale, e secondo il prof il lavoro pi√π importante in tutta l\u0026rsquo;informatica era (Turing 1937), che definisce cosa significa calcolare un problema. Questo porta al significato di calcolare un problema. √à interessante notare come Turing arriva al suo formalismo. Osserva\nL\u0026rsquo;esecuzione di certe regole Un foglio di carta in cui sono lette e scritte dei simboli L\u0026rsquo;azione eseguita dipende dal simbolo precedente Da queste osservazioni iniziali, hanno astratto i dati (ora simboli binari) e le azioni, un set molti semplice. Osservazione: computazione √® locale. Questo sembra simile quanto dichiarato in (Dehaene 2014) quando si parla che l\u0026rsquo;essere umano √® capace di porre davanti l\u0026rsquo;attenzione della coscienza solamente un solo simbolo alla volta.\nLa macchina di Turing Vedere precedente per capire come √® stata ideata questa macchina di Turing.\nDefinizione matematica üü© √à interessante confrontare questa definizione con Fondamenti teorica#La macchina di turing in cui usiamo un formato leggermente diverso, il formato preciso √® quello precedente fatto a linguaggi. In sto corso usiamo un formalismo pi√π semplice). Nel nostro caso √® una 5-tupla di\n$\\Sigma$, un alfabeto di simboli finiti, con simbolo speciale per cella vuota $Q$ Un insieme di stati $q_{0} \\in Q$ lo stato iniziale $H \\subseteq Q$ l\u0026rsquo;insieme degli stati finali $\\delta$ la funzione di transizione che soddisfa questo: $$ \\delta : (Q - H) \\times \\Sigma \\to Q\\times \\Sigma \\times \\left\\{ \\to, \\leftarrow \\right\\} $$ La differenza √® che in questo caso l\u0026rsquo;alfabeto dell\u0026rsquo;input √® uguale all\u0026rsquo;alfabeto del nastro, ma alla fine cambia poco, basta TODO (capire) secondo me ha sbagliato il prof. tempo fa, perch√© l\u0026rsquo;alfabeto di input non √® mai preso in considerazione nella funzione di transizione boh. Questa sintassi √® pi√π comprensibile della precedente quindi nice.\nCome per tutti i precedenti automi, anche questi hanno una rappresentazione possibile a diagramma: A lezione abbiamo anche visto esempi di macchine che computano moltiplicazione binaria o addizione binaria.\nProblemi di decisione Definizione problemi di decisione üü© Molti problemi si possono codificare attraverso un problema di decisione, ossia un problema in cui abbiamo solamente bisogno di una risposta s√¨ o no. Se riusciamo a codificarlo con il linguaggio delle macchine di Turing, allora forse si pu√≤ far verificare alla macchina. Si vedr√† che molti problemi non vanno.\nSchema di codifica Ossia un dato $\\alpha$ sar√† descritto con $code(\\alpha) \\in \\Sigma^{*}$. Una nota interessante √® che con Kolmogorov complexity abbiamo un dato di lunghezza minima, qui vediamo bene il link molto diretto. Questo ha delle propriet√†:\n√à Iniettiva Vorremmo capire in $\\Sigma^{*}$ quali siano dei codici possibili per un qualche $\\alpha$ nel nostro dominio. Sarebbe carino poter ritrovare $\\alpha$ a partire dal suo codice. Definizione decidibilit√† üü© Dato un certo linguaggio, supponiamo di avere una macchina di Turing come definita di sopra #La macchina di Turing tale per cui abbia due stati finali $\\left\\{ H, N \\right\\}$, allora diciamo che $\\mathcal{M}$ decide $L$ se vale che\nQuando $x \\in L$ allora $\\mathcal{M}$ accetta $x$, ossia finisce su stato $H$ Quando $x \\not\\in L$ allora $\\mathcal{M}$ rigetta $x$, ossia finisce su stato $N$ Diciamo che un linguaggio $L$ √® decidibile se una macchina di Turing lo decide. Ora abbiamo formalizzato il significato di decidibilit√†. Un altro modo per dire che una macchina √® decidibile √® se si ferma per ogni input, questo significa che o finisce in stato accettante o in stato rigettante.\nDefinizione riconoscibilit√†/semidecibilit√† üü© Uguale al precedente, con la differenza che quando la stringa non appartiene al linguaggio diverge.\nDiciamo un linguaggio $L$ √® riconoscibile se una macchina di Turing lo riconosce. Th: Decidibilit√† -\u0026gt; Riconoscibilit√†, √® facile costruire una tale macchina di Turing partendo da una che la decide, possiamo estendere il caso negativo in questo modo: se raggiungo lo stato negativo allora vado in loop infinito a caso.\nDefinizione non riconoscibilit√† Significa che non pu√≤ dire in tempo finito n√© s√¨ n√© no. Quindi √® una cosa ancora pi√π forte rispetto la semidecibilit√†.\nGerarchia di Chomskyüü®+ Vedere Linguaggi liberi e PDA#Classificazione dei linguaggi alla sezione schema generale delle grammatiche. La cosa da ricordare √® che TM √® il modello pi√π generale fra tutti i precedenti modelli di macchine di Turing e automi. Tesi di Church-Turing Enunciato della tesiüü© Se la soluzione di un dato problema pu√≤ essere calcolata attraverso una procedura algoritmica, allora pu√≤ essere calcolata da una macchina di Turing. (Alonzo Church)\nAlonzo proponeva una altra teoria di calcolo, √® stato proponente di lambda calcolo. Quelli che piacevano a Asperti.\nStoricamente sembra vero, perch√© sempre prendendo qualcosa che sembra pi√π espressibile, resta alla fine equivalente a turing.\nEsempi di conseguenze:\nMacchine di Turing \u0026lsquo;migliorate\u0026rsquo; (nondeterministiche, probabilistiche, pi√π nastri‚Ä¶) Macchine a registri Linguaggi di programmazione di alto livello come Python, Java, C, ‚Ä¶ (Codice macchina di) computer classici ‚Ä¢ Computer quantistici Espressibilit√† vs semplicit√† e efficienzaüü© Probabilmente lo abbiamo citato in Fondamenti teorica, il fatto che questo √® solamente una congettura perch√© non √® possibile codificare tutti i formalismi possibili. Parla di espressibilit√† ossia cosa pu√≤ essere calcolato, e se questo vale permette di dire che √® una macchina universale. Infatti non dice nulla su semplicit√† o efficienza dell\u0026rsquo;algoritmo (in questa astrazione non ci interesssa).\nGiustificazione valenza di Turing (non impo) La cosa interessante di queste macchine comunque √® che La macchina di Turing ci permette di formalizzare!\nRigorosit√† di algoritmo. (anche se non mi sembra buono per esprimere certe forme di calcolo (Denning 2010)). Teoremi di calcolabilit√† possono essere estese a qualunque altro formalismo, se vale. Versione rafforzata Questa versione √® una estensione della tesi di Church-Turing in modo che comprenda la parte in Time and Space Complexity.\nOgni modello di calcolo deterministico fisicamente realizzabile pu√≤ essere simulato da una TM (deterministica, su nastro singolo) con overhead al pi√π polinomiale.\nSe ci pensiamo questa versione rafforzata √® simile a quanto dimostrato in Kolmogorov complexity riguardo la complessit√† sulla lunghezza della minima stringa che lo descrive, perch√© l√¨ abbiamo un overhead al massimo costante per tradurre da una macchina all\u0026rsquo;altra.\nChiusura del linguaggio di TM Chiusura sulla decidibilit√†üü© Complemento: √® molto semplice decidere sul complemento perch√© basta scambiare gli stati finali Unione: basta eseguirlo sul multinastro e comparare l\u0026rsquo;input, vedi Estensioni di Turing e altre macchine. Intersezione: Usi de morgan con i precedenti. Concatenazione: stessa dimostrazione per Grammatiche Regolari, concateni le macchine. Star: s√¨\nUn esercizio √® dettagliare la definizione di queste macchina, in modo simile a quanto facevamo al corso di linguaggi.\nNOTA: ricorda di seguire la struttura della dimostrazione. Se no te la conter√† come sbagliata all\u0026rsquo;esame.\nPer la concatenazione √® un po\u0026rsquo; pi√π difficile del previsto, perch√© non so bene dove devo andare a tagliare per la seconda stringa, quindi vado in modo non deterministico sul taglio, cos√¨ in pratica faccio tutte le cose possibili.\nChiusura sulla riconoscibilit√† üü© Complemento: No Unione s√¨, stessa cosa precedente. Intersezione: credo basti concatenarli con reset dell\u0026rsquo;input e dire che si accetta se arriva in fondo Concatenazione: s√¨ Star: dovrebbe s√¨.\nLa non chiusura del complemento la trovi in Halting Theorem and Reducibility. Perch√© si dimostra che $HALT$ e il suo complementare non sono chiusi, e questo basta per il complemento.\nLa macchina di Turing universale Esempi di macchine universali Sono dei programmi in grado di eseguire altri programmi. √à una cosa molto particolare dell\u0026rsquo;informatica questa cosa, permetterebbe per esempio di eseguire un programma su se stesso, una cosa ricorsiva (oroboro quasi). Esempi di macchine universali possono essere\nSistemi operativi Stack di hardware che abbiamo, ognuna universale che esegue una sopra l\u0026rsquo;altra. Anche questo √® stato pensato in (Turing 1937). Una cosa interessante √® che prima di esso, la macchina era pensata per una unica cosa, dopo Turing si pu√≤ usare la stessa macchina per tutti gli algoritmi possibili. Ha introdotto la nozione di programmabilit√†! Utilizzare il dato (l\u0026rsquo;algoritmo) come input di s√© stesso √® stato usato da G√∂del nella sua dimostrazione famosa. Ha codificato teoremi come numeri, permettendo l\u0026rsquo;uso dell\u0026rsquo;aritmetica stessa.\nDescrizione UTMüü© La cosa importante √® che: \u003e La macchina universale deve avere lo stesso comportamento di $\\mathcal{M}$. Se si ferma, si ferma con stesso output, altrimenti non si ferma.\nCostruzione di UTMüü© $$ code(t) = code(q_{i})0code(\\sigma_{n})0code(q_{j})0code(\\sigma(m))0code(\\sigma_{o})0 $$$$ code(\\sigma_{1i}...\\sigma_{in}) = 00code(\\sigma_1)0 code(\\sigma_{12}) 0 ... 0 code(\\sigma_{in}). $$ √à interessante osservare che questo formato $code(\\mathcal{M})code(i)$ √® una cosa decidibile, perch√© √® un formato che si conosce.\nLettura simboli macchina specifica Interpretazione di essa Poi si pu√≤ continuare ad utilizzare il nastro per simulare la macchina stessa. Per cominciare una simulazione della UTM:\nPasso di preparazione: verifica che y = code(‚Ñ≥)code(x) per qualche TM ‚Ñ≥ e input x. Se no, cicla. Se si, allora nastro 1 contiene code(‚Ñ≥)code(x). Vai al passo 2. Sposta code(‚Ñ≥) dal nastro 1 al nastro 2. Ora nastro 1 mostra il contenuto del nastro di ‚Ñ≥ su input x alla configurazione iniziale, in forma codificata. Scrivi code(q0) su nastro 3. Posiziona testina 1 sul primo simbolo di code(x), testina 2 sul primo simbolo di code(‚Ñ≥), and testina tre sul primo simbolo di code(q0). Quindi poi: Cerco la funzione transizione corretta sul nastro 2 che contiene la codifica, poi aggiorno i nastri 1 e 3 a seconda di cosa scrivo, della testina e dello stato corrente in nastro 3.\nReferences [1] Dehaene ‚ÄúConsciousness and the Brain‚Äù Singapore Books 2014\n[2] Denning ‚ÄúUbiquity Symposium \u0026lsquo;What Is Computation?\u0026rsquo;: Opening Statement‚Äù Ubiquity Vol. 2010, pp. 1880066.1880067 2010\n[3] Turing ‚ÄúOn Computable Numbers, with an Application to the Entscheidungsproblem‚Äù Proceedings of the London Mathematical Society Vol. s2-42(1), pp. 230\u0026ndash;265 1937\n","permalink":"https://flecart.github.io/notes/la-macchina-di-turing/","summary":"\u003ch3 id=\"introduzione\"\u003eIntroduzione\u003c/h3\u003e\n\u003ch4 id=\"note-filosofiche-non-impo\"\u003eNote filosofiche (non impo)\u003c/h4\u003e\n\u003cp\u003eBisogna in primo momento cercare di definire \u003cstrong\u003ecosa √® la computazione\u003c/strong\u003e e cosa √® un computer.\nAristotele faceva la distinzione fra propriet√† \u003cstrong\u003eessenziali\u003c/strong\u003e e \u003cstrong\u003eaccidentali\u003c/strong\u003e. Quelle essenziali sono proprie dell\u0026rsquo;oggetto.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eUna sedia pu√≤ essere fatta di legno o di metallo, ma questa propriet√† √® accidentale, ovvero, essa rimane una sedia indipendentemente dal materiale di cui √® fatta.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eSolitamente in matematica si prova ad astrarre (vedi \u003ca href=\"/notes/astrazione-sul-controllo/\"\u003eAstrazione sul controllo\u003c/a\u003e per nota generale sull\u0026rsquo;astrazione). Per√≤ in questo campo si sono trovati molte concezioni equivalenti. Fino ad arrivare a concepire la tesi di Church-Turing. Il prof. nota che questo √® strano, perch√© in altre discipline si converge in unico modello, mentre qui molte cose sono indifferenti.\nQuesto √® importante per capire come la concezione di Computer Science si √® evoluta \u003ca href=\"https://dl.acm.org/doi/10.1145/1880066.1880067\"\u003e(Denning 2010)\u003c/a\u003e.\u003c/p\u003e","title":"La macchina di Turing"},{"content":"Dato che il software sta diventando sempre pi√π diffuso, diventa sempre pi√π importante andare a definire delle metriche che possano garantirne la qualit√†, ossia la non frequenza di errori o bug che possono in qualche modo limitarne la qualit√†.\nError, Fault and Failure Secondo la definizione esatta data da IEEE, questi tre termini hanno un significato ben specifico, molto diverso.\nError, sono comportamenti non previsti da un comportamento dell\u0026rsquo;utente, oppure il programmatore capisce male le specifiche. Fault sono i bugs, degli errori nel codice che creano un comportamento non previsto Failure, sono comportamenti non previsti da specifiche, che crea un guasto e non permette il funzionamento Qualit√† del software Rating and Ranking Il rating √® l\u0026rsquo;assegnazione di un punteggio assoluto di qualit√† riguardo al prodotto.\nRanking √® comparazione fra un prodotto rispetto all\u0026rsquo;altro per\nCondizioni necessarie (4) Qualit√† interna ed esterna Ci sono quei principi utili possono essere categorizzati in attributi\noperativi di manutenzione (modificabilit√†) adattabilit√†, ossia se il software pu√≤ essere usato in ambienti diversi. Goal Question Metric Principi di qualit√† (3) Gli obiettivi del prodotto devono essere chiare Metriche di qualit√† per sapere cosa esattamente andare a misurare Le domande per vedere se un certo obiettivo √® stato raggiunto, da quanto ho capito √® un check midpoint per avere feedback, nello stesso modo per cui fatto in Modelli AGILE Tre livelli di analisi Obiettivi Domande Metriche per valutare domande Esempio: Verifica e validazione Verifica = quanto viene implementato bene la specifica, che √® anche ci√≤ che deve essere testato in automatico o manualmente. a seconda del formato pu√≤ essere ispezione (manuale) o testing.\nValidazione = accettazione da parte del cliente.\nAspetti da testare Una idea molto presente in questo √® la copertura ossia il programma dovrebbe funzionare a seconda del branch, dei moduli, in questo senso dovrebbe esserci una copertura pi√π ampia possibile.\nBlack and white box testing Il primo quando non si ha accesso al codice sorgente, ma si testa solametne la specifica come pu√≤ essere una user story\nWhite box quando abbiamo visibilit√† sul sorgente (ad esempio match diretto sul codice di ritorno, o fare i mocks).\nComplessit√† ciclomatica di McCabe $$ cc(G) = e - n + 2 \\cdot G $$ G sono sottografi sconnessi. $e$ sono gli archi, $n$ sono i nodi. cos√¨ viene definito un valore di complessit√† ciclomatico, e ci dice il numero di test che bisogna avere per essere abbastanza sicuri.\nE il diagramma di fllusso √® calcolabile, quindi si pu√≤ sempre fare, come rule of thumb se la complessit√† √® alta, il rischio √® alto.\nManutenzione del software Tipologie di correzione (3) Perfettiva Per migliorare, ci sono nuove funzionalit√† tipo 1/2 sono questi Correttiva, circa 1/4 dei cambi. Adattiva Per ambiente che cambia Esiste anche uno standard IEEE per gestire questo cambiamento.\nI costi nella manutenzione Personale instabile Progettisti non responsabili (bisogna rendere i progettisti) Inesperienza dei progettisti Il software vecchio. ","permalink":"https://flecart.github.io/notes/la-qualit%C3%A0-del-software/","summary":"\u003cp\u003eDato che il software sta diventando sempre pi√π diffuso, diventa sempre pi√π importante andare a definire delle metriche che possano garantirne la qualit√†, ossia la non frequenza di errori o bug che possono in qualche modo limitarne la qualit√†.\u003c/p\u003e\n\u003ch4 id=\"error-fault-and-failure\"\u003eError, Fault and Failure\u003c/h4\u003e\n\u003cp\u003eSecondo la definizione esatta data da IEEE, questi tre termini hanno un significato ben specifico, molto diverso.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eError, sono comportamenti non previsti da un comportamento dell\u0026rsquo;utente, oppure il programmatore capisce male le specifiche.\u003c/li\u003e\n\u003cli\u003eFault sono i bugs, degli errori nel codice che creano un comportamento non previsto\u003c/li\u003e\n\u003cli\u003eFailure, sono comportamenti non previsti da specifiche, che crea un \u003cstrong\u003eguasto\u003c/strong\u003e e non permette il funzionamento\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"qualit√†-del-software\"\u003eQualit√† del software\u003c/h3\u003e\n\u003ch4 id=\"rating-and-ranking\"\u003eRating and Ranking\u003c/h4\u003e\n\u003cp\u003eIl rating √® l\u0026rsquo;assegnazione di un punteggio assoluto di qualit√† riguardo al prodotto.\u003c/p\u003e","title":"La qualit√† del software"},{"content":"This is also known as Lagrange Optimization or undetermined multipliers. Some of these notes are based on Appendix E of (Bishop 2006), others were found when studying bits of rational mechanics. Also (Boyd \u0026amp; Vandenberghe 2004) chapter 5 should be a good resource on this topic.\n$$ \\begin{array} \\\\ \\min f_{0}(x) \\\\ \\text{subject to } f_{i}(x) \\leq 0 \\\\ h_{j}(x) = 0 \\end{array} $$Lagrangian function $$ \\mathcal{L}(x, \\lambda, \\nu) = f_{0}(x) + \\sum \\lambda_{i}f_{i}(x) + \\sum\\nu_{j}h_{j}(x) $$ We want to say something about this function, because it is able to simplify the optimization problem a lot, but first we want to study this mathematically.\nWe call $\\lambda_{i}, \\nu_{i}$ the lagrange multipliers associated with their function, where we have that $\\lambda_{i} \\geq 0$ and $\\nu_{i}$ are free. We can also define the dual function as $g(\\lambda, \\nu) = \\min_{x} L(x, \\lambda, \\nu)$.\nMotivation In this section we try to explain step by step why this method works. We will find that it is easier than we could expect this. With this, we will evaluate the maximum (for the minimum just take the dual)\nSingle Equation constraint $$ g(x + \\varepsilon) \\approx g(x) + \\nabla g(x) \\varepsilon $$$$ \\mathcal{L}(x, \\lambda) = f(x) + \\lambda g(x) $$ We observe that its stationary point needs to have its partial derivatives set to zero, so we would have the original partial derivative condition, and also the inequality constraint for $\\lambda \\neq 0$. In this way we can find both the $x$ and the $\\lambda$.\n$$ \\mathcal{L}(x, \\lambda) = f(x) + \\lambda g(x) $$ So that the derivative has opposite direction. (actually I don\u0026rsquo;t have understood this point).\nAnother intuition The parameters for the Lagrange Optimization objective can be easily inferred if you remember this short story:\nSuppose you are a human and can just live in a rounded disk. Outside is fire, so you cannot go outside. You cannot fly, so you are obliged to stay on the disk ($g$ equality constraint). You cannot leave your disk, so you need to stay within some other inequality constraint. You would like to minimize the distance to a flying thing UFO. If you now consider three scenarios, namely:\nUFO on your disk UFO inside the area of your disk but flying at some altitude. UFO outside your disk. Then you see that in the first case, we can satisfy the disk constraints, and just go directly to the UFO, which is classical optimization problem, just set the derivative to 0. In the second case, you need to find the best location in the disk. So it will be directly below or on the UFO. You will see that the two gradients of $f$ and $g$ align or are anti-aligned. This is the above condition. In the third case, as it is outside, you would like to get as close to the boundary as possible, and the third gradient\u0026rsquo;s parameter should be positive, as it is pointing outside, while the others could be mis-aligned.\nInequality constraints If instead of having bounds like $g(x) = b$ we have bounds like $g(x) \\geq b$ it\u0026rsquo;s just a little bit more complicated, we have more points, and could be useful to divide the case when $g(x)= b$ with $g(x) \u003e b$. In the latter case, we just set $\\lambda = 0$ (because this is what we get if we take the derivative w.r.t. to $\\lambda$ and set $\\lambda g(x) = 0$) and maximize the lagrangian (doesn\u0026rsquo;t matter the direction of the gradient of $f$ now), when the solution is border, we should take a little bit more care: we want the gradient of $f$ to be away from the region $g$, which motivates us to have an equation like $\\lambda \\nabla g(x) = -\\nabla f(x)$ and $\\lambda \u003e 0$.\nKarush-Kuhn-Tucker Conditions $$ \\begin{cases} g(x) \\geq 0 \\\\ \\lambda \\geq 0 \\\\ \\lambda g(x) = 0 \\end{cases} $$ The last condition is called complementary slackness conditions.\nWe can work the four cases intuitively and get some other intuition about Lagrange optimizations. In the (Bishop 2006) there is quite good argumentation that naturlly exposes this part.\nPlaybook for Lagrange Multipliers üü© $$ \\begin{array} \\\\ \\mathop{\\min}_{w} \u0026f(w) \\\\ \\text{ s.t. } \u0026g_{i}(w) \\leq 0 \\\\ \u0026h_{i}(w) = 0 \\end{array} $$ Write the Lagrangian function $$ \\mathcal{L}(w, \\lambda, \\nu) = f(w) + \\sum_{i} \\lambda_{i}g_{i}(w) + \\sum_{i}\\nu_{i}h_{i}(w) $$ with $\\lambda_{i} \\geq 0$ these are the classical conditions, motivated above (just note the minimization problem, so we inverted one condition). Check for Slater\u0026rsquo;s condition which is check if there is a $w$ such that for every $i$ $g_{i}(w) \u003c 0$ $h_{i}(w) = 0$ Solve $\\nabla_{w} \\mathcal{L}$, $\\lambda_{i}g_{i}(w) = 0$ and $h_{i}(w) = 0$ Duality Primal problem üü©\u0026ndash; $$ \\begin{array} \\\\ \\min_{w} f(w) \\\\ \\text{ s.t. } g_{i}(w) \\leq 0 \\\\ h_{i}(w) = 0 \\end{array} $$$$ \\mathcal{L}(w, \\lambda, \\nu) = f(w) + \\sum_{i} \\lambda_{i}g_{i}(w) + \\sum_{i}\\nu_{i}h_{i}(w) $$$$ \\theta_{\\mathcal{P}}(w) = \\max_{\\lambda, \\nu : \\lambda_{i} \\geq 0} \\mathcal{L}(w, \\lambda, \\nu) $$ We observe that if any of the condition $g_{i}(w) \\leq 0$ or $h_{i}(w) = 0$ is violated, then it\u0026rsquo;s easy to say that $\\theta_{\\mathcal{P}} = +\\infty$.\n$$ p^{*} = \\min_{w} \\theta_{\\mathcal{P}}(w) = \\min_{w} \\max_{\\lambda, \\nu: \\lambda_{i} \\geq 0} \\mathcal{L}(w, \\lambda, \\nu) $$The dual of this optimization problem is just inverting the values in some manner. We easily notice the following:\n$$ \\begin{cases} p^{*} = +\\infty \u0026 \\text{ if the constraints are not satisfied} \\\\ p^{*} = \\min_{w}f(w) \u0026 \\text{ if the constraints are satisfied} \\end{cases} $$ This is the trick that makes the Lagrangian work! If we find a closed solution that optimizes the Lagrangian, we can be sure that that is a valid solution for the original problem.\nWeak duality üü®\u0026ndash; Consider the Lagrangian given the optimization problem above\n$$ \\mathcal{L}(x, \\lambda, \\nu) = f_{0}(x) + \\sum \\lambda_{i}f_{i}(x) + \\sum\\nu_{j}h_{j}(x) $$$$ \\theta_{D}(\\lambda, \\nu) = \\min_{x} \\mathcal{L}(x, \\lambda, \\nu) \\leq \\mathcal{L}(x^{*}, \\lambda, \\nu) \\leq f_{0}(x^{*}) $$ This is called weak duality: we observe that each possible solution is bounded below by the dual function. When Equality holds for the best $\\lambda$ and $\\nu$ we say that we have strong duality, which implies that the admissible $x$ that we have found is actually the best solution possible, and that solving the dual problem actually gives you the best solution for the primal problem.\nDual problem üü© $$ \\theta_{\\mathcal{D}}(\\lambda, \\nu) = \\min_{\\omega} \\mathcal{L}(w, \\lambda, \\nu) $$ We can prove some properties of this new function. Note that the chosen $w$ could also be a not admissible solution in this case. For weak duality, we know that this is a lower bound for the solution of the primal problem.\n$$ d^{*} = \\max_{\\lambda, \\nu: \\lambda_{i} \\geq 0} \\theta_{\\mathcal{D}}(\\lambda, \\nu) = \\max_{\\lambda, \\nu: \\lambda_{i} \\geq 0} \\min_{w} \\mathcal{L}(w, \\lambda, \\nu) $$$$ \\begin{align} \\max_{\\lambda, \\nu} \\theta_{\\mathcal{D}}(\\lambda, \\nu) \\\\ \\text{ s.t. } \\forall i, \\lambda_{i} \\geq 0 \\end{align} $$Slater\u0026rsquo;s condition üü® $$ \\begin{array} \\\\ \\min f(w), \u0026 w \\in \\mathbb{R}^{d} \\\\ \\text{ s.t. } g_{i}(w) = 0, \u0026 i \\leq m \\\\ h_{j}(w) \\leq 0 \u0026 j \\leq n \\end{array} $$ And we have that $f, h_{j}$ are all convex and $g_{i}$ is affine, then this theorem asserts that\nif there is a feasible $w$ such that $h_{j}(w) \u003c 0$ for all $j \\leq n$ then we have strong duality.\nWhen we have strong duality, we can solve the dual problem instead of the original problem, as the solution for one, is solution for the other. Recall that strong duality asserts that there is no gap between the primal and the dual problem, and that the solution for one is the solution for the other.\nReferences [1] Boyd \u0026amp; Vandenberghe ‚ÄúConvex Optimization ‚Äì Boyd and Vandenberghe‚Äù 2004\n[2] Bishop ‚ÄúPattern Recognition and Machine Learning‚Äù Springer 2006\n","permalink":"https://flecart.github.io/notes/lagrange-multipliers/","summary":"\u003cp\u003eThis is also known as \u003cem\u003eLagrange Optimization\u003c/em\u003e or \u003cem\u003eundetermined multipliers\u003c/em\u003e. Some of these notes are based on Appendix E of (Bishop 2006), others were found when studying bits of rational mechanics.\nAlso \u003ca href=\"https://web.stanford.edu/~boyd/cvxbook/\"\u003e(Boyd \u0026amp; Vandenberghe 2004)\u003c/a\u003e chapter 5 should be a good resource on this topic.\u003c/p\u003e\n$$\n\\begin{array} \\\\\n\\min f_{0}(x)  \\\\\n\\text{subject to } f_{i}(x) \\leq 0 \\\\\nh_{j}(x) = 0\n\\end{array}\n$$\u003ch3 id=\"lagrangian-function\"\u003eLagrangian function\u003c/h3\u003e\n$$\n\\mathcal{L}(x, \\lambda, \\nu) = f_{0}(x) + \\sum \\lambda_{i}f_{i}(x) + \\sum\\nu_{j}h_{j}(x)\n$$\u003cp\u003e\nWe want to say something about this function, because it is able to simplify the optimization problem a lot, but first we want to study this mathematically.\u003c/p\u003e","title":"Lagrange Multipliers"},{"content":"In order to understand language models we need to understand structured prediction. If you are familiar with Sentiment Analysis, where given an input text we need to classify it in a binary manner, in this case the output space usually scales in an exponential manner. The output has some structure, for example it could be a tree, it could be a set of words etc\u0026hellip; This usually needs an intersection between statistics and computer science.\nDefinition of a language model A language model is defined as a distribution over a $\\Sigma^{*}$ (See Descrizione linguaggio for the Kleene star and the alphabet). So it assigns probabilities to $y \\in \\Sigma^{*}$. Remember: every element in $\\Sigma^{*}$ is finite. This is important.\nBut we need to be careful about some details. As $\\Sigma^{*}$ is an infinite set it\u0026rsquo;s not trivial to define a probability distribution over it. This motivates us to have two other definitions\nGlobally normalized language models üü© We define a scoring function $\\Sigma^{*} \\to \\mathbb{R}$ and the normalize it over all $y \\in \\Sigma^{*}$. We define a scoring function $s$. Then we can do the following:\n$$ p(y) := \\frac{\\exp(-s(y))}{\\sum_{y' \\in \\Sigma^{*}} \\exp(- s(y'))} := \\frac{1}{Z} \\exp(- s(y)) $$ The $Z$ is a sum over an infinite set, which is often difficult to compute. Sometimes it is computable instead, the negative is for historical purposes: more similar to physics models Other problem is that the normalizer sometimes doesn\u0026rsquo;t converge. These are also sometimes called energy based LMs.\nLocally normalized language models üü©\u0026ndash; In this case, we try to take advantage of the structure of the strings, which is just a concatenation of the elements in an alphabet. Another advantage is not calculating the hideous partition function. We need a $EOS$ token and $BOS$ token in this case. Those are needed to model the starting symbol and the end symbol. Locally normalized language models model the conditional distribution $p(y \\mid \\boldsymbol{y})$ which means given a string $\\boldsymbol{y} \\in \\Sigma^{*}$ try to predict $y \\in \\Sigma$.\n$$ p(\\boldsymbol{y}) = p(y_{1} \\mid BOS) p(y_{2} \\mid BOS y_{1}) \\dots p(y_{n} \\mid \\boldsymbol{y}_{","permalink":"https://flecart.github.io/notes/language-models/","summary":"\u003cp\u003eIn order to understand language models we need to understand \u003cstrong\u003estructured prediction\u003c/strong\u003e. If you are familiar with \u003ca href=\"/notes/sentiment-analysis/\"\u003eSentiment Analysis\u003c/a\u003e, where given an input text we need to classify it in a binary manner, in this case the output space usually scales in an \u003cem\u003eexponential\u003c/em\u003e manner. The output has some structure, for example it could be a tree, it could be a set of words etc\u0026hellip; This usually needs an intersection between statistics and computer science.\u003c/p\u003e","title":"Language Models"},{"content":"Introduzione elettromagnetismo Note storiche: triboelettricit√† Il concetto di campo √® fondamentale per l\u0026rsquo;elettromagnetismo (vs forza in meccanica) da un punto di vista storico √® nato tramite l\u0026rsquo;osservazione in fenomeni come lo strofinio fra vetro e pelle, dopo il quale hanno osservato ci fosse una forza nascosta (appunto ombra dal greco di electron). Il vetro si caricava poi abbastanza da poter attrarre carta per esempio. esempio dell\u0026rsquo;esperimento. Se viene fatto invece fra due lastre in vetro invece diventa repulsiva invece che attrattiva. Questo effetto √® chiamato triboelettricit√†.\nDimensioni atomo Misure classiche dimensione atomo üü® Questa √® una piccolissima sezione per dare l\u0026rsquo;intuizione su quanto sia grande in generale un atomo, confronto fra protone ed elettrone: Forza di gravit√† vs elettromagnetico üü© TODO: in questa parte viene fatto un confronto fra quanto √® grande la forza di gravit√† contro la forza elettrica in un atomo Fatto da esempio 1.1 pagina 9 del Mazzoldi Abbiamo che la differenza in modulo della forza di gravit√† e forza elettrica sia molto differente (circa $10^{39}$ di differenza, quindi troppo per dire.)\nEsperimenti classici Elettroscopio a foglie üü© [Video per l'esperimento](https://youtu.be/XXVUuW5F0xU?si=eKnTMxnoIitJdTB_) in cui vengono presentati tre casi (e tre cariche risultanti diverse). avvicinando un oggetto carico, le foglie si separavano, questa √® una carica indotta dalla presenza di un altro oggetto, allontanando rimaneva poi uguale. Se tocco, caricher√≤ con la stessa carica del mi oggetto (scambio di elettroni) Se scarico a terra, la carica presente sar√† l\u0026rsquo;opposta. L\u0026rsquo;angolo di separazione fra le foglie hanno permesso di misurare la carica per la prima volta. (poi probabilmente qualcosa di meccanica per calcolare).\nBilancia a torsione üü©- Questo √® un setting un po\u0026rsquo; pi√π complesso anche se l\u0026rsquo;idea √® ancora quella presente in Elettroscopio a foglie di misurare un angolo per avere la distanza. video esempio.\nL'unica cosa importante era l'angolo di torsione, da cui si poteva dedurre la forza. Poi la palla blu √® di metallo, e si pu√≤ caricare. $$ \\frac{L}{2} \\lvert F \\rvert \\sin \\varphi = k \\theta \\implies \\lvert F \\rvert = \\frac{2k\\theta}{L \\sin \\varphi} $$ Da cui si pu√≤ derivare la forza, e quindi sperimentalmente anche i valori di questa carica elettrica.\nLa legge di coulomb Enunciato a parole üü© Date due cariche elettriche poste a una distanza $r$, tra di esse esercita una forza che √® direttamente proporzionale al prodotto delle cariche ed inversamente proporzionale al quadrato della distanza, tale forza √® diretta fra la congiungente delle cariche elettriche, repulsiva se i segni sono concordi e attrattiva se discordi.\nI risultati di coulomb Grazie al suo lavoro metodico di sperimentazione √® riuscito ad elaborare la legge che viene presentata subito sopra, √® riuscito a ridurre il tutto a tre propriet√† fondamentali\nla forza √® diretta sulla congiungente A volte √® attrattiva, altre volte repulsiva Varia inversamente al quadrato della distanza e direttamente al prodotto (questo √® riuscito a farlo con palle di metallo che spezzano la carica in due) $$ \\lvert \\vec{F} \\rvert = k \\frac{Q_{0}Q_{1}}{r^{2}} $$Con questa costante qui che non √® pi√π adimensionale come nel caso della costante elastica di torsione, ma √® stato nel tempo scoperto essere dipendente dalla costante dielettrica del vuoto, di cui capiremo un po\u0026rsquo; meglio quando andremo a parlare di dielettrici in seguito. Una analisi dimensionale ci dar√† che l\u0026rsquo;unit√† di misura di quello √® $\\frac{Nm^{2}}{C^{2}}$.\nCostante dielettrica del vuoto üü© Bisogna ricordarsi il valore della costante a memoria! Anche la sua dimensione!\n$$ k = \\frac{1}{4\\pi \\epsilon_{0}} = 8.99 \\cdot 10^{8} N \\frac{m^{2}}{c^{2}} $$$$ \\varepsilon_{0}=8.85 \\cdot 10^{-12}\\frac{C^{2}}{N m^{2}} $$Sulla carica Come propriet√† della materia Propriet√† (2) üü© La carica √® una propriet√† intrinseca della materia, esattamente come la massa, se consideriamo protoni ed elettroni, questi sono la pi√π piccola unit√† di carica possibile.\nCostante, questo significa che se il sistema √® isolato, la quantit√† di carica non cambia mai Invariante fra sistemi di riferimento, se lo guardo da un sistema di riferimento che si muove e non (quindi stiamo parlando di meccanica), questa carica non cambia. Subatomica (no) Si pu√≤ dire che un protone e un neutrone √® formato da quark, anche se non so esattamente cosa siano, puoi trovare una immagine negli appunti di Matti in questo modo:\nCarica protoni ed elettroni üü© Stiamo provando a rispondere alla domanda perch√© la carica di elettroni e protoni √® uguale? Proviamo a ragionare per assurdo, assumendo le costanti che conosciamo gi√† sopra nella sezione sui risultati di coulomb.\nSupponiamo ci sia una differenza di carica fra protoni ed elettroni, anche piccolissima, mettiamo caso sia $1.6 \\cdot 10^{-28}C$, e consideriamo due palle di ferro puro di massa $1Kg$ e raggio $1m$, allora dato che la $\\Delta q \\neq 0$ si avr√† una forza, che sar√† di $k \\Delta q \\frac{\\Delta q_{2}}{r^{2}}$, considerando che il ferro nella tavola periodica ha $Z=26$ ossia il numero totale di protoni e $A=55$, il numero di massa, avremo che $\\Delta Q = N_{protoni}\\cdot \\Delta q$, e da questo si pu√≤ ricavare un valore simile a $0,0455 C$, e considerando che $N_{p} = z \\cdot N_{atomi} = Z \\cdot \\frac{M}{A} N_{a}$ dove l\u0026rsquo;ultimo √® il numero di avocadro credo, la forza che sarebbe presente sarebbe di circa $1.7 \\cdot 10^{7} N$, e si avrebbe il terzo principio della dinamica, ma sperimentalmente non esiste questa forza\nPrincipio di sovrapposizione Enunciato del principio di sovrapposizione $$ \\frac{1}{4\\pi\\varepsilon_{0}} Q_{p} \\sum_{i=1}^{N} \\frac{q_{i}}{r_{i}^{2}} \\hat{r}_{ip} $$Questa stessa idea si pu√≤ utilizzare senza nessun problema anche nel caso in cui ho volumetti carichi\nDensit√† volumetrica di carica üü© $$ \\rho(\\vec{r}) = \\lim_{ \\Delta \\tau \\to 0 } \\frac{\\Delta q}{\\Delta \\tau} = \\frac{dq}{d\\tau} \\implies \\rho(\\vec{r}) d\\tau = dq $$ Andando a considerare gli infinitesimi\nDensit√† superficiale di carica üü© $$ \\rho(\\vec{r}) = \\lim_{ \\Delta s \\to 0 } \\frac{\\Delta q}{\\Delta s} = \\frac{dq}{ds} \\implies \\rho(\\vec{r}) ds = dq $$Densit√† lineare di carica üü© $$ \\vec{F}_{l} = \\frac{1}{4\\pi \\varepsilon_{0}} Q_{p} \\int _{l} \\frac{\\lambda(\\vec{r})}{\\Delta r^{2}} \\hat{\\Delta}r \\, dl $$ Integrale lineare\n","permalink":"https://flecart.github.io/notes/legge-di-coulomb/","summary":"\u003ch2 id=\"introduzione-elettromagnetismo\"\u003eIntroduzione elettromagnetismo\u003c/h2\u003e\n\u003ch3 id=\"note-storiche-triboelettricit√†\"\u003eNote storiche: triboelettricit√†\u003c/h3\u003e\n\u003cp\u003eIl concetto di \u003cstrong\u003ecampo\u003c/strong\u003e √® fondamentale per l\u0026rsquo;elettromagnetismo (vs forza in meccanica)\nda un punto di vista storico √® nato tramite l\u0026rsquo;osservazione in fenomeni come lo strofinio fra vetro e pelle, dopo il quale hanno osservato ci fosse una forza nascosta (appunto \u003cstrong\u003eombra\u003c/strong\u003e dal greco di electron).\nIl vetro si caricava poi abbastanza da poter attrarre carta per esempio. \u003ca href=\"https://youtu.be/iHBNWiHJaQQ?si=0GPKmcE2Oeh69zXj\"\u003eesempio dell\u0026rsquo;esperimento\u003c/a\u003e.  Se viene fatto invece fra due lastre in vetro invece diventa \u003cem\u003erepulsiva\u003c/em\u003e invece che attrattiva.\nQuesto effetto √® chiamato \u003cstrong\u003etriboelettricit√†\u003c/strong\u003e.\u003c/p\u003e","title":"Legge di Coulomb"},{"content":"Introduzione alla legge di gauss Giustificazione con angoli solidi üü®\u0026ndash; $$ d\\Phi = \\vec{E}\\cdot \\vec{dS} = \\lvert \\vec{E} \\rvert \\lvert \\vec{dS} \\rvert \\cos \\theta = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{1}{r^{2}} ds = \\frac{Q}{4\\pi\\varepsilon}d\\Omega $$ Il secondo passaggio √® giustificabile andando su coordinate polari considerando l\u0026rsquo;angolo solido di un oggetto quindi non dovrebbe essere un problema.\n$$ \\Phi = \\int _{\\sum} \\, d\\Phi= \\int _{\\sum} \\frac{Q}{4\\pi\\varepsilon}\\, d\\Omega = \\frac{Q}{4\\pi\\varepsilon}\\int _{\\sum} \\, d\\Omega = \\frac{Q}{4\\pi\\varepsilon} 4\\pi = \\frac{Q}{\\varepsilon} $$ Nota il flusso dipende solamente dalla CARICA, indipendente dalla singola posizione. Enunciato legge di Gauss (linguaggio naturale) üü© Il flusso attraverso qualunque superficie chiusa $\\sigma$ eguaglia la somma algebrica delle cariche contenute all\u0026rsquo;interno della superficie comunque esse siano distribuite divisa per ma costante dielettrica del vuoto $\\varepsilon_{0}$\n(praticamente scritto in linguaggio ambiguo naturale quello che viene espresso in formule, niente di pi√π e niente di meno).\nLegge di Gauss in forma integrale üü© $$ \\oint_{\\sum} \\vec{E} \\, \\vec{ds} = \\frac{Q}{\\varepsilon_{0}} $$E se ci sono pi√π cariche, per principio di sovrapposizione posso sommare tutte le cariche sopra, e quindi ho $Q_{T} = \\sum_{i=1}^{N}q_{i}$ questo vale per distribuzione di cariche discrete, se √® continuo √® leggermente diversa la cosa (per cose viste precedentemente il contributo delle cariche esterne √® zero.)\nLegge di Gauss e divergenza üü© Guarda il teorema della divergenza dimostrato pi√π generalmente in Divergenza e Circuitazione. Flusso di campo vettoriale su superficie chiusa sigma √® uguale a qualcosa sulla divergenza\n$$ \\oint_{\\Sigma} \\vec{E} \\, \\vec{d}s= \\int_{V(\\Sigma)} \\vec{\\nabla}\\vec{E} \\, dt $$In qualche modo posso dire che la densit√† di carica sul volume si pu√≤ fare senza problemi, Sappiamo sempre per gauss che\n$$ \\frac{1}{\\varepsilon_{0}}\\int _{V(\\sigma)}\\rho \\, dt = \\frac{Q_{T}}{\\varepsilon_{0}} $$$$ \\int _{V(\\Sigma)}\\vec{\\nabla}\\vec{E} \\, dt = \\int_{V(\\Sigma)} \\frac{\\rho}{\\varepsilon_{0}} \\, dt \\implies \\vec{\\nabla}\\cdot\\vec{E} = \\frac{\\rho}{\\varepsilon_{0}} $$Legge di Gauss in forma differenziale (locale) üü© $$ \\vec{\\nabla}\\cdot\\vec{E} = \\frac{\\rho}{\\varepsilon_{0}} $$ $\\rho$ √® la densit√† volumetrica di carica.\nChe mi da informazione sul valore del campo sul singolo punto, ossia se in quel punto c\u0026rsquo;√® il campo.\nOsservazione 1 √à ovvio osservare che questa forma del teorema di Gauss √® applicabile solo nei casi in cui la funzione √® differenziabile ovunque nello spazio, cosa che non √® mai detto. Se ho un punto di discontinuit√†, devo usare la forma integrale\nOsservazione 2: questa √® una forma locale perch√© nel caso la densit√† cambiasse, questa legge non pu√≤ essere utilizzata, non √® immediato che il campo cambi infatti, per√≤ √® utile per calcolare il campo nella singola posizione.\nUtilizzi della legge di Gauss Esempio: flusso dipolo üü© Essendo che altre parti escono, altre entrano, il flusso totale √® zero. Questo √® anche un modo per dimostrare che **non esiste nessuna linea che entra o esce dall'infinito**, andandosi quindi a trattare di induzione completa. Metodi per calcolare il flusso üü© sommo tutte le cariche che sono presenti (quanto fatto sopra) Uso Gauss (superficie) Sommo potenziali (gradiente cambiato di segno (recuperare)) Considerazioni sulla legge vs Coulomb üü© Questa legge di gauss √® direttamente dipendente dalla Legge di Coulomb, (probabilmente quello che si vuole dire √® che da una puoi derivare l\u0026rsquo;altra) e funziona solamente per il fatto che scende in modo inversamente quadrato.\nCaso particolare: campo costante üü© $$ \\oint_{\\sum}\\lvert \\vec{E} \\rvert ds \\cos \\theta = \\lvert \\vec{E} \\rvert \\oint_{\\sum}ds\\cos \\theta \\implies \\lvert \\vec{E} \\rvert = \\frac{Q_{T}}{\\varepsilon_{0}} \\frac{1}{\\oint_{\\sum}ds\\cos \\theta} $$ Un aspetto particolare √® che questo integrale $\\oint_{\\sum}ds \\cos \\theta$ √® semplicemente l\u0026rsquo;area della superficie.\n","permalink":"https://flecart.github.io/notes/legge-di-gauss/","summary":"\u003ch3 id=\"introduzione-alla-legge-di-gauss\"\u003eIntroduzione alla legge di gauss\u003c/h3\u003e\n\u003ch4 id=\"giustificazione-con-angoli-solidi---\"\u003eGiustificazione con angoli solidi üü®\u0026ndash;\u003c/h4\u003e\n$$\nd\\Phi = \\vec{E}\\cdot  \\vec{dS} = \\lvert \\vec{E} \\rvert \\lvert \\vec{dS} \\rvert \\cos \\theta = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{1}{r^{2}} ds = \\frac{Q}{4\\pi\\varepsilon}d\\Omega \n$$\u003cp\u003e\nIl secondo passaggio √® giustificabile andando su coordinate polari considerando \u003cstrong\u003el\u0026rsquo;angolo solido\u003c/strong\u003e di un oggetto quindi non dovrebbe essere un problema.\u003c/p\u003e\n$$\n\\Phi = \\int _{\\sum} \\, d\\Phi= \\int _{\\sum}  \\frac{Q}{4\\pi\\varepsilon}\\, d\\Omega =  \\frac{Q}{4\\pi\\varepsilon}\\int _{\\sum}  \\, d\\Omega   = \\frac{Q}{4\\pi\\varepsilon} 4\\pi = \\frac{Q}{\\varepsilon}\n$$\u003cp\u003e\nNota \u003cstrong\u003eil flusso dipende solamente dalla CARICA\u003c/strong\u003e, indipendente dalla singola posizione.\n\u003cimg alt=\" 300\" loading=\"lazy\" src=\"/notes/campo-elettrico-1696844095493.jpeg-\"\u003e\u003c/p\u003e","title":"Legge di Gauss"},{"content":"Gli argomenti della lezione 31 Ottobre sono circa da pagina 164 fino a 185 del mazzoldi.\nLeggi di Ohm Introduzione microscopica üü© Sappiamo che $$ \\vec{J} = -n e \\vec{v}_{d} ne^{2} t \\frac{\\vec{E}}{m} $$ Vedi analisi della velocit√† di deriva col modello del 1900 in Corrente Elettrica.\nDove abbiamo utilizzato la definizione di densit√† di corrente e la velocit√† fra collisioni ed altre Questo √® una motivazione per considerare la densit√† di corrente come se fosse nello stesso verso.\nDa questo notiamo che dipende solamente dal materiale perch√© abbiamo $t$ che √® il tempo che intercorre fra collisione uno e due, mentre $n$ √® la densit√† di elettroni per unit√† di volume, anche questo dipendente dal materiale, poi $e$ ed $m$ sono costanti universali.\n$$ \\vec{J} = \\sigma \\vec{E} $$$$ \\vec{E} = \\rho \\vec{J} $$ Dove $\\rho$ √® la resistivit√†, e si ha $\\rho = \\frac{1}{\\sigma}$\nNota: c\u0026rsquo;√® qualcosa con i semiconduttori o cose drogate, che puoi scomporre la parte di sopra con cariche negative o positive, questa cosa √® da approfondire sul libro, perch√© non la ho capita oggi a lezione Vedi 6.7 mazzoldi c\u0026rsquo;√® scritto.\nPotenza e densit√† elettrica üü©\u0026ndash; Chiamiamo $P_{\\tau}$ come la potenza per unit√† di volume, che ricordiamo la derivata del lavoro per il tempo. Ricordando che $P = \\frac{dW}{dt} = \\frac{\\vec{F}ds}{dt} = \\vec{F} \\cdot \\vec{v}$\n$$ P_{\\tau} = nP = n\\vec{F}\\cdot \\vec{v}_{d} = ne\\vec{v}_{d} \\cdot \\vec{E} = \\vec{J} \\cdot \\vec{E} $$$$ P_{\\tau} = \\vec{J} \\cdot \\vec{E} = \\sigma E^{2} = \\rho J^{2} $$Resistenza nei fili üü© $$ V_{A} - V_{B} = \\int _{A}^{B}\\vec{E} \\, d\\vec{l} = EL $$$$ I = \\int \\vec{J} \\cdot d\\vec{s} = J S \\implies J = \\frac{I}{S} $$ Ora usiamo la relazione fra campo elettrico e densit√† di corrente, e otteniamo che\n$$ V_{A} - V_{B} = \\rho J L = \\rho L \\frac{I}{S} = \\frac{\\rho L}{S} I = R I \\implies V = RI $$$$ R = \\frac{\\rho L}{S} $$$$ R = \\int _{A}^{B} \\frac{\\rho}{\\Sigma} \\, dl $$ Seguendo quanto c\u0026rsquo;√® in immagine.\nQuando abbiamo ai capi di un conduttore una differenza di un volt, si ottiene una corrente di un ampere, e questo √® l\u0026rsquo;ampere.\nLegge di Ohm della conduzione elettrica üü®++ $$ \\sigma = \\frac{ne^{2}\\tau_{+}}{m_{+}} + { \\frac{ne^{2}\\tau_{-}}{m_{-}}} $$ √à semplicemente un modello vecchio in cui andiamo a distinguere i portatori di carica negativa e positiva con delle masse diverse (e quindi velocit√† di deriva diversa). Per il resto resta la stessa derivazione di sopra.\n$$ \\vec{J} = \\sigma \\vec{E} $$ Dove la densit√† di corrente √® relazionata al campo elettrico generato solamente da variabili fisiche riguardanti la composizione del metallo e costanti elementari come massa di portatori di carica.\nIl regime stazionario üü© $$ \\oint \\vec{J} d\\vec{S} = 0 $$$$ \\vec{\\nabla} \\cdot \\vec{J} = 0 $$Resistivit√† e temperatura üü®+ Intuitivamente se aumenta l\u0026rsquo;agitazione termica, aumenta la resistivit√† perch√© c\u0026rsquo;√® pi√π agitazione, quindi pi√π incontri, si ha una legge del tipo:\n$$ \\rho = \\rho_{20}(1 + \\alpha \\Delta T) $$ Il grafico √® piatto fino a un certo punto, poi va su in modo lineare. Nei semiconduttori il coefficiente √® negativo.\nSupponiamo di avere una forma cilindrica a piacere, abbiamo che $$ dP = P_{\\tau} \\Sigma dh $$ integrando questo riesco a trovare la **potenza dissipata in conduttore** Si pu√≤ fare anche in altro modo partendo con la potenza $$ P = \\frac{dW}{dt} = \\frac{Vdq}{dt} = \\frac{Vidt}{dt} = VI $$\n$$ P = \\frac{V^{2}}{R} $$Noi paghiamo in $W = RI^{2}t$ che sono ikilowattora. il riscaldamento si chiama effetto Joule.\nLegge di Ohm generalizzata üü© $$ V_{A} -V_{B} + \\Sigma_{k}\\varepsilon_{k} = R_{T}i $$ Questa √® un caso generale della legge di Kirchhoff alle maglie descritta dopo\nPotenza per unit√† di volume üü© $$ P_{\\tau} = nP = \\rho J^{2} = \\sigma E^{2} $$$$ P_{\\tau} = \\vec{J} \\cdot \\vec{E} $$ L\u0026rsquo;abbiamo ricavato anche in Magnetismo parlando di Poynting, in qui possiamo relazionarlo utilizzando le equazioni di Maxwell anche col campo magnetico.\nResistori in serie e parallelo Una cosa da notare √® che saldare assieme √® una altra resistenza non considerata, comunque √® piccola, quindi approssimiamo che ci√≤ che √® filo non la valutiamo, √® trascurabile. Una cosa importante da notare √® che in questi casi √® utile utilizzare resistenze di valore simile altrimenti in serie prevarr√† la resistenza grossa, in quella parallela la resistenza piccola.\nSerie üü© L\u0026rsquo;osservazione principale per spiegare questo √® il fatto che la corrente che passa √® la stessa Abbiamo $V_{A} - V_{B} = iR_{1}$ e $V_{B} - V_{C} = iR_{2}$\n$$ iR_{eq} = V_{A} - V_{C} = R_{1}i + R_{2}i $$Anche la potenza √® semplicemente una cosa lineare!\nParallelo üü© In questo caso la differenza di potenziale √® la stessa dato che $V_{A} - V_{B}$ √® un valore condiviso, in questo caso la corrente si dividere in modo inversamente proporzionale alla resistenza. Quindi abbiamo\nSia $V = V_{A} - V_{B}$, allora $V = i_{1}R_{1}$ e che $V = i_{2}R_{2}$, quindi\n$$ i = \\frac{V}{R_{1}} + \\frac{V}{R_{2}} \\implies \\frac{1}{R_{eq}} = \\frac{1}{R_{1}} + \\frac{1}{R_{2}} $$ Che √® esattamente il contrario di quanto abbiamo visto nei Condensatori nel vuoto per quanto riguarda i circuiti. Riguardo la potenza si comporta bene lo stesso, seguendo questa relazione.\nGeneratori di FEM Introduzione ai generatori FEM Def forza elettromotrice üü© $$ \\varepsilon = \\oint_{\\Sigma} \\vec{E} d\\vec{l} $$ Ed √® qualcosa che permette di scorrere la corrente per tanto tempo. Un condensatore non sarebbe buono perch√© si scarica. √à presente nel circuito un campo elettrico che non √® conservativo, diverso rispetto a quello costante che viene sentito all\u0026rsquo;interno del circuito! Dato che applicando le leggi di sopra non c\u0026rsquo;√® la circuitazione nulla.\nQuesto √® un caso in non valgono le leggi conservative che abbiamo studiato per un mese e mezzo, trattate in Campo elettrico nella sezione elettromotrice.\nDerivazione forza elettromotrice üü©- Esiste una *piccola corrente interna del generatore* Allora il nostro generatore produrr√† una forza uguale a $$ W = Pt = i^{2}(R + r) t $$ O in altro modo: $$ W = \\varepsilon q = \\varepsilon i t $$ Questo √® valido perch√© $$ P = \\frac{dU}{dt} = \\frac{dqV}{dt} = iV $$ Quindi abbiamo una relazione sulla potenza spesa da un circuito in relazione alla variazione di differenza di potenziale elettrico. $$ \\varepsilon = (R + r) i $$ Che notiamo √® lo stesso valore per la differenza di potenziale elettrico per un circuito semplice\nCampo elettrico elettromotore üü®+ Trattato a pagina 181 del Mazzoldi\nDentro ai poli il campo elettrico √® opposto rispetto a quello del campo elettrico esterno! Il capo interno √® il **campo elettrico elettromotore** che non √® conservativo, siamo fuori dall'elettrostatica. $E^{*}$ √® solamente il campo interno. Abbiamo allora\n$$ \\varepsilon = \\oint_{\\vec{E}} d\\vec{l} = \\int _{A}^{B} \\vec{E}_{esterno} \\, d\\vec{l} + \\int _{B}^{A} \\vec{E}_{\\text{interno}}+\\vec{E}_{conservativa} \\, d\\vec{l} $$Il primo √® elettrostatico, quindi sappiamo che rimane solamente zero (con anche il suo apporto all\u0026rsquo;interno della fem), quindi abbiamo che\n$$ \\varepsilon = \\int _{B}^{A} \\vec{E}_{\\text{interno}} \\, d\\vec{l} $$ Quindi internamente abbiamo un campo $E = E^{*} + E_{el}$ mentre all\u0026rsquo;esterno c\u0026rsquo;√® solamente il campo statico.\nMisura fem üü© Nel caso in cui $i = 0$ √® molto semplice, basta prendere la differenza di potenziale ai due capi: $V_{A} - V_{B} = \\varepsilon$ e sappiamo che il campo elettrico all\u0026rsquo;interno della fem √® 0 Ossia $E^{*} + E_{el} = 0$\nA differenza se c\u0026rsquo;√® corrente avremo dei risultati diversi.\nRamo Definizione üü©\u0026ndash; Una parte di filo, parte del circuito fra pi√π nodi, in cui circola una certa corrente.\nPrima legge di Kirchhoff ai nodi üü© La somma algebrica delle correnti che confluiscono in un nodo √® nullo\nLa corrente che entra √® uguale a quello che esce\n$$ \\Sigma_{k}i_{k} = 0 $$ √à causa del principio di conservazione della carica, espressa alla fine in modo diverso.\nSeconda legge di Kirchhoff alle maglie üü© La somma algebrica delle f.e.m. presenti nei rami della maglia √® uguale alla somma algebrica dei prodotti $R_{k}i_{k}$\n$$ \\Sigma_{k}R_{k}i_{k} = \\Sigma_{k}\\varepsilon_{k} $$ Questo vale solo se il ramo √® chiuso, altrimenti bisogna aggiungere in RHS una componente per la differenza di potenziale in quei due punti.\n","permalink":"https://flecart.github.io/notes/leggi-di-ohm/","summary":"\u003cp\u003eGli argomenti della lezione 31 Ottobre sono circa da pagina 164 fino a 185 del mazzoldi.\u003c/p\u003e\n\u003ch3 id=\"leggi-di-ohm\"\u003eLeggi di Ohm\u003c/h3\u003e\n\u003ch4 id=\"introduzione-microscopica-\"\u003eIntroduzione microscopica üü©\u003c/h4\u003e\n\u003ch1 id=\"vecj---n-e-vecv_d\"\u003eSappiamo che\n$$\n\\vec{J} = -n e \\vec{v}_{d}\u003c/h1\u003e\n\u003cp\u003ene^{2} t \\frac{\\vec{E}}{m}\n$$\nVedi analisi della velocit√† di deriva col modello del 1900 in \u003ca href=\"/notes/corrente-elettrica/\"\u003eCorrente Elettrica\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eDove abbiamo utilizzato la definizione di densit√† di corrente e la velocit√† fra collisioni ed altre\nQuesto √® una motivazione per considerare la densit√† di corrente come se fosse nello stesso verso.\u003c/p\u003e","title":"Leggi di Ohm"},{"content":"Riguardare Successioni per avere primo attacco sui limiti\n4.1 Limiti finiti al finito 4.1.1 Intorno sferico Dato l\u0026rsquo;insieme $\\mathbb{R}$ si definisce l\u0026rsquo;intorno sferico aperto di $x \\in \\mathbb{R}$ di raggio $r \\in \\mathbb{R}$ l\u0026rsquo;insieme $I_r(x) = (x -r, x + r)$ questa nozione √® molto importante per definire il limite. Lo useremo subito su un punto di accumulazione\n4.1.2 Punto di accumulazione Un punto di accumulazione $x$ di un insieme $A \\subseteq \\mathbb{R}$ √® un punto tale per cui mi posso avvicinare in modo indefinito in quel punto. Infatti deve $\\forall r \u003e 0 \\in R, \\exists x_ 1 \\in A : x_1 \\in I_r(x) \\wedge x_1 \\not= x$ ossia per cui $A \\cap I_r(x) \\not= \\varnothing$.\nEcco che se mi avvicino in modo indefinito, possiamo definire per bene il limite tra poco.\n4.1.3 Accumulazione per successioni Un punto si pu√≤ definire di accumulazione per una successione $a_n$ se si ha che\n$\\lim_{n\\to\\infty} a_n = x$ con x punto di accumulazione. e $\\forall n \\in \\mathbb{N}, a_n \\not= x$\n4.1.4 Limite finito Questo √® il limite finito per una funzione\n$$ \\forall \\epsilon \u003e 0, \\exists \\delta \\in\\mathbb{R}: 0\u003c|x-x_0| \u003c \\delta \\implies |f(x) -y| \u003c \\epsilon $$In pratica comunque prendo un valore vicino al valore y di limite, (quindi sto definendo la mia $\\epsilon$ deve esistere sempre un $\\delta$ tale che valga quella roba.\nLa soluzione tipica per la dimostrare di tale cosa √® partire dalla tesi e scomporla, trovare che se x appartiene a un certo intervallo continuo allora possono sempre trovare un sottoinsieme di questo intervallo che sia $\\delta$.\n4.2 Teoremi dei limiti 4.2.1 Permanenza del segno Se il limite positivo allora esiste un x per cui f(x) √® positivo, ma lo dovresti dimostrare (dovrebbe essere ovvio considerando l\u0026rsquo;intorno di $\\delta$ per cui vale $\\varepsilon$\nDimostrazione permanenza del segno Teorema dei Carabinieri Quando una funzione si possa schiacciare all\u0026rsquo;interno di due altre funzioni ha lo stesso limite. Questo in modo intuitivo ma si potrebbe fare anche molto di pi√π\u0026hellip;\n4.2.3 Alcuni limiti notevoli (!) $\\lim_{x\\to0}\\sin(x) = 1$ con i carabinieri per 0 e x $\\lim_{x\\to0} \\cos(x) = 0$ con duplicazione e altre osservazioni $\\lim_{x\\to0}\\dfrac{sin(x)}{x} = 1$ $\\lim_{x\\to0} \\dfrac{e^x - 1}{x} = 1$\nQueste sono i limiti notevoli di base per trigonometriche e esponenziali (o logaritmiche) Esistono anche alcuni limiti notevoli riguardanti il confronto fra le funzioni polinomiali, esponenziali o fattoriali.\nDimostrazione perimetro e area cerchio (!) Ti ricordi come si fa la dimostrare il valore dell\u0026rsquo;area e del perimetro del cerchio utilizzando il limite noto? Un modo semplice √® integrale, ed √® ci√≤ che ogni universitario che abbia studiato un poco di analisi farebbe.\n4.3 Limiti finiti all\u0026rsquo;infinito 4.3.1 Definizione Definiamo il limite di una funzione x tende a x_0 √® uguale a pi√π o meno infinito nel caso in cui:\n$$ \\lim_{x\\to x_0} f(x) = +\\infty \\iff \\forall M \\in \\R, \\exists \\delta : 0\u003c|x-x_0| \u003c \\delta \\implies f(x) \u003eM $$In modo simile si pu√≤ dire per il limite che tende a un valore infinito negativo\n4.3.2 Limiti destri e sinistri √à molto simile alla definizione normale di limite, ma solo che invece di considerare un intorno completo di x debbo avere una parte, quindi invece di $0 \u003c \\lvert x-x_0 \\rvert\u003c \\delta$ ho che deve essere che $x_0 - \\delta \u003c x \u003c x_0$ per intorni sinistri e in modo simile per intorni destri ho che $x_0 \u003c x \u003c x_0 + \\delta$\nIl resto della definizione √® tutto uguale.\n4.3.3 Relazione limite e l destro e l sinistro Si potrebbe dimostrare questa propriet√†:\n$$ \\lim_{x \\rightarrow x_0} f(x)= L \\iff \\begin{cases} \\exists \\displaystyle{\\lim_{x \\to x_0^-}f(x)}, \\exists\\displaystyle{\\lim_{x \\to x_0^+}f(x)}\\\\ \\displaystyle{\\lim_{x \\rightarrow x_0^-}f(x)}=\\displaystyle{\\lim_{x \\rightarrow x_0^+}f(x)}=L \\end{cases} $$4.4 Limiti all\u0026rsquo;infinito Si possono trovare 3 casi:\n$\\forall \\varepsilon, \\exists \\delta= \\delta(\\varepsilon) \u003e 0 : \\forall x \\in A : x \u003e \\delta$\n$$ \\lim_{x\\to +\\infty} f(x) = \\begin{cases} l \\iff |f(x) - l| \u0026lt; \\epsilon \\ +\\infty \\\n\\infty \\end{cases} $$ 4.4.1 Esercizi algebra dei limiti 4.4.2 Limiti di polinomi Si dimostra che per limite di x tendente a x0 con la funzione lineare che √® uguale a x, poi si espande questo con i teoremi di algebra dei limiti e la moltiplicazione con le costanti in modo che il limite dei polinomi sia coincidente con il limite degli addendi moltiplicazioni e simili.\nCon la definizione di limite fatta in seguito si ha che tutti i polinomi sono continui nel proprio dominio naturale.\nFunzione continua Definizione $\\forall x_0 \\in A, A \\subseteq \\mathbb{R}$ allora deve essere che $x_0 \\not\\in D(A)$ con $D(A)$ l\u0026rsquo;insieme dei punti di accumulazione di A.\n$$ x_0 \\in D(A) \\implies \\lim_{x \\to x_0}f(x) = f(x_0) $$ con il limite definito come prima. E si scrive in questo modo $f \\in C(A)$, data una funzione nello spazio di funzione $A^\\mathbb{R}$\nOsservazioni La continuit√† di una funzione √® interessante perch√© definisce una regolarit√† della funzione. (anche se significa anche che possiamo tracciare la funzione senza lasciare la matita dal foglio).\n4.5.2 Continuit√† destra e sinistra Dalla definizione di funzione continua espansa si pu√≤ dedurre che\n$$ \\lim_{x \\to x_0}f(x) = f(x_0) \\begin{cases} \\exists\\lim_{x\\to x_0} f(x) \\\\ \\exists\\lim_{x\\to x_0^+} f(x),\\exists\\lim_{x\\to x_0^-} f(x),\\\\ \\lim_{x\\to x_0^+} f(x) = \\lim_{x\\to x_0^-} f(x), = \\lim_{x\\to x_0} f(x) \\end{cases} $$4.5.3 Continuit√† per inverse Dimostrazione (non richiesta) Non viene dimostrato ma, se √® definita una funzione continua per una certa funzione, allora √® continua anche la sua inversa. Per qualche motivo magico.\nQuesto teorema √® importante per la dimostrazione della derivabilit√† dell\u0026rsquo;inversa (quindi per avere una base per dimostrare la derivabilit√† dell\u0026rsquo;inversa\nTeorema degli zeri Lemmi preliminari per THZero Primo (dim)\nEnunciato sia data una successione bn appartenente a $\\R$ sempre positiva o sempre negativa tale che il limite di bn appartiene a $\\R$ allora il limite ha lo stesso segno della successione o √® nulla.\nSi dimostra per assurdo ponendo il limite il contrario (si apre poi il limite e si sceglie un epsilon carino che mi porti a questa contraddizione).\nSecondo (no dim)\nData una funzione da A a $\\R$, prendiamo x un punto di accumulazione di A tale che f sia continua in questo punto allora. Per ogni successione xn appartenente ad A che converga a x si ha che f(xn) tende a f(x)¬¥¬¥\nTHZero data una funzione continua in [a,b] in R allora se $f(a)f(b) \u003c 0 \\implies \\exists c \\in ]a,b[ : f(c) = 0$\nOssia, in modo intuitivo, dato un rettangolo tagliato da una linea, se prendo due punti nelle due parti, allora se provo a congiungere questi due punti si ha che deve tagliare la linea in almeno un punto.\nDIM\n$$ \\lim a_n = \\lim b_n = c\\\\ f(c) = 0 $$Bisogna dimostrare queste due cose.\nSi utilizza una divisione diadica in due parti, un algoritmo di costruzione costruttiva.(se l\u0026rsquo;algoritmo finisce √® banale.\nVoglio costruire due successioni, una sempre negativa una sempre positiva, entrambi devono tendere a 0, cos√¨ lo trovo.\nPropriet√† di queste successioni\nDa queste propriet√† ho ottenuto che entrambe le successioni sono limitate e sono crescenti o decrescenti, quindi per dimostrazione precedente esiste un limite che non conosciamo.\nUna cosa molto interessare da considerare √® la successione\n$a_n - b_n = \\dfrac{a - b}{2^{n-1}}$ che tende a 0. Poi insieme al teorema di convergenza dei limiti.\n$a_n$ si pu√≤ dire che √® una approssimazione dal basso mentre $b_n$ √® una approssimazione dall\u0026rsquo;alto\nPoi utilizzando il lemma 1 e il lemma 2 si pu√≤ concludere che, dato c questo limite che $f(a_n) = f(c) \\leq 0$ e che $f(b_n) = f(c) \\geq 0$ e quindi abbiamo dimostrato che esiste $f(c) = 0$\nCostruttiva ‚Üí Ho un metodo di approssimazione\nTeorema degli Zeri e polinomi Nei polinomi di grado dispari si pu√≤ notare che il limite del polinomio che tende a +infinito va a +infinito, uguale il contrario, grazie al thzero si pu√≤ concludere che deve avere necessariamente uno zero (si pu√≤ dimostrare anche la continuit√† di questo! √à algebra dei limiti)\nOgni polinomio di gradi dispari ha almeno una radice Reale.\nWeierstrass e Valore intermedio Weierstrass (Estremi finiti) Studia il concetto di punto di massimo o minimo assoluto. In particolare dice che esistono quei due punti per funzioni:\nDominio limitato e chiuso Funzione continua $$ \\exists x_{0} \\in \\left[ a, b \\right] : f(x) \\leq f(x_{0}), \\forall x \\in \\left[ a, b \\right] $$ E stessa cosa per il minimo.\nLa dimostrazione non √® data. Ma √® una propriet√† che molti direbbero che sia intuitivamente vera. Andare a dimostrarla si entrerebbero in tecnicismi inutili secondo me. Nel caso puoi sempre approfondirla nella pagina wikipedia associata.\nWeierstrass riformulato Quello che dice in pi√π √® che l\u0026rsquo;immagine della funzione coincide con il massimo e minimo assoluto.\nSi dovrebbe dimostrare con Weiestrass di prima e thzeri.\n$\\forall y \\in codominio, \\text{considero } g(x) = f(x) - y$ e poi utilizzo il teorema degli zeri per dire che esiste un x per cui $g(x) = 0 \\iff f(x) = y$ e quindi ho trovato un x per cui vale.\nTeorema del valore intermedio Questo √® anche chiamato intermediate value theorem. Lo abbiamo utilizzato per dimostrare qualcosa di molto breve su\nLa dimostrazione √® equivalente a Weierstrass riformulato.\nIntegral and Derivative Dominated Convergence Theorem See here. This allows under some conditions to swap gradients and integrals, which is quite handy. For example in RL Function Approximation we use it for the score trick.\nConvergence Types Definitions Uniform Convergence The convergence is uniform if for every $\\epsilon \u003e 0$ there exists a $N$ such that for every $n \u003e N$ and for every $x \\in A$ we have that $|f_n(x) - f(x)| \u003c \\epsilon$. Where $f_n$ is the sequence of functions and $f$ is the limit function.\nWe can write the same thing with $\\sup$:\n$$ \\forall \\epsilon \u003e 0, \\exists N : n \u003e N \\implies \\sup_{x \\in A} |f_n(x) - f(x)| \u003c \\epsilon $$ Where $A$ is the domain of the functions.\nPointwise Convergence The convergence is pointwise if for every $x \\in A$ and for every $\\epsilon \u003e 0$ there exists a $N$ such that for every $n \u003e N$ we have that $|f_n(x) - f(x)| \u003c \\epsilon$.\nNotes on the differences The difference is that in uniform convergence the $N$ is the same for every $x \\in A$, while in pointwise convergence the $N$ can change for every $x$. The main implication of this difference is that uniform convergence implies pointwise convergence, but the opposite is not true.\nOne student could wrongfully assume that if we take the maximum of $N$ for every $x$ we can have uniform convergence. Then we can have a same $N$ for every $x$ which implies uniform convergence. But we can have a counterexample where the $N$ is not bounded!\nPointwise convergence implies $\\liminf f_n = \\lim f_n$ This is some random result useful for some proofs about Banach Spaces. Intuitively, if a sequence gets close to the point (pointwise convergence) then also the inferior and upper limits are the same.\nLet\u0026rsquo;s go step by step and rigorously show that if $f_n(x) \\to f(x)$ pointwise, then\n$$ \\liminf_{n \\to \\infty} f_n(x) = \\lim_{n \\to \\infty} f_n(x). $$For a sequence $(f_n)$, we define:\n$$ \\liminf_{n \\to \\infty} f_n = \\sup_{m \\geq 1} \\inf_{n \\geq m} f_n. $$$$ \\limsup_{n \\to \\infty} f_n = \\inf_{m \\geq 1} \\sup_{n \\geq m} f_n. $$ The liminf represents the largest value that the sequence eventually stays above infinitely often.\nThe limsup represents the smallest value that the sequence eventually stays below infinitely often.\nThe sequence $(f_n)$ converges to $f$ if and only if\n$$ \\liminf f_n = \\limsup f_n = f. $$ Thus, our goal is to show that if $f_n(x) \\to f(x)$, then\n$$ \\liminf f_n = f = \\limsup f_n. $$ By definition,\n$$ \\liminf_{n \\to \\infty} f_n = \\sup_{m \\geq 1} \\inf_{n \\geq m} f_n. $$Since $f_n \\to f$, we know that for every $\\varepsilon \u003e 0$, there exists an integer $N$ such that for all $n \\geq N$,\n$$ f_n \\geq f - \\varepsilon. $$Taking the infimum over all $n \\geq m$ for $m \\geq N$, we get\n$$ \\inf_{n \\geq m} f_n \\geq f - \\varepsilon. $$Now, taking the supremum over all $m \\geq 1$, we obtain\n$$ \\sup_{m \\geq 1} \\inf_{n \\geq m} f_n \\geq f - \\varepsilon. $$Since this holds for every $\\varepsilon \u003e 0$, we conclude that\n$$ \\liminf_{n \\to \\infty} f_n \\geq f. $$$$ \\limsup_{n \\to \\infty} f_n = \\inf_{m \\geq 1} \\sup_{n \\geq m} f_n. $$Since $f_n \\to f$, for every $\\varepsilon \u003e 0$, there exists an integer $N$ such that for all $n \\geq N$,\n$$ f_n \\leq f + \\varepsilon. $$Taking the supremum over all $n \\geq m$ for $m \\geq N$, we get\n$$ \\sup_{n \\geq m} f_n \\leq f + \\varepsilon. $$Now, taking the infimum over all $m \\geq 1$, we obtain\n$$ \\inf_{m \\geq 1} \\sup_{n \\geq m} f_n \\leq f + \\varepsilon. $$Since this holds for every $\\varepsilon \u003e 0$, we conclude that\n$$ \\limsup_{n \\to \\infty} f_n \\leq f. $$ we now have\n$$ \\liminf_{n \\to \\infty} f_n \\geq f, \\quad \\limsup_{n \\to \\infty} f_n \\leq f. $$Since $\\liminf f_n \\leq \\limsup f_n$ always holds, this forces:\n$$ \\liminf_{n \\to \\infty} f_n = f = \\limsup_{n \\to \\infty} f_n. $$Thus, the limit exists and is equal to $f$:\n$$ \\lim_{n \\to \\infty} f_n = f. $$We have rigorously proven that if $f_n(x) \\to f(x)$ pointwise, then\n$$ \\liminf_{n \\to \\infty} f_n(x) = \\lim_{n \\to \\infty} f_n(x). $$Let me know if you need any further clarification! üòä\nClassical Results Uniform convergence implies classical convergence If a sequence of functions converges uniformly, then it converges pointwise.\nProof: By definition of uniform converge we have that $f_n$ converges uniformly to $f$. Then for every $\\epsilon \u003e 0$ there exists a $N$ such that for every $n \u003e N$ and for every $x \\in A$ we have that $|f_n(x) - f(x)| \u003c \\epsilon$. In particular, since the inequality holds for the supremum over all $x \\in A$, it holds for each individual $x \\in A$. This implies that for every $x \\in A$ and for every $\\epsilon \u003e 0$ there exists a $N$ (which is the $N$ of uniform convergence) such that for every $n \u003e N$ we have that $|f_n(x) - f(x)| \u003c \\epsilon$. This is the definition of pointwise convergence. $\\square$.\nCounterexample of the opposite Here we prove that pointwise convergence does not imply uniform convergence.\n$$ f(x) = \\begin{cases} 0 \u0026 \\text{if } x \\in [0, 1) \\\\ 1 \u0026 \\text{if } x = 1 \\end{cases} $$But there is no $N$ such that for every point $x \\in [0, 1]$ we have that $|f_n(x) - f(x)| \u003c \\epsilon$ for every $n \u003e N$! Let\u0026rsquo;s fix that $N$ and a $\\varepsilon$, we show that we can find a $\\delta \u003e 0$ such that it doesn\u0026rsquo;t hold for $x = (1 - \\delta)$. Then we have that $|f_n(1 - \\delta) - f(1 - \\delta)| = |(1 - \\delta)^{n} - 0| = (1 - \\delta)^{n} \u003e\\varepsilon \\implies \\delta \u003c 1 - \\sqrt[n]{ \\varepsilon }$, which is a contradiction.\n","permalink":"https://flecart.github.io/notes/limiti/","summary":"\u003cp\u003eRiguardare \u003ca href=\"/notes/successioni/\"\u003eSuccessioni\u003c/a\u003e per avere primo attacco sui limiti\u003c/p\u003e\n\u003ch2 id=\"41-limiti-finiti-al-finito\"\u003e4.1 Limiti finiti al finito\u003c/h2\u003e\n\u003ch3 id=\"411-intorno-sferico\"\u003e4.1.1 Intorno sferico\u003c/h3\u003e\n\u003cp\u003eDato l\u0026rsquo;insieme $\\mathbb{R}$ si definisce l\u0026rsquo;intorno sferico aperto di $x \\in \\mathbb{R}$ di raggio $r \\in \\mathbb{R}$ l\u0026rsquo;insieme\n$I_r(x) = (x -r, x + r)$ questa nozione √® molto importante per definire il limite. Lo useremo subito su un punto di accumulazione\u003c/p\u003e\n\u003ch3 id=\"412-punto-di-accumulazione\"\u003e4.1.2 Punto di accumulazione\u003c/h3\u003e\n\u003cp\u003eUn punto di accumulazione $x$ di un insieme $A \\subseteq \\mathbb{R}$ √® un punto tale per cui mi posso avvicinare in modo indefinito  in quel punto. Infatti deve $\\forall r \u003e 0 \\in R, \\exists x_ 1 \\in A : x_1 \\in I_r(x) \\wedge x_1 \\not= x$ ossia per cui $A \\cap I_r(x) \\not= \\varnothing$.\u003c/p\u003e","title":"Limiti"},{"content":"We will present some methods related to regression methods for data analysis. Some of the work here is from (Hastie et al. 2009). This note does not treat the bayesian case, you should see Bayesian Linear Regression for that.\nProblem setting $$ Y = \\beta_{0} + \\sum_{j = 1}^{d} X_{j}\\beta_{j} $$We usually don\u0026rsquo;t know the distribution of $P(X)$ or $P(Y \\mid X)$ so we need to assume something about these distributions.\nOne approach is assuming the distribution $Y \\mid X \\sim \\mathcal{N}(f(X), \\sigma^{2}I)$ and then solve the log likelihood on the probability If we use a statistical learning approach then we know we want to minimize this $\\arg \\min_{f} \\sum_{i = 1}^{n} (y_{i} - f(x_{i}))^{2}$ which is what is often used. Both methods end with the same solution. Usually for these kind of problems we use the Least Squares Method, initially studied in Minimi quadrati. We will describe it again better in this setting. Let\u0026rsquo;s consider the linear model\nNormal Equation solution üü© $$ Y = X^{T}\\beta $$$$ RSS(\\beta) = \\sum_{i = 1}^{n}(y_{i} - x_{i}^{T}\\beta)^{2} = (y - X\\beta)^{T}(y - X\\beta) $$ This loss can be briefly motivated: we don\u0026rsquo;t want to use normal $x - y$ because positive and negative errors can cancel out, then we want to square it to have better differentiability.\n$$ \\nabla _{\\beta} RSS(\\beta) = 0 \\implies X^{T}(y - X\\beta) = 0 \\implies \\hat{\\beta} = (X^{T}X)^{-1} X^{T}y $$ Which is just slow because of the inverse part, but easily feasible. This is done in the old note section. In order to know that this indeed is the minimum we should also see the hessian, but should be easy to check that. (if not check chapter 3 of (Hastie et al. 2009)).\nThis is the solution: $$ y = X\\hat{\\beta} = X(X^{T}X)^{-1}X^{T}y $$$$ \\hat{\\beta} \\sim \\mathcal{N} (\\beta, (X^{T}X)^{-1}\\sigma^{2}) $$ And we know that this is usually an unbiased estimator.\nNormal equation estimator is unbiased üü© $$ \\mathbb{E}(a^{T}\\beta) = a^{T} (X^{T}X)^{-1}X^{T}\\mathbb{E}[y] = a^{T} (X^{T}X)^{-1}X^{T}\\mathbb{E}[X\\beta + \\varepsilon] = a^{T}\\beta $$$$ \\mathbb{V}(a^{T}\\beta) = \\mathbb{E}(a^{T} (X^{T}X)^{-1}X^{T}\\varepsilon\\varepsilon X (X^{T}X)^{-1}a) = \\sigma^{2}a^{T}(X^{T}X)^{-1}a $$ I have no Idea why here we multiply by another vector $a$, probably because we want to generalize to any linear functional over the parameter space. The variance thing is just nice when you want to say that if you have an estimator of the form $Ay$ then it\u0026rsquo;s variance is $A^{T}A$.\nGauss Markov Theorem üü® This theorem only talks about unbiased estimators. But we need to remember the Rao-Cramer Bounds explained in Parametric Modeling that some biased methods could do better.\nFrom wiki: Gauss‚ÄìMarkov theorem¬†(or simply¬†Gauss theorem¬†for some authors)states that the¬†ordinary least squares¬†(OLS) estimator has the lowest¬†sampling variance¬†within the¬†class¬†of¬†linear¬†unbiased¬†estimators.\nIf we consider another estimator $\\hat{\\theta} = c^{T}y = a^{T}\\hat{\\beta} + a^{T}Dy$ we cannot use any deviation D, because if it is unbiased we will have $a^{T}DX = 0$\nYou can see the proof in the image: This shows that among all the unbiased models MLE with ordinary least squares produces the best results, but some biased results could do better! Here We have an easier proof based on the difference of the variance of the two estimators.\u0026ndash;\nRegression is biased üü•+ One can show that there are many examples where linear regression is quite biased. This is a problem especially with high dimensional data. There are some numerical instabilities with correlated features, especially when we are trying to invert something small (floating point imprecisions!)\nBias Variance trade-off üü© \u0026ndash; We want to decompose the value $\\mathbb{E}_{D}\\mathbb{E}_{X, Y}[(\\hat{f}(x) - y)^{2}]$ where $f$ is the parameterized function that we are trying to learn, and $y$ is the true label. $D$ is our dataset is a distribution on all available datasets, and has an influence on $\\hat{f}$ in this case., and $X, Y$ are the true un-accessible distributions of the data. Now let\u0026rsquo;s do some calculations. Let\u0026rsquo;s consider the value $\\hat{y} = \\mathbb{E}_{Y}[Y \\mid X=x]$. Then let\u0026rsquo;s decompose the prediction error at $X = x$\n$$ \\mathbb{E}_{D}\\mathbb{E}_{Y\\mid X=x}[(\\hat{f}(x) - \\hat{y} + \\hat{y} - y)^{2}] = \\mathbb{E}_{D}\\mathbb{E}_{Y\\mid X=x}[(\\hat{f}(x) - \\hat{y})^{2}] + \\mathbb{E}_{D}\\mathbb{E}_{Y\\mid X=x}[(\\hat{y} - y)^{2}] + 0 $$ Now $\\mathbb{E}_{D}\\mathbb{E}_{Y\\mid X=x}[(\\hat{y} - y)^{2}] = \\mathbb{E}_{Y \\mid X=x}[(\\hat{y} - y)^{2}]$ because we are not training anything on $D$, and one can see that this is the noise variance, mean difference between the correct mean and the $y$ itself.\n$$ \\mathbb{E}_{D}\\mathbb{E}_{Y\\mid X=x}[(\\hat{f}(x) - \\hat{y})^{2}] = \\mathbb{E}_{D}\\mathbb{E}_{Y\\mid X=x}[(\\hat{f}(x) - \\mathbb{E}[\\hat{f}(x)] + \\mathbb{E}[\\hat{f}(x)]- \\hat{y})^{2}] = \\mathbb{E}_{D}[(\\hat{f}(x) - \\mathbb{E}[\\hat{f}(x)])^{2}] + \\mathbb{E}_{D}[( \\mathbb{E}[\\hat{f}(x)] - \\hat{y})^{2}] + 0 $$ The first term - $\\mathbb{E}_{D}[(\\hat{f}(x) - \\mathbb{E}[\\hat{f}(x)])^{2}]$ - is the variance, the second term simplifies to $( \\mathbb{E}[\\hat{f}(x)] - \\hat{y})^{2}$ as everything is constant with respect to $D$ inside that, this is the bias squared (the expected prediction model across all possible datasets minus the expected real value).\nRegularizers A link to statistical learning üü© Quite often it is true that the Statistical learning framework with a cost function and a regularizator is exactly the same as a Maximum a posteriori estimate in the bayesian setting, we can see it quite quickly:\n$$ \\arg \\min_{\\theta} \\sum_{n = 1}^{N} \\mathcal{L}(f(x), y) + R(\\theta) = \\arg \\max_{\\theta} \\prod_{i =1 }^{N} P(y \\mid x, \\theta) P(\\theta) $$ If $R(\\theta) = -\\log(P(\\theta))$ and $\\mathcal{L}(f(x), y) = -\\log(P(y \\mid x, \\theta))$, so we can see the prior as if it was a regularizer!\nFrom a purely theoretical point of view, what we would like to calculate is the following $f^{*}(x) = \\mathbb{E}_{Y \\mid X} [Y \\mid X = x]$, but the number of samples for each $x$ is sparse, quite often we don\u0026rsquo;t have a label for a specific $x$. We need a function assumption that uses the nearby samples to make inference of the points close to those. For Buhmann, model free is non sense because its just a hidden model.\nRidge regression üü©\u0026ndash; With linear regression we assume that $y \\approx w^{T}x = f(x;w) = f_{w}(x)$. And usually we have some regularization thing that prevents the overfitting.\n$$ \\hat{w} = \\arg \\min_{w\\in \\mathbb{R}^{d}} \\sum_{i = 1}^{n} (y_{i} - w^{T}x_{i})^{2} + \\lambda \\lVert w \\rVert ^{2}_{2} $$ This is called ridge regression. The penalty term makes the weights shrunk towards zero. This idea is also used in neural networks, where it is known as weight decay.\nThe ridge solutions are not equivariant under scaling of the inputs, and one should standardize the inputs before solving\n$$ \\hat{w} = (X^{T}X + \\lambda I)^{-1} X^{T}y $$ It\u0026rsquo;s easy to derive this formula, just take the derivative with respect to $w$, just need to handle the vector calculus well enough. We note that adding the term on the diagonal of $X^{T}X$ makes the matrix non-singular which allows inversion. This was the original reason why it was introduced. Similar thing can be done with standard regression. We will later discover that this is somewhat equivalent to a MAP estimate in the bayesian learning setting, while the MLE estimate is the classical linear regression, see Bayesian Linear Regression.\nFor Ridge to have a sparse solution, the best solution should be on one of the axis, which is rare, not for the Lasso! The lasso sparse solution region scales quadratically with the distance to the rombus, so it\u0026rsquo;s far more probable to have sparsity! This is very good for interpretability.\nLasso regression üü© $$ \\hat{w} = \\arg \\min_{w\\in \\mathbb{R}^{d}} \\sum_{i = 1}^{n} (y_{i} - w^{T}x_{i})^{2} + \\lambda \\lVert w \\rVert_{1} $$ Which is without the power of two (just sum of the values norm) $\\lVert w \\rVert_{1} = \\sum_{i =1}^{d} \\lvert w_{i} \\rvert$\n$$ w \\sim \\frac{\\lambda}{4\\sigma^{2}}\\exp\\left( -\\lvert w \\rvert \\frac{\\lambda}{-2\\sigma^{2}} \\right) $$ Which is a Laplace distribution.\nThis is an image from the ESLI book. It justifies why with LASSO regularizers its far more easier to get sparse solutions. Diamonds are more likely to hit the error countours. The Kernel Case üü•++ $$ \\hat{\\beta} = \\arg \\min_{\\beta \\in \\mathbb{R}^{\\infty}} \\sum_{i} (y_{i} - \\beta^{T}\\varphi(x))^{2} $$$$ \\hat{\\beta} = (\\Phi^{T}\\Phi)^{-1}\\Phi^{T}y $$$$ \\hat{\\beta} = \\Phi^{T}(\\Phi \\Phi^{T})^{-1}y $$ Which simplifies a little bit because that $\\Phi \\Phi^{T}$ is a $\\mathbb{R}^{n\\times n}$ matrix, but we still need to solve the outside $\\Phi^{T}$.\n$$ \\varphi(\\hat{x})^{T}\\hat{\\beta} = \\varphi(\\hat{x})^{T}\\Phi^{T}(\\Phi \\Phi^{T})^{-1}y $$$$ \\hat{\\psi}(x) = k(x)A^{-1}y $$ With $A = \\Phi \\Phi^{T}$ the kernel matrix, where $A_{ij} = \\varphi(x_{i})^{T}\\varphi(x_{j})$.\nBut $A^{-1}$ is highly instable! This is why we add something in the diagonal, something similar to the ridge regression.\nSo we just add the thing on the diagonal: $\\hat{\\psi}(x) = k(x)(A + \\lambda I)^{-1}y$\nThe classification Case There is an analogous problem setting, but we assume that our target, the $y$ is some categorical data. So we still have the training dataset $\\left\\{ x_{i}, y_{i} \\right\\}_{i \\leq n} \\in \\mathbb{R}^{d} \\times \\mathcal{Y}$, we need to find (learn) a function $f: \\mathbb{R}^{d} \\to \\mathcal{Y}$. Usually $\\mathcal{Y} = \\left\\{ 0, 1 \\right\\}$ or $\\left\\{ -1, 1 \\right\\}$. Some common assumptions for this problem settings are:\n$X \\mid Y = y_{i} \\sim \\mathcal{N}(\\mu_{i}, \\Sigma)$ and unknown mean and variance $Y \\sim \\text{ Bern(0.5)}$ which is just uniform over the possible cases I think. $$ P(y_{i} = 1 \\mid X) = \\sigma(\\beta^{T}x) $$ Where $\\beta$ is dependent on the mean and variance of the training samples. You should also take a look at Logistic Regression where we have a natural derivation of the Sigmoid function.\nLoss Functions The loss function depends on the set of labels used:\nFor $\\mathcal{Y} = \\left\\{ 0, 1 \\right\\}$ we use the cross entropy loss which is $$ \\mathcal{L}(f(x), y) = -y\\log(f(x)) - (1 - y)\\log(1 - f(x)) $$ For $\\mathcal{Y} = \\left\\{ -1, 1 \\right\\}$ the loss the logistic loss is: $$ \\mathcal{L}(f(x), y) = \\log(1 + \\exp(-yf(x))) $$ Note that the last one is just the negative log likelihood of a probability given by the Sigmoid function! While for the first case, it\u0026rsquo;s the negative log likelihood with a probability given by the Bernoulli distribution. Ensemble methods $$ \\hat{f}(x) = \\frac{1}{M}\\sum_{m = 1}^{M} f_{m}(x) $$$$ \\text{ bias }[\\hat{f}(x)] = \\mathbb{E}_{D}[\\hat{f}(x)] - \\mathbb{E}[Y\\mid X=x] = \\frac{1}{M}\\sum_{m = 1}^{M} \\mathbb{E}_{D}[f_{m}(x)] - \\mathbb{E}[Y\\mid X=x] = \\frac{1}{M} \\sum_{m=1}^{M}bias(\\hat{f}_{m}(x)) $$Which implies if we have unbiased estimators, the ensemble will also be unbiased.\nIf we look at the variance we will see that\n$$ \\text{Var}[\\hat{f}(x)] = \\frac{1}{M^{2}}\\sum_{m = 1}^{M} \\text{Var}[f_{m}(x)] + \\frac{1}{M^{2}}\\sum_{m \\neq l} \\text{Cov}[f_{m}(x), f_{l}(x)] $$ And if the covariance is small enough, then the variance of the ensemble is smaller than the variance of the individual estimators, which is why the wisdom of the crowds work. We gain variance reduction of $\\frac{\\sigma^{2}}{M}$\nReferences [1] Hastie et al. ‚ÄúThe Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition‚Äù Springer Science \u0026amp; Business Media 2009\n","permalink":"https://flecart.github.io/notes/linear-regression-methods/","summary":"\u003cp\u003eWe will present some methods related to regression methods for data analysis.\nSome of the work here is from (Hastie et al. 2009). This note does not treat the bayesian case, you should see \u003ca href=\"/notes/bayesian-linear-regression/\"\u003eBayesian Linear Regression\u003c/a\u003e for that.\u003c/p\u003e\n\u003ch3 id=\"problem-setting\"\u003eProblem setting\u003c/h3\u003e\n$$\nY = \\beta_{0} + \\sum_{j = 1}^{d} X_{j}\\beta_{j}\n$$\u003cp\u003eWe usually don\u0026rsquo;t know the distribution of $P(X)$ or $P(Y \\mid X)$ so we need to assume something about these distributions.\u003c/p\u003e","title":"Linear Regression methods"},{"content":"DPDA Definizione (2)üü© La definizione di DPDA √® molto simile a quella trattata in Linguaggi liberi e PDA, con solo costraints sulla deterministicit√†, che si traducono in due condizioni:\nAl massimo posso avere un risultato per ogni coppia di lettura e simbolo su stack Se ho una transizione senza leggere, posso avere solo quella Slide\nLinguaggio libero deterministico Un linguaggio √® libero deterministico se esiste un PDA che lo riconosce per stato finale.\nPropriet√† accettazione per DPDAüü© Per stato finale accettato resta sempre, cambia un p√≤ l‚Äôaccettazione per pila vuota, in cui si deve avere una prefix property.\nQuesta prefix property ha un certo interesse perch√© basta aggiungere un simbolo che non √® presente nell‚Äôalfabeto, e ho la prefix property! (guarda esempi Lez12 prime slide).\nPrefix propertyüü© Due parole del linguaggio in cui il primo √® interamente dentro il secondo.\nslide Prefix property\nSe aggiungo un simbolo $ riesco a far sempre che ci sia la prefix property.\nLa dimostrazione √® pi√π o meno su questa scia. affinch√© uno sia prefisso dell‚Äôaltro, deve avere il dollaro nella stessa posizione, allora hanno la stessa lunghezza, ma se hanno la stessa lunghezza devono essere uguali, ecco la prefix property.\nEsiste DPDA che riconosce linguaggi regolariüü© Enunciato\nDimostrazione\nPraticamente la dimostrazione √® la stessa per Grammatiche Regolari, ma ho anche lo stack, basta che non lo uso e ho finito.\nNon ambiguit√† dei DPDAüü© Enunciato\nQuindi se esiste un DPDA che riconosce il linguaggio, si pu√≤ creare una grammatica non ambigua che riconosce lo stesso linguaggio.\nCon la lezione del 29/11 abbiamo introdotto che un linguaggio √® deterministico sse SLR(1) in LR(k) e YACC, quindi probabile che i DPDA posso essere ricondotti in una forma deterministica a singolo\nPropriet√† dei linguaggi deterministiciüü© Complemento s√¨ Unione o intersezione no. Complemento probabilmente s√¨ perch√© basta applicare lo stesso ragionamento fatto per le regex in Automi e Regexp, ossia basta invertire gli stati accettati.\nPer dimostrare che non sono chiusi per intersezione o unione sarebbe buona cosa fornire un esempio.\nEsempio non intersezione ‚áí non unione.\nAnalizzatori sintattici In modo simile a quanto presentato in Grammatiche Regolari nell discussione dei Lex.\nQuesta parte utilizziamo abbiamo i strumenti automatici che prendono una grammatica libera e resituiscono un DPDA\nTipologie di parser (2-2-2)üü© Deterministico o non-deterministico Top-Bottom Oltre a ci√≤ possiamo anche dividere i parse a seconda di\nLettura da destra o da sinistra Creazione derivazione rightmost o leftmost Numero di look ahead. Quindi per esempio se ho una grammatica che inizia a leggere da sinistra, crea derivazione leftmost e ha un lookahead di 1, lo rappresento come $LL(1)$\nTop down parsing con PDA singolo statoüü© Simile a quanto fatto in Linguaggi liberi e PDA per il teorema di equivalenza di linguaggio libero e PDA, vado a crearmi un automa in un certo modo (in particolare con singolo stato riconosce per pila vuota).\nSlide enunciato\nQuesta √® una semplice soluzione non deterministica, possiamo togliere questo non determinismo con il Look Ahead come rpesentato sotto\nLook Ahead(+)üü© Posso andare a guardare la lettera avanti per capire in che modo comportarmi con la derivazione.\nUtilizzo una tabella di parsing per capire in che modo devo espandere il non-terminale.\nEsempio di look ahead 1\ncon $S := aSb|\\varepsilon$\nNote per risolvere i conflitti\nPosso\nFattorizzare (creare una nuov agrammatic aequivalente senza ricorsione sinistra che non riesco a gestirla, va a divergere, quindi non finisce mai Fare un look ahead maggiore di 1 Queso √® utile per togliere il non determinismo.\nBottom up parsing(3)üü®- Si tratta sempre della creazione di un PDA a singolo stato!, ma fatto in modo di verso, in modo tale che ci sia una derivazione rightmost.\nImportanti in questa parte sono 3 operazioni\nShift, in cui facci ocrescere verso destra la pila, come se stessi facendo lo shift Reduce, quando creo il non terminale come se fosse una espansione di non terminale. Accept Esempio di creazione di parser bottom up\nEsempio di derivazione con il parser di sopra\nProblema non determinismo per sopra\nMa comunque andiamo a discutere meglio di questa parte in Bottom-up Parser LR(0).\nTipologie di conflitti di bottom up Shift-reduce Reduce-Reduce Oltre a questo c\u0026rsquo;√® un grandissimo problema delle produzioni del tipo $A \\to \\varepsilon$, perch√© queste divergono sempre, quindi √® meglio non avere grammatiche con questa produzione se vogliamo utilizzare parsing bottom up.3\n","permalink":"https://flecart.github.io/notes/linguaggi-deterministici-e-dpda/","summary":"\u003ch2 id=\"dpda\"\u003eDPDA\u003c/h2\u003e\n\u003ch3 id=\"definizione-2\"\u003eDefinizione (2)üü©\u003c/h3\u003e\n\u003cp\u003eLa definizione di DPDA √® molto simile a quella trattata in \u003ca href=\"/notes/linguaggi-liberi-e-pda/\"\u003eLinguaggi liberi e PDA\u003c/a\u003e, con solo costraints sulla deterministicit√†, che si traducono in due condizioni:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAl massimo posso avere un risultato per ogni coppia di lettura e simbolo su stack\u003c/li\u003e\n\u003cli\u003eSe ho una transizione senza leggere, posso avere solo quella\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Linguaggi Deterministici e DPDA/Untitled 1.png\" alt=\"image/universita/ex-notion/Linguaggi Deterministici e DPDA/Untitled 1\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"linguaggio-libero-deterministico\"\u003eLinguaggio libero deterministico\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eUn linguaggio √® libero deterministico se esiste un PDA che lo riconosce per \u003cstrong\u003estato finale\u003c/strong\u003e.\u003c/p\u003e","title":"Linguaggi Deterministici e DPDA"},{"content":"In questa parte del nostro percorso nei linguaggi di programmazione proviamo ad espandere NFA e DFA in modo che possano riconoscere linguaggi come $ww^r | w \\in \\{a, b\\}^*$ , con r maggiore o uguale a zero (r per dire che √® il contrario di w) (questo linguaggio per il pumping lemma).\nGrammatiche libere da contesto $$ G = \\langle \\mathcal{N}, S, \\Sigma, \\mathcal{R} \\rangle $$ Dove $\\mathcal{N}$ sono i non terminali, $S$ √® il non terminale iniziale, $\\Sigma$ sono l\u0026rsquo;alfabeto dei simboli finali e $\\mathcal{R}$ le relazioni possibili. Spesso lo scriviamo solo tramite le relazioni, perch√© √® la forma pi√π compatta. I nodi di una derivazione da grammatica libera da contesto √® chiamato costituente del linguaggio. Questo √® pi√π importante in linguistica.\nPush-down automata Introduzione automi a pila (7)üü© \u0026ndash; L‚Äôidea principale per espandere gli NFA √® il concetto di stato o memoria, avere quindi una stack o pila pu√≤ rendere molto pi√π espressivo queste entit√†.\nIl prof. definisce automa a pila non deterministico (PDA) questa settupla $(\\Sigma, Q, \\Gamma, \\delta, q_{0}, \\bot, F)$\n$\\Sigma$ l\u0026rsquo;alfabeto finito dei simboli in input $\\Gamma$ l\u0026rsquo;alfabeto dei simboli sulla pila $Q$ l\u0026rsquo;insieme degli stati $\\delta$ transizione, nella forma $\\delta: Q\\times (\\Sigma \\cup \\left\\{ \\varepsilon \\right\\}) \\times \\Gamma \\to \\mathbb{P}(Q \\times \\Gamma^{*})$ $q_{0}$ lo stato iniziale $\\bot \\in \\Gamma$ il simbolo iniziale sulla pila $F \\in Q$ l\u0026rsquo;insieme degli stati finali. Una differenza che fa questo prof. contro La macchina di Turing √® che lui fa distinzione dei simboli sulla pila, mentre l\u0026rsquo;altro no, una altra differenza √® che gli stati finali sono esterni nell\u0026rsquo;altro. Ma credo alla fine sia equivalente. Attenzione: l‚Äôautoma pu√≤ leggere qualcosa solo se la sua stack non √® vuota!\nLa parte inteessante dei PDA rispetto agli automi studiati in Automi e Regexp √® la funzione di transizione, che √® ora nella forma\n$$ \\delta: Q \\times (\\Sigma \\cup\\{\\varepsilon\\}) \\times \\Gamma \\to P(Q \\times \\Gamma ^*) $$ Esempio hard di PDA Computazione automi a pilaüü© \u0026ndash; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Linguaggi liberi e PDA/Untitled 7.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Linguaggi liberi e PDA/Untitled 7\u0026quot;\u0026gt; Accettazione della stringa üü© La cosa particolare degli automi a pila √® che accettano la stringa anche quando la pila diventa vuota, non solo quando finisco di leggere e ho uno stato che √® bello. Ossia detto meglio, posso costruirmi un automa a Pila che accetta la stessa stringa quando la pila diventa vuota, c‚Äô√® una sorta di equivalenza fra stato e cose sulla pila.\nSlide\nLa cosa importante da capire per questa parte √® che si differenziano due metodi di accettazione per la stringa:\nPila vuota Stato finale. In entrambi i casi devo leggere tutto l‚Äôinput, e poi vado a vadere dove sto. Nel primo caso se ho letto tutto l‚Äôinput e la pila √® vuota allora accetto, nel secondo caso se ho letto tutta la stringa e sono in uno stato finale allora vado ad accettare.\nTeorema equivalenza accettazione Vuoto-Stato üü© Enunciato\nDimostrazione in slide\nL\u0026rsquo;idea dietro questo teorema √® molto simile a quanto presente nella conversione fra espressione regolare e NFA, perch√© sto andando in modo ricorsivo, supponendo che ho gi√† un vecchio automa che funzioni, e basta che ci costruisca cose intorno ad essa. (in questo caso simbolo iniziale nuovo e stato finale che pi√π o meno racchiude tutti gli stati finali!\nZ √® un simbolo stack nel nostro nuovo automa, solo utilizzato per gestire meglio alcune cose con la stack.\nOgni linguaggio √® libero sse riconosciuto da PDA (chiede)üü© Enunciato\nDimostrazione\nDiagramma PDA per ‚Üí\nNota questo non √® il PDA di cui parlava il prof nelle slides, bisognerebbe condensarlo in un unico stato. Questo qui risolve per stato finale, quello del prof per stack vuota\nNote sulla dimo\nVogliamo dimostrare un sse, in una proviamo a costruire un automa partendo dalle regole della grammatica, (non dimostriamo che l‚Äôautoma riconosce effettivamente, la costruiamo ebbasta.\nPer l‚Äôaltra freccia bisogna avere dimostrato prima alcuni lemmi che noi saltiamo per ora.\nPropriet√† dei linguaggi liberi Unione, Conc, e Kleene üü© Dimostrazione\nIn pratica i non terminali e terminali sono uniti assieme, e con qualche produzione in pi√π sullo stato iniziale per gestire le cose.\nIntersezione con linguaggio regolare (chiede per alto voto) üü© Questa √® qualcosa di leggermente pi√π tosta, per√≤ in soldoni sto facendo un bruteforce, e prendendo tutte le combinazioni possibili per cui si possa riconoscere\nTh e dimostrazione\nCon questo teorema √® spesso utile per dimostrare che un linguaggio non √® libero.\nInvece non sono chiusi per intersezione i linguaggi liberi\nEsempio di non chiusura\nDa questo dato si pu√≤ concludere che non sono chiusi per complemento altrimenti lo sarebbero anche per l\u0026rsquo;intersezione.\nPumping theorem, tosta (!) üü®++ Enunciato\nDimostrazione\nDimostrazione libro sispser (pi√π chiaro)\nL‚Äôidea √® sempre avere cos√¨ tanti stati che avr√≤ per forza dei non terminali duplicati. uno sotto l‚Äôaltro, in una forma ricorsiva, allora prendo il minore e vado a fare ragionamenti l√¨.\nClassificazione dei linguaggi Classificazione di Chomsky Chomsky, linguista, ha descritto una gerarchia di linguaggi\nCaratterizzazione dei linguaggi Sulla decidibilit√† guardare Fondamenti teorica e La macchina di Turing\nIn questo caso i nuovi sono\nGrammatiche dipendenti dal contesto, in cui una singola produzione pu√≤ avere pi√π non-terminali. Grammatiche motonone, le cui produzioni basta che crescano Grammatiche generali, in cui non c‚Äô√® nessun vincolo di produzioni Schema generale delle grammatiche üü© Per turing, vedere La macchina di Turing.\nGerarchia automi üü®+ In generale si pu√≤ estendere dicendo\nAutomi Limitati riconoscono grammatiche dipendenti dal contesto Automi di Turing riconoscono i linguaggi ricorsivi, e sono in grado di enumerare ricorsivamente quelle generali. (anche se √® semidecidibile, quindi forse non riesce a ricononscerli tutte??) ","permalink":"https://flecart.github.io/notes/linguaggi-liberi-e-pda/","summary":"\u003cp\u003eIn questa parte del nostro percorso nei linguaggi di programmazione proviamo ad espandere NFA e DFA in modo che possano riconoscere linguaggi come $ww^r | w \\in \\{a, b\\}^*$ , con r maggiore o uguale a zero (r per dire che √® il contrario di w) (questo linguaggio per il pumping lemma).\u003c/p\u003e\n\u003ch4 id=\"grammatiche-libere-da-contesto\"\u003eGrammatiche libere da contesto\u003c/h4\u003e\n$$\nG = \\langle \\mathcal{N}, S, \\Sigma, \\mathcal{R} \\rangle \n$$\u003cp\u003e\nDove $\\mathcal{N}$ sono i non terminali, $S$ √® il non terminale iniziale, $\\Sigma$ sono l\u0026rsquo;alfabeto dei simboli finali e $\\mathcal{R}$ le relazioni possibili.\nSpesso lo scriviamo solo tramite le relazioni, perch√© √® la forma pi√π compatta.\nI nodi di una derivazione da grammatica libera da contesto √® chiamato \u003cstrong\u003ecostituente del linguaggio\u003c/strong\u003e. Questo √® pi√π importante in linguistica.\u003c/p\u003e","title":"Linguaggi liberi e PDA"},{"content":"Livello trasporto Protocolli classici Introduzione a TCP e UPD Il quarto livello dei protocolli dell‚Äôarchitettura di Internet √® il livello trasporto (transport), ed √® basato su due protocolli in particolare: il Transmission Control Protocol (TCP) e lo User Data Protocol (UDP), che possono essere usati in alternativa tra loro.\nQuesto √® nel genere di *connession oriented e non, il primo, TCP √® connection oriented, l\u0026rsquo;altro no, questa √® l‚Äôunica differenza fra i due. Questa differenza √® spiegata in maggior dettaglio qui 0.3.8 Servizi orientati alla connessione e non üü®+\nTCP\nConnection oriented (garantire il ripristino dell‚Äôordinamento dei pacchetti e la ri-trasmissione dei pacchetti perduti) Numero dell‚Äôordine (a cui riceve ack per questo numero) Controllare la velocit√† di invio ‚Üí Finestra scorrevole La parte importante di questo √® che la congestione si pu√≤ allargare a macchia d‚Äôolio all\u0026rsquo;interno di internet, e questo √® una cosa molto brutta! Quindi prova a risolvere gli errori di comunicazione di rete, cercando di garantire una buona trasmissione. Il problema √® l\u0026rsquo;efficienza, si possono inviare segmenti in pi√π e congestionare la rete.\nSi pu√≤ dire che questa √® la semantica diversa.\nCon la tree-way handshake si apre una connessione socket, quindi una coppia porta IP, per poter comunicare!\nUDP\n√à semplice perch√© non fa tutte le cose di TCP (no duplicati, no riordinamento, no checks) Tipo connectionless Socket Slide immagini\nIl protocollo TCP richiede a due dispositivi che intendano comunicare di effettuare preventivamente la configurazione dei parametri del socket TCP, originando in questo modo un canale virtuale di tipo punto a punto tra due socket, ovvero tra due applicazioni di livello superiore alle quali vengono smistati i pacchetti da TCP. Quindi sono degli estremi di comunicazione!\nDef socket\nUn socket √® un punto di arrivo o partenza (virtuale) dei dati a livello trasporto, dal quale √® in atto l‚Äôinvio e la ricezione di pacchetti destinati a un‚Äôapplicazione, ed equivale a una coppia: (indirizzo IP, numero di porta dell‚Äôapplicazione). Una volta instaurata la configurazione punto a punto tra due socket, attraverso lo scambio di pacchetti di configurazione, pu√≤ iniziare lo scambio dei dati a livello trasporto. In questo senso si dice che √® un trasporto TCP/IP, perch√© prima configurazione per IP poi effettivamente scambio.\nLa richiesta di connessione\nLa connessione viene instaurata con una richiesta di uno dei due host (il client) nei confronti dell‚Äôhost server.\nIndirizzo IP del server Numero della porta per l\u0026rsquo;applicazione (questo viene verificato dal server se qualche servizio ci √® aperto, se s√¨ risponde, e il client invia la configurazione). Poi iniziano a dialogare e alla fine liberano la porta, √® una connessione punto a punto!. Quando il server riceve il pacchetto, va a verificare se ha la porta aperta, se tutto va bene manda un messaggio di conferma, e il client invia un pacchetto di configurazione, allora possono cominciare a comunicare.\nWelcoming socket and client sockets\nWelcoming √® l\u0026rsquo;unico socket di ricezione di un server, che prende tutto e manda al thread corretto.\nClient sockets sono i molteplici sockets che il server utilizza per comunicare con il singolo client, vengono solitamente istanziati grazie al welcoming socket dopo che ho fatto richiesta di connessione.\nControllo della congestione TCP (2) Questa parte ora √® trattata meglio in Livello di trasporto\nSlide\nSchema\nTCP utilizza un protocollo molto particolare, e a prima vista non intuitivo per gestire la congestione della rete.\nL‚Äôidea generale √® che provo ad aumentare l‚Äôinvio finch√© posso, e quando mi accorgo che inizio a perdere chiudo tutto e ricomincio dal singolo pacchetto.\nCome si √® detto in precedenza, TCP richiede una conferma per ogni pacchetto inviato. La distanza tra due dispositivi che scambiano pacchetti a livello trasporto pu√≤ essere molto significativa. Il tempo per inviare un pacchetto e ottenere la conferma dell‚Äôavvenuta ricezione pu√≤ quindi diventare dell‚Äôordine dei secondi. Il problema del controllo di flusso dei pacchetti nel protocollo TCP si basa su due scopi apparentemente in contraddizione tra loro.\n√® quello di saturare il pi√π possibile la rete di pacchetti, inviandoli a un ritmo elevato. Questo favorisce l‚Äôutilizzo delle risorse e le prestazioni della rete (si spediscono e si ricevono tanti bit al secondo). Se si decidesse di inviare un pacchetto e aspettare l‚Äôarrivo della conferma, la rete sarebbe usata solo in minima percentuale, e si riuscirebbero a spedire solo pochi bit al secondo. Quindi la rete, pur essendo veloce nell‚Äôinvio dei bit, verrebbe sfruttata al minimo delle potenzialit√†. E‚Äô quindi evidente quanto sia opportuno spedire i pacchetti a un ritmo il pi√π veloce possibile. Evitare di saturare la rete occorre evitare che un ritmo di invio troppo elevato possa causare il sorgere della congestione nei router intermedi del cammino dei pacchetti, dal mittente TCP (client) al destinatario TCP (server). Se un router si trova a dover inoltrare troppi pacchetti, provenienti da flussi TCP diversi, i pacchetti si accumulano fino ad andare perduti e la rete va in crisi. In tal caso si deve ricorrere a una tecnica di controllo della congestione. Una forma di congestione pu√≤ comparire anche sul destinatario finale, nel caso in cui esso non sia in grado di ricevere i pacchetti inviati troppo velocemente. In tal caso si deve ricorrere a una tecnica di controllo di flusso. Finestra scorrevole Si parla di metodi di congestione, viene trattato meglio in Livello di trasporto Osservando l‚Äôesempio, partendo con SW uguale a 1, se la conferma √® ricevuta, la finestra viene raddoppiata, spedendo due pacchetti al massimo ritmo di invio. Se entrambi i pacchetti vengono confermati, si passa alla finestra di dimensione quattro, inviando quattro pacchetti al massimo ritmo di invio. Se i pacchetti sono confermati si passa a finestra di otto pacchetti. A questo punto, nell‚Äôesempio, almeno uno degli otto pacchetti non viene confermato. Si suppone che questo fatto sia dovuto a un router congestionato e quindi si rallenta il ritmo di invio ripartendo dalla finestra minima (pari a uno). Il massimo grado sostenibile di invio per la rete in esame nell‚Äôesempio √® stato quindi ottenuto con finestra pari a quattro.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Livello applicazione e socket/Untitled 6.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Livello applicazione e socket/Untitled 6\u0026quot;\u0026gt; TCP usa un meccanismo per il controllo di flusso, detto a finestra scorrevole (sliding window), e un meccanismo per il controllo della congestione, basato sul dimensionamento della finestra scorrevole. Tutto ci√≤ per cercare il massimo ritmo di spedizione che possa garantire l‚Äôinoltro dei pacchetti da parte del router pi√π lento del cammino, e prevenire la saturazione del destinatario finale.\nIdea della sliding window\nLa finestra scorrevole √® un valore intero, cha parte da un valore minimo (ad esempio il valore uno). L‚Äôidea alla base del controllo di flusso a finestra scorrevole √® quello di spedire non pi√π di Sliding Window pacchetti consecutivi, a partire dall‚Äôultimo pacchetto non confermato, e quindi attendere la ricezione di una conferma. Un valore di SW uguale a 1 significa che solo un pacchetto pu√≤ essere spedito, poi occorre aspettare di ricevere la conferma della ricezione. In questo caso la rete √® poco utilizzata. Ogni volta che alcuni pacchetti spediti sono confermati, allora √® possibile spedire i pacchetti successivi mantenendosi entro il limite massimo di SW pacchetti dall‚Äôultimo pacchetto non ancora confermato. Eventuali pacchetti non confermati sono rispediti fino al ricevimento della conferma.\nIl senso di questo meccanismo √® quello di lasciare in sospeso non pi√π di SW pacchetti, per evitare di saturare il mittente. Questo meccanismo, molto semplificato, realizza il controllo di flusso di TCP. Se i pacchetti vengono confermati, si pu√≤ adottare un meccanismo dinamico per accelerare gradualmente il ritmo di invio dei pacchetti, ovvero la dimensione della finestra SW, fino a che non si nota la perdita di almeno un pacchetto tra quelli inviati.\nComportamento a perdita di pacchetti\nSe i pacchetti vanno perduti, TCP assume anche che la causa di ci√≤ sia la presenza di un router intermedio congestionato, e quindi rallenta il ritmo di invio dei pacchetti per dare modo al router congestionato di smaltire i pacchetti accumulati. Tale meccanismo, sommariamente descritto, √® il meccanismo di controllo della congestione di rete di TCP.\nMultiplexing e Demultiplexing e porte Questi termini non hanno una traduzione diretta con l\u0026rsquo;italiano, la cosa pi√π simile possibile √® aggregare e disaggregare, perch√© da una unica scheda direte arriva tutto, questa cosa deve essere demultiplexata alla porta corretta, e multiplexata all\u0026rsquo;unica scheda di rete che si ha.\nLe well known ports sono di solito minori di 1023.\nLe porte alte sono decise da noi, basta che nell ostess ocomputer non ci sia un conflitto di porte.\nMultiplexing perch√© ho molte porte, ma unica scheda di rete, quindi far girare da una unica source tutto il resto. (per il mandante serve0\nDemultiplexing perch√© cos√¨ posso mandare alla porta corretta, ricevendo\nSlide multiplexing\nIn pratica il server con una singola porta non sarebbe in grado di rispondere a connessioni multiple! Ricorda che socket √® end-to-end, non saprei a quale client starei parlando.\nSi parla quindi di welcoming socket per il server, e quando si stabilisce la connessione ti dice in quale porta andare sopra per continuare a comunicare.\nEsempio di demux server\nApplicazione Introduzione livello applicazione (non fo) Il livello applicazione dei protocolli di Internet contiene l‚Äôimplementazione delle funzioni e dei servizi che permettono alle applicazioni di rete in esecuzione sull‚Äôhost di spedire e ricevere i dati. I protocolli sottostanti di Presentazione e Sessione, previsti dallo Standard ISO/OSI, non sono quasi mai considerati nell‚Äôarchitettura dei protocolli di Internet.\nIl livello Applicazione si appoggia direttamente sul livello trasporto e, in particolare, molte applicazioni che richiedono servizi connection-oriented si basano sul protocollo TCP, attraverso numeri di porta che nel tempo sono diventati standard ‚Äúde facto‚Äù. Ad esempio, la spedizione e il trasferimento dei messaggi di posta elettronica, basati sul protocollo di livello applicazione Simple Mail Transfer Protocol (SMTP) √® comunemente associata alla porta di livello applicazione 25. La porta 80 √® destinata al protocollo di trasferimento di ipertesti HyperText Transfer Protocol (HTTP) alla base del trasferimento delle pagine di siti del World Wide Web.\nAltri esempi di protocolli e servizi che si collocano al livello applicazione sono il protocollo e servizio di Domain Name Service (DNS) e i protocolli IMAP e POP3 per la consegna della posta elettronica. Una dettagliata illustrazione sul mondo dei servizi e protocolli applicativi di Internet sar√† oggetto di un modulo apposito\nHTTP1 (non fare) All\u0026rsquo;inizio bisognava aprire connessione per ogni singolo file che bisognava richiedere, quindi molto lento, ora sappiamo riuscire a creare socket di connessione che non si chiudono subito\nMolto bene √® descritto in HTTP e REST\nDomain Name System \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Livello applicazione e socket/Untitled 9.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Livello applicazione e socket/Untitled 9\u0026quot;\u0026gt; Immagine di spiegazione\nVorremmo avere un metodo molto semplice per umani per poter trovare un sito, ma il livello di rete non li sa gestire, ha bisogno di IP, allora ho bisogno di alcuni server dedicati che mi restituiscono l\u0026rsquo;IP dato un nome di dominio! Questo √® unico, altrimenti ci sarebbe ambiguit√† riguardo al nome. E altra cosa, ci sono i server DNS che sappiano dare l‚ÄôIP corretto a seguito del DNS.\nProblema\nGli utenti di Internet preferiscono usare nomi mnemonici per identificare le risorse in rete, ad esempio nomi di host appartenenti a una certa rete, oppure indirizzi di e-mail di utenti di una certa rete. Anche le reti, risultano spesso facilmente identificabili attraverso i nomi di dominio della rete. I nomi di dominio hanno quindi lo stesso senso degli indirizzi IP, e infatti vengono assegnati da enti internazionali, come gli indirizzi IP, per evitare confusione e nomi duplicati. Le risorse appartenenti a un dominio possono avere nomi scelti arbitrariamente (ad esempio nomi di host, indirizzi di e-mail) purch√® non siano duplicati all‚Äôinterno del dominio stesso. Nomi di risorse duplicati sono ammessi in domini diversi, (ad esempio, pippo@topolinia.it e pippo@paperopoli.com). I nomi di dominio hanno una struttura gerarchica del tipo (nomerisorsa.sottodominio.sottodominio.dominioradice). Ad esempio www.informatica.unibo.it √® il nome dell‚Äôhost che agisce da web server per il sottodominio informatica, del sottodominio Universit√† di Bologna, del sottodominio di livello massimo .it (Italia). In realt√† il dominio radice del mondo, che esiste implicitamente, non si scrive mai. Tutto ci√≤ √® comodo ma viola le esigenze del livello rete e dei router che pretendono solo indirizzi IP.\nDNS per risolvere il problema\nPer risolvere il problema, √® nato il servizio Domain Name System (DNS) che attraverso una gerarchia di server e un protocollo standard per le richieste permette di risolvere l‚Äôassociazione tra nome della risorsa e indirizzo IP. Ogni host in rete deve conoscere un server DNS al quale inviare le richieste e ogni server DNS deve conoscere almeno un server DNS di livello superiore. I server di livello superiore conoscono un numero sempre maggiore di nomi e relativi indirizzi IP, ma sono sempre meno per motivi di costo.\nL‚Äôesempio mostra come viene soddisfatta una richiesta DNS a seconda del punto della rete di server DNS dalla quale parte. Se un server DNS non conosce la risposta passa la richiesta al livello superiore, finch√© qualcuno non conosce l‚Äôindirizzo IP.\nNote sull\u0026rsquo;affidabilit√†\n√à una cosa molto brutta tenere un singolo server che possieda questo server DNS, perch√© se fallisce nessuno pu√≤ pi√π raggiungerlo!. Quindi vogliamo andare a creare una alta ridondanza riguardo questo server DNS.\nReplicare servizi anche in zone differenti (ne basta una su e il servizio apparentemente √® su, ecco il sistema distribuito!). Iterativo/ricorsivo (!)\niterativo il DNS ti risponde col nuovo dns server da contattare per poter avere una risposta\nRicoversivo quando il DNS stesso va a chiedere, e quindi quando ti risponde ti da gi√† il risultato corretto.\nQuindi in un caso si pone molto pi√π onere sul client che ha richiesto, nel secondo caso si pone onere sul server DNS. Quindi a seconda di quanto hai bisogno puoi fare l‚Äôuno o l‚Äôaltro direi.\nTyposquatting attack Questo √® un attacco sui DNS. Sappiamo che questo servizi risolvono testo in IPs che poi vengono utilizzati per mandare le richieste sulla rete. Per√≤ questo approccio √® attaccabile da domini che hanno codifiche diverse, ma carattere uguale all\u0026rsquo;utilizzatore. In questo modo un utente pu√≤ essere ingannato a cliccare su quell\u0026rsquo;url, anche se il domain name originale √® diverso perch√© invece di A scrive –ê, per esempio hex-dump di A –ê √® 41 20 d0 90 a vediamo chiaramente che la seconda A in cirillico √® rappresentato da tre bytes, anche se sembrano esattamente essere uguali. Questo pu√≤ essere utilizzato e attaccato.\nSulla connessione Riassumento, per poterci connettere sulla rete abbiamo bisogno di queste informazioni e stack di rete qui:\nStack TCP/IP firewall (IP, default router, maschera di rete) DNS DHCP Architetture a livello applicazione Client/server Peer To peer Le applicazioni e i servizi su Internet possono essere realizzati secondo almeno due modalit√† architetturali distinte: Architettura Client/Server e architettura Peer to Peer (P2P).\nClient/Server, i Client sono host che spediscono richieste di servizio ai Server. I Server sono i soli host sui quali sono in esecuzione i servizi che permettono di soddisfare le richieste. Un esempio di servizi di tipo Client/Server sono: il servizio DNS, dove ogni host pu√≤ agire da client spedendo richieste degli indirizzi IP ai DNS server, oppure il servizio World Wide Web, e il servizio di posta elettronica, entrambi basati su client che chiedono pagine web o spediscono e-mail, e server che mantengono le informazioni o memorizzano le e-mail spedite.\nPeer to Peer (P2P), invece, tutti gli host sono contemporaneamente sia client che server. Ogni host agisce da Server cercando di soddisfare, se possibile, le richieste ricevute da altri host. Ogni host agisce da Client quando spedisce ad altri host le sue richieste, o per conto personale, o per cercare di soddisfare richieste di terzi. Un esempio di servizi P2P sono: i servizi di condivisione dati (file-sharing) basati su protocolli Freenet, Gnutella, Kazaa. Esistono anche servizi ibridi, nei quali esistono server che aiutano solo a trovare pi√π rapidamente gli host P2P migliori per comunicare e implementare servizi P2P (esempio: file-sharing con Napster).\n","permalink":"https://flecart.github.io/notes/livello-applicazione-e-socket/","summary":"\u003ch1 id=\"livello-trasporto\"\u003eLivello trasporto\u003c/h1\u003e\n\u003ch2 id=\"protocolli-classici\"\u003eProtocolli classici\u003c/h2\u003e\n\u003ch3 id=\"introduzione-a-tcp-e-upd\"\u003eIntroduzione a TCP e UPD\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Livello applicazione e socket/Untitled.png\" alt=\"image/universita/ex-notion/Livello applicazione e socket/Untitled\"\u003e\n\u003cp\u003eIl quarto livello dei protocolli dell‚Äôarchitettura di Internet √® il livello trasporto (transport), ed √® basato su due protocolli in particolare: il Transmission Control Protocol (\u003cstrong\u003eTCP\u003c/strong\u003e) e lo User Data Protocol (\u003cstrong\u003eUDP\u003c/strong\u003e), che possono essere usati in alternativa tra loro.\u003c/p\u003e\n\u003cp\u003eQuesto √® nel genere di *\u003cem\u003econnession oriented\u003c/em\u003e e non, il primo, TCP √® connection oriented, l\u0026rsquo;altro no, questa √® l‚Äôunica differenza fra i due. Questa differenza √® spiegata in maggior dettaglio qui \u003ca href=\"/notes/0.3.8-servizi-orientati-alla-connessione--e-non-%F0%9F%9F%A8\u0026#43;\"\u003e0.3.8 Servizi orientati alla connessione  e non üü®+\u003c/a\u003e\u003c/p\u003e","title":"Livello applicazione e socket"},{"content":"Reti di Reti Le parti importanti per questo sono Data Plane e Control Plane (che ha saltato quasi tutto, ma almeno dijkstra lo dovresti fare bene)\nIntroduzione (puoi skippare üü©) La puoi skipppare perch√© tratta in modo molto generare parti che saranno trattati in modo pi√π approfondito in seguito. La parte importante forse √® il riassunto di cosa faccia questo livello.\nDiscussione rete locale globale Slide\nNo, non √® possible creare una connessione globale utilizzando le tecnologie locali, come hub, switch e simili, perch√© causerebbe flooding e impedirebbe scalabilit√† e crescita dinamica che √® classica della rete\nSe i milioni di calcolatori oggi connessi a Internet fossero tutti organizzati secondo i protocolli e gli schemi visti finora per le reti locali, la comunicazione tra due calcolatori su Internet richiederebbe di passare per migliaia di calcolatori intermedi, switch, bridge, segmenti di rete, ognuno dei quali aggiungerebbe ritardi di gestione, complessit√†, rischi di errore. Il problema dell‚Äôinstradamento dei frame (routing), ovvero il decidere da che parte o su che segmento deve essere inoltrato un frame per raggiungere il destinatario finale, richiederebbe in ogni dispositivo una lista completa (tabella di instradamento) di tutti gli indirizzi MAC dei dispositivi nel mondo, con a fianco l‚Äôindicazione della direzione di inoltro. Ovviamente questo limiterebbe in modo critico la scalabilit√† e la crescita di Internet. Inoltre causerebbe flooding perch√© praticamente ogni pacchetto di ogni computer rete di internet dovrebbe passare da ogni computer.\nUna soluzione semplice consiste nell‚Äôelezione di un rappresentante per ogni rete locale X (e indichiamo con la rete sotto di essa come dominio di rete locale) (il router di X), incaricato di ricevere tutti i pacchetti dati destinati a uno dei calcolatori della rete locale (es. mac1 di X, mac2 di X, ecc.). Ricevuti i pacchetti destinati alla rete locale, il router potrebbe occuparsi di recapitare alla rete locale i pacchetti, come se si trattasse di un frame a livello MAC/LLC destinato all‚Äôindirizzo MAC del destinatario. Allo stesso modo, ogni router dovrebbe farsi carico di inoltrare tutti i pacchetti uscenti dalla propria rete locale, verso i router delle reti di destinazione. Per rispettare le direttive dettate dallo standard ISO/OSI, il livello di indirizzamento e la gestione dell‚Äôinstradamento dei pacchetti tra i router vengono gestiti al terzo livello (rete) della gerarchia dei protocolli di Internet.\nPer ci√≤ che riguarda i router, tuttavia, lo scambio diretto tra router di pacchetti destinati alle rispettive reti locali potrebbe ridurre molto la complessit√† dell‚Äôinstradamento. I router comunicano quindi attraverso collegamenti dati molto veloci, dette dorsali (backbone). Ogni router deve ricordare in una tabella di instradamento (forwarding table) solo quale sia il primo router intermedio per raggiungere ogni altro router. La visione del sistema al terzo livello (Rete) da parte dei router √® quindi simile alla visione che appare a destra nella figura. Si nota come tutti i dettagli delle reti locali siano di fatto nascosti dai router a questo livello.\nIl router deve avere una mappa fra gli indirizzi IP e i mac!\nObiettivi generali del livello (6) (!) üü•+ Sintassi\nStruttura gerarchica fra dominio e host (per facilitare l‚Äôinvio) Busta a livello arancione, terzo livello. Semantica\nFrammentazione dei dati Questa parte non √® pi√π esistente per gli IPv6, perch√© √® un overhead in pi√π che non si vuole dare ai router Si occupa solamente di inviare. Un motivo per cui succede √® l‚Äôefficienza, tenere in memoria questa cosa √® molto costosa. I router devono solamente tritare pacchetti! Forwarding dei pacchetti, inoltramento dei pacchetti O ricezione del pacchetto se √® giusto. Non si occupa di affidabilit√† del trasporto (di cui si occupa il livello mac e trasporto) Hardware (operazionale credo)\nDispositivi fisici di questo livello, come i router (quindi tabelle di instradamento e protocollo di instradamento e aggiornamento) Protocollo di rete Slide1\nSlide2\nIn questa parte iniziamo ad analizzare il concetto di rete globale, ossia non √® pi√π locale!\nIl livello rete di Internet si basa sul protocollo IP (Internet Protocol). Il protocollo IP definisce un nuovo schema di indirizzamento globale e gerarchico, che permette di identificare univocamente tutti i dispositivi di rete e allo stesso tempo la loro rete locale di appartenenza. Gli indirizzi usati permettono di identificare intere reti locali come un riferimento singolo nella gestione dell‚Äôinstradamento dei pacchetti. Questo fatto semplifica molto la visione della rete che appare al livello Rete. Al protocollo IP, si possono associare protocolli di instradamento dei pacchetti dal mittente al destinatario finale (forwarding), originando servizi di trasmissione a pacchetto di tipo connectionless. Il protocollo IP richiede l‚Äôadozione di nuovi dispositivi amministratori dell‚Äôinoltro dei pacchetti a livello Rete, detti router.\nRouter I router sono forniti di tabelle di instradamento che illustrano la topologia della rete vista al livello dei router stessi (quindi non √® necessario conoscere gli indirizzi dei calcolatori di una LAN al di fuori della LAN stessa. I router devono implementare protocolli di aggiornamento delle tabelle di instradamento (detti protocolli di routing). Ulteriore compito dei router √® la gestione della frammentazione dei dati da spedire nei pacchetti, e la creazione della busta di livello rete con gli indirizzi del router mittente e destinatario di ogni pacchetto inoltrato.\nSono improntate alla efficienza! Principalmente √® solo hardware che √® in grado di far arrivare e partire un pacchetto a ogni ciclo di clock.\nNon self-similar üü© Si √® tentato di cercare di predire i dati futuri pensando a quanti dati ho ora. Ma si √® scoperto che non √® proprio possibile, perch√© ci sono dei burst di richieste, dipendenti dalle richieste delle singole applicazione, per questo motivo sembra che sia un sistema caotico (esempio della farfalla). Principalmente perch√© questo √® dipendente dai media (es. youtube).\nIndirizzo IP Gli indirizzi IP sono una nuova specie di indirizzi rispetto al MAC, necessari per il Protocollo omonimo;\nHeader IP üü®++ Slide del formato IP\nQuesto √® il bellissimo pacchetto di livello trasporto üôÇ. NOTA: vedi che contiene il pacchetto dello stato superiore.\nVersion sono 4 bit per la versione. Dimensione dell\u0026rsquo;header in byte (che il campo options lo rendere variabile). Il campo Type of Service, o TOS, definisce il valore di priorit√†, di cui abbiamo parlato Scheduling dei routers (3+) üü©. Che √® principalmente utilizzato in internet due (basta un router che non lo sia e fa droppare le garanzie). (solitamente √® ignorato). 16 bit per la lunghezza, quindi al massimo posso mandare 65k nel payload. L‚Äôidentificazion di 16 + cose bits √® per capire la targa, meglio per la frammentazione (quel sistema per spezzattare file lunghi e inviarli a pezzetti), sono ricomposti a destinazione, il router lo ignora üôÇ, l\u0026rsquo;ultimo ha flag a 0, e offset pi√π lungo Time to live √® una cosa che viene decrementata ad ogni router e viene dropatto il pacchetto se vado a 0 Upper layer √® il protocollo di livello 4 da utilizzare. Per verificare se non ci sono stati errori di trasmissione. (Che √® molto facile da manipolare, per√≤ buono per errori a caso di trasmissione). Alcune opzioni tipo la rotta da prendere (tipo i router da visitare), itmestamp, La cosa √® che questa parte √® variabile.\nC\u0026rsquo;√® un overhead di 40 bytes!.\nFrammentazione e Reassembly üü© Per questa parte concetti importanti da comprendere sono:\nPerch√© si fa frammetnazione (MTU) e perch√© si riassembla solamente alla fine. Campi dell‚Äôheader IP utili alla frammentazione e perch√© vengono utilizzati. Non ha molto senso fare reassembly in mezzo, perch√© il pacchetto potrebbe fare una altra strada, sono indipendenti una volta spediti.\npoi si potrebbero fare fragmentation anche in un router intermedio, si potrebbero fare fragmentation ancora dopo! Frammentazione √® necessaria se il pacchetto √® pi√π grande del MTU Maximum Transfer Unit.\nSlide esempio di fragmentazione\nStruttura IPv4 üü© Un indirizzo IPv4 √® un valore espresso su 32 bit (4 Byte), e pu√≤ essere espresso anche come sequenza di 4 valori decimali, separati da punto. Ogni valore decimale pu√≤ essere compreso tra i valori 0 e 255. Un esempio di indirizzo IP valido √® (130.136.250.1).\nOgni indirizzo IP √® sempre composto da due parti:\nnumero della rete IP alla quale appartiene la scheda (network number), numero dell‚Äôinterfaccia di rete (host number) all‚Äôinterno della rete IP. Esistono dei numeri speciali per ogni rete:\nHost tutti 0 e tutti 1\nTutti 0 ‚Üí indica la rete stessa Tutti 1 ‚Üí indica l‚Äôindirizzo di broadcast Datagramma IPv6 Slide IPv6\nIL nextheader dice il protocollo che sta sopra, stesso di upper level di sopra\nIl campo priority √® siile al Type of service, ci da la priorit√† del flusso di dati Flow label identifica il flusso di dati (infatti non c‚Äô√® la frammentazione), anche se non √® ben definito il concetto di flusso. Hop limit √® la stessa cosa del time to live. Flow label (questo √® molto importante!, se il flusso identifica una comunicazione, non ho bisogno di indirizzi sorgente, finale, porta etc., per questo motivo posso compattare le informazioni!) Struttura delle reti Univocit√† e statico/dinamico üü© Slide\nEsempio slide\nAttualmente usati si riferiscono al protocollo IP versione 4, (IPv4). Un indirizzo IP viene associato a una e una sola (univoca) interfaccia di rete (scheda di rete). Potrebbe essere contemporaneamente identificato da pi√π di un indirizzo IP nel caso in cui ci siano pi√π interfaccie di rete (e pi√π MAC). Se l‚Äôassociazione univoca tra indirizzo MAC dell‚Äôinterfaccia di rete e l‚Äôindirizzo IP rimane sempre lo stesso, allora si parla di IP statico. In caso contrario, se pu√≤ cambiare l‚Äôassociazione MAC-IP a seconda di vari fattori, si parla di IP dinamico. (cambio da dove mi connetto!).\nQuando √® statico √® utile quando stiamo ad offrire dei servizi, cos√¨ non devo fare aggiornamenti, i computer sanno che strada devono fare per raggiungere un certo computer.\nClassi di rete üü© Sono definite tre classi di reti IP, che si differenziano sulla base del numero massimo di host supportabili. Il valore dell‚Äôindirizzo IP determina la classe della rete: A,B,C (vedere figura).\nLe reti di classe A sono al massimo 126 e ognuna pu√≤ contenere fino a oltre 16 milioni di host. Per le reti di classe A, il byte di indirizzo pi√π significativo (a sinistra) ha sempre il primo bit uguale a zero, e pu√≤ assumere i valori da 1 a 126 (network number) rispetto ai 128 valori possibili. I tre byte rimanenti possono assumere oltre 16 milioni di combinazioni, ognuna associabile a un host della rete. 0XXXXXXX.xxxxxxxx.xxxxxxxx.xxxxxxxx\nUna nota particolare √® l\u0026rsquo;indirizzo 127 che √® un indirizzo di loopback perch√© fa finta di uscire, e poi all‚Äôultimo rientra. Questo indirizzo √® utile per testare protocolli di rete.\nLe reti di classe B sono al massimo 16.382 e ognuna pu√≤ contenere fino a oltre 64.000 host. Per le reti di classe B, il network number √® dato dai due byte di indirizzo pi√π significativi (a sinistra), che hanno sempre i primi due bit uguali alla coppia (uno,zero). I network number di classe B possono assumere i valori da 128.0. a 191.255. I due byte rimanenti (host number) possono assumere oltre 64.000 combinazioni, ognuna associabile a un host della rete.\nforma di 10XXXXXX.XXXXXXXX.xxxxxxxx.xxxxxxxx\nLe reti di classe C sono oltre 2 milioni, e ognuna pu√≤ contenere fino a 254 host. Per le reti di classe C, i tre byte di indirizzo pi√π significativi (a sinistra) rappresentano il network number, e hanno sempre i primi tre bit uguali alla terna (uno,uno,zero). I network number di classe C possono assumere i valori da 192.0.0 a 223.255.255. Il byte rimanente (host number) pu√≤ assumere 254 combinazioni utili, su 256 possibili, ognuna associabile a un host della rete.\n110XXXXX.XXXXXXXX.XXXXXXXX.xxxxxxxx\nConvenzione l‚Äôultimo IP disponibile per l‚ÄôHost di solito √® dato al Router.\nSottoreti e netmask !!! (3) üü© Slide\nLa figura mostra a sinistra uno schema gerarchico di strutturazione di una rete di classe B. A partire dall‚Äôalto troviamo il router principale (default router) della rete 130.136, il cui indirizzo IP √® nell‚Äôesempio 130.136.0.254. Alla rete 130.136 appartengono anche tre router subordinati, con IP 130.136.1.254, 130.136.2.254, 130.136.3.254 rispettivamente amministratori delle sottoreti (130.136.1.), (130.136.2.) e (130.136.3.).\nNetmask\nIl Netmask identifica nelle zone in cui √® settato 1 l\u0026rsquo;indirizzo di rete e sottorete, dove √® 0 l‚Äôindirizzo di host. Quindi ci dice √¨l modo con cui si interpreta un byte di rete. Obbligatoriamente deve essere in questa forma ($1^n0^m: n + m = 32$ se vogliamo utilizzare una sintassi pi√π famigliare da Linguaggi di programmazione).\nIl concetto di creare sottoreti si pu√≤ riassumere in frazionare l‚Äôhost in altre due parti che rappresentano l‚Äôindirizzo di sottorete e l‚Äôhost. Queste sono nuove componenti logiche.\nFacendo questa operazione abbiamo $nreti \\times(nhost - 1)$, mentre prima era $nhostgrosso$. Alla fine se si svolge questo calcolo sono stesso numero di host, (magari perdo nreti numero di host per i router, per√≤ la ho gerarchizzata meglio).\nEsiste una notazione molto pi√π carina per i netmask che √® il CIDR (Classless Interdomain ROuting) in pratica stai dicendo quanti bit sono messi a 1\nCreazione sottoreti\nIn questo modo √® possibile creare una gerarchia di sottoreti, ognuna delle quali √® amministrata da un router (il default router). Esempio: data la rete di classe B 130.136. per semplicit√† decidiamo di considerare possibili 256 sottoreti: netmask 255.255.255.0.\nIl numero della sottorete √® quindi fornito dai primi tre byte dell‚Äôindirizzo IP, es. 130.136.1. √® la sottorete 1, 130.136.2. √® la sottorete 2, mentre ad esempio 130.136.1.22 √® l‚Äôhost 22 della sottorete 1, 130.136.3.48 √® l‚Äôhost 48 della sottorete 3, e cos√¨ via. (quindi un router sottorete ora prende IP del genere 130.136.1.254, perch√© indica la sottorete 1 della rete di classe B che si possiede).\nPer istruire ogni router subordinato sulla dimensione e sull‚Äôinterpretazione degli indirizzi IP da amministrare, ogni router subordinato deve essere fornito di una maschera di rete (netmask), evidenziata a destra.\nElementi fondamentali per il Protocollo IP\nSenza questi tre elementi il protocollo IP non funziona proprio. Quindi √® la prima cosa da fare per configurarlo.\nMaschera di rete Indirizzo IP Indirizzo default di router (il primo router sopra la gerarchia, che √® a chi mandare quando non so a chi mandare). (pu√≤ essere che con dispositivi stupidi abbiamo solamente l‚Äôindirizzo del router). La maschera di rete serve per capire\nNetmask\nIn particolare rileviamo qui 2 funzionalit√† principali per questo netmask:\nDire quanti subnet esistono, oltre alla rete principale Far sapere all‚Äôhost a quale rete appartiene √à quindi una quantit√† fondamentale per configurare la regte\nClassless Inter Domain Routing üü© Questo nuovo modo per fare netmask (nuovo rispetto gli anni 80) √® un modo per avere tagli di rete pi√π efficienti, nel senso che se prima la C non bastava, ti davano una B( Renzone a unibo ha avuto in questo modo una classe B). Ora possono avere molta pi√π disponibilit√† per i tagli negli indirizzi di rete. Questa cosa permette anche un concetto di supernetting. (in cui ho un insieme condiguo di classi pi√π piccole, e cos√¨ mi creo una rete maggiore, pi√π grosso delle classi, cos√¨ ho maggiore dinamicit√†).\nEsempio forwarding dei Pacchetti\nSlide\nSlide esempio\nLa figura mostra un esempio di instradamento su rete IP. Esistono tre router Ry, Rz e Rk rispettivamente amministratori delle reti (140.217.), (190.89.), e (130.136.). Il router Ry √® connesso a Rz, e Rz √® connesso a Rk. Tale informazione risulta dalle tabelle di instradamento di Ry, Rz, Rk. La rete del router Ry include due sottoreti (140.217.1.) e (140.217.2), amministrate dai rispettivi default router 140.217.1.254 e 140.217.2.254 . La rete del router Rk include tre sottoreti (130.136.1.), (130.136.2.) e (130.136.3.), amministrate dai rispettivi default router 130.136.1.254, 130.136.2.254 e 130.136.3.254 . Un pacchetto IP spedito dall‚Äôhost 140.217.2.10 all‚Äôhost 130.136.2.33 deve compiere il seguente tragitto: passa per il default router di sottorete 140.217.2.254 che, notando che il destinatario non appartiene alla sottorete, lo inoltra al default router del livello superiore di rete: 140.217.0.254. Il default router di rete controlla la propria tabella di forwarding e scopre che per raggiungere la destinazione il pacchetto deve essere inoltrato al router intermedio 190.89.0.254. Il router intermedio riceve il pacchetto, verifica la propria tabella di forwarding, scopre che il prossimo destinatario intermedio √® il router 130.136.0.254, al quale inoltra il pacchetto. Il router 130.136.2.254 riceve il pacchetto e verifica che appartiene alla propria rete, inoltrando quindi il pacchetto internamente. Il router di sottorete 130.136.2.254 riceve il pacchetto e scopre che appartiene alla propria sottorete, inoltrando il pacchetto internamente. Finalmente, l‚Äôhost 130.136.2.33 riceve il pacchetto a lui destinato. Si possono notare alcuni aspetti importanti: malgrado il numero elevato di host che potrebbero essere parte del sistema considerato, il processo di instradamento permane molto semplice, composto da piccole e semplici operazioni di base. Le tabelle di instradamento sono limitate agli elementi che agiscono allo stesso livello, e quindi l**‚Äôinstradamento √® gerarchico**.\nRouting üü® Si parler√† molto meglio del routing in Data Plane e Control Plane\nSlide\nIl problema del routing pu√≤ essere definito come il problema di mantenere l‚Äôaggiornamento delle tabelle di forwarding in tutti i router della rete. Questo problema pu√≤ essere a volte molto complesso, a causa di frequenti modifiche forzate dei cammini per i pacchetti in rete. Le cause di tali modifiche possono essere dovute a molti fattori, ad esempio: la mobilit√† degli host in reti senza fili, guasti di mezzi trasmissivi, interruzione delle linee, guasti di router, nuove politiche e accordi per lo scambio dei dati tra gestori di dorsali e sistemi autonomi.\nUn sistema autonomo (AS) √® sinonimo di una grossa rete, o una collezione di reti, soggetta a una comune politica di amministrazione. Gli accordi commerciali tra gestori di AS possono modificare i cammini consentiti per lo scambio dei pacchetti di dati. Per realizzare un parallelo intuitivo, gli AS si comportano come nazioni che permettano o meno il passaggio di pacchetti, analoghi a voli aerei, sul loro suolo nazionale. Ogni volta che si verifica uno dei problemi citati, esistono router che hanno indicazioni errate nelle loro tabelle di forwarding. Tutto ci√≤ pu√≤ causare la perdita di pacchetti, oppure pu√≤ determinare un disordine nell‚Äôarrivo di pacchetti che hanno seguito strade diverse. Ecco quindi una causa del servizio connectionless ottenuto dal livello rete basato solo sul protocollo IP. I router hanno bisogno di aggiornare al pi√π presto le loro tabelle, per evitare malfunzionamenti del servizio.\nIn pratica fanno lo stesso modo per decidere dove mandare, cio√® hanno lo stesso protocollo, ma dato che si trovano in parti diverse avranno poi tabelle di instradamento diverse.\nla Core network √® molto veloce nel trovare il percorso giusto (√® molto pi√π fisso, e sa pi√π o meno dove mandare le cose).\nI protocolli di routing hanno la funzione di richiedere e scambiare informazioni per trovare cammini alternativi (idealmente il cammino migliore tra le possibili alternative), tra mittenti e destinatari dei pacchetti, e consentire quindi l‚Äôaggiornamento delle tabelle di forwarding. A puro titolo informativo, si citano alcune sigle di protocolli di routing adottati in Internet: Routing Information Protocol (RIP), Open Shortest Path First (OSPF), Border Gateway protocol (BGP). Questi algoritmi sono tutti utilizzati in locale. La cosa brutta √® che il cammino ottimo cambia nel tempo (anche nell‚Äôordine dei secondi), quindi gli algoritmi si devono abituare dinamicamente a questi nuovi dati.\nNote sistemi distribuiti o centralizzati\nIl centralizzato √® bello perch√© √® chiaro a chi chiedere per andare poi a mandare il pacchetto dove si vuole, il problema √® che se il nodo centrale fallisce, cade l\u0026rsquo;intera rete.\nDistribuito √® bello perch√© risolve il problema del single point of failure per√≤ dall‚Äôaltra parte ogni nodo non ha una visione globale quindi non pu√≤ fare altro che andare a massimizzare localmente, che spesso non √® la cosa migliore.\nWikipedia sui sistemi autonomi\nLink, in pratica singola autorit√† amministrativa √® la parola chiave.\nProtocolli basati su IP Protocollo ICMP (6) üü®+ Slide\nICMP (Internet Control Message Protocol) √® un protocollo standard definito per supportare i messaggi di controllo per la gestione della rete al livello 3. ICMP viene usato da semplici host, da router e persino da gateway (router speciali con ulteriori funzioni) per scambiare informazioni utili alla gestione del livello Rete. Le informazioni scambiate sono trasferite sotto forma di pacchetti IP. Utile per stabilire una sintomatologia dei problemi di reti.\nAlcuni esempi di messaggi ICMP che possono essere scambiati indicano, ad esempio:\nsituazioni di rete di destinazione irraggiungibile (possibile sintomo di problemi di routing, o di rottura di un router). In questo caso pu√≤ convenire andare a cercare il problema di rete, che pu√≤ essere fisico, e fixarlo in questo modo rete di destinazione sconosciuta (possibile sintomo di indirizzo IP di rete male specificato) In questo caso il router non sa a chi mandare, quindi alcuni fix sono 1. aggiornare tabelle di instradamento, o provare altre strade. Ossia nessuno conosce l‚Äôindirizzo della rete locale host di destinazione non raggiungibile (possibile sintomo che l‚Äôhost sia spento o il cavo di connessione sia male collegato). Questo √® un problema che non ci riguarda, quindi probabile che l‚Äôhost si sia sconesso. Per questo significa che la rete √® conosciuta!, quindi problema di rete locale!. host di destinazione sconosciuto (possibile sintomo di host number del‚Äôindirizzo IP male specificato, malgrado la rete indicata esista e sia raggiungibile). problemi con indirizzo IP protocollo richiesto non disponibile (sintomo di un tentativo di dialogo tra dispositivi male configurati, che non forniscono i servizi richiesti). (come se stessi provando ad accedere a un servizio in una porta sbagliata, o versione IP sbagliata o simili). ricerca di cammino alternativo (pu√≤ essere usato per risolvere i problemi di routing). Anche chi riceve il messaggio, pu√≤ rispondere in modo preinpostato a quelle richieste. (e dato che √® preimpostato non c\u0026rsquo;√® bisogno di avere un frame grosso!).\nApplicazioni su ICMP (2) üü© Slide\nLe applicazioni sono utilizzate solitamente per la verifica delle cause o del semplice sospetto di problemi di rete. L‚Äôapplicazione PING permette di testare la connessione tra due host: eseguendo il comando ‚Äúping \u0026lt;indirizzo IP di host2‚Äù da un host1 qualsiasi (mittente) connesso in rete, l‚Äôapplicazione invia una richiesta ICMP di eco, alla quale l‚Äôhost2 indicato risponde con una risposta ICMP (eco della richiesta). Dopo l‚Äôinvio della richiesta, host1 fa partire un timer. In caso di successo, viene calcolato il tempo di andata e ritorno dei pacchetti (durata o Round Trip Time, RTT), mentre in caso di insuccesso viene indicato che il timer per la richiesta inviata √® scaduto senza ottenere risposta (secondo esempio della prima figura). Al termine dei tentativi, viene mostrato un elenco di statistiche sul numero di richieste andate a buon fine e i tempi medi stimati di andata e ritorno dei pacchetti.\nL‚Äôapplicazione Traceroute (tracert) permette di verificare la lista di tutti i router attraversati da una richiesta ICMP inviata da host1 a host2. Il comando ‚Äútracert ‚Äù eseguito da host1, causa l‚Äôinvio di una sequenza di richieste ICMP verso host2, per le quali viene fissato il numero massimo di router da attraversare (numero di passaggi o tempo di vita, TTL), a valori crescenti da 1 in poi. Ogni router a distanza TTL risponde con un messaggio ICMP di errore (tempo di vita scaduto) attraverso il quale √® possibile risalire al suo indirizzo IP (ognuno mostrato su righe successive).\nProtocollo ARP e RARP üü© Slide\nSlide immagine\nIl protocollo Address Resolution Protocol (ARP) aiuta a gestire l‚Äôassociazione tra indirizzo IP di un dispositivo a livello rete e il suo indirizzo MAC a livello MAC/LLC . Quando un router riceve un pacchetto a livello IP destinato alla sua sottorete (es. 130.136.2.33) esso verifica se a tale IP risulti o meno associato un indirizzo MAC. In caso contrario, il router spedisce sui segmenti della rete locale un frame in broadcast (cio√® ricevuto da tutti i dispositivi) contenente il codice di richiesta ARP, e l‚Äôindirizzo IP del destinatario del pacchetto. Tutti i riceventi vanno a confrontare, e se matcha risponde.\nIntuiviamente\nTale frame equivale quindi al rivolgere a tutti i dispositivi la domanda: ‚Äúquale indirizzo MAC ha il dispositivo corrispondente al seguente indirizzo IP‚Äù? Il dispositivo in questione, se esiste, risponde con un frame indirizzato all‚Äôindirizzo MAC del router, contenente il codice di risposta ARP, e con allegato l‚Äôindirizzo MAC richiesto. A questo punto il router pu√≤ quindi preparare e spedire la busta di livello MAC/LLC, indirizzata al MAC del dispositivo destinatario del pacchetto IP, contenente il pacchetto IP incapsulato all‚Äôinterno. Il destinatario riceve il frame e risponde con il frame di conferma per il sottolivello LLC.\nQuando √® risposto possiamo andare a mappare l‚ÄôIP con il MAC locale. Chi ha il MAC corrispondente pu√≤ rispondere col proprio IP.\nEsiste anche una versione analoga del protocollo ARP, detta Reverse-ARP, che risponde alla domanda: ‚Äúquale indirizzo IP corrisponde al dispositivo con questo indirizzo MAC‚Äù?. Pu√≤ essere utile ad esempio se mi arriva un pacchetto a un IP nella mia sottorete, ma non so a quale host √® destinato.\nProtocolo DHCP üü©- Slide\nSlide di immagine\nQuesto protocollo √® utilizzato per assegnare un IP in modo dinamico. porta 67, unico all\u0026rsquo;interno della rete, chi non ha un servizio l√¨ aperto droppa il messaggio.\nIntroduzione: assegnazione IP\nI numeri di rete delle classi A, B e C, ovvero la parte sinistra degli indirizzi IP vengono assegnati da enti internazionali quali RIPE, ICANN, ARIN, APNIC a enti, aziende, consorzi e imprese che ne fanno richiesta motivata. Un problema molto pi√π pratico riguarda il modo in cui un nuovo dispositivo che venga connesso a una rete esistente, veda associare al proprio indirizzo MAC un indirizzo IP della rete stessa. Il numero di rete o di sottorete viene automaticamente determinato dall‚Äôappartenenza alla rete, ovvero alla presenza al di sotto del dominio di gestione di un router.\nSoluzioni La prima, ovvia alternativa (molto usata) √® quella di avere un amministratore di rete che assegna manualmente uno dei numeri di host disponibili al nuovo indirizzo MAC. In questo modo l‚Äôassociazione indirizzo MAC e indirizzo IP pu√≤ essere mantenuta per un tempo indeterminato, e quindi si considera l‚Äôindirizzo IP come statico.\nLa seconda alternativa, molto usata in reti senza fili, in reti locali e nei collegamenti domestici a Internet Service Provider (ISP) via Modem o ADSL consiste nell‚Äôutilizzare un server per Dynamic Host Configuration Protocol (DHCP). Il server DHCP √® dotato di una lista di numeri di host liberi per la sottorete amministrata, che provvede ad associare su richiesta agli indirizzi MAC dei dispositivi che lo richiedono. Tale associazione dipende spesso dalla disponibilit√† degli indirizzi gi√† assegnati in precedenza, quindi allo stesso indirizzo MAC possono essere associati di volta in volta indirizzi IP diversi, e si parla in questo caso di indirizzi IP dinamici. E‚Äô possibile configurare attraverso DHCP anche altri parametri di rete, come la maschera di rete, il defaul router e il server DNS (che vedremo dopo). Il servizio DHCP equivale spesso al concetto di rete ‚Äúplug and play‚Äù, ovvero rete in cui basta connettere il dispositivo al medium e non c‚Äô√® bisogno di nessuna configurazione manuale aggiuntiva. √à questo √® quasi un must per le reti wireless! Sarebbe improponibile che ci fosse un sistemista ad assegnare un indirizzo IP per ogni dispositivo che si connette!\nIn breve:\nHost che assegna IP a chi lo richiede Gestione degli IP liberi e associazione ai MAC Questa √® chiaramente una forma di indirizzamento dinamico discusso in Univocit√† e statico/dinamico üü© Ogni tot di tempo √® fatto un ping se la macchina risponde √® ancora l√¨, altrimenti libera l‚ÄôIP.\nMAGGIORE DETTAGLIO 4passi\nSlides\n√à importante avere 4 passi, perch√© l‚ÄôHOST deve rispondere con la scelta del DHCP, nel caso in una sottorete ci siano molto DHCP.\nma Non esiste nessuna autenticazione, quindi √® molto fragile ad attacchi (uno si potrebbe impersonare a DHCP senza problemi). I primi due passaggi sono facoltativi, ma lo rendono pi√π solido contro possibilit√† di avere 2 DHCP server.\nNOTA: comuqnue non √® un protocollo per dare IP a dispositivi mobili che si spostino.\nIPv6 e tunnelling üü© Slide\nhttps://www.notion.so\nImmagine\nNella figura viene mostrato come sia possibile spedire pacchetti IPv6 tra due router IPv6 passando per cammini che includono router IPv4, attraverso il tunnelling IPv6 in IPv4. Il pacchetto IPv6 viene incapsulato dai ogni router IPv4 in pacchetti IPv4, in modo da poter essere instradato lungo la rete di router IPv4. Uscito dal tunnel IPv4 il pacchetto IPv6 prosegue il suo inoltro fino alla destinazione IPv6 finale.\nIl motivo principale della necessit√† di IPv6 √® la necessit√† di altri indirizzi IP. IPv6 perch√© hanno tentato di fare un IPv5 in molti modi ma sono caduti in disuso.\nNon c\u0026rsquo;√® frammentazione, con IPv6, mentre IPv4 ha bisogno‚Ä¶ questo toglie il lavoro del router, e quindi rende tutto pi√π veloce.\nDal 1990 √® stato avviato un progetto di definizione e sviluppo di una nuova versione del protocollo IPv4, denominato versione IPv6. In seguito all‚Äôesplosione del collegamento di calcolatori in rete, e quindi dell‚Äôutilizzo di indirizzi e reti IP, le proiezioni mostrano che al ritmo attuale gli indirizzi IPv4 saranno esauriti nel decennio 2008-2018. Brevemente, le caratteristiche salienti di IPv6 vanno nella direzione di ovviare a questo problema, oltre a migliorare alcuni aspetti di IPv4. La caratteristica fondamentale di IPv6 √® la definizione di nuovi indirizzi IPv6 composti da 128 bit (16 byte), cio√® ben quattro volte la dimensione degli indirizzi IPv4. Questo incredibile numero di indirizzi potrebbe consentire di avere circa 15000 indirizzi IPv6 per dispositivi diversi su ogni metro quadrato di superficie dell‚Äôintero pianeta, oceani inclusi.\nSono inoltre stati ridefiniti i campi che costituiscono la busta dei pacchetti di livello IPv4, aggiungendo ad esempio parametri per la gestione di flussi di pacchetti IP con diversi livelli di priorit√†. Purtroppo la definizione di IPv6 nella maggioranza dei casi non permette di continuare a usare i vecchi router IPv4, e quindi non √® compatibile con l‚Äôattuale struttura di Internet.\nTunnelling\nIl tunnelling √® fondamentale per la compatibilit√† fra IPV4 e IPv6\nLa sperimentazione e lo sviluppo di IPv6 sta procedendo su reti IPv6 separate, che possono in certi casi integrarsi alle reti IPv4 usando la tecnica del tunnelling dei pacchetti IPv6 in IPv4. Quindi wrappo con un pacchetto IPv4 i router che capiscono solo IPv4.\nSi chiama tunnelling perch√© il wrap ci assomiglia tanto!\nNAT Cose vecchie Confronto col MAC L\u0026rsquo;indirizzo Internet Protocol √® il protocollo internet a livello 3 pi√π utile per la comunicazione fra reti locali diverse. Una delle caratteristiche che la contraddistingue dal MAC √® il fatto che sia gerarchico, ossia c\u0026rsquo;√® una sorta di indirizzo generale, indirizzo specifico e indirizzo della rete locale!. Oltre al fatto che √® gerarchico non √® univoco, perch√© pu√≤ succedere molto spesso che viene riassegnato.\nCaratteristiche IP (3) Globale perch√© non esiste rete connessa ad Internet che non abbia indirizzo IP; Strutturato perch√© √® diviso in due parti, una per l‚Äôindirizzo della rete locale e l‚Äôaltro per l‚Äôindirizzo della scheda di rete interna alla rete locale; Gerarchico perch√© appunto le due parti di indirizzo sono in ordine gerarchico (rete locale \u0026gt; scheda di rete). Indirizzamento IP Se succede che due IP sono uguali, questo succede solamente a rete locale perch√© anche la prima parte dell‚ÄôIP deve essere uguale, quindi se ne accorge il Router e risolve questo.\nStaticit√† e dinamicit√†\nStatico ‚Üí IP associato a MAC\nDinamico ‚Üí IP che cambia, quindi √® pi√π difficile\nClassi di rete Dividiamo l‚ÄôIP in 3 classi principali A, B, C a seconda di quanti IP riescono a supportare\nClasse A\nIl bit pi√π significativo √® 0. Quindi la prima sezione va da 1 a 126, perch√© 0 √® utilizzato per l‚Äôidentificazione. Sono quelle pi√π prezione perch√© possono avere pi√π host ($2^{24}$ host).\nClasse B\nHanno i primi due bit come valore 10. e vanno da 128 a 191,\nClasse C\nRouter I router ricevono pacchetti e guardano la parte di rete locale, se matcha √® OK, viene inoltrato ad altri router della rete locale per smistare ulteriormente, altrimenti inoltra ad altri router in altre reti, attraverso i collegamenti chiamati dorsali.\nTabelle e protocollo di instradamento Queste sono tabelle che hanno un utilizzo molto simile a quanto utilizzato per lo switch, che mappa una porta a un indirizzo MAC. In questo caso mappa la tolopogia di rete (che non so in che modo sia intesa questa mappa). Di solito il router √® collegato a un solo altro router che viene chiamato default gateway.\nIl protocollo, invece, si occupa di aggiornare questa tabella secondo le occorrenza (TODO, non so su quali regole).\nProtocollo di routing Questo protocollo che si occupa di trovare il percorso pi√π breve, e di frammentare il messaggio originale in pacchetti pi√π piccoli, ma senza fare controlli su un arrivo corretto di queste informazioni. Quind fa una scelta per capire che strada fare\nCIDR Classless Inter Domain Routing Si utilizza una scrittura molto compatta per\n","permalink":"https://flecart.github.io/notes/livello-di-rete/","summary":"\u003ch1 id=\"reti-di-reti\"\u003eReti di Reti\u003c/h1\u003e\n\u003cp\u003eLe parti importanti per questo sono \u003ca href=\"/notes/data-plane/\"\u003eData Plane\u003c/a\u003e e \u003ca href=\"/notes/control-plane/\"\u003eControl Plane\u003c/a\u003e (che ha saltato quasi tutto, ma almeno dijkstra lo dovresti fare bene)\u003c/p\u003e\n\u003ch2 id=\"introduzione-puoi-skippare-\"\u003eIntroduzione (puoi skippare üü©)\u003c/h2\u003e\n\u003cp\u003eLa puoi skipppare perch√© tratta in modo molto generare parti che saranno trattati in modo pi√π approfondito in seguito. La parte importante forse √® il riassunto di cosa faccia questo livello.\u003c/p\u003e\n\u003ch3 id=\"discussione-rete-locale-globale\"\u003eDiscussione rete locale globale\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Livello di Rete/Untitled.png\" alt=\"image/universita/ex-notion/Livello di Rete/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eNo, non √® possible creare una connessione globale utilizzando le tecnologie locali, come hub, switch e simili, perch√© causerebbe \u003cstrong\u003eflooding\u003c/strong\u003e e impedirebbe scalabilit√† e crescita dinamica che √® classica della rete\u003c/p\u003e","title":"Livello di Rete"},{"content":"Livello di trasporto Si parla di livello logico di trasporto, ma gran parte ne abbiamo gi√† parlato in Livello applicazione e socket di UDP, TCP e Socket. trasporto end-to-end, nel senso che livello traporto viene visto solamente ad inizio e alla fine, in tutti i nodi intermedi non √® visto sto pacchetto.\nUDP (3) üü©- Slide UDP\nClassico inizio e fine porta del socket. Lunghezza, si pu√≤ vedere che massimo √® 2 alla 16, e poi il checksum per vedere se √® comunicato bene. 8 byte di header, quindi molto efficiente! Sposto a livello applicazione il check al mancato pacchetto. (esempio DNS) Oppure casi in cui perdere pacchetti non √® molto importante. CARATTERISTICHE UDP\nNessun controllo del flow, senza handshake, e per questo motivo possiamo dire che non sia connection oriented (l\u0026rsquo;affidabilit√† della connessione pu√≤ essere spostata al livello superiore) Stateless Velocit√† di invio, 8 byte di overhead contro i 20 di TCP Per maggiori informazioni e confronto con TCP (il fatto di connectionless etc) guardare Intro TCP (3) e UPD üü©.\nTCP struttura pacchetto üü© In cui c\u0026rsquo;√® molto di pi√π.\nTCP segment structure\nLa nota importante oltre le flag, e altre cose √®\nAcknoledgement del pacchetto precedente √® messo nell‚Äôheader! Internet checksum üü© Slide internet checksum\nStile dell‚Äôalgoritmo:\nIncolonnati a 16 bit, faccio la somma di tutit i bit. Somma del riporto wraparound. Complemento a uno del risultato precedente Si ricordi che questo √® un metodo utile per capire se ci sono errori di trasmissione, ma non √® molto buono per difendersi da attacchi umani.\nCostruzione protocollo di trasporto reliable Vogliamo cercare di costruire un protocollo ground up, cio√® assumento piano piano, errore per errore e fixare ogni errore.\nAlla fine il protocollo cos√¨ creato sar√†\nAffidabilit√† del trasferimento di dati Vorremo creare l‚Äôequivalente di un canale di strasferimento affidabile, cosa che non √® internet, quindi vogliamo aggiungere altre cose per rendere questa interfaccia:\nSlide RDT (Reliable data transfer)\nPermetto di creare interfaccie come\nrdt_send() udt_send() unreliable data transfer, che √® quello offerto dalla rete. Stessa cosa per il lato di ricezione, ricevo da cosa unreliable, processo e li passo sopra.\nEsempi sono numerazione di pacchetti e resend di pacchetti chei non sono stati ricevuti, questi sono modi per rendere affidabili.\nPasso passo, 3 problemi Resistente alla corruzione dei pacchetti Corruzione dei pacchetti ACK Resistente alla perdita di pacchetti RETE RELIABLE\nSlide rete reliable\n√à la cosa pi√π stupida, si assume subito che sia reliable\nRETE CORRUTTIBILE\nSi utilizza un sistema ACK, NACK per vedere se arriva o meno il pacchetto\nSlide rete corruttibile\nSe dal lato ricevente, viene inviato il messaggio che √® arrivato sbagliato.\nCORRUZIONE DEI NAK e ACK\nChe succede con l‚Äôesempio sopra se si possono corrompere anche ACK e NACK? Facciamo ack e nack sui numeri pacchetto!\nSlide ack e nak\nSENZA NAK\nSlide senza nak\nBasta mandare l\u0026rsquo;ack al pacchetto corretto! Non abbiamo pi√π bisogno che si mandi nak quando arriva il pacchetto brutto.\nPERDITA DI PACCHETTI\nIn questo caso includiamoil timeout.\nSlide timing\nEsempio di rdt3 in azione\nANALISI DELLE PERFORMANCE\nSlide performance rdt3.0\nSi pu√≤ notare che l\u0026rsquo;utilizzo della rete √® pochissimo! 0.027 % di utilizzo in questa analisi.\nDovremo cercare di parallellizzare il processo utilizzato per mandare e riceve\nPipelining (2) üü©‚Äî √à un metodo per mandare pi√π pacchetti contemporaneamente.\nCi sono due metodologie principalemente, go back N, selective repeat.\nPipelined protocols\nGO BACK N\nSignifica che con gli ultimi n ack sono stati ricdevuti correttamente, quindi col singolo ack, mi dice da dove posso cominciare a ripartire a mandare. Ma manda un sacco di pacchetti, quindi pu√≤ congestionare la rete, con il vantaggio che non mi devo memorizzare.\nAutoma Go back N (NON FARE)\nEsempio di GBN\nil destinatario non deve memorizzare nel buffer i pacchetti che giungono fuori sequenza. (risparmio in memoria)\nMaggiore onere alla rete, che deve ritrasmettere alcuni pacchetti anche se vengono ricevuti correttamente.\nSELECTIVE REPEAT\nPerch√© ti faccio ripetere in modo selettivo.\nMeno lavoro dei router Overhead maggiore per i RTT per gli ACK, cosa che alla fine rallenta la prestazione della rete. Pi√π memoria per mantenere tempi per tutti i pacchetti. Approfondimento TCP TCP trip time Slides\nSi utilizza una tecnica di media esponenziale presente anche in Scheduler ma qui facciamo anche un safety margin per essere sicuri e molto conservativi parti a 4 deviazioni (quindi molto! affinch√© scada deve succedere veramente qualcosa di brutto).\nAck e numeri di sequenza (no) üü© Il libro dice che in fase di handshaking vengono stabiliti numeri di sequenza random, questo per evitare il fatto che lo 0 rappresenti una nuova sequenza, se in precedenza si √® gi√† connessi.\nPoi cosa, TCP utilizza un ack cumulativo, sul numero di byte, e il numero di sequenza √® sempre fatto sul numero di byte inviati e ricevuti.\nNOTA: grandezza della finestra pipelining e il numero di sequenza, si osservi che se abbiamo troppi pochi numeri di sequenza, allora potremmo conseguire nell‚Äôambiguit√† del fatto che un pacchetto non si pu√≤ distinguere se sia un pacchetto nuovo oppure una ripetizione di un vecchio pacchetto.\nla finestra deve avere ampiezza inferiore o uguale alla met√† dello spazio dei numeri di sequenza dei protocolli SR. per non incorrere ai problemi di ambiguit√†. ~libro\nIl resend (2) üü© TIMEOUT: √® molto speciale per il TCP, invece di calcolare il timeout con la formula con l‚Äôestimated time, con la media esponenziale e con 4 volte la deviazione standard, viene semplicemente raddoppiato il tempo, ogni volta che scade. Probabilmente si pensa che la rete sia congestionata, quindi si aspetta un p√≤.\nImportante notare che questo ack cumulativo non √® presente in selective repeat, quindi √® pi√π simile a GBN, per√≤ allo stesso tempo se scade il timeout, che √® messo solamente sul base (quindi il pacchetto pi√π vecchio che √® stato mandato, non su tutti a differenza di SR) non vado a rimandare\nFAST RESEND: Quando ricevo 3 acks con lo stesso numero di sequenza, assumo che √® stato perch√© il paccketto con il numero di base √® stato perso. Con questa assunzione provo a rimandare il pacchetto di base.\nControllo del flusso (no) üü© il mittente non vuole mandare cos√¨ tanti bytes da saturare il buffer del ricevente, per questo motivo il ricevente manda in un certo campo dell‚Äôheader anche l‚Äôampiezza del buffer che pu√≤ ancora ricevere, e solitamente il mittente cerca di stare all\u0026rsquo;interno di quel buffer, in modo che la richiesta possa sempre essre elaborata.\nSe il l\u0026rsquo;ampiezza √® 0 non voglio stopparmi! voglio sempre mandare almeno un singolo byte di dati, altrimenti rischierei una starvation, anche se il ricevente pu√≤ ricevere cose.\nControllo della Congestione (!) üü®++ Vengono define tre fasi per il controllo della congestione, le prime due pi√π importanti mentre l‚Äôultima √® facoltativa diciamo.\nSlow start Questa √® la fase che abbiamo gi√† studiato in precedenza, in pratica si parte con un MSS (maximum segment size) e si raddoppia fin quando continuano ad arrivare gli ACK (in pratica aggiungi 1MSS per ack). Quando perdo un pacchetto, o per il timeout o per il triplo ack, allora torno a 1 MSS, e mi setto un massimo numero di pacchetti (la met√† di quando √® successo la perdita) Congestion avoidance Sono in questa fase quando ho raggiunto il numero massimo di pacchetti inviati. Quando sono in questa fase allora aumento di 1/[pacchetti trasmessi] ad ogni ACK, in pratica cresco in modo lineare, molto pi√π lento, fino a quando non perdo di nuovo un pacchetto. Se lo perdo per timeout torno a 1 e sono a slow start, altrimenti alcuni pacchetti sono comunque giunti al destinatario, quindi reiverto in modo molto pi√π soft, in pratica dimezzo la mia window e vado in fast recovery. Fast recovery nella fast recovery aumento di 1 se l‚Äôack √® per il pacchetto che ho perso, quando arriva l‚Äôack per il segmento perso stesso rientro in quella fase, questo mi fa crescere linearmente e mi permette di partire molto pi√π in fretta. Esempio: se ero a 32 pacchetti, vi vengono 3 ack per pacchetto 1, dimezzo e assumo che il pacchetto 2 sia perso, e aumento di 3 (perch√© sono venuti 3 acks), sono a 19, mi arrivano altri ack di 1, aumento di 1, quando arriva il 2 entro in Congestion avoidance. ","permalink":"https://flecart.github.io/notes/livello-di-trasporto/","summary":"\u003ch1 id=\"livello-di-trasporto\"\u003eLivello di trasporto\u003c/h1\u003e\n\u003cp\u003eSi parla di \u003cstrong\u003elivello logico\u003c/strong\u003e di trasporto, ma gran parte ne abbiamo gi√† parlato in \u003ca href=\"/notes/livello-applicazione-e-socket/\"\u003eLivello applicazione e socket\u003c/a\u003e di UDP, TCP e Socket. \u003cstrong\u003etrasporto end-to-end\u003c/strong\u003e, nel senso che livello traporto viene visto solamente ad inizio e alla fine, in tutti i nodi intermedi non √® visto sto pacchetto.\u003c/p\u003e\n\u003ch3 id=\"udp-3--\"\u003eUDP (3) üü©-\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide UDP\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Livello di trasporto/Untitled.png\" alt=\"image/universita/ex-notion/Livello di trasporto/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003eClassico inizio e fine porta del socket.\u003c/li\u003e\n\u003cli\u003eLunghezza, si pu√≤ vedere che massimo √® 2 alla 16, e poi il checksum per vedere se √® comunicato bene.\u003c/li\u003e\n\u003cli\u003e8 byte di header, quindi molto efficiente!\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eSposto a livello applicazione il check al mancato pacchetto. (esempio DNS)\u003c/li\u003e\n\u003cli\u003eOppure casi in cui perdere pacchetti non √® molto importante.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCARATTERISTICHE UDP\u003c/p\u003e","title":"Livello di trasporto"},{"content":"il livello isa √® il livallo delle istruzioni\n8.1 Struttura Solitamente le istruzioni sono divise in due parti:\n8.1.1 Opcode e indirizzamento Opcode\nQuesto opcode indica la tipologia di istruzione.\nPer esempio per l\u0026rsquo;architettura HACK √® il primo bit, che indica se √® una istruzione C oppure una istruzione A.\nQuesto insieme poi alle altre istruzioni che definiscono cosa deve fare costituiscono OPcode.\nIndirizzamento\nPoi c\u0026rsquo;√® una sezione che indirizza, cio√® dice all\u0026rsquo;istruzione cosa deve prendere e dove deve salvare.\n8.2 Indirizzamento 8.2.1 Diretto chiamato un indirizzamento diretto quando l\u0026rsquo;istruzione deve contenere l\u0026rsquo;informazione della memoria su come operare:\nun esempio √® $inc[5]$ per dire di incrementare il valore all\u0026rsquo;indirizzo 5\n8.2.2 Immediato Ha gi√† l\u0026rsquo;operando da usare. Quindi nel caso dell\u0026rsquo;architettura HACK, per l\u0026rsquo;istruzione A ho gi√† quello che devo fare\n8.2.3 Registro diretto Questo √® l\u0026rsquo;indizzamento solito, si utilizza il nome simbolico per dire su quale registro operare.\nAd esempio:\ninc dx in cui sto direttamente incrementando il registro\n8.2.4 Registro indiretto un esempio di indirizzamento indiretto √®\ninc [dx] in cui sto andando a operare sulla locazione di memoria contenuta in dx.\nQuindi prende la locazione di dx, che pu√≤ essere 5 10 o quel che i vuole e poi opera su questo.\n√à molto simile al diretto, ma utilizza i registri\n8.2.5 Indicizzato Per esempio :\ninc [dx + 5] Prendo l\u0026rsquo;indirizzo di dx e ci prendo un offset\nDi solito pu√≤ essere utile per activation record, che non so cosa sia, o accedere a certo tipo di strutture.\n8.2.6 con Stack Questa √® una indicizzazione molto utilizzata, tanto che ci sono dei registri apposta.\nAlcune operazioni solite sono pop e push, e la presenza di un registro sp che mantiene la locazione attuale dello stack (un pointer!)\nAnche questo per activation record\n8.3 Tipologie di istruzioni 8.3.1 Dati da memoria a registro.\nRegistro a registro e simili\n8.3.2 Aritmetico-logiche binarie Quindi somme, divisioni moltiplicazioni sottrazioni.\n8.3.3 Unarie Per esempio shift. (moltiplicazione o div per due)\nDi solito risparmiamo molte istruzioni a livello assembli utilizzando le operazioni unarie.\n8.3.4 Salti Quindi spostamento del PC che contiene l\u0026rsquo;istruction register\n8.3.5 Invocazione procedure In hack queste non esistono, ma esistono per la maggior parte delle altre architetture.\nQuesto salta alla procedura poi fa un return sulla procedure vecchia (si dice chiamata di stack)\nQuindi sono due comandi in pi√π che non esistono per il nostro calcolatore\n8.4 Procedure 8.4.1 Activation record Quando viene chiamata una procedura, si crea un nuovo frame, salvando\nVariabili locali delle nuova chiamata Un puntatore alla vecchia istruzione Quando si ritorna alla istruzione precedente tutta questa roba, questo nuovo frame, viene eliminato.\nEsempio di chiamata di procedure\n8.5 Trap \u0026amp; interrupt Questi due gestiscono errori del programma. NO\n8.5.1 Caratteristiche del trap Questo errore viene chiamato nel caso in cui ci siano accessi non consentiti come\nOpcode non definito (strano, succede solo se codice corrotto o sistema sballato) Un accesso a memoria non consentita Questo √® gestito dal sistema operativo con un gestore di trap. Quindi togliere il controllo (e ucciderlo) al programma con la forza grazie al sistema operativo.\n8.5.2 Differenze con Interrupt La differenza principale √® che interrupt √® chiamato dall\u0026rsquo;esterno e interpretato grazie al sistema opertivo: per esempio il ctrl-c per ucciderei l programma. Questo √® gestito da interrupt Service Routine - ISR. Si pu√≤ dire che sono asincroni mentre le trap sono sincrone.\nEs. quando la lezione √® interrota da una domanda a cui si vuole rispondere.\n8.5.3 Priorit√† dell\u0026rsquo;interrupt La CPU pu√≤ scegliere di non seguire gli interrupt, si parla di interrupt mascherati nel caso in cui ci sia un lavoro molto importante (per esempio passare da un thread all\u0026rsquo;altro, qualcosa di strano che non dovrebbe essere interrotto mentre sta operando).\nOppure anche per scegliere delle priorit√† se tastiera o disco e simili..\nTipo se il prof non risponde subito alla domanda e dice che lo far√† dopo.\n8.5.4 Busy waiting √à una altra soluzione all\u0026rsquo;interrupt, cio√® ogni 100 millisecondi il sistema operativo va a guardare se esiste un input umano. Ovviamente √® molto inefficiente. (in pratica sta aspettando se il disco ha finito per ricominciare a fare le cose normali).\n8.5.5 Polling √à molto simile al busi waiting, per√≤ invece di non fare nulla e aspettare soltanto quando non va a guardare, fa qualche operazione.\nTipo il prof che chiede se ci sono delle domande. e al busi waiting, per√≤ invece di non fare nulla e aspettare soltanto quando non va a guardare, fa qualche operazione.\nTipo il prof che chiede se ci sono delle domande.\n","permalink":"https://flecart.github.io/notes/livello-isa/","summary":"\u003cp\u003eil livello isa √® il livallo delle istruzioni\u003c/p\u003e\n\u003ch2 id=\"81-struttura\"\u003e8.1 Struttura\u003c/h2\u003e\n\u003cp\u003eSolitamente le istruzioni sono divise in due parti:\u003c/p\u003e\n\u003ch3 id=\"811-opcode-e-indirizzamento\"\u003e8.1.1 Opcode e indirizzamento\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eOpcode\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eQuesto opcode indica la tipologia di istruzione.\u003c/p\u003e\n\u003cp\u003ePer esempio per l\u0026rsquo;architettura HACK √® il primo bit, che indica se √® una istruzione C oppure una istruzione A.\u003c/p\u003e\n\u003cp\u003eQuesto insieme poi alle altre istruzioni che definiscono cosa deve fare costituiscono OPcode.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eIndirizzamento\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003ePoi c\u0026rsquo;√® una sezione che indirizza, cio√® dice all\u0026rsquo;istruzione cosa deve prendere e dove deve salvare.\u003c/p\u003e","title":"Livello ISA"},{"content":"9.1 Caratteristiche Il sistema operativo non ha sempre avuto una interfaccia grafica.\n9.1.1 In generale Principalmente √® un gestore delle risorse come il disco, la CPU, l\u0026rsquo;output e l\u0026rsquo;input.\n√à qualcosa che si infrappone come interfaccia fra le applicazioni e quello che √® presente sotto.\n9.1.2 Ambiti principali 9.2 Paginazione Al programma non interessa se effettivamente √® presente in memoria fisica questa quantit√† di memoria, si di solito basta sempre.\nCi sono 3 casi:\nse la necessit√† di memoria √® anche superiore alla memoria virtuale esistente allora c\u0026rsquo;√® l\u0026rsquo;errore out-of-memory Se √® maggiore della fisica ma minore, dovr√† essere gestita dalla paginazione e simili. Se √® minore della memoria fisica allora tutto ok! Implementazione Slide\n9.2.1 Indirizzi virtuali e paginazione Vogliamo utilizzare tutti i bit per l\u0026rsquo;indirizzamento, anche se questi superano effettivamente la memoria effettiva, questa astrazione permette di facilitare al programma la comprensione di tutto. (ma il programma √® molto pi√π lento perch√© ogni volta doveva ricaricare la pagina di memoria).\n9.2.2 Hit and fault Si ha un page hit se la pagina √® caricata, altrimenti √® page fault e si deve ricaricare tutta la memoria per il programma.\n9.2.3 Memory Management Unit Esempio\nQuesto √® il chip che si differenzia dalla cache. Una pagina virtuale pu√≤ essere messo in qualunque pagina reale.\nTabella gestita dal sistema operativo che tiene in memoria le pagine che sono usate e quelle no.\nquindi se √® 1 (in memoria) si chiama working set.\n9.2.4 Algoritmi di paginazione (2) Ci dicono quale pagina togliere dalla memoria principale per sapere quale rimpiazzare con la nuova pagina.\nI principi che sono presenti per questi algoritmi di paginazione, sono molto simili ai principi della localit√† spaziale e temporale presenti per la Cache\nQuelle presentate sono LRU e FIFO, si pu√≤ dire che il primo funziona meglio mentre il secondo √® pi√π veloce, quindi bisogna vedere i tradeoff.\nQuesti algoritmi (in particolare La Least Recently Used √® utilizzata anche in Memoria per la cache).\n9.2.5 Dirty bit Si aggiunge un bit che ci dice se una pagina √® stata sporcata o meno (cos√¨ possiamo decidere se scrivere in memoria o no).\n9.2.6 Frammentazione interna Non vorremmo sprecare un pezzo del blocco, sprecheremmo mezzo blocco.\nPer ovviare a questo (il fatto di non utilizzare l\u0026rsquo;intero blocco si dice frammentazione interna)\n9.3 Segmentazione 9.3.1 Problemi della paginazione Questa opzione non √® pi√π presente nella realt√†, dato che si utilizza sempre la paginazione.\nProblemi della paginazione\nEvitare la frammentazione interna Le pagine sono scollegati dai programmi (potrebbe essere che un array sia scollegato in pi√π pagine, ho mano manovra). Si divide la memoria in segmenti che vengono dati a parti del processo (esempio i/o ) e altro a seconda dello scopo\n9.3.2 In memoria: frammentazione esterna Dato che i segmenti non sono della stessa grandezza, c\u0026rsquo;√® un p√≤ di complicazione mentre si trattano queste cose. ecco che si ha il fenomeno di frammentazione esterna in questo caso.\nL\u0026rsquo;operazione di compattare la memoria √® moolto costosa\u0026hellip;\nEsempio\n9.3.3 Scelta del \u0026ldquo;buco\u0026rdquo; (2) Ci sono due modi principali per scegliere la zone in cui mettere il programma\nBest Fit: (ci metto pi√π tempo perch√© devo cercare il buco migliore, ma poi trovo quello pi√π economico in cui c\u0026rsquo;√® meno spazio inusato) First fit: √® il pi√π veloce perch√© metto subito sul primo blocco, per√≤ grande spazio potrebbe essere inutilizzato 9.3.4 Combinazione segmentazione e paginazione Si possono mischiare: una parte per la segmentazione e poi la pagina per il segmento e da questo si raggiunge un blocco.\nEsempio\n9.4 Gestione del linking ! 9.4.1 il file oggetto Ogni file viene compilato assumendo che parta dall\u0026rsquo;indirizzo zero, poi questi vengono riorganizzati con successo da linker\nEsempio 9.4.2 Esempio 9.4.3 La rilocazione La rilocazione per chiamate di funzioni esterne (di sistema √® semplice), poi bisogna rilocare anche pointers e branches., si utilizza un dizionario di rilocazione.\n9.4.4 Indirizzamento dinamico Viene compilato normalmente, e viene linkato nel momento di esecuzione grazie al sistema operativo\nEsempio\nIndirizzamento dinamico\nViene compilato normalmente, e viene linkato nel momento di esecuzione grazie al sistema operativo\nEsempio\n","permalink":"https://flecart.github.io/notes/livello-os/","summary":"\u003ch2 id=\"91-caratteristiche\"\u003e9.1 Caratteristiche\u003c/h2\u003e\n\u003cp\u003eIl sistema operativo non ha sempre avuto una interfaccia grafica.\u003c/p\u003e\n\u003ch3 id=\"911-in-generale\"\u003e9.1.1 In generale\u003c/h3\u003e\n\u003cp\u003ePrincipalmente √® un \u003cstrong\u003egestore delle risorse\u003c/strong\u003e come il disco, la CPU, l\u0026rsquo;output e l\u0026rsquo;input.\u003c/p\u003e\n\u003cp\u003e√à qualcosa che si infrappone come interfaccia fra le applicazioni e quello che √® presente sotto.\u003c/p\u003e\n\u003ch3 id=\"912-ambiti-principali\"\u003e9.1.2 Ambiti principali\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Livello OS/Untitled.png\" alt=\"image/universita/ex-notion/Livello OS/Untitled\"\u003e\n\u003ch2 id=\"92-paginazione\"\u003e9.2 Paginazione\u003c/h2\u003e\n\u003cp\u003eAl programma non interessa se effettivamente √® presente in memoria fisica questa quantit√† di memoria, si di solito basta sempre.\u003c/p\u003e","title":"Livello OS"},{"content":"Log Linear Models can be considered the most basic model used in natural languages. The main idea is to try to model the correlations of our data, or how the posterior $p(y \\mid x)$ varies, where $x$ is our single data point features and $y$ are the labels of interest. This is a form of generalization because contextualized events (x, y) with similar descriptions tend to have similar probabilities.\nThese kinds of models are so common that it has been discovered in many fields (and thus assuming different names): some of the most famous are Gibbs distributions, undirected graphical models, Markov Random Fields or Conditional Random Fields, exponential models, and (regularized) maximum entropy models. Special cases include logistic regression and Boltzmann machines.\nIntroduction to log linear models Counting: first approach üü®++ A very easy model estimating $P(y \\mid x)$ is just taking the count, and assuming they are independent, so the value is $\\frac{\\text{count}(x, y)}{\\text{ count}(x)}$. This is also the easiest model, and could have some theoretical motivations. See Na√Øve Bayes for example. But it\u0026rsquo;s easy to see what problems are we getting with this simple model: So we have two main drawbacks, described in the image.\n$$ f'(x) = \\begin{cases} 1 \\text{, if f(x) \u003e= 0} \\\\ 0 \\text{ else } \\end{cases} $$Exponentiation üü© $$ p(y \\mid x) \\propto \\exp \\text{ score } (x, y) $$$$ \\exp \\text{ score}(x, y) = \\exp \\sum_{k = 1}^{K} (\\theta_{k} \\cdot f_{k}(x, y)) $$ We notice that the argument for the exp is always positive. At the current moment I do not understand why is this a property that we want. We would like to normalize our exponential function, so that we have a probability. We then introduce this value: $Z = \\sum_{y \\in Y} p(y \\mid x)$. This part is usually difficult to compute, it runs in$\\mathcal{O(\\lvert y \\rvert)}$ time.\n$$ \\log p(y \\mid x) = \\sum_{k = 1}^{K} (\\theta_{k} \\cdot f_{k}(x, y)) - \\log Z = \\vec{\\theta} \\cdot \\vec{f}(x, y) - \\log Z $$ Which is a nice form. Some reasons why we are using this function is presented in the first section of The Exponential Family.\nFeature pipeline The preprocessing steps üü®+ Historically, the features were hand-engineered, meaning people would try to extract functions after a step of preprocessing the text. the preprocessing step consisted in steps like\nTokenization Lower casing stemming (getting the root of the words) Stop word removal Reducing vocabulary. Here is an example: And then the input would be easy enough to be dealt with the log-linear method and the features. Feature engineering üü®++ After we have preprocessed the texts, how can we define the features? There are some classical methods: N-grams\n(BOS, BOS, UNK), (BOS, UNK, ‚Äòs), \u0026hellip;, (complete, broke, ! One-hot encoding (0, 0, 1, 0, ..) for a single word. Bag-of-words (see spam classification) (0, 1, 0, 2, \u0026hellip;), we don\u0026rsquo;t care about the order of the words, just if they are present or not in the text. Word embeddings Convert words into continuous representations Can be contextual (e.g., ELMo, BERT) or not (e.g., Glove, fastText) More on this in future lectures! Bag-of-embeddings Average embeddings for all words in a sequence Domain-specific features (for example if we know we want to agree the gender of an adjective, this feature could be built-in!) After we have defined this, we use MLE to minimize the loss. In the case of log linear models, it is a convex function, so we have that the local minima is also the global minima, and it\u0026rsquo;s a easy problem to solve.\nWith the new approach, features are designed automatically with neural networks.\nExpectation matching üü© $$ \\mathcal{L}(\\theta) = \\sum_{n = 1}^{N} \\vec{\\theta} \\cdot \\vec{f}(x_{n} , y_{n}) - \\sum_{n = 1}^{N} \\log\\sum_{y' \\in \\mathcal{Y}} p(y' \\mid x_{n} ; \\vec{\\theta}) $$ And that $p(y \\mid x) = \\exp(\\vec{\\theta} \\cdot \\vec{f}(x, y))$.\n$$ \\frac{ \\partial }{ \\partial \\theta_{k} } \\log \\sum_{y \\in \\mathcal{Y}} \\exp(\\vec{\\theta} \\cdot \\vec{f} (x, y)) = \\frac{\\left( \\frac{ \\partial }{ \\partial \\theta_{k} } \\sum_{y \\in \\mathcal{Y}} \\exp(\\vec{\\theta} \\cdot \\vec{f} (x, y)) \\right)}{\\sum_{y \\in \\mathcal{Y}} \\exp(\\vec{\\theta} \\cdot \\vec{f} (x, y))} = \\frac{ f_{k}(x, y) \\sum_{y \\in \\mathcal{Y}} \\exp(\\vec{\\theta} \\cdot \\vec{f}(x, y))}{\\sum_{y \\in \\mathcal{Y}} p(y \\mid x) } $$$$ \\sum_{i = 1}^{N}f_{k}(x_{i}, y_{i}) = \\sum_{i = 1}^{N} \\mathbb{E}_{y}[f_{k}(x_{i}, y)] $$ This tells us how we should model our $\\theta$ because modifying that, has some impact on the value of the expected feature count.\n$$ \\frac{ \\partial \\mathcal{L}(\\theta) }{ \\partial \\theta_{k} } = \\sum_{n = 1}^{N} f_{k}(x_{n}, y_{n}) - \\sum_{n = 1}^{N} \\sum_{y' \\in \\mathcal{Y}} p(y' \\mid x_{n}; \\theta) f_{k}(x_{n}, y') $$ The first part are the counts while the second part is the normalizer contribution. At the minimum we have that the above two are equal, because the derivative is zero. This is called expectation matching. (Berger 1996).\nIf we have Softmax Function for the loss it\u0026rsquo;s easy to explicitly write the gradient:\n$$ \\frac{ \\partial \\log \\text{ softmax}(\\vec{h}, y) }{ \\partial \\vec{\\theta} } = f(x, y) - \\sum_{y \\in \\mathcal{Y}} \\text{ softmax }(\\vec{h}, y) f(x, y) $$ The derivation is left as exercise.\n$$ \\sum_{i = 1}^{N} \\text{Cov}(f(x_{i}, Y)) $$Relation with linear models One can prove that log linear models can learn any linear model. The simple reason is that in a binary-class log-linear model the decision boundary is given by $\\theta g(x)$, and falls back to a Sigmoid function, this is the same as the linear model bound!\nLearning Notes People at Johns Hopkins University have done something quite nice to learn log linear models, check it out here. There are also some formulas here\nThis is another resource, more math heavy, for understanding log linear models in NLP. See here.\n","permalink":"https://flecart.github.io/notes/log-linear-models/","summary":"\u003cp\u003eLog Linear Models can be considered the most basic model used in natural languages. The main idea is to try to model the correlations of our data, or how the posterior $p(y \\mid x)$ varies, where $x$ is our single data point features and $y$ are the labels of interest. This is a \u003cem\u003eform of generalization\u003c/em\u003e because contextualized events (x, y) with similar descriptions tend to have similar probabilities.\u003c/p\u003e\n\u003cp\u003eThese kinds of models are so common that it has been discovered in many fields (and thus assuming different names): some of the most famous are Gibbs distributions, undirected graphical models, Markov Random Fields or Conditional Random Fields, exponential models, and (regularized) maximum entropy models. Special cases include logistic regression and Boltzmann machines.\u003c/p\u003e","title":"Log Linear Models"},{"content":"Logica del primo ordine Questa √® la logica pi√π utilizzata dai matematici\nLimitatezza della logica proposizionale La logica proposizionale classica non √® in grado di ragionare sull\u0026rsquo;infinito Fino ad ora abbiamo utilizzato una metalogica per giustificare il per ogni e l\u0026rsquo;esiste nelle dimostrazioni fin\u0026rsquo;ora.\nDobbiamo quindi dare una definizione pi√π formale dei quantificatori.\nObiettivo della logica del primo ordine Si pu√≤ quindi identificare come l\u0026rsquo;obiettivo della logica di primo ordine l\u0026rsquo;introduzione dei quantificatori dell\u0026rsquo;universale e dell\u0026rsquo;esiste\n## Sintassi In questa sintassi stiamo dividendo in Termini e proposizioni (le proposizioni che si possono trovare nella logica proposizionale classica).\n$$ t::= x \\mid c \\mid f^{n}(t_{1}, \\dots, t_{n}) $$Def: Vocabolario Ossia, simboli di relazione n-arie (ossia con $n$ argomenti) $p, q$ etc\u0026hellip; e simboli di funzione $f, g, h$ anche questi n-arie etc\u0026hellip; ricorda la differenza fra funzione e relazione fatta in Relazioni fra insiemi\nDef: Termine Lo facciamo in modo induttivo.\nUna variabile qualunque √® un termine Poi caso induttivo: se $t_{1}, \\dots, t_{n}$ sono termini, lo √® anche $f^{n}(t_{1}, \\dots, t_{n})$ NOTA: qui non facciamo uso di relazioni per definire i termini\nDef: Formula o proposizione Anche qua definiamo per induzione:\n$P(t_{1}, \\dots, t_{n})$ √® un predicato $n-ario$ ed √® una formula. (un predicato √® una funzione che mappa in 0, 1) Se $\\varphi, \\phi$ sono formule, lo sono anche tutte le banali cose logiche, quindi $\\varphi \\land \\phi, \\varphi \\lor \\phi, \\varphi \\to \\delta, \\forall x.\\varphi, \\exists x. \\varphi$ NOTA: si chiama Prenex normal form quando tutti i quantificatori sono all\u0026rsquo;inizio dell\u0026rsquo;espressione.\nFully quantified: aka sentence quando non ci sono variabili libere. Def: Teoria √à un insieme di formule come definito di sopra, basate su un certo vocabolario fissato. √à interessante la roba di (Choi 2022) che dice che non √® possibile usare la logica per problemi real world.\nRiassunto sintassi: Come si pu√≤ osservare nella sintassi di logica del primo ordine estende la logica proposizionale classica perch√© per P 0 ho le singole proposizioni\nQuindi si divide in un dominio di discorso, ossia l\u0026rsquo;insieme dei termini possibili come costanti e leformule o proposizioni che possiedono un valore di verit√†.\nPerch√© primo ordine Si chiama logica di primo ordine perch√© non si possono utilizzare le funzioni sulle variabili nel dominio di discorso.\nQuesta √® l\u0026rsquo;ultima logica in cui vale ancora la completezza, e la correttezza, nelle logiche superiori non sar√† pi√π possibile catturare tramite un concetto sintattico il valore semantico.\nQuesta √® la logica di primo ordine che basta ai matematici per fare tutto (questo perch√© le funzioni dei matematici in realt√† sono degli insiemi, non qualcosa che calcola).\nPossibili denotazioni Oggetti ignoti nel dominio Oggetti fissati Connotazioni di denotazioni oggetti Connotazioni di denotazioni di valori di verit√† Semantica Questa parte √® approfondita dopo con mondo ed interpretazione\nBinder I binder sono un concetto fondamentale nell\u0026rsquo;informatica (soprattutto a chi andr√† a fare i compilatori). Quindi stiamo astraendo un livello di semantica! Connettivi ancora pi√π astratti.\nI binder legano una variabile e uno scope (Cattura una variabile (o serie di varaibile) in uno scope che viene valutato pi√π e pi√π volte).\nFormula matematica (uno scope nel senso di derivata, integrale sommatoria e simili) I Simboli logici per ogni esiste. Vado a valutare una unica formula all\u0026rsquo;interno di uno scope (e continuo ripetutamente a sostituire e calcolare su tanti valori, e restituisco il risultato sintetizzato).\nShadowing Nei binder non si pu√≤ accedere alle variabili esterne se hanno lo stesso nome, si dice shadowing (quello interno nasconde l\u0026rsquo;esterno, quindi fa ombra, nasconde).\nUn esempio √® ridichiarare un parametro formale in una funzione.\nDiagrammi di legame Sono molto utili per capire le variabili del binder e lo scope di queste variabili\nCose da fare:\nLegare variabile a ogni binder e lo scope Esistono le variabili che non vengono mai legate, si dicono variabili libere queste (come libreria o variabili globali), queste si indicano con una freccia all\u0026rsquo;infinito con il nome Variabili libere Queste variabili non sono modificabili (come provare a cambiare il nome di una funzione di libreria esterna).\nDefinizione per induzione strutturale\nalfa-convertibilit√† Si chiama alfa perch√© una branca dell\u0026rsquo;informatica che studiava i lambda, cuore del linguaggio di programmazione funzionale. (io lo chiamo anche sostituzione idiota, ma attento che in linguaggi normali c\u0026rsquo;√® il fenomeno dell\u0026rsquo;opacit√† che non ci permette di farlo!)\nSi dice che una serie di formule sono alfa-convertibili se il diagramma di legame creato dalle formule √® uguale ‚Üí relazione di equivalenza\nEssendo una relazione di equivalenza possiamo lavorare su una classe di equivalenza, quindi sarebbe bene ragionare al livello di insieme quoziente delle formule.\nEsempi\nNell\u0026rsquo;esempio in giallo, la Z fa shadowing, ha cambiato una variabile che in primo momento apparteneva a uno scope esterno.\nSostituzione in logica primo ordine Praticamente questa nozione ci dice che una funzione ha lo stesso output anche se quello che ci va dentro √® una variabile con un nome diverso. Questa nozione ha una certa similitudine con la funzione di sostituzione, in quanto entrambi parlano di invarianza sulla sostituzione di variabili.\nLa differenza principale √® che questa parla di binder mentre quella di prima parla di stesso valore di verit√† di una proposizione.\nPossiamo allora definire una funzione di sostituzione anche per la logica del primo ordine che faccia attenzione anche ai diagrammi di flusso e i binder\nSostituzione\nMondo o interpretazione Non √® pi√π sufficiente avere un mondo indicato solamente come una v, ma √® necessaria una coppia ordinata: (A, l) dove A √® l\u0026rsquo;insieme non vuoto di denotazioni, mentre l √® simile alla vecchia funzione semantica v, per√≤ associa degli elementi in A altri elementi in A, non dice niente sulle connotazioni.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Logica del Primo ordine/Untitled 9.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Logica del Primo ordine/Untitled 9\u0026quot;\u0026gt; Def: Modello Questo √® anche chiamato mondo in questo caso.\nUn simbolo non ha significato finch√© non ne diamo uno, questo √® la parte della semantica, che vuole cercare di dare senso al mondo. Uno stesso simbolo pu√≤ avere diverse interpretazioni (diversa semantica) in modelli diversi\nDato un vocabolario $(f_{1}, \\dots, f_{j}, p_{1},\\dots, p_{i})$ un modello √®\nUn insieme $U$ Le funzioni $f_{1}^{U},\\dots, f_{j}^{U}$ e similmente definite $p$ tali per cui se $f_{1}$ ha ariet√† n, allora $f_{1}^{U} : U^{n} \\to U$, ossia √® una relazione n-aria. Per $p_{1}$ si ha che $p_{1}^{U} \\subseteq U^{n}$. Def: Interpretazione Con un insieme $V$ possiamo definire interpretazione una funzione $I: V \\to U$ con $U$ l\u0026rsquo;insieme del modello definito #Def Modello. Solitamente questo √® definito in modo induttivo.\nNozione semantica di per ogni ed esiste Esempi di formalizzazione sintattica errata\nPer esempio: elefante √® una connotazione, mentre la denotazione √® quell\u0026rsquo;animale in carne ed ossa, non posso manipolare delle denotazioni in questo caso, quindi non avrebbe senso utilizzarlo.\nNel secondo caso sto testando molte pi√π cose (connotazioni sono molti di pi√π rispetto alle denotazioni in quanto esistono i sinonimi)\nL\u0026rsquo;idea principale √® tenersi una lista (una mappa) che associ nomi (connettivi) e denotazioni del mondo, questa √® l\u0026rsquo;ambiente indicata con la lettere csi.\nSemantica della logica primo ordine La funzione di interpretazione va per ricorsione strutturale in tutte le sotto-formule, per cui basta definirlo nell\u0026rsquo;insieme dei termini e la ho per tutto il modello.\nRicorsione strutturale Conseguenza logica in Primo ordine Dobbiamo prendere in questo caso considerazione della definizione pi√π complessa del mondo (ricordarsi che nelle logiche di ordine superiore √® proprio questa ulteriore complessit√† che non permette di avere una completezza).\nQuindi dobbiamo tenere conto del significato di (A, l), $\\xi$.\nDef: Verit√† $$ U, I \\models P(t_{1}, \\dots, t_{n}) \\text{ se } \\langle I(t_{1}), \\dots, I(t_{n}) \\rangle \\in P_{I}^{U} $$$$ U, I \\models \\varphi \\land \\phi \\text{ se } U, I \\models \\varphi \\land U, I \\models \\phi $$$$ U, I \\models \\varphi \\lor \\phi \\text{ se } U, I \\models \\varphi \\lor U, I \\models \\phi $$$$ U, I \\models \\neg \\varphi \\text{ se } U, I \\not \\models \\varphi $$$$ U, I \\models \\exists x. \\varphi \\text{ se esiste } \\alpha \\in U \\mid U, I\\left[ x \\to \\alpha \\right] \\models \\varphi $$$$ U, I \\models \\forall x. \\varphi \\text{ se per ogni } \\alpha \\in U \\mid U, I\\left[ x \\to \\alpha \\right] \\models \\varphi $$ NOTA: se andiamo a considerare una formula chiusa, ci basta il modello, perch√© l\u0026rsquo;interpretazione √® utile quando andiamo a trattare formule libere.\nPropriet√† esiste e per ogni Queste propriet√† espandono la lista CAIDANA delle propriet√† presenti in Connettivi Logici, correttezza, variabili.\nCompletezza debole \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Logica del Primo ordine/Untitled 13.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Logica del Primo ordine/Untitled 13\u0026quot;\u0026gt; Commutativit√† e non chiaramente se Sono gli stessi x e y in due per ogni es $\\forall A, \\forall B$ questo √® uguale a dire $\\forall B, \\forall A$, stessa cosa per l\u0026rsquo;esiste.\nMa il senso della frase cambia nel caso in cui abbia un per ogni e in seguito un esiste.\nSemidistributivit√† In certi casi (non per tutti) posso spostare (addirittura eliminare!) i quantificatori\n### De morgan Equivalenze notevoli Deduzione naturale In questa sezione di appunto andiamo ad indagare le regole della deduzione naturale per la logica di primo ordine, per questo motivo linko la deduzione naturale in ambito proposizionale Deduzione naturale\nVogliamo utilizzare delle cosa uguali a meno di alfa conversione.\nIntroduzione Per ogni Forma generale\nAttento che Y non deve affatto appartenere alle variabili libere delle foglie!\nQuesto mi dice che devo utilizzare solamente solamente una variabile che non √® stata gi√† presa (quindi libera, data dall\u0026rsquo;esterno)\nSuggerimento: per non sbagliare mai ti basterebbe prendere una variabile mai presa prima.\n/to\nCorrettezza ed invertibilit√† intuizionista\nCorrettezza classica\nIo sintatticamente ci metto y e il mondo mi risponde xi y. Ora l\u0026rsquo;ambiente xi mi dice che x vale xi di y e quindi √® la stessa. Ma lo devo dimostrare per induzione strutturale.\nInvertibilit√† classica\nEliminazione per ogni Forma generale\nDovrei passare per la formula pi√π complessa a volte! A volte √® pi√π semplice dimostrare il generale che il particolare perch√© possiedo induzione strutturale e simili.\nCorrettezza intuizionista e classica\nAnche da questo possiamo sapere che non possiamo andare a cercare tutte le variabili, sono infiniti! L\u0026rsquo;algoritmo non concluderebbe mai.\nIntroduzione Esiste Questa dimostrazione √® praticamente uguale all\u0026rsquo;eliminazione del per ogni, mentre l\u0026rsquo;eliminazione √® simile all\u0026rsquo;introduzione\nForma generale\nEliminazione dell\u0026rsquo;esiste In questa forma io non ho nessuna informazione sulla x, non posso prendere una x che √® gi√† stata utilizzata nella conclusione C oppure nelle foglie.\nDeve essere una variabile libera!, non deve avere nessuna altra ipotesi presa da altro.\nForma generale\nCompletezza ed incompletezza di Godel Angelo was here 18/10/22, and 20/03/24 too! Primo teorema \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Logica del Primo ordine/Untitled 28.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Logica del Primo ordine/Untitled 28\u0026quot;\u0026gt; Gamma voglio identificare un singolo mondo.\nSe contiene l\u0026rsquo;aritmetica ho i numeri la somma i prodotti e simili. Se gamma √® consistente (quindi interessante, senn√≤ tutto e dimostrabile, √® anche un modo per dire che non ho pi√π mondi). Allora non posso filtrare in maniera da tenerne solamente uno. il gamma deve tenere anche dei mondi in pi√π. Quindi quando gamma parla di artimetica non si pu√≤ filtrare fino a un singolo mondo. Quindi qualunque aritmetica prendo, non posso mai filtrare fino a singolo mondo! √® una incompletezza di Gamma, ma non √® una incompletezza delle regole!\nAbbozzo\n√à una delle prime assolute codifiche!\nbigezione fra formule ed alberi, e la sintassi dimostrazione e poi utilizza il paradosso del mentitore (io mento) crea un numero che dice che non √® dimostrabile, quindi fonde livello e metalivello per cui non pu√≤ n√© essere dimostrabile n√© essere indimostrabile (altrimenti sarebbe inconsistente). Entrambe sono false\nIo sono dimostrabile se e solo se io non sono dimostrabile, quindi entrambe devono essere false.\nUno dei teoremi pi√π storpiati dai divulgatori scientifici. Ma allo stesso tempo √® uno dei teoremi pi√π profondi della logica.\nSe abbiamo abbastanza ipotesi da poter identificare solamente un singolo mondo, allora vale il concetto di terzo escluso, quindi o vale F conseguenza logica del mondo oppure not F √® conseguenza logica\n(nel caso contrario posso avere sia non G sia G non sono conseguenze logiche di pi√π mondi).\nGodel trova la P, per√≤ quel singolo P √® ben conosciuto, non √® molto interessante.\nQuesto √® stato introdotto per la prima volta in Incompletezza nella logica del primo ordine. √à importante qui conoscere sia la\nSintassi della logica del primo ordine. Semantica della logica del primo ordine. Panoramica della dimostrazione Supponiamo di avere una logica del primo ordine ben definita sintatticamente. Consideriamo l\u0026rsquo;insieme $\\mathbb{N}, +, \\times$ Definiamo la prima teoria dell\u0026rsquo;altro di $(\\mathbb{N}, + , \\times)$ in questo modo $Th(\\mathbb{N}, +, \\times) = \\left\\{ \\varphi \\mid \\varphi \\text{ √® una formula vera della logica del primo ordine su } (\\mathbb{N}, +, \\times) \\right\\}$ Il nostro obiettivo √® dimostrare che $ETH$ √® riducibile tramite mappatura a questo insieme. Vedere Halting Theorem and Reducibility].\nCuriosit√†: La teoria $Th(\\mathbb{N}, +)$ √® decidibile, ma √® meno espressiva rispetto all\u0026rsquo;altra teoria aritmetica. Questo √® chiamato aritmetica di Presburger. E per l\u0026rsquo;analisi aritmetica √® piuttosto importante dal punto di vista computazionale.\nDimostrazione dell\u0026rsquo;Incompletezza Dato un vocabolario arbitrario e una teoria su quel vocabolario, l\u0026rsquo;insieme $\\left\\{ \\varphi \\mid \\varphi \\in T \\text{ ed √® valido} \\right\\}$ non √® un insieme decidibile. Questo approccio √® pi√π computazionale.\nSupponiamo di avere una macchina di Turing che decide sopra, vogliamo ridurre il linguaggio $ETH$ su questo. Questo si pu√≤ fare tramite turing riducibilit√†.\nCodifica della Macchina di Turing Vedere La macchina di Turing per definizione di TM. Andremo a codificare il comportamento di una macchina di Turing utilizzando la logica di primo ordine. E poi dato che questa codifica √® possibile si pu√≤ dire che non √® decidibile quel problema. Il processo che usiamo √® chiamato g√∂delizzazione perch√© andiamo ad utilizzare codifiche per risolvere questo problema.\nConsideriamo questo vocabolario:\nSimboli di funzione sono $O^{0}, S^{1}, P^{1}$ che sono il 0, il successore e il precedessore. Simboli di relazione $head(n,m)$ se al passo $n$ √® sulla cella $m$ $state(n, m)$ se al passo $n$ √® sullo stato $q_{m}$ $cell_{i}(n, m)$ se al passo $n$ la cella $i$ contiene $m$ $$ state(0, 0) \\land head(0, 1) \\land \\forall y(\\neg head(0, 0) \\land \\neg head(0, S(S(y)))) $$ Qui vediamo come la logica √® molto molto verbosa, sostanzialmente inutile per applicazioni molto pi√π pratiche.\nPoi possiamo codificare la caratteristica della macchina di Turing principale ossia che \u0026ldquo;Ad ogni passo la macchina √® solo in uno stato, testina su una unica cella, che contiene al pi√π un simbolo\u0026rdquo; Molto molto verboso scriverlo in modo logico anche questo. Poi possiamo andare a definire anche le regole di transizione e la regola dello stato finale, una volta fatto questo abbiamo codificato interamente una TM con le formule di Turing. Riconoscibilit√† di un sistema deduttivo Vedi Deduzione naturale#Il sistema deduttivo, dato questo sistema deduttivo, vogliamo che\n√à corretta, ossia $P \\vdash \\varphi \\implies \\varphi \\text{ √® corretta}$ sound, se lo dimostro allora √® vero. L\u0026rsquo;insieme $\\left\\{ \\langle \\varphi, \\pi \\rangle \\mid \\pi \\text{ √® una dimostrazione di } \\varphi \\right\\}$ √® un insieme decidibile $$ \\left\\{ \\varphi \\mid \\varphi \\in T \\land P \\vdash \\varphi \\right\\} $$ √à riconoscibile, data una teoria $T$ e un sistema deduttivo come sopra. Basta usare la schematizzazione di sopra, ed enumerare tutte le dimostrazioni per vedere se risolve questo. Potrebbe non finire, ma se √® valido mi fermo!\nIndecibilit√† di un sistema aritmetico Usando la costruzione di sopra possiamo vedere che chiaramente abbiamo fatto la riduzione $ETH \\leq Th(\\mathbb{N}, +, \\times)$ quindi non √® decidibile. Ossia non esiste un metodo algoritmico (sistema deduttivo) che ci dice se una data formula √® nel sistema. La codifica √® pi√π complicata, per√≤ √® possibile.\nProposizioni indimostrabili Questo √® il secondo teorema di G√∂del, che ci dice che esistono formule che in nessun sistema deduttivo sono dimostrabili.\nOssia: $\\exists \\varphi \\in Th(\\mathbb{N}, +, \\times) \\mid \\forall P \\not\\vdash \\varphi$ Esiste una formula nella teoria dei numeri naturali tale per cui non esiste nessun sistema deduttivo che lo dimostri.\nSupponiamo per assurdo che tale proposizione esiste, allora abbiamo un sistema deduttivo che lo prova. Ma vogliamo dire che se vale questa propriet√† $Th(\\mathbb{N}, + , \\times)$ √® decidibile, contraddicendo #Indecibilit√† di un sistema aritmetico.\nL\u0026rsquo;algoritmo per deciderlo √® abbastanza semplice:\nUso una TM non deterministica che ci permette di verificare in parallelo se $P \\vdash \\varphi$ oppure se $P \\vdash \\neg \\varphi$, per ipotesi sappiamo che esiste una prova per $\\varphi$ o $\\neg\\varphi$. Tanto so che $P$ esiste per ipotesi. A seconda se sia vera $\\varphi$ o $\\neg\\varphi$ possiamo rispondere s√¨ o no, e quindi decidere il termine. Fine. Secondo teorema di incompletezza Questo ha un apporto molto maggiore, molto importante, la base dell\u0026rsquo;informatica.\nEnunciato\nNon riesco mai a concludere la consitenza della logica, dovrei rimettermi al metalivello continuamente, senza finire mai.\nNon possiamo mai essere sicuri della consistenza di una teoria, e alla fin fine la logica, la matematica si pu√≤ paragonare alla religione da questo punto di vista. Noi non siamo sicuri che sia vero. Serve l\u0026rsquo;atto di fede. a di una teoria**, e alla fin fine la logica, la matematica si pu√≤ paragonare alla religione da questo punto di vista. Noi non siamo sicuri che sia vero. Serve l\u0026rsquo;atto di fede.\nRegistro Ripassi Data Descrizione 20/08/2024 Con boost Alessandro Panconesi, ripassato un po' Vecchi dubbi Definizione per induzione strutturale delle variaibli libere Cosa sono le due funzioni n-arie definite nella sintassi? Riguardare registrazione 09/12 (10 minuti iniziali in cui riassume tutta la logica del primo ordine) i nomi tecnici per dire termini e proposizioni Ancora da definire Le propriet√† delle equivalenze logiche notevoli Quali sono le equivalenze notevoli del per ogni e dell\u0026rsquo;esiste? Rivedere sostituzione in logica di primo ordine Registrazione 16/12 per prove di sostituzione o dim con primo ordine. Ripasso Prox: 4 Ripasso: December 14, 2021 Ultima modifica: October 18, 2022 6:01 PM Primo Abbozzo: December 1, 2021 9:56 AM Stato: üåïüåïüåïüåïüåó Studi Personali: No\nReferences [1] Choi ‚ÄúThe Curious Case of Commonsense Intelligence‚Äù Daedalus Vol. 151(2), pp. 139\u0026ndash;155 2022\n","permalink":"https://flecart.github.io/notes/logica-del-primo-ordine/","summary":"\u003ch1 id=\"logica-del-primo-ordine\"\u003eLogica del primo ordine\u003c/h1\u003e\n\u003cp\u003eQuesta √® la logica pi√π utilizzata dai matematici\u003c/p\u003e\n\u003ch3 id=\"limitatezza-della-logica-proposizionale\"\u003eLimitatezza della logica proposizionale\u003c/h3\u003e\n\u003cp\u003eLa logica proposizionale classica non √® in grado di ragionare sull\u0026rsquo;infinito\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Logica del Primo ordine/Untitled.png\" alt=\"image/universita/ex-notion/Logica del Primo ordine/Untitled\"\u003e\u003c/p\u003e\n\u003cp\u003eFino ad ora abbiamo utilizzato una metalogica per giustificare il per ogni e l\u0026rsquo;esiste nelle dimostrazioni fin\u0026rsquo;ora.\u003c/p\u003e\n\u003cp\u003eDobbiamo quindi dare una definizione pi√π formale dei \u003cstrong\u003equantificatori\u003c/strong\u003e.\u003c/p\u003e\n\u003ch3 id=\"obiettivo-della-logica-del-primo-ordine\"\u003eObiettivo della logica del primo ordine\u003c/h3\u003e\n\u003cp\u003eSi pu√≤ quindi identificare come l\u0026rsquo;obiettivo della logica di primo ordine l\u0026rsquo;introduzione dei quantificatori dell\u0026rsquo;universale e dell\u0026rsquo;esiste\u003c/p\u003e","title":"Logica del Primo ordine"},{"content":"Con questo documento iniziamo a parlare di logica, alcuni paradossi famosi all\u0026rsquo;interno di questo mondo.\nParadossi Metalinguistici Antinomie e Paradossi Antinomia Definizione di antinomia √® un ragionamento corretto da cui deriva una conclusione errata, probabilmente √® l\u0026rsquo;insieme o campo in cui stiamo operando ad essere errato e bisogna cercare di ridefinirlo in modo pi√π corretto, in quanto le premesse erano accettabili\nParadosso Paradosso quando il ragionamento corretto va contro l\u0026rsquo;intuizione, come il paradosso dei gemelli in fisica e simili. premesse erano accettabili\nFalsi paradossi: in cui c\u0026rsquo;√® un errore del ragionamento da cui viene dedotto un ragionamento errato.\nLinguaggio naturale Per linguaggio naturale andiamo ad indicare linguaggi che esseri umani hanno inventato e usano in alcune civilt√†.\nCaratteristiche del Linguaggio naturale Il linguaggio naturale √® il linguaggio comunemente utilizzato come italiano, inglese arabo e cinese etc. utilizzato nella maggior parte della vita quotidiana.\nQuesto linguaggio non √® utile per i ragionamenti rigorosi come descrizione del calcolo o dimostrazioni in quanto questo linguaggio √®:\nFortemente dipendente dal contesto Ambigua grammatica: e.g. Il poliziotto ha ucciso il ladro con la pistola (pistola mezzo oppure compagnia?), le ambiguit√† sono molto studiate in linguistica, le riprendiamo nel corso di NLP parlando di constituents, guarda qui. Paradossi in NL Paradossi visti in classe:\nIo mento eterologico √® eterologico. Le cause individuate per i paradossi sono\nUtilizzo meta-linguistico, ce si riferisce sul linguaggio stesso (Io mento).\nLinguaggio naturale potrebbe essere cos√¨ ampio che pu√≤ parlare di s√© stesso, per esempio: contare numero di sillabe o parole, o mischiare il senso del linguaggio o simile, questo genera paradossi. Sarebbe difficile esprimere idee senza la negazione in poche parole. Per scoprire l\u0026rsquo;utilizzo meta linguistico si utilizza un teorema di invarianza delle denotazioni\nAuto applicazione di meta-linguistico a se stesso (eterologico √® eterologico).\nCerco di usare qualcosa su s√© stesso, anche se la definizione dell\u0026rsquo;aggettivo non dovrebbe essere utilizzate in questo modo, possiamo dire che perde di senso L\u0026rsquo;utilizzo della negazione (x minore non definibile in meno di 1000 parole).\nL\u0026rsquo;utilizzo della negazione su s√© stesso e anche la negazione di s√© stesso crea antinomia (paradosso NL) Ricerca di un linguaggio formale La negazione √® necessaria per fare i ragionamenti, non si pu√≤ togliere.\nNon si riesce a evitare di applicare una definizione su s√© stessa, dopo che hai oggetto e soggetto puoi scegliere dove applicarlo, cio√® √® brutto evitare solamente l\u0026rsquo;applicazione a s√© stesso, una volta creata la preposizione pu√≤ essere usata senza questi piccoli vincoli.\nI\u0026rsquo;uso metalinguistico invece si pu√≤ evitare, e quindi bisogna abbandonare il linguaggio naturale e approdare in un linguaggio artificiale, il linguaggio rigoroso della matematica.\nLinguaggio Matematico Storia dell\u0026rsquo;insiemistica Quando ancora la matematica non era ancora scienza diversa dalla informatica, i matematici si mettevano proprio a calcolare modi di calcolo,\nVennero studiate le basi e introdotte la teoria degli insiemi, da Cantor, una base per tutta la matematica attuale, ma questo viene messo in crisi dal paradosso di Russel, creando due filosofie matematiche, gli insiemisti e altri contrari.\nParadosso di Russel: $X = \\{ Y \\,|\\, Y \\not\\in Y \\, \\}$ e si ha ancora un paradosso auto-refere\nDopo tutta questa diatriba, venne creato circa nel 1930 il significato di calcolare, credo e venne creato il campo dell\u0026rsquo;informatica.\nParadosso di Russel $$ R = \\left\\{ x \\mid x \\not\\in x \\right\\} $$Analisi del paradosso Possiamo vedere che la teoria degli insiemi √® possibile creare paradossi:\nPresente l\u0026rsquo;uso della negazione La negazione, la caratteristica usata √® fatta in modo autoreferenziale Gli insiemi possono contenere s√© stessi, e quindi √® possibile l\u0026rsquo;use meta-linguistico. Quindi non pu√≤ esistere un insieme che li contenga tutti come voleva sostenere Cantor.\n$$ R \\in R \\iff R \\not \\in R $$ Cerchiamo di capire perch√©:\n$\\implies$ allora se supponiamo che $R$ √® in $R$ per struttura di $R$ vale che $R \\not \\in R$ che √® una contraddizione, assurdo. $\\Longleftarrow$ allora vale che $R \\not \\in R$ √® falso, quindi deve valere che $R \\in R$ quindi abbiamo anche in questo caso una contraddizione. Da questo concludiamo che non ha senso poter definire quell\u0026rsquo;insieme, e c\u0026rsquo;√® qualcosa che non va nell\u0026rsquo;utilizzo di quel linguaggio. Risultato dell\u0026rsquo;analisi Su questa soluzione basa l\u0026rsquo;intera matematica e non si sa se ci sono altri paradossi dentro questo. Potrebbe essere errata anche questa.\nLimitazioni sulla creazione di insiemi che abbiano propriet√† comunque ‚Üí Assioma di comprensione deve essere gettata. Assioma di separazione ovvero gli elementi devono essere presi da un insieme esistente e una propriet√† di questo insieme (quindi posso solamente restringere un insieme). √à definita come separata la collezione di tutti gli insiemi, per evitare il paradosso di auto-referenzialit√†, prevenire l\u0026rsquo;uso meta-linguistico. Paradossi Informatici Esistenza di paradossi La composizione di funzioni, cio√® l\u0026rsquo;utilizzo in modo meta-linguistico delle informazioni informatiche √® necessaria Sia in linguaggi funzionali, imperativi, basta saltare, quindi si pu√≤ modificare un programma ~~ Insieme che contiene insieme, molto simile questa cosa. La negazione delle affermazioni √® necessaria Una funzione applicata su s√© stessa √® presente, possibilissima l\u0026rsquo;autoreferenzialit√† Per questo motivo non si pu√≤ evitare il paradosso nell\u0026rsquo;ambito dell\u0026rsquo;informatica.\nParadosso sulle funzioni non totali Riguardare se sei in grado di definire il significato di Espressivit√† di un linguaggio Convergenza e divergenza di una funzione totalit√† di una funzione Totalit√† significa che una funzione riesca a restituire un output in tempo finito.\n$f(g) = not\\,(g(g))$ √® una funzione che pu√≤ creare un paradosso, se analizzata si possono trovare tutti i tre ingredienti per la creazione di paradosso:\nC\u0026rsquo;√® la negazione, c\u0026rsquo;√® l\u0026rsquo;uso meta-linguistico (composizione di funzione) e se al posto di $g$ ci metto $f$ c\u0026rsquo;√® anche l\u0026rsquo;auto-referenzialit√†, creando un paradosso.\nüí° Le funzioni matematiche danno sempre risultato, invece le funzioni informatiche possono divergere.\nParadosso sulla divergenza Questo √® il problema della fermata discusso in Halting Theorem and Reducibility#Halting theorem Nelle funzioni informatiche c\u0026rsquo;√® una fase di calcolo ed elaborazione delle informazioni. Nelle funzioni matematiche sono solamente una relazione fra insiemi (ossia calcolano un unico input). Una funzione tale che $f(g,x) = true \\, iff \\, g(x) \\downarrow$ Definisco una funzione: $h(g) = \\uparrow if \\,f(g,g) \\, else \\downarrow$\nQuesto porta alla conclusione che non esiste un programma che decida se un altro diverga.$f(g) = \\uparrow if \\,f(g,g) \\, else \\downarrow$\nParadosso sull\u0026rsquo;espressivit√† di funzioni matematiche Spiegata per filo e per segno per la diagonalizzazione di cantor Relazioni fra insiemi#Diagonalizzazione di Cantor\n!\n","permalink":"https://flecart.github.io/notes/logica-meta-linguistica/","summary":"\u003cp\u003eCon questo documento iniziamo a parlare di logica, alcuni paradossi famosi all\u0026rsquo;interno di questo mondo.\u003c/p\u003e\n\u003ch1 id=\"paradossi-metalinguistici\"\u003eParadossi Metalinguistici\u003c/h1\u003e\n\u003ch2 id=\"antinomie-e-paradossi\"\u003eAntinomie e Paradossi\u003c/h2\u003e\n\u003ch3 id=\"antinomia\"\u003eAntinomia\u003c/h3\u003e\n\u003cp\u003eDefinizione di antinomia √® un ragionamento corretto da cui deriva una conclusione errata, probabilmente √® \u003cstrong\u003el\u0026rsquo;insieme o campo in cui stiamo operando ad essere errato\u003c/strong\u003e e bisogna cercare di ridefinirlo in modo pi√π corretto, in quanto \u003cstrong\u003ele premesse erano accettabili\u003c/strong\u003e\u003c/p\u003e\n\u003ch3 id=\"paradosso\"\u003eParadosso\u003c/h3\u003e\n\u003cp\u003eParadosso quando il ragionamento corretto va \u003cem\u003econtro\u003c/em\u003e l\u0026rsquo;intuizione, come il paradosso dei gemelli in fisica e simili. \u003cstrong\u003epremesse erano accettabili\u003c/strong\u003e\u003c/p\u003e","title":"Logica meta-linguistica"},{"content":"Con la logica proposizionale studiamo le denotazioni che hanno un valore di verit√†, ovvero deve essere una sentenza assertiva. Studio solamente le connotazioni che hanno una capacit√† denotativa, in quanto √® solo quello ch emi importa.\n6.1 La sintassi Vengono qui definite le produzioni che valgono in ogni singolo mondo.\n$$ F ::= \\top|\\bot|A|B|...|\\not F| F \\wedge F| F \\vee F| F \\implies F $$Questa √® la BNF della nostra sintassi.\nLe lettere sono asserzioni, sono sentenze dichiarative a cui posso dare un valore\nConnotazioni atomiche Sono solamente ABCD e le singole lettere che rappresentano le proposizioni.\n6.1.1 Formalizzazione Ovvero il tentativo di esprimere asserzioni attraverso la sintassi della logica proposizionale. Quindi dare un valore logico a frasi come oggi piove, marco √® bello, marco √® brutto e simili. Quest √® importante perch√© √® probabile che all\u0026rsquo;esame ci sia un esercizio di formalizzazione\n6.1.2 Note per attenzione Fare attenzione ai sinonimi e contrari, che devono avere la stessa lettera, non √® ovvio.\nUna altra cosa su cui fare attenzione sono le connotazioni ovvero modi diversi per dire la stessa denotazione come:\n$A \\implies B$ √® la denotazione delle connotazioni : A √® condizione sufficiente di B, B √® condizione necessaria di A e altro.\n6.2 La semantica La semantica classica associa il valore di verit√† per ogni connotazione del linguaggio. Allora si dice che stiamo utilizzando la logica proposizionale classica\nNoi parliamo tutti i giorni con una semantica naturale, principale o intesa sono tutti dei sinonimi Devo partire da alcune premesse filosofiche che mi portano alla logica classica.\n$filosofia \\implies logica \\implies matematica$\nNota di wiki La semantica studia il significato delle parole, quindi ci dice cosa deve significare una connotazione, e possono essere molto diverse: molte semantiche per una stessa sintassi.\nEsempio semantica (interpretazione) in prog Semantica che interpreta la sintassi in termini di tempo: Interpreto i miei costrutti come il tempo che impiega ad eseguire (molto utile per avere una complessit√† computazionale (es. if, vado a guardare guardia). Semantica che interpreta la sintassi in termini di memoria occupata. 6.2.1 Dominio di interpretazione, f semantica Dominio di interpretazione sono connotazioni (definite tramite BNF)\nDipende dai mondi in Verita, Teorie, modelli, connotazione, denotazione, ossia si pu√≤ interpretare la connotazione in modi diversi a seconda della denotazione in quello specifico mondo\nSi potrebbe dire che ogni mondo possieda una funzione semantica che parte da un dominio di interpretazione e denota queste connotazioni con oggetti precisi in un mondo.\n6.2.2 Enunciati della logica classica TODO: fai una parte a s√© per questo\nQuesta logica parla della verit√†.\nManicheo (visioni estreme)\nSulla falsit√† e verit√†\nOgni enunciato √® vero o falso (esistono gradi di verit√†, secondo alcuni, dibattibile ~Fuzziness) Ogni enunciato non pu√≤ essere vero o falso allo stesso momento Platoniche\nStaticit√† il valore di verit√† non muta nel tempo, immutabile. No libero arbitrio o possibilit√† di cambiare il proprio futuro (se √® una verit√†\u0026hellip;) ah i trip mentali. Determinatezza il valore di verit√† √® sempre determinato (simile al primo aristoteo?) Tutto il futuro √® predicibile e non si pu√≤ fare niente (ma mancano le conoscenze). Utilizzando queste due caratteristiche del valore di verit√† possiamo gi√† fare delle inferenze:\nDifferenza fra verit√† e conoscenza La conoscenza non possiede il senso di staticit√† e determinatezza (pu√≤ cambiare nel tempo (cresce), e non √® sempre quella) mentre la verit√† lo √®\nDifferenza fra verit√† e risorse La verit√† √® statica (si pu√≤ utilizzare quante volte si vuole), mentre le risorse vengono consumate (esempio cibo, se lo mangio scompare,o almeno non √® pi√π nella forma attuale).\nCritiche della logica intuizionista Esistono dei mondi non determinati che si possono determinare a seconda dei mondi, non posso avere una verit√† statica immutabile.\nNon vale per la conoscenza e mondi non-deterministici\n6.2.3 Booleani e funzione di interpretazione classica Scegliemo di indicare i booloani come 1 ‚Üí Vero 0 ‚Üí Falso Per tre motivi principali:\nPosso utilizzare le regole dell\u0026rsquo;algebra in quanto sono dei numeri e possiedono quelle propriet√† Non vanno in confuzione con top e bottom per il loro essere dei numeri (altrimenti avrei dovuto distinguere il vero e il falso a livello sintattivo, a livello denotativo e poi latro) Si pu√≤ facilmente trovare un intervallo di verit√†. Interpretazione Si pu√≤ definire (funzione di) interpretazione (classica) di un mondo, possibile solamente grazie all\u0026rsquo;esistenza di cui sopra dei boleani, che associa a ogni sentenza del mondo un valore di verit√†.\nAllora dato che √® una funzione, possiamo notare che possiede i valori di:\nStaticit√†, in quanto le funzioni sono solamente quelle e non cambiano Determinatezza per le propriet√† delle funzioni, ossia per ogni sentenza del mondo posso associare un valore di verit√†. 6.2.4 funzione semantica per la logica classica Questo √® definito tramite BNF e fissa il linguaggio della logica in un mondo preciso.\nNOTA: distingui bene la differenza fra valore semantico e interpretazione in un mondo.\n6.2.5 Tabella di verit√† Le tabelle di verit√† hanno senso solamente nell\u0026rsquo;ambito della logica classica, in quanto pu√≤ solamente rappresentare una logica finita,, quindi la classica non la intuizionistica.\nLe tabelle di verit√† sono le stesse viste in Porte Logiche (con una nota particolare sulla implicazione materiale, molto diversa dalla normale relazione di causalit√† utilizzata tutti i giorni\nSemantica Tarskiana\n√à una logica che utilizzano i matematici (molto lapalissiana, inutile dal punto di vista di nuove informazioni che la definizione riesce a dare) (Coen critica anche che questo √® perch√© i matematici se ne fregano della logica, di quello che sta sotto la matematica).\nPraticamente utilizza il linguaggio naturale per descrivere la funzione semantica descritta qui sopra, cosa che funziona solamente con la logica classica, e appena si esce da questo reame non ha pi√π senso. Utilizza troppe nozioni meta-linguistiche, tanto che potrebbe dire che meta-linquistica e linguistica siano quasi la stessa cosa\n6.3 Conseguenza logica (formale) Questa √® la definizione formale di conseguenza logica\n$$ \\Gamma \\Vdash F \\iff \\forall v, (\\forall G \\in \\Gamma, [G](/notes/g)^v = 1) \\implies [F](/notes/f)^v = 1 $$NOTA 1 questa definizione non √® computabile, non √® direttamente studiabile in ambito informatico, allora c\u0026rsquo;√® bisogno della creazione di un #6.4 Sistemi deduttivi. (In questa definizione stiamo parlando di infiniti (di mondi v e assiomi G, che chiaramente non √® computabile quindi non √® possibile prendere decisioni in questo ambito).\nNOTA 2 Intelligenza artificiale forte, che possa sapere tutto, √® ucciso da questa osservazione, in quanto la computazione non pu√≤ arrivare a sapere tutto. (quindi non pu√≤ essere un programma\u0026hellip; mmmm).\n6.3.1 Equivalenza logica ovvero la semantica per ogni modello v di una teoria √® uguale, quindi possiamo dire che valgono per gli stessi mondi. $G \\equiv F \\iff \\forall v, [F](/notes/f)^v = [G](/notes/g)^v$\n6.4 Sistemi deduttivi 6.4.1 Intro Esistono sistemi deduttivi diversi, quella che vediamo noi √® la deduzione naturale.\nPossono variare per\nSintassi diverse Esigenze diverse Cosa √® un sistema deduttivo\nIl sistema deduttivo √® una nozione sintattica **che contiene in s√© una prova (dimostrazione) di una proposizione. (sintattico perch√© parla di connotazioni, non di denotazione esatta di quello presente sotto).\nDeve quindi utilizzare regole precise per le prove. Ci sono molti modi per fare regole, la pi√π naturale √® la deduzione naturale.\n6.4.2 Deduzione (3) $\\Gamma \\vdash F$, si legge da $\\Gamma$ deduco $F$, ed √® una nuova nozione sintattica (prova esplicita tale per cui la sintassi vada, quasi algoritmico). Poi si potr√† dire che ogni dimostrazione deve essere una conseguenza logica e il contrario. Dimostrazione √® un dato!\nDeve esserci una prova esplicita\n√à possibile scrivere una dimostrazione in una qualche sintassi, questo √® il significato di deduzione.\nSe √® sintatizzabile (si pu√≤ scrivere con una sintassi) si pu√≤ trasmettere ecco che si cerca una sintassi per le dimostrazioni.\nDeve essere corretta, ossia $\\Gamma \\vdash F \\implies \\Gamma \\Vdash F$\nDevo definire il motivo per cui le regole di dimostrazione siano giuste (Le varie regole di introduzione e eliminazione. non vale per le logiche espressive ma solo per la classica! Questa nozione √® dimostrata in quando parliamo di connettivi, anche se utilizza solamente il concetto di induzione strutturale per dimostrarla\u0026hellip;\nCompletezza (non per logiche espressive (?)) $\\forall \\Gamma, F, \\Gamma \\Vdash F \\implies \\Gamma \\vdash F$ vale per logiche semplici, ma esistono dimostrazioni logiche che non saremo mai in grado di dimostrare, in modo simile alla non implementabilit√† di funzioni matematiche, utilizzando paradossi.\nQuesta dimostrazione esiste ma √® molto complessa, lo ha saltato di striscio il prof.\n6.4.3 La deduzione naturale Studieremo la deduzione naturale in Deduzione naturale\n6.6 Definizioni 6.6.1 Tautologia $\\Vdash F$, quando √® √® conseguenza logica per tutto. Quindi √® anche una verit√† assoluta perch√© non dipende da mondo in esame. (la tabella logica in esame possiede solamente delgi uno).\nNot-tautologia ricorda che il contrario del per ogni √® l\u0026rsquo;esiste il not!, quindi basta un mondo in cui questa proposizione sia falsa.\n6.6.2 Soddisfacibilit√† e non Soddisfacibilit√†\nSi utilizza lo stesso simbolo $\\exists v,v \\Vdash F \\iff \\llbracket F \\rrbracket ^v = 1$ tale che v sia un mondo\nInsoddisfacibilit√†\nQuando non esiste nessun mondo, quindi per ogni mondo nno vale la cosa sopra.\n(Pi√π o meno questa propriet√† √®\nTaotologicit√† (teorema)\nSi pu√≤ dimostrare da sopra che una formula √® tautologica se per ogni mondo vale che la funzione semantica per input quella propriet√† si ha 1\nNota: tautologica implica soddisfacibile, quindi devi fare attenzione!\n6.6.3 Conseguenza logica per mondi diversi Ricondursi al concetto di variabile presente in Connettivi Logici, correttezza, variabili\nRagionamento Con questo per trovare una conseguenza logica mi posso ridurre a leggere le tabelle di verit√†.\nDrawback Le righe totali sono $2 ^n$ per le $n$ variabili totali, m per numeri grossi Non mi dice il perch√© sia una conseguenza logica. Quindi sappiamo che esiste ma non si fa mai.\n6.7 Deduzione semantica 6.7.1 Teorema di DS $$ \\Gamma \\Vdash F \\implies G \\iff \\Gamma, F \\Vdash G $$ Dim Destra Dim Sinistra Nota: dopo aver supposto che $v \\Vdash \\Gamma$, sto utilizzando l\u0026rsquo;eliminazione dell\u0026rsquo;or $F \\vee \\neg F$ per finire la dimostrazione (questa √® una tautologia).\n6.7.2 Corollario DS La conclusione dovrebbe essere quasi banale grazie al teorema sopra. (Questo mi diche che sono quasi **infinite le tautologie**!) Possiamo trovare cose vere in ogni mondi. 6.7.3 Teoremini $\\Vdash F \\iff \\neg F$ insoddisfacibile $\\Gamma$ Insoddisfacibile sse $\\Gamma\\Vdash \\bot$ e √® soddisfacibile nel caso in cui non √® conseguenza logica $\\Gamma \\Vdash F \\iff \\Gamma,\\neg F$, insoddisfacibili.,Gamma finito $\\neg F \\equiv F \\implies \\bot$ ash \\bot$ e √® soddisfacibile nel caso in cui non √® conseguenza logica $\\Gamma \\Vdash F \\iff \\Gamma,\\neg F$, insoddisfacibili.,Gamma finito $\\neg F \\equiv F \\implies \\bot$\n","permalink":"https://flecart.github.io/notes/logica-proposizionale/","summary":"\u003cp\u003eCon la logica proposizionale studiamo le denotazioni che hanno un valore di verit√†, ovvero deve essere una sentenza assertiva. Studio solamente le connotazioni che hanno una capacit√† denotativa, in quanto √® solo quello ch emi importa.\u003c/p\u003e\n\u003ch2 id=\"61-la-sintassi\"\u003e6.1 La sintassi\u003c/h2\u003e\n\u003cp\u003eVengono qui definite le produzioni che valgono in ogni singolo mondo.\u003c/p\u003e\n$$\nF ::= \\top|\\bot|A|B|...|\\not F| F \\wedge F| F \\vee F| F \\implies F\n$$\u003cp\u003eQuesta √® la BNF della nostra sintassi.\u003c/p\u003e","title":"Logica Proposizionale"},{"content":"Queste note sono molto di base. Per cose leggermente pi√π avanzate bisogna guardare Bayesian Linear Regression, Linear Regression methods.\nIntroduzione alla logistic regression Giustificazione del metodo Questo √® uno dei modelli classici, creati da Minsky qualche decennio fa In questo caso andiamo direttamente a computare il valore di $P(Y|X)$ durante l\u0026rsquo;inferenza, quindi si parla di modello discriminativo.\nIntroduzione al problema Supponiamo che\n$Y$ siano variabili booleane $X_{i}$ siano variabili continue $X_{i}$ siano indipendenti uno dall\u0026rsquo;altro. $P(X_{i}| Y= k)$ sono modellate tramite distribuzioni gaussiane $\\mathbb{N}(\\mu_{ik}, \\sigma_{i})$ NOTA! la varianza non dipende dalle feature!, questo mi permetterebbe di poi togliere la cosa quadratico dopo, rendendo poi l\u0026rsquo;approssimazione lineare Per esempio se utilizziamo nelle immagini, avrebbe senso normalizzare pixel by pixel, e non image wide con un unico valore, √® una assunzione, che se funziona dovrebbe poi far andare meglio la regressione logistica! $Y$ √® una distribuzione bernoulliana. Ci chiediamo come √® fatto $P(Y|X)$?\nCaratterizzazione di P(Y|X) üü®+ Proviamo a calcolare analiticamente come √® fatto $P(Y|X)$ usando le assunzioni di sopra\n$$ P(Y=1| X= \\left\u003c x_{1},\\dots, x_{n} \\right\u003e ) = \\frac{1}{1 + \\exp\\left( w_{0} + \\sum_{i} w_{i}x_{i} \\right)} $$ Nella derivazione di sopra si ha che $\\pi = P(Y=1)$ E poi sappiamo che\n$$ \\ln \\frac{P(X_{i} | Y=0)}{P(X_{i} | Y=1)} = \\ln \\frac{e^{-\\frac{(X_{i} - \\mu_{i0})^{2}}{2 \\sigma_{0}^{2}}}}{ e^{-\\frac{(X_{i} - \\mu_{i_{1}})^{2}}{2 \\sigma_{1}^{2}}}} = -\\frac{(X_{i} - \\mu_{i0})^{2}}{2 \\sigma_{i}^{2}} + \\frac{(X_{i} - \\mu_{i1})^{2}}{2 \\sigma_{i}^{2}} $$E si pu√≤ notare che poi abbiamo il risultato di sopra e diventa sensato avere la forma di Sigmoid, che esce in modo molto molto naturale\nDalla parte in blu capiamo che √® una cosa lineare, perch√© se √® maggiore di zero allora √® meglio la probabilit√† di stare da una parte rispetto all\u0026rsquo;altra.\nFunzione di Sigmoid üü© Questo ci d√† una motivazione del motivo per cui utilizziamo $$ \\text{ Funzione di sigmoid: }\\sigma(x) = \\frac{1}{1 + e^{-x}} $$ Questa funzione si pu√≤ vedere come un caso particolare di [Softmax Function](/notes/softmax-function). $$ \\sigma'(x) = \\sigma(x) (1 - \\sigma(x)) $$$$ P(Y=1|x,w) = \\sigma\\left( w_{0} + \\sum_{i} w_{i}x_{i} \\right) $$Possiamo scrivere la probabilit√† di ogni singolo campione come in figura sotto\nFunzione di loss üü© Che sembra una cross-entropy classica, che per√≤ non ha una soluzione analitica, per questo motivo si utilizza **discesa del gradiente**. Ottimizzazione discesa del gradiente Intuizione sul gradiente üü© abbiamo alla fine che il gradiente √®\n$$ \\frac{\\delta \\mathcal{L}(w)}{\\delta w_{i}} = \\sum_{l} x^{l}_{i} \\cdot (y^{l} - \\alpha^{l}) $$ Perch√© gi√† $(y - \\alpha)$ sta misurando in un certo senso la differenza (l\u0026rsquo;errore), e il prodotto lo sta legando all\u0026rsquo;input preciso, quindi √® molto bello quando la formula √® interpretabile in modo fisico quasi.\n$$ \\nabla_{w} \\ell(w)(x, y) = [\\sigma(w \\cdot x) - y]x $$Calcolo del gradiente cross entropy üü®++ $$ a^{l} = \\sigma\\left( w_{0} + \\sum_{i} x_{i}w_{i} \\right) = \\sigma(z) $$$$ \\sum_{l} \\log P(Y= y^{l} | x ^{l}, w) = \\sum_{l} y^{l}\\log(\\alpha^{l}) + (1- y^{l})(1 - \\log(\\alpha^{l})) $$ Dalla formula di sopra riscritta in altro modo.\nQuesto √® esattamente poi quanto sar√† fatto durante il percettrone, per l'aggiornamento delle variabili in quelle istanze. Fase update del gradiente üü© $$ \\frac{\\delta \\mathcal{L}(w)}{\\delta w_{i}} = \\sum_{l} (y^{l} - \\alpha^{l}) x^{l} $$ Possiamo usare questa per aggiornare il peso di $w_{i}$\n$$ w_{i} = w_{i} + \\mu \\frac{\\delta \\mathcal{L}(w)}{\\delta w_{i}} $$$$ w_{i} = w_{i} + \\mu \\frac{\\delta \\mathcal{L}(w)}{\\delta w_{i}} + \\mu \\lambda|w_{i}| $$ Che implica il fatto che se abbiamo un singolo peso grande, far√† molta fatica ad esserci nel regolarizzatore (quindi ho meno varianza fra i pesi diciamo).\n","permalink":"https://flecart.github.io/notes/logistic-regression/","summary":"\u003cp\u003eQueste note sono molto di base. Per cose leggermente pi√π avanzate bisogna guardare \u003ca href=\"/notes/bayesian-linear-regression/\"\u003eBayesian Linear Regression\u003c/a\u003e, \u003ca href=\"/notes/linear-regression-methods/\"\u003eLinear Regression methods\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"introduzione-alla-logistic-regression\"\u003eIntroduzione alla logistic regression\u003c/h2\u003e\n\u003ch3 id=\"giustificazione-del-metodo\"\u003eGiustificazione del metodo\u003c/h3\u003e\n\u003cp\u003eQuesto √® uno dei modelli classici, creati da \u003cstrong\u003eMinsky\u003c/strong\u003e qualche decennio fa\nIn questo caso andiamo direttamente a computare il valore di $P(Y|X)$ durante l\u0026rsquo;inferenza, quindi si parla di modello \u003cstrong\u003ediscriminativo\u003c/strong\u003e.\u003c/p\u003e\n\u003ch4 id=\"introduzione-al-problema\"\u003eIntroduzione al problema\u003c/h4\u003e\n\u003cp\u003eSupponiamo che\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$Y$ siano variabili booleane\u003c/li\u003e\n\u003cli\u003e$X_{i}$ siano variabili continue\u003c/li\u003e\n\u003cli\u003e$X_{i}$ siano indipendenti uno dall\u0026rsquo;altro.\u003c/li\u003e\n\u003cli\u003e$P(X_{i}| Y= k)$ sono modellate tramite distribuzioni gaussiane $\\mathbb{N}(\\mu_{ik}, \\sigma_{i})$\n\u003cul\u003e\n\u003cli\u003eNOTA! la varianza non dipende dalle feature!, questo mi permetterebbe di poi togliere la cosa quadratico dopo, rendendo poi l\u0026rsquo;approssimazione lineare\u003c/li\u003e\n\u003cli\u003ePer esempio se utilizziamo nelle immagini, avrebbe senso normalizzare pixel by pixel, e non image wide con un unico valore, √® una assunzione, che se funziona dovrebbe poi far andare meglio la regressione logistica!\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e$Y$ √® una distribuzione bernoulliana.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCi chiediamo come √® fatto $P(Y|X)$?\u003c/p\u003e","title":"Logistic Regression"},{"content":"LR(k) Grammatiche LR(k) üü© Anche in questo caso proviamo a generalizzare il concetto dei pirmi k caratteri, in modo da generalizzare in qualche senso il concetto di LR(k), quindi andiamo a modificare la closure considerando ora first k\nPer ricordarti come si calcolava first k, andare a guardare Top-down Parser\nil problema che poi diventa pratico riguardo questo √® l\u0026rsquo;impossibilit√† di gestire stringhe lunghezza k che sono una assurdit√† (esponenziale per la lunghezza)\nGrammatiche SLR(k) üü© Uguale a SLR(k), ma possiamo andare a fare il reduce solamente quando il nostro terminale di interesse appartiene al follow k!\nGrammatiche LALR(k)üü®+ Questo √® esattamente identico a LALR, si va a considerare il concetto di nucleo, e questo concetto di nucleo √® uguale al precedente speigato in Bottom-up Parser -LR(1)\nClassificazione dei linguaggi Gerarchia generale üü® Da qui si pu√≤ creare una semplicissima gerarchia dei parser, che si possono riassumere in\n$$ \\forall k, SLR(k) \\subset LALR(k) \\subset LR(k) $$E oltre questo inclusioni per ogni k, rispetto al k minore e la non inclusione. Questo riassume il tutto. Con qualche intersezione con LL k\nNote sulla classificazione (!!) üü® √à molto pi√π facile classificare un linguaggio invece che grammatica potrei avere delle grammatiche che non siano LL(k), mentre il linguaggio che genera lo √®\nEsiste grammatica non ambigua non deterministica!\nQuesto √® il punto motivatore per cui andiamo a concentrarci sui linguaggi invece che sulle grammatiche, ci possono essere delle miriadi di grammatiche per uno stesso linguaggio e il fatto che possano anche non essere deterministiche non ci aiuta molto in questa analisi:\n$$ S \\to aSa | bSb|\\varepsilon $$Si pu√≤ vedere subito il conflitto shift reduce al primo passo, persino con un parser LR(1).\nTeoremi sulla classificazione dei linguaggi\nImportante l\u0026rsquo;equivalenza del fatto che $LL(k) \\equiv SLR(1)$, qualunque sia k! posso andare a costruire una grammatica equivalente che sia in grado di fare ci√≤. (credo valga anche LR(k) = SLR(1), dato che √® un sse per entrambi riguardo linguaggi liberi deterministici).\nUna altra nota interessante √® che tutte le gramamtiche che sono SLR(1) oppure LR(k) allora sono non-ambigue e deterministiche. la cosa importante di queste proposizione √® che ambiguit√† ‚Üí impossibile LR o LL!\nGli SLR(1) ci piacciono in modo particolare üôÇ, hanno una grandissima capacit√† espressiva ma √® probabile che la grammatica che √® riconosciuta da questo sia estremamente complessa e difficile da modellizzare diciamo, per questo motivo conviene utilizzare grammatiche LR k con k alto, se mi crea un parser pi√π carino.\nPropriet√† di (non) chiusura (3)üü©- Le osservazioni di maggior rilievo riguardo questo sono\nUnione di linguaggi LL 1 pu√≤ non essere LL 1 Union edi linguaggi LR 0 pu√≤ non essere LR 0 Concatenazione di LL 1 pu√≤ non essere LL 1 Quindi un sacco di nozioni negative!\nYACC In modo simile a quanto presentato per Lex in Lex/Flex e Yacc. Yacc √® l\u0026rsquo;equivalente utilizzato per i Parser.\nCollaborazione con LEX Solitamente YACC non √® impiegato da solo, ma in stretta collaborazione col LEX.\nInfatti esistono delle funzioni yylex() e la variabile yylval che sono spesso utilizzate per gestire il tempo di lettura diciamo.\nyylex - chiedi il prossimo token yylval - puntatore nella tabella dei simboli dell‚Äôultimo lessema.\nDescrizione input e output üü® Prende un programma in questo linguaggio yacc, in cui √® presente la descrizione della grammatica libera che si vuole andare a riconoscere, e d√† in output un programma che sia in grado di riconoscere quella grammatica\nQuesto programma pu√≤ essere compilato, e poi sar√† in grado di ricevere in input alcuni token e crearci un albero di derivazione.\n(ma alla fine dipende l‚Äôuso che vogliamo andare a farci:\nSe vogliamo creare un interprete, possiamo dare la valutazione dell‚Äôalbero Se vogliamo andare a creare un compilatore potrebbe essere codice intermedio oppure l‚Äôalbero di derivazione. (questa roba √® descritta in azione semantica del matching.) In realt√†\nCome abbiamo detto nel documento precedente, yacc lavora in strettissimo contatto con il lexer, al quale chiede di volta in volta altri token ogni volta in cui ne ha bisogno, quindi chiede sul momento!\nCondivisione di variabili!\nStruttura di un file Yacc (4) https://www.ibm.com/docs/en/aix/7.1?topic=information-example-program-lex-yacc-programs\nPrologo (defines) Definizioni (token o operatori) Regole con azioni semantiche Funzioni ausiliarie (utilizzate in azioni semantiche spesso). Esempio di un file YACC Sintassi regole e funzioni ausiliarie Le regole sono proprio nella forma\nnonterm: corpo1 ‚Üí azione semantica\ncorpo2 ‚Üí azion sem 2‚Ä¶ etc‚Ä¶ molto simile a quanto faceva lex.\nRiguardo alle funzioni ausiliarie di solito √® compilato insieme a lex, e linkati assieme, altrimenti se non c‚Äô√® viene generato in automatico un yylex().\nAzione semantica √à la parte di codice eseguito una volta che si √® trovato un altro pezzo dell‚Äôalbero (ricorda che vanno in contemmporanea).\nQuesto potrebbe dare un valore semantico diverso a seconda del metodo che stiamo andando ad utilizzare diciamo.\nAlbero sintattico Valutazione Codice intermedio. Default risoluzione conflitti Slide Come prima regola per la risoluzione dei conflitti si considera l‚Äôassociativit√† degli operatori, poi l‚Äôordine di dichiarazione (precedenza) se non sbaglio l‚Äôoperatore dichiarato pi√π tardi ha la precedenza su quelli dichiarati prima.\nSe ci sono ancora delle ambiguit√† dopo queste dichiarazioni allora si va alla risoluzione di default.\nSe ci sono alcune forme di conflitti shift/reduce o reduce/reduce vengono risolti in questo modo:\nShift-reduce viene sempre risolto in favore alla shift\nReduce reduce viene risolto col reduce listato prima (quindi una forma di precedenza).\n","permalink":"https://flecart.github.io/notes/lrk-e-yacc/","summary":"\u003ch2 id=\"lrk\"\u003eLR(k)\u003c/h2\u003e\n\u003ch3 id=\"grammatiche-lrk-\"\u003eGrammatiche LR(k) üü©\u003c/h3\u003e\n\u003cp\u003eAnche in questo caso proviamo a generalizzare il concetto dei pirmi k caratteri, in modo da generalizzare in qualche senso il concetto di LR(k), quindi \u003cstrong\u003eandiamo a modificare la closure\u003c/strong\u003e considerando ora first k\u003c/p\u003e\n\u003cp\u003ePer ricordarti come si calcolava first k, andare a guardare \u003ca href=\"/notes/top-down-parser/\"\u003eTop-down Parser\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eil problema che poi diventa pratico riguardo questo √® l\u0026rsquo;impossibilit√† di gestire \u003cstrong\u003estringhe lunghezza k\u003c/strong\u003e che sono una assurdit√† (esponenziale per la lunghezza)\u003c/p\u003e","title":"LR(k) e YACC"},{"content":"Introduzione Ricordiamo che vogliamo cercare di arbitrare l‚Äôaccesso al canale fisico sottostante. In questo momento andiamo ad assumere di avere gi√† tutto l‚Äôimpianto di trasmissione fisica che abbiamo in Tecnologia Wireless, Modulazione wireless Fisica del Wireless.\nObiettivi: Arbitraggio del singolo canale fisico (la tesi di dottorato del prof era su collision avoidance di wifi). Sia in tempo Sia in spazio (come gestire il segnale mandato nello stesso spazio) Utilizzo minimo di energia Quality of service Adaptive behaviour (come il 6G che vuole andare ad utilizzare AI per fare predizione). Evitare segnale spaghetti o jammed Collisioni fanno sprecare energia ad entrambi (sia ricevente sia sender) bisogna trovare un metodo per fare risoluzione (controllare il sender riguardo la trasmissione, in quanto non sono in grado di trasmettere e ascoltare in modo contemporaneo) Questo si lega alla parte di arbitraggio del canale Ricordiamo che ethernet provava ad ascoltare il segnale e provare a trasmettere, si pu√≤ utilizzare la stessa cosa anche qui? No, ethernet permetteva di ascolatare il segnale nel momento di generazione, mentre wifi non pu√≤, perch√© semplicemente il segnale prodotto localmente √® molto pi√π grande. Inoltre wifi ha anche bisogno di fare multiplexing sullo spazio non solo nel tempo come per l‚Äôethernet.\nAnticollisione primo tentativo Allora, in questa parte continuiamo ad analizzare un protocollo che tenti di evitare la collisione, si pu√≤ utilizzare un sistema simile ad ethernet?\nRisposta negativa: non evita le collisioni Slide fenomeno\nNonostante i senders non sentano niente, c\u0026rsquo;√® interferenza, credo si chiami anche problema del terminale nascosto, perch√© non senti l‚Äôinterferenza (asimmetria di informazioni).\nNon arbitra niente alla fine‚Ä¶ Classificazione accesso multiplo MAC-WIFIüü© Senza contesa, ossia si cerca di evitare la contesa della rete wifi Centralizzati statici, con un coordinatore statico che dica quando puoi comunicare (prenotazioni registrate da un coordinatore) ‚Üí garanzia del servizio Costo coordinatore (centralizzato, quindi se cade cade tutto, facile da attaccare) Costo allocazione statica delle risorse. token-based chi vuole comunicare tiene solamente il token (solo che il rischio √® che si perda il token per una interferenza o simili). Content, provare a prendersi il segnale, o provare finch√© non ci si riesce. Probabilistico √® quello pi√π sicuro dal punto di vista della sicurezza, e ha allocazione dinamica di servizi (provare a comunicare a tempi random, probabilisticamente parlando provandoci cos√¨ prima o poi si comunicher√†). Solo che ha il problema delle collissioni ,quindi sarebbe molto buono questo metodo di allocazioen dinamica con il server centrale (0 collisioni e 0tempi vuoti). Solo che il coordinatore ha un costo. ‚Üí reliability della comunicazione. Deterministico (mi sono distratto a configurare alacritty e non ho capito). Abbiamo un accesso probabilistico in cui si prova a comunciare nel vuoto (nel senso che non si pu√≤ spegnere questa rete, nel caso della presenza di un accesso centralizzato allora si utilizza quella. (ma nessuno paga))\nAloha protocol Funzionamento in breveüü© √à stato uno dei primi protocolli radio presenti. Stiamo parlando di 1970, Abramson1970 era alle Hawaii e aveva solamente dispositivi radio a disposizione, sono le prime sperimentazioni.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Mac Wifi/Untitled 2.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Mac Wifi/Untitled 2\u0026quot;\u0026gt; Il round trip time veniva calcolato, se non riceve l‚Äôack aspetta un tempo un p√≤ random. (il seme sar√† diverso, tipo l‚Äôid della scheda di rete, il tempo di backoff che coincida √® abbastanza basso)\nAnalisi dominio di collisioneüü© Ci vogliamo chiedere quando √® il time frame in cui pu√≤ avvenire una collisione?\nSiano due comunicanti, che devono entrambi trasmettere, se uno trasmette, quando non potrebbe trasmettere l √°ltro per evitare la connessioen? Ci interessa solamente il tempo.\nLa risposta √® semplice, vogliamo solo che sia una dimensione di frame prima e una dimensione di frame dopo: tempo/slot di collisione √® due volte.\nSlide intuizione dominio di collisione\nCon questa osservazione, possiamo cambiare leggermente l\u0026rsquo;algoritmo di aloha al fine di risolvere, o meglio alleviare, il problema della collisione:\nSlotted alohaüü© Lo slotted aloha permette solamente la trasmissione in certi slot di tempo, questo aiuta ad alleviare il problema della collisione:\nHa senso che la dimensione dello slot √® dimensione massima del frame con anche trasmission delay vogliamo andare a contare anche il delay della trasmissione perch√© altrimenti due frames possono comunque influenzarsi fra di loro durante la trasmissione.\nSlide slotted aloha\nQuindi ora il tempo di vulnerabilit√† √® ridotto a slot + propagation, invece che due slots (anche se solitamente pensavo che il tempo di propagazione √® maggiore? Credo dipenda‚Ä¶).\nCSMA Carrier sense multiple access\nIntroduzione all\u0026rsquo;algoritmoüü© In questo caso il FVT (frame vulnerability time) √® due volte il propagation, perch√© se sono dentro a questo intervallo allora non sento il segnale dell\u0026rsquo;altro, che non √® ancora arrivato. Questo valore solitamente √® molto pi√π piccolo rispetto al frame size.\nSlotted CSMAüü© Alla fine molto simile questa idea allo slotted aloha, tutti possono trasmettere soltanto in certi slots di times\nThroughput comparisonüü© Vediamoc he il throughput cambia molto seguendo i protocolli (e va gi√π perch√© ci sono troppe collisioni se provo a trasmettere troppo.\nMi serve sapere il numero di stazioni trasmittenti, una cosa che non conosco generalmente.\nMACA hidden and exposed terminals üü© Vogliamo cercare di limitare le trasmittenti a comunicare bene con un ricevitore (sto ragionando sull esempio di ACBD in mezzo) cio√® in un caso di hidden terminal in cui due senders non si sentono fra di loro, ma il loro segnale potrebbe interferire in un certo punto.\nUn problema opposto √® il exposed terminal quando il sender √® condiviso da pi√π host, un host che vorrebbe comunicare, a un host diverso, non pu√≤ comunicare perch√© sente questo.\nRTS and CTSüü®++ Un altro problema di hidden terminal oltre alla trasmissione su un terminale comune √® il fatto che se CB provano a comunicare a persone differenti (rispettivamente ad A e D, B non pu√≤ perch√© sente ricevere).\nUna soluzione semplice √® semplicemente chiedere al canale ricevente se ci sono interferenze o meno. (un pacchetto breve che si chaiama RTS (request to send).) questo √® un piccolo pacchetto, potrebbe interferire, si spera che faccia molti pochi interferenze.\nIl ricevitore risponde con un CTS (clear to send) Se il cts √® ricevuto allora comincia a rispondere.\n‚Üí Non ho carrier sensing qui.\nRTS and CTS drawback Non abbiamo garanzia di comunicazione senza interferenze, questa garanzia c\u0026rsquo;√® solamente quando il range di comunicazione sono uguali fra di loro, un esempio in cui non funziona √® l‚Äôesempio qui sotto in cui esiste una rete grande ch epossa andare a fare interferenza con tutte. MACAW Voglio ritardare il RTS in un tempo casuale in modo che non sovrappongano fra di loro. C\u0026rsquo;√® carrier sensing **per gli acks, posso spedire solo quando mando RTS cos√¨ posso ricevere ack in silenzio. Gli altri quando sentono dovrebbero restare in silenzio.\nRTS Carrier sensing (anche questa credo sia la cosa nuova, il sistema RTS/CTS √® lo stesso di MACA) backoff (questa √® l‚Äôunica cosa nuov acredo). L‚Äôunico che ha preso la RTS sar√† l‚Äôunico a comunicare, gli altri stanno in silenzion perch√© sentono il canale occupato.\nSi pu√≤ settare il RTS threshhol superiore alla soglia per dire che non verr√† mai utilizzato.\nChe √® molto simile a un coordinator function with backoff, solo che questo √® senza infrastruttura, mentre nell\u0026rsquo;altro credo ci sia.\nAd hoc networks Ci sono delle cose nuove che sono delle veicole infrastructures ossia in realt√† non esisterebbe una infrastruttura per questa connessione, ma passa da veicolo a veicolo quindi √® una comunicazione locale. fino a un certo punto in cui alla fine si comunica con una infrastruttura. Come se le auto stesse fossero diventati dei sensori del traffico (quindi molte auto ferme riescono a dire se c\u0026rsquo;√® troppo traffico o meno.\nnon sono ancora diffusi questi servizi, ma stanno arrivanto, u n altro metodo √® fare unit√† di ricarica per i veicoli.\nC\u0026rsquo;√® una trasmissione con CSMA/CA , poi c\u0026rsquo;√® una fase di contention in cui si potrebbero trasmettere cose e cose di altro tipo. ci otrebbero essere un sacco di rts che vadano a vuoto. Ognuna delle fasi di rts √® un passaggio indipendente in cui si rischia ancora la collisione.\nMa quando trasmette indietro potrei avere delle (la collisione :\nFast forward intra-stream in cui il RTS del nodo successivo √® interpretato dal nodo davanti come se fosse un ACK, questo risolve il problema delle interferenze (la fase di contesa non ci sarebbe pi√π). (c\u0026rsquo;√® un campo che rappresenta il tipo di questo segnale, che valga sia come ack sia come rts). Quick exchange inter-stream, se i due nodi intermedi hanno cose da scambiarsi in direzioni diverse, potrebbe essere una buonissima soluzione il fatto di scambiarsi i dati nello stesso stream di dati (dopo l\u0026rsquo;ack di una direzione viene mandato il dato dell\u0026rsquo;altra direzione). Se uno cade allora c\u0026rsquo;√® tempo vuoto e viene interpretato come autorizzazione alla trasmissione\nCarrier sensing virtuale Carrier sensing virtuale sapere che il canale sia occupato senza andare ad ascoltarlo? Appena sentono un RTS, e se sanno la lunghezza del campo di trasmissione classico (Network Allocation Vector NAV) allora sicuramente nessuno ascolta il canale.\nQuesto fa risparmiare batteria al destinatario. E trasmettere prende un sacco di energia, anche solamente andare ad ascoltare consuma.\nFAMA Voglio utilizzare una soglia adattiva oltre la quale comincio ad utilizzare il meccanismo rts/cts. Solitamente questo mi serve quando ho troppe connessioni.\nSe il frame √® minore di una soglia allor anon ha bisogno di rts/cts, altrimenti ha bisogno.\nAnche questo √® per reti ad hoc.\nCoordinator functions Ci sono principalemente due meccanismi che vanno a regolare l‚Äôaccesso al canale C‚Äô√® l‚Äôaccess point che fa un beacon e che rende possibile la coordinazione (cose come il nome della rete e annuncio della sua esistenza √® il beacon che sempre ogni tanto manda il beacon!).\nUna volta fatto una comunciazione coordinata d√† il temop alla DCF. In questo momento l‚ÄôAP non comunca\nPoint coordination functionüü© Slide PCF\nQuando esiste un access point che cerchi di evitare le collisioni e governi tutto la comunicazione nel canale.\nQuesta cosa √® bella perch√© funziona anche se muore l\u0026rsquo;access point. Ma alla fine l‚Äôunica cosa rimasta √® la DCF, quindi abbiamo molte pi√π collisioni. (perch√© creare firmware era molto costoso).\nInter-Frame spaces \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Mac Wifi/Untitled 13.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Mac Wifi/Untitled 13\u0026quot;\u0026gt; Point, ditributed and short,, sono una ddurata di tempo in cui carrier sensing deve avere vuoto prima di poter tentare di comunicare.\nShort IFS SIFS tempo prima di autorizzare la comunicazione qualcuno che sa gi√† che deve parlare a seconda del contesto (e dovrebbe essere solamente un unico host) Se non parte significa o che sia morto o non ci sia nessuno. E Questo √® necessario per avere un PIFS Point IFS PIFS questo √® il tempo per far parlare l\u0026rsquo;access point. se nemmeno questo c\u0026rsquo;√® (ad esempio se l\u0026rsquo;access point vuole permettere la comunicazione contesa) allora il tempo aumenta e diventa un difs. (pu√≤ essere che trasmettino un polling, con l\u0026rsquo;id di quello che deve andare a trasmettere). Distributed IFS DIFS Questo √® come dire un liberi tutti quindi si rientra al tempo di contesa del WIFI. Distributed coordination functionüü© Spazio RTS-CTS anche adattivo con una soglia\nTempo √® avoidance con carrier sensing, in un ambiente distribuito. In questo caso tutti provano a comunicare, finch√© non ci riescono.\nLo slot non √® l\u0026rsquo;intero frame come in ALOHA, ma solamente il tempo di propagazione (esempio il tempo necessario per la luce in 100 metri), gli slots sono messi in questo senso. Nello slot successivo sicuramente il tentativo √® stato ricevuto.\nil backoff √® basato sul numero di questi slot vuoti che abbiamo ascoltato. E se vado a 0 allora mi metto a comunicare in modo descritto da sopra.\nIl numero degli slot dovrebbe dipendere dal numero di comunicanti questo non √® a priori definito (e non √® nemmeno possibile stimarla secondo il prof).\nGestione del back-offüü© Il backoff √® via via crescente, si potrebbe dire che sia la come la dimensione della finestra di contesa CW = contention window che √® diversa rispetto alla congestion window, per√≤ il signfiicato √® completamente diverso! Congestion trattato in Livello di trasporto serve per mandare tot frammenti allo stesso tempo senza far esplodere il router (il livello √® diverso!) mentre ora siamo a livello fisico, e si prova a comunicare localmente.\nLa cosa brutta √® che deve andare a sperimentare contesa per sapere quanta contesa ci sia! Per questo motivo si dice che non sia efficiente: se il canale √® occupato con questo metodo ci provi lo stesso e quindi vai a disturbare.\nQuando va a 0 allora io faccio proprio la tramissi contione e aspetto ack, se arrivo √® ok, altrimenti si aumenta timer nel backoff e si rif√†. Continua finch√© non ce la fai.\n","permalink":"https://flecart.github.io/notes/mac-wifi/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003cp\u003eRicordiamo che vogliamo cercare di \u003cstrong\u003earbitrare l‚Äôaccesso al canale fisico sottostante\u003c/strong\u003e. In questo momento andiamo ad assumere di avere gi√† tutto l‚Äôimpianto di trasmissione fisica che abbiamo in \u003ca href=\"/notes/tecnologia-wireless/\"\u003eTecnologia Wireless\u003c/a\u003e, \u003ca href=\"/notes/modulazione-wireless/\"\u003eModulazione wireless\u003c/a\u003e \u003ca href=\"/notes/fisica-del-wireless/\"\u003eFisica del Wireless\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id=\"obiettivi\"\u003eObiettivi:\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eArbitraggio del singolo canale fisico (la tesi di dottorato del prof era su collision avoidance di wifi).\n\u003col\u003e\n\u003cli\u003eSia in tempo\u003c/li\u003e\n\u003cli\u003eSia in spazio (come gestire il segnale mandato nello stesso spazio)\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eUtilizzo minimo di energia\u003c/li\u003e\n\u003cli\u003eQuality of service\u003c/li\u003e\n\u003cli\u003eAdaptive behaviour (come il 6G che vuole andare ad utilizzare AI per fare predizione).\u003c/li\u003e\n\u003cli\u003eEvitare segnale spaghetti o jammed\n\u003col\u003e\n\u003cli\u003eCollisioni fanno sprecare energia ad entrambi (sia ricevente sia sender)\u003c/li\u003e\n\u003cli\u003ebisogna trovare un metodo per fare risoluzione (controllare il sender riguardo la trasmissione, in quanto non sono in grado di trasmettere e ascoltare in modo contemporaneo)\u003c/li\u003e\n\u003cli\u003eQuesto si lega alla parte di arbitraggio del canale\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eRicordiamo che ethernet provava ad ascoltare il segnale e provare a trasmettere, si pu√≤ utilizzare la stessa cosa anche qui? No, ethernet permetteva di ascolatare il segnale nel momento di generazione, mentre wifi non pu√≤, perch√© semplicemente il segnale prodotto localmente √® molto pi√π grande. Inoltre wifi ha anche bisogno di fare multiplexing sullo \u003cstrong\u003espazio\u003c/strong\u003e non solo nel tempo come per l‚Äôethernet.\u003c/p\u003e","title":"Mac Wifi"},{"content":"Definizione ed esempi per macchine astratte üü© Una macchina astratta √® un qualunque insieme di algoritmi e strutture di dati che permettono di memorizzare ed eseguire il linguaggio $L$, quindi una macchina astratta esiste per esguire il proprio linguaggio (inteso come insieme finito di istruzioni primitive che riesce ad comprendere e eseguire).\nSi pu√≤ proprio dire che esiste una simbiosi fra macchina e linguaggio. Si potrebbe dire che la macchina fisica √® soltanto una implementazione FISICA di un linguaggio, ossia una macchina che capisce ed esegue quel linguaggio e che sia solamente un caso particolare della macchina astratta.\nQuesta macchina astratta √® costituita da una memoria e un interprete.\nCome si potrebbe intuire una singola macchina ha un singolo linguaggio ma un linguaggio pu√≤ avere infinite macchine che differiscono per strutture di dati utilizzate nell‚Äôimplementazione!\nMacchina di von Neumann (esempio)\nUna delle prime macchine astratte, in questo caso molto semplice, con un unico bus centrale, e tante cose di mezzo.\nLinguaggio macchina Una macchina fisica √® la realizzazione ‚Äúa fili‚Äù di un particolare algoritmo che, sfruttando alcune strutture dati, √® capace di ‚Äúeseguire‚Äù programmi scritti in un certo linguaggio, detto il linguaggio macchina\nIn pratica √® una implementazione ad hardware, come si vedr√† dopo.\nPossiamo dire che il linguaggio di una certa macchina astratta √® il linguaggio compreso da quella macchina!\nInterpreti e compilatori Interprete üü© L‚Äôinterprete per un linguaggio mantiene la SEMANTICA!\nEsempio di interprete per macchina fisica\nciclo FDE, vedi 3.1.3 Central Control Unit , √® l‚Äôinterprete della macchina hardware, ossia\nDecodifica l‚Äôistruzione che deve andare ad eseguire Esegue quanto deve eseguire (in questo caso recupera gli operandi, esegue e stora). In generale possiamo astrarre questo ciclo FDE fisico utilizzando questi passaggi un poco pi√π astratti\nElaborazione dei dati primitivi (primitivi = che riesce a rappresentare direttamente in memoria) (es ALU che elabora bits, dato primitivo della macchina fisica) Controllo sequenza delle operazioni (es. salti, sposta PC in macchina fisica, chiamate di funzione) Controllo trasferimento di dati (es copia, move, copia bits fra registri (nella macchina fisica registri come MDR e MAR). Gestione della memoria (es pointers, allocazione, ma anche cache fra CPU e simili, rilocazione degli indirizzi e bla bla bla) Esempio MA dell‚Äôhardware\nHa un set istruzioni RISC o CISC eseguibili direttamente dalla parte elettronica\nUna osservazione principale da cui deriva dal concetto di macchina astratta √® il concetto di gerarchizzazione fra le macchine astratte. Un primo esempio √® la microprogrammazione\nSlide interpretativa pura\nCompilatore üü© Slide compilativa pura\nVantaggi e svantaggi Inteprete-compilatore üü©- Vantaggi interpretazione\nImplementazione: Di facile realizzazione rispetto-compilatore Memoria: risparmio in quanto non ho un nuovo programma da memorizzare Flessibilit√†: facile cambiare comportamento in esecuzione (eg. per debugging) (mentre compilatore perde anche dati di debug, come la struttura dell‚Äôinformazione) Svantaggi interpretazione\nLentezza, dato che legge ed esegue insieme\nIn breve\nImplementazione Compilativa-interpretativa üü© Se l\u0026rsquo;interprete della macchina intermedia √® sostanzialmente diverso dall\u0026rsquo;in- terprete di $Mo_{Lo}$, diremo che siamo in presenza di un\u0026rsquo;implementazione di tipo interpretativo. Se l\u0026rsquo;interprete della macchina intermedia √® sostanzialmente uguale all\u0026rsquo; in- terprete di $Mo_{Lo}$ (di cui estende alcune funzionalit√†), diremo che siamo in presenza di un\u0026rsquo;implementazione di tipo compilativo. In generale non si utilizza mai una implementazione di tipo interpretativo pura o pura compilativa.\nNella realt√† üü© Non vengono mai utilizzate soluzioni compilative o interpretative pure, ma si utilizzano sempre cose miste (ad esempio per chiamate input e output si utilizzano chiamate a sistema operativo, che sono solitamente interpretate).\nLa compilazione di solito si utilizza per linguaggi molto simili (√® questa la difficolt√† maggiore per la costruzione di un compilatore), e ci sono alcuni passi che sono simulati (quindi non compilativa pura).\nMentre l\u0026rsquo;interpretazione √® molto pi√π facile da scrivere (perch√© di solito ho subito molte funzionalit√† del linguaggio attuale), e capita spesso che il codice iniziale venga compilato in un linguaggio intermedio che sia interpretabile.\nNel pratico esistono linguaggi pi√π interpretati che compilati e anche il contrario, oppure entrambi (esempio pascal).\nSchema di compilazione intermedia classico\nA seconda di quanto il linguaggio della macchina intermedia si avvicini al linguaggio sorgente o macchina possiamo definire le sfumature di linguaggio interpretato o compilato. vedi 20pg libro. (1.2.3)\nImplementazione via Kernel üü®- Facciamo solamente degli accenni a come si fa a creare compilatori o interpretatori\nSi implementa un linguaggio intermedio, il cui compilatore o interprete √® molto facile da fare $H$.\nPoi si costruiranno compilatori o interpreti che avranno come target questo linguaggio, quindi questo linguaggio sembra un linguaggio intermedio quasi.\nSlides\nBoostrapping üü®+ Implementazione delle macchine astratte Esistono 3 modi principali per realizzare l‚Äôimplementazione di una macchina astratta:\nImplementazione tramite Hardware Emulazione tramite micro-programmazione (firmware) Interpretazione tramite Software Hardware üü© L\u0026rsquo;implementazione hardware √® spesso\npoco flessibile, dato che capisce solamente questo linguaggio.\nMolto veloce, dato che esegue a livello hardware le sue istruzioni.\nNota influenza linguaggio astratto in linguaggio hardware\nCi√≤ non toglie che vi siano molti casi in cui la struttura della macchina astratta di un linguaggio di alto livello ha influenzato la realizzaz√¨one di un‚Ä¢architettura hardware, non nel senso di una diretta realizzazione in hardware della macchina astratta, ma nella scelta di operazioni primitive e strutture dati che permettessero una pi√π semplice e efficiente realizzazione dell\u0026rsquo;interprete del linguaggio di alto livello. Questo √® il caso, ad esempio, dell\u0026rsquo;architettura del B5500, un computer degli anni \u0026lsquo;60, influenzata dalla struttura del linguaggio ALGOL.\nMicroprogrammazione üü©- Pu√≤ essere (soprattutto nelle macchine NON-risc) in cui alcune istruzioni non sono esattamente eseguibili dall‚Äôhardware, ma l‚Äôinterprete decodifica l‚Äôistruzione in pi√π istruzioni al livello inferiore, ora queste istruzioni sono eseguibili.\nL‚Äôinterprete del linguaggio di questo livello √® solitamente scritto in un linguaggio di livello inferiore. Di solito la microprogrammazione √® fatta a livello firmware. Questa microprogrammazione √® spesso depositata in una zona di memoria adibita alla sola lettura (ROM).\nCi√≤ permette una flessibilit√† maggiore rispetto all‚Äôimplementazione a livello hardware, e tiene una velocit√† maggiore rispetto all‚Äôimplementazione tramite software (per√≤ resta sempre un linguaggio a basso livello vicino alla macchina).\nMotivo storico della microprogrammazione\nMacchina ospite - software üü© √à possibile implementare tramite software una macchina astratta su una macchina ospite. Ossia una macchina che appunto ospita una macchina astratta con un proprio linguaggio. Solitamente questa macchina con questo linguaggio compila in un linguaggio della macchina ospite, in modo che sia eseguibile. Ecco che da qui si pu√≤ vedere una gerarchizzazione.\nmacchina con Linguaggio di alto livello ‚Üí macchina di altro livello ‚Üí ‚Ä¶ ‚Üí macchina fisica che esegue.\nMoltissima flessibilit√†\nVelocit√† leggermente minore\nLivello di interpretazione/traduzione in pi√π\nEsempio di astrazione solita\n","permalink":"https://flecart.github.io/notes/macchine-astratte/","summary":"\u003ch3 id=\"definizione-ed-esempi-per-macchine-astratte-\"\u003eDefinizione ed esempi per macchine astratte üü©\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eUna macchina astratta √® un qualunque insieme di algoritmi e strutture di dati che permettono di memorizzare ed eseguire il linguaggio $L$, quindi una macchina astratta esiste per esguire \u003cstrong\u003eil proprio linguaggio\u003c/strong\u003e (inteso come insieme finito di istruzioni primitive che riesce ad  comprendere e eseguire).\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eSi pu√≤ proprio dire che \u003cem\u003eesiste una simbiosi\u003c/em\u003e fra macchina e linguaggio. Si potrebbe dire che la macchina fisica √® soltanto una implementazione FISICA di un linguaggio, ossia una macchina che capisce ed esegue quel linguaggio e che sia solamente un caso particolare della macchina astratta.\u003c/p\u003e","title":"Macchine Astratte"},{"content":"Introduzione ai campi magnetici Introduzione storica (non impo) üü© Il magnetismo √® stato in primi osservato e documentato da Greci, che hanno osservato che materiali metallici come ferro, questo √® successo in magnesia, una penisola dell\u0026rsquo;Asia minore, mentre elettro era pi√π sull\u0026rsquo;ambra, che credo fosse il nome dato a quel materiale.\nUna cosa nota era che se vicino a un materiale magnetico, venivano create linee con materiale ferroso all\u0026rsquo;estremit√† (limatura magnetica).\nUna altra cosa, conosciuta dai cinesi, era che un materiale magnetico si orientava sempre sullo stesso verso, per cui possiamo chiamare polo magnetico sulla barretta. E si chiamavano poli nord e sud geografici. Si pu√≤ paragonare a un Dipolo elettrico. E permette di analizzarlo come se fosse una carica magnetica. abbiamo quindi un dipolo magnetico, almeno matematicamente analizzabile in questo modo.\nSperimentalmente si √® osservato che *poli stesso segno si respingevano e di valore opposto si attraevano in modo simile a quanto succedeva per Legge di Coulomb. Solo che in questo caso non ha senso parlare di unit√† di carica che la genera diciamo. C\u0026rsquo;√® la teoria del monopolo ma poi quella non so quanto sia effettivamente vero.\nFino al 1800 questo √® quanto si sapeva, dopo si ebbe uno studio sistematico, permesso da un progresso tecnologico (forse direi ingegneristico), grazie alla pila di Alessandro Volta, con l\u0026rsquo;inizio dello studio dei circuiti. Con lo studio dell\u0026rsquo;interazione del campo magnetico ed elettrico si hanno i bei risultati :).\nCampo magnetico terrestre üü© La terra si comporta come un magnete gigante :D. E creer√† momenti di dipolo per i magnetini presenti sulla superficie. ma nota: il polo sud geografico, in realt√† √® il polo nord magnetico! E anche il contrario. Esiste anche una versione periodica (non definita), ogni qualche milioni di anni. Si nota da come si sono solidificati i magma nel tempo (si solidificher√† in un certo modo). La teoria pi√π buona √® che ci sono delle specie di dinamo all\u0026rsquo;interno della Terra che generano il campo. Il monopolo magnetico üü© $$ \\lvert \\vec{F} \\rvert = k_{m} \\frac{C_{m}^{1}C_{m}^{2}}{r^{2}} $$ Per il Dipolo elettrico √® facile questo, basta prendere il dipolo e separarlo! Come si fa per il monopolo? Se taglio una calamita in due, avr√≤ due nuove calamite, questa caratteristica continua anche a livello atomico -\u0026gt; non esistono monopoli magnetici secondo questa scia La ricerca del monopolo magnetico √® molto sentita, perch√© il modello standard prevede l\u0026rsquo;esistenza di questi monopoli per√≤ sperimentalmente non sono stati rilevati ancora. Questa cosa motiva che la legge simile a Coulomb √® abbastanza inutile. NOTA: essendo la legge sperimentalmente sempre inversamente proporzionale a $r^{2}$ si pu√≤ utilizzare la Legge di Gauss. Condizione necessaria per far funzionare la dimostrazione con angoli solidi.\nL\u0026rsquo;induzione magnetica e dipolo magnetico üü© Partendo da conoscenze presenti per il Dipolo elettrico possiamo andare a definire il campo magnetico come la linea individuata dai dipoli magnetici, perch√© i dipoli si allineeranno in qualche modo quando sono dentro un campo magnetico. Con la convenzione che entra in sud ed esce in nord. In un certo senso il sud √® equivalente al - del dipolo elettrico e il nord al +.\nQuesto √® il campo di induzione magnetica chiamato $\\vec{B}$\nFigure descrittive di quanto detto sul campo magnetico, in ordine vediamo i campi, molto simili a quelli che si possono trovare per il dipolo, e l\u0026rsquo;allineamento di dipoli . Si pu√≤ anche avere un ferro di cavallo per avere un campo uniforme. Campo solenoidale üü© $$ \\oint_{\\Sigma}\\vec{B} \\cdot \\vec{s} = \\frac{M_{tot}}{k} = 0 $$ Che √® la definizione di un campo solenoidale, ossia sempre 0 per qualunque superficie.\n$$ \\vec{\\nabla} \\cdot \\vec{B} = 0 $$ √à anche chiamata la seconda legge di Maxwell.\nRiguardo alla circuitazione, basta prendere un percorso sulla stessa linea (il campo √® sempre sullo stesso verso, anche fra i poli (cosa che invece per dipoli elettrici non √® vero)), √® diverso da zero, quindi il campo che abbiamo non √® conservativo, questo √® sempre vero per campi solenoidali. Questo √® quanto si sapeva all\u0026rsquo;inizio del 800, fine 700.\nCi dice che non ci sono monopoli magnetici, perch√© √® una parte della materia (√® il singolo atomo che √® un dipolo, per questo si distrugge tutto), i dipoli non sono altro che correnti elettriche in materiali!\nDa approfondire: In Diamagnetici √® Larmor in Magnetismo nella materia. In paramagnetici √® corrente intrinseco In ferromagnetici √® lo spin degli elettroni\nEsperimenti storici Facciamo una carrellata fra esperimenti storici che hanno relazionato correnti e cambi magnetici e hanno contribuito a una migliore comprensione del motivo per cui abbiamo certi fenomeni. Attorno al 1820 questi esperimenti, poi nel 1865 Maxwell enuncia le leggi, in poco tempo conosciamo del tutto tutti i fenomeni di elettromagnetismo classico.\nEsperimenti di Oersted üü© Un filo percorso da corrente genera un campo magnetico\nQuesto √® un primo collegamento col campo elettrico! Come fanno cariche che si muovono a creare campo elettrico?\nOersted ha messo un magnete vicino a un filo. E ha osservato che se si chiude lo switch del circuito, l\u0026rsquo;ago magnetico gira. Esperimenti di Faraday üü©- Faraday ha poi l\u0026rsquo;intuizione che un magnete pi√π magnete √® in grado di influenzare la corrente, vede che se non c\u0026rsquo;√® corrente √® tutto ok, non succede niente, se per√≤ ci fa scorrere corrente, vede una forza perpendicolare al filo.\nUn filo percorso da corrente si comporta come un magnete\nOssia il filo √® in grado di attrarre il magnete.\nEsperimenti di Ampere üü© Ampere ha avuto l\u0026rsquo;intuizione che pu√≤ trattare fili come magneti, quindi due fili con corrente vicina dovrebbero essere soggette a forza, ed √® effettivamente ci√≤ che nota. E nota anche quanto presente in immagine: se sono verso diverso sono repulsive, altrimenti attrattive. Questo veramente sembra motivare l\u0026rsquo;utilizzo del filo per studiare il campo magnetico. il vantaggio di usare questo √® che\nFacilit√† di costruzione rispetto alla calamita La geometria del filo √® sotto mio controllo L\u0026rsquo;intensit√† di corrente √® modulabile, quindi posso definire l\u0026rsquo;intensit√† del campo nei magneti. Seconda legge di Laplace e Esperimento üü© Definiamo l\u0026rsquo;esperimento come segue, una sbarretta metallica libera di scorrere fra le due e due supporti sopra, sotto abbiamo una batteria. Ci metto un dinamometro, e cos√¨ ho la misura della forza esercitata sulla sbarretta metallica mi serve per misurare la forza del campo magnetico. Nel nostro sistema avremo che la barretta ha lunghezza $d\\vec{l}$, e una corrente che sale e scende (proprio come circuito) Le osservazioni sono:\n$\\lvert d\\vec{F} \\rvert \\propto i \\lvert d\\vec{l} \\rvert$ $d\\vec{F} \\perp d\\vec{l}$ $\\lvert d\\vec{F} \\rvert = f(\\theta)$, dove $\\theta$ √® l\u0026rsquo;orientazione nello spazio di $d\\vec{l}$, e ho sempre un angolo in cui √® 0, che quello uscente dal piano credo. Allora cos√¨ ho definito l\u0026rsquo;interazione del campo $\\vec{B}$ con un filo percorso da corrente $i$. $$ d\\vec{F} = id\\vec{l} \\times \\vec{B} = i\\lvert d\\vec{l} \\rvert \\lvert \\vec{B} \\rvert \\sin \\theta $$ Questo permette ricavare il modulo della forza di B. Posso anche misurare la direzione con l\u0026rsquo;angolo. Questo √® utile per dare la definizione del campo magnetico. Probabilmente la forza √® sulla nuvola di elettroni o portatori di carica dentro al filo quando si muovono. Questo motiva chiedersi quanto sia la forza sul singolo elettrone che si muove:\nCampo magnetico Anche qui vale il principio di sovrapposizione! vedi Campo elettrico.\nAnalisi forza su cariche in movimento üü©- $$ d\\vec{F} = \\vec{J} \\cdot d\\vec{S} \\cdot d\\vec{l} \\land \\vec{B} $$ Ho che $J$ e $dS$ hanno stessa direzione e verso per costruzione, e sarebbe bene prendere stesso verso anche per la lunghezza, mi permette di scrivere $dS$ e $dl$ stesso verso, quindi √® solamente uno scalare, e posso spostarlo in giro nel prodotto vettoriale:\n$$ d\\vec{F} = \\vec{J} \\land \\vec{B} (d\\vec{s} \\cdot d\\vec{l}) = \\vec{J} \\land \\vec{B} d\\tau $$$$ d\\vec{F} = nq\\vec{v}_{d} \\land \\vec{B} d\\tau $$ Ma ricordiamo da Corrente Elettrica che $n$ √® il numero di cariche per unit√† di volume, ma abbiamo l\u0026rsquo;unit√† di volume, quindi $n d\\tau = N$ il numero totale di elettroni in uno spazio molto piccolo $dl$!, quindi abbiamo che\n$$ d\\vec{F} = dNq\\vec{v}_{d} \\land \\vec{B} $$ Questa √® relazione diretta fra chi si muove dentro e la quantit√† di forza che ho! Questa √® la su un segmento di filo infinitesimale!\nForza di Lorentz üü© $$ \\vec{F} = q\\vec{v} \\land \\vec{B} $$$$ \\lvert \\vec{F} \\rvert = \\lvert q \\rvert \\lvert \\vec{v} \\rvert \\lvert \\vec{B} \\rvert \\sin \\theta $$ E la forza totale √® la somma di tutte queste particelle in una sezione di filo!. La nota importante √® che una forza perpendicolare alla direzione della velocit√†, quindi √® una forza centripeta che implica che non pu√≤ cambiare il modulo della forza di $v$. pu√≤ solo cambiare la direzione, il che implica che non fa lavoro!.\n-\u0026gt; La forza di Lorentz non √® posizionale, quindi non ha senso chiedersi se √® conservativa, perch√© tanto lavoro √® sempre 0.\n-\u0026gt; √à una forza media sul portatore di carica, perch√© non posso andare a misurare il singolo portatore, da un punto di vista qualitativo la forza di Laplace √® molto meglio!\nQuesto ci permette di definire una nuova unit√†, che √® il Tesla, ossia quanto campo magnetico per avere 1N di forza su una singola particella di $q$\nForza di Lorentz generalizzata üü© $$ \\vec{F} = q\\vec{E} + q\\vec{v} \\land \\vec{B} $$ Se ho due cariche che stanno ferme, tutta la teoria sviluppata in elettrostatica funziona ancora! Se una delle due, invece, si muove c\u0026rsquo;√® solo elettrostatica ancora\nSistema di due cariche Se entrambe si muovono ho entrambe le forze\nIntroduzione al problema üü© Una cosa strana √® che dipende dal sistema di riferimento perch√© la velocit√† pu√≤ cambiare col sistema. √à un hint sulla correlazione fra i due campi. Come si pu√≤ risolvere questo? Se ho due cariche ferme, ma io mi muovo, allora per me loro si muovono entrambe, e dal mio punto di vista sono soggette anche di forza magnetica sulle cariche.\nQuindi succede che per una carica ho sia forza elettrica, e anche in questo caso una forza magnetica opposta! Mentre per il filo si vede sempre non cambiando anche sistema di riferimento!\nAnalisi della forza caso per caso üü®- Proviamo ad analizzare secondo due sistemi di riferimento, una in cui il sistema √® solidale con le due cariche, una altra con riferimento inerziale, con velocit√† $v$ lungo asse $x$. Per il principio di relativit√† di galileo, dovrei osservare la stessa cosa, vediamo nei due cosa si vede.\n$$ \\vec{F} = q_{1}\\vec{E}_{2} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R_{2}} \\hat{d} $$$$ \\vec{v}_{1} = \\vec{v}_{2} = -v $$$$ \\vec{F}' = q_{1}\\vec{E}_{2} + q_{1}\\vec{v}_{1} \\times \\vec{B}_{2} $$ Quindi abbiamo un campo magnetico generato dal movimento dell\u0026rsquo;altra carica in pi√π.\n$$ \\vec{B}_{2} = \\mu_{0} \\frac{q_{2}}{4\\pi} \\frac{ \\vec{v}_{2} \\times\\hat{r}}{r^{2}} = \\mu_{0} \\frac{q_{2}}{4\\pi} \\frac{ \\vec{v}_{2} \\times -\\hat{k}}{r^{2}} \\implies \\vec{F} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R^{2}} \\hat{d} + \\frac{1}{4\\pi\\varepsilon_{0}} q_{1} v \\cdot \\mu_{0}\\varepsilon_{0} \\frac{q_{2} v \\cdot (-\\hat{d})}{R^{2}} $$ in cui la direzione √® dentro il foglio, per il campo magnetico. Raccogliendo l\u0026rsquo;ultima abbiamo\n$$ \\vec{F} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R^{2}} [1 - \\varepsilon_{0} \\mu_{0} v^{2}] \\hat{d} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R^{2}} \\left[ 1 - \\frac{v^{2}}{c^{2}} \\right] \\hat{d} $$ Questo √® vero perch√© per velocit√† molto piccole √® simile al normale, ma la cosa strana si ha quando cominciamo ad avvicinarci alla velocit√† della luce, perch√© l√¨ cambia! Abbiamo forze diverse in due sistemi di riferimento inerziali!\nCorrelazione E e B per relativit√† galileiana üü®- $$ \\vec{F}' = \\vec{F} \\implies q_{1}\\vec{E}_{2} = q_{1}\\vec{E}_{2}' + q_{1}\\vec{v}_{1} \\times \\vec{B}_{2}' \\implies \\vec{E}_{2} = \\vec{E}_{2}' + \\vec{v}_{1} \\times \\vec{B}_{2}' $$$$ \\vec{B}_{2} = 0 = \\vec{B}_{2}' - \\frac{1}{c^{2}} \\vec{v} \\times \\vec{E}_{2}' $$ Cosa che si deriva utilizzando la relazione campo magnetico ed elettrico. Fino al 1905 si √® convinti di questo.\nCorrelazione E e B per relativit√† ristretta (non fare). La forza tridimensionale non √® un invariante relativistico, ma la forza che conta anche il tempo. (per quella relativit√† non c\u0026rsquo;√® problema che la forza vari).\n$$ \\begin{cases} F_{x}' = F_{x} \\\\ F_{y}' = F_{y} \\sqrt{ 1 - \\frac{v^{2}}{c^{2}} } \\\\ F_{z}' = F_{z} \\sqrt{ 1 - \\frac{v^{2}}{c^{2}} } \\end{cases} $$ Nel momento in cui la velocit√† √® lungo $x$, quindi la forza cambia secondo la radice. Ma nell\u0026rsquo;analisi di sopra non abbiamo il rapporto con la radice, ma velocit√† senza radice, come mai? Anche qui $E$ ha dipendenze con $B$, ma le relazioni sono diverse.\n$$ \\begin{cases} E_{x}' = E_{x} \\\\ E_{y}' = \\gamma [E_{y} - v B_{z}] \\\\ E_{z}' = \\gamma [ E_{y} + v B_{z}] \\\\ B_{x}' = B_{x}' \\\\ B_{y}' = \\gamma [B_{y} + \\frac{v}{c^{2} }E_{z} ] \\\\ B_{z}' = \\gamma \\left[ B_{z} - \\frac{v}{c^{2}} E_{y} \\right] \\end{cases} $$ Dove $\\gamma = \\frac{1}{\\sqrt{ 1 - \\frac{v^{2}}{c^{2}}} }$ Applicando queste trasformazioni nel nostro sistema a due cariche abbiamo che\n$$ E_{y}' = \\gamma E_{y} = \\frac{\\gamma}{4\\pi\\varepsilon_{0}} \\frac{q_{2}q_{1}}{R^{2}} $$$$ B_{z}' = \\frac{\\gamma v}{c^{2}} E_{y} $$ E possiamo sostituirli dentro la legge generale di Lorentz per la forza finale, che √® simile a quella versione di Galileo, un po\u0026rsquo; differente\n$$ F' = q_{1}\\gamma E_{y} + q_{1}v \\frac{\\gamma v}{c^{2}} E_{y} = \\gamma q_{1} E_{y}\\left( 1 + \\frac{v^{2}}{c^{2}}\\right) = q_{1}E_{y} \\sqrt{ 1 + \\frac{v^{2}}{c^{2}} } $$ Questo valore √® proprio il valore predetto come trasformazione secondo la relativit√†?\nPrima legge di Laplace Prima legge di Laplace üü© Vogliamo sapere esattamente quale sia il valore del campo magnetico generato da un filo. Il piccolo tratto di energia sar√† di valore $$ d\\vec{B} = \\frac{\\mu_{0}i}{4\\pi} \\frac{d\\vec{l} \\times \\hat{r}}{ r^{2}} $$ Questa √® la **prima legge di Laplace**. Osservazioni:\nPerpendicolare sempre a l e r, quindi al piano del nostro disegno Permette di capire quale sia il modulo del campo magnetico, e si nota che cade su $\\frac{1}{r^{2}}$ che √® la cosa che permette l\u0026rsquo;utilizzo della legge di gauss per i monopoli magnetici Sulla congiungente della retta dl, il valore del campo magnetico √® 0! Permeabilit√† magnetica del vuoto üü© $$ \\text{permeabilit√† magnetica del vuoto}: \\mu_{0} = 4\\pi \\times 10 ^{7} \\, \\frac{Tm}{A} $$ Scoperta direi in modo simile a quanto fatto per permeabilit√† elettrica nel vuoto! Per Legge di Coulomb\nIl valore del campo magnetico e la forza di un altro filo definiscono il comportamento qualitativo per i campi magnetici!\nCampo magnetico totale üü© Per trovare il valore basta sommare tutti i contributi!\n$$ \\vec{B} = \\int _{Filo} d\\vec{B} = \\int _{Filo} \\frac{\\mu_{0}i}{4\\pi} \\frac{d\\vec{l} \\times\\hat{r}}{r^{2}} $$ In modo simile a quanto fatto in Campo elettrico, se siamo in regime stazionario, la $i$ pu√≤ essere portata fuori dall\u0026rsquo;integrale\nCampo magnetico da singola carica üü®+ $$ id\\vec{l} = \\vec{J} \\cdot d\\vec{s} d\\vec{l} = \\vec{J} \\cdot d\\tau = nq\\vec{v}_{d} d\\tau = Nq\\vec{v}_{d} $$ Quindi ha un valore generato dal totale di cariche in movimento in un unit√† di volume infinitesimo. Questa osservazione ci permette di scrivere la seconda legge in relazione alla velocit√† di deriva: E isolare anche il campo magnetico per singola carica!\n$$ \\vec{B} = \\frac{\\mu_{0}q}{4\\pi} \\frac{\\vec{v}_{d} \\times\\hat{r}}{r^{2}} $$Da qui osserviamo che se si muovono pi√π in fretta allora il campo magnetico va pi√π in fretta! E sappiamo che la velocit√† √® dipendente dal campo elettrico da cui sono sottoposti.\nLegame col campo elettrico üü®+ $$ \\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q\\hat{r}}{r^{2}} \\implies \\frac{q}{r^{3}} = \\vec{E} 4\\pi\\varepsilon_{0} $$$$ \\vec{B} = \\frac{\\mu_{0}\\vec{v}_{d}}{4\\pi} \\times \\vec{E} 4\\pi\\varepsilon_{0} = \\mu_{0}\\varepsilon_{0} \\vec{v}_{d} \\times \\vec{E} = \\frac{1}{c^{2}} \\vec{v}_{d} \\times \\vec{E} $$ E la relazione stupenda √® con la velocit√† della luce, e si nota come queste sono veramente costanti fondamentali dell\u0026rsquo;universo!? √à da notare per√≤ che questo vale solo per valori della velocit√† tali per cui siano molto minori rispetto alla velocit√† della luce. (regimi non relativistici).\n","permalink":"https://flecart.github.io/notes/magnetismo/","summary":"\u003ch3 id=\"introduzione-ai-campi-magnetici\"\u003eIntroduzione ai campi magnetici\u003c/h3\u003e\n\u003ch4 id=\"introduzione-storica-non-impo-\"\u003eIntroduzione storica (non impo) üü©\u003c/h4\u003e\n\u003cp\u003eIl magnetismo √® stato in primi osservato e documentato da Greci, che hanno osservato che materiali metallici come \u003cem\u003eferro\u003c/em\u003e, questo √® successo in \u003cem\u003emagnesia\u003c/em\u003e, una penisola dell\u0026rsquo;Asia minore, mentre \u003cem\u003eelettro\u003c/em\u003e era pi√π sull\u0026rsquo;ambra, che credo fosse il nome dato a quel materiale.\u003c/p\u003e\n\u003cp\u003eUna cosa nota era che se vicino a un materiale magnetico, venivano create linee con materiale ferroso all\u0026rsquo;estremit√† (limatura magnetica).\u003c/p\u003e","title":"Magnetismo"},{"content":"Analisi macroscopica Setting dell\u0026rsquo;esperimento üü© $$ \\vec{F} = -\\vec{\\nabla} \\cdot U \\implies F = -\\vec{\\nabla}(\\vec{m} \\cdot \\vec{B}) = \\pm m \\frac{dB}{dx} $$ La prima relazione si deriva da definizione di lavoro e forza. (esteso al caso di una forza applicata su spira che non √® banale, facciamola brevemente).\n$$ Fds = dW = -dU = i \\nabla \\Phi(B) ds \\implies F = i\\nabla \\Phi(B) = m \\cdot \\nabla B = -\\nabla U $$La cosa da notare √® che per campi uniformi abbiamo che si pu√≤ definire il lavoro.\nComunque questo esperimento √® stato importante per dire che se metto un materiale nella bobina, a volte viene attratta, altre volte respinta, quindi faceva pensare che esiste qualcosa nel materiale che induceva queste cose.\nMagnetizzazione üü© Considerando la forza per unit√† di volume si pu√≤ introdurre la densit√† del momento magnetico, anche chiamata magnetizzazione.\n$$ M = \\frac{m}{\\tau} $$Campo magnetico in materiali $$ \\frac{B}{B_{0}} = k_{m} $$ Simile a quanto abbiamo fatto in Condensatori con dielettrici.\nPermeabilit√† magnetica relativa üü© $$ \\mu = \\mu_{0} k_{m} $$ In modo simile a quanto fatto per la costante dielettrica.\nInterpretazione correnti Amperiane üü© $$ \\vec{B}_{m} = \\mu_{0}\\chi_{m}ni $$ Vedere pagina 272 del Mazzoldi. Ed effettivamente ci sono delle correnti cos√¨ indotte su questo materiale. Si potranno studiare da un punto di vista microscopico dopo.\nSuscettivit√† magnetica üü© $$ \\chi_{m } = k_{m } - 1 $$Classificazione di sostanze magnetiche Diamagnetiche üü© Se $k_{m} \u003c 1$ Ossia le correnti amperiane hanno verso opposto.\nparamagnetiche üü© Se $k_{m} \u003e 1$. In cui si ha anche una dipendenza con la temperatura. A temperatura normale questo sono piccolissime\nFerromagnetiche üü© Quando la differenza √® tipo $10^{3}$, ed √® una relazione non lineare.\nConsiderazioni microscopiche Analisi del momento angolare Questa analisi √® verso pagine 234 del Mencuccini, da fare un po\u0026rsquo; meglio.\nProviamo a considerare il modello di Rutherford (credo), in cui abbiamo un atomo centrale e poi roba (elettroni) che ci girano attorno.\n$$ \\vec{L} = \\vec{r} \\times m\\vec{v}_{e} \\implies L = rm v_{e} $$$$ \\vec{m}= -\\frac{er}{2} \\left( \\frac{\\vec{L}}{rm} \\right) = -\\frac{e}{2m} \\vec{L} $$ Dove si ha una chiara relazione fra momento magnetico (quella cosa necessaria per magnetizzazione) direttamente nel nucleo di un atomo.\nMagnetone di Bohr $$ \\mu_{e} = \\frac{e}{2m} \\hbar $$ dove lo spin √® uguale a $\\lvert S \\rvert = \\frac{1}{2}\\hbar$ Questa costante trovata di sopra √® detta magnetone di Bohr che √® da notare opposta al momento magnetico precedente. Infatti nella maggior parte dei materiali questo si cancella, mentre in alcuni materiali non succede, e abbiamo il paramagnetismo.\nModello diamagnetismo In questo modello si assume che non ci sia momento magnetico intrinseco degli atomi, si pu√≤ dimostrare che abbiamo un moto di precessione:\nAbbiamo\n$$ \\vec{M} = \\vec{m} \\times \\vec{B} = -\\frac{e}{2m} \\vec{L} \\times \\vec{B} $$$$ M = \\frac{dL}{dt} = \\vec{\\omega_{L}} \\times \\vec{L} \\implies \\vec{\\omega_{L}} = \\frac{e}{2m}\\vec{B} $$Dove il secondo √® una velocit√† angolare indotta dal campo magnetico che implica un moto di precessione. Questa √® la precessione di Larmor.\n$$ \\Delta i = -\\frac{e}{T_{L}} = -\\frac{e}{2\\pi}\\omega_{L} = -\\frac{e^{2}}{4\\pi m}B $$$$ \\Delta m = i\\pi r^{2} = -\\frac{e^{2}r^{2}}{4m}B $$ Ora conviene analizzare questo dato da un punto di vista mean field theory e assumere un raggio medio perch√© non conosciamo il valore di $r$ nell\u0026rsquo;orbita di precessione nemmeno il verso rispetto al campo magnetico esterno. Quindi prendiamo una media, assumiamo una simmetria sferica $x^{2} + y^{2} + z^{2} = r^{2}$ che che i tre assi siano equamente equiprobabili, quindi $x^{2} = y^{2} = z^{2} = \\frac{r^{2}}{3}$\nCon questo abbiamo che il raggio medio sulla stessa orbita dell\u0026rsquo;elettrone (piano xy) diventa ora $r_{i}^{2} = x^{2} + y^{2} = \\frac{2}{3} r^{2}$ Se messo dentro l√¨ sopra abbiamo ora\n$$ \\Delta m = -e^{2} \\frac{r^{2}}{6m} B $$E nel caso ci siano pi√π elettroni prendiamo un raggio medio, e si avr√† lo stesso valore.\nApproccio in classe non compreso (non fare) $$ \\omega_{0} = \\frac{v}{r} = \\frac{L}{r^{2}m_{e}} $$$$ i = -\\frac{e}{T}, \\vec{m}_{0} = -\\frac{e}{T} \\pi r^{2} \\hat{u}_{n}, v = \\omega r, L = r m_{e} \\omega r = m_{e} \\omega r^{2} $$$$ T = \\frac{2\\pi}{\\omega} = \\frac{2\\pi}{L} r^{2}m_{e} $$ Utilizzando quanto avevamo ricavato prima sulla velocit√† angolare dell\u0026rsquo;elettrone.\n$$ \\vec{m}_{0} = i \\Sigma = -\\frac{e \\vec{L}}{2m_{e}} $$Nel momento in cui una sostanza √® in un campo magnetico, sar√† generata una corrente che si oppone, e si avr√† una forza repulsiva, questo c\u0026rsquo;√® sempre in tutto.\nOgni atomo crea un momento magnetico all\u0026rsquo;interno del suo atomo.\nAltre cose, abbiamo che\n$$ \\vec{M} = i\\vec{S} \\times \\vec{B} = \\vec{\\omega_{L}} \\times \\vec{L} $$ Noi dovremmo essere in grado di sapere quanto sia la corrente e la superficie e in questo modo dovrei riuscire a ricavare omega.\nLe sostanze diamagnetiche vengono solo respinte. (??)\n$$ \\vec{m}_{L} = -\\frac{e^{2}}{6m_{e}} \\left( \\sum_{i=1}^{z} r_{i}^{2} \\vec{B} \\right) $$$$ \\omega_{L} = \\frac{eB}{2m_{e}} $$ E vorremmo chiederci se la frequenza di Larbor sia maggiore o minore rispetto a quella iniziale. E si scopre in qualche modo che se $B \\ll 5 \\times 10^{5} T$ si avr√† che il periodo di Larbor √® molto piccolo rispetto a quello iniziale. E nella realt√† max 100 tesla, e non si riesce a raggiungere.\nTutta la parte sopra dovrebbe essere fatta prima pagina 274 del mazzoldi.\nLarmor üü®\u0026ndash; Quando proviamo a definire il momento angolare, tramite una velocit√† angolare e inerzia, introduciamo la velocit√† angolare di Larbor\n$$ \\vec{M} = \\vec{\\omega}_{L} \\times \\vec{L} $$$$ \\vec{M} = \\vec{m}_{0} \\times \\vec{B} = \\vec{\\omega}_{L} \\times \\vec{L} $$$$ \\omega_{L} = \\frac{eB}{2m_{e}} $$ Con questo possiamo andare a definire un momento di Larmor.\n$$ m_{L} = i_{L}S_{L} = -\\frac{e}{T_{L}} S_{L} $$$$ T_{L} = \\frac{2\\pi}{\\omega_{L}} \\implies \\frac{4\\pi m_{e}}{eB} $$ E questo si pu√≤ sostituire si sopra e otteniamo che il momento di Larbor √®:\nPrecessione di Larmor üü®\u0026ndash; Abbiamo detto che abbiamo un fattore di momento angolare che √® dipendente dal campo magnetico, per questo motivo possiamo spiegare l\u0026rsquo;effetto del campo magnetico nel creare correnti (in questo caso l\u0026rsquo;elettrone che si muove).\nMomento magnetico per unit√† di volume üü©\u0026ndash; $$ \\vec{M} = \\frac{\\Delta \\vec{m}}{\\Delta \\tau}, \\Delta \\vec{m} = n $$ Con N il numero di atomi per unit√† di volume e $\\vec{m}$ il momento magnetico per unit√† di volume.\n$\\vec{M}$ descritto sopra √® il momento magnetico per unit√† di volume, chiamato anche MAGNETIZZAZIONE.\nConsideriamo ora un cilindro con un certo momento magnetico. Per un certo principio di equivalenza di Ampere, possiamo dire che il momento magnetico\u0026hellip; (vedere pagina 275 Mazzoldi).\n$$ dm = di_{m}dS\\hat{u} = M dSdz\\hat{u} \\implies di_{m} = Mdz $$ Ma tutte le correnti interne si elideranno, e questo sar√† equivalente a un circuito esterno (una spira per dire), questo motiva anche l'utilizzo del solenoide, perch√© sembra simile a questo setting. Vedere [Geometrie di spire](/notes/geometrie-di-spire). $$ i_{m} = \\int \\, di_{m} = \\int M \\, dz = Mh $$$$ j_{m} = \\frac{i}{h} = \\lvert M \\rvert = \\vec{M} \\times \\hat{u} $$Caso Magnetizzazione non uniforme üü®\u0026ndash; Questo rende la cosa un po\u0026rsquo; pi√π compelssa perch√© le correnti amperiane non si cancellano. Consideriamo il setting in figura: $$ di_{1} - di_{2} = (M_{z} - M'_{z})dz = -\\frac{\\delta M_{z}}{dx} dxdz $$$$ di_{3} - di_{4} = (M'_{x} - M_{x})dx = \\frac{\\delta M_{x}}{\\delta z}dzdx $$ E possiamo considerare ora il valore totale:\n$$ di = di_{1} - di_{2} + di_{3} - di_{4} = \\left( \\frac{\\delta M_{x}}{\\delta z} - \\frac{\\delta M_{z}}{\\delta x} \\right) dxdz $$ E si pu√≤ estendere questo concetto il rotore facendo praticamente la stessa cosa anche per altri e abbiamo:\n$$ j = \\vec{\\nabla} \\times \\vec{M} $$ dove $j$ √® la densit√† lineare di corrente.\n$$ \\oint_{\\Gamma} \\vec{M} d\\vec{l} = i_{m} $$Equazioni del campo magnetico revisited üü©- $$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{l} = \\mu_{0} (i_{c} + i_{m}) = \\mu_{0}i_{c} + \\mu_{0} \\oint_{\\Gamma} \\vec{M} \\cdot d\\vec{l} $$ Dove aggiungiamo anche la corrente di ampere oltre la corrente concatenata.\n$$ \\oint_{\\Gamma} (\\vec{B} - \\mu_{0} \\vec{M}) \\cdot d\\vec{l} = \\mu_{0}i_{c} $$E dividendo per $\\mu_{0}$ si ha\n$$ \\oint_{\\Gamma} \\left( \\frac{\\vec{B}}{\\mu_{0}} -\\vec{M} \\right) \\cdot d\\vec{l} = i_{c} $$In cui abbiamo una altra sorgente del campo magnetico che √® dipendente dal materiale presente al campo magnetico.\nForma divergente üü© $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}(\\vec{J} + \\vec{J}{M}) = \\mu{0}(\\vec{J}_{c} + \\vec{\\nabla} \\times \\vec{M}) \\vec{\\nabla} \\times (\\vec{B} - \\mu_{0} \\vec{M}) = \\mu_{0} \\vec{J}_{c} $$\nCampo di magnetizzante üü©- $$ \\vec{H} = \\frac{\\vec{B}}{\\mu_{0}} - \\vec{M} $$$$ \\vec{\\nabla} \\times \\vec{H} = \\vec{J}_{c} $$$$ \\oint_{\\Gamma} \\vec{H} d\\vec{l} = i_{c} $$ Dimensione Ampere su Metro, la stessa del vettore di magnetizzazione.\nRelazioni M, H, B üü©\u0026ndash; VALGONO SOLO PER MATERIALI NON FERROMAGNETICI!\n$$ \\vec{M} = \\chi_{m} \\vec{H} $$$$ \\vec{B} = \\mu_{0} (\\vec{H} + \\vec{M}) = \\mu_{0}(1 + \\chi_{m}) \\vec{H} = \\mu \\vec{H} $$Si ha anche la stessa relazione fra M e B rispetto a quello vecchio!\n$$ \\vec{M} = \\frac{k - 1}{k} \\vec{B} $$Discontinuit√† nelle superfici magnetizzate üü®++ $$ 0 = \\oint_{\\Sigma}\\vec{B} \\cdot \\hat{u}_{N} dS = B_{1}\\cdot \\cos \\theta_{1} dS - B_{2} \\cdot \\cos \\theta_{2} dS \\implies B_{1} \\cos \\theta_{1} = B_{2}\\cos \\theta_{2} $$$$ k_{1} H_{1 \\perp} = k_{2} H_{2\\perp} $$ E possiamo dire che la componente $H$ √® discontinua.\n$$ i_{c} = 0 = \\oint_{\\Gamma} H\\cdot dS = H_{1}h - H_{2}h \\implies H_{1} = H_{2} $$$$ H_{1} \\sin \\theta_{1} = H_{2} \\sin \\theta_{2} $$$$ \\frac{B_{1 \\parallel}}{k_{1}} = \\frac{B_{2\\parallel}}{k_{2}} $$calcoliamo il modulo di $B_{2}$ in funzione di $B_{1}$ che mi serve per calcolare il rapporto:\n$$ B_{2}^{2} = B_{1}^{2} \\cos ^{2} \\theta_{1} + B_{1}^{2} \\frac{\\cos ^{2}\\theta_{1}}{\\cos ^{2} \\theta_{2}} $$Scriviamo in modo chiaro le componenti normali e non per $H$ Allora abbiamo che\n$$ H_{1t} = H_{2t} $$$$ k_{1}H_{1n} = k_{2}H_{2n} $$ E allora abbiamo:\n$$ \\frac{\\tan \\theta_{2}}{\\mu_{2}} = \\frac{H_{2t}}{\\mu_{2}H_{2n}} = \\frac{H_{1t}}{\\mu_{1}H_{1n}} = \\frac{\\tan \\theta_{1}}{\\mu_{1}} $$$$ \\frac{\\tan \\theta_{1}}{\\tan \\theta_{2}} = \\frac{\\mu_{1}}{\\mu_{2}} = \\frac{k_{1}}{k_{2}} $$Schermi magnetici üü© Pensiamo di avere un materiale ferromagnetico, e facciamo finta che abbiamo campo magnetico entrante. Per questa relazione abbiamo che probabilmente per ogni angolo, questo sar√† deflesso in modo praticamente parallelo alla superficie. E se c\u0026rsquo;√® un buco, allora non ci passa praticamente campo magnetico, e possiamo costruire schermi magnetici in questo modo. Quindi se il materiale del conduttore √® fatto di roba ferromagnetica, questa scherma sia campo magnetico che elettrico.\nMateriale ferromagnetico Certi materiali si magnetizzano velocemente quando si mettono vicino a campi magnetici forti\nConsideriamo un toroide, uguale a quello descritto in Geometrie di spire, abbiamo che quando mettiamo un materiale, $H$ non cambia, perch√© dipende solo da correnti concatenate.\nMagnetizzazione in funzione di H üü© Lo **stato vergine** √® lo stato iniziale del materiale. POi si ha la **curva di prima magnetizzazione** che √® la curva $a$ in figura. Per **magnetizzazione residua** si indica il valore di $M_{sat}$ quando $H = 0$ dopo aver salito la prima curva $a$. Abbiamo questo grafico (che poi si spiega con teorie quantistiche), che se aumento la corrente oltre un certo punto la magnetizzazione non aumenta. Questo si chiama magnetizzazione di saturazione. La cosa particolare √® che dopo che sono state magnetizzate, questi sono magneti permanenti. Si parla di campo coercitivo quando abbiamo un campo che fa diventare 0 la magnetizzazione.\nCiclo di isteresi di smagnetizzazione: In pratica devo fargli fare tanti giri (senza portarlo a saturazione!)\nCiclo di isteresi üü© √à il grafico che abbiamo visto di sopra, in cui il materiale va su e gi√π. e si potrebbero anche definire concetti come permeabilit√† differenziale che mi rappresenta come cambia in fretta se seconda dell\u0026rsquo;induzione magnetica\n$$ \\mu_{d} = \\frac{dB}{dH} $$ √à un diagramma di stato questo ciclo, in un certo senso come quelli descritti da Unified Modeling Language.\nUna altra osservazione √® che posso avere tutti i punti all\u0026rsquo;interno del ciclo, ed √® per questo che posso smagnetizzare un magnete. Il metodo √® accende e spegnere in un certo modo $H$.\nMateriali duri e dolci üü© Dolci sono usati solamente negli elettromagneti, perch√© sono facili da magnetizzare. Quelli duri sono difficili da magnetizzare, e hanno solitamente un ciclo di isteresi molto lungo.\nSeconda legge di curie (non importante) üü®++ Questa √® la relazione per materiali dolci, e lega la temperatura con la suscettibilit√† magnetica ()\n$$ \\chi_{m} (T - T_{c}))/\\rho = C $$ dove $\\rho$ √® la densit√† della sostanza.\nDomini di Weiss üü®\u0026ndash; Trattato pagina 316 del Mazzoldi:\nPossiamo caratterizzare alcuni domini magnetici ($~10^{5}$ atomi per il prof, per il libro circa $10^{11}$ atomi, sono regioni di circa 0.001 picometri., che ha senso perch√© i ferromagnetici sono questo fattore pi√π grandi rispetto agli altri., e poi vanno ad influenzare ed ingrandire, capire da Heisemberg (ma per il prof. difficili).\nUna cosa strana √® che $H$ dentro a un solenoide √® verso gi√π all\u0026rsquo;interno, perch√© abbiamo che \u0026hellip; boh non ho capito per√≤ la cosa strana era che era direzione opposta.\nSolenoide infinitamente lungo: non abbiamo vettore H perch√© la circuitazione √® sempre 0. ","permalink":"https://flecart.github.io/notes/magnetismo-nella-materia/","summary":"\u003ch3 id=\"analisi-macroscopica\"\u003eAnalisi macroscopica\u003c/h3\u003e\n\u003ch4 id=\"setting-dellesperimento-\"\u003eSetting dell\u0026rsquo;esperimento üü©\u003c/h4\u003e\n\u003cimg src=\"/images/notes/Magnetismo nella materia-1701163856145.jpeg\" alt=\"Magnetismo nella materia-1701163856145\"\u003e\n$$\n\\vec{F} = -\\vec{\\nabla} \\cdot U \\implies F \n= -\\vec{\\nabla}(\\vec{m} \\cdot \\vec{B})\n= \\pm m \\frac{dB}{dx}\n$$\u003cp\u003e\nLa prima relazione si deriva da definizione di lavoro e forza. (esteso al caso di una forza applicata su spira che non √® banale, facciamola brevemente).\u003c/p\u003e\n$$\nFds = dW = -dU = i \\nabla \\Phi(B) ds \\implies F = i\\nabla \\Phi(B) = m \\cdot \\nabla B = -\\nabla U\n$$\u003cp\u003eLa cosa da notare √® che per campi uniformi abbiamo che si pu√≤ definire il lavoro.\u003c/p\u003e","title":"Magnetismo nella materia"},{"content":"Introduzione alle catene di Markov La propriet√† di Markov Una sequenza di variabili aleatorie $X_{1}, X_{2}, X_{3}, \\dots$ gode della propriet√† di Markov se vale:\n$$ P(X_{n}| X_{n - 1}, X_{n - 2}, \\dots, X_{1}) = P(X_{n}|X_{n-1}) $$ Ossia posso scordarmi tutta la storia precedente, mi interessa solamente lo stato precedente per sapere la probabilit√† attuale.\nDa un punto di vista filosofico/fisico, ha senso perch√© mi sta dicendo che posso predire lo stato successivo se ho una conoscenza (completa, (lo dico io completo, originariamente non esiste)) del presente.\nLa catena di Markov üü© $$ \\mathbb{P}(X_{t+1} = j \\mid X_{0} = i_{0}, \\dots, X_{t} = i_{t}) = \\mathbb{P}(X_{t + 1} = j \\mid X_{t} = i_{t}) = P_{ij} $$ Queste catene sono dette time-homogeneus. Con la probabilit√† di Markov si pu√≤ dimostrare che se $X_{0} \\sim \\mu_{0}$ con $\\mu_{0}$ il vettore riga, allora la probabilit√† della distribuzione $X_{t}$ sar√† $\\mu_{t} = \\mu_{0}P^{t}$. We have that $\\mu$ is a stationary distribution if $\\mu = \\mu P$ is valid. A study of this property is sometimes interesting.\nCatena di 3 variabili üü© $$ p(x, y, z) = p(x)p(y|x)p(z|y) $$$$ p(x, y, z) = p(z)p(y|z)p(x|y) $$$$ P(x, z|y) = P(x|y)P(z|y) $$ Che dovrebbe essere una conseguenza diretta della parte di sopra. Una altra osservazione √® che se vale quella catena, vale anche l\u0026rsquo;inversa, ossia $Z \\to Y \\to X$.\nAbbiamo analizzato molte catene di questo genere quando abbiamo parlato di d-separabilit√† in Counterfactual Invariance.\nData processing inequality üü® $$ I(X ; Y) \\geq I(X; Z) $$ Perch√© una parte di computazione √® possibile modellarlo con la catena di Markov. E mi sta dicendo che l\u0026rsquo;informazione comune all\u0026rsquo;input $X$ con l\u0026rsquo;output $Y$ o output $Z$ dopo seguente computazione viene sempre meno con pi√π computazione, e anche che non aggiungo informazione con pi√π computazione.\n$$ X \\to Y \\to Z $$$$ I(X; Y) \\geq I(X; Z) $$ If the equality is satisfied then $Z$ is the sufficient statistic for $Y$. This has some relation with The Exponential Family.\n$$ \\begin{align} I(X;Z) \u0026= I(X; Y, Z) - I(X; Y \\mid Z) \\\\ \u0026= I(X;Y) - I(X; Z \\mid Y)- I(X; Y \\mid Z) \\\\ \u0026\\implies I(X;Y) \\geq I(X;Z) \\end{align} $$Definizioni Comuni Raggiungibilit√† $$ P_{ij}^{m} \u003e 0 $$ Molto pi√π facile vedere sta cosa se lo rappresentiamo come un comunissimo grafo.\nClasse di stati Sono un insieme di stati tutti raggiungibili fra di loro (comunque presi due stati all\u0026rsquo;interno della classe, esiste un percorso che parte da uno e finisce sull\u0026rsquo;altro per dire).\nRecurrent vs Transient üü© √à recurrent se per ogni nodo, tutti i nodi raggiungibili da un nodo $i$ raggiungono anche il nodo $i$ stesso. Transient se non √® recurrent. Alcuni chiamano la recurrent come irreducible come in (Cover \u0026amp; Thomas 2012).\nPeriodic vs Aperiodic üü© Sia $d$ il massimo comune divisore per tutti gli $m$ tali per cui vale $P_{ii}^{m} \u003e 0$ (ossia pu√≤ raggiungere s√© stesso con probabilit√† non nulla), allora √® periodico se $d \u003e 1$ altrimenti √® aperiodico. Questo implica che non esistono cicli di passi che siano divisibili per un numero $d$, e abbiamo una definizione un poco pi√π intuitiva di periodicit√†. Una catena di Markov √® aperiodica se tutti i nodi sono aperiodici.\nErgodic Markov Chain üü©- Una catena di Markov si dice Ergodico se √® recurrent e aperiodico. Si pu√≤ anche definire come se esista un $t$ finito tale per cui tutti gli stati siano raggiungibili da tutti gli altri in esattamente $t$ steps, questa √® una definizione molto pi√π intuitiva, che √® anche giustificata dal teorema seguente.\n$$ P^{(M - 1)^{2} + 1}_{ij} \u003e 0 $$ Con $M$ il numero totale di stati, e $ij$ qualunque stato iniziale o finale. Dimostrazione √® un esercizio. Pu√≤ essere molto utile il Chicken McNugget Theorem per dimostrare questo, e fare ragionamenti sul massimo risultato ottenibile. Comunque possiamo dire che esiste un $t$ tale per cui tutti gli stati sono raggiungibili da tutti gli altri in $t$ steps, la dimostrazione si pu√≤ trovare nel teorema 1.7 di questo Originariamente preso da qui al corso di discrete stochastic processes.\nUnichain Una catena che contiene una singola classe recurrent pi√π alcuni stati transienti\nChapman-Kolmogorov Equation üü© $$ P^{n + m}_{ij} = \\sum_{k = 0}^{N} P_{ik}^{n} P_{kj}^{m} $$ Ossia posso moltiplicare matrici di transizione assieme per avere la probabilit√† di muovermi da uno stato $i$ a uno stato $j$ in $n + m$ passi.\nPossiamo scrivere questa equazione nella forma continua, che √® utile per l\u0026rsquo;analisi di processi di diffusione: Quando scritto √® preso da qui, pagina 30: in questo caso $t$ sono i passi di tempo\nConvergenza Ha senso pensare che una catena di Markov converga nel proseguire delle transazioni.\nTeorema di convergenza per catene ergodiche Questo √® un teorema importante. Fatto sta che esiste una distribuzione stazionaria una volta che ho fatto abbastanza passi. Da fare.\nConvergenza per unichains ergodiche. Stationary distributions üü© Una distribuzione $\\pi$ √® detta stazionaria se vale che $\\pi = \\pi P$. ossia la probabilit√† di finire in uno stato $x$ dopo aver fatto una altra mossa seguendo la distribuzione $\\pi$ √® uguale a $\\pi(x)$.\nThe Ergodic Theorem üü®+ Questa √® una generalizzazione della Legge dei grandi numeri (guarda qui Central Limit Theorem and Law of Large Numbers), per catene di Markov ergodiche. In generale ci permette di utilizzare catene di markov per fare stime di probabilit√†, elementi che risultano molto utili per fare Markov Chain Monte Carlo.\n$$ \\lim_{n \\to \\infty} \\frac{1}{n}\\sum_{t = 0}^{n}f(X_{t}) = \\sum_{x \\in S}\\pi(x)f(x) \\approx \\mathbb{E}_{x \\sim \\pi}[f(x)] $$Questo teorema ci permetter√† di fare sampling, utilizzando catene di Markov.\nSee appendix C of ‚ÄúMarkov chains and mixing times‚Äù (Levin and Peres, 2017) for a proof.\nQuesto ci dice che l\u0026rsquo;estimatore che abbiamo √® unbiased.\nInoltre abbiamo un burn-in time prima di iniziare a fare sampling in modo corretto, quindi i primi samples vengono scartati.\nDetailed Balance Equation üü®+ Intuitivamente questa assunzione ci dice che per catene di Markov Ergodiche tale che per cui probabilit√† di andare da $x \\to x'$ e da $x' \\to x$ √® esattamente uguale, cosa non ovvia per catene di Markov qualunque, ammettono una distribuzione stazionaria $Q(x)$ per ogni stato $Q$. Questo ci da un modo per costruire Markov Chains in modo che producano seguendo una distribuzione $Q$ data a priori.\n$$ \\pi(x)P(x \\mid y) = \\pi(y)P(y\\mid x) $$ Queste catene di Markov si dicono anche reversible per l\u0026rsquo;osservazione di sopra.\nSe una catena di Markov √® reversible per una certa distribuzione $\\pi$ allora quella √® la distribuzione stazionaria della catena.\n$$ \\begin{align} P(X_{t + 1} = x') = \\\\ \\sum_{x}\\pi(X_{t} = x)P(X_{t + 1} = x' \\mid x) = \u0026\u0026 \\text{ using marginalization and product}\\\\ \\sum_{x}\\pi(X_{t} = x')P(X_{t+1} =x \\mid x') = \u0026\u0026 \\text{reversibility}\\\\ \\pi(X_{t} = x')\\sum_{x}P(X_{t+1} =x \\mid x') = \\pi( x') \\\\ \\end{align} $$Che √® la distribuzione stazionaria che volevamo. Si vede che √® stazionaria perch√© facendo un update della catena, la probabilit√† resta ancora la stessa, per ogni stato di partenza.\nCon rewards Vogliamo associare a ogni stato $i$ un reward $r_{i}$ Si pu√≤ creare allora una altra variabile aleatoria che prende la variabile aleatoria di Markov $X_{i}$ e lo mappa a un reward. Quello che ci interessano di pi√π sono le expectation dei rewards.\nNoi vogliamo il valore\n$$ E[R(X_{n})| X_{0} = i] = \\sum_{j}r_{j}P_{ij}^{n} $$ E per la propriet√† di Markov credo sia la stessa cosa quando non parto da step 0.\nAggregate reward function Questo √® definito anche come value function in Reinforcement Learning, a introduction.\n$v_{i}(n) = E[R(X_{m}) + \\dots + R(X_{m + n - 1}) | X_{m} = i]$\nSe la catena √® convergente, abbiamo che anche il value function √® convergente a un valore preciso, ed √®:\n$$ g = \\sum \\pi_{j}r_{j} = \\vec{\\pi} \\cdot \\vec{r} $$ Indipendentemente allo stato iniziale (che stupisce molto).\nReferences [1] Cover \u0026amp; Thomas ‚ÄúElements of Information Theory‚Äù John Wiley \u0026amp; Sons 2012\n","permalink":"https://flecart.github.io/notes/markov-chains/","summary":"\u003ch3 id=\"introduzione-alle-catene-di-markov\"\u003eIntroduzione alle catene di Markov\u003c/h3\u003e\n\u003ch4 id=\"la-propriet√†-di-markov\"\u003eLa propriet√† di Markov\u003c/h4\u003e\n\u003cp\u003eUna sequenza di variabili aleatorie $X_{1}, X_{2}, X_{3}, \\dots$ gode della propriet√† di Markov se vale:\u003c/p\u003e\n$$\nP(X_{n}| X_{n - 1}, X_{n - 2}, \\dots, X_{1}) = P(X_{n}|X_{n-1})\n$$\u003cp\u003e\nOssia posso scordarmi tutta la \u003cstrong\u003estoria precedente\u003c/strong\u003e, mi interessa solamente lo stato precedente per sapere la probabilit√† attuale.\u003c/p\u003e\n\u003cp\u003eDa un punto di vista filosofico/fisico, ha senso perch√© mi sta dicendo che posso predire lo stato successivo se ho una conoscenza (completa, (lo dico io completo, originariamente non esiste)) del presente.\u003c/p\u003e","title":"Markov Chains"},{"content":"Andiamo a parlare di processi Markoviani. Dobbiamo avere bene a mente il contenuto di Markov Chains prima di approcciare questo capitolo.\nMarkov property Uno stato si pu√≤ dire di godere della propriet√† di Markov se, intuitivamente parlando, possiede gi√† tutte le informazioni necessarie per predire lo stato successivo, ossia, supponiamo di avere la sequenza di stati $(S_n)_{n \\in \\mathbb{N}}$, allora si ha che $P(S_k | S_{k-1}) = P(S_k|S_0S_1...S_{k - 1})$, ossia lo stato attuale in $S_{k}$ dipende solamente dallo stato precedente.\nNormalmente poche cose nel mondo reale si possono dire puramente Markoviane, per√≤ non si pu√≤ negare che √® un modello molto buono di partenza come modello di decisione.\nma potremmo sempre rendere Markoviano creando una nuova variabile che ci rappresenta tutta la storia (√® qualcosa che non ho capito molto bene, ma credo si possa fare senza probbi).\nMarkov processes Possiamo andare a definire un processo markoviano come un insieme di stati e il modello di transizione probabilistico: $(S, P)$, una coppia di stati e tutto il modello di transizione. mi sembra di aver letto che un processo markoviano sia molto buono per studiare i moti browniani in fisica. Praticamente a random abbiamo che ogni punto si pu√≤ muovere\nEsempio di processo markoviano\nMarkov Reward Processes Quando andiamo a parlare di processo markoviano con reward indichiamo che associamo una funzione valore $V(s)$ che restituisce un certo valore a ogni stato. Di solito questo valore ci √® ignoto agli agenti che seguono il modello, quindi diventa un buon problema con questa impostazione provare a stimare il valore dello stato in seguito a numerose osservazioni. Solitamente non vogliamo considerare tutti i reward con lo stesso peso. Vorremmo avere anche a disposizione un parametro che ci indichi quanto siano importanti i reward subito di ora, e i reward nel futuro. Con questo indichiamo un discount factor $\\gamma$\nDefinition Un tale processo viene formalizzato tramite una quadrupla $S, P, R,\\gamma$, con s stati possibili, P il modello di transizione e R la funzione che ritorna il reward per ogni stato.\n$(S, P, R, \\gamma)$, ossia ora abbiamo sia stato, sia azione possibile e la funzione di transizione deve contare entrambi: $P(\\cdot | s, a)$, mentre le reward sono ancora come prima.\n$S$ l‚Äôinsieme finito o infinito numerabile di stati possibili $P$ probabilit√† di raggiungere un certo stato, dato uno stato iniziale e una azione, solitamente modellati come $P(x' \\mid x)$ come arrivare a stato $x'$ da $x$. Questa √® un genere di approccio Markoviano, perch√© dipende solamente dallo stato precedente. $R$ reward di uno stato. Talvolta il reward stesso di una azione in un certo stato pu√≤ essere rumoroso (noisy). $\\gamma$: decadimento del reward. State Value Function üü© Solitamente viene definito state value function:\n$$ V(s) = \\mathbb{E}[R_t + \\gamma R_{t + 1} + \\gamma^2 R_{t + 2} + ... | s = s _{t}] $$La parte dentro il valore atteso √® solitamente indicata con $G_t$.\nPolicy evaluation üü© Metodi di estimazione della funzione valore:\nAbbiamo abbastanza metodi per stimare il valore della funzione: metodi di sampling, metodi diretti (analitici) e metodi basati su programmazione dinamica.\nRiguardo i metodi di sampling questi sono i pi√π dinamici, nel senso che permettono l‚Äôapplicazione a pi√π problemi possibili, in generale hanno una precisione che va nell\u0026rsquo;ordine dell $\\dfrac{1}{\\sqrt {n}}$ anche se non so su quali basi in particolare.\nI metodi diretti sono leggermente pi√π lenti, perch√© si tratta di risolvere l‚Äôinversa della matrice, cosa che va in $O(n^3)$. Il motivo di questo √® che possiamo sfruttare la propriet√† di V\nBellman expectation equation üü© La dimostrazione √® sul libro di Krause pagina 186. La differenza qua, √® che lo stiamo dimostrando per markov reward process, mentre l√¨ √® per decision process, ma √® analoga la cosa. Possiamo dire che\n$$ V_k(s_t) = \\mathbb{E}[R_t + \\gamma G_{t + 1} | s = s _{t}] = R(s) + \\gamma \\sum_{s'}P(s'|s)V_{k -1}(s') = (R + \\gamma P V_{k - 1})(s) $$ E scritto sfruttando il valore atteso abbiamo: $$ V^{\\pi}{k}(x) = R(x) + \\gamma \\mathbb{E}{x\u0026rsquo; \\mid x, \\pi(x)}[V_{k - 1}(x\u0026rsquo;)]\n$$\n$$ V^{\\pi}_{k}(x) = \\mathbb{E}_{a \\sim \\pi}[R(x, a) + \\gamma \\mathbb{E}_{x' \\mid x, a}[V_{k - 1}(x')]]] $$Una nota √® che questa √® stazionaria quindi avremo alla fine che $V_{k} = V_{k - 1}$ se continuiamo per tanto. Questa osservazione permette di sviluppare un algoritmo iterativo per stimare il $V$ fino a convergenza (sul perch√© converge sicuramente guardare altro, probabilmente idea degli operatori di bellman pu√≤ essere utile)\nMarkov Decision Process Questo √® molto simile alla Markov Reward Processes, solo che ora introduciamo una policy, ossia una funzione che ci dica quanto √® probabile compiere una certa azione in un certo stato, in pratica aggiungiamo la possibilit√† di avere azioni ai Markov Reward Processes, allora otteniamo i MDP. Questi modelli sono utilizzati per modellare decisioni sequenziali finite.\nDefinition $(S, A, P, R, \\gamma)$, which means we now have both state and possible action, and the transition function must account for both: $P(\\cdot | s, a)$, while the rewards are still as before.\n$S$ is the finite or countably infinite set of possible states $A$ is the set of possible actions $P$ a function $S \\times A \\to S$ which represents the probability of reaching a certain state, given an initial state and an action; typically modeled as $P(x' \\mid x, a)$ representing how to reach state $x'$ from $x$ with action $a$. This is a kind of Markovian approach, because it depends only on the previous state. $R$ is the reward of a state-action pair, a function $S \\times A \\to \\mathbb{R}$. Sometimes the reward itself of an action in a certain state can be noisy. $\\gamma$: reward decay. √à da notare che se possediamo una policy, allora possiamo ridurci al caso di Markov Reward Process, infatti possiamo dire che\n$$ \\begin{align} R^\\pi(s) = \\sum_{a \\in A}\\pi(a | s)R(s) \\\\ P^\\pi(s'|s) = \\sum_{a \\in A} \\pi(a | s) P(s'|s, a) \\end{align} $$ Notiamo che MDP assumono che lo stato sia totalmente osservabile. Ma normalmente gli stati sono solamente accessibili tramite sensori, quindi si pu√≤ dire che gli stati sono parzialmente osservabili. Questo √® un problema che si chiama POMDP. L\u0026rsquo;immagine seguente riassume questi concetti brevemente: Modelling reward $$ \\max \\mathbb{E} \\left[ \\sum_{t = 0}^{\\infty} \\gamma^{t}r_{t} \\right] $$ Si potrebbero interpretare come una sorta di Markov Chains, con labels negli edge di transizione (quindi potremmo riutilizzare la nozione di Ipergrafo fatta per Backpropagation forse) Comunque a seconda se la funzione di transizione sia deterministica, ossia da uno stato dia una azione, oppure probabilistica, possiamo definire effettivamente la Markov Chains sottostante:\n$$ \\begin{align} \\\\ P(x' \\mid x) = P(x' \\mid x , \\pi(x)) \u0026 \\text{ se deterministica} \\\\ P(x' \\mid x) = \\sum_{a \\in \\mathcal{A}} \\pi(a \\mid x)P(x' \\mid x, a) \u0026 \\text{ se probabilistica} \\\\ \\end{align} $$Quindi data una policy possiamo utilizzare gli argomenti fatti di sopra e riuscire a dare una valutazione di essa\nPolicy Evaluation Bellman backup üü© Algoritmo iterativo DP per policy evaluation With vector notation, we can define the bellman backup as follows:\n$$ \\begin{align} \\\\ B: \\mathbb{R}^{n} \\to \\mathbb{R}^{n} \\\\ B(V)(s) = R(s) + \\gamma \\sum_{s'} P(s'|s)V(s') \\\\ \\end{align} $$Bellman backup is a contraction üü© We can prove that bellman backup is a contraction, which is useful to prove that the iteration converges. We can use this bellman backup operator to find an iterative algorithm to estimate the value of a single state.\n$$ \\begin{align} \\lvert BV - BV' \\rvert_{\\infty} \u0026 = \\lvert R + \\gamma PV - R - \\gamma PV' \\rvert_{\\infty} \\\\ \u0026= \\gamma \\lvert PV - PV' \\rvert_{\\infty} \\\\ \u0026 = \\gamma \\max_{y} \\sum_{x} P(x \\mid y) \\lvert V(x) - V'(x)) \\rvert \\\\ \u0026 \\leq \\gamma \\cdot \\max_{y}\\sum_{x} P(x \\mid y) \\lvert V - V' \\rvert_{\\infty} \\\\ \u0026 \\leq \\gamma \\cdot \\lvert V - V' \\rvert_{\\infty} \\\\ \\end{align} $$As we need to multiply the transition vector, the speed is polynomial on the number of states.\nPolicy Search Cerchiamo ora la policy migliore possibile da applicare a un MDP, questo √® il problema del policy control ora che sappiamo come fare policy evaluation √® il momento giusto per introdurre soluzioni a questo problema.\nUna soluzione na√Øve √® semplicemente enumerare tutte le policy e utilizzare l‚Äôalgoritmo di policy evaluation, poi andare a vedere quale sia la migliore. Questo √® molto dispendioso perch√© assumendo che posso applicare tutto l‚Äôinsieme di azioni a tutti gli stati ho potenzialmente $|S|^{|A|}$ policy possibili, che sono troppi.\n√à bene, raggiunti questo punto, provare a introdurre alcune definizioni utili.\nDefinitions: state-action-value, optimal value policy Sia $\\pi$ una policy e $V^\\pi$ la evaluation di quella policy, allora possiamo andare a definire la state-action-value function in questo modo:\n$$ Q^{\\pi}(s, a) = R(s, a) + \\gamma \\sum_{s'} P(s'|s, a)V^\\pi(s') $$ossia ci dice pi√π o meno il valore atteso dell‚Äôazione a un certo stato!\nPossiamo anche definire la policy migliore:\n$$ \\pi^*(s) = \\arg\\max_{\\pi} V^\\pi(s) $$ Ossia √® la policy che rende massimo il valore in qualunque stato!\nOther Properties Bellman\u0026rsquo;s theorem üü© $$ \\pi^*(s) = \\arg\\max_a Q(s, a) $$ Which means that the optimal policy is greedy with respect to the state-action value function. This is the same as the Characterization of optimal policies explained layer\n$$ V^*(s) = \\max_{a \\sim \\pi} Q^*(s, a) $$ So, if the policy satisfies this condition, we can call it to be optimal. If it\u0026rsquo;s a stationary condition of the above, then the condition is satisfied.\nCharacterization of Optimal policies üü© $$ V^{*}(x) = \\max_{a} \\left[ Q^{*}(x, a) \\right]=\\max_{a} \\left[ R(x, a) + \\gamma \\sum_{x'} P(x' \\mid x, a)V^{*}(x') \\right] $$ This is another fixed point, an observation that we can use for another contraction operator which guarantees convergence. This is an optimality condition for deterministic policies.\nPolicy iteration The algorithm üü© Una volta creato una policy iteration, √® una cosa molto sensata andare a definire una nuova policy $\\pi_{k + 1}$ definita in questo modo:\n$$ \\forall s, \\pi_{k + 1}(s) = \\arg\\max_a Q(s, a) $$Ossia andiamo proprio a crearci una nuova policy, cercando di rendere maggiore possibile il valore atteso a fare una certa azione a uno stato, in modo greedy! Riusciremo a dimostrare che $\\forall s, V^{\\pi_{k + 1}}(s) \\geq V^{\\pi_{k}}(s)$\nIn formule, possiamo caratterizzare l\u0026rsquo;algoritmo in modo molto semplice:\nInitialize $V^{\\pi}(s)$ and $\\pi(s)$ Repeat until convergence: Policy evaluation: $V^{\\pi} \\leftarrow V^{\\pi}$ Policy improvement: $\\pi \\leftarrow \\pi$ Monotonicity of policy iteration üü®++ Si nota che una policy induce un value, che induce una policy migliore, quindi si pu√≤ provare a reiterare questo algoritmo fino a convergenza.\nDimostrazione dal (Sutton \u0026amp; Barto 2018)\nl‚Äôidea principalmente √® prendere sempre il massimo volta dopo volta, e dimostrarlo per induzione in pratica‚Ä¶ Anche non ho capito come formalizzare e non ho capito se posso trarne vantaggi didattici nella formalizzazione di questa merda\n$$ \\begin{align} v_{1}(x) \u0026= (B^{*}v^{\\pi_{t}})(x) \\\\ \u0026= \\max_{a} R(x, a) + \\gamma \\sum_{x'} P(x' \\mid x, a) v^{\\pi_{t}}(x') \\\\ \u0026\\geq R(x, \\pi_{t}(x)) + \\gamma \\sum_{x'} P(x' \\mid x, \\pi_{t}(x)) v^{\\pi_{t}}(x') \\\\ \u0026= v^{\\pi_{t}}(x) = v_{0}(x)\u0026 \\text{ for all } x \\end{align} $$Convergence of Policy Iteration üü© The number of deterministic policies is finite for finite Markov decision processes (it\u0026rsquo;s easy to count them). It was shown by Ye 2011 that we need a polynomial number of iterations for it to converge. The complexity should be dependent on the number of states and actions. Note that the policy evaluation is cubic in the number of states, so the polynomial is at least cubic.\n$$ \\mathcal{O}\\left( \\frac{n^{2}m}{1 - \\gamma} \\right) $$ Where $n$ is the number of states, $m$ are the actions.\nValue Iteration The idea üü© L‚Äôidea di value iteration √® sostituirla subito, cio√® non stare a sviluppare fino in fondo la value evaluation, ma aggiornare la policy subito dopo appena si ha il valore. Questo perch√© la parte di policy evaluation pu√≤ essere molto molto lunga.\nPseudo-codice value iteration Note: the above could also be written in terms of state-action value $Q(s, a)$. One can prove that this algorithm is also $\\varepsilon-$optimal.\nBellman update operator üü© The bellman update is defines as:\n$$ \\begin{align} B: \\mathbb{R}^{n} \\to \\mathbb{R}^{n} \\\\ B(V)(s) = \\max_{a} R(s, a) + \\gamma \\sum_{s'} P(s'|s, a)V(s') \\end{align} $$ This operator yields a value function over all states $s$ and returns a new value function. If we found a fixed point for this function, then we know that is the optimal value function that satisfies the Bellman theorem, which implies we have reached the best policy possible for this fixed case.\nSi pu√≤ dimostrare che questo operatore √® una contrazione, quindi value iteration converge qualunque sia il punto di partenza\nCon questo operatore, possiamo anche riscrivere in modo migliore la policy evaluation\nSlide Convergence analysis üü© Proof of contraction of bellman operator\nThis proof is enough to use Banach Fixed Point Theorem and say there is an unique fixed point. Then we can use the fact that $\\gamma \u003c 1$ to say that it converges, in a manner akin to what we have done with policy Evaluation. Also in this case we can prove it converges in a polynomial number of iterations But differently from Policy Iteration, value iteration does not converge to the exact solution.\nThe only part which could be seen as not obvious is why $\\lVert max(f(x)) - max(g(x)) \\rVert \\leq max \\lVert f(x) - g(x) \\rVert$ this is a simple consequence from the observation that $max(f(x) + g(x)) \\leq max(f(x)) + max(g(x))$, moving a max to the other side, and setting the functions accordingly.\nPOMDP POMDP stands for Partially Observable Markov Decision Process. It has some similarities with Kalman Filters, which the relaxation that we are not constrained to have Gaussian Transitions.\nDefinition of POMDP üü©\u0026ndash; A POMDP is defined as a tuple $(S, A, P, R, \\Omega, O, \\gamma)$, where:\n$S$ is the set of states $A$ is the set of actions $P$ is the transition probability $R$ is the reward function $\\Omega$ is the set of observations $O$ is the observation probability, a function that given the real state returns a probability distribution over the set of observations $\\gamma$ is the discount factor So we have added the set of possible observations and how it links with the hidden true state.\nEquivalence to MDP üü• TODO: should be a good exercise, these are the current hints:\nDefine a belief space, and the you just need to work out the belief transitions to this new space. Also define the new rewards for this. References [1] Sutton \u0026amp; Barto ‚ÄúReinforcement Learning: An Introduction‚Äù A Bradford Book 2018\n","permalink":"https://flecart.github.io/notes/markov-processes/","summary":"\u003cp\u003eAndiamo a parlare di processi Markoviani. Dobbiamo avere bene a mente il contenuto di \u003ca href=\"/notes/markov-chains/\"\u003eMarkov Chains\u003c/a\u003e prima di approcciare questo capitolo.\u003c/p\u003e\n\u003ch3 id=\"markov-property\"\u003eMarkov property\u003c/h3\u003e\n\u003cp\u003eUno stato si pu√≤ dire di godere della propriet√† di Markov se, intuitivamente parlando, possiede gi√† tutte le informazioni necessarie per predire lo stato successivo, ossia, supponiamo di avere la sequenza di stati $(S_n)_{n \\in \\mathbb{N}}$, allora si ha che $P(S_k | S_{k-1}) = P(S_k|S_0S_1...S_{k - 1})$, ossia lo stato attuale in $S_{k}$ dipende solamente dallo stato precedente.\u003c/p\u003e","title":"Markov Processes"},{"content":"Introduzione alle funzioni del markup üü© La semantica di una parola √® caratterizzata dalla mia scelta (design sul significato). Non mi dice molto, quindi proviamo a raccontare qualcosa in pi√π.\nDefiniamo markup ogni mezzo per rendere esplicita una particolare interpretazione di un testo.\nIn particolare √® un modo per esplicitare qualche significato. (un po\u0026rsquo; come la punteggiatura, che da qualche altra informazione oltre le singole parole, rende pi√π chiaro l\u0026rsquo;uso del testo).\nLe informazioni aggiuntive possono essere riguardanti:\nLa struttura del testo La formattazione del testo Relazioni fra parti del testo. Tipologie di Markup (6) üü®+ Puntuazionale Questo √® un markup che l‚Äôautore stesso d√†. ed √® fortemente ambiguo!.\nIl markup puntuazionale consiste nell‚Äôusare un insieme prefissato di segni per fornire informazioni perlopi√π sintattiche sul testo.\nPresentazionale Effetti grafici per comunicare fine capitolo o altri simili\nProcedurale Questo √® una tipologia di markup che utilizza delle istruzioni per definire la presentazione. (quindi in questa parte ci sono dei comandi!) (esempi credo siano latex o Tex)\nDescrittivo Vuole descrivere la struttura e la semantica di frammenti di testo. (non √® procedurale, perch√© non gli dico pezzo per pezzo la grafica), io dico se √® un testo, se √® una didascalia, in modo simile a quanto fatto qui su Notion.\nReferenziale Quando faccio riferimento a cose esterne per risolvere il significato. Di solito fa usi di SIGLE o abbreviazioni di qualcosa\nMetaMarkup Se utilizzo un linguaggio per creare un linguaggi di Markup, un esempio √® Word, perch√© con quello utilizzo il linguaggio di markup (descrittivo, su font e simili), anche HTML.\nMetamarkup consiste nel fornire regole di interpretazione del markup e permette di estendere o controllare il significato del markup.\nMetodi di classificazione di markup Standard privato oppure pubblico Se √® interno o esterno (nel senso se si riferisce al testo interno oppure al testo esterno) binario o leggibile (per dire se √® pi√π fruibile per le macchine oppure se √® fatto per essere fruibile per esseri umani) Poi si fa anche una distinzione fra procedurale (latex o troff like) oppure dichiarativi, nel senso che si taggano parti per indicarne l\u0026rsquo;utilizzo (come pe rl‚ÄôHTML). Alcuni linguaggi di Markup Groff, Troff and NROFF Questi sono scritti i linguaggi di markup per i manuali tecnici di Linux.\nTex and LaTeX Software di impaginazione autoomatica, principalmente per formule matematiche, perch√© ci metteva troppo a fare il suo libro che la casa editrice sbagliava le formule. C\u0026rsquo;√® anche un metafont utilizzato per astrarre la fomra dei caratteri‚Ä¶ √à poi turing completo, molto difficile, moltissime keyword. √à molto difficile quindi Leslie Lamport crea una libreria molto pi√π facile da utilizzare.\nMarkdown Una semplificazione molto semplice, con formattazioni ad hoc, utili per testi semplici, senza molta possibilit√† di avere cose tipografiche precise.\nJSON and YAML Introduction to JSON JSON (JavaScript Object Notation) is a data format designed to facilitate data exchange over the internet.\nFrom a Big Data perspective, it is a very common format for storing data in a denormalized way (see Database Normalization). It can operate without adhering to strict data integrity rules without any issue.\nJSON data is often referred to as semi-structured data because it can be easily processed by both machines and humans, whereas traditional databases are typically machine-readable only, and plain text is primarily human-readable (though this distinction may be changing).\nYAML, which has a Python-like structure, uses indentation (spaces) as delimiters. It is a superset of JSON, meaning it can also parse JSON. Other than this, YAML is similar to JSON but has the added feature of supporting comments.\nWell-formedness üü© JSON and other Markups have standardized syntaxes, also called languages in theoretical computer science, because they have some specific syntactical rules which specify whether if a string is well-formed or not (note that this is different from validation!). These data formats are important in the context of Big Data as they allow to store data in denormalized form for fast reads. We explained in Relational Model how we can mathematically model relational databases, we can also simply map them to key-values, as we do with JSONs! JSON documents can start with an object or array, the two composite datatypes.\nJSON datatypes üü® JSONs have 6 datatypes:\nstrings As normal strings, but you can escape characters with a backslash. Numbers JSON places a few restrictions: a leading + is not allowed. Also, a leading 0 is not allowed except if the integer part is exactly 0 (in which case it is even mandatory, i.e., .23 is not a well-formed SON number literal) null objects keys must be quoted strings keys should not be repeated arrays boolean We will skip examples of these types, but you need to know what type is what for the exam. SGML SGML (Standard Generalized Markup Language) √® uno standard di IBM rilasciato gratis. SGML √® un meta-linguaggio non proprietario di markup descrittivo. Facilita markup leggibili, generici, strutturali, gerarchici.\nThis is just historical remark, you can skip this without any problem.\n√à una tipologia di markup chiara, leggibile, strutturata, descrittiva e gerarchica, i primi fisici erano molto felici per questo metalinguaggio di markup.\nStruttura di un documento SGML\nDichiarazione SGML DOCTYPE, o dichiarazione dei nomi utilizzabili all\u0026rsquo;interno del documento Istanza del documento Slide\nEsempio SGML\n√à uno dei Markup pi√π importanti perch√© possiamo dire che sia il precursore dell\u0026rsquo;HTML\nCostituenti base di SGML\nElementi\nAttributi\nEntit√†\nPCDATA\nCommenti\nProcessing instructions\nQuesta parte dovrebbe essere molto importante se si parla della parte teorica, per√≤ nella pratica mi sembra che siano in verit√† utilizzate pochissimo, sono comuqnue interessanti sapere che esistano\nXML XML (eXtensible Markup Language) is a quite mature W3C standard. Many things in industry need to be formatted in XML format, even if it seems JSON seem to be more popular. Technically JSON and XML are the same, but XML is just a little more mature. It is very similar to #HTML, but that is for webpages (browsers are lot more lenient when parsing HTML), and XML is for data, they have two divergent stories, even if the starting syntax is similar.\nXML is used in tax collection in Switzerland, or in publishing industry for books for example. √à un sottoinsieme di SGML, che ha molte pi√π garanzie formali. (infatti se definita con BNF √® abbastanza difficile da comprendere).\nThe XML information Set üü®\u0026ndash; The XML Information Set is a formal, tree-based abstraction of an XML document as defined by the World Wide Web Consortium (W3C). It breaks down an XML document into ‚Äúinformation items‚Äù, for example:\nElements (tags) Attributes of the elements Textsj They have different rules of nesting, we will see it in the next section. Below, is a wider discussion on information items.\nDocument Information Item: This is the root of the information set for an XML document and represents the entire document. It includes properties like children (the top-level elements of the document) and optionally the document type declaration.\nElement Information Items: These represent XML elements in the document. Each element information item has properties such as:\nLocal name and namespace: The name of the element and the namespace it belongs to. Children: Other element information items or character information items (text nodes) that are contained within the element. Attributes: A set of attribute information items associated with the element. Parent: The parent information item (either another element or the document). Attribute Information Items: These represent the attributes of elements. Key properties include:\nLocal name and namespace: The name of the attribute and the namespace it belongs to. Normalized value: The value of the attribute after normalization (processing character references and entities). Owner Element: The element information item to which the attribute belongs. Character Information Items: These represent the text within elements. They consist of a sequence of characters, also called text\nOther Information Items: Depending on the XML document, there can be other types of information items, such as comments, processing instructions, and namespaces, though these are not always included in every XML document\u0026rsquo;s information se\nAbbiamo detto che XML √® un sotto-formato di SGML, ed √® utilizzato principalmente per fare una verifica formale che tutti i tags dichiarati siano a validi e cose simili.\nValid XML Elements XML elements are not free to have whatever character in the utf-8 charset, they have some rules:\nThey cannot start with a number or \u0026ldquo;:\u0026rdquo;, \u0026ldquo;-\u0026rdquo;, \u0026ldquo;.\u0026rdquo; They cannot start with xml (reserved for the XML standard) They cannot contain spaces They cannot contain special characters (Only _ are allowed everywhere). Well-Formed XML üü®+ We have a few rules about XML:\nTags should be well nested (you can only nest between open and closed tags, not in the middle) There should be no \u0026lt; and closing \u0026gt; in the attribute or quotation marks or somewhere else, they should be escaped There should be a single root element Attributes cannot be in the top level, and should be between quotation marks They should be different for a single tag (not same attribute repeated!) They cannot start with xml, see namespaces later. Single elements can be closed with the following syntax \u0026lt;empty/\u0026gt;. Text can be only between element tags Entities should be defined (? did not understood this). It should start with the text declaration (defining the version and the encoding). DOCTYPE declaration is optional, it has the name of the top level element in it. The table above summarizes valid XML formats.\nAlso the tags have some rules about possible characters: Namespaces üü©\u0026ndash; This is the same idea as a module in python or namespace in C++. This prevents tags with the same name to conflict with each other. To specify a namespace we add an attribute xmlns, usually in the top level element to keep things clean. These namespaces usually point to a URI resource (good practice is using a domain that you own as a namespace, and it\u0026rsquo;s this authority that decides what is this namespace for), which could be a website or something similar to that. You can use default namespaces, or use QNames and define a name for that namespace, you use a syntax like xmnls:name and then prepend name:tag to every tag.\n","permalink":"https://flecart.github.io/notes/markup/","summary":"\u003ch3 id=\"introduzione-alle-funzioni-del-markup-\"\u003eIntroduzione alle funzioni del markup üü©\u003c/h3\u003e\n\u003cp\u003eLa semantica di una parola √® caratterizzata dalla mia scelta (design sul significato). Non mi dice molto, quindi proviamo a raccontare qualcosa in pi√π.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eDefiniamo markup ogni mezzo per rendere esplicita una particolare \u003cem\u003einterpretazione\u003c/em\u003e di un testo.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eIn particolare √® un modo per esplicitare qualche significato. (un po\u0026rsquo; come la punteggiatura, che da qualche altra informazione oltre le singole parole, rende pi√π chiaro l\u0026rsquo;uso del testo).\u003c/p\u003e","title":"Markup"},{"content":"Matrice Jacobiana √à un modo per scrivere il gradiente di una funzione quando √® in una certa forma.\nData una funzione $f: \\mathbb{R}^n \\to \\mathbb{R}^p$ ossia per esempio $x=(x_1,...,x_n) \\to(f_1(x),...,f_p(x))$ Se le p funzioni di arrivo sono differenziabili, allora la matrice Jacobiana √® definita in questo modo:\n$$J_f(x) = \\begin{pmatrix} \\delta_{x_1} f_1(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{x_n} f_1(x)\\ . \u0026amp; . \u0026amp; . \\ \\delta_{x_1} f_p(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{x_n} f_p(x)\n\\end{pmatrix}$$\nUna matrice con p righe e n colonne, che rappresentano tutte le derivate parziali possibile\nOsservazione Da una funzione differenziabile $f(r(x))$ in modo simile a quanto fatto prima, abbiamo che $J_f(r(t)) J_r(t)$ √® uguale al prodotto scalare!\n$$ (\\delta_1f(r(t)), ..., \\delta_nf(r(t))) \\cdot \\begin{pmatrix} \\delta_{s} r_1(t) \\\\ . \\\\ \\delta_{s} r_n(t) \\end{pmatrix} $$Ossia √® proprio $\\delta_t(f(r(t))$ il prodotto scalare, ossia $J_{f \\cdot r}(t)$ e la cosa bella √® che vale per dimensione qualsiasi. (vedere gli appunti lezione 11, ci dovrebbe essere l\u0026rsquo;enunciato di questo).\nComposizione di funzioni\nSi pu√≤ dimostrare che la Jacobiana si comporta bene per le composizione di funzioni ossia:\nE questo vale per funzioni definite per qualunque dimensione.\n$$ J_{g \\cdot f}(v)= J_g(f(v)) J_f(v) $$$$ \\frac{ \\partial y_{i} }{ \\partial x_{j} } = \\sum_{k = 1}^{m} \\frac{ \\partial y_{i} }{ \\partial z_{k} } \\frac{ \\partial z_{k} }{ \\partial x_{j} } $$ Dobbiamo sommare per tutti i $k$ intermedi.\nStudio del massimo e del minimo In pi√π dimensioni non possiamo pi√π applicare lo studio del segno della derivata come nella prima dimensione, in questo momento abbiamo pi√π derivate, e non abbiamo nemmeno il concetto di funzione crescente. Vogliamo affidarci al concetto delle derivate seconde (concavit√† e convessit√†)\nVedere che $f'(x) = 0 \\land f''(x)\u003e0$ oppure minore. Andremo a generalizzare questa idea.\nCondizione di stazionariet√† Andiamo a definire una condizione di stazionariet√† a pi√π dimensione, che ci sar√† molto utile per trovare il minimo locale (o massimo locale).(√® anche chiamato fermat, come ti ricordi qui Teoremi Base Analisi)\nsia $f:A \\to \\mathbb{R}, \\bar{x} \\in A$ √® minimo locale, f √® differenziabile in xbar, allora si ha che $\\nabla f(\\bar{x}) = 0$\nQuando il gradiente si annulla, quel punto in cui si annulla si chiama punto critico o stazionario.\nLa stazionariet√† non permette di distinguere massimi e minimi (valeva anche per R dim 1 Def: punto di sella √à la generalizzazione di un punto di flesso (in cui 2 derivata seconda si annullava).\nsia $f$ una funzione ben definita differenziabile tale che il suo gradiente sia 0 in un punto a. Allora si dice che il punto a √® di sella se esistono due punti $x_{0}, x_{1}$ per ogni intorno di $a$, tali per cui $f(x_{0}) \u003c f(a) \u003c f(x_{1})$\nIn pratica mi sta dicendo che comunque io mi avvicini a questo punto, riesco sempre a trovare un punto la cui immagine √® minore, e riesco sempre a trovare un punto la cui immagine √® maggiore.\nQuesto √® la terza possibilit√†, nel caso questo punto stazionario non sia n√© massimo n√© minimo.\nNecessit√† della differenziabilit√† Affinch√© valga la condizione di stazionariet√† devono sempre esistere almeno le derivate parziali in OGNI direzione.\nQuesto √® utile per le considerazioni dell\u0026rsquo;inverso, in quanto per $f(x) = \\lvert x \\rvert$, nel punto 0 non √® differenziabile, ma √® un punto di minimo.\nDimostrazione Sia f ben definita e a un punto di minimo locale, vogliamo dimostrare che ogni derivata parziale in questo punto sia 0. (ovvero che il gradiente sia 0).\nConsideriamo $g(t) = f(a + te_1)$, ovvero incrementato solamente nella direzione 1. Poich√© f ha minimo in a, ho che per t=0 ho un minimo locale di g (dato che g √® scritta in funzione di f).\nHo che la derivata di g √® la derivata parziale di f (per come √® definita), quindi g √® differenziabile poich√© per ipotesi f √® differenziabile. Per fermat, in quanto t=0 √® un punto di minimo, ho che la derivata di g in t = 0 √® 0, quindi applicando questa idea per ogni direzione ho che l\u0026rsquo;intero gradiente √® 0.\nDerivata seconda Possiamo derivare parzialmente in pi√π direzioni\nDerivate seconde pure se derivo rispetto alla stessa variabile anche la seconda volta\nDerivate seconde miste se derivo rispetto a una variabile differente.\nMatrice Hessiana Questa matrice contiene tutte le derivate seconde possibili per una certa funzione da Rn a R (sar√† di dimensione n x n\n$$ Hf(x) = \\begin{pmatrix} \\delta_{11} f(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{1n} f(x)\\ . \u0026amp; . \u0026amp; . \\ \\delta_{n1} f(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{nn} f(x)\n\\end{pmatrix} $$\nTeorema di Schwarz Sia $f$ una funzione ben definita, con dominio multidimensionale. Siano tutte le derivate seconde ben definite.\nAllora $\\forall ij \\in \\{1,..,n\\}, i \\neq j$ si ha che $\\delta_{ij}f = \\delta_{ji}f$, ossia √® un altro modo per dire che la matrice hessiana √® simmetrica.\nDimostrazione l\u0026rsquo;idea principale √® utilizzare qualcosa di simile alla differenziabilit√† per continuit√† e derivabilit√† parziale. Considero $g(h) = f(x + h, y+h) + f(x, y) - f(x + h,y) - f(x, y + h)$\npoi considero $u(t) = f(x + t, y+h) + f(x, y) - f(x + t,y) - f(x, y + h)$ e utilizzando lagrange due volte ottengo che $g(h) = \\delta_{xy}f(x + ah, y + bh)h^2$\nCome usare Lagrange due volte Noto che $u(h) = g(h)$ e che $u(0) = 0$. Per Lagrange noto che $u(h) - u(0) = h\\cdot u'(\\theta_1 h)$ con theta da 0 a 1. Facendo la derivata prima di $u$ ottengo che √® uguale a $\\delta_x f(x + t, y+ h) - \\delta_x f(x + t, y)$ perch√© il resto √® costante in t. Utilizzando di nuovo taylor su questo (su y) ottengo che $$ \\delta_x f(x + t, y+ h) - \\delta_x f(x + t, y) = h \\delta_y(\\delta_x f(x + t, y + \\theta_2 y)) $$ mettendo tutto all\u0026rsquo;inizio, ottengo che $g(h) = u(h) - u(0) = h^2 \\delta_y(\\delta_x f(x + \\theta_1h, y + \\theta_2 h))$ Lo faccio ancora per il simmetrico (cio√® costruendomi una funzione v(t) che vari a seconda della y e mi trovo che $g(h) = \\delta_{yx}f(x + ah, y + bh)h^2$\nFaccio il limite per h tendente a 0, dividendo per la stessa variabile, e trovo che sono esattamente uguali. cio√® $\\lim_{h \\to 0} \\dfrac{\\delta_{yx}f(x + ah, y + bh)h^2}{h^2} = \\lim_{h \\to 0} \\delta_{yx}f(x + ah, y + bh)= \\delta_{yx}f(x,y)$ l\u0026rsquo;ultimo uguale √® giustificabile per la continuit√† della funzione f (basta aprire e controllare üôÇ).\nForma Hessiana Conoscendo le forme quadratiche, possiamo andare a definire una forma Hessiana di una funzione di classe $C^{2}$.\nLa forma hessiana di una funzione di class $C^2$ √® la funzione cos√¨ definita:\n$h\\to \\langle Hf(x) h, h\\rangle$\nTaylor di ordine 2 Resto secondo Peano Questa √® una analisi multivariabile vedere sotto per il caso univariabile col resto espresso in altro modo.\nPossiamo andare a definire una funzione di taylor per funzioni do ordine superiore, lo facciamo utilizzando la matrice hessiana (per definire la derivata seconda üòÄ) Possiamo andare in teoria anche a definire formule di taylor di ordine superiore al 2 ma per questo corso finiamo qui. (probabilmente ci saranno matrici pi√π complicate, e di dimensioni maggiori).\nVogliamo dimostrare che $\\forall v \\in \\R^n$\n$$ f(w + tv) = f(w) + \\langle\\nabla f(w), tv\\rangle + \\dfrac{1}{2}\\langle H(f(w)) tv, tv\\rangle + o(|t^2|), \\\\t \\to 0_v, v\\in Dominio $$ Osservazione paraboloide\nScriviamolo in maltro modo:\n$f(w) = f(v) + \\langle\\nabla f(v), w - v\\rangle + \\dfrac{1}{2}\\langle H(f(v)) w - v, w - v\\rangle + o(|(w - v)^2|), w \\to v$\nQuesta √® una funzione al secondo ordine in w, √® un paraboloide in cui possiamo andare a cercare la miglior funzione in questa classe di funzioni quadratiche.\nDimostrazione definiamo $g(t) = f(w + tv)$, la derivata √® uguale a $g'(t) = \\delta_t f(r(t))$ con $r(t) = w + tv$ che per il teorema della derivata di funzioni composte √® $\\langle \\nabla f(w + tv), v \\rangle$ Calcoliamo la derivata seconda di questo, ovvero si va ad ottenere: (praticamente sto applicando la 10.4.4 estensivamente.\n$$ \\sum \\delta_t (\\delta_k f) (r(t))v_k = \\sum \\langle(\\nabla\\delta_k f) (r(t)), r'(t)\\rangle v_k \\\\ = \\sum \\langle(\\nabla\\delta_k f) (r(t)), v\\rangle v_k = \\sum\\sum \\delta_j \\delta_k f(r(t) v_jv_k = \\\\ \\langle Hf(r(t))v,v\\rangle $$In quanto $g: \\mathbb{R} \\to \\mathbb{R}$ possiamo utilizzare taylor classico per affermare che $g(t) = g(0) + g'(0) t + \\dfrac{1}{2}g''(0)t^2 + o(t^2)$, che per dimostrazione precedente, sostituendo pezzo per pezzo, si ottiene che $f(w + vt) = f(w) + \\langle \\nabla f(w), v \\rangle t + \\dfrac{1}{2}\\langle Hf(w)v,v\\rangle t^2 + o(t^2)$ il che finisce la dimostrazione\nResto secondo Lagrange (univar) Questo √® equivalente al precedente, col resto secondo Peano.\nSia $f:\\mathbb{R} \\to \\mathbb{R}$ f derivabile due volte, allora\n$\\forall x, \\bar{x} \\in \\mathbb{R} , \\exists c \\in [x, \\bar{x}]$ tale per cui\n$$ f(x) = f(\\bar{x}) + f'(\\bar{x})(x - \\bar{x}) + f''(c) \\dfrac{(x - \\bar{x}) ^2}{2} $$ Note sulla dimostrazione Noto che l\u0026rsquo;unica cosa che cambia √® la parte finale della somma, quindi vorrei in qualche modo dimostrare che queste due cose siano uguali.\nIo aggiungo e tolgo questo valore : (imprecisato) e riesco a dire la funzione ottenuta √® un opiccolo per la continuit√† della derivata seconda. questo nella direzione lagrange $\\implies$peano\nNon so esattamente cosa stia facendo in questo momento il prof. Quindi la ometto, dico solo che stranamente sta cercando dimostrare che esiste un valore $k \\in R$ tale che\n$f(x) = f(\\bar{x}) + f'(\\bar{x})(x - \\bar{x}) + k{(x - \\bar{x}) ^2}$ e lo dimostra utilizzando Rolle presente in Teoremi Base Analisi costruendosi una funzione che prenda la roba di sopra.\nOssia mi creo $g(\\bar{x}) = f(x) - f(\\bar{x}) -f'(\\bar{x})(x - \\bar{x}) - k{(x - \\bar{x}) ^2}$ In secondo momento calcolandosi il valore della derivata della funzione cos√¨ creata si ottengono altri valori.\nNel caso in cui derivata seconda √® continua Allora posso dimostrare quanto sopra, semplicemente utilizzando la continuit√† della derivata seconda, perch√© cambiano di poco le due cose.\nResto secondo Lagrange in Rn (multivar) Sia $A \\subseteq \\mathbb{R}^n$ aperto e $f$ di classe $C^2(A)$ ovvero con le derivate seconde continue.\nSia $a, a+h \\in A$ e il segmento $[a, a+h] \\subseteq A$ allora esiste $\\theta \\in (0,1)$ tale che\n$$ f(a + h) = f(a) + \\langle\\nabla f(a), h\\rangle + \\dfrac{1}{2}\\langle H(f(a + \\theta h)) h, h\\rangle $$ Dimostrazione\nconsidero la parametrizzazione data dalla funzione\n$g(t) = f(a + th)$, notiamo che $g(0) = f(a)$ e $g(1) = f(a + h)$ che sono le cose da cui eravamo partiti. se prendiamo $r(t) = a + th$ si ha che $g(t) = f(r(t))$ e allora possiamo utilizzare la derivata di funzioni composte e riscriverla.\nPoi si procede in modo equivalente alla dimostrazione del teorema di lagrange con resto di peano (per√≤ si parte con lagrange con resto lagrange in R).\nPolinomio di Taylor √à un taylor senza o-piccolo, per√≤ di devi andare a cercare l\u0026rsquo;appunto giusto.\nForme quadratiche Queste cose sembrano essere un buon utilizzo della matrice hessiana. Comunque vediamo cosa sono: prendiamo una matrice $A \\in \\mathbb{R}^{n \\times n}$ tale che sia simmetrica, consideriamo una funzione $q_A : \\mathbb{R} ^n \\to \\mathbb{R}$ definita in questo modo : $q_A(h) = \\langle Ah, h\\rangle = h^TAh$. Scopriremo che c\u0026rsquo;√® una equivalenza (forse isomorfismo) fra un polinomio di grado n e una matrice n per n. Si pu√≤ dimostrare che √® uguale a una forma quadrata questa matrice, questo perch√© $\\sum^n_{k,j=1} a_{kj}h_jh_k = \\sum^n_{k=1}a_k h^2_k + 2 \\sum_{ 1\\leq j \u003c k \\leq n} a_{jk} h_j h_k$ ed √® qualcosa di molto comodo perch√© questo non √® altro che (ricordando che $a_k$ √® un modo semplice per scrivere $a_{kk}$\n$$ \\langle Ah, h\\rangle = (a_1h_1 + ...+ a_nh_n)^2 $$Ma questo vale nel caso solo in cui $a_ia_k = a_{ik}$, da ricordare!. Comunque c\u0026rsquo;√® questa buonissima corrispondenza e ci piace molto.\nSegno della forma quadratica Positivo (Negativo) Se per ogni $h \\in \\mathbb{R}^{n} \\neq 0$ si ha che la forma quadratica $q(h) \u003e 0 (\u003c0)$ Esempio se ho solo numeri sulla diagonale, probabilmente √® di segno positivo\nSemi positivo (negativo) Uguale a sopra, ma possiamo avere anche l\u0026rsquo;uguale\nIndefinita Se esistono $h_{1}, h_{2}$ per qui $q(h_{1}) \u003e0$ e che $q(h_{2}) \u003c 0$.\nAltro Ci sono anche altre caratterizzazione della forma quadratica. ad esempio q(h1, h2) = h2^2 non √® n√© indefinita, n√© positiva questa √® semidefinita\nClassificazione del segno n-dimensionale Vogliamo una forma quadratica in Rn, con n‚â•3 ora.(fino ad ora abbiamo solamente considerato il caso in cui forma quadratica √® 2).\nDeterminanti\nMi sono costruito molte sottomatrici.\nLavagna prof\nAutovalori\nCriterio di Sylvester Questo criterio, spiegato qui √® un metodo molto conveniente per stabilire se una matrice √® definita positiva. In breve, una matrice lo √®, se tutte le sotto matrici $\\forall n \\in \\left\\{ 1,\\dots, N \\right\\}:n\\times n$ che partono dall\u0026rsquo;angolo in alto a sinistra della matrice generale, hanno determinanti positivi.\nTeorema criterio classificazione 2x2 $$ \\begin{pmatrix} a \u0026 b \\\\ b \u0026 c \\\\ \\end{pmatrix} $$ Allora possiamo individuare i seguenti casi:\nPositivo Una forma quadratica √® positiva sse $a \u003e 0 \\land ac - b^2 \u003e 0$\nNegativa Una forma quadrata √® negativa sse $a \u003c 0 \\land ac - b^2 \u003e 0$\nIndefinita sse il determinante √® negativo., se il determinante √® 0 si dice che √® una matrice singolare.\nDimostrazione primo caso vogliamo dimostrare un sse, andiamo per le due frecce. $\\implies$ Se pongo h = (1, 0) ottengo $a \u003e 0$ quindi deve essere cos√¨ altrimenti assurdo.\nse pongo h = (h,1) (nota questi due h sono diversi) ottengo $ah ^2 + 2bh + c$ che √® sempre positivo quando il determinante √® negativo, quindi verificato\n$\\impliedby$ Se $h_2 = 0$ ottengo $ah^2_1 \u003e 0$ vero perch√© a \u0026gt; 0 e ho un quadrato in R\nSe $h_2 \\neq 0$, allora raccogliendo un h2 e ponendo $e = \\dfrac{h1}{h2}$, ottengo\n$q(h) = ae^2 + 2be + c \u003e 0$ (gi√† diviso per h2 alla seconda), prendendo il determinante ho che √® $b^2 - ac$ , che √® sempre minore di 0, quindi sempre vera.\nSemidefinito\nQuando ho il determinante che √® 0\nCaratteristica positivit√† negativit√† della Forma Quadratica Possiamo trovare una caratteristica fondante per le matrici positive e negative (sono uguali ma inverse, enunciamole).\nSia $A = A ^t \\in \\mathbb{R} ^{n \\times n}$ allora se $A$ √® definito positivo si ha che $\\exists m \u003e 0$\n$\\langle Ah, h\\rangle \\geq m \\lvert h \\rvert^2$\nHint di dimostrazione (osservazione) Questo √® vero perch√© se consideriamo un $h \\neq 0$, possiamo riscrivere l\u0026rsquo;equazione in tesi come $\\langle A \\dfrac{h}{\\lvert h \\rvert}, \\dfrac{h}{\\lvert h \\rvert}\\rangle \\geq m$, che √® equivalente a dire che comunque prendo un vettore unitario, si ha che la forma quadratica √® maggiore di un numero m.\nDimostrazione Allora scrivo h con coordinate polari, apro A in dimensione 2 e raccolgo questo $r ^2$. Allora ho in tesi qualcosa di questo tipo $r ^2 f(\\theta) \\geq r^2 m$ e devo dire che esiste questo m. utilizziamo 2 cose per terminare.\n$r^2 f(\\theta) \u003e 0$ in quanto la forma quadratica √® positiva f √® una funzione continua, e limitata in $[0, 2\\pi] \\in \\mathbb{R}$, quindi possiamo usare Weierstrass per concludere che esiste un minimo. √® proprio questo il minimo! Concludo dicendo che $r^2 f(\\theta) \\geq r^2 m$ per ogni theta, in particolare il minimo √® maggiore di 0 in quanto per ipotesi la hessiana √® positiva, quindi ho finito qui\nDimostrazione con autovalori Condizione sufficiente per minimo e massimo e sella Questa cosa ci piace per calcolare i punti di massimi e minimi!\nMassimo Se il gradiente √® 0 e la hessiana √® definita negativa, ho un punto di massimo.\nMinimo Grandiente 0 e hessiana √® definita positiva, ho un punto di minimo.\nIndefinita Se gradiente √® 0 e la hessiana √® indefinita √® un punto di sella.\nDimostrazione (minimo)\nConsideriamo una funzione $f :A \\subseteq \\mathbb{R}^n \\to \\mathbb{R}$ di classe $C^2$ consideriamo un punto $a \\in A$ tale che $\\nabla f(a) = 0$ e so che $Hf(a) \u003e0$. Voglio dimostrare che sia un minimo locale, ovvero che $\\exists \\delta \u003e0$ tale che $f(a + h) \\geq f(a)$ per ogni $h \\in B(0, \\delta)$, ossia $|h| \u003c \\delta$ Espando con Taylor, e utilizzo l\u0026rsquo;ipotesi di punto critico e ottengo che $f(a + h) - f(a) = \\dfrac{1}{2} \\langle Hf(a),h,h \\rangle + o(|h^2|)$ voglio dimostrare che per un delta opportuno RHS sia maggiore di 0, se ho questa cosa ho finito, in qualche modo voglio utilizzare la positivit√† della matrice hessiana.\n$$ f(a + h) - f(a) \\geq |h^2|(m/2 - m/4) \\geq 0 $$ (abbiamo anche dimostrato che dipende da h) per√≤ √® finito, questa cosa vale per ogni h nell\u0026rsquo;intorno scelto sopra.\nSemidefinita\nNel caso in cui il determinante della hessiana √® 0, non posso utilizzare i metodi precedenti, quindi in questo caso devo dividere il processo analizzando le derivate parziali.\nCondizione necessaria per minimo e massimo √à molto simile alla condizione sufficiente, solo √® abbiamo ora che la hessiana pu√≤ anche essere semidefinita positiva.\n","permalink":"https://flecart.github.io/notes/massimi-minimi-multi-variabile/","summary":"\u003ch2 id=\"matrice-jacobiana\"\u003eMatrice Jacobiana\u003c/h2\u003e\n\u003cp\u003e√à un modo per scrivere il gradiente di una funzione quando √® in una certa forma.\u003c/p\u003e\n\u003cp\u003eData una funzione $f: \\mathbb{R}^n \\to \\mathbb{R}^p$\nossia per esempio $x=(x_1,...,x_n) \\to(f_1(x),...,f_p(x))$\nSe le p funzioni di arrivo sono differenziabili, allora la matrice Jacobiana √® definita in questo modo:\u003c/p\u003e\n\u003cp\u003e$$J_f(x) = \\begin{pmatrix}\n\\delta_{x_1} f_1(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{x_n} f_1(x)\\\n. \u0026amp; . \u0026amp; . \\\n\\delta_{x_1} f_p(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{x_n} f_p(x)\u003c/p\u003e","title":"Massimi minimi multi-variabile"},{"content":"We have a group of mappers that work on dividing the keys for some reducers that actually work on that same group of data. The bottleneck is the assigning part: when mappers finish and need to handle the data to the reducers.\nIntroduction Common input formats üü® You need to know well what\nShards Textual input binary, parquet and similars CSV and similars Sharding üü© It is a common practice to divide a big dataset into chunks (or shards), smaller parts which recomposed give the original dataset. For example, in Cloud Storage settings we often divide big files into chunks, while in Distributed file systems the system automatically divides big files into native files of maximum 10 GB size.\nThis has two main advantages:\nWe can use the MapReduce framework to process the chunk in a highly parallelized manner. We are more robust to network communication . MapReduce We can process terabytes of data with thousands of nodes with this architecture.\nLogical Model General framework üü© We can see in the image taken from the course book [({fourny} 2024)](https://ghislainfourny.github.io/big-data-textbook/), that there are two general phases for the map reduce framework: 1. First phase is mapping, where the data is divided into chunks and processed by the mappers, then these are delivered to the designated reducers. This is usually the bottleneck, the part that runs in $\\mathcal{O}(n^{2})$. 2. The reduce process connects to all other machines to get the their own mapped value. 3. Reducers then processed the partitioned, probably homogeneous data and return a result, which is often a file in HDFS. Key Value Pairs üü© We have seen that MapReduce is composed of mainly two parts:\nOne part where we are extracting the data from various sources (Could be cloud, distributed files systems, wide column storages etc\u0026hellip;) We map this data to the correct reducer This part often produces some spaghetti like data flows in it. Which has some weird shapes of arrows in all directions (some parts could be more linear, while others could be more spaghetti like) The final part is the reduce where the actual value is produced and stored. The three parts in principle can have different key types, but they need to have some key type known at compile time. But often the output key and the key input to the reducer have the same type.\nThe Architecture Centralized Architecture üü©\u0026ndash; Hadoop MapReduce builds upon a centralized architecture compatible to Distributed file systems and HBase. In this case there is a Jobtracker, often in the same node as the NameNode; and Tasktrackers that are in the same node as the DataNodes. We have now three processes on the same machine. When MapReduce finishes, usually every TaskTracker produces a file in the disk (usually sharded, numerated increasingly). If the task fails for a node, the Jobtracker usually re-assigns the node to another.\nJobtracker\u0026rsquo;s responsibilities The Jobtracker has many responsibilities, see (Dean \u0026amp; Ghemawat 2008):\nTracking the state of each map and reduce task (idle, executed, on execution). Actively pinging the Tasktrackers to see if they are still active or dead. If a worker has died, then re-issue the task to another machine. In the case a map machine has failed, it should issue all reducers to read from the machine of the newly-assigned worker. Scheduling the tasks to account for locality information (meaning usually the map task needs a split that is in the same node, or on node close by it). Impendance Mismatch üü© MapReduce needs to have key-values to process the files. For text, we usually use the lines and its character offset to index them. We could also use a special character to separate different parts of the text. Often this part part of preprocessing the dataset so that it is understandable by mapreduce is called impendance mismatch\nTask Granularity We subdivide the map phase into M pieces and the reduce phase into R pieces, as described above. Ideally, $M$ and $R$ should be much larger than the number of worker machines. From (Dean \u0026amp; Ghemawat 2008).\nThe reason why $M$ and $R$ should be larger is that in this manner we have better load balancing. Usual numbers are: $M$ knowing the size of the original dataset, the aim is to keep the blocks of data around 64MB, the size of a Google GFS. $R$ is usually a multiple of the number of reduce nodes. The paper reports usual numbers like: $M = 200'000$ and $R = 5'000$, using 2,000 worker machines.\nCombining üü© This is a form of optimization. Recall that a big bottleneck of this system is the network communication, when we are mapping, we can do part of the reducing step so that later we have fewer key-value pairs to transmit. Often the combining step is the same as the reducing step. But this is not often possible:\nType must be the same for reduce function. We need to have commutative and associative functions for reduce. After the combining step we have the following diagram: And there will be less overload on the network, which makes the whole thing faster.\nRule of thumb: tasks are 3x the number of nodes that are mapping and reducing.\nOn Terminology You need to know what maps, reducer and combiners are. You also need to know what tasks, slots and phases, are.\nFunctions üü© The only difference between a map and reduce function, is that the former takes a single key-value pair as input, while the second can take one or more. Both of them are functions that can produce zero, one, or more output key-value pairs. The combine function has the same definition as the reduce function.\nTasks üü© Tasks are sequential calls to the respective functions. If we consider map-tasks for example, then the number of map function calls within the task is the the number of key-value pairs within an input task. The input split is so divided into many mapping tasks, and each task calls the mapping function individually for each key-value pair.\nSame thing could be said for reduce tasks: they are sequential calls to the reduce function on a subset of intermediate key-value pairs.\nBut, there are no combine tasks, as they are immediately executed after the map function, if any.\nSlots üü© Slots are bundles of resources like CPU cores, memory resources, and network bandwidth. Usually, a single node could have more than one slot, which helps to handle the different needs for resources of different slots (some could need more memory, while others on the same node could need less memory, this better balances it).\nA Map Slot is usually a single CPU core with some memory. As we have a single core, the slot processes a single map task at a time, but several map tasks after one other.\nSame thing is said for Reduce Slots, but in this case we are talking about reduce functions.\nPhase üü© The map phase is several map slots processing several map tasks in parallel. Same thing is said for the reduce phase. With the standard MapReduce framework, slots are allocated statically at the beginning, which could hinder performance. Innovation like YARN ease this problem, we will talk about this in the following sections.\nSplits and Blocks üü• the data belonging to the split that is the input of a map task resides on the same machine as the map slot processing this map task.\nSplits are map or reduce partition sets of the whole data that needs to be processed. This is physically stored in HDFS blocks. These blocks are exactly of size 128MB, which implies the first and last key-values could be splitted in different blocks. This is an inconvenience as one needs to fetch also the preceding and successive blocks. This is why in HDFS\u0026rsquo;s api one can read blocks partially. The underlying details on how these optimizations are done are not covered here.\nResource Management We now introduce ResourceManagers, ApplicationManagers and NodeManagers. See here. For a not checked explanation.\nBottlenecks of the original version Jobtrackers were the bottleneck and have many responsibilities.\nJobtracker\u0026rsquo;s single point of failure With the above traditional MapReduce function, the Jobtracker is just assumed not to die: (Dean \u0026amp; Ghemawat 2008). This is clearly a single point of failure. Here the idea is to shift the responsibility of managing the job to some specific slot (container) within the tasktracker.\nSome responsibilities of the Jobtracker\nResource Management Monitoring every task\u0026rsquo;s progress Job scheduling This point of failure is still not solved! The Resource Manager becomes the next point of failure within the system!\nScalability issues :üü© This is usually a bottleneck in this model. Clusters of about 4,000 become usually very very slow and about 10,000 tasks. Another drawback is that many reducers are idle during the map phase.\nContainers are virtual collections of slots (one container could have more than one map or reduce slot), each with some cpu and some amount of memory.\nOther bottlenecks üü• Scalability : MapReduce has limited scalability, while YARN can scale to 10,000 nodes and 100,000 tasks, one order of magnitute higher compared to classical MapReduce! Rigidity : MapReduce v1 only supports MapReduce specific jobs. There is a need, however, for scheduling non-MapReduce workloads. For instance, we would like the ability to share cluster with MPI, graph processing, and any user code. Resource utilization : in MapReduce v1, the reducers wait on the mappers to finish (and vice-versa), leaving large fractions of time when either the reducers or the mappers are idle. Ideally all resources should be used at any given time. Flexibility : mapper and reducer roles are decided at configuration time, and cannot be reconfigured, this is also called lack of fungibility. Spark makes use of in-memory data too, making the access to data much faster.\nAdvantages of MapReduce Nonetheless, there could be cases where MapReduce is better than Spark, for example when the data is too big to fit in memory.\nUltra-large datasets that do not fit in memory: For massive datasets that don‚Äôt fit even across a large Spark cluster‚Äôs memory, MapReduce‚Äôs disk-based processing can be more manageable. Strict fault tolerance requirements: MapReduce‚Äôs fault tolerance mechanism is very robust, as it writes intermediate results to HDFS, which may be preferred in environments where data recovery is critical. Low hardware resources: Spark requires more memory and computational resources than MapReduce, so in resource-constrained environments, MapReduce may be a more practical choice. ApplicationMaster and ResourceMaster YARN decouples the scheduling of the jobs, the allocation of resource of the jobs, and the monitoring of the jobs, the first is done by the ResourceMaster, the last by the ApplicationMaster, while the middle one is done in collaboration.\nThis is an innovation introduced by the YARN architecture. With this new architecture we have containers and a resource manager that allocates resources to the tasks that need to be processed.\nResourceMaster The ResourceMaster\u0026rsquo;s main job is to grant:\nleases for resources when the ApplicationManager requests it. Schedule the jobs, and track only the state (on queue, executed, done). Accept requests by clients for jobs. Track the resources requested by each application. Disaster recovery The RM recovers from its own failures by restoring its state from a persistent store on initialization. Once the recovery process is complete, it kills all the containers running in the cluster, including live ApplicationMasters. It then launches new instances of each AM. From (Vavilapalli et al. 2013).\nApplicationMaster When a user starts a task, the resource manager elevates a container to be the application master by communicating with a process. This container then takes part of the responsibilities of the Jobtracker in the old version;\nit now tracks task state, as done with the Jobtracker, re-allocates other containers when one fails (expects liveliness by the worker machines) it asks or releases resources to the resource manager, at any time. (they are quite good with pre-emption, see Gestione delle risorse). Send HeartBeats to the resource-manager to signal he is still alive. NodeManagers These processes run on everynode in the cluster, and are responsible for:\nMonitoring the resources on the node (CPU, memory, disk, network) Reporting to the ResourceManager (using heartbeats) Managing the containers on the node. If a NodeManager dies, the ResourceManager assumes all the containers on the node are gone, and reports failure to all ApplicationManagers, who then will re-request resources and update their state tracking part. Setting up a task üü® ApplicationMasters can request and release containers at any time, dynamically. A container request is typically made by the ApplicationMasters with a specific demand (e.g., ‚Äú10 containers with each 2 cores and 16 GB of RAM‚Äù). If the request is granted by the ResourceManager fully or partially, this is done indirectly by signing and issuing a container token to the ApplicationMaster that acts as proof that the resource was granted. The ApplicationMaster can then connect to the allocated NodeManager and send the token. The NodeManager will then check the validity of the token and provide the memory and CPU granted by the ResourceManager. The ApplicationMaster ships the code (e.g., as a jar file) as well as parameters, which then runs as a process with exclusive use of this memory and CPU. ~From the Book ({fourny} 2024)\nThe main facts to keep in mind:\nApplicationMasters can set up and release resources dynamically at any time ApplicationMasters can request resources in a fine-grained manner, asking for exactly a specific amount of resources to the ResourceManager The Granting procedure uses authorization tokens. Code is usually shipped by the ApplicationMaster to the worker container. ApplicationMasters can be pre-empted by the ResourceManager if the resources are needed by another application. All the information to create a container is called Container Launch Context or CLC for short. Containers usually contain many slots, in fact they can execute several tasks in parallel.\nResource tracking Also in this case, as has been done similarly for Distributed file systems and others, we track the available resources of each machine using heartbeats sent by NodeManagers to the ResourceManager. In this way, the ResourceManager knows exacly what is the load of each node.\nScheduling methods Queue scheduler üü© For example, the queue scheduler where a job takes the whole cluster one after the other. But it\u0026rsquo;s probably not efficient as it doesn\u0026rsquo;t allow for multiple-tenancy of the cluster.\nCapacity Scheduler üü© Another way could be the hierarchical scheduler where the amount of resource is allocated a priori. This is also called capacity scheduling because the whole cluster is divided into multiple sub-clusters corresponding to a specific department in a university or parts of a company. Then, each department can use a specific local scheduler, which could be a standard fair queue.\nFair Schedule üü® Fair scheduling involves more complex algorithms that attempt to allocate resources in a way fair to all users of the cluster and based on the share they are normally entitled to.\nIt\u0026rsquo;s difficult to orchestrate the allocation of different resources. But how to allocate it correctly when the need of resources is different for other processes? Some processes could need more memory than cpu, Disk and Network Input and Output and others other resources. If some department is not using the resource, then it could be allocated to another department. There are different types of fair scheduling, the next sections briefly examine the main methods of scheduling\nSteady Fair Share üü© This is the share of the cluster officially allocated to each department. The various departments agree upon this with each other in advance. This number is thus static and rarely changes.\nInstantaneous Fair Share üü® this is the fair share that a department should ideally be allocated (according to economic and game theory considerations) at any point in time. This is a dynamic number that changes constantly, based on departments being idle: if a department is idle, then the instantaneous fair share of others department becomes higher than their steady fair shares.\nCurrent Share üü• this is the actual share of the cluster that a department effectively uses at any point in time. This is highly dynamic. The current share does not necessarily match the instantaneous fair share because there is some inertia in the process: a department might be using more resources while another is idle. When the other department later stops being idle, these resources are not immediately withdrawn from the first department; rather, the first department will stop getting more resources, and the second department will gradually recover these resources as they get released by the first department.\nDominant Resource Fairness üü® The idea is quite simple: consider the dominant resource usage by each user. Then allocate the containers in a manner that is constant with respect to max resource usage ratio / number of containers. For example if Alice is using 6% of the available CPU, and Bob 3% of the available RAM, then bob should have twice as the number of containers compared to Alice.\nThree types of schedule sharing TODO: fill this in a later occasion (See page 273 of the book)\nSteady fair share: Instantaneous fair share: Current share: References [1] Dean \u0026amp; Ghemawat ‚ÄúMapReduce: Simplified Data Processing on Large Clusters‚Äù Communications of the ACM Vol. 51(1), pp. 107\u0026ndash;113 2008\n[2] {fourny} ‚ÄúThe Big Data Textbook‚Äù 2024\n[3] Vavilapalli et al. ‚ÄúApache Hadoop YARN: Yet Another Resource Negotiator‚Äù ACM 2013\n","permalink":"https://flecart.github.io/notes/massive-parallel-processing/","summary":"\u003cp\u003eWe have a group of mappers that work on dividing the keys for some reducers that actually work on that same group of data. The bottleneck is the assigning part: when mappers finish and need to handle the data to the reducers.\u003c/p\u003e\n\u003ch3 id=\"introduction\"\u003eIntroduction\u003c/h3\u003e\n\u003ch4 id=\"common-input-formats-\"\u003eCommon input formats üü®\u003c/h4\u003e\n\u003cp\u003eYou need to know well what\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eShards\u003c/li\u003e\n\u003cli\u003eTextual input\u003c/li\u003e\n\u003cli\u003ebinary, parquet and similars\u003c/li\u003e\n\u003cli\u003eCSV and similars\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"sharding-\"\u003eSharding üü©\u003c/h4\u003e\n\u003cp\u003eIt is a common practice to divide a big dataset into \u003cem\u003echunks\u003c/em\u003e (or shards), smaller parts which recomposed give the original dataset.\nFor example, in \u003ca href=\"/notes/cloud-storage/\"\u003eCloud Storage\u003c/a\u003e settings we often divide big files into chunks, while in \u003ca href=\"/notes/distributed-file-systems/\"\u003eDistributed file systems\u003c/a\u003e the system automatically divides big files into native files of maximum 10 GB size.\u003c/p\u003e","title":"Massive Parallel Processing"},{"content":"The maximum entropy principle is one of the most important guiding motives in artificial artificial intelligence. Its roots emerge from a long tradition of probabilistic inference that goes back to Laplace and Occam\u0026rsquo;s Razor, i.e. the principle of parsimony.\nLet\u0026rsquo;s start with a simple example taken from Andreas Kraus\u0026rsquo;s Lecture notes in the ETH course of Probabilistic Artificial Intelligence:\nConsider a criminal trial with three suspects, A, B, and C. The collected evidence shows that suspect C can not have committed the crime, however it does not yield any information about sus- pects A and B. Clearly, any distribution respecting the data must assign zero probability of having committed the crime to suspect C. However, any distribution interpolating between (1, 0, 0) and (0, 1, 0) respects the data. The principle of indifference suggests that the desired distribution is $(\\frac{1}{2}, \\frac{1}{2}, 0)$, and indeed, any alterna- tive distribution seems unreasonable.\n$$ H[p] = \\mathbb{E}_{x \\sim p}[-\\log p(x)] $$Gaussian as Maximum Entropy Distribution One nice thing about Gaussians is that this distribution has the maximum entropy between all distributions with known mean and variance. So we can say that it\u0026rsquo;s the distribution that assumes less information: it\u0026rsquo;s the distribution that best applies Occam\u0026rsquo;s Razor.\nLet\u0026rsquo;s say $f \\sim \\mathcal{N}(f; \\mu, \\Sigma)$ and assume we have another distribution $g$ with the same mean and variance. Then we can say that $f$ is the distribution that maximizes the entropy.\n$$ H[g\\mid f] = \\mathbb{E}_{x \\sim g}[-\\log f(x)] = \\mathbb{E}_{x\\sim f}[-\\log f(x)] = H[f] $$$$ KL(g \\mid f) = H[g \\mid f] - H[g] = H[f] - H[g] \\implies H[f] \\geq H[g] $$ For every possible distribution with same mean and Variance.\n","permalink":"https://flecart.github.io/notes/maximum-entropy-principle/","summary":"\u003cp\u003eThe maximum entropy principle is one of the most important guiding motives in artificial artificial intelligence. Its roots emerge from a long tradition of probabilistic inference that goes back to Laplace and Occam\u0026rsquo;s Razor, i.e. the principle of parsimony.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s start with a simple example taken from Andreas Kraus\u0026rsquo;s Lecture notes in the ETH course of Probabilistic Artificial Intelligence:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eConsider a criminal trial with three suspects, A, B, and C. The\ncollected evidence shows that suspect C can not have committed\nthe crime, however it does not yield any information about sus-\npects A and B. Clearly, any distribution respecting the data must\nassign zero probability of having committed the crime to suspect\nC. However, any distribution interpolating between (1, 0, 0) and\n(0, 1, 0) respects the data. The principle of indifference suggests\nthat the desired distribution is $(\\frac{1}{2}, \\frac{1}{2}, 0)$, and indeed, any alterna-\ntive distribution seems unreasonable.\u003c/p\u003e","title":"Maximum Entropy Principle"},{"content":"Ultima modifica: September 18, 2022 9:43 AM Primo Abbozzo: September 16, 2022 9:52 AM Studi Personali: Yes\nElementi di ripasso Measure Theory Introduzione Requirements of the measure function Vorremmo cercare di estendere il concetto di misurabilit√† a gruppi molto pi√π ampi di un singolo intervallo, vorrei creare una funzione che sia in grado di misurare degli insiemi. *su vedr√† che sono impossibili).\nImpossibilit√† di questi requirements (assurdo) Costruzione dell‚Äôinsieme di interesse\nConsideriamo la classe di equivalenza definita come in immagine, mi costruisco (credo si chiami cosets) $\\Lambda$ in quel modo, prendendo le classi di equivalenza, posso dire che questo lambda non √® numerabile, perch√© se lo fosse ogni elemento di R sarebbe rappresentabile con lambda e un pezzo di X (ad esempio .\nAllora mi costruisco $\\Omega$ definito con assioma della scelta prendendo un singolo elemento in ogni classe di equivalenza. √à chiaro che questo insieme cos√¨ creato sia innumerabile.\nInoltre lo creo in modo che $\\Omega \\subseteq (0, 1)$, credo sia abbastanza intuitivo vedere che c‚Äô√® sempre un elemento compreso, quindi basta traslare.\nOra vado a utilizzare la regola 2, ossia invarianza per traslazione.\n$\\forall p, q \\in \\mathbb{Q}\\, (\\Omega + p) \\cap (\\Omega + q) = \\varnothing \\iff p \\neq q$\nSupponiamo che l‚Äôintersezione non sia vuota, allora $\\exists x : x = \\alpha + p = \\beta + q$, ossia ho che $\\alpha - \\beta = q - p \\implies \\alpha \\equiv \\beta \\implies \\alpha = \\beta \\implies p = q$ l‚Äôuguaglianza dalla relazione di equivalenza deriva dal fatto che appartengono alla stessa classe di equivalenza, ma per costruzione ne ho presa solo una, quindi sono uguali. Quindi se l‚Äôintersezione non √® vuota ho che p e q sono uguali. se sono uguali, invece, √® chiaro che la loro intersezione √® l‚Äôinsieme stesso, quindi non √® vuota.\nUpper bound\nOra che abbiamo questa invarianza, sarebbe utile per cercare di utilizzare 3 e farci dei bounds, e poi dimostrare l‚Äôassurdo con questi bounds, allora considero l‚Äôinsieme $\\bigcup_{-1","permalink":"https://flecart.github.io/notes/measure-theory/","summary":"\u003cp\u003eUltima modifica: September 18, 2022 9:43 AM\nPrimo Abbozzo: September 16, 2022 9:52 AM\nStudi Personali: Yes\u003c/p\u003e\n\u003ch1 id=\"elementi-di-ripasso\"\u003eElementi di ripasso\u003c/h1\u003e\n\u003ch1 id=\"measure-theory\"\u003eMeasure Theory\u003c/h1\u003e\n\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"requirements-of-the-measure-function\"\u003eRequirements of the measure function\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Measure Theory/Untitled.png\" alt=\"image/universita/ex-notion/Measure Theory/Untitled\"\u003e\n\u003cp\u003eVorremmo cercare di \u003cstrong\u003eestendere il concetto di misurabilit√†\u003c/strong\u003e a gruppi molto pi√π ampi di un singolo intervallo, vorrei creare una funzione che sia in grado di misurare degli insiemi. *su vedr√† che sono impossibili).\u003c/p\u003e\n\u003ch3 id=\"impossibilit√†-di-questi-requirements-assurdo\"\u003eImpossibilit√† di questi requirements (assurdo)\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Measure Theory/Untitled 1.png\" alt=\"image/universita/ex-notion/Measure Theory/Untitled 1\"\u003e\n\u003cp\u003e\u003cstrong\u003eCostruzione dell‚Äôinsieme di interesse\u003c/strong\u003e\u003c/p\u003e","title":"Measure Theory"},{"content":"4.1 Caratteristiche della Memoria La gerarchia della memoria, pi√π si va gi√π pi√π spazio si ha, pi√π √® lento il caricamento delle informazioni\n4.1.1 Catalogazione della memoria Le tipologie di memoria sono presenti a fianco.\nIn generale pi√π la memoria √® veloce da riprendere, pi√π √® costosa da memorizzare (c\u0026rsquo;√® poco spazio)\n4.1.2 Byte e Word Il libro a pagina 74 parte con la discussione del perch√© si √® preferito evitare la BCD (Binary coded decimal, in cui i numeri da 0 a 9 erano codificato da 4 bit), per questioni di efficienza.\nLa memoria √®, in modo spiccio, una serie di cellette numerate, ognuno pu√≤ contenere qualche informazione.\nNacque nel 1960 circa con IBM 360 nacque la definizione di byte.\nWord √® una seguenza di byte ‚Üí unit√† di dato che non stanno solamente in un singolo indirizzo.\n4.1.3 Endianess Questi termini descrivono l\u0026rsquo;organizzazione dei bytes all\u0026rsquo;interno della memoria. A volte √® molto conveniente netere i bytes al contrario per facilit√† di accesso.\n4.1.4 RAM Abbiamo presentato il funzionamento hardware della RAM nel momento in cui abbiamo descritto il funzionamento di Circuiti Sequenziali come LATCH SR, D, DFF.\n4.1.5 Paginazione - Caricamento Una altra funzione della gerarchia di memoria √® utilizzare la paginazione, ossia il caricamento di risorse utili nella ram veloce e scaricamento nella memoria secondaria di ci√≤ che non viene utilizzato.\n√à gestito dal sistema operativo.\nSono dei blocchi di data nella memoria principale che vengono caricati nella memoria principale nel momento del bisogno.\nQuindi ci sono proprio degli algoritmi per caricare e scaricare le pagine di memoria dalla memoria principale, gestiti dal sistema operativo.\n4.2 Memoria Cache La cache √® una zona di memoria condivisa alle CPU, di facile accesso (meno facile in confronto ai registri, ma comunque veloce) ma senza molto spazio.\n√à sempre consultata ** prima di andare nella memoria.\nSe va a cercare un word in memoria, questa viene messa nella cache dopo essere ritrovata.\nUna caratteristica principale della cache √® che non √® necessario al programmatore sapere che esiste o meno, √® solo qualcosa che si interpone in modo TRASPARENTE che pu√≤ rispondere subito nel caso possieda una certa informazione.\nMa l‚Äôidea di tenere una memoria pi√π veloce intermedia per dati pi√π utili del prossimo futuro √® una idea che si utilizza anche in altri ambiti (come Disco, accesso messaggi, e simili) e migliora molto la velocit√†.\n4.2.1 Livelli memoria Cache 4.2.2 Principio di localit√† spaziale e temporale Programmi eseguiti vicini nel tempo sono messi in luoghi in memoria vicini\nSi spera di guadagnare tempo in questo modo, cos√¨ √® pi√π facile ritrovare delle informazioni utili quando si eseguono dei comandi vicini nella cache.\nChiaramente se un programma continua a saltare da un indirizzo della memoria a un altro questo principio non ha pi√π senso e la cache servirebbe a poco.\nLocalit√† spaziale e temporale\nUn programma naturale di solito utilizza la cache (un programma potrebbe essere progettato in modo che usi 0 cache, ma sarebbe uno spreco di risorse).\nTemporale: la stessa cella viene acceduta a breve distanza di tempo (come Stack)\nSpaziale: celle vicine possono essere prese a breve tempo di distanza. (per esempio accedere ad un array, accesso sequenziale che ha un nome suo di localit√† sequenziale)\n√à molto facile che la cache debba accedere alla stessa risorsa in termini brevi di tempo\nLocalit√† secondo WIKI\n4.2.3 Efficienza della cache La velocit√† d\u0026rsquo;accesso alla cache √® di granlunga minore rispetto a quello della memoria, di solito il tempo speso per memorizzare qualcosa qui viene sempre recuperato.\nUsiamo un p√≤ di matematica ora per descrivere questa cosa un pochino pi√π rigorosamente:\n$c \u003c\u003c m$ con $c$ il tempo per accedere alla cache e $m$ il tempo per accedere alla memoria.\nAllora si ha che il tempo medio per accedere alle informazioni, tenendo $h$ come hit rate √® di:\n$$ hc + (1 - h)(c + m) = c + (1-h)m $$4.2.4 Cache ad accesso diretto Linee di cache, vanno k mod n, ogni linea di cache di dimensione m. ok? √à una cosa temporale, a seconda di cosa ci sia ora.\nData: √® effettivamente il data che sto prendendo n √® il numero di linee di cache (che decide quanto grande sia la cache). Tag serve per sapere quale blocco sto utilizzando (quindi se 0-31 oppure 65536 e simili) Valid se √® un blocco valido, se √® 0 vuol dire che non √® roba interessante.\nEsempio di query cache Teniamo 5 bit per l\u0026rsquo;indicizzazione dentro i 32 bit di data. 11 bit per sapere quale linea di cache utilizzare 16 bit per confrontare con il tag e vedere se √® giusto oppure no. Cos√¨ riesco a trovare in modo univoco la linea di cache che mi serve. 4.2.5 Cache hit and miss Si dice che si ha un cache hit oppure cache miss a seconda del caso in cui la cache √® riuscita a dare la richiesta oppure meno.\nMiss\nRiportare la cache in memoria centrale in quanto potrebbe essere modificata ora, √® un aggiornamento della roba nella memoria centrale Caricare la nuova memoria. Se per√≤ si tenta di accedere alla cache allo stesso momento, si possono esserci data race e quindi bisognerebbe bloccare l\u0026rsquo;accesso all\u0026rsquo;inizio\nSe vuoi approfondire su algoritmi per la gestione della cache:\nhttps://en.wikipedia.org/wiki/Cache-oblivious_algorithm\ne altro ancora\n4.3 Memoria secondaria Storicamente le velocit√† delle CPU si sono sviluppate molto pi√π velocemente rispetto alle memorie secondarie.\n4.3.1 Hard Disk (4) I dischi magnetici oppure Hard disk sono generalmente in tre parti:\nSettore √® il nome di una traccia specifica di memoria di dimensione fissata. Traccia √® una sequenza di bit circolari Testina che magnetizza e modifica il contenuto nel disco. Controllore Disco . Ogni settore comincia con un preamble che dovrebbe aiutare a diminuire gli errori di lettura.\nPer dare un senso, circa in un centimetro di Hard Disk ci possono stare parecchi giga di informazioni.\nI dati posso essere messi in due modi:\nStessa densit√† per angolo (pi√π rientri pi√π hai i dati in modo compatto) Diverso numero di settori (la parte esterna del disco contiene pi√π settori) Processo di recupero di dati:\nLa CPU dice di andare a recuperare un blocco in un certo indirizzo di memoria La testina gira e va fisicamente a recuperare la zona di memoria 4.3.2 SSD SSD or Solid State drive non hanno nessuna parte che si muove quindi sono meno soliti a rompersi meccanicamente, tutto elettronico.\nStoricamente sono state utilizzate per portatili per resistenza ad urti, ma poi si possono utilizzare anche per altro data la loro velocit√† (per minore spazio).\n4.4 RAID https://en.wikipedia.org/wiki/Standard_RAID_levels\nRedundant array of indipendend disks (originariamente inexpensive, per contrapporla a Single Large Expensive Disk ossia SLED, ma poi hanno scoperto che anche RAID costa, LMAO.\n4.4.1 Vantaggi generali Redundant Array of Inexpensive Disks.\nRidurre il gap di efficienza fra CPU e HD Utilizzo di pi√π dischi in contemporanea + lettura di dati Facilit√† di correttezza di dati e verifica errori 4.4.2 6 Tipologie di RAID Diminuire di 1 l\u0026rsquo;intera lista, perch√© RAID va da 0\nNon redundant data striping (C\u0026rsquo;√® solo una copia di dati nel disco) Velocit√†, no info retrieval\nRedundant, c\u0026rsquo;√® una copia esatta dei RAID e sono entrambi striped\nC\u0026rsquo;√® bisogno di una grande sincronizzazione in quanto i dati sono divisi fra i dischi a livello bit.\nPossono avere solamente una richiesta, a differenza di RAID 1 che pu√≤ gestirne tanti Unico raid mai utilizzato, per√≤ introduce Hamming per la corrrezione!\nUguale al terzo ma c\u0026rsquo;√® un bit di parit√† per controllo errori invece che codice hamming, spesso bit di parit√† √® bastato.\nSolo una richiesta https//en.wikipedia.org/wiki/Parity_bit¬†disk with each color representing the group of blocks in the respective¬†parity¬†block (a stripe)](Memoria%20f3746a630031414b935cca93dd06f1ad/Untitled%2010.png)\nA RAID¬†4 setup with dedicated¬†parity¬†disk with each color representing the group of blocks in the respective¬†parity¬†block (a stripe)\nRitornano gli stripe, ma stavolta un intero disco √® utilizzato per verificare che la scrittura √® stata corretta,\n√® brutto se vogliamo scriverci ","permalink":"https://flecart.github.io/notes/memoria/","summary":"\u003ch2 id=\"41-caratteristiche-della-memoria\"\u003e4.1 Caratteristiche della Memoria\u003c/h2\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Memoria/Untitled.png\" alt=\"image/universita/ex-notion/Memoria/Untitled\"\u003e\n\u003cp\u003eLa gerarchia della memoria, pi√π si va gi√π pi√π spazio si ha, pi√π √® lento il caricamento delle informazioni\u003c/p\u003e\n\u003ch3 id=\"411-catalogazione-della-memoria\"\u003e4.1.1 Catalogazione della memoria\u003c/h3\u003e\n\u003cp\u003eLe tipologie di memoria sono presenti a fianco.\u003c/p\u003e\n\u003cp\u003eIn generale pi√π la memoria √® veloce da riprendere, pi√π √® costosa da memorizzare (c\u0026rsquo;√® poco spazio)\u003c/p\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Memoria/Untitled 1.png\" alt=\"image/universita/ex-notion/Memoria/Untitled 1\"\u003e\n\u003ch3 id=\"412-byte-e-word\"\u003e4.1.2 Byte e Word\u003c/h3\u003e\n\u003cp\u003eIl libro a pagina 74 parte con la discussione del perch√© si √® preferito \u003cstrong\u003eevitare la BCD\u003c/strong\u003e (Binary coded decimal, in cui i numeri da 0 a 9 erano codificato da 4 bit), per questioni di efficienza.\u003c/p\u003e","title":"Memoria"},{"content":"Memoria virtuale Perch√© √® utile la MV? üü®- I programmi non usano tutta la memoria, ma pensano di averla tutta disponibile dal suo punto di vista. L\u0026rsquo;idea principale √® che molte zone di memoria sono inutili per lungo tempo, possono essere utilizzati per altro.\ncaricamento codice dinamico Per esempio anche a caricare il codice di un compilatore √® diviso in fasi, se andiamo a caricare tutto, stiamo utilizzando solo un pezzo piccolo, tanta inefficienza, se una pagina contiene una parte del compilatore potrei caricare in memoria solamente le parti eseguite sul momento, giusto per fare un esempio diciamo. Crescita dei segmenti stack, heap, ad esempio ci permette di far crescere come ci pare la stack, e anche caricare solamente le parti della stack che ci servono, e mantenere la memoria libera per altro. Gestione degli errori. che utilizzer√† i dati solamente della parte di gestione di memoria attuale diciamo. Paginazione a richiesta üü©‚Äî Questo √® un aspetto della cache delle pagine di cui abbiamo gi√† parlato in Livello OS.\nSlide paginazione a richiesta\nin pratica nella cache √® presente un bit, chiamato valid bit, che ci dice se la pagina correntemente caricata √® valida o meno.\nSe non √® presente una pagina valida, allora chiamiamo trap di page fault, e il pager si occupa di caricare la nuova pagina ed aggiornare la pagina vecchia.\nEsempio di demand paging\nNOTA: la memoria secondaria con questo metodo ha l‚Äôintero contenuto, in questo senso la memoria principale √® utilizzata come se fosse cache.\nEsempio completo con page fault\n*ALGORITMO GENERALE DI DEMAND PAGING\nSlide demand paging\nNOTA: la cosa importante √® il fatto che invalida subito la pagina scelta da sostituire. Non vorremmo che se un altro processo chieda quella pagina possa ancora scriverci o leggerci (e quindi problemi di concorrenza).\nMemoria di Swapüü© In realt√† quando un intero processo √® caricato in memoria secondaria, questa parte in memoria secondaria √® l‚Äôarea di swap.\nMa questo metodo qui √® come se fosse uno swap pigro. (se un processo √® vecchio, nel senso che non utilizza la pagina per tanto tempo, √® probabile che la sua memoria √® messa in memoria secondaria).\nil termine swap area per indicare l\u0026rsquo;area del disco utilizzata per ospitare le pagine in memoria secondaria\nAlgoritmi di rimpiazzamento AKA Paginazione.\nObiettivo del rimpiazzamento üü©‚Äî Quando la memoria centrale √® piena, come si gestisce il processo di rimpiazzamento? In che modo si decide quale sia la pagina da togliere? Su quali basi andare a valutare per fare questa decisione?\nUtilit√†, nel senso meno utilizzata Sar√† utilizzata fra pi√π tempo. Minimizzare il numero di page faults possibili. vorremmo evitare di togliere e rimpiazzare subito.\nNUMERO DI FRAME E PAGE FAULTS\nNon √® che il numero dei frame aumenta implica che il numero di faults sia minore? Ma stranamente non √® sempre cos√¨, gli algoritmi di rimpiazzamento potrebbero fare peggio se hai troppa memoria, per esempio Algoritmi FIFO üü©\nQuesto fenomeno √® proprio studiato, ed √® conosciuto nel nome di Anomalia di belady üü©\nStringa di riferimenti üü© √à la sequenza degl iindirizzi di memoria al quale un processo accede durante la sua esecuzione, (ci importa solamente il numero di pagina!) Questo ci d√† un criterio per valutare quanto buona √® una pagina in memoria\nSlide stringa di riferimenti\nAlgoritmi FIFO üü© Questo l\u0026rsquo;abbiamo studiato anche in Scheduler, oppure Data Plane per i routers.\nPraticamente la pagina che dovr√† uscire sar√† la pagina in memoria da piu`tempo. Ma non √® detto che la pagina caricata da pi√π tempo sia anche poco utilizzata! potrebbe essere ancora utilizzata!\nEsempio di paginazione fifo\nEsempio paginazione 2 fifo\nEsempio brutto, di maggiori faults con aumento memori\nAnomalia di belady üü© Slide anomalia di belady\nUn buon algoritmo di rimpiazzamento dovrebbe essere immune a questa anomalia! Perch√© non avrebbe senso che aggiungere memoria renda il sistema pi√π lento!\nIn questo paragrafo: Implementazione a stack parliamo di una condizione sufficiente affinch√© non si verifichi questa condizione.\nAlgoritmo MIN üü© Questo √® l\u0026rsquo;algoritmo ottimale, ma utilizza informazioni che non abbiamo gi√†, perch√© non sappiamo quando i processi accederanno a cosa. Quindi buon algoritmo in teoria (perch√© utilizza informazioni che non abbiamo ancora nel presente), nessun uso ora.\nPer√≤ si pu√≤ dimostrare che questo algo genera il minor numero di faults.\nSeleziona come pagina vittima una pagina che non sar√† pi√π acceduta o la pagina che verr√† acceduta nel futuro pi√π lontano\n√à un buon algoritmo per utilizzare come paragone di altri algoritmi reali, cio√® questi reali quanto bene fanno rispetto a questo algoritmo perfetto!\nSlide algoritmo MIN\nLeast Frequently usedüü® Slide LFU\nMa solitamente questo, come FIFO, non √® che venga utilizzata.\nVado a considerare il concetto di frequenza, definita in questo modo: contatore / tempo di permanenza in memoria.\nAlgoritmo di LRU Ne abbiamo parlato anche in architettura, qui: 9.2.4 Algoritmi di paginazione (2).\nseleziona come pagina vittima la pagina che √® stata usata meno recentemente nel passato\nIn pratica provo a stimare l‚Äôutilizzo della pagina in base a quanti accessi abbia fatto in passato.\nEsempio LRU\nImplementazione LRU Come facciamo a capire quanto spesso √® stato utilizzato una pagina? Non possiamo mica aggiungere il numero di accesso a tutte le risoluzioni MMU, deve essere implementato in hardware stesso, in MMU.\nSlide implementazione MMU\nAccessi in memoria in pi√π\nLa MMU dovrebbe tenersi i timestamps e dovrebbe gestire gli overflows\nO(n) per scandire la tabella di frame, e trovare la pagina\nQuindi √® molto lenta, ma almeno √® realizzabile.\nIMPLEMENTAZIONE A STACK\nOssia quando accediamo una pagina, la mettiamo sopra la stack. Ma √® brutto perch√© in hardware dovrei aggiornare 6 puntatori, che non dovrebbe essere cosa da niente, per questo non √® utilizzato.\nLa cosa carina per√≤ √® che avrei in cima le cose utilizzate in basso quelle meno utilizzate!\nImplementazione a stack Slide definizione di algoritmi a stack\nSi noti che la condizione √® molto simile a una sufficiente per risolvere la condizione di belady, ci sta dicendo che in pratica: l‚Äôinsieme delle pagine mantenute in memoria √® contanuto allo stesso algoritmo con pi√π pagine in memoria!\n√à anche una condizione sufficiente per dire: avere fage faults in meno, non pi√π, perch√© contiene sempre le stesse pagine con una versione a pi√π.\nPer dimostrare che FIFO non √® a stack, basta un esempio.\nACCENNO DIMOSTRAZIONE LRU √à STACK\nSi utilizza una dimostrazione costruttiva per induzione (altra tecnica √® per assurdo). Questo lo facciamo sul tempo.\nPasso base: al tempo 0 la stack √® vuota, non ci importa quale numero di stack, la memoria resta la stessa. Supponiamo al tempo t-1 che la condizione di stack sia verificata. Ora abbiamo due casi: non c‚Äô√® abbstanza spazio, o c‚Äô√® ancora spazio: Se c‚Äô√® abbastanza spazio, allora non ci cambia per un m numero di frame maggiore Se non c‚Äô√® abbastanza spazio, quello minore deve cambiare, dovr√† scegliere uno a caso, scegliendone uno a caso allora l‚Äôinsieme delle pagine √® ancora incluso. Al passo successivo ancora, l‚Äôelemento che esce dovr√† essere lo stesso, o comunque offsettato non di tanto credo, in pratica quello grosso elimini cose solamente eliminate gi√† da quello piccolo!. E questa cosa con LRU l‚Äôabbiamo. Non √® che ho formalizzato molto bene questa parte. Additional reference bit üü©- Andiamo ora a parlare di approssimazione di LRU perch√© col discorso a stack non √® proprio fattibile con l‚Äôhardware attuale.\nQuando accedo a una pagina, il bit viene messo a 1, inizialmente sono tutte 0, meglio descritta nella slide:\nSlide descrizione reference bit\nbasta fare shift e assegnamento! Quindi easy! Andiamo a prendere la pagina con valore minore poi.\nVARIANTE: SECOND CHANGE ALGO\nSlide second change (storia = 1)\nVengono gestiti come una lista circolare, per questo motivo √® anche detto algoritmo dell‚Äôorologio.\nIn pratica scandisco la lista con questo algo:\nBit a 1? Allora lo metto a 0 e vado avanti Bit a 0? Allora tolgo questa! E sostituisco. Esempio di second change algo\nNon si capisce sto esempio lol\nAllocazione della memoria virtuale Tipologie di allocamento (3) üü®‚Äî Slide allocazione\nAlgo di allocazione: risponde alla domanda su come allocare i frame per un certo processo. Allocazione globale: permetto di allocare l\u0026rsquo;intero programma (male ‚Üí thrashing) Allocazione locale: il processo √® a conoscenza dei propri frame, ma non √® molto flessibile, di solito fanno meglio quelli globali, Praticamente fin‚Äôora abbiamo parlato di metodi per sostituire delle pagine in caso di page faults, ma non abbiamo mai definito in che modo decidiamo quanti frames allocare a un processo, nel momento del bisogno. Allocazione globale e locale sono dei modi per fare questa decisione.\nLocale ‚Üí implica che posso sostituire solamente i frames del mio processo, in queto senso sono poco flessibile, se qualcun‚Äôaltro ha pi√π roba che posso sottrarre converrebbe fare quello. Globale ‚Üí implica che posso sostituire i processi di chissivoglia. Normalmente si utilizzano anche delle euristiche per sapere quante pagine allocare: per esempio se ho troppi page faults, probabilmente il processo ha bisogno di pi√π memoria, se ne ho troppi pochi probabilmente il processo ne ha troppa, e si pu√≤ allocare ad altri.\nThrashing üü© un processo (o un sistema) si dice che √® in trashing quando spende pi√π tempo per la paginazione che per l\u0026rsquo;esecuzione\nQuesto √® quindi un effetto molto brutto! Va a finire che l\u0026rsquo;intero sistema si impalli. rubano le pagine a vicenda, l\u0026rsquo;effetto pi√π classico √® questo: non riescono a tenere in memoria i frame utili a breve termine (perch√® altri processi chiedono frame liberi) e quindi generano page fault ogni pochi passi di avanzamento) In pratica quasi ogni operazione √® un page fault.\nPer evitare questo, massimo 2x memoria virtuale, altrimenti potrei andare in thrashing.\nEsempio di effetto di thrashing\nL\u0026rsquo;efficienza cade di interi ordini di grandezza!\nWorking set üü©‚Äî si definisce working set di finestra Œî l\u0026rsquo;insieme delle pagine accedute nei pi√π recenti Œî riferimenti\nQuesto √® utile per stimare se il sistema √® in thrashing. Questo √® utile per avere un concetto di localit√† delle pagine, vogliamo avere una stima delle pagine attualmente utili, e utilizziamo questo per andare a decidere se una pagina √® ancora utile o meno.\nSlide valutazione working set per thrashing\nSe la somma di tutti i pages di cui ho bisogno nel breve √® maggiore di pi√π pagine presenti in RAM, allora sicuramente quando questa si riattiva crea page faults! Ecco il criterio per i page faults.\nScelta del delta\nSOLUZIONE PROPOSTA\nBasta sospendere alcuni processi, in modo che alcuni terminino senza andare in troppi page faults, in modo che la somma di tutti working set stiano ancora dentro.\nSlide della soluzione\n","permalink":"https://flecart.github.io/notes/memoria-virtuale/","summary":"\u003ch2 id=\"memoria-virtuale\"\u003eMemoria virtuale\u003c/h2\u003e\n\u003ch3 id=\"perch√©-√®-utile-la-mv--\"\u003ePerch√© √® utile la MV? üü®-\u003c/h3\u003e\n\u003cp\u003eI programmi non usano tutta la memoria, ma pensano di averla tutta disponibile dal suo punto di vista. L\u0026rsquo;idea principale √® che molte zone di memoria sono inutili per lungo tempo, possono essere utilizzati per altro.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ecaricamento codice dinamico\u003c/strong\u003e Per esempio anche a caricare il codice di un compilatore √® diviso in fasi, se andiamo a caricare tutto, stiamo utilizzando solo un pezzo piccolo, tanta inefficienza, se una pagina contiene una parte del compilatore potrei caricare in memoria solamente le parti eseguite sul momento, giusto per fare un esempio diciamo.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCrescita dei segmenti stack, heap\u003c/strong\u003e, ad esempio ci permette di far crescere come ci pare la stack, e anche caricare solamente le parti della stack che ci servono, e mantenere la memoria libera per altro.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGestione degli errori.\u003c/strong\u003e che utilizzer√† i dati solamente della parte di gestione di memoria attuale diciamo.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"paginazione-a-richiesta-\"\u003ePaginazione a richiesta üü©‚Äî\u003c/h3\u003e\n\u003cp\u003eQuesto √® un aspetto della cache delle pagine di cui abbiamo gi√† parlato in \u003ca href=\"/notes/livello-os/\"\u003eLivello OS\u003c/a\u003e.\u003c/p\u003e","title":"Memoria virtuale"},{"content":"First of all, we need to have a strong understanding of how a program allocates memory during its execution. See Memoria, Memoria virtuale and other notes about Nomi e Scope, Gestione della memoria. The thing you have to remember is that\nEvery new function call allocates a new block, with his local variables. How the calling parameters are stored in the stack How the heap is allocated (common heap algos are in Gestione della memoria) How the stack grows (and how it can overflow it, and overwriting important data). Common attack vectors We use C, as it is the easiest way to show how this could be attacked.\nThe threat model Attacker‚Äôs goal:\nInject malicious code into a program and execute it (Return Object Programming) Gain all privileges and capabilities of the target program (e.g. setuid) System‚Äôs goal:\nprevent code injection Integrity ‚Äì program should execute faithfully, as programmer intended Crashes should be handled gracefully Attacker‚Äôs capability:\nsubmit arbitrary input to the program Environment variables Command line parameters Contents of files Network data The thing is that it is highly variable. Stack smash example Some functions don't have boundary controls, for example `strcpy` or `gets` and are vulnerable to stack overflows. Common defenses Compiler Hardening These are just hardening attempts, which means it makes the attack more difficult, but still not impossible to execute.\nStack canaries Just a random string that is checked before returning. This allows you to check if there has been a stack overflow. Usually this can be bypassed if you can leak the value of the canary before-hand.\nNon executable stacks So you can\u0026rsquo;t execute the shell-code you have just wrote in the stack! :).\nOs hardening Some hardening at the OS level to prevent common exploits.\nAddress-Space Layout Randomization (ASLR) The location of the data and code are always randomized when the program is loaded. This makes it more difficult to have exploits jumping around the code! Example ROP attacks are more difficult. (ROP = Return-oriented-programming, method that allows you to control where the program jumps by overwriting return addresses.)\nSome rules Use memory safe languages Example: C is not memory safe, see Teoria dei Tipi. using safe languages allow you to have provable guarantees that the type is always respected and stuff like this!\nData vs Code You need to differentiate the data with the code. They are two very different things! Many different exploits use data to be interpreted as code, and thus have this bug.\nPatch! Patch as soon as you can. most of the vulnerabilities are discovered but then left to be, without been patched for a long time. (e.g. exploit kits for these vulnerabilities) Automatic patches are the best.\n","permalink":"https://flecart.github.io/notes/memory-corruption/","summary":"\u003cp\u003eFirst of all, we need to have a strong understanding of how a program allocates memory during its execution. See \u003ca href=\"/notes/memoria/\"\u003eMemoria\u003c/a\u003e, \u003ca href=\"/notes/memoria-virtuale/\"\u003eMemoria virtuale\u003c/a\u003e and other notes about \u003ca href=\"/notes/nomi-e-scope/\"\u003eNomi e Scope\u003c/a\u003e, \u003ca href=\"/notes/gestione-della-memoria/\"\u003eGestione della memoria\u003c/a\u003e.\nThe thing you have to remember is that\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEvery new function call allocates a new block, with his local variables.\u003c/li\u003e\n\u003cli\u003eHow the calling parameters are stored in the stack\u003c/li\u003e\n\u003cli\u003eHow the heap is allocated (common heap algos are in \u003ca href=\"/notes/gestione-della-memoria/\"\u003eGestione della memoria\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eHow the stack grows (and how it can overflow it, and overwriting important data).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"common-attack-vectors\"\u003eCommon attack vectors\u003c/h2\u003e\n\u003cp\u003eWe use C, as it is the easiest way to show how this could be attacked.\u003c/p\u003e","title":"Memory Corruption"},{"content":"Merkle Trees: A Fundamental Structure in Cryptography\nMerkle trees, introduced by Ralph Merkle in 1979, are a pivotal data structure in cryptographic systems. These binary hash trees enable efficient and secure verification of data integrity within distributed systems. Their design capitalizes on hash functions to reduce computational overhead, making them indispensable in blockchain and peer-to-peer networks.\nWhat are Merkle Trees? Structure and Construction A Merkle tree is a rooted binary tree where:\nLeaf nodes store the hash of individual data blocks:$h_0 = H(d_0), h_1 = H(d_1), \\dots, h_n = H(d_n)$, where $H$ is a cryptographic hash function, and$d_i$represents a data block. Internal nodes are computed iteratively by concatenating and hashing child nodes: $h_{\\text{parent}} = H(h_{\\text{left child}} || h_{\\text{right child}})$. The root node, or Merkle root, encapsulates the integrity of the entire dataset. For$n$leaf nodes, the tree contains$2n - 1$nodes in total. Efficient construction and traversal are enabled by this logarithmic height.\nProof of Inclusion Merkle trees facilitate compact proofs of inclusion for a data block$d_i$without requiring access to the full dataset:\nA Merkle proof includes the hashes of sibling nodes along the path from$d_i$to the root. The verifier iteratively reconstructs the root from$d_i$and the provided proof, comparing it with the stored root. The computational cost of verification is $O(\\log n)$ , where $n$ is the number of data blocks.\nSecurity Properties Merkle trees derive their robustness from cryptographic hash functions, see Tabelle di hash\nCollision and Preimage resistance Collision resistance ensures that altering any$d_i$requires recalculating the entire Merkle root, making tampering detectable. Preimage resistance prevents reversing the hash, ensuring data confidentiality. Probability of corruption If the dataset contains $n$ blocks, the probability of undetected corruption is negligible given a strong hash function $H$. For a hash function with $b$ -bit output, the collision probability is approximately $\\frac{1}{2^b}$, emphasizing the importance of selecting secure hash algorithms like SHA-256 or SHA-3.\nApplications Merkle trees underpin many systems, including:\nBlockchain Networks: Bitcoin and Ethereum employ Merkle trees to validate transactions efficiently within blocks. Light clients rely on Merkle proofs to confirm transactions without downloading the entire blockchain. File Systems: Distributed file systems like IPFS use Merkle trees for data versioning and deduplication. Certificate Transparency: Logs of public key certificates are stored and audited using Merkle trees. They have also been used for Cloud Storage#Key-value stores in the dynamo replication algorithm to check for inconsistencies in the replicas. ","permalink":"https://flecart.github.io/notes/merkle-trees/","summary":"\u003cp\u003e\u003cstrong\u003eMerkle Trees: A Fundamental Structure in Cryptography\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eMerkle trees, introduced by Ralph Merkle in 1979, are a pivotal data structure in cryptographic systems. These binary hash trees enable efficient and secure verification of data integrity within distributed systems. Their design capitalizes on hash functions to reduce computational overhead, making them indispensable in blockchain and peer-to-peer networks.\u003c/p\u003e\n\u003ch3 id=\"what-are-merkle-trees\"\u003eWhat are Merkle Trees?\u003c/h3\u003e\n\u003ch4 id=\"structure-and-construction\"\u003eStructure and Construction\u003c/h4\u003e\n\u003cp\u003eA Merkle tree is a rooted binary tree where:\u003c/p\u003e","title":"Merkle Trees"},{"content":"ora abbiamo alcune primitive per passarci i messaggi, vogliamo creare metodo in modo che i processi si possano sincronizzare mandando messaggi.\nla memoria √® sempre privata.\nPrimitive Send e receive üü© Send\nSpedizione del messaggio input deve avere un identificato al processo su cui spedire. Se si vuole espandere si possono avere multicast e broadcasting ma non li studieremo in questo corso.\nReceive\nRicevi messaggi\nTassonomia dei message passing (!)üü© Slide\nSincrono\nIn questo caso entrambi send e receive sono bloccanti, quindi non possono andare avanti finch√© non √® mandato e finch√© non √® ricevuto!\nAsincrono\nSimile al precedente, solo che il send non aspetta che il ricevente prenda il messaggio!\nNOTA: non si aspetta che il receiver riceva il messaggio!\nCompletamente asincrono\nnessuno di due aspetta, il receive se nessuno ha inviato non riceve niente!\nThoth proponeva 3, reply receive send, principalmente solo la reply √® bloccante.\npi√π o meno tutti gli autori avevano una sintassi diversa per il message passing\nEquivalenza fra sincrono asincrono Si pu√≤ vedere che questi due metodi si possono rivelare equivalenti\nSincrono dato quello asincrono üü© Slide\nPer bloccare il asendodevo fare un areceive per un ack, cos√¨ lo blocco\nNOTA: ed √® esattamente questo, un ack aggiuntivo che hai fatto all‚Äôesame che ti ha fatto perdere tipo 2 punti, stai attento!\nAsincrono dato quello sincrono üü©- Slide\nSi vede che il sincrono non √® espressivo tanto l‚Äôasincrono perch√© abbiamo bisogno di far uso di un altro processo server.\nProblemi classici üü® Filosofi a cena Slide\nBasta ricordarsi di fare anche il filosofo mancino e poi siamo apposto! Sarebbe poi la stessa soluzione proposta in Semafori\nProducer consumer Slide\n","permalink":"https://flecart.github.io/notes/message-passing/","summary":"\u003cp\u003eora abbiamo alcune primitive per passarci i messaggi, vogliamo creare metodo in modo che i processi si possano sincronizzare mandando messaggi.\u003c/p\u003e\n\u003cp\u003ela memoria \u003cstrong\u003e√® sempre privata\u003c/strong\u003e.\u003c/p\u003e\n\u003ch2 id=\"primitive\"\u003ePrimitive\u003c/h2\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Message Passing/Untitled.png\" alt=\"image/universita/ex-notion/Message Passing/Untitled\"\u003e\n\u003ch3 id=\"send-e-receive-\"\u003eSend e receive üü©\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eSend\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSpedizione del messaggio\u003c/li\u003e\n\u003cli\u003einput deve avere un \u003cstrong\u003eidentificato al processo su cui spedire.\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSe si vuole espandere si possono avere \u003cstrong\u003emulticast e broadcasting\u003c/strong\u003e ma non li studieremo in questo corso.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eReceive\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eRicevi messaggi\u003c/p\u003e\n\u003ch2 id=\"tassonomia-dei-message-passing-\"\u003eTassonomia dei message passing (!)üü©\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide\u003c/p\u003e","title":"Message Passing"},{"content":"Metadati web https://csunibo.github.io/tecnologie-web/lucidi/teoria/23-metadati.pdf https://csunibo.github.io/tecnologie-web/lucidi/teoria/24-a-web-semantico-lod-rdf-json-ld.pdf\ninconfrontabilit√† del sapere Stessa informazione in forme diverse Stessa parola per cose diversa. Serializzazione La semantica √® relegata alle applicazioni che devono decidere in che modo interpretarli, oppure esseri umani.\nPICS Platform for Internet Content Selection vuole cercare di tenere sotto controllo i materiali del film. √à un sistema di rating. ‚Üí tanti criteri di classificazione a seconda dei criteri ideologici su cui voglio andare a basarmi.\nClassificare e categorizzare, non`e una cosa centralizzata da parte di un governo. Fonte terza, non √® n√© l\u0026rsquo;usufruitore ne il creatore ‚Üí metadati = dati sui dati. Metadati vantaggi e svantaggi\nTesauri e tassonomie Si parla di gerarchizzazione e di relazione fra parole dello stesso livello\nTassonomia linneo Esempio di tassonomia La cosa che generalizza Esempi di relazioni has_a is_a instance of Classificazione a faccette possibilit√† di descrivere un oggetto complesso attraverso un insieme di affermazioni appartenenti ad uno schema fisso di propriet√†, ciascuna delle quali in grado di usare valori da un apposito tesauro.\nOntologie Vocabolario controllato Organizzato in thesaurus Una ontologia √® un sistema di classi, descritta da propriet√† che hanno valori puri o riferimenti ad istanze di altre classi (credo che questa cosa sia molto simile anche in database o simili).\nCritica alle ontologie\nComplessivamente, sono un approccio costoso, ingessato, non democratico, centralizzato e riduzionistico.\nFolksonomie Semantic web Resource description framework - RDF Spieghiamo meglio in Graph Databases Sono delle triple soggetto predicato e oggetto, e posso creare degli alberi che sembrano delle tassonomie a riguardo.\nUna cosa interessante √® che tutto √® identificato da URI, nomi, predicati e oggetti, a volte ci sono degli elementi vuoti chiamati blank nodes.\nbisogna distinguere questo formato di triple con il formato di serializzazione che √® la forma in cui sono rappresentati sottostante.\nProblema delle relazioni n-arie Reificazione üü• La differenza principale con la modellizzazione a relazione n-aria √® che il blank era il soggetto e tutti erano oggetti di questo, mentre ora ogni cosa pu√≤ essere soggetto oppure oggetto. In particolare rdf:statement sub, pred, obj, ci sono sempre queste predicati per la reificazione. Ma ha un problema per i databases perch√© non vengono trovati le relazioni soggetto - predicato - oggetto classici.\nNamed graph Slide named graph\nossia ho sempre delle triple, ma queste sono messe a livello differente.\nSerializzazioni Serializzazione significa dare una sintassi per andare a descrivere le informazioni di rdf in modo che sia possibile metterli in database.\nRDF/XML Turtle JSON-LD Generazione di conoscenza utilizzare il database RDF per andare a generare nuove informazioni Andare a verificare la coerenza delle informazioni che abbiamo gi√† RDF schema √à l\u0026rsquo;insieme dei concetti possibili per un certo RDF.\nWeb Ontology language (OWL) TODO\nSPARQL TODO\n","permalink":"https://flecart.github.io/notes/metadati-web-e-web-semantico/","summary":"\u003ch1 id=\"metadati-web\"\u003eMetadati web\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://csunibo.github.io/tecnologie-web/lucidi/teoria/23-metadati.pdf\"\u003ehttps://csunibo.github.io/tecnologie-web/lucidi/teoria/23-metadati.pdf\u003c/a\u003e\n\u003ca href=\"https://csunibo.github.io/tecnologie-web/lucidi/teoria/24-a-web-semantico-lod-rdf-json-ld.pdf\"\u003ehttps://csunibo.github.io/tecnologie-web/lucidi/teoria/24-a-web-semantico-lod-rdf-json-ld.pdf\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"inconfrontabilit√†-del-sapere\"\u003einconfrontabilit√† del sapere\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eStessa informazione in forme diverse\u003c/li\u003e\n\u003cli\u003eStessa parola per cose diversa.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"serializzazione\"\u003eSerializzazione\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Metadati web e web semantico/Untitled.png\" alt=\"image/universita/ex-notion/Metadati web e web semantico/Untitled\"\u003e\n\u003cp\u003eLa semantica √® relegata alle \u003cstrong\u003eapplicazioni\u003c/strong\u003e che devono decidere in che modo interpretarli, oppure esseri umani.\u003c/p\u003e\n\u003ch3 id=\"pics\"\u003ePICS\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003ePlatform for Internet Content Selection\u003c/strong\u003e vuole cercare di tenere sotto controllo i materiali del film. √à un sistema di rating. ‚Üí \u003cstrong\u003etanti criteri di classificazione\u003c/strong\u003e a seconda dei criteri ideologici su cui voglio andare a basarmi.\u003c/p\u003e","title":"Metadati web e web semantico"},{"content":"Introduzione ai metodi di discesa. Generali sui metodi di discesa Vogliamo creare algoritmi che riescano a trovare i punti di minimo delle funzioni non vincolate.\nIn generale si trova un punto stazionario (condizioni necessarie) ma non √® garantito lo stato ottimo.\nSolitamente sono divisi in first order methods in cui viene considerata solamente la derivata prima della funzione. E cose di metodi superiori.\nCondizioni di arresto classiche (2) üü©- Slide\nDifferenza fra due iterati √® minore a una tolleranza, in modo simile a quanto fatto in Equazioni non lineari sulla tolleranza per il metodo delle approssimazioni I criteri di arresto sono i sempre classici\nNumero di iterazioni superate Tolleranza sull‚Äôobiettivo ossia gradiente $\\simeq$ 0 per il punto di stazionariet√†. Idea principale dei metodi di discesa üü© Slide\nTrovare una direzione di discesa Aggiornare x in modo da andare in quella direzione di un passo fissato. direzione di ricerca e lunghezza del passo sono due nuovi termini di interesse per questa roba Ottimizzazione non vincolata (non studiare) In pratica questa parte √® un ripasso molto veloce di 2 mesi di analisi 2‚Ä¶ E poi ovviamente fatti molto male!\nGuarda Massimi minimi multi-variabile. In pratica ottimizzazione √® trovare il massimo o il minimo di una funzione‚Ä¶\nDiscesa Condizione per direzione di discesaüü©- Slide\nSi pu√≤ osservare che io stia proprio scendendo, in questo senso vado a cercare qualcosa che sia uguale a 0.\nInterpretazione geometrica della condizione di discesa\nSe forma angolo ottuso con il gradiente √® OK!\nE guardare le curve di livello √® una cosa molto buona.\nAlgoritmo generale di GDüü© Slide\nSi pu√≤ notare che la scelta del passo √® la parte critica di questo algoritmo. Scegliere un alpha fisso non garantisce la convergenza, devono essere soddisfatte certe propriet√†.\nRicerca dell‚Äôalpha Scelta della alpha (linea esatta)üü©- Definizione di funzione dipendente da alpha\nVado a scegliere l‚Äôalpha in modo tale che assuma il valore pi√π piccolo possibile, significa minimizzare questa funzione di alpha.\nSolitamente si utilizza quando f √® in forma quadratica, per resto spesso non si utilizza (perch√© la f si calcola in modo molto veloce, di solito √® molto lento. dimostrato converge! punto minimo o massimo boh.\nlinea inesatta üü®+ Slide\nQuindi inesatta perch√© devo trovare l\u0026rsquo;insieme di alpha buoni, non quell preciso\nCondizioni di Wolfe üü®- Due funzioni costituiscono le condizioni di Wolfe:\nCondizione di Armijo: $f(x_{k} + \\alpha p_{k}) \\leq f(x_{k}) + c_{1}\\alpha \\nabla f(x_{k})^{T} p_{k}$ assicura una decrescita sufficiente di $f$ nella direzione trovata $p$. Questa condizione √® anche chiamata condizione della decrescita sufficiente. Condizione della curvatura: $\\nabla f(x_{k} + \\alpha_{k} p_{k})^{T} p_{k} \\geq c_{2} \\nabla f(x_{k})^{T} p_{k}$ impedisce che $\\alpha_{k}$ diventi troppo piccolo. Slide Armijo e backtrackingüü® Intro a backtracking\nbacktracking\nL‚Äôalgoritmo\nNOTA: bisgona anche mettere una condizione di maxit, se si esce per quella allora √® perch√© non si pu√≤ trovare! (molto probabilmente)\nCondizioni di ottimalit√† Definizione üü© Quando sono in un minimo locale o globale per la nostra funzione.\nAndiamo a definire una condizione di ottimalit√† di primo secondo oordine perch√© andiamo a guardare le derivata\nCondizione necessaria e sufficiente al primo e secondo ordine üü© Primo ordine\nQuesto non √® altro che il teorema di fermat del secondo ordine che puoi trovare qui 11.1.2 Condizione di stazionariet√† (fermat) !!!\nSlide\nNon esiste una condizione sufficiente al primo ordine\nSecondo ordine\nQuesto √® il modo con cui trovavamo i punti di minimo, √® anche una condizione sufficiente se √® definita positiva\nOttimalit√† per funzioni convesse ! üü© Funzioni quadratiche Questo tipo di funzioni ci piace molto perch√© sono convesse e le funzioni convesse sono facili da analizzare per sta robba.\nQuadratiche convesse üü• Slide\nCon $Q$ matrice simmetrica\nCon $q$ convessa se la matrice √® semidefinita positiva, e convessa stretta se √® definita positiva.\nQuesta funzione ci pu√≤ essere utile per la risoluzione dei Minimi quadrati. Quando mi calcolavo la norma quadrata per quel problema, avevo una funzione quadratica convessa (quasi, credo che il termine noto non fa male)!\nSoluzioni eq. normali Slide\nCon la roba di sopra dimostro anche che una soluzione ottima (ricorda che √® ottima anche una soluzione locale) esiste sempre.\nMetodo di newton puro L‚Äôunica cosa che cambia nello step di newton √® che la direzione di discesa √® calcolata in modo differente, in particolare possiamo vedere che lo step sia:\n$p_k = H(x_k) ^{-1} \\nabla f(x_k)$, le ragioni sono sconosciute (a me), e non √® conveniente in termini di tempo provare a capire questo. lo step √® sempre di 1.\nLa velocit√† di convergenza √® quadratica come nel caso descritto per newton in Equazioni non lineari. L\u0026rsquo;hessiana solitamente contiene informazioni sulla curvatura che permette, soprattutto nei casi in cui la nostra funzione √® quadratica, di convergere pi√π velocemente (invece di oscillare tanto, probabilmente va diretto nel minimo).\nRipasso (roba di analisi) Derivata parziale Guardare Calcolo differenziale. Ma √® una roba troppo base sta roba üòë\nHessiana Questa matrice ci da informazioni sulle derivate seconde\nMatrice simmetrica derivata $ij$, prima derivo su $i$, poi su $j$. Ricordarsi il teorema di Schwarz, che √® sufficiente per dimostrare che la matrice √® simmetrica\nJacobiana Questa ci da informazioni sulle derivate prime per tutti i modi possibili!\n$f: \\mathbb{R}^n \\to \\mathbb{R}^m$, $J(f) : \\mathbb{R}^n \\to \\mathbb{R}^{m\\times n}$\nIn particolare sulle righe ho tutte le derivate parziali possibili Sulle colonne ho la derivata fatta su tutte le funzioni possibili Analogo minimimo massimo Se ho il massimo e voglio il minimo, basta costruirsi la funzione swappata\n$$ \\arg \\max_{x} f(x) = \\arg \\min_{x} - f(x) $$Teorema sulle funzioni differenziabili Calcolo differenziale Spiega bene questo teorema, con\nSe le derivate parziali esistono e sono continue, allora la funzione si dice differenziabile con continuit√† $C$.\nPunti di minimo locali e globali Globale\nQuando √® minimo per tutto il dominio.\nLocale\nSe √® un punto di minimo globale con dominio ridotto ad un intorno (basta che esista un interno).\nFunzioni convesse Questa parte √® trattata in analisi in Convessit√† (cenni)\nSlides\n!\nSlide\n!\n","permalink":"https://flecart.github.io/notes/metodi-di-discesa/","summary":"\u003ch2 id=\"introduzione-ai-metodi-di-discesa\"\u003eIntroduzione ai metodi di discesa.\u003c/h2\u003e\n\u003ch3 id=\"generali-sui-metodi-di-discesa\"\u003eGenerali sui metodi di discesa\u003c/h3\u003e\n\u003cp\u003eVogliamo creare algoritmi che riescano a trovare i punti di minimo delle funzioni non vincolate.\u003c/p\u003e\n\u003cp\u003eIn generale \u003cstrong\u003esi trova un punto stazionario (condizioni necessarie)\u003c/strong\u003e ma non √® garantito lo stato ottimo.\u003c/p\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Metodi di Discesa/Untitled.png\" alt=\"image/universita/ex-notion/Metodi di Discesa/Untitled\"\u003e\n\u003cp\u003eSolitamente sono divisi in \u003cstrong\u003efirst order methods\u003c/strong\u003e in cui viene considerata solamente la derivata prima della funzione. E cose di metodi superiori.\u003c/p\u003e\n\u003ch3 id=\"condizioni-di-arresto-classiche-2--\"\u003eCondizioni di arresto classiche (2) üü©-\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide\u003c/p\u003e","title":"Metodi di Discesa"},{"content":"There is a close relationship between topologies and metric spaces. We will see that every metric space directly induces a topology based on its metric. (from a CS point of view, this means topologies are more general than metric spaces).\nDefinition of Metric Space üü© We say that $(\\mathcal{X}, d)$ is a metric space if $\\mathcal{X}$ is a set and $d$ a function $\\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{R}$ such that:\nDistance from it self is zero $d(a, b) = 0 \\iff a = b$ Symmetric function: $d(a, b) = d(b, a), \\forall a, b \\in \\mathcal{X}$ Triangle inequality is satisfied: $\\forall a, b, c \\in \\mathcal{X}: d(a, b) + d(b, c) \\geq d(a, c)$ Induced topology üü© If we define the sets $B(c, r) = \\left\\{ p \\in \\mathcal{X} \\mid d(p, c) \u003c r \\right\\}$ to be open, this induces a topology $(\\mathcal{X}, \\mathbb{B})$ where $\\mathbb{B} := \\left\\{ B(c, r) \\mid c \\in \\mathcal{X}, r \\in\\mathbb{R} \\right\\}$. This should be easy to verify, but it is mostly uninteresting and quite intuitive (i\u0026rsquo;m not reasoning like a mathematician now).\nConnectedness of $\\left[ 0, 1 \\right]$ üü® We define the subspace topology of $\\mathbb{R}$ on it\u0026rsquo;s subset $\\left[ 0, 1 \\right]$ we can prove that this is connected. This is uses the intermediate value theorem see Limiti#Weierstrass e Valore intermedio, the concept is very similar.\n$$ f(x) = \\begin{cases} 0 \\text{ if } x \\in A \\\\ 1 \\text{ if } x \\in B \\\\ \\end{cases} $$ We observe that this function is defined for every point in the domain, so it is well defined, and it\u0026rsquo;s continuous because we have that every set of the domain has a pre-image either $A, B, A \\cup B, \\varnothing$, that are all continuous. But if we have these assumptions we have that for all inputs either $A = \\varnothing$ or $B = \\varnothing$ because if it has some values $0$ or $1$ then by the intermediate value theorem it should take all the values. This contradicts the hypothesis the set is disconnected.\n","permalink":"https://flecart.github.io/notes/metric-spaces/","summary":"\u003cp\u003eThere is a close relationship between topologies and metric spaces. We will see that every metric space directly induces a topology based on its metric. (from a CS point of view, this means topologies are more general than metric spaces).\u003c/p\u003e\n\u003ch3 id=\"definition-of-metric-space\"\u003eDefinition of Metric Space\u003c/h3\u003e\n\u003cp\u003eüü©\nWe say that  $(\\mathcal{X}, d)$ is a metric space if $\\mathcal{X}$ is a set and $d$ a function $\\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{R}$ such that:\u003c/p\u003e","title":"Metric Spaces"},{"content":"Note matematiche introduttive Vettori ortonormali üü© Questa parte √® fatto molto meglio in Inner product spaces.\nDue vettori si dicono ortonormali se $vv^T = ||v|| = 1$ e sono ortogonali, ossia $v_i v^T_j = 0$ con i e j diversi fra di loro\nMatrici ortogonale (4) üü©- Matrici si dicono ortonomali se le sue colonne sono vettori sono ortonormali\nMatrici ortonormali sono isometrie, cio√® mantengono le distanze. Queste matrici sono tutte non singolari e quadrate per definizione La sua inversa √® ortogonale La sua inversa √® uguale alla trasposta slide Propriet√† matrice ortonormale\nMinimi quadrati lineari Introduzione al problema Sappiamo che non esiste una soluzione esatta per sistemi di equazione lineare che pi√π equazioni che soluzioni. Si pu√≤ concludere che la soluzione a questo problema (in slide) esiste sempre ed √® unica se $k = n$, se √® minore ci sono infinite soluzioni.\nSlide introduzione\nOssia mi interessa solamente l‚Äôascissa del minimo, ossia\n$\\text{ argmin }\\lVert Ax - b \\rVert$, cercando la x.\nSoluzione con equazione normale üü® Questo si pu√≤ fare solamente se $k = n$\nTeorema, soddisfacimento delle equazioni normali √® sufficiente per trovare una soluzione\nIn questo caso esiste una soluzione unica.\nSoluzione equazione normale\nnota ci sono errori sia sulla trasposta che sul gradiente in immagine\nIn breve\nFare il gradiente della funzione ed eguagliarlo a 0, perch√© solo se ho 0 ho il punto di minimo di questa funzione convessa della norma\nSingular Value decomposition Moved to Singular Value Decomposition.\n","permalink":"https://flecart.github.io/notes/minimi-quadrati/","summary":"\u003ch2 id=\"note-matematiche-introduttive\"\u003eNote matematiche introduttive\u003c/h2\u003e\n\u003ch3 id=\"vettori-ortonormali-\"\u003eVettori ortonormali üü©\u003c/h3\u003e\n\u003cp\u003eQuesta parte √® fatto molto meglio in \u003ca href=\"/notes/inner-product-spaces/\"\u003eInner product spaces\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eDue vettori si dicono ortonormali se $vv^T = ||v|| = 1$ e sono ortogonali, ossia $v_i v^T_j = 0$ con i e j diversi fra di loro\u003c/p\u003e\n\u003ch3 id=\"matrici-ortogonale-4--\"\u003eMatrici ortogonale (4) üü©-\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eMatrici si dicono ortonomali se le sue colonne sono vettori sono ortonormali\u003c/p\u003e\u003c/blockquote\u003e\n\u003col\u003e\n\u003cli\u003eMatrici ortonormali sono \u003cstrong\u003eisometrie\u003c/strong\u003e, cio√® mantengono le distanze.\u003c/li\u003e\n\u003cli\u003eQueste matrici sono tutte non singolari e quadrate per definizione\u003c/li\u003e\n\u003cli\u003eLa sua inversa √® ortogonale\u003c/li\u003e\n\u003cli\u003eLa sua inversa √® uguale alla trasposta\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eslide Propriet√† matrice ortonormale\u003c/p\u003e","title":"Minimi quadrati"},{"content":" The human ability of making analogies proceeds in such a way as to keep complexity minimal.\nPerch√© facciamo questo? Perch√© √® la cosa pi√π semplice da fare! Anche su Vapnik\u0026rsquo;s dimensions √® simile questa idea!\nOccam razor, Epicuro, con Solomonoff che ha risolto problema dell\u0026rsquo;induzione che Hume pensava di fare con abitudini. Attualmente IQ tests provano a misurare la capacit√† di estendere questo.\nAnalogia Studiamo l\u0026rsquo;analogia come oggetto matematico perch√© sembra essere una capacit√† molto difficile da generalizzare e utilizzare nelle macchine.\nDefinizione di analogia Scrivo $A:B :: C:D$ per dire che esiste una relazione $\\mathcal{R}$ tale per cui valga $R(A,B), R(C,D)$ Questa relazione deve soddisfare certi assiomi come\nPropriet√† dell\u0026rsquo;analogia $$ \\mathcal{A}(A,B,A,B) $$ Simmetria\n$$ \\mathcal{A}(A,B,C,D) \\implies \\mathcal{A}(C, D, A, B) $$ Permutazione centrale\n$$ \\mathcal{A}(A,B,C,D) \\implies \\mathcal{A}(A,C,B,D) $$Sono tutte propriet√† che intuivamente hanno senso quando si parla di analogia.\nEquazione di analogia $$ A:B::C:x $$$$ x = argmin(K(A,B,C,x)) $$Minimum Description length principle https://truththeory.com/2018/05/07/string-theory-explained-what-is-the-true-nature-of-reality-video/\nPrinciple used to choose models to describe phenomenons of the world in particular:\n$$ M_{0} = argmin_{M}(K(M) + K(D|M)) $$ Che √® in un certo senso un trade fra overfitting e undefitting classico, solo da un punto di vista di AIT.\nThe best model is neither the simplest one nor the one that offers the best fit with the data, but the model that achieves the best compromise between simplicity and data fitting.\nUniversal Induction Solomonoff usa principle of Multiple explanations (Epicuro, tiene tutte le spiegazioni che sono buone per i dati).\n","permalink":"https://flecart.github.io/notes/model-of-analogies/","summary":"\u003cblockquote\u003e\n\u003cp\u003eThe human ability of making analogies proceeds in such a way as to keep complexity minimal.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003ePerch√© facciamo questo? Perch√© √® la cosa pi√π semplice da fare! Anche su Vapnik\u0026rsquo;s dimensions √® simile questa idea!\u003c/p\u003e\n\u003cp\u003eOccam razor, Epicuro, con Solomonoff che ha risolto problema dell\u0026rsquo;induzione che Hume pensava di fare con abitudini. Attualmente IQ tests provano a misurare la capacit√† di estendere questo.\u003c/p\u003e\n\u003ch3 id=\"analogia\"\u003eAnalogia\u003c/h3\u003e\n\u003cp\u003eStudiamo l\u0026rsquo;analogia come oggetto matematico perch√© sembra essere una capacit√† molto difficile da generalizzare e utilizzare nelle macchine.\u003c/p\u003e","title":"Model of Analogies"},{"content":"Programmazione lineare Programmazione lineare contiene alcuni algoritmi utili per risolvere certi problemi di ottimizzazione.\nIntroduzione Andiamo in questa sezione a definire un problema di programmazione lineare\nDefinizione üü©- Variabili reali che saranno le variabili del nostro problema, sono in numero finito (eg. tutti in Rn) Funzione obiettivo che ci definisce il costo $f: \\R^n \\to \\R$ Vincoli lineari che limitano il dominio delle variabili reali e li mettono in relazione fra di loro Se le variabili appartengono agli interi andiamo a parlare di programmazione lineare intera.\nSlide\nRappresentazione della soluzione si pu√≤ formalizzare sempre in questo modo:\n$$ max\\{cx | Ax ‚â§ b\\} : A \\in M_{m\\times n}, c,b \\in M_{n \\times 1} $$Programmazione lineare intera In modo curioso la programmazione lineare √® pi√π facile rispetto alla PLI.\nEsempio di modelizzazione\nHa fatto un esempio di modelizzazione di un problema introduttivo in classe, in effetti si deve fare attenzione a moltissime cose‚Ä¶ (soprattutto costraints impliciti).\nQuantitative rappresentano alcune quantit√†\nLogiche rappresentano valori binari (di solito utilizzati per modellare l‚Äôassegnamento ad un task)\nRelazioni logiche üü®+ Possiamo codificare con relazioni fra variabili logiche il concetto di negazione, implicazione congiuzione e disgiunzione.\nLe variabili $x \\in \\{0, 1\\}$ in questo caso. La cosa interessante √® che possiamo codificare relazioni logiche con relazioni lineari!\nSlide rappresentazione di relazioni logiche con relazioni lineari\nVincoli di (semi-)assegnamento üü© Abbiamo un insieme di $N = \\{1,..., n\\}$ oggetti da assegnare in $V = \\{1,...,m\\}$ luoghi.\nQuesto si pu√≤ codificare con una matrice $n \\times m$ e usare una variabile logica per specificare se √® stato assegnato a quel luogo o meno.\n(Secondo me si potrebbe anche utilizzare un numero per questo, ma magari l‚Äôalgoritmo utilizzato √® leggermente diverso, no forse specifica una possibilit√† di assegnamento, per questo una matrice √® una cosa giusta).\nVincoli di semiassegnamento\nOssia ogni oggetto √® assegnato a un singolo luogo\nSlide semiassegnamento\nVincoli di assegnamento\nOgni oggetto ha un singolo luogo e ogni luogo un oggetto\nSlide assegnamento\nSelezione sottoinsiemi üü®+ Vogliamo selezionare il minimo fra certi sottoinsiemi (non per forza partizioni!)\nFormulazione classica: sia $F = \\{F_1,..., F_m\\}, F_i \\in \\N$, voglia determinare $D \\subseteq F$ tale che abbia il costo minimo fra tutti. Nella selezione di questi sottoinsiemi possiamo considerare insiemi di copertura, di riempimento o di partizione.\nEsempio del costo classico $\\min\\sum x_j c_j$ cio√® aggiungo il costo con la variabile booleana che decide se lo scelgo o meno, e poi chiamo $a_{ij}$ una matrice che dice se l\u0026rsquo;elemento i √® in $F_j$\nFormalizzazione classica\nCopertura, riempimento partizione\nVariabili a Valori Discreti üü©- Questa parte tratta di valori vincolati a valori reali. (un esempio solito √® una macchina che √® stata costruita a lavorare entro voltaggi precisi).\nSi indica per un insieme di valori che una variabile pu√≤ assumere. Una rappresentazione classica √® in silde sotto\nSlide\nMinima Quantit√† Positiva Prefissata üü®+ Di solito queste tipologie di variabili rappresentano valori di produzione di una macchina perch√© o √® spenta, rappresentata da uno 0, oppure √® accesa e presente in un intervallo\nSlide\nFunzione a carico fisso üü© Indica costi 0 quando la macchina non √® in produzione, mentre per√≤ √® attiva, anche se fa poco, c\u0026rsquo;√® un carico fisso ossia un costo che c\u0026rsquo;√® sempre, e poi cresce in modo lineare\nSlide introduttive\nFormalizzazione classica\nRappresentazione del valore assoluto üü® SI tratta di come rappresentare mediante vincoli la relazione di valore assoluto.\nUn problema con questo metodo √® che non sempre si riescono a gestire\nAnche gestendolo in questo modo ci sono alcune ambiguit√†\nSlide, formalizzazione classica e funzione costo\nFunzioni lineari a tratti üü®+ L\u0026rsquo;idea √® utilizzare una variabile logica che ci dice in quale tratto √® presente, poi utilizzare la funzione per calcolare il valore corretto.\nIn pratica questa √® una forma di generalizzazione dei problemi con funzioni a carico fisso, in cui vengono introdotte delle variabili per dire dove sei, e poi utilizzare la funzione di costo del carico fisso.\nQuesto metodo √® buono perch√© posso utilizzarlo per quanti tratti mi pare\nFormalizzazione\nModellizzazione per Problemi noti Problema della fonderia Soluzione fonderia\nProblema pianificazione della produzione Soluzione pianificazione produzione\nProblema dello zaino (!) Soluzione del modello\nAlbero di copertura di costo minimo Soluzione\nProblema del commesso viaggiatore Note sulla path hamiltoniana\nSoluzione modellizzazione\nProblema dell‚Äôagenzia matrimoniale (!) Soluzione modellizzazione\nProblema allocazione dei lavori alle macchine (!) Descrizione del problema\nDal libro\nAbbiamo dei lavori che devono essere svolti in questi intervalli : $t_i, t_i + d_i$, che sono certi valori che svolgono qualcosa, vogliamo cercare di massimizzare il numero di cose svolte, avendo un certo numero di macchine. Una macchina pu√≤ avere solo un lavoro (o dipendente).\nQuesto √® un problema di semiassegnamento.\nModellizzazione\nponiamo $x_{ij} = 1$ se il lavoro $i$ √® svolto dalla macchina $j$, altrimenti 0\nvincoli necessari semi-assegnamento $\\forall i, \\sum_{j = 1} ^mx_{ij} = 1$, ora dobbiamo andare a modellizzare il concetto dell‚Äôintervallo.\nQuindi mi definisco un insieme $S(i)$ che contiene tutti i lavori incompatibili a $i$.\nAllora il vincolo diventa $x_{ij} + x_{hj} \\leq 1$ con $h \\in S(i)$, Cio√® vogliamo che una macchina esegua solamente un lavoro, o nessun lavoro. E questo vincolo ci d√† il concetto di vincolo.\nOra passo alla discussione della funzione obiettivo, quindi introduco una nuova variabile che mi conta le macchine utilizzate\n$f(obiettivo) = \\sum y_j$, per tutte le macchine, e poi questa $y_j$ √® maggiore di tutti gli $x_{ij}$ per una macchina j fissata.. Cos√¨ provo ad utilizzare meno macchine possibili\nSoluzione dal libro\nhttps://www.notion.so\nProblema docente di informatica (!) Questo problema √® rappresentato nel libro come di minimizzazione del tempo per lavori di macchina a pagina 37 del pdf delle dispense\nDescrizione del problema\nHo $t_1...t_n$ progetti da compilare su $m$ pc, voglio che ci mettano meno tempo possibile.\nModellizzazione\nSia la variabile $x_{ij}$ la variabile logica se il progetto $t_i$ √® data alla macchina $j$\nSemi-assegnamento al massimo assegno il progetto a una singola macchina\n$\\sum_{j = 1} x_{ij} = 1$. Ora entra la parte difficile, introdurre delle variabili che siano utili per avere questo concetto di tempo.\nSia $y_j = \\sum_i t_i x_{ij}$, questo rappresenta il tempo di utilizzo del singolo PC. Quello che noi dobbiamo minimizzare √®\nMa questo vincolo non √® lineare, quindi √® un problema $\\min (\\max Y), Y = \\{y_j : j = 1,...,m\\}$\nQuindi introduco un valore che $z : \\forall j \\sum_i x_{ij} t_i \\leq z$ e provo a minimizzare solamente z, quindi sar√† il suo valore pi√π basso. (minimo upper bound)\nProblema assegnamento delle frequenze Soluzione problema assegnamento\nProblema della commesse üü•- Ho n dipendenti, devo evadere m pacchi, un sottoinsieme $D_j$ che indica da chi pu√≤ essere eseguito questo pacco j, pu√≤ essere da luogo a un ricavo di $r_j$. Un dipendente pu√≤ lavorare su un solo pacco per un intervallo di tempo. Pu√≤ essere che non tutti i pacchi siano da evadere.\nInizio modello\n$F_j = boh$\n$x_j = 1$ se la commessa j √® selezionata, altrimenti 0\n$a_{ij}$ boh\n$x_i \\in \\Z, 0 \\leq x_i\\leq1$\n$\\forall i \\sum a_{ij} x_j \\leq 1$\nFunzione obiettivo $\\max \\sum _{j = 1} ^m x_j r_j$\n","permalink":"https://flecart.github.io/notes/modelizzazione/","summary":"\u003ch1 id=\"programmazione-lineare\"\u003eProgrammazione lineare\u003c/h1\u003e\n\u003cp\u003eProgrammazione lineare contiene alcuni algoritmi utili per risolvere certi problemi di ottimizzazione.\u003c/p\u003e\n\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003cp\u003eAndiamo in questa sezione a definire un problema di programmazione lineare\u003c/p\u003e\n\u003ch3 id=\"definizione--\"\u003eDefinizione üü©-\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eVariabili reali\u003c/em\u003e che saranno le variabili del nostro problema, sono in numero finito (eg. tutti in Rn)\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eFunzione obiettivo\u003c/em\u003e che ci definisce il costo $f: \\R^n \\to \\R$\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eVincoli lineari\u003c/em\u003e che limitano il dominio delle variabili reali e li mettono in relazione fra di loro\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSe le variabili appartengono agli interi andiamo a parlare di \u003cstrong\u003eprogrammazione lineare intera\u003c/strong\u003e.\u003c/p\u003e","title":"Modelizzazione"},{"content":"Socialit√† dello sviluppo del software (3) üü®- Si assume che\n√à difficile assegnarsi i compiti, bisogni di utenti, tempi di consegna (+ persone difficile) √à facile scrivere software (almeno software classico, e non computazione scientifica) La gente sia brava tecnicamente che socialmente √® una cosa rara VS Waterfall (3) üü®++ Pianificare tutto come viene descritto nel modello del waterfall non √® possibile. Per i seguenti motivi\nNon √® chiaro cosa vuole l\u0026rsquo;utente finale (quindi sarebbe meglio avere feedback continuo). Non si sa gi√† dall\u0026rsquo;inizio cosa √® che interessa all\u0026rsquo;utente, per questo motivo si consegna il prodotto passo passo per feedback continuo dato che i requisiti cambiano nel tempo. Giustificazione agile alto livello üü© Vorremo una metodologia che permetta una iterazione ossia un cambio continuo specifiche in funzione di un utente, vogliamo fare le cose a seconda di quanto vuole l\u0026rsquo;utente.\nMetodologia agile La metodologia AGILE √® nata basandosi sulla giapponese Toyota system.\nEtica (!!!) (4) üü®++ Creati verso l\u0026rsquo;anno 2000 https://agilemanifesto.org/iso/it/manifesto.html\nIndividui e interazioni pi√π che a processi e strumenti\nSoftware che funziona pi√π che a documentazione completa\nCollaborazione col cliente pi√π che a negoziazione contrattuale\nReagire al cambiamento pi√π che a seguire un piano\nUmani :)\nDal punto di vista della burocrazia, dovrebbe essere sempre ben documentato il software.\nSoftware √® difficile da tutelare perch√© non √® tangibile come cosa.\nLa possibilit√† di negoziare tutto, invece che seguire un piano di tre anni diciamo.\nPrincipi (12) üü® Proviamo a cercare di commentare questi principi uno per uno\n√à la regola per user-centered philosophy. il fatto che il gruppo deve essere coeso al fine di fare un buon lavoro. La capacit√† di adattamento. Il fatto che deve funzionare perch√© alla fine questo serve all\u0026rsquo;utente finale. Si ribadisce il punto 4 perch√© quello che deve essere misurato √® il funzionamento del codice. Ribadisce l\u0026rsquo;importanza del team, il fatto che devono essere motivati. Regole imposte dall\u0026rsquo;alto sono il male, il team si dovrebbe organizzare da solo riguardo architetture e requisiti. (non sempre avere uno che fa tutto √® di aiuto). Faccia a faccia √® meglio rispetto ad online. Sostenibile nel senso di investimento di risorse, senza sprecare risorse e che siano sufficienti per fare quello che devi fare. Lo interpreto come fare cose che dovrebbero essere modulari e facilmente estendibili. Semplice √® pi√π facile da leggere e capire. La capacit√† di cambiare e adattarsi a seconda di come si evolve la situazione. (scrum master prover√† a far capire cosa c\u0026rsquo;√® da fare capire diciamo). Extreme programming The XP life-cicle (4) üü© Questa √® stata una delle prime forme di sviluppo iterativo che sono esistite, si pu√≤ dire che √® un precursore di Scrum Method.\nIn contrario rispetto: se funziona quanto basta, Defines features, che sono le cose che vorrebbe Poi il developer stima il costo per l\u0026rsquo;implementazione, si deve alla fine dare un prezzo al software. Customer sceglie fra quelle che pu√≤ Poi si costruisce Valori XP (4) üü®++ semplicit√† (vedi 11 #Principi (12) üü®) comunicazione (ossia collaborazione internamente) feedback (comunicazione con l\u0026rsquo;utente) coraggio nel modificare comportamento non funzionato in passato, quindi sempre relazionato sulla capacit√† di cambiamento Modificare e buttare parte del codice. Che si traducono in modo effettivo in:\nTutti devono capire specifiche e cose riguardo il codice. Usato per gruppi di piccola grandezza Ci deve essere un rappresentante Other practices Minimum Viable Product üü© L\u0026rsquo;idea √® non costruire alla fine un qualcosa di funzionante, ma partire con gi√† con qualcosa di funzionante e reiterare, migliorando alcuni pezzi Quando si avr√† un MVP, allora si potrebbe anche fare un test di accettazione, ossia mostrare quanto fatto al cliente e ricevere un primo feedback.\nUser stories Definition of stories üü© Vengono descritte ci√≤ che gli utenti possono o non possono fare utilizzando le user stories diciamo. Secondo il prof. Missiroli queste user stories devono anche avere un input e un output. (che non √® sensato per√≤.). Poi devono essere stimate e prioritizzate\nPriorit√† e story points üü© Queste storie solitamente sono caratterizzate da un ordine di priorit√† che descrive ci√≤ che deve essere fatto e ci√≤ che non dovrebbe diciamo. Sono utili perch√© aiutano a definire un ordine in cui andare ad affrontare le varie task, definito dal singolo cliente. Gli sviluppatori fanno poi una stima delle risorse utilizzate chiamate story points per cercare di dare una stima del costo in sforzo per sviluppare ci√≤. Il processo di scelta delle task che dovranno essere fatte si chiama planning game, ed √® fatta all\u0026rsquo;inizio di ogni iterazione.\nFormato preferito (3) üü©- Questo √® il formato preferito per andare a descrivere delle user stories (con l\u0026rsquo;aspetto della motivazione in pi√π per aiutare il programmatore a capire meglio cosa deve andare a fare).\nTipo di utente Obiettivo Motivazione (non funzionale per il codice, ma buono per immedesimarsi in quello che dovremo fare). Questo √® importante, ci aiuta a capire bene in che modo sia l\u0026rsquo;importante per il cliente, cio√® quello che dovr√† essere implementato.\nCarpaccio di elefante Secondo Missoroli √® meglio che le storie siano verticali ossia che spaziano praticamente ogni campo (un po\u0026rsquo; di tutto per l\u0026rsquo;appunto, ma che allo stesso tempo siano molto specifiche), per me non ha molto senso perch√© sono due cose che vanno uno contro l\u0026rsquo;altro, non vogliamo che US tocchi tutto. e hanno\nstima priorit√† Condizioni di accettazione (test) oltre alle singole motivazioni Ma secondo me non ci ha capito niente\u0026hellip;\nMoscow Method (4) üü©\u0026ndash; Questo √® un metodo utilizzato per scegliere quali user stories andare ad implementare.\nMust: funzioni che DEBBONO esserci nel prodotto Should: funzioni che DOVREBBERO esserci Could: funzioni che POTREBBERO esserci Wont: funzioni che NON INSERIREMO nella versione attuale https://www.agilebusiness.org/page/ProjectFramework_10_MoSCoWPrioritisation\nBacklog üü© √à l\u0026rsquo;insieme dei task (ossia delle #User stories üü®) che devono essere fatte, e hanno delle priorit√†, che ad ogni iterazione possono cambiare l\u0026rsquo;ordine.\nQuesta parte viene solitamente divisa in due perch√© una √® nel backlog, l\u0026rsquo;altro quello che si vuole implementare durante lo sprint.\nEpiche üü© Saranno alla fine sempre delle user-stories, ma dato che sono molto grandi solitamente sono divisi in task pi√π semplici.\nTask üü© User stories sono richieste dall\u0026rsquo;utente, mentre le task sono dei pezzi utili per la production, qualcosa che √® lecito per lo sviluppatore, ma non ovvio per il cliente.\nFramework Invest The INVEST framework is a set of criteria used to assess the quality of user stories in Agile development. It was introduced by Bill Wake as a reminder of the characteristics that good user stories should possess. The INVEST acronym stands for:\nIndependent: Each user story should be independent, meaning that it can be developed, tested, and delivered without relying on other stories. This helps in prioritizing and sequencing stories based on business value. Negotiable: User stories should not be overly detailed or rigid. They should allow for negotiation between the development team and the product owner, fostering collaboration and adaptation as the project progresses. Valuable: Each user story should deliver value to the end user or customer. It\u0026rsquo;s important that the work being done is meaningful and contributes to the overall goals of the project. Estimable: The team should be able to estimate the effort required to implement a user story. This helps in planning and prioritizing work effectively. If a story is too vague or complex to estimate, it may need to be broken down into smaller, more manageable pieces. Small: User stories should be small enough to be completed within a single iteration or sprint. This helps in maintaining a steady and predictable pace of development, and it allows for frequent releases of working software. Testable: There should be clear criteria for determining when a user story is complete. This ensures that the development team and stakeholders have a shared understanding of what needs to be done and can confirm that the story meets the specified requirements. By applying the INVEST criteria, Agile teams aim to create user stories that are well-defined, manageable, and focused on delivering value to the customer. This, in turn, contributes to the overall success of the Agile development process.\nCasi d\u0026rsquo;uso Descrizione casi d\u0026rsquo;uso üü© I casi d\u0026rsquo;uso sono un metodo per descrivere i requirements vedi Requisiti e backlog del software, tali per cui abbiano il massimo valore possibile. Sono un modo diverso rispetto alle user stories descritte in Modelli AGILE per fare questo. Definisce un scenario dettagliato su esattamente cosa vuole del prodotto, il contesto in questo caso √® molto importante.\nDa quanto mi sembra di aver capito √® proprio una descrizione passo passo per ogni cosa che vuole fare l\u0026rsquo;utente.\nSolitamente questo viene rappresentato con una specie di UML, come descritto in Unified Modeling Language.\nNOTA: non c\u0026rsquo;√® nessun concetto di tempo all\u0026rsquo;interno di questo diagramma, a differenza di sequence e collaboration diagrams.\nI casi d\u0026rsquo;uso sono pi√π utili a descrivere il contesto in cui il software lavora, e per comprendere in che modo pu√≤ aiutare i clienti con il sistema software.\nL\u0026rsquo;attore üü© Sono enti, umani o macchine, che agiscono su un sistema e da questo ottengono valore (servizio, calcolo o simili). Solitamente questi sono distinti in business e tecnici, i primi sono direttamente per clienti, i secondi sono operazionali, per far funzionare bene tutto, sono pi√π interne come cose.\nEstensioni e inclusioni di casi d\u0026rsquo;uso Sono quando alcuni utilizzi devono avere delle funzionalit√† necessarie in questo caso includes, oppure funzionalit√† che sono estese da qualcosaltro, l\u0026rsquo;unica cosa che cambia √® il verso da cui parte la freccia.\nTest driven development Filosofia TDD üü© Solitamente il test per una funzione viene scritta dopo che il codice √® gi√† stato scritto. Questo porta a scrivere codice che spesso non √® testabile Un approccio alternativo √® partire direttamente dalle specifiche ed andare ad implementare del test prima del codice in pratica il codice ci saranno solamente backbones diciamo. Test di accettazione üü© Sono dei test (quindi sempre nella verifica che il software soddisfi i requisiti o meno, non automatici, che vengono fatti insieme al cliente, in modo tale per cui alla fine la user story venga accettata, questo √® solitamente chiamato User acceptance testing perch√© √® fatto col cliente.\nRefactoring Migliorare il codice esistente mantenendo la funzionalit√† inalterata\nSolitamente √® una cosa necessaria, perch√© il codice evolve continuamente, utile a diminuire il technical debt.\nVantaggi refactoring (2) üü© Alcuni esempi possono essere\nrenderlo pi√π leggibile Astrarre dove necessario Buttare codice non necessario Semplificare codice con stessa funzionalit√†. semplicit√† di mantenimento Astrazioni Operazioni di refactoring classiche üü© Aggiungere, cancellando o rinominando Spostare classi nel codice e nella catena di derivazione. Su classi, membri, funzioni statiche, data temporaneo. Pair programming Dinamiche driver navigator üü© Driver and navigator, uno che scrive il codice e l\u0026rsquo;altro che legge e guarda se ci sono alcuni difetti o modi in cui si pu√≤ scrivere il codice (solitamente sono scambiati durante la stessa giornata)\nPlus: propriet√† collettiva del codice, dovrebbe essere famigliare a tanti nel progetto (forse tutti) Propriet√† collettiva del codice üü®++ Tutti dovrebbero essere in grado di capire e modificare secondo necessit√† una parte del codice.\nSe codice √® complesso non verr√† mantenuto o usato.\nAltri argomenti Convenzioni di codifica TODO:\nSostenibilit√† dello sviluppo TODO:\nIntegrazione del codice (!) üü© Ossia fare small releases, giorno per giorno viene integrata una nuova funzionalit√† che viene accettata e validata dal team. Questo poi √® una cosa normalissima in Scrum Method, in cui si vanno proprio per piccoli rilasci.\nStanding Meeting (3) (!) üü© Cosa fatto ieri Cosa si vuole fare oggi Quali sono i problemi maggiori, √® per portare il team tutti sulla stessa pagina. ","permalink":"https://flecart.github.io/notes/modelli-agile/","summary":"\u003ch3 id=\"socialit√†-dello-sviluppo-del-software-3--\"\u003eSocialit√† dello sviluppo del software (3) üü®-\u003c/h3\u003e\n\u003cp\u003eSi assume che\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e√à difficile assegnarsi i compiti, bisogni di utenti, tempi di consegna (+ persone difficile)\u003c/li\u003e\n\u003cli\u003e√à facile scrivere software (almeno software classico, e non computazione scientifica)\u003c/li\u003e\n\u003cli\u003eLa gente sia brava tecnicamente che socialmente √® una cosa rara\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"vs-waterfall-3-\"\u003eVS Waterfall (3) üü®++\u003c/h3\u003e\n\u003cp\u003ePianificare tutto come viene descritto nel modello del waterfall non √® possibile.\nPer i seguenti motivi\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNon √® chiaro cosa vuole l\u0026rsquo;utente finale (quindi sarebbe meglio avere feedback continuo).\u003c/li\u003e\n\u003cli\u003eNon si sa gi√† dall\u0026rsquo;inizio cosa √® che interessa all\u0026rsquo;utente, per questo motivo si consegna il prodotto passo passo per \u003cstrong\u003efeedback continuo\u003c/strong\u003e dato che i requisiti cambiano nel tempo.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"giustificazione-agile-alto-livello-\"\u003eGiustificazione agile alto livello üü©\u003c/h4\u003e\n\u003cp\u003eVorremo una metodologia che permetta una \u003cstrong\u003eiterazione\u003c/strong\u003e ossia un cambio continuo specifiche in funzione di un \u003cstrong\u003eutente\u003c/strong\u003e, vogliamo fare le cose a seconda di quanto vuole l\u0026rsquo;utente.\u003c/p\u003e","title":"Modelli AGILE"},{"content":"Introduzione ai modelli lineari Processi di sviluppo Definizione L‚Äôinsieme strutturato di attivit√†, eventi, documenti e procedure necessari per la costruzione di un sistema software\nCosa viene descritto (4) üü© Questo √® proprio quanto vuole studiare l\u0026rsquo;ingegneria del software -\u0026gt; metodi di sviluppo, in modo da portare i migliori risultati possibile.\nNella formazione classica va a definire 4 concetti (soprattutto utili nel lavoro di gruppo, al fine di comunicare nella maniera pi√π efficace):\nChi fa Cosa viene fatto Quanto la fa Come la fa In breve si vanno a definire l\u0026rsquo;attivit√† di persone che collaborano allo sviluppo di un software, informazioni come: In che modo lavorano? Quali sono i ruoli e le responsabilit√† di ognuno? Come valutare la qualit√† del lavoro? Quali documenti produrre? Ciclo di vita del software üü® Trattando il software come una entit√† viva, sono tutte le parti che partono dalla creazione fino alla sua morte, ossia dismission.\nFasi della vita, da ideazione, sviluppo, rilascio, mantenimento e deprecazione.\nAndiamo a capire quali sono i metodi principali\nAltre note Legge di Conway üü®+ Le organizzazioni che progettano sistemi ne progettano la struttura riproducendo le proprie strutture comunicative (es. l‚Äôorganigramma)\nRiformulando in qualche modo: l\u0026rsquo;architettura del prodotto finale rispecchier√† il modo con cui i creatori hanno comunicato fra di loro. Ossia alcune propriet√† del sistema vengono influenzate dal processo di costruzione. Quindi non √® trasparente questa parte, almeno √® molto difficile renderlo tale.\nEsempio:\nse 4 team collaborano a costruire un compilatore, la struttura finale sar√† su 4 processi in pipeline\nLegge di Brooks Aggiungere personale ad un progetto sw in ritardo lo far√† ritardare ancora di pi√π\nPerch√© in altri campi aggiungere uomini lo fa andare pi√π in fretta, ma nel nostro caso rallenta, perch√© dovr√† esserci tempo per insegnare le conoscenze necessarie per cominciare.\nSoftware come processo sociale üü© Data l\u0026rsquo;osservazione di sopra, √® chiaro che il processo di sviluppo √® fortemente influenzato dai processi di comunicazione interni, che sono un aspetto puramente sociale di questa disciplina. Ecco che entra in gioco questo aspetto delle persone e della comunicazione. Dall\u0026rsquo;altro lato, se la costruzione ha un aspetto sociale in s√©, anche l\u0026rsquo;effetto ha una parte sociale. Guarda per esempio i social, hanno cambiato radicalmente il nostro modo di comunicazione fra persone. (un esempio sulla slide √® la banca per esempio)\nModello di processo software (4) (!) üü© Insieme di processi software che provano a catturare un punto di vista specifico il processo software\nTODO: approfondire? Sembra molto stupido Esempi di modelli Waterfall üü© Questo √® uno dei modelli di processo pi√π vecchi (ormai in disuso per il software), √® un processo lineare.\nEsempio sviluppo classico Una osservazione principale √® che alcuni ruoli sono fermi in certi momenti del waterfall, per esempio lo sviluppatore dovrebbe aspettare di ricevere le specifiche sviluppate dall\u0026rsquo;architetto, che deve sapere ci√≤ che il cliente vuole dal business analyst.\nPositive e negative di waterfall üü©- Chiara definizione dei requisiti fino all\u0026rsquo;inizio Feedback solamente finale dal cliente. Fasi bloccanti Il problema principale √® che il mercato cambia pi√π velocemente dello sviluppo, quindi altra probabilit√† che il requisito cambi prima della fine dello sviluppo. Per il software questo non sembra proprio una strategia buona per dire! ","permalink":"https://flecart.github.io/notes/modelli-lineari-di-sviluppo/","summary":"\u003ch2 id=\"introduzione-ai-modelli-lineari\"\u003eIntroduzione ai modelli lineari\u003c/h2\u003e\n\u003ch3 id=\"processi-di-sviluppo\"\u003eProcessi di sviluppo\u003c/h3\u003e\n\u003ch4 id=\"definizione\"\u003eDefinizione\u003c/h4\u003e\n\u003cblockquote\u003e\n\u003cp\u003eL‚Äôinsieme strutturato di attivit√†, eventi, documenti e procedure necessari per la costruzione di un sistema software\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch4 id=\"cosa-viene-descritto-4-\"\u003eCosa viene descritto (4) üü©\u003c/h4\u003e\n\u003cp\u003eQuesto √® proprio quanto vuole studiare l\u0026rsquo;ingegneria del software -\u0026gt; \u003cstrong\u003emetodi di sviluppo\u003c/strong\u003e, in modo da portare i migliori risultati possibile.\u003c/p\u003e\n\u003cp\u003eNella formazione classica va a definire 4 concetti (soprattutto utili nel lavoro di gruppo, al fine di comunicare nella maniera pi√π efficace):\u003c/p\u003e","title":"Modelli Lineari di sviluppo"},{"content":"Introduzione Digital modulation üü® Slide introduzione\nModulazione digitale: prendiamo un dato digitale e trasmesso con un segnale analogico, come le RF.\nASK: amplitude shift keying\nFSK: frequency shift\nPSK: phase shift\nQuesti sono i tre metodi principali, che dipendono dalle caratteristiche dell‚Äôonda descritte in Fisica del Wireless.\nTRE CARATTERISTICHE\nPower\nResistenza interferenze. (robustezza)\nANALOG MODULATION\nPer modulare un segnale analogico si utilizzano principalemente AM o FM, amplitude o frequency modulation, raramente si utilizza PM.\nIn AM la frequenza √® la stessa, ma posso cambiare la ampiezza, in pratica con l‚Äôampiezza provo a ricalcare l‚Äôampiezza dell‚Äôonda iniziale (credo che intuitivamente onda radio ha frequenza molto pi√π alta del suono, quindi riesco a descriverlo bene, credo, probabilmente sbaglio).\nModello trasmittente e ricevente üü© Struttura trasmittente\nIl primo prova a rappresentare il segnale digitale in un segnale sinusoidale. (probabilmente trasformate here).\nIl secondo blocco prende la codifica in segnale analogico e la trasforma in una onda radio (modulata in un certo modo). (prende in input anche il canale in cui codificare le cose), e questa √® data all‚Äôantenna che genera RF.\nStruttura ricevente\nIl segnale nel frattempo:\nHa perso intensit√† Pu√≤ avere shift di fase a seconda dei rimbalsi Dal ricevente modula l‚Äôonda radio che riceve in un segnale analogico, che ora per√≤ possiede itnerferenze quindi non √® una onda clean, e prova a fare una interpretazione.\nAlgoritmi di modulazione digitale In questa sezione andiamo a presentare tre metodi principali di implementazione della modulazione che sono in ampiezza, in frequenza e in fase. Questi sono metodi per rappresentare 0 o 1 per dire.\nASK FSK PSK üü© Nella parte tagliata c‚Äô√® scritto ‚ÄúSignal modulation (Shift keying)‚Äù\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Modulazione wireless/Untitled 3.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Modulazione wireless/Untitled 3\u0026quot;\u0026gt; ASK\nLa tecnica pi√π semplice √® amplitude shift keying (aka modulazione digitale con amplitude) che non √® altro che trasmettere onde di frequenza precisa per canale per 1 silezio per 0. (ma come faccio a gestire le interferenze? Non c\u0026rsquo;√® silenzio in questo modo!) Credo che questo sia molto simile al morse.\nAd esempio se la distanza √® troppo larga, leggerebbe 0.\nSe il rumore di fondo √® troppo alto leggerebbe 1. ecco interferenze\nFSK\nIl segnale digitale √® codificato attraverso la frequenza del valore, per esempio se utilizziamo una metafora fisica, se il segnale √® rosso ho 1 se viola 0, cambia colore diciamo :).\nQuesto √® pi√π resistente alle interferenze.\nPSK\n√à pi√π difficile da implementare. Viene mantenuta sia la frequenza sia l‚Äôampiezza.\nRappresentazione del segnale üü© Slide rappresentazione\nTre tipologie di grafici, la terza, in cordinate polari √® la pi√π utilizzata, anche se non ci dice la frequenza (la frequenza √® quella mantenuta durante la radio carrier nel sistema di modulazione accennato prima). I punti su questo grafico sono chiamati simboli\nNella sconda perdiamo la fase, poco utilizzata.\nNella prima ha praticamente tutte le infomrazioni (la fase per√≤ credo sia solo relativa).\nBinary Phase Shift Keying e QPSK üü© Slide BPSK e QPSK\nAbbiamo dato ai simboli del grafico alcuni valori binari, questo ci da un modo per andare a interpretare i segnali seguendo quel grafico.\nQAM and HIerarchical modulation üü© Solo che la densit√† dei simboli √® ora ancora maggiore, utilizzo sia intensit√† sia fase\nSlide QAM\nHIERARCHICAL MODULATION\n√à una cosa ancora pi√π precisa!\nSlide HM\nSi utilizza un trucco di codifica di utilizzo della nuvola di segnali e una codifica interna!\nQuesot si utilizza anche per mobile video call in modo che la voce sia codificata meglio.\nSlide mobile video call nice\nSpread spectrum techniques Solitamente potremmo utilizzare delle narrow-band spectrum, solo che queste sono molto sensibili ad interferenze nella narrow-band, per questo motivo si preferisce andare su spread spectrum e andiamo ora a parlare di alcune tecnologie utilizzate per questo. Wireless attack vectors.\nDirect sequence spread spectrum üü©- In pratica vado a definire una chipping spectrum che possiede certe propriet√† statistiche che vengono interpretate come rumore di sottofondo (non correlate fra di loro) nel caso in cui non si conosca il codice.\nSlide funzionamento del chipping sequence\nLa codifica col chiping sequence non √® altro che un xor, con il bit che vogliamo inviare e la chipping sequence\nSlide codifica e decodifica del codice\nQuesto processo di xor √® descritto sotto in Code division multiple access üü©. √à questa tecnologia di code division multiple access. che permette questa trasmsisione su frequenze molto diverse, ed essere comunque ricevuto.\nCode division multiple access üü© Fa s√¨ che utilizzando chipping sequence poco (preferibilmente niente) correlate fra di loro, il segnale viene interpretato come segnale di sottofondo (white noise) e quindi il ricevitore, come per magia, riesce comunque a comprendere il segnale iniziale.\nEsempio di trasmissioen corretta di CMA\nPraticamente a lato ricevente esiste un integratore che fa la somma e viene utilizzato questo per andare a decidere se √® un bit 0 oppure 1 (per comodit√† solitamente lo 0 viene codificato come se fosse un -1).\nFrequency hopping spread spectrum üü© Viene utilizzata l\u0026rsquo;energia per mandare in modo pseudorandomico (secondo il seed, credo ne abbiamo gi√† parlato in precedenza con la cosa di hedy lamarr).\nSlide FHSS\nPraticamente il segnale √® unico (cio√® non √® disperso su una banda larga di segnale, ma √® narrowband) comuqnue per chi non conosce il codice sembra rumore di fondo\nSi utilizza host_master come seed\nFast and slow hopping a seconda del numero di bit mandati prima di switchare segnale.\nOrthogonal Frequency Division Multiplexing üü© signal transmission technology that separates a single high-speed data stream into multiple sub-carrier signals that are transmitted simultaneously. Each sub-carrier signal uses a different frequency, presenting a unique path for data transfer. By using multiple sub-carriers in a single channel, OFDM technology can transmit data more efficiently and reliably, even in noisy and highly congested RF environments\nAbbiamo pacchetti di dati poco distanziati (quind il bitrate nominale √® molto alto, tutto viene fatto in parallelo).\nSlide OFDM\nEsempio\nSTRUTTURA\nQuattro carrier sono utilizzati per gestire il canale quindi per dire che il canale non va, bisogna cambiare, rallentare etc. In modo simile ai pacchetti di gestione della congestione nei routers.\n√à molto efficiente dal vista del bandwith (servono 9.76 kilohearz per un sub carrier) e se ho 20 Mhz ho 2048 subcarrier (questo ci fa venire in mente il perch√© √® lungo quella quantit√† di band withd :D)\nLa cosa bella √® anche l‚Äôindipendenza con i subcarriers!\n1 milione per ogni subcarrier (basta fare qualche calcolo, tipo massimo di tutti i canali sono circa 3 Gbit per questa tecnologia). questa √® WiMax\nSlide WiMax\n250k bit per subcarrier che sono comunque 500 Mb su distanza larga.\nFunzionamento di OFDM üü® Si utilizzano magie matematiche per questa tecnologia, ed √® molto intelligente :D\nAbbiamo un teorema che ci dice che le funzioni di seno e coseno sono tutte fra diloro ortogonali ossia l‚Äôintergrale del segnale √® sempre 0 sopra il periodo di tutti.\nSlide segnali ortogonali\nQuesto permette di sapere che la somma di tutti gli altri segnali danno somma zero e io so in che modo andare a leggere. In questo senso i segnali interferiscono s√¨, ma lo fanno in un modo predicibile che mi permette di ritrovare la informazione iniziale.\nEsempio decodifica\nIntuitivamente le FFT ci permettono di cambiare frame of view, se prima erano tutte compattate sul tempo, ora √® compattato sulla frequenza, per questo motivo riuscimo a distinguerle per bene (quindip ossiamo distinguere anche il bit trasmesso per il singolo subcarrier)\n20Mhz con 52 subcarrier con 4 pilot e il resto dei dati. e utilizza 250k modulazioni l secondo (questo √® il massimo!).\nNelle slides c\u0026rsquo;√® una D, che sta per differential, perch√© sta relativo al precedente (non √® 0, o 180, ma √® differenza rispetto al precedente credo, ma comunque ha detto che non √® per niente importante questa cosa. Esistono bits di convoluzione che sono utilizzati per fixare errori di trasmissione.\nESEMPI:\nSlide OFDM\nEsempio per DBPSK: 1 bit per 48 subcarrier, la met√† sono utilizzati per dato, l\u0026rsquo;altra per protezione, ho 24 carriers per durata, quindi 24 * 250k bits al secondo che √® proprio 6kk!\nSe prendo DQPSK allora ho 3/4 per dati, e questo fa tanti calcoli, ma poca roba..\nUna cosa che accade con 64 QAM che invece di fare 1/2 di protezione viene fatto solamente un terzo perch√© se raggiungi quel punto vuol dire che il canale √® gi√† molto forte.\nE c‚Äô√® un programma di controllo che decide quale codifica andarea d utilizzare (tornando indietro se non (riceve gli acks)\nNel caso io abbia bisogno di ancora altri bit potrei aggiungere altri subcarriers (e si pu√≤ fare in modo dinamico, si chiama channel bonding. (canali di frequenza arbitraria in base a quanto ne ho bisogno ! esempi di tecnologie che lo utilizzano: 802.11 af ac)\n","permalink":"https://flecart.github.io/notes/modulazione-wireless/","summary":"\u003ch3 id=\"introduzione\"\u003eIntroduzione\u003c/h3\u003e\n\u003ch3 id=\"digital-modulation--\"\u003eDigital modulation  üü®\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide introduzione\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Modulazione wireless/Untitled.png\" alt=\"image/universita/ex-notion/Modulazione wireless/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eModulazione digitale: prendiamo un dato digitale e trasmesso con un segnale analogico, come le RF.\u003c/p\u003e\n\u003cp\u003eASK: amplitude shift keying\u003c/p\u003e\n\u003cp\u003eFSK: frequency shift\u003c/p\u003e\n\u003cp\u003ePSK: phase shift\u003c/p\u003e\n\u003cp\u003eQuesti sono i tre metodi principali, che dipendono dalle caratteristiche dell‚Äôonda descritte in \u003ca href=\"/notes/fisica-del-wireless/\"\u003eFisica del Wireless\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTRE CARATTERISTICHE\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003ePower\u003c/p\u003e\n\u003cp\u003eResistenza interferenze. (robustezza)\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eANALOG MODULATION\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003ePer modulare un segnale analogico si utilizzano principalemente \u003cstrong\u003eAM o FM\u003c/strong\u003e, amplitude o frequency modulation, raramente si utilizza PM.\u003c/p\u003e","title":"Modulazione wireless"},{"content":"Questo √® un modo di pi√π alto livello per creare programmazione concorrente.\nIntroduzione ai monitor Questo costrutto per la programmazione concorrente, prende molto dalla programmazione agli oggetti, abbiamo delle variabili presenti al monitor, private solamente accessibili ad essa, tramite procedure che sono mutex automaticamente!\nElementi costituenti üü© Dati locali Sequenza di inizializzazione Procedure di entrata Appena provo a chiamare una procedura, questa √® fatta gi√† in mutua esclusione!.\nE possono modificare dati locali solo tramite chiamate a sue procedure\nCose in slide\nVariabili di condizione üü© Queste sono variabili utilizzate per sincronizzare l‚Äôaccesso,\nStrutture classiche\nPolitica del signal urgent (!) üü© Slide\nL‚Äôidea √® molto simile a quanto fatto per i signal presenti in Semafori, se qualcuno √® in attesa, dai subito il bastone a lui, altrimenti non fai niente.\nQuesta √® la politica di signalling che viene usata implicitamente in esame.\nAltre politiche di signalling (3) üü® Slide\nDifferenze con semafori (3) üü©- Slide\nSembrano simili la Wait e la signal con P e la V, ma sono cose totalmente diverse!!!!.\nSignal non ha nessun effetto se non ci sono processi in attesa, mentre V memorizza sempre Wait √® sempre bloccante! mentre P no‚Ä¶ Il processo risvegliato √® sempre eseguito per primo! (signal urgent). Implementazione dei semafori con monitor üü© Slide\n√à una implementazione molto facile! Per questo motivo ci piace abbastanza üòÄ\nImplementazione monitor con semafori üü®+ Slide\nProblemi classici con monitor Readers and writers üü®+ la parte difficile di questa parte √® scrivere bene le invarianti, quindi √® molto pi√π facile scrivere una soluzione una volta che si sa.\nDriver code\nReaderWriter controller\nVersione senza starvation !!!\nProducer and consumers üü© Soluzione producer and consumers\nBuffer limitato üü© Sol\nQuesta soluzione con i semafori √® molto pi√π clean rispetto a quello dei semafori!\nbasta andare a verificare che le invarianti siano soddisfatte, riguardanti la possibilit√† di scrittura e la possiblit√† di lettura.\nFilosofi a cena Sol\nDriver code, dal punto di vista del filosofo\nWithout deadlock\nWithout deadlock, all destri!\nSoluzione con chopsticks\nuna cosa molto bella √® che che non √® deadlock nemmeno se sono tutti destri! il motivo √® che l\u0026rsquo;accesso √® sempre in mutua esclusione, il primo che va a prenderli √® buona roba.\nUlteriori delucidazioni su questa roba\nSupponiamo per assurdo che ci sia deadlock per la versione in cui i filosofi sono tutti destri. Supponiamo che siamo al filosofo $i$, questo prende la sua bacchetta, e deve aspettare la bacchetta successiva, fino a creare il ciclo. fino a qui abbiamo enunciato quello che deve succedere affinch√© ci sia deadlock. Ma questo non pu√≤ succedere perch√© ogni filosofo guarda da solo se pu√≤ prenderlo o meno (mi sembra che questa soluzione sia un poco meno efficiente rispetto a quello con i semafori, perch√© solamente un filosofo pu√≤ prendere‚Ä¶)\n","permalink":"https://flecart.github.io/notes/monitor/","summary":"\u003cp\u003eQuesto √® un modo di pi√π alto livello per creare programmazione concorrente.\u003c/p\u003e\n\u003ch2 id=\"introduzione-ai-monitor\"\u003eIntroduzione ai monitor\u003c/h2\u003e\n\u003cp\u003eQuesto costrutto per la programmazione concorrente, prende molto dalla programmazione agli oggetti, abbiamo delle variabili presenti al monitor, \u003cstrong\u003eprivate\u003c/strong\u003e solamente accessibili ad essa, tramite procedure che sono \u003cstrong\u003emutex\u003c/strong\u003e automaticamente!\u003c/p\u003e\n\u003ch3 id=\"elementi-costituenti-\"\u003eElementi costituenti üü©\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eDati locali\u003c/li\u003e\n\u003cli\u003eSequenza di inizializzazione\u003c/li\u003e\n\u003cli\u003eProcedure di entrata\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAppena provo a chiamare una procedura, questa √® fatta gi√† in mutua esclusione!.\u003c/p\u003e\n\u003cp\u003eE \u003cstrong\u003epossono modificare dati locali\u003c/strong\u003e solo tramite chiamate a sue procedure\u003c/p\u003e","title":"Monitor"},{"content":"DI Law of Large Numbers e Central limit theorem ne parliamo in Central Limit Theorem and Law of Large Numbers. Usually these methods are useful when you need to calculate following something similar to Bayes rule, but don\u0026rsquo;t know how to calculate the denominator, often infeasible integral. We estimate this value without explicitly calculating that.\nInterested in $\\mathbb{P}(x) = \\frac{1}{z} \\mathbb{P}^{*}(x) = \\frac{1}{Z} e^{-E(x)}$ Can evaluate E(x) at any x.\nProblem 1 Make samples x(r) ~ 2 P Problem 2 Estimate expectations $\\Phi = \\sum_{x}\\phi(x)\\mathbb{P}(x)$) What we\u0026rsquo;re not trying to do: We\u0026rsquo;re not trying to find the most probable state. We\u0026rsquo;re not trying to visit all typical states. Law of large numbers $$ S_{n} = \\sum^n_{i=1} x_{i} ,:, \\bar{x}_{n} = \\frac{S_{n}}{n} $$$$ \\bar{x}_{n} \\to \\mu $$ Ossia il limite converge sul valore atteso di tutte le variabili aleatorie.\n$$ var(\\hat{x}_{n}) = \\frac{\\sigma^{2}}{n} \\to 0 $$Strong Law of large Numbers $$ \\mathbb{P}(\\lim_{ n \\to \\infty } \\bar{x}_{n} =\\mu) = 1 $$$$ \\bar{h}_{n} = \\sum_{i=1}^{n} \\frac{h(x_{i})}{n} $$ E questo converge $O(\\sqrt{ n })$ per la legge dopo.\nCentral limit theorem Data una sequenza di variabili aleatorie, $X_{1}, X_{2}, \\dots, X_{n}\\dots$, tali che siano i.i.d tali per cui $E(X_{1}) = E(X_{2}) = \\dots = E(X_{n}) =\\dots = \\mu$ tale che sia finito, e con varianza tutti uguali $= \\sigma^{2}$ finito.\n$$ \\sqrt{ n } (\\hat{x}_{n} - \\mu) \\to N(0, \\sigma^{2}) $$ La prima parte √® una variabile aleatoria e converge a quel valore. (questo permette di utilizzare la gaussiana quando $n$ √® grande abbastanza).\nMonte carlo integration $$ \\int_{X} h(x) \\cdot f(x) dx = E_{f}[h(x)] = \\mu $$ Questo √® tutto il significato dell\u0026rsquo;integrazione di monte carlo (molte variabili aleatorie per stimare il valore di qualcosa). E questo vale sempre, anche se $f$ non √® una funzione di densit√†, basta che sia positiva (basta riscalare).\nIl motivo per cui funziona √® per LLN, perch√© abbiamo che converger√† su $\\mu$ in lungo termine, basta considerare molte variabili aleatorie consecutive.\nCose interessanti:\nPosso stimare il valore atteso grazie a LLN Posso stimare la varianza grazie ad essa Posso stimare variabili condizionali. Importance sampling Deve soddisfare la cosa del supporto (contiene supporto sia di h che di f) Deve avere varianza finita per i pesi che sono trovati. (ci sono metodi per stimare poi il $g$). la frazione $\\frac{f}{g}$ deve essere limitata e la varianza di $h$ rispetto alla densit√† $f$ deve essere finita. Bound on samples TODO: this should be interesting and important and should use Hoeffding\u0026rsquo;s inequality.\nMarkov Chain Monte Carlo L\u0026rsquo;idea principale di Markov Chain Monte carlo √® di costruire una catena di Markov tale che si possa utilizzare per generare dalla distribuzione difficilmente trattabile. Uno dei metodi principali per fare ci√≤ √® utilizzare tecniche si sampling.\nMetropolis Hastings The Sampling Algorithm üü© We observe that this sampling algorithm takes idea from Markov Chains balanced equation\u0026rsquo;s property of stationary distributions and the Accept Reject algorithm for sampling some distributions. Also in this case, we don\u0026rsquo;t care about the normalization constant for $p$, the distribution that we would like to sample from. We choose the that acceptance probability as it allows us to satisfy the balance equation and thus, the stationary property of the constructed Chain.\nWith Metropolis-Hasting we need to\nBe able to calculate the density for the target distribution Be able to sample easily from the $q$ distribution. Then it has some links with Random Walks inside the space we want to sample. $$ \\alpha = \\min\\left(1, \\frac{p(x')q(x \\mid x')}{p(x)q(x' \\mid x)}\\right) $$ Where $x$ is the current state and $x'$ is the proposed state.\nStationary Distribution üü© We can prove that with that acceptance rate, the probability of transitioning in a given state satisfies the balance equation for the stationary distribution, which implies we can have a well behaved Markov Chain, and continue to sample from this.\n$$ p(x)q(x' \\mid x) \\alpha = p(x')q(x \\mid x') \\alpha $$ To prove this, just consider the two possible cases for the min function.\nCon distribuzioni Gaussiane üü© $$ \\frac{r(x' \\mid x)}{r(x \\mid x')} = \\frac{\\mathcal{N}(x'; x, \\tau I)}{\\mathcal{N}(x; x', \\tau I)} = 1 $$ Quindi il coefficiente $\\alpha$ si pu√≤ scrivere anche solo come le distribuzioni $\\frac{q(x)}{q(x')}$ che se si assume una distribuzione di Gibbs, si pu√≤ intendere come un $\\exp(f(x) - f(x'))$, che √® di facile interpretazione. Quindi possiamo fare sampling solamente considerando il rapporto fra le due distribuzioni.\nVariations and Improvements Metropolis-Hastings\u0026rsquo; sample efficiency could be improved by adding information about the gradient of the distribution. This is the idea behind the Langevin algorithm.\nMetropolis Adjusted Langevin Algorithm üü® $$ r(x'\\mid x) = \\mathcal{N}(x'; x + \\tau \\nabla f(x), 2\\tau I)\\propto \\exp\\left( -\\frac{1}{2} \\left\\| \\frac{x' - x - \\tau \\nabla \\log p(x)}{G} \\right\\|^2 \\right), $$ ¬ß It is possible to show that for log-concave distributions (e.g., Bayesian log. Regression), MALA efficiently converges to the stationary distribution (mixing time is polynomial in the dimension)\nSomehow, one can prove that if $\\tau \\to 0$ then the Metropolis Hastings tends to always accept the proposal, which is why it is more efficient. The version of Metropolis Hastings that always accepts is called Unadjusted Langevin Algorithm.\n$$ p(\\theta \\mid x_{1:n}, y_{1:n}) = \\frac{1}{Z} \\exp(\\log p(\\theta) + \\sum_{i=1}^{n} \\log p(y_{i} \\mid x_{i}, \\theta)) $$$$ \\theta_{t+1} = \\theta_{t} + \\tau \\nabla_{\\theta} \\log p(\\theta) + \\tau \\sum_{i=1}^{n} \\nabla_{\\theta} \\log p(y_{i} \\mid x_{i}, \\theta) + \\varepsilon $$ Where $\\varepsilon \\sim \\mathcal{N}(0, 2\\tau I)$\nThe drawback of this method is that computing the energy for the whole dataset is expensive for large datasets. This is why sometimes we use a stochastic version of this algorithm. Which drives to the stochastic gradient Langevin dynamics.\nStochastic Gradient Langevin Dynamics üü®+ The double value for the Noise signal is justifiable if you study diffusion processes. So if you want to know how the $2$ factor comes into play when analyzing the process take a look at those courses. One can also estimate the update of the gradient of the likelihood by having $m$ samples and then using that values for the update: So the algorithm for the update becomes:\nSample $m$ points and then update $\\theta$ as follows: $$ \\theta_{t+1} = \\theta_{t} + \\tau \\nabla_{\\theta} \\log p(\\theta) + \\tau\\frac{n}{m} \\sum_{i=1}^{m} \\nabla_{\\theta} \\log p(y_{i} \\mid x_{i}, \\theta) + \\varepsilon $$ Langevin Monte Carlo TODO: this is just an Outlook, and it is left out from here.\nLandscape of sampling methods üü®\u0026ndash; we can broadly categorize optimization methods based on the use of\nMomentum Stochasticity Sampling Then we would have this cube. Gibbs Sampling These are probably not very important for the exam. We use a collapsed version of Gibbs Sampling for Dirichlet Processes.\nThe Idea üü© Gibbs sampling is a special case of Metropolis Hasting, in this case the proposal distribution $r$ is as follows:\n$$ r_{i}(x' \\mid x) = \\begin{cases} p(x_{i}' \\mid x'_{-i}) \u0026 \\text{if } x' \\text{ differs from } x \\text{ only in } i \\\\ 0 \u0026 \\text{else} \\\\ \\end{cases} $$ We just focus on a single coordinate difference. Similar to the coordinate descent in some manner.\nProof of correctness This sections proves that Gibbs Sampling indeed gives the original distribution. We will use a similar idea presented for #Metropolis Hastings.\nOne can observe the following: $$ \\begin{align} \\alpha_{i}(x\u0026rsquo;\\mid x) = \\min \\left(1, \\frac{p(x\u0026rsquo;)}{p(x)} \\right) = 1 \\end{align}\n$$\nA simple code example This code example shows how we can sample from a multivariate Gaussian using Gibbs sampling. Note that we just need to be able to compute marginals in order to sample this.\nimport numpy as np import matplotlib.pyplot as plt # Define parameters of the bivariate Gaussian mu1, mu2 = 0, 0 # Means sigma1, sigma2 = 1, 1 # Standard deviations rho = 0.8 # Correlation coefficient # Derived quantities cov = rho * sigma1 * sigma2 # Covariance Sigma = np.array([[sigma1**2, cov], [cov, sigma2**2]]) # Covariance matrix Sigma_inv = np.linalg.inv(Sigma) # Precision matrix # Conditional distributions def sample_x1_given_x2(x2, mu1, mu2, sigma1, sigma2, rho): cond_mean = mu1 + rho * (sigma1 / sigma2) * (x2 - mu2) cond_var = (1 - rho**2) * sigma1**2 return np.random.normal(cond_mean, np.sqrt(cond_var)) def sample_x2_given_x1(x1, mu1, mu2, sigma1, sigma2, rho): cond_mean = mu2 + rho * (sigma2 / sigma1) * (x1 - mu1) cond_var = (1 - rho**2) * sigma2**2 return np.random.normal(cond_mean, np.sqrt(cond_var)) # Gibbs Sampling def gibbs_sampling(num_samples, burn_in=100): samples = [] x1, x2 = 0, 0 # Initial values for _ in range(num_samples + burn_in): x1 = sample_x1_given_x2(x2, mu1, mu2, sigma1, sigma2, rho) x2 = sample_x2_given_x1(x1, mu1, mu2, sigma1, sigma2, rho) samples.append((x1, x2)) return np.array(samples[burn_in:]) # Discard burn-in samples # Run Gibbs Sampling num_samples = 5000 samples = gibbs_sampling(num_samples) # Plot results plt.figure(figsize=(8, 6)) plt.scatter(samples[:, 0], samples[:, 1], alpha=0.5, s=5, label=\u0026#34;Samples\u0026#34;) plt.title(\u0026#34;Gibbs Sampling: Bivariate Gaussian\u0026#34;, fontsize=14) plt.xlabel(\u0026#34;$X_1$\u0026#34;, fontsize=12) plt.ylabel(\u0026#34;$X_2$\u0026#34;, fontsize=12) plt.axhline(0, color=\u0026#39;gray\u0026#39;, linewidth=0.5) plt.axvline(0, color=\u0026#39;gray\u0026#39;, linewidth=0.5) plt.grid(alpha=0.3) plt.legend() plt.show() ","permalink":"https://flecart.github.io/notes/monte-carlo-methods/","summary":"\u003cp\u003eDI Law of Large Numbers e Central limit theorem ne parliamo in \u003ca href=\"/notes/central-limit-theorem-and-law-of-large-numbers/\"\u003eCentral Limit Theorem and Law of Large Numbers\u003c/a\u003e.\nUsually these methods are useful when you need to calculate following something similar to Bayes rule, but don\u0026rsquo;t know how to calculate the denominator, often infeasible integral. We estimate this value without explicitly calculating that.\u003c/p\u003e\n\u003cp\u003eInterested in $\\mathbb{P}(x) = \\frac{1}{z} \\mathbb{P}^{*}(x) = \\frac{1}{Z} e^{-E(x)}$\nCan evaluate E(x) at any x.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eProblem 1 Make samples x(r) ~ 2 P\u003c/li\u003e\n\u003cli\u003eProblem 2 Estimate expectations  $\\Phi = \\sum_{x}\\phi(x)\\mathbb{P}(x)$)\nWhat we\u0026rsquo;re not trying to do:\u003c/li\u003e\n\u003cli\u003eWe\u0026rsquo;re not trying to find the most probable state.\u003c/li\u003e\n\u003cli\u003eWe\u0026rsquo;re not trying to visit all typical states.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"law-of-large-numbers\"\u003eLaw of large numbers\u003c/h3\u003e\n$$\nS_{n} = \\sum^n_{i=1} x_{i} ,:, \\bar{x}_{n} = \\frac{S_{n}}{n}\n$$$$\n\\bar{x}_{n} \\to \\mu\n$$\u003cp\u003e\nOssia il limite converge sul valore atteso di tutte le variabili aleatorie.\u003c/p\u003e","title":"Monte Carlo Methods"},{"content":"Multi-variable derivative To the people that are not used to matrix derivatives (like me) it could be useful to see how $$ \\frac{ \\partial u^{T}Su }{ \\partial u } = 2Su $$ First, we note that if you derive with respect to some matrix, the output will be of the same dimension of that matrix. That notation is just deriving every single component independently and then joining them together, so it will be better understood as as $$ \\frac{ \\partial u^{T}Su }{ \\partial u } = \\begin{bmatrix} \\frac{ \\partial u^{T}Su }{ \\partial u_{1} } \\ \\dots \\ \\frac{ \\partial u^{T}Su }{ \\partial u_{M} } \\ \\end{bmatrix} $$ So we can prove each derivative independently, it's just a lot of manual work! We see that $u^{T}Su$ is just a quadratic form, studied in [Massimi minimi multi-variabile#Forme quadratiche](/notes/massimi-minimi-multi-variabile#forme-quadratiche) so it is just computing this: $$ u^{T}Su = \\sum_{i, j = 1, 1}^{M} u_{i}u_{j}S_{ij} \\implies \\frac{ \\partial u^{T}Su }{ \\partial u_{1} } =2u_{1}S_{11} + \\sum_{j \\neq 1}^{M}(u_{j}S_{1j} + u_{j}S_{j1}) = 2\\left( u_{1}S_{11} + \\sum_{j \\neq 1}u_{j}S_{1j} \\right) = 2(Su)_{1} $$ Last equation is true because $S$ is a symmetric matrix, then we easily see that indeed it\u0026rsquo;s true that indeed it\u0026rsquo;s the first row of the $Su$ matrix multiplied by 2.\nKnown theorems The Multivariate Chain Rule Let $\\mathbf{x} = (x_1, x_2, \\dots, x_n)$ be an $n$-dimensional vector, and let each $x_i$ depend on a scalar variable $t$, i.e.,\n$$ x_i = x_i(t), \\quad \\text{for } i = 1, 2, \\dots, n. $$Suppose we have a function $f$ that maps $\\mathbb{R}^n \\to \\mathbb{R}$, i.e.,\n$$ f: \\mathbb{R}^n \\to \\mathbb{R}, \\quad f = f(x_1, x_2, \\dots, x_n). $$Then, the total derivative of $f$ with respect to $t$ is given by:\n$$ \\frac{d f}{d t} = \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x_i} \\frac{d x_i}{d t}. $$or, in vector notation:\n$$ \\frac{d f}{d t} = \\nabla f \\cdot \\frac{d \\mathbf{x}}{d t}, $$where:\n$\\nabla f = \\left( \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\dots, \\frac{\\partial f}{\\partial x_n} \\right)$ is the gradient of $f$. $\\frac{d \\mathbf{x}}{d t} = \\left( \\frac{d x_1}{d t}, \\frac{d x_2}{d t}, \\dots, \\frac{d x_n}{d t} \\right)$ is the time derivative of $\\mathbf{x}$. Proof\nBy definition, the total derivative of $f$ with respect to $t$ measures the rate of change of $f$ as $t$ varies:\n$$ \\frac{d f}{d t} = \\lim_{\\Delta t \\to 0} \\frac{f(\\mathbf{x}(t + \\Delta t)) - f(\\mathbf{x}(t))}{\\Delta t}. $$Since $f$ is a function of $\\mathbf{x}$, we perform a first-order Taylor expansion (see Hopital, Taylor, Peano) around $\\mathbf{x}(t)$:\n$$ f(\\mathbf{x}(t + \\Delta t)) \\approx f(\\mathbf{x}(t)) + \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x_i} \\Big|_{\\mathbf{x}(t)} \\cdot \\Delta x_i. $$Dividing by $\\Delta t$ and taking the limit:\n$$ \\frac{d f}{d t} = \\lim_{\\Delta t \\to 0} \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x_i} \\frac{\\Delta x_i}{\\Delta t} $$Since $\\lim_{\\Delta t \\to 0} \\frac{\\Delta x_i}{\\Delta t} = \\frac{d x_i}{d t}$, we obtain:\n$$ \\frac{d f}{d t} = \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x_i} \\frac{d x_i}{d t}. $$$$ \\frac{d f}{d t} = \\nabla f \\cdot \\frac{d \\mathbf{x}}{d t}. $$This represents the directional derivative of $f$ along the trajectory $\\mathbf{x}(t)$, showing how $f$ evolves as $t$ changes.\nTotal Derivative Rule This is a simple extension of the multi-variable chain rule described above:\nLet $f(\\mathbf{w}, \\theta)$ be a function of:\nA vector $\\mathbf{w} \\in \\mathbb{R}^n$ which itself depends on $\\theta$, i.e., $\\mathbf{w} = t(\\theta, \\epsilon)$. A scalar parameter $\\theta$. The total derivative of $f(\\mathbf{w}, \\theta)$ with respect to $\\theta$ is given by:\n$$ \\frac{d}{d \\theta} f(\\mathbf{w}, \\theta) = \\frac{\\partial f}{\\partial \\mathbf{w}} \\cdot \\frac{d \\mathbf{w}}{d \\theta} + \\frac{\\partial f}{\\partial \\theta}. $$This result follows from the multivariate chain rule. For a function $f(x_1, x_2, \\dots, x_n, \\theta)$ where each $x_i$ depends on $\\theta$, the total derivative is:\n$$ \\frac{d f}{d \\theta} = \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x_i} \\frac{d x_i}{d \\theta} + \\frac{\\partial f}{\\partial \\theta} \\frac{ \\partial \\theta }{ \\partial \\theta } $$In our case:\nThe variables $x_i$ correspond to the components of $\\mathbf{w}$. $\\mathbf{w}$ is a vector, so we sum over its components. Thus, applying the chain rule:\n$$ \\frac{d}{d \\theta} f(\\mathbf{w}, \\theta) = \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial w_i} \\frac{d w_i}{d \\theta} + \\frac{\\partial f}{\\partial \\theta}. $$We can rewrite the above in vector notation. Since $\\mathbf{w}$ is an $n$-dimensional vector, we rewrite the sum as a dot product:\n$$ \\frac{d}{d \\theta} f(\\mathbf{w}, \\theta) = \\nabla_{\\mathbf{w}}f\\cdot \\frac{d \\mathbf{w}}{d \\theta} + \\frac{\\partial f}{\\partial \\theta}=\\frac{\\partial f}{\\partial \\mathbf{w}} \\cdot \\frac{d \\mathbf{w}}{d \\theta} + \\frac{\\partial f}{\\partial \\theta} $$where:\n$\\frac{\\partial f}{\\partial \\mathbf{w}}$ is the gradient $\\left[ \\frac{\\partial f}{\\partial w_1}, \\frac{\\partial f}{\\partial w_2}, \\dots, \\frac{\\partial f}{\\partial w_n} \\right]$. $\\frac{d \\mathbf{w}}{d \\theta}$ is the Jacobian $\\left[ \\frac{d w_1}{d \\theta}, \\frac{d w_2}{d \\theta}, \\dots, \\frac{d w_n}{d \\theta} \\right]$. One application of this formalism can is the reparametrization trick in Variational Inference.\nCommon derivatives Determinant $$ \\frac{\\partial \\det(\\mathbf{A}(t))}{\\partial \\mathbf{t}} = \\det(\\mathbf{A}) \\cdot \\left( \\text{tr}(\\mathbf{A}^{-1}) \\cdot \\frac{ \\partial A(t) }{ \\partial x } \\right) $$$$ \\frac{\\partial \\det(\\mathbf{A})}{\\partial \\mathbf{A}} = \\det(\\mathbf{A}) \\cdot (\\mathbf{A}^{-1})^\\top $$$$ \\begin{align} \\frac{\\partial \\det(\\mathbf{A})}{\\partial \\mathbf{A}} \u0026= \\det(\\mathbf{A}) \\cdot \\frac{\\partial \\ln \\det(\\mathbf{A})}{\\partial \\mathbf{A}} \\\\ \u0026= \\det(\\mathbf{A}) \\cdot \\frac{\\partial \\text{tr} (\\ln A)}{\\partial \\mathbf{A}}\\\\ \\\\ \u0026= \\det(\\mathbf{A}) \\cdot (\\mathbf{A}^{-1})^\\top \\end{align} $$ I don\u0026rsquo;t think I have understood this thing quite well\u0026hellip;\nMatrix Inverse $$ \\frac{\\partial \\mathbf{A}^{-1}}{\\partial \\mathbf{A}} = -\\mathbf{A}^{-1} \\otimes \\mathbf{A}^{-1}. $$$$ \\begin{align} \\frac{\\partial}{\\partial \\mathbf{A}} (\\mathbf{A} \\mathbf{A}^{-1}) \u0026= \\frac{\\partial \\mathbf{I}}{\\partial \\mathbf{A}} = 0 \\\\ \u0026\\implies \\frac{\\partial \\mathbf{A}}{\\partial \\mathbf{A}} \\cdot \\mathbf{A}^{-1} + \\mathbf{A} \\cdot \\frac{\\partial \\mathbf{A}^{-1}}{\\partial \\mathbf{A}} = 0 \\\\ \u0026\\implies\\mathbf{I} \\cdot \\mathbf{A}^{-1} + \\mathbf{A} \\cdot \\frac{\\partial \\mathbf{A}^{-1}}{\\partial \\mathbf{A}} = 0 \\\\ \u0026\\implies \\frac{\\partial \\mathbf{A}^{-1}}{\\partial \\mathbf{A}} = -\\mathbf{A}^{-1} \\cdot \\mathbf{A}^{-1}. \\end{align} $$Quadratic Form $$ \\frac{\\partial}{\\partial \\mathbf{A}} \\left( \\mathbf{v}^\\top \\mathbf{A} \\mathbf{v} \\right) = \\mathbf{v} \\mathbf{v}^\\top. $$This should be easy, and quite similar to the above case when we have derived $v$.\nQuadratic Inverse $$ \\frac{\\partial}{\\partial \\mathbf{A}} \\left( \\mathbf{v}^\\top \\mathbf{A}^{-1} \\mathbf{v} \\right) = -\\mathbf{A}^{-1} \\mathbf{v} \\mathbf{v}^\\top \\mathbf{A}^{-1}. $$You can interpret this as a function composition.\n","permalink":"https://flecart.github.io/notes/multi-variable-derivatives/","summary":"\u003ch4 id=\"multi-variable-derivative\"\u003eMulti-variable derivative\u003c/h4\u003e\n\u003ch1 id=\"endbmatrix\"\u003eTo the people that are not used to matrix derivatives (like me) it could be useful to see how\n$$\n\\frac{ \\partial u^{T}Su }{ \\partial u }  = 2Su\n$$\nFirst, we note that if you derive with respect to some matrix, the output will be of the same dimension of that matrix. That notation is just deriving every single component independently and then joining them together, so it will be better understood as as\n$$\n\\frac{ \\partial u^{T}Su }{ \\partial u }  =\n\\begin{bmatrix}\n\\frac{ \\partial u^{T}Su }{ \\partial u_{1} }  \\\n\\dots \\\n\\frac{ \\partial u^{T}Su }{ \\partial u_{M} }  \\\n\\end{bmatrix}\u003c/h1\u003e\n$$\nSo we can prove each derivative independently, it's just a lot of manual work!\nWe see that $u^{T}Su$ is just a quadratic form, studied in [Massimi minimi multi-variabile#Forme quadratiche](/notes/massimi-minimi-multi-variabile#forme-quadratiche) so it is just computing this:\n$$\u003cp\u003e\nu^{T}Su = \\sum_{i, j = 1, 1}^{M} u_{i}u_{j}S_{ij} \\implies \\frac{ \\partial u^{T}Su }{ \\partial u_{1} } =2u_{1}S_{11} + \\sum_{j \\neq 1}^{M}(u_{j}S_{1j}  + u_{j}S_{j1}) = 2\\left( u_{1}S_{11} + \\sum_{j \\neq 1}u_{j}S_{1j} \\right) = 2(Su)_{1}\n$$\nLast equation is true because $S$ is a symmetric matrix, then we easily see that indeed it\u0026rsquo;s true that indeed it\u0026rsquo;s the first row of the $Su$ matrix multiplied by 2.\u003c/p\u003e","title":"Multi Variable Derivatives"},{"content":"Introduzione a Na√Øve Bayes NOTE: this note should be reviewed after the course I took in NLP. This is a very old note, not even well written.\nBisognerebbe in primo momento avere benissimo in mente il significato di probabilit√† condizionata e la regola di naive Bayes in seguito.\nBayes ad alto livello üü© Da un punto di vista intuitivo non √® altro che predire la cosa che abbiamo visto pi√π spesso in quello spazio Assunzioni principali per na√Øve Bayes üü© I sample di input sono condizionalmente indipendenti uno con l\u0026rsquo;altro. Questo permette di utilizzare questa ipotesi $$ P(X_{1}\\dots X_{n} | Y = y_{i}) = \\prod_{i}^{n} P(X_{i} | Y) $$ E permette di rendere la parte di inferenza anche molto semplice perch√© per classificare un caso basta prendere label con la probabilit√† maggiore. che √® dato solamente dal numeratore durante la regola di Bayes. Tecnica generativa üü© La distinzione fra generativa e discriminativa √® fatta in Introduction to machine learning. Ossia cerchiamo di capire come si distribuiscono i dati? (ossia prova a capire le probabilit√† che abbiano generato questi dati). Mentre in modelli supervisionati classici si potrebbe dire che provano a capire $Y$ assumendo i dati esistenti di training.\nProva a capire $P(X|Y)$ diciamo e poi da questo si pu√≤ ricalcolare $P(Y | X)$ grazie alla formula di Bayes una volta capito $P(X)$ e l\u0026rsquo;altro.\n$$ P(Y | X) = \\frac{P(X|Y)P(Y)}{P(X)} $$Classificazione lineare Bayes üü©- Si viene a scoprire che Na√Øve bayes alla fine fa classificazione lineare, che ci dice che √® un modello molto molto semplice.\n$$ \\frac{P(Y = 1, X_{1}\\dots X_{n} = \\vec{x})}{P(Y = 0, X_{1}\\dots X_{n} = \\vec{x})} = \\frac{P(Y = 1 | X_{1}\\dots X_{n} = \\vec{x})}{P(Y = 0 | X_{1}\\dots X_{n} = \\vec{x})}\\geq 1 $$ La prima uguaglianza di sopra √® ottenuta osservando che $P(Y=1, X_{1}, \\dots, X_{n} = \\vec{x}) = P(Y=1 | X_{1}, \\dots, X_{n} = \\vec{x}) \\cdot P(X_{1}, \\dots, X_{n} = \\vec{x})$ E poi semplificando entrambi.\n$$ \\log \\frac{P(Y=1)}{P(Y=0)} + \\sum_{i} \\log \\frac{P(X_{i} = x_{i} | Y=1)}{P(X_{i} = x_{i} | Y=0)} \\geq 0 $$ E usando un trucco lo facciamo diventare lineare (vedi slide 126)\nNotiamo che una funzione da booleani a booleani si pu√≤ approssimare come\n$$ f(x) = x f(1) + (1 - x) f(0) $$$$ \\theta_{ik} = P(X_{i} = 1 | Y = y_{k}) $$Non so in che modo possa essere estesa ad altri casi, ma nel caso booleano funziona Quindi unendo le due cose abbiamo:\n$$ \\sum_{i} \\log \\frac{P(X_{i} = x_{i} | Y=1)}{P(X_{i} = x_{i} | Y=0)} = \\sum_{i}x_{i} \\log \\frac{\\theta_{i1}}{\\theta_{i0}} + \\sum_{i} (1 - x_{i}) \\log \\frac{1 - \\theta_{i1}}{1- \\theta_{i0}} $$ Assumendo che $f(x) = \\log \\frac{P(X_{i} = x | Y=1)}{P(X_{i} = x | Y=0)}$ Vediamo da sopra che √® lineare.\nCaso continuo Introduzione modellazione nel caso continuo üü®+ Per ora abbiamo sempre assunto che le classi da predire fossero discreti, per√≤ si pu√≤ utilizzare anche in un caso continuo, e in questo caso si usa una gaussiana.\nScegliamo una legge gaussiana perch√© naturalmente se sommiamo un sacco di distribuzioni, verr√† che sar√† una gaussiana. Legge dei grandi numeri, quindi √® una fra le distribuzioni pi√π naturali. √à la distribuzione con entropia maggiore fra tutte le distribuzioni con data media e varianza. Se si hanno altre informazioni, sarebbe molto pi√π sensato utilizzare una altra distribuzione, ma introdurrebbe un bias di un certo tipo. Metriche TP FP TN FN üü©- Questa parte √® molto importante per sapere quali metriche siano importanti, riguardo\nTrue positives False positives True Negatives False positives E con queste possiamo definire concetti come accuratezza, recall e precisione Inferenza nel caso continuo üü©\u0026ndash; Sembra molto simile a una Gaussian Mixture Models, perch√© alla fine √® una interpolazione in un certo senso, solo che √® motivato in modo diverso. Training nel caso continuo E probabilmente si pu√≤ dimostrare, facendo un ragionamento come Maximum Likelihood extimate anche in questo caso. Algoritmo di fitting Si tratta quindi di creare tutti i parametri $\\theta_{ijk}$, anche se in questo momento non sto capendo in che modo Al fine di stimare questo usiamo maximum likelihood extimate. Guardare #Sul MLE sotto per capire in che modo sono stimati.\nStima P(Y) üü© Poniamo la cosa pi√π banale, la stima di $P(Y = y_{i})$ √® solamente la percentuale delle labels che abbiamo, ossia\n$$ \\pi_{i} = P(Y = y_{i}) = \\frac{\\#D(Y = y_{i})}{\\lvert D \\rvert} $$Utilizziamo $\\pi$ per scrivere in modo pi√π veloce la probabilit√† del singolo label.\nStima parametri P(X|Y) üü© $$ \\theta_{ijk} = P(X = x_{ij} | Y = y_{k}) = \\frac{\\#D(X_{i} = x_{i,j} \\cap Y = y_{k})}{\\#D(Y=y_{k})} $$Edge cases (2) üü©- Probabilit√† id zero: Non vogliamo avere che $P(X_{i}|Y) = 0$ perch√© produrrebbe sempre nullo (questo succede per esempio per i modelli di testo mi pareva), √® improbabile che sia 0 perch√© noi per ora ci stiamo concentrando su una stima, una cosa che fanno √® aggiungere sempre almeno un esempio perch√© cos√¨ non ho una probabilit√† nulla per tutto in questo caso.\nCasi non indipendenti Questo √® molto difficile da gestire, dipende da come abbiamo generato i dati, quindi √® esterna a questa fase di scelta del modello diciamo. Bayes √® probabilmente non molto utile in questi casi, perch√© questo caso viola l\u0026rsquo;assunzione iniziale, si dovrebbe probabilmente fare preprocessing per cercare di limitare la dipendenza.\nMaximum Likelihood estimation Di questo parleremo molto meglio in Parametric Modeling.\nIntroduzione al problema C\u0026rsquo;√® una parte teorica molto pi√π interessante per quanto si tratta di maximum likelihood estimation. Andiamo a giustificare il motivo per cui stime molto semplici ed intuitive come quelli presenti in #Stima P(Y) e #Stima parametri P(X Y) possono funzionare. Ci chiediamo in questa istanza quale sia il caso pi√π probabile ossia quello con maximum likelihood\nMLE su bernoulli Supponiamo di avere $n$ lanci con una moneta unfair, ossia $p(X) \\neq 0.5$ di avere testa. Date certe osservazioni, quale √® il valore pi√π probabile di $P(X)$?\nConsideriamo $X^{n}$ la variabile aleatoria che misura il numero di 0 all\u0026rsquo;interno del nostro problema, allora questo segue la legge di Bernoulli.\n$$ P(X^{n} = \\alpha_{0} | \\theta) = \\binom{n}{\\alpha_{0}} \\theta^{\\alpha_{0}} (1 - \\theta)^{n-\\alpha_{0}} $$ Seguendo l\u0026rsquo;idea del pi√π probabile quello che noi stiamo cercando √®\n$$ \\hat{\\theta} = \\arg\\max_{\\theta} P(X^{n} = \\alpha_{0} | \\theta) $$Soluzione problema analitico Prendiamo il logaritmo, che non cambia il nostro massimo, dato che √® monotona, ma ci semplifica un sacco l\u0026rsquo;analisi\n$$ \\ln(\\theta^{\\alpha} (1- \\theta)^{n - \\alpha }) = \\alpha \\ln \\theta + (n- \\alpha) \\ln(1 - \\theta) $$ Derivando rispetto a $\\theta$ abbiamo che\n$$ \\frac{\\alpha}{\\theta} - \\frac{n - \\alpha}{1- \\theta} = \\frac{\\alpha - \\alpha \\theta - (n - \\alpha) \\theta}{\\theta (1 - \\theta)} $$$$ \\alpha - \\alpha \\theta - (n - \\alpha) \\theta = 0 \\implies \\theta = \\frac{\\alpha}{n} $$E se ben ricordiamo, $\\alpha$ non era altro che il numero di samples negativi, quindi questo √® un esempio locale in cui MLE √® la soluzione ottimale per stimare.\n","permalink":"https://flecart.github.io/notes/na%C3%AFve-bayes/","summary":"\u003ch3 id=\"introduzione-a-na√Øve-bayes\"\u003eIntroduzione a Na√Øve Bayes\u003c/h3\u003e\n\u003cp\u003eNOTE: this note should be reviewed after the course I took in NLP. This is a very old note, not even well written.\u003c/p\u003e\n\u003cp\u003eBisognerebbe in primo momento avere benissimo in mente il significato di \u003cstrong\u003eprobabilit√† condizionata\u003c/strong\u003e e la regola di naive Bayes in seguito.\u003c/p\u003e\n\u003ch4 id=\"bayes-ad-alto-livello-\"\u003eBayes ad alto livello üü©\u003c/h4\u003e\n\u003cp\u003eDa un punto di vista intuitivo non √® altro che predire la cosa che abbiamo \u003cstrong\u003evisto pi√π spesso in quello spazio\u003c/strong\u003e\n\u003cimg src=\"/images/notes/Na√Øve Bayes-1696854772448.jpeg\" width=\"500\" alt=\"Na√Øve Bayes-1696854772448\"\u003e\u003c/p\u003e","title":"Na√Øve Bayes"},{"content":"NAT Network address translation Introduzione Col il NAT possiamo avere tutto lo spazio degli IP di cui abbiamo bisogno, che per√≤ non sono esposti. All\u0026rsquo;esterno vengono esposte solamente l‚ÄôIP del NAT.\nSchema classico NAT\nQuindi in breve\nAll\u0026rsquo;esterno √® esposto solamente l\u0026rsquo;indirizzo del router, il router, a seconda della porta giusta, d√† in risposta al computer giusto, quindi all\u0026rsquo;interno della nostra rete conosciamo tutti gli indirizzi IP giusti.\nAddr translation table üü© Sembra che ad ogni richiesta ci sia una table di transizione all\u0026rsquo;interno del router che matcha porta ‚Üí indirizzo locale corretto!.\nEsempio funzionamento üü© Slide\nUn client locale fa una richiesta esterna, viene inviato al router Il router salva la porta all‚ÄôIP interno e invia fuori Il server fuori ritorna la risposta alla porta corretta del router Il router manda questa risposta al client con l\u0026rsquo;indirizzo corrispondente a quella porta Controversie NAT (3) üü®+ Slide\nil router dovrebbero lavorare solamente sul livello 3 (IP), qui sta andando anche livello trasporto, per capire come mandare (infatti ha bisogno di un socket spiegato in Socket (!!!) üü©), dato che ha bisogno anche del livello di porta).\nL‚Äôobiettivo di avere pi√π indirizzi Ip non dovrebbe essere risolto con questa sorta di hack, dovrebbe essere risolto con IPv6 utilizzare il NAT sembra una specie di Hack.\nInoltre tutte le richieste devono passare da questo router e manipolate per poter accedere alla rete dietro il NAT, non abbiamo il pretesto per parlare di end-to-end. (il prof. parla di lato porcherie (dietro il nat) e il lato bello che √® il fuori, e il router sembra quasi l‚Äôambiente di cambio vestiti, in modo che tutti si possano comprendere, lol).\nUna cosa molto brutta √® fare NAT di NAT. Dall\u0026rsquo;altra parte i NAT sembrano un modo per isolare computer di cui non mi fido (che conoscono un falso IP proprio che non √® raggiungibile esternamente.).\n","permalink":"https://flecart.github.io/notes/network-address-translation/","summary":"\u003ch1 id=\"nat-network-address-translation\"\u003eNAT Network address translation\u003c/h1\u003e\n\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003cp\u003eCol il NAT possiamo avere tutto lo spazio degli IP di cui abbiamo bisogno, che per√≤ non sono esposti. All\u0026rsquo;esterno vengono esposte solamente l‚ÄôIP del NAT.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSchema classico NAT\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Network Address Translation/Untitled.png\" alt=\"image/universita/ex-notion/Network Address Translation/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eQuindi in breve\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAll\u0026rsquo;esterno √® esposto solamente l\u0026rsquo;indirizzo del router\u003c/strong\u003e, il router, a seconda della porta giusta, d√† in risposta al computer giusto, quindi all\u0026rsquo;interno della nostra rete conosciamo tutti gli indirizzi IP giusti.\u003c/p\u003e","title":"Network Address Translation"},{"content":"ve2\u0026gt; The synaptic connections that define such circuits are typically made in a dense tangle of dendrites, axons terminals, and glial cell processes that together constitute what is called neuropil.\nKnee-Jerk Response The knee-jerk reflex (also known as the patellar reflex) is a classic example of a mono-synaptic reflex arc, which involves a direct connection between sensory and motor neurons, as well as inhibitory circuits to regulate movement.\nNeural Circuit of the Knee-Jerk Reflex üü© The reflex involves the following components:\nSensory Neuron (Afferent Pathway) When the patellar tendon is tapped, muscle spindles in the quadriceps detect the sudden stretch. This activates Ia afferent fibers, which send an electrical signal to the spinal cord. Interneuron (Inhibitory Pathway) Within the spinal cord, the afferent neuron synapses onto an inhibitory interneuron. This interneuron, in turn, inhibits the motor neuron controlling the antagonist muscle (flexor muscle, e.g., hamstring) to prevent opposing contraction. Motor Neuron (Efferent Pathway to Extensor Muscle) The direct monosynaptic connection between the sensory neuron and the alpha motor neuron in the spinal cord leads to activation of the quadriceps muscle. This results in contraction of the extensor muscle (quadriceps), producing the characteristic leg kick. Motor Neuron (Efferent Pathway to Flexor Muscle - Inhibition) The inhibitory interneuron prevents contraction of the antagonist muscle (hamstring), ensuring smooth movement. This reflex demonstrates the fundamental organization of afferent (sensory) and efferent (motor) pathways, where information flows toward the central nervous system (CNS) via afferents and away from it via efferents.\nThe inhibitory interneuron releases neurotransmitters like GABA or glycine, which cause hyperpolarization of the flexor motor neuron.\nThis inhibits the hamstring contraction, allowing smooth knee extension. The hyperpolarization prevents unwanted co-contraction of opposing muscles. Recording Methods for Neural Activity üü® Neural activity can be recorded during reflex responses, including in clinical and surgical settings.\nThere are two primary methods:\nExtracellular Recording with Microelectrodes A glass microelectrode with a super-thin metal tip is used to measure the voltage difference between the inside and outside of a neuron. This is mainly used to record action potentials or field potentials from neurons. Intracellular Current Injection A current can be injected into the neuron to measure its passive properties (such as resistance and capacitance) and active properties (such as action potential threshold and firing patterns). Intracellular recordings can detect the smaller, graded potential changes that trigger action potentials, and thus allow a more detailed analy- sis of communication between neurons within a circuit.\nIn a similar way, we measure the myotatic circuits in the heart.\nThese techniques have also been applied in the human brain during surgery, such as in procedures for epilepsy treatment or deep brain stimulation, where patients can report their sensations in real time while neuronal activity is recorded.\nReceptive Fields üü©- The receptive field of a neuron refers to the specific region of the body (e.g., skin, retina) that, when stimulated, alters the neuron‚Äôs firing rate.\nFor example:\nIn the somatosensory system, a mechanoreceptor in the skin will fire when a specific area is touched. In the visual system, a retinal ganglion cell has a receptive field defined by a portion of the visual space. Key properties of receptive fields:\nSize and resolution: Smaller receptive fields (e.g., in fingertips) allow higher spatial resolution and finer touch discrimination. Excitatory and inhibitory zones: Many neurons have center-surround organization, where stimulation of the center excites the neuron, while stimulation of the surrounding area inhibits it. The single neuron electrophysiological recording is opposed to functional brain imaging.\nElectrical Signals in Neurons Neurons communicate through electrical signals that arise due to the movement of ions across the cell membrane. This is achieved through:\nTypes of potentials and signals Potentials üü® Receptor Potentials (input signals from sensory receptors) Synaptic Potentials (signals from other neurons) Action Potentials (output signals transmitted down the axon) \\[...\\] To compensate for this deficiency, neurons have evolved a ‚Äúbooster system‚Äù that allows them to conduct electrical signals over great distances despite their intrinsically poor electrical characteristics. he electrical signals produced by this booster system are called action potentials\nDepolarization and Hyperpolarization At rest, neurons are in a hyperpolarized state (negative membrane potential, typically around -70 mV). When a negative current is passed, the cell membrane just addapts passively and becomes a little bit less negative. When they receive input (e.g., touch, neurotransmitters), they become depolarized (more positive). If the depolarization reaches a threshold, called threshold potential, an action potential is triggered, and we see a spike. The number of spikes is related to the intensity of the action potential. Action Potential: A Rapid Electrical Signal An action potential is a rapid, transient change in membrane voltage that propagates along the axon. It is fundamental to neural communication and muscle contraction.\nAmplitude and frequency the amplitude of the action potential is independent of the magnitude of the current used to evoke it; that is, larger currents do not elicit larger action potentials. The action potentials of a givenneuron are therefore said to be all-or-none, because they occur fully or not at all\nthe intensity of a stimulus is encoded in the frequency of action potentials rather than in their amplitude. This arrangement differs dramatically from receptor potentials, whose amplitudes are graded in proportion to the magnitude of the sensory stimulus, or synaptic potentials, whose amplitude varies according to the number of synapses activated and the previous amount of synaptic activity.\nPhases of the Action Potential Rising Phase (Depolarization) Voltage-gated Na‚Å∫ channels open. Sodium influx makes the inside of the neuron more positive. Overshoot Phase Membrane potential becomes more positive than 0 mV. The inside of the neuron is now briefly positively charged compared to the outside. Falling Phase (Repolarization) Na‚Å∫ channels inactivate. Voltage-gated K‚Å∫ channels open, allowing potassium efflux, restoring a negative charge inside the neuron. Undershoot Phase (Hyperpolarization) K‚Å∫ channels remain open too long, making the neuron even more negative than the resting potential. The neuron is temporarily less likely to fire another action potential. The ReLU Activation Function The Rectified Linear Unit (ReLU) activation function used in artificial neural networks is loosely inspired by biological action potentials.\n$$ f(x)= \\max‚Å°(0,x)f(x) = \\max f(0, x) $$ Threshold-like behavior: Like a neuron, ReLU only activates when input exceeds zero, similar to how neurons fire only when a threshold potential is reached. No negative output: Biological neurons do not fire negatively; they either remain inactive (hyperpolarized) or fire a positive action potential. Computational efficiency: ReLU simplifies calculations, much like how neurons minimize energy use by firing only when necessary. However, real neurons exhibit more complex non-linearity, including:\nAdaptation (changes in firing patterns over time). Refractory periods (temporary inactivation after firing). Subthreshold activity (graded responses below threshold). Thus, while ReLU is inspired by neuroscience, it oversimplifies real neural dynamics.\nSodium and Potassium Channels Neurons communicate via electrical signals generated by the movement of ions across the cell membrane. These movements are mediated by two primary types of membrane proteins:\nIon Transporters vs. Ion Channels Ion Transporters (Active Transporters) Move ions against their concentration gradient using ATP. Example: Na‚Å∫/K‚Å∫ ATPase (Sodium-Potassium Pump), which pumps 3 Na‚Å∫ out and 2 K‚Å∫ in, maintaining a concentration gradient. Establish the chemical and electrical gradients necessary for neuron function. Ion Channels Allow ions to diffuse down their concentration gradient (passive transport). Highly selective for specific ions (e.g., K‚Å∫ channels, Na‚Å∫ channels). Can be voltage-gated (open/close based on membrane potential) or leak channels (always open). The osmotic gradient drives ions, but the membrane potential balances the flow. Chloride is used to hyperpolarize the cells.\nThe Hodgkin-Huxley Model Alan Hodgkin and Andrew Huxley pioneered the study of action potentials in neurons using electrophysiology.\nExperimental Breakthroughs They inserted electrodes into the axons of the giant squid (which has thick axons ~800 Œºm in diameter, ideal for measurements, hundreths of times larger compared to mammalian axons). They are larger for better conductivity, which helped them having faster reaction times. Measured how ion permeability changes over time during an action potential. Demonstrated that K‚Å∫ is the dominant ion at rest, while Na‚Å∫ permeability increases during an action potential, and returns with dominant K at rest (higher concentration in the cell than outside). Key Findings Ion Concentration Dependence They determined that the action potential depends on Na‚Å∫ and K‚Å∫ gradients, but not Cl‚Åª. Increasing external K‚Å∫ concentration disrupts the resting potential, making neurons more likely to fire spontaneously. Voltage-Dependent Ion Channels Na‚Å∫ channels open at depolarization (threshold level ~ -55 mV). K‚Å∫ channels open later and restore resting potential. Both channels show voltage-dependent gating: Na‚Å∫ channels open rapidly, allowing inward Na‚Å∫ current (depolarization). K‚Å∫ channels open slower, allowing outward K‚Å∫ current (repolarization). Logarithmic Graph of Potassium vs. Energy Level Hodgkin and Huxley plotted log K‚Å∫ vs. voltage, showing a predictable relationship (consistent with the Nernst equation). Mathematical Modeling of Action Potentials They wrote a set of differential equations describing ion channel kinetics. These equations successfully predicted experimental results, marking the beginning of computational neuroscience. The equations describe: Membrane capacitance (how the membrane stores charge). Ion conductance (how easily ions pass through). Time-dependent changes in channel permeability. Sodium Permeability and Action Potentials Action potentials depend on a higher concentration of Na‚Å∫ outside the cell. Hodgkin and Huxley confirmed that removing extracellular Na‚Å∫ eliminates action potentials. Cl‚Åª was shown to be unimportant for action potential generation. Nernst Equation $$ E_{K} = \\frac{RT}{zF} \\ln \\frac{[K^{+}]_{out}}{[K^{+}]_{in}} $$ Where $R$ is the gas constant, $T$ is the temperature, $z$ is the valence of the ion, $F$ is the Faraday constant, and $[K^{+}]_{out}$ and $[K^{+}]_{in}$ are the concentrations of $K^{+}$ outside and inside the cell, respectively. If we remove the constants and use log with base $10$ then the constant is $58$. 10 fold change in concentration is about 58 volts of difference. So at equilibrium (outflux equals influx) we have 58 voltages. Assuming valence $1$:\n$$ E_{ION} = \\frac{58}{z} \\log \\frac{[ION^{+}]_{out}}{[ION^{+}]_{in}} $$Examples of electrostatic equilibrium To reinforce and extend the concept of electrochemical equilibrium, con- sider some additional experiments on the influence of ionic species and ionic permeability that could be performed on the simple model system in Figure 2.4. What would happen to the electrical potential across the membrane (the potential of side 1 relative to side 2) if the potassium on side 2 were replaced with 10 mM sodium (Na+) and the K+ in compartment 1 were replaced by 1 mM Na+? No potential would be generated, because no Na+ could flow across the membrane (which was defined as being permeable only to K+). However, if under these ionic conditions (10 times more Na+ in compartment the K+-permeable membrane were to be magically replaced by a mem- brane permeable only to Na+, a potential of +58 mV would be measured at equilibrium. If 10 mM calcium (Ca2+) were present in compartment 2 and 1 mM Ca2+ in compartment 1, and a Ca2+-selective membrane separated the two sides, what would happen to the membrane potential? A potential of +29 mV would develop, because the valence of calcium is +2. Finally, what would happen to the membrane potential if 10 mM Cl‚Äì were present in com- partment 1 and 1 mM Cl‚Äì were present in compartment 2, with the two sides separated by a Cl‚Äì-permeable membrane? Because the valence of this anion is ‚Äì1, the potential would again be +58 mV.\nEquivalent circuit model of a membrane patch If the entire surface of an axon were insulated, there would be no place for current to flow out of the axon and action potentials could not be generated.\n$$ I(t) = \\frac{u(t) - u_{\\text{rest}}}{R} + C \\frac{du(t)}{dt} $$$$ u(t) = u_{\\text{rest}} + \\Delta u \\exp\\left( - \\frac{t - t_{0}}{\\tau_{m}} \\right) $$ Which is called the free solution, useful to model passive membrane models.\nGenerating an Action Potential We can revise this model by adding parallel sections for $K$, $Na$ ions and leaked current. The current in the axon is a self-regenerating current trace, that allows to propagate it over long distances.\nNodes of Ranvier Nodes of Ranvier are gaps in the myelin sheath along the axon. It takes from the name of the discoverer of these nodes. Myelinated sections make the current flow 150x times faster compared to non Myelinated sections. It is believed that myelinated section originated from a virus that joined the cell, and now they are in symbiosys.\nThey have a lower threshold for triggering an action potential. The distance between each section is about 1.5mm. The voltage decay is lower in insulated versions, because the current is not lost to the environment (higher resistivity of the membrane thanks to the fatty part). The myelination makes thin nerve fibers even faster than big squid axons! But they are quite expensive to maintain and build.t\n","permalink":"https://flecart.github.io/notes/neural-mechanisms/","summary":"\u003cp\u003eve2\u0026gt; The synaptic connections that define such circuits are typically made in a dense tangle of dendrites, axons terminals, and glial cell processes that together constitute what is called neuropil.\u003c/p\u003e\n\u003ch3 id=\"knee-jerk-response\"\u003eKnee-Jerk Response\u003c/h3\u003e\n\u003cp\u003e\u003cimg alt=\"Image from Purves\" loading=\"lazy\" src=\"/notes/neural-mechanisms-20250217161536263.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eThe \u003cstrong\u003eknee-jerk reflex\u003c/strong\u003e (also known as the \u003cstrong\u003epatellar reflex\u003c/strong\u003e) is a classic example of a \u003cstrong\u003emono-synaptic reflex arc\u003c/strong\u003e, which involves a direct connection between sensory and motor neurons, as well as inhibitory circuits to regulate movement.\u003c/p\u003e","title":"Neural mechanisms"},{"content":"Introduction: a neuron I am lazy, so I\u0026rsquo;m skipping the introduction for this set of notes. Look at Andrew Ng\u0026rsquo;s Coursera course for this part. Historical notes are (Rosenblatt 1958). One can view a perceptron to be a Log Linear Models with the temperature of the softmax that goes to 0 (so that it is an argmax). Trained with a stochastic gradient descent with a batch of 1 (this is called the perceptron update rule).\nStructure A single layer of a function can be written in the following way:\n$$ F(\\theta)(x) = \\phi(Wx + b) $$ Which can be summarized by: linear part + activation function. Where $F(\\theta)$ is a partial function that returns another function, $\\theta = (W, b)$ a vector, this is just a way to separate the bias with the parameters. The $\\phi$ is the non linearity, that is needed for the universal approximation function.\nCompositionality The main idea in going deep is extract features of increasing complexity, it\u0026rsquo;s like attempting to give it more computation so that it is possible to extract more interesting parts. We can mathematically view deep networks in the following way:\n$$ x = F^{(l)} F^{(l - 1)} \\dots F^{(0)}(x_{0}) $$ And a composition of layers!\nModularity We can compose parts of the network together! For example residual networks are a clear example, or the inception network.\nTraining network tricks Activation functions Solitamente le funzioni classiche per i network neurali sono sigmoid, tanh, e ReLU. La cosa brutta delle prime due √® vanishing gradient, perch√© se il valore √® molto grosso o molto piccolo, la derivata √® molto vicino allo 0, quindi √® molto difficile aggiornare.\nThe activation function is presented as $\\phi$ before. One thing to note is that this non-linearity doesn\u0026rsquo;t mix the dimensions together. Let me explain clearly with some maths:\nWe say that $\\phi: \\mathbb{R}^{n} \\to \\mathbb{R}^{n}$ and it\u0026rsquo;s a composition of some $\\bar{\\phi}: \\mathbb{R} \\to \\mathbb{R}$ which are just applied independently to every dimension.\nOther properties are:\nIncreasing Continuous There are important to remember from a mathematical point of view. Level Sets $$ L_{f}(z) = \\left\\{ x : \\phi(w\\cdot x + \\beta) = z \\right\\} \\perp w $$ These are also called generalized linear models, or ridge functions.\nReLU activation $$ f(x) = \\begin{cases} 0,\\, \\text{ if } x \u003c 0 \\\\ x, \\, \\text{ if } x \\geq 0 \\end{cases} $$The important thing to notice is that when it backpropagates, it just activates or kills the signal, allowing the gradient to flow naturally, and not vanish.\n$$ \\frac{ \\partial x^{(k+1)} }{ \\partial x^{(k)} } = \\sigma'(W^{(k)}x^{(k)} + b) W^{(k)} $$ And $\\sigma'$ in the case of the ReLU is just 0 or 1, which aids toward the problem of vanishing gradient and similars. The thing to note is that this doesn\u0026rsquo;t exactly work as an activation function if the input depends on $x$ with more than one parameter\nHyperbolic tangent This activation is usually preferred to the Sigmoid, better treated in Logistic Regression, because it has sign symmetry.\nInput normalization In un certo senso in questo modo abbiamo un p√≤ di tati che sono Normali gaussiani. Non ho capito ancora perch√© normale gaussiana sia una tipologia di dati che ci piace cos√¨ tanto. (il motivo che viene dato in lezione √® che Gradient Descent si comporta molto meglio per loss function che sono gaussiane, perch√© la direzione di discesa √® sempre quella, e non deve zigzagare).\nWeight initialization Ci sono moltissimi modi per inizializzare i Weights, in modo che si eviti il problema di vanishing or exploding gradients. L‚Äôidea √® comunque tenere i valori vicini a 1 per evitare che esplodino, e inversamente proporzionali a n o funzioni di n, perch√© se n √® molto grosso potrebbe esplodere lo stesso.\nAlcune inizializzazioni famose sono\nXavier He (qualcosa che funziona per Sigmoid, (alcune funzionano a seconda dell‚Äôactivation function giusta) C‚Äô√® ne sono molte, non so se conviene lavorare sulla inizializzazione, non credo sia comunque buona spesa del tempo a capire queste.\nOptimization Momentum, praticamente un gradient descent che tiene conto delle computazioni passate, e calcola la direzione anche secondo quelle (quindi se vado su e gi√π e a destra sempre nelle iterazioni passate, andr√≤ a destra pi√π spesso diciamo, questa √® l‚Äôintuizione per questa idea).\nUna cosa molto strana √® che il training delle NN √® molto stabile. Cio√® vari un p√≤ l‚Äôinput e non varia molto l‚Äôouput!\nPossibili motivi:\nWeights Loss function Internal redundancy? cio√® ho troppi parametri e questo lo rende bello.(teoria del prof) Loss functions $$ \\mathcal{l}(y, \\hat{y}) = \\frac{1}{2} \\lVert y - \\hat{y} \\rVert ^{2} $$$$ l(\\theta)(x, y) = l(y, F(\\theta)(x)) $$Sometimes you need to tailor the loss function to the problem you are trying to solve! For example a very famous function is the Softmax Function, for multiclass classification. In the case you just have two classes then it\u0026rsquo;s the logistic function.\n$$ l(y, \\hat{p}) = - \\log \\hat{p}_{y} $$ If we view this from an information theoretical point of view, then it\u0026rsquo;s the expected length of our codeword.\nRisks After we have the loss we can go on and define the empirical risk, which is just:\n$$ \\mathcal{R}(\\theta; \\mathcal{S}) := \\mathbb{E}_{\\mathcal{S}} [\\ell(\\theta)] := \\frac{1}{s} \\sum_{i = 1}^{s} \\ell(\\theta)(x_{i}, y_{i}) = \\frac{1}{s} \\sum_{i = 1}^{s} \\ell(y_{i}, F(\\theta)(x_{i})) $$This is the training risk, and same thing could be defined for the test risk.\nOverfitting Slide ways to reduce overfitting, we have 7 it seems\nSometimes overfitting is weird for neural networks, because even if we have it, it seems that training a lot more doesn\u0026rsquo;t produce overfitting.\nOverfitting √® il drago del training classico del machine learning, molto simile a dire che la macchina sta allucinando alcuni pattern causati probabilmente dalla varianza dei dati, o anche dal fatto che alcuni casi positivi sono pochi‚Ä¶\n√à comunque una cosa troppo specifica, perch√© significa che la macchina stia quasi imparando a memoria i casi, dovrebbe provare a generalizzare, per farlo deve scordare dettagli non interessanti (che con overfitting pu√≤ imparare) e imparare le cose importanti. Per√≤ i computer sono troppo bravi a memorizzare dettagli, a differenza di umani.\nDropout Idea del dropout\nL‚Äôidea √® il fatto che il network deve risolvere il problema, anche se √® un p√≤ rotto, questo cerca di renderlo pi√π robusto, e sembra funzionare molto bene.\nKullback-Leibler Divergence We want to measure the distance between two distributions, usually from a real distribution and the one we are predicting. Vedere Entropy#Relative Entropy or Kullback-Leibler\n√à una cosa che proviene dalla teoria dell‚Äôinformazione.\nPer capire questo, √® molto importante andare a capire cosa sia la cross-entropy e questo √® un modo abbastanza naturale per capire quanto vicino √® una distribuzione, solitamente predetta, con quella del training data, si pu√≤ comparare molto con log-likelihood loss function, si potrebbe dire che sia un caso particolare la log likelihood.\nReferences [1] Rosenblatt ‚ÄúThe Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain.‚Äù 1958\n","permalink":"https://flecart.github.io/notes/neural-networks/","summary":"\u003ch2 id=\"introduction-a-neuron\"\u003eIntroduction: a neuron\u003c/h2\u003e\n\u003cp\u003eI am lazy, so I\u0026rsquo;m skipping the introduction for this set of notes. Look at Andrew Ng\u0026rsquo;s Coursera course for this part. Historical notes are \u003ca href=\"https://psycnet.apa.org/record/1959-09865-001\"\u003e(Rosenblatt 1958)\u003c/a\u003e.\nOne can view a perceptron to be a \u003ca href=\"/notes/log-linear-models/\"\u003eLog Linear Models\u003c/a\u003e with the temperature of the softmax that goes to 0 (so that it is an argmax).\nTrained with a stochastic gradient descent with a batch of 1 (this is called the perceptron update rule).\u003c/p\u003e","title":"Neural Networks"},{"content":"I Nomi e oggetti Oggetti denotati e identificatoriüü© I nomi sono sequenze di caratteri o numeri aka: token alfanumerico (anche IDENTIFICATORE (per token guardare Grammatiche Regolari) utilizzate principalmente come Astrazione sul controllo e sui dati (quindi sono cose molto pi√π facili da ricordare rispetto il suo encoding binario o a indirizzi). Infatti utilizziamo i nomi per evitare di interessarci di informazioni come l‚Äôindirizzo di memoria del nostro dato o per creare una interfaccia con visibili solo nome della procedura e parametri.\nI nomi quindi possono essere utilizzati per cose come\nElementi definiti al momento di progettazione del linguaggio: Costanti predefinite operazioni primitive (+, * etc) Tipi di dato primitivi Elementi definiti da utenti Variabili Parametri Indirizzi di memoria. Procedure (le funzioni) Costanti dell‚Äôutente tipi dell‚Äôutente Bindings (4) üü©- Il binding √® proprio il collegamento che si ha fra il nome e l‚Äôoggetto che viene denotato da essa.\nQuesto binding √® creato in 4 momenti diversi:\nProgettazione del linguaggio In questa fase possono venire definite le cose come elencate sopra Struttura del programma In questa parte viene solamente iniziato il collegamento fra identificatore e variabile identificata (e.s. se identifica una zona di memoria non allocata, non √® ancora completato il binding), per questo motivo possiamo dire che √® iniziato il binding delle variabili definite dall‚Äôutente ma non √® stata completata. In fase di compilazione Per esempio in questa fase vengono allocate le variabili statiche (e.g. quelle globali su C/C++), quindi certe variabili effettivamente hanno finito di bindare in questa fase A runtime Per esempio nelle allocazioni dinamiche, oppure allocazione su stack (che comunque √® runtime), un identificatore come un indirizzo ha finito il binding con l‚Äôoggetto denotato solamente in questo momento. Importante a questo punto √® stabilire il concetto di statico vs dinamico.\nNell‚Äôesempio di sopra i primi 3 punti sono parte del binding statico, mentre il quarto √® dinamico. Questo perch√© statico si intendono tutte le associazioni fatte dal compilatore prima dell‚Äôesecuzione del programma, mentre dinamico √® solitamente fatto dalla macchina astratta al momento dell‚Äôesecuzione\nLifetime üü© Bisogna in questa fase fare una distinzione della vita dell‚Äôassociazione e vita dell‚Äôoggetto denotato.\nIn certi casi si pu√≤ avere che la vita dell‚Äôassociazione √® minore di quella dell‚Äôoggetto denotato, questo pu√≤ succedere per esempio quando l‚Äôassociazione √® cambiata (quindi distrutta e ricreata in altro modo), anche un cambio di ambiente (e quindi di blocco pu√≤ avere lo stesso effetto). (oppure un oggetto passato per riferimento nella chiamata di funzione, la vita del binding all‚Äôinterno della funzione resta quella)\nIn altri casi pu√≤ succedere che la vita dell‚Äôoggetto denotato sia minore dell‚Äôassociazione, questo pu√≤ capitare per esempio quando un oggetto allocato dinamicamente sia stato liberato, mentre l‚Äôassociazione non lo sia, si parla in questo caso di dangling reference.\nAmbiente √à l‚Äôinsieme di associazioni fra identificatori e oggetti denotati in un certo momento dell‚Äôesecuzione a uno specifico punto.\nIn certi punti di esecuzione del programma pu√≤ succedere che uno stesso oggetto √® denotato da pi√π nomi, in questo caso si dice che i nomi sono degli alias fra di loro.\nTipologie di ambiente (3) üü© Facciamo distinzione fra tre tipologie principali di ambiente:\nLocale (quelli creati dal blocco corrente) Non Locale (quelli creati da blocchi superiori (quindi quelli che non sono dichiarati localmente in pratica). Globale (quelli creati nel blocco pi√π sopra possibile, solitamente all‚Äôinizio del nostro programma) Blocco pi√π esterno Codice importato Operazioni sull\u0026rsquo;ambiente (5) üü© Dato che l‚Äôambiente √® l‚Äôinsieme di associazioni, questo sono anche operazioni sui nomi.\nNaming Quando proprio viene creato un nuovo collegamento con un oggetto. (aka dichiarazione). Unnaming Quando il collegamento viene distrutto Referencing Quando viene utilizzato un nome per accedere a un oggetto (quindi nessuna creazione qui). Attivazione binding Quando il collegamento con un oggetto viene ricreato Disattivazione binding Operazioni sugli oggetti (4) üü© Queste operazioni sembrano le classiche che si fanno per i databases:\nAccesso (sola lettura dell‚Äôoggetto) Modifica (scrittura sull‚Äôoggetto) Creazione Eliminazione dell‚Äôoggetto. Da notare la similitudine con il framework CRUD citato in HTTP e REST\nBlocchi Definizione üü® Un blocco testuale di codice, in cui sono dichiarate localmente delle variabili, che ha un inizio e una fine chiara.\nIn generale si fanno distinzione fra\nBlocchi procedurali (come le funzioni in pratica) Blocchi anonimi (sono blocchi in line che si possono mettere in qualunque posto del codice). Per√≤ a volte √® meglio creare delle regole specifiche del linguaggio che dipendano dal creatore del linguaggio. non vorremmo ad esempio poter utilizzare la variabile prima che fosse dichiarata. (ma dipende dalla pragmatica del linguaggio (oppure sintattica, dipende comunque da come √® stato progettato questo linguaggio)).\ne.g.\n{ a = 1; int a; } Questo per molti linguaggi dovrebbe essere un errore, di semantica statica! ma a seconda delle regole sintattiche potrebbe essere corretto (potrebbe essere una a esterna, se esiste).\nUn discorso simile si pu√≤ fare per le funzioni, che possono essere visibili o meno prima della dichiarazione o meno. Ma non credo questi dettagli siano troppo importanti, dopo un p√≤ capisci dai‚Ä¶\nAnnidamento üü© L‚Äôannidamento dei blocchi deve soddisfare alcune caratteristiche, per esempio non possono esistere delle intersezioni parziali fra blocchi quindi che siano tipo ABAB (con primo A l‚Äôinizio del blocco, e secondo A la fine). In un certo senso la stringa che deve esserci deve essere palindroma.\nVisibilit√† üü© Una dichiarazione locale ad un blocco √® visibile in quel blocco e in tutti i blocchi in esso annidati, a meno che non intervenga in tali blocchi una nuova dichiarazione dello stesso nome (che nasconde, o maschera, la precedente)\nQuesto principio di visibilit√† pu√≤ essere espresso in maniere differenti, ecco cos√¨ che si creano lo scoping statico e dinamico.\nRegola di Scope La regola di visibilit√† non √® definita in modo disambiguato, pu√≤ essere interpretato in modo differente:\nEsempio\nA seconda di una interpretazione di Scoping, che √® anche detta regola di visibilit√† che √® qulel enunciata poco sopra, stampa risultati diversi. In questa parte proviamo a fare pi√π chiarezza riguardo questo aspetto qui.\nPer capire bene questa parte sullo scope sarebbe meglio andare a guardare come di solito √® implementato, questo √® spiegato in Gestione della memoria\nStatico (3) üü© 3 Regole descrivono bene lo scoping statico\nL‚Äôambiente locale ha solamente in s√© le dichiarazioni locali del blocco (direi che √® una convenzione, poi col punto 2 ha pi√π senso questo mini algo, che vai a cercarti te). Se non viene trovato va a cercare nel blocco sopra, fino ad arrivare allo scope globale, se ancora qui non c‚Äô√® allora vado nelle built-in, se nemmeno qui c‚Äô√® allora errore (algoritmo stupido per fare la ricerca dell‚Äôassociazione). Per i blocchi con nome, il nome √® anche presente nello scope sopra (cos√¨ posso fare la ricorsione) Da notare che nello scoping statico quello che importa √® la struttura del nostro programma. Questo ci da alcuni vantaggi:\nFacile comprensione (perch√© non dobbiamo eseguire, basta leggere il programma, capire la struttura e sappiamo il binding corretto) Velocit√† (il compilatore si pu√≤ tenere degli offset per capire quale √® la variabile corretta a cui accedere). Per√≤ per tenersi lo scoping statico √® leggermente pi√π difficile perch√© non basta una stack, come invece √® per lo scope dinamico.\nDinamico üü© Lo scope dinamico √® molto pi√π semplice da implementare rispetto lo scope statico, √® guidato da questa unica regola.\nL‚Äôoggetto a cui si riferisce un nome X √® quella dichiarata pi√π recentemente a run-time, a patto che l‚Äôassociazione sia ancora attiva.\nQuindi se ci teniamo una stack di blocchi attivi (che poi vengono poppati, l‚Äôultima ad essere poppata √® il blocco globale, quello principale) √® molto facile seguire il percorso creazione di tutte le variabili per un blocco, e distruzione quando si esce dal blocco.\nSolitamente lo scope dinamico non viene mai utilizzato. (pi√π lento e meno leggibile, bisognerebbe sempre leggere).\nRidefinizione di variabili globali per funzioni, questo si potrebbe considerare una possibilit√† dello scope dinamico di gestire input per variabili globali:\nEsempio in slide\nIl modo corretto per fare questa cosa √® dichiarare la funzione in modo che accetti come parametro un altro colore.\n","permalink":"https://flecart.github.io/notes/nomi-e-scope/","summary":"\u003ch2 id=\"i-nomi-e-oggetti\"\u003eI Nomi e oggetti\u003c/h2\u003e\n\u003ch3 id=\"oggetti-denotati-e-identificatori\"\u003eOggetti denotati e identificatoriüü©\u003c/h3\u003e\n\u003cp\u003eI nomi sono sequenze di caratteri o numeri aka: \u003cstrong\u003etoken alfanumerico\u003c/strong\u003e (anche \u003cstrong\u003eIDENTIFICATORE\u003c/strong\u003e (per token guardare \u003ca href=\"/notes/grammatiche-regolari/\"\u003eGrammatiche Regolari\u003c/a\u003e) utilizzate principalmente come \u003cstrong\u003eAstrazione sul controllo e sui dati\u003c/strong\u003e (quindi sono cose molto pi√π facili da ricordare rispetto il suo encoding binario o a indirizzi). Infatti utilizziamo i nomi per evitare di interessarci di informazioni come l‚Äôindirizzo di memoria del nostro dato o per creare una interfaccia con visibili solo nome della procedura e parametri.\u003c/p\u003e","title":"Nomi e Scope"},{"content":"Introduzione alla normalizzazione Perch√© si normalizza? üü© Cercare di aumentare la qualit√† del nostro database, perch√© praticamente andiamo a risolvere delle anomalie possibili al nostro interno, e questo aiuta per la qualit√†. Solitamente queste anomalie sono interessanti per sistemi write intensive, in cui vogliamo mantenere i nostri dati in una forma buona. Per√≤ capita non raramente che vogliamo solamente leggere. In quei casi sistemi come Cloud Storage, Distributed file systems potrebbero risultare pi√π effettivi.\nTipologie di anomalie üü© Ridondanze, non vorrei avere la stessa informazione espressa pi√π volte in troppi punti. Update non consistente, quando per aggiornare un singolo valore devo aggiornare moltissime altre tuple dipendenti da essa. Deletion non consistente, la presenza di certe entit√† √® strettamente dipendente da presenza di altri, nell\u0026rsquo;esempio in questione sulle slides, se elimino tutti gli utenti, elimino anche i progetti su cui hanno partecipato, mentre invece dovrebbero essere separati. Insertion, ad esempio se non posso inserire un certa entry finch√© una altra propriet√† legata (ma per il resto indipendente non √® stata definita, nell\u0026rsquo;esempio del prof provare ad inserire un lavoratore, ma senza progetto.) Ci possono essere molte forme di non-normalizzazione per i database. La figura seguente riassume il concetto (preso da qui). Forme di integrit√† üü© Integrit√† atomica: ogni cella deve avere un singolo valore, non pu√≤ avere delle tavole innestate e non ci devono essere righe ripetute (ridondanze). Integrit√† di dominio: ogni valore della cella deve possedere valori che appartengono al dominio della colonna. Integrit√† relazionale: Foreign key values must either be NULL or match an existing value in the referenced table‚Äôs primary key. Dipendenze funzionali Vogliamo cercare di identificare le dipendenze funzionali e separarle, questo aiuta a creare qualit√† nel database La dipendenza funzionale √® un vincolo di integrit√† speciale, simile a quello relazionale spiegato in Relational Model\nDefinizione formale di dipendenza funzionale üü© Data una relazione $r$ sullo schema $R(X)$ due sottoinsiemi non vuoti di attributi $Y$ e $Z$ sono detti funzionalmente dipendenti per ogni coppia di tuple $t_{1}$ e $t_{2}$ in $r$ con stessi valori per tutti gli attributi in $Y$ abbiamo che questi hanno gli stessi valori anche su $Z$.\nOsservazioni:\nFunzione, perch√© in un certo senso il primo insieme √® il dominio, e il secondo √® il codominio, ed √® come se ci fosse una funzione che li associ. Esistono dipendenze funzionali banali quelli il cui il secondo insieme di attributi √® un sottoinsieme del primo. Dipendenza funzionale con chiave essendo unica, non abbiamo duplicati di chiave, quindi l\u0026rsquo;implica implicito nella definizione ha sempre l\u0026rsquo;ipotesi falsa, quindi √® sempre vero (guarda logica per capire il senso della mia frase). Livelli di normalizzazione Definizione formale Boyce e Codd (!) üü©\u0026ndash; Una relazione $r$\tsi dice in forma normale di Boyce e Codd se per ogni dipendenza funzionale non banale $X \\to A$ definita sulla relazione, $X$ contiene una chiave $K$ di $r$, cio√® $X$ √® una super-chiave di $r$\nQuesta il professor Ghislayn lo chiama anche forma normale 3.5 Ossia vogliamo solamente dipendenza funzionali tramite chiavi, e non in altro modo, altrimenti probabilmente avr√≤ una ripetizione. Per esempio, con questa forma normale non sono accettate parti di chiavi che dipendono da altre chiavi, mentre con la terza forma normale questo era tollerato.\nL\u0026rsquo;idea principale √® che una tavola fa una singola cosa e niente altro.\nPrima forma normale üü© Questo √® la stessa cosa delle integrit√† atomica.\nSeconda forma normale üü© Possiede la prima forma normale e deve essere che ogni colonna non chiave deve essere dipendente dall\u0026rsquo;intera chiave, e non una sotto parte. Altrimenti possiamo andare a denormalizzare.\nDefinizione terza forma normale üü©\u0026ndash; √à una forma leggermente pi√π rilassata, utile per normalizzare anche quando BC non √® possibile fare.\nUna relazione $r$ √® in terza forma normale se per ogni dipendenza funzionale $X \\to Y$ non banale vengono verificate una delle due condizioni:\n$X$ ha una chiave di $r$ Ogni attributo di $Y$ appartiene ad almeno una chiave di $r$ Il primo dovrebbe corrispondere a Boyce Codd. Il secondo credo sia nuovo, possiamo dire quindi che sia una estensione, che permette la definizione di normalizzazione essere applicata a pi√π cose. Questa decomposizione √® sempre possibile, abbiamo un teorema che lo dice.\nIntuitivamente, possiamo dire che √® in terza forma normale se √® in seconda e non ci sono dipendenze funzionali fra le non chiavi stesse, altrimenti possiamo scomporre ancora.\nLa pagina Wikipedia asserisce questo requisito:\ntutti gli attributi non-chiave dipendono soltanto dalla chiave, ovvero non esistono dipendenze funzionali tra attributi non-chiave.\nChe √® molto pi√π semplice da ricordare, e in un certo senso simile a Boyce-Codd.\nNel contesto di NoSQL NoSQL va a rilassare questi constraints, per questo motivo abbiamo\nData eterogeneo (no tabulare) Nested data (no prima forma normale) Data denomalizzato (non abbiamo boyce Codd o altra forma normalizzata) not having to join brings a significant performance improvement in reads\nQuesto √® uno dei motivi per cui i dati sono solitamente non normalizzati nei big data attuali. Metodi di normalizzazione Decomposizione senza perdita üü© Sia dato un insieme di attributi $X$ e una decomposizione, non partizione, in $X_{1}$ e $X_{2}$, abbiamo che la relazione $r$ si decompone senza perdita su $X_{1}$ e $X_{2}$ quando la join delle due √® uguale a $r$. ossia: $\\pi_{X_{1}}(r) \\bowtie \\pi_{X_{2}}(r) = r$\nQuesta √® una necessit√† per ricostruire le informazioni iniziali senza nessuna perdita. Si pu√≤ notare che talvolta seguendo in modo cielo le dipendenze funzionali che si possono trovare seguendo una via di Boyce and Codd, non √® sufficiente per mantenere questa propriet√† tanto importante.\nPrendiamo un esempio con perdita (perch√© vado a ricostruire un esempio con pi√π informazioni): Questa non √® una cosa che vogliamo!\nUn modo per risolvere questo √® aggiungere degli attributi fittizi che ci aiutano a discriminare sulle cose che ci servono. Ci fanno da specie di chiave.\nConservazione delle dipendenze üü© Questo permette di mantenere i vincoli di integrit√†.\nUna decomposizione preserva la dipendenza se ogni dipendenza funzionale dello schema originale ha attributi che compaiono nello stesso schema, altrimenti non √® possibile rilevare le dipendenze funzionali (Atzeni, pagina 332)\nCio√® se spezzo una dipendenza funzionale in tavole diverse, questa propriet√† non viene soddisfatta, perch√© non sarei pi√π in grado di trackarlo.\nPrendiamo un esempio in cui questa caratteristica si dimostra utile\nNormalizzazione nello schema concettuale üü®\u0026ndash; Possiamo utilizzare questa idea anche nella parte di sviluppo di schemi E-R. Se riconosco a questo livello che c\u0026rsquo;√® una dipendenza funzionale, questo mi da indicazioni su come continuare lo sviluppo di questo. Nell\u0026rsquo;esempio sulle slides motiva un partizionamento verticale, vedi Database logical design.\n","permalink":"https://flecart.github.io/notes/normalizzazione-dei-database/","summary":"\u003ch3 id=\"introduzione-alla-normalizzazione\"\u003eIntroduzione alla normalizzazione\u003c/h3\u003e\n\u003ch4 id=\"perch√©-si-normalizza-\"\u003ePerch√© si normalizza? üü©\u003c/h4\u003e\n\u003cp\u003eCercare di aumentare la qualit√† del nostro database, perch√© praticamente andiamo a risolvere delle anomalie possibili al nostro interno, e questo aiuta per la qualit√†.\nSolitamente queste anomalie sono interessanti per sistemi write intensive, in cui vogliamo mantenere i nostri dati in una forma buona. Per√≤ capita non raramente che vogliamo solamente leggere. In quei casi sistemi come \u003ca href=\"/notes/cloud-storage/\"\u003eCloud Storage\u003c/a\u003e, \u003ca href=\"/notes/distributed-file-systems/\"\u003eDistributed file systems\u003c/a\u003e potrebbero risultare pi√π effettivi.\u003c/p\u003e","title":"Normalizzazione dei database"},{"content":"Errore inerente Bisogna cercare di generalizzare il concetto di errore e lo si fa con la norma\nNorma vettoriale √à una funzione da $f: \\mathbb{R}^n \\to \\mathbb{R}$ indicata con due barrette, questa funzione mi d√† un concetto di distanza.\nPropriet√† della norma Si definisce una norma una funzione che soddisfa queste propriet√†\n$\\lVert x \\rVert \\geq 0$ per ogni $x \\in \\mathbb{R}^{n}$ $\\lVert x \\rVert = 0 \\iff x = 0$ $\\lVert \\alpha x \\rVert = \\lvert \\alpha \\rvert \\lVert x \\rVert$ per ogni $x \\in \\mathbb{R}^{n}$ e $\\alpha \\in \\mathbb{R}$ Vale la disuguaglianza triangolare, ossia $\\forall x, y \\in \\mathbb{R}^{n}, \\lVert x + y \\rVert \\leq \\lVert x \\rVert + \\lVert y \\rVert$. Convessit√† Analizzato meglio in Analisi di Convessit√†. Si pu√≤ dimostrare tramite la propriet√† 3 e 4 che la norma √® una funzione convessa. Infatti sia $f$ la funzione che soddisfa le propriet√† della norma (quindi effettivamente si pu√≤ chiamare norma). Allora:\n$$ f(\\theta x + (1 - \\theta)y) \\leq f(\\theta x) + f((1 - \\theta)y) = \\theta f(x) + (1 - \\theta)f(x) $$ Che finisce la dimostrazione.\nNorma püü©- $$ (\\sum_{i = 1}^{n}|x_i|^p)^{1/p} $$Nel caso in cui $p = 2$ si chiama norma euclidea o viva\nNel caso $p = 1$ √® la distanza di manhattan\nNorma di chebichevüü® quando ho $p = +\\infty$ √® definita come $\\max_{1\\leq i \\leq n} |x_i|$ e si indica con $||x||_\\infty$\nEquivalenza fra le normeüü© Questo √® un teorema che ci permette di asserire che pi√π o meno tutte le norme hanno la stessa propriet√† di definire il concetto di distanza fra due punti poich√©\nSiano $||\\cdot||, ||\\cdot||_x$ due norme differenti, allora $\\exists m, M : m ||\\cdot|| \\leq || \\cdot || _x \\leq M||\\cdot ||$, ma questo vale solo se siamo in un campo finito.\nNorma matriciale Propriet√†üü© Vogliamo riprendere tutte le propriet√† descritte per la norma vettoriale, in pi√π vogliamo andare ad aggiungere un quinto punto ossia\nNorma naturale (o indotte) üü©- $$ ||A|| = \\sup_{x \\neq 0} \\dfrac{||Ax||}{||x||} = ||Ay||, y = \\dfrac{x}{||x||} $$Considero solamente le righe, come se compattassi tutte le colonne in una\n$$ ||A||_\\infty = \\max_{1 \\leq i \\leq m} \\sum_{j = 1}^n|a_{ij}| $$La norma-1 indotta √® molto simile, solo che ora compatto sulle colonne\n$$ ||A||_1 = \\max_{j} \\sum_{i = 1}^n|a_{ij}| $$Norma 2, o norma spettrale:\n$$ ||A||_2 = \\sqrt{\\Lambda(A^TA)} $$Con $A^TA$ simmetrica e semidefinita positiva. con $\\Lambda$ gli autovalori di $A^TA$ Se $A$ ha rango massimo allora √® definita positiva, che √® il rango qui? Le norme dell‚Äôidentit√† in tutte queste cose indotte √® 1\nNorma di frobenius $$ ||A||_ F = \\sqrt{\\sum_{i = 1}^m \\sum_{j = 1}^n a^2_{ij}} $$$||I||_F = \\sqrt{n}$\nSlide relazione fra le norme matriciali\nCondizionamento Vogliamo andare a definire il concetto di condizionamento per il sistema lineare.\nOssia vorremmo valutare quanto un piccolo cambiamento della matrice influisca sul risultato finale.\nChiamiamo come errore inerente la distanza fra il risultato vero e il risultato perturbato. Questo errore dipende fortemente da una natura dei dati in input (che sono mal condizionati)\nMal condizionamento üü© si verifica quando a piccoli cambi della matrice di partenza, si ha un grande errore nel risultato (potremmo dire ordini di grandezza diversi, solitamente questo √® una cosa che non vorremmo che ci fosse)\nE la differenza fra i risultati √® un errore inerente, che dipende dai dati, ma non dall\u0026rsquo;algoritmo\nPerturbazione e n-condizionamento üü© Vogliamo ora vedere quanto siano grandi gli effetti di una perturbazione su una matrice. si pu√≤ dimostrare che\n$$ \\dfrac{||\\Delta x||}{||x||} \\leq k(A) \\dfrac{||\\Delta A|| }{||A||} $$Con $k(A)$ il numero di condizione della matrice, solamente pi√π √® grande pi√π l\u0026rsquo;errore viene amplificato., se questo valore √® sempre maggiore o uguale a 1 √® non singolare.\n$$ k(A) = ||A||\\cdot||A^{-1}|| \\geq ||AA^{-1}|| = ||I|| = 1 $$ Slide ricavo relazioni condizionamento\n","permalink":"https://flecart.github.io/notes/norme-e-condizionamento/","summary":"\u003ch1 id=\"errore-inerente\"\u003eErrore inerente\u003c/h1\u003e\n\u003cp\u003eBisogna cercare di generalizzare il concetto di errore e lo si fa con la norma\u003c/p\u003e\n\u003ch2 id=\"norma-vettoriale\"\u003eNorma vettoriale\u003c/h2\u003e\n\u003cp\u003e√à una funzione da $f: \\mathbb{R}^n \\to \\mathbb{R}$ indicata con due barrette, questa funzione mi d√† un concetto di distanza.\u003c/p\u003e\n\u003ch3 id=\"propriet√†-della-norma\"\u003ePropriet√† della norma\u003c/h3\u003e\n\u003cp\u003eSi definisce una norma una funzione che soddisfa queste propriet√†\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e$\\lVert x \\rVert \\geq 0$ per ogni $x \\in \\mathbb{R}^{n}$\u003c/li\u003e\n\u003cli\u003e$\\lVert x \\rVert = 0 \\iff x = 0$\u003c/li\u003e\n\u003cli\u003e$\\lVert \\alpha x \\rVert = \\lvert \\alpha \\rvert \\lVert x \\rVert$ per ogni $x \\in \\mathbb{R}^{n}$ e $\\alpha \\in \\mathbb{R}$\u003c/li\u003e\n\u003cli\u003eVale la disuguaglianza triangolare, ossia $\\forall x, y \\in \\mathbb{R}^{n}, \\lVert x + y \\rVert \\leq \\lVert x \\rVert + \\lVert y \\rVert$.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"convessit√†\"\u003eConvessit√†\u003c/h3\u003e\n\u003cp\u003eAnalizzato meglio in \u003ca href=\"/notes/analisi-di-convessit%C3%A0/\"\u003eAnalisi di Convessit√†\u003c/a\u003e.\nSi pu√≤ dimostrare tramite la propriet√† 3 e 4 che la norma √® una funzione convessa.\nInfatti sia $f$ la funzione che soddisfa le propriet√† della norma (quindi effettivamente si pu√≤ chiamare norma). Allora:\u003c/p\u003e","title":"Norme e Condizionamento"},{"content":"Introduzione alla notazione asintotica Cercare di definire il tempo impiegato da una funzione per essere eseguita in termini di DIMENSIONE dell\u0026rsquo;input. **(il numero di bit a livello basso basso)\nMa abbiamo il problema di misura, in quanto dobbiamo considerare delle variabili che siano indipendenti rispetto alla macchina.\nCaratteristiche della notazione Vogliamo considerare una notazione asintotica (che guarda quanto fa il comportamento verso l\u0026rsquo;infinito)\n### Accesso di memoria Ogni operazione in un processore moderno ha in generale un numero di accessi in memoria constante (solitamente abbiamo sempre un numero fissato di operandi possibile, questo significa che se un certo algoritmo ha una certa complessit√†, resta di questa complessit√† anche tenendo in considerazione le operazioni di accesso di memoria). Questo discorso non tiene pi√π se teniamo in considerazione numeri a precisione infinita, che possono avere un numero arbitrario di accessi in memoria per poter essere computato.\nFunzione di costo Solitamente teniamo in considerazione nel conteggio di costo solamente le operazioni utili per computare matematicamente la funzione. In realt√† ci sono delle operazioni di accesso di memoria nascoste che solitamente non vediamo.\nSolitamente andiamo a definire la performance di un certo algoritmo in una certa architettura come:\n$$ \\text{ performance } = \\frac{\\text{ operazioni elementari }}{\\text{ tempo di esecuzione }} $$ Questo si chiama flops per secondo, ed √® l\u0026rsquo;unit√† di memoria utilizzata solitamente. Possiamo andare a confrontare l\u0026rsquo;upper bound di performance di un algoritmo su un processore usando la performance massima data dal produttore. Solitamente secondo il professore si arriva a circa 30% di performance del processore per una cosa molto buona.\nContare le operazioni Il conteggio delle operazioni √® un modo possibile per contare il costo di certe implementazioni di algoritmi.\nIdentifichiamo tree metodi principali per andare a contare gli algoritmi:\nConteggio delle operazioni elementari: Contare le operazioni di base che vengono eseguite (somma, moltiplicazione, confronto, assegnamento) Codice strumentale: codice esterno che conta quando certi eventi avvengono o meno. Performance counters: strumenti ad hoc che vanno a contare questo genere di cose (cache miss, cicli di clock e simili). Modelli asintotici Abbiamo trattato di o-piccolo e ogrande in Analisi.\nO-grande $$ f(n) \\leq c g(n) $$ Ossia: la funzione √® upper-bounded per numeri molto grandi. Quando vale la versione stretta si pu√≤ dire che √® anche o-piccolo.\n$$ n^{c}, 2^{O(\\log n)}, n^{O(1)} $$ Sono equivalenti.\no-piccolo Usiamo la definizione trattata in Analisi: Œò (Theta) $$ c_1 g(n) \\leq f(n) \\leq c_2 g(n) $$\nQuesto implica che $f(n)$ cresce alla stessa velocit√† di $g(n)$ per valori di $n$ sufficientemente grandi.\nAlcune propriet√† della notazione $\\Theta$:\nSe $f(n) = \\Theta(g(n))$, allora $f(n)$ √® sia $O(g(n))$ che $\\Omega(g(n))$. La notazione viene usata per descrivere il comportamento preciso della funzione, senza una sovrastima (come $O$) o una sottostima (come $\\Omega$). Œ©-grande $$ f(n) \\geq c g(n) $$\nQuesto significa che $f(n)$ cresce almeno alla stessa velocit√† di $g(n)$ per valori grandi di $n$.\nœâ-piccolo $$ f(n) \u003e c g(n) $$\nCi√≤ implica che $f(n)$ cresce strettamente pi√π velocemente di $g(n)$, ovvero non esiste un limite superiore costante per il loro rapporto.\nCosto e Complessit√† computazionale Definizioni Analisi ammortizzata Introduzione Questa √® una tecnica che trova il costo medio di un algoritmo. La differenza con il calcolo del costo medio classico √® che questo calcolo mi trova il costo medio per una sequenza di operazioni mentre il classico mi trova il costo medio per una singola operazione\nCasi di utilizzo Di solito √® utile utilizzare questo metodo di analisi in queste condizioni\nCaso pessimo non frequente (quindi per dire che nella media un algoritmo √® molto pi√π efficiente) Semplificare l\u0026rsquo;analisi del caso medio Aggregazione Vogliamo cercare un limite superiore su n operazioni, poi dividere il tutto per n. Questo √® pi√π utile quando il costo totale √® conosciuto\nAccantonamenti Questo √® basato sulla contabilit√†, ho un certo credito iniziale, posso utilizzare tutto, ma non posso mai andare in negativo.\nQuesto √® utile quando ci sono diverse operazioni.\nUn esempio di analisi ammortizzata utilizzando gli accantonamenti √® la doubling and halving in cui 3 monete per ogni operazione di inserimento bastano poi per ricopiare ed espandere o diminuire il tutto a piacere (quindi 3n , si ha un costo costante). menti √® la doubling and halving in cui 3 monete per ogni operazione di inserimento bastano poi per ricopiare ed espandere o diminuire il tutto a piacere (quindi 3n , si ha un costo costante).\nRegistro Ripassi 14/03/2024 Ripassato per Time and Space Complexity Ripasso Prox: 31 Ripasso: May 28, 2022 Ultima modifica: April 28, 2022 5:07 PM Primo Abbozzo: February 24, 2022 9:19 AM Stato: üåïüåïüåïüåïüåï Studi Personali: No\n","permalink":"https://flecart.github.io/notes/notazione-asintotica/","summary":"\u003ch2 id=\"introduzione-alla-notazione-asintotica\"\u003eIntroduzione alla notazione asintotica\u003c/h2\u003e\n\u003cp\u003eCercare di definire il tempo impiegato da una funzione per essere eseguita \u003cstrong\u003ein termini di DIMENSIONE dell\u0026rsquo;input\u003c/strong\u003e. **(il numero di bit a livello basso basso)\u003c/p\u003e\n\u003cp\u003eMa abbiamo il problema di misura, in quanto dobbiamo considerare delle variabili che siano indipendenti rispetto alla macchina.\u003c/p\u003e\n\u003ch3 id=\"caratteristiche-della-notazione\"\u003eCaratteristiche della notazione\u003c/h3\u003e\n\u003cp\u003eVogliamo considerare una notazione asintotica (che guarda quanto fa il comportamento verso l\u0026rsquo;infinito)\u003c/p\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Notazione Asintotica/Untitled.png\" alt=\"image/universita/ex-notion/Notazione Asintotica/Untitled\"\u003e\n### Accesso di memoria\nOgni operazione in un processore moderno ha in generale un numero di accessi in memoria constante (solitamente abbiamo sempre un numero fissato di operandi possibile, questo significa che se un certo algoritmo ha una certa complessit√†, resta di questa complessit√† anche tenendo in considerazione le operazioni di accesso di memoria).\n\u003cp\u003eQuesto discorso non tiene pi√π se teniamo in considerazione numeri a precisione infinita, che possono avere un numero arbitrario di accessi in memoria per poter essere computato.\u003c/p\u003e","title":"Notazione Asintotica"},{"content":"Interrupt Descrizione iniziale üü© Di interrupt e trap se n‚Äô√® parlato un p√≤ in Livello ISA di architettura, ora andiamo ad approfondire come viene gestito a livello SO.\nUn interrupt √® un segnale che viene mandato o da un dispositivo hardware (di solito dopo la fine di un processo input output) oppure da software, in questo caso viene chiamato trap che √® un interrupt software sincrono..\nSlide Interrupt Hardware e software\nQuesti segnali sono utilizzati per indicare eventi che dovrebbero essere gestiti (come end of I/O, divisione per 0, ma anche semplicemente syscall e passare livello kernel).\nIl segnale solitamente implica la interruzione di quanto viene svolto in questo momento, per gestire l‚Äôinterrupt corrente, e poi tornare all‚Äôistruzione precedente. Solitamente perch√© potrebbe anche essere che il processo non sia interrompibile, e quindi l‚Äôinterrupt dovrebbe essere rischedulato.\nPer poter ripristinare lo stato precedente solitamente ci si devono salvare l‚Äôimmagine dei registri del programma, tutte le informazioni utili a far runnare il processo (di solito messe nelle PCB), e l‚Äôistruzione di ritorno.\nQuando ci si ritorna sopra basta mettere nel PC l‚Äôindirizzo della istruzione corretta.\nProcedimento classico di gestione interrupt üü© Praticamente durante il Ciclo va a fare un check per vedere se il filo dell‚Äôinterrupt √® settato, se s√¨ carica istruzioni a un certo indirizzo (e si deve salvare l‚Äôistruzione attuale).\nMasked se si sta facendo qualcosa che non si pu√≤ interrompere, quindi √® delayed. (quando il processore non pu√≤ essere interrotto, ad esempio quando sei in Sezioni Critiche, o quando arrivano interrupt dello stesso tipo, se ogni interrupt ha una stack propria, andrebbe a sovrascrivere).\nSe tutto va bene e non √® delayed ed esiste un interrupt, ad alto livello fa:\nSospende (in un modo che possa essere ripreso) il processo corrente Salta all‚Äôistruzione definito in interrupt vector **(**tabella fissa cos√¨ √® pi√π veloce) Esegue l‚Äôinterrupt Si ritorna al processo precedente, o altro (scheduling potrebbe far andare in altro processo). Slides passi ad alto livello\nSlides passi a basso livello (!!!)\nFino a qui tutte le operazioni sono HARDWARE. Da ora in poi viene ripreso il ciclo FDE con il controllo dell Interrupt handler.\nTipologie di gestione di interrupt Multipli (2) üü© Quando ho interrupt multipli diventa leggermente pi√π difficile gestire questi interrupt. Potrebbero interagire, che succede quando mi arriva un interrupt da device 1 mentre sto runnando l‚Äôinterrupt handler di device 2???\nDisabilitazione degli interrupt\nQuesta √® la forma pi√π semplice per la gestione dell‚Äôinterrupt, in pratica quando sto gestendo un interrupt, li disabilito, in modo che non possa riceverne altri, cos√¨ sono sicuro che non posso ricevere nessun altro interrupt. Una soluzione simile per le CS ne abbiamo discusso in Sezioni Critiche\nQuando sto per finire riattivo gli interrupt e cos√¨ posso vedere se ce ne erano alcuni pendenti.\nHo alcuni svantaggi come:\nNon ho un concetto di priorit√† degli interrupt a questo livello Slide idea di gestione\nAnnidamento degli interrupt\nQuesta √® la soluzione pi√π moderna, ed √® anche la pi√π efficiente che permette di\nAvere un concetto di priorit√† di interrupts Necessita di stack separati (se gli interrupt utilizzano la stessa stack, potrebbero sovrascriversi alcune informazioni!) quindi pi√π difficile da implementare. Forse ogni interrupt ha una propria stack, se viene stetsso tipo di interrupt sono maskerati! PI/O, or Interrupt based I/O üü© PI/O\nIn questo caso la CPU setta tutti i valori utili al controllore del device driver. e poi fa polling per chiedere al driver se ha finito o meno (attraverso un controllo sul registro di stato del driver).\nSe il driver ha finito, la CPU si mette a copiare i dati di output del device alla propria memoria.\nUn chiaro svantaggio √® che il polling √® molto inefficiente per la soluzione di questo tipo di problemi.\nInterrupt driven I/O\nQuesta √® la soluzione moderna, quella pi√π utilizzata, dato che ora √® il dispositivo driver a comunicare quando un processo I/O √® stato completato o men, cos√¨ la CPU √® a conoscenza di questo evento e pu√≤ comportarsi di conseguenza. (quindi quando gestire l‚Äôinterrupt, e poi effettivamente runnare il codice corrispondente quando l‚Äôinterrupt √® avvenuto).\nMemoria Direct Memory Access üü© Per copiare alcuni dati utili per I/O dalla memoria RAM alla memoria del controllore bisognerebbe spendere tanti cicli di clock della CPU, di solito questa √® una operazione molto lenta.\nDMA ci permette di accedere direttamente alla memoria, quindi il controllore stesso √® programmato con l‚Äôindirizzo su cui andare a prelevare la memoria corretta, sollevando la CPU da questo primo lavoro.\nChiaramente il vantaggio principale di questo metodo √® la velocit√†, dato che abbiamo pi√π cicli di clock per la CPU, oltre a questo, crea una interfaccia pi√π facile da gestire, quindi i drivers sono pi√π semplici.\nUno svantaggio √® la contesa del BUS, che per trasferire c‚Äô√® bisogno che il bus sia libero.\nSicurezza\nQuesto √® un possibile falla di sicurezza, infatti se il codice del controller √® malevolo potrebbe fare attacchi al sistema di certo tipo.\nSecondo Renzo sarebbe meglio che questo codice fosse open, in modo che sia molto probabile di trovare cose maligne.\nRam üü© √à semplificata da poche istruzioni di accesso, che di solito sono solo LOAD E STORE. (Tutti i dettagli fisici sono astratti, la CPU non si interessa di questi, sono built-in del calcolatore!).\nDi solito (in modi che non so), sono gestiti da MMU.\nNOTA: ci mettono un p√≤ i condensatori a scaricarsi. (possibile recuperare un p√≤ di informazioni se tipo congeli la RAM subito).\nLe ROM esistono ancora, ma sono per cose basilari, come per la parte del boot.\nMemory Mapped I/O üü©- Alcune aree di memoria, come quelle del video grafico, sono scritti e letti subito da alcuni driver e sono utilizzati per sapere cosa mostrare sullo schermo per esempio.\nMa dato che 2 componenti (read and write) devono sincronizzarci nella lettura. Questa sincronizzazione di solito √® fatta a livello hardware.\nDischi e SSD üü© Abbiamo spiegato meglio questa parte in Devices OS\nDischi memorizzano in maniera magnetica, e lo fanno in maniera non-volatile, cio√® possiamo ritrovare i nostri dati.\nSono a accesso diretto, in contrasto con i nastri che erano sequenziali. leggermente accennato in Memoria. E per capire dove leggere e scrivere si devono impostante movimenti di settore del cilindro e testina per leggere il settore corretto. Settore si aspetta che giri, testina si aspetta che si sposti. √à lento, nell‚Äôordine dei microsecondi.\nOperazioni possibili\nREAD, WRITE e anche Seek (quando vado a spostare la testina da altre parti!)\nSlide\nOsservazioni sulla velocit√†\nNon ci converrebbe avere uno stesso file messo in posti molto diversi fra di loro all‚Äôintenro del disco!\nCose di scheduling in modo da leggere cose che siano vicine. (Ma anche il filesystem, in modo che cose che cose che vengono utilizzate spesso siano vicine, ma questa roba la vedremo dopo)\nSSD, Solid State Disk\nAnche questi sono per cose non volatili.\nSolitamente scrivono ad insieme di blocchi! e lo si fa in cicli di scrittura perch√© non scrive ad ogni singola scrittura, ma sono in un buffer, e saranno scritti insieme in tutti in un ciclo di scrittura, questo √® per rendere pi√π efficiente questa operazione.\nPer ssd a volte tengo la RAM come una cache intermedia per la scrittura.\nGerarchie di memoria üü© Slide piramide\nL‚Äôaltro argomento si parlerebbe di Cache, ma penso sia trattato gi√† benissimo in 4.2 Memoria Cache\nQuindi guardare l√¨, guardare la piramide della memoria il tradeoff velocit√† e quantit√† di memoria, il costo di accesso (in termini di tempo ed energia).\nSicurezza Il processo\nNon dovrebbe accedere ad aree di memoria a cui non dovrebbe accedere Non dovrebbe accedere direttamente ai dispositivi I/O, altrimenti potrei accedere e modificare qualunque cosa sui driver, e qualunque processo potrebbe farlo. √à importante garantire la sicurezza anche per l‚Äôaffidabilit√† del sistema, anche per proteggere il programmatore stesso, quando fa qualcosa in modo accidentale, in modo da evitare danni brutti. al sistema\nMode Bit üü© nella realt√† le protezioni principali sono due, messe a livello hardware\nUn Mode bit che sta a specificare se il CPU √® in Kernel mode o user mode. Questi metodi sono importanti perch√© il modo kernel permette accesso totale controllo totale sulla memoria, sull‚ÄôIO, mentre user solamente gli indirizzi a lui illegali. Questo metodo permette di entrare in kernel mode in modo controllato, in modo che riesca sempre a gestire questa protezione. Ovviamente il cambio del mode bit √® privilegiato, un programma normalmente non pu√≤ cambiare mode con una singola istruzione, deve passare con system call che sono le interrupt software o trap, con una istruzione specifica per mandare interrupt. √à l\u0026rsquo;unico modo!. Nota: ovviamente quando il computer parte, in boostrap √® in modalit√† kernel, che appena finisce torner√† in User Mode (√® il processo INIT!) Una mappatura a indirizzi illegali per il programma, in modo che possa accedere solamente a quello a cui dovrebbe accedere. Protezione memoria üü©- Slide protezione Memoria MMU\nQuesto pezzo di hardware ha il ruolo di tradurre indirizzi logici in fisici, e gestire l\u0026rsquo;accesso (ritorna l‚Äôerrore se non si potrebbe fare).\n√àimportante che sia in Hardware perch√©:\nDeve essere molto veloce, perch√© sono operazioni molto veloci Si potrebbe bypassare e allora avresti accesso a tutta la memoria ugualmente. System call üü©- La sistem call √® una unica istruzione, mediante la quale √® possibile accedere al kernel mode, in grado di accedere a tutto, utile per la protezione e affidabilit√† del sistema, e non permettere programmi di fare tutto.\nEsistono convenzioni di chiamata, perch√© si aspetta in un certo registro la presenza di un codice che specifichi la tipologia di system call, poi la sistem call ritorner√† il valore corretto in un certo registro.\n","permalink":"https://flecart.github.io/notes/note-sullarchitettura/","summary":"\u003ch2 id=\"interrupt\"\u003eInterrupt\u003c/h2\u003e\n\u003ch3 id=\"descrizione-iniziale-\"\u003eDescrizione iniziale üü©\u003c/h3\u003e\n\u003cp\u003eDi interrupt e trap se n‚Äô√® parlato un p√≤ in \u003ca href=\"/notes/livello-isa/\"\u003eLivello ISA\u003c/a\u003e di architettura, ora andiamo ad approfondire come viene gestito a livello SO.\u003c/p\u003e\n\u003cp\u003eUn interrupt √® un \u003cstrong\u003esegnale\u003c/strong\u003e che viene mandato o da un dispositivo hardware (di solito dopo la fine di un processo input output) oppure da software, in questo caso viene chiamato \u003cstrong\u003etrap\u003c/strong\u003e che √® un interrupt software sincrono..\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide Interrupt Hardware e software\u003c/p\u003e","title":"Note sull‚Äôarchitettura"},{"content":"Introduction Semantic segmentation Vorremo trovare regioni che corrispondano a categorie diverse. E dividere in questo modo l‚Äôimmagine secondo zone di informazione.\nObject detection Vogliamo trovare il pi√π piccolo box che vada a contenere l‚Äôoggetto. Questo √® fatto con il bounding box.\nIn questo caso la funzione di loss √® un p√≤ pi√π difficile da definire, si utilizza la funzione intersection over union con le aree, in pratica la percentuale di immagine comune diciamo.\nDeep object detection (2) Region proposals\nQuesta √® una versione che prova a catturare le regioni di interesse all‚Äôinterno della nostra immagine. (pi√π o meno non sa cosa sia l‚Äôoggetto, ma sa che c‚Äô√® qualcosa in quella zona). Poi questa regione di interesse √® passata in un secondo step che va a riconoscere cosa √® presente in quella immagine. (la regione di interesse era presente anche prima di CNN).\nSIngle shots\nQuesti sono pi√π veloci dei precedenti, quindi sono buoni per applicazioni real time.\nYOLO You Only Look Once intro https://pjreddie.com/darknet/yolo/\nhttps://towardsdatascience.com/yolo-v4-or-yolo-v5-or-pp-yolo-dad8e40f7109\nProva a trovare il bounding box con la predizione con una singola passata! CNN per individuare i boxes, poi algoritmicamente per cancellare i boxes.\nMain Idea FUNZIONAMENTO\nFa delle predizioni, che sono dei bounding box con dei labels (espressi attraverso una probabilit√†).\nDopo avevi un certo numero di neuroni dopo aver fatto downsampling (queste hanno visisione solamente di una zona limitata dell‚Äôimmagine).\nL‚Äôidea principale √® allenare il singolo neurone a riconoscere l‚Äôoggetto (wtf hoooow). E ignorare tutti i resti dei neuroni (si fa con una mask in qualche modo).\nOutput format Slide formato dell‚Äôoutput\nSi deve tenere molte informazioni (i punti, lo score, e un valore di score per tutte le classi).\nSolitamente si parte da un anchor box di dimensioni fisse (width e height). I valori di ritorno sono un displacement dal centro in entrambe le direzioni e un fattore di deformazione per ogni direzione.\nLoss function Localization loss function\nLa loss di localizzazione non √® altro che una differenza\nNota: c‚Äô√® una binary map, che che √® in una cella e 0 in tutto il resto (questo per dire che il neurone vuole predire solamente quello che gli sta intorno, il resto lo ignora tutto).\nClassification loss\n!\n","permalink":"https://flecart.github.io/notes/object-detection/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003ch3 id=\"semantic-segmentation\"\u003eSemantic segmentation\u003c/h3\u003e\n\u003cp\u003eVorremo trovare \u003cstrong\u003eregioni che corrispondano a categorie diverse\u003c/strong\u003e. E dividere in questo modo l‚Äôimmagine secondo zone di informazione.\u003c/p\u003e\n\u003ch3 id=\"object-detection\"\u003eObject detection\u003c/h3\u003e\n\u003cp\u003eVogliamo trovare \u003cstrong\u003eil pi√π piccolo box\u003c/strong\u003e che vada a contenere l‚Äôoggetto. Questo √® fatto con il \u003cstrong\u003ebounding box\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eIn questo caso la funzione di loss √® un p√≤ pi√π difficile da definire, si utilizza la funzione \u003cstrong\u003eintersection over union\u003c/strong\u003e con le aree, in pratica la percentuale di immagine comune diciamo.\u003c/p\u003e","title":"Object Detection"},{"content":"Definition of problems Object detection Bisogna trovare all\u0026rsquo;interno dell\u0026rsquo;immagine quali siano gli oggetti presenti, e in pi√π vogliamo sapere dove siano quindi utilizzare una bounding box per caratterizzarli sarebbe buono.\nObject segmentation √à riuscire a caratterizzare categoria per categoria per singoli pixelsm e per questo motivo potrei riuscire a fare delle image map in cui colorare singoli oggetti in una categoria.\nDatasets Example datasets Pascal VOC 2012 Coco datasets Cityscapes dataset Autogenerated datasets But I don\u0026rsquo;t know much about these datasets Applications Auto drive Campo medico (per segmentazione medica o riconoscimento immagini). reidentificazione. Key posse extimations. U-net Il primo skip connection ci permette di capire bene quali siano i bordi, perch√© sappiamo che la convoluzione riesce a prendere bene\nArchitettura di Yolo Downsampling, fare dei mini quadratini, 32 fattori di downsampling, di solito l\u0026rsquo;immagine √® 416x416 e arriva a 13x13. Ogni neurone fa tre predizioni. Quattro valori per una bounding box (offsettata dal neurone), quanto penso di essere sicuro, e poi dire cosa esattamente sto vedendo. Importante avere la funzione di loss per analizzare bene. Vogliamo avere un singolo neurone, quindi forzo a zero tutti gli altri neuroni. Questo √® quello che faccio con la funzione maschera per avere solamente la box di interesse. Poi una volta definito questo provo a definire errore di localizzazione e l\u0026rsquo;errore di classificazione. Quello √® l\u0026rsquo;errore di di localizzazione in cui vogliamo avere la bounding box pi√π corretta. La radice √® una euristica umana per cercare di favorire il punto principale (ma cambia la loss fra versione all\u0026rsquo;altra).\nUna volta che ho le due loss posso provare a bilanciarle: $$ L = \\lambda_{c}L_{loc} + L_{cls} $$ E le variabili si mettono a mano seconda dell'architettura. Region proposals and single shots Region proposals: (R-CNN, Fast R-CNN, Faster R-CNN).\nIl primo √® un vecchio metodo per attaccare il problema. In passato si analizzava la texture per capire le regioni con struttura e dove si avevano altre, utilizzato per avere zone di interesse, senza informazioni semantiche a riguardo. una volta capite le regioni di interesse l\u0026rsquo;altra rete prova a fare classificazione e bounding box.\nSingle shots (Yolo, SSD, Retina-net, FPN).\nSi fanno in unica passata indetificazione del luogo e categorizzazione.\nIntersection over Union $$ IoU(A, B) =\\frac{\\lvert A \\cap B \\rvert }{\\lvert A\\cup B \\rvert } $$This metric is also used for other types of algorithms, for example the MinHash algorithm used something very similar. Sometimes this is also called Jaccard Metric.\nNon-maximum-suppression algorithms üü© √à un modo per trovare le bounding box migliori per un certo argomento. In pratica √® un algoritmo greedy, che va cos√¨:\nSorta tutte le bounding box in ordine decrescente di confidence Prendo la prima come vera Le prossime le elimino se hanno una intersection over union alta, altrimenti le tengo. Cos√¨ finch√© non finiscono tutte le bounding box. ","permalink":"https://flecart.github.io/notes/object-detection-and-segmentation/","summary":"\u003ch3 id=\"definition-of-problems\"\u003eDefinition of problems\u003c/h3\u003e\n\u003ch4 id=\"object-detection\"\u003eObject detection\u003c/h4\u003e\n\u003cp\u003eBisogna trovare all\u0026rsquo;interno dell\u0026rsquo;immagine quali siano gli oggetti presenti, e in pi√π \u003cstrong\u003evogliamo sapere dove siano\u003c/strong\u003e quindi utilizzare una bounding box per caratterizzarli sarebbe buono.\u003c/p\u003e\n\u003ch4 id=\"object-segmentation\"\u003eObject segmentation\u003c/h4\u003e\n\u003cp\u003e√à riuscire a caratterizzare categoria per categoria per \u003cstrong\u003esingoli pixels\u003c/strong\u003em e per questo motivo potrei riuscire a fare delle image map in cui colorare singoli oggetti in una categoria.\u003c/p\u003e\n\u003ch3 id=\"datasets\"\u003eDatasets\u003c/h3\u003e\n\u003ch4 id=\"example-datasets\"\u003eExample datasets\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003ePascal VOC 2012\u003c/li\u003e\n\u003cli\u003eCoco datasets\u003c/li\u003e\n\u003cli\u003eCityscapes dataset\u003c/li\u003e\n\u003cli\u003eAutogenerated datasets\nBut I don\u0026rsquo;t know much about these datasets\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"applications\"\u003eApplications\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eAuto drive\u003c/li\u003e\n\u003cli\u003eCampo medico (per segmentazione medica o riconoscimento immagini).\u003c/li\u003e\n\u003cli\u003ereidentificazione.\u003c/li\u003e\n\u003cli\u003eKey posse extimations.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"u-net\"\u003eU-net\u003c/h4\u003e\n\u003cp\u003eIl primo skip connection ci permette di capire bene quali siano i bordi, perch√© sappiamo che la convoluzione riesce a prendere bene\u003c/p\u003e","title":"Object detection and Segmentation"},{"content":"Ripasso Prox: 10 Ripasso: May 29, 2023 Ultima modifica: May 19, 2023 10:33 AM Primo Abbozzo: May 8, 2023 9:20 AM Stato: üåïüåïüåïüåïüåë Studi Personali: No\nElementi di ripasso Object orientation il tipo di dato astratto Introduzione Per questi tipi di dato non ci interessa di sapere cosa ci sia sotto (storato come bit? storato come sabbia boh), ci interessa solamente che abbia quei metodi, che possiamo in un certo senso identificare come la sua capsula, opaca in questo caso.\nQuando si pu√≤ andare a modificare solamente attraverso questo metodo potrei dire che sia safe collegato alla Algebra dei tipi, nel senso che vengono soddisfatte sempre le propriet√† del tipo.\nCostituenti del ADT (4) (abstract data structure) üü® Slide ADT\nCi sono principalmente 4 elementi:\nIl nome del tipo di dato astratto Il dato concreto che sta sotto (ad esempio intero Operazioni di creazione ed accesso (che in un certo senso sono simili ai meccanismi di Architettura software del OS) confine di astrazione che sono come le interfaccie, o politiche? In pratica credo siano equivlaenti alle cose pubbliche di questa, mentre il punto 3 racchiude anche quelle private. Information hiding üü© Slide information hiding\nIl fatto che vogliamo cercare di andare ad operare e prendere da questo tipo di dato astratto solamente attraverso delle interfacce. Per questo motivo si pu√≤ dire che stiamo nascondendo cosa c\u0026rsquo;√® dentro a quella classe.\nSotto questo punto di vista, si dice spesso che la classe √® come contratto con la superficie, perch√© va a soddisfare certe propriet√† con chi la utilizza.\nIl fatto che l\u0026rsquo;implementazione effettiva viene nascosta, aiuta alla modularit√†. Non posso fare assunzioni sull‚Äôimplementazione effettiva, mi basta che le propriet√† dell‚Äôinterfaccia siano rispettate.\nUn altro aspetto √® che √® facile organizzare progetto in moduli a seconda di cosa stiamo rappresentando (prova a tenerti in mente la classica organizzazione in un file per una classe che si fa spesso in java).\nIndipendenza della rappresentanza üü© Andiamo ora ad introdurre il concetto di indipendenza della rappresentanza (ossia il fatto che non ci interessa questo tipo di dato astratto da quale tipo concreto √® rappresentato), un fatto che la caratteristica dell‚Äôinformation hiding ci ha permesso di avere:\nSlide indipendenza\nimplementazioni corrette (ben tipate) dello stesso ADT sono osservabilmente indistinguibili dai consumatori dell‚ÄôADT.\nTipi esistenziali üü© Questi sono quasi l\u0026rsquo;opposto dei tipi di polimorfismo universale parametrico in Polimorfismo, praticamente √® un exist invece che un forall, che carina questa relazione.\nSi potrebbe vedere come la rappresentazione di ADT attraverso teoria dei tipi.\nSlide tipi esistenziali\nQuando vado a definire un tipo che soddisfa quella caratteristiche non starei facendo altro che risolvendo il tipo esistenziale da un punto di vista di teoria dei tipi.\nEsempio risoluzione di tipi esistenziali\nOggetti esistenziali üü© Slide problema tipi esistenziali\nSlide oggetti esistenziali\nGli oggetti esistenziali mantengono l\u0026rsquo;astrazione del tipo esistenziale, a differenza delle ADT che vanno ad eliminare l‚Äôesiste e quindi diventano inoperabili fra di loro, tenendo l‚Äôastrazione possiamo andare a cooperare fra istanziazioni diverse di questo oggetto esistenziale. (si porta avanti l\u0026rsquo;interfaccia senza andarlo a risolvere come per ADT)\nUna altra differenza √® che oggetti fanno una differenza fra stati e metodi, mentre il tipo di dato astratto tiene solamente operazioni e il tipo sotto di esso.\nSlide confronto oggetti esistenziali con abstract data types\nIn breve ADT sono aperti, mentre oggetti sono chiusi e quest\u0026rsquo;ultimo fatto permette di utilizzare tipi con istanziazione anche diversa fra di loro.\nuna differenza rilevante degli oggetti rispetto agli ADT √® che, poich√© ogni oggetto ha la propria rappresentazione interna e implementa le proprie operazioni, un programma pu√≤ liberamente mescolare implementazioni diverse dello stesso tipo di oggetto (esistenziale).\nClassi e oggetti Def oggetto üü© Oggetto: una capsula che contiene sia dati che operazioni per manipolarli e che fornisce un\u0026rsquo;interfaccia al mondo esterno attraverso la quale √® possibile accedervi.\nLe operazioni sono anche chiamate metodi. mentre i dati sono chiamati campi dell\u0026rsquo;oggetto.\nDef classe üü© Una classe √® un modello per un insieme di oggetti: stabilisce quali sono i loro dati (quanti, di che tipo, con quale visibilit√†) e fissa il nome, la segnatura, la visibilit√† e l\u0026rsquo;implementazione dei suoi metodi\nIn modo pi√π intuitivo potremmo andare a dire:\nclasse: Specifica un canovaccio o un modello di implementazione di riferimento che contiene le variabili e i metodi comuni alla stessa classe (da cui il nome) di oggetti.\nImplementazione delle classi (2)üü© La definizione dei metodi della classe √® unica, sono solamente i campi di dati che sono diversi per ogni istanziazione. Come fanno ogni istanziazione ad accedere al metodo corretto allora? Puntatore all\u0026rsquo;unica istanziazione! L\u0026rsquo;immagine sotto pu√≤ chiarificare questo concetto:\ndall‚Äôaltra parte quando dall\u0026rsquo;implementazione mi vado a riferire a this, questo deve derefernziarwsi sulla corretta istanziazione dell‚Äôoggetto!\nLo storage, come al solito, pu√≤ essere sia a stack sia sulla heap, a seconda dell‚Äôimplementazione del linguaggio.\nPrincipalmente credo che le osservazioni principali siano due:\nDereferenziare correttamente il this Sapere accedere alle funzioni definite nella classe Prototipi e confronto con classi üü® Questi sono un pattern che piace tanto a Javascript.\nsi basa sulla possibilit√† che gli oggetti deleghino parti della loro implementazione ad altri oggetti.\nCreazione ora si pu√≤ fare in due modi, uno il classico √® new, l\u0026rsquo;altro √® ex-nihilo andando a definire passo passo tutto (in modo direi estensionale, andando a ricollegarmi con Teoria dei Tipi)\nla differenza principale dei prototipi con le classi √® la flessibilit√† vs sicurezza dato che in js i prototipi possono essere assegnati a runtime, quindi potrebbero anche cambiare (sicuramente cattiva pratica, credo si chiami anche monkey typing).\nNelle classi non possiamo andare a cambiare l\u0026rsquo;implementazione una volta dichiarata.\nSi una possibilit√† di fare una delegazione ossia il metodo √® implementato in modo dinamico e vado a cercare il primo prototipo per quell\u0026rsquo;oggetto. √à molto flessibile, perch√© utilizza duck-typing, molto facile cambiare le cose, solo che dal punto di vista della correttezza e sicurezza √® un p√≤ pi√π difficile.\n","permalink":"https://flecart.github.io/notes/object-orientation/","summary":"\u003cp\u003eRipasso Prox: 10\nRipasso: May 29, 2023\nUltima modifica: May 19, 2023 10:33 AM\nPrimo Abbozzo: May 8, 2023 9:20 AM\nStato: üåïüåïüåïüåïüåë\nStudi Personali: No\u003c/p\u003e\n\u003ch1 id=\"elementi-di-ripasso\"\u003eElementi di ripasso\u003c/h1\u003e\n\u003ch1 id=\"object-orientation\"\u003eObject orientation\u003c/h1\u003e\n\u003ch2 id=\"il-tipo-di-dato-astratto\"\u003eil tipo di dato astratto\u003c/h2\u003e\n\u003ch3 id=\"introduzione\"\u003eIntroduzione\u003c/h3\u003e\n\u003cp\u003ePer questi tipi di dato non ci interessa di sapere cosa ci sia sotto (storato come bit? storato come sabbia boh), ci interessa solamente che abbia quei metodi, che possiamo in un certo senso identificare come la sua capsula, \u003cstrong\u003eopaca\u003c/strong\u003e in questo caso.\u003c/p\u003e","title":"Object orientation"},{"content":"This note will mainly attempt to summarize the introduction of some intuitive notions of probability used in common sense human reasoning. Most of what is said here is available here (Jaynes 2003).\nThree intuitive notions of probability Jaynes presents some forms of inference that are not possible in classical first order or propositional logic, yet they are frequent in human common sense reasoning. Let\u0026rsquo;s present some rules and some examples along them:\nIf there exists a logical rule $A \\to B$ we have that observing $\\bar{A}$ makes $\\bar{B}$ more probable. For example if the sentence is \u0026ldquo;If it rains, the terrain will be wet\u0026rdquo;, if we observe that it is not raining, it is more probable that the terrain is not even wet!. This can be also captured by the classical Bayesian rule: Let\u0026rsquo;s say $R$ is raining probability and $W$ is wet probability, then:\n$$ \\mathbb{P}(W \\mid \\bar{R}) = \\frac{\\mathbb{P}(\\bar{R} \\mid W)\\mathbb{P}(W)}{\\mathbb{P}(\\bar{R})} \\leq \\mathbb{P}(W) $$We also can infer that if we observe that the terrain is wet, then we say it is more probable that it has rained.\n$$ \\mathbb{P}(R \\mid W) = \\frac{\\mathbb{P}(W \\mid R)\\mathbb{P}(R)}{\\mathbb{P}(W)} = 1 \\frac{\\mathbb{P}(R)}{\\mathbb{P}(W)} \\geq \\mathbb{P}(R) $$These are some natural inferences that could be made by just having a specific logical rule. This is not logical reasoning, but it captures many facets of human probabilistical reasoning that we would like to imbue into machines.\n$$ P(A \\mid B) = \\frac{P(B \\mid A)P(A)}{P(B)} \\geq P(A) $$So simple Bayes rule allows us to encode these important reasoning systems!\nReferences [1] Jaynes ‚ÄúProbability Theory: The Logic of Science‚Äù Cambridge University Press 2003\n","permalink":"https://flecart.github.io/notes/on-intuitive-notions-of-probability/","summary":"\u003cp\u003eThis note will mainly attempt to summarize the introduction of some intuitive notions of probability used in common sense human reasoning. Most of what is said here is available here \u003ca href=\"https://www.cambridge.org/core/books/probability-theory/9CA08E224FF30123304E6D8935CF1A99\"\u003e(Jaynes 2003)\u003c/a\u003e.\u003c/p\u003e\n\u003ch4 id=\"three-intuitive-notions-of-probability\"\u003eThree intuitive notions of probability\u003c/h4\u003e\n\u003cp\u003eJaynes presents some forms of inference that are not possible in classical first order or propositional logic, yet they are frequent in human common sense reasoning.\nLet\u0026rsquo;s present some rules and some examples along them:\u003c/p\u003e","title":"On intuitive notions of probability"},{"content":"Double descent is a striking phenomenon in modern machine learning that challenges the traditional bias‚Äìvariance tradeoff. In classical learning theory, increasing model complexity beyond a certain point is expected to increase test error because the model starts to overfit the training data. However, in many contemporary models‚Äîfrom simple linear predictors to deep neural networks‚Äîa second descent in test error emerges as the model becomes even more overparameterized.\nAt its core, the double descent curve can be understood in three stages. In the first stage, as the model‚Äôs capacity increases, the error decreases because the model is better able to capture the underlying signal in the data. As the model approaches the interpolation threshold‚Äîwhere the number of parameters is roughly equal to the number of data points‚Äîthe model fits the training data exactly. This exact fitting, however, makes the model extremely sensitive to noise, leading to a spike in test error. Surprisingly, when the model complexity is increased further into the highly overparameterized regime, the training algorithm (often stochastic gradient descent) tends to select from the many possible interpolating solutions one that exhibits desirable properties such as lower norm or smoothness. This implicit bias toward simpler, more generalizable solutions causes the test error to decrease again, producing the second descent.\nThe key to this behavior lies in the interplay between the model capacity, noise in the data, and the inductive biases of the learning algorithm. In the overparameterized regime, despite the apparent overfitting, the abundance of parameters allows the optimizer to ‚Äúchoose‚Äù a solution that not only fits the training data perfectly but also generalizes well on unseen data. This self-regularization effect, or implicit regularization, explains why the test error can improve even when traditional theory would suggest it should worsen.\nThis conceptual framework for double descent has been illustrated using simple polynomial regression and extended to complex models such as deep neural networks. For instance, analyses show that when key factors like noise level, data dimensionality, and the model‚Äôs parameterization interact, the effective complexity of the model (or its ‚Äúsmoothness‚Äù as enforced by the learning algorithm) governs its generalization performance rather than the sheer number of parameters alone 1 . More recent work continues to build on these ideas, highlighting that the phenomenon is not merely a quirk of specific models but a robust aspect of modern machine learning dynamics .\nIn summary, double descent occurs because there is a delicate balance: near the interpolation threshold, the model‚Äôs capacity is just enough to fit all the data‚Äîincluding its noise‚Äîresulting in high variance and poor test performance. Once past that point, additional parameters provide the flexibility for the optimizer to favor solutions that inherently generalize better, thus reducing the test error despite the increased complexity.\nhttps://arxiv.org/abs/2303.14151\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://flecart.github.io/notes/on-the-double-descent-phenomenon/","summary":"\u003cp\u003eDouble descent is a striking phenomenon in modern machine learning that challenges the traditional bias‚Äìvariance tradeoff. In classical learning theory, increasing model complexity beyond a certain point is expected to increase test error because the model starts to overfit the training data. However, in many contemporary models‚Äîfrom simple linear predictors to deep neural networks‚Äîa second descent in test error emerges as the model becomes even more overparameterized.\u003c/p\u003e\n\u003cp\u003eAt its core, the double descent curve can be understood in three stages. In the first stage, as the model‚Äôs capacity increases, the error decreases because the model is better able to capture the underlying signal in the data. As the model approaches the interpolation threshold‚Äîwhere the number of parameters is roughly equal to the number of data points‚Äîthe model fits the training data exactly. This exact fitting, however, makes the model extremely sensitive to noise, leading to a spike in test error. Surprisingly, when the model complexity is increased further into the highly overparameterized regime, the training algorithm (often stochastic gradient descent) tends to select from the many possible interpolating solutions one that exhibits desirable properties such as lower norm or smoothness. This implicit bias toward simpler, more generalizable solutions causes the test error to decrease again, producing the second descent.\u003c/p\u003e","title":"On The Double Descent Phenomenon"},{"content":"$$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$$$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} $$ Con questi abbiamo le onde elettromagnetiche.\nNel vuoto possiamo dire che non abbiamo densit√† di corrente, per questo posso andare nel vuoto, sono due cose che si autosostengono. Sono simmetriche a meno di costante.\nQuesto ci dice che\nPreso un campo elettrico che varia nel tempo (tipo una carica oscillante). Questo mi dice che si genera un campo magnetico prima non esistente Questo campo che varia nel tempo va a creare un altro campo elettrico Quindi abbiamo un processo che continua cos√¨ all\u0026rsquo;infinito sostenendosi. In queste due equazioni abbiamo la luce. 2 circuitazioni 2 Leggi di gauss e le 4 equazioni di Maxwell sono in grado di descrivere tutti i fenomeni elettromagnetici.\nNote storiche dei progressi in elettromagnetismo Il risultato curioso il fatto che sembrasse relazionato alla velocit√† della luce quella costante. Poi 1885 Hertz dimostra l\u0026rsquo;esistenza delle onde elettromagnetiche (quindi soggetti ai fenomeni delle onde, come l\u0026rsquo;interferenza, e si capisce che sono la stessa cosa con la luce. Una altra cosa curiosa √® che tutto elettromagnetismo √® fatto senza sapere l\u0026rsquo;esistenza di elettroni (solo all\u0026rsquo;inizio del \u0026lsquo;900 abbiamo iniziato a comprendere meglio come sono fatti e sono iniziati anche prodotti forti con queste) 1930 Fermi a Roma ha fatto una conferenza per la scoperta dell\u0026rsquo;elettrone da Thompson (Rutherford ha scoperto di pi√π su atomi, il mini sistema planetario), in questa conferenza si studia i neutroni (che non esistevano), e si inizia a comprendere meglio la materia. Strana cosa era che dal nucleo venivano emessi elettroni (questo √® il decadimento radioattivo? Non si sapeva del neutrone, qui ).\nTeorema di Poynting Setting del problema üü© Consideriamo una distribuzione di cariche $dq = \\rho dt$ che dipende dalla posizione $\\rho = \\rho(\\hat{r}t)$, stessa cosa per la velocit√† in un campo elettromagnetico costante. Voglio sapere il **lavoro** e **potenza** fatto dai campi sulla carica. $$ \\vec{F} = q\\vec{E} + q\\vec{v} \\times \\vec{B} \\implies df = [\\rho \\vec{E} + \\rho \\vec{v}\\times \\vec{B}]d\\tau $$$$ dW = d\\vec{f} \\cdot \\vec{v} \\implies dW = [\\rho \\vec{E}\\cdot \\vec{v} + \\rho \\vec{v}\\times \\vec{B} \\cdot \\vec{v}]d\\tau $$$$ dW = \\rho \\vec{E} \\cdot \\vec{v} d\\tau $$$$ dW = \\vec{J} \\cdot \\vec{E} d\\tau $$ Questa √® la stessa formula, calcolata in modo diverso in Leggi di Ohm quando calcolavamo la potenza\nDerivazione con Ampere e Faraday (tosta) üü® $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{d\\tau} \\implies \\vec{E}\\cdot[\\vec{\\nabla} \\times \\vec{B}] = \\mu_{0}\\vec{E}\\cdot\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{d\\tau} \\cdot \\vec{E} \\implies \\vec{J} \\cdot \\vec{E} = \\frac{1}{\\mu_{0}} \\vec{E}\\cdot[\\vec{\\nabla} \\times \\vec{B}] - \\varepsilon_{0} \\frac{\\delta \\vec{E}}{d\\tau} \\cdot \\vec{E} $$ Ora proviamo ad analizzarlo pezzo per pezzo, partiamo dalla parte magnetica e elettrica üü®\n$$ \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) = (\\vec{\\nabla}\\times \\vec{E}) \\cdot \\vec{B} - (\\vec{\\nabla} \\times \\vec{B}) \\cdot \\vec{E} \\implies (\\vec{\\nabla} \\times \\vec{B}) \\cdot \\vec{E} = - \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) + (\\vec{\\nabla}\\times \\vec{E}) \\cdot \\vec{B} $$ Ora utilizziamo la legge di Faraday in Magnetismo in forma differenziale e otteniamo $$\n(\\vec{\\nabla} \\times \\vec{B}) \\cdot \\vec{E} = - \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) + \\left( -\\frac{\\delta \\vec{B}}{d\\tau} \\right) \\cdot \\vec{B} $$ Questo risultato possiamo metterlo nella parte di sopra e cos√¨ abbiamo espanso la prima parte (urca quanti calcoli per√≤)\n$$ W_{\\tau} = \\vec{J} \\cdot \\vec{E} = -\\frac{1}{\\mu_{0}} \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) + \\frac{1}{\\mu_{0}} \\left( -\\frac{\\delta \\vec{B}}{d\\tau} \\right) \\cdot \\vec{B}\n\\varepsilon_{0} \\frac{\\delta \\vec{E}}{d\\tau} \\cdot \\vec{E} $$ $$ \\frac{\\delta B^{2}}{\\delta t} = \\frac{\\delta}{\\delta t} (\\vec{B} \\cdot \\vec{B}) = \\vec{B} \\cdot \\frac{\\delta}{\\delta t}(\\vec{B}) + \\frac{\\delta}{\\delta t}(\\vec{B}) \\cdot \\vec{B} = 2 \\vec{B} \\frac{\\delta}{\\delta t}\\vec{B} $$Questo ci permette di sostituire nelle forme di sopra come derivate seconde:\n$$ W_{\\tau} = \\vec{J} \\cdot \\vec{E} = -\\frac{1}{\\mu_{0}} \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) - \\frac{1}{2\\mu_{0}} \\frac{\\delta B^{2}}{dt}\n\\frac{1}{2}\\varepsilon_{0} \\frac{\\delta E^{2}}{dt} $$ Questa √® la potenza trasferita dai campi elettrici e magnetici a un volumetto $d\\tau$ che si muove con velocit√† $v$ nello spazio.\nVogliamo sapere energia totale trasferita da $\\vec{E}$ e $\\vec{B}$ per far questo basterebbe integrare sul nostro volume:\n$$ \\int dW = \\int \\vec{J} \\cdot \\vec{E} , d\\tau = -\\int \\frac{1}{\\mu_{0}} \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) , d\\tau - \\frac{1}{2}\\int \\left( \\frac{1}{\\mu_{0}} \\frac{\\delta B^{2}}{dt}\n\\varepsilon_{0} \\frac{\\delta E^{2}}{dt}\\right) d\\tau $$ Proviamo ad utilizzare il teorema della divergenza perch√© gli integrali di volume sono brutti. $$ -\\int_{\\tau} \\frac{1}{\\mu_{0}} \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) \\, d\\tau = - \\int_{\\Sigma(\\tau)} \\frac{1}{\\mu_{0}}\\cdot (\\vec{E} \\times \\vec{B}) \\, d\\vec{S} $$Quindi riscrivendo ancora abbiamo: $$ \\int_{\\tau} dW = \\int_{\\tau} \\vec{J} \\cdot \\vec{E} , d\\tau = - \\int_{\\Sigma(\\tau)} \\frac{1}{\\mu_{0}}\\cdot (\\vec{E} \\times \\vec{B}) , d\\vec{S}\n\\frac{1}{2}\\int_{\\tau} \\left( \\frac{1}{\\mu_{0}} \\frac{\\delta B^{2}}{dt} \\varepsilon_{0} \\frac{\\delta E^{2}}{dt}\\right) d\\tau $$ Attenzione: a volte tau √® usato come tempo a volte come volume (fai attenzione a distinguerli bene) Formulazione e interpretazione finale üü®+ $$ W = - \\int_{\\Sigma(\\tau)} \\frac{1}{\\mu_{0}}\\cdot (\\vec{E} \\times \\vec{B}) , d\\vec{S}\n\\frac{\\delta}{dt}\\int_{\\tau} \\left( \\frac{1}{2\\mu_{0}} B^{2} \\frac{\\varepsilon_{0}}{2} E^{2}\\right) d\\tau $$ Abbiamo due termini che descrivono il trasferimento di energia.\nEnergia trasferita alla distribuzione di carica dai campi $E$ e $B$, ossia abbiamo Il concetto di densit√† volumetrica di energia elettromagnetica, quella che abbiamo studiato separatamente in Condensatori nel vuoto e Geometrie di spire (tipicamente sono statici questi campi) $$ du = \\frac{1}{2\\mu_{0}} B^{2} \\frac{1}{2} \\varepsilon_{0}E^{2} $$ Che ha senso (somma di due energie, somma classica)), perch√© l\u0026rsquo;energia trasferita √® uguale al valore dei campi in un certo punto preciso (somma dell\u0026rsquo;energia dei campi E ed B dentro al volume). Si parla di integrale su una superficie chiusa che contiene il volume, e abbiamo un vettore perpendicolare ai campi $E$ e $B$, rappresenta flusso del vettore di Poynting, che √® una energia proveniente da fuori. (tipicamente sono onde elettromagnetiche, perch√© entrano, forniscono energia, ed escono) -\u0026gt; ONDA ELETTROMAGNETICA TRASPORTA ENERGIA. In pratica √® un Or logico, l\u0026rsquo;energia o √® presa da dentro, o da fuori, il primo termine √® il dentro, il secondo √® il fuori. Concettualmente √® semplice, la derivazione √® complessa e utilizza molte cose di algebra e analisi.\nIl vettore di Poynting üü© $$ S' = \\frac{1}{\\mu_{0}} \\vec{E} \\times \\vec{B} $$ in un certo senso √® una densit√† superficiale di potenza elettromagnetica, perch√© per avere la potenza devo moltiplicare la superficie. Forse √® con questo che utilizzo per costruire pannelli solari, √® l\u0026rsquo;energia che riscalda al sole, che impatta superficie :D.\nEnergia per unit√† di tempo e superficie trasportata da una onda.\nQuantit√† di moto üü© $$ d\\vec{P} = \\mu_{0}\\varepsilon_{0} \\vec{S}' d\\tau $$ Quantit√† di moto per unit√† di tempo e volume! Per questo posso far muovere oggetti sparandoci laser!\nNel vuoto $$ \\vec{\\nabla} \\cdot \\vec{E} = 0 $$$$ \\vec{\\nabla} \\cdot \\vec{B} = 0 $$$$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} $$$$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$Consideriamo $\\vec{\\nabla} \\times \\vec{\\nabla} \\times \\vec{E} = -\\vec{\\nabla} \\times \\frac{\\delta \\vec{B}}{\\delta t}$ Si pu√≤ vedere che\n$$ -\\nabla^{2}\\vec{E} = - \\frac{\\delta (\\vec{\\nabla} \\times\\vec{B})}{\\delta t} = -\\mu_{0}\\varepsilon_{0} \\frac{ \\delta^{2}\\vec{E}}{\\delta t^{2}} $$ Che dovrebbe essere una equazione di onda.\nEquazioni di D\u0026rsquo;Alambert üü®- $$ \\nabla^{2}\\vec{E} = \\mu_{0}\\varepsilon_{0}\\frac{ \\delta^{2} \\vec{E}}{\\delta t^{2}} $$$$ \\nabla^{2}\\vec{B} = \\mu_{0}\\varepsilon_{0} \\frac{\\delta^{2}\\vec{B}}{\\delta t^{2}} $$$$ \\frac{\\delta^{2}E_{x}}{\\delta x^{2}} + \\frac{\\delta^{2}E_{y}}{\\delta y^{2}} + \\frac{\\delta^{2}E_{z}}{\\delta z^{2}}= \\mu_{0}\\varepsilon_{0}\\frac{ \\delta^{2} \\vec{E}}{\\delta t^{2}} $$$$ \\mu_{0}\\varepsilon_{0} = \\frac{1}{v^{2}} \\implies v = \\frac{1}{\\sqrt{ \\varepsilon_{0}\\mu_{0} }} = c $$Solo alla fine dell'800 si capisce che la luce √® questo.\nExtra: frontiers Ma ci sono alcuni problemi aperti. In gravitazione ho precessione di Mercurio che metteva sotto problema le predizioni della gravit√† di Newton.\nCarica accelerata emette energia (come fa a non collassare nel nucleo?).\nRadiazione corpo nero (problema di conservazione dell\u0026rsquo;energia (catastrofe ultravioletta)).\nNon si sa in quale sistema di riferimento C valga\nEspansione accelera\nNeutrini non hanno massa zero\nGalassia ruota in modo costante, nonostante rallentare.\nEnergia del vuoto predetto male da quantistica.\n","permalink":"https://flecart.github.io/notes/onde-elettromagnetiche/","summary":"$$\n\\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} \n$$$$\n\\vec{\\nabla} \\times \\vec{E} =  - \\frac{\\delta \\vec{B}}{\\delta t}\n$$\u003cp\u003e\nCon questi abbiamo le onde elettromagnetiche.\u003c/p\u003e\n\u003cp\u003eNel vuoto possiamo dire che \u003cem\u003enon abbiamo densit√† di corrente\u003c/em\u003e, per questo posso andare nel vuoto, sono due cose che si autosostengono.\nSono \u003cstrong\u003esimmetriche a meno di costante\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eQuesto ci dice che\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ePreso un campo elettrico che varia nel tempo (tipo una carica oscillante).\u003c/li\u003e\n\u003cli\u003eQuesto mi dice che si genera un campo magnetico prima non esistente\u003c/li\u003e\n\u003cli\u003eQuesto campo che varia nel tempo va a creare un altro campo elettrico\u003c/li\u003e\n\u003cli\u003eQuindi abbiamo un processo che continua cos√¨ all\u0026rsquo;infinito sostenendosi.\nIn queste due equazioni abbiamo la luce.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e2 circuitazioni\n2 Leggi di gauss\ne le 4 equazioni di Maxwell sono in grado di descrivere tutti i fenomeni elettromagnetici.\u003c/p\u003e","title":"Onde elettromagnetiche"},{"content":"In this note we will briefly present one problem common in operation research. The practical needs that formulated this problem are quite obvious: choosing the best location to build some important services for communities.\nThe optimal minimax facility location refers to the placement of a facility (such as a warehouse, hospital, or service center) in such a way that the maximum distance or cost between the facility and any of the demand points (such as customers, patients, or users) is minimized. This approach is particularly useful when the goal is to ensure that no demand point is too far from the facility, thus providing a form of equity in service delivery.\nKey Concepts: Minimax Objective: The primary goal is to minimize the maximum distance (or cost) from the facility to any demand point. This is in contrast to other objectives, such as minimizing the total or average distance.\nFacility Location Problem: This is a classic problem in operations research where the aim is to determine the best location for one or more facilities to serve a set of demand points efficiently.\nDemand Points: These are the locations that the facility needs to serve. They could be customers, population centers, or other entities requiring service.\nDistance Metric: The distance can be measured in various ways, such as Euclidean distance, Manhattan distance, or travel time, depending on the context.\nMathematical Formulation: Given a set of demand points $D = \\{d_1, d_2, \\ldots, d_n\\}$ and a potential facility location $F$, the minimax facility location problem can be formulated as:\n$$ \\text{Minimize } \\max_{i} \\text{distance}(F, d_i) $$Where:\n$\\text{distance}(F, d_i)$ is the distance between the facility $F$ and the demand point $d_i$. Solution Approaches: Geometric Median: In some cases, especially with Euclidean distances, the optimal minimax facility location can be found using the geometric median, which minimizes the maximum distance to any point.\nVoronoi Diagrams: These can be used to partition the space into regions based on distance to the facility, helping to identify the optimal location.\nLinear Programming: For more complex scenarios, linear programming techniques can be employed to find the optimal location.\nHeuristics and Metaheuristics: For large-scale problems, heuristic methods like genetic algorithms, simulated annealing, or tabu search might be used to find a near-optimal solution.\nApplications: Emergency Services: Placing hospitals or fire stations so that the maximum response time is minimized. Logistics: Locating warehouses to ensure that no customer is too far from a distribution center. Telecommunications: Positioning cell towers to minimize the maximum distance to any user. One view that we need is in ProbCover, explained in Active Learning.\n","permalink":"https://flecart.github.io/notes/optimal-minimax-facility-location/","summary":"\u003cp\u003eIn this note we will briefly present one problem common in operation research.\nThe practical needs that formulated this problem are quite obvious: choosing the best location to build some important services for communities.\u003c/p\u003e\n\u003cp\u003eThe optimal minimax facility location refers to the placement of a facility (such as a warehouse, hospital, or service center) in such a way that the \u003cstrong\u003emaximum distance or cost\u003c/strong\u003e between the facility and any of the demand points (such as customers, patients, or users) is minimized. This approach is particularly useful when the goal is to ensure that no demand point is too far from the facility, thus providing a form of equity in service delivery.\u003c/p\u003e","title":"Optimal Minimax Facility Location"},{"content":"Metodi altri sono trovare una approssimazione facile da calcolare (simile all\u0026rsquo;approccio del modello surrogato credo). Ma nel nostro caso proviamo a trovare metodi di esplorare lo spazio dei parametri in modo intelligente.\nDeterministic methods Sono utilizzabili quando ci sono delle propriet√† come convessit√†, limitatezza, continuit√†.\nNewton Raphson method Molte implementazioni in R usano questo metodo, √®\nPerfetto quando $h$ √® quadratico, e in statistica molti problemi sono quadratici e funziona in modo perfetto Ma in cose non lineari si ha meno performance (perch√© l\u0026rsquo;hessiana √® molto instabile per l\u0026rsquo;inversione, si dice che √® mal condizionata, e si fa con attenzione.) l\u0026rsquo;unica cosa da sapere secondo me √®\n$$ f(x) = x - H^{-1}\\nabla f(x) $$ Vedere Equazioni non lineari per dimostrazione del perch√© viene utilizzata\nStochastic methods Stochastic search In pratica faccio uniform su tutto il dominio, e tengo il maggiore come la soluzione, solo che\nDifficile da calcolare Soffre di problemi di scaling Ha bisogno che la funzione sia facile da valutare. La caratteristica negativa √® che spende tempo anche per zone di poco interesse, perch√© d√† stessa importanza a tutto. Sarebbe buono provare a fare sampling in modo proporzionale al valore di $h(\\theta)$\nMax of function = mode of the distribution, if that is a density! Quindi se faccio sampling usando quella funzione come densit√† riesco a trovare il massimo!\nStochastic gradient methods √à una categoria di algos.\nRandom walk $$ \\theta_{j+1} = \\theta_{j} + \\varepsilon_{t} $$ In cui $\\varepsilon$ √® una variabile aleatoria, questo √® anche una catena di markov. Questo √® un random walk approach. (che √® stupido perch√© comunque non sto utilizzando nessuna informazione sulla funzione!)\nGradient descent Questo lo sai. Solo che in questo caso viene fatta una sequenza di pesi (non √® un learning rate)\u0026hellip; Solo che soffre molto facilmente sulla possibilit√† di stuck su minima o maxima.\nC\u0026rsquo;√® anche una versione stocastica, in cui si una una versione approssimata del gradiente (che strano, di solito questa informazione √® disponibile). (si utilizza la definizione di gradiente in pratica, quindi si usa una variabile random sullo step\u0026hellip;)\n$$ \\nabla h(\\theta) \\approx \\frac{h(\\theta_{j} + \\beta_{j} \\gamma) - h(\\theta_{j} - \\beta_{j} \\gamma)}{2\\beta_{j}} $$ in cui ho di nuovo una sequenza di $\\beta$ che mi definisco io, solo che $\\gamma$ √® sampling da sfera unitaria, √® un tentativo di perturbare la discesa, in modo da non essere stuck in minimi o massimi locali.\nPoi l\u0026rsquo;update diventa\n$$ \\theta = \\theta - \\frac{\\alpha_{i}}{2\\beta_{i}} \\nabla h(\\theta)\\gamma $$Simulated Annealing Boltzmann-Gibbs transform quando proviamo in local search un sampling basato su local search minima.\nWe want to sample a sequence proportional to the time! $\\propto \\frac{\\exp(h(\\theta))}{T}$\n$$ \\pi_{i}(\\theta) \\propto L(0)^{T} \\pi_{0}(\\theta) $$ Dove $\\pi_{0}$ √® la distribuzione di densit√† iniziale, mentre l\u0026rsquo;altro √® una costante. questo approccio si chiama prior feedback approach.\nIl tempo possiamo sceglierlo di farlo scendere in molti modi\nLogaritmico Geometrico Metropolis hastings Vogliamo utilizzare la trasformata di boltzmann-gibbs per fare sampling del nuovo valore $\\theta$ seguendo quello.\nAlgo:\nPrendo $y$ da una distribuzione $g$, tale che sia simmetrica per questo motivo utilizzo una gaussiana. (anche questo deve essere scalato col tempo). Poi faccio sampling condizionale: (con probabilit√† $p$ posso sommare, con probabilit√† $1- p$ rimane la stessa). La cosa in pi√π √® che mi muovo con probabilit√† (la scelta stocastica) √® la differenza con random walk\u0026hellip; In particolare $p$ non √® costante ma cambia nel tempo, ed √® calcolata come: $$ p = min\\left( \\exp\\left( \\frac{\\Delta h}{T} \\right), 1 \\right) $$ Con $h = h(\\theta + y) - h(\\theta)$, una osservazione √® che se √® positiva, allora √® sempre maggiore di 1, quindi mi muovo sempre (qui √® equivalente a random walk). Altrimenti vorrei essere pi√π conservativo, e restare di pi√π con la stessa posizione. Ma allora continuo a muovermi di meno col tempo. Linear Programming See Programmazione lineare.\nEM Algorithms See Clustering\n","permalink":"https://flecart.github.io/notes/optimization-methods/","summary":"\u003cp\u003eMetodi altri sono trovare una \u003cstrong\u003eapprossimazione\u003c/strong\u003e facile da calcolare (simile all\u0026rsquo;approccio del modello surrogato credo).\nMa nel nostro caso proviamo a trovare metodi di esplorare lo \u003cstrong\u003espazio dei parametri\u003c/strong\u003e in modo intelligente.\u003c/p\u003e\n\u003ch3 id=\"deterministic-methods\"\u003eDeterministic methods\u003c/h3\u003e\n\u003cp\u003eSono utilizzabili quando ci sono delle propriet√† come convessit√†, limitatezza, continuit√†.\u003c/p\u003e\n\u003ch4 id=\"newton-raphson-method\"\u003eNewton Raphson method\u003c/h4\u003e\n\u003cp\u003eMolte implementazioni in R usano questo metodo, √®\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePerfetto quando $h$ √® quadratico, e in statistica molti problemi sono quadratici e funziona in modo perfetto\u003c/li\u003e\n\u003cli\u003eMa in cose non lineari si ha meno performance (perch√© l\u0026rsquo;hessiana √® molto instabile per l\u0026rsquo;inversione, si dice che √® mal condizionata, e si fa con attenzione.)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003el\u0026rsquo;unica cosa da sapere secondo me √®\u003c/p\u003e","title":"Optimization methods"},{"content":"XOR operation √à una operazione binaria abbastanza semplice per√≤ ci sar√† importante per andare ad analizzare dei cifrari di un certo genere. Come il ONE TIME PAD che faremo fra poco in OTP and Stream Ciphers.\nTeorema cifratura con XOR Prendiamo $X$ una variabile aleatoria in $\\left\\{ 0,1 \\right\\}^{n}$ uniforme, sia $Y$ una variabile aleatoria su uno stesso dominio come vogliamo. Tali per cui $X, Y$ siano indipendenti Allora avremo che $C = X \\oplus Y$ √® una variabile aleatoria uniforme.\n$$ \\mathbb{P}(C=0) = \\mathbb{P}((X,Y) = (0,0)) + \\mathbb{P}((X, Y) =(1,1)) = \\frac{p_{0}}{2} + \\frac{p_{1}}{2} = \\frac{1}{2} $$ Quindi $\\mathbb{P}(C=1) = \\frac{1}{2}$ e si continua provando ad aggiungere parti.\nOne Time Pad Cipher Inventato da Vernam 1917. e 1926 sempre lui, infatti questo √® il cipher che √® nella teoria veramente unbreakable! Lo ha chiamato BSS = Binary Symmetric source, vedi: https://cs.ioc.ee/yik/schools/win2006/massey/slides1.pdf\nDescrizione del cipher üü© $$ E(k, m) = k \\oplus m $$$$ D(k, C) = k \\oplus C $$La cosa importante √® che $k$ √® usato solo una volta, altrimenti ho problemi di sicurezza molto importanti (vedi many-time-pad). Una altra cosa importante √® che $k$ sia uniforme, che poi usando il teorema di XOR di sopra, possiamo avere massima sicurezza (entropia massima)\nNecessit√† del mezzo comunicativo üü®++ Ci sono anche restrizioni sulla generazione e sulla conoscenza della chiave dai due parties che cercano di comunicare! Dimostrazione segretezza perfetta üü© Si basa sulla definizione in Classical Cyphers#Security of the Key.\nVogliamo dimostrare $\\mathbb{P}(E(k, m_{0}) = c) = \\mathbb{P}(E(k, m_{1}) = c)$, assumendo di fare sampling di $k$ in modo uniforme.\n$$ \\forall m,c: \\mathbb{P}(E(k, m) = c)] = \\frac{\\#\\text{Chiavi tali per cui } E(k,m) = c}{\\lvert K \\rvert } $$ Va vale il fatto che $\\forall m, c$ $\\#\\left\\{ k \\in K: E(k, m) = c \\right\\} = 1$ Quindi abbiamo la segretezza. (√® 1 perch√© con OTP √® unica la chiave che viene utilizzata per ottenere quello).\nQuesto √® importante perch√© dimostra che non esistono attacchi ciphertext only per OTP\nSvantaggi OTP üü© La difficolt√† di utilizzo di OTP, nonostante le forti garanzie teoriche √® dalla lunghezza della chiave. Vedi Classical Cyphers#Security of the Key per maggiori dettagli.\nLa chiave deve avere stessa lunghezza del messaggio (overhead, difficolt√† per mandare messaggi lunghi) Distruzione della chiave dopo l‚Äôutilizzo (che si fa solo una volta!) La comunicazione della chiave. Per questo motivo non si utilizza per applicazioni commerciali.\nAttacks on OTP Many time pad attack üü®+ $$ c_{1} \\oplus c_{2} = k \\oplus m_{1} \\oplus k \\oplus m_{2} = m_{1} \\oplus m_{2} $$Questo √® stato usato nel verona project (\u0026lsquo;41 - \u0026lsquo;80)\nAmerican National Security Agency decrypted Soviet messages that were transmitted in the 1940s. That was possible because the Soviets reused the keys in the one-time pad scheme.\nNel caso vecchio di MS-pptp √® stato possibile attaccarlo, perch√© la chiave viene riutilizzata per server-client e client to server. Stessa cosa per il WEP.\nNo integrit√† üü© Un attaccante pu√≤ cambiare a suo piacimento il valore del plaintext iniziale, questo √® soprattutto utile se sa bene cosa cambiare, altrimenti un umano probabilmente pu√≤ capire che il messaggio √® senza senso, ma nella teoria √® giusto, il ricevente non pu√≤ capire se il messaggio √® stato modificato, o originariamente √® stato mandato cos√¨:\nSe attaccante modifica $c$ creando $c^{*} = c \\oplus p$ il ricevente avr√† $m \\oplus p$ quindi √® modificato, e non sa che √® stato cambiato.\nNOTA particolare Questo attacco √® particolarmente pericolo quanso\nSi sa la posizione del testo da cambiare Si sa il contenuto del testo cifrato in quella posizione. Se si hanno queste informazioni posso metterci un valore a piacere in quella zona. Questa cosa dovresti riuscire a capire perch√© sia cos√¨. Ad alto livello ti dico: fai xor con quella parte di testo, cos√¨ hai 0 in plaintext, poi rifai xor col tuo messaggio per metterci quello che ti pare. Real-world attacks L\u0026rsquo;unico takeaway √® non usare chiavi ripetute, che vedi sopra.\nWindows NT PPT (non fare) Perch√© veniva ripetuta la chiave sia client che server\nWEP (non fare) IV veniva ripetuta ongi 16M frames, che era presente Le chiavi generate per i vari frame sono molto correlate, perch√© cambia solo IV in seguente (dice la prof. che inviava anche in chiaro). Non so esattamente i dettagli ma non dovrebbe essere importante. Stream Ciphers Now we talk about stream ciphers, next about block ciphers, after that asymmetric cipher.., con questra struttura\nIntroduction Motivation and basic stuff üü© LSM was first kind of crypto for cellphones, and it was a stream cipher (fast, at least 12 y ago confronted with the other ciphers that existed).\nEncrypting individual bits! when block ciphers encrypt blocks of it. This leads to simple encryption and decryption operations. (this is a big addendum! most of embeeded devices use this because its easy and fast!) The hardware is nice for these cyphers. Standard template of encrypt decrypt (non fare) And we can note it‚Äôs an shift cipher (affine cipher) discussed in the Classical Cyphers.\nA note is that the decryption uses the Plus! This is because we are in modulus 2, and a sum is actually a xor operation. (see the logic table of it).\nProof of why the two operations are the same\nSempre dalla tavola logica si pu√≤ vedere che uno 0 pu√≤ essere criptato 50% a 0 e 50% a1, quindi √® resistente ad attacchi di analisi delle frequenze (ma questo solo se ho un generatore randomico buono !).\nRandom generators As the security of the scream cipher is dependent on the keys, we need to have a way to generate random keys.\nCategories of random number generators (3) (non fare) Cercare su Randomness per descrizione sul tema.\nTrue Random Number Generators tipically from random physical processes ma non riesco a farlo moltro in fretta\nLancio di dati Rumore Movimento del mouse. Random keyboard types. (e distanza tempo fra di essi). Pseudo-random Number Generators (vorremmo qualcosa di random, ma che possa produrre la stessa sequenza deterministic\nMost of these are not criptografically secure! (are usually predictable, so useless for cryptography). But they satisfy important statistical properties necessary for randomness (and tests) Forma classica di computazione\nCryptographically Secure PRNGs (same as PRNGs, but with unpredictability).\nDefinition of unpredictability\nCio√® non riesco a predire in che modo la sequenza pu√≤ continuare in tempo polinomiale, data una sequenza di bits di output. Definizione PRNG √à una funzione $\\left\\{ 0, 1 \\right\\}^{s} \\to \\left\\{ 0, 1 \\right\\}^{n}$ in cui $s \\ll n$ computabile da funzioni deterministiche, con solo il seed che √® l\u0026rsquo;input al randomness. In teoria gli algoritmi possono generare cose infinite, ma per quanto ci interessa, vogliamo restringerci solamente a un numero finito di bit in output (che √® cosa nella pratica abbiamo) Una cosa √® che l\u0026rsquo;algoritmo che li genera √® deterministico, compattabile diciamo con Kolmogorov complexity, ma con buoni security guarantees e anche statistiche, vedi Randomness. √à importante che quanto prodotto sembri essere random.\nOPT tramite PRNGüü© Possiamo usare #One Time Pad Cipher usando i PRNG! Cos√¨ risolviamo il problema di comunicazione di cose troppo grosse.\nAnalisi sicurezza stream cipher con PRNG Non abbiamo segretezza perfetta. Solamente che abbiamo la nota teorica in Classical Cyphers#Security of the Key che non possiamo avere sicurezza se la chiave reale √® minore rispetto a quella reale.\nStiamo spostando la sicurezza dell\u0026rsquo;OTP sul seed che genera. Abbiamo bisogno di una nuova definizione di sicurezza.\nExamples of PRNGs Questi sono stati analizzati tempo fa da Knuth nell\u0026rsquo;art of computer programming.\nLinear Congruential Generatorüü© abbiamo una sequenza $r_{0} = seed$ e $r_{i+1} = a \\cdot r_{i} + b \\mod p$ Sembra che questa cosa molto semplice abbiamo propriet√† statistiche Randomness molto carine, ma molto facile da scoprire.\nglibc random (non impo) $r_{i} = (r_{i - 3} + r_{i - 31}) \\mod 2^{32}$ in cui gli index sono dei singoli bit credo Poi viene ritornato $r_{i} /2$ per qualche motivo\nNota: questo non √® sicuro per√≤ come generatore!\nSecurity necessities for PRNGs Non predictability Possiamo definire che un PRNG √® predictable se esiste $i \\in N$ tale per cui avendo la sequenza $x_{0}, x_{1}, \\dots, x_{i}$ esista un algoritmo computabile secondo La macchina di Turing e che sia anche efficiente tale per cui possa calcolare $x_{i+1}, \\dots$. con una probabilit√† alta. Se vale questo, e possono trovare l\u0026rsquo;algoritmo che computa questo algoritmo, avrei tutto poi per decifrare il messaggio (known plain-text attack), anche se non conosco la chiave iniziale.\n$$ \\mathbb{P}_{k \\leftarrow K} \\left[ A(G(k)|x_{1},x_{2}, \\dots, x_{i}) = G(k)|x_{i+1}\\right] \\geq \\frac{1}{2} + \\varepsilon $$$$ \\forall i \\text{ no \"eff\" adv. can predict bit } (i + 1) \\text{ for \"non-negligible\" }\\varepsilon $$Definition of negligibility Usiamo negligible e simili per avere un rule of thumb per capire ogni quanto non viene mantenuta la propriet√†.\n$\\varepsilon \\geq \\frac{1}{2^{30}}$ significa che ogni 1GB di data ho un caso in cui succede. Se ho $\\varepsilon \\leq \\frac{1}{2^{80}}$ non avverr√† tipo mai. La cosa √® che questo non √® molto rigoroso. Nella teoria possiamo definirli come funzione di un parametro di sicurezza. $$ \\varepsilon : \\mathbb{Z}^{\\geq 0} \\to \\mathbb{R}^{\\geq 0} $$ $$ \\text{ non neg: } \\exists d: \\varepsilon(\\lambda) \\geq \\frac{1}{\\lambda^{d}} $$ $$ \\text{ negligible } \\forall d, \\lambda \\geq \\lambda_{d} : \\varepsilon(\\lambda) \\leq \\frac{1}{\\lambda^{d}} $$ la cosa che ci interessa di negligible, √® simile al limite, √® qualcosa che cresce con $\\lambda$ che va sempre gi√π Statistical Tests e Advantage Qui viene definito solo come un algoritmo che ritorna 0 o 1 dopo che gli diamo la stringa iniziale in input. Per dire se √® random oppure non. Note migliori dovrebbero essere in Randomness.\nCon questo test e la possibilit√† di definire una sequenza truly random $r$ possiamo definire il concetto di advantage che in breve √® quanto bene riusciamo a distinguere la PRNG dal random vero. A me sembra abbastanza inutile questa definizione. Per√≤ pu√≤ essere utile per definire che il PRNG non √® abbastanza simile al random. L\u0026rsquo;intuizione principale √® che lo spazio $\\left\\{ 0, 1 \\right\\}^{n}$ √® molto pi√π ampio rispetto alle stringhe effettivamente generabili da $k$ sampling da $K$. Per√≤ vogliamo che statisticamente siano indistinguibili. La misura di advantage ci dice quanto sono distinguibili.\nL\u0026rsquo;algoritmo $A$ √® spesso chiamato oracolo.\nSecurity with advantage Secondo la prof. questa \u0026ldquo;advantage\u0026rdquo; √® una misura di quanto il sistema √® rompibile. Se √® simile a 1 sono abbastanza sicuro, altrimenti √® 0.\n$$ Adv_{PRNG}[A, G] \\leq \\varepsilon $$ dove $\\varepsilon$ √® molto molto piccolo, negligible si potrebbe dire. Sembra che questo problema si riduca a $P \\not= NP$ per qualche motivo strano. Queste sono definizioni con oracolo perch√© assumiamo di avere un $r$ che √® truly random.\nQuesta definizione comunque secondo (Stinson 2005) chapt 6.9 √® molto difficile da raggiungere, perch√© troppo facile da rompere, perch√© tratta di leaks di informazione, ma solitamente di molto poco conto.\nConseguenza su P e NP Se si riesce a dimostrare che esiste un $PRG$ sicuro sotto questa definizione si pu√≤ dimostrare che $P \\neq NP$ vedi Time and Space Complexity.\nPredictable =\u0026gt; insecurity Suppose you have a predictable $PRG$, that is $\\mathbb{P}_{k \\sim K}\\left[ A(G(k)\\mid_{1,\\dots,i}) = G(k) \\mid_{i = 1} \\right] \\geq \\frac{1}{2} + \\varepsilon$ We can have a statistical test with non negligible security. Let\u0026rsquo;s define\n$$ B(x) = \\begin{cases} \\text{ if } A(X \\mid_{1,\\dots,i}) = X_{i+1} \\text{ output } 1 \u0026 \\\\ \\text{ else output } 0 \\end{cases} $$ If $r \\sim_{R} \\left\\{ 0, 1 \\right\\}^{n}$ this statistical test gives $\\frac{1}{2}$ because we have supposed it is not predictable. If we have the predictable sequence, by definition we can predict with $\\frac{1}{2} + \\varepsilon$ so the advantage is greater than $\\varepsilon$ so it is insecure given this definition.\nWe have now proved that secure -\u0026gt; unpredictability. We can also prove unpredictability -\u0026gt; security (this is Yao'82). So these are equivalent.\nsecure PRG -\u0026gt; semantically secure stream cipher $$ Adv_{SS}\\left[ A, Q \\right] \\leq 2 \\cdot Adv_{PRG}\\left[ B,G \\right] $$ Given $G$ a secure $PRG$ and $Q$ the stream cipher derived from $G$.\nSemantic security Why is semantic security important? see here. It relates to the notion \u0026ldquo;no information about the plaintext from the ciphertext\u0026rdquo;. It can be viewed as a relaxed version for Classical Cyphers#Security of the Key. The idea has subtle connotations. This restricts the perfect secrecy idea onto computationally plausible scenarios, where you assume that a computational entity can\u0026rsquo;t distinguish it.\nDefinizione semantic security Da https://en.wikipedia.org/wiki/Semantic_security\na¬†semantically secure¬†cryptosystem¬†is one where only negligible information about the¬†plaintext¬†can be feasibly extracted from the¬†ciphertext.\nDa un punto di vista teorico, questo √® un rilassamento della nozione di Classical Cyphers#Security of the Key, in cui si richiede che siano uguali, in questo setting richiediamo che siano solo vicine le due probabilit√†. Solo che sembra che sia inutile la nozione per s√© quindi introduciamo l\u0026rsquo;esperimento.\nNelle slides si fa un gioco di questo genere:\nChallenger e adversary L\u0026rsquo;avversario invia due messaggi in chiaro, Challenger invia i messaggi cifrati L\u0026rsquo;obiettivo dell\u0026rsquo;avversario √® identificare quale ciphertext coincide a quale messaggio, se si pu√≤ fare, non √® sicuro secondo la definizione di semantic security di sopra, anche se non so nella pratica quanto sia vero. Questo √® vero quando #Security with advantage √® negligible, quindi non si pu√≤ fare. Per il prof. √® leggermente diverso rispetto a questo:\nProbabilit√† di associare il ciphertext al corrispettivo plaintext.\nQuesto si pu√≤ riassumere in questo: Ossia non √® in grado di distinguere la funzione fatta con chiave da una funzione a caso nell\u0026rsquo;insieme delle funzioni. E quindi per l\u0026rsquo;avversario entrambi i plain-text sembrano essere uguali e non ha advantage.\nSemantic security for many-time key Abbiamo ora che la chiave √® usata pi√π di una volta, quindi abbiamo molte coppie, magari anche qualche plain-text, vogliamo chiederci in teoria se √® possibile usare la stessa chiave e avere ancora lo stesso livello di sicurezza. Questo pattern √® molto comune, IPsec, criptare dischi\u0026hellip; Infatti pu√≤ scegliere quale plain-text avere a suo piacimento, si chiama chosen plain-text.\nOssia pu√≤ scegliere quanti messaggi vuole per un certo esperimento\nThe challenger chooses a $b$ to compute, then adversary can send messages and receive ciphertexts how many times as he likes. Security of same ciphertext under CPA If the cipher outputs the same message when encrypting the same plain-text, it can be proven that it has not CPA security. This urges the creation of ciphertexts that need to create different ciphertexts with the same plaintext!\n##### Nonce based-security L'idea √® la stessa di cui abbiamo parlato in [Sicurezza delle reti](/notes/sicurezza-delle-reti) per un protocollo di autenticazione. Un esempio carino di questo √® in [Block Ciphers#Cipher Block Chaining (CBC)](/notes/block-ciphers#cipher-block-chaining-(cbc)) per cercare di randomizzare l'IV. Semantic security for Chosen Ciphertext This definition is used for public encryption schemes. Two phases.\nAdversary can ask for decriptions of any ciphertext. Then classically sends two messages, and receives a ciphertext Then can again send ciphertext again, except for the ciphertext he received Then outputs $0$ or $1$. Practical stream ciphers In questo caso andiamo ad utilizzare un PRNGs, non pi√π truly random, per le ragioni di efficienza di comunicazione‚Ä¶\nla chiave sono i valori delle cose affini nel LCG.. (forse anche il seed? boh)\nRC4 cipher Non so bene come √® stato creato questo algoritmo, probabilmente provato cose a caso??? Questo √® stato inventato da Ron Rivest, lo stesso che ha inventato l\u0026rsquo;algoritmo di RSA del 1987.\nInizializzazione Usiamo il seed $s$ per inizializzare una permutazione dei primi 256 numeri\nS[i] \u0026lt;- arange(0, 257) s = len S j \u0026lt;- 0 for i \u0026lt;- 0 to 255 do: k \u0026lt;- S[i mod s] j \u0026lt;- (j + S[i] + k) mod 256 swap(s[i], s[j]) Con questo algoritmo in pseudocodice\nGenerazione (non fatta) #### Attacchi üü® Non segue la definizione di [Classical Cyphers#Security of the Key](/notes/classical-cyphers#security-of-the-key), c'√® del bias in quanto generato che si pu√≤ sfruttare in modo abbastanza semplice, per esempio si pu√≤ attaccare WEP che usava questo algoritmo in questo modo. ### Content Scrambling System (non fatto) Ma Dan Boneh parla di [#Linear Feedback Shift Registers](#linear-feedback-shift-registers) in questa sezione. eStream Cypher Si ha solitamente un nonce in questo caso, lo stesso che abbiamo usato in Sicurezza delle reti. Quindi un valore randomico utilizzato una singola volta\nSalsa 20 √à un algoritmo moderno di stream cipher, solitamente implementato in hardware per velocit√†. Prende una chiave 256 bit e un nonce di 64. Utilizza questo per fare un mix di 20 rounds e poi produrre ili bit stream utilizzato per encodare il plaintext iniziale. Questo √® ancora sicuro, attacchi esistenti non riescono a romperlo totalmente pagina wiki Veloce che fa Mezzo giga al secondo di cifrazione.\nLinear Feedback Shift Registers This is a way to create a stream of bits to xor with the message. This stream is generated with a key. One of the advantages is that it‚Äôs low power in hardware.\nShift registers You have to remember flip flops by Circuiti Sequenziali in architecture.\nCoso per storare un singolo bit sincronizzato dal clock del computer. La cosa interessante quando si collegano input e output fra flipflops diversi, √® che ad ogni ciclo di clock, si ha una specie di onda che shifta tutti i bit! Quando l‚Äôoutput √® rixorato in certi modi e rimesso all‚Äôinizio, ecco che riusciamo ad avere il feedback lineare!\nEsempio di mini Linear feedback Shift register\nEsempio di LFSR generalizzato\nMatematical Description Con p, per dire se √® 0 o 1 (o aperto o chiuso). E poi in pratica √® l‚Äôoperazione di +, o xor.\nWe want to have a LSFR which has a very long period\nPossiamo anche descrivere un LSFR con dei polinomi. In particolare √® importante sapere\nil numero dei registri Le porte che sono aperte e quelle che sono chiuse. $$ P(x) = x^{m} + p_{m - 1}x^{m - 1} + \\dots + p_{1}x + p_{0} $$ Per√≤ non so ancora perch√© questa rappresentazione del LSFR √® utile, boh, lasciamo star.\nTheorem on the period of LSFR L‚Äôidea della dimostrazione √® tipo che gli stati interni della LSFR √® al massimo $2^m - 1$, quindi al massimo il periodo √® quello. (non posso avere 0 perch√© senn√≤ avrei periodo di 1, che non serve a niente).\nMa non tutti hanno periodo massimo! Forse centrano qualcosa i polinomi ciclotomici, per√≤ sta fuori dalla mia capacit√† matematica lol.\nEsempi di LSFR massimi e non\nKnown Plaintext Attacks Il nemico conosce\nTutto il ciphertext il grado dell‚ÄôLSFR (se non lo sa fa bruteforce, e quindi √® come se lo sapesse) Conosce i primi 2m bits del plaintext, quindi sa i primi 2m bits generati. Dal plaintext conosciuto, vorremme ricavare tutti i bits successivi di questo stream cipher. (basta ricavare i valori dei p, ora vediamo un metodo per ricavarli).\nDato che possiede 2m bits conosciuti e conosce m, deve risolvere un sistema di m incognite e m equazioni, e questo si fa, quindi cos√¨ riesce a ricavare LSFR da queste!\nReferences [1] Stinson ‚ÄúCryptography: Theory and Practice, Third Edition‚Äù CRC Press 2005\n","permalink":"https://flecart.github.io/notes/otp-and-stream-ciphers/","summary":"\u003ch3 id=\"xor-operation\"\u003eXOR operation\u003c/h3\u003e\n\u003cp\u003e√à una operazione binaria abbastanza semplice  per√≤ ci sar√† importante per andare ad analizzare dei cifrari di un certo genere. Come il ONE TIME PAD che faremo fra poco in \u003ca href=\"/notes/otp-and-stream-ciphers.\"\u003eOTP and Stream Ciphers.\u003c/a\u003e\u003c/p\u003e\n\u003ch4 id=\"teorema-cifratura-con-xor\"\u003eTeorema cifratura con XOR\u003c/h4\u003e\n\u003cp\u003ePrendiamo $X$ una variabile aleatoria in $\\left\\{ 0,1 \\right\\}^{n}$ \u003cstrong\u003euniforme\u003c/strong\u003e, sia $Y$ una variabile aleatoria su uno stesso dominio come vogliamo. Tali per cui $X, Y$ siano indipendenti\nAllora avremo che $C = X \\oplus Y$ √® una variabile aleatoria \u003cstrong\u003euniforme\u003c/strong\u003e.\u003c/p\u003e","title":"OTP and Stream Ciphers"},{"content":"Memoria sistema Operativo Guradare Memoria virtuale Per vedere come vengono rimpiazzate le pagine\nIn quest sezione andiamo a parlare di come fanno molti processi a venire eseguiti insieme, anche se lo spazio di memoria fisico √® lo stesso. Andiamo quindi a parlare di spazio di indirizzi, risoluzione di questi indirizzi logici, segmentazione e paginazione. (e molto di pi√π!)\nMMU Controlla se l‚Äôaccesso di memoria √® bono o meno. (traduzione fra indirizzo logico e fisico)\nCosa succederebbe se non fosse hardware?\nLa performance sarebbe molto peggiore. Sicurezza, si dovrebbe implementare uno mode switch e andare al kernel mode per accedere (syscall per accedere ad indirizzi di memoria), quindi non si utilizza mai, perch√© sarebbe ancora pi√π lentooo. Memory manager üü© Its job is to keep track of which parts of memory are in use and which parts are not in use, to allocate memory to processes when they need it and deallocate it when they are done, and to manage swapping between main memory and disk when main memory is too small to hold all the processes. (pg. 373 Tanenbaum)\nCOSA FA il MMEMORY MANAGER?\nTiene traccia della memoria libera Configura la MMU Binding (3) üü© In questo caso parliamo di associazione fra indirizzi logici e indirizzi fisici, in pratica ad altro livello, ma la stessa cosa. Nomi e Scope parliamo di binding fra variabili e nome della variabile.\nL√¨ abbiamo deciso 4 modi in cui si pu√≤ fare il binding! Sono molto simili rispetto a quelle, per√≤ ora stiamo parlando a un livello pi√π basso.\nBINDING A COMPILAZIONE\nDue istanze del programma non possono mai essere eseguiti CONTEMPORANEAMENTE, come per microcontrollori si pu√≤ fare una cosa simile.\nChiamato codice assoluto. perch√© √® mappato direttamente in una certa zona in fase di compilazione, non cambier√† MAI.\nStessi indirizzi per ogni esecuzione del programma.\nSlide binding compilazione\nSlide vantaggi e svantaggi\nBINDING A CARICAMENTO\nTutti gli indirizzi sono offsettati da un indirizzo 0.\nIn questo senso quando carico una istanza del programma, basta offsettare tutti gli indirizzi a un certo punto.\nSlide binding a caricamento\nSlide vantaggi e svantaggi\nSi pone pi√π onere al loader che deve sapere dove caricarti la roba. Per√≤ anche qui niente hardware!\nBINDING A ESECUZIONE\nAnche qui c‚Äô√® l‚Äôoffset, ma √® pi√π fine. L‚Äôeseguibile pensa di avere gli indirizzi offsettati da 0, poi a runtime la MMU traduce questo indirizzo logico all‚Äôindirizzo reale, che √® offsettato a qualcosa.\nSlide binding a esecuzione\nRegistri MMU Registro di locazione üü© In pratica abbiamo una tabella, molto simile a una tabella Network Address Translation di rete, ma con scopi molto diversi.\nAllo stesso modo in cui un pacchetto entra, viene fatto match nella tabella ed esce in modo diverso, abbiamo una registro di rilocazione che fa lo stesso JOB.\nSlide Registro di rilocazione\nSolitamente\nCodice Dati Stack Extra (utilizzi speciali, tipo copia da stack a dato o simili, praticamente usi come ti pare). Registro di limite üü© Questo nuovo registro permette di fare controlli sulla sicurezza. Praticamente fa check su indirizzi, se l‚Äôindirizzo soddisfa regola e.g. maggiore di 1000 allora manda avanti, altrimenti in errore\nSlide registro di limite\nLoading dinamico üü© Routine vengono caricate solo quando le chiamo, le abbiamo gi√† fatte in archietttura quando abbiamo parlato di traslazione di indirizzi dinamici 9.4.4 Indirizzamento dinamico. Generava una trap, e poi veniva trovato l‚Äôindirizzo corretto.\nLINKING STATICO E DINAMICO\nNota Loading ‚â† Linking!, per√≤ posso fare loading dinamico con linking dinamico. üòÄ\nStatico invece √® quando l‚Äôeseguibile ha tutte le funzioni che gli servono (copiate e incollate dentro l‚Äôeseguibile, senza dipendenze esterne, molto pi√π pesante, ma √® isolato, diciamo).\nSlide vantaggi svantaggi\nMINIDEMO LOADING\nProva a compilare un file e poi compilare con\n#include \u0026lt;stdio.h\u0026gt; int main() { puts(\u0026#34;eee\u0026#34;); } gcc -o out prova.c, normalmente linka dinamicamente, che puoi vedere con nm,\nse runni con la flag -static e fai la stessa cosa, allora vedi che il sinbolo √® definito.\nAllocazione pagine Definizioni: üü© ALLOCARE: Significa assegnare spazio di memoria fisica al programma.\nSTATICA DINAMICA,: se resta per l\u0026rsquo;intera vita del programma o meno.\nCONTIGUA O NON CONTIGUA: se la memoria mappata √® tutta a un filo senza buchi o meno.\nSlide definizioni\nPartizioni fisse üü® Questa √® una tecnica molto simile alla gestione della heap in blocchi fissi Gestione della memoria. In pratica ho delle partizioni fisse.\nSlide partizioni fisse\nSolitamente sono utili per sistemi Embedded, in cui non vuoi perdere tempo a fare conversioni, e vuoi questa cosa statica.\nPoi c‚Äô√® di nuovo il pippone della frammentazione interna ed esterta presente in Gestione della memoria, e in Livello OS. Si parla anche di soluzioni a questo, come la compattazione, ne abbiamo gi√† parlato, quindi qui sto zitto.\nNOTA SULLA COMPATTAZIONE:\nQuando voglio fare compattazione, devo interrompere certi programmi, copiare tutto il programma ad indirizzo diverso, cambio indirizzo di allocazione e poi lo posso far ripartire (quindi da stato running a ready dopo queste operazioni), per√≤ lentissimo!.\nBitmap üü© In pratica tutta la memoria viene divisa in qualche chunks di memoria, per esempio se ho in totale 1024 byte di memoria, potrei dividerla in blocchi da 32 byte, allora mi tengo una bitmap di 1024 /32 = 32, cos√¨ so che mi dovr√≤ tenere una bitmap di 32 bits, un bit mi indica 1 se ho usato quel blocco, 0 altrimenti.\nPer allocare in questa struttura di dati basta andare a cercare una serie di blocchi contigui liberi.\nSlide bitmap\nLinked list üü© Tutti i blocchi sono tenuti in una lista linkata, che ha un booleano per indicare se √® occupato o meno, e poi la lunghezza. L‚Äôallocazione √® uno scorrimento di questa lista linkata.\nSlide linked list\nQuando vengono deallocati, si pu√≤ utilizzare la compattazione parziale di cui abbiamo parlato in Gestione della memoria.\nSlide compattazione parziale\nCi sono altri generi di algoritmi, come next fit, oppure worst fit, per√≤ alla fine hanno performance molto peggiori rispetto a first o best fit. In generale questi problemi fanno ancora frammentazione, quindi non √® che siano buone buone buone come cose.\nPaginazione Le tecniche di paginazione nascono per essere una alternativa molto pi√π efficiente rispetto ai metodi di fitting precedenti, per questo motivo ora andiamo a descriverlo:\nAndare a guardare Algoritmi di paging per capire in che modo vengono gestite le pagine.\nDescrizione idee generale üü© La memoria del programma √® divisa in pagine, e poi questo √® messo nella memoria fisica dette frame, e sar√† gestita dalla MMU. La frammentazione interna esiste ma √® molto minimo, la frammentazione esterna non esiste proprio ora.\nSlide esempio di paginazione\nImplementazione della paginazione üü© Questa √® esattamente la parte che abbiamo spiegato in Livello OS, in pratica, l\u0026rsquo;indirizzo logico viene diviso in indirizzo di paginazione e indirizzo di memoria dentro la pagina stessa\nPer esempio se ho 4096 bit per una singola pagina (standard attuale), ho che nell‚Äôintero indirizzo della pagina √® data dai primi 20 bit, l\u0026rsquo;inddirizzo all‚Äôinterno della pagina dai next 12.\nEsempio di utilizzo della paginazione\nDESIGN DELLA PAGINAZIONE\nBlocchi potenza di due cos√¨ √® facile dividere gli indirizzi senza altre conversioni Non troppo grosso, cos√¨ fa meno frammentazione Non troppo piccolo, cos√¨ non ho troppe pagine. Storare la tabella delle pagine (2) üü© Dobbiamo trovare un modo per storare la tabella delle pagine, per esempio con un giga di memoria sarebbero circa un milione di pagine, storare in una tabella stile registri (come NAT di reti) √® troppo costoso come metodo.\nMettere in memoria, dovresti fare due accessi una nella page table, e una in memoria (e quindi molto lento!).\nQuindi vogliamo fare qualcosa di mezzo:\nLa page table sta in memoria In MMU sta una cache della page table per risoluzione di indirizzi recenti, guarda Memoria, questa si chaima Translation lookaside buffer, utilizzata la tecnica dei registri associativi, quelli che abbiamo utilizzato nell\u0026rsquo;implementazione dei Router in Data Plane, praticamente ti fanno ili confronto in modo immediato. Slide TLB\nEsempio tabella di pagine nuovo\nQuando il TLB missa, crea una trap, e iil sistema operativo rimette nella TLB quello che manca. Solitamente se sono grandi 10 celle √® gi√† sufficiente, perch√© principio di localit√† √® molto imporntante\nSegmentazione Introduzione idee segmentazione üü© Anche questo ne abbiamo gi√† parlato in architettura Livello OS.\nComunque divido il programma logicamente in diverse sezioni\nConcettualmente diversi (quindi regole di accesso diverse)\nLe singole aree contengono codice omogeneo (e.g. Testo ‚Üí area codice).\nEsempio di aree di segmentazione\nAllora se dividiamo in questo modo individiamo l\u0026rsquo;indirizzo logico come\n(nome-segmento, offset del segmento) ‚Üí indirizzo fisico.\nMa come fare a ricondurre questo con le pagine? Come metterlo dentro la MMU?\nVedremo l‚Äôutilizzo di una tecnica ibrida che unisce segmentazione con paginazione.\nConfronto con paginazione (!) üü®+ Slide differenze segmentazione e paginazione\nAllocare segmenti in memoria √® totalmente simile all‚Äôallocazione di zone di memoria contigue in memoria quindi devo tornare ad utilizzare algoritmi per memoria continua, per questo motivo ho forti problemi di frammentazione, quindi torno ad avere problemi come in precedenza!\nImplementazione segmentazione üü© Per i motivi di sopra, utilizzo la paginazione per andare con segmentazione, divido i segmenti in pagine!\nQuesto implica aumento della frammentazione interna. dato che per ogni segmento posso perdere pezzi nella pagina allocata (per√≤ alla fine √® molto ininfluente, al massimo 4k di ram per pagina)\nImplementazione slide\nEccesso del segmento ‚Üí segmentation fault ecco da dove deriva il nome üòÄ\n","permalink":"https://flecart.github.io/notes/paginazione-e-segmentazione/","summary":"\u003ch1 id=\"memoria-sistema-operativo\"\u003eMemoria sistema Operativo\u003c/h1\u003e\n\u003cp\u003eGuradare \u003ca href=\"/notes/memoria-virtuale/\"\u003eMemoria virtuale\u003c/a\u003e Per vedere come vengono rimpiazzate le pagine\u003c/p\u003e\n\u003cp\u003eIn quest sezione andiamo a parlare di come fanno molti processi a venire eseguiti insieme, anche se lo spazio di memoria fisico √® lo stesso. Andiamo quindi a parlare di spazio di indirizzi, risoluzione di questi indirizzi logici, segmentazione e paginazione. (e molto di pi√π!)\u003c/p\u003e\n\u003ch2 id=\"mmu\"\u003eMMU\u003c/h2\u003e\n\u003cp\u003eControlla se l‚Äôaccesso di memoria √® bono o meno.  (traduzione fra indirizzo logico e fisico)\u003c/p\u003e","title":"Paginazione e segmentazione"},{"content":"In this note we will first talk about briefly some of the main differences of the three main approaches regarding statistics: the bayesian, the frequentist and the statistical learning methods and then present the concept of the estimator, compare how the approaches differ from method to method, we will explain maximum likelihood estimator and the Rao-Cramer Bound.\nShort introduction to the statistical methods Bayesian üü© $$ p(\\theta \\mid X) = \\frac{1}{z}p(X \\mid \\theta) p(\\theta) $$The quantity $P(X \\mid \\theta)$ could be very complicated if our model is complicated.\nFrequentist üü© $$ \\hat{\\theta}_{ML} = \\arg \\max_{\\theta} \\log p_{\\theta}(x_{1}, \\dots, x_{n}) $$$$ \\hat{\\theta}_{ML} = \\arg \\max_{\\theta} \\log \\sum_{i = 1}^{n} p_{\\theta}(x_{i}) $$ This is how maximum likelihood estimators naturally arise with the frequentist approach. This is asymptotically true.\nUsually with enough data and big models, frequentist\u0026rsquo;s methods are preferred.\nStatistical learning üü© $$ \\hat{\\theta}_{SL} = \\arg \\min_{\\theta} \\mathcal{R}(f) = \\arg \\min_{\\theta} \\mathbb{E}_{X, Y} \\mathcal{L} (f(X), Y) $$$$ \\hat{R}(f) = \\frac{1}{n} \\sum_{i = 1}^{n} \\mathcal{L}(f(x_{i}), y_{i}) $$ And then choose the best $f$ from his family of functions\nThree problems in statistical learning The goal of statistical learning is to find a function $f : \\mathcal{X} \\to \\mathcal{Y}$ such that the error rate is minimized. We define the error rate to be just the cases where $f(x) \\neq y$. Let\u0026rsquo;s have so a simple model:\n$$ \\lim_{ n \\to \\infty } \\frac{1}{n} \\sum_{i= 1}^{N}\\mathbb{1} \\left\\{ f(x_{i}) \\neq y_{i} \\right\\} = \\mathbb{E}_{\\mathcal{x}, \\mathcal{y} \\sim p^{*}} [\\mathbb{1} \\left\\{ f(x) \\neq y \\right\\} ] $$$$ \\min_{f}\\mathbb{E}_{\\mathcal{x}, \\mathcal{y} \\sim p^{*}} [\\mathbb{1} \\left\\{ f(x) \\neq y \\right\\} ] $$ We don\u0026rsquo;t know anything about $f$, we need to have some assumptions, the easiest is to define a hypothesis class. We don\u0026rsquo;t know the starting distribution $p^{*}$, we solve this by collecting training samples so that we have an estimate of the starting distribution. (This is the fundamental problem in machine learning, we have empirical distribution, never the true distribution!) The risk $\\mathcal{R}$ is not differentiable, we solve this by choosing a loss function $\\mathcal{L} : \\mathcal{Y} \\times \\mathcal{Y} \\to \\mathbb{R}$ such that this is differentiable. We can write the starting problem in the following way as a proxy for the expected value. $$ \\min_{f \\in \\mathcal{H}} \\frac{1}{n} \\sum_{i \\leq n} \\mathcal{L} (f(x_{i}), y_{i}) $$ This image summarizes the whole pipeline Let\u0026rsquo;s have a simple example. Let\u0026rsquo;s attempt to chose the hypothesis class for the iris setosa classification problem. We arbitrarily choose $X$ and $Y$ to be\n$Y \\sim Bern(0.5)$ $X\\mid Y \\sim \\mathcal{N(\\mu_{y}, \\Sigma)}$ Then we can use Bayes rule to find $P(Y=y \\mid X = x) \\propto P(X = x \\mid Y = y) P(Y = y)$ and we can define then a simple loss, for example the classical binary cross entropy loss.\nBayesian and Frequentist head to head Estimators Estimators are functions or procedures that in this context of parametric models allow us to pin-point the correct parameters $\\theta$, in the case of the frequentist view, or give a distribution over possible $\\theta$s. Usually the generating function is called a density function parameterized by the $\\theta$ so we have to define the class of models and likelihood first.\nWe will mainly focus in this setting with the Maximum likelihood estimator\nThe Maximum Likelihood Estimator $$ \\mathcal{L}(\\theta) = \\prod_{i=1}^{n} f(X^{(i)} ; \\theta) $$Definition of MLE üü©\u0026ndash; $$ \\hat{\\theta}_{ML} = \\arg \\max_{\\theta} \\mathcal{L}(\\theta) $$Sometimes is useful to consider the log-likelihood because sums are usually easier to handle. We will indicate the log version with $\\ell(\\theta)$. Usually the loss is the likelihood of the data, this is why it\u0026rsquo;s called Maximum Likelihood estimator.\nProperties of the MLE üü®++ The important thing here is to be able to name the properties, not prove them. You can see a good presentation of these properties with (Wasserman 2004) chapter 9 (page 127 on wards). Three main properties concern us:\nConsistency: (meaning it will converge to the true parameter, if modelling assumptions are correct e.g. function family) In formula it means that a point estimator $\\hat{\\theta}_{n}$ of a $\\theta$ is consistent if it converges in probability which is: $$ \\forall \\varepsilon \u003e 0, \\mathbb{P}(\\lvert \\hat{\\theta}_{n} - \\theta \\rvert \u003e \\varepsilon) \\to_{n \\to \\infty} 0 $$ See Central Limit Theorem and Law of Large Numbers for definition of convergence in probability, the proof is not trivial and has many technicalities. Asymptotic efficiency: For well-behaved estimators, the MLE has the smallest variance for large $n$. - For example the median estimator satisfies $\\sqrt{ n } (\\theta_{\\text{ median}} - \\theta_{*}) = \\mathcal{N}\\left( 0, \\sigma^{2} \\frac{\\pi}{2} \\right)$, but the MLE doesn\u0026rsquo;t have that $\\pi$ factor. Asymptotically normal: meaning the error will be Gaussian if we have too many samples. Which means that $$ \\frac{\\hat{\\theta} - \\theta_{*}}{\\text{standard error}} \\sim \\mathcal{N}(0, 1) $$ Informally, this theorem states that the distribution of the parameters $\\theta$ that we find with MLE follows a normal distribution $\\mathcal{N}(\\theta_{*}, se)$. This theorem holds also for estimated standard errors. The interesting thing is that with this method we can build asymptotic confidence intervals for MLE, which can come quite handy in many occasions, and rival the bayesian approach for confidence intervals. The proof is quite hard, it is presented in the appendix of Chapter 9 of (Wasserman 2004). Equivariance meaning: if $\\hat{\\theta}$ is MLE of $\\theta$ then for any given $g$ we have that $g(\\hat{\\theta})$ is the MLE of $g(\\theta)$. I don\u0026rsquo;t know what is this useful for, but nice to know. We will discuss these properties one by one. These properties are the reason why MLE is preferred over other estimators, such as means or medians.\n$$ \\lim_{ n \\to \\infty } \\mathbb{E} \\left[ (\\hat{\\theta}_{ML} - \\theta_{0})^{2} \\right] = \\frac{1}{I_{n}(\\theta_{0})} $$ Where $I_{n}$ is the fisher information. Every estimator is lower bounded by this. (this is the maximum efficiency) and it\u0026rsquo;s very important.\nBiases usually are good if it includes information that is correct with the data. (helps it learn faster, an example of why bias works is the Stein estimator, but I didn\u0026rsquo;t understood exactly why). Simple cases and reasoning for first principles usually helps you build the intuition to attack more complex cases. This is something you would need to keep in mind.\nMLE is overconfident üü• TODO: see Sur and Candes 2018\nOne can show that there are many examples where logistic regression (see Linear Regression methods) is quite biased. This is a problem especially with high dimensional data. There are some numerical instabilities with correlated features, especially when we are trying to invert something small (floating point imprecisions!)\nYou can see it quite easily: Remember that the ordinary least squares solution is $(X^{T}X)^{-1}X^{T}y$, let\u0026rsquo;s suppose we use Singular Value Decomposition and write $X = V^{T}DU$ then we have $X^{T}X = U^{T}DVV^{T}DU = U^{T}D^{2}U$ Inverting this we get $U^{T}D^{-2}U$ and multiplying with the original one we get $\\beta = U^{T}D^{-1}Vy$ but the matrix $D^{-1}$ is quite unstable, especially when you are inverting small numbers.\nOne nice thing about this decomposition is that the inference is just $X\\beta = V^{T}Vy$ and that is a nice form.\nRao-Cramer Bound üü® Professor says this bound has same principle with the Heisenberg\u0026rsquo;s uncertainty principle with the Cauchy-Schwarz inequality somehow. But I don\u0026rsquo;t know about that.\nLet\u0026rsquo;s consider a likelihood $p(y \\mid \\theta)$, for $\\theta \\in \\Theta$ which is our parameter space, and some samples $y_{1}, \\dots, y_{n} \\sim p(y \\mid \\theta_{0})$, using a particular $\\theta_{0}$. We want to know how precisely can we estimate the value $\\theta_{0}$ given $n$ samples. So let\u0026rsquo;s define an estimator $\\hat{\\theta}$ and consider the expected deviation $\\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta_{0})^{2} \\right]$, which tells us how much can the estimated value $\\hat{\\theta}$ vary compared to the ground truth. One nice thing is that this holds for every distribution.\nScore function $$ \\Lambda := \\frac{ \\partial }{ \\partial \\theta } \\log p(y \\mid \\theta) = \\frac{\\left( \\frac{ \\partial }{ \\partial \\theta } p(y \\mid \\theta) \\right)}{p(y \\mid \\theta)} $$$$ b_{\\hat{\\theta}} = \\mathbb{E}_{y \\mid \\theta} [ \\hat{\\theta} (y_{1}, \\dots, y_{n})] - \\theta $$$$ \\mathbf{E}_{y \\mid \\theta} \\Lambda = \\int p(y \\mid \\theta) \\cdot \\frac{1}{p(y \\mid \\theta)} \\frac{ \\partial }{ \\partial \\theta } p(y \\mid \\theta) \\, dy = \\int \\frac{ \\partial }{ \\partial \\theta } p(y \\mid \\theta) \\, dy = \\frac{ \\partial }{ \\partial \\theta } 1 = 0 $$ which is an interesting result.\nScore estimator Covariance $$ \\mathbf{E}_{y \\mid \\theta} \\left[ \\Lambda \\cdot \\hat{\\theta} \\right] = \\frac{ \\partial }{ \\partial \\theta } \\int p(y \\mid \\theta) \\hat{\\theta} \\, dy = \\frac{ \\partial }{ \\partial \\theta } \\mathbf{E}_{y \\mid \\theta} \\left[ \\hat{\\theta} \\right] = \\frac{ \\partial }{ \\partial \\theta } \\left( \\mathbf{E}_{y \\mid \\theta} \\left[ \\hat{\\theta} \\right] - \\theta \\right) + 1 = \\frac{ \\partial }{ \\partial \\theta } b_{\\hat{\\theta}} + 1 $$ And the first part is surprisingly the bias of our estimator, so we want to see how much we can lower the bias value when we want to assess these kinds of problems.\nWe now consider the cross correlation between $\\Lambda$ and $\\hat{\\theta}$\n$$ \\mathbf{E}_{y \\mid \\theta} \\left[ ( \\Lambda - \\mathbf{E} \\Lambda)( \\hat{\\theta} - \\mathbf{E} \\hat{\\theta}) \\right] = \\mathbf{E}_{y \\mid \\theta}\\left[ \\Lambda \\cdot \\hat{\\theta} \\right] - \\mathbf{E}_{y \\mid \\theta} \\left[ \\Lambda \\mathbf{E} \\hat{\\theta} \\right] = \\mathbb{E}_{y \\mid \\theta} \\left[ \\Lambda \\cdot \\hat{\\theta} \\right] $$$$ \\mathbb{E}_{y \\mid \\theta} \\left[ \\Lambda \\cdot \\hat{\\theta} \\right] ^{2} = \\left( \\mathbf{E}_{y \\mid \\theta} \\left[ ( \\Lambda)( \\hat{\\theta} - \\mathbf{E} \\hat{\\theta}) \\right] \\right)^{2} \\leq \\mathbf{E}_{y \\mid \\theta}\\left[ \\Lambda^{2} \\right] \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\mathbf{E} \\hat{\\theta}) ^{2} \\right] $$$$ \\begin{align} \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\mathbf{E} \\hat{\\theta}) ^{2} \\right] \u0026= \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] - 2 \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta) (\\mathbf{E} \\hat{\\theta} - \\theta) \\right] + \\mathbf{E}_{ y \\mid \\theta} \\left[ (\\mathbf{E} \\hat{\\theta} - \\theta)^{2} \\right] \\\\ \u0026= \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] - 2 \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta) b_{\\hat{\\theta}} \\right] + b^{2}_{\\hat{\\theta}} \\\\ \u0026= \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] - b^{2}_{\\hat{\\theta}} \\end{align} $$ Which is just $= \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] - b^{2}_{\\hat{\\theta}}$\nFinal Bound Putting everything together we have that\n$$ \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] \\geq\n\\frac{\\mathbb{E}{y \\mid \\theta} \\left[ \\Lambda \\cdot \\hat{\\theta} \\right] ^{2}}{\\mathbf{E}{y \\mid \\theta}\\left[ \\Lambda^{2} \\right] } + b^{2}_{\\hat{\\theta}} \\frac{\\left( \\frac{ \\partial }{ \\partial \\theta } b_{\\hat{\\theta}} + 1 \\right)^{2}}{\\mathbf{E}{y \\mid \\theta}\\left[ \\Lambda^{2} \\right] } + b^{2}{\\hat{\\theta}} $$\nIf we have an unbiased estimator, which means that $b_{\\hat{\\theta}} = 0$ then we have that the expected difference of the models is always greater than the expected value of the double power of the score, also known as the fisher information in maths:\n$$ \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] \\geq \\frac{1}{\\mathbf{E}_{y \\mid \\theta} \\left[ \\Lambda^{2} \\right] } = \\frac{1}{I_{n}(\\theta_{0})} $$ If instead we have a biased estimator, sometimes is advantageous because the numerator could actually be smaller.\nFisher information Fisher information is defined as the variance of the score function. We discovered that the fisher information has something to do with the Rao-Cramer bound, let\u0026rsquo;s briefly analyze that:\n$$ \\mathbf{E}_{y \\mid \\theta} \\left[ \\Lambda^{2} \\right] = \\int p(y \\mid \\theta) \\left( \\frac{ \\partial }{ \\partial \\theta } \\log p(y \\mid \\theta) \\right)^{2} \\, dy =: I^{(1)}(\\theta) $$$$ I(\\theta) = Var(\\Lambda) = \\mathbb{E}_{y \\mid \\theta}[(\\Lambda - \\mathbb{E}_{y \\mid \\theta}[\\Lambda])^{2}] $$ And simplifying, as we know that the mean of the score function is 0.\nFisher information could also be written as the derivative with respect of theta of the score function, if $\\log p(y \\mid \\theta)$ is twice differentiable. See wikipedia.\nThe Multi-variable case üü®++ $$ I^{(n)} (\\theta) = \\int p(y_{1}\\dots y_{n} \\mid \\theta) \\left( \\frac{ \\partial }{ \\partial \\theta } \\log p(y_{1} \\dots y_{n}) \\right)^{2} \\, dy_{1}\\dots dy_{n} $$$$ \\int p(y_{1}\\dots y_{n} \\mid \\theta) \\left( \\frac{ \\partial }{ \\partial \\theta } \\log p(y_{1} \\dots y_{n}) \\right)^{2} \\, dy_{1}\\dots dy_{n} = \\int p(y_{1}\\dots y_{n} \\mid \\theta) \\left( \\sum \\Lambda_{i}^{2} \\right) \\, dy_{1}\\dots dy_{n} = n I^{(1)}(\\theta) $$ Which is a nice property of the fisher information\nStein estimator If we use this estimator we have that it is consistently better than the MLE, but we can\u0026rsquo;t prove that this is the best ever possible. This has been known as stein\u0026rsquo;s paradox for some time. See here. This video gives a nice intuition about Stein\u0026rsquo;s estimator, you can visualize it as a biased estimator that concentrates variance by warping the space closer to the origin, so that all the candidate solutions are acqually closer to the true solution.\nWe have to assume we have a multivariate random variable with $\\mathbb{R}^{d}$ with $d \\geq 3$ the exact details are not important, but we want to say that MLE is not always the best, this is the surprising fact.\n$$ \\hat{\\theta}_{JS} := \\left( 1 - \\frac{(d - 2)\\sigma^{2}}{\\lVert y \\rVert ^{2}} \\right) y $$$$ \\mathbb{E}\\left[ (\\hat{\\theta}_{JS}- \\theta_{0})^{2} \\right] \\leq \\mathbb{E}\\left[ (\\hat{\\theta}_{MLE}- \\theta_{0})^{2} \\right] $$References [1] Wasserman ‚ÄúAll of Statistics: A Concise Course in Statistical Inference‚Äù Springer Science \u0026amp; Business Media 2004\n[2] Vapnik ‚ÄúEstimation of Dependences Based on Empirical Data‚Äù Springer 2006\n[3] Murphy ‚ÄúMachine Learning: A Probabilistic Perspective‚Äù 2012\n","permalink":"https://flecart.github.io/notes/parametric-modeling/","summary":"\u003cp\u003eIn this note we will first talk about briefly some of the main differences of the three main approaches regarding statistics: the bayesian, the frequentist and the statistical learning methods and then present the concept of the estimator, compare how the approaches differ from method to method, we will explain maximum likelihood estimator and the Rao-Cramer Bound.\u003c/p\u003e\n\u003ch3 id=\"short-introduction-to-the-statistical-methods\"\u003eShort introduction to the statistical methods\u003c/h3\u003e\n\u003ch4 id=\"bayesian-\"\u003eBayesian üü©\u003c/h4\u003e\n$$\np(\\theta \\mid X) = \\frac{1}{z}p(X \\mid \\theta) p(\\theta) \n$$\u003cp\u003eThe quantity $P(X \\mid \\theta)$ could be very complicated if our model is complicated.\u003c/p\u003e","title":"Parametric Modeling"},{"content":"What is a part of Speech? A part of speech (POS) is a category of words that display similar syntactic behavior, i.e., they play similar roles within the grammatical structure of sentences. It has been known since the Latin era that some categories of words behave similarly (verbs for declination for example).\nThe intuitive take is that knowing a specific part of speech can help understand the meaning of the sentence.\nDefinition of the problem We assume there are some given categories (it has some drawbacks, because we can define too many categories sometimes, making the thing more difficult), for example, in a classical analysis, we would have articles, noun verbs.\nIt is possible to see this problem as a path in a graph, even though currently I don\u0026rsquo;t know what is the exact advantage for this. These kind of graphs are called trellis. There is a relation between statistica models and combinatorial algorithms. We should use this relation to score the path.\nConditional Random Fields These are just Log Linear Models on structured data (e.g. lattices), they were first introduced in 2001, and first they were not seen as log linear models. It\u0026rsquo;s very similar to Hidden Markov Models, which are similar to the Kalman Filters from some kind of view.\nWe define our conditional probabilistic model for sequence labeling, aka conditional random field:\n$$ p(t \\mid w) = \\frac{\\exp(s(t, w))}{\\sum_{t' \\in \\mathcal{T}^{N}} \\exp(s(t', w))} $$ where $s$ is the scoring function that marks the compatibility of a tag for a sentence. The score could also be negative. If the score is linear the whole random field would be a in The Exponential Family. The only requirement is that it returns a scalar.\nSo higher score is better, lower score is worse. But this algorithm is very slow! Computing the normalizer takes $\\mathcal{O}(\\lvert \\mathcal{T} \\rvert^{N})$ time. Assuming more structure (it is free information from another point of view), allows to have faster algorithms.\nAdditively decomposable assumption üü© We assume additively decomposability into the score function in order to bring down the complexity of computing the normalizer for the exponential space, which actually makes the problem tractable. Now we assume the score function to be: $$ s(\\boldsymbol{t}, w) = \\sum_{n = 1}^{N} s(\\langle t_{n - 1}, t_{n} \\rangle , w) \\implies \\exp(s(\\boldsymbol{t}, w)) = \\exp\\left( \\sum_{n = 1}^{N} s(\\langle t_{n - 1}, t_{n} \\rangle , w) \\right) \\prod_{n = 1}^{N} \\exp(s(\\langle t_{n - 1}, t_{n} \\rangle ,w)) $$ which means: instead of looking at the whole structure we only look adjacent tags. This is a strong assumption, but it\u0026rsquo;s ok to start doing something that might be useful. NOTE: we use a special symbol when $n = 1$. This makes it easy to compute the score, because we can just take adjacent couples instead of the whole string.\nIf the score is a neural network, then we can train this function without exactly knowing how they are made!\nThis has a clear visual interpretation by putting a score on a Arc, now we have weighted directed acyclic graph. But then we can use Backpropagation algorithms too!\nEmission and transition $$ s(\\langle t_{n - 1}, t_{n} \\rangle, w) = s_{\\text{emission}}(t_{n}, w_{n}) + s_{\\text{transition}}(t_{n - 1}, t_{n}) $$Simplifying the partition function After we have a score, then it is just a shortest path problem, a combinatorial optimization problem, it\u0026rsquo;s nice to see the derivation of why it\u0026rsquo;s easy to compute the normalizer:\n$$\n\\begin{align} \\sum_{t \\in \\mathcal{T}^{N}} \\exp \\left{ \\sum_{n = 1}^{N} s(\\langle t_{n - 1}, t_{n} \\rangle , w) \\right} =\\ =\\sum {t{1:N} \\in \\mathcal{T}^{N}} \\prod_{n = 1}^{N} \\exp \\left{ s(\\langle t_{n - 1}, t_{n} \\rangle , w) \\right}\\ = \\sum {t{1:N-1} \\in \\mathcal{T}^{N-1}} \\sum_{t_{N} \\in \\mathcal{T}} \\prod_{n = 1}^{N} \\exp \\left{ s(\\langle t_{n - 1}, t_{n} \\rangle , w) \\right} \\ = \\sum {t{1:N-1} \\in \\mathcal{T}^{N-1}} \\prod_{n - 1}^{N - 1} \\exp \\left{ s(\\langle t_{n- 1}, t_{n} \\rangle , w) \\right} \\times \\sum_{t_{N} \\in \\mathcal{T}} \\exp \\left{ s(\\langle t_{N - 1}, t_{N} \\rangle , w) \\right} \\ = \\sum_{t_{1} \\in \\mathcal{T}} \\exp \\left{ s(\\langle t_{0}, t_{1} \\rangle , w) \\right} \\times \\left( \\dots \\times \\sum_{t_{N} \\in \\mathcal{T}} \\exp \\left{ s(\\langle t_{N - 1}, t_{N} \\rangle , w) \\right} \\right) \\end{align} $$\nWhere we have just applied a distributive property in the 4 line, and reapplied the same line of reasoning over and over again. This is somewhat similar to factorizing polynomials. Now we have a simple and fast way to calculate it, it\u0026rsquo;s just a linear number of terms. The deep insight is that here we derived an algorithm by just doing some algebra! Is there some deep links between an algebraic view of computation and algorithms with algebra?\nThe backward algorithm We see now all the algorithm for the backward dynamic programming solution to compute the normalizer (remember the visual interpretation that we have). The Viterbi algorithm How to find the highest-scoring tagging for a certain input sequence $w$? We just add a max operator instead of the sum! This makes it quite easy. Viterbi was a code cracker times ago. This is very similar to the backward algorithm used to calculate the partition function: The only thing we need is a semi-ring.\nRelation with Logistic Regression CRF can be seen as a generalization of Logistic Regression for sequences prediction. See Linear Regression methods for something about regression methods. TODO: say why this is true.\nRelation with HNN CRF are also a more flexible generalization of HNN models. TODO: say why this is true.\nSemirings This section has been moved to Semirings.\n","permalink":"https://flecart.github.io/notes/part-of-speech-tagging/","summary":"\u003ch4 id=\"what-is-a-part-of-speech\"\u003eWhat is a part of Speech?\u003c/h4\u003e\n\u003cp\u003eA part of speech (POS) is a \u003cstrong\u003ecategory of words that display similar syntactic behavior\u003c/strong\u003e, i.e.,\nthey play similar roles within the grammatical structure of sentences. It has been known since the Latin era that some categories of words behave similarly (verbs for declination for example).\u003c/p\u003e\n\u003cp\u003eThe intuitive take is that knowing a specific part of speech can help understand the \u003cstrong\u003emeaning\u003c/strong\u003e of the sentence.\u003c/p\u003e","title":"Part of Speech Tagging"},{"content":"Some specific phenomenons in modern systems happen only when we scale into large systems. This note will gather some observations about the most important phenomena we observe at these scales.\nTail Latency Phenomenon Tail latency refers to the high-end response time experienced by When scaling our services, using Massive Parallel Processing, and similar technology, it is not rare that a small percentage of requests in a system experience a high-end response time, typically measured at the 95th or 99th percentile. This significant delays that can degrade user experience or system reliability.\nSource of the Bottlenecks These outliers often result from resource contention, network variability, or workload spikes. Often it is caused by an overload of a specific resource in the system. Recall from Cloud Storage, that data-centers, have a limited availability of CPU cores, RAM, storage, network bandwidth. If one of these resources is full, then the machines could suffer from high latency.\nTypical latencies We observe that simply reading from the disk, already brings a latency of 20ms.\nIf we compare this with the throughput, it\u0026rsquo;s quite easy to see something on the order of MegaBytes per second.\nThese values are important to consider as the user\u0026rsquo;s waiting time is exactly the sum of the initial latency + time of transmission.\nHedge Requests Reducing tail latency is critical in latency-sensitive systems, such as cloud services, where even occasional delays can lead to cascading performance issues or customer dissatisfaction.\nOne big problems becomes identifying the source of latency, and then connecting to the machine to solve it.\nOne common approach is called Hedge Requests:\nBasically, do all tasks twice. Monitor, and start tasks when you notice some stragglers. This is what it\u0026rsquo;s done in (Dean \u0026amp; Ghemawat 2008). With the first solution, the cluster should be twice as slow, because it has to do so much more computation.\nSolving Disk-IO For example, if the disk-io is the bottleneck, using Apache Spark or MapReduce helps to solve this problem, as we are now reading from disk in parallel.\nLaw\u0026rsquo;s of speedups Amdahl\u0026rsquo;s Law Amdahl\u0026rsquo;s Law quantifies the potential speedup of a system when a portion of its workload is parallelized. It states that the overall improvement is limited by the fraction of the workload that remains sequential. We assume we have a constant problem size.\nMathematically, the speedup $S$ is given by $S = \\frac{1}{(1 - P) + \\frac{P}{N}}$, where $P$ is the parallelizable fraction, and $N$ is the number of parallel processing units. This principle highlights the diminishing returns of adding more resources when the sequential portion dominates, emphasizing the importance of optimizing both parallel and sequential components for maximum performance gains.\nThe takeaway from here is that not everything is parallelizable or speedable with just more machines.\nGustafson\u0026rsquo;s Law Gustafson\u0026rsquo;s Law provides an alternative perspective to Amdahl\u0026rsquo;s Law, focusing on scalability in parallel computing. It asserts that increasing the problem size can maintain efficiency as more processors are added, rather than being limited by a fixed workload. The speedup SS is expressed as S=P‚ãÖN+(1‚àíP)S = P \\cdot N + (1 - P), where PP is the fraction of work that scales with parallelism, and NN is the number of processors. By emphasizing the expansion of parallel workloads, Gustafson\u0026rsquo;s Law highlights the potential for achieving greater performance by leveraging the computational power of modern systems effectively.\nReferences [1] Dean \u0026amp; Ghemawat ‚ÄúMapReduce: Simplified Data Processing on Large Clusters‚Äù Communications of the ACM Vol. 51(1), pp. 107\u0026ndash;113 2008\n","permalink":"https://flecart.github.io/notes/performance-at-large-scales/","summary":"\u003cp\u003eSome specific phenomenons in modern systems happen only when we scale into large systems. This note will gather some observations about the most important phenomena we observe at these scales.\u003c/p\u003e\n\u003ch4 id=\"tail-latency-phenomenon\"\u003eTail Latency Phenomenon\u003c/h4\u003e\n\u003cp\u003eTail latency refers to the high-end response time experienced by\nWhen scaling our services, using \u003ca href=\"/notes/massive-parallel-processing/\"\u003eMassive Parallel Processing\u003c/a\u003e, and similar technology, it is not rare that\na small percentage of requests in a system experience a \u003cstrong\u003ehigh-end response\u003c/strong\u003e time, typically measured at the 95th or 99th percentile.\nThis significant delays that can degrade user experience or system reliability.\u003c/p\u003e","title":"Performance at Large Scales"},{"content":"There is huge literature on planning. We will attack this problem from the view of probabilistic artificial intelligence. In this case we focus on continuous, fully observed with non-linear transitions, an environment often used for robotics. It\u0026rsquo;s called Model Predictive Control (MPC).\n\\[...\\] Moreover, modeling uncertainty in our model of the environment can be extremely useful in deciding where to explore. Learning a model can therefore help to dramatically reduce the sample complexity over model-free techniques.\nA general algorithm usually follows this outline:\nInitialize policy For some episodes: Collect data following a certain policy Learn a model $f$ of the world and the rewards $r$. Update the policy using the learned model. We can categorize the challenges into three main buckets:\nHow to develop policies given some model of the world How to infer the model of the world How to balance exploitation against exploration (the classical problem). Known Dynamics Case We try develop methods to scale to large MDPs. in this setting we have a deterministic model of the world, and would like to develop a policy that returns the maximum reward. This problem has been heavily studied in a field named optimal control.\nSetting of the problem üü©\u0026ndash; We have a deterministic model (often used for optimal control):\n$$ x_{t + 1} = f(x_{t}, a_{t}) $$$$ \\max_{a_{0}: \\infty} \\sum_{t=0}^{\\infty} \\gamma^{t} r(x_{t}, a_{t}) $$ But his is often not feasible to compute. This is exactly the same as the ones we have explored in RL Function Approximation, but here we explicitly model the transition probabilities, and the time horizon was equal to $1$.\nFinite horizon version üü©\u0026ndash; $$ \\max_{a_{0}: H} \\sum_{t=0}^{H} \\gamma^{t}r(x_{t}, a_{t}) $$$$ J_{H}(a_{t:t + H - 1}) = \\sum_{\\tau = t}^{t + H - 1} \\gamma^{\\tau - t}r(x_{\\tau}, a_{\\tau}) $$ Where $x_{\\tau}$ is the state we reached after executing the first $\\tau - 1$ actions. The objective is then finding the actions that minimize that cost. If this cost is continuous and differentiable, then we can use gradient descent methods with Backpropagation. This problem is calle model predictive control.\nIf it is not differentiable, we can use Monte Carlo Methods (AlphaZero can be seen as an advanced version of these methods). These are called random shooting methods.\nOne clear drawback of finite horizon setting is when we have sparse rewards. If in the whole horizon the model doesn\u0026rsquo;t see any action that brings any reward, then it cannot learn anything. This is quite intuitive. One possible solution is adding a value estimate to the last reached state, (Krause calls this method return to go).\n$$ J_{H}(a_{t:t + H - 1}) = \\underbrace{\\sum_{\\tau = t}^{t + H - 1} \\gamma^{\\tau - t}r(x_{\\tau}, a_{\\tau})}_{\\text{Short Term}} + \\underbrace{\\gamma^{H} V(x_{t + H})}_{\\text{Long Term}} $$If $H = 1$, then we have the greedy policy with respect to the value function, we have studied many of these settings in Tabular Reinforcement Learning and RL Function Approximation.\nThe stochastic Case üü© $$ J_{H}(a_{t:t + H - 1}) = \\mathop{\\mathbb{E}}_{x_{t + 1: t+H}} \\left[ \\sum_{\\tau = t}^{t + H - 1} \\gamma^{\\tau - t}r(x_{\\tau}, a_{\\tau}) + \\gamma^{H} V(x_{t + H}) \\mid a_{t: t+ H - 1}, f\\right] $$ A common approach is using monte carlo trajectory sampling. This is usually a high dimensional integral.\nWe have the same problem of states that depend on the actions. So we can use the score trick or reparameterization trick, as before. A common approach is the latter with the Gaussian policy. Applying this trick, we can estimate the expectation in this way:\n$$ J_{H}(a_{t:t + H - 1}) = \\frac{1}{N}\\sum_{i=1}^{N} \\left[ \\sum_{\\tau = t}^{t + H - 1} \\gamma^{\\tau - t}r(x_{\\tau}^{(i)}, a_{\\tau}^{(i)}) + \\gamma^{H} V(x_{t + H}^{(i)}) \\right] $$ Where $x_{\\tau}$ is derived from the stochastic model instead with the underlying stochastic transition function. (Sample from normal Gaussian and then reparameterize). (See slides, this syntax has been written in a slightly different manner).\nControl Loops üü®++ The problem with the current approach is that solving this optimization problem at every step could be quite expensive! This problem is called closed control loop. This leads to parameterized $q$ functions in an attempt to make things faster. We parameterize a policy $a_{t} = \\pi(x_{t}, \\theta)$, which brings us to offline methods for faster online evaluation. This is called open control loop.\n$$ J_{\\mu, H}(\\varphi;\\theta) = \\mathop{\\mathbb{E}}_{x_{0} \\sim \\mu, x_{1:H} \\mid \\pi_{\\varphi}, f} \\left[ \\sum_{\\tau = 0}^{H - 1} \\gamma^{\\tau}r_{\\tau} + \\gamma^{H} Q(x_{H}, \\pi(x_{H}, \\theta)) \\mid \\theta \\right] $$ Where $\\mu$ explores all states with probability $\u003e 0$. One nice thing about this approach is that with $H = 0$ it corresponds with the DDPG algorithm.\n$$ \\pi^{*}(x) = \\arg\\max_{a} Q^{*}(x, a; \\theta) $$ The two methods are quite similar if viewed from this point of view.\nUnknown Dynamics In this setting, we don\u0026rsquo;t know the transition model $f$ neither the reward function $r$. We will use the same idea in Tabular Reinforcement Learning, we will attempt to learn the transition and reward model based on some rollouts of the current policy.\nThe main idea üü© $$ x_{t + 1} \\sim f(x_{t}, a_{t},; \\psi) $$ The case of the reward function can be done in exactly the same manner.\nUsing Conditional Gaussians üü®++ $$ x_{t + 1} \\sim \\mathcal{N}(\\mu(x_{t}, a_{t}; \\psi), \\sigma(x_{t}, a_{t}; \\psi)) $$ And one nice thing we only need to use $n (n + 1) / 2$ parameters. We note that if the variance is 0, then it reduces to a deterministic setting.\nMain Drawbacks If we set some finite horizon $H \u003e 1$ the problem with the approximations is that the errors compound. The planning algorithm then runs on probably erroneous models (or uses the noise as information), which brings poor performance. This is also often why using point estimates is a bad idea in control settings. One way to address this problem is to capture epistemic and aleatoric error and try to model them.\nGreedy Planning Separating Errors The epistemic error is the uncertainty in $P(f \\mid D)$ while the aleatoric is the uncertainty of the point given the model $p(x_{t + 1} \\mid f, x_{t}, a_{t})$ and is usually irreducible and inherent of the problem we are trying to solve and can be attributed to uncertainty of the transitions in the underlying Markov Process.\nThen, we would like to focus on the epistemic uncertainty, i.e. the error that we have some control over. We can use the same idea of sampling repeatedly from the model and then taking the mean of the rewards. (Somewhat akin to Thompsom Sampling explored in Bayesian Optimization).\nThe PILCO algorithm üü® This is somewhat similar to an algorithm called probabilistic inference for learning control (PILCO).\nDefine empty dataset and prior $P(f) = P(f \\mid \\left\\{ \\right\\})$ Iterate: Find $\\pi$ such that it maximizes $$ \\arg\\max_{a_{t:t+H - 1}} \\mathop{\\mathbb{E}}_{f \\sim P(f \\mid D)} \\left[ \\sum_{\\tau = 0}^{H - 1} \\gamma^{\\tau}r_{\\tau}(x_{\\tau}, a_{\\tau}) + \\gamma^{H} Q(x_{H}, \\pi(x_{H}, \\theta)) \\mid \\theta \\right] $$ Collect a dataset of rollouts $D = \\left\\{ (x_{1}, a_{1}, r_{1}, x_{i + 1})_{i} \\right\\}$ using this policy Update the prior $P(f \\mid D)$ The PETS algorithm is one example of these methods.\nHere $f$ is a model of the world which tells us how the state updates after a certain action is made: $x_{t + 1} = f(x_{t}, a_{t}; \\psi)$, sometimes we parametrize with Gaussians, especially in continuous settings.\nExploration Reinforcement Learning can be seen as an expansion over Bayesian Optimization: we add actions and world models to the states (inputs) and rewards (outputs). This motivates the usage of some algorithms developed in that setting in the new one. One of the problems we had in Bayesian Optimization is the exploration and exploration trade-off. In this section, we will discuss about that problem in this setting.\nSome exploration techniques Gaussian Dithering üü© This is a simple idea: we add some noise to the actions. This idea has been discussed before too. See Bayesian Optimization.\nThompson Sampling üü© This is exactly the same idea in Bayesian Optimization: The algorithm goes as follows:\nInitialize the empty dataset $\\mathcal{D} = \\varnothing$ and the prior $p(f) = p(f \\mid \\mathcal{D})$ For some episodes do: Sample a model $f \\sim p(f \\mid \\mathcal{D})$ Find the policy that maximizes the expected reward under this model $\\max_{\\pi} J_{H}(\\pi; f)$. Execute this policy and collect the data $\\mathcal{D}$ Update the prior $p(f \\mid \\mathcal{D})$ Optimistic Exploration The Idea üü• Let us consider a set $\\mathcal{M}(\\mathcal{D})$ of plausible models given some data $\\mathcal{D}$. Optimistic exploration would then optimize for the most advantageous model among all models that are plausible given the seen data.\n$$ f_{i}(x, a) \\in \\mathcal{C}_{i} = \\left[ \\mu_{i}(x, a) - \\beta_{i}\\sigma_{i}(x, a), \\mu_{i}(x, a) + \\beta_{i}\\sigma_{i}(x, a) \\right] $$ Then the set of plausible models is $\\mathcal{M}(\\mathcal{D}) = \\left\\{ f_{i} \\mid i = 1, \\ldots, d \\right\\}$. Such that that function is in $\\mathcal{C}_{i}$\nThe algorithm goes as follows:\nInitialize the empty dataset $\\mathcal{D} = \\varnothing$ and the prior $p(f) = p(f \\mid \\mathcal{D})$ For some episodes do: Find the policy that maximizes the expected reward under the most optimistic model.$$ \\max_{\\pi} \\max_{f \\in \\mathcal{M}(\\mathcal{D})} J_{H}(\\pi; f) $$ Execute this policy and collect the data $\\mathcal{D}$ Update the prior $p(f \\mid \\mathcal{D})$ H-UCRL üü• $$ \\pi_{t + 1} = \\arg\\max_{\\pi} \\max_{\\eta(\\cdot) \\in [-1, 1]^{d}} J_{H}(\\pi; \\hat{f}_{t}) $$$$ \\hat{f}_{t}(x, a) = \\mu_{t}(x, a) + \\beta_{t}\\eta_{t}\\sigma_{t}(x, a) $$ Where the new variable $\\eta \\in [-1, 1]$.\nIllustration of H-UCRL from the Textbook. Safe Exploration TODO\nThis part also links to H√ºbotter\u0026rsquo;s idea on transductive learning, see Active Learning.\nBasic formulation We define a constrained formulation with some variable $\\delta$ and say that the function is safe (constrained) if it satisfies the following:\n$$ \\begin{align} \\max_{\\pi} \u0026J_{\\mu}(\\pi, f) = \\mathop{\\mathbb{E}}_{x_{0} \\sim \\mu, x_{1:H} \\mid \\pi, f} \\left[ \\sum_{\\tau = 0}^{H - 1} \\gamma^{\\tau}r_{\\tau} + \\gamma^{H} Q(x_{H}, \\pi(x_{H}, \\theta)) \\mid \\theta \\right] \\\\ \\text{Subject to } \u0026 J_{\\mu}^{c}(\\pi, f) = \\mathop{\\mathbb{E}}_{x_{0} \\sim \\mu, x_{1:H} \\mid \\pi, f} \\left[ \\sum_{\\tau = 0}^{H - 1} \\gamma^{\\tau}c(x_{\\tau}) \\right] \\leq \\delta \\end{align} $$One usually optimizes for the Lagrangian, see Lagrange Multipliers.\nOptimistic and Pessimistic We have already encountered some optimistic approaches in RL Function Approximation. Here we will introduce a simple idea of being pessimistic about the safety contraints: TODO.\n","permalink":"https://flecart.github.io/notes/planning/","summary":"\u003cp\u003eThere is huge literature on planning. We will attack this problem from the view of probabilistic artificial intelligence.\nIn this case we focus on continuous, fully observed with non-linear transitions, an environment often used for robotics. It\u0026rsquo;s called Model Predictive Control (MPC).\u003c/p\u003e\n\u003cblockquote\u003e\n\\[...\\]\u003cp\u003e Moreover, modeling uncertainty in our model of the environment can be extremely useful in deciding where to explore. Learning a model can therefore help to dramatically reduce the sample complexity over model-free techniques.\u003c/p\u003e","title":"Planning"},{"content":"Planning Automatico Vogliamo andare a creare un programma che sia in grado di creare un piano per fare una azione, andiamo in questo capitolo gli algoritmi storicamente migliori adatti a risolvere questo problema\nIl problema di pianificazione Andiamo a rappresentare il nostro problema di pianificazione con un linguaggio molto simile alla Logica del Primo ordine.\n√à il PDDL ossia il Planning domain definition language\nPDDL Questo linguaggio √® definito da\nUna serie di predicati in FOL iniziali Una serie di predicati in FOL di arrivo Una serie di azioni Con una serie di precondizioni E una serie di effetti Il nostro obiettivo sar√† principalmente raggiungere un obiettivo finale, utilizzando le azioni per cambiare lo stato attuale\nEsempio\nIn cui si pu√≤ notare che una soluzione di questo problema √® molto semplice:\nAlgoritmi generali Gli algoritmi principali per risolvere la PDDL sono di due tipologie\nForward search Backward search Entrambe dovrebbero avere delle euristiche molto forti per funzionare in un ambiente reale. (nota: essendo questa poi una rappresentazione fattorizzata del mondo, si possono creare delle euristiche indipendenti dal dominio molto forti!).\nSulla soddisfacibilit√† booleana\nSi pu√≤ anche trasformare il problema di pianificazione in un problema di logica proposizionale da dare in pasto ad un sat solver. Con lo stato attuale dei sat solver questo potrebbe anche essere considerato una soluzione possibile interessante.\nAltri metodi da almeno tenere in mente i nomi\nPlanning graph\nSituation calculus **praticamente sat-plan ma con la FOL\nPartial ordering planning, molto figo perch√© ci fanno i rover per andare su marte questo üòÄ, √® usato perch√© puoi vedere in modo molto chiaro il motivo per cui ha scelto questo piano.\nBackward search Vogliamo partire dall‚Äôobiettivo, dal nostro goal, ed andare indietro fino a trovare uno stato che sia adatto allo stato iniziale.\nPer fare questo vogliamo cercare azioni che siano rilevanti, ossia le cui precondizioni non siano assurde con quello che avremmo gi√†. Questo aiuta moltro a diminuire il fattore di branching.\nPer maggiori dettagli su come si faccia l‚Äôupdate dello stato andare a vedere sul libro.\nForward search Praticamente andiamo a guardare tutte le soluzioni, √® la stessa cosa di un Problemi di ricerca ed √® quindi facilmente attaccabile (se non per la grandezza dello spazio di ricerca) dagli algoritmi l√¨ studiati. Il pi√π importante dei quali resta sempre A* con una buona euristica.\n","permalink":"https://flecart.github.io/notes/planning-automatico/","summary":"\u003ch1 id=\"planning-automatico\"\u003ePlanning Automatico\u003c/h1\u003e\n\u003cp\u003eVogliamo andare a creare un programma che sia in grado di creare un piano per fare una azione, andiamo in questo capitolo gli algoritmi storicamente migliori adatti a risolvere questo problema\u003c/p\u003e\n\u003ch2 id=\"il-problema-di-pianificazione\"\u003eIl problema di pianificazione\u003c/h2\u003e\n\u003cp\u003eAndiamo a rappresentare il nostro problema di pianificazione con un linguaggio molto simile alla \u003ca href=\"/notes/logica-del-primo-ordine/\"\u003eLogica del Primo ordine\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e√à il PDDL ossia il \u003cstrong\u003ePlanning domain definition language\u003c/strong\u003e\u003c/p\u003e\n\u003ch3 id=\"pddl\"\u003ePDDL\u003c/h3\u003e\n\u003cp\u003eQuesto linguaggio √® definito da\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eUna serie di predicati in FOL iniziali\u003c/li\u003e\n\u003cli\u003eUna serie di predicati in FOL di arrivo\u003c/li\u003e\n\u003cli\u003eUna serie di azioni\n\u003col\u003e\n\u003cli\u003eCon una serie di precondizioni\u003c/li\u003e\n\u003cli\u003eE una serie di effetti\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eIl nostro obiettivo sar√† principalmente raggiungere un obiettivo finale, utilizzando le azioni per cambiare lo stato attuale\u003c/p\u003e","title":"Planning automatico"},{"content":"I processi di Poisson sono dei processi stocastici, interpretabili come collezione indicizzata dal tempo di variabili aleatorie. Esempi semplici sono una uniforme, altri pi√π complessi potrebbe essere una catena di Markov (see Markov Chains) (utile per modellare cammini randomici) o quella di Poisson spiegata qui.\nIntroduzione ai processi di Poisson Arrival processes Sia una sequenza di variabili aleatorie $0 \u003c S_{1} \u003c S_{2} \u003c \\dots$ (il fatto che sia positivo significa che per ogni elemento del dominio vale che quell\u0026rsquo;elemento √® \u0026lt;, non so se mi sono spiegato.) Il fatto che siano crescenti ci permette di metterli in linea, perch√© siamo sicuri che $S_{2}$ produrr√† un valore maggiore di $S_{1}$.\n$$ \\{S_{n} \\leq t\\} = \\{N(t) \\geq n\\} $$Possiamo connettere questa nozione con le reti di petri e quantum (Baez \u0026amp; Biamonte 2019)\ndef: Renewal processes un arrival process in cui inter-arrival times $x_{1}, x_{2}, \\dots$ sono IID.\ndef: Poisson processes Sono renewal processes in cui gli $X_{1}, X_{2}, \\dots$ $F_{X}(x) = 1 - \\exp(-\\lambda x)$, ossia seguono la cumulativa di Poisson.\nPropriet√† def: Memory-less $$ P(X \u003e t + x)= P(X \u003e t) P(X \u003e x) $$$$ P(X \u003e t + x | X \u003e t) = P(X \u003e x) $$ il prof. dice che non ha perso tempo n√© guadagnato niente. Perso tempo perch√© se vuoi la cosa prima o poi devi entrare in coda.\nSi pu√≤ dimostrare che se e solamente se la variabile aleatoria √® esponenziale allora √® memory-less.\nTeorema indipendenza di arrival counting and arrival process sketch:\nPrendiamo un tempo $t$\nStationary increment property Se prendiamo un counting process, questo si dice stazionario se la variabile $N(t') - N(t)$ con $t' \u003e t \u003e 0$ ha la stessa distribuzione di $N(t'- t)$ ossia √® lineare senza costanti. Questo sembra chiaro perch√© ci sta dicendo che il numero di arrivi in un lasso di tempo resta sempre lo stesso.\nUn esempio √® che nel lavoro di Ermanno le sue cose non rispettano la stationary property.\nIndependent property $$ N(t_{1}) - N(0), N(t_{2}) - N(t_{1}), \\dots $$ Sono indipendenti fra di loro\nPer il teorema dimostrato sopra si pu√≤ dire che la distribuzione di Poisson possieda queste propriet√†.\nEquivalenze con i processi di Poisson Arrival counting processes Si pu√≤ dire che un processo che soddisfa (reference al libro) che sia independent increment e stationary increment sia un processo di poisson\nConditional arrival densities Se so che in un intervallo c\u0026rsquo;√® un arrivo, allora √® uniforme la probabilit√† di dove sia arrivato (solo che abbiamo una uniforme su un volume molto strano). Questo √® una cosa che credo sia relazionata con la indipendenza di Poisson per questo genere di processi.\nLa cosa da notare √® che questa densit√† √® indipendente da $s_{1}, s_{2}, .., s_{n}$.\n$$ f(s_{1}s_{2}\\dots s_{n}|n) = \\frac{n!}{t^{n}} $$Applicazioni Neuronal firing Da approfondire\nOptical trasmission Da approfondire\nReferences [1] Baez \u0026amp; Biamonte ‚ÄúQuantum Techniques for Stochastic Mechanics‚Äù 2019\n","permalink":"https://flecart.github.io/notes/poisson-processes/","summary":"\u003cp\u003eI processi di Poisson sono dei \u003cstrong\u003eprocessi stocastici\u003c/strong\u003e, interpretabili come  collezione indicizzata dal tempo di variabili aleatorie.\nEsempi semplici sono una uniforme, altri pi√π complessi potrebbe essere una catena di Markov (see \u003ca href=\"/notes/markov-chains/\"\u003eMarkov Chains\u003c/a\u003e) (utile per modellare cammini randomici) o quella di Poisson spiegata qui.\u003c/p\u003e\n\u003ch3 id=\"introduzione-ai-processi-di-poisson\"\u003eIntroduzione ai processi di Poisson\u003c/h3\u003e\n\u003ch4 id=\"arrival-processes\"\u003eArrival processes\u003c/h4\u003e\n\u003cp\u003eSia una sequenza di variabili aleatorie $0 \u003c S_{1} \u003c S_{2} \u003c \\dots$ (il fatto che sia positivo  significa che per ogni elemento del dominio vale che quell\u0026rsquo;elemento √® \u0026lt;, non so se mi sono spiegato.)\n\u003cimg src=\"/images/notes/Poisson processes-20240128100752878.webp\" width=\"443\" alt=\"Poisson processes-20240128100752878\"\u003e\u003c/p\u003e","title":"Poisson processes"},{"content":"Introduzione Monoforfo üü© Quando non posso utilizzare un tipo come parametro. Ossia non possiamo definire una funzione generica.\nSlide monomorfismo\nPolimorfismo Polimorfismo, come dice il nome, significa avere tante forme, in questo caso tanti tipi. Ma avere tanti tipi non √® una cosa ambigua? Questa cosa si risolve solitamente a compile time (facendo checks di sottotipo, oppure dispatch della funzione corretta).\nTipologie di Polimorfismo (3) üü© Slide tipologie di monomorfismo\nad-hoc polymorphism questo √® anche chiamato overloading in cui vado a definire un nuova funzione (con lo stesso nome) che accetti il nuovo tipo di dato.\nsubtype polymorphism\nparametric polymorphism\nAd-hoc (3) üü© Slide ad-hoc polimorphism\nQuesto √® molto simile al tipo somma, solamente fatto da un punto di vista funzionale (i domini devono essere separati).\nIn C sono molto conosciute questa tipologia di polimorfismo. Per√≤ ci sono anche forme comuni, come l‚Äôoperatori aritmetici.\nL‚Äôinvocazione √® anche chiamato dispatch , quando abbiamo risolto l‚Äôoverloading, ossia abbiamo fatto il dispatch dell‚Äôinvocazione, allora l‚Äôoverloading scompare e viene eseguita una specifica funzione. Questa funzione pu√≤ essere fatta in modo statico oppure dinamico.\nRiassumento:\nDefinisco stesso nome che prendono tipi diversi Avviene un dispatch statico o dinamico Una volta avvenuto il dispatch, la funzione eseguita √® univocamente identificata. Statico o dinamico nel dispatch\nDispatch √® il processo che va a decidere la funzione overloadata da chiamare, questo processo si pu√≤ classificare come dinamico se avviene durante il runtime (come solitamente √® per le interfacce) oppure statico quando avviene e a tempo di compilazione (come solitamente avviene per le funzioni overloaddate).\nDi sottotipo Possiamo andare a dire che un tipo S √® sottotipo di un tipo T, indicato con $S \u003c: T$, quando S pu√≤ essere utilizzato in qualunque occasione al posto di T. Questo √® anche chiamato come principio di sostitutione di Liskov.\nSetTheory per sottotipi üü©‚Äî Slide polimorfismo di sottotipo\nQuesto concetto l‚Äôabbiamo anche accennato in Algebra dei tipi quando abbiamo parlato di coercizione.\npraticamente quando abbiamo un tipo pi√π specifico $S$ che andiamo ad indicare con $S \u003c: T$, allora quando ho S e devo utilizzare T, lo posso fare, questo perch√© S contiene tutte le caratteristiche di T.\nSolitamente questa √® una relazione di preordine ossia riflessiva e transitiva, spesso anche antisimmetrica, quindi √® spesso un ordine parziale.\nSi pu√≤ dire che esiste un rapporto di specificazione (parola da utilizzare nell‚Äôorale per bella figura lel) perch√© S √® pi√π specifico di T, in questo senso possiamo utilizzare S in ogni posto in cui c‚Äô√® T.\nTipologie di sottotipaggio (2) üü© Slides subtyping con records\nPer questa parte possiamo andare a definire un concetto di sottotipaggio per profondit√† o per larghezza.\nPer laghezza: basta che il sottotipo abbia molti pi√π campi! in questo senso Dog \u0026lt; Animal, perch√© anche dog posso utilizzarlo come un animal, dato che ha tutte le cose di animal. (l‚Äôunica differenza col duck typing √® il fatto che T qui √® esplicito, mentre nel duck typing non mi importa del tipo, solamente dello stesso utilizzo).\nDifferenza fra duck e width subtyping per chatGPT\nWidth subtyping is a form of subtype polymorphism where a type is considered a subtype of another type if it has at least the same properties and methods as the supertype. This means that a subtype can have more properties and methods than the supertype, but it must at least have all of the ones that are defined in the supertype. This is called \u0026ldquo;width\u0026rdquo; because it is based on the width of the type\u0026rsquo;s interface.\nDuck typing, on the other hand, is a more dynamic approach to type checking where the type of an object is determined by its behavior at runtime rather than its static type. In other words, if it walks like a duck and quacks like a duck, then it must be a duck. This means that two objects with different types can still be treated as if they have the same type if they share the same behavior.\nIn summary, width subtyping is based on the interface of a type and allows for subtype polymorphism, while duck typing is based on the behavior of an object at runtime and allows for more dynamic type checking.\nPer profondit√†: Quando un campo ha un tipo che sia un sottotipo di un altro. Questo √® visto molte meno volte, per√≤ si pu√≤ fare. Questa ha per√≤ delle particolarit√†, √® importante introdurre il concetto di covariante per tipi quando le parti del record mantengono la stessa direzione di sottotipaggio. Quando abbiamo due tipi che sono covarianti, possiamo utilizzarli solo per le letture. In scrittura per√≤ potremmo avere dei campi non inizializzati, quindi non va molto bene. (nell\u0026rsquo;esempio avremmo un animale in output in scrittura, mentre gli abbiamo dato un dog e ci aspettavamo un dog in output). (queste nozioni di covarianza comunque sono sempre in funzione del contesto).\nIn pratica vado a rimpazzare i campi del record con dei sottotipi, questo √® buono per cose immutabili, for example, you can assign 1.5 to the \u0026lsquo;x\u0026rsquo; field of a real point (a record with two real fields), but you can\u0026rsquo;t do the same to the \u0026lsquo;x\u0026rsquo; field of an integer point (which, however, is a deep subtype of the real point type) because 1.5 is not an integer.\nCovariante e Controvariante e consumo (!!) üü®++ Slide covariante, controvariante e consumi e produzione\nEsempio strano\nQuesta nozione si basa sull‚Äôinversione fra produzione e consumazione.\nAvevamo detto che abbiamo una relazione di sottotipo, perch√© DogHouse \u0026lt; AnimalHouse quindi sono covarianti rispatto a Dog \u0026lt; Animal House. Ma nella fase di consumo, questo si inverte, quindi si pu√≤ dire che siano controvarianti.\nIn breve:\nConsumo (input) ‚Üí Controvariante Produzione (output) ‚Üí Covariante Il motivo per cui succede √® che Dog fn utilizza i campi di Dog, che sono pi√π estesi, posso sostituire a questo consumo anche animal, che utilizza i campi di animal, quindi sono anche presenti in Dog, ecco che il rapporto si inverte\nPossiamo fare un parallelo fra le funzioni di consumo e quelle di produzione.\nSlide esempio covariante e controvariante easy\nSussunzione üü® Con sussunzione andiamo a parlare di quando possiamo fare l‚Äôinferenza di sottotipaggio ossia se √® vero o meno che un tipo √® sottotipo di un altro (e quindi possibile utilizzare S al posto di T in qualunque luogo).\nSlide sussunzione metodi\nPossiamo fare la sussunzione in modo estensionale o intensionale quindi o:\nCaratterizzando tutti gli elementi del sottotipo Parlare di predicati e domini. Tipo estensionali o intensionali üü©- abbiamo parlato di estensionale o intensionale\nEsempi di sussunzione\nPolimorfismo parametrico Tipi parametrici üü© Slide tipi parametrici\nQuando abbiamo delle operazioni anche se non conosciamo esattamente cosa c‚Äô√® sotto, per√≤ riguardo la struttura so bene cosa vanno a fare. (un esempio riguardo a questo √® il sort).\nQuesta parametrizzazione ci permette di definire delle cose per tutti i tipi che possiedono quella funzione (ricorda i tratti di rust), ed √® per questo che possiamo dire che sia un tipo universale. Questa cosa che vale per tutti ci permette di poter provare dei teoremi aggratis.\nEsempio di teorema for free\nIbridazione con polimorfismo di sottotipo üü® Slide ibrido con pol di sottotipo\nA volte non vogliamo che la nostra funzione vada per tutti, senza quindi conoscere come √® fatto sotto, vorremmo avere certe funzioni (quindi un sottotipo del tipo generale), per esempio nei tratti di rust possiamo dire che questa nostra funzione vada per tutte in cui √® definita una certa funzione/interfaccia/tratto, in questo senso andiamo ad utilizzare un sottotipo\nArray c‚Äôerano gi√† all‚Äôinizio, lo puoi utilizzare covariante in entrambe le direzioni, mentre altrimenti non ti permetterebbe di utilizzare in entrambe le direzioni (vuole che tu sia prima sicuro se vuoi utilizzarlo come consumer o producer. un buon modo per ricordarsi √® PECS producer deve estender, mentre consumer deve fare super.\nAbbiamo sempre che √® safe, nel senso che ritorna sempre un tipo senza bloccarsi (e posso sapere a tempo di compilazione cosa vada a ritornare).\nEsempi di utilizzo di polimorfismo parametrico e di sottotipo Tipi maybe e result üü© Questi sono alcuni tipi ispirati alle monadi, solamente capire in che formato sono:\nMaybe: Some + None Result: come le promises di js, possiamo esprimere i risultati di errore e nel caso sia andato tutto bene. ","permalink":"https://flecart.github.io/notes/polimorfismo/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"monoforfo-\"\u003eMonoforfo üü©\u003c/h3\u003e\n\u003cp\u003eQuando non posso utilizzare un tipo come parametro. Ossia non possiamo definire una funzione generica.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide monomorfismo\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Polimorfismo/Untitled.png\" alt=\"image/universita/ex-notion/Polimorfismo/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"polimorfismo\"\u003ePolimorfismo\u003c/h2\u003e\n\u003cp\u003ePolimorfismo, come dice il nome, significa avere tante forme, in questo caso tanti tipi. Ma avere tanti tipi non √® una cosa ambigua? Questa cosa si risolve solitamente a compile time (facendo checks di sottotipo, oppure dispatch della funzione corretta).\u003c/p\u003e\n\u003ch3 id=\"tipologie-di-polimorfismo-3-\"\u003eTipologie di Polimorfismo (3) üü©\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide tipologie di monomorfismo\u003c/p\u003e","title":"Polimorfismo"},{"content":"In questa nota andiamo a trattare argomenti come tabelle di verit√†. Mappe di Karnaugh. E piccolissima introduzione ai circuiti integrati.\nBoole Un signor Boole ha creato le basi dell\u0026rsquo;algebra booleana su cui si basano le porte logiche dei computer moderni.\nTabelle di verit√† Le tabelle di verit√† sono sufficienti per descrivere il funzionamento di una porta logica.\nQuesta cosa √® possibile grazie alla limitatezza delle funzioni all\u0026rsquo;interno dell\u0026rsquo;insieme $\\{0,1\\}$ dominio di partenza e fine dell\u0026rsquo;algebra booleana.\nPropriet√† nell\u0026rsquo;algebra di Boole Prova a spiegare da solo queste leggi:\nPropriet√†: 9\nIdentit√† Null Idempotenza Inverso Commutativo Associativo Distributivo Assorbimento De morgan La tabella con le leggi\nEsercizio in classe:\n$\\bar{A} + A \\not= \\bar{A}A$ Dimostrare sta cosa usando le leggi di de Morgan ( e non dicendo che √® la legge dell\u0026rsquo;inverso), in pratica dire che $\\bar{A} + A = \\overline{\\bar{A}A}$. dsafds\nFunzione booleana Si possono utilizzare delle funzioni booleane per mappare gli zeri e uno a certi\nEsercizio in classe\nScrivere la tabella di verit√† per\n$$ A + \\overline{(B + C)}B $$La soluzione √® che vale solo per $A$, il secondo addendo √® tutto\nMintermini\n√à una variabile o la negazione di una variabile Su $n$ termini √® l\u0026rsquo;AND fra tutti il min termine, attraverso relazioni di mintermini si pu√≤ creare una funzione booleana. √à l\u0026rsquo;unica combinazione booleana in cui in una riga sola √® uno mentre in ogni altra riga √® falsa Una forma canonica √à una somma di alcuni mintermini, e questa √® unica per ogni funzione **booleana.\nLa forma canonica o funzione canonica di una espressione booleana √® un\u0026rsquo;espressione logica contenente tutte le variabili booleane in forma vera o negata, in forma di prodotti fondamentali o somme fondamentali di essi. Essa si ricava dalla tabella della verit√†.\nCircuiti combinatori: Sono l\u0026rsquo;implementazione della funzione booleana, e sono deterministici.\nTransistor e Array Struttura di un transistor Un transistor √® composto da tre parti principali:\nUn collettore che riceve una corrente esterna stabile Una base che riceve una corrente esterna e cambia la struttura del transistor a seconda che ci sia o no Un emettitore che lascia passare se c\u0026rsquo;√® corrente, altrimenti si comporta come resistenza infinita. Nand, Not e Nor Array programmabili Un insieme di And e Or che rappresentano la forma canonica per un elemento. Si possono programmare fondendo o lasciando alcuni fusibili per simulare l\u0026rsquo;uso del not, come in figura.\nMappa di Karnaugh Introduzione √à un metodo che prende la forma canonica e cerca di semplificarla con qualcosa di molto pi√π facile da implementare (prende una forma canonica e restituisce elementi semplificati) Non fa peggio della forma canonica ergo una forma semplificata o uguale che dia stessi output.\nSi pu√≤ fare anche a 3D o 4D per permettere l\u0026rsquo;uso per pi√π input ma non sempre √® facile immaginarsi 4 dimensioni, queste devono soddisfare il codice grey.\nCodice gray La mappa di Karnaugh deve essere un codice Gray\nCostruisco con la tecnica a specchio cio√® da una riga all\u0026rsquo;altro sto cambiando solamente una singola cifra.\nUtilizzando invece la numerazione delle tabelle di verit√† non funziona in quanto non possiede questa propriet√†.\nDalla pagina di wikipedia\nEsempi di applicazione Disegno\nSi possono scrivere in due modi, a seconda di come piace\nRaggruppamento\nbisogna creare grossi raggruppamenti ossia catturare pi√π uni possibile con pochi, fatto questo sono sicuro di creare una forma minimale.\nDopo questo scegli il raggruppamento pi√π piccolo e sarai abbastanza sicuro che sia minimale\nCircuiti integrati Di solito sono pezzi di silicone che variano di grandezza e struttura a seconda degli input e dei output per quello che si deve fare (questi sono anche chiamati Chip)\nLGA PGA Large Grid Array, Pin grid Array.\nCi sono due tipologie di Pin per i circuiti integrati\n! sti sono anche chiamati Chip)\n","permalink":"https://flecart.github.io/notes/porte-logiche/","summary":"\u003cp\u003eIn questa nota andiamo a trattare argomenti come tabelle di verit√†. Mappe di Karnaugh. E piccolissima introduzione ai circuiti integrati.\u003c/p\u003e\n\u003ch2 id=\"boole\"\u003eBoole\u003c/h2\u003e\n\u003cp\u003eUn signor Boole ha creato le basi dell\u0026rsquo;algebra booleana su cui si basano le porte logiche dei computer moderni.\u003c/p\u003e\n\u003ch3 id=\"tabelle-di-verit√†\"\u003eTabelle di verit√†\u003c/h3\u003e\n\u003cp\u003eLe tabelle di verit√† sono sufficienti per descrivere il funzionamento di una porta logica.\u003c/p\u003e\n\u003cp\u003eQuesta cosa √® possibile grazie alla limitatezza delle funzioni all\u0026rsquo;interno dell\u0026rsquo;insieme $\\{0,1\\}$ dominio di partenza e fine dell\u0026rsquo;algebra booleana.\u003c/p\u003e","title":"Porte Logiche"},{"content":"Introduzione al potenziale elettrostatico Abbiamo studiato in dinamica che il potenziale √® un concetto strettamente legato al Lavoro, ossia dalla quantit√† di energia necessaria per spostare un oggetto da un punto all\u0026rsquo;altro, vogliamo cercare di definire le relazioni che intercorrono nel caso della forza elettromagnetica\nRotore nullo =\u0026gt; forza conservativa üü© $$ \\vec{\\nabla} \\times \\vec{F} \\implies \\vec{F} \\text{ √® una forza conservativa} $$$$ \\oint_{L} \\vec{F} \\cdot d\\vec{l} = \\iint_{S} \\vec{\\nabla} \\times \\vec{F} \\,d\\vec{s} $$ E se abbiamo che il rotore √® nullo, allora la forza √® conservativa perch√© per definizione √® conservativa se non dipende dal percorso, e la cosa che un circuito chiuso √® sufficiente per dimostrare il sopra.\nNote mie che non ho ben capito: Questo si pu√≤ dimostrare senza molta difficolt√† se scriviamo la forza di coulomb nella forma cartesiana, alla fine facendo la derivata si dovrebbe cancellare tutto.\nForza radiale =\u0026gt; forza conservativa üü© Consideriamo una qualunque forza radiale e qualunque percorso lineare Consideriamo il setting come in immagine, abbiamo un qualunque percorso, e una carica che crea forza in modo radiale diciamo.\nAllora possiamo osservare se prendiamo un segmentino infinitesimale, ci sembrer√† una scaletta, ma la forza coseno √® attiva solamente in $\\bar{AB} \\text{ e } \\bar{CD}$ questo ci permette di affermare che il lavoro (quella cosa potenziale) √® solamente dipendente dalla distanza\nFormula dell\u0026rsquo;energia potenziale elettrostatica üü© Proviamo in questo momento a derivare la formula per il potenziale elettrostatico, valido per praticamente ogni percorso\n$$ L_{AB} = -\\int _{A}^{B} \\vec{F} \\cdot d\\vec{r} = -\\int _{A}^{B} \\lvert \\vec{F} \\rvert ds \\cos \\theta = -\\int _{A}^{B} \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Qq}{r_{p}^{2}} \\cos \\theta \\, ds = -\\frac{Qq}{4\\pi\\varepsilon_{0}} \\int _{A}^{B} \\frac{1}{r_{p}^{2}} \\, dr_{p} = \\frac{Qq}{4\\pi\\varepsilon_{0}} \\left( \\frac{1}{r_{a}} - \\frac{1}{r_{b}} \\right) $$ (col coseno dello spazio percorso, abbiamo che il valore dipenden solamente dalla distanza, per questo motivo √® semplice, un altro motivo per spiegare questo √® spezzettare il percorso con zigzag infinitesimi). E dall\u0026rsquo;ultimo possiamo capire il potenziale classicamente definito\n$$ U(r) = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Qq}{r} + const $$ Quindi dipende solamente dalla distanza a meno di una costante additiva. Il motivo per cui (credo) possiamo utilizzare la costante additiva √® che ci basta fissare un altro punto ad hoc, fissato un altro punto, diventa allora possibile definire il potenziale o l\u0026rsquo;energia potenziale in ogni punto dello spazio prendendo quello come riferimento.\nForza elettromotrice üü© Spiegato in maggiore dettaglio in Leggi di Ohm, dove iniziamo a parlare di circuiti. La circuitazione per un campo elettrico √® definito in modo molto simile a quello di una forza qualunque\n$$ \\mathbb{\\varepsilon} = \\oint_{L} \\vec{E} \\cdot d\\vec{l} $$E valgono esattamente le stesse propriet√† che abbiamo dimostrato sopra riguardo al rotore.\nPotenziale elettrostatico Definizione üü© Questa non √® una energia, si potrebbe dire che √® la capacit√† di creare energia potenziale per singole cariche\n$$ V(A) = \\frac{U(A)}{q} $$ Che in un certo senso √® il lavoro fatto dal campo, non dalla forza (NOTA: non √® corretto dire lavoro di un campo, non credo sia un concetto ben definito).\nAnalisi di dimensionalit√† per potenziale elettrostatico üü© $$ V(r) = \\frac{1}{4\\pi \\varepsilon_{0}} \\frac{Q}{r} \\implies \\left[ V \\right] = \\left[ U \\right] \\left[ Q^{-1} \\right] =\\left[ M \\right] \\left[ L^{2} \\right] \\left[ T^{-2} \\right] \\left[ Q^{-1} \\right] $$ E quindi potremmo misurare il campo elettrico anche come volt su metri, per la definizione con gli integrali\nPrincipio di sovrapposizione per potenziale elettrostatico üü© L\u0026rsquo;esatto principio che abbiamo descritto in precedenza per il campo elettrico vale anche il per il potenziale elettrostatico, anzi potrebbe essere utile nel calcolo del campo elettrico stesso se possiamo derivare in un singolo punto, otteniamo il campo elettrico in quel punto.\nSuperfici equipotenziali üü© Possiamo definire delle sfere che abbiamo tutti lo stesso potenziale elettrostatico, che da un punto di vista matematico basta stessa r ma serve il concetto di angolo solito per poter caratterizzare matematicamente questo concetto.\nTODO: avere superficie della sfera con angoli solidi, perch√© questa √® l\u0026rsquo;analisi pi√π semplice per superfici equipotenziali di singola carica\nEquazione di Poissonüü© $$ \\vec{\\nabla} \\cdot \\vec{E} = \\vec{\\nabla} \\cdot (-\\vec{\\nabla}V) = \\frac{\\rho}{\\varepsilon_{0}} $$ Quindi l\u0026rsquo;equazione di poisson √®\n$$ \\nabla^{2} V = -\\frac{\\rho}{\\varepsilon_{0}} $$ Nel caso in cui non ci sia carica in un punto nello spazio abbiamo l\u0026rsquo;equazione di Laplace\n$$ \\nabla^{2} V = 0 $$ Per qualche motivo a me oscuro, la soluzione dell\u0026rsquo;equazione di Poisson in coordinate cartesiane √®:\n$$ V(x, y, z) = \\frac{1}{4\\pi\\varepsilon_{0}} \\int _{\\Sigma} \\frac{\\rho(x', y', z')\\, dx'dy'dz'}{\\sqrt{ (x - x')^{2} + (y - y')^{2} + (z - z') ^{2} }} $$ Questo risulta utile per caratterizzare la soluzione dell\u0026rsquo;equazione di Poisson per il Vettore potenziale.\n","permalink":"https://flecart.github.io/notes/potenziale-elettrostatico/","summary":"\u003ch3 id=\"introduzione-al-potenziale-elettrostatico\"\u003eIntroduzione al potenziale elettrostatico\u003c/h3\u003e\n\u003cp\u003eAbbiamo studiato in dinamica che il potenziale √® un concetto strettamente legato al Lavoro, ossia dalla quantit√† di energia necessaria per spostare un oggetto da un punto all\u0026rsquo;altro, vogliamo cercare di definire le relazioni che intercorrono nel caso della forza elettromagnetica\u003c/p\u003e\n\u003ch4 id=\"rotore-nullo--forza-conservativa-\"\u003eRotore nullo =\u0026gt; forza conservativa üü©\u003c/h4\u003e\n$$\n\\vec{\\nabla}  \\times \\vec{F} \\implies \\vec{F} \\text{ √® una forza conservativa}\n$$$$\n\\oint_{L} \\vec{F} \\cdot d\\vec{l} = \\iint_{S} \\vec{\\nabla} \\times \\vec{F} \\,d\\vec{s}\n$$\u003cp\u003e\nE se abbiamo che il rotore √® nullo, allora la forza √® conservativa perch√© per definizione √® conservativa se non dipende dal percorso, e la cosa che un circuito chiuso √® sufficiente per dimostrare il sopra.\u003c/p\u003e","title":"Potenziale Elettrostatico"},{"content":"Language Constituents A constituent is a word or a group of words that function as a single unit within a hierarchical structure\nThis is because there is a lot of evidence pointing towards an hierarchical organization of human language.\nExample of constituents Let\u0026rsquo;s have some examples: John speaks [Spanish] fluently John speaks [Spanish and French] fluently\nMary programs the homework [in the ETH computer laboratory] Mary programs the homework [in the laboratory]\nThese sentences can be swapped without problem with each other. These group of words work like a single unit.\nAmbiguity üü®\u0026ndash; We expand on the first notions of ambiguity of natural language introduced here. We can see that ambiguous sentences have different constituents. Here is an example: [Fruit flies] [like [a green banana]] or Fruit [flies [like [a green banana]]]\nSources of ambiguity are\nattachment: I [shot [an elephant] [in my pajamas]] vs. I [shot [an elephant [in my pajamas]]] modifier scope [[plastic cup] holder] vs. [plastic [cup holder]] (Is it a holder for plastic cups or a cup holder made of plastic?) Others that are not treated here. Having different parse trees correspond to different consituents! The main idea is to create a probability distribution over possible parse trees, as some are more probable than others, then learn this distribution from data. Binding This is the analogous for natural language. We have studied these in many different settings: analysis of programming languages Nomi e Scope, logic Logica del Primo ordine and operative systems Paginazione e segmentazione. TODO: explain in the context of natural languages.\nContext-Free Grammar extensions We first introduced context free in these documents Descrizione linguaggio and Linguaggi liberi e PDA. Here we expand on a probabilistic version to model the likeliness of a given parse of an ambiguous structure.\nProbabilistic Context-Free Grammars The easiest way to extend this is to assign a probability to each production. After we have this, then the probability of a given three is just the product of all the production probabilities. This is a easy and natural way to extend the classic notion of derivation trees.\nPCFG are Locally Normalized $$ \\sum_{k = 1}^{K} p(\\alpha_{k} \\mid N) = 1 $$ Which mean for a single non-terminal, we would like that the sum of the probabilities of the productions is one, i.e. it is not leaked elsewhere. This is the same idea presented in Language Models.\nWeighted CFGs Instead of assigning a probability, we just add a weight to each of the production. In this case, what is important is the relative weight of the productions. Then we can use the same idea in Log Linear Models to put them back into a probability space. This is easier as we just need to assign a score over the productions, and not a probability. WCFGs are Globally Normalized $$ p(t) = \\frac{1}{Z} \\prod_{r \\in t} \\exp[\\text{(score}(r)] $$$$ Z = \\sum_{t' \\in \\mathcal{T}} \\prod_{r \\in t'}\\exp[\\text{(score}(r)] $$ For some grammars the normalizer could also diverge For example with the grammar $\\left\\{ S \\to S, S \\to a \\right\\}$ has infinite derivations of the same string $a$, but there are infinite ones.\nNormalized Grammars We solve this problem by converting the grammar into a Chomsky Normal Form (see Semplificazione grammatiche#Chomsky Normal Form). In this case the number of possible trees is no longer infinite, but around $\\mathcal{O}(4^{n})$, which is the number of rooted binary trees, which follows Catalan Numbers for some reason unknown to me. One interesting observation, is that the number of rooted binary trees of $n$ nodes has Catalan number $C_{n - 1}$ We lose the original structure of our tree but we gain on the possibility of computing the normalizer.\n$$ p(t \\mid s) = \\frac{1}{Z(s)} \\prod_{X \\to Y Z \\in t} \\exp(\\text{score}(X \\to Y Z)) \\cdot \\prod_{X \\to a \\in t} \\exp(\\text{score}(X \\to a)) $$$$ Z(s) = \\sum_{t' \\in \\mathcal{T}(s)} \\prod_{X \\to Y Z \\in t'} \\exp(\\text{score}(X \\to Y Z)) \\cdot \\prod_{X \\to a \\in t'} \\exp(\\text{score}(X \\to a)) $$The CKY parser Introduction to CKY The Cocke‚ÄìKasami‚ÄìYounger Algorithm provides an efficient way to compute the normalizer for a CNF grammar, in $\\mathcal{O}(n^{3} \\lvert \\mathcal{R} \\rvert)$, with $n$ length of our sentence and $\\lvert \\mathcal{R} \\rvert$ size of the rule-set of the CNF. Originally this algorithm has been developed for a classical recognition problem: given a string, recognize if the grammar accepts it. Goodman wrote a paper generalizing the algorithm to arbitrary semirings. Humans parse in linear time usually perhaps: they don\u0026rsquo;t need to rehearse and go back in the string. There could be local patches where humans are non-linear (i.e. they go back and try to make sense of it), but mostly a\nSee wikipedia for the pseudocode of the algorithm.\nThe Algorithm This is another dynamic programming algorithm. Originally, it has been used to compute the normalizer for a WCFG, but then it has been generalized by Goodman (1999) to arbitrary semirings. This allows to compute different things like\nBest parse tree Entropy of parse tree distribution Normalizing constant (its the case we are interested in) Let\u0026rsquo;s analyze this algorithm in detail. We need a WCFG, a score function for each production rule, and a sentence $s$ for which we want to compute the normalizer for the parsing trees. We first initialize the base of our dynamic programming table with the scores of the terminal rules. Then we iterate over the length of the sentence, and for each cell we iterate over the possible splits of the sentence in two parts, and we check if the two parts can be generated by the non-terminal $X$ in a span (a contiguous substring). If they can, then we add the score of the rule $X \\to Y Z$ to the score of the cell. This algorithm can be visualized in the following diagram: It is a little weird for the count starts, but other than that it is quite intuitive.\n","permalink":"https://flecart.github.io/notes/probabilistic-parsing/","summary":"\u003ch2 id=\"language-constituents\"\u003eLanguage Constituents\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA constituent is a word or a group of words that function as a single unit within a\nhierarchical structure\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eThis is because there is a lot of evidence pointing towards an hierarchical organization of human language.\u003c/p\u003e\n\u003ch4 id=\"example-of-constituents\"\u003eExample of constituents\u003c/h4\u003e\n\u003cp\u003eLet\u0026rsquo;s have some examples:\nJohn speaks [Spanish] fluently\nJohn speaks [Spanish and French] fluently\u003c/p\u003e\n\u003cp\u003eMary programs the homework [in the ETH computer laboratory]\nMary programs the homework [in the laboratory]\u003c/p\u003e","title":"Probabilistic Parsing"},{"content":"Introduction to the probabilistic Turing Machine Most of real phenomena are better comprehended by a probabilistic view. This pushes to build a formal model that takes probability into account\nDef: Probabilistic TM $$ \\mathbb{P}(b) = 2^{-k} $$ Where $k$ is the length of the branch. Then the probability of accepting the word is given by this:\n$$ \\mathbb{P}(\\mathcal{M} \\text{ accepts } \\omega) = \\sum_{b \\text{ is an accepting branch}} \\mathbb{P}(b) $$ Note that this is very similar to the Algorithmic probability defined in Kolmogorov complexity.\nWe have here a probability of error.\nBounded-error Probabilistic Polynomial Class This is the new complexity class of the Turing machine, and sort of is similar to the PAC model of the machine learning predictions.\nBPP is the class of languages that are decided by probabilistic polynomial time Turing machines with an error probability of $\\frac{1}{3}$ .\nFormal Language Models This is something very similar to this model, but needs to be investigated. See (Cotterell et al. 2023).\nReferences [1] Cotterell et al. ‚ÄúFormal Aspects of Language Modeling‚Äù 2023\n","permalink":"https://flecart.github.io/notes/probabilistic-turing-machines/","summary":"\u003ch2 id=\"introduction-to-the-probabilistic-turing-machine\"\u003eIntroduction to the probabilistic Turing Machine\u003c/h2\u003e\n\u003cp\u003eMost of real phenomena are better comprehended by a probabilistic view. This pushes to build a formal model that takes probability into account\u003c/p\u003e\n\u003ch3 id=\"def-probabilistic-tm\"\u003eDef: Probabilistic TM\u003c/h3\u003e\n$$\n\\mathbb{P}(b) = 2^{-k}\n$$\u003cp\u003e\nWhere $k$ is the length of the branch.\nThen the probability of accepting the word is given by this:\u003c/p\u003e\n$$\n\\mathbb{P}(\\mathcal{M} \\text{ accepts }  \\omega) = \\sum_{b \\text{ is an accepting branch}} \\mathbb{P}(b)\n$$\u003cp\u003e\nNote that this is very similar to the Algorithmic probability defined in \u003ca href=\"/notes/kolmogorov-complexity/\"\u003eKolmogorov complexity\u003c/a\u003e.\u003c/p\u003e","title":"Probabilistic Turing Machines"},{"content":"Condizionata Definizione üü© Andiamo a definire una probabilit√† di un evento $A$, condizionata a un evento non nullo $B$, come\n$$ P(A|B) = \\dfrac{P(A\\cap B)}{P(B)} $$Questo √® la cosa fondamentale per poter considerare cose come bayes perch√© in questo modo abbiamo una certa relazione fra causa ed effetto e anche il contrario! Cosa che ci piace molto molto molto.\nLa definizione di sopra √® un probabilit√† üü© Dimostrazione mia\ninanzitutto vediamo che soddisfatta il fatto che $P(A) \\in [0, 1]$, poi possiamo notare che\n$$ P(\\Omega | B) = \\dfrac{P(\\Omega\\cap B)}{P(B)} = P(B) / P(B) = 1 $$$$ P(\\bigcup A_n | B) = \\dfrac{P(\\bigcup A_i\\cap B)}{P(B)} = \\dfrac{P(\\bigcup (A_i\\cap B))}{P(B)} = \\sum_{i = 1} ^\\infty\\dfrac{P(A_i\\cap B)}{P(B)} $$Quindi ecco che √® una probabilit√† su Omega!\nL‚Äôultima disuguaglianza vale perch√© sto facendo unione di insiemi disgiunti. (che sono disgiunti per ipotesi.\nRegola della catena üü© Dimostrazione in libro\nQuesta √® uno delle propriet√† pi√π importanti che abbiamo per la probabilit√† √® molto interessante notare come basta una induzione cos√¨ semplice per fare questo\nFormula di disintegrazione o delle probabilit√† totali üü© Dimostrazione\nQuesto non √® tanto difficile da dimostrare, bisogna notare che\n$$ B = \\bigcup_i (B \\cap A_i) $$il che √® vero perch√© $\\forall i, j A_i \\cap A_j = \\empty, \\bigcup A_i = \\Omega$ per ipotesi, e quindi sto facendo una unione disgiunta, si ha per $\\sigma-$additivit√† la prima tesi, mentre la seconda tesi √® derivante dalla definizione di probabilti√† condizionate\nIndipendenza d\u0026rsquo;eventi Introduzione L‚Äôintuizione di maggior rilievo √® il fatto che non ho nuove informazioni se √® successo B ossia deve valere che $P(A|B) = P(A)$, oppure che $P(B|A) = P(B)$, dato che vale per entrambi, √® una propriet√† simmetrica.\nha quindi senso andare a definire che due eventi siano indipendenti se vale questa propriet√†:\n$$ P(A \\cap B) = P(A)P(B) $$√à molto importante notare che l\u0026rsquo;indipendenza di a due a due due eventi non implica l\u0026rsquo;indipendenza di 3! (guardare l\u0026rsquo;esempio sul libro)\nEsempio fatto in classe di questo\nSe ho un evento composto da due lanci un dado a 6 faccie, se considero gli eventi:\nAl primo lancio esce un numero dispari Al secondo un numero pari La somma dei due lanci √® pari. Si pu√≤ notare che insieme tutti non possono avvenire, ma se li prendo a due a due sono indipendenti, questo √® molto curioso come fenomeno!\nInfatti deve essere che valga la propriet√† di sopra per ogni singolo sottoinsieme. √à una cosa molto importante!\nCaso speciale\nNel caso in cui $P(A) = 0$ , oppure vale l‚Äôaltro, oppure basta che siano $P(A \\cap B) = 0$ ossia siano disgiunti allora secondo la definizione sono indipendenti, anche se logicamente dovrebbero essere dipendenti, dato che uno implica l\u0026rsquo;esclusione dell‚Äôaltro.\nTh Indipendenza e complementari üü® Dimostrazione\nDubbio vecchio\nLa dimostrazione √® un po`strana, per quale motivo per (ii) ‚Üí (i) √® necessario utilizzare l\u0026rsquo;induzione? Perch√© voglio dimostrarlo per ogni modo in cui posso scegliere un sottoinsieme! √à molto interessante come con il secondo riesco a dimostrare il tutto.\nRisposta:\nhai capito male la definizione di indipendenza, affinch√© sia indipendente, deve essere che lo siano tutti i sottoinsiemi di eventi! Quindi ci√≤ rende la dimostrazioen molto pi√π contorta.\n","permalink":"https://flecart.github.io/notes/probabilita-condizionata-e-indipendenza/","summary":"\u003ch2 id=\"condizionata\"\u003eCondizionata\u003c/h2\u003e\n\u003ch3 id=\"definizione-\"\u003eDefinizione üü©\u003c/h3\u003e\n\u003cp\u003eAndiamo a definire una probabilit√† di un evento $A$, condizionata a un evento non nullo $B$, come\u003c/p\u003e\n$$\nP(A|B) = \\dfrac{P(A\\cap B)}{P(B)}\n$$\u003cp\u003eQuesto √® la cosa fondamentale per poter considerare cose come bayes perch√© in questo modo abbiamo una certa relazione fra causa ed effetto e anche il contrario! Cosa che ci piace molto molto molto.\u003c/p\u003e\n\u003ch3 id=\"la-definizione-di-sopra-√®-un-probabilit√†-\"\u003eLa definizione di sopra √® un probabilit√† üü©\u003c/h3\u003e\n\u003cimg src=\"/images/notes/Probabilit√† condizionata e indipendenza/Untitled.png\" alt=\"Probabilit√† condizionata e indipendenza/Untitled\"\u003e\n\u003cp\u003e\u003cstrong\u003eDimostrazione\u003c/strong\u003e mia\u003c/p\u003e","title":"Probabilita condizionata e indipendenza"},{"content":"I problem idi accoppiamento sono abbastanza comuni per ottimizzazione a grafi. In questa serie di note andiamo a trattare brevemente i problemi principali, con un accenno veloce ad alcuni algoritmi di soluzione per esse.\nGrafo bipartitoüü© Un grafo bipartito √® un insieme $(O \\cup D), (A)$ di nodi e di archi. Tutti i nodi sono o fra i nodi di origine oppure fra i nodi di destinazione, e gli archi sono solamente collegati fra nodi di origine e nodi di destinazione.\nAccoppiamenti (lessico)üü© Consideriamo $M$ archi che non abbiano nodi in comune, vogliamo cercare in questo senso di fare un accoppiamento fra i nodi di origine e i nodi di destinazione.\ndiciamo accoppiamento perfetto se tutti i nodi sono stati accoppiati\nArco di bottleneck √® l\u0026rsquo;arco di costo massimo, che si dice costo di bottleneck.\nAccoppiamento di massima cardinalita Trasformazione del problemaüü© Vogliamo cercare di utilizzare gli algoritmi noti sui flussi di costo minimo e flusso massimo, algo di flusso massimo. In questo caso se giriamo il problema in modo opportuno possiamo renderlo un problema di flusso massimo\nCreo nuovo nodo fittizzio di origine e destinazione, in modo simile a quanto fatto in precedenza in Reti di flusso Capacit√† degli archi sono tutti 1, se c\u0026rsquo;√® flusso lo prendo, altrimenti no. (in questo senso i flussi devono essere interi! Osservazioni sulla tipologia di pathüü© La path che viene in questo modo creata dovr√† essere per forza alternanti, che vanno a rimbalzare fra i nodi interni!\nRicorda cosa sono gli archi interni e gli archi estermi.\nDato un insieme $M$ di tutti gli archi del nostro grafo bipartito che andiamo a prendere, consideriamo archi interni questi, ed archi estermi l\u0026rsquo;insieme $P - M$, con P tutti gli archi.\nChiaramente devo passare dalla sorgente alla destinazione, e lo posso fare solamente una volta per ecco che si pu√≤ dire che\n$$ |P_e| - |P_i| = 1 $$con Pe l\u0026rsquo;insieme degli archi esterni che prendo e Pi l‚Äôinsieme degli archi interni che vado a prendere, vado poi solamente a considerare la cardinalit√† di questo robo.\nQuesta osservazione √® importante per poter mettere in relazione molto stretta il fatto che i cammini aumentanti ‚Üî cammini alternanti con quella propriet√†, perch√© in questo modo il cammino alternante inizia e finisce in un nodo esterno, cio√® un nodo che non √® mai stato utilizzato per l‚Äôaccoppiamento.\nRelazione con Minimum Vertex Cover Abbiamo il teorema di K√∂nig che afferma che il numero di archi di un accoppiamento di cardinalit√† massima √® uguale al numero di nodi di un minimum vertex cover, in un grafo bipartito.\nAccoppiamento di costo minimo Possiamo utilizzare gli algoritmi di MCMF Tarjan e MCMF per risolvere questo problema qui! Importante notare che gli accoppiamenti devono essere perfetti, ossia non ho nessun nodo libero.\nAccoppiamento di minimo bottleneck Anche qui deve essere fra tutti gli accoppiamenti perfetti. In questo caso si cerca di avere il minimo arco maggiore possibile, non per forza il minimo di costo.\n","permalink":"https://flecart.github.io/notes/problemi-di-accoppiamento/","summary":"\u003cp\u003eI problem idi accoppiamento sono abbastanza comuni per ottimizzazione a grafi. In questa serie di note andiamo a trattare brevemente i problemi principali, con un accenno veloce ad alcuni algoritmi di soluzione per esse.\u003c/p\u003e\n\u003ch3 id=\"grafo-bipartito\"\u003eGrafo bipartitoüü©\u003c/h3\u003e\n\u003cp\u003eUn grafo bipartito √® un insieme $(O \\cup D), (A)$ di nodi e di archi. Tutti i nodi sono o fra i nodi di origine oppure fra i nodi di destinazione, e gli archi sono solamente collegati fra nodi di origine e nodi di destinazione.\u003c/p\u003e","title":"Problemi di accoppiamento"},{"content":"2 Problemi di ricerca In questa prima parte si tratta di ricerca semplice, ossia si utilizza un modello basato su obiettivi, di struttura atomica, in un ambiente che risulti singolo-agente, episodico, totalmente osservabile, deterministico, statico, discreto, conosciuto.\n2.1 Il problema Vogliamo cercare di enunciare in un modo che possa essere formale, senza nessuna ambiguit√† il concetto di problema di ricerca.\n2.1.1 Framework di soluzione Individuiamo 4 fasi principali per un problema di ricerca, questo √® un framework molto generico.\nFormulazione dell\u0026rsquo;obiettivo (si cerca di individuare l\u0026rsquo;obiettivo della nostra ricerca). Individuazione del problema (in cui si va a trascrivere il problema utilizzando una impostazione formale, solitamente astraendo dettagli non interessanti, il formato √® descritto subito dopo nella sezione articolazione) Ricerca della soluzione (in cui si cerca una effettiva soluzione per il problema di ricerca, probabilmente √® la parte pi√π dispendiosa di algoritmica). esecuzione della soluzione (in cui gli attuatori eseguino la soluzione del problema trovato) 2.1.2 Articolazione Vogliamo cercare di formalizzare il problema di ricerca nel modo pi√π chiaro possibile, lo facciamo separando le funzioni e dati necessari per definire tutti gli aspetti di un problema di ricerca:\nStati possibili Stato iniziale Stati obiettivo Funzione di azioni (da quale stato posso muovermi a quale stato) Funzione di costo (il movimento da questo stato a quello quanto mi costa ?) Funzione di transizione (mi muovo da uno stato all\u0026rsquo;altro) 2.1.3 Problemi standarizzati e reali Questi problemi sono standarizzati proprio perch√© rappresentano un modello su cui comparare altre soluzioni che verranno in seguito sviluppate. Sono un cardine per vedere l\u0026rsquo;efficienza di una propria soluzione, e simili.\nInvece i problemi reali possono avere una formulazione vaga, che cio√® √® dipendente dal contesto, o comunque da ci√≤ che sia necessario al momento.\nEsempi di standard problems:\n15/8 tile problem Knuth factorial problem (partendo da 4, e applicando fattoriale e radici, si pu√≤ fare qualunque numero) Esempi problemi reali\nTravelling salesman Chip VSLI 2.2 Note generali 2.2.1 Percorsi ridondanti Possiamo andare a definire un percorso ridondante, ogni percorso per cui se togli una tappa, il costo √® minore (ricordiamo che in questo libro parliamo sempre di percorsi con un peso positivo), quindi ridondanti sono cicli, o percorsi con qualche tappa in pi√π. Si pu√≤ considerare come se fosse un concetto pi√π generale di ciclo questo.\nOvviare alle ridondanze\nNon vogliamo trovare percorsi che siano alla fine ridondati, vogliamo in qualche modo ricordare il nostro percorso:\nAvere una tavola che ci dica se abbiamo gi√† fatto quel percorso o meno Avere una struttura, o formulazione del problema che non abbia questo problema di ridondanze (ad esempio una ricerca tipo-albero) Ovviare solo ai cicli, e non alle ridondanze in generale, come vi adi mezzo. 2.2.2 Valutazione dell\u0026rsquo;algoritmo In generale si valuta l\u0026rsquo;algoritmo secondo le risorse utilizzate, nel caso della ricerca in AI potrebbe essere il costo in soldi e in carburante, oltre alla classica memoria e tempo. Si propongono quindi 4 valori su cui valutare ci√≤:\nCompletezza (se esiste una soluzione perfetta la trovo sempre? Se non esiste so che non c\u0026rsquo;√®?) Ottimalit√† del costo della soluzione (es soldi etc). Costo in tempo Costo in memoria Di particolare interesse sarebbe valutare la completezza dell\u0026rsquo;algoritmo.\n2.3 Algoritmi disinformati Pseudocodice best-first-search\n2.3.1 Perch√© sono disinformati Chiamiamo questi algoritmi come disinformati perch√© non hanno idea di come √® fatta la struttura del campo di ricerca.\nIn pratica cercano con informazioni fortemente limitate sulla topologia del proprio ambiente.\nDirei che vadano a cercare valutando solamente il costo, o indiscretamente nodi quasi casuali dell‚Äôambiente circostante.\n2.3.2 Carrellata di algos Non mi √® piaciuto molto questa parte, perch√© la maggior parte degli algoritmi esposti √® presente nel corso di Algoritmi e Strutture fanno all\u0026rsquo;uni.\nBFS DFS Dept-limited dfs Dijkstra/uniform-cost-search Iterative deepening 2.4 Algoritmi informati Questi algoritmi informati sono molto pi√π interessanti rispetto agli algoritmi scorsi, per cui ne diamo pi√π larga discussione\nIl fatto che siano informati ci sta a significare soltanto che utilizzano un euristica per decidere meglio in che modo espandersi.\n2.4.1 Euristiche Bisogna cercare di definire in modo migliore le caratteristiche che ci potrebbero interessare delle euristiche: euristica ammissibile significa che la funzione di euristica √® sempre minore del costo effettivo.\nConsistente invece √® in pratica soltanto una forma della disuguaglianza triangolare.\nTrovare un euristica √® come risolvere una versione pi√π rilassata del problema, questa √® una delle osservazioni fondamentali per quando si va a trattare di euristiche.\nAltre soluzioni possibili sono Landmarks e pattern databases di cui rispettivamente i primi sono dei punti cardine, in cui si calcola tutto passando prima di quelli (come se mi chiedessi tipo: quanto ci metto se per andare da A a C, passo prima per il landmark B?) prima si calcolano questi landmark e si prendono decisioni in funzione di quanto mi danno ci√≤.\nI pattern databases sono solamente un modo per cercare soluzioni gi√† precomputate di pattern che ci sono solito. Si √® utilizzato un pattern database per 8-puzzle e funzionava distintamente bene.\nContours\nCome se fossero dei piano di livello di una montagna, anche per dijkstra si potrebbe disegnare un contour, ci indica in pratica in modo semplice in che modo si sta espandendo l‚Äôalgoritmo di ricerca.\n2.4.2 Carrellata algoritmi informati quella pi√π bella, usata in tutte le salse √® l‚Äôalgoritmo di A* Search, che in pratica √® un uniform cost search, che invece di utilizzare solamente la funzione costo g(n) che rappresenta quanto effettivamente si paga per raggiungere il nodo n, tiene in considerazione anche una funzione h(n) che cerca di stimare il costo da n a un goal.\nUna variante studiata √® il greedy-first-search che praticamente tiene in conto solamente dell‚Äôeuristica, senza la funzione di costo.\nAltre varianti come WEIGHTED A* search applicano un fattore di peso sull‚Äôeuristica, spesso rendendola non ammissibile o perfino inconsistente (non ho capito bene in che modo l‚Äôammissibilit√† e la consistenza modificano le caratteristiche dell‚Äôeuristica).\nTecniche che tengono molto in conto la memoria\nAltre studiate possono essere la RBFS (Recursive best first search, che √® simile a un MINIMAX con pruning, ma singolo agente, in pratica si espande sempre il nodo migliore, tenendo in conto il secondo valore migliore tra questi vicini, io continuo ad esplorare in profondit√† finch√© non mi converrebbe di pi√π cominciare ad esplorare qualcosa a un livello molto meno profondo).\nOppure la SMA* la simple memory A star, che in pratica tiene in considerazione un numero massimo di nodi in memoria, se nel momento in cui va ad espandere lo ha finito, rimuove il nodo pi√π vecchio, tenendo per√≤ un informazione riguardo quando costava esplorare quella via. (questo comunque pu√≤ condurre a problemi simili al thrashing, in cui continua a switchare percorsi, restando cos√¨ quasi bloccato).\nBEAM SEARCH va in modo molto focalizzato verso una direzione sviluppando solamente i primi k nodi migliori sulla frontiera, invece A* si sviluppa nel suo territorio (quindi ++ sui contorni)\n2.5 Interesse stato finale In questi problemi non ci importa pi√π di avere un percorso che ci porta alla soluzione, ma solamente la soluzione stessa. Non ci conviene pi√π utilizzare gli algoritmi di ricerca presentati al capitolo precedente in Problemi di ricerca. Quindi si sono sviluppati algoritmi che si comportassero bene per massimizzare anche gli obiettivi di questi.\nTermini importanti per parlare di questi ambienti:\nMassimo locale Ridge (che rende algoritmi greedy molto difficili da essere efficienti) Plateau, parti piatte 2.5.1 Hill Climbing Hill Climb in breve (pseudoalgo)\nQuesto √® uno degli algoritmi pi√π semplici per quanto riguarda la ricerca in questi ambienti, l‚Äôidea principale √® scegliere il migliore fra i propri successori, e seguire quella strada finch√© si pu√≤ migliorare.\nIl problema principale √® che questa versione semplice di Hill Climbing si blocca molto facilmente su minimi locali, o piani. Poi l‚Äôambiente di Ridge √® una cosa di difficilissima navigazione.\nQuindi si sono inventati variazioni che tentavano di risolvere questo problema:\nRandom restart, ricominciare da un punto random, prendendo alla fine la migliore fra tutte Local beam search, in cui si tengono ogni step i k migliori successori fra i k punti iniziali. Stochastic local beam search in cui randomicamente si considerano alcuni nodi anche lontani rispetto a questi, per cercare di sfavorire il fatto che tutti i punti migliori si ammassino su uno stesso punto. Stochastic hill climbing, in cui in cui si seleziona un punto a caso, e lo si segue sempre se √® migliore, e solo a volte se √® peggiore Simulated Annealing in cui la probabilit√† di scegliere il punto peggiore dall‚Äôaltra parte scende col tempo, con una funzione che decade esponenzialmente. 2.5.2 Algoritmi genetici Pseudoalgo\nLe caratteristiche generali di un algoritmo genetico sono in breve queste:\nDimensione della popolazione Rappresentazione della stringa genetica in caratteristiche della popolazione Funzione scelta dei n elementi pi√π adatti tra la popolazione Generazione di un figlio da coppie, o singola persona, o anche pi√π persone di queste. (crossover) Mutazione randomica di caratteri cos√¨ generati Elitismo o abbattimento di individui non adatti (a volte aiuta a velocizzare il processo). Ripetizione di ci√≤ fino a tempo finito o caratteristiche cercate trovate. La differenza principale con lo stochastic local beam search √® il momento di generazione di un nodo successore, che in questo caso, in quanto giustificato dalla biologica, o almeno da una forma contorta di biologia perch√© io personalmente credo che sia una forma eccessivamente semplificata, nonostante riconosco che √® un buon punto di partenza) √® generata da una ricombinazione di pi√π individui.\nSCHEMAS\nSi √® notato nel tempo (e lo si √® anche dimostrato) che gli algoritmi genetici hanno un senso solo se pattern vicini codificano informazioni importanti cio√® se i caratteri vicini non hanno nessuna relazione, √® totalmente inutile utilizzare un algoritmo genetico.\nPoi si √® notato che se un pattern specifico aiuta il progenito a sopravvivere, effettivamente √® probabile che si mandi alla generazione successiva. Ciononostante √® doveroso tenere a mente che non tutti i pattern necessari vengono trasferiti, e non tutti i pattern inutili vengono eliminati, leggere l‚Äôapprofondimento in biologia a pagina 136 dell‚Äôedizione cartacea che possiedi.\n2.5.3 In ambienti continui Se l‚Äôambiente √® continuo, √® di gran lunga di pi√π di interesse matematico. Si pu√≤ vedere come un problema di calcolo numerico nella ricerca di un punto di minimo come il Newton-Raphson-method, che si pu√≤ estendere anche a pi√π dimensioni.\nOppure si pu√≤ vedere come un problema di ottimizzazione-constrained, che si pu√≤ risolvere con programmazione lineare, cose che riguardano analisi di superfici convesse. In pratica idee e cose altamente tecniche che non conosco ancora.\nL‚Äôidea principale di questa parte comunque resta il fatto che si pu√≤ discretizzare l‚Äôambiente continuo, o cercando di aggiornarlo con passi piccoli, delta alla volta, in ogni direzione, o campionando lo spazio, dividendolo in tanti quadrettini lunghi delta, alla fine credo che questi approcci siano equivalenti.\n2.6 non-deterministiche e not-fully observable Introduciamo ora il concetto di belief state ossia una rappresentazione interna degli stati possibili dell‚Äôambiente. Per gli algoritmi presentati in Problemi di ricerca ogni singolo stato esterno corrispondeva lo stato di belief state interno, ossia c‚Äôera una corrispondenza, invece in questo caso andiamo a rilassare questo assunto, il determinismo, ossia il fatto che a una singola azione vada a corrispondere un singolo stato, ossia andiamo a dire che a singola azione, possono risultare una serie di stati differenti, maggiori di 1.\n2.6.1 And-Or tree (non-det) Con la possibilit√† di avere pi√π stati a seguito di una singola azione cerchiamo di dividere cose che sono sotto il controllo dell‚Äôagente e cosa non lo √®\nOR-node, √® una cosa che dipende dall‚Äôazione dell‚Äôagente AND-node, √® una cosa che dipende dalla reazione dell‚Äôambiente in seguito ad azioni dell‚Äôagente. Avendo questi due tipologie di nodi, possiamo andare a rappresentare l‚Äôintero ambiente attraverso un albero, per cui si possono utilizzare gli algoritmi di trasverse di alberi per trovare una soluzione che ora chiamiamo piano condizionale in quanto sar√† constituito da un array di azioni, nel caso si √® andato su un or-node, oppure di if-then, nel caso si stia andando avanti per un and-node.\nNota: soluzioni cicliche\nA volte converrebbe cercare di ragionare sui motivi della non-determinatezza perch√© in questo modo sappiamo se una soluzione ciclica, ossia una soluzione che ha per foglie solamente un obiettivo, ma nel suo percorso pu√≤ avere anche delle foglie che vadano in loop, sia effettivamente una soluzione: ossia il non-raggiungimento sia dovuto al caso, oppure a una sistematicit√† dell‚Äôambiente in cui si √® presenti.\n2.6.2 Osservabilit√† parziale Un aspetto che colpisce √® che in ambienti in cui l‚Äôosservabilit√† √® parziale, si possono ricavare delle informazioni semplicemente muovendosi, non per forza stando ad osservare l‚Äôambiente! diciamo in questo caso che lo stato √® coerced\nPer ricondurci da tale ambiente a un problema di ricerca trattato in Problemi di ricerca, possiamo fare una cosa molto simile a quanto √® fatto per Non-deterministic automata convertito a deterministic automata, ossia si ha una esplosione esplonenziale, ma comunque ben definita degli stati e delle funzioni di transizione che li legano.\nRicerca incrementale\nA volte conviene, invece di esplorare tutto insieme, come fa il non-determinismo, causando computazioni impraticabili, di provare a cercare una soluzione in via incrementale, buildando prima una soluzione che funzioni per un nodo, poi per il secondo, cambiando leggermente la soluzione trovata, e poi via.\nSi ha il risultato di trovare una soluzione o una assenza di essa in modo molto veloce.\n2.6.3 Percezione nell‚Äôosservabilit√† parziale Essendo un ambiente parzialmente osservabile, possiamo dare per scontato che esista una funzione Perceipt(state) che restituisce un insieme di stati osservati. Questa √® una funzione stretttamente legata all‚Äôambiente in cui agisce l‚Äôagente.\nAllora in un ambiente non-deterministico ad osservabilit√† parziale dovremmo approfondire la funzione di transizione, che non si pu√≤ considerare pi√π l‚Äôunione o l‚Äôintersezione dell‚Äôazione che viene applicata a tutti gli stati, ma qualcosa di meno perch√© deve prendere in conto anche la percezione (ad ogni azione corrisponde uno stato che corrisponde subito una percezione).\nLa dividiamo in 3 parti\nPredizione di quello che succede se applico l‚Äôazione a (ritorna un insieme di stati possiibili) Percezioni possibili lista delle percezioni possibili per tutti gli stati raggiunti. Aggiornamento degli stati di belief a un sottoinsieme a seconda degli stati raggiunti e delle percezioni possibili. In questo modo si forma sempre un albero di ricerca, di azioni non-deterministiche.\n2.6.4 Ricerca online La ricerca online ci fa avvicinare a come sia l‚Äôesplorazione in un mondo vero, in pratica ora lo stato del mondo √® dinamico, e dipende dalla presenza fisica dell‚Äôagente osservatore che non pu√≤ pi√π saltare da un nodo o un altro, oltre al fatto che lo stato pu√≤ cambiare anche se non sta facendo niente. (c‚Äô√® un problema riguardo punti di non ritorno, in cui le azioni sono irreversibili, ma questo lo tratteremo in capitolo seguenti).\nPseudocodice per DFS-online\nLa cosa stupida di questo algoritmo √® che non conosce le azioni che pu√≤ fare in un determinato stato, e potrebbe ripetere azioni che si cancellano fra di loro (es. UP e DOWN uno di seguito all‚Äôaltro). Le azioni qui dipendono dallo stato in cui si √® presenti!\nHill Climbing online (LRTA)*\nUn osservazione che si √® fatto con la DFS √® che ora si ha un oggetto fisico che si sposta, e non pu√≤ fare voli dall‚Äôaltra parte del labirinto per vedere come si sviluppa quel nodo di ricerca, per questo motivo possiamo affermare che c‚Äô√® bisogno di un algoritmo di ricerca locale, questo era HILL CLIMBING!\nMa avevamo discusso in precedenza che si poteva bloccare molto facilmente questo algoritmo! Ma non possiamo pi√π utilizzare random restart, dato che non esiste il teletrasporto, allora utilizziamo il random walk, in modo randomico scegli una direzione e la esplori.\nQuesta cosa adattata con anche una euristica che ti direzioni verso la parte giusta diventa un LRTA\nPseudocodice Learning RealTime A*\nIn pratica riaggiorna l‚Äôeuristica del costo a seconda delle proprie mosse.\n","permalink":"https://flecart.github.io/notes/problemi-di-ricerca/","summary":"\u003ch1 id=\"2-problemi-di-ricerca\"\u003e2 Problemi di ricerca\u003c/h1\u003e\n\u003cp\u003eIn questa prima parte si tratta di ricerca semplice, ossia si utilizza un modello basato su obiettivi, di struttura atomica, in un ambiente che risulti singolo-agente, episodico, totalmente osservabile, deterministico, statico, discreto, conosciuto.\u003c/p\u003e\n\u003ch2 id=\"21-il-problema\"\u003e2.1 Il problema\u003c/h2\u003e\n\u003cp\u003eVogliamo cercare di enunciare in un modo che possa essere formale, senza nessuna ambiguit√† il concetto di problema di ricerca.\u003c/p\u003e\n\u003ch3 id=\"211-framework-di-soluzione\"\u003e2.1.1 Framework di soluzione\u003c/h3\u003e\n\u003cp\u003eIndividuiamo 4 fasi principali per un problema di ricerca, questo √® un framework molto generico.\u003c/p\u003e","title":"Problemi di ricerca"},{"content":"Il processo e la gestione dell\u0026rsquo;esecuzione √® uno dei compiti principali dei sistemi operativi. Lo vuole fare in maniera efficace ed efficiente, come descritto in Note sull‚Äôarchitettura.\nSlide schema generale tabelle\nProcessi Il process control block √® la struttura di dati principali da comprendere.\nHa una tabella dei file aperti, che sono dei file descriptor (all\u0026rsquo;interno della propria struttura di dati), riferiti a una tabella dell\u0026rsquo;interno sistema credo, e questi puntano a un VNode che permette di localizzarlo nella memoria secondaria.\nDescrittori di processi (4) üü© √à anche un aspetto dei descrittori dei processi.\nSlide descrittori\nHo bisogno del codice segment code\nUno stack su cui lavorare, quindi memorizzare le cose temporanee\nsegment data per i dati necessari\nIl PCB per gli attributi necessari per disattivare attivare, o comunque descrive tutto il processo.\nIl PCB (3) üü®‚Äî Qui si parlano di attributi mantenuti nel PCB, sono di fondamentale importanza per il context switch, descritto in Scheduler\ninformazioni di identificazione di processo informazioni di stato del processo informazioni di controllo del processo Sono queste le informazioni principali mantenute.\nIdentificazione del processo\nindice nella tabella dei processi (problema di reincarnazione, se ho un nuovo processo al posto di uno che √® stato chiuso, allora non potrei riattivare un processo col vecchio pid), cos√¨ magari tutte le reference vecchie restano, con l‚Äôindice non riesco a farlo, potrebbe essere stato sostituito! numero progressivo che sarebbe il PID, che viene mappato al relativo descrittore, possiamo dire che il PID √® un identificatore logico! Che poi viene risolto al descrittore vero. Altre identificazioi come utente, gruppo, pid del padre, in modo che possa controllare l\u0026rsquo;accesso e le limitazioni del processo.\nInformazioni di stato del processo\nHo la necessit√† di avvicendare i processi, quindi ho bisogno di qualcosa per fermare e riattivare i processi, questa sezione di informazione √® utile per questa parte.\n√à importante che questi valori sono presenti i valori dell‚Äôultimo salvataggio perch√© salvo solo quando devo switchare, se sto runnando non ha senso che utilizzi queste cose.\nContenuto dei registri, normali e speciali (questi vengono persi quando facciamo switch), si potrebbe chiamare come se fosse una istantanea dei registri. La memoria in RAM √® meglio mantenerla, quindi non andiamo a ricordarlo. informazioni di controllo del processo\nUna lista enorme di cose per il controllo, cio√® in questa parte c‚Äô√® tanta roba!\nScheduling (forse pi√π importante come priorit√†, tempo di esecuzione etc). Gestione memoria, MMU. Risorse utilizzate (quindi accounting delle risorse) Comunicazione con altri processi. Slides\nStati dei processi (3) üü© Possiamo generalizzare lo stato del processo come se avesse principalmente 3 stati:\nRunning, il programma sta runnando senza problemi Waiting, il processo non pu√≤ essere eseguito perch√© sta aspettando qualcosa, es. un I/O Ready, il processo non √® eseguito, ma pu√≤ essere continuato quando la CPU ha tempo per dedicare ancora tempo a questo. Slide stati processi\nLa cosa carina che sembra essere descrivibile dallo schemini simili agli automi Grammatiche Regolari.\nSolitamente per gestire tutto l\u0026rsquo;insieme dei processi ready, lo si mette in una coda ready, ma esistono anche altre code come disk queue, terminal queue.\nGerarchie di processi üü© √à molto facile fare cose a sua immagine e somiglianza, ci sono molti campi in cui basta fare una copia, e ho la maggior parte delle informazioni che mi interessano.\nSpecifico solo quello che cambio. Questo rende molto facile creare nuovi processi, basta cambiare ci√≤ che √® diverso!\nSistema gerarchico UNIX\nBound sui processi (2) üü© Si pu√≤ dire che un processo sia CPU bound, I/O bound, queste sono le cose che interessano poi allo Scheduler per decidere cosa fare.\nil primo, CPU, quando fa calcoli che sono molto lunghi.\nIl secondo I/O, quando fa richieste IO che prendono molto tempo.\nIn generale i processi si possono descrivere come in alternanza continua fra CPU use e richieste IO.\nSlide descrizione bounds processi\nEsempio di CPU e IO bound\nThreads Il processo √® il titolare delle risorse di elaborazione ma pu√≤ eseguire solamente una cosa alla volta. Con i thread possiamo dividere il processo in pi√π linee esecutive che condividono delle risorse.\nQuesta √® una cosa molto comoda, per esempio quando ho un browser ho bisogno di un altro thread per scaricare in modo contemporaneo pi√π file. Sono pi√π linee di controllo. ma pi√π vantaggioso rispetto a fare processi separati, perch√© mi permette la pi√π facile condivisione di risorse. (dovrei mettermi a mandare messaggi anche per cose banali, quindi anche leggero overhead, per copiare molte informazioni Message Passing).\nVantaggi sui processi üü©- Condivisione di memoria facile Molto pi√π facile fare context switch di thread che di processi. (pu√≤ essere un ordine di grandezza pi√π veloce) Facilit√† di scrittura del codice, rispetto a message passing e pi√π processi. I lati negativi sono:\nMolti descrittori Molti context switch Quindi utilizzo leggermente pi√π risorse con i thread.\nInformazioni dei thread (2) üü®‚Äî ha informazioni parziali rispetto al processo, con cui condividono un sacco di cose, come dati, I/O, e il codice del programma.\nStack separato. Program counter proprio, dato che voglio una storia esecutiva indipendente. (e quindi anche propria copia dei registri). In questo modo sposto il livello di running e waiting al singolo thread.\nKernel e user thread Questo la saltato boh\nPer√≤ ora sono tutte livello kernel e user non viene pi√π utilizzato.\nLa differenza sta nel fatto se il kernel sia a conoscenza o meno dell‚Äôesistenza dei threads (se √® a consocenza per esempio ci pu√≤ fare scheduling, mentre altrimenti no, per√≤ se ne √® a conoscenza deve tutto essere gestito dal kernel, questo in qualche modo rende molto pi√π pesante la gestione).\nRelation threads Anche questi sono stati saltati\n","permalink":"https://flecart.github.io/notes/processi-e-thread/","summary":"\u003cp\u003eIl processo e la gestione dell\u0026rsquo;esecuzione √® uno dei compiti principali dei sistemi operativi. Lo vuole fare in maniera efficace ed efficiente, come descritto in \u003ca href=\"/notes/note-sullarchitettura/\"\u003eNote sull‚Äôarchitettura\u003c/a\u003e.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide schema generale tabelle\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Processi e thread/Untitled.png\" alt=\"image/universita/ex-notion/Processi e thread/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"processi\"\u003eProcessi\u003c/h2\u003e\n\u003cp\u003eIl process control block √® la struttura di dati principali da comprendere.\u003c/p\u003e\n\u003cp\u003eHa una tabella dei file aperti, che sono dei file descriptor (all\u0026rsquo;interno della propria struttura di dati), riferiti a una tabella dell\u0026rsquo;interno sistema credo, e questi puntano a un VNode che permette di localizzarlo nella memoria secondaria.\u003c/p\u003e","title":"Processi e thread"},{"content":"Vogliamo cercare di restare nel nostro spazio delle soluzioni ammissibili, senza dover stare ad esplorare tutto, vogliamo andare a concentrarci su una parte specifica di essa. Vogliamo utilizzare una struttura fondamentale per i problemi di programmazione lineare, che √® quello con cui vogliamo andare a fare. Il fatto √® che spostandoci leggermente da un punto tra le soluzioni, possiamo gestire in modo molto semplice il modo con cui si sposta la retta dei valori.\nQuesto √® possiamo ridurci a considerare i vertici del poliedro che si costruisce, quindi andiamo in questa prima parte a definire alcune nozioni matematiche utili a mettere in gioco questa intuizione\nNozioni preliminari Vocabolario di base Iperpiano L\u0026rsquo;insieme delle soluzioni di equazioni in\n$$ \\left\\{ x \\in \\mathbb{R}^{n} \\mid a^{T}x = b, a \\neq 0 \\right\\} $$ E si pu√≤ dimostrare che questo √® un insieme affine, quindi √® una linea. Questi piani sono anche convessi perch√© prendiamo tutti i punti ü§†. Una nota interessante √® che in analisi dei dati √® molto difficile che i punti non siano linearmente separabili in uno spazio con molte dimensioni. Le nostre intuizioni con low dimensions spesso non funzionano. Un esempio banale √® il volume di una sfera n dimensionale, che √® molto pi√π concentrata sui bordi.\nSemispazio $$ \\left\\{ x \\in \\mathbb{R}^{n} \\mid a^{T}x \\geq b, a \\neq 0 \\right\\} $$Lo spazio √® diviso fra zone in cui √® maggiore e altre in cui √® minore. Questi non sono affini ma sono solo convessi (perch√© limitati in certe zone)\nPalla euclidea $$ B(x_{c}, r) = \\left\\{ x \\mid \\lvert x - x_{c} \\rvert _{2} \\leq r \\right\\} = \\left\\{ x _{c} + ru \\mid \\lvert u \\rvert _{2} \\leq 1 \\right\\} $$ Dove $r$ √® chiamato raggio.\nEllissoide $$ \\left\\{ x \\mid (x - x_{c})^{T} P^{-1} (x - x_{c}) \\leq 1 \\right\\} $$$$ \\left\\{ x_{c} + Au \\mid \\lvert u \\rvert _{2} \\leq 1 \\right\\} $$Poliedro $$ \\left\\{ x \\mid Ax \\leq b \\right\\} $$ Per qualche valore di $A$ e $b$.\nUn poliedro √® una qualunque intersezione di semispazi (anche vuota, ma non √® molto interessante un poliedro vuoto), ed √® un insieme sempre convesso perch√© l‚Äôintersezione di cose convesse √® ancora convesso.\nL‚Äôamico del poliedro che deve essere per forza finito √® il politopo. (che √® la versione non bounded, ma alcuni autori utilizzano una definizione opposta, ma comunque non √® molto importante).)\nFacce üü® Formalmente:\nPreso un poliedro, andiamo a definire una sua faccia, un insieme di punti che soddisfano queste caratteristiche:\nGiace direttamente su una o pi√π condizioni Giace dentro il poliedro (quindi ogni punto della faccia √® un punto del poliedro anche!) Che matematicamente si possono andare a caratterizzare in questo modo: sia $I$ l‚Äôinsieme degli indici delle condizioni della matrice del poliedro che andiamo a prendere, e $\\bar{I}$ il suo complementare, allora\n$$ P_I = \\{x: A_Ix=b_I \\wedge A_{\\bar{I}}x \\leq b_{\\bar{I}} \\} $$Intuitivamente L\u0026rsquo;intuizione per questa parte √® prendere un sottoinsieme che ci piace riguardante la nostra matrice, quella cosa corrisponder√† a una faccia del nostro poliedro.\nnozioni sulla dimensione della matrice finale √® molto buona, ci pu√≤ dare un concetto di dimensione della faccia che andiamo a prendere. Per fare un esempio, se riusciamo ad avere una faccia di dimensione n, √® un singolo punto, quindi √® un vertice!\nin generale, come dicono le dispense vale la relazione sul fatto che\nE` possibile verificare che una faccia determinata da una matrice AI di rango k ha dimensione n ‚àí k o inferiore, pagina 8 dispense 3.\nSpigoli e vertici e soluzioni base üü© Una sottomatrice di dimensione n, √® un vertice!.\nUna sottomatrice di dimensione n - 1 √® uno spigolo!.\nQuesto sar√† il nostro spazio di ricerca quelli sui vertifici!\nSoluzione di base\nParlano dei vertici e lo fanno attraverso il concetto di invertibilit√†. Una soluzione di base non √® detto che faccia parte del poliedro che stiamo andando a considerare! Vogliamo andare a considerare delle basi ammissibili ossia che sono anche all\u0026rsquo;interno del poliedro (un esempio ez. √® il vertice).\nMatrice di base, ammissibilit√† o non della base.\nVincoli attivi üü®+ I vincoli attivi sono vincoli del nostro problema che vengono soddisfatte come uguaglianze. Questa √® una cosa di interesse, per ragioni che mi sono ancora oscure.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Programmazione lineare/Untitled 2.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Programmazione lineare/Untitled 2\u0026quot;\u0026gt; $$ I(x) = \\{ i | A_ix = b_i\\} $$Questa notazione pi√π o meno ci dice quante righe della matrice sto andando poi a contare\nCose convesse Trattate un po\u0026rsquo; meglio in Analisi di Convessit√†.\nInviluppi convessi üü© Queste cose ci sono molto utili, vanno simili al concetto di Base e dimensione, cercare di riassumere un insieme di punti illimitato con alcuni punti cardine limitati. In questo caso considero l\u0026rsquo;insieme , $X = \\{x_1, ..., x_n\\}$\n$$ conv(X) = \\{ \\sum _{i = 0} \\lambda_ix_i | \\sum_{i = 0} \\lambda_i = 1 \\land \\lambda_i \\geq 0\\} $$Questo insieme ci √® sufficiente per avere un politopo, per il caso infinito dovremmo andare sui coni.\nPer ora basta avere un intuizione per questo. Riusciamo a costruire in questo modo tutti i spigoli che uniscono i nostri punti di vertice, e partendo da questi possiamo andare a costruire l‚Äôintero politopo, ma la dimostrazione formale non la andiamo a dare.\nConi convessi See Analisi di Convessit√†#Convex Cone. Il concetto di cono convesso ci aiuta a costruire il caso infinito, considerando alcune operazioni di prolungamento e somma\n$x,y \\in C, \\lambda, \\beta \\in \\mathbb{R} \\implies \\lambda x + \\beta y \\in C$\nPossiamo provare a generalizzare questo concetto utilizzando la somma fra tutti i possibili\n$V = \\{ v_1, ... v_n\\}$\n$$ cono(V) = \\{ \\sum _{i = 1} \\lambda_i v_i | \\lambda_i \\in \\mathbb{R} ^+\\} $$Teorema di Motzkin o di decomposizione (!) üü®+ Slide\nQuesto √® un teorema molto importante perch√© teorema caratterizzante dei poliedri!\nIntuizione\nPi√π o meno questo teorema ci dice che tutti i poliedri possono essere ridotti a un insieme di punti di partenza, che quasi vanno a formare una base (nel caso del politopo sono solamente questi punti di base, il cono che andiamo a considerare √® vuoto!) e poi poter estenderli in una direzione utilizzando il cono!\nDifferenza dimensione motzkin e vincoli\nL‚Äôutilizzo pi√π importante di questo teorema √® che possiamo caratterizzare i poliedri in modo molto pi√π semplice, differentemente a quanto fatto con i vincoli lineari, perch√© quelli hanno un‚Äôesplosione esponenziale per quanto riguarda il numero di vertici. (nota importnate √® che i vertici non si calcolano in modo molto veloce fra i vertici e i vincoli lineari!).\nVertici ‚Üí exp\nVincoli ‚Üí lin.\nQuesta differenza di crescita non ci piace proprio! Non ci piace andare a cercare il numero di vertici se questi vertici crescono in modo esponenziale!\nTh esistenza dell‚Äôottimo finito (!!) üü®++ $$ P = \\text{conv}\\left( \\left\\{ x_{1}, \\dots, x_{s} \\right\\} \\right) + \\text{cone}\\left( \\left\\{ v_{1}, \\dots, v_{t} \\right\\} \\right) $$ Then the problem $\\max\\left\\{ cx \\mid Ax \\leq b \\right\\}$ has an finite optimal point if and only if $cv_{j} \\leq 0$ for all $j \\in \\left\\{ 1, \\dots, t \\right\\}$. In this case $\\exists k \\in \\left\\{ 1, \\dots, s \\right\\}$ such that $x_{k}$ is the optimal solution.\nDimostrazione Questo teorema lega in modo molto forte la parte di cono convesso con la soluzione del nostro problema lineare!\nossia possiamo avere soluzione solo se il cono non si espande verso l\u0026rsquo;infinito positivo, se succede, la soluzione ottimale √® infinito, altrimenti possiamo andare a scartare il contributo negativo del cono, e tenerci solamente il contributo dato dalla inviluppo convesso.\nTeoria della dualit√† Moved to Duality Theory\n","permalink":"https://flecart.github.io/notes/programmazione-lineare/","summary":"\u003cp\u003eVogliamo cercare di restare nel nostro spazio delle soluzioni ammissibili, senza dover stare ad esplorare tutto, vogliamo andare a concentrarci su una parte specifica di essa. Vogliamo utilizzare una struttura fondamentale per i problemi di programmazione lineare, che √® quello con cui vogliamo andare a fare. Il fatto √® che spostandoci leggermente da un punto tra le soluzioni, possiamo gestire in modo molto semplice il modo con cui si sposta la retta dei valori.\u003c/p\u003e","title":"Programmazione lineare"},{"content":"Vorremmo cercare di stabilire una teoria riguardante programmi che vengono eseguiti appunto concorrentemente, senza una esecuzione classica uno dpo l‚Äôaltro\nEsempio mini-programma rallentamento\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; void test(void *s) { for (int i = 0; i \u0026lt; 10; i++) { printf(\u0026#34;%s\\n\u0026#34;, s); for (int j = 0; j \u0026lt; 100000000; j++); } } int main(int argc, char *argv[]) { pthread_t t1, t2; pthread_create(\u0026amp;t1, NULL, (void *)test, \u0026#34;Uno\u0026#34;); pthread_create(\u0026amp;t2, NULL, (void *)test, \u0026#34;Due\u0026#34;); pthread_join(t1, NULL); pthread_join(t2, NULL); } Example output:\nDue Uno Uno Due Uno Due Due Uno Due Uno Due Uno Due Uno Due Uno Due Uno Due Uno\nEsempio 2 mini-programma rallentamento\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int count = 0; void test(void *s) { for (int i = 0; i \u0026lt; 100000; i++) { count+= 1; } } int main(int argc, char *argv[]) { pthread_t t1, t2; pthread_create(\u0026amp;t1, NULL, test, \u0026#34;Uno\u0026#34;); pthread_create(\u0026amp;t2, NULL, test, \u0026#34;Due\u0026#34;); pthread_join(t1, NULL); pthread_join(t2, NULL); printf(\u0026#34;%d\\n\u0026#34;, count); } Vogliamo creare un modello teorico che riesca a rappresentare il concetto di processi concorrenti, questo √® il modello concorrente\nProcessi Differenza col programma üü© Il programma √® statico, mentre il programma √® dinamico. Questo perch\u0026rsquo;e il processo √® un programma attivo, in esecuzione. Un filo esecutivo, qualcosa che evolve in modo autonomo.\nInvece il programma √® la sequenza di istruzioni.\nFinite progress üü© Ogni processo viene eseguito a velocit√† finita non nulla\nDescrizione del processo (3) üü© Questa parte √® descritta meglio in Processi e thread\nPossiamo descrivere lo stato di un processo memorizzando alcuni dati molto precisi, questi sono:\nStato di avanzamento (Istruzione da eseguire e il suo stato) La sua memoria utilizzata (dati, stack e file aperti) Memoria nel processore (i dati nel registro e simili) Concorrenza Concorrenza e dove trovarla\nDefinizioni concorrenza e Race C üü© Esecuzione concorrente\nDue processi si dicono in esecuzione concorrente se vengono eseguiti in parallelo (con parallelismo reale o apparente)\nConcorrenza\nUn insieme di notazioni e tecniche per rappresentare e risolvere problemi di esecuzione concorrente.\nRace condition\nSi dice che un sistema di processi multipli presenta una race condition qualora il risultato finale dell\u0026rsquo;esecuzione dipenda dalla temporizzazione con cui vengono eseguiti i processi\nTipologie di concorrenza (3) üü© Multiprogramming\n√à un parallelismo apparente perch√© la CPU √® solamente quella, ma esegue tante cose e cos√¨ velocemente che sembra star eseguendo in modo parallelo. Si parla infatti di interleaving.\nMultiprocessing\nparallelismo reale perch√© effettivamente ho tante CPU, o tanti core in cui far eseguire programmi in modo contemporaneo, in questo caso, come anche nell\u0026rsquo;esempio seguente si parla di overlapping (distanti nello spazio)\nDistributed processing\nParallelismo reale ma a una scala pi√π grande che va oltre al singolo computer dato che ho un sistema di pi√π computer che eseguono pi√π processi\nEsempio di problema di concorrenza üü©- Codice slide cattivo\nSuccede un problema molto simile a read after write, che un programma ha uno stato non aggiornato e fa una operazione con informazioni vecchie che sovrascrivono le informazioni nuove.\nEsempio multiprogramming di esecuzione errata\nEsempio multiprocessing di esecuzione errata\nPossiamo andare a cercare le cause di questi problemi, che sono principalmente causati da\nCause principali (comuni a multiproc e multiprog)\nAccesso a memoria condivisa Sconosciuta velocit√† di esecuzione del singolo processo. Interazione fra progressi(2)üü© Vogliamo cercare di avere alcuni metodi affinch√© due processi differenti si possano coordinaree cooperare.\nConoscenza indiretta\nQuando condividono un pezzo di memoria e comunicano in questo modo indiretto.\nConoscenza diretta\nQuando un processo conosce un ID di un altro processo e manda proprio dei messaggi e cose all‚Äôaltro programma\nPropriet√† cooperazione (2) üü©- Propriet√† vogliamo dire una caratteristica che rimane vera per ogni esecuzione del programma, come se fosse un teorema per il programma.\nSafety ‚Üí Correttezza\nVuol dire che il programma non fa cose cattive (se pu√≤ scegliere fra due valori, devono scegliere lo stesso valore).\nun programma non interferisce con un altro.\nLiveness ‚Üí Terminazione\nOssi ail programma continua ad eseguire rimane vivo e ritorna il suo risultato e fa quello che deve fare (ossia deve arrivare a soluzione).\nUn programma non deve essere interrotto ininterrottamente (ossia non deve continuare all\u0026rsquo;infinito) (possiamo dire che non c\u0026rsquo;√® starvation in questa parte).\nMutua esclusione, Deadlock e starvation üü© l\u0026rsquo;accesso ad una risorsa si dice mutualmente esclusivo se ad ogni istante, al massimo un processo pu√≤ accedere a quella risorsa\nDeadlock\n√à un problema che √® risolto dalla mutua esclusione (in cui due programmi interferiscono fra di loro e causano questo blocco).\nDa vedere l‚Äôesempio dei programmi\nEsempio in figura degli incroci\nEsempio programmi\nStarvation\n√à un problema di liveness dato che pu√≤ capitare che un processo sia sempre messo davanti a un altro, e quindi un certo programma non verrebbe mai eseguito.\nEsempio coda\nEsempio programmi\nAzioni atomiche üü© Propriet√†:\nIndivisibile O avviene o non avviene niente Nel linguaggio c in particolare, dipende da processore e compilatore (perch√© potrebbe utilizzare istruzioni che non si traducono in una singola in codice macchina).\nEsempi atomicit√† di istruzioni in C\nParallelismo reale\nquesta azione atomica non interferisce con altri\nAl fine di raggiungere questo obiettivo viene utilizzato un sistema di arbitraggio dei bus. (quindi un processo prende prima dell‚Äôaltro).\nParallelismo apparente\nil context switch avviene prima o dopo l‚Äôazione. Questo √® possibile perch√© l‚Äôinterrupt √® sempre runnato prima o dopo quell‚Äôazione.\nNote sul C (non importante, + pratica) Inizialmente questo linguaggio √® nato proprio per scrivere sistemi operativi, non si scrive in assembly perch√© questo linguaggio non √® portabile su macchine diverse.\nCaratteristiche di linguaggio per SO Possibilit√† di gestione completa dei dati nella memoria. Leggibilit√† di un linguaggio di alto livello https://so.v2.cs.unibo.it/wiki/index.php/Prin_C_ples\nEsempietto boostrap\nEsperimento didattico: portabilit√† dei compilatori\nHo un linguaggio di alto livello L, e una macchina fisica M e una macchina intermedia N, vorrei fare un compilatore da L a M.\nAllora ho un compilatore da L a M che gira in N molto scrauso. Mi scrivo il compilatore da L a M che gira in N, lo compilo e ho un compilatore da L a M scritto in M\n","permalink":"https://flecart.github.io/notes/programmi-concorrenti/","summary":"\u003cp\u003eVorremmo cercare di stabilire una teoria riguardante programmi che vengono eseguiti appunto concorrentemente, senza una esecuzione classica uno dpo l‚Äôaltro\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eEsempio mini-programma rallentamento\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;stdio.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;pthread.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003etest\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;%s\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ej\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ej\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e100000000\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eargc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003echar\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eargv\u003c/span\u003e\u003cspan class=\"p\"\u003e[])\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epthread_t\u003c/span\u003e \u003cspan class=\"n\"\u003et1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003et2\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epthread_create\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003et1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eNULL\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"n\"\u003etest\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;Uno\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epthread_create\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003et2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eNULL\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"n\"\u003etest\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;Due\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epthread_join\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003et1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eNULL\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epthread_join\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003et2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eNULL\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eExample output:\u003c/p\u003e\n\u003cp\u003eDue\nUno\nUno\nDue\nUno\nDue\nDue\nUno\nDue\nUno\nDue\nUno\nDue\nUno\nDue\nUno\nDue\nUno\nDue\nUno\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEsempio 2 mini-programma rallentamento\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;stdio.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;pthread.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ecount\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003etest\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e100000\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"o\"\u003e++\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003ecount\u003c/span\u003e\u003cspan class=\"o\"\u003e+=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eargc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003echar\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eargv\u003c/span\u003e\u003cspan class=\"p\"\u003e[])\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"kt\"\u003epthread_t\u003c/span\u003e \u003cspan class=\"n\"\u003et1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003et2\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003epthread_create\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003et1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eNULL\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etest\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;Uno\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003epthread_create\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003et2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eNULL\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etest\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;Due\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003epthread_join\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003et1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eNULL\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003epthread_join\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003et2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eNULL\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;%d\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecount\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eVogliamo creare un \u003cstrong\u003emodello\u003c/strong\u003e teorico che riesca a rappresentare il concetto di processi concorrenti, questo √® il modello concorrente\u003c/p\u003e","title":"Programmi Concorrenti"},{"content":"Project, product management, project management Bisogna capire queste definizioni. Vedere https://dynamik.vercel.app/ingegneria-del-software/lucidi/13-gestione-del-progetto.pdf?from=informatica, slide 5 per definizione\nProgetto: inizia e finisce in tempo preciso. √à importante comunque ricordare gli steps principali per il progetto ossia ideazione, creazione, mantenimento, rilascio, e poi morte, questo in genere √® per qualunque progetto.\nProject Manager Compiti principali (costi e risorse) Vedere se il progetto √® fattibile Allocare risorse Monitorare come sta andando. (preventivo e consuntivo). Work Breakdown structure Descrizione WBS √à una suddivisione del progetto in piccoli sottoparti che si possono gestire in modo autonomo.\nA Work Breakdown Structure (WBS) is a hierarchical decomposition of a project into phases, deliverables, and work packages. It is a visual representation that helps project managers and teams organize and define the scope of work required to complete a project. The WBS breaks down the project into smaller, more manageable components, making it easier to plan, execute, and control.\nhttps://chat.openai.com/share/1d74fa24-d198-4c17-9fbe-1c8cc93333d4\nSi pu√≤ rappresentare con un grafico di Gantt (vedi Scheduler#Diagramma di Gantt). Perch√© cos√¨ so quando ogni singola attivit√† inizia e finisce.\nMilestone e percorso critico Debito tecnico Il debito tecnico √® una stima del costo di futuro sforzo addizionale causato da una soluzione prematura adottata oggi pur di consegnare un prodotto con qualche valore (lo sforzo futuro andr√† ripagato con gli interessi)\nIl costo di versioni successive, √® costo in debito tecnico, per questo motivo √® maggiore. E si dovrebbe dare valore prima.\nMisura dei costi di sviluppo Misura nel software costo e valore del software Valore √® sul ricavo -\u0026gt; numero di utenti * ricavo medio. Mentre il costo del software e tempo persona.\nPer stimare il costo usiamo 4 cose:\nCosto hardware Costo sviluppo del software Costo risorse umane Durata del progetto. Metodi generici di stima (4) Design-to-cost nel senso che chi √® in industria fa prodotto tailored al costo. L\u0026rsquo;ultima √® funzionale\nLinee di codice (fisiche e logiche) Fisiche sono quelle effettivamente presenti nel codice, invece le linee logiche sono quelle che contengono istruzioni base (per base intendo quelli C like). Se si riesce a fare una stima dell\u0026rsquo;architettura del progetto, e poi delle linee logiche necessarie per fare questo sviluppo, possiamo tenere conto di una media di numeri giornalieri, e possiamo calcolare cose come costo totale del software avendo una media per riga. Chiaramente mi sembra che questa stima sia fortemente imprecisa.\nVantaggi e svantaggi di LOC La cosa carina di questo metodo √® che √® facile da fare. Poi abbiamo metriche derivate molto semplici da intendere come:\nBugs per kLoC. la produttivit√† √® una cosa molto facile. Il costo per linea di codice Sono certe metriche che potrebbero servire lato business, per√≤ sono abbastanza senza senso per quanto riguarda features date al cliente. Mi sembra il caso in cui una metrica pu√≤ diventare facilmente l\u0026rsquo;oggetto (massimizzare per cosa sbagliata dico), e non una linea guida Per√≤\ndipende dal linguaggio quasi nessuna correlazione con la qualit√† del software (quindi produce bloatware per dire), non viene prodotto software conciso o efficiente. Non tiene conto della complessit√†, certe istruzioni possono fare un sacco di cose, a seconda del livello di astrazione. Non possiamo distinguere bene le linee logiche con quelle fisiche, non abbiamo un metodo per contarle per dire. Function point Idea principale del metodo L‚Äôanalisi Function Point enumera le funzionalit√† di un sistema dal punto di vista utente\nElaborata da un certo Dr. Allan Albrecht in 1979, sono il numero di features fatte, che l\u0026rsquo;utente pu√≤ utilizzare (e questa stima mi piace molto di pi√π rispetto a quello di linee di codice). Cerchiamo di analizzare il software tramite le funzionalit√† nuove che possono venire offerte.\nL\u0026rsquo;idea √® partire da quello che √® necessario all cliente, quelli che chiamiamo functional requirements trattati a Requisiti e backlog del software. Insieme a questi sono collegati i non functional requirements che sono features necessarie a sviluppatori, e non utenti.\nUFC e TFC Ufc √® Unadjusted Function Count che √® la somma semplice di tutte le funzionalit√† su tutti i lati in cui potrebebro essere necessit√† di function points.\nCocomo e modelli di costo Non fatti.\n","permalink":"https://flecart.github.io/notes/project-management/","summary":"\u003ch4 id=\"project-product-management-project-management\"\u003eProject, product management, project management\u003c/h4\u003e\n\u003cp\u003eBisogna capire queste definizioni.\nVedere \u003ca href=\"https://dynamik.vercel.app/ingegneria-del-software/lucidi/13-gestione-del-progetto.pdf?from=informatica,\"\u003ehttps://dynamik.vercel.app/ingegneria-del-software/lucidi/13-gestione-del-progetto.pdf?from=informatica,\u003c/a\u003e slide 5 per definizione\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eProgetto: inizia e finisce in tempo preciso.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e√à importante comunque ricordare gli steps principali per il progetto ossia ideazione, creazione, mantenimento, rilascio, e poi morte, questo in genere √® per qualunque progetto.\u003c/p\u003e\n\u003ch3 id=\"project-manager\"\u003eProject Manager\u003c/h3\u003e\n\u003ch4 id=\"compiti-principali-costi-e-risorse\"\u003eCompiti principali (costi e risorse)\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003eVedere se il progetto √® fattibile\u003c/li\u003e\n\u003cli\u003eAllocare risorse\u003c/li\u003e\n\u003cli\u003eMonitorare come sta andando. (preventivo e consuntivo).\n\u003cimg src=\"/images/notes/Project Management-1701099646139.jpeg\" alt=\"Project Management-1701099646139\"\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"work-breakdown-structure\"\u003eWork Breakdown structure\u003c/h3\u003e\n\u003ch4 id=\"descrizione-wbs\"\u003eDescrizione WBS\u003c/h4\u003e\n\u003cp\u003e√à una suddivisione del progetto in piccoli sottoparti che si possono gestire in modo autonomo.\u003c/p\u003e","title":"Project Management"},{"content":"PAC Learning is one of the most famous theories in learning theory. Learning theory concerns in answering questions like:\nWhat is learnable? Somewhat akin to La macchina di Turing for computability theory. How well can you learn something? PAC is a framework that allows to formally answer these questions. Now there is also a bayesian version of PAC in which there is a lot of research. Some definitions Empirical Risk Minimizer and Errors $$ \\arg \\min_{\\hat{c} \\in \\mathcal{H}} \\hat{R}_{n}(\\hat{c}) $$ Where the inside is the empirical error.\nThe Generalization error is $R(\\hat{c}) = P_{x\\sim D}(\\hat{c}(x) \\neq c(x)) = \\mathbb{E}_{x \\sim D} \\mathbb{1}_{\\hat{c}(x) \\neq c(x)}$ where $\\hat{c}$ is the learned concept (classifier) and $c$ is the true error and $x$ is the instance space.\n$$ \\hat{R}_{n} (\\hat{c}) = \\frac{1}{n} \\sum_{i = 1}^{n} \\mathbb{1}_{\\hat{c}(x) \\neq c(x)} $$ It is true that in expectation the empirical error is the same as the generalization error.\nIt is quite easy to see that $\\mathbb{E}_{s \\sim \\mathcal{D}^{m}}[\\hat{R}_{S}(\\hat{c})] = R(\\hat{c})$ This will be important when we will prove some bounds for the inconsistent learner case, see #The Inconsistent Case.\nConcepts and Hypothesis üü®\u0026ndash; We define a instance space $\\mathcal{X}$ that is the space of the object of interest of our learning task. We define a concept a subset of $\\mathcal{X}$ (this is why sometimes it is useful to use an indicator function to get a specific concept). A concept class is just a set of concepts. A Hypothesis class is the class of concepts that we are using to learn the true concept class.\nLearning Algorithm üü© Given an Hypothesis Class $\\mathcal{H}$ and a concept $c$ a learning algorithm in this context is a computable function that takes in input a labelled dataset $(x_{1}, y_{1}), \\dots, (x_{n}, y_{n})$ and outputs an hypothesis $\\hat{c} \\in \\mathcal{H}$. One result that we will have is that we cannot have infinite precision (learn the concept class infinitely well).\nPAC Learnability üü© In words, we say that something is PAC learnable when given a sufficiently large sample, we can learn a concept with high probability. Formally, we say that a concept class $\\mathcal{C}$ is PAC learnable if there exists a learning algorithm such that:\nfor all $\\epsilon, \\delta \u003e 0$ (respectively error parameter and confidence value) for all distributions $\\mathcal{D}$ over $\\mathcal{X}$, if the learning algorithm is given a sample of size $m \\geq \\text{poly}(1/\\epsilon, 1/\\delta, \\text{size}(x))$ =\u0026gt; with probability at least $1 - \\delta$ the algorithm outputs a hypothesis $\\hat{c}$ such that $P(\\hat{c}(x) \\neq c(x)) \\leq \\epsilon$. So recalling that the above is exactly the definition of risk: $$ \\mathbb{P}_{Z \\sim D^{n}} (R(\\hat{c}) \u003e \\epsilon) \\leq \\delta $$ The PAC framework is a distribution-free model : no particular assumption is made about the distribution D from which examples are drawn.\nGeneral PAC Learnability üü© Above we assumed hypothesis where consistent, meaning we could correctly learn all the mappings. This is often not the case as we will probably observe noise in the observations:\n$$ \\mathbb{P}_{Z \\sim D^{n}} (R(\\hat{c}) - \\inf_{c \\in \\mathcal{C}} \\mathcal{R}(c) \u003e \\epsilon) \\leq \\delta $$Efficiently Learnable üü®+ If the sample size just depends on $\\varepsilon$ and $\\delta$ then it is called efficiently learnable.\nAnd one thing we would need to note is that sometimes the true concept is not in the hypothesis, so it\u0026rsquo;s impossible to attain a risk\nExample: Axis-aligned rectangles üü®\u0026ndash; Suppose we are in $\\mathbb{R}^{2}$ and the concept class is the set of all axis-aligned rectangles. We generate some points with these rectangles. Let our learning algorithm return the minimum rectangle that contains all the points that return true. With this learning algorithm we do not have false positives.\n$$ P_{Z \\sim D^{n}} (R(\\hat{c}) \u003e \\varepsilon) \\leq\\sum_{i = 1}^{4} P_{Z \\sim D^{n}} (Z \\cap r_{i} = \\varnothing) \\leq 4 (1 - \\varepsilon / 4)^{m} \\leq 4 \\exp(-m \\varepsilon / 4) $$ This implies that the number of samples needed is: $$ 4 \\exp(-m \\varepsilon / 4) \\leq \\delta \\Rightarrow m \\geq \\frac{4}{\\varepsilon} \\log\\left( \\frac{4}{\\delta} \\right)\n$$\nOften the sample efficiency bounds are derived in this manner in the framework of this theory.\nThis is a nice example on how to prove PAC related stuff. You should definitely remember the root idea of this example and how to write such proofs. There are nice exercises in the book to see if you are able to solve a PAC proof, refer to (Mohri et al. 2012).\nLearning Bounds Finite Hypothesis Class $$ n \\geq \\frac{1}{\\varepsilon} \\left( \\log(|\\mathcal{H}|) + \\log\\left( \\frac{1}{\\delta} \\right) \\right) $$Proof $$ P(\\exists h \\in \\mathcal{H}_{\\varepsilon} : \\hat{R}(h) = 0) \\leq \\sum_{h \\in \\mathcal{H}_{\\varepsilon} }\\mathbb{P}(\\hat{R}(h) = 0) \\leq |\\mathcal{H}_{\\varepsilon}| (1 - \\varepsilon)^{m} \\leq |\\mathcal{H}| \\exp(-m \\varepsilon) $$$$ |\\mathcal{H}| \\exp(-m \\varepsilon) \\leq \\delta \\Rightarrow m \\geq \\frac{1}{\\varepsilon} \\left( \\log(|\\mathcal{H}|) + \\log\\left( \\frac{1}{\\delta} \\right) \\right) $$ $\\square$\nIn theory, this result strongly suggest that in our finite world, we can PAC-learn everything, we only need to model finite hypothesis worlds (or hypothesis that are small enough). This will is usually the difficult part.\nUniversal Concept Class is not PAC-learnable $$ n \\geq \\frac{1}{\\varepsilon} \\left( 2^{n}log 2 + \\log\\left( \\frac{1}{\\delta} \\right) \\right) $$ Which is not polynomial in $n$.\nThe Inconsistent Case Finite Classifier Sets Bound üü® Now we will tolerate that our learner does not learn the training data perfectly. We leverage Hoeffding\u0026rsquo;s inequality, introduced in Central Limit Theorem and Law of Large Numbers, to prove the following theorem. If we fix an hypothesis $h : \\mathcal{X} \\to \\left\\{ 0, 1 \\right\\}$ we have\n$$ \\mathbb{P}_{S \\sim \\mathcal{D}^{m}} \\left[ \\hat{R}_{S}(h) - R(h) \\geq \\varepsilon \\right] \\leq \\lvert C \\rvert \\exp(-2m \\varepsilon^{2}) $$$$ \\mathbb{P}_{S \\sim \\mathcal{D}^{m}} \\left[ \\hat{R}_{S}(h) -R(h) \\leq - \\varepsilon \\right] \\leq \\lvert C \\rvert\\exp(-2m \\varepsilon^{2}) $$$$ \\mathbb{P}_{S \\sim \\mathcal{D}^{m}} \\left[ \\left| R(h) - \\hat{R}_{S}(h) \\right| \\geq \\varepsilon \\right] \\leq 2\\lvert C \\rvert \\exp(-2m \\varepsilon^{2}) $$ But note that this works for a fixed $h$. If we use learned hypothesis $\\hat{c}$ it is not guaranteed that the above holds as $\\hat{c}$ is a random variable dependent on the samples drawn (i.e. it could actually be bigger)! In my opinion, this has quite strong limits on the theory part. What is an unapplicable theory for? It seems to be more useful for philosophical insights on learnability.\nProof: We will prove the first inequality for the general case of finite $h$, the idea is similar for the single hypothesis case. $$ \\begin{align} P_{S\\sim \\mathcal{D}^{m}} \\left[ \\hat{R}{S}(h) - R(h) \\geq \\varepsilon \\right] \u0026amp;\\leq P{S\\sim \\mathcal{D}^{m}} \\left[ \\sup_{c \\in C}\\hat{R}{S}(c) - R(c) \\geq \\varepsilon \\right] \\ \u0026amp;= P{S\\sim \\mathcal{D}^{m}} \\left[ \\bigcup_{c \\in C}\\hat{R}{S}(c) - R(c) \\geq \\varepsilon \\right] \\ \u0026amp;\\leq \\sum{c \\in C} P_{S\\sim \\mathcal{D}^{m}} \\left[ \\hat{R}_{S}(c) - R(c) \\geq \\varepsilon \\right] \\ \\text{Hoeffding\u0026rsquo;s Inequality}\u0026amp;\\leq \\lvert C \\rvert \\exp(-2m \\varepsilon^{2})\n\\end{align} $$ We note that $P( \\max_{i} X_{i} \u003e \\varepsilon) = P(X_{1} \u003e \\varepsilon \\lor \\dots X_{n} \u003e \\varepsilon)$, this is the same argument put forward for the sup. By doing the same thing for the other side, we get the result.\nA looser Inequality üü®\u0026ndash; Usually VC Inequality is used to address another looser inequality that is close, but not exactly that: If we consider $\\hat{c}_{n} \\in \\arg\\min_{c \\in \\mathcal{C}} \\hat{R}_{n}(c)$ and $c^{*} \\in \\arg\\min_{c \\in \\mathcal{C}} R(c)$, then we have that:\n$$ \\begin{align} R(\\hat{c}_{n}) - R(c^{*}) \u0026= R(\\hat{c}_{n}) - \\hat{R}_{n}(\\hat{c}_{n}) + \\hat{R}_{n}(\\hat{c}_{n}) - R(c^{*}) \\\\ \u0026 \\leq \\lvert \\hat{R}_{n}(\\hat{c}_{n}) - R(\\hat{c}_{n}) \\rvert + \\hat{R}_{n}(c^{*}) - R(c^{*}) \\\\ \u0026 \\leq \\underbrace{\\sup_{c \\in \\mathcal{C}} \\lvert \\hat{R}_{n}(c) - R(c) \\rvert}_{ \\substack{\\text{``Optimization\"} \\newline \\text{Uniform Convergence}}} + \\underbrace{\\hat{R}_{n}(c^{*}) - R(c^{*})}_{\\substack{\\text{``Prediction\"} \\\\ \\text{Pointwise Convergence}}} \\\\ \u0026 \\leq 2 \\sup_{c \\in \\mathcal{C}} \\lvert \\hat{R}_{n}(c) - R(c) \\rvert \\end{align} $$There is a tradeoff between the optimization and the prediction part. I can get pointwise convergence with more samples, but this does not generalize to the real unseen risk, the uniform convergence.\nGeneralization Inequality: single hypothesis üü© $$ R(h) \\leq \\hat{R}_{S}(h) + \\sqrt{\\frac{1}{2m} \\log \\left( \\frac{2}{\\delta} \\right)} $$$$ 2 \\exp(-2 m \\varepsilon^{2}) \u003c \\delta \\implies \\varepsilon \u003e \\sqrt{\\frac{1}{2m} \\log \\left( \\frac{2}{\\delta} \\right)} $$Plugging this into the previous stuff we get the result.\nGeneralization inequality: Finite H üü®\u0026ndash; $$ \\underbrace{R(h)}{\\text{Expected Error}} \\leq \\underbrace{\\hat{R}{S}(h)}{\\text{Emprirical Error}} + \\underbrace{\\sqrt{\\frac{1}{2m} \\log \\left( \\frac{2 \\lvert \\mathcal{H} \\rvert}{\\delta} \\right)}}{\\text{Variance}}\n$$ In practice, the bounds were quite loose. If $\\hat{R}$ is smaller, that is some suggestion of overfitting.\n$$ P(\\exists h \\in \\mathcal{H} : \\lvert \\hat{R}_{S}(h) - R(h) \\rvert \u003e \\varepsilon) \\leq 2\\lvert \\mathcal{H} \\rvert \\exp(-2m \\varepsilon^{2})) $$Then we see that we can bound the probability that the generalization error is bigger than $\\varepsilon$ by $\\delta$: $$ \\varepsilon\n\\sqrt{\\frac{1}{2m} \\log \\left( \\frac{2 \\lvert \\mathcal{H} \\rvert}{\\delta} \\right)} = \\sqrt{\\frac{\\log \\lvert \\mathcal{H} \\rvert - \\log (\\delta / 2)}{2m} } $$\nVapnik-Chervonenkis\u0026rsquo; Bound $$ P(R(\\hat{c}) \u003e \\varepsilon) \\leq \\lvert \\mathcal{H} \\rvert \\exp(-n \\varepsilon))) $$$$ \\mathbb{E}[R(\\hat{c})] \\leq \\frac{1 + \\log \\lvert \\mathcal{H} \\rvert}{n} $$$$ \\begin{align} P(R(\\hat{c}) \u003e \\varepsilon) \u0026\\leq P(\\max_{c \\in \\mathcal{H}, \\hat{R}_{n}(c) = 0} R(c) \u003e \\varepsilon) \\\\ \u0026= \\mathbb{E}[\\max_{c \\in \\mathcal{H}, \\hat{R}_{n}(c) = 0} \\mathbb{1}_{R(c) \u003e \\varepsilon} )] \\\\ \u0026\\leq \\sum_{c \\in \\mathcal{H}, R(c) \u003e \\varepsilon} \\underbrace{P(\\hat{R}_{n}(c) = 0)}_{(1-\\varepsilon)^{n}} \\\\ \\\\ \u0026\\leq \\lvert \\mathcal{H} \\rvert \\exp(-n \\varepsilon) \\end{align} $$ Which ends the proof of the first part. Note that this is just a different bound for the same thing we have proved in #Finite Hypothesis Class. This is very similar to the VC inequality.\nUncountable Hypothesis $$ P(\\mathcal{R}(\\hat{c}_{n}^{*}) - \\inf_{c \\in \\mathcal{C}} \\mathcal{R}(c) \u003e \\varepsilon) \\leq 9 n ^{VC_{\\mathcal{C}}} \\exp (- n\\varepsilon^{2} / 32) $$Fingering Argument Suppose you have $n$ points. Suppose you want to take a subset $d$ of these points, and associate to each subset two possible different hypothesis, the d-dimensional hyperplanes that passes through the points (two possible labelling, this is why we set 2). This set of hypothesis has size $2 \\binom{n}{d}$. Let\u0026rsquo;s consider the one that has the best empirical error among these. Call this hypothesis $\\hat{\\phi}$ and the value that it can achieve to be $L$, and $\\phi^{*}$ the best possible among all linear classifiers. What we want to show is that $\\hat{\\phi}$ is a good classifier.\nGood classifier The interesting thing of this setting is that we can use finitely many hypothesis to approximate an infinite hypothesis set.\nOne can show that in the infinite set of all possible classifiers, there is no classifier $\\phi$ whose empirical error is smaller than $\\hat{L}(\\hat{\\phi}) - \\frac{d}{ n}$. This is easy to see: by choosing $d$ points, it can disagree at a maximum of $d$ points, leading to that empirical error.\nStandard result One can prove that given the setting above it is true that\n$$ P(\\mathcal{R}(\\hat{c}) - \\inf _{c \\in \\mathcal{C}}\\mathcal{R}(c) \u003e \\varepsilon) \\leq \\exp\\left( 2d\\varepsilon - n \\frac{\\varepsilon^{2}}{2} \\right) (2 \\binom{n}{d} + 1) $$ Then learnability is obvious: binomials grow polynomial, while $n$ decreases exponentially, so it is bounded.\nAnd that for $n \u003e d$ we have:\n$$ \\mathop{\\mathbb{E}}[\\mathcal{R}(\\hat{c}) - \\mathcal{R}] \\leq \\sqrt{ \\frac{2}{n} (d + 1) (\\log(n) + 2)} $$Classifiers with vanishing errors If we have the above assumptions plus that the best classifier has risk $\\mathcal{R}(c^{*})=0$ then one can prove that the best classifier with the same hyperplane logic as above has this for $n \u003e d$ and $\\varepsilon \\leq 1$:\n$$ P(\\mathcal{R}(\\hat{c}_{n})\u003e \\varepsilon) \\leq 2 \\binom{n}{d} \\exp ( -\\varepsilon (n - d)) $$Note that if $\\mathcal{R}(c^{*}) = 0$ means that in our set exists a classifier with $\\hat{R}(c) \\leq \\frac{d}{n}$ (this is the fingering assumption).\nVC Dimension When a theory is too powerful, that theory is not falsifiable in a Popperian sense. Meaning every type of data can be explained by that theory, suggesting that the theory does not explain anything. This is why for Buhmann says about Vapnik\u0026rsquo;s work in 1982 was so interesting. In his opinion, it was able to bridge philosophy of science and mathematics.\nWhat is VC Dimension The Growth Function üü• The growth function of a hypothesis class $\\mathcal{H}$ is the maximum number of dichotomies that can be induced by $\\mathcal{H}$ on a set of $n$ points.\n$$ m_{\\mathcal{H}}(n) = \\max_{x_{1}, \\ldots, x_{n} \\in \\mathcal{X}} \\lvert \\left\\{ (h(x_{1}), \\ldots, h(x_{n})) : h \\in \\mathcal{H} \\right\\} \\rvert $$ Intuitively, the growth function is the maximum number of ways that the hypothesis class can split the data, this is later used to define the VC dimension. For example, an hypothesis class with a single hypothesis that just returns a constant, has growth function constant equal to $1$.\nShattering üü• We say that a set of point $S$ of $m \\geq 1$ is shattered by some hypothesis class $\\mathcal{H}$ if the growth function is $2^{m}$. That is, the hypothesis class can split the data in all possible ways.\nIntuitively, we say that an hypothesis class shatters a set of point $m$ if whatever assignment of $y$ we have to those point, there exists a $h \\in \\mathcal{H}$ that learns it.\nDefinition of VC Dimension üü© The VC dimension is kinda the opposite of the Shattering number: if in the shattering we keep the set constant and try to see what hypothesis class shatters it, here we set the hypothesis class fixed, and ask The VC dimension of a hypothesis class $\\mathcal{H}$ is the cardinality of the largest set shattered by $\\mathcal{H}$. This can be seen as some sort of opposite of the growth function. While the growth function focused on the number of data points, keeping $\\mathcal{H}$ fixed, the VC dimension focuses on the number of points that $\\mathcal{H}$ can shatter.\n$$ \\text{VC}(\\mathcal{H}) = \\max \\left\\{ m : m_{\\mathcal{H}}(m) = 2^{m} \\right\\} $$Sauer\u0026rsquo;s Lemma $$ \\Pi_{\\mathcal{H}}(m) \\leq \\sum_{i = 1}^{d} \\binom{m}{i} $$Infinite VC dimension are not Learnable TODO\nExamples with VC-dimensions For this section, check chapter 3 of (Mohri et al. 2012).\nHyperplanes in $\\mathbb{R}^{d}$ It can be proven that the VC dimension of the set of all hyperplanes in $\\mathbb{R}^{d}$ is $d+1$. One simple example is the XOR function in $\\mathbb{R}^{2}$, that is not linearly separable. The proof is not so simple and requires the use of Radon\u0026rsquo;s theorem.\nSine Waves It can be shown that the family of functions $h(x) = \\sin(wx)$ has infinite VC dimension. TODO. I have no idea how VC could be proved formally\nReferences [1] Mohri et al. ‚ÄúFoundations of Machine Learning‚Äù The MIT Press 2012\n","permalink":"https://flecart.github.io/notes/provably-approximately-correct-learning/","summary":"\u003cp\u003ePAC Learning is one of the most famous theories in learning theory. Learning theory concerns in answering questions like:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhat is learnable? Somewhat akin to \u003ca href=\"/notes/la-macchina-di-turing/\"\u003eLa macchina di Turing\u003c/a\u003e for computability theory.\u003c/li\u003e\n\u003cli\u003eHow well can you learn something?\nPAC is a framework that allows to formally answer these questions.\nNow there is also a bayesian version of PAC in which there is a lot of research.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"some-definitions\"\u003eSome definitions\u003c/h3\u003e\n\u003ch4 id=\"empirical-risk-minimizer-and-errors\"\u003eEmpirical Risk Minimizer and Errors\u003c/h4\u003e\n$$\n\\arg \\min_{\\hat{c} \\in \\mathcal{H}} \\hat{R}_{n}(\\hat{c})\n$$\u003cp\u003e\nWhere the inside is the empirical error.\u003c/p\u003e","title":"Provably Approximately Correct Learning"},{"content":"(Schulman et al. 2017) √® uno degli articoli principali che praticamente hanno dato via al campo. Anche questo √® buono per Policy gradients:\nhttps://lilianweng.github.io/posts/2018-04-08-policy-gradient/\nIntroduzione a PPO References [1] Schulman et al. ‚ÄúProximal Policy Optimization Algorithms‚Äù 2017\n","permalink":"https://flecart.github.io/notes/proximal-policy-optimization/","summary":"\u003cp\u003e\u003ca href=\"http://arxiv.org/abs/1707.06347\"\u003e(Schulman et al. 2017)\u003c/a\u003e √® uno degli articoli principali che praticamente hanno dato via al campo.\nAnche questo √® buono per Policy gradients:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lilianweng.github.io/posts/2018-04-08-policy-gradient/\"\u003ehttps://lilianweng.github.io/posts/2018-04-08-policy-gradient/\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"introduzione-a-ppo\"\u003eIntroduzione a PPO\u003c/h3\u003e\n\u003ch1 id=\"references\"\u003eReferences\u003c/h1\u003e\n\u003cp\u003e[1] Schulman et al. \u003ca href=\"http://arxiv.org/abs/1707.06347\"\u003e‚ÄúProximal Policy Optimization Algorithms‚Äù\u003c/a\u003e  2017\u003c/p\u003e","title":"Proximal Policy Optimization"},{"content":"This documents attempts to briefly present the algorithm and some experiments found online about it. The following repo seems to be a good resource: here.\nUsually, PPO is explained as an actor critic framework. This means there is an agent that acts on the environment, and then there is a critic that collects the feedback from the environment. The main idea about this framework is to select a policy that is similar, so that it is less probable that a bad policy, a very different policy from the original is selected. This is achieved by clipping over the advantage. And then\n","permalink":"https://flecart.github.io/notes/proximal-polixy-optimization/","summary":"\u003cp\u003eThis documents attempts to briefly present the algorithm and some experiments found online about it.\nThe following repo seems to be a good resource: \u003ca href=\"https://github.com/ericyangyu/PPO-for-Beginners\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eUsually, PPO is explained as an \u003cstrong\u003eactor critic framework\u003c/strong\u003e. This means there is an \u003cem\u003eagent\u003c/em\u003e that acts on the environment, and then there is a \u003cem\u003ecritic\u003c/em\u003e that collects the feedback from the environment.\nThe main idea about this framework is to \u003cem\u003eselect\u003c/em\u003e a policy that is similar, so that it is \u003cem\u003eless probable\u003c/em\u003e that a bad policy, a very different policy from the original is selected. This is achieved by clipping over the advantage. And then\u003c/p\u003e","title":"Proximal Polixy Optimization"},{"content":"TODO: write the introduction to the note.\nJSONiq purports as an easy query language that could run everywhere. It attempts to solve common problems in SQL i.e. the lack of support for nested data structures and also the lack of support for JSON data types. A nice thing about JSONiq is that it is functional, which makes its queries quite powerful and flexible. It is also declarative and set-based. These are some commonalities with SQL.\nJSONiq on RumbleDB supports many many data types and many storage systems (classical S3, HDFS, local file systems) and lake houses (which works both as a data warehouse (editable) and a data lake).\nSintax of JSONiq Atomic operations Simple Arithmetic operations üü© JSONiq allows to have some simple arithmetic operations like 1 + 1 or 3 * 4 or 5 - 2 or 10 div 2 or 10 mod 3.\nObjects üü© We can create objects using the following syntax:\n{ \u0026#34;attr\u0026#34; : 1, \u0026#34;attr2\u0026#34; : 2 } Which is just the classical syntax for JSON objects.\nArrays üü© It\u0026rsquo;s easy to create arrays using this simple syntax:\n{ \u0026#34;attr\u0026#34; : [1, 2, 3, 4] } We can also extract a certain item inside the array:\njson-file(\u0026#34;data.json\u0026#34;)[1](/notes/1) Get\u0026rsquo;s the first item of the array (but here it starts to count from 1).\nWe can extract the content of the whole array using the [] syntax\njson-file(\u0026#34;data.json\u0026#34;)[] Composability JSON-iq allows a quite dynamic composition of the above atomic operations we presented.\nDynamic JSON construction We can dynamically compute the value in an array, something similar to:\n{ \u0026#34;attr\u0026#34; : string-length(\u0026#34;foobar\u0026#34;) \u0026#34;values\u0026#34; : [ for $i in 1 to 10 return long($i) ] } Precedence of operations From most important to least:\nComma Data Flow (FLWOR, if-then-else, switch\u0026hellip;) Logic Comparison String concatenation Range Arithmetic Path expressions Filter predicates, dynamic function calls Literals, constructors and variables Function calls, named function references, inline functions\nSwitch and if conditions We can use the switch and if conditions to make the query more dynamic:\n{ \u0026#34;attr\u0026#34; : switch(1) case 1 return \u0026#34;one\u0026#34; case 2 return \u0026#34;two\u0026#34; case 3 return \u0026#34;three\u0026#34; default return \u0026#34;other\u0026#34; } { \u0026#34;attr\u0026#34; : if (1 = 1) then \u0026#34;true\u0026#34; else \u0026#34;false\u0026#34; } Try catch We can use the try-catch block to handle exceptions:\n{ \u0026#34;attr\u0026#34; : try { 1 div 0 } catch * { \u0026#34;Division by zero\u0026#34; } } Let expression These are also called FLWOR (pronounced flower) expressions: for, let, where, order, group.\nAs in every other functional language, we can use the let expression to define a variable:\n{ \u0026#34;attr\u0026#34; : let $x := 1 return $x + 1 } But this variable is just the substitution of an expression, it is immutable.\nOther expressions JSONiq also supports other classical database query operations like, filtering (WHERE), ordering and grouping.\nExample of JSONiq expressions from page 395 of ({fourny} 2024). Trasversal In origin techniques like XPATH were developed for XML trasversal. JSON has introduced a much simpler syntax, the one that is used also for JSONiq, which uses a dot syntax. It is possible to navigate into objets with dots, similar to object-oriented programming.\n{ \u0026#34;attr\u0026#34; : json-file(\u0026#34;data.json\u0026#34;).attr } On a similar note, there is also an operator called array un-boxing that returns a sequence of items from an array:\n{ \u0026#34;attr\u0026#34; : json-file(\u0026#34;data.json\u0026#34;).attr[] } Simple Filtering We can filter the data using the where keyword:\n{ \u0026#34;attr\u0026#34; : json-file(\u0026#34;data.json\u0026#34;).attr[$$ \u0026gt; 10] } Where the $ syntax represents the current member being tested.\nTypes Variable types In JSONiq we have a syntax to define the arity of a certain variable:\n* for any number + for one or more ? for zero or one If there is no suffix, it means exactly one. Type Casting We can cast types using the cast as syntax:\n(3.14, \u0026#34;foo\u0026#34;) instance of integer*, false ([1], [ 2, 3 ]) instance of array+ true We can cast explicitly and throws error if it is not possible:\n\u0026#34;3.14\u0026#34; cast as integer Or we can check if it\u0026rsquo;s possible to cast it\n\u0026#34;3.14\u0026#34; castable as integer Which returns a boolean.\nWe also have treat which just checks if the type is correct else throws error, without changing the underlying type:\n\u0026#34;3.14\u0026#34; treat as integer One quite advanced feature is typeswitch\ntypeswitch (1) case integer return \u0026#34;integer\u0026#34; case string return \u0026#34;string\u0026#34; default return \u0026#34;other\u0026#34; Types in functions Functions can be typed or not typed, in the same way as python can have type annotations or not:\ndeclare function foo($x as integer) as integer { $x + 1 } But also the following will work:\ndeclare function foo($x) { $x + 1 } Type Validation We can also define schemas and validate the type of a certain variable using the validate keyword:\ndeclare type histogram as object { \u0026#34;name\u0026#34; : string, \u0026#34;values\u0026#34; : array } validate { \u0026#34;name\u0026#34; : \u0026#34;histogram\u0026#34;, \u0026#34;values\u0026#34; : [1, 2, 3] } as histogram Architecture of the Engine RumbleDB is an implementation of the JSONiq language.\nThe creation of syntax tree We use technology that has been first developed for compilers:\nWe create the abstract syntax tree This gets converted to an expression tree (using the Visitor Pattern, studied in Design patterns). This tree gets optimized (inferring types for example is a useful optimization thing, e.g. if I know that it\u0026rsquo;s a boolean that gets returned, I can optimize a lot for the space). The Expression tree is converted to an Iterator Tree, which has every information to run the code. This is what is called query plan. Execution methods Materialization üü© When a sequence of items is materialized, it means that an actual List (or Array, or Vector), native to the language of implementation (in this case Java) is stored in local memory, filled with the items.\nThis is possible only if the elements are small enough to fit into memory (RAM). Another drawback is that it is usually sequential (not parallelized).\nStreaming üü© This is usually used when the data is too big to fit into memory -\u0026gt; We produce and consume elements in chunks or one by one. The main advantage we have with streaming is efficient memory usage, we don\u0026rsquo;t need to allocate too much memory. A common pattern is the Volcano Iterator:\nWe open the file. Call hasNext to check if there are things to consume, if yes it it retrieved and consumed. Continue to consume until nothing is left. We still have the sequentiality. But another reason is that it is not compatible to some operations, like grouping. One advantage is that it usually doesn\u0026rsquo;t crash, unlike parallel execution which is more probable (more difficult to orchestrate a cluster with so many elements).\nGroup by, Orderby clauses need to be materialized and not streamed, as we cannot know if the group is complete or not, we can just process one and forget all the ones before.\nParallel execution üü© We use the ideas in Massive Parallel Processing, use RDDs to parallelize the execution all over the cluster. In some cases it is not convenient to parallelize: it has a fixed cost to instantiate the execution! And usually takes more machines :). So it pushes down to Spark to do some parallel processing with java or sparksql code, which is hidden from the user. (this is called user defined function as this is what gets executed). If the data is homogeneus, it can use dataframes implicitly, as they are more efficient to process and store.\nWe can improve over these kinds of solutions. References [1] {fourny} ‚ÄúThe Big Data Textbook‚Äù 2024\n","permalink":"https://flecart.github.io/notes/querying-denormalized-data/","summary":"\u003cp\u003eTODO: write the introduction to the note.\u003c/p\u003e\n\u003cp\u003eJSONiq purports as an easy query language that could run everywhere. It attempts to solve common problems in SQL i.e. the lack of support for nested data structures and also the lack of support for JSON data types.\nA nice thing about JSONiq is that it is functional, which makes its queries quite powerful and flexible. It is also declarative and \u003cstrong\u003eset-based\u003c/strong\u003e. These are some commonalities with SQL.\u003c/p\u003e","title":"Querying Denormalized Data"},{"content":"2.1 Necessit√† e caratteristiche di R 2.1.1 Radici di N non perfetti e Q $\\sqrt{n} \\in \\mathbb{Q} \\implies n \\text{ √® quadrato perfetto}$\nFai lemma della divisibilit√† fra due numeri\nLemma: Dati $m,n,l$ tali che $MCD(m,l)=1$ e $l | m n$ allora allora $l | n$ Questo si risolve con ragionamenti sui fattori di m e n. Per dimostrare che √® razionale la radice di solamente una radice perfetta parto da un numero razionale, faccio certi ragionamenti e scoprir√≤ alla fine che il numero deve essere una radice perfetta.\nQuesto teorema si pu√≤ ancora estendere con questo:\nEsercizio (dimostrare) 2.1.2 Necessit√† di R Per dimostrazione del punto precedente, ci sono un sacco di lacune in quanto la maggior parte delle radici non appartiene a Q. C\u0026rsquo;√® bisogno di un insieme che operi bene al limite, cosa che con Q non va bene.\nIntuizione di R\nAggiungere a Q tutti i punti di cui mancano. Si dice che R √® Continuo\nEsempio inefficacia di Q\nIn questo esempio l\u0026rsquo;esistenza di un $sup$ c\u0026rsquo;√® solo in R perch√© in Q la radice di due non √® presente e quindi non c\u0026rsquo;√®\u0026hellip;\nCaratteristican unica\nSupremum property esiste sempre il limite superiore o inferiore di un insieme ,questo non succede anche per Q.\n2.1.3 Completezza di R $$ \\forall A:A\\neq\\empty \\implies A\\in \\R $$Si ottiene completando Q con i pezzi mancanti, per farlo si deve introdurre il concetto di Continuit√† ‚Üí Intervalli\nQuesta propriet√† di R √® molti importante perch√© permette di avere sup e inf definiti in seguito qui\nInnumerabilit√† di R Cardinalit√†\nSi pu√≤ affermare che la cardinalit√† di R sia molto maggiore di N, infatti si pu√≤ dimostrare che √® innumerabile grazie\nCantor, si fa la costruzione a tabella e si dimostra che non √® suriettiva, ovvero che nell\u0026rsquo;intervallo $[0,1[$ esiste un numero che non √® mai raggiunto da un numero naturale, infatti riesco a costruire un numero che sia diverso in una cifra da tutti i numeri decimali in tabella. Questa √® la dimostrazione pi√π semplice di Cantor.\nUn altro argomento insiemistico lo puoi trovare qui Relazioni fra insiemi#Diagonalizzazione di Cantor.\n2.1.5 Esistenza unicit√† della radice File per pdf di lezione per questa\n$$ \\forall a \\in \\R_+, \\forall n \\in \\N - \\{0\\} ,\\exists !b \\in \\R_+ : b^n = a $$Si indica con $^n\\sqrt{a} = b$\nUna serie di lemmi utili per la dimostrazione:\nLemmi $x^n \\geq y^n \\implies x \\geq y$ $x^n \\leq y^n \\implies x \\leq y$ $x ^n = y^n \\implies x = y$ $x^n \u003c y \\implies \\exists \\epsilon ,(x + \\epsilon) ^n \u003c y$ $x ^n \u003e y \\implies \\exists\\epsilon (x - \\epsilon)^n \u003e y$ NOTA: per dimostrare i lemmi potrebbe essere molto pi√π semplice provare a dimostrare prima per $n = 2$ e poi estendere da questo e poi passando per n generalizzatot\nSapendo di tutti questi lemmi si pu√≤ dimostrare esistenza ed unicit√† della radice n-esima.\nPer l\u0026rsquo;unicit√† basta utilizzare il lemma numero 3 (che si dimostra utilizzando i lemmi 1 e 2)\nPer dimostrare l\u0026rsquo;esistenza della radice bisogna dimostrare l\u0026rsquo;assurdo che la radice sia minore di quello e maggiore di quello (quello nel senso di 4 e 5)\nPer farlo si parte dalla continuit√† di R creando prima un insieme in cui il sup √® x, e da l√¨ dimostrare che √® assurdo che la radice sia diversa da quello\nDimostrazione:\nSia $A := \\{x \\in \\mathbb{R} \\mid x^2 \\leq b\\}$ devo dimostrare che esiste ed √® unico la radice a: $a ^2= b$\nAllora pongo per assurdo che non esiste tale radice, quindi devo dimostrare l\u0026rsquo;assurdo per $a ^2 \u003c b \\wedge a ^2 \u003e b$.\nPoniamo $a$ come il sup dell\u0026rsquo;insieme A, cosa che esiste dato che √® superiormente limitato. (poi usiamo i lemmi 4 e 5)\nCaso 1:\n$a^2 \u003c b \\implies (a + \\epsilon) ^2 \u003c b \\implies a + \\epsilon \\in A \\implies a + \\epsilon \u003c a \\implies absurd$\nCaso 2:\n$a^2 \u003e b \\implies (a - \\epsilon)^2 \u003e b \\implies a - \\epsilon \\not\\in A \\implies a - \\epsilon \\geq a \\implies absurd$\nQuindi esiste la radice.\nPer dimostrare che sia unico mi basta usare il lemma 3\n2.2 Intervalli, Maggioranti ed estremi 2.2.1 Intervalli Intervalli\n2.2.2 Maggioranti o minoranti Un maggiorante (o minorante) √® un elemento che √® maggiore (o minore di tutti gli elementi) di un certo insieme.\n2.2.3 Limitatezza Un insieme √® maggiormente o inferiormente limitato se esiste un maggiorante o un minorante di un insieme.\nSe un insieme √® sia maggiormente sia inferiormente limitato si dice che √® limitato\n2.2.4 Estremi (superiori ed inferiori) Un estremo √® definito in questo modo, che funziona anche per i razionali.\n$$ l = sup X \\iff \\begin{cases} \\forall x \\in X , l \\geq x \\\\ \\forall\\epsilon : \\epsilon \u003e 0,\\exists x \\in X, l-\\epsilon \\leq x \\\\ \\end{cases} $$ l √® un maggiorante l √® anche il pi√π piccolo dei minoranti. In modo simile si pu√≤ definire la parte inferiore.\nDetto in altre parole il sup √® il minimo dell\u0026rsquo;intero insieme dei maggioranti, se esiste questo insieme\n2.2.5 Massimi e minimi di insiemi Dato un $x \\in X, x:= _{min} \\forall y: y\\in X \\implies x \\leq y$\nE in modo simile i massimi.\nSi pu√≤ mettere in relazione massimi e minimi fra di loro, quindi posso dire che:\nSe esiste il minimo, questo √® il MASSIMO fra tutti i minoranti.\nPunto di massimo e minimo Questa parte sar√† utile per weierstrass.\nPMassimo:\n$f:X \\to\\R$ si dice punto di massimo $x$ se:\n$\\forall x_0 \\in X, f(x) \\geq f(x_0)$\nPMinimo\n$f:X \\to\\R$ si dice punto di massimo $x$ se:\n$\\forall x_0 \\in X, f(x) \\leq f(x_0)$\nüí° Stai molto attento a non confondere il punto di massimo assoluto con il massimo assoluto! Uno sta sul dominio, l'altro sul codominio 2.3 Valore assoluto Definizione del valore assoluto $\\lvert a \\rvert = max(a, -a)$ e si pu√≤ fare anche una funzione a tratti\n2.3.1 7 Propriet√† del valore assoluto $|a| \\geq 0$ $|a| =|-a|$ $-|a| \\leq a \\leq |a|$ $|a + b| \\leq | a| + | b|$ $||a|-|b|| \\leq |a-b|$ Espansione con disuguaglianze con altre cose senza valore assoluto Caratteristiche di R Campo ordinato Ordine totale e completo (completo = con gli infiniti) **(in cui le relazioni di ordine valgono) vedi pp 76 di Foundations of real analisys.\nPropriet√† archimedea nessun numero in R √® infinitamente grande Nessun elemento in R √® infinitamente piccolo (esiste sempre un elemento in Q pi√π piccolo). L\u0026rsquo;insieme R √® denso e nessun numero in R √® infinitamente grande Nessun elemento in R √® infinitamente piccolo (esiste sempre un elemento in Q pi√π piccolo).\n","permalink":"https://flecart.github.io/notes/r-e-intervalli/","summary":"\u003ch2 id=\"21-necessit√†-e-caratteristiche-di-r\"\u003e2.1 Necessit√† e caratteristiche di R\u003c/h2\u003e\n\u003ch3 id=\"211-radici-di-n-non-perfetti-e-q\"\u003e2.1.1 Radici di N non perfetti e Q\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/R e Intervalli/Untitled.png\" alt=\"image/universita/ex-notion/R e Intervalli/Untitled\"\u003e\n\u003cp\u003e$\\sqrt{n} \\in \\mathbb{Q} \\implies n \\text{ √® quadrato perfetto}$\u003c/p\u003e\n\u003cp\u003eFai lemma della divisibilit√† fra due numeri\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLemma:\u003c/strong\u003e\nDati $m,n,l$ tali che $MCD(m,l)=1$ e $l | m n$ allora  allora $l | n$\nQuesto si risolve con ragionamenti sui fattori di m e n.\nPer dimostrare che √® razionale la radice di solamente una radice perfetta parto da un numero razionale, faccio certi ragionamenti e scoprir√≤ alla fine che il numero deve essere una radice perfetta.\u003c/p\u003e","title":"R e Intervalli"},{"content":"This note used the definitions present in Provably Approximately Correct Learning. So, go there when you encounter a word you don\u0026rsquo;t know. Or search online\nRademacher Complexity $$ \\mathcal{G} = \\left\\{ g : (x, y) \\to L(h(x), y) : h \\in \\mathcal{H} \\right\\} $$ Where $L : \\mathcal{Y} \\times \\mathcal{Y} \\to \\mathbb{R}$ is a generic loss function.\nThe Rademacher complexity captures the richness of a family of functions by measuring the degree to which a hypothesis set can fit random noise. From (Mohri et al. 2012).\nThe thing is that you can do some generalization bounds with this kind of complexity, but for the moment we will just list the definitions and ignore the results.\nDefinitions Empirical Rademacher Complexity $$ \\hat{\\mathcal{R}}_m(\\mathcal{G}) = \\mathbb{E}_\\sigma \\left[ \\sup_{g \\in \\mathcal{G}} \\frac{1}{m} \\sum_{i=1}^m \\sigma_i g(x_i, y_i) \\right] $$$$ \\hat{\\mathcal{R}}_m(\\mathcal{G}) = \\mathbb{E}_\\sigma \\left[ \\sup_{g \\in \\mathcal{G}} \\frac{1}{m} \\sigma^T g(x, y) \\right] $$ The inner product can be intuitively understood as how well the hypothesis set can fit random noise. Intuitively, a more expressive set of functions will have a larger empirical Rademacher complexity, as they can fit the noise in a better fashion\nRademacher Complexity $$ \\mathcal{R}_m(\\mathcal{G}) = \\mathop{\\mathbb{E}}_{S \\sim \\mathcal{D}^{m}} \\left[ \\hat{\\mathcal{R}}_m(\\mathcal{G}) \\right] $$References [1] Mohri et al. ‚ÄúFoundations of Machine Learning‚Äù The MIT Press 2012\n","permalink":"https://flecart.github.io/notes/rademacher-complexity/","summary":"\u003cp\u003eThis note used the definitions present in \u003ca href=\"/notes/provably-approximately-correct-learning/\"\u003eProvably Approximately Correct Learning\u003c/a\u003e. So, go there when you encounter a word you don\u0026rsquo;t know. Or search online\u003c/p\u003e\n\u003ch2 id=\"rademacher-complexity\"\u003eRademacher Complexity\u003c/h2\u003e\n$$\n\\mathcal{G}  = \\left\\{ g : (x, y) \\to L(h(x), y) : h \\in \\mathcal{H} \\right\\} \n$$\u003cp\u003e\nWhere $L : \\mathcal{Y} \\times \\mathcal{Y} \\to \\mathbb{R}$ is a generic loss function.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe Rademacher complexity captures the richness of a family of functions by measuring the degree to which a hypothesis set can fit random noise. From (Mohri et al. 2012).\u003c/p\u003e","title":"Rademacher Complexity"},{"content":"Introduzione alla Randomicit√† Questo √® principalmente basato su (Li \u0026amp; Vit√°nyi 2019) Capito 1.9 Sembra che la nozione di random sia alla fine una cosa molto profonda. Per esempio, un caso lampante che le definizioni non funzionano nel caso di numeri trascendenti √® che catalogano i numeri di $\\pi$ come se fossero casuali, mentre in realt√† possono essere trovati mediante procedimenti precisi. √à una distinzione filosoficamente molto interessante.\nAlla fine sembra ci sia un link molto diretto con la crittografia, si pu√≤ vedere (Stinson 2005).\nMinimum description length come probabilit√† reale Una altra osservazione √® che gli assiomi della probabilit√† sviluppati da Kolmogorov, che puoi trovare inIntroduzione alla probabilita, sono nella teoria molto belli, ma mancano un framework reale su cui possono essere applicati. Un possibile ipotesi √® che il sistema sviluppato da Kolmogorov complexity possa essere alla fine il nostro sistema buono per descrivere le cose randomiche, come programmi che generano la stringa voluta.\nVon Mises all\u0026rsquo;inizio del secolo scorso fu uno dei primi che ha studiato questo problema, lui era un frequentista, quindi credeva nel Central Limit Theorem and Law of Large Numbers. Una nota interessante √® che secondo lui le probabilit√† sono cose osservabili, come fenomeni fisici, come Magnetismo. mentre nel corso fatto di Poisson processes il prof. del MIT ha chiaramente detto come le probabilit√† a differenza di altri fenomeni, non sono osservabili da sole, ma hanno bisogno di altri eventi (misura sulla collezione, non sul singolo evento). Un po\u0026rsquo; questo fa la distinzione fra Entropy e Kolmogorov complexity, in cui una √® su cose che hanno frequenza, l\u0026rsquo;altra definibile anche su singoli oggetti.\nMises‚ÄìWald‚ÄìChurch randomness $$ \\lim_{ n \\to \\infty } \\frac{f_{n}}{n} = p, 0\\leq p\\leq 1 $$ Ossia il numero di $1$ deve essere la nostra probabilit√† di interesse\nE che valga la place selection rule, anche conosciuta come law of excluded gambling strategy, ossia per qualunque sotto sequenza della nostra sequenza, valga l stesso il limite, e questo limite deve essere lo stesso valore di $p$. La formalizzazione di questa regola √® un po\u0026rsquo; strana, si vuole avere una funzione computabile parziale $\\phi: \\left\\{ 0, 1 \\right\\}^{n} \\to \\left\\{ 0, 1 \\right\\}$, allora seleziono l\u0026rsquo;indice $n$ se vale $\\phi(a_{1}a_{2}a_{3},\\dots,a_{n-1}) = 1$. Se ho questa propriet√† prendo $a_{n}$ nella mia sequenza, poi vado a considerare la sottosequenza $a_{n_{1}}, a_{n_{2}}, \\dots$ e questa vogliamo che converga ancora a $p$ questo dovrebbe essere una necessit√† abbastanza forte.\nNo analisi a posteriori Una altra nota negativa √® che questa definizione non si pu√≤ verificare a posteriori, perch√© in nessun caso reale abbiamo un limite vero (realt√† finita, non riusciamo ad andare all\u0026rsquo;infinito).\nRandom stocastico vs random regolare Un controesempio classico a questa definizione √® il numero $0,123456789010203040506070809111213141516171819\\dots$ che dovrebbe soddisfare queste propriet√†, ma chiaramente non √® per niente random. Si chiama Champernowne‚Äôs number. Kolmogorov giustifica questo dicendo questo:\n‚ÄúIn everyday language we call random those phenomena where we cannot Ô¨Ånd a regularity allowing us to predict precisely their results. Generally speaking, there is no ground to believe that random phenomena should possess any deÔ¨Å- nite probability. Therefore, we should distinguish between randomness proper (as absence of any regularity) and stochastic randomness (which is the sub- ject of probability theory). There emerges the problem of Ô¨Ånding reasons for the applicability of the mathematical theory of probability to the real world.‚Äù [Kolmogorov]\nMartin-L√∂f randomness Kolmogorov randomness Randomness tests Vorremmo creare un formalismo che ci permetta di descrivere se una certa stringa √® random o meno. Utilizziamo l\u0026rsquo;idea da statistica dell\u0026rsquo;elemento tipico che definiamo come un elemento appartenente alla maggiorit√†. Per qualche motivo che non ho capito vuole definire in modo random la cosa che appartiene al confine.\n$$ \\forall n \\in \\mathbb{N},\\sum_{x} \\left\\{ P(x | l(x) = n) : x \\in V_{m} \\right\\} \\leq \\varepsilon $$ Si generalizza scegliendo degli insiemi $V_{m}$ su cui valutare, sul libro ci sono esempi 2.4.1, 2.4.2. Se vale la cosa di sopra vuol dire che il test √® superato a quel livello. Non so quanto possa essere utile questa def, ma sicuramente √® qualcosa. In pratic\nReferences [1] Stinson ‚ÄúCryptography: Theory and Practice, Third Edition‚Äù CRC Press 2005\n[2] Li \u0026amp; Vit√°nyi ‚ÄúAn Introduction to Kolmogorov Complexity and Its Applications‚Äù Springer International Publishing 2019\n","permalink":"https://flecart.github.io/notes/randomness/","summary":"\u003ch3 id=\"introduzione-alla-randomicit√†\"\u003eIntroduzione alla Randomicit√†\u003c/h3\u003e\n\u003cp\u003eQuesto √® principalmente basato su \u003ca href=\"http://link.springer.com/10.1007/978-3-030-11298-1\"\u003e(Li \u0026amp; Vit√°nyi 2019)\u003c/a\u003e Capito 1.9\nSembra che la nozione di random sia alla fine una cosa molto profonda. Per esempio, un caso lampante che le definizioni non funzionano nel caso di numeri trascendenti √® che catalogano i numeri di $\\pi$ come se fossero casuali, mentre in realt√† possono essere trovati mediante procedimenti precisi. √à una distinzione filosoficamente molto interessante.\u003c/p\u003e\n\u003cp\u003eAlla fine sembra ci sia un link molto diretto con la crittografia, si pu√≤ vedere \u003ca href=\"https://books.google.it/books/about/Cryptography.html?id=FAPLBQAAQBAJ\"\u003e(Stinson 2005)\u003c/a\u003e.\u003c/p\u003e","title":"Randomness"},{"content":"Questo √® stato un capitolo molto vasto, che andava in certi punti a toccare la filosofia, la fisica. Un aspetto, quello di codifica delle informazioni reali in un ambiente logico (che per quanto i miei pregiudizi siano, ritengo una cosa molto impossibile, molto limitata e altrettanto impossibile). Si tratta dello studio della logica per rappresentazione di conoscenza.\nFatto sta che mi sembra assurdamente teorico tanto da non aver nessun utilizzo (probabilmente mi sbaglio di grosso), e che sia roba da filosofi.\nCredo che questo capitolo sia sopratuttto importante per i pattern di rappresentazione di certe cose.\nOntologia Pu√≤ fare comodo questa pagina di wikipedia,.\nUn ontologia organizza tutto il mondo in una gerarchia di categorie.\nIl libro non fornisce mai una definizione dettagliata di ontologia, definisce solamente il suo scopo, che √® quello di dare una struttura agli oggetti che possiamo trovare tutti i giorni (cani, gatti, frutta, pomodori) e li mette ognuna in qualche categoria precisa.\nCredo (questa √® una mia interpretazione che non esiste, o almeno non ho trovato nel libro), che l‚Äôontologia descriva la struttura tutto quanto pu√≤ esistere nel mondo creato. Quindi se ti dico Banana, tu puoi subito mettere nel cassetto giusto questo oggetto e averne molte propriet√†, ma non sono sicuro che sia ci√≤ che intenda il libro Norvig, per√≤ di sicuro propone alcuni modi per rappresentare oggetti come Eventi, tempo, credenze, oggetti fisici, credo siano questi 4 i fulcri del capitolo, come rappresentare queste cose astratte.\nUpper ontology L‚Äôontologia elevata √® una rappresentazione grafica di una possibile ontologia. (credo che una ontologia sia pi√π o meno quello che descrive il mondo costruito in quel determinato istante).\nCaratteristiche di un ontologia generale\nApplicabilit√†**,** dovrebbe essere applicata a qualunque istanziazione concreta di oggetto. Riutilizzabilit√†, dovrebbe avere in s√© concetti abbastanza generati che possono essere utilizzati in pi√π modi (esempio il concetto di tempo lo puoi usare come misurazione della durata, ma anche del costo dell‚Äôevento). Ma sembra che sistemi simili non siano stati molto famosi (c‚Äô√® un fattore umano che non permette la creazione di ontologie generali).\nCategorie Le categorie sono come degli insiemi grossi che accomunano oggetti con certe propriet√†. Per√≤ noi stiamo utilizzando la Logica del Primo ordine e quindi una categoria √® un particolare predicato, che pu√≤ essere reificato in un oggetto (ossia invece di tenerti il concetto astratto, definisci tutto quello che serve per poterlo rappresentare, proprio come se fosse una conversione).\nLa cosa bella √® che esistono sottocategorie, che prendono in AUTOMATICO tutte le propriet√† delle proprie super-categorie\nDecomposizione delle categorie Possiamo andare a definire delle partizioni (molto simile a quelle in teoria degli insiemi, anzi direi che il concetto √® praticamente lo stesso lol).\nDisgiunzione (se non hanno nessun elemento in comune) Decomposizione esaustiva (se la loro unione √® l‚Äôelemento iniziale) Partizione (se a due a due sono disgiunti e vale anche 2). Se sai teoria degli insiemi credo che per questa parte non c‚Äô√® nulla da dire\nRappresentazione di oggetti fisici Sono molto importanti le funzione bunchOf, partOf che definiscono un insieme di cose (che possono essere ad esempio 3 mele, o una parte di essa, come la gamba √® una parte del corpo)\n(poi su part of puoi fare la decomposizione come per le categorie, il concetto credo sia esattamente lo stesso).\nMisurazione Di solito per la misurazione ti tieni una funzione di unit√† che restituisce il valore di unit√† astratto, questa poi la puoi andare ad eguagliare all‚Äôunit√† specifiche, come il metro, il pollice, la spanna etc.\nquindi as esempio $lunghezza(L) = metro(1) = pollici(39,3701)$ etc. e questa cosa la fai per tutti. √à una misurazione pi√π astratta possibile.\nSecondo il libro questo √® un campo molto sviluppato in fisica quantitativa, anche se Milanese ha cringiato quando l‚Äôho condiviso.\nCategorie naturali Le categorie naturali sono molto difficili da definire con delle regole esatte come stiamo provando con la logica (l‚Äôessere umano √® molto ambiguo a riguardo). Potremmo solo definire qualcosa di tipico e se soddisfa queste propriet√† chiamarlo Banana e simili. Comunque questa parte sembra essere stato analizzato per benino da Wittgenstein 1953.\nOggetti I concetti di maggiore importanza da capire degli oggetti √® che certi oggetti, anche se divisi, mantengono ancora la propria sostanza, un esempio di questo √® un butto, mentre invece esseri umani non lo sono (una mano o gamba non sono un essere umano, mentre un pezzo di burro √® ancora burro).\nQuindi differenza fra stuff and things.\nOltre a ci√≤ l‚Äôesistenza di propriet√† intrinseche ed estrinseche, ossia cose che sopravivivono o meno alla suddivisione\nEventi Le relazioni di maggiore imoprtanza per rappresentare gli eventi sono questi\nSe hai queste propriet√† definite, puoi proprio avere un sistema di calcolo degli eventi per descrivere quanto accade durante qualcosa, mentre in passato col fluente potevi solamente descrivere cosa c‚Äôera prima o dopo\nTempo No comment, questi sono quelle cose di cui hai bisogno per descrivere il tempo (si noti che si utilizza una funzione di misura descritta in precedenza).\nNota dei fluenti con oggetti\n√à difficile che l‚Äôoggett Presidente identifichi una certa persona, perch√© questa persona cambia nel tempo, quindi teniamo questo come se fosse una classe astratta. E una funzione che prende come input il tempo d‚Äôinizio e di fine e una persone e ti dice se √® vero o falso se questa persona era presidente in questo periodo di tempo.\nLogica modale La logica modale permette la rappresentazione metaconoscitiva ossia la conoscenza del conoscere.\nIntroduce il concetto di operatore modale (che in pratica √® come se fosse un punto di vista, un frame of reference), che √® come se restringesse il campo di conoscenza al singolo operatore.\nSemantica\nLa semantica di questa logica cambia totalmente, ora si pu√≤ dire che un modello √® vero, se √® vero in tutti i mondi accessibili, non tutti i mondi possibili. Un mondo √® accessibile quando non sa nulla su di essa.\nesempio se so A, allora questo √® accessibile nel mondo A and not B, ma anche al mondo A and B, e sarebbe vera in entrambi i mondi quindi OK.\nOnniscienza\nIl problema di questa logica √® che l‚Äôagente conosce tutto quello che pu√≤ sapere, automaticamente si ricava tutte le inferenze possibili da suo campo di sapere, questo √® alquanto irrealistico (altrimenti l‚Äôessere umano, lol, potrebbe conoscere tutte le conseguenze della matematica per esempio, perch√© tanto sono tutte inferenze da basi conosciute, ma √® chiaro che sia qualcosa di altamente irrealistico.\nSistemi di ragionamento su categorie Network semantici All‚Äôinizio della loro creazione, i network semantici erano in forte discussione con la logica, ma si √® poi notato a posteriore che non sono altro che la stessa cosa, ma formulati in modo molto differente.\nI network semantici permettono una bella e semplice visualizzazione dei concetti\nEsempio di un network semantico\nQuesti si comportano bene per l‚Äôereditariet√† (che puoi andare a sovrascrivere come se stessi lavorando su un OOP). per√≤ ha problemi con la eridariet√† molteplice, perch√© ci sarebbe ambiguit√† se entrambi i genitori condividono una informazione, ma sono contrarie uno dall‚Äôaltra.\nLogica descrittiva Non √® altro che una logica di primo ordine semplificata nella verbosit√†, soprattuto per i concetti di almeno n elementi e simili.\nInformazioni di default Spesso torna molto comodo nella semantica del database (in cui √® a mondo chiuso, tutto quello che non conosci espressamente √® negato) avere delle informazioni di default in esse, e questo si pu√≤ raggiungere principalemtne in due modi ora presentati molto velocemente\nCircoscrizione mah, non l‚Äôho proprio capita\nLogica di default Ovvero se vengono soddisfatte delle premesse, e la conseguenza non √® assurda, allora conoscer√≤ questa conseguenza.\nEsempietto\nTruth maintenance systems I sistemi come JTMS (Justification-based truth maintenance system) che tengono per tutte le inferenze che hanno una spiegazione ossia le regole usate per inferire questa cosa, quando si aggiorna tale sistema bisogna andare a togliere tutte le regole che hanno questa altra nella spiegazione .\nUn suo amico stretto √® ATMS(assumption-based truth maintenance system) in cui per colmare l‚Äôinesistenza di qualcosa si ha qualche regola di default (credo di stare sbagliando in questo passo) ma comunque non √® molto importante ed √® molto probabile che stia semplificando troppo in questa parte\n","permalink":"https://flecart.github.io/notes/rappresentazione-della-conoscenza/","summary":"\u003cp\u003eQuesto √® stato un capitolo molto vasto, che andava in certi punti a toccare la filosofia, la fisica. Un aspetto, quello di \u003cstrong\u003ecodifica\u003c/strong\u003e delle informazioni reali in un ambiente logico (che per quanto i miei pregiudizi siano, ritengo una cosa molto impossibile, molto limitata e altrettanto impossibile). Si tratta dello \u003cstrong\u003estudio della logica per rappresentazione di conoscenza\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eFatto sta che mi sembra assurdamente teorico tanto da non aver nessun utilizzo (probabilmente mi sbaglio di grosso), e che sia roba da filosofi.\u003c/p\u003e","title":"Rappresentazione della conoscenza"},{"content":"6.1 Codifiche Si utilizzano codifiche, che sono delle convenzioni, qualcosa che un gruppo di umani ha deciso fosse utile darci un significato.\n6.1.1 Codifica posizionale Dove $d_i$ √® il valore in posizione $i$ e $b$ √® la base\n$$ \\sum_{i=0}^k d_ib $$6.1.2 Ottale, esadecimale e binario Queste sono le codifiche principali per i computer in quanto sono comodi da visualizzare. Inoltre Ottale e esadecimale in particolare sono riassunti dei binari, cio√® sono dei sottoinsiemi che possiedono ancora tutte le caratteristiche e quindi sono comodi\n6.1.3 Conversione di base Se la conversione √® fra ottali, esadecimali o binari allora √® molto semplice perch√© basta prendere un gruppo di bit e caricare un numero a seconda di quanto valga, la conversione dovrebbe essere abbastanza semplice.\nAnche la conversione da questi in base 10 non √® difficile, basta utilizzare la formula in codifica posizionale\nTecnica delle conversioni successive BIN‚Üí DEC\nQuesta √® una tecnica leggermente diversa ma fatta per parti piccoline, parti dal numero pi√π significativo e da l√¨ moltiplichi ogni volta per 2 e aggiungi 1 se c\u0026rsquo;√®.\nDEC ‚Üí BIN\nSi continua a dividere per due e si tiene il resto come risultato del numero binario.\nQuesto corrisponde al contrario delle conversioni successive\n6.2 Numeri negativi 6.2.1 Modulo e segno Un primo modo di codificare √® solamente prendere la cifra pi√π significativa come se fosse un uno e contare in modo uguale, ma questa codifica non √® molto utile poi per la somma, bisogna inventare un nuovo metodo.\n6.2.2 Complemento a 1 Il complemento a 1 √® praticamente la negazione del valore di 1. La cosa che non funziona √® che la somma non funziona perfettamente, esiste un zero positivo e un zero negativo, mentre invece per il complemento a 2 funziona grazie al modulo.\nQuesta codifica riesce a fare, dati $k \\text{ bit }, [-2^{k - 1} + 1, 2^{k-1} - 1]$ Per esempio -127 e 127\nSomma\nLa somma del complemento a 1 deve tenere conto del riporto se esiste (probabilmente causato dall\u0026rsquo;esistenza di uno 0 negativo), invece il complemento a due no.\n6.2.3 Complemento a 2 Il complemento a 2 √® fattibile a con questa formula:\ndati $b_{k},b_{k-1}...b_0$ con ogni $b$ i valori in rappresentazione binaria del numero, il numero nella forma decimale corrispondente √®\n$$ x = \\sum_{i=0}^{k-1}b_{i}2^k - b_k 2^k $$In pratica √® il complemento a 1 sommato 1, si pu√≤ vedere mettendo tutti i numeri su un cerchio e notare che il complemento a 2 ha la parte negativa spostata di uno, in particolare si pu√≤ dire che il complemento a 2 utilizza il modulo.\n$k \\text{ bit }, [-2^{k - 1}, 2^{k-1} - 1]$, per esempio -128 fino a 127\n6.2.4 Codifica in eccesso Ad alcuni non piace che lo 0 si trovi proprio a 00000000, quindi lo metto a 10000000, cos√¨ a 0000000 ho il numero pi√π piccolo rappresentabile. In pratica sto sommando due alla k-1 rispetto alla rappresentazione normale di complemento a due.\nScelte, non so perch√© lo facciano per√≤.\n6.3 Floating point 6.3.1 La codifica Bisogna definire una mantissa(frazione) e caratteristica(esponente) e segno sono gli elementi pi√π importanti per la definizione di un floating point:\nIn particolare rappresentiamo N come $f \\times 10 ^{e}$ con f frazione e e esponente.\nLa mantissa √® definita tramite esponenti negativi.\n6.3.2 Overflow e underflow Questa codifica ha degli errori nella rappresentazione di numeri troppo grandi o troppo piccoli\n6.3.3 ISEE 754 Questo √® lo standard industriale per codificare floating points numbers.\n√à costituito da un totale di 32 bit per BINARY32, ma esiste anche il BINARY64 che utilizza un ragionamento molto simile per i floating points:\n1 bit per segno 8 per l\u0026rsquo;esponente 23 per la mantissa 6.3.4 Tecnica codifica Per trovare la codifica di un floating point, si moltiplica per due il numero che si deve codificare, e ogni volta che l\u0026rsquo;unit√† √® un uno si mette un uno, altrimenti uno zero, questo perch√© la moltiplicazione equivale a uno shift a sinistra.\n6.4 Caratteri Creo una funzione binaria per ogni carattere esistente, storicamente si utilizzavano 8 bit per fare questa codifica, di cui i primi 32 erano caratteri speciali per la stampa tipografica, altri erano utilizzati per maiuscole e minuscole e caratteri speciali\n6.4.1 ASCII American Standard Code of information exchange, √® la codifica storica per i caratteri, questa codifica per√≤ non bastava perch√© bisognava aggiungere codifiche per caratteri non alfabetici oppure agli emoji\n6.4.2 Unicode √® l\u0026rsquo;espansione con 16 bit al posto di 8 ma sono finiti molto presto e quindi c\u0026rsquo;√® bisogno di qualche altra forma che possa essere molto pi√π sicur\n6.4.3 UTF-8 Questa √® il nome della codifica moderna che permette di avere molti altri caratteri invece che solamente i caratteri dell\u0026rsquo;alfabeto inglese. (esempio gli accenti italiani sono codificati con UTF-8)\nDinamico in quanto pu√≤ prendre da 1 a 4 byte in modo dinamico.\nEsiste anche UTF-16 ma non √® ancora diffuso come UTF-8\n6.5 Errori 6.5.1 Necessit√† di errori Raggi cosmici, (mandare segnali a sonde spaziali √® molto facile avere interferenze e gli errori sono comuni) Errori di memorizzazione di trasmissione Vibrazioni e radiazioni dell\u0026rsquo;ambiente circostante, quindi vogliamo trasmettere in modo che non ci siano errori di trasmissione. A volte non c\u0026rsquo;√® necessit√† di controllare errori: esempio il protocollo UDP\nOppure se voglio fare una transazione il codice di errore allora √® molto pi√π importanti\n6.5.2 Parola codice Sto aggiungendo a m bit r bit di controllo e prendo n = m + r come la parola codice che contiene\nInformazioni di controllo correttezza (si prende che ci sia una probabilit√† molto piccola di errori). Informazioni da trasmettere 6.5.3 Costo controllo delle informazioni C\u0026rsquo;√® una differenza fra la correzione di un errore e il rilevamento, la correzione √® molto pi√π dispendiosa. C\u0026rsquo;√® un modo per correggere in modo semplice? Con poco costo?\n6.5.4 Distanza di Hamming Praticamente √® il numero di 1 dopo che si ha uno xor fra tutti.\nPer rappresentare di mettono n numeri in un cubo n dimensionale, e si valuta la distanza fra i due.\n6.5.5 Minima distanza per trovare un errore The minimum Hamming distance is used to define some essential notions in coding theory, such as error detecting and error correcting codes. In particular, a code C is said to be k error detecting if, and only if, the minimum Hamming distance between any two of its code-words is at least k+1.\nCome mai per trovare un errore su d bytes servono d + 1 bits? come mai per corregger di pi√π?\n6.5.6 Minima distanza per correggere un errore A code C is said to be k-errors correcting if, for every word w in the underlying Hamming space H, there exists at most one codeword c (from C) such that the Hamming distance between w and c is at most k. In other words, a code is k-errors correcting if, and only if, the minimum Hamming distance between any two of its codewords is at least $2k + 1$. This is more easily understood geometrically as any closed balls of radius k centered on distinct codewords being disjoint. These balls are also called Hamming spheres in this context.\nAssunto massimo un bit sbagliato abbiamo che il codice correttore deve soddisfare\n$2^m(1 + n) \\leq 2 ^n$\nIl bit di parit√† utilizza tanti bit.\nUna parola pu√≤ essere solo una sbagliata e poi m modi di sbagliarla ancora\n6.5.7 Studio del bit parit√† In pratica √® lo Xor fra tutti i bit della parola, quindi molto utile per scoprire errori di un singolo bit. Utile per rilevare gli errori.\n6.5.8 Codice di hamming Sull\u0026rsquo;ALU Ci sono alcune operazioni interessanti per come l\u0026rsquo;ALU calcola ci√≤ che calcola\nDimostrazione trucco per sottrazione !\nE poi nel caso + 1, basta sommare - 1, che si conosce\nShifters ","permalink":"https://flecart.github.io/notes/rappresentazione-delle-informazioni/","summary":"\u003ch2 id=\"61-codifiche\"\u003e6.1 Codifiche\u003c/h2\u003e\n\u003cp\u003eSi utilizzano codifiche, che sono delle \u003cstrong\u003econvenzioni\u003c/strong\u003e, qualcosa che un gruppo di umani ha deciso fosse utile darci un significato.\u003c/p\u003e\n\u003ch3 id=\"611-codifica-posizionale\"\u003e6.1.1 Codifica posizionale\u003c/h3\u003e\n\u003cp\u003eDove $d_i$ √® il valore in posizione $i$ e $b$ √® la base\u003c/p\u003e\n$$\n\\sum_{i=0}^k d_ib\n$$\u003ch3 id=\"612-ottale-esadecimale-e-binario\"\u003e6.1.2 Ottale, esadecimale e binario\u003c/h3\u003e\n\u003cp\u003eQueste sono le codifiche principali per i computer in quanto sono comodi da visualizzare. Inoltre Ottale e esadecimale in particolare sono riassunti dei binari, cio√® sono dei sottoinsiemi che possiedono ancora tutte le caratteristiche e quindi sono comodi\u003c/p\u003e","title":"Rappresentazione delle informazioni"},{"content":"The main difference between reinforcement learning and other machine learning, pattern inference methods is that reinforcement learning takes the concept of actions into its core: models developed in this field can be actively developed to have an effect in its environment, while other methods are mainly used to summarize interesting data or generating sort of reports.\nReinforcement learning¬†(RL) is an interdisciplinary area of¬†machine learning¬†and¬†optimal control¬†concerned with how an¬†intelligent agent¬†ought to take¬†actions¬†in a dynamic environment in order to maximize the¬†cumulative reward. ~Wikipedia page.\nNote: there is a big gap between theory and practise in this field.\nIntroduzione Una delle idee migliori riguardanti questo campo del reinforcement learning √® il focus sul processo decisionale del singolo agente, condizionato al reward che l‚Äôambiente esterno gli d√† (feedback). Il setting classico di questo genere di problemi √® un caso speciale della caratterizzazione presente in l‚Äôintelligenza.\nAbbiamo in questo caso un agente all‚Äôinterno del suo ambiente. L‚Äôagente √® in grado di interagire col suo ambiente attraverso alcune azioni ben definite, e l‚Äôambiente restituisce un feedback ad ogni azione. L‚Äôagente si regola di conseguenza, nel tentativo di massimizzare il reward che riceve.\n√à da notare che questa impostazione √® molto diversa rispetto al machine learning classico, seppur si pu√≤ comunque collocare al suo interno. Classifcamente nei modelli di machine learning supervised si cerca di minimizzare un errore con alcuni dataset etichettati, mentre qui non abbiamo nessuna etichetta, mentre nel unsupervised proviamo a trovare alcuni pattern nei dati, mentre qui non cerchiamo nessun pattern. Si potrebbe dire che questo sia un terzo paradigma di machine learning.\nNOTA: questi appunti riassumono concetti dai primi 4 capitoli del Sutton and Barto 2020\nUn problema classico: n-bandit Vedere N-Bandit Problem.\nSetting classico (Model Policy Reward) Quando andiamo a parlare di Reinforcement learning andiamo a considerare un setting classico di agente che interagisce con un ambiente attraverso delle azioni, e l‚Äôambiente che risponde attraverso i reward. L‚Äôagente osserva quindi lo stato (se √® full-observable vede lo stato esterno, altrimenti partially observable vede solamente parte delle informazioni dello stato dell‚Äôambiente) e insieme al reward percepito prova a eseguire delle altre azioni.\nSono particolarmente importanti quindi 3 parole chiave utili per descrivere una delle 3 frecce in immagine\nModel Il modello dell\u0026rsquo;ambiente lo indichiamo anche come dinamica o sistema di transizione dell‚Äôambiente. nel modello sono definite tutte le distribuzioni di probabilit√† che portano uno stato a un altro: $P(s'|s)$, questo possiamo dire, ossia partendo da uno stato s, quanto √® probabile finire in uno stato s‚Äô ??\n$$ \\begin{align} P: S \\times \\mathcal{A} \\to \\Delta(S) \\\\ r: S \\times \\mathcal{A} \\to [0, 1] \\end{align} $$ Dove $\\Delta$ √® una distribuzione su $S$.\nPolicy La policy √® un indicatore delle azioni del singolo agente, ci dice quanto √® probabile che l‚Äôagente esegua una certa azione, dato che sia sopra un certo stato s, lo indichiamo solitamente con $\\pi(a | s)$. Nel caso in cui √® una policy deterministica, nel senso che a uno stato corrisponde uno e un solo azione, potremmo scrivere qualcosa del tipo $\\pi (s) = a$ Quindi √® una funzione $\\pi: S \\to \\Delta(\\mathcal{A})$.\nReward Il reward descrive il feedback che l‚Äôambiente ritorna al giocatore una volta che una azione √® stata eseguita, spesso lo indichiamo in questi modi\n$$ r(s, a) \\\\ r(s, a, s') \\\\ r(s) $$A seconda di quanto vogliamo esprimere (quindi il reward atteso dopo aver fatto una azione da unc erto stato, il reward atteso dopo aver fatto una azione da un certo stato ed essere arrivati a un certo stao e cos√¨ via\nThe Value function $$ v_{i}(S_{j}) = \\mathbf{E} [r_{i} + r_{i + 1} + \\dots | S_{j}] $$$$ v_{i}(S_{j}) = \\mathbf{E} [r_{i} + v_{i+1}(S) | S_{j}] $$ Con $S$ uno stato su cui puoi essere al passo successivo.\nAll components are functions:\nPolicies: $\\pi: S \\rightarrow A$ (or to probabilities over A) Value functions: $v: S \\rightarrow R$ Models: $m: S \\rightarrow S$ and/or $r: S \\rightarrow R$ State update: $u: S \\times O \\rightarrow S$ Categorie di agenti Policy - Value categorization Value Based ha solamente value based, la sua policy √® basata sul suo valore (in modo greedy va a cercare quale sia lo stato con valore maggiore) Esempi sono Monte Carlo, SARSA, Q-learning, DQN.\nPolicy based Il contrario, non ha value function, ma solamente la policy, tenta direttamente Policy Gradient, NPG, TRPO, PPO.\nActor Critic Ha entrambi, ha sia policy (l\u0026rsquo;attore) e il critico che cerca di aiutare. Questi sono anche chiamati model based.\nModels Model free Se hanno policy o value, ma non hanno nessun modello sull\u0026rsquo;ambiente in cui sono presenti Solitamente sono molto semplici, e permettono di imparare direttamente la policy migliore possibili per questo ambiente. Secondo il professor Buhmann non ha senso parlare di model free perch√© qualunque modello implicitamente ne ha uno.\nModel based Hanno il modello dell\u0026rsquo;ambiente, e non necessariamente hanno policy o value function. Questi potremmo anche chiamarli (Ha \u0026amp; Schmidhuber 2018). Solitamente questi permettono di utilizzare l\u0026rsquo;esperienza meglio (+ sample efficient).\nOther definitions Prediction and control Prediction √® la capacit√† di sapere come sar√† il futuro Control √® la capacit√† di ottimizzare la propria value function. Solitamente sono molto legati fra di loro.\nEpisodic and Non-episodic Episodic -\u0026gt; We have a collection of episodes, each of which gave us new trajectories about it. We can reset the environment as we like Non-episodic -\u0026gt; We learn this online, each one yields a single trajectory, we can\u0026rsquo;t reset.\nOnline vs Offline RL Per i modelli online possiamo andare direttamente ad agire sull\u0026rsquo;ambiente per ottenere dei dati. Si parla di exploitation exploration tradeoff. Solo che bisogna stare attenti perch√© ci pu√≤ essere un rischio per certe azioni. Per esempio una macchina potrebbe schiantarsi quando esplora, perch√© lo sta facendo nel mondo reale. Per i modelli offline abbiamo gi√† collezionato un sacco di dati, e possiamo usare questo per cercare di creare un modello ed imparare. Sono anche chiamati batched RL.\nOn-policy vs Off-policy RL Con on-policy √® sempre un RL online, in cui andiamo ad imparare utilizzando la policy attuale. Con off-policy stiamo usando una policy diversa per andare ad imparare la nostra policy finale. Magari abbiamo un buffer in questo caso che utilizziamo per memorizzare in modo temporaneo le nostre informazioni.\nModel based and Model free Model-based -\u0026gt; We want to create a world model, and try to estimate the state transitions and the rewards Model-free -\u0026gt; We just try to learn enough to act well: we just estimate the value of a single state.\nMarkov chains Dovrebbe essere approfondito meglio in Markov Chains\nReferences [1] Ha \u0026amp; Schmidhuber ‚ÄúWorld Models‚Äù 2018\n","permalink":"https://flecart.github.io/notes/reinforcement-learning-a-introduction/","summary":"\u003cp\u003eThe main difference between reinforcement learning and other machine learning, pattern inference methods is that reinforcement learning takes the concept of \u003cstrong\u003eactions\u003c/strong\u003e into its core: models developed in this field can be actively developed to have an effect in its environment, while other methods are mainly used to summarize interesting data or generating sort of reports.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eReinforcement learning\u003c/strong\u003e¬†(\u003cstrong\u003eRL\u003c/strong\u003e) is an interdisciplinary area of¬†\u003ca href=\"https://en.wikipedia.org/wiki/Machine_learning\"\u003emachine learning\u003c/a\u003e¬†and¬†\u003ca href=\"https://en.wikipedia.org/wiki/Optimal_control\"\u003eoptimal control\u003c/a\u003e¬†concerned with how an¬†\u003ca href=\"https://en.wikipedia.org/wiki/Intelligent_agent\"\u003eintelligent agent\u003c/a\u003e¬†ought to take¬†\u003ca href=\"https://en.wikipedia.org/wiki/Action_selection\"\u003eactions\u003c/a\u003e¬†in a dynamic environment in order to maximize the¬†\u003ca href=\"https://en.wikipedia.org/wiki/Reward-based_selection\"\u003ecumulative reward\u003c/a\u003e. \u003cem\u003e~Wikipedia page\u003c/em\u003e.\u003c/p\u003e","title":"Reinforcement Learning, a introduction"},{"content":"Introduzione all\u0026rsquo;algebra relazionale Confronto con relazioni matematiche Le relazioni come le intendiamo in database sono leggermente diverse rispetto a quelle presenti per le relazioni matematiche:\nNon conta l\u0026rsquo;ordine Ci sono gli attributi Per il resto se introduciamo questo sistema per tenere conto delle astrazioni, possiamo analizzarle matematicamente, e questo ci fornisce qualche sicurezza in pi√π diciamo.\nFour types of operations Set operations: union, intersection, difference Filter queries: Projecting or selecting Renaming queries: renames Join: correlare tuple di relazioni diverse Definition of tuples üü© Le relazioni sono esattamente quelle definite in matematica, per√≤ noi aggiungiamo anche gli attributi, in modo da poter considerare l\u0026rsquo;ordine delle colonne non importante.\nPer prendere anche gli attributi possiamo definire cos√¨:\nTupla = funzione che associa attributo (una stringa) a un valore del dominio dell\u0026rsquo;attributo, definito da una funzione esterna Relazione √® un insieme di tuple. Facendo in questo modo ho risolto il problema dell\u0026rsquo;ordine Set operations Possiamo modellare l\u0026rsquo;algebra come se\nUnions Intersections üü© Vengono indicati con i simboli classici presenti nella teoria degli insiemi $\\cap ,\\cup$ Questa parte non ho capito perch√© deve esistere\u0026hellip; Che scopo ha?\nOperazioni principali Renaming Sintassi e semantica üü© Questo √® un operatore unario.\nIt produces changes on the schema that keep the underlying data un-altered\nDa questa immagine √® abbastanza intuitivo la sintassi utilizzata. $$ \\rho_{end \\impliedby start} (table) $$ **Semantica:** Un attributo del dataset viene richiamato con altro nome. ### Selection Anche questo √® un **operatore unario**. #### Propriet√† della selection (3) üü®+ 1. Schema dell'output √® lo stesso 2. L'output soddisfa un predicato (logico). 3. L'output √® solamente un subset. **Concatenazione**: $$ \\sigma_{a}(\\sigma_{b}(R)) = \\sigma_{a \\land b }(R) $$ $$ \\sigma_{a}(R_{1}\\cup R_{2}) = \\sigma_{a}(R_{1}) \\cup \\sigma_{a}(R_{2}) $$$$ \\sigma_{a}(R_{1} - R_{2}) = \\sigma_{a}(R_{1}) - \\sigma_{a}(R_{2}) $$Altro con insiemi Possiamo notare che operano proprio come se fossero dei set, nel senso unione per or, intersezione per and, e anche intersezione col contrario con il meno.\nSintassi e semantica üü© $$ \\sigma_{predicate}(Relation) $$ Semantica: un insieme che soddisfa le #Propriet√† della selection\nProjection Anche questo √® un unary operator.\nSemantica e sintassi üü© $$ \\pi_{attribute}(Relation) $$Semantica: viene ritornato un insieme con numero tuple della relazione iniziale (o minore per ripetizioni), ma solo con gli attributi di riferimento.\n$$ \\pi_{Y}(r) = \\left\\{ t[Y] | t \\in r \\right\\} $$ Ossia prendo i valori della tupla che corrispondono a quegli attributi, per ogni singola tupla presente in relazione\nCaso ripetizioni üü© Questa √® una cosa da notare, a differenza di Structured Query Language le cose ripetute vengono scartate, si ha unico, in questo caso, perch√© qui siamo nel reame degli insiemi\nPropriet√† di proiezioni üü© $$ \\pi_{x}(R) = \\pi_{x}(\\pi_{xy}(R)) $$ Se lo applico pi√π volte (anche con cose leggermente diverse rimane uguale)\n$$ \\pi_{x}(R_{1} \\cup R_{2}) = \\pi_{x}(R_{1}) \\cup \\pi_{x}(R_{2}) $$Join La join √® necessaria nel caso vogliamo creare correlazione fra tuple presenti in relazioni diverse fra di loro, mentre con #Projection e #Selection possiamo farlo solamente sulla prima.\nFull and empty joins üü© Full -\u0026gt; Every tuple is used (not full is some is used) Empty -\u0026gt; with no outputs Questo √® direttamente dipendente da quali chiavi abbiamo usato durante la join Types of Joins (2) üü©- $$ R_{1} \\bowtie R_{2} = \\left\\{ t \\text{ on } X_{1} \\cup X_{2} | \\exists t_{1} \\in R_{1} \\text{ and } \\exists t_{2} \\in R_{2} \\text{ with } t[X_{1}] = t_{1} \\text{ and } t[X_{2}] = t_{2}\\right\\} $$ Ossia data una tupla nella nuova relazione cos√¨ creata, se prendo i attributi appartenenti alla prima relazione avr√≤ che esiste effettivamente uguale per il secondo.\nOuter joins: Che sono le stesse spiegate in Structured Query Language, ossia andiamo a considerare left, right and full $A ‚üï B, A ‚üñB , A‚üóB$, sono i simboli utilizzati, ma user√≤ sempre $\\bowtie$ con pedice l, r, f per indicarne il tipo, per semplicit√† di notazione.\nLa semantica di questi √® la stessa per SQL, la descriviamo prevemente, sar√† left outer, nel caso in cui ho la garanzia che solamente le tuple della relazione 1 ci sar√†, contrario per right, per il full outer, ho la garanzia che una data tupla finale, sar√† presente in almeno uno dei due iniziali, ma non so quale.\nPropriet√† (2) üü© Push selection $$ R \\bowtie(R_{1} \\cup R_{2}) = (R \\bowtie R_{1}) \\cup(R\\bowtie R_{2}) $$Theta Join üü©- Il theta join viene motivato grazie al fatto che solitamente bisogna sempre rinominare prima di fare una selection, o bisogna fare sempre selection, per questo motivo. Solo che questo √® possibile fare solo se sono una #Cartesian product, ossia non abbiano attributi in comune.\nLa sintassi ammessa nella condizione sono solamente and e relazioni booleane binarie (minore, maggiore, uguale e combinazione fra questi). Altra cosa necesssaria per la theta join, √® che non ci siano attributi in comune fra le due relazioni.\nE si pu√≤ notare sulle slides che questo √® molto simile alla natural join dopo renaming espresso in #Types of Joins (2) in precedenza.\nEqui Join üü© Quello pi√π interessante sono le equi-join che accade quando ho relazioni di equivalenza, questo si manifesta solamente quando la theta join di sopra √® fatta da atomi di uguaglianza, questo mi dovrebbe garantire per certo tale propriet√†.\nCartesian product Si pu√≤ considerare come una join naturale su relazioni senza attributi in comune (quindi tutto si pu√≤ combinare con tutto!).\nViews Introduzione alle data-views üü©- Sono delle rappresentazioni diverse dello stesso genere di data, solitamente utili per fare view diverse (e.g. dipartimento altro avr√† necessit√† diverse), abbiamo accennato a questa necessit√† durante la nostra Introduction to databases. Nel caso preciso di SQL ne andiamo a parlare in Advanced SQL.\nNel caso di algebra relazionale, √® soltanto una specie di dichiarazione di variabile con un altro nome, che specifica quale √® il risultato della sua query.\nView utilization Questa √® una cosa classica in informatica, il concetto di astrazione implementazione presente come descritto in Astrazione sul controllo#Significato di astrazione E dividere in questo modo quello che √® effettivamente memorizzato da quello che l\u0026rsquo;utente deve volere vedere.\nMaterialized views üü©\u0026ndash; La differenza con l\u0026rsquo;altra tipologia di view che viene proposta √® che questa view √® storata fisicamente sui dispositivi di memorizzazione.\nPros:\nVeloce da leggere (non da creare ogni volta) Cons:\nRidondanza dei dati update deve essere doppio (problemi di coerenza) Non supportati dai DBMS. Virtual views üü® Al fine di creare la view viene fatto una query sul database. Non so esattamente se questi possono essere fatti sempre o meno.\nView update üü© Nel caso di sql possiamo andare a definire due valori local o cascade, con il primo la view non aggiorna le tabelle effettivamente presenti, mentre con cascade s√¨. Ma credo non si possa sempre fare e bisogna sempre stare leggermente attenti.\nSome notes on update difficulties √à molto pi√π difficile updatare la view, perch√© questo update deve essere coerente con la versione originale che era esistente! Per questo motivo non tutti gli update sono disponibili per update.\nRelational calculi üü• Si differenzia leggermente dall\u0026rsquo;al\nIntroduction to relational calculi Alla fine si basano tutti su Logica del Primo ordine, Questo √® sempre un modo per modellare le relazioni che sono molto comuni nei casi che abbiamo trovato di relational databases, ma invece di utilizzare algebra utilizzano una logica, descritta sotto.\nQuesto √® molto pi√π vicino all\u0026rsquo;approccio logico, sviluppato durante gli anni 70-80 con knowledge bases in AI.\nGeneral form üü®+ $$ \\left\\{ A_{1}: x_{1}, \\dots A_{k} : x_{k} | f \\right\\} $$In cui abbiamo\n$f$ che √® una formula che probabilmente da un booleano per decidere se prenderlo o meno. $A_{i}$ che sono degli attributi $x_{i}$ che sono delle variabili Avremo come output una tupla di $(x_{1}, \\dots x_{n})$ che soddisfano $f$ Esempi: Esistono forme anche leggermente pi√π complicate, ma dobbiamo introdurre gli esistenziali: Esistono anche i de morgan rules che si possono applicare, perch√© in pratica √® logica.\nRelational calculi, considerations Aspetti negativi (2) üü® Moltissime variabili inutili (troppo verboso scriverci). Presenza di espressioni senza senso e dipendenti dal dominio questo significa che se cambiamo il dominio di definizione cambiamo anche i valori che sono possibilmente denotati (non ho capito perch√© questa dovrebbe essere una caratteristica negativa poi). Per risolvere il primo problema si aggiunge una sintassi pi√π compatta, presentata come \u0026ldquo;range declaration syntax\u0026rdquo; (ma non √® espressivo quanto algebra, in qualche modo si dimostra)\u0026hellip;\nRange declaration syntax üü® Pagina 78 del libro ne parla meglio, dovrei approfondire quello. #### Indipendenza da dominio üü® $$ A_{1} : x_{1} | not R(A_{1} : x_{1}) $$ √à dipendente dal dominio, perch√© prende l\u0026rsquo;insieme degli elementi nel dominio, tali che non sono presenti nella relazione. Abbiamo bisogno di questa propriet√† perch√© se √® dipendente dal dominio si potrebbero produrre risultati enormi, che rendono l\u0026rsquo;applicazione pratica nulla.\nEquivalenza con Algebra relazionale üü© Si pu√≤ dimostrare che se ci limitiamo alle espressioni indipendenti col dominio, i due modelli sono esattamente uguali, ossia possiamo dire che possiamo creare una espressione di algebra, partendo da calcolo, e viceversa.\nLa dimostrazione (che non facciamo) andr√† per induzione strutturale, quella che trovi in Logica in Deduzione naturale.\nPossiamo notare che l\u0026rsquo;algebra √® indipendente dal dominio, perch√© l√¨ non √® mai esplicitata la relazione in che dominio sia (abbiamo operazioni chiuse si pu√≤ dire).\n","permalink":"https://flecart.github.io/notes/relational-algebra/","summary":"\u003ch2 id=\"introduzione-allalgebra-relazionale\"\u003eIntroduzione all\u0026rsquo;algebra relazionale\u003c/h2\u003e\n\u003ch3 id=\"confronto-con-relazioni-matematiche\"\u003eConfronto con relazioni matematiche\u003c/h3\u003e\n\u003cp\u003eLe relazioni come le intendiamo in database sono leggermente diverse rispetto a quelle presenti per le relazioni matematiche:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eNon conta l\u0026rsquo;ordine\u003c/li\u003e\n\u003cli\u003eCi sono gli attributi\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003ePer il resto se introduciamo questo sistema per tenere conto delle astrazioni, possiamo analizzarle matematicamente, e questo ci fornisce qualche sicurezza in pi√π diciamo.\u003c/p\u003e\n\u003ch4 id=\"four-types-of-operations\"\u003eFour types of operations\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSet operations\u003c/strong\u003e: union, intersection, difference\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFilter queries\u003c/strong\u003e: Projecting or selecting\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRenaming queries\u003c/strong\u003e: renames\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eJoin\u003c/strong\u003e: correlare tuple di relazioni diverse\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"definition-of-tuples-\"\u003eDefinition of tuples üü©\u003c/h4\u003e\n\u003cp\u003eLe relazioni sono esattamente quelle definite in matematica, per√≤ noi aggiungiamo anche gli attributi, in modo da poter considerare l\u0026rsquo;ordine delle colonne non importante.\u003c/p\u003e","title":"Relational Algebra"},{"content":"This is the classical format that we encounter, it is the format used for relational databases introduced in databases course introduction, introduced in (Codd 1970).\nIntroduzione, i modelli di dati Lista modelli di dati (4) Nel tempo sono stati sviluppati molti modelli di dati:\nRelational Data Model: This is the most common data model and uses tables to represent data. It organizes data into rows and columns, where each row represents a record, and each column represents an attribute of that record. Relationships between data are established through keys.\nEntity-Relationship Model: This model focuses on the relationships between entities, which are objects or concepts, and how they relate to each other. It is often used in the design of databases.\nNoSQL Data Model: NoSQL databases use various data models, such as document, key-value, column-family, or graph, to store and manage data. These models offer more flexibility than the traditional relational model.\nHierarchical and Network Data Models: These older models organize data in a tree or graph structure, which was common in early database systems.\nIn questa sezione andiamo ad analizzare il primo. (anche perch√© quello storicamente pi√π rilevante, e ancora (tristemente) pi√π utilizzato).\nAltri modelli come reticolare e gerarchico erano famosi all\u0026rsquo;inizio, ma si √® scelto di andare sul modello relazionale col tempo\nVantaggi relazionale (Codd 1970) √® stato un contributo fondamentale, la separazione fra layer logico e fisico √® stato proprio necessario per fare questi modelli Rappresenta solamente ci√≤ che √® importante Semplicit√† del passaggio per valori. Il modello relazionale We can represent each row of a table as a partial function, in the domain of the headers,\nDomini e attributi Schemi e istanze di relazione e di basi di dati üü© Potremmo definire in maniera lasca, che una base di dati a modello relazione √® un insieme di relazioni, che possono avere schemi diversi. Ad alto livello possiamo dire che uno schema √® la descrizione matematica dei domini, mentre l\u0026rsquo;istanza √® una serie di dati che rispettano quello schema. In matematichese possiamo vedere in immagine:\nIntroduzione concetti fondamentali üü© In pratica abbiamo $D_{1}, \\dots D_{n}$ domini a cui spesso sono associati dei nomi, chiamati attributi che spiegano l\u0026rsquo;interpretazione di questo dominio, che vengono rappresentati come gli headers o nomi delle colonne. Un campione di questo dataset non √® altro che un cittadino nell\u0026rsquo;insieme $D_{1} \\times \\dots \\times D_{n}$, in cui non importa n√© l\u0026rsquo;ordine dei singoli elementi all\u0026rsquo;interno della tupla, ma non importa per gli elementi fra una tupla e una altra.\nNel caso in cui la posizione degli attributi non √® importante (quindi posso mischiare una colonna a una altra) si dice che il database √® non-posizionale Le due colonne scambiate non ci fanno differenza dal punto di vista logico.\nSchemi matematici o relazionali üü© $$ dom: X \\to D,,,, A \\in X $$ E si pu√≤ introdurre una notazione simile per le tuple $t$ su una certa relazione, che permette di prendere il valore di quella tupla, scegliendo una relazione specifica.\nCondizioni necessarie per relazione (3) üü© Devono esserci tutti i dati (colonne) per ogni riga.\nQuindi non vengono ammesse NaN Tutte le righe sono elementi diversi (questa non la ho capita bene, perch√© necessariamente devono essere tutti diversi?)\nLe tipologie di valori per colonna sono omogenee Domain integrity, Relational Integrity\nChiavi e vincoli Keys and superkeys üü© Superkeys Sono il subset degli attributi utili a identificare in modo univoco un sample.\nCandidate Keys Sono il subset minimo di chiavi utilizzati per identificare un record\nPrimary keys sono solo dei candidate keys identificati da un designer.\nPossiamo proprio dare una definizione formale del concetto di chiave, come l\u0026rsquo;insieme di cardinalit√† minima degli attributi superchiave.\nCosa succede invece nel momento in cui includiamo la possibilit√† che certi valori possano essere nulli nel nostro schema? Chiaramente se una chiave diventa nulla diventa impossibile identificare il valore di essa! Per questo motivo dobbiamo mettere un constraint e dire che non pu√≤ esserlo, in questo modo possiamo identificare in modo univoco ogni entry.\nForeign Key and Referential integrity (!) üü© √à un attributo del nostro schema che si riferisce a una primary key esterna. Anche chiamato referential integrity constraint.\nDefinizione:\nfra un insieme di attributi $X$ di una relazione $R_{1}$ e un‚Äôaltra relazione $R_{2}$ √® soddisfatto se i valori su $X$ di ciascuna tupla dell\u0026rsquo;istanza di $R_{1}$ compaiono come valori della chiave (primaria) dell‚Äôistanza di $R_{2}$\nSe ho una foreign key, non avrebbe senso se il valore a cui si riferisce non esistesse!\nVincoli I vincoli servono per imporre dei limiti tali per cui i dati abbiano un senso nel nostro dominio, possono essere di tipi specifici, come di tupla e in genere sono intra-relazionali, ossia non hanno bisogno di andare su altre relazioni, oppure inter-relazionali, se prendono pi√π relazioni.\nDatabase schema The schema of a relation refers to its logical design, while an instance of the relation refers to its contents at a point in time. The schema of a database and an instance of a database are similarly defined. The schema of a relation in- cludes its attributes, and optionally the types of the attributes and constraints on the relation such as primary and foreign key constraints.\nStandardization Da questa parte trattiamo meglio quando parliamo di forma Normale in seguito Abbiamo detto che il dataset relazionale ha un formato preciso #Condizioni necessarie per relazione (3) espresso in questo punto, ma ci sono alcuni formati comuni che non lo sono, andiamo a vedere come si possono riportare nel formato standard\nUnnesting Per questo riguarda questo un\nPartial information Non sarebbe sensato utilizzare elementi che siano dentro il nostro dominio della colonna per rappresentare un dato che manca. Per questo motivo si utilizza NULL che rappresenta proprio il dato mancante, e il dominio della colonna sarebbe sempre esteso con NULL (almeno ch√© esplicitamente vietato).\nTypes of Nulls (3) Unknown Inexistant Uninformative Ma nei DBMS non si fa distinzione, quindi si utilizza un unico null type. References [1] Codd ‚ÄúA Relational Model of Data for Large Shared Data Banks‚Äù Communications of the ACM Vol. 13(6), pp. 377\u0026ndash;387 1970\n","permalink":"https://flecart.github.io/notes/relational-model/","summary":"\u003cp\u003eThis is the classical format that we encounter, it is the format used for relational databases introduced in \u003ca href=\"/notes/introduction-to-databases/\"\u003edatabases course introduction\u003c/a\u003e, introduced in \u003ca href=\"https://dl.acm.org/doi/10.1145/362384.362685\"\u003e(Codd 1970)\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id=\"introduzione-i-modelli-di-dati\"\u003eIntroduzione, i modelli di dati\u003c/h3\u003e\n\u003ch4 id=\"lista-modelli-di-dati-4\"\u003eLista modelli di dati (4)\u003c/h4\u003e\n\u003cp\u003eNel tempo sono stati sviluppati molti modelli di dati:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eRelational Data Model:\u003c/strong\u003e This is the most common data model and uses tables to represent data. It organizes data into rows and columns, where each row represents a record, and each column represents an attribute of that record. Relationships between data are established through keys.\u003c/p\u003e","title":"Relational Model"},{"content":"Iterazione Questo metodo semplicemente consiste di calcolare tutte le operazioni e scriverlo con una notazione asintotica.\nslide\nSostituzione (induzione) slide\nAnalisi della relazione di ricorrenza di fibonacci\nSi pu√≤ dimostrare utilizzando l\u0026rsquo;induzione che una relazione di questo tipo\n$$ T(n) = \\begin{cases} O(1) \\\\ T(n-1) + T(n-2) + 1 \\end{cases} $$Si trova che √® $O(2^n), \\Omega(2^{n/2})$\nAnalisi finale.\nSi pu√≤ creare una stima corretta, utilizzando la formula per il calcolo di fibonacci (che dimostri facendo osservazioni su una funzione generatrice di essa, una serie infinita).\nAlbero di ricorsione slide\nTeorema dell‚Äôesperto (master) Questo teorema permette di stabilire subito la stima asintotica per tutte le ricorrenze nella forma\n$T(n) = aT(n/b) + f(n)$ ed √® diviso in tre casi:\n23/03 Ricordo tutto come se fosse ieri 09/04 Non ti ricordi esattamente tutto (teoricamente albero di ricorsione, ma in pratica non lo so se lo fa) in tre casi: 23/03 Ricordo tutto come se fosse ieri 09/04 Non ti ricordi esattamente tutto (teoricamente albero di ricorsione, ma in pratica non lo so se lo fa) ","permalink":"https://flecart.github.io/notes/relazioni-di-ricorrenza/","summary":"\u003ch3 id=\"iterazione\"\u003eIterazione\u003c/h3\u003e\n\u003cp\u003eQuesto metodo semplicemente consiste di calcolare tutte le operazioni e scriverlo con una notazione asintotica.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eslide\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Relazioni di Ricorrenza/Untitled.png\" alt=\"image/universita/ex-notion/Relazioni di Ricorrenza/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"sostituzione-induzione\"\u003eSostituzione (induzione)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eslide\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Relazioni di Ricorrenza/Untitled 1.png\" alt=\"image/universita/ex-notion/Relazioni di Ricorrenza/Untitled 1\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eAnalisi della relazione di ricorrenza di fibonacci\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eSi pu√≤ dimostrare utilizzando l\u0026rsquo;induzione che una relazione di questo tipo\u003c/p\u003e\n$$\nT(n) = \\begin{cases}\nO(1) \\\\\nT(n-1) + T(n-2) + 1\n\\end{cases}\n$$\u003cp\u003eSi trova che √® $O(2^n), \\Omega(2^{n/2})$\u003c/p\u003e\n\u003cp\u003eAnalisi finale.\u003c/p\u003e\n\u003cp\u003eSi pu√≤ creare una stima corretta, utilizzando la formula per il calcolo di fibonacci (che dimostri facendo osservazioni su una funzione generatrice di essa, una serie infinita).\u003c/p\u003e","title":"Relazioni di Ricorrenza"},{"content":"Coppia ordinata Definizione di Kuratowsky Una coppia ordinata √® definita dall\u0026rsquo;insieme\n$$ \\langle X, Y \\rangle = \\{X, \\{X, Y\\}\\} $$√à quindi chiaro che due coppie ordinate sono uguali fra di loro nel caso in cui gli elementi sono uguali ma anche la loro posizione sono uguali\nTeorema caratterizzazione delle coppie\nDefinizione di Wiener $$ (X,Y) := \\{\\{\\{X\\}, \\varnothing\\}, \\{\\{Y\\}\\}\\} $$Definizione di Hausdorff $$ (X,Y) := \\{\\{X, 1\\}, \\{X,2\\}\\} $$Propriet√† fondamentale coppie ordinate Due coppie ordinate si dicono uguali se e solo se il primo elemento dei due sono uguali e la stessa cosa per il secondo\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Relazioni fra insiemi/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Relazioni fra insiemi/Untitled 1\u0026quot;\u0026gt; DImostrazione di wiki, difficile\nProdotto cartesiano Definizione del prodotto $$ \\forall A, \\forall B, \\exists C,\\forall Z (Z \\in C \\iff \\exists a, \\exists b(a \\in A \\, \\wedge \\, b \\in B \\, \\wedge \\, Z \\in \\langle a, b\\rangle)) $$Utilizzando un linguaggio naturale, stiamo prendendo tutti gli elementi da due insiemi e stiamo prendendo una coppia ordinata: prendiamo tutte le coppie ordinate possibili.\nquesto si indica con $A \\times B$\nRelazione e con il Vuoto Una relazione √® una qualunque sottoinsieme di $A \\times B$\nQuesta cosa si scrive come $a\\mathcal{R}b \\iff \\langle a,b \\rangle \\in \\mathcal{R}$\nTeorema relazioni da e verso insiemi vuoti.\nSe $\\mathcal{R} \\subseteq A \\times \\varnothing \\text{ or } \\varnothing \\times A \\text{ allora } \\mathcal{R} = \\\\varnothing$ questo si dimostra che il prodotto cartesiano con un insieme vuoto √® sempre vuoto, quindi l\u0026rsquo;unica relazione esistente √® il vuoto.\n##Funzione\nPer ogni elemento di un elemento dominio, si ha solo una unica immagine in un insieme d\u0026rsquo;arrvo immagine, si scrive $X f Y$:\n$$ \\forall X(X \\in A \\implies \\exists! Y, X f Y) $$L\u0026rsquo;abuso di notazione tipico dei matematici √® una falsit√† perch√© sembra che la funzione calcoli Y, inverit√† non calcola niente, ma solamente √® una relazione. Ecco l\u0026rsquo;abuso di notazione.\nSpazio di funzioni $\\forall A, \\forall B, \\exists C, \\forall f (f \\in C \\iff \\text{ f √® una funzione dal dominio A e codominio B} \\text{ e si ha che C = } B^A)$\nFunzioni da e verso insieme vuoti Se √® il codominio vuoto, allora non esistono funzioni possibili perch√© non esistono relazioni possibili, non ho nessun elemento da collegare agli elementi del dominio.\n$\\varnothing^{A} = \\varnothing$\nSe il dominio √® vuoto, allora esiste la funzione vuota, che non fa nulla, perch√© tanto non ho nessun X appartenente a A da loopare, non faccio niente quindi creo l\u0026rsquo;insieme che non ha nulla.\n$$ B^{\\varnothing} = \\left\\{ \\varnothing \\right\\} $$ Se sia codominio che dominio sono vuoti allora devo prima loopare nel dominio, che √® vuoto, quindi gi√† l\u0026rsquo;insieme vuoto ho creato.\nRelazioni RST Propriet√† delle relazioni Riflessiva se $\\forall X, X\\mathcal{R}X$\nSImmetrica $\\forall X, \\forall Y X\\mathcal{R}Y \\implies Y\\mathcal{R}X$\nTransitiva $\\forall X,Y,Z (X\\mathcal{R}Y \\wedge Y\\mathcal{R}Z\\implies X\\mathcal{R}Z)$\nPropriet√†\nEsempi\n= Vale tutti e tre\n\u0026lt; Transitiva non simmetrica e non riflessiva\n‚â§ transitiva e riflessiva ma non simmetrica\n‚â† √® simmetrica e bbasta\nOrdinamento stretto Una funzione che sia transitiva e non riflesssiva, per esempio il \u0026lt; o il \u0026gt;\nOrdinamento lasco Una funzione che sia transitiva e riflessiva per esempio ‚â§ o il ‚â• In pi√π si pu√≤ dire che sia antisimmetrica, cio√® che se vale $x\\mathcal{R}y \\wedge y\\mathcal{R}x \\implies x = y$ Un altro buon esempio √® la relazione di divisione.\nEquivalenza Se ha tutte e tre le propriet√† si pu√≤ dire che sia una relazione di equivalenza. Questa relazione √® utile per confrontare oggetti perch√© √® come dire che sono la stessa cosa due elementi quando soddisfano una relazione di equivalenza. Dire che sono uguali √® stato un qualcosa di cui la matematica si √® interessata storicamente, dire uguale √® diverso da dire che sono equivalenti.\nEsercizio Difficile Soluzione\nMisc Classi $\\equiv\\subseteq A \\times A \\text{ √® una relazione di equivalenza, allora la classe di equivalenza di } x\\in A \\text{ rispetto a } \\equiv \\text{ √® definito come }[x]_\\equiv =^{def} \\{ y \\in A | y \\equiv x\\}$\nRelazioni fra classi di equivalenza Fra tutte le classi di equivalenza di ha che ho le due classi sono equivalenti fra di loro, oppure sono diverse (disgiunte) fra di loro.\nAbbozzo di dim\nPreso classe equivalente X, Y,allora per la transivit√† Z √® transitivo sia a Z X sia a Y, e poi si pu√≤ utilizzare, usiamo l\u0026rsquo;assioma di estensionalit√† per dimostrare che le due classi sono uguali.\nPoi cerco l\u0026rsquo;intersezione, se nell\u0026rsquo;intersezione di due classi di equivalenza trovo un Z, ho che queste due classi sono identitiche, e se sono identiche so che ci sono Z e simili.\nInsieme quoziente L\u0026rsquo;insieme quoziente contiene tutti gli elementi (classi di equivalenza) possibili (disgiunti per la classe di equivalenza).\n√® definita come, fatto con l\u0026rsquo;assioma di rimpiazzamento (posso creare un insieme se possiedo una funzione)\n$$ U_{/\\equiv} := \\{[x]_\\equiv \\,|\\, x \\in U \\} $$Utilit√†\nQuesti insiemi sono utili per costruire ancora, scegliere qualche propriet√† a seconda del bisogno.\nCostruzione di $\\mathbb{Z}$ Partendo dall\u0026rsquo;insieme del prodotto cartesiano $\\mathbb{N} \\times \\mathbb{N}$ definiamo ogni coppia $\\langle a, b\\rangle$ come $a - b$. Allora possiamo definire una classe di equivalenza per il risultato di una sottrazione\u0026hellip; Preso l\u0026rsquo;insieme quoziente di tutte queste classi di equivalenza si pu√≤ creare $\\mathbb{Z}$ e lo possiamo indicare con numeri come al solito. Quindi invece di indicare un numero in Zeta come una classe di equivalenza, indico normalmente con + -.\nCostruzione di $\\mathbb{Q}$ Uguale a Z solo che invece della sottrazione creo la somma Esistenza funzione bigettiva N ‚Üí Q\nCardinalit√† di un insieme Intuizione dalle funzioni Si pu√≤ creare una prima intuizione dal concetto di iniettivit√†, suriettivit√† e bigezione di funzioni fra due insiemi sul concetto di cardinalit√†\nIniettivit√†\nSe il codominio fosse pi√π piccolo del dominio, per il principio dei cassetti deve esserci una relazione che punta allo stesso elemento nel codominio, per cui la cardinalit√† del codominio deve essere pi√π grande\nSuriettivit√†\nSe il dominio fosse pi√π piccolo del cominio, non avrei abbastanza frecce per raggiungere tutti gli elementi del codominio, quindi sarebbe impossibile una funzione suriettiva.\nBigettivit√†\nSe per iniettivit√† e suriettivit√† i due insiemi devono essere uguali per cardinalit√†\nDefinizione di cardinalit√† Due elementi hanno la stessa cardinalit√† sse esiste una bigezione fra i due, e quindi possono definire una classe di equivalenza indicata\n$U_{/\\equiv}$ e posso poi definire anche una classe quoziente delle relazioni di equivalenza.\nDefinizione con insiemi √à possibile, con un lunghissimo lavoro, costruire questa classe attraverso solamente gli insiemi questa classe, invece di utilizzare le classi di equivalenza.\nIn altre parole si pu√≤ dimostrare che √® abbastanza piccola la classe dei numeri cardinali\nCritica al matematico\nIl matematico indica con lo stesso numero un numero cardinale e il numero naturale, ma per definizione di numero cardinale e numero naturale sono diverse, il primo √® una classe di quivalenza ddell\u0026rsquo;insieme {1,2,3} (che contiene in s√© tutti gli insiemi di 3 elementi, fra qui anche il numero naturale 3, mentre per definizione del numero natuale 3 √® {0,1,2}\nAbuso di notazione e aleph Si indica la classe di equivalenza per la classe di equivalenza $[x]_{/\\equiv}$ come $|x|$\nIn particolare per indicare la cardinalit√† dei numeri naturali √® $\\aleph_0$\nInsiemi infiniti Fra questi definiamo anche l\u0026rsquo;insieme finito che praticamente √® definito come la negazione dell\u0026rsquo;insieme finito.\nAlbergo di Hilbert Hilbert √® stato uno dei matematici pi√π famosi a fine secolo scorso e cre√≤ i problemi del millennio per lo sviluppo della matematica attuale.\nAlbergo finito e infinito Se √® finito allora non si pu√≤ accomodare in nessun modo.\nMa se invece √® infinito? Una soluzione potrebbe essere che ogni cliente si muova nella stanza col numero seguente e si potrebbe trovare di nuovo altro spazio.\nDefinizione di infinito Infinito √® quando in bigezione con un suo sottoinsieme proprio, ma non √® s√© stesso. In simboli: $A \\subset B \\wedge \\exists f: B f A$ e f sia bigettiva.\nqui infatti esiste un paradosso, in quanto essendo essendo un sottoinsieme allora si pu√≤ dire che sia pi√π piccolo, ma con l\u0026rsquo;intuizione dell\u0026rsquo;infinito possiamo dire che hanno la stessa cardinalit√†, hanno la stessa grandezza.\nOrdinamento sugli infiniti \u0026lt;, ‚â§ ‚â§ Ordinamento lasco\nEsiste una classe di equivalenza di ordinamento lasco sse dati due insiemi A, B si ha |A| ‚â§ |B| se esiste una iniezione fra |A| o |B|\n\u0026lt; Ordinamento stretto\n√à simile al precedente, ma devo togliere l\u0026rsquo;uguale quindi dico che non esiste una bigezione.\nDiagonalizzazione di Cantor Dimostrazione diagonalizzazione di Cantor Teorema $|T| \u003c | 2^T|$\nDimostrare per assurdo che non esiste una funzione bigettiva da T a $2^T$ e poi dimostrare che esiste una funzione iniettiva da T a $2^T$.\nLa funzione iniettiva √® semplice perch√© basta mappare ogni T al suo singoletto equivalente in $2^T$\nIn seguito dimostriamo per assurdo che non esiste una funzione bigettiva.\nSupponiamo una funzione bigettiva, al fine di creare l\u0026rsquo;assurdo abbiamo bisogno dei tre elementi presentati in Logica meta-linguistica. Quindi meta linguistica, riflessione e negazione.\nDefiniamo quindi un insieme $A = \\{x \\in T| x \\not\\in g(x) \\}$ data la funzione $g(x)$ bigettiva.\n(Possiamo definire x che appartiene all\u0026rsquo;insieme imamgine perch√© l\u0026rsquo;insieme di arrivo sono degli insiemi, in quanto √® l\u0026rsquo;insieme delle parti).\nMa allora data l\u0026rsquo;iniettivit√† della funzione $g(y) \\in 2^T$ esiste un $y \\in T$, ma allora $y \\in g(x) \\iff y \\not\\in g(x)$ e quindi porta all\u0026rsquo;assurdo.\nDimostrazione con tabella Questa √® quella usata in R e Intervalli#Innumerabilit√† di R.\nSupponiamo che l\u0026rsquo;intervallo $[0, 1[$ sia numerabile, ossia esiste una funzione $f: \\mathbb{N} \\to [0, 1[$ che sia bigettiva. Scriviamo tutti i numeri possibili in forma binaria\nAvremo una tabella simile: che ci dice che\nNatural Real number 1 0,00001010101\u0026hellip; 2 0,100101011010 E continua all\u0026rsquo;infinito (poi sopra sarebbe bello avere anche uno 0), allora posso creare un nuovo numero che per costruzione non √® mappato da nessun naturale (flippo i numeri sulla diagonale). Quindi non √® suriettiva, e la costruzione porta ad un assurdo. Sintesi Dim Data la dimostrazione abbastanza complicata (per me boh) provo a rilistare i passaggi principali utili per questa dimostrazione.\nUtilizzare l\u0026rsquo;assurdo per dimostrare l\u0026rsquo;inesistenza di una funzione bigettiva Utilizzare la suriettivit√† della funzione bigettiva per creare un insieme che possa dare un assurdo. Allora $g(y) = A$ definito con quella propriet√† per assurdo, questa deve esistere per suriettivit√† Devo creare un y appartenente a $T$ l\u0026rsquo;insieme iniziale perch√© cos√¨ comincio a creare qualcosa Dico assurdo perch√© entrambi i casi, che $y \\in A, y\\not\\in A$ creano assurdo perch√© implicano tra di loro. $\\lvert T \\rvert \u003c \\lvert T^{T} \\rvert$ Questo √® un corollario della diagonalizzazione di Cantor, che utilizza una semplice disuguaglianza di una funzione caratteristica.\nL\u0026rsquo;unica cosa nuova √® $\\mathbb{B}^T \\leq |T^T|$ questo √® vero perch√© le funzioni che restituiscono un booleano, sono un sottoinsieme delle funzioni che restituiscono T, quindi iniezione √® semplice da trovare e si dimostra.\nFunzione caratteristica Data un\u0026rsquo;insieme booleano, prendiamo un insieme che restituisce vero se l\u0026rsquo;elemento appartiene, falso se non lo fa.\n$\\mathbb{B}$ √® un insieme con due elementi indicati con 1, 0.\n$\\chi_c \\in \\mathbb{B} ^A$, posso dire che esiste una bigezione fra questo e l\u0026rsquo;insieme delle parti di A.\nAAAAAA, ovvio, per ogni sottoinsieme C, esiste una unica funzione che mi dice se questi elementi appartengono o meno ad A!\nImpossibilit√† eguaglianza in matematica Questo teorema ci dice che non si pu√≤ creare totalmente una funzione implementata che sia precisa come una funzione matematica.\nData una funzione che va da un insieme grande da un insieme grande, √® possibile che non possa essere implementata\nCuriosit√†\nPer il matematico, data una qualunque funzione, la probabilit√† che sia implementabile, √® molto vicina a Zero\nCostruzione di $\\mathbb{R}$ Immaginando un numero reale, si ha che un $n\\in\\R$ in pu√≤ rappresentare come una parte intera e una sequenza infinita di numeri dopo (di cui possiamo solo approssimare).\nCardinalit√† dei reali superiore di Aleph 0 Per semplicit√†, prendiamo la rappresentazione in base due di questo numero, allora questo $\\in B^\\N$\n(Questo si pu√≤ vedere senza molti problemi, quanto la sequenza √® infinita, prendo per ogni posizione dopo la virgola arriva a un numero Booleano)\nEs. 0,111100001111\u0026hellip;\nN 0 0123456789\u0026hellip;.\nMa se queste funzioni appartengono a questo spazio di funzioni, si pu√≤ finire dicendo che √® $|B^\\N| \u003e |N|$\nEsempio sulla densit√† di R I numeri hanno possibilmente infinite cifre dopo la virgola, ma √® possibile tenerli solamente per $\\dfrac{1}{10^n}$ con n il numero di cifre dopo la virgola (e ci stanno un sacco di numeri).\nQuesta successione tende chiaramente a 0. Quindi le probabilit√† sono quasi nulle.\n","permalink":"https://flecart.github.io/notes/relazioni-fra-insiemi/","summary":"\u003ch2 id=\"coppia-ordinata\"\u003eCoppia ordinata\u003c/h2\u003e\n\u003ch3 id=\"definizione-di-kuratowsky\"\u003eDefinizione di Kuratowsky\u003c/h3\u003e\n\u003cp\u003eUna coppia ordinata √® definita dall\u0026rsquo;insieme\u003c/p\u003e\n$$\n\\langle X, Y \\rangle = \\{X, \\{X, Y\\}\\}\n$$\u003cp\u003e√à quindi chiaro che due coppie ordinate sono uguali fra di loro nel caso in cui gli elementi sono uguali ma anche la loro posizione sono uguali\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTeorema caratterizzazione delle coppie\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Relazioni fra insiemi/Untitled.png\" alt=\"image/universita/ex-notion/Relazioni fra insiemi/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"definizione-di-wiener\"\u003eDefinizione di Wiener\u003c/h3\u003e\n$$\n(X,Y) := \\{\\{\\{X\\}, \\varnothing\\}, \\{\\{Y\\}\\}\\}\n$$\u003ch3 id=\"definizione-di-hausdorff\"\u003eDefinizione di Hausdorff\u003c/h3\u003e\n$$\n(X,Y) := \\{\\{X, 1\\}, \\{X,2\\}\\}\n$$\u003ch3 id=\"propriet√†-fondamentale-coppie-ordinate\"\u003ePropriet√† fondamentale coppie ordinate\u003c/h3\u003e\n\u003cp\u003eDue coppie ordinate si dicono uguali se e solo se il primo elemento dei due sono uguali e la stessa cosa per il secondo\u003c/p\u003e","title":"Relazioni fra insiemi"},{"content":"Replication and consistency Introduzione Ci sono due vantaggi principali nella replicazione dei dati\nVelocit√† Vicinanza geografica (quindi meno tempo ad andare a tornare) Maggiore computazione, quindi avere molti pi√π processori che cercano di offrire lo stesso servizio. Affidabilit√† Cos√¨ se una sede diventa corrotta, posso avere abbondanza, avere una copia da una altra parte, cos√¨ non perdo le informazioni! Se una macchina cade in errore, ho altre macchine che lo sostituiscono! Quindi dal punto di vista dell‚Äôutente funziona ancora. Ma provare ad avere lo stesso dato in zone diverse porta a grandi problemi riguardo la consistenza! Come facciamo ad avere la garanzia che due cose diverse abbiano la stessa informazione?\nConsistency La nozione di consistenza non √® che sia definito in modo molto formale, possiamo solo descriverlo in modo molto generale come un contratto fra processo e dati su cui opera. Si pu√≤ dire che un processo √® consistente se fa quello che dovrebbe fare (quindi vago vago descrizione).\nContinuous consistency Questo √® un modello molto vecchio, caduto in disuso perch√© principalemente pone delle interfaccie di difficile implementazione, nel senso che √® difficile utilizzarle e definirle in casi di applicazione reale (credo un p√≤ come se stessi utilizzando i semafori).\nIl concetto principale √® di errore assoluto o relativo di inconsistenza (‚Üí quando l‚Äôinconsistenza supera una certa deviazione, allora si prova a rimediare e ristabilire la consistenza), che andiamo a chiamare il conit. A seconda di quanto conit abbiamo decidiamo o meno se propagare la consistenza. Si nota subito da qui che √® difficile dare un valore di inconsistenza e quindi andiamo a disuso.\nEsempi di caso d‚Äôuso sono i prezzi degli stock. Se variano di poco, non so 0.0001, allora non provo a renderlo consistente ancora (per quanto riguarda la lettura)\nPer maggiori informazioni consultare il capitolo 7 sulla consistenza continua.\nOrdered consistency (2) In questa parte trattiamo un idea presente gi√† da tempo negli studi di parallelismo e sistemi distribuiti. L‚Äôidea principale √® che cerchiamo di ordinare la sequenza di lettura e scrittura. Questo sar√† la cosa comune ai vari protocolli.\nSequential consistency Definito in Lamport 1979\nThe result of any execution is the same as if the (read and write) operations by all processes on the data store were executed in some sequential order and the operations of each individual process appear in this sequence in the order specified by its program\nIn questa definizione lo vediamo come ci sia il bozzolo dell‚Äôidea che il sistema distribuito sia una unica macchina un pochetto sparsa. Abbiamo che tutte le operazioni sono sequenziali, come se stessimo su una macchina! In particolare ci basta che siano in ordine non sappiamo per√≤ quale ordine sia.\nCausal consistency Questo √® un tipo speciale di sequential consistency, e l‚Äôidea principale si basa sul fatto che non ha senso dare un ordine a delle cose indipendenti fra di loro, per esempio se faccio solamente dei read, non ha senso che provi a dare un ordine di lettura, tanto le cose che leggo sono le stesse.\nQuindi avrebbe senso ordinare solo le read che hanno una write che la influenza quindi che sia in qualche modo causato o influenzato dalla write.\nEventual consistency TODO\nClient-centric consistency Questo √® un modello che abbiamo creato principalmente per i dispositivi mobili. Vogliamo garantire consistenza all‚Äôutente anche quando il server non potrebbe essere pienamente consistente. Il motivo di cambiare visuale e ora metterci dal punto di vista dell‚Äôutente √® che non possiamo predire lo spostamento di essa. E per esempio cambiare password in un punto. Spostarsi, e provare a loggare da un altro punto porta a un fallimento, questa non √® una buona cosa. La client centric consistency prova a risolvere questo problema\nEventual consistency\nOssia prima o poi il dato sar√† sincronizzato fra i dispositivi diversi (un giorno? due giorni? prima o poi lo fa!).\nPer molte cose questo ritardo non √® molto importante, per esempio i DNS.\nRead \u0026amp; write consistencies Monotonic-read consistency if a process reads the value of a data item x, any successive read operation on x by the process will always return that same value or a more recent value\nOssia, una volta letto una cosa al tempo t, non posso pi√π leggere cose al tempo \u0026lt; t.\nEsempio: email , non voglio rileggere una email che ho gi√† letto.\nMonotonic-write consistency a write operation by a process on a data item x is completed before any successive operation on x by the same process\nOssia se voglio scrivere cose al tempo t, devo aspettare che tutte le write prima di t finiscano per fare qualunque cosa dopo t.\nUpdate del software, devo andare a leggere o scrivere sulla versione pi√π recente.\nRead your writes the effect of a write operation by a process on data item x will always be seen by a successive read operation on x by the same process\nOssia prima scrivo poi leggo.\nEs: password update. (non voglio che una password vecchia sia ancora considerata come valida dopo un cambio).\nWrites follow reads a write operation by a process on data item x following a previous read operation on x by the same process is guaranteed to take place on the same or a more recent value of x that was read\nOssia quando modifico, lo faccio solo sull‚Äôultimo valore. (cio√® non posso scrivere su elementi vecchi (aka, non pu√≤ succedere che il mio messaggio arrivi prima del messaggio che ho letto, dopo che c‚Äô√® stato consistenza))\nReplication Questa √® una parte complicata.\nPosso replicare non solo i dati ma ANCHE i servizi. E qui sale il problema dell‚Äôidentit√†. Come gestire i servizi che fanno esattamente la stessa cosa?\n","permalink":"https://flecart.github.io/notes/replication-and-consistency/","summary":"\u003ch1 id=\"replication-and-consistency\"\u003eReplication and consistency\u003c/h1\u003e\n\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003cp\u003eCi sono due vantaggi principali nella replicazione dei dati\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eVelocit√†\u003c/strong\u003e\n\u003col\u003e\n\u003cli\u003eVicinanza geografica (quindi meno tempo ad andare a tornare)\u003c/li\u003e\n\u003cli\u003eMaggiore computazione, quindi avere molti pi√π processori che cercano di offrire lo stesso servizio.\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAffidabilit√†\u003c/strong\u003e\n\u003col\u003e\n\u003cli\u003eCos√¨ se una sede diventa corrotta, posso avere abbondanza, avere una copia da una altra parte, cos√¨ non perdo le informazioni!\u003c/li\u003e\n\u003cli\u003eSe una macchina cade in errore, ho altre macchine che lo sostituiscono! Quindi dal punto di vista dell‚Äôutente funziona ancora.\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eMa provare ad avere lo stesso dato in zone diverse porta a grandi problemi riguardo la \u003cstrong\u003econsistenza\u003c/strong\u003e! Come facciamo ad avere la garanzia che due cose diverse abbiano la stessa informazione?\u003c/p\u003e","title":"Replication and consistency"},{"content":"Introduzione sui requisiti del software Note introduttive In linguaggio naturale (dizionario) üü•+ Sono tutte le qualit√† necessarie per uno scopo ben determinato.\nSecondo il prof. I requisiti sono dei desideri ossia ci√≤ che idealmente vorresti riguardo qualcosa (nel nostro caso il software). Ma credo sia anche una tendenza italiana di fare le cose meglio possibile senza mai soddisfare tutto\nFunctional requirements üü© Sono ci√≤ che permetter√† di fare il sistema\nEsempio:\nIl sistema permetter√† di prenotare un taxi e di avere una stima del tempo di attesa\nNel nostro caso possiamo anche definire scenario ossia un caso di utilizzo concreto del sistema e user story come ci√≤ che il cliente vuole che il sistema debba fare.\nLegge di Humphrey üü®- I requisiti di un nuovo prodotto software non saranno chiari finch√© gli utenti non iniziano a usarlo\nOssia finch√© non ho una prima soluzione, non so bene cosa voglio -\u0026gt; \u0026ldquo;I\u0026rsquo;ll know it when I\u0026rsquo;ll see it\u0026rdquo;. In un certo senso questo giustifica anche la scelta di iniziare a costruire subito, perch√© prima non puoi sapere, quindi non puoi farne un design. Quando hai una prima versione, poi puoi iterarci.\nProcesso di analisi del requisito (3) üü®++ √à una analisi preliminare, ossia prima ancora di iniziare lo sviluppo e serve per:\nCapire ci√≤ che vuole il cliente (quindi le funzionalit√† che deve avere il sistema finale). Questo √® stabilito senza sapere come effettivamente viene implementato il sistema. Cosa deve soddisfare il sistema, quindi una propriet√† Test per verifica dei requisiti, quindi capire esattamente cosa testare, perch√© la propriet√† possa essere verificabile Vincoli per esempio di sistema operativo, o risorse (quindi giochi per esempio), oppure di tempo, per esempio in cose real time. (o ci√≤ che deve essere costruito, cose funzionali) Requisiti in livelli diversi üü®- Certe formulazioni di requisiti sono pi√π utili a certe parti d\u0026rsquo;azienda, dipende dal livello di astrazione che deve avere il requisito. vedere il triangolino in immagine: User Personae üü© Sono degli utenti ideali, che dovrebbero essere i nostri utenti. Esempio: Ci chiediamo cosa fa questo utente ideale? Quali sono i suoi obiettivi? Cosa fa di solito di abitudine?\nBacklog management Digital product management Passi per la creazione del prodotto digitale (3) üü®\u0026ndash; Ricerca di mercato: ci chiediamo quali sono i prodotti utili? Ideazione del prodotto: quali sono i target principali? Cosa deve essere il prodotto? Per chi √® buono il prodotto? Requisiti del prodotto piano dettagliato di tutti i requisiti ","permalink":"https://flecart.github.io/notes/requisiti-e-backlog-del-software/","summary":"\u003ch2 id=\"introduzione-sui-requisiti-del-software\"\u003eIntroduzione sui requisiti del software\u003c/h2\u003e\n\u003ch3 id=\"note-introduttive\"\u003eNote introduttive\u003c/h3\u003e\n\u003ch4 id=\"in-linguaggio-naturale-dizionario-\"\u003eIn linguaggio naturale (dizionario) üü•+\u003c/h4\u003e\n\u003cblockquote\u003e\n\u003cp\u003eSono tutte le \u003cstrong\u003equalit√† necessarie\u003c/strong\u003e per \u003cem\u003euno scopo ben determinato\u003c/em\u003e.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eSecondo il prof. I requisiti sono dei \u003cstrong\u003edesideri\u003c/strong\u003e ossia ci√≤ che idealmente vorresti riguardo qualcosa (nel nostro caso il software). Ma credo sia anche una tendenza italiana di fare le cose meglio possibile senza mai soddisfare tutto\u003c/p\u003e\n\u003ch4 id=\"functional-requirements-\"\u003eFunctional requirements üü©\u003c/h4\u003e\n\u003cp\u003eSono \u003cstrong\u003eci√≤ che permetter√† di fare il sistema\u003c/strong\u003e\u003c/p\u003e","title":"Requisiti e backlog del software"},{"content":"Abbiamo trattato i modelli classici in Convolutional NN. Con i vecchi files di notion\nIl Kernel I punti interessanti delle immagini sono solamente i punti di cambio solo che attualmente siamo in stato discreto, quindi ci √® difficile usare una derivata, si usano kernel del tipo: $\\left[ 1, 0, -1 \\right]$, che sar√† positivo se cresce verso sinistra, negativo se scende. feature map Sono delle mappe che rappresentano alcune informazioni interessanti della nostra immagine.\nPrincipi di base Nota sulla depth Come viene spiegato in (Cohen et al. 2016) shallow e deep sono equivalenti, ma c\u0026rsquo;√® una esplosione esponenziale sul numero di neuroni necessari\nCaratteristiche di convoluzionali Localit√†, Condivisione, Invarianza per traslazioni Localit√† perch√© ho una field of view, che √® la grandezza del kernel precedente, condivisione perch√© i pesi del kernel sono sempre gli stessi. Poi non ho capito perch√© il pooling fa invarianza per traslazioni.\nReferences [1] Cohen et al. ‚ÄúOn the Expressive Power of Deep Learning: A Tensor Analysis‚Äù 2016\n","permalink":"https://flecart.github.io/notes/reti-convoluzionali/","summary":"\u003cp\u003eAbbiamo trattato i modelli classici in \u003ca href=\"/notes/convolutional-nn/\"\u003eConvolutional NN\u003c/a\u003e. Con i vecchi files di notion\u003c/p\u003e\n\u003ch3 id=\"il-kernel\"\u003eIl Kernel\u003c/h3\u003e\n\u003cp\u003eI punti interessanti delle immagini sono solamente i \u003cstrong\u003epunti di cambio\u003c/strong\u003e solo che attualmente siamo in stato discreto, quindi ci √® difficile usare una derivata, si usano kernel del tipo:\n$\\left[ 1, 0, -1 \\right]$, che sar√† positivo se cresce verso sinistra, negativo se scende.\n\u003cimg src=\"/images/notes/Reti convoluzionali-1700037160855.jpeg\" alt=\"Reti convoluzionali-1700037160855\"\u003e\u003c/p\u003e\n\u003ch4 id=\"feature-map\"\u003efeature map\u003c/h4\u003e\n\u003cp\u003eSono delle mappe che rappresentano alcune informazioni interessanti della nostra immagine.\u003c/p\u003e","title":"Reti convoluzionali"},{"content":"Questi problemi sono una sottoclasse della programmazione lineare con variabili reali. (Alcuni riescono a riconoscere se un problema √® in questa forma, e lo risolvono in modo istantaneo se questo succede).\nUn problema dei router √® un classico problema di flusso, che si risolvono con questi algoritmi polinomiali\nNote introduttive Rete, terminologia In questo caso andiamo ad indicare con rete un grafo con $G = (N, A)$ con $N$ nodi e $A$ archi, che solitamente sono diretti con pesi associati. Possiamo interpretare gli archi come canali in cui fluiranno un qualcosa (ad esempio acqua in un tubo). Questi possono essere discreti o continui (mi sembra di ricordare che il discreto stranamente √® pi√π facile del continuo, non so se vale anche in questo caso). Abbiamo poi i nodi che sono punti di ingresso e uscita della nostra rete.\nAbbiamo studiato questo nel corso di algoritmi, nella lezione sui Grafi.\nSbilanciamento Sbilanciamento, mi da informazione riguardo se il nodo vuole ricevere o dare fuori, quindi il fatto che sia negativo positivo pu√≤ essere buona roba.\nNodi di input output e trasferimento Importante sapere cosa sono nodo di input, output e trasferimento e quando un nodo si pu√≤ chiare in questo modo.\nCapacit√† inferiore e superiore Oltre a ci√≤ possiamo definire capacit√† inferiore e superiore degli archi, e definire un concetto di ammissibilit√† di un trasferimento di un arco quando la quantit√† che ci passa rispetta queste condizioni.\nVincoli di un problema di flusso (3) üü®+ Domanda e offerta globale Conservazione del flusso sol nodo locale Ammissibilit√† del flusso Slide\nIl perch√© si utilizzano grafi √® perch√© sono espressivi per questo genere di problemi, ossia sono molto utili per modellizzare questo. E hanno una complessit√† gestibile perch√© sono stati molto studiati ed esistono algoritmi efficienti per questa(credo)\nNormalizzazione della capacit√† inferiore (3) üü©- Si tratta in questa parte di trasformare il problema in un altro problema con le capacit√† inferiori nulle, basta considerare questa cosa nel calcolo della funzione obiettivo e rimodulare i valori degli archi (per capacit√† superiore).\nLe 3 cose per normalizzare\nTogliere l a capacit√† superiore Aggiungere l a b (cos√¨ flusso si conserva Considerare il costo di questo flusso Cio√® semplifico mettendo quanto deve passare per la capacit√† inferiore come flusso proveniente dall\u0026rsquo;esterno!\nSlide\nModelizzazione del flusso di costo minimo (!!!) (3) üü®- Come si pu√≤ notare la condizione √® molto facile da scrivere.\nMinimizzare il costo $cx$, con x il vettore dei flussi, c il vettore dei costi Condizione di massimo flusso $\\forall i, 0\\leq x_i \\leq u_i$, con u il vettore dei massimi E tutte le condizioni di bilanciamento $Ex = b$ con E la matrice (probabilmente sparsa) che mi calcola l‚Äôincidenza (0, 1, -1 per dire esiste, entrata o uscita), che devono essere uguali a b. Condizione dei pozzi üü©\nSpesso √® molto buono idealizzare con un solo pozzo di entrata e un solo pozzo di uscita. Al fine di avere questo risultato si creano due pozzi aggiuntivi , uno che prende tutte le entrate e una che prende tutte le uscite\nSlide costruzione dei pozzi e sorgenti\nCondizione limiti di nodoüü®‚Äî\nPer modellizzare cose come i router, che sono s√¨ dei nodi, ma hanno dei limiti per trasmettere e ricevere creiamo un nodo fittizio che sia in grado di rappresentare questo genere di occazioni\nslide\nProblema del flusso massimo Caratteristiche flusso max (3) üü© Slide definizione del problema\nDa notare che questo problema pu√≤ essere visto come caso particolare di MCF in cui\nCosti sono nulli Sbilanciamenti sono nulli Presenza di arco fittizio con capacit√† infinita da target a source Tagli Definizione üü© Slide\nIn pratica √® una partizione dei nodi di una rete.\nUn s-t taglio√® un taglio in cui s e t stanno in partizioni differenti (dato che sono due le partizioni direi che stanno nelle due partizioni corrispondenti).\nAndiamo ora a caratterizzare gli archi.\nA+ attraversa da s a t\nA- attraversa da t a s.\nEsempio di Taglio\nI rossi sono A+, i verdi sono A-\nEsempio del prof pi√π contorto\nPropriet√† !! (2) üü© Enunciato:\n$$ \\forall (s-t)\\text{-taglio} \\, (N_{s}, N_{t}) \\text{ e ogni flusso ammissibile } x \\text{ con valore } v: $$$$ \\begin{cases} v = \\sum_{(i, j) \\in A^{+}(N_{s}, N_{t})} x_{ij} - \\sum_{(i, j) \\in A^{-} (N_{s}, N_{t})} x_{ij} \\\\ v \\leq \\sum_{(i, j) \\in A^{+}(N_{s}, N_{t})} u_{ij} \\end{cases} $$Ossia il flusso √® uguale a ci√≤ che attraversa il taglio, e tutto questo √® sempre minore alla capacit√† del taglio!\nDimostrazione\nPer 1 in pratica prende la differenza iniziale e riscrive i nodi di trasferimento (quindi input - output = 0) in altro modo per averlo nella forma che ci piace). Gli archi interni si cancellano fra di loro, gli archi esterni in Nt non vengono proprio contati, quindi possiamo andare a considerare solamente gli archi della frontiera quindi andiamo a finire in questo modo.\nDimo Slides\nFlusso e capacit√† del taglio üü© Le propriet√† dei tagli spiegati in precedenza sono dei punti fondamentali per l‚Äôanalisi di questo problema di flusso!.\nIl valore di un flusso ammissibile √® sempre minore o uguale della capacit√† di qualunque taglio.\nAndremo a cercare un caso in cui il flusso = capacit√†. In quanto trovato questo taglio, questo √® un flusso massimo! Per il lemma precedente non pu√≤ crescere ancora.\nFord Fulkerson Andremo in questa parte ad introdurre alcuni concetti molto utili che ci porteranno alla definizione dell‚Äôalgoritmo di Ford Fulkelson.\nGrafi residui üü© Utile per dirmi se possono ancora migliorare o meno in un arco.\nQuindi ci d√† un concetto di flusso rimanente per un arco (termine mio questo) utilizzato per decidere se possiamo utilizzarlo o meno per migliorare qualcosa.\nSlide\nCammini aumentanti üü© Chiachiamo in questo modo i cammini nel grafo dei residui. Lo chiamiamo in questo modo perch√© ci permette di avere pi√π flusso da s a t. In particolare lo utilizzo in questo modo\nSe √® un arco discorde diminuisco il valore del flusso. Se √® un arco concorde aumento il flusso. Il valore di aumento o diminuzione √® il minimo del residuo fra tutti gli archi, questa cosa la chiamiamo capacit√† del cammino aumentante.\nL‚Äôalgoritmo üü© L‚Äôalgoritmo si traduce nel\nSetta flusso iniziale a 0 Prendi un cammino aumentante a caso, se esiste aggiungi al flusso il valore di cui √® aumentato, altrimenti ritorna il flusso. Continua finch√© non esci. Slide\nCorrettezza üü® Per dimostrare la correttezza √® spesso molto bello trovare l‚Äôinvariante, in questo caso √® il seguente lemma\nSe x √® un flusso ammissibile, allora √® ammissibile anche il flusso modificato con una iterazione dell‚Äôalgoritmo. Se ho il flusso massimo, allora non posso trovare cammini aumentanti o flussi altri.\nSlide lemmi su flusso massimo e ammissibilit√†, con cammini aumentanti\nLemma fondamentale per correttezza, esistenza di taglio v\nNOTA: raggiungibili con un cammino aumentante!\nIntera dimostrazione insieme\nComplessit√† üü®+ Possiamo dire che ha fine solo se ha capacit√† intere, altrimenti potrebbe essere che non termini mai. Il prof dice che questo algo d√† troppa libert√† per cui la complessit√† non √® sotto controllo.\nTeorema e dimostrazione complessit√† casi interi\nMa questa √® una complessit√† pseudo-polinomiale nel senso che √® polinomiale solo se non si utilizza la compressione logaritmica nella rappresentazione degli interi (quindi polinomiale nel tempo, ma non nella rappresentazione in memoria).\nMa comunque il termine U ci √® abbastanza brutto.\nMax Flow Min Cut (!) üü© Se riusciamo a dimostrare che il massimo flusso √® ‚â• di un taglio allora mettendo insieme al lemma sul upper bound del massimo flusso ho finito.\nUtilizziamo il risultato nella dimostrazione di FF, assumendo che abbiamo un flusso massimo, quindi non ci sono cammini aumentanti, allora abbiamo un taglio di capacit√† v, per cui ho finito.\nEnunciato e dimo\nEdmonds Karp Introduzione üü© Questo algoritmo non √® altro che una implementazione di Ford_fulkerson. Quindi sappiamo gi√† che sia corretta. Utilizza una bfs per trovare il cammino aumentante migliore.\nUtilizzando la bfs, quindi scegliemo sempre il percorso pi√π corto questa √® una delle propriet√† di maggior rilievo per EK.\nLemma distanze di EK (non chiede dim) üü®‚Äî Questo √® un lemma che caratterizza fortemente EK, perch√© √® una conseguenza della sua ricerca in BFS che trova gli archi critici pi√π corti prima di quelli pi√π lunghi.\n√à anche fondamentale per fare il calcolo della complessit√† dell\u0026rsquo;algoritmo!\nEnunciato\nDimostrazione (non fatta in classe) preso dal cormen\nComplessit√† (!!) üü®+ Il lemma di sopra ci permette di togliere il termine sulla capacit√† degli archi. Il motivo √® che per il lemma precedente ogni arco pu√≤ essere considerato al pi√π |N| volte, con N il numero dei nodi. Quindi Applico BFS, per ogni arco, al pi√π N volte, costo $O(NM^2)$\nHint dimostrazione\nAndiamo a considerare gli archi che vengono saturati durante il percorso di un cammino aumentante (questo esiste sempre perch√© il cammino aumentante √® costruito sul minimo del percorso.\nVogliamo dire che ogni arco pu√≤ essere al massimo considerato critico N volte, per cui al massimo ho NA.\nDopo aver fatto questa osservazione, bisogna andare a fare un ragionamento sulla distanza, che continua a crescere per ogni iterazione, e lo pu√≤ fare per al massimo il numero di nodi, prima di diventare staccato.\nDimostrazione\nGoldberg-Tarjan Slide algoritmo\n!\n","permalink":"https://flecart.github.io/notes/reti-di-flusso/","summary":"\u003cp\u003eQuesti problemi sono una \u003cstrong\u003esottoclasse della programmazione lineare\u003c/strong\u003e con variabili reali. (Alcuni riescono a riconoscere se un problema √® in questa forma, e lo risolvono in modo istantaneo se questo succede).\u003c/p\u003e\n\u003cp\u003eUn problema dei router √® un classico problema di flusso, che si risolvono con questi algoritmi polinomiali\u003c/p\u003e\n\u003ch2 id=\"note-introduttive\"\u003eNote introduttive\u003c/h2\u003e\n\u003ch3 id=\"rete-terminologia\"\u003eRete, terminologia\u003c/h3\u003e\n\u003cp\u003eIn questo caso andiamo ad indicare con rete un grafo con $G = (N, A)$ con $N$ nodi e $A$ archi, che solitamente sono diretti con pesi associati.\nPossiamo interpretare gli archi come \u003cstrong\u003ecanali\u003c/strong\u003e in cui fluiranno un qualcosa (ad esempio acqua in un tubo). Questi possono essere discreti o continui (mi sembra di ricordare che il discreto stranamente √® pi√π facile del continuo, non  so se vale anche in questo caso).\nAbbiamo poi i \u003cem\u003enodi\u003c/em\u003e che sono \u003cstrong\u003epunti di ingresso e uscita\u003c/strong\u003e della nostra rete.\u003c/p\u003e","title":"Reti di flusso"},{"content":"These algorithms are good for scaling state spaces, but not actions spaces.\nThe Gradient Idea Recall Temporal difference learning and Q-Learning, two model free policy evaluation techniques explored in Tabular Reinforcement Learning.\nA simple parametrization üü© The idea here is to parametrize the value estimation function so that similar inputs gets similar values akin to Parametric Modeling estimation we have done in the other courses. In this manner, we don\u0026rsquo;t need to explicitly explore every single state in the state space.\nFor example, a single linear parametrization for the value function gives a quite nice interpretation of why we are introducing loss functions in this case:\n$$ V^{\\pi}(x; \\theta_{\\text{new}}) = r(x, \\pi(x)) + \\gamma \\sum_{x'}p(x'\\mid x, \\pi(x))V^{\\pi}(x^{'}; \\theta_{\\text{old}}) $$$$ \\forall x, \\theta_{new, x} = \\arg\\min_{\\theta_{x} \\in \\mathbb{R}} (\\theta_{x} - (r(x, \\pi(x)) + \\gamma \\sum_{x'}p(x'\\mid x, \\pi(x))V^{\\pi}(x^{'}; \\theta_{\\text{old}}))))^{2} $$ Which can be written for every single state: $$ \\theta_{new} = \\arg\\min_{\\theta \\in \\mathbb{R}^{n}} \\mathbb{E}_{x}(V^{\\pi}(x; \\theta)\n(r(x, \\pi(x)) + \\gamma \\sum_{x\u0026rsquo;}p(x\u0026rsquo;\\mid x, \\pi(x))V^{\\pi}(x^{\u0026rsquo;}; \\theta_{\\text{old}})))^{2} $$ Where $x$ is drawn from some distribution that has non zero mass for every state (so that it updates every state indefinitely). This simple motivation example opens the door for gradient descent methods for parameter estimation! The only drawback that we will see using these methods is the enormous number of samples that we need to get a good estimate of the value function.\nTD-Gradient View üü© $$ V^{\\pi}(x) = V_{\\text{old}}^{\\pi}(x) + \\alpha_{t}(r + \\gamma V^{\\pi}_{\\text{old}}(x^{(i)}) - V_{\\text{old}}^{\\pi}(x)) $$$$ l(\\theta; x, x') = -\\frac{1}{2}(r + \\gamma V^{\\pi}_{\\text{old}}(x^{'};\\theta) - V_{\\text{old}}^{\\pi}(x;\\theta))^{2} $$ Where the value is parameterized by theta. It\u0026rsquo;s derivative, is called the TD error, indicated with $\\delta(x)$. TODO: fix the mistake for the expectation of the estimate, also expand on the fact that the gradient is 1 for the linear case, so classic TD and Q-Learning are just doing gradient descent on the linear feature vector.\nOne nice thing about this view, is that the gradient with respect of this loss is unbiased, due to the law of large numbers, see Central Limit Theorem and Law of Large Numbers. Sometimes gradient descent with a bootstrap estimate is called stochastic semi-gradient descent.\nQ-Learning View üü© $$ Q^{\\pi}(x, a) = Q_{\\text{old}}^{\\pi}(x, a) + \\alpha_{t}(r + \\gamma \\max_{a} Q^{\\pi}_{\\text{old}}(x^{'}, a) - Q_{\\text{old}}^{\\pi}(x, a)) $$$$ l(\\theta; x, a, r, x') = -\\frac{1}{2}(r + \\gamma \\max_{a} Q^{\\pi}_{\\text{old}}(x^{'}, a;\\theta) - Q_{\\text{old}}^{\\pi}(x, a;\\theta))^{2} $$Deep Q-networks üü© DQN updates the neural network used for the approximate bootstrapping estimate infrequently to maintain a constant optimization target across multiple episodes.\nThe problem we are trying to solve is the moving optimization target property of the above q-learning optimization, which leads to instabilities (it\u0026rsquo;s somewhat similar to changing the array you are iterating in, which gives unpredictable results, sometimes, or more difficult to analyze or debug).\nWe assume to have a dataset $\\mathcal{D}$ called experience buffer. The idea here is use one network for the $old$ values, and the other used for the optimization objective. This idea is quite simple. This technique is known in the literature as Polyak averaging, or experience replay. here $\\theta_{old}$ is not update every step, but only after $D$ iterations, which attempts to give some stability to the optimization.\n$$ \\max_{a} q(x, a) \\approx \\max_{a} Q(x, a; \\theta_{\\text{old}}) $$ The problem with this technique is introducing the q-value estimation, this leads to a maximization bias: Double Q-learning üü© This leads to Double Q-Learning which leads to more accurate estimation of the real $q$ (Van Hasselt et al., 2016) Which is just taking the maximum with respect of the new network, and not the old. Also during gradient estimation, we are always selecting with the new network, not the old, we just use the old network to get the reward. (Meaning the $a$ inside the $Q(x, a; \\theta_{\\text{old}})$) is now taken from the new policy induced by the network parameterized with $\\theta$ that changes often.\n$$ \\mathcal{L}(\\theta) = \\frac{1}{2}\\mathbb{E}_{s, a, r, s'}\\left[ (r + \\gamma \\max_{a'}Q(s', a'; \\theta_{\\text{old}}) - Q(s, a; \\theta))^{2} \\right] $$$$ \\mathcal{L}(\\theta) = \\frac{1}{2}\\mathbb{E}_{s, a, r, s'}\\left[ (r + \\gamma Q(s', a^{*}; \\theta_{\\text{old}}) - Q(s, a; \\theta))^{2} \\right] $$It works quite well, but the reason why it works is not well explained mathematically. Intuitively, the old network is quite biased toward overly high values of $Q$. With Double Q-learning, we are shifting this bias towards a more accurate version, the current $Q_{\\theta}$, but still evaluating using the bootstrapped old estimate.\nPolicy Approximation $$ \\pi^{*}(x) = \\pi(x; \\varphi) $$ The methods that attempt to estimate this are called policy search or policy gradient methods.\nPolicy Parametrization examples $$ \\pi(a \\mid x, \\theta) \\sim \\mathcal{N}(a ; \\mu(x, \\theta), \\Sigma(x, \\theta)) $$$$ \\pi(a \\mid x, \\theta) = Cat(a; \\sigma(f(x, \\theta))) $$ We can also decompose this using the Markov property if $m$ is large.\nThe important thing we need is:\nBe able to use Backpropagation Easy to sample from, so that we can use Monte Carlo Methods. Function Gradient Methods The Objective üü©\u0026ndash; $$ J_{T}(\\theta) = \\mathbb{E}_{\\tau \\sim \\Pi_{\\theta}}[G_{0}] \\approx \\frac{1}{N}\\sum_{i=1}^{N}G_{0}^{(i)} $$ Taking trajectories following the current policy.\nScore Trick üü© We have encountered the score function before in Parametric Modeling when estimating the Rao-Cramer Bound. In this context, the score is defined as follows:\n$$ \\nabla_{\\varphi} \\log \\Pi_{\\varphi} = \\frac{\\nabla_{\\varphi}\\Pi_{\\varphi}}{\\Pi\\varphi} $$We will use it here to get an unbiased estimate of the gradient of the policy, so that we can use Backpropagation to estimate the gradient of the policy.\n$$ \\nabla_{\\varphi}\\mathbb{E}_{\\tau \\sim \\prod_{\\varphi}}[G_{0}] = \\mathbb{E}_{\\tau \\sim \\prod_{\\varphi}}\\left[ G_{0}\\nabla_{\\varphi}\\log \\Pi_{\\varphi}(x) \\right] $$ Then we can use this estimate for the update of the gradient. Then you can also prove that in the context of the optimization of $\\varphi$ we can write the score as $$ \\begin{align} \\nabla_{\\varphi}\\log \\Pi_{\\varphi}(x) \u0026amp;= \\nabla_{\\varphi} \\left[ \\log p(x_{0}) + \\sum_{t = 0}^{T - 1} \\log \\pi(a_{t} \\mid x_{t}) + \\sum_{t = 0}^{T - 1} \\log p(x_{t + 1} \\mid x_{t}, a_{t}) \\right] \\ \u0026amp;=\\sum_{t = 0}^{T - 1}\\nabla {\\varphi}\\log \\pi(a{t}\\mid x_{t})\n$$ The latter is often called the *eligibility vector*. A common parametrization akin to [Log Linear Models](/notes/log-linear-models) is the following: $$ \\pi_{\\varphi}(a \\mid x) = \\frac{\\exp(h(x, a, \\varphi))}{\\sum_{a\u0026rsquo; \\in A} \\exp(h(x, a\u0026rsquo;, \\varphi))} $$\nAnd $h(x, a, \\varphi) = \\varphi^{T}\\phi(x, a)$ given some feature vector.\n$$ \\nabla_{\\varphi}J_{T}(\\theta) \\approx \\frac{1}{m} \\sum_{i = 1}^{m}g^{(i)}_{0:T} \\sum_{t = 0}^{T - 1}\\nabla _{\\varphi}\\log \\pi(a_{t}\\mid x_{t}) $$But this estimate has usually high variance.\nAdding Baselines üü©\u0026ndash; $$ \\mathbb{E}_{\\tau \\sim \\prod_{\\varphi}}\\left[ (G_{0} - b)\\nabla_{\\varphi}\\log \\Pi_{\\varphi}(x) \\right] $$ Adding this constant still keeps the expectation unvaried, as the derivative of the score is 0, so it doesn\u0026rsquo;t affect the estimate, but it affects the variance by reducing it if we choose $b$ correctly, which helps in the stability of the estimate.\n$$ b_{0:t - 1} = \\sum_{i = 0}^{t - 1}\\gamma^{i}r_{i} $$$$ \\nabla_{\\varphi}J(\\theta) \\approx \\mathbb{E}_{\\tau \\sim \\Pi} \\left[ \\sum_{t = 0}^{T - 1} \\gamma^{t}G_{t:T} \\nabla_{\\varphi} \\log \\pi_{\\varphi}(a_{t }\\mid x _{t}) \\right] $$ Which should be better in terms of its variance.\nBaselines reduce variance üü®+ The condition we need to satisfy is $b^{2} \\leq 2 b \\cdot r(x, a)$ for each state and action. (The proof is along variance and covariance of the two functions).\n$$ \\mathop{\\mathbb{E}}[f(x)]= \\mathop{\\mathbb{E}}[f(x) - b] + \\mathop{\\mathbb{E}}[b] = \\mathop{\\mathbb{E}}[f(x) - b] $$ Furthermore, under certain conditions we have that:\nRecall that $\\text{Var[X + Y]} = \\text{Var[X]} + \\text{Var[Y]} + 2\\text{Cov[X, Y]}$.\n$$ \\text{Var}[f(x) - b] = \\text{Var}[f(x)] + \\text{Var}[b] - 2\\text{Cov}[f(x), b] $$Which means that if $\\text{Var}[b] \\leq 2\\text{Cov}[f(x), b]$ then the variance of the function will be reduced.\nIn the case of the baseline, the variance of $b$ is exactly $\\mathop{\\mathbb{E}}[b^{2}(\\nabla \\log \\pi(a \\mid x)^{2}]$ One can prove that given a sample trajectory, the above state dependent baseline is a valid baseline.\nREINFORCE üü© The Reinforce algorithm allows optimization for the policy in continuous spaces but does not guarantee the convergence to the best policy possible.\nOne can also add the baseline as before, and it should reduce the variance, under certain cases. (for the classical state dependent baseline is easy to see that it indeed does it).\nA common technique is to further reduce the variance, and only consider step-1 updates. This is somewhat akin to Stochastic Gradient Descent on policy. One can also subtract the baseline from t onwards.\nDrawbacks of REINFORCE üü®\u0026ndash; These methods are On-policy because we need to simulate many many roll-outs High variance in the gradient estimates The last point implied slow convergence of the method (related to the sample efficiency) Not guaranteed convergence Another drawback is the difficulty of handling the exploration-exploitation tradeoff. These algorithms, along with the AC methods in the next section, are fundamentally exploitative. We usually employ random exploration or epsilon-greedy methods to explore, but usually these still might converge without actually having explored the state space enough.\nPolicy Gradient Method üü© Given a trajectory ($\\tau_{t: \\infty} = (x_{t}, a_{t}, r_{t}, x_{t + 1}, \\ldots)$) we can write the policy gradient as: $$ \\begin{align} \\nabla_{\\varphi} J_{T}(\\varphi) \u0026amp;= \\sum_{t = 0}^{\\infty}\\mathbb{E}{t: \\infty \\sim \\Pi{\\varphi}}\\left[ \\gamma^{t} G_{t} \\nabla_{\\varphi}\\log \\pi(a_{t}\\mid x_{t})\\right] \\ \u0026amp;= \\sum_{t = 0}^{\\infty} \\mathbb{E}{x{t}, a_{t}} \\left[ \\gamma^{t}Q^{\\pi}(x_{t}, a_{t})\\nabla_{\\varphi}\\log \\pi(a_{t}\\mid x_{t}) \\right]\n\\end{align} $$ Assuming we are using a baseline that starts from the $t$ time step.\nOften, the above policy gradient we derived for the REINFORCE algorithm is written in terms of discounted rate occupancy measure.\n$$ d_{\\pi}(x) = (1-\\gamma)\\sum_{t = 0}^{\\infty}\\gamma^{t}p(x_{t} = x) $$ The $1 - \\gamma$ factor is a normalization constant.\n$$ \\nabla_{\\varphi}J_{T}(\\varphi) = \\frac{1}{(1 - \\gamma)} \\cdot \\mathbb{E}_{x\\sim d_{\\pi}}\\left[ \\mathbb{E}_{a\\sim \\pi(\\cdot \\mid x)}[Q^{\\pi}(x, a)\\nabla_{\\varphi}\\log \\pi(a\\mid x)] \\right] $$ This form is known as the policy gradient theorem, it will be useful to characterize the actor critic methods.\nWe will see that for offline methods, explored in #Offline Actor Critic, we wont need the $\\log \\pi$ part, as we cannot actively explore the next state from the current state.\nPolicy Gradient and The Exponential Family üü® If the policy is characterized by a distribution in the exponential family, it is easy to derive a closed form solution for the policy gradient as above. In this section we briefly discuss some gradients that are part of this family. See The Exponential Family for a discussion on distributions of this family.\n$$ \\pi(a \\mid x ) = h(a) \\exp(a f_{\\varphi}(x) - A(f_\\varphi(x))) $$And written in this manner the un-baselined policy gradient is:\n$$ \\begin{align} \\nabla_{\\varphi}J_{T}(\\varphi) \u0026= \\mathbb{E}_{x\\sim d_{\\pi}}\\left[ \\mathbb{E}_{a\\sim \\pi(\\cdot \\mid x)}[Q^{\\pi}(x, a)\\nabla_{\\varphi}\\log \\pi(a\\mid x)] \\right] \\\\ \u0026= \\mathbb{E}_{x\\sim d_{\\pi}}\\left[ \\mathbb{E}_{a\\sim \\pi(\\cdot \\mid x)}[Q^{\\pi}(x, a)\\nabla_{\\varphi}(a f_{\\varphi}(x) - A(f_\\varphi(x)))] \\right] \\\\ \u0026= \\mathbb{E}_{x\\sim d_{\\pi}}\\left[ \\mathbb{E}_{a\\sim \\pi(\\cdot \\mid x)}[Q^{\\pi}(x, a)(f_{\\varphi}(x) - \\nabla_{\\varphi}A(f_\\varphi(x))\\nabla_{\\varphi}f_{\\varphi}(x))] \\right] \\\\ \\end{align} $$We just need to plug the correct values of the exponential family in.\nActor Critic Methods Actor critic methods describe a different family of approaches that explicitly attempt to jointly improve an approximator network for the value, called critic, and a network for the policy, called actor. These methods are, as usual, divided into online and offline actor critic methods. We will analyze and present a few different methods and their properties.\nOnline Actor Critic With online methods, we\nA first algorithm üü© The main idea here is to use an approximated $Q-$value to get an approximate policy update. The main drawback is that we are doing an approximation of an approximation, so the variance of this method should be quite high. From other point of view, this is somewhat similar to the SARSA update explained in Tabular Reinforcement Learning Usually the updates here are bootstrapped too!\nThe notion of Advantage üü© This will be the base for the so called A2C algorithm, where we use the notion of Advantage to bound the variance, in a manner similar to what we have done with the baselines.\n$$ A^{\\pi}(x, a) = Q^{\\pi}(x, a) - V^{\\pi}(x) $$$$ \\forall \\pi, x \\max_{a} A^{\\pi}(x, a) \\geq 0 $$ This is easy to see for deterministic policies, if we choose an $a$ following the policy, then it is 0, but if it could be improved then it has positive value.\nAdvantage Actor Critic üü© This method is very similar to the original Actor Critic method: instead of using the $Q$ estimate to update the critic we use the advantage This can be view as the standard Policy Gradient method with some special baseline.\n$$ \\varphi = \\varphi + \\alpha_{\\varphi}\\nabla_{\\varphi}\\log \\pi(a_{t}\\mid x_{t})A^{\\pi}(x_{t}, a_{t}) $$ Which is similar to the above actor-critic model, but with lesser variance if we choose the baseline equivalent correctly.\nRecall that $V(x) = \\mathop{\\mathbb{E}}_{a \\sim \\pi(x)} Q(x, a)$, so this is the baseline that has been chosen for this kind of Actor-Critic network. This is probably difficult to compute, and probably not stable to estimate using MonteCarlo Networks.\nOne thing that is usually done, is adding the parametrized value network $V(x ; \\theta)$ and use that one.\nTrusted Region Policy Optimization üü©\u0026ndash; This method is a variant of the above method, but it introduces a constraint on the policy update, so that we don\u0026rsquo;t update the policy too much, which can lead to instability in the optimization. For a similar reason, we use a fixed critic for multiple iterations.\n$$ \\varphi_{t + 1} = \\arg\\max_{\\varphi} J(\\varphi) \\text{ s.t. } KL(\\pi_{\\varphi_{t}} \\parallel \\pi_{\\varphi}) \\leq \\delta $$$$ J(\\varphi) = \\mathbb{E}_{x, a\\sim \\pi_{\\varphi_{t}}}\\left[ \\frac{\\pi_{\\varphi}(a\\mid x)}{\\pi_{\\varphi_{t}}(a\\mid x)}A^{\\pi_{\\varphi_{t}}}(x, a) \\right] $$One nice thing about TRPO is that it is possible to use this algorithm in an offline fashion as long as the policy can still be trusted (i.e. it satisfies the delta constraint).\nProximal Policy Optimization üü©\u0026ndash; This method is a variant of the above method, but instead of using the KL divergence, we use a penalty term in the loss function to keep the policy update close to the old policy. This algorithm has also had great influence during training of language models.\n$$ \\varphi_{t + 1} = \\arg\\max_{\\varphi} J(\\varphi) - \\beta \\cdot KL(\\pi_{\\varphi_{t}} \\parallel \\pi_{\\varphi}) $$ With $\\beta \u003e 0$. Other variants might work on the importance sampling.\nOffline Actor Critic One clear advantage of offline learning algorithms is the possibility of re-using past data.\nThe Main Idea üü®++ $$ \\mathcal{L}(\\theta) = \\mathbb{E}_{s, a, r, s'}\\left[ (r + \\gamma \\max_{a'}Q(s', a'; \\theta_{\\text{old}}) - Q(s, a; \\theta))^{2} \\right] $$ The main problem with the standard setting is having to maximize over the set of actions, which could be very large, or even continuous.\n$$ \\mathcal{L}(\\theta) = \\mathbb{E}_{s, a, r, s'}\\left[ (r + \\gamma Q(s', \\pi_{\\varphi}(s'); \\theta_{\\text{old}}) - Q(s, a; \\theta))^{2} \\right] $$ Where $\\pi_{\\varphi}$ is the policy network. If the policy is good enough, by Bellman Optimality condition (see Markov Processes), it will naturally converge to the maximum of the $Q$ function, one problem could be the instability of this double optimization, as we are optimizing for $Q$ and $\\pi$ at the same time.\n$$ \\varphi_{t + 1} = \\arg\\max_{\\varphi} \\mathbb{E}_{s, a\\sim \\pi_{\\varphi_{t}}}\\left[ Q(s, a; \\theta_{t}) \\right] = \\arg\\max_{\\varphi} J(\\varphi) $$$$ \\nabla_{\\varphi}J(\\varphi) = \\mathbb{E}_{s \\sim \\mu}\\left[ Q(s, \\pi_{\\varphi}(s); \\theta_{t}) \\right] $$$$ \\nabla_{\\varphi}Q(s, a; \\theta) = D\\varphi \\pi_{\\varphi}(s) \\cdot \\nabla_{a}Q(s, a; \\theta) \\mid_{a = \\pi_{\\varphi}(s)} $$Note that here we are not considering the $\\log \\pi(a \\mid x)$ to compute the gradient for the policy. My personal take is just that we don\u0026rsquo;t know how to compute this value (we don\u0026rsquo;t have a forward step to compute it), so we just ignore it. Here we can see a discussion on the use of $\\log \\pi(a \\mid x)$.\nDeep Deterministic Policy Gradient üü®++ Putting everything together from the section before we get the DDPG algorithm: It is possible to extend this algorithm with TD3, which is a variant of the above algorithm that uses a double critic to estimate the Q-value, which helps in reducing the overestimation bias.\nOn Exploration With the offline methods we have just presented, the usual solution for exploration is what is called Gaussian Noise Dithering: this method just adds some noise to the output of the policy $\\pi_{\\varphi}$ in continuous settings. However, these methods often suffer from not exploring enough. The following section presents a method that attempts to ease this problem. Some methods of exploration as are also cited in Planning.\nMaximum Entropy Reinforcement Learning üü® $$ J(\\varphi) = \\mathbb{E}_{s, a\\sim \\pi_{\\varphi}}\\left[ Q(s, a; \\theta) + \\alpha \\mathcal{H}(\\pi_{\\varphi}(\\cdot \\mid s)) \\right] $$ Where the parameter $\\alpha$ is a hyper-parameter that controls how much the entropy of the policy weights.\nTrust Region Policy Optimization (TRPO) To address the instability of optimizing both $Q$ and $\\pi$ simultaneously, Trust Region Policy Optimization (TRPO) introduces a constrained optimization framework. The primary idea behind TRPO is to update the policy in such a way that it stays within a trust region, ensuring that each update does not deviate excessively from the current policy. This prevents performance degradation due to overly large updates.\nObjective Function: TRPO optimizes the following constrained objective:\n$$ \\max_{\\varphi} \\mathbb{E}_{s \\sim \\mu, a \\sim \\pi_{\\varphi_t}}\\left[ \\frac{\\pi_{\\varphi}(a \\mid s)}{\\pi_{\\varphi_t}(a \\mid s)} A_{\\pi_{\\varphi_t}}(s, a) \\right] $$subject to:\n$$ \\mathbb{E}_{s \\sim \\mu}\\left[ D_{\\text{KL}}(\\pi_{\\varphi_t}(\\cdot \\mid s) \\parallel \\pi_{\\varphi}(\\cdot \\mid s)) \\right] \\leq \\delta, $$where $A_{\\pi_{\\varphi_t}}(s, a)$ is the advantage function, $D_{\\text{KL}}$ is the Kullback-Leibler divergence, and $\\delta$ is a small positive constant controlling the size of the update.\nProximal Policy Optimization (PPO) Proximal Policy Optimization (PPO) simplifies TRPO by avoiding the computational complexity of solving a constrained optimization problem. PPO achieves similar benefits by clipping the policy update directly within the objective function.\nObjective Function PPO modifies the policy update by introducing a clipped surrogate objective:\n$$ \\mathcal{L}^{\\text{PPO}}(\\varphi) = \\mathbb{E}_{s, a}\\left[ \\min\\left( r_t(\\varphi) A_{\\pi_{\\varphi_t}}(s, a), \\text{clip}(r_t(\\varphi), 1 - \\epsilon, 1 + \\epsilon) A_{\\pi_{\\varphi_t}}(s, a) \\right) \\right], $$where:\n$$ r_t(\\varphi) = \\frac{\\pi_{\\varphi}(a \\mid s)}{\\pi_{\\varphi_t}(a \\mid s)}, $$and $\\epsilon$ is a small hyperparameter (e.g., $\\epsilon = 0.2$) controlling the extent of clipping.\nAlgorithm Advantages Challenges TRPO Stable updates, trust region enforcement Computationally expensive, complex PPO Simplicity, robust performance Sensitive to hyperparameters ($\\epsilon$) ","permalink":"https://flecart.github.io/notes/rl-function-approximation/","summary":"\u003cp\u003eThese algorithms are good for scaling state spaces, but not actions spaces.\u003c/p\u003e\n\u003ch3 id=\"the-gradient-idea\"\u003eThe Gradient Idea\u003c/h3\u003e\n\u003cp\u003eRecall Temporal difference learning and Q-Learning, two model free policy evaluation techniques explored in \u003ca href=\"/notes/tabular-reinforcement-learning/\"\u003eTabular Reinforcement Learning\u003c/a\u003e.\u003c/p\u003e\n\u003ch4 id=\"a-simple-parametrization-\"\u003eA simple parametrization üü©\u003c/h4\u003e\n\u003cp\u003eThe idea here is to parametrize the value estimation function so that \u003cem\u003esimilar inputs\u003c/em\u003e gets \u003cem\u003esimilar values\u003c/em\u003e akin to \u003ca href=\"/notes/parametric-modeling/\"\u003eParametric Modeling\u003c/a\u003e estimation we have done in the other courses. In this manner, we don\u0026rsquo;t need to explicitly explore every single state in the state space.\u003c/p\u003e","title":"RL Function Approximation"},{"content":"La cosa che rende il PO diverso rispetto agli sviluppatori √® la conoscenza delle necessit√† del cliente. Questo permette di prioritizzare del task e capire in che modo dovrebbe essere il prodotto finale. In questo modo si crea una vision del prodotto. Pensiamo che il PO debba condividere questa informazione e prendere decisioni di gruppo.\nDomande da fare: La user interface, come sembra il wireframe? Pensavamo di utilizzare i social solamente per i login, pensavate di utilizzare anche per altro durante il gioco? Bassa priorit√† (poter condividere i risultati con un post). Vorreste poter selezionare il livello del bot? Quanto sarebbe il massimo livello e quale il minimo? 4. Per kriegspiel la forza √® massima. Cosa √® la modalit√† \u0026lsquo;mob\u0026rsquo; per giocare (2 descrizione del problema documento progetto). si intende il social che permette di condividere mosse. tutte le persone interessante possono rispondere con tempo un giorno, e la maggioranza determina la risposta. Bassa priorit√†. Esistono i soci (utenti registrati) e non, cosa pu√≤ fare un utente non registrato? E quelli registrati? O definiamo noi? Che genere di commenti deve fare l\u0026rsquo;AI durante la partita? Va bene qualunque commento (anche in giro), commenti interessanti sul contesto). In che modo salvare una partita? Solamente la sequenza delle mosse o possibilit√† di riprendere la partita? Non √® richiesto poter salvare e riprendere nei giochi a informazione incompleta La seconda cosa interessante per l\u0026rsquo;utente? Leaderboard (non per noi, ELO). Cosa deve avere la leaderboard per giochi diversi da bad chess? Legato all\u0026rsquo;ELO questa, il classico. O mobile o web o come ci pare (non √® importante). No sicurezza, non √® importante. 50 giocatori max.\n","permalink":"https://flecart.github.io/notes/scelta-del-po/","summary":"\u003cp\u003eLa cosa che rende il PO diverso rispetto agli sviluppatori √® la \u003cstrong\u003econoscenza\u003c/strong\u003e delle necessit√† del cliente. Questo permette di prioritizzare del task e capire in che modo dovrebbe essere il prodotto finale. In questo modo si crea una \u003cstrong\u003evision\u003c/strong\u003e del prodotto.\nPensiamo che il PO debba condividere questa informazione e prendere decisioni di gruppo.\u003c/p\u003e\n\u003ch4 id=\"domande-da-fare\"\u003eDomande da fare:\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003eLa user interface, come sembra il wireframe?\u003c/li\u003e\n\u003cli\u003ePensavamo di utilizzare i social solamente per i login, pensavate di utilizzare anche per altro durante il gioco?\n\u003col\u003e\n\u003cli\u003eBassa priorit√† (poter condividere i risultati con un post).\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eVorreste poter selezionare il livello del bot? Quanto sarebbe il massimo livello e quale il minimo?\n4. Per kriegspiel la forza √® massima.\u003c/li\u003e\n\u003cli\u003eCosa √® la modalit√† \u0026lsquo;mob\u0026rsquo; per giocare (2 descrizione del problema documento progetto).\n\u003col\u003e\n\u003cli\u003esi intende il social che permette di condividere mosse.\u003c/li\u003e\n\u003cli\u003etutte le persone interessante possono rispondere con tempo un giorno, e la maggioranza determina la risposta.\u003c/li\u003e\n\u003cli\u003eBassa priorit√†.\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eEsistono i soci (utenti registrati) e non, cosa pu√≤ fare un utente non registrato? E quelli registrati? O definiamo noi?\u003c/li\u003e\n\u003cli\u003eChe genere di commenti deve fare l\u0026rsquo;AI durante la partita?\n\u003col\u003e\n\u003cli\u003eVa bene qualunque commento (anche in giro), commenti interessanti sul contesto).\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eIn che modo salvare una partita? Solamente la sequenza delle mosse o possibilit√† di riprendere la partita?\n\u003col\u003e\n\u003cli\u003eNon √® richiesto poter salvare e riprendere nei giochi a informazione incompleta\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eLa seconda cosa interessante per l\u0026rsquo;utente?\n\u003col\u003e\n\u003cli\u003eLeaderboard (non per noi, ELO).\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eCosa deve avere la leaderboard per giochi diversi da bad chess?\n\u003col\u003e\n\u003cli\u003eLegato all\u0026rsquo;ELO questa, il classico.\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eO mobile o web o come ci pare (non √® importante).\nNo sicurezza, non √® importante.\n50 giocatori max.\u003c/p\u003e","title":"Scelta del PO"},{"content":"Il suo scopo principale √® gestire l\u0026rsquo;avvicendamento dei processi. Ad esempio sospendere il processo che chiede I/O. O un sistema time sharing, quando arriva un interrupt sul time.\nSolitamente il nome scheduler √® solamente un gestore dell\u0026rsquo;avvicendamento, si pu√≤ quindi utilizzare per indicare scheduler di altro tipo.\nNote introduttive Diagramma di Gantt Questo √® il diagramma per presentare lo scheduling, ossia da quando a quando √® eseguito cosa\nEsempio gantt\nMode switch (link) üü© il mode switch √® il passaggio fra user e kernel e viceversa, di cui abbiamo parlato in Note sull‚Äôarchitettura. si continua con lo stesso processo con permessi maggiori.\nContext switch (4) üü© Context switch invece si passa da un processo all‚Äôaltro, e bisogna salvare lo stato del vecchio processo nel PCB, come descritto in Processi e thread.\nEsempio context switch\nServe un mode switch, fanno cose, un altro mode switch, e stessa sequenza per tornare indietro, sono 2 context swithc qui\nCause del context switch\nSlide descrizione delle cause\nNota che per certe cause √® necessario fare un context switch in altri casi no.\nVita di un processo üü© Si parla di tutti i passaggi fra int\nSistema attesa e interrupt\nPraticamente il processo continua a runnare finch√© non lo fermano, con una syscall, con un interrupt di time slice oppure quando fa una syscall bloccante.\nQuando √® pronto a riprendere viene rimessa nella coda ready, e questa sar√† la coda gestita dallo scheduler.\nCatalogazione scheduler Preemptive e non-preemptive üü© Slide descrizione preempty non preemptive\nNon-preemptive √® quando cambio processo solamente se cedo io, processo, il controllo.\nMentre preemptive √® quando posso cambiare in ogni singolo caso.\nVantaggi dello scheduling cooperativo non richiede alcuni meccanismi hardware come ad esempio timer programmabili Potevi monopolizzare la CPU se programmavi male. Vantaggi dello scheduling preemptive permette di utilizzare al meglio le risorse per questo motivo gli scheduler sono sempre preemptive ora. Le risorse considerate (2) üü© Vogliamo ora trovare un modo per decidere in che modo decidere quale processo far partire e quale no.\nSlide scelta dello scheduler\nSistemi batch\nUtilizzo della risorsa CPU, vorremmo che la CPU stia sempre a lavorare. Massimizzare il numero di processi completati, ossia massimizzare il throughput, se ci mette poco lo faccio. Turnaround time, ossia minimizzare il tempo di risposta, da quando il processo √® sottomesso (issued) a quando √® completato Sistemi interattivi\nTempo di attesa deve essere minimizzato (il tempo di attesa nella ready queue) Tempo di risposta deve essere minimizzato (vorrei avere feedback molto veloce), almeno non percepibile dall‚Äôumano. When a request that is perceived as complex takes a long time, users accept that, but when a request that is perceived as simple takes a long time, users get irritated.\nSistemi real-time\nIl fatto che un processo venga runnato prima di un certo tempo (altrimenti si perdono un p√≤ di dati)\nLibro sui metodi di valutazione dello scheduler\n√à importante questa parte perch√© sulle slides vengono valutati solamente turnaround e throughput!\nNOTA: il tempo di utilizzo della CPU √® l√¨ riportata ma non √® una buona misura!\nAlgoritmi di scheduling (!!) FIFO: First come first served üü© Questo √® l\u0026rsquo;algoritmo pi√π banale, cio√® appena arriva un processo. √à una cosa molto semplice da implementare.\nSolitamente non √® molto veloce, buono per microcontrollori o comunque ambienti molto semplici. Per esempio se ho qualcosa che √® CPU bound ritarda un sacco tutti quei processi IO bound\nEsempio di processo lento\nAltro esempio con convoy effect\nQuando ho il convoy effect, ho continuamente il process dispendioso che fa ritardare tutti, e ci sono intere zone vuote.\nProcessi CPU bound piccoli vanno dopo CPU bound larghi, √® una cosa probabilistica, questo motiva la scelta di fare i lavori corti prima.\nShortest Job first üü©‚Äî Slide shortest Job first\nSi pu√≤ notare che il tempo di turnaround e il tempo di attesa scendono di molto! ma come sapere quanto tempo ci metteranno ad eseguire? Non si pu√≤ sapere a priori.\nSi pu√≤ anche dimostrare che √® la miglior soluzione possibile, per√≤ non √® possibile capire il cpu burst, posso solamente fare delle approssimazioni, che non sono per forza vere, non √® possibile implementarle\nMEDIA ESPONENZIALE\nQuesto √® la media che si utilizza per approssimare, √® la stessa media per le previsioni meteorologiche, che tengono conto del tempo.\nSlide media esponenziale\nVERSIONE PREEMPTIVE\nPraticamente √® un shortest remaining time first, che a seconda della predizione, si mette ad eseguire quello col tempo rimanente pi√π piccolo. (nota potrebbe essere negativa la previsione).\nPer la versioen non-preemptive si lascia\nRound robin üü© Slide round robin\nQuesta √® una soluzione pensata per sistemi interattivi, e a seconda del numero di questi processi, √® possibile definire il quanto di tempo, ossia il massima durata in cui pu√≤ rimanere in esecuzione, poi deve essere switchata.\nDeve essere abbastanza corto che il tempo non sia percepibile umanamente, in questo senso sono interattivi.\nQuando √® in coda si mette in FIFO.\nNon conviene mettere il quanto di tempo troppo piccolo perch√© si perderebbe troppo per switchare\nIMPLEMENTAZIONE\nC\u0026rsquo;√® bisogno di un timer che genera interrupt ogni tot tempo, questo √® il quanto di tempo per il round robin. Questa √® proprio una cosa necessaria. per implementarlo.\nQuesto interrupt √® settato! Nel senso ogni tot tempo da quando lo ho fatto partire.\nEsempio\nScheduling a priorit√† üü© In questa parte i concetti importanti sono:\nDifferenza priorit√† statica e dinamica I metodi per assegnare la priorit√† Aging (si implementa in un modo simile ai bit history visti in Paginazione e segmentazione Il sistema classi di priorit√† √à necessario un concetto di priorit√†, ad esempio se faccio video, non vorrei che sia rallentato da un servizio di posta, il primo ha bisogno di maggiore interattivit√†, quindi avrei bisogno questo concetto di priorit√†.\nLa priorit√† pu√≤ essere statica (che potrebbe fare starvation) o dinamica, per la dinamica si utilizza la tecnica di aging, in cui un processo ha una priorit√† naturale, che continua ad essere aumentato man mano resta nella coda di priorit√†.\nstatica si better for sistemi realtime per raggiungere.\nPossiamo anche fare classi di priorit√† diverse e scelta la classe si pu√≤ utilizzare la politica .\nQuesta politica √® molto simile a quello utilizzato nei router in Data Plane.\nServer Interattivi Processi utente FIFO demoni e vuoti FIFO banali Slide priorit√† (TODO: approfondire)\nEsempio: https://www.geeksforgeeks.org/multilevel-queue-mlq-cpu-scheduling/\nSISTEMI A REALTIME (non fare) Ci sono certe cose aperiodiche e periodiche. Periodico come reattori nucleari che devono stare a guardare sempre qualcosa (come cose per i reattori nucleari).\nPer periodici come rate monotonic (praticamente a priorit√†, quelli a frequenza alta sono di alta priorit√†) o earliest deadline first.\nSpiegazione di chatGPT\nRate Monotonic Scheduling (RMS): Rate Monotonic Scheduling is a widely used real-time scheduling algorithm. The RMS algorithm is based on priority assignment to periodic tasks, where the task with the shortest period has the highest priority. The scheduling of tasks is done in a way that the higher-priority task always preempt the lower-priority task.\nThe RMS algorithm assumes that the execution time of all tasks is known in advance and that there are no other sources of delay, such as I/O or interrupts. This is known as the \u0026ldquo;static scheduling\u0026rdquo; assumption.\nEarliest Deadline First Scheduling (EDF): Earliest Deadline First (EDF) is another real-time scheduling algorithm. In EDF, each task has a deadline, and the task with the earliest deadline is scheduled first. The deadlines can be either hard (absolute) or soft (flexible). Hard deadlines must be met, while soft deadlines can be missed, but a penalty is incurred for each missed deadline.\nLike RMS, EDF is based on the assumption of static scheduling, which means that the execution time of tasks is known in advance and there are no other sources of delay. EDF can also handle aperiodic tasks, which do not have a fixed period but must be executed within a specified time limit.\nThe key difference between RMS and EDF is that RMS uses a fixed priority assignment based on task period, while EDF assigns priority dynamically based on the task deadline.\nIn summary, both RMS and EDF are real-time scheduling algorithms used to schedule tasks in real-time systems. RMS assigns priority based on the task period, while EDF assigns priority dynamically based on the task deadline.\n","permalink":"https://flecart.github.io/notes/scheduler/","summary":"\u003cp\u003eIl suo scopo principale √® \u003cstrong\u003egestire l\u0026rsquo;avvicendamento dei processi.\u003c/strong\u003e Ad esempio sospendere il processo che chiede I/O. O un sistema time sharing, quando arriva un interrupt sul time.\u003c/p\u003e\n\u003cp\u003eSolitamente il nome scheduler √® solamente un gestore dell\u0026rsquo;avvicendamento, si pu√≤ quindi utilizzare per indicare scheduler di altro tipo.\u003c/p\u003e\n\u003ch2 id=\"note-introduttive\"\u003eNote introduttive\u003c/h2\u003e\n\u003ch3 id=\"diagramma-di-gantt\"\u003eDiagramma di Gantt\u003c/h3\u003e\n\u003cp\u003eQuesto √® il diagramma per presentare lo scheduling, ossia da quando a quando √® eseguito cosa\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eEsempio gantt\u003c/p\u003e","title":"Scheduler"},{"content":"Introduzione (idea principale) In breve: essence card üü©- Giallo = Prodotto. Metafora staffetta-rugby üü© Con altri metodi si fanno produzioni stile staffetta, ossia un membro sta fermo, finch√© non ha il testimone e poi si uccide correndo\u0026hellip; Il metodo pi√π utile ispirato a scrum √® rugby, che tutti si muovo insieme collaborando. Un po\u0026rsquo; di tutto √® fatto durante lo sprint\nCicli di base (3) üü© Planning: in cui vengono scelti i task da eseguire durante questo sprint, solitamente questo viene preso da un subset dei task descritti dal product owner. Execution: questo √® abbastanza chiaro, si sviluppa. Retrospective and review: in cui vengono identificati i problemi che sono stati incontrati durante lo sviluppo, e modi possibili per risolverli. Lo sprint (3) üü©- Una cosa molto importante che aiuter√† di gran lunga lo sviluppo √® la costanza che Si scelgono\nTask READY che vengono fatte Queste vengono spostate in done quando sono fatte E poi vengono testate, questo per tutto il prodotto. Questo lo guarderemo in una sezione successiva.\nRuoli Introduzione in generale ai ruoli (3) üü© Product owner: deve rappresentare il cliente e scrivere le features pi√π interessanti per il team, sempre secondo ci√≤ che deve essere utile per il cliente.. Scrum Master deve cercare di eliminare gli ostacoli. Esempio: persone che litigano internamente al team Persone lavorano meno e non portano risultati, e si isola. Developer chi sviluppa. All\u0026rsquo;esterno ci sono gli stakeholders che sono in pratica i clienti, vuole cercare di capire esattamente cosa debba essere fatto.\nIn breve: Dinamiche del team üü® Auto-organizzazione, ossia il team stesso dovrebbe definire i suoi ruoli TODO: definire questa parte meglio, in che sensi si dovr√† auto-organizzare il team? Scrum pillars Scrum team A Scrum team is a group of individuals who work collaboratively to deliver high-quality product increments. The team is typically composed of a Scrum Master, a Product Owner, and Developers. The Scrum Team is cross-functional, self-organizing, and responsible for all product-related activities, including stakeholder collaboration, verification, maintenance, operation, experimentation, research, and development. The team is structured and empowered by the organization to manage their own work, and they work in Sprints at a sustainable pace to improve focus and consistency. The Scrum Team is small enough to remain nimble and large enough to complete significant work within a Sprint, typically consisting of 10 or fewer people. The team is focused on achieving the Product Goal and shares the same Product Backlog and Product Owner. The Scrum Team embodies the principles of transparency, inspection, and adaptation, and is essential for the successful implementation of the Scrum framework in delivering valuable products https://www.visual-paradigm.com/scrum/what-is-scrum-team/ Product Owner √à il membro del team che si relaziona con gli stakeholders esterni. rappresenta il punto di vista del cliente e deve essere in grado di descrivere il prodotto al team. Dato che √® il cliente che stabilisce le priorit√†, dovrebbe gestire le priorit√† (massimizza il valore dei rilasci). Dato che √® la figura che va con i clienti, deve anche essere in grado di recepire i cambiamenti di mercato e comunicarlo per bene al team. Deve sapere cosa prioritizzare per avere prodotto migliore nelle prossime iterazioni seguendo i dati che vengono raccolti durante lo scrum.\nResponsabilit√†\nProduct Goal. Triangolo di Ferro (3) Scope Cost Time Si tratta di migliorare la qualit√† del software restando dentro a questi limiti. √à anche una cosa che dovrebbe essere per Project Management, ossia quello che il manager deve considerare per fare stime dei progetti e consegnare pi√π qualit√†. In waterfall √® lo scopo la dimensione costante, cambiano le altre due.\nEventi scrum Riassunti eventi scrum (!!) (4) üü© Planning, in cui si scelgono le cose da fare Review, in cui si analizza quanto bene si √® fatto Retrospective, in cui si guarda come si potrebbe migliorare Daily Standup, feedback su quanto siamo messi. Sprint planning (2) üü© Si tengono in conto vari fattori (vedi immagine), e a seconda di questi vogliamo avere due output\nGOAL, l\u0026rsquo;obiettivo del nostro sprint Planning Chi fa cosa Il backlog presente Planning Poker üü© √à un gioco per stimare il tempo dei task https://planningpokeronline.com/ che √® molto divertente. Solve il problema di stimare il tempo necessario per fare qualcosa.\nVelocit√† sprint üü© Si pu√≤ intendere come il numero di story point completati, che solitamente √® dipendente da qualcosa di passato. Questo serve per stimare quanto si riuscir√† a fare negli sprint successivi.\nSprint review üü© In cui √® presente una demo del prodotto, con anche magari gli stakeholders Una specie di presentazione e pi√π gente forse :). Quindi si ha un feedback su quanto fatto per il prodotto durante lo sprint.\nSprint retrospective (3) üü© Si parla di ci√≤ che\nStart doing (che magari potrebbe aiutare, che prima non si faceva) Stop Doing che magari √® una cosa tossica da fare, non aiuta, e prende tempo Continue doing se va ancora bene √à sempre all\u0026rsquo;interno di scrum un modo per vedere se si pu√≤ migliorare il modo di lavorare. Artefatti Product backlog üü© Qui trattiamo l\u0026rsquo;insieme degli aspetti utili a gestire tutti i task che dovranno essere fatti\nGestione del backlog üü© La scelta dei singoli task √® fatta in maniera volontaria da parte di chi lavora. Il lavoro-board deve essere aggiornato volta volta in cui si continua a starci sopra. User story mapping üü© L\u0026rsquo;idea √® gi√† dividere task per task, nei sprint corretti.\nEsempi di mapping possibili Burndown chart üü© In pratica il numero totale di ore che sar√† una stima di quanto fatto.\nCaso ideale: lineare. Sono quindi dei grafici per valutare qualit√† del lavoro\nConclusioni Meta-scrum Cause effetti negativi NOTA: questa alla fine non √® scienza, si fa fatica a fare uno studio comparativo che cerchi di identificare se funziona o meno questo metodo, √® solamente\nDefinizioni di fatto o finito The DoR outlines the criteria that a specific user story must meet before being considered for estimation or inclusion into a sprint. It describes the characteristics of an effective user story and ensures that the team has a shared understanding of what\u0026rsquo;s needed for a user story to be brought into a sprint. The DoR is optional and is particularly useful when aspects of user stories are impeding progress, leading to stories being rolled into the next sprint. It is focused on user story level characteristics and is changeable based on the team\u0026rsquo;s needs\nThe DoD is a shared understanding among team members of what it means for a product backlog item (PBI) to be considered complete. It applies to all work in the backlog and represents the acceptance criteria for a sprint or release. The DoD outlines the quality standards that a piece of work needs to reach to be releasable. It is essential for ensuring consistent delivery of quality and is often standardized across the company. The DoD is changeable and may need to be adjusted based on the team\u0026rsquo;s needs\nMancanze di supporto Scrum master che non fa il lavoro Cattiva comunicazione di PO Cattiva comunicazione dei desiderata da parte degli stakeholders. ","permalink":"https://flecart.github.io/notes/scrum-method/","summary":"\u003ch3 id=\"introduzione-idea-principale\"\u003eIntroduzione (idea principale)\u003c/h3\u003e\n\u003ch4 id=\"in-breve-essence-card--\"\u003eIn breve: essence card üü©-\u003c/h4\u003e\n\u003cimg src=\"/images/notes/Scrum Method-1697470925893.jpeg\" alt=\"Scrum Method-1697470925893\"\u003e\nGiallo = Prodotto.\n\u003ch4 id=\"metafora-staffetta-rugby-\"\u003eMetafora staffetta-rugby üü©\u003c/h4\u003e\n\u003cimg src=\"/images/notes/Scrum Method-1697097959678.jpeg\" alt=\"Scrum Method-1697097959678\"\u003e\n\u003cp\u003eCon altri metodi si fanno produzioni stile \u003cem\u003estaffetta\u003c/em\u003e, ossia un membro sta fermo, finch√© non ha il testimone e poi si uccide correndo\u0026hellip;\nIl metodo pi√π utile ispirato a scrum √® rugby, che tutti si muovo insieme collaborando.\n\u003cstrong\u003eUn po\u0026rsquo; di tutto √® fatto\u003c/strong\u003e durante lo sprint\u003c/p\u003e\n\u003ch4 id=\"cicli-di-base-3-\"\u003eCicli di base (3) üü©\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003ePlanning\u003c/strong\u003e: in cui vengono scelti i task da eseguire durante questo sprint, solitamente questo viene preso da un \u003cem\u003esubset\u003c/em\u003e dei task descritti dal product owner.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExecution\u003c/strong\u003e: questo √® abbastanza chiaro, si sviluppa.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRetrospective and review\u003c/strong\u003e: in cui vengono identificati i problemi che sono stati incontrati durante lo sviluppo, e modi possibili per risolverli.\n\u003cimg alt=\" 500\" loading=\"lazy\" src=\"/notes/scrum-method-1697098147819.jpeg-\"\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4 id=\"lo-sprint-3--\"\u003eLo sprint (3) üü©-\u003c/h4\u003e\n\u003cp\u003eUna cosa molto importante che aiuter√† di gran lunga lo sviluppo √® la \u003cstrong\u003ecostanza\u003c/strong\u003e che\n\u003cimg src=\"/images/notes/Scrum Method-1697098373334.jpeg\" alt=\"Scrum Method-1697098373334\"\u003e\nSi scelgono\u003c/p\u003e","title":"Scrum Method"},{"content":"Introduzione Concetto principale üü©- √à sempre stato introdotto da Dijkstra, 1965 (Cooperating Sequential Processes) utilizzato come strumento di cooperazione semplice\nQuesto √® un sistema fortemente ispirato dai semafori che regolano gli incroci stradali.\ndue o pi√π processi possono cooperare attraverso semplici segnali, in modo tale che un processo possa essere bloccato in specifici punti del suo programma finch√© non riceve un segnale da un altro processo\nPrimitive dei semafori üü©- Il semaforo solitamente √® una variabile intera non negativa.\nV anche chiamato sem_wait.\nDa verhogen utilizzata per rilasciare una risorsa. Di solito √® implementata aumentando il valore di un semaforo.\nP, anche chiamato sem_post.\nDa proberen per attendere evento o rilascio di una risorsa. Di solito √® implementata decrementando il valore del semaforo solo se √® positivo non nullo.\nInvarianti per i semafori (!!!)\nSlide invarianti\nImplementazione classica della CS üü© Programma concorrente con semafori per CS\nImplementazione classica di P e V (ricordare da metterle nella CS)\nSi pu√≤ notare che tutte le 4 propriet√† espresse per la concorrenza sembrano essere soddisfatte.\nOltre a questo bisogna avere una struttura di dati (Queue) che tenga conto dei processi che stanno aspettando la risorsa dietro questo semaforo, in modo da poter ricominciare.\nSi potrebbe in questo caso anche disabilitare l\u0026rsquo;interrupt! Perch√© tanto ora non √® dentro lo scope del programmatore, √® dentro lo scope del semaforo! Per i multicore si possono utilizzare le soluzioni trattate in parti precedenti.\nVantaggi dei semafori üü© Fairness data dalla politica FIFO utilizzata per la struttura di dati della coda\nSlide\nBusy waiting molto minore\nInterleaving controllato? Boh non ho capito il concetto di questa frase\nSemafori binari Descrizione generale üü© Sono semafori che possono solamente avere come valore 0 e 1.\nTODO: dire anche cosa succede per l‚Äôattesa dei due‚Ä¶\nImplementazione üü©- Implementazione semaforo binario\nI semafori binari ci garantiscono mutua esclusione\nSemafori binari equiv. semafori normali üü© Implementazione dei semafori con semafori binari üü©\nImplementazione di semafori binari con semafori üü©\nProblemi classici Producer consumer üü© Abbiamo due agenti, un programma che produce una risorsa e un agente che la consuma. Questa comunicazione di disponibilit√† di un valore avviene attraverso una singola variabile condivisa.\nPropriet√† importanti\nProducer non pu√≤ scrivere la zona di memoria comune prima che il consumer l\u0026rsquo;abbia consumato Consumer non deve leggere due volte la stessa cosa. No deadlock n√© starvation In questo caso sono come delle sezioni critiche alternate passing the baton perch√© √® come se passasse il testimone, e vanno avanti in modo alternato.\nSoluzione\nLimited Buffer üü© La descrizione del problema √® molto simile, la differenza √® che si utilizza un buffer condiviso per lo scambio di informazioni, non una singola variabile, il resto delle propriet√† √® molto simile.\nSoluzione\nOsservazioni personali\nNon c\u0026rsquo;√® deadlock perch√© si bloccherebbero assieme solo se sia empty sia full sono 0, ma questo sarebbe un problema di inizializzazione. Dining philophers üü©- Ho 5 filosofi intorno a una tavola che devono acquisire le due bacchette (risorse condivise) per mangiare, altrimenti pensano.\nInvarianti\nResource hierarchy solution\nSoluzione\nIn questa soluzione si crea una gerarchia di priorit√† per chi deve acquisire la fork, con una rottura di simmetria per l‚Äôultima.\nIl problema √® che non √® libero da starvation.\nPagina wiki\nAltre soluzioni\nOsservazioni personali\nCredo ci sia starvation perch√© non c\u0026rsquo;√® niente che mi garantisca che non ci sia.\nRoba da buttare, riguardo dining\nPseudocodice per il problema dei dining filosophers che utilizza il token, e la struttura ad anello inizializza 5 semafori, solo uno sar√† a 1 sar√† quello attivo direi. 5 booleani che indicano la disponibilit√†. inizializzo 5 numeri che identificano il numero delle volte che si ha mangiato Alla fine di ogni ciclo di mangiata viene incrementato il numero, e questo numero viene incrementato solamente da un unico thread, quello di un certo filosofo, quindi non devo metterci il mutex, o forse s√¨??. Quindi fra gli attivi voglio solamente chi ha il token e chi pu√≤ mangiare. bool done = false; while (!done): waiting_for_token = true, // anche done pu√≤ essere utilizzato come waiting for token. [enter CS] if (disponibile left): prendi left if (disponibile right): prendi right waiting_for_token = false; // done = true qui, invece che sotto. make calls to take left and right. else: release left [exit CS] if (has both forks): eat() releaseLeft() signal left is available releaseRight() signal right is available done = true; else: go to sleep (try again lather, if not done)) passtoken to next waiting for token. - somebody is waiting for token if 1. Is not eating 2. Has not finished Quindi ci metto il check booleano sopra. Readers and writers üü©- Questo √® uno dei problemi pi√π importanti, adremo in seguito a sviluppare il concetto di awaiting.\nCi sono due tipi di processi che devono leggere un database. I lettori accedono al database per leggerlo, gli scrittori per scriverlo, fatto √® che i lettori possono leggere quanto vogliono, quando per√≤ uno ci vuole scrivere, nessun altro ci pu√≤ andare a leggere.\nUn solo scrittore, che blocca tutti\nSe nessuno scrive tutti possono leggere.\nInvarianti da rispettare\nSoluzione Readers and Writers con semafori\nStarvation degli scrittori\nQuesta soluzione ha il drawback del fatto che starvation per i scrittori.\nQuesta √® una soluzione che funziona ma vorremmo trovare un metodo per descrivere tutti i problemi con await, in modo molto clean.\nPriorit√† ai scrittori con await framework üü®+ Vogliamo in questa parte trattare di una soluzione che non metta in starvation gli scrittori, ma mette in starvation i lettori in questo caso.\nSlide soluzione\nLa soluzione √® quasi la stessa, ma si cambia la condizione di entrata per i lettori che sar√† quando non c\u0026rsquo;√® nessun scrittore che sta scrivendo e nemmeno nessuno che sta aspettando di scrivere.\nScegliere quale soluzione utilizzare dipende molto dall‚Äôambiente in cui stiamo, dipende se vogliamo pi√π gente che scriva o pi√π gente che legga (di solito per un database c\u0026rsquo;√® molta gente ch elegge e poca che scrive).\nProblema del barbiere addormentato Slide\nFramework per semafori Andiamo in questa parte a creare un framework generale per la discussione di problemi con await con i semafori.\nFramework semafori Andrews (4) üü®- Notazione con Await (2) üü®+ Notazione (andrews Await)\nQuindi la sintassi diventa di due parametri in particoalre\nStatement atomico Statemento atomico con await su una condizione booleana. Molto interessante notare che √® questo ci√≤ che stato implementato con Javascript! Ed √® una cosa molto clean questo paradigma :D.\nSoluzione readers and writers con await (generale)\nSi noti che questa soluzione √® equivalente alla soluzione dei semafori, ma √® scritta in modo molto pi√π clean.\nImplementazione await con semafori üü© Note sulle variabili di implementazione\nLe note principali sono i semafori e i waiting.\nImplementazione in slide\ni quadrati sono degli if non deterministici, nel senso che posso riordinarli come mi pare e sarebbe comunque apposto\nSu signal, ci d√† un idea di quanti processi possono andare avanti dato un cambiamento di stato.\nLa modifica sul waiting[i]- - non √® un write non protetto??? No perch√© sempre passaggi di testimoni! Siamo sempre in una sezione critica, ma divisa fra pi√π processi grazie a questo meccanismo passing the baton.\nInfatti √® per questo che possono fare waiting[i]- - senza apparentemente essere in mutua esclusione!.\nNota che sembra interessante √® che questo baton viene continuamente passato da processo a un altro da signal ad un altro finch√© non posso pi√π fare signal.\nNota sui passaggi di testimoni\nLa mutex √® sempre rilasciata attraverso la tecnica del passing the baton, in qui il mutex √® rilasciato da processi diversi, si pu√≤ espandere su molti processi diversi la mutua esclusione‚Ä¶ Cavolo per√≤ credo sia molto difficile sbagliarci qualcosa no? boh.\nReaders and writers con await (!) üü®- Slide soluzione\nSoluzione in singola slide (e con signal ottimizzato)\nConsiderazioni finali (3) üü® I semafori pongono forti problemi di leggibilit√† dato che sono costrutti a basso livello sparsi in mezzo al codice.\n√à possibile inoltre compiere errori stupidi in modo molto facile, come scambiare P o V, omettere Po V.\nE pone un sacco di responsabilit√† sul prorammatore che deve gestire lui in modo corretto le risorse e definire gli accessi.\n","permalink":"https://flecart.github.io/notes/semafori/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"concetto-principale--\"\u003eConcetto principale üü©-\u003c/h3\u003e\n\u003cp\u003e√à sempre stato introdotto da Dijkstra, 1965 (Cooperating Sequential Processes) utilizzato come strumento di cooperazione semplice\u003c/p\u003e\n\u003cp\u003eQuesto √® un sistema fortemente ispirato dai semafori che regolano gli incroci stradali.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003edue o pi√π processi possono cooperare attraverso semplici\nsegnali, in modo tale che un processo possa essere bloccato\nin specifici punti del suo programma finch√© non riceve un\nsegnale da un altro processo\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch3 id=\"primitive-dei-semafori--\"\u003ePrimitive dei semafori üü©-\u003c/h3\u003e\n\u003cp\u003eIl semaforo solitamente √® una \u003cstrong\u003evariabile intera non negativa\u003c/strong\u003e.\u003c/p\u003e","title":"Semafori"},{"content":"Vincoli sintattici contestuali Intro: dipendenze da contesto üü© I vincoli sintattici non sono esprimibili tramite BNF perch√© dipendono dal contesto, mentre le grammatiche libere sono per definizione libere da contesto, vogliamo quindi trovare una soluzione a questo problema. Vengono usati metodi Ad-Hoc nella fase di analisi semantica del programma.\nGrammatiche dipendenti dal contesto\nQueste grammatiche sono molto pi√π complicate (e lente) rispetto a quelle libere da contesto, quindi √® poco pratico e non utilizzabile (tempo esponenziale, quindi non finisce mai).\nSemantica statica üü© Facciamo differenza fra semantica statica e dinamica con il primo che √® analizzato nella fase di compilazione del programma, mentre per dinamico √® analizzato nella fase di run-time, ma √® una forzatura del nome, perch√© storicamente sintassi √® indicata solamente a grammatica libera, mentre semantica √® tutto il resto, ma in verit√† semantica statica √® parte di sintassi.\nPrincipalmente questa parte riguarda controlli ad-hoc sul programma durante la compilazione. (ad hoc perch√© non √® vista dall‚Äôalbero di sintassi).\nSemantica statica def slide\nEsempi di controlli semantica statica\nSempre da tenere in mente che gli errori riportati in questa fase sono riguardanti la sintassi del programma (quindi ad esempio l‚Äôutilizzo di variabili non assegnate √® possibile in C non in Java, questo √® un controllo di semantica statica che dipende da questa sintassi del programma)\nUtilizzo dell‚Äôassegnamento a una variabile Le funzioni sono chiamate col giusto numero di variabili Divisione per zero (guarda esempio sul libro non √® ben definita questa cosa sul fatto che sia statica o dinamica). Assegnamento di variabili dello stesso tipo. Questi sono esempi di vincoli sintattici contestuali.\nSemantica dinamica (e utilizzi) üü©‚Äî Def semantica dinamica slide\nQuesta semantica √® un modello matematico utile per ogni architettura! √à una sorta di specifica che deve descrivere il concetto di correttezza di un programma dal punto di vista semantico. √à una rappresentazione dell‚Äôesecuzione del programma!\nEsempi di utilizzi:\nSlide utilizzi (!!!)\nDimostrazione di propriet√† del programma\nSpecifica formale del linguaggio\nImplementazione √® corretta?\nQuesti utilizzi si possno distinguere se l\u0026rsquo;autore √® un programmatore, un progettista del linguaggio, un implementatore di un linguaggio. (vedere le slides)\nTecniche di definizione di semantica (4) üü© Questa parte descrive la semantica, ma per certi punti ha un sacco di roba in comune con Classical Cyphers\nOperazionale\nSi mostra l‚Äôeffetto di ogni istruzione durante l‚Äôesecuzione, per dare enfasi su questo aspetto dobbiamo avere bene in mente la macchina astratta (registri stati etc..) (o mini automa). In parole povere proviamo a far eseguire su una macchina astratta\nCome calcola? questo √® quello che andiamo a fare oggi.\nDenotazionale\nSi fa enfasi su cosa va a calcolare (in cui si fa enfasi sulla funzione che viene calcolata).\nPragmatica\nDa ricordare la pragmatica in Pragmatica üü© in cui vengono trattati in generale principi per la descrizione di un linguaggio. In pi√π si va a chiedersi sul come utilizzare un costrutto e sullo scopo del singolo comando.\nSi parla di stile di programmazione.\nEsempi di pragmatica\nImplementazione\nSi va a rispondere a domande come\nL‚Äôimplementazione √® corretta? (veramente il sorgente e l\u0026rsquo;output implementano la stessa semantica?) Come √® implementato? Il codice in output √® efficiente o meno? Le strutture di dati utilizzate sono troppo pesanti o sono ok? Struttura del compilatore Slide struttura del compilatore\nAnalisi lessicale (Scanner) üü© Viene generata e riempita una tabella di simboli, questa fase vengono identificati ogni singola parola (o token) che incontra nel nostro programma.\nIn breve fa queste cose\nGenera i token (il lessico ammissibile) Riporta errori se trova token non legali Riempie parzialmente la tabella dei simboli Se qualche parola non √® valida viene utilizzato un gestore dell\u0026rsquo;errore\nI token sono spesso\nidentificatori Numeri operatori Parentesi Parole riservate Sono usati in questa parte grammatiche regolari espressioni regolari automi NFA DFA\nAnalisi sintattica (Parser) üü© In input riceve i token, utilizza la grammatica del linguaggio per verificare se √® corretto in output restituisce un albero di sintassi astratta del nostro programma. (quindi riporta errori sintattici del nostro programma) e aggiunge informazioni alla tabella dei simboli.\nQuindi in breve\nGenerazione albero di derivazione Report degli errori sintattici (al livello di frase) Sono usati in questa parte grammatiche libere da contesto pushdown automata (DPDA)\nAnalisi semantica üü© Controlla se tutta la sintassi libera da contesto sia coerente con la semantica del contesto (quindi verifica tipi, verifica chiamate o moltiplicazioni che abbiano senso o meno)\nIn breve\nControlli di semantica statica (verifica dei tipi, parametri etc) vedi sopra Aggiorna la tabella dei simboli con informazioni sui tipi Espande l‚Äôalbero con cose sui tipi Codice intermedio üü©- Scrive questo codice intermedio pi√π semplice\nSi segue la struttura sintattica, quindi spesso genera del codice molto verboso\nProduce codice molto semplice ,spesso three-address code.\nEsempio di codice intermedio\nOttimizzazione (4) üü© Ottimizza il codice nella forma intermedia\nCodice inutile √® rimosso Ottimizzazioni varie Espansione delle chiamate in linea (inline) Fattorizzazione di sottoespressioni Mettere fuori cicli sottoespressioni che non variano Generazione codice üü© Ottimizzazione specifica all‚Äôarchitettura Generazione del codice specifico (quindi a livello del singolo registro, o gestione stack e simili La tabella dei simboli üü© Contiene informazioni riguardo tutti i simboli all\u0026rsquo;interno del programma, quindi molto utile nella fasi di analisi.\nQuindi contiene metainformazioni riguardo ai simboli di interesse.\nSemantica Operazionale strutturata The meaning of a program in the strict language is explained in terms of a hypothetical computer which performs the set of actions that constitute the elaboration of that program. (Algol68, Section 2)\nIntro: insiemi di riferimento üü® Ha un linguaggio definito con la sintassi astratta solita (qualunque stringa √® parte dell‚Äôalbero di sintassi valido)\nAgisce principalmente su 3 insiemi\nBooleani Numeri Variabili (simbolici) Con questi dati primitivi definiamo delle espressioni\nSlide\nEspressioni aritmetiche (che agiscono su numeri o variabili) Espressioni booleane Comandi (control flow, gestione memoria, move di variabili) La descrizione di questi insiemi con le BNF sono ambigue ma per l\u0026rsquo;analisi della semantica non ci serve che abbiano un senso vero per questa roba. Non ci interessa di farlo in modo dis-ambiguo ci interessa questa parte solo per la semantica dinamica\nI parser danno in output degli alberi in sintassi astratta\nSistema di transizione (!) üü©‚Äî Slide di definizione\nQuesto sistema di transizione ci √® utile per descrivere al meglio la semantica.\n√à una tripla $\\Gamma, T, \\to$ dove il primo √® l‚Äôinsieme degli stati, il secondo l‚Äôinsieme degli stati terminali e il terzo una relazione di transizione (che pi√π o meno ci dice in che modo possiamo muoverci all‚Äôinterno di questi stati).\nIndichiamo con computazione da uno stato $\\gamma_o$ di partenza una seguenza (possibilmente infinita) di transizioni.\nIndichiamo con $\\to^*$ la chiusura riflessiva e transitiva della relazione di transizione.\nInterna sinistra, destra, ed esterne üü© Questo concetto di definizione di operazioni interna sinistra,destra ed esterne √® solamente un metodo che piace al prof per descrivere questo, per√≤ mi sembra che sia praticamente inutile lmao.\nComunque una operazione la descrivi come interna se valuti entrambi gli operandi, sinistra se valuti prima il sinistro e poi il destro e poi viceversa.\nLa definisci come esterna se √® possibile valutare soltanto l‚Äôoperatore sinistro (quindi esterna sinistra) o destro.\nOltre IS, esistono anche ID, ES, ED e Interna Parallela = IP (in cui posso utilizzare in modo alternato il destro o sinistro, e quindi mi basta solo sum1 o sum1‚Äô, quindi questa √® non-deterministica), perch√© posso avere delle derivazioni diverse (ad ogni step posso avere pi√π di un unico assioma da utilizzare!), e potrei anche farli in parallelo.\nSemantica delle espressioni aritmetiche (!) üü© Assiomi per le relazioni (3 tipi)\nVar sostituzione con variabile con un numero terminale\nSum1 mi d√† una sorta di idea di equivalenza per la somma per alberi che si derivano.\nSum2 mi d√† una equivalenza quando la somma √® su un numero\nSum3 mi d√† una equivalenza nella somma nei naturali.\nSub{1,2,3} sono esattamente equivalenti ma per la sottrazione.\nOsservazioni\nLo store non viene mai modificato.\nPer la valutazione si preferisce valutare l‚Äôoperando pi√π a sinistra. ‚ÜíInterna sinistra in modo analogo esiste l‚Äôinterna destra.\nCostruzione solita, con store\nFunzione di transizione √® deterministica (non richiesta) üü• Questa √® una caratteristica importante della funzione di transizione, si fa uso della ricorsione strutturale presente in 4.6 Ricorsione strutturale.\n$$ y \\to y', y \\to y'' \\implies y' =y'' $$Ossia ho una sola possibile mossa\nDimostrazione\nEval üü© Il fatto che sia deterministica ci permette di definire un concetto di eval tanto √® unica!\n√à definita con le funzioni di valutazione interne sinistre!\nEssere esterno significa che a volte non valuto tutti gli operandi nella nostra operazione, mentre le interne devono valutare tutte.\nIn generale valgono queste valutazioni\nEquivalenza (!!) üü©- Possiamo anche definire un concetto di equivalenza di espressioni come propriet√† di questo eval.\nDefinizione di equivalenza per espressioni\nSemantica delle espressioni booleane (!) üü© Assiomi per la semantica delle espressioni booleane\nValgono le propriet√† per le espressioni aritmetiche\nStore non cambia La relazione √® deterministica. Semantica dei comandi (statements) (!) üü®+ Assiomi per la semantica dei comandi\nCommenti sugli assiomi\nSkip non faccio niente, lascio la funzione di valutazione esattamente la stessa\nAssign viene fatto uno step di sostituzione (e quindi bisogna anche creare una funzione di sostituzione, ma √® definita bene in logica in questo blocco 8.1.2 Operazione di sostituzione.\nSeq cerca di far andare avanti la computazione\nIf decide in quale ramo andare, quindi due regole easy\nWhile in modo molto simile, decide se rieseguire il corpo del while oppure andare fuori.\nSi pu√≤ notare che anche questa semantica √® deterministica! In modo simile si pu√≤ dimostrare per ricorsione strutturale insieme le altre, dato che √® deterministica possiamo *definire una funzione exec. che √® definita solo se √® terminale\nDivergenza e deadlock sono EQUIVALENTI (Ossia computazione ch enon pu√≤ andare avanti e cicli infiniti, non si distinguono con questa semantica, bisogna introdurre delle cose in pi√π).\nErrori dinamici (runtime) üü® Regole di generazione e propagazione dell‚Äôerrore\nAltre regole per errori (che in un linguaggio solitamente esistono)\nNon determinismo e parallelismo üü® Non deterministico perch√© si pu√≤ eseguire in mondi diversi e ritornare cose diverse a seconda di quei mondi.\nParallelismo perch√© pu√≤ eseguire in contemporanea le istruzioni (in questo senso l‚Äôordine di esecuzione pu√≤ essere ben differente).\nSlide\nEsempio di esecuzione non deterministica\n","permalink":"https://flecart.github.io/notes/semantica-di-un-linguaggio/","summary":"\u003ch2 id=\"vincoli-sintattici-contestuali\"\u003eVincoli sintattici contestuali\u003c/h2\u003e\n\u003ch3 id=\"intro-dipendenze-da-contesto-\"\u003eIntro: dipendenze da contesto üü©\u003c/h3\u003e\n\u003cp\u003eI vincoli sintattici non sono esprimibili tramite BNF perch√© dipendono dal contesto, mentre le grammatiche libere sono per definizione libere da contesto, vogliamo quindi trovare una soluzione a questo problema. Vengono usati metodi Ad-Hoc nella fase di \u003cstrong\u003eanalisi semantica\u003c/strong\u003e del programma.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eGrammatiche dipendenti dal contesto\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eQueste grammatiche sono molto pi√π complicate (e lente) rispetto a quelle libere da contesto, quindi √® poco pratico e non utilizzabile (tempo esponenziale, quindi non finisce mai).\u003c/p\u003e","title":"Semantica di un linguaggio"},{"content":"Molto importante questo documento per avere chiara la differenza fra la logica intuizionista e la Logica Proposizionale classica.\nQuesta logica intuizionista non si preoccupa del noumeno platonico, ma solo di una prova reale.\nIntroduzione:\nwikipedia\n9 11 Scopi di intuizionista (3) Semantica dell\u0026rsquo;evidenza ‚Üí costruzione della prova Semantica della conoscenza diretta = conoscenza diretta Semantica della calcolabilit√† = programma, algoritmo della soluzione 9.1 Invenzione o scoperta La semantica intuizionista vede la matematica come una creazione (e questa cosa interessa molto all\u0026rsquo;informatico perch√© √® una prova., mentre la semantica classica vede la matematica come una scoperta\nCaratteristica principale della logica intuizionista\nEsempio il paradosso di Banach-tarksi non √® calcolabile (nessuno ha duplicato una sfera doro diciamo :) )\nSeziono la sfera in 3 parti e faccio movimenti rigidi (non deformo, posso rotare, trasportare) e dimostro che da questi movimenti rigidi ottengo due sfere con lo stesso volume e con gli stessi punti.\n9.1.1 Evidenza indiretta e diretta Nelle due logiche il significato di esistenza √® differente.\nClassica: l\u0026rsquo;esistenza, ma non so esattamente che numero sia Intuizionista: l\u0026rsquo;elemento che soddisfa, riesco proprio a trovare l\u0026rsquo;elemento tale che mi soddisfi le mie propriet√†. NOTA: il fatto che esista una prova intuizionista mi permette di avere un algoritmo per tirare fuori un elemento che me lo soddisfi, mentre dalla prova classica no.\n9.1.2 Effetti dimostrazione per assurdo Questo metodo di dimostrazione non √® stato ben accettato nell\u0026rsquo;epoca in cui √® stato creato perch√© non permetteva il buon calcolo:\nNo calcolo Molto utile per dimostrare teoremi che non si potevano dimostrare in modo intuizionistico Molto veloce perch√© rende le dimensioni delle prove minori (ma perch√© fa meno lavoro!) 9.2 Enunciati e semantiche della logica intuizionista Algoritmo l\u0026rsquo;evidenza diretta √® necessaria per la determinazione del valore di verit√† Il valore di verit√† √® potenzialmente determinabile (ossia pu√≤ diventare fissata dopo un p√≤ di tempo), ci deve essere una algoritmo o che non esista. Enunciato ed esempi\nAnalizzando la prima proposizione, per la logica classica dovrei avere un valore di verit√† fissato, invece sono in un mondo indeterminato.\nPer i numeri, l\u0026rsquo;algoritmo non riuscirebbe mai a finire a comparare due numeri periodici e non riuscirebbe a dare un risultato in tempo finito.\nMentre l\u0026rsquo;ultimo esempio √® stato dimostrato in Logica meta-linguistica\nDa questi si posso ricavare due semantiche:\n9.2.1 Semantica di Kripke La caratteristica principale di questa semantica √® che le proposizioni possono avere un range da [0,1].\nE che queste denotazioni possono evolvere da 0 a 1 col tempo. Bisogna quindi avere una funzione semantica che possa trattenere il tempo.\n0 √® ignoto 1 √® vero e questi valori evolvono.\nQuesti valori sono dei valori di conoscenza ma non verit√†, e non algoritmico!\nEnunciato\n9.2.2 Altro Si tratter√† anche della semantica di Brouwer-Heyting-Kolmogorov subito dopo\n9.3 Semantica di Brouwer-Heyting-Kolmogorov 9.3.1 Introduzione Data una formula F, la sua denotazione √® l\u0026rsquo;insieme delle prove esplicite (algoritmi) che risolvono quella formula.\nQuesta semantica √® molto utile per l\u0026rsquo;informatico perch√© le formule sono descrizioni di problemi e l\u0026rsquo;altro soluzione.\nosservazioni:\nQuesta semantica √® molto utile per comporre delle soluzioni (grazie ai connettivi). L\u0026rsquo;insieme vuoto √® l\u0026rsquo;inesistenza di soluzioni algoritmiche (che potrebbe essere non pi√π vuoto in futuro).\nQui ha senso introdurre il concetto di dedicibilit√† ovvero la possibilit√† di costruire un algoritmo che me lo risolva.\n9.3.2 Enunciato e definizione semantica Enunciato\nDefinizione semantica\n9.3.3 Nota sul VOID: con void in c starei restituendo la stellina (valore vero), ovvero sto restituendo sempre una sequenza giusta (eliminazione del top √® inutile quindi non ci faccio caso).\n9.3.4 EM e RAA in semantica intuizionista Queste dimostrazioni valide in logica classica non hanno pi√π senso in questo caso\nEsempio\n9.3.5 Correttezza e completezza Potrebbe essere un buon esempio confrontare la correttezza e completezza intuizionistica con quella classica.\nSlide\nCompletezza forte e debole\nSlide\nAbbozzo di ragionamento per queste completezza\nUn algoritmo in un tempo finito non pu√≤ analizzare un input infinito, quindi non potrebbe dimostrarlo un algoritmo. Esiste per√≤ una dimostrazione classica.\n9.3.6 Conclusioni Questa semantica si pu√≤ evolvere nel tempo (trovando nuovi algoritmi che mi risolvano il problema)\nSi ha una completezza debole per logiche senza RAA\nSe ho una prova intuizionista riesco a costruire un algoritmo che mi risolvi un problema\nEM non ha molto senso qua, se fosse una tautologia sarebbe un risultato molto forte\nSlide\n9.3.7 La negazione Le formule negate non hanno informazione al loro interno.\nPartiamo dalla regola del not, ovvero per dimostrare nonF devo dimostrare che F implica l\u0026rsquo;assurdo.\nOvvero devo dire che ci sia una funzione che parta da F e che arrivi a nulla.\nLe soluzioni possibili sono solamente vuoto e singoletto di vuoto (in altri termini possiamo dire che abbiamo 0 e 1). chiaramente queste funzioni non sono affatto utili per cui non esiste un algoritmo che mi da cose utili.\nNegare due volte √® equivalente a distruggere una informazione (devi fare una tabellina con la regola per vedere che c\u0026rsquo;√® questo)\nnotF Stato di F notnotF singoletto vuoto Uguale a Vuoto vuoto vuoto Diverso da vuoto singoletto vuoto perch√© nonF mi pu√≤ dare solamente due output, mi ha distrutto tutto l\u0026rsquo;algoritmo iniziale!\nDimostrare che non esiste significa dire che non esiste informazione.\nProva a dimostrare queste:\n$$ \\neg(F_1 \\vee F_2) \\Vdash \\neg F_1 \\wedge \\neg F_2 $$Mentre per quello sopra invertito (invertendo or e and di sopra) non √® intuizionista, perch√© l\u0026rsquo;output ha pi√π informazioni per qualche motivo strano.\n9.4 Teorema di compattezza Questo teorema √® una conseguenza molto utile della propriet√† di completezza, come in slide:\nEnunciato e dimostrazione del teorema\nQuesto teorema √® molto forte, perch√© se ho un insieme infinito di filtri, vuol dire che ho bisogno solamente di limiti finiti. E il fatto che l\u0026rsquo;infinito si possa ridurre al finito √® un fatto sorprendente.\n9.4.1 Conseguenze della compattezza (4) La cosa che era sorpredente della compattezza in questi casi √® la possibilit√† di ritrovare in un caso infinito un caso finito da cui √® possibile poter ricavare la cosa voluta!.\nConseguenze\n9.4.2 Fallimento della compattezza per logiche complesse (3) Slide\nze\n\u0026lt;img src=\u0026quot;/images/notes/Semantica intuizionista/Untitled 12.png\u0026quot; alt=\u0026quot;Semantica intuizionista/Untitled 12\u0026quot;\u0026gt; 9.4.2 Fallimento della compattezza per logiche complesse (3) Slide\n","permalink":"https://flecart.github.io/notes/semantica-intuizionista/","summary":"\u003cp\u003eMolto importante questo documento per avere chiara la differenza fra la logica intuizionista e la \u003ca href=\"/notes/logica-proposizionale/\"\u003eLogica Proposizionale\u003c/a\u003e classica.\u003c/p\u003e\n\u003cp\u003eQuesta logica intuizionista non si preoccupa del noumeno platonico, ma solo di una prova reale.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eIntroduzione:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ewikipedia\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Semantica intuizionista/Untitled.png\" alt=\"image/universita/ex-notion/Semantica intuizionista/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"9-11-scopi-di-intuizionista-3\"\u003e9 11 Scopi di intuizionista (3)\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eSemantica dell\u0026rsquo;evidenza ‚Üí costruzione della prova\u003c/li\u003e\n\u003cli\u003eSemantica della conoscenza diretta = conoscenza diretta\u003c/li\u003e\n\u003cli\u003eSemantica della calcolabilit√† = programma, algoritmo della soluzione\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"91-invenzione-o-scoperta\"\u003e9.1 Invenzione o scoperta\u003c/h2\u003e\n\u003cp\u003eLa semantica intuizionista vede la matematica come una creazione (e questa cosa interessa molto all\u0026rsquo;informatico perch√© √® una prova., mentre la semantica classica vede la matematica come una scoperta\u003c/p\u003e","title":"Semantica intuizionista"},{"content":"Semirings allow us to generalize many many common operations. One of the most powerful usages is the algebraic view of dynamic programming.\nDefinition of a semiring A semiring is a 5-tuple $R = (A, \\oplus, \\otimes, \\bar{0}, \\bar{1})$ such that.\n$(A, \\oplus, \\bar{0})$ is a commutative monoid $(A, \\otimes, \\bar{1})$ is a monoid $\\otimes$ distributes over $\\oplus$. $\\bar{0}$ is annihilator for $\\otimes$. Monoid Let $K, \\oplus$ be a set and a operation, then:\n$\\forall a, b, c \\in K$ we have that $a \\oplus (b \\oplus c) = (a \\oplus b) \\oplus c$ $\\exists 1$ such that $\\forall a \\in K$ we have $1 \\oplus a = a \\oplus 1 = a$ A monoid has associativity and identity element. This structure allows us to use that sort of backpropagation. A simple example of a semiring would be $\\left( \\mathbb{R}^{+}, +, \\times, 0, 1 \\right)$. We can show every property above. The deep insight is that dynamic programming just needs semirings with distributive property to work! All of the above derivation for the algebraic method for the algorithm just needs that our operation is a semiring! Then everything would work in the same manner.\nRing We have a semiring, with the addition that addition is invertible. So instead of monoid, we have a group for the addition.\\\nIf a semiring has a multiplication operation that is commutative, then it\u0026rsquo;s called communicative semiring. If semiring has idempotent operation, then it\u0026rsquo;s a idempotent semiring.\nAnej Svete said there are also some cool applications of defining some sampling from transformers as operations over some special semirings.\nTable of semirings See (Huang 2008).\nApplications We usually lift some algorithm to a semiring to implement a generalized version of it. In this manner, a single proof of correctness can be applied to many algorithms.\nGeneralized Backward with Semi-rings Usages and rings TODO: in this section you should describe what semiring is used, and what is each for. Example: normal semiring is used to compute the normalizer, when the tropical semiring is used for the best part of speech tagging.\nOther variations Closed semiring $$ \\begin{array} \\\\ x^{*} = 1 \\oplus x \\otimes x^{*} \\\\ x^{*} = 1 \\oplus x^{*} \\otimes x \\end{array} $$Example: infinite sum is a Kleene unary operation, let\u0026rsquo;s take an integer $x \\in [0, 1)$ Then $x^{*} = \\sum_{n = 1}^{\\infty} x^{n} = \\frac{1}{1 - x}$, and it\u0026rsquo;s easy to check the axioms.\nFor example $0$ should be the Kleene Star for the arctic semiring, also for the tropical semiring. $1$ is the Kleene for the boolean semiring.\nK-closed semirings $$ \\bigoplus ^{k + 1}_{n = 1} x^{n} = \\bigoplus^{k}_{n = 1} x^{n} $$$$ \\bigoplus^{k}_{n = 1} x^{n} = x^{*} $$Matrix Semiring $$ \\begin{align} \\mathcal{M}_{n \\times m}(R) = \\left\\{ A \\in R^{n \\times m} \\right\\} \\\\ \\oplus = \\oplus_{R} \\\\ \\otimes = \\otimes_{R} \\\\ \\bar{0} = \\bar{0}_{R} \\\\ \\bar{1} = \\bar{1}_{R} \\end{align} $$ Where the operations are defined element-wise, the null operator is the matrix with all zeros, and the identity matrix is the matrix with all $\\bar{1}$ on the diagonal and $\\bar{0}$ elsewhere. We can prove that this is a semiring.\nIn the matrix semiring setting, is is useful to consider the Kleene Star operation. This is interpretable as the pathsum of all paths of length $k \u003e 0$ starting and finishing at a certain index. This also motivates\nReferences [1] Huang ‚ÄúAdvanced Dynamic Programming in Semiring and Hypergraph Frameworks‚Äù Coling 2008 Organizing Committee 2008\n","permalink":"https://flecart.github.io/notes/semirings/","summary":"\u003cp\u003eSemirings allow us to generalize many many common operations. One of the most powerful usages is the algebraic view of dynamic programming.\u003c/p\u003e\n\u003ch3 id=\"definition-of-a-semiring\"\u003eDefinition of a semiring\u003c/h3\u003e\n\u003cp\u003eA semiring is a 5-tuple $R = (A, \\oplus, \\otimes, \\bar{0}, \\bar{1})$ such that.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e$(A, \\oplus, \\bar{0})$ is a commutative monoid\u003c/li\u003e\n\u003cli\u003e$(A, \\otimes, \\bar{1})$ is a monoid\u003c/li\u003e\n\u003cli\u003e$\\otimes$ distributes over $\\oplus$.\u003c/li\u003e\n\u003cli\u003e$\\bar{0}$ is annihilator for $\\otimes$.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4 id=\"monoid\"\u003eMonoid\u003c/h4\u003e\n\u003cp\u003eLet $K, \\oplus$ be a set and a operation, then:\u003c/p\u003e","title":"Semirings"},{"content":"Gestione del non determinismo Il modo pi√π facile per gestire il non determinsmo √® semplificare le grammatiche quindi andiamo a vedere metodi per fare ci√≤.\nSemplificazione grammatiche (5) Slide\nNo produzioni del tipo $A \\to \\varepsilon$ per bottom up (altrimenti va all‚Äôinfinito!) No produzioni unitarie, cos√¨ evito cicli in cui da A derivo s√© stesso. No simboli inutili No ricorsione sinistra (divergenza per top-down) Fattorizzazione della grammatica Eliminazione delel produzioni nulle Vogliamo creare un algoritmo utile ad eliminare le produzioni che non ci piacciono.\nFormalizzazione algo obiettivo !\nInsieme dei simboli annullabili üü© Vogliamo con questa parte definire in modo formale l\u0026rsquo;insieme dei non terminali che portano a produzioni di quel genere\nSlide definizione simboli annullabili !\nOssia una annullabilit√† in n passi, e andiamo ad indagare tutti i simboli che soddisfano queste cose.\nNOTA: nello step induttivo, un simbolo √® annulable solo se l‚Äôintera produzione √® annullabile (quindi tutte le cose in output.\nUna cosa del tipo $A \\to BC$ √® annullabile solo se lo sono entrambi (sia B che C).\nDerivazione grammatica annullabilit√† üü© Slide\nSlide esempio\nIntuizione\nIn pratica vado ad eliminare i non terminali in tutti i modi possibili, e vado ad eliminare quelle che poi vanno ad eliminare. In pratica mi vado a tenere tutte le configurazioni che posso attenere, annullando quello che si pu√≤ annullare.\nFaccio questa cosa per tutti!\nNota sul vuoto\nSe vogliamo che il nuovo linguaggio possa accettare il vuoto, allora basta aggiungere al non terminale iniziale la produzione dle tipo $S \\to \\varepsilon$, ma questo √® presente solo al primo!.\nProduzioni unitarie Vorremmo evitare le produzioni unitarie che portano a cicli perch√© altrimenti avrei dei cicli infiniti che non sono molto buoni per il parsing.\nDefinizioni utili\nCoppie unitarie üü© Slide\nIn pratica √® come se definissi una operazion per le coppie unitarie, e la chiudo per riflessivit√† e transitivit√†.\nAlgoritmo di eliminazione üü© Algoritmo per eliminare coppie unitarie\nPer la creazione della nuova grammatica, quello che faccio non √® altro che filtrare quelle che mi portano a coppie unitarie.\nOltre a questo faccio una copia‚Ä¶ Se guardi l‚Äôesempio comunque lo vedi un p√≤ meglio\nEsempio\nRimozione di simboli inutili Def generatore e raggiungibilit√† (2) üü© In questa sezione andiamo a definire alcuni concetti utili a definire l\u0026rsquo;inutilit√† di alcuni simboli\nSlide !\nCos√¨ andiamo a definire come simbolo utile simbolo generatore e raggiungibile.\nCos√¨ andiamo a racchiudere il concetto di simbolo che non genera nulla, come inutle\nEsempio in slide !\nCalcolo dei simboli generatori üü©- Slide !\nOssia se da un simbolo ricavo qualcosa che √® un generatore, allora questo √® un generatore!\nE posso creare un algoritmo ricorsivo che genera questi simboli, partendo dai terminali che sono sempre dei generatori\nCalcolo dei simboli raggiungibili üü®++ Slide\nIn pratica mi calcolo, ancora qui in modo ricorsivo, tutti i strumenti raggiungibili dal nodo di start, con qualcosa di simile a una dfs (aggiungo ai raggiungibili ogni non terminale figlio, e comincio ad esplorare questo non terminale).\nWrap-up (chiede) üü®+ Enunciato e dimostrazione\nL‚Äôalgoritmo √® molto semplice, √® costituito da due passi fondamentali:\nElimino tutti i simboli che non sono generatori Rimuovo tutti i simboli non raggiungibili Nota sull‚Äôordine\n√à importante eseguire le operazioni in questo ordine, altrimenti capita come in slide\nEsempio importanza di ordine\nEsempio pi√π tosto di applicazione di questo\nEliminazione rico sinistre Rico sinistre immediate üü® Slide\nL\u0026rsquo;idea √® spaccare la ricorsione sinistra in una altra produzione e un nuovo non terminale fittizzio che vado ad utilizzare come non terminale di supporto.\nEsempio di risoluzione\nPosso considerare queste immediate, quando non ho dei cicli chiari nelle ricorsioni sinistre, sotto proviamo a creare un algoritmo per risolvere ricorsioni sinistre con cicli.\nRico sinistre non-immediate üü•+ Esempio di non-immediato\nAlgoritmo di risoluzione O(n2)\nIn pratica provo a sostituire tutto quanto posso in modo greedy.\nEsempio di applicazione\nEsempio applicazione con tutto finora\nFattorizzazione üü© Slide problema generale\nL‚Äôintuizione per sta parte √® raccogliere le cose in comune. L‚Äôalgoritmo non va a far altro che guardare i prefissi, e prendere il pi√π lungo per ogni non terminale.\nAlgoritmo per fattorizzazione\nesempio di applicazione\nForme normali Chomsky Normal Form Slide\nQuesta ci piace, perch√© le produzioni o sono di\nSIngolo terminale Doppio non terminale. Si pu√≤ notare che questa forma √® sia libera da epsilon sia sia libera da coppie unitarie.\nE si pu√≤ sempre trovare una grammatica in questa forma, questa cosa ci piace.\nGreibach Normal Form Slide\nAnche questa si pu√≤ sempre fare, ed √® una forma che ci piace perch√© non abbiamo derivazione ricorsive sinistre brutte che ci distruggono tutto.\n","permalink":"https://flecart.github.io/notes/semplificazione-grammatiche/","summary":"\u003ch2 id=\"gestione-del-non-determinismo\"\u003eGestione del non determinismo\u003c/h2\u003e\n\u003cp\u003eIl modo pi√π facile per gestire il non determinsmo √® \u003cstrong\u003esemplificare le grammatiche\u003c/strong\u003e quindi andiamo a vedere metodi per fare ci√≤.\u003c/p\u003e\n\u003ch3 id=\"semplificazione-grammatiche-5\"\u003eSemplificazione grammatiche (5)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Semplificazione grammatiche/Untitled 1.png\" alt=\"image/universita/ex-notion/Semplificazione grammatiche/Untitled 1\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003eNo produzioni del tipo $A \\to \\varepsilon$ per bottom up (altrimenti va all‚Äôinfinito!)\u003c/li\u003e\n\u003cli\u003eNo produzioni unitarie, cos√¨ evito cicli in cui da A derivo s√© stesso.\u003c/li\u003e\n\u003cli\u003eNo simboli inutili\u003c/li\u003e\n\u003cli\u003eNo ricorsione sinistra (divergenza per top-down)\u003c/li\u003e\n\u003cli\u003eFattorizzazione della grammatica\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"eliminazione-delel-produzioni-nulle\"\u003eEliminazione delel produzioni nulle\u003c/h2\u003e\n\u003cp\u003eVogliamo creare un algoritmo utile ad eliminare le produzioni che non ci piacciono.\u003c/p\u003e","title":"Semplificazione grammatiche"},{"content":"Sentiment analysis is one of the oldest tasks in natural language processing. In this note we will introduce some examples and terminology, some key problems in the field and a simple model that we can understand by just knowing Backpropagation Log Linear Models and the Softmax Function.\nWe say:\nPolarity: the orientation of the sentiment. Subjectivity: if it expresses personal feelings. See demo\nSome applications: Businesses use sentiment analysis to understand if users are happy or not with their product. It\u0026rsquo;s linked to revenue: if the reviews are good, usually you make more money. But companies can\u0026rsquo;t read every review, so they want automatic methods.\nOther applications are opinion mining: if you like a politician or not. Spam detection. Recommender systems.\nA simple solution: MLP Traditionally you define a set of features and then try to log linear model to get a result. This is a complicated pipeline to get this result. A surprising result from Iyyer (2015) says we just need a bag of words model and an MLP to get good result. Over 90% accuracy they say!. With this solution you just:\nPool the embeddings of the input sequence tokens. Pass this to MLP layers Softmax at the end. Currently, we can have the same thing asking ChatGPT and it also works quite well. (Prof. Cotterell says it could have been trained on this kind of tasks). With 2-3 layers it works the best! And it seems the network is very sentitive to the sentiment of the kind of word that is used e.g. (okay, good, terrible etc\u0026hellip;).\n","permalink":"https://flecart.github.io/notes/sentiment-analysis/","summary":"\u003cp\u003eSentiment analysis is one of the oldest tasks in natural language processing. In this note we will introduce some examples and terminology, some key problems in the field and a simple model that we can understand by just knowing \u003ca href=\"/notes/backpropagation/\"\u003eBackpropagation\u003c/a\u003e \u003ca href=\"/notes/log-linear-models/\"\u003eLog Linear Models\u003c/a\u003e and the \u003ca href=\"/notes/softmax-function/\"\u003eSoftmax Function\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWe say:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePolarity:\u003c/strong\u003e the orientation of the sentiment.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSubjectivity:\u003c/strong\u003e if it expresses personal feelings.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSee \u003ca href=\"http://text-processing.com/demo/sentiment\"\u003edemo\u003c/a\u003e\u003c/p\u003e\n\u003ch4 id=\"some-applications\"\u003eSome applications:\u003c/h4\u003e\n\u003cp\u003eBusinesses use sentiment analysis to understand if users are happy or not with their product. It\u0026rsquo;s linked to revenue: if the reviews are good, usually you make more money. But companies can\u0026rsquo;t read every review, so they want automatic methods.\u003c/p\u003e","title":"Sentiment Analysis"},{"content":"Questo √® un tentativo di aggiungere un argomento che non era presente quando abbiamo fatto il corso due anni fa. Inizio la scrittura il 2024-03-03. Questo non √® stato trattano nel corso, ma √® importante per molte cose. Quindi introduco questo appunto.\nIntroduzione alle serie Le serie infinite sono dei mostri strani perch√© non si comportano spesso come dovrebbero.\nDefinizione di convergenza $$ \\lim_{ n \\to \\infty } f_{n} = c $$ con $c$ un numero reale.\nResto di serie convergenti Sia data una serie convergente, allora $\\forall \\varepsilon$ esiste un $N_{0} \\in \\mathbb{N}$ per cui $\\sum_{n = N_{0}}^{\\infty} a_{n} \u003c \\varepsilon$\nIntuitivamente questo lemma ci dice che la maggior parte del contributo alla somma viene fatta dalla prima parte della serie.\n$$ \\forall\\varepsilon ,\\exists N_{0} \\in N: \\forall N \\geq N_{0}, \\left\\lvert \\sum_{n=1}^{N}a_{n} - c \\right\\rvert \u003c \\varepsilon $$$$ \\lim_{ N \\to \\infty } \\sum_{n=1}^{N} a_{n} = \\sum_{n=1}^{\\infty}a_{n} = c $$$$ 0 = \\lim_{ n \\to \\infty } b_{n} =\\lim_{ n \\to \\infty } (c - f_{n}) = \\lim_{ n \\to \\infty } \\sum_{i= n + 1}^{\\infty} a_{i} $$ Ossia abbiamo la tesi. Qualcosa di simile lo facciamo anche in Spazi di probabilita per calcolo di up and down, ma non mi ricordo esattamente come si chiamano. La nota sul resto, solitamente ci permette di ricondurci a un caso discreto per le serie convergenti, e diventa quindi utile per tornare sul discreto, molto spesso.\nCauchy Convergence Limit Comparison Test $$ \\lim_{ n \\to \\infty } \\frac{a_{n}}{b_{n}} = c $$ Si hanno due casi possibili per il valore di $\\sum_{i=1}^{+\\infty}a_{n}$ e di $\\sum_{i=1}^{+\\infty}b_{n}$\nEntrambi convergono a un valore $c$ Entrambi divergono Questo √® abbastanza intuitivo se pensiamo che l\u0026rsquo;ipotesi ci sta dicendo che al limite le due successioni distano al massimo di un fattore reale. Se divergono, e distano di un fattore reale, anche l\u0026rsquo;altro dovr√† divergere, se invece converge, anche l\u0026rsquo;altro dovr√† convergere.\nLa dimostrazione credo passa dalla definizione di limite per successioni presente in Successioni#3.2 Limiti di successioni.\nLimit definitions $$\\forall \\varepsilon \u003e 0, \\exists N \\in \\mathbb{N} \\text{ such that } \\forall n \\geq N: |a_n - L| \u003c \\varepsilon$$$$\\forall \\varepsilon \u003e 0, \\exists N \\in \\mathbb{N} \\text{ such that } \\forall m,n \\geq N: |a_m - a_n| \u003c \\varepsilon$$Equivalence of limit definitions A sequence $(a_n)$ in $\\mathbb{R}$ converges if and only if it is Cauchy.\nProof: ($\\Rightarrow$) First, let\u0026rsquo;s prove that convergent implies Cauchy:\nSuppose $(a_n)$ converges to $L$. Let $\\varepsilon \u003e 0$ be given.\n$$|a_n - L| \u003c \\frac{\\varepsilon}{2} \\text{ for all } n \\geq N$$ Then for any $m,n \\geq N$:\n$$ \\begin{align*} |a_m - a_n| \u0026amp;= |a_m - L + L - a_n| \\ \u0026amp;\\leq |a_m - L| + |L - a_n| \\text{ (triangle inequality)} \\ \u0026amp;\u0026lt; \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} \\ \u0026amp;= \\varepsilon \\end{align*}\n$$\nTherefore, $(a_n)$ is Cauchy. ($\\Leftarrow$) Now, let\u0026rsquo;s prove that Cauchy implies convergent:\nSuppose $(a_n)$ is Cauchy. We need to show it converges.\n$$|a_m - a_n| \u003c 1 \\text{ for all } m,n \\geq N_1$$ $$|a_n| \\leq |a_{N_1}| + 1$$ So the sequence is bounded.\nBy the Bolzano-Weierstrass theorem, $(a_n)$ has a convergent subsequence $(a_{n_k})$. Let\u0026rsquo;s say it converges to $L$.\nNow, let $\\varepsilon \u003e 0$ be given. Choose $N$ large enough so that:\n$|a_m - a_n| \u003c \\frac{\\varepsilon}{2}$ for all $m,n \\geq N$ (Cauchy property) $|a_{n_k} - L| \u003c \\frac{\\varepsilon}{2}$ for all $n_k \\geq N$ (subsequence convergence) $$ \\begin{align*} |a_n - L| \u0026\\leq |a_n - a_{n_k}| + |a_{n_k} - L| \\\\ \u0026\u003c \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} \\\\ \u0026= \\varepsilon \\end{align*} $$ where $n_k$ is chosen large enough ($\\geq N$).\nTherefore, $(a_n)$ converges to $L$.\nThis completes the proof. The key insight is that:\nConvergence ‚Üí Cauchy is relatively straightforward using the triangle inequality Cauchy ‚Üí Convergence requires the completeness of $\\mathbb{R}$ (via Bolzano-Weierstrass) Serie Armonica Definizione $$ \\sum_{n=1}^{+\\infty} \\frac{1}{n} $$$$ \\sum_{i=1}^{+\\infty} \\frac{1}{i} = \\lim_{ n \\to \\infty } \\sum_{i = 1}^{n}\\frac{1}{i} \\geq \\lim_{ n \\to \\infty } \\int _{1}^{n} \\frac{1}{x} \\, dx = \\lim_{ n \\to \\infty } \\ln(n) = +\\infty $$ Ma la parte importante √® il rate di crescita della serie armonica.\nTest per Serie Ereditariet√† delle propriet√† $$ f_{n} = \\sum_{n=1}^{\\infty} \\frac{\\sin(3^{n}x)}{2^{n}} $$ Non soddisfa la propriet√†, perch√© questa serie converge assolutamente tramite l\u0026rsquo;osservazione che $f_{n} \\leq \\frac{1}{2^{n}}$, per questo esempio specifico, possiamo dire che la serie converge grazie al bound, ma se facciamo la derivata, questa diverge (che √® abbastanza assurdo).\nSi pu√≤ fare anche l\u0026rsquo;esempio opposto, ossia possiamo definire una funzione per cui termine a termine siano integrabili, mentre nel totale non lo sono.\nConvergenza Totale $$ f: I \\to \\mathbb{R}, f = \\sum_{n=1}^{\\infty} f_{n}(x) $$Ces√†ro mean Sia data una sequenza $a_{n} \\to a$ allora la sequenza della media converge in $a$ anch\u0026rsquo;essa, in formule abbiamo:\n$$ \\lim_{ n \\to \\infty } \\frac{1}{n} \\sum_{i=1}^{n} a_{i} = a $$Dimostrazione: Se $a_{n} \\to a$ allora abbiamo che per ogni $\\varepsilon$ esiste un $N$ per cui per ogni $n \u003e N$ si avr√† che $\\lvert a_{n} - a \\rvert \\leq \\varepsilon$.\n$$ \\left\\lvert \\frac{1}{n} \\sum_{i = 1}^{n} a_{i} - a \\right\\rvert \\leq \\varepsilon $$L\u0026rsquo;idea generale √® che usando l\u0026rsquo;idea precedente, possiamo ignorare gli elementi da $N$ in poi perch√© saranno sempre abbastanza vicini alla media, mentre pi√π facciamo salire il valore di $M$ pi√π la parte importante perder√† di valore.\nQuindi mettiamo a nostra scelta un $\\varepsilon_{1}$ per cui la prima definizione valga, allora avremo un $N$ per cui la differenza sia minore di essa, mettiamo che $n \u003e N$. avremo:\n$$ \\begin{align} \\frac{1}{n}\\left\\lvert \\sum_{i = N}^{n} (a_{i} - a) + \\sum_{i = 0}^{N}(a_{i} - a) \\right\\rvert \u0026amp;\\leq \\frac{1}{n} \\left\\lvert (n - N)\\varepsilon_{1} + \\sum_{i = 0}^{N}(a_{i} - a) \\right\\rvert \\ \u0026amp;\\leq \\left\\lvert \\left( 1 - \\frac{N}{n} \\right)\\varepsilon_{1} \\right\\rvert + \\frac{ \\lvert C_{N} \\rvert }{n} \\ \u0026amp;\\leq \\varepsilon_{1}+ \\frac{ \\lvert C_{N} \\rvert }{n} \\\n$$ Where we have chosen $\\varepsilon_{1}$ such that $\\varepsilon_{1} \u003c \\varepsilon$ and $n \u003e M$ with $M$ such that: $$ M \\geq \\frac{\\lvert C_{n} \\rvert }{\\varepsilon - \\varepsilon_{1}} $$\nProof of the Inverse In questo caso abbiamo che la media di Ces√†ro converge come vorremmo, dobbiamo dimostrare che anche $a_{n}\\to a$.\n$$ \\lvert a_{n} - a \\rvert \\leq \\varepsilon $$$$ \\begin{align*} A_N \u0026= \\frac{1}{N} \\sum_{n=1}^N a_n \\\\ \\Rightarrow \\left| A_N - L \\right| \u0026= \\left| \\frac{1}{N} \\sum_{n=1}^N (a_n - L) \\right| \\\\ \u0026\\leq \\frac{1}{N} \\sum_{n=1}^N \\left| a_n - L \\right| \\quad \\text{(Triangle inequality)}. \\end{align*} $$ Then it\u0026rsquo;s easy to conclude.\n","permalink":"https://flecart.github.io/notes/serie/","summary":"\u003cp\u003eQuesto √® un tentativo di aggiungere un argomento che non era presente quando abbiamo fatto il corso due anni fa. Inizio la scrittura il 2024-03-03. Questo non √® stato trattano nel corso, ma √® importante per molte cose. Quindi introduco questo appunto.\u003c/p\u003e\n\u003ch2 id=\"introduzione-alle-serie\"\u003eIntroduzione alle serie\u003c/h2\u003e\n\u003cp\u003eLe serie infinite sono dei mostri strani perch√© non si comportano spesso come dovrebbero.\u003c/p\u003e\n\u003ch3 id=\"definizione-di-convergenza\"\u003eDefinizione di convergenza\u003c/h3\u003e\n$$\n\\lim_{ n \\to \\infty }  f_{n} = c\n$$\u003cp\u003e\ncon $c$ un numero reale.\u003c/p\u003e","title":"Serie"},{"content":"Ripasso Prox: 80 Ripasso: May 21, 2023 Ultima modifica: March 12, 2023 10:00 AM Primo Abbozzo: October 8, 2022 11:30 AM Stato: üåïüåïüåïüåïüåë Studi Personali: No\nElementi di ripasso 2 Sezioni Critiche Introduzione La parte di un programma che utilizza una o pi√π risorse condivise viene detta sezione critica (critical section, o CS)\nAndiamo in questa altra parte a valutare certe soluzioni:\nProgramma d‚Äôesempio üü© Vorremmo garantire che a = b invariante. (espressione logica verificata nell\u0026rsquo;esecuzione di questo programma). quindi una coerenza di uno prima dell\u0026rsquo;altro vogliamo.\nNon funziona lasciare la gestione dell\u0026rsquo;invarianza al sistema operativo o al compilatore perch√© manca questa informazione (quindi non abbiamo potere per la gestione dell‚Äôordine in questo caso.\nRequisiti per le CS (5) üü©‚Äî‚Äî Vogliamo ora cercare di listare le propriet√† delle critical sections in modo teorico, per implementare un programma che riesca ad implementare la critical section.\nSlide requisiti\nSafety:\nMutua esclusione, solo uno all\u0026rsquo;interno della CS No deadlocks Liveness:\nUn processo fuori dalla CS non dovrebbe ritardare l‚Äôentrata di un altro programma Un processo eventualmente deve entrarci Altro:\nNessun processo pu√≤ terminare in una critical section (secondo me perch√© si porterebbe la risorsa critica con s√©, nel senso che nessun altro programam pu√≤ utilizzarlo, suppongo. Questo si pu√≤ associare al principio 4 di Liveness. Algoritmo di Dekker Listo qua in breve le idee principali che daranno vita all‚Äôalgoritmo\nTurni per disambiguare chi pu√≤ entrare e chi vuole entrare Booleani per esprimere il concetto di voler entrare. Dare la precedenza all‚Äôaltro. Soluzioni provate e non funzionanti üü©- (prolly non richiede) Soluzione 1 (busy waiting esterno con i turni)\nNon √® buona perch√© viola il principio 3 del non rallentamento. Pu√≤ succedere che nessuno √® dentro la sezione critica, ma uno non ci pu√≤ entrare finch√© l‚Äôaltro non ci entra ed esce (ma pu√≤ essere che l‚Äôaltro sia molto pi√π lento!)\nSoluzione 2 (busy waiting esterno con 2 booleani)\nIl problema √® che possono entrambi entrare nella soluzione critica, quindi non √® mutex e quindi non √® una soluzione\nSoluzione 3 (2 booleani, assegnamento prima)\nPu√≤ accadere un deadlock, viola principio 4\nSoluzione 4 (livelook, assegnamenti nel busy waiting)\nPu√≤ accadere starvation in questo problema nel requisito 4, ossia uno non entra mai.\nl‚Äôalgoritmo üü® Questo √® un algoritmo che funziona per implementare le sezioni critiche.\nAndremo in questa parte a considerare moltissime soluzioni che non soddisfano i requisiti esplicitati precedentemente, fino a raggiungere l‚Äôalgoritmo di dekker. (Questo √® proprio il processo seguito da Dijkstra nel raggiungimento della soluzione!)\nAlgoritmo di Dekker\nDimostrazione correttezza di Dekker üü©- Mutua esclusione\nMutua esclusione\nIn pratica si riduce che in un certo momento deve esserci un momenti in cui uno √® nella critical section, e il valore di need associato deve essere falso. Ci√≤ √® impossibile, devo essere eseguite entrambe le istruzioni di uscita!\nAssenza di deadlock\nSlide\nAssenza di ritardi\nSlide\nAssenza di starvation\nSlide\nAlgoritmo di Peterson Descrizione dell‚Äôalgoritmo üü©‚Äî Slide\nAlgortitmo generalizzato üü• Slide peterson generalizzato (non so perch√© funzioni, comunque il prof. lo ha saltato).\nTODO: se vuoi fare bene questo pezzo sarebbe anche Peterson\n√à una cosa molto pi√π compatta rispetto Dekker, e l\u0026rsquo;idea principale √® che il turno √® stabilito prima di entrare nel while\nDimostrazione correttezza di Peterson üü© Mutua esclusione\nSlide\nAssenza deadlock\nSlide\n√à quasi ovvio perch√© turn non pu√≤ avere due variabili diverse\nAssenza di ritardi\nSlide\nAssenza di starvation\nSlide\nSoluzioni hardware Perch√© √® meglio di software (3) üü®- Si preferirebbero delle soluzioni hardware perch√© tutte le soluzioni software fanno utilizzo di busy waiting che √® molto dispendioso.\nDispendioso dal punto di vista della CPU per il busy waiting Difficile da implementare senza bug (difficile da testare) Gestione delle responsabilit√† a livello software (cosa che non si vuole) Disabilitazione interrupt (2) üü© Cos√¨ non posso passare ad un altro processo all\u0026rsquo;inizio di una sezione critica. (ma c\u0026rsquo;√® il problema dei multicore perch√© dovrei disabilitarlo per tutti!).\nCi sono altri motivi per cui questa √® una brutta soluzione:\nLasciare la gestione degli interrupt ai programmi perch√© agisce sull\u0026rsquo;intera macchina, ma non dovrebbe avere questo diritto. Multicore dovrebbero essere sincronizzati su questo aspetto (quindi difficolt√† di parallelizzazione). Quindi non posso essere interrotto Non funziona su multicore perch√© anche se li disabilito su entrambi, pu√≤ esser che due processi lavorano sempre con la stessa sezione critica Test \u0026amp; set (spin lock) üü©- L‚Äôhardware ha delle istruzioni in pi√π che aiutano a creare l‚Äôimplementazione per le sezioni critiche.\nProgramma con test e set\nDimostrazione di correttezza (senza starvation)\nOltre a questo si pu√≤ implementare con altre istruzioni atomiche come fetch and set, compare and swap.\nCS con swap e divisione üü©- Protocollo entrata con swap\nlock = 0; do { v = 1; swap(v, lock); } while(v); Chiaramente posso entrare quando lock √® 0, altrimenti lock √® sempre 1.\nProtocollo entrata con divisione\nlock = 2 do v = \u0026lt; lock /= 2 \u0026gt; while (v != 1) Con questo abbiamo raggiunto una notevole semplificazione nella programmazione (ed anche della generalizzazione di questa soluzione), ma non sono risolti i problemi di starvation n√© busy waiting, ancora fortemente inefficiente.\n","permalink":"https://flecart.github.io/notes/sezioni-critiche/","summary":"\u003cp\u003eRipasso Prox: 80\nRipasso: May 21, 2023\nUltima modifica: March 12, 2023 10:00 AM\nPrimo Abbozzo: October 8, 2022 11:30 AM\nStato: üåïüåïüåïüåïüåë\nStudi Personali: No\u003c/p\u003e\n\u003ch1 id=\"elementi-di-ripasso\"\u003eElementi di ripasso\u003c/h1\u003e\n\u003ch1 id=\"2-sezioni-critiche\"\u003e2 Sezioni Critiche\u003c/h1\u003e\n\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eLa parte di un programma che utilizza una o pi√π risorse\ncondivise viene detta sezione critica (critical section, o CS)\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eAndiamo in questa altra parte a valutare certe soluzioni:\u003c/p\u003e\n\u003ch3 id=\"programma-desempio-\"\u003eProgramma d‚Äôesempio üü©\u003c/h3\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Sezioni Critiche/Untitled.png\" alt=\"image/universita/ex-notion/Sezioni Critiche/Untitled\"\u003e\n\u003cp\u003eVorremmo garantire che \u003cstrong\u003ea = b invariante.\u003c/strong\u003e (espressione logica verificata nell\u0026rsquo;esecuzione di questo programma). quindi una coerenza di uno prima dell\u0026rsquo;altro vogliamo.\u003c/p\u003e","title":"Sezioni Critiche"},{"content":"Obiettivi della sicurezza (!!!) üü© Vogliamo creare delle reti che abbiamo certe garanzie di sicurezza, soprattutto:\nConfidenzialit√†, non vorremmo che il nostro messaggio sia intercettabile e leggibili da persone intermedie Integrit√†: non vogliamo che messaggi possano essere cambiati senza intervento del sender Autenticazione: vorremmo sapere con chi stiamo parlando, e vorremmo essere sicuri che non stiano mentendo sull‚Äôidentit√†. Sicurezza operativa(Availability): vorremmo essere in grado di poter continuare a fornire il servizio (quindi non sia possibile dossare, o installare malware che modifichino il comportamento del servizio). Questi sono stati trattati un po\u0026rsquo; in Theoretical Notions of Security.\nQuesti principi possono essere messe in pratica con specifiche politiche nella fase di invio dei messaggi, implementate nei vari livelli o firewall per poter identificare tentativi di intrusione.\nCome vengono raggiunti questi obiettivi\nVedremo in seguito che il primo obiettivo viene raggiunto senza molti problemi utilizzando la crittografia, mentre le altre due con le funzioni di hashing. Il quarto con la creazione di protocolli solidi.\nUn principio di sicurezza üü© La sicurezza del messaggio non dovrebbe essere basato sull\u0026rsquo;algoritmo utilizzato per codificare, ma solamente sull\u0026rsquo;utilizzo della chiave.\nIl primo √® molto facile da recuperare, o farci reverse engineering, ne abbiamo parlato qui in breve Classical Cyphers#On security of cipher\nTipologie di attacchi (!!) üü® Se √® possibile l‚Äôattaccante pu√≤ avere moltissimi vettori di attacchi che possono incrinare i principi di sicurezza che abbiamo enunciato sopra\neavesdrop: spiare la conversazione (eventualmente rubando password e dati) Impersonation: impersonare un altro soggetto (o la macchina di un soggetto). Hijacking dirottare una sessione in corso, quindi controllare le richieste che fai, magari ti mando su una copia di paypal falsa, o Denial of service: negare il servizio agli utenti legittimi, questo sulla sicurezza operativa. Crittografia La crittografia diventa una delle tecnologie chiave per poter garantire i principi di sicurezza.\nAlcune tipologie di cifrari simmetrici üü© Approfonditi in Block Ciphers che solitamente sono utilizzati negli scambi di messaggi simmetrici. Elenco qui alcuni cifrari classici:\nCifrario mono-alfabetico (sostituzione) (come codice cesare, in cui c¬¥√® una mappatura per ogni singola lettera ad altra lettera). Cifrario poli-alfabetico (in cui la criptazione dipende anche dalla posizione). Cifrario a blocchi, come DES, AES etc. Importante diventa anche l‚Äôhashing, che serve un sacco per poter mantenere l‚Äôintegrit√† del messaggio.\nIl problema principale di questo metodo √® lo scambio delle chiavi, che dovrebbe essere sicura anche questa parte. Ma solitamente cifrari asimmetrici come RSA risolvono questa parte.\nLa soluzione ottima per questo metodo √® utilizzare un sistema a chiave pubblica PKI per scambiarsi la chiave privata con cui continuare le transazioni da l√¨ in poi.\nTipologie di attacco üü© i principali metodi di attacco sono\nCipher-text only attack:\nForza bruta, in cui cerco la chiave Statistical analysis attack (per cercare alcuni pattern che possono esistere per rompere il cifrario). Oltre a questi ho anche classici attacchi col plain text: chosen-plaintext attack, known plaintext attack, questi mi permettono un p√≤ pi√π informazioni. Se si ha segretezza perfetta come per OTP allora √® sicuro, ma √® difficile averlo.\nChiavi di sessione e RSA üü© Si √® parlato di questo ambito per abbastanza, ma non la ritengo molto interessante quindi non la metto, √® per√≤ molto importante, ma credo tu sappia come funzioni quindi non la scrivo.\nSemmai due note sulle chiavi di sessione, √® molto semplice, in pratica dato che RSA √® molto pi√π lento e costoso (in termini di energia) dei cifrari a chiave simmetrica utilizzo RSA per scambiarmi la chiave con cui faccio la crittazione simmetrica, questa √® la chiave di sessione.\nda notare che la combinazione di Cifrari simmetrici e asimmetrici riescono a dare forti garanzie (non assolute, perch√© i cifrari possono essere comunque rotti) di confidenzialit√† fra le persone.\nAutenticazione Protocollo di autenticazione üü© Il libro prova a costruire passo passo un protocollo di autenticazione (cio√® una serie di passaggi che finiscono per riuscire ad asserire l\u0026rsquo;identit√† con cui si stia comunicando).\nProtocolli di autenticazione passo passo Dato che lo scambio di password √® sempre vulnerabile a playback attack. Ci costruiamo un segreto temporaneo, la nonce, che √® una mini specie di challenge utilizzata per convincere dell\u0026rsquo;identit√†. Se provo a rimandare la nonce criptata con una chiave privata, allora potrei dire che sono ALICE.\nE dato che la nonce √® unica, non √® vulnerabile a playback attack.\nUltimo protocollo con NONCE e PKI\nR √® la nonce\nNel nuovo sistema con la nonce e il sistema chiave pubblica e chiave privata √® ancora vulnerabile a MITM. Dato che Eve pu√≤ sempre mettersi in mezzo, e praticamente avere in chiaro tutti i collegamenti, dovremmo cercare di identificare in qualche modo la chiave pubblica della identit√† giusta. (devo prendere la chiave pubblica da un servizio fidato, queste sono le certification autorities, CA).\nCertificate authorities üü© Sono dei servizi utili ad identificare l\u0026rsquo;identit√† di una persona, e sono in grado di giustificare la corrispondenza della chiave pubblica con una certa identit√†. Generano per te la chiave pubblica E privata. Per protocolli come TLS-SSL protocol sono fondamentali.\nOvviamente la sicurezza dipende dai processi di autenticazione di questa CA (potrebbe chiederti la carta d\u0026rsquo;identit√†, o altre informazioni simili), che potrebbe essere vulnerabile anche essa. (nella storia sono anche stati hackerati, quindi hanno molte coppie di chiavi messe a gente falsa).\nIntegrit√† del messaggio üü© Potremmo utilizzare il PKI, per firmare con la nostra chiave privata (e poi CA per trovare la chiave pubblica per poter verificare il messaggio) in questo modo il nostro interlocutore √® sicuro dell‚Äôintegrit√† del nostro messaggio e dell‚Äôautenticit√† di chi me lo sta mandando (con le CA).\nSe poi si fa la stessa cosa mandando un messaggio gi√† cifrato, allora ho anche segretezza, senza nessun problema!\nMa poi, dato che √® molto costoso firmare un messaggio tanto lungo, solitamente si firma solamente l\u0026rsquo;hash del messaggi originale, quindi rende molto pi√π efficiente il protocollo. ma anche il fatto che in questo modo posso firmare messaggi molto corti! Ho sempre un codice della stessa linguaggio.\nFunzione di hashing üü© Ci sono un sacco di caratteristiche che dovrebbero tutte le funzioni di hashing soddisfare\nUn digest fisso, di una certa lunghezza. Pre-image collision, dovrebbe essere difficile trovare un altro messaggio con lo stesso hash. Una propriet√† che dovrei soddisfare √® il fatto che se cambio un bit di input cambi di molto l\u0026rsquo;output, ossia ci sia pochissima correlazione fra input e output! (certamente cose lineari non ci piacciono) Esempio di hash brutto Internet checksum\nUn esempio di hash brutto √® l\u0026rsquo;internet checksum perch√© √® molto facile poter creare una collisione!\n√à in grado di rilevare solamente errori idioti (quelli fatti senza l\u0026rsquo;intelligenza di un EvE che prova a cambiarti i bit, ma sono abbastanza random!)\nProtocollo Mail sicura üü© \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 9.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 9\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 10.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 10\u0026quot;\u0026gt; Praticamente generiamo una chiave simmetrica, poi se vogliamo firmarla e metterci un coso di integrit√† MAC possiamo farlo, cifriamo con chiave pubblica di bob presa da CA la nostra chiave e mandiamo il pacco con Messaggio privato, magari firmato, e chiave criptata.\nBob riceve e riesce a ricavare tutto quanto possibile per verificare l‚Äôintegrit√† del messaggio e comprendere il messaggio!\nProtocollo SSL Trattato un po\u0026rsquo; meglio (con altri dettagli) in TLS-SSL protocol Se rendiamo il socket sicuro, rendiamo sicuro tutto quello che c\u0026rsquo;√® sotto, quindi dal livello 4 in gi√π, vedi Architettura e livelli 1, 2 per dettagli sulla stack. In questo modo le applicazioni possono decidere se utilizzare o meno questo protocollo, dato che √® sotto di essa.\nSlide presentazione ssl\nImplementazione Toy-SSL üü®+ Utilizzando il sistema presentato sopra riescono a cambiare un segreto (come una chiave condivisa per comunicare, ma sar√† un robo per creare un set di chiavi, o il vettore di inizializzazione)\nIl set di chiavi sono utilizzati per invio direzionale e verifica di integrit√† direzionale (quindi sono 4 chiavi). Che sono generate dalla Master Key scambiata dalla prima fase.\nCARATTERISTICHE PACCHETTI SSL üü•\nDurante il trasferimento dei dati vogliamo avere anche altre caratteristiche che aiutino a mantenere la sicurezza di questo protocollo:\nNumerazione per evitare che eve duplichi pacchetti o simili. Verifica di integrit√† ha un proprio hash MAC (hashato √® anche la numerazione a livello SSL). Slide record and sequence numbers COMMON ATTACKS\nReorder attack, utilizzo le sequence numbers per numerare i records, cos√¨ sono sicuro che non pu√≤ riordinare dato che non possiede le chiavi\nReplay attack riutilizzo anche in questo momento le nonce\nTruncation attack vogliamo anche avere un modo per terminare in modo sicuro la comunicazione, cio√® non dovremmo permettere a Eve di terminare la comunicazione per noi. Per fare questo mettiamo anche una parte tipologia di messaggio in ogni MAC. (importante il fatto che √® su due versi la chisura!)\nImplementazione SSL (skip) Questo √® uguale al toy SSL alla fine‚Ä¶ Solo con qualche accorgimento in pi√π, non √® importante sta parte\nhandshake √® leggermente pi√π complicato, c‚Äô√® anche una fase di autenticazione dell\u0026rsquo;utente e scelta dell‚Äôalgoritmo crittografico asimmetrico. Alla fine mando anche MAC di tutti i messaggi di handshake per prevenire tampering, come l‚Äôeliminazione degli algoritmi pi√π forti per poter provare a bruteforcare meglio. Record Format in questo modo si chiamano i pacchetti di SSL, contengono cose simili a quanto abbiamo descritto per il toy SSL\nLa cosa particolare √® che i dati e il mac sono entrambi criptati con la chiave simmetrica che abbiamo derivato prima, in modo simile a quanto fatto dal toy-SSL.\nIPsec Moved to IPSec protocol\nFirewalls Vogliamo cercare di filtrare quello che entra dall\u0026rsquo;esterno. mentre in generale ci fidiamo di quello che √® presente all‚Äôinterno del firewall (quindi se riesco a controllare una macchina che sia dentro avrei pieno accesso).\nObiettivi dei Firewalls üü®- L‚Äôobiettimo principale dei Firewalls √® proteggere da attacchi esterni, esempi di attacchi potrebbero essere\nVorrei evitare DoS, ossia permettere senza problemi di aprire delle porte TCP senza andare a chiuderne una. Non devo permettere la modifica arbitraria dei dati (che hanno conseguenze penali credo) Permettere l‚Äôaccesso solamente a utenti autenticati Per fare ci√≤ possono avere a disposizione tre tipologie di firewalls, quelly che iltrato senza avere uno stato quelli con uno stato, ma anche le application gateways (che controllano il contenuto di quello che esce e quello che entra).\nSlide obiettivi\nAccess control List üü®+ \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 29.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 29\u0026quot;\u0026gt; In sede diversa, questa strategia √® stata analizzata anche in analisi delle autorizzazioni nei sistemi operativi. Vedi Sicurezza OS. Vogliamo permettere certe cose, e negarne altre. La ACL √® solamente una lista di regole di permessi e negazioni, con specificazione di source, address, protocollo, porta di arrivo e di partenza e flag‚Ä¶\nCon queste regole posso implementare senza problemi il Stateless filtering\nStateless/Stateful Packet filtering üü© Alcuni pacchetti vengono droppati quando ci sono certe informazioni all\u0026rsquo;interno del pacchetto.\nInformazione come Source e destination IP\nPort numbers for TCP or UDP\nICMP messages\nSyn and Ack bits, and maybe more\nSlides Stateless packet filtering\nMore examples of these Quando una cosa non ha molto senso da sola, e ha bisogno di tenere conto dello stato della connessione allora abbiamo bisogno di utilizzare uno stateful packet filtering in cui si monitora la storia della connessione TCP una volta che la connessione √® stata aperta.\nApplication gateway and IDS üü© Fanno a vedere il contenuto, e gli header dei pacchetti che provengono dall\u0026rsquo;interno. TODO meglio, il prof ha saltato.\nIntrusion detection systems /turn\nVogliamo cercare di capire se siamo sotto attacco, quindi se qualcuno fa port scanning, oppure packet filtering pesante da certe cose, oppure provare a vedere se il contenuto del pacchetto potrebbe essere dannoso.\nDemilitarized üü© https://doubleoctopus.com/security-wiki/network-architecture/demilitarized-zone/\nin pratica √® possiamo considerarla come una rete di appoggio per accedere a una rete untrusted esterna, come Internet.\nSolitamente in questa DMZ ci mettiamo cose come Email, web servers e cose simili. √à una zona quarantinata, cio√® per interagire col network interno si passa di nuovo d aun firewall, questo per garantire maggiore protezione della roba interna, solitamente molto pi√π importante.\n","permalink":"https://flecart.github.io/notes/sicurezza-delle-reti/","summary":"\u003ch3 id=\"obiettivi-della-sicurezza--\"\u003eObiettivi della sicurezza (!!!) üü©\u003c/h3\u003e\n\u003cp\u003eVogliamo creare delle reti che abbiamo certe garanzie di sicurezza, soprattutto:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eConfidenzialit√†\u003c/strong\u003e, non vorremmo che il nostro messaggio sia intercettabile e leggibili da persone intermedie\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIntegrit√†\u003c/strong\u003e: non vogliamo che messaggi possano essere cambiati senza intervento del sender\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAutenticazione\u003c/strong\u003e: vorremmo sapere con chi stiamo parlando, e vorremmo essere sicuri che non stiano mentendo sull‚Äôidentit√†.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSicurezza operativa\u003c/strong\u003e(Availability): vorremmo essere in grado di poter continuare a fornire il servizio (quindi non sia possibile dossare, o installare malware che modifichino il comportamento del servizio).\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eQuesti sono stati trattati un po\u0026rsquo; in \u003ca href=\"/notes/theoretical-notions-of-security/\"\u003eTheoretical Notions of Security\u003c/a\u003e.\u003c/p\u003e","title":"Sicurezza delle reti"},{"content":"Possiamo classificare tre aree generali quando si parla di sicurezza informatica:\nHardware Software human-ware. Non tratteremo in particolare esattamente come ogni campo viene declinato, per√≤ possiamo\nUna altra tendenza generale √® che pi√π √® complessa pi√π √® insicura. e questo senso di insicurezza cresce in modo maggiore rispetto al lineare.\nSecurity principles Open Design perch√© cos√¨ pu√≤ essere scrutata da pi√π persone Economy of mechanism spiegata sotto. Fail-safe defaults questo molto importante perch√© molti sistemi hanno dei default che possono essere exploitati. Complete mediation: cos√¨ abbiamo qualcosa che tracka tutti gli accessi, che controlla gli accessi. Least privilege questo va a braccetto con il fail-safe. Privilege separation cos√¨ possiamo mettere in modo indipendente un privilegio per qualcos\u0026rsquo;altro. CIA properties Ne abbiamo parlato in modo leggermente inverso in Sicurezza delle reti e in Theoretical Notions of Security. In questo caso sono\nAvailability Integrity Confidentiality √à cambiata solamente l‚Äôavailability, ossia la disponibilit√† in confronto alla sicurezza delle reti, in cui c‚Äôera l‚Äôautenticazione. Availability significa la disponibilit√† del servizio agli utenti, fare un DDoS per esempio √® una violazione di questo genere. La cosa difficile √® garantire tutti e 3.\nPoi ci sono anche AAA ossia\nAutenticazione Autorizzazione Accounting (logging delle tue operazioni). Violazione Nome Disclosure Alteration Denial of service Nel caso dell‚Äôautenticazione sarebbe il phishing, furto d\u0026rsquo;identit√† diciamo. Sistema politica e meccanismi Gi√† descritta in Architettura software del OS. l‚Äôidea √® la stessa, separazione meccanismi e la messa in atto di queste, solo che ora siamo in ambito sicurezza ora e non implementazione del kernel. L\u0026rsquo;idea generale √® che\nMeccanismo implementa la singola feature, come permesso di scrittura se possiedi certa flag, capability etc. Politica o policy, decide effettivamente quale meccanismo usare e in quale modo. Questo decoupling dovrebbe aiutare a rendere la cosa pi√π comoda. Crittografia √à una nota importante, ma in questa sede non andremo a trattarle Anche questo √® stato descritto in Sicurezza delle reti, pubbliche private, simmetriche asimmetriche, DES AES RSA e ora curve ellittiche etc. Puoi approfondire in OTP and Stream Ciphers, Block Ciphers e Asymmetric Cryptography. Simmetrica, in cui sapere la chiave sai tutto.\nTipologie di attacchi üü® Divisione per attivit√† dell‚Äôattaccante Per veicolo dell\u0026rsquo;attacco (se da dentro o da fuori) Obiettivi dell‚Äôattacco (quindi gravit√† della compromissione della macchina diciamo.\nAttacchi soliti Buffer overflow üü© Confrontare quanto presente con Memory Corruption, in cui andiamo ad approfondire molto meglio i dettagli degli attacchi di basso livello.\nTime of Check Time of use üü© Tipo access ha detto, quando non √® atomico il check e l‚Äôutilizzo, nel mezzo il file potrebbe essere cambiato\nTrojan horse üü© Virus e batteri üü® Solitamente questi virus hanno comportamenti classici, e si pu√≤ estrarre una firma, questo √® quello con cui utilizzano antivirus per checkare.\nAutenticazione Memorizzazione password üü© Salt Parlare di etc passwd ed /etc/shadow Abbiamo fatto qualche laboratorio carino sul cracking delle password l\u0026rsquo;anno seguente al corso di cybersecurity.\nLogin spoofing üü© Sniffersüü®+ Challenge based üü© Possiamo osservare i challenge based in Wireless attack vectors quando si parla di porte automatiche e\nSmart card and physical objects üü©- Pluggable Authetnication Moduleüü® \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza OS/Untitled 6.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza OS/Untitled 6\u0026quot;\u0026gt; I campi sono 2/3, si indica per chi si utilizza la policy, poi politiche della policy (se passa o meno o simili) e poi qualcosa di pam da utilizzare\nAutorizzazione Vogliamo dare i permessi alle persone (chi pu√≤ fare cosa). Solitamente dividiamo in tre possibili parti separate\nSoggetto: (a chi stiamo dando la possibilit√† di accedere alle nostre risorse?) Oggetto: cosa stiamo dando come permesso? Diritto: che genere di permesso stiamo dando al soggetto verso l\u0026rsquo;oggetto? Principi d‚Äôautorizzazione(4)üü®- Domini di accesso e ACL üü© Definiamo una riga per utente e in questa riga mettiamo tutti i permessi per questo utente.\nSlide Access control list\nExtended ACL Quando nelle acl Praticamente ogni posso associare dei permessi aggiuntivi che vanno ad ogni user del singolo gruppo. Poi queste sono passate da delle mask. In pratica mi permette di avere pi√π controllo sui permessi. In linux se viene utilizzato questo c‚Äô√® un + alla fine della lista permessi. si utilizzano comandi come getfactl per gestire queste credo.\nCapabilityüü© C‚Äô√® il concetto di capability ossia ogni risorsa deve essere associata una serie di diritti d‚Äôaccesso. Quando viene mantenuto in lato utente, in pratica viene cifrata con la chiave privata del root, e questo viene sempre verificato. (solitamente nei sistemi distribuiti viene utilizzato questo metodo (posso eliminare la capability)\nMa come eseguire la revoca della capability di questi servizi?\nEsempi di capabilities sono cookie, o file aperti. (in Unix sono molto comuni).\nFile descriptor table Quando un processo accede a un file, il file descriptor table non √® altro che una tabella con le capability del processo su quella risorsa. (descrive cosa ci puoi fare). La verifica del permesso √® fatta solo una volta (molto alta solitamente), ma quando √® messa nella tavola puoi farci tutte le letture e scritture che vuoi, ammortizzando il costo della verifica iniziale.\nRevoca delle capabilities Rimuovere una capability data √® spesso molto difficile. Abbiamo i quattro casi. Effective real and saved idsüü© Saved user e group id sono gli user id precedenti a quando si fa la chiamata setuid e simili, sono utilizzati per ripristinare il servizio. Si possono fare attacchi Toc Tou anche su questi checks (real sono quelli effettivi, dell‚Äôutente, mentre effettive sono i permessi utilizzati durante il momento di check).\nSpecial permission bits Sono\nSetuid su dir non fa niente, su file rende l\u0026rsquo;esecuzione come quello principale. Setgid su file rende possibile eseguire come gruppo, sulla directory d√† ai file creati qui lo stesso gruppo. Sticky-bit (permette l\u0026rsquo;eliminazione e movimento di file solamente al proprietario, ma il resto permette di fare come al solito) Discretionary Access Control DAC √® quello che solitamente viene usato, l\u0026rsquo;owner della risorsa d√† il permesso, che in pratica √® il sistema classico con gli ACL descritto sopra. Discretionary perch√© √® il singolo utente che decide se dare i permessi ad altri o meno\nMandatory Access Control MAC, mandatory access control (mandatory perch√© √® il sistema che definisce le regole e quelle sono, non le puoi cambiare), definisce delle regole generali del sistema e possono essere di due casi (quindi quando abbiamo MAC, ci sono ruoli di default.`\nBell La-padulaüü© Si basa sul principio che informazione va su (scrittura di nuove informazioni). Per esempio questa √® una cosa che √® stata fatta per prendere cose\nTop Secret Secret Public Seguono questo pattern casi in cui si vuole proteggere l\u0026rsquo;informazione. Bibaüü© √à l\u0026rsquo;opposto di Bell La-padula, perch√© la scrittura √® in gi√π, mentre la lettura in su. Il motivo di questo √® perch√© la scrittura rappresenta comandi, quindi devi mandarlo gi√π.\nCapitano Tenente Carabiniere Scelto Pi√π utilizzata in sistemi in cui l\u0026rsquo;integrit√† √® importante. Quindi sistemi in cui vogliamo dare l\u0026rsquo;ordine (informazione verso il basso).\nAccounting Si interessa dei sistemi di logging. Come per esempio il Journal che utilizzano tutti i servizi nel sistema operativo. In Ext4, forse citato in Filesystem viene trattato in breve.\nQuesta parte dovrebbe essere approfondita.\n","permalink":"https://flecart.github.io/notes/sicurezza-os/","summary":"\u003cp\u003ePossiamo classificare tre aree generali quando si parla di sicurezza informatica:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHardware\u003c/li\u003e\n\u003cli\u003eSoftware\u003c/li\u003e\n\u003cli\u003ehuman-ware.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNon tratteremo in particolare esattamente come ogni campo viene declinato, per√≤ possiamo\u003c/p\u003e\n\u003cp\u003eUna altra tendenza generale √® che \u003cstrong\u003epi√π √® complessa pi√π √® insicura\u003c/strong\u003e. e questo senso di insicurezza cresce in modo maggiore rispetto al lineare.\u003c/p\u003e\n\u003ch3 id=\"security-principles\"\u003eSecurity principles\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOpen Design\u003c/strong\u003e perch√© cos√¨ pu√≤ essere scrutata da pi√π persone\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEconomy of mechanism\u003c/strong\u003e spiegata \u003ca href=\"/notes/sicurezza-os/#sistema-politica-e-meccanismi\"\u003esotto\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFail-safe defaults\u003c/strong\u003e questo molto importante perch√© molti sistemi hanno dei default che possono essere exploitati.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eComplete mediation\u003c/strong\u003e: cos√¨ abbiamo qualcosa che tracka tutti gli accessi, che \u003cem\u003econtrolla\u003c/em\u003e gli accessi.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLeast privilege\u003c/strong\u003e questo va a braccetto con il fail-safe.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePrivilege separation\u003c/strong\u003e cos√¨ possiamo mettere in modo indipendente un privilegio per qualcos\u0026rsquo;altro.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"cia-properties\"\u003eCIA properties\u003c/h4\u003e\n\u003cp\u003eNe abbiamo parlato in modo leggermente inverso in \u003ca href=\"/notes/sicurezza-delle-reti/\"\u003eSicurezza delle reti\u003c/a\u003e e in \u003ca href=\"/notes/theoretical-notions-of-security/\"\u003eTheoretical Notions of Security\u003c/a\u003e.\nIn questo caso sono\u003c/p\u003e","title":"Sicurezza OS"},{"content":"Algoritmo del simplesso Ricerca della direzione migliore Ricerca dello step Pseudocodice Slide\nB sono gli indici di partenza, poi questi vengono aggiornati\nIn riga 5 vado a checkare se ho direzioni di crescita possibili, se √® tutto positivo non ne ho.\nin riga 6, si sceglie il pi√π piccol per evitare loop.\nL\u0026rsquo;idea in generale va in questo modo\nCerco di trovare il duale e confrontarlo con la x attuale Se sono uguali, allora ho trovato l‚Äôottimo ed esco Altrimenti cerco una direzione di crescita che sia anche ammissibile Continuo fino a trovare un vertice, se ho il vertice allora mi muovo l√¨ e riapplico, altrimenti √® illimitata, se non esiste un vertice. Correttezza Slide\n**\nInvarianti (3)\nqueste invarianti vengono mantenute per tutto il corso dell\u0026rsquo;algoritmo\nLa scelta della direzione di crescita\nNOTA: il vettore $u_h$ √® un versore utilizzato per selezionare la direzione che ci interessa (quindi 0 in tutto e 1 nella parte che ci interessa!).\nLa parte in cui dobbiamo stare attenti nella scelta della direzione di crescit√† √® restare nella zona delle soluzioni ammissibili.\nComplessit√† Slide\nFare una analisi in modo rigoroso non riusciamo a farlo, pi√π o meno ora restiamo con l\u0026rsquo;intuizione che al massimo ogni singolo vertice √® visitato una volta quindi teniamo il bound su questo.\nsi tratterebbe quindi di prendere fra tutti gli $m$ restrizioni possibili, dobbiamo andare a prendere $n$ elementi, con questo il numero di variabili.\nquindi $m \\choose n$.\nNella pratica √® molto veloce poi ha un runtime nel costo medio polinomiale, ma per fare questa analisi abbiamo bisogno di altri strumenti, molto avanzati.\nBranch and bound non si pu√≤ applicare l\u0026rsquo;algoritmo del simplesso per vincoli interi, questo sembra quasi paradossale ma √® cos√¨. il motivo √® che il simplesso gira sui vertici delle rette, cosa che non pu√≤ essere intera, e non abbiamo un modo banale per trovare la parte intera pi√π vicina!.\nIntuizione Slide\nProviamo a rilassare il problema chiedendo che anche i vincoli non interi siano buoni. Spesso questa cosa non √® buona, quindi utilizziamo una partition per andare a ritrovare una cosa intera.\nIn pratica, cerco la soluzione non intera utilizzando Simplesso o altri algoritmi che mi diano dei risultati boni. Poi se √® intera ritorno, altrimenti aggiungo due vincoli interi, creandomi due sottoproblemi, e me li vado ad esplorare in questo modo‚Ä¶\nPseudocodice Slide\nSi basa sull‚Äôapplicare in modo continuo un algoritmo per la risoluzione della programmazione lineare non intera, e cercare con una sorta di divide e conquer una soluzione che sia intera.\nCorrettezza Slide\nComplessit√† Slide\nEsponenziale, bisogna andare ad utilizzare il simplesso come subroutine molte volte, anche se magari si pu√≤ velocizzare di molto come subroutine, resta comunque almeno della complessit√† del simplesso.\n","permalink":"https://flecart.github.io/notes/simplesso-e-bb/","summary":"\u003ch2 id=\"algoritmo-del-simplesso\"\u003eAlgoritmo del simplesso\u003c/h2\u003e\n\u003ch3 id=\"ricerca-della-direzione-migliore\"\u003eRicerca della direzione migliore\u003c/h3\u003e\n\u003ch3 id=\"ricerca-dello-step\"\u003eRicerca dello step\u003c/h3\u003e\n\u003ch3 id=\"pseudocodice\"\u003ePseudocodice\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide\u003c/p\u003e\n\u003cp\u003eB sono gli indici di partenza, poi questi vengono aggiornati\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Simplesso e B\u0026B/Untitled.png\" alt=\"image/universita/ex-notion/Simplesso e B\u0026B/Untitled\"\u003e\n\u003cp\u003eIn riga 5 vado a checkare se ho \u003cstrong\u003edirezioni di crescita possibili\u003c/strong\u003e, se √® tutto positivo non ne ho.\u003c/p\u003e\n\u003cp\u003ein riga 6, si sceglie il pi√π piccol per \u003cstrong\u003eevitare loop\u003c/strong\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eL\u0026rsquo;idea in generale va in questo modo\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eCerco di trovare il duale e confrontarlo con la x attuale\n\u003col\u003e\n\u003cli\u003eSe sono uguali, allora ho trovato l‚Äôottimo ed esco\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eAltrimenti cerco una direzione di crescita che sia anche ammissibile\u003c/li\u003e\n\u003cli\u003eContinuo fino a trovare un vertice, se ho il vertice allora mi muovo l√¨ e riapplico,\naltrimenti √® illimitata, se non esiste un vertice.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"correttezza\"\u003eCorrettezza\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide\u003c/p\u003e","title":"Simplesso e B\u0026B"},{"content":"Next time, use this resource.\nDi solito √® utilizzata per ridurre lo spazio utilizzato trattenendo la maggiore quantit√† di informazione possibile, utilizzata spesso in Principal Component Analys\nEnunciato SVD slide\nImmagine esplicativa\nQuesto √® qualcosa che si pu√≤ applicare a qualunque matrice. Sono di particolare interesse le matrici con numero di colonne maggiore del numero di righe.1\nSlide vecchia\nRelazione valori singolari con AAt üü©- Con k ho il numero di numeri non zero che sono il rango della matrice. Questa matrice √® particolare, la chiamiamo gramiano ed √® sempre definita positiva.\nSlide\nQuindi i valori singolari che sono gli autovalori della matrice $A^TA$ sono\n$\\geq 0$ $\\in \\R$ se k √® il rango di $A$, ho k elementi diversi da 0. Il motivo per cui succede quanto sopra √® perch√© √® come se stessi facendo il cambio di base per trovare una matrice diagonale! Cambio di Base, e non c\u0026rsquo;√® nessuna relazione altra fra la matrice di A e il valore singolare, deve essere con AAt!\nRelazione molto importante (!!!!!)\nVettori singolari sinistri e destri üü© Definiamo in questo modo i vettori associati a $\\sigma_i$ che formano una base ortonormale rispettivamente di $R^m, R^n$. E in particolare sono le colonne delle matrici $U, V$\nNOTA: √® molto probabile che la relazione sotto che lega vettori singolari sinistri e destri sia errata perch√© sulla pagina di wiki u e v sono invertite. √à pi√π importante il fatto che i vettori singolari sinistri e destri sono rispettivamente autovettori di AAt e AtA.\nSlide\nDecomposizione diadica üü•+ \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 11.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Minimi quadrati/Untitled 11\u0026quot;\u0026gt; In pratica con la decomposizione a valori singolari, e utilizzando i vettori singolari si pu√≤ dimostrare che\n$$ A = U\\Sigma V^T = \\sum_{i=1}^k \\sigma_iu_iv_i^T $$Espandere questi calcoli √® abbastanza easy creddo, perch√© la matrice di mezzo √® molto semplice da gestire. L‚Äôintuito per sta parte (che √® l‚Äôunica cosa di cui si √® preoccupata di spiegare) √® che √® utile qui il concetto di un prodotto esterno che po\nRisoluzione minimi quadrati con SVD üü®+ \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 12.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Minimi quadrati/Untitled 12\u0026quot;\u0026gt; Dimostrazione\nRegressione Polinomiale (!) Abbiamo un insieme di dati, vogliamo creare un algoritmo che stimi la funzione migliore per approssimare i dati.\nSiano dati un insieme di punti $(x_i, y_i)$, sia un polinomio p cos√¨ definito\n$p(x) = \\sum_{i =0} ^m c_ix^i$, vogliamo andare a definire per bene i valori dei coefficienti in modo che aderiscano ai dati.\nPer fare questo, in pratica √® la risoluzione di certi errori.\nIn pratica mi costruisco la matrice di vandermonde per tutti gli input di dati, di n numero di colonne, con n l‚Äôesponente massimo del polinomio che voglio andare ad approssimare.\nPoi faccio cose per minimizzare l‚Äôerrori di questo e lo possono fare con SVD o minimi quadrati (nel cosi in cui il rango fosse giusto).\nImportante per questa parte la matrice di vandermonde.\nPseudo inversa (4) üü• Slide\nQuesta definizione ci permette di scrivere il problema dei minimi quadrati in modo pi√π clean, infatti la soluzione della SVD diventa\n$x = V\\Sigma^+U^Tb = A^+b$, come se stessi prendendo l‚Äôinversa üòÄ, quindi ci permette di semplificare questa notazione.\nSi pu√≤ notare che l‚Äôinversa possiede tutte le propriet√† della pseudoinversa.\nIn soldoni: inverto le matrici di vettori singolari e inverto tutti i valori singolari (prendo iil loro reciproco).\nImportanti sono alcune loro propriet√† (hermitiana per AA* e A*A, ossia simmetrica, inversa debole e l‚Äôaltra boh).\nSecondo la definizione di moore-penrose quelle 4 propriet√† sono sufficienti per una pseudoinversa, in questo caso abbiamo la pseudoinversa della SVD, che √® una cosa leggermente diversa (cio√® istanziazione specifica della pseudoinversa).\nCondizionamento in LSQ (non fare) Questa sezione ha cose da ricordare a memoria (gi√† leggermente presentate in precedenza) quindi non ha molto senso dare attenzione a sta roba brutta, imparare poi a memoria il costo dei vari argoritmi bruuh\nVogliamo in questa sezione andare ad indagare quanto influenza il numero di condizione tutte le tecniche che abbiamo introdotto in questo capitolo.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 16.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Minimi quadrati/Untitled 16\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 17.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Minimi quadrati/Untitled 17\u0026quot;\u0026gt; Da ricordarsi di Norme e Condizionamento, che il condizionamento ci dice quanto cambia la soluzione quando cambio i dati (la b)\n","permalink":"https://flecart.github.io/notes/singular-value-decomposition/","summary":"\u003cp\u003eNext time, use \u003ca href=\"https://rich-d-wilkinson.github.io/MATH3030/3.3-linalg-SVD.html\"\u003ethis\u003c/a\u003e resource.\u003c/p\u003e\n\u003cp\u003eDi solito √® utilizzata per \u003cstrong\u003eridurre lo spazio utilizzato\u003c/strong\u003e trattenendo la maggiore quantit√† di informazione possibile, utilizzata spesso in Principal Component Analys\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eEnunciato SVD slide\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 5.png\" alt=\"image/universita/ex-notion/Minimi quadrati/Untitled 5\"\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eImmagine esplicativa\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 6.png\" alt=\"image/universita/ex-notion/Minimi quadrati/Untitled 6\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eQuesto √® qualcosa che si pu√≤ applicare a \u003cstrong\u003equalunque matrice\u003c/strong\u003e. Sono di particolare interesse le matrici con numero di colonne maggiore del numero di righe.1\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide vecchia\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 7.png\" alt=\"image/universita/ex-notion/Minimi quadrati/Untitled 7\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"relazione-valori-singolari-con-aat--\"\u003eRelazione valori singolari con AAt üü©-\u003c/h3\u003e\n\u003cp\u003eCon k ho il numero di numeri non zero che sono il \u003cstrong\u003erango della matrice\u003c/strong\u003e. Questa matrice √® particolare, la chiamiamo gramiano ed √® sempre definita positiva.\u003c/p\u003e","title":"Singular Value Decomposition"},{"content":" Programmare e dimostrare sono sostanzialmente la stessa attivit√† ~Coen\nMa non secondo l\u0026rsquo;industria\u0026hellip;\n4.1.1 Definizione e necessit√† Branca della linguistica, studia creazione di proposizione e il loro collegamento per la creazione di un periodo\nIn seguito la semantica d√† un metodo a queste proposizioni in modo che abbiano un senso.\nUtile o necessario per la definizione del linguaggio artificiale 4.1.2 Alfabeto, stringa, linguaggio e grammatica Alfabeto: Insieme non vuoto di simboli (che spesso sono diversi fra di loro) Stringa seguenza finita (vuoto √® possibile) di simboli $\\epsilon = \\varnothing$ Linguaggio: insieme di stringhe (di qualunque tipo, finito o infinito). Grammatica formalismo (un insieme di regole che lo rende finito) che definisce un linguaggio\n4.2 Backus-Naur Form Ora √® descritto anche in Descrizione linguaggio Indicato con BNF\n4.2.1 Perch√© BNF Una formalizzazione informatica che permetta l\u0026rsquo;elaborazione di grammatiche ‚Üí notazione per descrivere grammatiche\nNon √® l\u0026rsquo;unica ma per gli informatici √® la migliore.\n4.2.2 Caratteristiche Indichiamo con $(T, NT, X, P)$ rispettivamente T = l\u0026rsquo;alfabeto, l\u0026rsquo;insieme di simboli che usiamo NT √® un insieme di simboli diversi da T (insieme non terminale) Sono solamente ausigliari. X = qualunque elemento di NT, basta che sia iniziale P = simile alla grammatica, sono delle coppie come produzioni: comprendono:\nNon terminali Insieme di stringhe che contengono un p√≤ di tutto ,indicate con $\\omega_n$ Es. $(X, \\{\\omega_1 ...\\omega_n\\})$ √® una produzione.\nQuindi questi quattro elementi riescono ad identificare in maniera univoca la semantica di un linguaggio.\nCapiremo il senso di questa definizione per l\u0026rsquo;informatica fra poco.\nIndicazione Si pu√≤ indicare con $X ::= 0|0Y$ e simili, utilizzando solo per produzioni come coppie √® sufficiente per definire una sintassi BNF.\n4.2.3 Definizione di un linguaggio Di solito fra tutte √® sufficiente prendere le produzioni per dire un linguaggio.(ha senso supponendo che tutti i simboli della grammatica siano utilizzati)\nProcesso iterativo che parte dal non terminale e arriva a stringhe finite.\nDimostrare che 000 non appartiene a questo linguaggio\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sintassi e RI strutturali/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sintassi e RI strutturali/Untitled 1\u0026quot;\u0026gt; 4.3 Ambiguit√† in BNF 4.3.1 Definizione ambiguit√† Se si pu√≤ definire in due modi diversi la stessa parola, allora si dice che il linguaggio √® ambiguo.\n4.3.2 Soluzione ambiguit√† (3) Queste non sono sempre necessarie in ogni grammatica, ma sarebbero utili per la comprensione\nOrdine di precedenza per operatori Associativit√† per ogni operatore (cio√® se l\u0026rsquo;operatore prende solo a destra o da sinistra) Parentesi? Cos√¨ definisco un ordine di precedenza quindi risolvo le ambiguit√†, ma non dovrei fare in questo modo.\n4.4 Albero di Sintassi astratta Buona cosa potrebbe essere la pagina di wiki.\nAfferma che questo albero √® molto utile per il compilatore (cos√¨ capisce cosa stiamo provando a fare).\nUn approfondimento possibile per questi alberi √® la Contex-free-grammar ovvero come evitare l\u0026rsquo;ambiguit√† del linguaggio naturale. (simile a BNF).\n4.4.1 Definizione (4) Prima si deve trovare una BNF non ambigua, poi possiamo creare un albero di questo genere.\nDefinizione di albero di sintassi\nDi solito ogni linguaggio di programmazione √® prima trasformato in un albero di sintassi e in seguito il compilatore elabora su questa cosa.\n4.4.2 Ricorsivit√†: le sottoformule immediate Sono figli diretti, sottoformule immediate generate dal nodo padre.\nEcco una struttura di dati ricorsiva, impareremo a sfruttare questa caratteristica della ricorsione.\nQuesta sottostruttura ricorsiva √® molto utile perch√© so anche come √® stato ricavato, non solo so se appartiene o meno! Pi√π informazioni! Riusciamo ad assegnare un significato.\nLa cosa bella di questra struttura √® che possiamo utillizzare la stessa funzione (programma o quel che si voglia chiamarlo) per risolvere il problema su alcuni dati pi√π piccoli (sotto dati).\n4.5 Pseudo-linguaggio funzionale puro non tipato Altolivello- vicino dominio del problema, senza alcuni dettagli di implementazione (che far√† da solo).\nBasso livello- vicino al dominio della soluzione ossia tratta alivello vicino al computer.\nTutti questi linguaggi hanno un albero sotto, che cerca di utilizzare questa grammatica formale per capire ci√≤ che √® scritto.\n4.5.1 Significato del nome Pseudo linguaggio perch√© questo linguaggio non esiste realmente, √® solamente qualcosa di simile, di vicino al un linguaggio reale (meno sintassi diciamo)\nfunzionale si utilizzano funzioni, sia come input, output per memorizzare cose e simili\nPuro senza side effect, senza storare variabili e fare cicli while o for\nNon tipato senza che un compilatore si lamenti di come √® implementato il tipo, quindi maggiore astrazione anche da questo punto di vista\n4.5.2 Funzioni unarie (3) Le funzioni unarie sono definite da tre parti principali:\nIl nome della funzione Un pattern $\\omega$, di solito una stringa dell\u0026rsquo;alfabeto Variabili ‚Üí Non terminali Costruttori e simili ‚Üí terminali costruiti con la gramatica del linguaggio. Corpo, quello che √® dentro la funzione Chiamate ad altre funzioni Parametri formali e altre costanti Condizioni di control flow 4.5.3 Pattern matching Questa √® la definizione di matching\nIn modo intuitivo: Match = se $p$ terminale matcha $\\omega$ se partendo da $\\omega$ si pu√≤ creare $p$\nChiamate di funzione\nIn questo linguaggio funzionale, andremo ad utilizzare Haskell, la chiamata di funzione avviene per pattern match.\nPasso a sostituire i parametri formali a seconda di cosa matchi, ricostruendo tutto continuando.\n4.5.4 Side effects Questi linguaggi funzionali non devono avere side effects, ossia non devono accedere a locazioni di memoria fuori dal loro scope, o fuori dai propri parametri formali, quindi molto pi√π controllabile.\nMa questo significa che non abbiamo la libert√† di allocare memoria e simili.\n4.5.5 Potenza espressiva Noi non possiamo programmare tutto quello che la matematica pu√≤ fare.\nMa certe cose si possono fare in un linguaggio e non in un altro. Ma qualunque funzione in qualunque altro linguaggio potrebbe essere espresso nello pseudo-codice attuale (quando questa cosa accade Turing-completezza).\nMa dato che non abbiamo side effect non ci interessa I/O e video o simili.\n4.6 Ricorsione strutturale 4.6.1 Solito ragionamento per ricorsione Come di solito le ricorsioni, se √® un caso base allora risolvo subito, in modo diretto.\nAltrimenti risolvo ricorsivamente un sotto problema pi√π facile, ma √® ancora lo stesso problema, ecco perch√© strutturale ‚Üí Hanno la stessa struttura, quindi sto utilizzando la stessa funzione per risolvere lo stesso problema ma per input diversi.\nQuindi risolvo problemi pi√π piccoli e poi le ricompongo alla maniera iniziale.\nStrutture uguali (cio√® i sottodati devono essere ancora dei tipi dei dati iniziali, se ho in input lista di qualcosa e poi ho totalmente altro non posso fare). Risolvo cos√¨ problemi pi√π semplici in modo ricorsivo. 4.6.2 Errori comuni DI solito la ricorsione √® difficile perch√© le persone tendono a cercare di scoprire in che modo sia implementata la ricorsione, cio√® cercano di comprendere cosa faccia la ricorsione a livello troppo basso.\nChiamate ricorsive non sui sottoproblemi Struttura della ricorsione √® errata (usando produzioni inesistenti) Mancare di qualche produzione 4.6.3 Esercizi Ricorsione strutturale Questi esercizi sono importanti dato che poi all\u0026rsquo;esame dovrai risolvere qualcosa di simile!\nEs 1\n-- Problema 1: data una lista (di numeri) -- calcolare l\u0026#39;insieme potenza della lista Es 2\n-- Problema 1: data una lista (di numeri) -- calcolare la lista di tutte le permutazioni -- della lista in input -- Es: dato 1:2:3:[], restituire -- (1:2:3:[]):(1:3:2:[]):(2:1:3:[]):(2:3:1:[]): -- (3:1:2:[]):(3:2:1:[]):[] -- Soluzione: per l1 Es 3\nUno tostino come esercizio √® definire una funzione che ritorni vero se e solo se un elemento compare due volte nell\u0026rsquo;insieme.\nEs 4\nN ::= O | S N\ndove il simbolo terminale O rappresenta lo 0 e il simbolo terminale S, letto \u0026ldquo;successore\u0026rdquo;, dato un numero naturale N forma il numero naturale S N che segue N nella numerazione.\nEsempio: 3 viene rappresentato in base 1 come¬†S (S (S O)))¬†e 5 come S (S (S (S (S O)))).\nNota: la rappresentazione corrisponde al modo con cui i bambini imparano a contare, usando le dita. O √® il pugno chiuso e ogni S corrispondere ad aggiungere un dito.\nProblema 1: definire per ricorsione strutturale una funzione + sui numeri naturali in base 1 che ne implementi la somma\nEsempio:¬†S (S O) + S (S (S O))) = S (S (S (S (S O)))))\nSuggerimento: procedere per ricorsione strutturale sul primo argomento\nProblema 2:\ndefinire per ricorsione strutturale una funzione * sui numeri naturali in base 1 che ne implementi il prodotto\nEsempio: S (S O) * S (S O) = S (S (S (S O))))\nSuggerimento: per implementare il * potete usare il +\nProblema 3:\ndefinire per ricorsione strutturale una funzione ^ sui numeri naturali in base 1 che elevi il primo numero alla potenza indicato dal secondo\nEsempio: S (S O) ^ S (S (S O))) = S (S (S (S (S (S (S (S O))))))))\nSuggerimento: scegliere bene su quale input procedere per ricorsione strutturale\nQuesti dovrebbero essere difficili, se sai risolvere questi, dovresti essere in grado di farlo per tutti.\n4.7 Induzione strutturale Questa √® una tecnica dimostrativa per dimostrare che una struttura gode di una certa propriet√†. √à strettamente legata alla ricorsione perch√© la ricorsione √® il calcolo della soluzione mentre l\u0026rsquo;induzione la dimsotrazione della correttezza.\nQuesta forma di dimostrazione √® valida per ragioni molto simili alla ricorsione strutturale, perch√© ogni passo √® giustificato dal precedente, di cui il caso base √® assunto come vero.\nQuindi bisogna prima capire quali siano le differenze fra induzione e strutturale.\n4.7.1 Il procedimento L\u0026rsquo;output deve essere una dimostrazione Si suppone che valga per tutti i sottocasi di questo di input (in pratica uguale alla ricorsione, per tutti gli sottoinput immediati stiamo supponendo che valga) come in matematica puoi affermare che valga per tutti i numeri minori di n come ipotesi induttiva. 4.8 Confronto funzioni mate e info Questo paragrafetto si rif√† all\u0026rsquo;iniziale introduzione sui Logica meta-linguistica sui paradossi in matematica e informatica.\n4.8.1 Matematica Rappresentazione √® fatta con relazioni, sottoinsieme del prodotto cartesiano. Questa √® inefficiente dal punto di vista del calcolo in quanto non ci da un modo per creare un calcolo. (non posso scorrere perch√© le liste restano illimitate).\nSi in questo caso stai pensando alle Relazioni fra insiemi non al modo per calcolarle.\n4.8.2 Informatica Di solito gli algoritmi ragionano in modo simile in basi diverse, that is l\u0026rsquo;efficienza degli algoritmi √® molto simile in basi diverse, tranne in base 1 che √® esponenzialmente pi√π grande rispetto alle altre basi.\nEsempio di def. di funzioni somma\nO `+ m = m S n `+ m = S (n `+ m) ----- n +\u0026#39; ) = n n +\u0026#39; S m = S (n +\u0026#39; m) ------ O ``+ m = m S n ``+ m = n ``+ S m ------- n +\u0026#34; O = m n +\u0026#34; S m = S n +\u0026#34; m Queste sono quattro procedure di calcolo per la somma non uguali in quanto calcolano diversamente.\nIl prof. ha detto (non ho capito il motivo) per cui quelli con un singolo apice utilizzano la stack, mentre invece quelli con due apici utilizzano la heap), non ho capito perch√©, ma tanto lo spiegher√† ad architettura.\n4.8.3 Specifiche di funzioni Possiamo utilizzare le dimostrazioni per induzione strutturale per verificare la correttezza di una funzione.\nPer esempio una funzione di concatenzazione dovrebbe soddisfare questi teoremi\nDi cui il primo mantiene il numero , il secondo appartenenza, il terzo l\u0026rsquo;ordine.\n$|l_1 fl_2| = |l_1| + |l_2|$ $x\\in l_1 \\implies$ $l_1fl_2$ $\\forall n, n \\leq |l1| \\implies$ nth n l1 = nth n (l1@l2) $\\wedge$ $\\forall n, n\\leq |l2| \\implies$ nth n l2 = nth (|l+1| +n) (l1@l2) Se una funzione soddisfa questi teoremi allora possiamo definire in modo rigoroso una funzione.\nFunzioni helper per questo\ncat [] l2 = l2 cat (t:l) l2 = t:cat l l2 length [] = 0 length (n:l) = 1 + length l -- nth n l tira fuori n-elemento di l head [] = [] head (n:l) = n tail [] = [] tail (n:l) = l nth 0 l = head l nth (S n) l = nth n (tail l) nthCorto 0 (t:l) = t nthCorto (S n) (t:l) = nthCorto n l E poi dovrei verificare ogni singola funzione di questo\u0026hellip;\nSpesso nella vita reale non c\u0026rsquo;√® bisogno di questo, si scriva specifica parziale n) (t:l) = nthCorto n l ```\nE poi dovrei verificare ogni singola funzione di questo... Spesso nella vita reale non c\u0026rsquo;√® bisogno di questo, si scriva specifica parziale\n","permalink":"https://flecart.github.io/notes/sintassi-e-ri-strutturali/","summary":"\u003cblockquote\u003e\n\u003cp\u003eProgrammare e dimostrare sono sostanzialmente la stessa attivit√† ~\u003cem\u003eCoen\u003c/em\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eMa non secondo l\u0026rsquo;industria\u0026hellip;\u003c/p\u003e\n\u003ch3 id=\"411-definizione-e-necessit√†\"\u003e4.1.1 Definizione e necessit√†\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eBranca della linguistica, studia creazione di proposizione e il loro collegamento per la creazione di un periodo\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eIn seguito la semantica d√† un metodo a queste proposizioni in modo che abbiano un senso.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eUtile o necessario per la definizione del linguaggio artificiale\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"412-alfabeto-stringa-linguaggio-e-grammatica\"\u003e4.1.2 Alfabeto, stringa, linguaggio e grammatica\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eAlfabeto\u003c/strong\u003e: Insieme non vuoto di simboli (che spesso sono diversi fra di loro)\n\u003cstrong\u003eStringa\u003c/strong\u003e seguenza finita (vuoto √® possibile) di simboli $\\epsilon = \\varnothing$\n\u003cstrong\u003eLinguaggio\u003c/strong\u003e: insieme di stringhe (di qualunque tipo, finito o infinito).\n\u003cstrong\u003eGrammatica\u003c/strong\u003e formalismo (un insieme di regole che lo rende finito) che definisce un linguaggio\u003c/p\u003e","title":"Sintassi e RI strutturali"},{"content":"4.1 Sistemi lineari La cosa buona √® che possiamo analizzare il sistema lineare utilizzando tutti i teoremi che abbiamo sviluppato finora, quindi siamo molto pi√π potenti per attaccare questo problema.\nDefiniamo un sistema lineare cos√¨\n$Ax = b$ con A la matrice associata.\n4.1.1 Preimmagine Data una applicazione lineare $F:V \\to W$, allora la controimmagine √® l\u0026rsquo;insieme dei vettori di V che fanno a finire in quel punto, in matematichese:\n$F^{-1}(w) = \\{v \\in V | F(v) = w\\} \\subseteq V$, un esempio di preimmagine √® Ker F.\nPossiamo anche definire un concetto di suriettivit√† in questo modo:\nUna funzione √® suriettiva, se per ogni elemento dell\u0026rsquo;immagine, ho un elemento nel dominio, quindi l\u0026rsquo;insieme preimmagine deve essere diverso da vuota\nKer e Imm sono qui\n4.1.2 Relazione preimmagine e immagine e nucleo 6.1.4 (chiede) Fare attenzione a dimostrare la doppia inclusione per l\u0026rsquo;uguale! Stiamo utilizzando sempre l\u0026rsquo;assioma dell\u0026rsquo;estensionalit√†, ricordatelo!\nDimostrazione\n4.1.3 Rango righe di righe e colonne uguali (6.2.3) !!! Possiamo definire il rango righe come la dimensione dello spazio riga di A\nMentre il rango colonna la dimensione dello spazio colonna (questo √® ovvio conoscendo i teoremi sulle matrici!, ricorda che con le operazioni di gauss riuscivi a trovare una serie di vettori indipendenti e generatori!)\nDimostrazione\nIl rango colonne, per un teorema precedente che diceva base di uno √® base anche dell\u0026rsquo;altro, √® uguale alla dimensione dell\u0026rsquo;immagine, quindi se la dimensione dell\u0026rsquo;immagine √® uguale al rango righe, ho che i due ranghi sono uguali, allora posso considerare solo un unico rango per la matrice.\nDimostrazione della 5.7.4\nLa dimostrazione di 5.7.4 dovrebbe essere banale, una volta che generalizzi la soluzione di gauss per il nucleo (lo puoi sempre scrivere come spazio generato da n - rr(A) variabili libere per le propriet√† credo delle riduzione matriciale di gauss.\n4.1.4 Rouch√© - Capelli (chiede) Dimostrazione da libro\nDimostrazione (informale)\nLe soluzioni sono le preimmagini della nostra funzione, ha soluzione se la preimmagine di b non`e nulla e per questo deve essere che b deve appartenere al sottospazio generato dalle colonne di a (perch√© queste generano l\u0026rsquo;intera immagine) e per la 3.1.8 allora lo spazio colonna di A √® uguale allo spazio colonna di A con b, allora hanno la stessa dimensione perch√© sono uguali, allora i ranghi sono uguali. (4.2.4?)\npreimmagine 0 coimplica b nello spazio immagine\nb nello spazio immagine coimplica generato con e senza b √® uguale\nquesto coimplica dimensioni uguali quindi finito entrambe le frecce\nPassando per la seconda parte della dimostrazione, sappiamo che l\u0026rsquo;insieme delle soluzioni, ossia la controimmagine, si pu√≤ scrivere in questa forma:\n$f^{-1}(w) = \\{ v + z | f(v) = w \\land z \\in ker(f)\\}$\nallora nel caso in cui io abbia che le due matrici siano uguali come al punto 1, posso creare un insieme infinito di soluzioni partendo da questa cosa.\n4.2 Determinanti 4.2.1 Definizione Non abbiamo una definizione diretta del determinante, per cui la definiamo in modo indiretta facendo una lista delle propriet√†\nVedremo che l\u0026rsquo;inversa di una matrice esiste sse il determinante √® diverso da 0, ed √® l\u0026rsquo;aspetto pi√π importante del determinante per la nostra analisi\nSi pu√≤ dimostrare (ma non si √® fatto) che la funzione associata al determinante esiste sempre ed √® unica.\nPropriet√† (4)\nLe propriet√† 1, 2 ci dicono come comportarci rispetto alla somma (distributiva) e la moltiplicazione scalare per singole righe.\nLa propriet√† 3 ci da un relazione con la combinazione lineare (e quindi dipendenza)\nLa 4 ci permette di calcolare :D\nConseguenze delle propriet√† (3)\nLa propriet√† 3 √® molto utile per il calcolo, direi che √® la propriet√† pi√π importante per fare i calcoli\nHint di dimostrazione Considero la matrice somma, che per la propriet√† 1 √® uguale alla somma dei determinanti di A e B. Allora questa ha due righe uguali, quindi √® uguale a 0. Riscrivendo la somma si ha la sol. Considero la riga scritta come combinazione lineare come somma di due di determinanti di due matrici. Una di queste avr√† due righe uguali, quindi √® 0. I due determinanti sono uguali. Partendo dalla triangolare inferiore, posso trovare la matrice diagonale con matrici con combinazioni lineari. Teorema di Binet\nQuesta propriet√† non si dimostra senza aver considerato la base di dimostrazione con permutazioni.\nPer√≤ dice che se ho due matrici, si ha che il determinante della matrice prodotto √® uguale al determinante delle singole matrici.\n4.2.2 Metodo savius Per le matrici 3x3, il classico\n4.2.3 Metodo Laplace (ricorsivo) 4.3 L\u0026rsquo;inversa della matrice 4.3.1 Definizione e unicit√† L\u0026rsquo;inversa di una matrice $A \\in M_{n\\times n}(\\R)$ √® una matrice $B$ nello stesso spazio tale che\n$AB = BA = I$.\nQuando si fa il controllo della matrice inversa, dovresti dimostrare che $AB = BA$ che di solito non vale, per√≤ dimostri che l\u0026rsquo;inversa √® unica quindi ti basterebbe fare un unico controllo\nDimostrazione unicit√† dell\u0026rsquo;inversa\nSia $A^{-1}$ l\u0026rsquo;inversa di $A$, supponiamo che esista $B$ che sia l\u0026rsquo;inversa e tale per cui $A^{-1} \\neq B$, allora ho che\n$AB =I \\implies A^{-1}AB = A^{-1}I \\implies I B = A^{-1}I \\implies B = A^{-1}$\n4.3.2 Equivalenza di invertibilit√† col determinante (!!) Si pu√≤ dimostrare che $A$ √® invertibile nel caso in cui la determinante √® diverso da 0.\nDimostrazione\n$\\implies$Se √® invertibile, il determinante di A √® diverso da 0.\nPerch√© per binet, se $I = AB$ allora $\\det(I) = \\det(AB) = \\det(A)\\det(B)$ se fosse 0 allora sarebbe impossibile, quindi √® diverso da 0, e posso dire che\n$\\det(B) = \\dfrac{1}{\\det(A)}$\n$\\impliedby$\nDevo dimostrare che se il determinante di A √® diverso da 0 allora √® invertibile. Facciamo una dimostrazione costruttiva, cio√® diciamo qua proprio come √® fatto la matrice inversa.\nPosso costruire la matrice inversa in questo modo:\n$b_{ij} = \\dfrac{1}{\\det A} \\Gamma_{ji}$ ora devi controllare questa cosa e sei apposto.\n4.3.3 Calcolo dell‚Äôinversa con GAUSS SI pu√≤ calcolare l\u0026rsquo;inversa di una matrice utilizzando gauss su una matrice del tipo\n$A|I$, fino ad andare ad ottenere la matrice $I|B$ con B la inversa.\nTEOREMONE (!!!!) 7.6.1 Enunciato (11)\nTutte le dimostrazioni fra 1 e 9 compreso sono sono tutte gi√† state spiegate in precedenza, l\u0026rsquo;unica cosa nuova √® l\u0026rsquo;equivalenza fra 1 e 10\nDimostrazione (1-10)\nSe dimostro che 1 √® equivalente a 10, ho dimostrato l\u0026rsquo;equivalenza anche per 1-11 perch√© 10 √® equivalente a 11 per il teorema questo.\nAllora dimostriamo $\\implies$.\nSupponiamo di avere una funzione bigettiva. Allora posso prendere la sua funzione inversa, che esiste per la biiettivit√†. Considero la matrice associata all\u0026rsquo;inversa, allora posso concludere che $f \\cdot g \\approx AA^-1$ che termina la dimostrazione perch√© ho la matrice inversa.\nPossiamo enunciare le equivalenze fra cose riguardo le applicazioni lineari\nNota su composizione di funzioni\nSia A la matrice associata a f e B associata a g.\nAllora si pu√≤ dimostrare che la matrice associata a $f \\cdot g$ √® $AB$, questo si dimostra utilizzando l\u0026rsquo;associativit√† della moltiplicazione matriciale.\n","permalink":"https://flecart.github.io/notes/sistemi-lineari-e-determinanti/","summary":"\u003ch2 id=\"41-sistemi-lineari\"\u003e4.1 Sistemi lineari\u003c/h2\u003e\n\u003cp\u003eLa cosa buona √® che possiamo analizzare il sistema lineare utilizzando tutti i teoremi che abbiamo sviluppato finora, quindi siamo molto pi√π potenti per attaccare questo problema.\u003c/p\u003e\n\u003cp\u003eDefiniamo un sistema lineare cos√¨\u003c/p\u003e\n\u003cp\u003e$Ax = b$ con A la matrice associata.\u003c/p\u003e\n\u003ch3 id=\"411-preimmagine\"\u003e4.1.1 Preimmagine\u003c/h3\u003e\n\u003cp\u003eData una applicazione lineare $F:V \\to W$, allora la controimmagine √® l\u0026rsquo;insieme dei vettori di V che fanno a finire in quel punto, in matematichese:\u003c/p\u003e","title":"Sistemi Lineari e determinanti"},{"content":"Softmax is one of the most important functions for neural networks. It also has some interesting properties that we list here. This function is part of The Exponential Family, one can also see that the sigmoid function is a particular case of this softmax, just two variables. Sometimes this could be seen as a relaxation of the action potential inspired by neuroscience (See The Neuron for a little bit more about neurons). This is because we need differentiable, for gradient descent. The action potential is an all or nothing thing.\nThere are some reasons why softmax is preferred over other functions to induce a probability.\nConnections with physics Part of the exponential family Differentiability Satisfies the Maximum Entropy Principle This is why it is usually preferred over other ways to induce a simplex. Definition of the function The softmax function is usually defined as follows:\n$$ \\text{ softmax } (h, y, T) = \\frac{\\exp\\left( \\frac{h_{y}}{T} \\right)}{\\sum_{y' \\in \\mathcal{Y}} \\exp\\left( \\frac{h_{y'}}{T} \\right)} $$The softmax takes the vector $\\vec{h}$ into a simplex which is useful for categorical distributions. For this reason, often the output is not exactly correct to say we have a probability distribution (we don\u0026rsquo;t often have priors), but in practice it\u0026rsquo;s a useful concept.\nThe simplex The $K$ dimensional simplex $\\Delta^{K - 1}$ is the region of $\\mathbb{R}^{K}_{\\geq 0}$ where the sum of components is 1. Down here we have an example of the $\\Delta^{2}$ simplex. $d-1$ degrees of freedom for the simplex, because the last dimension is a linear combination of the previous ones. The role of temperature The $T$ parameter is a non-negative parameter that tells us how much spread our categories are. If $T \\to 0$ we have the $\\max$ function automatically. if $T \\to \\infty$ we have maximum entropy, so we have uniform categorical distribution. So $T$ allows us to smoothly interpolate between argmax and uniform distribution. The interesting thing is that it is a differentiable version of the max, which byitself is not differentiable.\n$$ \\lim_{ T \\to 0 } \\text{softmax}(\\vec{h}) = \\begin{cases} [1, 0]^{T}, h_{1} \u003e h_{2} \\\\ \\left[ \\frac{1}{2}, \\frac{1}{2} \\right]^{T}, h_{1} = h_{2} \\\\ [0, 1]^{T}, h_{1} \u003c h_{2} \\end{cases} $$ If we have $\\vec{h} = [h_{1}, h_{2}]$. This is a easy giustification of why we call this softmax.\nThe partial derivative We can calculate the derivative of the log softmax and we obtain:\n$$ \\frac{ \\partial \\log \\text{ softmax }(\\vec{h}, y) }{ \\partial h_{i} } = \\delta_{yi} - \\text{softmax} (\\vec{h}, i) $$Relationship with Maximum Entropy Principle Related to Maximum Entropy Principle for a discussion about that principle. Here we will provide some arguments why Softmax is usually a good choice:\nTODO: See here slide 98.\nSigmoid and Rates of Growth $$ \\frac{d f}{d x} = f(1 - f) $$$$ f(x) = \\frac{1}{1 + C\\exp(-x)} $$ Which is exactly the Sigmoid function, by modelling $C = \\exp(w)$.\n","permalink":"https://flecart.github.io/notes/softmax-function/","summary":"\u003cp\u003eSoftmax is one of the most important functions for neural networks. It also has some interesting properties that we list here. This function is part of \u003ca href=\"/notes/the-exponential-family/\"\u003eThe Exponential Family\u003c/a\u003e, one can also see that the sigmoid function is a particular case of this softmax, just two variables.\nSometimes this could be seen as a relaxation of the action potential inspired by neuroscience (See \u003ca href=\"/notes/the-neuron/\"\u003eThe Neuron\u003c/a\u003e for a little bit more about neurons). This is because we need \u003cstrong\u003edifferentiable\u003c/strong\u003e, for gradient descent. The action potential is an all or nothing thing.\u003c/p\u003e","title":"Softmax Function"},{"content":"In order to define the concept of probability formally, we need first to introduce some mathematical concepts.\nLa probabilit√† Termini Esito ed esperimenti aleatorio L‚Äôevento √® quello che accade, mentre un esperimento aleatorio qualcosa di cui vogliamo andare a misurare la probabilit√† diciamo. Esperimento aleatorio: esperimento di cui non conosciamo il risultato con certezza. Esito: risultato dell‚Äôesperimento aleatorio\nSpazio campionario ed evento Spazio campionatorio Lo spazio campionatorio √® l\u0026rsquo;insieme di tutti gli stati possibili per una certa cosa da misurare (ossia di un esperimento aleatorio), gli stati sono talvolta anche chiamati sample points oppure outcomes in modo pi√π semplice.\nEvento √à un sottoinsieme dello spazio campionatorio. Se qualcosa della cosa che stiamo misurando √® dentro questo sottoinsieme, all\u0026rsquo;ora diciamo che l\u0026rsquo;evento √® accaduto altrimenti no.\nNOTA: dato che stiamo parlando di sottoinsiemi, valgono tutte le operazioni di intersezione unione, complementare studiate durante Teoria assiomatica degli insiemi.\nUno spazio di probabilit√† di solito √® definito come $\\Omega, F, P$, con F sigma algebra e P una misura di probabilit√†, ossia tale per cui $P(\\Omega) = 1,$ √® additiva, che descriviamo leggermente meglio in seguito. Si pu√≤ dire che $P$ sia una funzione dall\u0026rsquo;insieme delle parti di $\\Omega$ ai reali in $[0, 1]$.\nUna cosa particolare da osservare riguardo $P$ √® che questa probabilit√† non √® osservabile, non riusciamo ad osservare il fatto che il singolo evento abbia una certa probabilit√†, questa probabilit√† √® qualcosa che nasce dopo un numero molto alto di trials che si susseguono per uno stesso processo stocastico.\nGli eventi poi formano una algebra.\n$\\sigma$-algebra: The Events üü®++ Given a set $\\Omega$, a sigma algebra $\\mathcal{A} \\in P(\\Omega)$ is a set such that:\n$\\Omega \\in \\mathcal{A}$. If $A \\in \\mathcal{A}$ then $\\bar{A} \\in \\mathcal{A}$. Closed under countable unions: if $A_{i} \\in \\mathcal{A}$ then $\\cup_{i= 1}^{\\infty} A_{i} \\in \\mathcal{A}$ This will be central when we will talk about experiments. We say that all elements of the set $\\mathcal{A}$ are called events. $\\Omega$ is often called sample space.\nProbability measure üü© We say that the function $\\mathbb{P} : \\mathcal{A} \\to \\mathbb{R}$ is a probability measure, given a certain $\\sigma$-algebra $(\\Omega, \\mathcal{A})$, when it satisfies the classical Kolmogorov Axioms (aka probability axioms):\n$0 \\leq \\mathbb{P}(\\mathcal{A}) \\leq 1$ for any $A \\in \\mathcal{A}$ $\\mathbb{P}(\\Omega) = 1$ For any disjoint set of events $A_{i} \\in \\mathcal{A}$ we have $$ \\mathbb{P}(\\cup_{i = 1}^{\\infty}A_{i}) = \\sum_{i=1}^{\\infty}\\mathbb{P}(A_{i}) $$ Conseguenze principali degli assiomi Valore dell\u0026rsquo;insieme vuoto Possiamo considerare una successione infinita di elementi vuoti, questi sono tutti disgiunti, e sono anche tutti uguali perch√© sono applicati sullo stesso insieme.\nSe fosse diverso da 0 allora sarebbe infinito, ma deve essere compreso fra 0 e 1, quindi deve essere 0.\nUnione Disgiunta finita Basta andare a considerare una successione con 0, questa √® infinita, ma i vuoti non danno nessun contributo quindi vale ancora:\n$$ \\mu(\\bigcup^n A_n) = \\mu(\\bigcup^\\infty A_n) = \\sum^\\infty \\mu(A_n) = \\sum^n \\mu(A_n) = $$Valore dell\u0026rsquo;inverso deve essere che, basta considerare che $\\Omega = A_n \\cup A_n^c$ e l‚Äôunione disgiunta.\n$$ \\mu(A_n) = 1 - \\mu(A_n^c) $$Monotonia della probabilit√† Ossia se vale\n$$ A \\subset B \\implies \\mu(A) \\leq \\mu (B) $$Principio di inclusione esclusione Probabilit√† uniforme üü© Il primo √® vero perch√©\n$$ \\forall i, n \\cdot P(w_i) = \\sum_{i =1}^n P(\\omega_i) = P(\\bigcup_{i = 1} ^n \\omega_i) = P(\\Omega) = 1 \\implies \\forall i, P(w_i) = 1/n $$L‚Äôaltro √® la formula di laplace, perch√© siano il numero di eventi di A, posso scriverlo come unione di quegli elementi, abbiamo detto che sono n, per questo riesco a ricostruire quel numero.\nProbabilit√† discreta Se abbiamo una distribuzione di probabilit√†, cio√® una probabilit√† definita su tutti gli elementi singoletto, allora possiamo avere una probabilit√† discreta, ossia probabilit√† ben definita che sia finito o numerabile.\nDefinizione probabilit√† discreta üü© Densit√† discreta\nPer 1.7 si intende che p deve essere compreso fra 0 e 1 e la somma per tutti gli elementi dello spazio campionario deve essere 1\nCaratterizzazione probabilit√† discrete üü© Continuit√† della probabilit√† discreta üü®+ Dimostrazione\nOssia se ho uno spazio di probabilit√† allora posso avere delle caratteristiche (brutte secondo lollo) riguardo la continuit√† della funzione.\nAnche se per questa parte che non utilizza teoria della misura questo teorema non √® che sia molto utile.\nComunque per questa parte forse √® meglio farlo dalla misura definita sulle algebre, che √® fatta in maniera pi√π generale e ho anche la sigma sub-additivit√† all\u0026rsquo;interno, non so, forse pi√π difficile??\nImpostazione classica della teoria della probabilit√† (non fare) Spazi di misura e di probabilit√† Dico che ho uno spazio misurabile una coppia $(\\Omega, F)$, tale che F sia un insieme di sottoinsiemi di omega, chiamato spazio campionario, e F insieme di eventi. Deve essere che F √® una sigma algebra, ossia tali per cui siano chiusi per complementazione e per unione contabile.\nSi parla di spazio di misura quando allo spazio misurabile associamo una funzione di misura.\nParliamo di spazio di probabilit√† se ho anche una funzione di misura tale per cui $P(\\Omega) = 1$, . Si ricorda che la funzione di misura √® tale se ha come codominio 0 to infty, e ha vuoto = 0, e che sia sigma additiva.\nContinuit√† dall‚Äôalto e dal basso. Se ho che la funzione di misura sia finita, allora vale che $A_n \\uparrow A, \\lim_{n \\to \\infty} \\mu(A_n) = \\mu (A)$ , e che\n$\\forall i, i \u003c n, A_i \\subseteq A_n$\nIn modo simile √® definito la continuit√† dal basso, solo che ora sono insiemi uno incluso l‚Äôaltro. Attualmente non so cosa implichi questo fatto, n√© in che modo √® utilizzata questa continuit√†‚Ä¶ Forse per Borel Cantelli, ma poi non so cosa farmene di borel cantelli‚Ä¶\nEvento complementare\nSommatoria finita di eventi disgiunti\nPrincipio di inclusione-esclusione üï≥Ô∏è\n","permalink":"https://flecart.github.io/notes/spazi-di-probabilita/","summary":"\u003cp\u003eIn order to define the concept of probability formally, we need first to introduce some mathematical concepts.\u003c/p\u003e\n\u003ch2 id=\"la-probabilit√†\"\u003eLa probabilit√†\u003c/h2\u003e\n\u003ch2 id=\"termini\"\u003eTermini\u003c/h2\u003e\n\u003ch3 id=\"esito-ed-esperimenti-aleatorio\"\u003eEsito ed esperimenti aleatorio\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eL‚Äôevento\u003c/strong\u003e √® quello che accade, mentre un esperimento aleatorio qualcosa di cui vogliamo andare a misurare la probabilit√† diciamo.\n\u003cstrong\u003eEsperimento aleatorio:\u003c/strong\u003e esperimento di cui non conosciamo il risultato con certezza.\n\u003cstrong\u003eEsito\u003c/strong\u003e: risultato dell‚Äôesperimento aleatorio\u003c/p\u003e\n\u003ch3 id=\"spazio-campionario-ed-evento\"\u003eSpazio campionario ed evento\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eSpazio campionatorio\u003c/strong\u003e\nLo spazio campionatorio √® l\u0026rsquo;insieme di tutti gli stati possibili per una certa cosa da misurare (ossia di un esperimento aleatorio), gli stati sono talvolta anche chiamati \u003cem\u003esample points\u003c/em\u003e oppure \u003cem\u003eoutcomes\u003c/em\u003e in modo pi√π semplice.\u003c/p\u003e","title":"Spazi di probabilita"},{"content":"Spazi vettoriali 1.1 Piano cartesiano 1.1.1 Definizione Possiamo considerare il piano cartesiano come l\u0026rsquo;insieme $\\R^2$ potremmo dire che esiste una corrispondenza fra una coordinata e un punto del piano, una volta che abbiamo definito un punto di origine. Si pu√≤ vedere anche come corrispondenza biunivoca con vettori del piano per l\u0026rsquo;origine (parte dall\u0026rsquo;origine).\nQuesta cosa vale anche per uno spazio n-dimensionale, non soltanto due, ma per semplicit√† di introduzione di questo lo faccio con 2\n1.1.2 Operazioni definite Possiamo definire una somma fra questi punti in coordinata e un prodotto.\nSomma $\\forall a,b,c,d \\in \\mathbb{R} \\,\\,\\langle a,b\\rangle + \\langle c,d \\rangle = \\langle a + c, b+d\\rangle$\n(dovremmo definire invece queste cose nello spazio vettoriale, in quanto non necessariamente dobbiamo averle in R)\nProdotto scalare $\\forall a,b \\in V, \\lambda \\in \\mathbb{R}, \\lambda\\langle a, b\\rangle = \\langle \\lambda a, \\lambda b \\rangle$\nSpazio normato Una tupla $(X, \\lVert \\cdot \\rVert)$ dove $X$ √® uno spazio vettoriale e $\\lVert \\cdot \\rVert$ una funzione che soddisfa gli assiomi della norma (vedi Norme e Condizionamento), si chiama spazio normato.\n$$ \\lambda(x, y) = \\lVert x- y \\rVert $$ Che lo rende quindi una topologia (vedi Topological Spaces).\nSpazi di Banach Se ogni sequenza di Cauchy (vedi Serie) converge in $X$ allora $X$ √® uno spazio di Banach. Scritto in matematichese questo si traduce cos√¨: data una successione $\\{x_n\\}$ di Cauchy, esiste un $x \\in X$ tale che $\\forall \\varepsilon$ \u0026gt; 0 , $\\exists N \u003e 0$ tale che per ogni $n ,m$ \u0026gt; N si ha che $\\lVert x_n - x_m \\rVert \u003c \\varepsilon$.\n1.2 Introduzione agli spazi vettoriali 1.2.1 Assiomi di base Definiamo qui le propriet√† necessarie per essere uno spazio vettoriale.\nGruppo abeliano rispetto alla addizione (4) $V \\times V \\to V$ Vedi: Gruppi Moltiplicazione √® scalare, definito su un campo $C \\times V \\to V$ Associativit√† Elemento neutro presente. Vale distributivit√† destra e sinistra che collega addizione e prodotto 1.2.2 Conseguenze principali degli assiomi 1.2.3 Interpretazione geometrica (2) Principalmente ci sono due interpretazioni possibili. Per punti o vettori.\nPunti esiste una corrispondenza biunivoca fra uno spazio n-dimensionale e la coordinata Vettori esiste una corrispondenza biunivoca fra vettori che iniziano dall\u0026rsquo;origine e in punti. 1.2.4 Polinomi a coefficienti in R (Esempio) Questo √® un esempio di spazio vettoriale. Si pu√≤ fare una verifica per vedere che gli assiomi sono soddisfatti.\nAltri spazi vettoriali sono l\u0026rsquo;insieme delle matrici con coefficienti reali, l\u0026rsquo;insieme delle funzioni continue in R.\n1.2.5 Sottospazio vettoriale (def e banale) Un sottospazio vettoriale √® un sottoinsieme che √® chiuso per l\u0026rsquo;addizione e moltiplicazione.\nSia U un sottospazio di V, allora per definizione vale:\nU non √® vuoto chiuso rispetto somma Chiuso rispetto moltiplicazione Il sottospazio banale √® un sottospazio che contiene solo l\u0026rsquo;elemento nullo per l\u0026rsquo;addizione\nSi pu√≤ anche trovare una serie di assiomi equivalenti per il sottospazio\n1\u0026rsquo;. il vettore $0_v$appartiene al sottospazio U, e valgono 2 e 3\nE si pu√≤ scrivere una propriet√† equivalente a 2 e 3, ossia chiuso rispetto a una combinazione lineare.\nEsercizio\nDimostrare che le ipotesi 2 e 3 implicano che $\\lambda a + \\lambda_2b \\in V,$ con i lambda valori del campo.\n1.2.6 Minimi sottospazi (classificazione sottospazi di R2) Se prendiamo un punto nel piano, ci basta una retta che passa per essa e per l\u0026rsquo;origine per avere il minimo sottospazio che lo contenga.\nIl ragionamento per dire che √® il minimo √® pi√π o meno su questa scia:\nSe contiene quel punto diverso da 0, allora deve contenere tutti i punti sulla retta almeno (altrimenti non √® chiuso per il prodotto scalare). Se ne contiene di pi√π non √® pi√π il minimo sottospazio, se ne contenesse di meno allora ci sarebbe un assurdo con il punto uno. Si pu√≤ dire la stessa cosa per 2 o pi√π punti allineati. Se per√≤ non sono allineati, allora devo prendere il loro span. Ovvero se ho $u, v$ indipendenti fra di loro allora il minimo sottospazio √®\n$\\alpha v + \\beta u$ che √® l\u0026rsquo;intero piano. (questo poi √® anche la condizione 23 per dimostrare che √® sottopiano).\nSu questa analisi pu√≤ dimostrare che gli unici sottospazi di R2 sono 3.\nBanale Retta R2 Possiamo formalizzare il senso di pi√π piccolo sottospazio che contiene un elemento come l\u0026rsquo;insieme sottospazio che √® contenuto in ogni altro sottospazio (e si potrebbe dire quindi anche che non esiste un altro sottospazio pi√π piccolo)\n1.3 Combinazioni lineari 1.3.1 definizione Si dice che $v$ √® combinazione lineare di vettori $v_1, ... v_n$ se esistono $\\lambda_1,...,\\lambda_n \\in K$ tali che\n$\\lambda_1v_1 + ....+ \\lambda_n v_n = v$\nPossiamo prendere l\u0026rsquo;insieme delle combinazioni lineari cihe scriviamo come\n$\\langle v_1, ..., v_n \\rangle = \\{\\lambda_1 v_1 +... + \\lambda_n v_n | \\lambda_1, ..., \\lambda_n \\in R\\}$\nSe $V = \\langle v_1, ..., v_n \\rangle$ allora i vettori $v_1, ..., v_n$ generano lo spazio vettoriale $V$\n1.3.2 Proposizione 3.1.5 minimo sottospazio (chiede in esame) Enunciato:\nSia $V$ uno spazio vettoriale, allora $v_1, ..., v_n \\in V$ allora $\\langle v_1,...v_n\\rangle$ √® uno sottospazio vettoriale di $V$ ed √® il minimo sottospazio vettoriale contenenti questi punti.\nDimostrazione: esercizio (non troppo complessa).\nhint di dimostrazione\nBisogna dimostrare due cose: 1 √® uno sottospazio vettoriale (soddisfa quei tre requisiti) e 2 √® il minimo sottospazio vettoriale, quindi qualunque latro sottospazio vettoriale che contiene quei punti contiene anche questo spazio vettoriale).\n1.3.3 Prop 3.1.8 dipendenza lineare + 1 (relativo a span) sia $\\langle v_1, ..., v_n \\rangle$ uno spazio vettoriale generato da quei vettori, considero $\\langle v_1, ..., v_n, \\omega \\rangle$ con $\\omega$ una combinazione vettoriale dei vettori base, allora si ha che\n$\\langle v_1, ..., v_n \\rangle = \\langle v_1, ..., v_n, \\omega \\rangle$\nHint di dimostrazione\nil primo √® contenuto nel secondo (abbastanza ovvio, basta che tengo W 0), devo dimostrare che il secondo √® contenuto nel primo.\n(in pratica riesco a dimostrare che qualunque combinazione lineare con $\\omega$ √® esprimibile come combinazione lineare dei vettori che generano lo spazio vettoriale iniziale\nUn altro modo per dimostrarlo √® prendere Z generato dal primo insieme di vettori, so che tutti questi vettori sono contenuti in Z, cos√¨ anche omega √® contenuto, allora si ha per la 3.1.5 che questo spazio vettoriale √® contenuto in Z.\nSi pu√≤ dimostrare una cosa anche contraria, ovvero\n$\\langle v_1, ..., v_n \\rangle = \\langle v_1, ..., v_n, \\omega \\rangle \\implies \\omega$ combinazione lineare di $v_1,..., v_n$\n1.4 Indipendenza lineare Questo concetto di indipendenza lineare ci permette di definire una base per uno spazio vettoriale (ossia il minimo insieme di vettori necessario per generare uno spazio)\n1.4.1 Definizione Un insieme di vettori $v_1,..., v_n$ sono linearmente indipendenti sse $\\alpha_1v_1 + ... + \\alpha_nv_n = 0 \\iff \\alpha_1 = ... = \\alpha_n = 0$\nUn insieme di vettori allora si dice linearmente dipendente se esiste un insieme di coefficienti tali che non tutti diversi da zero ottengo che $\\alpha_1v_1 + ... + \\alpha_n = 0$\nOsservazione\nSe un insieme di vettori contiene il vettore $0_v$ allora so per certo che sono linearmente dipendenti in quanto a questo vettore posso molitplicare qualunque cosa, fatto che va contro la definizione di indipendenza lineare\n1.4.2 Prop 3.2.4 Corrispondenza combinazione e dipendenza lineare (chiede) Enunciato\nSe $v_1,...,v_n$ vettori dipendenti fra loro $\\iff$ almeno uno di essi √® combinazione lineare di dell\u0026rsquo;insieme dei vettori in questione.\nDimostrazione\n$\\implies$\nSiano v1\u0026hellip; vn vettori dipendenti fra loro, dobbiamo dimostrare che esiste uno che sia combinazione lineare di altri.\nPer ipotesi di dipendenza se $\\lambda_1v_1 +... + \\lambda_nv_n =0, \\exists k, 0 \u003c k \\leq n, \\lambda_k \\neq 0$.\nAllora $\\lambda_kv_k = -(\\lambda_1v_1 +...+ \\lambda_{k-1}v_{k-1} +\\lambda_{k+1}v_{k+1} +...+ \\lambda_nv_n)$ e da qui √® abbastanza ovvio che posso scrivere $v_k$ come combinazione lineare di altri.\n$\\impliedby$\nSia $v_k$ una combinazione lineare dell\u0026rsquo;insieme di vettori $v_1, ..., v_{k-1},v_{k+1},..., v_n$\nAllora ho che $v_k = \\lambda_1v_1 +...+ \\lambda_{k-1}v_{k-1} +\\lambda_{k+1}v_{k+1} +...+ \\lambda_nv_n$ per certi valori di lambda.\nAllora se considero questa combinazione lineare\n$-\\lambda_1v_1 +... -\\lambda_{k-1}v_{k-1} + 1\\cdot v_k -\\lambda_{k+1}v_{k+1} +...- \\lambda_nv_n$ ottengo che questo √® uguale a 0 e in particolare ho che il coefficiente di $v_k$ √® diverso da 0, quindi questi vettori sono dipendenti.\nOsservazione (sui multipli)\nNel caso in cui ho due vettori, il fatto che uno √® combinazione lineare dell\u0026rsquo;altro √® equivalente a dire che uno √® multiplo dell\u0026rsquo;altro.,\n1.4.3 Geometria nella dipendenza lineare Due vettori\nAbbiamo detto che due vettori sono linearmente dipendenti quando uno sono multiplo dell\u0026rsquo;altro, possiamo intendere questo fatto algebrico come un fatto geometrico osservando che tali vettori devono giacere sulla stessa retta\nTre vettori\nIn modo analogo al precedente, possiamo concludere che tre vettori sono linearmente dipendenti sse giacciono su uno stesso piano (COMPLANARI)\nPi√π vettori\nSe ho n vettori, questi se fossero indipendenti giacerebbero su uno spazio n-dimensionale, appena √® possibile esprimerli come appartenenti a uno spazio di dimensione minore di n, allora posso dire che questi n vettori sono dipendenti, questa √® l\u0026rsquo;astrazione necessaria per comprendere questo fatto.\n","permalink":"https://flecart.github.io/notes/spazi-vettoriali/","summary":"\u003ch1 id=\"spazi-vettoriali\"\u003eSpazi vettoriali\u003c/h1\u003e\n\u003ch2 id=\"11-piano-cartesiano\"\u003e1.1 Piano cartesiano\u003c/h2\u003e\n\u003ch3 id=\"111-definizione\"\u003e1.1.1 Definizione\u003c/h3\u003e\n\u003cp\u003ePossiamo considerare il piano cartesiano come l\u0026rsquo;insieme $\\R^2$ potremmo dire che esiste una corrispondenza fra una coordinata e un punto del piano, una volta che abbiamo definito un punto di origine. Si pu√≤ vedere anche come corrispondenza biunivoca con vettori del piano per l\u0026rsquo;origine (parte dall\u0026rsquo;origine).\u003c/p\u003e\n\u003cp\u003eQuesta cosa vale anche per uno spazio n-dimensionale, non soltanto due, ma per semplicit√† di introduzione di questo lo faccio con 2\u003c/p\u003e","title":"Spazi vettoriali"},{"content":"Particelle in campi magnetici Moto in campo magnetico uniforme üü© Se abbiamo una particella carica con velocit√† uniforme in campo magnetico uniforme, come abbiamo detto in precedenza, una forza centripeta, questo far√† curvare la carica, una cosa interessante sarebbe provare a capire raggio di curvatura della nostra carica. Sotto in immagine abbiamo l\u0026rsquo;esempio di curvatura. $$ F = qvB= ma = \\frac{mv^{2}}{r} \\implies r = \\frac{mv^{2}}{qvB} = \\frac{mv}{qB} = \\frac{p}{qB} $$ Dove $p$ √® la quantit√† di moto, quantit√† che credo sia relazionata al lavoro ed inerzia, parte di fisica 1 che non ho studiato da pi√π di due anni. Questa stessa relazione, conoscendo il raggio pu√≤ essere usata per calcolare il campo magnetico!.\n$$ \\omega = \\frac{v}{r} = \\frac{vqB}{mv} = \\frac{qB}{m} $$$$ \\vec{\\omega} = -\\frac{q\\vec{B}}{m} $$ Ma questo vale solo classicamente, perch√© poi entrano in gioco irradiazioni che fanno perdere energia e anche cose relativistiche se accelero troppo.\nSupponiamo ora che ci sia un certo angolo fra i due allora ho che solamente la parte normale ha forza, avr√≤ un moto elicoidale.\nAngolo generico üü© $$ F = qv \\times B = q(\\vec{v}_{n} + \\vec{v}_{p}) \\times \\vec{B} = q\\vec{v}_{n}\\times \\vec{B} $$$$ p = v_{p} T = v_{p} \\frac{2\\pi}{\\omega} = \\frac{2\\pi mv_{p}\\cos \\theta}{qB} $$ Dove $v_{p}$ √® la velocit√† parallela al campo magnetico, e $T$ √® il periodo che √® calcolato dalla velocit√† angolare. Il coseno serve per prendere la componente corretta credo\u0026hellip;.\nEffetto Hall üü© $$ \\vec{F} = q\\vec{v}_{d} \\times \\vec{B} $$$$ F = qE_{m} = q\\vec{v}_{d}\\times \\vec{B} \\implies E_{m} = v_{d}B $$ Questo fa accumulare carica positiva sopra, che crea un altro campo elettrico statico che prova a bilanciare. Il primo passaggio √® motivato perch√© √® come se esistesse un campo elettrico fittizio, per spostarlo su. (√à un campo elettrico generato!).\n$$ \\Delta V_{M} = E_{m} b = v_{d}Bb = b\\vec{J}\\times \\frac{\\vec{B}}{nq} = i \\frac{\\hat{u}}{a}\\times \\frac{\\vec{B}}{nq} \\implies \\Delta V = \\frac{iB}{nqa} $$ Dove $b$ √® l\u0026rsquo;altezza, e $a$ √® la width del nostro filo.\nQuesto permette di misurare il campo magnetico ed √® chiamato sonda di Hall, basta misurare la differenza potenziale presente. Per esempio questo diventa molto utile quando per Magnetismo nella materia andiamo poi a misurare il campo magnetico in buchi, basta mettere questa sonda di Hall.\nSpettrometri di massa Spettrometro di massa di Thomson üü© Ho un coso che emette particelle in tutte le direzioni, faccio passare una zona per aumentare energia e poi campo magnetico $$ \\frac{1}{2}mv^{2} = q\\Delta V \\implies v = \\sqrt{ \\frac{2qV}{m} } $$ Usiamo poi questo valore che ci permette di descrivere la velocit√† della particella prima che entrino nel campo magnetico, e otteniamo poi che, considerando l\u0026rsquo;accelerazione centripeta. $$ F = qvB = \\frac{mv^{2}}{r} \\implies r = \\frac{mv}{qB} =\n$$ Questo √® uno strumento buono per separare **isotopi**, perch√© hanno una massa diversa, ma stessa carica. Posso anche definire il rapporto fra i raggi degli isotopi che √® $$ \\frac{r_{1}}{r_{2}} = \\sqrt{ \\frac{m_{1}}{m_{2}} } $$\nSelettore di velocit√† üü© $$ qE = q\\vec{v} \\times \\vec{B} \\implies E = vB $$$$ qvB_{0} = \\frac{mv^{2}}{R} \\implies R = \\frac{mv}{qB_{0}} = \\frac{mE}{qBB_{0}} $$ Anche questo posso usarlo per separare isotopi diversi, ma la cosa bella √® che questo √® lineare mentre prima avevamo una radice quadrata.\nSpire Setting classico: spira rettangolare üü© Prendiamo un campo magnetico costante, e un rettangolo di filo indeformabile (perch√© ci sono forze che potrebbero deformarla), in cui c\u0026rsquo;√® corrente, questo fa girare. $$ F_{4} = F_{3} = 0, F_{1} = F_{2} = 0 $$ Ossia la spira non trasla, perch√© non c\u0026rsquo;√® accelerazione, non trasla il centro di massa. E questo per qualche motivo ci permette anche di usare qualunque sistema di riferimento, tanto diventer√† uguale\u0026hellip;\n$$ M = \\vec{M}_{1} + \\vec{M}_{2} = \\vec{r}_{1}\\times \\vec{F}_{1} + \\vec{r}_{2}\\vec{F}_{2} = \\frac{b}{2}\\sin \\theta F_{1} + \\frac{b}{2} \\sin \\theta F_{2} = bsen\\theta F = b \\sin \\theta iaB = i \\vec{S} \\times \\vec{B} $$Per i lati su e gi√π abbiamo stessa forza che si annulla, per altri invece abbiamo un momento ora.\nMomento magnetico di spira üü© $$ \\vec{m} = i\\vec{S} $$$$ \\vec{M} = \\vec{m} \\times \\vec{B} $$ Che sta clean. Questo √® molto simile al valore trovato per il momento nel Dipolo elettrico, in cui abbiamo il momento di dipolo.\nPiccole oscillazioni üü• $$ \\lvert \\vec{M} \\rvert = -mB\\sin \\theta = mB\\theta = I\\dot{\\omega}= I\\ddot{\\theta} $$$$ \\ddot{\\theta} + \\omega^{2}\\theta=0 $$ Questo permette di calcolare il campo magnetico, col periodo. La cosa interessante √® che questo si comporta come un ago magnetico, stesso comportamento.\n","permalink":"https://flecart.github.io/notes/spettrometri-di-massa/","summary":"\u003ch3 id=\"particelle-in-campi-magnetici\"\u003eParticelle in campi magnetici\u003c/h3\u003e\n\u003ch4 id=\"moto-in-campo-magnetico-uniforme-\"\u003eMoto in campo magnetico uniforme üü©\u003c/h4\u003e\n\u003cp\u003eSe abbiamo una particella carica con velocit√† uniforme in campo magnetico uniforme, come abbiamo detto in precedenza, una forza centripeta, questo far√† \u003cstrong\u003ecurvare la carica\u003c/strong\u003e, una cosa interessante sarebbe provare a capire \u003cstrong\u003eraggio di curvatura\u003c/strong\u003e della nostra carica. Sotto in immagine abbiamo l\u0026rsquo;esempio di curvatura.\n\u003cimg src=\"/images/notes/Magnetismo-1700054485909.jpeg\" alt=\"Magnetismo-1700054485909\"\u003e\u003c/p\u003e\n$$\nF = qvB= ma = \\frac{mv^{2}}{r}\n\\implies r = \\frac{mv^{2}}{qvB} = \\frac{mv}{qB} = \\frac{p}{qB}\n$$\u003cp\u003e\nDove $p$ √® la quantit√† di moto, quantit√† che credo sia relazionata al lavoro ed inerzia, parte di fisica 1 che non ho studiato da pi√π di due anni.\nQuesta stessa relazione, conoscendo il raggio \u003cem\u003epu√≤ essere usata per calcolare il campo magnetico!\u003c/em\u003e.\u003c/p\u003e","title":"Spettrometri di massa"},{"content":"$$ x! \\approx x^{x}e^{-x}\\sqrt{ 2\\pi x } \\iff \\ln x! \\approx x\\ln x - x + \\frac{1}{2} \\ln(2\\pi x) $$This proof (more like an interesting justification). is taken from page 2 of (MacKay 2003).\n$$ P(r \\mid \\lambda) = \\frac{e^{-\\lambda}\\lambda^{r}}{r!} $$$$ e^{-\\lambda} \\frac{\\lambda^{\\lambda}}{\\lambda!} \\approx \\frac{1}{\\sqrt{ 2\\pi \\lambda }} \\implies \\lambda! \\approx \\lambda^{\\lambda}e^{-\\lambda}\\sqrt{ 2\\pi \\lambda } $$ Which finishes the derivation of the approximation.\nApproximation of the binomial A quick derivation with the Stirling\u0026rsquo;s approximation gives a nice approximation for log of the binomials\n$$ \\ln \\binom{N}{r} \\equiv \\ln \\frac{N!}{(N - r)! r!} \\approx \\ln \\frac{N^{N} \\sqrt{ 2\\pi N }}{(N - r)^{N - r} \\sqrt{ 2\\pi (N - r) } r^{r} \\sqrt{ 2\\pi r }} = $$$$ = N\\ln N + \\frac{1}{2}\\ln(2\\pi N) - (N - r)\\ln(N - r) - r\\ln r - \\frac{1}{2}\\ln(4\\pi^{2}(N - r)r) = $$$$ = (N - r) \\ln\\left( \\frac{N}{N - r} \\right) + r \\ln \\left( \\frac{N}{r} \\right) + \\frac{1}{2}\\ln\\left( 2\\pi N \\frac{N-r}{N} \\frac{r}{N} \\right) $$$$ H_{2}(x) = x \\ln\\left( \\frac{1}{x} \\right) + (1- x)\\ln\\left( \\frac{1}{1 - x} \\right) $$ with $x = \\frac{r}{N}$, + another asymptotically constant approximation term (or $\\sqrt{ n }$ if you look at the logits..\nReferences [1] MacKay ‚ÄúInformation Theory, Inference and Learning Algorithms‚Äù Cambridge University Press 2003\n","permalink":"https://flecart.github.io/notes/stirlings-approximation/","summary":"$$\nx! \\approx x^{x}e^{-x}\\sqrt{ 2\\pi x } \\iff \\ln x! \\approx x\\ln x - x  + \\frac{1}{2} \\ln(2\\pi x)\n$$\u003cp\u003eThis proof (more like an interesting justification). is taken from page 2 of (MacKay 2003).\u003c/p\u003e\n$$\nP(r \\mid \\lambda) = \\frac{e^{-\\lambda}\\lambda^{r}}{r!}\n$$$$\ne^{-\\lambda} \\frac{\\lambda^{\\lambda}}{\\lambda!} \\approx \\frac{1}{\\sqrt{ 2\\pi \\lambda }}\n\\implies \\lambda! \\approx \\lambda^{\\lambda}e^{-\\lambda}\\sqrt{ 2\\pi \\lambda }\n$$\u003cp\u003e\nWhich finishes the derivation of the approximation.\u003c/p\u003e\n\u003ch3 id=\"approximation-of-the-binomial\"\u003eApproximation of the binomial\u003c/h3\u003e\n\u003cp\u003eA quick derivation with the Stirling\u0026rsquo;s approximation gives a nice approximation for log of the binomials\u003c/p\u003e","title":"Stirling's Approximation"},{"content":"Guerre dei browser Prima guerra ~1995\nFra netscape, una forma di rete (?) che poi viene ripresa da firefox da Mozilla, dopo che √® stato mandato in bancarotta da Microsoft (che ha ancora con IE una grandissima fetta del mercato in questo primo periodo).\nSecondo periodo di guerra ~2010\nQuando arriva chrome, che vuole creare un browser che risolva tutti i problemi per creare integrazioni sui browser di altre aziende), mentre IE ha perso interesse per nuove features, che in questo periodo sono capi del proprio mercato.\nSu questa logica, partendo dal 2009, Chrome acquista una fetta del mercato grossa nel 2012. M$ prova a controbattere con Edge nel 2015, ma ormai √® un p√≤ tardi (ora rientra con bing tipo).\nIn questa parte viene anche introdotto un ciclo di bug-fix veloce, si chiama rapid release\nW3C and HTML Cose strane su brevetti‚Ä¶ Non volevano permettere modifiche dal loro standard HTML √® un living standard, non esiste pi√π un modo per definire se fosse coerente allo standard o meno.\nLock-in technologico e sviluppatori come utenti Vogliono creare un ambiente di sviluppo facile, e cercare di attirare alcuni sviluppatori, in modo che questi siano bloccati sui loro framework! (infatti costa imparare un nuovo framework, principalmente nuovo tempo, anche chiamao sunk cost).\n","permalink":"https://flecart.github.io/notes/storia-del-web/","summary":"\u003ch2 id=\"guerre-dei-browser\"\u003eGuerre dei browser\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003ePrima guerra ~1995\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eFra netscape, una forma di rete (?) che poi viene ripresa da firefox da Mozilla, dopo che √® stato mandato in bancarotta da Microsoft (che ha ancora con IE una grandissima fetta del mercato in questo primo periodo).\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSecondo periodo di guerra ~2010\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eQuando arriva chrome, che vuole creare un browser che risolva tutti i problemi per creare integrazioni sui browser di altre aziende), mentre IE ha perso interesse per nuove features, che in questo periodo sono capi del proprio mercato.\u003c/p\u003e","title":"Storia del web"},{"content":"Little bits of history It was invented in 1970 in Almaden (San Jose) by IBM (Don Chamberlin, Raymond Boyce worked on this) for the first relational database, called system R. Then for copyright issues it hasn\u0026rsquo;t been called SEQUEL, so they branded it as SQL.\nSQL is a declarative language With declaratives language there is a separation between what I call the intentionality and the actual process. In declarative languages we just say what we want the result to be, and don\u0026rsquo;t care what the actual implementation is like. This allows queries to be executed and optimized in different ways, even if the query on the surface is the same\nSQL is a functional language SQL is also a functional language, because the main principle is based on expression evaluation. This allows SQL to have some nested expressions in it.\nData types Default data types üü© I tipi di dati sono\nCarattere numero data tempo intervallo di tempo booleano blob (binario) clob (carattere) Setting custom data types üü© Ma possono essere definiti anche tipi di dati custom, la sintassi √® simile\nCREATE DOMAIN Grade AS SMALLINT DEFAULT NULL CHECK (value \u0026gt;= 18 AND value \u0026lt;= 30) Altering existing domains üü© In cui posso mettere anche dei check custom.\nDROP DOMAIN Per cancellare il domain l√¨ presente\nE si pu√≤ anche cambiare con\nALTER DOMAIN Posso aggiungere o eliminare constraints per esempio.\nPer√≤ a seguito di questo comando, dovrei essere in grado di modificare correttamente i valori con schema cambiato, metterli a default, o metterli a null diciamo.\nData definitions Database Creation üü© CREATE DATABASE db_name, che va a creare un database che pu√≤ contenere molte tavole, schemi diversi e simili.\nSchema üü® √à una descrizione logica di come √® strutturato l\u0026rsquo;intero database, non √® da confondere con lo schema di una singola tavola.\nSchema creation Lo schema √® la specificazione dei domini e delle restrizioni che ogni colonna deve avere per essere integra. In pi√π possono essere definite view diverse o anche authorization.\nCREATE SCHEMA schema_name\nTable La tavola specifica una relazione vuota, che pu√≤ seguire o meno uno schema, come definito di sopra.\nCreate table üü© Table constraints üü© Durante la creazione di una table posso specificare cose come\nTipo (intero, carattere?) Valore di default Constraints (tipo NOT NULL) Reference esterna o chiave di tavola. Deletion and change üü© Abbiamo comandi come\nDROP TABLE ALTER TABLE Per eliminare o cambiare lo schema della singola table.\nSolitamente posso modificare singole colonne per sql, aggiungere constraints o dati di default.\nReferential trigger üü©- Per le foreign keys posso andare a definire anche una\nAzione che viene eseguito quanto l\u0026rsquo;altra tabella viene Aggiornata Eliminata Azioni permesse sulla table con foreign key Cascade (eliminare o aggiornare di conseguenza) Set null set default no op, che non permette di fare l\u0026rsquo;operazione nemmeno sulla tavola originaria. Indexes üü®- Sono delle strutture di dati che permettono di svolgere certe operazioni in modo pi√π efficiente, cercheremo di distinguere i casi in cui √® effettivamente utile andare a creare questo indice. Questo solitamente √® fatto al livello fisico.\nCREATE INDEX idx_surname ON officer (Surname) Creo un indice con nome, su un attributo della table.\nData operations CRUD:\nCreate -\u0026gt; Insert Read -\u0026gt; SELECT Update -\u0026gt; UPDATE Delete -\u0026gt; DELETE (molto rischioso!) Select Le operazioni di select √® molto simile a proiezione e selezione che sono trattati in Relational Algebra.\nSintassi classica üü© SELECT attributes FROM tables and joins [WHERE condition] [GROUP BY attributes] [HAVING conditions] [ORDER BY attributes] Compare: algebra relazionale üü© Si possono considerare molte similitudini in Relational Algebra\nSelect and projection $\\pi_{age, height}(\\sigma_{age \u003c 30}(people))$ Select with renaming (projection) Pure select $\\sigma_{age\u003c30}(People)$ Projection without selection $\\pi_{age, height}(people)$ che prende colonne. Da questo si pu√≤ notare che SELECT da sola gestisce tre relazioni\nSelect Projection Rename Che sono stati trattati nell\u0026rsquo;algebra relazionale. Possono anche essere estesi ad avere le JOIN usando cose del from. Si potrebbe semplificare affermando\nWHERE = Selection in algebra relazionale SELECT = projection FROM = prodotto cartesiano. Esempio complesso di query con Cartesian product e renaming Like and null values üü© Like √® utilizzato per fare pattern matching sulla stringa. Mentre i null values si possono gestire con sintassi $AGE\\, is \\, NULL$\nJoin Sintassi üü® precedentemente nella sezione #Select abbiamo utilizzato join delle tables in maniera implicita utilizzando il prodotto cartesiano. Esiste per√≤ anche una istruzione esplicita per dire che vogliamo fare JOIN, molto coerente con la teoria presente in Relational Algebra.\nSELECT ... FROM leftTable [JOIN rightTable ON condition] [WHERE predicate] Esempio di differenza fra JOIN e il prodotto cartesiano con la sintassi di sopra. Inner and outer joins üü© La differenza principale fra inner e outer join √®\nInner Dati che non hanno elementi in comune vengono scartati (come quello presente sulla slides di sopra) questo viene anche chiamato natural join. Outer Vengono tenuti anche i dati che non fanno matching in una parte in comune, solitamente questi sono sempre chiamati left o right, ma vedremo dopo esattamente quale sia la semantica LEFT: (right √® esattamente il contrario) Ritorna sempre il sinistro, ma il destro pu√≤ anche essere null FULL: ritorna sinistro se c\u0026rsquo;√® e destro se c\u0026rsquo;√®.\nRemaining CRUD operations La sintassi di insertion, deletion and update √® molto pi√π semplice rispetto alla lettura, quindi la mettiamo nella sottosezione.\nInsert üü© NOTE: √® importante l\u0026rsquo;ordine di inserimento!\nINSERT INTO table [attrs] VALUES(vals) | SELECT roba.. Update üü© UPDATE TableName SET Attribute = \u0026lt; Expression, select, null or similar \u0026gt; WHERE \u0026lt;cond\u0026gt; Esempi: Delete üü© DELETE FROM table [WHERE condition] ### Altre Istruzioni #### Sorting üü© Per fare sorting basta aggiungere **ORDER BY** Order by pu√≤ essere ascendente o discendente (facile se √® alfanumerica come attributo). DEFAULT: descending. Union intersection and difference üü® UNIONE\nUso normale: come in figura Nel caso venga definito ALL, anche se √® doppio, viene mantenuto. Nel caso di conflitti semantici, utilizzare positional notation, se sono nella stessa posizione vengono messi assieme (il nome dell\u0026rsquo;attributo √® sempre della prima tavola) DIFFERENZA Si usa except, e poi altre notazioni sono simil ial precedente.\nINTERSEZIONE Si usa intersect come istruzione. (ma √® meglio usare il where, descritto in #Select, che √® equivalente).\nIntersection\nNested Queries NOTA: ogni subquery viene eseguita ogni volta per\nCorrectness conditions üü© Le queries innestate vengono eseguite per ogni tupla esterna, e sono corrette se quanto viene ritornato √® coerente con l\u0026rsquo;input del secondo\nSELECT Name, Income FROM People WHERE Name IN (SELECT Father FROM Fatherhood, People WHERE Child=Name AND Income\u0026gt;20) In questo caso IN si aspetta poi un insieme, che √® quanto ritornato nella subquery, il vantaggio principale di questo approccio √® la leggibilit√†,\nVisibilit√† üü© Ci sono due note riguardo la visibilit√†, perch√© seguendo una logica simile agli scopes strutturali se sono in scope esterno non posso accedere a quello internamente definito. Mentre la query innestata pu√≤ leggere variabili definite esternamente. Chiaramente se hai due nested diverse, non riescono ad avere stesso variabile, segui le stesse regole di scoping definito in linguaggi di programmazione.\nExistance üü© Exists Molto intuitivo, se sai un po' di [Logica del Primo ordine](/notes/logica-del-primo-ordine). #### Any and ALL üü©--- Sono altri predicati possibili per cose innestate Aggregate functions Gli aggregate consentono di ritornare un valore unico da una lista di dati. Hanno una semantica precisa: Prima fatto tutto, ignorando dell\u0026rsquo;esistenza del groupby, fanno una selezione di tutti gli attributi che sono presenti qui, e poi effettivamente raggruppano. Sul libro atzeni √® descritto in pagina 123. L\u0026rsquo;aspetto principale da ricordare √® che attributi in group by sono superset degli attributi di selezione.\nClassical sintax üü© La sintassi classica per questo genere di query √®\nAggr([DISTINCT] attribute) Attribute √® il dominio su cui andare a runnare la funzione di aggregazione.\nSome aggregate functions Count Ritorna semplicemente il numero di elementi dentro la lista Caso interessante da ricordare √® count NULL values AVG, MAX, MIN üü© Sintassi √® uguale al precedente, poi la semantica √® un po\u0026rsquo; diversa, ma credo sia chiara dal nome delal fuznione aggregate\nGrouping üü© La sintassi classica √® GROUP BY attributeList.\nSemantica üü© Prima esegue la query normale, come se grouping non esistesse. Poi esegue il grouping, e se c\u0026rsquo;√® un aggregate function, eseguirlo sul singolo gruppo. Questa cosa √® molto importante da conoscere perch√© altrimenti sbagli al query e questo mi era successo in passato, ci ho speso molto tempo. Giustifica anche il motivo per cui devi fare select dell\u0026rsquo;attributo di cui vuoi fare grouping, altrimenti non hai niente da grouppare diciamo! NOTA: aggregate √® eseguito sul singolo gruppo!\nOther conditions üü© Si pu√≤ usare HAVING per aggiungere altre condizioni sui gruppi in modo simile a quanto faceva WHERE dentro #Select.\nComportamento con i NULLs Altro Sull\u0026rsquo;esecuzione di SQL üü© √à il DBMS che si occupa di eseguire la query ed ottimizzarla. Avere query corrette e leggibili √® pi√π importante. Questo descrive anche il perch√© sarebbe a volte sensato farle innestate. ","permalink":"https://flecart.github.io/notes/structured-query-language/","summary":"\u003ch3 id=\"little-bits-of-history\"\u003eLittle bits of history\u003c/h3\u003e\n\u003cp\u003eIt was invented in 1970 in Almaden (San Jose) by IBM (Don Chamberlin, Raymond Boyce worked on this) for the first relational database, called system R. Then for copyright issues it hasn\u0026rsquo;t been called SEQUEL, so they branded it as SQL.\u003c/p\u003e\n\u003ch4 id=\"sql-is-a-declarative-language\"\u003eSQL is a declarative language\u003c/h4\u003e\n\u003cp\u003eWith declaratives language there is a separation between what I call the intentionality and the actual process. In declarative languages we just say what we want the result to be, and don\u0026rsquo;t care what the actual implementation is like.\nThis allows queries to be executed and optimized in different ways, even if the query on the surface is the same\u003c/p\u003e","title":"Structured Query Language"},{"content":"3.1 Introduzione 3.1.1 Cosa sono Le strutture di dati si interessano solamente di come memorizzare i dati, non necessariamente va a memorizzare un tipo di dato concreto.\nQuindi + sul come - sul cosa.\n3.1.2 Prototipo e implementazione Avevamo introdotto la differenza fra algoritmo e programma all\u0026rsquo;inizio del corso, andiamo ora a definire la differenza fra prototipo e implementazione:\nPrototipo:\nva a fare una descrizione dei metodi che deve avere una determinata struttura di dati. Lo puoi intendere come una specie di interfaccia.\nImplementazione:\n√à la creazione del programma in un determinato linguaggio di programmazione\n3.1.3 Distinzioni generali fra strutture di dati Le strutture di dati vengono distinte principalmente secondo 3 fattori\nLinearit√† vs non-linearit√† (sequenzialit√† degli elementi es std::set, std::unordered_set\nStaticit√† vs dinamicit√† (es array e vector)\nOmogeneit√† vs eterogeneit√† ( che tratta dei tipi di dato che sono memorizzabili\n3.2 Dizionario 3.2.1 Prototipo (propriet√† caratterizzanti) Questa √® una struttura di dati astratta composta principalmente da due cose:\nUn insieme di chiavi (uniche) associati a un valore (duplicabili). per questo motivo si pu√≤ anche chiamare array associativo\nSi nota che √® una struttura di dati dinamica, riguardo invece linearit√† e non linearit√† dipende dall\u0026rsquo;implementazione.\n3.2.2 Operazioni primitive Ricerca(Chiave) restituisce il valore della chiave Inserimento(Chiave, Valore) crea una chiave con quel valore Elimina(Chiave) elimina l\u0026rsquo;elemento con una determinata chiave 3.2.3 Esempio di implementazione su array ordinato Slide\nLe seguenti sono tutte implementazione ad alto livello senza codice\nImplementazione di Search\nImplementazione di Insert\nImplementazione di Delete\nLa cosa importante da osservare √® la costo asintotico di questa implementazione, ossia l\u0026rsquo;aspetto che varia a seconda dell\u0026rsquo;implementazione.\nRiassunto del costo computazionale di questa implementazione\n3.2.4 Esempio di implementazione su lista concatenata Qui si utilizza una lista concatenata *circolare ** ovvero l\u0026rsquo;ultimo elemento della lista punta al primo, e il precedente del primo punta all\u0026rsquo;ultimo elemento, solo per non avere un null.\nSlide\nImplementazione di insert/delete\nImplementazione di Search\nScorri la lista ordinata, lo hai gi√† visto molto spesso üôÇ\nRiassunto costo computazionale lista concatenata\nConfronto fra le due implementazioni\nSlide\nIn conclusione abbiamo delle velocit√† diverse, per le operazioni che definiscono il dizionario. La scelta dell\u0026rsquo;implementazione migliore dipende dalle necessit√† dell\u0026rsquo;algoritmo, cosa che si decide caso per caso.\nUna osservazione √® che lista √® dinamica, mentre array ordinato √® statico.\n3.3 Liste concatenate 3.3.1 Prototipo semplice Una lista concatenata bidirezionale semplice √® simile a quanto studiato in programmazione, gli estremi sono terminati da dei null.\nEsempio di lista concatenata unidirezionale semplice\nEsempio di lista concatenata bidirezionale semplice\nCircolare\n3.3.2 Prototipo circolare In particolare qui utilizziamo una lista concatenata bidirezionale circolare.\nOgni nodo contiene il valore, una chiave, e due puntatori al precedente e successivo.\nEsempio di lista concatenata circolare\n3.3.3 Operazioni elementari Sono tre le operazioni principali per una lista concatenata\nSearch\nInsert\nDelete\n3.4 Pile 3.4.1 Prototipo Vogliamo avere qualcosa che stori le cose come se fossero una pila di elementi. Quindi vogliamo solamente delle operazioni molto semplici. diciamo che √® una struttura di dati di tipo LIFO.\nQuesta semplice struttura di stack √® molto comoda: ha delle applicazioni non da poco:\nrecord delle chiamate operazioni per un editor di testo per scrivere e no. Parentesi per sintax-parsing Operazioni elementari\nVogliamo queste cose che siano entrambe molto veloci (costante\nPUSH(element)\nPOP()\n3.4.2 Confronto due implementazioni Possiamo utilizzare una lista o array (senza considerare l\u0026rsquo;array doubling)\nSlide\nRisposta domanda: perch√© l‚Äôunica cosa che serve √® push e pop, non servono altre operazioni da necessitare della doppia concatenazione\nImplementazione statica Slide\nQuesta √® la classica implementazione. utilizzando l\u0026rsquo;array statico. ma ha il problema che devo allocare uno spazio in memoria che sia sempre quello. Utilizziamo ora una tecnica che utilizza doubling e halving, per avere un array dinamico\nImplementazione dinamica La cosa buona di questo elemento √® che il costo ammortizzato √® costante.\nSlide\nAnalisi del costo ammortizzato\nAnalisi del push ammortizzato\nNel libro √® anche presente una tecnica utilizzando doubling-halving che utilizza l\u0026rsquo;accantonamento, che si potrebbe dire essere pi√π intuitivo.\nAnalisi del pop ammortizzato (accantonamenti)\nNon viene fatto nelle slide, ma √® presente sul libro, che incollo qui\n3.5 Code 3.5.1 Prototipo La struttura √® molto simile a quella della stack, ma qui l\u0026rsquo;unica differenza √® che invece di togliere il primo che ho messo, tolgo l\u0026rsquo;ultimo. Come se fosse una coda ad un bar.First in first out\nScheduling operazioni BFS Operazioni elementari\nEnqueue(element)\nDequeue()\n3.5.2 Confronto implementazioni (array circolari o liste semplici) Slide di confronto ad alto livello\nImplementazione con la array circolare Questa implementazione non √® presente nel codice java sorgente.\nSlide\n3.6 Alberi Di pi√π inAlberi BST e AVL\nCose importanti per l\u0026rsquo;albero sono:\nNodi Archi (singolo percorso fra un nodo e un altro, questa √® la differenza principale con i grafi) Poi possiamo identificare anche un ordine sui figli, radicato. **se ho unnodo come radice.\n3.6.1 Prototipo Come un albero binario di ricerca\u0026hellip;\n3.6.2 Operazioni elementari Lo scorrimento di un albero nei 3 modi: pre-ordine, in-ordine, post-ordine utilizzando gli algoritmi come DFS e BFS\n","permalink":"https://flecart.github.io/notes/strutture-di-dati-elementari/","summary":"\u003ch2 id=\"31-introduzione\"\u003e3.1 Introduzione\u003c/h2\u003e\n\u003ch3 id=\"311-cosa-sono\"\u003e3.1.1 Cosa sono\u003c/h3\u003e\n\u003cp\u003eLe strutture di dati si interessano solamente di \u003cstrong\u003ecome memorizzare i dati\u003c/strong\u003e, non necessariamente va a memorizzare un tipo di dato concreto.\u003c/p\u003e\n\u003cp\u003eQuindi + sul come - sul cosa.\u003c/p\u003e\n\u003ch3 id=\"312-prototipo-e-implementazione\"\u003e3.1.2 Prototipo e implementazione\u003c/h3\u003e\n\u003cp\u003eAvevamo introdotto la differenza fra algoritmo e programma all\u0026rsquo;inizio del corso, andiamo ora a definire la differenza fra prototipo e implementazione:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePrototipo:\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eva a fare una descrizione dei metodi che deve avere una determinata struttura di dati. Lo puoi intendere come una specie di \u003cem\u003einterfaccia\u003c/em\u003e.\u003c/p\u003e","title":"Strutture di dati elementari"},{"content":"3.1 Successioni $$ \\begin{cases} f: \\mathbb{N} \\to \\mathbb{R} \\\\ n \\to f(n) \\\\ \\{a\\}_{n \\in \\mathbb{N}} \\vee a_n \\end{cases} $$$$ \\left\\{ a \\right\\} _{n \\in \\mathbb{N}} $$3.1.1 Immagine e successione L\u0026rsquo;immagine di una successione (l\u0026rsquo;insieme dei suoi elementi) non √® una successione! la successione √® anche ordinata.\n3.1.2 Limitazioni della successione Come per gli insiemi si pu√≤ definire se l\u0026rsquo;insieme √® limitato superiormente, inferiormente o entrambi, a seconda di come lo definiamo in questo modo possiamo poi farci altri ragionamenti\nPer decidere se esiste questo limite, continui a fare gli stessi ragionamento sul maggiorante e minorante come per gli insiemi.\nSe uniamo l\u0026rsquo;essere superiormente o inferiormente limitato con la monotonia allora possiamo unire questa con il concetto di convergenza a un limite finito.\n3.1.3 Monotonia delle successioni Le successioni possono essere crescenti, descrescenti.\nLa definizione di queste successioni √® lasciata al lettore.\n3.2 Limiti di successioni 3.2.1 Intuizione Mi posso arrivare a un certo valore di quanto mi pare, del singolo valore che mi pare so che esiste sempre un valore che mi posso avvicinare.\n3.2.2 Limite Convergente Si definisce un limite per x che tende all\u0026rsquo;infinito di una successione $a_ n$ in questo modo:\n$$ L=\\lim_{x\\to\\infty} a_{n}:=\\forall \\epsilon\\in \\R^+, \\exists n_0\\in \\N^*,\\forall n \\in \\N:n \\geq n_0 \\implies |a_n - L| \u003c \\epsilon $$3.2.3 Limiti divergenti Ossia per qualunque k, posso andare a cercare un $n_0$ da qui in poi la successione √® sempre maggiore, posso scegliere come mi pare\n$$ \\infty = \\lim_{ x\\to +\\infty} a_ n:= \\forall k\\in \\R^+, \\exists n_0\\in \\N^*,\\forall n \\in \\N:n \\geq n_0 \\implies a_n \\geq k $$$$ -\\infty = \\lim_{ x\\to +\\infty} a_ n:= \\forall k\\in \\R^+, \\exists n_0\\in \\N^*,\\forall n \\in \\N:n \\geq n_0 \\implies a_n \\leq k $$ Nota di italiano\nSI pu√≤ dire solamente se una successione tende ma non puoi mai dire che il limite tende a qualcosa, perch√© il limite √® definito come un certo valore.\n3.2.4 Limiti finiti Questa definizione di limite di rif√† al concetto di intorno, ed √® un limite valutato su un unico punto 3.2.5 Limiti su successioni monotone !!! Sia data una successione crescente $a_n$, allora $\\lim_{x \\to \\infty} = \\sup \\{a_n | n \\in \\N\\}$\nSimile per successioni decrescenti\nDimostrazione\nDimostriamo ora per il caso decrescente.\nAllora il limite $L$ √® o finito, o √® $-\\infty$.\nCaso 1 $L = -\\infty$:\nLa successione non ha un limite inferiore, quindi non esistono dei minoranti per questo insieme, allora $\\forall k \u003e0 \\implies \\exists n_0 : a_{n_0} \u003c k$ allora essendo la successione decrescente abbiamo che $\\forall n : n\\in\\N, n \u003c n_o \\implies a_n \u003c a_{n_0}$ quindi $a_n \u003c k$ per ogni n minore di $n_0$ ci√≤ √® sufficiente per dimostrare la tesi dell\u0026rsquo;esistenza del limite divergente\nCaso 2 $L$ finito:\ndobbiamo dimostrare che $-\\epsilon \\leq |a_n - L| \\leq \\epsilon \\iff L - \\epsilon \\leq a_n \\leq L + \\epsilon$ ma sappiamo in quanto $L$ √® un minorante che vale $L - \\epsilon \\leq a_n$, consideriamo ora, $L + \\epsilon$, non essendo un minorante, deve esistere un $a_{n_0} \u003c L + \\epsilon$ allora essendo la successione decrescente abbiamo che $\\forall n : n\\in\\N, n \u003c n_o \\implies a_n \u003c a_{n_0}$ , quindi esiste un $n_0$ tale per per ogni $n$ minore di quello vale la sufficienza per il limite.\n3.3 Algebra dei limiti Ipotesi e tesi di ci√≤\n3.3.1 Somma limiti finiti Siano $a_n , b_n$ successioni con limite finito $l_1,l_2$, allora il limite di $a_n + b_n$ √® $l _1 + l_2$.\n$-\\epsilon_a \\leq a_n - l_1 \\leq \\epsilon_a$\nallora $-\\epsilon_b \\leq b_n - l_1 \\leq \\epsilon_b$\nallora $-\\epsilon_a -\\epsilon_b \\leq a_n - l_1 + b_n - l_1\\leq \\epsilon_a +\\epsilon_b$ e ci√≤ finisce la dimostrazione.\n3.3.2 Somma limiti Se usiamo un limite tale che una dei due √® infinito e hanno lo stesso segno allora abbiamo quello che abbiamo\u0026hellip;. Guarda le slides!\n3.3.3 Prodotto dei limiti finiti 3.3.4 Prodotto di limiti infiniti 3.3.5 Forme indeterminate somma e prodotto e divisione Somma di $+\\infty-\\infty$ oppure il contrario.\n$0 \\cdot \\pm\\infty$\nQualunque divisione fra infiniti .\n3.4 Numero di Nepero 3.4.1 Necessit√† per dimostrazioni Per dimostrare l\u0026rsquo;esistenza del numero di Nepero come\n$$ \\lim_{n \\to \\infty} (1 + \\dfrac{1}{n})^n = e $$Devo dimostrare in particolare due cose:\nCrescenza della funzione Limitatezza della funzione (ricorda che per questa propriet√† ho che una successione crescente o √® limitata e ha limite finito o √® divergente) 3.4.2 La disuguaglianza di Bernoulli La tesi e ipotesi della disuguaglianza di Bernoulli\nDimostrazione:\nSi ha una dimostrazione per induzione\nPB:\n$n = 0 \\implies 1 \\geq 1$ Verificato\nSupponiamo che valga per n, dobbiamo dimostrare che\n$(1 + x) ^{n + 1} \\geq 1 + x + nx$\n$(1 + x) ^{n + 1} \\geq (1 + x)(1 + nx) = 1 + nx + x + nx^2$ ovvio che sia maggiore della parte di destra, per cui √® dimostrato.\n3.4.3 Crescenza della successione La successione √® strettamente crescente, con 2 pagine e mezzo di calcoli.\nPrima dimostri che la divisione fra due numeri successivi della sequenza sia $\u003e 1$, poi fai i calcoli, in modo strano, facendo delle mosse anche intelligenti per quanto riguarda togliere e aggiungere degli uno e finisci a dire che vale.\n3.4.4 Limitatezza della successione Questa dimostrazione si dimostra espandendo la definizione con il binomio di Newton, in seguito si devono avere queste seguenti osservazioni interessanti:\nSemplificare $\\dfrac{n(n-1)...(n-k+1)}{n^k}$ dicendo che √® minore di 1, in quanto tutti i $k$ fattori al numeratore sono minori del denominatore. Semplificare il restante $\\dfrac{1}{k!}$ con le somme telescopiche (usando la disuguaglianza 1/k! ‚â§ della somma telescopica) e dimostrare che √® finito. Si dimostra quindi che l\u0026rsquo;upper bound √® 3.\n","permalink":"https://flecart.github.io/notes/successioni/","summary":"\u003ch2 id=\"31-successioni\"\u003e3.1 Successioni\u003c/h2\u003e\n$$\n\\begin{cases}\nf: \\mathbb{N} \\to \\mathbb{R} \\\\\nn \\to f(n) \\\\\n\\{a\\}_{n \\in \\mathbb{N}} \\vee a_n\n\\end{cases}\n$$$$\n\\left\\{ a \\right\\} _{n \\in \\mathbb{N}}\n$$\u003ch3 id=\"311-immagine-e-successione\"\u003e3.1.1 Immagine e successione\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eL\u0026rsquo;immagine di una successione (l\u0026rsquo;insieme dei suoi elementi) \u003cstrong\u003enon √® una successione!\u003c/strong\u003e la successione √® anche ordinata.\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch3 id=\"312-limitazioni-della-successione\"\u003e3.1.2 Limitazioni della successione\u003c/h3\u003e\n\u003cp\u003eCome per gli insiemi si pu√≤ definire se \u003cstrong\u003el\u0026rsquo;insieme √® limitato superiormente, inferiormente o entrambi\u003c/strong\u003e, a seconda di come lo definiamo in questo modo possiamo poi farci altri ragionamenti\u003c/p\u003e","title":"Successioni"},{"content":"This is a quite good resource about this part of Support Vector Machines (step by step derivation). (Bishop 2006) chapter 7 is a good resource. The main idea about this supervised method is separating with a large gap. The thing is that we have a hyperplane, when this plane is projected to lower dimensional data, it can look like a non-linear separator. After we have found this separator, we can intuitively have an idea of confidence based on the distance of the separator.\nMid 90\u0026rsquo; and early 2000 these models were very popular. With support vector machines, we generalize the idea of a linear separator.\nDefinitions We consider a dataset $S = \\left\\{ (x^{(1)}, y^{(1)}), \\dots, (x^{(n)}, y^{(n)}) \\right\\}$. This is a classical dataset with points, and dimensionality $d$, and labels $y^{(i)} \\in \\left\\{ -1, 1 \\right\\}$.\nFunctional Margin üü®++ Given a hyperplane $w^{T}x + b$ a margin for the $i$-th point is just $\\lambda^{(i)} = y^{(i)}(w^{T}x^{(i)} + b)$. Why is this a good definition? We discussed that the main idea is that we want a large gap between the hyperplane and the points. When a classification is correct we have that $\\lambda^{(i)} \u003e 0$. And the value of this margin can be interpreted as a sign of confidence. One observation is that $w$ are not scaled, so we should usually take the norm, or any other transformation that is useful for us. The important thing to notice is the sign.\n$$ \\lambda = \\min_{i} \\lambda^{(i)} $$Geometrical Margin üü®++ $$ w^{T}\\left( x^{(i)} - \\frac{w}{\\lVert w \\rVert }\\lambda^{(i)} \\right) + b = 0 \\implies \\lambda^{(i)} = \\frac{w^{T}x^{(i) }+ b}{\\lVert w \\rVert } $$$$ \\lambda = \\min_{i}\\lambda^{(i)} $$We note that if $\\lVert w \\rVert = 1$ we have that geometrical margin = functional margin, so we have the properties of correct classification that the functional margin gives, and we also have the easy geometrical interpretation of the geometrical margin.\nThe technique The primal problem üü®\u0026ndash; $$ \\begin{array} \\\\ \\max \\lambda \\\\ \\lVert w \\rVert = 1 \\\\ y^{(i)}(w^{T}x^{(i)} + b) \\geq \\lambda \\\\ \\end{array} $$ Which means we want to find the best geometrical margin. But some conditions are not so nice to handle (the norm constraint is not so easy, because it is not convex), this allows us to try to re-scale the $w$ and the $b$ such that the third condition is $1$, and the second is implicit. This is possible because scaling $w$ and $b$ does not change the final solution of the margin. Let\u0026rsquo;s see this. Given the support points $x^{+}$ and $x^{-}$ we want to find the best $w$ and $b$ such that the margin is maximized. We can write the optimization problem in this way:\n$$ \\begin{align} \\max \\lVert proj_{+} - proj_{-} \\rVert = \\max \\frac{\\lVert w^{T}x^{+} - w^{T}x^{-} \\rVert}{\\lVert w \\rVert } \\implies \\max \\frac{1}{\\lVert w \\rVert} \\\\ y^{(i)}(w^{T}x^{(i)} + b) \\geq 1 \\end{align} $$ Where we have used the definition of vector projection, and the scaling property, which allowed us to build that constraint. We need to note that in this case we are still assuming linear separability of the data.\nIn this way we reduce this problem to be $$ \\begin{array} \\ \\min \\frac{1}{2} \\lVert w \\rVert ^{2} \\ y^{(i)}(w^{T}x^{(i)} + b) \\geq 1\\\n\\end{array} $$ Which could be solved by Quadratic Programming and the use of Lagrange Multiplies. We see now how is this possible.\nFunctional and Geometrical Margin The original problem\u0026rsquo;s margin is called geometrical margin (because the distance actually corresponds to a real geometrical distance) while, if we set the constraint $\\lVert w \\rVert = 1$, it is called the functional margin, as the optimization objective is the same, which makes it scalable.\nThe dual üü© $$ \\mathcal{L}(w, b, \\alpha) = \\frac{1}{2}\\lVert w \\rVert ^{2} - \\sum_{i} \\alpha_{i}(y^{(i)}(w^{T}x^{(i)} + b) - 1) $$ Where $\\alpha_{i} \\geq 0 \\forall i$. We check Slater\u0026rsquo;s condition hold, which imply strong duality on this optimization problem. In order for this to hold we need to find $w$ and $b$ such that strict inequality hold. This is simple, as it is scaling invariant, given some $w$ and $b$ such that the equality holds (this is true by construction, because we have set the support vectors to be 1), then just re-scale them by a strictly positive value $\\lambda \u003e 0$ and you have your new $w$ and $b$.\nNow we find the gradient and substitute in the Lagrange Multiplier equation, and we obtain the dual problem: $$\n\\begin{align} \\min_{\\alpha} \\frac{1}{2} \\sum_{i, j} \\alpha_{i}\\alpha_{j}y^{(i)}y^{(j)}x^{(i)T}x^{(j)} - \\sum_{i} \\alpha_{i} \\ \\text{subject to} \\sum_{i} \\alpha_{i}y^{(i)} = 0 \\ \\alpha_{i} \\geq 0 \\end{align} $$\nFinding support vectors üü®+ $$ w^{*} = \\sum_{i} \\alpha_{i}y^{(i)}x^{(i)} $$$$ w^{*T}x^{+} + b = 1 \\implies b = 1 - w^{*T}x^{+} $$Extensions of SVM Soft SVM In this case we assume the data is not linearly separable so we add a relaxation on the optimization problem.\nNew setting of the problem üü© $$ \\begin{array} \\\\ \\min \\frac{1}{2} \\lVert w \\rVert ^{2} + C\\sum_{i} \\xi_{i} \\\\ y^{(i)}(w^{T}x^{(i)} + b) \\geq 1 - \\xi_{i} \\\\ \\xi_{i} \\geq 0 \\end{array} $$ Intuitively, we are now allowing for some points to be misclassified, but we are penalizing this misclassification. The parameter $C$ is a hyper-parameter that we can tune to adjust the tradeoff between the margin and the misclassification. Qualitatively, if $\\xi_{i} = 0$ then the point is correctly classified, if $\\xi_{i} = 1$ then the point is on the margin, and if $\\xi_{i} \u003e 1$ then the point is misclassified. We see that if we have higher value ok $\\xi$ this is penalized by the $C$ parameter. So, you see $C$ tells you how much you penalize misclassification.\nRelation with the Hinge Loss $$ \\mathcal{L}_{\\text{Hinge}}(y, x) = \\max(0, 1 - y^{(i)}(w^{T}x^{(i)} + b)) = \\max(0, 1 - y^{(i)}f(x^{(i)})) $$$$ \\frac{1}{2} \\lVert w \\rVert^{2} + C\\sum_{i = 1}^{N}\\mathcal{L}_{\\text{Hinge}}(y^{(i)}, x^{(i)}) $$ , which is the same as the Soft SVM loss function. This is because for correctly classified points the hinge loss is zero, and for misclassified points the hinge loss is $1 - y^{(i)}f(x^{(i)})$ which is the same as the slack variable $\\xi_{i}$.\nDeriving the optimization objective üü© $$ \\begin{align} \\mathcal{L}(w, b, \\xi,\\alpha, \\mu) = \\frac{1}{2}\\lVert w \\rVert ^{2} + C\\sum_{i} \\xi_{i} - \\sum_{i} \\alpha_{i}(y^{(i)}(w^{T}x^{(i)} + b) - 1 + \\xi_{i}) - \\sum_{i} \\mu_{i}\\xi_{i} \\end{align} $$$$ \\begin{cases} \\frac{\\partial \\mathcal{L}}{\\partial w} = 0 \\implies w = \\sum_{i} \\alpha_{i}y^{(i)}x^{(i)} \\\\ \\frac{\\partial \\mathcal{L}}{\\partial b} = 0 \\implies \\sum_{i} \\alpha_{i}y^{(i)} = 0 \\\\ \\frac{\\partial \\mathcal{L}}{\\partial \\xi_{i}} = 0 \\implies \\alpha_{i} = C - \\mu_{i} \\end{cases} $$$$ \\begin{align} \\min_{\\alpha} \\frac{1}{2} \\sum_{i, j} \\alpha_{i}\\alpha_{j}y^{(i)}y^{(j)}x^{(i)T}x^{(j)} - \\sum_{i} \\alpha_{i} \\\\ \\text{subject to} \\sum_{i} \\alpha_{i}y^{(i)} = 0 \\\\ 0 \\leq \\alpha_{i} \\leq C \\end{align} $$ Which is very similar to the original problem, but with the added constraint that $\\alpha_{i} \\leq C$.\n$$ \\forall i \\begin{cases} C = \\alpha_{i} + \\mu_{i} \\\\ \\mu_{i} \\geq 0 \\\\ \\alpha_{i} \\geq 0 \\end{cases} \\implies 0 \\leq \\alpha_{i} \\leq C $$Kernelized SVM $$ w^{*}\\varphi(x) = \\sum_{i} \\alpha_{i}y^{(i)}\\varphi(x^{(i)}) \\varphi(x) = \\sum_{i} \\alpha_{i}y^{(i)}K(x^{(i)}, x) $$ We see kernels again! Usually Kernelized SVM is justified by the observation that data might be separable in higher dimensional spaces, so we just lift the data on that space and compute everything there. Example, if the $1-D$ data is as follows: $[0, 1] \\to 1$ else where in the real line is $0$ this is clearly not linearly separable. But if we lift to $(x, x^{2})$ it is separable. This is the intuition behind how kernels work for SVMs too!\nKernelized SVM loss üü® $$ \\begin{align} \\min_{\\alpha} \\frac{1}{2} \\sum_{i, j} \\alpha_{i}\\alpha_{j}y^{(i)}y^{(j)}K(x^{(i)}, x^{(j)}) - \\sum_{i} \\alpha_{i} \\\\ \\text{subject to} \\sum_{i} \\alpha_{i}y^{(i)} = 0 \\\\ 0 \\leq \\alpha_{i} \\end{align} $$Inference with K-SVM üü©- $$ w^{*T}\\varphi(x) + b = \\sum_{i} \\alpha_{i}y^{(i)}K(x^{(i)}, x) + b $$ As in this case we have that $w^{*} = \\sum_{i} \\alpha_{i}y^{(i)}\\varphi(x^{(i)})$.\nStructured SVM Structured SVMs attempt to generalize the idea of SVMs into multi-class prediction, or prediction of structured objects (like parse threes covered in Probabilistic Parsing or tags in Part of Speech Tagging).\nThe generalized Margin üü© $$ (w_{i}^{T}x + w_{i,0}) - \\max_{j \\neq i} (w^{T}_{j}x + w_{j, 0}) \\geq m $$ where $m$ is our margin, and $i$ is the current considered class among the $k$ possible (note we have different weight vectors for each class). If we want to extend this to structured data, then instead of taking indexes, we should take the maximum margin different from the one we are considering inside the space of possible structures (which is often huge).\nThis generalization is not exactly the generalization we would expect for the binary classification case, but in any case it is useful to extend the technique to structured objects.\nThen after having made this consideration, we can still use the functional margin idea of re-normalizing, and using the soft-SVM idea of adding a slack variable accounting for possible errors.\nAnother way to generalize SVM to multiclass is training many models in a one versus rest manner, and then just take the model that has the highest margin among the present. But we will not discuss this case.\nProblems with SSVMs üü• From the slides:\nCompact representation of the output space If we allowed even just one parameter for each class, we would already have more parameters than we could ever hope to have enough training data for. Efficient prediction: Sequentially enumerating all possible classes may be infeasible, hence making a single prediction on a new example may be computationally challenging. Prediction error: The notion of a prediction error must be refined ‚Äì for example, predicting a parse tree that is almost correct should be treated differently from predicting a tree that is completely wrong. Furthermore, the training data may be inconsistent. Efficient training: Efficient training algorithms are needed that have a run-time complexity sub-linear in the number of classes. Scores and feature maps üü• To solve the first two problems, we usually define a feature map $\\psi(y, x)$ that tells us something about the input and possible relations with the structures. This is often considered the hard part that needs a lot of problem knowledge. In order to solve the prediction error problem, we define a notion of score, which often comes naturally with a given problem. This is often modeled as $f_{y, x} = w^{T}\\psi(y, x)$. Which allows us to compare even similar solutions. These ideas have been also developed in the NLP course. e.g. Log Linear Models clearly define the concept of scores, which are quite common in the other community. While the features are often derived from data, with some neural network models nowadays (e.g. Part of Speech Tagging they used Bert to have an estimate of the emission, which is the probability of a certain word to have a certain tagging).\nThen we just choose the class with the highest score as our prediction.\nReferences [1] Bishop ‚ÄúPattern Recognition and Machine Learning‚Äù Springer 2006\n","permalink":"https://flecart.github.io/notes/support-vector-machines/","summary":"\u003cp\u003e\u003ca href=\"https://cs229.stanford.edu/main_notes.pdf\"\u003eThis\u003c/a\u003e is a quite good resource about this part of Support Vector Machines (step by step derivation). (Bishop 2006) chapter 7 is a good resource. The main idea about this \u003cem\u003esupervised\u003c/em\u003e method is separating with a \u003cstrong\u003elarge gap\u003c/strong\u003e. The thing is that we have a hyperplane, when this plane is projected to lower dimensional data, it can look like a non-linear separator. After we have found this separator, we can intuitively have an idea of \u003cem\u003econfidence\u003c/em\u003e based on the distance of the separator.\u003c/p\u003e","title":"Support Vector Machines"},{"content":"Synapses They are the connections that exist between one neuron and another, so we can think of them as the communication channel between neurons.\nElectrical based üü© These are also called Gap Junctions These are more direct connections between neurons, allowing excitation ions to pass through quite directly (this is the difference compared to chemically based ones). It‚Äôs a circuit more similar to an electronic one because it‚Äôs faster. Another characteristic of these kinds of synapses is that they are two-way channels.\nThey are usually necessary for fast processes, such as when we want neurons to fire together, like in arc reflexes.\nElectronmyscroscopy has a definition of 10nm, so its quite a challenge to see these gap Junctions of about 3.5nm, between each other..\nWe have almost instantaneous spike transmission, between the neurons (almost synchronized activity).\nChemical-Based üü© These are slower gates, the classic ones, which we then call neurotransmitters. When there is an action potential, vesicles are released into the intracellular space. On the other neuron, there are receptors that pick up these neurotransmitters and activate accordingly.\nThey are also quite slow diffusion takes about a couple of ms to reach the other side.\nThe interesting thing about this method is that the receptor can change gates to determine how much it cares about this new information. (So, if it cares about that signal, it can increase the number of gates; otherwise, it can decrease them‚Äîat least, that‚Äôs the theory.)\nWhen the neurotrasmittor binds with the post-synaptic neuron, it triggers a release of ions in the other cell.\nThe cerebral cortex is one of the most important parts of the brain. It consists of 6 uniform layers of neurons that follow a similar pattern.\nLayers 1 and 4 receive input from higher cortical areas, layer 4 from subcortical areas, and layer 6 from internal structures like the thalamus.\nCorrelations with Action Potential Timing Between two communicating neurons, there is a fairly evident correlation that implies an increase in the strength of the connection (synaptic strength) with the timing of the spikes.\nThese are called Long-Term Depression and Long-Term Potentiation.\nEPSP stands for Excitatory Post-Synaptic Potentiation. In the image, we see that if the second neuron activates after the first neuron has activated, the signal tends to strengthen; otherwise, it weakens.\nThe weakening makes sense because it‚Äôs like I‚Äôm giving the signal back to you (even if not necessarily connected), or the other neuron is just tired, lol.\n","permalink":"https://flecart.github.io/notes/synapses/","summary":"\u003ch3 id=\"synapses\"\u003eSynapses\u003c/h3\u003e\n\u003cp\u003eThey are the connections that exist between one neuron and another, so we can think of them as the \u003cstrong\u003ecommunication channel\u003c/strong\u003e between neurons.\u003c/p\u003e\n\u003ch4 id=\"electrical-based-\"\u003eElectrical based üü©\u003c/h4\u003e\n\u003cp\u003eThese are also called \u003cstrong\u003eGap Junctions\u003c/strong\u003e\n\u003cimg src=\"/images/notes/The Neuron-1704441720132.jpeg\" alt=\"The Neuron-1704441720132\"\u003e\u003cbr\u003e\nThese are more direct connections between neurons, allowing excitation ions to pass through quite directly (this is the difference compared to chemically based ones). It‚Äôs a circuit more similar to an electronic one because it‚Äôs \u003cstrong\u003efaster\u003c/strong\u003e.\nAnother characteristic of these kinds of synapses is that they are \u003cstrong\u003etwo-way\u003c/strong\u003e channels.\u003c/p\u003e","title":"Synapses"},{"content":"Introduction Da ricordare il \u0026ldquo;The State Machine Replication (SMR) Problem\u0026rdquo; in Consensus protocols che √® importantissimo per comprendere questa parte.\nStoria locale Transazioni al singolo noto Problema del sync fra tutti questi nodi.\nGoal of SMR solution in blockchains Andiamo a considerare alcune propriet√† di safety e liveness Programmi Concorrenti\nConsistenza i nodi devono essere daccordo su quale transazione mettere prima e dopo ‚Üí stessa storia per tutte le transazioni. (con la possibilit√† di alcuni nodi che siano indietro, ma solo prefisso!). Liveness che vogliamo dire che tutte le transazioni valide devono essere aggiunte alla fine Assunzioni per sincrono (4) Permissioned, ossia i nodi del nostro modello sono fissi, non possiamo averne di pi√π, non possiamo averne di meno e sono conosciuti. Public key infrastructure, Ogni nodo ha una coppia pubblica e privata. Synchronous, esiste una sorta di stato globale, e tutti i nodi condividono questa informazione. 0, 1, ‚Ä¶ t. I messaggi sono tutti mandati bene, e arrivano esattamente uno step dopo. (mandato al tempo t, arriva a t + 1). Onest√† di tutti i nodi (sar√† lasciato subito questa assunzione). 4‚Äô. Una percentuale dei nodi √® bizantina.\nAltre di base trattate prima\nesistenza di internet Esistenza di crittografia Si pu√≤ notare che le ultime due assunzioni sono le stesse pi√π generali definite in Consensus protocols, andremo negli appunti in seguito solamente a rilassare alcune assunzioni di 1 e 2.\nLa 1 √® stata storicamente molto sensata, dato che era pensata per database che comunicassero fra di loro, e chiaramente quello era un settings pi√π controllato, per blockchain vorremmo anche provare rilassare questo.\nBizantine broadcast problem Questo √® un problema molto simile a SMR, tanto che si potr√† dimostra che che risolvere SMR si pu√≤ ridurre a dimostrare BB. Andremo quindi a descrivere questo problema\nFaulty/Bizantine Nodes Alcuni nodi falliscono, anche se non intenzionalmente, per esempio con errori di hardware.\nUn nodo che non √® onesto (comporta come si dovrebbe comportare) √® faulty.\nFault types Crash fault (errore del software oppure dell‚Äôhardware). Omission fault (in cui la trasmissione di informazione importante √® fallita, pu√≤ essere intenzionale o meno) Omissione di send-receive O altro genere di omissione simile. Bizantine fault (un certo insieme di nodi fa come gli pare) √à molto importante comprendere questo concetto, dato che sar√† di base nell\u0026rsquo;analisi della costruzione di protocolli che funzionino per BB.\nIn modo intuitivo possiamo intendere un nodo come bizantino sse non si comporta come dovrebbe. E l√¨ vengono descritte anche 3 cause per il suo non-comportamento corretto.\nDescrizione del problema Un nodo leader e n - 1 nodi non leader. Il leader ha una informazione privata $v ^*$ che deve mandare a tutti. Una soluzione del problema deve soddisfare queste tre caratteristiche\nValidit√† ossia se il nodo sender (leader) √® onesto, gli altri devono essere d\u0026rsquo;accordo che il messaggio √® $v^*$ Terminazione non di deve essere deadlock, i nodi devono terminare con qualche risultato. Agreement quando termina, tutti i nodi onesti devono essere d‚Äôaccordo sullo stesso risultato. SMR si riduce a BB Prenderemo in questa soluzione l‚Äôidea presente in #Round-Robin leaders, ad avere ad ogni momento un leader.\nAllora dato questo leader, utilizziamo BB con leader = sender, e gli altri nodi per mandare il messaggio privato.\nAllora questo algoritmo possiede sia liveness che consistency. Liveness per stesso motivo di prima, prima o poi un nodo diventa un leader, quindi riesce ad aggiungere la sua informazione privata.\nConsistency perch√© perla soluzione di BB, ogni nodo onesto alla fine sar√† d‚Äôaccordo su quanto deve aggiungere alla sua lista privata. In particolare se il leader √® onesto sar√† esattamente quanto mandato dal sender.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Syncronous model/Untitled.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Syncronous model/Untitled\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Syncronous model/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Syncronous model/Untitled 1\u0026quot;\u0026gt; Alcune soluzioni Lazy SMR Se ogni nodo non comunicasse, ma aggiungesse alla propria lista privata la transazione, questo non funziona. Non c‚Äô√® proprio la consistenza. Non ci si pu√≤ aspettare che il nodo esterno, la transazione riesca a richiedere allo stesso tempo a tutti i nodi.\nDa qui concludiamo che i nodi devono comunicare fra di loro (che √® una cosa molto banale).\nRound-Robin leaders Quest√† √® una idea che ogni nodo diventa leader e si mette a coordinare i nodi a turni, in un certo senso √® molto simile all‚Äôidea presente in Architettura e livelli 1, 2 riguardo le reti ad anello e il passaggio del testimone.\nFunzionamento I nodi diventano leader a seconda del tempo globale. Il nodo leader manda a tutti gli altri la sua lista, gli altri aggiungeranno al proprio alla fine, all‚Äôinizio metto le propria (quindi).\nCorrettezza Sia consistenza sia liveness vengono soddisfatti. La liveness √® soddisfatta perch√© prima o poi il nodo n sar√† il leader, allora avr√† l‚Äôoccasione di aggiungere alla catena i suoi dati privati.\nLa consistenza viene soddisfatta perch√© sotto le assunzioni che abbiamo i messaggi vengono mandati e ricevuti esattamente in uno step di tempo, quindi ogni nodo riesce ad aggiungere alla sua lista privata quello che gli √® di interesse.\nNecessit√† dell\u0026rsquo;onest√† Se un nodo non onesto diventa leader, potrebbe mandare un p√≤ della sua lista ad lacuni nodi e niente ad altro (omission fault) e quindi questo rompe tutta la consistenza! Quindi questo metodo funziona solamente nel caso in cui nessun nodo fallisca. Vorremmo per√≤ resiste anche al fallimento!\nDolev-Strong protocol L‚Äôidea generale di questo protocollo √® capire se il sender √® onesto o meno. Se si riesce a capire questa cosa, allora se √® onesto prendo il suo valore, altrimenti metto bottom sulla mia pila\nConvincing messages \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Syncronous model/Untitled 2.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Syncronous model/Untitled 2\u0026quot;\u0026gt; The protocol Quel mandare cose √® pi√π o meno cercare di capire se il nodo sender ha mandato messaggi contraddittori.\nProof of correctness PKI (Hexagon proof) https://groups.csail.mit.edu/tds/papers/Lynch/jacm88.pdf Pease, Shostak, and Lamport [PSL80], and later the proof was simplified by Fischer, Lynch, and Merritt [FLM85].\nQuesta √® una dimostrazione molto importante per quanto riguarda questo modello. Mostra che ci sono delle limitazioni pesanti riguardanti il modello. Come si vedr√† in seguito anche in Asynchronous model, ci saranno delle limitazioni in praticamente qualunque modello.\nEnunciato Siano n nodi all‚Äôinterno di un modello a comunicazione sincrona in cui non √® presente un setting PKI (chiave privata e pubblica), se i nodi bizantini sono $f \\geq n / 3$, allora non √® possibile avere contemporaneamente terminazione, safety e liveness.\nDimostrazione Dimostreremo solamente il caso in cui n = 3, poi si dovrebbe estendere senza molto sforzo al caso maggiore generico.\nQuesta dimostrazione va a contraddizione. Supponiamo di avere un setting a 6 nodi come in figura\nI nodi F sono i sender, mentre M e L sono le altre cose.\nOra da notare √® che il protocollo pu√≤ eseguire su questo sistema, cio√® anche se era inteso per essere eseguito nel caso $n = 3$, le uniche cose di cui ha bisogno il protocollo √®\nSapere se √® un sender o meno Il messaggio da inviare se √® il sender I suoi n - 2 vicini (quindi sapere a chi mandare). Quindi sotto queste assunzioni il protocollo pu√≤ eseguire\nAllora andiamo a considerare 3 scenari possibili:\nScenario 1 F bizantino\nSupponiamo di essere in un sistema a 3, con L, M, F, ma F √® il nodo bizantino. F dato che √® bizantino pu√≤ fare cose arbitrarie, in particolare facciamo finta che simuli i nodi F‚Äô, M‚Äô, L‚Äô, F collegati come di sopra.\nAllora dato che il nosto protocollo deve soddisfare consistenza, ossia tutti i nodi onesti devono finere per essere d‚Äôaccordo su qualcosa, deve essere che nel sistema l‚Äôoutput di L = M\nScenario 2 L bizantino\nSistema a 3 dato da L, M, e F‚Äô, ma in questo caso ora il nodo M simula i nodi M, L, F, M‚Äô. Per validit√† del protocollo deve essere che L √® d\u0026rsquo;accordo con l‚Äôoutput 1, del sender F‚Äô.\nScenario 3 M bizantino\nSimile al sistema tre nel primo caso, ora L simula L, F‚Äô, M‚Äô, L‚Äô. Quindi per validit√† M d√† in output F.\nma allora abbiamo un assurdo perch√© L dovrebbe essere uguale a M, invece l\u0026rsquo;output √® diverso. Quindi questo scenario non pu√≤ succedere.\n","permalink":"https://flecart.github.io/notes/syncronous-model/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eDa ricordare il \u0026ldquo;The State Machine Replication (SMR) Problem\u0026rdquo; in \u003ca href=\"/notes/consensus-protocols/\"\u003eConsensus protocols\u003c/a\u003e che √® importantissimo per comprendere questa parte.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eStoria locale\u003c/li\u003e\n\u003cli\u003eTransazioni al singolo noto\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eProblema del sync fra tutti questi nodi.\u003c/p\u003e\n\u003ch3 id=\"goal-of-smr-solution-in-blockchains\"\u003eGoal of SMR solution in blockchains\u003c/h3\u003e\n\u003cp\u003eAndiamo a considerare alcune propriet√† di safety e liveness \u003ca href=\"/notes/programmi-concorrenti/\"\u003eProgrammi Concorrenti\u003c/a\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eConsistenza\u003c/strong\u003e i nodi devono essere daccordo su quale transazione mettere prima e dopo ‚Üí stessa storia per tutte le transazioni. (con la possibilit√† di alcuni nodi che siano indietro, ma solo prefisso!).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLiveness\u003c/strong\u003e che vogliamo dire che tutte le transazioni valide devono essere aggiunte alla fine\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"assunzioni-per-sincrono-4\"\u003eAssunzioni per sincrono (4)\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003ePermissioned\u003c/strong\u003e, ossia i nodi del nostro modello sono fissi, non possiamo averne di pi√π, non possiamo averne di meno e sono conosciuti.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePublic key infrastructure\u003c/strong\u003e, Ogni nodo ha una coppia pubblica e privata.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSynchronous\u003c/strong\u003e,\n\u003col\u003e\n\u003cli\u003eesiste una sorta di stato globale, e tutti i nodi condividono questa informazione.\n0, 1, ‚Ä¶ t.\u003c/li\u003e\n\u003cli\u003eI messaggi sono tutti mandati bene, e arrivano esattamente uno step dopo. (mandato al tempo t, arriva a t + 1).\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOnest√†\u003c/strong\u003e di tutti i nodi (sar√† lasciato subito questa assunzione).\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e4‚Äô. Una percentuale dei nodi √® bizantina.\u003c/p\u003e","title":"Syncronous model"},{"content":"NOTA: tolgo dalle note perch√© non mi sembra importante.\nIntroduction to system design Packages vs diagrams üü©- Packages fisica implementazione, perch√© √® una cosa utile per lo sviluppo Diagrams logica visualizzazione perch√© aiuta solamente a comprendere meglio come funziona il sistema in toto. Components What is a component (3) üü® √à una entit√† totalmente indipendente che funziona a s√©, un esempio √® il dll, dynamically loaded libraries presente nei sistemi di windows. Una cosa √® che espongono interfacce per interagirci, e questi possono essere utilizzati per creare sistemi complessi.\nQuindi riassumendo:\nIndipendenza da altri software (almeno √® contenuto) Presenza di interfacce per interagirci Risolvono un certo problema specifico (appunto isolato) Se ho questo allora posso rappresentare la struttura in esecuzione con i diagrammi di sopra, a seconda di come li carico scarico e simili.\nDifference with collaboration diagrams üü•+ nel nostro caso √® una dipendenza esterna non √® una estensione ereditaria come potrebbe sembrare se lo analizziamo come class diagram.\nCi permette lo stesso di creare diagrammi che rappresentano in che modo i singoli oggetti comunicano con altri.\n#### Stereotypes üü• Capire un po' meglio questa parte. Node What is a node üü© Sono una risorsa computazionale, quindi con CPU e memoria per poter eseguire qualcosa. Un esempio sono micro-controllori per temperatura, smart-home e simili. Questo √® qualcosa di base se vogliamo andare ad analizzare cose come sistemi distribuiti e nodi di computazione in quel punto.\nDifference with components (1) üü© I componenti rappresentano il pacchetto logico per una esecuzione, quindi sono pi√π strutturali, astratti, rappresentano in che modo esegue un certo sistema. Mentre i nodi sono rappresentazione fisica esecuzione, in cui effettivamente eseguono qualcosa, prima solo per rappresentarlo, quindi deployment di ci√≤\nReal Time UML Una delle caratteristiche fondamentali dei real time √® che hanno garanzia di esecuzione entro tot tempo, questa √® una cosa anche indagata per gli schedulers, vedi Scheduler#SISTEMI A REALTIME (non fare)\nTime events (3) üü® Change event: rappresentano il momento in cui una azione √® avvenuta e quindi probabilmente deve essere gestito un cambio di stato in questo caso. Time Event: descrivono quanto deve essere fatto un evento, per esempio Fra 5 minuti alle 12 P.M. Timing costraints entro quanto tempo deve essere fatto (o ogni quanto). Solo che manca un linguaggio per esprimere questi constraints. Esempio: Object Contraint Language Introduzione a OCLüü• √® un linguaggio di modellazione utilizzato per modellare in modo non ambiguo tutte le pre e post condizioni per un linguaggio. √à un linguaggio puro. Secondo Succi √® utile quando facciamo i test durante il progetto.\n","permalink":"https://flecart.github.io/notes/system-design/","summary":"\u003cp\u003eNOTA: tolgo dalle note perch√© non mi sembra importante.\u003c/p\u003e\n\u003ch3 id=\"introduction-to-system-design\"\u003eIntroduction to system design\u003c/h3\u003e\n\u003ch4 id=\"packages-vs-diagrams--\"\u003ePackages vs diagrams üü©-\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003ePackages \u003cstrong\u003efisica implementazione\u003c/strong\u003e, perch√© √® una cosa utile per lo sviluppo\u003c/li\u003e\n\u003cli\u003eDiagrams \u003cstrong\u003elogica visualizzazione\u003c/strong\u003e perch√© aiuta solamente a comprendere meglio come funziona il sistema in toto.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"components\"\u003eComponents\u003c/h3\u003e\n\u003ch4 id=\"what-is-a-component-3-\"\u003eWhat is a component (3) üü®\u003c/h4\u003e\n\u003cp\u003e√à una \u003cstrong\u003eentit√† totalmente indipendente\u003c/strong\u003e che funziona a s√©, un esempio √® il \u003cem\u003edll, dynamically loaded libraries\u003c/em\u003e presente nei sistemi di windows.\nUna cosa √® che \u003cstrong\u003eespongono interfacce\u003c/strong\u003e per interagirci, e questi possono essere utilizzati per creare sistemi complessi.\u003c/p\u003e","title":"System Design"},{"content":"Introduzione alle Tabelle di Hash 5.1.1 Prototipo Vogliamo implementare le operazioni del prototipo dizionario presentato in Strutture di dati elementari, e vogliamo fare solo queste 3 ma molto bene.\nInsert O(1) Delete O(1) Search in O(1) La struttura dati di hash riesce a fare bene queste singole operazioni\nSi vedr√† che l\u0026rsquo;array modificato √® il modo migliore per avere questo hash, solo generalizzando un modo per indicizzarlo che non saranno numeri (indici).\nNoteremo che in media hanno operazioni costanti queste tabelle di hash (nel caso peggiore sempre lineare).\nEsempi di utilizzi soliti Nei compilatori di solito √® molto utilizzato per mantenere in memoria il mapping con le variabili e simili\nTabelle ad indirizzamento diretto Queste tabelle di hash sono altres√¨ chiamate array, in quanto il numero di chiavi utilizzate √® esattamente uguale al numero di chiavi presente nel nostro universo di chiavi.\nMa per uso pratico questo sarebbe improponibile, in quanto vorremmo avere come chiavi anche stringhe, ma il numero di chiavi esploderebbe in maniera esponenziale e un utilizzo di memoria esponenziale non √® buona\u0026hellip;\nTempo O(1)\nSpazio O(n) con n il numero di chiavi nell\u0026rsquo;universo.\nTabelle di hash (idea) Idea vorremmo in qualche modo trasformare un elemento nel nostro insieme di chiavi possibili in un elemento appartenente solamente al nostro spazio di chiavi utilizzate.\nCio√® ridurre senza collisione (ovvero per input diversi, ottengo uno stesso output) una chiave nell\u0026rsquo;universo pi√π esteso in un numero utilizzabile.\nSlide\nIn questo modo riduco lo spazio utilizzato solamente a O(K) dove K sono le chiavi effettivamente utilizzate, deciso da caso a caso.\nRiassunto della ricetta dell\u0026rsquo;hashing\nRiassunto:\nFunzione di hash che mi riduca le chiavi dell\u0026rsquo;universo totale all\u0026rsquo;insieme delle chiavi utilizzate Queste devono essere veloci nel calcolo Minimizzare le collisioni Implementazione concreta come pu√≤ essere un vettore di una certa dimensione, che contenga effettivamente il valore dell\u0026rsquo;hash in quella zona. (possibile anche ridimensionamento) 5.2 Le chiavi Le chiavi sono uno strumento principale per comprendere le tabelle di hash. Sono il modo con cui troviamo il nostro valore e sarebbe bene cercare di definirlo in un modo pi√π formale\n5.2.1 Universo delle chiavi e insieme chiavi effettive Definiamo un insieme astratto di tutte le chiavi possibili Definiamo le chiavi effettive il sottoinsieme dell\u0026rsquo;universo delle chiavi, che contiene le chiavi effettivamente utilizzate in un momento Esempio\nCaratteristiche delle chiavi per le funzioni di hashing Le chiavi devono essere distribuite in maniera uniforme (questo √® il caso migliore per evitare il pi√π possibile delle collisioni) Le chiavi devono essere sempre positive o nulle La prima assunzione √® necessaria per l\u0026rsquo;analisi della nostra funzione di hash. Semplifica abbastanza direi.\nLa funzione di hash Cerchiamo qui di definire alcune propriet√† di una buona funzione di hash.\nDistribuzione uniforme semplice Se soddisfa questa propriet√†, ho una buona probabilit√† che io stia distribuendo i valori presenti in modo uniforme nel nostro spazio delle chiavi utilizzate (questo per√≤ non implica l\u0026rsquo;assenza o minimizzazione di collisioni!)\n√à difficile dimostrare o calcolare la distribuzione di probabilit√† di una funzione di hash.\nPer√≤ dall\u0026rsquo;altra parte sono sicuro se prendessi una chiave a caso in un intervallo di mia scelta allora ho finito, ho dimostrato che sono distribuite in modo uniforme.\n5.3.2 Costo computazionale costante Deve essere abbastanza semplice da avere un costo costante nel suo calcolo, altrimenti l\u0026rsquo;intera tabella avrebbe il costo di questa funzione, rallentando l\u0026rsquo;intera tabella.\nEsempi di funzioni di hash (4)!!! Rappresentazione della stringa in intero:\nQuesto metodo cresce insieme alla lunghezza della stringa, quindi di solito non √® una buona cosa farla in questo modo.\nVantaggio: posso rappresentare qualunque cosa che si pu√≤ rappresentare sul calcolatore\nSvantaggio: lo spazio cresce in funzione alla grandezza dell\u0026rsquo;input.\nRiduzione in modulo Questa √® in pratica una divisione. Nella slide sono mostrati anche vantaggi e svantaggi di questo metodo. (principalmente perch√© se il modulo √® preso brutto, ignora gran parte delle informazioni, quindi ottengo un hash che non mi rappresenta totalmente questo numero)\nCostante m descrive la funzione di hash in modo molto importante! (anche l\u0026rsquo;uniformit√†)\nMetodo della moltiplicazione Vogliamo introdurre maggiore scombinamento dell\u0026rsquo;input, questo si pu√≤ fare moltiplicando il valore di hash per qualcosa.\nEsempio in slide\nCostante C descrive l\u0026rsquo;uniformit√† di distribuzione\nMetodo codifica algebrica Riguardo al calcolo di questa codifica esiste il metodo di horner che permette la computazione di questo hash in maniera lineare rispetto all\u0026rsquo;input.\nRegola di Horner Soluzione delle collisioni Slide\nVogliamo trovare un sistema per risolvere le collisioni, che sono molto pi√π frequenti del solito per\nConcatenazione Una volta presente una collisione lo si inserisce nella lista concatenata presente in quella locazione. Questa lista in posizione precisa la chiamo lista di trabocco.\nAnalisi del concatenamento (ottimo e pessimo)\nAnalisi nel caso medio\nUna volta definito questo fattore di carico riesco a dimostrare il costo per la ricerca con successo e senza successo, e si ha che entrambi hanno costo\n$\\Theta(1 + \\alpha)$\nIndirizzamento aperto L\u0026rsquo;inserimento viene messo nel prossimo slot aperto.\nSlide\nL\u0026rsquo;idea principale √® quella dell‚Äôispezione.\nLa funzione di hash √® estesa con un altra funzione di ispezione che visita gli indici di una tabella permutata in modo sempre che sia visitata ogni cella una singola volta.\nPseudocodice per insert, search e delete\nL\u0026rsquo;idea principale √® mettere nella cella in cui si elimina un valore deleted per marcare la cancellazione, cos√¨ search continua a cercare dopo invece di fermarsi, subito (come se avessi perso la testa in un linked list).\nAnalisi:\nPeggiore: devo percorre l\u0026rsquo;intero array per inserire, eliminare o cercare, quindi O(n)\nMedio: dipende dall\u0026rsquo;ispezione, quindi andiamo ora ad analizzare l\u0026rsquo;ispezione.\nAssunzioni\nTeoremi su ricerca ad indirizzamento aperto\nStrategie di ispezione per l‚Äôhashing aperto (3) Ispezione lineare\n√® in una forma\n$h(k,i) = (h'(k) + i) \\mod n$\nContinua a guardare la cella successiva se quella precedente √® occupata.\nProblema del clustering primario (vicino)\nPraticamente √® abbastanza probabile che ci siano un sacco di sequenze vicine essere occupate (mentre altre sono basse). √à un fenomeno che non si vuole avere!\nToglie l\u0026rsquo;uniformit√† di occupazione! cosa che non va bene.\nEsempio di clustering\nCome si vede, le celle di hash 3 sono inframezzate molto! creando quella lunghissima linea di cellette occupate.\nAnalisi del costo medio (differente negli altri due casi esposti qui)\nIspezione quadratica\n$h(k, i) = h'(k) + c_1i + c_2i^2 \\mod n$\nAnche questo metodo di ispezione crea un clustering, che per√≤ √® secondario, ossia creano collezioni di celle lontano rispetto alla cella trovata.\nClustering secondario\nComunque questo tipo di clustering √® migliore rispetto al clustering primario\nDoppio hashing\n$h(k, i) = h_1(k) + ih_2(k) \\mod n$\nSlide\nEsempio\n","permalink":"https://flecart.github.io/notes/tabelle-di-hash/","summary":"\u003ch2 id=\"introduzione-alle-tabelle-di-hash\"\u003eIntroduzione alle Tabelle di Hash\u003c/h2\u003e\n\u003ch3 id=\"511-prototipo\"\u003e5.1.1 Prototipo\u003c/h3\u003e\n\u003cp\u003eVogliamo implementare le operazioni del prototipo dizionario presentato in \u003ca href=\"/notes/strutture-di-dati-elementari/\"\u003eStrutture di dati elementari\u003c/a\u003e, e vogliamo fare solo queste 3 ma molto bene.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eInsert O(1)\u003c/li\u003e\n\u003cli\u003eDelete O(1)\u003c/li\u003e\n\u003cli\u003eSearch in O(1)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eLa struttura dati di hash riesce a fare bene queste singole operazioni\u003c/p\u003e\n\u003cp\u003eSi vedr√† che \u003cstrong\u003el\u0026rsquo;array\u003c/strong\u003e modificato √® il modo migliore per avere questo hash, solo generalizzando un modo per indicizzarlo che non saranno numeri (indici).\u003c/p\u003e","title":"Tabelle di hash"},{"content":"This note extends the content Markov Processes in this specific context.\nStandard notions Explore-exploit dilemma üü© We have seen something similar also in Active Learning when we tried to model if we wanted to look elsewhere or go for the maximum value we have found. The dilemma under analysis is the explore-exploit dilemma: whether if we should just go for the best solution we have found at the moment, or look for a better one. This also has implications in many other fields, also in normal human life there are a lot of balances in these terms.\nIn the context of RL, if we exploit too much, we would get a sub-optimal solution. Instead, if we explore too much, we would get a low reward.\nTrajectories üü© Trajectories can be considered our data in RL settings. Intuitively, trajectories are just sequences of states, action and rewards. So: $\\tau_{i} = \\left\\{ x_{i}, a_{i}, r_{i} , x_{i + 1}\\right\\}$ and a trajectory is $\\tau = \\left\\{ \\tau_{0}, \\dots, \\tau_{n} \\right\\}$ (the trajectory should be correctly linked, the end state of a single item $\\tau_{i}$ should be the start state of the other, but this is just a formalism).\nLearning the World Model üü© Given a trajectory, one simple way to estimate transitions and rewards is just the empirical mean:\n$$ P(x_{t + 1}\\mid x , a) = \\frac{\\text{Count}(x_{t + 1}, x_{t}, a)}{\\text{Count}(x_{t}, a)} $$ Which how often we see a sequence in the form $x_{t}, a, r, x_{t + 1}$ where $r$ is any reward, in the trajectories, and the$x, a$ are fixed values of interest. Also in this setting, we are using the Markovian assumption (See Markov Chains.\n$$ r(x, a) = \\frac{1}{N_{x, a}} \\sum_{t: x_{t} = x, a_{t}=a} r_{t} $$ Where $N_{x, a}$ are the total numbers of states in the trajectory where the start state is $x$ and the action is $a$. Simple as that.\nModel-based algorithms There is something more in the case of simple n-bandit, see N-Bandit Problem. Usually, these kinds of models are more sample efficient. (The model of the world acts acts as some sort of prior). Another positive thing is the online fashion: we can interact with the environment and learn. Model free methods are more suitable to cases where you just need to train and then deploy.\nGreedy Approaches üü© This is a very simple algorithm, it has something in common with the Metropolis Hasting things we have studied in Monte Carlo Methods. We just choose a new action with probability $\\varepsilon$, else, we go for the best solution we have.\nGreedy solution üü©\u0026ndash; $$ A_{t} = \\arg\\max_{a} Q_{t}(a) $$ Il problema √® che questo non esplora. Potrebbe trovare il minimo e restare in quello perch√© la sua stima √® quella.\nEpsilon greedy solution üü© $$ \\pi_{t}(a) = \\begin{cases} (1 - e) + \\frac{e}{|A|} \u0026 \\text{if } Q(a) = \\max_b Q(b) \\\\ \\\\ \\frac{\\varepsilon}{\\lvert \\mathcal{A} \\rvert } \u0026 \\text{otherwise} \\end{cases} $$ Questo dovrebbe essere l\u0026rsquo;algoritmo utilizzato per Atari. Problema √® che continua ad esplorare anche se ha raggiunto convergenza buona della stima\nThe key problem of œµ-greedy is that it explores the state space in an uninformed manner. In other words, it explores ignoring all past experience. It thus does not eliminate clearly sub-optimal actions. From the lecture notes.\nConvergence of Greedy üü©\u0026ndash; If instead of keeping the sequence of $\\varepsilon$ fixed, we make it dependent on the time-step, and assume it satisfies the Robbins-Moro conditions (e.g. with $\\varepsilon_{t} = \\frac{\\lambda}{t}$, then it converges to the best solution. This is also why it does very well in practice.\nWe call Greedy in the limit with infinite exploration, meaning we are assuming we visit a state infinitely often.\nFormally this condition is valid if:\nWe explore every action pair infinitely often: $\\lim_{ n \\to \\infty } N_{t}(x, a) = +\\infty$ The policy converges to the greedy policy: $\\lim_{ n \\to \\infty } \\pi_{t}(a \\mid x) = \\mathbb{1}(a = \\arg\\max_{b} Q_{t}(b \\mid x))$ Softmax exploration üü© $$ \\pi_{t}(a \\mid x) = \\frac{e^{Q_{t}(x, a) / \\tau}}{\\sum_{b} e^{Q_{t}(x, b) / \\tau}} $$$R_{\\max}$ Algorithm This is based on (Brafman \u0026amp; Tennenholz ‚Äò02).\nThis captures the gist of many techniques, but it is more of a theoretical algorithm. We are optimistic at the beginning, then we become more realistic (meaning our assumptions will coincide more with reality after some time).\nWe have these assumptions: if we don\u0026rsquo;t know $r(x, a)$ we set it to the upper bound $R_{\\max}$ set at the beginning. If we don\u0026rsquo;t know $P(x' \\mid x, a)$, we add another state that gets all the mass: $P(x^{*} \\mid x, a) = 1$. This is like a black hole state, you will stay there forever, and get a negative or null reward of $r(x^{*}, a) - R_{\\max}$.\nThe nice observation is that we don\u0026rsquo;t need to distinguish between exploration and exploitation\nThe algorithm üü© Initially we assume that every transition leads to the fairy-tale state, and every reward is the best possible. We just use this temporarily as we know that in the end reality will be different, meaning the actual rewards of the MDP will be lower than the fairy-tale ones.\nFrom the lecture notes: We estimate the reward and transition probabilities as before, using the empirical observations. We need to precisely define the enough, which we will do in the next section.\nBounds on $R_{\\max}$ üü©\u0026ndash; We use Hoeffding\u0026rsquo;s Inequality, presented in Central Limit Theorem and Law of Large Numbers. And we have: $$ \\begin{align} P(\\lvert R_{n} - \\mathbf{E}[R_{n}] \\rvert \\geq \\varepsilon) \u0026amp;\\leq 2e^{-2N(a \\mid x)\\varepsilon^{2}/R_{max}^{2} } \\ \u0026amp;\\implies \\delta \\leq 2e^{-2N(a \\mid x)\\varepsilon^{2}/R_{max}^{2} } \\ \u0026amp;\\implies N(a \\mid x) \\geq \\frac{R_{\\max}^{2}}{2\\varepsilon^{2}} \\log \\frac{2}{\\delta}\n\\end{align} $$\nSo we need that amount of actions per state $x$ in order to be PAC sure of the reward we have there.\nTo get an estimate of the value of each state with $1 - \\delta$ confidence within an error of $\\varepsilon$. We assume $r(x, a) \\in \\left[ 0, R_{\\max} \\right]$\nThen we have another result that tells you that with probability $1 - \\delta$ $R_{\\max}$ will reach an $\\varepsilon$-optimal policy in a number of steps polynomial to the number of actions, states, times, and then free variables of the above bound. This bounds has some similarities with Provably Approximately Correct Learning.\nIn the paper, the authors have proved that an $\\varepsilon$ optimal policy is reached in polynomial time dependent on the number of states $\\lvert X \\rvert$, actions $\\lvert A \\rvert$, time, $\\varepsilon$, $:\\delta$, and $R_{max}$, similar to optimistic Q-learning that we will explore in model-free settings.\nAnalysis of the Computational Requirements Memory üü© We need to keep each state and action in memory. For each state we need to store tuples $x_{t}, a, x_{t + 1}$ so the transition probabilities alone are in the order of $\\mathcal{O}(\\lvert S \\rvert^{2} \\lvert A \\rvert)$\nComputation Time üü©\u0026ndash; We need to apply policy iteration and value iteration each time we have found a new transition probability, which is often costly. The trade-off is the sample-efficiency: these model based models are more efficient on the number of data needed to achieve a good policy, but infer in high computation costs. Furthermore, the update on R max is done at least for each state action pair, so we have at least $\\mathcal{O}(\\lvert S \\rvert \\lvert A \\rvert)$ solutions of the value or policy iteration, which is often quite costly.\nModel-free Algorithms With model free algorithms we don\u0026rsquo;t have access to the underlying state-action-state distributions, thus we cannot do policy evaluation using the Bellman backup as in Markov Processes\nTemporal Difference Learning A Monte Carlo estimate üü©\u0026ndash; The idea is to run a trajectory starting from $x$ many times and obtaining a Monte Carlo estimate\n$$ \\begin{align} V^{\\pi}(x) \u0026amp;= r(x, \\pi(x)) + \\gamma \\mathop{\\mathbb{E}}{x\u0026rsquo; \\mid x, a} [V^{\\pi}(x\u0026rsquo;)] \\ \u0026amp;= \\mathop{\\mathbb{E}}{x\u0026rsquo; \\mid x, \\pi(x)} [r(x, \\pi(x)) + \\gamma V^{\\pi}(x\u0026rsquo;)] \\ \u0026amp;\\approx \\lim_{ N \\to \\infty } \\frac{1}{N} \\sum_{i = 1}^{N} [r^{(i)} + \\gamma V^{\\pi}_{\\text{old}}(x^{(i)})]\n\\end{align} $$ Where $(r^{(i)}, x^{(i)}) \\sim P(x', R \\mid x, \\pi(x))$. But the problem in reality is that after have sampled a $x'$ we cannot go back. So the crude approximation is using a single observation as our approximation, which is $r + \\gamma V^{\\pi}_{\\text{old}}(x^{(i)})$. But the variance of the single estimate would be probably quite big, we would like to tamper the problem of this. So we can be more conservative and keep part of the previous estimate. This yields the rule of Temporal Difference Learning for model free value estimation:\nIn theory we can use a full estimate to approximate the value, but in practice is not possible due to the length of simulation that you would need to do. The expected reward $G_{0}$ is not available.\nBootstrapping the Value üü© $$ V^{\\pi}(x) = (1 - \\alpha_{t}) V_{\\text{old}}^{\\pi}(x) + \\alpha_{t}(r + \\gamma V^{\\pi}_{\\text{old}}(x^{(i)}) $$ This is sort of a bootstrap estimate, the idea of using running averages for estimating the value of something. This probably introduces a bias, but I need to investigate this a little bit more. Note that the meaning of Bootstrapping here is different compared to bootstrapping for datasets Ensemble Methods or operative systems.\n$$ V^{\\pi}(x) = V_{\\text{old}}^{\\pi}(x) + \\alpha_{t}(r + \\gamma V^{\\pi}_{\\text{old}}(x^{(i)}) - V_{\\text{old}}^{\\pi}(x)) $$ Where now $\\alpha_{t}$ is now interpretable as a learning rate, and the inside can be seen as a TD error. We can also have here the same convergence bounds that we have used for the epsilon greedy case. This converges to the correct bounds.\nThis is called On-policy as it can continuously estimate the value function.\nBias Analysis of TD We have said that bootstrapped samples lead to biased estimates. See https://claude.ai/chat/512eec65-2c84-4871-a973-de90b5757fab.\nIf $G_{t}$ is the expected reward at time $t$, an unbiased montecarlo update would be:\n$$ V_{t + 1}(x) = (1 - \\alpha)(V_{t}(x)) + \\alpha G_{t} $$$$ \\mathop{\\mathbb{E}}[V_{t + 1}(x)] = (1 - \\alpha) \\mathop{\\mathbb{E}}[V_{t}(x)] + \\alpha \\mathop{\\mathbb{E}}[G_{t}] = (1 - \\alpha) \\mathop{\\mathbb{E}}[V_{t}(x)] + \\alpha V(x) $$$$ \\mathop{\\mathbb{E}}[V_{t + 1}(x)] - V(x) = (1 - \\alpha) (\\mathop{\\mathbb{E}}[V_{t}(x)] - V(x)) $$ Meaning if at step $t$ is unbiased, it will remain unbiased at step $t + 1$. This is not true when using bootstrapping as we are assuming the estimate of the next state is noisy.\nThe gist is: if you start with an unbiased estimate, the monte carlo update will keep it unbiased, bu the Bootstrapped value using TD will not.\nConvergence of TD üü© . The convergence theorem states that if we choose the $\\alpha$ such that they satisfy the Robbins Moro conditions explained in Active Learning, and we suppose all actions pairs are chosen infinitely often, then the value function converges to the optimal value function, with probability 1. A quite similar convergence argument could be put forward for SARSA.\nGradient Update Interpretation üü© See RL Function Approximation.\nSARSA On-policy version üü© We can use TD-learning to do policy evaluation under model-free setting, we now need a way to estimate the best policy without knowing the transitions. Now SARSA comes into play. (now we use $s$ instead of $x$ for the state because it is more intuitive with the name).\n$$ Q^{\\pi}(s, a) = (1 - \\alpha_{t})Q^{\\pi}(s, a) + \\alpha_{t}(r + \\gamma Q^{\\pi}(s', a') ) $$ We now have observed two consecutive couples of states in the trajectory: $(x, a, r, x') \\to (x', a', r', x'')$ We can use the same convergence guarantee that we used for TD.\nFinding the optimal Policy üü© $$ \\pi(x) = \\max_{a \\in \\mathcal{A}} Q^{\\pi_{\\text{old}}}(s, a) $$ But in practice this method does not explore enough and one needs to do some random exploration, as for the $\\varepsilon$ greedy method. In principle, on-policy is more general. This is exactly the bellman optimality condition presented in Markov Processes.\nDrawbacks of SARSA üü© On-policy nature prevents the reuse of the sampled trajectories. (So one could argue that is not data efficient). In practice, the policy does not explore enough. This is partially offset by using epsilon exploration. Off-policy version üü© If instead of picking the policy via $\\pi$, we can run exactly the same algorithm and get the off-policy version. But now we need to assess the probability having any action. This allows us to estimate it from just a single state, instead of relying on the observed $a$\n$$ Q^{\\pi}(s, a) = (1 - \\alpha_{t})Q^{\\pi}(s, a) + \\alpha_{t}(r + \\gamma \\mathbb{E}_{a' \\sim \\pi(\\cdot \\mid x)}[Q^{\\pi}(x', a')] ) $$But this is exactly the same, we are just reweighing the bootstrapped q values following our policy.\nQ Learning The Q-Learning Algorithm üü© We can interpret the Q-learning algorithm as the analogous of Value Iteration in the model-free case. The convergence proof is always the same, with Robbins-Moro. Convergence Bounds of Q-Learning üü® Compared to #$R_{ max}$ Algorithm, the bounds are tighter: It has been shown that Q-Learning converges to the $\\varepsilon$ optimal policy with time polynomial with respect to $\\log \\lvert X \\rvert, \\log \\lvert A \\rvert, \\varepsilon, \\delta$.\nOptimistic Q-Learning üü© We can use the same idea of $R_{\\max}$ in the model-free case. We are optimistic and then, with some time, find better estimates of the values.\nWhere $V_{\\max} = R_{\\max} / (1 - \\gamma)$ as we would like to get an upper bound on the best value, not just maximum Reward.\nFor large Action Spaces Q learning is quite expensive (difficult to find the maximum of all possible actions). This is a common drawback for every tabular-based reinforcement-learning method.\nChoosing the bounds üü• $$ V_{max} = R_{max} + \\gamma R_{max} + \\dots = R_{max} \\sum_{i = 0}^{\\infty}\\gamma^{i} = R_{max} / (1 - \\gamma) \\geq \\max_{x, a} q(x, a) $$This bound is already ok for the Optimistic algorithm, the main concept is that the initial value is very very high. In the proof given in the book, one assumes that there is a learning phase where the $Q$ learning is still showing the optimist behaviour, then it actually starts to learn. But these details are probably irrelevant. The important thing to remember is that we are using the same idea for the $R_{max}$ algorithm, but here we are model free.\nComplexity Analysis üü© If $n$ is the number of states $s$ and $m$ the number of actions\nSpace: We need to store states and actions so the space complexity is $\\mathcal{O}(n \\cdot m)$, Time: the computation time is just finding the maximum so the complexity is $\\mathcal{O}(m)$ for a single iteration. In the next section we will try to approximate the state value function, see RL Function Approximation.\n","permalink":"https://flecart.github.io/notes/tabular-reinforcement-learning/","summary":"\u003cp\u003eThis note extends the content \u003ca href=\"/notes/markov-processes/\"\u003eMarkov Processes\u003c/a\u003e in this specific context.\u003c/p\u003e\n\u003ch3 id=\"standard-notions\"\u003eStandard notions\u003c/h3\u003e\n\u003ch4 id=\"explore-exploit-dilemma-\"\u003eExplore-exploit dilemma üü©\u003c/h4\u003e\n\u003cp\u003eWe have seen something similar also in \u003ca href=\"/notes/active-learning/\"\u003eActive Learning\u003c/a\u003e when we tried to model if we wanted to look elsewhere or go for the maximum value we have found.\nThe dilemma under analysis is the \u003cstrong\u003eexplore-exploit\u003c/strong\u003e dilemma: whether if we should just go for the best solution we have found at the moment, or look for a better one.\nThis also has implications in many other fields, also in normal human life there are a lot of balances in these terms.\u003c/p\u003e","title":"Tabular Reinforcement Learning"},{"content":"Questa sezione la tengo separata rispetto agli altri per favorire lo studio, cos√¨ questa roba nuova la ripasso pi√π spesso, in seguito si pu√≤ accorpare.\nGoldberg Tarjan/Push-relabel Questo algoritmo √® importante perch√© introduce ragionamenti sul minimo locale che possa alla fine essere ricomposto come soluzione globale.\nQuesta lezione youtube lo spiega da Dio\nPreflusso üü© Slide\nLa parte nuova di questa cosa √® che i vincoli di bilanciamento possono diventare una disuguaglianza. (cio√® quello che arriva √® di pi√π rispetto quanto va fuori.\nAndiamo inoltre a definire un concetto di attivit√† del nodo, ossia il fatto o meno che abbia un eccesso di flusso in entrata (e che quindi io abbia cose da mandare fuori ancora).\nPush forward e backward üü© Slide\nVogliamo utilizzare un algoritmo locale che sposti il flusso in avanti oppure all‚Äôindietro, questi sono gli unici modi per spostare flussi in giro.\nPseudocodice üü®+ Slide\nSi noti che √® presente un sistema di etichettatura utilizzato per tenere sotto controllo il costo\nNOTA ERRORE: Devono tornare a 5 invece che a 6\nL‚Äôetichettatura üü©- L‚Äôetichettatura per questo algoritmo √® fondamentale. Lo utilizziamo principalmente per evitare che ci siano push che poi vadano a ciclo, cosa molto brutta dato che non finirebbe mai l‚Äôalgoritmo.\nSi fa una etichettatura iniziale in questo modo:\nSparo al massimo tutti gli archi che partono da S. Metto N l‚Äôaltezza di S, e 0 tutto il resto. In questo modo vengono soddisfatte queste INVARIANTI:\nil Label per S √® sempre N il label per L √® sempre 0 Esiste un arco nel grafo residuo fra v, w solo se $h(v) \\leq h(w) + 1$ Noi vorremmo pushare solamente se ho una relazione del tipo $h(v) = h(w) + 1$, ossia esattamente pi√π alto di 1.\nAnalisi del costo üü©+ Slide\nSul perch√© sia vero non lo presenta, bisogna fare un approfondimento a riguardo.\nSe si sceglie il nodo di altezza massima si avr√† alla fine un costo di $O(N^3)$.\nFlusso di costo minimo algoritmi simili a ford fulkelson non sono molto buoni per trovare la migliore soluzione per questo, vorremmo andare a cercare il pseudoflusso del costo minimo!\nPseudoflusso üü© Slide\nIntuitivamente sto prendendo qualunque flusso che soddisfi i vincoli di capacit√†, ma che non √® sufficiente per soddisfare i vincoli di bilanciamento sui nodi.\nNodi di eccesso e difetto e sbilanciamento compressivo üü© Slide\nCon la nozione di pseudoflusso √® utile fare questa differenza.\n$O_x$ i nodi con eccesso di flusso quindi $e$ positivo, ci√≤ che entra √® di pi√π\n$D_x$ il contrario. ci√≤ che esce √® di pi√π.\nQuesti sono molto importanti, perch√© vorremmo far partire ed arrivare flusso dai nodi O ai nodi D, in modo da renderli bilanciati. E poi vorremmo avere il percorso di costo minimo.\nCammini aumentanti üü©- In sta parte viene esteso il concetto di cammino aumentante introdotto in precedenza per introdurre il costo di un cammino aumentante.\nUna cosa in pi√π √® che si pu√≤ partizionare l‚Äôinsieme degli archi nel cammino. Questa cosa sar√† utile per calcolare il costo\nCosto dei cammini aumentanti üü© Slide calcolo costo cammino aumentante\nQuesto √® un concetto nuovo rispetto a quello passato perch√© prima non si faceva caso ai costi, invece ora s√¨.\nTh struttura equivalenza dei pseudoflussi (!!) üü© Enunciato\nNota, inizio e fine dei cammini\n√à un teorema molto forte, dati due pseudoflussi qualunque, possiamo legare questi due con un numero di cammini aumentanti!\nLa dimostrazione non si fa üòÄ.\nDimostrazione in dispensa\nTh struttura del pseudoflusso minimo (!) üü©- Enunciato e dimostrazione\nHint per ‚Üê\nConsideriamo il nostro pseudoflusso, per ipotesi non √® minimale, allora esiste un altro pseudoflusso di costo minore con gli stessi vettori di sbilanciamento, allora per il teorema precedente pu√≤ essere applicato, posso trasformare uno nell‚Äôaltro.\nLa parte difficile da qui √® trovare il ciclo con costo negativo. Per sapere questo bisogna fare un p√≤ meglio il teorema precedente, infatti si pu√≤ dire che tutti i percorsi sono dei cicli!\nQuindi il pseudoflusso di costo minimo √® strettamente legato all\u0026rsquo;esistenza di cicli aumentanti di costo negativo!. Quindi vogliamo andare a togliere questi cicli, se riesco a togliergli tutti allora possono trovare il pseudoflusso minimale.\nNOTA: si ricordi che gli pseudoflussi si possono confrontare fra di solo solo se hanno gli stessi sbilanciamenti!.\nTh pseudoflusso minimo con aggiornamenti (!!!) üü© Enunciato e dimo\nhint a dimostrazione\nDobbiamo prendere il cammino aumentante di costo minimo e poi anche il flusso di costo minimo! Questi due sono gli ingredienti fondamentali per questo teorema qui.\nE s√¨ tal cred, sta roba √® nell\u0026rsquo;enunciato\nDimostrazione\nCome mai quella relazione riguardo i theta? Perch√© altrimenti avrei che lo sbilanciamento fra start-finish sarebbe diverso.\nQuesto √® il teorema principale che ci garantisce l‚Äôinvariante! Riusciamo a mantenere lo pseudoflusso di costo minimo in seguito alle operazioni di update con i cammini aumentanti!\nQuindi si pu√≤ costruire un algoritmo che utilizza questa propriet√†\nTrova un pseudoflusso minimo fra tutti quelli con lo stesso vettore di sbilanciamento Aggirona finch√© c\u0026rsquo;√® cammino aumentante Quando non posso pi√π aggiornare ho finito, ho il pseudoflusso di costo minimo, e di flusso massimo. Algoritmo cammini minimi successivi Pseudocodice algo üü©‚Äî Per avere uno pseudo-flusso minimale basta non avere cicli di costo negativo, vedremo fra poco come far ci√≤.\nDa notare che ora l‚Äôaggiornamento tengo conto anche del minimo fra inizio e arrivo! Ricordo che il mio obiettivo √® risolvere gli sbilanciamenti\nCorrettezza e terminazione üü©‚Äî Slide\nQuindi se termina allora √® corretto per i teoremi precedenti. Riguardo la terminazione riesco a fare ragionamenti sulla capacit√† del flusso, che posso dire che √® sempre intero, e diminuisci almeno di uno, quindi se andiamo a fare un bound sullo sbilanciamento iniziale riusciamo a fare una stima sul numero di iterazioni necessarie per finire.\nComplessit√† üü© Slide\nQuesto dipende fortemente dipende dallo sbilanciamento iniziale e dal tempo per trovare il cammino minimo (eg. bellman ford).\nAlgoritmo eliminazione cicli negativi Questo √® un altro algoritmo utilizzato per trovare il flusso minore, l\u0026rsquo;obiettivo √® trovare un qualunque flusso ammissibile, e poi togliere tutti i cicli negativi che trovo, in questo modo so per teorema precedente che il flusso che ho trovato √® il minore possibile.\nSe non sbaglio questo algoritmo √® acnhe chiamato algoritmo del ciclo di klein e ha complessit√† pseudopolinomiale di $O(m^2nCU)$ dove C √® la capacit√† massima e U il costo massimo. Il ragionamento per questa complessit√† √® che mi costa mn per Bellman ford per trovare il ciclo, e lo faccio diminuendo al massimo mCU volte (che √® il lower bound per il costo minimo).\nCostruzione flusso ammissibile üü© Vogliamo costruire un qualunque flusso ammissibile, e vogliamo cambiarlo in modo che essa abbia anche il costo minimo.\nRisolvere il problema di maximum flux, in questo modo ho un flusso ammissibile di flusso massimo Poi vado a cercare i cicli negativi, questi non cambiano nessun bilanciamento, e abbassano solamente il costo. So che il minimo costo sar√† quello che non avr√† cicli di costo negativo. In questo modo Ho trovato la migliore soluzione.\nPseudocodice üü© Slide\nAnalisi del costo e correttezza üü© Slide\nil bound per il numero di iterazioni √® molto banale, in pratica vado a considerare il massimo costo possibile, so che almeno diminuisce di 1 ad ogni iterazione, pi√π un costo di bellman ford per trovare i cicli. costo:\n$$ O(NA) \\cdot O(Auc) = O(NA^2uc) $$","permalink":"https://flecart.github.io/notes/tarjan-e-mcmf/","summary":"\u003cp\u003eQuesta sezione la tengo separata rispetto agli altri per favorire lo studio, cos√¨ questa roba nuova la ripasso pi√π spesso, in seguito si pu√≤ accorpare.\u003c/p\u003e\n\u003ch2 id=\"goldberg-tarjanpush-relabel\"\u003eGoldberg Tarjan/Push-relabel\u003c/h2\u003e\n\u003cp\u003eQuesto algoritmo √® importante perch√© introduce ragionamenti sul \u003cstrong\u003eminimo locale\u003c/strong\u003e che possa alla fine essere ricomposto come soluzione globale.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.youtube.com/watch?v=0hI89H39USg\"\u003eQuesta lezione youtube\u003c/a\u003e lo spiega da Dio\u003c/p\u003e\n\u003ch3 id=\"preflusso-\"\u003ePreflusso üü©\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Tarjan e MCMF/Untitled.png\" alt=\"image/universita/ex-notion/Tarjan e MCMF/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLa parte nuova di questa cosa √® che i vincoli di bilanciamento possono diventare una disuguaglianza. (cio√® quello che arriva √® di pi√π rispetto quanto va fuori.\u003c/p\u003e","title":"Tarjan e MCMF"},{"content":"In questa nota andiamo a parlare in modo sommario (si impara probabilmente molto meglio con la pratica) di generali tipologie di approcci che esistono per affrontare problemi di tipo algoritmico.\nDivide et impera Introduzione Abbiamo gi√† visto L\u0026rsquo;utilizzo di questa tecnica per quick e merge sort in Algoritmi di ordinamento\nQuesta tecnica si focalizza in tre passi fondamentali:\nDividere il problema in sotto-problemi Risolvere il sotto-problema Mergiare le soluzioni di questi sotto-problemi. Questa √® pi√π una tecnica che si impara di pi√π con la pratica, andremo a fare un problema che utilizza questa tecnica\nLa torre di Hanoi Enunciato\nSoluzione con ricorsione\nMoltiplicazione fra interi Questo potrebbe sembrare semplice. In realt√† per numeri pi√π grandi del limite dei registri (le macchine moderne sono tutte a registri, secondo il modello di Estensioni di Turing e altre macchine#Macchine a registri). Quindi possiamo provare algoritmi che funzionano bene per lunghezza infinita.\nSi utilizza una tecnica divide ed impera per moltiplicare assieme i due numeri. Quindi divido il numero in parte superiore e parte inferiore\u0026hellip;\nPrima applicazione\nMa si potr√† notare che questo metodo non porta a migliroamenti\nMoltiplicazione pi√π efficiente\nSottovettore di valore massimo Questo √® un problema classico che ho gi√† riscontrato in maximum subarray sum.\nAlgoritmo banale Va a guardare tutte le sottosequenze possibili, che sono O(N2) perch√© √® uguale al numero di coppie di indici (ordinate) che si possono prendere.\nAlgoritmo Divide et Impera Si nota che la massima sottosequenza √® o nella parte destra o sinistra, oppure in mezzo, quindi si conside\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Tecniche algoritmiche/Untitled 5.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Tecniche algoritmiche/Untitled 5\u0026quot;\u0026gt; Greedy Greedy √® buono quando si pu√≤ Dimostrare (e se non lo dimostri perdi un sacco di tempo a implementare una soluzione che non √® nemmeno giusta) e si basa sui sotto-problemi ottimali.\nProblema del resto In cui basta scegliere la moneta migliore ogni volta (perch√© sicuramente(con piccolo ragionamento) ci vorranno meno monete rispetto a usare altre)\nUn osservazione √® che pu√≤ fallire in sistemi non CANONICI.\nJob scheduling Si avr√† che basta ordinare secondo la lunghezza minore (perch√© si guadagna sempre in questo caso)\nHuffman coding Questo problema √® stato trattato meglio in Kolmogorov complexity legati a cose come Entropy. Si crea un albero di codifica che sia il meno profondo possibile, in questo modo ho un modo pi√π formale per giustificare il fatto di avere la minima codifica.\nPseudocodice per l‚Äôalbero di huffman.\nHuffman(real f[1..n], char c[1..n]) ‚Üí Tree Q ‚Üê new MinPriorityQueue() integer i; for i ‚Üê 1 to n do z ‚Üê new TreeNode(f[i], c[i]); Q.insert(f[i], z); endfor for i ‚Üê 1 to n ‚Äì 1 do z1 ‚Üê Q.findMin(); Q.deleteMin(); z2 ‚Üê Q.findMin(); Q.deleteMin(); z ‚Üê new TreeNode(z1.f + z2.f, \u0026#39;\u0026#39;); z.left ‚Üê z1; z.right ‚Üê z2; Q.insert(z1.f + z2.f, z); endfor return Q.findMin(); Programmazione dinamica Abbiamo risolto fibonacci, Maximum subarray sum con la programmazione dinamica, entrambi in O(n). Ora andiamo a parlare del problema pi√π importante per la programmazione dinamica, il problema dello zaino\nKnapsack problem TODO\nDistanza di levenstein TODO\nSeam Carving TODO\n","permalink":"https://flecart.github.io/notes/tecniche-algoritmiche/","summary":"\u003cp\u003eIn questa nota andiamo a parlare in modo sommario (si impara probabilmente molto meglio con la pratica) di generali tipologie di approcci che esistono per affrontare problemi di tipo algoritmico.\u003c/p\u003e\n\u003ch2 id=\"divide-et-impera\"\u003eDivide et impera\u003c/h2\u003e\n\u003ch3 id=\"introduzione\"\u003eIntroduzione\u003c/h3\u003e\n\u003cp\u003eAbbiamo gi√† visto L\u0026rsquo;utilizzo di questa tecnica per quick e merge sort in \u003ca href=\"/notes/algoritmi-di-ordinamento/\"\u003eAlgoritmi di ordinamento\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eQuesta tecnica si focalizza in tre passi fondamentali:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDividere il problema in sotto-problemi\u003c/li\u003e\n\u003cli\u003eRisolvere il sotto-problema\u003c/li\u003e\n\u003cli\u003eMergiare le soluzioni di questi sotto-problemi.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eQuesta √® pi√π una tecnica che si impara di pi√π con la pratica, andremo a fare un problema che utilizza questa tecnica\u003c/p\u003e","title":"Tecniche algoritmiche"},{"content":"Introduzione Spettro del wireless networks (skip) Slide spettro Wirelesss networks\nQuesto solamente la classica differenziazione fra radio, visibile, raggi x raggi gamma etcetera.\nSe andiamo a guardare le onde radio, quelle che ci interessano, se ho frequenza alta ho densit√† di frequenza alta, se ho frequenza bassa ho alta capacit√† di suparamento di ostacoli.\nISM √® una banda da 2 a 5.0 GHz e c\u0026rsquo;√® tutto il WiFi, bluetooth. (anche wifi a 5 ghz.\nGSM prima rete cellulare a 900, poi 1800 nella seconda versione.\nDivisione statica delle frequenze\nAvre una frequenza comprata √® una miniera d\u0026rsquo;oro, attualmente il prof sta facendo della ricerca su come andare a\nTrasmissione via wireless : bandwidth (!) üü© Slide bandwidth\nSolitamente √® una ampiezza di frequenza ossia quando √® grande un insieme di frequenza (questa √® anche la definizione formale da utilizzare). Per√≤ √® erroneamente utilizzata anche per descrivere il numero di bits trasmessi (che √® il bitrate nominale), √® un errore voluto perch√© solitamente se hai una bandwidth maggiore riesci a trasmettere pi√π dati.\nNotare che la velocit√† del segnale √® sempre la stessa che √® quella della radiofrquenza (quella della luce), √® solamente l\u0026rsquo;alternarsi di quelle scatolette di colore diverso (codifica diversa).\nSe il segnale √® pi√π lungo allora √® pi√π facile andare ad interpretare se √® uno 0 oppure √® uno 1, diciamo che c\u0026rsquo;√® il tradeoff sulla reliability del segnale credo, anche se √® principalmente limitato dalla capacit√† del ricevente\ndef: connettivit√† di link üü© Slides connettivit√†\nIl primo √® una partizione, poi unidirezionali e bidirezionali.\nNota: solamente sui link direzionali possiamo andare a definire un link simmetrico o asimmetrico.\nLe parole principali sono:\nUnidirezionale Bidirezionale Partizione. Tipologie di wireless Slide introduzione alle tecnologie wireless\nNarrowband system √à un frequenza molto piccola in cui si pu√≤ comunicare (statica diciamo).\nProblemi di privacy perch√© mi posso connettere alla frequenza e ascoltare quanto viene mandato. Problemi di interferenza se voglio comunicare su questa frequenza con canali diversi Infatti per questa tipologia √® molto semplice fare un attacco di Jamming, ossia mando informazioni alla stessa frequenza, impedendo la comunicazione sul canale.\nFrequency Hopping Possiamo utilizzare pseudogeneratori per andare a saltare in modo pseudorandom in spettri di frequenza diversi.\nAbbiamo bisogno di una sincronizzazione di questi salti, quindi un clock comune sarebbe molto comodo. (per√≤ dell‚Äôhardware per filtri per quelle frequenze ci dovrebbe essere).\nQuesto era soprattuttto un modo per trasmettere nel tentativo di non essere ascoltati. In questo senso di hop, √® protetto by design.\nCuriosit√†: inventata da una attrice di hollywood, Hedy Lamarr (perch√© il suo canto andava fuori sinc lol) donato poi senza brevetto per salvare i soldati americani.\nDirect sequence spread spectrumüü® Ne parliamo un po\u0026rsquo; meglio in Modulazione wireless\nOssia mando il segnale encodato su tutto lo spettro con un chipping code. E qui si pu√≤ riutilizzare la metafora del vagone e del treno, nel senso che se √® lungo allora riconosco meglio il valore del bit encodato con quella forma.\nIn un certo senso √® anche sicura rispetto al narrowband, perch√© devi conoscere il pattern del chip code per poterlo decodificare correttamente. (vari interlocutori avrebbero un codice non correlata fra di loro, cio√® la comunciazione sovrapposta sembra una interferenza casuale) Questo ci permette di riestrarre da molte comunicazioni la nostra comunicazione iniziale.\nIn breve sembra che questa forma di trasmissione sia quella pi√π affidabile per errori (anche la natura in modo naturale pu√≤ dare interferenze)\nNote sulle generazioni (skip) 1G era solamente come codifica della voce, la differenza principale con la 2G √® con la digitalizzazione, con 2G possiamo trasmettere megabytes, per√≤ era pagato per la durata di trasmissione (era telefonare per trasmettere bits lol, per√≤ era lenta, quindi pagava tanto, questa parte l\u0026rsquo;abbiamo accennata in Introduzione a reti, dato che la banda era occupata per tempo).\nCon 2.5G andiamo a sfruttare il tempo libero delle altre comunicazioni, ecco la differenza fra commutazione a pacchetto rispetto a commutazione a circuito\n3G era bono 1Mbit si pensava risolveva tutto.\nInfrastruttura wifi Struttura WWAN WMAN üü®- C\u0026rsquo;√® il problema di scoprire access points, e connettersi ai access point e anche predire il movimento delle persone per prevenire il collegamento alla rete.\nUn altro problema √® tipo il cambio dell‚Äôindirizzo IP ad ogni cambio di rete connettendoci ad access point diverso, per questo motivo si utilizza una forma mobile di IPv4 per mantenere lo stesso IP (se cambiasse sempre allora non potrei sostenere video o simili quando mi sposto).\nGeostazionario: che gira insieme alla terra, quindi l‚Äôabbiamo costantemente sopra la nostra testa questo satellite.\nWLAN Queste sono delle reti ad hoc peer to peer, senza infrastruttura, sono solamente dei nodi che si trovano nella stessa stanza!\nNon abbiamo costi di gestione e manutenzione se siamo senza infrastruttura e possiamo comunicare localmente senza problemi\nBridges with wires Solitamente potremmo avere un access point che sia dual stack con due interfacci una che va in wireless, l‚Äôaltra in wire, a livello 3 posso fare delle bridging functions,\nSvantaggi wireless üü®‚Äî Location tracking √® la cosa di pi√π rilievo riguardo a questo, e anche la cosa pi√π figa perch√© l‚Äôinformazione per trackare le persone ci sarebbe üòÄ\nMultiplexing wireless Slide multiplexing\nDa cui vediamo che abbiamo 4 modi per fare multiplexing dello stesso segnale\nCodice Frequenza del sengale Tempo (non credo abbiamo molto controllo suq uesto lol) E spazio Vogliamo rendere non ambiguo la trasmissione, pi√π dispositivi che utilizzino la stessa risorsa (mezzo di trasmissione di RF diciamo).\nFrequency üü© Slide frequenza\nLe energie di canali diversi dovrebbero essere separate, se comunque si vada ad invadere, il filtro dovrebbe essere sufficiente per ignorare gli altri canali, oppure possiamo separare di pi√π le frequenze, questi spazi vuoti sono spazi di guardia\nUn altro lato negativo √® che il canale √® occupato, quindi quando c\u0026rsquo;√® una asimmetria rispetto al modo in cui √® occupato, allora c\u0026rsquo;√® uno spreco.\nTime multiplexing üü© Slide time multiplex\nSi va in round robin in pratica, c‚Äô√® uno spazio di guardia nel tempo. Che √® uno spreco.\ne c‚Äô√® bisongo di sincronizzazione tra i mezzi trasmissivi molto forte. Il vantaggio principale √® che posso fare una trasmissione molto densa. (va diciamo a burst, quindi anche questo √® uno svantaggio).\nTime and frequency multiplexing üü© Slide time and frequency\nViene utilizzato in GSM wifi. (√® il provider che fornisce per ogni collegamento il seme per la gene), anche per quesot motivo era una comunicazione per tempo. (pagare telefonate per comunicare 9600 bit al secondo avevano di bitrate, costava molto).\nServe coordinamento preciso:\nMappa dei salti deve essere conosciuto Doppio spazio di guardia, sia per tempo sia per frequenze. (quindi anche qui utilizziamo molto spreco! Code multiplexing üü© La magia del CDMA in Modulazione wireless\nSlide code multiplexing\nQuesto sembra molto antiintuitivo, come facciamo ad utilizzare lo stesso canale per comunicare informazioni differenti?\nUtilizzo un codice che mi permette di riestrarre! Che figa la cosa che si pu√≤ riestrarre dal caos.\nbandwidth efficient ossia maggior bitrate con la minore banda. dal punto di vista dell‚Äôuser √® pi√π lento (singolarmente pi√π lento, ma complessivamente di maggiore utilizzo). Un p√≤ di computazione in pi√π per ricevere e mandare. Space multiplexing üü©- Slide space multiplexing\nOssia posizioniamo le nostre antenne in zone differenti. (abbiamo tipo tiling problem) (5G prova a ridurre al minimo l‚Äôarea del segnale)\n","permalink":"https://flecart.github.io/notes/tecnologia-wireless/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"spettro-del-wireless-networks-skip\"\u003eSpettro del wireless networks (skip)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide spettro Wirelesss networks\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Tecnologia Wireless/Untitled.png\" alt=\"image/universita/ex-notion/Tecnologia Wireless/Untitled\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eQuesto solamente la classica differenziazione fra radio, visibile, raggi x raggi gamma etcetera.\u003c/p\u003e\n\u003cp\u003eSe andiamo a guardare le onde radio, quelle che ci interessano, se ho frequenza alta ho densit√† di frequenza alta, se ho frequenza bassa ho alta capacit√† di suparamento di ostacoli.\u003c/p\u003e\n\u003cp\u003eISM √® una banda da 2 a 5.0 GHz e c\u0026rsquo;√® tutto il WiFi, bluetooth. (anche wifi a 5 ghz.\u003c/p\u003e","title":"Tecnologia Wireless"},{"content":"Classi laterali Dimostrazione dei lemmi sopra. La cosa interessante di questa parte √® possiamo usare una classe laterale per partizionare il gruppo iniziale!\nIl teorema di Lagrange Dividere significa che **partiziona** l'insieme iniziale in alcuni insiemi distinti. L'insieme $G:H$ √® l'insieme che contiene tutti i cosets, credo. Dimostrazione\n|G:H| = |G|/|H| |a| divide |G| Ossia un corollario dopo il teorema di Lagrange. La cosa citata √® dimostrata in Gruppi ciclici e permutazioni#Criterio $a {i} = a {j}$.\nI gruppi di ordine primo sono ciclici Se ho un gruppo di ordine primo, per il teorema di Lagrange non posso avere sottogruppi propri, perch√© l‚Äôordine di questi dovrebbe dividere l‚Äôordine del gruppo di partenza. Per questo motivo ho un unico gruppo. Ossia ogni elemento genera l‚Äôintero gruppo\na elevato all‚Äôordine del gruppo √® uguale ad e Dimostrazione L‚Äôordine dell‚Äôelemento a deve dividere l‚Äôordine di |G| per Lagrange, quindi, in simboli $$ |a| =n, |G| = m, n \\mid m \\implies m = nj, a^{|G|} = a^{nj} = e ^j = e $$ Il piccolo teorema di fermat Dimostrazione\n$$ a^{p - 1} = 1 \\mod p $$ E la cosa comoda √® che $a^{p - 2}$ √® l\u0026rsquo;inversa di quello.\nTeorema di Eulero Proof. http://www.fen.bilkent.edu.tr/~franz/nt/ch7.pdf.\n$$ a^{\\varphi(n)} = 1 \\mod n $$Questo √® molto pi√π complesso da descrivere e dimostrare. Bisognerebbe per esempio anche definire propriet√† della funzione di Eulero.\nClassificazione dei gruppi di ordine 2p SCHIVA STO TEOREMA CHE NON MI SERVE A NUCAZZU\nIdee della dimostrazione\nDividere la discussione con la presenza o meno di elementi di ordine 2p Caso in cuinon ci sono elementi di ordine 2p Dimostrare che esiste almeno un elemento di ordine p, perch√© se fossero tutti di ordine 2, riesco a crearmi (in modo creativo) un sottogruppo di ordine 4 a piacere, molto simile al gruppo quaternione. Avendo un sottogruppo di ordine p, questo quozienta l‚Äôinsieme G per il teorema di lagrange, ho solamente un altro insieme che posso scrivere come elemento_fuori_a * gruppo_generato_da_a_di_ordine_p Dimostro che l‚Äôordine dell‚Äôelemento fuori da a deve essere necessariamente di ordine 2. (in qualche modo che non ho compreso) Dimostrazione\nStabilizzatore e orbita Stabilizzatore Orbita !\nTeorema orbita stabilizzatore !\n","permalink":"https://flecart.github.io/notes/teorema-di-lagrange/","summary":"\u003ch2 id=\"classi-laterali\"\u003eClassi laterali\u003c/h2\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Teorema di Lagrange/Untitled.png\" alt=\"image/universita/ex-notion/Teorema di Lagrange/Untitled\"\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eDimostrazione dei lemmi sopra.\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Teorema di Lagrange/Untitled 1.png\" alt=\"image/universita/ex-notion/Teorema di Lagrange/Untitled 1\"\u003e\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Teorema di Lagrange/Untitled 2.png\" alt=\"image/universita/ex-notion/Teorema di Lagrange/Untitled 2\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLa cosa interessante di questa parte √® possiamo usare una classe laterale per partizionare il gruppo iniziale!\u003c/p\u003e\n\u003ch2 id=\"il-teorema-di-lagrange\"\u003eIl teorema di Lagrange\u003c/h2\u003e\n\u003cimg src=\"/images/notes/image/universita/ex-notion/Teorema di Lagrange/Untitled 3.png\" alt=\"image/universita/ex-notion/Teorema di Lagrange/Untitled 3\"\u003e\nDividere significa che **partiziona** l'insieme iniziale in alcuni insiemi distinti.\nL'insieme $G:H$ √® l'insieme che contiene tutti i cosets, credo.\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eDimostrazione\u003c/p\u003e","title":"Teorema di Lagrange"},{"content":"Introduction to the Rice Theorem Ci sono molti teoremi che non possono essere decisi, vedere Halting Theorem and Reducibility. Qui andiamo a chiederci quale sia l\u0026rsquo;insieme dei problemi decidibili.\nPropriet√† dei linguaggi TMüü© $$ L_{\\mathcal{M}} = \\left\\{ x \\in \\Sigma^{*}: \\mathcal{M} \\text{ accetta } x \\right\\} $$$$ L_{\\mathcal{M}} = L_{\\mathcal{M}'} \\implies P(\\mathcal{M}) = P(\\mathcal{M}') $$ Definiamo questa non triviale se esiste una macchina per cui √® 0, e una per cui √® 1 (ossia non √® costante). Practically this definition is useful when we need to have a difference between the language and the Turing machine that decides that language.\nThree properties of Turing Machinesüü© Language properties (what language does it decide? This property concerns Rice\u0026rsquo;s Theorem) Structural properties (what are constituents of turing machine?) Algorithmic properties (how is computing) It is important to note that only Language properties concerns Rice\u0026rsquo;s Lemma. Enunciato di Rice Se $P$ √® una propriet√† dei linguaggi TM, allora √® indecidibile il problema \u0026ldquo;$\\mathcal{M}$ ha la propriet√† $P$\u0026rdquo;.\nProof of Rice $$ \\left\\{ \\langle M \\rangle : code(\\mathcal{M}) \\land P(M) = 1 \\right\\} $$ is undecidable. We proved this by Mapping reducibility with the HALT language.\nWithout loss of generality, we assume that given a $P$ we have that $P(\\mathcal{M}_{\\varnothing}) = 0$. Then, given the fact that the property is not trivial we have that exists a $\\mathcal{M}$ such that $P(\\mathcal{M}) = 1$. Let\u0026rsquo;s procede by contradiction. Assume that $P$ is decidable. Let\u0026rsquo;s proof that $HALT \\leq P$ where $P$ is the language that knows the same stuff. This proves Rice Theorem by mapping reducibility properties.\nL\u0026rsquo;insieme delle funzioni non decidibili Qui andiamo a dimostrare che la stragrande maggioranza dei linguaggi non sono riconoscibili. TODO: questo si potrebbe ripassare dalle slides e verrebbe fatto in maniera diversa.\nUnione di insiemi numerabili √® numerabileüü© Vedi Descrizione linguaggio#Numerabilit√† per alfabeti per costruzione e dimostrazione. Sarebbe buono saperlo fare da solo. L\u0026rsquo;idea √® avere un parametro che di dice quanto √® l\u0026rsquo;esponente dell\u0026rsquo;insieme. E poi andare per sorta di ricorsione.\nL\u0026rsquo;insieme delle TM √® numerabile.üü© Basta vedere che l\u0026rsquo;insieme delle TM √® un sottoinsieme di $A^{*}$, che √® numerabile. Questo quando usiamo la codifica binaria, quindi $A = \\left\\{ 0, 1 \\right\\}$.\nL\u0026rsquo;insieme dei linguaggi su alfabeto finito non √® numerabileüü© Possiamo rappresentare un linguaggio su un alfabeto con funzioni indicatrici. Avremmo cos√¨ una stringa binaria che ci indica o no se una stringa √® presente nel linguaggio o meno. Allora posso praticamente usare lo stesso argomento usato in diagonalizzazione di Cantor e avere il risultato.\n","permalink":"https://flecart.github.io/notes/teorema-di-rice/","summary":"\u003ch2 id=\"introduction-to-the-rice-theorem\"\u003eIntroduction to the Rice Theorem\u003c/h2\u003e\n\u003cp\u003eCi sono molti teoremi che non possono essere decisi, vedere \u003ca href=\"/notes/halting-theorem-and-reducibility/\"\u003eHalting Theorem and Reducibility\u003c/a\u003e.\nQui andiamo a chiederci quale sia l\u0026rsquo;insieme dei problemi decidibili.\u003c/p\u003e\n\u003ch3 id=\"propriet√†-dei-linguaggi-tm\"\u003ePropriet√† dei linguaggi TMüü©\u003c/h3\u003e\n$$\nL_{\\mathcal{M}} = \\left\\{ x \\in \\Sigma^{*}: \\mathcal{M} \\text{ accetta } x \\right\\} \n$$$$\nL_{\\mathcal{M}} = L_{\\mathcal{M}'} \\implies P(\\mathcal{M}) = P(\\mathcal{M}')\n$$\u003cp\u003e\nDefiniamo questa \u003cstrong\u003enon triviale\u003c/strong\u003e se esiste una macchina per cui √® 0, e una per cui √® 1 (ossia non √® costante).\nPractically this definition is useful when we need to have a difference between the language and the Turing machine that decides that language.\u003c/p\u003e","title":"Teorema di Rice"},{"content":"Def: Massimo minimo relativo (locale) $$ \\exists r \u003e 0 : f(x) \\leq f(x_{0}), \\, \\forall x \\in \\mathcal{A} \\cap I_{r}(x_{0}) $$ Dove $I_{r}(x_{0}) = \\left[ x_{0} -r, x_{0} + r \\right]$, √® un intorno\nDef: Massimo minimo assoluto $$ f(x) \\leq f(x_{0}), \\, \\forall x \\in \\mathcal{A} $$Fermat 6.2.1 Ipotesi Sia data una funzione $f: \\left[ a, b \\right] \\to \\mathbb{R}$ Se abbiamo che\n$x_{0} \\in \\left( a, b \\right)$ √® un punto di massimo o minimo relativo $f$ √® derivabile in $x_{0}$ Implica che $f'(x_{0}) = 0$\n6.2.2 Note Un p√≤ intuitivamente, questo teorema ci sta dicendo che il valore della derivata in un punto di massimo oppure di minimo deve essere uguale a 0.\nBisogno fare attenzione che il punto non deve essere sugli estremi perch√© la derivata l√¨ non √® definita in modo sufficiente per soddisfare questo teorema.\nDimostrazione\nSono due casi diversi, ma con la stessa logica\nLa permanenza del segno √® una dimostrazione per assurdo implicita, perch√© se si pone che il limite √® minore di 0 allora per la permanenza del segno per gli X presenti in quell\u0026rsquo;intorno vale che √® minore o uguale a 0!\nStessa cosa per quell\u0026rsquo;intorno.\n6.3 Rolle 6.3.1 Ipotesi Enunciato\n6.3.2 Note Ricorda l\u0026rsquo;esempio della montagnola per dare l\u0026rsquo;intuizione di questo teorema\nDimostrazione\nUso Weierstrass e posso dire che la funzione deve avere tutti i valori nel massimo e nel minimo.\nCi sono due casi, entrambi minimo e massimo sono estremi o uno dei due oppure uno dei due sono dentro l\u0026rsquo;intervallo, se sono dentro posso utilizzare fermat, invece la funzione √® constante nel primo caso.\n6.4 Lagrange 6.4.1 Ipotesi Enunciato\n6.4.2 Osservazioni Sembra che sia una generalizzazione di Rolle, in verit√† √® come Rolle ma con il piano cartesiano girato, in questo senso possiamo intuire che siano equivalenti, poi si pu√≤ anche provare a dimostrare (da Rolle si deriva lagrange e da lagrange si pu√≤ derivare rolle).\nDimostrazione\nPer la dimostrazione di questo teorema si vuole in qualche modo utilizzare il teorema di Rolle, quindi sarebbe buona cosa costruirsi una funzione ausiliaria in cui si possa utilizzare il teorema di Rolle.\n6.4.3 Corollario costante Dimostrazione\n6.5 Cauchy 6.5.1 Ipotesi Enunciato\nOsservazione sull\u0026rsquo;ipotesi 3\n6.5.2 Osservazioni La dimostrazione √® molto simile a Lagrange, in quanto voglio costruirmi una funzione ausiliaria che soddisfi Rolle.\n6.5.3 Legame con le altre funzioni Si pu√≤ notare che nel caso in cui la seconda funzione sia uguale alla funzione identit√† si pu√≤ trovare la funzione di Cauchy senza nessun problema, si pu√≤ dire che siano equivalenti\nSi pu√≤ quindi dire che i due teoremi sono equivalenti a livello logico in quanto sostanzialmente mi dicono la stessa cosa, in forme diverse (seque dalla coimplicazione delle funzioni).\n6.6 Monotonia funzioni Ora si tende a correlare la crescita di una funzione al segno di una funzione.\nEnunciato\n6.6.1 Nota Bisogna fare attenzione alla dimostrazione inversa.\nPerch√© non si pu√≤ utilizzare il teorema di Lagrange nello stesso modo con cui si va l\u0026rsquo;implica nella prima direzione. Per la seconda direzione bisogna utilizzare un assurdo con il teorema di permanenza del segno\n6.6.2 Dimostrazioni Freccia in gi√π\nFreccia in su\n6.7 Lo studio di funzione 6.7.1 I passi per l\u0026rsquo;analisi: Studio del dominio (Facoltativo) Studio di simmetrie Studio dei limiti sulle frontiere del dominio Studio della monotonia ","permalink":"https://flecart.github.io/notes/teoremi-base-analisi/","summary":"\u003ch3 id=\"def-massimo-minimo-relativo-locale\"\u003eDef: Massimo minimo relativo (locale)\u003c/h3\u003e\n$$\n\\exists r \u003e 0 : f(x) \\leq f(x_{0}), \\, \\forall x \\in \\mathcal{A} \\cap I_{r}(x_{0})\n$$\u003cp\u003e\nDove $I_{r}(x_{0}) = \\left[ x_{0} -r, x_{0} + r \\right]$, √® un intorno\u003c/p\u003e\n\u003ch3 id=\"def-massimo-minimo-assoluto\"\u003eDef: Massimo minimo assoluto\u003c/h3\u003e\n$$\nf(x) \\leq f(x_{0}), \\, \\forall x \\in \\mathcal{A}\n$$\u003ch2 id=\"fermat\"\u003eFermat\u003c/h2\u003e\n\u003ch3 id=\"621-ipotesi\"\u003e6.2.1 Ipotesi\u003c/h3\u003e\n\u003cp\u003eSia data una funzione $f: \\left[ a, b \\right] \\to \\mathbb{R}$\nSe abbiamo che\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e$x_{0} \\in \\left( a, b \\right)$ √® un punto di massimo o minimo relativo\u003c/li\u003e\n\u003cli\u003e$f$ √® derivabile in $x_{0}$\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eImplica che $f'(x_{0}) = 0$\u003c/p\u003e","title":"Teoremi Base Analisi"},{"content":"2.1 Elementi di base 2.1.1 Definizione e caratteristiche Tutto √® un insieme (su questo si basa la maggior parte della matematica) Efficace nella descrizione degli oggetti (infiniti √® ez), ma non √® efficiente nel calcolo in quanto non d√† nessun indizio sul\u0026rsquo;implementazione in memoria o sul modo per calcolarlo, c\u0026rsquo;√® solo una associazione Si pu√≤ concludere che per l\u0026rsquo;informatico non serve a molto questa teoria, ma √® la base per la matematica.\n2.1.2 Teoria Naif √à la teoria disposta a paradossi (Russel) che afferma che gli insiemi si possono formare liberamente ‚Üí Assioma di comprensione.\nAbbiamo gi√† analizzato in Logica meta-linguistica che questo paradosso √® distruttivo,\nin particolare guardare qui\nOperazioni di base\nl\u0026rsquo;appartenenza Creazione di sottoinsiemi 2.1.3 Diagrammi di Venn Il diagramma di Venn permette la rappresentazione di insiemi finiti\nL\u0026rsquo;unica cosa di ricordare, √® che non permette nesting di insiemi.\n2.2 Zermelo-Frank Set Theory Questa √® una possibile teoria assiomatica degli insiemi.\nEnti primitivi\nSono enti di cui non esiste la definizione (perch√© serve un punto di partenza).\nIn particolare sono enti primitivi\nAppartenenza Uguaglianza Nella slide c\u0026rsquo;√® scritto che non vengono definiti, ma poi l\u0026rsquo;assioma di estensionalit√† lo definisce, invece estensionalit√† definisce solo una relazione Insieme Andiamo ora a definire assiomi, cose ovvie di questa teoria che sia utile per dimostrare altre propriet√†\n2.2.1 Assioma di Estensionalit√† e sottoinsiemi Questo assioma definisce l\u0026rsquo;uguaglianza fra gli insiemi.\nPer ogni X e Y, i due insiemi sono uguali sse hanno gli stessi elementi (un Z che sta sia in X sia in Y, possiamo dire che Z √® un elemento temporaneo utile per la stesura)\nSottoinsieme\nDefinizione = #define in c++ ossia una sostituzione, una abbreviazione.\nUguale a sopra, ma invece di SSE, utilizziamo un SE.\nSe Z appartiene a X allora appartiene a Y.\nCosa √®\nRelazione fra l\u0026rsquo;ente primitivo uguaglianza con l\u0026rsquo;appartenenza, ma non √® definito come appartenenza, ente primitivo √® dato come gli pare.\n2.2.2 Assioma di separazione L\u0026rsquo;assioma di separazione √® lo strumento utile che hai visto durante la risoluzione del paradosso di Russel.\nQuindi definiamo un insieme Y a seconda di una caratteristica di X. Usiamo sempre un insieme temporaneo Z per definirlo.\nQuindi scriviamo $Y=\\{Z\\in X | P(X) \\}$ ossia esiste un Y definito per elementi Z tale che questo Z appartenga a X e soddisfa una propriet√† P(Z). Questo √® un abuso di notazione, che per√≤ d√† il senso, dovresti scrivere sempre in altro modo.\n$$ \\forall X,\\exist Y, \\forall Z, (Z \\in Y \\iff Z \\in X \\wedge Z \\in P(X)) $$Esempio, L\u0026rsquo;insieme degli studenti biondi √® definito per gli studenti biondi che siano studenti (X) e che abbiano la propriet√† di essere biondi P(Z).\n2.2.3 Assioma dell\u0026rsquo;insieme vuoto e definizione Questo assioma definisce l\u0026rsquo;insieme vuoto e definisce alcune caratteristiche\nL\u0026rsquo;insieme vuoto non ha elementi\n$\\exist X, \\forall Z, Z \\not\\in X$ Ma √® ridondante perch√© √® sufficiente definirlo con l\u0026rsquo;assioma di separazione in questo modo:\nSto ottenendo l\u0026rsquo;insieme vuoto svuotandolo da un insieme che esiste gi√†, in questo modo:\n$$ \\empty \\coloneqq \\{X \\in Y| false\\} $$2.2.4 Definizione di intersezione infinita L\u0026rsquo;intersezione si pu√≤ definire come l\u0026rsquo;insieme tale che sia contenuto sia in X sia in Y, quindi utilizzando assioma di separazione di pu√≤ fare.\nTeorema di appartenenza a un insieme intersezione\nSi pu√≤ dimostrare subito partendo dall\u0026rsquo;assioma di separazione, intendi A come insieme da cui prendi e P(Z) come appartenza a B.\nEstensione a intersezioni infinite\nBasta prendere l\u0026rsquo;intersezione binaria e utilizzare l\u0026rsquo;insieme di ritorno per altri, in modo ricorsivo se potrebbe aiutare.\nQuesto per√≤ non funziona per l\u0026rsquo;intersezione infinita ecco che c\u0026rsquo;√® il bisogno di definire l\u0026rsquo;intersezione meglio.\nDefinizione di intersezione\nF √® l\u0026rsquo;insieme tdi tutti gli insiemi da intersecare, se F vuoto lo definisco come vuoto, altrimenti utilizzo un insieme A e interseco sempre per ogni insieme Y!.\n$$ A\\in F,\\{X \\in A\\,|\\,\\forall Y :Y \\in F \\implies X \\in Y\\} $$$\\bigcap F =$ intersezione dell\u0026rsquo;insieme Insieme di tutti gli elementi da intersecare\nEsempio\n2.2.5 Assioma di unione L\u0026rsquo;assioma dell\u0026rsquo;unione definisce l\u0026rsquo;unione fra insiemi infiniti e la notazione √® molto simile per l\u0026rsquo;insieme intersezione\n$\\bigcup F$ definito in modo simile\n$$ \\exists A \\, \\forall X, \\{X \\in A\\iff\\,\\exists Y: Y \\in F \\wedge X \\in Y \\} $$E da questo si pu√≤ dimostrare il teorema dell\u0026rsquo;unione binaria che √® la definizione di unione classica che abbiamo.\n2.2.6 Assioma del singoletto Se c\u0026rsquo;√® solo un elemento in un insieme allora questo si dice singoletto\n$$ \\forall X,\\exists Y, \\forall Z \\{Z \\in Y \\iff Z = X \\} $$Si pu√≤ utilizzare insieme all\u0026rsquo;unione per relazionarsi all\u0026rsquo;ente primitivo dell\u0026rsquo;appartenenza.\nNOTA:\nl\u0026rsquo;assioma del singoletto a volte √® ridondante perch√© si potrebbe definire in altro modo, in particolare attraverso l\u0026rsquo;assioma di rimpiazzamento\nINSIEME A UNIONE\nPossiamo utilizzare un abuso di notazione di questo genere:\n$$ I = \\{ A_0,A_1 ... A_n\\} := \\{A_0\\} \\cup \\{A_1\\} \\cup ... \\cup \\{A_n\\} $$Definendo ogni insieme con pi√π elementi tramite l\u0026rsquo;unione dei singoletti dei suoi elementi.\n2.2.7 Definizione dei numeri naturali e caratteristiche Definiamo ogni codifica del numero naturale partendo da $\\empty = 0$ e definendo in modo ricorsivo\n$[N + 1](/notes/n-+-1) = [N](/notes/n) \\bigcup \\{[N](/notes/n)\\}$\nUsiamo la notazione $[\\,\\,](/notes/\\,\\,)$ per le definizioni, una relazione, una implementazione di un concetto astratto\n2.2.8 Assioma dell\u0026rsquo;infinito Questo assioma permette la creazione di un insieme infinito da cui poi si possono creare i numeri, in finiti, unito all\u0026rsquo;assioma potenza si possono creare infiniti ancora pi√π grandi, dato che possiede all\u0026rsquo;interno tutte le codifiche dei numeri naturali, qualcosa di metamatematico. Alcuni matematici pensano che sia una classe.\n$$ \\exists Y(\\empty \\in Y, \\forall N(N\\in Y \\implies N \\cup\\{N\\} \\in Y)) $$Definisce in modo univoco ogni elemento di N, partendo dagli insiemi, esiste una biunivicit√† fra elementi di questo insieme e elementi dei numeri naturali.\nAbusi di notazione\nL\u0026rsquo;insieme infinito cos√¨ definito si indica con $\\mathit{N}$\n2.2.9 Assioma dell\u0026rsquo;insieme potenza Questo insieme √® utile per espandere l\u0026rsquo;infinito ossia creare degli insiemi ancora pi√π grandi.\n√à il primo tra gli assiomi per ora esistenti che pu√≤ avere qualcosa di controverso.\n$$ \\forall X, \\exists Y, \\forall Z (Z \\in Y \\implies Z\\subseteq X) $$Ossia l\u0026rsquo;insieme Y contiene tutti gli insiemi di X.\nAbusi di notazione\nPossiede due abusi di notazione possibili: come\n$2^{\\{1,2\\}} \\,\\text{or} \\,P(x)$\n2.2.10 Assioma di regolarit√† o fondazione $$ \\forall A (A \\neq \\empty \\implies \\exists B(B \\in A \\,\\wedge \\not\\exists C(C \\in A \\wedge C \\in B))) $$ Ogni insieme non vuoto ha un elemento dal quale √® disgiunto.\nFra le conseguenze: nessun insieme contiene (ricorsivamente) se stesso e ha quindi senso cercare di misurare la taglia (chiamata cardinalit√†) di un insieme.\nSi chiama di fondazione perch√© evita la ricorsione infinita permettendo, quindi, una fine. Sar√† in seguito su questa fine che si baser√† il concetto di cardinalit√† di un insieme.\nOssia l\u0026rsquo;insieme A deve possedere per questo assioma un elemento per cui l\u0026rsquo;intersezione sia vuota).\n2.2.11 Assioma di rimpiazzamento Questo √® un assioma dibattuto, in pratica mi dice che posso costruire un altro insieme a partire da un insieme e una funzione.\nIntuitivamente: l‚Äôimmagine di un insieme rispetto a una formula che descrive una funzione √® ancora un insieme.\nIntuitivamente: se A √® un insieme, quindi √® abbastanza piccolo, e a ogni elemento ne associo un altro, in una relazione molti-a-uno, quello che ottengo come immagine √® ancora piccolo.\nIntuizione\nData una funzione che associa elementi fra due insiemi, allora questo assioma stabilisce che l\u0026rsquo;insieme d\u0026rsquo;arrivo, l\u0026rsquo;immagine, esiste come insieme (cio√® √® un insieme ben definito\nQuesto assioma √® necessario per gli infiniti e gestire queste cose, per le cose finite non serve.`\n2.3 Regole di dimostrazione Queste regole sono presentate con maggiore rigore in Deduzione naturale\n2.3.1 Regole di introduzione e eliminazione Eliminazione mi serve per restringere sull\u0026rsquo;ipotesi, un risultato intermedio per avere qualcosa che voglio.\nQuesta eliminazione pu√≤ essere utilizzata con $\\forall X. P(X) ||\\implies$\nIntroduzione\n$\\subseteq$\n2.3.2 Abbreviazioni sia x tale che P(X) significa che prendo ogni x tale che valga quello. Probabilmente per dimostrare un certo risultato Q(X).\nDi solito si fa una lunga catena di relazioni da ipotesi che finiscono con un quindi per asserire la tesi.\n2.3.3 Esempi di dimostrazione Riflessivit√† di $\\subseteq$, Asimmetria di $\\subseteq$, transivit√† di $\\subseteq$\n2.3.4 Dimostrazione per assurdo Si utilizzano le ipotesi per dimostrare una contraddizione, per cui l\u0026rsquo;ipotesi √® falsa.\nPosso concludere qualunque cosa dopo la dimostrazione per assurdo ex-falso quodlibet abbiamo solamente dimostrato che le ipotesi sono false (quindi se le ipotesi sono binarie, √® vero l\u0026rsquo;opposto).\nSignifica che una volta giunto ad un assurdo posso dire qualunque cosa, in particolare quello che mi serviva, terminando la dimostrazione.\nL\u0026rsquo;assurdo si ha quando si ha una antinomia, un p√≤ come un paradosso in cui si conclude P e Not P.\nNON P\nsi pu√≤ definire non P come P $\\implies$Assurdo\nPoniamo che $P = \\text{true} \\,$ allora $\\bar P \\implies \\text{absurd}$ passando da qualche ragionamento, cosa che chiaramente √® contro la tesi.\nDimostrazione di ex-falso quodlibet\nIP: $P, \\bar{P}$\nHP: $B$\nessendo vera P, √® vera l\u0026rsquo;unione $P \\cup B$ partendo da questa ipotesi, e unendola con l\u0026rsquo;ipotesi $\\bar{P}$ si sa che $P$ √® falso allora $B$ deve essere vera affinch√© $P \\cup B$ sia vera. Ecco che da un assurdo si ha qualunque cosa.\n2.4 Relazioni fra insiemi Vedere la pagina di appunti sulle relazioni fra insiemi (classi di equivalenza e simili, con anche le funzioni!) Relazioni fra insiemi\n","permalink":"https://flecart.github.io/notes/teoria-assiomatica-degli-insiemi/","summary":"\u003ch2 id=\"21-elementi-di-base\"\u003e2.1 Elementi di base\u003c/h2\u003e\n\u003ch3 id=\"211-definizione-e-caratteristiche\"\u003e2.1.1 Definizione e caratteristiche\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eTutto √® un insieme (su questo \u003cem\u003esi basa la maggior parte della matematica\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eEfficace nella descrizione degli oggetti (infiniti √® ez), ma \u003cstrong\u003enon √® efficiente\u003c/strong\u003e nel calcolo in quanto non d√† nessun indizio sul\u0026rsquo;implementazione in memoria o sul modo per calcolarlo, c\u0026rsquo;√® solo una associazione\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eSi pu√≤ concludere che per l\u0026rsquo;informatico non serve a molto questa teoria, ma √® la base per la matematica.\u003c/p\u003e","title":"Teoria assiomatica degli insiemi"},{"content":"Ripasso Prox: 30 Ripasso: June 6, 2023 Ultima modifica: May 14, 2023 6:13 PM Primo Abbozzo: March 13, 2023 9:20 AM Studi Personali: No\nElementi di ripasso Teoria dei Tipi Introduzione Definizione üü©‚Äî Un metodo sintattico praticabile per dimostrare l\u0026rsquo;assenza di determinati comportamenti del programma, fatto classificando le unit√† sintattiche in base ai tipi di valore che assumono\nVogliamo che fosse praticabile nel senso che effettivamente lo possiamo implementare, cio√® ci permettono di avere certe tipologie di garanzia. ma ancora √® una definizione molto ampia. E di solito si pu√≤ fare una analisi statica del comportamento del programma.\nUn altro modo per definirlo (questo molto pi√π buono) √®\nCollezioni di valori omogenei e rappresentabili e una serie di operazioni su di esse.\nOssia omogenei nel senso che hanno tutti certe propriet√†, e rappresentabili perch√© effettivamente possiamo metterli in memoria (per esempio non posso avere come tipo i Reali in modo primitivo, perch√© non √® rappresentabile).\nEsecuzione corretta, + ottimizzazione da parte del compilatore. Utilizzo dei tipi (4+) (!!!) üü®‚Äî- Slide sull\u0026rsquo;utilizzo dei tipi organizzazione concettuale\nSlide astrazione\nSlide correttezza\nSlide implementazione\nProgettazione: posso descrivere in modo concettuale cosa fa il programma e aiutare a verificare la correttezza del programma, ‚Äúseparare logicamente elementi concettualmente diversi‚Äù (posso creare tipi per certi concetti e quindi ragionare meglio, pensa sviluppare solo in assembly!) Documentazione: ci danno informazioni in pi√π riguardo il ruolo della variabile nel nostro programma. Una idea bella √® parlare di tipi come se fossero commenti Astrazione: in fase di implementazione possono aiutare a gestire meglio il nostro progetto, solitamente attraverso interfacce (a questo tipo ho certe operazioni, non ho niente di sotto), ci permette di modulizzare e gestire meglio, ++manutentibilit√†, ++ comprensibilit√† del progetto. L‚Äôastrazione su un concetto di cambia il modo di ragionare riguardo l\u0026rsquo;implementazione, o l‚Äôidea sottostante comunque. Correttezza, possiamo utilizzare i tipi per avere errori di programmazione, quindi se faccio qualcosa con un tipo, io mi aspetto di ricevere altro. (ad esempio se mi aspetto che una funzione mi ritorni qualcosa, ma mi ritorna qualcosal‚Äôaltro o non sempre quel tipo, posso darti errore staticamente parlando). Per cose di refactoring √® molto comodo, se cambi un tipo e una strtutura vorresti cambiarla anche da altre parti (se lo fai tipo in python √® molto pi√π difficile per sto motivo che non ha tipi all‚Äôesterno). O per la cosa della safety, √® impossibile sbagliare quando hai un buon sistema dei tipi (ti fa sbagliare in fase di compilazione lel, come Rust). Proprio per questa cosa che hai delle garanzie quando programmi, riesci a predire cosa ti ritorna e quindi puoi predire il modo con cui si comporta il programma. Possiamo dire che un programma √® sicuro quando rispetta sempre i vincoli del suo tipo. Per lui C non ha la caratteristica della safety, quindi puoi andare oltre alle limitazioni di utilizzo del singolo tipo (tipo array puoi accedere anche fuori dal suo range, un tipo buono non dovrebbe permettere queste cose), si potrebbe considerare quindi weakly typed, ma √® una cosa strana Implementazione: possiamo fare certe ottimizzazioni col sistema dei tipi. non servirebbero controlli dinamici per la sicurezza con un buon sistema dei tipi. Per esempio possiamo anche utilizzare offset per accedere in memoria quindi guadagniamo anche da quel punto di vista. Si migliora anche l\u0026rsquo;impatto che si ha sull quantit√† di memoria utilizzata, forse‚Ä¶ non sono sicuro da questo. Tipo theorem provers e simili\nAltre applicazioni\nUn sistema di tipi (e, per estensione, un linguaggio) √® sicuro relativamente ai tipi (o type safe) quando nessun programma pu√≤ violare le distinzioni tra tipi definite in quel linguaggio. Detto in altri termini, un sistema di tipi √® sicuro quando nessun programma durante l\u0026rsquo;esecuzione pu√≤ generare un errore non segnalato che derivi da una violazione di tipo.\nDynamic and static typing üü©‚Äî STATICO\nQuando il controllo dei tipi avviene a livello di struttura del testo. Solitamente queste informazioni sono poi rimosse nel file compilato, almenoch√© non serva per runnare.\nDato che eventuali errori sono individuati in tempo di compilazione, il prezzo in genere che si paga per un linguaggio statico √® il tempo di sviluppo del linguaggio! Solitamente un compilatore che abbia static typing e che sia safe richiede molto molto pi√π tempo.\nDINAMICO\nQuando i controlli di tipi √® fatta a runtime, e quindi bisogna runnarlo per capire cosa runna. Questo aggiunge un leggero overhead, perch√© ho bisogno di un descrittore a runtime che contenga le informazioni sul tipo, e ci sia la verifica in questo momento.\nDato che dobbiamo eseguire per trovare un errore di tipo dinamico, questo errore potrebbe essere scoperto solo nella fase finale, quando il nostro prodotto √® gi√† in produzione, e ha clienti!\nImportante osservare che la divisione fra dinamico e inferred √® indipendente al fatto che sia dinamic o static!\nManifest vs Inferred typing üü© La differenza fra manifest ed inferred typing riguarda la quantit√† di informazioni che il programmatore deve dare al compilatore per creare il sistema dei tipi\nL\u0026rsquo;inferred typing non √® altro che un typing manifesto automatico, nel senso che il compilatore stesso riesce a capire che tipo stai dichiarando. Queste cose gi√† esistono in c++ nuovo e anche golang Rust.\nInvece il manifest tiping √® quando il programmatore va ad annotare ili tipo di tute le variabili.\nTipo estensionali o intensionali üü©- Slide estensionali o intensionali\nINTENSIONALE\nQuando gli abitanti del tipo sono descritti secondo un predicato che √® una propriet√† che √® soddisfatta da tutti gli abitanti.\nSalviamo molta memoria per tipi grossi e ci permette anche di rappresentare (fino a un certo punto i tipi infiniti).\nESTENSIONALE\nQuando si va a listare tutti gli abitanti nel nostro tipo, la stessa cosa che si fa con gli enums\nSistemi di tipi Caratterizzazione di base (4) (!) üü®+ Tipi di base Poter definire nuovi tipi Controllo dei vincoli, che siano statici o dinamici non ci importa, ma ci importa che siano rispettati Computare sui tipi (equivalenza, compatibilit√†, inferenza dei tipi). Slide sistemi di tipi\nTipi di base üü© Sono i valori denotabili del linguaggio. Si dice abitante, una variabile che faccia parte di questo tipo. Cose come float, caratteri interi etc.\nVOID/UNIT, √® un tipo di base che contiene solamente il singoletto, per questo √® anche chiamato unit, in java per esempio √® il NUll, mentre in C √® il void (che per√≤ ha la differenza che non si pu√≤ assegnare, perch√© starei assegnando il niente!), e che non si pu√≤ assegnare. Solitamente √® il valore delle funzioni che non ritornano nulla, utilizzato spesso per ritornare il controllo delle funzioni. In C void √® utilizzato per distinguere procedure e funzioni e rende difficile fare le composizioni (che non so cosa sia), unit √® per avere ancora funzioni, che deveono per forza avere un codominio non nullo.\nTIPI BOOLEANI\nChe hanno vero o falso come abitanti, e ho tutte le operazioni logiche, come congiunzione disgiunzione negazione etc. La cosa particolare √® che utilizziamo un byte invece di un bit per rappresentare un bool, perch√© per accedere al valore √® molto veloce se √® allineato.\nTIPO CARATTERE\nSono i caratteri Unicode, oppure ascii,operazioni classiche sarebbero comparazione, comparazione (perch√© c‚Äô√® un ordine fra i caratteri nell‚Äôencoding, come abbiamo detto in Codifica dei caratteri), e il resto √® dipendente dal linguaggio.\nTIPI INTERI\nSolitamente spaziano fra $[-2^{r - 1}, 2 ^{r - 1} - 1 ]$hanno tutte le operazioni fra interi come uguaglianza, ordine, tutte le operazioni aritmetiche.\nTIPO REALE\nSono un subset dei reali, in particolare solamente i razionali rappresentabili, hanno stesse operazioni degli interi (importanti per ragioni di compatibilit√† e conversione con gli interi!), ricorda che ci sono fixed point or floating point representation. Abbiamo fatto principalmente floating point di IEEE745 in Calcolo di numeri finiti .\nFixed point slide\nTIPO COMPLESSO\nAnche questo, subset dei numeri complessi, stesse operazioni degli interi, con forse qualcosina in pi√π.\nENUMS\nQuesto √® il nostro primo tipo non di base, perch√© √® un costruttore di tipo possiamo infatti dichiarare nuovi tipi, e enums sono un modo per farlo. In pratica si dichiara un nuovo tipo con definizione di abitanti appartenenti a questo.\nIn C non c‚Äô√® differenza fra interi e enums, quindi non c‚Äô√® una chiara differenziazione dei tipi, quindi difficile andare a checkare la correttezza fra i due.\nTipi composti Come si fa a definire alcuni tipi pi√π complessi, composti utilizzando alcuni tipi primitivi?\nArrays Sono unacollezzione di elementi omogenei indexati da una chiave (questo mapping riesce a dare in un certo senso un ordine) (che non necessariamente devono essere degli interi, credo che su questa scia anche le hashtable sono classificati come tipo array).\nInfatti le mappe sono chiamate associative arrays.\nSi potrebbe considerare il costruttore di tipo, che prende in input un tipo e crea un array di una certra dimensione (quindi fa eccezzioni se provi ad accedere oltre) e crea un altro tipo, che √® l‚Äôarray di certa dimensione.\nEsempi di notazioni con array\nPropriet√† del tipo array\nOrdine di storage degli array (row column major)\nSe la grandezza dell‚Äôarray √® conosciuta a tempo di compilazione si pu√≤ allocare in stack, altrimenti si mette in heap, e si utilizza un descrittore, chiamato dope vector per accederci sulla heap. Di solito in rust o golang sono gli slice\nEsempio di dope vector\nEcco tutte le informazioni per il descrittore :D, stride ci dice ogni quanto saltare per avere il prossimo elemento.\nCONTROLLO\nUna delle operazioni fondamentali affinch√© abbiamo un tipo di array che sia safe √® il fatto check all‚Äôaccesso, in modo da evitare out of bounds, √® la cosa migliore che ho in termini di sicurezza.\nAltre operazioni utili sono assegnamento, confronto\nSets/Insiemi (3) Unici e orderless e omogenei sono gli elementi dei set. Quindi l‚Äôunica differenza √® il fatto che siano unici e quindi siano tutti distinti fra di loro secondo l‚Äôoperatore di uguaglianza.\nOperazioni importanti sono unione, intersezione, differenza, complemento, etc. tutte le operazioni belle sugli insiemi.\nUn esempio di operazioni fra i set sono unioni (e tutti gli amici degli insiemi) quindi per esempio se provo ad unire due insiemi con gli stessi elementi, restano gli stessi.\nAppartenenza, Unione, intersezione, complemento etc‚Ä¶ IMPLEMENTAZIONE SETS\nL‚Äôimplementazione pi√π semplice dei set √® avere un bitset, che il valore del bit ci dice se l‚Äôelemento √® presente o meno in essa. Ma non funziona per sets che sono molto larghi. Quindi di solito si utilizzano gli hash tables per sti set.\nUn altro modo √® utilizzare una hashset in pratica ogni valore ha una hash, e questo viene utilizzato per vedere se √® presente o meno (spesso funzioni fra dominio a un mio)\nUn altro modo per fare set √® utilizzare un albero binario, come fa C++ in set.\nReference Types NOTA: i puntatori sono abitanti di questi reference types, per√≤ non sono gli unici! (esempio URL, reference alla risorsa. Via di casa, reference alla tua casa).\nSono le reference a qualcosa! Questo permettono di creare strutture di dati ricorsive.\nOperazioni tipiche sono, creazione, check uguaglianza, dereferenziazione. Il pointer √® l‚Äôimplementazione pi√π semplice di questo tipo di dato.\nCASI SPECIALI REFERENCE TYPES (3)\nSenza certe tipologie di checks, le references possono causare molti problemi, come le reference wild (quando ho dei pointer non inziializzati e quindi posso avere random della stack)\nPer questi √® meglio sempre assegnare a Null per evitare questo, se non lo fa gi√† il linguaggio.\ndangling (quando si riferisce ad elementi gi√† liberati, o ci sono altre cose). Questo √® principalmente causato dal fatto che solitamente sono soluzioni basso livello, che interfaccia praticamente direttamente sulla memoria.\nMemory leak, quando sto perdendo memoria, nel senso che non ho pi√π nessuna reference, quando per esempio dislinko un puntatore, senza averla marcata come libera (quindi perdo un sacco di memoria, che non posso pi√π allocare).\nOPERAZIONI CLASSICHE (4)\nSlide reference types\nCreazione di un certo referenze ad un oggetto\nDereferencing, cerco il dato puntato da questa referenza\nEquality, per vedere se √® uguale la reference\nOPERAZIONI GENERALI CON I REFERENCES.\nVariabile referencing operator, in pratica vorrei che creasse una variabile che abbia come r-value la l-value di una certa variabile (descritto in Valutazione Espressioni), ossia il suo indirizzo o contenitore, la sua reference\nAllocazione e deallocazione dinamica, ma questa non √® che dovrebbe essere operazione su questo tipo\nPower sets Questo sono i primi tipi che non abbiamo visto in un linguaggio di programmazione, alla fine √® sempre un Sets/Insiemi, ma con qualche informazione in pi√π.\nDefinizione di powerset P, partendo da un set iniziale S.\nQuesto soprattutto √® un modo molto utile per rappresentare tuple, ossia coppie ordinate, molto naturali con dei powerset.\nOsservazione powerset per due\nCon l‚Äôosservazione di sopra abbiamo detto che la tupla definita in quel modo, che segue la definizione di kuratowsky in 3.1.1 Definizione di Kuratowsky, √® un elemento del powerset del powerset, quello √® proprio il prodotto cartesiano! Chiachiamo product types, o tipi prodotto come combinazioni una o pi√π strutture (quindi non pi√π omogeneo come prima)\nPAIRS AND TUPLES\nSlide pairs and tuples\nAbbiamo la stessa informazione con gli array (solo che possono non essere omogenei!) abbiamo sempre informazione sulla posizione, e un valore all‚Äôinterno della posizione. La coppia generalizzata √® una tupla.\nRECORDS\nSe astraiamo le tuple, aggiungendoci un nome per ogni tipo ad una certa posizione, allora abbiamo i records, che non sono altro che delle strutture.\nQuando andiamo a prendere un elemento stiamo facendo una proiezione monomorfa, perch√© da tutto quell‚Äôarray di elementi stiamo andando a prenderne un singolo.\nPATTERN MATCHING\nQuesto √® una struttura molto comune nei linguaggi funzionali, ma anche presente in rust. Sono buoni da poter definire all‚Äôinterno di un tipo prodotto.\nSlide pattern matching\nPraticamente vorremmo fare una partizione completa degli abitanti di un tipo, per questo motivo posso fare una specie di casework completo per gestire in modo esplicito tutti i casi. Questa partizione √® fatta in modo libero con delle regole :D.\nTIPI RICORSIVI\nQuesti tipi sono definiti per la prima volta grazie ai pairs (quelli con riferimento erano invece delle cose diverse, anche se concettualmente √® simile). Possiamo definire che questo sia un tipo ricorsivo nel senso che si potrebbe descrivere come un powersets infinito (credo).\nDalla lezione ora mi sembra abbia detto che deve necessariamente avere una reference dello stesso tipo\nSum Types Slide introduttiva sum types\nI tipi di somma ci permettono di avere abitandi di pi√π mondi.\nNell‚Äôesempio di sopra gli insiemi sono taggati per non confondere un elemento di un insieme con un altro! anche chiamato or types, choice types, tagged unions, union types, variant types, perch√© pu√≤ assumere un inabitante a caso fra tutti i tipi che costituiscono questa unione.\nAbbiamo gi√† visto le ENUMS che fanno cose simili, ossia pu√≤ avere abitanti di tipi diversi, quindi stiamo comunque catturando la somma dei tipi. √à interessante osservare che dal punto di vista teorico prendere un elemento di union implementato per enumerazione √® simile a tirare fuori da un pacchetto.\nUNION DATATYPES\nCome in C, posso avere le union data types, in cui stessa zona di memoria posso metterci i dati che ho scelto (solo che non mi fa check statico a vedere cosa ci pu√≤ stare!!), cio√® a differenza degli enums, non ho il controllo dell‚Äôaccesso, decido io come guardarlo.\nRECURSIVE TYPES\nAnche con i sum types posso andare a descrivere i tipi ricorsivi (solamente che alla fine invece di dire che Null √® un inabidante delle reference, gli dico che √® un abitante di qualcos‚Äôaltro!) Questo mi rende molto carina la sua struttura (e mi permette anche pattern matchin senza nessun problema (√® un modo pi√π sicuro per aprire, dato che posso fare matching).\nSlide recursive types with sum\nFunction types Praticamente sono elementi di $A^B$, con B partenza A arrivo. L‚Äôoperazione fondamentale di questi tipi sono l‚Äôapplicazione.\n","permalink":"https://flecart.github.io/notes/teoria-dei-tipi/","summary":"\u003cp\u003eRipasso Prox: 30\nRipasso: June 6, 2023\nUltima modifica: May 14, 2023 6:13 PM\nPrimo Abbozzo: March 13, 2023 9:20 AM\nStudi Personali: No\u003c/p\u003e\n\u003ch1 id=\"elementi-di-ripasso\"\u003eElementi di ripasso\u003c/h1\u003e\n\u003ch1 id=\"teoria-dei-tipi\"\u003eTeoria dei Tipi\u003c/h1\u003e\n\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"definizione-\"\u003eDefinizione üü©‚Äî\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eUn metodo sintattico \u003cstrong\u003epraticabile\u003c/strong\u003e per dimostrare\nl\u0026rsquo;assenza di determinati comportamenti del\nprogramma, fatto classificando le unit√† sintattiche in\nbase ai tipi di valore che assumono\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eVogliamo che fosse praticabile nel senso che effettivamente lo possiamo implementare, cio√® ci permettono di avere certe tipologie di garanzia. ma ancora √® una definizione molto ampia. E di solito si pu√≤ fare una analisi statica del comportamento del programma.\u003c/p\u003e","title":"Teoria dei Tipi"},{"content":"Struttura del DBMS Introduzione ai DBMS Schema riassuntivo #### Operazioni classiche Ci stiamo chiedendo, come facciamo a descrivere i processi che portano alla comprensione della query e della retrieval degli elementi utili? Questo deve fare il DBMS, ossia capace di - Aggiornare tuple - Trovare tuple - Gestire gli accessi - Gestire accessi concorrenti? ### Query processor #### Query compiler (3) üü© - Parsing (crea l'albero di derivazione per la nostra query) - Pre-processing (fa check semantici sulla query) - Optimization, si occupa lui di migliorare L'ottimizzazione #### Execution engine üü© Esegue l'effettiva computazione per la query, ed √® il punto d'incontro col resto (indexes, e logging per dire) Esegue il piano di esecuzione che probabilmente un livello superiore ha calcolato Interagisce con tutti gli altri componenti del db (ad esempio Log per transazioni e durabilit√†, buffer e scheduler delle operazioni prolly). Anche se non so nei dettagli in che modo esegue questo (alla fine roba assembly? che livello di astrazione ha?)\nThe resource manager Compiti del resource manager (2) üü©\u0026ndash; La cosa principale che fa questo √®:\nSapere dove siano le informazioni di interessa Sapere come leggerli e restituirli in fretta In questo senso gestisce le risorse, perch√© gestisce le informazioni, in questo caso risorsa principale del nostro db.\nIndex file record manager üü®++ √à la parte del database che conosce le strutture delle tables e sa accedere ai dati, ossia contiene le strutture di dati utili per l\u0026rsquo;accesso a queste tables.\nPer√≤ non so in che modo √® implementato un index, dovresti guardare in Index, B-trees and hashes.\nBuffer Manager üü© Si occupa di memorizzare in modo temporaneo le informazioni necessarie per fare le join e altre operazioni (anche una cache diciamo). ram riservata. Qui sar√† presente un nodo pi√π forte e normale tipo! Pu√≤ essere molto utile per tenere gli indici, per tabelle pi√π frequentemente accedute! Solitamente 100MB di ram qui!, circa 25k nodi di b-tree anche!\nStorage Manager üü© Probabilmente utilizza hash Index, B-trees and hashes per capire quale esatto blocco gli √® stato richiesto.\nSi occupa di tenere traccia dei blocchi precisi con informazioni nel disco principale (√® la parte del sistema che si occupa di restituire il blocco di interesse una volta richiesto la chiave).\nOther parts Transaction Manager Permette di fare le transazioni. Logging üü©- Come per i filesystem basati su logging, questo √® un metodo utile per tenere traccia dei cambiamenti effettivamente fatti o meno. vedere Filesystem. Aiuta a creare l\u0026rsquo;atomicit√† e la consistenza necessari per ACID.\nCosa fa: Scrive log in RAM, nel buffer manager, e ci sono protocolli per far s√¨ che questi vengano correttamente salvati sul disco. Nel caso di problemi, comunica col recovery manager in modo che il database torni indietro in stato consistente.\nConcurrency control Questa parte si occupa della isolation in ACID, cerca di fare s√¨ che tutte le operazioni siano eseguite come se fossero isolate uno dall\u0026rsquo;altra, in questo caso si parla di serializzabilit√† dell\u0026rsquo;operazione.\nQuesta √® la parte che ha il controllo sui locks come i Semafori o Monitor per la gestione della concorrenza.\nSchedule üü® Una sequenza di azioni (read, write, commit, abort) da un** insieme di transazioni**\nIn questo contesto le transazioni sono una cosa primitiva per dire. (esecuzione cronologica).\nSerializzazione üü•+ Questo schedule si pu√≤ classificare in completo se prende in esame le operazioni di ogni singola transazione. Seriale se viene eseguita una azione alla volta per ogni transazione (anche se potrei farne di pi√π assieme). Significa che faccio prima tutte le operazioni di una singola transazione, poi della prossima e cos√¨ via.\nUno schedule √® serializzabile, se l\u0026rsquo;effetto finale √® come di uno schedule completo seriale.\nTipologie di anomalie di concorrenza (4) Una cosa carina √® che questi processi possono essere intesi come errori di Theory of mind secondo me. Si hanno errori quando una serie fa qualcosa, ma l'altro pensa che lo stato sia di un altro genere. Pi√π in generale questo problema si pu√≤ riassumere in phantom anomaly, perch√© un oggetto viene cambiato nel momento in cui una altra transazione pensa resti la stessa.\nTransaction isolation levels üü• Concurrency control methods (3) La prima √® la pi√π restrittiva, per√≤ ha forti garanzie su serializzabilit√† basate su locks, praticamente il concetto principale √® che una singola risorsa pu√≤ essere usata da una transazione alla volta (non √® totalmente corretto, le read possono essere condivise, ma il concetto resta quello l√¨), quindi se √® concorrente su risorse diverse, non ho problemi Optimistic concurrency control in pratica faccio tutto come se non ci fosse niente, e poi faccio. Timestamping concurrency control, ad ogni transazione √® associata un timestamp e si utilizza questo per decidere chi va prima. Se l\u0026rsquo;ordine viene violato basta rollback della transazione che lo ha violato. Join methods Nested loop join üü© √à l\u0026rsquo;algoritmo $O(n^{2})$ idiota classico per la comparisons\nSingle loop join üü®++ Viene utilizzato un hash o un tree esterno di una relazione per comparare in fretta e vedere se c\u0026rsquo;√® l\u0026rsquo;esistenza.\nIn pratica si chiama single loop perch√© ciclo solamente sulla struttura esterna\nHash based join üü®+ Usiamo double hash!? Non ho capito come. Prendiamo una relazione, quella relazione la salviamo tutta dentro la hash table (con i rispettivi buckets, che siano linked list o rb-trees). Poi prendiamo l\u0026rsquo;altra relazione, passiamo dalla stessa hash, questa avr√† anche lui un bucket, poi su questo bucket ci faccio ricerca lineare per trovare le cose che mi interessano (quindi match su cose piccole). √à molto simile a single loop, solo che in questo caso la struttura √® necessariamente un hash per dire.\nSort Merge Join üü© L\u0026rsquo;algoritmo lineare di sort merge, utile quando si ha un doppio ordinamento per andare a confrontare per benino i due cosi. (this should be the fastest !?!?! solo per dati generali per√≤, but needs ordering).\n","permalink":"https://flecart.github.io/notes/the-database-management-system/","summary":"\u003ch2 id=\"struttura-del-dbms\"\u003eStruttura del DBMS\u003c/h2\u003e\n\u003ch3 id=\"introduzione-ai-dbms\"\u003eIntroduzione ai DBMS\u003c/h3\u003e\n\u003ch4 id=\"schema-riassuntivo\"\u003eSchema riassuntivo\u003c/h4\u003e\n\u003cimg src=\"/images/notes/The Database Management System-1700648809120.jpeg\" alt=\"The Database Management System-1700648809120\"\u003e\n#### Operazioni classiche\nCi stiamo chiedendo, come facciamo a descrivere i processi che portano alla comprensione della query e della retrieval degli elementi utili?\nQuesto deve fare il DBMS, ossia capace di \n- Aggiornare tuple\n- Trovare tuple\n- Gestire gli accessi\n- Gestire accessi concorrenti?\n### Query processor\n#### Query compiler (3)  üü©\n- Parsing (crea l'albero di derivazione per la nostra query)\n- Pre-processing (fa check semantici sulla query)\n- Optimization, si occupa lui di migliorare L'ottimizzazione\n#### Execution engine üü©\nEsegue l'effettiva computazione per la query, ed √® il punto d'incontro col resto (indexes, e logging per dire)\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eEsegue il piano di esecuzione\u003c/strong\u003e che probabilmente un livello superiore ha calcolato\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInteragisce\u003c/strong\u003e con tutti gli altri componenti del db (ad esempio Log per transazioni e durabilit√†, buffer e scheduler delle operazioni prolly).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAnche se non so nei dettagli in che modo esegue questo (alla fine roba assembly? che livello di astrazione ha?)\u003c/p\u003e","title":"The Database Management System"},{"content":"This is the generalization of the family of function where Softmax Function belongs. Many many functions are part of this family, most of the distributions that are used in science are part of the exponential family, e.g. beta, Gaussian, Bernoulli, Categorical distribution, Gamma, Beta, Poisson, are all part of the exponential family. The useful thing is the generalization power of this set of functions: if you prove something about this family, you prove it for every distribution that is part of this family. This family of functions is also closely linked too Generalized Linear Models (GLMs).\nThe definition $$ p(x \\mid \\vec{\\theta}) = \\frac{1}{Z(\\vec{\\theta}) } \\vec{h}(x) \\exp(\\vec{\\theta} \\cdot \\phi (x)) $$ Where $h$ defines the support, $\\theta$ are the canonical parameters and $\\phi$ is the sufficient statistics. $Z$ is called the partition function. $h$ is called the support. If a function can be written in this form then we have a member of this family. Note that if we set $h$, $\\phi$ and $Z$ and let the parameter $\\theta$ vary this is a single family (or set). And one can prove this.\nInteresting properties Finite sufficient statistics (we can compress into a finite vector without loss of information) but I did not understand this very well) Conjugate priors (I didn\u0026rsquo;t understood this very well). We say that a prior distribution (i.e. $p(\\theta)$) is conjugate to some likelihood function ($p(x\\mid \\theta)$) if the posterior distribution $p(\\theta \\mid x)$ (which results from this likelihood function and prior distribution) is the same distribution as the prior distribution (with updated parameters). This is often useful for bayesian inference, we used this in Bayesian Linear Regression for example. Corresponds to maximum entropy distributions (don\u0026rsquo;t know why). Sufficient statistics We have briefly mentioned what is a sufficient statistic above, in this section we will formally describe what that is\nDefinition of sufficient statistic $$ p(X \\mid T(X), \\theta) = p(X \\mid T(X)) $$Who is part of this family? Bernoulli is part of this family We can write the Bernoulli distribution as $p(y \\mid \\theta) = \\theta^{y}(1 - \\theta)^{1 - y}$ where $\\theta \\in [0, 1]$ and $y \\in \\left\\{ 0, 1 \\right\\}$. This is a standard trick, we did something very similar when analyzing the MLE in bernoulli in Na√Øve Bayes.\n$$ \\begin{array} \\\\ \\theta^{y}(1 - \\theta)^{1 - y} = \\exp(y \\log \\theta + (1 - y) \\log(1 - \\theta)) \\\\ = \\exp\\left( y \\log \\left( \\frac{\\theta}{1 - \\theta} \\right) + \\log ( 1- \\theta) \\right) \\\\ = (1- \\theta) \\exp\\left( y \\log\\left( \\frac{\\theta}{1 - \\theta} \\right) \\right) \\end{array} $$ We can observe that $Z(\\theta) = \\frac{1}{1 -\\theta}$, $h(x) = 1$, $\\phi(x) = x$ is the identity function and we use a change of parameter to say that the natural parameter is given by $\\log ( \\frac{\\theta}{1- \\theta})$ instead of $\\theta$, which needs to rewrite the value of $Z$ in another way, noticing that $\\mu = \\log \\left( \\frac{\\theta}{1-\\theta} \\right) \\implies \\theta = \\frac{1}{1 - e^{\\mu}}$.\nBut the important thing to notice is that Bernoulli indeed can be rewritten as a member of the exponential family, thus concluding the proof.\nGaussian is part of this family $$ p(y \\mid \\mu, \\sigma) = \\frac{1}{\\sqrt{ 2\\pi } \\sigma} \\exp \\left( -\\frac{(x - \\mu)^{2}}{2\\sigma^{2}} \\right) $$In this case the natural parameter is two-dimensional. We just need a little care handing this peculiar trait.\nThe above can be rewritten in the following way: $$ = \\frac{1}{\\sqrt{ 2\\pi \\sigma^{2} } \\exp \\frac{\\mu^{2}}{2\\sigma^{2}}} \\cdot 1 \\cdot \\exp \\left( \\begin{bmatrix} \\frac{\\mu}{\\sigma^{2}} \u0026amp; - \\frac{1}{2\\sigma^{2}}\n\\end{bmatrix} \\cdot \\begin{bmatrix} x \\ x^{2} \\end{bmatrix}\n\\right) $$\nThen it is kinda awful to rewrite the $Z$ with respect to those parameters, but I think you can be convinced it is possible. It\u0026rsquo;s far easier to see it when we set $\\sigma^{2} = 1$. That is available here see 3.1. We use this fact in proving a theorem in minimizing the Forward KL divergence for Gaussians in Variational Inference.\nWe can prove this also for the multivariate Gaussian: Image from here.\nBeta is part of this family The classical Beta distribution is\n$$ p(x \\mid \\alpha, \\beta) = \\frac{x^{\\alpha - 1} (1 - x)^{\\beta - 1}}{B(\\alpha, \\beta)} $$ Where $\\alpha \u003e 0, \\beta \u003e 0$ and the support of the beta in $[0 ,1 ]$. This is usually considered as the updated prior for the Bernoulli distribution after you have seen $\\alpha$ successes and $\\beta$ failures. A generalization for this distribution is the Dirichlet Distribution.\nThis is quite easy, after we rewrite the numerator in the following way: $$ x^{\\alpha - 1} (1 - x)^{\\beta - 1} = \\exp( (\\alpha - 1) \\log x + \\log(1 - x) (\\beta - 1))\n$$ Which can be rewritten in multivariable form in the following way: $$ \\exp \\left( \\begin{bmatrix} \\alpha - 1 \u0026amp; \\beta - 1 \\end{bmatrix} \\cdot \\begin{bmatrix} \\log x \\ \\log ( 1- x) \\end{bmatrix}\n\\right) $$ Adding the partition function completes the expression.\nChi-square is part of this family The chi-square distribution is as follows:\n$$ p(x, k) = \\frac{ x^{k / 2 - 1} \\exp\\left( -\\frac{x}{2} \\right)}{2^{k / 2} \\Gamma(k / 2)} $$ Where $k \\in \\mathbb{N}^{+}$, and the support is $(0 , \\infty)$ if $k = 1$, and $[0, \\infty)$ otherwise.\nThis is easy if we set $k / 2 - 1$ to be the canonical parameter, $\\exp(- x / 2)$ is the support, the denominator is the partition function, we just need to express $x^{ k / 2 - 1} = \\exp (( k / 2 - 1) \\log x)$ and we have also the sufficient statistics which is $\\phi(x) = \\log x$.\nBinomial is part of the family $$ p(x \\mid \\pi) = \\begin{pmatrix} n \\\\ x \\end{pmatrix} \\pi^{x} (1 - \\pi)^{n - x} $$ This is the classical count for the Tartaglia triangle, also known as the Pascal Triangle, in this case is just the iterated Bernoulli assuming $x$ number of successes. This is a special case of the multinomial distribution. We have $\\pi \\in [0, 1]$ and the support is $\\left\\{ 0, \\dots, n \\right\\}$.\n$$ \\pi^{x} (1 - \\pi)^{n - x} = \\exp(x \\log \\pi + (n - x) \\log(1 - \\pi)) = \\exp(n \\log(1- \\pi)) \\cdot \\exp\\left( x \\log \\frac{\\pi}{1- \\pi} \\right) $$And now we can clearly see that $\\exp( - n \\log(1- \\pi))$ is our partition, $\\phi(x) = x$ is our sufficient statistics, $\\log \\frac{\\pi}{1-\\pi}$ is our canonical parameter and the binomial coefficient is our support.\nUniform distribution is not in the family $$ p(x \\mid b) = \\begin{cases} \\frac{1}{b} \u0026 \\text{ for } x \\in [0, b] \\\\ 0 \u0026 \\text{ otherwise} \\end{cases} $$ We want to prove that this classical distribution is not part of our family of distributions. We have $b \\in (0, \\infty)$ and the support is $[0, b]$.\nIn this case there is no way to encode into the exponential family the cases of the function. The exponential can\u0026rsquo;t just return $0$. And the support has no information about the $b$. This is not a proof, but it is reasonable.\nDirichlet is part of the family TODO\n","permalink":"https://flecart.github.io/notes/the-exponential-family/","summary":"\u003cp\u003eThis is the generalization of the family of function where \u003ca href=\"/notes/softmax-function/\"\u003eSoftmax Function\u003c/a\u003e belongs. Many many functions are part of this family, most of the distributions that are used in science are part of the exponential family, e.g. beta, Gaussian, Bernoulli, Categorical distribution, Gamma, Beta, Poisson, are all part of the exponential family.\nThe useful thing is the generalization power of this set of functions: if you prove something about this family, you prove it for every distribution that is part of this family.\nThis family of functions is also closely linked too Generalized Linear Models (GLMs).\u003c/p\u003e","title":"The Exponential Family"},{"content":"Some history: Reticular Theory vs Neuron Doctrine The late 19th century witnessed a debate in neuroscience between Camillo Golgi and Santiago Ram√≥n y Cajal, two pioneers whose opposing views shaped our understanding of the nervous system. This debate centered on the structural and functional organization of neurons, culminating in their joint reception of the 1906 Nobel Prize in Physiology or Medicine.\nGolgi‚Äôs Reticular Theory Golgi proposed the Reticular Theory based on his staining techniques (see #Staining methods), which held that:\nThe nervous system functions as a continuous network rather than being composed of individual cells. Neurons are physically fused together into a syncytium, forming a vast, interconnected reticulum. Electrical impulses travel freely through this continuous structure, without the need for discrete cellular units. Golgi‚Äôs model was conceptually aligned with other biological systems of the time, such as the circulatory system, which was known to form a continuous network of blood vessels.\nCajal‚Äôs Neuron Doctrine Santiago Ram√≥n y Cajal, a Spanish neuroscientist, refined and expanded upon Golgi‚Äôs staining method, using it to produce detailed drawings of neurons. His meticulous observations led him to reject the Reticular Theory in favor of the Neuron Doctrine, which proposed that:\nThe nervous system is composed of discrete, individual cells called neurons. Neurons communicate through specialized contact points (later identified as synapses by Sherrington) rather than through direct cytoplasmic continuity. Information flows in a directional manner from dendrites to axon terminals, supporting the concept of unidirectional signal propagation. Cajal‚Äôs work provided strong anatomical evidence that neurons were separate entities, fundamentally reshaping the understanding of neural communication.\nTheir conflicting views were most prominently displayed at the 1906 Nobel Prize ceremony, where both gave speeches that reinforced their respective positions.\nLa struttura del neurone Main Structural Parts (2) üü© We can identify three main parts regarding the structure of a single neuron:\nAxons, which are responsible for sending activation potential signals externally, communicating with other cells. The signal originating from the axon starts from a section called the initial segment. They travel for around few hundred micrometers typically, most of them no more than few millimeters in length. A few special cases can be up to a meter long, like the axon that goes from the spinal cord to the foot. Dendrites (also called dentritic branches or processes), which are responsible for receiving signals from other neurons. The number of inputs that a particular neuron receives depends on the complexity of its dendritic arbor: nerve cells that lack den- drites are innervated by (thus, receive electrical signals from) just one or a few other nerve cells, whereas those with increasingly elaborate dendrites are innervated by a commensurately larger number of other neurons.\nWhich means that the complexity of the input in these cells is related to the branching of the dendrites. These inputs can vary from 1 to 100'000 for each nerve cell. We cal the end of an axon the pre-synaptic terminal and the end postsynaptic specialization.\nThe axons and dendrites are not directly connected; there is a small space between them called the synaptic cleft (the discovery of this was astonishing; in the past, it was thought that the brain was a continuous entity (see above), but instead, we have small discrete units, discovered through the silver staining methods of Golgi, see #Staining methods). The information in this pre- and post-synaptic space is managed by neurotransmitters.\nTypically, for a single neuron, we are dealing with dimensions on the order of micrometers.\nWe can also analyze the neuron from the perspective of its main functional parts, in which case there are four, as illustrated in the image for different types of neurons. The magically interesting thing is that the connections can be vastly different, yet they ultimately adhere to a fairly coherent concept of the parts (in a sense, we also find here the reasoning by abstraction common in computer science‚Äîlikely, from the physical perspective of neurotransmitters, there are differences, but they offer the same interface for attachment, so to speak).\nOther parts Endoplasmatic reticulum (stores the calcium, which is important for the activation potentials) The endoplasmic reticulum is a network of membranous tubules within the cytoplasm of eukaryotic cells, continuous with the nuclear membrane. It usually has ribosomes attached and is involved in protein and lipid synthesis. dentrites Golgi apparatus The golgi apparatus is a complex of vesicles and folded membranes within the cytoplasm, it is involved in secretion and intracellular transport. Vesicles (pre and post synaptic parts) axon. Mitochondria Mitochondria are the energy factories of the cells. The energy currency for the work that animals do is the energy-rich molecule adenosine triphosphate (ATP). The ATP is produced in the mitochondria using energy stored in food. Ribosome A Ribosome is a minute particle consisting of RNA and associated proteins found in large numbers in the cytoplasm of living cells. Ribosomes bind messenger RNA and transfer RNA to synthesize polypeptides and proteins. See that neurons are separated! The synaptic endings (called terminal boutons) have little spaces, called synaptic clefts where neurostrasmettitors are released. We call it presynaptic and postsynaptic connections.\nClassificazioni dei neuroni Ci sono molte tipologie di neuroni in natura, specialmente differiscono a seconda se stiamo parlando di vertebrati o invertebrati. In generale possiamo caratterizzarli in\nUnipolar Bipolar Multipolar Che viene riassunto dal diagramma sottostante. Solitamente i multipolar sono dei vertebrati. Convergenza e divergenza üü© Questa √® una cosa che probabilmente non abbiamo in modo naturale nelle reti, si parla di divergenza del segnale neuronale nel momento in cui un singolo neurone eccitato va a comunicare con molti neuroni, potenzialmente attivandone molti. Convergenza invece quando un neurone, prendiamo caso quello incaricato per fare contrarre il muscolo, deve prendere input da molti neuroni sensoriali, e quindi decidere se si deve contrarre o estendere a seconda di questa informazione.\nStaining methods Silver Staining Golgi silver staining, pioneered by Camillo Golgi in the late 1800s, is a groundbreaking histological technique that has profoundly influenced neuroscience. This method uses silver nitrate to selectively and randomly stain a small fraction of neurons in their entirety, unveiling the complete structure of individual nerve cells, including cell bodies, dendrites, and axons, against a clear, unstained background.\nSantiago Ram√≥n y Cajal built on Golgi‚Äôs groundbreaking silver staining technique by using it to meticulously reveal the intricate architecture of neurons. Cajal‚Äôs detailed observations and artistic renderings provided crucial evidence for the neuron doctrine, demonstrating that the nervous system is composed of discrete, individual cells rather than a continuous network.\nToday, modern staining methods‚Äîsuch as immunohistochemistry, fluorescent in situ hybridization, and genetically encoded markers like green fluorescent protein (GFP), are some modern methods used to visualize the neurons.\nFluorescent microscopy Another way to stain it so to have cell-specific bacteria (This is called fluorescent microscopy) or other stuff (I didn\u0026rsquo;t understood exactly what) and use it to stain the neurons via fluorescent stuff.\nFluorescent microscopy uses properties of fluorescent dyes or proteins to illuminate specific components within a specimen (eg. tubulin, actin proteins in the cell). In this method, samples are tagged with fluorophores that absorb light at one wavelength and then emit it at a longer wavelength, producing vivid, high-contrast images against a dark background. This selective labeling allows researchers to visualize and track the distribution, interactions, and dynamic behavior of molecules and cellular structures in real time. Advances in fluorescent microscopy, such as confocal and two-photon imaging, have enabled three-dimensional reconstruction of tissues and deep-tissue imaging with minimal phototoxicity.\nIn vivo (functional dies) High resolution Selectivity of proteins The high-magnification, high-resolution pictures that could be obtained with the electron microscope clearly established that nerve cells are functionally independent units; such pictures also identified the specialized cellular junc- tions that Sherrington had named synapses\nRam√≥n two principles üü® Veder 24 del KANDEL Principle of dynamic polarization: afferma che l\u0026rsquo;eccitazione di un neurone va linearmente in un verso (prolly per escludere il fatto che torni indietro)\nConnectional specificity: afferma che c\u0026rsquo;√® un senso, una semantica per cos√¨ dire, sul perch√© certi neuroni sono connessi assieme.\nGlial Cells Function and Etymology üü© Typically, these cells, as the Latin name suggests (similar to the English word glue), are connecting cells, meaning they facilitate proper communication between one neuron and another. They are essential for maintaining homeostasis, modulating synaptic function, and responding to injury. In the brain, most cells are glia cells outnumbering nerve cells 3 to 1.\nThe first type forms myelin for axons in the central system, the second in the peripheral system (it‚Äôs like a burrito, with many layers). The function of the third type is unknown. Astrocytes Astrocytes are star-shaped glial cells predominantly found in the central nervous system (CNS) (brain and neural cord). They are involved in maintaining the blood-brain barrier, regulating ion and neurotransmitter concentrations in the extracellular environment, and providing metabolic support to neurons. Additionally, astrocytes contribute to synaptic plasticity by modulating neuro-transmission and facilitating the clearance of excess glutamate, preventing excitotoxicity.\nOligodendrocytes Oligodendrocytes are specialized glial cells responsible for myelinating axons in the CNS. Unlike Schwann cells, which myelinate a single axon in the peripheral nervous system, a single oligodendrocyte can extend its processes to myelinate multiple axons. This myelin sheath enhances the speed of electrical conduction through saltatory conduction, which is critical for efficient neural communication. Oligodendrocytes also provide metabolic support to neurons and are implicated in neurodegenerative diseases such as multiple sclerosis, where their dysfunction leads to demyelination and impaired neural signaling.\nMicroglia Microglia serve as the resident immune cells of the CNS, functioning as the first line of defense against pathogens and injury. They constantly survey their environment and, upon detecting damage or infection, transition into an activated state to clear debris, remove apoptotic cells, and release inflammatory mediators. While microglia are essential for neuroprotection, their overactivation has been linked to chronic neuroinflammation, which plays a role in neurodegenerative diseases such as Alzheimer‚Äôs and Parkinson‚Äôs. Recent research suggests that microglia also contribute to synaptic pruning, a crucial process in neural circuit refinement during development.\nThey share many properties with macrophages found in other tissues, and are primarily scavenger cells that remove cellular debris from sites of injury or normal cell turnover.\nSchwann Cells Schwann cells are the principal myelinating glial cells in the peripheral nervous system (PNS). Unlike oligodendrocytes, each Schwann cell wraps around a single axon segment, forming the myelin sheath necessary for rapid signal transmission. Beyond myelination, Schwann cells support axonal regeneration following injury, a capability that is notably limited in the CNS. They achieve this by releasing growth factors, clearing myelin debris, and guiding regenerating axons toward their targets. Due to their regenerative potential, Schwann cells are being investigated for therapeutic applications in spinal cord injuries and peripheral nerve repair.\n","permalink":"https://flecart.github.io/notes/the-neuron/","summary":"\u003ch3 id=\"some-history-reticular-theory-vs-neuron-doctrine\"\u003eSome history: Reticular Theory vs Neuron Doctrine\u003c/h3\u003e\n\u003cp\u003eThe late 19th century witnessed a debate in neuroscience between \u003cstrong\u003eCamillo Golgi\u003c/strong\u003e and \u003cstrong\u003eSantiago Ram√≥n y Cajal\u003c/strong\u003e, two pioneers whose opposing views shaped our understanding of the nervous system. This debate centered on the \u003cstrong\u003estructural and functional organization of neurons\u003c/strong\u003e, culminating in their joint reception of the \u003cstrong\u003e1906 Nobel Prize in Physiology or Medicine\u003c/strong\u003e.\u003c/p\u003e\n\u003ch4 id=\"golgis-reticular-theory\"\u003eGolgi‚Äôs Reticular Theory\u003c/h4\u003e\n\u003cp\u003eGolgi proposed the \u003cstrong\u003eReticular Theory\u003c/strong\u003e based on his staining techniques (see \u003ca href=\"/notes/the-neuron/#staining-methods\"\u003e#Staining methods\u003c/a\u003e), which held that:\u003c/p\u003e","title":"The Neuron"},{"content":"The perceptron is a fundamental binary linear classifier introduced by (Rosenblatt 1958). It maps an input vector $\\mathbf{x} \\in \\mathbb{R}^n$ to an output $y \\in \\{0,1\\}$ using a weighted sum followed by a threshold function.\nThe Mathematical Definition Given an input vector $\\mathbf{x} = (x_1, x_2, \\dots, x_n)$ and a weight vector $\\mathbf{w} = (w_1, w_2, \\dots, w_n)$, the perceptron computes:\n$$ z = \\mathbf{w}^\\top \\mathbf{x} + b = \\sum_{i=1}^{n} w_i x_i + b $$where $b$ is the bias term. The output is determined by the Heaviside step function:\n$$ y = f(z) = \\begin{cases} 1, \u0026 \\text{if } z \\geq 0 \\\\ 0, \u0026 \\text{otherwise} \\end{cases} $$Learning Rule Given a labeled dataset $\\{ (\\mathbf{x}^{(i)}, y^{(i)}) \\}_{i=1}^{m}$, the perceptron uses the following weight update rule for misclassified samples ($y^{(i)} \\neq f(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b)$):\n$$ \\mathbf{w} \\leftarrow \\mathbf{w} + \\eta (y^{(i)} - f(z^{(i)})) \\mathbf{x}^{(i)} $$$$ b \\leftarrow b + \\eta (y^{(i)} - f(z^{(i)})) $$where $\\eta \u003e 0$ is the learning rate.\nKey Properties Linear separability: The perceptron converges if and only if the data is linearly separable (perceptron convergence theorem). Limitations: It cannot solve problems like XOR due to its inability to learn non-linearly separable functions. Extension: The multi-layer perceptron (MLP) overcomes this limitation using hidden layers and nonlinear activation functions. Perceptron Convergence Theorem The perceptron learning algorithm converges in a finite number of updates if the training data is linearly separable.\nSetup and Notation Let the training set be $\\{ (\\mathbf{x}^{(i)}, y^{(i)}) \\}_{i=1}^{m}$, where $\\mathbf{x}^{(i)} \\in \\mathbb{R}^n$ and $y^{(i)} \\in \\{-1, +1\\}$.\nThe perceptron updates its weight vector $\\mathbf{w}$ as follows for each misclassified point $(\\mathbf{x}^{(i)}, y^{(i)})$:\n$$ \\mathbf{w} \\leftarrow \\mathbf{w} + y^{(i)} \\mathbf{x}^{(i)} $$where we assume the bias is absorbed into $\\mathbf{x}$ by appending an extra dimension with $x_0 = 1$.\nWe assume the update rate is $1$, the same argument can be done with any update rate.\nAssumption (Linear Separability): There exists a weight vector $\\mathbf{w}^*$ and a margin $\\gamma \u003e 0$ such that for all training points,\n$$ y^{(i)} (\\mathbf{w}^* \\cdot \\mathbf{x}^{(i)}) \\geq \\gamma $$where $\\|\\mathbf{w}^*\\| = 1$.\nProof We first bound the Growth of $\\mathbf{w} \\cdot \\mathbf{w}^*$ Define $\\mathbf{w}_t$ as the weight vector after $t$ updates. Initially, let $\\mathbf{w}_0 = \\mathbf{0}$. Each update modifies $\\mathbf{w}$ as:\n$$ \\mathbf{w}_{t+1} = \\mathbf{w}_t + y^{(i)} \\mathbf{x}^{(i)} $$ Taking the dot product with $\\mathbf{w}^*$,\n$$ \\begin{align} \\mathbf{w}_{t+1} \\cdot \\mathbf{w}^* \u0026amp;= (\\mathbf{w}_t + y^{(i)} \\mathbf{x}^{(i)}) \\cdot \\mathbf{w}^* \\\n\u0026amp;= \\mathbf{w}_t \\cdot \\mathbf{w}^* + y^{(i)} (\\mathbf{x}^{(i)} \\cdot \\mathbf{w}^) \\end{align} $$ Since $y^{(i)} (\\mathbf{x}^{(i)} \\cdot \\mathbf{w}^*) \\geq \\gamma$, summing over all updates, $$ \\mathbf{w}_T \\cdot \\mathbf{w}^ \\geq T \\gamma $$ Where $T$ is the number of updates till now. We then bound $\\|\\mathbf{w}_t\\|^2$: The norm squared of $\\mathbf{w}$ evolves as:\n$$ \\begin{align} \\|\\mathbf{w}_{t+1}\\|^2 \u0026= \\|\\mathbf{w}_t + y^{(i)} \\mathbf{x}^{(i)}\\|^2 \\\\ \u0026= \\|\\mathbf{w}_t\\|^2 + 2 y^{(i)} (\\mathbf{w}_t \\cdot \\mathbf{x}^{(i)}) + \\|\\mathbf{x}^{(i)}\\|^2 \\end{align} $$Since the update happens only for misclassified points, $y^{(i)} (\\mathbf{w}_t \\cdot \\mathbf{x}^{(i)}) \u003c 0$, so we drop it to get:\n$$ \\|\\mathbf{w}_{t+1}\\|^2 \\leq \\|\\mathbf{w}_t\\|^2 + R^2 $$where $R = \\max_i \\|\\mathbf{x}^{(i)}\\|$. Iterating over $T$ updates,\n$$ \\|\\mathbf{w}_T\\|^2 \\leq T R^2 $$We wrap up with the convergence bound. Using the Cauchy-Schwarz inequality,\n$$ \\mathbf{w}_T \\cdot \\mathbf{w}^* \\leq \\lVert \\mathbf{w}_T\\rVert \\lVert \\mathbf{w}^*\\rVert \\implies T \\gamma \\leq \\lVert \\mathbf{w}_T \\rVert \\leq \\sqrt{T R^2} $$ $$\n$$ Dividing by $\\sqrt{T}$, $$ \\sqrt{T} \\geq \\frac{T \\gamma}{R} \\implies T \\leq \\frac{R^2}{\\gamma^2} $$ Since $R$ and $\\gamma$ are constants, this implies that the perceptron makes at most $\\frac{R^2}{\\gamma^2}$ updates, proving convergence in $\\mathcal{O}(\\frac{R^2}{\\gamma^2})$\nReferences [1] Rosenblatt ‚ÄúThe Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain.‚Äù 1958\n","permalink":"https://flecart.github.io/notes/the-perceptron-model/","summary":"\u003cp\u003eThe \u003cstrong\u003eperceptron\u003c/strong\u003e is a fundamental binary linear classifier introduced by \u003ca href=\"https://psycnet.apa.org/record/1959-09865-001\"\u003e(Rosenblatt 1958)\u003c/a\u003e. It maps an input vector $\\mathbf{x} \\in \\mathbb{R}^n$ to an output $y \\in \\{0,1\\}$ using a weighted sum followed by a threshold function.\u003c/p\u003e\n\u003ch3 id=\"the-mathematical-definition\"\u003eThe Mathematical Definition\u003c/h3\u003e\n\u003cp\u003eGiven an input vector $\\mathbf{x} = (x_1, x_2, \\dots, x_n)$ and a weight vector $\\mathbf{w} = (w_1, w_2, \\dots, w_n)$, the perceptron computes:\u003c/p\u003e\n$$\nz = \\mathbf{w}^\\top \\mathbf{x} + b = \\sum_{i=1}^{n} w_i x_i + b\n$$\u003cp\u003ewhere $b$ is the \u003cstrong\u003ebias\u003c/strong\u003e term. The output is determined by the Heaviside step function:\u003c/p\u003e","title":"The Perceptron Model"},{"content":"https://huyenchip.com/2023/05/02/rlhf.html √® un blog post che lo descrive in modo abbastanza dettagliato e buono.\nIntroduzione a RLHF Questo √® il processo che √® quasi la migliore per la produzione di LLM moderni (maggior parte si basano su questo per dire).\nStruttura generale Si pu√≤ dire che RLHF si divida in 3 parti fondamentali\nCompletion il modello viene allenato a completare parole dal web,solitamente √® molto inutile Fine tuning per le singole task, per esempio riassumere, rispondere in certo modo etc. Reinforcement Learning basato su un reward model scoperto. Partiamo con l\u0026rsquo;approccio di reinforcement learning che √® la parte un po\u0026rsquo; pi√π interessante in questo momento\nHuman Feedback Introduzione al metodo Dato che utilizziamo gli LLM come aiutanti per noi umani, √® importante che il loro output sia il pi√π possibile allenato sulle preferenze di noi umani. Per questo motivo dobbiamo creare un metodo che permetta di allenare il modello basandoci su queste preferenze.\nThe reward model Come descritto da (Ziegler et al. 2020), un approccio inizialmente utilizzato √® provare a definire in modo esplicito un modello $r(x, y)$ in cui $x$ √® il prompt iniziale e $y$ √® la completion data dal modello. Segue poi uno schema del genere: $y_{1}, y_{2}, y_{3}, y_{4}$ generati dal modello, poi questi vengono rankati in ordine di preferenza (oppure anche solamente il migliore fra i quattro, poi si utilizzano 4 e non due in questo papero perch√© cos√¨ una persona pu√≤ scegliere, solo pi√π veloce per dire). E da questo si pu√≤ allenare in un modo che non ho ancora capito una cosa di preferenza.\nReferences [1] Ziegler et al. ‚ÄúFine-Tuning Language Models from Human Preferences‚Äù 2020\n","permalink":"https://flecart.github.io/notes/the-rlhf-pipeline/","summary":"\u003cp\u003e\u003ca href=\"https://huyenchip.com/2023/05/02/rlhf.html\"\u003ehttps://huyenchip.com/2023/05/02/rlhf.html\u003c/a\u003e √® un blog post che lo descrive in modo abbastanza dettagliato e buono.\u003c/p\u003e\n\u003ch2 id=\"introduzione-a-rlhf\"\u003eIntroduzione a RLHF\u003c/h2\u003e\n\u003cp\u003eQuesto √® il processo che √® quasi la migliore per la produzione di LLM moderni (maggior parte si basano su questo per dire).\u003c/p\u003e\n\u003ch3 id=\"struttura-generale\"\u003eStruttura generale\u003c/h3\u003e\n\u003cp\u003eSi pu√≤ dire che RLHF si divida in 3 parti fondamentali\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eCompletion\u003c/strong\u003e il modello viene allenato a completare parole dal web,solitamente √® molto inutile\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFine tuning\u003c/strong\u003e per le singole task, per esempio riassumere, rispondere in certo modo etc.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReinforcement Learning\u003c/strong\u003e basato su un \u003cstrong\u003ereward model\u003c/strong\u003e scoperto.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003ePartiamo con l\u0026rsquo;approccio di reinforcement learning che √® la parte un po\u0026rsquo; pi√π interessante in questo momento\u003c/p\u003e","title":"The RLHF pipeline"},{"content":"Some notes Mix-based systemsüü® Created in 1981 by David Chaum. Very similar to the previous one, in practice, in the end, it acts as a proxy but not only does it take and receive, but it also mixes together the packets it has received from the sources, applying its key.\nDisadvantage: The public-private mixing system is very slow. For this reason, a network of nodes is established, each having a symmetric key, making it much faster.\nThe important thing to note is that this system has been influential in modern tor networks.\nFullz dataleak A fullz dataleak has the minimum indispensable to create bank accounts or pay with credit cards\nName and Surname birthdate fiscal code phone number residence address So its very important to keep this information private!\nThe Tor Ecosystem This system tries to anonymize the user with principles similar to #Anonymity by proxy. The initial user message goes through different relays before reaching the end destination. The system is a little bit more complex than this, so we are breaking down a connection example\nIt\u0026rsquo;s called onion because each relay has only an outer layer of the onion. The core is what the end user receives.\nHow Tor Works The Tor network sends the payload through three random relay servers in the network. Information about what we are accessing, from who, is not accessible. But some information is still accessible, for example:\nOur ISP knows that we are trying to access the Tor network, because we need a listing of tor nodes. The exit relay knows to whom we are talking to, as this information is needed to send the message. As the exit node is often public, they are often blocked by institutions, like banks.\n#### Overlay networks \u003e Rete ‚Äúoverlay‚Äù. Una rete **chiusa** al quale interno vengono distribuiti dati in **forma anonima**. Questo √® il principio dei servizi onion. Service setup When a service is put onto this network it connects to some intro nodes whose role is to introduce clients to the servers. The map server-\u0026gt;intro nodes is then saved into another node, which is called the directory node. This node contain mappings from services and intro points.\nClient Connection The client that wants to connect to an anonymous service needs to know who are the intro nodes. He asks the directory node who gives him the connections. Directory gives him a descriptor, that is verified with the original .onion address who acts as a secure key.\nThe the client asks a secret string from a rendezvous node. The secret string and rendezvous are then sent to the intro nodes, and these sent it to the original service that decides whether to accept or not that service.\nIf it accepts, it sends the secret to the rendezvous, who then creates a circuit between the client and the server. Now everything can be sent and received anonymously.\n","permalink":"https://flecart.github.io/notes/the-tor-protocol/","summary":"\u003ch2 id=\"some-notes\"\u003eSome notes\u003c/h2\u003e\n\u003ch4 id=\"mix-based-systems\"\u003eMix-based systemsüü®\u003c/h4\u003e\n\u003cp\u003eCreated in 1981 by David Chaum.\nVery similar to the previous one, in practice, in the end, it acts as a proxy but not only does it take and receive, but it also mixes together the packets it has received from the sources, applying its key.\u003c/p\u003e\n\u003cimg src=\"/images/notes/Introduction to Cyber Security-20240326102655961.webp\" alt=\"Introduction to Cyber Security-20240326102655961\"\u003e\n\u003cp\u003e\u003cstrong\u003eDisadvantage:\u003c/strong\u003e\nThe public-private mixing system is very slow. For this reason, a network of nodes is established, each having a symmetric key, making it much faster.\u003c/p\u003e","title":"The Tor protocol"},{"content":"CIAA principles of security We have already outlined these principles in Sicurezza delle reti and talked about the concepts of authentication and integrity. Here we try to deepen these concepts and delve a little bit more on the attack vectors These are acronyms, usually called CIA and AAA for infrastructure\nConfidentiality This is one concerns about the secrecy of the sent message. We do not want others to be able to access and read what we are doing.\nEavesdropping üü© This is an example of attack of confidentiality. The setting is usually like this: Eve that intercepts the message sent by each other. For example in network security, it is quite easy to eavesdrop with Wireshark or similars.\nIntegrity Integrity concerns with message tampering. The received message should be the same as the sent one (man in the middle are common attacks).\nAuthentication Authentication is important when we need to know to whom we are talking to. We should need to be sure that that is exactly the person (or the machine) we are trying to connect (or talk to). In this framework it is about integrity. For more in depth analysis see User authentication.\nSpoofing attacksüü© When an attacker authenticates as another user.\nManipulation attacksüü© This is tampering.\nAvailability The system should be available, that is accessible by its users.\nDenial of service attacksüü© For example if you have limited number of ports, a common example of denial of service attack is the Syn flooding where multiple services ask to open a TCP connection, but it doesn\u0026rsquo;t continue with the communication, leaving the port occupied but useless.\nAnonymity On the internet we are not anonymous we are always tracked by ISP, cookies and many other strategies that I am not even aware of. This is a problem we we want to be anonymous, so how can we reach this target??\nAnonymity by proxyüü© We just use another computer to repeat my information, this computer doesn\u0026rsquo;t have access to the underlying information, but it substitutes his IP to ours, so the end receiver doesn\u0026rsquo;t exactly know where the initial message comes from.\nAAA principles of security See Sicurezza OS\nAuthentication Answers: who are you?\nAuthorization Answers: what can you do?\nAccounting Answers: what have you done?\n","permalink":"https://flecart.github.io/notes/theoretical-notions-of-security/","summary":"\u003ch2 id=\"ciaa-principles-of-security\"\u003eCIAA principles of security\u003c/h2\u003e\n\u003cp\u003eWe have already  outlined these principles in \u003ca href=\"/notes/sicurezza-delle-reti/\"\u003eSicurezza delle reti\u003c/a\u003e and talked about the concepts of authentication and integrity. Here we try to deepen these concepts and delve a little bit more on the attack vectors\nThese are acronyms, usually called CIA and AAA for infrastructure\u003c/p\u003e\n\u003ch3 id=\"confidentiality\"\u003eConfidentiality\u003c/h3\u003e\n\u003cp\u003eThis is one concerns about the secrecy of the sent message. We do not want others to be able to access and read what we are doing.\u003c/p\u003e","title":"Theoretical Notions of Security"},{"content":"In this note we explore a theme of time and space complexity. Those are cardinal themes in Theoretical CS. Time -\u0026gt; execution step bounds on algorithms Space -\u0026gt; the cells visited by a Turing Machine when executed.\nIntroduction to Time Complexity This note will build upon know techniques of algorithms analysis explained in Notazione Asintotica. We will need big-$O$ notation and $o$ notation. L\u0026rsquo;idea √® che il problema di decisione √® decidibile se limito la lunghezza del teorema. Simile al numero di Chaitin, che non √® computabile, ma √® approssimabile quanto si vuole. In un certo senso √® computabile. The general idea is to ask how the function $\\varphi$ that maps the longest $n$ proof to the number of steps of computation behaves.\nRobustness of the notion of time complexityüü® The notion of \u0026ldquo;computational steps\u0026rdquo; used to measure the time complexity varies along\nComputational models definition of computational steps The code of the input and output (not always binary, for example big numbers are not fixed size). Influence of the Computational Model In Complexity Theory the choice of the formal model influences the complexity class of the model! This is different from the argument from computational theory of the Church Turing Thesis, where it asserts that a function is computable in every computational model. See 7.7 in (Sipser 2012).\nMulti-tape vs single-tape TM It can be proved that every $t(n)$ time multi-tape TM can be simulated by a $t^{2}(n)$ single tape TM. See Theorem 7.8 of (Sipser 2012).\nThe Time Complexity Class Definition of the Time Complexity Classüü© Languages that are decidable in $O(t(n))$ time are part of this class, denoted as $TIME(t(n))$. With $t : \\mathbb{N} \\to \\mathbb{R}^{+}$.\nAnother way to understand this is that if a algorithms terminates in at most $t(n)$ steps then it belongs to this class.\nPolynomial Complexity Classüü© $$ P = \\bigcup_{i \\geq 1} TIME(n^{i}) $$ This is defined as the class of the reasonable efficiency programs. NOTE: this is invariant with respect to the chosen coding system (if an algorithm is still in P, then it will remain in P even if you change code scheme).\nP is invariant for all models of computation that are polynomially equivalent to the deterministic single-tape Turing machine, and P roughly corresponds to the class of problems that are realistically solvable on a computer. $$ EXP = \\bigcup_{i \\geq 1} TIME(2^{n^{i}}) $$ See later.\nPATH is in Püü© We can prove that the language $\\left\\{ \\langle G, s, t \\rangle \\mid G \\text{ is a graph that has a route from } s \\text{ to } t \\right\\}$ is in $P$ class. (Just use Grafi#BFS or Grafi#DFS).\nNOTE: we have worked assuming that the algorithm worked on the nodes, but usually TM work with bits, the thing is that there is a polynomial algo that converts that nodes into binary format, so it is not much of a big deal.\nOverview of problems in $P$ Exponential Complexity Classüü© $$ EXP = \\bigcup_{i\\geq 1} TIME(2^{n^{i}}) $$ This class is common of the algorithms that use backtracking, for example Costraint Satisfaction Problems. Or just brute-force search all the branches.\nNon-deterministic Complexity Class Let $N$ be a non-deterministic decider (which means that the TM will halt on every computation branch) then we have that a problem is in this complexity class, called $NTIME$ if the running time cost $f: \\mathbb{N} \\to \\mathbb{N}$ is bounded by that (longest computational branch). The difference with #Polynomial Complexity Class is that here we consider the length of a single branch, but we explore everything at the same time!\nQuindi\n$$ NP = \\bigcup_{i\\geq 1} NTIME(n^{k}) $$Simulation by Deterministic TM We can prove that every TM in NP can be simulated by a deterministic machine in $2^{Ot(n)}$ time, where $t(n)$ is the complexity class of the TM. The intuition is easy, just try every possible computational branch, and see for the result. We then observe that $NP \\subseteq EXP$ but this is not so useful.\nClique problem See Common problems in Theoretical CS#The Clique problem for description of the problem.\nNP algorithm Just\nSelect a subset of nodes from $G$. Do it non deterministically. Verify if this subset is a complete graph. If yes add it to the solution set. We can prove that this is correct, and it works, but it is a non deterministic algorithm, so it isn\u0026rsquo;t easily simulated by deterministic algorithms, even though we proved in Estensioni di Turing e altre macchine that from the computability point of view it is the same.\nVerifiable Given input the graph, and a subset, we need to\nFor each node in the subset, check if it is linked to each other. Return the previous truth result. So easy. Other NP-complete problems If you have some time, you should give a proof for each problem (poly-reduction from sat)\nVertex Cover Hamiltonian paths Undirected Hamiltonian paths Subset-sum Verifiability Def: verifiability $$ w \\in A \\iff \\exists c : M \\text{ accepts } \\langle w, c \\rangle $$ If $M$ is polynomial then we say that this is polynomially verifiable. We can prove that this notion is equivalent for $NP$ complexity classes. We also require that $c$ is of polynomial length.\nTh: Verifiability = NPüü© From a philosophical point of view, if a problem is in NP, we can just guess a solution, or just do brute force. There is no classical algorithmical solution that solves it, or a constructive proof for it.\n$\\leftarrow$: let\u0026rsquo;s suppose we have a $M$ that decides non deterministically that language. On input $\\langle w, c \\rangle$ we run $M(w)$ and if it accepts, return true if the branch is good. ($c$ guides us about what non-deterministic branch to choose).\n$\\to$ : let\u0026rsquo;s assume we have a polynomial verifier, we need to build a TM that decides it non deterministically in polynomial time. choose non deterministically a certificate $c$ the encodes the path of the non-deterministic computation. If this accepts then accept!\nPhilosophical thoughts on P vs NP Intuitively we can have this intuition: The class of problems in $P$ is the class of problems were you need to come up with a solution by yourself. The class of problems in $NP$ is the class of problems were you just need to verify if a given solution is valid. From a personal human point of view this clearly seem to indicate that the two classes are different. But we have no proof.\nIf P were equal to NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in ‚Äúcreative leaps‚Äù, no fundamental gap between solving a problem and recognizing the solution once it‚Äôs found. Everyone who could appreciate a symphony would be Mozart; Everyone who could follow a step-by-step argument would be Gauss.\n‚Äì Prof. Scott Aaronson, 2006\nSpace complexity terminology Def: space complexity Given a $\\mathcal{M}$ Turing Machine that halts on every input, then his space complexity is a function $t : \\mathbb{N} \\to \\mathbb{N}$ such that $t(n)$ is the maximum number of cells visited by $\\mathcal{M}$ on inputs of length $n$. We can say something very similar for the non-deterministic TM, se way that its space complexity is the maximum number of tape cells visited on a single computational branch.\nDef: Space complexity Class We define the space complexity class $SPACE(t(n))$ as all languages decidable by a TM in $O(t(n))$ space. Analogously the $NSPACE(t(n))$ complexity class is defined. We use a non-deterministic TM here.\n$$ P \\subseteq NP \\subseteq PSPACE = NPSPACE \\subseteq EXPTIME $$ The last subset is given by an observation that a TM that uses $f(n)$ space (PSPACE) cannot have more than $f(n)2^{O(f(n))}$ computational steps before looping. Def: PSPACE and NPSPACE $$ PSPACE = \\bigcup_{k}SPACE(n^{k}) $$$$ NPSPACE = \\bigcup_{k} NSPACE(n^{k}) $$Def: PSPACE-completeness We say that $L$ is PSPACE-complete if it is $\\in PSPACE$ and every other $L' \\in PSPACE$ is poly-reducible to it.\nTh: $NP \\in PSPACE$ In order to prove this we prove that $SAT \\in PSPACE$ because as it is $NP-complete$ every NP problem can be reduced to $SAT$ and so it is in $PSPACE$. For more about SAT see Common problems in Theoretical CS#The SAT problem.\nProof of SAT in PSPACE We note that the simple algorithm that just enumerates all possible assignments is in $PSPACE$. Consider this algorithm: For all assignments for the input boolean formula do:\nAssign it and verify in poly-time if it is ok. If ok return true else continue until every assignment is used. We note that just $O(m)$ space is used, where $m$ is the number of terms. All the computation could be done in polynomial space, so the problem is in PSPACE. $\\square$. References [1] Sipser ‚ÄúIntroduction to the Theory of Computation‚Äù Cengage Learning 2012\n","permalink":"https://flecart.github.io/notes/time-and-space-complexity/","summary":"\u003cp\u003eIn this note we explore a theme of time and space complexity. Those are cardinal themes in Theoretical CS.\nTime -\u0026gt; execution step bounds on algorithms\nSpace -\u0026gt; the cells visited by a \u003ca href=\"/notes/la-macchina-di-turing/\"\u003eTuring Machine\u003c/a\u003e when executed.\u003c/p\u003e\n\u003ch2 id=\"introduction-to-time-complexity\"\u003eIntroduction to Time Complexity\u003c/h2\u003e\n\u003cp\u003eThis note will build upon know techniques of algorithms analysis explained in \u003ca href=\"/notes/notazione-asintotica/\"\u003eNotazione Asintotica\u003c/a\u003e.\nWe will need big-$O$ notation and $o$ notation.\nL\u0026rsquo;idea √® che il problema di decisione √® decidibile se limito la lunghezza del teorema.\nSimile al \u003ca href=\"https://en.wikipedia.org/wiki/Chaitin%27s_constant\"\u003enumero di Chaitin\u003c/a\u003e, che non √® computabile, ma √® approssimabile quanto si vuole. In un certo senso √® computabile.\nThe general idea is to ask how the function $\\varphi$ that maps the longest $n$ proof to the number of steps of computation behaves.\u003c/p\u003e","title":"Time and Space Complexity"},{"content":"First time we talked about this was in Sicurezza delle reti#Protocollo SSL But that was a simple toy model.\nSecure Socket Layer Secure socket Layer and TLS add security (see security principles in Theoretical Notions of Security) on the transport layers, whereas IPSec protocol adds it to the network level. So this works on a higher level of abstraction following the ISO OSI framework Architettura e livelli 1, 2#Livelli ISO/OSI.\nSSL is the old version of the TLS protocol. This provides integrity and confidentiality to the communication, see Theoretical Notions of Security. The main difference of SSL and TLS is that this has vulnerabilities like POODLE attack\nPrinciples Session It\u0026rsquo;s an association (probably something similar to SA in Sicurezza delle reti). That connects the client to the server. Defines the cryptographic parameters to allow the communication.\nStuff for session:\nSession identifier: generated by the server to identify an active or resumable session. Peer certificate: X 509v3 certificate. Compression method: algorithm used to compress the data before encryption. Cipher spec: encryption and hash algorithm, including hash size. Master secret: 48 byte secret shared between the client and server. Is resumable: indicates if the session can be used to initiate new connections. The main takeaways, similarly to what is done for SA, is that the session keeps identifying parameters and security parameters for the communication.\nConnection The same session can have more connections.\nServer¬†and¬†client:¬†random chosen¬†for¬†each¬†connection. Server write MAC secret: shared key used to computeMAC on¬†data¬†sent¬†by the¬†server. Client¬†writes¬†MAC¬†secret:¬†same¬†as¬†above¬†for¬†the¬†clientServer¬†write¬†key:¬†shared¬†key¬†used¬†by¬†encryption¬†whenserver¬†sends¬†data. Client¬†writes¬†key:¬†same¬†as¬†above¬†for¬†the¬†client.Initialization¬†vector:¬†initialization¬†vectors¬†required¬†byencryption.\nSequence¬†numbers:¬†both¬†server¬†and¬†client¬†maintain such¬†a¬†counter¬†to¬†prevent¬†replay,¬†cycle¬†is $2^{64} - 1$\nThe SSL record Alerts They are two bytes used for error/warning information.\nTLS handshake protocol TLS stands for Transport Layer Security, it provides CIA (See Theoretical Notions of Security) guaranties at the process level, not at the host or gateway level as IPSec does.\nThis works at the process layer to ensure security from the protocol perspective. It\u0026rsquo;s more granular because it is out of the ISO/OSI stack.\nProperties Two of the tree principles in Theoretical Notions of Security are done with this. Integrity and Confidentiality. Auth is implemented at the application layer.\nExchange of keys It\u0026rsquo;s important, TLS uses a symmetric key to communicate after communication is established. Another diagram that better specifies the encryption of the messages Exchange protocol Just use common exchange protocols!\nDiffie Hellman RSA And variations are some examples\nAuthenticity of certificates CA\u0026rsquo;s are used to exchange the security keys securely. This is the default, historically there have been some attacks on this method\nOther options could be just self sign the certificate and exchange that signed thing (needs other things, like manual operations to validate and trust it).\nValidation of the Certificates During the negotiation of the keys, a certificate is needed. Within this certificate are present some information about\nIssuer CA Issuing and expiration date. Public key, and who can use this cert Where it can be verified Where to look for if it has been revoked. These certificates build a chain of certification, which should be validated by the client before connecting.\nDomain Validation and extended validation: issuer makes different checks. With the former only the domain is validated (it is issued if the domain is owned), with the latter also organization or company is validated. So the main difference between the two is the cost of issuing a certificate. This is checked with the policy number on the certificate.\nRevocation of the certificatesüü®+ Hosts should check if the certificate is still valid or not. If a certificate has been revoked, it should be listed in a certificate revocation list on a site. You should check a serial number in the certificate. If this is present on the site then it is revoked.\nBut there is a more recent protocol, the OCSP (online certificate status protocol) that has an api style for checking the revocation. In this way the client doesn\u0026rsquo;t need to download the whole CRL.\nAttacks on TLS CA trustworthiness See verisign 2001 to Microsoft, Comodo hack, DigiNotar, TrustWave\nUsage of weak ciphers During the negotiation, some weak cipher could be chosen, this makes the communication easier to break. (AKA using RC4 or MD5).\nProtocol Attacks Renegotiate with NULL algorithm (lol!) Downgrade TSL version to a vulnerable one, or force usage of insecure ciphers. Man in the middle You need to stole a valid certificate, then you can put yourself in the middle of the communication with the user.\nUsually the main defense against this type of attack is certificate pinning.\nHearthbeat Some package sent to keep the communication on between idle times. Some firewalls for example could kill the connection if no package is sent. The response is a echo and random strings.\n","permalink":"https://flecart.github.io/notes/tls-ssl-protocol/","summary":"\u003cp\u003eFirst time we talked about this was in \u003ca href=\"/notes/sicurezza-delle-reti/#protocollo-ssl\"\u003eSicurezza delle reti#Protocollo SSL\u003c/a\u003e But that was a simple toy model.\u003c/p\u003e\n\u003ch2 id=\"secure-socket-layer\"\u003eSecure Socket Layer\u003c/h2\u003e\n\u003cp\u003eSecure socket Layer and TLS add security (see security principles in \u003ca href=\"/notes/theoretical-notions-of-security/\"\u003eTheoretical Notions of Security\u003c/a\u003e) on the transport layers, whereas \u003ca href=\"/notes/ipsec-protocol/\"\u003eIPSec protocol\u003c/a\u003e adds it to the network level. So this works on a higher level of abstraction following the ISO OSI framework \u003ca href=\"/notes/architettura-e-livelli-1-2/#livelli-iso/osi\"\u003eArchitettura e livelli 1, 2#Livelli ISO/OSI\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSSL is the old version of the TLS protocol.\nThis provides \u003cstrong\u003eintegrity\u003c/strong\u003e and \u003cstrong\u003econfidentiality\u003c/strong\u003e to the communication, see \u003ca href=\"/notes/theoretical-notions-of-security/\"\u003eTheoretical Notions of Security\u003c/a\u003e.\nThe main difference of SSL and TLS is that this has vulnerabilities like POODLE attack\u003c/p\u003e","title":"TLS-SSL protocol"},{"content":"Introduction to tokenization Tokenization is the process of converting normal strings into small little pieces that could be fed into one of our models. It usually comes from a tradition in programming languages, as we can see in Automi e Regexp where we define a specific token to have a known pattern, usually recognized by regular expressions.\nThere have been historically been many approaches to tokenization, let\u0026rsquo;s see a few:\nUn approccio semplice (e non funzionante) Uno dei primi approcci che potrebbe venire in mente per questo problema di divisione delle parole √® avere delle componenti fisse (ad esempio lettere di alfabeto, o lettere) e utilizzare queste per fare tokenization. Cio√® stiamo mappando parti delle parole in modo greedy, prima arriva meglio √®. Si potrebbe rappresentare in questo modo: Da questo ipynb Subword tokenization A volte conviene dividere una stessa parola in token che siano pi√π piccoli della parola, perch√© questi potrebbero essere utilizzati in modo ricorrente in suffissi o prefissi (questo ha senso), per√≤ abbiamo bisogno di algoritmi che facciano questa tokenizzazione. Byte Pair Encoding Viene tratta per benino in ambito NLU (Sennrich et al. 2016)\nAlgoritmo in breve With this approach we use al algorithm similar to this:\nStart with each character as a different symbol (create a set) begin iterate The most frequent pair of symbols is merged into a single symbol. end iteration on n done iterations, or when the set is considered small enough So this is just a small and easy algorithm that we can use to create tokenizations over a single text corpus.\nStudio versione in paper (Credo da (Sennrich et al. 2016)) Un esempio breve in python tratto dal papero stesso:\nimport re, collections def get_stats(vocab): pairs = collections.defaultdict(int) for word, freq in vocab.items(): symbols = word.split() for i in range(len(symbols)-1): pairs[symbols[i],symbols[i+1]] += freq return pairs def merge_vocab(pair, v_in): v_out = {} bigram = re.escape(\u0026#39; \u0026#39;.join(pair)) p = re.compile(r\u0026#39;(?\u0026lt;!\\S)\u0026#39; + bigram + r\u0026#39;(?!\\S)\u0026#39;) for word in v_in: w_out = p.sub(\u0026#39;\u0026#39;.join(pair), word) v_out[w_out] = v_in[word] return v_out vocab = {\u0026#39;l o w \u0026lt;/w\u0026gt;\u0026#39; : 5, \u0026#39;l o w e r \u0026lt;/w\u0026gt;\u0026#39; : 2, \u0026#39;n e w e s t \u0026lt;/w\u0026gt;\u0026#39;:6, \u0026#39;w i d e s t \u0026lt;/w\u0026gt;\u0026#39;:3} num_merges = 10 for i in range(num_merges): pairs = get_stats(vocab) best = max(pairs, key=pairs.get) vocab = merge_vocab(best, vocab) print(best) NOTE: defaultdict √® solamente un dict normale che ha un default value, in questo caso 0 se non esiste la chiave, e get che ritorna None se non c\u0026rsquo;√®, invece di dare errore.\nVersione di GPT In GPT √® stato introdotto l\u0026rsquo;idea di creare gruppi di cattura che escludessero suffissi diversi, per esempio \u0026rsquo;s, punteggiature et cetera. Puoi vedere meglio in sezione 2.2 qui (Radford et al. 2019). Esempio del regex pattern Grammatiche Regolari per GPT2 del paper citato:\ngp2pat = re.compile(r\u0026#34;\u0026#34;\u0026#34;\u0026#39;s|\u0026#39;t|\u0026#39;re|\u0026#39;ve|\u0026#39;m|\u0026#39;ll|\u0026#39;d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?! \\S) |\\s+\u0026#34;\u0026#34;\u0026#34;) Durante l\u0026rsquo;allenamento dei GPT sono stati presenti anche tokens speciali come \u0026lt;|endoftext|\u0026gt; tokens speciali per indicare fine documento. Credo sia stata una cosa per facilitare il training effettivo. https://tiktokenizer.vercel.app/ se vuoi vedere.\nReferences [1] Radford et al. ‚ÄúLanguage Models Are Unsupervised Multitask Learners‚Äù 2019\n[2] Sennrich et al. ‚ÄúNeural Machine Translation of Rare Words with Subword Units‚Äù 2016\n","permalink":"https://flecart.github.io/notes/tokenization/","summary":"\u003ch3 id=\"introduction-to-tokenization\"\u003eIntroduction to tokenization\u003c/h3\u003e\n\u003cp\u003eTokenization is the process of converting normal strings into small little pieces that could be fed into one of our models. It usually comes from a tradition in programming languages, as we can see in \u003ca href=\"/notes/automi-e-regexp/\"\u003eAutomi e Regexp\u003c/a\u003e where we define a specific token to have a known pattern, usually recognized by regular expressions.\u003c/p\u003e\n\u003cp\u003eThere have been historically been many approaches to tokenization, let\u0026rsquo;s see a few:\u003c/p\u003e\n\u003ch4 id=\"un-approccio-semplice-e-non-funzionante\"\u003eUn approccio semplice (e non funzionante)\u003c/h4\u003e\n\u003cp\u003eUno dei primi approcci che potrebbe venire in mente per questo problema di divisione delle parole √® avere delle componenti fisse (ad esempio lettere di alfabeto, o lettere) e utilizzare queste per fare tokenization.\nCio√® stiamo mappando parti delle parole in modo greedy, prima arriva meglio √®. Si potrebbe rappresentare in questo modo:\nDa \u003ca href=\"https://github.com/microsoft/LoRA/blob/main/examples/NLU/notebooks/01-training-tokenizers.ipynb\"\u003equesto ipynb\u003c/a\u003e\n\u003cimg src=\"/images/notes/Tokenization-20240121105419785.webp\" alt=\"Tokenization-20240121105419785\"\u003e\u003c/p\u003e","title":"Tokenization"},{"content":"Top-down Algoritmo di parsing üü© Slide\nQuesto si potrebbe considerare come algoritmo classico di parsing con non determinismo. (vado avanti, ed esploro tutto, senza look ahead).\nEsempio di esecuzione\nCommenti efficienza di sopra üü© √à molto inefficiente, in particolare si potrebbe trovare una compessit√† esponenziale del tipo\n$O(b^{|w|})$, con b il massimo numero di produzioni. (la produzione maggiore la espando sempre!)\nSlide\nSi pu√≤ rendere molto pi√π efficiente con un valore di lookahead.\nFirst e Follow Utilizzeremo il simbolo $ per segnalare la fine di una stringa, cos√¨ pu√≤ godere della prefix property, che √® una cosa fondamentale per le DPDA, vedi Linguaggi Deterministici e DPDA.\nFirst intro üü© Slide\nIn pratica √® un insieme che contiene i primi caratteri possibili per tutti! (ad ochio attento si pu√≤ notare quanto sia importante per il lookahead, andiamo in pratica a considerare le produzioni che abbiano il simbolo di lookahead).\nEsempio di uso e in-uso di first\nCalcolo del first üü© Interessante in questa parte l‚Äôutilizzo dell‚Äôinsieme dei simboli annullabili che abbiamo descritto in Semplificazione grammatiche., sembra sia legata molto al first\nSlide\nL‚Äôintuizione di maggior rilievo per questo algoritmo √® che in quel modo si sta facendo un or , unione fra tutti i simboli che sono annullabili.\nQuesto algoritmo si pu√≤ estendere in modo quasi banale ai non terminali che non sono annullabili (perch√© basta prendere il primo carattere\nSlide che descrive per simboli non annullabili\nEsempi del calcolo del first\nFollow intro üü©‚Äî Slide\nQuindi un terminale appartiene a follow terminale se pu√≤ comparire dopo\nUna cosa particolare di questa definizione √® il terminale $.\nA volte ci pu√≤ interessare sapere cosa viene dopo un non terminale annullabile cos√¨ possiamo decidere di annullarlo e tenere il prossimo.\nMini esempio\nCalcolo del follow üü© Slide algo\nDa notare che per calcolare questa funzione abbiamo bisogno del first!\nEsempio 1\nEsempio 2\nGrammatiche LL(1) Tabella di parsing intro LL(1) üü© Definizione\nHo una tabella che mappa (NT, T) ‚Üí produzione.\nIn pratica una tabella di parsing ci d√† una idea del modo in cui comportarci per ogni singolo input e ogni terminale, √® quindi fondamentale per capire in che modo espandersi‚Ä¶\nOssia se ho un NT sulla stack e vedo con lookahead 1 un terminale, allora provo a capire con quale produzione posso espandere.\nAlgoritmo per riempimento tabella üü© Algoritmo calcolo della tabella\nSe il first di qualcosa che voglio mettere √® noto, allora √® easy‚Ä¶\nAltrimenti la metto per l‚Äôintera riga.\nTh sui LL(1) (chiede molto) üü© Definizione di grammatica LL(1)\nEnunciato e dimo\nLa dimostrazione di questo √® molti dalla costruzione della tabella di parsing. (in particolare l\u0026rsquo;unici modi che ci importano per dimostrare se un linguaggio √® LL(1) √® questo oppure la costruzione della tabella d parsing).\nEsempio grammatica in forma sopra\nEsempio 2\nParser LL(1) ! üü© Slide Algo pseudocodice\nL‚Äôidea √® principalmente di utilizzare la tabella di parsing per capire quale produzione utilizzare quando ho un non terminale!\nQuanto ho terminali li poppo dalla pila (se non posso poppare ritorno errore) Quando ho non-terminali vado a guardare nella tabella, se non ho niente fallisco Alla fine se ho svuotato la pila e letto tutto sono molto felice. Esempio di parsing 1\nEsempio 2\nesempio 3\nTh. ling regolare ‚Üí generabile da LL(1) üü®- Dalla lezione 14 (credo)\nCon i teoremi espressi in Grammatiche Regolari, posso trasformare l‚Äôespressione regolare in DFA e poi il dfa minimo in grammatica regolare da questo posso creare la grammatica LL1, vogliamo ora dire che possiamo sempre farlo (nel toggle c‚Äô√® il piccolo algoritmino utilizzato per creare la grammatica).\nDimo\nMini lemma:\nOgni grammatica regolare con solo produzioni $V \\implies aW$ e produzioni epsilon √® una grammatica LL(1)\nIl motivo √® che i first di ogni produzione di un non terminale sono diversi fra di loro, perch√© sono tutti parte dell‚Äôalfabeto e sono unici. E i follow sono sempre stringa terminale, quindi per il teorema di caratterizzazione dei linguaggi LL(1), questo √® un linguaggio LL(k).\nSi pu√≤ verificare che questo √® il tipo di grammatica che si estrae da un automa minimo, quindi il teorema √® soddisfatto.\nGrammatiche LL(k) Generalizzazione first follow e tabella üü©- Slide\nIntuizione\nOra il first ha la concezione dei **primi k **, lettere che possono essere anche minori di k, nel caso in cui io abbia gi√† una stringa terminale. Ma non posso avere minore di K se non √® terminale!!!!\nAllo stesso modo follow k sono i primi k caratteri che possono seguire il nostro non terminale.\nLa tabella √® generata esattamente nello stesso modo**,* solo che bisogna fare un p√≤ di attenzione alle colonne, che ora possono essere di dimensione molto maggiore rispetto alla dimensione dell‚Äôalfabeto (potenze di esse, almeno potenzialmente, poi nella pratica io mi metto a storare quello che mi serve.\nEsempio di utilizzo di first e follow generali\nTeoremi (4) su LL(k) üü® Slide\nQuesti teoremi ci danno una forte relazione fra\ngrammatica ambigua ‚Üí non √® LL(k) con questa anche la sua contronominale ricorsiva sinistra ‚Üí non LL(k) essere LL(k) ‚Üí essere un linguaggio libero deterministico ‚Üí Non ambigua esiste L deterministico tale che non ci sia G di class LL(k) (quindi i linguaggi LL(k) non bastano per avere tutti i linguaggi deterministici! Gerarchia classi di linguaggi LL(k) üü© Slide\nQuello che si pu√≤ osservare √® che ogni classe di linguaggio con k maggiore include quella con k minore. Il motivo intuitivo che non √® presente nella slide √® tipo: se posso riconoscerlo guardando una lettera pi√π avanti, lo posso ancora fare guardandone 2 o pi√π‚Ä¶\nSi pu√≤ notare che non tutti i linguaggi liberi deterministici sono riconosciuti da linguaggi LL(k), si pu√≤ osservare l\u0026rsquo;esempio di sotto.\nLibero det not implies LL(k) üü®+ esempio Incompletezza dei linguagg LL(1)\nIn questo caso √® solamente enunciato che non si pu√≤ modellare la grammatica cos√¨ trovata per renderla di classe LL(k).\nPer√≤ intuitivamente si pu√≤ capire che avrei bisogni di un k infinito per poter scegliere fra le due produzioni, riesco sempre a trovare un k che non funzioni‚Ä¶\nEsercizio a caso\n","permalink":"https://flecart.github.io/notes/top-down-parser/","summary":"\u003ch2 id=\"top-down\"\u003eTop-down\u003c/h2\u003e\n\u003ch3 id=\"algoritmo-di-parsing-\"\u003eAlgoritmo di parsing üü©\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Top-down Parser/Untitled 1.png\" alt=\"image/universita/ex-notion/Top-down Parser/Untitled 1\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eQuesto si potrebbe considerare come algoritmo classico di parsing con non determinismo. (vado avanti, ed esploro tutto, senza look ahead).\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eEsempio di esecuzione\u003c/p\u003e\n  \u003cimg src=\"/images/notes/image/universita/ex-notion/Top-down Parser/Untitled 2.png\" alt=\"image/universita/ex-notion/Top-down Parser/Untitled 2\"\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"commenti-efficienza-di-sopra-\"\u003eCommenti efficienza di sopra üü©\u003c/h3\u003e\n\u003cp\u003e√à molto inefficiente, in particolare si potrebbe trovare una compessit√† esponenziale del tipo\u003c/p\u003e\n\u003cp\u003e$O(b^{|w|})$, con b il massimo numero di produzioni. (la produzione maggiore la espando sempre!)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSlide\u003c/p\u003e","title":"Top-down Parser"},{"content":"Introduction to topological spaces We want now to extend the idea of continuity presented in limits, which is a function $f : E^{n} \\to E^{n}$ is continuous if given $x$ then $\\forall\\varepsilon \u003e 0$ $\\exists \\delta$ such that $\\forall y : \\lVert y -x \\rVert \u003c \\delta \\implies \\lVert f(y) - f(x) \\rVert \u003c \\varepsilon$. But we want to get rid of the idea of distance, and base our definition on the idea of neighborhoods, which in $E^{n}$ are just spherical radius centered around a point.\nDefinition of Topological space We define a set $X$ to be a topological space and for each $x \\in X$ we define a set of subsets of $X$ called $N_{x} : \\forall S \\in N_{x}, S \\subseteq X$ such that they satisfy the following axioms:\n$\\forall S \\in N_{x} : x \\in S$ if $S, T \\in N_{x} \\implies S \\cap T \\in N_{x}$ if $S \\in N_{x}, U \\subseteq X, S \\subseteq U \\implies U \\in N_{x}$, this implies that the union of $S_{1}, S_{2} \\in N_{x}$ is in $N_{x}$. If $S \\in N_{x}$ and $T = \\left\\{ z \\in S \\mid S \\in N_{z} \\right\\}$ then we have that $T \\in N_{x}$. We call $T$ the interior of $S$ The first three conditions seems to be reasonable, and coherent to our intuitive idea of neighborhoods. Let\u0026rsquo;s use our geometrical interpretation of a neighborhood as circles in a 2D plane. 1. is trivial to check, the second condition is just the smallest radius of the two neighborhoods, the third condition is a little bit more tricky, as $U$ is not guaranteed to be a circle with some radius, but it satisfies the first two conditions (we see here a relaxing of the strict ball radius condition). The fourth condition is just the circle without the boundary.\nIn brief, if we have a set $X$ and an assignment of neighborhoods to each point $x \\in X$ then we have a topology over the set $X$.\nThis is good resource for topological spaces. Another definition is this (this should be a preferred definition because it\u0026rsquo;s easier to remember):\nWe say that a couple $(X, \\mathcal{T})$ is a topological space on a set $X$ when $\\mathcal{T}$ is a set of subsets of $X$ such that:\n$\\varnothing, X \\in \\mathcal{T}$ $G_{i} \\in \\mathcal{T}, \\forall i \\in A \\implies \\bigcup_{i}G_{i} \\in \\mathcal{T}$ $G_{i} \\in \\mathcal{T}, \\forall i \\in \\left\\{ 1, \\dots, n \\right\\} \\implies \\bigcap_{i}G_{i} \\in \\mathcal{T}$. This behaves well for infinite unions and finite intersections. But it is equivalent, but now I don\u0026rsquo;t know exactly why. Still the most important thing here is that we have a natural notion of neighbourhood .\nIt\u0026rsquo;s easy to see that every set $S \\subseteq X$ is a subspace-topology. An easy way to convince ourselves about why we need finite intersection bound for closeness is the classical example of accumulation point studied in Limiti, e.g. the succession of sets $\\left\\{(0, \\frac{1}{n}] \\mid n \\in \\mathbb{R} \\right\\}$.\nProduct Topologies One interesting observation is that if $(X, T_{x})$ and $(Y, T_{y})$ are topologies, then there exists a product topology $X \\times Y$. We just take all the possible open sets in $T_{x}$ and product that with $T_{y}$ and one can observe that the axioms of topology are good also in this case. One can observe that this kind of proof is somehow similar to the proofs presented in Grammatiche Regolari when we try to prove things joining other things together.\nContinuity of topological spaces Let\u0026rsquo;s take, say $X$ and $Y$ to be two topologies, then the function $f : X \\to Y$ is continuous if $\\forall x \\in X, \\forall S \\in N_{f(x)}, S \\subseteq Y$ we have that $f^{-1}(S) \\in N_{x}$. This is just a difficult way to say that if the function maps to a open set in the co-domain, then it should start from an open set in the domain. We can also write the above in the following manner: Given an open set $U \\subseteq Y$ we want the pre-image $f^{-1}(U)$ to be an open set for the domain topology, which seems a lot easier to understand.\nThis is just a different characterization of the ideas of continuity we developed in #Motivation.\nPath-connected spaces We say that a topology is path connected if for every $a, b \\in \\mathcal{X}$ exists a continuous function $f$ from $f: \\left[ 0, 1 \\right] \\to \\mathcal{X}$ such that $f(a) = 0$ and $f(b) = 1$ this function describes a path in the topology that connects the two points. This is usually considered a stronger condition on the connected condition of the topological space and it\u0026rsquo;s very useful for initial exploration of the mathematical space.\nTh: path-connected space implies connected. Proof: we assume path-connected and disconnected and try to prove a contradiction. By hypothesis of disconnected space, we have two disjoint open sets $A, B$ that make up the original space $\\mathcal{X}$, let\u0026rsquo;s consider now two points in these sets. We know that we have a continuous function $f$ that connects these two points. We would like to use the disconnected hypothesis to prove that the function is not continuous, getting a contradiction. Let\u0026rsquo;s consider the sets $f^{-1}(A)$ and $f^{-1}(B)$ these two sets are disjoint in $\\left[ 0, 1 \\right]$ and their union is $[0, 1]$ because $f$ is continuous and $[0, 1] = f^{-1}(\\mathcal{X}) = f^{-1}(A) \\cup f^{-1}(B)$. But these two sets are non empty. Which contradicts the connectivity of $[0,1]$ proved in [[Metric Spaces#Connectedness of $ left[ 0, 1 right]$]]. Thus we conclude that the original set is connected.\nOne Wrong proof This is a wrong proof, some wrong proofs are educational, so I\u0026rsquo;ll include this here. Consider a ball topology (strict inequality) on the real interval with the extremes $[0], [1]$ included. We can observe that $f^{-1}(\\mathcal{X}) = f^{-1}(A) \\cup f^{-1}(B) = [0, a) \\cup (b, 1]$, we can conclude that $a = b$, these sets are open sets for construction, but their union is not $[0, 1]$ which gives the contradiction.\nSome definitions Def: Interior and boundaries Given a topology $(X, \\mathcal{T})$ we call a set $S \\subseteq X$ open if $S \\in \\mathcal{T}$. A set is closed if its complement is open. This is a easier definition of open and closeness compared to the definition present in real analysis. In this case the concept of neighbourhood is built in.\nWe cal interior set of $A$ the union of all open sets of $A$. We call boundary the difference between the closure of the set $A$ and its interior set.\nDef: connected and disconnected spaces Intuitively, we say that a topology is disconnected if we can split the original set in at least two parts. Which means: given a topology $\\mathcal{X}, \\mathcal{T}$ we can find $A, B \\in T : A \\cap B = \\varnothing \\land A \\cup B = \\mathcal{X}$. If the above condition is false, then we say that the topology is connected.\nDef: Homeomorphism A function $f: X \\to Y$ where $X, Y$ are topological spaces is said to be a homeomorphism if\nBijective Continuous Inverse is continuous This definition allows us to define a concept of equivalence of two topologies. If two spaces are homeomorphic we write $X \\simeq Y$. Def: Isotopy $A$ is the ambient space, the space where the topologies live. We define a isotopy connecting $X \\subseteq A$ and $Y \\subseteq A$ to be a continuous map $\\phi: X \\times [0, 1] \\to A$ such that $\\phi(X, 0) = X$ and $\\phi(X, 1) = Y$ and $\\forall t \\in [0, 1]$ we have that $\\phi( \\cdot, t)$ is a homeomorphism between $X$ and its image. We say that two spaces are isotopic if there is an isotopy connecting them.\nDef: Surface A surface is a topological space in which each point has a neighbourhood homeomorphic to the plane, and for which any two distinct points possess disjoint neighborhoods.\nClassification Theorem Any closed surface is homeomorphic either to the sphere, or to the sphere with a finite number of handles added, or to the sphere with a finite number of discs removed and replaced by M√∂bius strips. No two of these surfaces are homeomorphic.\nThis is one of the most important theorems in topology, but for a student that just started to understand this field, it will be probably a little difficult to do so.\nFurstenberg\u0026rsquo;s proof of infinite prime numbers There is a nice proof explained here about the infiniteness of prime numbers by just assuming basic properties of arithmetic and successions.\nStatement Let\u0026rsquo;s consider the set $\\mathbb{Z}$ we define the set $S(a, b) := \\left\\{ an + b \\mid n \\in \\mathbb{Z} \\right\\}, a, b \\in \\mathbb{Z}$. Then we consider open a set $U \\subseteq \\mathbb{Z}$ if we have that $x \\in U \\implies \\exists a, b \\in \\mathbb{Z} : x \\in S(a, b) \\land S(a, b) \\subseteq U$ which means that the set $U$ is composed by unions (that could also be infinite) of $S(a, b)$ successions.\nProof We prove that with this definition of openness we have a topology:\n$\\varnothing, \\mathbb{Z}$ are contained in this definition, check. We have infinite unions, because by definition if we can unite $S(a, b)$ together as much as we want. We have finite unions, because it\u0026rsquo;s just taking the MCD. This is not a formal mathematical proof. but you can be convinced that this is right. Then we note that if a set is finite and non-empty it\u0026rsquo;s complementary set is not closed. We notice that the set $S(a, b)$ is both closed and open for all $a, b \\in \\mathbb{Z}$. This is quite easy to be convinced with. We notice that if we take $UU = \\bigcup_{p \\text{ is prime}} S(p, 0)$ this is equal to $\\mathbb{Z} - \\left\\{ -1, 1 \\right\\}$. So we know that this set is only open and cannot be closed, by the observation of finite sets. We note now that $$ \\left( \\bigcup_{p \\text{ is prime}} S(p, 0) \\right) ^{c} = \\bigcap_{p \\text{ is prime}} S(p, 0)^{c} $$ We know that $S(p, 0)^{c}$ is open, and now conclude that if the number of $p$ was finite, then by property of topology the set should be open, which implies that the set $UU$ should be closed. Contradiction, which means the number of primes if infinite. ","permalink":"https://flecart.github.io/notes/topological-spaces/","summary":"\u003ch4 id=\"introduction-to-topological-spaces\"\u003eIntroduction to topological spaces\u003c/h4\u003e\n\u003cp\u003eWe want now to extend the idea of continuity presented in \u003ca href=\"/notes/limiti/#funzione-continua\"\u003elimits\u003c/a\u003e, which is a function $f : E^{n} \\to E^{n}$ is continuous if given $x$ then $\\forall\\varepsilon \u003e 0$ $\\exists \\delta$ such that $\\forall y : \\lVert y -x \\rVert \u003c \\delta \\implies \\lVert f(y) - f(x) \\rVert \u003c \\varepsilon$.\nBut we want to get rid of the idea of distance, and base our definition on the idea of neighborhoods, which in $E^{n}$ are just spherical radius centered around a point.\u003c/p\u003e","title":"Topological Spaces"},{"content":"Ultima modifica: March 11, 2023 7:22 PM Primo Abbozzo: March 8, 2023 6:05 PM Studi Personali: No\nElementi di ripasso Training of NN How can we be sure that we can train well our function?\nDataset quality (this cannot be changed in training time) Models and parameters of our model, we can describe it as $L(x, \\theta)$, and we try to minimize this function. Training approaches Random perturn weights, this is ispired by evolution, but it‚Äôs slow and not effective (and we can make things worse in many ways) Predict adjustments, usually we can analitically define what is the best way to minimize the loss, so we would like to follow that slope and go down! When we try to learn with the second method we usually follow the direction of a derivative (this is also an idea of gradient descent that we discussed in Metodi di Discesa.\nSo if we have a step function, we can‚Äôt learn anything, this is not a good loss. This is the classic gradient descent, but the new thing is that we have optimizers, more on them later.\nThe standard Gradient descent uses the whole dataset to calculate the direction and module of descent. Usually this is quite expensive, why would we need to use all the data when a subset could be enough? And also, why can‚Äôt we use the last gradient to know where to go? There are the ideas for the next gradient descent methods.\nStochastic Gradient descent faster More noise Sometimes when we try to escape from the noise, we can add some noise, like having a bigger step function, and we can escape a local minima if we get to.\nMomentum This is the other type of gradient descent, we add a momentum factor something like\n$$ v_{t + 1} = \\mu\\nabla L(x) + \\alpha v_t $$The first term is the gradient (direction term) the second is the momentum term.\nSlide on momentum\nA different kind of momentum is nesterov momentum that just calculates the gradient from the next point after we applied the momentum, and not before, this should be a little better because we are just going from the gradient direction in an offsetted point, and not changing the gradient with some heuristic, (non mi sono affatto spiegato bene qui, non credo infatti di averlo capito bene sto momentum)\nSlides nesterov\nBackpropagation This is the gradient descent for neural networks.\n","permalink":"https://flecart.github.io/notes/training-a-nn/","summary":"\u003cp\u003eUltima modifica: March 11, 2023 7:22 PM\nPrimo Abbozzo: March 8, 2023 6:05 PM\nStudi Personali: No\u003c/p\u003e\n\u003ch1 id=\"elementi-di-ripasso\"\u003eElementi di ripasso\u003c/h1\u003e\n\u003ch1 id=\"training-of-nn\"\u003eTraining of NN\u003c/h1\u003e\n\u003cp\u003eHow can we be sure that we can train well our function?\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDataset quality (this cannot be changed in training time)\u003c/li\u003e\n\u003cli\u003eModels and parameters of our model, we can describe it as $L(x, \\theta)$, and we try to minimize this function.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"training-approaches\"\u003eTraining approaches\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eRandom perturn weights\u003c/strong\u003e, this is ispired by evolution, but it‚Äôs slow and not effective (and we can make things worse in many ways)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePredict adjustments\u003c/strong\u003e, usually we can analitically define what is the best way to minimize the loss, so we would like to follow that slope and go down!\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eWhen we try to learn with the second method we usually follow the direction of a derivative (this is also an idea of gradient descent that we discussed in \u003ca href=\"/notes/metodi-di-discesa/\"\u003eMetodi di Discesa\u003c/a\u003e.\u003c/p\u003e","title":"Training a NN"},{"content":"Transformers, introduced in NLP language translation in (Vaswani et al. 2017), are one of the cornerstones of modern deep learning. For this reason, it is quite important to understand how they are done.\nIntroduction to Transformers Transformers are called in this manner because they transform the input data space into another with the same dimensionality.\nThe goal of the transformation is that the new space will have a richer internal representation that is better suited to solving downstream tasks. (Bishop \u0026amp; Bishop 2024)\nGeneral characteristics One major advantage of transformers is that transfer learning is very effective, so that a transformer model can be trained on a large body of data and then the trained model can be applied to many downstream tasks using some form of fine-tuning.\nMoreover, the transformer is especially well suited to massively parallel processing hardware such as graphical processing units, or GPUs, allowing exceptionally large neural network language models having of the order of a trillion (1012 ) parameters to be trained in reason- able time\nA powerful property of transformers is that we do not have to design a new neural network architecture to handle a mix of different data types but instead can simply combine the data variables into a joint set of tokens.\nIntroduction to the structure Transformers are just repeated blocks of attention layers, norms, MLP, followed by a final softmax on the final MLP layer, and preceded by a encoding layer. The first encoding layer has to embed some information about the original structure:\nSemantic information about the input Positional information about the input. Then we use the transformer blocks to process the input and get the final embedding layer. Positional encoding We need to keep positional information about the contents.\ntwo randomly chosen uncorrelated vectors tend to be nearly orthogonal in spaces of high dimensionality, indicating that the network is able to process the token identity information and the position information relatively separately.\nBinary positional encoding üü® This is just a simple idea to encode the information about the position of the tokens. The above can be generalized with a periodic function (mod 2 equivalent but continuous) $f(\\alpha^{-j}i)$. A simple way is using $\\sin$ and $\\cos$ functions. But we would like a manner to encode the relative position between one token and another.\nSin and Cos positional encoding üü®- You just put $\\alpha = 10^{4/d}$ and then the positional encoding of a token $p_{i, 2j} = \\sin(\\alpha^{-2j}i)$ and $p_{i, 2j + 1} = \\cos(\\alpha^{-2j}i)$\nIt\u0026rsquo;s not clear why we need to interleave them.\nTh: High dimensional unit vectors are almost always orthogonal This theorem states that given $a, b \\in \\mathbb{R}^{n}$, and $\\lVert a \\rVert = \\lVert b \\rVert = 1$ we have that it is highly probable that $a \\cdot b \u003c \\varepsilon$. For a small epsilon. This is not exactly a formal proof (we haven\u0026rsquo;t formalized the idea of highly probable)., but it gives an idea about why does it work. We will say that the expected product will be 0.\nProof To prove that two random high-dimensional vectors are nearly orthonormal, consider the following steps:\n$$ \\mathbf{u} = \\frac{\\mathbf{x}}{\\|\\mathbf{x}\\|}, \\quad \\mathbf{v} = \\frac{\\mathbf{y}}{\\|\\mathbf{y}\\|}, $$\nwhere $\\mathbf{x}, \\mathbf{y} \\sim \\mathcal{N}(0, I_n)$.\n$$ \\mathbb{E}[\\mathbf{u} \\cdot \\mathbf{v}] = 0 \\quad \\text{(symmetry of Gaussian distributions)}. $$$$ \\text{Var}(\\mathbf{u} \\cdot \\mathbf{v}) = \\mathbb{E}[(\\mathbf{u} \\cdot \\mathbf{v})^2] - \\underbrace{(\\mathbb{E}[\\mathbf{u} \\cdot \\mathbf{v}])^2}_{=0}. $$$$ \\mathbb{E}[(\\mathbf{u} \\cdot \\mathbf{v})^2] = \\sum_{i=1}^n \\mathbb{E}[u_i^2 v_i^2] = \\sum_{i=1}^n \\frac{1}{n} \\cdot \\frac{1}{n} = \\frac{1}{n}. $$\nThus, $\\text{Var}(\\mathbf{u} \\cdot \\mathbf{v}) = \\frac{1}{n}$.\n$$ \\mathbb{P}\\left(|\\mathbf{u} \\cdot \\mathbf{v}| \\geq \\epsilon\\right) \\leq \\frac{\\text{Var}(\\mathbf{u} \\cdot \\mathbf{v})}{\\epsilon^2} = \\frac{1}{n \\epsilon^2}. $$\nAs $n \\to \\infty$, this probability vanishes. Hence, $\\mathbf{u} \\cdot \\mathbf{v} \\to 0$ in probability.\n$$ |\\mathbf{u} \\cdot \\mathbf{v}| = \\mathcal{O}\\left(\\frac{1}{\\sqrt{n}}\\right), $$\nand their norms are exactly 1. This demonstrates the concentration of measure phenomenon in high-dimensional spaces.\nFinal Answer\nTwo random high-dimensional unit vectors are nearly orthonormal because their dot product concentrates around zero with variance $\\mathcal{O}(1/n)$, ensuring near-orthogonality, while their norms are exactly 1.\nTwo random high-dimensional unit vectors are nearly orthonormal with probability approaching 1 as dimension increases\nAnother fact: Concatenation is similar to addition: https://chatgpt.com/share/3bc87143-006a-4821-807e-5a35b06ec4da\nBuilding the embeddings üü© Usually, the embeddings for each vector are backpropagated during training. In Pytorch, you would use nn.Embedding. In this manner, each token is assigned a vector of size embedding chosen by the designer of the architecture. This value is then initialized, and every index of the vector is a learnable parameter.\nAttention First introduced in (Bahdanau et al. 2014) in the context of translation.\nWhereas standard networks multiply activations by fixed weights, here the activations are multiplied by the data-dependent attention coefficients.\nSoft attention in which we use continuous variables to measure the degree of match between queries and keys and we then use these variables to weight the influence of the value vectors on the outputs.\nThe desiderata We have said that transformers transform a set of data points into another with the same dimensionality. Attention is one important part of the architecture. To have richer representation space, we need each entry of the new vector to be a linear combination of the input. Plus, we need two properties for the attention coefficients:\nThey should be positive or null (you pay some attention, or none, it doesn\u0026rsquo;t make sense to have negative attention!) It should be limited (e.g. their sum should be 1), we choose one so that we don\u0026rsquo;t make the variance of the input explode. The intuition Attention is an architecture used in Transformers to encode a soft version of dictionaries. In the context of text classification, the main intuition is giving a certain weight of some tokens, probably contextually more important, and less than others. If we have a query, which is something we would like to know about the text, then we try to match it with a key and the relative value. The softness of attention prevents us to say: \u0026ldquo;if the key doesn\u0026rsquo;t match just return error\u0026rdquo;, instead, it returns a linear combination of possible values, accordingly weighted by the rescaled keys.\nIntuitively in the text context, attention models how much the value of one token influences another, directionally.\nOn the Asymmetricity üü© For example, we might expect that ‚Äòchisel‚Äô should be strongly associ- ated with ‚Äòtool‚Äô since every chisel is a tool, whereas ‚Äòtool‚Äô should only be weakly associated with ‚Äòchisel‚Äô because there are many other kinds of tools besides chis- els.\nAsymmetric matrices have a higher relation representation capacity as we see from the above example. This motivates a different matrix for queries keys and values.\nSelf attention üü®++ Compared to a conventional neural network, the signal paths have multiplicative relations between activation values. Whereas standard networks multiply activations by fixed weights, here the activations are multiplied by the data-dependent attention coefficients.\nUsually it is called self-attention when everything we want is just trying to change the values of the $X$ with a value. This value is called attention weight.\nIn standard attention based architectures the self-attention layer is computed as follows.\n$$ a = \\text{softmax}((W^{q}x)^{T} (W^{k}x) /\\sqrt{ D }) $$$$ y_{j} = \\sum_{i= 0}^{n} a_{i} (W^{v}x)_{ji} $$ Apply this over all batches in a parallel manner.\nThis image summarizes the main points of the attention mechanism. Why do we rescale? This is to keep the variance of the output the same as the input! If we assume that Q and K are normally distributed with variance 1 and mean 0, we are summing $D$ random variables with mean 0 and variance 1, then it\u0026rsquo;s variance is $D$ (it\u0026rsquo;s a quick exercise), dividing by $\\sqrt{ D }$ keeps the variance unitary. In this manner, the numbers do not explode.\nCross-attention In translation settings, we would like to add a context to the attention, meaning the key and query input values are different.\nCausal-attention This is also called the masked attention. In this case, we would like prevent the model to attend to tokens into the future. The intuition is easy: we just set the upper triangle to 0. We just set it to minus infinity.\nMulti-head version This is easy. We just TODO\nThe Architecture Adding the embeddings Since the positional embeddings are somewhat statistically independent from the token embeddings, both embeddings are somewhat orthogonal. Hence, the addition still preserves information about the two vectors. Since most of the operations done in an attention mechanism are linear. The final embedding is somewhat the addition of the result of the operations applied to both the positional and the token embeddings.\nThe whole architecture This is the classical image by (Vaswani et al. 2017). Which are just a lot of blocks concatenated with each other.\nReferences [1] Bahdanau et al. ‚ÄúNeural Machine Translation by Jointly Learning to Align and Translate‚Äù 2014\n[2] Vaswani et al. ‚ÄúAttention Is All You Need‚Äù 2017\n[3] Bishop \u0026amp; Bishop ‚ÄúDeep Learning: Foundations and Concepts‚Äù Springer International Publishing 2024\n","permalink":"https://flecart.github.io/notes/transformers/","summary":"\u003cp\u003eTransformers, introduced in NLP language translation in \u003ca href=\"http://arxiv.org/abs/1706.03762\"\u003e(Vaswani et al. 2017)\u003c/a\u003e, are one of the cornerstones of modern deep learning. For this reason, it is quite important to understand how they are done.\u003c/p\u003e\n\u003ch3 id=\"introduction-to-transformers\"\u003eIntroduction to Transformers\u003c/h3\u003e\n\u003cp\u003eTransformers are called in this manner because they \u003cem\u003etransform\u003c/em\u003e the input data space into another with the \u003cem\u003esame dimensionality\u003c/em\u003e.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe goal of the transformation is that the new space will have a richer internal representation that is better suited to solving downstream tasks. \u003ca href=\"https://link.springer.com/10.1007/978-3-031-45468-4\"\u003e(Bishop \u0026amp; Bishop 2024)\u003c/a\u003e\u003c/p\u003e","title":"Transformers"},{"content":"This note is still a TODO.\nTransliteration is learning learning a function to map strings in one character set to strings in another character set. The basic example is in multilingual applications, where it is needed to have the same string written in different languages.\nThe goal is to develop a probabilistic model that can map strings from input vocabulary $\\Sigma$ to an output vocabulary $\\Omega$.\nWe will extend the concepts presented in Automi e Regexp for Finite state automata to a weighted version. You will also need knowledge from Descrizione linguaggio for definitions of alphabets and strings, Kleene Star operations.\nWeighted finite-state automata Definition of WFSA We take the 5-tuple of the finite-state automata and add two functions $\\lambda : Q \\to \\mathbb{K}$ and $\\rho: Q \\to \\mathbb{K}$ (which represent the initial and final weighting function) and the transition function to a multiset (somewhat similar to non deterministic finite state automatas) $\\delta : Q \\times (\\Sigma \\cup \\varepsilon)\\times \\mathbb{K} \\times Q$, which tells us some sort of probability of transition.\nIntuitively $\\lambda$ and $\\rho$ tells us how much is that starting or finishing sequence probable. Then a path in the WFSA has a natural notion of probability. If it satisfies other axioms, see Language Models then it can be effectively also used as a language model.\nWe then need to go to define the notions of paths, yield, length of a path, if it is ambiguous or unambiguous in order to be able to speak about these automatas. Ambiguous if there is at most one accepting path for $s$.\nThe interesting thing about WFSA is that they can model many models! Part of Speech Tagging\u0026rsquo;s conditional random fields are WFSA, Language Models\u0026rsquo;s N-gram models are WFSA, also HMMs are WFSAs! So this model is quite general! The nice thing is that if you develop an algorithm for WFSAs then you can use the same algo for the other models too.\nN-grams to WFSA üü©\u0026ndash; This representation of N-grams can be easily interpreted as WFSA. The difficult thing is to define the space of the states. There is a small technical thing to include all the BOS and EOS. Relations to CRF $$ p(y|x) = \\frac{1}{Z(x)} \\exp\\left(\\sum_{i=1}^n \\sum_{j=1}^m \\lambda_j f_j(\\langle y_{i-1}, y_i \\rangle, x)\\right) $$ Assuming additive decomposability.\nCRFs are WFSAs üü®\u0026ndash; With CRFs we only had 1-1 alighments, WFSA allow to have one to many or many to one in different formats, so it is more general.\nDisadvantages for transliteration CRFs can have only a single emission per input token. This is a problem for transliteration where we can have many outputs for a single input. WFSA can model this.\nWe can observe that CRFs model emissions as $a : b$ where $\\lvert a \\rvert = \\lvert b \\rvert = 1$ each of them has length 1. This also corresponds to cases where we have a strict alignment between the input and output alphabet.\nPathsum Def: path and inner path weight $$ \\text{weight}(\\pi) = \\bigotimes_{i = 1} ^{n} w_{i} $$$$ \\text{weight}(\\pi) = \\lambda(q_{1}) \\otimes \\left( \\bigotimes_{i = 1} ^{n} w_{i} \\right) \\otimes \\rho(q_{n}) $$We accept the state if the path weight is $\\neq 0$. TODO.\nTransducers Definition of Transducers Same thing as WFSA, but we also add an output alphabet. We observe that this definition naturally translates the input text to an output format. The nice thing is that it builds upon that formal languages machinery.\nComposability $$ T := T_{1} \\circ T_{2} \\mid T(x, y) = \\bigoplus_{z \\in \\Omega^{*}} T_{1}(x, z) \\otimes T_{2}(z, y) $$ Intuitively, we say that the probability that the composed transducer $T$ goes from $x$ to $y$ is the sum of the probabilities of all the possible intermediate states $z$. This is the same idea as marginalizing over another variable in probability, here we are somewhat marginalizing over another alphabet.\nNaive Explicit construction TODO: You should provide the algorithm for exclicitly building the transducer.\nAccessible construction The main idea is to build states that can be accessed. TODO: explain and present this algorithm.\nTranslitteration General strategy is have WFST for a language, another for the other, then compose them so that we have a transducer.\nAlignment TODO:\nCollapsing into single Matrix TODO: this is content of slide 97. You need to understand the details well, better if you can work out the math.\nLehmann\u0026rsquo;s Algorithm Lehmann‚Äôs algorithm Lehmann, 1977 is a very general dynamic program for computing the Kleene closure of matrices over arbitrary closed semirings.\nWe use this algorithm to compute normalizer (or other things) for the It's very easy to see that Floyd Warshall's all shortest path (see [Grafi#Algoritmo di Floyd-Warshall](/notes/grafi#algoritmo-di-floyd-warshall)) is just Lehmann's algorithm on a tropical semiring, with Kleene start $=0$.P Connection with Gauss-Jordan TODO\nBackward algorithm for Graphs TODO: present and prove how this works, and that this is correct. This should be easy, but I never really seen a proof of correctness over topologically sorted nodes :) need to figure that out.\n","permalink":"https://flecart.github.io/notes/transliteration-systems/","summary":"\u003cp\u003eThis note is still a TODO.\u003c/p\u003e\n\u003cp\u003eTransliteration is learning learning a function to map strings in one character set to strings in another character set.\nThe basic example is in \u003cstrong\u003emultilingual\u003c/strong\u003e applications, where it is needed to have the same string written in different languages.\u003c/p\u003e\n\u003cp\u003eThe goal is to develop a probabilistic model that can map strings from\ninput vocabulary $\\Sigma$ to an output vocabulary $\\Omega$.\u003c/p\u003e\n\u003cp\u003eWe will extend the concepts presented in \u003ca href=\"/notes/automi-e-regexp/\"\u003eAutomi e Regexp\u003c/a\u003e for Finite state automata  to a weighted version. You will also need knowledge from \u003ca href=\"/notes/descrizione-linguaggio/\"\u003eDescrizione linguaggio\u003c/a\u003e for definitions of alphabets and strings, Kleene Star operations.\u003c/p\u003e","title":"Transliteration systems"},{"content":"Cosa √® UML √® un linguaggio di modelling (molto vecchio) ma ancora di continua evoluzione, da un punto di vista storico √® nato insieme ai concetti di Object Oriented Programming che ora √® molto presente all\u0026rsquo;interno dell\u0026rsquo;industria, descritto bene in Classi OOP, anche se in questa occasione sviluppata in maniera molto pi√π intuitiva (grafica).\nPerch√© serve üü© Per cercare di comunicare quanto necessario riguardo struttura e dinamicit√† dell\u0026rsquo;architettura.\nStruttura di UML Structural Diagram üü®++ These diagrams focus on representing the static structure of a system. They help depict the components, classes, objects, and their relationships in a system. Some common structural diagrams in UML include:\nClass Diagram: Shows the classes in a system and their relationships, attributes, and methods. Object Diagram: Represents instances of classes and their relationships at a specific point in time. Component Diagram: Illustrates the physical components of a system and their dependencies. Package Diagram: Organizes classes and other elements into packages to show their relationships. Behavioral diagrams (4) üü©\u0026ndash; These diagrams focus on illustrating the dynamic aspects of a system, including how it behaves and interacts over time. They are used to model the interactions between objects, the flow of control, and the system\u0026rsquo;s behavior. Common behavioral diagrams in UML include:\nUse Case Diagram: Depicts the interactions between actors (users or external systems) and the system to achieve specific goals or functions. Sequence Diagram: Shows the chronological sequence of messages exchanged between objects over time. Statechart Diagram: Represents the various states an object or system can be in and how it transitions between those states. Activity Diagram: Describes the flow of activities or processes within a system. Main relationships Queste sono anche chiamate le freccie, ossia le tipologie di relazioni che possono esistere fra entit√† diverse.\nLe relazioni esistenti Association: An association is a basic relationship that represents a link between two or more classes or objects. It indicates that instances of one class are related to instances of another class. In a graph context, you can think of associations as edges connecting nodes in a graph. Associations can have multiplicities to specify how many instances are involved in the relationship (e.g., one-to-one, one-to-many).\nAggregation: Aggregation is a specialized form of association that represents a whole-part relationship. It indicates that one class (the whole) is composed of or contains instances of another class (the part). In a graph, aggregation can be seen as a hierarchical relationship, where nodes at one level represent composite objects made up of nodes at another level. Esempio di aggregazione: Composition: Composition is a stronger form of aggregation, indicating a strict ownership relationship. It means that the whole class has exclusive responsibility for the existence and lifetime of its parts. In a graph, composition is similar to aggregation but with a stronger emphasis on the containment of parts within the whole.\nInheritance (Generalization): Inheritance, represented by a solid arrow with an open triangle, signifies an \u0026ldquo;is-a\u0026rdquo; relationship. It is used to model the inheritance hierarchy in object-oriented programming, where one class (the subclass or derived class) inherits attributes and methods from another class (the superclass or base class). In graph terms, it represents a hierarchy, with edges pointing from subclasses to their superclass.\nRealization (Interface Implementation): Realization is used to show that a class or component implements a specific interface or fulfills a particular contract. It indicates a relationship between a classifier and an interface. In graph theory, this can be seen as a form of dependency or connection between nodes representing classes and interfaces.\nDependency: Dependency is a relationship that indicates that one element relies on another element. It can be used to represent various forms of relationships, such as method dependencies, parameter dependencies, or simple associations between classes. In a graph, dependencies are akin to edges indicating connections or reliance between nodes.\nStructural diagrams Class diagrams Descrivo in che modo le varia classi sono relazionati fra di loro (ad esempi con l\u0026rsquo;albero di ereditariet√†)\nTypes of behavioral diagrams (5) Use cases (!) üü®+ Structure of use case diagrams A use case is a concept in software engineering and system design that describes a specific interaction or set of interactions between a system (usually software) and its external actors\nGoal-Oriented: Use cases are centered around achieving specific goals or objectives. Each use case represents a particular task, process, or scenario that an external actor wants to accomplish using the system. Actor: An actor is any external entity that interacts with the system. Actors can be users, other software systems, hardware devices, or any external entity that initiates a use case. Actors are defined based on their roles and responsibilities in the system. Flow of Events: A use case typically includes a description of the main flow of events, which outlines the steps or interactions involved in achieving the desired goal. It can also include alternative or exceptional flows to cover various scenarios. Preconditions and Post-conditions: Use cases may specify conditions that must be met before the use case can be initiated (preconditions) and the state of the system after the use case has been successfully completed (post-conditions). (ossia ci√≤ che abbiamo bisogno, e ci√≤ per rendere deterministico questo processo). Quindi √® utilizzato per modellare in che modo chi usa dovrebbe interagire con il nostro sistema, e ci√≤ che il nostro sistema ha bisogno per funzionare.\nEsempio: More on actors Use case modelling and diagrams üü• Use Case Diagrams: Use cases are often visualized using diagrams called use case diagrams. These diagrams show the relationships between actors and use cases, helping to provide a high-level overview of the system\u0026rsquo;s functionality. Use Case Modeling: Use case modeling is a technique used during the early stages of system design to identify and define the various use cases that the system will support. It helps in understanding and documenting user requirements and system behavior. State-chart diagrams Notazione sugli stati (4) üü®+ #### Notazione delle transizioni üü©- In modo simile agli automi a stato finito, definisco gli stati (in questo caso aggiungo anche una semantica per gli stati, e poi una possibile transizione all'interno di quelli). Perch√© utilizzare state-chart üü© Descrizione di cambi di stato, in modo a simile a quanto si farebbe per automata per esempio. Descrizione di campi statici presenti negli oggetti per esempio. √à contrapposto con gli interaction diagrams che racconta in che modo cose differenti comunicano fra di loro, questo state-chart √® utilizzato per definire in modo statico se succede cosa, cosa cambia. Esempi di state diagrams In pratica √® un grafico pi√π rilassato di Deterministic Finite Automata [Grammatiche Regolari](/notes/grammatiche-regolari) Si pu√≤ usare anche in modo innestato come in seguito Activity diagrams Cosa descrivono le activity diagrams üü© Workflows, ossia in che modo il sistema agisce, ad alto livello per poter a Parallelizzazione, se devono essere eseguite pi√π cose allo stesso tempo, √® molto comodo. Sincronizzazione, quindi anche per logica con async ha senso Sequence diagrams Interaction diagrams Cercano di modellare in che modo comunicano fra l\u0026rsquo;uno e l\u0026rsquo;altro, serve per fare cose complesse Un esempio sono i sequence diagrams\nPerch√© sequence diagrams? üü© Shows object interactions arranged in time sequence\nUn esempio di utilizzo comune √® per i protocolli, dato che il tempo √® importante √® molto facile comunicare esattamente cosa viene scambiato. Quindi utile per rappresentare in che modo chi chiama cosa nel tempo. Altro esempio, un po\u0026rsquo; pi√π complesso Descrizione della struttura üü© In alto abbiamo degli oggetti oppure degli agenti differenti, poi col tempo questi oggetti diversi scambiano messaggi, in questo caso √® chiara sequenza dei messaggi, che √® il vantaggio principale di questi diagrammi.\nAsincroni Sincroni Non bloccanti, esattamente gli stessi che abbiamo visto in sistemi Collaboration diagrams Descrizione collaboration diagrams üü© Uguale ai sequence diagrams, ma esprime messaggi possibili fra una classe e una altra e non esprime il tempo durante una singola comunicazione.\nUn altro aspetto √® che la sequenza dei messaggi √® identificata da numeri\nConfronto con i diagrammi di sequenza üü© Facile vedere messaggi che vengono scambiati da enti differenti, quindi organizzazioni diciamo. Si perde per√≤ informazione sul tempo Per il resto √® molto simile rispetto ai #Sequence diagrams perch√© anche in questo caso si scambiano messaggi, solo che non √® ben definito il tempo. (viene marcato con un numerino).\nUn esempio: ","permalink":"https://flecart.github.io/notes/unified-modeling-language/","summary":"\u003ch4 id=\"cosa-√®\"\u003eCosa √®\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003eUML\u003c/strong\u003e √® un linguaggio di modelling (molto vecchio) ma ancora di continua evoluzione, da\nun punto di vista storico √® nato insieme ai concetti di \u003cstrong\u003eObject Oriented Programming\u003c/strong\u003e che ora √® molto presente all\u0026rsquo;interno dell\u0026rsquo;industria, descritto bene in \u003ca href=\"/notes/classi-oop/\"\u003eClassi OOP\u003c/a\u003e, anche se in questa occasione sviluppata in maniera molto pi√π intuitiva (grafica).\u003c/p\u003e\n\u003ch4 id=\"perch√©-serve-\"\u003ePerch√© serve üü©\u003c/h4\u003e\n\u003cp\u003ePer cercare di \u003cstrong\u003ecomunicare\u003c/strong\u003e quanto necessario riguardo struttura e dinamicit√† dell\u0026rsquo;architettura.\u003c/p\u003e\n\u003ch3 id=\"struttura-di-uml\"\u003eStruttura di UML\u003c/h3\u003e\n\u003ch4 id=\"structural-diagram-\"\u003eStructural Diagram üü®++\u003c/h4\u003e\n\u003cp\u003eThese diagrams focus on representing the \u003cstrong\u003estatic structure of a system\u003c/strong\u003e. They help depict the components, classes, objects, and their relationships in a system. Some common structural diagrams in UML include:\u003c/p\u003e","title":"Unified Modeling Language"},{"content":"URI Sono stata LA vera invenzione di Berners Lee accennati in Storia del web. Il problema √® avere un modo per identificare una risorsa in modo univoco sull‚Äôinternet.\nIntroduzione La risorsa üü© Una risorsa √® qualunque struttura che sia oggetto di scambio tra applicazioni all‚Äôinterno del World Wide Web.\nOra una risorsa pu√≤ essere qualunque cosa, non solamente solo un file! Quindi √® agnostico rispetto a contenuto oppure metodo di memorizzazione del dato, appare anche in questo ambiente importante vedere quanto siano importanti standard che permettano una comunicazione\nEsempi di risorsa:\nFile di testo Immagine Chiave di Hash Chiave per una query di database Una funzione da chiamare da remoto In pratica qualunque cosa che possa fare il web, e identificabile da un URI si potrebbe chiamare risorsa, √® un termine molto generale, non definito in modo formale o tecnico.\nSlide\nIn breve √® risorsa qualunque cosa che possa essere oggetto di scambio in una interazione web.\nURL and URN Gli URI (Uniform Resource Identifier) sono una sintassi usata in WWW per definire i nomi e gli indirizzi i oggetti (risorse) su Internet.\nURL indicano la locazione della risorsa, ossia dove si pu√≤ andare per trovarla, (che il browser riesce ad andare a questa locazione, ma pu√≤ essere cambiato dal gestore della risorsa, e quindi pu√≤ essere spostato e mai pi√π trovato!), a volte non piace molto questa cosa, e quindi si cerca di creare un URL permanente. Che di solito o √® fatto per redirezione quando si sposta o Ho un sistema di virtualizzazione di uri fisici (in qui veramente c‚Äô√® la risorsa e virtuali (quelli in interfaccia su cui faccio la richiesta).\nURN √® una etichetta permanente di una risorsa, √® PERMANENTE ma ha bisogno di una risoluzione per la sua locazione, per risolvere il problema della locazione nel caso venisse spostata.\nSolitamente per√≤ nell\u0026rsquo;internet di ora √® difficile trovare questa suddivisione.\nGli URI potremmo definirli come l\u0026rsquo;intersezione fra le due, sia un modo per identificare la locazione (quindi andare ad accederci) sia un modo per etichettarli in modo definitivo (in questo modo sono degli URN).\nCaratteristiche URI sono un sistema sintattico (focus sul fatto che siano puramente sintattici!!!, non descrivono la semantica (cosa fare per accedere, ma comunicano il protocollo usato per accedere)che possiamo vederlo anche come sistema di 7 livello OSI utilizzato per identificare la risorsa √® importante quindi che\nTrascrivibili, ossia hanno caratteri limitati, e tutti leggibili da umani. Identificazione, non interazione, avendo solo l‚ÄôURI non posso fare operazioni sulla risorsa. Gerarchizzazione dei nomi url ha una certa struttura (come i caratteri speciali nell‚ÄôURL), in questo senso esiste una certa gerarchizzazione dei nomi! (simile a quanto faccia il filesystem). Struttura dell‚ÄôURI 5 üü© URI = schema : [// authority] path [? query][# fragment]\nPer favorire la trascrivibilit√† ci sono certi caratteri scpeciali tenuti apparte (e se servono sono encodati). curi si parla di caratteri per URI.\ncuri = unreserved | reserved | escaped Per sapere i caratteri encodati, sarebbe bene tenersi a mente le slides, o comunque la grammatica diciamo!\nURI resolution and dereference Un uri pu√≤ essere assoluto oppure una URI reference. Se √® assoluto allora deve soddisfare tutta la struttura di cui sopra, oppure semplicemente dire il nome del file a seconda di una certa base.\nIn questo caso si parla di URI Reference perch√© √® relativo a un certo dato. resolution: Quando do in input un URI reference e in output mi aspetto una URI completa Dereferencing: quando do in input un URI completo e mi aspetto indietro una risorsa.\nAlcune regole di URI resolution Routing Tipologie di routing (2) Managed Route Questo √® la forma di gestione degli URI pi√π nuova, in pratica il mapping di gestione delle risorse √® fatto a livello server. (quindi e.g. in Express posso dire a un certo URL quale risorsa interna corrisponde).\nFile-system route Questo √® il modo pi√π facile diciamo, praticamente c‚Äô√® corrispondenza fra un percorso all\u0026rsquo;interno del file system all\u0026rsquo;indirizzo URI.\nQuesto ha problemi di security perch√©\nDo informazioni sulla struttura interna del nostro sito Non ho controllo sull\u0026rsquo;accesso dall\u0026rsquo;esterno Non √® molto malleabile se voglio cambiare la struttura URI Rewriting √à un modo di virtualizzare la URI, una risorsa interna (con uri fisico vero, cio√® dove sta fisicamente) con un uri virtuale all‚Äôesterno, questo √® quello che farebbe ad esempio mod_rewrite di apache.\n√à particolarmente comodo perch√© mi permette di essere pi√π sicuro di informazioni nascoste e di gestire meglio il nome delle risorse esposte a seconda di cosa io abbia internamente, praticamente √® un sistema managed route.\nLa differenza con URI alias √® che l‚ÄôURI vero qui √® nascosto, e non √® esposto\nCURIE \\[prefix:curie\\]. Ora che conosciamo meglio l\u0026rsquo;XML introdotto in HTTP e REST possiamo meglio comprendere come i namespace si combinino bene con questo formato di URL.\nAlcuni protocolli (schema URI) Di questi non ci importa sapere esattamente i dettagli della loro sintassi, ma che esistono e sono degli URI per qualche tipologia di risorsa!\nHTTP e HTTPS HTTP √® uno dei protocolli pi√π comuni per il WWW. HTTPS √® la sua forma sicura.\nPer maggiori dettagli riguardo funzionamento del protocollo guardare HTTP e REST\nFile Schema Equivalente ad aprire un file dal browser. Importante osservare che non esiste un server che gira con questo schema\nData Di solito questo √® presente nel payload come messaggio di risposta a qualcosa.\nFTP Slide\nTentativi di internazionalizzazione CDN una rete fortemente distribuita di server commerciali che collaborano tra loro per distribuire in maniera omogenea contenuti di grande successo senza inutili duplicazioni di occupazione e trasmissione di file.\nin pratica questi sono dei server che fanno caching con praticamente la stessa idea che avresti avuto in Memoria! Una zona di computer che praticamente contiene tutte le librerie pi√π utilizzate, che siano di facile accesso, e che quindi velocizzano il tempo per prendere una risorsa di molto! In pratica, rendono l\u0026rsquo;accesso di risorse pi√π veloce.\nX-WWW-URLENCODED Una estensione al formato URI per HTTP, questo credo sia un modo per evitare di mandare dei form-multipart data che si leggono male, ma con questo si dovrebbe leggere meglio. Altri motivi non mi vengono in mente del perch√© sono proprio necessari.\nIRI e IDN IRI √® un International resource identifier che permette di risolvere risorse identificate da nomi non solo in ASCII 7, senza dover utilizzare url-encoding. Esteso a UTF-32! Tutti gli URI attualmente sarebbero propriamente URI, ma non li chiamiamo in questo modo per ragioni pi√π storiche che altro.\nIl problema principale √® che da problemi di aliasing (a cirillica molto simile di a latina, quindi uno potrebbe fare phishing basandosi su questa cosa), questo √® stato permesso da IDN (Internationalized DomainName) che permette di avere nomi di dominio anche non di soli caratteri latini, utilizza UNICODE ???. Questi sono attacchi via omografi.\nLa visione dei software Le cose online dovrebbero essere accessibili anche ai software, non solo agli umani. Questo e importante per i crawling bots credo, cos√¨ riescono a farsi una idea del sito o allo stesso modo queste cose strane‚Ä¶\nPer Berners Lee, che introdusse il Linked Data questo era importante perch√© cos√¨ un dato poteva essere accessibile anche da applicazioni. affermazioni atomiche minimali\nNome, propriet√†, Valore (sono in sta forma, come URI per√≤). Questo √® quello che fa WIkiDATA!!!\nQuesto si collega senza nessun problema all\u0026rsquo;ultima parte trattata nel corso riguardante il Metadati web e web semantico.\nIn cui si vanno a parlare di RDF e simili. (immagine di un web accessibile tanto ai bot quanto agli umani, perch√© i dati sono tutti tanto strutturati).\n","permalink":"https://flecart.github.io/notes/uniform-resource-identifier/","summary":"\u003ch1 id=\"uri\"\u003eURI\u003c/h1\u003e\n\u003cp\u003eSono stata LA vera invenzione di Berners Lee accennati in \u003ca href=\"/notes/storia-del-web/\"\u003eStoria del web\u003c/a\u003e. Il problema √® avere un modo per identificare una risorsa in modo univoco sull‚Äôinternet.\u003c/p\u003e\n\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003ch3 id=\"la-risorsa-\"\u003eLa risorsa üü©\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eUna risorsa √® qualunque struttura che sia oggetto di scambio tra\napplicazioni all‚Äôinterno del World Wide Web.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eOra una risorsa pu√≤ essere qualunque cosa, non solamente solo un file! Quindi √® agnostico rispetto a contenuto oppure metodo di memorizzazione del dato, appare anche in questo ambiente importante vedere quanto siano importanti standard che permettano una comunicazione\u003c/p\u003e","title":"Uniform Resource Identifier"},{"content":"The user authentication is one of the most important parts for computer security, because every security policy starts with authentication. This authentication should be easy to use, if not users will not use this. So this should be a good compromise.\nParts of authentication security security:\nRegistration Authentication check Recovery These three are the main parts of security. Some challenges in user authentication Intermediate principals A part that we will not cover are the intermediate principals which attach the mean of transmission or intermediate devices used in the transmission. E.g. a key-logger in the client system is enough to compromise the security of the authentication.\nUser identity Another problem is the user identity, how to be sure that we are talking with a specific person? With just a password authentication is often quite difficult to have this property. Some websites don\u0026rsquo;t need to know a lot about user identity, for example Amazon just needs to know your credit card, not about yourself. While others, like institutions, need to know that you are a student, so they need to know something more about you.\nPassword based authentication Why use password based? Password authentication is one of the most used. Why is that? It is user friendly, and usually convenient. The problem is that they are often easy to steal or to guess, offering no user identity verification, this is usually a problem. Most of the password on the internet are easy to guess and common names: Defense strategies So how can we defend ourselves against these attacks?\nUse the password in few places as possible Use single password for a single session (so change password). Use a password manager for these! Rate limit use. augment with second factor authentication. Rainbow attacks Usually password are stored with hashes like sha256 on the system. Another thing is that they use a slow hash function, because this would make the attacker very hard to calculate everything (and less side channel attacks). For example bcrypt is a slow one.\nRainbow attack is just -\u0026gt; Calculate hash of many common words -\u0026gt; Compare this hash to the value found in the db.\nFor this reason we hash with salt See Sicurezza OS#Autenticazione, that is random prefix or postfix saved in clear in the database to hash the password with. Would make rainbow attack much much harder.\nTwo factor authentication How 2FA helps? Weak passwords are not a problem anymore with 2FA, given if the second method is strong enough. Phishing attacks are not more useful, provided if the the attacker can\u0026rsquo;t break the second method. Implementation methods Just send a SMS with a second code, that could be used within a limited time. Time-based OTP for example the authenticator app, gives every moment some passwords, usually calculated as $H(\\text{ secret } \\mid \\text{ time })$ concatenated in this way. This is quite bad in the case the server gets compromised (change every single secret) Another downside is that it needs to be reinstalled on different phones if it is changed. Physical authentication with USB sticks. These are keys that contain the password or some other codes used to authenticate. ","permalink":"https://flecart.github.io/notes/user-authentication/","summary":"\u003cp\u003eThe user authentication is one of the most important parts for computer security, because \u003cem\u003eevery security policy\u003c/em\u003e starts with authentication.\nThis authentication should be \u003cstrong\u003eeasy to use\u003c/strong\u003e, if not users will not use this. So this should be a good compromise.\u003c/p\u003e\n\u003cp\u003eParts of authentication security security:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRegistration\u003c/li\u003e\n\u003cli\u003eAuthentication check\u003c/li\u003e\n\u003cli\u003eRecovery\nThese three are the main parts of security.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"some-challenges-in-user-authentication\"\u003eSome challenges in user authentication\u003c/h3\u003e\n\u003ch4 id=\"intermediate-principals\"\u003eIntermediate principals\u003c/h4\u003e\n\u003cp\u003eA part that we will not cover are the \u003cem\u003eintermediate principals\u003c/em\u003e which attach the mean of transmission or intermediate devices used in the transmission. E.g. a key-logger in the client system is enough to compromise the security of the authentication.\u003c/p\u003e","title":"User authentication"},{"content":"Espressioni, Comandi, Ricorsione Espressioni Con espressione intendiamo una entit√† sintattica, che una volta valutata ritorner√† un valore, oppure non termina, in questo caso si dice che la espressione √® INDEFINITA.\nQuesta √® una definizione √® leggermente ambigua dato che non abbiamo una definizione precisa di valutazoine, che √® fortemente dipendente dalla macchina astratta in cui viene eseguito.\nNotazioni (sintassi possibili) (3) üü© Notazione infissa\nQuesta √® la notazione classica matematica, per cose tipo $a -b$, in cui l\u0026rsquo;operando sta nel mezzo degli operatori.\nAbbiamo il vantaggio di famigliarit√† e semplicit√† della istruzione, ma perdiamo con ambiguit√† di precendenza degli operatori e associativit√† degli operatori, cio√® non sempre sappiamo se una espressione ha precedenza con l‚Äôaltra, per esempio una espressione del tipo x == y and y == 1d in un certo linguaggio and ha una precedenza, e quindi farebbe perdere di senso all\u0026rsquo;espressione.\nProblemi di precedenza abbiamo per cose come $1 - 1 -1$, che a seconda se facciamo prima il primo - o il secondo meno possiamo avere dei risultati differenti.\nQuindi se utilizziamo una notazione infissa, guadagniamo di semplicit√† e famigliarit√†, e perdiamo in complessit√† della valutazione, che per essere eseguita vorremmo creare un albero di valutazione, che spesso si deriva dall\u0026rsquo;albero di derivazione dopo il parser.\nNotazione prefissa (polacca)\nSono scritture come questo: $+ \\, a\\,b$, in qui scriviamo prima il + e poi gli operandi.\n√à una cosa molto comoda perch√© non abbiamo la necessit√† di specificare precedenze n√© parentesi, ma basta sapere l\u0026rsquo;ariet√† del nostro operatore per poter valutare l\u0026rsquo;espressione.\nNotazione postfissa (polacca inversa)\nQuesta √® uguale alla precedente, ma al contrario, quindi abbiamo cose come $a\\, b\\,+$, √® anche pi√π semplice da valutare, ma in generale molto semplice.\nPrefissa matematica e di cambridge\ncome f(a, b), oppure (f a b) per cambridge\nInterpretazione dell‚Äôalbero\nSi potrebbe interpretare la notazione infissa, prefissa o postfissa come una visita dell‚Äôalbero di valutazione.\nsimmetrica = visita infissa prefissa = visita prefissa (anticipata) (provo a valutare l‚Äôoperatore e poi vado gi√π) Postfissa = visita postfissa (valuta dopo aver eseguito sinistra e destra) Semantica üü© Con la semantica andiamo ad indicare il processo di valutazione di una espressione. Abbiamo detto prima che per la notazione infissa √® pi√π complicata, infatti dovremmo andare a creare un albero di valutazione, creato dall\u0026rsquo;albero di derivazione (che quando compiliamo col parser √® facile da creare dalle foglie).\nInvece se proviamo a valutare con la notazione prefissa, questa √® una cosa molto pi√π semplice, perch√© basta una singola scansione che va con questo algoritmo:\nSe √® un operatore inizializzo un counter e torno a leggere Se vedo un operando pusho in pila e decremento il counter. Se counter √® 0 faccio l\u0026rsquo;operazione e metto in stack, se √® diverso da 0 torno a leggere Se √® postfissa allora √® ancora pi√π semplice, se ho un operando pusho in pila, se ho un operatore prelevo quanto mi serve ed eseguo e pusho in pila il risultato.\nOrdine di valutazione delle sottoespressioni (4) üü©‚Äî Matematicamente parlando non sarebbe molto importante andare a considerare l‚Äôordine di valutazione, per√≤ in questo caso diventa molto importante perch√© l‚Äôordine stesso potrebbe incidere sul risultato dell\u0026rsquo;espressione, un esempio √® quando una espressione implica un side effect.\nSide effect (come potrebbe essere la chiamata di una funzione con side effect mentre valutiamo l\u0026rsquo;espressione!)\nPossibilit√† di overfow per aritmetica finita eg. (INT_MAX - 10 + 5) vs (INT_MAX + 5 - 10)\nCorto circuito e operatori non definiti.\nPer esempio una scrittura del tipo (p ‚â† NULL) \u0026amp;\u0026amp; (p.next == 1)sarebbe un errore in pascal, perch√© fa una esecuzione eager, cio√® valuta tutto prima di valutare qualcosa, mentre in C se √® null torno subito, questo si dice corto circuito perch√© non vado a valutare tutto. Efficienza, l\u0026rsquo;ordine di valutazione pu√≤ anche cambiare l‚Äôefficienza dell‚Äôesecuzione, ad esempio inizializzando un accesso in memoria, e poi andare a fare altre operazioni che non avevano bisogno di accesso. Perch√© nell‚Äôesempio di sotto √® probabile che aa non sia ancora disponibile, quindi conveniva fare cd prima di andare sull‚Äôaltro, che deve attendere.\nEsempio a= vettore[i]; b = a*a + c*d In questa sede quindi √® importante fare differenza fra\nComandi Definizione di comandi üü© Per comando intendiamo una entit√† sintattica che quando valutata non necessariamente ritorna un valore, inoltre potrebbe fare un effetto collaterale. (NOTA: anche le espressioni possono avere effetto collaterale)\nDa questa definizione non sembra ci sia una differenza chiara con l‚Äôespressione. per√≤ concettualmente dovremmo tenerci in mente che un comando √® qualcosa di utile per cambiare lo stato del programma, ossia alla fine del comando ho uno stato differente, quindi ho avuto un side effect, mentre una espressione √® qualcosa che idealmente non dovrebbe avere side-effect, ma alla fine ritorna sempre un valore.\nUn esempio di side-effect del comando pu√≤ essere la stampa a schermo, che avr√≤ cambiato la zona memory mapped come descritto in Note sull‚Äôarchitettura.\nStato computazione = valore di tutte le variabili nel programma in un certo momento (oppure memoria, boh), va a modificare questo l¬¥effetto collaterale.\nVariabili (2) üü© √à importante tenere a mente che le variabili sono diverse rispetto a quelle definite in matematica, l√¨ sono incognite che possono assumere valori in un certo insieme che non sono modificabili.\nInvece in informatica per le variabili abbiamo due modi principale di interpretazione, una reference model e l\u0026rsquo;altra come variabili modificabili\nIl primo modo intende la variabile come una reference a una zona di memoria in cui veramente √® presente il dato che ho, quindi come se fosse un puntatore (senza possibilit√† di modifica) (solitamente messo nella heap). Quindi la variabile denota il riferimento, alla variabile, non il contenitore al valore.\nIl secondo modo intende le variabili proprio per il valore che possiedono, quindi come contenitore o locazione di memoria che contiene qualcosa che pu√≤ cambiare nel tempo. Sembra molto simile, ma nel secondo modo vado a riferirmi al valore, che √® proprio in quella zona, mentre nel primo caso √® un puntatore ad una altra zona.\nAltri modelli\nSlide altri modelli di variabile\nNei linguaggi funzionali, come le variabili matematiche, che una volta assegnata non √® pi√π modificabile un valore. O modificabili in un certo senso nei linguaggi logici.\nAssegnamento üü© Solitamente l\u0026rsquo;assegnamento ha una forma exp1 assignmentOp exp2a ed √® importante andare a distinguere l-value e r-value.\nl-value √® l\u0026rsquo;indirizzo di memoria (quindi denota una locazione) in cui si dovr√† andare a scrivere la r-value, che solitamente pu√≤ essere la locazione se utilizzo la reference model (e quindi in pratica sposto il pointer in questo modello), o proprio una copia del valore se utilizzo l‚Äôaltra interpretazione, quella delle variabili modificabili, in questo caso indica (un valore che pu√≤ essere contenuto)\nSolitamente questa istruzione produce un side effect (quindi si pu√≤ notare che il side effect sia un necessario), dato che il valore della variabile √® stato modificato, e solitamente non ritiorna nessun valore (tranne in C che ritorna sempre una variabile, perch√© credo che l‚Äôassegnamento √® visto come se fosse una espressione).\nIMPLICAZIONI IMPORTANTI PER SIDE EFFECT.\n√à importante tenere a mente la possibilit√† di side effect, perch√© se provo a fare una cosa come a[f(x)] = a[f(x)] + 1 Questo potrebbe dare risultati differenti a seconda del fatto che io abbia side effect o meno. Sarebbe meglio fare cose come j = f(x); a[j] = a[j] + 1\nGli operatori come += e quelli della stessa famiglia sono utili a ovviare a questo side effect dovuto all‚Äôesempio di prima, ecco una loro utilit√† üòÄ, non √® solo un modo compatto lel.\nControllo della sequenza Ambiente e memoria (3) (ni) üü®‚Äî Slide ambiente e memoria\nSolitamente una associazione del tipo f: nome -\u0026gt; Valore Non √® sufficiente perch√© non posso esprimere che un assegnamento per reference cambi i valori per entrambi (secondo questo modello dovrebbe cambiarlo solo per il singolo nome!).\nSolitamente andiamo a definire 3 modelli di valore:\nValori denotabili da variabili Valori memorizzabili in locazioni di memoria Valori esprimibili come risultati di espressione. All\u0026rsquo;interno del nostro linguaggio imperativo imperativo abbiamo bisogno delle prime due, mentre in un linugaggio funzionale solamente il primo che associa valori a variabili.\nInfatti per utilizzare l-value vogliamo andare a modificare il valore associato alla variabile. mentre per accedere al r-value dobbiamo andare a prendere il contenitore, quindi dovremmo prima accedere alla locazione, e poi dalla locazione andare a riprenderci il valore.\nPoi il fatto che la l-value cambi anche il valore in memoria √® una altra cosa credo‚Ä¶ Non lo ho capito dovrei chiederlo. Questa parte non ha molto senso, e non √® importante posso saltare per√≤ tenere a mente che esistono quelle 3 cose.\nComandi sequenziali üü© Sono comandi come\n; Ossia il singolo comando sequenziali begin ... end Che sono i comandi a blocchi anche indicati con {} in C goto Che √® ora in disuso ma in passato era molto importante. Il goto ha avuto una fortissima discussione negli anni 1970 con Dijkstra. Si basava sull\u0026rsquo;idea di assembly e labels che permettevano di fare salti a piacere.\nIl goto ha la stessa espressivit√† di un programma senza di esso (th di B√∂hn Jacopini) Il goto rende il codice difficilmente leggibile, quindi non permette la facile manutenzione. (si pensi a un goto per uscire da un loop 100 righe dopo, non √® pi√π strutturata la lettura diciamo). Come posso interpretare il fatto di goto che salta all\u0026rsquo;interno di un blocco? Come gestire RdA?? Sarebbe buono utilizzarlo come break e continue, ma ci sono gi√† quei comandi‚Ä¶ Produce spaghetti code (che crea proprio un grafo a forma di spaghetti se seguiamo il flusso di controllo del programma) Viola il concetto della programmazione strutturata, di cui tratteremo in software engineering l\u0026rsquo;anno prossimo. Slides programmazione strutturata\nCondizionali (2) üü© if Bexp then Cl e1se C2 Semmai potremmo dire che ci siano qualche ambiguit√† quando ho qualche if annidato senza delimitatori. Per la valutazione di questi if √® importante tenere a mente che esiste il short-circuit per rendere pi√π efficiente la cosa.\nCase la cosa bella √® che ho un jumping table, quindi rende tutte le operazioni di controllo e salto leggermente pi√π efficienti.\nVelocit√† per la jumping table (faccio solo 2 salti, invece in if-then else √® lineare nel numero di if annidati). Chiarezza del costrutto. Slide case\nEsempio di Jumping table\nIterativi (2) üü© I comandi iterativi sono necessari per la turing completezza del linguaggio\nIterazione indeterminata\nSono comandi come while o repeat ... until oppure il do while. Ed √® indeterminata perch√© prima dell\u0026rsquo;esecuzione non so esattamente quante iterazioni andr√≤ a fare. dal punto della macchina fisica √® molto facile implementarlo, dato che basta un salto con un check, pi√π facile da implementare di un for.\nCon, if, ass, while ho gi√† un linguaggio turning completo! Esattamente come √® descritto in Fondamenti teorica.\nIterazione determinata\nQueste sono tutte le iterazioni in cui conosciamo a priori il numero di iterazioni da compiere (a runtime, prima di cominciare l\u0026rsquo;esecuzione del comando), per esempio for e foreach . Di solito credo che nell\u0026rsquo;implementazione si pu√≤ calcolare il numero di iterazioni\nSi pu√≤ osservare che la iterazione determinata sia meno espressiva dell‚Äôiterazione indeterminata, per√≤ da un punto di vista pragmatico √® molto utile perch√© mi compatta tutta la struttura che esisteva per l‚Äôiterazione indeterminata.\nMeno espressiva perch√© non posso computare programmi come\n$$ f(x) = \\begin{cases} x \\text{ se √® pari} \\\\ \\uparrow \\text{ altrimenti }\\end{cases} $$Se ho iterazione determinata non riesco a divergere.\nfor {exp1; expz; exp3) comando √® la sintassi di C, ma nota che qui non √® determinata! perch√© posso modificare il valore dell‚Äôindice e anche del controllo, quindi in pratica √® equivalente all‚Äôiterazione determinata (posso renderlo indeterminato modificando l‚Äôindice all\u0026rsquo;interno).\nNOTE DI IMPLEMENTAZIONE\n√à importante capire che in questo caso esiste il vincolo di semantica statica, che il fine e il valore del passo non dovrebbero essere modificati (cosa che non vale in C, per questo non √® il for settato bene).\nCome fare ad implementare il passo? Se √® negativo? Proco a costruire il concetto di iteration counter definito come segue:\n$$ ic = \\lfloor \\dfrac{fine - inizio + passo}{passo}\\rfloor $$+passo perch√© il fine √® incluso nella iterazione, per questo aggiungo 1.\nRicorsione Definizioni induttive üü© Una cosa cosa molto interessante √® che se possediamo una funzione da $g: \\N \\times A \\to A$, e abbiamo una funzione $f: \\N \\to A$, e un qualunque valore $a \\in A$, allora posto\n$$ f(0) = a \\\\ f(n + 1) = g(n, f(n)) $$f √® univocamente determinata per tutti i valori del dominio. Basta che g sia una funzione totale.\nCredo che questa definizione della funzione f, sfrutti la struttura dei numeri naturali (la stessa struttura su cui si basa il principio di induzione). Studieremo queste definizioni in maggior dettaglio in informatica teorica.\nIn modo simile una funzione ricorsiva √® simile a questa, √® definita in termini di funzioni precedenti gi√† definite. Nonostante ci√≤ ci possono essere dei casi in cui √® calcolabile, ma si discosta un p√≤ dalle definizioni matematiche.\nCasi in cui ci√≤ si discosta\nSi pu√≤ dimostrare, cosa che non facciamo in questa sede che ricorsione √® equivalente alla iterazione. Nonostante ci√≤ in alcune implementazioni, in particolare l\u0026rsquo;implementazione standard della ricorsione, questo porti a forti inefficienze. Analizzeremo solamente la tail recursion come ottimizzazione possibile.\nTail recursion üü©- Una chiamata di g in f di si dice ‚Äúchiamata in coda‚Äù (o tail call) se f restituisce il valore restituito da g senza ulteriore computazione.\nQuando faccio una chiamata ricorsiva alla fine, prima di ritornare dalla funzione, allora posso ottimizzare tutto il discorso che abbiamo fatto sugli RdA in Nomi e Scope, perch√© non avrei bisogno di allocare un nuovo RdA, mi basta lo spazio attuale!\n√à una cosa molto particolare perch√© con questo riesco a implementare la ricorsione con memoria statica! Un singolo RdA.\nTail recursion si ha quando l‚Äôultima istruzione di ritorno non possiede computazioni aggiuntive, avendo questa propriet√†, la chiamata della funzione pu√≤ essere posta in modo che sovrascriva tutti i parametri, le variabili locali, con l\u0026rsquo;indirizzo di ritorno e il valore di ritorno le stesse della funzione chaiamante.\nIn pratica invece di far crescere continuamente la stack, posso fare in modo di utilizzare lo stesso record scrivendoci i nuovi parametri, un risparmio di memoria non da niente!\n","permalink":"https://flecart.github.io/notes/valutazione-espressioni/","summary":"\u003ch1 id=\"espressioni-comandi-ricorsione\"\u003eEspressioni, Comandi, Ricorsione\u003c/h1\u003e\n\u003ch2 id=\"espressioni\"\u003eEspressioni\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eCon espressione intendiamo una entit√† sintattica, che una volta valutata \u003cstrong\u003eritorner√† un valore\u003c/strong\u003e, oppure non termina, in questo caso si dice che la espressione √® INDEFINITA.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eQuesta √® una definizione √® leggermente ambigua dato che non abbiamo una definizione precisa di valutazoine, che √® fortemente dipendente dalla macchina astratta in cui viene eseguito.\u003c/p\u003e\n\u003ch3 id=\"notazioni-sintassi-possibili-3-\"\u003eNotazioni (sintassi possibili) (3) üü©\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eNotazione infissa\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eQuesta √® la notazione classica matematica, per cose tipo $a -b$, in cui l\u0026rsquo;operando sta nel mezzo degli operatori.\u003c/p\u003e","title":"Valutazione Espressioni"},{"content":"This note will introduce the ideas presented by Vapnik, presented in (Shalev-Shwartz \u0026amp; Ben-David 2014) chapter 6. Briefly this says that infinite-size classes are indeed learnable.\nThis set of note is still a work in progress. But it\u0026rsquo;s very important for statistical learning theory.\nWe have that if $\\lvert \\mathcal{H} \\rvert \u003c \\infty \\implies vc(\\mathcal{H} \\rvert) \\leq \\log_{2} \\lvert \\mathcal{H}$ Example: if $\\mathcal{H}$ is the set of linear classifiers on $\\mathbb{R}^{d}$ then we have that the dimension is $d + 1$.\nif $vc(\\mathcal{H}) \u003c \\infty \\implies E_{m}(\\mathcal{H}) = \\sqrt{ vc(\\mathcal{H} / m) }$ which means every finite hypothesis set is learnable. $m$ is the size of our training set.\nEven if $vc(\\mathcal{H}) = \\infty$ there exists a class $C \u003e 0$ that makes it to be learnable. But I did not understood the details.\nReferences [1] Shalev-Shwartz \u0026amp; Ben-David ‚ÄúUnderstanding Machine Learning: From Theory to Algorithms‚Äù Cambridge University Press 2014\n","permalink":"https://flecart.github.io/notes/vapnik-chervonenkis-dimension/","summary":"\u003cp\u003eThis note will introduce the ideas presented by Vapnik, presented in (Shalev-Shwartz \u0026amp; Ben-David 2014) chapter 6. Briefly this says that infinite-size classes are indeed learnable.\u003c/p\u003e\n\u003cp\u003eThis set of note is still a work in progress. But it\u0026rsquo;s very important for statistical learning theory.\u003c/p\u003e\n\u003cp\u003eWe have that if $\\lvert  \\mathcal{H} \\rvert \u003c \\infty \\implies vc(\\mathcal{H} \\rvert) \\leq \\log_{2} \\lvert \\mathcal{H}$\nExample: if $\\mathcal{H}$ is the set of linear classifiers on $\\mathbb{R}^{d}$ then we have that the dimension is $d + 1$.\u003c/p\u003e","title":"Vapnik-Chervonenkis Dimension"},{"content":"Le variabili aleatorie ci permettono di dire qualcosa sullo spazio di probabilit√† senza andare troppo nei dettagli a considerare singoli eventi e cose simili.\nVariabili aleatorie discrete Con le variabili aleatorie cominciamo ad entrare nel noccio della questione, finalmente possiamo in un certo senso legare l‚Äôoutcome di un evento, alla probabilit√† dell‚Äôevento.\nDefinizione Variabili aleatorie üü© Si definisce variabile aleatoria $X$ una funzione da $\\Omega \\to E$, con $\\Omega$ il nostro spazio campionario, e $E$ qualunque insieme (quando $E = \\mathbb{R}$ si parla di variabile aleatoria reale\nQuindi un esempio classico per il dado, potremmo definire una variabile aleatoria dallo spazio campionario $\\Omega = [1, 2, 3, 4, 5, 6]$ ai reali, tali che $X(1) = 1, X(2) = 2$ etc, in questo senso stiamo facendo una funzione fra abitanti di insiemi diversi, ma resta una funzione.\nSpesso variabili aleatorie rappresentano un qualcosa che dipende dall‚Äôesito, questo valore pu√≤ essere numerico come in questo caso (noi in questo corso resteremo al numerico), ma non √® necessario che lo sia.\nvariabili aleatorie pi√π interessanti per esempio il numero di lanci medio per avere 6, obboh, hai molte libert√† di creare le funzioni.\nNOTA: solitamente indichiamo il dominio della variabile aleatoria come da uno spazio di probabilit√†, ossia in cui $P$ sia definita. Questa notazione ci risutler√† comodo quando andiamo a parlare di distribuzione di probabilit√† di uno spazio aleatorio.\n(Legge) Distribuzione di probabilit√† üü© Definiamo una funzione $P_X$ in questo modo:\n$$ P_X(A) = P(\\{\\omega \\in \\Omega: X(w) \\in A\\}), A \\subseteq E $$Possiamo dimostrare che questa √® effettivamente una probabilit√† su $E$! Basta dimostrare la sigma additivit√† e il fatto che $P_X(E) = 1$, l\u0026rsquo;ultimo √® ovvio, perch√© per come √® definito X, abbiamo che $\\Omega = \\{\\omega \\in \\Omega: X(w) \\in E\\}$\nIl secondo punto √® leggermente pi√π complicato, ma lascio al lettore.\nInoltre andiamo a definire questo insieme come l‚Äôesito associato\n$$ \\text{Esito associato a una variabile aleatoria X:} \\\\ \\{\\omega \\in \\Omega: X(w) \\in A\\} $$Def: Funzione di ripartizione (CDF) üü© Propriet√† Fn ripartizione discreta (4) üü®- Monot√≤na crescente (tal cred lol) Continua a destra $\\lim_{x \\to -\\infty} F_X(x) = 0$ $\\lim_{x \\to +\\infty} F_X(x) = 1$ Dimostrazione delle propriet√†\nDef: Densit√† discreta La funzione di probabilit√† di massa o anche densit√† discreta ci dice nell‚Äôinsieme di arrivo quanto sia probabile che si abbia quel valore, possiamo rappresentarlo in questo modo:\n$$ p_X(x) = P(\\{w\\in \\Omega: X(w) = x\\}), x\\in E $$Variabili aleatorie discrete Si parla di variabili aleatorie discrete quando il sottoinsieme $S_X \\subseteq E$ degli elementi tali per cui $P_X(S_X) \u003e 0$, √® o finito o numerabile, allora in questi casi se $\\forall y \\in S_X$ definiamo una probabilit√†, abbiamo una probabilit√†!\nTeorema di caratterizzazione delle variabili aleatorie discrete Slide del teorema\nQuesto teorema ci dice una cosa molto stupida sulle variabili aleatorie, una cosa che credo abbiamo gi√† dimostrato in Spazi di probabilita, che in pratica √® la stessa.\nIn pratica ci sta dicendo che tutte le variabili aleatorie discrete possono essere descritte secondo la probabilit√† di massa\nVariabili aleatorie continue Le variabili aleatorie continue ci sono utili quando vogliamo descrivere qualcosa che √® difficilmente discretizzabile, come per esempio l‚Äôemivita di una batteria. Fatto sta che il suo modello ha un sacco di peculiarit√† che lo rendono molto diversa rispetto a una variabile aleatoria normale:\nPropriet√† di VA continua (2) $\\forall x \\in \\R, f_X(x) = 0$ $\\int_{-\\infty}^\\infty f_X(x)dx = 1$ Si pu√≤ poi dimostrare che\n$P(a \\leq x\\leq b) = \\int_a^bf_X(x)dx$ Si noti che non abbiamo pi√π bisogno che $f_X (x) \\leq 1 \\forall x \\in \\R$, basta che l\u0026rsquo;integrale di tutto sia 1\nPer la propreit√† 1 abbiamo questo fatto:\nla probabilit√† che una variabile aleatoria continua X assuma valori in un intervallo non dipende dal fatto che gli estremi dell‚Äôintervallo siano inclusi o esclusi,\nNon univocit√† della densit√† la funzione f_X definita in precedenza sarebbe la funzione di densit√† continua della nostra probabilit√†. Fatto sta che cos√¨ definita se cambiamo la nostra funzione in un numero finito oppure infinto numerabile di punti, allora l\u0026rsquo;integrale possiede ancora lo stesso valore, quindi √® una densit√† valida (basta provare a spezzare la somma dell\u0026rsquo;integrale per tutti i punti in cui si √® cambiato e si pu√≤ verificare questo dato).\n","permalink":"https://flecart.github.io/notes/variabili-aleatorie/","summary":"\u003cp\u003eLe variabili aleatorie ci permettono di dire qualcosa sullo spazio di probabilit√† senza andare troppo nei dettagli a considerare singoli eventi e cose simili.\u003c/p\u003e\n\u003ch2 id=\"variabili-aleatorie-discrete\"\u003eVariabili aleatorie discrete\u003c/h2\u003e\n\u003cp\u003eCon le variabili aleatorie cominciamo ad entrare nel noccio della questione, finalmente possiamo in un certo senso legare l‚Äôoutcome di un evento, alla probabilit√† dell‚Äôevento.\u003c/p\u003e\n\u003ch3 id=\"definizione-variabili-aleatorie-\"\u003eDefinizione Variabili aleatorie üü©\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eSi definisce variabile aleatoria $X$ una funzione da $\\Omega \\to E$, con $\\Omega$ il nostro spazio campionario, e $E$ qualunque insieme (quando $E = \\mathbb{R}$ si parla di \u003cstrong\u003evariabile aleatoria reale\u003c/strong\u003e\u003c/p\u003e","title":"Variabili aleatorie"},{"content":"$$ p(\\theta \\mid x_{1:n}, y_{1:n}) = \\frac{1}{z} p(y_{1:n} \\mid \\theta, x_{1:n}) p(\\theta \\mid x_{1:n}) \\approx q(\\theta \\mid \\lambda) $$For Bayesian Linear Regression we had high dimensional Gaussians which made the inference closed form, in general this is not true, so we need some kinds of approximation.\nLaplace approximation Introduction to the Idea üü© $$ \\psi(\\theta) \\approx \\hat{\\psi}(\\theta) = \\psi(\\hat{\\theta}) + (\\theta-\\hat{\\theta} ) ^{T} \\nabla \\psi(\\hat{\\theta}) + \\frac{1}{2} (\\theta-\\hat{\\theta} ) ^{T} H_{\\psi}(\\hat{\\theta})(\\theta-\\hat{\\theta} ) = \\psi(\\hat{\\theta}) + \\frac{1}{2} (\\theta-\\hat{\\theta} ) ^{T} H_{\\psi}(\\hat{\\theta})(\\theta-\\hat{\\theta} ) $$ We simplified the term on the first order because we are considering the mode, so the gradient should be zero for the stationary point.\n$$ \\hat{\\psi}(\\theta) =\\log \\mathcal{N}(\\theta; \\hat{\\theta}, -H_{\\psi}^{-1}) + const $$ Then we choose $q(\\theta)= \\mathcal{N}(\\theta; \\hat{\\theta}, -H_{\\psi}^{-1}) \\propto \\exp(\\hat{\\psi}(\\theta))$ One can verify that the hessian in the covariance matrix is indeed symmetric semidefinite positive. (the positive definiteveness comes from the minus of a negative semidefinite matrix of the maximum point). Normally, the covariance matrix of the Laplace approximation is indicated as $\\Lambda = - H^{-1}_{\\psi}$.\nLaplace approximation for a Gaussian üü© We can easily see that the Laplace approximation for a Gaussian is the same as the Gaussian itself, because the Hessian is the inverse of the covariance matrix.\n$$ D_{\\theta}D_{\\theta}\\log p(\\theta) = (D_{\\theta}(\\Sigma^{-1}\\mu - \\Sigma^{-1} \\theta))^{T} = -\\Sigma^{-1} $$An analysis of Bayesian Logistic regression Setting $$ p(y_{1:n} \\mid w, x_{1:n}) = \\prod_{i = 1}^{N} \\sigma(y_{i}w^{T}x_{i}) $$ And that $p(w) = \\mathcal{N}(w; 0, \\sigma^{2}_{p}I)$, where $\\sigma$ is the Sigmoid function $\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$.\n$$ p(y_{i} \\mid w, x_{1:n}) = \\begin{cases} \\sigma(w^{T}x) \u0026 \\text{ if } y = 1 \\\\ 1 - \\sigma(w^{T}x) \u0026 \\text{ if } y = 0 \\end{cases} \\implies \\sigma(y_{i}w^{T}x) $$ Thanks to the properties of the Sigmoid function $1 - \\sigma(x) = \\sigma(-x)$\nMAP Weight update We then see that in order to have the proxy distribution for $w$ we need to find the Hessian of that We have that (we omit $x$ for brevity). $$ \\hat{w} = \\arg \\max_{w} p(w \\mid y_{1:n}) = \\arg \\max_{w} \\log p(w) + \\log p(y_{1:n} \\mid w) = \\arg \\max_{w} \\frac{1}{2\\sigma^{2}{p}} w^{T}w + \\sum{i = 1}^{N} \\log \\sigma(y_{i}w^{T}x_{i})\n$$ Continuing:\n$$ = \\arg \\min_{w} - \\frac{1}{2\\sigma^{2}_{p}}w^{T}w + \\sum_{i = 1}^{N} \\underbrace{ \\log(1 + \\exp(- y_{i}w^{T}x_{i})) }_{\\log p(y_{i} \\mid w)} \\implies \\frac{ \\partial \\log p(y_{1:n} \\mid w) }{ \\partial w } = -\\sum_{i = 1}^{N}y_{i}x_{i} \\sigma( - y_{i}w^{T}x_{i}) $$$$ w \\leftarrow w(1 - 2c\\eta) + \\eta yx\\sigma(-y_{i}w^{T}x_{i}) $$Laplace approximation for Bayesian logistic regression üü®+ $$ \\Lambda = -\\nabla_{w} \\nabla_{w} \\log p(w \\mid y_{1:n} x_{1:n}) = X^{T}\\text{diag}_{i \\in [n]} \\left\\{ \\pi_{i} (1 - \\pi_{i}) \\right\\} X + \\sigma^{-2}_{p} I $$ With $\\pi_{i} = \\sigma(w^{T}x_{i})$. There is a nice interpretation of this covariance matrix, because if the data point is certain then the diagonal value is small, else it is a little bit larger.\nDownsides of Laplace approximation üü© Laplace could be overconfident, in the same way linear regression is for some samples. This is because it greedily approximates basing on the mean of it. So perhaps one direction is ok, other directions can be quite bad.\nPrediction with Variational Posterior üü•++ $$ p(y^{*} \\mid x^{*}, x_{1:n}, y_{1:n}) = \\int p(y^{*} \\mid x^{*}, \\theta) p(\\theta \\mid x_{1:n} y_{1:n}) \\, d\\theta \\approx \\int p(y^{*} \\mid x^{*}, \\theta) q_{\\lambda}(\\theta) \\, d\\theta = \\mathbb{E}_{\\theta \\sim q_{\\lambda}} [p(y^{*} \\mid x^{*}, \\theta)] $$$$ \\mathbb{E}_{\\theta \\sim q} [p(y^{*} \\mid x^{*}, \\theta)] \\approx \\frac{1}{m} \\sum_{j = 1}^{m} p(y^{*} \\mid x^{*}, \\theta) $$$$ \\int p(y^{*} \\mid x^{*}, \\theta) q(\\theta) \\, d\\theta= \\int \\sigma (y^{*} \\cdot \\theta^{T}x)q(\\theta) \\, d\\theta = \\int \\sigma (y^{*} \\cdot f)(x^{*}q(\\theta)) \\, df = \\int \\sigma(y^{*} f) \\mathcal{N}(f; x^{*T}\\mu, x^{*T}\\Sigma x^{*}) \\, df $$ As this is just a single dimensional integral, it could be well approximated with numerical methods like Gauss-Legendre quadrature.\nThe variational approach With this approach we define a family of distributions $Q$ called variational family and the try to find the best member within this family to approximate our $P$.\nFor example we can define the variational family of Gaussians as\n$$ \\mathcal{Q} = \\left\\{ q(\\theta \\mid \\lambda) = \\mathcal{N}(\\theta; \\mu, \\Sigma \\right\\} $$ Where the parameters $\\lambda$ are the mean and the covariance matrix of the Gaussian.\nReverse and Forward KL üü© So we optimize for this: Reverse KL:\n$$ q^{*} \\in \\arg \\min_{q \\in Q} KL(q \\mid \\mid p) $$ $$ q^{*} \\in \\arg \\min_{q \\in Q} KL(p \\mid \\mid q) $$See Kullback-Leibler divergence in Entropy.\nKL of Gaussians üü© Understanding the properties of the KL divergence between Gaussian distributions is crucial for grasping variational inference. I strongly encourage you to review Gaussians#Information Theoretic Properties closely, probably we will use that result in the next observations\nMinimizing Forward KL Divergence We can provide two interpretations of the forward KL divergence. One is a MLE estimation of the dataset in the variational family, the other is a moment matching.\nMLE Estimation We can prove the following: $$ \\begin{align} \\arg\\min_{\\lambda} KL(p \\mid \\mid q) \u0026amp; = \\arg\\min_{\\lambda} H[p \\mid \\mid q_{\\lambda}] - H[p]\\ \u0026amp; = \\arg\\min_{\\lambda} \\mathbb{E}{\\theta \\sim p} [-\\log q{\\lambda}(y)] -\\text{ const} \\ \u0026amp; \\approx \\arg\\min_{\\lambda}- \\frac{1}{m} \\sum_{j = 1}^{m} \\log q_{\\lambda}(y^{(i)})\\ \\end{align}\n$$\nThe problem is that it is often unfeasible.\nThis tells us that any maximum likelihood estimate $q_{\\lambda}$ minimizes the forward KL-divergence to the empirical data distribution.\nThe first interpretation is usually not used as we cannot draw samples using the true distribution.\nMoment Matching We can prove that if we find such $q$ that minimizes the forward KL divergence, then the first two moments of the distribution are the same.\n$$ q(\\theta) = \\exp(\\lambda^{T}T(\\theta) - A(\\lambda)) $$ Where $T(\\theta)$ are the sufficient statistics of the distribution and $A(\\lambda)$ is the log partition function.\n$$ \\begin{align} q^{*} = \\arg\\max_{\\lambda}KL(p \\mid \\mid q) \u0026= \\arg\\max_{\\lambda}\\mathbb{E}_{\\theta \\sim p} \\left[ \\log \\frac{p(\\theta)}{q(\\theta)} \\right] \\\\ \u0026= \\arg\\min_{\\lambda}\\mathbb{E}_{\\theta \\sim p} \\left[\\lambda^{T}T(\\theta) - A(\\lambda) \\right] \\\\ \\end{align} $$ Recall that $A(\\lambda) = \\log \\int \\exp(\\lambda^{T}T(\\theta)) \\, d\\theta$.\n$$ \\begin{align} 0 \u0026= \\nabla_{\\lambda} \\mathbb{E}_{\\theta \\sim p} \\left[\\lambda^{T}T(\\theta) - A(\\lambda) \\right] \\\\ \u0026= \\mathbb{E}_{\\theta \\sim p} \\left[T(\\theta) \\right] - \\nabla_{\\lambda} A(\\lambda) \\\\ \u0026= \\mathbb{E}_{\\theta \\sim p} \\left[T(\\theta) \\right] - \\nabla_{\\lambda} \\log \\int \\exp(\\lambda^{T}T(\\theta)) \\, d\\theta \\\\ \u0026= \\mathbb{E}_{\\theta \\sim p} \\left[T(\\theta) \\right] - \\mathbb{E}_{\\theta \\sim q} \\left[T(\\theta) \\right] \\\\ \u0026\\implies \\mathbb{E}_{\\theta \\sim p} \\left[T(\\theta) \\right] = \\mathbb{E}_{\\theta \\sim q} \\left[T(\\theta) \\right] \\end{align} $$ Which means the expected value of the sufficient statistics of the true distribution are the same as the variational one. For Gaussians, we have that the mean and the covariance matrix are the same as those are the sufficient statistics.\nMinimizing Reverse KL Divergence üü©- We need to compute the value\n$$ \\begin{align}\nq^{}{\\lambda} \u0026amp;= \\arg\\min{q \\in Q} KL(q \\mid \\mid p(\\cdot \\mid y)) \\ \u0026amp;= \\arg\\min_{q \\in Q}\\mathbb{E}{\\theta \\sim q} \\left[ \\frac{\\log q(\\theta)}{\\log p(\\theta \\mid y)} \\right] \\ \u0026amp;= \\arg\\min{q \\in Q} - H(q) - \\mathbb{E}{\\theta \\sim q}[\\log p(\\theta \\mid y)] \\ \u0026amp;= \\arg\\max{q \\in Q} H(q) + \\mathbb{E}{\\theta \\sim q}[\\log p(\\theta \\mid y)] \\ \u0026amp;= \\arg\\max{q \\in Q} H(q) + \\mathbb{E}{\\theta \\sim q}[\\log p(\\theta)] + \\mathbb{E}{\\theta \\sim q} [\\log p (y \\mid \\theta)]+const \\ \u0026amp;\\implies q^{}{\\lambda }= \\arg\\max{q \\in Q} \\mathbb{E}_{\\theta \\sim q} [\\log p(y \\mid \\theta)] - KL(q \\mid \\mid p(\\theta)) = ELBO \\end{align} $$ Where we have now the prior what we were trying to optimize. We can interpret the first part as sort of likelihood while the second part is a proximity measure that acts as a regularizer. This cost function is known as the variational free energy principle (highly put forward by Hinton). This optimizer has also some links with the minimum description length principle, cited in Randomness, Model of Analogies.\nEvidence Lower Bound üü® \u0026ndash; $$ L(q, p; D_{n}) = \\log p(y_{1:n} \\mid x_{1:n}) - KL(q \\mid \\mid p(\\cdot \\mid x_{1:n}, y_{1:n})) \\implies \\log p(y_{1:n}) \\geq L(q, p; D_{n}) $$The evidence is defines a $\\log p(y_{1:n})$. This can be played with to have a lower bound on this value with the above knowledge. We can prove the lower bound in another way, noticing that: $$ \\begin{align} \\log p(y_{1:n}) \u0026amp;= \\log \\int p(y_{1:n} \\mid \\theta) p(\\theta) , d\\theta \\ \u0026amp;= \\log \\int p(y_{1:n} \\mid \\theta) p(\\theta) \\frac{q(\\theta)}{q(\\theta)} , d\\theta \\ \\text{using Jensen}\u0026amp;\\geq{E}{\\theta \\sim q} \\left[ \\log p(y{1:n} \\mid \\theta) \\frac{p(\\theta)}{q(\\theta)} \\right] \\ \u0026amp; ={E}{\\theta \\sim q} \\left[ \\log p(y{1:n} \\mid \\theta) \\right] - KL(q \\mid \\mid p) = ELBO \\\n\\end{align} $$ We observe that this is the same thing that we have seen before while trying to minimize the reverse KL divergence. Thus, finding the best approximation is equivalent to identifying the maximum lower bound on the evidence. Essentially, it involves determining the posterior that is most likely to explain the evidence.\nThis indicates that maximizing the evidence lower bound is an adequate method of model selection which can be used instead of maximizing the evidence (marginal likelihood) directly.\nELBO of logistic regression üü® Suppose we have a classic logistic regression with prior on the weights to be $p(w) = \\mathcal{N}(w; 0, I)$ and the likelihood to be $p(y \\mid w, x) = \\prod_{i = 1}^{N} \\sigma(y_{i}w^{T}x_{i})$. Let\u0026rsquo;s take the parameters from a Gaussian distribution $\\mathcal{N}(\\mu, \\text{diag}_{i \\in [d]}\\left\\{ \\sigma_{i}^{2} \\right\\})$, our variational family. We want now to find the ELBO for this model.\n$$ KL(q \\mid \\mid p) = \\frac{1}{2} \\sum_{i = 1}^{d} \\left( \\sigma_{i}^{2} + \\mu_{i}^{2} - \\log \\sigma_{i}^{2} - 1 \\right) $$$$ \\mathbb{E}_{w \\sim q} \\left[ \\log p(y \\mid w, x) \\right] = \\sum_{i = 1}^{N} \\mathbb{E}_{w \\sim q} \\left[ \\log \\sigma(y_{i}w^{T}x_{i}) \\right] $$ And we can use everything now.\nGradient of ELBO üü©\u0026ndash; One possible approach is using the score function trick, explored in RL Function Approximation. Also called score gradients or monte-carlo gradients. Another is using the so called reparametrization trick. We can compute the gradient of the ELBO with respect to the variational parameters $\\lambda$. But the first parameter is difficult to compute.\n$$ \\mathbb{E}_{\\theta \\sim q} [f(\\theta)] = \\mathbb{E}_{\\varepsilon \\sim \\phi} [f(g(\\varepsilon, \\lambda))] $$ So now we can use a known distribution to sample from and then compute the gradient of the expectation, this allows to compute stochastic gradients. If you know the ideas of Volume, then the formula of change of variables becomes very clean.\nLet\u0026rsquo;s work out an example: Let\u0026rsquo;s suppose $q$ follows a Gaussian distribution $\\mathcal{N}(\\mu, \\Sigma)$ then we can reparametrize it with $\\theta = \\mu + \\Sigma^{1/2} \\varepsilon$ with $\\varepsilon \\sim \\mathcal{N}(0, I)$ that we can sample from.\n$$ \\begin{align} \\\\ \\nabla_{\\lambda} L(\\lambda) = \\nabla_{\\lambda} \\mathbb{E}_{\\theta \\sim q} [ \\log p(y \\mid x, \\theta) ] - KL(q \\mid \\mid p) = \\\\ \\nabla_{\\lambda} \\mathbb{E}_{\\varepsilon \\sim \\phi} [ \\log p(y \\mid x, \\Sigma^{1/2}\\varepsilon + \\mu ) ] - KL(q \\mid \\mid p) = \\\\ \\end{align} $$$$ \\begin{align} \\nabla_{\\lambda} \\mathbb{E}_{\\theta \\sim q} [ \\log p(y_{1:n} \\mid x_{1:n}, \\theta) ] \u0026= \\nabla_{\\lambda} \\mathbb{E}_{\\varepsilon \\sim \\mathcal{N}(0, 1)} [ \\log p(y_{1:n} \\mid x_{1:n}, \\Sigma^{1/2}\\varepsilon + \\mu ) ] \\\\ \u0026 = n \\mathbb{E}_{\\varepsilon \\sim \\mathcal{N}(0, 1)} \\mathbb{E}_{i \\sim \\text{unif}[0, n]}[\\nabla_{\\lambda} \\log p(y_{i} \\mid x_{i}, \\Sigma^{1/2}\\varepsilon + \\mu ) ]\\\\ \u0026 \\approx \\frac{n}{m} \\sum_{j = 1}^{m} \\nabla_{C, \\mu} \\log p(y_{i_{j}} \\mid x_{i_{j}}, C\\varepsilon_{j} + \\mu) \\\\ \\end{align} $$ Which means: We can approximate the derivate of the likelihood with respect of the variational parameters by sampling from a normal and uniformly from the dataset and only then computing an average gradient of the likelihood with respect to the parameters.\nVariational inference enables us to find approximations of distributions using highly optimized stochastic optimization techniques. However, a significant drawback is the difficulty in assessing the quality of these approximations.\n","permalink":"https://flecart.github.io/notes/variational-inference/","summary":"$$\np(\\theta \\mid x_{1:n}, y_{1:n}) = \\frac{1}{z} p(y_{1:n} \\mid \\theta, x_{1:n}) p(\\theta \\mid x_{1:n}) \\approx q(\\theta \\mid \\lambda)\n$$\u003cp\u003eFor \u003ca href=\"/notes/bayesian-linear-regression/\"\u003eBayesian Linear Regression\u003c/a\u003e we had high dimensional \u003ca href=\"/notes/gaussians/\"\u003eGaussians\u003c/a\u003e which made the inference \u003cem\u003eclosed form\u003c/em\u003e, in general this is not true, so we need some kinds of approximation.\u003c/p\u003e\n\u003ch2 id=\"laplace-approximation\"\u003eLaplace approximation\u003c/h2\u003e\n\u003ch4 id=\"introduction-to-the-idea-\"\u003eIntroduction to the Idea üü©\u003c/h4\u003e\n$$\n\\psi(\\theta) \\approx \\hat{\\psi}(\\theta) = \\psi(\\hat{\\theta}) + (\\theta-\\hat{\\theta} ) ^{T} \\nabla \\psi(\\hat{\\theta}) + \\frac{1}{2} (\\theta-\\hat{\\theta} ) ^{T} H_{\\psi}(\\hat{\\theta})(\\theta-\\hat{\\theta} ) = \\psi(\\hat{\\theta}) + \\frac{1}{2} (\\theta-\\hat{\\theta} ) ^{T} H_{\\psi}(\\hat{\\theta})(\\theta-\\hat{\\theta} ) \n$$\u003cp\u003e\nWe simplified the term on the first order because we are considering the mode, so the gradient should be zero for the stationary point.\u003c/p\u003e","title":"Variational Inference"},{"content":"Questa √® una necessit√† per stabilire il significato di una sintassi definiti.\n5.1 Verit√† e Realt√† La verit√† ha solamente senso quando lo si relaziona con un mondo sensibile, ossia il mondo che si pu√≤ percepire con i nostri sensi.\n5.1.1 Verit√† parametrica e assoluta Se un esperimento √® ripetibile all\u0026rsquo;interno del mondo sensibili allora questa √® considerata come una verit√† parametrica, ossia dipende da uno stato del mondo sensibile.\nverit√† assoluta come le costanti della fisica.\n5.1.2 Scienze pure e scienze molli La differenza fra queste due √® che le scienze pure non stanno parlando del mondo sensibile, ma crea un mondo a s√©, astratto, in cui ha senso tutto ci√≤ che viene detto riguardo a questo mondo preciso. Anche l\u0026rsquo;informatica √® teorica.\nMa cosa √® la verit√† senza il mondo sensibile? L\u0026rsquo;esempio che abbiamo fatto prima non funziona pi√π.\nLe scienze molli descrivono la realt√† sensibile mentre le scienze pure descrivono un mondo astratto inesistente nella realt√†. (quindi fisica non √® pura, secondo questo).\n5.1.3 Teoria matematica √à come una storia descritta prima: insieme di sentenze,connotazioni.\nEnti primitivi di un mondo Assiomi che valgono in certi mondi üí° Gli assiomi sono come le leggi fisiche di un mondo fantastico: descrivono delle regole che valgono in un mondo preciso, e quindi si possono derivare delle conseguenze e le interazioni fra queste. 5.1.4 Modello matematico Interpretare i concetti primitivi in modo che valgano tutti gli assiomi, questo √® il modello.\nQuindi il modello matematico √® una interpretazione degli enti primiti e edegli assiomi del mondo!\nNon √® definito a priori ma si d√† il senso\nEsempio in classe\nPer esempio il mondo con i numeri colorati, quella relazione resta la stessa, posso colorare come mi pare, allora la prima proposizione della slide sono falsi\nEsempio teoria e modello\n5.2 Il mondo Il mondo √® una descrizione completa delle caratteristiche e regole del mondo (quindi oggetti, leggi e simili). Ovviamente questa √® solamente una descrizione ipotetica in quanto non possiamo conoscere tutto di un mondo (non conosciamo tutto nemmeno nel mondo in cui viviamo).\nUn assioma √® valido solamente in alcuni mondi precisi, spesso ci interessa indagare solamente quei mondi. (√à utile indagare solamente un mondo in cui quel determinato assioma valga o meno.)\nIl concetto di verit√† non ha senso come concetto a s√© stante in quanto dipende dal mondo in cui la proposizione √® valutata\nLe teorie e i modelli matematici hanno senso solamente se interpretati in un mondo particolare. Da soli no. Una proposizione ha un concetto di verit√† solamente se ha poi senso all\u0026rsquo;interno del mondo.\n5.2.1 Conseguenza logica Data una teoria T(un insieme di sentenze) si dice conseguenza logica F di T quando F vale per tutti i modelli di T, ovvero in tutti i mondi in cui valgono le sentenze della teoria.\nDue cose:\nVera per tutti i modelli T Vera in tutti i mondi in cui le ipotesi G1 G2 etc √® vero, ossia tutti gli assiomi sono veri. Miniriassunto\nCon gli assiomi sto filtrando nei mondi in cui questi assiomi siano veri, quindi prendiamo solamente mondi in cui siano veri questi assiomi, con questi assiomi e enti primitivi creiamo un mondo. Allora poi possiamo avere una semantica, un modo di interpretare che √® il modello e da qua possiamo avere proposizioni e conseguenze logiche\nDetto in altri modi\nGli assiomi creano dei sottomondi in cui esse valgono (sto filtrando sui mondi).\nF (un insieme di modelli matematici) √® una conseguenza logica di T se vale in tutti i mondi in cui valgono tutte le ipotesi (assiomi) (sentenze) G1 G2 etc\u0026hellip; di T\nNota: pi√π ipotesi che ho, pi√π sto restringendo nell\u0026rsquo;insieme dei mondi, quindi avr√≤ pi√π conseguenze logiche, quindi diventa una cosa pi√π interessante.\n5.2.2 Equivalenza logica Due sentenze sono dette equivalenti se sono soddisfatte esattamente dagli stessi mondi. (ossia filtrano sugli stessi mondi) (assiomi rindondanti uno con l\u0026rsquo;altro)\nRelazione di equivalenza per equivalenza logica\nConsidera solamente i mondi in cui valgono\nNel secondo caso nella slide ho come ipotesi che entrambi hanno gli stessi mondi cin cui valgono, allora √® ovvio che si ha il contrario\nIn modo simile si ha per il terzo caso\n5.3 Valutazione della teoria Quando √® interessante?\nNon ha senso chiedersi se un assioma √® vero o falso, nemmeno se √® giusto o falso, ha solamente senso chiedersi se √® vero o falso in un mondo preciso. Vale allora la teoria di consistenza\n5.3.1 Inconsistenza di una teoria Una teoria √® inconsistente quando non ammette nessun modello. (ossia non ammette nessuna interpretazione degli enti primitivi in modo che valgano tutti gli assiomi)\nSi pu√≤ anche dire che l\u0026rsquo;assurdo √® conseguenza logica di una teoria inconsistente, quindi √® tutto vero, tutto vero per assurdo!?\nCi sono troppi vincoli, quindi sto parlando di niente (ho un insieme vuoto di modelli e quindi sto parlando del vuoto) (tutto √® conseguenza logica in questo caso)\nQuesto vale anche il contrario, per√≤ non √® dimostrabile in modo semplice anche l\u0026rsquo;altra freccia.\nQuindi se √® falso questo, allora ho almeno un mondo in cui tutto ci√≤ che ho √® vero! Quindi che sia consistente! (e poi la cosa bella sarebbe cercare le applicazioni pratiche di queste cose)\nLa Logica studia la conseguenza logica! Introduzione a Logica\n5.3.2 Interpretazione Si pu√≤ considerare interpretazione una funzione semantica che per ogni connotazione associa una unica denotazione, considerato un oggetto di un mondo preciso. (enti primitivi sono connotazioni di un mondo, considerati connotazioni atomiche).\nLa funzione di interpretazione √® descritta meglio in Logica Proposizionale\nLe connotazioni sono interpretate come denotazioni del mondo.\nPoi ci sono funzioni del mondo e simboli del mondo.\nDi solito le connotazioni composte sono ottenute da connotazioni atomiche (denotazioni del mondo) combinate tramite connettivi logici.\n5.4 Connotazione denotazione In informatica sono sintassi e semantica. Sar√† ci√≤ che mi serve per evitare l\u0026rsquo;uso meta-linguistico, invarianza per sostituzione √® il primo teorema che serve per questo\n5.4.1 Intuizione iniziale In linguistica la connotazione √® il significato psicologico di una parola, mentre la denotazione √® la prima cosa che di solito di d√† il dizionario, ossia cosa √® detto effettivamente.\nIn breve: (‚Üí indica il significato in informatica)\nConnotazione: ci√≤ che voglio comunicare, come voglio cominciare (per la logica i messaggi subliminali non sono utili) ‚Üí Sintassi il modo in cui lo sto dicendo Denotazione cosa √® detto ‚Üí Semantica ci√≤ che voglio dire, anche considerabile come l\u0026rsquo;oggetto che viene considerato in questo mondo. Nel caso dell\u0026rsquo;informatica l\u0026rsquo;uso metalinguistico √® parlare sulle connotazioni\n5.4.2 Teorema Invarianza delle denotazioni Data un qualunque contesto (un buco di una frase) e una connotazione, se sostituita con una altra connotazione, le denotazioni delle frasi restano le stesse allora quelle due connotazioni sono equivalenti.\nPossiamo utilizzare il test di invarianza per vedere se qualcosa √® metalinguistico o meno.\nSe due connotazioni che possiedono la stessa denotazione hanno output diversi per certi contesti allora questo fa uso metalingusitico\nFondamentale per l\u0026rsquo;uso metalinguistico\n5.4.3 Connettivi logici Intro Per maggiore precisione sui connettivi logici guardare Connettivi Logici, correttezza, variabili\nAbbiamo bisogno di tenere certe cose fisse in modo da tenere un ordine generale fra i mondi. Questi sono i connettivi logici che hanno lo stesso senso ovunque.\nPossono essere\nBinari\nUnari\n0-ari\nE poi quantificatori come esiste e per ogni in modo da tenere un ordine generale fra i mondi. Questi sono i connettivi logici che hanno lo stesso senso ovunque.\nPossono essere\nBinari\nUnari\n0-ari\nE poi quantificatori come esiste e per ogni\n","permalink":"https://flecart.github.io/notes/verita-teorie-modelli-connotazione-denotazione/","summary":"\u003cp\u003eQuesta √® una necessit√† per stabilire il significato di una sintassi definiti.\u003c/p\u003e\n\u003ch2 id=\"51-verit√†-e-realt√†\"\u003e5.1 Verit√† e Realt√†\u003c/h2\u003e\n\u003cp\u003eLa verit√† ha solamente senso quando lo si relaziona con un mondo sensibile, ossia il mondo che si pu√≤ percepire con i nostri sensi.\u003c/p\u003e\n\u003ch3 id=\"511-verit√†-parametrica-e-assoluta\"\u003e5.1.1 Verit√† parametrica e assoluta\u003c/h3\u003e\n\u003cp\u003eSe un esperimento √® ripetibile all\u0026rsquo;interno del mondo sensibili allora questa √® considerata come una \u003cstrong\u003everit√† parametrica\u003c/strong\u003e, ossia dipende da uno stato del mondo sensibile.\u003c/p\u003e","title":"Verita, Teorie, modelli, connotazione, denotazione"},{"content":"Introduzione al vettore potenziale Definizione vettore potenziale üü© $$ \\vec{B} = \\vec{\\nabla} \\times \\vec{A} $$ Con un campo vettoriale a caso $\\vec{A}$, vedremo che questo campo avr√† qualche utilit√† per fare i calcoli.\nPossiamo notare che soddisfa la propriet√† dell campo solenoidale citato in Magnetismo, infatti\n$$ \\vec{\\nabla} \\cdot \\vec{B} = \\vec{\\nabla} \\cdot (\\vec{\\nabla} \\times \\vec{A}) = 0 $$ Perch√© sappiamo che la divergenza del rotore (questo operatore dico) √® sempre nullo per ragioni di Cauchy, se ne parla in Divergenza e Circuitazione.\nUnicit√† del campo üü© Proviamo ad analizzarlo matematicamente, ci stiamo chiedendo, √® unica?\nLo √® a meno di un gradiente di una funzione scalare\n$$ \\vec{A}' = \\vec{A} + \\vec{\\nabla}F $$ Abbiamo:\n$$ \\vec{\\nabla} \\times \\vec{A}' = \\vec{\\nabla} \\times \\vec{A} + \\vec{\\nabla} \\times (\\vec{\\nabla}F) = \\vec{\\nabla} \\times \\vec{A} + 0 $$Dove il gradiente di $F$, si ricorda √® vettoriale, ed √® utilizzato per rappresentare un vettore qualunque, basta che esista $F$ che lo generi, che lo abbiamo in ipotesi.\nSimile con il potenziale, che √® una funzione definita a meno di una costante perch√© possiamo mettere un punto (che scegliamo noi) in un certo punto, o potenziale del sistema che sono contati in quella costante, ne parliamo in Campo elettrico. (in questo capo la nostra costante √® un vettore in un certo senso :P)\nScelta del campo A üü© Per la divergenza abbiamo invece:\n$$ \\vec{\\nabla} \\cdot \\vec{A}' = \\vec{\\nabla} \\cdot(\\vec{A} + \\vec{\\nabla}F) = \\vec{\\nabla} \\cdot \\vec{A} + \\nabla^{2}F $$$$ \\vec{\\nabla} \\cdot \\vec{A} = 0 $$ Per qualche motivo questa cosa vale solo nel caso stazionario (con $\\vec{J}$ stabile).\nComodit√† del vettore potenziale Ampere Max-well con vettore potenziale üü© Abbiamo quindi\n$$ \\vec{\\nabla} \\times (\\vec{\\nabla} \\times \\vec{A}) = \\mu_{0}\\vec{J} $$Questa espressione si pu√≤ semplificare tenendo conto che $a\\times b\\times c = b (a \\cdot c) - (a\\cdot b) c$ Da cui abbiamo:\n$$ \\vec{\\nabla} \\cdot (\\vec{\\nabla} \\cdot \\vec{A}) - (\\vec{\\nabla} \\cdot \\vec{\\nabla})\\vec{A} = \\mu_{0}\\vec{J} $$$$ \\nabla^{2}\\vec{A} = -\\mu_{0}\\vec{J} $$ Possiamo notare che $A$ ha la stessa direzione della corrente! seguendo la soluzione dell\u0026rsquo;equazione di Poisson per campo elettrico abbiamo che\n$$ A(x, y, z) = \\frac{\\mu_{0}}{4\\pi} \\int _{\\Sigma} \\frac{J(x', y', z')\\, dx'dy'dz'}{\\sqrt{ (x - x')^{2} + (y - y')^{2} + (z - z') ^{2} }} $$$$ \\vec{A} = \\frac{\\mu_{0}}{4\\pi} \\int \\frac{\\vec{J} d\\Sigma \\, dl}{r} = \\frac{\\mu_{0}}{4\\pi} \\int \\frac{i \\, dl}{r} $$ Quindi quantit√† di corrente lungo un certo tratto di filo!\nFaraday con vettore potenziale üü©\u0026ndash; $$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} = \\frac{\\delta (\\vec{\\nabla} \\times \\vec{A})}{\\delta t} $$E abbiamo:\n$$ \\vec{\\nabla} \\times \\left( \\vec{E} + \\frac{\\delta \\vec{A}}{\\delta t} \\right) = 0 $$ Quindi abbiamo che vale:\n$$ \\vec{E} = -\\frac{\\delta A}{\\delta t} \\implies \\vec{\\nabla}V = \\frac{\\delta A}{\\delta t} $$Circuitazione del vettore potenziale üü© Consideriamo il flusso del vettore su una superficie\n$$ \\int_{\\Sigma} \\vec{B} \\hat{u}_{n} \\, ds = \\int_{\\Sigma} \\vec{\\nabla} \\times \\vec{A} \\hat{u}_{n} \\, ds = \\int_{\\Gamma(\\Sigma)} \\vec{A} \\cdot\\, d\\vec{l} $$ Dove l\u0026rsquo;ultima vale per Stokes in Divergenza e Circuitazione, quindi possiamo calcolare il flusso su un campo andando a considerare la circuitazione del potenziale vettore!\nEsempi di applicazione Studio del vettore potenziale in un solenoide üü© $$ \\vec{A} = B \\frac{r}{2} \\hat{u}_{c} $$$$ \\vec{A} = B \\frac{R^{2}}{2r} \\hat{u} $$","permalink":"https://flecart.github.io/notes/vettore-potenziale/","summary":"\u003ch3 id=\"introduzione-al-vettore-potenziale\"\u003eIntroduzione al vettore potenziale\u003c/h3\u003e\n\u003ch4 id=\"definizione-vettore-potenziale-\"\u003eDefinizione vettore potenziale üü©\u003c/h4\u003e\n$$\n\\vec{B} = \\vec{\\nabla} \\times \\vec{A}\n$$\u003cp\u003e\nCon un campo vettoriale a caso $\\vec{A}$, vedremo che questo campo avr√† qualche utilit√† per fare i calcoli.\u003c/p\u003e\n\u003cp\u003ePossiamo notare che soddisfa la propriet√† dell \u003cstrong\u003ecampo solenoidale\u003c/strong\u003e citato in \u003ca href=\"/notes/magnetismo/\"\u003eMagnetismo\u003c/a\u003e, infatti\u003c/p\u003e\n$$\n\\vec{\\nabla} \\cdot \\vec{B} = \\vec{\\nabla} \\cdot (\\vec{\\nabla} \\times \\vec{A}) = 0\n$$\u003cp\u003e\nPerch√© sappiamo che la divergenza del rotore  (questo operatore dico) √® sempre nullo per ragioni di Cauchy, se ne parla in \u003ca href=\"/notes/divergenza-e-circuitazione/\"\u003eDivergenza e Circuitazione\u003c/a\u003e.\u003c/p\u003e","title":"Vettore potenziale"},{"content":"Introduzione Quando abbiamo una switch, ma vogliamo allo stesso momento andare a creare pi√π LAN, allora abbiamo bisogno delle VLAN. Questi switch che hanno delle VLAN si chiamano managed switches\nQueste vlan sono numerate (ricorda l‚Äôespericomento cn LUCA!).\nIl problema Sono un protocollo livello 2 (Link-Layer, di collegamento), non vorremmo per esempio che un broadcast di una certa rete vada anche in altre reti che non centrino praticamente nulla, come possiamo vedere in figura.\nEsempio problema di vlan\nImplementazione: porte Posso andare a raggruppare alcune porte come se fossero in una unica network separata rispetto al resto. Posso andare a numerare certe porte e proprio andare a taggarli come se sono parte di una altra rete.\nSi noti che per comincare fra VLAN in switches diverse, bisogna che il pacchetto possieda informazioni riguardo la VLAN in modo che quando viene ricevuto venga correttamente interpretato essere nell vlan corretta.\nVantaggi delle VLAN (3) Formato pacchetto VLAN √à una estensione del pacchetto livello MAC classico con informazioni riguardo le vlan\nPreable: sincronizzare chi trasmette e chi riceve Dest e source sono gli stessi classici livello 2, quindi con MAC. Multiprotocol Layer switching MPLS Esempio\nData center networks Load balancers Cerca di equalizzare il carico di lavoro di tutti.\n","permalink":"https://flecart.github.io/notes/vlan/","summary":"\u003ch2 id=\"introduzione\"\u003eIntroduzione\u003c/h2\u003e\n\u003cp\u003eQuando abbiamo una switch, ma vogliamo allo stesso momento andare a creare pi√π LAN, allora abbiamo bisogno delle VLAN. Questi switch che hanno delle VLAN si chiamano \u003cstrong\u003emanaged switches\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eQueste vlan sono numerate (ricorda l‚Äôespericomento cn LUCA!).\u003c/p\u003e\n\u003ch3 id=\"il-problema\"\u003eIl problema\u003c/h3\u003e\n\u003cp\u003eSono un protocollo livello 2 (Link-Layer, di collegamento), non vorremmo per esempio che un broadcast di una certa rete vada anche in altre reti che non centrino praticamente nulla, come possiamo vedere in figura.\u003c/p\u003e","title":"VLAN"},{"content":"Introduction to Wide Column Storages One of the bottlenecks of traditional relational databases is the speed of the Joints, which could be done in $\\mathcal{O}(n)$ using a merge join, assuming some indexes are present which make the keys already sorted. The other solution, of just using Distributed file systems, is also not optimal: they have usually a high latency, with high throughput, that is not optimal with the series of small files that it is optimized for. While Object Storages, do not have APIs that could be helpful -\u0026gt; richer logical model.\nWide Column Storage solve this problem by keeping the entire table already joined -\u0026gt; highly structured data, and providing similar querying abilities compared to relational tables. This brings to highly sparse relational tables.\nThe Usage Wide column stores were invented to provide more control over performance and in particular, in order to achieve high-throughput and low latency for objects ranging from a few bytes to about 10 MB, which are too big and numerous to be efficiently stored as so-called clobs (character large objects) or blobs (binary large objects) in a relational database system, but also too small and numerous to be efficiently accessed in a distributed file system. ~From Chapter 6 of Big Data book\nThe idea here is sharding, trying to spread RDBMS into multiple machines, so that one machine has some tables, others other, one example is the famous cassandra that Discord used to scale their system.\nDesign principles üü®\u0026ndash; Two main principles guide the design of wide column stores:\nWide sparse, joint, data tables, because the joins are the expensive operations Batch processing: Store together what is accessed together. These are the current problems, with wide column stores we should solve all of these problems. This project has originated at Google with Big Table (similarly to Big Query). HBase is an opensource equivalent of the Google projects.\nWith traditional relational database management systems, the joins are the expensive part of the operations. Wide Column Stores solve this problem by storing large sparse tables, as in the image: Basic Characteristics We summarize here some of the defining characteristics for Wide Column Storages:\nSupport up to 10MB for files Sparse data model No Schema enforcement (difference compared to RBDMS) No SQL, but something lower level similar to key-value stores. HBase Logical Model Row Ids and Keys üü© Row ids are just sequences of bits, but unlike RDBMS they are sortable, and is compound of different things, like row, column or version.\nSpecifically a key is composed of\nColumn Family Row Id Column qualifier (name) Version (timestamp associated to a value). Column Families üü© An intution over this new concept is the following: these could be the actual tables that would get stored if the table was normalized. These must be known in advance; it is possible to add a new family but it is an expensive operation. One can also add columns on the fly in the tables, but not column families.\nAlso columns have names (array of bytes, that are repeated a lot in the physical model, so they should be quite short!), not specific types as with RDBMS, those are called column qualifiers. We will see later in the physical level that both families and qualifiers are repeated in every key-value pair, which pushes towards a shorter names.\nOperations üü© They have classical GET, POST, PUT, DELETE operations. The difference with RDBMS is that they also support range queries on the ID or timestamp for the versions, called scans, differently from object stores or key value stores.\nLocks Row updates are atomic, no matter how many row columns constitute the row-level transaction. This keeps the locking model simple.\nFrom the Hadoop guide here.\nPhysical Architecture Image From the textbook. Regions and Stores üü© A region is just a continuous section of the rows. We define the stores which are intersections between a region and a column family. All the cells of a store are stored together. A single region is usually assigned to a RegionServer (see next section). When a region becomes too large, a RegionServer splits this region into two, and then could be rebalanced by the HMaster. The responsibility does not imply storage! This is a very important thing because the actual data is in HDFS. The responsibility is not replicated, because HDFS automatically replicates the underlying data.\nOn a probability point of view, all the files are going to come back to the RegionServer because RegionServers are usually going to delete and recreate files, and HDFS by default stores the first copy on the same machine it is creating it from. The nice thing is that if the hblock is in the same machine, the process can circumvent HDFS and directly read that HDFS block. This was possible because HDFS and Wide column storage has been developed by the same team. So they have nice compatibilities.\nNetwork architecture üü© The network topology is the same as the one we have for Distributed file systems. We have a main node and some slave nodes. In this context they are called HMaster and RegionServers. We also have standby master nodes in this case.\nThe HMaster has a metatable of all the responsibilities of every RegionServer, heartbeat and reports system also here to keep track of this in a old version, before there were also race conditions, see Programmi Concorrenti. Now in order too keep the presence of everybody is something called a zoo-keeper.\nCreating tables, deleting them, creating column families, all the Data Definition operations go through the HMaster. HMaster\u0026rsquo;s job is to load balance the RegionServer\u0026rsquo;s load in terms of quantity of data. If regions grow too big, then it can split or reorganize the regions across the servers.\nHFiles and KeyValues üü® Stores are Memorized as HFiles, organized in HBlocks of fixed size of 64Kb (+ last key key value, so it could be a little larger), usually the key-values are read in the blocks. These blocks are then compacted together (see #Log Structured Trees) until it reaches a maximum size for a region, which is typically 10GB. When the limit is reached, the region is usually divided into two.\nThese files are just list of the cells, stored by coordinate (keys, often in CamelCase) and values (also different versions are stored along side each other)\nA KeyValue in a HFiles is made of 4 parts:\nKey-length Value-length Key Value This is a prefix code, see Algorithmic Probability for something more about prefix codes.\nThe HFile also contains the boundary index of all the blocks that it has. So that it is easy to check for membership inside the blocks\nStructure of Key and Values üü•++ One also has an index, idea similar from b-trees, so the lookup inside a HDFS block is easy.\nThis image from the book cleanly summarizes the structure of the Key: The red part of the key is of variable length. Grey boxes are of fixed length, also column family. The qualifier is variable, but you can recover that by knowing the length of the whole key.\nIn memory key-value store üü©- We store the key values in order in memory using some sort of tree. The upside is that we don\u0026rsquo;t need to cancel and recreate the block in HDFS, because that only allows appending, the written data is not modifiable. When the RAM store is full, then we flush the memory down to an HFile. When we flush we have a linear merge and we store the new file in this way.\nWe have three cases when the flush happens:\nWrite-ahead log is full Memstore size if sull Max memstore for a single store Write-Ahead log üü© This is a log to keep the changes done in the RAM, so that we don\u0026rsquo;t lose things after a crash. Appending is ok in HDFS, so it\u0026rsquo;s quite compatible with the underlying system. -\u0026gt; Every write is first written in this log file before being put in the RAM. This is similar to the EditLog in HDFS.\nLog Structured Trees These structures attempt to optimize for throughput, the B-Trees are optimized for latency. As every id is sorted by key, it\u0026rsquo;s easy to merge the HFiles together, we just need to use the Merge function, the same for MergeSort algorithm.\nCompaction üü© This is a process that merges many HFiles together when you have too many HFiles because of the flushes. The compaction process is still a linear process because the key values stores are linear. Merging two HFiles usually is makes the system faster for reads because we don\u0026rsquo;t need to search anymore for all all the mini files that the system creates after the memstore is full. By default HFiles have a maximum size of 10GB (this is the max size after compactions I suppose). If it gets bigger, then the region might be splitted.\nThis is usually triggered when:\nThe number of files is above a certain threshold. Or it might follow a 2048 game rule by merging HFiles with the same size (this is what the Professor has explained). Optimization of HBase Lookup tables üü®\u0026ndash; In order to know which RegionServer a client should communicate with to receive KeyValues corresponding to a specific region, there is a main, big lookup table that lists all regions of all tables together with the coor dinates of the RegionServer in charge of this region as well as additional metadata.\nSo, just lookup tables that are known by everybody, and this should make communication a little bit faster.\nCache Usages We should not use cache when we have random access or when we are doing batch processing, because the data the batches are processing are usually separate and independent with each other. You should refer to Memoria and Memoria virtuale to know how usually is cache made.\nKey Ranges Efficiently tells for sure that a Key range is not contained in a file.\nSo they are just some small optimizations, which at the end make HBase quite fast.\nBloom Filters üü© It is basically a black box that can tell with absolute certainty that a certain key does not belong to an HFile, while it only predicts with good probability (albeit not certain) that it does belong to it.\nSo that we can skip over files so that we can fasten the lookup time. Without bloom filters we would look for a specific key value in every single HFile, which could be quite slow.\nSee Bloom Filters for an overview on how they work.\nData locality and Short Circuiting üü© We have specified in some paragraphs before that when HBase writes a HFile to a node, the first replica of the file is written on the same node. This allows for short circuiting which allows to directly read from the disk without asking the NameNode for the classical HDFS system.\n","permalink":"https://flecart.github.io/notes/wide-column-storage/","summary":"\u003ch3 id=\"introduction-to-wide-column-storages\"\u003eIntroduction to Wide Column Storages\u003c/h3\u003e\n\u003cp\u003eOne of the bottlenecks of traditional relational databases is the speed of the Joints, which could be done in $\\mathcal{O}(n)$ using a merge join, assuming some indexes are present which make the keys already sorted.\nThe other solution, of just using \u003ca href=\"/notes/distributed-file-systems/\"\u003eDistributed file systems\u003c/a\u003e, is also not optimal: they have usually a high latency, with high throughput, that is not optimal with the series of small files that it is optimized for.\nWhile Object Storages, do not have APIs that could be helpful -\u0026gt; \u003cstrong\u003ericher logical model\u003c/strong\u003e.\u003c/p\u003e","title":"Wide Column Storage"},{"content":"In this document, we will discuss the actual Wi-Fi standard that we can find in the market.\nThe initial slides consist of extensive lists of Wi-Fi technologies and their uses, such as Bluetooth network, Wi-Fi network, long-range Wi-Fi, and 3G network.\nHowever, they are currently out of service.\nService Sets Basic Service Set There are various divisions within the service set, each of which provides certain types of service.\nIn the basic service, we have things like SSID, which is the service set identifier that is broadcasted in the beacon as described in Mac Wifi.\nThe SSID is mainly used to announce the presence of the network and allow hosts to connect to it.\nExtended Service Set I have an ESS when I have multiple BSSs collaborating with each other to provide service, giving the user a single interface. I believe it could be explained simply as if it were multiple APs that appear as one network.\nAn ESS is typically used to provide wireless coverage over a larger area, such as in a campus or office building, where multiple access points are needed to cover the entire area. The access points within an ESS communicate with each other to provide seamless wireless coverage and allow users to move from one area to another without losing connectivity.\nOne downside of SSID is the default password set by manufacturers (for example, \u0026ldquo;tsunami\u0026rdquo; for Cisco).\nRogue access points ‚Üí attacks on networks left open.\nSecurity considerations See Wireless attack vectors#Defenses of IEEE 802.11.\n","permalink":"https://flecart.github.io/notes/wifi-802-11/","summary":"\u003cp\u003eIn this document, we will discuss the actual Wi-Fi standard that we can find in the market.\u003c/p\u003e\n\u003cp\u003eThe initial slides consist of extensive lists of Wi-Fi technologies and their uses, such as Bluetooth network, Wi-Fi network, long-range Wi-Fi, and 3G network.\u003c/p\u003e\n\u003cp\u003eHowever, they are currently out of service.\u003c/p\u003e\n\u003ch2 id=\"service-sets\"\u003eService Sets\u003c/h2\u003e\n\u003ch3 id=\"basic-service-set\"\u003eBasic Service Set\u003c/h3\u003e\n\u003cp\u003eThere are various divisions within the service set, each of which provides certain types of service.\u003c/p\u003e\n\u003cp\u003eIn the basic service, we have things like \u003cstrong\u003eSSID\u003c/strong\u003e, which is the service set identifier that is broadcasted in the beacon as described in \u003ca href=\"/notes/mac-wifi/\"\u003eMac Wifi\u003c/a\u003e.\u003c/p\u003e","title":"Wifi 802-11"},{"content":"In this note we will talk about some common ways to attack wireless based devices.\nAttacking an automated door Usually these doors are opened by radio frequency keys, and can be opened easily (e.g. replay attacks, Jam the frequency)\nJamming This is the easiest way to attack. Just send many signals to make a certain frequency un-usable in our space. But with Frequency hopping this attack is solved. See Tecnologia Wireless#Frequency Hopping But this method could be easily known and observed (enables eavesdropping, against confidentiality, a principle in Theoretical Notions of Security#CIAA principles of security.) if the initial seed is known.\nFrom this we conclude that\nIf the modulation used is known If the initial seed is known. We can eavesdrop. Rolling code In some systems like automated doors, they just check for a sequence of signals, if that is present open the door. This is clearly easily attacked by replay attacks. So, a common way to protect against those types of attacks is to use a rolling code. With rolling code both transmitter and receiver have a PRNG. The transmitter sends codes based on the PRNG, and receiver tries to get those messages. He tries to see codes in a large frame window, so that a missed code doesn\u0026rsquo;t dis-align it too much. This makes replay attacks more difficult (usually it is good enough), but does not prevent them: if the attacker captures too many codes then it can be broken!\nChallenge and response More secure way to handle these is using challenge-response protocols. The door generates a nonce to the receiver. The receiver than uses a common secret to cipher it and return back to the door. This needs a back and forth not present in the previous methods. With these in place, we can authenticate the client, and solve replay attacks.\nDefenses of IEEE 802.11 The physical layer There are usually no defenses against attacks on the physical layer of the wifi network stack. Electromagnetic radiations are transmitted freely in the space. Some solutions are for example use paints that absorb most of the radio waves. The Mac layer Inter-Frame spaces DoS Remember that the mac layer uses silent periods, called SIFS, PIFS, DIFS to orchestrate the communication Mac Wifi#Inter-Frame spaces. There is a easy denial of service attack with this protocol: just permanently communicate before the end of a PIFS, so it\u0026rsquo;s just you that does it.\nSSID Hiding This link is an interesting resource regarding this topic. Let\u0026rsquo;s ask: is it secure to hid the SSID of your wi-fi network? Answer: No, you are using security by obscurity Classical Cyphers#On security of cipher explains why it is a bad idea.\nMAC whitelisting Also, this is not a good idea, because it is easy to spoof the wanted MAC if an attacker really wanted to.\nDisassociation attacküü®+ Some packets, like disassociation packets are sent in clear, with no need for authentication of the request. This makes easy to send disassociation packets to make a terminal disconnect from the access point.\nSee here. The solution for this problem is to authenticate the terminal with WPA or other ciphers.\nRogue AP As SSID (see briefly Wifi 802-11), are public, it\u0026rsquo;s possible to spoof the network, and put an access point that is not the real one, but pretends to be. In this way, you can receive passwords or other secrets that pass through this AP.\nWi-fi Cryptography WEP protocol Has two operating modes, shared key and open system.\nWEP Shared Key Challenge and response framework is used, like this: But as the nonce is in clear, the key can be recovered using Known plain-text attacks and other similar to those! And it\u0026rsquo;s possible to do it in every session.\nWEP Open System With this protocol, the sender and receiver already have the secret key in common. Then the sender does this to create the cipher text: RC4_seed(IV | k), then uses this OTP and Stream Ciphers#Stream Ciphers to generate the key used to cipher the messages. The message is split to $n$ blocks at the beginning, so there are like blocks of messages. The problem is that after 30k packages is almost sure collision that would allow an attacker to recover the plain-text, as they share the same IV. So this is not secure at all.\nWPA protocol Stands for WiFi protected access. This protocol solves some of the common problems of WEP security. It can be divided into 3 channel based categories and two cipher-based categories.\nPSK Enterprise WPS For the channels And TKIP(Temporal Key Integrity Protocol) and CCMP (Counter Mode Cipher Block Chaining Message Authentication Code Protocol) for cipher modes. TKIP is wep compatible. CCMP uses AES with CBC. WPA with TKIP has been deprecated.\nWPA-PSKüü© So, a WPA that uses phase shift keying to send the messages. Using the TKIP, it has problems like WEP, so it is not used anymore.\nCCMP version is still quite used, usually in domestic systems. It is still reliable.\nWPSüü© With these system, there is no need for a password. But it needs a physical access to the access point. Example of this method is a button or PIN on the wifi router.\nWPA-Enterpriseüü© This method is used on WANs, for example Unibo WAN uses this method. They use an external server for authentication, called RADIUS (Remote Authentication Dial-In User Service). WPA3üü® WPA2 was possible to have a Replay attack, as the used nonce was cached to make the authentication faster. WPA3 solved this problem, so it can be considered as the most secure method.\n","permalink":"https://flecart.github.io/notes/wireless-attack-vectors/","summary":"\u003cp\u003eIn this note we will talk about some common ways to attack wireless based devices.\u003c/p\u003e\n\u003ch3 id=\"attacking-an-automated-door\"\u003eAttacking an automated door\u003c/h3\u003e\n\u003cp\u003eUsually these doors are opened by radio frequency keys, and can be opened easily (e.g. replay attacks, Jam the frequency)\u003c/p\u003e\n\u003ch4 id=\"jamming\"\u003eJamming\u003c/h4\u003e\n\u003cp\u003eThis is the easiest way to attack. Just send many signals to make a certain frequency un-usable in our space.\nBut with Frequency hopping this attack is solved. See \u003ca href=\"/notes/tecnologia-wireless/#frequency-hopping\"\u003eTecnologia Wireless#Frequency Hopping\u003c/a\u003e\nBut this method could be easily known and observed (enables eavesdropping, against confidentiality, a principle in \u003ca href=\"/notes/theoretical-notions-of-security/#ciaa-principles-of-security\"\u003eTheoretical Notions of Security#CIAA principles of security\u003c/a\u003e.) if the initial seed is known.\u003c/p\u003e","title":"Wireless attack vectors"}]