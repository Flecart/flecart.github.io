[{"content":"A seconda dell\u0026rsquo;utilizzatore l‚ÄôOS pu√≤ essere molte cose, come solamente l‚Äôinterfaccia se sei un programmatore, servizi (se sei un utente, ma gran parte dei servizi sono astratti e l\u0026rsquo;utente ne pu√≤ anche essere a non-conoscenza).\nMa se sei un programmatore OS ti interessa capire le componenti principali dell‚ÄôOS\nSlide componenti OS alto livello Introduzione sui componenti (salto) Questa parte la salto perch√© √® una descrizione molto generale di cosa si occupa L‚Äôos verso drivers, processi, filesystem I/O, quindi non √® molto importante\nGestione dei processi All\u0026rsquo;interno del SO, il processo √® rappresentato come un processo control block, che in linux √® in sched, parte dello scheduler dei processi. Questo √® importante perch√© per esempio per fare una fork, non faccio altro che duplicare questa struttura e settare bene i figli e genitori.\nQuesti sono solitamente messi un un process table o forse una lista per tenerne traccia.\nSlide\nnel parliamo in Processi e thread.\nGestione memoria principale e secondaria Principale\n√à un array temporaneo(nel senso che non √® mantenuto quando viene spento il PC.), indicizzato singolarmente a differenza del secondario, che √® indicizzato a blocchi,\nUna parte importante di questa parte √® la gestione della memoria virtuale. Come allocare pagine di memoria, deallocarle e simili, ne parliamo in Paginazione e segmentazione\nSecondaria\nLa cosa buona √® che questa memoria √® permanente, efficienza (ordinare le richieste per non andare qui e l√¨ quando si legge! minimizare tempi per seek) e partizionamento e reliability dei dischi sono problemi che interessano questa parte. Abbiamo parlato di raid in Memoria. e di nuovo in Devices OS.\nSlide\nI/O e filesystem Principalmente per IO servono driver per interagire con specifici hardware, e un sistema di comunicazione che spesso sono buffer e cache.\nSlides\nEsiste un file system virtuale che mappa a tutto (quindi alcune cose non esistono realmente sul disco, potrebbe essere una astrazione utilizzata per esempio per comunicare con i devices.\nCi sono molti filesystem, che per√≤ posso gestire in modo differente la forma che hanno sul disco, Ed √® per questo che possiamo dire che esistono dei filesystem diversi.\nAnche i processi sono files, la cosa figa di questa astrazioen √® che posso utilizzare gli stessi sistemi di protezione file per processi.\nStruttura dei sistemi Obiettivi di design dei SO (4) üü® Slide obiettivi nella struttura dei sistemi (4)\nEfficienza\nModularit√†\nMantenibilit√†\nEspansibilit√†\nStruttura del kernel üü© Slide riassuntiva\nIl kernel √® un unico processo, parte da un main che parte da un initialize in cui raccoglie tutte le risorse del sistema, fa partire tutti i device drivers e crea il PCB del primo processo, anche chiamato init, messo poi nella queue dello scheduler come spiegato in Scheduler. Fatta una volta non √® mai pi√π eseguito quel codice di init.\nLo stato kernel √® la parte a sinistra dell‚Äôimmagine, quella parte blu, tutto il giallo, a destra √® lo stato user.\nScheduler scegliere il processo da eseguire nello user space Il controllo √® passato al processo user, che pu√≤ fare traps (come fork) o fare I/O, a quel punto √® rimesso a codice kernel. Tipologie di struttura OS (2) üü®++ Solitamente i sistemi sono costruiti in due modi, sistemi semplici senza struttura, che praticamente c\u0026rsquo;√® una prima versione, e poi viene ammassato roba senza struttura generale, fatti quando servono. Solitamente sono insieme di procedure che si chiamano fra di loro, e ben presto sono andate fuori dal loro ambito di interesse diciamo (fuori dal loro scope)\nEsempi di OS semplici:\nUn esempio √® free-dos che √® quanto installato su un computer senza sistema operativo.\nIn modo simile √® MS-DOS, che √® stato fatto per i primi personal computer, che non avevano un sistema kernel a livello hardware (non era quindi possibile fare queste protezioni).. In generale in questo ambiente un programma aveva accesso all\u0026rsquo;intera memoria, e poteva mandare in crash tutto.\nStruttura Free-DOS\nUNIX, √® diviso diviso in due parti in kernel e programmi di sistemi, molto semplice, un kernel monolitico, un unico eseguibile, anche questo fu all‚Äôepoca limitato enormemente dal suo hardware, e una serie di programmi di sistema.\nDato che c\u0026rsquo;√® una separazione, l‚Äôutente √® separato dall‚Äôinterfaccia dal codice kernel. Ma comunque il codice kernel resta vulnerabile, e potrebbe essere modificato e quindi attaccato, o cumunque vulnerabile a bug, anche colposi, distruttivi.\nStruttura UNIX\nStratificazione OS:\nLa struttura a stati √® pi√π affidabile dell\u0026rsquo;altra e rende pi√π facile la programmazione di tale sistema, utili, la logica √® la stessa presentata in Architettura e livelli 1, 2, per la divisione a stack del sistema e dei vantaggi che si hanno con questo tipo di architettura.\nEsemplificazione struttura a strati\nStrutture proposte classiche (non fatte, non importanti)\nQuesti sono rimasti accademici\nMa nella pratica questi strati sono rimasti solamente a livello accademico, perch√© crea overhead anche se si guadagnerebbe in manutentibilit√† e estensibilit√† e gestione, quindi molto meno efficiente, inoltre non erano ben chiare le API fra strati. Oggi c\u0026rsquo;√® una forma intermedia (non c\u0026rsquo;√® esattamente la gestione a strati come abbiamo per Web, ma abbiamo una divisione per componenti e responsabilit√† delle componenti).\nPolitiche e meccanismi üü© La suddifivisione politiche e meccanismi √® un pattern di software engineering che lo rende molto comodo da gestire.\nInvece che una gestione a strati come per le reti, abbiamo una gestione di politiche e meccanismi ossia abbiamo qualcosa che decide cosa andare a fare e qualcosa che gestisce il come farla.\nEG. un certo modo di memoria allocata per fare qualcosa, quindi indirizzare il sistema verso qualcosa, e MMU che attualmente implementa la decisione politica.\nEsempio Microkernel o MINIX:\nIl kernel √® visto come il meccanismo quindi le parti di gestione e politica sono fuori dal kernel. Questo rende la struttura del SO molto mantenibile ed estendibile.\nSlide\nEsempio Mac OS ‚â§ 9 / Windows 9x:\nPolitiche e meccanismi sono messi tutti nel kernel, perch√© cos√¨ imponevo un feeling unico al look and feel suo (obbligato tutti ad avere questi elementi grafici). Questo √® un problema praticamente di mercato.\nQuesto era brutto perch√© la grafica pu√≤ mandare in crash tutto il sistema. Anche se i nuovi sistemi non dovrebbero avere questo problema.\nCategorizzazione dei Kernel (3) üü®‚Äî Monolitici:\nIl kernel √® un unico programma. Si possono creare moduli che poi vengono caricati. Il problema principale di questo tipo di kernel √® che se un modulo bugga crolla l\u0026rsquo;intero sistema. Un vantaggio √® che √® molto efficiente perch√© non deve passare ad astrazioni come per lo stack, basta fare una chiamata di funzione, tanto siamo nello stesso programma. Ed √® altamente modularizzabile per poter attaccare nuove funzionalit√†.\nIn breve:\nVantaggi\nEfficienza Modularit√† e mantenibilit√† (non devo ricompilare tutto, basta runtime). Svantaggio\nUn modulo pu√≤ mandare in crash tutto, perch√© √® eseguito nello stesso spazio del kernel.\nSlide\nEsempi sono Linux o BSD.\nMicrokernel:\nL‚Äôobiettivo del microkernle √® isolare solamente le funzionalit√† essenziali e tenere solo quelli, tutto il resto interagisce con esso con system call (un esempio √® il filesystem che potrebbe essere fuori dal kernel, e avrebbe syscall leggermente diverse rispetto a quelle di linux, per aprire un file allora si chiederebbe a questo processo in user space, che poi fa altre richeste per kernel space)\nBisogna fare un messaggio, la syscall diventano Send! Che sarebbe unico modo per raggiungere il processo che offre il servizio che mi serve.\nVantaggi: üü•\nAltissima modularit√† e mantenibilit√† del sistema e semplice da realizzare Assenza di danni di sistema, perch√© moduli e kernel sono eseguiti in spazio differente. Sicuro e affidabile per la divisione (non ho propagazione di errori e guasti) Molto portabile, che ho solo il microkernel. Svantaggio:\nFortemente Inefficienza rispetto al monolitico, che devo fare message passing e comunicazione.\nSlide di comparazione\nKernel Ibridi\nSono dei microkernel modificati, con qualcosa in pi√π forse (aziende per pubblicizzarsi dicevano di avere microkernel, ma con un ibridone, mettendo le cose inefficienti del microkernel dentro il kernel).\nEsempio windows\nCi sono diversi server, che fanno parte di un sottosistema d‚Äôambiente che √® in grado di emulare certe cose (sono nascoste le syscall reali del sistema cos√¨).\nIl codice per un certo ambiente funziona anche nel sottosistema, un esempio √® un WSL.\nLa parte grafica importante per fare i videogiochi, √® dentro il kernel, questo ad esempio per MACOS, perch√© volevano imporre la grafica simile\nMacchine virtuali Virtualization allows a single computer to host multiple virtual machines, each poten- tially running a completely different operating system.\n√à virtuale nel senso che la macchina virtuale ha la stessa percezione della realt√† di una macchina reale. Qualcosa che non √® la realt√† ma appare molto simile ad essa.\nStoricamente parlando le macchine virtuali erano un primo approccio al multitasking.\nL‚Äôidea principale √® creare un sistema che possa apparire al sistema operativo come hardware, in questo modo posso utilizzare un programma per emulare un altro sistema operativo. √à hypervisor, VMM (virtual machine monitor).\nOvviamente ho uno fortissimo svantaggio in velocit√†, perch√© la simulazione software √® molto meno efficiente della simulazione hardware. Un collegamento carino √® con strange loops, una macchina che sia abbastanza espressiva da poter emulare s√© stesso.\nAnalisi vantaggi svantaggi üü® Slide\nPosso avere sistemi operativi differenti sulla stessa macchina o SO, quindi posso sperimentarli senza installarli veramente.\nPosso simulare architetture differenti, e quindi supporre di avere istruzioni differenti di architettura altra!\nSO monotask in sistemi multitask???\nMaggiore sicurezza a bug software, √® efficienza energetica\nSvantaggi:\nfortemente inefficiente Difficile condividere risorse fra una macchina virtuale o all‚Äôaltra. Livello processo o sistema üü© Le macchine virtuali di cui abbiamo parlato ora virtualizzano solamente l‚Äôhardware, cio√® fa finta di avere un sistema hardware???\nMentre altre macchine virtuali provano a virtualizzare a livello di ABI (application binary interface) (che √® livello di processo).\nMacchina virtuale a livello di processo (process VM): permette ad un programma di essere eseguito allo stesso modo su qualsiasi piattaforma. Viene eseguita come una normale applicazione all‚Äôinterno di un SO ospite e supporta un singolo processo. Il suo scopo √® fornire un ambiente indipendente dalla piattaforma hardware e dal SO ospite. Vengono virtualizzati sia l‚Äôhardware che il sistema operativo. Macchina virtuale a livello di sistema (system VM): permette l\u0026rsquo;esecuzione di un completo SO, anche con un ISA diverso da quello della macchina reale. Viene virtualizzato esclusivamente e completamente l‚Äôhardware Differenza type 1 and 2 hypervisors\ntype 1 hypervisor and a type 2 hypervisor is that a type 2 makes uses of a host operating system and its file system to create processes, store files, and so on. A type 1 hypervisor has no underlying support and must perform all these functions itself (it runs on the bare metal, come se fosse lui stesso un sistema operativo, √® infatti un sistema operativo che non fa altro che fare sistemi operativi!)\nQemu üü© qemu √® un traduttore dinamico come se fosse un compilatore fra una architettura in una altra, fatta a runtime (quindi √® un interprete, tipo 10x pi√π lento rispetto esecuzione normale, ma un ordine di grandezza pi√π veloce rispetto altri emulatori).\nCon qemu posso anche dire al processo emulato di utilizzare il mio stesso kernel, nel caso che condivida l\u0026rsquo;architettura, questo rende la cosa molto pi√π veloce del normale! e.g. KVM (che √® il nome dell‚ÄôHypervisor per linux). Questo √® anche una tipologia di type-2-hypervisor perch√© attingo al kernel della macchina ospite per fare funzionare pi√π in fretta, e non faccio simulazione sistema totale.\nUtile o per runnare programmi per architettura differente (in questo senso program VM), oppure per emulare un sistema operativo dentro un sistema operativo\nComando per caricare una macchina virtuale con qemu e utilizzare KVM\nsenza vga, non starebbe sullo schermo senza quella flag.\nhda gli specifica il file con cui emulare il disco, k il layout del keyboard\nm √® la memoria ram\nmonitor √® per poter mandare interrupt dal terminale in cui ho lanciato il mio comando di emulazione.\nQuando installa prima √® installato nella RAM disk, e poi viene utilizzato per l‚Äôinstallazione vera e propria.\nXEN üü© XEN √® hypervisor livello 1 (SO che permette di fare altri SO virtuali), e utilizzare paravirtualizzazione (si fanno trap and emulate principalmente) , e utilizza una gestione diversa dei drivers che possiede, ossia il Domain0 possiede tutti i drivers fisici (le interazioni con i device le manda alla macchina 0, perch√© per restare un sistema operativo semplice non riesce a gestire sistemi operativi).\nParavirtualizzatione\nIn questo caso il SO virtuale √® a conoscenza che esiste un hypervisor quindi pu√≤ fare delle hypercall per eseguire delle istruzioni sensitive, e in generale √® un approccio pi√π veloce invece della virtualizzazione totale di cui abbiamo parlato prima.\nEsempio di maggiore efficienza\nPer il type 2 hypervisor il SO installato pensa veramente di stare in una macchina s√©, quindi fa cose per minimizzare i seek del disco ma in questo caso non deve fare veramente seek, quindi √® meno efficiente, facendo una assunzione errata.\nSi utilizzano paravirtualizzazione, ossia devices virtuali pi√π efficienti per questa cosa, ed effettivamente non assumo di stare utilizzando device fisici, ma sono a conoscenza di utilizzare device virtuali, e posso fare ottimizzazioni del caso (che non so quali siano forse per il disco non faccio cose strane per il seek ad esempio).\nIl problema √® che essendo a conoscenza, dovrei fare il mio SO in modo che sia compatibile con le hyper all offerte dall hypervisor\nParametrizzazione SO üü© Essendo libero linux, √® molto comodo poter cambiare alcuni parametri e poi ricompilare il kernel seguendo quei parametri. Tanto √® tutto open source, quindi si potrebbe fare. Questo permette al kernel di essere molto portabile.\nUna cosa molto importante da capire √® che il kernel √® una cosa diversa della distribuzione, il kernel √® il primo programma che viene caricato dal bootloader e carica il FS e tutto il resto (quindi le cose iniziali), il secondo sono tutte le utility per il kernel che lo rendono utilizzabile da un utente normale.\nComando runnato per la emulazione kernel/distribuzione\nSlide parametrizzazione ++ portabilit√† (che deve runnare per hardware differentI)\nIstruzioni di virtualizzazione üü• Abbiamo aggiunto delle istruzioni di emulazione come VMX ON, VMX OFF, VMLAUNCH, VMRETURN in cui il processore sa di stare emulando, e quindi √® pi√π veloce perch√© esegue l\u0026rsquo;istruzione in altro modo, forse con istruzione nativa. Pagina wiki\nfa pensare di essere in kernel mode, ma non √® in kernel mode, √® come se stesse in un livello di priviliegio intermedio.\nVMLAUNCH\nQueste sono quelle principali istruzioni che permettono la virtualizzazioen a livello software, il fatto che rende l\u0026rsquo;esecuzione molto pi√π veloce, quindi invece di simulare tutto sopra il sistema operativo attuale (e syscalls attuali) posso accedere ad istruzioni hardware molto pi√π veloci.\nMemoria Virtuale (non fare) C\u0026rsquo;√® una MMU del sistema operativo che mappa alla VM fisica, che si deve basare all\u0026rsquo;indirizzo logico, che deve essere risolto dalla MMU reale fino ad avere un indirizzo fisico.\nMINI SCHEMA\n","permalink":"https://flecart.github.io/notes/architettura-software-del-os/","summary":"A seconda dell\u0026rsquo;utilizzatore l‚ÄôOS pu√≤ essere molte cose, come solamente l‚Äôinterfaccia se sei un programmatore, servizi (se sei un utente, ma gran parte dei servizi sono astratti e l\u0026rsquo;utente ne pu√≤ anche essere a non-conoscenza).\nMa se sei un programmatore OS ti interessa capire le componenti principali dell‚ÄôOS\nSlide componenti OS alto livello Introduzione sui componenti (salto) Questa parte la salto perch√© √® una descrizione molto generale di cosa si occupa L‚Äôos verso drivers, processi, filesystem I/O, quindi non √® molto importante","title":"Architettura software del OS"},{"content":"Introduzione alla notazione asintotica Cercare di definire il tempo impiegato da una funzione per essere eseguita in termini di DIMENSIONE dell\u0026rsquo;input. **(il numero di bit a livello basso basso)\nMa abbiamo il problema di misura, in quanto dobbiamo considerare delle variabili che siano indipendenti rispetto alla macchina.\nCaratteristiche della notazione Vogliamo considerare una notazione asintotica (che guarda quanto fa il comportamento verso l\u0026rsquo;infinito)\nFunzione di costo Modelli asintotici Abbiamo trattato di o-piccolo e ogrande in Analisi.****\nO-grande Prendiamo due funzioni $f, g : \\mathbb{N} \\to \\mathbb{R}^{+}$ allora definiamo $f(x) = O(g(x))$ se esiste un $n_{0} \\in \\mathbb{N}$ e un $c$ tale che per cui per ogni $n \u003e n_{0}$ si ha che $$ f(n) \\leq c g(n) $$ Ossia: la funzione √® upper-bounded per numeri molto grandi. Quando vale la versione stretta si pu√≤ dire che √® anche o-piccolo.\nNote interessanti che notazioni come $$ n^{c}, 2^{O(\\log n)}, n^{O(1)} $$ Sono equivalenti.\no-piccolo Usiamo la definizione trattata in Analisi: Theta Omega-grande omega-piccolo Costo e Complessit√† computazionale Definizioni Analisi ammortizzata Introduzione Questa √® una tecnica che trova il costo medio di un algoritmo. La differenza con il calcolo del costo medio classico √® che questo calcolo mi trova il costo medio per una sequenza di operazioni mentre il classico mi trova il costo medio per una singola operazione\nCasi di utilizzo Di solito √® utile utilizzare questo metodo di analisi in queste condizioni\nCaso pessimo non frequente (quindi per dire che nella media un algoritmo √® molto pi√π efficiente) Semplificare l\u0026rsquo;analisi del caso medio Aggregazione Vogliamo cercare un limite superiore su n operazioni, poi dividere il tutto per n.\nQuesto √® pi√π utile quando il costo totale √® conosciuto\nAccantonamenti Questo √® basato sulla contabilit√†, ho un certo credito iniziale, posso utilizzare tutto, ma non posso mai andare in negativo.\nQuesto √® utile quando ci sono diverse operazioni.\nUn esempio di analisi ammortizzata utilizzando gli accantonamenti √® la doubling and halving in cui 3 monete per ogni operazione di inserimento bastano poi per ricopiare ed espandere o diminuire il tutto a piacere (quindi 3n , si ha un costo costante). menti √® la doubling and halving in cui 3 monete per ogni operazione di inserimento bastano poi per ricopiare ed espandere o diminuire il tutto a piacere (quindi 3n , si ha un costo costante).\nRegistro Ripassi 14/03/2024 Ripassato per Time and Space Complexity Ripasso Prox: 31 Ripasso: May 28, 2022 Ultima modifica: April 28, 2022 5:07 PM Primo Abbozzo: February 24, 2022 9:19 AM Stato: üåïüåïüåïüåïüåï Studi Personali: No\n","permalink":"https://flecart.github.io/notes/notazione-asintotica/","summary":"Introduzione alla notazione asintotica Cercare di definire il tempo impiegato da una funzione per essere eseguita in termini di DIMENSIONE dell\u0026rsquo;input. **(il numero di bit a livello basso basso)\nMa abbiamo il problema di misura, in quanto dobbiamo considerare delle variabili che siano indipendenti rispetto alla macchina.\nCaratteristiche della notazione Vogliamo considerare una notazione asintotica (che guarda quanto fa il comportamento verso l\u0026rsquo;infinito)\nFunzione di costo Modelli asintotici Abbiamo trattato di o-piccolo e ogrande in Analisi.","title":"Notazione Asintotica"},{"content":"Particelle in campi magnetici Moto in campo magnetico uniforme üü© Se abbiamo una particella carica con velocit√† uniforme in campo magnetico uniforme, come abbiamo detto in precedenza, una forza centripeta, questo far√† curvare la carica, una cosa interessante sarebbe provare a capire raggio di curvatura della nostra carica. Sotto in immagine abbiamo l\u0026rsquo;esempio di curvatura. $$ F = qvB= ma = \\frac{mv^{2}}{r} \\implies r = \\frac{mv^{2}}{qvB} = \\frac{mv}{qB} = \\frac{p}{qB} $$ Dove $p$ √® la quantit√† di moto, quantit√† che credo sia relazionata al lavoro ed inerzia, parte di fisica 1 che non ho studiato da pi√π di due anni. Questa stessa relazione, conoscendo il raggio pu√≤ essere usata per calcolare il campo magnetico!.\nPossiamo anche avere una velocit√† angolare! $$ \\omega = \\frac{v}{r} = \\frac{vqB}{mv} = \\frac{qB}{m} $$ Questo risultato si poteva anche avere osservando che $F = m \\vec{\\omega} \\times \\vec{v}$ E si noter√† che il verso √® opposto al campo magnetico. Quindi: $$ \\vec{\\omega} = -\\frac{q\\vec{B}}{m} $$ Ma questo vale solo classicamente, perch√© poi entrano in gioco irradiazioni che fanno perdere energia e anche cose relativistiche se accelero troppo.\nSupponiamo ora che ci sia un certo angolo fra i due allora ho che solamente la parte normale ha forza, avr√≤ un moto elicoidale.\nAngolo generico üü© $$ F = qv \\times B = q(\\vec{v}_{n} + \\vec{v}_{p}) \\times \\vec{B} = q\\vec{v}_{n}\\times \\vec{B} $$ Passo dell\u0026rsquo;elica Vogliamo capire quale sia la distanza fra un top di elica e una altra, avremo che questo √® $$ p = v_{p} T = v_{p} \\frac{2\\pi}{\\omega} = \\frac{2\\pi mv_{p}\\cos \\theta}{qB} $$ Dove $v_{p}$ √® la velocit√† parallela al campo magnetico, e $T$ √® il periodo che √® calcolato dalla velocit√† angolare. Il coseno serve per prendere la componente corretta credo\u0026hellip;.\nEffetto Hall üü© Da studiare bene pagina 230 Mazzoldi. Sia dato un conduttore parallelepipedo, una piccola sottile lastra, che scorre una corrente, allora avremo una forza $$ \\vec{F} = q\\vec{v}_{d} \\times \\vec{B} $$ La forza √® non-elettrostatica, chiamata forza elettromotore, simile a quello per i circuiti, lo scrivo cos√¨: $$ F = qE_{m} = q\\vec{v}_{d}\\times \\vec{B} \\implies E_{m} = v_{d}B $$ Questo fa accumulare carica positiva sopra, che crea un altro campo elettrico statico che prova a bilanciare. Il primo passaggio √® motivato perch√© √® come se esistesse un campo elettrico fittizio, per spostarlo su. (√à un campo elettrico generato!).\nQuesto campo elettrico che bilancia si chiama campo elettrico di Hall. √à utile per capire se i portatori di carica √® negativo o positivo, forse ha una cosa storica questa cosa. Avremo che $$ \\Delta V_{M} = E_{m} b = v_{d}Bb = b\\vec{J}\\times \\frac{\\vec{B}}{nq} = i \\frac{\\hat{u}}{a}\\times \\frac{\\vec{B}}{nq} \\implies \\Delta V = \\frac{iB}{nqa} $$ Dove $b$ √® l\u0026rsquo;altezza, e $a$ √® la width del nostro filo.\nQuesto permette di misurare il campo magnetico ed √® chiamato sonda di Hall, basta misurare la differenza potenziale presente. Per esempio questo diventa molto utile quando per Magnetismo nella materia andiamo poi a misurare il campo magnetico in buchi, basta mettere questa sonda di Hall.\nSpettrometri di massa Spettrometro di massa di Thomson üü© Ho un coso che emette particelle in tutte le direzioni, faccio passare una zona per aumentare energia e poi campo magnetico Abbiamo che $$ \\frac{1}{2}mv^{2} = q\\Delta V \\implies v = \\sqrt{ \\frac{2qV}{m} } $$ Usiamo poi questo valore che ci permette di descrivere la velocit√† della particella prima che entrino nel campo magnetico, e otteniamo poi che, considerando l\u0026rsquo;accelerazione centripeta. $$ F = qvB = \\frac{mv^{2}}{r} \\implies r = \\frac{mv}{qB} =\n\\sqrt{ 2 \\frac{m\\Delta V}{qB^{2}} } $$ Questo √® uno strumento buono per separare **isotopi**, perch√© hanno una massa diversa, ma stessa carica. Posso anche definire il rapporto fra i raggi degli isotopi che √® $$ \\frac{r_{1}}{r_{2}} = \\sqrt{ \\frac{m_{1}}{m_{2}} } $$\nSelettore di velocit√† üü© Metto in modo che ci sia un condensatore che abbia un certo campo elettrico, e anche che ci sia un campo magnetico, vorrei avere che abbiamo stesso valore, ossia $$ qE = q\\vec{v} \\times \\vec{B} \\implies E = vB $$ Nel nostro setting, questo √® utile per sapere la velocit√† da mettere poi in uno spettrometro di massa e fargli fare un certo giro! Allora abbiamo di nuovo $$ qvB_{0} = \\frac{mv^{2}}{R} \\implies R = \\frac{mv}{qB_{0}} = \\frac{mE}{qBB_{0}} $$ Anche questo posso usarlo per separare isotopi diversi, ma la cosa bella √® che questo √® lineare mentre prima avevamo una radice quadrata.\nSpire Setting classico: spira rettangolare üü© Prendiamo un campo magnetico costante, e un rettangolo di filo indeformabile (perch√© ci sono forze che potrebbero deformarla), in cui c\u0026rsquo;√® corrente, questo fa girare. Il campo magnetico ha un angolo con la nostra spira. Ossia -\u0026gt; $$ F_{4} = F_{3} = 0, F_{1} = F_{2} = 0 $$ Ossia la spira non trasla, perch√© non c\u0026rsquo;√® accelerazione, non trasla il centro di massa. E questo per qualche motivo ci permette anche di usare qualunque sistema di riferimento, tanto diventer√† uguale\u0026hellip;\nI due invece fanno ruotare la spira: $$ M = \\vec{M}_{1} + \\vec{M}_{2} = \\vec{r}_{1}\\times \\vec{F}_{1} + \\vec{r}_{2}\\vec{F}_{2} = \\frac{b}{2}\\sin \\theta F_{1} + \\frac{b}{2} \\sin \\theta F_{2} = bsen\\theta F = b \\sin \\theta iaB = i \\vec{S} \\times \\vec{B} $$ Per i lati su e gi√π abbiamo stessa forza che si annulla, per altri invece abbiamo un momento ora.\nMomento magnetico di spira üü© dal risultato precedente sembra sensato definire una nuova variabile: $$ \\vec{m} = i\\vec{S} $$ Il che ci permette di scrivere la relazione di sopra come $$ \\vec{M} = \\vec{m} \\times \\vec{B} $$ Che sta clean. Questo √® molto simile al valore trovato per il momento nel Dipolo elettrico, in cui abbiamo il momento di dipolo.\nPiccole oscillazioni üü• usiamo quanto scritto sopra, e valutiamo cosa succede per cose piccole: $$ \\lvert \\vec{M} \\rvert = -mB\\sin \\theta = mB\\theta = I\\dot{\\omega}= I\\ddot{\\theta} $$ E abbiamo che $$ \\ddot{\\theta} + \\omega^{2}\\theta=0 $$ Questo permette di calcolare il campo magnetico, col periodo. La cosa interessante √® che questo si comporta come un ago magnetico, stesso comportamento.\n","permalink":"https://flecart.github.io/notes/spettrometri-di-massa/","summary":"Particelle in campi magnetici Moto in campo magnetico uniforme üü© Se abbiamo una particella carica con velocit√† uniforme in campo magnetico uniforme, come abbiamo detto in precedenza, una forza centripeta, questo far√† curvare la carica, una cosa interessante sarebbe provare a capire raggio di curvatura della nostra carica. Sotto in immagine abbiamo l\u0026rsquo;esempio di curvatura. $$ F = qvB= ma = \\frac{mv^{2}}{r} \\implies r = \\frac{mv^{2}}{qvB} = \\frac{mv}{qB} = \\frac{p}{qB} $$ Dove $p$ √® la quantit√† di moto, quantit√† che credo sia relazionata al lavoro ed inerzia, parte di fisica 1 che non ho studiato da pi√π di due anni.","title":"Spettrometri di massa"},{"content":"Sembra essere molto simile a Central Limit Theorem and Law of Large Numbers per√≤ per Entropy. This is also called Shannon\u0026rsquo;s source coding theorem see here\nEnunciato AEP Data una serie di variabili aleatorie $X_{1}, X_{2}, \\dots$ i.i.d. $\\sim p(x)$ se vale che $$ -\\frac{1}{n} \\log p(X_{1}, X_{2}, \\dots, X_{n}) \\to H(X) $$ in probability (la definizione data in Central Limit Theorem and Law of Large Numbers#Convergence in probability).\nUn modo alternativo per enunciarla √® cos√¨, segue il metodo in (MacKay 2003).\nPer un certo $N$ tender√† all\u0026rsquo;infinito. $$ \\left\\lvert \\frac{1}{N} H_{\\delta}(X^{N}) - H(x) \\right\\rvert \\leq \\varepsilon $$ Ossia a grandi linee: dato una variabile aleatoria $X$ e $N$ estrazioni della stessa, possiamo comprimere questa sequenza in $NH(X)$.\nDimostrazione Principalmente sorvolata, ma utilizza cose simili a Central Limit Theorem and Law of Large Numbers, e una idea simile a Monte carlo integration per le probabilit√†. In realt√† nella prima formulazione √® un concetto molto semplice il motivo per cui funziona.\n$$ -\\frac{1}{n} \\log p(X_{1}, \\dots, X_{n}) = -\\frac{1}{n} \\sum_{i=1}^{n}\\log p(X_{i}) \\to -\\mathbf{E}[\\log p(X)] = H(X) $$ La cosa principale da comprendere √® come ci pu√≤ essere questo fenomeno con convergenza in probabilit√†, che √® una nozione pi√π che altro tecnica per questo discorso.\nTypical sets Elements in the typical set have roughly the same probability.\nQuesto insieme √® un oggetto matematico che ha delle propriet√† interessanti, viene corretto analizzarlo dopo che si ha AEP, perch√© in breve la sua esistenza √® giustificata da quello. √à l\u0026rsquo;insieme delle sequenze $(x_{1}, x_{2}, \\dots , x_{n})$ prese da una distribuzione $p(x)$ sempre uguale tale per cui valga $$ 2^{-n(H(X) + \\varepsilon)} \\leq p(x_{1}, x_{2}, \\dots, x_{n}) \\leq 2^{-n(H(X) - \\varepsilon)} $$ Il motivo per cui abbiamo le cose strane all\u0026rsquo;esponente √® proprio la definizione di convergenza in probabilit√† data. (basta che le espandi) Ossia il fatto che $$ P\\left( \\left\\lvert -\\frac{1}{n} \\log p(x_{1}, x_{2}, \\dots, x_{n}) - H(X) \\right\\rvert \u003e \\varepsilon \\right) = 0, n \\to +\\infty $$ Se si espande quanto √® presente dentro si ottiene quel bound di sopra.\nPropriet√† Vedi 3.1.2 di (Cover \u0026amp; Thomas 2012).\nIl risultato importante √® che possiamo rappresentare sequenze di $X^{n}$ in media usando $nH(X)$ bits, senza perdita di informazione.\nReferences [1] Cover \u0026amp; Thomas ‚ÄúElements of Information Theory‚Äù John Wiley \u0026amp; Sons 2012\n[2] MacKay ‚ÄúInformation Theory, Inference and Learning Algorithms‚Äù Cambridge University Press 2003\n","permalink":"https://flecart.github.io/notes/asymptotic-equipartition-property/","summary":"Sembra essere molto simile a Central Limit Theorem and Law of Large Numbers per√≤ per Entropy. This is also called Shannon\u0026rsquo;s source coding theorem see here\nEnunciato AEP Data una serie di variabili aleatorie $X_{1}, X_{2}, \\dots$ i.i.d. $\\sim p(x)$ se vale che $$ -\\frac{1}{n} \\log p(X_{1}, X_{2}, \\dots, X_{n}) \\to H(X) $$ in probability (la definizione data in Central Limit Theorem and Law of Large Numbers#Convergence in probability).\nUn modo alternativo per enunciarla √® cos√¨, segue il metodo in (MacKay 2003).","title":"Asymptotic Equipartition Property"},{"content":"7.1 Introduzione 7.1.1 Perch√© usarli Sono utili per mantenere delle informazioni nel tempo\n7.1.2 Caratteristiche Hanno feedback cio√® ci sono degli output che tornano dentro al circuito, quindi √® molto difficile senza sapere niente cosa succede dentro\nQuesto circuito non √® combinatorio, che √® formalizzabile in modo deterministico con l\u0026rsquo;lgebra booleana.\n7.1.3 Il Bit di memoria Questo bit ha due input, un load e un input, se il load √® attivo comincia a storare, altrimenti l\u0026rsquo;output √® sempre il bit che ha memoriazzato.\n7.2 Latch 7.2.1 Latch SR Con 0 0, qualunque bit ci sia, rimane sto bit che gira.\n1 1 = reset, 0 0 , NON FARLO\nQuesto √® uno dei pi√π semplici circuiti non sequenziali. Se l\u0026rsquo;input sono diversi fra di loro, allora sappiamo cosa esce,\nMa nel caso in cui l\u0026rsquo;input √® 0 0 oppure 1 1 allroa non va bene.\n7.2.2 Latch SR temporizzato e clock Il clock serve per stabilizzare la ram, il clock (voglio prendere solamente dei valori che siano stabili)\n7.2.3 Latch D Questo latch possiede un unico input per impedire che sia possibile che si verifichi\nil caso 1, 1, che non ci piace.\n7.2.4 D-Flip Flop √à uguale al Latch D ma solo con qualcosa in pi√π, dovrebbe sempre tornare in Zero il clock, per√≤ il Not ha un p√≤ di delay, che permette un velocissimo segnale a passare\nQuindi questo circuito carica solamente quando c\u0026rsquo;√® il clock che gli va, e permette il loading di qualcosa, quindi effettivamente riesce a mantenere il bit in memoria.\nQUesto √® migliore perch√© con il flipflop ho pi√π tempo per far stabilizzare i dati, invece di poter caricare per l\u0026rsquo;intero tempo in cui clock √® su, posso farlo in un solo piccolo frangente (ma sufficiente)\nHo un intero ciclo di clock per farlo stabilizzare, invece per il latch solo met√† (in quanto l\u0026rsquo;altra met√† √® di caricamento)\n7.3 Registri e RAM 7.3.1 Registro Questi il DFF √® il componente principale per il registro, che messo insieme ad altro √® in grado di creare la memoria RAM necessaria per far funzionare.\nin\nX\n0\n0\n1\n1\nload\nX\n0\n1\n0\n1\nclock\nNull\nSalita\nSalita\nSalita\nSalita\nout[N]\nMem\nout[N-1]\n0\nout[N-1]\n1\nDa notare che l\u0026rsquo;out vale il valore di in solo nel caso in cui il load √® 1 e il clock sta permettendo di salvare il dato.\nPer il resto √® sempre memoria.\n7.3.2 Program counter 7.3.3 chip RAM Il ram √® costruito da una serie di registri. In Input pu√≤ avere il valore in in, l\u0026rsquo;indirizzo in cui si vuole scrivere e un booleano che dice se vogliamo scrivere o no.\nCi saranno demultiplexer che indirizzeranno l\u0026rsquo;in al registro giusto. In out ho solamente l\u0026rsquo;out di questo registro, quindi devo anche filtrare fra l\u0026rsquo;output di tutti gli altri registri in quanto voglio solamente uno.\n7.4 Il microprocessore HACK In questo schema si possono vedere tutti gli elementi principali per il processore HACK, come ALU, program counter, il decoder e simil.\nUna caratteristica principale √® la ROM di HACK (noi oggi abbiamo solamente una ROM per boostrap, ma invece in HACK deve avere solo ROM per le istruzioni).\noutM √® il mit della memoria che viene fuori\n7.4.1 Accesso ai dati in memoria S, D, RAM Questa parte si pu√≤ considerare un approfondimento di una zona in Memoria.\nParliamo d SRAM e DRAM.\nSRAM si parla di Cache, sono pi√π costose rispetto alle memorie ram dinamiche\nDRAM √® la memoria principale, fatte con transistor e un condensatore. (contiene una carica per un p√≤ di tempo)\nEcco che allora DRAM ha bisogno di Refresh! In modo che il condensatore venga ricaricato.Questo rallenta anche la velocit√† del ram, ma si guadagna in economia\n7.5 Altro Abbiamo fatto anche altro riguardo a questa lezione.\nDa notare principalmente √® il funzionamento della cache qui di cui abbiamo anche fatto degli esercizi.\nPoi la predizione di pipelining distrutta dai salti nelle istruzioni presentata qui almente √® il funzionamento della cache qui di cui abbiamo anche fatto degli esercizi.\nPoi la predizione di pipelining distrutta dai salti nelle istruzioni presentata qui\n","permalink":"https://flecart.github.io/notes/circuiti-sequenziali/","summary":"7.1 Introduzione 7.1.1 Perch√© usarli Sono utili per mantenere delle informazioni nel tempo\n7.1.2 Caratteristiche Hanno feedback cio√® ci sono degli output che tornano dentro al circuito, quindi √® molto difficile senza sapere niente cosa succede dentro\nQuesto circuito non √® combinatorio, che √® formalizzabile in modo deterministico con l\u0026rsquo;lgebra booleana.\n7.1.3 Il Bit di memoria Questo bit ha due input, un load e un input, se il load √® attivo comincia a storare, altrimenti l\u0026rsquo;output √® sempre il bit che ha memoriazzato.","title":"Circuiti Sequenziali"},{"content":"8.1 Dimostrazione teorema invarianza 8.1.1 Introduzione Basi: Due proposizioni sono equivalenti quando valgono sugli stessi mondi.\nquindi $\\forall v, \\llbracket F \\rrbracket ^v \\equiv \\llbracket G \\rrbracket ^ v$.\nVogliamo dire che dati un buco presente in una proposizione, queste valgono sempre, sono in effetti equivalenti. Il buco la prendo come una variabile proposizionale. (riempire = rimpiazzare il buco)\n8.1.2 Operazione di sostituzione Si pu√≤ notare che ci sono 4 casi base, mentre le altre 4 sono per ricorsione strutturale.\n8.1.3 Enunciato La funzione di sostituzione ci permette di utilizzare una sostituzione anche nel profondo di un albero di deduzione naturale, per√≤ non √® accettabile poi in sede d\u0026rsquo;esame utilizzare questo teorema per fare deduzione naturale.\nLa dimostrazione √® per induzione strutturale abbastanza banale dopo aver definito la sostituzione, ma comunque resta un buon esercizio che dovresti fare.\n8.1.4 Osservazione 8.2 Connettivi logici 8.2.1 Definizione semantica (denotazione) Enunciato\nDalla definizione di connettivo unario si pu√≤ dedurre che esistono $2 ^{2^n}$ connettivi possibili ($2^n$ funzioni possibili per scelte dominio e 2 scelte posssibili per codominio.\nEs, per tutte le $2^n$ righe, devo dare in output un numero. Quindi posso dare una funzione che passa tutti 0 per tutte le righe, fino alla righa che da tutti uno per tutte le $2^n$ righe, finendo per avere $2^{2^n}$ funzioni possibili. Dobbiamo ora scegliere il perch√© abbiamo scelto questi connettivi fra tutti quelli presenti\n8.2.2 Giustificazione delle scelte Zero: Abbiamo preso tutti i connettivi zeroari, identificano il concetto di giusto o falso.\nUno: abbiamo preso solamente il connetivo not. (uno √® uguale all\u0026rsquo;input, gli altri due la ignorano, uno la ribalta, per questo abbiamo scelto solo il not).\nBinari questi sono tanti, ma non abbiamo dato una connotazione solo ad alcuni (eliminando tutti quelli banali tipo uguale a input, o inverso di input, o bot e top).\n8.2.3 Riduzione fra connettivi (classico) Questo concetto √® molto simile al ruolo di equivalenza fra due regole diverse (l\u0026rsquo;eliminazione dell\u0026rsquo;and e e1 e2). in Deduzione naturale.\nDefinizioni\nQui viene introdotto il concetto di funzionalmente completo che abbiamo utilizzato in Porte Logiche.\nE anche il concetto di riduzione indicato con $\\rhd$\nStudiamo quali connettivi sono necessari, scopriamo che nor e nand sono sufficienti, tutto si potrebbe ridurre a questi. Sono completi anche $\\vee, \\wedge, \\neg, \\bot, \\top, \\implies$ ridondante, ma funzionalmente completo\n8.2.4 Motivi della scelta dei connettivi (3) Lista motivi\nPoi c\u0026rsquo;√® una lunghissima lista di propriet√† possibili. Il prof. in classe ha dato l\u0026rsquo;intuizione del conceto di dualit√† fra top e bottom e and e or (basta ordinare la retta fra -1 e 0 per verificare che corrispondono, in pratica per la definizione attuale della nostra semnatica si hanno questi valori)\n8.2.5 Propriet√† dei connettivi (9) Queste scelte sono \u0026ldquo;funzionalmente complete\u0026rdquo; per la relazione di equivalenza.\ncaidana per ricordartelo. \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Connettivi Logici, correttezza, variabili/Untitled 6.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Connettivi Logici, correttezza, variabili/Untitled 6\u0026quot;\u0026gt; Infatti grazie a questo si pu√≤ creare un teorema di completezza per le regole, ovvero si pu√≤ dimostrare che\n$P \\equiv Q$ partendo solamente da queste regole, per√≤ non servono spesso per il calcolo. (a volte queste regole complicano la forma originale perch√© la forma di assorbimento di dovrebbe espandere).\nAltre cose sono\nModus barbara e risoluzione.\n8.3 Correttezza e completezza La correttezza la saltiamo, perch√© √® troppo complicato ed enunciata in breve sul teorema di completezza di sopra.\n8.3.1 Correttezza $\\Gamma \\vdash F \\implies \\Gamma \\Vdash F$\nEnunciato pi√π corretto\nLocalmente corrette significa che devono essere delle regole valide (che creano conseguenze logiche).\nOvvero significa che ho una ipotesi che funziona localmente ma non globalmente e lo scrivo come un implica.\nIntuizione\nOgni regola metto in un foglietto diverso (anche l\u0026rsquo;ipotesi scaricata √® presente di un foglietto sopra).\nVoglio dire che quella regola non √® una regola scaricata per un foglietto sotto. (viene scaricata solamente da un foglietto sopra.\nDimostrazione\nI Passi principali di dimostrazione\nCaso base A e caso impossibile [A] Ipotesi induttiva: i sotto-alberi sono conseguenza logica di ipotesi globali e ipotesi locali (localmente corrette). Per utilizzo di regole locali so che F √® conseguenza logica di molti implica. Per il teorema di deduzione semantica trasformo l\u0026rsquo;ipotesi induttiva con implica in RHS e LHS solo ipotesi globali del ramo principale. Unisco con transitivit√† della conseguenza logica. 8.3.2 Perch√© correttezza pi√π semplice di completezza Affinch√© abbia la correttezza, mi bastano delle regole che siano localmente corrette, se invece ho una regola incorretta riesco a derivare bottom da top, e quindi mi creerebbe una teoria inconsistente (tutto che valga).\nVorrei dire che ho tutte le regole per catturare un concetto semantico utilizzando un concetto sintattico (finito). Come faccio a usare una quantit√† finita per catturare l\u0026rsquo;infinito? Quindi per le logiche semplici come la logica proposizionale classica si pu√≤, per le altre no.\n√à sorprendente che un insieme finito di regole sia sufficiente a dimostrare infinite ipotesi, questo in matematica √® catturato il concetto di compattezza.\nDue ingredienti\nDevo avere tutte le regole, queste sono sufficienti per dimostrare tutte le conseguenze logiche. Da un insieme finito di regole devo essere in grado di dimostrare tutto. 8.3.3 Completezza in logica classica Non √® possibile dimostrare queste classiche tautologie RAA, EM\nNel caso due, posso dimostrare A oppure non A per introduzione dell\u0026rsquo;OR. Per√≤ poi non ho niente per continuare, in certi mondi non funziona A, perch√© non ho ipotesi, e non ho niente per dimostrare bottom con l\u0026rsquo;introduzione della negazione. Quindi queste non sono dimostrabili.\nMa questi valori sono validi se i valori di verit√† sono solamente due! le regole che ho non colgono la dualit√† (vero falso) della logica classica. infatti queste si dimostrazione solamente con l\u0026rsquo;introduzione della regola RAA.\nMa l\u0026rsquo;introduzione di questa regola toglie l\u0026rsquo;algoritmicit√† della dimostrazione quindi non √® da fare.\nPer avere dimostrazione della correttezza della regola qui\n8.4 Variabili Definizione funzione Var\nCostruiamo una funzione Variabile definita per ricorsione strutturale che ritorni tutte le variabili esistenti in una formula logica.\nCerchiamo di creare una sintassi che possa essere utilizzabile tutta l\u0026rsquo;infinit√† dei mondi.\nRiesco quindi a introdurre il concetto di equivalenza di mondi in funzione di una proposizione.\n8.4.1 Teorema: var(F) finito per ogni F La dimostrazione (intuizione) per induzione strutturale √® abbastanza easy. Nel caso dei casi finiti dovrei dimostrare che il singoletto e il vuoto sono finiti. Nel caso di parti composte, devo supporre che siano finite per le espansioni, allora l\u0026rsquo;unione di insiemi finiti √® ovvia\nIn realt√† la dimostrazione vera devi formalizzare prima il concetto di finito e non finito, che √® in teoria degli insiemi, quindi hai bisogno di molte altre cose.\n8.4.2 F in v usa restrizione di v al dominio Var(F) Posso creare una relazione di equivalenza se per ogni X in Var(F) ho che v(X) = v2(X) e ho che i due mondi sono uguali.\nChiamo solamente delle variabili di un mondo?\nDimo\nDimostrazione\nIn pratica sto collassando in una classe di equivalenza con il\nIl fatto che siano finiti mi permette di costruire tabelle di verit√†.\nNota\nGrazie a questo teorema posso dire che una variabile (proposizione) sia valida in tutti i mondi dipendentemente solamente dal valore di verit√† di una variabile al caso base.\nQuesto significa che le proposizioni logiche sono valide per tutti i mondi che soddisfino le precodizioni e non solamente nel mondo specifico! l valore di verit√† di una variabile al caso base.\nQuesto significa che le proposizioni logiche sono valide per tutti i mondi che soddisfino le precodizioni e non solamente nel mondo specifico!\n","permalink":"https://flecart.github.io/notes/connettivi-logici-correttezza-variabili/","summary":"8.1 Dimostrazione teorema invarianza 8.1.1 Introduzione Basi: Due proposizioni sono equivalenti quando valgono sugli stessi mondi.\nquindi $\\forall v, \\llbracket F \\rrbracket ^v \\equiv \\llbracket G \\rrbracket ^ v$.\nVogliamo dire che dati un buco presente in una proposizione, queste valgono sempre, sono in effetti equivalenti. Il buco la prendo come una variabile proposizionale. (riempire = rimpiazzare il buco)\n8.1.2 Operazione di sostituzione Si pu√≤ notare che ci sono 4 casi base, mentre le altre 4 sono per ricorsione strutturale.","title":"Connettivi Logici, correttezza, variabili"},{"content":"We have enormous state functions, having a generic approssimation could really help! We want to use a differentiable value function so that we can use gradient descent to optimize it, for example a good way of loss would be $$ J(w) = \\mathbb{E}_\\pi[(V^\\pi(s) - \\hat{V}^\\pi(s;w))^2] $$ The second one is parametrized with $w$. There are two ways (recuperali!) MC policy or Time differential (that is boostrapped, instead the Monte carlo uses a full simulation in order to know what to use). 2\n","permalink":"https://flecart.github.io/notes/function-approximation/","summary":"We have enormous state functions, having a generic approssimation could really help! We want to use a differentiable value function so that we can use gradient descent to optimize it, for example a good way of loss would be $$ J(w) = \\mathbb{E}_\\pi[(V^\\pi(s) - \\hat{V}^\\pi(s;w))^2] $$ The second one is parametrized with $w$. There are two ways (recuperali!) MC policy or Time differential (that is boostrapped, instead the Monte carlo uses a full simulation in order to know what to use).","title":"Function approximation"},{"content":"In order to understand language models we need to understand structured prediction. If you are familiar with Sentiment Analysis, where given an input text we need to classify it in a binary manner, in this case the output space usually scales in an exponential manner. The output has some structure, for example it could be a tree, it could be a set of words etc\u0026hellip; This usually needs an intersection between statistics and computer science.\nDefinition of a language model A language model is defined as a distribution over a $\\Sigma^{*}$ (See Descrizione linguaggio for the Kleene star and the alphabet). So it assigns probabilities to $y \\in \\Sigma^{*}$. Remember: every element in $\\Sigma^{*}$ is finite. This is important.\nBut we need to be careful about some details. As $\\Sigma^{*}$ is an infinite set it\u0026rsquo;s not trivial to define a probability distribution over it. This motivates us to have two other definitions\nGlobally normalized language models We define a scoring function $\\Sigma^{*} \\to \\mathbb{R}$ and the normalize it over all $y \\in \\Sigma^{*}$. We define a scoring function $s$. Then we can do the following:\n$$ p(y) := \\frac{\\exp(-s(y))}{\\sum_{y' \\in \\Sigma^{*}} \\exp(- s(y'))} := \\frac{1}{Z} \\exp(- s(y)) $$ The $Z$ is a sum over an infinite set, which is often difficult to compute. Sometimes it is computable instead.\nLocally normalized language models In this case, we try to take advantage of the structure of the strings, which is just a concatenation of the elements in an alphabet. We need a $EOS$ token and $BOS$ token in this case. Those are needed to model the starting symbol and the end symbol. Locally normalized language models model the conditional distribution $p(y \\mid \\boldsymbol{y})$ which means given a string $\\boldsymbol{y} \\in \\Sigma^{*}$ try to predict $y \\in \\Sigma$.\nGiven this model, then it is easy to define the probability of a string $\\boldsymbol{y} = y_{1}y_{2}\\dots y_{n}$ then we have $$ p(\\boldsymbol{y}) = p(y_{1} \\mid BOS) p(y_{2} \\mid BOS y_{1}) \\dots p(y_{n} \\mid \\boldsymbol{y}_{","permalink":"https://flecart.github.io/notes/language-models/","summary":"In order to understand language models we need to understand structured prediction. If you are familiar with Sentiment Analysis, where given an input text we need to classify it in a binary manner, in this case the output space usually scales in an exponential manner. The output has some structure, for example it could be a tree, it could be a set of words etc\u0026hellip; This usually needs an intersection between statistics and computer science.","title":"Language Models"},{"content":"Riguardare Successioni per avere primo attacco sui limiti\n4.1 Limiti finiti al finito 4.1.1 Intorno sferico Dato l\u0026rsquo;insieme $\\mathbb{R}$ si definisce l\u0026rsquo;intorno sferico aperto di $x \\in \\mathbb{R}$ di raggio $r \\in \\mathbb{R}$ l\u0026rsquo;insieme $I_r(x) = (x -r, x + r)$ questa nozione √® molto importante per definire il limite. Lo useremo subito su un punto di accumulazione\n4.1.2 Punto di accumulazione Un punto di accumulazione $x$ di un insieme $A \\subseteq \\mathbb{R}$ √® un punto tale per cui mi posso avvicinare in modo indefinito in quel punto. Infatti deve $\\forall r \u003e 0 \\in R, \\exists x_ 1 \\in A : x_1 \\in I_r(x) \\wedge x_1 \\not= x$ ossia per cui $A \\cap I_r(x) \\not= \\varnothing$.\nEcco che se mi avvicino in modo indefinito, possiamo definire per bene il limite tra poco.\n4.1.3 Accumulazione per successioni Un punto si pu√≤ definire di accumulazione per una successione $a_n$ se si ha che\n$\\lim_{n\\to\\infty} a_n = x$ con x punto di accumulazione. e $\\forall n \\in \\mathbb{N}, a_n \\not= x$\n4.1.4 Limite finito Questo √® il limite finito per una funzione\n$$ \\forall \\epsilon \u003e 0, \\exists \\delta \\in\\mathbb{R}: 0\u003c|x-x_0| \u003c \\delta \\implies |f(x) -y| \u003c \\epsilon $$ In pratica comunque prendo un valore vicino al valore y di limite, (quindi sto definendo la mia $\\epsilon$ deve esistere sempre un $\\delta$ tale che valga quella roba.\nLa soluzione tipica per la dimostrare di tale cosa √® partire dalla tesi e scomporla, trovare che se x appartiene a un certo intervallo continuo allora possono sempre trovare un sottoinsieme di questo intervallo che sia $\\delta$.\n4.2 Teoremi dei limiti 4.2.1 Permanenza del segno Se il limite positivo allora esiste un x per cui f(x) √® positivo, ma lo dovresti dimostrare (dovrebbe essere ovvio considerando l\u0026rsquo;intorno di $\\delta$ per cui vale $\\varepsilon$\nDimostrazione permanenza del segno Teorema dei Carabinieri Quando una funzione si possa schiacciare all\u0026rsquo;interno di due altre funzioni ha lo stesso limite. Questo in modo intuitivo ma si potrebbe fare anche molto di pi√π\u0026hellip;\n4.2.3 Alcuni limiti notevoli (!) $\\lim_{x\\to0}\\sin(x) = 1$ con i carabinieri per 0 e x $\\lim_{x\\to0} \\cos(x) = 0$ con duplicazione e altre osservazioni $\\lim_{x\\to0}\\dfrac{sin(x)}{x} = 1$ $\\lim_{x\\to0} \\dfrac{e^x - 1}{x} = 1$\nQueste sono i limiti notevoli di base per trigonometriche e esponenziali (o logaritmiche) Esistono anche alcuni limiti notevoli riguardanti il confronto fra le funzioni polinomiali, esponenziali o fattoriali.\nDimostrazione perimetro e area cerchio (!) Ti ricordi come si fa la dimostrare il valore dell\u0026rsquo;area e del perimetro del cerchio utilizzando il limite noto? Un modo semplice √® integrale, ed √® ci√≤ che ogni universitario che abbia studiato un poco di analisi farebbe.\n4.3 Limiti finiti all\u0026rsquo;infinito 4.3.1 Definizione Definiamo il limite di una funzione x tende a x_0 √® uguale a pi√π o meno infinito nel caso in cui:\n$$ \\lim_{x\\to x_0} f(x) = +\\infty \\iff \\forall M \\in \\R, \\exists \\delta : 0\u003c|x-x_0| \u003c \\delta \\implies f(x) \u003eM $$ In modo simile si pu√≤ dire per il limite che tende a un valore infinito negativo\n4.3.2 Limiti destri e sinistri √à molto simile alla definizione normale di limite, ma solo che invece di considerare un intorno completo di x debbo avere una parte, quindi invece di $0 \u003c \\lvert x-x_0 \\rvert\u003c \\delta$ ho che deve essere che $x_0 - \\delta \u003c x \u003c x_0$ per intorni sinistri e in modo simile per intorni destri ho che $x_0 \u003c x \u003c x_0 + \\delta$\nIl resto della definizione √® tutto uguale.\n4.3.3 Relazione limite e l destro e l sinistro Si potrebbe dimostrare questa propriet√†:\n$$ \\lim_{x \\rightarrow x_0} f(x)= L \\iff \\begin{cases} \\exists \\displaystyle{\\lim_{x \\to x_0^-}f(x)}, \\exists\\displaystyle{\\lim_{x \\to x_0^+}f(x)}\\\\ \\displaystyle{\\lim_{x \\rightarrow x_0^-}f(x)}=\\displaystyle{\\lim_{x \\rightarrow x_0^+}f(x)}=L \\end{cases} $$ 4.4 Limiti all\u0026rsquo;infinito Si possono trovare 3 casi:\n$\\forall \\varepsilon, \\exists \\delta= \\delta(\\varepsilon) \u003e 0 : \\forall x \\in A : x \u003e \\delta$\n$$ \\lim_{x\\to +\\infty} f(x) = \\begin{cases} l \\iff |f(x) - l| \u0026lt; \\epsilon \\ +\\infty \\\n\\infty \\end{cases} $$ 4.4.1 Esercizi algebra dei limiti 4.4.2 Limiti di polinomi Si dimostra che per limite di x tendente a x0 con la funzione lineare che √® uguale a x, poi si espande questo con i teoremi di algebra dei limiti e la moltiplicazione con le costanti in modo che il limite dei polinomi sia coincidente con il limite degli addendi moltiplicazioni e simili.\nCon la definizione di limite fatta in seguito si ha che tutti i polinomi sono continui nel proprio dominio naturale.\nFunzione continua Definizione $\\forall x_0 \\in A, A \\subseteq \\mathbb{R}$ allora deve essere che $x_0 \\not\\in D(A)$ con $D(A)$ l\u0026rsquo;insieme dei punti di accumulazione di A.\n$$ x_0 \\in D(A) \\implies \\lim_{x \\to x_0}f(x) = f(x_0) $$ con il limite definito come prima. E si scrive in questo modo $f \\in C(A)$, data una funzione nello spazio di funzione $A^\\mathbb{R}$\nOsservazioni La continuit√† di una funzione √® interessante perch√© definisce una regolarit√† della funzione. (anche se significa anche che possiamo tracciare la funzione senza lasciare la matita dal foglio).\n4.5.2 Continuit√† destra e sinistra Dalla definizione di funzione continua espansa si pu√≤ dedurre che\n$$ \\lim_{x \\to x_0}f(x) = f(x_0) \\begin{cases} \\exists\\lim_{x\\to x_0} f(x) \\\\ \\exists\\lim_{x\\to x_0^+} f(x),\\exists\\lim_{x\\to x_0^-} f(x),\\\\ \\lim_{x\\to x_0^+} f(x) = \\lim_{x\\to x_0^-} f(x), = \\lim_{x\\to x_0} f(x) \\end{cases} $$ 4.5.3 Continuit√† per inverse Dimostrazione (non richiesta) Non viene dimostrato ma, se √® definita una funzione continua per una certa funzione, allora √® continua anche la sua inversa. Per qualche motivo magico.\nQuesto teorema √® importante per la dimostrazione della derivabilit√† dell\u0026rsquo;inversa (quindi per avere una base per dimostrare la derivabilit√† dell\u0026rsquo;inversa\nTeorema degli zeri Lemmi preliminari per THZero Primo (dim)\nEnunciato sia data una successione bn appartenente a $\\R$ sempre positiva o sempre negativa tale che il limite di bn appartiene a $\\R$ allora il limite ha lo stesso segno della successione o √® nulla.\nSi dimostra per assurdo ponendo il limite il contrario (si apre poi il limite e si sceglie un epsilon carino che mi porti a questa contraddizione).\nSecondo (no dim)\nData una funzione da A a $\\R$, prendiamo x un punto di accumulazione di A tale che f sia continua in questo punto allora. Per ogni successione xn appartenente ad A che converga a x si ha che f(xn) tende a f(x)¬¥¬¥\nTHZero data una funzione continua in [a,b] in R allora se $f(a)f(b) \u003c 0 \\implies \\exists c \\in ]a,b[ : f(c) = 0$\nOssia, in modo intuitivo, dato un rettangolo tagliato da una linea, se prendo due punti nelle due parti, allora se provo a congiungere questi due punti si ha che deve tagliare la linea in almeno un punto.\nDIM\n$$ \\lim a_n = \\lim b_n = c\\\\ f(c) = 0 $$ Bisogna dimostrare queste due cose.\nSi utilizza una divisione diadica in due parti, un algoritmo di costruzione costruttiva.(se l\u0026rsquo;algoritmo finisce √® banale.\nVoglio costruire due successioni, una sempre negativa una sempre positiva, entrambi devono tendere a 0, cos√¨ lo trovo.\nPropriet√† di queste successioni\nDa queste propriet√† ho ottenuto che entrambe le successioni sono limitate e sono crescenti o decrescenti, quindi per dimostrazione precedente esiste un limite che non conosciamo.\nUna cosa molto interessare da considerare √® la successione\n$a_n - b_n = \\dfrac{a - b}{2^{n-1}}$ che tende a 0. Poi insieme al teorema di convergenza dei limiti.\n$a_n$ si pu√≤ dire che √® una approssimazione dal basso mentre $b_n$ √® una approssimazione dall\u0026rsquo;alto\nPoi utilizzando il lemma 1 e il lemma 2 si pu√≤ concludere che, dato c questo limite che $f(a_n) = f(c) \\leq 0$ e che $f(b_n) = f(c) \\geq 0$ e quindi abbiamo dimostrato che esiste $f(c) = 0$\nCostruttiva ‚Üí Ho un metodo di approssimazione\nTeorema degli Zeri e polinomi Nei polinomi di grado dispari si pu√≤ notare che il limite del polinomio che tende a +infinito va a +infinito, uguale il contrario, grazie al thzero si pu√≤ concludere che deve avere necessariamente uno zero (si pu√≤ dimostrare anche la continuit√† di questo! √à algebra dei limiti)\nOgni polinomio di gradi dispari ha almeno una radice Reale.\nWeierstrass e Valore intermedio Weierstrass (Estremi finiti) Studia il concetto di punto di massimo o minimo assoluto. In particolare dice che esistono quei due punti per funzioni:\nDominio limitato e chiuso Funzione continua Sia data una $f: \\left[ a, b \\right] \\to \\mathbb{R}$ tale per cui sia continua. Allora esistono massimo e minimo globale per la funzione. Ossia: $$ \\exists x_{0} \\in \\left[ a, b \\right] : f(x) \\leq f(x_{0}), \\forall x \\in \\left[ a, b \\right] $$ E stessa cosa per il minimo.\nLa dimostrazione non √® data. Ma √® una propriet√† che molti direbbero che sia intuitivamente vera. Andare a dimostrarla si entrerebbero in tecnicismi inutili secondo me. Nel caso puoi sempre approfondirla nella pagina wikipedia associata.\nWeierstrass riformulato Quello che dice in pi√π √® che l\u0026rsquo;immagine della funzione coincide con il massimo e minimo assoluto.\nSi dovrebbe dimostrare con Weiestrass di prima e thzeri.\n$\\forall y \\in codominio, \\text{considero } g(x) = f(x) - y$ e poi utilizzo il teorema degli zeri per dire che esiste un x per cui $g(x) = 0 \\iff f(x) = y$ e quindi ho trovato un x per cui vale.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Limiti/Untitled 6.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Limiti/Untitled 6\u0026quot;\u0026gt; Teorema del valore intermedio Questo √® anche chiamato intermediate value theorem. Lo abbiamo utilizzato per dimostrare qualcosa di molto breve su\nLa dimostrazione √® equivalente a Weierstrass riformulato.\n","permalink":"https://flecart.github.io/notes/limiti/","summary":"Riguardare Successioni per avere primo attacco sui limiti\n4.1 Limiti finiti al finito 4.1.1 Intorno sferico Dato l\u0026rsquo;insieme $\\mathbb{R}$ si definisce l\u0026rsquo;intorno sferico aperto di $x \\in \\mathbb{R}$ di raggio $r \\in \\mathbb{R}$ l\u0026rsquo;insieme $I_r(x) = (x -r, x + r)$ questa nozione √® molto importante per definire il limite. Lo useremo subito su un punto di accumulazione\n4.1.2 Punto di accumulazione Un punto di accumulazione $x$ di un insieme $A \\subseteq \\mathbb{R}$ √® un punto tale per cui mi posso avvicinare in modo indefinito in quel punto.","title":"Limiti"},{"content":"Introduction Semantic segmentation Vorremo trovare regioni che corrispondano a categorie diverse. E dividere in questo modo l‚Äôimmagine secondo zone di informazione.\nObject detection Vogliamo trovare il pi√π piccolo box che vada a contenere l‚Äôoggetto. Questo √® fatto con il bounding box.\nIn questo caso la funzione di loss √® un p√≤ pi√π difficile da definire, si utilizza la funzione intersection over union con le aree, in pratica la percentuale di immagine comune diciamo.\nDeep object detection (2) Region proposals\nQuesta √® una versione che prova a catturare le regioni di interesse all‚Äôinterno della nostra immagine. (pi√π o meno non sa cosa sia l‚Äôoggetto, ma sa che c‚Äô√® qualcosa in quella zona). Poi questa regione di interesse √® passata in un secondo step che va a riconoscere cosa √® presente in quella immagine. (la regione di interesse era presente anche prima di CNN).\nSIngle shots\nQuesti sono pi√π veloci dei precedenti, quindi sono buoni per applicazioni real time.\nYOLO You Only Look Once intro https://pjreddie.com/darknet/yolo/\nhttps://towardsdatascience.com/yolo-v4-or-yolo-v5-or-pp-yolo-dad8e40f7109\nProva a trovare il bounding box con la predizione con una singola passata! CNN per individuare i boxes, poi algoritmicamente per cancellare i boxes.\nMain Idea FUNZIONAMENTO\nFa delle predizioni, che sono dei bounding box con dei labels (espressi attraverso una probabilit√†).\nDopo avevi un certo numero di neuroni dopo aver fatto downsampling (queste hanno visisione solamente di una zona limitata dell‚Äôimmagine).\nL‚Äôidea principale √® allenare il singolo neurone a riconoscere l‚Äôoggetto (wtf hoooow). E ignorare tutti i resti dei neuroni (si fa con una mask in qualche modo).\nOutput format Slide formato dell‚Äôoutput\nSi deve tenere molte informazioni (i punti, lo score, e un valore di score per tutte le classi).\nSolitamente si parte da un anchor box di dimensioni fisse (width e height). I valori di ritorno sono un displacement dal centro in entrambe le direzioni e un fattore di deformazione per ogni direzione.\nLoss function Localization loss function\nLa loss di localizzazione non √® altro che una differenza\nNota: c‚Äô√® una binary map, che che √® in una cella e 0 in tutto il resto (questo per dire che il neurone vuole predire solamente quello che gli sta intorno, il resto lo ignora tutto).\nClassification loss\n!\n","permalink":"https://flecart.github.io/notes/object-detection/","summary":"Introduction Semantic segmentation Vorremo trovare regioni che corrispondano a categorie diverse. E dividere in questo modo l‚Äôimmagine secondo zone di informazione.\nObject detection Vogliamo trovare il pi√π piccolo box che vada a contenere l‚Äôoggetto. Questo √® fatto con il bounding box.\nIn questo caso la funzione di loss √® un p√≤ pi√π difficile da definire, si utilizza la funzione intersection over union con le aree, in pratica la percentuale di immagine comune diciamo.","title":"Object Detection"},{"content":"Vorremmo cercare di stabilire una teoria riguardante programmi che vengono eseguiti appunto concorrentemente, senza una esecuzione classica uno dpo l‚Äôaltro\nEsempio mini-programma rallentamento\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; void test(void *s) { for (int i = 0; i \u0026lt; 10; i++) { printf(\u0026#34;%s\\n\u0026#34;, s); for (int j = 0; j \u0026lt; 100000000; j++); } } int main(int argc, char *argv[]) { pthread_t t1, t2; pthread_create(\u0026amp;t1, NULL, (void *)test, \u0026#34;Uno\u0026#34;); pthread_create(\u0026amp;t2, NULL, (void *)test, \u0026#34;Due\u0026#34;); pthread_join(t1, NULL); pthread_join(t2, NULL); } Example output:\nDue Uno Uno Due Uno Due Due Uno Due Uno Due Uno Due Uno Due Uno Due Uno Due Uno\nEsempio 2 mini-programma rallentamento\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; int count = 0; void test(void *s) { for (int i = 0; i \u0026lt; 100000; i++) { count+= 1; } } int main(int argc, char *argv[]) { pthread_t t1, t2; pthread_create(\u0026amp;t1, NULL, test, \u0026#34;Uno\u0026#34;); pthread_create(\u0026amp;t2, NULL, test, \u0026#34;Due\u0026#34;); pthread_join(t1, NULL); pthread_join(t2, NULL); printf(\u0026#34;%d\\n\u0026#34;, count); } Vogliamo creare un modello teorico che riesca a rappresentare il concetto di processi concorrenti, questo √® il modello concorrente\nProcessi Differenza col programma üü© Il programma √® statico, mentre il programma √® dinamico. Questo perch\u0026rsquo;e il processo √® un programma attivo, in esecuzione. Un filo esecutivo, qualcosa che evolve in modo autonomo.\nInvece il programma √® la sequenza di istruzioni.\nFinite progress üü© Ogni processo viene eseguito a velocit√† finita non nulla\nDescrizione del processo (3) üü© Questa parte √® descritta meglio in Processi e thread\nPossiamo descrivere lo stato di un processo memorizzando alcuni dati molto precisi, questi sono:\nStato di avanzamento (Istruzione da eseguire e il suo stato) La sua memoria utilizzata (dati, stack e file aperti) Memoria nel processore (i dati nel registro e simili) Concorrenza Concorrenza e dove trovarla\nDefinizioni concorrenza e Race C üü© Esecuzione concorrente\nDue processi si dicono in esecuzione concorrente se vengono eseguiti in parallelo (con parallelismo reale o apparente)\nConcorrenza\nUn insieme di notazioni e tecniche per rappresentare e risolvere problemi di esecuzione concorrente.\nRace condition\nSi dice che un sistema di processi multipli presenta una race condition qualora il risultato finale dell\u0026rsquo;esecuzione dipenda dalla temporizzazione con cui vengono eseguiti i processi\nTipologie di concorrenza (3) üü© Multiprogramming\n√à un parallelismo apparente perch√© la CPU √® solamente quella, ma esegue tante cose e cos√¨ velocemente che sembra star eseguendo in modo parallelo. Si parla infatti di interleaving.\nMultiprocessing\nparallelismo reale perch√© effettivamente ho tante CPU, o tanti core in cui far eseguire programmi in modo contemporaneo, in questo caso, come anche nell\u0026rsquo;esempio seguente si parla di overlapping (distanti nello spazio)\nDistributed processing\nParallelismo reale ma a una scala pi√π grande che va oltre al singolo computer dato che ho un sistema di pi√π computer che eseguono pi√π processi\nEsempio di problema di concorrenza üü©- Codice slide cattivo\nSuccede un problema molto simile a read after write, che un programma ha uno stato non aggiornato e fa una operazione con informazioni vecchie che sovrascrivono le informazioni nuove.\nEsempio multiprogramming di esecuzione errata\nEsempio multiprocessing di esecuzione errata\nPossiamo andare a cercare le cause di questi problemi, che sono principalmente causati da\nCause principali (comuni a multiproc e multiprog)\nAccesso a memoria condivisa Sconosciuta velocit√† di esecuzione del singolo processo. Interazione fra progressi(2)üü© Vogliamo cercare di avere alcuni metodi affinch√© due processi differenti si possano coordinaree cooperare.\nConoscenza indiretta\nQuando condividono un pezzo di memoria e comunicano in questo modo indiretto.\nConoscenza diretta\nQuando un processo conosce un ID di un altro processo e manda proprio dei messaggi e cose all‚Äôaltro programma\nPropriet√† cooperazione (2) üü©- Propriet√† vogliamo dire una caratteristica che rimane vera per ogni esecuzione del programma, come se fosse un teorema per il programma.\nSafety ‚Üí Correttezza\nVuol dire che il programma non fa cose cattive (se pu√≤ scegliere fra due valori, devono scegliere lo stesso valore).\nun programma non interferisce con un altro.\nLiveness ‚Üí Terminazione\nOssi ail programma continua ad eseguire rimane vivo e ritorna il suo risultato e fa quello che deve fare (ossia deve arrivare a soluzione).\nUn programma non deve essere interrotto ininterrottamente (ossia non deve continuare all\u0026rsquo;infinito) (possiamo dire che non c\u0026rsquo;√® starvation in questa parte).\nMutua esclusione, Deadlock e starvation üü© l\u0026rsquo;accesso ad una risorsa si dice mutualmente esclusivo se ad ogni istante, al massimo un processo pu√≤ accedere a quella risorsa\nDeadlock\n√à un problema che √® risolto dalla mutua esclusione (in cui due programmi interferiscono fra di loro e causano questo blocco).\nDa vedere l‚Äôesempio dei programmi\nEsempio in figura degli incroci\nEsempio programmi\nStarvation\n√à un problema di liveness dato che pu√≤ capitare che un processo sia sempre messo davanti a un altro, e quindi un certo programma non verrebbe mai eseguito.\nEsempio coda\nEsempio programmi\nAzioni atomiche üü© Propriet√†:\nIndivisibile O avviene o non avviene niente Nel linguaggio c in particolare, dipende da processore e compilatore (perch√© potrebbe utilizzare istruzioni che non si traducono in una singola in codice macchina).\nEsempi atomicit√† di istruzioni in C\nParallelismo reale\nquesta azione atomica non interferisce con altri\nAl fine di raggiungere questo obiettivo viene utilizzato un sistema di arbitraggio dei bus. (quindi un processo prende prima dell‚Äôaltro).\nParallelismo apparente\nil context switch avviene prima o dopo l‚Äôazione. Questo √® possibile perch√© l‚Äôinterrupt √® sempre runnato prima o dopo quell‚Äôazione.\nNote sul C (non importante, + pratica) Inizialmente questo linguaggio √® nato proprio per scrivere sistemi operativi, non si scrive in assembly perch√© questo linguaggio non √® portabile su macchine diverse.\nCaratteristiche di linguaggio per SO Possibilit√† di gestione completa dei dati nella memoria. Leggibilit√† di un linguaggio di alto livello https://so.v2.cs.unibo.it/wiki/index.php/Prin_C_ples\nEsempietto boostrap\nEsperimento didattico: portabilit√† dei compilatori\nHo un linguaggio di alto livello L, e una macchina fisica M e una macchina intermedia N, vorrei fare un compilatore da L a M.\nAllora ho un compilatore da L a M che gira in N molto scrauso. Mi scrivo il compilatore da L a M che gira in N, lo compilo e ho un compilatore da L a M scritto in M\n","permalink":"https://flecart.github.io/notes/programmi-concorrenti/","summary":"Vorremmo cercare di stabilire una teoria riguardante programmi che vengono eseguiti appunto concorrentemente, senza una esecuzione classica uno dpo l‚Äôaltro\nEsempio mini-programma rallentamento\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; void test(void *s) { for (int i = 0; i \u0026lt; 10; i++) { printf(\u0026#34;%s\\n\u0026#34;, s); for (int j = 0; j \u0026lt; 100000000; j++); } } int main(int argc, char *argv[]) { pthread_t t1, t2; pthread_create(\u0026amp;t1, NULL, (void *)test, \u0026#34;Uno\u0026#34;); pthread_create(\u0026amp;t2, NULL, (void *)test, \u0026#34;Due\u0026#34;); pthread_join(t1, NULL); pthread_join(t2, NULL); } Example output:","title":"Programmi Concorrenti"},{"content":"Introduzione Concetto principale üü©- √à sempre stato introdotto da Dijkstra, 1965 (Cooperating Sequential Processes) utilizzato come strumento di cooperazione semplice\nQuesto √® un sistema fortemente ispirato dai semafori che regolano gli incroci stradali.\ndue o pi√π processi possono cooperare attraverso semplici segnali, in modo tale che un processo possa essere bloccato in specifici punti del suo programma finch√© non riceve un segnale da un altro processo\nPrimitive dei semafori üü©- Il semaforo solitamente √® una variabile intera non negativa.\nV anche chiamao sem_wait.\nDa verhogen utilizzata per rilasciare una risorsa. Di solito √® implementata aumentando il valore di un semaforo.\nP, anche chiamato sem_post.\nDa proberen per attendere evento o rilascio di una risorsa. Di solito √® implementata decrementando il valore del semaforo solo se √® positivo non nullo.\nInvarianti per i semafori (!!!)\nSlide invarianti\nImplementazione classica della CS üü© Programma concorrente con semafori per CS\nImplementazione classica di P e V (ricordare da metterle nella CS)\nSi pu√≤ notare che tutte le 4 propriet√† espresse per la concorrenza sembrano essere soddisfatte.\nOltre a questo bisogna avere una struttura di dati (Queue) che tenga conto dei processi che stanno aspettando la risorsa dietro questo semaforo, in modo da poter ricominciare.\nSi potrebbe in questo caso anche disabilitare l\u0026rsquo;interrupt! Perch√© tanto ora non √® dentro lo scope del programmatore, √® dentro lo scope del semaforo! Per i multicore si possono utilizzare le soluzioni trattate in parti precedenti.\nVantaggi dei semafori üü© Fairness data dalla politica FIFO utilizzata per la struttura di dati della coda\nSlide\nBusy waiting molto minore\nInterleaving controllato? Boh non ho capito il concetto di questa frase\nSemafori binari Descrizione generale üü© Sono semafori che possono solamente avere come valore 0 e 1.\nTODO: dire anche cosa succede per l‚Äôattesa dei due‚Ä¶\nImplementazione üü©- Implementazione semaforo binario\nI semafori binari ci garantiscono mutua esclusione\nSemafori binari equiv. semafori normali üü© Implementazione dei semafori con semafori binari üü©\nImplementazione di semafori binari con semafori üü©\nProblemi classici Producer consumer üü© Abbiamo due agenti, un programma che produce una risorsa e un agente che la consuma. Questa comunicazione di disponibilit√† di un valore avviene attraverso una singola variabile condivisa.\nPropriet√† importanti\nProducer non pu√≤ scrivere la zona di memoria comune prima che il consumer l\u0026rsquo;abbia consumato Consumer non deve leggere due volte la stessa cosa. No deadlock n√© starvation In questo caso sono come delle sezioni critiche alternate passing the baton perch√© √® come se passasse il testimone, e vanno avanti in modo alternato.\nSoluzione\nLimited Buffer üü© La descrizione del problema √® molto simile, la differenza √® che si utilizza un buffer condiviso per lo scambio di informazioni, non una singola variabile, il resto delle propriet√† √® molto simile.\nSoluzione\nOsservazioni personali\nNon c\u0026rsquo;√® deadlock perch√© si bloccherebbero assieme solo se sia empty sia full sono 0, ma questo sarebbe un problema di inizializzazione. Dining philophers üü©- Ho 5 filosofi intorno a una tavola che devono acquisire le due bacchette (risorse condivise) per mangiare, altrimenti pensano.\nInvarianti\nResource hierarchy solution\nSoluzione\nIn questa soluzione si crea una gerarchia di priorit√† per chi deve acquisire la fork, con una rottura di simmetria per l‚Äôultima.\nIl problema √® che non √® libero da starvation.\nPagina wiki\nAltre soluzioni\nOsservazioni personali\nCredo ci sia starvation perch√© non c\u0026rsquo;√® niente che mi garantisca che non ci sia.\nRoba da buttare, riguardo dining\nPseudocodice per il problema dei dining filosophers che utilizza il token, e la struttura ad anello inizializza 5 semafori, solo uno sar√† a 1 sar√† quello attivo direi. 5 booleani che indicano la disponibilit√†. inizializzo 5 numeri che identificano il numero delle volte che si ha mangiato Alla fine di ogni ciclo di mangiata viene incrementato il numero, e questo numero viene incrementato solamente da un unico thread, quello di un certo filosofo, quindi non devo metterci il mutex, o forse s√¨??. Quindi fra gli attivi voglio solamente chi ha il token e chi pu√≤ mangiare. bool done = false; while (!done): waiting_for_token = true, // anche done pu√≤ essere utilizzato come waiting for token. [enter CS] if (disponibile left): prendi left if (disponibile right): prendi right waiting_for_token = false; // done = true qui, invece che sotto. make calls to take left and right. else: release left [exit CS] if (has both forks): eat() releaseLeft() signal left is available releaseRight() signal right is available done = true; else: go to sleep (try again lather, if not done)) passtoken to next waiting for token. - somebody is waiting for token if 1. Is not eating 2. Has not finished Quindi ci metto il check booleano sopra. Readers and writers üü©- Questo √® uno dei problemi pi√π importanti, adremo in seguito a sviluppare il concetto di awaiting.\nCi sono due tipi di processi che devono leggere un database. I lettori accedono al database per leggerlo, gli scrittori per scriverlo, fatto √® che i lettori possono leggere quanto vogliono, quando per√≤ uno ci vuole scrivere, nessun altro ci pu√≤ andare a leggere.\nUn solo scrittore, che blocca tutti\nSe nessuno scrive tutti possono leggere.\nInvarianti da rispettare\nSoluzione Readers and Writers con semafori\nStarvation degli scrittori\nQuesta soluzione ha il drawback del fatto che starvation per i scrittori.\nQuesta √® una soluzione che funziona ma vorremmo trovare un metodo per descrivere tutti i problemi con await, in modo molto clean.\nPriorit√† ai scrittori con await framework üü®+ Vogliamo in questa parte trattare di una soluzione che non metta in starvation gli scrittori, ma mette in starvation i lettori in questo caso.\nSlide soluzione\nLa soluzione √® quasi la stessa, ma si cambia la condizione di entrata per i lettori che sar√† quando non c\u0026rsquo;√® nessun scrittore che sta scrivendo e nemmeno nessuno che sta aspettando di scrivere.\nScegliere quale soluzione utilizzare dipende molto dall‚Äôambiente in cui stiamo, dipende se vogliamo pi√π gente che scriva o pi√π gente che legga (di solito per un database c\u0026rsquo;√® molta gente ch elegge e poca che scrive).\nProblema del barbiere addormentato Slide\nFramework per semafori Andiamo in questa parte a creare un framework generale per la discussione di problemi con await con i semafori.\nFramework semafori Andrews (4) üü®- Notazione con Await (2) üü®+ Notazione (andrews Await)\nQuindi la sintassi diventa di due parametri in particoalre\nStatement atomico Statemento atomico con await su una condizione booleana. Molto interessante notare che √® questo ci√≤ che stato implementato con Javascript! Ed √® una cosa molto clean questo paradigma :D.\nSoluzione readers and writers con await (generale)\nSi noti che questa soluzione √® equivalente alla soluzione dei semafori, ma √® scritta in modo molto pi√π clean.\nImplementazione await con semafori üü© Note sulle variabili di implementazione\nLe note principali sono i semafori e i waiting.\nImplementazione in slide\ni quadrati sono degli if non deterministici, nel senso che posso riordinarli come mi pare e sarebbe comunque apposto\nSu signal, ci d√† un idea di quanti processi possono andare avanti dato un cambiamento di stato.\nLa modifica sul waiting[i]- - non √® un write non protetto??? No perch√© sempre passaggi di testimoni! Siamo sempre in una sezione critica, ma divisa fra pi√π processi grazie a questo meccanismo passing the baton.\nInfatti √® per questo che possono fare waiting[i]- - senza apparentemente essere in mutua esclusione!.\nNota che sembra interessante √® che questo baton viene continuamente passato da processo a un altro da signal ad un altro finch√© non posso pi√π fare signal.\nNota sui passaggi di testimoni\nLa mutex √® sempre rilasciata attraverso la tecnica del passing the baton, in qui il mutex √® rilasciato da processi diversi, si pu√≤ espandere su molti processi diversi la mutua esclusione‚Ä¶ Cavolo per√≤ credo sia molto difficile sbagliarci qualcosa no? boh.\nReaders and writers con await (!) üü®- Slide soluzione\nSoluzione in singola slide (e con signal ottimizzato)\nConsiderazioni finali (3) üü® I semafori pongono forti problemi di leggibilit√† dato che sono costrutti a basso livello sparsi in mezzo al codice.\n√à possibile inoltre compiere errori stupidi in modo molto facile, come scambiare P o V, omettere Po V.\nE pone un sacco di responsabilit√† sul prorammatore che deve gestire lui in modo corretto le risorse e definire gli accessi.\n","permalink":"https://flecart.github.io/notes/semafori/","summary":"Introduzione Concetto principale üü©- √à sempre stato introdotto da Dijkstra, 1965 (Cooperating Sequential Processes) utilizzato come strumento di cooperazione semplice\nQuesto √® un sistema fortemente ispirato dai semafori che regolano gli incroci stradali.\ndue o pi√π processi possono cooperare attraverso semplici segnali, in modo tale che un processo possa essere bloccato in specifici punti del suo programma finch√© non riceve un segnale da un altro processo\nPrimitive dei semafori üü©- Il semaforo solitamente √® una variabile intera non negativa.","title":"Semafori"},{"content":"Intuition The most important observation that allows Fourier series approximation is that given $k = 1, 2, \\dots$ we have that $$ \\frac{1}{\\sqrt{ 2\\pi }}, \\frac{\\cos(kx)}{\\sqrt{ \\pi }}, \\frac{\\sin(kx)}{\\sqrt{ \\pi }}, \\dots $$ Form a infinitely dimensional orthonormal basis given the integral relations $$ \\int_{0}^{2\\pi} (\\sin (kx))^{2} \\, dx = \\int_{0}^{2\\pi} (\\cos(kx))^{2} \\, dx = \\pi $$ $$ \\int_{0}^{2\\pi}\\sin(kx)\\sin(hx) \\, dx = \\int_{0}^{2\\pi}\\cos(kx)\\cos(hx) \\, dx = 0 $$ And that $$ \\int_{0}^{2\\pi}\\sin(kx)\\cos(hx) \\, dx = \\int_{0}^{2\\pi} \\sin(kx) \\, dx = \\int_{0}^{2\\pi}\\cos(hx) \\, dx = 0 $$ Proofs of the relations In this section we quickly prove why the above equations hold. First we all agree that $\\int_{0}^{2\\pi} \\sin(kx) \\, dx = \\int_{0}^{2\\pi} \\cos(hx) \\, dx = 0$ because their period divides $2\\pi$ and the sum of the area of a period is clearly 0. Or we can explicitly find the primitive and solve\n$$ \\int_{0}^{2\\pi} \\sin(kx) \\, dx = -\\frac{1}{k} \\cos(kx) \\bigg\\vert_{0}^{2\\pi} = 0 - 0 $$ Equivalently the other part with the cosine.\nFor the other relations we need to remember some trigonometric identities:\n$\\sin(kx)\\cos(hx) = \\frac{1}{2}\\left[ \\sin(kx + hx) + \\sin(kx - hx) \\right]$ And if we solve now the integral we can see that $$ \\int_{0}^{2\\pi} \\sin(kx) \\cos(hx) \\, dx = \\frac{1}{2} \\left[ \\int_{0}^{2\\pi} \\sin((k + h)x) \\, d + \\int_{0}^{2\\pi}\\sin((k - h)x) \\, dx \\right] $$ $$ = = \\frac{1}{2}\\left[ \\frac{-1}{k + h} \\cos((k + h)x)\\bigg\\vert_{0}^{2\\pi} + \\frac{-1}{k - h} \\cos((k - h)x) \\bigg\\vert_{0}^{2\\pi} \\right] = \\frac{1}{2} (0 + 0) $$ Same thing with the others but we use the identities $$ \\sin x \\cdot \\sin y = \\frac{1}{2}\\left[ \\cos(x - y) - \\cos(x + y) \\right] $$ And $$ \\cos x \\cdot \\cos y = \\frac{1}{2} \\left[ \\cos(x - y) + \\cos(x + y) \\right] $$ And then you can prove every relation.\nFourier Series This allows us to define the projection $S_{n}$ of every function $f$ onto that basis. Defined as $$ S_{n}f = \\sum_{i=0}^{2n} \\langle f, e_{i} \\rangle e_{i} $$ Which is explicitely: $$ S_{n}f(x) = \\left( \\int_{0}^{2n} \\frac{1}{\\sqrt{ 2\\pi }} f(t) \\, dt \\right) \\frac{1}{\\sqrt{ 2\\pi }} + \\sum_{k=1}^{n} \\left[ \\left( \\int_{0}^{2n} \\frac{\\cos(kt)}{\\sqrt{ \\pi }} f(t) \\, dt \\right) \\frac{\\cos(kx)}{\\sqrt{ \\pi }} + \\left( \\int_{0}^{2\\pi} \\frac{\\sin(kt)}{\\sqrt{ \\pi }}f(t) \\, dt \\right) \\frac{\\sin(kx)}{\\sqrt{ \\pi }} \\right] $$ Which could be rewritten as follows (called Fourier Series): $$ S_{n}f(x) = \\frac{1}{2}a_{0} + \\sum_{k=1}^{n}(a_{k}\\cos(kx) + b_{k}\\sin(kx)) $$ With $a_{k} = \\frac{1}{\\pi}\\int_{0}^{2\\pi} f(t) \\cos (kt) \\, dt$ and $b$ equivalently. these $a, b$ are called Fourier coefficients of $f$. We call $S_{n}f(x)$ nth Fourier sum\nProperties of the Fourier Series Norm of the Fourier Series We assert that $$ \\lVert S_{n} f \\rVert ^{2} = \\pi \\left[ \\frac{a_{0}^{2}}{2} + \\sum_{k = 1}^{n} (a_{k}^{2} + b_{k}^{2}) \\right] $$ In this case the definition of the norm squared is as follows: $$ \\lVert S_{n}f \\rVert^{2} = \\int_{0}^{2\\pi} \\lvert S_{n}f \\rvert ^{2} \\, dx $$ And then it is far easier to derive.\n","permalink":"https://flecart.github.io/notes/fourier-series/","summary":"Intuition The most important observation that allows Fourier series approximation is that given $k = 1, 2, \\dots$ we have that $$ \\frac{1}{\\sqrt{ 2\\pi }}, \\frac{\\cos(kx)}{\\sqrt{ \\pi }}, \\frac{\\sin(kx)}{\\sqrt{ \\pi }}, \\dots $$ Form a infinitely dimensional orthonormal basis given the integral relations $$ \\int_{0}^{2\\pi} (\\sin (kx))^{2} \\, dx = \\int_{0}^{2\\pi} (\\cos(kx))^{2} \\, dx = \\pi $$ $$ \\int_{0}^{2\\pi}\\sin(kx)\\sin(hx) \\, dx = \\int_{0}^{2\\pi}\\cos(kx)\\cos(hx) \\, dx = 0 $$ And that $$ \\int_{0}^{2\\pi}\\sin(kx)\\cos(hx) \\, dx = \\int_{0}^{2\\pi} \\sin(kx) \\, dx = \\int_{0}^{2\\pi}\\cos(hx) \\, dx = 0 $$ Proofs of the relations In this section we quickly prove why the above equations hold.","title":"Fourier Series"},{"content":"What is it for Estimation Sampling generate numbers from any distribution! (distributions are important in statistics). Density Cumulative distribution (and others similar). Optimization how to find computationally the min and max of functions. Generating?\nRandom (difficile anche filosoficamente definire cosa significa questo). Molto importante perch√© si assume in Comp stats che abbiamo il random vero, e questa assunzione che non vale pu√≤ rompere cose. And independent Sample proportion Average of something (example of the lake cannonball).\nFiga la possibilit√† di fare sampling secondo una distribuzione, partendo dalla $U$.\nLista delle nozioni Generalized inverse definition.\nFai la dimostrazione della generalized inverse transform (non dovrebbe essere tanto difficile, una volta che enunci quanto importante dovrebbe andare liscio).\nCosa dice la inverse transform? Perch√© possiamo partire dalla distribuzione uniforme?\nIn che modo √® relazionato la distribuzione $\\exp$ con chi squared, gamma e beta distribution?\nGeneralized transform formula (not in the exam, serve per avere le densit√† e non la CDF) üü•, non ho proprio capito perch√© funziona, in questo corso si impara solo ad imparare a memoria ed applicare queste cose.\nCome fare sampling fra distribuzioni discrete (che √® la soluzione idiota).\nSampling discrete from long tail distributions.\nExplain and use the accept reject method.\nProbabilit√† di accettazione, sia normalizzato che non normalizzato.\nFare gli esercizi a fine capitolo due per accept reject. (registrazione 7 primi 50 minuti parlano di questo).\nGuardare meglio l\u0026rsquo;esempio 3.4 per l\u0026rsquo;importance sampling (e la roba dei tail sampling).\nMinuto 52 Lecture 11, ci sono gli esercizi dispari del capitolo 3.\nFino a Lecture 12 minuto 48 ci sono altri esercizi.\nCose pratiche Essere in grado di implementare grafico e calcolare i valori per la inverse (esattamente quelli). ","permalink":"https://flecart.github.io/notes/introduction-to-computational-statistics/","summary":"What is it for Estimation Sampling generate numbers from any distribution! (distributions are important in statistics). Density Cumulative distribution (and others similar). Optimization how to find computationally the min and max of functions. Generating?\nRandom (difficile anche filosoficamente definire cosa significa questo). Molto importante perch√© si assume in Comp stats che abbiamo il random vero, e questa assunzione che non vale pu√≤ rompere cose. And independent Sample proportion Average of something (example of the lake cannonball).","title":"Introduction to computational statistics"},{"content":"Tutta sta parte si fa in modo formale in Sistemi Lineari e determinanti, quindi potresti saltarla totalmente\nEquazioni lineari L\u0026rsquo;obiettivo dell\u0026rsquo;algebra lineare √® risolvere n equazioni con n sconosciuti di primo grado. Cosa che ci riesce con grandissimo successo! Andiamo ora a definire meglio cosa √® una equazione lineare\nDefinizione Una equazione lineare √® una equazione a coefficienti appartenenti a un certo campo (che pu√≤ essere R) e incognite il cui grado √® 1 e che siano indipendenti:\nes.\n$$ a_1x_1 + a_2x_2 +...+a_nx_n=b $$ lo puoi considerare come una equazione lineare, mentre cose come\n$$ \\begin{cases} x^2 = 2 \\\\ xy = 2 \\\\ \\end{cases} $$ Non lo sono.\nEquivalenza e compatibilit√† Equivalenza: due sistemi sono equivalenti quanto hanno le stesse soluzioni\nCompatibilit√†: Un sistema si dice compatibile quando ammette soluzioni\nSoluzione di una equazione lineare Una soluzione di una equazione lineare a n variabili, √® una n-tupla di valori ordinati che soddisfano l\u0026rsquo;equazione. La cosa che ci interesser√† sar√† la soluzione di un sistema di equazioni lineari ovvero tante equazioni lineari che vogliono essere tutte soddisfatte allo stesso momento.\nPropriet√† dell‚Äôuguaglianza √à molto importante per comprendere le equazioni comprendere le due propriet√† dell\u0026rsquo;uguaglianza che si studiano di solito alle medie.\nSono due, una per la somma e una per la moltiplicazione scalare.\nSomma: Data una eguaglianza a = b, questa √® uguale sse per ogni c, c + a = c + b. Moltiplicazione scalare: Data una eguaglianza a = b, questa √® uguale sse per ogni c si ha ca = cb (la prof ha tolto il caso in c = 0) Le matrici Definizione Potremmo definire la matrice solamente come una tabella che contiene dei numeri, a volte nemmeno si d√† il nome di tabella, ma solamente come una collezione indicizzata di coefficienti.\npotresti definire matrice cos√¨ $M = (a_{ij})_{nm}$\nIn genere una matrice di dimensione nxm si scrive in notazione sul campo su cui √® definito, per esempio\n$M_{n \\times m}(\\R)$, se √® quadrata di solito si sottindende l\u0026rsquo;altra dimensione e si scrive $M_n(\\R)$.\nVettori riga e colonna Si potrebbero definire dei vettori riga e colonna a seconda delle dimensioni della matrice: di dimensione $1\\times n$ sono vettori riga di dimensione $n\\times_{1}$ sono vettori colonna Questi vettori sono importanti poi per scomporre la matrice, quindi ora basta tenerli a mente\nCostruzione della somma e prodotto scalare Possiamo sempre fare la somma di due matrici con le stesse dimensioni definite sullo stesso campo.\nSomma Infatti se prendiamo A e B , la matrice somma C √® la matrice costituita dalla somma elemento per elemento (somma per indici corrispondenti).\nScalare Per il prodotto scalare moltiplichiamo ogni elemento della matrice per quel coefficiente.\nProdotto matriciale Questo prodotto fra matrici √® pi√π complessa rispetto alla somma e il prodotto. (√à utile perch√© le matrici rappresentano una trasformazione nello spazio, questo prodotto rappresenta la composizione fra le funzioni che rappresentano).\nTratto da wikipedia\nQuindi vogliamo avere che il numero delle colonne del primo sia uguale al numero delle righe del secondo. Questo √® soddisfatta questa condizione possiamo sempre fare la moltiplicazione. Lo facciamo cos√¨, consideriamo il risultato fra il prodotto del vettore riga i con il vettore colonna j, questo √® un prodotto scalare, che mi restituir√† un unico numero, questo √® il valore di $c_{ij}$\nPropriet√†:\nSi pu√≤ dimostrare che il prodotto fra matrici gode della propriet√†\nAssociativa Distributiva Non √® commutativa!\nTransposizione Si pu√≤ definire una matrice trasposta, bisogna scambiare gli indici associati. Es:\n$(A^T)_{ij} = (A)_{ji}$ con i, j gli indici della matrice\nMatrici a scala Matrice a scala: Si ha quando considerando il primo elemento non nullo partendo da sinistra, sotto di questo sta uno 0, e eementi a sinistra di questo sono nulli ( o niente), partendo a contare dall\u0026rsquo;alto.\nMatrice associata a un sistema Si pu√≤ associare una matrice a ogni sistema lineare, come in figura.\nDal libro\nNotare il significato di matrice completa o incompleta presente nella slides\nCostruendo la matrice associata completa, dobbiamo distinguere fra la matrice delle incognite, dei coefficienti e dei termini noti\nPivot e RR Pivot: per ogni riga, il primo valore da sinistra per cui non √® nullo, √® il valore di pivot\nRango righe: il rango righe di una matrice a scala √® il numero di pivot totale, si indica spesso con $rr_a()$ questo determina anche una dimensione dello spazio vettoriale o simili, li vedi in Spazi vettoriali\nRisolvere una matrice a scala Quando ho una matrice a scala diventa molto semplice risolvere il sistema per sostituzione.\nRiesco subito a determinare se la matrice ha soluzione finita, infinita e simili. (√® una cosa pratica quindi non ti metto appunti qui).\nPer avere in generale un feeling generale su questo:\n$rr(A) = rr(A|b)$ una sola soluzione $rr(A) \u003c rr(A|b)$ impossibile $rr(A) \u003e rr(A|b)$ infinite soluzioni con certe variabili libere Operazioni elementari (3) Possiamo agire sul sistema (e quindi anche sulla matrice associata al sistema) con certe operazioni che mi cambiano la matrice ma non cambiano la soluzione del sistema\nScambio posizione riga di due equazioni Moltiplicazione per un numero reale diverso da 0 (deriva dalle propriet√† dell\u0026rsquo;uguaglianza descritto in precedenza) Sommare (o sottrarre) una riga all\u0026rsquo;altra. (quindi unendola alla 2 posso farlo con una riga scalata) Trasformazione in matrice a scala Data una matrice normale possiamo sempre trasformalo in matrice a scala\nUna volta ottenuta questa matrice possiamo andare ad analizzarla con il rango righe come sopra\nSistema omogeneo Un sistema di equazioni si dice omogeneo quando i termini noti sono tutti 0. Questo sistema ha sempre almeno una soluzione la soluzione banale tutti 0.\n","permalink":"https://flecart.github.io/notes/introduzione-algebra/","summary":"Tutta sta parte si fa in modo formale in Sistemi Lineari e determinanti, quindi potresti saltarla totalmente\nEquazioni lineari L\u0026rsquo;obiettivo dell\u0026rsquo;algebra lineare √® risolvere n equazioni con n sconosciuti di primo grado. Cosa che ci riesce con grandissimo successo! Andiamo ora a definire meglio cosa √® una equazione lineare\nDefinizione Una equazione lineare √® una equazione a coefficienti appartenenti a un certo campo (che pu√≤ essere R) e incognite il cui grado √® 1 e che siano indipendenti:","title":"Introduzione algebra"},{"content":"Metodi altri sono trovare una approssimazione facile da calcolare (simile all\u0026rsquo;approccio del modello surrogato credo). Ma nel nostro caso proviamo a trovare metodi di esplorare lo spazio dei parametri in modo intelligente.\nDeterministic methods Sono utilizzabili quando ci sono delle propriet√† come convessit√†, limitatezza, continuit√†.\nNewton Raphson method Molte implementazioni in R usano questo metodo, √®\nPerfetto quando $h$ √® quadratico, e in statistica molti problemi sono quadratici e funziona in modo perfetto Ma in cose non lineari si ha meno performance (perch√© l\u0026rsquo;hessiana √® molto instabile per l\u0026rsquo;inversione, si dice che √® mal condizionata, e si fa con attenzione.) l\u0026rsquo;unica cosa da sapere secondo me √®\n$$ f(x) = x - H^{-1}\\nabla f(x) $$ Stochastic methods Stochastic search In pratica faccio uniform su tutto il dominio, e tengo il maggiore come la soluzione, solo che\nDifficile da calcolare Soffre di problemi di scaling Ha bisogno che la funzione sia facile da valutare. La caratteristica negativa √® che spende tempo anche per zone di poco interesse, perch√© d√† stessa importanza a tutto. Sarebbe buono provare a fare sampling in modo proporzionale al valore di $h(\\theta)$\nMax of function = mode of the distribution, if that is a density! Quindi se faccio sampling usando quella funzione come densit√† riesco a trovare il massimo!\nStochastic gradient methods √à una categoria di algos.\nRandom walk We use the gradients to guide the search. Un esempio √® solamente fare una cosa cos√¨ $$ \\theta_{j+1} = \\theta_{j} + \\varepsilon_{t} $$ In cui $\\varepsilon$ √® una variabile aleatoria, questo √® anche una catena di markov. Questo √® un random walk approach. (che √® stupido perch√© comunque non sto utilizzando nessuna informazione sulla funzione!)\nGradient descent Questo lo sai. Solo che in questo caso viene fatta una sequenza di pesi (non √® un learning rate)\u0026hellip; Solo che soffre molto facilmente sulla possibilit√† di stuck su minima o maxima.\nC\u0026rsquo;√® anche una versione stocastica, in cui si una una versione approssimata del gradiente (che strano, di solito questa informazione √® disponibile). (si utilizza la definizione di gradiente in pratica, quindi si usa una variabile random sullo step\u0026hellip;)\n$$ \\nabla h(\\theta) \\approx \\frac{h(\\theta_{j} + \\beta_{j} \\gamma) - h(\\theta_{j} - \\beta_{j} \\gamma)}{2\\beta_{j}} $$ in cui ho di nuovo una sequenza di $\\beta$ che mi definisco io, solo che $\\gamma$ √® sampling da sfera unitaria, √® un tentativo di perturbare la discesa, in modo da non essere stuck in minimi o massimi locali.\nPoi l\u0026rsquo;update diventa\n$$ \\theta = \\theta - \\frac{\\alpha_{i}}{2\\beta_{i}} \\nabla h(\\theta)\\gamma $$ Simulated Annealing Boltzmann-Gibbs transform quando proviamo in local search un sampling basato su local search minima.\nWe want to sample a sequence proportional to the time! $\\propto \\frac{\\exp(h(\\theta))}{T}$\nSolitamente per fare questo si fa $$ \\pi_{i}(\\theta) \\propto L(0)^{T} \\pi_{0}(\\theta) $$ Dove $\\pi_{0}$ √® la distribuzione di densit√† iniziale, mentre l\u0026rsquo;altro √® una costante. questo approccio si chiama prior feedback approach.\nIl tempo possiamo sceglierlo di farlo scendere in molti modi\nLogaritmico Geometrico Metropolis hastings Vogliamo utilizzare la trasformata di boltzmann-gibbs per fare sampling del nuovo valore $\\theta$ seguendo quello.\nAlgo:\nPrendo $y$ da una distribuzione $g$, tale che sia simmetrica per questo motivo utilizzo una gaussiana. (anche questo deve essere scalato col tempo). Poi faccio sampling condizionale: (con probabilit√† $p$ posso sommare, con probabilit√† $1- p$ rimane la stessa). La cosa in pi√π √® che mi muovo con probabilit√† (la scelta stocastica) √® la differenza con random walk\u0026hellip; In particolare $p$ non √® costante ma cambia nel tempo, ed √® calcolata come: $$ p = min\\left( \\exp\\left( \\frac{\\Delta h}{T} \\right), 1 \\right) $$ Con $h = h(\\theta + y) - h(\\theta)$, una osservazione √® che se √® positiva, allora √® sempre maggiore di 1, quindi mi muovo sempre (qui √® equivalente a random walk). Altrimenti vorrei essere pi√π conservativo, e restare di pi√π con la stessa posizione. Ma allora continuo a muovermi di meno col tempo. EM Algorithms ","permalink":"https://flecart.github.io/notes/optimization-methods/","summary":"Metodi altri sono trovare una approssimazione facile da calcolare (simile all\u0026rsquo;approccio del modello surrogato credo). Ma nel nostro caso proviamo a trovare metodi di esplorare lo spazio dei parametri in modo intelligente.\nDeterministic methods Sono utilizzabili quando ci sono delle propriet√† come convessit√†, limitatezza, continuit√†.\nNewton Raphson method Molte implementazioni in R usano questo metodo, √®\nPerfetto quando $h$ √® quadratico, e in statistica molti problemi sono quadratici e funziona in modo perfetto Ma in cose non lineari si ha meno performance (perch√© l\u0026rsquo;hessiana √® molto instabile per l\u0026rsquo;inversione, si dice che √® mal condizionata, e si fa con attenzione.","title":"Optimization methods"},{"content":"Molto importante questo documento per avere chiara la differenza fra la logica intuizionista e la Logica Proposizionale classica.\nQuesta logica intuizionista non si preoccupa del noumeno platonico, ma solo di una prova reale.\nIntroduzione:\nwikipedia\n9 11 Scopi di intuizionista (3) Semantica dell\u0026rsquo;evidenza ‚Üí costruzione della prova Semantica della conoscenza diretta = conoscenza diretta Semantica della calcolabilit√† = programma, algoritmo della soluzione 9.1 Invenzione o scoperta La semantica intuizionista vede la matematica come una creazione (e questa cosa interessa molto all\u0026rsquo;informatico perch√© √® una prova., mentre la semantica classica vede la matematica come una scoperta\nCaratteristica principale della logica intuizionista\nEsempio il paradosso di Banach-tarksi non √® calcolabile (nessuno ha duplicato una sfera doro diciamo :) )\nSeziono la sfera in 3 parti e faccio movimenti rigidi (non deformo, posso rotare, trasportare) e dimostro che da questi movimenti rigidi ottengo due sfere con lo stesso volume e con gli stessi punti.\n9.1.1 Evidenza indiretta e diretta Nelle due logiche il significato di esistenza √® differente.\nClassica: l\u0026rsquo;esistenza, ma non so esattamente che numero sia Intuizionista: l\u0026rsquo;elemento che soddisfa, riesco proprio a trovare l\u0026rsquo;elemento tale che mi soddisfi le mie propriet√†. NOTA: il fatto che esista una prova intuizionista mi permette di avere un algoritmo per tirare fuori un elemento che me lo soddisfi, mentre dalla prova classica no.\n9.1.2 Effetti dimostrazione per assurdo Questo metodo di dimostrazione non √® stato ben accettato nell\u0026rsquo;epoca in cui √® stato creato perch√© non permetteva il buon calcolo:\nNo calcolo Molto utile per dimostrare teoremi che non si potevano dimostrare in modo intuizionistico Molto veloce perch√© rende le dimensioni delle prove minori (ma perch√© fa meno lavoro!) 9.2 Enunciati e semantiche della logica intuizionista Algoritmo l\u0026rsquo;evidenza diretta √® necessaria per la determinazione del valore di verit√† Il valore di verit√† √® potenzialmente determinabile (ossia pu√≤ diventare fissata dopo un p√≤ di tempo), ci deve essere una algoritmo o che non esista. Enunciato ed esempi\nAnalizzando la prima proposizione, per la logica classica dovrei avere un valore di verit√† fissato, invece sono in un mondo indeterminato.\nPer i numeri, l\u0026rsquo;algoritmo non riuscirebbe mai a finire a comparare due numeri periodici e non riuscirebbe a dare un risultato in tempo finito.\nMentre l\u0026rsquo;ultimo esempio √® stato dimostrato in Logica meta-linguistica\nDa questi si posso ricavare due semantiche:\n9.2.1 Semantica di Kripke La caratteristica principale di questa semantica √® che le proposizioni possono avere un range da [0,1].\nE che queste denotazioni possono evolvere da 0 a 1 col tempo. Bisogna quindi avere una funzione semantica che possa trattenere il tempo.\n0 √® ignoto 1 √® vero e questi valori evolvono.\nQuesti valori sono dei valori di conoscenza ma non verit√†, e non algoritmico!\nEnunciato\n9.2.2 Altro Si tratter√† anche della semantica di Brouwer-Heyting-Kolmogorov subito dopo\n9.3 Semantica di Brouwer-Heyting-Kolmogorov 9.3.1 Introduzione Data una formula F, la sua denotazione √® l\u0026rsquo;insieme delle prove esplicite (algoritmi) che risolvono quella formula.\nQuesta semantica √® molto utile per l\u0026rsquo;informatico perch√© le formule sono descrizioni di problemi e l\u0026rsquo;altro soluzione.\nosservazioni:\nQuesta semantica √® molto utile per comporre delle soluzioni (grazie ai connettivi). L\u0026rsquo;insieme vuoto √® l\u0026rsquo;inesistenza di soluzioni algoritmiche (che potrebbe essere non pi√π vuoto in futuro).\nQui ha senso introdurre il concetto di dedicibilit√† ovvero la possibilit√† di costruire un algoritmo che me lo risolva.\n9.3.2 Enunciato e definizione semantica Enunciato\nDefinizione semantica\n9.3.3 Nota sul VOID: con void in c starei restituendo la stellina (valore vero), ovvero sto restituendo sempre una sequenza giusta (eliminazione del top √® inutile quindi non ci faccio caso).\n9.3.4 EM e RAA in semantica intuizionista Queste dimostrazioni valide in logica classica non hanno pi√π senso in questo caso\nEsempio\n9.3.5 Correttezza e completezza Potrebbe essere un buon esempio confrontare la correttezza e completezza intuizionistica con quella classica.\nSlide\nCompletezza forte e debole\nSlide\nAbbozzo di ragionamento per queste completezza\nUn algoritmo in un tempo finito non pu√≤ analizzare un input infinito, quindi non potrebbe dimostrarlo un algoritmo. Esiste per√≤ una dimostrazione classica.\n9.3.6 Conclusioni Questa semantica si pu√≤ evolvere nel tempo (trovando nuovi algoritmi che mi risolvano il problema)\nSi ha una completezza debole per logiche senza RAA\nSe ho una prova intuizionista riesco a costruire un algoritmo che mi risolvi un problema\nEM non ha molto senso qua, se fosse una tautologia sarebbe un risultato molto forte\nSlide\n9.3.7 La negazione Le formule negate non hanno informazione al loro interno.\nPartiamo dalla regola del not, ovvero per dimostrare nonF devo dimostrare che F implica l\u0026rsquo;assurdo.\nOvvero devo dire che ci sia una funzione che parta da F e che arrivi a nulla.\nLe soluzioni possibili sono solamente vuoto e singoletto di vuoto (in altri termini possiamo dire che abbiamo 0 e 1). chiaramente queste funzioni non sono affatto utili per cui non esiste un algoritmo che mi da cose utili.\nNegare due volte √® equivalente a distruggere una informazione (devi fare una tabellina con la regola per vedere che c\u0026rsquo;√® questo)\nnotF Stato di F notnotF singoletto vuoto Uguale a Vuoto vuoto vuoto Diverso da vuoto singoletto vuoto perch√© nonF mi pu√≤ dare solamente due output, mi ha distrutto tutto l\u0026rsquo;algoritmo iniziale!\nDimostrare che non esiste significa dire che non esiste informazione.\nProva a dimostrare queste:\n$$ \\neg(F_1 \\vee F_2) \\Vdash \\neg F_1 \\wedge \\neg F_2 $$ Mentre per quello sopra invertito (invertendo or e and di sopra) non √® intuizionista, perch√© l\u0026rsquo;output ha pi√π informazioni per qualche motivo strano.\n9.4 Teorema di compattezza Questo teorema √® una conseguenza molto utile della propriet√† di completezza, come in slide:\nEnunciato e dimostrazione del teorema\nQuesto teorema √® molto forte, perch√© se ho un insieme infinito di filtri, vuol dire che ho bisogno solamente di limiti finiti. E il fatto che l\u0026rsquo;infinito si possa ridurre al finito √® un fatto sorprendente.\n9.4.1 Conseguenze della compattezza (4) La cosa che era sorpredente della compattezza in questi casi √® la possibilit√† di ritrovare in un caso infinito un caso finito da cui √® possibile poter ricavare la cosa voluta!.\nConseguenze\n9.4.2 Fallimento della compattezza per logiche complesse (3) Slide\nze\n\u0026lt;img src=\u0026quot;/images/notes/Semantica intuizionista/Untitled 12.png\u0026quot; alt=\u0026quot;Semantica intuizionista/Untitled 12\u0026quot;\u0026gt; 9.4.2 Fallimento della compattezza per logiche complesse (3) Slide\n","permalink":"https://flecart.github.io/notes/semantica-intuizionista/","summary":"Molto importante questo documento per avere chiara la differenza fra la logica intuizionista e la Logica Proposizionale classica.\nQuesta logica intuizionista non si preoccupa del noumeno platonico, ma solo di una prova reale.\nIntroduzione:\nwikipedia\n9 11 Scopi di intuizionista (3) Semantica dell\u0026rsquo;evidenza ‚Üí costruzione della prova Semantica della conoscenza diretta = conoscenza diretta Semantica della calcolabilit√† = programma, algoritmo della soluzione 9.1 Invenzione o scoperta La semantica intuizionista vede la matematica come una creazione (e questa cosa interessa molto all\u0026rsquo;informatico perch√© √® una prova.","title":"Semantica intuizionista"},{"content":"Relazioni con fili - Ampere Legge di Biot-Savart/Formalizzazione esperienza di Ampere üü© Poniamo che ho due fili in cui scorra della corrente, voglia capire la forza per unit√† di lunghezza del filo uno su due e viceversa.\nSo che entrambi generano campo magnetico So che il campo magnetico induce forza su correnti in movimento. Supponiamo che la loro distanza sia $D$, allora avremo che: Per la prima legge so: $$ d\\vec{B} = \\mu_{0}i d\\vec{l} \\times \\frac{\\hat{r}}{4\\pi r^{2}} $$ da questo posso calcolare il campo magnetico totale, in un modo simile a quanto fatto in precedenza per il campo elettrico (solo che in questo caso abbiamo il prodotto seno, quindi l\u0026rsquo;angolo che conviene scegliere √® un po\u0026rsquo; diverso), e una volta che ho questo posso usare la seconda legge per avere la forza, questo √® il piano. Calcoliamo ora il valore del campo magnetico per una corrente di lunghezza infinita, una osservazione fondamentale √® che i contributi sono stesso verso quindi posso solamente sommare e concentrarmi sul modulo: $$ \\vec{B} = \\int _{Filo} \\frac{\\mu_{0}i}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}} = \\hat{k} \\frac{\\mu i}{4\\pi} \\int_{-\\frac{\\pi}{2}}^{+\\pi/2} \\frac{dl}{r^{2}} \\sin \\theta $$ Dovremo scrivere $dl$ e $r$ in funzione dell\u0026rsquo;angolo. L\u0026rsquo;obiettivo √® poi scomporre l\u0026rsquo;integrale in due parti. met√† sotto e met√† sopra: $$ r\\sin \\theta = D \\implies r = \\frac{D}{\\sin \\theta} $$ E $$ \\frac{D}{l} = \\tan \\theta \\implies l = \\frac{D}{\\tan \\theta} \\implies dl = D \\frac{d\\theta}{\\sin ^{2}\\theta} $$ Sostituendo tutto questo dentro otteniamo: $$ \\lvert \\vec{B} \\rvert = \\frac{\\mu_{0}i}{4\\pi} \\int _{\\pi}^{0} \\frac{\\sin \\theta}{D} d\\theta \\, dx = \\frac{\\mu_{0}i}{4\\pi D} (-\\cos \\theta) ^{0}_{\\pi} = \\frac{\\mu_{0}i}{2\\pi D} $$ Da qui abbiamo ottenuto la legge di Biot Savart. Qui notiamo che il campo magnetico circola intorno al filo (√® tangente al campo magnetico in questo caso, molto simile). Possiamo utilizzare questo per calcolare la forza applicata in un tratto di filo:\n$$ d\\vec{F} = i_{2}d\\vec{l} \\times (-\\vec{k})\\frac{\\mu i_{1}}{2\\pi D} $$ Quindi otteniamo una forza $$ d\\vec{F} = \\frac{i_{1}i_{2}}{2\\pi D} d\\vec{l} \\implies \\vec{F} = \\frac{i_{1}i_{2}L}{2\\pi D} $$ Questo vale perch√© abbiamo considerato fili infiniti rettilinei. Per la terza legge della dinamica la forza esercitata da due su uno √® la stessa, invertita per√≤, e questo conferma anche quanto sperimentalmente trovato con l\u0026rsquo;esperienza di ampere\nDefinizioni di dimensioni üü© L\u0026rsquo;ampere posso definirlo in questo modo: corrente percorsa in due fili paralleli nel momenti in cui la distanza √® un singolo metro, e la lunghezza √® un metro e ho una forza uguale a $2\\times 10^{-7} N$ . Questo poi mi permette di definire il Coulomb in termini di corrente. √à una definizione utile per anche avere in automatico il valore di $\\mu_{0}$ (quindi molto artificiale secondo me).\nOsservazioni\nLinee chiuse del campo $\\vec{B}$ il flusso √® nullo, perch√© le linee sono chiuse (questo √® coerente con Gauss) Posso usare la regola della mano destra per sapere la direzione del campo magnetico Posso calcolare la circuitazione del campo magnetico generato da una corrente Posso calcolare la circuitazione, e scelgo una circonferenza chiusa:\nCircuitazione del campo magnetico (!) üü© $$ \\oint_{\\Gamma} \\vec{B}d\\vec{r} = \\oint_{\\gamma} \\frac{\\mu_{0}i}{2\\pi} \\frac{dr}{R} = \\frac{\\mu_{0}i}{2\\pi} \\frac{1}{R} \\oint_{\\gamma} dr = \\frac{\\mu_{0}i}{2\\pi} \\frac{1}{R} 2\\pi R = \\mu_{0}i $$ Ossia dipende dalla corrente. La stessa relazione vale anche se scelgo un percorso spezzato! perch√© se scelgo il raggio, in quel caso la circuitazione √® nulla, perch√© √® perpendicolare alla direzione del campo! Il motivo √® perch√© come sopra i raggi si semplificano, e rimane solamente l\u0026rsquo;angolo, che si semplificher√† alla fine.\nProviamo a formalizzare questo discorso, poniamo di avere due circonferenze concentriche che rappresentano la direzione del nostro campo magnetico, poniamo che il tratto sul $R_{1}$ sia di $\\theta_{1}$ e il tratto su $R_{2}$ sia di $\\theta_{2}$ , e che $\\theta_{1} + \\theta_{2} = 2\\pi$, abbiamo allora che\n$$ \\oint_{\\Gamma} \\vec{B} d\\vec{r} = \\frac{\\mu_{0}i}{2\\pi} \\left( \\frac{1}{R_{1}} \\theta_{1}R_{1} + \\frac{1}{R_{2}} \\theta_{2}R_{2} \\right) = \\mu_{0}i $$ Questo discorso ha delle similitudini con l\u0026rsquo;analisi del Potenziale elettrico in Campo elettrico. Anche l√¨ spezzettavamo, e concludevamo conservativit√† per cose radiali.\nLegge di Ampere üü© La circuitazione di $\\vec{B}$ lungo una qualsiasi linea chiusa Gamma, √® pari all\u0026rsquo;intensit√† di corrente complessiva concatenata alla linea chiusa moltiplicata per la permeabilit√† magnetica del vuoto\nQuesto √® motivato da quanto fatto sopra per la circuitazione del campo magnetico, solo che quando l\u0026rsquo;abbiamo derivato l\u0026rsquo;abbiamo fatto per un filo rettilineo uniforme.\nIn un certo senso questa legge √® simile a Legge di Gauss perch√© consideriamo solamente le correnti dentro alla nostra circuitazione (come per gauss si considerava solamente le cariche all\u0026rsquo;interno).\nCorrente concatenata (!!) üü© Dobbiamo capire il significato di corrente concatenata, possiamo riprendere la definizione di corrente elettrica che abbiamo dato durante Corrente Elettrica, e considerare una superficie pi√π ampia! Infatti considero la superficie aperta con bordo $\\Gamma$, dalla definizione di densit√† di corrente, non mi importa che questa superficie sia oltre il nostro filo, pu√≤ esser pi√π ampio , e in questo senso la corrente √® sempre quella, definita come $$ i = \\int _{\\Sigma} \\vec{J} \\cdot d\\vec{s} $$ Considero una altra superficie a cappello come in figura (in cui il rosso √® vuoto, perch√© √® superficie aperta, ci piace questo perch√© non ci limita sulla forma della superficie), allora provo a calcolare il flusso su questo. Definisco il verso di $ds$ come convenzione, in base alla circuitazione (stessa della corrente diciamo.) Qualsiasi superficie aperta con bordo Gamma, riscrivendo l\u0026rsquo;equazione precedente: $$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{r} = \\mu_{0} \\int _{\\Sigma(\\Gamma)} \\vec{J} \\cdot d\\vec{s} $$ Ampere in forma differenziale üü© Guardare Divergenza e Circuitazione, √® il teorema di Stokes quello che utilizziamo:\n$$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{r} = \\int _{\\Sigma(\\Gamma)} \\vec{\\nabla} \\times \\vec{B} \\cdot d\\vec{s}= \\mu_{0} \\int _{\\Sigma(\\Gamma)} \\vec{J} \\cdot d\\vec{s} $$ Allora possiamo scrivere la legge di Ampere in forma differenziale e abbiamo: $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} $$ Da cui abbiamo ancora che $B$ non √® conservativo, e quindi non ha senso chiedersi del lavoro fatto dal campo.\nTerza legge di Maxwell (Ampere-Maxwell) üü© Come si gestisce il caso in cui l\u0026rsquo;intensit√† della corrente cambia? Ricordiamo la legge di continuit√† della corrente, ossia abbiamo $$ \\begin{cases} \\vec{\\nabla} \\cdot \\vec{J} + \\frac{\\delta \\rho}{\\delta t} = 0 \\\\ \\vec{\\nabla} \\cdot \\vec{E} = \\frac{\\rho}{\\varepsilon_{0}} \\implies \\rho = \\varepsilon_{0} \\vec{\\nabla}\\cdot \\vec{E} \\end{cases} \\implies $$ $$ \\implies \\vec{\\nabla} \\cdot \\vec{J} = -\\left( \\varepsilon_{0} \\vec{\\nabla} \\frac{\\delta \\vec{E}}{dt} \\right) \\implies \\vec{\\nabla}\\left( \\vec{J} + \\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} \\right) = 0 $$ Questa legge vale non solo per il caso stazionario (esteso). In $J$ sono presenti le correnti concatenate, ma anche quelle atomiche (le correnti di magnetizzazione esplorate in Magnetismo nella materia).\nDa questo possiamo ricavare la altra legge di Maxwell (inizialmente non considerato dalla Royal Academy, sar√† utilizzabile solo per correnti non stazionarie)\n$$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$ Si estende con la parte di Maxwell: $$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{r} = \\mu_{0} \\int _{\\Sigma(\\Gamma)} \\vec{J} \\cdot d\\vec{s} + \\mu_{0}\\varepsilon_{0} \\frac{d\\left( \\int _{\\Sigma(\\Gamma)} \\vec{E} \\, ds \\right)}{dt} $$ Questo √® fondamentale! Perch√© basta far variare il campo elettrico e questo crea un campo magnetico!\nSono quattro equazioni differenziali a derivate parziali (stessa cosa per il campo elettrico), e con questo si pu√≤ risolvere tutto.\nDensit√† di corrente di spostamento üü© Il termine nuovo che ha introdotto Maxwell √® chiamato densit√† di corrente di spostamento e si pu√≤ vedere che hanno le stesse dimensioni infatti $$ \\vec{J}_{s} = \\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$ Guardare Condensatori nel vuoto per il ragionamento sul condizionatore e corrente di spostamento. Si chiama corrente perch√© ha le stesse dimensioni delle correnti.\nUna nota interessante √® vedere questo come viene derivato: Partendo dalla equazione di continuit√† della corrente, abbiamo che\n$$ \\vec{\\nabla} \\cdot \\vec{J} = - \\frac{\\delta \\rho}{\\delta t} = -\\frac{\\delta}{\\delta t} (\\varepsilon_{0} \\vec{\\nabla} \\cdot \\vec{E}) \\implies \\vec{\\nabla} \\cdot \\left( \\vec{J} + \\frac{\\delta}{\\delta t} (\\varepsilon_{0} \\vec{E}) \\right) = 0 $$ E dato che sommo anche quello √® una densit√†, e la chiamo densit√† di corrente di spostamento.\nCampi magnetici non stazionari Questi possono indurre una forza elettromotrice. Faraday ha indagato questa possibilit√† e attraverso molti esperimenti si cerca di verificare questo.\nEsperimento di Faraday per campi magnetici non stazionari üü® 1. Magnete statico: Ha messo prima una calamita su un circuito, ma questo non genera corrente 2. Magnete in estrazione: genera una corrente che nel solenoide (comunque spira) ha un campo magnetico attrattivo 3. Magnete in inserimento: campo magnetico repulsivo generato dalla corrente Osservazioni:\nLa corrente √® pi√π grande quanto √® pi√π grande la velocit√† v Quando la calamita √® dentro al solenoide, non si ha corrente Si ha una forza opposta al movimento Viene generata corrente Invertendo i poli si ha la stessa cosa (solo con verso della corrente opposta). Questi risultati sono uguali quando si usa un circuito affacciato al primo (ci sono esattamente le stesse cose di prima). -\u0026gt; Un flusso variabile pu√≤ generare forza elettromotrice.\nQuarta legge di Maxwell (Faraday-Neumann-Lenz) üü© $$ \\varepsilon_{IND} = -\\frac{d\\Phi(\\vec{B})}{dt} \\implies \\oint_{\\Gamma} \\vec{E} \\cdot \\vec{r} = -\\frac{d\\Phi(\\vec{B})}{dt} = - \\frac{d}{dt} \\left( \\int _{\\Sigma(\\Gamma))} \\vec{B} \\cdot d\\vec{s} \\, \\right) $$ Posso scrivere anche utilizzando il teorema del rotore (e il fatto che integro e derivo rispetto a variabili indipendenti) nella forma differenziale: $$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} $$ In cui ho una informazione puntuale.\nEnunciato in modo matematico da Ampere, e attraverso testo da Faraday. Che √® in pratica il risultato sperimentale osservato precedentemente.\nA volte il fatto che √® opposto si dice che sia grazie agli esperimenti di Lenz. ed √® necessaria per la conservazione dell\u0026rsquo;energia. L\u0026rsquo;orientazione della superficie $\\Sigma$ √® data dalla regola della mano destra (e quindi decide il verso).\nPossiamo individuare tre casi in cui la variazione non √® nulla, li andiamo a discutere uno a uno.\n$B = f(t)$ $\\theta = \\theta(t)$ $\\Sigma = \\Sigma(t)$ Angolo variabile nel tempo üü© Supponiamo di avere un campo magnetico costante, vogliamo cercare di guardare quant\u0026rsquo;√® la corrente indotta quando la spira ruota. Supponiamo ruoti con $\\omega = \\frac{d\\theta}{dt}$ Allora: $$ \\Phi(\\vec{B}) = \\int _{\\Sigma} \\vec{B} \\cdot \\, d \\vec{s} = BS \\cos \\theta(t) \\implies \\varepsilon_{IND} = BS \\sin \\theta \\omega $$ Qui abbiamo una corrente alternata. √à interessante notare che abbiamo corrente alternata anche se non c\u0026rsquo;√® nessuna forza elettromotrice.\nFlusso variabile nel tempo üü© Supponiamo di avere un circuito in parallelo con una corrente che cambia intensit√†, cos√¨ ho un flusso distante.\n$i = kt$, $\\lvert B \\rvert = \\frac{\\mu_{0}i(t)}{2\\pi r}$ $$ \\varepsilon_{IND} = -d \\frac{\\Phi(\\vec{B})}{dt} = i_{I}R $$ Con $R$ la resistenza del circuito e $i_{I}$ la corrente indotta. Per il verso della superficie √® uguale, si fa una assunzione sul verso della corrente e poi si avr√† il verso della corrente vera come segno.\ncalcoliamo il flusso allora:\n$$ \\Phi(\\vec{B}) = \\int _{\\Sigma} \\lvert \\vec{B} \\rvert \\, d\\vec{S} = \\int _{\\Sigma} \\frac{\\mu_{0}i}{2\\pi r}\\, \\vec{dS} = \\frac{\\mu_{0}i}{2\\pi} \\int_{D}^{D+L} \\frac{1}{r}L\\, dr = \\frac{\\mu_{0}iL}{2\\pi} \\ln\\left( \\frac{D+L}{D} \\right) $$ Allora otteniamo che, sapendo che $i(t) = kt$ $$ \\frac{d\\Phi(\\vec{B})}{dt} = \\frac{\\mu_{0}L}{2\\pi} \\ln\\left( \\frac{D+L}{D} \\right)k $$ Con questo poi posso descrivere la FEM indotta e quindi avere la direzione della corrente\nArea variabile nel tempo üü© Consideriamo un circuito con una barra che si muove di velocit√† costante, in questo senso varia l'area, e un campo magnetico uscente costante, sappiamo che $A = x_{0} + vt$ Allora $$ \\Phi(\\vec{B}) = \\oint_{\\Sigma} \\lvert \\vec{B} \\rvert d\\vec{S} = -BS(t) $$ Abbiamo allora che $$ \\varepsilon_{IND} = BLv $$ Notiamo che abbiamo bisogno di una forza per continuare a tenerlo La forza che viene applicata √®\n$$ \\vec{F} = i_{I}lB \\hat{r} = \\frac{BLv}{R} LB = \\frac{B^{2}L^{2}v}{R} $$ Per avere velocit√† costante, bisogna avere una forza che annulli questo, in modo che sia inerziale.\nBarra in movimento üü© Da questo esperimento proveremo che correnti vengono generati anche nel vuoto. Consideriamo una barretta che si muove in un campo magnetico costante. Allora abbiamo che deve valere $$ qvB = qE_{IND} \\implies E_{IND} = vB $$ E sapendo che in questo caso semplice abbiamo $$ \\Delta V = \\int_{\\Gamma}\\vec{E} d\\vec{l} = El $$ Che possiamo mettere dentro: $$ \\Delta V = vBl $$ Questa √® la differenza di potenziale generata all\u0026rsquo;interno. Abbiamo una giustificazione che la forza elettromotrice √® generata dalla forza di Lorentz, e questo funziona anche nello spazio vuoto. E solitamente questo non √® conservativo (se √® indotto non √® statico solitamente, perch√© ci sar√† qualcosa che varia).\nVogliamo cercare di ricavare una equazione di conservazione dell\u0026rsquo;energia in elettromagnetismo classico\n","permalink":"https://flecart.github.io/notes/ampere-e-faraday/","summary":"Relazioni con fili - Ampere Legge di Biot-Savart/Formalizzazione esperienza di Ampere üü© Poniamo che ho due fili in cui scorra della corrente, voglia capire la forza per unit√† di lunghezza del filo uno su due e viceversa.\nSo che entrambi generano campo magnetico So che il campo magnetico induce forza su correnti in movimento. Supponiamo che la loro distanza sia $D$, allora avremo che: Per la prima legge so: $$ d\\vec{B} = \\mu_{0}i d\\vec{l} \\times \\frac{\\hat{r}}{4\\pi r^{2}} $$ da questo posso calcolare il campo magnetico totale, in un modo simile a quanto fatto in precedenza per il campo elettrico (solo che in questo caso abbiamo il prodotto seno, quindi l\u0026rsquo;angolo che conviene scegliere √® un po\u0026rsquo; diverso), e una volta che ho questo posso usare la seconda legge per avere la forza, questo √® il piano.","title":"Ampere e Faraday"},{"content":"Perch√© filesystem? Questa √® l\u0026rsquo;idea presa dall\u0026rsquo;archivio, come se fosse un ufficio che deve tenere delle pratiche ordinate in cartelle e cartelloni.\nL‚Äôutilizzo principale √® dare un interfaccia comune di accesso ai dispositivi. perch√© dispositivi diversi hanno sotto modi di accedere diversi, questa interfaccia facilita molto l\u0026rsquo;accesso.\nInformazioni dei files (5+) üü® Il file √® l‚Äôunit√† logica di memorizzazione. il formato che c\u0026rsquo;√® dentro √® gestito dall\u0026rsquo;applicazione, non dal file system!\nLista degli attributi \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Filesystem/Untitled.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Filesystem/Untitled\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Filesystem/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Filesystem/Untitled 1\u0026quot;\u0026gt; Ci sono un sacco di informazioni memorizzate nei file (un sacco di metadata anche)\nNome Data e ora di accesso o modifica Informazioni sull\u0026rsquo;ownership e protezione di accesso. Dimensione del file TIpo del file Categorizzazione dei files (3) üü©- Tipi di files\nPossiamo andare a distinguere i files a seconda del\nContenuto (se contiene codice oggetto, se contiene dati o informazioni) Struttura, se sono plain text sequenze di bytes, oppure dati strutturati come database., e possono anche essere un albero**.** UNIX: files speciali (blocchi o caratteri), pipes, oltre ai classici files e directories. NOTA: ci sono molte cose che sono viste come files, in unix tutto √® un file :D. Sono identificati da una coppia di numeri che identificano il device driver Files in sistemi operativi comuni üü© I files sono nati con la metafora dell‚Äôufficio:\nArchivi di informazione, che vanno aperti e richiusi (messi nella loro collocazione corretta) √à utile conoscere il tipo di file per capire quale utilizzo andiamo a fare di essa.\nC‚Äô√® un tradeoff, se ho tanti tipi di files, il sistema operativo diventa molto pi√π complesso, se ho troppi pochi potrebbero essere troppo generali.\nSlide tradeoff tipologie di files\nTecniche di identificazione dei file (3) üü© Generalmente ci sono 3 modi per riconoscere il tipo di files:\nMagic numbers Attributo tipo del filesystem estensione. Rispettivamente queste tecniche sono utilizzate in:\nWin (estensioni) Mac, informazioni aggiuntive sui files Unix, il magic number all‚Äôinizio dei files Slide metodi di riconoscimento nei sistemi di riconoscimento\nUnix riconosce solamente gli eseguibili, in questo senso √® minimalista.\nCol magic number riesce anche a riconoscere l‚Äôarchitettura target dell‚Äôeseguibile.\nMac OS ha un codice identificativo per un programma che ha creato il file o la risorsa.\nWindows guarda l\u0026rsquo;estensione. che solitamente sempre da 3 caratteri. (inizilamente il nome del file aveva solo 8 caratteri.\nMetodi di accesso comuni (3) Slide metodi di accesso\nseguenziale\ndiretto\nindicizzato\nUno di particolare interesse √® INDICIZZATO, che si usa spesso per i databases:\nSlide metodo di accesso ad indice\nOperazioni sui files üü® Slide lista delle operazioni\nL‚Äôapertura √® una operazione molto costosa, bisogna\nTrovare i files Capire se si hanno i permessi corretti per poter leggere, o scrivere sul file. Questo si collega molto bene con la metafora dell‚Äôufficio e con l‚Äôarchivio. Se ne ho bisogno vado a prendere dall‚Äôarchivio e la apro se mi serve. Una volta finito lo si rimette apposto.\nNote sull‚Äôapertura e chiusura dei files\nDirectories Introduzione alle directories üü® \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Filesystem/Untitled 10.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Filesystem/Untitled 10\u0026quot;\u0026gt; √à quindi un file speciale che contiene le informazioni di accesso per la gestione dei files al suo interno.\nA seconda dell‚Äôimplementazione possono essere degli array lineari oppure degli hashtable. (si pensi a quanto possano essere grandi le directories, se uso una lista diventa molto lento, se invece si sa gi√† che sia piccola si perde del tempo a fare l‚Äôhash).\nInformazioni nelle directories (2) üü® Slide informazioni delle directories\nSono contenuti i-nodes, che sono degli indici per andare a comprendere la struttura dei files.\nMa pu√≤ cambiare, questo √® un fatto implementativo, potrebbe benissimo anche essere messo nelle entries della directory.\nUNIX ‚Üí messe negli i-node\nMSDOS ‚Üí messe nelle dir entries.\nLunghezza dei nomi üü® Introduzione al problema della lunghezza dei nomi Anche qui facciamo distinzione fra nomi a lunghezza variabile e nomi fissi, MSDOS al tempo utilizzava nomi fissi con necessariamente estensioni a tre caratteri.\nMetodi per nomi a lunghezza variabile Il metodo a √® preferita, perch√© nel secondo devo leggere in fondo per trovare il nome del file Directories a grafo aciclico I files, possono avere pi√π nomi, in questo senso non ho pi√π un albero ma un grafo.\nSlide struttura grafo aciclico Semantica di coerenza üü• Dato che i sistemi moderni sono maggiormente tutti multitasking, vogliamo andare a specificare quando una modifica di un file pu√≤ essere vista da un altro processo.\nimmediato: questa √® la semantica che viene utilizzata anche nei sistemi UNIX, una modifica √® subito vista da altri programmi. Bisogna chiedersi ora come si faccia ad implementare una cosa di questo genere.\nAFS: √® un esempio di file system interplanetario, in cui non era possibile fare una semantica imemdiata (i dati erano sparsi in mezzo al mondo). semantica di coerenza delle sessioni √® il nome di questo. ossia il file veniva modificato quando il file era chiuso. Questo era necessario perch√© ogni write dovevano rendere traffico sulla rete, era troppa questa sincronizzazione e troppo traffico direi.\nLa struttura Inode Allocazione Master Boot Record üü®+ Slide MBR\nQuesto √® il classico modo di fare partizioni, e si possono fare al massimo 4 partizioni.\nPraticamente √® una prima sezione del disco, che contiene una piccola tavola di partizioni, indice alla partizione attiva e informazioni per fare il boot, poi individua la sezione della partizione col boot, ed esegue quello per caricare il sistema operativo.\n√à utile soprattutto per creare delle aree logiche diverse in cui possono esserci diverse informazioni.\n(altro √® global partitioning table anche GPT, che permette pi√π partizioni)\nStruttura di una partizione (5) üü©‚Äî \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Filesystem/Untitled 16.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Filesystem/Untitled 16\u0026quot;\u0026gt; Slide spiegazione sezioni logiche della partizione\nUn boot block che c\u0026rsquo;√® sempre Superblock contiene informazioni per mount, ad esempio √® qui che si accorge se √® stato unmounted o mounted correttamente Alcune cose per gestire spazio libero ed occupato Directory root e poi il filesystem √® gestito come pare a seconda dei filesystem Allocazione contiguaüü© Slide allocazione contigua Slide svantaggi allocazione contigua Contigua nel senso che lo metto nel blocco di memoria contiguo libero.\nQuesto √® l‚Äôimplementazione pi√π veloce, facile da indicizzare.\nIl problema principale √® che √® statico, per esempio non posso allargare il file giallo, si dovrebbe andare a cercare un blocco abbastanza largo per storare questo. Questo √® il problema principale.\nInfatti se ho un filesystem si sola lettura viene utilizzato questa tipologia di allocazione ISO9660\nAllocazione concatenata üü® Slide allocazione concatenata Slide vantaggi svantaggi\nIn pratica in ogni blocco di dati abbiamo un indice per il prossimo (per√≤ √® lento perch√© sono molto sparsi, perch√© devo fare seek e i file vanno in molti posti, per questo dovrei lanciare defrags molto spesso, ma almeno i file possono crescere ed essere modificati liberamente)\nSVANTAGGI:\nAccesso inefficiente (posso solo inziare dall\u0026rsquo;inizio a scandire, non posso fare un offset) √® che i puntatori possono avere un grosso overhead per blocchi di dati piccoli. (e anche l\u0026rsquo;assunzione che il blocco di dati non √® pi√π una potenza di due). Seek di file, che vengono dispersi per utto il disco Per limitare la frammentazione dei file e l\u0026rsquo;overhead posso utilizzare cluster\nSlide cluster blocchi\nAllocazione a File Allocation Table (FAT) üü®+ Slide FAT Slide svantaggi e vantaggi\nIn pratica ho una tabella apparte che mi dice in che modi i blocchi sono concatenati, in questo modo tolgo l‚Äôoverhead ai blocchi stessi e posso gestirmi apparte sti puntatori.\nSarebbe lento un accesso in pi√π alla tabella fat, ma di solito questa viene caricata in RAM come se fosse una cache, quindi √® molto pi√π veloce. (se poi il blocco √® grosso si dovrebbe perdere molto di meno).\nSarebbe lenta perch√© il disco dovrebbe andare avanti indietro ogni volta per accedere al blocco successivo.\nAllocazione indicizzata üü®++ Slide allocazione indicizzata\nIn pratica ho un blocco di dati che contiene solamente i blocchi di dati del file, questo permette un accesso diretto molto veloce. Per√≤ non posso avere una lunghezza a piacere del file, perch√© il numero di indici in un blocco di dati √® limitato (prima aveva dimensione a piacere).\nSlide svantaggi vantaggi2\nSOLUZIONE ALLA LIMITAZIONE INDICI:\nConcatenazione blocchi indici\nSlide soluzione concatenazione\nPer√≤ con questa soluzione torno ai problemi di accesso diretto lento e frammentazione delle allocazioni precedenti (‚Üí prestazione degrada linearmente con i blocchi)\nMultilivello\nIndice multilivello\nQuesta cosa si pu√≤ rendere ricorsiva, la prestazione degrada logaritmicamente, molto poco abbiamo una sorta di albero here.\nGestione dello spazio libero Bitmap Slide allocazione bitmap\nHo praticamente una bitmap con un bit per ogni cluster, per indicare se √® libero occupato, una soluzioen simile √® anche utilizzata in Bitmap üü© parlando di allocazione di pagine in RAM.\nLista concatenata Slide lista concatenata\nProblemi di frammetazione grossi, dato che i blocchi libero possono praticamente stare ovunque.\nAnche questo metodo l\u0026rsquo;abbiamo descritto in Paginazione e segmentazione, abbiamo anche una lista di bloccchi liberi per la FAT. ne abbiamo parlato anche in Gestione della memoria per la HEAP, gli algoritmi alla fine sono gli stessi.\nConfronto cluster dati e spazio utilizzato Notiamo che dopo un certo punto se abbiamo un blocco di dati troppo grosso il disco lo utilizziamo poco ma il rate dei dati √® molto bello. Quindi se ho dati grossi ho buona roba.\nIn UNIX Multi-livello in unix. Ci sono tanti file piccoli e pochi grandi, quelli grandi possono essere anche molto annidati con l‚Äôallocazione indicizzata multilivello. I file piccoli sono molto veloci di accedere, sono praticamente subito accessibile\nLink hard e soft Per sistemi FAT questi non sono possibili solitamente. in unix √® identificato dall‚Äôinode, se due cose indicano lo stesso inode ecco che posso creare un link, √® come se avessi due files per lo stesso inode.\nLa cancellazione logica √® proprio chiamata unlink, quando l‚Äôultimo nome del file √® tolto allora il file √® stato cancellato.\nIl soft link √® un file, il so capisce che √® un link, ma non si riferisce allo stesso inode.\nCurare e prevenireüü• Curare il filesystem significa riportare lo stato del filesystem in uno stato coerente, ma non abbiamo garanzie riguardo che i files siano stati tutti salvati correttamente\nil check √® uno scan completo di tutto il filesystem\nSlide curare fsck\nPraticamente l\u0026rsquo;eseguibile fsck si va a ricostruire l‚Äôalbero degl inode, se non c\u0026rsquo;√® nessuna reference la mette nei lost and found, riporta tutti gli errori di block size e path names.\nPer filesystems che prevengono ,come ext3, prova a vedere tutto come una transazione, quindi va a registrare le operazioni riguardo il filesystem in un singolo file. Dopo ci√≤ si mette a farlo. √® idempotente.\nSlide transazioni\nConcatenata FAT\n","permalink":"https://flecart.github.io/notes/filesystem/","summary":"Perch√© filesystem? Questa √® l\u0026rsquo;idea presa dall\u0026rsquo;archivio, come se fosse un ufficio che deve tenere delle pratiche ordinate in cartelle e cartelloni.\nL‚Äôutilizzo principale √® dare un interfaccia comune di accesso ai dispositivi. perch√© dispositivi diversi hanno sotto modi di accedere diversi, questa interfaccia facilita molto l\u0026rsquo;accesso.\nInformazioni dei files (5+) üü® Il file √® l‚Äôunit√† logica di memorizzazione. il formato che c\u0026rsquo;√® dentro √® gestito dall\u0026rsquo;applicazione, non dal file system!","title":"Filesystem"},{"content":"NAT Network address translation Introduzione Col il NAT possiamo avere tutto lo spazio degli IP di cui abbiamo bisogno, che per√≤ non sono esposti. All\u0026rsquo;esterno vengono esposte solamente l‚ÄôIP del NAT.\nSchema classico NAT\nQuindi in breve\nAll\u0026rsquo;esterno √® esposto solamente l\u0026rsquo;indirizzo del router, il router, a seconda della porta giusta, d√† in risposta al computer giusto, quindi all\u0026rsquo;interno della nostra rete conosciamo tutti gli indirizzi IP giusti.\nAddr translation table üü© Sembra che ad ogni richiesta ci sia una table di transizione all\u0026rsquo;interno del router che matcha porta ‚Üí indirizzo locale corretto!.\nEsempio funzionamento üü© Slide\nUn client locale fa una richiesta esterna, viene inviato al router Il router salva la porta all‚ÄôIP interno e invia fuori Il server fuori ritorna la risposta alla porta corretta del router Il router manda questa risposta al client con l\u0026rsquo;indirizzo corrispondente a quella porta Controversie NAT (3) üü®+ Slide\nil router dovrebbero lavorare solamente sul livello 3 (IP), qui sta andando anche livello trasporto, per capire come mandare (infatti ha bisogno di un socket spiegato in Socket (!!!) üü©), dato che ha bisogno anche del livello di porta).\nL‚Äôobiettivo di avere pi√π indirizzi Ip non dovrebbe essere risolto con questa sorta di hack, dovrebbe essere risolto con IPv6 utilizzare il NAT sembra una specie di Hack.\nInoltre tutte le richieste devono passare da questo router e manipolate per poter accedere alla rete dietro il NAT, non abbiamo il pretesto per parlare di end-to-end. (il prof. parla di lato porcherie (dietro il nat) e il lato bello che √® il fuori, e il router sembra quasi l‚Äôambiente di cambio vestiti, in modo che tutti si possano comprendere, lol).\nUna cosa molto brutta √® fare NAT di NAT. Dall\u0026rsquo;altra parte i NAT sembrano un modo per isolare computer di cui non mi fido (che conoscono un falso IP proprio che non √® raggiungibile esternamente.).\n","permalink":"https://flecart.github.io/notes/network-address-translation/","summary":"NAT Network address translation Introduzione Col il NAT possiamo avere tutto lo spazio degli IP di cui abbiamo bisogno, che per√≤ non sono esposti. All\u0026rsquo;esterno vengono esposte solamente l‚ÄôIP del NAT.\nSchema classico NAT\nQuindi in breve\nAll\u0026rsquo;esterno √® esposto solamente l\u0026rsquo;indirizzo del router, il router, a seconda della porta giusta, d√† in risposta al computer giusto, quindi all\u0026rsquo;interno della nostra rete conosciamo tutti gli indirizzi IP giusti.\nAddr translation table üü© Sembra che ad ogni richiesta ci sia una table di transizione all\u0026rsquo;interno del router che matcha porta ‚Üí indirizzo locale corretto!","title":"Network Address Translation"},{"content":"In this note we will first talk about briefly some of the main differences of the three main approaches regarding statistics: the bayesian, the frequentist and the statistical learning methods and then present the concept of the estimator, compare how the approaches differ from method to method, we will explain maximum likelihood estimator and the Rao Cramer Bound.\nShort introduction to the statistical methods Bayesian With bayesian methods we often assume a prior, often human picked, that allows to give a regularizer term over the possible distribution that we are trying to model. The prior is just an assumption on the distribution of the model $p(\\theta)$ and the likelihood $P(X \\mid \\theta)$, where $X$ are the features, and $\\theta$ the model. After we have these two distributions defined, we can then use the famous Bayes rule to compute the posterior, and chose the best possible model given our dataset in this manner. This induces a distribution over possible $\\theta$ that we can consider. Another characteristic is that the Bayes\u0026rsquo; rule is often infeasible to compute practically.\nThe quantity $P(X \\mid \\theta)$ could be very complicated if our model is complicated.\nFrequentist Fisher founded this view of statistics. Frequentist methods start by having assumptions on the space of the model parameters (this is the $\\mathcal{C}$ class) and likelihood too, but now this assumption is not a belief on the data itself, instead, a restriction that you have to pose in order to limit your search space (the need arises from practical purposes, not from beliefs, we want the most general possible models). But then, instead of using the Bayes\u0026rsquo; rule, they just try to maximize the possibility that a certain $\\theta$ has given rise to that data. In formulas we have: $$ \\hat{\\theta}_{ML} = \\arg \\max_{\\theta} P(x_{1}, \\dots, x_{n} \\mid \\theta) $$ This is how maximum likelihood estimators naturally arise with the frequentist approach. This is asymptotically true.\nUsually with enough data and big models, frequentist\u0026rsquo;s methods are preferred.\nStatistical learning The last possible interpretation, the statistical learning approach, I think is due to (Vapnik 2006)\u0026rsquo;s studies on Statistical learning theory, asserts that the best method is the one that minimizes the empirical risk, meaning it should have the least error on the test split of our dataset. So we try to chose the $\\theta$ is this way: (prolly this is wrong, needs to be fixed). $$ \\hat{\\theta}_{SL} = \\arg \\min_{\\theta} \\mathcal{R}(X^{\\text{test}}, \\theta) $$ where $\\mathcal{R}$ is defined as in Introduction to Advanced Machine Learning.\nBayesian and Frequentist head to head Estimators Estimators are functions or procedures that in this context of parametric models allow us to pin-point the correct parameters $\\theta$, in the case of the frequentist view, or give a distribution over possible $\\theta$s. Usually the generating function is called a density function parameterised by the $\\theta$ so we have to define the class of models and likelihood first.\nWe will mainly focus in this setting with the Maximum likelihood estimator\nThe Maximum Likelihood Estimator Given an assumption on the likelihood, we define the Maximum likelihood function to be $$ \\mathcal{L}(\\theta) = \\prod_{i=1}^{n} f(X^{(i)} ; \\theta) $$ We define the Maximum Likelihood Estimator (MLE) to be simply the best maximum likelihood $$ \\hat{\\theta}_{ML} = \\arg \\max_{\\theta} \\mathcal{L}(\\theta) $$ Sometimes is useful to consider the log-likelihood because sums are usually easier to handle. We will indicate the log version with $\\ell(\\theta)$.\nProperties of the MLE The important thing here is to be able to name the properties, not prove them. You can see a good presentation of these properties with Wasserstein chapter 9. Three main properties concern us:\nConsistency: (meaning it will converge to the real parameter, if modelling assumptions are correct) In formula it means that a point estimator $\\hat{\\theta}_{n}$ of a $\\theta$ is consistent if it converges in probability which is: $$ \\forall \\varepsilon \u003e 0, \\mathbb{P}(\\lvert \\hat{\\theta}_{n} - \\theta \\rvert \u003e \\varepsilon) \\to_{n \\to \\infty} 0 $$ Asymptotic efficiency: For well-behaved estimators, the MLE has the smallest variance for large $n$. Asymptotically normal: meaning the error will be Gaussian if we have too many samples. Which means that $$ \\frac{\\hat{\\theta} - \\theta_{*}}{\\text{standard deviation}} \\sim \\mathcal{N}(0, 1) $$ Equivariance meaning: if $\\hat{\\theta}$ is MLE of $\\theta$ then for any given $g$ we have that $g(\\hat{\\theta})$ is the MLE of $\\theta$. We will discuss these properties one by one. These properties are the reason why MLE is preferred over other estimators, such as means or medians.\nWe want to say that an estimator is efficient if it uses its information well, which means $$ \\lim_{ n \\to \\infty } \\mathbb{E} \\left[ (\\hat{\\theta}_{ML} - \\theta_{0})^{2} \\right] = \\frac{1}{I_{n}(\\theta_{0})} $$ Biases usually are good if it includes information that is correct with the data. (helps it learn faster, an example of why bias works is the Stein estimator, but I didn\u0026rsquo;t understood exactly why). Simple cases and reasoning for first principles usually helps you build the intuition to attack more complex cases. This is something you would need to keep in mind.\nRao Cramer Bound üü•+ Professor says this bound has same principle with the Heisenberg\u0026rsquo;s uncertainty principle with the Cauchy-Schwarz inequality somehow. But I don\u0026rsquo;t know about that.\nLet\u0026rsquo;s consider a likelihood $p(y \\mid \\theta)$, and some samples $y_{1}, \\dots, y_{n} \\sim p(y \\mid \\theta_{0})$. We want to know how well can we estimate the value $\\theta_{0}$ given $n$ samples. So let\u0026rsquo;s consider the expected deviation $\\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta_{0})^{2} \\right]$, which tells us how much can the estimated value $\\hat{\\theta}$ vary compared to the ground truth. We consider the value of a score to be (use the log because perhaps the $p$ could be large, and we try to see how much it varies when varying the parameters). $$ \\Lambda := \\frac{ \\partial }{ \\partial \\theta } \\log p(y \\mid \\theta) = \\frac{\\left( \\frac{ \\partial }{ \\partial \\theta } p(y \\mid \\theta) \\right)}{p(y \\mid \\theta)} $$ Now let\u0026rsquo;s consider the value of the expected score: $$ \\mathbf{E}_{y \\mid \\theta} \\Lambda = \\int \\frac{ \\partial }{ \\partial \\theta } p(y \\mid \\theta) \\, dy = \\frac{ \\partial }{ \\partial \\theta } 1 = 0 $$ which is an interesting result.\nLet\u0026rsquo;s consider another value: $$ \\mathbf{E}_{y \\mid \\theta} \\left[ \\Lambda \\cdot \\hat{\\theta} \\right] = \\frac{ \\partial }{ \\partial \\theta } \\int p(y \\mid \\theta) \\hat{\\theta} \\, dy = \\frac{ \\partial }{ \\partial \\theta } \\mathbf{E}_{y \\mid \\theta} \\left[ \\hat{\\theta} \\right] = \\frac{ \\partial }{ \\partial \\theta } \\left( \\mathbf{E}_{y \\mid \\theta} \\left[ \\hat{\\theta} \\right] - \\theta \\right) + 1 = \\frac{ \\partial }{ \\partial \\theta } b_{\\hat{\\theta}} + 1 $$ And the first part is the BIAS of our estimator, so we want to see how much we can lower the bias value when we want to assess these kinds of problems.\nWe now consider the cross correlation between $\\Lambda$ and $\\hat{\\theta}$\n$$ \\mathbf{E}_{y \\mid \\theta} \\left[ ( \\Lambda - \\mathbf{E} \\Lambda)( \\hat{\\theta} - \\mathbf{E} \\hat{\\theta}) \\right] = \\mathbf{E}_{y \\mid \\theta}\\left[ \\Lambda \\cdot \\hat{\\theta} \\right] - \\mathbf{E}_{y \\mid \\theta} \\left[ \\Lambda \\mathbf{E} \\hat{\\theta} \\right] = \\mathbb{E}_{y \\mid \\theta} \\left[ \\Lambda \\cdot \\hat{\\theta} \\right] $$ We now use Cauchy-Schwarz Inequality to observe that $$ \\mathbb{E}_{y \\mid \\theta} \\left[ \\Lambda \\cdot \\hat{\\theta} \\right] ^{2} = \\left( \\mathbf{E}_{y \\mid \\theta} \\left[ ( \\Lambda)( \\hat{\\theta} - \\mathbf{E} \\hat{\\theta}) \\right] \\right)^{2} \\leq \\mathbf{E}_{y \\mid \\theta}\\left[ \\Lambda^{2} \\right] \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\mathbf{E} \\hat{\\theta}) ^{2} \\right] $$ We now expand the second term: $$ \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\mathbf{E} \\hat{\\theta}) ^{2} \\right] \\mathbf{E}{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] - 2 \\mathbf{E}{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta) (\\mathbf{E} \\hat{\\theta} - \\theta) \\right] + \\mathbf{E}_{ y \\mid \\theta} \\left[ (\\mathbf{E} \\hat{\\theta} - \\theta)^{2} \\right] \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] - (\\mathbf{E} \\hat{\\theta} - \\theta) $$ Which is just $= \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] - b_{\\hat{\\theta}}$ Putting everything together we have that\n$$ \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] \\geq \\frac{\\left( \\frac{ \\partial }{ \\partial \\theta } b_{\\hat{\\theta}} + 1 \\right)^{2}}{\\mathbf{E}_{y \\mid \\theta}\\left[ \\Lambda^{2} \\right] } + b^{2}_{\\hat{\\theta}} $$ If we have an unbiased estimator, which means that $b_{\\hat{\\theta}} = 0$ then we have that the expected difference of the models is always greater than the expected value of the double power of the score, also known as the fisher information in maths:\n$$ \\mathbf{E}_{y \\mid \\theta} \\left[ (\\hat{\\theta} - \\theta)^{2} \\right] \\geq \\frac{1}{\\mathbf{E}_{y \\mid \\theta} \\left[ \\Lambda^{2} \\right] } = \\frac{1}{I_{n}(\\theta_{0})} $$ If instead we have a biased estimator\u0026hellip; I don\u0026rsquo;t know\u0026hellip;\nFisher information We discovered that the fisher information has something to do with the Rao-Cramer bound, let\u0026rsquo;s briefly analyze that:\n$$ \\mathbf{E}_{y \\mid \\theta} \\left[ \\Lambda^{2} \\right] = \\int p(y \\mid \\theta) \\left( \\frac{ \\partial }{ \\partial \\theta } \\log p(y \\mid \\theta) \\right)^{2} \\, dy =: I(\\theta) $$ Where $I(\\theta)$ is the fisher information. We can also define the Fisher information as the Variance of the score function i.e. : $$ I(\\theta) = Var(\\Lambda) = \\mathbb{E}_{y \\mid \\theta}((\\Lambda - \\mathbb{E}_{y \\mid \\theta}[\\Lambda])^{2}) $$ And simplifying, as we know that the mean of the score function is 0.\nThe Multivariable case Let\u0026rsquo;s consider this $$ I^{(n)} (\\theta) = \\int p(y_{1}\\dots y_{n} \\mid \\theta) \\left( \\frac{ \\partial }{ \\partial \\theta } \\log p(y_{1} \\dots y_{n}) \\right)^{2} \\, dy_{1}\\dots dy_{n} $$ And assuming we have independent variables we can see with some tricks and reasoning about he mean that: $$ \\int p(y_{1}\\dots y_{n} \\mid \\theta) \\left( \\frac{ \\partial }{ \\partial \\theta } \\log p(y_{1} \\dots y_{n}) \\right)^{2} \\, dy_{1}\\dots dy_{n} = \\int p(y_{1}\\dots y_{n} \\mid \\theta) \\left( \\sum \\Lambda_{i}^{2} \\right) \\, dy_{1}\\dots dy_{n} = n I^{(1)}(\\theta) $$ Which is a nice property of the fisher information\nStein estimator If we use this estimator we have that it is consistently better than the MLE, but we can\u0026rsquo;t prove that this is the best ever possible. We have to assume we have a multivariate random variable with $\\mathbb{R}^{d}$ with $d \\geq 3$ the exact details are not important, but we want to say that MLE is not always the best, this is the surprising fact.\n$$ \\hat{\\theta}_{JS} := \\left( 1 - \\frac{(d - 2)\\sigma^{2}}{\\lVert y \\rVert ^{2}} \\right) y $$ We then have that $$ \\mathbb{E}\\left[ (\\hat{\\theta}_{JS}- \\theta_{0})^{2} \\right] \\leq \\mathbb{E}\\left[ (\\hat{\\theta}_{MLE}- \\theta_{0})^{2} \\right] $$ References [1] Vapnik ‚ÄúEstimation of Dependences Based on Empirical Data‚Äù Springer 2006\n","permalink":"https://flecart.github.io/notes/parametric-models/","summary":"In this note we will first talk about briefly some of the main differences of the three main approaches regarding statistics: the bayesian, the frequentist and the statistical learning methods and then present the concept of the estimator, compare how the approaches differ from method to method, we will explain maximum likelihood estimator and the Rao Cramer Bound.\nShort introduction to the statistical methods Bayesian With bayesian methods we often assume a prior, often human picked, that allows to give a regularizer term over the possible distribution that we are trying to model.","title":"Parametric Models"},{"content":"1.1 Il cammino minimo 1.1.1 Definizione e caratteristiche 1.1.2 Costi negativi Sono cose molto brutte\n1.1.3 Cammino minimo semplice Costruzione di cammini minimi 1.2 Vertici 1.2.1 definizione distanza fra due vertici Costo del cammino minimo che li connette\nCondizione di bellman Albero dei cammini minimi Rilassamento Definizione Si va a vedere dove non funziona la disuguaglianza triangolare, se localmente non funziona ovvero se per esempio succede $D_{xu} + \\omega(u,y) \u003c D_{xy}$ per qualche vertice all\u0026rsquo;interno del grafo, so di per certo che la distanza $D_{xy}$ non √® una distanza, quindi possiamo riassegnarla in modo che verifichi la disuguaglianza\nBellman ford Questo algoritmo parte definendo tutti i vertici a distanza infinita, riassegna i valori partendo da un vertice prefissato.\nQuesto ragionamento √® solamente possibile con l\u0026rsquo;osservazione che il cammino √® minimo se tutti i suoi sottocammini lo sono, quindi mi sto costruendo cammini minimi da zero.\nSto riassegnando valore a tutti gli archi piano piano\u0026hellip;\nRilassamento topologico Bellman-ford con ordinamento Permette di non ripetere l\u0026rsquo;ordinamento di n vertici\nGrafi Aciclici Ordinamento topologico Dijkstra Lemma sull\u0026rsquo;espansione del grafo di esplorazione ordinamento\nPermette di non ripetere l\u0026rsquo;ordinamento di n vertici\nGrafi Aciclici Ordinamento topologico Dijkstra Lemma sull\u0026rsquo;espansione del grafo di esplorazione\n","permalink":"https://flecart.github.io/notes/cammini/","summary":"1.1 Il cammino minimo 1.1.1 Definizione e caratteristiche 1.1.2 Costi negativi Sono cose molto brutte\n1.1.3 Cammino minimo semplice Costruzione di cammini minimi 1.2 Vertici 1.2.1 definizione distanza fra due vertici Costo del cammino minimo che li connette\nCondizione di bellman Albero dei cammini minimi Rilassamento Definizione Si va a vedere dove non funziona la disuguaglianza triangolare, se localmente non funziona ovvero se per esempio succede $D_{xu} + \\omega(u,y) \u003c D_{xy}$ per qualche vertice all\u0026rsquo;interno del grafo, so di per certo che la distanza $D_{xy}$ non √® una distanza, quindi possiamo riassegnarla in modo che verifichi la disuguaglianza","title":"Cammini"},{"content":"Questa parte √® strettamente collegata conl a parte di Astrazione sul controllo.\nSi parla di passare le funzioni come dati. e quindi possono essere passati come se fossero dei parametri.\nun linguaggio di programmazione √® di ordine superiore qualora ammetta funzioni sia come parametro che come risultato di altre funzioni.\nLa parte molto simile alla precedente √® il fatto di valutare la funzione nell\u0026rsquo;ambiente iniziale, quindi bisogna utilizzare un sistema simile a quello del passaggio per nome.\nDeep and shallow binding Esempio di passaggio di funzione\nSi noti che questa distinzione fra scope statico e dinamico √® indipendente da queste regole di shallow e deep binding, queste regole qui ci dicono quale ambiente scegliere per la valutazione, mentre le altre ci dicono in che modo percorrere le catene, se andare per catena dinamica o statica.\nDeep Binding In questo caso viene associato alla funzione la x presente al momento di creazione del binding. Nell‚Äôesempio di sopra la x in riga 11. se ho scope dinamico, invece quello a riga 2 se ho scope statico\nShallow Binding In questo caso l‚Äôultimo binding possibile, quando sono proprio dentro la funzione (quindi la x attiva in quell‚Äôambiente). Nell‚Äôesempio di sopra la x in riga 5. Quindi si valuta la funzione al momento della chiamata.\nImplementazione del shallow binding Questa √® l\u0026rsquo;implementazione semplice, praticamente uguale allo scope dinamico in Nomi e Scope. Quindi cerco l‚Äôultima istanza presente fra tutte quelle presenti (se voglio scope statico, risalgo catena statica, altrimenti risalgo catena dinamica). Esattamente come si faceva per lo scope dinamico, infatti si potrebbe dire che √® pi√π naturale utilizzare scope dinamico con questo, anche se si potrebbe senza problemi utilizzare scope statico!.\nQuesto perch√© l‚Äôultima presente era quella ancora presente nell\u0026rsquo;ambiente di chiamata!\nImplementazione del deep binding Abbiamo detto che vogliamo valutare il deep binding seguendo la sua struttura (in questo caso statico, oppure nello scope di chiamata, in quel caso dinamico).\nQuesto √® easy, si segue direttamente lo stesso sistema fatto per il nome e per la catena statica, passando una coppia (funzione, ambiente) chiamata chiusura della funzione, la funzione sar√† il puntatore al codice, mentre l\u0026rsquo;ambiente √® determinato cos√¨:\nStatico In questo caso devo mettere nel puntatore d‚Äôambiente in cui la nostra funzione √® dichiarata, questo si pu√≤ avere a tempo di compilazione, perch√© conosco il livello di annidamento della funzione, e anche al momento della creazione del binding, quindi utilizzo un sistema simile in Nomi e Scope. (quindi scorrere la catena statica con la differenza che conosco, oppure display).\nDinamico In questo caso basta mettere l\u0026rsquo;ambiente in cui metto creo il binding fra parametro formale e attuale.\nIl caso del C In C non abbiamo cose come i lambda, non abbiamo quindi problemi di risoluzione di ambienti, perch√© tanto non posso dichiarare funzioni in ambienti non locali.\nSemplicemente in C tutte le funzioni passate come parametro vengono risolte nell\u0026rsquo;ambiente globale. Non c\u0026rsquo;√® proprio la necessit√† di utilizzare la catena statica! Tutto risolto a compile-time.\nFunzioni come ritorno di funzione Quello che viene ritornato √® una chiusura, ma come valutare una chiusura in un ambiente che √® gi√† scomparso üòµ ?? Scomparso nel senso che non l‚Äôavremmo pi√π sulla stack sto ambiente! Non possiamo fare altro che utilizzare un ambinete illimitato di vita. E dare la responsabilit√† al garbace collector l\u0026rsquo;onere di liberare questo ambiente.\n","permalink":"https://flecart.github.io/notes/fn-ordine-superiore/","summary":"Questa parte √® strettamente collegata conl a parte di Astrazione sul controllo.\nSi parla di passare le funzioni come dati. e quindi possono essere passati come se fossero dei parametri.\nun linguaggio di programmazione √® di ordine superiore qualora ammetta funzioni sia come parametro che come risultato di altre funzioni.\nLa parte molto simile alla precedente √® il fatto di valutare la funzione nell\u0026rsquo;ambiente iniziale, quindi bisogna utilizzare un sistema simile a quello del passaggio per nome.","title":"Fn Ordine superiore"},{"content":"Spire Spira quadrata Questo √® descritto nell\u0026rsquo;esempio 8.1 del Mazzoldi. √à stato descritto anche in un esercizio in classe (non √® importante).\nSpira circolare üü© Vedere pagina 245 Vogliamo cercare il valore del campo sull\u0026rsquo;asse della spira circolare. Questo √® semplice, basta usare la prima di Laplace e trovare l\u0026rsquo;apporto del campo magnetico al centro. Si pu√≤ anche pensare come momento magnetico, allora si utilizza sempre lo stesso discorso per la spira quadrata classica e il suo momento.\nProviamo a modellizzare il problema e risolvere ci√≤. Utilizziamo la prima legge di Laplace $$ d\\vec{B} = \\frac{\\mu_{0}i}{4\\pi} d\\vec{l}\\times \\frac{\\hat{r}}{r^{2}} $$ Con le variabili dichiarate come in figura, possiamo scrivere $dl = Rd\\theta$ e che $r^{2} = R^{2} + x^{2}$ E sappiamo che il verso del campo sull\u0026rsquo;asse √® sempre concorde sullo stesso verso (quindi i contributi si sommano, dobbiamo considerare per ragioni di simmetria solamente quella lungo l\u0026rsquo;asse.)\nAllora abbiamo\n$$ d\\vec{B} = \\frac{\\mu_{0}i}{4\\pi} \\frac{R}{R^{2} + x^{2}} d\\theta $$ E dobbiamo moltiplicare per il coseno di $\\varphi$ per avere la componente lungo l\u0026rsquo;asse: $d\\vec{B}_a = d\\vec{B} \\cdot \\cos \\varphi = d\\vec{B} \\cdot \\frac{R}{r}$ Da cui abbiamo che $$ d\\vec{B}_{a} = \\frac{\\mu_{0}i}{4\\pi} \\frac{R^{2}}{(R^{2} + x^{2})^{3/2}} d\\theta $$ E integrando su tutta la superficie della spira otteniamo\n$$ \\vec{B}_{a}(x) = \\frac{\\mu_{0}i}{4\\pi} \\frac{R^{2}}{(R^{2} + x^{2})^{3/2}} 2\\pi = \\frac{\\mu_{0}i}{2} \\frac{R^{2}}{(R^{2} + x^{2})^{3/2}} $$ Da cui possiamo ricavare il caso specifico in cui $x = 0$, abbiamo il campo al centro della spira\n$$ \\vec{B}_{a}(0) = \\frac{\\mu_{0}i}{2R} $$ Questo risultato ci sar√† utile per l\u0026rsquo;analisi del solenoide in seguito.\nMomento magnetico della spira Prova a ricorda quanto fatto per la spira quadrata in Spettrometri di massa. ossia ancora da capire bene (la cosa con l\u0026rsquo;inerzia, e il momento di dipolo, una cosa che dipende solamente dalla struttura) descritta da $i \\cdot S$ ossia dalla corrente e dalla superficie, da cui poi ha senso descrivere un concetto di flusso.\nComponenti del campo magnetico üü•+ Possiamo scriverlo in modo simile a quanto si ha precedentemente con il Dipolo elettrico. Quindi possiamo calcolare le componenti radiali e ad un certo angolo per questa spira, e data la somiglianza con essa sar√† esattamente nella stessa forma $$ B = \\frac{\\mu_{0}}{4\\pi} \\frac{m}{r^{3}}(2\\cos \\theta \\hat{r} + \\sin \\theta \\hat{\\theta}) $$ Con componente radiale e trasversa. Pg 254 Mazzoldi\nSolenoide Descrizione del solenoide üü© Vogliamo cercare di definire quale sia il campo magnetico presente sull'asse Utilizzando la funzione per la singola spira, abbiamo che basta integrare fra l\u0026rsquo;angolo formato fr ail primo e l\u0026rsquo;ultimo argomento del nostro solenoide, e facendo una cosa del genere dovrebbe venire molto pi√π semplice. La parte difficile qui √® riscrivere le variabili in funzione delle variabili che abbiamo: $$ \\begin{cases} r \\sin \\phi = R \\\\ x - x_{0} = R \\frac{\\cos\\phi}{\\sin \\phi} \\implies dx = \\frac{Rd\\phi}{\\sin ^{2}\\phi} \\end{cases} $$ Utilizzando queste e l\u0026rsquo;informazione sopra con la spira abbiamo che (utilizzando anche la prima di Laplace credo). $$ dB = \\frac{\\mu_{0}ni}{2} \\sin \\phi d\\phi $$ E integrando questo valore fra $\\phi_{1}$ e $\\phi_{2}$ ci viene una cosa clean, avremo che:\n$$ B =\\frac{\\mu_{0}ni}{2}(\\cos \\phi_{2} - \\cos \\phi_{1}) $$ Mettendo l\u0026rsquo;origine all\u0026rsquo;inizio della spira, e supponendo che la lunghezza della spira sia $d$ otteniamo questo per i valori di sopra e gli angoli di sopra, ma comunque spiega meglio il libro su questo. Campo esterno del solenoide üü®+ Se assumiamo che i raggi siano simili, allora prendiamo due contributi e abbiamo che $B = \\frac{\\mu_{0}i}{4\\pi} (dl_{1} r_{1} \\sin \\theta + dl_{2}r_{2}\\sin(\\pi - \\theta))$ E si elidono, e questo dovrebbe funzionare anche per cose un po\u0026rsquo; a lato!\nAl centro del solenoide üü© Bisogna in primo momento scrivere la derivazione di sopra in altro modo, possiamo trovare il valore del campo elettrico al centro del solenoide e otteniamo (vedere 248 Mazzoldi): $$ B_{0} = \\mu_{0}ni \\frac{d}{\\sqrt{ d^{2} + 4R^{2} }} $$ E si pu√≤ dimostrare che questo √® il punto massimo di $B$. E se supponiamo di essere molto molto distanti, con $d \\gg R$ allora avremo che il campo magnetico √® $$ B_{\\infty} = \\mu_{0}ni $$ E si pu√≤ dimostrare che all\u0026rsquo;interno il campo √® sempre quello, lo stesso, costante. Analisi tramite circuitazione del solenoide üü© Possiamo provare ad applicare Ampere Magnetismo per potere sapere quanto valga il valore del campo magnetico. Noi sappiamo che il campo magnetico all\u0026rsquo;interno (da fare ancora) √® sempre parallelo all\u0026rsquo;asse del solenoide Se mettiamo dentro il quadratino, possiamo notare come la circuitazione sia nulla, perch√© la corrente concatenata √® nulla, per questo motivo ad ogni momento √® nullo, ed √® sempre uguale a quello dell\u0026rsquo;a Prendendo questa figura, abbiamo che BC e AD che nada non c\u0026rsquo;√® niente, per√≤ in questo caso ci dovr√† essere un po\u0026rsquo; di circuitazione. Fuori abbiamo detto non c\u0026rsquo;√® nessun campo, mentre dentro √® uguale al campo. E si dimostra $$ \\oint Bds = Bh = \\mu_{0}nih = \u003e B = \\mu_{0}ni $$ Potrebbe essere interessante rifare l\u0026rsquo;analisi seguendo la 256, in cui si divide la corrente in circolare e lineare(falla e scrivi qui i risultati come esercizio al prossimo ripasso)\nToroide #### Campo esterno üü© Possiamo usare ampere e dire che corrente concatenata √® nulla e concludere che il campo magnetico √® nullo. #### Campo magnetico del toroide üü© Possiamo fare la sequente analisi: $$ \\oint Bds = \\mu_{0} Ni \\implies B 2\\pi r = \\mu_{0} Ni \\implies B = \\mu_{0} \\frac{Ni}{2\\pi r} $$ Quindi solo se $r$ √® piccolo si pu√≤ assumere che sia uniforme, altrimenti il valore cambia con quel valore. Si pu√≤ dire che $$ H = \\frac{Ni}{2\\pi r} $$ Vedere descrizione in Magnetismo nella materia\nToroide pieno üü©- Supponiamo ci sia un materiale dentro al toroide, allora so che $$ H = \\frac{Ni}{2\\pi r} $$ Riprendendo il ragionamento di sopra. Poi avendo questo posso sia calcolare B che M.\nTanti fili carichi #### Simmetria su asse y üü© Dalla figura 8.35 si pu√≤ dire che non abbiamo una componente $y$ , perch√© si eliminano. Quindi non abbiamo circuitazione sui pezzi AD e BC, per√≤ abbiamo cose sullo stesso verso ma cose oppose sugli altri versi!\nDiscontinuit√† parallela üü©- Stiamo sempre considerando una linea carica di correnti come da esempio sopra.\nProviamo ad usare ampere, abbiamo allora: $$ \\oint B ds = \\mu_{0}nhi \\implies 2hB = \\mu_{0}nhi \\implies B = \\frac{\\mu_{0}ni}{2} $$ Abbiamo sempre questo valore per il campo magnetico, ma i versi sono diversi. Questo giustifica anche una discontinuit√† della componente parallela, per il campo magnetico, di valore $\\mu_{0}ni$. Conviene talvolta scrivere $ni\\hat{u} = \\vec{J}$ e con $\\hat{u}$ la direzione della corrente, cos√¨ posso sapere subito quale sia la direzione diciamo.\nContinuit√† perpendicolare üü© Prendo sempre il classico cilindro, avr√≤ che $$ \\oint \\vec{B} \\hat{u}_{n} = \\oint \\vec{B}_{1} ds - \\oint \\vec{B}_{2}ds = B_{1\\perp}A_{1} - B_{2\\perp}A_{1} = 0 \\implies B_{1} = B_{2} $$ Flusso concatenato campi magnetici üü© Setting delle spire Poniamo di avere due spire. Vorrei sapere il flusso del campo magnetico indotto dentro la seconda superficie.\n$$ \\Phi (\\vec{B}) = \\int_{\\Sigma(\\Gamma_{2})} \\vec{B} \\cdot d\\vec{s} $$ Misurato in Weber, ossia Tesla per metro quadro.\nCalcoliamo il contributo della prima spira utilizzando la prima legge di ampere: $$ d\\vec{B} = \\frac{\\mu_{0}i}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}} $$ Integriamo tutti i contributi:\n$$ \\vec{B}_{1} = \\oint_{\\Gamma_{1}} d\\vec{B}_{1} = \\oint_{\\Gamma_{1}} \\frac{\\mu_{0}i}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}} $$ Quindi per avere il flusso \u0026ldquo;basta\u0026rdquo; fare l\u0026rsquo;integrale di nuovo poi sulla superficie aperta concatenata a quella spira.\nCoefficiente di mutua induzione üü© $$ \\Phi_{2} (\\vec{B}_{1}) = \\int _{\\Sigma(\\Gamma_{2})} \\vec{B}_{1} \\, \\vec{dS_{2}} = \\int _{\\Sigma(\\Gamma_{2})} [\\oint_{\\Gamma_{1}} \\frac{\\mu_{0}i}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}}] \\, \\vec{dS_{2}} $$ $$ \\Phi_{2} (\\vec{B}_{1}) = i_{1} \\int _{\\Sigma(\\Gamma_{2})} [\\oint_{\\Gamma_{1}} \\frac{\\mu_{0}}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}}] \\, \\vec{dS_{2}} = i_{1} M_{12} $$ Dove tutto quanto della seconda parte √® un fattore geometrico dipendente da\nCome sono disposti la prima e seconda superficie lineare I materiali con cui son fatti. Si pu√≤ dimostrare che $M_{12} = M_{21} = M$. La dimostrazione dovrebbe venire semplice con Vettore potenziale\nDimostrazione che sono uguali:\nInduttanza Introduzione valore fisico üü© Consideriamo l\u0026rsquo;autoinduzione, si pu√≤ applicare un concetto simile al precedente e possiamo scrivere che $$ \\Phi(\\vec{B}) = i_{1} \\int _{\\Sigma(\\Gamma_{1})} [\\oint_{\\Gamma_{1}} \\frac{\\mu_{0}}{4\\pi} d\\vec{l} \\times \\frac{\\hat{r}}{r^{2}}] = i_{1}L $$ Con $L$ l\u0026rsquo;induttanza della sfera, il cui verso della superficie lo intendo orientato secondo la regola della mano destra\nSia questo sia il coefficiente di mutua induzione √® misurato in $\\frac{W}{A}$. Questo si misura in Henry\nSolitamente l\u0026rsquo;induttanza di un circuito di casa √® $\\approx 10^{-7} H$.\nInduttanza su solenoide üü© Ora consideriamo l\u0026rsquo;induttanza con l\u0026rsquo;auto-flusso, abbiamo: $$ \\Phi(\\vec{B}) = Li $$ E consideriamo il campo magnetico in un solenoide: con $n = \\frac{N}{l}$ e $B_{0} = \\mu_{0}ni$ Allora il flusso in una singola spira √® (poi calcoliamo per l\u0026rsquo;intero solenoide assumendo che sia costante il campo all\u0026rsquo;interno e poi ci ricaviamo ) $$ \\Phi_{1}(\\vec{B}_{0}) = B_{0}S = \\mu_{0}niS \\implies \\Phi(\\vec{B}_{0}) = NB_{0}S = N\\mu_{0}niS \\implies L = N\\mu_{0}nS = n^{2}\\mu_{0}(Sl) = \\mu_{0}n^{2}V $$ Allora possiamo determinare una induttanza per unit√† di volume, che in questo caso √®: $$ \\mu_{0}n^{2} $$ Circuito con induttanza üü© Pu√≤ essere opportuno confrontare questo circuito con quello trovato in [Condensatori nel vuoto](/notes/condensatori-nel-vuoto) per la carica/scarica. Consideriamo la relazione fra forza elettromotrice e campo magnetico, abbiamo che $$ \\varepsilon_{IND} = -\\frac{d\\Phi(\\vec{B})}{dt} = -\\frac{d(Li)}{dt} $$ Da questo possiamo usare le Leggi di Ohm, in particolare la prima:\n$$ \\varepsilon + \\varepsilon_{IND} = Ri \\implies \\varepsilon = Ri + \\frac{Ldi}{dt} $$ Questo possiamo risolverlo separando le variabili in questo modo: $$ \\frac{\\varepsilon}{R} = i + \\frac{L}{R} \\frac{di}{dt} \\implies -\\frac{L}{R} \\frac{di}{dt} = i- \\frac{\\varepsilon}{R} \\implies \\frac{di}{i - \\frac{\\varepsilon}{R}} = -\\frac{R}{L}dt $$ Quindi ora abbiamo: $$ \\int_{0} ^{i(t)} \\frac{di}{i - \\frac{\\varepsilon}{R}} = -\\frac{R}{L} \\int_{0}^{t} \\, dt \\implies \\ln\\left( \\frac{\\left( i(t) - \\frac{\\varepsilon}{R} \\right)}{-\\frac{\\varepsilon}{R}} \\right) = -\\frac{R}{L} t $$ E l\u0026rsquo;ultimo passo questo ora si pu√≤ esprimere come $$ \\frac{\\left( i(t) - \\frac{\\varepsilon}{R} \\right)}{-\\frac{\\varepsilon}{R}} = e^{-\\frac{R}{L} t} \\implies i(t) = \\frac{\\varepsilon}{R} (1 - e^{-\\frac{R}{L} t}) $$ Una corrente con andamento asintotico, con limite $\\frac{\\varepsilon}{R}$ Con un tempo caratteristico stavolta di $\\frac{L}{R}$ Un buon esercizio √® verificare le dimensioni di questo.\nCon questo valore possiamo andare a calcolare il valore di $\\varepsilon_{IND}$ $$ \\varepsilon_{IND} = -\\varepsilon e ^{- Rt/L} $$ Che va a 0, asintoticamente abbiamo il caso classico\nEnergia dell\u0026rsquo;induttanza üü®++ Facciamo un altro genere di analisi: $$ \\varepsilon = Ri + \\frac{Ldi}{dt} \\implies \\varepsilon idt = Ri^{2}dt + Lidi $$ Abbiamo che il primo termina √® l\u0026rsquo;energia fornita dalla forza elettromotrice, l\u0026rsquo;energia dissipata per effetto Joule nella resistenza √® quello con la resistenza, mentre l\u0026rsquo;ultimo √® l\u0026rsquo;energia immagazzinata dalla induttanza. Allora possiamo dire: $$ dU_{l} = Lidi \\implies U_{l} = \\frac{1}{2}Li^{2} $$ Che confrontasi, molto simile a quanto trovato per il condensatore, in cui abbiamo $\\frac{1}{2}CV^{2}$l\nL\u0026rsquo;energia √® spesa per la costruzione del campo magnetico dal nulla, mentre per il condensatore √® stato usato per avere il campo elettrico.\nDensit√† energetica dell\u0026rsquo;induttanza üü©\u0026ndash; Abbiamo che $$ B = \\mu_{0}ni, L = \\mu_{0} n^{2}(ls) \\implies i = \\frac{B}{\\mu_{0}n} $$ Da cui abbiamo che $$ U_{L} = \\frac{1}{2}Li^{2} = \\frac{1}{2}(\\mu_{0}n^{2} lS) \\frac{B^{2}}{\\mu_{0}^{2}n^{2}} \\implies U_{L} = \\frac{1}{2} \\frac{B^{2}}{\\mu_{0}} (lS) $$ Da questo possiamo definire la densit√† energetica magnetica come $$ u_{l} = \\frac{1}{2} \\frac{B^{2}}{\\mu_{0}} $$ E si pu√≤ fare la stessa cosa con il vettore di spostamento, in questo caso con la magnetizzazione, che abbiamo studiato in Magnetismo nella materia. $$ u_{l} = \\frac{1}{2} \\mu_{0} H^{2} = \\frac{1}{2 }HB $$ ","permalink":"https://flecart.github.io/notes/geometrie-di-spire/","summary":"Spire Spira quadrata Questo √® descritto nell\u0026rsquo;esempio 8.1 del Mazzoldi. √à stato descritto anche in un esercizio in classe (non √® importante).\nSpira circolare üü© Vedere pagina 245 Vogliamo cercare il valore del campo sull\u0026rsquo;asse della spira circolare. Questo √® semplice, basta usare la prima di Laplace e trovare l\u0026rsquo;apporto del campo magnetico al centro. Si pu√≤ anche pensare come momento magnetico, allora si utilizza sempre lo stesso discorso per la spira quadrata classica e il suo momento.","title":"Geometrie di spire"},{"content":"Ultima modifica: September 18, 2022 9:43 AM Primo Abbozzo: September 16, 2022 9:52 AM Studi Personali: Yes\nElementi di ripasso Measure Theory Introduzione Requirements of the measure function Vorremmo cercare di estendere il concetto di misurabilit√† a gruppi molto pi√π ampi di un singolo intervallo, vorrei creare una funzione che sia in grado di misurare degli insiemi. *su vedr√† che sono impossibili).\nImpossibilit√† di questi requirements (assurdo) Costruzione dell‚Äôinsieme di interesse\nConsideriamo la classe di equivalenza definita come in immagine, mi costruisco (credo si chiami cosets) $\\Lambda$ in quel modo, prendendo le classi di equivalenza, posso dire che questo lambda non √® numerabile, perch√© se lo fosse ogni elemento di R sarebbe rappresentabile con lambda e un pezzo di X (ad esempio .\nAllora mi costruisco $\\Omega$ definito con assioma della scelta prendendo un singolo elemento in ogni classe di equivalenza. √à chiaro che questo insieme cos√¨ creato sia innumerabile.\nInoltre lo creo in modo che $\\Omega \\subseteq (0, 1)$, credo sia abbastanza intuitivo vedere che c‚Äô√® sempre un elemento compreso, quindi basta traslare.\nOra vado a utilizzare la regola 2, ossia invarianza per traslazione.\n$\\forall p, q \\in \\mathbb{Q}\\, (\\Omega + p) \\cap (\\Omega + q) = \\varnothing \\iff p \\neq q$\nSupponiamo che l‚Äôintersezione non sia vuota, allora $\\exists x : x = \\alpha + p = \\beta + q$, ossia ho che $\\alpha - \\beta = q - p \\implies \\alpha \\equiv \\beta \\implies \\alpha = \\beta \\implies p = q$ l‚Äôuguaglianza dalla relazione di equivalenza deriva dal fatto che appartengono alla stessa classe di equivalenza, ma per costruzione ne ho presa solo una, quindi sono uguali. Quindi se l‚Äôintersezione non √® vuota ho che p e q sono uguali. se sono uguali, invece, √® chiaro che la loro intersezione √® l‚Äôinsieme stesso, quindi non √® vuota.\nUpper bound\nOra che abbiamo questa invarianza, sarebbe utile per cercare di utilizzare 3 e farci dei bounds, e poi dimostrare l‚Äôassurdo con questi bounds, allora considero l‚Äôinsieme $\\bigcup_{-1","permalink":"https://flecart.github.io/notes/measure-theory/","summary":"Ultima modifica: September 18, 2022 9:43 AM Primo Abbozzo: September 16, 2022 9:52 AM Studi Personali: Yes\nElementi di ripasso Measure Theory Introduzione Requirements of the measure function Vorremmo cercare di estendere il concetto di misurabilit√† a gruppi molto pi√π ampi di un singolo intervallo, vorrei creare una funzione che sia in grado di misurare degli insiemi. *su vedr√† che sono impossibili).\nImpossibilit√† di questi requirements (assurdo) Costruzione dell‚Äôinsieme di interesse","title":"Measure Theory"},{"content":"Errore inerente Bisogna cercare di generalizzare il concetto di errore e lo si fa con la norma\nNorma vettoriale √à una funzione da $f: \\mathbb{R}^n \\to \\mathbb{R}$ indicata con due barrette, questa funzione mi d√† un concetto di distanza.\nPropriet√† della norma Si definisce una norma una funzione che soddisfa queste propriet√†\n$\\lVert x \\rVert \\geq 0$ per ogni $x \\in \\mathbb{R}^{n}$ $\\lVert x \\rVert = 0 \\iff x = 0$ $\\lVert \\alpha x \\rVert = \\lvert \\alpha \\rvert \\lVert x \\rVert$ per ogni $x \\in \\mathbb{R}^{n}$ e $\\alpha \\in \\mathbb{R}$ Vale la disuguaglianza triangolare, ossia $\\forall x, y \\in \\mathbb{R}^{n}, \\lVert x + y \\rVert \\leq \\lVert x \\rVert + \\lVert y \\rVert$. Convessit√† Analizzato meglio in Analisi di Convessit√†. Si pu√≤ dimostrare tramite la propriet√† 3 e 4 che la norma √® una funzione convessa. Infatti sia $f$ la funzione che soddisfa le propriet√† della norma (quindi effettivamente si pu√≤ chiamare norma). Allora:\n$$ f(\\theta x + (1 - \\theta)y) \\leq f(\\theta x) + f((1 - \\theta)y) = \\theta f(x) + (1 - \\theta)f(x) $$ Che finisce la dimostrazione.\nNorma püü©- $$ (\\sum_{i = 1}^{n}|x_i|^p)^{1/p} $$ Nel caso in cui $p = 2$ si chiama norma euclidea o viva\nNel caso $p = 1$ √® la distanza di manhattan\nNorma di chebichevüü® quando ho $p = +\\infty$ √® definita come $\\max_{1\\leq i \\leq n} |x_i|$ e si indica con $||x||_\\infty$\nEquivalenza fra le normeüü© Questo √® un teorema che ci permette di asserire che pi√π o meno tutte le norme hanno la stessa propriet√† di definire il concetto di distanza fra due punti poich√©\nSiano $||\\cdot||, ||\\cdot||_x$ due norme differenti, allora $\\exists m, M : m ||\\cdot|| \\leq || \\cdot || _x \\leq M||\\cdot ||$, ma questo vale solo se siamo in un campo finito.\nNorma matriciale Propriet√†üü© Vogliamo riprendere tutte le propreit√† descritte per la norma vettoriale, in pi√π vogliamo andare ad aggiungere un quinto punto ossia\nNorma naturale (o indotte)üü®‚Äî $$ ||A|| = \\sup_{x \\neq 0} \\dfrac{||Ax||}{||x||} = ||Ay||, y = \\dfrac{x}{||x||} $$ Considero solamente le righe, come se compattassi tutte le colonne in una\n$$ ||A||_\\infty = \\max_{1 \\leq i \\leq m} \\sum_{j = 1}^n|a_{ij}| $$ La norma-1 indotta √® molto simile, solo che ora compatto sulle colonne\n$$ ||A||_1 = \\max_{j} \\sum_{i = 1}^n|a_{ij}| $$ Norma 2, o norma spettrale:\n$$ ||A||_2 = \\sqrt{\\Lambda(A^TA)} $$ Con $A^TA$ simmetrica e semidefinita positiva. con $\\Lambda$ gli autovalori di $A^TA$\nSe $A$ ha rango massimo allora √® definita positiva, che √® il rango qui?\nLe norme dell‚Äôidentit√† in tutte queste cose indotte √® 1\nNorma di frobenius $$ ||A||_ F = \\sqrt{\\sum_{i = 1}^m \\sum_{j = 1}^n a^2_{ij}} $$ $||I||_F = \\sqrt{n}$\nSlide relazione fra le norme matriciali\nCondizionamento Vogliamo andare a definire il concetto di condizionamento per il sistema lineare.\nOssia vorremmo valutare quanto un piccolo cambiamento della matrice influisca sul risultato finale.\nChiamiamo come errore inerente la distanza fra il risultato vero e il risultato perturbato. Questo errore dipende fortemente da una natura dei dati in input (che sono mal condizionati)\nMal condizionamentoüü© si verifica quando a piccoli cambi della matrice di partenza, si ha un grande errore nel risultato (potremmo dire ordini di grandezza diversi, solitamente questo √® una cosa che non vorremmo che ci fosse)\nE la differenza fra i risultati √® un errore inerente, che dipende dai dati, ma non dall‚Äôalgoritmo\nPerturbazione e n-condizionamentoüü© Vogliamo ora vedere quanto siano grandi gli effetti di una perturbazione su una matrice. si pu√≤ dimostrare che\n$$ \\dfrac{||\\Delta x||}{||x||} \\leq k(A) \\dfrac{||\\Delta A|| }{||A||} $$ Con $k(A)$ il numero di condizione della matrice, solamente pi√π √® grande pi√π l\u0026rsquo;errore viene amplificato., se questo valore √® sempre maggiore o uguale a 1 √® non singolare.\n$$ k(A) = ||A||\\cdot||A^{-1}|| \\geq ||AA^{-1}|| = ||I|| = 1 $$ Slide ricavo relazioni condizionamento\n","permalink":"https://flecart.github.io/notes/norme-e-condizionamento/","summary":"Errore inerente Bisogna cercare di generalizzare il concetto di errore e lo si fa con la norma\nNorma vettoriale √à una funzione da $f: \\mathbb{R}^n \\to \\mathbb{R}$ indicata con due barrette, questa funzione mi d√† un concetto di distanza.\nPropriet√† della norma Si definisce una norma una funzione che soddisfa queste propriet√†\n$\\lVert x \\rVert \\geq 0$ per ogni $x \\in \\mathbb{R}^{n}$ $\\lVert x \\rVert = 0 \\iff x = 0$ $\\lVert \\alpha x \\rVert = \\lvert \\alpha \\rvert \\lVert x \\rVert$ per ogni $x \\in \\mathbb{R}^{n}$ e $\\alpha \\in \\mathbb{R}$ Vale la disuguaglianza triangolare, ossia $\\forall x, y \\in \\mathbb{R}^{n}, \\lVert x + y \\rVert \\leq \\lVert x \\rVert + \\lVert y \\rVert$.","title":"Norme e Condizionamento"},{"content":"Introduzione Intuizione del campo elettrostatico Elettrostatico vs elettrodinamico üü© Andiamo a chiamare elettrostatico perch√© nel nostro caso non si sta muovendo nessuna carica all\u0026rsquo;itnerno di questo campo.\nPropriet√† del campo elettrostatico (5) üü® Le linee di forza in ogni punto dello spazio sono tangenti e concorde al campo in quel punto; le linee di forza si addensano dove l\u0026rsquo;intensit√† del campo e maggiore; le linee di forza non si incrociano mai, in quanto in ogni punto il campo √® definito univocamente e non pu√≤ avere due direzioni distinte. le linee di forza hanno origine dalle cariche positive e terminano sul cariche negative; qualora ci siano solo cariche dello stesso segno le linee di forza si chiudono all\u0026rsquo; infinito; nel caso di cariche di segno opposto, ma eguali in modulo, tutte le linee the partono dalle cariche positive si chiudono su quelle negative (induzione completa), alcune passando eventualmente per l\u0026rsquo;infinito; se invece le cariche non sono eguali in modulo, alcune linee terminano o provengono dall\u0026rsquo; infinito. Carica esploratrice üü© √à anche chiamata carica di prova, √® una carica fittizia messa per esplorare la struttura del campo elettrico in un certo spazio\nTalvolta (Mencuccini), si potrebbe definire il valore del campo come $$ \\vec{E}(\\vec{r}) = \\lim_{ q \\to 0 } \\frac{\\vec{F}}{q} $$ in questo caso $q$ √® una carica di prova, talmente piccola che non varia il campo, utilizzato per sondare il valore del campo in un certo punto. Da un punto di vista intuitivo, costruiamo la linea passo passo, a tratti infinitesimi, e componiamo tutto lo spazio con queste.\nCampo come grandezza üü© Il campo elettrico √® proprio una grandezza fisica (ossia una propriet√† misurabile di un oggetto non √® solo una cosa comoda matematicamente), che √® solitamente utilizzata per conoscere la forza applicata dal campo elettrico in un certo punto. √à una caratteristica dello spazio e una carica √® in grado di modificare questo aspetto.\nSi rappresentano uscenti se positiva, entrante se negativa Definizione di campo elettrico üü© $$ \\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q}{R^{2}} \\hat{R} $$ Dove $Q$ √® la sorgente di carica, si pu√≤ usare il principio di sovrapposizione anche in questo caso\nFlusso di campo vettoriale üü© Dato un certo campo vettoriale, il flusso studia la relazione fra questi e una superficie a scelta. Intuitivamente si potrebbe dire quante linee di campo attraversano quella superficie.\nNormalmente si indica cos√¨ $$ \\phi_{S}(\\vec{F}) = \\iint_{S} \\vec{F} \\cdot d\\vec{s} = \\iint_{S} \\vec{F} \\cdot \\hat{n} \\, ds $$ Con $\\hat{n}$ indicato per marcare che deve essere orientato e perpendicolare alla superficie considerata. Esempio di vettori normali alla superficie, nel nostro esempio il valore di $\\hat{n}$.\nCampo tangenziale e parallelo üü© Questa parte la devo ancora scrivere per bene, in breve andiamo a trattare della discontinuit√† del flusso di fronte a una superficie carica, e il fatto che la circuitazione parallela √® 0. La discontinuit√† √® trattata a pagina 79 del Mazzoldi.\nQuesta parte serve per spiegare alcune propriet√† del campo nei materiali conduttori trattata in Conduttori elettrici. Alla fine possiamo andare a concludere che $$ \\Delta \\vec{E}_{\\parallel} = 0 $$ Questo √® necessario per poter spiegare la rifrazione nei mezzi, vedi Condensatori con dielettrici.\nProblemi classici Dipolo elettrico Fatto (molto) meglio in Dipolo elettrico\nIntroduzione al problema del dipolo elettrico üü© Questo sar√† uno dei nostri primi problemi (e probabilmente anche fra le pi√π semplici che ci permetteranno di analizzare il campo). Abbiamo due cariche (stessa carica assoluta), una positiva e una negativa, vogliamo andare a capire come √® fatto il campo elettrico attorno a queste cariche.\nModellizzazione del problema dipolo elettrico üü®+ Consideriamo un punto esattamente a met√† fra le due cariche, sia $d$ la distanza fra le due cariche, mettiamo il nostro sistema di riferimento come in figura. il campo elettrico in quel punto √® dato da. $$ \\vec{E}_{tot} = \\vec{E}_{+} + \\vec{E}_{-} = \\frac{Q}{4\\pi \\varepsilon_{0}}\\left( \\frac{\\hat{R}_{+}}{R^{2}_{+}} + \\frac{\\hat{R}_{-}}{R^{2}_{-}} \\right) $$ Usiamo ora l\u0026rsquo;ipotesi che il punto sia a met√†, abbiamo allora che la distanza in modulo sia uguale, avremo che $$ \\vec{E}_{tot} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q}{R^{3}}\\left( \\left( y \\hat{j} - \\frac{d}{2} \\hat{k} \\right) - \\left( y \\hat{j} + \\frac{d}{2} \\hat{k} \\right) \\right) = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q}{R^{3}} (-d \\hat{k}) $$ Il valore $-d Q\\hat{k}$ avr√† un significato speciale, sar√† il momento di dipolo\nIl momento di dipolo (2) üü© Direttamente proporzionale fra $d$, la distanza fra le cariche e $q$ la quantit√† di carica delle due. Mi da informazioni sulla geometria e sulla carica del sistema Per questo √® comodo poter analizzare un caso cos√¨ semplificato di dipolo\nDistribuzione di carica uniforme lineare infinita Questa sar√† la nostra seconda applicazione del concetto di campo e di sovrapposizione che conosciamo\nIntroduzione problema carica uniforme lineare üü© Abbiamo sull'asse $Z$ una distribuzione uniforme lineare, vogliamo cercare di capire come √® fatto il campo in questo caso #### Modellizzazione problema carica uniforme lineare infinita üü© Consideriamo un punto $P$ come in figura, sia dato un piccolissimo contributo di campo $d \\vec{E}$, vogliamo cercare di capire come √® fatto questo contributo per l'intera linea lineare. Possiamo fare una osservazione di simmetria e affermare che la componente $z$ si elimina (ad ogni carica corrisponde una uguale e contraria)., mentre la componente $x$, quella che esce o entra dal piano √® inesistente per come √® fatto il sistema la soluzione diventa quindi $\\vec{E} = E_{y} \\hat{j}$ ossia $$ E_{y} = \\int \\lvert d\\vec{E} \\rvert \\cos \\theta = \\frac{\\lambda}{4\\pi\\varepsilon_{0}} \\int _{-\\infty}^{+\\infty} \\frac{dz}{r^{2}} \\cos \\theta $$ Le ultime tre sono strettamente relazione fra di loro, quindi le possiamo esprimere con cose di angoli, ora l\u0026rsquo; integrale finale diventerebbe, con $r'$ la distanza del punto con la linea retta. Questo funziona perch√© si pu√≤ osservare che $$ dz = r' \\, \\frac{ d \\tan\\theta}{d\\theta} $$ Perch√© cos√¨ abbiamo espresso totalmente l\u0026rsquo;altezza in funzione dell\u0026rsquo;angolo, √® un trick che √® stato usato molto spesso quindi √® molto importante che te lo impari.\n$$ \\int _{-\\infty}^{+\\infty} \\frac{dz}{r^{2}} \\cos \\theta = \\int _{-\\frac{\\pi}{2}}^{+\\frac{\\pi}{2}} \\frac{\\cos\\theta}{r'}d\\theta $$ La soluzione diventa quindi $$ E_{y} = \\frac{1}{2\\pi\\varepsilon_{0}} \\frac{\\lambda}{r'} $$ Osservazione variare campo elettrico al variare dei problemi visti üü© Un osservazione interessante √® che il campo elettrico √®\nSingola carica -\u0026gt; $\\frac{1}{r^{2}}$ Dipolo elettrico -\u0026gt; $\\frac{1}{r^{3}}$ Lineare -\u0026gt; $\\frac{1}{r}$ Miscellanea: problemi semplici Flusso in una sfera üü© Questa √® una semplicissima applicazione della definizione di flusso. Consideriamo una sfera, poniamo il sistema di riferimento al centro di questa sfera, ci chiediamo quanto √® il flusso del campo radiale che varia come $\\vec{F} = k \\vec{r}, \\vec{r} = (x, y , z)$?\nApplicando la definizione di flusso abbiamo: $$ \\phi_{s}(\\vec{F}) = \\oint \\vec{F} \\cdot d\\vec{s} = \\iint k \\vec{r} \\cdot d\\vec{s} = kr \\iint ds =4\\pi r^{3}k $$ Potenziale elettrostatico Introduzione al potenziale elettrostatico Abbiamo studiato in dinamica che il potenziale √® un concetto strettamente legato al Lavoro, ossia dalla quantit√† di energia necessaria per spostare un oggetto da un punto all\u0026rsquo;altro, vogliamo cercare di definire le relazioni che intercorrono nel caso della forza elettromagnetica\nRotore nullo =\u0026gt; forza conservativa üü© Teorema: $$ \\vec{\\nabla} \\times \\vec{F} \\implies \\vec{F} \\text{ √® una forza conservativa} $$ Il motivo √® che per il teorema presente in #Teorema di stokes, abbiamo che $$ \\oint_{L} \\vec{F} \\cdot d\\vec{l} = \\iint_{S} \\vec{\\nabla} \\times \\vec{F} \\,d\\vec{s} $$ E se abbiamo che il rotore √® nullo, allora la forza √® conservativa perch√© per definizione √® conservativa se non dipende dal percorso, e la cosa che un circuito chiuso √® sufficiente per dimostrare il sopra.\nNote mie che non ho ben capito: Questo si pu√≤ dimostrare senza molta difficolt√† se scriviamo la forza di coulomb nella forma cartesiana, alla fine facendo la derivata si dovrebbe cancellare tutto.\nForza radiale =\u0026gt; forza conservativa üü© Consideriamo una qualunque forza radiale e qualunque percorso lineare Consideriamo il setting come in immagine, abbiamo un qualunque percorso, e una carica che crea forza in modo radiale diciamo.\nAllora possiamo osservare se prendiamo un segmentino infinitesimale, ci sembrer√† una scaletta, ma la forza coseno √® attiva solamente in $\\bar{AB} \\text{ e } \\bar{CD}$ questo ci permette di affermare che il lavoro (quella cosa potenziale) √® solamente dipendente dalla distanza\nFormula dell\u0026rsquo;energia potenziale elettrostatica üü© Proviamo in questo momento a derivare la formula per il potenziale elettrostatico, valido per praticamente ogni percorso\n$$ L_{AB} = -\\int _{A}^{B} \\vec{F} \\cdot d\\vec{r} = -\\int _{A}^{B} \\lvert \\vec{F} \\rvert ds \\cos \\theta = -\\int _{A}^{B} \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Qq}{r_{p}^{2}} \\cos \\theta \\, ds = -\\frac{Qq}{4\\pi\\varepsilon_{0}} \\int _{A}^{B} \\frac{1}{r_{p}^{2}} \\, dr_{p} = \\frac{Qq}{4\\pi\\varepsilon_{0}} \\left( \\frac{1}{r_{a}} - \\frac{1}{r_{b}} \\right) $$ (col coseno dello spazio percorso, abbiamo che il valore dipenden solamente dalla distanza, per questo motivo √® semplice, un altro motivo per spiegare questo √® spezzettare il percorso con zigzag infinitesimi). E dall\u0026rsquo;ultimo possiamo capire il potenziale classicamente definito\n$$ U(r) = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Qq}{r} + const $$ Quindi dipende solamente dalla distanza a meno di una costante additiva. Il motivo per cui (credo) possiamo utilizzare la costante additiva √® che ci basta fissare un altro punto ad hoc, fissato un altro punto, diventa allora possibile definire il potenziale o l\u0026rsquo;energia potenziale in ogni punto dello spazio prendendo quello come riferimento.\nForza elettromotrice üü© Spiegato in maggiore dettaglio in Leggi di Ohm, dove iniziamo a parlare di circuiti. La circuitazione per un campo elettrico √® definito in modo molto simile a quello di una forza qualunque\n$$ \\mathbb{\\varepsilon} = \\oint_{L} \\vec{E} \\cdot d\\vec{l} $$ E valgono esattamente le stesse propriet√† che abbiamo dimostrato sopra riguardo al rotore.\nPotenziale elettrostatico Definizione üü© Questa non √® una energia, si potrebbe dire che √® la capacit√† di creare energia potenziale per singole cariche\nDefiniamo $$ V(A) = \\frac{U(A)}{q} $$ Che in un certo senso √® il lavoro fatto dal campo, non dalla forza (NOTA: non √® corretto dire lavoro di un campo, non credo sia un concetto ben definito).\nAnalisi di dimensionalit√† per potenziale elettrostatico üü© $$ V(r) = \\frac{1}{4\\pi \\varepsilon_{0}} \\frac{Q}{r} \\implies \\left[ V \\right] = \\left[ U \\right] \\left[ Q^{-1} \\right] =\\left[ M \\right] \\left[ L^{2} \\right] \\left[ T^{-2} \\right] \\left[ Q^{-1} \\right] $$ E quindi potremmo misurare il campo elettrico anche come volt su metri, per la definizione con gli integrali\nPrincipio di sovrapposizione per potenziale elettrostatico üü© L\u0026rsquo;esatto principio che abbiamo descritto in precedenza per il campo elettrico vale anche il per il potenziale elettrostatico, anzi potrebbe essere utile nel calcolo del campo elettrico stesso se possiamo derivare in un singolo punto, otteniamo il campo elettrico in quel punto.\nSuperfici equipotenziali üü© Possiamo definire delle sfere che abbiamo tutti lo stesso potenziale elettrostatico, che da un punto di vista matematico basta stessa r ma serve il concetto di angolo solito per poter caratterizzare matematicamente questo concetto.\nTODO: avere superficie della sfera con angoli solidi, perch√© questa √® l\u0026rsquo;analisi pi√π semplice per superfici equipotenziali di singola carica\nEquazione di Poissonüü© $$ \\vec{\\nabla} \\cdot \\vec{E} = \\vec{\\nabla} \\cdot (-\\vec{\\nabla}V) = \\frac{\\rho}{\\varepsilon_{0}} $$ Quindi l\u0026rsquo;equazione di poisson √®\n$$ \\nabla^{2} V = -\\frac{\\rho}{\\varepsilon_{0}} $$ Nel caso in cui non ci sia carica in un punto nello spazio abbiamo l\u0026rsquo;equazione di Laplace\n$$ \\nabla^{2} V = 0 $$ Per qualche motivo a me oscuro, la soluzione dell\u0026rsquo;equazione di Poisson in coordinate cartesiane √®:\n$$ V(x, y, z) = \\frac{1}{4\\pi\\varepsilon_{0}} \\int _{\\Sigma} \\frac{\\rho(x', y', z')\\, dx'dy'dz'}{\\sqrt{ (x - x')^{2} + (y - y')^{2} + (z - z') ^{2} }} $$ Questo risulta utile per caratterizzare la soluzione dell\u0026rsquo;equazione di Poisson per il Vettore potenziale.\n","permalink":"https://flecart.github.io/notes/campo-elettrico/","summary":"Introduzione Intuizione del campo elettrostatico Elettrostatico vs elettrodinamico üü© Andiamo a chiamare elettrostatico perch√© nel nostro caso non si sta muovendo nessuna carica all\u0026rsquo;itnerno di questo campo.\nPropriet√† del campo elettrostatico (5) üü® Le linee di forza in ogni punto dello spazio sono tangenti e concorde al campo in quel punto; le linee di forza si addensano dove l\u0026rsquo;intensit√† del campo e maggiore; le linee di forza non si incrociano mai, in quanto in ogni punto il campo √® definito univocamente e non pu√≤ avere due direzioni distinte.","title":"Campo elettrico"},{"content":"This note is useful to gather in a single place the description of some common problems in CS and their theoretical implications explained in other notes.\nThe Clique problem Description of the problem This problem is in NP, find all sub-graphs where all nodes are connected (this set of nodes forms a complete graph).\nWe can prove that the problem is in NP because there is an easy non-deterministic algorithm that computes it. See Time and Space Complexity#Clique problem for details of this proof.\nA little more formally: Given a graph $\\langle G, E \\rangle$ we say that the solver for the clique problem returns a list of nodes $N \\subseteq G$ such that that is a complete graph. A subset of this problem is when we need cliques of $k$ nodes. So the problem is to return these $k$ nodes if they exist (or just say they don\u0026rsquo;t ).\nThe SAT problem SAT stands for SATisfiability.\nBackground notions Boolean formulas We define a language with variables and their negations. Logical and and or operations. Then we assign all possible values to the variables and see their end values after passing to the polynomial problem. But this explodes exponentially. Sometimes the boolean formula is in Logica Proposizionale, another time using Logica del Primo ordine.\nThird conjunct normal form If we have only OR operations, that is a clause. Then we say it is in conjunct normal form if these clauses are linked with AND operations. It\u0026rsquo;s third when the clauses have exactly tree variables.\nWhy is this problem important Many historical approaches used this problem to think about satisfiability. This problem is also important in constraint programming. TODO: add links in the future when it happens.\nDefinition of 3-SAT problem Given a third conjunct normal form, find assignments such that it satisfies the boolean formula.\n3-SAT $\\leq_{P}$ CLIQUE We prove using the notion of Cook-Levin and Savitch#Poly-reduction that 3-sat is reducible polynomially to clique.\nIn order to do this we need to transform the problem into graph format, and graph format to assignments.\nConversion strategyüü© For every clause we defines 3 nodes. Then we link every node in this way:\nIf in same clause, don\u0026rsquo;t link If in other link, link only if it\u0026rsquo;s not your negation. Example:\nWe can prove that this conversion is polynomial (clear, you can write the algo and prove it üí†).\nWhy does the conversion work? Now, if the 3-SAT formula is satisfiable, then at least one node for each clause is true. We select a single true node for each clause, and this brings us the clique. By construction, this is a complete sub-graph. So this reduction works. Why does it work? Because as we have $k$ clauses, we have selected a node from each clause, and we know that each node is connected to each other node, because if not that wouldn\u0026rsquo;t be satisfied (by construction there is a link with other node $\\iff$ the node is in other triplet $\\land$ it\u0026rsquo;s not himself negated).\nWe now have a graph, let\u0026rsquo;s suppose we have a clique, then the 3-SAT is satisfiable because of similar arguments above (just assign true to those variables).\nTrue quantified Boolean formula Also called TQBF, it is defines as follows:\n$$ TQBF = \\left\\{ \\langle F \\rangle \\mid F \\text{ is a true boolean statement } \\right\\} $$ Where statement is a boolean formula were the values are all bounded. This problem is important for Time and Space Complexity analysis.\nTQBF is PSPACE-complete Remember that a problem is PSPACE complete if it is in PSPACE and every other PSPACE languages can be poly-reduced to this language.\nTQBF is in PSPACE This technique is something similar to Sintassi e RI strutturali technique.\nIf there are no quantifiers, evaluate the statements, and if it is true accept, else reject. If we have a format like $F = \\exists x.G$ Then enumerate all: evaluate the truthfulness given $x = 1$, and then with $x = 0$ if one of them is true then return true. If we have a format like $F = \\forall x. G$ then evaluate both $x= 1$ and $x = 0$ and if both true return true. This is a recursive algorithm, and it is $O(m)$ where $m$ are the terms (max $m$ recursive passes, every recursive pass has at most a single term memorized). $\\square$. TQBF is PSPACE-hard This is difficult to grasp. Go to see (Sipser 2012) Chapter 8.3 pp. 340.\nThe idea is to convert the computation of the TM that decides the given language $L$ using some formulas like $\\phi_{c_{1}, c_{2}, t}$ which means that this is true if it\u0026rsquo;s possible to go from $c_{1}$ to $c_{2}$ in at most $t$ steps. In this setting $c_{1}$ and $c_{2}$ are different configurations of the Turing Machine.\nThe proof is by induction:\nIf $t=1$ then $c_{1}=c_{2}$ or it\u0026rsquo;s possible to go into $c_{2}$ using a single step. This is verifiable using the windows argument in the Cook-Levin theorem. Else it\u0026rsquo;s a little bit more difficult. It\u0026rsquo;s easy to verify it ü§†. $$ F_{c, c', t} = \\exists m_{1} \\forall(c_{3}, c_{4}) \\in \\left\\{ (c, m_{1}), (m_{1}, c') \\right\\} F_{c_{3}, c_{4}, \\frac{t}{2}} $$ Given this inductive formulation, we can observe that we add only $O(n^{k})$ quantifiers in the recursive proof. So the formula has $\\log (2^{dn^{k}})$ induction steps which is $O(n^{k})$. So this problem is PSPACE-hard. Two player games It is possible to prove that every two player zero-sum game like chess or Go, that uses a minimax tree search strategy can be expressed into a TQBF problem like this (informally): For every move of the opponent, exists one of my moves such that for every move of the opponent \u0026hellip;. -\u0026gt; I win. This is a TQBF statement.\nThe Tiling Problem Formalizzazione del problema Definizione formale del tiling Consideriamo una tupla $\\langle \\mathcal{T}, t_{0}, H, V \\rangle$\n$\\mathcal{T}$ √® un insieme di piastrelle. $t_{0} \\in \\mathcal{T}$ √® la piastrella d\u0026rsquo;origine. $H \\subseteq \\mathcal{T} \\times \\mathcal{T}$ le regole di adiacenza orizzontali. $V \\subseteq \\mathcal{T} \\times \\mathcal{T}$ le regole di adiacenza verticali. L\u0026rsquo;obiettivo √® vedere se √® possibile riempire tutto il piano con queste piastrelle, all\u0026rsquo;infinito. Sappiamo gi√† che non √® sempre possibile farlo. Ci chiediamo se √® automatizzabile. Questo problema √® stato risolto nel 1966, e sembra non essere riconoscibile nemmeno.\nOssia in matematichese definire la funzione $f : \\mathbb{N} \\times \\mathbb{N} \\to \\mathcal{T}$ Con\n$f(1, 1) = t_{0}$ $\\forall n,m \\in \\mathbb{N}, (f(n, m), f(n + 1, m)) \\in V$ $\\forall n,m \\in \\mathbb{N}, (f(n, m), f(n, m+1)) \\in H$ Strategia di dimostrazione Vogliamo ridurlo da $ETH^{-}$ che abbiamo spiegato in Halting Theorem and Reducibility. Questo √® un linguaggio non riconoscibile, perch√© il suo complemento √® riconoscibile in modo banale.\nQuesta dimostrazione avr√† un sacco di punti molto tecnici per dire che una macchina di turing deve essere tradotta in un problema di tiling\u0026hellip;\nDimostrazione irriconoscibilit√† del tiling L\u0026rsquo;idea principale √® che con un tiling posso simulare l\u0026rsquo;esecuzione di una macchina di Turing. E in questo modo riduco il problema a un Halt. Perch√© sapere tassellare significa sapere dire quando una macchina di Turing finisce.\nCodifica delle regole dei tiling Posso codificare sia i tile disponibili, sia le regole di adiacenza in questo modo.\nPoi vogliamo codificare ogni casella verticale un singolo step di computazione.\nCella di identit√† Questa cella non fa niente. Celle di transizione Possiamo codificare le funzioni di transizione della macchina di Turing. Poi ho ancora le cose che mantengono il simbolo nella cella di arrivo.\nConclusione sse non si ferma la macchina, allora esiste un tiling (che √® una cosa banale perch√© significa che continua all\u0026rsquo;infinito, e quindi posso mappare tutto).\nReferences [1] Sipser ‚ÄúIntroduction to the Theory of Computation‚Äù Cengage Learning 2012\n","permalink":"https://flecart.github.io/notes/common-problems-in-theoretical-cs/","summary":"This note is useful to gather in a single place the description of some common problems in CS and their theoretical implications explained in other notes.\nThe Clique problem Description of the problem This problem is in NP, find all sub-graphs where all nodes are connected (this set of nodes forms a complete graph).\nWe can prove that the problem is in NP because there is an easy non-deterministic algorithm that computes it.","title":"Common problems in Theoretical CS"},{"content":"Per trovare i zeri di una funzione continua non lineare non esistono alcuni metodi diretti che ci portano subito a una soluzione. Per questo motivo andremo ad analizzare molteplici pasis iterativi per trovare i zeri di una funzione.\nLa discussione di convergenza di ordine p √® stata gi√† discussa qui Note introduttive convergenza e iterazione , per quanto riguarda i metodi iterativi per risolvere sistemi di equazioni lineari\nGlobale e local Ricordiamo di Norme e Condizionamento, in cui il condizoinamento era pi√π o meno una stima di quanto cambia la soluzione quando cambia brevemente l\u0026rsquo;input. Ma ora vogliamo estendere il concetto per equazioni non lineari.\nSlide dimo (non chiede) espsilon √® una perturbazione gestita da una funzione h Cose da ricordare\nSe √® uno zero con moltiplicit√† maggiore di 1 √® sempre mal condizionato Altrimenti √® nell\u0026rsquo;ordine dell‚Äôinversa della derivata calcolata in quel punto Slide di questa ultima roba\nMetodo di bisezione Introduzione al metodo di bisezione Questo metodo funziona per funzione continua in un intervallo e $f(a)f(b) \u003c 0$, per il teorema degli zeri esiste una soluzione, allora dobbiamo andare ad iterare l‚Äôargomento fin quando non abbiamo una stima abbastanza precisa del punto.\nSlide\nIn pratica va a dimezzare sempre ad ogni iterazione l‚Äôintervallo in cui pu√≤ essere presente il nostro numero.\nConvergenza e Costo Una cosa bella di questo, in confronto ai metodi per equazioni lineari √® che posso stimare il numero di iterazioni\nSlides\nIl costo di questo metodo dipende dalla funzione che bisogna essere calcolata ad ogni iterazione, ma al massimo facciamo un numero di iterazioni logaritmico rispetto al nostro intervallo, quindi qualcosa del tipo\n$$ O(\\log(b - a) \\times O(f)) $$ Talvolta pu√≤ succedere che √® sempre costante la variabile in mezzo, quindi non posso diminuire di pi√π l‚Äôintervallo, vedi esempio in toggle\nImprecisione floating point, e non convergenza\nPer risolvere questo aggiungo eps dell‚Äôintervallo, in modo da rilassare la cosa, ed evitare che rimanga bloccato.\nEsempio blocco se non uso questo\na = 98.5, 98.6 =b e epsilon = 0.004, precisione macchina √® 0.01 / 2 (da 1/2 beta t - 1)\nQuindi si ferma se 0.004 + 0.01/2 * 98.6 = 0.004 + 0.986 / 2 quindi effettivamente si dovrebbe fermare. perch√© la differenza √® minore di 0.5 tipo.\nNote sulla implementazione (2) Si preferisce di calcolare il punto medio in questa forma\n$a + (b -a)/2$, invece che $(a + b)/ 2$ per limitare gli errori.\nEsempio di questo vantaggio\n0.983, 0.984, F(10, 3, -5, 5)\nLa somma √® 1.967, che normalizzato troncato √® 0.196 1e1,, diviso diventa 0.980, oppure 0.985 se arrotondo al pi√π vicino, in ogni caso √® errato. Mentre con l‚Äôaltro metodo ottenevo\n0.983 + (0.001 = 0.1 1e-2), 0.05 1e-2 = 0.5 1e-3 la somma √® 0.9835, che √® 0.983 quindi √® ancora dentro l‚Äôintervallo.\nOltre a questo introduco la funzione sign e non lo calcolo il prodotto ella funzione, quindi vado a considerare\n$sign(f(a)) sign(f(b)) \u003c0$\nAnalisi dei punti fissi Slide idea\nIdea dagli appunti pisani In pratica andiamo a dire che √® pi√π facile trovare punti fissi Invece di trovare uno zero per f, cerco di trovare uno zero per la funzione di g equivalente, tale che sia un punto fisso. Probabilmente perch√© √® pi√π facile trovare dei punti fissi ed √® per questo che vado a cercarlo. La funzione $\\Phi(x)$ di supporto √® maggiore di 0.\nBanach fixed-point theorem - Wikipedia\nQuello sopra √® il teorema principale utile a giustificare l‚Äôesistenza del punto fisso, e anche dell‚Äôunicit√†. Chiaramente non sappiamo cosa siano gli spazi metrici, e costa troppo in termini di tempo provare a capire il motivo.\nTi basti sapere che la funzione deve essere:\nContinua in [a, b] Una contrazione, ossia soddisfare questa relazione: $|g(a) - g(b)| \\leq L|a - b|$ Esistenza del punto fisso La funzione deve essere continua La funzione deve essere una contrazione nell‚Äôintervallo prestabilito. L‚Äôimmagine deve essere contenuta al dominio, altrimenti non posso utilizzare l‚Äôimmagine come input. Enunciato\nNota; questo teorema √® abbastanza importante (e anche tosto se si vuole far bene), lo puoi trovare in questa pagina di wiki\nNota: derivabilit√† e contrazione: Se il modulo della derivata √® minore di 1 allora √® una contrazione! (non il perch√© ti basta ricordare sta cosa lel). Un altra nota √® che se sono soddisfatte quelle due cose, si pu√≤ dimostrare che converge sempre! TODO: velocit√† di convergenza? Criteri di convergenza??\nL-Smoothness Questa nota √® anche molto simile al concetto di L-Smoothness. Una funzione $f$ √® definita L-smooth se $\\forall x, y$ e $L \\geq 0$ abbiamo che $$\\lVert \\nabla f(x) - \\nabla f(y) \\rVert \\leq L \\lvert x - y \\rvert$$ E questo ha qualcosa a che fare con il gradient flow che √® la formalizzazione continua di questo.\nUna conseguenza che potrebbe ritornare utile di questo √® che $$ \\forall x, y: f(y) \\leq f(x) + \\langle \\nabla f(x), y- x \\rangle + \\frac{L}{2} \\lvert x - y \\rvert ^{2} $$ E si potrebbe utilizzare una cosa simile per avere la garanzia di una discesa. Possiamo scendere tramite\n$$ f(x') \\leq f(x) - \\alpha\\left( 1 - \\frac{\\alpha}{2} L \\right) \\lVert \\nabla f(x) \\rVert ^{2} $$ Se scegliamo $\\alpha = \\frac{1}{L}$ allora la costante di discesa sar√† $\\frac{1}{2L}$\nConvergenza delle contrazioni Molto simile al teorema di esistenza e di unicit√†, questo invece stabilisce la convergenza, ed √® sufficiente che la funzione sia una contrazione per ogni punto in un intorno del punto fisso.\nSlide Cio√® √® fatta su una variazione su applicazione successive, e sul valore della funzione che deve essere abbastanza vicina allo 0.\nOppure si pu√≤ fare su errori relativi oppure frazione del massimo della funzione. Ad ogni modo √® a seconda di tolleranze prefissate.\nIn ogni modo con questo vogliamo cercare di\nVedere che la nostra funzione abbia raggiunto un valore vicino allo zero. Vedere quanto varia ancora la soluzione proposta, non vorremmo che variasse ancora tanto. Slide\nTi basti sapere che √® lineare, sul perch√© non lo so. Ma √® lineare lel.\nMetodo di Newton (delle tangenti) √à molto simile al metodo delle approssimazioni successive, ma in questo caso vogliamo utilizzare la derivata, come funzione ausiliaria. Vogliamo cercare di riassegnare la x a seconda di dove tenda a 0.\nDa notare che √® una convergenza quadratica quindi molto veloce! Solo che si spende il tempo per calcolare la funzione due volte per s√© stessa e la derivata\nalla fine si avr√† una successione nella forma\n$$ x_{n + 1} = x_n - \\dfrac{f(x_n)}{f'(x_n)} $$ Note velocit√† di convergenza Caso lineare (metodo approssimazioni classico)\nCaso convergenza quadratica\nPer il metodo di newton, la convergenza √® quadratica!\nCondizioni di convergenza locale (3) Significa che riesce a trovare il minimo locale per la funzione\nSlide Condizioni di convergenza globale Significa che riesce sempre a trovare il minimo globale della funzione, come vedremo ci sono un sacco di condizioni restringenti (poi con\nSlide Convergono anche tutte le variazioni possibili, sempre con a e b opposti (ma in modo diverso), e derivata seconda fatta in modo diverso\nSe la derivata seconda √® minore o ugualedi 0, parto da quello alto, altrimenti, da quello basso (non ho capito bene la 4 condizione boh).\nTODO: Capire enunciati di questo\n08/11/22 Enunciati pi√π o meno bene, dovrei semmai approfondire con dim o, Newton sembra essere particolarmente interessante‚Ä¶ 14/11/22 Boh, okey. 02/12/22 Boh okey x2 02/01/22 Dovrei farmi un po meglio le condizioni, ma pi√π o meno ci sono ancora ","permalink":"https://flecart.github.io/notes/equazioni-non-lineari/","summary":"Per trovare i zeri di una funzione continua non lineare non esistono alcuni metodi diretti che ci portano subito a una soluzione. Per questo motivo andremo ad analizzare molteplici pasis iterativi per trovare i zeri di una funzione.\nLa discussione di convergenza di ordine p √® stata gi√† discussa qui Note introduttive convergenza e iterazione , per quanto riguarda i metodi iterativi per risolvere sistemi di equazioni lineari\nGlobale e local Ricordiamo di Norme e Condizionamento, in cui il condizoinamento era pi√π o meno una stima di quanto cambia la soluzione quando cambia brevemente l\u0026rsquo;input.","title":"Equazioni non lineari"},{"content":"Vogliamo in questa sezione andare ad indagare la costruzione di funzioni che passano in tutti i punti che vogliamo, appunto interpolare. La funzione √® molto simile alla regressione trattata in Minimi quadrati (con il metodo della regressione, chiamato anche approssimazione ai minimi quadrati).\nQuindi mentre la precedente voleva andare a minimizzare l\u0026rsquo;errore, questo attuale va a creare proprio da 0 la funzione che ci passa sempre.\nIntroduzione Andremo a creare una funzione f tale che per ogni x in input si abbia esattamente la y in output\nMetodi di interpolazione (3)üü© In questo corso utilizzeremo solmanete l\u0026rsquo;interpolatore polinomiale!\nInterpolazione polinomiale Enunciato e unicit√†üü© Enunciato Da notare che il grado della funzione √® esattamente il numero delle y.\nDimostrazione dell‚Äôunicit√† Polinomi di Lagrange e costruzioneüü© Costruzione del polinomio di interpolazione In soldoni, mi sto costruendo molteplici funzioni che nel mio punto assumono il valore che voglio e in tutti gli altri punti sono nulli. Costruisco n funzioni per gli n input e li sommo assieme. Questa funzione qui mi basta per interpolare il tutto.\nImportante in questa sezione capire cosa √® la notazione.\n$\\varphi_k(x_i)$ √® il polinomio di lagrange che per xi, con i = k √® 1, altrimenti √® 0.\nIn particolare √® costruito in questo modo:\n$$ \\varphi_k(x) = \\prod^n_{j =0, j\\neq k} \\frac{x - x_j}{x_k - x_j}, \\forall k \\in \\{0, ..., n\\} $$ $\\Pi_n(x)$ √® la funzione di interpolazione costruita come\n$$ \\Pi_n(x) = \\sum_{i = 1}^n y_i \\varphi_i(x) $$ Teorema del resto d\u0026rsquo;interpolazioneüü• Slide della prof Note e osservazioni Faccio finta di prendere i punti da una funzione gi√† esistente e voglio in questo caso cercare di valutare quanto buona sia l‚Äôinterpolazione.\nla funzione pi√π a destra mi d√† una stima dell\u0026rsquo;errore della funzione di interpolazione.\nEsempio funzione di runge Questa funzione mostra come con l‚Äôaumentare del grado del polinomio, la precisione del polinomio di interpolazione non aumenta, anzi diminuisce! L‚Äôerrore cresce con pi√π punti.\nAd intuito la funzione d‚Äôinterpolazione oscilla, se ho un insieme di punti equidistanti non gli sto dando spazio per oscillare indietro.\nEsempio grafico runge Nodi di chebicheffüü• Questo √® un modo intelligente per prendere i nodi, in modo che si risolva il problema dell‚Äôequidistanza e dando al poliminio spazio (non so poi perch√© dargli spazio risolva ci√≤).\nCon n ‚Üí inf, l‚Äôerrore tende a zero! Quindi la convergenza dell‚Äôinterpolazione DIPENDE DAI PUNTI scelti. (questo chiaramente non va sui dati random che troviamo in ambiente, quindi √® molto inutile il metodo dell‚Äôinterpolazione per altra roba, inoltre staremmo seguendo il rumore dei dati).\nSlide nodi di chebicheff-Gauss-Lobatto\nInterpolazione a tratti üü© Dato che non ci conviene di interpolare troppi punti vogliamo spezzare l‚Äôinterpolazione a tratti! E inoltre per avere una regolarit√† impongo uguaglianza delle derivate 1 e 2 evitando spigoli nelel funzioni finali.\nMa questo √® quanto ci vuole insegnare a riguardo la prof. quindi mi fermo in questo punto per questi appunti.\n","permalink":"https://flecart.github.io/notes/interpolazione/","summary":"Vogliamo in questa sezione andare ad indagare la costruzione di funzioni che passano in tutti i punti che vogliamo, appunto interpolare. La funzione √® molto simile alla regressione trattata in Minimi quadrati (con il metodo della regressione, chiamato anche approssimazione ai minimi quadrati).\nQuindi mentre la precedente voleva andare a minimizzare l\u0026rsquo;errore, questo attuale va a creare proprio da 0 la funzione che ci passa sempre.\nIntroduzione Andremo a creare una funzione f tale che per ogni x in input si abbia esattamente la y in output","title":"Interpolazione"},{"content":"Con questo documento iniziamo a parlare di logica, alcuni paradossi famosi all\u0026rsquo;interno di questo mondo.\nParadossi Metalinguistici Antinomie e Paradossi Antinomia Definizione di antinomia √® un ragionamento corretto da cui deriva una conclusione errata, probabilmente √® l\u0026rsquo;insieme o campo in cui stiamo operando ad essere errato e bisogna cercare di ridefinirlo in modo pi√π corretto, in quanto le premesse erano accettabili\nParadosso Paradosso quando il ragionamento corretto va contro l\u0026rsquo;intuizione, come il paradosso dei gemelli in fisica e simili. premesse erano accettabili\nFalsi paradossi: in cui c\u0026rsquo;√® un errore del ragionamento da cui viene dedotto un ragionamento errato.\nLinguaggio naturale Per linguaggio naturale andiamo ad indicare linguaggi che esseri umani hanno inventato e usano in alcune civilt√†.\nCaratteristiche del Linguaggio naturale Il linguaggio naturale √® il linguaggio comunemente utilizzato come italiano, inglese arabo e cinese etc. utilizzato nella maggior parte della vita quotidiana.\nQuesto linguaggio non √® utile per i ragionamenti rigorosi come descrizione del calcolo o dimostrazioni in quanto questo linguaggio √®:\nFortemente dipendente dal contesto Ambigua grammatica: e.g. Il poliziotto ha ucciso il ladro con la pistola (pistola mezzo oppure compagnia?) Paradossi in NL Paradossi visti in classe:\nIo mento eterologico √® eterologico. Le cause individuate per i paradossi sono\nUtilizzo meta-linguistico, ce si riferisce sul linguaggio stesso (Io mento).\nLinguaggio naturale potrebbe essere cos√¨ ampio che pu√≤ parlare di s√© stesso, per esempio: contare numero di sillabe o parole, o mischiare il senso del linguaggio o simile, questo genera paradossi. Sarebbe difficile esprimere idee senza la negazione in poche parole. Per scoprire l\u0026rsquo;utilizzo meta linguistico si utilizza un teorema di invarianza delle denotazioni\nAuto applicazione di meta-linguistico a se stesso (eterologico √® eterologico).\nCerco di usare qualcosa su s√© stesso, anche se la definizione dell\u0026rsquo;aggettivo non dovrebbe essere utilizzate in questo modo, possiamo dire che perde di senso L\u0026rsquo;utilizzo della negazione (x minore non definibile in meno di 1000 parole).\nL\u0026rsquo;utilizzo della negazione su s√© stesso e anche la negazione di s√© stesso crea antinomia (paradosso NL) Ricerca di un linguaggio formale La negazione √® necessaria per fare i ragionamenti, non si pu√≤ togliere.\nNon si riesce a evitare di applicare una definizione su s√© stessa, dopo che hai oggetto e soggetto puoi scegliere dove applicarlo, cio√® √® brutto evitare solamente l\u0026rsquo;applicazione a s√© stesso, una volta creata la preposizione pu√≤ essere usata senza questi piccoli vincoli.\nI\u0026rsquo;uso metalinguistico invece si pu√≤ evitare, e quindi bisogna abbandonare il linguaggio naturale e approdare in un linguaggio artificiale, il linguaggio rigoroso della matematica.\nLinguaggio Matematico Storia dell\u0026rsquo;insiemistica Quando ancora la matematica non era ancora scienza diversa dalla informatica, i matematici si mettevano proprio a calcolare modi di calcolo,\nVennero studiate le basi e introdotte la teoria degli insiemi, da Cantor, una base per tutta la matematica attuale, ma questo viene messo in crisi dal paradosso di Russel, creando due filosofie matematiche, gli insiemisti e altri contrari.\nParadosso di Russel: $X = \\{ Y \\,|\\, Y \\not\\in Y \\, \\}$ e si ha ancora un paradosso auto-refere\nDopo tutta questa diatriba, venne creato circa nel 1930 il significato di calcolare, credo e venne creato il campo dell\u0026rsquo;informatica.\nParadosso di Russel $$ R = \\left\\{ x \\mid x \\not\\in x \\right\\} $$ Analisi del paradosso Possiamo vedere che la teoria degli insiemi √® possibile creare paradossi:\nPresente l\u0026rsquo;uso della negazione La negazione, la caratteristica usata √® fatta in modo autoreferenziale Gli insiemi possono contenere s√© stessi, e quindi √® possibile l\u0026rsquo;use meta-linguistico. Quindi non pu√≤ esistere un insieme che li contenga tutti come voleva sostenere Cantor.\nVale che $$ R \\in R \\iff R \\not \\in R $$ Cerchiamo di capire perch√©:\n$\\implies$ allora se supponiamo che $R$ √® in $R$ per struttura di $R$ vale che $R \\not \\in R$ che √® una contraddizione, assurdo. $\\Longleftarrow$ allora vale che $R \\not \\in R$ √® falso, quindi deve valere che $R \\in R$ quindi abbiamo anche in questo caso una contraddizione. Da questo concludiamo che non ha senso poter definire quell\u0026rsquo;insieme, e c\u0026rsquo;√® qualcosa che non va nell\u0026rsquo;utilizzo di quel linguaggio. Risultato dell\u0026rsquo;analisi Su questa soluzione basa l\u0026rsquo;intera matematica e non si sa se ci sono altri paradossi dentro questo. Potrebbe essere errata anche questa.\nLimitazioni sulla creazione di insiemi che abbiano propriet√† comunque ‚Üí Assioma di comprensione deve essere gettata. Assioma di separazione ovvero gli elementi devono essere presi da un insieme esistente e una propriet√† di questo insieme (quindi posso solamente restringere un insieme). √à definita come separata la collezione di tutti gli insiemi, per evitare il paradosso di auto-referenzialit√†, prevenire l\u0026rsquo;uso meta-linguistico. Paradossi Informatici Esistenza di paradossi La composizione di funzioni, cio√® l\u0026rsquo;utilizzo in modo meta-linguistico delle informazioni informatiche √® necessaria Sia in linguaggi funzionali, imperativi, basta saltare, quindi si pu√≤ modificare un programma ~~ Insieme che contiene insieme, molto simile questa cosa. La negazione delle affermazioni √® necessaria Una funzione applicata su s√© stessa √® presente, possibilissima l\u0026rsquo;autoreferenzialit√† Per questo motivo non si pu√≤ evitare il paradosso nell\u0026rsquo;ambito dell\u0026rsquo;informatica.\nParadosso sulle funzioni non totali Riguardare se sei in grado di definire il significato di Espressivit√† di un linguaggio Convergenza e divergenza di una funzione totalit√† di una funzione Totalit√† significa che una funzione riesca a restituire un output in tempo finito.\n$f(g) = not\\,(g(g))$ √® una funzione che pu√≤ creare un paradosso, se analizzata si possono trovare tutti i tre ingredienti per la creazione di paradosso:\nC\u0026rsquo;√® la negazione, c\u0026rsquo;√® l\u0026rsquo;uso meta-linguistico (composizione di funzione) e se al posto di $g$ ci metto $f$ c\u0026rsquo;√® anche l\u0026rsquo;auto-referenzialit√†, creando un paradosso.\nüí° Le funzioni matematiche danno sempre risultato, invece le funzioni informatiche possono divergere.\nParadosso sulla divergenza Questo √® il problema della fermata discusso in Halting Theorem and Reducibility#Halting theorem Nelle funzioni informatiche c\u0026rsquo;√® una fase di calcolo ed elaborazione delle informazioni. Nelle funzioni matematiche sono solamente una relazione fra insiemi (ossia calcolano un unico input). Una funzione tale che $f(g,x) = true \\, iff \\, g(x) \\downarrow$ Definisco una funzione: $h(g) = \\uparrow if \\,f(g,g) \\, else \\downarrow$\nQuesto porta alla conclusione che non esiste un programma che decida se un altro diverga.$f(g) = \\uparrow if \\,f(g,g) \\, else \\downarrow$\nParadosso sull\u0026rsquo;espressivit√† di funzioni matematiche Spiegata per filo e per segno per la diagonalizzazione di cantor Relazioni fra insiemi#Diagonalizzazione di Cantor\n!\n","permalink":"https://flecart.github.io/notes/logica-meta-linguistica/","summary":"Con questo documento iniziamo a parlare di logica, alcuni paradossi famosi all\u0026rsquo;interno di questo mondo.\nParadossi Metalinguistici Antinomie e Paradossi Antinomia Definizione di antinomia √® un ragionamento corretto da cui deriva una conclusione errata, probabilmente √® l\u0026rsquo;insieme o campo in cui stiamo operando ad essere errato e bisogna cercare di ridefinirlo in modo pi√π corretto, in quanto le premesse erano accettabili\nParadosso Paradosso quando il ragionamento corretto va contro l\u0026rsquo;intuizione, come il paradosso dei gemelli in fisica e simili.","title":"Logica meta-linguistica"},{"content":"Introduzione alla logistic regression Giustificazione del metodo Questo √® uno dei modelli classici, creati da Minsky qualche decennio fa In questo caso andiamo direttamente a computare il valore di $P(Y|X)$ durante l\u0026rsquo;inferenza, quindi si parla di modello discriminativo.\nIntroduzione al problema Supponiamo che\n$Y$ siano variabili booleane $X_{i}$ siano variabili continue $X_{i}$ siano indipendenti uno dall\u0026rsquo;altro. $P(X_{i}| Y= k)$ sono modellate tramite distribuzioni gaussiane $\\mathbb{N}(\\mu_{ik}, \\sigma_{i})$ NOTA! la varianza non dipende dalle feature!, questo mi permetterebbe di poi togliere la cosa quadratico dopo, rendendo poi l\u0026rsquo;approssimazione lineare Per esempio se utilizziamo nelle immagini, avrebbe senso normalizzare pixel by pixel, e non image wide con un unico valore, √® una assunzione, che se funziona dovrebbe poi far andare meglio la regressione logistica! $Y$ √® una distribuzione bernoulliana. Ci chiediamo come √® fatto $P(Y|X)$?\nCaratterizzazione di P(Y|X) üü®+ Proviamo a calcolare analiticamente come √® fatto $P(Y|X)$ usando le assunzioni di sopra\nTheorem Assunte le cose di sopra si avr√† che $$ P(Y=1| X= \\left\u003c x_{1},\\dots, x_{n} \\right\u003e ) = \\frac{1}{1 + \\exp\\left( w_{0} + \\sum_{i} w_{i}x_{i} \\right)} $$ Nella derivazione di sopra si ha che $\\pi = P(Y=1)$ E poi sappiamo che\n$$ \\ln \\frac{P(X_{i} | Y=0)}{P(X_{i} | Y=1)} = \\ln \\frac{e^{-\\frac{(X_{i} - \\mu_{i0})^{2}}{2 \\sigma_{0}^{2}}}}{ e^{-\\frac{(X_{i} - \\mu_{i_{1}})^{2}}{2 \\sigma_{1}^{2}}}} = -\\frac{(X_{i} - \\mu_{i0})^{2}}{2 \\sigma_{i}^{2}} + \\frac{(X_{i} - \\mu_{i1})^{2}}{2 \\sigma_{i}^{2}} $$ E si pu√≤ notare che poi abbiamo il risultato di sopra e diventa sensato avere la forma di Sigmoid, che esce in modo molto molto naturale\nDalla parte in blu capiamo che √® una cosa lineare, perch√© se √® maggiore di zero allora √® meglio la probabilit√† di stare da una parte rispetto all\u0026rsquo;altra.\nFunzione di Sigmoid üü© Questo ci d√† una motivazione del motivo per cui utilizziamo $$ \\text{ Funzione di sigmoid: }\\sigma(x) = \\frac{1}{1 + e^{-x}} $$ Questa funzione si pu√≤ vedere come un caso particolare di [Softmax Function](/notes/softmax-function). Derivata Si pu√≤ calcolare che ha una derivata molto molto carina, ma √® anche il problema per cui esiste vanishing gradient. $$ \\sigma'(x) = \\sigma(x) (1 - \\sigma(x)) $$ Quindi diventa vero che $$ P(Y=1|x,w) = \\sigma\\left( w_{0} + \\sum_{i} w_{i}x_{i} \\right) $$ Possiamo scrivere la probabilit√† di ogni singolo campione come in figura sotto\nFunzione di loss üü© Che sembra una cross-entropy classica, che per√≤ non ha una soluzione analitica, per questo motivo si utilizza **discesa del gradiente**. Ottimizzazione discesa del gradiente Intuizione sul gradiente üü© abbiamo alla fine che il gradiente √®\n$$ \\frac{\\delta \\mathcal{L}(w)}{\\delta w_{i}} = \\sum_{l} x^{l}_{i} \\cdot (y^{l} - \\alpha^{l}) $$ Perch√© gi√† $(y - \\alpha)$ sta misurando in un certo senso la differenza (l\u0026rsquo;errore), e il prodotto lo sta legando all\u0026rsquo;input preciso, quindi √® molto bello quando la formula √® interpretabile in modo fisico quasi.\nSometimes is clearer to write $\\alpha$ in an explicit fashion: $$ \\nabla_{w} \\ell(w)(x, y) = [\\sigma(w \\cdot x) - y]x $$ Calcolo del gradiente cross entropy üü®++ $$ a^{l} = \\sigma\\left( w_{0} + \\sum_{i} x_{i}w_{i} \\right) = \\sigma(z) $$ $$ \\sum_{l} \\log P(Y= y^{l} | x ^{l}, w) = \\sum_{l} y^{l}\\log(\\alpha^{l}) + (1- y^{l})(1 - \\log(\\alpha^{l})) $$ Dalla formula di sopra riscritta in altro modo.\nQuesto √® esattamente poi quanto sar√† fatto durante il percettrone, per l'aggiornamento delle variabili in quelle istanze. Fase update del gradiente üü© Una volta calcolato che il valore di update √® analiticamente uguale a $$ \\frac{\\delta \\mathcal{L}(w)}{\\delta w_{i}} = \\sum_{l} (y^{l} - \\alpha^{l}) x^{l} $$ Possiamo usare questa per aggiornare il peso di $w_{i}$\nUpdate step: $$ w_{i} = w_{i} + \\mu \\frac{\\delta \\mathcal{L}(w)}{\\delta w_{i}} $$ A volte viene aggiunto un fattore di regolarizzazione che fa diventare la regola di update come $$ w_{i} = w_{i} + \\mu \\frac{\\delta \\mathcal{L}(w)}{\\delta w_{i}} + \\mu \\lambda|w_{i}| $$ Che implica il fatto che se abbiamo un singolo peso grande, far√† molta fatica ad esserci nel regolarizzatore (quindi ho meno varianza fra i pesi diciamo).\n","permalink":"https://flecart.github.io/notes/logistic-regression/","summary":"Introduzione alla logistic regression Giustificazione del metodo Questo √® uno dei modelli classici, creati da Minsky qualche decennio fa In questo caso andiamo direttamente a computare il valore di $P(Y|X)$ durante l\u0026rsquo;inferenza, quindi si parla di modello discriminativo.\nIntroduzione al problema Supponiamo che\n$Y$ siano variabili booleane $X_{i}$ siano variabili continue $X_{i}$ siano indipendenti uno dall\u0026rsquo;altro. $P(X_{i}| Y= k)$ sono modellate tramite distribuzioni gaussiane $\\mathbb{N}(\\mu_{ik}, \\sigma_{i})$ NOTA! la varianza non dipende dalle feature!","title":"Logistic Regression"},{"content":"There is a close relationship between topologies and metric spaces. We will see that every metric space directly induces a topology based on its metric. (from a CS point of view, this means topologies are more general than metric spaces).\nDefinition of Metric Space üü© We say that $(\\mathcal{X}, d)$ is a metric space if $\\mathcal{X}$ is a set and $d$ a function $\\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{R}$ such that:\nDistance from it self is zero $d(a, b) = 0 \\iff a = b$ Symmetric function: $d(a, b) = d(b, a), \\forall a, b \\in \\mathcal{X}$ Triangle inequality is satisfied: $\\forall a, b, c \\in \\mathcal{X}: d(a, b) + d(b, c) \\geq d(a, c)$ Induced topology üü© If we define the sets $B(c, r) = \\left\\{ p \\in \\mathcal{X} \\mid d(p, c) \u003c r \\right\\}$ to be open, this induces a topology $(\\mathcal{X}, \\mathbb{B})$ where $\\mathbb{B} := \\left\\{ B(c, r) \\mid c \\in \\mathcal{X}, r \\in\\mathbb{R} \\right\\}$. This should be easy to verify, but it is mostly uninteresting and quite intuitive (i\u0026rsquo;m not reasoning like a mathematician now).\nConnectedness of $\\left[ 0, 1 \\right]$ üü® We define the subspace topology of $\\mathbb{R}$ on it\u0026rsquo;s subset $\\left[ 0, 1 \\right]$ we can prove that this is connected. This is uses the intermediate value theorem see Limiti#Weierstrass e Valore intermedio, the concept is very similar.\nLet\u0026rsquo;s assume the space is disconnected, so there exists two non empty disjoint sets $A, B$ such that $A \\cup B = \\left[ 0 , 1 \\right]$. We want to build a function that says this gives a contradiction. Let\u0026rsquo;s take two points, $a \\in A$ and $b \\in B$. And let\u0026rsquo;s build a function in the following way: $$ f(x) = \\begin{cases} 0 \\text{ if } x \\in A \\\\ 1 \\text{ if } x \\in B \\\\ \\end{cases} $$ We observe that this function is defined for every point in the domain, so it is well defined, and it\u0026rsquo;s continuous because we have that every set of the domain has a pre-image either $A, B, A \\cup B, \\varnothing$, that are all continuous. But if we have these assumptions we have that for all inputs either $A = \\varnothing$ or $B = \\varnothing$ because if it has some values $0$ or $1$ then by the intermediate value theorem it should take all the values. This contradicts the hypothesis the set is disconnected.\n","permalink":"https://flecart.github.io/notes/metric-spaces/","summary":"There is a close relationship between topologies and metric spaces. We will see that every metric space directly induces a topology based on its metric. (from a CS point of view, this means topologies are more general than metric spaces).\nDefinition of Metric Space üü© We say that $(\\mathcal{X}, d)$ is a metric space if $\\mathcal{X}$ is a set and $d$ a function $\\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{R}$ such that:","title":"Metric Spaces"},{"content":"In questa nota andiamo a trattare argomenti come tabelle di verit√†. Mappe di Karnaugh. E piccolissima introduzione ai circuiti integrati.\nBoole Un signor Boole ha creato le basi dell\u0026rsquo;algebra booleana su cui si basano le porte logiche dei computer moderni.\nTabelle di verit√† Le tabelle di verit√† sono sufficienti per descrivere il funzionamento di una porta logica.\nQuesta cosa √® possibile grazie alla limitatezza delle funzioni all\u0026rsquo;interno dell\u0026rsquo;insieme $\\{0,1\\}$ dominio di partenza e fine dell\u0026rsquo;algebra booleana.\nPropriet√† nell\u0026rsquo;algebra di Boole Prova a spiegare da solo queste leggi:\nPropriet√†: 9\nIdentit√† Null Idempotenza Inverso Commutativo Associativo Distributivo Assorbimento De morgan La tabella con le leggi\nEsercizio in classe:\n$\\bar{A} + A \\not= \\bar{A}A$ Dimostrare sta cosa usando le leggi di de Morgan ( e non dicendo che √® la legge dell\u0026rsquo;inverso), in pratica dire che $\\bar{A} + A = \\overline{\\bar{A}A}$. dsafds\nFunzione booleana Si possono utilizzare delle funzioni booleane per mappare gli zeri e uno a certi\nEsercizio in classe\nScrivere la tabella di verit√† per\n$$ A + \\overline{(B + C)}B $$ La soluzione √® che vale solo per $A$, il secondo addendo √® tutto\nMintermini\n√à una variabile o la negazione di una variabile Su $n$ termini √® l\u0026rsquo;AND fra tutti il min termine, attraverso relazioni di mintermini si pu√≤ creare una funzione booleana. √à l\u0026rsquo;unica combinazione booleana in cui in una riga sola √® uno mentre in ogni altra riga √® falsa Una forma canonica √à una somma di alcuni mintermini, e questa √® unica per ogni funzione **booleana.\nLa forma canonica o funzione canonica di una espressione booleana √® un\u0026rsquo;espressione logica contenente tutte le variabili booleane in forma vera o negata, in forma di prodotti fondamentali o somme fondamentali di essi. Essa si ricava dalla tabella della verit√†.\nCircuiti combinatori: Sono l\u0026rsquo;implementazione della funzione booleana, e sono deterministici.\nTransistor e Array Struttura di un transistor Un transistor √® composto da tre parti principali:\nUn collettore che riceve una corrente esterna stabile Una base che riceve una corrente esterna e cambia la struttura del transistor a seconda che ci sia o no Un emettitore che lascia passare se c\u0026rsquo;√® corrente, altrimenti si comporta come resistenza infinita. Nand, Not e Nor Array programmabili Un insieme di And e Or che rappresentano la forma canonica per un elemento. Si possono programmare fondendo o lasciando alcuni fusibili per simulare l\u0026rsquo;uso del not, come in figura.\nMappa di Karnaugh Introduzione √à un metodo che prende la forma canonica e cerca di semplificarla con qualcosa di molto pi√π facile da implementare (prende una forma canonica e restituisce elementi semplificati) Non fa peggio della forma canonica ergo una forma semplificata o uguale che dia stessi output.\nSi pu√≤ fare anche a 3D o 4D per permettere l\u0026rsquo;uso per pi√π input ma non sempre √® facile immaginarsi 4 dimensioni, queste devono soddisfare il codice grey.\nCodice gray La mappa di Karnaugh deve essere un codice Gray\nCostruisco con la tecnica a specchio cio√® da una riga all\u0026rsquo;altro sto cambiando solamente una singola cifra.\nUtilizzando invece la numerazione delle tabelle di verit√† non funziona in quanto non possiede questa propriet√†.\nDalla pagina di wikipedia\nEsempi di applicazione Disegno\nSi possono scrivere in due modi, a seconda di come piace\nRaggruppamento\nbisogna creare grossi raggruppamenti ossia catturare pi√π uni possibile con pochi, fatto questo sono sicuro di creare una forma minimale.\nDopo questo scegli il raggruppamento pi√π piccolo e sarai abbastanza sicuro che sia minimale\nCircuiti integrati Di solito sono pezzi di silicone che variano di grandezza e struttura a seconda degli input e dei output per quello che si deve fare (questi sono anche chiamati Chip)\nLGA PGA Large Grid Array, Pin grid Array.\nCi sono due tipologie di Pin per i circuiti integrati\n! sti sono anche chiamati Chip)\n","permalink":"https://flecart.github.io/notes/porte-logiche/","summary":"In questa nota andiamo a trattare argomenti come tabelle di verit√†. Mappe di Karnaugh. E piccolissima introduzione ai circuiti integrati.\nBoole Un signor Boole ha creato le basi dell\u0026rsquo;algebra booleana su cui si basano le porte logiche dei computer moderni.\nTabelle di verit√† Le tabelle di verit√† sono sufficienti per descrivere il funzionamento di una porta logica.\nQuesta cosa √® possibile grazie alla limitatezza delle funzioni all\u0026rsquo;interno dell\u0026rsquo;insieme $\\{0,1\\}$ dominio di partenza e fine dell\u0026rsquo;algebra booleana.","title":"Porte Logiche"},{"content":"Questi problemi sono una sottoclasse della programmazione lineare con variabili reali. (Alcuni riescono a riconoscere se un problema √® in questa forma, e lo risolvono in modo istantaneo se questo succede).\nUn problema dei router √® un classico problema di flusso, che si risolvono con questi algoritmi polinomiali\nNote introduttive Rete, terminologia In questo caso andiamo ad indicare con rete un grafo con $G = (N, A)$ con $N$ nodi e $A$ archi, che solitamente sono diretti con pesi associati. Possiamo interpretare gli archi come canali in cui fluiranno un qualcosa (ad esempio acqua in un tubo). Questi possono essere discreti o continui (mi sembra di ricordare che il discreto stranamente √® pi√π facile del continuo, non so se vale anche in questo caso). Abbiamo poi i nodi che sono punti di ingresso e uscita della nostra rete.\nAbbiamo studiato questo nel corso di algoritmi, nella lezione sui Grafi.\nSbilanciamento Sbilanciamento, mi da informazione riguardo se il nodo vuole ricevere o dare fuori, quindi il fatto che sia negativo positivo pu√≤ essere buona roba.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Reti di flusso/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Reti di flusso/Untitled 1\u0026quot;\u0026gt; Nodi di input output e trasferimento Importante sapere cosa sono nodo di input, output e trasferimento e quando un nodo si pu√≤ chiare in questo modo.\nCapacit√† inferiore e superiore Oltre a ci√≤ possiamo definire capacit√† inferiore e superiore degli archi, e definire unconcetto di ammissibilit√† di un trasferimento di un arco quando la quantit√† che ci passa rispetta queste condizioni.\nVincoli di un problema di flusso (3) üü®+ Domanda e offerta globale Conservazione del flusso sol nodo locale Amissiblit√† del flusso Slide\nIl perch√© si utilizzano grafi √® perch√© sono espressivi per questo genere di problemi, ossia sono molto utili per modellizzare questo. E hanno una complessit√† gestibile perch√© sono stati molto studiati ed esistono algoritmi efficienti per questa(credo)\nNormalizzazione della capacit√† inferiore (3) üü©- Si tratta in questa parte di trasformare il problema in un altro problema con le capacit√† inferiori nulle, basta considerare questa cosa nel calcolo della funzione obiettivo e rimodulare i valori degli archi (per capacit√† superiore).\nLe 3 cose per normalizzare\nTogliere l a capacit√† superiore Aggiungere l a b (cos√¨ flusso si conserva Considerare il costo di questo flusso Cio√® semplifico mettendo quanto deve passare per la capacit√† inferiore come flusso proveniente dall\u0026rsquo;esterno!\nSlide\nModelizzazione del flusso di costo minimo (!!!) (3) üü®- Slide\nCome si pu√≤ notare la condizione √® molto facile da scrivere.\nMinimizzare il costo $cx$, con x il vettore dei flussi, c il vettore dei costi Condizione di massimo flusso $\\forall i, 0\\leq x_i \\leq u_i$, con u il vettore dei massimi E tutte le condizioni di bilanciamento $Ex = b$ con E la matrice (probabilmente sparsa) che mi calcola l‚Äôincidenza (0, 1, -1 per dire esiste, entrata o uscita), che devono essere uguali a b. Condizione dei pozzi üü©\nSpesso √® molto buono idealizzare con un solo pozzo di entrata e un solo pozzo di uscita. Al fine di avere questo risultato si creano due pozzi aggiuntivi , uno che prende tutte le entrate e una che prende tutte le uscite\nSlide costruzione dei pozzi e sorgenti\nCondizione limiti di nodoüü®‚Äî\nPer modellizzare cose come i router, che sono s√¨ dei nodi, ma hanno dei limiti per trasmettere e ricevere creiamo un nodo fittizio che sia in grado di rappresentare questo genere di occazioni\nslide\nProblema del flusso massimo Caratteristiche flusso max (3) üü© Slide definizione del problema\nDa notare che questo problema pu√≤ essere visto come caso particolare di MCF in cui\nCosti sono nulli Sbilanciamenti sono nulli Presenza di arco fittizio con capacit√† infinita da target a source Tagli Definizione üü© Slide\nIn pratica √® una partizione dei nodi di una rete.\nUn s-t taglio√® un taglio in cui s e t stanno in partizioni differenti (dato che sono due le partizioni direi che stanno nelle due partizioni corrispondenti).\nAndiamo ora a caratterizzare gli archi.\nA+ attraversa da s a t\nA- attraversa da t a s.\nEsempio di Taglio\nI rossi sono A+, i verdi sono A-\nEsempio del prof pi√π contorto\nPropriet√† !! (2) üü© Enunciato:\n$$ \\forall (s-t)\\text{-taglio} \\, (N_{s}, N_{t}) \\text{ e ogni flusso ammissibile } x \\text{ con valore } v: $$ Abbiamo che: $$ \\begin{cases} v = \\sum_{(i, j) \\in A^{+}(N_{s}, N_{t})} x_{ij} - \\sum_{(i, j) \\in A^{-} (N_{s}, N_{t})} x_{ij} \\\\ v \\leq \\sum_{(i, j) \\in A^{+}(N_{s}, N_{t})} u_{ij} \\end{cases} $$ Ossia il flusso √® uguale a ci√≤ che attraversa il taglio, e tutto questo √® sempre minore alla capacit√† del taglio!\nDimostrazione\nPer 1 in pratica prende la differenza iniziale e riscrive i nodi di trasferimento (quindi input - output = 0) in altro modo per averlo nella forma che ci piace). Gli archi interni si cancellano fra di loro, gli archi esterni in Nt non vengono proprio contati, quindi possiamo andare a considerare solamente gli archi della frontiera quindi andiamo a finire in questo modo.\nDimo Slides\nFlusso e capacit√† del taglio üü© Le propriet√† dei tagli spiegati in precedenza sono dei punti fondamentali per l‚Äôanalisi di questo problema di flusso!.\nIl valore di un flusso ammissibile √® sempre minore o uguale della capacit√† di qualunque taglio.\nAndremo a cercare un caso in cui il flusso = capacit√†. In quanto trovato questo taglio, questo √® un flusso massimo! Per il lemma precedente non pu√≤ crescere ancora.\nFord Fulkerson Andremo in questa parte ad introdurre alcuni concetti molto utili che ci porteranno alla definizione dell‚Äôalgoritmo di Ford Fulkelson.\nGrafi residui üü© Utile per dirmi se possono ancora migliorare o meno in un arco.\nQuindi ci d√† un concetto di flusso rimanente per un arco (termine mio questo) utilizzato per decidere se possiamo utilizzarlo o meno per migliorare qualcosa.\nSlide\nCammini aumentanti üü© Chiachiamo in questo modo i cammini nel grafo dei residui. Lo chiamiamo in questo modo perch√© ci permette di avere pi√π flusso da s a t. In particolare lo utilizzo in questo modo\nSe √® un arco discorde diminuisco il valore del flusso. Se √® un arco concorde aumento il flusso. Il valore di aumento o diminuzione √® il minimo del residuo fra tutti gli archi, questa cosa la chiamiamo capacit√† del cammino aumentante.\nSlide\nL‚Äôalgoritmo üü© L‚Äôalgoritmo si traduce nel\nSetta flusso iniziale a 0 Prendi un cammino aumentante a caso, se esiste aggiungi al flusso il valore di cui √® aumentato, altrimenti ritorna il flusso. Continua finch√© non esci. Slide\nCorrettezza üü® Per dimostrare la correttezza √® spesso molto bello trovare l‚Äôinvariante, in questo caso √® il seguente lemma\nSe x √® un flusso ammissibile, allora √® ammissibile anche il flusso modificato con una iterazione dell‚Äôalgoritmo. Se ho il flusso massimo, allora non posso trovare cammini aumentanti o flussi altri.\nSlide lemmi su flusso massimo e ammissibilit√†, con cammini aumentanti\nLemma fondamentale per correttezza, esistenza di taglio v\nNOTA: raggiungibili con un cammino aumentante!\nIntera dimostrazione insieme\nComplessit√† üü®+ Possiamo dire che ha fine solo se ha capacit√† intere, altrimenti potrebbe essere che non termini mai. Il prof dice che questo algo d√† troppa libert√† per cui la complessit√† non √® sotto controllo.\nTeorema e dimostrazione complessit√† casi interi\nMa questa √® una complessit√† pseudopolinomiale nel senso che √® polinomiale solo se non si utilizza la compressione logaritmica nella rappresentazione degli interi (quindi polinomiale nel tempo, ma non nella rappresentazione in memoria).\nMa comunque il termine U ci √® abbastanza brutto.\nMax Flow Min Cut (!) üü© Se riusciamo a dimostrare che il massimo flusso √® ‚â• di un taglio allora mettendo insieme al lemma sul upper bound del massimo flusso ho finito.\nUtilizziamo il risultato nella dimostrazione di FF, assumento che abbiamo un flusso massimo, quindi non ci sono cammini aumentanti, allora abbiamo un taglio di capacit√† v, per cui ho finito.\nEnunciato e dimo\nEdmonds Karp Introduzione üü© Questo algoritmo non √® altro che una implementazione di Ford_fulkerson. Quindi sappiamo gi√† che sia corretta. Utilizza una bfs per trovare il cammino aumentante migliore.\nUtilizzando la bfs, quindi scegliemo sempre il percorso pi√π corto questa √® una delle propriet√† di maggior rilievo per EK.\nLemma distanze di EK (non chiede dim) üü®‚Äî Questo √® un lemma che caratterizza fortemente EK, perch√© √® una conseguenza della sua ricerca in BFS che trova gli archi critici pi√π corti prima di quelli pi√π lunghi.\n√à anche fondamentale per fare il calcolo della complessit√† dell\u0026rsquo;algoritmo!\nEnunciato\nDimostrazione (non fatta in classe) preso dal cormen\nComplessit√† (!!) üü®+ Il lemma di sopra ci permette di togliere il termine sulla capacit√† degli archi.\nEnunciato\nIl motivo √® che per il lemma precedente ogni arco pu√≤ essere considerato al pi√π |N| volte, con N il numero dei nodi. Quindi Applico BFS, per ogni arco, al pi√π N volte, costo $O(NM^2)$\nHint dimostrazione\nAndiamo a considerare gli archi che vengono saturati durante il percorso di un cammino aumentante (questo esiste sempre perch√© il cammino aumentante √® costruito sul minimo del percorso.\nVogliamo dire che ogni arco pu√≤ essere al massimo considerato critico N volte, per cui al massimo ho NA.\nDopo aver fatto questa osservazione, bisogna andare a fare un ragionamento sulla distanza, che continua a crescere per ogni iterazione, e lo pu√≤ fare per al massimo il numero di nodi, prima di diventare staccato.\nDimostrazione\nGoldberg-Tarjan Slide algoritmo\n!\n","permalink":"https://flecart.github.io/notes/reti-di-flusso/","summary":"Questi problemi sono una sottoclasse della programmazione lineare con variabili reali. (Alcuni riescono a riconoscere se un problema √® in questa forma, e lo risolvono in modo istantaneo se questo succede).\nUn problema dei router √® un classico problema di flusso, che si risolvono con questi algoritmi polinomiali\nNote introduttive Rete, terminologia In questo caso andiamo ad indicare con rete un grafo con $G = (N, A)$ con $N$ nodi e $A$ archi, che solitamente sono diretti con pesi associati.","title":"Reti di flusso"},{"content":"This is the generalization of the family of function where Softmax Function belongs. Many many functions are part of this family, most of the distributions that are used in science are part of the exponential family, e.g. beta, Gaussian, Bernoulli, Categorical distribution, Gamma, Beta, Poisson, are all part of the exponential family. The useful thing is the generalization power of this set of functions: if you prove something about this family, you prove it for every distribution that is part of this family. This family of functions is also closely linked too Generalized Linear Models (GLMs).\nWe have a family of distributions $x \\in X$ parameterised by a $\\vec{\\theta}$ $$ p(x \\mid \\vec{\\theta}) = \\frac{1}{Z(\\vec{\\theta}) } \\vec{h}(x) \\exp(\\vec{\\theta} \\cdot \\phi (x)) $$ Where $h$ defines the support, $\\theta$ are the canonical parameters and $\\phi$ is the sufficient statistics. $Z$ is called the partition function. $h$ is called the support. If a function can be written in this form then we have a member of this family. Note that if we set $h$, $\\phi$ and $Z$ and let the parameter $\\theta$ vary this is a single family (or set). And one can prove this.\nInteresting properties Finite sufficient statistics (we can compress into a finite vector without loss of information) but I did not understand this very well) Conjugate priors (I didn\u0026rsquo;t understood this very well). We say that a prior distribution (i.e. $p(\\theta)$) is conjugate to some likelihood function ($p(x\\mid \\theta)$) if the posterior distribution $p(\\theta \\mid x)$ (which results from this likelihood function and prior distribution) is the same distribution as the prior distribution (with updated parameters). This is often useful for bayesian inference. Corresponds to maximum entropy distributions (don\u0026rsquo;t know why). Who is part of this family? Bernoulli is part of this family We can write the Bernoulli distribution as $p(y \\mid \\theta) = \\theta^{y}(1 - \\theta)^{1 - y}$ where $\\theta \\in [0, 1]$ and $y \\in \\left\\{ 0, 1 \\right\\}$. This is a standard trick, we did something very similar when analyzing the MLE in bernoulli in Na√Øve Bayes.\nWe can rewrite the above in the following way: $$ \\begin{array} \\\\ \\theta^{y}(1 - \\theta)^{1 - y} = \\exp(y \\log \\theta + (1 - y) \\log(1 - \\theta)) \\\\ = \\exp\\left( y \\log \\left( \\frac{\\theta}{1 - \\theta} \\right) + \\log ( 1- \\theta) \\right) \\\\ = (1- \\theta) \\exp\\left( y \\log\\left( \\frac{\\theta}{1 - \\theta} \\right) \\right) \\end{array} $$ We can observe that $Z(\\theta) = \\frac{1}{1 -\\theta}$, $h(x) = 1$, $\\phi(x) = x$ is the identity function and we use a change of parameter to say that the natural parameter is given by $\\log ( \\frac{\\theta}{1- \\theta})$ instead of $\\theta$, which needs to rewrite the value of $Z$ in another way, noticing that $\\mu = \\log \\left( \\frac{\\theta}{1-\\theta} \\right) \\implies \\theta = \\frac{1}{1 - e^{\\mu}}$.\nBut the important thing to notice is that Bernoulli indeed can be rewritten as a member of the exponential family, thus concluding the proof.\nGaussian is part of this family üü• The standard Gaussian is written as follows: $$ p(y \\mid \\mu, \\sigma) = \\frac{1}{\\sqrt{ 2\\pi } \\sigma} \\exp \\left( -\\frac{(x - \\mu)^{2}}{2\\sigma^{2}} \\right) $$ In this case the natural parameter is two-dimensional. We just need a little care handing this peculiar trait.\nThe above can be rewritten in the following way: $$ = \\frac{1}{\\sqrt{ 2\\pi \\sigma^{2} } \\exp \\frac{\\mu^{2}}{2\\sigma^{2}}} \\cdot 1 \\cdot \\exp \\left( \\begin{bmatrix} \\frac{\\mu}{\\sigma^{2}} \u0026amp; - \\frac{1}{2\\sigma^{2}}\n\\end{bmatrix} \\cdot \\begin{bmatrix} x \\ x^{2} \\end{bmatrix}\n\\right) $$\nThen it is kinda awful to rewrite the $Z$ with respect to those parameters, but I think you can be convinced it is possible. It\u0026rsquo;s far easier to see it when we set $\\sigma^{2} = 1$. That is available here see 3.1.\nBeta is part of this family The classical Beta distribution is\n$$ p(x \\mid \\alpha, \\beta) = \\frac{x^{\\alpha - 1} (1 - x)^{\\beta - 1}}{B(\\alpha, \\beta)} $$ Where $\\alpha \u003e 0, \\beta \u003e 0$ and the support of the beta in $[0 ,1 ]$.\nThis is quite easy, after we rewrite the numerator in the following way: $$ x^{\\alpha - 1} (1 - x)^{\\beta - 1} = \\exp( (\\alpha - 1) \\log x + \\log(1 - x) (\\beta - 1))\n$$ Which can be rewritten in multivariable form in the following way: $$ \\exp \\left( \\begin{bmatrix} \\alpha - 1 \u0026amp; \\beta - 1 \\end{bmatrix} \\cdot \\begin{bmatrix} \\log x \\ \\log ( 1- x) \\end{bmatrix}\n\\right) $$ Adding the partition function completes the expression.\nChi-square is part of this family The chi-square distribution is as follows:\n$$ p(x, k) = \\frac{ x^{k / 2 - 1} \\exp\\left( -\\frac{x}{2} \\right)}{2^{k / 2} \\Gamma(k / 2)} $$ Where $k \\in \\mathbb{N}^{+}$, and the support is $(0 , \\infty)$ if $k = 1$, and $[0, \\infty)$ otherwise.\nThis is easy if we set $k / 2 - 1$ to be the canonical parameter, $\\exp(- x / 2)$ is the support, the denominator is the partition function, we just need to express $x^{ k / 2 - 1} = \\exp (( k / 2 - 1) \\log x)$ and we have also the sufficient statistics which is $\\phi(x) = \\log x$.\nBinomial is part of the family Let\u0026rsquo;s consider a distribution defined as $$ p(x \\mid \\pi) = \\begin{pmatrix} n \\\\ x \\end{pmatrix} \\pi^{x} (1 - \\pi)^{n - x} $$ This is the classical count for the Tartaglia triangle, also known as the Pascal Triangle, in this case is just the iterated Bernoulli assuming $x$ number of successes. This is a special case of the multinomial distribution. We have $\\pi \\in [0, 1]$ and the support is $\\left\\{ 0, \\dots, n \\right\\}$.\nIn this case the trick is very similar to what we have done for the Bernoulli distribution. We rewrite $\\pi^{x} (1 - \\pi)^{n - x}$ in the following way: $$ \\pi^{x} (1 - \\pi)^{n - x} = \\exp(x \\log \\pi + (n - x) \\log(1 - \\pi)) = \\exp(n \\log(1- \\pi)) \\cdot \\exp\\left( x \\log \\frac{\\pi}{1- \\pi} \\right) $$ And now we can clearly see that $\\exp( - n \\log(1- \\pi))$ is our partition, $\\phi(x) = x$ is our sufficient statistics, $\\log \\frac{\\pi}{1-\\pi}$ is our canonical parameter and the binomial coefficient is our support.\nUniform distribution is not in the family Let\u0026rsquo;s consider a continuous uniform distribution: $$ p(x \\mid b) = \\begin{cases} \\frac{1}{b} \u0026 \\text{ for } x \\in [0, b] \\\\ 0 \u0026 \\text{ otherwise} \\end{cases} $$ We want to prove that this classical distribution is not part of our family of distributions. We have $b \\in (0, \\infty)$ and the support is $[0, b]$.\nIn this case there is no way to encode into the exponential family the cases of the function. The exponential can\u0026rsquo;t just return $0$. And the support has no information about the $b$. This is not a proof, but it is reasonable.\n","permalink":"https://flecart.github.io/notes/the-exponential-family/","summary":"This is the generalization of the family of function where Softmax Function belongs. Many many functions are part of this family, most of the distributions that are used in science are part of the exponential family, e.g. beta, Gaussian, Bernoulli, Categorical distribution, Gamma, Beta, Poisson, are all part of the exponential family. The useful thing is the generalization power of this set of functions: if you prove something about this family, you prove it for every distribution that is part of this family.","title":"The Exponential Family"},{"content":"Ultima modifica: March 11, 2023 7:22 PM Primo Abbozzo: March 8, 2023 6:05 PM Studi Personali: No\nElementi di ripasso Training of NN How can we be sure that we can train well our function?\nDataset quality (this cannot be changed in training time) Models and parameters of our model, we can describe it as $L(x, \\theta)$, and we try to minimize this function. Training approaches Random perturn weights, this is ispired by evolution, but it‚Äôs slow and not effective (and we can make things worse in many ways) Predict adjustments, usually we can analitically define what is the best way to minimize the loss, so we would like to follow that slope and go down! When we try to learn with the second method we usually follow the direction of a derivative (this is also an idea of gradient descent that we discussed in Metodi di Discesa.\nSo if we have a step function, we can‚Äôt learn anything, this is not a good loss. This is the classic gradient descent, but the new thing is that we have optimizers, more on them later.\nThe standard Gradient descent uses the whole dataset to calculate the direction and module of descent. Usually this is quite expensive, why would we need to use all the data when a subset could be enough? And also, why can‚Äôt we use the last gradient to know where to go? There are the ideas for the next gradient descent methods.\nStochastic Gradient descent faster More noise Sometimes when we try to escape from the noise, we can add some noise, like having a bigger step function, and we can escape a local minima if we get to.\nMomentum This is the other type of gradient descent, we add a momentum factor something like\n$$ v_{t + 1} = \\mu\\nabla L(x) + \\alpha v_t $$ The first term is the gradient (direction term) the second is the momentum term.\nSlide on momentum\nA different kind of momentum is nesterov momentum that just calculates the gradient from the next point after we applied the momentum, and not before, this should be a little better because we are just going from the gradient direction in an offsetted point, and not changing the gradient with some heuristic, (non mi sono affatto spiegato bene qui, non credo infatti di averlo capito bene sto momentum)\nSlides nesterov\nBackpropagation This is the gradient descent for neural networks.\n","permalink":"https://flecart.github.io/notes/training-a-nn/","summary":"Ultima modifica: March 11, 2023 7:22 PM Primo Abbozzo: March 8, 2023 6:05 PM Studi Personali: No\nElementi di ripasso Training of NN How can we be sure that we can train well our function?\nDataset quality (this cannot be changed in training time) Models and parameters of our model, we can describe it as $L(x, \\theta)$, and we try to minimize this function. Training approaches Random perturn weights, this is ispired by evolution, but it‚Äôs slow and not effective (and we can make things worse in many ways) Predict adjustments, usually we can analitically define what is the best way to minimize the loss, so we would like to follow that slope and go down!","title":"Training a NN"},{"content":"This note tries to summarize what I think I know about the attention architecture in Transformers. First introduced in (Bahdanau et al. 2014). Attention is an architecture used in Transformers to encode a soft version of dictionaries. Usually it is called self-attention when everything we want is just trying to change the values of the $X$ with a value. This value is called attention weight.\nIn standard attention based architectures the self-attention layer is computed as follows.\nWe have a set of weights $W^{q}$, $W^{k}$, $W^{v}$ of dimensions $D\\times D_{1}$, $D\\times D_{1}$ and $N\\times D_{2}$. Where $N$ is the batch size, $D$ is the latent size. Then, we say $a_{i}$ is a attention weight and we will have $$ a = softmax((W^{q}x) (W^{k}x)) $$ And after you have computed the weights, you just apply it to the scaled values: $$ y_{j} = \\sum_{i= 0}^{n} a_{i} (W^{v}x)_{ji} $$ Apply this over all batches in a parallel manner.\nThis image summarizes the main points of the attention mechanism. References [1] Bahdanau et al. ‚ÄúNeural Machine Translation by Jointly Learning to Align and Translate‚Äù 2014\n","permalink":"https://flecart.github.io/notes/attention/","summary":"This note tries to summarize what I think I know about the attention architecture in Transformers. First introduced in (Bahdanau et al. 2014). Attention is an architecture used in Transformers to encode a soft version of dictionaries. Usually it is called self-attention when everything we want is just trying to change the values of the $X$ with a value. This value is called attention weight.\nIn standard attention based architectures the self-attention layer is computed as follows.","title":"Attention"},{"content":"Sono variazioni possibili equivalenti: ‚Ä¢ Nastri addizionali ‚Ä¢ Testine addizionali ‚Ä¢ Nastri infiniti su entrambi i lati ‚Ä¢ Non-determinismo ‚Ä¢ Scelta probabilistica ‚Ä¢ Scelta quantistica Si pu√≤ dire che la definizione di TM √® stata robusta nella storia perch√© tantissimi formalismi che intuitivamente sembrano essere molto diversi rispetto alla TM alla fine possono essere dimostrate essere equivalenti.\nTuring con nastri addizionali Questo √® presente in modo abbastanza facile sul Sipser.\nLa computazione comincia con l‚Äôinput sul primo nastro, e tutti gli altri nastri vuoti. Macchine di Turing con nastri addizionali In ciascun passo di computazione, ogni testina √© nello stesso stato, ma pu√≤ essere in una posizione diversa, leggere un simbolo differente, e compiere un‚Äôazione diversa. Se si raggiunge uno stato finale, l‚Äôoutput √© letto dal primo nastro.\n#### Definizione formalismo üü© L'unica differenza formale √® che questa macchina √® **parallela** cio√® ho molte macchine di turing che vanno allo stesso momento $$ \\delta: (Q - H) \\times \\Sigma^{k} \\to Q \\times(\\Sigma \\times \\left\\{ \\to, \\leftarrow \\right\\} )^{k} $$ Il restante delle tuple resta uguale. L'altra osservazione √® che lo stato esterno √® **unico**. In un certo senso √® una **pila con macchina di turing** [Linguaggi liberi e PDA](/notes/linguaggi-liberi-e-pda). Teorema di equivalenza üü© Dimostriamo che questo formalismo √® equivalente con La macchina di Turing. √à ovvio il caso in cui nastro addizionale -\u0026gt; Turing. Ossia che\nTermina quando il l\u0026rsquo;altro non termina Se termina hanno stesso output. Si pu√≤ formalizzare per√≤ alla fine √® quello.\nL\u0026rsquo;altra freccia √® provare a simulare con La macchina di Turing tutti i nastri aggiuntivi del nostro multinastro, con un simbolo in pi√π che identifichiamo con $\\#$. Cominciamo (dimostrazione intuitiva): Supponiamo di avere una macchina multi nastro $\\mathcal{M}$, costruiamo con l\u0026rsquo;altra macchina $\\mathcal{M}'$ con singolo nastro che sia equivalente al primo, in questo modo dimostriamo che una TM √® anche uguale alla versione multi-nastro. Prendiamo $$ \\Sigma' = \\Sigma \\cup \\left\\{ \\# \\right\\} \\cup \\left\\{ \\bar{a} : a \\in \\Sigma \\right\\} $$ Allora I molteplici passi di computazione su molti nastri che sono un singolo passo per la multinastro possono essere simulati sul singolo nastro. La lettere barretta ci permette di mantenere il pointer sul nastro originale. Se c\u0026rsquo;√® bisogno di spazio in pi√π su un nastro, debbo postare tutto a destra (tanto √® infinito e posso farlo). (nota che per questo teorema √® necessario l\u0026rsquo;infinito!!) Alla fine cancello tutto dopo il primo cancelletto e ritorno quello.\nEnumerators Questo √® un argomento extra non trattato a lezione 3.2 del Sipser viene trattato. Si pu√≤ dire che √® una altra cosa equivalente alla La macchina di Turing. In modo informale, un enumeratore √® una macchina di turing con una stampante, che pu√≤ esser considerato l\u0026rsquo;output della nostra macchina. Poi c\u0026rsquo;√® un work tape che pu√≤ essere utilizzato come cache. Da un punto di vista formale non √® altro che una macchina di turing con 2 nastri\nMacchine di Turing non deterministiche Descrizione formalismo non deterministico üü© L\u0026rsquo;unica differenza con La macchina di Turing, √® che invece di funzione abbiamo una relazione! Ossia da un unico stato e simbolo sul nastro possono avere molti simboli e stati di arrivo. $$ \\delta: ((Q - H) \\times \\Sigma) \\times (Q \\times\\Sigma \\times \\left\\{ \\to, \\leftarrow \\right\\} ) $$ Oltre a questo anche lo stato di accettazione, se un qualunque ramo accetta, allora questa macchina accetta. Pu√≤ anche essere rappresentato da una funzione sull\u0026rsquo;insieme delle parti, anche se potrebbe sembrare meno intuitivo. $$ \\delta: ((Q - H) \\times \\Sigma) \\to \\mathbb{P}(Q \\times\\Sigma \\times \\left\\{ \\to, \\leftarrow \\right\\} ) $$ In un certo senso questo non determinismo √® simile a quanto fatto in Grammatiche Regolari e Linguaggi liberi e PDA. Per il non determinismo. Solo che l√¨ il prof. li faceva pi√π formali.\nSulle slides c\u0026rsquo;√® un esempio di NMT molto semplice per dimostrare che la primalit√† di un numero √® calcolabile. (idea prendo in modo non deterministico un numero minore di $n$ e calcolo il modulo).\nSketch di dimostrazione di equivalenza üü®++ Supponendo che abbiamo l\u0026rsquo;albero di computazione, posso esplorare con Grafi#BFS tutto l\u0026rsquo;albero di computazione e avere alla fine lo stesso risultato.\nQui c\u0026rsquo;√® un albero di computazione. (poi probabilmente bisogner√† codificare un backtracking) Altre Una altra macchina di Turing di interesse che non trattiamo qui √® il prefix turing machine, che trattiamo in Kolmogorov complexity.\nMacchine a registri Chiamato anche URM unlimited register machine, √® un formalismo pi√π simile a come sono fatti i computer moderni perch√© utilizzano i regsitri. Definito in (Shepherdson \u0026amp; Sturgis 1963).\nDescrizione Unlimited Register Machineüü®++ Supponiamo di avere $R_{1}, R_{2}, R_{3}, \\dots$ registri, ogni registro ha un numero naturale indicato con $r_{n}$ (contenuto di registro $n$) Se la computazione finisce, questa viene messa in $R_{1}$ (simile a RAX in archietture intel). L\u0026rsquo;input $N^{k}$ √® messo in tutti i registri in ordine (se non definito sono a 0).\nEsistono un sistema di istruzioni che muovono e modificano le cose dei registri:\nZero $Z(n)$ il registro $n$ √® messo a 0. Successor $S(n)$ il registro $n$ √® aumentato a $n$ Move $R(n, m)$ $m$ √® messo uguale a $n$ (sono registri) Jump $J(n, m, p)$ Salta a istruzione $I_{p}$ se i registri $n$ e $m$ sono uguali. altrimenti ignora istruzione. Ora possiamo definire una specie di ALU che √® la cosa classica di programma imperativo.\nEnunciato equivalenza üü© Vogliamo passare in questo caso a dimostrare la calcolabilit√† di funzioni parziali, ossia funzioni $$ \\mathbb{N}^{k} \\to \\mathbb{N} $$ Che possono anche non terminare (in questo caso parziale).\nUna funzione parziale √® calcolabile in URM sse √® calcolabile su TM\nIdea TM =\u0026gt; URM üü® Uso il risultato in #Turing con nastri addizionali, ho tanti nastri che fanno cose:\nFa instruction pointer e punta all\u0026rsquo;istruzione attuale Ha il codice del programma Ha il valore dei registri in notazione unaria (che √® equivalente), separati da U. Altri registri sono cache. Allora posso usare il contenuto del nastro 1 per trovare l\u0026rsquo;istruzione, poi uso altro per interpretarla ed eseguirla. Alla fine uso il primo valore del terzo nastro per avere il risultato. Per la modifica dei registri posso usare nastri ausiliari.\nIdea TM \u0026lt;= URM üü® Supponiamo di avere un URM, vogliamo simulare una macchina di turing con la classica tupla $\\Sigma, Q, q_{0}, H, \\delta$\nChiamo un registro TAPE che conterr√† i valori presenti su un nastro di Turing. Inoltre dobbiamo ricordarci che questa macchina contiene numeri naturali per questo motivo abbiamo bisogno di una codifica. Scegliamo $\\Sigma = \\left\\{ 0, 1, U \\right\\}$ dove $U$ sta per empty, nel caso in cui l\u0026rsquo;alfabeto sia diverso da questo, la dimostrazione dovr√† essere equivalente. Allora possiamo usare la notazione in base $3$ per decodificare il numero, assumendo $code(0) = 0$, $code(1) = 1$, $code(U) = 2$.\nPoi introduciamo registri per codificare $\\delta$ la funzione di transizione. Modello WHILE Questo √® un formalismo pi√π simile a uno di alto livello (quindi programma normale).Descritto in\nKfoury, Moll, Arbib - A programming approach to computability.\nDescrizione del modello WHILE(3)üü© Questo √® simile a quanto descritto per la Semantica di un linguaggio per la parte procedurale. Abbiamo:\nAssegnazione Cicli while seguenziamento Possiamo definirlo in Sintassi e RI strutturali#4.2 Backus-Naur Form Ci sono tre forme di assegnazione, uno zero, uno successivo, uno uguale credo. Non viene fatta la parte della semantica che abbiamo fatto tempo fa a linguaggi.\nDimostrazione equivalenza üü© Una funzione (parziale) √© computabile da un programma WHILE se e solo se √© computabile da una macchina di Turing.\nSi dimostra per induzione strutturale sulla BNF l√¨ precedente. I casi base sono i 3 assegnamenti (zero, successore, e predecessore) e il programma vuoto.\nPer il caso base, utilizzo un nastro separato come ho fatto per #Turing con nastri addizionali, su questo ci metto le variabili di interesse. Su questo posso codificare i casi base accennati di sopra.\nPoi caso induttivo √® while e sequenza di istruzioni. Poi per codificare la sequenza, basta concatenare molte macchine di turing normali, ognuna che codifica l\u0026rsquo;istruzione. Sappiamo che queste esistono per ipotesi induttiva. Per il while possiamo usare due macchine, una per il test, una per il corpo del while e dire che accetta quando esco dal ciclo. √à interessante osservare come siano uguali questi.\nReferences [1] Shepherdson \u0026amp; Sturgis ‚ÄúComputability of Recursive Functions‚Äù Journal of the ACM Vol. 10(2), pp. 217\u0026ndash;255 1963\n","permalink":"https://flecart.github.io/notes/estensioni-di-turing-e-altre-macchine/","summary":"Sono variazioni possibili equivalenti: ‚Ä¢ Nastri addizionali ‚Ä¢ Testine addizionali ‚Ä¢ Nastri infiniti su entrambi i lati ‚Ä¢ Non-determinismo ‚Ä¢ Scelta probabilistica ‚Ä¢ Scelta quantistica Si pu√≤ dire che la definizione di TM √® stata robusta nella storia perch√© tantissimi formalismi che intuitivamente sembrano essere molto diversi rispetto alla TM alla fine possono essere dimostrate essere equivalenti.\nTuring con nastri addizionali Questo √® presente in modo abbastanza facile sul Sipser.","title":"Estensioni di Turing e altre macchine"},{"content":"Introduzione This is a short introduction to statistical learning, made with the help of the book (James et al. 2023).\nstatistical learning refers to a set of approaches for estimating $f$ .\nUtilizzi del statistical learning Solitamente sono due gli utilizzi Predizione e inferenza. Per predizione intendiamo il miglior modello che possa produrre le Y che ancora non conosciamo. Per inferenza significa il miglior modello f per predire Y che conosciamo.\nNel primo caso la funzione migliore $f$ potrebbe benissimo restare sconosciuta, ci importa solamente che predica con accuratezza, mentre nel secondo caso vorremmo anche conoscere $f$.\nIn un certo senso l\u0026rsquo;inferenza ci permette di calcolare una specie di legge fisica, (√® incorretto chiamarlo in questo modo, ma credo dia l\u0026rsquo;idea), ossia permette la comprensione del perch√© avendo questi input, potr√≤ avere quei output. NOTA: avendo questa comprensione potrei anche fare predizioni su dati che non esistono, credo.\nErrore riducibile e irriducibile Questo √® un concetto statistico abbastanza nuovo, utile per parlare di stima di modelli statistici. Supponiamo di avere una serie di dati solitamente indicati con $X$ , vogliamo con questi andare a predire la variabile dipendente $Y$. Solitamente andiamo anche ad introdurre un errore rappresentato con $\\varepsilon$ . Questo √® un errore indipendente da $X$, ossia non possiamo predirlo utilizzando X.\nLa branca dell\u0026rsquo;apprendimento statistico vuole utilizzare X per andare a predire Y. Per√≤ il meglio che pu√≤ fare resterebbe sempre solamente una funzione $f$ che abbia quell\u0026rsquo;errore che lo faccia variare. Quell\u0026rsquo;errore potrebbe essere dovuto a informazioni che non conosciamo oppure solamente a cose che non possono essere misurate (elementi che sono principalmente dovuti al caso, che difficilmente avremmo potuto utilizzare per misurarlo)\nFormalizzazione di sopra Tutto si potrebbe formalizzare con questo ragionamento $$ E[Y - \\hat{Y}]^2 = E[(f(X) + \\varepsilon) - \\hat{f}(X)]^2 = [f(X) - \\hat{f}(X)]^2 + var(\\varepsilon) = \\text{ bias }^{2} + var(\\varepsilon) $$ Osservando che X √® una costante in questo caso, e ci interessa solamente la varianza. Si potrebbe intendere che la prima parte √® un errore riducibile (pu√≤ essere fino a 0), mentre la varianza dell\u0026rsquo;errore √® parte di errore irriducibile.\nTipologie di modelli Principalmente esistono due tipologie di modelli, proveremo a parlarne estensivamente qui sotto:\nModelli parametrici L\u0026rsquo;inferenza/predizione con questo genere di modelli si fa in due step:\nScelta del modello (lineare? Quadratico? rete neurale? allora architettura della rete) Algoritmo di scelta dei parametri del modello Vedere sul libro pagina 31 per degli esempi. La caratteristica negativa di questo √® che √® fortemente dipendente dal nostro modello scelto, che non sempre pu√≤ risultare essere la migliore per stimare la funzione che abbiamo:\nThe potential disadvantage of a parametric approach is that the model we choose will usually not match the true unknown form of $f$ .\nModelli non parametrici Non-parametric methods do not make explicit assumptions about the functional form of $f$ . Instead they seek an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly.\nUn esempio di questo genere di modelli potrebbero essere splines, che sono molto pi√π variabili di un modello parametrico\nVantaggio principale sui parametrici by avoiding the assumption of a particular functional form for f , they have the potential to accurately fit a wider range of possible shapes for f .\nSvantaggio principale Dato che non devo imparare solamente dei parametri, ho bisogno di molto pi√π dati affinch√© io sia accurato nella predizione\nReferences [1] James et al. ‚ÄúAn Introduction to Statistical Learning: With Applications in Python‚Äù Springer International Publishing 2023\n","permalink":"https://flecart.github.io/notes/introduction-to-statistical-learning/","summary":"Introduzione This is a short introduction to statistical learning, made with the help of the book (James et al. 2023).\nstatistical learning refers to a set of approaches for estimating $f$ .\nUtilizzi del statistical learning Solitamente sono due gli utilizzi Predizione e inferenza. Per predizione intendiamo il miglior modello che possa produrre le Y che ancora non conosciamo. Per inferenza significa il miglior modello f per predire Y che conosciamo.","title":"Introduction to statistical learning"},{"content":"Questo √® un modo di pi√π alto livello per creare programmazione concorrente.\nIntroduzione ai monitor Questo costrutto per la programmazione concorrente, prende molto dalla programmazione agli oggetti, abbiamo delle variabili presenti al monitor, private solamente accessibili ad essa, tramite procedure che sono mutex automaticamente!\nElementi costituenti üü© Dati locali Sequenza di inizializzazione Procedure di entrata Appena provo a chiamare una procedura, questa √® fatta gi√† in mutua esclusione!.\nE possono modificare dati locali solo tramite chiamate a sue procedure\nCose in slide\nVariabili di condizione üü© Queste sono variabili utilizzate per sincronizzare l‚Äôaccesso,\nStrutture classiche\nPolitica del signal urgent (!) üü© Slide\nL‚Äôidea √® molto simile a quanto fatto per i signal presenti in Semafori, se qualcuno √® in attesa, dai subito il bastone a lui, altrimenti non fai niente.\nQuesta √® la politica di signalling che viene usata implicitamente in esame.\nAltre politiche di signalling (3) üü® Slide\nDifferenze con semafori (3) üü©- Slide\nSembrano simili la Wait e la signal con P e la V, ma sono cose totalmente diverse!!!!.\nSignal non ha nessun effetto se non ci sono processi in attesa, mentre V memorizza sempre Wait √® sempre bloccante! mentre P no‚Ä¶ Il processo risvegliato √® sempre eseguito per primo! (signal urgent). Implementazione dei semafori con monitor üü© Slide\n√à una implementazione molto facile! Per questo motivo ci piace abbastanza üòÄ\nImplementazione monitor con semafori üü®+ Slide\nProblemi classici con monitor Readers and writers üü®+ la parte difficile di questa parte √® scrivere bene le invarianti, quindi √® molto pi√π facile scrivere una soluzione una volta che si sa.\nDriver code\nReaderWriter controller\nVersione senza starvation !!!\nProducer and consumers üü© Soluzione producer and consumers\nBuffer limitato üü© Sol\nQuesta soluzione con i semafori √® molto pi√π clean rispetto a quello dei semafori!\nbasta andare a verificare che le invarianti siano soddisfatte, riguardanti la possibilit√† di scrittura e la possiblit√† di lettura.\nFilosofi a cena Sol\nDriver code, dal punto di vista del filosofo\nWithout deadlock\nWithout deadlock, all destri!\nSoluzione con chopsticks\nuna cosa molto bella √® che che non √® deadlock nemmeno se sono tutti destri! il motivo √® che l\u0026rsquo;accesso √® sempre in mutua esclusione, il primo che va a prenderli √® buona roba.\nUlteriori delucidazioni su questa roba\nSupponiamo per assurdo che ci sia deadlock per la versione in cui i filosofi sono tutti destri. Supponiamo che siamo al filosofo $i$, questo prende la sua bacchetta, e deve aspettare la bacchetta successiva, fino a creare il ciclo. fino a qui abbiamo enunciato quello che deve succedere affinch√© ci sia deadlock. Ma questo non pu√≤ succedere perch√© ogni filosofo guarda da solo se pu√≤ prenderlo o meno (mi sembra che questa soluzione sia un poco meno efficiente rispetto a quello con i semafori, perch√© solamente un filosofo pu√≤ prendere‚Ä¶)\n","permalink":"https://flecart.github.io/notes/monitor/","summary":"Questo √® un modo di pi√π alto livello per creare programmazione concorrente.\nIntroduzione ai monitor Questo costrutto per la programmazione concorrente, prende molto dalla programmazione agli oggetti, abbiamo delle variabili presenti al monitor, private solamente accessibili ad essa, tramite procedure che sono mutex automaticamente!\nElementi costituenti üü© Dati locali Sequenza di inizializzazione Procedure di entrata Appena provo a chiamare una procedura, questa √® fatta gi√† in mutua esclusione!.\nE possono modificare dati locali solo tramite chiamate a sue procedure","title":"Monitor"},{"content":"Data types Default data types üü© I tipi di dati sono\nCarattere numero data tempo intervallo di tempo booleano blob (binario) clob (carattere) Setting custom data types üü© Ma possono essere definiti anche tipi di dati custom, la sintassi √® simile\nCREATE DOMAIN Grade AS SMALLINT DEFAULT NULL CHECK (value \u0026gt;= 18 AND value \u0026lt;= 30) Altering existing domains üü© In cui posso mettere anche dei check custom.\nDROP DOMAIN Per cancellare il domain l√¨ presente\nE si pu√≤ anche cambiare con\nALTER DOMAIN Posso aggiungere o eliminare constraints per esempio.\nPer√≤ a seguito di questo comando, dovrei essere in grado di modificare correttamente i valori con schema cambiato, metterli a default, o metterli a null diciamo.\nData definitions Database Creation üü© CREATE DATABASE db_name, che va a creare un database che pu√≤ contenere molte tavole, schemi diversi e simili.\nSchema üü® √à una descrizione logica di come √® strutturato l\u0026rsquo;intero database, non √® da confondere con lo schema di una singola tavola.\nSchema creation Lo schema √® la specificazione dei domini e delle restrizioni che ogni colonna deve avere per essere integra. In pi√π possono essere definite view diverse o anche authorization.\nCREATE SCHEMA schema_name\nTable La tavola specifica una relazione vuota, che pu√≤ seguire o meno uno schema, come definito di sopra.\nCreate table üü© Table constraints üü© Durante la creazione di una table posso specificare cose come\nTipo (intero, carattere?) Valore di default Constraints (tipo NOT NULL) Reference esterna o chiave di tavola. Deletion and change üü© Abbiamo comandi come\nDROP TABLE ALTER TABLE Per eliminare o cambiare lo schema della singola table.\nSolitamente posso modificare singole colonne per sql, aggiungere constraints o dati di default.\nReferential trigger üü©- Per le foreign keys posso andare a definire anche una\nAzione che viene eseguito quanto l\u0026rsquo;altra tabella viene Aggiornata Eliminata Azioni permesse sulla table con foreign key Cascade (eliminare o aggiornare di conseguenza) Set null set default no op, che non permette di fare l\u0026rsquo;operazione nemmeno sulla tavola originaria. Indexes üü®- Sono delle strutture di dati che permettono di svolgere certe operazioni in modo pi√π efficiente, cercheremo di distinguere i casi in cui √® effettivamente utile andare a creare questo indice. Questo solitamente √® fatto al livello fisico.\nCREATE INDEX idx_surname ON officer (Surname) Creo un indice con nome, su un attributo della table.\nData operations CRUD:\nCreate -\u0026gt; Insert Read -\u0026gt; SELECT Update -\u0026gt; UPDATE Delete -\u0026gt; DELETE (molto rischioso!) Select Le operazioni di select √® molto simile a proiezione e selezione che sono trattati in Relational Algebra.\nSintassi classica üü© SELECT attributes FROM tables and joins [WHERE condition] [GROUP BY attributes] [HAVING conditions] [ORDER BY attributes] Compare: algebra relazionale üü© Si possono considerare molte similitudini in Relational Algebra\nSelect and projection $\\pi_{age, height}(\\sigma_{age \u003c 30}(people))$ Select with renaming (projection) Pure select $\\sigma_{age\u003c30}(People)$ Projection without selection $\\pi_{age, height}(people)$ che prende colonne. Da questo si pu√≤ notare che SELECT da sola gestisce tre relazioni\nSelect Projection Rename Che sono stati trattati nell\u0026rsquo;algebra relazionale. Possono anche essere estesi ad avere le JOIN usando cose del from. Si potrebbe semplificare affermando\nWHERE = Selection in algebra relazionale SELECT = projection FROM = prodotto cartesiano. Esempio complesso di query con Cartesian product e renaming Like and null values üü© Like √® utilizzato per fare pattern matching sulla stringa. Mentre i null values si possono gestire con sintassi $AGE\\, is \\, NULL$\nJoin Sintassi üü® precedentemente nella sezione #Select abbiamo utilizzato join delle tables in maniera implicita utilizzando il prodotto cartesiano. Esiste per√≤ anche una istruzione esplicita per dire che vogliamo fare JOIN, molto coerente con la teoria presente in Relational Algebra.\nSELECT ... FROM leftTable [JOIN rightTable ON condition] [WHERE predicate] Esempio di differenza fra JOIN e il prodotto cartesiano con la sintassi di sopra. Inner and outer joins üü© La differenza principale fra inner e outer join √®\nInner Dati che non hanno elementi in comune vengono scartati (come quello presente sulla slides di sopra) questo viene anche chiamato natural join. Outer Vengono tenuti anche i dati che non fanno matching in una parte in comune, solitamente questi sono sempre chiamati left o right, ma vedremo dopo esattamente quale sia la semantica LEFT: (right √® esattamente il contrario) Ritorna sempre il sinistro, ma il destro pu√≤ anche essere null FULL: ritorna sinistro se c\u0026rsquo;√® e destro se c\u0026rsquo;√®.\nRemaining CRUD operations La sintassi di insertion, deletion and update √® molto pi√π semplice rispetto alla lettura, quindi la mettiamo nella sottosezione.\nInsert üü© NOTE: √® importante l\u0026rsquo;ordine di inserimento!\nINSERT INTO table [attrs] VALUES(vals) | SELECT roba.. Update üü© UPDATE TableName SET Attribute = \u0026lt; Expression, select, null or similar \u0026gt; WHERE \u0026lt;cond\u0026gt; Esempi: Delete üü© DELETE FROM table [WHERE condition] ### Altre Istruzioni #### Sorting üü© Per fare sorting basta aggiungere **ORDER BY** Order by pu√≤ essere ascendente o discendente (facile se √® alfanumerica come attributo). DEFAULT: descending. Union intersection and difference üü® UNIONE\nUso normale: come in figura Nel caso venga definito ALL, anche se √® doppio, viene mantenuto. Nel caso di conflitti semantici, utilizzare positional notation, se sono nella stessa posizione vengono messi assieme (il nome dell\u0026rsquo;attributo √® sempre della prima tavola) DIFFERENZA Si usa except, e poi altre notazioni sono simil ial precedente.\nINTERSEZIONE Si usa intersect come istruzione. (ma √® meglio usare il where, descritto in #Select, che √® equivalente).\nIntersection\nNested Queries NOTA: ogni subquery viene eseguita ogni volta per\nCorrectness conditions üü© Le queries innestate vengono eseguite per ogni tupla esterna, e sono corrette se quanto viene ritornato √® coerente con l\u0026rsquo;input del secondo\nSELECT Name, Income FROM People WHERE Name IN (SELECT Father FROM Fatherhood, People WHERE Child=Name AND Income\u0026gt;20) In questo caso IN si aspetta poi un insieme, che √® quanto ritornato nella subquery, il vantaggio principale di questo approccio √® la leggibilit√†,\nVisibilit√† üü© Ci sono due note riguardo la visibilit√†, perch√© seguendo una logica simile agli scopes strutturali se sono in scope esterno non posso accedere a quello internamente definito. Mentre la query innestata pu√≤ leggere variabili definite esternamente. Chiaramente se hai due nested diverse, non riescono ad avere stesso variabile, segui le stesse regole di scoping definito in linguaggi di programmazione.\nExistance üü© Exists Molto intuitivo, se sai un po' di [Logica del Primo ordine](/notes/logica-del-primo-ordine). #### Any and ALL üü©--- Sono altri predicati possibili per cose innestate Aggregate functions Gli aggregate consentono di ritornare un valore unico da una lista di dati. Hanno una semantica precisa: Prima fatto tutto, ignorando dell\u0026rsquo;esistenza del groupby, fanno una selezione di tutti gli attributi che sono presenti qui, e poi effettivamente raggruppano. Sul libro atzeni √® descritto in pagina 123. L\u0026rsquo;aspetto principale da ricordare √® che attributi in group by sono superset degli attributi di selezione.\nClassical sintax üü© La sintassi classica per questo genere di query √®\nAggr([DISTINCT] attribute) Attribute √® il dominio su cui andare a runnare la funzione di aggregazione.\nSome aggregate functions Count Ritorna semplicemente il numero di elementi dentro la lista Caso interessante da ricordare √® count NULL values AVG, MAX, MIN üü© Sintassi √® uguale al precedente, poi la semantica √® un po\u0026rsquo; diversa, ma credo sia chiara dal nome delal fuznione aggregate\nGrouping üü© La sintassi classica √® GROUP BY attributeList.\nSemantica üü© Prima esegue la query normale, come se grouping non esistesse. Poi esegue il grouping, e se c\u0026rsquo;√® un aggregate function, eseguirlo sul singolo gruppo. Questa cosa √® molto importante da conoscere perch√© altrimenti sbagli al query e questo mi era successo in passato, ci ho speso molto tempo. Giustifica anche il motivo per cui devi fare select dell\u0026rsquo;attributo di cui vuoi fare grouping, altrimenti non hai niente da grouppare diciamo! NOTA: aggregate √® eseguito sul singolo gruppo!\nOther conditions üü© Si pu√≤ usare HAVING per aggiungere altre condizioni sui gruppi in modo simile a quanto faceva WHERE dentro #Select.\nComportamento con i NULLs Altro Sull\u0026rsquo;esecuzione di SQL üü© √à il DBMS che si occupa di eseguire la query ed ottimizzarla. Avere query corrette e leggibili √® pi√π importante. Questo descrive anche il perch√© sarebbe a volte sensato farle innestate. ","permalink":"https://flecart.github.io/notes/structured-query-language/","summary":"Data types Default data types üü© I tipi di dati sono\nCarattere numero data tempo intervallo di tempo booleano blob (binario) clob (carattere) Setting custom data types üü© Ma possono essere definiti anche tipi di dati custom, la sintassi √® simile\nCREATE DOMAIN Grade AS SMALLINT DEFAULT NULL CHECK (value \u0026gt;= 18 AND value \u0026lt;= 30) Altering existing domains üü© In cui posso mettere anche dei check custom.\nDROP DOMAIN Per cancellare il domain l√¨ presente","title":"Structured Query Language"},{"content":"Le variabili aleatorie ci permettono di dire qualcosa sullo spazio di probabilit√† senza andare troppo nei dettagli a considerare singoli eventi e cose simili.\nVariabili aleatorie discrete Con le variabili aleatorie cominciamo ad entrare nel noccio della questione, finalmente possiamo in un certo senso legare l‚Äôoutcome di un evento, alla probabilit√† dell‚Äôevento.\nDefinizione VA üü© Si definisce variabile aleatoria $X$ una funzione da $\\Omega \\to E$, con Omega il nostro spazio campionario, e $E$ qualunque insieme (quando $E = \\mathbb{R}$ si parla di variabile aleatoria reale\nQuindi un esempio classico per il dado, potremmo definire una variabile aleatoria dallo spazio campionario $\\Omega = [1, 2, 3, 4, 5, 6]$ ai reali, tali che $X(1) = 1, X(2) = 2$ etc, in questo senso stiamo facendo una funzione fra abitanti di insiemi diversi, ma resta una funzione.\nSpesso variabili aleatorie rappresentano un qualcosa che dipende dall‚Äôesito, questo valore pu√≤ essere numerico come in questo caso (noi in questo corso resteremo al numerico), ma non √® necessario che lo sia.\nvariabili aleatorie pi√π interessanti per esempio il numero di lanci medio per avere 6, obboh, hai molte libert√† di creare le funzioni.\nNOTA: solitamente indichiamo il dominio della variabile aleatoria come da uno spazio di probabilit√†, ossia in cui $P$ sia definita. Questa notazione ci risutler√† comodo quando andiamo a parlare di distribuzione di probabilit√† di uno spazio aleatorio.\n(Legge) Distribuzione di probabilit√† üü© Definiamo una funzione $P_X$ in questo modo:\n$$ P_X(A) = P(\\{\\omega \\in \\Omega: X(w) \\in A\\}), A \\subseteq E $$ Possiamo dimostrare che questa √® effettivamente una probabilit√† su $E$! Basta dimostrare la sigma additivit√† e il fatto che $P_X(E) = 1$, l\u0026rsquo;ultimo √® ovvio, perch√© per come √® definito X, abbiamo che $\\Omega = \\{\\omega \\in \\Omega: X(w) \\in E\\}$\nIl secondo punto √® leggermente pi√π complicato, ma lascio al lettore.\nInoltre andiamo a definire questo insieme come l‚Äôesito associato\n$$ \\text{Esito associato a una variabile aleatoria X:} \\\\ \\{\\omega \\in \\Omega: X(w) \\in A\\} $$ Def: Funzione di ripartizione (CDF) üü© Propriet√† Fn ripartizione discreta (4) üü®- Monot√≤na crescente (tal cred lol) Continua a destra $\\lim_{x \\to -\\infty} F_X(x) = 0$ $\\lim_{x \\to +\\infty} F_X(x) = 1$ Dimostrazione delle propriet√†\nDef: Densit√† discreta La funzione di probabilit√† di massa o anche densit√† discreta ci dice nell‚Äôinsieme di arrivo quanto sia probabile che si abbia quel valore, possiamo rappresentarlo in questo modo:\n$$ p_X(x) = P(\\{w\\in \\Omega: X(w) = x\\}), x\\in E $$ Variabili aleatorie discrete Si parla di variabili aleatorie discrete quando il sottoinsieme $S_X \\subseteq E$ degli elementi tali per cui $P_X(S_X) \u003e 0$, √® o finito o numerabile, allora in questi casi se $\\forall y \\in S_X$ definiamo una probabilit√†, abbiamo una probabilit√†!\nTeorema di caratterizzazione delle variabili aleatorie discrete Slide del teorema\nQuesto teorema ci dice una cosa molto stupida sulle variabili aleatorie, una cosa che credo abbiamo gi√† dimostrato in Spazi di probabilita, che in pratica √® la stessa.\nIn pratica ci sta dicendo che tutte le variabili aleatorie discrete possono essere descritte secondo la probabilit√† di massa\nVariabili aleatorie continue Le variabili aleatorie continue ci sono utili quando vogliamo descrivere qualcosa che √® difficilmente discretizzabile, come per esempio l‚Äôemivita di una batteria. Fatto sta che il suo modello ha un sacco di peculiarit√† che lo rendono molto diversa rispetto a una variabile aleatoria normale:\nPropriet√† di VA continua (2) $\\forall x \\in \\R, f_X(x) = 0$ $\\int_{-\\infty}^\\infty f_X(x)dx = 1$ Si pu√≤ poi dimostrare che\n$P(a \\leq x\\leq b) = \\int_a^bf_X(x)dx$ Si noti che non abbiamo pi√π bisogno che $f_X (x) \\leq 1 \\forall x \\in \\R$, basta che l\u0026rsquo;integrale di tutto sia 1\nPer la propreit√† 1 abbiamo questo fatto:\nla probabilit√† che una variabile aleatoria continua X assuma valori in un intervallo non dipende dal fatto che gli estremi dell‚Äôintervallo siano inclusi o esclusi,\nNon univocit√† della densit√† la funzione f_X definita in precedenza sarebbe la funzione di densit√† continua della nostra probabilit√†. Fatto sta che cos√¨ definita se cambiamo la nostra funzione in un numero finito oppure infinto numerabile di punti, allora l\u0026rsquo;integrale possiede ancora lo stesso valore, quindi √® una densit√† valida (basta provare a spezzare la somma dell\u0026rsquo;integrale per tutti i punti in cui si √® cambiato e si pu√≤ verificare questo dato).\n","permalink":"https://flecart.github.io/notes/variabili-aleatorie/","summary":"Le variabili aleatorie ci permettono di dire qualcosa sullo spazio di probabilit√† senza andare troppo nei dettagli a considerare singoli eventi e cose simili.\nVariabili aleatorie discrete Con le variabili aleatorie cominciamo ad entrare nel noccio della questione, finalmente possiamo in un certo senso legare l‚Äôoutcome di un evento, alla probabilit√† dell‚Äôevento.\nDefinizione VA üü© Si definisce variabile aleatoria $X$ una funzione da $\\Omega \\to E$, con Omega il nostro spazio campionario, e $E$ qualunque insieme (quando $E = \\mathbb{R}$ si parla di variabile aleatoria reale","title":"Variabili aleatorie"},{"content":"Scalare Scalare e gradiente üü© Un campo scalare assegna a ogni punto dello spazio un valore reale, quindi √® naturalmente rappresentabile tramite una funzione $$ \\varphi(x, y, z) : \\mathbb{R}^{3} \\to \\mathbb{R} $$ Un esempio abbastanza naturale √® il gradiente del valore scalare che si indica con $$\\vec{\\nabla}\\varphi = ( \\frac{\\delta\\varphi}{\\delta x}, \\frac{\\delta\\varphi}{\\delta y}, \\frac{\\delta\\varphi}{\\delta z}) = \\frac{\\delta\\varphi}{\\delta x} \\hat{i} + \\frac{\\delta\\varphi}{\\delta y} \\hat{j} + \\frac{\\delta\\varphi}{\\delta z} \\hat{k}$$ Se consideriamo il gradiente da solo √® un campo vettoriale (dice la direzione della derivata multidimensionale).\nGradiente in coordinate polari üü® Questo √® un po\u0026rsquo; pi√π difficile da gestire, per√≤ √® abbastanza facile una volta che si fanno certe osservazioni. Sappiamo che $dV = \\vec{\\nabla} V \\cdot d\\vec{s}$, TODO: finire la dimostrazione, √® descritta bene a pagina 47 del mazzoldi.\nComunque si finisce con\n$$ \\vec{\\nabla} = \\frac{\\delta}{\\delta r} u_{r} + \\frac{1}{r}\\frac{\\delta}{\\delta \\theta}u_{\\theta} + \\frac{1}{r\\sin \\theta}u_{\\phi} $$ A volte questo pu√≤ risultare utile se proviamo a fare cose come calcolare il campo elettrico attraverso il gradiente.\nNOTA: la divergenza per√≤ assume una forma diversa, che non so bene spiegare il motivo in questo momento per√≤.\nGradiente in coordinate cilindriche $$ \\vec{\\nabla} = \\frac{\\delta}{\\delta r} u_{r} + \\frac{1}{r}\\frac{\\delta}{\\delta \\theta}u_{\\theta} + \\frac{\\delta}{\\delta \\phi}u_{\\phi} $$ Vettoriale Superfice di separazione üü© Per la definizione di questo, √® chiaro che il flusso su una superficie di separazione √® nulla, quindi posso dividere superfici come mi pare internamente, tanto su queste √® nulla, o posso considerare solamente la superficie pi√π esterna che li racchiude (√® nulla perch√© avr√≤ due versioni uguali e contrarie).\nTODO: scrivere il ragionamento in formule\nIntegrale per un campo: teorema del gradiente üü®++ In analisi abbiamo studiato il teorema di torricelli, ma possiamo estenderlo senza troppa fatica (almeno intuitivamente), nel caso in pi√π dimensioni!\ntorricelli ci dice che (mettere condizioni qui di esistenza integrale) $f(B) - f(A) = \\int _{A}^{B} f'(x) \\, dx$, Poniamo il concetto di differenziale ossia piccolo rettangolino nell\u0026rsquo;integrale di rieman come $df = f'dx$, attraverso questo abuso di notazione, allora diventa molto naturale estenderlo nelle 3 dimensioni come $d\\varphi(x, y, z) = \\vec{\\nabla}\\varphi \\cdot d\\vec{l}$ usando il prodotto scalare, in pratica ho il prodotto scalare amplificato per quello che mi serve. Allora diventa intuitivo che nel caso tridimensionale l\u0026rsquo;integrale sia\n$$ \\varphi(B) - \\varphi(A) = \\int _{A}^{B} \\vec{\\nabla}\\varphi \\cdot d\\vec{l} $$ √à da notare che nel nostro caso, se abbiamo un campo conservativo, questo integrale √® dipendente solamente da inizio e fine, non dipende dal percorso, il che implica che il campo √® conservativo.\nTeorema della divergenza (!!) üü©- Dal ragionamento precedente abbiamo capito che potrei dividere la superficie con quante superfici di separazione mi pare, tanto il flusso esterno non cambia, questo mi permette di dividere in tanti volumetti e cercare il flusso con questi volumetti\n$$ \\phi_{s}(\\vec{F}) = \\sum_{i=1}^{N} V_{i} \\frac{\\oint_{\\Sigma} \\vec{F} \\cdot dS_{i}}{V_{i}} $$ Andiamo a chiamare la seconda parte la divergenza di F, e sar√† il flusso per unit√† di volume, vedremo che questa sar√† strettamente vicina al significato di gradiente indicato con nabla. Dato che sto considerando piccolissimi volumi, se la Divergenza √® positiva, significa che c\u0026rsquo;√® del flusso che esce da quel punto si dice che sono delle sorgenti, perch√© generano campo, e solitamente queste sono punti in cui le linee di campo si incontrano. Quando √® uguale a 0 non si dovrebbero incontrare\nEnunciato in modo corretto il teorema afferma: $$ \\phi_{S \\text{ chiusa}} = \\oint_{S} \\vec{F} \\cdot d\\vec{s} = \\iiint_{V}(div \\vec{F}) \\, dV = \\iiint_{V} \\vec{\\nabla} \\cdot \\vec{F} \\, dV $$ Che ha il bel risultato di rendere un integrale di superficie (2 dimensioni) come se fosse un integrale di volume. Assumendo il risultato descritto in #Superfice di separazione diventa banale per√≤.\nOsservazione: la divergenza prende in input un campo vettoriale, in output restituisce un campo scalare (che si potrebbe interpretare quasi fosse il modulo del vettore di derivata, con il gradiente ancora scalare).\nOsservazione: questa forma diventa molto pi√π intuitiva se direttamente andiamo a parlare di cubi infinitesimali (Mencuccini spiega per benino sta parte diciamo e arriva subito al risultato, senza passare per il discorso che non ho capito bene sul flusso in una qualunque forma infinitesimale).\nRelazione divergenza e intuizione divergenza (!) üü©+ si avr√† che $$ \\frac{\\oint_{\\Sigma} \\vec{F} \\cdot dS}{dV} = div \\vec{F} = \\text{per il teorema che verr√† dimostrato} = \\vec{\\nabla} \\cdot \\vec{F} $$ A parole: il flusso per unit√† di volume del nostro campo √® uguale al gradiente del campo stesso.\nUn modo molto pi√π semplice per dimostrare questo, assumendo gi√† di avere fatto la cosa del cubo √® notare questo $$ d\\phi = \\vec{\\nabla}\\cdot \\vec{E} d\\tau \\implies \\vec{\\nabla}\\cdot \\vec{E} = \\frac{d\\phi}{d\\tau} $$ E nella seconda parte abbiamo esattamente il flusso per cubo infinitesimo.\nHint di dimostrazione Mi definisco un cubo, e poi provo ad analizzare il flusso per ogni 6 lato, provo a porre un cubo infinitesimo, e dovrebbe poi tornare Mencuccini pagina 29 √® presente, sul Mazzoldi lo trovi a pagina 79.\nCircuitazione Intuizione di circuitazione e th separazione üü© In questa parte qui ci chiediamo il flusso lungo una linea CHIUSA. Probabilmente sar√† utile per leggi come Lenz o Faraday. Anche in questo caso non ha senso considerare linee di separazione, perch√© avendo direzioni diverse si annullano. (guarda #Superfice di separazione descritto in precedenza.\nDefinizione di circuitazione $$ \\Gamma = \\oint_{L} \\vec{F} \\cdot d\\vec{l} $$ Che possiamo notare essere una forma molto molto simile rispetto a quanto definito per il flusso #Flusso di campo vettoriale.\nPosso fare un giochino (esattamente uguale a quello fatto in precedenza per la divergenza), ma lo faccio per piccole superfici, e flusso che gira attorno a quella superficie allora posso andare a definire il rotore\nIl rotore e teorema di stokes üü©- Dividiamo tutta la nostra superficie con percorso chiuso in un sacco di piccoli pezzettini: $$ \\Gamma_{L} = \\sum_{i=1}^{N} \\oint_{L_{i}} \\vec{F} \\cdot d\\vec{l_{i}} = \\sum_{i=1}^{N} \\frac{ \\oint_{L_{i}} \\vec{F} \\cdot d\\vec{l_{i}}}{S_{i}} S_{i} $$ Allora definisco rotore questo: $$\\frac{ \\oint_{L_{i}} \\vec{F} \\cdot d\\vec{l_{i}}}{s_{i}} = \\vec{rot} \\vec{F} \\cdot \\hat{n} $$ Che intuitivamente √® la circuitazione infinitesimale.\nQuesto √® fatto a pagina 52\nTeorema di stokes Da questo ragionamento possiamo osservare che la circuitazione (che √® anche il lavoro si potrebbe dire) si pu√≤ esprimere come il rotore. $$ \\oint \\vec{F} \\cdot d\\vec{l} = \\iint_{S_{L}} \\vec{rot} \\vec{F} \\cdot \\hat{n} \\, ds $$ Questo √® il teorema di stokes, e si pu√≤ applicare per qualsiasi circuitazione, per qualsiasi superficie che ha come contorno alla fine L.\nRotore dimostrazione üü© In questa parte proviamo ad esplorare la relazione che c\u0026rsquo;√® fra il rotore, come l\u0026rsquo;abbiamo definito di sopra, e la divergenza.\nConsideriamo un problema come in immagine Vogliamo cerca di definire la circuitazione, proviamo ad applicare proprio la definizione, quindi abbiamo che $$ \\oint \\vec{F} \\cdot d\\vec{l} = \\int _{A}^{B}F(x, y_{0}) \\, dx + \\int _{B}^{C}F(x_{0} + \\Delta x, y) \\, dy + \\int _{C}^{D}F(x, y_{0} + \\Delta y) \\, dx + \\int _{D}^{A}F(x_{0}, y) \\, dy $$ Supponiamo che la nostra funzione sia continua, quindi abbiamo che $\\exists c : \\int _{A}^{B}F(x, y_{0}) \\, dx = (B - A)F(c, y_{0}) = \\Delta xF(c, y_{0})$, questa cosa si pu√≤ utilizzare per ogni singolo addendo della precedente, e scritto facendo in modo da contare anche le direzioni abbiamo che: $$ \\oint \\vec{F} \\cdot d\\vec{l} = \\Delta x F(\\hat{x}, y_{0}) + \\Delta y F(x_{0} +\\Delta x, \\hat{y}) - \\Delta x F(\\hat{x}, y_{0} + \\Delta y) - \\Delta y F(x_{0}, \\hat{y}) $$ Raccogliendo il delta e facendo tendere sia $x$ che $y$ a 0, possiamo scrivere una cosa del genere: $$ \\Gamma = -\\Delta x \\left[ \\frac{\\delta F_{x}}{\\delta y} \\Delta y \\right] + \\Delta y \\left[ \\frac{\\delta F_{y}}{\\delta x} \\Delta x \\right] \\implies \\Delta x\\Delta y \\left( \\frac{\\delta F_{y}}{\\delta x} - \\frac{\\delta F_{x}}{\\delta y} \\right) $$ Si pu√≤ notare che se intendiamo questo come sopra, durante la dimostrazione per il #Teorema di stokes, allora $\\Delta x \\Delta y$ √® esattamente la superficie, orientata secondo $\\hat{n}$, mentre, proprio per matching dei parametri, il rotore diventa $rot \\vec{F} = \\left( \\frac{\\delta F_{y}}{\\delta x} - \\frac{\\delta F_{x}}{\\delta y} \\right)$ in questo caso, si potrebbe dire da un punto di vista a tre dimensioni, se avessimo il nostro quadratino in pi√π dimensioni allora che\n$$ \\vec{rot}\\vec{F} = \\left( \\frac{\\delta F_{z}}{\\delta y} - \\frac{\\delta F_{y}}{\\delta z} \\right) \\hat{i} + \\left( \\frac{\\delta F_{x}}{\\delta z} - \\frac{\\delta F_{z}}{\\delta x} \\right) \\hat{j} + \\left( \\frac{\\delta F_{y}}{\\delta x} - \\frac{\\delta F_{x}}{\\delta y} \\right) \\hat{z} = \\vec{\\nabla} \\times \\vec{F} $$ Si pu√≤ notare che questo √® strettamente legato al concetto di velocit√† angolare.\nDivergenza del rotore (!) üü© Una volta espresso il rotore matematicamente come in precedenza (e sapendo anche il suo significato intuitivo di circuitazione per superficie), allora possiamo andare a fare cose interessanti come la divergenza che mi va a creare il rotore, ed √® molto particolare come i calcoli portano poi alla fine ad affermare che $$ \\oint_{S} (\\vec{\\nabla} \\times \\vec{F}) d\\vec{s} = \\iiint_{V} div (\\vec{\\nabla} \\times \\vec{F}) d\\vec{s} = \\iiint_{V} \\vec{\\nabla} \\cdot (\\vec{\\nabla} \\times \\vec{F}) d\\vec{s} = 0 $$ L\u0026rsquo;ultima uguaglianza lo abbiamo per cauchy, perch√© avremo delle derivate seconde, che si eliminano tutte fra di loro\nFisicamente forse mi sta dicendo che il rotore non crea flusso.\nNote sul gradiente Per qualche motivo √® vero questa cosa:\n$$ dV = \\frac{\\delta V}{\\delta x}dx + \\frac{\\delta V}{\\delta y}dy + \\frac{\\delta V}{\\delta z}dz $$ Questo √® un risultato ovvio (che non so perch√© √® ovvio, ma chatGPT https://chat.openai.com/share/c40e539d-9dd2-4bf7-b63d-2fc402751929) e altre ricerche sembrano dire questo del teorema del differenziale totale (che sembra se cercato in inglese ha significato giusto, in italiano diverso boh https://en.wikipedia.org/wiki/Total_derivative).\nComunque √® la base matematica per poter utilizzare il gradiente e scrivere cose come\n$$ dV = \\nabla V \\cdot ds $$ Dove $ds = u_{x}dx + u_{y}dy + u_{z}dz$\n","permalink":"https://flecart.github.io/notes/divergenza-e-circuitazione/","summary":"Scalare Scalare e gradiente üü© Un campo scalare assegna a ogni punto dello spazio un valore reale, quindi √® naturalmente rappresentabile tramite una funzione $$ \\varphi(x, y, z) : \\mathbb{R}^{3} \\to \\mathbb{R} $$ Un esempio abbastanza naturale √® il gradiente del valore scalare che si indica con $$\\vec{\\nabla}\\varphi = ( \\frac{\\delta\\varphi}{\\delta x}, \\frac{\\delta\\varphi}{\\delta y}, \\frac{\\delta\\varphi}{\\delta z}) = \\frac{\\delta\\varphi}{\\delta x} \\hat{i} + \\frac{\\delta\\varphi}{\\delta y} \\hat{j} + \\frac{\\delta\\varphi}{\\delta z} \\hat{k}$$ Se consideriamo il gradiente da solo √® un campo vettoriale (dice la direzione della derivata multidimensionale).","title":"Divergenza e Circuitazione"},{"content":"√à una branca dell\u0026rsquo;algebra lineare che ci permette di semplificare tutti i concetti.\nIntro dualit√†üü© \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Programmazione lineare/Untitled 8.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Programmazione lineare/Untitled 8\u0026quot;\u0026gt; Si fa una sorta di trasposta alla matrice di A. y √® pari al numero di righe di A La trasformazione al duale √® molto facile, ed √® abbastanza intuitiva una volta che capiamo che vogliamo andare a fare l‚Äôupper bound.\nDualit√† asimmetrica üü•+ Teorema debole di dualit√† üü© Slide\nQui c\u0026rsquo;√® una cosa simile a quanto fatto in MCMF, il cui massimo di x √® boundato dal minimo del suo duale, in Tarjan e MCMF.\nCorollari di dualit√† (2) üü© Slide\nil fatto che ci sia un bound a x, implica che se x √® illimitato, non posso avere il bound! Abbiamo una condizione di ottimalit√† delle soluzioni trovate! Def Direzioni ammissibili Vogliamo trovare un modo per muoverci e trovare ancora una direzione ottimale!\nDef: un vettore $\\varepsilon \\in \\mathbb{R} ^n$ √® una direzione ammissibile se esiste $\\bar{\\lambda} \u003e 0$ tale che $x(\\lambda) = x + \\lambda \\varepsilon$, per ogni $\\lambda \\in 0...\\bar{\\lambda}$\nIntuizione Ossia se possiamo spostarci di almeno un p√≤ verso la direzione che vogliamo!\nDef direzione di crescita Possiamo considerare una direzione di crescita $\\lambda \\iff cx(\\lambda) = c \\bar{x} + \\lambda c\\varepsilon \u003e c \\bar{x} \\iff c\\varepsilon \u003e 0$\nLa cosa interessante √® che una direzione di crescita cresce indipendentemente dal punto, questo √® una propriet√† molto forte della programmazione lineare! Questi due concetti sono molto utili perch√© una volta che abbiamo una direzione ammissibile e di crescita allora si pu√≤ verificare che si pu√≤ migliorare ancora la soluzione di x.\nSuff e nec per direzione ammissibile Slide L\u0026rsquo;idea principale per questa dimostrazione √® sui vincoli attivi, differenziare se una riga √® un vincolo attivo o meno. Se lo √® allora voglio che sia minore, altrimeni basta scegliere un intorno sufficientemente piccolo perch√© il vincolo √® stretto.\nDa notare che se non √® un vincolo attivo allora ho una disuguaglianza stretta allora posso andare ad utilizzare cose di analisi\nOttimalit√† del punto Dato un punto $x$ ammissibile, questo punto √® ottimo sse non ci sono direzioni di crescita ammisibile\nIntuizione sulla dimo\n‚Üí se √® gi√† ottimo allora se esistessa una direzione di crescita, si potrebbe far crescere ancora il nostro punto di ottimo, violando l‚Äôipotesi di ottimalit√†\n‚ÜêSe non ho direzioni di crescita, supponendo per assurdo che non sia ottimo abbiamo allora possiamo trovare una direzione di crescita ammissibile, creando un assurdo, questa direzione la andiamo a trovare prendendo un punto ottimo e creando il vettore da questo punto a quello nostro iniziale.\nDimostrazione dispense\n!\nLegendre Transform This is also known as Conjugate function in Analisi di Convessit√†#Conjugate function.\nGiven a convex function $f$ the Legendre transform of this function $f$ is the function $$ g(p) = \\sup_{p} \\left( px - f(x) \\right) $$ This is used in Lagrangian Mechanics for the Eulero Lagrange, and one can see that its dual is the Hamiltonian Mechanics (but need to verify wait).\nThis has an easy geometrical interpretation, is just the maximum distance between the family of the lines through origin to a point of the function that is under the line. First image is the intuition of the Legendre transform (the straight line and the convex shape), the second image represents how an angle is converted to a segment thanks to this transform.\nWe note that $p = f'(x)$ because that is an extremum, this will be useful when we prove the involutivity.\nExamples of Legendre transforms One can see that $f(x) = x^{2}$ has $g(p) = \\frac{1}{4}p^{2}$ as dual. $f(x) = \\frac{mx^{2}}{2}$ has as dual $g(p) = \\frac{p^{2}}{2m}$ $f(x) = \\frac{x^{\\alpha}}{\\alpha}$ has as dual $g(p) = \\frac{p^{\\beta}}{\\beta}$ where $\\frac{1}{\\alpha} + \\frac{1}{\\beta} = 1$.\nYou got the Idea.\nInvolutive property The involutive property asserts that applying the Legendre transform twice gives back the original function.\nIf we set $G(x, p) = xp - g(p)$ we have by definition of $g(p)$ that $G(x, p) = f(x)$, we still need to prove that this is the maximum possible, so that we know that this is indeed the transform.\nWe can have an easy interpretation of reapplying this operator: we can observe that $xp$ is the line passing through the origin, and $g(p)$ is the distance to a point of the $f(x)$ and we know that this point is tangent. It is easy to observe that this point is exactly the $y$ of the point of $f(x)$ for a fixed $x$.\nYoung Duality We say the $f, g$ that are one the Legendre Transform of the other are duals following Young\u0026rsquo;s definition. We have that $F(x, p) = px - f(x) \\leq g(p)$ because $g(p)$ is the supremum. This follows that $px \\leq f(x) +g(p)$ in any case.\nAM-GM application We can prove the classical AM-GM inequality in this way, by setting $f(x) = \\frac{x^{2}}{2}$ and $g(p) = \\frac{p^{2}}{2}$ we have that $px \\leq \\frac{x^{2}}{2} + \\frac{p^{2}}{2}$.\nSimilarly we can prove that $$ px \\leq \\frac{x^{\\alpha}}{\\alpha} + \\frac{p^{\\beta}}{\\beta} $$ Where $\\frac{1}{\\alpha} + \\frac{1}{\\beta} = 1$ is valid.\nMulti-variable Legendre Given a convex function $f(x)$ (If you don\u0026rsquo;t remember see convexity), meaning that the input is a vector $(x_{1}, \\dots, x_{n})$ and the quadratic form $\\left\\langle \\frac{ \\partial^{2} f }{ \\partial x^{2} }dx, dx \\right\\rangle$ is positive definite (see Massimi minimi multi-variabile for positive definite matrices) then the Legendre transform is a function $g(\\vec{p})$ where $\\vec{p} = \\left( p_{1}, \\dots, p_{n} \\right)$ such that everything done for the single case is valid: $$ F(\\vec{p}, x(\\vec{p})) = max_{x}F(\\vec{p}, \\vec{x}), F(\\vec{p}, \\vec{x}) = (\\vec{p}\\cdot \\vec{x} ) - f(\\vec{x}), \\vec{p} = \\frac{ \\partial f }{ \\partial \\vec{x} } $$ Every result of the above is still valid in this case.\nCoincidence of specific points We can prove that given $f(x)$ and his Legendre transform $g(p)$ then we have that $f(x) = g(p)$, which has a geometrical interpretation that $f(x)$ divides the straight line with a fixed $x$ from the $y=0$ to $y=px$ in half.\nThis proof is easy for the Euler\u0026rsquo;s lemma on homogeneous functions which states that $$ \\frac{ \\partial f }{ \\partial x } x = 2f $$ Which this in mind we can just do the following: $$ g(p(x)) = px - f(x) = \\frac{ \\partial f }{ \\partial x } x - f = 2f(x) - f(x) = f(x) $$ This will allow us to prove some relation between Lagrangian Mechanics and Hamiltonian Mechanics. In particular that $H = p\\dot{q} - L = 2T - (T - U) = T + U$.\nThe Lagrangian Moved to Lagrange Multipliers.\n","permalink":"https://flecart.github.io/notes/duality-theory/","summary":"√à una branca dell\u0026rsquo;algebra lineare che ci permette di semplificare tutti i concetti.\nIntro dualit√†üü© \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Programmazione lineare/Untitled 8.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Programmazione lineare/Untitled 8\u0026quot;\u0026gt; Si fa una sorta di trasposta alla matrice di A. y √® pari al numero di righe di A La trasformazione al duale √® molto facile, ed √® abbastanza intuitiva una volta che capiamo che vogliamo andare a fare l‚Äôupper bound.\nDualit√† asimmetrica üü•+ Teorema debole di dualit√† üü© Slide","title":"Duality Theory"},{"content":"Introduction Capire in che modo una rete convoluzionale ci pu√≤ dare insight migliori su come funzionano questi networks.\nVisualizzazione dei hidden layers Slide visualization\nPotremmo fissare una immagine anche a caso, e modificare la x in modo che sia pi√π simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa.\nForse questo √® anche il metodo con cui vengono generate le immagini??\nExamples of extracted patterns\nProbabilmente tutte le CNN vanno quindi a tentare ad estrarre questo genere di patterns dall‚Äôimmagine iniziale.\nRicreazione di immagini Vogliamo computare la rappresentazione interna dell‚Äôimmagine, ossia l‚Äôattivazione prodotta da una certa immagine, e da questo possiamo sintetizzare una immagine e poi continuare a fare gradient descent su questa per massimizzare. Una volta al minimo dovremmo avere l‚Äôimmagine migliore per questo layer.\nSlide di esempio\nPer un certo layer non c‚Äô√® differenza fra quei 6 immagini\nQuindi prima partivamo da noise, da questo partiamo da una immagine gi√† e guardiamo in che modo √® rappresentato in questo layer.\nSlide sulla tecnica di solito utilizzata per queste\nSi pu√≤notare che √® pi√π difficile recovery dell‚Äôimmagine nei layers lontani, probabilmente perch√© sta creando una specie di astrazione dell‚Äôimmagine iniziale, quindi l‚Äôimmagine sarebbe l‚Äôimmagine dell‚Äôastrazione. Riusciamo a visualizzare una astrazione, che sembra una contraddizione.\nInceptionism Style transfer Come facciamo a ricreare una immagine utilizzando lo stile di un certo autore?\nEsempi di risultati con style transfer\nMa come facciamo a catturare un concetto astratto di stile di un certo autore?\nConcetto di stile di un autore Non vogliamo solamente avere un contenuto simile (come abbiamo fatto prima, nei primi layers √® una cosa abbastanza semplice) vorremmo proprio essere in grado di catturare lo stile dell‚Äôartista. Quindi da un punto di vista astratto\nSlides stile autore\nCi interessa la correlazione fra features maps di un certo livello, e quando abbiamo una immagine vogliamo allenare per massimizzare la similitudine con la correlazione fra le feature maps.\nData manifolds perch√© facile ingannare le reti Si pu√≤ vedere che con le tecniche dello stile si possono ingannare molto facilmente le reti di sopra. Questo √® perch√© fanno delle classificazioni, fanno discriminazione anzich√© generazione. Ossia con generazione provo a stimare la probabilit√† iniziale che si sia creato la cosa che vogliamo classficiare e con questa probabilit√† poi andiamo a fare la predizione.\nInvece nelle tecniche discriminazione vanno solamente a fare una discriminazione di dati, una cosa statistica. (la frontiera pu√≤ essere molto diversa rispetto alla funzione che lo ha generata diciamo.\nSeguendo comunque il ragionamento sui manifolds di data possiamo dire che √® molto improbabile ~0, che generando a caso, sia una immagine sensata. Infatti lo spazio delle immagini √® enorme, la maggior parte sono ranodm per umani, per√≤ stiamo provando a fare questo un modello di discriminazione (quindi √® chiaro che molte zone che per noi non hanno senso, sono rappresentate nella rete neurale come categorizzate in un certo modo).\nAutoencoders Vogliamo cercare di cambiare lo spazio in modo che la parte delle immagini sensate sia meglio descrivibile, vogliamo andare in pratica a creare una descrizione compatta di quello che vogliamo analizzare. Con gli autoencoder andremo proprio a comprimere il data manifold e poi lavorare su questa compressione.\nSlide intuizione autoencoder\nQuello che vorremmo fare √® una funzione identit√† per certe cose (dato che sono meno, non possiamo fare altro che perdere altre informazioni, ma vogliamo solamente perdere informazioni che non ci servano).\nPossiblit√† della compressione\nLa compressione dovrebbe essere possibile perch√© stiamo cercando regolarit√† nel data, cosa che ci dovrebbe essere perch√© noi umani riusciamo a riconoscere questi pattern, non riusciamo ad insegnarlo ad una macchina. (quando √® molto random per√≤ non si pu√≤ comprimere, stranamente il random √® la cosa con pi√π informazione in termini di teoria dell‚Äôinformazione, ma meno informazione per noi umani, che strana questa asimmetria).\nCaratteristiche della compressione\nSlide caratteristiche\nLa cosa di maggior rilievo √® il fatto del loss, che non riusciamo a fare un reverse che diventi proprio uguale! E poi funziona solamente con data simili (con caratteristiche fortemente correlate fra di loro.\n","permalink":"https://flecart.github.io/notes/explainability-of-cnn/","summary":"Introduction Capire in che modo una rete convoluzionale ci pu√≤ dare insight migliori su come funzionano questi networks.\nVisualizzazione dei hidden layers Slide visualization\nPotremmo fissare una immagine anche a caso, e modificare la x in modo che sia pi√π simile a quanto vuole computare il neurone. In questo modo genero una immagine che generi una activation forte nel neuron trainato, e si potrebbe dire che sia il genere di immagine che viene generata da essa.","title":"Explainability of CNN"},{"content":"Note: Questo corso √® troppo astratto. Pi√π che probabilit√† tratta di teoria della Misura. Quindi affossato‚Ä¶\nLink della serie: https://www.youtube.com/watch?v=172m7qVy_FQ\u0026amp;list=PLrb6X_RiBI94b6dzCx-QwM-r0aZpJyPxS\nCampo (di probabilit√†) Nota:\n2 e 3 ‚áí 4\n2 e 4 ‚áí 3\nQuindi 3 e 4 sono interscambiabili, e si potrebbe eliminare uno dei due.\nAnche il fatto che il vuoto sia presente in F si pu√≤ omettere. combinando 1 e 2 ottengo il vuoto (complementare dell‚Äôinsieme che prenda tutto).\nNOTA: SIGMA FIELDS se soddisfa il criterio sotto al 4.\nNOTA: per insiemi finiti sigma-f = f\nEsempi:\nSono tutti dei $\\sigma -fields$\nL‚Äôultimo caso √® difficile da descrivere‚Ä¶ Devi utilizzare demorgan.\nLemma intersezioni di sigma-fields Ossia da verificare i 3 punti per dire che √® un sigma field\nSigma fields generated by sets Si pu√≤ vedere che questo field sono sempre presenti $\\Omega$ e vuoto. e per il lemma precedente tutti i Sigma-fields che hanno $\\epsilon$ √® un sigma field.\nDimostrazione costruttiva\nDobbiamo ora dimostrare che sia unico. (si pu√≤ dire che l‚Äôintersezione sia unica??? se s√¨ allora ez).\nEsercizio\nBorel sigma-field NOTA: intersezione di invervalli aperti pu√≤ comportare un intervallo semi aperto (eg $1/n$ e -1, questi l‚Äôintersezione infinita di questi intervalli √® $(-1, 0]$\nBorel Field Riusciamo a dare una struttura sul campo di Borel, riuscendo in questo passo a dimostrare che l‚Äôinsieme cos√¨ costruito non √® altro che l‚Äôinsieme di Borel.\nSemi-algebra di insiemi Proof\nFinitevely additive measures and semi-algebras Stieltjes (pre_measures) on Borel sets R Main observation:\nMeasure space Examples\nSet of measure functions Example\n3 basic properties of Measures Premeasure, finitely-additive Measures) Motivazione √à difficile costruire delle misure complete su $\\sigma$ fields, soprattutto se √® un campo non numerabile. Per questo motivo vorremmo utilizzare nozioni pi√π deboli di misura e da quelle estenderle anche a questi campi, pi√π difficili da trattare. Quindi andiamo a costruire pre-misure e finitely-additive measures. QUesta sezione √® II, 5.2.1 nel driver del corso su youtube.\nDefinizione: Una coppia $\\Omega, \\mathcal{A}$ √® uno spazio di pre-misura se $\\mathcal{A}$ √® un campo su $\\Omega$. (non abbiamo pi√π bisogno che sia un $\\sigma$ campo), solo che sia chiuso sotto unione e differenza.\nUna funzione countably additive (Ossia che valga che $\\left\\{ E_{i} \\right\\}_{i=1}^{\\infty} \\in \\mathcal{A} : \\cup_{i=1}^{\\infty}E_{i} = E \\in \\mathcal{A} \\implies \\mu(E) = \\sum_{i=1}^{\\infty}\\mu(E_{i})$$\\mu: \\mathcal{A} \\to [0, \\infty]$) √® una premisura Se assumiamo che $\\mu$ sia solamente finitely-additive allora la chiamiamo finitely-additive measure.\nPer fare una pre-misura basta un campo, non un sigma-campo, quindi √® molto pi√π facile da costruire.\nF-A measures is premeasure iff countably sub-additive Questo permette di passare da finitely-additive measures a pre-misure senza troppi intoppi.\nProof\nStiljes premeasure on borel field Proof\nMeasure extension Theorem Sigma finite\nEsempio quelle di probabilit√† che sono sempre finite\nExample non-uniqueness of extensions(not done, ma esistono se non √® sigma finito)\nCarath√©odor√Ωs Extension Cose da provare\nProof\nOuter measures Abbiamo visto alcune propriet√† importanti da dover verificare per la dimostrazione che $\\rho*$ sia una misura, queste caratteristiche si possono estendere per qualunque cosa quindi ha senso definire una altra misura in questo senso:\nSu caratheodory\nOgni misura $v$ che estende la premisura $\\mu$ vale che $v \\leq \\mu *\\, su \\, \\sigma(A)$ (largest extension)\nOther OuterMeasure properties with premeasure spaces\n","permalink":"https://flecart.github.io/notes/introduzione-alla-probabilita/","summary":"Note: Questo corso √® troppo astratto. Pi√π che probabilit√† tratta di teoria della Misura. Quindi affossato‚Ä¶\nLink della serie: https://www.youtube.com/watch?v=172m7qVy_FQ\u0026amp;list=PLrb6X_RiBI94b6dzCx-QwM-r0aZpJyPxS\nCampo (di probabilit√†) Nota:\n2 e 3 ‚áí 4\n2 e 4 ‚áí 3\nQuindi 3 e 4 sono interscambiabili, e si potrebbe eliminare uno dei due.\nAnche il fatto che il vuoto sia presente in F si pu√≤ omettere. combinando 1 e 2 ottengo il vuoto (complementare dell‚Äôinsieme che prenda tutto).","title":"Introduzione alla probabilita"},{"content":"Livello di trasporto Si parla di livello logico di trasporto, ma gran parte ne abbiamo gi√† parlato in Livello applicazione e socket di UDP, TCP e Socket. trasporto end-to-end, nel senso che livello traporto viene visto solamente ad inizio e alla fine, in tutti i nodi intermedi non √® visto sto pacchetto.\nUDP (3) üü©- Slide UDP\nClassico inizio e fine porta del socket. Lunghezza, si pu√≤ vedere che massimo √® 2 alla 16, e poi il checksum per vedere se √® comunicato bene. 8 byte di header, quindi molto efficiente! Sposto a livello applicazione il check al mancato pacchetto. (esempio DNS) Oppure casi in cui perdere pacchetti non √® molto importante. CARATTERISTICHE UDP\nNessun controllo del flow, senza handshake, e per questo motivo possiamo dire che non sia connection oriented (l\u0026rsquo;affidabilit√† della connessione pu√≤ essere spostata al livello superiore) Stateless Velocit√† di invio, 8 byte di overhead contro i 20 di TCP Per maggiori informazioni e confronto con TCP (il fatto di connectionless etc) guardare Intro TCP (3) e UPD üü©.\nTCP struttura pacchetto üü© In cui c\u0026rsquo;√® molto di pi√π.\nTCP segment structure\nLa nota importante oltre le flag, e altre cose √®\nAcknoledgement del pacchetto precedente √® messo nell‚Äôheader! Internet checksum üü© Slide internet checksum\nStile dell‚Äôalgoritmo:\nIncolonnati a 16 bit, faccio la somma di tutit i bit. Somma del riporto wraparound. Complemento a uno del risultato precedente Si ricordi che questo √® un metodo utile per capire se ci sono errori di trasmissione, ma non √® molto buono per difendersi da attacchi umani.\nCostruzione protocollo di trasporto reliable Vogliamo cercare di costruire un protocollo ground up, cio√® assumento piano piano, errore per errore e fixare ogni errore.\nAlla fine il protocollo cos√¨ creato sar√†\nAffidabilit√† del trasferimento di dati Vorremo creare l‚Äôequivalente di un canale di strasferimento affidabile, cosa che non √® internet, quindi vogliamo aggiungere altre cose per rendere questa interfaccia:\nSlide RDT (Reliable data transfer)\nPermetto di creare interfaccie come\nrdt_send() udt_send() unreliable data transfer, che √® quello offerto dalla rete. Stessa cosa per il lato di ricezione, ricevo da cosa unreliable, processo e li passo sopra.\nEsempi sono numerazione di pacchetti e resend di pacchetti chei non sono stati ricevuti, questi sono modi per rendere affidabili.\nPasso passo, 3 problemi Resistente alla corruzione dei pacchetti Corruzione dei pacchetti ACK Resistente alla perdita di pacchetti RETE RELIABLE\nSlide rete reliable\n√à la cosa pi√π stupida, si assume subito che sia reliable\nRETE CORRUTTIBILE\nSi utilizza un sistema ACK, NACK per vedere se arriva o meno il pacchetto\nSlide rete corruttibile\nSe dal lato ricevente, viene inviato il messaggio che √® arrivato sbagliato.\nCORRUZIONE DEI NAK e ACK\nChe succede con l‚Äôesempio sopra se si possono corrompere anche ACK e NACK? Facciamo ack e nack sui numeri pacchetto!\nSlide ack e nak\nSENZA NAK\nSlide senza nak\nBasta mandare l\u0026rsquo;ack al pacchetto corretto! Non abbiamo pi√π bisogno che si mandi nak quando arriva il pacchetto brutto.\nPERDITA DI PACCHETTI\nIn questo caso includiamoil timeout.\nSlide timing\nEsempio di rdt3 in azione\nANALISI DELLE PERFORMANCE\nSlide performance rdt3.0\nSi pu√≤ notare che l\u0026rsquo;utilizzo della rete √® pochissimo! 0.027 % di utilizzo in questa analisi.\nDovremo cercare di parallellizzare il processo utilizzato per mandare e riceve\nPipelining (2) üü©‚Äî √à un metodo per mandare pi√π pacchetti contemporaneamente.\nCi sono due metodologie principalemente, go back N, selective repeat.\nPipelined protocols\nGO BACK N\nSignifica che con gli ultimi n ack sono stati ricdevuti correttamente, quindi col singolo ack, mi dice da dove posso cominciare a ripartire a mandare. Ma manda un sacco di pacchetti, quindi pu√≤ congestionare la rete, con il vantaggio che non mi devo memorizzare.\nAutoma Go back N (NON FARE)\nEsempio di GBN\nil destinatario non deve memorizzare nel buffer i pacchetti che giungono fuori sequenza. (risparmio in memoria)\nMaggiore onere alla rete, che deve ritrasmettere alcuni pacchetti anche se vengono ricevuti correttamente.\nSELECTIVE REPEAT\nPerch√© ti faccio ripetere in modo selettivo.\nMeno lavoro dei router Overhead maggiore per i RTT per gli ACK, cosa che alla fine rallenta la prestazione della rete. Pi√π memoria per mantenere tempi per tutti i pacchetti. Approfondimento TCP TCP trip time Slides\nSi utilizza una tecnica di media esponenziale presente anche in Scheduler ma qui facciamo anche un safety margin per essere sicuri e molto conservativi parti a 4 deviazioni (quindi molto! affinch√© scada deve succedere veramente qualcosa di brutto).\nAck e numeri di sequenza (no) üü© Il libro dice che in fase di handshaking vengono stabiliti numeri di sequenza random, questo per evitare il fatto che lo 0 rappresenti una nuova sequenza, se in precedenza si √® gi√† connessi.\nPoi cosa, TCP utilizza un ack cumulativo, sul numero di byte, e il numero di sequenza √® sempre fatto sul numero di byte inviati e ricevuti.\nNOTA: grandezza della finestra pipelining e il numero di sequenza, si osservi che se abbiamo troppi pochi numeri di sequenza, allora potremmo conseguire nell‚Äôambiguit√† del fatto che un pacchetto non si pu√≤ distinguere se sia un pacchetto nuovo oppure una ripetizione di un vecchio pacchetto.\nla finestra deve avere ampiezza inferiore o uguale alla met√† dello spazio dei numeri di sequenza dei protocolli SR. per non incorrere ai problemi di ambiguit√†. ~libro\nIl resend (2) üü© TIMEOUT: √® molto speciale per il TCP, invece di calcolare il timeout con la formula con l‚Äôestimated time, con la media esponenziale e con 4 volte la deviazione standard, viene semplicemente raddoppiato il tempo, ogni volta che scade. Probabilmente si pensa che la rete sia congestionata, quindi si aspetta un p√≤.\nImportante notare che questo ack cumulativo non √® presente in selective repeat, quindi √® pi√π simile a GBN, per√≤ allo stesso tempo se scade il timeout, che √® messo solamente sul base (quindi il pacchetto pi√π vecchio che √® stato mandato, non su tutti a differenza di SR) non vado a rimandare\nFAST RESEND: Quando ricevo 3 acks con lo stesso numero di sequenza, assumo che √® stato perch√© il paccketto con il numero di base √® stato perso. Con questa assunzione provo a rimandare il pacchetto di base.\nControllo del flusso (no) üü© il mittente non vuole mandare cos√¨ tanti bytes da saturare il buffer del ricevente, per questo motivo il ricevente manda in un certo campo dell‚Äôheader anche l‚Äôampiezza del buffer che pu√≤ ancora ricevere, e solitamente il mittente cerca di stare all\u0026rsquo;interno di quel buffer, in modo che la richiesta possa sempre essre elaborata.\nSe il l\u0026rsquo;ampiezza √® 0 non voglio stopparmi! voglio sempre mandare almeno un singolo byte di dati, altrimenti rischierei una starvation, anche se il ricevente pu√≤ ricevere cose.\nControllo della Congestione (!) üü®++ Vengono define tre fasi per il controllo della congestione, le prime due pi√π importanti mentre l‚Äôultima √® facoltativa diciamo.\nSlow start Questa √® la fase che abbiamo gi√† studiato in precedenza, in pratica si parte con un MSS (maximum segment size) e si raddoppia fin quando continuano ad arrivare gli ACK (in pratica aggiungi 1MSS per ack). Quando perdo un pacchetto, o per il timeout o per il triplo ack, allora torno a 1 MSS, e mi setto un massimo numero di pacchetti (la met√† di quando √® successo la perdita) Congestion avoidance Sono in questa fase quando ho raggiunto il numero massimo di pacchetti inviati. Quando sono in questa fase allora aumento di 1/[pacchetti trasmessi] ad ogni ACK, in pratica cresco in modo lineare, molto pi√π lento, fino a quando non perdo di nuovo un pacchetto. Se lo perdo per timeout torno a 1 e sono a slow start, altrimenti alcuni pacchetti sono comunque giunti al destinatario, quindi reiverto in modo molto pi√π soft, in pratica dimezzo la mia window e vado in fast recovery. Fast recovery nella fast recovery aumento di 1 se l‚Äôack √® per il pacchetto che ho perso, quando arriva l‚Äôack per il segmento perso stesso rientro in quella fase, questo mi fa crescere linearmente e mi permette di partire molto pi√π in fretta. Esempio: se ero a 32 pacchetti, vi vengono 3 ack per pacchetto 1, dimezzo e assumo che il pacchetto 2 sia perso, e aumento di 3 (perch√© sono venuti 3 acks), sono a 19, mi arrivano altri ack di 1, aumento di 1, quando arriva il 2 entro in Congestion avoidance. ","permalink":"https://flecart.github.io/notes/livello-di-trasporto/","summary":"Livello di trasporto Si parla di livello logico di trasporto, ma gran parte ne abbiamo gi√† parlato in Livello applicazione e socket di UDP, TCP e Socket. trasporto end-to-end, nel senso che livello traporto viene visto solamente ad inizio e alla fine, in tutti i nodi intermedi non √® visto sto pacchetto.\nUDP (3) üü©- Slide UDP\nClassico inizio e fine porta del socket. Lunghezza, si pu√≤ vedere che massimo √® 2 alla 16, e poi il checksum per vedere se √® comunicato bene.","title":"Livello di trasporto"},{"content":"Introduction: a neuron I am lazy, so I\u0026rsquo;m skipping the introduction for this set of notes. Look at Andrew Ng\u0026rsquo;s Coursera course for this part. Historical notes are (Rosenblatt 1958).\nStructure A single layer of a function can be written in the following way:\n$$ F(\\theta)(x) = \\phi(Wx + b) $$ Which can be summarized by: linear part + activation function. Where $F(\\theta)$ is a partial function that returns another function, $\\theta = (W, b)$ a vector, this is just a way to separate the bias with the parameters. The $\\phi$ is the non linearity, that is needed for the universal approximation function.\nCompositionality The main idea in going deep is extract features of increasing complexity, it\u0026rsquo;s like attempting to give it more computation so that it is possible to extract more interesting parts. We can mathematically view deep networks in the following way:\n$$ x = F^{(l)} F^{(l - 1)} \\dots F^{(0)}(x_{0}) $$ And a composition of layers!\nModularity We can compose parts of the network together! For example residual networks are a clear example, or the inception network.\nTraining network tricks Activation functions Solitamente le funzioni classiche per i network neurali sono sigmoid, tanh, e ReLU. La cosa brutta delle prime due √® vanishing gradient, perch√© se il valore √® molto grosso o molto piccolo, la derivata √® molto vicino allo 0, quindi √® molto difficile aggiornare.\nThe activation function is presented as $\\phi$ before. One thing to note is that this non-linearity doesn\u0026rsquo;t mix the dimensions together. Let me explain clearly with some maths:\nWe say that $\\phi: \\mathbb{R}^{n} \\to \\mathbb{R}^{n}$ and it\u0026rsquo;s a composition of some $\\bar{\\phi}: \\mathbb{R} \\to \\mathbb{R}$ which are just applied independently to every dimension.\nOther properties are:\nIncreasing Continuous There are important to remember from a mathematical point of view. Level Sets Level sets are interesting to analyze the behaviour of a single neuron. We define the sets of constant activation to be: $$ L_{f}(z) = \\left\\{ x : \\phi(w\\cdot x + \\beta) = z \\right\\} \\perp w $$ These are also called generalized linear models, or ridge functions.\nReLU activation The relu activation is easily described as the following step function: $$ f(x) = \\begin{cases} 0,\\, \\text{ if } x \u003c 0 \\\\ x, \\, \\text{ if } x \\geq 0 \\end{cases} $$ The important thing to notice is that when it backpropagates, it just activates or kills the signal, allowing the gradient to flow naturally, and not vanish.\n$x^{k + 1} = \\sigma(W^{k}x^{k} + b)$ so the derivative is $$ \\frac{ \\partial x^{(k+1)} }{ \\partial x^{(k)} } = \\sigma'(W^{(k)}x^{(k)} + b) W^{(k)} $$ And $\\sigma'$ in the case of the ReLU is just 0 or 1, which aids toward the problem of vanishing gradient and similars. The thing to note is that this doesn\u0026rsquo;t exactly work as an activation function if the input depends on $x$ with more than one parameter\nHyperbolic tangent This activation is usually preferred to the Sigmoid, better treated in Logistic Regression, because it has sign symmetry.\nInput normalization In un certo senso in questo modo abbiamo un p√≤ di tati che sono Normali gaussiani. Non ho capito ancora perch√© normale gaussiana sia una tipologia di dati che ci piace cos√¨ tanto. (il motivo che viene dato in lezione √® che Gradient Descent si comporta molto meglio per loss function che sono gaussiane, perch√© la direzione di discesa √® sempre quella, e non deve zigzagare).\nWeight initialization Ci sono moltissimi modi per inizializzare i Weights, in modo che si eviti il problema di vanishing or exploding gradients. L‚Äôidea √® comunque tenere i valori vicini a 1 per evitare che esplodino, e inversamente proporzionali a n o funzioni di n, perch√© se n √® molto grosso potrebbe esplodere lo stesso.\nAlcune inizializzazioni famose sono\nXavier He (qualcosa che funziona per Sigmoid, (alcune funzionano a seconda dell‚Äôactivation function giusta) C‚Äô√® ne sono molte, non so se conviene lavorare sulla inizializzazione, non credo sia comunque buona spesa del tempo a capire queste.\nOptimization Momentum, praticamente un gradient descent che tiene conto delle computazioni passate, e calcola la direzione anche secondo quelle (quindi se vado su e gi√π e a destra sempre nelle iterazioni passate, andr√≤ a destra pi√π spesso diciamo, questa √® l‚Äôintuizione per questa idea).\nUna cosa molto strana √® che il training delle NN √® molto stabile. Cio√® vari un p√≤ l‚Äôinput e non varia molto l‚Äôouput!\nPossibili motivi:\nWeights Loss function Internal redundancy? cio√® ho troppi parametri e questo lo rende bello.(teoria del prof) Loss functions There are many many many loss functions. The easiest is $$ \\mathcal{l}(y, \\hat{y}) = \\frac{1}{2} \\lVert y - \\hat{y} \\rVert ^{2} $$ And sometimes we write it in this way so the parameters are clear: $$ l(\\theta)(x, y) = l(y, F(\\theta)(x)) $$ Sometimes you need to tailor the loss function to the problem you are trying to solve! For example a very famous function is the Softmax Function, for multiclass classification. In the case you just have two classes then it\u0026rsquo;s the logistic function.\nOther functions could be the cross-entropy, which we can find an analysis here: Entropy. We write it sometimes as log-loss: $$ l(y, \\hat{p}) = - \\log \\hat{p}_{y} $$ If we view this from an information theoretical point of view, then it\u0026rsquo;s the expected length of our codeword.\nRisks After we have the loss we can go on and define the empirical risk, which is just:\n$$ \\mathcal{R}(\\theta; \\mathcal{S}) := \\mathbb{E}_{\\mathcal{S}} [\\ell(\\theta)] := \\frac{1}{s} \\sum_{i = 1}^{s} \\ell(\\theta)(x_{i}, y_{i}) = \\frac{1}{s} \\sum_{i = 1}^{s} \\ell(y_{i}, F(\\theta)(x_{i})) $$ This is the training risk, and same thing could be defined for the test risk.\nOverfitting Slide ways to reduce overfitting, we have 7 it seems\nSometimes overfitting is weird for neural networks, because even if we have it, it seems that training a lot more doesn\u0026rsquo;t produce overfitting.\nOverfitting √® il drago del training classico del machine learning, molto simile a dire che la macchina sta allucinando alcuni pattern causati probabilmente dalla varianza dei dati, o anche dal fatto che alcuni casi positivi sono pochi‚Ä¶\n√à comunque una cosa troppo specifica, perch√© significa che la macchina stia quasi imparando a memoria i casi, dovrebbe provare a generalizzare, per farlo deve scordare dettagli non interessanti (che con overfitting pu√≤ imparare) e imparare le cose importanti. Per√≤ i computer sono troppo bravi a memorizzare dettagli, a differenza di umani.\nDropout Idea del dropout\nL‚Äôidea √® il fatto che il network deve risolvere il problema, anche se √® un p√≤ rotto, questo cerca di renderlo pi√π robusto, e sembra funzionare molto bene.\nKullback-Leibler Divergence We want to measure the distance between two distributions, usually from a real distribution and the one we are predicting. Vedere Entropy#Relative Entropy or Kullback-Leibler\n√à una cosa che proviene dalla teoria dell‚Äôinformazione.\nPer capire questo, √® molto importante andare a capire cosa sia la cross-entropy e questo √® un modo abbastanza naturale per capire quanto vicino √® una distribuzione, solitamente predetta, con quella del training data, si pu√≤ comparare molto con log-likelihood loss function, si potrebbe dire che sia un caso particolare la log likelihood.\nReferences [1] Rosenblatt ‚ÄúThe Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain.‚Äù 1958\n","permalink":"https://flecart.github.io/notes/neural-networks/","summary":"Introduction: a neuron I am lazy, so I\u0026rsquo;m skipping the introduction for this set of notes. Look at Andrew Ng\u0026rsquo;s Coursera course for this part. Historical notes are (Rosenblatt 1958).\nStructure A single layer of a function can be written in the following way:\n$$ F(\\theta)(x) = \\phi(Wx + b) $$ Which can be summarized by: linear part + activation function. Where $F(\\theta)$ is a partial function that returns another function, $\\theta = (W, b)$ a vector, this is just a way to separate the bias with the parameters.","title":"Neural Networks"},{"content":"4.1 Sistemi lineari La cosa buona √® che possiamo analizzare il sistema lineare utilizzando tutti i teoremi che abbiamo sviluppato finora, quindi siamo molto pi√π potenti per attaccare questo problema.\nDefiniamo un sistema lineare cos√¨\n$Ax = b$ con A la matrice associata.\n4.1.1 Preimmagine Data una applicazione lineare $F:V \\to W$, allora la controimmagine √® l\u0026rsquo;insieme dei vettori di V che fanno a finire in quel punto, in matematichese:\n$F^{-1}(w) = \\{v \\in V | F(v) = w\\} \\subseteq V$, un esempio di preimmagine √® Ker F.\nPossiamo anche definire un concetto di suriettivit√† in questo modo:\nUna funzione √® suriettiva, se per ogni elemento dell\u0026rsquo;immagine, ho un elemento nel dominio, quindi l\u0026rsquo;insieme preimmagine deve essere diverso da vuota\nKer e Imm sono qui\n4.1.2 Relazione preimmagine e immagine e nucleo 6.1.4 (chiede) Fare attenzione a dimostrare la doppia inclusione per l\u0026rsquo;uguale! Stiamo utilizzando sempre l\u0026rsquo;assioma dell\u0026rsquo;estensionalit√†, ricordatelo!\nDimostrazione\n4.1.3 Rango righe di righe e colonne uguali (6.2.3) !!! Possiamo definire il rango righe come la dimensione dello spazio riga di A\nMentre il rango colonna la dimensione dello spazio colonna (questo √® ovvio conoscendo i teoremi sulle matrici!, ricorda che con le operazioni di gauss riuscivi a trovare una serie di vettori indipendenti e generatori!)\nDimostrazione\nIl rango colonne, per un teorema precedente che diceva base di uno √® base anche dell\u0026rsquo;altro, √® uguale alla dimensione dell\u0026rsquo;immagine, quindi se la dimensione dell\u0026rsquo;immagine √® uguale al rango righe, ho che i due ranghi sono uguali, allora posso considerare solo un unico rango per la matrice.\nDimostrazione della 5.7.4\nLa dimostrazione di 5.7.4 dovrebbe essere banale, una volta che generalizzi la soluzione di gauss per il nucleo (lo puoi sempre scrivere come spazio generato da n - rr(A) variabili libere per le propriet√† credo delle riduzione matriciale di gauss.\n4.1.4 Rouch√© - Capelli (chiede) Dimostrazione da libro\nDimostrazione (informale)\nLe soluzioni sono le preimmagini della nostra funzione, ha soluzione se la preimmagine di b non`e nulla e per questo deve essere che b deve appartenere al sottospazio generato dalle colonne di a (perch√© queste generano l\u0026rsquo;intera immagine) e per la 3.1.8 allora lo spazio colonna di A √® uguale allo spazio colonna di A con b, allora hanno la stessa dimensione perch√© sono uguali, allora i ranghi sono uguali. (4.2.4?)\npreimmagine 0 coimplica b nello spazio immagine\nb nello spazio immagine coimplica generato con e senza b √® uguale\nquesto coimplica dimensioni uguali quindi finito entrambe le frecce\nPassando per la seconda parte della dimostrazione, sappiamo che l\u0026rsquo;insieme delle soluzioni, ossia la controimmagine, si pu√≤ scrivere in questa forma:\n$f^{-1}(w) = \\{ v + z | f(v) = w \\land z \\in ker(f)\\}$\nallora nel caso in cui io abbia che le due matrici siano uguali come al punto 1, posso creare un insieme infinito di soluzioni partendo da questa cosa.\n4.2 Determinanti 4.2.1 Definizione Non abbiamo una definizione diretta del determinante, per cui la definiamo in modo indiretta facendo una lista delle propriet√†\nVedremo che l\u0026rsquo;inversa di una matrice esiste sse il determinante √® diverso da 0, ed √® l\u0026rsquo;aspetto pi√π importante del determinante per la nostra analisi\nSi pu√≤ dimostrare (ma non si √® fatto) che la funzione associata al determinante esiste sempre ed √® unica.\nPropriet√† (4)\nLe propriet√† 1, 2 ci dicono come comportarci rispetto alla somma (distributiva) e la moltiplicazione scalare per singole righe.\nLa propriet√† 3 ci da un relazione con la combinazione lineare (e quindi dipendenza)\nLa 4 ci permette di calcolare :D\nConseguenze delle propriet√† (3)\nLa propriet√† 3 √® molto utile per il calcolo, direi che √® la propriet√† pi√π importante per fare i calcoli\nHint di dimostrazione Considero la matrice somma, che per la propriet√† 1 √® uguale alla somma dei determinanti di A e B. Allora questa ha due righe uguali, quindi √® uguale a 0. Riscrivendo la somma si ha la sol. Considero la riga scritta come combinazione lineare come somma di due di determinanti di due matrici. Una di queste avr√† due righe uguali, quindi √® 0. I due determinanti sono uguali. Partendo dalla triangolare inferiore, posso trovare la matrice diagonale con matrici con combinazioni lineari. Teorema di Binet\nQuesta propriet√† non si dimostra senza aver considerato la base di dimostrazione con permutazioni.\nPer√≤ dice che se ho due matrici, si ha che il determinante della matrice prodotto √® uguale al determinante delle singole matrici.\n4.2.2 Metodo savius Per le matrici 3x3, il classico\n4.2.3 Metodo Laplace (ricorsivo) 4.3 L\u0026rsquo;inversa della matrice 4.3.1 Definizione e unicit√† L\u0026rsquo;inversa di una matrice $A \\in M_{n\\times n}(\\R)$ √® una matrice $B$ nello stesso spazio tale che\n$AB = BA = I$.\nQuando si fa il controllo della matrice inversa, dovresti dimostrare che $AB = BA$ che di solito non vale, per√≤ dimostri che l\u0026rsquo;inversa √® unica quindi ti basterebbe fare un unico controllo\nDimostrazione unicit√† dell\u0026rsquo;inversa\nSia $A^{-1}$ l\u0026rsquo;inversa di $A$, supponiamo che esista $B$ che sia l\u0026rsquo;inversa e tale per cui $A^{-1} \\neq B$, allora ho che\n$AB =I \\implies A^{-1}AB = A^{-1}I \\implies I B = A^{-1}I \\implies B = A^{-1}$\n4.3.2 Equivalenza di invertibilit√† col determinante (!!) Si pu√≤ dimostrare che $A$ √® invertibile nel caso in cui la determinante √® diverso da 0.\nDimostrazione\n$\\implies$Se √® invertibile, il determinante di A √® diverso da 0.\nPerch√© per binet, se $I = AB$ allora $\\det(I) = \\det(AB) = \\det(A)\\det(B)$ se fosse 0 allora sarebbe impossibile, quindi √® diverso da 0, e posso dire che\n$\\det(B) = \\dfrac{1}{\\det(A)}$\n$\\impliedby$\nDevo dimostrare che se il determinante di A √® diverso da 0 allora √® invertibile. Facciamo una dimostrazione costruttiva, cio√® diciamo qua proprio come √® fatto la matrice inversa.\nPosso costruire la matrice inversa in questo modo:\n$b_{ij} = \\dfrac{1}{\\det A} \\Gamma_{ji}$ ora devi controllare questa cosa e sei apposto.\n4.3.3 Calcolo dell‚Äôinversa con GAUSS SI pu√≤ calcolare l\u0026rsquo;inversa di una matrice utilizzando gauss su una matrice del tipo\n$A|I$, fino ad andare ad ottenere la matrice $I|B$ con B la inversa.\nTEOREMONE (!!!!) 7.6.1 Enunciato (11)\nTutte le dimostrazioni fra 1 e 9 compreso sono sono tutte gi√† state spiegate in precedenza, l\u0026rsquo;unica cosa nuova √® l\u0026rsquo;equivalenza fra 1 e 10\nDimostrazione (1-10)\nSe dimostro che 1 √® equivalente a 10, ho dimostrato l\u0026rsquo;equivalenza anche per 1-11 perch√© 10 √® equivalente a 11 per il teorema questo.\nAllora dimostriamo $\\implies$.\nSupponiamo di avere una funzione bigettiva. Allora posso prendere la sua funzione inversa, che esiste per la biiettivit√†. Considero la matrice associata all\u0026rsquo;inversa, allora posso concludere che $f \\cdot g \\approx AA^-1$ che termina la dimostrazione perch√© ho la matrice inversa.\nPossiamo enunciare le equivalenze fra cose riguardo le applicazioni lineari\nNota su composizione di funzioni\nSia A la matrice associata a f e B associata a g.\nAllora si pu√≤ dimostrare che la matrice associata a $f \\cdot g$ √® $AB$, questo si dimostra utilizzando l\u0026rsquo;associativit√† della moltiplicazione matriciale.\n","permalink":"https://flecart.github.io/notes/sistemi-lineari-e-determinanti/","summary":"4.1 Sistemi lineari La cosa buona √® che possiamo analizzare il sistema lineare utilizzando tutti i teoremi che abbiamo sviluppato finora, quindi siamo molto pi√π potenti per attaccare questo problema.\nDefiniamo un sistema lineare cos√¨\n$Ax = b$ con A la matrice associata.\n4.1.1 Preimmagine Data una applicazione lineare $F:V \\to W$, allora la controimmagine √® l\u0026rsquo;insieme dei vettori di V che fanno a finire in quel punto, in matematichese:","title":"Sistemi Lineari e determinanti"},{"content":"In questo capitolo cerchiamo di andare oltre alla singola dimensione per l\u0026rsquo;analisi.\nLo spazio $\\mathbb{R}^{n}$ Possiamo definire uno spazio Rn come il prodotto cartesiano fra l\u0026rsquo;insieme R un numero di volte uguale a n $\\mathbb{R} \\times \\mathbb{R} \\times ... \\times\\mathbb{R} = \\mathbb{R}^n$\nAllora un tipico elemento in Rn √® nella forma $(x_1,...,x_n)$, questo elemento si chiama punto, mentre gli elelmenti in R che costituiscono questo elemento si chiamano componenti.\nOsservazione La maggior parte dei risultati che dimostro nello spazio ordinario (R3) si pu√≤ dimostrare per Rn, non andiamo pi√π nel dettaglio perch√© i problemi che ho in spazi maggiori sono parte di materiale per analisi 2\nOperazioni definite In modo simile a quanto definito negli Spazi vettoriali abbiamo principalmente due operazioni principali definite (in moto identico a quanto spiegato nell\u0026rsquo;altro documento) che sono:\nl\u0026rsquo;addizione vettoriale la moltiplicazione scalare. In pi√π aggiungiamo una operazione che non √® presente nel documento degli spazi vettoriali ma che √® importante in questo momento.\nProdotto scalare euclideo, definito qui sotto Il prodotto scalare euclideo Dati due elementi in Rn, che chiamiamo x e y, rispettivamente di componenti $x_1, ...,x_n$ e $y_1, ...,y_n$\n$$ \\langle x,y\\rangle = x\\cdot y\\coloneqq\\sum_{i=1}^nx_iy_i $$ Possiamo individuare 3 propriet√† principali per questo prodotto scalare (nota il significato x,y con parentesi cambia in algebra lineare rispetto a questo. (chiamo in questo caso x primo argomento e y secondo argomento).\nSimmetria, se scambio x con y il risultato resta lo stesso $x\\cdot y = y \\cdot x$ Distributivit√† (linearit√† del primo argomento) $\\forall x,y,z \\in \\mathbb{R}^n, \\forall \\lambda, \\mu \\in \\mathbb{R} (\\lambda x + \\mu y) \\cdot z = \\lambda(x\\cdot z) + \\mu(y \\cdot z)$ Utilizzando la simmetria puoi dimostrare anche la linearit√† per il secondo argomento. Positivit√† del riflessivo: $\\forall x \\in \\mathbb{R}^n , x\\cdot x \\geq 0$, e si pu√≤ osservare che $x\\cdot x = 0 \\iff x = 0_v$ Prodotto scalare nella forma col coseno\nDato un elemento $x \\in \\mathbb{R}^{2}$, posso dire che $x = \\lvert x \\rvert \\dfrac{x}{\\lvert x \\rvert}$ notiamo che il secondo fattore ha lunghezza 0, quindi possiamo scriverlo tramite una coordinata polare, qualcosa tipo $\\dfrac{x}{\\lvert x \\rvert} = (\\cos \\theta, \\sin \\theta)$. Quindi se prendo un $x \\neq 0$ possiamo dire che $x = (|x|\\cos \\theta, |x| \\sin \\theta), \\theta \\in \\mathbb{R}$\nAllora se prendo due vettori scriviamo cos√¨! $$ x \\cdot y = \\lvert x \\rvert \\lvert y \\rvert \\cos \\theta \\cos \\gamma + \\lvert x \\rvert \\lvert y \\rvert\\sin \\theta\\sin \\gamma = \\lvert x \\rvert \\lvert y \\rvert(\\cos(\\theta - \\gamma)) $$ che √® esattamente la formula che abbiamo visto alle superiori, il prodotto delle singole norme per il coseno dell\u0026rsquo;angolo fra i due.\nOrtogonalit√† Si pu√≤ definire l\u0026rsquo;ortogonalit√† di due vettori a seconda del risultato del loro prodotto scalare $x,y$ perpendicolari $\\implies x \\cdot y = 0$ Da questo si pu√≤ notare che il vettore nullo √® perpendicolare a ogni vettore.\nNorma di un vettore Scopriremo in seguito che la norma √® strettamente collegata con la lunghezza di un vettore, la definiamo in questo modo:\n$\\lVert x\\rVert = \\sqrt{x\\cdot x} = \\sqrt{x_1^2 + ... + x_n ^2}$\nPuoi notare come questo sia esattamente la distanza.\nPropriet√†\n$|\\lambda|\\lVert x\\rVert = \\lVert\\lambda x\\rVert$ $\\rVert x \\lVert \\geq 0$ e anche l\u0026rsquo;altro con 0, esattamente come per la propreit√† 3 del prodotto scalare vettoriale Disuguaglianza triangolare $\\lVert x \\cdot y \\rVert \\leq |x| |y|$ Normalizzazione\nPer la propriet√† 1 possiamo sempre normalizzare un vettore, ovvero moltiplicarlo per un reale tale che la somma dei componenti √® 1. Per trovare questo valore basta trovare il valore nella norma attuale $\\lambda$ e dividere ogni componente per questo valore. esempio $(3,4)$ noto che la norma √® 5, quindi questo punto normalizzato √® $(\\dfrac{3}{5}, \\dfrac{4}{5})$\nIl quadrato della norma cerchiamo di calcolare questo valore $||x + y|| ^2$ Per definizione si ha\n$$ \\lvert x + y \\rvert^ 2 = \\left( \\sqrt{ \\sum_{i=1}^n (x_i + y_i) ^2} \\right)^2 = \\sum_{i=1}^n (x_i + y_i) ^2 = \\sum_{i=1}^n (x_i^2 + 2x_iy_i + y_i^2) = \\lvert x \\rvert ^2 + 2x\\cdot y + \\lvert y \\rvert ^2 $$ Si pu√≤ anche dimostrare tramite le propreit√† 2 del prodotto scalare e l\u0026rsquo;additivit√†, dimostrare in questo modo per esercizio (oppure chiedere a qualcuno che era in classe).\nOsservazione: Si pu√≤ notare che se i due vettori sono perpendicolari si ritrova il teorema di Pitagora in quanto\n$x \\cdot y = 0$\nDisuguaglianza di Cauchy-Schwarz Trattiamo meglio la versione in Cauchy-Schwarz Inequality Siano x,y vettori in $\\mathbb{R}^n$, allora vale che\n$\\lvert x \\cdot y\\rvert \\leq \\lvert x \\rvert \\lvert y \\rvert$ dove uguale si ha sse x e y sono dipendenti. Dimostriamolo nel caso in cui n = 2, per n superiori dovrebbe essere analogo, prendiamo due valori come qui, allora ho che $\\lvert x \\cdot y\\rvert = \\lvert \\lvert x \\rvert \\lvert y \\rvert\\cos(\\theta - \\gamma) \\rvert \\leq \\lvert x \\rvert \\lvert y \\rvert$ osservando il coseno, questo √® sempre compreso fra -1 e 1 quindi √® ovvio che sia sempre minore. ed √® ovvio che sono uguali nel momento in cui coseno √® 0, quindi i due vettori sono dipendenti.\nQuesto poi si pu√≤ espandere con spazi Hilbertiani e simili, ma non li conosco bene.\nDimostrazione disuguaglianza triangolare da CS\n$\\lvert x + y \\rvert \\leq \\lvert x \\rvert + \\lvert y \\rvert \\iff \\lvert x\\cdot y\\rvert \\leq \\lvert x \\rvert\\lvert y \\rvert$ fai il prodotto e guarda i calcoli\nProdotto e calcoli $\\lvert x + y \\rvert \\leq \\lvert x \\rvert + \\lvert y \\rvert \\implies \\lvert x + y \\rvert^2 \\leq (\\lvert x \\rvert + \\lvert y \\rvert)^2 \\implies \\lvert x \\rvert^2 + 2x\\cdot y + \\lvert y \\rvert ^2 \\leq \\lvert x \\rvert^2 + 2\\lvert x \\rvert\\lvert y \\rvert + \\lvert y \\rvert^2$ e cancellando opportunamente nell\u0026rsquo;ultimo passaggio, √® banale la deduzione. Teorema di Pitagora Anche questa √® una derivazione senza molti problemi in quanto basta la forma del quadrato della norma e il fatto che sono perpendicolari per dire che √® uguale a 0.\nDistanza fra due punti Possiamo definire la distanza fra due punti come la norma del vettore differenza:\n$Dist(x, y) = \\lVert x - y \\rVert$ (il che ha senso, perch√© la differenza mi da un vettore differenza, mentre la norma mi da la lunghezza di questo vettore, ignorando il verso e la direzione, quindi riesco ad ottenere una distanza).\nInsiemi e intorni Intorno sferico Andiamo a definire la nozione di intorno sferico\n$I_r(x)$ √® l\u0026rsquo;insieme di punti che distano al pi√π r da x, ossia $\\{y \\in \\mathbb{R}^n ,t.c., \\lvert x - y\\rvert \u003c r\\}$\nSi pu√≤ notare poi che questa forma dal punto di vista geometrico definisce una sfera in 3 dimensioni, un disco in 2, un intervallo in 1. Analogamente si possono definire i punti di un cerchio con pi√π dimensioni in questo modo.\nInsieme limitato Un insieme $A$ si dice limitato se $\\exists k \u003e 0, k \\in \\mathbb{R},$ $A \\subseteq I_k(0)$. Quindi √® contenuto all\u0026rsquo;interno di una area ben definita.\nUna funzione che ha dominio fino ad infinito per esempio 1/x non √® limitato perch√© non riesco mai a rinchiuderlo, ma una macchia a caso invece si pu√≤ racchiudere.\nInsieme aperto Un insieme si dice aperto se per qualunque punto esiste un contorno abbastanza piccolo che √® contenuto nell\u0026rsquo;insieme (cosa che non succede per un insieme chiuso, se prendo un punto nel bordo non trovo tale intorno).\nSuccessioni generali Definizione $(x_n)_{k \\in \\mathbb{N}}: x_k \\in \\mathbb{R}^n, \\forall k \\in \\mathbb{N}$ si potrebbe quindi sempre vedere come una funzione che va da $\\mathbb{N} \\to \\mathbb{R}^n$\nConvergenza delle successioni (classica) Una successione converge in un punto in Rn, se ogni suo componente tende alla componente corrispondente del punto di convergenza.\nEs, suppongo che f tenda a un $x_0, y_0$ allora voglio dire che il limite per x tende a x0, anche limite per y tende a y0.\nConvergenza secondo distanza Se si utilizza la convergenza secondo la nozione di stanza, allora questo assume una forma molto simile alla nozione di convergenza per i numeri reali.\n$x_k \\to x \\in \\mathbb{R}^n \\iff \\lvert x_k - x\\rvert \u003c \\epsilon, \\forall \\epsilon \u003e0$ ossia quella distanza tende a 0.\nFunzioni con pi√π variabili Definizione $A\\subseteq \\mathbb{R}^n , B \\subseteq \\mathbb{R}^n, f: A \\to B, ,,Graf(f) = \\{(x, f(x)) \\in A \\times B \\}$ quindi alla fine √® sempre la classica definizione di insieme, ma con dominio e codominio diversi\n$Im(f) = (f(x) | x \\in A)$\nCategorie di funzioni Funzioni scalari $\\mathbb{R}^n \\to \\mathbb{R}$\nFunzioni curve o cammini $\\mathbb{R} \\to \\mathbb{R} ^n$\nContinuit√† $\\forall (x_k)_{k \\in \\mathbb{N}} x_k \\to x, \\text { si ha che } f(x_k) \\to f(x)$ rispettivamente utilizzando i domini e codominio corretti (questa sarebbe anche una definizione utile per la continuit√† normale, ma stiamo utilizzando l\u0026rsquo;equivalenza che ci danno le successioni).\ntutte le funzioni elementari sono continue (come le hai sempre viste)\nPossiamo anche scrivere una funzione di continuit√† utilizzando gli intervalli (praticamente uguale a quella classica):\n$f: A \\to B$ √® continua in $\\bar{x}$ se ho che $\\iff \\forall \\epsilon \u003e 0\\exists \\gamma \u003e0 t.c. \\lvert f(y) - f(\\bar{x}) \\rvert \u003c \\epsilon, \\text { con } x\\in A \\lvert x - \\bar{x} \\rvert \u003c \\gamma$\nOSSERVAZIONI\nsi dimostra che tutti gli insiemi definiti con disuguaglianze strette sono aperti.\novvero $f_1,...f_n$ una successione di funzioni $\\mathbb{R}^n \\to \\mathbb{R}$, continue si ha che $A = \\{x \\in \\mathbb{R}^n \\mid f_1(x) \u003e c_1, ..., f_n(x) \u003e c_n\\}$ si ha che A √® aperto per questo teorema che non si dimostra nel nostro corso, per√≤ si ha che √® vero.\nFunzione radiale Una funzione si dice radiale se $f: \\mathbb{R}^2 \\to \\mathbb{R} t.c. \\exists g: [0, +\\infty[ \\to \\mathbb{R}$ tale che $f(x,y) = g(\\lvert x,y\\rvert)$\nIntuizione\nOvvero possiamo dire radiale se possiamo scriverlo solo in funzione dalla sua distanza dall\u0026rsquo;origine (spesso sono superficie di rotazione)\nDi solito √® comodo avere queste funzioni perch√© mi semplificano subito l\u0026rsquo;analisi.\nAltro esempio: $f(x,y) = e ^{-(x^2 + y^2)} \\implies g(t) = e ^{ -t^2}$ che basta disegnare g e poi ruotarlo sull\u0026rsquo;asse delle y.\nInsiemi di livello Dato un insieme $A \\subseteq \\mathbb{R}^2$ e una funzione $f: A \\to \\mathbb{R}$ e dato un punto $b \\in \\mathbb{R}$ allora si dice insieme di livello $b$ di $f$ l\u0026rsquo;insieme $L_b = \\{ (x, y) \\in A \\mid f(x,y) = b\\}$ in pratica √® la pre-immagine della funzione (come se fosse $f^{-1}$).\nQuindi la stessa cosa in una dimensione, ma col nome diverso, perch√© dal punto di vista livello, l\u0026rsquo;insieme di livello √® come un taglio del dominio verso un certo punto.\nDi solito si trova una curva di livello, una curva lineare che rappresenta questo insieme (percorrendo questo punto, il valore in output resta lo stesso, come se mi stessi muovendo parallelamente a una montagna senza salire e senza scendere.\nPiani I piani sono nella forma $f(x,y) = ax + by + c$, √® abbastanza ovvio, perch√© in R2 rappresenta una retta, se ho una retta ma posso variare z come mi pare, allora ovvio che si ha il piano\u0026hellip;\n","permalink":"https://flecart.github.io/notes/analisi-multi-variabile/","summary":"In questo capitolo cerchiamo di andare oltre alla singola dimensione per l\u0026rsquo;analisi.\nLo spazio $\\mathbb{R}^{n}$ Possiamo definire uno spazio Rn come il prodotto cartesiano fra l\u0026rsquo;insieme R un numero di volte uguale a n $\\mathbb{R} \\times \\mathbb{R} \\times ... \\times\\mathbb{R} = \\mathbb{R}^n$\nAllora un tipico elemento in Rn √® nella forma $(x_1,...,x_n)$, questo elemento si chiama punto, mentre gli elelmenti in R che costituiscono questo elemento si chiamano componenti.\nOsservazione La maggior parte dei risultati che dimostro nello spazio ordinario (R3) si pu√≤ dimostrare per Rn, non andiamo pi√π nel dettaglio perch√© i problemi che ho in spazi maggiori sono parte di materiale per analisi 2","title":"Analisi multi-variabile"},{"content":"Definizione gruppo Qualunque insieme pi√π operazione tale per cui:\nEsistenza dell\u0026rsquo;inverso per ogni elemento $\\forall g \\in G, \\exists g^{-1} \\in G : gg^{-1} = e$ Esistenza di un elemento neutro $\\exists e \\in G: \\forall g \\in G, eg = g$ Associativit√†: $(gh)f = g(hf)$ Closure: $\\forall g, h \\in G \\implies gh \\in G$ Unicit√† dell‚Äôelemento neutro Supponiamo di avere un gruppo $G$ e due elementi neutri $e, f$ Allora abbiamo che $ae = a = af$ per√≤ se moltiplichiamo per l\u0026rsquo;inversa abbiamo che $a^{-1}ae = a^{-1}af \\implies e = f$\nUnicit√† dell‚Äôinverso Supponiamo di avere un gruppo $G$ e due elementi inversi per ogni $a \\in G$ Sia $a$ un elemento e gli inversi $a_{1}$ e $a_{2}$, allora abbiamo: $aa_{1} = e = aa_{2}$ ma se moltiplico a sinistra per l\u0026rsquo;inversa abbiamo\n$a_{1}aa_{1} = a_{1}aa_{2} \\implies ea_{1} = ea_{2} \\implies a_{1} = a_{2}$ Dove abbiamo utilizzato anche l\u0026rsquo;associativit√†.\nPropriet√† di cancellazione √à ovvio se moltiplichiamo per le cose giuste. L‚Äôinverso del prodotto Enunciato: $(ab)^{-1} = b^{-1}a^{-1}$ e per gruppi abeliani abbiamo $(ab)^{-1} = a^{-1}b^{-1}$\nLa dimostrazione √® molto semplice ed √® lasciato al visitatore :D\nTest per gruppo Ordine di gruppo e di elemento L\u0026rsquo;ordine di un gruppo √® la cardinalit√† dell\u0026rsquo;insieme, L\u0026rsquo;ordine dell\u0026rsquo;elemento del gruppo √® la potenza a cui si eleva questo elemento per avere il neutro\nTest unico per il sotto-gruppo $$ \\forall a,b \\in H ,H \\subseteq G, ab^{-1} \\in H \\implies H \\text{ is a subgroup of G} $$ Se vale questa propriet√† possiamo gi√† avere un sottogruppo! Quindi √® abbastanza comodo!\nDimostrazione:\nAssociativit√† si ha per $G$. Se prendo $a, a$ come la coppia abbiamo che $aa^{-1}=e$ appartiene a $H$, quindi c\u0026rsquo;√® l\u0026rsquo;elemento neutro. Se prendo $e, a$ vedo che $a^{-1} \\in H$. Quindi abbiamo che vale.\nTest doppio per il gruppo Mostrare che sia chiuso rispetto all\u0026rsquo;operazione e ci sia sempre l\u0026rsquo;inverso. Questo in pratica va per la #Definizione gruppo come espresso sopra!\nTest per gruppi finiti Mostrare solamente che sia chiuso per l\u0026rsquo;operazione (nella dimostrazione di deve mostrare che √® chiuso per l\u0026rsquo;inverso, cosa che si va per il terzo escluso\nSottogruppi Sottogruppi generati da un elemento (ciclico) Dimostrazione Osservazione:\nOgni sottogruppo generato in questo modo √® abeliano, perch√© √® in isomorfismo con il gruppo additivo Z (si vedr√† dopo di questo isomorfismo)\nIl centro di un gruppo √® un sottogruppo Dimostrazione enunciato in h3\nEsempio: centro di gruppi diedrali\nCentralizzatore di un gruppo √® un sottogruppo Osservazione: quando il centralizzatore √® l\u0026rsquo;intero gruppo, l\u0026rsquo;elemento su cui stiamo centralizzando √® esattamente il centro.\nDimostrazione Analoga alla precedente del centro Group actions Intuitively, a group action modifies a set, without changing some interesting property (structure preserving).\nIt is a function $\\alpha: G\\times \\Omega \\to \\Omega$ of group $G$ acting on set $\\Omega$ that satisfies this relation:\n$\\alpha(g, \\alpha(h, u)) = \\alpha(gh, u)$ meaning if i apply an action, then another action, is the same as applying the composition of the action. This is called compatibility. $\\alpha(e, u) = u$ has a identity application. For brevity we will omit the $\\alpha$ and $\\alpha(gh, u)$ will be written as $(gh)u$. $\\Omega$ acting on $X(\\Omega, C)$ follows that $(gx)(u) = x(g^{-1}u)$ why is this true?\n","permalink":"https://flecart.github.io/notes/gruppi/","summary":"Definizione gruppo Qualunque insieme pi√π operazione tale per cui:\nEsistenza dell\u0026rsquo;inverso per ogni elemento $\\forall g \\in G, \\exists g^{-1} \\in G : gg^{-1} = e$ Esistenza di un elemento neutro $\\exists e \\in G: \\forall g \\in G, eg = g$ Associativit√†: $(gh)f = g(hf)$ Closure: $\\forall g, h \\in G \\implies gh \\in G$ Unicit√† dell‚Äôelemento neutro Supponiamo di avere un gruppo $G$ e due elementi neutri $e, f$ Allora abbiamo che $ae = a = af$ per√≤ se moltiplichiamo per l\u0026rsquo;inversa abbiamo che $a^{-1}ae = a^{-1}af \\implies e = f$","title":"Gruppi"},{"content":" üí° Questa prima parte degli appunti √® fortemente mancante 1.1 Insiemistica Tutta Questa prima roba di insiemistica √® fatta molto meglio nel corso di logica, in particolare in questo documento\nTeoria assiomatica degli insiemi\n1.1.1 Definizione e caratteristiche degli insiemi Definizione di Campo ordinato (operazioni fra certi insiemi, sia per la addizione, per la moltiplicazione e simili) Corpo commutativo\nSono definiti somma e moltiplicazione e propriet√† come commutativit√†, associativit√†, distributiva, inversi, opposti, zero e nullo\nCampo ordinato\nIn un campo ordinato valgono le due propriet√†\n$$ x \u003c y \\implies x + z \u003c y + z \\newline z\\geq 0,x \u003c y \\implies x z \u003c yz $$ 1.1.2 Simboli per l\u0026rsquo;insiemistica Per ogni, esiste, and, or, tale che, implicazione, e operazione fra insiemi.\n1.1.3 Operazioni fra gli insiemi Addizione, sottrazione sottoinsiemi, complementari, unione intersezione\n1.1.4 Equipotenza Definizione di equipotenza:\nesiste una funzione bigettiva da un insieme a un altro.\n1.1.5 Numerabilit√† di Q e Z Dimostrazione equipotenza di N, Q, Z.\n1.2 Binomiali In seguito si utilizzeranno per calcolare i coefficienti dei monomi a seguito di una espansione.\nLa definizione di binomiale √® fatta per parti (definita per ora solamente da $N^2 \\rightarrow N$)\n1.2.1 Formula somma di combinazione $\\binom{n-1}{k} + \\binom{n-1}{k-1} =\\binom{n}{k}$\nSi fanno i calcoli e si dimostra.\nDimostrazione lasciata al lettore. Coglione angi, aveva fatto una dimostrazione carina, ora 25/12/22 la sto ricercando le non la trovo. vacca troia‚Ä¶\nComunque ora ho ritrovato dalle slides\nDimo ritrovata\nvai a considerare n, e un elemento a caso. Si tratta di prendere k elementi da n.\nAllora questo possiamo scomporlo in due casi, nel caso in cui prendo l\u0026rsquo;elemento a caso e nel caso in cui non lo prendo. Se lo prendo allora vado a cercare k - 1 nel resto, se non lo prendo allora nel resto vado a cercare k. ez.\nQuesta osservazione mi √® ritornata utile perch√© lo studio dei dearrangiamenti fa un ragionamento praticamente uguale, stessa idea, applicata in ambito diverso\n1.2.2 Permutazioni e Combinazioni Li sai dai.\n1.2.3 Binomio per l\u0026rsquo;espansione binomiale se ho una scrittura di questo genere:\n$$ (a + b) ^n $$ So che il grado del polinomio che si forma √® n, e che per ogni monomio, la somma dei suoi pr\n1.3 Alcune dimostrazioni 1.3.1 Teorema di Pitagora Dimostrazione grafica ‚Üí V Postulato di Euclide\nDimostrazione lasciata al lettore\n1.3.2 Radici di primi in Q Stesso argomento di radice di 2\nDimostrazione lasciata al lettore\n1.3.3 Infinit√† dei numeri primi Argomento di Euclide\nDimostrazione lasciata al lettore mi in Q\nStesso argomento di radice di 2\nDimostrazione lasciata al lettore\n1.3.3 Infinit√† dei numeri primi Argomento di Euclide\nDimostrazione lasciata al lettore\n","permalink":"https://flecart.github.io/notes/insiemi-numerici/","summary":"üí° Questa prima parte degli appunti √® fortemente mancante 1.1 Insiemistica Tutta Questa prima roba di insiemistica √® fatta molto meglio nel corso di logica, in particolare in questo documento\nTeoria assiomatica degli insiemi\n1.1.1 Definizione e caratteristiche degli insiemi Definizione di Campo ordinato (operazioni fra certi insiemi, sia per la addizione, per la moltiplicazione e simili) Corpo commutativo\nSono definiti somma e moltiplicazione e propriet√† come commutativit√†, associativit√†, distributiva, inversi, opposti, zero e nullo","title":"Insiemi numerici"},{"content":"Livello trasporto Protocolli classici Introduzione a TCP e UPD Il quarto livello dei protocolli dell‚Äôarchitettura di Internet √® il livello trasporto (transport), ed √® basato su due protocolli in particolare: il Transmission Control Protocol (TCP) e lo User Data Protocol (UDP), che possono essere usati in alternativa tra loro.\nQuesto √® nel genere di *connession oriented e non, il primo, TCP √® connection oriented, l\u0026rsquo;altro no, questa √® l‚Äôunica differenza fra i due. Questa differenza √® spiegata in maggior dettaglio qui 0.3.8 Servizi orientati alla connessione e non üü®+\nTCP\nConnection oriented (garantire il ripristino dell‚Äôordinamento dei pacchetti e la ri-trasmissione dei pacchetti perduti) Numero dell‚Äôordine (a cui riceve ack per questo numero) Controllare la velocit√† di invio ‚Üí Finestra scorrevole La parte importante di questo √® che la congestione si pu√≤ allargare a macchia d‚Äôolio all\u0026rsquo;interno di internet, e questo √® una cosa molto brutta! Quindi prova a risolvere gli errori di comunicazione di rete, cercando di garantire una buona trasmissione. Il problema √® l\u0026rsquo;efficienza, si possono inviare segmenti in pi√π e congestionare la rete.\nSi pu√≤ dire che questa √® la semantica diversa.\nCon la tree-way handshake si apre una connessione socket, quindi una coppia porta IP, per poter comunicare!\nUDP\n√à semplice perch√© non fa tutte le cose di TCP (no duplicati, no riordinamento, no checks) Tipo connectionless Socket Slide immagini\nIl protocollo TCP richiede a due dispositivi che intendano comunicare di effettuare preventivamente la configurazione dei parametri del socket TCP, originando in questo modo un canale virtuale di tipo punto a punto tra due socket, ovvero tra due applicazioni di livello superiore alle quali vengono smistati i pacchetti da TCP. Quindi sono degli estremi di comunicazione!\nDef socket\nUn socket √® un punto di arrivo o partenza (virtuale) dei dati a livello trasporto, dal quale √® in atto l‚Äôinvio e la ricezione di pacchetti destinati a un‚Äôapplicazione, ed equivale a una coppia: (indirizzo IP, numero di porta dell‚Äôapplicazione). Una volta instaurata la configurazione punto a punto tra due socket, attraverso lo scambio di pacchetti di configurazione, pu√≤ iniziare lo scambio dei dati a livello trasporto. In questo senso si dice che √® un trasporto TCP/IP, perch√© prima configurazione per IP poi effettivamente scambio.\nLa richiesta di connessione\nLa connessione viene instaurata con una richiesta di uno dei due host (il client) nei confronti dell‚Äôhost server.\nIndirizzo IP del server Numero della porta per l\u0026rsquo;applicazione (questo viene verificato dal server se qualche servizio ci √® aperto, se s√¨ risponde, e il client invia la configurazione). Poi iniziano a dialogare e alla fine liberano la porta, √® una connessione punto a punto!. Quando il server riceve il pacchetto, va a verificare se ha la porta aperta, se tutto va bene manda un messaggio di conferma, e il client invia un pacchetto di configurazione, allora possono cominciare a comunicare.\nWelcoming socket and client sockets\nWelcoming √® l\u0026rsquo;unico socket di ricezione di un server, che prende tutto e manda al thread corretto.\nClient sockets sono i molteplici sockets che il server utilizza per comunicare con il singolo client, vengono solitamente istanziati grazie al welcoming socket dopo che ho fatto richiesta di connessione.\nControllo della congestione TCP (2) Questa parte ora √® trattata meglio in Livello di trasporto\nSlide\nSchema\nTCP utilizza un protocollo molto particolare, e a prima vista non intuitivo per gestire la congestione della rete.\nL‚Äôidea generale √® che provo ad aumentare l‚Äôinvio finch√© posso, e quando mi accorgo che inizio a perdere chiudo tutto e ricomincio dal singolo pacchetto.\nCome si √® detto in precedenza, TCP richiede una conferma per ogni pacchetto inviato. La distanza tra due dispositivi che scambiano pacchetti a livello trasporto pu√≤ essere molto significativa. Il tempo per inviare un pacchetto e ottenere la conferma dell‚Äôavvenuta ricezione pu√≤ quindi diventare dell‚Äôordine dei secondi. Il problema del controllo di flusso dei pacchetti nel protocollo TCP si basa su due scopi apparentemente in contraddizione tra loro.\n√® quello di saturare il pi√π possibile la rete di pacchetti, inviandoli a un ritmo elevato. Questo favorisce l‚Äôutilizzo delle risorse e le prestazioni della rete (si spediscono e si ricevono tanti bit al secondo). Se si decidesse di inviare un pacchetto e aspettare l‚Äôarrivo della conferma, la rete sarebbe usata solo in minima percentuale, e si riuscirebbero a spedire solo pochi bit al secondo. Quindi la rete, pur essendo veloce nell‚Äôinvio dei bit, verrebbe sfruttata al minimo delle potenzialit√†. E‚Äô quindi evidente quanto sia opportuno spedire i pacchetti a un ritmo il pi√π veloce possibile. Evitare di saturare la rete occorre evitare che un ritmo di invio troppo elevato possa causare il sorgere della congestione nei router intermedi del cammino dei pacchetti, dal mittente TCP (client) al destinatario TCP (server). Se un router si trova a dover inoltrare troppi pacchetti, provenienti da flussi TCP diversi, i pacchetti si accumulano fino ad andare perduti e la rete va in crisi. In tal caso si deve ricorrere a una tecnica di controllo della congestione. Una forma di congestione pu√≤ comparire anche sul destinatario finale, nel caso in cui esso non sia in grado di ricevere i pacchetti inviati troppo velocemente. In tal caso si deve ricorrere a una tecnica di controllo di flusso. Finestra scorrevole Si parla di metodi di congestione, viene trattato meglio in Livello di trasporto Osservando l‚Äôesempio, partendo con SW uguale a 1, se la conferma √® ricevuta, la finestra viene raddoppiata, spedendo due pacchetti al massimo ritmo di invio. Se entrambi i pacchetti vengono confermati, si passa alla finestra di dimensione quattro, inviando quattro pacchetti al massimo ritmo di invio. Se i pacchetti sono confermati si passa a finestra di otto pacchetti. A questo punto, nell‚Äôesempio, almeno uno degli otto pacchetti non viene confermato. Si suppone che questo fatto sia dovuto a un router congestionato e quindi si rallenta il ritmo di invio ripartendo dalla finestra minima (pari a uno). Il massimo grado sostenibile di invio per la rete in esame nell‚Äôesempio √® stato quindi ottenuto con finestra pari a quattro.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Livello applicazione e socket/Untitled 6.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Livello applicazione e socket/Untitled 6\u0026quot;\u0026gt; TCP usa un meccanismo per il controllo di flusso, detto a finestra scorrevole (sliding window), e un meccanismo per il controllo della congestione, basato sul dimensionamento della finestra scorrevole. Tutto ci√≤ per cercare il massimo ritmo di spedizione che possa garantire l‚Äôinoltro dei pacchetti da parte del router pi√π lento del cammino, e prevenire la saturazione del destinatario finale.\nIdea della sliding window\nLa finestra scorrevole √® un valore intero, cha parte da un valore minimo (ad esempio il valore uno). L‚Äôidea alla base del controllo di flusso a finestra scorrevole √® quello di spedire non pi√π di Sliding Window pacchetti consecutivi, a partire dall‚Äôultimo pacchetto non confermato, e quindi attendere la ricezione di una conferma. Un valore di SW uguale a 1 significa che solo un pacchetto pu√≤ essere spedito, poi occorre aspettare di ricevere la conferma della ricezione. In questo caso la rete √® poco utilizzata. Ogni volta che alcuni pacchetti spediti sono confermati, allora √® possibile spedire i pacchetti successivi mantenendosi entro il limite massimo di SW pacchetti dall‚Äôultimo pacchetto non ancora confermato. Eventuali pacchetti non confermati sono rispediti fino al ricevimento della conferma.\nIl senso di questo meccanismo √® quello di lasciare in sospeso non pi√π di SW pacchetti, per evitare di saturare il mittente. Questo meccanismo, molto semplificato, realizza il controllo di flusso di TCP. Se i pacchetti vengono confermati, si pu√≤ adottare un meccanismo dinamico per accelerare gradualmente il ritmo di invio dei pacchetti, ovvero la dimensione della finestra SW, fino a che non si nota la perdita di almeno un pacchetto tra quelli inviati.\nComportamento a perdita di pacchetti\nSe i pacchetti vanno perduti, TCP assume anche che la causa di ci√≤ sia la presenza di un router intermedio congestionato, e quindi rallenta il ritmo di invio dei pacchetti per dare modo al router congestionato di smaltire i pacchetti accumulati. Tale meccanismo, sommariamente descritto, √® il meccanismo di controllo della congestione di rete di TCP.\nMultiplexing e Demultiplexing e porte Questi termini non hanno una traduzione diretta con l\u0026rsquo;italiano, la cosa pi√π simile possibile √® aggregare e disaggregare, perch√© da una unica scheda direte arriva tutto, questa cosa deve essere demultiplexata alla porta corretta, e multiplexata all\u0026rsquo;unica scheda di rete che si ha.\nLe well known ports sono di solito minori di 1023.\nLe porte alte sono decise da noi, basta che nell ostess ocomputer non ci sia un conflitto di porte.\nMultiplexing perch√© ho molte porte, ma unica scheda di rete, quindi far girare da una unica source tutto il resto. (per il mandante serve0\nDemultiplexing perch√© cos√¨ posso mandare alla porta corretta, ricevendo\nSlide multiplexing\nIn pratica il server con una singola porta non sarebbe in grado di rispondere a connessioni multiple! Ricorda che socket √® end-to-end, non saprei a quale client starei parlando.\nSi parla quindi di welcoming socket per il server, e quando si stabilisce la connessione ti dice in quale porta andare sopra per continuare a comunicare.\nEsempio di demux server\nApplicazione Introduzione livello applicazione (non fo) Il livello applicazione dei protocolli di Internet contiene l‚Äôimplementazione delle funzioni e dei servizi che permettono alle applicazioni di rete in esecuzione sull‚Äôhost di spedire e ricevere i dati. I protocolli sottostanti di Presentazione e Sessione, previsti dallo Standard ISO/OSI, non sono quasi mai considerati nell‚Äôarchitettura dei protocolli di Internet.\nIl livello Applicazione si appoggia direttamente sul livello trasporto e, in particolare, molte applicazioni che richiedono servizi connection-oriented si basano sul protocollo TCP, attraverso numeri di porta che nel tempo sono diventati standard ‚Äúde facto‚Äù. Ad esempio, la spedizione e il trasferimento dei messaggi di posta elettronica, basati sul protocollo di livello applicazione Simple Mail Transfer Protocol (SMTP) √® comunemente associata alla porta di livello applicazione 25. La porta 80 √® destinata al protocollo di trasferimento di ipertesti HyperText Transfer Protocol (HTTP) alla base del trasferimento delle pagine di siti del World Wide Web.\nAltri esempi di protocolli e servizi che si collocano al livello applicazione sono il protocollo e servizio di Domain Name Service (DNS) e i protocolli IMAP e POP3 per la consegna della posta elettronica. Una dettagliata illustrazione sul mondo dei servizi e protocolli applicativi di Internet sar√† oggetto di un modulo apposito\nHTTP1 (non fare) All\u0026rsquo;inizio bisognava aprire connessione per ogni singolo file che bisognava richiedere, quindi molto lento, ora sappiamo riuscire a creare socket di connessione che non si chiudono subito\nMolto bene √® descritto in HTTP e REST\nDomain Name System \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Livello applicazione e socket/Untitled 9.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Livello applicazione e socket/Untitled 9\u0026quot;\u0026gt; Immagine di spiegazione\nVorremmo avere un metodo molto semplice per umani per poter trovare un sito, ma il livello di rete non li sa gestire, ha bisogno di IP, allora ho bisogno di alcuni server dedicati che mi restituiscono l\u0026rsquo;IP dato un nome di dominio! Questo √® unico, altrimenti ci sarebbe ambiguit√† riguardo al nome. E altra cosa, ci sono i server DNS che sappiano dare l‚ÄôIP corretto a seguito del DNS.\nProblema\nGli utenti di Internet preferiscono usare nomi mnemonici per identificare le risorse in rete, ad esempio nomi di host appartenenti a una certa rete, oppure indirizzi di e-mail di utenti di una certa rete. Anche le reti, risultano spesso facilmente identificabili attraverso i nomi di dominio della rete. I nomi di dominio hanno quindi lo stesso senso degli indirizzi IP, e infatti vengono assegnati da enti internazionali, come gli indirizzi IP, per evitare confusione e nomi duplicati. Le risorse appartenenti a un dominio possono avere nomi scelti arbitrariamente (ad esempio nomi di host, indirizzi di e-mail) purch√® non siano duplicati all‚Äôinterno del dominio stesso. Nomi di risorse duplicati sono ammessi in domini diversi, (ad esempio, pippo@topolinia.it e pippo@paperopoli.com). I nomi di dominio hanno una struttura gerarchica del tipo (nomerisorsa.sottodominio.sottodominio.dominioradice). Ad esempio www.informatica.unibo.it √® il nome dell‚Äôhost che agisce da web server per il sottodominio informatica, del sottodominio Universit√† di Bologna, del sottodominio di livello massimo .it (Italia). In realt√† il dominio radice del mondo, che esiste implicitamente, non si scrive mai. Tutto ci√≤ √® comodo ma viola le esigenze del livello rete e dei router che pretendono solo indirizzi IP.\nDNS per risolvere il problema\nPer risolvere il problema, √® nato il servizio Domain Name System (DNS) che attraverso una gerarchia di server e un protocollo standard per le richieste permette di risolvere l‚Äôassociazione tra nome della risorsa e indirizzo IP. Ogni host in rete deve conoscere un server DNS al quale inviare le richieste e ogni server DNS deve conoscere almeno un server DNS di livello superiore. I server di livello superiore conoscono un numero sempre maggiore di nomi e relativi indirizzi IP, ma sono sempre meno per motivi di costo.\nL‚Äôesempio mostra come viene soddisfatta una richiesta DNS a seconda del punto della rete di server DNS dalla quale parte. Se un server DNS non conosce la risposta passa la richiesta al livello superiore, finch√© qualcuno non conosce l‚Äôindirizzo IP.\nNote sull\u0026rsquo;affidabilit√†\n√à una cosa molto brutta tenere un singolo server che possieda questo server DNS, perch√© se fallisce nessuno pu√≤ pi√π raggiungerlo!. Quindi vogliamo andare a creare una alta ridondanza riguardo questo server DNS.\nReplicare servizi anche in zone differenti (ne basta una su e il servizio apparentemente √® su, ecco il sistema distribuito!). Iterativo/ricorsivo (!)\niterativo il DNS ti risponde col nuovo dns server da contattare per poter avere una risposta\nRicoversivo quando il DNS stesso va a chiedere, e quindi quando ti risponde ti da gi√† il risultato corretto.\nQuindi in un caso si pone molto pi√π onere sul client che ha richiesto, nel secondo caso si pone onere sul server DNS. Quindi a seconda di quanto hai bisogno puoi fare l‚Äôuno o l‚Äôaltro direi.\nTyposquatting attack Questo √® un attacco sui DNS. Sappiamo che questo servizi risolvono testo in IPs che poi vengono utilizzati per mandare le richieste sulla rete. Per√≤ questo approccio √® attaccabile da domini che hanno codifiche diverse, ma carattere uguale all\u0026rsquo;utilizzatore. In questo modo un utente pu√≤ essere ingannato a cliccare su quell\u0026rsquo;url, anche se il domain name originale √® diverso perch√© invece di A scrive –ê, per esempio hex-dump di A –ê √® 41 20 d0 90 a vediamo chiaramente che la seconda A in cirillico √® rappresentato da tre bytes, anche se sembrano esattamente essere uguali. Questo pu√≤ essere utilizzato e attaccato.\nSulla connessione Riassumento, per poterci connettere sulla rete abbiamo bisogno di queste informazioni e stack di rete qui:\nStack TCP/IP firewall (IP, default router, maschera di rete) DNS DHCP Architetture a livello applicazione Client/server Peer To peer Le applicazioni e i servizi su Internet possono essere realizzati secondo almeno due modalit√† architetturali distinte: Architettura Client/Server e architettura Peer to Peer (P2P).\nClient/Server, i Client sono host che spediscono richieste di servizio ai Server. I Server sono i soli host sui quali sono in esecuzione i servizi che permettono di soddisfare le richieste. Un esempio di servizi di tipo Client/Server sono: il servizio DNS, dove ogni host pu√≤ agire da client spedendo richieste degli indirizzi IP ai DNS server, oppure il servizio World Wide Web, e il servizio di posta elettronica, entrambi basati su client che chiedono pagine web o spediscono e-mail, e server che mantengono le informazioni o memorizzano le e-mail spedite.\nPeer to Peer (P2P), invece, tutti gli host sono contemporaneamente sia client che server. Ogni host agisce da Server cercando di soddisfare, se possibile, le richieste ricevute da altri host. Ogni host agisce da Client quando spedisce ad altri host le sue richieste, o per conto personale, o per cercare di soddisfare richieste di terzi. Un esempio di servizi P2P sono: i servizi di condivisione dati (file-sharing) basati su protocolli Freenet, Gnutella, Kazaa. Esistono anche servizi ibridi, nei quali esistono server che aiutano solo a trovare pi√π rapidamente gli host P2P migliori per comunicare e implementare servizi P2P (esempio: file-sharing con Napster).\n","permalink":"https://flecart.github.io/notes/livello-applicazione-e-socket/","summary":"Livello trasporto Protocolli classici Introduzione a TCP e UPD Il quarto livello dei protocolli dell‚Äôarchitettura di Internet √® il livello trasporto (transport), ed √® basato su due protocolli in particolare: il Transmission Control Protocol (TCP) e lo User Data Protocol (UDP), che possono essere usati in alternativa tra loro.\nQuesto √® nel genere di *connession oriented e non, il primo, TCP √® connection oriented, l\u0026rsquo;altro no, questa √® l‚Äôunica differenza fra i due.","title":"Livello applicazione e socket"},{"content":"First of all, we need to have a strong understanding of how a program allocates memory during its execution. See Memoria, Memoria virtuale and other notes about Nomi e Scope, Gestione della memoria. The thing you have to remember is that\nEvery new function call allocates a new block, with his local variables. How the calling parameters are stored in the stack How the heap is allocated (common heap algos are in Gestione della memoria) How the stack grows (and how it can overflow it, and overwriting important data). Common attack vectors We use C, as it is the easiest way to show how this could be attacked.\nThe threat model Attacker‚Äôs goal:\nInject malicious code into a program and execute it (Return Object Programming) Gain all privileges and capabilities of the target program (e.g. setuid) System‚Äôs goal:\nprevent code injection Integrity ‚Äì program should execute faithfully, as programmer intended Crashes should be handled gracefully Attacker‚Äôs capability:\nsubmit arbitrary input to the program Environment variables Command line parameters Contents of files Network data The thing is that it is highly variable. Stack smash example Some functions don't have boundary controls, for example `strcpy` or `gets` and are vulnerable to stack overflows. Common defenses Compiler Hardening These are just hardening attempts, which means it makes the attack more difficult, but still not impossible to execute.\nStack canaries Just a random string that is checked before returning. This allows you to check if there has been a stack overflow. Usually this can be bypassed if you can leak the value of the canary before-hand.\nNon executable stacks So you can\u0026rsquo;t execute the shell-code you have just wrote in the stack! :).\nOs hardening Some hardening at the OS level to prevent common exploits.\nAddress-Space Layout Randomization (ASLR) The location of the data and code are always randomized when the program is loaded. This makes it more difficult to have exploits jumping around the code! Example ROP attacks are more difficult. (ROP = Return-oriented-programming, method that allows you to control where the program jumps by overwriting return addresses.)\nSome rules Use memory safe languages Example: C is not memory safe, see Teoria dei Tipi. using safe languages allow you to have provable guarantees that the type is always respected and stuff like this!\nData vs Code You need to differentiate the data with the code. They are two very different things! Many different exploits use data to be interpreted as code, and thus have this bug.\nPatch! Patch as soon as you can. most of the vulnerabilities are discovered but then left to be, without been patched for a long time. (e.g. exploit kits for these vulnerabilities) Automatic patches are the best.\n","permalink":"https://flecart.github.io/notes/memory-corruption/","summary":"First of all, we need to have a strong understanding of how a program allocates memory during its execution. See Memoria, Memoria virtuale and other notes about Nomi e Scope, Gestione della memoria. The thing you have to remember is that\nEvery new function call allocates a new block, with his local variables. How the calling parameters are stored in the stack How the heap is allocated (common heap algos are in Gestione della memoria) How the stack grows (and how it can overflow it, and overwriting important data).","title":"Memory Corruption"},{"content":"Interrupt Descrizione iniziale üü© Di interrupt e trap se n‚Äô√® parlato un p√≤ in Livello ISA di architettura, ora andiamo ad approfondire come viene gestito a livello SO.\nUn interrupt √® un segnale che viene mandato o da un dispositivo hardware (di solito dopo la fine di un processo input output) oppure da software, in questo caso viene chiamato trap che √® un interrupt software sincrono..\nSlide Interrupt Hardware e software\nQuesti segnali sono utilizzati per indicare eventi che dovrebbero essere gestiti (come end of I/O, divisione per 0, ma anche semplicemente syscall e passare livello kernel).\nIl segnale solitamente implica la interruzione di quanto viene svolto in questo momento, per gestire l‚Äôinterrupt corrente, e poi tornare all‚Äôistruzione precedente. Solitamente perch√© potrebbe anche essere che il processo non sia interrompibile, e quindi l‚Äôinterrupt dovrebbe essere rischedulato.\nPer poter ripristinare lo stato precedente solitamente ci si devono salvare l‚Äôimmagine dei registri del programma, tutte le informazioni utili a far runnare il processo (di solito messe nelle PCB), e l‚Äôistruzione di ritorno.\nQuando ci si ritorna sopra basta mettere nel PC l‚Äôindirizzo della istruzione corretta.\nProcedimento classico di gestione interrupt üü© Praticamente durante il Ciclo va a fare un check per vedere se il filo dell‚Äôinterrupt √® settato, se s√¨ carica istruzioni a un certo indirizzo (e si deve salvare l‚Äôistruzione attuale).\nMasked se si sta facendo qualcosa che non si pu√≤ interrompere, quindi √® delayed. (quando il processore non pu√≤ essere interrotto, ad esempio quando sei in Sezioni Critiche, o quando arrivano interrupt dello stesso tipo, se ogni interrupt ha una stack propria, andrebbe a sovrascrivere).\nSe tutto va bene e non √® delayed ed esiste un interrupt, ad alto livello fa:\nSospende (in un modo che possa essere ripreso) il processo corrente Salta all‚Äôistruzione definito in interrupt vector **(**tabella fissa cos√¨ √® pi√π veloce) Esegue l‚Äôinterrupt Si ritorna al processo precedente, o altro (scheduling potrebbe far andare in altro processo). Slides passi ad alto livello\nSlides passi a basso livello (!!!)\nFino a qui tutte le operazioni sono HARDWARE. Da ora in poi viene ripreso il ciclo FDE con il controllo dell Interrupt handler.\nTipologie di gestione di interrupt Multipli (2) üü© Quando ho interrupt multipli diventa leggermente pi√π difficile gestire questi interrupt. Potrebbero interagire, che succede quando mi arriva un interrupt da device 1 mentre sto runnando l‚Äôinterrupt handler di device 2???\nDisabilitazione degli interrupt\nQuesta √® la forma pi√π semplice per la gestione dell‚Äôinterrupt, in pratica quando sto gestendo un interrupt, li disabilito, in modo che non possa riceverne altri, cos√¨ sono sicuro che non posso ricevere nessun altro interrupt. Una soluzione simile per le CS ne abbiamo discusso in Sezioni Critiche\nQuando sto per finire riattivo gli interrupt e cos√¨ posso vedere se ce ne erano alcuni pendenti.\nHo alcuni svantaggi come:\nNon ho un concetto di priorit√† degli interrupt a questo livello Slide idea di gestione\nAnnidamento degli interrupt\nQuesta √® la soluzione pi√π moderna, ed √® anche la pi√π efficiente che permette di\nAvere un concetto di priorit√† di interrupts Necessita di stack separati (se gli interrupt utilizzano la stessa stack, potrebbero sovrascriversi alcune informazioni!) quindi pi√π difficile da implementare. Forse ogni interrupt ha una propria stack, se viene stetsso tipo di interrupt sono maskerati! PI/O, or Interrupt based I/O üü© PI/O\nIn questo caso la CPU setta tutti i valori utili al controllore del device driver. e poi fa polling per chiedere al driver se ha finito o meno (attraverso un controllo sul registro di stato del driver).\nSe il driver ha finito, la CPU si mette a copiare i dati di output del device alla propria memoria.\nUn chiaro svantaggio √® che il polling √® molto inefficiente per la soluzione di questo tipo di problemi.\nInterrupt driven I/O\nQuesta √® la soluzione moderna, quella pi√π utilizzata, dato che ora √® il dispositivo driver a comunicare quando un processo I/O √® stato completato o men, cos√¨ la CPU √® a conoscenza di questo evento e pu√≤ comportarsi di conseguenza. (quindi quando gestire l‚Äôinterrupt, e poi effettivamente runnare il codice corrispondente quando l‚Äôinterrupt √® avvenuto).\nMemoria Direct Memory Access üü© Per copiare alcuni dati utili per I/O dalla memoria RAM alla memoria del controllore bisognerebbe spendere tanti cicli di clock della CPU, di solito questa √® una operazione molto lenta.\nDMA ci permette di accedere direttamente alla memoria, quindi il controllore stesso √® programmato con l‚Äôindirizzo su cui andare a prelevare la memoria corretta, sollevando la CPU da questo primo lavoro.\nChiaramente il vantaggio principale di questo metodo √® la velocit√†, dato che abbiamo pi√π cicli di clock per la CPU, oltre a questo, crea una interfaccia pi√π facile da gestire, quindi i drivers sono pi√π semplici.\nUno svantaggio √® la contesa del BUS, che per trasferire c‚Äô√® bisogno che il bus sia libero.\nSicurezza\nQuesto √® un possibile falla di sicurezza, infatti se il codice del controller √® malevolo potrebbe fare attacchi al sistema di certo tipo.\nSecondo Renzo sarebbe meglio che questo codice fosse open, in modo che sia molto probabile di trovare cose maligne.\nRam üü© √à semplificata da poche istruzioni di accesso, che di solito sono solo LOAD E STORE. (Tutti i dettagli fisici sono astratti, la CPU non si interessa di questi, sono built-in del calcolatore!).\nDi solito (in modi che non so), sono gestiti da MMU.\nNOTA: ci mettono un p√≤ i condensatori a scaricarsi. (possibile recuperare un p√≤ di informazioni se tipo congeli la RAM subito).\nLe ROM esistono ancora, ma sono per cose basilari, come per la parte del boot.\nMemory Mapped I/O üü©- Alcune aree di memoria, come quelle del video grafico, sono scritti e letti subito da alcuni driver e sono utilizzati per sapere cosa mostrare sullo schermo per esempio.\nMa dato che 2 componenti (read and write) devono sincronizzarci nella lettura. Questa sincronizzazione di solito √® fatta a livello hardware.\nDischi e SSD üü© Abbiamo spiegato meglio questa parte in Devices OS\nDischi memorizzano in maniera magnetica, e lo fanno in maniera non-volatile, cio√® possiamo ritrovare i nostri dati.\nSono a accesso diretto, in contrasto con i nastri che erano sequenziali. leggermente accennato in Memoria. E per capire dove leggere e scrivere si devono impostante movimenti di settore del cilindro e testina per leggere il settore corretto. Settore si aspetta che giri, testina si aspetta che si sposti. √à lento, nell‚Äôordine dei microsecondi.\nOperazioni possibili\nREAD, WRITE e anche Seek (quando vado a spostare la testina da altre parti!)\nSlide\nOsservazioni sulla velocit√†\nNon ci converrebbe avere uno stesso file messo in posti molto diversi fra di loro all‚Äôintenro del disco!\nCose di scheduling in modo da leggere cose che siano vicine. (Ma anche il filesystem, in modo che cose che cose che vengono utilizzate spesso siano vicine, ma questa roba la vedremo dopo)\nSSD, Solid State Disk\nAnche questi sono per cose non volatili.\nSolitamente scrivono ad insieme di blocchi! e lo si fa in cicli di scrittura perch√© non scrive ad ogni singola scrittura, ma sono in un buffer, e saranno scritti insieme in tutti in un ciclo di scrittura, questo √® per rendere pi√π efficiente questa operazione.\nPer ssd a volte tengo la RAM come una cache intermedia per la scrittura.\nGerarchie di memoria üü© Slide piramide\nL‚Äôaltro argomento si parlerebbe di Cache, ma penso sia trattato gi√† benissimo in 4.2 Memoria Cache\nQuindi guardare l√¨, guardare la piramide della memoria il tradeoff velocit√† e quantit√† di memoria, il costo di accesso (in termini di tempo ed energia).\nSicurezza Il processo\nNon dovrebbe accedere ad aree di memoria a cui non dovrebbe accedere Non dovrebbe accedere direttamente ai dispositivi I/O, altrimenti potrei accedere e modificare qualunque cosa sui driver, e qualunque processo potrebbe farlo. √à importante garantire la sicurezza anche per l‚Äôaffidabilit√† del sistema, anche per proteggere il programmatore stesso, quando fa qualcosa in modo accidentale, in modo da evitare danni brutti. al sistema\nMode Bit üü© nella realt√† le protezioni principali sono due, messe a livello hardware\nUn Mode bit che sta a specificare se il CPU √® in Kernel mode o user mode. Questi metodi sono importanti perch√© il modo kernel permette accesso totale controllo totale sulla memoria, sull‚ÄôIO, mentre user solamente gli indirizzi a lui illegali. Questo metodo permette di entrare in kernel mode in modo controllato, in modo che riesca sempre a gestire questa protezione. Ovviamente il cambio del mode bit √® privilegiato, un programma normalmente non pu√≤ cambiare mode con una singola istruzione, deve passare con system call che sono le interrupt software o trap, con una istruzione specifica per mandare interrupt. √à l\u0026rsquo;unico modo!. Nota: ovviamente quando il computer parte, in boostrap √® in modalit√† kernel, che appena finisce torner√† in User Mode (√® il processo INIT!) Una mappatura a indirizzi illegali per il programma, in modo che possa accedere solamente a quello a cui dovrebbe accedere. Protezione memoria üü©- Slide protezione Memoria MMU\nQuesto pezzo di hardware ha il ruolo di tradurre indirizzi logici in fisici, e gestire l\u0026rsquo;accesso (ritorna l‚Äôerrore se non si potrebbe fare).\n√àimportante che sia in Hardware perch√©:\nDeve essere molto veloce, perch√© sono operazioni molto veloci Si potrebbe bypassare e allora avresti accesso a tutta la memoria ugualmente. System call üü©- La sistem call √® una unica istruzione, mediante la quale √® possibile accedere al kernel mode, in grado di accedere a tutto, utile per la protezione e affidabilit√† del sistema, e non permettere programmi di fare tutto.\nEsistono convenzioni di chiamata, perch√© si aspetta in un certo registro la presenza di un codice che specifichi la tipologia di system call, poi la sistem call ritorner√† il valore corretto in un certo registro.\n","permalink":"https://flecart.github.io/notes/note-sullarchitettura/","summary":"Interrupt Descrizione iniziale üü© Di interrupt e trap se n‚Äô√® parlato un p√≤ in Livello ISA di architettura, ora andiamo ad approfondire come viene gestito a livello SO.\nUn interrupt √® un segnale che viene mandato o da un dispositivo hardware (di solito dopo la fine di un processo input output) oppure da software, in questo caso viene chiamato trap che √® un interrupt software sincrono..\nSlide Interrupt Hardware e software","title":"Note sull‚Äôarchitettura"},{"content":"(Schulman et al. 2017) √® uno degli articoli principali che praticamente hanno dato via al campo. Anche questo √® buono per Policy gradients:\nhttps://lilianweng.github.io/posts/2018-04-08-policy-gradient/\nIntroduzione a PPO References [1] Schulman et al. ‚ÄúProximal Policy Optimization Algorithms‚Äù 2017\n","permalink":"https://flecart.github.io/notes/proximal-policy-optimization/","summary":"(Schulman et al. 2017) √® uno degli articoli principali che praticamente hanno dato via al campo. Anche questo √® buono per Policy gradients:\nhttps://lilianweng.github.io/posts/2018-04-08-policy-gradient/\nIntroduzione a PPO References [1] Schulman et al. ‚ÄúProximal Policy Optimization Algorithms‚Äù 2017","title":"Proximal Policy Optimization"},{"content":"In this note we will talk about some common ways to attack wireless based devices.\nAttacking an automated door Usually these doors are opened by radio frequency keys, and can be opened easily (e.g. replay attacks, Jam the frequency)\nJamming This is the easiest way to attack. Just send many signals to make a certain frequency un-usable in our space. But with Frequency hopping this attack is solved. See Tecnologia Wireless#Frequency Hopping But this method could be easily known and observed (enables eavesdropping, against confidentiality, a principle in Theoretical Notions of Security#CIAA principles of security.) if the initial seed is known.\nFrom this we conclude that\nIf the modulation used is known If the initial seed is known. We can eavesdrop. Rolling code In some systems like automated doors, they just check for a sequence of signals, if that is present open the door. This is clearly easily attacked by replay attacks. So, a common way to protect against those types of attacks is to use a rolling code. With rolling code both transmitter and receiver have a PRNG. The transmitter sends codes based on the PRNG, and receiver tries to get those messages. He tries to see codes in a large frame window, so that a missed code doesn\u0026rsquo;t dis-align it too much. This makes replay attacks more difficult (usually it is good enough), but does not prevent them: if the attacker captures too many codes then it can be broken!\nChallenge and response More secure way to handle these is using challenge-response protocols. The door generates a nonce to the receiver. The receiver than uses a common secret to cipher it and return back to the door. This needs a back and forth not present in the previous methods. With these in place, we can authenticate the client, and solve replay attacks.\nDefenses of IEEE 802.11 The physical layer There are usually no defenses against attacks on the physical layer of the wifi network stack. Electromagnetic radiations are transmitted freely in the space. Some solutions are for example use paints that absorb most of the radio waves. The Mac layer Inter-Frame spaces DoS Remember that the mac layer uses silent periods, called SIFS, PIFS, DIFS to orchestrate the communication Mac Wifi#Inter-Frame spaces. There is a easy denial of service attack with this protocol: just permanently communicate before the end of a PIFS, so it\u0026rsquo;s just you that does it.\nSSID Hiding This link is an interesting resource regarding this topic. Let\u0026rsquo;s ask: is it secure to hid the SSID of your wi-fi network? Answer: No, you are using security by obscurity Classical Cyphers#On security of cipher explains why it is a bad idea.\nMAC whitelisting Also, this is not a good idea, because it is easy to spoof the wanted MAC if an attacker really wanted to.\nDisassociation attacküü®+ Some packets, like disassociation packets are sent in clear, with no need for authentication of the request. This makes easy to send disassociation packets to make a terminal disconnect from the access point.\nSee here. The solution for this problem is to authenticate the terminal with WPA or other ciphers.\nRogue AP As SSID (see briefly Wifi 802-11), are public, it\u0026rsquo;s possible to spoof the network, and put an access point that is not the real one, but pretends to be. In this way, you can receive passwords or other secrets that pass through this AP.\nWifi Cryptography WEP protocol Has two operating modes, shared key and open system.\nWEP: Shared Key Challenge and response framework is used, like this: But as the nonce is in clear, the key can be recovered using Known plain-text attacks and other similar to those! And it\u0026rsquo;s possible to do it in every session.\nWEP: Open System With this protocol, the sender and receiver already have the secret key in common. Then the sender does this to create the cipher text: RC4_seed(IV | k), then uses this OTP and Stream Ciphers#Stream Ciphers to generate the key used to cipher the messages. The message is split to $n$ blocks at the beginning, so there are like blocks of messages. The problem is that after 30k packages is almost sure collision that would allow an attacker to recover the plain-text, as they share the same IV. So this is not secure at all.\nWPA protocol Stands for WiFi protected access. This protocol solves some of the common problems of WEP security. It can be divided into 3 channel based categories and two cipher-based categories.\nPSK Enterprise WPS For the channels And TKIP(Temporal Key Integrity Protocol) and CCMP (Counter Mode Cipher Block Chaining Message Authentication Code Protocol) for cipher modes. TKIP is wep compatible. CCMP uses AES with CBC. WPA with TKIP has been deprecated.\nWPA-PSKüü© So, a WPA that uses phase shift keying to send the messages. Using the TKIP, it has problems like WEP, so it is not used anymore.\nCCMP version is still quite used, usually in domestic systems. It is still reliable.\nWPSüü© With these system, there is no need for a password. But it needs a physical access to the access point. Example of this method is a button or PIN on the wifi router.\nWPA-Enterpriseüü© This method is used on WANs, for example Unibo WAN uses this method. They use an external server for authentication, called RADIUS (Remote Authentication Dial-In User Service). WPA3üü® WPA2 was possible to have a Replay attack, as the used nonce was cached to make the authentication faster. WPA3 solved this problem, so it can be considered as the most secure method.\n","permalink":"https://flecart.github.io/notes/wireless-attack-vectors/","summary":"In this note we will talk about some common ways to attack wireless based devices.\nAttacking an automated door Usually these doors are opened by radio frequency keys, and can be opened easily (e.g. replay attacks, Jam the frequency)\nJamming This is the easiest way to attack. Just send many signals to make a certain frequency un-usable in our space. But with Frequency hopping this attack is solved. See Tecnologia Wireless#Frequency Hopping But this method could be easily known and observed (enables eavesdropping, against confidentiality, a principle in Theoretical Notions of Security#CIAA principles of security.","title":"Wireless attack vectors"},{"content":"2.1 Basi 2.1.1 Definizione Un insieme di vettori $v_1,...,v_n$ sono basi di uno spazio vettoriale $V$ se sono soddisfatte queste propriet√†\n$V = \\langle v_1,...,v_n\\rangle$ $v_1,...,v_n$ sono linearmente indipendenti Dalla propriet√† 2 potremmo anche dire che √® il minimo insieme di vettori necessario per avere questa base.\nFinitamente generato\nSe l\u0026rsquo;insieme dei vettori nella base √® finito allora posso dire che √® finitamente generato\nMa possiamo trovare anche spazi che non sono finitamente generati come $\\R[x]$ che non hanno un numero finito di basi (perch√© dipende dal grado dei polinomi che pu√≤ essere infinito).\nNota: base dello spazio vettoriale banale\nLa base dello spazio banale √® l\u0026rsquo;insieme vuoto!, se fosse il vettore 0, per definizione posso trovare un coefficiente diverso da 0 tale che sia zero. eg $1\\cdot 0_v = 0$ quindi non √® linearmente indipendente.\nNota sulla seguente carrellata di proposizioni\nLe seguenti proposizioni parlando della possibilit√† di generare le basi partendo da vettori linearmente indipendenti e aggiungendo fino a generare, o partendo da vettori che generano e togliendo finch√© non hai una base.\nDa questa idea generale si possono ricavare molte osservazioni, che sono elencate dalle proposizioni seguenti\n2.1.2 Minimali e massimali Si dice che una propriet√† √® minimale per un insieme, se ogni sottoinsieme proprio possiede pi√π la propriet√†\nE si dice che √® massimale se per ogni sovrainsieme proprio, questo insieme perde la propriet√†\n2.1.3 Prop 4.1.4 Teorema caratterizzazione delle basi Questo teorema √® equivalente alla definizione data di base, solo che esprime il concetto utilizzando i minimali e massimali.\nEnunciato\nSi dice che un insieme di vettori $v_1, ..., v_n$ √® una base per uno spazio vettoriale sse:\nL\u0026rsquo;insieme massimale di vettori linearmente indipendenti Minimale di vettori generatori (cio√® se ne tolgo uno non genera pi√π, allora riesco a concludere che sono indipendenti) gi√† vista nella 4.2.1 Si pu√≤ notare come sia strettamente collegato alla 4.2.2\nIdee per la dimostrazione\nCaso 2$\\impliedby$Se mi prendo un insieme minimale di generatori, mi basta dimostrare che siano indipendenti per sapere che sia una base.\nSupponiamo per assurdo che siano dipendenti. Allora esiste un vettore linearmente dipendente, e quindi esprimibile come combinazione lineare di altri vettori 3.2.4, ma se √® una combinazione lineare allora non √® pi√π l\u0026rsquo;insieme minimale di generatori (cio√® questo vettore non ha contributi sullo spazio) √® il teorema 3.1.8 qed.\nCaso 1 $\\impliedby$Se ho un insieme massimale di vettori linearmente indipendenti, voglio dimostrare che genera V.\nAllora per massimalit√† appena aggiungo un vettore, ho un insieme di vettori linearmente dipendenti, allora mi posso trovare una combinazione lineare con coefficienti non nulli tali che la combinazione sia 0.\nquindi $\\lambda_1v_1 + ...+ \\lambda_nv_n + \\beta w = 0$, e per qualunque vettore $\\omega$ so che $\\beta \\neq 0$ perch√© altrimenti si ha l\u0026rsquo;assurdo in quanto i vettori $v_1, ..., v_n$ sarebbero dipendenti. Se √® diverso da 0 allora posso esprimerlo come combinazione lineare di altro, quindi riesco ad ottenere l\u0026rsquo;intero spazio.\n2.1.4 Prop. creazione di base da vettori generatori Questo teorema ci permette di ricavare una base partendo da un insieme di vettori che generino l\u0026rsquo;intero spazio vettoriale. L\u0026rsquo;idea principale √® che possiamo trovare dei vettori che sono combinazioni lineari di altro e continuare a toglierli finch√© non trovo la base.\nEnunciato\nSia $v_1... v_n$ un insieme che genera $V$, allora un sottoinsieme di questi vettori generatori sono una base per $V$.\nDimostrazione\nSe i vettori sono linearmente indipendenti allora ho la base, se sono dipendenti allora sia $\\omega$ il vettore dipendente, allora si pu√≤ scrivere come combinazione lineare per la 3.2.4, e per la proposizione 3.1.8 lo spazio generato da tali vettori √® esattamente lo stesso.\nPosso continuare con questo argomento finch√© non ottengo la base o non ci sono pi√π vettori. (nel caso in cui √® lo spazio nullo).\nNota\nSi pu√≤ fare anche il contrario, da un insieme di vettori linearmente indipendenti posso aggiungere vettori fino a quanto non creo una base, l\u0026rsquo;algoritmo √® molto simile, ma al contrario.\n2.1.5 prop 4.2.1 Teorema del completamento Enunciato\nDa una base $v_1,..., v_n$ e un insieme di vettori linearmente indipendenti $\\omega_1, ..., \\omega_m$ appartenenti allo stesso spazio allora so che $m \\leq n$, inoltre √® possibile aggiungere vettori a $\\omega$ in modo che sia una base, questa base ha la stessa cardinalit√† della base si sopra\nDimostrazione (non richiesta)\nSi utilizza la proposizione precedente al contrario probabilmente.\n2.2 Dimensione Il concetto di dimensione √® strettamente correlato con il concetto di base. Possiamo intendere la dimensione come il minimo insieme di coordinate necessarie per creare l‚Äôintero spazio (questa √® una definizione che c‚Äô√® anche nel teorema di caratterizzazione delle basi). Perch√© alla fine saranno le coordinate che ci interessano.\n2.2.1 prop. 4.2.2 Basi hanno stessa dimensione DIMENSIONE (chiede) C\u0026rsquo;√® il teorema del completamento\nEnunciato\nDato uno spazio vettoriale finitamente generato, allora tutte le sue basi hanno la stessa cardinalit√†, questo numero di chiama dimensione dello spazio vettoriale, ed √® una propriet√† caratterizzante di essa.\nDimostrazione\nMeglio una dimostrazione cos√¨: in quanto b1 √® base e b2 √® linearmente indipendente ho (per completamento) che $n \\geq m$, in quanto b2 √® base e b1 linearmente indipendente ho che $n \\leq m$, quindi $n = m$\n2.2.2 Basi canoniche Ci sono certe basi che sono particolarmente interessanti, le chiamiamo basi canoniche, e sono definite come\n$e_i = \\{0...0_{i-1},1,0_{i + 1},..., 0_n\\}$ ovvero ho un 1 alla n esima posizione\n2.2.3 prop 4.2.4 relazioni fra dimensioni Dato uno spazio vettoriale $W$e un suo sotto spazio $V$ si ha\n$dim(V) \\leq dim(W)$ $dim(V) = dim(W) \\iff V=W$ Dimostrazione\nCaso 1 Sia m la dimensione di $V$ allora la sua base ha m vettori che sono linearmente indipendenti. Questi vettori sono anche presenti in $W$, che poniamo abbia dimensione n, allora per il teorema del completamento ho che $m \\leq n$\nCaso 2 $\\impliedby$ questa freccia √® ovvia, se sono la stessa cosa hanno la stessa dimensione\nCaso 2 $\\implies$\nscambiare W e V in questa dimostrazione\n2.2.4 prop 4.2.6 Dimensione, base, lin ind, e generazione (3)! Enunciato\n3 to 1\nse ho un insieme di vettori che generano uno spazio allora posso togliere vettori fino a quando ho una base (ossia sono linearmente indipendenti). Ma per la dimensione ho che devo avere necessariamente n vettori, quindi un insieme di n vettori linearmente indipendenti √® gi√† una base.\n2 to 1\nL\u0026rsquo;argomento presente qui √® uguale alla superiore 4.2.4 (quindi dire per il completamento che posso espandere e ottenere una base) Anzi potresti direttamente utilizzare questa per dimostrare sto punto\n2.2.5 Coordinate di un punto in uno spazio vettoriale Sia data una base per uno spazio vettoriale $v_1, ..., v_n$, allora ho che posso scrivere qualunque vettore $\\omega$ nello spazio in un unico modo, moltiplicando per corrispondenti fattori. Questi fattori sono unici.\nDimostrazione unicit√†\n2.3 Algoritmo di gauss rivisitato 2.3.1 A.G non cambia sottospazio riga (non richiesta) L\u0026rsquo;intuizione per questo √® abbastanza ovvio, sto solamente applicando combinazioni lineari fra le righe, quindi sto sempre prendendo vettori che appartengono a questo spazio, non le sto modificando, questo giustificherebbe anche il motivo per cui l\u0026rsquo;algoritmo di gauss √® utile.\nDimostrazione\nla proposizione da utilizzare √® lo span che non cambia se aggiungo e tolgo una combinazione lineare\n2.3.2 Indipendenza delle righe non nulle Dimostrazione non fatta.\n","permalink":"https://flecart.github.io/notes/base-e-dimensione/","summary":"2.1 Basi 2.1.1 Definizione Un insieme di vettori $v_1,...,v_n$ sono basi di uno spazio vettoriale $V$ se sono soddisfatte queste propriet√†\n$V = \\langle v_1,...,v_n\\rangle$ $v_1,...,v_n$ sono linearmente indipendenti Dalla propriet√† 2 potremmo anche dire che √® il minimo insieme di vettori necessario per avere questa base.\nFinitamente generato\nSe l\u0026rsquo;insieme dei vettori nella base √® finito allora posso dire che √® finitamente generato\nMa possiamo trovare anche spazi che non sono finitamente generati come $\\R[x]$ che non hanno un numero finito di basi (perch√© dipende dal grado dei polinomi che pu√≤ essere infinito).","title":"Base e dimensione"},{"content":"Definizione Caratteristiche Variabili Dominio per ogni variabile Costraints per ogni variabile Queste tre sono elementi che definiscono un problema di soddisfazione delle restrizioni, una soluzione √® un assegnamento di variabili che soddisfi ogni restrizioone e sia all‚Äôinterno del dominio\nConsistenza Vogliamo andare a limitare il dominio valutando le consistenze possibili\nConsistenza del punto Si pu√≤ dire che un punto sia consistente se le sue variabili possibili non viola nessuna restrizione unaria: eg. se ho N e ho la restrizione n ‚â• 0, allora avere tutto N √® inconsistente nel punto.\nConsistenza ad arco Questo tratta delle restrizioni binarie: una coppia di punti si dice che √® arco consistente se per ogni variabile nel primo dominio esiste sempre una variabile nel secondo dominio che mi soddisfa la restrizione.\nk-consistenze Si pu√≤ estendere il concetto della consistenza per avere un numero arbitrario di nodi, questo dovrebbe causa per√≤ un costo del calcolo molto maggiore.\nAC-3 algorithm Questo √® un algoritmo per forzare la consistenza ad arco, praticamente va di forza bruta a imporre la consistenza su un arco, se i domini vengono aggiornati gli archi vicini vengono rimessi in coda, in modo da essere sicuri che restino ancora consistenti (infatti eliminando certe variabili potrebbero aver perso di consistenza)\nLa ricerca di una soluzione Backtracking Euristiche della scelta dei valori Minimum remaining Values\nvorremmo che la ricerca della variabile non assegnata fallisca il prima possibile, quindi scegliamo la variabile con pi√π vincoli, o meno valori assegnabili.\nLeast constraining value\nSe vogliamo una unica soluzione che soddisfa vogliamo scegliere variabili che hanno meno probabilit√† di fallire.\nForward check\nAbbastanza simile ad AC-3, toglie dei valori che non possono esserci??? boh cose simili.\n","permalink":"https://flecart.github.io/notes/costraint-satisfaction-problems/","summary":"Definizione Caratteristiche Variabili Dominio per ogni variabile Costraints per ogni variabile Queste tre sono elementi che definiscono un problema di soddisfazione delle restrizioni, una soluzione √® un assegnamento di variabili che soddisfi ogni restrizioone e sia all‚Äôinterno del dominio\nConsistenza Vogliamo andare a limitare il dominio valutando le consistenze possibili\nConsistenza del punto Si pu√≤ dire che un punto sia consistente se le sue variabili possibili non viola nessuna restrizione unaria: eg.","title":"Costraint Satisfaction Problems"},{"content":"Introduzione Definizione grammatica regolare üü© Definizione\nIn pratica posso avere solamente come terminali a, oppure un suffisso a su un non terminale.\nQueste grammatiche sono interessanti perch√© √® molto facile costruire un automa che sia in grado di riconoscere questo linguaggio.\nSeguendo una definizione pi√π lasca possono anche accettare dei nonterminali epsilon\nEspressione regolare a NFA üü© Questa sezione √® anche presente in Automi e Regexp, per√≤ √® riportata qui cos√¨ c‚Äô√® l‚Äôinsieme di tutte le cose in un unico posto.\nEnunciato\nDimostrazione\nMi creo un automa che riconosce in modo ricorsivo (per tutte le produzioni della grammatica delle regexp\nGuarda lezione 7\nDa grammatica regolare a NFA (!) üü© In modo simile a quanto si fa per la dimostrazione per espressioni regolari rappresentabili come NFA anche questa √® cos√¨\nDimostrazione\nDa DFA a grammatica regolare (chiede) üü© Dimostrazione\nGrammatica regolare a linguaggio regolare üü© Dimostrazione molto informale\nPraticamente l\u0026rsquo;idea principale √® fare rimpiazzamenti ricorsivi finch√© non lo ho in una forma bella.\nRiassunto tutte le equivalenze NFA, DFA, grammatiche ed espressioni.\nRiassunto delle equivalenze üü©- C‚Äô√® una precisa domanda che chiede di discutere in modo generale le equivalenze, quindi metto anche questo doc.\nSlide\nCostruzione dello scanner Introduzione üü© Slide\nPer fare questa cosa rientra il problema di creazione della DFA da NFA pi√π piccola possibile!.\nNon so come si faccia, ma almeno ora sai che esiste questo problema.\nAd intuito possiamo andare ad affermare che un automa √® minimo quando non ci sono due stati equivalenti ossia, sempre ad intuito, non li possono compattare in uno, quindi non ho ridondanza di stati.\nEsempio di minimizzazione\nEquivalenza ed indistiguibilit√† (di stati) üü© Slide\nOssia se due stati sono in grado di riconoscere esattamente lo stesso linguaggio, sono equivalenti. Ma ogni stringa del linguaggio √® una cosa difficile da gestire, per questo motivo provo a dimostrare che non siano equivalenti, ossia lo stato di accettazione per una stessa stringa sia diversa partendo dalla stringa vuota\nSlide strategia\nProvo a togliere tutti\nFamiglia di relazioni (5) üü©- Slide\nIn pratica sto andando a guardare se lo stato finale √® lo stesso o meno, partendo dalla stringa nulla, poi andando avanti a costruire altre, e continuando a togliere se lo stato finale ora √® diverso.\nQuesta √® una relazione di equivalenza.\nPropriet√†\nDimo propriet√† 4, se non cambia ho finito üü® Ossia se non tolgo pi√π coppie in un passo, allora il mio algoritmo dovr√† essere finito.\nDimostrazione\nEsempio di applicazione dell‚Äôalgoritmo di minimizzazione\nMinimizzazione In questa parte andremo a trattare definizioni e algoritmi utili a minimizzare un automa DFA (nel senso di meno stati possibili).\nAlgoritmo degli stati equivalenti üü© Algos\nPraticamente vado a marcare per tutte le cose possibili (partendo dalla relazione 0). Vado a marcare se non appartengono alla stessa relazione di equivalenza (ossia sono diversi). E se i percorsi pi√π lunghi finiscono su altre celle gi√† occupate, allora marco anche questo, con un segno diverso, per dire che non sono equivalenti per un certo percorso pi√π lungo.\nDimostrazione correttezza algoritmo üü®+ Enunciato di terminazione e correttezza dell‚Äôalgoritmo\nDimostrazione di sopra\nTerminazione √® dipendente dalla propriet√† 4 a 5, cio√® che se non cambia a un passo, allora non cambia a nessun passo, e la 5 che mi dice che ad ogni passo ne marco almeno uno (e questi sono numeri finiti).\nDistinguibilit√† se la casella marcata allora esiste un percorso che termina in modo diverso da uno rispetto all\u0026rsquo;altro, in altro termine esiste una stringa che √® riconosciuta da uno ma non √® riconosciuta da un altro! (ma se lo ho marcato in questo modo allora √® ovvio che succeda questo!).\nAutoma minimo (4) üü© Questa definizione tratta le caratteristiche formali di un automa minimo costruito da un DFA valido.\n(minimizzare gli stati, la funzione di transizione e gli stati accettati).\nIn pratica nello stesso stato dell‚Äôautoma minimo ci metto tutti gli stati equivalenti ad essa, in questo senso di minimo!\nDefinizione\nProbabilmente in questo passo intendevo sono 3 le cose nuove differenti\nStati possibili devono essere gli equivalenti fra tutti. Transizioni √® ora fatto su stati equivalenti Stato iniziale √® la classe di equivalenza sullo stato iniziale Gli stati accettati sono le classi si equivalenza sugli stati finali.. Alfabeto √® lo stesso. Equivalenza automa minimo e originale (non chiede) üü®‚Äî Slide linguaggio riconosciuto √® lo stesso, ed √® anche il minimo\nDimostrazione\nIn pratica per dimostrare il minimo suppongo che esista un automa con ancora meno stati, questi due (il minimo nuovo e il minimo costruito) devono riuscire a riconoscere esattamente le stesse cose, ma essendo questo con ancora meno, deve essere che il minimo costruito abbia due stati equivalenti, cosa che non pu√≤ succedere col nostro algoritmo\nLex/Flex e Yacc Questi sono analizzatori lessicali che prendono in input un file di definizioni regolari e restituisce un programma in C che riesca a riconoscere questi automi\nDiagramma semplificativo di quanto fa\nStruttura di file Lex (3) üü© Slide riassunto\nDichiarazioni\nPraticamente in sta parte ci sono le definizioni regolari che abbiamo discusso pi√π sopra nello stesso documento che ci rende la scrittura di espressioni regolari molto pi√π semplice\nRegole\nQui definisci tutte le espressioni regolari che ti servono. Definite in schema di\nPattern ‚Üí azione\nOssia se un pattern √® riconosciuto, esegui una azione.\nFunzioni ausiliarie\nNel caso in cui le azione sono tropp complesse una serie di funzioni ausiliare possono essere molto utili\nFunzionamento di Lex (4) üü®+ In questa parte descriviamo brevemente le regole che il lex utilizza per decidere cosa fare.\nMatcha seguendo le regole A parit√† di matching diversa, sceglie quello il matching pi√π lungo A parit√† di lunghezza di matching, sceglie quello listato prima Se non matcha, viene dato in output la stringa inalterata Esistono funzioni per gestire i match, la stringa matchata, la lunghezza della stringa matchata (yytext e yylenght) Esistono funzioni per matchare di pi√π o di meno, come yymore e yyless. Yacc üü© A differenza di Lex, Yacc si occupa di generare la sintassi.\nQuesto √® un analizzatore sintattico, quindi sar√† trattato nel dettaglio in un capitolo successivo. Per ora basta capire che i processi di scanning e parsing sono eseguiti pi√π o meno in parallelo, √® il parser che chiede ogni volta il token, evitando di avere in memoria rappresentazioni differenti della stessa cosa.\nyylval sono variabili comuni che permettono di scambiare informazioni.\nyylex() √® cchiamato da yacc nel momento di richiesta di lessemi\nPumping Lemma (!!!) üü© Enunciato\nDimostrazione\nNegazione del pumping lemma\nPropriet√† dei linguaggi regolari (5) üü© unione concatenazione stella di Kleene Complemento Intersezione Dimostrazione\n","permalink":"https://flecart.github.io/notes/grammatiche-regolari/","summary":"Introduzione Definizione grammatica regolare üü© Definizione\nIn pratica posso avere solamente come terminali a, oppure un suffisso a su un non terminale.\nQueste grammatiche sono interessanti perch√© √® molto facile costruire un automa che sia in grado di riconoscere questo linguaggio.\nSeguendo una definizione pi√π lasca possono anche accettare dei nonterminali epsilon\nEspressione regolare a NFA üü© Questa sezione √® anche presente in Automi e Regexp, per√≤ √® riportata qui cos√¨ c‚Äô√® l‚Äôinsieme di tutte le cose in un unico posto.","title":"Grammatiche Regolari"},{"content":"This is my first blog post. I\u0026rsquo;s the first time I\u0026rsquo;m writing something that would be published on my personal web-page. Programmers are used to write hello world programs as first line when they first approach a new language. It\u0026rsquo;s been a long tradition. This is something similar for me in this moment as I write this.\nI\u0026rsquo;m writing the first blog post in my website, I still have no idea of what I will be talking about in the next posts, they will probably be some thoughts and ideas of things i learn along the way, likely related to tech or University.\nAnyway I aim to write some high-quality content, something the other people would consider as valuable. This first post is just useful to test the functionalities and looks of this small platform.\nSee you in the next posts.\nUPDATE\nI still haven¬¥t got in the habit to write blog post in a regular manner, but i think now i have an activity that could help me to learn more about my fields of interest and also write more on my blog!\nI think that a two-week study of whatever subject I\u0026rsquo;m interested in and write a post for a week in which i explain what I have learned and my own thoughts about it could be a nice idea\nI\u0026rsquo;ll update this when I have more ideas about this.\n","permalink":"https://flecart.github.io/hello-world/","summary":"First blog post","title":"Hello World"},{"content":"Socialit√† dello sviluppo del software (3) üü®- Si assume che\n√à difficile assegnarsi i compiti, bisogni di utenti, tempi di consegna (+ persone difficile) √à facile scrivere software (almeno software classico, e non computazione scientifica) La gente sia brava tecnicamente che socialmente √® una cosa rara VS Waterfall (3) üü®++ Pianificare tutto come viene descritto nel modello del waterfall non √® possibile. Per i seguenti motivi\nNon √® chiaro cosa vuole l\u0026rsquo;utente finale (quindi sarebbe meglio avere feedback continuo). Non si sa gi√† dall\u0026rsquo;inizio cosa √® che interessa all\u0026rsquo;utente, per questo motivo si consegna il prodotto passo passo per feedback continuo dato che i requisiti cambiano nel tempo. Giustificazione agile alto livello üü© Vorremo una metodologia che permetta una iterazione ossia un cambio continuo specifiche in funzione di un utente, vogliamo fare le cose a seconda di quanto vuole l\u0026rsquo;utente.\nMetodologia agile La metodologia AGILE √® nata basandosi sulla giapponese Toyota system.\nEtica (!!!) (4) üü®++ Creati verso l\u0026rsquo;anno 2000 https://agilemanifesto.org/iso/it/manifesto.html\nIndividui e interazioni pi√π che a processi e strumenti\nSoftware che funziona pi√π che a documentazione completa\nCollaborazione col cliente pi√π che a negoziazione contrattuale\nReagire al cambiamento pi√π che a seguire un piano\nUmani :)\nDal punto di vista della burocrazia, dovrebbe essere sempre ben documentato il software.\nSoftware √® difficile da tutelare perch√© non √® tangibile come cosa.\nLa possibilit√† di negoziare tutto, invece che seguire un piano di tre anni diciamo.\nPrincipi (12) üü® Proviamo a cercare di commentare questi principi uno per uno\n√à la regola per user-centered philosophy. il fatto che il gruppo deve essere coeso al fine di fare un buon lavoro. La capacit√† di adattamento. Il fatto che deve funzionare perch√© alla fine questo serve all\u0026rsquo;utente finale. Si ribadisce il punto 4 perch√© quello che deve essere misurato √® il funzionamento del codice. Ribadisce l\u0026rsquo;importanza del team, il fatto che devono essere motivati. Regole imposte dall\u0026rsquo;alto sono il male, il team si dovrebbe organizzare da solo riguardo architetture e requisiti. (non sempre avere uno che fa tutto √® di aiuto). Faccia a faccia √® meglio rispetto ad online. Sostenibile nel senso di investimento di risorse, senza sprecare risorse e che siano sufficienti per fare quello che devi fare. Lo interpreto come fare cose che dovrebbero essere modulari e facilmente estendibili. Semplice √® pi√π facile da leggere e capire. La capacit√† di cambiare e adattarsi a seconda di come si evolve la situazione. (scrum master prover√† a far capire cosa c\u0026rsquo;√® da fare capire diciamo). Extreme programming The XP life-cicle (4) üü© Questa √® stata una delle prime forme di sviluppo iterativo che sono esistite, si pu√≤ dire che √® un precursore di Scrum Method.\nIn contrario rispetto: se funziona quanto basta, Defines features, che sono le cose che vorrebbe Poi il developer stima il costo per l\u0026rsquo;implementazione, si deve alla fine dare un prezzo al software. Customer sceglie fra quelle che pu√≤ Poi si costruisce Valori XP (4) üü®++ semplicit√† (vedi 11 #Principi (12) üü®) comunicazione (ossia collaborazione internamente) feedback (comunicazione con l\u0026rsquo;utente) coraggio nel modificare comportamento non funzionato in passato, quindi sempre relazionato sulla capacit√† di cambiamento Modificare e buttare parte del codice. Che si traducono in modo effettivo in:\nTutti devono capire specifiche e cose riguardo il codice. Usato per gruppi di piccola grandezza Ci deve essere un rappresentante Other practices Minimum Viable Product üü© L\u0026rsquo;idea √® non costruire alla fine un qualcosa di funzionante, ma partire con gi√† con qualcosa di funzionante e reiterare, migliorando alcuni pezzi Quando si avr√† un MVP, allora si potrebbe anche fare un test di accettazione, ossia mostrare quanto fatto al cliente e ricevere un primo feedback.\nUser stories Definition of stories üü© Vengono descritte ci√≤ che gli utenti possono o non possono fare utilizzando le user stories diciamo. Secondo il prof. Missiroli queste user stories devono anche avere un input e un output. (che non √® sensato per√≤.). Poi devono essere stimate e prioritizzate\nPriorit√† e story points üü© Queste storie solitamente sono caratterizzate da un ordine di priorit√† che descrive ci√≤ che deve essere fatto e ci√≤ che non dovrebbe diciamo. Sono utili perch√© aiutano a definire un ordine in cui andare ad affrontare le varie task, definito dal singolo cliente. Gli sviluppatori fanno poi una stima delle risorse utilizzate chiamate story points per cercare di dare una stima del costo in sforzo per sviluppare ci√≤. Il processo di scelta delle task che dovranno essere fatte si chiama planning game, ed √® fatta all\u0026rsquo;inizio di ogni iterazione.\nFormato preferito (3) üü©- Questo √® il formato preferito per andare a descrivere delle user stories (con l\u0026rsquo;aspetto della motivazione in pi√π per aiutare il programmatore a capire meglio cosa deve andare a fare).\nTipo di utente Obiettivo Motivazione (non funzionale per il codice, ma buono per immedesimarsi in quello che dovremo fare). Questo √® importante, ci aiuta a capire bene in che modo sia l\u0026rsquo;importante per il cliente, cio√® quello che dovr√† essere implementato.\nCarpaccio di elefante Secondo Missoroli √® meglio che le storie siano verticali ossia che spaziano praticamente ogni campo (un po\u0026rsquo; di tutto per l\u0026rsquo;appunto, ma che allo stesso tempo siano molto specifiche), per me non ha molto senso perch√© sono due cose che vanno uno contro l\u0026rsquo;altro, non vogliamo che US tocchi tutto. e hanno\nstima priorit√† Condizioni di accettazione (test) oltre alle singole motivazioni Ma secondo me non ci ha capito niente\u0026hellip;\nMoscow Method (4) üü©\u0026ndash; Questo √® un metodo utilizzato per scegliere quali user stories andare ad implementare.\nMust: funzioni che DEBBONO esserci nel prodotto Should: funzioni che DOVREBBERO esserci Could: funzioni che POTREBBERO esserci Wont: funzioni che NON INSERIREMO nella versione attuale https://www.agilebusiness.org/page/ProjectFramework_10_MoSCoWPrioritisation\nBacklog üü© √à l\u0026rsquo;insieme dei task (ossia delle #User stories üü®) che devono essere fatte, e hanno delle priorit√†, che ad ogni iterazione possono cambiare l\u0026rsquo;ordine.\nQuesta parte viene solitamente divisa in due perch√© una √® nel backlog, l\u0026rsquo;altro quello che si vuole implementare durante lo sprint.\nEpiche üü© Saranno alla fine sempre delle user-stories, ma dato che sono molto grandi solitamente sono divisi in task pi√π semplici.\nTask üü© User stories sono richieste dall\u0026rsquo;utente, mentre le task sono dei pezzi utili per la production, qualcosa che √® lecito per lo sviluppatore, ma non ovvio per il cliente.\nFramework Invest The INVEST framework is a set of criteria used to assess the quality of user stories in Agile development. It was introduced by Bill Wake as a reminder of the characteristics that good user stories should possess. The INVEST acronym stands for:\nIndependent: Each user story should be independent, meaning that it can be developed, tested, and delivered without relying on other stories. This helps in prioritizing and sequencing stories based on business value. Negotiable: User stories should not be overly detailed or rigid. They should allow for negotiation between the development team and the product owner, fostering collaboration and adaptation as the project progresses. Valuable: Each user story should deliver value to the end user or customer. It\u0026rsquo;s important that the work being done is meaningful and contributes to the overall goals of the project. Estimable: The team should be able to estimate the effort required to implement a user story. This helps in planning and prioritizing work effectively. If a story is too vague or complex to estimate, it may need to be broken down into smaller, more manageable pieces. Small: User stories should be small enough to be completed within a single iteration or sprint. This helps in maintaining a steady and predictable pace of development, and it allows for frequent releases of working software. Testable: There should be clear criteria for determining when a user story is complete. This ensures that the development team and stakeholders have a shared understanding of what needs to be done and can confirm that the story meets the specified requirements. By applying the INVEST criteria, Agile teams aim to create user stories that are well-defined, manageable, and focused on delivering value to the customer. This, in turn, contributes to the overall success of the Agile development process.\nCasi d\u0026rsquo;uso Descrizione casi d\u0026rsquo;uso üü© I casi d\u0026rsquo;uso sono un metodo per descrivere i requirements vedi Requisiti e backlog del software, tali per cui abbiano il massimo valore possibile. Sono un modo diverso rispetto alle user stories descritte in Modelli AGILE per fare questo. Definisce un scenario dettagliato su esattamente cosa vuole del prodotto, il contesto in questo caso √® molto importante.\nDa quanto mi sembra di aver capito √® proprio una descrizione passo passo per ogni cosa che vuole fare l\u0026rsquo;utente.\nSolitamente questo viene rappresentato con una specie di UML, come descritto in Unified Modeling Language.\nNOTA: non c\u0026rsquo;√® nessun concetto di tempo all\u0026rsquo;interno di questo diagramma, a differenza di sequence e collaboration diagrams.\nI casi d\u0026rsquo;uso sono pi√π utili a descrivere il contesto in cui il software lavora, e per comprendere in che modo pu√≤ aiutare i clienti con il sistema software.\nL\u0026rsquo;attore üü© Sono enti, umani o macchine, che agiscono su un sistema e da questo ottengono valore (servizio, calcolo o simili). Solitamente questi sono distinti in business e tecnici, i primi sono direttamente per clienti, i secondi sono operazionali, per far funzionare bene tutto, sono pi√π interne come cose.\nEstensioni e inclusioni di casi d\u0026rsquo;uso Sono quando alcuni utilizzi devono avere delle funzionalit√† necessarie in questo caso includes, oppure funzionalit√† che sono estese da qualcosaltro, l\u0026rsquo;unica cosa che cambia √® il verso da cui parte la freccia.\nTest driven development Filosofia TDD üü© Solitamente il test per una funzione viene scritta dopo che il codice √® gi√† stato scritto. Questo porta a scrivere codice che spesso non √® testabile Un approccio alternativo √® partire direttamente dalle specifiche ed andare ad implementare del test prima del codice in pratica il codice ci saranno solamente backbones diciamo. Test di accettazione üü© Sono dei test (quindi sempre nella verifica che il software soddisfi i requisiti o meno, non automatici, che vengono fatti insieme al cliente, in modo tale per cui alla fine la user story venga accettata, questo √® solitamente chiamato User acceptance testing perch√© √® fatto col cliente.\nRefactoring Migliorare il codice esistente mantenendo la funzionalit√† inalterata\nSolitamente √® una cosa necessaria, perch√© il codice evolve continuamente, utile a diminuire il technical debt.\nVantaggi refactoring (2) üü© Alcuni esempi possono essere\nrenderlo pi√π leggibile Astrarre dove necessario Buttare codice non necessario Semplificare codice con stessa funzionalit√†. semplicit√† di mantenimento Astrazioni Operazioni di refactoring classiche üü© Aggiungere, cancellando o rinominando Spostare classi nel codice e nella catena di derivazione. Su classi, membri, funzioni statiche, data temporaneo. Pair programming Dinamiche driver navigator üü© Driver and navigator, uno che scrive il codice e l\u0026rsquo;altro che legge e guarda se ci sono alcuni difetti o modi in cui si pu√≤ scrivere il codice (solitamente sono scambiati durante la stessa giornata)\nPlus: propriet√† collettiva del codice, dovrebbe essere famigliare a tanti nel progetto (forse tutti) Propriet√† collettiva del codice üü®++ Tutti dovrebbero essere in grado di capire e modificare secondo necessit√† una parte del codice.\nSe codice √® complesso non verr√† mantenuto o usato.\nAltri argomenti Convenzioni di codifica TODO:\nSostenibilit√† dello sviluppo TODO:\nIntegrazione del codice (!) üü© Ossia fare small releases, giorno per giorno viene integrata una nuova funzionalit√† che viene accettata e validata dal team. Questo poi √® una cosa normalissima in Scrum Method, in cui si vanno proprio per piccoli rilasci.\nStanding Meeting (3) (!) üü© Cosa fatto ieri Cosa si vuole fare oggi Quali sono i problemi maggiori, √® per portare il team tutti sulla stessa pagina. ","permalink":"https://flecart.github.io/notes/modelli-agile/","summary":"Socialit√† dello sviluppo del software (3) üü®- Si assume che\n√à difficile assegnarsi i compiti, bisogni di utenti, tempi di consegna (+ persone difficile) √à facile scrivere software (almeno software classico, e non computazione scientifica) La gente sia brava tecnicamente che socialmente √® una cosa rara VS Waterfall (3) üü®++ Pianificare tutto come viene descritto nel modello del waterfall non √® possibile. Per i seguenti motivi\nNon √® chiaro cosa vuole l\u0026rsquo;utente finale (quindi sarebbe meglio avere feedback continuo).","title":"Modelli AGILE"},{"content":"Possiamo classificare tre aree generali quando si parla di sicurezza informatica:\nHardware Software human-ware. Non tratteremo in particolare esattamente come ogni campo viene declinato, per√≤ possiamo\nUna altra tendenza generale √® che pi√π √® complessa pi√π √® insicura. e questo senso di insicurezza cresce in modo maggiore rispetto al lineare.\nSecurity principles Open Design perch√© cos√¨ pu√≤ essere scrutata da pi√π persone Economy of mechanism spiegata sotto. Fail-safe defaults questo molto importante perch√© molti sistemi hanno dei default che possono essere exploitati. Complete mediation: cos√¨ abbiamo qualcosa che tracka tutti gli accessi, che controlla gli accessi. Least privilege questo va a braccetto con il fail-safe. Privilege separation cos√¨ possiamo mettere in modo indipendente un privilegio per qualcos\u0026rsquo;altro. CIA properties Ne abbiamo parlato in modo leggermente inverso in Sicurezza delle reti e in Theoretical Notions of Security. In questo caso sono\nAvailability Integrity Confidentiality √à cambiata solamente l‚Äôavailability, ossia la disponibilit√† in confronto alla sicurezza delle reti, in cui c‚Äôera l‚Äôautenticazione. Availability significa la disponibilit√† del servizio agli utenti, fare un DDoS per esempio √® una violazione di questo genere. La cosa difficile √® garantire tutti e 3.\nPoi ci sono anche AAA ossia\nAutenticazione Autorizzazione Accounting (logging delle tue operazioni). Violazione Nome Disclosure Alteration Denial of service Nel caso dell‚Äôautenticazione sarebbe il phishing, furto d\u0026rsquo;identit√† diciamo. Sistema politica e meccanismi Gi√† descritta in Architettura software del OS. l‚Äôidea √® la stessa, separazione meccanismi e la messa in atto di queste, solo che ora siamo in ambito sicurezza ora e non implementazione del kernel. L\u0026rsquo;idea generale √® che\nMeccanismo implementa la singola feature, come permesso di scrittura se possiedi certa flag, capability etc. Politica o policy, decide effettivamente quale meccanismo usare e in quale modo. Questo decoupling dovrebbe aiutare a rendere la cosa pi√π comoda. Crittografia √à una nota importante, ma in questa sede non andremo a trattarle Anche questo √® stato descritto in Sicurezza delle reti, pubbliche private, simmetriche asimmetriche, DES AES RSA e ora curve ellittiche etc. Puoi approfondire in OTP and Stream Ciphers, Block Ciphers e Asymmetric Cryptography. Simmetrica, in cui sapere la chiave sai tutto.\nTipologie di attacchi üü® Divisione per attivit√† dell‚Äôattaccante Per veicolo dell\u0026rsquo;attacco (se da dentro o da fuori) Obiettivi dell‚Äôattacco (quindi gravit√† della compromissione della macchina diciamo.\nAttacchi soliti Buffer overflow üü© Confrontare quanto presente con Memory Corruption, in cui andiamo ad approfondire molto meglio i dettagli degli attacchi di basso livello.\nTime of Check Time of use üü© Tipo access ha detto, quando non √® atomico il check e l‚Äôutilizzo, nel mezzo il file potrebbe essere cambiato\nTrojan horse üü© Virus e batteri üü® Solitamente questi virus hanno comportamenti classici, e si pu√≤ estrarre una firma, questo √® quello con cui utilizzano antivirus per checkare.\nAutenticazione Memorizzazione password üü© Salt Parlare di etc passwd ed /etc/shadow Abbiamo fatto qualche laboratorio carino sul cracking delle password l\u0026rsquo;anno seguente al corso di cybersecurity.\nLogin spoofing üü© Sniffersüü®+ Challenge based üü© Possiamo osservare i challenge based in Wireless attack vectors quando si parla di porte automatiche e\nSmart card and physical objects üü©- Pluggable Authetnication Moduleüü® \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza OS/Untitled 6.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza OS/Untitled 6\u0026quot;\u0026gt; I campi sono 2/3, si indica per chi si utilizza la policy, poi politiche della policy (se passa o meno o simili) e poi qualcosa di pam da utilizzare\nAutorizzazione Vogliamo dare i permessi alle persone (chi pu√≤ fare cosa). Solitamente dividiamo in tre possibili parti separate\nSoggetto: (a chi stiamo dando la possibilit√† di accedere alle nostre risorse?) Oggetto: cosa stiamo dando come permesso? Diritto: che genere di permesso stiamo dando al soggetto verso l\u0026rsquo;oggetto? Principi d‚Äôautorizzazione(4)üü®- Domini di accesso e ACL üü© Definiamo una riga per utente e in questa riga mettiamo tutti i permessi per questo utente.\nSlide Access control list\nExtended ACL Quando nelle acl Praticamente ogni posso associare dei permessi aggiuntivi che vanno ad ogni user del singolo gruppo. Poi queste sono passate da delle mask. In pratica mi permette di avere pi√π controllo sui permessi. In linux se viene utilizzato questo c‚Äô√® un + alla fine della lista permessi. si utilizzano comandi come getfactl per gestire queste credo.\nCapabilityüü© C‚Äô√® il concetto di capability ossia ogni risorsa deve essere associata una serie di diritti d‚Äôaccesso. Quando viene mantenuto in lato utente, in pratica viene cifrata con la chiave privata del root, e questo viene sempre verificato. (solitamente nei sistemi distribuiti viene utilizzato questo metodo (posso eliminare la capability)\nMa come eseguire la revoca della capability di questi servizi?\nEsempi di capabilities sono cookie, o file aperti. (in Unix sono molto comuni).\nFile descriptor table Quando un processo accede a un file, il file descriptor table non √® altro che una tabella con le capability del processo su quella risorsa. (descrive cosa ci puoi fare). La verifica del permesso √® fatta solo una volta (molto alta solitamente), ma quando √® messa nella tavola puoi farci tutte le letture e scritture che vuoi, ammortizzando il costo della verifica iniziale.\nRevoca delle capabilities Rimuovere una capability data √® spesso molto difficile. Abbiamo i quattro casi. Effective real and saved idsüü© Saved user e group id sono gli user id precedenti a quando si fa la chiamata setuid e simili, sono utilizzati per ripristinare il servizio. Si possono fare attacchi Toc Tou anche su questi checks (real sono quelli effettivi, dell‚Äôutente, mentre effettive sono i permessi utilizzati durante il momento di check).\nSpecial permission bits Sono\nSetuid su dir non fa niente, su file rende l\u0026rsquo;esecuzione come quello principale. Setgid su file rende possibile eseguire come gruppo, sulla directory d√† ai file creati qui lo stesso gruppo. Sticky-bit (permette l\u0026rsquo;eliminazione e movimento di file solamente al proprietario, ma il resto permette di fare come al solito) Discretionary Access Control DAC √® quello che solitamente viene usato, l\u0026rsquo;owner della risorsa d√† il permesso, che in pratica √® il sistema classico con gli ACL descritto sopra. Discretionary perch√© √® il singolo utente che decide se dare i permessi ad altri o meno\nMandatory Access Control MAC, mandatory access control (mandatory perch√© √® il sistema che definisce le regole e quelle sono, non le puoi cambiare), definisce delle regole generali del sistema e possono essere di due casi (quindi quando abbiamo MAC, ci sono ruoli di default.`\nBell La-padulaüü© Si basa sul principio che informazione va su (scrittura di nuove informazioni). Per esempio questa √® una cosa che √® stata fatta per prendere cose\nTop Secret Secret Public Seguono questo pattern casi in cui si vuole proteggere l\u0026rsquo;informazione. Bibaüü© √à l\u0026rsquo;opposto di Bell La-padula, perch√© la scrittura √® in gi√π, mentre la lettura in su. Il motivo di questo √® perch√© la scrittura rappresenta comandi, quindi devi mandarlo gi√π.\nCapitano Tenente Carabiniere Scelto Pi√π utilizzata in sistemi in cui l\u0026rsquo;integrit√† √® importante. Quindi sistemi in cui vogliamo dare l\u0026rsquo;ordine (informazione verso il basso).\nAccounting Si interessa dei sistemi di logging. Come per esempio il Journal che utilizzano tutti i servizi nel sistema operativo. In Ext4, forse citato in Filesystem viene trattato in breve.\nQuesta parte dovrebbe essere approfondita.\n","permalink":"https://flecart.github.io/notes/sicurezza-os/","summary":"Possiamo classificare tre aree generali quando si parla di sicurezza informatica:\nHardware Software human-ware. Non tratteremo in particolare esattamente come ogni campo viene declinato, per√≤ possiamo\nUna altra tendenza generale √® che pi√π √® complessa pi√π √® insicura. e questo senso di insicurezza cresce in modo maggiore rispetto al lineare.\nSecurity principles Open Design perch√© cos√¨ pu√≤ essere scrutata da pi√π persone Economy of mechanism spiegata sotto. Fail-safe defaults questo molto importante perch√© molti sistemi hanno dei default che possono essere exploitati.","title":"Sicurezza OS"},{"content":"Algoritmo del simplesso Ricerca della direzione migliore Ricerca dello step Pseudocodice Slide\nB sono gli indici di partenza, poi questi vengono aggiornati\nIn riga 5 vado a checkare se ho direzioni di crescita possibili, se √® tutto positivo non ne ho.\nin riga 6, si sceglie il pi√π piccol per evitare loop.\nL\u0026rsquo;idea in generale va in questo modo\nCerco di trovare il duale e confrontarlo con la x attuale Se sono uguali, allora ho trovato l‚Äôottimo ed esco Altrimenti cerco una direzione di crescita che sia anche ammissibile Continuo fino a trovare un vertice, se ho il vertice allora mi muovo l√¨ e riapplico, altrimenti √® illimitata, se non esiste un vertice. Correttezza Slide\n**\nInvarianti (3)\nqueste invarianti vengono mantenute per tutto il corso dell\u0026rsquo;algoritmo\nLa scelta della direzione di crescita\nNOTA: il vettore $u_h$ √® un versore utilizzato per selezionare la direzione che ci interessa (quindi 0 in tutto e 1 nella parte che ci interessa!).\nLa parte in cui dobbiamo stare attenti nella scelta della direzione di crescit√† √® restare nella zona delle soluzioni ammissibili.\nComplessit√† Slide\nFare una analisi in modo rigoroso non riusciamo a farlo, pi√π o meno ora restiamo con l\u0026rsquo;intuizione che al massimo ogni singolo vertice √® visitato una volta quindi teniamo il bound su questo.\nsi tratterebbe quindi di prendere fra tutti gli $m$ restrizioni possibili, dobbiamo andare a prendere $n$ elementi, con questo il numero di variabili.\nquindi $m \\choose n$.\nNella pratica √® molto veloce poi ha un runtime nel costo medio polinomiale, ma per fare questa analisi abbiamo bisogno di altri strumenti, molto avanzati.\nBranch and bound non si pu√≤ applicare l\u0026rsquo;algoritmo del simplesso per vincoli interi, questo sembra quasi paradossale ma √® cos√¨. il motivo √® che il simplesso gira sui vertici delle rette, cosa che non pu√≤ essere intera, e non abbiamo un modo banale per trovare la parte intera pi√π vicina!.\nIntuizione Slide\nProviamo a rilassare il problema chiedendo che anche i vincoli non interi siano buoni. Spesso questa cosa non √® buona, quindi utilizziamo una partition per andare a ritrovare una cosa intera.\nIn pratica, cerco la soluzione non intera utilizzando Simplesso o altri algoritmi che mi diano dei risultati boni. Poi se √® intera ritorno, altrimenti aggiungo due vincoli interi, creandomi due sottoproblemi, e me li vado ad esplorare in questo modo‚Ä¶\nPseudocodice Slide\nSi basa sull‚Äôapplicare in modo continuo un algoritmo per la risoluzione della programmazione lineare non intera, e cercare con una sorta di divide e conquer una soluzione che sia intera.\nCorrettezza Slide\nComplessit√† Slide\nEsponenziale, bisogna andare ad utilizzare il simplesso come subroutine molte volte, anche se magari si pu√≤ velocizzare di molto come subroutine, resta comunque almeno della complessit√† del simplesso.\n","permalink":"https://flecart.github.io/notes/simplesso-e-bb/","summary":"Algoritmo del simplesso Ricerca della direzione migliore Ricerca dello step Pseudocodice Slide\nB sono gli indici di partenza, poi questi vengono aggiornati\nIn riga 5 vado a checkare se ho direzioni di crescita possibili, se √® tutto positivo non ne ho.\nin riga 6, si sceglie il pi√π piccol per evitare loop.\nL\u0026rsquo;idea in generale va in questo modo\nCerco di trovare il duale e confrontarlo con la x attuale Se sono uguali, allora ho trovato l‚Äôottimo ed esco Altrimenti cerco una direzione di crescita che sia anche ammissibile Continuo fino a trovare un vertice, se ho il vertice allora mi muovo l√¨ e riapplico, altrimenti √® illimitata, se non esiste un vertice.","title":"Simplesso e B\u0026B"},{"content":"Guerre dei browser Prima guerra ~1995\nFra netscape, una forma di rete (?) che poi viene ripresa da firefox da Mozilla, dopo che √® stato mandato in bancarotta da Microsoft (che ha ancora con IE una grandissima fetta del mercato in questo primo periodo).\nSecondo periodo di guerra ~2010\nQuando arriva chrome, che vuole creare un browser che risolva tutti i problemi per creare integrazioni sui browser di altre aziende), mentre IE ha perso interesse per nuove features, che in questo periodo sono capi del proprio mercato.\nSu questa logica, partendo dal 2009, Chrome acquista una fetta del mercato grossa nel 2012. M$ prova a controbattere con Edge nel 2015, ma ormai √® un p√≤ tardi (ora rientra con bing tipo).\nIn questa parte viene anche introdotto un ciclo di bug-fix veloce, si chiama rapid release\nW3C and HTML Cose strane su brevetti‚Ä¶ Non volevano permettere modifiche dal loro standard HTML √® un living standard, non esiste pi√π un modo per definire se fosse coerente allo standard o meno.\nLock-in technologico e sviluppatori come utenti Vogliono creare un ambiente di sviluppo facile, e cercare di attirare alcuni sviluppatori, in modo che questi siano bloccati sui loro framework! (infatti costa imparare un nuovo framework, principalmente nuovo tempo, anche chiamao sunk cost).\n","permalink":"https://flecart.github.io/notes/storia-del-web/","summary":"Guerre dei browser Prima guerra ~1995\nFra netscape, una forma di rete (?) che poi viene ripresa da firefox da Mozilla, dopo che √® stato mandato in bancarotta da Microsoft (che ha ancora con IE una grandissima fetta del mercato in questo primo periodo).\nSecondo periodo di guerra ~2010\nQuando arriva chrome, che vuole creare un browser che risolva tutti i problemi per creare integrazioni sui browser di altre aziende), mentre IE ha perso interesse per nuove features, che in questo periodo sono capi del proprio mercato.","title":"Storia del web"},{"content":"7.1 De Hopital 7.1.1 Lemmi preliminari Questo lemma preliminare era gi√† presente per la prova del teorema degli zeri\nQuesto lemma √® molto interessante perch√© mette in relazione il finito (le successioni) con l\u0026rsquo;infinito (i reali) In molte dimostrazioni si d√† per scontato questo lemma, ma √® una sottigliezza importante che giustifica l\u0026rsquo;utilizzo di successioni per limiti reali. Ci permette di semplificare molto le dimostrazioni perch√© riusciamo a trattare le successioni molto meglio.\n7.1.2 ipotesi Enunciato al finito, finito\nEnunciato, limite al finito, asintoto\nEnunciato, limite destro o sinistro\nEnunciato limite all\u0026rsquo;infinito\nIl fatto che voglio che sia sigma sia la derivata di sigma siano diversi da zero, √® perch√© la conclusione deve avere entrambi diversi da zero.\n7.1.3 Dimostrazione Dimostrazione in slide\nNote sulla dimostrazione\nUtilizzo Cauchy per dire che esiste una successione che mi piace. Utilizzo il lemma delle successioni per dire che la successione trovata con cauchy √® proprio quello che mi serve Faccio uguale questa cosa di cauchy con la divisione senza le derivate e concludo per una parte. I passi principali sono:\nCercare di esprimere il limite della frazione come il limitie della frazione con input una successione.\nRiscrivere la frazione come la frazione - il punto che vogliamo calcolare (per ipotesi sto sottraendo 0) perch√© cos√¨ possiamo utilizzare dopo cauchy. Utilizziamo cauchy ed esprimiamo la frazione al punto uno come una divisione fra derivate. Dalla divisione fra derivate in successione utilizziamo il lemma e ci riconduciamo alla continuit√†. 7.2 Infiniti ed infinitesimi Queste conclusioni si adagiano fortemente sulle conclusioni del teorema di de l\u0026rsquo;Hopital\n7.2.1 Confronto fra infiniti Il teorema di De l\u0026rsquo;Hopital √® molto utile per descrivere una gerarchia degli infiniti. Possiamo confrontare quale funzione cresce pi√π in fretta di un altro.\nEnunciato\nC\u0026rsquo;√® anche il caso in L = $\\infty$, in quel caso si dice che √® di ordine inferiore.\nConclusioni\n7.2.2 Confronto fra infinitesimi Si potrebbe fare la stessa cosa per gli infinitesimi, si otterrebbero risultati opposti, ma il concetto √® lo stesso si utilizza sempre il concetto di teorema di Hopital.\nDefinizione infinitesimo\nEnunciato\nO-piccolo di funzione Il concetto di O-piccolo riesce a catturare il concetto di errore di misura (pi√π o-piccolo √® grande, pi√π precisa √® la mia misura).\nDefinizione Intuizione\nIn modo grossolano, se f √® infinitesimo di ordine maggiore rispetto al denominatore g, allora f √® un opiccolo di g.\nIn pratica si dice che una funzione g √® un o-piccolo di una funzione f se per il punto di cui stiamo calcolando il limite, g √® un infinitesimo di ordine superiore rispetto a f. (ricolleghiamo con il confronto fra infinitesimi)\n7.3.2 Propriet√† algebriche O-piccolo possiede alcune propriet√† algebriche di interesse, che sarebbe buona cosa studiare, quindi:\nDerivazione di altri O- e somma\nPotenze\nComposizione\nConstante\n7.3.3 Funzioni di stesso ordine Enunciato e dimostrazione\n7.4 Serie di Taylor L\u0026rsquo;idea principale per le serie di Taylor √® trasformare le funzioni trascendentali con alcuni polinomi.\nIn modo che alla fine si abbia un limite di rapporto di polinomi che equivalga alla funzione trascendentale, vogliamo una approssimazione della funzione che sia abbastanza precisa.\nsar√† alla fine un polinomio infinito!\n7.4.1 Intuizione Vogliamo cercare quale polinomio approssima meglio una funzione per ogni grado. Scopriamo che per una funzione continua √® la costante f(0) stessa per una funzione continua in questo punto. Formalizzato leggermente meglio questo pu√≤ diventare una dimostrazione.\ne si ha che √® O(1). Faccio lo stesso ragionamento per gradi superiori e mi trovo la serie di taylor, con qualunque approssimazione che mi serva. Consideriamo il caso in cui siamo sul 0, per una funzione continua e derivabile reale.\nEsempio con O(x) Allora sappiamo che $$ \\lim_{ x \\to 0 } \\frac{f(x) - f(0)}{x} = f'(0) \\in \\mathbb{R} $$ Questo implica il fatto che $$ \\lim_{ n \\to 0 } \\frac{f(x) - f(0)}{x} - f'(0) = 0 \\implies \\lim_{ n \\to 0 } \\frac{f(x) - f(0) - f'(0)x}{x} = 0 $$ Dove abbiamo utilizzato la continuit√† del limite per somme e sottrazioni. Questo ci dice che tutto quanto sopra √® un $o(x)$ Ossia si pu√≤ riscrivere quanto sopra come $f(x) = f(x) + f'(0)x + o(x)$\nSi pu√≤ continuare su su questa scia e approssimare la funzione tramite $o(x^{2})$ e in teoria si pu√≤ continuare cos√¨ all\u0026rsquo;infinito. Questo non √® una dimostrazione formale, nemmeno matematica, ma d√† la giusta intuizione sul perch√© la serie di Taylor funziona.\nEsempio con $O(x^{2})$ Consideriamo per un instante questo limite $$ \\lim_{ x \\to 0 } \\frac{f(x) - f(0) - f'(0) x - a_{1}x^{2}}{x^{2}} $$ Notiamo che sia sopra che sotto √® continuo, per questo motivo possiamo utilizzare il teorema #7.1 De Hopital da cui ricaviamo $$ \\lim_{ x \\to 0 } \\frac{f'(x) - f'(0) - 2a_{1}x}{2x} $$ Si pu√≤ notare che la prima parte √® un altra derivata, mentre l\u0026rsquo;altra parte √® un coefficiente, ossia abbiamo $$ \\lim_{ x \\to 0 } \\frac{f'(x) - f'(0)}{2x} - a_{1} = \\frac{1}{2}f''(0) - a_{1} $$ Questo significa che se settiamo il coefficiente in modo adatto possiamo avere un $o(x^{2})$ senza nessun problema! Ossia se $a_{1} = \\frac{1}{2}f''(0)$ vale che l\u0026rsquo;espressione di sopra √® un $o(x^{2})$ di sopra, per cui possiamo scrivere che\n$$ f(x) \\approx f(0) + f'(0)x + a_{1}x^{2} + o(x^{2}) $$ Con $a_{1}$ il valore di sopra. Applicando ancora Hopital sopra si pu√≤ avere il termine con esponente ancora superiore cos√¨ via!\n7.4.2 Enunciato Taylor e Peano Nota: si pu√≤ analizzare Taylor in una altra forma, che √® trattata in Massimi minimi multi-variabile#Resto secondo Peano\nEnunciato Taylor Sia $f: (a, b) \\to \\mathbb{R}$ una funzione continua, e sia $0 \\in (a, b)$ Poniamo $f$ derivabile n-volte in $\\bar{x} = 0$\nAllora andiamo a definire il polinomio di taylor in $\\bar{x} = 0$ di grado $\\leq n$ il polinomio $$ T_{n}(x) = \\sum_{j=0}^{n} \\frac{f^{(j)}(0)}{j!}x^{j} $$ Che √® l\u0026rsquo;unico polinomio di grado $\\leq n$ tale per cui valga $$ f(x) = T_{n}(x) + o(x^{n}) $$ per $x \\to 0$\nEnunciato Peano Questo √® esattamente il precedente, ma stiamo shiftando il polinomio, permettendo di avere dei valori che non siano necessariamente su 0. Sia $f: (a, b) \\to \\mathbb{R}$ una funzione continua, e sia $\\bar{x} \\in (a, b)$ Poniamo $f$ derivabile n-volte in $\\bar{x}$\nAllora andiamo a definire il polinomio di taylor in $\\bar{x}$ di grado $\\leq n$ il polinomio $$ T_{n}(x) = \\sum_{j=0}^{n} \\frac{f^{(j)}(\\bar{x})}{j!}(x - \\bar{x})^{j} $$ Che √® l\u0026rsquo;unico polinomio di grado $\\leq n$ tale per cui valga $$ f(x) = T_{n}(x) + o((x - \\bar{x})^{n}) $$ per $x \\to \\bar{x}$\nSerie di Taylor note 7.5.1 Esponenziale e Logaritmo Dimostrazione espo\nLogaritmo $$ \\ln(1 + x) = \\sum_{i = 1}^{n} \\frac{(-1)^{i - 1}}{i} \\cdot x^{i} + o(x^{n}) $$ con $x \\to 0$.\n7.5.2 Goniometriche Una nota di valore √® che l\u0026rsquo;espansione del seno ha solamente polinomi dispari, questo √® in stretta relazione con la disparit√† del seno, mentre per il coseno, dato che √® pari, si hanno solamente polinomi di gradi pari.\nSeno\nCoseno\n!\nBinomiale generalizzato Descrizione\n, Peano/Untitled 26.png]]\nCoseno\n!\n$$ \\cos t t = \\sum_{k = 0}^{n} (-1)^{k} \\frac{t^{2k}}{(2k)!} + o(t^{2m}) $$ ","permalink":"https://flecart.github.io/notes/hopital-taylor-peano/","summary":"7.1 De Hopital 7.1.1 Lemmi preliminari Questo lemma preliminare era gi√† presente per la prova del teorema degli zeri\nQuesto lemma √® molto interessante perch√© mette in relazione il finito (le successioni) con l\u0026rsquo;infinito (i reali) In molte dimostrazioni si d√† per scontato questo lemma, ma √® una sottigliezza importante che giustifica l\u0026rsquo;utilizzo di successioni per limiti reali. Ci permette di semplificare molto le dimostrazioni perch√© riusciamo a trattare le successioni molto meglio.","title":"Hopital, Taylor, Peano"},{"content":"Questi appunti sono stati scritti leggendo il (Russell \u0026amp; Norvig 2009).\n1 Introduzione L‚Äôintelligenza artificiale √® un campo in velocissima espansione, con gi√† un mercato enorme di un trillion dollars.\nInoltre il suo campo di studi spazia da moltissimi campi, √® per questo che quasi potresti considerarla universale.\n1.1 L‚Äôintelligenza artificiale 1.1.1 Cosa √® (2) Nel tempo si √® cercato di definire con esattezza cosa sia l‚Äôintelligenza artificiale. In generare si √® basato su alcuni parametri cardine ossia:\nLa capacit√† di replicare attivit√† umane / la capacit√† di applicare attivit√† razionali La capacit√† di ragionare / il comportamento intelligente Su questi due binomi sono stati fatti dei modelli, andiamo ora a scoprire in che senso l‚Äôintelligenza artificiale √® intelligente.\n1.1.2 Modelli generali Tra i modelli presenti quello di maggiore interesse nel tempo √® stato l‚Äôultimo, per il resto vanno a toccare molti campi che sono un p√≤ fuori dalle competenze dell‚Äôinformatico. (credo)\nAgire umanamente Come il test di turing, definisce l‚Äôintelligenza artificiale come un software che riesce ad emulare il comportamento umano, talmente che non riusciresti a riconoscerlo.\nMa i ricercatori hanno preferito cercare di capire cosa √® l‚Äôintelligenza in s√©, invece di cercare di emulare quella umana.\nPensare umanamente Questo modello ha un campo molto fiorente nelle scienze cognitive, attraverso scan delle immagini, o comunque una conoscenza approfondita in primo luogo della stessa conoscenza umana, vogliamo cercare di costruire un intelligenza artificiale che ne emuli le capacit√† (pensiero interiore, psicologia etc).\nPensare logico Questo √® stato uno dei primi metodi per costruire un software che si potesse considerare intelligente. Si basa sugli sviluppi della logica come campo di studi: ossia la possibilit√† di costruire software che siano in grado di dimostrare tutto il possibile.\nOppure utilizzando una analisi probabilistica, per analizzare la realt√†.\nAgire logico L‚Äôimmagine dell‚Äôagente √® stato il metodo pi√π florido nella storia dell‚Äôintelligenza artificiale nel momento in cui se ne voleva costruire una. Tanto che l‚Äôobiettivo della costruzione di un ente che potesse agire in modo logico in un ambiente si potrebbe considerare come se fosse un modello standard per la costruzione di un intelligenza artificiale.\nUn problema per√≤ sorge: allineamento dei valori: a volte fare la cosa logicamente pi√π corretta non √® la migliore soluzione, esempio se l‚Äôobiettivo fosse vincere a tutti i costi una partita a scacchi, l‚Äôagente, con la possibilit√† di agire sull\u0026rsquo;ambiente circostante, potrebbe compiere azioni che solitamente considereremmo ingiuste, al solo scopo di raggiungere questo obiettivo! ‚Üí vorremmo costruire qualche agente che sia in grado di portare un beneficio provato (dimostrato).\n1.2 L‚Äôagente Definiamo in modo molto generale, l‚Äôagente come qualcosa che possiede attuatori e percettori per interagire e percepire l‚Äôambiente (che pu√≤ essere molto vario).\nUn concetto importante √® che l‚Äôagente pu√≤ basare il suo output attraverso solamente ci√≤ che ha percepito (dall\u0026rsquo;inizio fino al tempo corrente) quindi potremmo considerare l‚Äôesistenza di una funzione agente che mappa sequenza input ‚Üí azione. e l‚Äôimplementazione di essa.\n1.2.1 La razionalit√† Vogliamo cercare di dare una definizione di razionalit√† in qualunque agente, e si pu√≤ formalizzare in questo modo: PEAS FRAMEWORK (performance, environment, actuators, sensors)\nUna funzione di performance L‚Äôinsieme delle conoscenze a priori sul mondo L‚Äôinsieme delle azioni possibili sul mondo La sequenza di percezione Con questi 4 oggetti, definiamo che l‚Äôagente √® intelligente se la funzione che prende in input la sequenza di percezione e le conoscenze sul mondo, dia in output l‚Äôazione che massimizza la performance.\nLa misura della performance Il modo migliore che abbiamo per misurare la performance √® sulle conseguenze che ha sull\u0026rsquo;ambiente. Quindi valutare se l‚Äôeffetto che ha √® positivo (sempre in funzione alla positivit√† descritta da chi ha progettato l‚Äôagente) o negativo.\nUna nota: √® importante costruire la performance secondo gli effetti sull\u0026rsquo;ambiente, e non secondo il modo con cui si dovrebbe comportare l‚Äôagente!\nMa non √® detto che sia il modo migliore per fare ci√≤, √® un problema pi√π filosofico (quello sugli effetti uguali, ma uno sta basso e fa sempre, mentre l‚Äôaltro √® molto efficiente a momenti e per il resto del tempo sta proprio fermo).\nOnniscienza ed autonomia Non possiamo avere un agente che sappia tutto, bisogna tarare la performance su questa osservazione: l‚Äôazione scelta non deve essere la migliore possibile in assoluto (altrimenti l‚Äôagente dovrebbe sapere tutto) ma dovrebbe essere la migliore azione in guadagno atteso.\nQuesto comporta la migliore decisione che possa massimizzare scelte future (come raccolta delle informazioni si spende un p√≤ di tempo per raccogliere pi√π informazioni sull‚Äôambiente) oppure l‚Äôazione stessa nel caso si abbia gi√† conoscenza sull‚Äôambiente.\n√à da notare che il caso in cui si ha una totale conoscenza sull‚Äôambiente a priori (caso anche di alcune specie di animali come lowly dung beetle o sphex wasp) toglie di autonomia (ossia la capacit√† di agire a seconda di input ambientali e non solo secondo conoscenze a priori) all‚Äôagente, e potrebbe non dare le soluzioni volute (in questi casi l‚Äôagente agisce soltanto, perch√© pensa di sapere gi√† tutto).\n1.2.2 L‚Äôambiente Ci sono una moltitudine di variabili che possono risultare utili per classificare un ambiente tra cui:\nDeterminismo-nondeterminismo o stocastico Osservabilit√† parziale-totale singolo-multi agente episodico - sequenziale (si basa o no su eventi passati?) statico o dinamico (o semidinamico) (l‚Äôambiente pu√≤ cambiare quando l‚Äôagente pensa sul da farsi?) discreto o continuo (gli stati sono infiniti o finiti?) conosciuto o sconosciuto (i risultati delle azioni sono conosciute a priori, come se fossero leggi della fisica). Per esempio, il progetto mnk-game √® un ambiente che √® Determinista, totalmente osservabile, agente multiplo, sequenziale, statico, discreto e conosciuto.\nQuesti direi sono i 7 cardini che definiscono ad alto livello un ambiente.\n1.3 Tipologie di agente In questa parte vengono descritti le tipologie di agente a cui si √® pensato. Parlando in generale √® come se fossero dei modelli che vengono costruiti uno sopra l‚Äôaltro, in senso crescente, fino ad arrivare all‚Äôagente che apprende come modello finale (correntemente pi√π gettonato).\nI modelli qui presentati sono molto astratti, utili per semplicit√† e chiarezza, ma non ci aiuta in alcun modo per capire come implementare tale modello, tutti gli agenti qui presentati saranno di questo tipo\n1.3.1 Basati su riflessi L‚Äôagente che si basa sui riflessi √® il pi√π semplice degli agenti che possono essere presenti. Come dice il nome si basa sul concetto di riflesso molto simile al riflesso umano, come sbattere le ciglia, scattare via da una fonte di calore simili azioni.\nSi tratta di un agente che agisce sulla singola percezione e trova l‚Äôazione corrispondente a seguito di questa. Le percezioni passate non interessano proprio, sa gi√† agire subito dalla percezione presente.\nCaratteristiche di questo agente:\nStaticit√† nelle azioni, esegue solo ci√≤ per cui √® programmato, quasi fosse un if-then agent, infatti dovremmo parlare di regole di condizione-azione\nNecessit√† di osservabilit√† totale, altrimenti √® difficile che faccia l‚Äôazione pi√π intelligente\nModello in breve\n1.3.2 Basati su modelli Questo modello si pu√≤ considerare una espansione al modello precedente. Si cerca piano piano di rendere l‚Äôagente pi√π flessibile, e non soltanto qualcosa di programmato, come se fosse un singolo algoritmo:\nOra l‚Äôagente possiede un modello interno del mondo, che √® cambiato a seconda della percezione nel momento. Quindi l‚Äôazione ora non √® presa solamente secondo la percezione attuale, ma anche secondo il modello del mondo, e la percezione attuale.\nCaratteristiche\nFunzione di transizione del modello, che serve per aggiornare il modello interno del mondo a seconda dei cambiamenti percepiti Funzione di sensore, che traduce le informazioni percepite in funzione dello stato del mondo (es. se ho la telecamera sporca di acqua per la pioggia, l‚Äôinput sar√† un p√≤ diverso) Quindi maggiore flessibilit√† in confronto alla precedente.\nModello in breve\n1.3.3 Basati su obiettivi L‚Äôulteriore espansione di questo agente rispetto alla precedente √® che ora il modello tiene conto anche delle possibili conseguenze future delle proprie azioni in funzione del raggiungimento o meno del proprio obiettivo\nCaratteristiche\nEsistenza di un obiettivo ben dichiarato proprio (che condiziona la funzione di valutazione) Possibilit√† di rimpiazzare l‚Äôobiettivo precedente con uno simile (flessibilit√†) Aggiornamenti su conseguenze delle proprie azioni sullo stato del raggiungimento per l‚Äôobiettivo Modello in breve\n1.3.4 Basati su utility cerca di valutare se √® una conseguenza buona o cattiva, a seconda di una propria funzione di valutazione che cerchi di rispettare il meglio possibile la funzione di valutazione dell‚Äôambiente in cui √® presente.\n√à buono in caso ci possano essere degli obiettivi che si eliminano uno a vicenda, √® buono per trovare i tradeoff **comune in molte situazioni (es. voglio arrivare pi√π in fretta possibile, ma non voglio investire persone).\nCaratteristiche\nUna funzione di valutazione che cerca di massimizzare il valore atteso della propria azione. Modello in breve\n1.3.5 Basati su apprendimento Al fine di avere un agente flessibile che possa adattarsi in ambienti anche molto differenti fra di loro, vorremmo creare un metodo per cui l‚Äôagente possa imparare dai propri errori. Questo modello si prefissa l‚Äôobiettivo di creare un framework generale per un agente che impara.\nCaratteristiche:\nCritico: cerca di valutare le azioni prese dall‚Äôagente e pone consigli su cosa cambiare Elemento apprendimento: che cambia lo stato di conoscenza interna dell‚Äôagente in modo che possa prendere decisioni migliori, grazie al feedback del critico generatore di problemi che propone nuovi problemi/esperimenti che possono migliorare altri tratti dell‚Äôagente. Modello in breve\nL‚Äôagente vecchio √® interamente raccolto nel performance element\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/l‚Äôintelligenza/Untitled 6.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/l‚Äôintelligenza/Untitled 6\u0026quot;\u0026gt; References [1] Russell \u0026amp; Norvig ‚ÄúArtificial Intelligence: A Modern Approach‚Äù Prentice Hall Press 2009\n","permalink":"https://flecart.github.io/notes/lintelligenza/","summary":"Questi appunti sono stati scritti leggendo il (Russell \u0026amp; Norvig 2009).\n1 Introduzione L‚Äôintelligenza artificiale √® un campo in velocissima espansione, con gi√† un mercato enorme di un trillion dollars.\nInoltre il suo campo di studi spazia da moltissimi campi, √® per questo che quasi potresti considerarla universale.\n1.1 L‚Äôintelligenza artificiale 1.1.1 Cosa √® (2) Nel tempo si √® cercato di definire con esattezza cosa sia l‚Äôintelligenza artificiale. In generare si √® basato su alcuni parametri cardine ossia:","title":"l‚Äôintelligenza"},{"content":"Memoria virtuale Perch√© √® utile la MV? üü®- I programmi non usano tutta la memoria, ma pensano di averla tutta disponibile dal suo punto di vista. L\u0026rsquo;idea principale √® che molte zone di memoria sono inutili per lungo tempo, possono essere utilizzati per altro.\ncaricamento codice dinamico Per esempio anche a caricare il codice di un compilatore √® diviso in fasi, se andiamo a caricare tutto, stiamo utilizzando solo un pezzo piccolo, tanta inefficienza, se una pagina contiene una parte del compilatore potrei caricare in memoria solamente le parti eseguite sul momento, giusto per fare un esempio diciamo. Crescita dei segmenti stack, heap, ad esempio ci permette di far crescere come ci pare la stack, e anche caricare solamente le parti della stack che ci servono, e mantenere la memoria libera per altro. Gestione degli errori. che utilizzer√† i dati solamente della parte di gestione di memoria attuale diciamo. Paginazione a richiesta üü©‚Äî Questo √® un aspetto della cache delle pagine di cui abbiamo gi√† parlato in Livello OS.\nSlide paginazione a richiesta\nin pratica nella cache √® presente un bit, chiamato valid bit, che ci dice se la pagina correntemente caricata √® valida o meno.\nSe non √® presente una pagina valida, allora chiamiamo trap di page fault, e il pager si occupa di caricare la nuova pagina ed aggiornare la pagina vecchia.\nEsempio di demand paging\nNOTA: la memoria secondaria con questo metodo ha l‚Äôintero contenuto, in questo senso la memoria principale √® utilizzata come se fosse cache.\nEsempio completo con page fault\n*ALGORITMO GENERALE DI DEMAND PAGING\nSlide demand paging\nNOTA: la cosa importante √® il fatto che invalida subito la pagina scelta da sostituire. Non vorremmo che se un altro processo chieda quella pagina possa ancora scriverci o leggerci (e quindi problemi di concorrenza).\nMemoria di Swapüü© In realt√† quando un intero processo √® caricato in memoria secondaria, questa parte in memoria secondaria √® l‚Äôarea di swap.\nMa questo metodo qui √® come se fosse uno swap pigro. (se un processo √® vecchio, nel senso che non utilizza la pagina per tanto tempo, √® probabile che la sua memoria √® messa in memoria secondaria).\nil termine swap area per indicare l\u0026rsquo;area del disco utilizzata per ospitare le pagine in memoria secondaria\nAlgoritmi di rimpiazzamento AKA Paginazione.\nObiettivo del rimpiazzamento üü©‚Äî Quando la memoria centrale √® piena, come si gestisce il processo di rimpiazzamento? In che modo si decide quale sia la pagina da togliere? Su quali basi andare a valutare per fare questa decisione?\nUtilit√†, nel senso meno utilizzata Sar√† utilizzata fra pi√π tempo. Minimizzare il numero di page faults possibili. vorremmo evitare di togliere e rimpiazzare subito.\nNUMERO DI FRAME E PAGE FAULTS\nNon √® che il numero dei frame aumenta implica che il numero di faults sia minore? Ma stranamente non √® sempre cos√¨, gli algoritmi di rimpiazzamento potrebbero fare peggio se hai troppa memoria, per esempio Algoritmi FIFO üü©\nQuesto fenomeno √® proprio studiato, ed √® conosciuto nel nome di Anomalia di belady üü©\nStringa di riferimenti üü© √à la sequenza degl iindirizzi di memoria al quale un processo accede durante la sua esecuzione, (ci importa solamente il numero di pagina!) Questo ci d√† un criterio per valutare quanto buona √® una pagina in memoria\nSlide stringa di riferimenti\nAlgoritmi FIFO üü© Questo l\u0026rsquo;abbiamo studiato anche in Scheduler, oppure Data Plane per i routers.\nPraticamente la pagina che dovr√† uscire sar√† la pagina in memoria da piu`tempo. Ma non √® detto che la pagina caricata da pi√π tempo sia anche poco utilizzata! potrebbe essere ancora utilizzata!\nEsempio di paginazione fifo\nEsempio paginazione 2 fifo\nEsempio brutto, di maggiori faults con aumento memori\nAnomalia di belady üü© Slide anomalia di belady\nUn buon algoritmo di rimpiazzamento dovrebbe essere immune a questa anomalia! Perch√© non avrebbe senso che aggiungere memoria renda il sistema pi√π lento!\nIn questo paragrafo: Implementazione a stack parliamo di una condizione sufficiente affinch√© non si verifichi questa condizione.\nAlgoritmo MIN üü© Questo √® l\u0026rsquo;algoritmo ottimale, ma utilizza informazioni che non abbiamo gi√†, perch√© non sappiamo quando i processi accederanno a cosa. Quindi buon algoritmo in teoria (perch√© utilizza informazioni che non abbiamo ancora nel presente), nessun uso ora.\nPer√≤ si pu√≤ dimostrare che questo algo genera il minor numero di faults.\nSeleziona come pagina vittima una pagina che non sar√† pi√π acceduta o la pagina che verr√† acceduta nel futuro pi√π lontano\n√à un buon algoritmo per utilizzare come paragone di altri algoritmi reali, cio√® questi reali quanto bene fanno rispetto a questo algoritmo perfetto!\nSlide algoritmo MIN\nLeast Frequently usedüü® Slide LFU\nMa solitamente questo, come FIFO, non √® che venga utilizzata.\nVado a considerare il concetto di frequenza, definita in questo modo: contatore / tempo di permanenza in memoria.\nAlgoritmo di LRU Ne abbiamo parlato anche in architettura, qui: 9.2.4 Algoritmi di paginazione (2).\nseleziona come pagina vittima la pagina che √® stata usata meno recentemente nel passato\nIn pratica provo a stimare l‚Äôutilizzo della pagina in base a quanti accessi abbia fatto in passato.\nEsempio LRU\nImplementazione LRU Come facciamo a capire quanto spesso √® stato utilizzato una pagina? Non possiamo mica aggiungere il numero di accesso a tutte le risoluzioni MMU, deve essere implementato in hardware stesso, in MMU.\nSlide implementazione MMU\nAccessi in memoria in pi√π\nLa MMU dovrebbe tenersi i timestamps e dovrebbe gestire gli overflows\nO(n) per scandire la tabella di frame, e trovare la pagina\nQuindi √® molto lenta, ma almeno √® realizzabile.\nIMPLEMENTAZIONE A STACK\nOssia quando accediamo una pagina, la mettiamo sopra la stack. Ma √® brutto perch√© in hardware dovrei aggiornare 6 puntatori, che non dovrebbe essere cosa da niente, per questo non √® utilizzato.\nLa cosa carina per√≤ √® che avrei in cima le cose utilizzate in basso quelle meno utilizzate!\nImplementazione a stack Slide definizione di algoritmi a stack\nSi noti che la condizione √® molto simile a una sufficiente per risolvere la condizione di belady, ci sta dicendo che in pratica: l‚Äôinsieme delle pagine mantenute in memoria √® contanuto allo stesso algoritmo con pi√π pagine in memoria!\n√à anche una condizione sufficiente per dire: avere fage faults in meno, non pi√π, perch√© contiene sempre le stesse pagine con una versione a pi√π.\nPer dimostrare che FIFO non √® a stack, basta un esempio.\nACCENNO DIMOSTRAZIONE LRU √à STACK\nSi utilizza una dimostrazione costruttiva per induzione (altra tecnica √® per assurdo). Questo lo facciamo sul tempo.\nPasso base: al tempo 0 la stack √® vuota, non ci importa quale numero di stack, la memoria resta la stessa. Supponiamo al tempo t-1 che la condizione di stack sia verificata. Ora abbiamo due casi: non c‚Äô√® abbstanza spazio, o c‚Äô√® ancora spazio: Se c‚Äô√® abbastanza spazio, allora non ci cambia per un m numero di frame maggiore Se non c‚Äô√® abbastanza spazio, quello minore deve cambiare, dovr√† scegliere uno a caso, scegliendone uno a caso allora l‚Äôinsieme delle pagine √® ancora incluso. Al passo successivo ancora, l‚Äôelemento che esce dovr√† essere lo stesso, o comunque offsettato non di tanto credo, in pratica quello grosso elimini cose solamente eliminate gi√† da quello piccolo!. E questa cosa con LRU l‚Äôabbiamo. Non √® che ho formalizzato molto bene questa parte. Additional reference bit üü©- Andiamo ora a parlare di approssimazione di LRU perch√© col discorso a stack non √® proprio fattibile con l‚Äôhardware attuale.\nQuando accedo a una pagina, il bit viene messo a 1, inizialmente sono tutte 0, meglio descritta nella slide:\nSlide descrizione reference bit\nbasta fare shift e assegnamento! Quindi easy! Andiamo a prendere la pagina con valore minore poi.\nVARIANTE: SECOND CHANGE ALGO\nSlide second change (storia = 1)\nVengono gestiti come una lista circolare, per questo motivo √® anche detto algoritmo dell‚Äôorologio.\nIn pratica scandisco la lista con questo algo:\nBit a 1? Allora lo metto a 0 e vado avanti Bit a 0? Allora tolgo questa! E sostituisco. Esempio di second change algo\nNon si capisce sto esempio lol\nAllocazione della memoria virtuale Tipologie di allocamento (3) üü®‚Äî Slide allocazione\nAlgo di allocazione: risponde alla domanda su come allocare i frame per un certo processo. Allocazione globale: permetto di allocare l\u0026rsquo;intero programma (male ‚Üí thrashing) Allocazione locale: il processo √® a conoscenza dei propri frame, ma non √® molto flessibile, di solito fanno meglio quelli globali, Praticamente fin‚Äôora abbiamo parlato di metodi per sostituire delle pagine in caso di page faults, ma non abbiamo mai definito in che modo decidiamo quanti frames allocare a un processo, nel momento del bisogno. Allocazione globale e locale sono dei modi per fare questa decisione.\nLocale ‚Üí implica che posso sostituire solamente i frames del mio processo, in queto senso sono poco flessibile, se qualcun‚Äôaltro ha pi√π roba che posso sottrarre converrebbe fare quello. Globale ‚Üí implica che posso sostituire i processi di chissivoglia. Normalmente si utilizzano anche delle euristiche per sapere quante pagine allocare: per esempio se ho troppi page faults, probabilmente il processo ha bisogno di pi√π memoria, se ne ho troppi pochi probabilmente il processo ne ha troppa, e si pu√≤ allocare ad altri.\nThrashing üü© un processo (o un sistema) si dice che √® in trashing quando spende pi√π tempo per la paginazione che per l\u0026rsquo;esecuzione\nQuesto √® quindi un effetto molto brutto! Va a finire che l\u0026rsquo;intero sistema si impalli. rubano le pagine a vicenda, l\u0026rsquo;effetto pi√π classico √® questo: non riescono a tenere in memoria i frame utili a breve termine (perch√® altri processi chiedono frame liberi) e quindi generano page fault ogni pochi passi di avanzamento) In pratica quasi ogni operazione √® un page fault.\nPer evitare questo, massimo 2x memoria virtuale, altrimenti potrei andare in thrashing.\nEsempio di effetto di thrashing\nL\u0026rsquo;efficienza cade di interi ordini di grandezza!\nWorking set üü©‚Äî si definisce working set di finestra Œî l\u0026rsquo;insieme delle pagine accedute nei pi√π recenti Œî riferimenti\nQuesto √® utile per stimare se il sistema √® in thrashing. Questo √® utile per avere un concetto di localit√† delle pagine, vogliamo avere una stima delle pagine attualmente utili, e utilizziamo questo per andare a decidere se una pagina √® ancora utile o meno.\nSlide valutazione working set per thrashing\nSe la somma di tutti i pages di cui ho bisogno nel breve √® maggiore di pi√π pagine presenti in RAM, allora sicuramente quando questa si riattiva crea page faults! Ecco il criterio per i page faults.\nScelta del delta\nSOLUZIONE PROPOSTA\nBasta sospendere alcuni processi, in modo che alcuni terminino senza andare in troppi page faults, in modo che la somma di tutti working set stiano ancora dentro.\nSlide della soluzione\n","permalink":"https://flecart.github.io/notes/memoria-virtuale/","summary":"Memoria virtuale Perch√© √® utile la MV? üü®- I programmi non usano tutta la memoria, ma pensano di averla tutta disponibile dal suo punto di vista. L\u0026rsquo;idea principale √® che molte zone di memoria sono inutili per lungo tempo, possono essere utilizzati per altro.\ncaricamento codice dinamico Per esempio anche a caricare il codice di un compilatore √® diviso in fasi, se andiamo a caricare tutto, stiamo utilizzando solo un pezzo piccolo, tanta inefficienza, se una pagina contiene una parte del compilatore potrei caricare in memoria solamente le parti eseguite sul momento, giusto per fare un esempio diciamo.","title":"Memoria virtuale"},{"content":"Coppia ordinata Definizione di Kuratowsky Una coppia ordinata √® definita dall\u0026rsquo;insieme\n$$ \\langle X, Y \\rangle = \\{X, \\{X, Y\\}\\} $$ √à quindi chiaro che due coppie ordinate sono uguali fra di loro nel caso in cui gli elementi sono uguali ma anche la loro posizione sono uguali\nTeorema caratterizzazione delle coppie\nDefinizione di Wiener $$ (X,Y) := \\{\\{\\{X\\}, \\varnothing\\}, \\{\\{Y\\}\\}\\} $$ Definizione di Hausdorff $$ (X,Y) := \\{\\{X, 1\\}, \\{X,2\\}\\} $$ Propriet√† fondamentale coppie ordinate Due coppie ordinate si dicono uguali se e solo se il primo elemento dei due sono uguali e la stessa cosa per il secondo\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Relazioni fra insiemi/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Relazioni fra insiemi/Untitled 1\u0026quot;\u0026gt; DImostrazione di wiki, difficile\nProdotto cartesiano Definizione del prodotto $$ \\forall A, \\forall B, \\exists C,\\forall Z (Z \\in C \\iff \\exists a, \\exists b(a \\in A \\, \\wedge \\, b \\in B \\, \\wedge \\, Z \\in \\langle a, b\\rangle)) $$ Utilizzando un linguaggio naturale, stiamo prendendo tutti gli elementi da due insiemi e stiamo prendendo una coppia ordinata: prendiamo tutte le coppie ordinate possibili.\nquesto si indica con $A \\times B$\nRelazione e con il Vuoto Una relazione √® una qualunque sottoinsieme di $A \\times B$\nQuesta cosa si scrive come $a\\mathcal{R}b \\iff \\langle a,b \\rangle \\in \\mathcal{R}$\nTeorema relazioni da e verso insiemi vuoti.\nSe $\\mathcal{R} \\subseteq A \\times \\varnothing \\text{ or } \\varnothing \\times A \\text{ allora } \\mathcal{R} = \\\\varnothing$ questo si dimostra che il prodotto cartesiano con un insieme vuoto √® sempre vuoto, quindi l\u0026rsquo;unica relazione esistente √® il vuoto.\n##Funzione\nPer ogni elemento di un elemento dominio, si ha solo una unica immagine in un insieme d\u0026rsquo;arrvo immagine, si scrive $X f Y$:\n$$ \\forall X(X \\in A \\implies \\exists! Y, X f Y) $$ L\u0026rsquo;abuso di notazione tipico dei matematici √® una falsit√† perch√© sembra che la funzione calcoli Y, inverit√† non calcola niente, ma solamente √® una relazione. Ecco l\u0026rsquo;abuso di notazione.\nSpazio di funzioni $\\forall A, \\forall B, \\exists C, \\forall f (f \\in C \\iff \\text{ f √® una funzione dal dominio A e codominio B} \\text{ e si ha che C = } B^A)$\nFunzioni da e verso insieme vuoti Se √® il codominio vuoto, allora non esistono funzioni possibili perch√© non esistono relazioni possibili, non ho nessun elemento da collegare agli elementi del dominio.\n$\\varnothing^{A} = \\varnothing$\nSe il dominio √® vuoto, allora esiste la funzione vuota, che non fa nulla, perch√© tanto non ho nessun X appartenente a A da loopare, non faccio niente quindi creo l\u0026rsquo;insieme che non ha nulla.\n$$ B^{\\varnothing} = \\left\\{ \\varnothing \\right\\} $$ Se sia codominio che dominio sono vuoti allora devo prima loopare nel dominio, che √® vuoto, quindi gi√† l\u0026rsquo;insieme vuoto ho creato.\nRelazioni RST Propriet√† delle relazioni Riflessiva se $\\forall X, X\\mathcal{R}X$\nSImmetrica $\\forall X, \\forall Y X\\mathcal{R}Y \\implies Y\\mathcal{R}X$\nTransitiva $\\forall X,Y,Z (X\\mathcal{R}Y \\wedge Y\\mathcal{R}Z\\implies X\\mathcal{R}Z)$\nPropriet√†\nEsempi\n= Vale tutti e tre\n\u0026lt; Transitiva non simmetrica e non riflessiva\n‚â§ transitiva e riflessiva ma non simmetrica\n‚â† √® simmetrica e bbasta\nOrdinamento stretto Una funzione che sia transitiva e non riflesssiva, per esempio il \u0026lt; o il \u0026gt;\nOrdinamento lasco Una funzione che sia transitiva e riflessiva per esempio ‚â§ o il ‚â•\nIn pi√π si pu√≤ dire che sia antisimmetrica, cio√® che se vale $x\\mathcal{R}y \\wedge y\\mathcal{R}x \\implies x = y$\nUn altro buon esempio √® la relazione di divisione.\nEquivalenza Se ha tutte e tre le propriet√† si pu√≤ dire che sia una relazione di equivalenza.\nQuesta relazione √® utile per confrontare oggetti perch√© √® come dire che sono la stessa cosa due elementi quando soddisfano una relazione di equivalenza.\nDire che sono uguali √® stato un qualcosa di cui la matematica si √® interessata storicamente, dire uguale √® diverso da dire che sono equivalenti.\nEsercizio Difficile\nSoluzione\nMisc\nClassi $\\equiv\\subseteq A \\times A \\text{ √® una relazione di equivalenza, allora la classe di equivalenza di } x\\in A \\text{ rispetto a } \\equiv \\text{ √® definito come }[x]_\\equiv =^{def} \\{ y \\in A | y \\equiv x\\}$\nRelazioni fra classi di equivalenza Fra tutte le classi di equivalenza di ha che ho le due classi sono equivalenti fra di loro, oppure sono diverse (disgiunte) fra di loro.\nAbbozzo di dim\nPreso classe equivalente X, Y,allora per la transivit√† Z √® transitivo sia a Z X sia a Y, e poi si pu√≤ utilizzare, usiamo l\u0026rsquo;assioma di estensionalit√† per dimostrare che le due classi sono uguali.\nPoi cerco l\u0026rsquo;intersezione, se nell\u0026rsquo;intersezione di due classi di equivalenza trovo un Z, ho che queste due classi sono identitiche, e se sono identiche so che ci sono Z e simili.\nInsieme quoziente L\u0026rsquo;insieme quoziente contiene tutti gli elementi (classi di equivalenza) possibili (disgiunti per la classe di equivalenza).\n√® definita come, fatto con l\u0026rsquo;assioma di rimpiazzamento (posso creare un insieme se possiedo una funzione)\n$$ U_{/\\equiv} := \\{[x]_\\equiv \\,|\\, x \\in U \\} $$ Utilit√†\nQuesti insiemi sono utili per costruire ancora, scegliere qualche propriet√† a seconda del bisogno.\nCostruzione di $\\mathbb{Z}$ Partendo dall\u0026rsquo;insieme del prodotto cartesiano $\\mathbb{N} \\times \\mathbb{N}$ definiamo ogni coppia $\\langle a, b\\rangle$ come $a - b$. Allora possiamo definire una classe di equivalenza per il risultato di una sottrazione\u0026hellip; Preso l\u0026rsquo;insieme quoziente di tutte queste classi di equivalenza si pu√≤ creare $\\mathbb{Z}$ e lo possiamo indicare con numeri come al solito. Quindi invece di indicare un numero in Zeta come una classe di equivalenza, indico normalmente con + -.\nCostruzione di $\\mathbb{Q}$ Uguale a Z solo che invece della sottrazione creo la somma Esistenza funzione bigettiva N ‚Üí Q\nCardinalit√† di un insieme Intuizione dalle funzioni Si pu√≤ creare una prima intuizione dal concetto di iniettivit√†, suriettivit√† e bigezione di funzioni fra due insiemi sul concetto di cardinalit√†\nIniettivit√†\nSe il codominio fosse pi√π piccolo del dominio, per il principio dei cassetti deve esserci una relazione che punta allo stesso elemento nel codominio, per cui la cardinalit√† del codominio deve essere pi√π grande\nSuriettivit√†\nSe il dominio fosse pi√π piccolo del cominio, non avrei abbastanza frecce per raggiungere tutti gli elementi del codominio, quindi sarebbe impossibile una funzione suriettiva.\nBigettivit√†\nSe per iniettivit√† e suriettivit√† i due insiemi devono essere uguali per cardinalit√†\nDefinizione di cardinalit√† Due elementi hanno la stessa cardinalit√† sse esiste una bigezione fra i due, e quindi possono definire una classe di equivalenza indicata\n$U_{/\\equiv}$ e posso poi definire anche una classe quoziente delle relazioni di equivalenza.\nDefinizione con insiemi √à possibile, con un lunghissimo lavoro, costruire questa classe attraverso solamente gli insiemi questa classe, invece di utilizzare le classi di equivalenza.\nIn altre parole si pu√≤ dimostrare che √® abbastanza piccola la classe dei numeri cardinali\nCritica al matematico\nIl matematico indica con lo stesso numero un numero cardinale e il numero naturale, ma per definizione di numero cardinale e numero naturale sono diverse, il primo √® una classe di quivalenza ddell\u0026rsquo;insieme {1,2,3} (che contiene in s√© tutti gli insiemi di 3 elementi, fra qui anche il numero naturale 3, mentre per definizione del numero natuale 3 √® {0,1,2}\nAbuso di notazione e aleph Si indica la classe di equivalenza per la classe di equivalenza $[x]_{/\\equiv}$ come $|x|$\nIn particolare per indicare la cardinalit√† dei numeri naturali √® $\\aleph_0$\nInsiemi infiniti Fra questi definiamo anche l\u0026rsquo;insieme finito che praticamente √® definito come la negazione dell\u0026rsquo;insieme finito.\nAlbergo di Hilbert Hilbert √® stato uno dei matematici pi√π famosi a fine secolo scorso e cre√≤ i problemi del millennio per lo sviluppo della matematica attuale.\nAlbergo finito e infinito Se √® finito allora non si pu√≤ accomodare in nessun modo.\nMa se invece √® infinito? Una soluzione potrebbe essere che ogni cliente si muova nella stanza col numero seguente e si potrebbe trovare di nuovo altro spazio.\nDefinizione di infinito Infinito √® quando in bigezione con un suo sottoinsieme proprio, ma non √® s√© stesso. In simboli: $A \\subset B \\wedge \\exists f: B f A$ e f sia bigettiva.\nqui infatti esiste un paradosso, in quanto essendo essendo un sottoinsieme allora si pu√≤ dire che sia pi√π piccolo, ma con l\u0026rsquo;intuizione dell\u0026rsquo;infinito possiamo dire che hanno la stessa cardinalit√†, hanno la stessa grandezza.\nOrdinamento sugli infiniti \u0026lt;, ‚â§ ‚â§ Ordinamento lasco\nEsiste una classe di equivalenza di ordinamento lasco sse dati due insiemi A, B si ha |A| ‚â§ |B| se esiste una iniezione fra |A| o |B|\n\u0026lt; Ordinamento stretto\n√à simile al precedente, ma devo togliere l\u0026rsquo;uguale quindi dico che non esiste una bigezione.\nDiagonalizzazione di Cantor Dimostrazione diagonalizzazione di Cantor Teorema $|T| \u003c | 2^T|$\nDimostrare per assurdo che non esiste una funzione bigettiva da T a $2^T$ e poi dimostrare che esiste una funzione iniettiva da T a $2^T$.\nLa funzione iniettiva √® semplice perch√© basta mappare ogni T al suo singoletto equivalente in $2^T$\nIn seguito dimostriamo per assurdo che non esiste una funzione bigettiva.\nSupponiamo una funzione bigettiva, al fine di creare l\u0026rsquo;assurdo abbiamo bisogno dei tre elementi presentati in Logica meta-linguistica. Quindi meta linguistica, riflessione e negazione.\nDefiniamo quindi un insieme $A = \\{x \\in T| x \\not\\in g(x) \\}$ data la funzione $g(x)$ bigettiva.\n(Possiamo definire x che appartiene all\u0026rsquo;insieme imamgine perch√© l\u0026rsquo;insieme di arrivo sono degli insiemi, in quanto √® l\u0026rsquo;insieme delle parti).\nMa allora data l\u0026rsquo;iniettivit√† della funzione $g(y) \\in 2^T$ esiste un $y \\in T$, ma allora $y \\in g(x) \\iff y \\not\\in g(x)$ e quindi porta all\u0026rsquo;assurdo.\nDimostrazione con tabella Questa √® quella usata in R e Intervalli#Innumerabilit√† di R.\nSupponiamo che l\u0026rsquo;intervallo $[0, 1[$ sia numerabile, ossia esiste una funzione $f: \\mathbb{N} \\to [0, 1[$ che sia bigettiva. Scriviamo tutti i numeri possibili in forma binaria\nAvremo una tabella simile: che ci dice che\nNatural Real number 1 0,00001010101\u0026hellip; 2 0,100101011010 E continua all\u0026rsquo;infinito (poi sopra sarebbe bello avere anche uno 0), allora posso creare un nuovo numero che per costruzione non √® mappato da nessun naturale (flippo i numeri sulla diagonale). Quindi non √® suriettiva, e la costruzione porta ad un assurdo. Sintesi Dim Data la dimostrazione abbastanza complicata (per me boh) provo a rilistare i passaggi principali utili per questa dimostrazione.\nUtilizzare l\u0026rsquo;assurdo per dimostrare l\u0026rsquo;inesistenza di una funzione bigettiva Utilizzare la suriettivit√† della funzione bigettiva per creare un insieme che possa dare un assurdo. Allora $g(y) = A$ definito con quella propriet√† per assurdo, questa deve esistere per suriettivit√† Devo creare un y appartenente a $T$ l\u0026rsquo;insieme iniziale perch√© cos√¨ comincio a creare qualcosa Dico assurdo perch√© entrambi i casi, che $y \\in A, y\\not\\in A$ creano assurdo perch√© implicano tra di loro. $\\lvert T \\rvert \u003c \\lvert T^{T} \\rvert$ Questo √® un corollario della diagonalizzazione di Cantor, che utilizza una semplice disuguaglianza di una funzione caratteristica.\nL\u0026rsquo;unica cosa nuova √® $\\mathbb{B}^T \\leq |T^T|$ questo √® vero perch√© le funzioni che restituiscono un booleano, sono un sottoinsieme delle funzioni che restituiscono T, quindi iniezione √® semplice da trovare e si dimostra.\nFunzione caratteristica Data un\u0026rsquo;insieme booleano, prendiamo un insieme che restituisce vero se l\u0026rsquo;elemento appartiene, falso se non lo fa.\n$\\mathbb{B}$ √® un insieme con due elementi indicati con 1, 0.\n$\\chi_c \\in \\mathbb{B} ^A$, posso dire che esiste una bigezione fra questo e l\u0026rsquo;insieme delle parti di A.\nAAAAAA, ovvio, per ogni sottoinsieme C, esiste una unica funzione che mi dice se questi elementi appartengono o meno ad A!\nImpossibilit√† eguaglianza in matematica Questo teorema ci dice che non si pu√≤ creare totalmente una funzione implementata che sia precisa come una funzione matematica.\nData una funzione che va da un insieme grande da un insieme grande, √® possibile che non possa essere implementata\nCuriosit√†\nPer il matematico, data una qualunque funzione, la probabilit√† che sia implementabile, √® molto vicina a Zero\nCostruzione di $\\mathbb{R}$ Immaginando un numero reale, si ha che un $n\\in\\R$ in pu√≤ rappresentare come una parte intera e una sequenza infinita di numeri dopo (di cui possiamo solo approssimare).\nCardinalit√† dei reali superiore di Aleph 0 Per semplicit√†, prendiamo la rappresentazione in base due di questo numero, allora questo $\\in B^\\N$\n(Questo si pu√≤ vedere senza molti problemi, quanto la sequenza √® infinita, prendo per ogni posizione dopo la virgola arriva a un numero Booleano)\nEs. 0,111100001111\u0026hellip;\nN 0 0123456789\u0026hellip;.\nMa se queste funzioni appartengono a questo spazio di funzioni, si pu√≤ finire dicendo che √® $|B^\\N| \u003e |N|$\nEsempio sulla densit√† di R I numeri hanno possibilmente infinite cifre dopo la virgola, ma √® possibile tenerli solamente per $\\dfrac{1}{10^n}$ con n il numero di cifre dopo la virgola (e ci stanno un sacco di numeri).\nQuesta successione tende chiaramente a 0. Quindi le probabilit√† sono quasi nulle.\n","permalink":"https://flecart.github.io/notes/relazioni-fra-insiemi/","summary":"Coppia ordinata Definizione di Kuratowsky Una coppia ordinata √® definita dall\u0026rsquo;insieme\n$$ \\langle X, Y \\rangle = \\{X, \\{X, Y\\}\\} $$ √à quindi chiaro che due coppie ordinate sono uguali fra di loro nel caso in cui gli elementi sono uguali ma anche la loro posizione sono uguali\nTeorema caratterizzazione delle coppie\nDefinizione di Wiener $$ (X,Y) := \\{\\{\\{X\\}, \\varnothing\\}, \\{\\{Y\\}\\}\\} $$ Definizione di Hausdorff $$ (X,Y) := \\{\\{X, 1\\}, \\{X,2\\}\\} $$ Propriet√† fondamentale coppie ordinate Due coppie ordinate si dicono uguali se e solo se il primo elemento dei due sono uguali e la stessa cosa per il secondo","title":"Relazioni fra insiemi"},{"content":"La cosa che rende il PO diverso rispetto agli sviluppatori √® la conoscenza delle necessit√† del cliente. Questo permette di prioritizzare del task e capire in che modo dovrebbe essere il prodotto finale. In questo modo si crea una vision del prodotto. Pensiamo che il PO debba condividere questa informazione e prendere decisioni di gruppo.\nDomande da fare: La user interface, come sembra il wireframe? Pensavamo di utilizzare i social solamente per i login, pensavate di utilizzare anche per altro durante il gioco? Bassa priorit√† (poter condividere i risultati con un post). Vorreste poter selezionare il livello del bot? Quanto sarebbe il massimo livello e quale il minimo? 4. Per kriegspiel la forza √® massima. Cosa √® la modalit√† \u0026lsquo;mob\u0026rsquo; per giocare (2 descrizione del problema documento progetto). si intende il social che permette di condividere mosse. tutte le persone interessante possono rispondere con tempo un giorno, e la maggioranza determina la risposta. Bassa priorit√†. Esistono i soci (utenti registrati) e non, cosa pu√≤ fare un utente non registrato? E quelli registrati? O definiamo noi? Che genere di commenti deve fare l\u0026rsquo;AI durante la partita? Va bene qualunque commento (anche in giro), commenti interessanti sul contesto). In che modo salvare una partita? Solamente la sequenza delle mosse o possibilit√† di riprendere la partita? Non √® richiesto poter salvare e riprendere nei giochi a informazione incompleta La seconda cosa interessante per l\u0026rsquo;utente? Leaderboard (non per noi, ELO). Cosa deve avere la leaderboard per giochi diversi da bad chess? Legato all\u0026rsquo;ELO questa, il classico. O mobile o web o come ci pare (non √® importante). No sicurezza, non √® importante. 50 giocatori max.\n","permalink":"https://flecart.github.io/notes/scelta-del-po/","summary":"La cosa che rende il PO diverso rispetto agli sviluppatori √® la conoscenza delle necessit√† del cliente. Questo permette di prioritizzare del task e capire in che modo dovrebbe essere il prodotto finale. In questo modo si crea una vision del prodotto. Pensiamo che il PO debba condividere questa informazione e prendere decisioni di gruppo.\nDomande da fare: La user interface, come sembra il wireframe? Pensavamo di utilizzare i social solamente per i login, pensavate di utilizzare anche per altro durante il gioco?","title":"Scelta del PO"},{"content":"This note will give a brief derivation of Stirling\u0026rsquo;s approximation. This bound is often useful for factorials. $$ x! \\approx x^{x}e^{-x}\\sqrt{ 2\\pi x } \\iff \\ln x! \\approx x\\ln x - x + \\frac{1}{2} \\ln(2\\pi x) $$ This proof (more like an interesting justification). is taken from page 2 of (MacKay 2003).\nLet\u0026rsquo;s start with a Poisson distribution with mean $\\lambda$ $$ P(r \\mid \\lambda) = \\frac{e^{-\\lambda}\\lambda^{r}}{r!} $$ If $\\lambda$ is large and $r \\approx \\lambda$, this distribution is approximated by a Gaussian distribution (it is often referred as a discrete Gaussian see Poisson processes). Assuming $r \\approx \\lambda$ we have $$ e^{-\\lambda} \\frac{\\lambda^{\\lambda}}{\\lambda!} \\approx \\frac{1}{\\sqrt{ 2\\pi \\lambda }} \\implies \\lambda! \\approx \\lambda^{\\lambda}e^{-\\lambda}\\sqrt{ 2\\pi \\lambda } $$ Which finishes the derivation of the approximation.\nApproximation of the binomial A quick derivation with the Stirling\u0026rsquo;s approximation gives a nice approximation for log of the binomials\n$$ \\ln \\binom{N}{r} \\equiv \\ln \\frac{N!}{(N - r)! r!} \\approx \\ln \\frac{N^{N} \\sqrt{ 2\\pi N }}{(N - r)^{N - r} \\sqrt{ 2\\pi (N - r) } r^{r} \\sqrt{ 2\\pi r }} = $$ $$ = N\\ln N + \\frac{1}{2}\\ln(2\\pi N) - (N - r)\\ln(N - r) - r\\ln r - \\frac{1}{2}\\ln(4\\pi^{2}(N - r)r) = $$ $$ = (N - r) \\ln\\left( \\frac{N}{N - r} \\right) + r \\ln \\left( \\frac{N}{r} \\right) + \\frac{1}{2}\\ln\\left( 2\\pi N \\frac{N-r}{N} \\frac{r}{N} \\right) $$ We observe there is an approximation similar to the formula of entropy, by grouping the $N$. It\u0026rsquo;s like the binary cross entropy formula $$ H_{2}(x) = x \\ln\\left( \\frac{1}{x} \\right) + (1- x)\\ln\\left( \\frac{1}{1 - x} \\right) $$ with $x = \\frac{r}{N}$, + another asymptotically constant approximation term (or $\\sqrt{ n }$ if you look at the logits..\nReferences [1] MacKay ‚ÄúInformation Theory, Inference and Learning Algorithms‚Äù Cambridge University Press 2003\n","permalink":"https://flecart.github.io/notes/stirlings-approximation/","summary":"This note will give a brief derivation of Stirling\u0026rsquo;s approximation. This bound is often useful for factorials. $$ x! \\approx x^{x}e^{-x}\\sqrt{ 2\\pi x } \\iff \\ln x! \\approx x\\ln x - x + \\frac{1}{2} \\ln(2\\pi x) $$ This proof (more like an interesting justification). is taken from page 2 of (MacKay 2003).\nLet\u0026rsquo;s start with a Poisson distribution with mean $\\lambda$ $$ P(r \\mid \\lambda) = \\frac{e^{-\\lambda}\\lambda^{r}}{r!} $$ If $\\lambda$ is large and $r \\approx \\lambda$, this distribution is approximated by a Gaussian distribution (it is often referred as a discrete Gaussian see Poisson processes).","title":"Stirling's Approximation"},{"content":"In questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders Blog di riferimento Blog secondario che sembra buono\nIntroduzione agli autoencoders L\u0026rsquo;idea degli autoencoders √® rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso √® la compressione con loss. Per cosa intendiamo qualunque tipologia di dato, che pu√≤ spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder. Una volta scelta una tipologia di dato, come per gli algoritmi di compressione, valutiamo come buono il modello che riesce a comprimere in modo efficiente e decomprimere in modo fedele rispetto all\u0026rsquo;originale. Abbiamo quindi un trade-off fra spazio latente, che √® lo spazio in cui sono presenti gli elementi compressi, e la qualit√† della ricostruzione. Possiamo infatti osservare che se spazio latente = spazio originale, loss di ricostruzione = 0 perch√© basta imparare l\u0026rsquo;identit√†. In questo senso si pu√≤ dire che diventa sensato solo quando lo spazio originale sia minore di qualche fattore rispetto all\u0026rsquo;originale. Quando si ha questo, abbiamo pi√π difficolt√† di ricostruzione, e c\u0026rsquo;√® una leggera perdita in questo senso.\nPropriet√† interessanti Vogliamo in un certo senso imporre una regolarit√† nello spazio latente perch√© questo ci permette di esprimere in un modo pi√π coerente da quanto ci attendiamo le cose dello spazio:\nSe prendiamo un punto vicino a un encoding noto, ci aspettiamo che sia simile al punto stesso Se prendiamo un punto del nostro spazio latente ci aspettiamo che dia qualcosa di sensato Rispettivamente queste propriet√† sono state chiamate continuit√† e completezza.\nVariational Auto-Encoders Intuizione L\u0026rsquo;idea sembra avere uno spazio regolarizzato, ossia un $z \\sim \\mathcal{N}(\\mu, \\sigma^{2}I)$ con $\\sigma$ vettore di dimensione spazio latente e $\\mu$ degli offset che rappresentano media. Quindi il decoder parametrizzato secondo $\\theta$ dovr√† essere in una forma dipendente da questa.\nInsieme a questo utilizziamo anche un encoder parametrizzato con $\\phi$ che dovr√† darci indicazioni su $z$, per esempio media e varianza.\nSecondo Murphy-1, Questo dovrebbe essere molto simile a un lavoro di uno 95, vedi capitolo su VAE in que libro.\nLa formulazione dei VAE sembra molto simile ai Factor Analysis. Che √® una caratterizzazione di un certo tipo sia spazio latente che quello normale.\nSetting del problema In questo senso vogliamo cercare di regolarizzare il nostro spazio latente assumendo che $$ p(x | z) \\sim \\mathrm{N}(media, varianza) $$ Ossia i samples della parte condizionata nello spazio latente non sono altro che una media e varianza dipendenti solo dalla parte condizionale, mentre $p(z) = N(0, 1)$ multidimensionale (quindi varianza $I$)\nELBO e derivazione Se assumiamo questo, allora la loss di Kullback-Leibler diventa abbastanza carina, perch√© infatti abbiamo che\n$$ KL(q_{x}(z), p(z|x)) = E_{x \\sim q_{x} }(\\log(q_{x}(z))) - E_{x \\sim q_{x}}\\left(\\log( \\frac{p(x, z)}{p(x)}) \\right) $$ $$ = E_{x \\sim q_{x}}(\\log(q_{x}(z))) - E_{x \\sim q_{x}}(\\log(p(x, z))) + E_{z \\sim q_{x}}(\\log(p(x))) = E_{z \\sim q_{x}}(\\log(p(x))) - E_{z \\sim q_{x}}\\left( \\log\\left( \\frac{p(x, z)}{q_{x}(z)} \\right) \\right) $$ Ora le ultime due si chiamano rispettivamente **evidence** e **ELBO** che sta per Evidence Lower Bound Notiamo che la evidence non dipende da $z$, infatti avremmo che $$ E_{z \\sim q_{x}}(p(x)) = \\int {-\\infty}^{+\\infty} q{x}(z) p(x) , dz = p(x) \\int {-\\infty}^{+\\infty} q{x}(z) dz = p(x) $$ Quindi se vogliamo minimizzare la divergenza, ci basta Massimizzare ELBO nel nostro caso.\nEsplicitazione di ELBO Possiamo lavorare ancora di pi√π su ELBO, provando ad esplicitarne alcuni valori, infatti possiamo considerare\n$$ ELBO = E_{z \\sim q_{x}}\\left( \\log\\left( \\frac{p(x, z)}{q_{x}(z)} \\right) \\right) =E_{z \\sim q_{x}}\\left( \\log\\left( p(x|z) \\right) \\right) + E_{z \\sim q_{x}}\\left( \\log\\left( \\frac{p(z)}{q_{x}(z)} \\right) \\right) $$ $$ = E_{z \\sim q_{x}}\\left( \\log\\left( p(x|z) \\right) \\right) - KL(q_{x}(z), p(z)) $$ Ossia abbiamo il secondo termine che prova a regolarizzare la distribuzione $q$ trovata, e il primo termine che √® un maximum likelihood, simile a quanto trovato per Na√Øve Bayes nel corso di Asperti. Questo √® la nostra loss per il VAE.\nOra l\u0026rsquo;ultimo passo sarebbe come esplicitare ELBO in modo che possa essere implementato come loss di una net?\nDerivazione della loss per VAE Vedere qui, √® calcolosa, ma molto carina, e ti permette di impratichirti con gaussiane multivariabili.\nAlla fine si avr√† come risultato:\n$$ KL(q_{x}(z), p(z)) = -\\frac{1}{2} \\sum_{j=1}^{J}(1 + \\log \\sigma^{2}_{j} - \\mu^{2}_{j} - \\sigma^{2}_{j}) $$ Derivazione di KL per la loss Vedere https://mr-easy.github.io/2020-04-16-kl-divergence-between-2-gaussian-distributions/. E poi sostituire. Per l\u0026rsquo;expectation della forma quadratica vedere qui https://statproofbook.github.io/P/mean-qf.html.\nAllora, sappiamo che $p(z) = \\mathcal{N}(0, \\mathcal{I})$ quindi ha una forma ben nota, dovremo cercare di fare questa piccolissima derivazione.\n","permalink":"https://flecart.github.io/notes/autoencoders/","summary":"In questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders Blog di riferimento Blog secondario che sembra buono\nIntroduzione agli autoencoders L\u0026rsquo;idea degli autoencoders √® rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso √® la compressione con loss. Per cosa intendiamo qualunque tipologia di dato, che pu√≤ spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder.","title":"Autoencoders"},{"content":"Introduction to design patterns Introduzione personale üü© I design patterns sono simili a dei plug and play, ossia delle soluzioni che hanno funzionato bene in passato e che sono ora riutilizzati. Solitamente dovrebbe essere una abilit√† implicita, cio√® un buon programmatore √® in grado di fare senza pensarci, dovrebbe essere automatico. Infatti quando uno fa il design non lo fa esplitamente seguendo un certo modello, ma farlo solitamente risulta utile per guidare il processo.\nDefinizione design pattern üü®++ Descriptions of communicating objects and classes that are customized to solve a general design problem in a particular context\nA Pattern describes a problem which occurs over and over again in our environment, and then describes the core of the solution to that problem, in such a way that you can use this solution a million times over, without ever doing it the same way twice\nCommon OO patterns Singleton üü© Questa la sai. Provi a ritornare un oggetto gi√† inizializzato che vive per tutto il tempo del tuo programma. √à il singoletto, qualcosa che esiste solamente una volta. Un pattern solito con questo √® il check dell\u0026rsquo;esistenza del valore statico, e il getter di istanza.\nComposite üü© In pratica √® un albero in cui solamente le foglie sono operazioni. √® stato utilizzato nelle slides per modellizzare un oggetto composto che deve semplicemente eseguire il codice dei figli (quindi diciamo un qualcosa di mezzo per poter dare in modo chiaro l\u0026rsquo;operazione corretta).\nIterator pattern üü®++ Viene utilizzato per scorrere qualcosa di generico, in C++ per esempio √® utilizzato in moltissime librerie standard. in Python √® possibile definire due metodi __next__ e __iter__ e anche in rust √® molto molto usato questo pattern.\nCreational Perch√© creational? (2) üü©\u0026ndash; Sono i pattern utilizzati per creare nuovi oggetti in modo sostenibile.\nAstrarre la creazione del singolo oggetto Incapsulamento, quindi voglio limitare l\u0026rsquo;accesso a informazione a solamente certi metodi ben definiti. Builder üü®+ https://refactoring.guru/design-patterns/builder\nIn questo caso abbiamo un director che in pratica orchestra la costruzione dei componenti reali. E singole componenti in cui sono specificati esattamente cosa fare. √à utile soprattutto quando ho qualcosa di molto complesso da costruire, che pu√≤ cambiare in molti modi. Un esempio √® il build di Zig credo.\nAbstract factory üü©\u0026ndash; https://refactoring.guru/design-patterns/abstract-factory\nServe soprattutto come interfaccia comune per andare a creare qualcosa di concreto (nel nostro caso una factory concreta). Ricorda l\u0026rsquo;esempio di sedia, tavoli, e stili diversi! Avere l\u0026rsquo;abstract factory ti permette di utilizzare la stessa interfaccia, quando nel concreto puoi produrre cose diverse. (dal punto di vista del cliente √® sempre la stessa cosa).\nFactory Method üü© https://refactoring.guru/design-patterns/factory-method\nDa un punto di vista intuitivo, questo √® solamente quando si utilizzano le classi virtuali. In C++ li abbiamo usati, vengono utili soprattutto quando la stessa funzione viene chiamata, la semantica √® uguale, ma l\u0026rsquo;implementazione cambia a seconda del tizio che la vuole usare tipo. Un esempio √® la funzione attacco dei mostri, che possono attaccare in molti modi, ma quello che vogliono fare √® attaccare.\nPrototype Structural Sono utilizzati come interfacce utili per far funzionare delle cose assieme.\nAdapter and Bridge Adapter viene utilizzato per problemi di nome, bridge per nascondere l\u0026rsquo;interfaccia Decorators Sono delle funzioni che ritornano altre funzioni con delle funzionalit√† aggiunte (e sono comode) se lo hai visto in python o JS lo conosci senza problemi. Per linguaggi statici tipo C √® pi√π difficile da mettere.\nProxy pattern Invece di accedere qualcosa in modo diretto usiamo una altra classe od oggetto che si occupa di controllare l\u0026rsquo;accesso, un esempio guardare i permessi, controllare altro, fare log o simili\u0026hellip; Behavioural I patter comportamentali definiscono quali sono le classi di responsabilit√† per una classe e una altra, e gli algoritmi da utilizzare.\nVisitor √à tipo una visita dfs, bfs, prende informazioni in modo strutturato senza cambiarne la struttura. Strategy √à un pattern che specialmente per librerie di python si vede spessissimo, si utilizza un identificatore e un dispatcher all\u0026rsquo;algoritmo corretto. Chain of responsibility √à una suddivisione di classi di responsabilit√†, come se fosse una catena di montaggio. Una cosa comune √® l\u0026rsquo;albero, e il responsabile diretto √® il suo parente, che magari deve gestire altro, non lo so. Se in un certo punto un check fallisce, la cosa non continua, ma viene cestinata.\nMediator Mi sembra simile alla reificazione che abbiamo studiato per la prima volta (in logica un po\u0026rsquo; ma di pi√π in) Design del database. ossia invece di avere $N^{2}$ collegamenti, basta avere un punto intermedio di comunicazione e abbassi di una potenza. √à la potenza del mediatore.\n","permalink":"https://flecart.github.io/notes/design-patterns/","summary":"Introduction to design patterns Introduzione personale üü© I design patterns sono simili a dei plug and play, ossia delle soluzioni che hanno funzionato bene in passato e che sono ora riutilizzati. Solitamente dovrebbe essere una abilit√† implicita, cio√® un buon programmatore √® in grado di fare senza pensarci, dovrebbe essere automatico. Infatti quando uno fa il design non lo fa esplitamente seguendo un certo modello, ma farlo solitamente risulta utile per guidare il processo.","title":"Design patterns"},{"content":"Determinanti I determinanti sono un numero associato alle matrici quadrate. Pi√π o meno ne sono il riassunto.\nPropriet√† Le prime 3 sono quelle fondamentali per calcolare il tutto, i numeri dopo il 3 sono alcune conseguenze.\ndet I = 1\nCambiare righe ‚Üí cambiare il segno della determinante.\n(Importante)\nSe moltiplico una riga per una costante, il determinante √® moltiplicato per questa costante. Se sommo una costante a una riga, allora il determinante √® una somma strana\u0026hellip; Immagine di esempio\nSe la matrice ha due righe uguali, il determinante √® 0, questo √® derivabile dalla propriet√† 2.\nSottrarre un multiplo di una riga a una altra riga della matrice produce la stessa determinante. (in pratica sto sottraendo una matrice che ha due righe uguali, la cui determinante √® 0).\nUna riga di 0 implica che il determinante dell‚Äôintera matrice sia 0, questo si pu√≤ dimostrare con 3a.\nData una matrice uppertriangular, il determinante √® la moltiplicazione degli elementi nella diagonale principale. (posso ottenere una matrice diagonale sottraendo all‚Äôins√π, e poi posso tirare fuori multipli per riga).\nL‚Äôultima propriet√† ci dice come si fa a calcolare il determinante, ossia ridurre in forma U e poi moltiplicare la diagonale. Ez. (da tenere in conto anche possibili cambi di riga).\ndet A = 0 quando A √® singolare (possiede una riga di 0) e det A ‚â† 0 quando non lo √® il determinante del prodotto di due matrici √® il prodotto delle determinanti delle due matrici, √® un isomorfismo! Questa propriet√† ci d√† anche il determinante dell‚Äôinverso in modo immediato, questo ci d√† anche un modo immediato per trovare l‚Äôinversa di una matrice diagonale (basta invertire tutti i numeri üôÇ) e questo √® anche un motivo per cui se invertibile not 0, altrimenti divido per 0. determinante della transposizione di A √® uguale al determinante di A, in quanto se ragioniamo nella forma diagonale la transposizione √® esattamente uguale ad A. Calcolo Possiamo splittare il calcolo della determinante in somme pi√π semplici. Inoltre possiamo notare che un determinante √® diverso da nullo, per la propriet√† 8 se non √® singolare, quindi vogliamo avere un elemento per ogni colonna e riga.\nContinuando questo ragionamento possiamo cercare di riassumere tutto in una unica formula\n$$ \\det A = \\sum_{\\text{n! sums}} P(\\alpha, \\beta, ..., \\omega) a_{1\\alpha} a_{2\\beta}...a_{n\\omega}\\\\ \\{\\alpha,\\beta, ..., \\omega\\} \\in \\text{ Perm of } \\{1,2,3...,n\\}, \\text{ where } A \\text{ is } n \\times n \\\\ P(\\alpha, \\beta, ..., \\omega) =\\begin{cases} 1 \\text{ if it's even permutation } \\\\ -1 \\text{ if it's odd permutation } \\end{cases} $$ Determinante come volume Per esempio se prendiamo una matrice 3x3, possiamo prendere ogni punto identificato da una riga come 3 punti. Questi tre punti riescono ad identificare una scatola. (ogni lato √® un parallelogramma e il volume del cubo √® uguale al determinante).\nCofattori I cofattori sono utili per semplificare il calcolo della determinante presentata in precedenza.\nIn altre parole si potrebbe dire che il determinante di una matrice quadrata grossa si potrebbe ridurre come una combinazione lineare di alcune sottomatrici.\nDeterminante con cofattori Quindi il calcolo del determinante si pu√≤ riassumere come\n$$ \\det A = \\sum_{i=1}^{n} a_{1i}C_{1i} $$ Inverse con cofattori Si potrebbe notare che questo sia il metodo matematico per l‚Äôinverso, mentre le eliminazioni con il metodo di Gauss Jordan √® il metodo pi√π informatico.\n$$ A^{-1} = \\dfrac{1}{\\det A} C^T $$ Che √® equivalente nel verificare che\n$$ \\det A \\cdot I = A C^T $$ E questo ha senso, se moltiplico per righe corrispondenti ho la formula sopra per il determinante per riga.\nMentre se lo faccio per tutte le altre righe √® come se stessi calcolando il determinante con una riga doppia, quindi il determinante √® 0 per quelle righe.\nSe utilizzo questo risulato, posso derivare la formula di cramer\nRegola di cramer $$ Ax = b \\\\ x = A^{-1}b \\\\ x = \\dfrac{1}{\\det A} C^T b $$ Questo √® code rimpiazzare la prima colonna della matrice A con b\nQuesto algoritmo √® lentissimo, costa molto calcolare un determinante.\nAutovettori Moved to Autovalori e Autovettori the 19th of July 2024.\n","permalink":"https://flecart.github.io/notes/determinanti/","summary":"Determinanti I determinanti sono un numero associato alle matrici quadrate. Pi√π o meno ne sono il riassunto.\nPropriet√† Le prime 3 sono quelle fondamentali per calcolare il tutto, i numeri dopo il 3 sono alcune conseguenze.\ndet I = 1\nCambiare righe ‚Üí cambiare il segno della determinante.\n(Importante)\nSe moltiplico una riga per una costante, il determinante √® moltiplicato per questa costante. Se sommo una costante a una riga, allora il determinante √® una somma strana\u0026hellip; Immagine di esempio","title":"Determinanti"},{"content":"See https://peterbloem.nl/blog/pca series. The main idea is to find the directions with the most variance in a dataset. Those will be principal components.\nThere is a very easy derivation present in (Bishop \u0026amp; Bishop 2024). It is also known as the Kosambi-Karhunen-Lo√®ve transform (you will probably like this name more if you are from physics). Another good resource is the Wilkinson.\nTechnique setting Le\u0026rsquo;t say we have $\\left\\{ \\boldsymbol{x}_{n} \\right\\}$ observations of dimension $D$ and $n \\in \\left\\{ 1, \\dots, N \\right\\}$. We want to project this onto a dimension $M$, with the constraint of maximizing the variance of the projected data. Let\u0026rsquo;s say $u$ is our basis matrix.\nMaximum variance approach If $M=1$ then we have a single direction, and it\u0026rsquo;s easy to see that the projected points are $u^{T}\\boldsymbol{x}_{n}$. Then we can easily calculate the statistics. Mean: $$ \\bar{x} = \\frac{1}{N} \\sum_{n=1}^{N} x_{n} \\implies \\text{ mean is }u^{T}\\bar{x} $$ The variance: $$ \\frac{1}{N} \\sum_{n = 1}^{N} \\left( u^{T}x_{n} - u^{T}\\bar{x} \\right) ^{2} = u^{T}Su $$ With $S$ the covariance matrix defined as $S = \\frac{1}{N}\\sum_{n = 1}^{N} (x_{n} - \\bar{x}) (x_{n }- \\bar{x}) ^{2}$. And then we can try to maximize $u^{T}Su$ with respect to $u$. With the condition that $u^{T}u = 1$ so that it is a normalized direction, we can use the Lagrange Multipliers technique explained in Duality Theory#Lagrangian function. So our optimization problem is $$ \\text{ minimize } f(u, \\lambda) = u^{T}Su - \\lambda(1 - u^{T}u) $$ And we use the multi-variable optimization tools, derived in Massimi minimi multi-variabile to see that $$ \\frac{ \\partial f(u, \\lambda) }{ \\partial u } = 2Su - 2\\lambda u $$ Which equated to zero for a stationary point we have $Su = \\lambda u$ which is then just try to find the eigenvalues of $S$, explained here Determinanti. Now if we use some maths and the property that $u^{T}u = 1$ we observe that the variance is exactly the Lagrange multiplier: $u^{T}Su = \\lambda$. So the eigenvectors of $S$ describe the variance, and this variance will be the largest when we chose the biggest eigenvector. This is also why we call it first principal component.\nThe above is also known as the Rayleigh quotient optimization problem, where the covariance matrix is a special case.\nDerivation of the covariance property If you are not familiar with matrix calculation and are unsure about why this is true check the following argument:\nWe know that: $$ \\left( u^{T}x_{n} - u^{T}\\bar{x} \\right) ^{2} = (u_{1}x_{1} + \\dots + u_{M}x_{M} - u_{1}\\bar{x}{1} - \\dots - u{M}\\bar{x}_{M})^{2} $$ $$ = \\sum_{i = 1}^{M} (u^{2}{i}x^{2}{i} + u_{i}^{2}\\bar{x}^{2}_{i})\n2\\sum_{i\\neq j}^{M} u_{i}u_{j}x_{i}x_{j} 2\\sum_{i,j=1, 1}^{M} u_{i}u_{j}x_{i}\\bar{x}_{j} 2\\sum_{i \\neq j}^{M} u_{i}u_{j}\\bar{x}{i}\\bar{x}{j} $$ Note: first i used $n$ to indicate the nth vector, then i used $i$ to index the $n$-th vector, take care of this thing. Now let\u0026rsquo;s compare the last result with the covariance matrix. We have in the covariance matrix what $$ S_{ij} = (x_{n} - \\bar{x})_{i} (x_{n} - \\bar{x})_{j} = x_{i}x_{j} - x_{i}\\bar{x}_{j} - \\bar{x}_{i}x_{j} + \\bar{x}_{i}\\bar{x}_{j} $$ And summing $S_{ij} + S_{ji}$ we have $2(x_{i}x_{j} + \\bar{x}_{i}\\bar{x}_{j} - x_{i}\\bar{x}_{j} - \\bar{x}_{i}x_{j})$ Which takes care of all the sums where $i \\neq j$ when we calculate the $u_{i}S_{ij}u_{j} + u_{j}S_{ji}u_{i}$ When $i = j$ we observe that $S_{ii} = x_{i}^{2} + \\bar{x}_{i}^{2} - 2x_{i}\\bar{x}_{i}$. This proves the relation, just a lot of sums.\nMulti-variable derivative To the people that are not used to matrix derivatives (like me) it could be useful to see how $$ \\frac{ \\partial u^{T}Su }{ \\partial u } = 2Su $$ First, we note that if you derive with respect to some matrix, the output will be of the same dimension of that matrix. That notation is just deriving every single component independently and then joining them together, so it will be better understood as as $$ \\frac{ \\partial u^{T}Su }{ \\partial u } = \\begin{bmatrix} \\frac{ \\partial u^{T}Su }{ \\partial u_{1} } \\ \\dots \\ \\frac{ \\partial u^{T}Su }{ \\partial u_{M} } \\ \\end{bmatrix} \\begin{bmatrix} 2(Su){1} \\ \\dots \\ 2(Su){M} \\end{bmatrix} = 2Su $$ So we can prove each derivative independently, it's just a lot of manual work! We see that $u^{T}Su$ is just a quadratic form, studied in [Massimi minimi multi-variabile#Forme quadratiche](/notes/massimi-minimi-multi-variabile#forme-quadratiche) so it is just computing this: $$ u^{T}Su = \\sum_{i, j = 1, 1}^{M} u_{i}u_{j}S_{ij} \\implies \\frac{ \\partial u^{T}Su }{ \\partial u_{1} } =2u_{1}S_{11} + \\sum_{j \\neq 1}^{M}(u_{j}S_{1j} + u_{j}S_{j1}) = 2\\left( u_{1}S_{11} + \\sum_{j \\neq 1}u_{j}S_{1j} \\right) = 2(Su)_{1} $$ Last equation is true because $S$ is a symmetric matrix, then we easily see that indeed it\u0026rsquo;s true that indeed it\u0026rsquo;s the first row of the $Su$ matrix multiplied by 2.\nProof by induction Now that we know the general idea in the special case where $M = 1$ we want to generalize this approach, and say that it works also for the case where $M = N$. We have the base case of our induction done, we assume inductively that the $\\lambda_{1}, \\dots \\lambda_{N}$ the ordered eigenvectors of the covariance matrix are the best solution to our optimization problem when we still take the next eigenvector. By induction we know that those eigenvectors are orthonormal and that the projection matrix defined by them, that we call $w$ is the one that maximizes the variance, now defined as $u^{T}Su$. with $w : \\mathbb{R}^{D} \\to \\mathbb{R}^{M}$. Let\u0026rsquo;s add a column to this projection matrix. We have other conditions caused by the fact that we want orthonormal vectors. Let\u0026rsquo;s call $v_{1}, v_{2}, \\dots, v_{N}$ the eigenvectors associated to the found eigenvalues, then the Lagrange Multipliers technique tells us to $$ \\text{ maximize } u^{T}Su + \\lambda(1 - u^{T}u) + \\sum_{k = 1}^{N} \\mu_{k} (0 - u^{T}v_{k}) $$ We derive with respect to $w$ and we have $$ 2Su - 2\\lambda u - \\sum_{k= 1}^{N}\\mu_{k}v_{k} \\implies \\lambda = $$ Now to continue this multiplication, the trick is to multiply this by $v_{l}$ and then we have $$ 2v_{l}Su - 2\\lambda v_{l}u - \\sum_{k=1}^{N}\\mu_{k}v_{l}v_{k} = 0 - 0 - \\mu_{l}v_{l}^{2} $$ which implies that $\\mu_{l}=0$ we can repeat this for all $\\mu$ and show that all of those coefficients should be 0, this falls back to the original proof, and in this way we know that it is the next possible eigenvector, because if not it would not be orthonormal.\nReferences [1] Bishop \u0026amp; Bishop ‚ÄúDeep Learning: Foundations and Concepts‚Äù Springer International Publishing 2024\n","permalink":"https://flecart.github.io/notes/principal-component-analysis/","summary":"See https://peterbloem.nl/blog/pca series. The main idea is to find the directions with the most variance in a dataset. Those will be principal components.\nThere is a very easy derivation present in (Bishop \u0026amp; Bishop 2024). It is also known as the Kosambi-Karhunen-Lo√®ve transform (you will probably like this name more if you are from physics). Another good resource is the Wilkinson.\nTechnique setting Le\u0026rsquo;t say we have $\\left\\{ \\boldsymbol{x}_{n} \\right\\}$ observations of dimension $D$ and $n \\in \\left\\{ 1, \\dots, N \\right\\}$.","title":"Principal Component Analysis"},{"content":"Cascading Style Sheets Inizialmente HTML era per la presentazione, abbiamo ancora un p√≤ di attributi storici e tag storici per questa parte di presentazione descritto in HTML e Markup.\nIntroduzione √à un linguaggio indipendente per la descrizione della grafica. La cosa bella √® iil fatto di essere indipendente, quindi √® adatto a HTML, a XML e simili.\nUna cosa particolare √® il cascading quindi il fatto che dichiarazioni pi√π nuove sovrascrivano o espandino dichiarazione vecchie.\nLivelli di CSS (cose storiche)\nSulla sintassi Statements Slide struttura dei statements\nLa sintassi classica di uno statements CSS √® in\npropriet√†: valore;\nE il problema per uno sviluppatore √® conoscere cosa fa una propriet√† e che esista üòÄ\nSelettori (!!) Slides selettori\nTipologia del markup e.g. h1 Selettore di classe e.g. .class Selettore di ID e.g. #id Slides selettori 1 pseudo elementi\nFirst letter (utilizzati per il capolettera nei testi vecchi. first Line Before, after sono aree, che normalmente sono vuote, riempibili con content Esempio hover, active e molte altre! https://developer.mozilla.org/en-US/docs/Web/CSS/Pseudo-elements Selettori di prossimit√†\nFiglio di un elemento Elemento figlio diretto. Successivi Tutti i successivi Selettori di attributi\nSelettori pseudo classi strutturali\nPotrebbero essere classi ma non lo sono davvere le pseudoclassi.\nSelettori pseudoclassi\nQui ci sono molti altr icontenuti https://developer.mozilla.org/en-US/docs/Web/CSS/Pseudo-classes\nTipi di dato Come numero o valori assoluti (e.g. col z index, o se non specifico sono dei pixel che √® pericolosa perch√© cambia da device a device il feeling che si avr√†, la dim dei pixel cambia!) o misure di lunghezza che sono moltissime per CSS, vedi slide\nSlide per tipi di misura\nE per i colori, come √® gi√† stato citato in HTML e Markup :\nSlide tipi di dato per colori\nCanvas e Viewport Il canvas √à una area di dimensione indefinita che si amplia secondo necessit√†. Cresce verso destra o verso il basso. Solitamente su screen √® sempre il pixel l\u0026rsquo;unita principale, ma questo dipende dalla risoluzione degli schermi e grandezza di essi! (anche le stampanti hanno scalabilit√† diverse).\noffscreen drawing √® una strategia per disegnare e mostrarti solamente quando il risultato √® pronto. Si disegna su coordinate negative, che non sono visibili, e poi quando √® pronto copiartela in coordinata positivia.\nViewport √® la parte visibile dello schermo. Solitamente su schermi PC ho una grandezza a piacere, √® solamente una cosa che interessa principalmente ai cellulari questo viewport. esiste il tag viewport come suggerimento, ma meglio non avere le misure di pixel.\ncasi in cui √® ok fare pixel:\ndire 0 pixel per dire che non lo voglio mostrare nello schermo dire 1 pixel per avere la cosa pi√π fine che possono avere Unit√† di misura di viewport Sono vh e vw che rappresentano la width e height, nel pC √® la dimensione della finestra, pe ri cellulari √® sempre lo schermo massimo.\nesistono anche cose come vmin e vmax che sono il pi√π piccolo fra vm e vh, e il massimo, quindi utilizzo questi per sopravvivere al cambio di oreintamento per lo smartphone.\nIl flex √à la misura dello spazio rimasto nel contenitore. √à solo una cosa che mi permette di calcolare pi√π velocemente le dimensioni, senza che debba andare io a guardarlo.\nSlide misura del flex\nSistema a scatole (flexbox) Ogni elemento ha una scatola che contiene l\u0026rsquo;elemento, e se un elemento sta all\u0026rsquo;interno allora la scatola esterna conterr√† l‚Äôelemento al suo interno\nFlussi, display Slide flussi\nPer la nostra concezione occidentale questi flussi corrispondono al nostro modo di scrivere.\nSolitamente se non voglio fare qualcosa di particolare non vado a specificarlo, ogni tag ha gi√† un suo display proprio.\nElementi della scatola (4) Margine\nBordo\nPadding\nContenuto\nSlide Scatola\nSlide tipografia per la scatola\nFlexbox c\u0026rsquo;√® moltissima altra roba sul flex box ma per ora non sono citati. √à molto flessibile e si riesce ad adattare in modo dinamico a molte cose.\nMentre Grid assumeva di avere un coso fisso.\nPosizionamento della scatola Slide Position\nSlide float, left, top, bottom, right\nZ-index\nstatico √® il default\nAssoluto √® dipendente dal canvas senza tenere conto del flusso\nRelativo √® relativo alla sua posizione naturale\nfisso √® relativo alla viewport.\nsticky resta in viewport quando proviamo ad uscire, altrimenti resta in canvas nella sua naturale.\nOltre position abbiamo anche altre propriet√†, che puoi esservare in slide.\nOverflow (3) Overflow\nVisible quando tutto il testo di overflow √® visibile Hidden quando l\u0026rsquo;overflow non si vede ed √® nascosta. scroll quando √® scrollabile, e la parte di scroll toglie spazio al testo, e sono diverse nei sistemi operativi ste scrollbar, mentre in smartphone non esistono. Il display Slide display\nFonts famiglia\nPeso e stile\nFonts preesistenti\nDecorazioni e spazi\nAltre propriet√† di CSS Ereditariet√† Display e background non sono ereditati Il resto si eredita sempre. Important Allora quanto caricato non viene modificato da riscritture successive.\nOrdine di cascata Slide ordine di cascata\nslide ordine 2\nNormali: che non sono important.\nElementi di Tipografia (non fare) Introduzione Graphic design Slide riguardo storia del graphic design\nStoricamente era fatta da emanuense che copiava tutto, questo lo sai, poi quando √® stato inventato la stampa si √® creato il nuovo mestiere del tipografo, in cui ci sono una serie di caratteri standarizzati che vengono utilizzati come struttura standard.\nDivisi in 3 sezioni principali:\nTipografia Layout (organizzazione della pagina) Organizzazione iconografica (visual art della pagina diciamo) Tipografia La tipografia √® la disposizione armoniosa di tipi (forme di caratteri precostituite) al fine di creare testo leggibile e piacevole alla vista sulla pagina e sugli schermi digitali. Si distingue dalla calligrafia, che √® l\u0026rsquo;armoniosa disposizione sulla pagina di caratteri scritti a mano ed individualmente.\nInizialmente era fatto con legno incavato, ma questo si rovinava molto infretta ed era molto difficile da fare. Gutemberg ebbe l\u0026rsquo;idea di farlo in piombo, utilizzando forme ben definite uguali fra di loro.\nQuesto √® fatto in modo da mantenere un buoon grigio tipografico, ossia equilibrio fr aspazio bianco e stampa in nero.\nFino in questo periodo era molto difficile creare periodici e avere stampa. Questo fino a quando linotype (line of type) che √® in grado di generare al volo la lettera di piombo dopo un tasto. Ebbe un buon successo, azienda americana. Ecco qui che si possono fare i quotidiani. (il problema √® che √® rumoroso, pericoloso per i fumi di piombo e il calore. etc, non √® una cosa da ufficio).\nMeccanismi fotosensibili\nQuesta √® una stampa automatica che utilizzano un fenomeno fisico e una carta fotosensibile, questa √® l\u0026rsquo;industria di stampa a freddo, ossia cold type. E in questo periodo nasce l\u0026rsquo;informatica, e nacque l‚Äôidea di controllare automaticamente questo processo con un programma.\nMarkup languages\nQuesti sono linguaggi nati per controllare le macchine per la stampa a freddo, escono linguaggi come GML, oppure POSTSCRIPTS di Adobe, al tempo una piccola startup di Silicon valley, che poi inventa anche i PDF (versione indipendente dall‚Äôhardware, semplificato e molto portabile a differenza di postscript). Questo aiuta la crezioen di desktop publishing, quindi facile da stampare una volta disegnato sul computer.\nFont Collezzioni di carattere con un certo stile che si possano disporre in modo armonioso. (solitamente per lettere, punteggiatura e numeri).\nFont family e font type Un font √® una collezione di forme di caratteri integrate armoniosamente per le necessit√† di un documento in stampa\nUn type face (o font-family) √® uno stile unico di caratteri che viene espanso in molti font di dimensione e peso e stili diversi.\nTipologie di font (5) Solitamente i font sono una arte occidentale, c‚Äô√® molta meno teoria per i font delle altre culture.\nSlide tipologie di font\nClassificazione di Font (non farlo) Slide classificazioen francese Vox Atypl\nSlide classificazione Novarese\nLe componenti fondamentali di un font: (tanti modi per valutare!)\nCap Serif or sans serif The strokes Ascender or descenders height or x-height (altezza media delle lettere, di solito la x). Letter spacing or kernel Slide componenti fondamentali\nBisogna fare distinzione fra stili e pesi, solitamente l\u0026rsquo;italico √® diverso dal normale, non √® solamente l‚Äôobliquo (il normale leggermente inclinato) e posso avere grandezze (aka pesi) diversi che mi vanno a determinare quanto sono bold.\nBlocchi\nSono una organizzazione del testo, che pu√≤ essere di tanti tipi.\nCi sono certe cose che i tipografi non piaccino come vedove, caccole di mosca, orfani, rivoli o header separati, bandiere\nColore Cosa che mi ha stupito √® che l\u0026rsquo;occhio proprio riesce a percepire solamente 3 colori differenti (wavelengths) che poi vengono interpretati in modo differente).\nSlide spazi di colore\nRGB e RGBa Sono una forma di colore additivo con un canale di Alpha. Se metto tutti i colori ho il bianco. Solitamente questo non √® una cosa lineare.\nSlide RGB\nCYMK Sono dei colori Sottrattivi, quindi aggiungendo tutti ottengo il Nero. Nella pratica il quarto colore √® necessario, anche se non lo sarebbe nel senso teorico (avrei un marrone strano senza il nero, ).\nSlide CYMK\nPage Layout Un altro componente molto importante del design √® il layout, ossia una\nPage layout √® la disposizione aromoniosa degli elementi visuali sulla pagina.\nUn p√≤ di storia Storicamente alcuni elementi come la spessore delle pagine era molto importante (perch√© questo implicava la visibilit√† o meno del carattere dall‚Äôaltra parte della pagina.) Una carta di lusso era importante lo spessore, la ruvidit√†.\nAnche lacuni problemi riconducibili ad affiancamento di pagine, che potrebbero dare un altro significato. Quindi importante andare anche a controllare il contenuto intorno.\nAspetti di Page Layout (6) ORIENTAMENTO\nSlide orientamento\nStoricamente i computer sono sempre stati landscape, cos√¨ come erano i video del cinema. Con l‚Äôarrivo dei cellulari abbiamo cominciato a preferire l‚Äôorientamento portrait. A livello naturale circ a 10 pollici c‚Äô√® uno switch.\nQuesto √® importante perch√© a seconda del nostro target decidiamo il layout.\nASPECT RATIO\nSlide aspect ratio\nCi dice il rapporto fra altezza e larghezza. E ce ne sono molti di aspect ratio.\nIl quadrato non √® mai stato utilizzato in editoria, ma solamente in opere d‚Äôarte carine. US letter √® la carta delle stampanti, anche quello per le lettere di mail 4/3 √® quello dei film, fino ai 2002. 11/8 poi √® messa bandina nera sopra e sotto per essere adatta a 4/3 Holliwod ISO216 √® la carta A4 e ha certe propriet√† particolari 16/10 √® il rapporto classico dei computer, molto vicino al rapporto aureo. US Legal √® una carta un p√≤ pi√π lunga utilizzata nella pubblica amminsitrazione 16/9 sono schermi allungati, utili per TV nuove. Molto bello quando ho dei panorami nei film, quindi schermo cos√¨ meglio. 18/9 Per smartphone, perch√© per le dita non mi conviene allungarl inell‚Äôaltro verso, quindi meglio farli lunghi. Altre su ragionamenti simili. DIMENSIONI\nDimensione\nIl fatto che sia radice, √® molto importante perch√© ci permette di duplicare con due fogli. Si parte con A0 che √® un metro quadro.\nRISOLUZIONE\nSlides risoluzione\nSe siamo ancora in ambiente anglossassone, utilizziamo come unit√† di misura il pollice. Normalmente √® di densit√† (importante soprattuto per la stampa digitali), ma attualmente √® il valore assoluto di pixel nello schermo.\nGRIGLIE DI LAYOUT\nSlides griglie\nLo scopo principale dei Layout √® allineare in maniera bella. Solitamente il numero bello √® 12, perch√© si possono creare dei bei rapporti, infatti anche twitter boostrap utilizza questo formato.\nUna griglia pu√≤ essere densa o con molto spazio, in questo caso si dice che le celle hanno breathing.\nSEZIONE AUREA\nSlides sezione aurea\n√à un rapporto che sembra molto carino.\n","permalink":"https://flecart.github.io/notes/css/","summary":"Cascading Style Sheets Inizialmente HTML era per la presentazione, abbiamo ancora un p√≤ di attributi storici e tag storici per questa parte di presentazione descritto in HTML e Markup.\nIntroduzione √à un linguaggio indipendente per la descrizione della grafica. La cosa bella √® iil fatto di essere indipendente, quindi √® adatto a HTML, a XML e simili.\nUna cosa particolare √® il cascading quindi il fatto che dichiarazioni pi√π nuove sovrascrivano o espandino dichiarazione vecchie.","title":"CSS"},{"content":"Entropy Questo √® stato creato da 1948 Shannon in (Shannon 1948). Questa nozione √® basata sulla nozione di probabilit√†, perch√© le cose rare sono pi√π informative rispetto a qualcosa che accade spesso. This is dependent on the notion of the Shannon information content defined as $$ h(x = a_{i}) = \\log_{2}\\frac{1}{P(x = a_{i})} $$ We will see that the entropy is a weighted average of the information, so the expected information content in a distribution. TODO: define this better.\nKolmogorov complexity √® un modo diverso per definire la complessit√†. Legato √® Neural Networks#Kullback-Leibler Divergence.\nWe can model the classical view of entropy as the from [^1]\nExpected value of Surprisal which is the uncertainty of a random variable $X$ taking a certain value which is $p(X = x) = P(x)$, but we want to measure it using log-likelihood.\n$$ H(\\cdot) = - \\sum p(x)\\log(p(x)) \\tag{1.1} $$ Ossia, possiamo dire in modo intuitivo quanto sarebbe sorprendente vedere che si avverasse quell\u0026rsquo;evento.\nOppure come descritto da [^2] $$ \\begin{align*} H(X) := E[I(X)] \u0026= \\sum_{i=1}^n P(x_i)I(x_i) \\\\ \u0026= \\sum_{i=1}^n p_i \\log(1/p_i) \\\\ \u0026= -\\sum_{i=1}^n p_i \\log(p_i) \\tag{1.2} \\end{align*} $$ Conditional Entropy $$ H(Y|X) = \\sum_{x \\in \\mathcal{X}}p(x) H(Y|X=x) = \\sum_{x \\in \\mathcal{X}, y \\in \\mathcal{Y}} p(x, y) \\log \\frac{1}{P(y|x)} = \\mathbf{E}\\left[ \\log\\frac{1}{p(Y|X)} \\right] $$ La nozione con il valore atteso √® la pi√π semplice anche in questo caso.\nChain Rule Una propriet√† random √® $$ H(X, Y) = H(X) + H(X|Y) $$ La dimostrazione √® abbastanza banale una volta che si conoscono le definizioni\u0026hellip;. La cosa interessante √® che si pu√≤ generale per qualunque numero di variabili aleatorie: $$ H(X_{0}, X_{1}, \\dots, X_{i}) = \\sum_{i}H(X_{i}|X_{i-1}\\dots X_{0}) $$ Upper bound $$ H(X) \\leq \\log \\lvert \\mathcal{X} \\rvert $$ Con $\\mathcal{X}$ l\u0026rsquo;insieme immagine della variabile aleatoria discreta $X$. Importante in questo caso che la nostra variabile sia discreta, altrimenti il teorema provvisto in (Cover \u0026amp; Thomas 2012) 2.6.4 non funziona. Non √® molto banale l\u0026rsquo;idea di utilizzare la uniforme per modellare il numero di elementi. e usare la positivit√† di KL per finire l\u0026rsquo;upper bound.\nEntropy is concave Uso l\u0026rsquo;upper bound e il fatto che KL √® convesso per dimostrare questa cosa.\nFunctional dependency Se $Y = f(X)$ per qualche funzione, allora $H(Y|X) = H(X|Y) = 0$ si pu√≤ risolvere con qualche ragionamento sul supporto di entropia. Interessante vedere che ha una piccola relazione con Normalizzazione dei database#Dipendenze funzionali.\nRelative Entropy or Kullback-Leibler In modo praticamente equivalente possiamo definire una versione condizionata. e si pu√≤ applicare anche in questo caso una chain rule $$ DL(P(x, y) \\mid\\mid Q(x, y) = DL(P(x) \\mid\\mid Q(x)) + DL(P(x|y) \\mid\\mid Q(x|y)) $$ KL is positive or null Ossia per ogni distribuzione $p$ o $q$ si ha che $$ DL(X \\mid\\mid Y) \\geq 0 $$ Con uguaglianza se hanno esattamente la stessa distribuzione.\nE ricordandoci che $\\log$ √® una funzione concava, quindi si pu√≤ utilizzare Jensen. Lo dimostriamo ora in breve. Sappiamo che la funzione $-\\log(x) = \\log\\left( \\frac{1}{x} \\right)$ √® una funzione convessa, perch√© il negativo di una funzione concava, che √® il logaritmo.\nAllora consideriamo $\\frac{1}{u} = \\frac{Q(x)}{P(x)}$ che √® la parte dentro al logaritmo perch√© cos√¨ possiamo usare Jensen Allora comunque abbiamo\n$$ \\sum_{x} P(x) \\log\\left( \\frac{Q(x)}{P(x)} \\right) \\geq \\log\\left( \\sum_{x} P(x) \\cdot \\frac{Q(x)}{P(x)} \\right) = \\log(1) = 0 $$ Che conclude che $$ D_{KL}(P \\mid \\mid Q) \\geq 0 $$ In modo facile.\nKL is convex $DL(p\\mid\\mid q)$ √® convesso sulla coppia $(p, q)$, 2.7.2 di (Cover \u0026amp; Thomas 2012). Anche sula 2.26 di McKay √® buono, anche se non esattamente parla di questo.\nMutual information Questa nozione definisce quanta informazione hanno in comune due variabili aleatorie\nDefinizione $$ I(X;Y) = \\sum_{x}\\sum_{y} p(x, y) \\log\\left( \\frac{p(x, y)}{p(x)p(y)} \\right) = H(X) - H(X|Y) $$ Si pu√≤ fare dopo un po\u0026rsquo; di calcoli che qui ho omesso, ma non dovrebbe essere difficile farlo.888\nSi pu√≤ intendere la mutual information anche come KL fra le distribuzioni $p(x, y)$ e $p(x)p(y)$ si pu√≤ notare che queste due sono uguali quando le due sono indipendenti, che √® coerente con la nostra nozione che abbiamo dell\u0026rsquo;indipendenza.\nPropriet√† Sufficient Statistics Possiamo rappresentare il sampling da una certa famiglia di distribuzioni $f_{\\theta}(x)$ , rappresentato da $X$, e una sua statistica a caso (media varianza etc, che credo basti una funzione sul valore) come T, allora possiamo rappresentarlo come una Markov Chains#Catena di 3 variabili $\\theta \\to X \\to T(X)$ E vale il teorema di information processing\n$$ I(\\theta; T(X)) \\leq I(\\theta; X) $$ Si pu√≤ chiamare una statistica per $\\theta$ sufficiente se $X$ contiene tutta l\u0026rsquo;informazione di $\\theta$. Non so bene cosa significhi. La cosa importante √® che la statistica sufficiente preserva la mutua informazione ossia si ha una uguaglianza in quella relazione di sopra. Vedere 2.9 di (Cover \u0026amp; Thomas 2012) per esempi .\nQuesta cosa potrebbe permettere di dire che usando quella statistica io posso dimenticarmi del parametro, perch√© riesco a ricavarmelo senza problemi credo\u0026hellip;.\nThe purpose of sufficiency is to demonstrate that statistics that satisfy this property do not discard information about the parameter, and as such, estimators that might be based on a sufficient statistic are in a sense \u0026ldquo;good\u0026rdquo; ones to choose.\nDa https://math.stackexchange.com/questions/1186645/understanding-sufficient-statistic.\nFano\u0026rsquo;s inequality L\u0026quot;idea principale √® utilizzare una variabile aleatoria per stimarne una altra, usando l\u0026rsquo;entropia condizionale fra le due.\nEnunciato fano Per ogni estimantore $\\hat{X}$ tale per cui $X \\to Y \\to \\hat{X}$ sia una catena di markov, e con $P_{e} = Pr(X \\not= \\hat{X})$ ossia la probabilit√† di errore, abbiamo che vale $$ H(P_{e}) + P_{e}\\log \\lvert \\mathcal{X} \\rvert \\geq H(X|\\hat{X}) \\geq H(X|Y) $$ Ci sono forme pi√π deboli che possiamo considerare in un certo senso corollari, ossia che $$ 1 + P_{e} \\log \\lvert \\mathcal{X} \\rvert \\geq H(X|Y) $$ Dimostrazione Fano Questa √® una bomba da fare. Poi per√≤ ha un sacco di conseguenze non applicabili in modo immediato (cio√® non ci arrivi subito se non le fai un po\u0026rsquo; prima).\nMaximum Distribution entropy Un problema classico nella teoria dell\u0026rsquo;informazione √® trovare la distribuzione che massimizzi l\u0026rsquo;entropia (quindi l\u0026rsquo;informazione contenuta credo) dati certe conoscenze a priori, Ossia data una funzione $f$ e certe condizioni che deve rispettare, massimizzare l\u0026rsquo;entropia.\nSI pu√≤ dimostrare (lo si pu√≤ vedere da una reference di sopra) che la distribuzione che massimizza l\u0026rsquo;entropia, avendo solamente la condizione di probabilit√†, ossia che $\\sum_{x}p(x) = 1$ √® la distribuzione uniforme. Mentre se assumo anche media $\\mu$ e varianza $\\sigma^{2}$ allora √® la gaussiana. In un certo senso possiamo dire che queste distribuzioni sono molto ricche di informazioni.\nCodewords Jensen\u0026rsquo;s Inequality Questo √® un teorema fondamentale per moltissime cose, e da un certo punto di vista √® una cosa banale per le cose convesse/concave. Allora, sia data una funzione in $[a, b]$ tale che sia convessa (concava) in questo intervallo, allora vale che $$ f\\left( \\sum_{i} \\lambda_{i} x_{i} \\right) \\leq \\sum_{i}\\lambda_{i}f(x_{i}) $$ Con $\\sum_{i}\\lambda_{i} = 1$. Questa cosa si estende in modo molto semplice a variabili aleatorie e $E$ quando al posto di $\\lambda_{i}$ mettiamo una probabilit√† in un punto.\nLa dimostrazione non dovrebbe essere molto difficile. La strategia √® utilizzare l\u0026rsquo;induzione in modo abbastanza classico. Non so in che modo si estende su funzioni continue, ma quelle sono cose tecniche matematiche non interessantissime.\nLog sum inequality Siano $a_{1}, a_{2}, \\dots a_{n}$ e $b_{1}, b_{2}, \\dots, b_{n}$ numeri non negativi, allora vale che $$ \\sum_{i=1}^{n}a_{i} \\log\\left( \\frac{a_{i}}{b_{i}} \\right) \\geq \\left( \\sum_{i=1}^{n}a_{i} \\right)\\log \\frac{\\left( \\sum_{i=1}^{n} a_{i} \\right)}{\\sum_{i=1}^{n}b_{i}} $$ Con uguaglianza se vale che $\\forall i, \\frac{a_{i}}{b_{i}}= const$\nKrafts Inequality https://en.wikipedia.org/wiki/Kraft%E2%80%93McMillan_inequality Questo teorema interessa cose dei codewords, perch√© ci interessano dei set di prefixfree che sono molto pi√π gestibili probabilmente dal punto di vista dell\u0026rsquo;interpretazione. La cosa interessante √®:\nSiano $l_{1}, l_{2}, l_{3}, \\dots, l_{n}$ lunghezze di code-words all\u0026rsquo;interno del nostro alfabeto, allora vale che esistono dei code-words (stringhe binarie) che hanno quelle lunghezze se e solo se viene soddisfatta la propriet√† $$ \\sum_{x} 2^{-l(x)} \\leq 1 $$ Il motivo √® abbastanza semplice, questo si spiega in modo grafico in maniera praticamente immediata quando facciamo il disegno. Si pu√≤ vedere dall\u0026rsquo;albero binario corrispondente di un insieme di set binari con prefissi che se un parente √® scelto (colorato nel disegno), allora nessun discendente pu√≤ essere scelto perch√© altrimenti avresti un prefisso. Inoltre se colori quelli sopra, significa che al massimo se sommi tutti quei valori otterrai 1 sse hai utilizzato tutti i rami a tua disposizione (meaning, che non puoi scegliere altri code-work, altrimenti perdi la prefix property). Source coding theorem for symbol codes Chiamata anche come la relazione con Kolmogorov. 1.11.3 di (Li \u0026amp; Vit√°nyi 2019), allora se prendiamo un set di code-words con $L$ il minimo prefix code che possiamo mai avere Ossia $L = \\sum_{x} P(x)l(x)$, con $l$ scelto il minimo possibile. Allora vale che $$ H(P) \\leq L \\leq H(P) + 1 $$ Ossia la lunghezza migliore possibile √® boundata da valori di entropia. Che √® una cosa abbastanza forte perch√© relaziona come deve essere fatto il code-words, con la complessit√† dell\u0026rsquo;informazione che vogliamo andare a utilizzare. La dimostrazione non la facciamo qui, ma √® fattibile con le tue conoscenze credo, ti serve la Gibbs inequality qui sotto per una freccia\nDimostrazione Prendiamo $q_{i} = 2^{-l_{i}}$, allora abbiamo $l_{i} = \\log\\left( \\frac{1}{q_{i}} \\right)$ vale $$ L = \\sum_{x} p(x) l(x) = \\sum_{x} \\left( p(x) \\log\\left( \\frac{1}{q(x)} \\right) \\right) \\geq \\sum_{x}p(x) \\log\\left( \\frac{1}{p(x)} \\right) =H(x) $$ Dove abbiamo usato anche l\u0026rsquo;ineguaglianza di Gibbs #Gibbs Inequality e il fatto che vale #Krafts Inequality.\nProvando a dimostrare l\u0026rsquo;altro bound, supponiamo che $$ l_{i} = \\lceil -\\log_{2}(p_{i}) \\rceil $$ Si pu√≤ dimostrare che questo √® un prefix code, perch√© soddisfa Kraft. Allora si pu√≤ notare come $$ L = \\sum_{x} p(x) l(x) = \\sum_{x} p(x) \\lceil -\\log_{2}(p_{x}) \\rceil \\leq \\sum_{x}p(x) \\left( \\log_{2}\\left( \\frac{1}{p(x)}\\right) +1 \\right) = H(x) + 1 $$ Una nota interessante √® questo teorema ci permette di definire un concetto di efficienza di rappresentazione. Tutto quanto dato da KL divergence √® una specie di inefficienza.\nInfatti possiamo scrivere $$ L = H(x) + D_{KL}(P \\mid \\mid Q) $$ Con $Q$ la probabilit√† associata alle singole codewords, assumendo che siano uniformi e simili per dire.\nGibbs Inequality Afferma che l\u0026rsquo;entropia √® minore rispetto alla cross-entropy di qualunque cosa, ossia $$ \\sum_{x} P(x) \\log\\left( \\frac{1}{P(x)} \\right) \\leq \\sum_{x} P(x) \\log\\left( \\frac{1}{Q(x)} \\right) $$ Qualunque sia l\u0026rsquo;altra distribuzione. Si pu√≤ dimostrare in modo abbastanza diretto utilizzando il fatto che la Kullback Leibler divergence, presentato in Neural Networks, √® sempre positiva o uguale a 0. Infatti la parte di sopra si pu√≤ riscrivere come\n$$ -\\sum_{x} P(x) \\log\\left( \\frac{P(x)}{Q(x)} \\right) = D_{KL}(P \\mid \\mid Q) $$ References [1] Shannon ‚ÄúA Mathematical Theory of Communication‚Äù The Bell System Technical Journal Vol. 27, pp. 379\u0026ndash;423, 623\u0026ndash;656 1948\n[2] Li \u0026amp; Vit√°nyi ‚ÄúAn Introduction to Kolmogorov Complexity and Its Applications‚Äù Springer International Publishing 2019\n[3] Cover \u0026amp; Thomas ‚ÄúElements of Information Theory‚Äù John Wiley \u0026amp; Sons 2012\n","permalink":"https://flecart.github.io/notes/entropy/","summary":"Entropy Questo √® stato creato da 1948 Shannon in (Shannon 1948). Questa nozione √® basata sulla nozione di probabilit√†, perch√© le cose rare sono pi√π informative rispetto a qualcosa che accade spesso. This is dependent on the notion of the Shannon information content defined as $$ h(x = a_{i}) = \\log_{2}\\frac{1}{P(x = a_{i})} $$ We will see that the entropy is a weighted average of the information, so the expected information content in a distribution.","title":"Entropy"},{"content":"Logica del primo ordine Questa √® la logica pi√π utilizzata dai matematici\nLimitatezza della logica proposizionale La logica proposizionale classica non √® in grado di ragionare sull\u0026rsquo;infinito Fino ad ora abbiamo utilizzato una metalogica per giustificare il per ogni e l\u0026rsquo;esiste nelle dimostrazioni fin\u0026rsquo;ora.\nDobbiamo quindi dare una definizione pi√π formale dei quantificatori.\nObiettivo della logica del primo ordine Si pu√≤ quindi identificare come l\u0026rsquo;obiettivo della logica di primo ordine l\u0026rsquo;introduzione dei quantificatori dell\u0026rsquo;universale e dell\u0026rsquo;esiste\n## Sintassi In questa sintassi stiamo dividendo in Termini e proposizioni (le proposizioni che si possono trovare nella logica proposizionale classica).\nDefiniamo i termini o vocabolario ossia gli elementi del discorso come $$ t::= x \\mid c \\mid f^{n}(t_{1}, \\dots, t_{n}) $$ Def: Vocabolario Ossia, simboli di relazione n-arie (ossia con $n$ argomenti) $p, q$ etc\u0026hellip; e simboli di funzione $f, g, h$ anche questi n-arie etc\u0026hellip; ricorda la differenza fra funzione e relazione fatta in Relazioni fra insiemi\nDef: Termine Lo facciamo in modo induttivo.\nUna variabile qualunque √® un termine Poi caso induttivo: se $t_{1}, \\dots, t_{n}$ sono termini, lo √® anche $f^{n}(t_{1}, \\dots, t_{n})$ NOTA: qui non facciamo uso di relazioni per definire i termini\nDef: Formula o proposizione Anche qua definiamo per induzione:\n$P(t_{1}, \\dots, t_{n})$ √® un predicato $n-ario$ ed √® una formula. (un predicato √® una funzione che mappa in 0, 1) Se $\\varphi, \\phi$ sono formule, lo sono anche tutte le banali cose logiche, quindi $\\varphi \\land \\phi, \\varphi \\lor \\phi, \\varphi \\to \\delta, \\forall x.\\varphi, \\exists x. \\varphi$ NOTA: si chiama Prenex normal form quando tutti i quantificatori sono all\u0026rsquo;inizio dell\u0026rsquo;espressione.\nFully quantified: aka sentence quando non ci sono variabili libere. Def: Teoria √à un insieme di formule come definito di sopra, basate su un certo vocabolario fissato. √à interessante la roba di (Choi 2022) che dice che non √® possibile usare la logica per problemi real world.\nRiassunto sintassi: Come si pu√≤ osservare nella sintassi di logica del primo ordine estende la logica proposizionale classica perch√© per P 0 ho le singole proposizioni\nQuindi si divide in un dominio di discorso, ossia l\u0026rsquo;insieme dei termini possibili come costanti e leformule o proposizioni che possiedono un valore di verit√†.\nPerch√© primo ordine Si chiama logica di primo ordine perch√© non si possono utilizzare le funzioni sulle variabili nel dominio di discorso.\nQuesta √® l\u0026rsquo;ultima logica in cui vale ancora la completezza, e la correttezza, nelle logiche superiori non sar√† pi√π possibile catturare tramite un concetto sintattico il valore semantico.\nQuesta √® la logica di primo ordine che basta ai matematici per fare tutto (questo perch√© le funzioni dei matematici in realt√† sono degli insiemi, non qualcosa che calcola).\nPossibili denotazioni Oggetti ignoti nel dominio Oggetti fissati Connotazioni di denotazioni oggetti Connotazioni di denotazioni di valori di verit√† Semantica Questa parte √® approfondita dopo con mondo ed interpretazione\nBinder I binder sono un concetto fondamentale nell\u0026rsquo;informatica (soprattutto a chi andr√† a fare i compilatori). Quindi stiamo astraendo un livello di semantica! Connettivi ancora pi√π astratti.\nI binder legano una variabile e uno scope (Cattura una variabile (o serie di varaibile) in uno scope che viene valutato pi√π e pi√π volte).\nFormula matematica (uno scope nel senso di derivata, integrale sommatoria e simili) I Simboli logici per ogni esiste. Vado a valutare una unica formula all\u0026rsquo;interno di uno scope (e continuo ripetutamente a sostituire e calcolare su tanti valori, e restituisco il risultato sintetizzato).\nShadowing Nei binder non si pu√≤ accedere alle variabili esterne se hanno lo stesso nome, si dice shadowing (quello interno nasconde l\u0026rsquo;esterno, quindi fa ombra, nasconde).\nUn esempio √® ridichiarare un parametro formale in una funzione.\nDiagrammi di legame Sono molto utili per capire le variabili del binder e lo scope di queste variabili\nCose da fare:\nLegare variabile a ogni binder e lo scope Esistono le variabili che non vengono mai legate, si dicono variabili libere queste (come libreria o variabili globali), queste si indicano con una freccia all\u0026rsquo;infinito con il nome Variabili libere Queste variabili non sono modificabili (come provare a cambiare il nome di una funzione di libreria esterna).\nDefinizione per induzione strutturale\nalfa-convertibilit√† Si chiama alfa perch√© una branca dell\u0026rsquo;informatica che studiava i lambda, cuore del linguaggio di programmazione funzionale. (io lo chiamo anche sostituzione idiota, ma attento che in linguaggi normali c\u0026rsquo;√® il fenomeno dell\u0026rsquo;opacit√† che non ci permette di farlo!)\nSi dice che una serie di formule sono alfa-convertibili se il diagramma di legame creato dalle formule √® uguale ‚Üí relazione di equivalenza\nEssendo una relazione di equivalenza possiamo lavorare su una classe di equivalenza, quindi sarebbe bene ragionare al livello di insieme quoziente delle formule.\nEsempi\nNell\u0026rsquo;esempio in giallo, la Z fa shadowing, ha cambiato una variabile che in primo momento apparteneva a uno scope esterno.\nSostituzione in logica primo ordine Praticamente questa nozione ci dice che una funzione ha lo stesso output anche se quello che ci va dentro √® una variabile con un nome diverso. Questa nozione ha una certa similitudine con la funzione di sostituzione, in quanto entrambi parlano di invarianza sulla sostituzione di variabili.\nLa differenza principale √® che questa parla di binder mentre quella di prima parla di stesso valore di verit√† di una proposizione.\nPossiamo allora definire una funzione di sostituzione anche per la logica del primo ordine che faccia attenzione anche ai diagrammi di flusso e i binder\nSostituzione\nMondo o interpretazione Non √® pi√π sufficiente avere un mondo indicato solamente come una v, ma √® necessaria una coppia ordinata: (A, l) dove A √® l\u0026rsquo;insieme non vuoto di denotazioni, mentre l √® simile alla vecchia funzione semantica v, per√≤ associa degli elementi in A altri elementi in A, non dice niente sulle connotazioni.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Logica del Primo ordine/Untitled 9.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Logica del Primo ordine/Untitled 9\u0026quot;\u0026gt; Def: Modello Questo √® anche chiamato mondo in questo caso.\nUn simbolo non ha significato finch√© non ne diamo uno, questo √® la parte della semantica, che vuole cercare di dare senso al mondo. Uno stesso simbolo pu√≤ avere diverse interpretazioni (diversa semantica) in modelli diversi\nDato un vocabolario $(f_{1}, \\dots, f_{j}, p_{1},\\dots, p_{i})$ un modello √®\nUn insieme $U$ Le funzioni $f_{1}^{U},\\dots, f_{j}^{U}$ e similmente definite $p$ tali per cui se $f_{1}$ ha ariet√† n, allora $f_{1}^{U} : U^{n} \\to U$, ossia √® una relazione n-aria. Per $p_{1}$ si ha che $p_{1}^{U} \\subseteq U^{n}$. Def: Interpretazione Con un insieme $V$ possiamo definire interpretazione una funzione $I: V \\to U$ con $U$ l\u0026rsquo;insieme del modello definito #Def Modello. Solitamente questo √® definito in modo induttivo.\nNozione semantica di per ogni ed esiste Esempi di formalizzazione sintattica errata\nPer esempio: elefante √® una connotazione, mentre la denotazione √® quell\u0026rsquo;animale in carne ed ossa, non posso manipolare delle denotazioni in questo caso, quindi non avrebbe senso utilizzarlo.\nNel secondo caso sto testando molte pi√π cose (connotazioni sono molti di pi√π rispetto alle denotazioni in quanto esistono i sinonimi)\nL\u0026rsquo;idea principale √® tenersi una lista (una mappa) che associ nomi (connettivi) e denotazioni del mondo, questa √® l\u0026rsquo;ambiente indicata con la lettere csi.\nSemantica della logica primo ordine La funzione di interpretazione va per ricorsione strutturale in tutte le sotto-formule, per cui basta definirlo nell\u0026rsquo;insieme dei termini e la ho per tutto il modello.\nRicorsione strutturale Conseguenza logica in Primo ordine Dobbiamo prendere in questo caso considerazione della definizione pi√π complessa del mondo (ricordarsi che nelle logiche di ordine superiore √® proprio questa ulteriore complessit√† che non permette di avere una completezza).\nQuindi dobbiamo tenere conto del significato di (A, l), $\\xi$.\nDef: Verit√† Possiamo definire che una proposizione √® vera se: $$ U, I \\models P(t_{1}, \\dots, t_{n}) \\text{ se } \\langle I(t_{1}), \\dots, I(t_{n}) \\rangle \\in P_{I}^{U} $$ ossia se il termine usando tutta l\u0026rsquo;interpretazione presente √® dentro il nostro modello. √à un modo leggermente differente per sopra Si pu√≤ continuare a definirlo per tutti i quantificatori: $$ U, I \\models \\varphi \\land \\phi \\text{ se } U, I \\models \\varphi \\land U, I \\models \\phi $$ $$ U, I \\models \\varphi \\lor \\phi \\text{ se } U, I \\models \\varphi \\lor U, I \\models \\phi $$ $$ U, I \\models \\neg \\varphi \\text{ se } U, I \\not \\models \\varphi $$ $$ U, I \\models \\exists x. \\varphi \\text{ se esiste } \\alpha \\in U \\mid U, I\\left[ x \\to \\alpha \\right] \\models \\varphi $$ $$ U, I \\models \\forall x. \\varphi \\text{ se per ogni } \\alpha \\in U \\mid U, I\\left[ x \\to \\alpha \\right] \\models \\varphi $$ NOTA: se andiamo a considerare una formula chiusa, ci basta il modello, perch√© l\u0026rsquo;interpretazione √® utile quando andiamo a trattare formule libere.\nPropriet√† esiste e per ogni Queste propriet√† espandono la lista CAIDANA delle propriet√† presenti in Connettivi Logici, correttezza, variabili.\nCompletezza debole \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Logica del Primo ordine/Untitled 13.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Logica del Primo ordine/Untitled 13\u0026quot;\u0026gt; Commutativit√† e non chiaramente se Sono gli stessi x e y in due per ogni es $\\forall A, \\forall B$ questo √® uguale a dire $\\forall B, \\forall A$, stessa cosa per l\u0026rsquo;esiste.\nMa il senso della frase cambia nel caso in cui abbia un per ogni e in seguito un esiste.\nSemidistributivit√† In certi casi (non per tutti) posso spostare (addirittura eliminare!) i quantificatori\n### De morgan Equivalenze notevoli Deduzione naturale In questa sezione di appunto andiamo ad indagare le regole della deduzione naturale per la logica di primo ordine, per questo motivo linko la deduzione naturale in ambito proposizionale Deduzione naturale\nVogliamo utilizzare delle cosa uguali a meno di alfa conversione.\nIntroduzione Per ogni Forma generale\nAttento che Y non deve affatto appartenere alle variabili libere delle foglie!\nQuesto mi dice che devo utilizzare solamente solamente una variabile che non √® stata gi√† presa (quindi libera, data dall\u0026rsquo;esterno)\nSuggerimento: per non sbagliare mai ti basterebbe prendere una variabile mai presa prima.\n/to\nCorrettezza ed invertibilit√† intuizionista\nCorrettezza classica\nIo sintatticamente ci metto y e il mondo mi risponde xi y. Ora l\u0026rsquo;ambiente xi mi dice che x vale xi di y e quindi √® la stessa. Ma lo devo dimostrare per induzione strutturale.\nInvertibilit√† classica\nEliminazione per ogni Forma generale\nDovrei passare per la formula pi√π complessa a volte! A volte √® pi√π semplice dimostrare il generale che il particolare perch√© possiedo induzione strutturale e simili.\nCorrettezza intuizionista e classica\nAnche da questo possiamo sapere che non possiamo andare a cercare tutte le variabili, sono infiniti! L\u0026rsquo;algoritmo non concluderebbe mai.\nIntroduzione Esiste Questa dimostrazione √® praticamente uguale all\u0026rsquo;eliminazione del per ogni, mentre l\u0026rsquo;eliminazione √® simile all\u0026rsquo;introduzione\nForma generale\nEliminazione dell\u0026rsquo;esiste In questa forma io non ho nessuna informazione sulla x, non posso prendere una x che √® gi√† stata utilizzata nella conclusione C oppure nelle foglie.\nDeve essere una variabile libera!, non deve avere nessuna altra ipotesi presa da altro.\nForma generale\nCompletezza ed incompletezza di Godel Angelo was here 18/10/22, and 20/03/24 too! Primo teorema \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Logica del Primo ordine/Untitled 28.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Logica del Primo ordine/Untitled 28\u0026quot;\u0026gt; Gamma voglio identificare un singolo mondo.\nSe contiene l\u0026rsquo;aritmetica ho i numeri la somma i prodotti e simili. Se gamma √® consistente (quindi interessante, senn√≤ tutto e dimostrabile, √® anche un modo per dire che non ho pi√π mondi). Allora non posso filtrare in maniera da tenerne solamente uno. il gamma deve tenere anche dei mondi in pi√π. Quindi quando gamma parla di artimetica non si pu√≤ filtrare fino a un singolo mondo. Quindi qualunque aritmetica prendo, non posso mai filtrare fino a singolo mondo! √® una incompletezza di Gamma, ma non √® una incompletezza delle regole!\nAbbozzo\n√à una delle prime assolute codifiche!\nbigezione fra formule ed alberi, e la sintassi dimostrazione e poi utilizza il paradosso del mentitore (io mento) crea un numero che dice che non √® dimostrabile, quindi fonde livello e metalivello per cui non pu√≤ n√© essere dimostrabile n√© essere indimostrabile (altrimenti sarebbe inconsistente). Entrambe sono false\nIo sono dimostrabile se e solo se io non sono dimostrabile, quindi entrambe devono essere false.\nUno dei teoremi pi√π storpiati dai divulgatori scientifici. Ma allo stesso tempo √® uno dei teoremi pi√π profondi della logica.\nSe abbiamo abbastanza ipotesi da poter identificare solamente un singolo mondo, allora vale il concetto di terzo escluso, quindi o vale F conseguenza logica del mondo oppure not F √® conseguenza logica\n(nel caso contrario posso avere sia non G sia G non sono conseguenze logiche di pi√π mondi).\nGodel trova la P, per√≤ quel singolo P √® ben conosciuto, non √® molto interessante.\nQuesto √® stato introdotto per la prima volta in Incompletezza nella logica del primo ordine. √à importante qui conoscere sia la\nSintassi della logica del primo ordine. Semantica della logica del primo ordine. Panoramica della dimostrazione Supponiamo di avere una logica del primo ordine ben definita sintatticamente. Consideriamo l\u0026rsquo;insieme $\\mathbb{N}, +, \\times$ Definiamo la prima teoria dell\u0026rsquo;altro di $(\\mathbb{N}, + , \\times)$ in questo modo $Th(\\mathbb{N}, +, \\times) = \\left\\{ \\varphi \\mid \\varphi \\text{ √® una formula vera della logica del primo ordine su } (\\mathbb{N}, +, \\times) \\right\\}$ Il nostro obiettivo √® dimostrare che $ETH$ √® riducibile tramite mappatura a questo insieme. Vedere Halting Theorem and Reducibility].\nCuriosit√†: La teoria $Th(\\mathbb{N}, +)$ √® decidibile, ma √® meno espressiva rispetto all\u0026rsquo;altra teoria aritmetica. Questo √® chiamato aritmetica di Presburger. E per l\u0026rsquo;analisi aritmetica √® piuttosto importante dal punto di vista computazionale.\nDimostrazione dell\u0026rsquo;Incompletezza Dato un vocabolario arbitrario e una teoria su quel vocabolario, l\u0026rsquo;insieme $\\left\\{ \\varphi \\mid \\varphi \\in T \\text{ ed √® valido} \\right\\}$ non √® un insieme decidibile. Questo approccio √® pi√π computazionale.\nSupponiamo di avere una macchina di Turing che decide sopra, vogliamo ridurre il linguaggio $ETH$ su questo. Questo si pu√≤ fare tramite turing riducibilit√†.\nCodifica della Macchina di Turing Vedere La macchina di Turing per definizione di TM. Andremo a codificare il comportamento di una macchina di Turing utilizzando la logica di primo ordine. E poi dato che questa codifica √® possibile si pu√≤ dire che non √® decidibile quel problema. Il processo che usiamo √® chiamato g√∂delizzazione perch√© andiamo ad utilizzare codifiche per risolvere questo problema.\nConsideriamo questo vocabolario:\nSimboli di funzione sono $O^{0}, S^{1}, P^{1}$ che sono il 0, il successore e il precedessore. Simboli di relazione $head(n,m)$ se al passo $n$ √® sulla cella $m$ $state(n, m)$ se al passo $n$ √® sullo stato $q_{m}$ $cell_{i}(n, m)$ se al passo $n$ la cella $i$ contiene $m$ Poi diamo gli assiomi di peano al nostro sistema logico, poi codifichiamo con le relazioni questa affermazione: \u0026ldquo;Al passo $0$ la cella √® $1$ , lo stato √® $q_{0}$ e tutte le celle sono vuote.\u0026rdquo; abbiamo che $$ state(0, 0) \\land head(0, 1) \\land \\forall y(\\neg head(0, 0) \\land \\neg head(0, S(S(y)))) $$ Qui vediamo come la logica √® molto molto verbosa, sostanzialmente inutile per applicazioni molto pi√π pratiche.\nPoi possiamo codificare la caratteristica della macchina di Turing principale ossia che \u0026ldquo;Ad ogni passo la macchina √® solo in uno stato, testina su una unica cella, che contiene al pi√π un simbolo\u0026rdquo; Molto molto verboso scriverlo in modo logico anche questo. Poi possiamo andare a definire anche le regole di transizione e la regola dello stato finale, una volta fatto questo abbiamo codificato interamente una TM con le formule di Turing. Riconoscibilit√† di un sistema deduttivo Vedi Deduzione naturale#Il sistema deduttivo, dato questo sistema deduttivo, vogliamo che\n√à corretta, ossia $P \\vdash \\varphi \\implies \\varphi \\text{ √® corretta}$ sound, se lo dimostro allora √® vero. L\u0026rsquo;insieme $\\left\\{ \\langle \\varphi, \\pi \\rangle \\mid \\pi \\text{ √® una dimostrazione di } \\varphi \\right\\}$ √® un insieme decidibile Possiamo subito dire che l\u0026rsquo;insieme $$ \\left\\{ \\varphi \\mid \\varphi \\in T \\land P \\vdash \\varphi \\right\\} $$ √à riconoscibile, data una teoria $T$ e un sistema deduttivo come sopra. Basta usare la schematizzazione di sopra, ed enumerare tutte le dimostrazioni per vedere se risolve questo. Potrebbe non finire, ma se √® valido mi fermo!\nIndecibilit√† di un sistema aritmetico Usando la costruzione di sopra possiamo vedere che chiaramente abbiamo fatto la riduzione $ETH \\leq Th(\\mathbb{N}, +, \\times)$ quindi non √® decidibile. Ossia non esiste un metodo algoritmico (sistema deduttivo) che ci dice se una data formula √® nel sistema. La codifica √® pi√π complicata, per√≤ √® possibile.\nProposizioni indimostrabili Questo √® il secondo teorema di G√∂del, che ci dice che esistono formule che in nessun sistema deduttivo sono dimostrabili.\nOssia: $\\exists \\varphi \\in Th(\\mathbb{N}, +, \\times) \\mid \\forall P \\not\\vdash \\varphi$ Esiste una formula nella teoria dei numeri naturali tale per cui non esiste nessun sistema deduttivo che lo dimostri.\nSupponiamo per assurdo che tale proposizione esiste, allora abbiamo un sistema deduttivo che lo prova. Ma vogliamo dire che se vale questa propriet√† $Th(\\mathbb{N}, + , \\times)$ √® decidibile, contraddicendo #Indecibilit√† di un sistema aritmetico.\nL\u0026rsquo;algoritmo per deciderlo √® abbastanza semplice:\nUso una TM non deterministica che ci permette di verificare in parallelo se $P \\vdash \\varphi$ oppure se $P \\vdash \\neg \\varphi$, per ipotesi sappiamo che esiste una prova per $\\varphi$ o $\\neg\\varphi$. Tanto so che $P$ esiste per ipotesi. A seconda se sia vera $\\varphi$ o $\\neg\\varphi$ possiamo rispondere s√¨ o no, e quindi decidere il termine. Fine. Secondo teorema di incompletezza Questo ha un apporto molto maggiore, molto importante, la base dell\u0026rsquo;informatica.\nEnunciato\nNon riesco mai a concludere la consitenza della logica, dovrei rimettermi al metalivello continuamente, senza finire mai.\nNon possiamo mai essere sicuri della consistenza di una teoria, e alla fin fine la logica, la matematica si pu√≤ paragonare alla religione da questo punto di vista. Noi non siamo sicuri che sia vero. Serve l\u0026rsquo;atto di fede. a di una teoria**, e alla fin fine la logica, la matematica si pu√≤ paragonare alla religione da questo punto di vista. Noi non siamo sicuri che sia vero. Serve l\u0026rsquo;atto di fede.\nRegistro Ripassi Data Descrizione 20/08/2024 Con boost Alessandro Panconesi, ripassato un po' Vecchi dubbi Definizione per induzione strutturale delle variaibli libere Cosa sono le due funzioni n-arie definite nella sintassi? Riguardare registrazione 09/12 (10 minuti iniziali in cui riassume tutta la logica del primo ordine) i nomi tecnici per dire termini e proposizioni Ancora da definire Le propriet√† delle equivalenze logiche notevoli Quali sono le equivalenze notevoli del per ogni e dell\u0026rsquo;esiste? Rivedere sostituzione in logica di primo ordine Registrazione 16/12 per prove di sostituzione o dim con primo ordine. Ripasso Prox: 4 Ripasso: December 14, 2021 Ultima modifica: October 18, 2022 6:01 PM Primo Abbozzo: December 1, 2021 9:56 AM Stato: üåïüåïüåïüåïüåó Studi Personali: No\nReferences [1] Choi ‚ÄúThe Curious Case of Commonsense Intelligence‚Äù Daedalus Vol. 151(2), pp. 139\u0026ndash;155 2022\n","permalink":"https://flecart.github.io/notes/logica-del-primo-ordine/","summary":"Logica del primo ordine Questa √® la logica pi√π utilizzata dai matematici\nLimitatezza della logica proposizionale La logica proposizionale classica non √® in grado di ragionare sull\u0026rsquo;infinito Fino ad ora abbiamo utilizzato una metalogica per giustificare il per ogni e l\u0026rsquo;esiste nelle dimostrazioni fin\u0026rsquo;ora.\nDobbiamo quindi dare una definizione pi√π formale dei quantificatori.\nObiettivo della logica del primo ordine Si pu√≤ quindi identificare come l\u0026rsquo;obiettivo della logica di primo ordine l\u0026rsquo;introduzione dei quantificatori dell\u0026rsquo;universale e dell\u0026rsquo;esiste","title":"Logica del Primo ordine"},{"content":"LR(k) Grammatiche LR(k) üü© Anche in questo caso proviamo a generalizzare il concetto dei pirmi k caratteri, in modo da generalizzare in qualche senso il concetto di LR(k), quindi andiamo a modificare la closure considerando ora first k\nPer ricordarti come si calcolava first k, andare a guardare Top-down Parser\nil problema che poi diventa pratico riguardo questo √® l\u0026rsquo;impossibilit√† di gestire stringhe lunghezza k che sono una assurdit√† (esponenziale per la lunghezza)\nGrammatiche SLR(k) üü© Uguale a SLR(k), ma possiamo andare a fare il reduce solamente quando il nostro terminale di interesse appartiene al follow k!\nGrammatiche LALR(k)üü®+ Questo √® esattamente identico a LALR, si va a considerare il concetto di nucleo, e questo concetto di nucleo √® uguale al precedente speigato in Bottom-up Parser -LR(1)\nClassificazione dei linguaggi Gerarchia generale üü® Da qui si pu√≤ creare una semplicissima gerarchia dei parser, che si possono riassumere in\n$$ \\forall k, SLR(k) \\subset LALR(k) \\subset LR(k) $$ E oltre questo inclusioni per ogni k, rispetto al k minore e la non inclusione. Questo riassume il tutto. Con qualche intersezione con LL k\nNote sulla classificazione (!!) üü® √à molto pi√π facile classificare un linguaggio invece che grammatica potrei avere delle grammatiche che non siano LL(k), mentre il linguaggio che genera lo √®\nEsiste grammatica non ambigua non deterministica!\nQuesto √® il punto motivatore per cui andiamo a concentrarci sui linguaggi invece che sulle grammatiche, ci possono essere delle miriadi di grammatiche per uno stesso linguaggio e il fatto che possano anche non essere deterministiche non ci aiuta molto in questa analisi:\n$$ S \\to aSa | bSb|\\varepsilon $$ Si pu√≤ vedere subito il conflitto shift reduce al primo passo, persino con un parser LR(1).\nTeoremi sulla classificazione dei linguaggi\nImportante l\u0026rsquo;equivalenza del fatto che $LL(k) \\equiv SLR(1)$, qualunque sia k! posso andare a costruire una grammatica equivalente che sia in grado di fare ci√≤. (credo valga anche LR(k) = SLR(1), dato che √® un sse per entrambi riguardo linguaggi liberi deterministici).\nUna altra nota interessante √® che tutte le gramamtiche che sono SLR(1) oppure LR(k) allora sono non-ambigue e deterministiche. la cosa importante di queste proposizione √® che ambiguit√† ‚Üí impossibile LR o LL!\nGli SLR(1) ci piacciono in modo particolare üôÇ, hanno una grandissima capacit√† espressiva ma √® probabile che la grammatica che √® riconosciuta da questo sia estremamente complessa e difficile da modellizzare diciamo, per questo motivo conviene utilizzare grammatiche LR k con k alto, se mi crea un parser pi√π carino.\nPropriet√† di (non) chiusura (3)üü©- Le osservazioni di maggior rilievo riguardo questo sono\nUnione di linguaggi LL 1 pu√≤ non essere LL 1 Union edi linguaggi LR 0 pu√≤ non essere LR 0 Concatenazione di LL 1 pu√≤ non essere LL 1 Quindi un sacco di nozioni negative!\nYACC In modo simile a quanto presentato per Lex in Lex/Flex e Yacc. Yacc √® l\u0026rsquo;equivalente utilizzato per i Parser.\nCollaborazione con LEX Solitamente YACC non √® impiegato da solo, ma in stretta collaborazione col LEX.\nInfatti esistono delle funzioni yylex() e la variabile yylval che sono spesso utilizzate per gestire il tempo di lettura diciamo.\nyylex - chiedi il prossimo token yylval - puntatore nella tabella dei simboli dell‚Äôultimo lessema.\nDescrizione input e output üü® Prende un programma in questo linguaggio yacc, in cui √® presente la descrizione della grammatica libera che si vuole andare a riconoscere, e d√† in output un programma che sia in grado di riconoscere quella grammatica\nQuesto programma pu√≤ essere compilato, e poi sar√† in grado di ricevere in input alcuni token e crearci un albero di derivazione.\n(ma alla fine dipende l‚Äôuso che vogliamo andare a farci:\nSe vogliamo creare un interprete, possiamo dare la valutazione dell‚Äôalbero Se vogliamo andare a creare un compilatore potrebbe essere codice intermedio oppure l‚Äôalbero di derivazione. (questa roba √® descritta in azione semantica del matching.) In realt√†\nCome abbiamo detto nel documento precedente, yacc lavora in strettissimo contatto con il lexer, al quale chiede di volta in volta altri token ogni volta in cui ne ha bisogno, quindi chiede sul momento!\nCondivisione di variabili!\nStruttura di un file Yacc (4) https://www.ibm.com/docs/en/aix/7.1?topic=information-example-program-lex-yacc-programs\nPrologo (defines) Definizioni (token o operatori) Regole con azioni semantiche Funzioni ausiliarie (utilizzate in azioni semantiche spesso). Esempio di un file YACC Sintassi regole e funzioni ausiliarie Le regole sono proprio nella forma\nnonterm: corpo1 ‚Üí azione semantica\ncorpo2 ‚Üí azion sem 2‚Ä¶ etc‚Ä¶ molto simile a quanto faceva lex.\nRiguardo alle funzioni ausiliarie di solito √® compilato insieme a lex, e linkati assieme, altrimenti se non c‚Äô√® viene generato in automatico un yylex().\nAzione semantica √à la parte di codice eseguito una volta che si √® trovato un altro pezzo dell‚Äôalbero (ricorda che vanno in contemmporanea).\nQuesto potrebbe dare un valore semantico diverso a seconda del metodo che stiamo andando ad utilizzare diciamo.\nAlbero sintattico Valutazione Codice intermedio. Default risoluzione conflitti Slide Come prima regola per la risoluzione dei conflitti si considera l‚Äôassociativit√† degli operatori, poi l‚Äôordine di dichiarazione (precedenza) se non sbaglio l‚Äôoperatore dichiarato pi√π tardi ha la precedenza su quelli dichiarati prima.\nSe ci sono ancora delle ambiguit√† dopo queste dichiarazioni allora si va alla risoluzione di default.\nSe ci sono alcune forme di conflitti shift/reduce o reduce/reduce vengono risolti in questo modo:\nShift-reduce viene sempre risolto in favore alla shift\nReduce reduce viene risolto col reduce listato prima (quindi una forma di precedenza).\n","permalink":"https://flecart.github.io/notes/lrk-e-yacc/","summary":"LR(k) Grammatiche LR(k) üü© Anche in questo caso proviamo a generalizzare il concetto dei pirmi k caratteri, in modo da generalizzare in qualche senso il concetto di LR(k), quindi andiamo a modificare la closure considerando ora first k\nPer ricordarti come si calcolava first k, andare a guardare Top-down Parser\nil problema che poi diventa pratico riguardo questo √® l\u0026rsquo;impossibilit√† di gestire stringhe lunghezza k che sono una assurdit√† (esponenziale per la lunghezza)","title":"LR(k) e YACC"},{"content":"Vogliamo cercare di restare nel nostro spazio delle soluzioni ammissibili, senza dover stare ad esplorare tutto, vogliamo andare a concentrarci su una parte specifica di essa. Vogliamo utilizzare una struttura fondamentale per i problemi di programmazione lineare, che √® quello con cui vogliamo andare a fare. Il fatto √® che spostandoci leggermente da un punto tra le soluzioni, possiamo gestire in modo molto semplice il modo con cui si sposta la retta dei valori.\nQuesto √® possiamo ridurci a considerare i vertici del poliedro che si costruisce, quindi andiamo in questa prima parte a definire alcune nozioni matematiche utili a mettere in gioco questa intuizione\nNozioni preliminari Vocabolario di base Iperpiano L\u0026rsquo;insieme delle soluzioni di equazioni in\n$$ \\left\\{ x \\in \\mathbb{R}^{n} \\mid a^{T}x = b, a \\neq 0 \\right\\} $$ E si pu√≤ dimostrare che questo √® un insieme affine, quindi √® una linea. Questi piani sono anche convessi perch√© prendiamo tutti i punti ü§†.\nSemispazio $$ \\left\\{ x \\in \\mathbb{R}^{n} \\mid a^{T}x \\geq b, a \\neq 0 \\right\\} $$ Lo spazio √® diviso fra zone in cui √® maggiore e altre in cui √® minore. Questi non sono affini ma sono solo convessi (perch√© limitati in certe zone)\nPalla euclidea $$ B(x_{c}, r) = \\left\\{ x \\mid \\lvert x - x_{c} \\rvert _{2} \\leq r \\right\\} = \\left\\{ x _{c} + ru \\mid \\lvert u \\rvert _{2} \\leq 1 \\right\\} $$ Dove $r$ √® chiamato raggio.\nEllissoide √à un insieme formato in questo modo $$ \\left\\{ x \\mid (x - x_{c})^{T} P^{-1} (x - x_{c}) \\leq 1 \\right\\} $$ Quindi √® una forma quadratica quelle saltate in algebra. Nella pratica √® una palla, un po\u0026rsquo; allungata in certe direzioni descritte da $P$, che √® una matrice simmetrica definita positiva. ossia nell\u0026rsquo;insieme $S_{++}$ Si scrive anche a volte come $$ \\left\\{ x_{c} + Au \\mid \\lvert u \\rvert _{2} \\leq 1 \\right\\} $$ Poliedro √à una intersezione di un numero finito di $m$ semispazi come definiti di sopra inoltre non vogliamo che da nessuna parte si estenda all\u0026rsquo;infinito, quindi vogliamo che valga $$ \\left\\{ x \\mid Ax \\leq b \\right\\} $$ Per qualche valore di $A$ e $b$.\nUn poliedro √® una qualunque intersezione di semispazi (anche vuota, ma non √® molto interessante un poliedro vuoto), ed √® un insieme sempre convesso perch√© l‚Äôintersezione di cose convesse √® ancora convesso.\nL‚Äôamico del poliedro che deve essere per forza finito √® il politopo. (che √® la versione non bounded, ma alcuni autori utilizzano una definizione opposta, ma comunque non √® molto importante).)\nFacce üü® Formalmente:\nPreso un poliedro, andiamo a definire una sua faccia, un insieme di punti che soddisfano queste caratteristiche:\nGiace direttamente su una o pi√π condizioni Giace dentro il poliedro (quindi ogni punto della faccia √® un punto del poliedro anche!) Che matematicamente si possono andare a caratterizzare in questo modo: sia $I$ l‚Äôinsieme degli indici delle condizioni della matrice del poliedro che andiamo a prendere, e $\\bar{I}$ il suo complementare, allora\n$$ P_I = \\{x: A_Ix=b_I \\wedge A_{\\bar{I}}x \\leq b_{\\bar{I}} \\} $$ Intuitivamente L\u0026rsquo;intuizione per questa parte √® prendere un sottoinsieme che ci piace riguardante la nostra matrice, quella cosa corrisponder√† a una faccia del nostro poliedro.\nnozioni sulla dimensione della matrice finale √® molto buona, ci pu√≤ dare un concetto di dimensione della faccia che andiamo a prendere. Per fare un esempio, se riusciamo ad avere una faccia di dimensione n, √® un singolo punto, quindi √® un vertice!\nin generale, come dicono le dispense vale la relazione sul fatto che\nE` possibile verificare che una faccia determinata da una matrice AI di rango k ha dimensione n ‚àí k o inferiore, pagina 8 dispense 3.\nSpigoli e vertici e soluzioni base üü© Una sottomatrice di dimensione n, √® un vertice!.\nUna sottomatrice di dimensione n - 1 √® uno spigolo!.\nQuesto sar√† il nostro spazio di ricerca quelli sui vertifici!\nSoluzione di base\nParlano dei vertici e lo fanno attraverso il concetto di invertibilit√†. Una soluzione di base non √® detto che faccia parte del poliedro che stiamo andando a considerare! Vogliamo andare a considerare delle basi ammissibili ossia che sono anche all\u0026rsquo;interno del poliedro (un esempio ez. √® il vertice).\nMatrice di base, ammissibilit√† o non della base.\nVincoli attivi üü®+ I vincoli attivi sono vincoli del nostro problema che vengono soddisfatte come uguaglianze. Questa √® una cosa di interesse, per ragioni che mi sono ancora oscure.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Programmazione lineare/Untitled 2.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Programmazione lineare/Untitled 2\u0026quot;\u0026gt; Di importanza per√≤ √® la notazione $$ I(x) = \\{ i | A_ix = b_i\\} $$ Questa notazione pi√π o meno ci dice quante righe della matrice sto andando poi a contare\nCose convesse Trattate un po\u0026rsquo; meglio in Analisi di Convessit√†.\nInviluppi convessi üü© Queste cose ci sono molto utili, vanno simili al concetto di Base e dimensione, cercare di riassumere un insieme di punti illimitato con alcuni punti cardine limitati. In questo caso considero l\u0026rsquo;insieme , $X = \\{x_1, ..., x_n\\}$\n$$ conv(X) = \\{ \\sum _{i = 0} \\lambda_ix_i | \\sum_{i = 0} \\lambda_i = 1 \\land \\lambda_i \\geq 0\\} $$ Questo insieme ci √® sufficiente per avere un politopo, per il caso infinito dovremmo andare sui coni.\nPer ora basta avere un intuizione per questo. Riusciamo a costruire in questo modo tutti i spigoli che uniscono i nostri punti di vertice, e partendo da questi possiamo andare a costruire l‚Äôintero politopo, ma la dimostrazione formale non la andiamo a dare.\nConi convessi See Analisi di Convessit√†#Convex Cone. Il concetto di cono convesso ci aiuta a costruire il caso infinito, considerando alcune operazioni di prolungamento e somma\n$x,y \\in C, \\lambda, \\beta \\in \\mathbb{R} \\implies \\lambda x + \\beta y \\in C$\nPossiamo provare a generalizzare questo concetto utilizzando la somma fra tutti i possibili\n$V = \\{ v_1, ... v_n\\}$\n$$ cono(V) = \\{ \\sum _{i = 1} \\lambda_i v_i | \\lambda_i \\in \\mathbb{R} ^+\\} $$ Teorema di Motzkin o di decomposizione (!) üü®+ Slide\nQuesto √® un teorema molto importante perch√© teorema caratterizzante dei poliedri!\nIntuizione\nPi√π o meno questo teorema ci dice che tutti i poliedri possono essere ridotti a un insieme di punti di partenza, che quasi vanno a formare una base (nel caso del politopo sono solamente questi punti di base, il cono che andiamo a considerare √® vuoto!) e poi poter estenderli in una direzione utilizzando il cono!\nDifferenza dimensione motzkin e vincoli\nL‚Äôutilizzo pi√π importante di questo teorema √® che possiamo caratterizzare i poliedri in modo molto pi√π semplice, differentemente a quanto fatto con i vincoli lineari, perch√© quelli hanno un‚Äôesplosione esponenziale per quanto riguarda il numero di vertici. (nota importnate √® che i vertici non si calcolano in modo molto veloce fra i vertici e i vincoli lineari!).\nVertici ‚Üí exp\nVincoli ‚Üí lin.\nQuesta differenza di crescita non ci piace proprio! Non ci piace andare a cercare il numero di vertici se questi vertici crescono in modo esponenziale!\nTh esistenza dell‚Äôottimo finito (!!) üü®++ Given $P = \\left\\{ x \\mid Ax \\leq b \\right\\}$ and given $x_{1}, \\dots, x_{s}$, $v_{1}, \\dots, v_t \\in \\mathbb{R}^{n}$ such that $$ P = \\text{conv}\\left( \\left\\{ x_{1}, \\dots, x_{s} \\right\\} \\right) + \\text{cone}\\left( \\left\\{ v_{1}, \\dots, v_{t} \\right\\} \\right) $$ Then the problem $\\max\\left\\{ cx \\mid Ax \\leq b \\right\\}$ has an finite optimal point if and only if $cv_{j} \\leq 0$ for all $j \\in \\left\\{ 1, \\dots, t \\right\\}$. In this case $\\exists k \\in \\left\\{ 1, \\dots, s \\right\\}$ such that $x_{k}$ is the optimal solution.\nDimostrazione Questo teorema lega in modo molto forte la parte di cono convesso con la soluzione del nostro problema lineare!\nossia possiamo avere soluzione solo se il cono non si espande verso l\u0026rsquo;infinito positivo, se succede, la soluzione ottimale √® infinito, altrimenti possiamo andare a scartare il contributo negativo del cono, e tenerci solamente il contributo dato dalla inviluppo convesso.\nTeoria della dualit√† Moved to Duality Theory\n","permalink":"https://flecart.github.io/notes/programmazione-lineare/","summary":"Vogliamo cercare di restare nel nostro spazio delle soluzioni ammissibili, senza dover stare ad esplorare tutto, vogliamo andare a concentrarci su una parte specifica di essa. Vogliamo utilizzare una struttura fondamentale per i problemi di programmazione lineare, che √® quello con cui vogliamo andare a fare. Il fatto √® che spostandoci leggermente da un punto tra le soluzioni, possiamo gestire in modo molto semplice il modo con cui si sposta la retta dei valori.","title":"Programmazione lineare"},{"content":"This is the classical format that we encounter, it is the format used for relational databases introduced in databases course introduction, introduced in (Codd 1970).\nIntroduzione, i modelli di dati Lista modelli di dati (4) Nel tempo sono stati sviluppati molti modelli di dati:\nRelational Data Model: This is the most common data model and uses tables to represent data. It organizes data into rows and columns, where each row represents a record, and each column represents an attribute of that record. Relationships between data are established through keys.\nEntity-Relationship Model: This model focuses on the relationships between entities, which are objects or concepts, and how they relate to each other. It is often used in the design of databases.\nNoSQL Data Model: NoSQL databases use various data models, such as document, key-value, column-family, or graph, to store and manage data. These models offer more flexibility than the traditional relational model.\nHierarchical and Network Data Models: These older models organize data in a tree or graph structure, which was common in early database systems.\nIn questa sezione andiamo ad analizzare il primo. (anche perch√© quello storicamente pi√π rilevante, e ancora (tristemente) pi√π utilizzato).\nAltri modelli come reticolare e gerarchico erano famosi all\u0026rsquo;inizio, ma si √® scelto di andare sul modello relazionale col tempo\nVantaggi relazionale (Codd 1970) √® stato un contributo fondamentale, la separazione fra layer logico e fisico √® stato proprio necessario per fare questi modelli Rappresenta solamente ci√≤ che √® importante Semplicit√† del passaggio per valori. Il modello relazionale We can represent each row of a table as a partial function, in the domain of the headers,\nDomini e attributi Schemi e istanze di relazione e di basi di dati üü© Potremmo definire in maniera lasca, che una base di dati a modello relazione √® un insieme di relazioni, che possono avere schemi diversi. Ad alto livello possiamo dire che uno schema √® la descrizione matematica dei domini, mentre l\u0026rsquo;istanza √® una serie di dati che rispettano quello schema. In matematichese possiamo vedere in immagine:\nIntroduzione concetti fondamentali üü© In pratica abbiamo $D_{1}, \\dots D_{n}$ domini a cui spesso sono associati dei nomi, chiamati attributi che spiegano l\u0026rsquo;interpretazione di questo dominio, che vengono rappresentati come gli headers o nomi delle colonne. Un campione di questo dataset non √® altro che un cittadino nell\u0026rsquo;insieme $D_{1} \\times \\dots \\times D_{n}$, in cui non importa n√© l\u0026rsquo;ordine dei singoli elementi all\u0026rsquo;interno della tupla, ma non importa per gli elementi fra una tupla e una altra.\nNel caso in cui la posizione degli attributi non √® importante (quindi posso mischiare una colonna a una altra) si dice che il database √® non-posizionale Le due colonne scambiate non ci fanno differenza dal punto di vista logico.\nSchemi matematici o relazionali üü© In matematica la tupla ha un uso posizionale, nel senso che la posizione al suo interno √® importante, mentre noi abbiamo dati omogenei per questo motivo definiamo che le tuple sono identificate da attributi diversi fra di loro. Gli attributi sono delle funzioni che mappano a un dominio (es. stringhe, numeri o simili). $$ dom: X \\to D,,,, A \\in X $$ E si pu√≤ introdurre una notazione simile per le tuple $t$ su una certa relazione, che permette di prendere il valore di quella tupla, scegliendo una relazione specifica.\nCondizioni necessarie per relazione (3) üü© Devono esserci tutti i dati (colonne) per ogni riga.\nQuindi non vengono ammesse NaN Tutte le righe sono elementi diversi (questa non la ho capita bene, perch√© necessariamente devono essere tutti diversi?)\nLe tipologie di valori per colonna sono omogenee Domain integrity, Relational Integrity\nChiavi e vincoli Keys and superkeys üü© Superkeys Sono il subset degli attributi utili a identificare in modo univoco un sample.\nCandidate Keys Sono il subset minimo di chiavi utilizzati per identificare un record\nPrimary keys sono solo dei candidate keys identificati da un designer.\nPossiamo proprio dare una definizione formale del concetto di chiave, come l\u0026rsquo;insieme di cardinalit√† minima degli attributi superchiave.\nCosa succede invece nel momento in cui includiamo la possibilit√† che certi valori possano essere nulli nel nostro schema? Chiaramente se una chiave diventa nulla diventa impossibile identificare il valore di essa! Per questo motivo dobbiamo mettere un constraint e dire che non pu√≤ esserlo, in questo modo possiamo identificare in modo univoco ogni entry.\nForeign Key and Referential integrity (!) üü© √à un attributo del nostro schema che si riferisce a una primary key esterna. Anche chiamato referential integrity constraint.\nDefinizione:\nfra un insieme di attributi $X$ di una relazione $R_{1}$ e un‚Äôaltra relazione $R_{2}$ √® soddisfatto se i valori su $X$ di ciascuna tupla dell\u0026rsquo;istanza di $R_{1}$ compaiono come valori della chiave (primaria) dell‚Äôistanza di $R_{2}$\nSe ho una foreign key, non avrebbe senso se il valore a cui si riferisce non esistesse!\nVincoli I vincoli servono per imporre dei limiti tali per cui i dati abbiano un senso nel nostro dominio, possono essere di tipi specifici, come di tupla e in genere sono intra-relazionali, ossia non hanno bisogno di andare su altre relazioni, oppure inter-relazionali, se prendono pi√π relazioni.\nDatabase schema The schema of a relation refers to its logical design, while an instance of the relation refers to its contents at a point in time. The schema of a database and an instance of a database are similarly defined. The schema of a relation in- cludes its attributes, and optionally the types of the attributes and constraints on the relation such as primary and foreign key constraints.\nStandardization Da questa parte trattiamo meglio quando parliamo di forma Normale in seguito Abbiamo detto che il dataset relazionale ha un formato preciso #Condizioni necessarie per relazione (3) espresso in questo punto, ma ci sono alcuni formati comuni che non lo sono, andiamo a vedere come si possono riportare nel formato standard\nUnnesting Per questo riguarda questo un\nPartial information Non sarebbe sensato utilizzare elementi che siano dentro il nostro dominio della colonna per rappresentare un dato che manca. Per questo motivo si utilizza NULL che rappresenta proprio il dato mancante, e il dominio della colonna sarebbe sempre esteso con NULL (almeno ch√© esplicitamente vietato).\nTypes of Nulls (3) Unknown Inexistant Uninformative Ma nei DBMS non si fa distinzione, quindi si utilizza un unico null type. References [1] Codd ‚ÄúA Relational Model of Data for Large Shared Data Banks‚Äù Communications of the ACM Vol. 13(6), pp. 377\u0026ndash;387 1970\n","permalink":"https://flecart.github.io/notes/relazional-model/","summary":"This is the classical format that we encounter, it is the format used for relational databases introduced in databases course introduction, introduced in (Codd 1970).\nIntroduzione, i modelli di dati Lista modelli di dati (4) Nel tempo sono stati sviluppati molti modelli di dati:\nRelational Data Model: This is the most common data model and uses tables to represent data. It organizes data into rows and columns, where each row represents a record, and each column represents an attribute of that record.","title":"Relazional Model"},{"content":"Obiettivi della sicurezza (!!!) üü© Vogliamo creare delle reti che abbiamo certe garanzie di sicurezza, soprattutto:\nConfidenzialit√†, non vorremmo che il nostro messaggio sia intercettabile e leggibili da persone intermedie Integrit√†: non vogliamo che messaggi possano essere cambiati senza intervento del sender Autenticazione: vorremmo sapere con chi stiamo parlando, e vorremmo essere sicuri che non stiano mentendo sull‚Äôidentit√†. Sicurezza operativa(Availability): vorremmo essere in grado di poter continuare a fornire il servizio (quindi non sia possibile dossare, o installare malware che modifichino il comportamento del servizio). Questi sono stati trattati un po\u0026rsquo; in Theoretical Notions of Security.\nQuesti principi possono essere messe in pratica con specifiche politiche nella fase di invio dei messaggi, implementate nei vari livelli o firewall per poter identificare tentativi di intrusione.\nCome vengono raggiunti questi obiettivi\nVedremo in seguito che il primo obiettivo viene raggiunto senza molti problemi utilizzando la crittografia, mentre le altre due con le funzioni di hashing. Il quarto con la creazione di protocolli solidi.\nUn principio di sicurezza üü© La sicurezza del messaggio non dovrebbe essere basato sull\u0026rsquo;algoritmo utilizzato per codificare, ma solamente sull\u0026rsquo;utilizzo della chiave.\nIl primo √® molto facile da recuperare, o farci reverse engineering, ne abbiamo parlato qui in breve Classical Cyphers#On security of cipher\nTipologie di attacchi (!!) üü® Se √® possibile l‚Äôattaccante pu√≤ avere moltissimi vettori di attacchi che possono incrinare i principi di sicurezza che abbiamo enunciato sopra\neavesdrop: spiare la conversazione (eventualmente rubando password e dati) Impersonation: impersonare un altro soggetto (o la macchina di un soggetto). Hijacking dirottare una sessione in corso, quindi controllare le richieste che fai, magari ti mando su una copia di paypal falsa, o Denial of service: negare il servizio agli utenti legittimi, questo sulla sicurezza operativa. Crittografia La crittografia diventa una delle tecnologie chiave per poter garantire i principi di sicurezza.\nAlcune tipologie di cifrari simmetrici üü© Approfonditi in Block Ciphers che solitamente sono utilizzati negli scambi di messaggi simmetrici. Elenco qui alcuni cifrari classici:\nCifrario mono-alfabetico (sostituzione) (come codice cesare, in cui c¬¥√® una mappatura per ogni singola lettera ad altra lettera). Cifrario poli-alfabetico (in cui la criptazione dipende anche dalla posizione). Cifrario a blocchi, come DES, AES etc. Importante diventa anche l‚Äôhashing, che serve un sacco per poter mantenere l‚Äôintegrit√† del messaggio.\nIl problema principale di questo metodo √® lo scambio delle chiavi, che dovrebbe essere sicura anche questa parte. Ma solitamente cifrari asimmetrici come RSA risolvono questa parte.\nLa soluzione ottima per questo metodo √® utilizzare un sistema a chiave pubblica PKI per scambiarsi la chiave privata con cui continuare le transazioni da l√¨ in poi.\nTipologie di attacco üü© i principali metodi di attacco sono\nCipher-text only attack:\nForza bruta, in cui cerco la chiave Statistical analysis attack (per cercare alcuni pattern che possono esistere per rompere il cifrario). Oltre a questi ho anche classici attacchi col plain text: chosen-plaintext attack, known plaintext attack, questi mi permettono un p√≤ pi√π informazioni. Se si ha segretezza perfetta come per OTP allora √® sicuro, ma √® difficile averlo.\nChiavi di sessione e RSA üü© Si √® parlato di questo ambito per abbastanza, ma non la ritengo molto interessante quindi non la metto, √® per√≤ molto importante, ma credo tu sappia come funzioni quindi non la scrivo.\nSemmai due note sulle chiavi di sessione, √® molto semplice, in pratica dato che RSA √® molto pi√π lento e costoso (in termini di energia) dei cifrari a chiave simmetrica utilizzo RSA per scambiarmi la chiave con cui faccio la crittazione simmetrica, questa √® la chiave di sessione.\nda notare che la combinazione di Cifrari simmetrici e asimmetrici riescono a dare forti garanzie (non assolute, perch√© i cifrari possono essere comunque rotti) di confidenzialit√† fra le persone.\nAutenticazione Protocollo di autenticazione üü© Il libro prova a costruire passo passo un protocollo di autenticazione (cio√® una serie di passaggi che finiscono per riuscire ad asserire l\u0026rsquo;identit√† con cui si stia comunicando).\nProtocolli di autenticazione passo passo Dato che lo scambio di password √® sempre vulnerabile a playback attack. Ci costruiamo un segreto temporaneo, la nonce, che √® una mini specie di challenge utilizzata per convincere dell\u0026rsquo;identit√†. Se provo a rimandare la nonce criptata con una chiave privata, allora potrei dire che sono ALICE.\nE dato che la nonce √® unica, non √® vulnerabile a playback attack.\nUltimo protocollo con NONCE e PKI\nR √® la nonce\nNel nuovo sistema con la nonce e il sistema chiave pubblica e chiave privata √® ancora vulnerabile a MITM. Dato che Eve pu√≤ sempre mettersi in mezzo, e praticamente avere in chiaro tutti i collegamenti, dovremmo cercare di identificare in qualche modo la chiave pubblica della identit√† giusta. (devo prendere la chiave pubblica da un servizio fidato, queste sono le certification autorities, CA).\nCertificate authorities üü© Sono dei servizi utili ad identificare l\u0026rsquo;identit√† di una persona, e sono in grado di giustificare la corrispondenza della chiave pubblica con una certa identit√†. Generano per te la chiave pubblica E privata. Per protocolli come TLS-SSL protocol sono fondamentali.\nOvviamente la sicurezza dipende dai processi di autenticazione di questa CA (potrebbe chiederti la carta d\u0026rsquo;identit√†, o altre informazioni simili), che potrebbe essere vulnerabile anche essa. (nella storia sono anche stati hackerati, quindi hanno molte coppie di chiavi messe a gente falsa).\nIntegrit√† del messaggio üü© Potremmo utilizzare il PKI, per firmare con la nostra chiave privata (e poi CA per trovare la chiave pubblica per poter verificare il messaggio) in questo modo il nostro interlocutore √® sicuro dell‚Äôintegrit√† del nostro messaggio e dell‚Äôautenticit√† di chi me lo sta mandando (con le CA).\nSe poi si fa la stessa cosa mandando un messaggio gi√† cifrato, allora ho anche segretezza, senza nessun problema!\nMa poi, dato che √® molto costoso firmare un messaggio tanto lungo, solitamente si firma solamente l\u0026rsquo;hash del messaggi originale, quindi rende molto pi√π efficiente il protocollo. ma anche il fatto che in questo modo posso firmare messaggi molto corti! Ho sempre un codice della stessa linguaggio.\nFunzione di hashing üü© Ci sono un sacco di caratteristiche che dovrebbero tutte le funzioni di hashing soddisfare\nUn digest fisso, di una certa lunghezza. Pre-image collision, dovrebbe essere difficile trovare un altro messaggio con lo stesso hash. Una propriet√† che dovrei soddisfare √® il fatto che se cambio un bit di input cambi di molto l\u0026rsquo;output, ossia ci sia pochissima correlazione fra input e output! (certamente cose lineari non ci piacciono) Esempio di hash brutto Internet checksum\nUn esempio di hash brutto √® l\u0026rsquo;internet checksum perch√© √® molto facile poter creare una collisione!\n√à in grado di rilevare solamente errori idioti (quelli fatti senza l\u0026rsquo;intelligenza di un EvE che prova a cambiarti i bit, ma sono abbastanza random!)\nProtocollo Mail sicura üü© \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 9.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 9\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 10.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 10\u0026quot;\u0026gt; Praticamente generiamo una chiave simmetrica, poi se vogliamo firmarla e metterci un coso di integrit√† MAC possiamo farlo, cifriamo con chiave pubblica di bob presa da CA la nostra chiave e mandiamo il pacco con Messaggio privato, magari firmato, e chiave criptata.\nBob riceve e riesce a ricavare tutto quanto possibile per verificare l‚Äôintegrit√† del messaggio e comprendere il messaggio!\nProtocollo SSL Trattato un po\u0026rsquo; meglio (con altri dettagli) in TLS-SSL protocol Se rendiamo il socket sicuro, rendiamo sicuro tutto quello che c\u0026rsquo;√® sotto, quindi dal livello 4 in gi√π, vedi Architettura e livelli 1, 2 per dettagli sulla stack. In questo modo le applicazioni possono decidere se utilizzare o meno questo protocollo, dato che √® sotto di essa.\nSlide presentazione ssl\nImplementazione Toy-SSL üü®+ Utilizzando il sistema presentato sopra riescono a cambiare un segreto (come una chiave condivisa per comunicare, ma sar√† un robo per creare un set di chiavi, o il vettore di inizializzazione)\nIl set di chiavi sono utilizzati per invio direzionale e verifica di integrit√† direzionale (quindi sono 4 chiavi). Che sono generate dalla Master Key scambiata dalla prima fase.\nCARATTERISTICHE PACCHETTI SSL üü•\nDurante il trasferimento dei dati vogliamo avere anche altre caratteristiche che aiutino a mantenere la sicurezza di questo protocollo:\nNumerazione per evitare che eve duplichi pacchetti o simili. Verifica di integrit√† ha un proprio hash MAC (hashato √® anche la numerazione a livello SSL). Slide record and sequence numbers COMMON ATTACKS\nReorder attack, utilizzo le sequence numbers per numerare i records, cos√¨ sono sicuro che non pu√≤ riordinare dato che non possiede le chiavi\nReplay attack riutilizzo anche in questo momento le nonce\nTruncation attack vogliamo anche avere un modo per terminare in modo sicuro la comunicazione, cio√® non dovremmo permettere a Eve di terminare la comunicazione per noi. Per fare questo mettiamo anche una parte tipologia di messaggio in ogni MAC. (importante il fatto che √® su due versi la chisura!)\nImplementazione SSL (skip) Questo √® uguale al toy SSL alla fine‚Ä¶ Solo con qualche accorgimento in pi√π, non √® importante sta parte\nhandshake √® leggermente pi√π complicato, c‚Äô√® anche una fase di autenticazione dell\u0026rsquo;utente e scelta dell‚Äôalgoritmo crittografico asimmetrico. Alla fine mando anche MAC di tutti i messaggi di handshake per prevenire tampering, come l‚Äôeliminazione degli algoritmi pi√π forti per poter provare a bruteforcare meglio. Record Format in questo modo si chiamano i pacchetti di SSL, contengono cose simili a quanto abbiamo descritto per il toy SSL\nLa cosa particolare √® che i dati e il mac sono entrambi criptati con la chiave simmetrica che abbiamo derivato prima, in modo simile a quanto fatto dal toy-SSL.\nIPsec Moved to IPSec protocol\nFirewalls Vogliamo cercare di filtrare quello che entra dall\u0026rsquo;esterno. mentre in generale ci fidiamo di quello che √® presente all‚Äôinterno del firewall (quindi se riesco a controllare una macchina che sia dentro avrei pieno accesso).\nObiettivi dei Firewalls üü®- L‚Äôobiettimo principale dei Firewalls √® proteggere da attacchi esterni, esempi di attacchi potrebbero essere\nVorrei evitare DoS, ossia permettere senza problemi di aprire delle porte TCP senza andare a chiuderne una. Non devo permettere la modifica arbitraria dei dati (che hanno conseguenze penali credo) Permettere l‚Äôaccesso solamente a utenti autenticati Per fare ci√≤ possono avere a disposizione tre tipologie di firewalls, quelly che iltrato senza avere uno stato quelli con uno stato, ma anche le application gateways (che controllano il contenuto di quello che esce e quello che entra).\nSlide obiettivi\nAccess control List üü®+ \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 29.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 29\u0026quot;\u0026gt; In sede diversa, questa strategia √® stata analizzata anche in analisi delle autorizzazioni nei sistemi operativi. Vedi Sicurezza OS. Vogliamo permettere certe cose, e negarne altre. La ACL √® solamente una lista di regole di permessi e negazioni, con specificazione di source, address, protocollo, porta di arrivo e di partenza e flag‚Ä¶\nCon queste regole posso implementare senza problemi il Stateless filtering\nStateless/Stateful Packet filtering üü© Alcuni pacchetti vengono droppati quando ci sono certe informazioni all\u0026rsquo;interno del pacchetto.\nInformazione come Source e destination IP\nPort numbers for TCP or UDP\nICMP messages\nSyn and Ack bits, and maybe more\nSlides Stateless packet filtering\nMore examples of these Quando una cosa non ha molto senso da sola, e ha bisogno di tenere conto dello stato della connessione allora abbiamo bisogno di utilizzare uno stateful packet filtering in cui si monitora la storia della connessione TCP una volta che la connessione √® stata aperta.\nApplication gateway and IDS üü© Fanno a vedere il contenuto, e gli header dei pacchetti che provengono dall\u0026rsquo;interno. TODO meglio, il prof ha saltato.\nIntrusion detection systems /turn\nVogliamo cercare di capire se siamo sotto attacco, quindi se qualcuno fa port scanning, oppure packet filtering pesante da certe cose, oppure provare a vedere se il contenuto del pacchetto potrebbe essere dannoso.\nDemilitarized üü© https://doubleoctopus.com/security-wiki/network-architecture/demilitarized-zone/\nin pratica √® possiamo considerarla come una rete di appoggio per accedere a una rete untrusted esterna, come Internet.\nSolitamente in questa DMZ ci mettiamo cose come Email, web servers e cose simili. √à una zona quarantinata, cio√® per interagire col network interno si passa di nuovo d aun firewall, questo per garantire maggiore protezione della roba interna, solitamente molto pi√π importante.\n","permalink":"https://flecart.github.io/notes/sicurezza-delle-reti/","summary":"Obiettivi della sicurezza (!!!) üü© Vogliamo creare delle reti che abbiamo certe garanzie di sicurezza, soprattutto:\nConfidenzialit√†, non vorremmo che il nostro messaggio sia intercettabile e leggibili da persone intermedie Integrit√†: non vogliamo che messaggi possano essere cambiati senza intervento del sender Autenticazione: vorremmo sapere con chi stiamo parlando, e vorremmo essere sicuri che non stiano mentendo sull‚Äôidentit√†. Sicurezza operativa(Availability): vorremmo essere in grado di poter continuare a fornire il servizio (quindi non sia possibile dossare, o installare malware che modifichino il comportamento del servizio).","title":"Sicurezza delle reti"},{"content":"Perch√© a stack üü©- Capire l‚Äôarchitettura significa capire la struttura (l‚Äôorganizzazione) del nostro app e comprenderne i motivi (i sottoproblemi risolti) che ogni livello prova a risolvere\nLa soluzione che √® stata individuata, e ha rappresentato uno dei principali cardini del successo delle reti e della nascita di Internet, √® data dalla separazione delle classi di protocolli in livelli. La struttura dei livelli dei protocolli di rete prende il nome di architettura dei protocolli di rete. Il concetto di architettura dei protocolli, suddivisa in livelli, √® semplice ed √® basato su alcune condizioni.\nOgni livello\nSvolge determinate funzioni di gestione dei processi di comunicazione, attraverso uno o pi√π protocolli alternativi. Fornisce un livello di astrazione pi√π elevato della rete di comunicazione sottostante, sfruttando i servizi implementati dai livelli sottostanti. Ha relazioni dirette solo con i livelli immediatamente superiore e inferiore, attraverso richieste e servizi concordati, detti interfaccia del livello In altre parole, i livelli superiori non devono preoccuparsi di risolvere problemi che saranno gestiti e risolti dai livelli inferiori.\nLa cosa migliore per questa struttura √® che se ho bisogni differenti posso individuare il livello che mi interessa e re-mplementare solo quanto ho bisogno, senza dover cambiare l\u0026rsquo;intera stack.\nEsempio architettura a livelli (fatta dal prof in persona e rubata da altri profzz, lel)\nSi ha un esempio di trasmissione e ricezione delle informazioni tramite questa metafora.\nOgni livello risolvere un problema preciso nella fase di trasmissione dell‚Äôinformazione‚Ä¶\nLa cosa interessante √® che dal livello di dichiarazione (o app) non si vede tutto il sotto, √® come se magicamente fosse tradotto e presentato nella lingua corretta! Risolve un grande problema di complessit√†.\nVantaggi\nRiutilizzabilit√† di molti layers, basta cambiare cose di un singolo layer se ho bisogno di fare cose mie. Gli strati paritari si parlano astraendo tutto quanto avviene di sotto. Si potrebbe andare a parlare di encapsulation and data hiding cio√® tutti i dati di un singolo livello sono isolati a quello e i dati sono solamenti di questo livello. Esposte sono solamente le relazioni, come si parla sopra. (facilita anche il debuggin per singolo LIVELLO)\nArchitettura standard (OSI) !!! üü© \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Architettura e livelli 1, 2/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Architettura e livelli 1, 2/Untitled 1\u0026quot;\u0026gt; Lo Standard ISO/OSI RM (International Organization for Standardization (ISO)/Open System Interconnection Reference Model) definisce un insieme di livelli completo e rigoroso per l‚Äôarchitettura dei protocolli di rete, prevedendo un livello per la gestione di ogni problema di comunicazione in rete.\nCi√≤ che si va a standarizzare √® l\u0026rsquo;interfaccia dei vari livelli. (API)*. Mentre l\u0026rsquo;implementazione di queste funzioni √® lasciato a piacere, basta che soddisfi quello che deve fare. (Questo √® ci√≤ che permette la flessibilit√† di questra struttura). L‚Äôarchitettura dei protocolli di rete definita da ISO/OSI RM prevede sette livelli dei protocolli, numerati da 7 a 1 dall‚Äôalto al basso.\nil livello fisico si occupa di definire le tecniche di codifica dei dati, la trasmissione e la ricezione dei dati sul mezzo fisico di trasmissione (‚Üí Fisica here). livello LLC/MAC si occupa di garantire l‚Äôaffidabilit√† del mezzo di trasmissione e la gestione dell‚Äôaccesso al mezzo trasmissivo ad accesso multiplo (evitando le collisioni). A questo livello il pacchetto si chiama FRAME. MAC (Media Access Control) √® sotto. Inserisce gli indirizzi di destinatario e mittente (MAC) (spesso questi indirizzi sono solamente locali, per sapere a chi dare come step intermedio), forniti dal costruttore Decisione di quando trasmette (ad esempio pu√≤ chiedere al livello fisico se il canale √® libero o meno, e gestisce questa cosa col suo protocollo, quindi dilazionare il tempo di trasmissione) LLC (Logical link control) √® sopra Verifica che non ci siano stati errori di trasmissione delle informazioni ricevute. Dire di inviare l‚Äôacknowledgement, se √® il momento giusto. Gestire pacchetti duplicati. Il livello rete si occupa di frammentare i dati in pacchetti, scrivere gli indirizzi dei destinatari finali e instradare i pacchetti verso i destinatari intermedi del cammino. In questa sezione andiamo oltre alla rete locale, √® qui che nasce internet vero! Il router √® un elemento principale di questo. Frammentazione dei pacchetti Indirizzamento IP che servono a dare un identificativo alla scheda di rete in ambito locale per capire in quale direzione trasferire. Il livello trasporto si occupa di garantire i servizi di trasmissione dei pacchetti (orientati alla connessione e non) e del controllo della congestione della rete. Un esempio di protocollo a questo livello √® il TCP(Trasmission Control Protocol). Che fa i controlli sull‚Äôacknowledgement e simili Potrebbe essere ch ealcuni router siano congestionati, quindi che droppino alcuni pacchetti Non √® una soluzione dire agli altri router di inviare in modo pi√π lento. (Dovrebbe essere il mittente che dovrebbe rallentare nell\u0026rsquo;invio di pacchetti, in modo che non si congestionano nessun nodo). Il livello sessione mantiene e gestisce lo stato attuale del collegamento tra due applicazioni remote. (quindi poter riprendere da un certo stato quando per un certo momento ti sconnetti). Di solito questo √® gestito dall‚Äôapplicazione, e non viene implementato. Il livello presentazione risolve eventuali eterogeneit√† del formato dei dati tra i nodi della rete. Perch√© i formati sono gi√† leggibili, senza dover interpretare i bit per capire cosa rappresentano. Il livello applicazione fornisce alle applicazioni in esecuzione sul calcolatore i servizi e le primitive di trasmissione e ricezione dei dati. primitive che servono al processo di esecuzione per funzionare. es. funzione per mandare i dati e simli. Qui le funzioni possono essere moooltee Architettura dei protocolli di internet üü© In questa sezione si tratta di come effettivamente quanto dell\u0026rsquo;architettura OSI √® implementata\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Architettura e livelli 1, 2/Untitled 2.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Architettura e livelli 1, 2/Untitled 2\u0026quot;\u0026gt; L‚Äôarchitettura dei protocolli di Internet, nel senso pi√π comunemente adottato, prevede di fatto l‚Äôimplementazione di solo cinque livelli dei sette livelli dello Standard ISO/OSI RM. Rimangono spesso esclusi i livelli 5 (sessione) e 6 (presentazione), gli altri livelli sono uguali. Il motivo per cui succede √® che principalmente questi livelli sono implementati a livello applicazione.\nUn aspetto che si pone in evidenza, √® il concetto di incapsulamento dei dati tra i livelli implementati. In fase di trasmissione, ogni livello riceve dati dall‚Äôalto (dati spediti dall‚Äôapplicazione) e li inserisce in ‚Äúbuste virtuali‚Äù (incapsulamento) ponendo in testa e in coda alcuni dati aggiuntivi, necessari per fornire al livello della controparte ricevente le informazioni utili all‚Äôimplementazione del protocollo dello stesso livello. In fase di ricezione, ogni livello X riceve dal livello pi√π basso i dati imbustati dallo stesso livello X sul trasmettitore, quindi verifica i dati della busta, agisce in conseguenza alle specifiche fornite nei dati della busta, e passa solo il contenuto della busta ai livelli superiori (decapsulamento). Il livello trasporto spezza i dati dell‚Äôapplicazione in frammenti e li imbusta, aggiungendo informazioni utili all‚Äôordinamento e al riassemblaggio dei dati ricevuti, oltre che al controllo della congestione della rete.\nIl livello rete frammenta ulteriormente i dati in pacchetti (se sono troppo lunghi), scrive l‚Äôindirizzo del destinatario sulla busta, e decide il cammino sul quale inviare il pacchetto a seconda dell‚Äôindirizzo di rete del destinatario.\nIl livello MAC/LLC esegue la consegna finale dei dati a dispositivi di una rete locale.\nLivelli ISO/OSI Livello fisico\nSono a livelli fisico perch√© devono avere lo stesso mezzo fisico (eg ethernet solo ethernet!, wifi solo wifi!)\nSegmento di rete üü© - Segmento di rete\nun mezzo di trasmissione condiviso con canale ad accesso multiplo, in cui tutte le schede collegate al segmento ricevono quanto trasmesso\nGli indirizzi MAC sono consapevoli dell\u0026rsquo;esistenza di questo mezzo di broadcast, con prima il destinatario, cos√¨ lo legge subito.\nCollegarli tutti in un canale broadcast non √® che sia molto buono\nRischio di collisioni molto alto Perdita di intensit√† dei segnali elettrici Principalmente spreco di tempo ed energie. Quindi abbiamo bisogno di modi per creare segmenti per risolvere questi problemi., che facciano cose intelligenti.\nIl segmento di rete √® importante! Mini rete locale, √® anche il modo in cui mando il pacchetto al router con source e destination.\nComposizione di segmenti di rete (4) üü© Appunti prof di dispositivi per livello 1 e 2\nA questo punto esistono i presupposti per introdurre alcuni dispositivi che possono essere usati per comporre ed estendere una rete locale di calcolatori, unendo segmenti di rete altrimenti separati. Il primo dispositivo √® il ripetitore (repeater). Siccome i segnali emessi su qualsiasi mezzo fisico si degradano al crescere della distanza percorsa, esiste un limite massimo per la lunghezza di un segmento di rete. Ad esempio, un segmento Ethernet, pu√≤ variare dai 100 ai 200 metri. Un repeater √® un dispositivo che agendo solo a livello fisico, amplifica e rigenera il segnale ricevuto verso un prolungamento del segmento di rete. Mediante un repeater √® possibile collegare due segmenti di rete aventi la stessa tecnologia a livello MAC, ed estendere la lunghezza dei segmenti di rete locale. Un Hub (che significa perno di una ruota a raggi) √® un altro dispositivo che agisce solo a livello fisico. Esso realizza il punto centrale di connessione, detto concentratore, dei segmenti di una rete locale con topologia a stella. In pratica si tratta di un ripetitore (repeater) con tante connessioni entranti e uscenti. Un Bridge (ponte) √® invece un dispositivo che agisce anche da traduttore a livello due (MAC/LLC). Un bridge permette di connettere segmenti di una stessa rete locale ma con tecnologie e MAC diversi tra loro (ad esempio un segmento Ethernet con uno Token Ring). I bridge fanno quindi da traduttori dei frame nei formati richiesti dal livello MAC di ogni segmento connesso al bridge, e provvedono alla trasmissione su segmenti diversi adottando il protocollo MAC opportuno. I Bridge sono dotati della capacit√† di filtrare e instradare opportunamente i frame di dati sul segmento opportuno, osservando sui frame le informazioni di indirizzo MAC del dispositivo destinatario. Uno Switch (commutatore) √® un dispositivo di livello due (MAC/LLC) analogo al bridge. Al contrario del bridge, esso permette di connettere un numero maggiore di segmenti diversi (fino a 10 o 12).\nRepeater\nRipetitori. I segnali trasmessi sul mezzo fisico degradano con la distanza, nella fattispecie l‚Äôethernet degrada dopo circa 200 metri, quindi ogni 200 (o, meglio, 100) metri si aggiunge un ripetitore. Il ripetitore amplifica e rigenera il segnale ricevuto. Il repeater collega due segmenti di rete che hanno la stessa tecnologia MAC; non legge i dati, vede semplicemente che sta arrivando un segnale e lo amplifica e passa oltre. Con l‚Äôallungarsi delle distanze chiaramente le trasmissioni impiegano un po‚Äô di tempo in pi√π per viaggiare da mittente e destinatario, quindi nel caso di reti LAN pi√π grandi diventa necessario allungare i tempi di timeout.\nHub\n√à un repeater multiporta. √à il nodo centrale di una rete a stella. Quando riceve un segnale da una porta lo copia e lo manda a tutti gli altri elementi della rete. √à usato pochissimo in quanto costa poco meno dello switch, che per√≤ offre pi√π funzionalit√† e porte.\nBridge\nhub ripete tutto quanto ha avuto a tutti quanti sono collegati, ma ha il problema grosso delle collisioni\nSwitch\nConnette tecnologie omogenee.\nriesce a filtrare e inviare i frame al segmento giusto. Quindi si comporta come un hub quando non sa dove andare, ma riesce ad ascoltare gli segmenti e vedere se √® libero, se √® libero manda, e se torna l‚ÄôACK allora aggiorna la propria tabella dei segmenti che mappa il MAC con il segmento corretto.\nAppunti di bianchi\nLavora a livello 2. A differenza del bridge permette di connettere molti pi√π segmenti (oggi gli switch hanno anche 96 porte). Interconnette tecnologie omogenee, non diverse, e filtra i pacchetti da inoltrare a seconda della loro destinazione. Manda i dati in broadcast solo se non sa dov‚Äô√® il destinatario. - Buffered switch: ha un buffer di memoria che ha la funzione di memorizzare tutti i frame che arrivano. Questo siccome la trasmissione deve essere smistata e non √® automatica, ma segue le regole del protocollo MAC, pu√≤ essere necessario che una trasmissione debba attendere il completamento di un‚Äôaltra precedente.\nBridge\nFunziona come uno switch (quindi lavora a livello 2) ma connette tecnologie a livello locale con MAC protocol diversi (ad es. Ethernet e Wifi). Se riceve trasmissioni da un protocollo (ad es. Ethernet) e deve mandarle ad un altro protocollo (ad es. Wifi) prende il pacchetto, lo smembra e lo ricostruisce in un frame compatibile con l‚Äôaltro protocollo (i dati cambiano la ‚Äúbusta gialla‚Äù).\nNote sui primi 2 livelli Livello fisico üü© √à il livello della scheda di rete, dei mezzi di trasmissione fisici, codifica e decodifica dei segnali in analogici e digitali.\nImportante in questa parte √® il concetto di velocit√† del mezzo trasmissivo e velocit√† di trasmissione.\nLa velocit√† di trasmissione dipenda dalla durata del vagone, o della rappresentazione dei dati nel mezzo trasmissivo.\nAppunti prof Livello fisico I valori possibili per i dati digitali (bit) del calcolatore sono solo due: i valori 0 e 1. Tali valori devono essere trasmessi o ricevuti sui mezzi di trasmissione delle reti, sotto forma di variazioni di segnali analogici (elettrici, ottici o radio), uno di seguito all‚Äôaltro. Per questo scopo, i dati digitali devono essere opportunamente codificati o decodificati, in sequenza, da parte della scheda di rete. L‚Äôattivit√† di codifica, effettuata in fase di trasmissione, equivale a tradurre i valori dei bit in segnali analogici. L‚Äôattivit√† di decodifica, effettuata in fase di ricezione, equivale a tradurre i segnali analogici ricevuti nei valori dei bit. Le tecniche di codifica digitali permettono di ridurre, ma non di escludere completamente, la possibilit√† di errori di trasmissione sulla rete. Una nota importante riguarda l‚Äôambiguit√† di fondo sul concetto di velocit√† della trasmissione dei segnali in rete. Dal punto di vista fisico, tutti i segnali analogici, elettrici, ottici o radio, si propagano praticamente alla stessa velocit√†, cio√® alla velocit√† della luce, pari a circa 300.000 Km/sec. Non ha quindi senso parlare di bit, oppure di segnali, pi√π veloci di altri. Tuttavia, nell‚Äôesempio in figura, un canale A di comunicazione sul quale siano codificati dieci bit al secondo ha una densit√† di trasmissione dei bit (detta anche capacit√† del canale) pari alla met√† della capacit√† ottenuta da un canale B, sul quale possano essere codificati venti bit al secondo. I canali a capacit√† pi√π elevata, ovvero in grado di trasmettere pi√π bit al secondo, devono tali prestazioni al fatto di usare meno tempo per codificare, ovvero rappresentare il valore del bit sul mezzo trasmissivo, rispetto a canali pi√π ‚Äúlenti‚Äù. Le migliori tecnologie di rete sono quelle che permettono di codificare i bit nel minor tempo possibile, ottenendo quindi alte capacit√† dei canali (ad esempio, miliardi di bit trasmessi al secondo). Livello di collegamento üü© MAC\nCanale Mac di broadcast\nStruttura e utilizzo dell\u0026rsquo;indirizzo MAC\nPolicies generali per l‚Äôarbitraggio del canale per risolvere le collisioni.\nAppunti prof Livello Mac\nAnalizziamo ora l‚Äôesempio pi√π semplice per la definizione di una rete di calcolatori a commutazione di pacchetto: un segmento di rete locale. Un segmento di rete locale √® definito come un mezzo di trasmissione condiviso sul quale sia definito un canale ad accesso multiplo.\nOgni calcolatore si assume dotato della scheda di rete opportuna per il mezzo trasmissivo e i protocolli di codifica utilizzati al livello uno (fisico). Ogni scheda di rete √® dotata di un identificativo (indirizzo) di livello MAC unico al mondo (assegnato dal costruttore). Ogni trasmissione di un pacchetto di dati (detto frame a questo livello) sul canale ad accesso multiplo √® ricevuta da tutti i calcolatori la cui scheda di rete sia connessa al canale stesso. Immaginiamo che il dispositivo con indirizzo MAC1 voglia spedire un frame di dati al dispositivo con indirizzo MAC5, e allo stesso tempo il dispositivo di indirizzo MAC4 voglia spedire un frame di dati al dispositivo di indirizzo MAC2.\nNel contesto del canale condiviso, la conoscenza degli indirizzi MAC dei dispositivi mittente e destinatario basta ad effettuare la trasmissione, sul canale comune. Semplificando molto il problema, per ragioni di presentazione, √® sufficiente aggiungere le informazioni sull‚Äôindirizzo MAC del destinatario e del mittente sulla busta di ogni frame, prima di trasmetterlo.\nOgni frame trasmesso sul canale da parte di ogni dispositivo risulta quindi rilevato da tutti gli altri dispositivi, ma viene ricevuto (cio√® copiato e passato ai livelli superiori) solo se l‚Äôindirizzo MAC del destinatario specificato nel frame coincide con l‚Äôindirizzo MAC del dispositivo ricevente. Il compito principale dei protocolli di livello 2 (MAC/LLC), oltre all‚Äôindirizzamento dei frame trasmessi sul canale condiviso del segmento di rete locale, √® dato dall‚Äôarbitraggio degli accessi al canale. Ossia\nDeterminare i nodi che possono trasmettre Quando possono trasmettere L‚Äôordine di trasmissione per evitare collisioni LLC\nControllare se i dati sono corretti, o ricevuti doppi (se doppio o errato faccio finta di non averlo ricevuto). Mandare acknowledgment (che non succede col broadcast). Appunti prof affidabilit√† di questo livello (ACKs) Scopo dei protocolli del livello 2 (MAC/LLC) √® nascondere ai livelli superiori i dettagli del mezzo fisico, e mostrare il canale condiviso sul segmento di rete locale come se si trattasse di un canale affidabile, senza alcun errore di trasmissione. A tal fine il frame di dati viene delimitato mediante particolari etichette di bit, poste all‚Äôinizio e alla fine del frame, e viene arricchito con altri campi di dati utili al protocollo. La trasmissione di un frame procede per tentativi, fino alla ricezione di una conferma (un frame di conferma) da parte del destinatario. Quello qui illustrato √® solo un meccanismo semplice per realizzare trasmissione affidabile, tra quelli possibili. La figura mostra la sequenza temporale di eventi gestiti dal livello 2 (MAC/LLC) per la trasmissione affidabile di un frame di dati tra due dispositivi sulla stessa rete locale. Il frame di dati viene spedito dal dispositivo con indirizzo MAC1 al dispositivo con indirizzo MAC2 sul mezzo trasmissivo. Il mittente fa partire un timer dopo la trasmissione. Il ricevente MAC2 si accorge che il frame √® destinato a lui, ma rileva errori sui bit ricevuti, per cui non fa nulla (non passa il frame ai livelli superiori) e non invia la conferma a MAC1. Allo scadere del timer, MAC1 verifica che non ha ricevuto conferma, per cui ripete da capo la trasmissione, e fa ripartire il timer. Questa volta MAC2 riceve correttamente il frame e spedisce a MAC1 un frame di conferma. MAC1 riceve il frame di conferma e solo ora considera terminata con successo la trasmissione del frame. Ai livelli dei protocolli superiori al livello due tutto ci√≤ viene nascosto, e appare solamente la trasmissione corretta del frame sul segmento di rete. Collaborazione livelli per affidabilit√† (!!)üü© Acknowledgement livello 4\nNon √® sufficiente verificare che funzioni a livello 2, bisogna anche avere un ACK a livello 4 che sia end-to-end, cos√¨ so sicuro che tutto il processo passo passo a livello MAC funziona, ossia sono riuscito effettivamente a raggiungere il destinatario.\nQuindi serve questo ack a livelli diversi e tempi diversi (uno fa end-to-end ack, l‚Äôaltro fa ack ogni step). Ma l‚ÄôACK a livello 4 √® necessario, perch√© il mittende deve sapere se sia ricevuto, mentre il livello 2 non sarebbe strettamente necessario, ma √® molto probabile che vada male qualcosa a livello intermedio, e questo ACK riesce a risolvere problemi a questo livello ritrasmettendo.\nLivello 2 Evitare che un fallimento di singolo frame fallisca l‚Äôintera trasmissione a livello pi√π alto (e quindi riuscire a recuperare molto pi√π in fretta se viene perso a questo livello). Livello 4 Informare il mittente che l‚Äôinformazione √® stato ricevuto correttamente (quindi end-to-end). Caso di segmento faulty !\nNel caso in cui il livello MAC non riesce proprio a ricevere l‚ÄôACK, questo lo comunica al livello di Rete che ha una immagine della sua topologia di rete, e prova a creare un nuovo percorso per arrivare a destinazione. Si vede qua come avere pi√π strare possibili per arrivare alla destinazione sia necessario.\nAlcune tecnologie di rete üü© Ethernet Il pi√π famoso √® il protocollo Ethernet che da il nome a una vasta serie di schede di rete che implementano la sua definizione, per l‚Äôutilizzo in reti locali basate su mezzo fisico cablato. L‚Äôidea di base di Ethernet, per ridurre le collisioni dei segnali, √® di adottare il principio dell‚Äôascolto del canale, prima di ogni trasmissione (se vede che √® occupato, viene rigenerato un tempo di attesa casuale). Se nessuno sta gi√† trasmettendo, allora la trasmissione pu√≤ essere iniziata senza collisione con le trasmissioni in atto. Siccome pu√≤ accadere che due schede di rete possano iniziare allo stesso istante le rispettive trasmissioni, occorre trovare una soluzione all‚Äôinsorgere di possibili collisioni. La scheda di rete trasmittente √® in grado di rilevare le collisioni in atto durante la trasmissione, e in tal caso interrompe immediatamente il tentativo di trasmissione. Il tentativo verr√† tentato da capo, dopo un attesa di tempo casuale, variabile da scheda a scheda.\nWifi Una tecnica simile a Ethernet viene adottata nelle reti senza fili (wireless), ad esempio in reti Wi-Fi conformi allo Standard IEEE 802.11. Il problema principale in reti senza fili √® dato dall‚Äôimpossibilit√† pratica di realizzare la rilevazione di collisioni in atto durante la fase di trasmissione. La tecnica si basa sulla prevenzione delle collisioni, dilazionando nel tempo i tentativi di accesso.\nToken Ring Il protocollo Token Ring √® un protocollo MAC concepito per reti locali con topologia ad anello. L‚Äôaccesso √® regolato per mezzo di un frame speciale, detto Token, che viene passato (trasmesso), come se fosse un ‚Äútestimone‚Äù, ciclicamente tra tutti i dispositivi in rete. Solo chi detiene il token ha diritto di trasmettere sul canale, evitando il rischio di collisione, dopodich√© deve trasmettere il token alla stazione successiva nell‚Äôanello.\nLa cosa bella di questo √® che la trasmissione √® necessariamente senza collisioni dato che parla solo uno alla volta, questo √® una cosa molto bella.\nUn altra cosa √® acknowledgement implicito perch√© se il messaggio ritorna al mittente uguale, allora √® OK. Potrei anche costruire comunicazioni a pochi bit, veloci (simili a voice over IP).\nSvantaggio\nNon ho modo di recuperare se\nPerdo il token (questo √® una cosa molto grave!). Un host va gi√π, e viene rotto il link. (unique point of failure!) Note generali\nQueste reti si identificano tutte come best effort perch√© possono sempre non funzionare, causa collisioni o interferenze di rete\nEsempio di rete locale Appunti prof di boh La figura mostra un esempio di rete locale composta da diversi segmenti: un segmento con topologia ad anello e protocollo MAC di tipo token ring colorato in rosso e da vari segmenti ethernet, con topologia a stella e a bus, colorati in blu. A sinistra, un calcolatore dotato di dispositivo di rete token ring con indirizzo MAC A √® connesso a un anello di rete token ring insieme ad altri 3 calcolatori e insieme a un bridge (oppure uno switch) identificato dal colore giallo (per indicare che agisce a livello MAC/LLC) e dalla lettera B sullo schermo. Il bridge B agisce da collegamento e traduttore dei frame tra il segmento token ring (rosso) ed il successivo segmento ethernet (blu). Il bridge B ha quindi due connettori di rete: uno token ring e uno ethernet. Il segmento ethernet del bridge B √® connesso a un Hub (H) dal quale partono sei segmenti ethernet, di tipo punto a punto, verso altrettanti calcolatori. Uno di questi calcolatori, identificato dalla lettera R √® un repeater, che propaga e amplifica i segnali verso un successivo segmento ethernet con topologia a bus, sul quale esistono quattro calcolatori. Al termine del bus esiste un nuovo repeater R, che propaga e amplifica i segnali verso un ultimo segmento ethernet con topologia a bus, al quale √® collegato un calcolatore dotato di scheda ethernet con indirizzo MAC B. Al di sopra dei dispositivi citati viene rappresentato il cammino logico di un frame trasmesso dal calcolatore con MAC A al calcolatore con MAC B, passando per i segmenti, i connettori di rete, e i livelli dei protocolli opportuni. In particolare, il bridge B √® l‚Äôunico elemento nel quale il frame trasmesso sul segmento token ring sale fino al livello 2, per essere tradotto e ritrasmesso sul segmento uscente adottando il nuovo protocollo MAC ethernet. Nei rimanenti dispositivi hub e repeater, i frame sono semplicemente ricevuti e ri-trasmessi sui segmenti uscenti. Se il bridge avesse dovuto connettere pi√π di due segmenti diversi, allora si sarebbe utilizzato uno switch, che svolge l‚Äôattivit√† del bridge gestendo pi√π interfacce di rete e protocolli. Dovrebbe essere chiaro a questo punto come sia possibile connettere diversi segmenti di rete locale, e gestire la trasmissione di frame di dati tra due dispositivi qualsiasi di una rete locale, semplicemente identificando i dispositivi attraverso il loro indirizzo MAC. ","permalink":"https://flecart.github.io/notes/architettura-e-livelli-1-2/","summary":"Perch√© a stack üü©- Capire l‚Äôarchitettura significa capire la struttura (l‚Äôorganizzazione) del nostro app e comprenderne i motivi (i sottoproblemi risolti) che ogni livello prova a risolvere\nLa soluzione che √® stata individuata, e ha rappresentato uno dei principali cardini del successo delle reti e della nascita di Internet, √® data dalla separazione delle classi di protocolli in livelli. La struttura dei livelli dei protocolli di rete prende il nome di architettura dei protocolli di rete.","title":"Architettura e livelli 1, 2"},{"content":"Per l‚Äôanalisi lessicale vogliamo cercare di ricordare le parole legali all\u0026rsquo;interno di questo linguaggio e questo √® fatto con i linguaggi regolari.\nIntroduzione a analizzatori lessicali Token üü© Struttura del token √® fatto da due parti\nIdentificatore della classe del token Identificatore del valore del token Pattern e lessema ci sono direi boh Pattern e Lessema üü© I pattern sono una descrizione generale della forma dei valori di una classe di token.\nLessema √® una istanza di un particolare pattern\nEsempio di scan\nDi solito viene storato come puntatore alla tabella dei simboli\nEspressioni regolari Definizione üü© Slide definizione espressioni regolari\nDisambiguazione della grammatica\nEsempio espressione regolare\nLinguaggio generato da regexp üü© Per capire questa parte √® importante avere in mente le operazioni sui linguaggio definiti in Descrizione linguaggio\nSlide\nLinguaggio regolare üü© Definizione linguaggio regolare\nOgni linguaggio finito √® un linguaggio regolare questo √® una proposizione che lega fortemente i linguaggi (utilizzati poi veramente per l\u0026rsquo;implementazione) (basta fare l‚Äôunione!)\nEsempio linguaggio finito generato da linguaggio regolare\nEsempi di espressioni regolari infiniti\nOltre ai classici operatori definiti in precedena per questa sezione aggiungiamo\nRipetizione-positiva, Possibilit√†, Elenco\nDefinizioni regolari üü©- Le definizioni regolari ci aiutano a creare una struttura del token di cui dobbiamo fare lo scanning.\nIn pratica andiamo a creare delle definizioni che rendono pi√π facile la descrizione di un pattern con regexp.\nSlide\nEsempi\nEquivalenza regexp üü© Esempi di equivalenze\nQueste equivalenze non sono sempre facili da dimostrare\nAutomi In questa parte si fa una descrizione molto generale di cosa siano gli automi.\nCaratteristiche (3) üü© Slide\nMemoria finita (dato da un numero di stati) Input una stringa da riconoscere Output √® solamente un singolo bit (si oppure no) Descrizione e funzionamento üü© Slide\nDescrizione\nTestina sul primo carattere in input. Su stato q0 Funzionamento\nIl funzionamento dell\u0026rsquo;automa √® molto semplice, esegue un semplice algoritmo:\nLeggi il carattere attuale, se esiste una transizione etichettata con quanto letto spostati secondo la regola di quel carattere. Dopo aver finito di leggere la stringa, se √® in uno stato buono restituisci 1, altrimenti 0 Se √® bloccato in uno stato ritorna 0 Diagrammi di transizione üü© I diagrammi di transizione sono utili per definire in modo grafico cosa fa l\u0026rsquo;espressione regolare\nSlide\nAutomi finiti non deterministici (NFA) Definizione (5) üü© Slide\nPossiamo definire gli automi non deterministici come una quintupla di\n$$ (\\Sigma, Q, q_0 \\in Q, F \\subseteq Q, \\delta) \\\\ \\delta : Q \\times (\\Sigma \\cup \\varepsilon) \\to P(Q) $$ Albeto dei simboli di input Stati possibili Stato iniziale Stati finali (accettati) Funzioni di transizione, che ha come codominio l\u0026rsquo;insieme delle parti di Q Alla fine, per scopi didattici si utilizza sempre il diagramma di transizione. La differenza principale con gli automi a stati finiti √® che posso avere lo stesso label di transizione per singolo stato\nCaratteristiche (2) üü© Facili da realizzare (esiste quasi una bigezione credo fra NDA ed espressione regolare) Inefficienti (backtracking, e fallibile), principalmente causato dal suo non determinismo Stato finale accettato üü© ‚Äî Slide\nQuesto √® una slide molto importante per definire il concetto di stringa accettata/riconosciuta. Praticamente posso affermare che una stringa √® riconosciuto da questo automa finito non-deterinistico se anche un solo cammino da q0 a un qualunque stato accettato.\nOltre questo voglio andare a definire in modo formale il concetto di mossa, o cammino in un diagramma di rappresentazione per un automa finito.\nDescrizione istantanea, mossa, cammino, stringa accettata\nIndico che uno stato $q$ √® raggiungibile da uno stato $s$, con il simbolo $\\vdash$, ossia $s \\vdash v$, questo √® possibile solo se sto leggendo una stringa che ha come relazione una stringa buona, ma questo pezzo √® pi√π chiaro negli appunti quindi ti invito di leggere dal√¨ con la rappresentazione logica classica.\nLa chiusura riflessiva e transitiva di questo concetto di mossa √® indicata con $\\vdash ^*_N$, N √® il nome di questo automa, dovrebbe essere ancora sopra.\nTODO: da definire bene cosa sia la mossa e il cammino!\nLinguaggio riconosciuto da NDA e equivalenza üü© Slide\n$$ L[N] = \\{ w \\in \\Sigma^* | \\exists q \\in F, (q_0, w) \\vdash ^*_N (q , \\varepsilon)\\} $$ La parte di sopra √® la definizione di un linguaggio riconosciuto da un automa, √® un modo molto compatto per esprire l\u0026rsquo;esistenza di un cammino come sopra.\nInoltre possiamo definire il concetto di equivalenza fra NDA che √® quando il linguaggio riconosciuto √® esattamente lo stesso.\nDefinizione di linguaggio riconosciuto con e-closure üü®+ Linguaggio riconosciuto, scritto in modo pi√π elegante, con epsilon closure\nCon la definizione di delta cappuccio possiamo definire che un linguaggio in questo modo:\n$$ w \\in L[N] \\iff \\exists p \\in F : p \\in \\hat{\\delta}(q_0, w) $$ NFA da espressioni regolari (!!!) (duplicato) üü© Questo √® un teorema molto importante per rappresentare una sorta di equivalenza fra linguaggi regolari e NFA.\nEnunciato\nHint dimostrazione\nInduzione strutturale sulla sintassi BNF delle espressioni regolari, andremo a dimostrare che posso comporre NFA che alla fine riescono a riconoscere il linguaggio regolare\nConsigli di studio\nImpararsi i metodi di conversione di ogni parte della sintassi in NFA, poi li componi come dei lego e sei apposto\nDimostrazione\nAutomi finiti deterministici (DFA) Definizione üü© Slide\nDifferenze rispetto NDA\nPrincipalmente la definizione √® uguale agli automi non deterministici l‚Äôunica cosa che cambia √® il delta che ora √® definito come\n$$ \\delta: Q \\times \\Sigma \\to Q $$ Non c‚Äô√® pi√π l‚Äôinsieme delle parti, magari dopo vediamo come questi automi sono equivalenti, ma c‚Äô√® una esplosione esponenziale al momento di conversione da deterministico a non deterministico.\nAlgoritmo creazione DFA da NFA üü© L‚Äôalgoritmo di creazione\nEsempio di utilizzo dell\u0026rsquo;algoritmo (lezione 6)\ncon $F$ l‚Äôinsieme degli stati finali della NFA.\nDFA equivalente a NFA (non chiede) üü® Dimostrazione both, e osservazioni in modo informale\nSlide ‚Üí\nQuesta proposizione si pu√≤ vedere dalla definizione\nSlide ‚Üê\nC\u0026rsquo;√® veramente in questo passo una esplosione esponenziale perch√© il numero degli stati diventa esponenzialmente tanto.\nDimostrazione, induzione, molto formale.\nEsempio di conversione\nepsilon-closure üü© Slide\nAlgoritmo per epsilon-closure\nQuesto concetto di chiusura Epsilon ci racchiude il concetto degli stati raggiungibili in un NFA senza leggere nessun input.\n","permalink":"https://flecart.github.io/notes/automi-e-regexp/","summary":"Per l‚Äôanalisi lessicale vogliamo cercare di ricordare le parole legali all\u0026rsquo;interno di questo linguaggio e questo √® fatto con i linguaggi regolari.\nIntroduzione a analizzatori lessicali Token üü© Struttura del token √® fatto da due parti\nIdentificatore della classe del token Identificatore del valore del token Pattern e lessema ci sono direi boh Pattern e Lessema üü© I pattern sono una descrizione generale della forma dei valori di una classe di token.","title":"Automi e Regexp"},{"content":"The landscape of NLP was very different in the beginning of the field.\n\u0026ldquo;But it must be recognized that the notion \u0026lsquo;probability of a sentence\u0026rsquo; is an entirely useless one, under any known interpretation of this term 1968 p 53. Noam Chomsky.\nProbability was not seen very well (Chomsky has said many wrong things indeed), and linguists were considered useless. Recently deep learning and computational papers are ubiquitous in major conferences in linguistics, e.g. ACL.\nOne of the main aims of linguistics is understanding the structure of human language. How are we able to speak it so naturally, when we are not able to formally describe it? Other natural phenomenon are clearly described, but not language. And another thing is that nobody exposes these idea to young people during middle or high school! Even if it\u0026rsquo;s so ubiquitous. In Prof. Cotterell\u0026rsquo;s opinion, Linguistics is a science, even if it\u0026rsquo;s catalogued in humanities. Mathematics is very useful to study language (this is not very intuitive). For Cotterell, linguistics can be as formal as physics from a mathematical point of view. A weird thing is that linguistics PhD people usually have no college-math experience, and this is as if you are starting a physics PhD without any maths, in Cotterell\u0026rsquo;s point of view. The main difference is that the maths of linguistics is mostly discrete.\nChomsky proposed the idea of competence and performance. (Similar thing explained in (Mahowald et al. 2023)).\nCompetence asserts that there is a true grammar for a language. We have those grammars for programming languages, but we don\u0026rsquo;t clearly know for human languages. This is much studied especially for the study of compilers. And Chomsky 1943 McCullochs paper for perceptrons invented finite-state automata in the same paper!?!? The whole objective is trying to build this function that says yes or no for a syntactical correct sentence.\nPerformance is studied by psycholinguistists. They want to know how humans produce language. But humans usually don\u0026rsquo;t use the competence to produce their sentences.\nWhat is NLP? A set of methods and algorithms for making natural languages accessible to computers.\nE.g. autocorrect, grammarly, machine translation, question answering, many many things, so a quite broad field.\nWhat is linguistics? Linguistics studies properties of languages. Computational linguistics uses techniques from computer science to study language. This is the main difference with NLP. In NLP computers are central, in computational linguistics they are aiding devices.\nReferences [1] Mahowald et al. ‚ÄúDissociating Language and Thought in Large Language Models: A Cognitive Perspective‚Äù 2023\n","permalink":"https://flecart.github.io/notes/introduction-to-natural-language-processing/","summary":"The landscape of NLP was very different in the beginning of the field.\n\u0026ldquo;But it must be recognized that the notion \u0026lsquo;probability of a sentence\u0026rsquo; is an entirely useless one, under any known interpretation of this term 1968 p 53. Noam Chomsky.\nProbability was not seen very well (Chomsky has said many wrong things indeed), and linguists were considered useless. Recently deep learning and computational papers are ubiquitous in major conferences in linguistics, e.","title":"Introduction to Natural Language Processing"},{"content":"Definition of problems Object detection Bisogna trovare all\u0026rsquo;interno dell\u0026rsquo;immagine quali siano gli oggetti presenti, e in pi√π vogliamo sapere dove siano quindi utilizzare una bounding box per caratterizzarli sarebbe buono.\nObject segmentation √à riuscire a caratterizzare categoria per categoria per singoli pixelsm e per questo motivo potrei riuscire a fare delle image map in cui colorare singoli oggetti in una categoria.\nDatasets Example datasets Pascal VOC 2012 Coco datasets Cityscapes dataset Autogenerated datasets But I don\u0026rsquo;t know much about these datasets Applications Auto drive Campo medico (per segmentazione medica o riconoscimento immagini). reidentificazione. Key posse extimations. U-net Il primo skip connection ci permette di capire bene quali siano i bordi, perch√© sappiamo che la convoluzione riesce a prendere bene\nArchitettura di Yolo Downsampling, fare dei mini quadratini, 32 fattori di downsampling, di solito l\u0026rsquo;immagine √® 416x416 e arriva a 13x13. Ogni neurone fa tre predizioni. Quattro valori per una bounding box (offsettata dal neurone), quanto penso di essere sicuro, e poi dire cosa esattamente sto vedendo. Importante avere la funzione di loss per analizzare bene. Vogliamo avere un singolo neurone, quindi forzo a zero tutti gli altri neuroni. Questo √® quello che faccio con la funzione maschera per avere solamente la box di interesse. Poi una volta definito questo provo a definire errore di localizzazione e l\u0026rsquo;errore di classificazione. Quello √® l\u0026rsquo;errore di di localizzazione in cui vogliamo avere la bounding box pi√π corretta. La radice √® una euristica umana per cercare di favorire il punto principale (ma cambia la loss fra versione all\u0026rsquo;altra).\nUna volta che ho le due loss posso provare a bilanciarle: $$ L = \\lambda_{c}L_{loc} + L_{cls} $$ E le variabili si mettono a mano seconda dell'architettura. Region proposals and single shots Region proposals: (R-CNN, Fast R-CNN, Faster R-CNN).\nIl primo √® un vecchio metodo per attaccare il problema. In passato si analizzava la texture per capire le regioni con struttura e dove si avevano altre, utilizzato per avere zone di interesse, senza informazioni semantiche a riguardo. una volta capite le regioni di interesse l\u0026rsquo;altra rete prova a fare classificazione e bounding box.\nSingle shots (Yolo, SSD, Retina-net, FPN).\nSi fanno in unica passata indetificazione del luogo e categorizzazione.\nIntersection over Union This is an evaluation metric used to determine if two regions are the same. If this metric is high enough, the better one is kept (better one as more secure and things like that). Defined as $$ IoU(A, B) =\\frac{\\lvert A \\cap B \\rvert }{\\lvert A\\cup B \\rvert } $$ This metric is also used for other types of algorithms, for example the MinHash algorithm used something very similar. Sometimes this is also called Jaccard Metric.\nNon-maximum-suppression algorithms üü© √à un modo per trovare le bounding box migliori per un certo argomento. In pratica √® un algoritmo greedy, che va cos√¨:\nSorta tutte le bounding box in ordine decrescente di confidence Prendo la prima come vera Le prossime le elimino se hanno una intersection over union alta, altrimenti le tengo. Cos√¨ finch√© non finiscono tutte le bounding box. ","permalink":"https://flecart.github.io/notes/object-detection-and-segmentation/","summary":"Definition of problems Object detection Bisogna trovare all\u0026rsquo;interno dell\u0026rsquo;immagine quali siano gli oggetti presenti, e in pi√π vogliamo sapere dove siano quindi utilizzare una bounding box per caratterizzarli sarebbe buono.\nObject segmentation √à riuscire a caratterizzare categoria per categoria per singoli pixelsm e per questo motivo potrei riuscire a fare delle image map in cui colorare singoli oggetti in una categoria.\nDatasets Example datasets Pascal VOC 2012 Coco datasets Cityscapes dataset Autogenerated datasets But I don\u0026rsquo;t know much about these datasets Applications Auto drive Campo medico (per segmentazione medica o riconoscimento immagini).","title":"Object detection and Segmentation"},{"content":"Work like (Luo 2021) show that our brain has naturally some types of circuits, which can be classified mainly as 4 types as described in (Wang et al.):\nReferences [1] Wang et al. ‚ÄúCircuitNet: A Generic Neural Network to Realize Universal Circuit Motif Modeling‚Äù\n[2] Luo ‚ÄúArchitectures of Neuronal Circuits‚Äù Science Vol. 373(6559), pp. eabg7285 2021\n","permalink":"https://flecart.github.io/notes/circuit-motifs/","summary":"Work like (Luo 2021) show that our brain has naturally some types of circuits, which can be classified mainly as 4 types as described in (Wang et al.):\nReferences [1] Wang et al. ‚ÄúCircuitNet: A Generic Neural Network to Realize Universal Circuit Motif Modeling‚Äù\n[2] Luo ‚ÄúArchitectures of Neuronal Circuits‚Äù Science Vol. 373(6559), pp. eabg7285 2021","title":"Circuit Motifs"},{"content":"Tipologie di control plane La control plane √® la parte al livello di rete che si occupa di riempire le tabelle di istradamento dei router. In questo caso si possono in generare dividere gli algoritmi in due grandi famiglie\nCentralizzati, anche chiamati algoritmi LS( Link state) perch√© devono conoscere in che modo sono collegati i router fra di loro. Solitamente le SDN ossia software defined networking di cui abbiamo parlato in Data Plane utilizzano questi metodi, c\u0026rsquo;√® un server centralizzato (che per ragioni di tolleranza pu√≤ anche essere distribuito, per√≤ diciamo che √® esterno al router la decisione) Distribuiti in cui nessuno ha informazioni complete sulla rete, ma √® possibile scambiarsi informazioni sui vicini e congiungere cos√¨ al percorso pi√π breve. Vengono in questa sede utilizzati algoritmi di distance vector. Possono anche essere statici, ma dato che la topologia della rete √® spesso dinamica √® difficile che vengano utilizzati. Sono molto pi√π preferibili gli algoritmi dinamici che vanno ogni tot ad aggiornare le tabelle.\nSi possono anche differenziare secondo la sensibilit√† al carico. Anche se gli algoritmi moderni sono insensibili.\nAlgoritmi per Control Plane Link state e Dijkstra Questa √® la parte pi√π importante per il prof\nCon grafo indiretto ad archi pesati. questo l\u0026rsquo;abbiamo gi√† studiato in Cammini, ad algoritmi, ed √® stato fatto bene.\nNOTA: ci potrebbero essere problemi di oscillazione dei percorsi calcolati se utilizziamo solamente il carico come unica metrica per misurare il peso di un nodo. Attualmente il metodo migliore per evitare questo √® calcolare il percorso migliore in tempi randomici.\nEsempio di oscillazione dei percorsi\nDistance vectors Non hanno visto Bellman ford e distance vector routing, per√≤ sarebbe carino farle TODO: Autonomous systems Definizione AS Alcuni vorrebbero essere in grado di gestire un blocco di router come vogliono loro, ossia vogliono avere una autonomia amministrativa su un insieme di router. Possiamo quindi dividere tutti i router in delle AS, alcune grandi, di primo livello, pi√π piccole, decide l‚ÄôISP in che modo gestirsele. (ad ogni AS √® associato, sembra, un numero). La cosa importante per√≤ √® che\nTutti i router all\u0026rsquo;interno di una AS eseguono lo stesso protocollo di instradamento. Intra e inter routing Algoritmi di routing a due livelli diversi (BGP Border Gateway protocol per inter, che non chiede, ma sa che esiste. e altri per Intra.)\nIntra sono algoritmi di routing omogenei.\nInter in cui ci interessa solamente capire in che modo si interfaccia in altri sistemi.\nIn pratica non ha fatto niente di control plane‚Ä¶\nOpen Shortest Path first (intra) OSPF √® un algoritmo link state che regola il routing all\u0026rsquo;interno di un sistema autonomo. Per il resto non ci importa sapere altro.\nUtilizza Dijkstra I pesi possono essere messi a mano seguendo certi criteri Minimum hop (peso 1) Inversamente proporzionale alla banda (quindi favorire l‚Äôutilizzo di connessioni di banda maggiori) Supportano un protocollo a livello IP per scambiarsi informazioni sulla congestione (ogni 30 min tipo) Supportano protocolli per la sicurezza e l‚Äôautenticazione (cos√¨ possono ripudiare altri router che non possiedano la chiave di sicurezza). Border Gateway Protocol (!) Introduzione al protocollo BGP Border Gateway Protocol √® uno dei protocolli pi√π importanti insieme a IP. √à il protocollo che ci permette di comunicare fra AS divers, si pu√≤ dire infatti che sia un protocollo inter-AS per questo motivo.\nHa due funzioni principali:\nAnnunciare che un host o un router √® raggiungibile a tutti gli AS Trovare il percorso pi√π veloce per raggiungere quell‚Äôhost In generale qui vengono utilizzati algoritmi Distance Vector decentralizzati sui singoli AS.\nPer far questo in generale ci teniamo una coppia (prefisso, interfaccia) ossia il prefisso contiene un range di indirizzi, e interfaccia √® l‚Äôinterfaccia del router che possiede quei prefissi.\nAnnuncio presenza In questa fase facciamo distinzione ai messaggi eBGP annunci di messaggi fra router di AS diversi fra di loro e di iBGP annunci fra router degli stessi AS.\nPer dare l‚Äôintuizione generale, quando un nuovo router si connette, manda un messaggio iBGP a tutti i router dell‚ÄôAS, quando il messaggio viene a un router gateway, cos√¨ chiamati i router che hanno connessioni con AS diverse, questa manda una eBGP al router dell‚Äôaltro BGP, con informazioni sulla presenza di x e di come raggiungere x, il processo di ripete finch√© non √® stato recepito da tutte le AS.\nRicerca del percorso pi√π breve (2) Ricordiamo prima che le rotte sono delle coppie (‚Äùpercorso fra sistemi autonomi‚Äù, primo router fuori dall\u0026rsquo;AS attuale).\nUna volta che un sistema autonomo √® a conoscenza di tutte le rotte verso un certo router pu√≤ utilizzare questi due algoritmi:\nHot potato\nQuando provo a uscire pi√π in fretta possibile dall\u0026rsquo;AS attuale. Sfruttando protocolli di intra-routing per sapere dove andare. Selezione delle rotte\nHo delle regole da seguire che eliminano tutte le rotte fino ad avere una singola Preferenza locale (impostata manualmente da un operatore solitamente) Numero minimo di hop minimo costo di intra routing. Identificatori BGP (che non trattiamo) Quindi uno dopo l‚Äôaltro utilizzo quelle per discriminare le routes e scegliere, quindi al passo 2 saranno rimaste tutte le routes con stessa preferenza locale, al numero 3 ho tutte le routes con stesso numero di hops, al passo 4 ho tutte le routes con stessa preferenza locale, stesso numero di hops, e stesso costo interno.\n","permalink":"https://flecart.github.io/notes/control-plane/","summary":"Tipologie di control plane La control plane √® la parte al livello di rete che si occupa di riempire le tabelle di istradamento dei router. In questo caso si possono in generare dividere gli algoritmi in due grandi famiglie\nCentralizzati, anche chiamati algoritmi LS( Link state) perch√© devono conoscere in che modo sono collegati i router fra di loro. Solitamente le SDN ossia software defined networking di cui abbiamo parlato in Data Plane utilizzano questi metodi, c\u0026rsquo;√® un server centralizzato (che per ragioni di tolleranza pu√≤ anche essere distribuito, per√≤ diciamo che √® esterno al router la decisione) Distribuiti in cui nessuno ha informazioni complete sulla rete, ma √® possibile scambiarsi informazioni sui vicini e congiungere cos√¨ al percorso pi√π breve.","title":"Control Plane"},{"content":"Introduzione alla corrente elettrica Considerazioni generali Elettroni liberi nei materiali Ricorda che √® un reticolo cristallino, con un elettrone nell\u0026rsquo;ultimo orbitale poco legato, quindi facilmente ionizzabile, in cui gli elettroni si possono muovere facilmente, e abbiamo che $n \\approx 8.5 \\times 10^{28} \\frac{e^{-}}{m^{3}}$ nel rame Per l\u0026rsquo;argento abbiamo 5.9 con stesso ordine di grandezza.\nVelocit√† media elettroni senza campo elettrico üü© Se √® isotropo, gli elettroni si muovo in generale a caso e la velocit√† media dipendente dall\u0026rsquo;eccitazione termica (in teoria cinetica dei gas √® studiata sta cosa). $$ \\vec{v}_{m} = \\sum_{i = 1} ^{N} \\frac{\\vec{v}_{i}}{N} = 0 $$ Analisi che segue i gas: $$ \\frac{1}{2} m_{e} v^{2} = \\frac{3}{2} k T $$ Con $k = 1.38 \\times 10 ^{-23} J / K$ questo da studiare in altro posto\u0026hellip;\nComunque abbiamo che $$ \\vec{V} = \\sqrt{ \\frac{3kT}{m_{e}} } \\approx 1.16\\times 10^{5} \\frac{m}{s} = 116 \\frac{km}{s} $$ Assumendo che $T = 293K$ con la teoria cinetica dei gas classica. Ma probabilmente questa analisi non √® corretta, perch√© serve la meccanica quantistica per spiegare questo (Fermi-Sommerfield, calcola meglio questa parte), con questa otteniamo che √® ti tipo $1580 \\frac{km}{s}$ che √® un ordine di grandezza pi√π grande.\nIn assenza di campo sembra assistere a urti anelastici in giro, che vanno a caso e si scontrano con atomi molto pi√π pesanti.\nVelocit√† di deriva üü© Proviamo a considerare questo esperimento: Sia $\\vec{v}_{i}$ la velocit√† di un elettrone prima di un urto, e $\\vec{v}_{i + 1}$ la velocit√† dopo un urto. Facciamo finta che in un campo elettrico venga acceso un campo elettrico nell\u0026rsquo;intervallo fra $i$ e $i + 1$, allora sar√† sottoposto a una forza\n$$ \\vec{F} = -e\\vec{E} $$ Allora abbiamo che $$ m \\frac{dv}{dt} = -eE \\implies \\vec{v} = -\\frac{e\\vec{E}}{m} t $$ Allora sappiamo che in ogni urto, si avr√† in generale sempre una componente verso la direzione del campo (questa √® la parte che influenza la velocit√† di deriva che ricordiamo √® molto basso). Questo √® nell\u0026rsquo;ordine di metri all\u0026rsquo;ora.\nAllora provando a riconsiderare la velocit√† media:\n$$ \\vec{v}_{media} = \\frac{1}{N}\\sum \\vec{v}_{i} - \\frac{e\\vec{E}}{m}t = -\\frac{e\\vec{E}}{m}t $$ Dato che la velocit√† che proviene solamente da agitazione termica √® 0, e che ogni singola particella √® soggetta alla stessa forza (si semplifica il numero diciamo per il secondo addendo).\nSimilitudine velocit√† di deriva con caduta üü® Molto brevemente se sottoposti a un campo elettrico, gli elettroni si spostano, ma questa cosa dura molto poco, quindi non era poi utile a utilizzare.\nDopo Alessandro Volta abbiamo un campo elettrico costante all\u0026rsquo;interno di un conduttore. Riusciva a generare una differenza di potenziale costante sui capi dell\u0026rsquo;oggetto. Questo √® pila, fem, generatore. Allora in questo caso la loro velocit√† media √® diversa da 0, iniziano quindi ad urtare gli urti (elastici) gli atomi, molto casuale, ma in media √® sempre accelerato verso la direzione del campo. Questo caso sembra simile a quello di un corpo che fa urti con atomi dell\u0026rsquo;atmosfera, non fanno altro che rallentare il moto di caduta libera in quel caso avevamo $$ \\vec{F} = \\vec{P} = m\\vec{g} - \\beta \\vec{v} \\implies \\vec{V}_{lim} = \\frac{m\\vec{g}}{\\beta} = \\text{constant} $$ Anche in questo caso ci sar√† una velocit√† constante media degli elettroni, quando continuamente cominciano a sbattere.\nNel caso delle correnti si chiama effetto di RESISTENZA ossia l\u0026rsquo;effetto di urti sugli atomi del mezzo conduttore, che rallentano, qui il baricentro delle cariche si sposta all\u0026rsquo;interno del campo, che va in modo costante.\nSuperconduttori üü© Sono materiali in cui non c\u0026rsquo;e resistenza, solitamente leghe di metalli rari (boruro di metallo tipo), in cui vicino allo 0 assoluto non hanno resistenza.\nSemiconduttori üü© Sono dei dielettrici drogati con aggiunta di ioni che siano in grado di liberare carica, come sali disciolti nell\u0026rsquo;acqua. Hanno una densit√† di elettroni molto molto minori rispetto ai conduttori, ma sono sufficienti per condurre La caratteristica principale √® che hanno molti meno elettroni liberi, ma ne hanno alcuni.\nIntroduzione con definizioni Definizione della corrente üü© Intensit√† di corrente $$ i = \\lim_{ \\Delta t \\to 0 } \\frac{\\Delta q}{\\Delta t} = \\frac{dq}{dt} $$ Questo si pu√≤ mettere in relazione con la densit√† di corrente che sar√† spiegata subito dopo, abbiamo che\nGrandezza della corrente üü© $$ [i] = [Q][T]^{-1} = [A] $$ Ossia $1A = 1C / 1s$ che √® una quantit√† enorme.\nDensit√† di corrente Definizione di densit√† di corrente üü© Perch√© la $\\vec{J}$ che √® definita ha stesso verso del campo elettrico. √à la quantit√† di corrente che attraversa una superficie qualunque, quindi √® un flusso.\nDefinito come $$ \\vec{J} = ne \\cdot \\vec{v}_{d} $$ Con la velocit√† di deriva.\nDensit√† di corrente motivazione (!) üü© Vogliamo capire, quanta corrente in un intervallo $dt$ attraversa quella superficie? Tutta la carica che sta a distanza $v_{d}dt$ riesce a passare la superficie. abbiamo quindi che il volume √® $$ d\\tau = v_{d} \\Delta t dS \\cos \\theta $$ in cui $v_{d}\\Delta t$ √® il parallelepipedo, o comunque la zona di spazio delle cariche che passeranno attraverso la superficie. E allora il numero di elettroni l√¨ dentro √® $n_{e}\\cdot \\tau$ Quindi\n$$ dq = qn_{e} \\cdot d\\tau $$ Con questo possiamo ri-caratterizzare la definizione di corrente:\n$$ i = \\lim_{ \\Delta t \\to 0 } \\frac{\\Delta q}{\\Delta t} = ne v_{d} S \\cos \\theta = ne \\vec{v}_{d} \\cdot \\vec{S} = \\vec{J} \\cdot \\vec{S} $$ che √® proprio ci√≤ che abbiamo ragionando per first principles.\nPi√π in generale: $$ i = \\int _{\\Sigma} di = \\int _{\\Sigma} \\vec{J} \\cdot d\\vec{S} $$ E chiamo la nuova grandezza $\\vec{J}$ con lo stesso verso del campo elettrico come densit√† di corrente Di valore $\\frac{[A]}{[m]^{2}}$ Quindi la $i$ √® il flusso all\u0026rsquo;interno di quello, come se fosse acqua in tubo. Dal punto di vista del flusso per√≤ √® impossibile distinguere fra positivi e negativi, perch√© tanto si annullano Questo √® vero considerando questa semplice osservazione:\n$$ \\vec{J} = nqv $$ $$ \\vec{J} = n (-q) (-v) $$ In ogni caso √® sempre positivo, quindi possiamo usare la parte positiva come carica giustificato da questo artificio matematico.\nStima densit√† di corrente (no impo) Supponiamo di avere un tubo di rame per cui abbiamo $n \\approx 8.5 \\times 10^{28} \\frac{e^{-}}{m^{3}}$, $r = 0.8 mm$ con una corrente $i = 15 A$, consideriamo una superficie perpendicolare. Applichiamo i concetti:\n$$ i = \\int _{\\Sigma} \\vec{J} \\cdot \\vec{dS} = J \\int _{\\Sigma} \\, dS = J \\cdot S = J \\pi r^{2} = nev_{d} \\pi r^{2} \\implies v_{d} = \\frac{i}{neS} $$ Sappiamo che $S \\approx 2 \\times 10^{-6} m^{2}$ e sappiamo che $ne$ √® la densit√† volumetrica di carica, dipendente la carica di conduzione $\\rho$ che √® il valore di n che abbiamo descritto sopra. $ne = \\rho = 8.5 \\times 10^{28} \\cdot 1.6 \\times 10^{-19} \\approx 13.6 \\times 10^{9} \\frac{C}{m^{3}}$\nSostituendo sopra abbiamo che $v_{d} \\approx 5 \\times 10^{-4} \\frac{m}{s} = 2\\frac{m}{h}$ Quindi due metri all\u0026rsquo;ora, avendo gli elettroni che si muovono a 1k chilometri a secondo, la velocit√† di deriva √® molt lenta, ed √® corrente. Ma essendo la carica enorme, alla fine ho grandi valori!\nFacendo tutto questo calcolo abbiamo che\nEquazione di continuit√† della densit√† di corrente (!) üü© $$ i = \\int _{\\Sigma} \\vec{J} \\cdot \\vec{S} = -\\frac{dq}{dt} $$ Perch√© sto considerando la carica positiva che sta uscendo, quindi dentro sto perdendo carica.\nRegime stazionario si ha quando $i = 0$, quindi non ho carica che gira, nel senso che stessa carica esce, e stessa carica esce durante il circuito.\nContinuit√† in forma differenziale üü© Questo √® l\u0026rsquo;equivalente di conservazione di carica per la corrente.\nNoi abbiamo per il teorema della divergenza (vedi Divergenza e Circuitazione) che\n$$ \\oint_{\\Sigma} \\vec{J} \\cdot d\\vec{S} = \\int _{V(\\tau)} \\vec{\\nabla} \\cdot \\vec{J} \\, d\\tau $$ Abbiamo anche per definizione di densit√† di flusso che $$ \\frac{dq}{dt} = \\int _{V(\\tau)} \\frac{\\delta\\rho}{\\delta t} \\, d\\tau $$ Quindi ho che $$ \\int _{V(\\tau)} \\frac{\\delta\\rho}{\\delta t} \\, d\\tau = - \\int _{V(\\tau)} \\vec{\\nabla} \\cdot \\vec{J} \\, d\\tau $$ Questa √® l\u0026rsquo;equazione di continuit√† in forma differenziale:\n$$ \\vec{\\nabla} \\cdot \\vec{J} + \\frac{\\delta \\rho}{\\delta t} = 0 $$ ","permalink":"https://flecart.github.io/notes/corrente-elettrica/","summary":"Introduzione alla corrente elettrica Considerazioni generali Elettroni liberi nei materiali Ricorda che √® un reticolo cristallino, con un elettrone nell\u0026rsquo;ultimo orbitale poco legato, quindi facilmente ionizzabile, in cui gli elettroni si possono muovere facilmente, e abbiamo che $n \\approx 8.5 \\times 10^{28} \\frac{e^{-}}{m^{3}}$ nel rame Per l\u0026rsquo;argento abbiamo 5.9 con stesso ordine di grandezza.\nVelocit√† media elettroni senza campo elettrico üü© Se √® isotropo, gli elettroni si muovo in generale a caso e la velocit√† media dipendente dall\u0026rsquo;eccitazione termica (in teoria cinetica dei gas √® studiata sta cosa).","title":"Corrente Elettrica"},{"content":"Gli argomenti della lezione 31 Ottobre sono circa da pagina 164 fino a 185 del mazzoldi.\nLeggi di Ohm Introduzione microscopica üü© Sappiamo che $$ \\vec{J} = -n e \\vec{v}_{d} ne^{2} t \\frac{\\vec{E}}{m} $$ Vedi analisi della velocit√† di deriva col modello del 1900 in Corrente Elettrica.\nDove abbiamo utilizzato la definizione di densit√† di corrente e la velocit√† fra collisioni ed altre Questo √® una motivazione per considerare la densit√† di corrente come se fosse nello stesso verso.\nDa questo notiamo che dipende solamente dal materiale perch√© abbiamo $t$ che √® il tempo che intercorre fra collisione uno e due, mentre $n$ √® la densit√† di elettroni per unit√† di volume, anche questo dipendente dal materiale, poi $e$ ed $m$ sono costanti universali.\nPossiamo rispondere a questo assumendo un parametro dipendente dal mezzo, e la regola diventa allora: $$ \\vec{J} = \\sigma \\vec{E} $$ Dove $\\sigma$ √® il tensore di conducibilit√† elettrica Questo si pu√≤ riscrivere anche in $$ \\vec{E} = \\rho \\vec{J} $$ Dove $\\rho$ √® la resistivit√†, e si ha $\\rho = \\frac{1}{\\sigma}$\nNota: c\u0026rsquo;√® qualcosa con i semiconduttori o cose drogate, che puoi scomporre la parte di sopra con cariche negative o positive, questa cosa √® da approfondire sul libro, perch√© non la ho capita oggi a lezione Vedi 6.7 mazzoldi c\u0026rsquo;√® scritto.\nPotenza e densit√† elettrica üü©\u0026ndash; Chiamiamo $P_{\\tau}$ come la potenza per unit√† di volume, che ricordiamo la derivata del lavoro per il tempo. Ricordando che $P = \\frac{dW}{dt} = \\frac{\\vec{F}ds}{dt} = \\vec{F} \\cdot \\vec{v}$\n$$ P_{\\tau} = nP = n\\vec{F}\\cdot \\vec{v}_{d} = ne\\vec{v}_{d} \\cdot \\vec{E} = \\vec{J} \\cdot \\vec{E} $$ Si pu√≤ riscrivere con la legge di Ohm, e abbiamo che $$ P_{\\tau} = \\vec{J} \\cdot \\vec{E} = \\sigma E^{2} = \\rho J^{2} $$ Resistenza nei fili üü© Consideriamo un cilindro (che sar√† il nostro filo) con superficie $S$ verticale e lunghezza $L$, consideriamo due lati $A$ e un lato $B$ Assumiamo di avere una batteria che crea un campo costante: Allora abbiamo: $$ V_{A} - V_{B} = \\int _{A}^{B}\\vec{E} \\, d\\vec{l} = EL $$ Abbiamo che che $$ I = \\int \\vec{J} \\cdot d\\vec{s} = J S \\implies J = \\frac{I}{S} $$ Ora usiamo la relazione fra campo elettrico e densit√† di corrente, e otteniamo che\n$$ V_{A} - V_{B} = \\rho J L = \\rho L \\frac{I}{S} = \\frac{\\rho L}{S} I = R I \\implies V = RI $$ Chiamo la resistenza questo valore $$ R = \\frac{\\rho L}{S} $$ Perch√© dipende solamente dalla geometria del filo che abbiamo preso. Possiamo definire anche lo stesso concetto per conduttori non lineari (quindi forme a piacere) Per questo si pu√≤ generalizzare con $$ R = \\int _{A}^{B} \\frac{\\rho}{\\Sigma} \\, dl $$ Seguendo quanto c\u0026rsquo;√® in immagine.\nQuando abbiamo ai capi di un conduttore una differenza di un volt, si ottiene una corrente di un ampere, e questo √® l\u0026rsquo;ampere.\nLegge di Ohm della conduzione elettrica üü®++ Vedi mazzoldi pagina 170. $$ \\sigma = \\frac{ne^{2}\\tau_{+}}{m_{+}} + { \\frac{ne^{2}\\tau_{-}}{m_{-}}} $$ √à semplicemente un modello vecchio in cui andiamo a distinguere i portatori di carica negativa e positiva con delle masse diverse (e quindi velocit√† di deriva diversa). Per il resto resta la stessa derivazione di sopra.\nLa legge in question (legge di Ohm della conduzione elettrica) √®: $$ \\vec{J} = \\sigma \\vec{E} $$ Dove la densit√† di corrente √® relazionata al campo elettrico generato solamente da variabili fisiche riguardanti la composizione del metallo e costanti elementari come massa di portatori di carica.\nIl regime stazionario üü© Che ha senso solo in regime stazionario ossia in cui il campo elettrico non varia, ed √® costante. Un altro modo per dirlo √® che in ogni punto passa sempre la stessa corrente quindi il flusso del $\\vec{J}$ √® 0. Ossia $$ \\oint \\vec{J} d\\vec{S} = 0 $$ $$ \\vec{\\nabla} \\cdot \\vec{J} = 0 $$ Resistivit√† e temperatura üü®+ Intuitivamente se aumenta l\u0026rsquo;agitazione termica, aumenta la resistivit√† perch√© c\u0026rsquo;√® pi√π agitazione, quindi pi√π incontri, si ha una legge del tipo:\n$$ \\rho = \\rho_{20}(1 + \\alpha \\Delta T) $$ Il grafico √® piatto fino a un certo punto, poi va su in modo lineare. Nei semiconduttori il coefficiente √® negativo.\nSupponiamo di avere una forma cilindrica a piacere, abbiamo che $$ dP = P_{\\tau} \\Sigma dh \\rho J^{2} \\Sigma dh = \\frac{\\rho i^{2}}{\\Sigma}dh \\implies P = \\int , dP = \\int _{\\tau} \\frac{\\rho i^{2}}{\\Sigma} , dh = I^{2} \\int _{\\tau} \\frac{\\rho}{\\Sigma} , dh = RI^{2} $$ integrando questo riesco a trovare la **potenza dissipata in conduttore** Si pu√≤ fare anche in altro modo partendo con la potenza $$ P = \\frac{dW}{dt} = \\frac{Vdq}{dt} = \\frac{Vidt}{dt} = VI $$\nE si pu√≤ scrivere anche come $$ P = \\frac{V^{2}}{R} $$ Noi paghiamo in $W = RI^{2}t$ che sono ikilowattora. il riscaldamento si chiama effetto Joule.\nLegge di Ohm generalizzata üü© Per ogni ramo dovrei mettere la differenza di potenziale pi√π tutte le forze elettromotrici meno tutte le cadute. Si scrive: $$ V_{A} -V_{B} + \\Sigma_{k}\\varepsilon_{k} = R_{T}i $$ Questa √® un caso generale della legge di Kirchhoff alle maglie descritta dopo\nPotenza per unit√† di volume üü© Vedi Mazzoldi pagina 170 $$ P_{\\tau} = nP = \\rho J^{2} = \\sigma E^{2} $$ Questo si pu√≤ riscrivere come $$ P_{\\tau} = \\vec{J} \\cdot \\vec{E} $$ L\u0026rsquo;abbiamo ricavato anche in Magnetismo parlando di Poynting, in qui possiamo relazionarlo utilizzando le equazioni di Maxwell anche col campo magnetico.\nResistori in serie e parallelo Una cosa da notare √® che saldare assieme √® una altra resistenza non considerata, comunque √® piccola, quindi approssimiamo che ci√≤ che √® filo non la valutiamo, √® trascurabile. Una cosa importante da notare √® che in questi casi √® utile utilizzare resistenze di valore simile altrimenti in serie prevarr√† la resistenza grossa, in quella parallela la resistenza piccola.\nSerie üü© L\u0026rsquo;osservazione principale per spiegare questo √® il fatto che la corrente che passa √® la stessa Abbiamo $V_{A} - V_{B} = iR_{1}$ e $V_{B} - V_{C} = iR_{2}$\nQuindi: $$ iR_{eq} = V_{A} - V_{C} = R_{1}i + R_{2}i $$ Anche la potenza √® semplicemente una cosa lineare!\nParallelo üü© In questo caso la differenza di potenziale √® la stessa dato che $V_{A} - V_{B}$ √® un valore condiviso, in questo caso la corrente si dividere in modo inversamente proporzionale alla resistenza. Quindi abbiamo\nSia $V = V_{A} - V_{B}$, allora $V = i_{1}R_{1}$ e che $V = i_{2}R_{2}$, quindi\n$$ i = \\frac{V}{R_{1}} + \\frac{V}{R_{2}} \\implies \\frac{1}{R_{eq}} = \\frac{1}{R_{1}} + \\frac{1}{R_{2}} $$ Che √® esattamente il contrario di quanto abbiamo visto nei Condensatori nel vuoto per quanto riguarda i circuiti. Riguardo la potenza si comporta bene lo stesso, seguendo questa relazione.\nGeneratori di FEM Introduzione ai generatori FEM Def forza elettromotrice üü© si basano sul concetto introdotto molto tempo fa: $$ \\varepsilon = \\oint_{\\Sigma} \\vec{E} d\\vec{l} $$ Ed √® qualcosa che permette di scorrere la corrente per tanto tempo. Un condensatore non sarebbe buono perch√© si scarica. √à presente nel circuito un campo elettrico che non √® conservativo, diverso rispetto a quello costante che viene sentito all\u0026rsquo;interno del circuito! Dato che applicando le leggi di sopra non c\u0026rsquo;√® la circuitazione nulla.\nQuesto √® un caso in non valgono le leggi conservative che abbiamo studiato per un mese e mezzo, trattate in Campo elettrico nella sezione elettromotrice.\nDerivazione forza elettromotrice üü©- Esiste una *piccola corrente interna del generatore* Allora il nostro generatore produrr√† una forza uguale a $$ W = Pt = i^{2}(R + r) t $$ O in altro modo: $$ W = \\varepsilon q = \\varepsilon i t $$ Questo √® valido perch√© $$ P = \\frac{dU}{dt} = \\frac{dqV}{dt} = iV $$ Quindi abbiamo una relazione sulla potenza spesa da un circuito in relazione alla variazione di differenza di potenziale elettrico. Messi insieme queste due equazioni abbiamo: $$ \\varepsilon = (R + r) i $$ Che notiamo √® lo stesso valore per la differenza di potenziale elettrico per un circuito semplice\nCampo elettrico elettromotore üü®+ Trattato a pagina 181 del Mazzoldi\nDentro ai poli il campo elettrico √® opposto rispetto a quello del campo elettrico esterno! Il capo interno √® il **campo elettrico elettromotore** che non √® conservativo, siamo fuori dall'elettrostatica. $E^{*}$ √® solamente il campo interno. Abbiamo allora\n$$ \\varepsilon = \\oint_{\\vec{E}} d\\vec{l} = \\int _{A}^{B} \\vec{E}_{esterno} \\, d\\vec{l} + \\int _{B}^{A} \\vec{E}_{\\text{interno}}+\\vec{E}_{conservativa} \\, d\\vec{l} $$ Il primo √® elettrostatico, quindi sappiamo che rimane solamente zero (con anche il suo apporto all\u0026rsquo;interno della fem), quindi abbiamo che\n$$ \\varepsilon = \\int _{B}^{A} \\vec{E}_{\\text{interno}} \\, d\\vec{l} $$ Quindi internamente abbiamo un campo $E = E^{*} + E_{el}$ mentre all\u0026rsquo;esterno c\u0026rsquo;√® solamente il campo statico.\nMisura fem üü© Nel caso in cui $i = 0$ √® molto semplice, basta prendere la differenza di potenziale ai due capi: $V_{A} - V_{B} = \\varepsilon$ e sappiamo che il campo elettrico all\u0026rsquo;interno della fem √® 0 Ossia $E^{*} + E_{el} = 0$\nA differenza se c\u0026rsquo;√® corrente avremo dei risultati diversi.\nRamo Definizione üü©\u0026ndash; Una parte di filo, parte del circuito fra pi√π nodi, in cui circola una certa corrente.\nPrima legge di Kirchhoff ai nodi üü© La somma algebrica delle correnti che confluiscono in un nodo √® nullo\nLa corrente che entra √® uguale a quello che esce\n$$ \\Sigma_{k}i_{k} = 0 $$ √à causa del principio di conservazione della carica, espressa alla fine in modo diverso.\nSeconda legge di Kirchhoff alle maglie üü© La somma algebrica delle f.e.m. presenti nei rami della maglia √® uguale alla somma algebrica dei prodotti $R_{k}i_{k}$\n$$ \\Sigma_{k}R_{k}i_{k} = \\Sigma_{k}\\varepsilon_{k} $$ Questo vale solo se il ramo √® chiuso, altrimenti bisogna aggiungere in RHS una componente per la differenza di potenziale in quei due punti.\n","permalink":"https://flecart.github.io/notes/leggi-di-ohm/","summary":"Gli argomenti della lezione 31 Ottobre sono circa da pagina 164 fino a 185 del mazzoldi.\nLeggi di Ohm Introduzione microscopica üü© Sappiamo che $$ \\vec{J} = -n e \\vec{v}_{d} ne^{2} t \\frac{\\vec{E}}{m} $$ Vedi analisi della velocit√† di deriva col modello del 1900 in Corrente Elettrica.\nDove abbiamo utilizzato la definizione di densit√† di corrente e la velocit√† fra collisioni ed altre Questo √® una motivazione per considerare la densit√† di corrente come se fosse nello stesso verso.","title":"Leggi di Ohm"},{"content":"Definizione ed esempi per macchine astratte üü© Una macchina astratta √® un qualunque insieme di algoritmi e strutture di dati che permettono di memorizzare ed eseguire il linguaggio $L$, quindi una macchina astratta esiste per esguire il proprio linguaggio (inteso come insieme finito di istruzioni primitive che riesce ad comprendere e eseguire).\nSi pu√≤ proprio dire che esiste una simbiosi fra macchina e linguaggio. Si potrebbe dire che la macchina fisica √® soltanto una implementazione FISICA di un linguaggio, ossia una macchina che capisce ed esegue quel linguaggio e che sia solamente un caso particolare della macchina astratta.\nQuesta macchina astratta √® costituita da una memoria e un interprete.\nCome si potrebbe intuire una singola macchina ha un singolo linguaggio ma un linguaggio pu√≤ avere infinite macchine che differiscono per strutture di dati utilizzate nell‚Äôimplementazione!\nMacchina di von Neumann (esempio)\nUna delle prime macchine astratte, in questo caso molto semplice, con un unico bus centrale, e tante cose di mezzo.\nLinguaggio macchina Una macchina fisica √® la realizzazione ‚Äúa fili‚Äù di un particolare algoritmo che, sfruttando alcune strutture dati, √® capace di ‚Äúeseguire‚Äù programmi scritti in un certo linguaggio, detto il linguaggio macchina\nIn pratica √® una implementazione ad hardware, come si vedr√† dopo.\nPossiamo dire che il linguaggio di una certa macchina astratta √® il linguaggio compreso da quella macchina!\nInterpreti e compilatori Interprete üü© L‚Äôinterprete per un linguaggio mantiene la SEMANTICA!\nEsempio di interprete per macchina fisica\nciclo FDE, vedi 3.1.3 Central Control Unit , √® l‚Äôinterprete della macchina hardware, ossia\nDecodifica l‚Äôistruzione che deve andare ad eseguire Esegue quanto deve eseguire (in questo caso recupera gli operandi, esegue e stora). In generale possiamo astrarre questo ciclo FDE fisico utilizzando questi passaggi un poco pi√π astratti\nElaborazione dei dati primitivi (primitivi = che riesce a rappresentare direttamente in memoria) (es ALU che elabora bits, dato primitivo della macchina fisica) Controllo sequenza delle operazioni (es. salti, sposta PC in macchina fisica, chiamate di funzione) Controllo trasferimento di dati (es copia, move, copia bits fra registri (nella macchina fisica registri come MDR e MAR). Gestione della memoria (es pointers, allocazione, ma anche cache fra CPU e simili, rilocazione degli indirizzi e bla bla bla) Esempio MA dell‚Äôhardware\nHa un set istruzioni RISC o CISC eseguibili direttamente dalla parte elettronica\nUna osservazione principale da cui deriva dal concetto di macchina astratta √® il concetto di gerarchizzazione fra le macchine astratte. Un primo esempio √® la microprogrammazione\nSlide interpretativa pura\nCompilatore üü© Slide compilativa pura\nVantaggi e svantaggi Inteprete-compilatore üü©- Vantaggi interpretazione\nImplementazione: Di facile realizzazione rispetto-compilatore Memoria: risparmio in quanto non ho un nuovo programma da memorizzare Flessibilit√†: facile cambiare comportamento in esecuzione (eg. per debugging) (mentre compilatore perde anche dati di debug, come la struttura dell‚Äôinformazione) Svantaggi interpretazione\nLentezza, dato che legge ed esegue insieme\nIn breve\nImplementazione Compilativa-interpretativa üü© Se l\u0026rsquo;interprete della macchina intermedia √® sostanzialmente diverso dall\u0026rsquo;in- terprete di $Mo_{Lo}$, diremo che siamo in presenza di un\u0026rsquo;implementazione di tipo interpretativo. Se l\u0026rsquo;interprete della macchina intermedia √® sostanzialmente uguale all\u0026rsquo; in- terprete di $Mo_{Lo}$ (di cui estende alcune funzionalit√†), diremo che siamo in presenza di un\u0026rsquo;implementazione di tipo compilativo. In generale non si utilizza mai una implementazione di tipo interpretativo pura o pura compilativa.\nNella realt√† üü© Non vengono mai utilizzate soluzioni compilative o interpretative pure, ma si utilizzano sempre cose miste (ad esempio per chiamate input e output si utilizzano chiamate a sistema operativo, che sono solitamente interpretate).\nLa compilazione di solito si utilizza per linguaggi molto simili (√® questa la difficolt√† maggiore per la costruzione di un compilatore), e ci sono alcuni passi che sono simulati (quindi non compilativa pura).\nMentre l\u0026rsquo;interpretazione √® molto pi√π facile da scrivere (perch√© di solito ho subito molte funzionalit√† del linguaggio attuale), e capita spesso che il codice iniziale venga compilato in un linguaggio intermedio che sia interpretabile.\nNel pratico esistono linguaggi pi√π interpretati che compilati e anche il contrario, oppure entrambi (esempio pascal).\nSchema di compilazione intermedia classico\nA seconda di quanto il linguaggio della macchina intermedia si avvicini al linguaggio sorgente o macchina possiamo definire le sfumature di linguaggio interpretato o compilato. vedi 20pg libro. (1.2.3)\nImplementazione via Kernel üü®- Facciamo solamente degli accenni a come si fa a creare compilatori o interpretatori\nSi implementa un linguaggio intermedio, il cui compilatore o interprete √® molto facile da fare $H$.\nPoi si costruiranno compilatori o interpreti che avranno come target questo linguaggio, quindi questo linguaggio sembra un linguaggio intermedio quasi.\nSlides\nBoostrapping üü®+ Implementazione delle macchine astratte Esistono 3 modi principali per realizzare l‚Äôimplementazione di una macchina astratta:\nImplementazione tramite Hardware Emulazione tramite micro-programmazione (firmware) Interpretazione tramite Software Hardware üü© L\u0026rsquo;implementazione hardware √® spesso\npoco flessibile, dato che capisce solamente questo linguaggio.\nMolto veloce, dato che esegue a livello hardware le sue istruzioni.\nNota influenza linguaggio astratto in linguaggio hardware\nCi√≤ non toglie che vi siano molti casi in cui la struttura della macchina astratta di un linguaggio di alto livello ha influenzato la realizzaz√¨one di un‚Ä¢architettura hardware, non nel senso di una diretta realizzazione in hardware della macchina astratta, ma nella scelta di operazioni primitive e strutture dati che permettessero una pi√π semplice e efficiente realizzazione dell\u0026rsquo;interprete del linguaggio di alto livello. Questo √® il caso, ad esempio, dell\u0026rsquo;architettura del B5500, un computer degli anni \u0026lsquo;60, influenzata dalla struttura del linguaggio ALGOL.\nMicroprogrammazione üü©- Pu√≤ essere (soprattutto nelle macchine NON-risc) in cui alcune istruzioni non sono esattamente eseguibili dall‚Äôhardware, ma l‚Äôinterprete decodifica l‚Äôistruzione in pi√π istruzioni al livello inferiore, ora queste istruzioni sono eseguibili.\nL‚Äôinterprete del linguaggio di questo livello √® solitamente scritto in un linguaggio di livello inferiore. Di solito la microprogrammazione √® fatta a livello firmware. Questa microprogrammazione √® spesso depositata in una zona di memoria adibita alla sola lettura (ROM).\nCi√≤ permette una flessibilit√† maggiore rispetto all‚Äôimplementazione a livello hardware, e tiene una velocit√† maggiore rispetto all‚Äôimplementazione tramite software (per√≤ resta sempre un linguaggio a basso livello vicino alla macchina).\nMotivo storico della microprogrammazione\nMacchina ospite - software üü© √à possibile implementare tramite software una macchina astratta su una macchina ospite. Ossia una macchina che appunto ospita una macchina astratta con un proprio linguaggio. Solitamente questa macchina con questo linguaggio compila in un linguaggio della macchina ospite, in modo che sia eseguibile. Ecco che da qui si pu√≤ vedere una gerarchizzazione.\nmacchina con Linguaggio di alto livello ‚Üí macchina di altro livello ‚Üí ‚Ä¶ ‚Üí macchina fisica che esegue.\nMoltissima flessibilit√†\nVelocit√† leggermente minore\nLivello di interpretazione/traduzione in pi√π\nEsempio di astrazione solita\n","permalink":"https://flecart.github.io/notes/macchine-astratte/","summary":"Definizione ed esempi per macchine astratte üü© Una macchina astratta √® un qualunque insieme di algoritmi e strutture di dati che permettono di memorizzare ed eseguire il linguaggio $L$, quindi una macchina astratta esiste per esguire il proprio linguaggio (inteso come insieme finito di istruzioni primitive che riesce ad comprendere e eseguire).\nSi pu√≤ proprio dire che esiste una simbiosi fra macchina e linguaggio. Si potrebbe dire che la macchina fisica √® soltanto una implementazione FISICA di un linguaggio, ossia una macchina che capisce ed esegue quel linguaggio e che sia solamente un caso particolare della macchina astratta.","title":"Macchine Astratte"},{"content":"Introduzione alla Randomicit√† Questo √® principalmente basato su (Li \u0026amp; Vit√°nyi 2019) Capito 1.9 Sembra che la nozione di random sia alla fine una cosa molto profonda. Per esempio, un caso lampante che le definizioni non funzionano nel caso di numeri trascendenti √® che catalogano i numeri di $\\pi$ come se fossero casuali, mentre in realt√† possono essere trovati mediante procedimenti precisi. √à una distinzione filosoficamente molto interessante.\nAlla fine sembra ci sia un link molto diretto con la crittografia, si pu√≤ vedere (Stinson 2005).\nMinimum description length come probabilit√† reale Una altra osservazione √® che gli assiomi della probabilit√† sviluppati da Kolmogorov, che puoi trovare inIntroduzione alla probabilita, sono nella teoria molto belli, ma mancano un framework reale su cui possono essere applicati. Un possibile ipotesi √® che il sistema sviluppato da Kolmogorov complexity possa essere alla fine il nostro sistema buono per descrivere le cose randomiche, come programmi che generano la stringa voluta.\nVon Mises all\u0026rsquo;inizio del secolo scorso fu uno dei primi che ha studiato questo problema, lui era un frequentista, quindi credeva nel Central Limit Theorem and Law of Large Numbers. Una nota interessante √® che secondo lui le probabilit√† sono cose osservabili, come fenomeni fisici, come Magnetismo. mentre nel corso fatto di Poisson processes il prof. del MIT ha chiaramente detto come le probabilit√† a differenza di altri fenomeni, non sono osservabili da sole, ma hanno bisogno di altri eventi (misura sulla collezione, non sul singolo evento). Un po\u0026rsquo; questo fa la distinzione fra Entropy e Kolmogorov complexity, in cui una √® su cose che hanno frequenza, l\u0026rsquo;altra definibile anche su singoli oggetti.\nMises‚ÄìWald‚ÄìChurch randomness Questo prende in considerazioni solo cose statistiche: Una sequenza $a_{1}, a_{2}, \\dots$ composta di 0 e 1 √® definita random dal punto di vista di collezione (probabilmente avremo una altra definizione pi√π tardi) se valgono le seguenti condizioni: Sia $f_{n}$ il numero di $1$ nei suoi primi $n$ numeri, allora deve valere che $$ \\lim_{ n \\to \\infty } \\frac{f_{n}}{n} = p, 0\\leq p\\leq 1 $$ Ossia il numero di $1$ deve essere la nostra probabilit√† di interesse\nE che valga la place selection rule, anche conosciuta come law of excluded gambling strategy, ossia per qualunque sotto sequenza della nostra sequenza, valga l stesso il limite, e questo limite deve essere lo stesso valore di $p$. La formalizzazione di questa regola √® un po\u0026rsquo; strana, si vuole avere una funzione computabile parziale $\\phi: \\left\\{ 0, 1 \\right\\}^{n} \\to \\left\\{ 0, 1 \\right\\}$, allora seleziono l\u0026rsquo;indice $n$ se vale $\\phi(a_{1}a_{2}a_{3},\\dots,a_{n-1}) = 1$. Se ho questa propriet√† prendo $a_{n}$ nella mia sequenza, poi vado a considerare la sottosequenza $a_{n_{1}}, a_{n_{2}}, \\dots$ e questa vogliamo che converga ancora a $p$ questo dovrebbe essere una necessit√† abbastanza forte.\nNo analisi a posteriori Una altra nota negativa √® che questa definizione non si pu√≤ verificare a posteriori, perch√© in nessun caso reale abbiamo un limite vero (realt√† finita, non riusciamo ad andare all\u0026rsquo;infinito).\nRandom stocastico vs random regolare Un controesempio classico a questa definizione √® il numero $0,123456789010203040506070809111213141516171819\\dots$ che dovrebbe soddisfare queste propriet√†, ma chiaramente non √® per niente random. Si chiama Champernowne‚Äôs number. Kolmogorov giustifica questo dicendo questo:\n‚ÄúIn everyday language we call random those phenomena where we cannot Ô¨Ånd a regularity allowing us to predict precisely their results. Generally speaking, there is no ground to believe that random phenomena should possess any deÔ¨Å- nite probability. Therefore, we should distinguish between randomness proper (as absence of any regularity) and stochastic randomness (which is the sub- ject of probability theory). There emerges the problem of Ô¨Ånding reasons for the applicability of the mathematical theory of probability to the real world.‚Äù [Kolmogorov]\nMartin-L√∂f randomness Kolmogorov randomness Randomness tests Vorremmo creare un formalismo che ci permetta di descrivere se una certa stringa √® random o meno. Utilizziamo l\u0026rsquo;idea da statistica dell\u0026rsquo;elemento tipico che definiamo come un elemento appartenente alla maggiorit√†. Per qualche motivo che non ho capito vuole definire in modo random la cosa che appartiene al confine.\nDefiniamo un insieme $V = \\mathcal{N} \\times S$, e poi una sequenza di $V_{m} = \\left\\{ x : (m, x) \\in V \\right\\}$ tale per cui $V_{m + 1} \\subseteq V_{m}$ allora puoi definire un livello di confidenza $\\varepsilon$ entro il quale considerarlo random, solitamente questo lo mettiamo come valore a $2^{-m}$ non so per quale motivo, probabilmente per il fatto che definisce una sorta di valore lunghezza. Dato un certo $V_{m}$ $$ \\forall n \\in \\mathbb{N},\\sum_{x} \\left\\{ P(x | l(x) = n) : x \\in V_{m} \\right\\} \\leq \\varepsilon $$ Si generalizza scegliendo degli insiemi $V_{m}$ su cui valutare, sul libro ci sono esempi 2.4.1, 2.4.2. Se vale la cosa di sopra vuol dire che il test √® superato a quel livello. Non so quanto possa essere utile questa def, ma sicuramente √® qualcosa. In pratic\nReferences [1] Li \u0026amp; Vit√°nyi ‚ÄúAn Introduction to Kolmogorov Complexity and Its Applications‚Äù Springer International Publishing 2019\n[2] Stinson ‚ÄúCryptography: Theory and Practice, Third Edition‚Äù CRC Press 2005\n","permalink":"https://flecart.github.io/notes/randomness/","summary":"Introduzione alla Randomicit√† Questo √® principalmente basato su (Li \u0026amp; Vit√°nyi 2019) Capito 1.9 Sembra che la nozione di random sia alla fine una cosa molto profonda. Per esempio, un caso lampante che le definizioni non funzionano nel caso di numeri trascendenti √® che catalogano i numeri di $\\pi$ come se fossero casuali, mentre in realt√† possono essere trovati mediante procedimenti precisi. √à una distinzione filosoficamente molto interessante.\nAlla fine sembra ci sia un link molto diretto con la crittografia, si pu√≤ vedere (Stinson 2005).","title":"Randomness"},{"content":"Backpropagation is perhaps the most important algorithm of the 21th century. It is used everywhere in machine learning. It has also connected to computing marginal distributions. This is the motivation why all machine learning scientists, all data scientists should understand this algorithm very well. An important observation is that this algorithm is linear: the time complexity is the same as the forward pass. Karpathy has a nice resource for this topic.\nA brief history of Backpropagation Backpropagation builds on some backbone ideas in mathematics and computer science.\nBuilding blocks of backpropagation go back a long time\nThe chain rule (Leibniz, 1676; L\u0026rsquo;H√¥pital, 1696) Dynamic Programming (DP, Bellman, 1957) Minimisation of errors through gradient descent (Cauchy 1847, Hadamard, 1908) in the parameter space of complex, nonlinear, differentiable, multi-stage, NN-related systems (Kelley 1960; Bryson, 1961; Bryson and Denham, 1961; Pontryagin et al., 1961, \u0026hellip;)\nExplicit, efficient error backpropagation (BP) in arbitrary, discrete, possibly sparsely connected, NN-like networks apparently was first described in 1970 by Finnish master student Seppo Linnainmaa\nOne of the first NN-specific applications of efficient BP was described by Werbos (1982)\nRumelhart, Hinton and William, 1986 significantly contributed to the popularization of BP for NNs as computers became faster.\nThe problem setting We have a dataset $D$ with input output pairs, we have a loss function $\\mathcal{L}$ and we want to find this $$ \\min_{\\theta} \\sum_{(x, y) \\in \\mathcal{D}} \\mathcal{L}(f(x ; \\theta), y) $$ A common tool is gradient descent but we need to compute the gradients for this algorithm. The astounding fact is that the speed of computing the gradients is same as a forward pass. In optimization classes computing the gradients is given for granted, while the algorithm itself is not trivial.\nIn the old times people would calculate the gradients by hand for every parameter. We need automatic differentiation and we will explain here how does it work.\nAutomatic Differentiation We will use a specific type of automatic differentiation, called reverse-mode. This is not all automatic because we need to know\nHow to decompose the whole function in easy parts Need to know the differential of the simple primitive functions that we use compute the forward pass. We can summarize the whole thing with this theorem: Reverse-mode automatic differentiation can compute the gradient of $f$ in the same time complexity as computing $f$\nThis will be a constructive theorem. First refresh some basis of analysis, see for example Limiti, Derivate, Hopital, Taylor, Peano, Calcolo differenziale, e Jacobians, and some notes about Computer Science i.e. Notazione Asintotica.\nComputational graphs A composite function is a function composed by a series of (nonlinear) functions. Hypergraph is a graph that allows hyperedges, which is a edge that branches into more than one node, or two edges that merge into one.\nFor example the $+$ is a hyper-edge with two parents. We need hyper edges because we need a kind of ordering.\nIt\u0026rsquo;s easy to see that we have an exponential number of paths in the computational graph when computing the derivative, because we need to account all possible paths where it can propagate! $$ \\frac{ \\partial y }{ \\partial x } = \\sum_{p \\in \\mathcal{P(i, j)}} \\prod_{(k, l) \\in p} \\frac{ \\partial z_{l} }{ \\partial z_{k} } $$ Meaning we need to find all paths from $i$ to $j$ and then use the chain rule to compute the gradient contribution for this path. And this algorithm is exponential in time complexity.\nThe forward pass We can write the forward pass of this algorithm in the following way: The backward pass We just to the backward pass, this example is explanatory: You can see that the derivative of $g$ to intermediate point is stored when doing the backpropagation part, and this makes it easy to propagate back step by step.\nBauer Paths TODO: this is a theoretical explanation of why this algorithm is beautiful. But I had not had time to write this down. 5 September 2024.\nTypes of Differentiation There are other types of automatic differentiation. In this section we will briefly present two of the most known aside auto-grad.\nNumerical differentiation This is the form of differentiation that can treat the function actually as a black box, and you can prove bounds about this. You just try to compute the function many times with sensitivity analysis and assume the result is an approximation. The drawback is that this scales on the number of inputs, so it\u0026rsquo;s much more slower. $$ \\frac{ \\partial f(x, y, z) }{ \\partial z } \\approx \\frac{f(x, y, z + h) - f(x, y, z)}{h} $$ Symbolic differentiation This is what is done by engines like wolphram alpha, it computes the real derivative of the expression, but this is inefficient because in some cases there is repeated computation when the same expression compares in different parts. I don\u0026rsquo;t know how exactly is done by automatic differentiation, but probably you as a programmer need to write the function in some specific way.\nSupplementary notes With this notion of gradient flow, one can try to generalize this notion and create works like this (Du et al. 2023). Where the only thing needed is to have a semi-ring and then you can use the same algorithm for some interpretability analysis or similar.\nA simple exercise We will attempt to use backpropagation for the following function so that we can understand a little bit more about this algorithm:\n$$ f(x, y, z, v) = \\exp(y ^{-x} - \\log(z)) + (y - z)^{2} \\cdot \\log(v) $$ Let\u0026rsquo;s try to calculate its symbolic gradient, that is $\\nabla f$, so we need to calculate every partial derivative: $$ \\begin{array} \\\\ \\frac{ \\partial f }{ \\partial x } = \\exp(y^{-x} - \\log(z)) \\cdot e^{-x \\log y} (-\\log y) \\\\ \\frac{ \\partial f }{ \\partial y } = \\exp(y^{-x} - \\log(z)) \\cdot e^{-x \\log y} (-x / y) + 2(y - z) \\log(v) \\\\ \\frac{ \\partial f }{ \\partial z } = \\exp(y^{-x} - \\log(z)) / (-z) - 2(y - z) \\log(v) \\\\ \\frac{ \\partial f }{ \\partial v } = 0 + \\frac{(y - z)^{2}}{v} \\end{array} $$ We can observe that with the symbolic method a lot of computation is repeated in the $\\exp$ thing.\nThis is an example of the computational graph (forward in red and backward in blue, it should be, but it is not checked by others) Check the original excalidraw here.\nAn algorithm for k-th order gradients If we know the computational graph of a certain function, it becomes also easy to compute the k-th gradient. Let\u0026rsquo;s now consider the simple case of computing the hessian. We know that if $m$ is the number of edges in the computational graph, we need $m$ operations for the forward and $m$ operations for the backward, thus giving us $\\mathcal{O}(m)$ complexity for computing the $\\nabla f$. What about $\\nabla^{2}f$? We notice that $$ \\nabla^{2}f = \\begin{bmatrix} \\nabla (e_{1}^{T} \\nabla f(x)) \\\\ \\vdots \\\\ \\nabla (e_{n}^{T} \\nabla f(x)) \\end{bmatrix} $$ This is a handy relation, that could be extended also to the $k-th$ order case. We need $\\mathcal{O(m)}$ operations to compute the gradient for a single component, we just unfold the computation graph (we take the last backward used for the gradient, as another forward component) and do the same for every component. This algorithm runs in $\\mathcal{O(n \\cdot m)}$. It\u0026rsquo;s easy to prove by induction that if we apply the same algorithm, in order to compute the $k$ order algorithm it will take $\\mathcal{O}(n^{k - 1}m)$ time.\nReferences [1] Du et al. ‚ÄúGeneralizing Backpropagation for Gradient-Based Interpretability‚Äù 2023\n","permalink":"https://flecart.github.io/notes/backpropagation/","summary":"Backpropagation is perhaps the most important algorithm of the 21th century. It is used everywhere in machine learning. It has also connected to computing marginal distributions. This is the motivation why all machine learning scientists, all data scientists should understand this algorithm very well. An important observation is that this algorithm is linear: the time complexity is the same as the forward pass. Karpathy has a nice resource for this topic.","title":"Backpropagation"},{"content":"The perceptron Slide summary of working of perceptron\nNote on the bias: it is only useful to move the treshhold where to consider the output to be 1 and where to be 1.\nNow we ask what can be predicted by a perceptron?\nWe can see the update rule of the perceptron:\n$$ \\begin{cases} w = w + \\alpha x \\\\ b = b + \\alpha \\end{cases} $$ Where $$ \\alpha = \\begin{cases} 0 \u0026 \\Theta(x \\theta + b) = y \\\\ -1 \u0026 \\Theta(x \\theta + b) \u003e y \\\\ 1 \u0026 \\Theta(x \\theta + b) \u003c y \\end{cases} $$ Linearly separability necessity Hyperplanes, because that equation is an hyperplane, so we are sure that we can predict an hyperplane, and that it, and it‚Äôs only it. (it‚Äôs predicting wheter it can be above or below that line). So the perceptron is correct only if the data is linearly separable!\n√à molto peculiare che questa struttura predica qualcosa di tanto semplice! √à solamente quella roba, perch√© basta interpretarla come la linea nel piano, si potrebbe forse dire che esiste un isomorfismo fra percettrone e iperpiano in Rn, dove n √® la dimensione di input!\nNovikoff\u0026rsquo;s Theorem Initialized at zero, the perceptron converges in at most $\\lfloor \\gamma^{-2} \\rfloor$ update steps on any $\\gamma-$separable sample.\nNo gradient information needed! We have an error bound on the test! Number of iterations may be much larger (I don\u0026rsquo;t know why) Finite convergence Learning logical operators We can predict NAND operators, because we can create a plane to divide that, but we can‚Äôt say the same of XOR operators.\nPredicting the NAND operator \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Expressiveness of NN/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Expressiveness of NN/Untitled 1\u0026quot;\u0026gt; The XOR problem If we try to predict XOR, we can see that his graph is\nWe can see that a line can‚Äôt be predicting this function, so we can say that perceptron is not COMPLETE. can‚Äôt predict every function, and we can say it‚Äôs not enough expressive.\nBad thing because for example perceptron can‚Äôt be predicting some kind of pixels put in that configuration, if we interpret the preceding image as pixel colors. It‚Äôs useless (gives me no new information) when we have to compare two features, because this implies it is not linear!\nThis problem is historically very important because it has influenced the first AI winter. They were surprised that it couldn\u0026rsquo;t even learn this easy function.\nMultiplayer Perceptron With the preceding idea, if we can compose nands, we can compute every logical cirtuit, this is the same idea behing the completeness of MLP, this can compute everything! (even two layers is enough using this NAND analogy!)\nSlide XOR prediction with MLP\nShallow networks are COMPLETE after this argument. (but with deepness we would need less neurons (maybe exponentially less, with an argument based on CNF exponential explosion when they are not so deep)!, so deepness has some advantages).\nContinous case Can we compute a continous function as precisely as we want with a neural network?\nAt the end yes! Even with single hidden layer NN! The argument is based on step function activation (and the ability of sigmoid or other non linear functions to mimic the step function when we have the right weights). We can add or subtract an arbitrarily small function, with a value as small as we want!\nSee this for more information!\nWe should not be surprised by this expressiveness, also a big table of numbers would be able to aproximate quite well some functions, to an arbitrarily precise fascion.\n","permalink":"https://flecart.github.io/notes/expressiveness-of-nn/","summary":"The perceptron Slide summary of working of perceptron\nNote on the bias: it is only useful to move the treshhold where to consider the output to be 1 and where to be 1.\nNow we ask what can be predicted by a perceptron?\nWe can see the update rule of the perceptron:\n$$ \\begin{cases} w = w + \\alpha x \\\\ b = b + \\alpha \\end{cases} $$ Where $$ \\alpha = \\begin{cases} 0 \u0026 \\Theta(x \\theta + b) = y \\\\ -1 \u0026 \\Theta(x \\theta + b) \u003e y \\\\ 1 \u0026 \\Theta(x \\theta + b) \u003c y \\end{cases} $$ Linearly separability necessity Hyperplanes, because that equation is an hyperplane, so we are sure that we can predict an hyperplane, and that it, and it‚Äôs only it.","title":"Expressiveness of NN"},{"content":"Memoria statica Elementi in memoria statica (4) üü©- Variabili globali Istruzioni macchina Costanti (Variabili locali, paramentri e ritorno di funzione?) Le primi tre elementi descritti di sopra sono sicuramente presenti dopo la fase di compilazione, infatti sono allocati dal compilatore in una zona presente nell‚Äôeseguibile (un esempio √® il READONLY per le stringhe in C).\nQuindi se vogliamo\nAvere funzioni ricorsive Potere allocare e deallocare variabili in modo dinamico Abbiamo bisogno di far uso di Pila o Heap, che riescano a cresere e restringersi in modo dinamico.\nImplementazione di funzioni statiche üü© Si potrebbe anche utilizzare la memoria statica per implementare le funzioni, ma questo ha il fortissimo drawback che non permette la ricorsione in quanto stiamo assumento che in ogni momento di esecuzione la funzione √® chiamata una singola volta. (ho un unico indirizzo di memoria per l\u0026rsquo;indirizzo di ritorno.\nInfatti se chiamassimo in modo ricorsivo questa funzione, perderemmo alcuni valori, come l\u0026rsquo;indirizzo di ritorno, il valore di ritorno precedente, e porterebbe in uno stato invalido.\nOltre a questo avremmo un elevato uso della memoria nel caso in cui il numero di chiamate di funzioni sia in media minore del numero di dichiarazioni di funzione (avremmo un sacco di funzioni inutilizzate).\nSlide di quanto memorizzato per la funzione statica\nFigura 7.1 Gestione della memoria statica. per le funzioni\nSull\u0026rsquo;efficienza\nSolitamente se utilizziamo questo metodo il compilatore solitamente √® in grado di accedere a delle variabili utilizzando un OFFSET senza dover stare a fare risoluzione di nomi simbolici (una volta che abbiamo un frame o RdA, possiamo calcolare la posizione della variabile locale, o parametro attraverso l‚Äôoffset sul base pointer, che qui √® anche chiamato puntatore di RdA). Qualcosina in pi√π forse c\u0026rsquo;√® da fare sulle variabili non locali\nUn altra ottimizzazione √® memorizzare i risultati intermedi su REGISTRI invece che utilizzare la stack. In generale ci sono moltissimi modi di ottimizzare, quindi non andiamo a parlare di questo.\nGestione della pila La pila √® la struttura pi√π comoda per la gestione dei blocchi di codice, che come abbiamo descritto in Nomi e Scope, devono essere LIFO, ossia il blocco pi√π annidato deve finire prima di uscire. Questo √® il motivo per cui possiamo giustificare la gestione della pila. Ecco che si giustifica l\u0026rsquo;idea di creazione della pila di sistema.* Che √® in grado di stabilire le posizioni delle variabili locale, dei parametri attraverso un Offset rispetto al base pointer del frame.\nRecord di attivazione di blocchi (3) üü© Ne abbiamo accennato in 8.4.1 Activation record, parlando anche l√¨ dei record di attivazione, in questo momento andremo a parlarne in modo pi√π approfondito.\nOra parliamo brevemente di record attivazione di blocchi, per questi quando entriamo in un nuovo blocco vogliamo creare spazio per queste cose:\nVariabili intermedie (per storare calcolo intermedio) Variabili locali nuove Catena dinamica che mi dice in quale blocco sono, ed √® utilizzato per eliminare tutto il nuovo spazio allocato in questo blocco. Esempio:\nFigura 7 .3 Allocazione del record di attivazione per I blocchi A e B nell\u0026rsquo;Esempio 7.2.\nRecord di attivazione per funzioni (7) üü© Questi record di attivazione, anche chiamate RdA in modo abbreviato hanno lo stesso concetto per i record di attivazione per i blocchi, ma devono avere qualche informazione in pi√π per indirizzo di ritorno e modo di ritornare la variabile di output.\nTutti i 3 punti per i RdA dei blocchi Catena statica per gli scope (che attualmente non so in che modo venga utilizzata) Indirizzo di ritorno, per il program counter Indirizzo per il Valore di ritorno I parametri di chiamata della funzione. Figura 7.7 Struttura del record di attivazione per una procedura.\nGestione della pila a runtime (!!!) üü®++ In questa parte andiamo a parlare di alcune istruzioni che sono utili per implementare questo sistema di RdA in un linguaggio classico.\nAndiamo a parlare di sequenza di chiamata per l\u0026rsquo;insieme di procedure che deve eseguire il chiamante prima di entrare nel blocco della funzioen chiamata, e una sequenza di ritorno per uscire dal blocco, poi di prologo e epilogo per l‚Äôuscita. ora nel pezzo sequente andiamo a descrivere alcune istruzioni da eseguire per entrare ed uscire da un blocco di RdA di una funzione.\nQuesta divisione √® necessaria perch√© alcune cose possono essere fatte solo dal chiamante, e altre solo dal chiamato!\nChiamata di funzione\nQuesta parte interessa la parte di sequenza di chiamata e il prologo della funzione.\nAllocazione dello spazio necessario nella stack (per parametri, variabili locali, e risultati intermedi, e catene statiche e dinamiche). Passare i parametri (di solito copiati nella nuova RdA) Aggiornare il puntatore di RdA al nuovo, in C di solito √® il base pointer, anche chiamato frame pointer. Salvare quanto necessario dai registri (e.g. il chiamante deve settare l‚Äôindirizzo di ritorno della funzione). Salvare il PC precedente, e settare il nuovo PC. Eseguire codice di inizializzazione specifico del linguaggio, se c\u0026rsquo;√® (anche in C mi pare ci fossero alcune istruzioni, di solito erano nel prologo, come dei push rbp). Ritorno del controllo al programma chiamante\nRipristinare i valori dei registri precedenti. Risettare il PC precedente Copiare il valore di ritorno nell\u0026rsquo;indirizzo giusto ripristinare il puntatore di RdA Deallocare la parte della stack che non utilizziamo pi√π. Esecuzione di codice di uscita. Gestione della heap Per la heap non √® possibile utilizzare stack perch√© in questo caso l\u0026rsquo;utilizzo non soddisfa la propriet√† LIFO tipida della stack, posso freeare una cosa anche prima di una cosa allocata dopo diciamo. Bisogna quindi creare un metodo di gestione dinamica della memoria differente.\nQuesto √® solamente una zona contigua di memoria diversa dalla stack, in cui possiamo allocare e deallocare dinamicamente cose, non c‚Äôentra niente con la struttura di dati!\nDimensione fissa üü© Questa √® l\u0026rsquo;implementazione della heap pi√π semplice, in pratica divido tutto il mio array disponibile in blocchi liberi disponibili.\nQuando vado ad allocare un blocco, vado a togliere questo blocco e metterlo a disposizione al chiamante, a chi ha allocato il blocco, e tolgo questo blocco dai liberi, ora la lista dei liberi punter√† al prossimo blocco libero.\nQuando vado a deallocare il blocco non faccio altro che marcare come libero il blocco, reinserendolo nella lista dei liberi.\nDimensione variabile üü©- Questa √® una soluzione molto pi√π bella per quanto riguarda la soluzione della frammentazione interna, ossia quanta parte di memoria ho ancora inutilizzato, se ho richiesto un blocco (e.g. prima se avevo blocchi da 256, anche se volevo un singolo byte, mi dava un blocco da 256 e gran parte della memoria sarebbe stata sprecata per allocazione dinamica.)\nOra vorrei dividere tutta la memoria che ho secondo una certa logica, solitamente si pu√≤ dividere in due modi di gestire questa cosa:\nHeap dimensione variabile a liste multiple\nQuesta √® una gestione della lista in cui ho pi√π liste di una certa grandezza, i sistemi principali sono a buddy system o fibonacci heap. Discuteremo solamente il primo sistema, il secondo sistema √® molto simile, con una leggera efficienza in pi√π perch√© utilizzando i numeri di fibonacci si ha minore frammentazione interna**.**\nAllora se richiedo un blocco di grandezza n, vado a cercare il blocco libero nella lista di k, con grandezza pi√π grande di n (in buddy system le liste sono tutte di grandezze di potenze di due).\nSe trovo una lista allora alloco e restituisco. Se invece non c\u0026rsquo;√®, allora vado a cercare nelle liste pi√π grosse se c\u0026rsquo;√®. Se lo trovo, allora lo spezzo a met√†, creando i buddies, uno lo aggiungo alla lista dei liberi della lista precedente, l\u0026rsquo;altra la restituisco come blocco allocato.\nin fase di deallocazione vado a controllare se ho dei buddies spezzati, se esistono e sono liberi allora li ricompongo e li metto nella lista grossa originale, altrimenti rimane nella lista libera pi√π piccola!\nHeap a singola lista üü© Anche in questo caso possiamo avere dei problemi di frammentazione quando allochiamo e deallochiamo gli elementi della lista libera che possediamo, ne abbiamo parlato sempre in architettura quando abbiamo accennato alla paginazione: 9.3.2 In memoria: frammentazione esterna. Infatti anche qui possiamo andare a parlare di politiche di first and best FIT. Questi sono entrambi metodi di inserimento lineare, il primo favorisce il tempo, il secondo l‚Äôefficienza in memoria.\nCon questo sistema ho un blocco di spazio UNICO disponibile. Quindi se chiedo n, posso effettivamente allocarti un blocco grosso n, senza nessuna frammentazione. Questo posso continuare finch√© non finisco la memoria. Quando la finisco potrei gestirla in due modi praticamente.\nLista dei liberi\nIn questo caso quando faccio free faccio append di tutti i blocchi deallocati alla lista dei liberi. Posso inserire controlli che quando ho due blocchi contigui nei liberi li compatto assieme. Questo √® la compattazione parziale.\nPoi quando finisco la memoria utilizzo direttamente la lista dei liberi per allocare nuovi blocchi, questo pu√≤ portare al problema di frammentazione interna o esterna. Ci metto in tempo lineare ad allocare. (oppure posso tenere i blocchi ordinati, se utilizzo alberi ordinati allora log(n) per tirare via ed inserire.) Ma in generale ci sono molti modi per gestire questa struttura di dati.\nCompattazione della memoria libera\nQuando finisco la memoria, risolvo la frammentazione esterna rimettendo assieme tutti i blocchi allocati, e poi posso continuare l\u0026rsquo;algoritmo di sopra, allocando esattamente quando mi richiede.\nIl problema di questo metodo √® che difficilmente posso spostare le cose, che √® una precondizione per poter utilizzare questo metodo.\nImplementazione delle regole di scope Abbiamo parlato per la prima volta di scope in Nomi e Scope.\nScope statico üü© Per implementare lo scope statico vogliamo utilizzare la catena statica presente all\u0026rsquo;interno del record di attivazione per poter risalire al blocco giusto.\nIn particolare dividiamo in due casi, il caso in cui il nome chiamato sia presente nell\u0026rsquo;ambiente locale del chiamante, e il caso in cui non lo sia. Questo √® importante perch√© nella fase di sequenza di chiamata dovrebbe essere il lavoro del chiamante per impostare il puntatore di catena statica del chiamato. Notare che in questa sezione utilizziamo nomi come chiamante chiamato, ma il chiamato potrebbe anche essere riferimento al nome di una variabile, il concetto di risalita √® comune.\nCaso presente nell‚Äôambiente locale\nQuesto √® il caso semplice, so che la catena statica deve puntare al chiamante, quindi basta inserirla nel record di attivazione del chiamato!\nCaso non presente\nQuesto √® una cosa leggermente pi√π complessa, se io so che il chiamato √® a livello di annidamento statico n (per tenersi queste informazioni probabilmente si utilizzano informazioni di annidamento e di ambienti locale, che sono comunque presenti nella struttura (statica), e quindi le posso calcolare al momento di compilazione)), e il chiamante a livello di m, devo percorrere k = m - n, livelli per trovare il puntatore di catena statica del chiamato e settarlo puntatore di catena statica del nuovo RdA che mi ritrovo dopo aver risalito di k sulla catena statica.\nQuesto lo so perch√© dato che il chiamato √® esterno, so che √® presente nell‚Äôambiente non locale, quindi non pu√≤ che essere a livello di annidamento inferiore, quindi risalire la catena statica √® corretto.\nChiaramente √® una cosa molto inefficiente fare k dereferenziazioni di pointer per arrivare fino al punto che mi interessa, vedremo subito dopo un metodo per velocizzare questo sistema di scope statico.\nEsempio funzionamento\n!\nFigura 7.14 Catena statica per la struttura precedente e la sequenza di chiamate A, B, C, D, E, C.\nstatico: Il display üü© Vogliamo trovare un metodo pi√π veloce per settare il RdA nel campo della catena statica, tanto che possiamo ridurre a k dereferenziazioni a solamente un numero costante piccolo (2, ma poi il problema precedente non √® brutto dato che il numero di annidamenti per linguaggi reali sta molto piccolo in generale, di solito 3).\nAllora un modo per fare questo √® tenersi un altro array, che contenga un puntatore a seconda del livello di annidamento!\nIdea: tenersi una struttura ausiliaria che viene aggiornato ad ogni cambio di ambiente che contenga il puntatore alla struttura statica di riferimento a ogni livello. (chiaramente il livello massimo si annidamento, va a determinare la lunghezza del display).\nDue accessi, uno nel display per trovare il RdA corretto, l\u0026rsquo;altro accesso per trovare l‚Äôindex della variabile locale corretta.\nFunzionamento generale\nSia m il livello di annidamento del chiamato, allora salvo il valore che c\u0026rsquo;era prima, perch√© il display sar√† comune a tutti i livelli diversi da m.\nQuando ritorno ripristino il vecchio valore, in questo senso il display contiene tutte le RdA statiche a seconda del livello di annidamento, e posso utilizzare questo per capire il puntatore di catena statica.\nEsempio display\n!\nFigura 7.15 Display per la struttura di Figura 7.13 e la sequenza di chiamate A,' B, C, D, E, C.\nScope dinamico: La ricerca per nome üü© Questa √® la soluzione pi√π lenta che potrebbe esistere, che √® quella della ricerca per nome negli RdA, in pratica risalgo i record fin quando non lo trovo o lo trovo.\nUn problema diventa andare ad attivare o disattivare le variabili a seconda del fatto di averlo gi√† visto o meno, e dello scope.\nSlide descrive questo metodo\nScope dinamico lista associazioni üü© Una cosa banale √® tenersi una lista di associazioni globale, chiamata A-list (che viene usato in lisp) che si tiene conto di tutte le associazioni attive. Un entrare e uscire da un certo ambiente non si tratta altro che andare a manipolare questa lista globale di associazioni.\nCercare un valore dell‚Äôassociazione a runtime non sarebbe altro che andare a scorrersi la lista fino a trovare il simbolo di mio interesse, alla prima occorrenza, perch√© quella √® la pi√π recente.\nEntro in nuovo ambiente non faccio altro che aggiungere nella A-list i valori locali\nEsco dall‚Äôambiente non faccio altro che poppare i valori locali\nRicerca simboli non faccio che scorrere tutta la A-list per trovare il valore corretto.\nChiaramente questo runtime non √® che sia molto invitante (nella pratica per√≤ √® sufficiente, anche se non avrei comunque una efficienza di C), quindi vorremmo trovare anche metodi migliori per implementare lo scope dinamico.\nUn altro metodo comparabile per inefficienza √® scorrersi le RdA finch√© non troviamo il simbolo di nostro interesse..\nSvantaggi\nDevo memorizzare i nomi in momento di esecuzione, per poter ritrovare l\u0026rsquo;istanza. Lentezza ad accedere valori globali, che sono in cima alla lista. Entrambi questi svantaggi sono risolti con la CRT esposta nella squenza successiva.\nCentral Referencing environment Table üü© Durante l\u0026rsquo;esecuzione e durante le entrate in ogni ambiente locale, posso tenermi un array di tutti i simboli che posso avere (oppure una hastable). Questo mi permette di accedere al simbolo in tempo costante, e se a tempo di compilazione conosco tutte le variabili a mia disposizione, poi mi basta accedere con offset, e non mi serve sapere il nome originario! (se invece non √® nota bisogna utilizzare la hastable).\nIn questo modo ho un leggere overhead in pi√π per uscire ed entrare in un blocco. Perch√© devo aggiornare l\u0026rsquo;array globale di liste, per√≤ mi implementa in modo semplice questo scope dinamico.\nPer tenere conto dei valori vecchi abbiamo principalmente due metodi:\nTenersi la stack degli elementi nascosti che viene ripristinata quando usciamo dal blocco (quindi √® temporaneo per tenere i vecchi valori) Lista dei vecchi valori, ossia ogni elemento si tiene una lista, che possiamo interpretarla come stack per ogni valore, che contiene i vecchi valori, in testa solamente il valore pi√π recente. Esempio stack elementi nascosti\nEsempio lista vecchi valori\n","permalink":"https://flecart.github.io/notes/gestione-della-memoria/","summary":"Memoria statica Elementi in memoria statica (4) üü©- Variabili globali Istruzioni macchina Costanti (Variabili locali, paramentri e ritorno di funzione?) Le primi tre elementi descritti di sopra sono sicuramente presenti dopo la fase di compilazione, infatti sono allocati dal compilatore in una zona presente nell‚Äôeseguibile (un esempio √® il READONLY per le stringhe in C).\nQuindi se vogliamo\nAvere funzioni ricorsive Potere allocare e deallocare variabili in modo dinamico Abbiamo bisogno di far uso di Pila o Heap, che riescano a cresere e restringersi in modo dinamico.","title":"Gestione della memoria"},{"content":"Introduzione Note filosofiche (non impo) Bisogna in primo momento cercare di definire cosa √® la computazione e cosa √® un computer. Aristotele faceva la distinzione fra propriet√† essenziali e accidentali. Quelle essenziali sono proprie dell\u0026rsquo;oggetto.\nUna sedia pu√≤ essere fatta di legno o di metallo, ma questa propriet√† √® accidentale, ovvero, essa rimane una sedia indipendentemente dal materiale di cui √® fatta.\nSolitamente in matematica si prova ad astrarre (vedi Astrazione sul controllo per nota generale sull\u0026rsquo;astrazione). Per√≤ in questo campo si sono trovati molte concezioni equivalenti. Fino ad arrivare a concepire la tesi di Church-Turing. Il prof. nota che questo √® strano, perch√© in altre discipline si converge in unico modello, mentre qui molte cose sono indifferenti. Questo √® importante per capire come la concezione di Computer Science si √® evoluta (Denning 2010).\nNascita della calcolabilit√†: Turing (curiosit√†) Al tempo si voleva in matematica trovare un formalismo, un fondamenta logico alla matematica che poteva permettere di dimostrare tutto dalle fondamenta. Il contributo principale, e secondo il prof il lavoro pi√π importante in tutta l\u0026rsquo;informatica era (Turing 1937), che definisce cosa significa calcolare un problema. Questo porta al significato di calcolare un problema. √à interessante notare come Turing arriva al suo formalismo. Osserva\nL\u0026rsquo;esecuzione di certe regole Un foglio di carta in cui sono lette e scritte dei simboli L\u0026rsquo;azione eseguita dipende dal simbolo precedente Da queste osservazioni iniziali, hanno astratto i dati (ora simboli binari) e le azioni, un set molti semplice. Osservazione: computazione √® locale. Questo sembra simile quanto dichiarato in (Dehaene 2014) quando si parla che l\u0026rsquo;essere umano √® capace di porre davanti l\u0026rsquo;attenzione della coscienza solamente un solo simbolo alla volta.\nLa macchina di Turing Vedere precedente per capire come √® stata ideata questa macchina di Turing.\nDefinizione matematica üü© √à interessante confrontare questa definizione con Fondamenti teorica#La macchina di turing in cui usiamo un formato leggermente diverso, il formato preciso √® quello precedente fatto a linguaggi. In sto corso usiamo un formalismo pi√π semplice). Nel nostro caso √® una 5-tupla di\n$\\Sigma$, un alfabeto di simboli finiti, con simbolo speciale per cella vuota $Q$ Un insieme di stati $q_{0} \\in Q$ lo stato iniziale $H \\subseteq Q$ l\u0026rsquo;insieme degli stati finali $\\delta$ la funzione di transizione che soddisfa questo: $$ \\delta : (Q - H) \\times \\Sigma \\to Q\\times \\Sigma \\times \\left\\{ \\to, \\leftarrow \\right\\} $$ La differenza √® che in questo caso l\u0026rsquo;alfabeto dell\u0026rsquo;input √® uguale all\u0026rsquo;alfabeto del nastro, ma alla fine cambia poco, basta TODO (capire) secondo me ha sbagliato il prof. tempo fa, perch√© l\u0026rsquo;alfabeto di input non √® mai preso in considerazione nella funzione di transizione boh. Questa sintassi √® pi√π comprensibile della precedente quindi nice.\nCome per tutti i precedenti automi, anche questi hanno una rappresentazione possibile a diagramma: A lezione abbiamo anche visto esempi di macchine che computano moltiplicazione binaria o addizione binaria.\nProblemi di decisione Definizione problemi di decisione üü© Molti problemi si possono codificare attraverso un problema di decisione, ossia un problema in cui abbiamo solamente bisogno di una risposta s√¨ o no. Se riusciamo a codificarlo con il linguaggio delle macchine di Turing, allora forse si pu√≤ far verificare alla macchina. Si vedr√† che molti problemi non vanno.\nSchema di codifica Ossia un dato $\\alpha$ sar√† descritto con $code(\\alpha) \\in \\Sigma^{*}$. Una nota interessante √® che con Kolmogorov complexity abbiamo un dato di lunghezza minima, qui vediamo bene il link molto diretto. Questo ha delle propriet√†:\n√à Iniettiva Vorremmo capire in $\\Sigma^{*}$ quali siano dei codici possibili per un qualche $\\alpha$ nel nostro dominio. Sarebbe carino poter ritrovare $\\alpha$ a partire dal suo codice. Definizione decidibilit√† üü© Dato un certo linguaggio, supponiamo di avere una macchina di Turing come definita di sopra #La macchina di Turing tale per cui abbia due stati finali $\\left\\{ H, N \\right\\}$, allora diciamo che $\\mathcal{M}$ decide $L$ se vale che\nQuando $x \\in L$ allora $\\mathcal{M}$ accetta $x$, ossia finisce su stato $H$ Quando $x \\not\\in L$ allora $\\mathcal{M}$ rigetta $x$, ossia finisce su stato $N$ Diciamo che un linguaggio $L$ √® decidibile se una macchina di Turing lo decide. Ora abbiamo formalizzato il significato di decidibilit√†. Un altro modo per dire che una macchina √® decidibile √® se si ferma per ogni input, questo significa che o finisce in stato accettante o in stato rigettante.\nDefinizione riconoscibilit√†/semidecibilit√† üü© Uguale al precedente, con la differenza che quando la stringa non appartiene al linguaggio diverge.\nDiciamo un linguaggio $L$ √® riconoscibile se una macchina di Turing lo riconosce. Th: Decidibilit√† -\u0026gt; Riconoscibilit√†, √® facile costruire una tale macchina di Turing partendo da una che la decide, possiamo estendere il caso negativo in questo modo: se raggiungo lo stato negativo allora vado in loop infinito a caso.\nDefinizione non riconoscibilit√† Significa che non pu√≤ dire in tempo finito n√© s√¨ n√© no. Quindi √® una cosa ancora pi√π forte rispetto la semidecibilit√†.\nGerarchia di Chomskyüü®+ Vedere Linguaggi liberi e PDA#Classificazione dei linguaggi alla sezione schema generale delle grammatiche. La cosa da ricordare √® che TM √® il modello pi√π generale fra tutti i precedenti modelli di macchine di Turing e automi. Tesi di Church-Turing Enunciato della tesiüü© Se la soluzione di un dato problema pu√≤ essere calcolata attraverso una procedura algoritmica, allora pu√≤ essere calcolata da una macchina di Turing. (Alonzo Church)\nAlonzo proponeva una altra teoria di calcolo, √® stato proponente di lambda calcolo. Quelli che piacevano a Asperti.\nStoricamente sembra vero, perch√© sempre prendendo qualcosa che sembra pi√π espressibile, resta alla fine equivalente a turing.\nEsempi di conseguenze:\nMacchine di Turing \u0026lsquo;migliorate\u0026rsquo; (nondeterministiche, probabilistiche, pi√π nastri‚Ä¶) Macchine a registri Linguaggi di programmazione di alto livello come Python, Java, C, ‚Ä¶ (Codice macchina di) computer classici ‚Ä¢ Computer quantistici Espressibilit√† vs semplicit√† e efficienzaüü© Probabilmente lo abbiamo citato in Fondamenti teorica, il fatto che questo √® solamente una congettura perch√© non √® possibile codificare tutti i formalismi possibili. Parla di espressibilit√† ossia cosa pu√≤ essere calcolato, e se questo vale permette di dire che √® una macchina universale. Infatti non dice nulla su semplicit√† o efficienza dell\u0026rsquo;algoritmo (in questa astrazione non ci interesssa).\nGiustificazione valenza di Turing (non impo) La cosa interessante di queste macchine comunque √® che La macchina di Turing ci permette di formalizzare!\nRigorosit√† di algoritmo. (anche se non mi sembra buono per esprimere certe forme di calcolo (Denning 2010)). Teoremi di calcolabilit√† possono essere estese a qualunque altro formalismo, se vale. Versione rafforzata Questa versione √® una estensione della tesi di Church-Turing in modo che comprenda la parte in Time and Space Complexity.\nOgni modello di calcolo deterministico fisicamente realizzabile pu√≤ essere simulato da una TM (deterministica, su nastro singolo) con overhead al pi√π polinomiale.\nSe ci pensiamo questa versione rafforzata √® simile a quanto dimostrato in Kolmogorov complexity riguardo la complessit√† sulla lunghezza della minima stringa che lo descrive, perch√© l√¨ abbiamo un overhead al massimo costante per tradurre da una macchina all\u0026rsquo;altra.\nChiusura del linguaggio di TM Chiusura sulla decidibilit√†üü© Complemento: √® molto semplice decidere sul complemento perch√© basta scambiare gli stati finali Unione: basta eseguirlo sul multinastro e comparare l\u0026rsquo;input, vedi Estensioni di Turing e altre macchine. Intersezione: Usi de morgan con i precedenti. Concatenazione: stessa dimostrazione per Grammatiche Regolari, concateni le macchine. Star: s√¨\nUn esercizio √® dettagliare la definizione di queste macchina, in modo simile a quanto facevamo al corso di linguaggi.\nNOTA: ricorda di seguire la struttura della dimostrazione. Se no te la conter√† come sbagliata all\u0026rsquo;esame.\nPer la concatenazione √® un po\u0026rsquo; pi√π difficile del previsto, perch√© non so bene dove devo andare a tagliare per la seconda stringa, quindi vado in modo non deterministico sul taglio, cos√¨ in pratica faccio tutte le cose possibili.\nChiusura sulla riconoscibilit√† üü© Complemento: No Unione s√¨, stessa cosa precedente. Intersezione: credo basti concatenarli con reset dell\u0026rsquo;input e dire che si accetta se arriva in fondo Concatenazione: s√¨ Star: dovrebbe s√¨.\nLa non chiusura del complemento la trovi in Halting Theorem and Reducibility. Perch√© si dimostra che $HALT$ e il suo complementare non sono chiusi, e questo basta per il complemento.\nLa macchina di Turing universale Esempi di macchine universali Sono dei programmi in grado di eseguire altri programmi. √à una cosa molto particolare dell\u0026rsquo;informatica questa cosa, permetterebbe per esempio di eseguire un programma su se stesso, una cosa ricorsiva (oroboro quasi). Esempi di macchine universali possono essere\nSistemi operativi Stack di hardware che abbiamo, ognuna universale che esegue una sopra l\u0026rsquo;altra. Anche questo √® stato pensato in (Turing 1937). Una cosa interessante √® che prima di esso, la macchina era pensata per una unica cosa, dopo Turing si pu√≤ usare la stessa macchina per tutti gli algoritmi possibili. Ha introdotto la nozione di programmabilit√†! Utilizzare il dato (l\u0026rsquo;algoritmo) come input di s√© stesso √® stato usato da G√∂del nella sua dimostrazione famosa. Ha codificato teoremi come numeri, permettendo l\u0026rsquo;uso dell\u0026rsquo;aritmetica stessa.\nDescrizione UTMüü© La cosa importante √® che: \u003e La macchina universale deve avere lo stesso comportamento di $\\mathcal{M}$. Se si ferma, si ferma con stesso output, altrimenti non si ferma.\nCostruzione di UTMüü© Codifichiamo simboli che possono apparire nella definizione di $\\delta$, per esempio $\\sigma_{0} = \\cup, \\sigma_{1} = \\leftarrow, \\sigma_{2} = \\to$ e poi in modo simile per ogni simbolo dell\u0026rsquo;alfabeto finito. Poi possiamo codificare in modo unario, per esempio $code(q_{i}) = 111..11$ per $i+1$ volte in totale, in modo simile per $\\sigma_{i}$. Poi uso gli 0 per separare i codici. Quindi posso avere una singola transizione, che √® una tupla di simbolo in input, stato input, stato output, simbolo output, e movimento. Quindi $$ code(t) = code(q_{i})0code(\\sigma_{n})0code(q_{j})0code(\\sigma(m))0code(\\sigma_{o})0 $$ Poi possiamo separarli con uno 0 in pi√π, o contare quanti 0 hai visto. Si pu√≤ encodare anche l\u0026rsquo;input, in modo simile $$ code(\\sigma_{1i}...\\sigma_{in}) = 00code(\\sigma_1)0 code(\\sigma_{12}) 0 ... 0 code(\\sigma_{in}). $$ √à interessante osservare che questo formato $code(\\mathcal{M})code(i)$ √® una cosa decidibile, perch√© √® un formato che si conosce.\nLettura simboli macchina specifica Interpretazione di essa Poi si pu√≤ continuare ad utilizzare il nastro per simulare la macchina stessa. Per cominciare una simulazione della UTM:\nPasso di preparazione: verifica che y = code(‚Ñ≥)code(x) per qualche TM ‚Ñ≥ e input x. Se no, cicla. Se si, allora nastro 1 contiene code(‚Ñ≥)code(x). Vai al passo 2. Sposta code(‚Ñ≥) dal nastro 1 al nastro 2. Ora nastro 1 mostra il contenuto del nastro di ‚Ñ≥ su input x alla configurazione iniziale, in forma codificata. Scrivi code(q0) su nastro 3. Posiziona testina 1 sul primo simbolo di code(x), testina 2 sul primo simbolo di code(‚Ñ≥), and testina tre sul primo simbolo di code(q0). Quindi poi: Cerco la funzione transizione corretta sul nastro 2 che contiene la codifica, poi aggiorno i nastri 1 e 3 a seconda di cosa scrivo, della testina e dello stato corrente in nastro 3.\nReferences [1] Turing ‚ÄúOn Computable Numbers, with an Application to the Entscheidungsproblem‚Äù Proceedings of the London Mathematical Society Vol. s2-42(1), pp. 230\u0026ndash;265 1937\n[2] Denning ‚ÄúUbiquity Symposium \u0026lsquo;What Is Computation?\u0026rsquo;: Opening Statement‚Äù Ubiquity Vol. 2010, pp. 1880066.1880067 2010\n[3] Dehaene ‚ÄúConsciousness and the Brain‚Äù Singapore Books 2014\n","permalink":"https://flecart.github.io/notes/la-macchina-di-turing/","summary":"Introduzione Note filosofiche (non impo) Bisogna in primo momento cercare di definire cosa √® la computazione e cosa √® un computer. Aristotele faceva la distinzione fra propriet√† essenziali e accidentali. Quelle essenziali sono proprie dell\u0026rsquo;oggetto.\nUna sedia pu√≤ essere fatta di legno o di metallo, ma questa propriet√† √® accidentale, ovvero, essa rimane una sedia indipendentemente dal materiale di cui √® fatta.\nSolitamente in matematica si prova ad astrarre (vedi Astrazione sul controllo per nota generale sull\u0026rsquo;astrazione).","title":"La macchina di Turing"},{"content":"Introduzione agli alberi di decisione Setting del problema üü©- Spazio delle ipotesi Definizione spazio ipotesi üü©\u0026mdash; Per spazio delle ipotesi andiamo a considerare l\u0026rsquo;insieme delle funzioni rappresentabili dal nostro modello. Questo implica che l\u0026rsquo;allenamento ricerca l\u0026rsquo;ipotesi ossia la parametrizzazione ottimale del nostro modello, ottimale in quanto minimizza l\u0026rsquo;errore che viene compiuto nel training set.\nL\u0026rsquo;insieme iniziale si pu√≤ anche considerare come inductive bias ossia il restringimento solamente a certe ipotesi e non tutte. Altrimenti abbiamo no free lunch.\nEspressivit√† üü© In pratica ci andiamo a chiedere\nPer quali $h$ esistono modelli di alberi di decisione? Per tutti Dato un albero per una ipotesi $h$, l\u0026rsquo;albero √® unico? Se non √® unico abbiamo una preferenza? Overfitting and underfitting üü© Sono dei fenomeni molto comuni nel campo dell\u0026rsquo;apprendimento statistico. Si potrebbe dire in modo intuitivo che:\nUnderfitting quando il modello non √® ancora stato allenato, quindi possiede un bias molto alto per quanto riguarda la precisione del modello\nOverfitting quando il modello √® stato allenato troppo, tanto che ha imparato del rumore presente sul training set, questo non permette la generalizzazione sul test set.\nSi potrebbe parlare in modo pi√π formale di overfitting come il verificarsi allo stesso tempo di due condizioni $$ error_{D}(h) \u003e error_{D}(h') $$ $$ error_{train}(h) \u003c error_{train}(h') $$ Ossia ho un errore basso nel training set, ma non riesco a generalizzare sul validation set.\n### Esempio di struttura albero decisionale Vorremmo cercare di modellare alcuni modelli di regressione o classificazione seguendo un albero di decisione come in figura Il problema sarebbe capire come creare l\u0026rsquo;albero in automatico, a seconda di un training set labellato: Input:\n$$ coppie di training set. Output Un ipotesi $h$ che √® un albero di decisione. Entropia Definizione entropia üü© $$ H(X) = - \\sum_{i=1}^{n}P(X = i) \\log_{2}P(X=i) $$ In cui se sono uguali hanno entropia massima, segue il grafico di questo genere\nC\u0026rsquo;√® un apparato teorico non da poco per questo, perch√© √® stato utilizzato molto nella teoria della comunicazione. Una cosa che riguarda la probabilit√† del singolo dato, se √® sempre uguale ho entropia pi√π alta.\nInformation Gain üü®+ Una definizione che segue l\u0026rsquo;intuizione √® che la probabilit√† dell\u0026rsquo;avvenimento influenzi il concetto di informazione, ossia se un evento compare sempre (tipo il sole che sorge), non ha molto informazione, perch√© √® sempre uguale.\nProbabilit√† 1 ha zero informazione given two independent events with probabilities p1 and p2 their joint probability is p1p2 but the information acquired is the sum of the informations of the two independent events, so $I(p_{1}p_{2}) = I(p_{1}) + I(p_{2})$ Le due propreit√† di sopra giustificano il fatto di definire in modo abbastanza naturale che $$ I(p) = -\\log(p) $$ Propriet√† importanti (4) üü®++ Algoritmo di costruzione dell\u0026rsquo;albero Descrizione algoritmo di costruzione üü©- Bisogna introdurre il concetto di entropia per poter discriminare, vorremmo cercare il punto che diminuisca di pi√π l\u0026rsquo;entropia.\nRiduzione overfitting Pruning dell\u0026rsquo;albero (2) üü©\u0026ndash; Posso fare early stopping, ossia smetto di alllenarmi (ossia di creare altre branch), dopo che ne ho create un tot. Posso fare post-pruning, ossia dopo che ho creato tutto l\u0026rsquo;albero (probabilmente facendo overfitting), mi metto ad eliminare alcune branches di poco conto. Questo si utilizza il validation set per vedere in che modo potare pu√≤ influenzare la performance su questo (se migliora allora di fa, lo facciamo in modo greedy) Index di Impurit√† di Gini üü©- Questo √® un indice che √® stato usato in economia per studiare la disuguaglianza fra le persone, nel nostro caso lo utilizziamo per capire in che modo fare branching con l\u0026rsquo;albero di decisione\nGini‚Äôs impurity measures the probability that a generic element get misclassified according to the current classification (an alternative to entropy).\n$$ I_{G}(F) = \\sum_{i=1}^{m} f_{i}(1 - f_{i}) = \\sum_{i=1}^{m} (f_{i} - f_{i}^{2}) = 1 - \\sum_{i= 1}^{m}f_{i}^{2} $$ Dove $f_{i}$ √® la frazione del dataset che appartiene ad $i$ Questo √® quindi un modo alternativo per fare split ad un nodo dell\u0026rsquo;albero.\nRandom forests Vengono costruiti molti alberi e si utilizzano le loro decisioni assieme per avere un risultato finale, questo √® una tecnica ensemble perch√© vengono messe assieme conoscenze di tutti gli alberi.\nEnsemble models üü© Ensemble techniques exploits the principle that a large number of relatively uncorrelated models (e.g. trees) operating as a committee will typically outperform any of the individual constituent models.\nMetodi di differenziazione (2) üü©\u0026ndash; Chiaramente non abbiamo molto vantaggio se tutti gli alberi che vengono cos√¨ creati sono tutti uguali fra di loro, √® quindi utile utilizzare tecniche che li differenzino fra di loro:\nBagging uso input random. Feature randomness (uso subset di features per predire) Conclusioni Aspetti positivi degli alberi di decisione (4) üü©- Molto veloci Non hanno bisogno di grandi quantit√† di dati Facile capire perch√© viene fatto la decisione (posso plottare le immagini) Adatti sia a problemi continui che discreti Aspetti negativi (3) üü©- Molto facile andare in overfitting Esistono molti alberi per lo stesso dataset (instabile con le features e struttura dell\u0026rsquo;albero) Possono diventare molto unbalanced se c\u0026rsquo;√® qualche predittore forte (andare a guardare questo). Side notes (altro) ","permalink":"https://flecart.github.io/notes/alberi-di-decisione/","summary":"Introduzione agli alberi di decisione Setting del problema üü©- Spazio delle ipotesi Definizione spazio ipotesi üü©\u0026mdash; Per spazio delle ipotesi andiamo a considerare l\u0026rsquo;insieme delle funzioni rappresentabili dal nostro modello. Questo implica che l\u0026rsquo;allenamento ricerca l\u0026rsquo;ipotesi ossia la parametrizzazione ottimale del nostro modello, ottimale in quanto minimizza l\u0026rsquo;errore che viene compiuto nel training set.\nL\u0026rsquo;insieme iniziale si pu√≤ anche considerare come inductive bias ossia il restringimento solamente a certe ipotesi e non tutte.","title":"Alberi di decisione"},{"content":"Basi di dati Cosa √® un database? (2) üü© Si potrebbe intendere come un insieme di dati strutturato, utili per certi obiettivi di enterprise, aziende pubbliche o simili (uno delle necessit√† che la rivoluzione informatica ha pi√π contribuito diciamo.)\nUn altro significato pi√π importante √®\nUn insieme di dati gestito da un Database Management System\nTristemente con questa definizione anche excel √® un DBMS\u0026hellip;\nSolitamente sono utilizzati per gestire grandi quantit√† di dati.\nIl sistema informativo üü© Componente di una istituzione\nSi potrebbe dire che sia una base utile alle organizzazioni per gestire l\u0026rsquo;informazione, questi sistemi erano gi√† presenti molto prima rispetto alla creazione dei sistemi dell\u0026rsquo;informazione moderni, per esempio registri e tavole venivano utilizzate in questo senso, ossia come sistemi per registrare alcuni strumenti utili per il nostro enterprise. Quindi storicamente c\u0026rsquo;√® molta necessit√†, √® solamente con la rivoluzione storica che abbiamo nuove cose.\nNecessit√† dell\u0026rsquo;informazione üü®++ Ci sono alcuni aspetti che possiamo dire molto comuni quando mettiamo mano ai dati e sono tipo:\nCollezionare i dati Filtrare i dati e memorizzarli elaborare i dati Restituire e visualizzare i dati Database Management System Caratteristiche generali dei DBMS (5) üü© Le slides affermano che i dati in questione devono essere:\nGrandi dimensioni (righe) Persistenti Condivisi efficienti efficaci Io aggiungerei anche strutturati perch√© se sono dati non strutturati √® difficile che vengano messi in un DBMS. Comunque commentiamo ora pezzo per pezzo il motivo per cui abbiamo bisogno di queste caratteristiche per i DBMS:\nGrandi dimensioni perch√© vogliamo che sia efficiente anche su questi (soprattutto su questi, quando tengono dati di tante cose rimanendo comunque organizzati diciamo) Terabyte e terabyte di data secondo le slides (500 TB per dati scientifici :O) Persistenti perch√© non avremmo bisogno di un database se tutto rimanesse in RAM\u0026hellip; I dati sono pi√π longevi dei computer che li ospitano diciamo. Cos√¨ abbiamo un unico punto di sicurezza in cui molte persone possono affidarsi per avere una fonte di verit√† diciamo (questo forse ne parlava in the manga introduction to databases) Efficienti si parla da solo, dato che vogliamo che sia effettivo a prendere i dati non vorremmo aspettare tanto Efficace perch√© deve fare il suo lavoro di renderci la vita pi√π facile nella gestione dei documenti e dei dati :) Altro Comparazione con File System üü©\u0026ndash; Sembra che anche i file-system siano in grado di svolgere il lavoro di DBMS, infatti potremmo vedere il DBMS come un file-system allargato, con pi√π funzionalit√†. Infatti possiamo anche in questo caso tenere un file-system distribuito, e affidarci ad esso per\ngestire una grandissima mole di dati (perdiamo sulle garanzie di integrit√†), gestione dell\u0026rsquo;accesso (e quindi di privacy), pone interfaccia per accedere velocemente al supporto fisico sottostante. Diciamo che fa bene il suo lavoro. (efficace) In un certo senso si pu√≤ paragonare a tenere i dati su excel, funziona, per√≤ non √® il massimo, non si hanno garanzie che si vorrebbero avere, i check automatizzati diciamo.\nCol database abbiamo\ngaranzie in pi√π su uniformit√† e relazione dei dati con un Data Model velocit√† di accesso a query classiche Non limitazione ad aprire e chiudere file (prende o l\u0026rsquo;intero file o niente col file system) Architettura ANSI/SPARC (3) üü© Schema logico descrive come dovrebbero essere i dati ossia la struttura logica dei dati Schema interno come sono rappresentati i dati, potremmo dire l\u0026rsquo;implementazione del livello logico dei dati. Schema esterno che a volte √® chiamata anche view, ossia come gli utenti hanno bisogno di vedere i dati La cosa interessante di questa parte, √® che vorremmo che i dati siano indipendenti (sia il fisico dal logico, sia il logico dall\u0026rsquo;esterno) rispetto a come sono rappresentati, una idea molto importante introdotta per la prima volta da (Codd 1970).\nCredo anche sia la stessa idea, che sta alla base del processo di astrazioni comunissimo in informatica √® l\u0026rsquo;idea di interfaccia, un qualcosa che espone solamente la parte logica di quale sar√† l\u0026rsquo;effetto dell\u0026rsquo;operazione, ma ne nascone le operazioni effettive, che chiamiamo interne. Per i database forse questa cosa era nuova.\nTipologie di modelli logici (5) üü®+ Nel tempo sono stati creati molti modelli possibili dello strato logico del database Una lista di modelli presenti √®\nGerarchici Grafo (network based) relazionali Object Oriented XML-based Quello studiato in questo corso √® il modello relazionale di database management\nProblemi classici (2) üü®\u0026ndash; Ridondanza e coerenza per questo Sync dei valori che possono essere presenti in macchine anche molto distanti Availability √à un grande problema se un database va gi√π\u0026hellip; Privacy e gestione dei permessi, perch√© dato che sono shared, non vogliamo per√≤ che uno possa accedere a dati di altri. TODO Caratteristiche dei dati (3) vogliamo che i dati all\u0026rsquo;interno dei DBMS soddisfino certe desiderata al fine di garantire il buon servizio:\nPrivacy Reliability Availability E parte di queste desiderata sono le stesse che abbiamo anche richiesto all\u0026rsquo;interno di Sicurezza OS quando abbiamo parlato degli attacchi che era possibile fare ad un sistema informativo. Per gestire la reliability ossia la tolleranza a fallimenti hardware e software, e la possibilit√† di garantire anche la ridondanza si utilizzano le transazioni\nTransactions (3) (non fare) Questa parte √® trattata leggermente meglio quando andiamo a parlare di SQL transactions in Structured Query Language Anche in Advanced SQL\nAtomiche Concorrenti Permanenti Le facciamo per benino in The Database Management System\nPros and cons Pros (5) üü®+ √à necessario, molto pi√π efficiente nel caso quella stessa informazione venga utilizzata anche da dipartimenti diversi √à chiara la comunicazione e la struttura, che √® sempre una fonte di verit√† vabb√© ovvio Questo √® molto importante, ci sono stati un sacco di danni che ci sono stati a causa di inconsistenza, come nei file di excel Questo √® ancora una delle radici presenti nell\u0026rsquo;informatica, l\u0026rsquo;indipendenza del software dall\u0026rsquo;implementazione concreta dei dati, oppure dalla rappresentazione hardware. Cons (2) üü© Io aggiungerei anche il livello di astrazione (quindi magari tempo di implementazione delle cose) in pi√π, che poi si riguadagna indietro con la facilit√† di gestione dell\u0026rsquo;infrastruttura\nC\u0026rsquo;√® un grande overhead per mettere su un DBMS questo √® ovvio come con. Basi di dati attive Finora i database \u0026ldquo;passivi\u0026rdquo; non fanno niente finch√© non c\u0026rsquo;√® interazione con query o richiesta.\nIl comportamento reattivo üü© In sql ci sono dei checks a reference di integrit√†, che vengono attivati su update o deletions. La capacit√† di reagire ad eventi √® importante.\nEvent-Condition-Action (ECA) üü© Questo √® il costrutto principale dei database attivi, devono essere in grado di reagire ad eventi in modo reattivo.\nQuindi possiamo dire che il database √® attivo quando esistono dei triggers, regole che vengono eseguite in un certo momento.\nOracle √® stato uno dei primi che si √® accorto di questa necessit√† (infatti √® anche l\u0026rsquo;azienda che ha fatto questo, e l\u0026rsquo;ha chiamato stored procedures) Per√≤ aspetti negativi sono:\nLinguaggio procedurale (impendance mismatch con SQL) Non standarizzato Trigger, granularit√† e modalit√† üü© Esiste un comando SQL, nella DDL, che mi permette di definire in modo esplicito i trigger.\nGranularit√†:\nTupla (attivazione per ogni tupla) Operazione, a singola operazione Modalit√†:\nImmediato Dilazionato. Questi si possono rappresentare anche con semantica differente. References [1] Codd ‚ÄúA Relational Model of Data for Large Shared Data Banks‚Äù Communications of the ACM Vol. 13(6), pp. 377\u0026ndash;387 1970\n","permalink":"https://flecart.github.io/notes/introduction-to-data-bases/","summary":"Basi di dati Cosa √® un database? (2) üü© Si potrebbe intendere come un insieme di dati strutturato, utili per certi obiettivi di enterprise, aziende pubbliche o simili (uno delle necessit√† che la rivoluzione informatica ha pi√π contribuito diciamo.)\nUn altro significato pi√π importante √®\nUn insieme di dati gestito da un Database Management System\nTristemente con questa definizione anche excel √® un DBMS\u0026hellip;\nSolitamente sono utilizzati per gestire grandi quantit√† di dati.","title":"Introduction to data-bases"},{"content":"Questa nota raccoglie note introduttive al corso di reti dei calcolatori fatto all\u0026rsquo;universit√† di Bologna.\n0.1.1 Definizione di rete di calcolatori (2) üü©- I requisiti sono principalmente 2\nEssere autonomi nel calcolo (capacit√† di eseguire dei programmi) Essere interconnessi (capacit√† di ricevere ed inviare dei segnali) Gli scopi sono principalmente per la comunicazione fra utenti o calcolatori.\nNon-esempi\nRete telefonica, non sono autonomi Rete televisiva Esempi\nSmartphones con wi-fi WWW E-mail Una rete di calcolatori √® un insieme di dispositivi autonomi, cio√® in grado di eseguire e svolgere autonomamente i compiti programmati di calcolo e di comunicazione, interconnessi tra loro da supporti fisici alla trasmissione di segnali. Non sono considerate reti di calcolatori, ad esempio, n√© le reti di comunicazione telefonica (i cui terminali telefonici non sono dispositivi autonomi), n√© le reti di distribuzione televisiva (in quanto i televisori non sono dispositivi autonomi in grado di comunicare informazione). Nel prosieguo della presentazione, con il generico termine di ‚Äúrete‚Äù o ‚Äúrete di comunicazione‚Äù intenderemo implicitamente solo le reti di calcolatori elettronici. Con l‚Äôavvento dei calcolatori elettronici, e con la loro diffusione tra comunit√† sempre pi√π grandi di utenti, √® emersa l‚Äôesigenza e l‚Äôutilit√† di fornire un supporto alla comunicazione tra utenti, attraverso l‚Äôuso del calcolatore, supportando innovativi servizi di comunicazione per l‚Äôutente, quali ad esempio il World Wide Web e la posta elettronica. In tempi pi√π recenti si sono sviluppati ulteriormente i sistemi di rete includendo Internet of Things (IoT), reti senza fili (Wireless), ecc. Le necessit√† di comunicare e condividere informazione sono tra i principali motivi che favoriscono la nascita e lo sviluppo di reti di calcolatori. La fruizione dell‚Äôinformazione contenuta in questo corso rappresenta un esempio. Un ulteriore aspetto che ha favorito la nascita e la diffusione delle reti di calcolatori √® legato alla possibilit√† di condividere dispositivi costosi, altrimenti sotto-utilizzati, come ad esempio stampanti o capienti dispositivi di memorizzazione dei dati, e la possibilit√† di accedere e lavorare sui dati di un calcolatore, senza doversi spostare fisicamente sul calcolatore stesso. Una rete di calcolatori pu√≤ consentire di eseguire calcoli complessi in parallelo e in maniera distribuita, aumentando le prestazioni per l‚Äôottenimento dei risultati. In tal senso, le reti rendono possibile la scalabilit√† dei sistemi di comunicazione e di calcolo: il numero di dispositivi usati, e l‚Äôinvestimento relativo, possono essere dimensionati dinamicamente in funzione delle richieste di servizio. In tempi recenti, le reti sono utilizzate in particolare per supportare la comunicazione utente, secondo svariate forme e applicazioni, oppure per supportare la comunicazione diretta tra dispositivi pervasivi e mobili (es. Internet of Things, Wireless Networks), ecc\n0.1.2 Classificazione delle reti (5 principali) üü© Una prima classificazione delle reti di calcolatori si basa sulla dimensione delle reti stesse. Non esiste in generale un criterio ben definito per tale classificazione, ma ci si basa su considerazioni generali, riguardanti la dimensione dell‚Äôarea di copertura geografica della rete, ovvero l‚Äôarea entro la quale possano esistere dispositivi connessi.\nLe reti personali (PAN) sono reti di comunicazione per connettere dispositivi vicini tra loro, ad esempio sul corpo di una persona o entro una stanza. Un esempio potrebbe essere dato dalla connessione di due dispositivi indossabili, sensori e smartphone, oppure calcolatori, una stampante e un agenda elettronica. Le reti personali sono di solito finanziate e gestite dal singolo utente che le utilizza.\nLe reti locali (LAN) sono molto spesso reti gestite e mantenute da organizzazioni, universit√†, enti o aziende. Esse connettono calcolatori nel raggio di qualche centinaio di metri, ad esempio su interi edifici o campus universitari. Ad esempio, la rete delle aule del Dipartimento.\nLe reti metropolitane (MAN) hanno connessioni in un raggio dell‚Äôordine delle decine di chilometri, e possono connettere intere aree urbane. Esse sono mantenute e gestite da fornitori di servizi di comunicazione (provider) e gestori di servizi telefonici.\nLe reti geografiche (WAN) sono reti in grado di coprire distanze internazionali e addirittura planetarie. Tali reti sono mantenute e gestite da enti nazionali e internazionali, oppure da grossi enti o gestori delle comunicazioni. L‚Äôorganizzazione e la struttura di tali reti pu√≤ essere molto complessa, e pu√≤ risultare composta da diverse parti, e da diverse tecnologie, eterogenee e integrate (ad esempio, molte reti collegate tra loro con tecnologie cablate o in fibra, fino a reti basate su comunicazione satellitare senza fili).\nInternet (inter-networking, ossia comunicazione di rete fra rete diverse) √® una rete di reti, composta da molte reti diverse connesse tra loro, integrate grazie a un insieme di regole comuni: i protocolli della rete Internet.\nAlcuni esempi PAN Anche reti all‚Äôinterno del corpo stesso! (es. per autenticazione). (qualcosa che passa da un pezzo del corpo a un altro pezzo). (molto piccola) LAN Alma-wifi (wireless) ‚Üí WLAN MAN Alma-wifi, perch√© ce in molte parti della citt√† (diffusa con ripetitori, che all‚Äôinsieme hanno una rete metropolitana). NOTA: MAN (e pi√π in generale le reti) si possono espandere componendo reti pi√π piccole NOTA: la grandezza della rete influenza i problemi che la rete deve risolvere. WAN Internet C‚Äô√® un problema di comunicazione, come connettere tutti i calcolatori del mondo??? 0.1.3 Evoluzione e costi della rete (storia, non richiesta) üü® Slide\nLo sviluppo delle reti di calcolatori, che ha permesso la nascita di Internet, non sarebbe stato possibile senza una distribuzione dei costi di realizzazione e gestione delle infrastrutture tra molte entit√†.\nUn p√≤ di storia Storicamente, la prima rete di Internet nasce da un esperimento nel 1969, connettendo solo 4 calcolatori di 4 universit√† americane (con linee di telefoni!).\nDa allora molte entit√† hanno dato il loro contributo per lo sviluppo e la diffusione delle reti di calcolatori. All‚Äôinizio del 2003 Internet contava oltre 172 milioni di calcolatori (fonte Internet Software Consortium). Gi√† nel 2017 si parla di oltre 4 miliardi di dispositivi connessi (anche se non tutti connessi allo stesso momento). Entro 5-7 anni si raggiungeranno i 60 miliardi di dispositivi connessi, realizzando l‚Äôavvento dell‚ÄôInternet of Things.\nPoi si √® sviluppata (dal primo esperimento, si racconta che HELL sia stato il primo messaggio, poi c\u0026rsquo;√® stato un system crash) grazie ad ingesti investimenti militari, poi aziende private. Queste aziende private poi rivendono al cliente finale.\nSui costi Per quello che riguarda i costi, la realizzazione, mantenimento e gestione dell‚Äôinfrastruttura di una rete molto ampia richiede investimenti economici elevati, che possono essere maggiori a seconda del grado di avanzamento delle tecnologie e delle prestazioni richieste.\nCosti MAN e WAN Alcune delle infrastrutture principali delle reti estese MAN e WAN (e di Internet) hanno costi affrontabili solo attraverso un consistente investimento e una pianificazione delle ricadute commerciali da parte di consorzi o fornitori di servizi di comunicazione nazionali e multinazionali.\nCosti LAN Tuttavia, la maggior percentuale del complesso delle infrastrutture di rete che compongono Internet risultano essere mantenute e gestite capillarmente da piccoli gestori e piccoli gruppi, con investimenti relativamente modesti per la realizzazione di piccole reti locali (LAN). L‚Äôintegrazione di un insieme molto vasto di reti grandi e soprattutto piccole reti locali, eterogenee e distribuite su tutto il pianeta, ha permesso la crescita incrementale, il successo commerciale e la esplosiva diffusione delle reti su scala globale, fino a Internet.\nCosti utente finale L‚Äôutente delle reti paga tipicamente per i servizi di trasmissione offerti dalle reti, con tariffe che possono essere basate sul tempo di collegamento, sulla quantit√† di dati.\n0.1.4 Valutazione prestazioni della rete (2) üü© Per ci√≤ che riguarda le prestazioni delle reti di calcolatori, l‚Äôutente √® principalmente interessato a due indici: la capacit√† di trasmissione (impropriamente detta velocit√† della rete) e il ritardo del collegamento di rete.\nLa capacit√† di trasmissione si misura sulla base della quantit√† di dati che √® possibile comunicare in un secondo mediante la rete. I dati digitali del calcolatore si misurano in bit o in byte (gruppi di 8 bit), e di conseguenza l‚Äôunit√† di misura usata tipicamente per misurare la capacit√† di trasmissione dei dati di una rete √® il numero di bit oppure di byte trasmessi al secondo (bit/sec, byte/sec). Spesso si usano i prefissi Kilo (K) per le migliaia, Mega (M) per i milioni e Giga (G) per i miliardi di bit o byte al secondo, Tera (T) per le migliaia di miliardi, ecc. (esempio Kbit/sec, Kbyte/sec). Il ritardo del collegamento di rete indica il tempo necessario ai dati per transitare dal mittente al destinatario finale sulla rete. I fattori del ritardo (non solo questi): la distanza fisica del collegamento i tempi necessari alla gestione delle regole dei processi di comunicazione in rete (protocolli) che i dati devono subire durante il loro tragitto. (che pu√≤ essere anche fisico letterale: eg. aereo o furgone, invece che fibra o reti, questo √® un protocollo üôÇ). Variazione del ritardo (es. coda per furgoni, congestione delle linee e simili) Jitter (su quale sia meglio, dipende sempre dagli utilizzi ‚Üí Streaming? o semplice scaricare? a seconda di quanto ci serve √® meglio la rete blu o rossa) Ovviamente sono da preferire reti dotate di basso ritardo, in quanto ci√≤ favorisce la rapidit√† e l‚Äôinterattivit√† del processo di comunicazione. Per fare un parallelo intuitivo, pensando alle reti come a tubi che trasportano bit, la capacit√† di trasmissione equivale al diametro del tubo, mentre il ritardo equivale al tempo che i bit impiegano ad attraversare una serie di tubi in tutta la loro lunghezza.\n0.2 Componenti della rete Introduzione generali dei componenti principali üü©- Slide\nEsempi di pezzi di rete\nLa connessione di un calcolatore a una rete di calcolatori richiede un insieme essenziale di componenti, hardware e software, in aggiunta al calcolatore elettronico di base.\nL‚Äôelemento primario da aggiungere al calcolatore √® il dispositivo (o scheda) di rete: si tratta di un dispositivo hardware di comunicazione, fisicamente collegato al calcolatore, in grado di codificare e trasmettere, oppure ricevere e decodificare i dati inviati dal calcolatore alla rete, e dalla rete al calcolatore.\n0.2.1 Mezzo fisico di trasmissioneüü© sono supporti fisici alla propagazione e trasmissione di segnali, quali cavi o fili elettrici, fibre ottiche, o semplicemente lo spazio tridimensionale nel quale si propagano le onde radio. Tali mezzi di trasmissione realizzano l‚Äôinfrastruttura fisica della rete. Il costo di realizzazione dell‚Äôinfrastruttura di rete rappresenta spesso un fattore rilevante e critico per la diffusione e l‚Äôimplementazione di reti di calcolatori.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Introduzione a reti/Untitled 8.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Introduzione a reti/Untitled 8\u0026quot;\u0026gt; Esempi mezzi di trasmissione\nIl mezzo di trasmissione √® l‚Äôelemento fisico che supporta la propagazione dei segnali trasmessi tra i dispositivi della rete. Ne abbiamo parlato anche nella sezione dispositivi di rete Le connessioni di rete possono essere realizzate mediante tre mezzi di trasmissione diversi:\ncavi conduttori fibre ottiche connessioni senza fili. I cavi di materiale conduttore (cavetti, doppino intrecciato o cavo coassiale), sono in grado di propagare segnali elettrici, cio√® variazioni di tensione e corrente elettrica. Questi mezzi fisici sono i pi√π utilizzati nelle reti locali, e nelle brevi distanze, per il loro buon rapporto tra costo e prestazioni. Oggi tale mezzo trasmissivo √® in grado di supportare trasmissioni dati con una capacit√† dell‚Äôordine del miliardo di bit al secondo (1-2 Gbit/sec).\nLa tecnologia a fibre ottiche √® tecnologicamente avanzata, e si basa sulla trasmissione di segnali ottici, cio√® di luce, vincolata all‚Äôinterno di una sottile fibra di vetro purissimo. La fibra √® sottile come un capello, √® elastica ed √® protetta da una guaina esterna per facilitare il suo impiego. Il costo della fibra non √® molto elevato, tuttavia la fibra √® molto delicata per quanto riguarda la connessione degli estremi (giunzione) e questo influisce molto sui costi di distribuzione e di realizzazione dell‚Äôinfrastruttura di rete. La capacit√† di una fibra ottica pu√≤ arrivare oggi a qualche decina di migliaia di miliardi di bit al secondo (oltre 10000 Gbit/sec).\nOnde elettromagnetiche e dalla loro propagazione nello spazio. Esempi in tal senso sono forniti dalle onde radio e dalla luce infrarossa. Tali tecnologie vengono dette senza fili (wireless). Le reti senza fili sono molto interessanti, e la loro diffusione √® oggi esplosiva, in quanto permettono la mobilit√† dei dispositivi e degli utenti. La capacit√† dei collegamenti senza fili pu√≤ arrivare oggi a qualche decina di milioni di bit al secondo (1- 54 Mbit/sec). Il limite della tecnologia senza fili √® dato dalla vulnerabilit√† del segnale rispetto ad errori e interferenza dei segnali, e dai limiti fisici della propagazione dei segnali. Due dispositivi possono essere connessi senza fili solo se rimangono entro un limite di distanza $d$ che dipende dalla potenza del segnale radio emesso dal trasmettitore, e da eventuali ostacoli intermedi per il segnale. Inoltre non √® precisa, nel senso che non si riesce in modo effettivo ad isolare la direzione di arrivo (la destination e sorgente non sono isolate). Vedere Onde elettromagnetiche per spiegazione sul funzionamento fisico.\nCollisione √® un problema molto comune per\nOgni rete pu√≤ essere realizzata attraverso un singolo mezzo fisico di trasmissione, oppure attraverso la composizione di mezzi fisici eterogenei.\nCanali, vedi canali di comunicazione, dividono spesso il mezzo di comunicazione. (si potrebbe infatti dire che il singolo mezzo di comunicazione abbia un fascio di canali)\n0.2.2 Dispositivo o scheda di rete üü© √® semplicemente un‚Äôinterfaccia standard presente sul dispositivo di rete, per il collegamento del dispositivo di rete al mezzo di trasmissione. Esistono vari connettori, diversi a seconda del tipo di tecnologia impiegata per la rete di comunicazione. I connettori possono avere varie forme, e tipicamente permettono il collegamento solo quando le tecnologie dei dispositivi di rete, dei protocolli di gestione, e dei mezzi di trasmissione sono tra loro compatibili. I dispositivi di rete sono amministrati da componenti software del sistema operativo, e devono rispettare un insieme di regole standard per la gestione dei processi di comunicazione, definite dai protocolli di rete. Le schede di rete permettono la comunicazione in rete tra calcolatori diversi, attraverso i vari mezzi di trasmissione illustrati, avviene mediante dispositivi interni o periferiche esterne del calcolatore. Queste schede sono collegate al calcolatore attraverso un‚Äôinterfaccia di collegamento del calcolatore: su tale interfaccia transitano i dati (bit di informazione) da trasmettere in rete, oppure ricevuti dalla rete.\nLa scheda di rete si occupa inoltre di trasformare i bit di informazione in segnali trasmissibili sul mezzo di trasmissione della rete e viceversa: tali trasformazioni si chiamano codifica e decodifica dei dati. Un connettore di rete pone direttamente in contatto la scheda di rete con il mezzo di trasmissione per l‚Äôinvio e ricezione dei segnali in rete.\nIn sintesi, la funzione della scheda di rete √® quella di memorizzare temporaneamente, codificare, decodificare, trasmettere e ricevere i dati da e verso il mezzo di trasmissione (cio√® la rete) o il calcolatore.\nIdentificazione della scheda di rete Il tipo della scheda di rete viene identificato a seconda del mezzo trasmissivo, e soprattutto a seconda dei protocolli di comunicazione utilizzati per la codifica, e per la trasmissione dei dati in rete. Per le reti locali (LAN) basate su mezzo di trasmissione cablato, le tecnologie pi√π diffuse sono chiamate con il nome del protocollo di comunicazione primario: ad esempio Ethernet, nelle varianti a 10, 100 Mbit/sec (Fast Ethernet) e 1000 Mbit/sec (Gigabit Ethernet).\nPer le reti LAN senza fili (WLAN), le schede di rete pi√π diffuse sono denominate Wi-Fi (da 11 a 54 Mbit/sec), e Bluetooth (da 1 a 2 Mbit/sec). Ogni scheda di rete, per permettere di essere identificata univocamente nel contesto di una rete locale, dispone dalla sua costruzione di un indirizzo univoco (unico) a livello mondiale, non modificabile, detto indirizzo MAC (Medium Access Control), spesso questa scheda di rete √® specifica per il mezo trasmissivo!. Tali indirizzi vengono assegnati dai costruttori delle schede, per evitare che si possano originare indirizzi MAC duplicati. (spesso hai moltissime informazioni riguardo al modello della scheda di rete e del produttore solo guardando questo).\nIl MAC si occupa anche di evitare le collisioni (come non lo so).\n0.2.3 Protocolli di rete üü© I protocolli di rete sono un insieme di regole, univocamente definite, per garantire la compatibilit√† e la corretta configurazione e gestione delle fasi della comunicazione tra i dispositivi di rete.\nSlide (la parte sull‚Äôarchitettura presente in slide √® trattata in Architettura e livelli 1, 2\nLe regole che governano i processi di comunicazione in rete, tra dispositivi e sistemi eterogenei\nPerch√© √® necessario: La necessit√† di accordarsi su regole e servizi comuni per la comunicazione di rete ha lo scopo di permettere una completa compatibilit√† e supporto alla comunicazione su sistemi, tecnologie e dispositivi eterogenei.\nAl fine di far ci√≤ definiscono delle regole semantiche (processi) e sintattiche (struttura pacchetto) formali.\nI protocolli definiscono aspetti e regole semantiche sulla sequenza dei messaggi, e regole sintattiche sul formato dei messaggi scambiati durante la comunicazione. La definizione dei protocolli di rete deve prevedere e supportare diverse finalit√† di comunicazione.\nNon ha quindi senso definire un protocollo rigido, ma ha senso definire classi di protocolli, deputate a svolgere e gestire determinate funzioni della comunicazione. Tali classi di protocolli, opportunamente organizzate, permettono di semplificare la gestione della rete, ma √® necessario definire in modo non ambiguo le relazioni tra le classi di protocolli (ovvero quale protocollo si occupa di gestire un certo problema? Come avviene il dialogo tra protocolli?)\n0.3 Struttura della rete 0.3.1 Strutture della connessione di rete (4) üü© \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Introduzione a reti/Untitled 12.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Introduzione a reti/Untitled 12\u0026quot;\u0026gt; Un collegamento o connessione fisica di rete √® fornita da un mezzo di trasmissione (ad esempio un cavo, una fibra ottica oppure lo spazio per la propagazione di onde radio) che sia condiviso tra due o pi√π dispositivi ad esso collegati, e che permetta il trasferimento di segnali, e quindi informazione, tra i dispositivi stessi.\nUn‚Äôinfrastruttura di rete rappresenta l‚Äôinsieme dei collegamenti o connessioni fisiche esistenti tra tutti i dispositivi di una rete.\nLa comunicazione tra una coppia qualsiasi di calcolatori in rete, detti nodi (oppure host) della rete, √® possibile se esiste un collegamento diretto tra i nodi, oppure se esiste una sequenza di collegamenti, detta cammino, che permetta la comunicazione dei segnali passando per eventuali nodi e collegamenti intermedi.\nClassi di strutture di connessione della rete. (4)\nLe connessioni di rete punto a punto, come nell‚Äôesempio (a), sono connessioni che possono essere instaurate tra una coppia di calcolatori, senza coinvolgerne altri. Esse rappresentano il caso pi√π semplice di infrastruttura di rete, e sono semplici da gestire. Reti completamente connesse: Le connessioni di rete multiple permettono di connettere contemporaneamente un dispositivo a molti altri dispositivi. Nell‚Äôesempio (b) viene mostrata una infrastruttura di rete nella quale ogni nodo √® connesso attraverso un linea dedicata ad ogni altro nodo. Questa infrastruttura di rete viene detta completamente connessa, ed √® molto ridondante: infatti esistono molti cammini, oltre al collegamento diretto, per connettere ogni coppia di nodi passando per nodi intermedi. Una simile infrastruttura di rete si pu√≤ ritenere a volte troppo complessa e costosa. Ad esempio, sarebbe impensabile disporre di una connessione dedicata (cio√® un filo diretto) da ogni calcolatore ad ogni altro calcolatore sulle reti mondiali. Reti parzialmente connesse: Nell‚Äôesempio c, malgrado il ridotto numero di collegamenti rispetto al caso b, √® comunque possibile per ogni dispositivo trasferire segnali, cio√® comunicare, verso ogni altro dispositivo. In altre parole esiste un cammino, attraverso le connessioni disponibili, per trasferire informazione tra ogni coppia di dispositivi della rete.Nella rete (c) esiste per√≤ un fattore di rischio: in seguito a un guasto di una connessione, potrebbe risultare un insieme di componenti separato da tutti gli altri, detto ‚Äúpartizione‚Äù della rete (esempio d). Le partizioni della rete limitano il grado di comunicazione possibile, e possono essere dovute a cause fisiche (guasti fisici della connessione) oppure a cause che dipendono da cattive applicazioni delle regole di utilizzo (ovvero dei protocolli, che vedremo in seguito). 0.3.2 Topologia di rete üü© Slide\nTopologie di rete sono i diversi schemi di connessione sono possibili per creare le infrastrutture di rete\nTopologia per PAN e locali LAN: Topologia ad anello (esempio a) √® basata sull‚Äôorganizzazione delle connessioni tra i dispositivi, in modo da creare un anello chiuso. Ogni componente pu√≤ comunicare con ogni altro componente inviando i segnali attraverso la sequenza di connessioni in senso orario o antiorario. La topologia a stella (esempio b) prevede un componente centrale direttamente connesso a tutti gli altri. Ogni componente periferico pu√≤ comunicare con ogni altro componente periferico passando attraverso il componente centrale. La topologia a bus (esempio c) prevede che ogni componente abbia una connessione verso un bus condiviso (cio√® una connessione condivisa da tutti). Questo tipo di connessione permette di introdurre una delle problematiche fondamentali che saranno trattate in seguito: la gestione dell‚Äôaccesso al bus, ovvero il decidere chi possa trasmettere tra tutti i possibili dispositivi, per evitare sovrapposizioni delle trasmissioni. La topologia ad albero (esempio d) prevede un‚Äôorganizzazione gerarchica delle connessioni. Se pensiamo all‚Äôanalogia con un albero genealogico, esiste un dispositivo (nonno) che connette direttamente due o pi√π dispositivi (figli), ognuno dei quali a sua volta connette direttamente un numero variabile di dispositivi (nipoti), e cos√¨ via.\nMano a mano che le reti pi√π piccole vengono collegate tra loro e organizzate in strutture di rete pi√π grandi, la topologia della rete globale pu√≤ diventare incredibilmente complessa, e quindi uno schema topologico generalizzato non √® quasi mai applicabile. In questo caso si parla di rete con topologia a grafo complesso, oppure a maglia. In tali topologie a grafo, possono essere presenti cammini multipli che connettono coppie di nodi, dando luogo a possibili alternative per la connessione dei dispositivi. Questo fatto pu√≤ ridurre il rischio di incorrere in partizioni della rete, in quanto un certo grado di ridondanza dei cammini di connessione permette di aggirare i collegamenti soggetti a eventuali guasti.\n0.3.3 I due generali üü© √à possibile implementare una comunicazione sicura in un ambiente che possa fallire, anzi con un nemico che voglia far fallire questo?\nFai finta che A = 3, B = 3, e C = 5, ma A e B sono separati, √® possibile avere una comunicazione per attaccare insieme? Se A o B attaccano da soli verrebbero ammazzati.\nSemplificazione del problema dei due generali\nCome si manda il messaggio in modo sicuro? Se si manda il singolo messaggio, senza aspettare nessuna risposta, allora √® molto insicuro (per niente sicuro) che il messaggio sia arrivato.\nPer questo motivo si aspetta un acknowledgment, e un altro acknowledgment dall‚Äôaltra parte ‚Üí SYN/ACK protocol √® simile.\nMa facendo in questo modo non si √® mai sicuri che l‚Äôaltro abbia ricevuto il messaggio. La rete a due √® fallibile, e questo √® dimostrato.\n0.3.4 Reti commutazione a circuito üü© Slide\nNelle reti a commutazione di circuito, i dati vengono trasmessi tra un mittente e un destinatario finale agli estremi di un cammino end-to-end (circuito) di canali di comunicazione punto a punto. Il circuito viene negoziato e prenotato, attraverso opportune procedure (come avviene quando si digita un numero per una chiamata telefonica). Una volta identificati e ottenuti i canali che collegano mittente e destinatario, la comunicazione dati pu√≤ avvenire anche come un‚Äôunica sequenza di bit, senza interruzioni.\nVantaggi\nNon c‚Äô√® bisogno di dichiarare periodicamente chi sia il mittente e il destinatario dei dati, in quanto entrambi sono fissati al momento della creazione del circuito riservato (riservato = prenotato da qualcuno). Ridotto ritardo di trasmissione per i dati, in quanto ogni nodo intermedio ha gi√† disponibile il canale libero uscente sul quale inviare immediatamente i dati ricevuti sul canale entrante, dal mittente fino al destinatario finale. Svantaggi\nUtilizzo basso dei canali del circuito Quantit√† dei dati da trasmettere non √® grande I dati arrivano a gruppi, intervallati da tempi di vuoto. Inefficienza di utilizzo delle risorse del circuito nei casi sopraelencati (il canale resta tutto occupato). Pagato a tempo! Un p√≤ di tempo in pi√π per prenotare il percorso all‚Äôinizio. 0.3.5 Reti commutazione a pacchetto üü© Slides\nLa maggior parte delle reti per trasmissione dati digitali, inclusa la rete di reti globale Internet, sono di questo tipo.\nCome funziona\nI dati digitali vengono suddivisi in pacchetti separati, e vengono trasmessi su canali ad accesso multiplo (broadcast, non per forza deve essere punto a punto ). Per consentire la corretta ricezione dei dati, √® per√≤ necessario includere in ogni pacchetto l‚Äôinformazione sull‚Äôidentit√† del rispettivo mittente e soprattutto del destinatario. Si attua in questo modo la condivisione di un canale unico per diversi flussi di pacchetti appartenenti a diversi mittenti e destinatari. Componendo in serie una sequenza di canali broadcast a commutazione di pacchetto, i nodi ricevitori devono di volta in volta farsi carico di verificare se il pacchetto sia giunto a destinazione o, in caso contrario, possono provvedere all‚Äôinoltro del pacchetto ricevuto sul successivo canale broadcast.\nSvantaggi\nRitardo per la comunicazione dei dati tra mittente e destinatario (pi√π lenti dovuto all‚Äôesigenza di iterare pi√π volte la ricezione e l‚Äôinoltro di pacchetti su canali broadcast in sequenza. Maggiore rischio di collisione dei pacchetti (perdita di pacchetti) A causa dei jitter, i pacchetti possono arrivare in ordine diverso(perdita di ordine ‚Üí riordinamento) Se utilizzo il broadcast, serve il mittente e il destinatario Vantaggi\nmaggiore utilizzo dei canali ad accesso multiplo, e quindi alla possibilit√† di tariffare la comunicazione in base ai dati trasmessi, e non in base al tempo necessario. 0.3.6 Canali di comunicazione della rete üü© Slide\nBisogna dire che √® una virtualizzazione sul mezzo di comunicazione, ossia si utilizza il mezzo di comunicazione come se avesse alcuni canali diversi (che non interferiscono fra di loro) quindi possiamo riutilizzare la stessa risorsa fisica!\nDa riallacciarsi con mezzi di comunicazione per capire come sono implementate fisicamente i canali di comunicazione.\nI canali punto a punto si basano sull‚Äôaccordo tra un mittente e un destinatario riguardante la definizione del canale da usare (in figura equivale al colore). Solo due dispositivi possono usare il canale di tipo punto a punto a loro riservato. Possiamo creare un canale logico da un singolo mezzo trasmissivo (eg una frequenza diversa, che possono essere filtrate). Il problema principale di questo √® che √® fisso, ossia posso comunicare solamente con un unico computer, senza poter cambiare il destinatario, direi che abbia pi√π problemi nel momento di wiring.\nI canali ad accesso multiplo (broadcast) sono canali sui quali tutti possono trasmettere e dove tutti ricevono le trasmissioni di altri (chiaramente il problema di collissione √® molto alto). Half duplex o uno trasmette o uno riceve mentre i Full-duplex possono trasmettere e ricevere contemporaneamente. Spesso per queste reti c\u0026rsquo;√® un master e dei slave che gestiscono.\nEthernet risolve questo problema senza fare utilizzo di un master, utilizza un sistema di ___ (non mi ricordo, √® comunque una race condition) lo risolve con un sistema di counter interno dopo il quale, se √® ancora vuoto il canale di comunicazione broadcast, prova a fare la comunciazione.\n0.3.7 Problema delle collisioni su canali multiple üü® Un problema per i canali ad accesso multiplo √® legato alla possibile collisione di segnali appartenenti allo stesso canale di comunicazione. Se due trasmissioni di segnali si sovrappongono nel tempo sullo stesso canale di comunicazione, l‚Äôeffetto sui segnali pu√≤ essere distruttivo e l‚Äôesito della comunicazione pu√≤ essere nullo. Intuitivamente, se due dispositivi trasmettono i loro segnali contemporaneamente, nessuno ricevitore sar√† in grado di capire quali bit di informazione siano stati trasmessi.\nIl problema delle collisioni √® molto critico, e determina l‚Äôesigenza di arbitraggio nell‚Äôaccesso al canale: chi trasmette e quando? Il problema dell‚Äôarbitraggio pu√≤ essere banale su canali punto a punto, dove mittente e destinatario possono definire semplici leggi (cio√® protocolli di gestione della comunicazione) per evitare le collisioni: ad esempio, trasmetto io, poi trasmetti tu. In canali condivisi ad accesso multiplo (broadcast) il problema risulta invece molto complesso, in quanto occorre definire leggi non ambigue, in grado di regolare gli accessi da parte di molti utenti, evitando le collisioni.\nIl problema principale delle collisioni √® che fanno perdere tempo o infomazioni (se il nostro protocollo non le gestisce).\nUtilizzo\nDi solito √® uguale a $capacit√† \\cdot overhead$, ad esempio se trasmetto 100 bit e solo 1 un bit √® di informazione, questo √® l\u0026rsquo;utilizzo del protocollo. Questo va a misurare efficienza di informazioni di questo protocollo.\n0.3.8 Servizi orientati alla connessione e non üü®+ Slide\nI servizi orientati alla connessione (connection-oriented) garantiscono che la spedizione di pacchetti di dati tra mittente e destinatario sia equivalente a una trasmissione affidabile e corretta. In altre parole, essi implementano una serie di operazioni attraverso le quali tutti i pacchetti perduti saranno ritrasmessi, e correttamente ordinati, fino a ricostruire esattamente tutta l‚Äôinformazione trasmessa. L‚Äôimplementazione di tale tipo di servizi potrebbe essere basata sulla definizione di vari protocolli alternativi. Ad esempio, potrebbe essere definito un cammino riservato unico per i pacchetti. Intuitivamente, ci√≤ equivarrebbe a un circuito virtuale per l‚Äôinvio dei pacchetti. Un altro modo per ottenere tale servizio potrebbe essere basato sulla numerazione dei pacchetti inviati, sul riordino dei pacchetti ricevuti e sulla richiesta di ri-trasmissione dei pacchetti perduti.\nIn breve questo risolve un problema di:\nRiordinamento dei pacchetti\nSoluzione riordinamento\nBasta numerare i pacchetti e poi far riordinare dal destinatario, questo √® un problema molto facile da risolvere\nReinvio dei pacchetti perduti\nSoluzione reinvio\nBisogna che il destinatario mandi degli acknowledgements. Anche questi possono essere persi.\nProblema tempo da aspettare prima di reinviare il pacchetto Pacchetto duplicato quando si perde l\u0026rsquo;acknowledgement o ci mette troppo. I servizi non orientati alla connessione (connectionless) non si preoccupano di garantire l‚Äôordine corretto dei pacchetti inviati e nemmeno la ricezione di tutti i pacchetti. Tale servizio √® simile all‚Äôinvio dei pacchetti in modo analogo a una sequenza di lettere attraverso la posta ordinaria.\nNon ci importa l\u0026rsquo;ordine di arrivo n√© per forza alcuni buchi.\nQuesto √® come sono le reti normali, normalmente sono connectionless, con un protocollo in pi√π sono connection-oriented.\nIn modo molto veloce si potrebbe dire che i servizi non orientati alla connessione non garantiscono nulla.\n","permalink":"https://flecart.github.io/notes/introduzione-a-reti/","summary":"Questa nota raccoglie note introduttive al corso di reti dei calcolatori fatto all\u0026rsquo;universit√† di Bologna.\n0.1.1 Definizione di rete di calcolatori (2) üü©- I requisiti sono principalmente 2\nEssere autonomi nel calcolo (capacit√† di eseguire dei programmi) Essere interconnessi (capacit√† di ricevere ed inviare dei segnali) Gli scopi sono principalmente per la comunicazione fra utenti o calcolatori.\nNon-esempi\nRete telefonica, non sono autonomi Rete televisiva Esempi\nSmartphones con wi-fi WWW E-mail Una rete di calcolatori √® un insieme di dispositivi autonomi, cio√® in grado di eseguire e svolgere autonomamente i compiti programmati di calcolo e di comunicazione, interconnessi tra loro da supporti fisici alla trasmissione di segnali.","title":"Introduzione a reti"},{"content":"Scopi del sistema operativo üü© Un sistema operativo √® una astrazione sul HW che permette di\nGestire l‚Äôesecuzione di pi√π programmi assieme (concorrenza), tramite virtualizzazione CPU e Memoria Gestire le risorse (Quindi I/O, RAM, Memoria, Networking) Fornisce una interfaccia di programmazione (API) molto pi√π generale e potente, in grado di astrarre da dettagli di livello basso, vicini all‚ÄôHardware (come device drivers). Quindi in breve il SO √® n programma che crea un ambiente civile per i programmi in cui interagire, e facilita molto il lavoro al programmatore per la sua interfaccia nuova. (si potrebbe dire che sia una macchina virtuale con un suo linguaggio (che √® l‚ÄôAPI) se seguiamo la terminologia di Macchine Astratte)\nVantaggi principali üü© Col sistema operativo abbiamo ora una astrazione sull‚ÄôHWche ci permette di interagire con queste in modo molto pi√π facile (molto molto).\nQuindi\nIndipendenza dall‚Äôhardware (i dettagli nascosti sotto le interfacce) Programmabilit√† e comodit√† di Uso per le API che sono presenti. Un buon sistema operativo deve essere quindi semplice per l‚Äôutilizzo ed efficiente nell‚Äôutilizzo delle risorse che ha disponibili.\nSistemi paralleli ‚Ü©Ô∏è Sistemi paralleli sono dei sistemi che possono eseguire pi√π istruzioni allo stesso momento (quindi hanno pi√π centri computazionali diciamo.\nTassonomia sulla struttura Questo sono stati citati in CPU e storia degli elaboratori.\nSIMD, come le GPU. MIMD, multicore, quelli che ci sono anche nelle GPU. Tassonomia sulla dimensione Basso parallelismo, quando ho poche CPU potenti. Sistemi massicciamente paralleli, ho tante CPU, anche normali. Tipologie di Coupling Tight quando ho CPU su MEMORIA CONDIVISA\nLoose quando ho CPU su memoria privata, che possano comunque comunicare fra di loro.\nAlcune tipologie di sistemi paralleli Symmetric multiprocessing: quando hanno la stessa struttura di dati per ogni processore.\nQuesto rende pi√π semplice un p√≤ la gestione delle strutture di dati, che sono le stesse.\nAsymmetric multiprocessing quando c‚Äô√® un unico processo che d√† da fare un compito specifico a certi processi (quindi ho una asimmetria\nSistemi realtime Quando il valore di output dipende non solo dal valore, ma anche dall‚Äôistante in cui il valore viene prodotto.\nHard and soft real-time Hard quando pu√≤ avere effetti catastrofici, come controllo velivoli o Nucleari.\nSoft quando ho solo disservizi.\nVecchia roba Hardware e Software Il professore fa una distinzione molto strana fra software e hardware (ricorda teatrino dei limoni che ha fatto in classe).\nIn soldoni hardware √® tutto quello che √® composto da mero hardware. Il software √® la conoscenza, qualcosa che si distingue molto facilmente perch√© √® facilmetne copiabile, e distribuibile\nInformazione qualche conoscienza che √® utile. Ha 3 problemi principali\nElaborazione, che risolve il problema della trasformazione di un informazione in un altra forma che possa risultare utile (es bites in suoni che si possono sentire). Memorizzazione che risolve il problema di trattenimento dell‚Äôinformazione nel tempo. Comunicazione che risolve il problema di comunicazione dell‚Äôinformazione in due luoghi diversi (protocolli) Cosa fa un informatico secondo il prof. Studia un problema, da una descrizione della soluzione in modo preciso e dettagliato che un calcolatore si ain grado di eseguire la soluzione (e replica questo pensiero umano).\nSulle graffette esempio che ha fatto il prof riguardo le graffette. Afferma in soldoni che la scuola uccida la creativit√† perch√© si trovano molti meno modi di utilizzare la creativit√†, e sembra ch ela causa principale di questo sia la scuola. Ma √® davvero cos√¨???\nA me sembra che sia il processo di crescita normale in cui si impara cosa servno di solito a cosa, quindi si spendono meno risorse per cose comuni. √à una cosa normale nell‚Äôessere umano che una cosa comune sia poco interessante. √à interessante un modo nuovo e utile del suo utilizzo, ma il raggio di soluzioni √® vasto. Le cose comuni √® difficile che servano per soluzioni innovative, senza nessuna base: eg. se voglio fare maetematica non vado certo a considerare una graffetta, ci vorrebbero altri episodi serendipici che possano fare una associazione, cosa direi che non accadrebbe mai\n","permalink":"https://flecart.github.io/notes/introduzione-so/","summary":"Scopi del sistema operativo üü© Un sistema operativo √® una astrazione sul HW che permette di\nGestire l‚Äôesecuzione di pi√π programmi assieme (concorrenza), tramite virtualizzazione CPU e Memoria Gestire le risorse (Quindi I/O, RAM, Memoria, Networking) Fornisce una interfaccia di programmazione (API) molto pi√π generale e potente, in grado di astrarre da dettagli di livello basso, vicini all‚ÄôHardware (come device drivers). Quindi in breve il SO √® n programma che crea un ambiente civile per i programmi in cui interagire, e facilita molto il lavoro al programmatore per la sua interfaccia nuova.","title":"Introduzione SO"},{"content":"Dato che il software sta diventando sempre pi√π diffuso, diventa sempre pi√π importante andare a definire delle metriche che possano garantirne la qualit√†, ossia la non frequenza di errori o bug che possono in qualche modo limitarne la qualit√†.\nError, Fault and Failure Secondo la definizione esatta data da IEEE, questi tre termini hanno un significato ben specifico, molto diverso.\nError, sono comportamenti non previsti da un comportamento dell\u0026rsquo;utente, oppure il programmatore capisce male le specifiche. Fault sono i bugs, degli errori nel codice che creano un comportamento non previsto Failure, sono comportamenti non previsti da specifiche, che crea un guasto e non permette il funzionamento Qualit√† del software Rating and Ranking Il rating √® l\u0026rsquo;assegnazione di un punteggio assoluto di qualit√† riguardo al prodotto.\nRanking √® comparazione fra un prodotto rispetto all\u0026rsquo;altro per\nCondizioni necessarie (4) Qualit√† interna ed esterna Ci sono quei principi utili possono essere categorizzati in attributi\noperativi di manutenzione (modificabilit√†) adattabilit√†, ossia se il software pu√≤ essere usato in ambienti diversi. Goal Question Metric Principi di qualit√† (3) Gli obiettivi del prodotto devono essere chiare Metriche di qualit√† per sapere cosa esattamente andare a misurare Le domande per vedere se un certo obiettivo √® stato raggiunto, da quanto ho capito √® un check midpoint per avere feedback, nello stesso modo per cui fatto in Modelli AGILE Tre livelli di analisi Obiettivi Domande Metriche per valutare domande Esempio: Verifica e validazione Verifica = quanto viene implementato bene la specifica, che √® anche ci√≤ che deve essere testato in automatico o manualmente. a seconda del formato pu√≤ essere ispezione (manuale) o testing.\nValidazione = accettazione da parte del cliente.\nAspetti da testare Una idea molto presente in questo √® la copertura ossia il programma dovrebbe funzionare a seconda del branch, dei moduli, in questo senso dovrebbe esserci una copertura pi√π ampia possibile.\nBlack and white box testing Il primo quando non si ha accesso al codice sorgente, ma si testa solametne la specifica come pu√≤ essere una user story\nWhite box quando abbiamo visibilit√† sul sorgente (ad esempio match diretto sul codice di ritorno, o fare i mocks).\nComplessit√† ciclomatica di McCabe Cerca di calcolare quanto sia affidabile un software, ed √® fatto sul diagramma di flusso. cc si calcola come $$ cc(G) = e - n + 2 \\cdot G $$ G sono sottografi sconnessi. $e$ sono gli archi, $n$ sono i nodi. cos√¨ viene definito un valore di complessit√† ciclomatico, e ci dice il numero di test che bisogna avere per essere abbastanza sicuri.\nE il diagramma di fllusso √® calcolabile, quindi si pu√≤ sempre fare, come rule of thumb se la complessit√† √® alta, il rischio √® alto.\nManutenzione del software Tipologie di correzione (3) Perfettiva Per migliorare, ci sono nuove funzionalit√† tipo 1/2 sono questi Correttiva, circa 1/4 dei cambi. Adattiva Per ambiente che cambia Esiste anche uno standard IEEE per gestire questo cambiamento.\nI costi nella manutenzione Personale instabile Progettisti non responsabili (bisogna rendere i progettisti) Inesperienza dei progettisti Il software vecchio. ","permalink":"https://flecart.github.io/notes/la-qualit%C3%A0-del-software/","summary":"Dato che il software sta diventando sempre pi√π diffuso, diventa sempre pi√π importante andare a definire delle metriche che possano garantirne la qualit√†, ossia la non frequenza di errori o bug che possono in qualche modo limitarne la qualit√†.\nError, Fault and Failure Secondo la definizione esatta data da IEEE, questi tre termini hanno un significato ben specifico, molto diverso.\nError, sono comportamenti non previsti da un comportamento dell\u0026rsquo;utente, oppure il programmatore capisce male le specifiche.","title":"La qualit√† del software"},{"content":"NOTA: tolgo dalle note perch√© non mi sembra importante.\nIntroduction to system design Packages vs diagrams üü©- Packages fisica implementazione, perch√© √® una cosa utile per lo sviluppo Diagrams logica visualizzazione perch√© aiuta solamente a comprendere meglio come funziona il sistema in toto. Components What is a component (3) üü® √à una entit√† totalmente indipendente che funziona a s√©, un esempio √® il dll, dynamically loaded libraries presente nei sistemi di windows. Una cosa √® che espongono interfacce per interagirci, e questi possono essere utilizzati per creare sistemi complessi.\nQuindi riassumendo:\nIndipendenza da altri software (almeno √® contenuto) Presenza di interfacce per interagirci Risolvono un certo problema specifico (appunto isolato) Se ho questo allora posso rappresentare la struttura in esecuzione con i diagrammi di sopra, a seconda di come li carico scarico e simili.\nDifference with collaboration diagrams üü•+ nel nostro caso √® una dipendenza esterna non √® una estensione ereditaria come potrebbe sembrare se lo analizziamo come class diagram.\nCi permette lo stesso di creare diagrammi che rappresentano in che modo i singoli oggetti comunicano con altri.\n#### Stereotypes üü• Capire un po' meglio questa parte. Node What is a node üü© Sono una risorsa computazionale, quindi con CPU e memoria per poter eseguire qualcosa. Un esempio sono micro-controllori per temperatura, smart-home e simili. Questo √® qualcosa di base se vogliamo andare ad analizzare cose come sistemi distribuiti e nodi di computazione in quel punto.\nDifference with components (1) üü© I componenti rappresentano il pacchetto logico per una esecuzione, quindi sono pi√π strutturali, astratti, rappresentano in che modo esegue un certo sistema. Mentre i nodi sono rappresentazione fisica esecuzione, in cui effettivamente eseguono qualcosa, prima solo per rappresentarlo, quindi deployment di ci√≤\nReal Time UML Una delle caratteristiche fondamentali dei real time √® che hanno garanzia di esecuzione entro tot tempo, questa √® una cosa anche indagata per gli schedulers, vedi Scheduler#SISTEMI A REALTIME (non fare)\nTime events (3) üü® Change event: rappresentano il momento in cui una azione √® avvenuta e quindi probabilmente deve essere gestito un cambio di stato in questo caso. Time Event: descrivono quanto deve essere fatto un evento, per esempio Fra 5 minuti alle 12 P.M. Timing costraints entro quanto tempo deve essere fatto (o ogni quanto). Solo che manca un linguaggio per esprimere questi constraints. Esempio: Object Contraint Language Introduzione a OCLüü• √® un linguaggio di modellazione utilizzato per modellare in modo non ambiguo tutte le pre e post condizioni per un linguaggio. √à un linguaggio puro. Secondo Succi √® utile quando facciamo i test durante il progetto.\n","permalink":"https://flecart.github.io/notes/system-design/","summary":"NOTA: tolgo dalle note perch√© non mi sembra importante.\nIntroduction to system design Packages vs diagrams üü©- Packages fisica implementazione, perch√© √® una cosa utile per lo sviluppo Diagrams logica visualizzazione perch√© aiuta solamente a comprendere meglio come funziona il sistema in toto. Components What is a component (3) üü® √à una entit√† totalmente indipendente che funziona a s√©, un esempio √® il dll, dynamically loaded libraries presente nei sistemi di windows.","title":"System Design"},{"content":"10.1 Derivata parziale La derivata vuole descrivere quanto varia una funzione al variare dell\u0026rsquo;input. Ma ora siamo in pi√π dimensioni, quindi vogliamo descrivere il variare dell\u0026rsquo;input come il variare della distanza euclidea\n$\\dfrac{\\delta f}{\\delta x}(x,y) = \\lim _{h \\to 0} \\dfrac{f(x + h, y) - f(x, y)}{h}$ ovvero sto facendo variare solamente una variabile (la y in questo caso √® come se fosse una costante!?) Questo √® un rapporto incrementale su una direzione.\nSe esiste il limite, √® la derivata parziale rispetto a x.\nIn modo analogo puoi definire una derivata parziale rispetto a y\n10.1.1 Gradiente Se vogliamo considerare allo stesso momento la derivata parziale per ogni componente, possiamo farlo considerando un unico simbolo: (indica il gradiente della funzione).\n$$ \\nabla f(x,y) = (\\delta_xf(x,y), \\delta_y f(x,y)) $$ Se in ogni punto √® derivabile allora possiamo proprio definire una funzione gradiente di questa, nel modo di sopra.\nQuesta definizione si pu√≤ estendere per uno spazio n-dimensionale\n10.1.2 Legame con la continuit√† Si ha una relazione molto simile con la derivata a singola dimensione (cazzo non mi ricordo bene la dim????)\n$f:A \\to \\R$ se $f$ √® derivabile in $x$ allora $f$ √® continua in $x$ in R normale, ma se a pi√π dimensioni avessimo le derivate parziali non abbiamo la continuit√† in quel punto.\nEG $$\\begin{cases} \\dfrac{xy}{x^2 + y^2} \\text{ se diverso dall'origine }\\\\ 0 \\text { altrimenti } \\end{cases}$$ in questo esempio entrambe le derivate parziali in (0,0) esistono, ma non √® continua in questo punto (tende a +- infinito in questo punto).\nAnalisi della funzione sopra\nSi pu√≤ dimostrare che la funzione di sopra ha entrambe le derivate uguali a 0 quando tende a 0. (applicare la definizione di derivata parziale).\nDimostriamo che non √® continua in (0,0) ovvero esiste una successione che tende a 0, ma non vale la definizione di continuit√†, ovvero non vale che $f(a_n, b_n) \\to f(0,0) = 0$.\nScegliamo la successione simile: $(a_n,b_n) = (1/n, 1/n)$ che ovviamente tende a 0.\nMa .\n(1/n * 1/n) / (2/(n*n)) != 0 Quindi questa successione tende a 2, mentre dovrebbe tendere a 0. Un caso patologico di continuit√†, ma che comunque da l\u0026rsquo;idea di questo.\n10.1.3 Derivabilit√† e differenziabilit√† (intuizione) Si ricordi la definizione di derivata in $\\R$. Derivate.\nSi ricordi anche come si √® ricavata l\u0026rsquo;approssimazione con serie di taylor e gli o-piccoli in Hopital, Taylor, Peano\nPer descrivere la nozione di derivabilit√† vogliamo ricondurci a una formula di Taylor per il primo grado. (perch√© nelle derivate parziali sappiamo quando varia in due direzioni, ma mancano informazioni su quanto varia in tutte le direzioni, ed √® per questo motivo che non ho la continuit√†).\nVorrei considerare un limite simile a $f(x + h, y+ h) - f(x, y)$, che possiamo riscrivere in forma vettoriale $f((x + y)+ (h,k)) - f(x,y)$ e ricondurci a una forma di approssimazione con taylor.\nDef o-piccolo a pi√π dimensioni:\n$g: \\mathbb{R}^2 \\to \\mathbb{R}$ si dice che $g(h,k) = o(\\lvert(h,k)\\rvert)$ se ho che $\\lvert g(h,k)\\rvert/ \\lvert (h,k)\\rvert \u003c \\epsilon$ , con $0\u003c \\lvert(h,k)\\rvert \u003c \\delta$ per ogni epsilon maggiore di 0, quindi considero la norma (che mi da una nozione di distanza). Ma i concetto di o-piccolo √® ancora ben presente.\nPossiamo anche scrivere la stessa definizione utilizzando le successione.\nCome qui Avendo questa nozione di approssimazione per taylor, posso dare una nozione di differenziabilit√†. In questo modo riesco a dare una nozione di funzione che tende a zero pi√π o meno velocemente della norma. (o potenze di esse).\n10.2 Differenziabilit√† Questa √® la condizione molto pi√π forte rispetto alla derivata, √® il concetto che ci permette di avere subito la continuit√†.\nLa differenza principale con la derivata √® che qui non consideriamo una unica direzione cerchiamo di prenderle tutte. Andiamo ora a vedere come definire questo fatto.\n10.2.1 La funzione differenziabile Sia $f$ una funzione da $A \\subseteq \\mathbb{R}^2$ aperto da $f: A \\to \\mathbb{R}$. Si dice che la funzione $f$ sia differenziabile se:\nEsistono le derivate parziali per tutte le direzioni. Se vale $$ f((x + h, y + k)) = f((x, y) + (h,k)) = f(x,y) + \\langle\\nabla f(x,y), (h,k)\\rangle + o(\\lvert h,k \\rvert ) $$ Possiamo scrivere questa cosa con una altra notazione equivalente:\n$f(x, y) = f(\\bar{x}, \\bar{y}) +\\langle\\nabla f(x,y), (x - \\bar{x},y - \\bar{y})\\rangle + o((\\mid x - \\bar{x},y - \\bar{y} \\mid)$ con $(x,y) \\to(\\bar{x}, \\bar{y})$\nE questo assomiglia di pi√π rispetto al polinomio di taylor, perch√© effettivamente qui si ha l‚Äôapprossimazione in bella vista.\nAndiamo ora a dare una intuizione sul perch√© vogliamo la seconda condizione.\nIntuizione del punto 2\nNon stiamo facendo altro che dare la formula di Taylor del primo ordine (vedi Hopital, Taylor, Peano) sul punto (x, y) ma lo stiamo considerando a pi√π dimensioni.\nQuindi, ricordando che l‚Äôespansione con le serie di taylor ci permetteva di fare una approssimazione, questa condizione per il punto 2 non √® altro che una approssimazione al variare in una qualsivoglia direzione.\n10.2.2 Polinomio di taylor del primo ordine $$ T_1(x,y) = f(\\bar{x}, \\bar{y}) +\\langle\\nabla f(x,y), (x - \\bar{x},y - \\bar{y})\\rangle $$ In particolare qui abbiamo una approssimazione dell‚Äôequazione tangente a un punto voluto (in R2 un piano, in R1 una retta, in R3 vedi che √® uno spazio), il punto $(\\bar{x}, \\bar{y}, f(\\bar{x}, \\bar{y}))$\n10.2.3 Differenziabilit√† implica continuit√† $f:A \\to \\mathbb{R}$ aperto (perch√© cos√¨ ho tutti gli intorni e questo mi semplifica prendere successioni a caso)) in $R^{2}$.\nse f √® differenziabile in un punto $(a,b) \\implies f \\text{ continua in } (a, b)$\nDobbiamo dimostrare che per ogni successione che tende a (0,0) deve essere che $f(a + h_n, b+ k_n) \\to f(a,b)$ se ho dimostrato questa cosa ho la continuit√†. Ma per il punto 2 della definizione di differenziabilit√† ho che $f(a,b) + \\langle\\nabla f(a,b), (h,k)\\rangle$ ma con h e k tendenti a 0 ho che il prodotto scalare del gradiente di esse √® tendente a 0 (anche o piccolo lo √®) , quindi ho la continuit√†.\n10.2.4 Condizione sufficiente di differenziabilit√† (!!!) Se le derivate parziali esistono e sono continue (f di classe C1) , f √® differenziabile in ogni punto\nLa definizione di differenziabilit√† non √® molto maneggevole, per questo motivo ci √® utile cercare una condizione di differenziabilit√† che sia pi√π semplice da calcolare.\nQuesto √® uno dei teoremi principali della differenziabilit√†. Collega questo con il concetto di derivata, gi√† studiata in precedenza in R\nEnunciato\nUna volta definita la funzione di classe C1 possiamo riscrivere questo enunciato in maniera pi√π compatta. Queste funzioni sono tali per cui la derivata parziale in ogni direzione esiste , e questa derivata √® anche continua (ricorda questa definizione di Classe k)\nLemma preliminare (Lagrange multivariabile)\nUtilizziamo un lemma per dimostrare il punto di sopra.\n$$ f \\in C^1(\\R^2), \\text{ siano } (a,b) \\in \\R^2, h, k \\in \\R \\implies \\exists \\alpha, \\beta \\in (0,1) | \\\\f(a + h, b) - f(a,b) = \\delta_x f(a + \\alpha h, y) h \\\\ f(a, b + k) - f(a,b) = \\delta_y f(a, b + \\beta k) k $$ La dimostrazione √® analoga per i due punti, quindi lo facciamo solamnete per uno. Per il teorema di lagrange presente nei reali, mi costruisco la funzione $g(x) = f(x, t)$ con un t fissato (notiamo che g √® continua e derivabile in quanto √® costituito da f, che per ipotesi √® continua e derivabile), allora esiste c appartenente al dominio di g tale per cui $g'(c) \\cdot h = g(a + h) - g(a)$ ossia $f(a + h,b) - f(a,b)$. Ecco che appaiono i valori di cui abbiamo bisogno in RHS.\nGuardando LHS abbiamo che\n$$ g'(x) = \\lim_{s \\to 0}\\dfrac{g(x + s) - g(x)}{s} = \\lim_{s \\to 0}\\dfrac{f(x + s, t) - f(x, t)}{s} = \\delta_xf(x) $$ Scrivendo c come prodotto di h e un opportuno $\\alpha$ possiamo dire che $c = a + \\alpha h$ (tanto deve stare in questo intervallo $(a, a +h)$, quindi √® possibile assumere che ci sia tale alpha compreso da 0 e 1).\nRiscrivendo il tutto per benino abbiamo la nostra tesi.\nDimostrazione\nPer definizione di differenziabilit√† devo dimostrare che ci√≤ sia vero.\n$\\langle\\nabla f(a,b), (h,k)\\rangle + o(|h, k|) = f(a + h, b + k) - f(a,b) = f(a + h, b + k) - f( a+h, b) + f(a+h, b) - f(a,b)$\nAggiungendoci e togliendo quel fattore dopo l‚Äôultima equazione, posso mettermi ad utilizzare Lagrange multivariabile (ho per il primo che x √® la stessa, per il secondo y √® la stessa).\nAndiamo a utilizzare le derivate parziali allora:\n$f(a + h, b + k) - f( a+h, b) = \\delta_yf(a+h , b+\\beta k)k$\ne in modo simile\n$f(a+h, b) + f(a,b) = \\delta_x f(a + \\alpha h, b) h$\nAllora riscriviamo la equazione iniziale, e vediamo che sia corretta effettivamente:\n$\\langle\\nabla f(a,b), (h,k)\\rangle + o(\\lvert h,k \\rvert) = \\delta_yf(a+h , b+\\beta k)k + \\delta_x f(a + \\alpha h, b) h$\nHo $h\\delta_x f(x,y) + k \\delta _yf(x,y) + o(\\lvert h,k \\rvert)$ dal gradiente. Se riesco a dimostrare questo allora ho finito.\nSe riusciamo a dimostrare $\\delta_x f(a + \\alpha h, b) h = h\\delta_x f(x,y) + o(\\lvert h, k \\rvert)$ allora ho finito (stessa cosa per l‚Äôaltra).\nL‚Äôultima proposizione √® equivalente a dire che $\\delta_x f(a + \\alpha h, b) h - h\\delta_x f(a,b) = o(\\lvert h,k \\rvert)$\novvero che (per definizione di o piccolo) quella cosa tenda a 0, ossia che.\n$$ \\lim_{h,k \\to (0,0)} \\dfrac{h}{\\lvert h, k \\rvert} [\\delta_x f(a + \\alpha h, b) - \\delta_x f(a,b)] = 0 $$ $\\dfrac{h}{\\lvert h,k \\rvert} [\\delta_x f(a + \\alpha h, b) - \\delta_x f(a,b)] \\leq [\\delta_x f(a + \\alpha h, b) - \\delta_x f(a,b)]$ per le propriet√† della norma.\nOra utilizziamo la continuit√† della derivata, che si ha in ipotesi e possiamo concludere che quella differenza.\nConclusione con la continuit√† E si pu√≤ dimostrare che $a + \\alpha h, b) \\in B(a,b),\\delta)$ E l‚Äôultimo dato √® vero per ipotesi di continuit√†.\n10.3 Derivata direzionale Il concetto di derivata direzionale generalizza il concetto di derivata parziale, perch√© ora invece di andare in una direzione di una base canonica, andiamo nella direzione di un vettore.\n10.3.1 Definizione Dato $x \\in \\mathbb{R}^n$ e $v\\in \\mathbb{R}^n-\\{0\\}$, consideriamo l\u0026rsquo;insieme $\\{x + tv | t \\in \\mathbb{R}\\}$, abbiamo l\u0026rsquo;insieme di una linea, passante per il nostro punto che abbia la direzione del vettore preso.\nAllora con tutto questo iniziamo la definizione:\n$f:A \\to \\mathbb{R}, (a,b) \\in A$ e dato $v = (v_1, v_2)$ un vettore unitario, allora si ha che la derivata direzionale √®\n$$ \\lim_{t \\to 0} \\dfrac{f((a,b) + tv) - f(a,b)}{t} $$ In pratica stiamo andando in una direzione scelta di v. (da notare infatti che se preso il vettore in una direzione parallela alla base canonica, allora ho le derivate parziali).\nOsservazione 2 Posso creare una funzione ausiliaria, e vedo che la derivata direzionale √® uguale alla derivata (normale 1-variabile) della funzione ausiliaria: $g(t) = f(a + tv_1, b+ tv_2)$ Si nota che $D(g(t)) = \\lim_{h \\to 0} \\dfrac{g(h) -g(0)}{h} = \\dfrac{f(a + tv_1, b+ tv_2) - f(a, b)}{h}$\n10.3.2 Formula del gradiente (!!!) Presa una funzione differenziabile con dominio opportuno e codominio R2, e un vettore in R2, possiamo definire con precisione la derivata direzionale su questo vettore in particolare √®:\n$\\dfrac{\\delta f}{\\delta v} (a,b) = \\langle \\nabla f(a,b), (v_1,v_2)\\rangle$\nOsservazione\nQuesta √® una cosa forte, perch√© mi dice che se conosco le derivate parziali riesco a trovare il valore della derivata in qualunque direzione. Ma da notare che deve essere differenziabile!.\nDimostrazione $$ f(a + tv_1, b+ tv_2) - f(a, b) = \\langle\\nabla f(a,b), tv\\rangle + o(\\lvert tv \\rvert) $$ Questo vale per la formula di Taylor, noi siamo per√≤ interessati al limite, quindi siamo interessati a questo: $$ \\lim_{t \\to 0} \\dfrac{ \\langle\\nabla f(a,b), tv\\rangle + o(\\lvert tv \\rvert )}{t} $$ Ed √® abbastanza ovvio che la soluzione di questo limite √® $\\langle\\nabla f(a,b), v\\rangle$ (basta portare fuori la t e dividerla con la t di sotto), mentre l\u0026rsquo;o-piccolo tende a 0 per definizione di o piccolo. 10.3.3 Direzione massima e minima di crescita (!!) Il problema corrente √® stabilire la direzione massima di crescita per una funzione differenziabile definita in dominio di dimensione maggiore di 0.\nDato il gradiente (consideriamo questo diverso da 0 perch√© nell\u0026rsquo;altro caso √® qualcosa di abbastanza banale). Se √® diverso da 0, posso allora normalizzare il vettore (e scriverlo con coordinate polari in un modo simile a quanto fatto in Analisi multi-variabile.\n$$ \\nabla f(a,b) = \\lvert \\nabla f(a,b) \\rvert \\cdot (\\cos\\theta, \\sin \\theta) $$ Ricordiamo per punto sopra che la derivata direzionale √®\n$\\langle \\nabla f(a,b), (v_1,v_2)\\rangle$, (notiamo che v √® definito come versore, quindi possiamo passare alle cordinate polari anche l√¨, allora il valore di questa derivata direzionale √®\n$$ \\langle \\nabla f(a,b), (\\cos\\gamma,\\sin\\gamma)\\rangle = \\lvert \\nabla f(a,b) \\rvert \\cdot \\cos(\\theta - \\gamma) $$ Che √® massima quanto il valore nel coseno √® 1 (coseno 0), minima quando √® 0.\nMa esiste solamente un unico vettore unitario per cui succede, questa √® la direzione che rende massima la derivata. dunque $\\theta = \\gamma$ e quindi\n$$ v_{max} = \\dfrac{\\nabla f(a,b)}{ \\lvert \\nabla f(a,b) \\rvert } $$ Osservazione:\nAvendo il vettore di direzione per il massimo possiamo calcolare effettivamente il valore della derivata direzionale massima, questa √® effettivamente uguale al gradiente:\n$$ \\langle \\nabla f(a,b), v_{max})\\rangle = \\mid\\nabla f(a,b)\\mid $$ 10.4 Derivate di curve Consideriamo le curve (anche chiamati cammini in Rn)\nDue funzioni\nScalari da Rn a R Cammini parametrizzati (da un sottoinsieme di ab a Rn) In seguito saranno utili per comprendre gli insiemi di livello di f.\n10.4.1 Cammini I cammini sono una funzione da R a Rn.\nSono utili in fisica per descrivere il concetto di percorso (traiettoia) e simili\nVelocit√† di un cammino\npossiamo definire una dimensione di velocit√† di un cammino in questo modo:\nNota: non √® il gradiente, perch√© qui la derivata √® una sola, solo per funzioni differenti.\nQuella derivata (il vettore) √® velocit√† al tempo t.\n10.4.2 Nozioni di fisica (velocit√† e accelerazione) Velocit√† scalare:\nQuando la derivata √® nulla in tutti i punti si dice che quel punto della traiettoria √® un punto singolare\nAccelerazione:\n10.4.3 Taylor per curve Altro\n10.4.4 Derivata lungo una curva (!!) Introduzione intuitiva della derivata\nCome si nota, la curva non √® detto che sia derivabile, quindi prima la parametriziammo, e poi calcoliamo la derivata della funzione composta, e nient‚Äôaltro.\n10.4.5 Ortogonalit√† del differenziale (!) Dimostrazione veloce veloce\nCalcolo di queste derivate (idea) Se dobbiamo calcolare qualcosa di complesso, tipo\nf una funzione differenziabile, e voglio la derivata di $f(h_1(s),..., h_n(s))$ posso crearmi una funzione di appoggio, che possiamo anche chiamare la parametrizzazione della funzione come\n$r(s) = (h_1(s),...,h_n(s))$ e calcolarmi la derivata di $f(r(s))$ che abbiamo discusso sopra, alla fine avr√≤ qualcosa del tipo\n$\\delta_{e_1}f(r(s))\\delta_s(h_1(s)) + ... + \\delta_{e_n}f(r(s) \\delta_s(h_n(s))$\n","permalink":"https://flecart.github.io/notes/calcolo-differenziale/","summary":"10.1 Derivata parziale La derivata vuole descrivere quanto varia una funzione al variare dell\u0026rsquo;input. Ma ora siamo in pi√π dimensioni, quindi vogliamo descrivere il variare dell\u0026rsquo;input come il variare della distanza euclidea\n$\\dfrac{\\delta f}{\\delta x}(x,y) = \\lim _{h \\to 0} \\dfrac{f(x + h, y) - f(x, y)}{h}$ ovvero sto facendo variare solamente una variabile (la y in questo caso √® come se fosse una costante!?) Questo √® un rapporto incrementale su una direzione.","title":"Calcolo differenziale"},{"content":"Iterazione Questo metodo semplicemente consiste di calcolare tutte le operazioni e scriverlo con una notazione asintotica.\nslide\nSostituzione (induzione) slide\nAnalisi della relazione di ricorrenza di fibonacci\nSi pu√≤ dimostrare utilizzando l\u0026rsquo;induzione che una relazione di questo tipo\n$$ T(n) = \\begin{cases} O(1) \\\\ T(n-1) + T(n-2) + 1 \\end{cases} $$ Si trova che √® $O(2^n), \\Omega(2^{n/2})$\nAnalisi finale.\nSi pu√≤ creare una stima corretta, utilizzando la formula per il calcolo di fibonacci (che dimostri facendo osservazioni su una funzione generatrice di essa, una serie infinita).\nAlbero di ricorsione slide\nTeorema dell‚Äôesperto (master) Questo teorema permette di stabilire subito la stima asintotica per tutte le ricorrenze nella forma\n$T(n) = aT(n/b) + f(n)$ ed √® diviso in tre casi:\n23/03 Ricordo tutto come se fosse ieri 09/04 Non ti ricordi esattamente tutto (teoricamente albero di ricorsione, ma in pratica non lo so se lo fa) in tre casi: 23/03 Ricordo tutto come se fosse ieri 09/04 Non ti ricordi esattamente tutto (teoricamente albero di ricorsione, ma in pratica non lo so se lo fa) ","permalink":"https://flecart.github.io/notes/relazioni-di-ricorrenza/","summary":"Iterazione Questo metodo semplicemente consiste di calcolare tutte le operazioni e scriverlo con una notazione asintotica.\nslide\nSostituzione (induzione) slide\nAnalisi della relazione di ricorrenza di fibonacci\nSi pu√≤ dimostrare utilizzando l\u0026rsquo;induzione che una relazione di questo tipo\n$$ T(n) = \\begin{cases} O(1) \\\\ T(n-1) + T(n-2) + 1 \\end{cases} $$ Si trova che √® $O(2^n), \\Omega(2^{n/2})$\nAnalisi finale.\nSi pu√≤ creare una stima corretta, utilizzando la formula per il calcolo di fibonacci (che dimostri facendo osservazioni su una funzione generatrice di essa, una serie infinita).","title":"Relazioni di Ricorrenza"},{"content":"In questa nota andiamo a parlare in modo sommario (si impara probabilmente molto meglio con la pratica) di generali tipologie di approcci che esistono per affrontare problemi di tipo algoritmico.\nDivide et impera Introduzione Abbiamo gi√† visto L\u0026rsquo;utilizzo di questa tecnica per quick e merge sort in Algoritmi di ordinamento\nQuesta tecnica si focalizza in tre passi fondamentali:\nDividere il problema in sotto-problemi Risolvere il sotto-problema Mergiare le soluzioni di questi sotto-problemi. Questa √® pi√π una tecnica che si impara di pi√π con la pratica, andremo a fare un problema che utilizza questa tecnica\nLa torre di Hanoi Enunciato\nSoluzione con ricorsione\nMoltiplicazione fra interi Questo potrebbe sembrare semplice. In realt√† per numeri pi√π grandi del limite dei registri (le macchine moderne sono tutte a registri, secondo il modello di Estensioni di Turing e altre macchine#Macchine a registri). Quindi possiamo provare algoritmi che funzionano bene per lunghezza infinita.\nSi utilizza una tecnica divide ed impera per moltiplicare assieme i due numeri. Quindi divido il numero in parte superiore e parte inferiore\u0026hellip;\nPrima applicazione\nMa si potr√† notare che questo metodo non porta a migliroamenti\nMoltiplicazione pi√π efficiente\nSottovettore di valore massimo Questo √® un problema classico che ho gi√† riscontrato in maximum subarray sum.\nAlgoritmo banale\nVa a guardare tutte le sottosequenze possibili, che sono O(N2) perch√© √® uguale al numero di coppie di indici (ordinate) che si possono prendere.\nAlgoritmo Divide et Impera\nSi nota che la massima sottosequenza √® o nella parte destra o sinistra, oppure in mezzo, quindi si conside\nAlgo\nGreedy Greedy √® buono quando si pu√≤ Dimostrare (e se non lo dimostri perdi un sacco di tempo a implementare una soluzione che non √® nemmeno giusta) e si basa sui sottoproblemi ottimali.\nProblema del resto In cui basta scegliere la moneta migliore ogni volta (perch√© sicuramente(con piccolo ragionamento) ci vorranno meno monete rispetto a usare altre)\nUn osservazione √® che pu√≤ fallire in sistemi non CANONICI.\nJob scheduling Si avr√† che basta ordinare secondo la lunghezza minore (perch√© si guadagna sempre in questo caso)\nHuffman coding Questo problema √® stato trattato meglio in Kolmogorov complexity legati a cose come Entropy. Si crea un albero di codifica che sia il meno profondo possibile, in questo modo ho un modo pi√π formale per giustificare il fatto di avere la minima codifica.\nPseudocodice per l‚Äôalbero di huffman.\nHuffman(real f[1..n], char c[1..n]) ‚Üí Tree Q ‚Üê new MinPriorityQueue() integer i; for i ‚Üê 1 to n do z ‚Üê new TreeNode(f[i], c[i]); Q.insert(f[i], z); endfor for i ‚Üê 1 to n ‚Äì 1 do z1 ‚Üê Q.findMin(); Q.deleteMin(); z2 ‚Üê Q.findMin(); Q.deleteMin(); z ‚Üê new TreeNode(z1.f + z2.f, \u0026#39;\u0026#39;); z.left ‚Üê z1; z.right ‚Üê z2; Q.insert(z1.f + z2.f, z); endfor return Q.findMin(); Programmazione dinamica Abbiamo risolto fibonacci, Maximum subarray sum con la programmazione dinamica, entrambi in O(n). Ora andiamo a parlare del problema pi√π importante per la programmazione dinamica, il problema dello zaino\nKnapsack problem Distanza di levenstein Seam Carving ","permalink":"https://flecart.github.io/notes/tecniche-algoritmiche/","summary":"In questa nota andiamo a parlare in modo sommario (si impara probabilmente molto meglio con la pratica) di generali tipologie di approcci che esistono per affrontare problemi di tipo algoritmico.\nDivide et impera Introduzione Abbiamo gi√† visto L\u0026rsquo;utilizzo di questa tecnica per quick e merge sort in Algoritmi di ordinamento\nQuesta tecnica si focalizza in tre passi fondamentali:\nDividere il problema in sotto-problemi Risolvere il sotto-problema Mergiare le soluzioni di questi sotto-problemi.","title":"Tecniche algoritmiche"},{"content":"https://huyenchip.com/2023/05/02/rlhf.html √® un blog post che lo descrive in modo abbastanza dettagliato e buono.\nIntroduzione a RLHF Questo √® il processo che √® quasi la migliore per la produzione di LLM moderni (maggior parte si basano su questo per dire).\nStruttura generale Si pu√≤ dire che RLHF si divida in 3 parti fondamentali\nCompletion il modello viene allenato a completare parole dal web,solitamente √® molto inutile Fine tuning per le singole task, per esempio riassumere, rispondere in certo modo etc. Reinforcement Learning basato su un reward model scoperto. Partiamo con l\u0026rsquo;approccio di reinforcement learning che √® la parte un po\u0026rsquo; pi√π interessante in questo momento\nHuman Feedback Introduzione al metodo Dato che utilizziamo gli LLM come aiutanti per noi umani, √® importante che il loro output sia il pi√π possibile allenato sulle preferenze di noi umani. Per questo motivo dobbiamo creare un metodo che permetta di allenare il modello basandoci su queste preferenze.\nThe reward model Come descritto da (Ziegler et al. 2020), un approccio inizialmente utilizzato √® provare a definire in modo esplicito un modello $r(x, y)$ in cui $x$ √® il prompt iniziale e $y$ √® la completion data dal modello. Segue poi uno schema del genere: $y_{1}, y_{2}, y_{3}, y_{4}$ generati dal modello, poi questi vengono rankati in ordine di preferenza (oppure anche solamente il migliore fra i quattro, poi si utilizzano 4 e non due in questo papero perch√© cos√¨ una persona pu√≤ scegliere, solo pi√π veloce per dire). E da questo si pu√≤ allenare in un modo che non ho ancora capito una cosa di preferenza.\nReferences [1] Ziegler et al. ‚ÄúFine-Tuning Language Models from Human Preferences‚Äù 2020\n","permalink":"https://flecart.github.io/notes/the-rlhf-pipeline/","summary":"https://huyenchip.com/2023/05/02/rlhf.html √® un blog post che lo descrive in modo abbastanza dettagliato e buono.\nIntroduzione a RLHF Questo √® il processo che √® quasi la migliore per la produzione di LLM moderni (maggior parte si basano su questo per dire).\nStruttura generale Si pu√≤ dire che RLHF si divida in 3 parti fondamentali\nCompletion il modello viene allenato a completare parole dal web,solitamente √® molto inutile Fine tuning per le singole task, per esempio riassumere, rispondere in certo modo etc.","title":"The RLHF pipeline"},{"content":"Metodi di registrazione informazione Ci stiamo chiedendo in che modo possiamo registrare attivit√† del cervello e quindi cercare di fare decoding delle informazioni presenti Prima parliamo di alcune tecniche non invasive che ci permettono di vedere alcune attivit√† presenti nel cervello.\nMetodi macroscopici Functional Magnetic Resonance Imaging Un metodo √® fMRI. (ci sono cose ) TODO capire come funziona\nElectro-Encephalo-Gram EEG che prende direttamente dai segnali Ma il drawback di entrambi √® che non registrano attivit√† del singolo array.\nMetodi a livello cellulare Electrode arrays Ci permette di registrare voltaggi di singoli neuroni (quindi capire se √® in spike o meno). Solitamente si mette il tessuto cellulare direttamente su questo strato di elettrodi.\nIn modo simile si pu√≤ anche misurare la differenza di potenziale studiata in Campo elettrico, con una pipetta sonda, di solamente qualche micrometro di diametro, in modo da non danneggiare molto la membrana cellulare.\nCalcium Imaging Alcune cellule cambiano colore quando assorbono calcio, e si pu√≤ utilizzare questo segnale visivo per capire se sta sparando o meno.\nNeural codes Consideriamo una serie di neuroni su un array di elettrodi a cui √® sottoposto a uno stimolo visivo. Utilizziamo un raster plot per capire il momento nel tempo in cui sparano, e otteniamo cos√¨ un diagramma delle attivazioni di un neurone.\nVogliamo utilizzare un sistema probabilistico per gestire tutto sto rumore di cos√¨ tanti neuroni. Una cosa tipo\nQuant\u0026rsquo;√® la probabilit√† che il neurone si attivi dopo questo stimolo? encoding (come viene memorizzato questo input). Quant\u0026rsquo;√® la probabilit√† che il neurone si attivi per questo stimolo? decoding (motivo per cui si √® attivato diciamo). Cosa interessante, se diamo rumore white a caso preso da una gaussiana, e poi prendiamo le risposte, queste risposte sono disposte in modo gaussiano. Questo sistema con il gaussiano ci permette di trovare la feature ossia le attivazioni precedenti, il pattern diciamo, che contribuisce all\u0026rsquo;attivazione del neurone corrente.\n","permalink":"https://flecart.github.io/notes/analysis-of-neural-codes/","summary":"Metodi di registrazione informazione Ci stiamo chiedendo in che modo possiamo registrare attivit√† del cervello e quindi cercare di fare decoding delle informazioni presenti Prima parliamo di alcune tecniche non invasive che ci permettono di vedere alcune attivit√† presenti nel cervello.\nMetodi macroscopici Functional Magnetic Resonance Imaging Un metodo √® fMRI. (ci sono cose ) TODO capire come funziona\nElectro-Encephalo-Gram EEG che prende direttamente dai segnali Ma il drawback di entrambi √® che non registrano attivit√† del singolo array.","title":"Analysis of Neural Codes"},{"content":"Introduzione a Crittografia al corso di crittografia di Christof Paar su Youtube, con aggiunte del corso Unibo.\nClassifications and definitions Classification nowadays as many many applications like, and it‚Äôs a increasing important field\nCryptology (2) üü© La branca comunemente riferita come crittografia √® divisa principalmente in due campi crittografia e cryptanalysis in cui una cerca di creare nuovi metodi per cifrare i messaggi, e l‚Äôaltro prova ad attaccare questi messaggi ritrovando il messaggio originale.\nRelazione con Sicurezza informatica üü© Questo campo si pu√≤ considerare una piccola branca della sicurezza informatica, che √® praticamente necessaria per la sicurezza, per√≤ allo stesso tempo non pu√≤ essere utilizzata da sola, ha bisogno anche di sistemi operativi sicuri, hardware sicuro etc‚Ä¶\nCryptography üü© Questo √® quello che ci interessa, ed √® ci√≤ che il corso tratta.\nSymmetrical ciphers Asymmetrical ciphers Protocols Classification of cryptoattacks 3 üü©- We define attack vector as a possible way to attack a cipher\nClassical Cryptanalisys Bruteforce Analytical attacks (Properties of the Cipher, useful to decrypt it) Social engineering (like a people that gives you the key) (phishing) Implementation attacks (Attack hardware to discover key) Side channel analysis (eg. power consumption related to the key). Ovviamente questi sono molto diversi rispetto ai reali (nella vita reale ci sono molti attack vectors), secondo la Jocelyne, sembra che crypto sembra una scienza perch√© definisci metodi di risoluzione di errore per singolo attack vector, che puoi dimostrare come solido, ma nella vita reale credo che hai bisogno che sia valido per ogni tipologia di attacco (ne basta una per distruggerti e ritrovare la chiave diciamo).\nSymmetric cryptography Vogliamo cercare di trovare un modo di comunicare attraverso un canale di comunicazione insicuro, questo √® il problema principale di questa critografia.\nCanali insicuri possono essere per esempio\nInternet Wifi Setting classico del problema di comunicazione\nAllora introduco uno step di criptazione e decrittazione fra il pirmo e l‚Äôultimo comunicante.\nQuesto √® un scenario leggermente pi√π generale, in cui nel mezzo c'√® un attaccante, solitamente un *eve* o altro che ha accesso a $c$ e prova a decrittare. On security of cipher One important note is that the security of the cipher is not enough to mantain a security of the algorithm. But experience says it‚Äôs not! (Ma nonostante questo √® stato fatto per centinaia e centinaia di anni, ora sappiamo che √® cosa stupida).\nAnd a bad thing about this is that there is no clear way to know if a cipher is secure or not, usually what is done is that the algorithm is made public and if nobody knows how to break it is considered secure.\nAnd it‚Äôs very easy to build something that is breakable!!!\nKerckhoffs‚Äô Principle 1883 Enunciato kerckhoff üü©- This is the most important principle of the course!\nA cryptosystem should be secure even if the attacker (oscar in this case) knows all the details about the system, with the exception of the secret key.\nHow can we make sense of this? This is counterintuitive. Maybe because in the past there were like two keys, the key and the algorithm itself, seems like that this setting didn‚Äôt help to have a better security. But historically speaking, this principle seems to hold.\nSubstitution cipher Vedere #Affine and Caesar Cipher per definizione formale.\nThis was one of the oldest ciphers in history. (Old and stupid ciphers by the Professor).\nHistorical ciphers Operates on letters (solitamente delle permutazioni) Replace ever plaintext letter by a fixed ciphertext letter, this was the main idea. Examples\nCaesar Cipher, replace with a shift (bruteforce easy attack! The keyspace is very small) Function that replaces each letterwith another letter with bijective. bruteforce, it‚Äôs too big for a braindead bruteforce to attack this function. 26! Frequency attack because in the language the letters are not equally distributed! And this works. (when the most frequent letter is discovered a big part of ciphertext is found!) And a bad thing is that same letter to same letter (frequency attack)!!!! Attacco di frequenza üü© In teoria la chiave √® una permutazione (nel caso di vigenere, quindi avremmo $26! \\approx 2^{88}$ di keysize, per√≤ un attacco di frequenza √® troppo forte per questo genere di cifrari. Fatto per la prima volta da Al-Kindi 800 AD.\nAttacco brute-force üü© Un modo semplice, ma non molto pratico per fare questa definizione √® la corrente: dati una coppia $M, C$ di plaintext e ciphertext, un attacco bruteforce su un insieme di chaivi $K = \\left\\{ k_{1}, k_{2}, \\dots \\right\\}$ consiste nel provare almeno una chiave (solitamente unica) per cui vale $$ D(C, k_{i}) = M $$ Ossia la chiave che usando $D$ abbiamo il plaintext. Solitamente questo valore non si pu√≤ calcolare, perch√© avremmo bisogno di $M$, quindi abbiamo il problema dei falsi positivi all\u0026rsquo;interno del nostro spazio di interesse. (vedere sezione 5.2 di (Paar \u0026amp; Pelzl 2010))\nVigen√®re Cipher Esempio intuitive Vigen√®re üü© Tentativo formalizzazione üü© Consideriamo una chiave $k = (k_{1}, k_{2}, \\dots, k_{l})$ Ognuno equivalente al shift presente in cesare #Affine and Caesar Cipher. Ripetiamo la chiave pi√π volte e cifriamo col shift cipher corrispondente ogni lettera. Questo fa nascere l\u0026rsquo;idea dei rotori senza problemi!\nAttacco a Vigen√®re üü© Guess the length of the key l using some methods Divide the cyphertext into l shift cipher encryptions Use frequency analysis on each shift cipher √à una specie di algoritmo, e si riutilizza la vulnerabilit√† presente sui shift ciphers normali. L\u0026rsquo;attacco a frequenza diventa pi√π difficile rispetto a Cesare, ma ancora possibile (molti ciphers indipendenti). Per il primo steps un plaintext attack √® facilissimo per esempio! Qualcuno ha fatto la domanda su come scoprire la lunghezza chiave alla prof. La prof non sa come attaccarlo, e ha detto solo bruteforce su lunghezza. Poi ha citato un caso di plain-text senza chiamarlo plain-text. Ma √® stata molto vaga. Bad. Ha detto anche entrare nel sistema per trovarlo\u0026hellip; lol.\nRotor machines Main idea of rotors üü®- Queste macchine sono nate principalmente nel secolo scorso, da queste idee\nMultiple rounds of substitution, encryption consists of mapping a letter many times ‚óã M Mechanical/electrical wiring to automate the encryption/decryption process La meccanizzazione √® stata risolta dal punto di vista del red team da Turing, che ha dato un contributo fondamentale (Turing 1950).\nEsempi storici di rotor machines I moderni simili sono DES e AES, li tratteremo un po' pi√π avanti. ### Security of the Key Note sulla lunghezza della chiave (non fare) Andiamo in questa parte a misurare la sicurezza di una chiave di fronte agli attacchi. Una prima nota molto importante √® il fatto che questa misura della lunghezza ha senso solamente quando si parla di bruteforce, infatti la lunghezza della chiave non pu√≤ difendere contro side-channel oppure frequency-attacks.\nLa lunghezza della chiave per cifrari simmetrici e asimmetrici cambia. Segretezza perfettaüü©- Secondo Shannon 1949. Consideriamo un cifrario $E, D$ su $K, M, C$, allora si dice che si ha perfect secrecy quando $\\forall m_{0},m_{1} \\in M$ tale per cui $\\lVert m_{0} \\rVert = \\lVert m_{1} \\rVert$ , dove $k$ √® una variabile aleatoria presa da $K$ (quindi fatto sampling due 2 volte). e $\\forall c \\in C$ $$ \\mathbb{P}(E(k, m_{0}) = c) = \\mathbb{P}(E(k, m_{1}) = c) $$ Detto in altre parole, se ho un certo cipher-text, ho la stessa probabilit√† di avere qualunque messaggio possibile di una certa lunghezza rispetto al messaggio iniziale. Quando succede questo there are no computational assumptions about the attacker, this is why this is also called unconditional security or perfect security.\nIl cyphertext potrebbe essere qualunque messaggio!, cio√® non posso attaccare il $c$ sapendo solo $c$ con la segretezza perfetta. Altri autori come Stinson definisco tale per cui $P(E|M) = P(E)$. Attualmente non mi √® chiaro se le due definizioni sono equivalenti.\nL\u0026rsquo;idea √® limitare qualunque informazione che si pu√≤ trovare dalla chiave come\nNon posso ritrovare la chiave dai processi di $E$ e $D$ Non posso ritrovare il plain-text da cipher-text. Se abbiamo questa propriet√† non posso fare ciphertext only attack, in altre parole, nessuna informazione da ciphertext only, perch√© viene eliminato tutto Una definizione equivalente sembra essere: dato un $M$ deve essere che $\\forall e \\in E, P(e|M) = P(e) \\not = 0$ qui Questo significa che il $e$ √® indipendente da M quando non si conosce la chiave, nel senso che non riesci prendere nessuna informazione (se inverti con Bayes dovresti avere stesso valore). Si pu√≤ dimostrare che la seconda definizione, pi√π l\u0026rsquo;ipotesi che $\\lvert K \\rvert = \\lvert P \\rvert = \\lvert C \\rvert$ √® equivalente alla prima (il contrario dovrebbe essere facile!?).\nSegretezza perfetta e lunghezza chiaveüü®+ Si pu√≤ dimostrare che per avere segretezza perfetta √® necessario avere\n$$ \\lvert K \\rvert \\geq \\lvert M \\rvert $$ Questa propriet√† rende cifrari come OTP molto difficili da usare nella pratica, perch√© non riusciamo a comunicare questo valore, che tra l\u0026rsquo;altro dovrebbe essere utilizzato una singola volta.\nProof: https://cs.ioc.ee/yik/schools/win2006/massey/slides1.pdf Dove $H$ √® l\u0026rsquo;informazione Shannon. quindi $H(P) = \\sum_{x} P(x)\\log\\left( \\frac{1}{P(x)} \\right)$, e la lunghezza √® strettamente dipendente dall\u0026rsquo;entropia. Questo Shannon lo ha dimostrato nel 1949.\nUna altra dimo √® su (Stinson 2005) 3.3, abbastanza ez.\nUnconditional security üü© La nota importante √® il fatto che sia infinito, anche se ho il tempo dell‚Äôuniverso o maggiore non posso mai rompere un cifrario sicuro incondizionalmente. (molti cifrari sicuri nella pratica quindi non sono sicuri sequendo questa definizione). Questo dovrebbe essere equivalente alla definizione di sopra si segretezza perfetta.\nCome vedremo c‚Äô√® un cifrario teoricamente sicuro, ma nella pratica di poco utilizzo\nAffine and Caesar Cipher Definizione shift cipher üü© Sono definizioni 1.4.3 presenti su (Paar \u0026amp; Pelzl 2010). Shift Cipher\nSiano $x,y,k \\in \\mathbb{Z}_{26}$ Allora l\u0026rsquo;encryption √® $$ e_{k}(x) \\equiv x + k, \\mod 26 $$ Mentre il decryption √® $$ d_{k}(y) = y - k \\mod 26 $$ Definizione affine cipher üü© Affine cipher Siano $x, y, a, b \\in \\mathbb{Z}_{26}$ Encryption: $$ e_{k}(x) = y \\equiv a\\cdot x + b \\mod 26 $$ Decryption $$ d_{k}(y) = x \\equiv a^{-1}\\cdot(y - b) \\mod 26 $$ Con la restrizione del fatto che affinch√© $a$ sia invertibile dobbiamo avere $gcd(a, 26) = 1$\nAritmetica modulare Guardare Algebra modulare, perch√© √® praticamente quella stessa roba, molto importante crittografia, ma andiamo a trattare in un altro modo\nSul modulo üü© Il resto non √® unico! ci possono essere molte cose che soddisfano quelle cose Il resto si pu√≤ considerare una classe di equivalenza. Anelli üü© Un anello √® un insieme di elementi su cui sono definite certe propriet√† di interesse.\nEsiste somma e prodotto e sono chiusi. E ci sono molte altre cose‚Ä¶ L‚Äôinverso non ci deve stare\nReferences [1] Stinson ‚ÄúCryptography: Theory and Practice, Third Edition‚Äù CRC Press 2005\n[2] Paar \u0026amp; Pelzl ‚ÄúUnderstanding Cryptography: A Textbook for Students and Practitioners‚Äù Springer 2010\n[3] Turing ‚ÄúI.‚ÄîCOMPUTING MACHINERY AND INTELLIGENCE‚Äù Mind Vol. LIX(236), pp. 433\u0026ndash;460 1950\n","permalink":"https://flecart.github.io/notes/classical-cyphers/","summary":"Introduzione a Crittografia al corso di crittografia di Christof Paar su Youtube, con aggiunte del corso Unibo.\nClassifications and definitions Classification nowadays as many many applications like, and it‚Äôs a increasing important field\nCryptology (2) üü© La branca comunemente riferita come crittografia √® divisa principalmente in due campi crittografia e cryptanalysis in cui una cerca di creare nuovi metodi per cifrare i messaggi, e l‚Äôaltro prova ad attaccare questi messaggi ritrovando il messaggio originale.","title":"Classical Cyphers"},{"content":"Lo scopo della logica √®\nCorrettezza del ragionamento, anche verificata attraverso algoritmi predittivi. Si svilupperanno linguaggi logici I metodi per la veridicit√† di una sentenza. Possibilit√† e metodi del ragionamento logico Completezza e non-deducibilit√† di alcuni ragionamenti Necessit√† di completezza delle ipotesi: pi√π ipotesi = ragionamento valido? Completezza delle tesi, impossibile. Una necessit√† della logica √® Meta-logica:\nLa logica si deve cercare di basare su certe basi, spesso queste non sono certe, per√≤ danno un certo grado di sicurezza ‚Üí Se la base √® solida allora tutto il ragionamento di una parte √® giusta\n0.1 Storia Questo campo di studi √® nato dopo una necessit√† del secolo precedente quando si tentava di dare delle basi solide alla matematica ‚Üí La matematica (e informatica)si fonda sulla logica.\nGuardare la storia di Russel, Godel.\n0.2 Tipologie di logica 0.3 Processo di ragionamento Slide 18 per esempio di problema risolto con questo processo.\n0.4 Differenze con la matematica La matematica si interessa principalmente sull\u0026rsquo;esistenza di soluzioni, e dimostrazioni, ma non rigorose quanto le dimostraizoni logiche. L\u0026rsquo;informatica applicata classica √® meno rigorosa, si basa principalmente sui test, anche se un logico pu√≤ dimostrare la correttezza di una soluzione informatica.\nInoltre l\u0026rsquo;informatica indaga la possibilit√† di implementazione di alcune soluzioni matematiche, cio√® il modo per calcolare possibili soluzioni, anche con la limitatezza delle risorse.\n0.5 Logica in programmazione 0.5.1 Usi e costi C\u0026rsquo;√® un altissimo costo per la dimostrazione formale di un programma, secondo i dati Intel c\u0026rsquo;√® bisogno di circa 10x mesi uomo per creare una dimostrazione assistita di questo genere.\nPer questo genere viene utilizzato solamente in software critico cio√® il codice che controlla processi che se buggati possono creare ingenti danni economici, come centrali nucleari, smartcard, microprocessori Intel, controlli aereo e simili\n0.5.2 Processo di dimostrazione Definire la specifica del software in modo che possa fare sempre ci√≤ che deve fare Creare la semantica del programma, come il programma √® eseguito. Formula logica che √® la descrizione formale del funzionamento del programma. Creare una implicazione fra ci√≤ che il software deve fare secondo la semantica e ci√≤ che veramente fa. Non perdere punti 1 Logica Proposizionale 1.1 Senso e denotazione Sentenza\nDichiarativa quando √® assertiva, ovvero dichiara una proposizione di verit√†. Nomi\nPu√≤ avere funzioni denotative e connotative (il senso), spesso questo concerne solamente il problema denotativo Proposizioni\nSono delle sentenze che hanno un chiaro valore di verit√† Possono essere atomiche o composte. esso questo concerne solamente il problema denotativo Proposizioni\nSono delle sentenze che hanno un chiaro valore di verit√† Possono essere atomiche o composte. ","permalink":"https://flecart.github.io/notes/introduzione-a-logica/","summary":"Lo scopo della logica √®\nCorrettezza del ragionamento, anche verificata attraverso algoritmi predittivi. Si svilupperanno linguaggi logici I metodi per la veridicit√† di una sentenza. Possibilit√† e metodi del ragionamento logico Completezza e non-deducibilit√† di alcuni ragionamenti Necessit√† di completezza delle ipotesi: pi√π ipotesi = ragionamento valido? Completezza delle tesi, impossibile. Una necessit√† della logica √® Meta-logica:\nLa logica si deve cercare di basare su certe basi, spesso queste non sono certe, per√≤ danno un certo grado di sicurezza ‚Üí Se la base √® solida allora tutto il ragionamento di una parte √® giusta","title":"Introduzione a Logica"},{"content":"Softmax is one of the most important functions for neural networks. It also has some interesting properties that we list here. This function is part of The Exponential Family.\nDefinition of the function The softmax function is usually defined as follows:\n$$ \\text{ softmax } (h, y, T) = \\frac{\\exp\\left( \\frac{h_{y}}{T} \\right)}{\\sum_{y' \\in \\mathcal{Y}} \\exp\\left( \\frac{h_{y'}}{T} \\right)} $$ The softmax takes the vector $\\vec{h}$ into a simplex which is useful for categorical distributions. For this reason, often the output is not exactly correct to say we have a probability distribution (we don\u0026rsquo;t often have priors), but in practise it\u0026rsquo;s a useful concept.\nThe simplex The $K$ dimensional simplex $\\Delta^{K - 1}$ is the region of $\\mathbb{R}^{K}_{\\geq 0}$ where the sum of components is 1. Down here we have an example of the $\\Delta^{2}$ simplex. The role of temperature The $T$ parameter is a non-negative parameter that tells us how much spread our categories are. If $T \\to 0$ we have the $\\max$ function automatically. if $T \\to \\infty$ we have maximum entropy, so we have uniform categorical distribution. So $T$ allows us to smoothly interpolate between argmax and uniform distribution. The interesting thing is that it is a differentiable version of the max, which byitself is not differentiable.\nWe have that $$ \\lim_{ T \\to 0 } \\text{softmax}(\\vec{h}) = \\begin{cases} [1, 0]^{T}, h_{1} \u003e h_{2} \\\\ \\left[ \\frac{1}{2}, \\frac{1}{2} \\right]^{T}, h_{1} = h_{2} \\\\ [0, 1]^{T}, h_{1} \u003c h_{2} \\end{cases} $$ If we have $\\vec{h} = [h_{1}, h_{2}]$. This is a easy giustification of why we call this softmax.\nThe partial derivative We can calculate the derivative of the log softmax and we obtain:\n$$ \\frac{ \\partial \\log \\text{ softmax }(\\vec{h}, y) }{ \\partial h_{i} } = \\delta_{yi} - \\text{softmax} (\\vec{h}, i) $$ ","permalink":"https://flecart.github.io/notes/softmax-function/","summary":"Softmax is one of the most important functions for neural networks. It also has some interesting properties that we list here. This function is part of The Exponential Family.\nDefinition of the function The softmax function is usually defined as follows:\n$$ \\text{ softmax } (h, y, T) = \\frac{\\exp\\left( \\frac{h_{y}}{T} \\right)}{\\sum_{y' \\in \\mathcal{Y}} \\exp\\left( \\frac{h_{y'}}{T} \\right)} $$ The softmax takes the vector $\\vec{h}$ into a simplex which is useful for categorical distributions.","title":"Softmax Function"},{"content":"Introduzione Nozioni base Questi sono le parole chiave di questo capitolo, ci permettono di parlare con chiarezza riguardo l‚Äôagente logico.\nSentence\nKnowledge Base\nAxiom\nInference\nbackground knowledge\nKnowledge representation language\nKnowledge level\nImplementation level\nEsempio generale di agente logico\nLogica proposizionale Sintassi del linguaggio Descrivere la BNF della logica proposizionale.\nper sapere cosa sia la BNF di questo √® molto pi√π facile rifarsi agli appunti di logica presi durante l‚Äôanno di corso 2021/2022 Logica Proposizionale.\nDeduzione o derivazione Abbiamo ora un algoritmo (stupido) di verifica sul fatto se valga o meno $KB \\vDash \\alpha$, ovvero vogliamo sapere se alpha si pu√≤ derivare dal nostro modello\nAlgoritmo di derivazione\nInferenza ‚Üí (sound and complete inference methods) Risoluzione La risoluzione √® una operazione che si pu√≤ avere fra due clausole, come se fosse una regola di derivazione, come vedremo ci sta molto comodo, anche se non l‚Äôabbiamo mai fatta a lezione.\nIn breve:\nConsiste di eliminare qualche caso banale negli OR e.g. se ho a or b or c, e ho anche not a, allora posso dedurre b or c.\nSono interessanti soprattutto perch√© √® una operazione completa, cio√® che √® in grado di derivare tutto il derivabile (quindi se gli dai 2 clausole random, $\\alpha, \\beta$ riesce sempre a determinare se vale o meno $\\alpha \\vDash \\beta$.\noltre a ci√≤ sono anche sound, ossia quello che deducono √® corretto (non fanno mai teoremi sbagliati).\nPerch√© funziona\nIn pratica prova a dimostrare che not tesi‚Üí assurdo. e questa √® gestibile perch√© √® in forma congiuntiva normale, che permette di utilizzare la risoluzione\nAlgoritmo per la risoluzione\nCheck del modello Modelli di inferenza Conjunctive Normal Form Quando abbiamo delle clausole, ossia delle disgiunzioni di letterali, possiamo cercare di trasformare questa nella sua forma congiuntiva normale. Questo √® possibile perch√© ogni proposizione si pu√≤ ridurre a And e Or.\nBNF della CNF\nAndare a vedere questo per un algoritmo che utilizzi questa forma per runnare.\nForward Chaining Horn Clauses Una horn clause √® una proposizione composta di and, in cui al messimo un singolo valore √® vero.\nSi √® scoperto che esiste un algoritmo molto efficiente per checkare se una proposizione √® vera in un modello (che eseguen in O(n))\nIn pratica √® una cosa molto simile in And-or search presentato in Problemi di ricerca.\nAlgoritmo in breve\nPraticamente √® una BFS che prende come queue iniziale tutte le proposizioni atomiche che sono date per vere.\nUna volta poppati questi vanno a diminuire il conteggio degli implica che lo hanno come ipotesi. Se il singolo implica ha questo counter del numero di ipotesi necessarie che va a 0, allora si hanno nuove ipotesi.\nDa notare che questo funziona solamente per HORN CLAUSES perch√© ci fa molto comodo avere un unico effetto derivato da una serie di di ipotesi in AND iniziali.\nAlgoritmo\nAgente logico Frame problem Conclusione Creazione di Plan con SAT solvers Incapacit√† della logica proposizionale col tempo ","permalink":"https://flecart.github.io/notes/agente-logico/","summary":"Introduzione Nozioni base Questi sono le parole chiave di questo capitolo, ci permettono di parlare con chiarezza riguardo l‚Äôagente logico.\nSentence\nKnowledge Base\nAxiom\nInference\nbackground knowledge\nKnowledge representation language\nKnowledge level\nImplementation level\nEsempio generale di agente logico\nLogica proposizionale Sintassi del linguaggio Descrivere la BNF della logica proposizionale.\nper sapere cosa sia la BNF di questo √® molto pi√π facile rifarsi agli appunti di logica presi durante l‚Äôanno di corso 2021/2022 Logica Proposizionale.","title":"Agente Logico"},{"content":"Cook Levin theorem is important because says that in 1971 if $SAT \\in P$ then $NP = P$. We will start with this idea to define the concept of NP-completeness. Let\u0026rsquo;s start with the basics.\nPoly-reduction Def: poly-reductionüü© We say that two languages $L$ and $L'$ defines over alphabet $\\Sigma$. We say that $L¬¥$ is poly (mapping)-reducible in $L$, $L' \\leq_{p} L$ when a $TM$ that computes polynomial time a function $f: \\Sigma^{*} \\to \\Sigma^{*}$ such that $$ x \\in L' \\iff f(x) \\in L $$ This is very similar to the Halting Theorem and Reducibility#Mapping reducibility. The difference is that it needs to be polynomially-bounded, so to say, it is efficient function.\nTh: $L' \\leq_{p} L \\land L \\in P \\implies L' \\in P$üü© This theorem says that if we can reduce with a polynomially bounded function to a class of language in $P$ then we have automatically another language in $P$.\nProof: If $L \\in P$ there exists a $g$ that decides it in poly-time. If $L' \\leq _p L$ then exists $TM$ that polynomially computes a language into $L$, calculating $f$. Then we build this machine:\nGiven $x \\in L'$ in input, we say $g(f(x))$ decides that language. And we know that composition of polynomial functions is polynomial. So that function is polynomial and we proved it.\nTh: $L \\in P \\implies L^{-} \\leq_{p} L$üü© Given a $\\omega$ let\u0026rsquo;s run the decider to know whether if $\\omega \\in L$. If we know this then we know if $\\omega \\in L'$ or not just by inverting the last result. Now let\u0026rsquo;s build the converter, which works in constant time. Take two words $\\omega_{1}, \\omega_{2}$ such that $\\omega_{1} \\in L \\land \\omega_{2} \\not \\in L$ then if $\\omega \\in L' \\implies f(\\omega) = \\omega_{1}$ and if $\\omega \\not \\in L' \\implies f(\\omega) = \\omega_{2}$ this ends the proof. $f$ works in polynomial time thanks to the fact that $L \\in P$.\nCook-Levin Theorem Def: NP-completenessüü© We say that a $L$ is NP-complete if it is in $NP$ and every other $L'$ is reducible in $NP$ using #Poly-reduction.\nDef: NP-hardüü© $L$ is NP-hard if every $L'$ in $NP$ in reducible to it using #Poly-reduction. We don\u0026rsquo;t need that it is in $NP$.\nTMSATüü® This is a universal verifier. $$ TMSAT = \\left\\{ \\langle x, w, s,t \\rangle \\mid x = code(M) \\text{ and } M \\text{ accepts } \\langle w, c \\rangle \\right\\} $$ With other constraints of the length of the input and the time of the computation.\nAs this is a verifier we can prove that this language is $NP-complete$ but it is useless, because it says nothing on the class of problems.\nProblem statementüü© We want to prove that $SAT \\in NP-complete$ This is what Cook-Levin states.\nthis would imply that every other problem in $NP$ can be reduced into SAT, for example clique which is in NP, so we prove that $P = NP$\nProof of Cook-Levin SAT is in NPüü© This is quite easy, just non-deterministically take an assignment. If any of these assignments accept, then accept. We can say that SAT is easily verifiable.\nSAT is NP-hardüü®- This is the difficult part. The idea is to create a representation of the computation of the Turing Machine of whatever algorithm. So we create a tableau that represents the computation, and we want to translate this tableau as a satisfiability problem. We know that this tableau is finite because the problem is in $NP$.\nWe say that a formula is $$ F_{w} := F_{cell} \\land F_{start} \\land F_{move} \\land F_{accept} $$ And we want to say that this is satisfiable $\\iff$ exists a tableau as defined above such that accepts $\\iff$ a computation on $w$ of the machine $M$ accepts it.\nLet\u0026rsquo;s define $$ \\left\\{ x _{i, j, s} \\mid (i, j) \\in n^{k} \\times n^{k} ,s \\in Q \\cup \\Sigma \\cup \\left\\{ \\# \\right\\} \\right\\} $$ For example the variable $x_{1, 2, q_{0}}$ should be true. $$ F_{start} = x_{1, 1, \\#} \\land x_{1, 2, q_{0}} \\land \\\\ x_{1,3, w_{1}} \\land x_{1, 4, w_{2}} \\land \\dots \\land x_{1, n + 2, w_{n}} \\land \\\\ x_{1, n + 3, \\textvisiblespace} \\land \\dots \\land x_{1, n^{k} - 1, \\textvisiblespace x_{1, n^{k}, \\#}} $$ It means that the initial configuration is that of the Turing machine.\nThen $$ F_{cell} = \\bigwedge_{1 \\leq i, j \\leq n ^{k}} \\left[ (\\bigvee_{s \\in C} x_{i, j , s}) \\land (\\bigwedge_{s, t \\in C, s\\neq t} (\\bar{x}_{i, j, s} \\lor \\bar{x}_{i,j,t})) \\right] $$ In natural language: Exists at least a $s$ that is true, and other are false, for every cell in the tableau. That means that for every single cell, we have something like $x_{1, 2, a}$ which is true.\n$$ F_{accept} = \\bigvee_{1 \\leq i, j \\leq n^{k}} x_{i,j, T} $$ Then we need to define the $F_{move}$ function, which is the last formula we would need to define! As we only need to know how the state moves, we just need windows of 3.\nExamples: So for example: $$ F_{move} = \\bigwedge_{1 ","permalink":"https://flecart.github.io/notes/cook-levin-and-savitch/","summary":"Cook Levin theorem is important because says that in 1971 if $SAT \\in P$ then $NP = P$. We will start with this idea to define the concept of NP-completeness. Let\u0026rsquo;s start with the basics.\nPoly-reduction Def: poly-reductionüü© We say that two languages $L$ and $L'$ defines over alphabet $\\Sigma$. We say that $L¬¥$ is poly (mapping)-reducible in $L$, $L' \\leq_{p} L$ when a $TM$ that computes polynomial time a function $f: \\Sigma^{*} \\to \\Sigma^{*}$ such that $$ x \\in L' \\iff f(x) \\in L $$ This is very similar to the Halting Theorem and Reducibility#Mapping reducibility.","title":"Cook-Levin and Savitch"},{"content":"Introduzione al design logico Conoscenze sul carico dell\u0026rsquo;applicazione, ossia se ha pi√π read rispetto a writes per esempio, sono dei priors in pratica Un design concettuale spiegato in precedenza. E si avr√† in output un design logico con anche un po\u0026rsquo; di documentazione. bisogna in questa fase valutare la performance principalmente su indicatori, ossia una operazione quante istanze visiter√†? Invece di garanzie sul numero di transazioni al secondo.\nIndicatori visti (2) Costo di una operazione: viene valutato in termini di numero di occorrenze di entit√† e associazioni che mediamente vanno visitate per rispondere a una operazione sulla base d√¨ dati; questa schematizzazione √® molto forte e, pur nelle semplici valutazioni che svilupperemo, sar√† talvolta necessario riferirci a un criterio pi√π fine; Occupazione di memoria: viene valutato in termini dello spazio di memoria (misurato per esempio in numero di byte) necessario per memorizzare i dati descritti dallo schema.\nI volumi sono un concetto importante, sono una stima di quante entries dovranno avere, e serve per avere una idea di come progettare quella cosa. Bisogna utilizzare questi indicatori per valutare in che modo progettare la ristrutturazione e la logica.\nNOTA: C\u0026rsquo;√® un modo molto pi√π complicato per fare questa analisi, ma per questo corso √® ok valutare solo queste.\nMetodi di ristrutturazione E-R Redundancies analysis Per la ridondanza bisogna fare una analisi di efficienza per capire se √® buono o meno lasciare la ridondanza.\nTipologie di ridondanze (4) üü®+ Per il prof √® importante due cose:\nAttributi derivabili\nAssociazioni derivabili\nAttributi derivabili da cose della stessa entit√†\nAttributi derivabili da altri\nattributi derivabili da conteggio\nAssociazioni derivabili dalla composizione di altre associazioni in presenza di cicli\nEsempi: Nell\u0026rsquo;ultimo esempio, basta fare la join per avere quella informazione, un ciclo implica una ridondanza in pratica.\nGeneralizations deletion We need to delete the generalizations because in ER explained in Design del database the generalizations are not possible. A common way to fix this is embed children in the parent or something very similar.\nExample of deletion of generalization (3) üü©- In un caso abbiamo che il genitore prende tutti i campi. Oppure elimina il genitore e metti due relazioni Oppure crea relazioni col genitore Ma come fare a scegliere la versione corretta? Vogliamo prendere la soluzione che ci permette di minimizzare il numero di accessi, come per esempio se sappiamo che figli e genitori vengono acceduti insieme, ha senso usare la freccia in basso a sinistra! Partitioning or grouping of entities Se una stessa entit√† ha due attributi molto diverti, ossia c\u0026rsquo;√® solamente un accesso per uno, invece che per tutti, potrebbe avere senso dividerli. In modo simile se ho due entit√† che vengono spesso accedute assieme potrebbe essere una cosa sensata accorparli assieme.\nL\u0026rsquo;obiettivo √® sempre efficienza degli accessi.\nPartizionamento verticale o orizzontale üü©- Possiamo fare partizionamento in verticale o in orizzontale Verticale quando spezziamo una entit√† in due e le relazioniamo (utile quando accediamo solamente certe cose della tavola).\nOrizzontale quando ad esempio provo a dividere correnti e passati (dividere la stessa relazione in pi√π forme!). ### Identifying the primary keys (non fare) Questo passo √® chiaramente il passo necessario per utilizzare E-R nel nostro caso. Informazioni necessarie Le chiavi primarie in certi contesti possono essere complessi! E anche utili per identificare, non ho capito bene l\u0026rsquo;esempio del ferramenta fatto in classe (una nota √® che i ferramenta si fanno codici enormi e complessi come chiavi ed √® una brutta pratica probabilmente). Notare che saranno usate spesso, quindi non farle grosseeee! La cosa semplice √® creare codici identificativi, invece di avere chiavi complesse.\nTraduzione in schema logico Tradurre relazioni üü© Questa tabella riassume praticamente tutto. (303 Atzeni) La singola relazione üü© Una volta che abbiamo una relazione in E-R possiamo creare una tavola anche per questa parte! L\u0026rsquo;importante quando facciamo questo, bisogna encodare una referential integrity constraint che √® la cosa bella della tabella.\nLa nota √® che aggiungere la constraint non √® sufficiente per tenere in considerazione vincoli di cardinalit√†. Anche se √® n-aria si pu√≤ modellizzare senza troppi problemi!\n#### Relazioni ricorsive üü© La seconda tabella modella la parte ricorsiva (in teoria le due chiavi foreign dovrebbero essere code e code, ma il nome √® migliore in questo modo per esprimere questa relazione) Merge di relazioni A volte pu√≤ essere utile unire relazione con l\u0026rsquo;entit√†, succede spesso per relazioni unarie da una parte, perch√© cos√¨ faccio enforcing del 1. √à una cosa principalmente pratica, di difficile formalizzazione, ma deve passare l\u0026rsquo;idea diciamo.\n","permalink":"https://flecart.github.io/notes/database-logical-design/","summary":"Introduzione al design logico Conoscenze sul carico dell\u0026rsquo;applicazione, ossia se ha pi√π read rispetto a writes per esempio, sono dei priors in pratica Un design concettuale spiegato in precedenza. E si avr√† in output un design logico con anche un po\u0026rsquo; di documentazione. bisogna in questa fase valutare la performance principalmente su indicatori, ossia una operazione quante istanze visiter√†? Invece di garanzie sul numero di transazioni al secondo.\nIndicatori visti (2) Costo di una operazione: viene valutato in termini di numero di occorrenze di entit√† e associazioni che mediamente vanno visitate per rispondere a una operazione sulla base d√¨ dati; questa schematizzazione √® molto forte e, pur nelle semplici valutazioni che svilupperemo, sar√† talvolta necessario riferirci a un criterio pi√π fine; Occupazione di memoria: viene valutato in termini dello spazio di memoria (misurato per esempio in numero di byte) necessario per memorizzare i dati descritti dallo schema.","title":"Database logical design"},{"content":"Blockchain stack Vogliamo andare ora a descrivere la stack delle blockchain, in modo simile a quanto fatto con le internet, perch√© anche qui possiamo organizzarlo a stack!\nNota: le astrazioni fra questi layer non sono definiti bene come osi osint.\nLayer - 0 Internet Internet (semi-reliable point-to-point communication) and cryptography (specifically, cryptographic hash functions and secure digital signatures).\nLayer - 1 Consensus Ci concentreremo sui protocolli di questo per la maggior parte di quanto faremo! Bitcoin, Ethereum sono tutti a questo livello.\nLayer - 2 Scaling layer Strano lol, cerca di rendere il livello 1 pi√π efficiente. Le funzionalit√† sono le stesse, ma vorremmo che sia molto pi√π veloce, probabilmetne √® un livello temporaneo che scomparir√† in futuro, ma per ora si fa molta ricerca su questo.\nLayer - 3 application Che tratta di smart contracts e applicazioni utente. Easy su questa roba, troppa roba, quindi la possiamo ignorare, perch√© non andremo a fare cose a questo livello.\nWhy it‚Äôs new Computing paradigm Big programmable computer that lives on the sky! Owned by all users!\nOpen access computer! Global computational platform wo. Something with a very high potentiality!\nNot digital money! I soldi sono solamente un mezzo nuovo mezzo di scambio per questa robba. Ad esempio se utilizzi tropper risorse a questo computer, √® giusto che paghi l‚Äôenergia per runnare quello di cui hai bisogno!\nPrinciples over protocols Vogliamo andare ad individuare alcuniprincipi belli ** e vedere come vengono applicati sui protocolli!\n","permalink":"https://flecart.github.io/notes/introduzione-a-blockchain/","summary":"Blockchain stack Vogliamo andare ora a descrivere la stack delle blockchain, in modo simile a quanto fatto con le internet, perch√© anche qui possiamo organizzarlo a stack!\nNota: le astrazioni fra questi layer non sono definiti bene come osi osint.\nLayer - 0 Internet Internet (semi-reliable point-to-point communication) and cryptography (specifically, cryptographic hash functions and secure digital signatures).\nLayer - 1 Consensus Ci concentreremo sui protocolli di questo per la maggior parte di quanto faremo!","title":"Introduzione a blockchain"},{"content":"Ripasso: May 14, 2023 Ultima modifica: May 6, 2023 6:25 PM Primo Abbozzo: March 20, 2023 3:16 PM Studi Personali: No\nElementi di ripasso Javascript Obiettivo principale √® esegurie codice clientside\nUn p√≤ di storia nato all‚Äôinizio della prima guerra dei browser (da netscape, explorer √® in visual basic comunque non compatibile con JS) come il fratellino di java nel senso che runnava ovunque, attualmente √® ECMAScript, ed √® la versione migliore. (era pensato per fare microscript!)\nECMAScript quando √® nato √® il nucleo a tutte le implementazioni JS eseistenti fino a quel momento (che √® stato molto caotico!)\nAnche l‚Äôunico linguaggio che va sul browser. Typescript sarebbe molto carino üòÄ.\nEsecuzione di JS Client side o Server-side Possiamo eseguire server-side (node) per eseguire codice JS in server side, anche se non ho pi√π questa integrazione con il client (come eventi, e simili).\nOssia l‚Äôevento triggera il codice JS corrispondente!\nEsecuzione sincrona o asincrona\nSincrona = caricamento dello script (quando carica, il browser non fa altro! √à una cosa sincrona, quindi non carica altro HTML e simili).\nAsincrono su eventi DOM o callback di eventi di rete. (esempio chiamata AJAX asincrona, mentre la chiama sincrona √® molto brutto perch√© il server √® bloccatooo)\nBrevi e veloci per i sincroni! No n2.\nPosizionamento del codice (3) Si pu√≤ posizionare inline come il codice css Esempio 1.\nSezione script all‚Äôinizio, come style di css Esempio 2.\nFile separato Esempio 3.\nQuesti sono i metodi principali, solitamente si preferisce il terzo metodo per migliore gestione degli script.\nma col terzo metodo si deve fare molta attenzione sul tempo di caricamento dlelo script (che √® sincrona!)\nCose del linguaggio Cose come oggetti, arrays, somme, comparazioni, JSON, Dati, li hai fatti troppo dai.\nQuesto √® tutto ecmascript, mentre se andiamo ad interagire con il browser abbiamo altri metodi!.\nInterpolazione (!!) Se esiste una variabile visibile nello scope attuale, allora lo sostituisco nella stringa. Principalmente questo. Per la prima volta l\u0026rsquo;oggetto della computazione sono frammenti di HTML, questo permette di dividere html e JS (anche se non ho capito bene come).\nIIFE ! Queste sono funzioni dichiarate e subito eseguite, sono utili per avere delle variabili private. (con solamente gli oggetti infatti non √® possibile definire tali variabili.\nClient defined classes Un sacco di robe, non ha senso scriverle, quindi le enumero in modo molto breve qui\nWindow In pratica √® il tab della pagina di questo istante (sia in lettura sia in scrittura), contiene in s√© il documento.\nDocument Sono la rappresentazione in memoria del documento che √® mostrato (quindi ci sono tutti i nodi che ci importano!\nAjax PROBLEMA: Ogni volta in cui devo cambiare elemento dell\u0026rsquo;interfaccia, non posso fare altro che duplicare la pagina, ossia fare una piena richiesta HTTP con le modifiche, infatti √® grande cambio di informazioni, nel senso che non mi servirebbe.\nIntroduzione Ajax Slide introduzione La cosa carina che significa anche AIACE üòÄ, ma non c‚Äôentra niente.\nL‚Äôobiettivo √® caricamenti asincroni per frammenti XML con questo aggiorno la pagina HTML, invece di cambiare da un altro URL.\nOggi XML √® considerato troppo verboso, in verit√† andiamo a scambiare frammenti JSON di cui abbiamo parlato in Alcuni linguaggi di Markup (non impo) üü•+, e sempre in Javascript.\nOra il formato √® tipo:\ncarico HTML molto vuoto carico applicazione JS anche complessa L‚Äôapplicazione fa richieste e popola la pagina in modo attivo Utente fa altra attivit√†, triggera altre richieste, la pagina cambia. Ecco l‚Äôinterattivit√†!\nSlide AJAX\nConfronto architettura scambi HTML e AJAX\nQuando faccio la richiesta, il browser √® bloccato, poi quando il server finisce il browser riceve tutto, butta via vecchio e comincia a fare le cose nuove. (continuo stop and go)\nNota: browser non si blocca per l\u0026rsquo;utente (script sono molto veloci che non sembra bloccarsi!)\nUn esempio di applicazione AJAX √® maps.google.com, perch√© inizia a caricare secondo attivit√† dell‚Äôutente, le piastrelle a un certo livello i zoom üôÇ\nStruttura processo ajax (4) Slide processo applicazione Ajax\nCreazione della richiesta\nOn Ready state change chiama la funzione ogni volta che cambia lo stato (che abbiamo detto possono essere 5 valori.\nse √® 4 la richiesta √® tornata ed √® stata elaborata ‚Üícompletata:D\nInvio della richiesta (DIFFERENZA POST E GET!!!!)\nGestione della risposta\nVantaggi svantaggi AJAX Importantissimo per AJAX e js!\nNavigazione della pagina non √® sincronizzato con lo scambio di dati! mentre prima s√¨\nSlide vantaggi AJAX\nUsabile, interattiva, senza tempi morti Molto pi√π veloce, per minore numero di pacchetti mandati Chiunque lo implementa :D Slide svantaggi AJAX\nDevo aggiungere step di navigazione di history fittizi per poter andare avanti indietro nella storia! (non lo fa il browser ma lo fa la mia applicazione) si chiama routing Ajax √® inerentemente non lineare perch√© posso cambiare contenuto ovunque, anche mentre il mio sintetizzatore sta leggendo la pagina (per accessibilit√† invece serve la linearit√†). L‚Äôimplementazione pu√≤ cambiare da browser a browser, qualcosa potrebbe essere rotto qui e non in un altro browser. Framework Ajax XMLHTTPRequest\n√à la libreria per Ajax, ma √® molto molto macchinosa! Per questo motivo utiliziamo altro, come JQuery che vedremo dopo.\njQuery\n√à un framework che √® nato per semplificare tutta la parte macchinosa dell‚Äôapplicazione AJAX, oggi non √® pi√π utilizzato perch√© le funzionalit√† sono gi√† direttamente presenti sul browser. √à pi√π per mantenere codice vecchio. Ce ne sarebbero altre ma non le ha descritte\n","permalink":"https://flecart.github.io/notes/javascript/","summary":"Ripasso: May 14, 2023 Ultima modifica: May 6, 2023 6:25 PM Primo Abbozzo: March 20, 2023 3:16 PM Studi Personali: No\nElementi di ripasso Javascript Obiettivo principale √® esegurie codice clientside\nUn p√≤ di storia nato all‚Äôinizio della prima guerra dei browser (da netscape, explorer √® in visual basic comunque non compatibile con JS) come il fratellino di java nel senso che runnava ovunque, attualmente √® ECMAScript, ed √® la versione migliore.","title":"Javascript"},{"content":"Ripasso Prox: 10 Ripasso: May 29, 2023 Ultima modifica: May 19, 2023 10:33 AM Primo Abbozzo: May 8, 2023 9:20 AM Stato: üåïüåïüåïüåïüåë Studi Personali: No\nElementi di ripasso Object orientation il tipo di dato astratto Introduzione Per questi tipi di dato non ci interessa di sapere cosa ci sia sotto (storato come bit? storato come sabbia boh), ci interessa solamente che abbia quei metodi, che possiamo in un certo senso identificare come la sua capsula, opaca in questo caso.\nQuando si pu√≤ andare a modificare solamente attraverso questo metodo potrei dire che sia safe collegato alla Algebra dei tipi, nel senso che vengono soddisfatte sempre le propriet√† del tipo.\nCostituenti del ADT (4) (abstract data structure) üü® Slide ADT\nCi sono principalmente 4 elementi:\nIl nome del tipo di dato astratto Il dato concreto che sta sotto (ad esempio intero Operazioni di creazione ed accesso (che in un certo senso sono simili ai meccanismi di Architettura software del OS) confine di astrazione che sono come le interfaccie, o politiche? In pratica credo siano equivlaenti alle cose pubbliche di questa, mentre il punto 3 racchiude anche quelle private. Information hiding üü© Slide information hiding\nIl fatto che vogliamo cercare di andare ad operare e prendere da questo tipo di dato astratto solamente attraverso delle interfacce. Per questo motivo si pu√≤ dire che stiamo nascondendo cosa c\u0026rsquo;√® dentro a quella classe.\nSotto questo punto di vista, si dice spesso che la classe √® come contratto con la superficie, perch√© va a soddisfare certe propriet√† con chi la utilizza.\nIl fatto che l\u0026rsquo;implementazione effettiva viene nascosta, aiuta alla modularit√†. Non posso fare assunzioni sull‚Äôimplementazione effettiva, mi basta che le propriet√† dell‚Äôinterfaccia siano rispettate.\nUn altro aspetto √® che √® facile organizzare progetto in moduli a seconda di cosa stiamo rappresentando (prova a tenerti in mente la classica organizzazione in un file per una classe che si fa spesso in java).\nIndipendenza della rappresentanza üü© Andiamo ora ad introdurre il concetto di indipendenza della rappresentanza (ossia il fatto che non ci interessa questo tipo di dato astratto da quale tipo concreto √® rappresentato), un fatto che la caratteristica dell‚Äôinformation hiding ci ha permesso di avere:\nSlide indipendenza\nimplementazioni corrette (ben tipate) dello stesso ADT sono osservabilmente indistinguibili dai consumatori dell‚ÄôADT.\nTipi esistenziali üü© Questi sono quasi l\u0026rsquo;opposto dei tipi di polimorfismo universale parametrico in Polimorfismo, praticamente √® un exist invece che un forall, che carina questa relazione.\nSi potrebbe vedere come la rappresentazione di ADT attraverso teoria dei tipi.\nSlide tipi esistenziali\nQuando vado a definire un tipo che soddisfa quella caratteristiche non starei facendo altro che risolvendo il tipo esistenziale da un punto di vista di teoria dei tipi.\nEsempio risoluzione di tipi esistenziali\nOggetti esistenziali üü© Slide problema tipi esistenziali\nSlide oggetti esistenziali\nGli oggetti esistenziali mantengono l\u0026rsquo;astrazione del tipo esistenziale, a differenza delle ADT che vanno ad eliminare l‚Äôesiste e quindi diventano inoperabili fra di loro, tenendo l‚Äôastrazione possiamo andare a cooperare fra istanziazioni diverse di questo oggetto esistenziale. (si porta avanti l\u0026rsquo;interfaccia senza andarlo a risolvere come per ADT)\nUna altra differenza √® che oggetti fanno una differenza fra stati e metodi, mentre il tipo di dato astratto tiene solamente operazioni e il tipo sotto di esso.\nSlide confronto oggetti esistenziali con abstract data types\nIn breve ADT sono aperti, mentre oggetti sono chiusi e quest\u0026rsquo;ultimo fatto permette di utilizzare tipi con istanziazione anche diversa fra di loro.\nuna differenza rilevante degli oggetti rispetto agli ADT √® che, poich√© ogni oggetto ha la propria rappresentazione interna e implementa le proprie operazioni, un programma pu√≤ liberamente mescolare implementazioni diverse dello stesso tipo di oggetto (esistenziale).\nClassi e oggetti Def oggetto üü© Oggetto: una capsula che contiene sia dati che operazioni per manipolarli e che fornisce un\u0026rsquo;interfaccia al mondo esterno attraverso la quale √® possibile accedervi.\nLe operazioni sono anche chiamate metodi. mentre i dati sono chiamati campi dell\u0026rsquo;oggetto.\nDef classe üü© Una classe √® un modello per un insieme di oggetti: stabilisce quali sono i loro dati (quanti, di che tipo, con quale visibilit√†) e fissa il nome, la segnatura, la visibilit√† e l\u0026rsquo;implementazione dei suoi metodi\nIn modo pi√π intuitivo potremmo andare a dire:\nclasse: Specifica un canovaccio o un modello di implementazione di riferimento che contiene le variabili e i metodi comuni alla stessa classe (da cui il nome) di oggetti.\nImplementazione delle classi (2)üü© La definizione dei metodi della classe √® unica, sono solamente i campi di dati che sono diversi per ogni istanziazione. Come fanno ogni istanziazione ad accedere al metodo corretto allora? Puntatore all\u0026rsquo;unica istanziazione! L\u0026rsquo;immagine sotto pu√≤ chiarificare questo concetto:\ndall‚Äôaltra parte quando dall\u0026rsquo;implementazione mi vado a riferire a this, questo deve derefernziarwsi sulla corretta istanziazione dell‚Äôoggetto!\nLo storage, come al solito, pu√≤ essere sia a stack sia sulla heap, a seconda dell‚Äôimplementazione del linguaggio.\nPrincipalmente credo che le osservazioni principali siano due:\nDereferenziare correttamente il this Sapere accedere alle funzioni definite nella classe Prototipi e confronto con classi üü® Questi sono un pattern che piace tanto a Javascript.\nsi basa sulla possibilit√† che gli oggetti deleghino parti della loro implementazione ad altri oggetti.\nCreazione ora si pu√≤ fare in due modi, uno il classico √® new, l\u0026rsquo;altro √® ex-nihilo andando a definire passo passo tutto (in modo direi estensionale, andando a ricollegarmi con Teoria dei Tipi)\nla differenza principale dei prototipi con le classi √® la flessibilit√† vs sicurezza dato che in js i prototipi possono essere assegnati a runtime, quindi potrebbero anche cambiare (sicuramente cattiva pratica, credo si chiami anche monkey typing).\nNelle classi non possiamo andare a cambiare l\u0026rsquo;implementazione una volta dichiarata.\nSi una possibilit√† di fare una delegazione ossia il metodo √® implementato in modo dinamico e vado a cercare il primo prototipo per quell\u0026rsquo;oggetto. √à molto flessibile, perch√© utilizza duck-typing, molto facile cambiare le cose, solo che dal punto di vista della correttezza e sicurezza √® un p√≤ pi√π difficile.\n","permalink":"https://flecart.github.io/notes/object-orientation/","summary":"Ripasso Prox: 10 Ripasso: May 29, 2023 Ultima modifica: May 19, 2023 10:33 AM Primo Abbozzo: May 8, 2023 9:20 AM Stato: üåïüåïüåïüåïüåë Studi Personali: No\nElementi di ripasso Object orientation il tipo di dato astratto Introduzione Per questi tipi di dato non ci interessa di sapere cosa ci sia sotto (storato come bit? storato come sabbia boh), ci interessa solamente che abbia quei metodi, che possiamo in un certo senso identificare come la sua capsula, opaca in questo caso.","title":"Object orientation"},{"content":"Questo √® un tentativo di aggiungere un argomento che non era presente quando abbiamo fatto il corso due anni fa. Inizio la scrittura il 2024-03-03. Questo non √® stato trattano nel corso, ma √® importante per molte cose. Quindi introduco questo appunto.\nIntroduzione alle serie Le serie infinite sono dei mostri strani perch√© non si comportano spesso come dovrebbero.\nDefinizione di convergenza Sia data una funzione $(a_{n})_{n=0}^{\\infty}$ una funzione da $\\mathbb{N} \\to \\mathbb{R}$, possiamo dire che questa serie √® convergente se la somma cumulativa $f_{n} = \\sum_{n = 0}^{n} a_{n}$ ha un limite finito, ossia $$ \\lim_{ n \\to \\infty } f_{n} = c $$ con $c$ un numero reale.\nResto di serie convergenti Sia data una serie convergente, allora $\\forall \\varepsilon$ esiste un $N_{0} \\in \\mathbb{N}$ per cui $\\sum_{n = N_{0}}^{\\infty} a_{n} \u003c \\varepsilon$\nIntuitivamente questo lemma ci dice che la maggior parte del contributo alla somma viene fatta dalla prima parte della serie.\nDimostrazione: Sappiamo per ipotesi che $$ \\forall\\varepsilon ,\\exists N_{0} \\in N: \\forall N \\geq N_{0}, \\left\\lvert \\sum_{n=1}^{N}a_{n} - c \\right\\rvert \u003c \\varepsilon $$ Questo √® l\u0026rsquo;equivalente di scrivere $$ \\lim_{ N \\to \\infty } \\sum_{n=1}^{N} a_{n} = \\sum_{n=1}^{\\infty}a_{n} = c $$ Ora consideriamo il valore $f_{N} = \\sum_{n=1}^{N}a_{n}$ e la differenza $c - f_{N}$, chiamiamo $b_{n} = c - f_{n}$ e possiamo mostrare che $$ 0 = \\lim_{ n \\to \\infty } b_{n} =\\lim_{ n \\to \\infty } (c - f_{n}) = \\lim_{ n \\to \\infty } \\sum_{i= n + 1}^{\\infty} a_{i} $$ Ossia abbiamo la tesi. Qualcosa di simile lo facciamo anche in Spazi di probabilita per calcolo di up and down, ma non mi ricordo esattamente come si chiamano. La nota sul resto, solitamente ci permette di ricondurci a un caso discreto per le serie convergenti, e diventa quindi utile per tornare sul discreto, molto spesso.\nLimit Comparison Test Siano date due Successioni $a_{n}$ e $b_{n}$ sempre positive. Allora se esiste ed √® finito il limite $$ \\lim_{ n \\to \\infty } \\frac{a_{n}}{b_{n}} = c $$ Si hanno due casi possibili per il valore di $\\sum_{i=1}^{+\\infty}a_{n}$ e di $\\sum_{i=1}^{+\\infty}b_{n}$\nEntrambi convergono a un valore $c$ Entrambi divergono Questo √® abbastanza intuitivo se pensiamo che l\u0026rsquo;ipotesi ci sta dicendo che al limite le due successioni distano al massimo di un fattore reale. Se divergono, e distano di un fattore reale, anche l\u0026rsquo;altro dovr√† divergere, se invece converge, anche l\u0026rsquo;altro dovr√† convergere.\nLa dimostrazione credo passa dalla definizione di limite per successioni presente in Successioni#3.2 Limiti di successioni.\nEreditariet√† delle propriet√† Consideriamo una successione $(x_{n})_{n = 1}^{\\infty}$, e definiamo $\\sum x_{n} = x$ vogliamo chiederci se regolarit√† di $x_{n}$ sono mantenute o meno per quanto riguarda $x$. Possiamo concludere tramite esempi semplici che non sempre √® vero per quanto riguarda la derivabilit√†. Infatti abbiamo che $$ f_{n} = \\sum_{n=1}^{\\infty} \\frac{\\sin(3^{n}x)}{2^{n}} $$ Non soddisfa la propriet√†, perch√© questa serie converge assolutamente tramite l\u0026rsquo;osservazione che $f_{n} \\leq \\frac{1}{2^{n}}$, per questo esempio specifico, possiamo dire che la serie converge grazie al bound, ma se facciamo la derivata, questa diverge (che √® abbastanza assurdo).\nSi pu√≤ fare anche l\u0026rsquo;esempio opposto, ossia possiamo definire una funzione per cui termine a termine siano integrabili, mentre nel totale non lo sono.\nConvergenza Totale Definiamo l\u0026rsquo;intervallo $I \\subseteq \\mathbb{R}$ e una serie di funzioni $f_{n} : I \\to \\mathbb{R}$ allora la serie $\\sum_{n=1}^{\\infty} f_{n}$ converge totalmente se esiste una serie di successioni $\\left\\{ a_{n} \\right\\}_{n=1}^{\\infty}$ tali per cui\n$\\forall x \\in I, n \\in N:\\lvert f_{n}(x) \\rvert \\leq a_{n}$ $\\sum_{n=1}^{\\infty}a_{n}$ converge. Queste due condizioni implicano che √® ben definita la funzione $$ f: I \\to \\mathbb{R}, f = \\sum_{n=1}^{\\infty} f_{n}(x) $$ ","permalink":"https://flecart.github.io/notes/serie/","summary":"Questo √® un tentativo di aggiungere un argomento che non era presente quando abbiamo fatto il corso due anni fa. Inizio la scrittura il 2024-03-03. Questo non √® stato trattano nel corso, ma √® importante per molte cose. Quindi introduco questo appunto.\nIntroduzione alle serie Le serie infinite sono dei mostri strani perch√© non si comportano spesso come dovrebbero.\nDefinizione di convergenza Sia data una funzione $(a_{n})_{n=0}^{\\infty}$ una funzione da $\\mathbb{N} \\to \\mathbb{R}$, possiamo dire che questa serie √® convergente se la somma cumulativa $f_{n} = \\sum_{n = 0}^{n} a_{n}$ ha un limite finito, ossia $$ \\lim_{ n \\to \\infty } f_{n} = c $$ con $c$ un numero reale.","title":"Serie"},{"content":"3.1 Introduzione 3.1.1 Cosa sono Le strutture di dati si interessano solamente di come memorizzare i dati, non necessariamente va a memorizzare un tipo di dato concreto.\nQuindi + sul come - sul cosa.\n3.1.2 Prototipo e implementazione Avevamo introdotto la differenza fra algoritmo e programma all\u0026rsquo;inizio del corso, andiamo ora a definire la differenza fra prototipo e implementazione:\nPrototipo:\nva a fare una descrizione dei metodi che deve avere una determinata struttura di dati. Lo puoi intendere come una specie di interfaccia.\nImplementazione:\n√à la creazione del programma in un determinato linguaggio di programmazione\n3.1.3 Distinzioni generali fra strutture di dati Le strutture di dati vengono distinte principalmente secondo 3 fattori\nLinearit√† vs non-linearit√† (sequenzialit√† degli elementi es std::set, std::unordered_set\nStaticit√† vs dinamicit√† (es array e vector)\nOmogeneit√† vs eterogeneit√† ( che tratta dei tipi di dato che sono memorizzabili\n3.2 Dizionario 3.2.1 Prototipo (propriet√† caratterizzanti) Questa √® una struttura di dati astratta composta principalmente da due cose:\nUn insieme di chiavi (uniche) associati a un valore (duplicabili). per questo motivo si pu√≤ anche chiamare array associativo\nSi nota che √® una struttura di dati dinamica, riguardo invece linearit√† e non linearit√† dipende dall\u0026rsquo;implementazione.\n3.2.2 Operazioni primitive Ricerca(Chiave) restituisce il valore della chiave Inserimento(Chiave, Valore) crea una chiave con quel valore Elimina(Chiave) elimina l\u0026rsquo;elemento con una determinata chiave 3.2.3 Esempio di implementazione su array ordinato Slide\nLe seguenti sono tutte implementazione ad alto livello senza codice\nImplementazione di Search\nImplementazione di Insert\nImplementazione di Delete\nLa cosa importante da osservare √® la costo asintotico di questa implementazione, ossia l\u0026rsquo;aspetto che varia a seconda dell\u0026rsquo;implementazione.\nRiassunto del costo computazionale di questa implementazione\n3.2.4 Esempio di implementazione su lista concatenata Qui si utilizza una lista concatenata *circolare ** ovvero l\u0026rsquo;ultimo elemento della lista punta al primo, e il precedente del primo punta all\u0026rsquo;ultimo elemento, solo per non avere un null.\nSlide\nImplementazione di insert/delete\nImplementazione di Search\nScorri la lista ordinata, lo hai gi√† visto molto spesso üôÇ\nRiassunto costo computazionale lista concatenata\nConfronto fra le due implementazioni\nSlide\nIn conclusione abbiamo delle velocit√† diverse, per le operazioni che definiscono il dizionario. La scelta dell\u0026rsquo;implementazione migliore dipende dalle necessit√† dell\u0026rsquo;algoritmo, cosa che si decide caso per caso.\nUna osservazione √® che lista √® dinamica, mentre array ordinato √® statico.\n3.3 Liste concatenate 3.3.1 Prototipo semplice Una lista concatenata bidirezionale semplice √® simile a quanto studiato in programmazione, gli estremi sono terminati da dei null.\nEsempio di lista concatenata unidirezionale semplice\nEsempio di lista concatenata bidirezionale semplice\nCircolare\n3.3.2 Prototipo circolare In particolare qui utilizziamo una lista concatenata bidirezionale circolare.\nOgni nodo contiene il valore, una chiave, e due puntatori al precedente e successivo.\nEsempio di lista concatenata circolare\n3.3.3 Operazioni elementari Sono tre le operazioni principali per una lista concatenata\nSearch\nInsert\nDelete\n3.4 Pile 3.4.1 Prototipo Vogliamo avere qualcosa che stori le cose come se fossero una pila di elementi. Quindi vogliamo solamente delle operazioni molto semplici. diciamo che √® una struttura di dati di tipo LIFO.\nQuesta semplice struttura di stack √® molto comoda: ha delle applicazioni non da poco:\nrecord delle chiamate operazioni per un editor di testo per scrivere e no. Parentesi per sintax-parsing Operazioni elementari\nVogliamo queste cose che siano entrambe molto veloci (costante\nPUSH(element)\nPOP()\n3.4.2 Confronto due implementazioni Possiamo utilizzare una lista o array (senza considerare l\u0026rsquo;array doubling)\nSlide\nRisposta domanda: perch√© l‚Äôunica cosa che serve √® push e pop, non servono altre operazioni da necessitare della doppia concatenazione\nImplementazione statica Slide\nQuesta √® la classica implementazione. utilizzando l\u0026rsquo;array statico. ma ha il problema che devo allocare uno spazio in memoria che sia sempre quello. Utilizziamo ora una tecnica che utilizza doubling e halving, per avere un array dinamico\nImplementazione dinamica La cosa buona di questo elemento √® che il costo ammortizzato √® costante.\nSlide\nAnalisi del costo ammortizzato\nAnalisi del push ammortizzato\nNel libro √® anche presente una tecnica utilizzando doubling-halving che utilizza l\u0026rsquo;accantonamento, che si potrebbe dire essere pi√π intuitivo.\nAnalisi del pop ammortizzato (accantonamenti)\nNon viene fatto nelle slide, ma √® presente sul libro, che incollo qui\n3.5 Code 3.5.1 Prototipo La struttura √® molto simile a quella della stack, ma qui l\u0026rsquo;unica differenza √® che invece di togliere il primo che ho messo, tolgo l\u0026rsquo;ultimo. Come se fosse una coda ad un bar.First in first out\nScheduling operazioni BFS Operazioni elementari\nEnqueue(element)\nDequeue()\n3.5.2 Confronto implementazioni (array circolari o liste semplici) Slide di confronto ad alto livello\nImplementazione con la array circolare Questa implementazione non √® presente nel codice java sorgente.\nSlide\n3.6 Alberi Di pi√π inAlberi BST e AVL\nCose importanti per l\u0026rsquo;albero sono:\nNodi Archi (singolo percorso fra un nodo e un altro, questa √® la differenza principale con i grafi) Poi possiamo identificare anche un ordine sui figli, radicato. **se ho unnodo come radice.\n3.6.1 Prototipo Come un albero binario di ricerca\u0026hellip;\n3.6.2 Operazioni elementari Lo scorrimento di un albero nei 3 modi: pre-ordine, in-ordine, post-ordine utilizzando gli algoritmi come DFS e BFS\n","permalink":"https://flecart.github.io/notes/strutture-di-dati-elementari/","summary":"3.1 Introduzione 3.1.1 Cosa sono Le strutture di dati si interessano solamente di come memorizzare i dati, non necessariamente va a memorizzare un tipo di dato concreto.\nQuindi + sul come - sul cosa.\n3.1.2 Prototipo e implementazione Avevamo introdotto la differenza fra algoritmo e programma all\u0026rsquo;inizio del corso, andiamo ora a definire la differenza fra prototipo e implementazione:\nPrototipo:\nva a fare una descrizione dei metodi che deve avere una determinata struttura di dati.","title":"Strutture di dati elementari"},{"content":"Cosa √® UML √® un linguaggio di modelling (molto vecchio) ma ancora di continua evoluzione, da un punto di vista storico √® nato insieme ai concetti di Object Oriented Programming che ora √® molto presente all\u0026rsquo;interno dell\u0026rsquo;industria, descritto bene in Classi OOP, anche se in questa occasione sviluppata in maniera molto pi√π intuitiva (grafica).\nPerch√© serve üü© Per cercare di comunicare quanto necessario riguardo struttura e dinamicit√† dell\u0026rsquo;architettura.\nStruttura di UML Structural Diagram üü®++ These diagrams focus on representing the static structure of a system. They help depict the components, classes, objects, and their relationships in a system. Some common structural diagrams in UML include:\nClass Diagram: Shows the classes in a system and their relationships, attributes, and methods. Object Diagram: Represents instances of classes and their relationships at a specific point in time. Component Diagram: Illustrates the physical components of a system and their dependencies. Package Diagram: Organizes classes and other elements into packages to show their relationships. Behavioral diagrams (4) üü©\u0026ndash; These diagrams focus on illustrating the dynamic aspects of a system, including how it behaves and interacts over time. They are used to model the interactions between objects, the flow of control, and the system\u0026rsquo;s behavior. Common behavioral diagrams in UML include:\nUse Case Diagram: Depicts the interactions between actors (users or external systems) and the system to achieve specific goals or functions. Sequence Diagram: Shows the chronological sequence of messages exchanged between objects over time. Statechart Diagram: Represents the various states an object or system can be in and how it transitions between those states. Activity Diagram: Describes the flow of activities or processes within a system. Main relationships Queste sono anche chiamate le freccie, ossia le tipologie di relazioni che possono esistere fra entit√† diverse.\nLe relazioni esistenti Association: An association is a basic relationship that represents a link between two or more classes or objects. It indicates that instances of one class are related to instances of another class. In a graph context, you can think of associations as edges connecting nodes in a graph. Associations can have multiplicities to specify how many instances are involved in the relationship (e.g., one-to-one, one-to-many).\nAggregation: Aggregation is a specialized form of association that represents a whole-part relationship. It indicates that one class (the whole) is composed of or contains instances of another class (the part). In a graph, aggregation can be seen as a hierarchical relationship, where nodes at one level represent composite objects made up of nodes at another level. Esempio di aggregazione: Composition: Composition is a stronger form of aggregation, indicating a strict ownership relationship. It means that the whole class has exclusive responsibility for the existence and lifetime of its parts. In a graph, composition is similar to aggregation but with a stronger emphasis on the containment of parts within the whole.\nInheritance (Generalization): Inheritance, represented by a solid arrow with an open triangle, signifies an \u0026ldquo;is-a\u0026rdquo; relationship. It is used to model the inheritance hierarchy in object-oriented programming, where one class (the subclass or derived class) inherits attributes and methods from another class (the superclass or base class). In graph terms, it represents a hierarchy, with edges pointing from subclasses to their superclass.\nRealization (Interface Implementation): Realization is used to show that a class or component implements a specific interface or fulfills a particular contract. It indicates a relationship between a classifier and an interface. In graph theory, this can be seen as a form of dependency or connection between nodes representing classes and interfaces.\nDependency: Dependency is a relationship that indicates that one element relies on another element. It can be used to represent various forms of relationships, such as method dependencies, parameter dependencies, or simple associations between classes. In a graph, dependencies are akin to edges indicating connections or reliance between nodes.\nStructural diagrams Class diagrams Descrivo in che modo le varia classi sono relazionati fra di loro (ad esempi con l\u0026rsquo;albero di ereditariet√†)\nTypes of behavioral diagrams (5) Use cases (!) üü®+ Structure of use case diagrams A use case is a concept in software engineering and system design that describes a specific interaction or set of interactions between a system (usually software) and its external actors\nGoal-Oriented: Use cases are centered around achieving specific goals or objectives. Each use case represents a particular task, process, or scenario that an external actor wants to accomplish using the system. Actor: An actor is any external entity that interacts with the system. Actors can be users, other software systems, hardware devices, or any external entity that initiates a use case. Actors are defined based on their roles and responsibilities in the system. Flow of Events: A use case typically includes a description of the main flow of events, which outlines the steps or interactions involved in achieving the desired goal. It can also include alternative or exceptional flows to cover various scenarios. Preconditions and Post-conditions: Use cases may specify conditions that must be met before the use case can be initiated (preconditions) and the state of the system after the use case has been successfully completed (post-conditions). (ossia ci√≤ che abbiamo bisogno, e ci√≤ per rendere deterministico questo processo). Quindi √® utilizzato per modellare in che modo chi usa dovrebbe interagire con il nostro sistema, e ci√≤ che il nostro sistema ha bisogno per funzionare.\nEsempio: More on actors Use case modelling and diagrams üü• Use Case Diagrams: Use cases are often visualized using diagrams called use case diagrams. These diagrams show the relationships between actors and use cases, helping to provide a high-level overview of the system\u0026rsquo;s functionality. Use Case Modeling: Use case modeling is a technique used during the early stages of system design to identify and define the various use cases that the system will support. It helps in understanding and documenting user requirements and system behavior. State-chart diagrams Notazione sugli stati (4) üü®+ #### Notazione delle transizioni üü©- In modo simile agli automi a stato finito, definisco gli stati (in questo caso aggiungo anche una semantica per gli stati, e poi una possibile transizione all'interno di quelli). Perch√© utilizzare state-chart üü© Descrizione di cambi di stato, in modo a simile a quanto si farebbe per automata per esempio. Descrizione di campi statici presenti negli oggetti per esempio. √à contrapposto con gli interaction diagrams che racconta in che modo cose differenti comunicano fra di loro, questo state-chart √® utilizzato per definire in modo statico se succede cosa, cosa cambia. Esempi di state diagrams In pratica √® un grafico pi√π rilassato di Deterministic Finite Automata [Grammatiche Regolari](/notes/grammatiche-regolari) Si pu√≤ usare anche in modo innestato come in seguito Activity diagrams Cosa descrivono le activity diagrams üü© Workflows, ossia in che modo il sistema agisce, ad alto livello per poter a Parallelizzazione, se devono essere eseguite pi√π cose allo stesso tempo, √® molto comodo. Sincronizzazione, quindi anche per logica con async ha senso Sequence diagrams Interaction diagrams Cercano di modellare in che modo comunicano fra l\u0026rsquo;uno e l\u0026rsquo;altro, serve per fare cose complesse Un esempio sono i sequence diagrams\nPerch√© sequence diagrams? üü© Shows object interactions arranged in time sequence\nUn esempio di utilizzo comune √® per i protocolli, dato che il tempo √® importante √® molto facile comunicare esattamente cosa viene scambiato. Quindi utile per rappresentare in che modo chi chiama cosa nel tempo. Altro esempio, un po\u0026rsquo; pi√π complesso Descrizione della struttura üü© In alto abbiamo degli oggetti oppure degli agenti differenti, poi col tempo questi oggetti diversi scambiano messaggi, in questo caso √® chiara sequenza dei messaggi, che √® il vantaggio principale di questi diagrammi.\nAsincroni Sincroni Non bloccanti, esattamente gli stessi che abbiamo visto in sistemi Collaboration diagrams Descrizione collaboration diagrams üü© Uguale ai sequence diagrams, ma esprime messaggi possibili fra una classe e una altra e non esprime il tempo durante una singola comunicazione.\nUn altro aspetto √® che la sequenza dei messaggi √® identificata da numeri\nConfronto con i diagrammi di sequenza üü© Facile vedere messaggi che vengono scambiati da enti differenti, quindi organizzazioni diciamo. Si perde per√≤ informazione sul tempo Per il resto √® molto simile rispetto ai #Sequence diagrams perch√© anche in questo caso si scambiano messaggi, solo che non √® ben definito il tempo. (viene marcato con un numerino).\nUn esempio: ","permalink":"https://flecart.github.io/notes/unified-modeling-language/","summary":"Cosa √® UML √® un linguaggio di modelling (molto vecchio) ma ancora di continua evoluzione, da un punto di vista storico √® nato insieme ai concetti di Object Oriented Programming che ora √® molto presente all\u0026rsquo;interno dell\u0026rsquo;industria, descritto bene in Classi OOP, anche se in questa occasione sviluppata in maniera molto pi√π intuitiva (grafica).\nPerch√© serve üü© Per cercare di comunicare quanto necessario riguardo struttura e dinamicit√† dell\u0026rsquo;architettura.\nStruttura di UML Structural Diagram üü®++ These diagrams focus on representing the static structure of a system.","title":"Unified Modeling Language"},{"content":"Transliteration is learning learning a function to map strings in one character set to strings in another character set. The basic example is in multilingual applications, where it is needed to have the same string written in different languages.\nThe goal is to develop a probabilistic model that can map strings from input vocabulary $\\Sigma$ to an output vocabulary $\\Omega$.\nWe will extend the concepts presented in Automi e Regexp for Finite state automata to a weighted version. You will also need knowledge from Descrizione linguaggio for definitions of alphabets and strings, Kleene Star operations.\nWeighted finite-state automata We take the 5-tuple of the finite-state automata and add two functions $\\lambda : Q \\to \\mathbb{K}$ and $\\rho: Q \\to \\mathbb{K}$ and the transition function to a multiset (somewhat similar to non deterministic finite state automatas) $\\delta : Q \\times (\\Sigma \\cup \\varepsilon)\\times \\mathbb{K} \\times Q$.\nWe then need to go to define the notions of paths, yield, length of a path, if it is ambiguous or unambiguous.\nThe interesting thing about WFSA is that they can model many models! Part of Speech Tagging\u0026rsquo;s conditional random fields are WFSA, Language Models\u0026rsquo;s N-gram models are WFSA, also HMMs are WFSAs! So this model is quite general! The nice thing is that if you develop an algorithm for WFSAs then you can use the same algo for the other models too.\n","permalink":"https://flecart.github.io/notes/untitled/","summary":"Transliteration is learning learning a function to map strings in one character set to strings in another character set. The basic example is in multilingual applications, where it is needed to have the same string written in different languages.\nThe goal is to develop a probabilistic model that can map strings from input vocabulary $\\Sigma$ to an output vocabulary $\\Omega$.\nWe will extend the concepts presented in Automi e Regexp for Finite state automata to a weighted version.","title":"Untitled"},{"content":"One very insightful idea is unsupervised word representation. That is just say take a lot of text and try to model the word representations statistically.\nSalton (1975) was one of the first researchers that tried to use the techniques that later will be common in Google searches.\nTheory Johnson-Lindenstrauss Lemma This lemma basically says that semantic embedding is possible, without giving a real algorithm to do so. This seems to be a nice resource about this lemma.\nFor any $0 \u003c \\varepsilon \u003c 1$ and any $k$ bigger than $f(\\varepsilon)\\log n$ (see the reference for $f(\\varepsilon)$ its a simple function). The for any $n \\in \\mathbb{R}^{d}$ there is a function $f: \\mathbb{R}^{d} \\to \\mathbb{R}^{k}$ such that $\\forall x_{i} x_{j} \\in A$ we have $$ (1 - \\varepsilon)\\lVert x_{i} - x_{j} \\rVert ^{2} \\leq \\lVert f(x_{i}) - f(x_{j}) \\rVert^{2} \\leq (1 + \\varepsilon) \\lVert x_{i} - x_{j} \\rVert ^{2} $$ It says that the pairwise distances can be preserved (if meaning is relation between different entities, then this is everything that is needed to keep that concept almost unaltered.)\nProbably this is a proof but it needs to be checked: https://chatgpt.com/share/826d6525-7d06-4822-b514-3c1f6f006a99.\nVector Embeddings We want to translate entities (words, sentences) into vectors. We can embed many things, for example, images, audios etc. There are also some multi channel embeddings, for example CLIP embeddings.\nA simple Embedding: One-Hot One of the simplest ways to have an embedding, which could be used for techniques like Bag of words or neural techniques like Recurrent Neural Networks or Transformers, is to have a very high dimensional sparse vector that encodes at a single index true or false. This value tells us if the token is present or not.\nSome drawbacks easily arise:\nUsually these vectors are very high dimensional, so takes a lot of memory. They don\u0026rsquo;t encode any semantic information because you can\u0026rsquo;t define a notion of distance. You can\u0026rsquo;t compare between two different tokens because they are all orthogonal. Future methods like contextual embeddings solve the second problem and ease the first: we are able to define a notion of distance, and do some regularity operations like the famous king - man + woman = queen cited in (Mikolov et al. 2013).\nStatic word embeddings Word2Vec The reference paper is (Mikolov et al. 2013). This has been one of the first approaches that attempted to imbue a semantic meaning to the embedding, which is given statically by the context. Usually byte level Tokenization are not able to create meanings. A famous hypothesis states that the meaning of a word depends on the context words, as explained in (Firth). This is also called skip-gram model in this cases we accumulate pairs of words with a fixed context length of 3. Then we want to try to predict the context words by using the focal word. This is why we say this model produces contextual word embeddings.\nWe want to model the context as a log-bilinear model: $$ p(c \\mid w) = \\frac{1}{Z(w)} \\exp(e_{wrd}(w) \\cdot e_{ctx}(c)) $$ Similar model to Log Linear Models.\nIf we have $\\lvert V \\rvert$ words, then we have in this case $2 \\lvert V \\rvert d$ parameters. Where $d$ is the dimension of the embedding. Why do we need two embeddings, one for the word and one of the context? It makes it easier to model the unlikeliness of repeating the word in his context. The difficult thing for this method is scaling because the $Z(w)$ is slow to calculate (this is why later we need sampling methods).\nPer questo usiamo i contextualized word embeddings.\nNegative sampling It\u0026rsquo;s a way to speed up training for word2vec, doing 600k at the same time was not feasible at the time. Select 2-20 words in the vocabulary that we do not want to predict. 600k because Word2Vec is just a double linear layer, but with 3kk words of input and output.\nThe negative samples are just taking random words from the vocabulary randomly. While the positive samples are the couples of words effectively present.\nI don\u0026rsquo;t know if I understood it well but I think it samples a certain number of words at a time and updates only the weights involved (so k targets, and the set of weights involved, only those). I don\u0026rsquo;t know why it\u0026rsquo;s called negative sampling if this is the idea below.\nNOTE: this is not important, there are many sampling ways that are used to estimate the $Z$. So you can skip this method.\nOther resources Intuitive Youtube Video about Word2Vec Blog pratico\nOther famous embedding models are GloVe and ELMo\nContextualized Embeddings These are state of the art now. We want to have a different word embedding for every context. We usually use Transformers to model these.\nBERT is called \u0026ldquo;Bidirectional Encoder Representations from Transformers\u0026rdquo;. 3.3 Billion words (usually used after finetuning), 110 million parameters and 340 million parameters, not so much from today\u0026rsquo;s standards.\nReferences [1] Mikolov et al. ‚ÄúEfficient Estimation of Word Representations in Vector Space‚Äù 2013\n[2] Firth ‚ÄúFirth, J. (1957). A Synopsis of Linguistic Theory, 1930-55. In Studies in Linguistic Analysis (Pp. 1-31). Special Volume of the Philological Society. Oxford Blackwell. [Reprinted as Firth (1968)] - References - Scientific Research Publishing‚Äù\n","permalink":"https://flecart.github.io/notes/word-embeddings/","summary":"One very insightful idea is unsupervised word representation. That is just say take a lot of text and try to model the word representations statistically.\nSalton (1975) was one of the first researchers that tried to use the techniques that later will be common in Google searches.\nTheory Johnson-Lindenstrauss Lemma This lemma basically says that semantic embedding is possible, without giving a real algorithm to do so. This seems to be a nice resource about this lemma.","title":"Word Embeddings"},{"content":"Some useful links Main results: https://jblevins.org/notes/accept-reject\nIntuition: https://en.wikipedia.org/wiki/Rejection_sampling\nLa cosa √® che faccio sampling fra due distribuzioni diverse e devo settare anche un parametro (e a seconda di certe cose diventa molto lento).\nIntroduzione al metodo Vorrei utilizzare una funzione $g$ per generarne una altra, questo √® il fulcro del concetto. L\u0026rsquo;idea principale √®:\nConosco la funzione densit√† della funzione $f$ che voglio andare a generare Riesco a generare seguendo una funzione semplice, la chiamo $g$, candidate density. (che √® la densit√† che utilizzo per calcolare il target che non conosco molto bene). Ma devono esserci due cose:\nDue densit√† devono avere lo stesso supporto La funzione $\\frac{f}{g}$ deve essere limitata superiormente. (perch√© √® come l\u0026rsquo;esempio del lago in cui lancio cose dentro per approssimarne il valore). Allora sia $M$ il limite superiore, un buon modo per fare sampling sar√† allora $$ U \\leq \\frac{1}{M} \\frac{f(Y)}{g(Y)} $$ Ossia genero $Y$ usando g, e genero $U$ in modo uniforme normale Guardo se viene soddisfatta la funzione di sopra Se s√¨ prendo, altrimenti rifiuto e continuo cos√¨. Dimostrazione Probability of accepting dato una certa $M$ allora ho probabilit√† $\\frac{1}{M}$ di accettare un sample generato in questo modo, vedere dimostrazione su wikipedia. Ma qui diamo una altro valore:\n$$ \\mathbb{P}\\left( U \\leq \\frac{f(Y)}{Mg(Y)} \\right) \\ = \\int_{-\\infty}^{+\\infty} \\int _{-\\infty}^{f(Y)/f(X)M} 1 \\, du g(y) \\, dy $$ Dove abbiamo utilizzato la marginalizzazione sulla distribuzione $Y$, quello si semplifica con: $$ = \\int_{-\\infty}^{+\\infty} \\frac{1}{M} \\frac{f(y)}{g(y)} g(y) \\, dy = \\frac{1}{M} $$ E si ha la soluzione.\nAverage waiting time (!) il valore corretto √® $c^{-1}$ dove $$ c = \\sup_{x} \\frac{f(x)}{g(x)} $$ Ad intuito questo sarebbe il valore di $M$ migliore, perch√© √® quello con probabilit√† migliore per fare sampling, ma non so bene perch√© si potrebbe considerare come un concetto di tempo.\nWith Unnormalized density ossia tale per cui l\u0026rsquo;integrale su tutto il supporto non √® 1, ma un valore $k$, si pu√≤ dire che questo algoritmo funziona lo stesso. Il motivo che √® stato dato √® che questa costante si pu√≤ tirare fuori e messa dentro $M$ e quindi sarebbe come il dato precedente.\nconsideriamo $\\tilde{f}$ e $\\tilde{g}$ tale che entrambi non siano normalizzati, magari con costanti diversi, e supponiamo che anche questi siano limitati su $\\tilde{M}$.\nSi pu√≤ vedere che anche in questo caso la probabilit√† di acceptation √® uguale a una costante. di valore $$ \\frac{i}{\\tilde{M} \\cdot k} $$ Dove $k = \\int _{-\\infty}^{+\\infty} f(x) \\, dx$ dato che non √® normalizzato.\n","permalink":"https://flecart.github.io/notes/accept-reject-algorithm/","summary":"Some useful links Main results: https://jblevins.org/notes/accept-reject\nIntuition: https://en.wikipedia.org/wiki/Rejection_sampling\nLa cosa √® che faccio sampling fra due distribuzioni diverse e devo settare anche un parametro (e a seconda di certe cose diventa molto lento).\nIntroduzione al metodo Vorrei utilizzare una funzione $g$ per generarne una altra, questo √® il fulcro del concetto. L\u0026rsquo;idea principale √®:\nConosco la funzione densit√† della funzione $f$ che voglio andare a generare Riesco a generare seguendo una funzione semplice, la chiamo $g$, candidate density.","title":"Accept Reject algorithm"},{"content":"Check function A volte pu√≤ essere molto pesante, perch√©\nWhat does check do? Viene utilizzato per introdurre un constraint check per avere sicurezza su un range. Check e innestamenti üü©- Pu√≤ essere che certe implementazioni non permettano il check innestato, questo √® una cosa molto pesante, perch√© ogni modifica deve andare a rifare la modifica ai subalterni, quindi questo √® pesante pesante.\nAssertions üü©\u0026ndash; Sono dei check fatti al livello dello schema, quindi valgono sempre, e possono essere riutilizzati in table diversi credo. Un altro aspetto √® che √® database wide.\ncreate ASSERTION AtLeastOneEmployee check (1 \u0026lt;= (select count(*) from Employee))) View L\u0026rsquo;uso del view üü© create view ViewName [(attrlist)] as selectstatement [ with [local | cascaded ] check option] viene utilizzato per prendere dati esistenti, e metterli in una forma utile a una sotto-organizzazione, che vuole informazioni specifiche diciamo.\nCheck: viene utilizzato se update √® sensato (soddisfa ancora la check). Grouping, posso creare view con informazioni aggregate, e poi posso usare le informazioni aggregate simile a sopra. Cascaded vs local Cascaded significa che ogni modifica e view, viene riflessa su altri schema e view fisici effettivi Local significa Recursive queries üü•+ In questi casi viene proprio definito un approccio ricorsivo (anche se non ricordo benissimo la sintassi) andiamo a definire cose come caso base, e caso induttivo e poi si fa la query in questo modo.\nIn pratica costruisco una view in modo ricorsivo, e su questa posso farci delle query. Un esempio:\nwith recursive Ancestors(Ancestor, Descendant) AS ( select Father, Son from Fatherhood union all select Ancestor, Son from Ancestors, Fatherhood where Descendant = Father ) select * from Ancestors In pratica nel primo select popolo inizialmente la view, poi in modo ricorsivo, prendo gli elementi dentro la view, prendo alcuni elementi dentro son, e aggiungo tutti gli elementi che soddisfano quella condizione.\nOther expressions Coalesce üü• Ci permette di fare l\u0026rsquo;equivalente del default in alcuni linguaggi di programmazione per me. In pratica restituisce il primo elemento non nullo in una lista, quindi se per caso ho due elementi, e il primo √® nullabile, allora prende il default il secondo.\nEsempio:\nselect number, coalesce(Mobile, PhoneHome) from Employee Se non esiste mobile, si va su phonehome. Si pu√≤ fare una cosa come `coalesce(Dept, \u0026ldquo;None\u0026rdquo;) per mettere il default.\nScalar functions üü® String Time\ncurrent_date extract(yearExpresison) Esempio: SELECT EXTRACT(YEAR from orderDate) AS orderyear, FROM Orders WHERE DATE(orderDate) = current_date() Casting\nnullif Semantica: ritorna null se la condizione √® vera.\n√à buono per far tornare Null se un valore assume un certo valore hardcodato, ad esempio se il default √® \u0026ldquo;Unknown\u0026rdquo; per qualcosa, posso fargli tornare NULL se valore uguale a quella stringa hardcodata.\nEsempio:\nselect Surname, nullif(Dept, \u0026#34;unknown\u0026#34;) from employee Se √® vera la comparazione, si ritorna Null in automatico\nCase expressions üü®\u0026ndash; ### Transactions #### ACID framework üü© - Atomic: o tutto o niente, √® una transazione atomica - Consistency: tutto deve soddisfare i constraints - Isolation: simile ad atomico, le transazioni non devono influenzarsi fra di loro per tempo. - Durability: non √® su ram diciamo #### Example in sql for transactions ![ 600](/notes/structured-query-language-1697712948716.jpeg-) Authorization Privileges (6) Questa parte si ricollega in qualche modo con la parte di renzone, vogliamo specificare una risorsa e dire chi pu√≤ fare cosa su quella risorsa. La risorsa in questo caso pu√≤ essere lettura modifica o eliminazione su una tavola. Posso\nDare permessi (privilegi) Togliere permessi Specificare utenti che hanno permessi Propagazione di privilegi. I privilegi sono esattamente 6, descritti dall\u0026rsquo;immagine sotto Grant privileges grant \u0026lt; Privileges | all privileges \u0026gt; on Resource to Users [ with grant option ] Revoke privileges revoke Privileges on Resource from Users [ restrict | cascade ] Restrict -\u0026gt; non implica anche altri utenti Cascade -\u0026gt; la revoca √® estesa ad altri utenti anche, una reazione a catena. Privilegi come view RBAC √à pi√π facile usare il modello chiamato RBAC, ossia definiamo ruoli, una view, e i ruoli possono accedere solamente a certe view. Usare i ruoli √® un metodo classico, potremmo considerarlo come una astrazione su cosa ogni utente deve fare sul database (quindi le sue operazioni ideali) e da quello andare a descrivere cosa esattamente ha bisogno di poter fare. In questo modo definisco i permessi su questi ruoli ideali invece di andare a farli sui singoli utenti, magari anche ripetendo un sacco di queries.\n","permalink":"https://flecart.github.io/notes/advanced-sql/","summary":"Check function A volte pu√≤ essere molto pesante, perch√©\nWhat does check do? Viene utilizzato per introdurre un constraint check per avere sicurezza su un range. Check e innestamenti üü©- Pu√≤ essere che certe implementazioni non permettano il check innestato, questo √® una cosa molto pesante, perch√© ogni modifica deve andare a rifare la modifica ai subalterni, quindi questo √® pesante pesante.\nAssertions üü©\u0026ndash; Sono dei check fatti al livello dello schema, quindi valgono sempre, e possono essere riutilizzati in table diversi credo.","title":"Advanced SQL"},{"content":"On dangling pointers Tombstones üü© Slides tombstones\nQuando alloco, alloco anche una tombstone, e tutti i riferimenti passano per quella. (quindi ho due dereference per l‚Äôaccesso) quando vado a deallocare segno la tombstone come RIP, NULL.\nDopo molto tempo ho il problema del cimitero che diventa molto grande. Anche se non punta pi√π a niente, il cimitero.\nKeys and locks üü© Un p√≤ di overhead in pi√π dal punto di vista della memoria, che √® doppio\nOn GC Reference counting üü© Quando alloco, mi tengo anche un contatore di riferimenti, ossia puntatori che fanno riferimento a questo blocco. Quando arriva a zero dealloco. Questo √® una variabile privata del GC, non √® accessibile da nessuna parte dall‚Äôesterno.\nCome fare per riferimenti ricorsivi? Se avessimo due elementi che si puntano fra di loro ma non sono accessibili tramite stack?\nCon questa tecnica non √® possibile risolverlo bisogna utilizzare il metodo successivo.\nMark and sweep üü© Slide tecnica mark and sweep\nDefinito in due parti:\nFase di detection, in cui parto marcando tutto, poi se riesco a raggiungerlo tolgo il mark. remotion vado a rimuovere tutti quelli marcati (alla fine √® la stessa cosa marcare non marcare, basta invertire), in questo modo riconosco tutti i pezzi i memoria non raggiungibili e so cosa andare a togliere. Svantaggio principale:\nNon so quando andare a fare mark and sweep:\nOgni tot tempo Quando finisco la memoria (ogni tot memoria). Quando fa GC devo fermare il programma (stop the world) perch√© non ha senso che inserisco cose quando vado a marcare (pensala come modify list quando ci scorri). Per sistemi realtype non funziona proprio, perch√© non posso permettermi di bloccare la computazione. Implementazione: invesione dei puntatori üü®+ Come facciamo ad implementare questa tecnica quando magari √® invocata solamente quando ho finito lo spazio? Non possiamo utilizzare la stack, perch√© la memoria √® finita.\nSi utilizza la tecnica di inversione dei puntatori:\nSlide inversione dei puntatori\nStop and copy Slide tecnica stop and copy\nLa heap √® divisa in due regioni differenti, quando una √® piena (credo) copio tutto nell\u0026rsquo;altra zona. Questo √® buono quando ho pochi blocchi ancora buoni, perch√© ci metterei molto meno a spostare e emttere nell‚Äôaltra.y\nBorrow checking (non fatto) Questa √® la cosa nuova introdotta da Rust.\nOwnership Lifetimes ","permalink":"https://flecart.github.io/notes/garbage-collection/","summary":"On dangling pointers Tombstones üü© Slides tombstones\nQuando alloco, alloco anche una tombstone, e tutti i riferimenti passano per quella. (quindi ho due dereference per l‚Äôaccesso) quando vado a deallocare segno la tombstone come RIP, NULL.\nDopo molto tempo ho il problema del cimitero che diventa molto grande. Anche se non punta pi√π a niente, il cimitero.\nKeys and locks üü© Un p√≤ di overhead in pi√π dal punto di vista della memoria, che √® doppio","title":"Garbage Collection"},{"content":"Dependable systems Introduzione Possiamo individuare alcune propriet√† dei sistemi distribuiti. Per√≤ non siamo riusciti a renderli logicamente validi. Sono ancora un p√≤ misti di linguaggio naturale e della sua ambiguit√†! Comunque possiamo ridurci per guardare quanto un sistema sia affidabile a guardare poche sue caratteristiche precise.\nCaratteristiche fondamentali (4) Queste propriet√† sono pensate naturalmente caratterizzanti dei sistemi. In particolare dovrebbero essere tutti misurabili.\nAvailability\nChe risponde nell‚Äôistante in cui fai una richiesta.\nReliability\nReliable quando non crasha quando comincia a runnare.\nSafety\nNiente di catastrofico avviene, ossia qualcosa da cui non si pu√≤ tornare indietro. Vorrei riuscire a riprendere l‚Äôesecuzione dopo i crash.\nMaintanability\nQuanto √® facile risolvere i problemi quando succedono i problemi.\nFaults Definiamo concetti come errori, faults, system failure. Rispettivamente sono definiti come\nErrore: √® uno stato del sistema che ha causato il comportamento inaspettato faults: cosa che ha causato lo stato d‚Äôerrore. system failure: quando non si comporta come secondo le specifiche. Noi vorremmo avere un modo per controllare i faults. Quindi sistemi che riescano a prevedere, rimuovere e prevenire faults.\nClassificazione dei faults\nSorts of faults (tempo)\nObiettivi dei sistemi distribuiti Possiamo andare ad individuare alcuni principi cardine nella costruzione dei sistemi distribuiti\nTrasparenza Vogliamo che la distanza fisica della locazione del server non sia percepibile, quindi l‚Äôesperienza del sistema distribuito sia come nascosto. Possiamo andare ad individuare molti (probabilmente troppe) tipologie di trasparenza, e non tutte possono essere facilmente garantite (non tutte poi dovrebbero essere garantite secondo me)\nOpenness Per aprirsi alla non-predittibilit√† dell‚Äôambiente in cui presente, il sistema deve essere in grado di cambiare componenti, accettarne dei nuovi, e sapere comunicare con questi. Per questo motivo chiamiamo un sistema distribuito OPEN.\nChiaramente un linguaggio comune per cui parlarsi deve esistere. Diventano quindi importanti le IDL (interface definition Languages) linguaggi nati proprio per definire solamente delle interfacce di comunicazione. (++ sijntassi del protocollo, un buon esempio pu√≤ essere protobuf).\nScalabilit√† Come pu√≤ scalare il nostro sistema distribuito. Di solito pu√≤ scalare verticalmente oppure orrizzontalmente. Per verticale diciamo comprare una macchina pi√π potente. Per orizzontale diciamo comprare pi√π macchine.\nUn problema per la scalabilit√†, molto legata alla trasparenza √® mascherare la latency di comunicazione.\nAvailability Pi√π o meno questo dovrebbe essere il vantaggio dei sistemi distribuiti, che essendo replicati, √® molto probabile che siano tutti ON. Questo concetto dell‚Äôavailability comunque racchiude il concetto di quanto spesso ti risponde alle tue richieste.\nTipologie di sistemi distribuiti Distributed computing systems Questi sono i sistemi principalmente devoti al calcolo scientifico. (Quindi utilizzo di protocolli come Beowulf, che permettono un calcolo molto veloce e coordinato in Rete LAN, utile a fare calcoli molto simili.\nQueste cose si dividono in cluster, e grid. Il primo fa cose molto simili fra di loro. Il secondo pu√≤ fare anche cose diverse (mi pare, non ne sono sicuro).\nIl cluster possiede stesso sistema operativo e sono solitamente messi nella stessa zona, collegati a una LAN molto veloce. Di solito √® questo il modo con cui si costruisce un supercomputer, perch√© √® la cosa pi√π economica ammassare tanti computer insieme che lavorino bene per avere potenza di calcolo superiore.\nEsempio cluster beowulf\nInvece i Grid sono utili per connettere aree amministrative diverse. Quindi boh‚Ä¶ Forse connessione fra uni diverse, filesystem condiviso?? buo.\nDistributed information systems Storicamente √® stato presente un fortissimo bisogno di coordinare i basi di dati di dipartimenti anche molto diversi affinch√© non ci sia una ripetizione inutile di dati che possa andare a causare una burocrazia molto elevata. C‚Äô√® stato quindi bisogno di creare un sistema di middleware condiviso a tutti i basi di dati che provava a rendere consistente tutte le basi di dati diverse.\nPervasive systems Attualmente tutte le persone possiedono dispositivi di calcolo, quindi √® importante dare risalto anche a questo modello di sistema distribuito.\nPrincipalmente i metodi per questa parte la dividiamo in 2 parti:\nSensori che inviano costantemente dati (overhead network e il server che li deve processare) Sensori che hanno un processore locale, e dati locale, che rispondono in modo coerente (come se fossere un unico sistema) quando sono chiesti da una query Paxos Paxos √® un protocollo utile per risolvere il problema di Bizantine agreement, creato da Lamport nel 1998. per BA guardare Syncronous model.\nL‚Äôidea √® dividire il processo di agreement in due fasi. Una priomise e un commit.\nPoi andiamo a definire alcuni agenti principali in questo protocollo. Dei proposers,acceptors, quorum.** I primi propongono, gli altri accettano. Quando √® stato raggiunto un quorum, allora si va alla seconda fase, quella di commit o accettazione, se √® rifiutato si torna a prima, altrimenti si va al commit. Pu√≤ esserci livelock?\n","permalink":"https://flecart.github.io/notes/goals-of-distributed-systems/","summary":"Dependable systems Introduzione Possiamo individuare alcune propriet√† dei sistemi distribuiti. Per√≤ non siamo riusciti a renderli logicamente validi. Sono ancora un p√≤ misti di linguaggio naturale e della sua ambiguit√†! Comunque possiamo ridurci per guardare quanto un sistema sia affidabile a guardare poche sue caratteristiche precise.\nCaratteristiche fondamentali (4) Queste propriet√† sono pensate naturalmente caratterizzanti dei sistemi. In particolare dovrebbero essere tutti misurabili.\nAvailability\nChe risponde nell‚Äôistante in cui fai una richiesta.","title":"Goals of Distributed systems"},{"content":"Metodi di key exchange\nTrusted Key parties (sono come Certificate authorities studiati in Sicurezza delle reti) Merkle Puzzles DH protocol Trusted Third parties Squared Key problem Un problema abbastanza ovvio √® che per storare le chiavi di tutti c\u0026rsquo;√® una necessit√† $O(n^{2})$ on $O(n)$ users Se c\u0026rsquo;√® un trusted key parties il numero delle chiavi si riduce di molto, ritorna ad essere lineare!\nProtocols Toy Exchange protocolüü© TTP = Trusted Third party (simile a quanto poi si avr√† in Asymmetric Cryptography) Questa √® la base del servizio di Kerberos! Il servizio di sopra √® sicuro su Choosen plaintext, dato che Eve non capisce niente senza le chiavi!\nQuindi in pratica vengono scambiate due cose, un ticket e la chiave segreta, creati da TTP che sa creare segreti e conosce singole chiavi di tutte.\nAssumendo CPA security l\u0026rsquo;attaccante non pu√≤ sapere niente su $k_{AB}$, che sembra roba random. Problema:\nTTP √® il single node of failure se viene compromesso tutto viene compromesso, √® un obiettivo troppo Juicy. Pu√≤ essere soggetto a replay attacks senza problemi (ad esempio rimandando quanto mandato da Alice (es. se √® stato comprato qualcosa, se si ripete tutto si compra di nuovo, questo √® un danno)). La cosa carina √® che usa solo chiavi simmetriche, niente di nuovo rispetto Classical Cyphers, OTP and Stream Ciphers, Block Ciphers. Merkle Puzzles vogliamo cercare di risolvere problemi di origliamento (eavesdrop, senza modifiche varie sul messaggio. Avversario passivo. Vogliamo farlo senza avere un #Trusted Third parties, ma vogliamo usare solamente symmetric crypto. La cosa √® che questo √® possibile, ma molto inefficiente per cui inutili nella pratica.\nThe puzzle protocol Suppose we have $E(k, m)$ with $k \\in \\left\\{ 0, 1 \\right\\}^{128}$. Define $E(P, message)$ and $P = 0^{96} \\mid b_{1}\\dots b_{32}$, and a $x_{i} \\in \\left\\{ 0, 1 \\right\\}^{128}$and we want to find $P$ back by some sort of brute-force.\nAlice:\nCreates $2^{32}$ puzzles by creating $E(0^{96} \\mid P_{i}, \\text{ \"Puzzle \\#}x_{i} \\text{\"} \\mid k_{i})$ Sends every puzzle to Bob Bob: Chooses a puzzle randomly and tries to solve it (try all possible $P_{i}$), when the first part matches, the puzzle is solved Send $x_{j}$ to Alice Alice: Check what puzzle was chosen, then $k_{j}$ is the shared key. Quadratic Gap Alice and Bob to $O(n)$ work to create and solve a single puzzle. An attacker would need to break all the $2^{32}$ keys, so it is $O(n^{2})$ cost, which is $2^{64}$.\nTo increase the security, they should make $n$ bigger, but it would be very very slower. The nice idea is that participant has linear time, while the attacker needs squared time. It is called quadratic gap. We don¬¥t know if quadratic gap is the best gap we can do, but intuition says so.\nDiffie-Hellman Protocol In this case we have a exponential gap between participant and attacker.\nIntroduzione DH üü© Questo √® quello che abbiamo studiato anche a Olycyber quindi √® pi√π facile. √à basato su una costruzione matematica molto simile a RSA.\nIn pratica cos√¨\nScelgo $p$ primo largo Scelgo $g$ Alice sceglie $a$, e manda $g^{a}$ a Bob Bob fa lo stesso con $b$ Il segreto √® $g^{ab}$ , che √® difficile da capire con i moduli, faremo una analisi di sicurezza in seguito. Best algorithm for attacking this is $\\exp (O(\\sqrt[3]{ n})$, it is the Generalize Field Sieve (with a very high constant, like 80), not explained here here.\nDifficulty comparison Simmetric cipher DH Elliptic Curve 80 bits 1024 bits 160 bits 128 bits 3072 bits (in reality about 2048) 256 bits 256 bits 15360 bits 512 bits Attacco a DH üü© DH √® insicuro dal punto di vista del Man in the middle. Perch√© se uno in mezzo intercetta, pu√≤ usare la sua chiave privata al posto di quella dell\u0026rsquo;altro interlocutore. Tanto conosce il valore di $g$ e gli basta questo. ","permalink":"https://flecart.github.io/notes/key-exchange-protocols/","summary":"Metodi di key exchange\nTrusted Key parties (sono come Certificate authorities studiati in Sicurezza delle reti) Merkle Puzzles DH protocol Trusted Third parties Squared Key problem Un problema abbastanza ovvio √® che per storare le chiavi di tutti c\u0026rsquo;√® una necessit√† $O(n^{2})$ on $O(n)$ users Se c\u0026rsquo;√® un trusted key parties il numero delle chiavi si riduce di molto, ritorna ad essere lineare!\nProtocols Toy Exchange protocolüü© TTP = Trusted Third party (simile a quanto poi si avr√† in Asymmetric Cryptography) Questa √® la base del servizio di Kerberos!","title":"Key Exchange protocols"},{"content":"Si pu√≤ osservare che per il parser costruito in Bottom-up Parser LR(0), non riesce a riconoscere di linguaggi semplici come $L = \\{a, ab\\}$.\nEsempio di quanto detto Parser SLR(1) Questi parser qui utilizzano l‚Äôidea del look ahead ampiamente utilizzata in Top-down Parser, per escludere molte produzioni.\nLa s sta per simple, perch√© utilizza una idea semplice :D, credo ahah boh.\nRiduzione con follow üü© noi vogliamo ridurre solamente se ho follow corretto il terminale finale della stringa.\nQuindi in pratica vado ad aggiungere questa nuova regola per togliere alcune riduzioni senza questo terminale nella tabella.\nEsempio\nalla fine non deve essere solamente per S, deve essere per il follow!, ma sotto nella tabella di parsing ne parliamo un pochino meglio.\nOsservazioni varie (4) üü•+ slide\n√à molto raro che alcune produzioni che hanno la epsilon siano di LR(0), anche se √® possibile! Libero deterministico + prefix property ‚Üí LR(0) not LR(0) ‚Üí libero deterministico + not prefix property or prefix property or not libero deterministico. Finito e LR(0) ‚Üí prefix property. Se √® infinito e LR(0) pu√≤ non godere della prefix property. Tabella di parsing SLR(1) üü®+ Slide\nPraticamente il riempimento di questa tabella √® identica a quella del LR(0), solo con il check in pi√π sui follow di S.\nL\u0026rsquo;unica cosa differente √® che\n$A \\to \\alpha. \\in S, A \\not\\in S',$ allora il reduce si pu√≤ fare in $M[s, x] \\iff x \\in Follow(A)$, ossia solo se ho il follow, non devo andare a fare shift!\nMentre per LR(0) lo devo mettere per tutti gli entry!\nParser LR(1) Item LR(1) üü©- In questa serie di Item dobbiamo ancora andare ad estendere il concetto di item esposto in [Bottom-up Parser LR(0)](Bottom-up Parser LR(0) 92be8778006943cf99add4d634a3fb1a.md).\nApplicando anche una parte di lookahead, di non terminali\nClosure \u0026amp; goto üü© Slide\nLa cosa nuova riguardante questo √® che devo andare a considerare i first e simili!\nSi l\u0026rsquo;unica cosa in pi√π √® che devo agigungere ogni cosa riguardante il first.\nIl goto resta esattamente uguale!\nTabella di parsing üü®+ Slide\nL\u0026rsquo;algoritmo di creazione della tabella di parsing mi sembra sia molto simile a quelle precedenti, per√≤ per capire se ho compreso questo concetto sarebbe utile fare qualche esercizio a riguardo! LR(0) ha detto che per forza ce lo mette in esame!\nEsempio di parsing LR(0)\nNucleo dello stato LR 1\nSe rimuovo il look ahead, allora ottengo lo stato dell\u0026rsquo;automa LR(0)! In questo senso potremmo osservare che le transizioni di LR 1 dipendono solo dal nucleo. Questo diventa un hint molto importante per andare a costruire poi un automa LALR.\nLALR (1) Questi automi sono presenti all‚Äôorale per√≤ allo scritto non ci sono proprio.\nQuesto √® una forma di mezzo fra semplicit√† di SLR e la selettivit√† di LR.\nSi traduce come Look-Ahead Left-reading Right-most derivation 1 lookahead parser\nOsservazioni sulla tabella üü®+ Questo ha una tabella con il nucleo fuso per quelli che hanno le cose uguali, in questo modo cerco di limitare il numero di stati.\nQuesta parte √® molto simile a quanto fatto per la minimizzazione dei dfa in Automi e Regexp, perch√© stiamo andando ad accorpare stati che sono quasi equivalenti, questo col rischio di introdurre alcuni conflitti reduce-reduce che per√≤ non dovrebbero portare a troppi problemi, come andremo presto a vedere.\nEsempio slide entrambi errati\nlezione 16 slide 18\nPossibilit√† di conflitti (no shift-reduce dimo) üü® Slide\nDa questo esempio presente in slide vediamo che una grammatica pu√≤ essere LR(1) e non LALR(1), quindi non sono esattamente equivalenti.\nRiassunto di questa lezione 16\nEsempio LR not LALR üü® Questo √® un esempio importante solo perch√© √® richiesto nelle domande, altrimenti l‚Äôavrei saltato. Comunque basta un p√≤ ricordarsi cose riguardo simmetria della grammatica per costruire quasi ad Hoc un conflitto Reduce-Reduce nella grammatica LALR\nEsempio di conflitto ","permalink":"https://flecart.github.io/notes/bottom-up-parser-lr1/","summary":"Si pu√≤ osservare che per il parser costruito in Bottom-up Parser LR(0), non riesce a riconoscere di linguaggi semplici come $L = \\{a, ab\\}$.\nEsempio di quanto detto Parser SLR(1) Questi parser qui utilizzano l‚Äôidea del look ahead ampiamente utilizzata in Top-down Parser, per escludere molte produzioni.\nLa s sta per simple, perch√© utilizza una idea semplice :D, credo ahah boh.\nRiduzione con follow üü© noi vogliamo ridurre solamente se ho follow corretto il terminale finale della stringa.","title":"Bottom-up Parser LR(1)"},{"content":"1 Calcolo dei numeri finiti Il calcolo √® numerico perch√© si differenzia rispetto a un calcolo normale perch√© √® finito.\n1.1 Errore nei calcoli 1.1.1 Tipologie di errore (5) üü© Errore di misura, dovuto alle imperfezioni dello strumento di misura dei dati del problema. Errore di troncamento, quando un procedimento infinito viene realizzato come procedimento finito. (esempio: calcolo del valore di una funzione tramite sviluppo in serie, perch√© dato che l‚Äôalgoritmo deve essere finito, devo prima o poi interrompere il calcolo, ecco qui l‚Äôerrore). Errore inerente, dovuto al fatto che i dati di un problema non sono in una forma buona diciamo Errore di rappresentazione (simil troncamento) non sempre appartengono all‚Äôinsieme $\\mathbb{F}$ dei numeri rappresentabili e quindi vengono approssimati. Errore algoritmico, dovuto al propagarsi degli errori di arrotondamento sulle singole operazioni in un procedimento complesso. 1.1.2 Misura dell‚Äôaccuratezza üü© Anche per l‚Äôaccuratezza di una misura utilizziamo degli errori (questi tipi di errori li hai anche studiati in fisica durante il liceo).\nErrore assoluto $|stimato - expected|$ di solito ha poco valore perch√© dipende dal contesto, molto pi√π importante il relativo Errore relativo $E_a /expected$ questo molto buono, ed √® in pratica simile all‚Äôerrore percentuale Questo errore mi riesce effettivamente a dare un concetto di precisione del calcolo. Errore percentuale in pratica √® l‚Äôerrore percentuale $\\cdot 100\\%$ 1.2 Rappresentazione dei numeri üü©- Gli argomenti presentati in questa sezione sono gi√† stati trattati in modo anche pratico nel corso di Architettura degli elaboratori in Rappresentazione delle informazioni, qui andremo ad approfondire di pi√π da un punto di vista matematico.\n1.2.1 Numeri interi üü© Questa parte √® totalmente omessa perch√© presente in Rappresentazione delle informazioni\nLa stessa parte, sempre presente l√¨, tratta dell‚Äôalgoritmo di conversione dei numeri interi in binario e decimale\n1.2.2 Numeri reali üü© Slide per la rappresentazioni.\nLa prima cifra deve essere diversa da 0 per garantire unicit√† al numero.\nEsercizio: ricava la formula che rappresenta ogni numero reale in una base qualunque.\n1.3 Sistema floating point üü© 1.3.1 Rappresentazione matematica dell‚Äôinsieme üü© Slide\nl‚Äôinsieme\n$$ \\mathbb{F}(\\beta, t, L, U) = \\{0\\} \\cup \\{x \\in \\R = sign(x) \\beta ^p \\sum_{i = 1}^t d_i \\beta^{-i}\\}\\\\ 0 \\leq d_i \u003c \\beta, i \\in \\N_+, d_1 \\neq 0, L \\leq p \\leq U $$ descrive tutti i numeri nella retta reale che sono rappresentabili secondo il sistema floating point\nQuesto insieme $\\mathbb{F}$ √® finito, non continuo.\n1.3.2 Rappresentazione del numero nel calcolatore üü© Se il numero che vogliamo rappresentare √® nell‚Äôinsieme, allora √® facile, prendiamo quel numero Altrimenti si utilizza un troncamento o arrotondamento della mantissa al numero di $\\mathbb{F}$ pi√π adatto, vediamo come agiscono questi due metodi. Notiamo che questo caso succede quando $\\exists i \u003e t : d_i \\neq 0$.\nTroncamento rappresento tutto il numero fino a $t$ e poi ignoro il resto. Un altro modo per vedere il troncamento √® che arrotonda sempre al ribasso, mai dopo, prende il numero di $\\mathbb{F}$ pi√π vicino e minore del numero che vogliamo convertire.\nArrotondamento simile al troncamento, ma arrotonda. Che si conosca non c‚Äô√® un coso hardware che lo faccia (o comunque implementa questo algo:https://stackoverflow.com/questions/4572556/concise-way-to-implement-round-in-c)\n1.3.3 Breve discussione sui parametri üü© $\\beta$, descrive la base di rappresentazione del nostro insieme $t$, descrive il numero di cifre utilizzate per la rappresentazione, principalmente influiscono sulla precisione (densit√† dei numeri nell‚Äôintervallo, vedi sezione sequente). $U$ descrive il upper bound per la caratteristica (esponente alla base) $L$ uguale a $U$ ma √® un lower bound.\nQuindi $U, L$ descrivono il range di rappresetnazione per il nostro insieme di rappresentazione\n1.3.4 Densit√† dei numeri üü© Slide\nSi pu√≤ notare che col metodo di rappresentazione esposto sopra si possono individuare informazioni sulla dispersione dei numeri nella retta.\nIn ogni intervallo di lunghezza $[\\beta ^p, \\beta^{p + 1}]$ ho $(\\beta - 1)\\beta^{t- 1}$ numeri, distanziati in maniera uguale una dall‚Äôaltra (solo in questo intervallo), appena salgo di intervallo, l‚Äôintervallo cresce. Questo √® anch eun motivo dell‚Äôunderflow, in cui quando sono troppo vicino allo zero, l‚Äôintervallo √® troppo piccolo. (credo, √® da rivedere questa cosa).\nIl motivo di questi numeri √® perch√© ho $\\beta - 1$ numero di modi per scegliere il primo numero (che deve essere diverso da nullo) e il restanti cifre della mantissa come li voglio\n1.3.5 Standard IEEE üü®+ Slide descrizione dei floating points per lo standard IEEE\nIn pi√π sono riservati alcuni numeri per $+0, -0, +\\infty, -\\infty$. e NaN (esempio quando faccio 0 * inf ho un NaN)\nNota questi valori non sono codificabili nella forma che √® presente in slide, per√≤ lei li vuole cos√¨ quindi impara a memoria per l\u0026rsquo;esame saddo.\n1.3.6 Errore di rappresentazione ed errore di macchina üü©- Con double $\\approx 10^{-16}$, con float $\\approx 10^{-7}$\nDefinizione simile di epsilon, ma nell‚Äôaltro verso üü® TODO: chiedere se le due definizioni sono equivalenti pg 50 pdf introduzione al calcolo numerico\neps √® il pi√π piccolo numero macchina positivo tale che $eps + 1 \u003e 1$, in pratica √® il pi√π piccolo numero che √® arrotondato al pi√π piccolo numero rappresentabile da $\\mathbb{F}$.\nPer il calcolo dell‚Äôeps per il valore dell‚Äôerrore macchina ti puoi rifare a questo post machine epsilon value for IEEE double precision standard alternative proof using relative error\nLa prof ha sbagliato in questa parte, ha copiato il valore di epsilon per l‚Äôarrotondamento con normalizzazione che parte da 1, quindi il valore corretto di epsilon dovrebbe essere $\\varepsilon_{mach} = \\dfrac{1}{2}\\beta ^ {1-t}$. Anche la pagina di wiki spiega bene questa parte di dimostrazione dell‚Äôerrore macchina\n1.4 Aritmetica floating point 1.4.1 Definizione di funzione üü© √® una funzione $\\circ : F \\times F \\to F$, ma pu√≤ succedere che una operazione che prende due operandi da F e F non sia ancora in F, e quindi c\u0026rsquo;√® bisogno di arrotondarlo ad F, causando un errore di\n$$ | \\dfrac{x \\circ y - x \\cdot y}{x \\cdot y} | \u003c \\epsilon $$ Il valore √® sempre minore perch√© epsilon √® il maggior errore possibile per singola operazione\nPropagazione dell‚Äôerrore üü© Il processo di propagazioen dell‚Äôerrore √® molto difficile da tenere in considerazione, quindi ci limitiamo a considerare alcuni casi tipici di errori inerenti nell‚Äôoperazione di somma e sottrazione:\nNOTA: per questa parte $\\varepsilon$ √® definito come il pi√π grande numero tale che $1 + \\varepsilon = 1$, che √® quasi equivalente all\u0026rsquo;altro.\nSomma di due numeri con esponente molto differente, perch√© finisce che il computer non ha abbastanza bit in mantissa per rappresentare il risultato, e quindi deve andarea troncare. Questo incide principalemente su bit di poco significanza. $(1 + \\varepsilon) + (1 + \\varepsilon) = 1 + 1 = 2$, cos√¨ abbiamo perso $2\\varepsilon)$ Differenza fra numeri molto simili, questo incide su bit di grande signfiicanza: Esempio: ( $(1 + \\varepsilon) - (1 - \\varepsilon) = 0$ abbiamo perso $2\\varepsilon$, ma questo √® un errore relativo direi pi√π grosso, credo. Importanti sono l‚Äôesempio presente nelle slides epr il calcolo del numero di nepero\n","permalink":"https://flecart.github.io/notes/calcolo-di-numeri-finiti/","summary":"1 Calcolo dei numeri finiti Il calcolo √® numerico perch√© si differenzia rispetto a un calcolo normale perch√© √® finito.\n1.1 Errore nei calcoli 1.1.1 Tipologie di errore (5) üü© Errore di misura, dovuto alle imperfezioni dello strumento di misura dei dati del problema. Errore di troncamento, quando un procedimento infinito viene realizzato come procedimento finito. (esempio: calcolo del valore di una funzione tramite sviluppo in serie, perch√© dato che l‚Äôalgoritmo deve essere finito, devo prima o poi interrompere il calcolo, ecco qui l‚Äôerrore).","title":"Calcolo di numeri finiti"},{"content":"Indexes Trattiamo qui di alcuni metodi che sono utilizzati per costruire indici\nIntroduction to indexes Gli indici sono una struttura di dati aggiuntiva che ci permette di ricercare pi√π in fretta alcuni valori per le queries. In questa sezione proviamo ad approfondire in che modo possono essere costruite e gestite.\nSearch keys üü© Sono in breve la cosa che vogliamo andare a cercare. Solitamente sono nella forma \u0026lt;key, label\u0026gt;, che ci permette di trovare in fretta il label, che si potrebbe intendere come il valore che noi stiamo provando a cercare.\nLabels and record identifiers (3) üü© Primary vs secondary indexes √à primary se gli attributi che vengono guardati contengono la chiave primaria della relazione Altrimenti √® secondary Dense vs sparse indexes üü© Dense se per ogni chiave del file esiste una chiave di ricerca. Altrimenti √® sparsa. Chiaramente per index sparsi abbiamo bisogno di meno spazio per storarli in memoria!\nClustered vs unclustered indexes üü©\u0026ndash; Clustered se viene utilizzato l\u0026rsquo;ordine dei labels (eh, non ho capito questo criterio credo.)\nChiaramente se √® unclustered non abbiamo pi√π i vantaggi della cache, e quindi √® pi√π lento accedere!\nSequential Index example In pratica dividiamo il file in molti pezzi contigui, e proviamo ad indexarli in modo contiguo, come in figura: Questo metodo √® denso e clustered per fare indexing, mentre per il fatto che sia primario o meno dipende!?\nB-trees Abbiamo circa 40ms per l\u0026rsquo;accesso al blocco, solitamente di tipo 4k bytes. La osservazione principale √® che gli algoritmi non lavorano pi√π in RAM, che √® facile accedere subito (nanosecondi ad accedere), quindi √® pi√π facile fare algoritmi che tengano in conto questa cosa.. La base di dati ha bisogno di indici, perch√© in questo modo utilizzo permette il miglior accesso\nun index √® interamente di grandezza del blocco. Dipendente da chiavi valori. Un indice un singolo blocco diciamo (quindi abbiamo centinaia di archi) (il costo √® $\\log_{n}(N)$) con $n$ il branching factor. Con pochi livelli, posso accedere a molte cose! (quindi faccio pochi seek per raggiungere i valori). Indici Sono delle coppie chiavi valori con cui si vanno a cercare\nTipologie di indici (3) B-trees Nodi interi e nodi foglia Abbiamo che √® un albero con pi√π rami, solitamente largo per non necessitare di pi√π letture per andare a leggere (ricorda che ram √® circa un milione di volte pi√π veloce!). Praticamente\nInsertion and deletion Quando ho trovato il nodo in cui inserire, e trovando che il nodo √® pieno, dovrei provare a spezzare, e creare un nuovo nodo genitore e c\u0026rsquo;√® lo stesso il processo ricorsivo anche sul genitore, se non c\u0026rsquo;√® spazio continuo a dividere (anche la radice si pu√≤ splittare). Vedi slide 30 Lab06 Per la deletion la slide √® 39.\nC\u0026rsquo;√® un fattore di riempimento che si dovrebbe andare a considerare, per capire se posso fondere pi√π nodi assieme, in modo che non debbano prendere troppo spazio.\nCome in immagine:\nL\u0026rsquo;algoritmo √® molto chiaro se visto con le immagini e gli steps, poi in questa occasione non ci interessa analizzarlo.\nNotare: questa √® una implementazione un po\u0026rsquo; meno efficiente perch√© i valori effettivi possono essere presenti solamente sulle foglie, sarebbe pi√π efficiente se si vede che in un nodo intermedio il valore esiste allora esister√† anche sulle foglie per cui si pu√≤ gi√† restituire il risultato. Questo applicativo ha una versione pi√π efficiente: https://www.cs.usfca.edu/~galles/visualization/BTree.html.\nHashes Gli hash sono utili per la ricerca di chiavi uguali tipo per indici oppure per database piccoli (credo) che non hanno bisogno di b-trees.\nStatic Hash üü© Per questa tipologia di hash allochiamo uno spazio fisso non estensibile. Data una certa chiave di ricerca, andiamo a prendere il bucket con quel valore. Se √® gi√† pieno si possono usare linked list o alberi per memorizzare il valore.\nAnche in questo caso, come per i B-trees, si invita a guardare le slides, oppure disegnare per una comprensione migliore dell\u0026rsquo;argomento.\nExtensive hash üü®+ Elementi di rielievo:\nOgni singolo blocco ha un contatore che indica il numero di bits utilizzati per indexarlo. Abbiamo un blocco intermedio di puntatori che vanno sui singolo blocchi di dati, contiene anche un dato che indica numero di bits per indexare il singolo bucket. L\u0026rsquo;algoritmo di insertion √® un po\u0026rsquo; pi√π complicato, e differenzia caso in cui il numero di bit per indexare il blocco sia uguale o minore rispetto a quello per i bucket. Anche in questo caso dovresti descrivere l\u0026rsquo;esecuzione dell\u0026rsquo;algoritmo con immagini, aiuta molto.\nL\u0026rsquo;unica cosa negativa √® il fatto di crescere in modo esponenziale per lo spazio nelle directories in casi proprio avversariali (o comunque molto difficili con una distribuzione normale diciamo).\nLinear Hash In questo caso cresce un blocco alla volta, finch√© un certo threshold di record/numbero di buckets viene soddisfatto si resta, altrimenti prova a crescere. Anche in questo caso come static hash, usiamo gli overflow blocks.\nInverted indexes introduzione sul funzionamento Per gestire cose come testo a volte pu√≤ risultare utile fare questo genere di index per trovarlo. In pratica, supponiamo di avere n indici, allora possiamo fare una tabella nella forma\nParola -\u0026gt; Doc(posizione) In pratica matcho ogni singola parola con il documento e la posizione all\u0026rsquo;interno del documento che la parola ha, in questo modo posso fare ricerca veloce nelle posizioni in cui la parola compare.\nQuando cerco una stringa esatta posso prendere l\u0026rsquo;intersezione fra i documenti in cui compaiono e restituire solamente quelle\nLinguistic preprocessing Sono metodi per diminuire la veriet√† delle parole in modo che io abbia bisogno di meno spazio poi per memorizzare l\u0026rsquo;inverted index. Posso fare cose come\nStemming: in cui rimuovo lo stemdella parole, quindi suffissi o prefissi ricorrenti Normalization: ad esempio metto tutto minuscolo. Rimozione stop worlds: perch√© sono inutili ch√© non danno molte informazioni\n","permalink":"https://flecart.github.io/notes/index-b-trees-and-hashes/","summary":"Indexes Trattiamo qui di alcuni metodi che sono utilizzati per costruire indici\nIntroduction to indexes Gli indici sono una struttura di dati aggiuntiva che ci permette di ricercare pi√π in fretta alcuni valori per le queries. In questa sezione proviamo ad approfondire in che modo possono essere costruite e gestite.\nSearch keys üü© Sono in breve la cosa che vogliamo andare a cercare. Solitamente sono nella forma \u0026lt;key, label\u0026gt;, che ci permette di trovare in fretta il label, che si potrebbe intendere come il valore che noi stiamo provando a cercare.","title":"Index, B-trees and hashes"},{"content":"Matrice Jacobiana √à un modo per scrivere il gradiente di una funzione quando √® in una certa forma.\nData una funzione $f: \\mathbb{R}^n \\to \\mathbb{R}^p$ ossia per esempio $x=(x_1,...,x_n) \\to(f_1(x),...,f_p(x))$ Se le p funzioni di arrivo sono differenziabili, allora la matrice Jacobiana √® definita in questo modo:\n$$J_f(x) = \\begin{pmatrix} \\delta_{x_1} f_1(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{x_n} f_1(x)\\ . \u0026amp; . \u0026amp; . \\ \\delta_{x_1} f_p(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{x_n} f_p(x)\n\\end{pmatrix}$$\nUna matrice con p righe e n colonne, che rappresentano tutte le derivate parziali possibile\nOsservazione Da una funzione differenziabile $f(r(x))$ in modo simile a quanto fatto prima, abbiamo che $J_f(r(t)) J_r(t)$ √® uguale al prodotto scalare!\n$$ (\\delta_1f(r(t)), ..., \\delta_nf(r(t))) \\cdot \\begin{pmatrix} \\delta_{s} r_1(t) \\\\ . \\\\ \\delta_{s} r_n(t) \\end{pmatrix} $$ Ossia √® proprio $\\delta_t(f(r(t))$ il prodotto scalare, ossia $J_{f \\cdot r}(t)$ e la cosa bella √® che vale per dimensione qualsiasi. (vedere gli appunti lezione 11, ci dovrebbe essere l\u0026rsquo;enunciato di questo).\nComposizione di funzioni\nSi pu√≤ dimostrare che la Jacobiana si comporta bene per le composizione di funzioni ossia:\nE questo vale per funzioni definite per qualunque dimensione.\n$$ J_{g \\cdot f}(v)= J_g(f(v)) J_f(v) $$ √à importante in questo caso avere in mente come viene fatta la chain rule nel caso multivariabile perch√© avremo qualcosa di questo genere: $$ \\frac{ \\partial y_{i} }{ \\partial x_{j} } = \\sum_{k = 1}^{m} \\frac{ \\partial y_{i} }{ \\partial z_{k} } \\frac{ \\partial z_{k} }{ \\partial x_{j} } $$ Dobbiamo sommare per tutti i $k$ intermedi.\nStudio del massimo e del minimo In pi√π dimensioni non possiamo pi√π applicare lo studio del segno della derivata come nella prima dimensione, in questo momento abbiamo pi√π derivate, e non abbiamo nemmeno il concetto di funzione crescente. Vogliamo affidarci al concetto delle derivate seconde (concavit√† e convessit√†)\nVedere che $f'(x) = 0 \\land f''(x)\u003e0$ oppure minore. Andremo a generalizzare questa idea.\nCondizione di stazionariet√† Andiamo a definire una condizione di stazionariet√† a pi√π dimensione, che ci sar√† molto utile per trovare il minimo locale (o massimo locale).(√® anche chiamato fermat, come ti ricordi qui Teoremi Base Analisi)\nsia $f:A \\to \\mathbb{R}, \\bar{x} \\in A$ √® minimo locale, f √® differenziabile in xbar, allora si ha che $\\nabla f(\\bar{x}) = 0$\nQuando il gradiente si annulla, quel punto in cui si annulla si chiama punto critico o stazionario.\nLa stazionariet√† non permette di distinguere massimi e minimi (valeva anche per R dim 1 Def: punto di sella √à la generalizzazione di un punto di flesso (in cui 2 derivata seconda si annullava).\nsia $f$ una funzione ben definita differenziabile tale che il suo gradiente sia 0 in un punto a. Allora si dice che il punto a √® di sella se esistono due punti $x_{0}, x_{1}$ per ogni intorno di $a$, tali per cui $f(x_{0}) \u003c f(a) \u003c f(x_{1})$\nIn pratica mi sta dicendo che comunque io mi avvicini a questo punto, riesco sempre a trovare un punto la cui immagine √® minore, e riesco sempre a trovare un punto la cui immagine √® maggiore.\nQuesto √® la terza possibilit√†, nel caso questo punto stazionario non sia n√© massimo n√© minimo.\nNecessit√† della differenziabilit√† Affinch√© valga la condizione di stazionariet√† devono sempre esistere almeno le derivate parziali in OGNI direzione.\nQuesto √® utile per le considerazioni dell\u0026rsquo;inverso, in quanto per $f(x) = \\lvert x \\rvert$, nel punto 0 non √® differenziabile, ma √® un punto di minimo.\nDimostrazione Sia f ben definita e a un punto di minimo locale, vogliamo dimostrare che ogni derivata parziale in questo punto sia 0. (ovvero che il gradiente sia 0).\nConsideriamo $g(t) = f(a + te_1)$, ovvero incrementato solamente nella direzione 1. Poich√© f ha minimo in a, ho che per t=0 ho un minimo locale di g (dato che g √® scritta in funzione di f).\nHo che la derivata di g √® la derivata parziale di f (per come √® definita), quindi g √® differenziabile poich√© per ipotesi f √® differenziabile. Per fermat, in quanto t=0 √® un punto di minimo, ho che la derivata di g in t = 0 √® 0, quindi applicando questa idea per ogni direzione ho che l\u0026rsquo;intero gradiente √® 0.\nDerivata seconda Possiamo derivare parzialmente in pi√π direzioni\nDerivate seconde pure se derivo rispetto alla stessa variabile anche la seconda volta\nDerivate seconde miste se derivo rispetto a una variabile differente.\nMatrice Hessiana Questa matrice contiene tutte le derivate seconde possibili per una certa funzione da Rn a R (sar√† di dimensione n x n\n$$ Hf(x) = \\begin{pmatrix} \\delta_{11} f(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{1n} f(x)\\ . \u0026amp; . \u0026amp; . \\ \\delta_{n1} f(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{nn} f(x)\n\\end{pmatrix} $$\nTeorema di Schwarz Sia $f$ una funzione ben definita, con dominio multidimensionale. Siano tutte le derivate seconde ben definite.\nAllora $\\forall ij \\in \\{1,..,n\\}, i \\neq j$ si ha che $\\delta_{ij}f = \\delta_{ji}f$, ossia √® un altro modo per dire che la matrice hessiana √® simmetrica.\nDimostrazione l\u0026rsquo;idea principale √® utilizzare qualcosa di simile alla differenziabilit√† per continuit√† e derivabilit√† parziale. Considero $g(h) = f(x + h, y+h) + f(x, y) - f(x + h,y) - f(x, y + h)$\npoi considero $u(t) = f(x + t, y+h) + f(x, y) - f(x + t,y) - f(x, y + h)$ e utilizzando lagrange due volte ottengo che $g(h) = \\delta_{xy}f(x + ah, y + bh)h^2$\nCome usare Lagrange due volte Noto che $u(h) = g(h)$ e che $u(0) = 0$. Per Lagrange noto che $u(h) - u(0) = h\\cdot u'(\\theta_1 h)$ con theta da 0 a 1. Facendo la derivata prima di $u$ ottengo che √® uguale a $\\delta_x f(x + t, y+ h) - \\delta_x f(x + t, y)$ perch√© il resto √® costante in t. Utilizzando di nuovo taylor su questo (su y) ottengo che $$ \\delta_x f(x + t, y+ h) - \\delta_x f(x + t, y) = h \\delta_y(\\delta_x f(x + t, y + \\theta_2 y)) $$ mettendo tutto all\u0026rsquo;inizio, ottengo che $g(h) = u(h) - u(0) = h^2 \\delta_y(\\delta_x f(x + \\theta_1h, y + \\theta_2 h))$ Lo faccio ancora per il simmetrico (cio√® costruendomi una funzione v(t) che vari a seconda della y e mi trovo che $g(h) = \\delta_{yx}f(x + ah, y + bh)h^2$\nFaccio il limite per h tendente a 0, dividendo per la stessa variabile, e trovo che sono esattamente uguali. cio√® $\\lim_{h \\to 0} \\dfrac{\\delta_{yx}f(x + ah, y + bh)h^2}{h^2} = \\lim_{h \\to 0} \\delta_{yx}f(x + ah, y + bh)= \\delta_{yx}f(x,y)$ l\u0026rsquo;ultimo uguale √® giustificabile per la continuit√† della funzione f (basta aprire e controllare üôÇ).\nForma Hessiana Conoscendo le forme quadratiche, possiamo andare a definire una forma Hessiana di una funzione di classe $C^{2}$.\nLa forma hessiana di una funzione di class $C^2$ √® la funzione cos√¨ definita:\n$h\\to \\langle Hf(x) h, h\\rangle$\nTaylor di ordine 2 Resto secondo Peano Questa √® una analisi multivariabile vedere sotto per il caso univariabile col resto espresso in altro modo.\nPossiamo andare a definire una funzione di taylor per funzioni do ordine superiore, lo facciamo utilizzando la matrice hessiana (per definire la derivata seconda üòÄ) Possiamo andare in teoria anche a definire formule di taylor di ordine superiore al 2 ma per questo corso finiamo qui. (probabilmente ci saranno matrici pi√π complicate, e di dimensioni maggiori).\nVogliamo dimostrare che $\\forall v \\in \\R^n$\n$$ f(w + tv) = f(w) + \\langle\\nabla f(w), tv\\rangle + \\dfrac{1}{2}\\langle H(f(w)) tv, tv\\rangle + o(|t^2|), \\\\t \\to 0_v, v\\in Dominio $$ Osservazione paraboloide\nScriviamolo in maltro modo:\n$f(w) = f(v) + \\langle\\nabla f(v), w - v\\rangle + \\dfrac{1}{2}\\langle H(f(v)) w - v, w - v\\rangle + o(|(w - v)^2|), w \\to v$\nQuesta √® una funzione al secondo ordine in w, √® un paraboloide in cui possiamo andare a cercare la miglior funzione in questa classe di funzioni quadratiche.\nDimostrazione definiamo $g(t) = f(w + tv)$, la derivata √® uguale a $g'(t) = \\delta_t f(r(t))$ con $r(t) = w + tv$ che per il teorema della derivata di funzioni composte √® $\\langle \\nabla f(w + tv), v \\rangle$ Calcoliamo la derivata seconda di questo, ovvero si va ad ottenere: (praticamente sto applicando la 10.4.4 estensivamente.\n$$ \\sum \\delta_t (\\delta_k f) (r(t))v_k = \\sum \\langle(\\nabla\\delta_k f) (r(t)), r'(t)\\rangle v_k \\\\ = \\sum \\langle(\\nabla\\delta_k f) (r(t)), v\\rangle v_k = \\sum\\sum \\delta_j \\delta_k f(r(t) v_jv_k = \\\\ \\langle Hf(r(t))v,v\\rangle $$ In quanto $g: \\mathbb{R} \\to \\mathbb{R}$ possiamo utilizzare taylor classico per affermare che $g(t) = g(0) + g'(0) t + \\dfrac{1}{2}g''(0)t^2 + o(t^2)$, che per dimostrazione precedente, sostituendo pezzo per pezzo, si ottiene che $f(w + vt) = f(w) + \\langle \\nabla f(w), v \\rangle t + \\dfrac{1}{2}\\langle Hf(w)v,v\\rangle t^2 + o(t^2)$ il che finisce la dimostrazione\nResto secondo Lagrange (univar) Questo √® equivalente al precedente, col resto secondo Peano.\nSia $f:\\mathbb{R} \\to \\mathbb{R}$ f derivabile due volte, allora\n$\\forall x, \\bar{x} \\in \\mathbb{R} , \\exists c \\in [x, \\bar{x}]$ tale per cui\n$$ f(x) = f(\\bar{x}) + f'(\\bar{x})(x - \\bar{x}) + f''(c) \\dfrac{(x - \\bar{x}) ^2}{2} $$ Note sulla dimostrazione Noto che l\u0026rsquo;unica cosa che cambia √® la parte finale della somma, quindi vorrei in qualche modo dimostrare che queste due cose siano uguali.\nIo aggiungo e tolgo questo valore : (imprecisato) e riesco a dire la funzione ottenuta √® un opiccolo per la continuit√† della derivata seconda. questo nella direzione lagrange $\\implies$peano\nNon so esattamente cosa stia facendo in questo momento il prof. Quindi la ometto, dico solo che stranamente sta cercando dimostrare che esiste un valore $k \\in R$ tale che\n$f(x) = f(\\bar{x}) + f'(\\bar{x})(x - \\bar{x}) + k{(x - \\bar{x}) ^2}$ e lo dimostra utilizzando Rolle presente in Teoremi Base Analisi costruendosi una funzione che prenda la roba di sopra.\nOssia mi creo $g(\\bar{x}) = f(x) - f(\\bar{x}) -f'(\\bar{x})(x - \\bar{x}) - k{(x - \\bar{x}) ^2}$ In secondo momento calcolandosi il valore della derivata della funzione cos√¨ creata si ottengono altri valori.\nNel caso in cui derivata seconda √® continua Allora posso dimostrare quanto sopra, semplicemente utilizzando la continuit√† della derivata seconda, perch√© cambiano di poco le due cose.\nResto secondo Lagrange in Rn (multivar) Sia $A \\subseteq \\mathbb{R}^n$ aperto e $f$ di classe $C^2(A)$ ovvero con le derivate seconde continue.\nSia $a, a+h \\in A$ e il segmento $[a, a+h] \\subseteq A$ allora esiste $\\theta \\in (0,1)$ tale che\n$$ f(a + h) = f(a) + \\langle\\nabla f(a), h\\rangle + \\dfrac{1}{2}\\langle H(f(a + \\theta h)) h, h\\rangle $$ Dimostrazione\nconsidero la parametrizzazione data dalla funzione\n$g(t) = f(a + th)$, notiamo che $g(0) = f(a)$ e $g(1) = f(a + h)$ che sono le cose da cui eravamo partiti. se prendiamo $r(t) = a + th$ si ha che $g(t) = f(r(t))$ e allora possiamo utilizzare la derivata di funzioni composte e riscriverla.\nPoi si procede in modo equivalente alla dimostrazione del teorema di lagrange con resto di peano (per√≤ si parte con lagrange con resto lagrange in R).\nPolinomio di Taylor √à un taylor senza opiccolo, per√≤ di devi andare a cercare l\u0026rsquo;appunto giusto.\nForme quadratiche Queste cose sembrano essere un buon utilizzo della matrice hessiana. Comunque vediamo cosa sono: prendiamo una matrice $A \\in \\R^{n \\times n}$ tale che sia simmetrica, consideriamo una funzione $q_A : \\R ^n \\to \\R$ definita in questo modo : $q_A(h) = \\langle Ah, h\\rangle = h^TAh$. Scopriremo che c\u0026rsquo;√® una equivalenza (forse isomorfismo) fra un polinomio di grado n e una matrice n per n. Si pu√≤ dimostrare che √® uguale a una forma quadrata questa matrice, questo perch√© $\\sum^n_{k,j=1} a_{kj}h_jh_k = \\sum^n_{k=1}a_k h^2_k + 2 \\sum_{ 1\\leq j \u003c k \\leq n} a_{jk} h_j h_k$ ed √® qualcosa di molto comodo perch√© questo non √® altro che (ricordando che $a_k$ √® un modo semplice per scrivere $a_{kk}$\n$$ \\langle Ah, h\\rangle = (a_1h_1 + ...+ a_nh_n)^2 $$ Ma questo vale nel caso solo in cui $a_ia_k = a_{ik}$, da ricordare!. Comunque c\u0026rsquo;√® questa buonissima corrispondenza e ci piace molto.\nSegno della forma quadratica Positivo (Negativo) Se per ogni $h \\in \\mathbb{R}^{n} \\neq 0$ si ha che la forma quadratica $q(h) \u003e 0 (\u003c0)$ Esempio se ho solo numeri sulla diagonale, probabilmente √® di segno positivo\nSemi positivo (negativo) Uguale a sopra, ma possiamo avere anche l\u0026rsquo;uguale\nIndefinita Se esistono $h_{1}, h_{2}$ per qui $q(h_{1}) \u003e0$ e che $q(h_{2}) \u003c 0$.\nAltro Ci sono anche altre caratterizzazione della forma quadratica. ad esempio q(h1, h2) = h2^2 non √® n√© indefinita, n√© positiva questa √® semidefinita\nClassificazione del segno n-dimensionale Vogliamo una forma quadratica in Rn, con n‚â•3 ora.(fino ad ora abbiamo solamente considerato il caso in cui forma quadratica √® 2).\nDeterminanti\nMi sono costruito molte sottomatrici.\nLavagna prof\nAutovalori\nTeorema criterio classificazione 2x2 Consideriamo la matrice $$ \\begin{pmatrix} a \u0026 b \\\\ b \u0026 c \\\\ \\end{pmatrix} $$ Allora possiamo individuare i seguenti casi:\nPositivo Una forma quadratica √® positiva sse $a \u003e 0 \\land ac - b^2 \u003e 0$\nNegativa Una forma quadrata √® negativa sse $a \u003c 0 \\land ac - b^2 \u003e 0$\nIndefinita sse il determinante √® negativo., se il determinante √® 0 si dice che √® una matrice singolare.\nDimostrazione primo caso vogliamo dimostrare un sse, andiamo per le due frecce. $\\implies$ Se pongo h = (1, 0) ottengo $a \u003e 0$ quindi deve essere cos√¨ altrimenti assurdo.\nse pongo h = (h,1) (nota questi due h sono diversi) ottengo $ah ^2 + 2bh + c$ che √® sempre positivo quando il determinante √® negativo, quindi verificato\n$\\impliedby$ Se $h_2 = 0$ ottengo $ah^2_1 \u003e 0$ vero perch√© a \u0026gt; 0 e ho un quadrato in R\nSe $h_2 \\neq 0$, allora raccogliendo un h2 e ponendo $e = \\dfrac{h1}{h2}$, ottengo\n$q(h) = ae^2 + 2be + c \u003e 0$ (gi√† diviso per h2 alla seconda), prendendo il determinante ho che √® $b^2 - ac$ , che √® sempre minore di 0, quindi sempre vera.\nSemidefinito\nQuando ho il determinante che √® 0\nCaratteristica positivit√† negativit√† della Forma Quadratica Possiamo trovare una caratteristica fondante per le matrici positive e negative (sono uguali ma inverse, enunciamole).\nSia $A = A ^t \\in \\mathbb{R} ^{n \\times n}$ allora se $A$ √® definito positivo si ha che $\\exists m \u003e 0$\n$\\langle Ah, h\\rangle \\geq m \\lvert h \\rvert^2$\nHint di dimostrazione (osservazione) Questo √® vero perch√© se consideriamo un $h \\neq 0$, possiamo riscrivere l\u0026rsquo;equazione in tesi come $\\langle A \\dfrac{h}{\\lvert h \\rvert}, \\dfrac{h}{\\lvert h \\rvert}\\rangle \\geq m$, che √® equivalente a dire che comunque prendo un vettore unitario, si ha che la forma quadratica √® maggiore di un numero m.\nDimostrazione Allora scrivo h con coordinate polari, apro A in dimensione 2 e raccolgo questo $r ^2$. Allora ho in tesi qualcosa di questo tipo $r ^2 f(\\theta) \\geq r^2 m$ e devo dire che esiste questo m. utilizziamo 2 cose per terminare.\n$r^2 f(\\theta) \u003e 0$ in quanto la forma quadratica √® positiva f √® una funzione continua, e limitata in $[0, 2\\pi] \\in \\mathbb{R}$, quindi possiamo usare Weierstrass per concludere che esiste un minimo. √® proprio questo il minimo! Concludo dicendo che $r^2 f(\\theta) \\geq r^2 m$ per ogni theta, in particolare il minimo √® maggiore di 0 in quanto per ipotesi la hessiana √® positiva, quindi ho finito qui\nDimostrazione con autovalori Condizione sufficiente per minimo e massimo e sella Questa cosa ci piace per calcolare i punti di massimi e minimi!\nMassimo Se il gradiente √® 0 e la hessiana √® definita negativa, ho un punto di massimo.\nMinimo Grandiente 0 e hessiana √® definita positiva, ho un punto di minimo.\nIndefinita Se gradiente √® 0 e la hessiana √® indefinita √® un punto di sella.\nDimostrazione (minimo)\nConsideriamo una funzione $f :A \\subseteq \\mathbb{R}^n \\to \\mathbb{R}$ di classe $C^2$ consideriamo un punto $a \\in A$ tale che $\\nabla f(a) = 0$ e so che $Hf(a) \u003e0$. Voglio dimostrare che sia un minimo locale, ovvero che $\\exists \\delta \u003e0$ tale che $f(a + h) \\geq f(a)$ per ogni $h \\in B(0, \\delta)$, ossia $|h| \u003c \\delta$ Espando con Taylor, e utilizzo l\u0026rsquo;ipotesi di punto critico e ottengo che $f(a + h) - f(a) = \\dfrac{1}{2} \\langle Hf(a),h,h \\rangle + o(|h^2|)$ voglio dimostrare che per un delta opportuno RHS sia maggiore di 0, se ho questa cosa ho finito, in qualche modo voglio utilizzare la positivit√† della matrice hessiana.\nPer il teorema caratterizzante della matrice della forma quadratica, so che $\\exists m \u003e0 \\in \\mathbb{R} :\\langle Hf(a),h,h \\rangle \\geq m \\lvert h^{2} \\rvert, \\forall h \\in \\mathbb{R}^n$ Allora continuando il ragionamento Ottengo che $\\dfrac{1}{2} m \\lvert h^{2} \\rvert+ o(\\lvert h^{2} \\rvert) = \\lvert h^{2} \\rvert(\\dfrac{m}{2} + \\dfrac{o(\\lvert h^{2} \\rvert)}{\\lvert h^{2} \\rvert})$ Ragioniamo ora sull\u0026rsquo;o-piccolo. Allora per definizione di o piccolo, so che posso prendere questa cosa piccola quanto mi pare. In particolare scelgo un intorno in cui questo o piccolo sia compreso fra $m/4$, allora l\u0026rsquo;intorno delta √® definito da questo momento. Scelto questo intervallo allora finire la dimostrazione √® veloce, ottengo che $$ f(a + h) - f(a) \\geq |h^2|(m/2 - m/4) \\geq 0 $$ (abbiamo anche dimostrato che dipende da h) per√≤ √® finito, questa cosa vale per ogni h nell\u0026rsquo;intorno scelto sopra.\nSemidefinita\nNel caso in cui il determinante della hessiana √® 0, non posso utilizzare i metodi precedenti, quindi in questo caso devo dividere il processo analizzando le derivate parziali.\nCondizione necessaria per minimo e massimo √à molto simile alla condizione sufficiente, solo √® abbiamo ora che la hessiana pu√≤ anche essere semidefinita positiva.\n","permalink":"https://flecart.github.io/notes/massimi-minimi-multi-variabile/","summary":"Matrice Jacobiana √à un modo per scrivere il gradiente di una funzione quando √® in una certa forma.\nData una funzione $f: \\mathbb{R}^n \\to \\mathbb{R}^p$ ossia per esempio $x=(x_1,...,x_n) \\to(f_1(x),...,f_p(x))$ Se le p funzioni di arrivo sono differenziabili, allora la matrice Jacobiana √® definita in questo modo:\n$$J_f(x) = \\begin{pmatrix} \\delta_{x_1} f_1(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{x_n} f_1(x)\\ . \u0026amp; . \u0026amp; . \\ \\delta_{x_1} f_p(x) \u0026amp; \u0026hellip; \u0026amp; \\delta_{x_n} f_p(x)","title":"Massimi minimi multi-variabile"},{"content":" The human ability of making analogies proceeds in such a way as to keep complexity minimal.\nPerch√© facciamo questo? Perch√© √® la cosa pi√π semplice da fare! Anche su Vapnik\u0026rsquo;s dimensions √® simile questa idea!\nOccam razor, Epicuro, con Solomonoff che ha risolto problema dell\u0026rsquo;induzione che Hume pensava di fare con abitudini. Attualmente IQ tests provano a misurare la capacit√† di estendere questo.\nAnalogia Studiamo l\u0026rsquo;analogia come oggetto matematico perch√© sembra essere una capacit√† molto difficile da generalizzare e utilizzare nelle macchine.\nDefinizione di analogia Scrivo $A:B :: C:D$ per dire che esiste una relazione $\\mathcal{R}$ tale per cui valga $R(A,B), R(C,D)$ Questa relazione deve soddisfare certi assiomi come\nPropriet√† dell\u0026rsquo;analogia Identit√† $$ \\mathcal{A}(A,B,A,B) $$ Simmetria\n$$ \\mathcal{A}(A,B,C,D) \\implies \\mathcal{A}(C, D, A, B) $$ Permutazione centrale\n$$ \\mathcal{A}(A,B,C,D) \\implies \\mathcal{A}(A,C,B,D) $$ Sono tutte propriet√† che intuivamente hanno senso quando si parla di analogia.\nEquazione di analogia Scriviamo $$ A:B::C:x $$ L\u0026rsquo;obiettivo √® trovare un $x$ nel dominio che soddisfa la relazione $\\mathcal{R}$ scelta, che che sia pi√π semplice possibile. Per la semplicit√† utilizziamo Kolmogorov complexity quindi scegliamo $$ x = argmin(K(A,B,C,x)) $$ Minimum Description length principle https://truththeory.com/2018/05/07/string-theory-explained-what-is-the-true-nature-of-reality-video/\nPrinciple used to choose models to describe phenomenons of the world in particular:\n$$ M_{0} = argmin_{M}(K(M) + K(D|M)) $$ Che √® in un certo senso un trade fra overfitting e undefitting classico, solo da un punto di vista di AIT.\nThe best model is neither the simplest one nor the one that offers the best fit with the data, but the model that achieves the best compromise between simplicity and data fitting.\nUniversal Induction Solomonoff usa principle of Multiple explanations (Epicuro, tiene tutte le spiegazioni che sono buone per i dati).\n","permalink":"https://flecart.github.io/notes/model-of-analogies/","summary":"The human ability of making analogies proceeds in such a way as to keep complexity minimal.\nPerch√© facciamo questo? Perch√© √® la cosa pi√π semplice da fare! Anche su Vapnik\u0026rsquo;s dimensions √® simile questa idea!\nOccam razor, Epicuro, con Solomonoff che ha risolto problema dell\u0026rsquo;induzione che Hume pensava di fare con abitudini. Attualmente IQ tests provano a misurare la capacit√† di estendere questo.\nAnalogia Studiamo l\u0026rsquo;analogia come oggetto matematico perch√© sembra essere una capacit√† molto difficile da generalizzare e utilizzare nelle macchine.","title":"Model of Analogies"},{"content":"Introduzione sui requisiti del software Note introduttive In linguaggio naturale (dizionario) üü•+ Sono tutte le qualit√† necessarie per uno scopo ben determinato.\nSecondo il prof. I requisiti sono dei desideri ossia ci√≤ che idealmente vorresti riguardo qualcosa (nel nostro caso il software). Ma credo sia anche una tendenza italiana di fare le cose meglio possibile senza mai soddisfare tutto\nFunctional requirements üü© Sono ci√≤ che permetter√† di fare il sistema\nEsempio:\nIl sistema permetter√† di prenotare un taxi e di avere una stima del tempo di attesa\nNel nostro caso possiamo anche definire scenario ossia un caso di utilizzo concreto del sistema e user story come ci√≤ che il cliente vuole che il sistema debba fare.\nLegge di Humphrey üü®- I requisiti di un nuovo prodotto software non saranno chiari finch√© gli utenti non iniziano a usarlo\nOssia finch√© non ho una prima soluzione, non so bene cosa voglio -\u0026gt; \u0026ldquo;I\u0026rsquo;ll know it when I\u0026rsquo;ll see it\u0026rdquo;. In un certo senso questo giustifica anche la scelta di iniziare a costruire subito, perch√© prima non puoi sapere, quindi non puoi farne un design. Quando hai una prima versione, poi puoi iterarci.\nProcesso di analisi del requisito (3) üü®++ √à una analisi preliminare, ossia prima ancora di iniziare lo sviluppo e serve per:\nCapire ci√≤ che vuole il cliente (quindi le funzionalit√† che deve avere il sistema finale). Questo √® stabilito senza sapere come effettivamente viene implementato il sistema. Cosa deve soddisfare il sistema, quindi una propriet√† Test per verifica dei requisiti, quindi capire esattamente cosa testare, perch√© la propriet√† possa essere verificabile Vincoli per esempio di sistema operativo, o risorse (quindi giochi per esempio), oppure di tempo, per esempio in cose real time. (o ci√≤ che deve essere costruito, cose funzionali) Requisiti in livelli diversi üü®- Certe formulazioni di requisiti sono pi√π utili a certe parti d\u0026rsquo;azienda, dipende dal livello di astrazione che deve avere il requisito. vedere il triangolino in immagine: User Personae üü© Sono degli utenti ideali, che dovrebbero essere i nostri utenti. Esempio: Ci chiediamo cosa fa questo utente ideale? Quali sono i suoi obiettivi? Cosa fa di solito di abitudine?\nBacklog management Digital product management Passi per la creazione del prodotto digitale (3) üü®\u0026ndash; Ricerca di mercato: ci chiediamo quali sono i prodotti utili? Ideazione del prodotto: quali sono i target principali? Cosa deve essere il prodotto? Per chi √® buono il prodotto? Requisiti del prodotto piano dettagliato di tutti i requisiti ","permalink":"https://flecart.github.io/notes/requisiti-e-backlog-del-software/","summary":"Introduzione sui requisiti del software Note introduttive In linguaggio naturale (dizionario) üü•+ Sono tutte le qualit√† necessarie per uno scopo ben determinato.\nSecondo il prof. I requisiti sono dei desideri ossia ci√≤ che idealmente vorresti riguardo qualcosa (nel nostro caso il software). Ma credo sia anche una tendenza italiana di fare le cose meglio possibile senza mai soddisfare tutto\nFunctional requirements üü© Sono ci√≤ che permetter√† di fare il sistema","title":"Requisiti e backlog del software"},{"content":"Espressioni, Comandi, Ricorsione Espressioni Con espressione intendiamo una entit√† sintattica, che una volta valutata ritorner√† un valore, oppure non termina, in questo caso si dice che la espressione √® INDEFINITA.\nQuesta √® una definizione √® leggermente ambigua dato che non abbiamo una definizione precisa di valutazoine, che √® fortemente dipendente dalla macchina astratta in cui viene eseguito.\nNotazioni (sintassi possibili) (3) üü© Notazione infissa\nQuesta √® la notazione classica matematica, per cose tipo $a -b$, in cui l\u0026rsquo;operando sta nel mezzo degli operatori.\nAbbiamo il vantaggio di famigliarit√† e semplicit√† della istruzione, ma perdiamo con ambiguit√† di precendenza degli operatori e associativit√† degli operatori, cio√® non sempre sappiamo se una espressione ha precedenza con l‚Äôaltra, per esempio una espressione del tipo x == y and y == 1d in un certo linguaggio and ha una precedenza, e quindi farebbe perdere di senso all\u0026rsquo;espressione.\nProblemi di precedenza abbiamo per cose come $1 - 1 -1$, che a seconda se facciamo prima il primo - o il secondo meno possiamo avere dei risultati differenti.\nQuindi se utilizziamo una notazione infissa, guadagniamo di semplicit√† e famigliarit√†, e perdiamo in complessit√† della valutazione, che per essere eseguita vorremmo creare un albero di valutazione, che spesso si deriva dall\u0026rsquo;albero di derivazione dopo il parser.\nNotazione prefissa (polacca)\nSono scritture come questo: $+ \\, a\\,b$, in qui scriviamo prima il + e poi gli operandi.\n√à una cosa molto comoda perch√© non abbiamo la necessit√† di specificare precedenze n√© parentesi, ma basta sapere l\u0026rsquo;ariet√† del nostro operatore per poter valutare l\u0026rsquo;espressione.\nNotazione postfissa (polacca inversa)\nQuesta √® uguale alla precedente, ma al contrario, quindi abbiamo cose come $a\\, b\\,+$, √® anche pi√π semplice da valutare, ma in generale molto semplice.\nPrefissa matematica e di cambridge\ncome f(a, b), oppure (f a b) per cambridge\nInterpretazione dell‚Äôalbero\nSi potrebbe interpretare la notazione infissa, prefissa o postfissa come una visita dell‚Äôalbero di valutazione.\nsimmetrica = visita infissa prefissa = visita prefissa (anticipata) (provo a valutare l‚Äôoperatore e poi vado gi√π) Postfissa = visita postfissa (valuta dopo aver eseguito sinistra e destra) Semantica üü© Con la semantica andiamo ad indicare il processo di valutazione di una espressione. Abbiamo detto prima che per la notazione infissa √® pi√π complicata, infatti dovremmo andare a creare un albero di valutazione, creato dall\u0026rsquo;albero di derivazione (che quando compiliamo col parser √® facile da creare dalle foglie).\nInvece se proviamo a valutare con la notazione prefissa, questa √® una cosa molto pi√π semplice, perch√© basta una singola scansione che va con questo algoritmo:\nSe √® un operatore inizializzo un counter e torno a leggere Se vedo un operando pusho in pila e decremento il counter. Se counter √® 0 faccio l\u0026rsquo;operazione e metto in stack, se √® diverso da 0 torno a leggere Se √® postfissa allora √® ancora pi√π semplice, se ho un operando pusho in pila, se ho un operatore prelevo quanto mi serve ed eseguo e pusho in pila il risultato.\nOrdine di valutazione delle sottoespressioni (4) üü©‚Äî Matematicamente parlando non sarebbe molto importante andare a considerare l‚Äôordine di valutazione, per√≤ in questo caso diventa molto importante perch√© l‚Äôordine stesso potrebbe incidere sul risultato dell\u0026rsquo;espressione, un esempio √® quando una espressione implica un side effect.\nSide effect (come potrebbe essere la chiamata di una funzione con side effect mentre valutiamo l\u0026rsquo;espressione!)\nPossibilit√† di overfow per aritmetica finita eg. (INT_MAX - 10 + 5) vs (INT_MAX + 5 - 10)\nCorto circuito e operatori non definiti.\nPer esempio una scrittura del tipo (p ‚â† NULL) \u0026amp;\u0026amp; (p.next == 1)sarebbe un errore in pascal, perch√© fa una esecuzione eager, cio√® valuta tutto prima di valutare qualcosa, mentre in C se √® null torno subito, questo si dice corto circuito perch√© non vado a valutare tutto. Efficienza, l\u0026rsquo;ordine di valutazione pu√≤ anche cambiare l‚Äôefficienza dell‚Äôesecuzione, ad esempio inizializzando un accesso in memoria, e poi andare a fare altre operazioni che non avevano bisogno di accesso. Perch√© nell‚Äôesempio di sotto √® probabile che aa non sia ancora disponibile, quindi conveniva fare cd prima di andare sull‚Äôaltro, che deve attendere.\nEsempio a= vettore[i]; b = a*a + c*d In questa sede quindi √® importante fare differenza fra\nComandi Definizione di comandi üü© Per comando intendiamo una entit√† sintattica che quando valutata non necessariamente ritorna un valore, inoltre potrebbe fare un effetto collaterale. (NOTA: anche le espressioni possono avere effetto collaterale)\nDa questa definizione non sembra ci sia una differenza chiara con l‚Äôespressione. per√≤ concettualmente dovremmo tenerci in mente che un comando √® qualcosa di utile per cambiare lo stato del programma, ossia alla fine del comando ho uno stato differente, quindi ho avuto un side effect, mentre una espressione √® qualcosa che idealmente non dovrebbe avere side-effect, ma alla fine ritorna sempre un valore.\nUn esempio di side-effect del comando pu√≤ essere la stampa a schermo, che avr√≤ cambiato la zona memory mapped come descritto in Note sull‚Äôarchitettura.\nStato computazione = valore di tutte le variabili nel programma in un certo momento (oppure memoria, boh), va a modificare questo l¬¥effetto collaterale.\nVariabili (2) üü© √à importante tenere a mente che le variabili sono diverse rispetto a quelle definite in matematica, l√¨ sono incognite che possono assumere valori in un certo insieme che non sono modificabili.\nInvece in informatica per le variabili abbiamo due modi principale di interpretazione, una reference model e l\u0026rsquo;altra come variabili modificabili\nIl primo modo intende la variabile come una reference a una zona di memoria in cui veramente √® presente il dato che ho, quindi come se fosse un puntatore (senza possibilit√† di modifica) (solitamente messo nella heap). Quindi la variabile denota il riferimento, alla variabile, non il contenitore al valore.\nIl secondo modo intende le variabili proprio per il valore che possiedono, quindi come contenitore o locazione di memoria che contiene qualcosa che pu√≤ cambiare nel tempo. Sembra molto simile, ma nel secondo modo vado a riferirmi al valore, che √® proprio in quella zona, mentre nel primo caso √® un puntatore ad una altra zona.\nAltri modelli\nSlide altri modelli di variabile\nNei linguaggi funzionali, come le variabili matematiche, che una volta assegnata non √® pi√π modificabile un valore. O modificabili in un certo senso nei linguaggi logici.\nAssegnamento üü© Solitamente l\u0026rsquo;assegnamento ha una forma exp1 assignmentOp exp2a ed √® importante andare a distinguere l-value e r-value.\nl-value √® l\u0026rsquo;indirizzo di memoria (quindi denota una locazione) in cui si dovr√† andare a scrivere la r-value, che solitamente pu√≤ essere la locazione se utilizzo la reference model (e quindi in pratica sposto il pointer in questo modello), o proprio una copia del valore se utilizzo l‚Äôaltra interpretazione, quella delle variabili modificabili, in questo caso indica (un valore che pu√≤ essere contenuto)\nSolitamente questa istruzione produce un side effect (quindi si pu√≤ notare che il side effect sia un necessario), dato che il valore della variabile √® stato modificato, e solitamente non ritiorna nessun valore (tranne in C che ritorna sempre una variabile, perch√© credo che l‚Äôassegnamento √® visto come se fosse una espressione).\nIMPLICAZIONI IMPORTANTI PER SIDE EFFECT.\n√à importante tenere a mente la possibilit√† di side effect, perch√© se provo a fare una cosa come a[f(x)] = a[f(x)] + 1 Questo potrebbe dare risultati differenti a seconda del fatto che io abbia side effect o meno. Sarebbe meglio fare cose come j = f(x); a[j] = a[j] + 1\nGli operatori come += e quelli della stessa famiglia sono utili a ovviare a questo side effect dovuto all‚Äôesempio di prima, ecco una loro utilit√† üòÄ, non √® solo un modo compatto lel.\nControllo della sequenza Ambiente e memoria (3) (ni) üü®‚Äî Slide ambiente e memoria\nSolitamente una associazione del tipo f: nome -\u0026gt; Valore Non √® sufficiente perch√© non posso esprimere che un assegnamento per reference cambi i valori per entrambi (secondo questo modello dovrebbe cambiarlo solo per il singolo nome!).\nSolitamente andiamo a definire 3 modelli di valore:\nValori denotabili da variabili Valori memorizzabili in locazioni di memoria Valori esprimibili come risultati di espressione. All\u0026rsquo;interno del nostro linguaggio imperativo imperativo abbiamo bisogno delle prime due, mentre in un linugaggio funzionale solamente il primo che associa valori a variabili.\nInfatti per utilizzare l-value vogliamo andare a modificare il valore associato alla variabile. mentre per accedere al r-value dobbiamo andare a prendere il contenitore, quindi dovremmo prima accedere alla locazione, e poi dalla locazione andare a riprenderci il valore.\nPoi il fatto che la l-value cambi anche il valore in memoria √® una altra cosa credo‚Ä¶ Non lo ho capito dovrei chiederlo. Questa parte non ha molto senso, e non √® importante posso saltare per√≤ tenere a mente che esistono quelle 3 cose.\nComandi sequenziali üü© Sono comandi come\n; Ossia il singolo comando sequenziali begin ... end Che sono i comandi a blocchi anche indicati con {} in C goto Che √® ora in disuso ma in passato era molto importante. Il goto ha avuto una fortissima discussione negli anni 1970 con Dijkstra. Si basava sull\u0026rsquo;idea di assembly e labels che permettevano di fare salti a piacere.\nIl goto ha la stessa espressivit√† di un programma senza di esso (th di B√∂hn Jacopini) Il goto rende il codice difficilmente leggibile, quindi non permette la facile manutenzione. (si pensi a un goto per uscire da un loop 100 righe dopo, non √® pi√π strutturata la lettura diciamo). Come posso interpretare il fatto di goto che salta all\u0026rsquo;interno di un blocco? Come gestire RdA?? Sarebbe buono utilizzarlo come break e continue, ma ci sono gi√† quei comandi‚Ä¶ Produce spaghetti code (che crea proprio un grafo a forma di spaghetti se seguiamo il flusso di controllo del programma) Viola il concetto della programmazione strutturata, di cui tratteremo in software engineering l\u0026rsquo;anno prossimo. Slides programmazione strutturata\nCondizionali (2) üü© if Bexp then Cl e1se C2 Semmai potremmo dire che ci siano qualche ambiguit√† quando ho qualche if annidato senza delimitatori. Per la valutazione di questi if √® importante tenere a mente che esiste il short-circuit per rendere pi√π efficiente la cosa.\nCase la cosa bella √® che ho un jumping table, quindi rende tutte le operazioni di controllo e salto leggermente pi√π efficienti.\nVelocit√† per la jumping table (faccio solo 2 salti, invece in if-then else √® lineare nel numero di if annidati). Chiarezza del costrutto. Slide case\nEsempio di Jumping table\nIterativi (2) üü© I comandi iterativi sono necessari per la turing completezza del linguaggio\nIterazione indeterminata\nSono comandi come while o repeat ... until oppure il do while. Ed √® indeterminata perch√© prima dell\u0026rsquo;esecuzione non so esattamente quante iterazioni andr√≤ a fare. dal punto della macchina fisica √® molto facile implementarlo, dato che basta un salto con un check, pi√π facile da implementare di un for.\nCon, if, ass, while ho gi√† un linguaggio turning completo! Esattamente come √® descritto in Fondamenti teorica.\nIterazione determinata\nQueste sono tutte le iterazioni in cui conosciamo a priori il numero di iterazioni da compiere (a runtime, prima di cominciare l\u0026rsquo;esecuzione del comando), per esempio for e foreach . Di solito credo che nell\u0026rsquo;implementazione si pu√≤ calcolare il numero di iterazioni\nSi pu√≤ osservare che la iterazione determinata sia meno espressiva dell‚Äôiterazione indeterminata, per√≤ da un punto di vista pragmatico √® molto utile perch√© mi compatta tutta la struttura che esisteva per l‚Äôiterazione indeterminata.\nMeno espressiva perch√© non posso computare programmi come\n$$ f(x) = \\begin{cases} x \\text{ se √® pari} \\\\ \\uparrow \\text{ altrimenti }\\end{cases} $$ Se ho iterazione determinata non riesco a divergere.\nfor {exp1; expz; exp3) comando √® la sintassi di C, ma nota che qui non √® determinata! perch√© posso modificare il valore dell‚Äôindice e anche del controllo, quindi in pratica √® equivalente all‚Äôiterazione determinata (posso renderlo indeterminato modificando l‚Äôindice all\u0026rsquo;interno).\nNOTE DI IMPLEMENTAZIONE\n√à importante capire che in questo caso esiste il vincolo di semantica statica, che il fine e il valore del passo non dovrebbero essere modificati (cosa che non vale in C, per questo non √® il for settato bene).\nCome fare ad implementare il passo? Se √® negativo? Proco a costruire il concetto di iteration counter definito come segue:\n$$ ic = \\lfloor \\dfrac{fine - inizio + passo}{passo}\\rfloor $$ +passo perch√© il fine √® incluso nella iterazione, per questo aggiungo 1.\nRicorsione Definizioni induttive üü© Una cosa cosa molto interessante √® che se possediamo una funzione da $g: \\N \\times A \\to A$, e abbiamo una funzione $f: \\N \\to A$, e un qualunque valore $a \\in A$, allora posto\n$$ f(0) = a \\\\ f(n + 1) = g(n, f(n)) $$ f √® univocamente determinata per tutti i valori del dominio. Basta che g sia una funzione totale.\nCredo che questa definizione della funzione f, sfrutti la struttura dei numeri naturali (la stessa struttura su cui si basa il principio di induzione). Studieremo queste definizioni in maggior dettaglio in informatica teorica.\nIn modo simile una funzione ricorsiva √® simile a questa, √® definita in termini di funzioni precedenti gi√† definite. Nonostante ci√≤ ci possono essere dei casi in cui √® calcolabile, ma si discosta un p√≤ dalle definizioni matematiche.\nCasi in cui ci√≤ si discosta\nSi pu√≤ dimostrare, cosa che non facciamo in questa sede che ricorsione √® equivalente alla iterazione. Nonostante ci√≤ in alcune implementazioni, in particolare l\u0026rsquo;implementazione standard della ricorsione, questo porti a forti inefficienze. Analizzeremo solamente la tail recursion come ottimizzazione possibile.\nTail recursion üü©- Una chiamata di g in f di si dice ‚Äúchiamata in coda‚Äù (o tail call) se f restituisce il valore restituito da g senza ulteriore computazione.\nQuando faccio una chiamata ricorsiva alla fine, prima di ritornare dalla funzione, allora posso ottimizzare tutto il discorso che abbiamo fatto sugli RdA in Nomi e Scope, perch√© non avrei bisogno di allocare un nuovo RdA, mi basta lo spazio attuale!\n√à una cosa molto particolare perch√© con questo riesco a implementare la ricorsione con memoria statica! Un singolo RdA.\nTail recursion si ha quando l‚Äôultima istruzione di ritorno non possiede computazioni aggiuntive, avendo questa propriet√†, la chiamata della funzione pu√≤ essere posta in modo che sovrascriva tutti i parametri, le variabili locali, con l\u0026rsquo;indirizzo di ritorno e il valore di ritorno le stesse della funzione chaiamante.\nIn pratica invece di far crescere continuamente la stack, posso fare in modo di utilizzare lo stesso record scrivendoci i nuovi parametri, un risparmio di memoria non da niente!\n","permalink":"https://flecart.github.io/notes/valutazione-espressioni/","summary":"Espressioni, Comandi, Ricorsione Espressioni Con espressione intendiamo una entit√† sintattica, che una volta valutata ritorner√† un valore, oppure non termina, in questo caso si dice che la espressione √® INDEFINITA.\nQuesta √® una definizione √® leggermente ambigua dato che non abbiamo una definizione precisa di valutazoine, che √® fortemente dipendente dalla macchina astratta in cui viene eseguito.\nNotazioni (sintassi possibili) (3) üü© Notazione infissa\nQuesta √® la notazione classica matematica, per cose tipo $a -b$, in cui l\u0026rsquo;operando sta nel mezzo degli operatori.","title":"Valutazione Espressioni"},{"content":"In this document, we will discuss the actual Wi-Fi standard that we can find in the market.\nThe initial slides consist of extensive lists of Wi-Fi technologies and their uses, such as Bluetooth network, Wi-Fi network, long-range Wi-Fi, and 3G network.\nHowever, they are currently out of service.\nService Sets Basic Service Set There are various divisions within the service set, each of which provides certain types of service.\nIn the basic service, we have things like SSID, which is the service set identifier that is broadcasted in the beacon as described in Mac Wifi.\nThe SSID is mainly used to announce the presence of the network and allow hosts to connect to it.\nExtended Service Set I have an ESS when I have multiple BSSs collaborating with each other to provide service, giving the user a single interface. I believe it could be explained simply as if it were multiple APs that appear as one network.\nAn ESS is typically used to provide wireless coverage over a larger area, such as in a campus or office building, where multiple access points are needed to cover the entire area. The access points within an ESS communicate with each other to provide seamless wireless coverage and allow users to move from one area to another without losing connectivity.\nOne downside of SSID is the default password set by manufacturers (for example, \u0026ldquo;tsunami\u0026rdquo; for Cisco).\nRogue access points ‚Üí attacks on networks left open.\nSecurity considerations See Wireless attack vectors#Defenses of IEEE 802.11.\n","permalink":"https://flecart.github.io/notes/wifi-802-11/","summary":"In this document, we will discuss the actual Wi-Fi standard that we can find in the market.\nThe initial slides consist of extensive lists of Wi-Fi technologies and their uses, such as Bluetooth network, Wi-Fi network, long-range Wi-Fi, and 3G network.\nHowever, they are currently out of service.\nService Sets Basic Service Set There are various divisions within the service set, each of which provides certain types of service.\nIn the basic service, we have things like SSID, which is the service set identifier that is broadcasted in the beacon as described in Mac Wifi.","title":"Wifi 802-11"},{"content":"Gestione delle risorse Introduzione Definizione classe, fungibilit√† Classe di risorse sono un insieme di risorse fra loro equivalenti (nel senso che uno pu√≤ rimpiazzare l‚Äôuso dell\u0026rsquo;altro), anche detti fungibili.\nStatico o dinamico Anche in economia ci sono tali definizioni! Queste risorse possono essere allocate staticamente o dinamicamente, in modo simile a quanto abbiamo detto in Gestione della memoria.\nStatico quando gi√† in fase di compilazione del processo, o di avviamento del processo gli d√≤ la memoria, e quella sar√† per tutti il tempo della sua vita.\nMentre dinamico quando gli d√≤ cose pezzo per pezzo quando √® vivo\nTipologia di richieste e risorse (4) (!!!) MULTIPLO O SINGOLO\nSi pu√≤ dire che il programma pu√≤ chiedere risorse, e le tipologie che puoi richiedere sono multiplo o singole.\nIl significato sembra abbastanza simile:\nSingola per singola classe di risorsa Multipla richiesta per tante classi (la differenza principale √® l‚Äôatomicit√† della richiesta, nel secondo caso, faccio singola richiesta per molteplici classi, o li prendo tutti o zero). BLOCCANTE O NON BLOCCANTE\nSi pu√≤ anche dividere per richiesta bloccante o meno, e anche questo √® molto simile a quanto abbiamo fatto in Programmi Concorrenti. Quindi bloccante come le IO, quando mi metto ad aspettare che finisca, oppure la comunicazione sincrona del Message Passing.\nNon bloccante come il send della comunicazione asincrona, ma anche solo una notifica dell mancato svoglimento, come credo faccia il message passing completamente asincrono.\nCONDIVISIBILE O NON-CONDIVISIBILE\nSi pu√≤ anche dividere in risorse condivisibli o meno, nel senso che una risorsa possa essere utilizzata da pi√π processi contemporaneamente (come i file di sola lettura (o qualunque cosa di solo lettura, perch√© non ho problemi di RW).\nEsempi di non condivisibil sono le cose hardware, processori, stampanti, o anch ele sezioni critiche, versioni software.\nPREEMTABLE O NON-PREEMTABLE\nRisorse preemptable, ossia prelasciabili, quando posso forzare la rimozione della risorsa all\u0026rsquo;utilizzatore.\nuna risorsa si dice prerilasciabile se la funzione di gestione pu√≤ sottrarla ad un processo prima che questo l\u0026rsquo;abbia effettivamente rilasciata\novviamente non vorrei che continuasse senza questa risorsa (quindi la stoppo)\nnon posso cambiare lo stato!! nel senso delle preemptable, se glielo tolgo, lui si aspetta di ricevere la risorsa quando torna a runnare allo stesso stato con cui √® stato tolto! Diciamo √® come se prendo in prestito un tuo giocattolo a forza e poi te lo distruggo, invece te lo vorrei ridare sano, normale diciamo.\nIl Deadlock Gi√† studiato molto in precedenza, vorremmo caratterizzare le condizioni necessarie per i deadlock all\u0026rsquo;interno dei sistemi operativi.\nCondizioni necessarie e sufficienti per DL (4) Slide Necessario e sufficiente per Deadlock Quindi abbiamo caratterizzato con le propriet√† dei Deadlock! Quando ho tutte le 4 suddette cose, allora ho deadlock.\nGrafo di Holt Questo √® un sistema utilizzato per tracciare tutte le dipendenze delle risorse, che possono finire a creare deadlock.\nCaratteristiche di grafo di Holt Grafo di Holt Generale Lo rappresento come classe il quadrato e i puntini come singola risorsa, poi ho altre politiche per fare le frecce\nNote implementative su Holt Come facciamo a rappresentare nella memoria questo sistema? Alla fine √® un grafo pesato! Riduzione di grafo di holt un grafo di Holt si dice riducibile se esiste almeno un nodo processo con solo archi entranti.\nQuesto nodo eventualmente rilascia la risorsa, quindi posso posso riassegnare la risorsa!,\nIn questo modo faccio finta che la risorsa sia gi√† stata rilasciata.\nRiassegno tutti gli archi del processo riducibile agli altri. (non ci importa quale ordine rilasciare) Completa riducibilit√† lo stato non √® di deadlock se e solo se il grafo di Holt √® completamente riducibile, ossia quando non ho pi√π archi nel grafo\ni.e. esiste una sequenza di passi di riduzione che elimina tutti gli archi del grafo\nAd intuito quando ho ancora degli archi, vorr√† dire che c‚Äô√® una attesa circolare, ossia:\nnon tutti i nodi processo hanno tutte le risorse che gli servono Non c‚Äô√® modo di acquisire la risorsa perch√© anche un altro sta aspettando la stessa cosa In questo senso si crea l‚Äôattesa circolare, ed assumendo le altre 3 condizioni di sopra ho deadlock.\nDeadlock detection introduttivo (singola risorsa) Th sola risorsa per classe\nse le risorse sono a richiesta bloccante, non condivisibili e non prerilasciabili, lo stato √® di deadlock se e solo se il grafo di Holt contiene un ciclo.\nGenero il grafo wait-for (chiusura transitiviva degli archi delle risorsa, cio√® se ho P che vuole risorsa, e risorsa assegnata a P2, allora ho P to P2), che in pratica mi genera l\u0026rsquo;attesa circolare (la 4 condizoine necessaria che lo rende sufficiente), e esiste il ciclo.\nSlides del th Esempi Pi√π risorse per classe Questo √® il caso anche pi√π reale, e ci √® molto pi√π utile questo caso. Costruiremo questo caso passo per passo con le definizioni che seguono.\nInsieme di raggiungibilit√† e Knot üü© dato un nodo n, l\u0026rsquo;insieme dei nodi raggiungibili da n viene detto insieme di raggiungibilit√† di n (scritto R(n))\nE si pu√≤ definire knot molto simile a uno strongly connected component, ma diversa:\nun knot del grafo G √® il sottoinsieme (non banale) di nodi $M$ tale che per ogni $n \\in M \\to R(n) = M$\nIn pratica tutti possono raggiungere tutti all\u0026rsquo;interno del Knot.\nEsempio di knot Th deadlock detection con knot Dato un grafo di Holt con una sola richiesta sospesa per processo se le risorse sono a richiesta bloccante, non condivisibili e non pre-rilasciabili, allora il grafo rappresenta uno stato di deadlock se e solo se esiste un knot\nQuindi riusciamo a detectare l\u0026rsquo;esistenza in questo modo!\nAnche se non abbiamo la dimostrazione formale, intuitivamente possiamo dire che se tutti possono raggiugnere tutti, implica l\u0026rsquo;attesa circolare!\nRecovery deadlock (2) Checkpoint e rollback L\u0026rsquo;idea √® molto semplice, praticamente ogni tot si guarda lo stato attuale del progetto, e si tenta di ripartire da l√¨, √® lo stesso concetto del backup (per√≤ si spera che gli effetti dal backup al deadlock, siano effetti di poco costo), e.g. se stampo di nuovo stampa di nuovo, ma non sarebbe buono per cose come la banca.\nTerminazione dei processi Per certe tipologie di processi √® molto molto costoso terminarle:\nEsempio centro di ricerca beowulf ci mette 6 mesi a ripartire Terminare in modo brutale pu√≤ lasciare risorse in modo invalido. Deadlock prevention Spooling Faccio finta a credere di avere gi√† la risorsa. Un esempio √® lo spool di stampa, nel senso che tutti pensano di avere questa risorsa. (questo funziona bene per la stampante per√≤!)\nNon risolve il problema perch√© √® come spostare il problema in altro punto, e NON SEMPRE APPLICABILE.\nProcess table no Dischi no. Per√≤ se il sistema √® in grado di gestire una sua coda, come nel caso di una stampante. Questo metodo sembra molto legit.\nRichiesta bloccante o pre-rilascio nel senso che tutto quello che mi serve all\u0026rsquo;inizio, lo richiedo subito, cos√¨ non mi blocco mai!\nAd esempio i sistemi a real time, che richiedono proprio allocazione totale.\nIl problema √® che non √® sempre possibile fare questo. E poi √® molto inefficiente perch√© se lo tengo per tutto l‚Äôutilizzo del nostro programma, ma alla fine solamente un piccolissimo momento lo utilizzo, inefficienza al pi√π!\nAttesa Circolare Una soluzione forte per questo √® l\u0026rsquo;allocazione gerarchica dei processi. In questo modo sicuramente non abbiamo cicli o interdipendenze. Posso solamente richiedere risorse di classi superiori (in modo che non abbia cicli, quindi diciamo che vada solamente a un verso, e non ho mai modi per avere dei knot).\nAnalisi finale allocazione gerarchica, totale Riassunto dei metodi di prevention Banchiere, DL avoidance Algoritmo del banchiere üü© Dijkstra (1965)\nil nome deriva dal metodo utilizzato da un ipotetico banchiere di provincia che gestisce un gruppo di clienti a cui ha concesso del credito; non tutti i clienti avranno bisogno dello stesso credito simultaneamente\nDescrizione del problema \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Gestione delle risorse/Untitled 14.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Gestione delle risorse/Untitled 14\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Gestione delle risorse/Untitled 15.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Gestione delle risorse/Untitled 15\u0026quot;\u0026gt; Dati in input Stato safe e unsafe üü© Slide stato safe Detto in soldoni, lo stato √® safe quando il credito del tizio che chiede √® minore di tutti i soldi che possiedo. Se non esiste nessuna sequenza che mi garantisca quella cosa sono unsafe!\nunsafe √® necessario ma non sufficiente per DEADLOCK.\nBuona sequenza con ni CRESCENTI.\nEsempio di banchiere safe esempio di unsafe \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Gestione delle risorse/Untitled 22.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Gestione delle risorse/Untitled 22\u0026quot;\u0026gt; Il fatto che sia safe o meno √® utile per capire se si pu√≤ accettare la richiesta o meno!\nBanchiere multi-valuta Dati del banchiere multi-valuta Purtroppo se teniamo come i vettori non possiamo ordinare :(. Quindi vorremmo andare passo passo, e ogni volta aggiungere qualcosa di soddisfacibile.\nTeorema dell\u0026rsquo;algoritmo del banchiere üü©‚Äî Slide algoritmo del banchiere Dimostrazione correttezza Questo mi permette di dire che non importa scegliere qualcosa con logica, se ho una sequenza che va continuer√† ad andare sempre! Mi permette di scegliere a caso.\nPerch√© non √® utilizzato Semplicemente tutte le ipotesi dell‚Äôalgoritmo del banchiere non sono spesso soddisfatte nel momento in cui si prova veramente a metterlo in pratica. Poi gli ingegneri dicono che spesso se un deadlock esiste una volta in 5 anni, per la maggior parte delle applicazioni diventerebbe una cosa tollerabile.\nSi assume che il numero dei processi sia noto all‚Äôinizio Si assume che le risorse necessarie al processo siano note Si assume che le risorse saranno sempre quelle (invece si potrebbero rompere a caso) ","permalink":"https://flecart.github.io/notes/gestione-delle-risorse/","summary":"Gestione delle risorse Introduzione Definizione classe, fungibilit√† Classe di risorse sono un insieme di risorse fra loro equivalenti (nel senso che uno pu√≤ rimpiazzare l‚Äôuso dell\u0026rsquo;altro), anche detti fungibili.\nStatico o dinamico Anche in economia ci sono tali definizioni! Queste risorse possono essere allocate staticamente o dinamicamente, in modo simile a quanto abbiamo detto in Gestione della memoria.\nStatico quando gi√† in fase di compilazione del processo, o di avviamento del processo gli d√≤ la memoria, e quella sar√† per tutti il tempo della sua vita.","title":"Gestione delle risorse"},{"content":"Rappresentazione e terminologia Operazioni importanti\nDefinizione di grafo √à un insieme di nodi e di archi. (prendili da insiemi corretti)\nMetodi di rappresentazione Liste di incidenza (In pratica numero tutti gli archi e storo il valore dell\u0026rsquo;arco incidente per ogni nodo)\nListe di adiacenza Classico usato per Competitive, si memorizzano direttamente pointer a nodi di interesse. Quindi abbiamo una forma del genere: Nodo -\u0026gt; lista dei nodi a cui √® collegato.\nMatrici di adiacenza Se esiste un arco fra due nodi, metto un uno in questa posizione (si pu√≤ utilizzare una cosa simile per mantenere il peso di un arco)\nTermini importanti Cammino, cammino semplice, ciclo, ciclo semplice, fortemente e debolmetne connesso. grafo completo, aciclico\nCammino e cammino semplice Ciclo Componente debolmente connessa Grafo completo Grafo aciclico Algoritmi sui grafi Algoritmi di visita BFS DFS Ordinamento topologico √à una dfs üòÄ√® utile poi per utilizzare\n`\nComponenti fortemente connesse √à una relazione di equivalentz la raggiungibilit√† (anche per grafi indiretti) e quindi per connessione debole\nSi pu√≤ utilizzare l\u0026rsquo;algoritmo di Tarjan (credo si chiami cosi) per le SCC. si fa in m + n\nMinimum Spanning Tree Definizione di MST Un sottografo di un grafo che prenda tutti i vertici, tale per cui la somma del peso degli archi presi sia la minima possibile.\nTaglio di un grafo\nRegole per l‚Äôintuizione della sol greedy\nda libro\nKruscal Si utilizza la union find,\nPrim Solo sulla frontiera, si espande usando la regola del taglio\nCammini minimi Propriet√† (sottostruttura e esistenza per connettivit√†) Se ho un cammino minimo, allora anche un suo sotto cammino a un sottonodo √® un cammino minimo Se ho un grafo connesso, allora esistono cammini minimi fra due nodi connessi Condizione di Bellman Questa √® una condizione sul valore della distanza fra i nodi dei grafi:\nSe ho $d_{xy} \\leq d_{xp} + w(p, y)$, ovvero la distanza fra due nodi, √® sempre minore o uguale alla distanza fra un nodo intermedio e l\u0026rsquo;arco fra questo nodo a y. √à uguale se √® il cammino minimo.\nDa questa osservazione di pu√≤ definire una condizione di rilassamento di un arco. Gli algoritmi di rilassamento partono da una condizione grossolana, poi approssimano qualcosa sempre meglio, volta dopo volta.\nAlgoritmo di Bellman-ford Il pensiero per ricordarsi questo algoritmo √® questa osservazione:\nSuppongo di conoscere il cammino minimo da un vertice di partenza e un vertice di arrivo, allora sarebbe facile percorrerlo e conoscerne i costi. Noto che se provo a rilassare ogni singolo arco, allora dovrei aver almeno trovato il costo per il primo nodo del cammino. Continuo a fare cos√¨, con rilassamenti successivi finch√© non arrivo a uno stadio stabile.\nCerco di rilassare ogni arco finch√© qualcosa cambia, se cambia vuol dire che non ho ancora finito tutti i rilassamenti possibili.\nAlgoritmo\nNota:\nQuesto algoritmo √® buono perch√© trova il cammino minimo anche per archi negativi üå†\nAlgoritmo di Dijkstra Questo algoritmo funziona solamente nel caso in cui non ho archid i peso negativo.\nLemma fondamentale per comprendere Dijkstra\nAlgoritmo in pseudocodice generico\nAlgoritmo in pseudocodice con strutture di dati\nAlgoritmo di Floyd-Warshall Utilizziamo la programmazione dinamica per calcolare tutti i percorsi minimi.\nL\u0026rsquo;idea √® calcolare ad ogni step, una matrice di percorsi che passano per un certo specifico vertice.\nAlgoritmo in pseudocodice (si pu√≤ ottimizzare lo spazio in questo)\n!\n","permalink":"https://flecart.github.io/notes/grafi/","summary":"Rappresentazione e terminologia Operazioni importanti\nDefinizione di grafo √à un insieme di nodi e di archi. (prendili da insiemi corretti)\nMetodi di rappresentazione Liste di incidenza (In pratica numero tutti gli archi e storo il valore dell\u0026rsquo;arco incidente per ogni nodo)\nListe di adiacenza Classico usato per Competitive, si memorizzano direttamente pointer a nodi di interesse. Quindi abbiamo una forma del genere: Nodo -\u0026gt; lista dei nodi a cui √® collegato.","title":"Grafi"},{"content":"Programmazione lineare Programmazione lineare contiene alcuni algoritmi utili per risolvere certi problemi di ottimizzazione.\nIntroduzione Andiamo in questa sezione a definire un problema di programmazione lineare\nDefinizione üü©- Variabili reali che saranno le variabili del nostro problema, sono in numero finito (eg. tutti in Rn) Funzione obiettivo che ci definisce il costo $f: \\R^n \\to \\R$ Vincoli lineari che limitano il dominio delle variabili reali e li mettono in relazione fra di loro Se le variabili appartengono agli interi andiamo a parlare di programmazione lineare intera.\nSlide\nRappresentazione della soluzione si pu√≤ formalizzare sempre in questo modo:\n$$ max\\{cx | Ax ‚â§ b\\} : A \\in M_{m\\times n}, c,b \\in M_{n \\times 1} $$ Programmazione lineare intera In modo curioso la programmazione lineare √® pi√π facile rispetto alla PLI.\nEsempio di modelizzazione\nHa fatto un esempio di modelizzazione di un problema introduttivo in classe, in effetti si deve fare attenzione a moltissime cose‚Ä¶ (soprattutto costraints impliciti).\nQuantitative rappresentano alcune quantit√†\nLogiche rappresentano valori binari (di solito utilizzati per modellare l‚Äôassegnamento ad un task)\nRelazioni logiche üü®+ Possiamo codificare con relazioni fra variabili logiche il concetto di negazione, implicazione congiuzione e disgiunzione.\nLe variabili $x \\in \\{0, 1\\}$ in questo caso. La cosa interessante √® che possiamo codificare relazioni logiche con relazioni lineari!\nSlide rappresentazione di relazioni logiche con relazioni lineari\nVincoli di (semi-)assegnamento üü© Abbiamo un insieme di $N = \\{1,..., n\\}$ oggetti da assegnare in $V = \\{1,...,m\\}$ luoghi.\nQuesto si pu√≤ codificare con una matrice $n \\times m$ e usare una variabile logica per specificare se √® stato assegnato a quel luogo o meno.\n(Secondo me si potrebbe anche utilizzare un numero per questo, ma magari l‚Äôalgoritmo utilizzato √® leggermente diverso, no forse specifica una possibilit√† di assegnamento, per questo una matrice √® una cosa giusta).\nVincoli di semiassegnamento\nOssia ogni oggetto √® assegnato a un singolo luogo\nSlide semiassegnamento\nVincoli di assegnamento\nOgni oggetto ha un singolo luogo e ogni luogo un oggetto\nSlide assegnamento\nSelezione sottoinsiemi üü®+ Vogliamo selezionare il minimo fra certi sottoinsiemi (non per forza partizioni!)\nFormulazione classica: sia $F = \\{F_1,..., F_m\\}, F_i \\in \\N$, voglia determinare $D \\subseteq F$ tale che abbia il costo minimo fra tutti. Nella selezione di questi sottoinsiemi possiamo considerare insiemi di copertura, di riempimento o di partizione.\nEsempio del costo classico $\\min\\sum x_j c_j$ cio√® aggiungo il costo con la variabile booleana che decide se lo scelgo o meno, e poi chiamo $a_{ij}$ una matrice che dice se l\u0026rsquo;elemento i √® in $F_j$\nFormalizzazione classica\nCopertura, riempimento partizione\nVariabili a Valori Discreti üü©- Questa parte tratta di valori vincolati a valori reali. (un esempio solito √® una macchina che √® stata costruita a lavorare entro voltaggi precisi).\nSi indica per un insieme di valori che una variabile pu√≤ assumere. Una rappresentazione classica √® in silde sotto\nSlide\nMinima Quantit√† Positiva Prefissata üü®+ Di solito queste tipologie di variabili rappresentano valori di produzione di una macchina perch√© o √® spenta, rappresentata da uno 0, oppure √® accesa e presente in un intervallo\nSlide\nFunzione a carico fisso üü© Indica costi 0 quando la macchina non √® in produzione, mentre per√≤ √® attiva, anche se fa poco, c\u0026rsquo;√® un carico fisso ossia un costo che c\u0026rsquo;√® sempre, e poi cresce in modo lineare\nSlide introduttive\nFormalizzazione classica\nRappresentazione del valore assoluto üü® SI tratta di come rappresentare mediante vincoli la relazione di valore assoluto.\nUn problema con questo metodo √® che non sempre si riescono a gestire\nAnche gestendolo in questo modo ci sono alcune ambiguit√†\nSlide, formalizzazione classica e funzione costo\nFunzioni lineari a tratti üü®+ L\u0026rsquo;idea √® utilizzare una variabile logica che ci dice in quale tratto √® presente, poi utilizzare la funzione per calcolare il valore corretto.\nIn pratica questa √® una forma di generalizzazione dei problemi con funzioni a carico fisso, in cui vengono introdotte delle variabili per dire dove sei, e poi utilizzare la funzione di costo del carico fisso.\nQuesto metodo √® buono perch√© posso utilizzarlo per quanti tratti mi pare\nFormalizzazione\nModellizzazione per Problemi noti Problema della fonderia Soluzione fonderia\nProblema pianificazione della produzione Soluzione pianificazione produzione\nProblema dello zaino (!) Soluzione del modello\nAlbero di copertura di costo minimo Soluzione\nProblema del commesso viaggiatore Note sulla path hamiltoniana\nSoluzione modellizzazione\nProblema dell‚Äôagenzia matrimoniale (!) Soluzione modellizzazione\nProblema allocazione dei lavori alle macchine (!) Descrizione del problema\nDal libro\nAbbiamo dei lavori che devono essere svolti in questi intervalli : $t_i, t_i + d_i$, che sono certi valori che svolgono qualcosa, vogliamo cercare di massimizzare il numero di cose svolte, avendo un certo numero di macchine. Una macchina pu√≤ avere solo un lavoro (o dipendente).\nQuesto √® un problema di semiassegnamento.\nModellizzazione\nponiamo $x_{ij} = 1$ se il lavoro $i$ √® svolto dalla macchina $j$, altrimenti 0\nvincoli necessari semi-assegnamento $\\forall i, \\sum_{j = 1} ^mx_{ij} = 1$, ora dobbiamo andare a modellizzare il concetto dell‚Äôintervallo.\nQuindi mi definisco un insieme $S(i)$ che contiene tutti i lavori incompatibili a $i$.\nAllora il vincolo diventa $x_{ij} + x_{hj} \\leq 1$ con $h \\in S(i)$, Cio√® vogliamo che una macchina esegua solamente un lavoro, o nessun lavoro. E questo vincolo ci d√† il concetto di vincolo.\nOra passo alla discussione della funzione obiettivo, quindi introduco una nuova variabile che mi conta le macchine utilizzate\n$f(obiettivo) = \\sum y_j$, per tutte le macchine, e poi questa $y_j$ √® maggiore di tutti gli $x_{ij}$ per una macchina j fissata.. Cos√¨ provo ad utilizzare meno macchine possibili\nSoluzione dal libro\nhttps://www.notion.so\nProblema docente di informatica (!) Questo problema √® rappresentato nel libro come di minimizzazione del tempo per lavori di macchina a pagina 37 del pdf delle dispense\nDescrizione del problema\nHo $t_1...t_n$ progetti da compilare su $m$ pc, voglio che ci mettano meno tempo possibile.\nModellizzazione\nSia la variabile $x_{ij}$ la variabile logica se il progetto $t_i$ √® data alla macchina $j$\nSemi-assegnamento al massimo assegno il progetto a una singola macchina\n$\\sum_{j = 1} x_{ij} = 1$. Ora entra la parte difficile, introdurre delle variabili che siano utili per avere questo concetto di tempo.\nSia $y_j = \\sum_i t_i x_{ij}$, questo rappresenta il tempo di utilizzo del singolo PC. Quello che noi dobbiamo minimizzare √®\nMa questo vincolo non √® lineare, quindi √® un problema $\\min (\\max Y), Y = \\{y_j : j = 1,...,m\\}$\nQuindi introduco un valore che $z : \\forall j \\sum_i x_{ij} t_i \\leq z$ e provo a minimizzare solamente z, quindi sar√† il suo valore pi√π basso. (minimo upper bound)\nProblema assegnamento delle frequenze Soluzione problema assegnamento\nProblema della commesse üü•- Ho n dipendenti, devo evadere m pacchi, un sottoinsieme $D_j$ che indica da chi pu√≤ essere eseguito questo pacco j, pu√≤ essere da luogo a un ricavo di $r_j$. Un dipendente pu√≤ lavorare su un solo pacco per un intervallo di tempo. Pu√≤ essere che non tutti i pacchi siano da evadere.\nInizio modello\n$F_j = boh$\n$x_j = 1$ se la commessa j √® selezionata, altrimenti 0\n$a_{ij}$ boh\n$x_i \\in \\Z, 0 \\leq x_i\\leq1$\n$\\forall i \\sum a_{ij} x_j \\leq 1$\nFunzione obiettivo $\\max \\sum _{j = 1} ^m x_j r_j$\n","permalink":"https://flecart.github.io/notes/modelizzazione/","summary":"Programmazione lineare Programmazione lineare contiene alcuni algoritmi utili per risolvere certi problemi di ottimizzazione.\nIntroduzione Andiamo in questa sezione a definire un problema di programmazione lineare\nDefinizione üü©- Variabili reali che saranno le variabili del nostro problema, sono in numero finito (eg. tutti in Rn) Funzione obiettivo che ci definisce il costo $f: \\R^n \\to \\R$ Vincoli lineari che limitano il dominio delle variabili reali e li mettono in relazione fra di loro Se le variabili appartengono agli interi andiamo a parlare di programmazione lineare intera.","title":"Modelizzazione"},{"content":"Introduction to the probabilistic Turing Machine Most of real phenomena are better comprehended by a probabilistic view. This pushes to build a formal model that takes probability into account\nDef: Probabilistic TM Take a non deterministic TM La macchina di Turing. At each step there is a fair coin-flip that has two legal branches. So the probability of a certain branch is $$ \\mathbb{P}(b) = 2^{-k} $$ Where $k$ is the length of the branch. Then the probability of accepting the word is given by this:\n$$ \\mathbb{P}(\\mathcal{M} \\text{ accepts } \\omega) = \\sum_{b \\text{ is an accepting branch}} \\mathbb{P}(b) $$ Note that this is very similar to the Algorithmic probability defined in Kolmogorov complexity.\nWe have here a probability of error.\nBounded-error Probabilistic Polynomial Class This is the new complexity class of the Turing machine, and sort of is similar to the PAC model of the machine learning predictions.\nBPP is the class of languages that are decided by probabilistic polynomial time Turing machines with an error probability of $\\frac{1}{3}$ .\nFormal Language Models This is something very similar to this model, but needs to be investigated. See (Cotterell et al. 2023).\nReferences [1] Cotterell et al. ‚ÄúFormal Aspects of Language Modeling‚Äù 2023\n","permalink":"https://flecart.github.io/notes/probabilistic-turing-machines/","summary":"Introduction to the probabilistic Turing Machine Most of real phenomena are better comprehended by a probabilistic view. This pushes to build a formal model that takes probability into account\nDef: Probabilistic TM Take a non deterministic TM La macchina di Turing. At each step there is a fair coin-flip that has two legal branches. So the probability of a certain branch is $$ \\mathbb{P}(b) = 2^{-k} $$ Where $k$ is the length of the branch.","title":"Probabilistic Turing Machines"},{"content":"2 Problemi di ricerca In questa prima parte si tratta di ricerca semplice, ossia si utilizza un modello basato su obiettivi, di struttura atomica, in un ambiente che risulti singolo-agente, episodico, totalmente osservabile, deterministico, statico, discreto, conosciuto.\n2.1 Il problema Vogliamo cercare di enunciare in un modo che possa essere formale, senza nessuna ambiguit√† il concetto di problema di ricerca.\n2.1.1 Framework di soluzione Individuiamo 4 fasi principali per un problema di ricerca, questo √® un framework molto generico.\nFormulazione dell\u0026rsquo;obiettivo (si cerca di individuare l\u0026rsquo;obiettivo della nostra ricerca). Individuazione del problema (in cui si va a trascrivere il problema utilizzando una impostazione formale, solitamente astraendo dettagli non interessanti, il formato √® descritto subito dopo nella sezione articolazione) Ricerca della soluzione (in cui si cerca una effettiva soluzione per il problema di ricerca, probabilmente √® la parte pi√π dispendiosa di algoritmica). esecuzione della soluzione (in cui gli attuatori eseguino la soluzione del problema trovato) 2.1.2 Articolazione Vogliamo cercare di formalizzare il problema di ricerca nel modo pi√π chiaro possibile, lo facciamo separando le funzioni e dati necessari per definire tutti gli aspetti di un problema di ricerca:\nStati possibili Stato iniziale Stati obiettivo Funzione di azioni (da quale stato posso muovermi a quale stato) Funzione di costo (il movimento da questo stato a quello quanto mi costa ?) Funzione di transizione (mi muovo da uno stato all\u0026rsquo;altro) 2.1.3 Problemi standarizzati e reali Questi problemi sono standarizzati proprio perch√© rappresentano un modello su cui comparare altre soluzioni che verranno in seguito sviluppate. Sono un cardine per vedere l\u0026rsquo;efficienza di una propria soluzione, e simili.\nInvece i problemi reali possono avere una formulazione vaga, che cio√® √® dipendente dal contesto, o comunque da ci√≤ che sia necessario al momento.\nEsempi di standard problems:\n15/8 tile problem Knuth factorial problem (partendo da 4, e applicando fattoriale e radici, si pu√≤ fare qualunque numero) Esempi problemi reali\nTravelling salesman Chip VSLI 2.2 Note generali 2.2.1 Percorsi ridondanti Possiamo andare a definire un percorso ridondante, ogni percorso per cui se togli una tappa, il costo √® minore (ricordiamo che in questo libro parliamo sempre di percorsi con un peso positivo), quindi ridondanti sono cicli, o percorsi con qualche tappa in pi√π. Si pu√≤ considerare come se fosse un concetto pi√π generale di ciclo questo.\nOvviare alle ridondanze\nNon vogliamo trovare percorsi che siano alla fine ridondati, vogliamo in qualche modo ricordare il nostro percorso:\nAvere una tavola che ci dica se abbiamo gi√† fatto quel percorso o meno Avere una struttura, o formulazione del problema che non abbia questo problema di ridondanze (ad esempio una ricerca tipo-albero) Ovviare solo ai cicli, e non alle ridondanze in generale, come vi adi mezzo. 2.2.2 Valutazione dell\u0026rsquo;algoritmo In generale si valuta l\u0026rsquo;algoritmo secondo le risorse utilizzate, nel caso della ricerca in AI potrebbe essere il costo in soldi e in carburante, oltre alla classica memoria e tempo. Si propongono quindi 4 valori su cui valutare ci√≤:\nCompletezza (se esiste una soluzione perfetta la trovo sempre? Se non esiste so che non c\u0026rsquo;√®?) Ottimalit√† del costo della soluzione (es soldi etc). Costo in tempo Costo in memoria Di particolare interesse sarebbe valutare la completezza dell\u0026rsquo;algoritmo.\n2.3 Algoritmi disinformati Pseudocodice best-first-search\n2.3.1 Perch√© sono disinformati Chiamiamo questi algoritmi come disinformati perch√© non hanno idea di come √® fatta la struttura del campo di ricerca.\nIn pratica cercano con informazioni fortemente limitate sulla topologia del proprio ambiente.\nDirei che vadano a cercare valutando solamente il costo, o indiscretamente nodi quasi casuali dell‚Äôambiente circostante.\n2.3.2 Carrellata di algos Non mi √® piaciuto molto questa parte, perch√© la maggior parte degli algoritmi esposti √® presente nel corso di Algoritmi e Strutture fanno all\u0026rsquo;uni.\nBFS DFS Dept-limited dfs Dijkstra/uniform-cost-search Iterative deepening 2.4 Algoritmi informati Questi algoritmi informati sono molto pi√π interessanti rispetto agli algoritmi scorsi, per cui ne diamo pi√π larga discussione\nIl fatto che siano informati ci sta a significare soltanto che utilizzano un euristica per decidere meglio in che modo espandersi.\n2.4.1 Euristiche Bisogna cercare di definire in modo migliore le caratteristiche che ci potrebbero interessare delle euristiche: euristica ammissibile significa che la funzione di euristica √® sempre minore del costo effettivo.\nConsistente invece √® in pratica soltanto una forma della disuguaglianza triangolare.\nTrovare un euristica √® come risolvere una versione pi√π rilassata del problema, questa √® una delle osservazioni fondamentali per quando si va a trattare di euristiche.\nAltre soluzioni possibili sono Landmarks e pattern databases di cui rispettivamente i primi sono dei punti cardine, in cui si calcola tutto passando prima di quelli (come se mi chiedessi tipo: quanto ci metto se per andare da A a C, passo prima per il landmark B?) prima si calcolano questi landmark e si prendono decisioni in funzione di quanto mi danno ci√≤.\nI pattern databases sono solamente un modo per cercare soluzioni gi√† precomputate di pattern che ci sono solito. Si √® utilizzato un pattern database per 8-puzzle e funzionava distintamente bene.\nContours\nCome se fossero dei piano di livello di una montagna, anche per dijkstra si potrebbe disegnare un contour, ci indica in pratica in modo semplice in che modo si sta espandendo l‚Äôalgoritmo di ricerca.\n2.4.2 Carrellata algoritmi informati quella pi√π bella, usata in tutte le salse √® l‚Äôalgoritmo di A* Search, che in pratica √® un uniform cost search, che invece di utilizzare solamente la funzione costo g(n) che rappresenta quanto effettivamente si paga per raggiungere il nodo n, tiene in considerazione anche una funzione h(n) che cerca di stimare il costo da n a un goal.\nUna variante studiata √® il greedy-first-search che praticamente tiene in conto solamente dell‚Äôeuristica, senza la funzione di costo.\nAltre varianti come WEIGHTED A* search applicano un fattore di peso sull‚Äôeuristica, spesso rendendola non ammissibile o perfino inconsistente (non ho capito bene in che modo l‚Äôammissibilit√† e la consistenza modificano le caratteristiche dell‚Äôeuristica).\nTecniche che tengono molto in conto la memoria\nAltre studiate possono essere la RBFS (Recursive best first search, che √® simile a un MINIMAX con pruning, ma singolo agente, in pratica si espande sempre il nodo migliore, tenendo in conto il secondo valore migliore tra questi vicini, io continuo ad esplorare in profondit√† finch√© non mi converrebbe di pi√π cominciare ad esplorare qualcosa a un livello molto meno profondo).\nOppure la SMA* la simple memory A star, che in pratica tiene in considerazione un numero massimo di nodi in memoria, se nel momento in cui va ad espandere lo ha finito, rimuove il nodo pi√π vecchio, tenendo per√≤ un informazione riguardo quando costava esplorare quella via. (questo comunque pu√≤ condurre a problemi simili al thrashing, in cui continua a switchare percorsi, restando cos√¨ quasi bloccato).\nBEAM SEARCH va in modo molto focalizzato verso una direzione sviluppando solamente i primi k nodi migliori sulla frontiera, invece A* si sviluppa nel suo territorio (quindi ++ sui contorni)\n2.5 Interesse stato finale In questi problemi non ci importa pi√π di avere un percorso che ci porta alla soluzione, ma solamente la soluzione stessa. Non ci conviene pi√π utilizzare gli algoritmi di ricerca presentati al capitolo precedente in Problemi di ricerca. Quindi si sono sviluppati algoritmi che si comportassero bene per massimizzare anche gli obiettivi di questi.\nTermini importanti per parlare di questi ambienti:\nMassimo locale Ridge (che rende algoritmi greedy molto difficili da essere efficienti) Plateau, parti piatte 2.5.1 Hill Climbing Hill Climb in breve (pseudoalgo)\nQuesto √® uno degli algoritmi pi√π semplici per quanto riguarda la ricerca in questi ambienti, l‚Äôidea principale √® scegliere il migliore fra i propri successori, e seguire quella strada finch√© si pu√≤ migliorare.\nIl problema principale √® che questa versione semplice di Hill Climbing si blocca molto facilmente su minimi locali, o piani. Poi l‚Äôambiente di Ridge √® una cosa di difficilissima navigazione.\nQuindi si sono inventati variazioni che tentavano di risolvere questo problema:\nRandom restart, ricominciare da un punto random, prendendo alla fine la migliore fra tutte Local beam search, in cui si tengono ogni step i k migliori successori fra i k punti iniziali. Stochastic local beam search in cui randomicamente si considerano alcuni nodi anche lontani rispetto a questi, per cercare di sfavorire il fatto che tutti i punti migliori si ammassino su uno stesso punto. Stochastic hill climbing, in cui in cui si seleziona un punto a caso, e lo si segue sempre se √® migliore, e solo a volte se √® peggiore Simulated Annealing in cui la probabilit√† di scegliere il punto peggiore dall‚Äôaltra parte scende col tempo, con una funzione che decade esponenzialmente. 2.5.2 Algoritmi genetici Pseudoalgo\nLe caratteristiche generali di un algoritmo genetico sono in breve queste:\nDimensione della popolazione Rappresentazione della stringa genetica in caratteristiche della popolazione Funzione scelta dei n elementi pi√π adatti tra la popolazione Generazione di un figlio da coppie, o singola persona, o anche pi√π persone di queste. (crossover) Mutazione randomica di caratteri cos√¨ generati Elitismo o abbattimento di individui non adatti (a volte aiuta a velocizzare il processo). Ripetizione di ci√≤ fino a tempo finito o caratteristiche cercate trovate. La differenza principale con lo stochastic local beam search √® il momento di generazione di un nodo successore, che in questo caso, in quanto giustificato dalla biologica, o almeno da una forma contorta di biologia perch√© io personalmente credo che sia una forma eccessivamente semplificata, nonostante riconosco che √® un buon punto di partenza) √® generata da una ricombinazione di pi√π individui.\nSCHEMAS\nSi √® notato nel tempo (e lo si √® anche dimostrato) che gli algoritmi genetici hanno un senso solo se pattern vicini codificano informazioni importanti cio√® se i caratteri vicini non hanno nessuna relazione, √® totalmente inutile utilizzare un algoritmo genetico.\nPoi si √® notato che se un pattern specifico aiuta il progenito a sopravvivere, effettivamente √® probabile che si mandi alla generazione successiva. Ciononostante √® doveroso tenere a mente che non tutti i pattern necessari vengono trasferiti, e non tutti i pattern inutili vengono eliminati, leggere l‚Äôapprofondimento in biologia a pagina 136 dell‚Äôedizione cartacea che possiedi.\n2.5.3 In ambienti continui Se l‚Äôambiente √® continuo, √® di gran lunga di pi√π di interesse matematico. Si pu√≤ vedere come un problema di calcolo numerico nella ricerca di un punto di minimo come il Newton-Raphson-method, che si pu√≤ estendere anche a pi√π dimensioni.\nOppure si pu√≤ vedere come un problema di ottimizzazione-constrained, che si pu√≤ risolvere con programmazione lineare, cose che riguardano analisi di superfici convesse. In pratica idee e cose altamente tecniche che non conosco ancora.\nL‚Äôidea principale di questa parte comunque resta il fatto che si pu√≤ discretizzare l‚Äôambiente continuo, o cercando di aggiornarlo con passi piccoli, delta alla volta, in ogni direzione, o campionando lo spazio, dividendolo in tanti quadrettini lunghi delta, alla fine credo che questi approcci siano equivalenti.\n2.6 non-deterministiche e not-fully observable Introduciamo ora il concetto di belief state ossia una rappresentazione interna degli stati possibili dell‚Äôambiente. Per gli algoritmi presentati in Problemi di ricerca ogni singolo stato esterno corrispondeva lo stato di belief state interno, ossia c‚Äôera una corrispondenza, invece in questo caso andiamo a rilassare questo assunto, il determinismo, ossia il fatto che a una singola azione vada a corrispondere un singolo stato, ossia andiamo a dire che a singola azione, possono risultare una serie di stati differenti, maggiori di 1.\n2.6.1 And-Or tree (non-det) Con la possibilit√† di avere pi√π stati a seguito di una singola azione cerchiamo di dividere cose che sono sotto il controllo dell‚Äôagente e cosa non lo √®\nOR-node, √® una cosa che dipende dall‚Äôazione dell‚Äôagente AND-node, √® una cosa che dipende dalla reazione dell‚Äôambiente in seguito ad azioni dell‚Äôagente. Avendo questi due tipologie di nodi, possiamo andare a rappresentare l‚Äôintero ambiente attraverso un albero, per cui si possono utilizzare gli algoritmi di trasverse di alberi per trovare una soluzione che ora chiamiamo piano condizionale in quanto sar√† constituito da un array di azioni, nel caso si √® andato su un or-node, oppure di if-then, nel caso si stia andando avanti per un and-node.\nNota: soluzioni cicliche\nA volte converrebbe cercare di ragionare sui motivi della non-determinatezza perch√© in questo modo sappiamo se una soluzione ciclica, ossia una soluzione che ha per foglie solamente un obiettivo, ma nel suo percorso pu√≤ avere anche delle foglie che vadano in loop, sia effettivamente una soluzione: ossia il non-raggiungimento sia dovuto al caso, oppure a una sistematicit√† dell‚Äôambiente in cui si √® presenti.\n2.6.2 Osservabilit√† parziale Un aspetto che colpisce √® che in ambienti in cui l‚Äôosservabilit√† √® parziale, si possono ricavare delle informazioni semplicemente muovendosi, non per forza stando ad osservare l‚Äôambiente! diciamo in questo caso che lo stato √® coerced\nPer ricondurci da tale ambiente a un problema di ricerca trattato in Problemi di ricerca, possiamo fare una cosa molto simile a quanto √® fatto per Non-deterministic automata convertito a deterministic automata, ossia si ha una esplosione esplonenziale, ma comunque ben definita degli stati e delle funzioni di transizione che li legano.\nRicerca incrementale\nA volte conviene, invece di esplorare tutto insieme, come fa il non-determinismo, causando computazioni impraticabili, di provare a cercare una soluzione in via incrementale, buildando prima una soluzione che funzioni per un nodo, poi per il secondo, cambiando leggermente la soluzione trovata, e poi via.\nSi ha il risultato di trovare una soluzione o una assenza di essa in modo molto veloce.\n2.6.3 Percezione nell‚Äôosservabilit√† parziale Essendo un ambiente parzialmente osservabile, possiamo dare per scontato che esista una funzione Perceipt(state) che restituisce un insieme di stati osservati. Questa √® una funzione stretttamente legata all‚Äôambiente in cui agisce l‚Äôagente.\nAllora in un ambiente non-deterministico ad osservabilit√† parziale dovremmo approfondire la funzione di transizione, che non si pu√≤ considerare pi√π l‚Äôunione o l‚Äôintersezione dell‚Äôazione che viene applicata a tutti gli stati, ma qualcosa di meno perch√© deve prendere in conto anche la percezione (ad ogni azione corrisponde uno stato che corrisponde subito una percezione).\nLa dividiamo in 3 parti\nPredizione di quello che succede se applico l‚Äôazione a (ritorna un insieme di stati possiibili) Percezioni possibili lista delle percezioni possibili per tutti gli stati raggiunti. Aggiornamento degli stati di belief a un sottoinsieme a seconda degli stati raggiunti e delle percezioni possibili. In questo modo si forma sempre un albero di ricerca, di azioni non-deterministiche.\n2.6.4 Ricerca online La ricerca online ci fa avvicinare a come sia l‚Äôesplorazione in un mondo vero, in pratica ora lo stato del mondo √® dinamico, e dipende dalla presenza fisica dell‚Äôagente osservatore che non pu√≤ pi√π saltare da un nodo o un altro, oltre al fatto che lo stato pu√≤ cambiare anche se non sta facendo niente. (c‚Äô√® un problema riguardo punti di non ritorno, in cui le azioni sono irreversibili, ma questo lo tratteremo in capitolo seguenti).\nPseudocodice per DFS-online\nLa cosa stupida di questo algoritmo √® che non conosce le azioni che pu√≤ fare in un determinato stato, e potrebbe ripetere azioni che si cancellano fra di loro (es. UP e DOWN uno di seguito all‚Äôaltro). Le azioni qui dipendono dallo stato in cui si √® presenti!\nHill Climbing online (LRTA)*\nUn osservazione che si √® fatto con la DFS √® che ora si ha un oggetto fisico che si sposta, e non pu√≤ fare voli dall‚Äôaltra parte del labirinto per vedere come si sviluppa quel nodo di ricerca, per questo motivo possiamo affermare che c‚Äô√® bisogno di un algoritmo di ricerca locale, questo era HILL CLIMBING!\nMa avevamo discusso in precedenza che si poteva bloccare molto facilmente questo algoritmo! Ma non possiamo pi√π utilizzare random restart, dato che non esiste il teletrasporto, allora utilizziamo il random walk, in modo randomico scegli una direzione e la esplori.\nQuesta cosa adattata con anche una euristica che ti direzioni verso la parte giusta diventa un LRTA\nPseudocodice Learning RealTime A*\nIn pratica riaggiorna l‚Äôeuristica del costo a seconda delle proprie mosse.\n","permalink":"https://flecart.github.io/notes/problemi-di-ricerca/","summary":"2 Problemi di ricerca In questa prima parte si tratta di ricerca semplice, ossia si utilizza un modello basato su obiettivi, di struttura atomica, in un ambiente che risulti singolo-agente, episodico, totalmente osservabile, deterministico, statico, discreto, conosciuto.\n2.1 Il problema Vogliamo cercare di enunciare in un modo che possa essere formale, senza nessuna ambiguit√† il concetto di problema di ricerca.\n2.1.1 Framework di soluzione Individuiamo 4 fasi principali per un problema di ricerca, questo √® un framework molto generico.","title":"Problemi di ricerca"},{"content":"Ripasso Prox: 30 Ripasso: June 6, 2023 Ultima modifica: May 14, 2023 6:13 PM Primo Abbozzo: March 13, 2023 9:20 AM Studi Personali: No\nElementi di ripasso Teoria dei Tipi Introduzione Definizione üü©‚Äî Un metodo sintattico praticabile per dimostrare l\u0026rsquo;assenza di determinati comportamenti del programma, fatto classificando le unit√† sintattiche in base ai tipi di valore che assumono\nVogliamo che fosse praticabile nel senso che effettivamente lo possiamo implementare, cio√® ci permettono di avere certe tipologie di garanzia. ma ancora √® una definizione molto ampia. E di solito si pu√≤ fare una analisi statica del comportamento del programma.\nUn altro modo per definirlo (questo molto pi√π buono) √®\nCollezioni di valori omogenei e rappresentabili e una serie di operazioni su di esse.\nOssia omogenei nel senso che hanno tutti certe propriet√†, e rappresentabili perch√© effettivamente possiamo metterli in memoria (per esempio non posso avere come tipo i Reali in modo primitivo, perch√© non √® rappresentabile).\nEsecuzione corretta, + ottimizzazione da parte del compilatore. Utilizzo dei tipi (4+) (!!!) üü®‚Äî- Slide sull\u0026rsquo;utilizzo dei tipi organizzazione concettuale\nSlide astrazione\nSlide correttezza\nSlide implementazione\nProgettazione: posso descrivere in modo concettuale cosa fa il programma e aiutare a verificare la correttezza del programma, ‚Äúseparare logicamente elementi concettualmente diversi‚Äù (posso creare tipi per certi concetti e quindi ragionare meglio, pensa sviluppare solo in assembly!) Documentazione: ci danno informazioni in pi√π riguardo il ruolo della variabile nel nostro programma. Una idea bella √® parlare di tipi come se fossero commenti Astrazione: in fase di implementazione possono aiutare a gestire meglio il nostro progetto, solitamente attraverso interfacce (a questo tipo ho certe operazioni, non ho niente di sotto), ci permette di modulizzare e gestire meglio, ++manutentibilit√†, ++ comprensibilit√† del progetto. L‚Äôastrazione su un concetto di cambia il modo di ragionare riguardo l\u0026rsquo;implementazione, o l‚Äôidea sottostante comunque. Correttezza, possiamo utilizzare i tipi per avere errori di programmazione, quindi se faccio qualcosa con un tipo, io mi aspetto di ricevere altro. (ad esempio se mi aspetto che una funzione mi ritorni qualcosa, ma mi ritorna qualcosal‚Äôaltro o non sempre quel tipo, posso darti errore staticamente parlando). Per cose di refactoring √® molto comodo, se cambi un tipo e una strtutura vorresti cambiarla anche da altre parti (se lo fai tipo in python √® molto pi√π difficile per sto motivo che non ha tipi all‚Äôesterno). O per la cosa della safety, √® impossibile sbagliare quando hai un buon sistema dei tipi (ti fa sbagliare in fase di compilazione lel, come Rust). Proprio per questa cosa che hai delle garanzie quando programmi, riesci a predire cosa ti ritorna e quindi puoi predire il modo con cui si comporta il programma. Possiamo dire che un programma √® sicuro quando rispetta sempre i vincoli del suo tipo. Per lui C non ha la caratteristica della safety, quindi puoi andare oltre alle limitazioni di utilizzo del singolo tipo (tipo array puoi accedere anche fuori dal suo range, un tipo buono non dovrebbe permettere queste cose), si potrebbe considerare quindi weakly typed, ma √® una cosa strana Implementazione: possiamo fare certe ottimizzazioni col sistema dei tipi. non servirebbero controlli dinamici per la sicurezza con un buon sistema dei tipi. Per esempio possiamo anche utilizzare offset per accedere in memoria quindi guadagniamo anche da quel punto di vista. Si migliora anche l\u0026rsquo;impatto che si ha sull quantit√† di memoria utilizzata, forse‚Ä¶ non sono sicuro da questo. Tipo theorem provers e simili\nAltre applicazioni\nUn sistema di tipi (e, per estensione, un linguaggio) √® sicuro relativamente ai tipi (o type safe) quando nessun programma pu√≤ violare le distinzioni tra tipi definite in quel linguaggio. Detto in altri termini, un sistema di tipi √® sicuro quando nessun programma durante l\u0026rsquo;esecuzione pu√≤ generare un errore non segnalato che derivi da una violazione di tipo.\nDynamic and static typing üü©‚Äî STATICO\nQuando il controllo dei tipi avviene a livello di struttura del testo. Solitamente queste informazioni sono poi rimosse nel file compilato, almenoch√© non serva per runnare.\nDato che eventuali errori sono individuati in tempo di compilazione, il prezzo in genere che si paga per un linguaggio statico √® il tempo di sviluppo del linguaggio! Solitamente un compilatore che abbia static typing e che sia safe richiede molto molto pi√π tempo.\nDINAMICO\nQuando i controlli di tipi √® fatta a runtime, e quindi bisogna runnarlo per capire cosa runna. Questo aggiunge un leggero overhead, perch√© ho bisogno di un descrittore a runtime che contenga le informazioni sul tipo, e ci sia la verifica in questo momento.\nDato che dobbiamo eseguire per trovare un errore di tipo dinamico, questo errore potrebbe essere scoperto solo nella fase finale, quando il nostro prodotto √® gi√† in produzione, e ha clienti!\nImportante osservare che la divisione fra dinamico e inferred √® indipendente al fatto che sia dinamic o static!\nManifest vs Inferred typing üü© La differenza fra manifest ed inferred typing riguarda la quantit√† di informazioni che il programmatore deve dare al compilatore per creare il sistema dei tipi\nL\u0026rsquo;inferred typing non √® altro che un typing manifesto automatico, nel senso che il compilatore stesso riesce a capire che tipo stai dichiarando. Queste cose gi√† esistono in c++ nuovo e anche golang Rust.\nInvece il manifest tiping √® quando il programmatore va ad annotare ili tipo di tute le variabili.\nTipo estensionali o intensionali üü©- Slide estensionali o intensionali\nINTENSIONALE\nQuando gli abitanti del tipo sono descritti secondo un predicato che √® una propriet√† che √® soddisfatta da tutti gli abitanti.\nSalviamo molta memoria per tipi grossi e ci permette anche di rappresentare (fino a un certo punto i tipi infiniti).\nESTENSIONALE\nQuando si va a listare tutti gli abitanti nel nostro tipo, la stessa cosa che si fa con gli enums\nSistemi di tipi Caratterizzazione di base (4) (!) üü®+ Tipi di base Poter definire nuovi tipi Controllo dei vincoli, che siano statici o dinamici non ci importa, ma ci importa che siano rispettati Computare sui tipi (equivalenza, compatibilit√†, inferenza dei tipi). Slide sistemi di tipi\nTipi di base üü© Sono i valori denotabili del linguaggio. Si dice abitante, una variabile che faccia parte di questo tipo. Cose come float, caratteri interi etc.\nVOID/UNIT, √® un tipo di base che contiene solamente il singoletto, per questo √® anche chiamato unit, in java per esempio √® il NUll, mentre in C √® il void (che per√≤ ha la differenza che non si pu√≤ assegnare, perch√© starei assegnando il niente!), e che non si pu√≤ assegnare. Solitamente √® il valore delle funzioni che non ritornano nulla, utilizzato spesso per ritornare il controllo delle funzioni. In C void √® utilizzato per distinguere procedure e funzioni e rende difficile fare le composizioni (che non so cosa sia), unit √® per avere ancora funzioni, che deveono per forza avere un codominio non nullo.\nTIPI BOOLEANI\nChe hanno vero o falso come abitanti, e ho tutte le operazioni logiche, come congiunzione disgiunzione negazione etc. La cosa particolare √® che utilizziamo un byte invece di un bit per rappresentare un bool, perch√© per accedere al valore √® molto veloce se √® allineato.\nTIPO CARATTERE\nSono i caratteri Unicode, oppure ascii,operazioni classiche sarebbero comparazione, comparazione (perch√© c‚Äô√® un ordine fra i caratteri nell‚Äôencoding, come abbiamo detto in Codifica dei caratteri), e il resto √® dipendente dal linguaggio.\nTIPI INTERI\nSolitamente spaziano fra $[-2^{r - 1}, 2 ^{r - 1} - 1 ]$hanno tutte le operazioni fra interi come uguaglianza, ordine, tutte le operazioni aritmetiche.\nTIPO REALE\nSono un subset dei reali, in particolare solamente i razionali rappresentabili, hanno stesse operazioni degli interi (importanti per ragioni di compatibilit√† e conversione con gli interi!), ricorda che ci sono fixed point or floating point representation. Abbiamo fatto principalmente floating point di IEEE745 in Calcolo di numeri finiti .\nFixed point slide\nTIPO COMPLESSO\nAnche questo, subset dei numeri complessi, stesse operazioni degli interi, con forse qualcosina in pi√π.\nENUMS\nQuesto √® il nostro primo tipo non di base, perch√© √® un costruttore di tipo possiamo infatti dichiarare nuovi tipi, e enums sono un modo per farlo. In pratica si dichiara un nuovo tipo con definizione di abitanti appartenenti a questo.\nIn C non c‚Äô√® differenza fra interi e enums, quindi non c‚Äô√® una chiara differenziazione dei tipi, quindi difficile andare a checkare la correttezza fra i due.\nTipi composti Come si fa a definire alcuni tipi pi√π complessi, composti utilizzando alcuni tipi primitivi?\nArrays Sono unacollezzione di elementi omogenei indexati da una chiave (questo mapping riesce a dare in un certo senso un ordine) (che non necessariamente devono essere degli interi, credo che su questa scia anche le hashtable sono classificati come tipo array).\nInfatti le mappe sono chiamate associative arrays.\nSi potrebbe considerare il costruttore di tipo, che prende in input un tipo e crea un array di una certra dimensione (quindi fa eccezzioni se provi ad accedere oltre) e crea un altro tipo, che √® l‚Äôarray di certa dimensione.\nEsempi di notazioni con array\nPropriet√† del tipo array\nOrdine di storage degli array (row column major)\nSe la grandezza dell‚Äôarray √® conosciuta a tempo di compilazione si pu√≤ allocare in stack, altrimenti si mette in heap, e si utilizza un descrittore, chiamato dope vector per accederci sulla heap. Di solito in rust o golang sono gli slice\nEsempio di dope vector\nEcco tutte le informazioni per il descrittore :D, stride ci dice ogni quanto saltare per avere il prossimo elemento.\nCONTROLLO\nUna delle operazioni fondamentali affinch√© abbiamo un tipo di array che sia safe √® il fatto check all‚Äôaccesso, in modo da evitare out of bounds, √® la cosa migliore che ho in termini di sicurezza.\nAltre operazioni utili sono assegnamento, confronto\nSets/Insiemi (3) Unici e orderless e omogenei sono gli elementi dei set. Quindi l‚Äôunica differenza √® il fatto che siano unici e quindi siano tutti distinti fra di loro secondo l‚Äôoperatore di uguaglianza.\nOperazioni importanti sono unione, intersezione, differenza, complemento, etc. tutte le operazioni belle sugli insiemi.\nUn esempio di operazioni fra i set sono unioni (e tutti gli amici degli insiemi) quindi per esempio se provo ad unire due insiemi con gli stessi elementi, restano gli stessi.\nAppartenenza, Unione, intersezione, complemento etc‚Ä¶ IMPLEMENTAZIONE SETS\nL‚Äôimplementazione pi√π semplice dei set √® avere un bitset, che il valore del bit ci dice se l‚Äôelemento √® presente o meno in essa. Ma non funziona per sets che sono molto larghi. Quindi di solito si utilizzano gli hash tables per sti set.\nUn altro modo √® utilizzare una hashset in pratica ogni valore ha una hash, e questo viene utilizzato per vedere se √® presente o meno (spesso funzioni fra dominio a un mio)\nUn altro modo per fare set √® utilizzare un albero binario, come fa C++ in set.\nReference Types NOTA: i puntatori sono abitanti di questi reference types, per√≤ non sono gli unici! (esempio URL, reference alla risorsa. Via di casa, reference alla tua casa).\nSono le reference a qualcosa! Questo permettono di creare strutture di dati ricorsive.\nOperazioni tipiche sono, creazione, check uguaglianza, dereferenziazione. Il pointer √® l‚Äôimplementazione pi√π semplice di questo tipo di dato.\nCASI SPECIALI REFERENCE TYPES (3)\nSenza certe tipologie di checks, le references possono causare molti problemi, come le reference wild (quando ho dei pointer non inziializzati e quindi posso avere random della stack)\nPer questi √® meglio sempre assegnare a Null per evitare questo, se non lo fa gi√† il linguaggio.\ndangling (quando si riferisce ad elementi gi√† liberati, o ci sono altre cose). Questo √® principalmente causato dal fatto che solitamente sono soluzioni basso livello, che interfaccia praticamente direttamente sulla memoria.\nMemory leak, quando sto perdendo memoria, nel senso che non ho pi√π nessuna reference, quando per esempio dislinko un puntatore, senza averla marcata come libera (quindi perdo un sacco di memoria, che non posso pi√π allocare).\nOPERAZIONI CLASSICHE (4)\nSlide reference types\nCreazione di un certo referenze ad un oggetto\nDereferencing, cerco il dato puntato da questa referenza\nEquality, per vedere se √® uguale la reference\nOPERAZIONI GENERALI CON I REFERENCES.\nVariabile referencing operator, in pratica vorrei che creasse una variabile che abbia come r-value la l-value di una certa variabile (descritto in Valutazione Espressioni), ossia il suo indirizzo o contenitore, la sua reference\nAllocazione e deallocazione dinamica, ma questa non √® che dovrebbe essere operazione su questo tipo\nPower sets Questo sono i primi tipi che non abbiamo visto in un linguaggio di programmazione, alla fine √® sempre un Sets/Insiemi, ma con qualche informazione in pi√π.\nDefinizione di powerset P, partendo da un set iniziale S.\nQuesto soprattutto √® un modo molto utile per rappresentare tuple, ossia coppie ordinate, molto naturali con dei powerset.\nOsservazione powerset per due\nCon l‚Äôosservazione di sopra abbiamo detto che la tupla definita in quel modo, che segue la definizione di kuratowsky in 3.1.1 Definizione di Kuratowsky, √® un elemento del powerset del powerset, quello √® proprio il prodotto cartesiano! Chiachiamo product types, o tipi prodotto come combinazioni una o pi√π strutture (quindi non pi√π omogeneo come prima)\nPAIRS AND TUPLES\nSlide pairs and tuples\nAbbiamo la stessa informazione con gli array (solo che possono non essere omogenei!) abbiamo sempre informazione sulla posizione, e un valore all‚Äôinterno della posizione. La coppia generalizzata √® una tupla.\nRECORDS\nSe astraiamo le tuple, aggiungendoci un nome per ogni tipo ad una certa posizione, allora abbiamo i records, che non sono altro che delle strutture.\nQuando andiamo a prendere un elemento stiamo facendo una proiezione monomorfa, perch√© da tutto quell‚Äôarray di elementi stiamo andando a prenderne un singolo.\nPATTERN MATCHING\nQuesto √® una struttura molto comune nei linguaggi funzionali, ma anche presente in rust. Sono buoni da poter definire all‚Äôinterno di un tipo prodotto.\nSlide pattern matching\nPraticamente vorremmo fare una partizione completa degli abitanti di un tipo, per questo motivo posso fare una specie di casework completo per gestire in modo esplicito tutti i casi. Questa partizione √® fatta in modo libero con delle regole :D.\nTIPI RICORSIVI\nQuesti tipi sono definiti per la prima volta grazie ai pairs (quelli con riferimento erano invece delle cose diverse, anche se concettualmente √® simile). Possiamo definire che questo sia un tipo ricorsivo nel senso che si potrebbe descrivere come un powersets infinito (credo).\nDalla lezione ora mi sembra abbia detto che deve necessariamente avere una reference dello stesso tipo\nSum Types Slide introduttiva sum types\nI tipi di somma ci permettono di avere abitandi di pi√π mondi.\nNell‚Äôesempio di sopra gli insiemi sono taggati per non confondere un elemento di un insieme con un altro! anche chiamato or types, choice types, tagged unions, union types, variant types, perch√© pu√≤ assumere un inabitante a caso fra tutti i tipi che costituiscono questa unione.\nAbbiamo gi√† visto le ENUMS che fanno cose simili, ossia pu√≤ avere abitanti di tipi diversi, quindi stiamo comunque catturando la somma dei tipi. √à interessante osservare che dal punto di vista teorico prendere un elemento di union implementato per enumerazione √® simile a tirare fuori da un pacchetto.\nUNION DATATYPES\nCome in C, posso avere le union data types, in cui stessa zona di memoria posso metterci i dati che ho scelto (solo che non mi fa check statico a vedere cosa ci pu√≤ stare!!), cio√® a differenza degli enums, non ho il controllo dell‚Äôaccesso, decido io come guardarlo.\nRECURSIVE TYPES\nAnche con i sum types posso andare a descrivere i tipi ricorsivi (solamente che alla fine invece di dire che Null √® un inabidante delle reference, gli dico che √® un abitante di qualcos‚Äôaltro!) Questo mi rende molto carina la sua struttura (e mi permette anche pattern matchin senza nessun problema (√® un modo pi√π sicuro per aprire, dato che posso fare matching).\nSlide recursive types with sum\nFunction types Praticamente sono elementi di $A^B$, con B partenza A arrivo. L‚Äôoperazione fondamentale di questi tipi sono l‚Äôapplicazione.\n","permalink":"https://flecart.github.io/notes/teoria-dei-tipi/","summary":"Ripasso Prox: 30 Ripasso: June 6, 2023 Ultima modifica: May 14, 2023 6:13 PM Primo Abbozzo: March 13, 2023 9:20 AM Studi Personali: No\nElementi di ripasso Teoria dei Tipi Introduzione Definizione üü©‚Äî Un metodo sintattico praticabile per dimostrare l\u0026rsquo;assenza di determinati comportamenti del programma, fatto classificando le unit√† sintattiche in base ai tipi di valore che assumono\nVogliamo che fosse praticabile nel senso che effettivamente lo possiamo implementare, cio√® ci permettono di avere certe tipologie di garanzia.","title":"Teoria dei Tipi"},{"content":"Some notes Mix-based systemsüü® Created in 1981 by David Chaum. Very similar to the previous one, in practice, in the end, it acts as a proxy but not only does it take and receive, but it also mixes together the packets it has received from the sources, applying its key.\nDisadvantage: The public-private mixing system is very slow. For this reason, a network of nodes is established, each having a symmetric key, making it much faster.\nThe important thing to note is that this system has been influential in modern tor networks.\nFullz dataleak A fullz dataleak has the minimum indispensable to create bank accounts or pay with credit cards\nName and Surname birthdate fiscal code phone number residence address So its very important to keep this information private!\nThe Tor Ecosystem This system tries to anonymize the user with principles similar to #Anonymity by proxy. The initial user message goes through different relays before reaching the end destination. The system is a little bit more complex than this, so we are breaking down a connection example\nIt\u0026rsquo;s called onion because each relay has only an outer layer of the onion. The core is what the end user receives.\nHow Tor Works The Tor network sends the payload through three random relay servers in the network. Information about what we are accessing, from who, is not accessible. But some information is still accessible, for example:\nOur ISP knows that we are trying to access the Tor network, because we need a listing of tor nodes. The exit relay knows to whom we are talking to, as this information is needed to send the message. As the exit node is often public, they are often blocked by institutions, like banks.\n#### Overlay networks \u003e Rete ‚Äúoverlay‚Äù. Una rete **chiusa** al quale interno vengono distribuiti dati in **forma anonima**. Questo √® il principio dei servizi onion. Service setup When a service is put onto this network it connects to some intro nodes whose role is to introduce clients to the servers. The map server-\u0026gt;intro nodes is then saved into another node, which is called the directory node. This node contain mappings from services and intro points.\nClient Connection The client that wants to connect to an anonymous service needs to know who are the intro nodes. He asks the directory node who gives him the connections. Directory gives him a descriptor, that is verified with the original .onion address who acts as a secure key.\nThe the client asks a secret string from a rendezvous node. The secret string and rendezvous are then sent to the intro nodes, and these sent it to the original service that decides whether to accept or not that service.\nIf it accepts, it sends the secret to the rendezvous, who then creates a circuit between the client and the server. Now everything can be sent and received anonymously.\n","permalink":"https://flecart.github.io/notes/the-tor-protocol/","summary":"Some notes Mix-based systemsüü® Created in 1981 by David Chaum. Very similar to the previous one, in practice, in the end, it acts as a proxy but not only does it take and receive, but it also mixes together the packets it has received from the sources, applying its key.\nDisadvantage: The public-private mixing system is very slow. For this reason, a network of nodes is established, each having a symmetric key, making it much faster.","title":"The Tor protocol"},{"content":"Ripasso: May 14, 2023 Ultima modifica: June 17, 2023 11:54 PM Primo Abbozzo: February 24, 2023 1:33 PM Studi Personali: No\nElementi di ripasso URI Sono stata LA vera invenzione di Berners Lee accennati in Storia del web. Il problema √® avere un modo per identificare una risorsa in modo univoco sull‚Äôinternet.\nIntroduzione La risorsa üü© Una risorsa √® qualunque struttura che sia oggetto di scambio tra applicazioni all‚Äôinterno del World Wide Web.\nOra una risorsa pu√≤ essere qualunque cosa, non solamente solo un file! Quindi √® agnostico rispetto a contenuto oppure metodo di memorizzazione del dato, appare anche in questo ambiente importante vedere quanto siano importanti standard che permettano una comunicazione\nEsempi di risorsa:\nFile di testo Immagine Chiave di Hash Chiave per una query di database Una funzione da chiamare da remoto In pratica qualunque cosa che possa fare il web, e identificabile da un URI si potrebbe chiamare risorsa, √® un termine molto generale, non definito in modo formale o tecnico.\nSlide\nIn breve √® risorsa qualunque cosa che possa essere oggetto di scambio in una interazione web.\nURL and URN Gli URI (Uniform Resource Identifier) sono una sintassi usata in WWW per definire i nomi e gli indirizzi di oggetti (risorse) su Internet.\nURL indicano la locazione della risorsa (che il browser riesce ad andare a questa locazione, ma pu√≤ essere cambiato dal gestore della risorsa, e quindi pu√≤ essere spostato e mai pi√π trovato!), a volte non piace molto questa cosa, e quindi si cerca di creare un URL permanente. Che di solito o √® fatto per redirezione quando si sposta o Ho un sistema di virtualizzazione di uri fisici (in qui veramente c‚Äô√® la risorsa e virtuali (quelli in interfaccia su cui faccio la richiesta).\nURN √® una etichettazione permanente di una risorsa, √® PERMANENTE ma ha bisogno di una risoluzione per la sua locazione, per risolvere il problema della locazione nel caso venisse spostata.\nGli URI potremmo definirli come l\u0026rsquo;intersezione fra le due, sia un modo per identificare la locazione (quindi andare ad accederci) sia un modo per etichettarli in modo definitivo (in questo modo sono degli URN).\nCaratteristiche üü® URI sono un sistema sintattico (focus sul fatto che siano puramente sintattici!!!, non descrivono la semantica (cosa fare per accedere, ma comunicano il protocollo usato per accedere)che possiamo vederlo anche come sistema di 7 livello OSI utilizzato per identificare la risorsa √® importante quindi che\nTrascrivibili, ossia hanno caratteri limitati, e tutti leggibili da umani. Identificazione, non interazione, avendo solo l‚ÄôURI non posso fare operazioni sulla risorsa. Gerarchizzazione dei nomi url ha una certa struttura (come i caratteri speciali nell‚ÄôURL), in questo senso esiste una certa gerarchizzazione dei nomi! (simile a quanto faccia il filesystem). Struttura dell‚ÄôURI 5 URI = schema : [// authority] path [? query][# fragment]\nPer favorire la trascrivibilit√† ci sono certi caratteri scpeciali tenuti apparte (e se servono sono encodati). curi si parla di caratteri per URI.\ncuri = unreserved | reserved | escaped Slide sui caratteri encodati\nPer sapere i caratteri encodati, sarebbe bene tenersi a mente le slides, o comunque la grammatica diciamo!\nURI resolution and dereference (!) Un uri pu√≤ essere assoluto oppure una URI reference. Se √® assoluto allora deve soddisfare tutta la struttura di cui sopra, oppure semplicemente dire il nome del file a seconda di una certa base.\nIn questo caso si parla di URI Reference perch√© √® relativo a un certo dato. resolution: Quando do in input un URI reference e in output mi aspetto una URI completa Dereferencing: quando do in input un URI completo e mi aspetto indietro una risorsa.\nAlcune regole di URI resolution Routing Tipologie di routing (2) Managed Route\nQuesto √® la forma di gestione degli URI pi√π nuova, in pratica il mapping di gestione delle risorse √® fatto a livello server. (quindi e.g. in Express posso dire a un certo URL quale risorsa interna corrisponde).\nFile-system route\nQuesto √® il modo pi√π facile diciamo, praticamente c‚Äô√® corrispondenza fra un percorso all‚Äôinterno del file system all‚Äôindirizzo URI.\nQuesto ha problemi di security perch√©\nDo informazioni sulla struttura interna del nostro sito Non ho controllo sull‚Äôaccesso dall‚Äôesterno Non √® molto malleabile se voglio cambiare la struttura URI Rewriting √à un modo di virtualizzare la URI, una risorsa interna (con uri fisico vero, cio√® dove sta fisicamente) con un uri virtuale all‚Äôesterno, questo √® quello che farebbe ad esempio mod_rewrite di apache.\n√à particolarmente comodo perch√© mi permette di essere pi√π sicuro di informazioni nascoste e di gestire meglio il nome delle risorse esposte a seconda di cosa io abbia internamente, praticamente √® un sistema managed route.\nLa differenza con URI alias √® che l‚ÄôURI vero qui √® nascosto, e non √® esposto\nCURIE Compact URI, un nome carino per riferirsi a modi compatti di scrivere gli uri sono nella forma [prefix:curie].\nSlides\nAlcuni protocolli (schema URI) Di questi non ci importa sapere esattamente i dettagli della loro sintassi, ma che esistono e sono degli URI per qualche tipologia di risorsa!\nHTTP e HTTPS HTTP √® uno dei protocolli pi√π comuni per il WWW. HTTPS √® la sua forma sicura.\nPer maggiori dettagli riguardo funzionamento del protocollo guardare HTTP e REST\nFile Schema Equivalente ad aprire un file dal browser.\nImportante osservare che non esiste un server che gira con questo schema\nSlide\nData Di solito questo √® presente nel payload come messaggio di risposta a qualcosa.\nSlide\nFTP Slide\nTentativi di internazionalizzazione CDN una rete fortemente distribuita di server commerciali che collaborano tra loro per distribuire in maniera omogenea contenuti di grande successo senza inutili duplicazioni di occupazione e trasmissione di file.\nin pratica questi sono dei server che fanno caching con praticamente la stessa idea che avresti avuto in Memoria! Una zona di computer che praticamente contiene tutte le librerie pi√π utilizzate, che siano di facile accesso, e che quindi velocizzano il tempo per prendere una risorsa di molto!\nX-WWW-URLENCODED Una estensione al formato URI per HTTP, questo credo sia un modo per evitare di madnare dei form-multipart data che si leggono male, ma con questo si dovrebbe leggere meglio. Altri motivi non mi vengono in mente del perch√© sono proprio necessari.\nIRI e IDN IRI √® un International resource identifier che permette di risolvere risorse identificate da nomi non solo in ASCII 7, senza dover utilizzare url-encoding. Esteso a UTF-32!!!\nIl problema principale √® che da problemi di aliasing (a cirillica molto simile di a latina, quindi uno potrebbe fare pishing basandosi su questa cosa), questo √® stato permesso da IDN (Internationalized DomainName) che permette di avere nomi di nominio anche non di soli caratteri latini, utilizza UNICODE ???. Questi sono attacchi via omografi.\nLa visione dei software Le cose online dovrebbero essere accessibili anche ai software, non solo agli umani. Questo e importante per i crawling bots credo, cos√¨ riescono a farsi una idea del sito o allo stesso modo queste cose strane‚Ä¶\nPer berners Lee, che introdusse il Linked Data questo era importante perch√© cos√¨ un dato poteva essere accessibile anche da applicazioni. affermazioni atomiche minimali\nNome, propriet√†, Valore (sono in sta forma, come URI per√≤). Questo √® quello che fa WIkiDATA!!!\nSlides\nQuesto si collega senza nessun problema all\u0026rsquo;ultima parte trattata nel corso riguardante il Metadati web e web semantico.\nIn cui si vanno a parlare di RDF e simili. (immagine di un web accessibile tanto ai bot quanto agli umani, perch√© i dati sono tutti tanto strutturati).\n","permalink":"https://flecart.github.io/notes/uniform-resource-identifier/","summary":"Ripasso: May 14, 2023 Ultima modifica: June 17, 2023 11:54 PM Primo Abbozzo: February 24, 2023 1:33 PM Studi Personali: No\nElementi di ripasso URI Sono stata LA vera invenzione di Berners Lee accennati in Storia del web. Il problema √® avere un modo per identificare una risorsa in modo univoco sull‚Äôinternet.\nIntroduzione La risorsa üü© Una risorsa √® qualunque struttura che sia oggetto di scambio tra applicazioni all‚Äôinterno del World Wide Web.","title":"Uniform Resource Identifier"},{"content":"Markup Introduzione alle funzioni del markup üü© La semantica di una parola √® caratterizzata dalla mia scelta (design sul significato). Non mi dice molto, quindi proviamo a raccontare qualcosa in pi√π.\nDefiniamo markup ogni mezzo per rendere esplicita una particolare interpretazione di un testo.\nIn particolare √® un modo per esplicitare qualche significato. (un p√≤ come la punteggiatura, che da qualche altra informazione oltre le singole parole, rende pi√π chiaro l\u0026rsquo;uso del testo).\nLe informazioni aggiuntive possono essere riguardanti:\nLa struttura del testo La formattazione del testo Relazioni fra parti del testo. Tipologie di Markup (6) üü®+ Puntuazionale\nQuesto √® un markup che l‚Äôautore stesso d√†. ed √® fortemente ambiguo!.\nIl markup puntuazionale consiste nell‚Äôusare un insieme prefissato di segni per fornire informazioni perlopi√π sintattiche sul testo.\nPresentazionale\nEffetti grafici per comunicare fine capitolo o altri simili\nSlide\nProcedurale\nQuesto √® una tipologia di markup che utilizza delle istruzioni per definire la presentazione. (quindi in questa parte ci sono dei comandi!) (esempi credo siano latex o Tex)\nDescrittivo\nVuole descrivere la struttura e la semantica di frammenti di testo. (non √® procedurale, perch√© non gli dico pezzo per pezzo la grafica), io dico se √® un testo, se √® una didascalia, in modo simile a quanto fatto qui su Notion.\nReferenziale\nQuando faccio riferimento a cose esterne per risolvere il significato. Di solito fa usi di SIGLE o abbreviazioni di qualcosa\nMetaMarkup\nSe utilizzo un linguaggio per creare un linguaggi di Markup, un esempio √® Word, perch√© con quello utilizzo il linguaggio di markup (descrittivo, su font e simili), anche HTML.\n(6Il metamarkup consiste nel fornire regole di interpretazione del markup e permette di estendere o controllare il significato del markup.\nMetodi di classificazione di markup Standard privato oppure pubblico Se √® interno o esterno (nel senso se si riferisce al testo interno oppure al testo esterno) binario o leggibile (per dire se √® pi√π fruibile per le macchine oppure se √® fatto per essere fruibile per esseri umani) Poi si fa anche una distinzione fra procedurale (latex o troff like) oppure dichiarativi, nel senso che si taggano parti per indicarne l\u0026rsquo;utilizzo (come pe rl‚ÄôHTML). Alcuni linguaggi di Markup (non impo) üü•+ GROFF TROFF, NROFF\nQuesti sono scritti i linguaggi di markup per i manuali tecnici di Linux.\nTEX e LATEX\nSoftware di impaginazione autoomatica, principalmente per formule matematiche, perch√© ci metteva troppo a fare il suo libro che la casa editrice sbagliava le formule. C\u0026rsquo;√® anche un metafont utilizzato per astrarre la fomra dei caratteri‚Ä¶ √à poi turing completo, molto difficile, moltissime keyword. √à molto difficile quindi Leslie Lamport crea una libreria molto pi√π facile da utilizzare.\nMarkdown\nUna semplificazione molto semplice, con formattazioni ad hoc, utili per testi semplici, senza molta possibilit√† di avere cose tipografiche precise.\nJSON e YAML\nJSON (Javascript Object Notation) √® un formato dati per facilitare lo scambio di dati in internet.\nYAML √® molto python like, che utilizza spazi come delimitatori (√® superset di json, quindi capisce anche quello.). Per il resto √® uguale a JSON, ma ha i commenti.\nXML\n√à un sottoinsieme di SGML, che ha molte pi√π garanzie formali. (infatti definiamo ora con BNF, ed √® una complessit√† assurda!)\nBen forma (puramente sintattico) Validit√† del documento (a seconda delle regole della grammatica cheho definito) Slide documenti ben formali\nSGML üü®- SGML (Standard Generalized Markup Language) √® uno standard di IBM rilasciato gratis. SGML √® un meta-linguaggio non proprietario di markup descrittivo. Facilita markup leggibili, generici, strutturali, gerarchici.\n√à una tipologia di markup chiara, leggibile, strutturata, descrittiva e gerarchica, i primi fisici erano molto felici per questo metalinguaggio di markup.\nStruttura di un documento SGML\nDichiarazione SGML DOCTYPE, o dichiarazione dei nomi utilizzabili all\u0026rsquo;interno del documento Istanza del documento Slide\nEsempio SGML\n√à uno dei Markup pi√π importanti perch√© possiamo dire che sia il precursore dell\u0026rsquo;HTML\nCostituenti base di SGML\nElementi\nAttributi\nEntit√†\nPCDATA\nCommenti\nProcessing instructions\nQuesta parte dovrebbe essere molto importante se si parla della parte teorica, per√≤ nella pratica mi sembra che siano in verit√† utilizzate pochissimo, sono comuqnue interessanti sapere che esistano\nXML Questo √® un sottoformato di SGML, ed √® utilizzato principalmente per fare una verifica formale che tutti i tags dichiarati siano a validi e cose simili.\nSlide XML, strumenti di checks\nUn esempio √® il tag che non contiene niente, allora √® nella forma \u0026lt;.../\u0026gt;senza un altro tag che lo chiuda. E poi ci sono tutti i checks per attributi (che devono esere per forza con le virgolette, differentemente rispetto a HTML lasco che potrebbe permetterne anche senza, anche attributi senza niente potrebbe permettere per esempio, questo perch√© provano i browser ad accettare tipologie di documenti molto ampi.\nUn p√≤ di storia √à importante capire un p√≤ di storia per vedere che strano robo abbiamo oggi.\nDue linee di sviluppo, uno √® uno standard di W3C, l\u0026rsquo;altro √® il living standard. √à di fortissimo cambiamento, quindi di difficile definizione! (cambia significato sia di semantica e che di sintassi).\nNel 1997 abbiamo HTML4 che √® stata considerata la versione finale, per cui un sacchissimo di siti web fino al 2008 sono stati implementato con questo HTML\nTag Soup üü© I browser permettono molti tag, senza voler dare errore con l\u0026rsquo;obiettivo di essere comprensivi. Abbiamo quindi un sacco di tags, molti dei quali non sono conformi a nessuno standard. Non abbiamo una correttezza sintattica o semantica dei tags. Abbiamo in pratica troppe eccezioni.\nIl problema allora diventa, quando vogliamo andare a creare un parser per questo genere di html, come andare a crearne uno che riesca a gestire queste tipologie di tags?\nSlide quirks and strict mode\nIn particolare abbiamo con HTML5 una standarizzazione delle regole di parsing quindi possiamo andare ad utilizzare lo strict mode e avere pi√π garanzie sulle pagine.\nXHTML e HTML Le aziende dei webbrowser avevano gi√† il codice per parsare il HTML brutto, con molti codici, e non volevano creare un nuovo parse per XHTML, molto pi√π formale e che riusciva a garantire pi√π codice (ossia ci sarebbe un modo unico per scrivere del codice corretto!). L\u0026rsquo;hanno proposto ai tizi del W3C che l\u0026rsquo;hanno rifiutato. Cos√¨ √® stato creato il working group WHATWG in cui si lavor√≤ a una versione intermedia di HTML, che estese con alcuni tag. Dentro questo gruppo erano gi√† presenti i maggiori player per i browser come mozilla, microsoft, e poi ci √® entrato Google assumendo Ian per la creazione di chrome.\nIn questo moto ha vinto HTML5, che viene chiamato solamente HTML e un living standard che viene aggiornato ogni poche settimane.\nQuesto albero che viene creato dal parsing di quel modello √® utile per la creazione del DOM trattato pi√π sotto.\nHTML Struttura del documento üü© Ci deve essere una intestazione DOCTYPE che ci specifica che tipologia di documento stiamo andando a parsare (se non c\u0026rsquo;√® credo sarebbe sintatticamente invalido ma ciononostante il browser √® in grato di inferire come intenderlo!)\nhtml che include tutto\nhead che include informazioni generali sul documento\nbody che contiene il contenuto del sito.\nEsempio di file HTML\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt; Document title \u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt; Major Header \u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is a complete paragraph of a document. I write and write until I fill in several lines, since I want to see how it wraps automatically. Surely not a very exciting document.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Did you expect \u0026lt;b\u0026gt;poetry\u0026lt;/b\u0026gt;?\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Here you can see a paragraph \u0026lt;br\u0026gt; split by a \u0026amp;lt;br\u0026amp;gt;\u0026lt;/p\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt; A list of important things to remember: \u0026lt;/p\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Spaces, tabs and returns\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Document type declaration\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Document structure\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Nesting and closing tags\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Elementi inline üü© Molti sono stati deprecati (o non li usa nessuno), perch√© dovrebbero essere usati CSS per la parte grafica. Solo i, e B sono ancora presenti, o small, perch√© sono caratteri tipografici molto comuni!\nEsempi di elementi inline\nElementi di blocco e di lista üü© Sono i blocchi classici per rappresentare struttura di headers, di paragrafi, e blocchi generici, o citazoini, autori.\nBlocchi sequono una sequenza di lettura fra le letture!\nesempio:\n, un elemento anonimo, che deve essere totalmente stilato. , la stessa coda del div, che per√≤ non √® blocco ma INLINE. , ‚Ä¶, etc NOTA: whitespace √® praticamente sempre ignorato, tranne all‚Äôinterno del tag pre. (esiste white-space: pre, che permette di utilizzare whitespaces\nSlide\nEsempio\nElementi di lista\nSlide\nEsempio elementi lista\nElementi di struttura üü© Non vorremmo avere dei div come elementi di struttura, questo non √® che sia molto chiaro dal punto di vista semantico!\nQuindi introduciamo\nche descrive un qualcosa di annidabile che prende qualcosa di **self-contained** che pu√≤ essere utilizzato a s√©, e quindi potrei rimuoverla o inserirla senza problemi! Slide tags struttura\nSlide header e footer\nSlide nav\nEsempio confronto HTML 4 / HTML5\nAnchors and images üü© Anchors\nPosso metterci un fragment per gli a, questo non camibano niente nella transazione client e server, ma √® il browser che capisce la locazione dopo aver scaricato tutto.\nSi noti che l\u0026rsquo;attributo name non cambia la visuale del blocco, a differenza di href (che manda fuori).\nSlide anchors\nImmagini\nHa ancora degli attributi altezza e witdt, che rimangono ancora nonostante siano attributi rappresentazionali. Per√≤ precalcola l\u0026rsquo;occupazione dell\u0026rsquo;immagine e quindi il tutto carica pi√π in fretta.\nSlide immagini\nPotrei includerla con una immagine, e specificare height o width (se li includo entrambi avr√≤ resize dell‚Äôimmagine senza rispettare le proporzioni, se non metto niente avrei l‚Äôimmagine di grandezza naturale (px original) altrimenti se ne metto sono una avr√≤ una resize che mantenga le dimensioni iniziali).\nsrcset, vogliamo avere tantissime immagini, che si scalino in modo automatico aseconda del device, definisco srcset e delle sizes.\nSlide srcset\n**figure **√® un tag con un caption in pratica, niente di che‚Ä¶\nForm üü®- esistono da sempre, quindi gi√† dall\u0026rsquo;inizio sembrava che fossero utili per fare applicazioni con un rapporto in clientside.\nCreare una schermata per specificare i dati da passare a una applicazione server-side, per creare punti di raccolta di informazioni, e fare un submit all\u0026rsquo;applicazione server side, chiamata ACTION, .\nSlide struttura di un form\nSolitamente i metodi sono GET o POST, ma vedremo dopo con HTTP questa differenza.\nI widget sono le cose visibili nel form, come **textarea, radio,, input select, *button.\nInteractive forms\nNew input forms\nTags generali üü©- Embedding\nobject √® un tag per oggetti che non sono capibili dal browser naturalmente, infatti bisogna specificare un engine con cui runnarlo.\nQuesto √® un embedding molto, troppo generale, quindi vogliamo creare i tags per embedding specifici, che rende il tutto pi√π chiaro.\nSlide per tags di embedding\nTabelle\nCose come th per dire table header, or tr per dire table row., td per dire table data., e table per inizializzare le table\nSolitamente √® composta da tre parti. head, foot, e body, solitamente per questioni di efficienza foot deve essere messo subito dopo le head, perch√© ha i numeri pi√π grandi, quindi non devo andare a ricalcolare la grandezza della tabella.\nUna altra cosa interessante per le tabelle √® che ci sono stiling come attributi (esempio di questo sono colspan, rowspan etc), ma dovrebbe essere di CSS, infatti questo era un modo per farlo prima di CSS.3.\nTipicamente utilizare le tabelle per fare layout √® una delle cose meno accessibili che esistono! Quindi non ha pi√π nessun senso utilizzare le tabelle di layout. (non utilizzarle, penalizza!).\nDOM Questa parte √® fatta meglio in Javascript\nDocument object model, l‚Äôobiettivo della WHATWG era costruire un parser che potesse aiutare a creare una struttura di dati utile per la creazione di applicazioni, quindi molto pi√π tollerante rispetto a quanto proposto dal W3C e specifiche pi√π rigide come XHTML.\nDocument Object Model, una struttura di dati con alcune funzioni e strutture built in che permettono la facile manipolazione fornisce API. Dovrebbe essere facile creare un DOM da codice HTML cos√¨ come il constrario. √à esattamente quello che si vede sullo schermo!\n‚Äúl‚Äôimportante √® arrivare ad una struttura dati in memoria unica su cui costruire applicazioni\nDato che deve funzionare per HTML secondo la filosofia pi√π estesa del WHATWG, √® praticamente la struttura del XHTML ampliata per includere altro, questo permette al codice JS di intervenire direttamente sul DOM.\nStruttura del DOM üü© Slide struttura del dom\nCi sono alcune classi fondamentali per poter comprendere il DOM\nDocumento Nodo del DOM Nodo di testo Nodo di elemento Nodo di attributo Poi ci sono molte altre classi, come commendi, Datasection e molti altri che di solito si vedono poco, quelli pi√π importanti sono il Document e i nodi descritti sopra Alcune classi del dom üü©‚Äî Slide DOMNode\nSlide DOMDocument e Selettori\nSolitamente √® complicato lavorare col DOM vanilla, tanto che l\u0026rsquo;hanno chiamato sadico chi ne √® stato detrattore.\nSlide DOMElement\nInner e OuterHTML üü© Andare a modificare l‚ÄôHTML √® molto verboso, utilizzando questi metodi √® pi√π veloce andare a creare nuovi elementi.\nL‚Äôunica differenza fra i due √® che Outer include anche il contenitore nella modifica, inner √® solo per il contenuto\nSlide Inner e OuterHTML\nAltre note Whitespaces in HTML üü© Whitespace √® ignorato (soprattutto in elementi strutturali come i table) Whitespace √® collassato in un unico whitespace in il whitespace √® mantenuto. Cose saltate Queste cose per completezza le cito, e sono presenti sulle slides, ma le salto per pigrizia\nTipi di dati Attributi globali Attributi data e aria Entit√† predefinite Peculiarit√† sintattiche Il contenuto dell\u0026rsquo;elemento HEAD ","permalink":"https://flecart.github.io/notes/html-e-markup/","summary":"Markup Introduzione alle funzioni del markup üü© La semantica di una parola √® caratterizzata dalla mia scelta (design sul significato). Non mi dice molto, quindi proviamo a raccontare qualcosa in pi√π.\nDefiniamo markup ogni mezzo per rendere esplicita una particolare interpretazione di un testo.\nIn particolare √® un modo per esplicitare qualche significato. (un p√≤ come la punteggiatura, che da qualche altra informazione oltre le singole parole, rende pi√π chiaro l\u0026rsquo;uso del testo).","title":"HTML e Markup"},{"content":"Andremo ad analizzare integrali di funzioni continue su insiemi semplici (domini normali) .\nIntroduzione Y-semplice e regolarit√† √à un insieme semplice di punti, in pratica, se considero un intervallo limitato e due funzioni definite in questo intervallo tale che una √® sempre minore dell‚Äôaltra, l‚Äôinsieme y-semplice sono i punti compresi fra queste\nDefinizione del libro Intuizione integrale Definizione del prof. Dato un insieme semplice A e una funzione continua $f:A \\to R$ allora √® ben definito l‚Äôintegrale $$ \\int_Af(x, y) dxdy \\in R $$ Osservazione 1:\nSe integriamo la funzione costante 1 possiamo effettivamente trovare l‚Äôarea di integrazione.\nChe da un concetto di misura dell‚Äôinsieme di integrazione\nOsservazione 2:\nL‚Äôintegrale definisce una sorta di sottografico di una funzione, ma a pi√π dimensioni. (in questo caso con insieme di integrazione di dimensione 2 si ha il volume).\nCalcolo tramite riduzione Definizione del libro\nCerco di fare a fettine i punti, cos√¨ mi √® molto pi√π facile calcolare i punti.\nLavagna del prof. (caso y - semplice)\ncaso x -semplice\nSi pu√≤ utilizzare un calcolo in modo equivalente ma sta volta partendo prima dalla x, perch√© abbiamo definito l‚Äôintervallo in funzione della y\n","permalink":"https://flecart.github.io/notes/integrali-multi-dimensionali/","summary":"Andremo ad analizzare integrali di funzioni continue su insiemi semplici (domini normali) .\nIntroduzione Y-semplice e regolarit√† √à un insieme semplice di punti, in pratica, se considero un intervallo limitato e due funzioni definite in questo intervallo tale che una √® sempre minore dell‚Äôaltra, l‚Äôinsieme y-semplice sono i punti compresi fra queste\nDefinizione del libro Intuizione integrale Definizione del prof. Dato un insieme semplice A e una funzione continua $f:A \\to R$ allora √® ben definito l‚Äôintegrale $$ \\int_Af(x, y) dxdy \\in R $$ Osservazione 1:","title":"Integrali multi-dimensionali"},{"content":"0 Introduzione 0.1 L‚Äôalgoritmo Vogliamo cercare di creare algoritmi, ovvero soluzioni a problemi computazionali che non dipendono dal linguaggio di programmazione.\n0.1.1 Definizione Procedura per risolvere un problema in un numero finito di passi (quindi un algoritmo deve finire)\n0.1.2 Origine della parola Il nome \u0026ldquo;algoritmo\u0026rdquo; deriva da un nome di un matematico persiano dell 800 d.c. Muhammad ibn Musa al-Khwarizmi, che latinizzato diventa algorithmi, quindi i latini hanno creato la parola!\nQuesto matematico aveva creato un trattato per studiare il sistema di numerazione arabico che sostituir√† quello romano, si chiama Algoritmi de numero Indorum, un sistema pi√π efficiente rispetto al romano.\n0.1.3 Algoritmo vs programma Un algoritmo √® una cosa differente rispetto al programma, l\u0026rsquo;algoritmo √® pi√π concentrato sul design (la descrizione dei passi ad alto livello, di solito in pseudo codice che non √® eseguibile) mentre il programma √® l\u0026rsquo;implementazione dell\u0026rsquo;algoritmo, che dipende strettamente da un linguaggio di programmazione (che potrebbero esserci aspetti noiosi di implementazione) e dai limiti finiti della macchina, come memoria.\n0.1.4 Esempio massimo comune divisore 0.2 Fibonacci Possiamo trovare molteplici soluzioni per trovare il numero di fibonacci.\n0.2.1 One-shot Esiste la formula matematica per calcolare il numero di fibonacci. Questa la risolve subito, ma ha il problema di avere problemi di precisione in quanto le radici e simili non sono salvati correttamente in memoria.\n0.2.2 Classico algoritmo ricorsivo Algoritmo\nQuesto approccio funziona ma √® dannatamente lento in quanto ha bisogno di tempo di tempo. (lineare di memoria)\nLa cosa brutta di questo algoritmo √® che non utilizza il fatto di stare calcolando stesse istanze di quelle. Cio√® non sta riutilizzando calcoli gi√† fatti\nGiustificazione della linearit√† della memoria\nPossiamo osservare da questa rappresentazione dell\u0026rsquo;albero di chiamate che al massimo posso chiamare questa funzione un numero n di volte. (percorso pi√π lungo radice foglia)\nAnalisi temporale\nPer una analisi temporale corretta si cerca di prendere in considerazione alcune operazioni primitive dei computer dato che non possiamo tenere in conto l\u0026rsquo;istruzione codice macchina (che dipende dal compilatore e non funziona nemmeno tenere conto dei secondi che ci mette perch√© dipende dalla macchina) Quindi consideriamo solamente operazioni primitive che hanno bisogno di un tempo costante per esse eseguite.\nDimostrazione della relazione temporale\n0.2.3 Classico algoritmo iterativo Algoritmo\nAnalisi spaziale\nStiamo allocando un array lungo n, per cui si ha n item di spazio\nAnalisi temporale\nNel calcolo ha sbagliato a mettere un 3 davanti alla parentesi, dovrebbe essere 2 (ma resta lineare)\n0.2.4 Iterativo ottimizzato in memoria Una osservazione importante √® che non ci serve tenere in memoria l\u0026rsquo;intero array perch√© gli unici elementi che ci interessano sono i vecchi due elementi, quindi possiamo creare una formula iterativa che tenga conto di questo fatto e migliorare l\u0026rsquo;uso della memoria da lineare a costante.\nAlgoritmo\n0.2.5 Soluzione matriciale (mult non ottimizzato) Notiamo che fibonacci pu√≤ essere espresso come una potenza della matrice $\\begin{bmatrix} 1 \u0026 1 \\\\ 1 \u0026 0 \\end{bmatrix}$.\nQuesto fatto si pu√≤ dimostrare per induzione, una volta fatto possiamo andare ad implementare l\u0026rsquo;algoritmo nuovo. Questo algoritmo dopo una analisi ha stesse propriet√† dell\u0026rsquo;algoritmo precedente, per√≤ pu√≤ essere migliorato il passo di moltiplicazione matriciale\nAlgoritmo e l\u0026rsquo;analisi di essa\n0.2.6 Matriciale ottimizzato Utilizzando l\u0026rsquo;osservazione accennata sopra, che velocizza la moltiplicazione matriciale di molto, portandolo da n a log n. in pratica l\u0026rsquo;idea √® cos√¨: devo raggiungere n partendo da 1, nella precedente aggiungo 1 finch√© non arrivo a n, qui invece moltiplico per s√© stessa finch√© non ci arrivo quindi faccio una cosa tipo: in pratica possiamo vederla cos√¨, guardiamo n in binario, se c\u0026rsquo;√® un 1 moltiplico per matrice base, se 0 moltiplico per s√© stessa. Far√≤ sempre un numero logaritmico di operazioni.\nAlgoritmo helper\nAlgoritmo finale\n0.2.7 Algoritmi a confronto In questa immagine sottostante riusciamo a osservare il grafico sull\u0026rsquo;efficienza dei vari algoritmi.\n0.2.8 Valore in input vs dimensione di input Alla fine sono la stessa cosa.\nSi pu√≤ anche analizzare un input in termini di bit necessari per la rappresentazione dell‚Äôoggetto. Dipende dall‚Äôalgoritmo alla fine (per gli algoritmi di crittografia √® molto pi√π utile analizzare i bit dei numeri\nCosa che non centrano\n$$ f(n) \\in O(g(n)) := \\exists c \\in \\R|\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \\leq c \\\nf(n) \\in \\Omega(g(n)) := \\exists c \\in \\R|\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \\geq c \\ $$ $ f(n) \\in O(g(n)) := \\exists c \\in \\R|\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \\leq c \\\nf(n) \\in \\Omega(g(n)) := \\exists c \\in \\R|\\lim_{n \\to \\infty} \\dfrac{f(n)}{g(n)} \\geq c \\ $$\n","permalink":"https://flecart.github.io/notes/introduzione-algoritmi/","summary":"0 Introduzione 0.1 L‚Äôalgoritmo Vogliamo cercare di creare algoritmi, ovvero soluzioni a problemi computazionali che non dipendono dal linguaggio di programmazione.\n0.1.1 Definizione Procedura per risolvere un problema in un numero finito di passi (quindi un algoritmo deve finire)\n0.1.2 Origine della parola Il nome \u0026ldquo;algoritmo\u0026rdquo; deriva da un nome di un matematico persiano dell 800 d.c. Muhammad ibn Musa al-Khwarizmi, che latinizzato diventa algorithmi, quindi i latini hanno creato la parola!","title":"Introduzione algoritmi"},{"content":"This documents attempts to briefly present the algorithm and some experiments found online about it. The following repo seems to be a good resource: here.\nUsually, PPO is explained as an actor critic framework. This means there is an agent that acts on the environment, and then there is a critic that collects the feedback from the environment. The main idea about this framework is to select a policy that is similar, so that it is less probable that a bad policy, a very different policy from the original is selected. This is achieved by clipping over the advantage. And then\n","permalink":"https://flecart.github.io/notes/proximal-polixy-optimization/","summary":"This documents attempts to briefly present the algorithm and some experiments found online about it. The following repo seems to be a good resource: here.\nUsually, PPO is explained as an actor critic framework. This means there is an agent that acts on the environment, and then there is a critic that collects the feedback from the environment. The main idea about this framework is to select a policy that is similar, so that it is less probable that a bad policy, a very different policy from the original is selected.","title":"Proximal Polixy Optimization"},{"content":"La probabilit√† Termini Esito ed esperimenti aleatorio L‚Äôevento √® quello che accade, mentre un esperimento aleatorio qualcosa di cui vogliamo andare a misurare la probabilit√† diciamo. Esperimento aleatorio: esperimento di cui non conosciamo il risultato con certezza. Esito: risultato dell‚Äôesperimento aleatorio\nSpazio campionario ed evento Spazio campionatorio Lo spazio campionatorio √® l\u0026rsquo;insieme di tutti gli stati possibili per una certa cosa da misurare (ossia di un esperimento aleatorio), gli stati sono talvolta anche chiamati sample points oppure outcomes in modo pi√π semplice.\nEvento √à un sottoinsieme dello spazio campionatorio. Se qualcosa della cosa che stiamo misurando √® dentro questo sottoinsieme, all\u0026rsquo;ora diciamo che l\u0026rsquo;evento √® accaduto altrimenti no.\nNOTA: dato che stiamo parlando di sottoinsiemi, valgono tutte le operazioni di intersezione unione, complementare studiate durante Teoria assiomatica degli insiemi.\nUno spazio di probabilit√† di solito √® definito come $\\Omega, F, P$, con F sigma algebra e P una misura di probabilit√†, ossia tale per cui $P(\\Omega) = 1,$ √® additiva, che descriviamo leggermente meglio in seguito. Si pu√≤ dire che $P$ sia una funzione dall\u0026rsquo;insieme delle parti di $\\Omega$ ai reali in $[0, 1]$.\nUna cosa particolare da osservare riguardo $P$ √® che questa probabilit√† non √® osservabile, non riusciamo ad osservare il fatto che il singolo evento abbia una certa probabilit√†, questa probabilit√† √® qualcosa che nasce dopo un numero molto alto di trials che si susseguono per uno stesso processo stocastico.\nGli eventi poi formano una algebra.\nAssiomi sugli eventi Vogliamo cercare di dire cosa √® un evento su uno spazio campionatorio, possiamo dire che √® un subset dell\u0026rsquo;insieme delle parti tali per cui:\nse $E$ √® un evento, anche $E^{c} := \\{x \\in P(\\Omega) : x \\not\\in E)$ √® un evento L\u0026rsquo;unione infinita di eventi √® un evento $\\Omega$ √® un evento. Assiomi della probabilit√† Questi assiomi si potrebbero giustificare in modo molto migliore partendo dalla teoria della misura, prover√≤ a dire qualcosa partendo da quella nelle prossime sezioni.\nIntanto enuncio qui in modo molto informale gli assiomi principali che abbiamo.\nAssioma 1 La probabilit√† di qualunque evento √® maggiore di 0 $$ \\forall E \\in \\mathcal{P}(\\Omega), \\mathbb{P}(E) \\in \\mathbb{R}, \\mathbb{P}(E) \\geq 0 $$ Assioma 2 La probabilit√† dello spazio campionatorio √® 1 $$ P(\\Omega) = 1 $$ Assioma 3 la probabilit√† √® additiva per insiemi disgiunti. $$ \\mathbb{P}(\\cup_{i = 1}^{\\infty}E_{i}) = \\sum_{i=1}^{\\infty}\\mathbb{P}(E_{i}) $$ Conseguenze principali degli assiomi (4) Valore dell‚Äôinsieme vuoto\nPossiamo considerare una successione infinita di elementi vuoti, questi sono tutti disgiunti, e sono anche tutti uguali perch√© sono applicati sullo stesso insieme.\nSe fosse diverso da 0 allora sarebbe infinito, ma deve essere compreso fra 0 e 1, quindi deve essere 0.\nUnione disgiunta finita\nBasta andare a considerare una successione con 0, questa √® infinita, ma i vuoti non danno nessun contributo quindi vale ancora:\n$$ \\mu(\\bigcup^n A_n) = \\mu(\\bigcup^\\infty A_n) = \\sum^\\infty \\mu(A_n) = \\sum^n \\mu(A_n) = $$ Valore dell‚Äôinverso\ndeve essere che, basta considerare che $\\Omega = A_n \\cup A_n^c$ e l‚Äôunione disgiunta.\n$$ \\mu(A_n) = 1 - \\mu(A_n^c) $$ Monotonia della probabilit√†\nOssia se vale\n$$ A \\subset B \\implies \\mu(A) \\leq \\mu (B) $$ Principio di inclusione esclusione\nProbabilit√† uniforme üü© Il primo √® vero perch√©\n$$ \\forall i, n \\cdot P(w_i) = \\sum_{i =1}^n P(\\omega_i) = P(\\bigcup_{i = 1} ^n \\omega_i) = P(\\Omega) = 1 \\implies \\forall i, P(w_i) = 1/n $$ L‚Äôaltro √® la formula di laplace, perch√© siano il numero di eventi di A, posso scriverlo come unione di quegli elementi, abbiamo detto che sono n, per questo riesco a ricostruire quel numero.\nProbabilit√† discreta Se abbiamo una distribuzione di probabilit√†, cio√® una probabilit√† definita su tutti gli elementi singoletto, allora possiamo avere una probabilit√† discreta, ossia probabilit√† ben definita che sia finito o numerabile.\nDefinizione probabilit√† discreta üü© Densit√† discreta\nPer 1.7 si intende che p deve essere compreso fra 0 e 1 e la somma per tutti gli elementi dello spazio campionario deve essere 1\nCaratterizzazione probabilit√† discrete üü© Continuit√† della probabilit√† discreta üü®+ Dimostrazione\nOssia se ho uno spazio di probabilit√† allora posso avere delle caratteristiche (brutte secondo lollo) riguardo la continuit√† della funzione.\nAnche se per questa parte che non utilizza teoria della misura questo teorema non √® che sia molto utile.\nComunque per questa parte forse √® meglio farlo dalla misura definita sulle algebre, che √® fatta in maniera pi√π generale e ho anche la sigma sub-additivit√† all\u0026rsquo;interno, non so, forse pi√π difficile??\nImpostazione classica della teoria della probabilit√† (non fare) Spazi di misura e di probabilit√† Dico che ho uno spazio misurabile una coppia $(\\Omega, F)$, tale che F sia un insieme di sottoinsiemi di omega, chiamato spazio campionario, e F insieme di eventi. Deve essere che F √® una sigma algebra, ossia tali per cui siano chiusi per complementazione e per unione contabile.\nSi parla di spazio di misura quando allo spazio misurabile associamo una funzione di misura.\nParliamo di spazio di probabilit√† se ho anche una funzione di misura tale per cui $P(\\Omega) = 1$, . Si ricorda che la funzione di misura √® tale se ha come codominio 0 to infty, e ha vuoto = 0, e che sia sigma additiva.\nContinuit√† dall‚Äôalto e dal basso. Se ho che la funzione di misura sia finita, allora vale che $A_n \\uparrow A, \\lim_{n \\to \\infty} \\mu(A_n) = \\mu (A)$ , e che\n$\\forall i, i \u003c n, A_i \\subseteq A_n$\nIn modo simile √® definito la continuit√† dal basso, solo che ora sono insiemi uno incluso l‚Äôaltro. Attualmente non so cosa implichi questo fatto, n√© in che modo √® utilizzata questa continuit√†‚Ä¶ Forse per Borel Cantelli, ma poi non so cosa farmene di borel cantelli‚Ä¶\nEvento complementare\nSommatoria finita di eventi disgiunti\nPrincipio di inclusione-esclusione üï≥Ô∏è\n","permalink":"https://flecart.github.io/notes/spazi-di-probabilita/","summary":"La probabilit√† Termini Esito ed esperimenti aleatorio L‚Äôevento √® quello che accade, mentre un esperimento aleatorio qualcosa di cui vogliamo andare a misurare la probabilit√† diciamo. Esperimento aleatorio: esperimento di cui non conosciamo il risultato con certezza. Esito: risultato dell‚Äôesperimento aleatorio\nSpazio campionario ed evento Spazio campionatorio Lo spazio campionatorio √® l\u0026rsquo;insieme di tutti gli stati possibili per una certa cosa da misurare (ossia di un esperimento aleatorio), gli stati sono talvolta anche chiamati sample points oppure outcomes in modo pi√π semplice.","title":"Spazi di probabilita"},{"content":"5.1 Introduzione 5.1.1 Prototipo Vogliamo implementare le operazioni del prototipo dizionario presentato in Strutture di dati elementari, e vogliamo fare solo queste 3 ma molto bene.\nInsert O(1) Delete O(1) Search in O(1) La struttura dati di hash riesce a fare bene queste singole operazioni\nSi vedr√† che l\u0026rsquo;array modificato √® il modo migliore per avere questo hash, solo generalizzando un modo per indicizzarlo che non saranno numeri (indici).\nNoteremo che in media hanno operazioni costanti queste tabelle di hash (nel caso peggiore sempre lineare).\n5.1.2 Esempi di utilizzi soliti Nei compilatori di solito √® molto utilizzato per mantenere in memoria il mapping con le variabili e simili\n5.1.3 Tabelle ad indirizzamento diretto Queste tabelle di hash sono altres√¨ chiamate array, in quanto il numero di chiavi utilizzate √® esattamente uguale al numero di chiavi presente nel nostro universo di chiavi.\nMa per uso pratico questo sarebbe improponibile, in quanto vorremmo avere come chiavi anche stringhe, ma il numero di chiavi esploderebbe in maniera esponenziale e un utilizzo di memoria esponenziale non √® buona\u0026hellip;\nTempo O(1)\nSpazio O(n) con n il numero di chiavi nell\u0026rsquo;universo.\n5.1.4 Tabelle di hash (idea) Idea vorremmo in qualche modo trasformare un elemento nel nostro insieme di chiavi possibili in un elemento appartenente solamente al nostro spazio di chiavi utilizzate.\nCio√® ridurre senza collisione (ovvero per input diversi, ottengo uno stesso output) una chiave nell\u0026rsquo;universo pi√π esteso in un numero utilizzabile.\nSlide\nIn questo modo riduco lo spazio utilizzato solamente a O(K) dove K sono le chiavi effettivamente utilizzate, deciso da caso a caso.\nRiassunto della ricetta dell\u0026rsquo;hashing\nRiassunto:\nFunzione di hash che mi riduca le chiavi dell\u0026rsquo;universo totale all\u0026rsquo;insieme delle chiavi utilizzate Queste devono essere veloci nel calcolo Minimizzare le collisioni Implementazione concreta come pu√≤ essere un vettore di una certa dimensione, che contenga effettivamente il valore dell\u0026rsquo;hash in quella zona. (possibile anche ridimensionamento) 5.2 Le chiavi Le chiavi sono uno strumento principale per comprendere le tabelle di hash. Sono il modo con cui troviamo il nostro valore e sarebbe bene cercare di definirlo in un modo pi√π formale\n5.2.1 Universo delle chiavi e insieme chiavi effettive Definiamo un insieme astratto di tutte le chiavi possibili Definiamo le chiavi effettive il sottoinsieme dell\u0026rsquo;universo delle chiavi, che contiene le chiavi effettivamente utilizzate in un momento Esempio\n5.2.2 Caratteristiche delle chiavi per le funzioni di hashing Le chiavi devono essere distribuite in maniera uniforme (questo √® il caso migliore per evitare il pi√π possibile delle collisioni) Le chiavi devono essere sempre positive o nulle La prima assunzione √® necessaria per l\u0026rsquo;analisi della nostra funzione di hash. Semplifica abbastanza direi.\n5.3 La funzione di hash Cerchiamo qui di definire alcune propriet√† di una buona funzione di hash.\n5.3.1 Distribuzione uniforme semplice Se soddisfa questa propriet√†, ho una buona probabilit√† che io stia distribuendo i valori presenti in modo uniforme nel nostro spazio delle chiavi utilizzate (questo per√≤ non implica l\u0026rsquo;assenza o minimizzazione di collisioni!)\nSlide\n√à difficile dimostrare o calcolare la distribuzione di probabilit√† di una funzione di hash.\nPer√≤ dall\u0026rsquo;altra parte sono sicuro se prendessi una chiave a caso in un intervallo di mia scelta allora ho finito, ho dimostrato che sono distribuite in modo uniforme.\n5.3.2 Costo computazionale costante Deve essere abbastanza semplice da avere un costo costante nel suo calcolo, altrimenti l\u0026rsquo;intera tabella avrebbe il costo di questa funzione, rallentando l\u0026rsquo;intera tabella.\n5.3.3 Esempi di funzioni di hash (4)!!! Rappresentazione della stringa in intero:\nEsempio in slide\nQuesto metodo cresce insieme alla lunghezza della stringa, quindi di solito non √® una buona cosa farla in questo modo.\nVantaggio: posso rappresentare qualunque cosa che si pu√≤ rappresentare sul calcolatore\nSvantaggio: lo spazio cresce in funzione alla grandezza dell\u0026rsquo;input.\nRiduzione in modulo (divisione)\nEsempio in slide\nNella slide sono mostrati anche vantaggi e svantaggi di questo metodo. (principalmente perch√© se il modulo √® preso brutto, ignora gran parte delle informazioni, quindi ottengo un hash che non mi rappresenta totalmente questo numero)\ncostante m descrive la funzione di hash in modo molto importante! (anche l\u0026rsquo;uniformit√†)\nMetodo della moltiplicazione\nVogliamo introdurre maggiore scombinamento dell\u0026rsquo;input, questo si pu√≤ fare moltiplicando il valore di hash per qualcosa.\nEsempio in slide\nCostante C descrive l\u0026rsquo;uniformit√† di distribuzione\nMetodo codifica algebrica\nIn slide\nRiguardo al calcolo di questa codifica esiste il metodo di horner che permette la computazione di questo hash in maniera lineare rispetto all\u0026rsquo;input.\nRegola di Horner\n5.4 Soluzione delle collisioni Slide\nVogliamo trovare un sistema per risolvere le collisioni, che sono molto pi√π frequenti del solito per\nConcatenazione Una volta presente una collisione lo si inserisce nella lista concatenata presente in quella locazione. Questa lista in posizione precisa la chiamo lista di trabocco.\nAnalisi del concatenamento (ottimo e pessimo)\nAnalisi nel caso medio\nUna volta definito questo fattore di carico riesco a dimostrare il costo per la ricerca con successo e senza successo, e si ha che entrambi hanno costo\n$\\Theta(1 + \\alpha)$\nIndirizzamento aperto L\u0026rsquo;inserimento viene messo nel prossimo slot aperto.\nSlide\nL\u0026rsquo;idea principale √® quella dell‚Äôispezione.\nLa funzione di hash √® estesa con un altra funzione di ispezione che visita gli indici di una tabella permutata in modo sempre che sia visitata ogni cella una singola volta.\nPseudocodice per insert, search e delete\nL\u0026rsquo;idea principale √® mettere nella cella in cui si elimina un valore deleted per marcare la cancellazione, cos√¨ search continua a cercare dopo invece di fermarsi, subito (come se avessi perso la testa in un linked list).\nAnalisi:\nPeggiore: devo percorre l\u0026rsquo;intero array per inserire, eliminare o cercare, quindi O(n)\nMedio: dipende dall\u0026rsquo;ispezione, quindi andiamo ora ad analizzare l\u0026rsquo;ispezione.\nAssunzioni\nTeoremi su ricerca ad indirizzamento aperto\nStrategie di ispezione per l‚Äôhashing aperto (3) Ispezione lineare\n√® in una forma\n$h(k,i) = (h'(k) + i) \\mod n$\nContinua a guardare la cella successiva se quella precedente √® occupata.\nProblema del clustering primario (vicino)\nPraticamente √® abbastanza probabile che ci siano un sacco di sequenze vicine essere occupate (mentre altre sono basse). √à un fenomeno che non si vuole avere!\nToglie l\u0026rsquo;uniformit√† di occupazione! cosa che non va bene.\nEsempio di clustering\nCome si vede, le celle di hash 3 sono inframezzate molto! creando quella lunghissima linea di cellette occupate.\nAnalisi del costo medio (differente negli altri due casi esposti qui)\nIspezione quadratica\n$h(k, i) = h'(k) + c_1i + c_2i^2 \\mod n$\nAnche questo metodo di ispezione crea un clustering, che per√≤ √® secondario, ossia creano collezioni di celle lontano rispetto alla cella trovata.\nClustering secondario\nComunque questo tipo di clustering √® migliore rispetto al clustering primario\nDoppio hashing\n$h(k, i) = h_1(k) + ih_2(k) \\mod n$\nSlide\nEsempio\n","permalink":"https://flecart.github.io/notes/tabelle-di-hash/","summary":"5.1 Introduzione 5.1.1 Prototipo Vogliamo implementare le operazioni del prototipo dizionario presentato in Strutture di dati elementari, e vogliamo fare solo queste 3 ma molto bene.\nInsert O(1) Delete O(1) Search in O(1) La struttura dati di hash riesce a fare bene queste singole operazioni\nSi vedr√† che l\u0026rsquo;array modificato √® il modo migliore per avere questo hash, solo generalizzando un modo per indicizzarlo che non saranno numeri (indici).\nNoteremo che in media hanno operazioni costanti queste tabelle di hash (nel caso peggiore sempre lineare).","title":"Tabelle di hash"},{"content":"Introduzione al vettore potenziale Definizione vettore potenziale üü© Possiamo sempre scrivere il campo $\\vec{B}$ come $$ \\vec{B} = \\vec{\\nabla} \\times \\vec{A} $$ Con un campo vettoriale a caso $\\vec{A}$, vedremo che questo campo avr√† qualche utilit√† per fare i calcoli.\nPossiamo notare che soddisfa la propriet√† dell campo solenoidale citato in Magnetismo, infatti\n$$ \\vec{\\nabla} \\cdot \\vec{B} = \\vec{\\nabla} \\cdot (\\vec{\\nabla} \\times \\vec{A}) = 0 $$ Perch√© sappiamo che la divergenza del rotore (questo operatore dico) √® sempre nullo per ragioni di Cauchy, se ne parla in Divergenza e Circuitazione.\nUnicit√† del campo üü© Proviamo ad analizzarlo matematicamente, ci stiamo chiedendo, √® unica?\nLo √® a meno di un gradiente di una funzione scalare\nDefiniamo $$ \\vec{A}' = \\vec{A} + \\vec{\\nabla}F $$ Abbiamo:\n$$ \\vec{\\nabla} \\times \\vec{A}' = \\vec{\\nabla} \\times \\vec{A} + \\vec{\\nabla} \\times (\\vec{\\nabla}F) = \\vec{\\nabla} \\times \\vec{A} + 0 $$ Dove il gradiente di $F$, si ricorda √® vettoriale, ed √® utilizzato per rappresentare un vettore qualunque, basta che esista $F$ che lo generi, che lo abbiamo in ipotesi.\nSimile con il potenziale, che √® una funzione definita a meno di una costante perch√© possiamo mettere un punto (che scegliamo noi) in un certo punto, o potenziale del sistema che sono contati in quella costante, ne parliamo in Campo elettrico. (in questo capo la nostra costante √® un vettore in un certo senso :P)\nScelta del campo A üü© Per la divergenza abbiamo invece:\n$$ \\vec{\\nabla} \\cdot \\vec{A}' = \\vec{\\nabla} \\cdot(\\vec{A} + \\vec{\\nabla}F) = \\vec{\\nabla} \\cdot \\vec{A} + \\nabla^{2}F $$ Lo scalare $F$ lo posso scegliere io, e mi pu√≤ semplificare molti conti (si dovrebbe dimostrare che questo $F$ che me lo annulli esista sempre, probabilmente √® vero). Allora possiamo scegliere come il campo $A$ vettore potenziale tale per qui valnga $$ \\vec{\\nabla} \\cdot \\vec{A} = 0 $$ Per qualche motivo questa cosa vale solo nel caso stazionario (con $\\vec{J}$ stabile).\nComodit√† del vettore potenziale Ampere Max-well con vettore potenziale üü© Abbiamo quindi\n$$ \\vec{\\nabla} \\times (\\vec{\\nabla} \\times \\vec{A}) = \\mu_{0}\\vec{J} $$ Questa espressione si pu√≤ semplificare tenendo conto che $a\\times b\\times c = b (a \\cdot c) - (a\\cdot b) c$ Da cui abbiamo:\n$$ \\vec{\\nabla} \\cdot (\\vec{\\nabla} \\cdot \\vec{A}) - (\\vec{\\nabla} \\cdot \\vec{\\nabla})\\vec{A} = \\mu_{0}\\vec{J} $$ Utilizzando l\u0026rsquo;approssimazione sopra presente abbiamo ancora un laplaciano per rappresentare questa legge, in modo simile a quanto presente al differenziale potenziale per la quantit√† di carica. $$ \\nabla^{2}\\vec{A} = -\\mu_{0}\\vec{J} $$ Possiamo notare che $A$ ha la stessa direzione della corrente! seguendo la soluzione dell\u0026rsquo;equazione di Poisson per campo elettrico abbiamo che\n$$ A(x, y, z) = \\frac{\\mu_{0}}{4\\pi} \\int _{\\Sigma} \\frac{J(x', y', z')\\, dx'dy'dz'}{\\sqrt{ (x - x')^{2} + (y - y')^{2} + (z - z') ^{2} }} $$ Se applichiamo questo su un filo allora diventa in un certo senso: $$ \\vec{A} = \\frac{\\mu_{0}}{4\\pi} \\int \\frac{\\vec{J} d\\Sigma \\, dl}{r} = \\frac{\\mu_{0}}{4\\pi} \\int \\frac{i \\, dl}{r} $$ Quindi quantit√† di corrente lungo un certo tratto di filo!\nFaraday con vettore potenziale üü©\u0026ndash; $$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} = \\frac{\\delta (\\vec{\\nabla} \\times \\vec{A})}{\\delta t} $$ E abbiamo:\n$$ \\vec{\\nabla} \\times \\left( \\vec{E} + \\frac{\\delta \\vec{A}}{\\delta t} \\right) = 0 $$ Quindi abbiamo che vale:\n$$ \\vec{E} = -\\frac{\\delta A}{\\delta t} \\implies \\vec{\\nabla}V = \\frac{\\delta A}{\\delta t} $$ Circuitazione del vettore potenziale üü© Consideriamo il flusso del vettore su una superficie\n$$ \\int_{\\Sigma} \\vec{B} \\hat{u}_{n} \\, ds = \\int_{\\Sigma} \\vec{\\nabla} \\times \\vec{A} \\hat{u}_{n} \\, ds = \\int_{\\Gamma(\\Sigma)} \\vec{A} \\cdot\\, d\\vec{l} $$ Dove l\u0026rsquo;ultima vale per Stokes in Divergenza e Circuitazione, quindi possiamo calcolare il flusso su un campo andando a considerare la circuitazione del potenziale vettore!\nEsempi di applicazione Studio del vettore potenziale in un solenoide üü© Possiamo poi scoprire che $$ \\vec{A} = B \\frac{r}{2} \\hat{u}_{c} $$ Quando $r$ √® minore del raggio del solenoide, se √® maggiore abbiamo $$ \\vec{A} = B \\frac{R^{2}}{2r} \\hat{u} $$ ","permalink":"https://flecart.github.io/notes/vettore-potenziale/","summary":"Introduzione al vettore potenziale Definizione vettore potenziale üü© Possiamo sempre scrivere il campo $\\vec{B}$ come $$ \\vec{B} = \\vec{\\nabla} \\times \\vec{A} $$ Con un campo vettoriale a caso $\\vec{A}$, vedremo che questo campo avr√† qualche utilit√† per fare i calcoli.\nPossiamo notare che soddisfa la propriet√† dell campo solenoidale citato in Magnetismo, infatti\n$$ \\vec{\\nabla} \\cdot \\vec{B} = \\vec{\\nabla} \\cdot (\\vec{\\nabla} \\times \\vec{A}) = 0 $$ Perch√© sappiamo che la divergenza del rotore (questo operatore dico) √® sempre nullo per ragioni di Cauchy, se ne parla in Divergenza e Circuitazione.","title":"Vettore potenziale"},{"content":"Intractable problems are solvable in principle, but in reality they require so much time or space that there no physical computers that can solve them in reasonable time. We would like to define a clear hierarchy of these set of problems.\nSpace Hierarchies Def: Space constructible We say that a function $f: \\mathbb{N} \\to \\mathbb{N}$ such that $f(n) \\geq O(\\log n)$ is space constructible if there exists a function from $1^{n} \\to \\langle f(n) \\rangle$ is $O(f(n))$ space complexity.\nIntuitively, it is just a function that is computable in a specifically limited space. But at the moment I don\u0026rsquo;t know why is this important.\nSpace hierarchy theorem For any space constructible function $f: \\mathbb{N} \\to \\mathbb{N}$ there exists a language $A$ decidable in $O(f(n))$ but not in $o(f(n))$ space.\nProof of the theorem The proof is quite convoluted, and has some technical details that are quite ad-hoc to make things work. I personally think this is quite useless, and the hypothesis is quite intuitive with standard understanding. Nonetheless, we should need to understand the argument.\nDefine this algorithm: D = ‚ÄúOn input $w$:\nLet n be the length of $w$. Compute $f(n)$ using space constructibility and mark off this much tape. If later stages ever attempt to use more, reject . If w is not of the form $\\langle M \\rangle 10 ^{*}$ for some TM M , reject . Simulate M on w while counting the number of steps used in the simulation. If the count ever exceeds $2^{f(n)}$, reject . If M accepts, reject . If M rejects, accept .‚Äù Then the language defined as $\\left\\{ \\omega : D \\text{ accepts } \\omega \\right\\}$ is the language we want in the statement.\nMain consequence of Hierarchy theorem For all $k, j$ such that $k \u003c j$ we have that\n$$ SPACE(n^{k}) \\subset SPACE(n^{j}) $$ NOTE: contained, and not equal!\nMore general way to say it: $f(x) = o(g(x))$ implies $$ SPACE(f(x)) \\subset SPACE(g(x)) $$ Other: PSPACE is in EXPSPACE\nWhy is this concept useful? This allows us to categorize problems is different and not equal complexity classes. In my own opinion this is probably caused by human need to make order in this meaningless caos. I don\u0026rsquo;t know effective practical applications of this theory. But we need to be grounded on real problems, those are the ones driving innovation.\nTime Hierarchies Def: Time constructible This is the same as #Def Space constructible.\nWe say that a function $f: \\mathbb{N} \\to \\mathbb{N}$ such that $f(n) \\geq O(n\\log n)$ is time constructible if there exists a function from $1^{n} \\to \\langle f(n) \\rangle$ is $O(f(n))$ Time complexity.\nTime hierarchy theorem This theorem is analogous to the space complexity counter-part, with a small formality of simulating the given Turing machine.\nFor any time constructible function $f: \\mathbb{N} \\to \\mathbb{N}$ there exists a language $A$ decidable in $O(f(n))$ but not in $o\\left( \\frac{f(n)}{\\log f(n)} \\right)$ time.\n","permalink":"https://flecart.github.io/notes/complexity-hierarchies/","summary":"Intractable problems are solvable in principle, but in reality they require so much time or space that there no physical computers that can solve them in reasonable time. We would like to define a clear hierarchy of these set of problems.\nSpace Hierarchies Def: Space constructible We say that a function $f: \\mathbb{N} \\to \\mathbb{N}$ such that $f(n) \\geq O(\\log n)$ is space constructible if there exists a function from $1^{n} \\to \\langle f(n) \\rangle$ is $O(f(n))$ space complexity.","title":"Complexity Hierarchies"},{"content":"1.1 Il principio di astrazione/implementazione Astrazione per macchine livello n con linguaggi n.\n1.2 I livelli principali di astrazione Livelli in breve\n1.2.1 Livello 0 Qua √® utile indagare la\nPorte Logiche in cui si indagano in un modo molto alto il funzionamento di porte\n√à il livello fisico delle porte logiche e dell\u0026rsquo;ingegneria elettrica.\n1.2.2 Livello 1 Link utili potrebbero essere la CPU e storia degli elaboratori\nCircuiti Sequenziali Ossia la Memoria\nla microarchitettura governa il flusso dei dati fra i vari componenti del livello logico digitale\nQuesto √® il livello della micro-architettura, ossia come i componenti logici interagiscono fra di loro.\n1.2.3 Livello 2 Livello ISA\nLivello ISA, Instruction Set Architecture, che sono le sequenze di 0 e 1 che definiscono una istruzione\nFino a qua (+ anche parte del sistema operativo) √® il lavoro del system programmers che si devono occupare di cose di questo livello di astrazione, in seguito i linguaggi sono spesso compilati e non interpretati (application programmers).\n1.2.4 Livello 3-4 √à il sistema operativo, il programma che organizza le risorse per il problema, la memoria virtuale etc.\nLinguaggio assembly.\nSi parla di livello ibrido perch√© spesso questo livello utilizza ancora le istruzioni ISA (Quindi assembly tradotto), con semmai in aggiunta alcuni programmi per l\u0026rsquo;esecuzione concorrenziale, gestione della memoria e simili.\nEcco che questi due livelli non si distinguono molto l\u0026rsquo;uno dall\u0026rsquo;altro, Il SO √® fatto probabilmente in assembly o ISA (ma nessuno lo fa direttamente in codice macchian) in pi√π aggiunge servizi tipici del sistema operativo.\n1.2.5 Livello 5+ Sono i linguaggi utili alla risoluzione dei problemi, come Python, c++, Java, Js, Ts\nLivelli e macchine virtuali Traduzione e interpretazione Spesso linguaggi a livelli superiori non sono direttamente interpretabili da un livello, basso, per questo motivo devono essere tradotte a un linguaggio comprensibile al livello inferiore.\nMacchina virtuale Spasso invece di continuare a pensare come un continuum di traduzioni fra i livelli √® opportuno pensare a un livello come una macchian virtuale a s√© stante. Ossia ogni livello ha una macchina che opera con un metodo a s√© stante, diverso da tutti gli altri livelli.\nEsempio di questa struttura\ngni livello ha una macchina che opera con un metodo a s√© stante**, diverso da tutti gli altri livelli.\nEsempio di questa struttura\n","permalink":"https://flecart.github.io/notes/introduzione-ad-architettura/","summary":"1.1 Il principio di astrazione/implementazione Astrazione per macchine livello n con linguaggi n.\n1.2 I livelli principali di astrazione Livelli in breve\n1.2.1 Livello 0 Qua √® utile indagare la\nPorte Logiche in cui si indagano in un modo molto alto il funzionamento di porte\n√à il livello fisico delle porte logiche e dell\u0026rsquo;ingegneria elettrica.\n1.2.2 Livello 1 Link utili potrebbero essere la CPU e storia degli elaboratori\nCircuiti Sequenziali Ossia la Memoria","title":"Introduzione ad architettura"},{"content":"Gran parte di quanto scrivo ora √® tratto da (Li \u0026amp; Vit√°nyi 2019). Chaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni \u0026lsquo;60!\nSolomonoff lo ha trovato sul problema dell\u0026rsquo;induzione all\u0026rsquo;et√† di 38 anni, Kolmogorov invece era gi√† tardi, ha gi√† trovato gli assiomi della probabilit√† e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilit√†, nel 68 all\u0026rsquo;et√† di 19 anni. In AI teorico questo sembra un tema molto importante.\nCi sono degli esempi carini nella compressione di numeri naturali e stringhe binarie in Introduction to Algorithmic Information and Complexity.\nIntuizione Kolmogorov Per quanto ho capito io sulle motivazioni che sono state base alla creazione di questo concetto √® il concetto che: per descrivere cose complesse c\u0026rsquo;√® necessit√† di pi√π parole. Questa idea molto intuitiva la possiamo tradurre da un punto informatico come il programma pi√π corto per produrre un certo output.\nUn esempio classico √® una comparazione fra una stringa 01010101010101 contro una altra del tipo 11101111111100101011110000010101. Intuitivamente potremmo dire che la prima stringa sia molto pi√π semplice da descrivere rispetto alla seconda stringa, abbiamo per√≤ bisogno di un modo formale per descrivere questo concetto.\nFormalizzazione Definizione Kolmogorov Definiamo la complessit√† di Kolmogorov $K_{L}(\\omega )$ per un certo linguaggio di programmazione $L$ come la minima lunghezza del programma tale per cui se eseguita sulla macchina astratta di $L$ dia come output $\\omega$.\nQuesta definizione si pu√≤ riscrivere come $$ C(x) = \\min_{p}\\left\\{ length(p) : U(p) = x \\right\\} $$ Ossia il programma pi√π corto che se eseguito su una macchina di Turing completa ho $x$.\nNOTA: questa definizione seppur meno informale di prima, non √® ancora quella formalmente accettata, per√≤ fa il suo per trasmettere l\u0026rsquo;idea, vedere il libro [^2] per definizione matematicamente corretta (e anche molto pi√π astrusa)\nComplessit√† condizionale\nla complessit√† di Kolmogorov condizionale $K_{L}(\\omega | x)$ √® la lunghezza minima di un programma che prende in input $x$ e produce in output $\\omega$. (si legge proprio come se fosse un qualcosa di condizionato)\nLEMMA Ora diventa chiaro che un programma che stampa una qualunque stringa, sia sufficiente per dare in output, per questo motivo vale che: $$ K(x) \\le \\lvert x \\rvert + c \\tag{1} $$ Dove $c$ √® una costante per codificare le istruzioni per stampare. Pi√π intuitivamente un programma di questo genere pu√≤ stampare il carattere (dimostreremo in seguito, in #Teorema dell\u0026rsquo;invarianza che idea simile vale per ogni linguaggio)\nQuesto lemma giustifica anche la seguente definizione\nStringhe incomprimibili una stringa $\\omega$ si dice incomprimibile nel momento in cui $K(\\omega) = \\lvert \\omega \\rvert + O(1)$\nChe insieme all\u0026rsquo;upper bound di sopra, si avr√† che √® il massimo di complessit√† che pu√≤ avere.\nKolmogorov condizionato Condizionato $K(A|B)$ significa che diamo alla nostra macchina di turing in input anche $B$ per codificare $A$. Puoi vedere subito che la complessit√† di $K(A|A)$ √® $0$ perch√© la macchina di turing pu√≤ non fare nulla $\\varepsilon$ √® il programma diciamo, e avere subito un risultato. Intuitivamente avere qualcosa in pi√π non fa altro che ridurre il codice necessario, quindi possiamo dire che $K(A|B) \\leq K(A)$. E qui si pu√≤ creare anche una nozione di indipendenza.\nChain Rule Afferma che per qualunque oggetto vale che $$ K(A|B) \\geq K(A, B) - K(B) $$ Ossia la codifica di entrambi, sia $A$ che $B$ √® necessariamente minore di codificare prima $B$ e poi usare questa per codificare $A$. Si pu√≤ dimostrare ma intuitivamente questa legge sembra parlare in modo chiaro.\nQuesto vale se assumiamo che tutte le parole godano della Prefix Property Bottom-up Parser LR(1)Algorithmic Probability. Se non vale la regola diventa $$ C(s_{1}) \\leq C(s_{2}) + C(s_{1} | s_{2}) + O(\\log(C(s_{2}))) $$ Il motivo di questo $O$ grande strano √® che\n$\\log(C(s_{2}))$ is the maximal length of the information needed to separate the program that computes $s_{2}$¬†from what comes next (as we cannot guarantee that this program is uniquely decodable, contrary to the prefix case).\nMa non lo ho capito ancora bene.\nIncomputabilit√† di Kolmogorov Dimostrazione: Supponiamo che sia computabile, allora abbiamo un programma $P$ che calcola il programma minimo. Ora possiamo usare questo programma per trovare una stringa la cui complessit√† di Kolmogorov sia pi√π lunga di un certo $n$. Questo si pu√≤ fare provando ad aggiungere roba (probabilmente qui mi serve un lemma che dice che √® crescente stretto e non lasco). Ma la complessit√† di questa nuova stringa trovata deve essere uguale alla complessit√† di $n$, che gli d√≤ in input! (pi√π costante per la ricerca che ignoro per Kolmogorov). Questo significa che $K(n) \u003e n$ che √® assurdo perch√© $K(n) \\approx \\log_{2}(n)$ che √® strettamente minore di $n$.\nPossiamo per√≤ approssimare il valore, e per molte cose questo basta!\nKolmogorov complexity is an ideal notion that can be approximated, but that is not computable.\nUn pseudocodice di esempio per computare una cosa pi√π complessa (anche se non ho la dimostrazione che fa quello che deve fare, perch√© in teoria credo pu√≤ continuare in modo arbitrariamente lungo, solo che la probabilit√† che non finisca tende a 0)\ndef MoreComplex(n): i =1 while True: for m in range(2**i): s = bin(m)[2:]¬†if cc(s) \u0026gt; n:¬†return s i += 1 Teorema dell\u0026rsquo;invarianza Questo √® un teorema fondamentale (e anche di base) per quanto riguarda la definizione della teoria inerente a questa complessit√†. Ci permette di affermare che il concetto di complessit√† √® indipendente dal linguaggio di programmazione utilizzato, e ci dar√† presto anche alcuni risultati interessanti sulla computabilit√† di questa funzione (in modo diverso rispetto alle classiche dimostrazioni che si possono trovare in teoria della computabilit√†). Quindi questo teorema √® fondamentale per stabilire l\u0026rsquo;oggettivit√† della propriet√†. Cos√¨ possiamo dire che √® una propriet√† dell\u0026rsquo;oggetto, non di come lo stai valutando. Quindi non dipende dalla capacit√†/architettura di chi sta valutando il linguaggio.\nSiano $L$ e $L^{'}$ due linguaggi Turing completi, allora per ogni stringa $\\omega$ si ha che $$K_{L}(\\omega) = K_{L^{'}}(\\omega) + O(1)\\tag{2}$$ Dimostrazione: Essendo $L$ e $L^{'}$ dei linguaggi Turing completi, allora posso scrivere un programma in $L^{'}$ che esegua la macchina astratta di $L$ e quindi mantenga tutta la semantica del linguaggio $L$ (vedere Macchine Astratte per la definizione di interprete).\nAllora si avr√† che $$ K_{L^{'}}(w) = K_{L}(\\omega) + |I| \\tag{2.1} $$ ossia il costo per esprimere la complessit√† della string $\\omega$ in $L^{'}$ √® equivalente al costo per esprimere il programma $p$ in $L$, ed eseguirlo con un interprete (che avr√† una lunghezza finita, e costante una volta fissato i due linguaggi). L\u0026rsquo;interprete esiste perch√© stiamo usando macchine di Turing universali per la descrizione della lunghezza.\nNOTE: Grazie a questa propriet√† da ora in poi potremo parlare di $K(\\omega)$ indipendentemente da linguaggio su cui √® stato scritto, dato che tanto distano di una costante uno dall\u0026rsquo;altro.\nNOTE2: √à una cosa molto curiosa il fatto che sia dipendente dall\u0026rsquo;osservatore, anche se abbiamo una differenza, perch√© cose importanti per qualcuno, sono codificate in modo differente da ognuno. Questo √® un pensiero molto deep, e l\u0026rsquo;esempio della versione della macchina √® chiaro.\nEsistenza di stringhe complesse Un risultato importante che sar√† utile alla dimostrazione della non computabilit√† della funzione di complessit√† di Kolmogorov √® la seguente:\u0026gt; $$ \\forall n \\in \\mathbb{N}, \\exists \\omega : K(w) \\geq n $$ che √® un risultato che non sembra avere molto senso perch√© ci sta dicendo che esistono delle stringhe di complessit√† infinita (forse queste stringhe sono quelle non computabili, perch√© il programma che lo descrive dovrebbe avere lunghezza infinita).\nDimostrazione: La dimostrazione di questo teorema non √® altro che una applicazione del pigeonhole principle. In un certo senso salta fuori dalla relazione fra il finito e l\u0026rsquo;infinito, come quelle cose assurde che $2n$ √® in bigezione con i numeri naturali. Siamo nel mondo di Turing, quindi i programmi saranno anch\u0026rsquo;esse delle stringhe binarie. Consideriamo tutti i programmi di lunghezza zero. Questo produrr√† la stringa vuota, ossia la stringa di complessit√† zero. Supponiamo ora tutti i programmi di lunghezza uno. Al massimo potremo avere due stringhe con questa complessit√†. E cos√¨ via. Intuitivamente: dato che il numero delle stringhe $\\omega$ che possono esistere sono infinite, anche i la lunghezza dei programmi utilizzati per generare queste stringhe sono infinite, perch√© banalmente un programma di lunghezza $n$ pu√≤ generare al massimo $2^n$ stringhe diverse, un numero finito, anche se enormemente ampio.\nNon calcolabilit√† della funzione di Kolmogorov La funzione di Kolmogorov non √® calcolabile su un macchina di Turing\nDimostrazione: Supponiamo che esista una macchina di Turing $M$ che prenda in input una stringa $\\omega$ e ritorni $K(\\omega)$. Utilizzeremo il teorema #Esistenza di stringhe complesse\nAllora utilizziamo questa macchina di Turing $M$ per costruirne una altra $M^{'}$ che si comporti in questo modo:\ninput n for each string w in alphabet: do if K(w) \u0026gt;= n: return w done endfor In pratica vado a scorrere tutte le parole nell\u0026rsquo;alfabeto infinito, so che prima o poi trover√≤ una stringa tale per cui $K(w) \\geq n$ perch√© ne abbiamo dimostrato l\u0026rsquo;esistenza precedentemente. Questa macchina allora descriver√† la stringa $\\omega$ che viene in output, dato l\u0026rsquo;input $n$.\nMa allora abbiamo che $$ n \\leq K(\\omega) \\leq \\lvert \\langle M^{'}, n \\rangle \\rvert + O(1) = O(1) + \\lvert n \\rvert = O(1) + O(\\log(n)) = O(\\log(n)) $$ Ed √® assurdo perch√© afferma che $O(n) \\leq O(\\log(n))$ che sar√† vero per $n$ abbastanza alto.\nUpper bound con entropia Kolmogorov si pu√≤ vedere come una cosa pi√π generale dell\u0026rsquo;entropia di Shannon Entropy, si pu√≤ vedere come una approssimazione di essa perch√© basta prendere $L \\approx \\log_{2}\\left( \\frac{1}{p} \\right)$ e si ha l\u0026rsquo;entropia Shannoniana. La cosa carina √® che Kolmogorov ha senso anche in assenza di frequenze e probabilit√†.\nCose che non ho capito Per qualche motivo la complessit√† di un oggetto scende quando l\u0026rsquo;entropia √® massima (ah, quando sono tutti uguali le probabilit√†, la complessit√† scende)\nParte vecchia dal libro di complexity Questo √® il teorema fondamentale di questo campo, che ricordiamo prova a cercare di creare una teoria sulle descrizioni di minima lunghezza per qualcosa, questo dovrebbe essere in grado di risolvere il problema del limite della probabilit√†, e cose di teoria dell\u0026rsquo;informazione che non ho ancora ben compreso.\nComunque si √® notato che si pu√≤ definire una classe di equivalenza, e fra queste esiste una classe speciale che √® quello di descrizione minima. Partiamo per√≤ dalla definizione di di complessit√† diciamo: $$ C_{f}(x) = min\\{l(p) : f(p) = n(x)\\} $$ $f$ √® una macchina di turing.\nUna volta definito questo e creato un insieme fisso di macchine o funzioni si pu√≤ estendere questo modello in classi di equivalenza, perch√© possiamo utilizzare $\\langle n, p \\rangle$ on $n$ l\u0026rsquo;index alla macchina corretta e $p$ il nostro programma (anche se non ho capito perch√© si assume che il programma sia comprensibile a qualunque macchina, e non ho capito perch√© la funzione la si pu√≤ intendere come se fosse una macchina, questa √® una parte di teorica che mi dovrei recuperare).\nComunque fatto questo, si pu√≤ mostrare come data una sequenza contabile di funzioni $\\phi_{1}, \\phi_{2}, \\dots, \\phi_{n}$ allora posso andare a definirmi $\\phi_{n}(p) = \\phi_{0}(\\langle n, p \\rangle)$ anche se non ho capito cosa voglio dire qui, con $\\phi_{0}$ la funzione computata da una macchina di Turing universale $U$ . Indicheremo $$ C_{\\phi_{0}}(x) = C(x) $$ per ogni programma $x$.\nReferences [1] Li \u0026amp; Vit√°nyi ‚ÄúAn Introduction to Kolmogorov Complexity and Its Applications‚Äù Springer International Publishing 2019\n","permalink":"https://flecart.github.io/notes/kolmogorov-complexity/","summary":"Gran parte di quanto scrivo ora √® tratto da (Li \u0026amp; Vit√°nyi 2019). Chaitin, Kolmogorov e Solomonoff hanno elaborato il tema in modo indipendente e allo stesso tempo verso gli anni \u0026lsquo;60!\nSolomonoff lo ha trovato sul problema dell\u0026rsquo;induzione all\u0026rsquo;et√† di 38 anni, Kolmogorov invece era gi√† tardi, ha gi√† trovato gli assiomi della probabilit√† e poi nel 65 cerca randomness. Mentre Chaiten Information = Computation e non probabilit√†, nel 68 all\u0026rsquo;et√† di 19 anni.","title":"Kolmogorov complexity"},{"content":"4.1 Caratteristiche della Memoria La gerarchia della memoria, pi√π si va gi√π pi√π spazio si ha, pi√π √® lento il caricamento delle informazioni\n4.1.1 Catalogazione della memoria Le tipologie di memoria sono presenti a fianco.\nIn generale pi√π la memoria √® veloce da riprendere, pi√π √® costosa da memorizzare (c\u0026rsquo;√® poco spazio)\n4.1.2 Byte e Word Il libro a pagina 74 parte con la discussione del perch√© si √® preferito evitare la BCD (Binary coded decimal, in cui i numeri da 0 a 9 erano codificato da 4 bit), per questioni di efficienza.\nLa memoria √®, in modo spiccio, una serie di cellette numerate, ognuno pu√≤ contenere qualche informazione.\nNacque nel 1960 circa con IBM 360 nacque la definizione di byte.\nWord √® una seguenza di byte ‚Üí unit√† di dato che non stanno solamente in un singolo indirizzo.\n4.1.3 Endianess Questi termini descrivono l\u0026rsquo;organizzazione dei bytes all\u0026rsquo;interno della memoria. A volte √® molto conveniente netere i bytes al contrario per facilit√† di accesso.\n4.1.4 RAM Abbiamo presentato il funzionamento hardware della RAM nel momento in cui abbiamo descritto il funzionamento di Circuiti Sequenziali come LATCH SR, D, DFF.\n4.1.5 Paginazione - Caricamento Una altra funzione della gerarchia di memoria √® utilizzare la paginazione, ossia il caricamento di risorse utili nella ram veloce e scaricamento nella memoria secondaria di ci√≤ che non viene utilizzato.\n√à gestito dal sistema operativo.\nSono dei blocchi di data nella memoria principale che vengono caricati nella memoria principale nel momento del bisogno.\nQuindi ci sono proprio degli algoritmi per caricare e scaricare le pagine di memoria dalla memoria principale, gestiti dal sistema operativo.\n4.2 Memoria Cache La cache √® una zona di memoria condivisa alle CPU, di facile accesso (meno facile in confronto ai registri, ma comunque veloce) ma senza molto spazio.\n√à sempre consultata ** prima di andare nella memoria.\nSe va a cercare un word in memoria, questa viene messa nella cache dopo essere ritrovata.\nUna caratteristica principale della cache √® che non √® necessario al programmatore sapere che esiste o meno, √® solo qualcosa che si interpone in modo TRASPARENTE che pu√≤ rispondere subito nel caso possieda una certa informazione.\nMa l‚Äôidea di tenere una memoria pi√π veloce intermedia per dati pi√π utili del prossimo futuro √® una idea che si utilizza anche in altri ambiti (come Disco, accesso messaggi, e simili) e migliora molto la velocit√†.\n4.2.1 Livelli memoria Cache 4.2.2 Principio di localit√† spaziale e temporale Programmi eseguiti vicini nel tempo sono messi in luoghi in memoria vicini\nSi spera di guadagnare tempo in questo modo, cos√¨ √® pi√π facile ritrovare delle informazioni utili quando si eseguono dei comandi vicini nella cache.\nChiaramente se un programma continua a saltare da un indirizzo della memoria a un altro questo principio non ha pi√π senso e la cache servirebbe a poco.\nLocalit√† spaziale e temporale\nUn programma naturale di solito utilizza la cache (un programma potrebbe essere progettato in modo che usi 0 cache, ma sarebbe uno spreco di risorse).\nTemporale: la stessa cella viene acceduta a breve distanza di tempo (come Stack)\nSpaziale: celle vicine possono essere prese a breve tempo di distanza. (per esempio accedere ad un array, accesso sequenziale che ha un nome suo di localit√† sequenziale)\n√à molto facile che la cache debba accedere alla stessa risorsa in termini brevi di tempo\nLocalit√† secondo WIKI\n4.2.3 Efficienza della cache La velocit√† d\u0026rsquo;accesso alla cache √® di granlunga minore rispetto a quello della memoria, di solito il tempo speso per memorizzare qualcosa qui viene sempre recuperato.\nUsiamo un p√≤ di matematica ora per descrivere questa cosa un pochino pi√π rigorosamente:\n$c \u003c\u003c m$ con $c$ il tempo per accedere alla cache e $m$ il tempo per accedere alla memoria.\nAllora si ha che il tempo medio per accedere alle informazioni, tenendo $h$ come hit rate √® di:\n$$ hc + (1 - h)(c + m) = c + (1-h)m $$ 4.2.4 Cache ad accesso diretto Linee di cache, vanno k mod n, ogni linea di cache di dimensione m. ok? √à una cosa temporale, a seconda di cosa ci sia ora.\nData: √® effettivamente il data che sto prendendo n √® il numero di linee di cache (che decide quanto grande sia la cache). Tag serve per sapere quale blocco sto utilizzando (quindi se 0-31 oppure 65536 e simili) Valid se √® un blocco valido, se √® 0 vuol dire che non √® roba interessante.\nEsempio di query cache Teniamo 5 bit per l\u0026rsquo;indicizzazione dentro i 32 bit di data. 11 bit per sapere quale linea di cache utilizzare 16 bit per confrontare con il tag e vedere se √® giusto oppure no. Cos√¨ riesco a trovare in modo univoco la linea di cache che mi serve. 4.2.5 Cache hit and miss Si dice che si ha un cache hit oppure cache miss a seconda del caso in cui la cache √® riuscita a dare la richiesta oppure meno.\nMiss\nRiportare la cache in memoria centrale in quanto potrebbe essere modificata ora, √® un aggiornamento della roba nella memoria centrale Caricare la nuova memoria. Se per√≤ si tenta di accedere alla cache allo stesso momento, si possono esserci data race e quindi bisognerebbe bloccare l\u0026rsquo;accesso all\u0026rsquo;inizio\nSe vuoi approfondire su algoritmi per la gestione della cache:\nhttps://en.wikipedia.org/wiki/Cache-oblivious_algorithm\ne altro ancora\n4.3 Memoria secondaria Storicamente le velocit√† delle CPU si sono sviluppate molto pi√π velocemente rispetto alle memorie secondarie.\n4.3.1 Hard Disk (4) I dischi magnetici oppure Hard disk sono generalmente in tre parti:\nSettore √® il nome di una traccia specifica di memoria di dimensione fissata. Traccia √® una sequenza di bit circolari Testina che magnetizza e modifica il contenuto nel disco. Controllore Disco . Ogni settore comincia con un preamble che dovrebbe aiutare a diminuire gli errori di lettura.\nPer dare un senso, circa in un centimetro di Hard Disk ci possono stare parecchi giga di informazioni.\nI dati posso essere messi in due modi:\nStessa densit√† per angolo (pi√π rientri pi√π hai i dati in modo compatto) Diverso numero di settori (la parte esterna del disco contiene pi√π settori) Processo di recupero di dati:\nLa CPU dice di andare a recuperare un blocco in un certo indirizzo di memoria La testina gira e va fisicamente a recuperare la zona di memoria 4.3.2 SSD SSD or Solid State drive non hanno nessuna parte che si muove quindi sono meno soliti a rompersi meccanicamente, tutto elettronico.\nStoricamente sono state utilizzate per portatili per resistenza ad urti, ma poi si possono utilizzare anche per altro data la loro velocit√† (per minore spazio).\n4.4 RAID https://en.wikipedia.org/wiki/Standard_RAID_levels\nRedundant array of indipendend disks (originariamente inexpensive, per contrapporla a Single Large Expensive Disk ossia SLED, ma poi hanno scoperto che anche RAID costa, LMAO.\n4.4.1 Vantaggi generali Redundant Array of Inexpensive Disks.\nRidurre il gap di efficienza fra CPU e HD Utilizzo di pi√π dischi in contemporanea + lettura di dati Facilit√† di correttezza di dati e verifica errori 4.4.2 6 Tipologie di RAID Diminuire di 1 l\u0026rsquo;intera lista, perch√© RAID va da 0\nNon redundant data striping (C\u0026rsquo;√® solo una copia di dati nel disco) Velocit√†, no info retrieval\nRedundant, c\u0026rsquo;√® una copia esatta dei RAID e sono entrambi striped\nC\u0026rsquo;√® bisogno di una grande sincronizzazione in quanto i dati sono divisi fra i dischi a livello bit.\nPossono avere solamente una richiesta, a differenza di RAID 1 che pu√≤ gestirne tanti Unico raid mai utilizzato, per√≤ introduce Hamming per la corrrezione!\nUguale al terzo ma c\u0026rsquo;√® un bit di parit√† per controllo errori invece che codice hamming, spesso bit di parit√† √® bastato.\nSolo una richiesta https//en.wikipedia.org/wiki/Parity_bit¬†disk with each color representing the group of blocks in the respective¬†parity¬†block (a stripe)](Memoria%20f3746a630031414b935cca93dd06f1ad/Untitled%2010.png)\nA RAID¬†4 setup with dedicated¬†parity¬†disk with each color representing the group of blocks in the respective¬†parity¬†block (a stripe)\nRitornano gli stripe, ma stavolta un intero disco √® utilizzato per verificare che la scrittura √® stata corretta,\n√® brutto se vogliamo scriverci Anche questo utilizzato poco Diagram of a RAID¬†3 setup of six-byte blocks and two¬†parity¬†bytes, shown are two blocks of data in different colors.\nRisolve una lentezza del punto 5 distribuendo le sezioni di controllo sui vari dischi.\nhttps//en.wikipedia.org/wiki/Parity_bit¬†block (a stripe). This diagram shows¬†Left Asynchronous¬†layout](Memoria%20f3746a630031414b935cca93dd06f1ad/Untitled%2012.png)\nRAID¬†5 layout with each color representing the group of data blocks and associated¬†parity¬†block (a stripe). This diagram shows¬†Left Asynchronous¬†layout\nNon so quale sia la differenza con il 5, per saperlo vai a leggere i raid su Devices OS. In pratica fault tolerance maggiore.\n4.5 Errori Controllare come sono causati gli errori E tipologie di errori\nQuesta parte √® scritta molto meglio in Rappresentazione delle informazioni\ndove si parla di hamming distance e correzione errori.\n4.5.1 Cause degli errori Gli errori possono essere causati da:\nRaggi cosmici provenienti dal sole Vibrazioni fisiche Esistono codici per correggere gli errori, puoi trovare pi√π informazioni qui: Rappresentazione delle informazioni\n4.6 Altri dispositivi 4.6.1 Dischi ottici Un laser va a leggere i pattern di Pit-land e Land-pit, pit-pit presenti sul compact disk.\nI dischi sono sostanzialmente uguali per quanto riguarda l\u0026rsquo;encoding di 1 e 0 ma sono diversi per quanto riguarda il materiale impiegato, il raggio impiegato **lo spazio presente fra le varie linee di informazioni (la compattezza dei bit) e simili.\n4.6.2 Output-Input Per gestire tutti i pixel c\u0026rsquo;√® la necessit√† di avere architetture molto complicate, circa devono fare update di milioni di pixel in decimi di secondo (altrimenti l\u0026rsquo;occhio capisce che c\u0026rsquo;√® la distanza)\nCore complessi per la gestione di di milioni di Pixel. Linguaggi di programmazione specifici perch√© pi√π efficienti della CPU per programmi non grafici e.g. Cuda-C. 4.6.3 Bus per dispositivi sono legati tramite BUS, collegamenti elettrici.\nBUS di dati BUS di indirizzi I bus trasportano piccole quantit√† di informazioni. Si possono dividere in sotto-bus.\nI bus si sono evoluti nel tempo, partendo da standard ISA (industry standard architetture) sono state creati moderni bus molto pi√π veloci PCI, PCIe e simili.\nCollegamento con memoria e CPU\nController collega gli attacchi ai dispositivi ai Bus che si collegano all\u0026rsquo;unit√† di controllo. (la scrittura sul bus √® controllata dalla CPU) Altri dispositivi parlano direttamente alla memoria DMA mandano e ricevono degli interrupt. (se non usasse interrupt altra soluzione sarebbe continuamente inviare delle richieste per chiedere se sta ancora andando o meno) Direct Memory Access\nDi questo ne parliamo un p√≤ meglio, anche se alla fine √® lo stesso concetto in Note sull‚Äôarchitettura\nPer saperne di pi√π su interrupt e trap\nSarebbe molto inefficiente leggere e inviare continuamente, quindi mettiamo un trasferimento RAM ‚Üí Disco senza passare dalla CPU. Quando finisce il trasferimento il dispositivo invia un Interrupt che viene gestito subito dalla CPU interrompendo il processo corrente, iniziando un interrupt handler che gestisca eventuali errori del dispositivo e informa il sistema operativo che √® finito il processo di I/O. l processo corrente, iniziando un interrupt handler che gestisca eventuali errori del dispositivo e informa il sistema operativo che √® finito il processo di I/O.\n","permalink":"https://flecart.github.io/notes/memoria/","summary":"4.1 Caratteristiche della Memoria La gerarchia della memoria, pi√π si va gi√π pi√π spazio si ha, pi√π √® lento il caricamento delle informazioni\n4.1.1 Catalogazione della memoria Le tipologie di memoria sono presenti a fianco.\nIn generale pi√π la memoria √® veloce da riprendere, pi√π √® costosa da memorizzare (c\u0026rsquo;√® poco spazio)\n4.1.2 Byte e Word Il libro a pagina 74 parte con la discussione del perch√© si √® preferito evitare la BCD (Binary coded decimal, in cui i numeri da 0 a 9 erano codificato da 4 bit), per questioni di efficienza.","title":"Memoria"},{"content":"Introduzione ai modelli lineari Processi di sviluppo Definizione L‚Äôinsieme strutturato di attivit√†, eventi, documenti e procedure necessari per la costruzione di un sistema software\nCosa viene descritto (4) üü© Questo √® proprio quanto vuole studiare l\u0026rsquo;ingegneria del software -\u0026gt; metodi di sviluppo, in modo da portare i migliori risultati possibile.\nNella formazione classica va a definire 4 concetti (soprattutto utili nel lavoro di gruppo, al fine di comunicare nella maniera pi√π efficace):\nChi fa Cosa viene fatto Quanto la fa Come la fa In breve si vanno a definire l\u0026rsquo;attivit√† di persone che collaborano allo sviluppo di un software, informazioni come: In che modo lavorano? Quali sono i ruoli e le responsabilit√† di ognuno? Come valutare la qualit√† del lavoro? Quali documenti produrre? Ciclo di vita del software üü® Trattando il software come una entit√† viva, sono tutte le parti che partono dalla creazione fino alla sua morte, ossia dismission.\nFasi della vita, da ideazione, sviluppo, rilascio, mantenimento e deprecazione.\nAndiamo a capire quali sono i metodi principali\nAltre note Legge di Conway üü®+ Le organizzazioni che progettano sistemi ne progettano la struttura riproducendo le proprie strutture comunicative (es. l‚Äôorganigramma)\nRiformulando in qualche modo: l\u0026rsquo;architettura del prodotto finale rispecchier√† il modo con cui i creatori hanno comunicato fra di loro. Ossia alcune propriet√† del sistema vengono influenzate dal processo di costruzione. Quindi non √® trasparente questa parte, almeno √® molto difficile renderlo tale.\nEsempio:\nse 4 team collaborano a costruire un compilatore, la struttura finale sar√† su 4 processi in pipeline\nLegge di Brooks Aggiungere personale ad un progetto sw in ritardo lo far√† ritardare ancora di pi√π\nPerch√© in altri campi aggiungere uomini lo fa andare pi√π in fretta, ma nel nostro caso rallenta, perch√© dovr√† esserci tempo per insegnare le conoscenze necessarie per cominciare.\nSoftware come processo sociale üü© Data l\u0026rsquo;osservazione di sopra, √® chiaro che il processo di sviluppo √® fortemente influenzato dai processi di comunicazione interni, che sono un aspetto puramente sociale di questa disciplina. Ecco che entra in gioco questo aspetto delle persone e della comunicazione. Dall\u0026rsquo;altro lato, se la costruzione ha un aspetto sociale in s√©, anche l\u0026rsquo;effetto ha una parte sociale. Guarda per esempio i social, hanno cambiato radicalmente il nostro modo di comunicazione fra persone. (un esempio sulla slide √® la banca per esempio)\nModello di processo software (4) (!) üü© Insieme di processi software che provano a catturare un punto di vista specifico il processo software\nTODO: approfondire? Sembra molto stupido Esempi di modelli Waterfall üü© Questo √® uno dei modelli di processo pi√π vecchi (ormai in disuso per il software), √® un processo lineare.\nEsempio sviluppo classico Una osservazione principale √® che alcuni ruoli sono fermi in certi momenti del waterfall, per esempio lo sviluppatore dovrebbe aspettare di ricevere le specifiche sviluppate dall\u0026rsquo;architetto, che deve sapere ci√≤ che il cliente vuole dal business analyst.\nPositive e negative di waterfall üü©- Chiara definizione dei requisiti fino all\u0026rsquo;inizio Feedback solamente finale dal cliente. Fasi bloccanti Il problema principale √® che il mercato cambia pi√π velocemente dello sviluppo, quindi altra probabilit√† che il requisito cambi prima della fine dello sviluppo. Per il software questo non sembra proprio una strategia buona per dire! ","permalink":"https://flecart.github.io/notes/modelli-lineari-di-sviluppo/","summary":"Introduzione ai modelli lineari Processi di sviluppo Definizione L‚Äôinsieme strutturato di attivit√†, eventi, documenti e procedure necessari per la costruzione di un sistema software\nCosa viene descritto (4) üü© Questo √® proprio quanto vuole studiare l\u0026rsquo;ingegneria del software -\u0026gt; metodi di sviluppo, in modo da portare i migliori risultati possibile.\nNella formazione classica va a definire 4 concetti (soprattutto utili nel lavoro di gruppo, al fine di comunicare nella maniera pi√π efficace):","title":"Modelli Lineari di sviluppo"},{"content":"Il processo e la gestione dell\u0026rsquo;esecuzione √® uno dei compiti principali dei sistemi operativi. Lo vuole fare in maniera efficace ed efficiente, come descritto in Note sull‚Äôarchitettura.\nSlide schema generale tabelle\nProcessi Il process control block √® la struttura di dati principali da comprendere.\nHa una tabella dei file aperti, che sono dei file descriptor (all\u0026rsquo;interno della propria struttura di dati), riferiti a una tabella dell\u0026rsquo;interno sistema credo, e questi puntano a un VNode che permette di localizzarlo nella memoria secondaria.\nDescrittori di processi (4) üü© √à anche un aspetto dei descrittori dei processi.\nSlide descrittori\nHo bisogno del codice segment code\nUno stack su cui lavorare, quindi memorizzare le cose temporanee\nsegment data per i dati necessari\nIl PCB per gli attributi necessari per disattivare attivare, o comunque descrive tutto il processo.\nIl PCB (3) üü®‚Äî Qui si parlano di attributi mantenuti nel PCB, sono di fondamentale importanza per il context switch, descritto in Scheduler\ninformazioni di identificazione di processo informazioni di stato del processo informazioni di controllo del processo Sono queste le informazioni principali mantenute.\nIdentificazione del processo\nindice nella tabella dei processi (problema di reincarnazione, se ho un nuovo processo al posto di uno che √® stato chiuso, allora non potrei riattivare un processo col vecchio pid), cos√¨ magari tutte le reference vecchie restano, con l‚Äôindice non riesco a farlo, potrebbe essere stato sostituito! numero progressivo che sarebbe il PID, che viene mappato al relativo descrittore, possiamo dire che il PID √® un identificatore logico! Che poi viene risolto al descrittore vero. Altre identificazioi come utente, gruppo, pid del padre, in modo che possa controllare l\u0026rsquo;accesso e le limitazioni del processo.\nInformazioni di stato del processo\nHo la necessit√† di avvicendare i processi, quindi ho bisogno di qualcosa per fermare e riattivare i processi, questa sezione di informazione √® utile per questa parte.\n√à importante che questi valori sono presenti i valori dell‚Äôultimo salvataggio perch√© salvo solo quando devo switchare, se sto runnando non ha senso che utilizzi queste cose.\nContenuto dei registri, normali e speciali (questi vengono persi quando facciamo switch), si potrebbe chiamare come se fosse una istantanea dei registri. La memoria in RAM √® meglio mantenerla, quindi non andiamo a ricordarlo. informazioni di controllo del processo\nUna lista enorme di cose per il controllo, cio√® in questa parte c‚Äô√® tanta roba!\nScheduling (forse pi√π importante come priorit√†, tempo di esecuzione etc). Gestione memoria, MMU. Risorse utilizzate (quindi accounting delle risorse) Comunicazione con altri processi. Slides\nStati dei processi (3) üü© Possiamo generalizzare lo stato del processo come se avesse principalmente 3 stati:\nRunning, il programma sta runnando senza problemi Waiting, il processo non pu√≤ essere eseguito perch√© sta aspettando qualcosa, es. un I/O Ready, il processo non √® eseguito, ma pu√≤ essere continuato quando la CPU ha tempo per dedicare ancora tempo a questo. Slide stati processi\nLa cosa carina che sembra essere descrivibile dallo schemini simili agli automi Grammatiche Regolari.\nSolitamente per gestire tutto l\u0026rsquo;insieme dei processi ready, lo si mette in una coda ready, ma esistono anche altre code come disk queue, terminal queue.\nGerarchie di processi üü© √à molto facile fare cose a sua immagine e somiglianza, ci sono molti campi in cui basta fare una copia, e ho la maggior parte delle informazioni che mi interessano.\nSpecifico solo quello che cambio. Questo rende molto facile creare nuovi processi, basta cambiare ci√≤ che √® diverso!\nSistema gerarchico UNIX\nBound sui processi (2) üü© Si pu√≤ dire che un processo sia CPU bound, I/O bound, queste sono le cose che interessano poi allo Scheduler per decidere cosa fare.\nil primo, CPU, quando fa calcoli che sono molto lunghi.\nIl secondo I/O, quando fa richieste IO che prendono molto tempo.\nIn generale i processi si possono descrivere come in alternanza continua fra CPU use e richieste IO.\nSlide descrizione bounds processi\nEsempio di CPU e IO bound\nThreads Il processo √® il titolare delle risorse di elaborazione ma pu√≤ eseguire solamente una cosa alla volta. Con i thread possiamo dividere il processo in pi√π linee esecutive che condividono delle risorse.\nQuesta √® una cosa molto comoda, per esempio quando ho un browser ho bisogno di un altro thread per scaricare in modo contemporaneo pi√π file. Sono pi√π linee di controllo. ma pi√π vantaggioso rispetto a fare processi separati, perch√© mi permette la pi√π facile condivisione di risorse. (dovrei mettermi a mandare messaggi anche per cose banali, quindi anche leggero overhead, per copiare molte informazioni Message Passing).\nVantaggi sui processi üü©- Condivisione di memoria facile Molto pi√π facile fare context switch di thread che di processi. (pu√≤ essere un ordine di grandezza pi√π veloce) Facilit√† di scrittura del codice, rispetto a message passing e pi√π processi. I lati negativi sono:\nMolti descrittori Molti context switch Quindi utilizzo leggermente pi√π risorse con i thread.\nInformazioni dei thread (2) üü®‚Äî ha informazioni parziali rispetto al processo, con cui condividono un sacco di cose, come dati, I/O, e il codice del programma.\nStack separato. Program counter proprio, dato che voglio una storia esecutiva indipendente. (e quindi anche propria copia dei registri). In questo modo sposto il livello di running e waiting al singolo thread.\nKernel e user thread Questo la saltato boh\nPer√≤ ora sono tutte livello kernel e user non viene pi√π utilizzato.\nLa differenza sta nel fatto se il kernel sia a conoscenza o meno dell‚Äôesistenza dei threads (se √® a consocenza per esempio ci pu√≤ fare scheduling, mentre altrimenti no, per√≤ se ne √® a conoscenza deve tutto essere gestito dal kernel, questo in qualche modo rende molto pi√π pesante la gestione).\nRelation threads Anche questi sono stati saltati\n","permalink":"https://flecart.github.io/notes/processi-e-thread/","summary":"Il processo e la gestione dell\u0026rsquo;esecuzione √® uno dei compiti principali dei sistemi operativi. Lo vuole fare in maniera efficace ed efficiente, come descritto in Note sull‚Äôarchitettura.\nSlide schema generale tabelle\nProcessi Il process control block √® la struttura di dati principali da comprendere.\nHa una tabella dei file aperti, che sono dei file descriptor (all\u0026rsquo;interno della propria struttura di dati), riferiti a una tabella dell\u0026rsquo;interno sistema credo, e questi puntano a un VNode che permette di localizzarlo nella memoria secondaria.","title":"Processi e thread"},{"content":"Top-down Algoritmo di parsing üü© Slide\nQuesto si potrebbe considerare come algoritmo classico di parsing con non determinismo. (vado avanti, ed esploro tutto, senza look ahead).\nEsempio di esecuzione\nCommenti efficienza di sopra üü© √à molto inefficiente, in particolare si potrebbe trovare una compessit√† esponenziale del tipo\n$O(b^{|w|})$, con b il massimo numero di produzioni. (la produzione maggiore la espando sempre!)\nSlide\nSi pu√≤ rendere molto pi√π efficiente con un valore di lookahead.\nFirst e Follow Utilizzeremo il simbolo $ per segnalare la fine di una stringa, cos√¨ pu√≤ godere della prefix property, che √® una cosa fondamentale per le DPDA, vedi Linguaggi Deterministici e DPDA.\nFirst intro üü© Slide\nIn pratica √® un insieme che contiene i primi caratteri possibili per tutti! (ad ochio attento si pu√≤ notare quanto sia importante per il lookahead, andiamo in pratica a considerare le produzioni che abbiano il simbolo di lookahead).\nEsempio di uso e in-uso di first\nCalcolo del first üü© Interessante in questa parte l‚Äôutilizzo dell‚Äôinsieme dei simboli annullabili che abbiamo descritto in Semplificazione grammatiche., sembra sia legata molto al first\nSlide\nL‚Äôintuizione di maggior rilievo per questo algoritmo √® che in quel modo si sta facendo un or , unione fra tutti i simboli che sono annullabili.\nQuesto algoritmo si pu√≤ estendere in modo quasi banale ai non terminali che non sono annullabili (perch√© basta prendere il primo carattere\nSlide che descrive per simboli non annullabili\nEsempi del calcolo del first\nFollow intro üü©‚Äî Slide\nQuindi un terminale appartiene a follow terminale se pu√≤ comparire dopo\nUna cosa particolare di questa definizione √® il terminale $.\nA volte ci pu√≤ interessare sapere cosa viene dopo un non terminale annullabile cos√¨ possiamo decidere di annullarlo e tenere il prossimo.\nMini esempio\nCalcolo del follow üü© Slide algo\nDa notare che per calcolare questa funzione abbiamo bisogno del first!\nEsempio 1\nEsempio 2\nGrammatiche LL(1) Tabella di parsing intro LL(1) üü© Definizione\nHo una tabella che mappa (NT, T) ‚Üí produzione.\nIn pratica una tabella di parsing ci d√† una idea del modo in cui comportarci per ogni singolo input e ogni terminale, √® quindi fondamentale per capire in che modo espandersi‚Ä¶\nOssia se ho un NT sulla stack e vedo con lookahead 1 un terminale, allora provo a capire con quale produzione posso espandere.\nAlgoritmo per riempimento tabella üü© Algoritmo calcolo della tabella\nSe il first di qualcosa che voglio mettere √® noto, allora √® easy‚Ä¶\nAltrimenti la metto per l‚Äôintera riga.\nTh sui LL(1) (chiede molto) üü© Definizione di grammatica LL(1)\nEnunciato e dimo\nLa dimostrazione di questo √® molti dalla costruzione della tabella di parsing. (in particolare l\u0026rsquo;unici modi che ci importano per dimostrare se un linguaggio √® LL(1) √® questo oppure la costruzione della tabella d parsing).\nEsempio grammatica in forma sopra\nEsempio 2\nParser LL(1) ! üü© Slide Algo pseudocodice\nL‚Äôidea √® principalmente di utilizzare la tabella di parsing per capire quale produzione utilizzare quando ho un non terminale!\nQuanto ho terminali li poppo dalla pila (se non posso poppare ritorno errore) Quando ho non-terminali vado a guardare nella tabella, se non ho niente fallisco Alla fine se ho svuotato la pila e letto tutto sono molto felice. Esempio di parsing 1\nEsempio 2\nesempio 3\nTh. ling regolare ‚Üí generabile da LL(1) üü®- Dalla lezione 14 (credo)\nCon i teoremi espressi in Grammatiche Regolari, posso trasformare l‚Äôespressione regolare in DFA e poi il dfa minimo in grammatica regolare da questo posso creare la grammatica LL1, vogliamo ora dire che possiamo sempre farlo (nel toggle c‚Äô√® il piccolo algoritmino utilizzato per creare la grammatica).\nDimo\nMini lemma:\nOgni grammatica regolare con solo produzioni $V \\implies aW$ e produzioni epsilon √® una grammatica LL(1)\nIl motivo √® che i first di ogni produzione di un non terminale sono diversi fra di loro, perch√© sono tutti parte dell‚Äôalfabeto e sono unici. E i follow sono sempre stringa terminale, quindi per il teorema di caratterizzazione dei linguaggi LL(1), questo √® un linguaggio LL(k).\nSi pu√≤ verificare che questo √® il tipo di grammatica che si estrae da un automa minimo, quindi il teorema √® soddisfatto.\nGrammatiche LL(k) Generalizzazione first follow e tabella üü©- Slide\nIntuizione\nOra il first ha la concezione dei **primi k **, lettere che possono essere anche minori di k, nel caso in cui io abbia gi√† una stringa terminale. Ma non posso avere minore di K se non √® terminale!!!!\nAllo stesso modo follow k sono i primi k caratteri che possono seguire il nostro non terminale.\nLa tabella √® generata esattamente nello stesso modo**,* solo che bisogna fare un p√≤ di attenzione alle colonne, che ora possono essere di dimensione molto maggiore rispetto alla dimensione dell‚Äôalfabeto (potenze di esse, almeno potenzialmente, poi nella pratica io mi metto a storare quello che mi serve.\nEsempio di utilizzo di first e follow generali\nTeoremi (4) su LL(k) üü® Slide\nQuesti teoremi ci danno una forte relazione fra\ngrammatica ambigua ‚Üí non √® LL(k) con questa anche la sua contronominale ricorsiva sinistra ‚Üí non LL(k) essere LL(k) ‚Üí essere un linguaggio libero deterministico ‚Üí Non ambigua esiste L deterministico tale che non ci sia G di class LL(k) (quindi i linguaggi LL(k) non bastano per avere tutti i linguaggi deterministici! Gerarchia classi di linguaggi LL(k) üü© Slide\nQuello che si pu√≤ osservare √® che ogni classe di linguaggio con k maggiore include quella con k minore. Il motivo intuitivo che non √® presente nella slide √® tipo: se posso riconoscerlo guardando una lettera pi√π avanti, lo posso ancora fare guardandone 2 o pi√π‚Ä¶\nSi pu√≤ notare che non tutti i linguaggi liberi deterministici sono riconosciuti da linguaggi LL(k), si pu√≤ osservare l\u0026rsquo;esempio di sotto.\nLibero det not implies LL(k) üü®+ esempio Incompletezza dei linguagg LL(1)\nIn questo caso √® solamente enunciato che non si pu√≤ modellare la grammatica cos√¨ trovata per renderla di classe LL(k).\nPer√≤ intuitivamente si pu√≤ capire che avrei bisogni di un k infinito per poter scegliere fra le due produzioni, riesco sempre a trovare un k che non funzioni‚Ä¶\nEsercizio a caso\n","permalink":"https://flecart.github.io/notes/top-down-parser/","summary":"Top-down Algoritmo di parsing üü© Slide\nQuesto si potrebbe considerare come algoritmo classico di parsing con non determinismo. (vado avanti, ed esploro tutto, senza look ahead).\nEsempio di esecuzione\nCommenti efficienza di sopra üü© √à molto inefficiente, in particolare si potrebbe trovare una compessit√† esponenziale del tipo\n$O(b^{|w|})$, con b il massimo numero di produzioni. (la produzione maggiore la espando sempre!)\nSlide\nSi pu√≤ rendere molto pi√π efficiente con un valore di lookahead.","title":"Top-down Parser"},{"content":"In questa sezione andiamo ad indagare metodi di scomposizione, iterativi e non. Ci sono molte matrici importanti per questa parte che dovremmo prendere confidenza.\nImmagini Lab 2 images\nMetodo di gauss Vogliamo cercare un metodo per calcolare soluzioni a sistemi di equazione del genere:\n$Ax = b$, classico. Supponiamo che questo sistema abbia una soluzione.\nIl nostro obiettivo sarebbe scomporre la matrice $A = LU$ come prodotto di due matrici Lower triangular e Upper triangular.\nAlgoritmo per matrici Upper e lower triangular üü© Nel caso io abbia una matrice Lower o Upper triangular, i sistemi nella forma $Lx=b$ sono risolvibili con un algoritmo abbastanza banale che qui non riporto (sostituzioni via via‚Ä¶)\nIl costo √® di $O(n^2)$ e non ti scordare il /2 perch√© a lei piace\nScomposizione A = LU üü© Questo √® un algoritmo che necessita di una osservazione abbastanza difficile:\nNoto che durante l\u0026rsquo;applicazione dell‚Äôalgoritmo di gauss, per creare il pivot su una colonna, √® esattamente come se moltiplicassi per una (matrice identit√† + fattori per la colonna di interesse).\nCome in esempio\nSi pu√≤ notare inoltre che che l‚Äôinverso di L1 √® in una forma molto bella, esattamente la stessa con numeri invertiti!, inoltre la moltiplicazione fra Ln √® anch‚Äôessa in una forma molto carina!!! Facilita molto il prodotto. In questo modo mi creo una matrice L, in cui √® molto facile invertire.\ncosto $O(n^3/3)$ per la fattorizzazione LU e poi n2 due volte per risolvere L e U\nScomposizione con permutazione üü© Ogni tanto potrebbe capitare che ci sia il bisogno di permutare, altrimenti non ho nessuna soluzione, da notare che questo √® un passo all\u0026rsquo;interno dell‚Äôalgoritmo di gauss.\nInoltre scegliere il maggiore dovrebbe aiutare ad eliminare mini-errorini dovuti all‚Äôimprecisione della somma floating point.\nAlgoritmo\nForma finale scomposizioni üü© Se utilizziamo una sorta di pivoting parziale ossia per ridurre gli errori scegliamo il massimo della colonna (come del resto fa l‚Äôalgoritmo di sopra) allora non abbiamo bisogno di permutare colonne), se vogliamo invece un pivoting totale allora dobbiamo permutare le colonne e la matrice diventa qualcosa del tipo\n$A = QLUP$ con Q le permutazioni su riga, e P quelle su colonna (quelle su colonna non √® che ci importa molto, perch√© basta moltiplicare per $P^T$, ossia la sua inversa per x e si risolvono problemi di questo genere‚Ä¶ dato che alla fine $PP^T = I$\nMetodo di Cholesky üü© Se prendo una matrice A simmetrica definita positiva (ricorda analisi per questo), allora con questo metodo riesco a riscriverla nella forma $A = LL^T$, e so che la matrice L triangolare inferiore non √® singolare perch√© ho tutti gli autovalori positivi.\nQuesto metodo costa $O(n^3/6)$ leggermente pi√π veloce della fattorizzazione di Gauss.\nUna volta fatto la scomposizione poi va subito\n$Ly = b, L^Tx = y$ e si risolve, sul come funziona l\u0026rsquo;algoritmo, per ora ci importa solamente che √® pi√π veloce.\nSe non √® simmetrico o non √® definita positiva il programma crasha.\nMetodo di Schur Questo √® un metodo nuovo che aggiungo in seguito. Una risorsa buona per questo metodo lo trovi qui. √à utile quando vogliamo fare una cosa di questo tipo $$ A = QBQ^{-1} $$ Dove $Q$ √® una matrice di cambio di base. Questa cosa non si pu√≤ fare sempre quando vogliamo che $B$ sia diagonale, per√≤ la decomposizione di Schur ci d√† qualche nota in pi√π riguardo a questo, usando per√≤ matrici upper triangular\nEnunciato di Schur Per qualunque matrice a valori complessi $A$ esiste una base ortonormale in $\\mathbb{C}$ e una matrice upper triangular $T$ tale per cui vale $$ A = BTB^{-1} $$ NOTE: se $A$ √® una matrice normale, allora $T$ √® diagonale. Normale quando vale $AA^{*} = A^{*}A$. Con $A^{*}$ la trasposta coniugata della matrice $A$.\nIdee generali per la dimostrazione di Schur In pratica per un teorema dell\u0026rsquo;algebra (quello fondamentale) si ha che $T$, dato che √® quadrata, ha almeno un autovettore, allora prendi questo autovettore, usi il teorema di estensione per creare una base, e scomponi con questo. Questo ti creer√† una matrice a blocchi grossi $2\\times2$ in cui quello in basso a destra √® ancora quadrato con suo sottospazio. Continui cos√¨ finch√© non finisce tutto e resta una matrice upper triangular. Nella reference ci√≤ √® descritto molto bene da un punto di vista intuitivo. La cosa carina con le $T$ √® che per esempio √® spesso pi√π facile elevarli alla potenza, non quanto le diagonali, ma pi√π semplice.\nMatrici semi-definite o definite positive Se prendo un qualunque vettore e vale\n$$ x^TAx \\geq 0 $$ Oppure avendo autovalori sempre positivi sono maggiore di 0, si pu√≤ vedere che √® equivalente. Certi autori richiedono anche che la matrice $A$ sia simmetrica.\nGuarda Massimi minimi multi-variabile nella sezione forme quadratiche per questo.\nMetodi iterativi Sono buoni perch√© l\u0026rsquo;errore di questi √® molto pi√π alto, ma spesso molto pi√π veloce, mentre per i metodi diretti √® esattamente il contrario (errore basso, alta complessit√†).\nIn modo molto generale, possiamo definire un metodo iterativo come una funzione $G$ applicata all\u0026rsquo;input stesso: $x_n = G(x_{n - 1})$\nNote introduttive convergenza e iterazione Questa sotto √® la definizione di convergenza ad $\\alpha$ con ordine $p \\geq 1$\nSpesso la convergenza √® fissata da una condizione di arresto (che pu√≤ essere dipendente anche dal numero di iterazioni. Possiamo definire C = fattore di convergenza quando $p = 1$, perch√© pi√π √® piccolo pi√π converge in fretta. C\u0026rsquo;√® anche una relazione simile fra i p, pi√π √® grande, in questo caso, pi√π velocemente converge.\nMetodi iterativi stazionari Idee Generali üü© Questi sono nella forma $x _{k +1} = Hx_k + d_k$ Poi scriverlo come una differenza di matrici in particolare vorre $A = M - N$ , dove $M$ sia non singolare (e possibilmente facilmente invertibile). Se ci√≤ √® possibile allora\n$Ax = b \\implies Mx - Nx = b \\implies x = M^{-1}Nx + M^{-1}b \\implies x = Tx + c$\nUna volta avuto questa matrice $T$ possiamo riutilizzarla per ogni iterazione di successione!\nAvremo che $x_k = Tx_{k - 1} + c$, e si ha che $x* = \\lim x_k$ deve essere che\n$$ x* = Tx* + c $$ E vorremmo che questo metodo converga per ogni input quindi potrei mettere un x_0 a casissimo\nUna cosa non espressa durante la lezione √® che $N = M - A$ quindi\n$$ M^{-1}N = M^{-1}(M - A) = I - M^{-1}A $$ Che ci permette di scrivere la stessa cosa sente fare utilizzo della matrice $N$ e secondo me √® pi√π clean. Questa cosa √® presente nel libro.\nCondizione necessaria e sufficiente di convergenza üü© Teorema sulla condizione di convergenza:\nQuesto risultato si pu√≤ connettere col raggio spettrale e si pu√≤ concludere che converge sse\n$$ \\rho(T) \u003c 1 $$ Metodo di Jacobi üü© Sia $D$ la parte diagonale di $A$, allora l‚Äôiterazione in questa forma converge e si chiama metodo di jacobi\n$$ x_{k + 1} = (I -D^{-1}A)x_k + D^{-1}b $$ Nota: attento che la prof non ha insegnato in questo modo! Quindi probabilmente se te la chiede diglielo nella forma che le piace,\n$M = D, N = E + F$\nMetodo Gauss-Seidel üü© Si ricorda che $A = D - E - F$ in modo molto strano di scriverlo‚Ä¶\nSi fa uso della matrice Lower con anche la diagonale, per il resto √® esattamente uguale a tutto il resto per i metodi iterativi., quindi\n$$ M = D - E, N = F $$ Condizioni di convergenza per Jacobi e Gauss-Seidel üü• Per comprendere questa parte √® importante il concetto di matrice con diagonale dominante. In parole umane deve essere che ogni elemento sulla matrice deve essere maggiore della somma di tutto quanto non stia sulla diagonale maggiore.\nSlide condizioni\nNota questi sono in pratica da imparare a memoria, ma non me ne ricordo!\nGradiente coniugato Questo √® un metodo di arresto molto misterioso, direi di cacharla ü§ë.\nMetodi di cui non ha parlato Metodo SOR Metodi di Rilassamento Metodi di Krylov ","permalink":"https://flecart.github.io/notes/algebra-lineare-numerica/","summary":"In questa sezione andiamo ad indagare metodi di scomposizione, iterativi e non. Ci sono molte matrici importanti per questa parte che dovremmo prendere confidenza.\nImmagini Lab 2 images\nMetodo di gauss Vogliamo cercare un metodo per calcolare soluzioni a sistemi di equazione del genere:\n$Ax = b$, classico. Supponiamo che questo sistema abbia una soluzione.\nIl nostro obiettivo sarebbe scomporre la matrice $A = LU$ come prodotto di due matrici Lower triangular e Upper triangular.","title":"Algebra lineare numerica"},{"content":"Significato di astrazione L\u0026rsquo;astrazione √® una cosa fondamentale nell\u0026rsquo;informatica, l‚Äôabbiamo visto anche nella prima lezione in assoluto per architettura, il sistema a strati di Architettura e livelli 1, 2 reti e simili.\nIl principali metodi sono astrazioni sul controllo e sui dati sui dati stiamo cominciando a parlarne in Teoria dei Tipi.\nLe astrazioni sono utili a nascondere dettagli per qualche fenomeno o simile (ricorda l\u0026rsquo;esempio della mappa, che non √® il territorio √® una astrazione su essa, che contiene ancora informazioni utili). Vogliamo quindi concentrarci su quanto ci interessa\nuna cosa che a noi √® molto interessante √® la astrazione funzionale\nAstrazione funzionale üü© Vogliamo creare una associazione fra funzione e procedura, ossia esporre solamente cose come intestazione della funzione, parametri e valore di ritorno per descrivere una funzione, la implementazione non ci interessa.\nSi pu√≤ ben notare che meno la funzione interagire con l‚Äôambiente non locale, ossia pi√π √® indipendente, ha meno side effect, meglio √® fatta sta astrazione.\nComunicazione con l‚Äôambiente (3) üü© la comunicazione con l‚Äôambiente pu√≤ avvenire mediante tre metodi principali.\nParametri Ambiente no nlocali Il valore di ritorno Formali e attuali e 3 comunicazione üü© Nella dichiarazione di funzione si parla di parametri formali, nel senso che sono delle variabili legate, se rinominate correttamente attraverso funzioni definite in Logica si pu√≤ cambiare nome.\nUn parametro attuale √® quello effettivamente mandato, che si fa mediante la chiamata di funzione.\nSlide formali e attuali\nAnche il flusso di informazione pu√≤ essere diviso in pi√π modi.\nin entrata (come il passaggio per valore) In uscita (boh, si assegna il valore ebbasta, senza leggerle). In entrata e uscita (come le reference) Passaggio di parametri Passaggio per valore üü© Questo √® il classico passaggio di funzione che abbiamo in C.\nViene calcolato il valore (r-value)\nil valore viene messo sulla pila, quindi come se fosse una variabile locale.\nDistruzione quando si ritorna dalla funzione\nMolto costoso per dati grossi perch√© devo fare la copia\nnon ho modo di comunicare usando quella variabile direttamente al parametro.\nSlide per passaggio valore\nla cosa carina √® che √® una copia, non ho trasmissione delle informazioni.\nPassaggio per riferimento üü© In questo caso passo il riferimento, o l-valore dell‚Äôoggetto, quindi la sua locazione o riferimento. (in java in pratica √® un riferimento perch√© si utilizza la reference model come descritto in Valutazione Espressioni.\nSlide passaggio per riferimento\nSlide riassunto valore e riferimento\nUn concetto qui importante √® la trasparenza referenziale, nel senso che non ci importa di come √® stato chiamato, tanto √® una copia (per il passaggio per vlaore) quindi riesco ad avere quanto mi interessa. (questo non vale per reference, perch√© dipende da con cosa lo ho chiamato!)\nCome fare un passaggio con semantica semplice come il passaggio di valore e senza problemi di aliasing come reference, e con anche comunicazione.\nEsempio di problema di aliasing\nPassaggio per costante üü© VALORE NON MODIFICABILE\nSolo in una direzione, solo che non si pu√≤ modificare. √à come un passaggio per valore, solo che si potrebbe implementare per riferimento per ragioni di efficienza. Ma comunque dipende dall‚Äôimplementazione della macchina astratta.\nPassaggio per risultato üü© Questo √® il duale del passaggio per valore, perch√© alla chiamata di funzione assegno la funzione a questa variabile (alla fine assegno il valore del formale al parametro attuale), quindi √® molto utile per trasmettere valore dalla procedura al main.\nOssia ho una copia del valore formale *(aka valore attuale) al parametro attuale, ma lo ho solo alla fine della funzione.\nSlide passaggio per risultato\nPassaggio per valore risultato üü© Questo permette il passaggio in entrambe le direzioni (si fa la copia e si assegna alla fine). Alcuni linguaggi implementano questa cosa attraverso la reference, sempre per il concetto che √® molto pi√π efficiente tenere le reference, solo che c\u0026rsquo;√® il problema di aliasing, quando mando la stessa reference.\nEsempio di valorerisultato differente da reference\nPassaggio per Nome (!) üü© In pratica sostituisco il nome del parametro attuale al posto del parametro formale, senza cattura.\nuna chiamata alla procedura P √® la stessa cosa che eseguire il corpo di P dopo aver sostituito i parametri attuali al posto dei parametri formali\nSi pu√≤ notare come se fosse la macro espansione in assembly (di cui credo le macro di C sono molto simili)\nEsempi di cose del passaggio per nome\nPROBLEMI DI SCOPING\nSlide scopes\nQuesto sar√† il problema che permetter√† il passaggio dell‚Äôambiente molto utilizzato per le variabili di ordine superiore come le funzioni.\nIIMPLEMENTAZIONE DEL PASSAGGIO PER NOME\nL‚Äôimplementazione di questo passaggio √® molto interessante, perch√© dovrei passare anche l‚Äôambiente iniziale affinche‚Äôtutta l‚Äôespressione abbia senso! l‚Äôoperazione fondamentale √® lo scoping.\nSlide implementazione per nome\nSolitamente √® molto costoso perch√© per valutare devo sempre andare in un ambiente diverso dall\u0026rsquo;attuale, poi anche dal fatto che il valore √® rivalutato ad ogni occorrenza!\n","permalink":"https://flecart.github.io/notes/astrazione-sul-controllo/","summary":"Significato di astrazione L\u0026rsquo;astrazione √® una cosa fondamentale nell\u0026rsquo;informatica, l‚Äôabbiamo visto anche nella prima lezione in assoluto per architettura, il sistema a strati di Architettura e livelli 1, 2 reti e simili.\nIl principali metodi sono astrazioni sul controllo e sui dati sui dati stiamo cominciando a parlarne in Teoria dei Tipi.\nLe astrazioni sono utili a nascondere dettagli per qualche fenomeno o simile (ricorda l\u0026rsquo;esempio della mappa, che non √® il territorio √® una astrazione su essa, che contiene ancora informazioni utili).","title":"Astrazione sul controllo"},{"content":"Campo elettrico nei materiali Se prendiamo un conduttore, gli elettroni in questi materiali sono liberi, significa che sono liberi di muoversi come vogliono, si pu√≤ dire che \u0026ldquo;vadano in giro\u0026rdquo; (per esempio questo vale per il rame).\nil reticolo cristallino √® al struttura regolare che √® comune nei materiali, in cui gli atomi sono sempre a distanza costante (o comunque a pattern regolari) uno dall\u0026rsquo;altro $r$ per esempio.\nCampo e materiali (6) Schermatura del campo (!) üü© Quando un materiale conduttore √® sottoposto a un campo elettrico *gli elettroni si mettono in modo da schermare il campo esterno, in modo tale da raggiungere un equilibrio. Se andiamo a chiamare $\\vec{E}_{i}$ il campo elettrico indotto dentro il materiale, allora avremo che\n$$ 0 = \\vec{F}_{0} = e(\\vec{E}_{i} + \\vec{E}) \\implies\\vec{E}_{i} = -\\vec{E} $$ L\u0026rsquo;osservazione principale che porta a questo risultato √® il fatto che nel primo momento c\u0026rsquo;√® uno spostamento di carica. Questo √® l\u0026rsquo;unico risultato sperimentale che abbiamo. Le cariche sono ferme all\u0026rsquo;interno del conduttore.\nMa questa carica da dove origina? Dove sono posizionate? Sono sulla superficie o anche dentro il materiale?\nCariche non sono dentro al conduttore (!) üü© In ogni punto interno al conduttore, all\u0026rsquo;equilibrio la carica elettrica √® nulla, come avveniva in assenza del campo elettrico.\nQuesto implica che da dentro il conduttore non cambia niente.\nSi pu√≤ dimostrare con la divergenza, praticamente che la densit√† di carica volumetrica resta nulla, perch√© il campo elettrico totale √® ancora nullo.\n$$ \\vec{\\nabla} \\cdot\\vec{E}_{T} = \\frac{\\rho}{\\varepsilon_{0}} \\land \\vec{E}_{T} = 0 \\implies \\rho=0 $$ Si pu√≤ anche dimostrare usando Legge di Gauss per i campi elettrici Cariche si spostano in superficie üü© Lo spostamento di cariche elettriche determinato dal campo elettrico esterno all\u0026rsquo;equilibrio si risolve in un ri-arrangiamento di carica che interessa solo la superficie del conduttore\nLa componente tangente non esiste sulla superficie, perch√© altrimenti le cariche si muoverebbero, invece la componente normale esiste sigma su $\\varepsilon_{0}$, Nel caso di cariche positiva c\u0026rsquo;√® proprio una forza sempre normale alla superficie, che spinge cariche fuori, in presenza di campo elettrico\nUn altra spiegazione per cui √® sempre normale √® riguardante la differenza di potenziale, sappiamo che $$ dV = \\nabla V \\cdot ds = -\\vec{E} \\cdot ds $$ Sappiamo che per una componente tangenziale su superficie equipotenziale la variazione di $V$ √® nulla, quindi non esiste nessuna componente tangenziale, solamente quella normale. Possiamo anche scrivere\n$$ \\nabla V = \\frac{dV}{dn} $$ dove $\\hat{n}$ √® il vettore normale alla superficie equipotenziale\nSe √® negativa √® esattamente il contrario\nInfluenza sul campo elettrico üü© Dato un conduttore immerso in un campo elettrico esterno, all\u0026rsquo;equilibrio, altera le linee di campo anche all\u0026rsquo;esterno del conduttore. Il cambiamento delle linee di campo dipende dalla geometria del conduttore. Le linee di campo sulla superficie del conduttore sono normali e hanno modulo $\\frac{\\sigma}{\\varepsilon_{0}}$\nQuesto implica -\u0026gt; cambio del campo elettrico. L\u0026rsquo;induzione elettrostatica cambia il campo elettrico esterno, perch√© serve per schermare all\u0026rsquo;esterno. Quindi basta anche un conduttore neutro per cambiare il campo esterno 2. Un altro modo per cambia il campo √® introdurre nuove cariche.\nQuesto √® anche un modo per testare la conduttivit√† di un materiale, le linee di campo DEVONO essere 90 gradi ad entrare\nSuperficie equipotenziale come conduttore üü© La superficie del conduttore √® equipotenziale, cos√¨ come l\u0026rsquo;interno\nPer avere questo risultato vedere sotto #Potenziale sulla superficie.\nCampo elettrico in geometria cava üü© Se un conduttore cavo viene immerso in un campo elettrico esterno, all\u0026rsquo;equilibrio, il campo elettrico all\u0026rsquo;interno della cavit√† √® nullo e non vi sono cariche elettriche indotte sulla superficie della cavit√†\nPoniamo che la nostra geometria abbia un buco, √® corretto che certe cariche si mettono sulla superficie della nostra geometria?\nSe proviamo a considerare Gauss una superficie che comprende tutta la superficie, la carica totale della nostra superficie √® 0, ma non mi d√† informazioni su come sono messe le cariche, stessa cosa probabilmente per la divergenza utilizzato in questo caso.\nConsideriamo in questo caso la circuitazione, allora $$ \\oint_{\\Gamma}\\vec{E} \\cdot d\\vec{r} = 0 = \\int _{A}^{B} \\vec{E} \\, d\\vec{r} + \\int _{B}^{A} \\vec{E} \\, d\\vec{r} = \\int _{A}^{B} \\vec{E} \\, d\\vec{r} $$ Questo perch√© la forza √® conservativa, prendo una circuitazione che si muova SULLA linea di campo e si chiuda dentro al conduttore. (l\u0026rsquo;integrale dentro il conduttore √® nullo perch√© il campo stesso √® nullo.)\nMentre nel buco il campo √® normale, quindi avremmo che\n$$ \\int _{A}^{B} \\vec{E} \\, d\\vec{r} = \\int _{A}^{B} \\lvert \\vec{E} \\rvert \\, dr \\cos 0 \\neq 0, \\text{ nel caso in cui il campo sia presente} $$ Quindi $\\vec{E} = 0$, questo √® il principio di schermatura, se abbiamo qualcosa di conduttore, non passa. Negli ascensori se varia troppo in fretta, non viene fermato, perch√© gli elettroni ci mettono un po\u0026rsquo; a rimettersi in sesto. Un altro motivo √® che non √® puramente metallica (conduttrice) questo ascensore. Altri fenomeni Singola Carica elettrica in geometria cava üü© Le cariche si sposteranno, e cercheranno anche in questo caso di schermare. Se considero una superficie che li rinchiude, in questo caso avr√≤ un campo elettrico. $$ \\oint_{\\Sigma} \\vec{E} d\\vec{s} = \\frac{Q_{T}}{\\varepsilon_{0}} = \\frac{1}{\\varepsilon_{0}} (Q + Q_{I}) = 0 \\implies Q_{I} = Q $$ Ossia la carica sulla superficie √® **esattamente uguale alla carica nel buco**, per questo motivo scherma, il motivo per cui fa 0 √® perch√© direttamente sulla superficie Flusso esterno: $$ \\oint_{\\Sigma} \\vec{E} d\\vec{s} = \\frac{1}{\\varepsilon_{0}} (Q + Q_{C}) = \\frac{Q}{\\varepsilon_{0}} $$ Perch√© la carica del conduttore √® neutra, per ipotesi non era carica. $Q_{C} = Q_{I} + Q_{E}$ ossia carica interna (sul buco interno e sul buco esterno), ma in questo caso allora posso concludere che $Q_{E} = -Q_{I} = Q$, ossia sia una superficie esterna, sia la superficie interna vengono influenzate da questa carica.\nInduzione completa üü© Fenomeno descritto in precedenza √® **l'induzione completa** come fenomeno. Nel caso in cui **tutte le linee di campo** entrano nel conduttore. In un certo senso se stai fuori dal materiale conduttore, √® come se lasciasse passare il campo senza problemi (se sto molto lontano **sembra singola carica**) (invece di renderlo radiale, sto cambiando leggermente la\\ direzione del campo *sulla superficie* se sto vicino). **Il campo interno non viene schermato** Materiale conduttore carico üü© Supponiamo di avere un materiale conduttore carico, anche in assenza di campo elettrico. Nel caso precedente avevamo analizzato il caso di un conduttore neutro in campo elettrico, la differenza qui √® che √® il conduttore stesso che √® carico\nPosso avere esattamente le stesse propriet√† dette prima per conduttore immerso in campo elettrico\nLe cariche sono ferme Potenziale elettrico √® costante La carica elettrica dentro il conduttore √® 0 campo elettrico √® normale sulla superficie ed √® $\\frac{\\sigma}{\\varepsilon_{0}}$ Le cariche sono sulla superficie (si provano e repellere il pi√π possibile). Se il conduttore √® cavo allora le cariche restano su quella esterna. Una altra applicazione √® il parafulmine perch√© la carica si distribuisce sempre all\u0026rsquo;esterno.\nDistribuzione di carica e densit√† superficiale in conduttori connessi üü©\u0026mdash; Supponiamo di avere due sfere connesse da un filo conduttore (quindi la carica √® libera di connettersi), ci andiamo a chiedere che se metto $Q$ in questo sistema, in che modo si distribuisce? Io so che $R_{1} = 2R_{2}$ Noi sappiamo che il **potenziale sulla superficie** √® uguale, i due potenziali devono essere uguali anche nel nostro caso (altrimenti forse non √® bilanciato) $$ V(1) = V(2) \\implies \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q_{1}}{2R_{2}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q_{2}}{R_{2}} \\implies \\frac{Q_{1}}{Q_{2}} = \\frac{R_{1}}{R_{2}} \\implies Q_{1} = 2Q_{2} $$ Dove abbiamo definito che $$ V(1) = V(R_{1}) - V(\\infty) = V(R_{1}) = \\int _{R_{1}}^{\\infty} \\vec{E}\\, d\\vec{r} = \\int _{R_{1}} ^{\\infty} \\lvert \\vec{E} \\rvert \\, dr = \\int _{R_{1}} ^{\\infty} \\frac{Q}{4\\pi\\varepsilon_{0}} \\frac{1}{ r^{2}} \\, dr = \\frac{Q}{4\\pi\\varepsilon_{0}} -\\frac{1}{r} | _{R_{1}}^{\\infty} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Q}{R_{1}} $$ **Densit√† superficiale:** Qui andiamo ad analizzare come cambia la distribuzione di densit√† superficiale per cose connesse, noi sappiamo per definizione che $$ \\sigma = \\frac{Q}{S} = \\frac{Q}{4\\pi R^{2}} \\implies Q_{1} = \\sigma_{1} 4\\pi R_{1}^{2} $$ Questo vale anche per $Q_{2}$ ossia abbiamo che $$ \\frac{\\sigma_{1}4\\pi R_{1}^{2}}{ \\sigma_{2} 4\\pi R_{2}^{2}} = \\frac{Q_{1}}{Q_{2}} = \\frac{R_{1}}{R_{2}} \\implies \\frac{\\sigma_{1}}{\\sigma_{2}} = \\frac{R_{2}}{R_{1}} $$ In cui la densit√† superficiale √® maggiore! Questo spiega anche i casi in cui pi√π √® piccola la superficie, la densit√† superficiale √® maggiore, e questo spiega il motivo per cui nei temporali non piace stare in cose sottili. Se il raggio di curvatura √® piccola, la carica sar√† molto pi√π densa. (punta = raggio di curvatura infinitesimo). Sembra in qualche modo questo concetto una naturale ottimizzazione che segue lola voronoi perch√© se una cosa √® appuntita, cambia in fretta, ha bisogno di pi√π punti per essere descritta, sembra che in modo naturale avviene anche in questo caso :).\nQuesta cosa funziona anche per la Terra stessa, e si potrebbe considerare come quantit√† infinita di carica, ed √® questo il significato di mettere a terra (si pu√≤ scaricare a terra carica in eccesso).\nPotenziale nei conduttori in equilibrio Potenziale interno al conduttore üü© Si pu√≤ dimostrare, senza molta difficolt√† che il potenziale √® sempre 0 all\u0026rsquo;interno del conduttore.\n$$ \\Delta V = V(A) - V(B) = \\int _{A}^{B}\\vec{E} \\cdot \\, d\\vec{r} = 0 $$ Perch√© il campo elettrico √® 0. -\nPotenziale sulla superficie üü© Per risultato precedente, √® sempre perpendicolare col campo, quindi √® sempre 0, perch√© stiamo considerando il prodotto coseno. Si pu√≤ concludere che in questo caso l\u0026rsquo;intera superficie √® equipotenziale. $$ \\Delta V = V(C) - V(D) = \\int _{C}^{D} \\vec{E} \\, d\\vec{r} = 0 $$ ","permalink":"https://flecart.github.io/notes/conduttori-elettrici/","summary":"Campo elettrico nei materiali Se prendiamo un conduttore, gli elettroni in questi materiali sono liberi, significa che sono liberi di muoversi come vogliono, si pu√≤ dire che \u0026ldquo;vadano in giro\u0026rdquo; (per esempio questo vale per il rame).\nil reticolo cristallino √® al struttura regolare che √® comune nei materiali, in cui gli atomi sono sempre a distanza costante (o comunque a pattern regolari) uno dall\u0026rsquo;altro $r$ per esempio.\nCampo e materiali (6) Schermatura del campo (!","title":"Conduttori elettrici"},{"content":"2 Storia 2.1 0: Computer Meccanici dal 1600 a oggi\n2.2 1: Computer a Valvole Principalmente i computer della seconda guerra mondiale\n2.3 2: Computer a Transistor Abbattere i costi\n2.4 3: Circuiti stampati Computazione parallela Multiprogrammazione (Caricamento di pi√π programmi) 2.5 4: VLSI Possibilit√† di creare tansissimi transistor\n2.6 5: Computer moderni 2.6.1 Computer Ubiqui 2.6.2 Computer invisibili 2.7 Velocit√† di calcolo 2.7.1 Flops and MIPS 3 CPU La struttura moderna degli elaboratori sono basati principalmente sull\u0026rsquo;architettura di Von Neuman, l\u0026rsquo;unica differenza √® che gli elementi di questa architettura.\n3.1 Struttura e funzione della CPU La CPU si pu√≤ dividere in tre parti principali:\nUna unit√† di controllo che coordina i processi Registri che immagazzinano temporaneamente piccole quantit√† di informazioni ALU che fa i calcoli ordinategli dalla CPU 3.1.1 Registri Principali Program Counter o Instruction Pointer Contiene un pointer all\u0026rsquo;istruzione da eseguire cos√¨ lo prende dalla memoria Instruction Register Contiene l\u0026rsquo;istruzione da eseguire Memory Address Register Prende l\u0026rsquo;indirizzo del contenuto interessante dalla memoria Memory Data Register Prende il contenuto dalla memoria Program Status Word Raccoglie lo stato di esecuzione del programma, se fallisce se tutto ok oppure se ci sono errori 3.1.2 ALU Aritmetic Logic Unit, √® la componente che fa i calcoli.\nPer sapere cosa deve fare, √® la Control Unit che collega certe vie dai registri all\u0026rsquo;ALU.\nA seconda del genere di architettura pu√≤ collegarsi direttamente in memoria (CISC) oppure sempre passando per i registri (solitamente RISC)\n3.1.3 Central Control Unit Il processore che decide cosa fare, se chiedere qualche altro pezzo dalla memoria seguendo il processo FDE Fetch Decode, Execute, oppure Scrivere qualcosa in memoria e cose simili.\n3.2 Filosofie Architetturali Complex Instructions Set Computer and Reduced Instructions Set Computer definiscono delle filosofie di architettura degli elaboratori differenti.\n3.2.1 CISC e microprogrammazione Utilizza una interpretazione che credo sia cosa a cui il prof. ha riferito come microprogrammazione, ovvero una programmazione delle istruzioni a livello molto basso.\nQuesto livello di interpretazione rallentava la macchina, perch√© non era direttamente eseguito sull\u0026rsquo;hardware. Inoltre la tendenza ad accedere direttamente la memoria **rendeva questo modello a volte imprevedibile in termini di tempo\nEsempio di microprogramma\nChiaro che se questo interamente fosse considerato una istruzione, ci sarebbe un alto bisogno di cicli di clock (diventarebbe in generale pi√π lento).\n3.2.2 RISC e peculiarit√† Una delle peculiarit√† principali delle architetture RISC √® il numero ridotto di istruzioni necessarie (che per√≤ erano molto veloci perch√© girava direttamente sull\u0026rsquo;hardware).\nInoltre ha introdotto un sistema load store con cui affacciarsi alla memoria.\n3.2.3 Alcuni confronti La filosofia attuale √® la RISC, per√≤ a causa della grande presenza di elaboratori CISC, si √® preferito creare architetture ibride che comprendano entrambi: presenza di istruzioni complesse che vengano eseguite su istruzioni harware di RISC. ‚Üí Minore ciclo di Clock e quindi maggiore velocit√†.\nLa differenza principale √® che CISC possiede istruzioni complesse molte dei quali vanno ad accedere la memoria (la parte lenta del processo) invece la RISC possiede soltanto i comandi load and store per accedere alla memoria, il resto delle istruzioni opera all\u0026rsquo;interno del microprocessore.\n3.3 Velocit√† CPU 3.3.1 Clock e Data Path Cycle Il significato di clock √® spiegato molto meglio nella sezione dei Circuiti Sequenziali\nClock √® tempo per l\u0026rsquo;istruzione pi√π corta, se fosse ancora pi√π corta √® molto probabile che la CPU verrebbe indotta in errori molto comuni per cui il computer non funzionerebbe pi√π (un istruzione viene eseguita quando il precedente non √® ancora finito).\nUna Data Path Cycle √® l\u0026rsquo;intero processo che comporta lettura dai registri, calcolo e registrazione del risultato\n3.3.2 Aumentare la velocit√† Ci sono delle soluzioni per rendere la CPU pi√π veloce:\nMigliori reti elettriche (agli informatici non interessa) Overclocking (per un p√≤) Memoria cache (spesso in RISC) Multi-core Pipelining Parallelismo Esattamente come una linea di assemblaggio di fabbrica, possiamo definire alcune parti per processi specifici. 3.4 Parallelismo Circa 3-4 volte pi√π veloce e poco costoso per crearlo, in quanto i pezzi sono efficienti, con pipeline di 5 sotto c\u0026rsquo;√® bisogno di una sola ALU a differenza di 5 per avere funzionalit√† simili.\n3.4.1 Pipelining Spesso alcune istruzioni sono ottimizzate in termini di tempo nel caso sia presente la pipeline o meno, per cui √® interessante poter averlo a mente. Parallelismo livello istruzione\nEsempio:\n5 step.\nCarica l\u0026rsquo;istruzione Interpreta l\u0026rsquo;istruzione Fetch dei dati necessari Esecuzione dopo aver ricevuto i dati Scrittura del risultato. Ogni singola istruzione passa ogni volta secondo questa pipeline, che lavorano in parallelo, velocizzando il CHIP.\n3.4.2 Multicore ~ SIMD \u0026amp; MIMD Ci sono dei computer moderni che contengono molteplici CPU uguali a quanto descritti in 3.1.1\nSIMD\nSingle instruction-stream multiple data-stream *Istruzioni a dati diversi: Tutte le CPU hanno lo stesso stream di dati (magari elaborazione immagini, un qualcosa di ripetitivo su stessa cosa)\nSi guadagna in control unit, unica, fetch unica.\nEsistono anche i processori vettoriali.\nDi solito questo genere di architettura sono utili per istruzioni uguali a dati diversi come l\u0026rsquo;elaborazione di un immagine\nMIMD\nLa differenza dal precedente √® che l\u0026rsquo;istruction stream √® multiplo, ma un p√≤ pi√π costoso perch√© ci sono molte CPU complete.\nAvere troppe CPU su una memoria condivisa non andrebbe bene, perch√© si dovrebbero aspettare. Meglio avere una rete fra CPU per cose grosse.\nCio√® se collegassi troppe CPU, probabilmente l\u0026rsquo;unico bus andrebbe in stallo perch√© tutti cercherebbero ad accedere alla stessa memoria, e le CPU dovrebbero attendersi fra di loro, cosa non buona per la performance.\n3.4.3 Rete di Computer Una soluzione che si solito viene utilizzata dalle grandi aziende o comunque chi possiede le risorse √® la costruzione di grandi reti di calcolatori che possano operare all\u0026rsquo;unisono, o comunque con certo criterio. Dovrebbero essere un sacco di CPU separate che comunicano con un computer centrale che agisce come da Unit√† di Controllo.\nDi solito Multi-core e reti di computer sono conosiderati parallelismo a livello processore\nLe redi di computer sono solitamente facili da costruire ma difficile da programmare, mentre invece un multicore √® difficile da costruire ma facile da programmare.\nInvece il pipelining √® considerato un parallelismo a livello istruzione.\n3.4.4 Prefetch-istruzioni Questa cosa √® molto simile al prefetch della Memoria cache.\nInstruction Fetch Unit sono elementi di Hardware che caricano l\u0026rsquo;istruzione successiva nel momento in cui la presente √® in esecuzione.\nQuesto avviene perch√© il caricamento dell\u0026rsquo;istruzione √® spesso molto lenta.\nQuesta instruction cache prefecht pu√≤ essere implementata a due livelli, Hardware o software.\n3.4.5 Pipeline (e salti) Esempio di pipeline\nL\u0026rsquo;esempio fatto qui √® gi√† considerabile come un primo passo di Pipeline, in cui molteplici passi possono essere fatti allo stesso momento dentro la CPU.\nSolamente la prima esecuzione servono 5-7 clock (a differenza delle parti), quindi basta un ciclo di clock per la fase pi√π lunga per essere sicuri, ecco che riusciamo a completare l\u0026rsquo;istruzione in modo molto pi√π veloce.\nSe una singola istruzione dovrebbe fare tutto, saremmo costretti a tenere un clock molto elevato e il computer nel complesso sarebbe molto lento.\nSalti\nSe faccio un salto allora c\u0026rsquo;√® un buco nel pipeline, ossia cose nel pipeline che non eseguono (perch√© devo saltare), cio√® fetch e decode di certe istruzioni non mi devono servire.\n(ho decodato una istruzione) ma nel frattempo ho gi√† caricato 4 e 5 che non mi servono!\n3.4.6 Predizione di salti Possiamo utilizzare certe euristiche (ragionamenti caso per caso) per predire alcuni salti.\nSalti all\u0026rsquo;indietro\nSi possono prevedere per cicli while e for dei salti all\u0026rsquo;indietro.\nPer salti incondizionati si pu√≤ mettere una instruzione NOP in modo che faccia salti incondizionati senza sprecare istruzioni.\nEsempio data race (read after write)\nAX = 0\nBX = 0\nDX = 0\nAX = DX + 1\nBX = AX - 1\nfetch a decode a, fetch b leggo DX (a) , decode b DX + 1 (a), leggo AX (b) MA STO LEGGENDO TROPPO PRESTO! Quindi devo chiudere AX ed aspettare che AX venga scritto\nA volte, tipico dei processori CISC, si tende a eseguire minicomandi in ordine diverso perch√© ritenuti pi√π efficienti, quindi si mischia un p√≤, proprio come intendi per combinatorio e la fai.\nEntra cisc ma esegue risc.\nEsiste una BPU¬†(Branch Prediction Unit), che cerca di predire l\u0026rsquo;esito di un salto, come spiegato in questa pagina di wiki e una BTP (Branch Target Predictor) che controlla le istruzioni nel ramo di arrivo (qui). Questi sono le componenti principali che determinano la predizione dei salti.\nIn alternativa si mettono dei NOP. o di arrivo (qui). Questi sono le componenti principali che determinano la predizione dei salti.\nIn alternativa si mettono dei NOP.\n","permalink":"https://flecart.github.io/notes/cpu-e-storia-degli-elaboratori/","summary":"2 Storia 2.1 0: Computer Meccanici dal 1600 a oggi\n2.2 1: Computer a Valvole Principalmente i computer della seconda guerra mondiale\n2.3 2: Computer a Transistor Abbattere i costi\n2.4 3: Circuiti stampati Computazione parallela Multiprogrammazione (Caricamento di pi√π programmi) 2.5 4: VLSI Possibilit√† di creare tansissimi transistor\n2.6 5: Computer moderni 2.6.1 Computer Ubiqui 2.6.2 Computer invisibili 2.7 Velocit√† di calcolo 2.7.1 Flops and MIPS 3 CPU La struttura moderna degli elaboratori sono basati principalmente sull\u0026rsquo;architettura di Von Neuman, l\u0026rsquo;unica differenza √® che gli elementi di questa architettura.","title":"CPU e storia degli elaboratori"},{"content":"8.1 Introduzione 8.1.1 Il problema che risolve Vogliamo cercare di creare un metodo matematico che sia utile per calcolare area di qualunque curva.\nL\u0026rsquo;idea principale per risolvere questo problema √® approssimare l\u0026rsquo;area, lo facciamo utilizzando rettangoli, la formalizzazione sar√† molto aiutata dal limite.\n8.1.2 Sottografico di funzione $$ A = \\{ (x,y) \\in \\R^2 | x \\in D(f(x)), 0\\leq y \\leq f(x)\\} $$ Praticamente sto prendendo tutti in punti positivi sotto al grafico.\n8.2 Somma di Riemann La somma di riemann sta alla base della definizione di integrale.\n8.2.1 Intuizione a rettangoli Vorremmo cercare di approssimare l\u0026rsquo;area del grafico utilizzando un sacco di rettangoli di stessa ampiezza\n8.2.2 Definizione (formula) Diviso l\u0026rsquo;intervallo di interesse, che chiamiamo $[a,b]$ con n intervalli di stessa lunghezza, e presa in questi $\\xi_k$ n punti a caso per ogni intervallo, allora consideriamo la somma di Riemann:\n$$ h = \\dfrac{b- a}{n},\\\\ S = \\sum_{i=1}^nf(\\xi_i) \\cdot h $$ 8.3 Integrale di Riemann 8.3.1 Criterio di integrabilit√† secondo Riemann Se una funzione √® continua su un certo intervallo, allora √® integrabile secondo Riemann qui\nDimostrazione (Non richiesta) Servono teoremi che non hai mai fatto tipo heine borel etc. 8.3.2 Osservazioni su questo integrale $\\int_a^af(x) = 0$ perch√© si pu√≤ notare che l\u0026rsquo;ampiezza del rettangolo √® 0, quindi sto sommando uno 0. Nel caso di funzione costante\u0026hellip;. bah non lo scrivo nemmeno perch√© se ragioni sulla somma di Riemann √® abbastanza banale. 8.3.3 Propriet√† dell‚Äôintegrale Linearit√† (se ho f, g continue sullo stesso intervallo, allora l\u0026rsquo;integrale della funzione somma √® uguale alla somma degli integrali singoli). (posso anche moltiplicare per un fattore e considerare la funzione fattore * f, o fattore * g).\nAdditivit√†, posso dividere l\u0026rsquo;intervallo su cui sto integrando come la somma di due intervalli che coprono tutto l\u0026rsquo;intervallo iniziale\nConvenzione: se b\u0026lt;a e ho un integrale tipo cos√¨ $\\int^b_a = -\\int^a_b$, ovvero cambio il segno. Questa convenzione mi permette di scriverlo per ogni punto (basta che sia continuo).\nMonotonia, (se ho due funzioni definite in un intervallo in cui entrambe sono continue tali che f \u0026lt; g, allora anche l\u0026rsquo;integrale possiede questa disuguaglianza).\n8.3.4 Teorema della media integrale In modo simile alla media finita, in cui andiamo a dividere il numero di addendi per il valore della somma totale, possiamo andare a definire una media anche per gli integrali.\nPartiamo dalla somma di Riemann, per poi andare dalla media integrale:\n$$ \\text{INTUIZIONE: }S_n = \\sum^n_{k=1} f(\\xi_k)\\dfrac{b-a}{n} \\implies \\dfrac{S_n}{b-a} = \\dfrac{\\sum^n_{k=1}f(\\xi_k)}{n} $$ $$ f:[a,b] \\to \\mathbb{R} \\text{ continua }\\\\ \\exists c \\in [a,b] \\, t.c. \\,\\\\ \\dfrac{1}{b-a} \\int_a^bf(x)dx = f(c) $$ Dimostrazione: Si utilizza il teorema del valore intermedio: qui in passato $\\exists x_0, x_1 \\in [a,b]$, questi sono scelti in modo tale per cui $f(x_0) = min, f(x_1) = max$ che √® effettivamente ci√≤ che dice weierstrass per l\u0026rsquo;estremo valore, poi utilizziamo la definizione di funzione per diree che esitono anche tali x0 e x1, per ricordarci delle loro propriet√† li chiamiamo m e M sotto. $$ \\exists m, M \\in [a,b]\\text{ che diano massimo e minimo per weierstrass, ovvero che:} \\\\ f(m) \\leq f(x) \\leq f(M) \\, \\forall x \\in [a,b] \\text{ utilizziamo la monotonia dlel'integrale} \\\\ \\int_a^b f(m)dx \\leq \\int_a^b f(x)dx \\leq \\int_a^b f(M)dx ,\\\\\\text{ noto che alcuni sono costanti, allora} \\\\ f(m)(b-a) \\leq \\int_a^b f(x)dx \\leq f(M)(b-a) \\implies f(m) \\leq \\dfrac{1}{b-a} \\int_a^b f(x)dx \\leq f(M) $$ Arrivati all\u0026rsquo;ultimo passo allora possiamo dire che esiste un tale c, grazie al teorema del valore intermedio.\nMini riassunto del valore intermedio (che serve qui)\nUna funzione continua su un intervallo per Weierstrass possiede un minimo e un massimo, grazie al teorema degli zeri possiamo costruirci una funzione tale per cui si annulli per qualunque punto all\u0026rsquo;interno di questo intervallo. Cio√® possiamo concludere che\n$\\forall y \\in [m,M], \\exists c \\in [a,b] | f(c) = y$\n8.4 Primitiva e f integrale 8.4.1 La primitiva Una primitiva F di una funzione f √® una funzione definita nello stesso intervallo tale per cui per tutti i valori si ha che F\u0026rsquo;(x) = f(x).\n8.4.2 Unicit√† della primitiva La funzione primitiva √® unica a meno di una costante, in un intervallo ben definito. Possiamo osservare che esistono infinite primitive aggiungendo costanti.\nMa si pu√≤ dire che questa funzione √® unica in quanto:\nDimostrazione\nSiano f e g primitive di una funzione a. Allora consideriamo la funzione h definita come f - g. √® chiaro che la sua derivata √® a - a, quindi 0, quindi la sua derivata √® sempre 0.\nPer una conseguenza del teorema di lagrange ho che h deve essere una constante. Per cui si ha la relazione f = g + C. e abbiamo trovato che le funzioni primitive sono tutte a meno di costante\nI capitoli sotto sono probabilmente utili per altre cose dopo\n8.4.3 La funzione integrale Sia f una funzione continua definita su un certo intervallo. sia c un punto in questo intervallo, allora posso avere una funzione I tale che\n$$ I_c(x) = \\int^x_cf(t)dt $$ Ovvero sto prendendo tutta l\u0026rsquo;area da un punto a un punto di input di variabile per una certa funzione. chiamo c punto base.\n8.4.4 Osservazione sulla funzione integrale (fondamentale 1) Sia $f$ continua su $(a_0, b_0)$ sia $c \\in (a_0, b_0)$ allora $\\forall x \\in (a_0, b_0)$ ho che $I_c'(x) = f(x)$\nAccenno di dimostrazione mia\nvogliamo f(x) continua e definita in un intervallo.\nLa funzione integrale sar√† fondamentale poi per il calcolo integrale. Possiamo relazionarla strettamente con la funzione primitiva, in quanto se fosse una primitiva, sarebbe uguale a un integrale che ci piace. Proviamo a giustificare questa cosa, proviamo a prenderne la sua derivata:\n$$ \\dfrac{I_c(x) - I_c(x_0)}{x - x_0} = \\dfrac{\\int^x_cf(x)dx - \\int^{x_0}_c f(x)dx}{x - x_0} = \\dfrac{\\int_{x_0}^xf(x)dx}{x - x_0} $$ E questa ultima cosa esiste, ed √® compresa fra il massimo e il minimo della funzione f(x) per il teorema della media integrale.\nNon siamo stati abbastanza formali per la dimostrazione di esistenza della derivata. Vogliamo dire che\n$$ \\lim_{x \\to x_0}\\dfrac{\\int_{x_0}^xf(x)dx}{x - x_0} = f(x) $$ Andiamo a dividere la dimostrazione di questo limite in limite destro e limite sinistro.\nVogliamo creare una successione (perch√© l\u0026rsquo;equivalente √® una cosa reale, si pu√≤ dimostrare).\nPer media integrale diciamo che $\\exists c, x_0 \\leq c \\leq x : f(c) = \\dfrac{\\int_{x_0}^xf(x)dx}{x - x_0}$ , riusciamo quindi per ogni succesione xn che tende a x0 trovare una successione cn che tenda a x0 per carabinieri, quindi esiste questo limite ed √® uguale a f(x), si fa la stessa cosa con l\u0026rsquo;altro.\nDimostrazione nelle note del prof\n8.4.5 Tutte le funzioni integrali di f differiscono per una costante Una cosa molto simile alle funzioni primitive! basta svolgere i calcoli in modo simile alla funzione integrale con c diversi üôÇ e ottengo che la loro differenza √® sempre una costante! Questo mi fa pensare che potrebbe essere una primitiva! E infatti per 8.4.4 lo √®\n8.4.6 Teorema di Torricelli (fondamentale del calcolo integrale) Enunciato\nData una funzione f definita in un intervallo aperto in R continua, e una altra funzione primitiva della prima F, allora si ha\n$\\int^b_af(x)dx = F(b) - F(a)$\nDimostrazione mia\nSia c un numero reale a Caso, sia $I_c(x)$ la funzione integrale relativa a $f$, per dimostrazione precedente ho che $I_c(x)$ √® una primitiva di $f$, allora per l\u0026rsquo;unicit√† della primitiva a meno di costante ho che $I_c(b) - I_c(a) = F(b) - F(a)$ (tolto costanti e simili)\n8.4.7 Fondamentale del calcolo generalizzato Enunciato\nSia $f: I\\to\\R \\text{ continua}\\\\ h: \\R \\to I \\text{ derivabile}$, vogliamo calcolare l\u0026rsquo;integrale di sopra. e sia $A_c(x)$ la funzione integrale\nAllora vale che $D(A(h(x)) = D(\\int_c^{h(x)}f(t)dt) = f(h(x))h'(x)$\nVorrei dimostrare in questo teorema la possibilit√† di valutare l\u0026rsquo;integrale con una altra variabile.\nad esempio come calcolare\n$$ \\int_c^{g(x)}f(x)dx $$ E vogliamo ricondurci a funzioni integrali normali.\nInnanzitutto proviamo a ricordare alcuni risultati passati (derivata di funzione composta e il fondamentale).\nRisultati passati utili ora\nSia I un intervallo di R, sia $I_c(x) = \\int _c^xf(t)dt$ per il teorema fondamentale ho che $I_c'(x) = f(x)$ in ogni punto.\nConsidero ora $H_c(x) = \\int_x^cf(x)dt$, questo, grazie alla convenzione sugli integrali √® uguale a $-I_c(x)$\nDimostrazione\nPrendiamo l\u0026rsquo;integrale\n$$ \\forall z \\in I, I_c(z) = \\int_c^zf(t)dt $$ Allora se semplicemente sostituisco h(x) a z, allora sto facendo questo\n$I_c(h(x)) = \\int _c^{h(x)}f(t)dt$, che non √® altro che una funzione composta.\nProviamo allora a prenderne la derivata, che per il teorema fondamentale del calcolo integrale √® f(x). Quindi\n$$ f(x) = I_c'(x) \\text{ dal teorema fondamentale} \\\\ D(I_c(h(x)) = h'(x)I_c'(h(x)) \\text{ dalla derivata di f composta} \\\\ h'(x)I_c'(h(x)) = h'(x)f(h(x)) \\text{ sostituendo} $$ 8.4.8 Integrale generalizzato (Integrale funzioni con discontinuit√†) !! Possiamo andare a definire un intervallo di integrazione infinito, come $0, +\\infty$, basta definirlo con un limite.\nse esiste il limite (altrimenti non √® definito) e si definisce in modo analogo per il infinito negativo.\n$$ \\lim_{z\\to+\\infty} \\int^z_af(x)dx = \\int^{+\\infty}_a f(x)dx $$ 8.5 Calcolo di integrali 8.5.1 Tabella degli integrali Sono pigro per scrivere tutti\n8.5.2 Funzioni composte siano due funzioni componibili (quindi dominio codominio compatibili).\nLa primitiva di una funzione\n$$ g \\cdot f = \\int g'(f(x))f'(x) $$ 8.5.3 Integrazione per parti notiamo che\n$D(F(x)g(x)) = f(x)g(x) + F(x)g'(x)$\nSe prendiamo ora l\u0026rsquo;integrale da entrambe le parti e giriamo un p√≤ di cose riusciamo a trovare l\u0026rsquo;integrale che cerchiamo, in questo senso\n$$ \\int f(x)g(x) = F(x)g(x) - \\int F(x)g'(x) $$ Questo √® dimostrabile grazie al teorema fondamentale, che dice qualcosa a riguardo la derivata di una primitiva √® la funzione integranda di un integrale.\nAlcune funzioni classiche che si fanno per parti\n$f(x) = xe^x$\n$f(x) = ln(x)$\n$x^n \\arctan(x)$\n8.5.4 Sostituzione (cambio di variabile) Un p√≤ di teoria:\nsia h una funzione doppiamente derivabile da I in J, e f una funzione continua da J a R, allora, dati alpha e beta in I, si ha questa relazione:\n$$ \\int_{h(\\alpha)}^{h(\\beta)}f(x)dx = \\int_\\alpha^\\beta f(h(t))h'(t)dt $$ La dimostrazione si ha con il teorema fondamentale dell\u0026rsquo;integrale generalizzato, pi√π precisamenta guardare il toggle sotto.\ndimostrazione\nVogliamo dimostrare che una funzione integranda in\nSiano F, G due funzioni da I a R, voglio dimostrare che\n$F(z) = \\int_{h(\\alpha)}^{h(z)} f(x)dx, G(z) = \\int_\\alpha^z f(h(x))h'(x)dx$ queste due siano uguali\nCerco di dimostrare che abbiano la stessa derivata (per cui le funzioni originali distano al massimo di una costante) e che siano uguali in un punto (per cui sono uguali ovunque).\nL\u0026rsquo;ultima tesi si fa in modo immediato perch√© sto provando ad integrale in un unico punti, quindi sono entrambe 0.\n$G'(z) = f(h(z))h'(z)$ per la prima versione del teorema fondamentale del calcolo\n$F'(z) = f(h(z))h'(z)$ per la dimostrazione precedente in questo passo, quindi sono la stessa funzione.\nQuesto termina la dimostrazione\nesempio (sostituendo con t^2)\n$$ \\int e^{\\sqrt{x}}dx = 2e^{\\sqrt{x}}(\\sqrt{x} - 1) + c $$ ","permalink":"https://flecart.github.io/notes/integrali/","summary":"8.1 Introduzione 8.1.1 Il problema che risolve Vogliamo cercare di creare un metodo matematico che sia utile per calcolare area di qualunque curva.\nL\u0026rsquo;idea principale per risolvere questo problema √® approssimare l\u0026rsquo;area, lo facciamo utilizzando rettangoli, la formalizzazione sar√† molto aiutata dal limite.\n8.1.2 Sottografico di funzione $$ A = \\{ (x,y) \\in \\R^2 | x \\in D(f(x)), 0\\leq y \\leq f(x)\\} $$ Praticamente sto prendendo tutti in punti positivi sotto al grafico.","title":"Integrali"},{"content":"Introduzione elettromagnetismo Note storiche: triboelettricit√† Il concetto di campo √® fondamentale per l\u0026rsquo;elettromagnetismo (vs forza in meccanica) da un punto di vista storico √® nato tramite l\u0026rsquo;osservazione in fenomeni come lo strofinio fra vetro e pelle, dopo il quale hanno osservato ci fosse una forza nascosta (appunto ombra dal greco di electron). Il vetro si caricava poi abbastanza da poter attrarre carta per esempio. esempio dell\u0026rsquo;esperimento. Se viene fatto invece fra due lastre in vetro invece diventa repulsiva invece che attrattiva. Questo effetto √® chiamato triboelettricit√†.\nDimensioni atomo Misure classiche dimensione atomo üü® Questa √® una piccolissima sezione per dare l\u0026rsquo;intuizione su quanto sia grande in generale un atomo, confronto fra protone ed elettrone: Forza di gravit√† vs elettromagnetico üü© TODO: in questa parte viene fatto un confronto fra quanto √® grande la forza di gravit√† contro la forza elettrica in un atomo Fatto da esempio 1.1 pagina 9 del Mazzoldi Abbiamo che la differenza in modulo della forza di gravit√† e forza elettrica sia molto differente (circa $10^{39}$ di differenza, quindi troppo per dire.)\nEsperimenti classici Elettroscopio a foglie üü© [Video per l'esperimento](https://youtu.be/XXVUuW5F0xU?si=eKnTMxnoIitJdTB_) in cui vengono presentati tre casi (e tre cariche risultanti diverse). avvicinando un oggetto carico, le foglie si separavano, questa √® una carica indotta dalla presenza di un altro oggetto, allontanando rimaneva poi uguale. Se tocco, caricher√≤ con la stessa carica del mi oggetto (scambio di elettroni) Se scarico a terra, la carica presente sar√† l\u0026rsquo;opposta. L\u0026rsquo;angolo di separazione fra le foglie hanno permesso di misurare la carica per la prima volta. (poi probabilmente qualcosa di meccanica per calcolare).\nBilancia a torsione üü©- Questo √® un setting un po\u0026rsquo; pi√π complesso anche se l\u0026rsquo;idea √® ancora quella presente in Elettroscopio a foglie di misurare un angolo per avere la distanza. video esempio.\nL'unica cosa importante era l'angolo di torsione, da cui si poteva dedurre la forza. Poi la palla blu √® di metallo, e si pu√≤ caricare. Proviamo a considerare il setting: Sappiamo che il momento torcente √® dato da $\\vec{m} = \\vec{R}\\vec{F}$ e si pu√≤ dire che in modulo abbiamo $\\lvert \\vec{m} \\rvert = \\frac{L}{2} \\lvert F \\rvert \\sin \\varphi$ (questo da semplice meccanica), ma poi abbiamo anche che il momento torcente del setting (quello che va in alto √® solamente $\\lvert \\vec{M} = k \\theta \\rvert$) Quando raggiunge l\u0026rsquo;equilibrio si avr√† $$ \\frac{L}{2} \\lvert F \\rvert \\sin \\varphi = k \\theta \\implies \\lvert F \\rvert = \\frac{2k\\theta}{L \\sin \\varphi} $$ Da cui si pu√≤ derivare la forza, e quindi sperimentalmente anche i valori di questa carica elettrica.\nLa legge di coulomb Enunciato a parole üü© Date due cariche elettriche poste a una distanza $r$, tra di esse esercita una forza che √® direttamente proporzionale al prodotto delle cariche ed inversamente proporzionale al quadrato della distanza, tale forza √® diretta fra la congiungente delle cariche elettriche, repulsiva se i segni sono concordi e attrattiva se discordi.\nI risultati di coulomb Grazie al suo lavoro metodico di sperimentazione √® riuscito ad elaborare la legge che viene presentata subito sopra, √® riuscito a ridurre il tutto a tre propriet√† fondamentali\nla forza √® diretta sulla congiungente A volte √® attrattiva, altre volte repulsiva Varia inversamente al quadrato della distanza e direttamente al prodotto (questo √® riuscito a farlo con palle di metallo che spezzano la carica in due) $$ \\lvert \\vec{F} \\rvert = k \\frac{Q_{0}Q_{1}}{r^{2}} $$ Con questa costante qui che non √® pi√π adimensionale come nel caso della costante elastica di torsione, ma √® stato nel tempo scoperto essere dipendente dalla costante dielettrica del vuoto, di cui capiremo un po\u0026rsquo; meglio quando andremo a parlare di dielettrici in seguito. Una analisi dimensionale ci dar√† che l\u0026rsquo;unit√† di misura di quello √® $\\frac{Nm^{2}}{C^{2}}$.\nCostante dielettrica del vuoto üü© Bisogna ricordarsi il valore della costante a memoria! Anche la sua dimensione!\nAltra analisi di cui non so la derivazione si avr√† che $$ k = \\frac{1}{4\\pi \\epsilon_{0}} = 8.99 \\cdot 10^{8} N \\frac{m^{2}}{c^{2}} $$ Mentre la $\\epsilon_{0}$ costante dielettrica del vuoto vale $$ \\varepsilon_{0}=8.85 \\cdot 10^{-12}\\frac{C^{2}}{N m^{2}} $$ Sulla carica Come propriet√† della materia Propriet√† (2) üü© La carica √® una propriet√† intrinseca della materia, esattamente come la massa, se consideriamo protoni ed elettroni, questi sono la pi√π piccola unit√† di carica possibile.\nCostante, questo significa che se il sistema √® isolato, la quantit√† di carica non cambia mai Invariante fra sistemi di riferimento, se lo guardo da un sistema di riferimento che si muove e non (quindi stiamo parlando di meccanica), questa carica non cambia. Subatomica (no) Si pu√≤ dire che un protone e un neutrone √® formato da quark, anche se non so esattamente cosa siano, puoi trovare una immagine negli appunti di Matti in questo modo:\nCarica protoni ed elettroni üü© Stiamo provando a rispondere alla domanda perch√© la carica di elettroni e protoni √® uguale? Proviamo a ragionare per assurdo, assumendo le costanti che conosciamo gi√† sopra nella sezione sui risultati di coulomb.\nSupponiamo ci sia una differenza di carica fra protoni ed elettroni, anche piccolissima, mettiamo caso sia $1.6 \\cdot 10^{-28}C$, e consideriamo due palle di ferro puro di massa $1Kg$ e raggio $1m$, allora dato che la $\\Delta q \\neq 0$ si avr√† una forza, che sar√† di $k \\Delta q \\frac{\\Delta q_{2}}{r^{2}}$, considerando che il ferro nella tavola periodica ha $Z=26$ ossia il numero totale di protoni e $A=55$, il numero di massa, avremo che $\\Delta Q = N_{protoni}\\cdot \\Delta q$, e da questo si pu√≤ ricavare un valore simile a $0,0455 C$, e considerando che $N_{p} = z \\cdot N_{atomi} = Z \\cdot \\frac{M}{A} N_{a}$ dove l\u0026rsquo;ultimo √® il numero di avocadro credo, la forza che sarebbe presente sarebbe di circa $1.7 \\cdot 10^{7} N$, e si avrebbe il terzo principio della dinamica, ma sperimentalmente non esiste questa forza\nPrincipio di sovrapposizione Enunciato del principio di sovrapposizione Questo √® uno dei metodi principali che sar√† utilizzato per calcolare il Campo elettrico, dice semplicemente che i vettori della forza di Coulomb si possono semplicemente sommare fra di loro $$ \\frac{1}{4\\pi\\varepsilon_{0}} Q_{p} \\sum_{i=1}^{N} \\frac{q_{i}}{r_{i}^{2}} \\hat{r}_{ip} $$ Questa stessa idea si pu√≤ utilizzare senza nessun problema anche nel caso in cui ho volumetti carichi\nDensit√† volumetrica di carica üü© $$ \\rho(\\vec{r}) = \\lim_{ \\Delta \\tau \\to 0 } \\frac{\\Delta q}{\\Delta \\tau} = \\frac{dq}{d\\tau} \\implies \\rho(\\vec{r}) d\\tau = dq $$ Andando a considerare gli infinitesimi\nDensit√† superficiale di carica üü© Il concetto √® uguale al precedente, solo che ora andiamo a considerare una superficie, e non un volume infinitesimale $$ \\rho(\\vec{r}) = \\lim_{ \\Delta s \\to 0 } \\frac{\\Delta q}{\\Delta s} = \\frac{dq}{ds} \\implies \\rho(\\vec{r}) ds = dq $$ Densit√† lineare di carica üü© Stesso concetto per la lineare, ma anche qui non lo riscrivo per√≤, scrivo per√≤ l\u0026rsquo;equivalente dell #Enunciato del principio di sovrapposizione per pi√π facile comprensione. $$ \\vec{F}_{l} = \\frac{1}{4\\pi \\varepsilon_{0}} Q_{p} \\int _{l} \\frac{\\lambda(\\vec{r})}{\\Delta r^{2}} \\hat{\\Delta}r \\, dl $$ Integrale lineare\n","permalink":"https://flecart.github.io/notes/legge-di-coulomb/","summary":"Introduzione elettromagnetismo Note storiche: triboelettricit√† Il concetto di campo √® fondamentale per l\u0026rsquo;elettromagnetismo (vs forza in meccanica) da un punto di vista storico √® nato tramite l\u0026rsquo;osservazione in fenomeni come lo strofinio fra vetro e pelle, dopo il quale hanno osservato ci fosse una forza nascosta (appunto ombra dal greco di electron). Il vetro si caricava poi abbastanza da poter attrarre carta per esempio. esempio dell\u0026rsquo;esperimento. Se viene fatto invece fra due lastre in vetro invece diventa repulsiva invece che attrattiva.","title":"Legge di Coulomb"},{"content":"Introduzione Digital modulation üü® Slide introduzione\nModulazione digitale: prendiamo un dato digitale e trasmesso con un segnale analogico, come le RF.\nASK: amplitude shift keying\nFSK: frequency shift\nPSK: phase shift\nQuesti sono i tre metodi principali, che dipendono dalle caratteristiche dell‚Äôonda descritte in Fisica del Wireless.\nTRE CARATTERISTICHE\nPower\nResistenza interferenze. (robustezza)\nANALOG MODULATION\nPer modulare un segnale analogico si utilizzano principalemente AM o FM, amplitude o frequency modulation, raramente si utilizza PM.\nIn AM la frequenza √® la stessa, ma posso cambiare la ampiezza, in pratica con l‚Äôampiezza provo a ricalcare l‚Äôampiezza dell‚Äôonda iniziale (credo che intuitivamente onda radio ha frequenza molto pi√π alta del suono, quindi riesco a descriverlo bene, credo, probabilmente sbaglio).\nModello trasmittente e ricevente üü© Struttura trasmittente\nIl primo prova a rappresentare il segnale digitale in un segnale sinusoidale. (probabilmente trasformate here).\nIl secondo blocco prende la codifica in segnale analogico e la trasforma in una onda radio (modulata in un certo modo). (prende in input anche il canale in cui codificare le cose), e questa √® data all‚Äôantenna che genera RF.\nStruttura ricevente\nIl segnale nel frattempo:\nHa perso intensit√† Pu√≤ avere shift di fase a seconda dei rimbalsi Dal ricevente modula l‚Äôonda radio che riceve in un segnale analogico, che ora per√≤ possiede itnerferenze quindi non √® una onda clean, e prova a fare una interpretazione.\nAlgoritmi di modulazione digitale In questa sezione andiamo a presentare tre metodi principali di implementazione della modulazione che sono in ampiezza, in frequenza e in fase. Questi sono metodi per rappresentare 0 o 1 per dire.\nASK FSK PSK üü© Nella parte tagliata c‚Äô√® scritto ‚ÄúSignal modulation (Shift keying)‚Äù\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Modulazione wireless/Untitled 3.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Modulazione wireless/Untitled 3\u0026quot;\u0026gt; ASK\nLa tecnica pi√π semplice √® amplitude shift keying (aka modulazione digitale con amplitude) che non √® altro che trasmettere onde di frequenza precisa per canale per 1 silezio per 0. (ma come faccio a gestire le interferenze? Non c\u0026rsquo;√® silenzio in questo modo!) Credo che questo sia molto simile al morse.\nAd esempio se la distanza √® troppo larga, leggerebbe 0.\nSe il rumore di fondo √® troppo alto leggerebbe 1. ecco interferenze\nFSK\nIl segnale digitale √® codificato attraverso la frequenza del valore, per esempio se utilizziamo una metafora fisica, se il segnale √® rosso ho 1 se viola 0, cambia colore diciamo :).\nQuesto √® pi√π resistente alle interferenze.\nPSK\n√à pi√π difficile da implementare. Viene mantenuta sia la frequenza sia l‚Äôampiezza.\nRappresentazione del segnale üü© Slide rappresentazione\nTre tipologie di grafici, la terza, in cordinate polari √® la pi√π utilizzata, anche se non ci dice la frequenza (la frequenza √® quella mantenuta durante la radio carrier nel sistema di modulazione accennato prima). I punti su questo grafico sono chiamati simboli\nNella sconda perdiamo la fase, poco utilizzata.\nNella prima ha praticamente tutte le infomrazioni (la fase per√≤ credo sia solo relativa).\nBinary Phase Shift Keying e QPSK üü© Slide BPSK e QPSK\nAbbiamo dato ai simboli del grafico alcuni valori binari, questo ci da un modo per andare a interpretare i segnali seguendo quel grafico.\nQAM and HIerarchical modulation üü© Solo che la densit√† dei simboli √® ora ancora maggiore, utilizzo sia intensit√† sia fase\nSlide QAM\nHIERARCHICAL MODULATION\n√à una cosa ancora pi√π precisa!\nSlide HM\nSi utilizza un trucco di codifica di utilizzo della nuvola di segnali e una codifica interna!\nQuesot si utilizza anche per mobile video call in modo che la voce sia codificata meglio.\nSlide mobile video call nice\nSpread spectrum techniques Solitamente potremmo utilizzare delle narrow-band spectrum, solo che queste sono molto sensibili ad interferenze nella narrow-band, per questo motivo si preferisce andare su spread spectrum e andiamo ora a parlare di alcune tecnologie utilizzate per questo. Wireless attack vectors.\nDirect sequence spread spectrum üü©- In pratica vado a definire una chipping spectrum che possiede certe propriet√† statistiche che vengono interpretate come rumore di sottofondo (non correlate fra di loro) nel caso in cui non si conosca il codice.\nSlide funzionamento del chipping sequence\nLa codifica col chiping sequence non √® altro che un xor, con il bit che vogliamo inviare e la chipping sequence\nSlide codifica e decodifica del codice\nQuesto processo di xor √® descritto sotto in Code division multiple access üü©. √à questa tecnologia di code division multiple access. che permette questa trasmsisione su frequenze molto diverse, ed essere comunque ricevuto.\nCode division multiple access üü© Fa s√¨ che utilizzando chipping sequence poco (preferibilmente niente) correlate fra di loro, il segnale viene interpretato come segnale di sottofondo (white noise) e quindi il ricevitore, come per magia, riesce comunque a comprendere il segnale iniziale.\nEsempio di trasmissioen corretta di CMA\nPraticamente a lato ricevente esiste un integratore che fa la somma e viene utilizzato questo per andare a decidere se √® un bit 0 oppure 1 (per comodit√† solitamente lo 0 viene codificato come se fosse un -1).\nFrequency hopping spread spectrum üü© Viene utilizzata l\u0026rsquo;energia per mandare in modo pseudorandomico (secondo il seed, credo ne abbiamo gi√† parlato in precedenza con la cosa di hedy lamarr).\nSlide FHSS\nPraticamente il segnale √® unico (cio√® non √® disperso su una banda larga di segnale, ma √® narrowband) comuqnue per chi non conosce il codice sembra rumore di fondo\nSi utilizza host_master come seed\nFast and slow hopping a seconda del numero di bit mandati prima di switchare segnale.\nOrthogonal Frequency Division Multiplexing üü© signal transmission technology that separates a single high-speed data stream into multiple sub-carrier signals that are transmitted simultaneously. Each sub-carrier signal uses a different frequency, presenting a unique path for data transfer. By using multiple sub-carriers in a single channel, OFDM technology can transmit data more efficiently and reliably, even in noisy and highly congested RF environments\nAbbiamo pacchetti di dati poco distanziati (quind il bitrate nominale √® molto alto, tutto viene fatto in parallelo).\nSlide OFDM\nEsempio\nSTRUTTURA\nQuattro carrier sono utilizzati per gestire il canale quindi per dire che il canale non va, bisogna cambiare, rallentare etc. In modo simile ai pacchetti di gestione della congestione nei routers.\n√à molto efficiente dal vista del bandwith (servono 9.76 kilohearz per un sub carrier) e se ho 20 Mhz ho 2048 subcarrier (questo ci fa venire in mente il perch√© √® lungo quella quantit√† di band withd :D)\nLa cosa bella √® anche l‚Äôindipendenza con i subcarriers!\n1 milione per ogni subcarrier (basta fare qualche calcolo, tipo massimo di tutti i canali sono circa 3 Gbit per questa tecnologia). questa √® WiMax\nSlide WiMax\n250k bit per subcarrier che sono comunque 500 Mb su distanza larga.\nFunzionamento di OFDM üü® Si utilizzano magie matematiche per questa tecnologia, ed √® molto intelligente :D\nAbbiamo un teorema che ci dice che le funzioni di seno e coseno sono tutte fra diloro ortogonali ossia l‚Äôintergrale del segnale √® sempre 0 sopra il periodo di tutti.\nSlide segnali ortogonali\nQuesto permette di sapere che la somma di tutti gli altri segnali danno somma zero e io so in che modo andare a leggere. In questo senso i segnali interferiscono s√¨, ma lo fanno in un modo predicibile che mi permette di ritrovare la informazione iniziale.\nEsempio decodifica\nIntuitivamente le FFT ci permettono di cambiare frame of view, se prima erano tutte compattate sul tempo, ora √® compattato sulla frequenza, per questo motivo riuscimo a distinguerle per bene (quindip ossiamo distinguere anche il bit trasmesso per il singolo subcarrier)\n20Mhz con 52 subcarrier con 4 pilot e il resto dei dati. e utilizza 250k modulazioni l secondo (questo √® il massimo!).\nNelle slides c\u0026rsquo;√® una D, che sta per differential, perch√© sta relativo al precedente (non √® 0, o 180, ma √® differenza rispetto al precedente credo, ma comunque ha detto che non √® per niente importante questa cosa. Esistono bits di convoluzione che sono utilizzati per fixare errori di trasmissione.\nESEMPI:\nSlide OFDM\nEsempio per DBPSK: 1 bit per 48 subcarrier, la met√† sono utilizzati per dato, l\u0026rsquo;altra per protezione, ho 24 carriers per durata, quindi 24 * 250k bits al secondo che √® proprio 6kk!\nSe prendo DQPSK allora ho 3/4 per dati, e questo fa tanti calcoli, ma poca roba..\nUna cosa che accade con 64 QAM che invece di fare 1/2 di protezione viene fatto solamente un terzo perch√© se raggiungi quel punto vuol dire che il canale √® gi√† molto forte.\nE c‚Äô√® un programma di controllo che decide quale codifica andarea d utilizzare (tornando indietro se non (riceve gli acks)\nNel caso io abbia bisogno di ancora altri bit potrei aggiungere altri subcarriers (e si pu√≤ fare in modo dinamico, si chiama channel bonding. (canali di frequenza arbitraria in base a quanto ne ho bisogno ! esempi di tecnologie che lo utilizzano: 802.11 af ac)\n","permalink":"https://flecart.github.io/notes/modulazione-wireless/","summary":"Introduzione Digital modulation üü® Slide introduzione\nModulazione digitale: prendiamo un dato digitale e trasmesso con un segnale analogico, come le RF.\nASK: amplitude shift keying\nFSK: frequency shift\nPSK: phase shift\nQuesti sono i tre metodi principali, che dipendono dalle caratteristiche dell‚Äôonda descritte in Fisica del Wireless.\nTRE CARATTERISTICHE\nPower\nResistenza interferenze. (robustezza)\nANALOG MODULATION\nPer modulare un segnale analogico si utilizzano principalemente AM o FM, amplitude o frequency modulation, raramente si utilizza PM.","title":"Modulazione wireless"},{"content":"Impostazione del problema Supponiamo di stare giocando a n slot machine contemporaneamente. Queste macchine hanno internamente un valore di reward che non conosciamo. Ad ogni step possiamo scegliere una singola macchina e andare a tirare la sua leva. Riceviamo il valore del reward nascosto con un p√≤ di rumore. Vogliamo capire nel lungo quale sia la strategia che possa dare migliore reward medio possibile.\nQuesto √® un semplice problema, ma lo possiamo considerare un fulcro molto importante per poter comprendere il problema del reinforcement learning.\nThe mathematical model Supponiamo che $\\{ \\mathcal{R}_{a} | a \\in \\mathcal{A}\\}$ dove $a$ √® l\u0026rsquo;index per una certa macchina, assumiamo che ogni slot machine abbia un certo reward non conosciuto dall\u0026rsquo;agente. $a$ √® l\u0026rsquo;azione, ossia su quale slot machine possiamo andare a giocare. L\u0026rsquo;obiettivo √® massimizzare il reward sul tempo, assumendo che $R_{t}$ sia il reward al tempo $t$. Per farlo abbiamo bisogno di trovare una policy. Teniamo sempre le definizioni di action value, optimal value.\nDef: Regret, action value and optimal value Action value $q(a) = E[R_t | A_t = a]$\nOptimal value $V = \\max_a q(a)$\nRegret Ossia rappresenta quanto potremmo fare meglio. $$ \\Delta_{a} = v_{*} - q(a) $$ Total regret $$ L_{t} = \\sum_{n=1}^{t} \\Delta_{A_{n}} $$ Ossia tutti i regrets per l\u0026rsquo;azione del tempo\nSoluzioni classiche Accenno soluzioni (vecchio, da riguardare) I metodi presentati sono\nOptimistic initial value Mean-reward UCB choice Mean-reward\nVogliamo cercare di capire quale sia il valore nascosto all\u0026rsquo;interno di questi cosi. Possiamo supporre di avere un valore di default per ogni slot machine. Poi la strategia seguir√† questo pseudo codice\ndef make_choice( extimate_r, # /*array of extimates*/, epsilon # /* exploration-exploitation balance */ ): x = random_sample from 0 to 1 // uniform distribution if (x \u0026lt;= epsilon): // explore idx = random choice x from all r else: idx = argmax(extimate_r); return idx; Dopo aver fatto la scelta, cercheremo di aggiornare il valore del reward seguendo proprio la media, quindi\n$R_k = (r_k + \\dfrac{1}{(k -1)} R_{k - 1}) / k$, con rk il reward attuale e quella il nuovo robo, anche se solitamente questa formula la si trover√† scritta in questo modo, perch√© pi√π carina\n$$ R_k = R_{k - 1} + \\dfrac{1}{k}( r_k - R_{k - 1}) $$ Questo √® il classico reinforcement learning per sta roba. UCB cambia solo nella selezione dell‚Äôindice da esplorare, che lo fa con la formula dipendente dal numero di esplorazioni fatte su questo, sugli altri nodi e simili.\nmentre il optimistic initial value √® molto particolare, si assegna un valore molto ottimistico, poi 0 al valore epsilon per l‚Äôesplorazione, poi piano piano tutte le mosse scendono di valore, fin quando non diventano realistiche.\nGreedy solutions Estimate of the average $$ Q_t(a) = \\frac{\\sum_{n=1}^t I(A_n = a) R_n}{\\sum_{n=1}^t I(A_n = a)} $$ Questo si pu√≤ fare anche in modo incrementale:\n$$ Q_{t}(A_{t})) = Q_{t- 1} (A_{t} + \\alpha_{t}(R_{t} - Q_{t - 1} (A_{t}))) $$ Dove l\u0026rsquo;ultima parte √® un errore. e $\\alpha_{t} = \\frac{1}{N_{t}(A_{t})}$\nGreedy solution La parte greedy prende solamente l\u0026rsquo;azione che massimizza il valore atteso per l\u0026rsquo;azione. Quindi $$ A_{t} = arg\\max_{a} Q_{t}(a) $$ Il problema √® che questo non esplora. Potrebbe trovare il minimo e restare in quello perch√© la sua stima √® quella.\nEpsilon greedy solution La epsilon greedy prova a risolvere questo, tenendo una probabilit√† di esplorare. Uniform $\\varepsilon$, e con questa probabilit√† si fa qualcosa random, e in questo modo si aggiorna il resto. $$ \\pi_{t}(a) = \\begin{cases} (1 - e) + \\frac{e}{|A|} \u0026 \\text{if } Q(a) = \\max_b Q(b) \\\\ \\\\ \\frac{\\varepsilon}{\\lvert \\mathcal{A} \\rvert } \u0026 \\text{otherwise} \\end{cases} $$ Questo dovrebbe essere l\u0026rsquo;algoritmo utilizzato per Atari. Problema √® che continua ad esplorare anche se ha raggiunto convergenza buona della stima\nGradient Based Policy search Action preferences proviamo a stimare $$ \\pi(a) = \\frac{e^{H_{t}(a)}}{\\sum_{b} e^{H_{t}(b)}} $$ Utile per avere distribuzioni di probabilit√†. Vogliamo trovare action preferences per policies migliori. Questo ci permette di utilizzare gradient ascent per migliorare il $\\pi$.\nAbbiamo quindi $$ \\theta_{t + 1} = \\theta_{t} + \\alpha \\nabla_{\\theta}\\mathbf{E}[R_{t} | \\pi_{\\theta_{t}}] $$ E ci permette di fare gradient ascent. Abbiamo un problema di come fare sample.\nUsiamo (Williams 1992). Chiamato anche Reinforce. Da quello e da questo punto della lezione deriviamo $$ \\nabla_{\\theta}\\mathbf{E}[R_{t}|\\theta] = \\nabla_{\\theta}\\mathbf{E}[R_{t}\\nabla_{\\theta}\\log \\pi_{\\theta}(A_{t})] $$ E si pu√≤ fare classico gradient ascent con la parte dentro all\u0026rsquo;argomento.\nProviamo avere questo algoritmo per action preferences $$ H_{t+1}(a) = H_{t}(a) + \\alpha R_{T} \\frac{\\delta \\log\\pi_{t}(A_{t})}{\\delta H_{t}(a)} = H_{t}(a) + \\alpha R_{t} (\\mathbb{1}(a = A_{t}) - \\pi_{t}(a)) $$ √à un esercizio provare a derivare questo cosa.\nThe upper confidence bound L\u0026rsquo;idea √®\nSelezionare se l\u0026rsquo;azione √® big reward Selezionare se l\u0026rsquo;azione non √® ancora stata esplorata abbastanza Quindi come per il precedente, che vogliamo esplorare ancora, con la differenza che per√≤ vorremmo diminuire la possibilit√† nel caso fosse esplorata abbastanza\nL\u0026rsquo;algoritmo sembra poi molto simile ai greedy, solo che abbiamo una funzione di UCB in pi√π. Logarithmic regret as upperbound! (Auer et al 2002 questa roba).\nHoeffding\u0026rsquo;s Inequality How wrong is our extimate? Consider $X_{1}, X_{2}, \\dots, X_{n}$ variabili randomiche in 0, 1 con una certa media. rappresenteranno il nostro reward, e assumiamo che $\\bar{X}$ ma media fino a $n$, in un certo senso simile ai bounds che stavamo studiando in Central Limit Theorem and Law of Large Numbers. La differenza con Markov e Chebicheff √® che qui scende in modo esponenziale.\n$$ p\\left(\\overline{X}_{n}+u\\leq\\mu\\right)\\leq\\,e^{-2n u^{2}} $$ Questo √® un caso particolare in cui $b = 1, a = 0$ e funziona.\nPossiamo utilizzare questo teorema con $R_{t}$, infatti possiamo vedere che $$ p(Q_{t}(a) + U_{t}(a) \\leq q(a)) \\leq \\exp(-2N_{t}(a) U_{t}(a)^{2}) $$ E vale per qualche motivo strano anche con la - $$ p(Q_{t}(a) - U_{t}(a) \\geq q(a)) \\leq \\exp(-2N_{t}(a) U_{t}(a)^{2}) $$ Questo teorema giustifica perch√© vogliamo scegliere il bound come questo valore:\n$$ U_{t}(a) = \\sqrt{ \\frac{-\\log p}{ 2N_{t}(a)} } $$ $p$ possiamo stimarlo come il numero di volte che prendiamo quel valore nella nostra ricerca, quindi $p = \\frac{1}{t}$ . Questo √® la spiegazione teorica del perch√© il branch di esplorazione che abbiamo fatto durante il primo anno per il progetto di algoritmi funziona.\nLai and Robbins on Regret growth $$ \\lim_{ t \\to \\infty } L_{t} \\geq \\log t \\sum_{a| \\Delta_{a}} \\frac{\\Delta_{a}}{KL(\\mathcal{R}_{a} \\mid\\mid \\mathcal{R}_{a^{*}})} $$ Ossia il total regret √® bounded sotto almeno logaritmica-mente! Quindi se riesco a boundarlo sopra ho la cosa tight.\nDerivation of the algorithm Consideriamo $L_{t}$ che √® il total regret numero di volte che selezioniamo l\u0026rsquo;azione, per il regret atteso. $$ L_{t} = \\sum_{a} N_{t}(a) \\Delta_{a} $$ E vorremmo che questa cosa sia il pi√π basso possibile affinch√© possa risultare utile. Supponiamo che sia bounded. Ossia che per ogni $a = a^{*}$ valga $N_{t}(a) \\Delta_{a} \\leq x_{a} \\log t$ .\nVorremmo trovare con una versione di UCB, che ci serve per selezionare l\u0026rsquo;azione.\nOra prendiamo $m \\leq t$ allora dovrebbe valere che $N_{m}(a) \\Delta_{a} \\leq x_{a} \\log m \\leq x_{a} \\log t$\nProbability Matching and Thompson sampling Vogliamo scegliere l\u0026rsquo;azione che possa sembrare la migliore secondo la nostra credenza: $$ \\pi_{t}(a) = p\\left(q(a) = \\max_{a'}q(a') | \\mathcal{H}_{t - 1}\\right) $$ Per calcolare questo si pu√≤ utilizzare Thompson sampling.\nSample $Q_{t}(a) ~~~ p_{t}q(a)$ Seleziona l\u0026rsquo;azione che massimizza $Q_{t}(a)$ per ogni $a$ all\u0026rsquo;interno di $\\mathcal{A}$. Questo si avvicina al limite teorico ottimo, quindi nice. Ma il problema √® che non sono scalabili questi algoritmi. References [1] Williams ‚ÄúSimple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning‚Äù Machine Learning Vol. 8(3), pp. 229\u0026ndash;256 1992\n","permalink":"https://flecart.github.io/notes/n-bandit-problem/","summary":"Impostazione del problema Supponiamo di stare giocando a n slot machine contemporaneamente. Queste macchine hanno internamente un valore di reward che non conosciamo. Ad ogni step possiamo scegliere una singola macchina e andare a tirare la sua leva. Riceviamo il valore del reward nascosto con un p√≤ di rumore. Vogliamo capire nel lungo quale sia la strategia che possa dare migliore reward medio possibile.\nQuesto √® un semplice problema, ma lo possiamo considerare un fulcro molto importante per poter comprendere il problema del reinforcement learning.","title":"N-Bandit Problem"},{"content":"Prendiamo La legge di Ampere-Maxwell $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$ E la legge di Faraday neumann Lenz $$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} $$ Con questi abbiamo le onde elettromagnetiche.\nNel vuoto possiamo dire che non abbiamo densit√† di corrente, per questo posso andare nel vuoto, sono due cose che si autosostengono. Sono simmetriche a meno di costante.\nQuesto ci dice che\nPreso un campo elettrico che varia nel tempo (tipo una carica oscillante). Questo mi dice che si genera un campo magnetico prima non esistente Questo campo che varia nel tempo va a creare un altro campo elettrico Quindi abbiamo un processo che continua cos√¨ all\u0026rsquo;infinito sostenendosi. In queste due equazioni abbiamo la luce. 2 circuitazioni 2 Leggi di gauss e le 4 equazioni di Maxwell sono in grado di descrivere tutti i fenomeni elettromagnetici.\nNote storiche dei progressi in elettromagnetismo Il risultato curioso il fatto che sembrasse relazionato alla velocit√† della luce quella costante. Poi 1885 Hertz dimostra l\u0026rsquo;esistenza delle onde elettromagnetiche (quindi soggetti ai fenomeni delle onde, come l\u0026rsquo;interferenza, e si capisce che sono la stessa cosa con la luce. Una altra cosa curiosa √® che tutto elettromagnetismo √® fatto senza sapere l\u0026rsquo;esistenza di elettroni (solo all\u0026rsquo;inizio del \u0026lsquo;900 abbiamo iniziato a comprendere meglio come sono fatti e sono iniziati anche prodotti forti con queste) 1930 Fermi a Roma ha fatto una conferenza per la scoperta dell\u0026rsquo;elettrone da Thompson (Rutherford ha scoperto di pi√π su atomi, il mini sistema planetario), in questa conferenza si studia i neutroni (che non esistevano), e si inizia a comprendere meglio la materia. Strana cosa era che dal nucleo venivano emessi elettroni (questo √® il decadimento radioattivo? Non si sapeva del neutrone, qui ).\nTeorema di Poynting Setting del problema üü© Consideriamo una distribuzione di cariche $dq = \\rho dt$ che dipende dalla posizione $\\rho = \\rho(\\hat{r}t)$, stessa cosa per la velocit√† in un campo elettromagnetico costante. Voglio sapere il **lavoro** e **potenza** fatto dai campi sulla carica. Applichiamo la legge di lorentz (ricorda Magnetismo) $$ \\vec{F} = q\\vec{E} + q\\vec{v} \\times \\vec{B} \\implies df = [\\rho \\vec{E} + \\rho \\vec{v}\\times \\vec{B}]d\\tau $$ Questa √® la forza esercitata sul volumetto $d\\tau$ Sapendo che la potenza √® relazionata alla forza in modo conosciuto, sappiamo che $$ dW = d\\vec{f} \\cdot \\vec{v} \\implies dW = [\\rho \\vec{E}\\cdot \\vec{v} + \\rho \\vec{v}\\times \\vec{B} \\cdot \\vec{v}]d\\tau $$ Possiamo notare che il campo B non fa lavoro, perch√© la forza √® perpendicolare al percorso (e lo si vede anche in formule, perch√© abbiamo un prodotto vettore seguito da uno scalare), da questo abbiamo che $$ dW = \\rho \\vec{E} \\cdot \\vec{v} d\\tau $$ Ora, sapendo che $\\vec{J} = ne\\vec{v} = \\rho \\vec{v}$ (la seconda parte vale perch√© $n$ √® il numero di particelle per unit√† di volume, mentre $\\rho$ √® la carica per unit√† di volume e assumendo la cosa corpuscolare √® solamente la somma) Allora abbiamo $$ dW = \\vec{J} \\cdot \\vec{E} d\\tau $$ Questa √® la stessa formula, calcolata in modo diverso in Leggi di Ohm quando calcolavamo la potenza\nDerivazione con Ampere e Faraday (tosta) üü® Usando la legge di Ampere-Maxwell, presente in Ampere e Faraday, possiamo continuare questa esplorazione. $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{d\\tau} \\implies \\vec{E}\\cdot[\\vec{\\nabla} \\times \\vec{B}] = \\mu_{0}\\vec{E}\\cdot\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{d\\tau} \\cdot \\vec{E} \\implies \\vec{J} \\cdot \\vec{E} = \\frac{1}{\\mu_{0}} \\vec{E}\\cdot[\\vec{\\nabla} \\times \\vec{B}] - \\varepsilon_{0} \\frac{\\delta \\vec{E}}{d\\tau} \\cdot \\vec{E} $$ Ora proviamo ad analizzarlo pezzo per pezzo, partiamo dalla parte magnetica e elettrica üü®\n$$ \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) = (\\vec{\\nabla}\\times \\vec{E}) \\cdot \\vec{B} - (\\vec{\\nabla} \\times \\vec{B}) \\cdot \\vec{E} \\implies (\\vec{\\nabla} \\times \\vec{B}) \\cdot \\vec{E} = - \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) + (\\vec{\\nabla}\\times \\vec{E}) \\cdot \\vec{B} $$ Ora utilizziamo la legge di Faraday in Magnetismo in forma differenziale e otteniamo $$\n(\\vec{\\nabla} \\times \\vec{B}) \\cdot \\vec{E} = - \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) + \\left( -\\frac{\\delta \\vec{B}}{d\\tau} \\right) \\cdot \\vec{B} $$ Questo risultato possiamo metterlo nella parte di sopra e cos√¨ abbiamo espanso la prima parte (urca quanti calcoli per√≤)\n$$ W_{\\tau} = \\vec{J} \\cdot \\vec{E} = -\\frac{1}{\\mu_{0}} \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) + \\frac{1}{\\mu_{0}} \\left( -\\frac{\\delta \\vec{B}}{d\\tau} \\right) \\cdot \\vec{B}\n\\varepsilon_{0} \\frac{\\delta \\vec{E}}{d\\tau} \\cdot \\vec{E} $$ Ora dobbiamo fare altre osservazioni strambe: üü©- $$ \\frac{\\delta B^{2}}{\\delta t} = \\frac{\\delta}{\\delta t} (\\vec{B} \\cdot \\vec{B}) = \\vec{B} \\cdot \\frac{\\delta}{\\delta t}(\\vec{B}) + \\frac{\\delta}{\\delta t}(\\vec{B}) \\cdot \\vec{B} = 2 \\vec{B} \\frac{\\delta}{\\delta t}\\vec{B} $$ Questo ci permette di sostituire nelle forme di sopra come derivate seconde:\n$$ W_{\\tau} = \\vec{J} \\cdot \\vec{E} = -\\frac{1}{\\mu_{0}} \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) - \\frac{1}{2\\mu_{0}} \\frac{\\delta B^{2}}{dt}\n\\frac{1}{2}\\varepsilon_{0} \\frac{\\delta E^{2}}{dt} $$ Questa √® la potenza trasferita dai campi elettrici e magnetici a un volumetto $d\\tau$ che si muove con velocit√† $v$ nello spazio.\nVogliamo sapere energia totale trasferita da $\\vec{E}$ e $\\vec{B}$ per far questo basterebbe integrare sul nostro volume:\n$$ \\int dW = \\int \\vec{J} \\cdot \\vec{E} , d\\tau = -\\int \\frac{1}{\\mu_{0}} \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) , d\\tau - \\frac{1}{2}\\int \\left( \\frac{1}{\\mu_{0}} \\frac{\\delta B^{2}}{dt}\n\\varepsilon_{0} \\frac{\\delta E^{2}}{dt}\\right) d\\tau $$ Proviamo ad utilizzare il teorema della divergenza perch√© gli integrali di volume sono brutti. Da questo sappiamo: $$ -\\int_{\\tau} \\frac{1}{\\mu_{0}} \\vec{\\nabla} \\cdot (\\vec{E} \\times \\vec{B}) \\, d\\tau = - \\int_{\\Sigma(\\tau)} \\frac{1}{\\mu_{0}}\\cdot (\\vec{E} \\times \\vec{B}) \\, d\\vec{S} $$ Quindi riscrivendo ancora abbiamo: $$ \\int_{\\tau} dW = \\int_{\\tau} \\vec{J} \\cdot \\vec{E} , d\\tau = - \\int_{\\Sigma(\\tau)} \\frac{1}{\\mu_{0}}\\cdot (\\vec{E} \\times \\vec{B}) , d\\vec{S}\n\\frac{1}{2}\\int_{\\tau} \\left( \\frac{1}{\\mu_{0}} \\frac{\\delta B^{2}}{dt} \\varepsilon_{0} \\frac{\\delta E^{2}}{dt}\\right) d\\tau $$ Attenzione: a volte tau √® usato come tempo a volte come volume (fai attenzione a distinguerli bene) Formulazione e interpretazione finale üü®+ $$ W = - \\int_{\\Sigma(\\tau)} \\frac{1}{\\mu_{0}}\\cdot (\\vec{E} \\times \\vec{B}) , d\\vec{S}\n\\frac{\\delta}{dt}\\int_{\\tau} \\left( \\frac{1}{2\\mu_{0}} B^{2} \\frac{\\varepsilon_{0}}{2} E^{2}\\right) d\\tau $$ Abbiamo due termini che descrivono il trasferimento di energia.\nEnergia trasferita alla distribuzione di carica dai campi $E$ e $B$, ossia abbiamo Il concetto di densit√† volumetrica di energia elettromagnetica, quella che abbiamo studiato separatamente in Condensatori nel vuoto e Geometrie di spire (tipicamente sono statici questi campi) $$ du = \\frac{1}{2\\mu_{0}} B^{2} \\frac{1}{2} \\varepsilon_{0}E^{2} $$ Che ha senso (somma di due energie, somma classica)), perch√© l\u0026rsquo;energia trasferita √® uguale al valore dei campi in un certo punto preciso (somma dell\u0026rsquo;energia dei campi E ed B dentro al volume). Si parla di integrale su una superficie chiusa che contiene il volume, e abbiamo un vettore perpendicolare ai campi $E$ e $B$, rappresenta flusso del vettore di Poynting, che √® una energia proveniente da fuori. (tipicamente sono onde elettromagnetiche, perch√© entrano, forniscono energia, ed escono) -\u0026gt; ONDA ELETTROMAGNETICA TRASPORTA ENERGIA. In pratica √® un Or logico, l\u0026rsquo;energia o √® presa da dentro, o da fuori, il primo termine √® il dentro, il secondo √® il fuori. Concettualmente √® semplice, la derivazione √® complessa e utilizza molte cose di algebra e analisi.\nIl vettore di Poynting üü© Possiamo definire ora il vettore di Poynting come $$ S' = \\frac{1}{\\mu_{0}} \\vec{E} \\times \\vec{B} $$ in un certo senso √® una densit√† superficiale di potenza elettromagnetica, perch√© per avere la potenza devo moltiplicare la superficie. Forse √® con questo che utilizzo per costruire pannelli solari, √® l\u0026rsquo;energia che riscalda al sole, che impatta superficie :D.\nEnergia per unit√† di tempo e superficie trasportata da una onda.\nQuantit√† di moto üü© Si pu√≤ dimostrare che √® $$ d\\vec{P} = \\mu_{0}\\varepsilon_{0} \\vec{S}' d\\tau $$ Quantit√† di moto per unit√† di tempo e volume! Per questo posso far muovere oggetti sparandoci laser!\nNel vuoto Abbiamo che $$ \\vec{\\nabla} \\cdot \\vec{E} = 0 $$ $$ \\vec{\\nabla} \\cdot \\vec{B} = 0 $$ $$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} $$ $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$ Consideriamo $\\vec{\\nabla} \\times \\vec{\\nabla} \\times \\vec{E} = -\\vec{\\nabla} \\times \\frac{\\delta \\vec{B}}{\\delta t}$ Si pu√≤ vedere che\n$$ -\\nabla^{2}\\vec{E} = - \\frac{\\delta (\\vec{\\nabla} \\times\\vec{B})}{\\delta t} = -\\mu_{0}\\varepsilon_{0} \\frac{ \\delta^{2}\\vec{E}}{\\delta t^{2}} $$ Che dovrebbe essere una equazione di onda.\nEquazioni di D\u0026rsquo;Alambert üü®- $$ \\nabla^{2}\\vec{E} = \\mu_{0}\\varepsilon_{0}\\frac{ \\delta^{2} \\vec{E}}{\\delta t^{2}} $$ E uguale per il campo magnetico: $$ \\nabla^{2}\\vec{B} = \\mu_{0}\\varepsilon_{0} \\frac{\\delta^{2}\\vec{B}}{\\delta t^{2}} $$ Queste si possono scomporre, e abbiamo equazioni differenziali al secondo grado: $$ \\frac{\\delta^{2}E_{x}}{\\delta x^{2}} + \\frac{\\delta^{2}E_{y}}{\\delta y^{2}} + \\frac{\\delta^{2}E_{z}}{\\delta z^{2}}= \\mu_{0}\\varepsilon_{0}\\frac{ \\delta^{2} \\vec{E}}{\\delta t^{2}} $$ In cui abbiamo anche la velocit√† di propagazione delle onde, infatti abbiamo che $$ \\mu_{0}\\varepsilon_{0} = \\frac{1}{v^{2}} \\implies v = \\frac{1}{\\sqrt{ \\varepsilon_{0}\\mu_{0} }} = c $$ Solo alla fine dell'800 si capisce che la luce √® questo.\nExtra: frontiers Ma ci sono alcuni problemi aperti. In gravitazione ho precessione di Mercurio che metteva sotto problema le predizioni della gravit√† di Newton.\nCarica accelerata emette energia (come fa a non collassare nel nucleo?).\nRadiazione corpo nero (problema di conservazione dell\u0026rsquo;energia (catastrofe ultravioletta)).\nNon si sa in quale sistema di riferimento C valga\nEspansione accelera\nNeutrini non hanno massa zero\nGalassia ruota in modo costante, nonostante rallentare.\nEnergia del vuoto predetto male da quantistica.\n","permalink":"https://flecart.github.io/notes/onde-elettromagnetiche/","summary":"Prendiamo La legge di Ampere-Maxwell $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}\\vec{J} + \\mu_{0}\\varepsilon_{0} \\frac{\\delta \\vec{E}}{\\delta t} $$ E la legge di Faraday neumann Lenz $$ \\vec{\\nabla} \\times \\vec{E} = - \\frac{\\delta \\vec{B}}{\\delta t} $$ Con questi abbiamo le onde elettromagnetiche.\nNel vuoto possiamo dire che non abbiamo densit√† di corrente, per questo posso andare nel vuoto, sono due cose che si autosostengono. Sono simmetriche a meno di costante.\nQuesto ci dice che","title":"Onde elettromagnetiche"},{"content":"Gestione del non determinismo Il modo pi√π facile per gestire il non determinsmo √® semplificare le grammatiche quindi andiamo a vedere metodi per fare ci√≤.\nSemplificazione grammatiche (5) Slide\nNo produzioni del tipo $A \\to \\varepsilon$ per bottom up (altrimenti va all‚Äôinfinito!) No produzioni unitarie, cos√¨ evito cicli in cui da A derivo s√© stesso. No simboli inutili No ricorsione sinistra (divergenza per top-down) Fattorizzazione della grammatica Eliminazione delel produzioni nulle Vogliamo creare un algoritmo utile ad eliminare le produzioni che non ci piacciono.\nFormalizzazione algo obiettivo !\nInsieme dei simboli annullabili üü© Vogliamo con questa parte definire in modo formale l\u0026rsquo;insieme dei non terminali che portano a produzioni di quel genere\nSlide definizione simboli annullabili !\nOssia una annullabilit√† in n passi, e andiamo ad indagare tutti i simboli che soddisfano queste cose.\nNOTA: nello step induttivo, un simbolo √® annulable solo se l‚Äôintera produzione √® annullabile (quindi tutte le cose in output.\nUna cosa del tipo $A \\to BC$ √® annullabile solo se lo sono entrambi (sia B che C).\nDerivazione grammatica annullabilit√† üü© Slide\nSlide esempio\nIntuizione\nIn pratica vado ad eliminare i non terminali in tutti i modi possibili, e vado ad eliminare quelle che poi vanno ad eliminare. In pratica mi vado a tenere tutte le configurazioni che posso attenere, annullando quello che si pu√≤ annullare.\nFaccio questa cosa per tutti!\nNota sul vuoto\nSe vogliamo che il nuovo linguaggio possa accettare il vuoto, allora basta aggiungere al non terminale iniziale la produzione dle tipo $S \\to \\varepsilon$, ma questo √® presente solo al primo!.\nProduzioni unitarie Vorremmo evitare le produzioni unitarie che portano a cicli perch√© altrimenti avrei dei cicli infiniti che non sono molto buoni per il parsing.\nDefinizioni utili\nCoppie unitarie üü© Slide\nIn pratica √® come se definissi una operazion per le coppie unitarie, e la chiudo per riflessivit√† e transitivit√†.\nAlgoritmo di eliminazione üü© Algoritmo per eliminare coppie unitarie\nPer la creazione della nuova grammatica, quello che faccio non √® altro che filtrare quelle che mi portano a coppie unitarie.\nOltre a questo faccio una copia‚Ä¶ Se guardi l‚Äôesempio comunque lo vedi un p√≤ meglio\nEsempio\nRimozione di simboli inutili Def generatore e raggiungibilit√† (2) üü© In questa sezione andiamo a definire alcuni concetti utili a definire l\u0026rsquo;inutilit√† di alcuni simboli\nSlide !\nCos√¨ andiamo a definire come simbolo utile simbolo generatore e raggiungibile.\nCos√¨ andiamo a racchiudere il concetto di simbolo che non genera nulla, come inutle\nEsempio in slide !\nCalcolo dei simboli generatori üü©- Slide !\nOssia se da un simbolo ricavo qualcosa che √® un generatore, allora questo √® un generatore!\nE posso creare un algoritmo ricorsivo che genera questi simboli, partendo dai terminali che sono sempre dei generatori\nCalcolo dei simboli raggiungibili üü®++ Slide\nIn pratica mi calcolo, ancora qui in modo ricorsivo, tutti i strumenti raggiungibili dal nodo di start, con qualcosa di simile a una dfs (aggiungo ai raggiungibili ogni non terminale figlio, e comincio ad esplorare questo non terminale).\nWrap-up (chiede) üü®+ Enunciato e dimostrazione\nL‚Äôalgoritmo √® molto semplice, √® costituito da due passi fondamentali:\nElimino tutti i simboli che non sono generatori Rimuovo tutti i simboli non raggiungibili Nota sull‚Äôordine\n√à importante eseguire le operazioni in questo ordine, altrimenti capita come in slide\nEsempio importanza di ordine\nEsempio pi√π tosto di applicazione di questo\nEliminazione rico sinistre Rico sinistre immediate üü® Slide\nL\u0026rsquo;idea √® spaccare la ricorsione sinistra in una altra produzione e un nuovo non terminale fittizzio che vado ad utilizzare come non terminale di supporto.\nEsempio di risoluzione\nPosso considerare queste immediate, quando non ho dei cicli chiari nelle ricorsioni sinistre, sotto proviamo a creare un algoritmo per risolvere ricorsioni sinistre con cicli.\nRico sinistre non-immediate üü•+ Esempio di non-immediato\nAlgoritmo di risoluzione O(n2)\nIn pratica provo a sostituire tutto quanto posso in modo greedy.\nEsempio di applicazione\nEsempio applicazione con tutto finora\nFattorizzazione üü© Slide problema generale\nL‚Äôintuizione per sta parte √® raccogliere le cose in comune. L‚Äôalgoritmo non va a far altro che guardare i prefissi, e prendere il pi√π lungo per ogni non terminale.\nAlgoritmo per fattorizzazione\nesempio di applicazione\nForme normali Chomsky üü©‚Äî Slide\nQuesta ci piace, perch√© le produzioni o sono di\nSIngolo terminale Doppio non terminale. Si pu√≤ notare che questa forma √® sia libera da epsilon sia sia libera da coppie unitarie.\nE si pu√≤ sempre trovare una grammatica in questa forma, questa cosa ci piace.\nGreibach üü© Slide\nAnche questa si pu√≤ sempre fare, ed √® una forma che ci piace perch√© non abbiamo derivazione ricorsive sinistre brutte che ci distruggono tutto.\n","permalink":"https://flecart.github.io/notes/semplificazione-grammatiche/","summary":"Gestione del non determinismo Il modo pi√π facile per gestire il non determinsmo √® semplificare le grammatiche quindi andiamo a vedere metodi per fare ci√≤.\nSemplificazione grammatiche (5) Slide\nNo produzioni del tipo $A \\to \\varepsilon$ per bottom up (altrimenti va all‚Äôinfinito!) No produzioni unitarie, cos√¨ evito cicli in cui da A derivo s√© stesso. No simboli inutili No ricorsione sinistra (divergenza per top-down) Fattorizzazione della grammatica Eliminazione delel produzioni nulle Vogliamo creare un algoritmo utile ad eliminare le produzioni che non ci piacciono.","title":"Semplificazione grammatiche"},{"content":" Programmare e dimostrare sono sostanzialmente la stessa attivit√† ~Coen\nMa non secondo l\u0026rsquo;industria\u0026hellip;\n4.1.1 Definizione e necessit√† Branca della linguistica, studia creazione di proposizione e il loro collegamento per la creazione di un periodo\nIn seguito la semantica d√† un metodo a queste proposizioni in modo che abbiano un senso.\nUtile o necessario per la definizione del linguaggio artificiale 4.1.2 Alfabeto, stringa, linguaggio e grammatica Alfabeto: Insieme non vuoto di simboli (che spesso sono diversi fra di loro) Stringa seguenza finita (vuoto √® possibile) di simboli $\\epsilon = \\varnothing$ Linguaggio: insieme di stringhe (di qualunque tipo, finito o infinito). Grammatica formalismo (un insieme di regole che lo rende finito) che definisce un linguaggio\n4.2 Backus-Naur Form Ora √® descritto anche in Descrizione linguaggio Indicato con BNF\n4.2.1 Perch√© BNF Una formalizzazione informatica che permetta l\u0026rsquo;elaborazione di grammatiche ‚Üí notazione per descrivere grammatiche\nNon √® l\u0026rsquo;unica ma per gli informatici √® la migliore.\n4.2.2 Caratteristiche Indichiamo con $(T, NT, X, P)$ rispettivamente T = l\u0026rsquo;alfabeto, l\u0026rsquo;insieme di simboli che usiamo NT √® un insieme di simboli diversi da T (insieme non terminale) Sono solamente ausigliari. X = qualunque elemento di NT, basta che sia iniziale P = simile alla grammatica, sono delle coppie come produzioni: comprendono:\nNon terminali Insieme di stringhe che contengono un p√≤ di tutto ,indicate con $\\omega_n$ Es. $(X, \\{\\omega_1 ...\\omega_n\\})$ √® una produzione.\nQuindi questi quattro elementi riescono ad identificare in maniera univoca la semantica di un linguaggio.\nCapiremo il senso di questa definizione per l\u0026rsquo;informatica fra poco.\nIndicazione Si pu√≤ indicare con $X ::= 0|0Y$ e simili, utilizzando solo per produzioni come coppie √® sufficiente per definire una sintassi BNF.\n4.2.3 Definizione di un linguaggio Di solito fra tutte √® sufficiente prendere le produzioni per dire un linguaggio.(ha senso supponendo che tutti i simboli della grammatica siano utilizzati)\nProcesso iterativo che parte dal non terminale e arriva a stringhe finite.\nDimostrare che 000 non appartiene a questo linguaggio\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sintassi e RI strutturali/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sintassi e RI strutturali/Untitled 1\u0026quot;\u0026gt; 4.3 Ambiguit√† in BNF 4.3.1 Definizione ambiguit√† Se si pu√≤ definire in due modi diversi la stessa parola, allora si dice che il linguaggio √® ambiguo.\n4.3.2 Soluzione ambiguit√† (3) Queste non sono sempre necessarie in ogni grammatica, ma sarebbero utili per la comprensione\nOrdine di precedenza per operatori Associativit√† per ogni operatore (cio√® se l\u0026rsquo;operatore prende solo a destra o da sinistra) Parentesi? Cos√¨ definisco un ordine di precedenza quindi risolvo le ambiguit√†, ma non dovrei fare in questo modo.\n4.4 Albero di Sintassi astratta Buona cosa potrebbe essere la pagina di wiki.\nAfferma che questo albero √® molto utile per il compilatore (cos√¨ capisce cosa stiamo provando a fare).\nUn approfondimento possibile per questi alberi √® la Contex-free-grammar ovvero come evitare l\u0026rsquo;ambiguit√† del linguaggio naturale. (simile a BNF).\n4.4.1 Definizione (4) Prima si deve trovare una BNF non ambigua, poi possiamo creare un albero di questo genere.\nDefinizione di albero di sintassi\nDi solito ogni linguaggio di programmazione √® prima trasformato in un albero di sintassi e in seguito il compilatore elabora su questa cosa.\n4.4.2 Ricorsivit√†: le sottoformule immediate Sono figli diretti, sottoformule immediate generate dal nodo padre.\nEcco una struttura di dati ricorsiva, impareremo a sfruttare questa caratteristica della ricorsione.\nQuesta sottostruttura ricorsiva √® molto utile perch√© so anche come √® stato ricavato, non solo so se appartiene o meno! Pi√π informazioni! Riusciamo ad assegnare un significato.\nLa cosa bella di questra struttura √® che possiamo utillizzare la stessa funzione (programma o quel che si voglia chiamarlo) per risolvere il problema su alcuni dati pi√π piccoli (sotto dati).\n4.5 Pseudo-linguaggio funzionale puro non tipato Altolivello- vicino dominio del problema, senza alcuni dettagli di implementazione (che far√† da solo).\nBasso livello- vicino al dominio della soluzione ossia tratta alivello vicino al computer.\nTutti questi linguaggi hanno un albero sotto, che cerca di utilizzare questa grammatica formale per capire ci√≤ che √® scritto.\n4.5.1 Significato del nome Pseudo linguaggio perch√© questo linguaggio non esiste realmente, √® solamente qualcosa di simile, di vicino al un linguaggio reale (meno sintassi diciamo)\nfunzionale si utilizzano funzioni, sia come input, output per memorizzare cose e simili\nPuro senza side effect, senza storare variabili e fare cicli while o for\nNon tipato senza che un compilatore si lamenti di come √® implementato il tipo, quindi maggiore astrazione anche da questo punto di vista\n4.5.2 Funzioni unarie (3) Le funzioni unarie sono definite da tre parti principali:\nIl nome della funzione Un pattern $\\omega$, di solito una stringa dell\u0026rsquo;alfabeto Variabili ‚Üí Non terminali Costruttori e simili ‚Üí terminali costruiti con la gramatica del linguaggio. Corpo, quello che √® dentro la funzione Chiamate ad altre funzioni Parametri formali e altre costanti Condizioni di control flow 4.5.3 Pattern matching Questa √® la definizione di matching\nIn modo intuitivo: Match = se $p$ terminale matcha $\\omega$ se partendo da $\\omega$ si pu√≤ creare $p$\nChiamate di funzione\nIn questo linguaggio funzionale, andremo ad utilizzare Haskell, la chiamata di funzione avviene per pattern match.\nPasso a sostituire i parametri formali a seconda di cosa matchi, ricostruendo tutto continuando.\n4.5.4 Side effects Questi linguaggi funzionali non devono avere side effects, ossia non devono accedere a locazioni di memoria fuori dal loro scope, o fuori dai propri parametri formali, quindi molto pi√π controllabile.\nMa questo significa che non abbiamo la libert√† di allocare memoria e simili.\n4.5.5 Potenza espressiva Noi non possiamo programmare tutto quello che la matematica pu√≤ fare.\nMa certe cose si possono fare in un linguaggio e non in un altro. Ma qualunque funzione in qualunque altro linguaggio potrebbe essere espresso nello pseudo-codice attuale (quando questa cosa accade Turing-completezza).\nMa dato che non abbiamo side effect non ci interessa I/O e video o simili.\n4.6 Ricorsione strutturale 4.6.1 Solito ragionamento per ricorsione Come di solito le ricorsioni, se √® un caso base allora risolvo subito, in modo diretto.\nAltrimenti risolvo ricorsivamente un sotto problema pi√π facile, ma √® ancora lo stesso problema, ecco perch√© strutturale ‚Üí Hanno la stessa struttura, quindi sto utilizzando la stessa funzione per risolvere lo stesso problema ma per input diversi.\nQuindi risolvo problemi pi√π piccoli e poi le ricompongo alla maniera iniziale.\nStrutture uguali (cio√® i sottodati devono essere ancora dei tipi dei dati iniziali, se ho in input lista di qualcosa e poi ho totalmente altro non posso fare). Risolvo cos√¨ problemi pi√π semplici in modo ricorsivo. 4.6.2 Errori comuni DI solito la ricorsione √® difficile perch√© le persone tendono a cercare di scoprire in che modo sia implementata la ricorsione, cio√® cercano di comprendere cosa faccia la ricorsione a livello troppo basso.\nChiamate ricorsive non sui sottoproblemi Struttura della ricorsione √® errata (usando produzioni inesistenti) Mancare di qualche produzione 4.6.3 Esercizi Ricorsione strutturale Questi esercizi sono importanti dato che poi all\u0026rsquo;esame dovrai risolvere qualcosa di simile!\nEs 1\n-- Problema 1: data una lista (di numeri) -- calcolare l\u0026#39;insieme potenza della lista Es 2\n-- Problema 1: data una lista (di numeri) -- calcolare la lista di tutte le permutazioni -- della lista in input -- Es: dato 1:2:3:[], restituire -- (1:2:3:[]):(1:3:2:[]):(2:1:3:[]):(2:3:1:[]): -- (3:1:2:[]):(3:2:1:[]):[] -- Soluzione: per l1 Es 3\nUno tostino come esercizio √® definire una funzione che ritorni vero se e solo se un elemento compare due volte nell\u0026rsquo;insieme.\nEs 4\nN ::= O | S N\ndove il simbolo terminale O rappresenta lo 0 e il simbolo terminale S, letto \u0026ldquo;successore\u0026rdquo;, dato un numero naturale N forma il numero naturale S N che segue N nella numerazione.\nEsempio: 3 viene rappresentato in base 1 come¬†S (S (S O)))¬†e 5 come S (S (S (S (S O)))).\nNota: la rappresentazione corrisponde al modo con cui i bambini imparano a contare, usando le dita. O √® il pugno chiuso e ogni S corrispondere ad aggiungere un dito.\nProblema 1: definire per ricorsione strutturale una funzione + sui numeri naturali in base 1 che ne implementi la somma\nEsempio:¬†S (S O) + S (S (S O))) = S (S (S (S (S O)))))\nSuggerimento: procedere per ricorsione strutturale sul primo argomento\nProblema 2:\ndefinire per ricorsione strutturale una funzione * sui numeri naturali in base 1 che ne implementi il prodotto\nEsempio: S (S O) * S (S O) = S (S (S (S O))))\nSuggerimento: per implementare il * potete usare il +\nProblema 3:\ndefinire per ricorsione strutturale una funzione ^ sui numeri naturali in base 1 che elevi il primo numero alla potenza indicato dal secondo\nEsempio: S (S O) ^ S (S (S O))) = S (S (S (S (S (S (S (S O))))))))\nSuggerimento: scegliere bene su quale input procedere per ricorsione strutturale\nQuesti dovrebbero essere difficili, se sai risolvere questi, dovresti essere in grado di farlo per tutti.\n4.7 Induzione strutturale Questa √® una tecnica dimostrativa per dimostrare che una struttura gode di una certa propriet√†. √à strettamente legata alla ricorsione perch√© la ricorsione √® il calcolo della soluzione mentre l\u0026rsquo;induzione la dimsotrazione della correttezza.\nQuesta forma di dimostrazione √® valida per ragioni molto simili alla ricorsione strutturale, perch√© ogni passo √® giustificato dal precedente, di cui il caso base √® assunto come vero.\nQuindi bisogna prima capire quali siano le differenze fra induzione e strutturale.\n4.7.1 Il procedimento L\u0026rsquo;output deve essere una dimostrazione Si suppone che valga per tutti i sottocasi di questo di input (in pratica uguale alla ricorsione, per tutti gli sottoinput immediati stiamo supponendo che valga) come in matematica puoi affermare che valga per tutti i numeri minori di n come ipotesi induttiva. 4.8 Confronto funzioni mate e info Questo paragrafetto si rif√† all\u0026rsquo;iniziale introduzione sui Logica meta-linguistica sui paradossi in matematica e informatica.\n4.8.1 Matematica Rappresentazione √® fatta con relazioni, sottoinsieme del prodotto cartesiano. Questa √® inefficiente dal punto di vista del calcolo in quanto non ci da un modo per creare un calcolo. (non posso scorrere perch√© le liste restano illimitate).\nSi in questo caso stai pensando alle Relazioni fra insiemi non al modo per calcolarle.\n4.8.2 Informatica Di solito gli algoritmi ragionano in modo simile in basi diverse, that is l\u0026rsquo;efficienza degli algoritmi √® molto simile in basi diverse, tranne in base 1 che √® esponenzialmente pi√π grande rispetto alle altre basi.\nEsempio di def. di funzioni somma\nO `+ m = m S n `+ m = S (n `+ m) ----- n +\u0026#39; ) = n n +\u0026#39; S m = S (n +\u0026#39; m) ------ O ``+ m = m S n ``+ m = n ``+ S m ------- n +\u0026#34; O = m n +\u0026#34; S m = S n +\u0026#34; m Queste sono quattro procedure di calcolo per la somma non uguali in quanto calcolano diversamente.\nIl prof. ha detto (non ho capito il motivo) per cui quelli con un singolo apice utilizzano la stack, mentre invece quelli con due apici utilizzano la heap), non ho capito perch√©, ma tanto lo spiegher√† ad architettura.\n4.8.3 Specifiche di funzioni Possiamo utilizzare le dimostrazioni per induzione strutturale per verificare la correttezza di una funzione.\nPer esempio una funzione di concatenzazione dovrebbe soddisfare questi teoremi\nDi cui il primo mantiene il numero , il secondo appartenenza, il terzo l\u0026rsquo;ordine.\n$|l_1 fl_2| = |l_1| + |l_2|$ $x\\in l_1 \\implies$ $l_1fl_2$ $\\forall n, n \\leq |l1| \\implies$ nth n l1 = nth n (l1@l2) $\\wedge$ $\\forall n, n\\leq |l2| \\implies$ nth n l2 = nth (|l+1| +n) (l1@l2) Se una funzione soddisfa questi teoremi allora possiamo definire in modo rigoroso una funzione.\nFunzioni helper per questo\ncat [] l2 = l2 cat (t:l) l2 = t:cat l l2 length [] = 0 length (n:l) = 1 + length l -- nth n l tira fuori n-elemento di l head [] = [] head (n:l) = n tail [] = [] tail (n:l) = l nth 0 l = head l nth (S n) l = nth n (tail l) nthCorto 0 (t:l) = t nthCorto (S n) (t:l) = nthCorto n l E poi dovrei verificare ogni singola funzione di questo\u0026hellip;\nSpesso nella vita reale non c\u0026rsquo;√® bisogno di questo, si scriva specifica parziale n) (t:l) = nthCorto n l ```\nE poi dovrei verificare ogni singola funzione di questo... Spesso nella vita reale non c\u0026rsquo;√® bisogno di questo, si scriva specifica parziale\n","permalink":"https://flecart.github.io/notes/sintassi-e-ri-strutturali/","summary":"Programmare e dimostrare sono sostanzialmente la stessa attivit√† ~Coen\nMa non secondo l\u0026rsquo;industria\u0026hellip;\n4.1.1 Definizione e necessit√† Branca della linguistica, studia creazione di proposizione e il loro collegamento per la creazione di un periodo\nIn seguito la semantica d√† un metodo a queste proposizioni in modo che abbiano un senso.\nUtile o necessario per la definizione del linguaggio artificiale 4.1.2 Alfabeto, stringa, linguaggio e grammatica Alfabeto: Insieme non vuoto di simboli (che spesso sono diversi fra di loro) Stringa seguenza finita (vuoto √® possibile) di simboli $\\epsilon = \\varnothing$ Linguaggio: insieme di stringhe (di qualunque tipo, finito o infinito).","title":"Sintassi e RI strutturali"},{"content":"This note will introduce the ideas presented by Vapnik, presented in (Shalev-Shwartz \u0026amp; Ben-David 2014) chapter 6. Briefly this says that infinite-size classes are indeed learnable.\nThis set of note is still a work in progress. But it\u0026rsquo;s very important for statistical learning theory.\nWe have that if $\\lvert \\mathcal{H} \\rvert \u003c \\infty \\implies vc(\\mathcal{H} \\rvert) \\leq \\log_{2} \\lvert \\mathcal{H}$ Example: if $\\mathcal{H}$ is the set of linear classifiers on $\\mathbb{R}^{d}$ then we have that the dimension is $d + 1$.\nif $vc(\\mathcal{H}) \u003c \\infty \\implies E_{m}(\\mathcal{H}) = \\sqrt{ vc(\\mathcal{H} / m) }$ which means every finite hypothesis set is learnable. $m$ is the size of our training set.\nEven if $vc(\\mathcal{H}) = \\infty$ there exists a class $C \u003e 0$ that makes it to be learnable. But I did not understood the details.\nReferences [1] Shalev-Shwartz \u0026amp; Ben-David ‚ÄúUnderstanding Machine Learning: From Theory to Algorithms‚Äù Cambridge University Press 2014\n","permalink":"https://flecart.github.io/notes/vapnik-chervonenkis-dimension/","summary":"This note will introduce the ideas presented by Vapnik, presented in (Shalev-Shwartz \u0026amp; Ben-David 2014) chapter 6. Briefly this says that infinite-size classes are indeed learnable.\nThis set of note is still a work in progress. But it\u0026rsquo;s very important for statistical learning theory.\nWe have that if $\\lvert \\mathcal{H} \\rvert \u003c \\infty \\implies vc(\\mathcal{H} \\rvert) \\leq \\log_{2} \\lvert \\mathcal{H}$ Example: if $\\mathcal{H}$ is the set of linear classifiers on $\\mathbb{R}^{d}$ then we have that the dimension is $d + 1$.","title":"Vapnik-Chervonenkis Dimension"},{"content":"Questa √® una necessit√† per stabilire il significato di una sintassi definiti.\n5.1 Verit√† e Realt√† La verit√† ha solamente senso quando lo si relaziona con un mondo sensibile, ossia il mondo che si pu√≤ percepire con i nostri sensi.\n5.1.1 Verit√† parametrica e assoluta Se un esperimento √® ripetibile all\u0026rsquo;interno del mondo sensibili allora questa √® considerata come una verit√† parametrica, ossia dipende da uno stato del mondo sensibile.\nverit√† assoluta come le costanti della fisica.\n5.1.2 Scienze pure e scienze molli La differenza fra queste due √® che le scienze pure non stanno parlando del mondo sensibile, ma crea un mondo a s√©, astratto, in cui ha senso tutto ci√≤ che viene detto riguardo a questo mondo preciso. Anche l\u0026rsquo;informatica √® teorica.\nMa cosa √® la verit√† senza il mondo sensibile? L\u0026rsquo;esempio che abbiamo fatto prima non funziona pi√π.\nLe scienze molli descrivono la realt√† sensibile mentre le scienze pure descrivono un mondo astratto inesistente nella realt√†. (quindi fisica non √® pura, secondo questo).\n5.1.3 Teoria matematica √à come una storia descritta prima: insieme di sentenze,connotazioni.\nEnti primitivi di un mondo Assiomi che valgono in certi mondi üí° Gli assiomi sono come le leggi fisiche di un mondo fantastico: descrivono delle regole che valgono in un mondo preciso, e quindi si possono derivare delle conseguenze e le interazioni fra queste. 5.1.4 Modello matematico Interpretare i concetti primitivi in modo che valgano tutti gli assiomi, questo √® il modello.\nQuindi il modello matematico √® una interpretazione degli enti primiti e edegli assiomi del mondo!\nNon √® definito a priori ma si d√† il senso\nEsempio in classe\nPer esempio il mondo con i numeri colorati, quella relazione resta la stessa, posso colorare come mi pare, allora la prima proposizione della slide sono falsi\nEsempio teoria e modello\n5.2 Il mondo Il mondo √® una descrizione completa delle caratteristiche e regole del mondo (quindi oggetti, leggi e simili). Ovviamente questa √® solamente una descrizione ipotetica in quanto non possiamo conoscere tutto di un mondo (non conosciamo tutto nemmeno nel mondo in cui viviamo).\nUn assioma √® valido solamente in alcuni mondi precisi, spesso ci interessa indagare solamente quei mondi. (√à utile indagare solamente un mondo in cui quel determinato assioma valga o meno.)\nIl concetto di verit√† non ha senso come concetto a s√© stante in quanto dipende dal mondo in cui la proposizione √® valutata\nLe teorie e i modelli matematici hanno senso solamente se interpretati in un mondo particolare. Da soli no. Una proposizione ha un concetto di verit√† solamente se ha poi senso all\u0026rsquo;interno del mondo.\n5.2.1 Conseguenza logica Data una teoria T(un insieme di sentenze) si dice conseguenza logica F di T quando F vale per tutti i modelli di T, ovvero in tutti i mondi in cui valgono le sentenze della teoria.\nDue cose:\nVera per tutti i modelli T Vera in tutti i mondi in cui le ipotesi G1 G2 etc √® vero, ossia tutti gli assiomi sono veri. Miniriassunto\nCon gli assiomi sto filtrando nei mondi in cui questi assiomi siano veri, quindi prendiamo solamente mondi in cui siano veri questi assiomi, con questi assiomi e enti primitivi creiamo un mondo. Allora poi possiamo avere una semantica, un modo di interpretare che √® il modello e da qua possiamo avere proposizioni e conseguenze logiche\nDetto in altri modi\nGli assiomi creano dei sottomondi in cui esse valgono (sto filtrando sui mondi).\nF (un insieme di modelli matematici) √® una conseguenza logica di T se vale in tutti i mondi in cui valgono tutte le ipotesi (assiomi) (sentenze) G1 G2 etc\u0026hellip; di T\nNota: pi√π ipotesi che ho, pi√π sto restringendo nell\u0026rsquo;insieme dei mondi, quindi avr√≤ pi√π conseguenze logiche, quindi diventa una cosa pi√π interessante.\n5.2.2 Equivalenza logica Due sentenze sono dette equivalenti se sono soddisfatte esattamente dagli stessi mondi. (ossia filtrano sugli stessi mondi) (assiomi rindondanti uno con l\u0026rsquo;altro)\nRelazione di equivalenza per equivalenza logica\nConsidera solamente i mondi in cui valgono\nNel secondo caso nella slide ho come ipotesi che entrambi hanno gli stessi mondi cin cui valgono, allora √® ovvio che si ha il contrario\nIn modo simile si ha per il terzo caso\n5.3 Valutazione della teoria Quando √® interessante?\nNon ha senso chiedersi se un assioma √® vero o falso, nemmeno se √® giusto o falso, ha solamente senso chiedersi se √® vero o falso in un mondo preciso. Vale allora la teoria di consistenza\n5.3.1 Inconsistenza di una teoria Una teoria √® inconsistente quando non ammette nessun modello. (ossia non ammette nessuna interpretazione degli enti primitivi in modo che valgano tutti gli assiomi)\nSi pu√≤ anche dire che l\u0026rsquo;assurdo √® conseguenza logica di una teoria inconsistente, quindi √® tutto vero, tutto vero per assurdo!?\nCi sono troppi vincoli, quindi sto parlando di niente (ho un insieme vuoto di modelli e quindi sto parlando del vuoto) (tutto √® conseguenza logica in questo caso)\nQuesto vale anche il contrario, per√≤ non √® dimostrabile in modo semplice anche l\u0026rsquo;altra freccia.\nQuindi se √® falso questo, allora ho almeno un mondo in cui tutto ci√≤ che ho √® vero! Quindi che sia consistente! (e poi la cosa bella sarebbe cercare le applicazioni pratiche di queste cose)\nLa Logica studia la conseguenza logica! Introduzione a Logica\n5.3.2 Interpretazione Si pu√≤ considerare interpretazione una funzione semantica che per ogni connotazione associa una unica denotazione, considerato un oggetto di un mondo preciso. (enti primitivi sono connotazioni di un mondo, considerati connotazioni atomiche).\nLa funzione di interpretazione √® descritta meglio in Logica Proposizionale\nLe connotazioni sono interpretate come denotazioni del mondo.\nPoi ci sono funzioni del mondo e simboli del mondo.\nDi solito le connotazioni composte sono ottenute da connotazioni atomiche (denotazioni del mondo) combinate tramite connettivi logici.\n5.4 Connotazione denotazione In informatica sono sintassi e semantica. Sar√† ci√≤ che mi serve per evitare l\u0026rsquo;uso meta-linguistico, invarianza per sostituzione √® il primo teorema che serve per questo\n5.4.1 Intuizione iniziale In linguistica la connotazione √® il significato psicologico di una parola, mentre la denotazione √® la prima cosa che di solito di d√† il dizionario, ossia cosa √® detto effettivamente.\nIn breve: (‚Üí indica il significato in informatica)\nConnotazione: ci√≤ che voglio comunicare, come voglio cominciare (per la logica i messaggi subliminali non sono utili) ‚Üí Sintassi il modo in cui lo sto dicendo Denotazione cosa √® detto ‚Üí Semantica ci√≤ che voglio dire, anche considerabile come l\u0026rsquo;oggetto che viene considerato in questo mondo. Nel caso dell\u0026rsquo;informatica l\u0026rsquo;uso metalinguistico √® parlare sulle connotazioni\n5.4.2 Teorema Invarianza delle denotazioni Data un qualunque contesto (un buco di una frase) e una connotazione, se sostituita con una altra connotazione, le denotazioni delle frasi restano le stesse allora quelle due connotazioni sono equivalenti.\nPossiamo utilizzare il test di invarianza per vedere se qualcosa √® metalinguistico o meno.\nSe due connotazioni che possiedono la stessa denotazione hanno output diversi per certi contesti allora questo fa uso metalingusitico\nFondamentale per l\u0026rsquo;uso metalinguistico\n5.4.3 Connettivi logici Intro Per maggiore precisione sui connettivi logici guardare Connettivi Logici, correttezza, variabili\nAbbiamo bisogno di tenere certe cose fisse in modo da tenere un ordine generale fra i mondi. Questi sono i connettivi logici che hanno lo stesso senso ovunque.\nPossono essere\nBinari\nUnari\n0-ari\nE poi quantificatori come esiste e per ogni in modo da tenere un ordine generale fra i mondi. Questi sono i connettivi logici che hanno lo stesso senso ovunque.\nPossono essere\nBinari\nUnari\n0-ari\nE poi quantificatori come esiste e per ogni\n","permalink":"https://flecart.github.io/notes/verita-teorie-modelli-connotazione-denotazione/","summary":"Questa √® una necessit√† per stabilire il significato di una sintassi definiti.\n5.1 Verit√† e Realt√† La verit√† ha solamente senso quando lo si relaziona con un mondo sensibile, ossia il mondo che si pu√≤ percepire con i nostri sensi.\n5.1.1 Verit√† parametrica e assoluta Se un esperimento √® ripetibile all\u0026rsquo;interno del mondo sensibili allora questa √® considerata come una verit√† parametrica, ossia dipende da uno stato del mondo sensibile.","title":"Verita, Teorie, modelli, connotazione, denotazione"},{"content":"Public Key Encryption We now define a formally what is a public key encryption\nFormal definition of Public Key Encryption We define a 3-tuple formed as follows: $(G, E, D)$ where\n$G$ is the generator for the private and public keys, from now on identified as $(pk, sk)$ (public key and secret key) $E(pk, m)$ the encryption algorithm, that takes the $pk$ and the message in input $D(sk, c)$ the decryption algorithm, that takes the $sk$ and the ciphertext in input. Now is this definition useful? i don\u0026rsquo;t think so! We can\u0026rsquo;t create theorems for it, too general I suppose. Is it clear? yes! I think this is the usefulness of maths in many occasions, it delivers some complex information in a concise and understandable manner.\nSome observations about Public Key Encryption Semantic security to Eavesdropping This is the same as explained in Advantage security explained in a previous section. We defined the advantage as the ability of the attacker to distinguish the original message. This is still exactly the same, see that section. (the only difference is that here we use public key encryption) Resistance against Many Time Pads We know that in the symmetric context in Block Ciphers and OTP and Stream Ciphers, it is often not secure to use the symmetric key to many times. (This is clearly true when we are talking about the OTP cipher).\nBut in the context of Asymmetric keys this notion is not true as the key is public, this key can be used as many times as the attacker wants. So he can reuse the key, while the cipher should still remain secure!\nSharing a key It\u0026rsquo;s easy to share a key using this encryption scheme. Just send the secret key with the public key of this cipher!\nTrapdoor functions Definition of Trapdoor functions Trapdoor is generic function from $X \\to Y$. This is a triple $G, F, F^{-1}$ very similar to the previous one (indeed it\u0026rsquo;s kinda the same definition) The only difference is that $F^{-1}$ is the inverse. This function is one-way, meaning it\u0026rsquo;s difficult to invert. And has a trapdoor meaning that by knowing the secret $sk$ it is easy to do so. $F(pk, \\cdot)$ defines public encryption function, the other equivalent is the decryption.\nSecure Trapdoor Functionsüü©\u0026ndash; NOTE: direct use of $F$ and $F^{-1}$ to encrypt and decrypt using the created keys is not semantically secure. But I don\u0026rsquo;t know why.\nA trapdoor is secure if it\u0026rsquo;s difficult to invert without the knowledge of $sk$. (It\u0026rsquo;s difficult to invert the $x$) See image Creating a PKE from Trapdoorsüü®+ One Way Hash Algorithms These are different from Hash tables which is a datastructure!\nWe can see that One-Way hashes are a trapdors with $pk = sk$. Usually it is a function that takes a input of arbitrary length and outputs a limited string with some important properties.\nProperties of One Way Hash Algorithmsüü©- Easy to Evaluate: The hashing algorithm should be fast Hard to Reverse: There is no feasible algorithm to \u0026ldquo;reverse\u0026rdquo; a hash value, That is, given any hash value $h$, it is computationally infeasible to find any document $m$ such that $H(m) = h$. Hard to find Collisions: There is no feasible algorithm to find two or more input documents which are hashed into the same condensed output, That is, it is computationally infeasible to find any two documents $m_{2}, m_{2}$ such that $H(m_{1})= H(m_{2})$. Although, theoretical requirements say there are many many collisions. But the difficult thing is tampering, that is add some strings, make some modifications of the original messages such that that hash matches with others. A small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value RSA Cryptosystem Definition of the trapdoor function We define $F: \\mathbb{Z}^{*}_{\\mathbb{N}} \\to \\mathbb{Z}^{*}_{\\mathbb{N}}$ as $RSA(x) = x^{e}$ where $e$ is the public key generated by the key generation function and $N = pq$ is the private key, where $p, q$ are big primes.\nThen using Euler\u0026rsquo;s theorem we know how to compute $d$ such that $x^{ed} =x \\mod N$ where $d$ is the inverse modulo that, this is how we decrypt. How do we compute $d$? We use euler\u0026rsquo;s theorem, and find this $e\\cdot d = 1 \\mod \\varphi(N)$. and $e$ should be invertible with it is coprime with $N$ (true by construction).\nRSA with trapdoors A secure implementation of RSA uses trapdoor functions like this: $x \\sim X$ this is the secret, we generate $y = RSA(x, e)$ with this, and encrypt the message with $k = H(x)$ and $c = H_{s}(k, m)$ and send $y$. The decryption step is similar to that presented to trapdoor functions.\nSecurity Analysis of RSA NOTE: normal RSA as defined above is not secure, the main reason is that it is deterministic, so we can have semantic security breaches.\nSimple semantic security attack on RSA I can get back to the original message with a small effort. The percentage of success is high enough not to be negligible. We have a $2^{40}$ attach on $2^{64}$ long messages.\n#### Advantage notation for RSA We want the possibility to compute the $e$ root modulo $N$ to be small, and using the notion of advantage developed in [OTP and Stream Ciphers#Security with advantage](/notes/otp-and-stream-ciphers#security-with-advantage) we write $$ Pr\\left[ A(N, e, y) = y ^{1/e} \\right] \u003c \\varepsilon $$ Where $\\varepsilon$ is very small, **negligible** so to say, and $A$ is the $F$ trapdoor function used for RSA. This is the problem of the discrete logarithm, usually true. Wiener\u0026rsquo;s attack (non fatto) This section is not useful for the exam, just for personal knowledge! If the private keys have certain properties, there exists some attacks, one example is the Wiener\u0026rsquo;s attack, for example if the private key is too small. The concept is that this makes the search space quite small.\nLow public exponent attack üü© Usually minimum that is used is 3. If 2 then the inverse is not guaranteed because $mcd(2, (p - 1) ( q - 1)) \\neq 1$ .\nThis is a stupid attack. Then the exponent is small enough, and it is not able to wrap the module, then the root is quite easy to achieve. This is why the recommended value is big, usually = $2^{16} + 1 = 65537$.\nUsually this is used to speed up encryption, it easier to compute. Other variants, like Elgamal have almost same time to encrypt and decrypt.\nThe reduction problem In order to prove that the best solution is to factor n we should prove that Efficient algorithm for e\u0026rsquo;th roots mod $N$ implies having efficient algorithm for factoring $N$. There is some evidence that says this reduction exists (BV'98) but it is still an open problem. But as far as we know this is actually a hard problem.\nComparison with symmetric keys AES key size RSA modulus size 80 bit 1024 bits 128 bits 3072 bits 256 bits 15360 bits We observe that RSA needs a lot more bits to ensure the same security! Side channel attacks these attacks do not directly attack the cipher, but the infrastructure or computing that it uses.\nTiming attack Can leak $d$ secret key by tracking the compute time. (Kocher 1997)\nPower attack Can leak $d$ by tracking power usage. (Kocher 1999) Needs access to physical data.\nFaults attack Errors can leak $d$ somehow (don\u0026rsquo;t know!) (BDL 1997). In questa fase viene leakato il valore di $p$ che permette di ricostruire la chiave privata.\nKey generation First when you startup the entropy of $p$ is not so much, so it happens if two different firewalls generate a key, they are probably the same. So if you take the GCD of these, it is probable that they are the same. They factored 0.4% of all public https keys in this way. Which is a good number. This says that it is **crucial to add randomness before generating keys**. Variations Elgamalüü®- Find $g$ and $p$ such that $g$ is primitive root modulo $p$. Some strange properties here. This means that $\\forall a, \\exists k : g^{k} = a \\mod p$. This is inspired from the Key Exchange protocols#Diffie-Hellman Protocol. Then the first person chooses $a \\in \\left[ 0, p - 2 \\right]$ randomly and calculates $A = g^{a} \\mod p$ and the tuple $(p , g, A)$ is then considered as the public key. The interesting thing is that this algo is randomized, if you want to communicate with someone, you choose a key randomly first.\n$B = g^{b} \\mod p$ $c = A^{b}m \\mod p$ Ciphertext is $(B, c)$ La decrittazione √® diversa. Calcolo $x = p - 1 - a$ e poi posso usare questo per decrittare, facendo $m = B^{x}c \\mod p$\nEsiste anche una versione per fare l\u0026rsquo;exchange, ma di questa non ne abbiamo parlato\nNotes on security -\u0026gt; Discrete log problem. Efficiency -\u0026gt; No, ciphertext needs that public key to be sent, which is usually long and expensive to calculate compared to AES.\nRabin cripto-systemüü® we create $p,q$ such that their modulus $4$ is 3, probably for some nice properties I don\u0026rsquo;t know of\u0026hellip; The advantage is that his security is proved. Calculate $n = pq$ and this is the public key. When somebody wants to communicate, he just calculates\n$$ c = m^{2} \\mod n $$ And sends this, probably with this setting the properties of $p, q$ make that invertible, but not sure why. If you are curious try to understand why is this valid. It has some nice theoretical properties. Its difficulty is proven to be the same as integer factorization, not known for RSA.\nDigital signatures The main idea is to cipher with the private key, so that it can be verifiable using the public. It was cited in Sicurezza delle reti times before. To overcome the burden to encrypt the whole text, usually only an hash is encrypted.\nAdvantages of Digital signatures Unforgeable Un-deniable by the signatory (if you have signed it, it was you!) Universally verifiable (everybody can verify it) Every doc\u0026rsquo;s signature is different, or very sensible to little changes. ","permalink":"https://flecart.github.io/notes/asymmetric-cryptography/","summary":"Public Key Encryption We now define a formally what is a public key encryption\nFormal definition of Public Key Encryption We define a 3-tuple formed as follows: $(G, E, D)$ where\n$G$ is the generator for the private and public keys, from now on identified as $(pk, sk)$ (public key and secret key) $E(pk, m)$ the encryption algorithm, that takes the $pk$ and the message in input $D(sk, c)$ the decryption algorithm, that takes the $sk$ and the ciphertext in input.","title":"Asymmetric Cryptography"},{"content":"Lempel-Ziv-Welch Algorithm Introduzione sul funzionamento Primo scan con un dizionario indexato dei singoli caratteri Poi viene cercato di raggruppare caratteri a coppie. Se una coppia √® gi√† presente nel dizionario, allora aggiungo al dizionario una cosa pi√π lunga e metto un code diverso Esempio di sopra. La cosa carina √® che il dizionario si pu√≤ ricostruire in fase di decoding.\nTutti gli altri, tipo zip, gzip, png si basano poi su questa idea. Per certi versi la cosa di raggruppare √® simile a Byte pair encoding.\nHuffman Codes Questa parte probabilmente √® stata anche trattata in modo molto breve al corso di algoritmi. Basato sul paper di 1952 \u0026ldquo;A method for the construction of minimum redundancy codes\u0026rdquo;. Di Huffman L\u0026rsquo;idea principale √® creare un albero di codifica in modo che le cose frequenti siano in cima, ossia hanno un codice molto breve, mentre cose lunghe abbiano codici pi√π lunghi.\nIl codice di Huffman √® un algoritmo che nella media ha compressione migliore lossless. Ossia si ha $L^{*}(C_{huffman}) \\leq L(C)$ per qualunque altro carattere. Ha anche relazioni con le prefix strings, ne si parla di pi√π in Entropy, e ci sono note molto interessanti su questo algoritmo. Si pu√≤ dimostrare che √® algoritmo di compressione lossless migliore. Che √® una cosa affascinante.\nAssumiamo che ogni carattere abbiano una frequenza.\nAlgoritmo di Huffman Creo una lista ordinata dalla frequenza Inizio ad assegnare codici a questa lista volta per volta partendo dai pi√π bassi Inserisco in cima creando nuovi nodi (che reinserisco) volta per volta sempre prendendo il pi√π basso di frequenza Si crea un prefix-code in questo modo che si pu√≤ utilizzare a piacere. Una volta creato questo albero, posso usarlo per codificare e anche decodificare. \u0026#34;\u0026#34;\u0026#34; Huffman code generator -- after [https://stackoverflow.com/questions/11587044/how-can-i-create-a-tree-for-huffman-encoding-and-decoding](https://stackoverflow.com/questions/11587044/how-can-i-create-a-tree-for-huffman-encoding-and-decoding) \u0026#34;\u0026#34;\u0026#34; GRAPHIMAGE = \u0026#39;HuffmanGraph\u0026#39; # for Huffman tree display. SOURCETXT = \u0026#39;texts/English.txt\u0026#39; # for statistics ###################################### # Huffman coding # ##################### ######## def assign_code (nodes, label, result, prefix = \u0026#39;\u0026#39;): childs = nodes[label] tree = {} if len(childs) == 2: tree[\u0026#39;0\u0026#39;] = assign_code(nodes, childs[0], result, prefix+\u0026#39;0\u0026#39;) tree[\u0026#39;1\u0026#39;] = assign_code(nodes, childs[1], result, prefix+\u0026#39;1\u0026#39;) return tree else: result[label] = prefix return label def huffman_code(_vals): vals = _vals.copy() nodes = {} for n in vals: # leafs initialization nodes [n] = [] while len (vals) \u0026gt; 1: # binary tree creation s_vals = sorted(vals.items(), key=lambda x:x[1]) al = s_vals[0][0] a2 = s_vals[1][0] vals[al + a2] = vals.pop(al) + vals.pop(a2) nodes[al + a2] = [al, a2] code = {} root = al+a2 tree = {} tree = assign_code (nodes, root, code) # assignment of the code for the given binary tree return code, tree Proof of Optimality Given an alphabet $\\Sigma$ and a set of words $\\Omega \\subseteq \\mathbb{P}(\\Sigma)$. Assuming $p(\\omega_{1})$ is the probability of word $\\omega_{1}$ in the corpus, and $l(\\omega_{1})$ is it\u0026rsquo;s length (that are elements of the alphabet that compose it), we need to prove that $L = \\sum_{i} p(\\omega_{i}) l(\\omega_{i})$ produced by the Huffman coding algorithm is the minimum possible.\nObservations (informal):\nHuffman already produces strings such that $p_{i} \\geq p_{j} \\implies l_{i} \\geq l_{j}$, this could be deduced by the construction of the tree. I think it is provable that Huffman produces always complete codes. If the code is complete, gain is expected code length is possible only by switching assignments to the labels, or push some down and others up, preferring some. But from point 1 we know that this is already optimal. This concludes high-level reasoning. ","permalink":"https://flecart.github.io/notes/compression-algorithms/","summary":"Lempel-Ziv-Welch Algorithm Introduzione sul funzionamento Primo scan con un dizionario indexato dei singoli caratteri Poi viene cercato di raggruppare caratteri a coppie. Se una coppia √® gi√† presente nel dizionario, allora aggiungo al dizionario una cosa pi√π lunga e metto un code diverso Esempio di sopra. La cosa carina √® che il dizionario si pu√≤ ricostruire in fase di decoding.\nTutti gli altri, tipo zip, gzip, png si basano poi su questa idea.","title":"Compression Algorithms"},{"content":"Introduzione Radio üü© \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Fisica del Wireless/Untitled.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Fisica del Wireless/Untitled\u0026quot;\u0026gt; Antenna: converte corrente in segnali radiorequenza e viceversa. le segnali radiofrequenza sono onde radio con frequenza diversa per rappresentare 1 o 0. Un altro modo per mandare 1 o 0 sarebbe semplicemente cambiare l‚Äôintensit√† della onda, mantenendo la stessa frequenza.\nViene utilizzata una variazione di potenziale elettrico per creare il segnale, dovrebbe essere un oscillatore armonico in pratica credo. Creando questo flusso di elettroni, crea anche un campo elettromagnetico a lui ortogonale, questa √® l‚Äôonda radio, che si propaga alla velocit√† della luce.\nEss√¨ per capire questa parte serve ripassare un p√≤ di fisica, in Onde elettromagnetiche scuola (in realt√† c‚Äô√® molto poco qui).\nIl prof ha spiegato questo fenomeno in 20 minuti, questo video sembra buono per comprendere questa cosa.\nCaratteristiche dell‚Äôonda elettromagnetica (3) üü© L‚Äôonda radio utilizzata in wireless √® solamente un sottotipo delle onde radio.\nFrequenza onda La relazione fra lunghezza d‚Äôonda e frequenza dell‚Äôonda con la velocit√† dell‚Äôonda √® conosciuta: $v = f\\lambda$ Comunque la frequenza √® un altra caratterizzazione importante per l‚Äôonda.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Fisica del Wireless/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Fisica del Wireless/Untitled 1\u0026quot;\u0026gt; Nota: questo √® un range di frequenza! Questo ci permette di creare molti canali con frequenze diverse.\nUn problema molto difficile √® la scomposizione delle frequenze, cos√¨ possiamo isolare i singoli canali. Le onde sono additive, sono tutte messes assieme!\nNOTA: massima efficienza per la creazione di onde √® quando la lunghezza dell‚Äôantenna √® stessa lunghezza dell‚Äôonda radio, ma anche sottomultipli binari sembrano andare bene.\nAmpiezza Poi l‚Äôintensit√†, ossia l‚Äôampiezza dell‚Äôonda, √® l‚Äôaltro carattere importante\n√à strettamente correlato con l‚Äôenergia utilizzata per generare l‚Äôonda, cio√® se ho ampiezza maggiore ho speso in generare pi√π energia per generare quell‚Äôonda.\nNota: L‚Äôenergia dell‚Äôonda decade in distanza quadratica, (se voglio raggiungere doppia distanza, devo quadruplicare la potenza) quindi perde energia molto velocemente. In modo intuito il motivo per cui questo succede √® che l‚Äôenergia iniziale √® la stessa, idealmente dopo un certo momento √® ancora la stessa energia (nel senso che non la perdo), per√≤ √® dispersa in una area molto maggiore, che si espande quadraticamente con la distanza, ecco che quando andiamo a ricevere stiamo prendendo solamente un pezzo molto piccolo di questa energia iniziale.\nEsempio del panino con la nutella\nQuesto √® un esempio che il prof. ha fatto in aula, √® un modo molto visivo per dare l‚Äôintuito di questa decadimento di potenza.\nMettiamo caso che prendiamo un cucchiaione di nutella e la spalmiamo sulla fetta. In questo caso la fetta √® bona, si sente bene la nutella. Mettiamo caso che di nuovo prendiamo il cucchiaione, la mettiamo sulla fetta. E ops, la fetta diventa in un secondo grosso 300km, la nutella √® sempre la stessa, ed √® spalmata uniformemente, ora la sento ancora la nutella? Se c‚Äô√® anche un muro poi mi perndi anche la nutella quando la fetta si espande! ne ho ancora di meno Ovviamente se diventa troppa poca l‚Äôeneergia, poi non riesco a sentire cosa dice! cio√® non detecto il segnale\nSlide decadenza di potenza Fase dell\u0026rsquo;onda Una terza caratterizzazione, oltre l\u0026rsquo;ampiezza e la frequenza √® la fase dell‚Äôonda. ossia quanto sono spostate rispetto a un periodo assoluto (questo shift di fase √® in radianti o gradi)\nUn onda spostata rispetto al riferimento, posso considerarla o in anticipo o in posticipo, la somma delle due per√≤ √® 360, quindi √® lo stesso modo di descrivere le due.\nSlide phase shift\nSi hanno problemi con la fase quando questa rimbalza con qualcosa e va a interferire con s√© stesso.\nClassificazione zone di segnale (3) üü®+ Andiamo a definire una signal detection limit, ossia il punto da cui dopo non e piu detectabile il segnale, e quindi non comprendo pi√π cosa mi viene comunicato.\nSu quanto definito sopra potremmo definire 3 zone correlata alla distanza fra il sender e il ricevente:\nSlide zone di propagazione segnale\nLa capacit√† del ricevente influenza in quale zona stai (come se avessi l‚Äôorecchio pi√π fine o meno!)\nTrasmission range quando riesco a comprendere un un errore bitrate molto basso Detection range non si riesce a capire cosa viene trasmesso, ma si nota che si trasmette qualcosa Interference range quando i segnali potrebbero anche non essere rivelati perch√© troppo deboli A volte se ho molte sources, un buon metodo potrebbe essere mettere un filtro che filtri un certo tipo di canale, se ascolto sto ascoltanto un certo misto di segnale. (una cosa carina √® che la radiazione di fondo si mischia con questi üòõ)\nProblemi della rete wireless (3) üü®- intensit√† del segnale che decade in fretta intereferenza con stessa frequenza da sorgenti diversi Interferenza con s√© stesso (se percorre distanze diverse, rimbalzando da qui e la, e giunte sfasato! O passare ostacoli?) Ostacoli(3) Dietro l\u0026rsquo;ostacolo faccio fatica ad avere segnale L\u0026rsquo;ostacolo fa rimbalzare l‚Äôonda radio Il materiale influenza fortemente questo comportamento dell‚Äôonda (anche rifrazione!) Slide ostacoli assorbono\nSlide influenze ostacoli\nIn generale se l\u0026rsquo;onda √® a bassa frequenza, passa l\u0026rsquo;ostacolo, se √® alta √® molto facile che si blocchi.\nQuindi abbiamo un tradeoff di questo tipo:\nOnda bassa frequenza, va lontano, ma contiene poche informazioni al secondo Onda alta frequenza non va lontano, ma tante informazioni! (motivo per cui la cella 5g deve essere per forza piccola) E ci sono alcuni fenomeni come terminale nascosto o fading, sempre per caratteristiche di ostacoli e evanescenza del segnale che interferiscono fra di loro.\nPUNTI CIECHI DELLE ANTENNE (1)\nSe posiziono l\u0026rsquo;antenno in un certo modo, questa non riesce proprio a leggere le onde radio in una certa posizione (a causa della polarizzazione)\nSlide punti ciechi (polarizzazione)\nSe sto allo stesso orientamento dell\u0026rsquo;antenna, riesco a leggere tutto bene le informazioni delle antenne, mentre invece se sto ortogonale non potrei vedere niente. Questa √® anche chiamata polarizzazione dell‚Äôonda.\nSlide polarizzazione (con esempio di foro per intuito)\nLa soluzione a questo problema √® utilizzare pi√π antenne di diverse orientazioni. Quindi comunque riesco a prendere qualcosa (se lo metto in modo ortogonale, a L, riesco a ricavare il segnale iniziale sempre).\nNOTA: indoor ho i muri che rimbalzano, quindi alla fine comunque mi arriva di direzione giusta, e non ho un problema di sensibilit√† tale.\nNOTA2: i satelliti sono fighi, non hanno nessun ostacolo per comunciazione onde radio, forse le nuvole sono il pi√π grande problema, che riescono ad assorbire e riflettere anche qui le onde radio.\nEffetti sull\u0026rsquo;uomo (non fare) üü© 300 MHz and 300 GHz sono il range delle microonde, quando il cellulare emette certe onde di quella requenza, allora √® proprio questo! Solamente di intensit√† molto minore. (sono milliwatt contro centinaia di watt), quindi un p√≤ comunque scalda! E attraversa comunque un p√≤ la materia, e scalda l‚Äôacqua a questa frequenza.\nhttps://www.fda.gov/radiation-emitting-products/cell-phones/do-cell-phones-pose-health-hazard\napprofondimento carino: vedere come funziona la risonanza, e se questo √® il fenomeno che fa scaldare l‚Äôacqua.\nSlide effetti sull\u0026rsquo;uomo\nCome fanno le onde radio ad arrivare alle auto? Se la cabbia di faraday proprio va a schermare il tutto? Evade molto poco, e quello √® quello che va nell\u0026rsquo;access point.\nLa trasmissione del segnale Guadagno del segnale (2) üü© Si dice guadagno del segnale quando incremento la potenza del segnale, in un certo rapporto in confronto a quanto trasmesso. Si misura in DECIBEL.\nguadagno attivo questo √® quello che vanno a fare gli amplificatori, che hanno bisogno di energia dall\u0026rsquo;esternom prende le onde in input e utilizza l‚Äôenergia per rigenerare il segnale, sono quello che fanno i repeaters. guadagno passivo quando non ho bisogno di energia all‚Äôesterno. Per esempio √® cos√¨ che funzionano i dischi delle parabole, che riescono a prendere molto segnale, e concentrarla in un unico punto. Perdita di segnale üü©- Intenzionale questa √® utile per gestire l‚Äôenergia (e.g. far passare 6 ampere in un circuitino sarebbe troppo, quindi trasformo in calore prima di far entrare nel circuito) (oppur esempio un connettore, che riflette in parte e fa passare con intensit√† minore, e questo √® proprio misurabile id dB) ostacoli come acqua. perdita del segnale ‚Äònon voluta‚Äô, dovuta ad ostacoli, ad esempio in caso di nebbia, che rappresenta un ostacolo per le microonde che scaldando le particelle d‚Äôacqua di cui √® composta la nebbia, facendo ridurre l‚Äôenergia del segnale (e quindi l‚Äôampiezza), riducendo la distanza che pu√≤ percorrere il segnale. Slide tipologie di effetti di ostacoli\nMultipath propagation (2) üü®‚Äî Il segnale pu√≤ giungere da molte direzioni, e il segnale ricevuto pu√≤ essere in una fomra strana (phase shifted, tre echi meno energetici, parzialmente sovrapposti.\nGli effetti principali della multi path sono:\nI segnali possono arrivare in momenti diversi e fare interferenza con s√© stesso I segnali possono arrivare phase shiftati. Effects of mobility (non fare?) üü• Ci sono proprio delle zone in cui il segnale √® migliore e altre in cui non va per il wifi, in cui cambiano subito questa parte di segnale\nSlide mobilit√†\nL‚Äôeffetto principale √® la variabilit√† del segnale quando ci muoviamo, possiamo avere alti e bassi e continuamente ci connettiamo a ripetitori diversi (questo √® anche un modo per ricostruire il tuo percorso, a seconda di quale dispositivo ti sei connesso vicino).\nCambiano anche distanza dal destinatario e dagli obstacoli.\nVoltage Standing Wave Ratio üü®+ √à proprio necessario utilizzare la stessa impedenza! Altrimenti diventa molto inefficiente,\nVSWR √® una perdita del segnale quando l\u0026rsquo;impedenza della sorgente e del ricevente sono diversi fra di loro. C\u0026rsquo;√® un effetto resistivo quando le correnti si spotano in questo modo, che crea calore. (corrente genera Se il valore di impedenza √® diverso ho:\nIrregolarit√† (anche ritorno di energia), perdita di energia. bruciare delle componenti. Calcolato come rapporto delle impedenze del trasmettitore e ricevente.\nIntentional radiator e regulations üü©- Intentional radiator √® il trasmittitore pi√π cavi e connettori con l\u0026rsquo;antenna\nIntentional radiator Power output: quanit√† di energia data all\u0026rsquo;antenna dall\u0026rsquo;intero componente dietro l‚Äôantenna, quindi cavi connettori e il generatore (i cavi fanno perdere un p√≤ di energia, in questo senso l\u0026rsquo;antenna non riceve l‚Äôenergia del trasmettitore come da sorgente, ma quella decaduta dalla corrente.\nSu questo IR Poutput si mettono le regulations, ossia massimo energia a livello antenna, ma si potrebbe fare che l\u0026rsquo;energia che riceve siano dentro i limiti, ma utilizzo una antenna in modo da focalizzare il raggio, rendendolo molto pi√π denso.\nPer questo motivo bisognerebbe mettere il la regolazione non sul power output, che si pu√≤ concentrare, ma sul EIRP (Equivalent isotropically radiated power), ossia la potenza radio irradiata dall‚Äôantenna con anche gli effetti passivi (ossia concentrati diciamo), una volta che sono al massimo dell Power output.\nMisura della potenza Il WATT üü© Quelli che ci interessano sono soprattuto i watt, che sono una misura della potenza, la quantit√† di lavoro fatto al secondo.\nIn pratica √® una misura di\nenergy needed (in a given time unit) to apply a given ‚Äúpressure‚Äù to a given ‚Äúamount of charge‚Äù, by resulting in a flow of current.\nLe formule classiche sono le leggi di OHM che qui per√≤ saltiamo.\nSlide misura della potenza\nI decibels üü© Spesso andare a ragionare in watt √® molto scomodo, perch√© la potenza cade in modo logaritmico (non era quadratico??) dato che √® logaritmico meglio utilizzare i decibels\nDecibel (dB) measures the logarithmic relative strength between two signals (mW are a linear absolute measure a energy)\nNOTA: √® molto importante il fatto che i decibels siano relativi!\nSlide sui decibels\nCalcolo dei decibels $$ dB = 10 \\times \\log_{10}(\\dfrac{W_{Receiver}}{W_{Sender}}) $$ Formula inversa:\n$$ W_{receiver} = W_{sender}\\exp(dB \\log(10)/ 10) $$ Esempi di calcolo Il vantaggio principale √® che invece a stare modificare moltiplicazioni e divisioni, sto utilizzando somme e sottrazioni che creano numeri molto pi√π gestibili, (questo √® sempre isomorfismo prodotto e somma in un certo gruppo credo).\nUna cosa carina √® che tipo 3 decibels √® moltiplicare o dividere per 2.\nNormalized decibels dBm üü© Praticamente diciamo che $1 mW = 1dBm$ $$ P_{dBm} = 10 \\log(P_{mW}) \\\\ P_{mW} = \\exp(P_{dBm} / 10) $$ Con qualche costante messa bene per i logs.\nScala decibels milliwatt\nIsotropic decibels dBi üü© I decibels isotropici misurano il guadagno passivo dato dall‚Äôarchitettura dell‚Äôantenna confrontandolo con il caso ideale di un antenna isotropica, con efficienza 100%, equiparabile a un dipolo di lunghezza nulla.\nSlides isotropic decibels\ndB-dipole üü© Questo √® solamente un dipole translato di 2.14 se mi ricordo bene, solamente il compare di una antenna dipolo con una isotropica i suppose, quindi non molto di differenza.\n","permalink":"https://flecart.github.io/notes/fisica-del-wireless/","summary":"Introduzione Radio üü© \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Fisica del Wireless/Untitled.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Fisica del Wireless/Untitled\u0026quot;\u0026gt; Antenna: converte corrente in segnali radiorequenza e viceversa. le segnali radiofrequenza sono onde radio con frequenza diversa per rappresentare 1 o 0. Un altro modo per mandare 1 o 0 sarebbe semplicemente cambiare l‚Äôintensit√† della onda, mantenendo la stessa frequenza.\nViene utilizzata una variazione di potenziale elettrico per creare il segnale, dovrebbe essere un oscillatore armonico in pratica credo. Creando questo flusso di elettroni, crea anche un campo elettromagnetico a lui ortogonale, questa √® l‚Äôonda radio, che si propaga alla velocit√† della luce.","title":"Fisica del Wireless"},{"content":"Introduzione Metodi alternativi di gestione degli errori (3) üü© A volte le computazioni falliscono. Potremmo gestirle con i result come accennato in Polimorfismo, per√≤ diventa molto macchinoso fare tutte le funzioni che debbano inoltrare solamente delle results. bisogna trovare un modo pi√π naturale. Ecco che arriva una gestione delle eccezioni direttamente nel linguaggio. Si tratta un sistema di comunicazione degli errori.\nALTRI METODI\nResults, stile monadico, vedi sopra. definire dei valori eccezionali (questo si va spesso in C) Il chiamato dice al chiamante una cosa da chiamare quando fallisce. Diciamo inversione del controllo perch√© in questo caso √® il chiamato che dice cosa fare. Ma rende il codice poco composizionale, quindi difficile da seguire. (Questa √® la soluzione molto pi√π simile alla gestione effettiva degli errori). Ma nelle eccezioni vere non √® il chiamato che ritorn al\u0026rsquo;indirizzo da eseguire ma √® il runtime che decide cosa andare ad eseguire. Questa cosa non interrompe il flusso del calcolo Con le eccezioni vogliamo trasferire il controllo a un gestore delle eccezioni questo gestore solitamente si trova sulla stack (va a risalire tutta la stack di chiamata fino a raggiungere questo gestore).\nDefinizioni di eccezioni üü© Una eccezione √® un modo per poter interrompere la computazione attuale (descrizione di stati invalidi della computazione), in vista di errori semantici come la divisione per zero. Sono proprio dei nomi (!!!), ossia catturati nominalmente duratne la gestione degli errori.\nAlcuni stemp importanti sono la\nDefinizione di errori gestibili, e sollevamento, o raising di questi errori Politiche di gestione degli errori. (come viene trasmesso e il codiche che viene chiamato) Meccanismi di sollevamento di errori Caratteristiche delle eccezioni üü© Nomi, le eccezioni hanno nomi e rappresentano quale errore semantico di operazioni, hanno una sintassi precisa Valori, possono contenere certi valori che comunichino qualcosa sul‚Äôerrore. COSTRUTTI DELLE ECCEZIONI\nSono solitamente due\nUn modo per marcare la porzione di codice protetta Un gestore delle eccezioni, che esegue nel caso sia stato sollevato all\u0026rsquo;interno di tutto il codice protetto una eccezione non gestita. Eccezioni e sottotipaggio üü©- Possiamo utilizzare la machinery di Polimorfismo anche in questa fase! Possiamo catturare eccezioni e tutti i sottotipi di una certa eccezione.\n√à anche considerata una bad practice, perch√© vorresti catturare una eccezione specifica (pi√π facile da capirne la causa diciamo)\nhttps://stackoverflow.com/questions/2416316/why-is-the-catchexception-almost-always-a-bad-idea\nhttps://stackoverflow.com/questions/6083248/is-it-a-bad-practice-to-catch-throwable\nCATCH √® un controllo Con subtyping! IN JAVA\nSlide java sottotipaggio\nThrowable √® un tipo somma di due casi (Error, irrecuperabile) e Exception. Tutte le eccezioni tranne Runtimeexception (e.g. se finisce memoria sulla heap) √® da gestire.\nImplementazione classica üü© Solitamente l‚Äôerrore viene proprio sollevato.\nOssia se vogliamo gestire un errore in un certo blocco protetto, allora linkiamo questo gestore a questo blocco.\nAlgoritmo per le eccezioni:\nCheck se il blocco attuale ha il gestore corretto (ossia supertipo dell‚Äôeccezione che ho) S√¨ runna questo codice bindato staticamente al blocco protetto Altrimenti risolleva l‚Äôerrore andando al record precedente Continua fino ad arrivare al gestore di default Implementazione per ricerca binaria üü®- Questo solitamente per le applicazioni reali √® pi√π veloce, perch√© quando entro in blocco protetto non ho bisogno del leggero overhead in pi√π per darti il gestore.\nPraticamente per ogni singolo blocco io definisco una coppia :\nInizio del codice protetto Puntatore al gestore delle eccezioni Se non ci ho definito niente, c\u0026rsquo;√® un puntatore di default, che semplicemente risollevi gli errori.\nTutti i blocchi sono tenuti in maniera ordinata, in modo da farci una ricerca binaria se ne ho bisogno. Quindi √® pi√π lenta di un fattore log(n), per√≤ dato che non ho overhead a entrare, di solito √® una cosa pi√π veloce della precedente.\nIn Java Tipologie di eccezioni (2) ","permalink":"https://flecart.github.io/notes/gestione-delle-eccezioni/","summary":"Introduzione Metodi alternativi di gestione degli errori (3) üü© A volte le computazioni falliscono. Potremmo gestirle con i result come accennato in Polimorfismo, per√≤ diventa molto macchinoso fare tutte le funzioni che debbano inoltrare solamente delle results. bisogna trovare un modo pi√π naturale. Ecco che arriva una gestione delle eccezioni direttamente nel linguaggio. Si tratta un sistema di comunicazione degli errori.\nALTRI METODI\nResults, stile monadico, vedi sopra. definire dei valori eccezionali (questo si va spesso in C) Il chiamato dice al chiamante una cosa da chiamare quando fallisce.","title":"Gestione delle eccezioni"},{"content":"Introduzione Definizione normalit√† Test del sottogruppo normale Dimostrazione\nIl gruppo quoziente L‚Äôimportanza del gruppo normale √® che quando esso vale, possiamo avere il gurppo fattore\nDimostrazione\n!\n","permalink":"https://flecart.github.io/notes/gruppi-normali/","summary":"Introduzione Definizione normalit√† Test del sottogruppo normale Dimostrazione\nIl gruppo quoziente L‚Äôimportanza del gruppo normale √® che quando esso vale, possiamo avere il gurppo fattore\nDimostrazione\n!","title":"Gruppi Normali"},{"content":"Memoria sistema Operativo Guradare Memoria virtuale Per vedere come vengono rimpiazzate le pagine\nIn quest sezione andiamo a parlare di come fanno molti processi a venire eseguiti insieme, anche se lo spazio di memoria fisico √® lo stesso. Andiamo quindi a parlare di spazio di indirizzi, risoluzione di questi indirizzi logici, segmentazione e paginazione. (e molto di pi√π!)\nMMU Controlla se l‚Äôaccesso di memoria √® bono o meno. (traduzione fra indirizzo logico e fisico)\nCosa succederebbe se non fosse hardware?\nLa performance sarebbe molto peggiore. Sicurezza, si dovrebbe implementare uno mode switch e andare al kernel mode per accedere (syscall per accedere ad indirizzi di memoria), quindi non si utilizza mai, perch√© sarebbe ancora pi√π lentooo. Memory manager üü© Its job is to keep track of which parts of memory are in use and which parts are not in use, to allocate memory to processes when they need it and deallocate it when they are done, and to manage swapping between main memory and disk when main memory is too small to hold all the processes. (pg. 373 Tanenbaum)\nCOSA FA il MMEMORY MANAGER?\nTiene traccia della memoria libera Configura la MMU Binding (3) üü© In questo caso parliamo di associazione fra indirizzi logici e indirizzi fisici, in pratica ad altro livello, ma la stessa cosa. Nomi e Scope parliamo di binding fra variabili e nome della variabile.\nL√¨ abbiamo deciso 4 modi in cui si pu√≤ fare il binding! Sono molto simili rispetto a quelle, per√≤ ora stiamo parlando a un livello pi√π basso.\nBINDING A COMPILAZIONE\nDue istanze del programma non possono mai essere eseguiti CONTEMPORANEAMENTE, come per microcontrollori si pu√≤ fare una cosa simile.\nChiamato codice assoluto. perch√© √® mappato direttamente in una certa zona in fase di compilazione, non cambier√† MAI.\nStessi indirizzi per ogni esecuzione del programma.\nSlide binding compilazione\nSlide vantaggi e svantaggi\nBINDING A CARICAMENTO\nTutti gli indirizzi sono offsettati da un indirizzo 0.\nIn questo senso quando carico una istanza del programma, basta offsettare tutti gli indirizzi a un certo punto.\nSlide binding a caricamento\nSlide vantaggi e svantaggi\nSi pone pi√π onere al loader che deve sapere dove caricarti la roba. Per√≤ anche qui niente hardware!\nBINDING A ESECUZIONE\nAnche qui c‚Äô√® l‚Äôoffset, ma √® pi√π fine. L‚Äôeseguibile pensa di avere gli indirizzi offsettati da 0, poi a runtime la MMU traduce questo indirizzo logico all‚Äôindirizzo reale, che √® offsettato a qualcosa.\nSlide binding a esecuzione\nRegistri MMU Registro di locazione üü© In pratica abbiamo una tabella, molto simile a una tabella Network Address Translation di rete, ma con scopi molto diversi.\nAllo stesso modo in cui un pacchetto entra, viene fatto match nella tabella ed esce in modo diverso, abbiamo una registro di rilocazione che fa lo stesso JOB.\nSlide Registro di rilocazione\nSolitamente\nCodice Dati Stack Extra (utilizzi speciali, tipo copia da stack a dato o simili, praticamente usi come ti pare). Registro di limite üü© Questo nuovo registro permette di fare controlli sulla sicurezza. Praticamente fa check su indirizzi, se l‚Äôindirizzo soddisfa regola e.g. maggiore di 1000 allora manda avanti, altrimenti in errore\nSlide registro di limite\nLoading dinamico üü© Routine vengono caricate solo quando le chiamo, le abbiamo gi√† fatte in archietttura quando abbiamo parlato di traslazione di indirizzi dinamici 9.4.4 Indirizzamento dinamico. Generava una trap, e poi veniva trovato l‚Äôindirizzo corretto.\nLINKING STATICO E DINAMICO\nNota Loading ‚â† Linking!, per√≤ posso fare loading dinamico con linking dinamico. üòÄ\nStatico invece √® quando l‚Äôeseguibile ha tutte le funzioni che gli servono (copiate e incollate dentro l‚Äôeseguibile, senza dipendenze esterne, molto pi√π pesante, ma √® isolato, diciamo).\nSlide vantaggi svantaggi\nMINIDEMO LOADING\nProva a compilare un file e poi compilare con\n#include \u0026lt;stdio.h\u0026gt; int main() { puts(\u0026#34;eee\u0026#34;); } gcc -o out prova.c, normalmente linka dinamicamente, che puoi vedere con nm,\nse runni con la flag -static e fai la stessa cosa, allora vedi che il sinbolo √® definito.\nAllocazione pagine Definizioni: üü© ALLOCARE: Significa assegnare spazio di memoria fisica al programma.\nSTATICA DINAMICA,: se resta per l\u0026rsquo;intera vita del programma o meno.\nCONTIGUA O NON CONTIGUA: se la memoria mappata √® tutta a un filo senza buchi o meno.\nSlide definizioni\nPartizioni fisse üü® Questa √® una tecnica molto simile alla gestione della heap in blocchi fissi Gestione della memoria. In pratica ho delle partizioni fisse.\nSlide partizioni fisse\nSolitamente sono utili per sistemi Embedded, in cui non vuoi perdere tempo a fare conversioni, e vuoi questa cosa statica.\nPoi c‚Äô√® di nuovo il pippone della frammentazione interna ed esterta presente in Gestione della memoria, e in Livello OS. Si parla anche di soluzioni a questo, come la compattazione, ne abbiamo gi√† parlato, quindi qui sto zitto.\nNOTA SULLA COMPATTAZIONE:\nQuando voglio fare compattazione, devo interrompere certi programmi, copiare tutto il programma ad indirizzo diverso, cambio indirizzo di allocazione e poi lo posso far ripartire (quindi da stato running a ready dopo queste operazioni), per√≤ lentissimo!.\nBitmap üü© In pratica tutta la memoria viene divisa in qualche chunks di memoria, per esempio se ho in totale 1024 byte di memoria, potrei dividerla in blocchi da 32 byte, allora mi tengo una bitmap di 1024 /32 = 32, cos√¨ so che mi dovr√≤ tenere una bitmap di 32 bits, un bit mi indica 1 se ho usato quel blocco, 0 altrimenti.\nPer allocare in questa struttura di dati basta andare a cercare una serie di blocchi contigui liberi.\nSlide bitmap\nLinked list üü© Tutti i blocchi sono tenuti in una lista linkata, che ha un booleano per indicare se √® occupato o meno, e poi la lunghezza. L‚Äôallocazione √® uno scorrimento di questa lista linkata.\nSlide linked list\nQuando vengono deallocati, si pu√≤ utilizzare la compattazione parziale di cui abbiamo parlato in Gestione della memoria.\nSlide compattazione parziale\nCi sono altri generi di algoritmi, come next fit, oppure worst fit, per√≤ alla fine hanno performance molto peggiori rispetto a first o best fit. In generale questi problemi fanno ancora frammentazione, quindi non √® che siano buone buone buone come cose.\nPaginazione Le tecniche di paginazione nascono per essere una alternativa molto pi√π efficiente rispetto ai metodi di fitting precedenti, per questo motivo ora andiamo a descriverlo:\nAndare a guardare Algoritmi di paging per capire in che modo vengono gestite le pagine.\nDescrizione idee generale üü© La memoria del programma √® divisa in pagine, e poi questo √® messo nella memoria fisica dette frame, e sar√† gestita dalla MMU. La frammentazione interna esiste ma √® molto minimo, la frammentazione esterna non esiste proprio ora.\nSlide esempio di paginazione\nImplementazione della paginazione üü© Questa √® esattamente la parte che abbiamo spiegato in Livello OS, in pratica, l\u0026rsquo;indirizzo logico viene diviso in indirizzo di paginazione e indirizzo di memoria dentro la pagina stessa\nPer esempio se ho 4096 bit per una singola pagina (standard attuale), ho che nell‚Äôintero indirizzo della pagina √® data dai primi 20 bit, l\u0026rsquo;inddirizzo all‚Äôinterno della pagina dai next 12.\nEsempio di utilizzo della paginazione\nDESIGN DELLA PAGINAZIONE\nBlocchi potenza di due cos√¨ √® facile dividere gli indirizzi senza altre conversioni Non troppo grosso, cos√¨ fa meno frammentazione Non troppo piccolo, cos√¨ non ho troppe pagine. Storare la tabella delle pagine (2) üü© Dobbiamo trovare un modo per storare la tabella delle pagine, per esempio con un giga di memoria sarebbero circa un milione di pagine, storare in una tabella stile registri (come NAT di reti) √® troppo costoso come metodo.\nMettere in memoria, dovresti fare due accessi una nella page table, e una in memoria (e quindi molto lento!).\nQuindi vogliamo fare qualcosa di mezzo:\nLa page table sta in memoria In MMU sta una cache della page table per risoluzione di indirizzi recenti, guarda Memoria, questa si chaima Translation lookaside buffer, utilizzata la tecnica dei registri associativi, quelli che abbiamo utilizzato nell\u0026rsquo;implementazione dei Router in Data Plane, praticamente ti fanno ili confronto in modo immediato. Slide TLB\nEsempio tabella di pagine nuovo\nQuando il TLB missa, crea una trap, e iil sistema operativo rimette nella TLB quello che manca. Solitamente se sono grandi 10 celle √® gi√† sufficiente, perch√© principio di localit√† √® molto imporntante\nSegmentazione Introduzione idee segmentazione üü© Anche questo ne abbiamo gi√† parlato in architettura Livello OS.\nComunque divido il programma logicamente in diverse sezioni\nConcettualmente diversi (quindi regole di accesso diverse)\nLe singole aree contengono codice omogeneo (e.g. Testo ‚Üí area codice).\nEsempio di aree di segmentazione\nAllora se dividiamo in questo modo individiamo l\u0026rsquo;indirizzo logico come\n(nome-segmento, offset del segmento) ‚Üí indirizzo fisico.\nMa come fare a ricondurre questo con le pagine? Come metterlo dentro la MMU?\nVedremo l‚Äôutilizzo di una tecnica ibrida che unisce segmentazione con paginazione.\nConfronto con paginazione (!) üü®+ Slide differenze segmentazione e paginazione\nAllocare segmenti in memoria √® totalmente simile all‚Äôallocazione di zone di memoria contigue in memoria quindi devo tornare ad utilizzare algoritmi per memoria continua, per questo motivo ho forti problemi di frammentazione, quindi torno ad avere problemi come in precedenza!\nImplementazione segmentazione üü© Per i motivi di sopra, utilizzo la paginazione per andare con segmentazione, divido i segmenti in pagine!\nQuesto implica aumento della frammentazione interna. dato che per ogni segmento posso perdere pezzi nella pagina allocata (per√≤ alla fine √® molto ininfluente, al massimo 4k di ram per pagina)\nImplementazione slide\nEccesso del segmento ‚Üí segmentation fault ecco da dove deriva il nome üòÄ\n","permalink":"https://flecart.github.io/notes/paginazione-e-segmentazione/","summary":"Memoria sistema Operativo Guradare Memoria virtuale Per vedere come vengono rimpiazzate le pagine\nIn quest sezione andiamo a parlare di come fanno molti processi a venire eseguiti insieme, anche se lo spazio di memoria fisico √® lo stesso. Andiamo quindi a parlare di spazio di indirizzi, risoluzione di questi indirizzi logici, segmentazione e paginazione. (e molto di pi√π!)\nMMU Controlla se l‚Äôaccesso di memoria √® bono o meno. (traduzione fra indirizzo logico e fisico)","title":"Paginazione e segmentazione"},{"content":"Introduzione Monoforfo üü© Quando non posso utilizzare un tipo come parametro. Ossia non possiamo definire una funzione generica.\nSlide monomorfismo\nPolimorfismo Polimorfismo, come dice il nome, significa avere tante forme, in questo caso tanti tipi. Ma avere tanti tipi non √® una cosa ambigua? Questa cosa si risolve solitamente a compile time (facendo checks di sottotipo, oppure dispatch della funzione corretta).\nTipologie di Polimorfismo (3) üü© Slide tipologie di monomorfismo\nad-hoc polymorphism questo √® anche chiamato overloading in cui vado a definire un nuova funzione (con lo stesso nome) che accetti il nuovo tipo di dato.\nsubtype polymorphism\nparametric polymorphism\nAd-hoc (3) üü© Slide ad-hoc polimorphism\nQuesto √® molto simile al tipo somma, solamente fatto da un punto di vista funzionale (i domini devono essere separati).\nIn C sono molto conosciute questa tipologia di polimorfismo. Per√≤ ci sono anche forme comuni, come l‚Äôoperatori aritmetici.\nL‚Äôinvocazione √® anche chiamato dispatch , quando abbiamo risolto l‚Äôoverloading, ossia abbiamo fatto il dispatch dell‚Äôinvocazione, allora l‚Äôoverloading scompare e viene eseguita una specifica funzione. Questa funzione pu√≤ essere fatta in modo statico oppure dinamico.\nRiassumento:\nDefinisco stesso nome che prendono tipi diversi Avviene un dispatch statico o dinamico Una volta avvenuto il dispatch, la funzione eseguita √® univocamente identificata. Statico o dinamico nel dispatch\nDispatch √® il processo che va a decidere la funzione overloadata da chiamare, questo processo si pu√≤ classificare come dinamico se avviene durante il runtime (come solitamente √® per le interfacce) oppure statico quando avviene e a tempo di compilazione (come solitamente avviene per le funzioni overloaddate).\nDi sottotipo Possiamo andare a dire che un tipo S √® sottotipo di un tipo T, indicato con $S \u003c: T$, quando S pu√≤ essere utilizzato in qualunque occasione al posto di T. Questo √® anche chiamato come principio di sostitutione di Liskov.\nSetTheory per sottotipi üü©‚Äî Slide polimorfismo di sottotipo\nQuesto concetto l‚Äôabbiamo anche accennato in Algebra dei tipi quando abbiamo parlato di coercizione.\npraticamente quando abbiamo un tipo pi√π specifico $S$ che andiamo ad indicare con $S \u003c: T$, allora quando ho S e devo utilizzare T, lo posso fare, questo perch√© S contiene tutte le caratteristiche di T.\nSolitamente questa √® una relazione di preordine ossia riflessiva e transitiva, spesso anche antisimmetrica, quindi √® spesso un ordine parziale.\nSi pu√≤ dire che esiste un rapporto di specificazione (parola da utilizzare nell‚Äôorale per bella figura lel) perch√© S √® pi√π specifico di T, in questo senso possiamo utilizzare S in ogni posto in cui c‚Äô√® T.\nTipologie di sottotipaggio (2) üü© Slides subtyping con records\nPer questa parte possiamo andare a definire un concetto di sottotipaggio per profondit√† o per larghezza.\nPer laghezza: basta che il sottotipo abbia molti pi√π campi! in questo senso Dog \u0026lt; Animal, perch√© anche dog posso utilizzarlo come un animal, dato che ha tutte le cose di animal. (l‚Äôunica differenza col duck typing √® il fatto che T qui √® esplicito, mentre nel duck typing non mi importa del tipo, solamente dello stesso utilizzo).\nDifferenza fra duck e width subtyping per chatGPT\nWidth subtyping is a form of subtype polymorphism where a type is considered a subtype of another type if it has at least the same properties and methods as the supertype. This means that a subtype can have more properties and methods than the supertype, but it must at least have all of the ones that are defined in the supertype. This is called \u0026ldquo;width\u0026rdquo; because it is based on the width of the type\u0026rsquo;s interface.\nDuck typing, on the other hand, is a more dynamic approach to type checking where the type of an object is determined by its behavior at runtime rather than its static type. In other words, if it walks like a duck and quacks like a duck, then it must be a duck. This means that two objects with different types can still be treated as if they have the same type if they share the same behavior.\nIn summary, width subtyping is based on the interface of a type and allows for subtype polymorphism, while duck typing is based on the behavior of an object at runtime and allows for more dynamic type checking.\nPer profondit√†: Quando un campo ha un tipo che sia un sottotipo di un altro. Questo √® visto molte meno volte, per√≤ si pu√≤ fare. Questa ha per√≤ delle particolarit√†, √® importante introdurre il concetto di covariante per tipi quando le parti del record mantengono la stessa direzione di sottotipaggio. Quando abbiamo due tipi che sono covarianti, possiamo utilizzarli solo per le letture. In scrittura per√≤ potremmo avere dei campi non inizializzati, quindi non va molto bene. (nell\u0026rsquo;esempio avremmo un animale in output in scrittura, mentre gli abbiamo dato un dog e ci aspettavamo un dog in output). (queste nozioni di covarianza comunque sono sempre in funzione del contesto).\nIn pratica vado a rimpazzare i campi del record con dei sottotipi, questo √® buono per cose immutabili, for example, you can assign 1.5 to the \u0026lsquo;x\u0026rsquo; field of a real point (a record with two real fields), but you can\u0026rsquo;t do the same to the \u0026lsquo;x\u0026rsquo; field of an integer point (which, however, is a deep subtype of the real point type) because 1.5 is not an integer.\nCovariante e Controvariante e consumo (!!) üü®++ Slide covariante, controvariante e consumi e produzione\nEsempio strano\nQuesta nozione si basa sull‚Äôinversione fra produzione e consumazione.\nAvevamo detto che abbiamo una relazione di sottotipo, perch√© DogHouse \u0026lt; AnimalHouse quindi sono covarianti rispatto a Dog \u0026lt; Animal House. Ma nella fase di consumo, questo si inverte, quindi si pu√≤ dire che siano controvarianti.\nIn breve:\nConsumo (input) ‚Üí Controvariante Produzione (output) ‚Üí Covariante Il motivo per cui succede √® che Dog fn utilizza i campi di Dog, che sono pi√π estesi, posso sostituire a questo consumo anche animal, che utilizza i campi di animal, quindi sono anche presenti in Dog, ecco che il rapporto si inverte\nPossiamo fare un parallelo fra le funzioni di consumo e quelle di produzione.\nSlide esempio covariante e controvariante easy\nSussunzione üü® Con sussunzione andiamo a parlare di quando possiamo fare l‚Äôinferenza di sottotipaggio ossia se √® vero o meno che un tipo √® sottotipo di un altro (e quindi possibile utilizzare S al posto di T in qualunque luogo).\nSlide sussunzione metodi\nPossiamo fare la sussunzione in modo estensionale o intensionale quindi o:\nCaratterizzando tutti gli elementi del sottotipo Parlare di predicati e domini. Tipo estensionali o intensionali üü©- abbiamo parlato di estensionale o intensionale\nEsempi di sussunzione\nPolimorfismo parametrico Tipi parametrici üü© Slide tipi parametrici\nQuando abbiamo delle operazioni anche se non conosciamo esattamente cosa c‚Äô√® sotto, per√≤ riguardo la struttura so bene cosa vanno a fare. (un esempio riguardo a questo √® il sort).\nQuesta parametrizzazione ci permette di definire delle cose per tutti i tipi che possiedono quella funzione (ricorda i tratti di rust), ed √® per questo che possiamo dire che sia un tipo universale. Questa cosa che vale per tutti ci permette di poter provare dei teoremi aggratis.\nEsempio di teorema for free\nIbridazione con polimorfismo di sottotipo üü® Slide ibrido con pol di sottotipo\nA volte non vogliamo che la nostra funzione vada per tutti, senza quindi conoscere come √® fatto sotto, vorremmo avere certe funzioni (quindi un sottotipo del tipo generale), per esempio nei tratti di rust possiamo dire che questa nostra funzione vada per tutte in cui √® definita una certa funzione/interfaccia/tratto, in questo senso andiamo ad utilizzare un sottotipo\nArray c‚Äôerano gi√† all‚Äôinizio, lo puoi utilizzare covariante in entrambe le direzioni, mentre altrimenti non ti permetterebbe di utilizzare in entrambe le direzioni (vuole che tu sia prima sicuro se vuoi utilizzarlo come consumer o producer. un buon modo per ricordarsi √® PECS producer deve estender, mentre consumer deve fare super.\nAbbiamo sempre che √® safe, nel senso che ritorna sempre un tipo senza bloccarsi (e posso sapere a tempo di compilazione cosa vada a ritornare).\nEsempi di utilizzo di polimorfismo parametrico e di sottotipo Tipi maybe e result üü© Questi sono alcuni tipi ispirati alle monadi, solamente capire in che formato sono:\nMaybe: Some + None Result: come le promises di js, possiamo esprimere i risultati di errore e nel caso sia andato tutto bene. ","permalink":"https://flecart.github.io/notes/polimorfismo/","summary":"Introduzione Monoforfo üü© Quando non posso utilizzare un tipo come parametro. Ossia non possiamo definire una funzione generica.\nSlide monomorfismo\nPolimorfismo Polimorfismo, come dice il nome, significa avere tante forme, in questo caso tanti tipi. Ma avere tanti tipi non √® una cosa ambigua? Questa cosa si risolve solitamente a compile time (facendo checks di sottotipo, oppure dispatch della funzione corretta).\nTipologie di Polimorfismo (3) üü© Slide tipologie di monomorfismo","title":"Polimorfismo"},{"content":"Ultima modifica: June 21, 2023 9:07 PM Primo Abbozzo: June 17, 2023 11:59 PM Studi Personali: No\nURI Cosa sono? Per cosa vengono utilizzati? Che differenza c\u0026rsquo;√® fra URL e URN? sintassi dell‚ÄôURI Alcuni esempi di schema (e relativo utilizzo e sintassi per l‚ÄôURI) IRI e IDN, cosa sono? Cosa sono i CURIE? Cosa √® URL Ref e come viene risolto Cosa √® uri resolution, e cosa uri dereference? Cosa √® LOD? Cosa √® managed route? e filesystem route? Character and content encoding Character Quali sono le codifiche maggiormente utilizzate? Cosa sono ZWNBSP e BOM? Cosa sono Carriage Return Line Feed, Perch√© ci sono Delete e Canc? Quali sono le differenze principali fra UTF 8 e latin 1? Cosa sono utf 8, 16, e 32? Cosa √® UCS? Perch√© si fa differenza fra ucs 2 e 4? Cosa sono i piani? E i gruppi in UCS? Quali sono le difficolt√† maggiori per creare un encoding riguardanti un ampio spettro di linguaggi. Esistono alcuni principi per la creazione di encoding, per esempio continuit√†, ordine e raggruppamento. Spiegarli. Cosa sono i codici di controllo? Cosa sono i caratteri shift? in UTF-8? Quanti caratteri necessari sono per encodare caratteri latini, antichi, cinesi, o greci, accentati? Content Cosa √® il content encoding? Perch√© √® necessario? Cosa √® il protocollo SMTP? Perch√© √® importante in questo contesto? Quali sono le limitazioni principali per SMTP? Perch√© √® importante conoscere queste limitazioni? Cosa √® il MIME? in che modo vado oltre le limitazioni del SMTP in questo modo? Quali sono i due headers che MIME ha introdotto? cosa sono base64 e quoted printable? Perch√© ne parliamo nel contesto dei MIME? CSS Introduzione 1Ô∏è‚É£ Cosa √® la tipografia? 0Ô∏è‚É£ Fare una breve storia della tipografia. 2Ô∏è‚É£ Cosa √® un font famili e un type face? 0Ô∏è‚É£ Un esempio di classificazione di fonts. Quali sono alcune cattive pratiche sui blocchi? Qual √® la differenza fra spazi di colore additivi e sottrattivi? Un esempio reale di questi colori? CSS C\u0026rsquo;√® molto poco di teorico in questa parte, come per HTML direi di saltarlo.\nJavascript Su ajax quali sono gli stati di ajax principali? Come si fa una richiesta ajax? Perch√© si √® introdotto ajax? quali sono i vantaggi principalli di questa tecnologia? Perch√© √® stata soppiantata, perch√© non si utilizza pi√π? Sintassi avanzata Questa parte √® importante perch√© la pu√≤ chiedere nell‚Äôesame nuovo (cio√® leggere e comprendere delle cose astruse di javascript).\ndifferenza fra function expression e function statement. Quali sono i valori falsy e truthy in js? Fai proprio l‚Äôelenco. (che brutto linguaggio) cosa √® il this in javascript? Cosa √® una IIFE? In che modo si possono creare oggetti in variabile privata in ecmascript 2015? https://www.fabiovitali.it/TW/2023/UmmaGramma/ Altro Cookies e JWT In che modo i cookies differiscono rispetto al JWT? Perch√© cookie opachi? Quali sono i 3 schema di autenticazione pi√π comuni? Come funzionano? HTTP Quando si dice che un metodo HTTP √® safe? Quando √® idempotente? Fare esempi. Cosa sono method e action in un form? Cosa sono e qual √® la differenza fra pipelining e multiplexing? Che vantaggio c\u0026rsquo;√® ad utilizzare queste? ando √® idempotente? Fare esempi. Cosa sono method e action in un form? Cosa sono e qual √® la differenza fra pipelining e multiplexing? Che vantaggio c\u0026rsquo;√® ad utilizzare queste? ","permalink":"https://flecart.github.io/notes/preparazione-esame/","summary":"Ultima modifica: June 21, 2023 9:07 PM Primo Abbozzo: June 17, 2023 11:59 PM Studi Personali: No\nURI Cosa sono? Per cosa vengono utilizzati? Che differenza c\u0026rsquo;√® fra URL e URN? sintassi dell‚ÄôURI Alcuni esempi di schema (e relativo utilizzo e sintassi per l‚ÄôURI) IRI e IDN, cosa sono? Cosa sono i CURIE? Cosa √® URL Ref e come viene risolto Cosa √® uri resolution, e cosa uri dereference? Cosa √® LOD?","title":"Preparazione Esame"},{"content":"Condizionata Definizione üü© Andiamo a definire una probabilit√† di un evento $A$, condizionata a un evento non nullo $B$, come\n$$ P(A|B) = \\dfrac{P(A\\cap B)}{P(B)} $$ Questo √® la cosa fondamentale per poter considerare cose come bayes perch√© in questo modo abbiamo una certa relazione fra causa ed effetto e anche il contrario! Cosa che ci piace molto molto molto.\nLa definizione di sopra √® un probabilit√† üü© Dimostrazione mia\ninanzitutto vediamo che soddisfatta il fatto che $P(A) \\in [0, 1]$, poi possiamo notare che\n$$ P(\\Omega | B) = \\dfrac{P(\\Omega\\cap B)}{P(B)} = P(B) / P(B) = 1 $$ $$ P(\\bigcup A_n | B) = \\dfrac{P(\\bigcup A_i\\cap B)}{P(B)} = \\dfrac{P(\\bigcup (A_i\\cap B))}{P(B)} = \\sum_{i = 1} ^\\infty\\dfrac{P(A_i\\cap B)}{P(B)} $$ Quindi ecco che √® una probabilit√† su Omega!\nL‚Äôultima disuguaglianza vale perch√© sto facendo unione di insiemi disgiunti. (che sono disgiunti per ipotesi.\nRegola della catena üü© Dimostrazione in libro\nQuesta √® uno delle propriet√† pi√π importanti che abbiamo per la probabilit√† √® molto interessante notare come basta una induzione cos√¨ semplice per fare questo\nFormula di disintegrazione o delle probabilit√† totali üü© Dimostrazione\nQuesto non √® tanto difficile da dimostrare, bisogna notare che\n$$ B = \\bigcup_i (B \\cap A_i) $$ il che √® vero perch√© $\\forall i, j A_i \\cap A_j = \\empty, \\bigcup A_i = \\Omega$ per ipotesi, e quindi sto facendo una unione disgiunta, si ha per $\\sigma-$additivit√† la prima tesi, mentre la seconda tesi √® derivante dalla definizione di probabilti√† condizionate\nIndipendenza d\u0026rsquo;eventi Introduzione L‚Äôintuizione di maggior rilievo √® il fatto che non ho nuove informazioni se √® successo B ossia deve valere che $P(A|B) = P(A)$, oppure che $P(B|A) = P(B)$, dato che vale per entrambi, √® una propriet√† simmetrica.\nha quindi senso andare a definire che due eventi siano indipendenti se vale questa propriet√†:\n$$ P(A \\cap B) = P(A)P(B) $$ √à molto importante notare che l\u0026rsquo;indipendenza di a due a due due eventi non implica l\u0026rsquo;indipendenza di 3! (guardare l\u0026rsquo;esempio sul libro)\nEsempio fatto in classe di questo\nSe ho un evento composto da due lanci un dado a 6 faccie, se considero gli eventi:\nAl primo lancio esce un numero dispari Al secondo un numero pari La somma dei due lanci √® pari. Si pu√≤ notare che insieme tutti non possono avvenire, ma se li prendo a due a due sono indipendenti, questo √® molto curioso come fenomeno!\nInfatti deve essere che valga la propriet√† di sopra per ogni singolo sottoinsieme. √à una cosa molto importante!\nCaso speciale\nNel caso in cui $P(A) = 0$ , oppure vale l‚Äôaltro, oppure basta che siano $P(A \\cap B) = 0$ ossia siano disgiunti allora secondo la definizione sono indipendenti, anche se logicamente dovrebbero essere dipendenti, dato che uno implica l\u0026rsquo;esclusione dell‚Äôaltro.\nTh Indipendenza e complementari üü® Dimostrazione\nDubbio vecchio\nLa dimostrazione √® un po`strana, per quale motivo per (ii) ‚Üí (i) √® necessario utilizzare l\u0026rsquo;induzione? Perch√© voglio dimostrarlo per ogni modo in cui posso scegliere un sottoinsieme! √à molto interessante come con il secondo riesco a dimostrare il tutto.\nRisposta:\nhai capito male la definizione di indipendenza, affinch√© sia indipendente, deve essere che lo siano tutti i sottoinsiemi di eventi! Quindi ci√≤ rende la dimostrazioen molto pi√π contorta.\n","permalink":"https://flecart.github.io/notes/probabilita-condizionata-e-indipendenza/","summary":"Condizionata Definizione üü© Andiamo a definire una probabilit√† di un evento $A$, condizionata a un evento non nullo $B$, come\n$$ P(A|B) = \\dfrac{P(A\\cap B)}{P(B)} $$ Questo √® la cosa fondamentale per poter considerare cose come bayes perch√© in questo modo abbiamo una certa relazione fra causa ed effetto e anche il contrario! Cosa che ci piace molto molto molto.\nLa definizione di sopra √® un probabilit√† üü© Dimostrazione mia","title":"Probabilita condizionata e indipendenza"},{"content":"5.1 Geometria introduttiva 5.1.1 Tangente e pendenza Si pu√≤ trovare la relazione fra la pendenza della retta e la tangente.\nPossiamo analizzare la retta dal punto di vista analitico, della formula e si pu√≤ dimostrare che data una retta nella forma $y = mx + q$ $m$ √® la pendenza della retta.\n5.1.2 Formula generale delle rette Dati qualunque due punti .$(x_1, y_1), (x_2, y_2)$ possiamo dire che la pendenza √® esprimibile come\n$\\dfrac{ (y_2 - y_1)}{(x_2 - x_1)}$, possiamo anche creare un fascio di rette che passa per un punto come\n$y - y_0 = m(x - x_0) + q$\n5.1.3 Intuizione tangente Per qualunque funzione, possiamo intuitivamente designare la derivata come se fosse il valore della retta tangente in quel punto al grafico.\n5.2 Definizione 5.2.1 Rapporto incrementale Data una funzione $f(x)$, si dice rapporto incrementale di $f$ in $x_0$ questo valore\n$$ \\dfrac{f(x) - f(x_0)}{x - x_0} $$ 5.2.2 Derivabilit√† Allora cerchiamo di minimizzare la distanza fra i due punti che scelgo, allora ho la derivata in questo punto!\n$$ \\exists\\lim_{x \\to x_0} \\dfrac{f(x) - f(x_0)}{x - x_0} \\in \\R = \\dfrac{df(x)}{dx} $$ E si pu√≤ scrivere anche in una altra forma analoga: che √® pi√π comoda da gestire perch√© ho qualcosa che tende a 0\n$$ \\exists\\lim_{h \\to 0} \\dfrac{f(x + h) - f(x)}{h} = \\dfrac{df(x)}{dx} $$ Se esiste questo limite, allora la funzione √® derivabile in quel punto.\nFunzione\nSi dice che una funzione √® derivabile se lo √® nel suo dominio.\n(Per gli estremi destri si considera solamente la derivabilit√† sinistra, in modo simile anche per gli estremi sinistri)\nSe esiste la derivata in questo punto allora si pu√≤ dire che in questo punto esista una tangente geometrica\n5.2.3 Derivabilit√† destra e sinistra Si dice che una funzione $f$ √® derivabile a sinistra (in modo analogo a destra se\n$$ \\exists\\lim_{x \\to x_0^-} \\dfrac{f(x) - f(x_0)}{x - x_0} = \\dfrac{df(x)}{dx} $$ 5.2.4 Condizioni di derivabilit√† Dato che la derivata √® un limite, le condizioni di esistenza sono molto simili alle condizioni di esistenza di un limite. (no sono identtivi)\nSi pu√≤ analizzare la derivabilit√† delle funzioni utilizzando queste condizioni es:\n$f(x) = |x|$ si scopre che non √® derivabile perch√© a sinistra √® -1 mentre a destra √® +1, si dice che √® un punto angoloso (si scopre che per qualunque punto angoloso, questa non √® pi√π derivabile)\nBisogna fare per√≤ attenzione perch√© non √® vero che ogni valore assoluto non √® derivabile perch√© ad esempio $x|x|$ √® derivabile.\n5.3 Propriet√† e osservazioni 5.3.1 Proposizione della retta tangente Questa proprosizione collega il concetto di derivata e della tangente.\nSe $f$ √® derivabile in $x_0 \\in I \\implies \\exists \\text{retta tangente al grafico f in } x_0=x\\\\ \\text{si pu√≤ dire che abbia equazione} \\\\ y = f'(x_0)(x - x_0) + f(x_0)$\n5.3.2 Derivate conosciute Derivate\n5.3.3 Algebra delle derivate Si possono utilizzare in modo simile l\u0026rsquo;algebra delle derivate\nEnunciato\nDerivazione qui\n5.3.4 Composizione di funzioni Enunciato\nDimostrazione [qui](https://www.math-linux.com/mathematics/derivative-of-a-function/article/chain-rule-proof-derivative-of-a-composite-function#:~:text=Derivative%20of%20composite%20function%20(g,%C3%97%20v\u0026rsquo;(x)%20.)\n5.3.5 Continuit√† e derivabilit√† Si pu√≤ dimostrare che se una funzione √® derivabile in un punto allora √® continua nel punto stesso.\nx punto di accumulazione\n$$ \\lim_{h \\to 0}\\dfrac{f(x+h) - f(x)}{h} = l \\iff \\lim_{h \\to 0}\\dfrac{1}{h}\\cdot(\\lim_{h \\to 0}f(x+h) - f(x)) = l\\\\ \\iff \\lim_{h \\to 0}f(x+h) = f(x) + l\\lim_{h \\to 0}h = f(x) $$ C\u0026rsquo;√® anche una cosa dimostrazione molto simile.\nDimostrazione del prof.\n5.3.6 Derivate di inverse Enunciato\n5.4 Derivate di ordine superiori Una funzione potrebbe essere derivabile pi√π di una volta, allora si dice che si pu√≤ derivare pi√π volte.\n√à interessante relazionare questo concetto di derivabilit√† con il concetto di continuit√†\n5.4.1 Continuit√† classe C √à come classificare una funzione in base la sua regolarit√†, ossia rispetto a quante volte posso fare la derivata e la continut√† di classe C √® un buon modo di formalizzare questo dato.\nContinuit√† di classe C\n!\nSi pu√≤ notare che una funzione pu√≤ essere continua in $C^k$ ma non in $C^{k+1}$. zare questo dato.\nContinuit√† di classe C\n!\nSi pu√≤ notare che una funzione pu√≤ essere continua in $C^k$ ma non in $C^{k+1}$.\n","permalink":"https://flecart.github.io/notes/derivate/","summary":"5.1 Geometria introduttiva 5.1.1 Tangente e pendenza Si pu√≤ trovare la relazione fra la pendenza della retta e la tangente.\nPossiamo analizzare la retta dal punto di vista analitico, della formula e si pu√≤ dimostrare che data una retta nella forma $y = mx + q$ $m$ √® la pendenza della retta.\n5.1.2 Formula generale delle rette Dati qualunque due punti .$(x_1, y_1), (x_2, y_2)$ possiamo dire che la pendenza √® esprimibile come","title":"Derivate"},{"content":"This set takes inspiration from chapter 9.2 of (Bishop 2006). We assume that the reader already knows quite well what is a Gaussian mixture model and we will just restate the models here. We will discuss the problem of estimating the best possible parameters (so, this is a density estimation problem) when the data is generated by a mixture of Gaussians.\nRemember that the standard multivariate Gaussian has this format: $$ \\mathcal{N}(x \\mid \\mu, \\Sigma) = \\frac{1}{\\sqrt{ 2\\pi }} \\frac{1}{\\lvert \\Sigma \\rvert^{1/2} } \\exp \\left( -\\frac{1}{2} (x - \\mu)^{T} \\Sigma^{-1}(x - \\mu) \\right) $$ Problem statement Given a set of data points $x_{1}, \\dots, x_{n}$ in $\\mathbb{R}^{d}$ sampled by $k$ Gaussian each with responsibility $\\pi_{k}$ the objective of this problem is to estimate the best $\\pi_{k}$ for each Gaussian and the relative mean and covariance matrix. We will assume a latent model with a variable $z$ which represents which Gaussian has been chosen for a specific sample. We have this prior: $$ p(z) = \\prod_{i = 1}^{k} \\pi_{i}^{z_{i}} $$ Because we know that $z$ is a $k$ dimensional vector that has a single digit indicating which Gaussian was chosen.\nThe Maximum Likelihood problem The frequentist approach with Maximum likelihood is quite probable to give rise to particular edge-cases that make this method difficult to apply for this density estimation problem. Let\u0026rsquo;s remember that in the case of Gaussian mixture models, our loss function is the following: $$ \\min_{\\pi, \\mu, \\Sigma} \\log p(X \\mid \\pi, \\mu, \\Sigma) = \\sum_{n = 1}^{N} \\log \\left\\{ \\sum_{i = 1}^{k} \\pi_{i} \\mathcal{N}(x_{n} \\mid \\mu_{k}, \\Sigma_{k}) \\right\\} $$ Let\u0026rsquo;s see now a case where this function is not well behaved. Let\u0026rsquo;s consider the covariance matrix to be $\\sigma_{i}^{2}I$ and let\u0026rsquo;s say we have sampled a single point that is exactly $\\mu_{i}$ then we have that the contribution of this particular Gaussian to our loss function is $$ \\mathcal{N}(x_{n} \\mid x_{n}, \\mu_{i}, \\sigma_{i}) = \\frac{1}{\\sqrt{ 2\\pi } \\sigma_{_{i}}} $$ If we have a single point, and $\\sigma_{i} \\to 0$ which is reasonable because we have a single point on the mean, then this value explodes and makes the whole log-likelihood to go to infinity. This is a case we don\u0026rsquo;t want to explore. There are some methods that try to solve this problem. But in this setting we don\u0026rsquo;t want to explore this, and focus on the expectation maximization algorithm.\nThe expectation-maximization algorithm Dempster et al., 1977; McLachlan and Krishnan, 1997 are useful references for this method.\nDeriving the expected mean First we want to do some multivariable analysis in order to derive some conditions of the minima, for this reason we take the derivative with respect to $\\mu_{k}$ of the loss equation, and we derive that\n$$ 0 = - \\sum_{n = 1}^{N} \\frac{\\pi_{k}\\mathcal{N}(x_{n} \\mid \\mu_{k}, \\Sigma_{k})}{\\sum_{j} \\pi_{j} \\mathcal{N} (x_{n} \\mid \\mu_{j}, \\Sigma_{j})} \\Sigma^{-1}_{k} (x_{n} - \\mu_{k}) $$ We note that the bad part is that with the sum of the Gaussians at the denominator, we note that is the same as $$ p(z_{j} \\mid x) = \\frac{p (x \\mid z_{j}) p(z_{j})}{\\sum_{i} p(x \\mid z_{i}) p(z_{i})} = \\frac{\\pi_{j} \\mathcal{N}(x \\mid \\mu_{j}, \\Sigma_{j})}{\\sum_{i} \\pi_{i} \\mathcal{N}(x \\mid \\mu_{i}, \\Sigma_{i})} $$ Let\u0026rsquo;s call this variable $\\gamma(z_{j})$ and maybe introduce a index for the data point, so if $x = x_{n}$ (meaning if our variable $x$ is the $n$th sample then we call it $\\gamma(z_{nj})$. We can rewrite the above, after multiplying by $\\Sigma_{k}$ which is a constant after the vector is multiplied by this scalar value to be: $$ \\sum_{n=1}^{N} \\gamma(z_{nk})(x_{n} - \\mu_{k}) = 0 \\implies \\mu_{k} = \\frac{1}{N_{k}} \\sum_{n = 1}^{N} \\gamma(z_{nk}) x_{n} $$ Where $N_{k} = \\sum_{n = 1}^{N} \\gamma(z_{nk})$\nwe can interprete $N_{k}$ to be the number of points generated by the Gaussian $k$, and the internal part is just the weighted average of the points generated by $k$! This gives an easy interpretation of the mean of the expectation part of this algorithm.\nDeriving the expected deviation This one is harder, and I still have not understood how exactly this matrix derivative is done, but the end results is very similar to the above, we have $$ \\Sigma_{k} = \\frac{1}{N_{k}} \\sum_{n = 1}^{N} \\gamma(z_{nk})(x_{n} - \\mu_{k})^{T}(x_{n} -\\mu_{k}) $$ Deriving the priors By using Lagrange Multipliers we can find that $\\pi_{k} = \\frac{N_{k}}{N}$. Which is the last unknown parameter. This is not a closed form solution, but it\u0026rsquo;s why the iterative approach works for the expectation maximization algorithm. It\u0026rsquo;s easy to see that the two steps of the algorithms are the following:\nCompute the posterior $\\gamma$ Compute the best mean, variance and priors with the formula above and update them Repeat until convergence. It is guaranteed that the likelihood is increasing, but we might be stuck on local maxima and similar things.\nReferences [1] Bishop ‚ÄúPattern Recognition and Machine Learning‚Äù Springer 2006\n","permalink":"https://flecart.github.io/notes/expectation-maximization/","summary":"This set takes inspiration from chapter 9.2 of (Bishop 2006). We assume that the reader already knows quite well what is a Gaussian mixture model and we will just restate the models here. We will discuss the problem of estimating the best possible parameters (so, this is a density estimation problem) when the data is generated by a mixture of Gaussians.\nRemember that the standard multivariate Gaussian has this format: $$ \\mathcal{N}(x \\mid \\mu, \\Sigma) = \\frac{1}{\\sqrt{ 2\\pi }} \\frac{1}{\\lvert \\Sigma \\rvert^{1/2} } \\exp \\left( -\\frac{1}{2} (x - \\mu)^{T} \\Sigma^{-1}(x - \\mu) \\right) $$ Problem statement Given a set of data points $x_{1}, \\dots, x_{n}$ in $\\mathbb{R}^{d}$ sampled by $k$ Gaussian each with responsibility $\\pi_{k}$ the objective of this problem is to estimate the best $\\pi_{k}$ for each Gaussian and the relative mean and covariance matrix.","title":"Expectation Maximization"},{"content":"Ultima modifica: March 24, 2023 7:35 PM Primo Abbozzo: March 24, 2023 2:23 PM Studi Personali: No\nAmbienti di sviluppo Ambiente di sviluppo √® diverso rispetto all‚Äôambiente di deploy! bisognare fare delle differenze, sono dell macchine diverse, in questa sezione di documenti andiamo a parlare di norme e modi di lavorare per facilitare il metodo di sviluppo.\nNote di compatibilit√† Front-end Le compatibilit√†, soprattutto per cose browser (quindi front-end) cambiano molto spesso, come fare a trackare queste cose? C\u0026rsquo;√® un sito molto carino come https://caniuse.com/ .\nLa browser list, √® utilizzata per specificare unt browser di target per la nostra applicazione, non ho capito bene cosa serve.\nI *polifylli permettonol‚Äôesecuzione di codice recente\nGestione versioni Si utilizzano cose come package json, e tools come npm e yarn per gesitire queste dipendenze. Nei file lock ci sono gli hash, ti dice quale specifica versione funziona (praticamente serve per dirti esattamente tutte le cose necessarie per l‚Äôambiente di deploy, per questo lo devi committare! come il go sum). √à necessario, senn√≤ sono in dependency hell (una dipendenza che aggiunge una dipendenza di altre dipendenze, pu√≤ rallentare tutto), non riesco a gestire tutte queste velocemente!\nPoi si dividono in\ndevDependency quando √® solamente per lo sviluppo come linter, o file cli dependency quando serve per l\u0026rsquo;esecuzione del programma. semantic versioning\nSlide semantic versioning\nCi danno gi√† informazioni su compatibilit√†, versioni accettate e cose simili.\nStile Strumenti come esling, prettier, permettono di fare contorllo sullo stile, e anche correggerle in automatico! Queste fanno una analisi statica del codice e riformattano, oppure ti ritornano alcuni pezzi di roba ambigua.\nDi solito conviene perch√© rende il codice molto pi√π agibile e comprensibile dal team.\nCose come parentesi, indentazioni, sono importanti, anche ad esempio utilizzare stessi cases.\nType checking Slide typescript\nAbbiamo tutte le garanzie di Teoria dei Tipi! In pratica √® molto buono utilizzare questo\nTraspiler √à simile alla compilazione, ma √® fra linguaggi allo stesso livello (ad esempio versioni diverse di javascript, per essere comprensibile fra versioni browser diversi), mentre compilazione secondo vitali √® da linguaggi di alto livello a uno di livello inferiore, anche se non credo fosse questa la definizione in Macchine Astratte.\nReact utilizza molto babel, che √® il traspilatore principale per questo.\nMinifier e obfuscating vogliamo cercare di ridurre caratteri, in modo da minimizzare la grandezza del file di output mantenendone la semantica (quindi cosa faccia). Ci serve per esempio se vogliamo dare un file JS, ma vogliamo limitare la banda, per trasmettere le stesse informazioni.\nWebpack, un bundler che vedremo dopo riesce anche a fare minify.\nQuesta cosa √® molto diversa rispetto a offuscare!\noffuscare serve per rendere il coidce illeggibile, in modo da rendere pi√π difficile la comprensione del codice, e quindi da farci reverse engineering e scoprire vulnerabilit√† e simili ma anche per evitare di copiare l\u0026rsquo;applicaione e replicarlo altrove, anche questi sono fatti in automatico da certe applicazioni.\nRiassunto in breve traspiler minifier, obfuscating e compressione\nBundlers Ci sono molti bundlers il pi√π comune √® webpack.\nL‚Äôobiettivo √® mettere assieme tutti i moduli js in modo che sia solo 1, quindi molto pi√π efficiente da dare al web.\nAltro Sta facendo una lista di un sacco di tecnologie!!! üò±.\nMeglio andare a studiarseli da soli perch√© la lista non me ne facio niente, √® utile per√≤ sapere che esistono.\nDeve continuare dal testing\n","permalink":"https://flecart.github.io/notes/ambienti-di-sviluppo/","summary":"Ultima modifica: March 24, 2023 7:35 PM Primo Abbozzo: March 24, 2023 2:23 PM Studi Personali: No\nAmbienti di sviluppo Ambiente di sviluppo √® diverso rispetto all‚Äôambiente di deploy! bisognare fare delle differenze, sono dell macchine diverse, in questa sezione di documenti andiamo a parlare di norme e modi di lavorare per facilitare il metodo di sviluppo.\nNote di compatibilit√† Front-end Le compatibilit√†, soprattutto per cose browser (quindi front-end) cambiano molto spesso, come fare a trackare queste cose?","title":"Ambienti di sviluppo"},{"content":"Quick introduction Si assume che la descrizione pi√π intelligente di un qualcosa √® la stringa pi√π corta che descrive quella, un po\u0026rsquo; forse √® arbitrario, perch√© minore complessit√†, non √® detto che sia direttamente relazionata con la difficolt√† di descriverla.\nNel caso di AIT, diciamo che una cosa random non √® compressibile, altrimenti posso scriverla in modo pi√π compatto. √à importante stabilire che l\u0026rsquo;alfabeto che abbiamo per rappresentare qualcosa √® fissato a priori. Qualunque cosa che possiamo codare si pu√≤ analizzare da questo punto di vista della complessit√†.\nThe complexity of an object is assessed by finding\nthe¬†shortest among the available binary descriptions\nof that object.\nQuesta cosa permette di descrivere la complessit√† di un oggetto in modo assoluto (cio√® a s√© stante, mentre la entropia)\nInformation is what is left when any redundant data is thrown away.\nSi basa sulla ipotesi che se tolgo qualcosa comincio a non capirci pi√π diciamo di quella cosa, quindi √® tutto importante di quella stringa.\nSimple is frequent\n√à una assunzione che si ha su AIT, per√≤ in natura non √® sempre vero, perch√© un sasso lungo pu√≤ essere semplice per noi da comprendere, per√≤ resta una cosa rara da trovare per dire. Bisogna capire bene che cosa questa metrica mi sta misurando! La cosa √® che stranamente questa legge empirica sembra vera sul web! Words are optimally stored in memory according to the frequency of the use. Per√≤ non ci dice come avviene questo processo di aggiornamento della capacit√† della mente di fronte all\u0026rsquo;adattarsi a questi dati.\nRelative complexity Complexity of objects in different environments can vary, we say that this is a conditioned complexity: Un esempio banale: Prendiamo un insieme ordinato di elementi, allora posso rappresentare univocamente l\u0026rsquo;elemento tramite la rappresentazione del suo indice. Questo permette di semplificare molto la descrizione di quell\u0026rsquo;oggetto, ma comunque descriverlo nella sua interessa conoscendo il prior.\nWhen an object can be retrieved from a list,\nits complexity within the list can be estimated\nby the length of the binary representation of its rank.\nUpper bound con complexity When an object belongs to a set of size $N$,\nits complexity in that set cannot exceed¬†$\\log_{2}(N)$\nPer utilizzare l\u0026rsquo;indexing di una lista, mi basta poter essere in grado di codificare il numero pi√π alto presente, quindi la grandezza dell\u0026rsquo;insieme per descrivere l\u0026rsquo;elemento, per questo motivo posso affermare la frase di sopra. Questo bound mi permette di descrivere la complessit√† di oggetti senza ordine.\nRappresentazione dei Numeri interi Con la rappresentazione normale binaria dei numeri, possiamo avere necessit√† di $$ \\lceil \\log_{2}(n + 1) \\rceil $$ Usiamo il $+1$ per risolvere il problema col logaritmo di 0, questa comunque √® una buona misura. Solo che non √® il codice minimo, possiamo prendere il codice $\\lceil \\log_{2}(n + 3) - 1 \\rceil$ come un codice migliore, perch√© possiamo togliere 1 perch√© iniziamo a contare con la cifra 1. Possiamo prefixare qualcosa per scegliere il metodo di codifica. Per esempio un numero $90000$ si pu√≤ encodare come $9$ con $4$ per encodare l\u0026rsquo;esponente del 10. Ma spendiamo il bit per indexare il metodo di codifica.\nIn generale per rappresentare cose non numeri, si possono utilizzare strutture che rappresentano univocamente quell\u0026rsquo;oggetto e poi usare la complessit√† su queste strutture. Non √® chiaro sempre come utilizzare queste strutture.\nQuasi-continuous complexity In questa parte analizziamo come varia la lunghezza di descrizione per i numeri, notiamo che segue pi√π o meno la curva logaritmica, con i drops previsti per i numeri rotondi, come da intuizione (lo schema di coding presentato ha questa propriet√†).\nPer dire che √® una funzione quasi continua scriviamo $$ \\lvert C(n + h) - C(n) \\rvert \\leq f(\\lvert h \\rvert ) + O(1) $$ Mentre sappiamo che per una funzione continua quello dovrebbe essere 0.\nGenerati da questo codice Compressibilit√† di stringhe binarie Un risultato che consegue dalla limitatezza di stringhe di bassa lunghezza abbiamo che:\nSe dati un insieme di tutte le stringhe binarie lunghe $N$, volessimo contrarre la descrizione di almeno $k$, avremmo che solo $\\frac{1}{2^{k - 1}}$ delle $2^{N}$ stringhe iniziali possono essere compresse per $k$ o pi√π digits.\nDimostrazione: La quantit√† di stringhe disponibili per la rappresentazione sono $$ \\sum_{i=k}^{N} 2^{N - i} = 2^{N - k + 1} - 1 $$ E approssimando abbiamo che $$ \\frac{2^{N - k + 1}}{2^{N}} = \\frac{1}{2^{k - 1}} $$ E questo √® un valore che decresce in modo esponenziale, per questo le stringhe compressibili di molto sono veramente veramente poche.\nUna cosa interessante √® che per qualunque compressore $Z$ che si possa creare, se prendiamo sequenze binarie $N$ almeno una non √® compressibile.\nExpanding compressors Una osservazione banale ci dice che se il compressore √® una funzione con stesso dominio e codominio, e che sia iniettiva affinch√© sia univocamente decodabile, allora certe stringhe vengono espande invece che compresse! Solitamente nella pratica l\u0026rsquo;espansione succede perch√© il compressore aggiunge dei markers per dire che √® stato compresso.\nQuesto ci dice che il compressor non deve comprimere sempre, ma solamente comprimere in modo dipendente dal contesto secondo me.\nZipf\u0026rsquo;s Law Elaborato insieme a un altro tizio che si chiama Condon relaziona la frequenza di una parola nel linguaggio con il rank, ossia un dizionario che ordina le parole per frequenza d\u0026rsquo;uso. https://babel.hathitrust.org/cgi/pt?id=mdp.39015008729983\u0026amp;view=1up\u0026amp;seq=7 Il contributo di Zips √® una spiegazione di questo fenomeno empirico dato da Condon.\nEnunciato di Zipf $$ r_{f}(w) \\approx \\frac{c}{f(w)} $$ dove $f(w)$ √® la frequenza della parola, e $r_{f}(w)$ √® il suo rank, con una costante a caso $c$.\nThis means that the 10th¬†most frequent word is 10 times more frequent than the 100th¬†most frequent word, which is itself 10 times more frequent than the 1000th¬†most frequent word, which is itself 10 times more frequent than the 10¬†000th¬†most frequent word, and so on\nSembra che questa legge valga per molte lingue, non solo l\u0026rsquo;inglese.\nMinimize effort and time to find the right word to use. Questa √® la spiegazione a questo fenomeno.\nCorrispondenza sulla complessit√† dei codici Complexity of the meaning = complexity of word Complexity is related to the frequency of the word Questo spiega anche cose sulla ripetizione spaziata in (Brown et al. 2014). E ha senso, cose che vediamo pi√π spesso ci appaiono come semplici, cose che vediamo singola volta sono abbastanza complesse, la relazione sulla complessit√† sembra essere fortemente legata alla frequenza della parola. Che bella idea.\nNormalized information distance Basato su (Li et al. 2004).\nFor any pair of objects, NID determines what is common to them, and only keeps their difference to measure the distance that separates them.\nCalcolo del NID Misurare la differenza di informazione attraverso il Kolmogorov Condizionato quindi $max[K(x|y), K(y|x)]$ il max ci aiuta a rendere la distanza simmetrica. Normalizzare la differenza di informazione, perch√© vogliamo una nota relativa di questa misura. $max(K(x), K(y))$ che rappresenta la massima complessit√† di entrambi gli oggetti che vogliamo confrontare. Usare Kolmogorov complexity#Chain Rule cosicch√© possiamo riscrivere il numeratore. In questo modo otteniamo (a volte definito con la prima parte) $$ NCD(x, y) = \\frac{K(x, y) - min[K(x), K(y)]}{max(K(x), K(y))} $$ $$ NCD(x, y) = \\frac{max[K(x|y), K(y|x)]}{max(K(x), K(y))} $$ Questo non √® computabile perch√© $K$ non √® computabile, ma possiamo stimarlo con un compressore reale. La cosa triste √® che il compressore non prende in considerazione la semantica. Per la semantica √® interessante usare la (Cilibrasi \u0026amp; Vitanyi 2007), usando google per stimare la distanza. e questa la chiama la Normalized Google Distance.\nUniversal distance Questo √® lavoro di Charles Bennet in 1998. (information Dista) $$ \\forall D; \\forall x, y: D_{U}(x, y) \u003c D(x, y) + C_{D} $$ Questo: $max[K(x|y), K(y|x)]$ √® una distanza universale. Che √® una cosa molto interessante.\nReferences [1] Brown et al. ‚ÄúMake It Stick: The Science of Successful Learning‚Äù Harvard University Press 2014\n[2] Cilibrasi \u0026amp; Vitanyi ‚ÄúThe Google Similarity Distance‚Äù 2007\n[3] Li et al. ‚ÄúThe Similarity Metric‚Äù IEEE Transactions on Information Theory Vol. 50(12), pp. 3250\u0026ndash;3264 2004\n","permalink":"https://flecart.github.io/notes/introduction-to-algorithmic-information-and-complexity/","summary":"Quick introduction Si assume che la descrizione pi√π intelligente di un qualcosa √® la stringa pi√π corta che descrive quella, un po\u0026rsquo; forse √® arbitrario, perch√© minore complessit√†, non √® detto che sia direttamente relazionata con la difficolt√† di descriverla.\nNel caso di AIT, diciamo che una cosa random non √® compressibile, altrimenti posso scriverla in modo pi√π compatto. √à importante stabilire che l\u0026rsquo;alfabeto che abbiamo per rappresentare qualcosa √® fissato a priori.","title":"Introduction to Algorithmic Information and Complexity"},{"content":"Questo √® stato un capitolo molto vasto, che andava in certi punti a toccare la filosofia, la fisica. Un aspetto, quello di codifica delle informazioni reali in un ambiente logico (che per quanto i miei pregiudizi siano, ritengo una cosa molto impossibile, molto limitata e altrettanto impossibile). Si tratta dello studio della logica per rappresentazione di conoscenza.\nFatto sta che mi sembra assurdamente teorico tanto da non aver nessun utilizzo (probabilmente mi sbaglio di grosso), e che sia roba da filosofi.\nCredo che questo capitolo sia sopratuttto importante per i pattern di rappresentazione di certe cose.\nOntologia Pu√≤ fare comodo questa pagina di wikipedia,.\nUn ontologia organizza tutto il mondo in una gerarchia di categorie.\nIl libro non fornisce mai una definizione dettagliata di ontologia, definisce solamente il suo scopo, che √® quello di dare una struttura agli oggetti che possiamo trovare tutti i giorni (cani, gatti, frutta, pomodori) e li mette ognuna in qualche categoria precisa.\nCredo (questa √® una mia interpretazione che non esiste, o almeno non ho trovato nel libro), che l‚Äôontologia descriva la struttura tutto quanto pu√≤ esistere nel mondo creato. Quindi se ti dico Banana, tu puoi subito mettere nel cassetto giusto questo oggetto e averne molte propriet√†, ma non sono sicuro che sia ci√≤ che intenda il libro Norvig, per√≤ di sicuro propone alcuni modi per rappresentare oggetti come Eventi, tempo, credenze, oggetti fisici, credo siano questi 4 i fulcri del capitolo, come rappresentare queste cose astratte.\nUpper ontology L‚Äôontologia elevata √® una rappresentazione grafica di una possibile ontologia. (credo che una ontologia sia pi√π o meno quello che descrive il mondo costruito in quel determinato istante).\nCaratteristiche di un ontologia generale\nApplicabilit√†**,** dovrebbe essere applicata a qualunque istanziazione concreta di oggetto. Riutilizzabilit√†, dovrebbe avere in s√© concetti abbastanza generati che possono essere utilizzati in pi√π modi (esempio il concetto di tempo lo puoi usare come misurazione della durata, ma anche del costo dell‚Äôevento). Ma sembra che sistemi simili non siano stati molto famosi (c‚Äô√® un fattore umano che non permette la creazione di ontologie generali).\nCategorie Le categorie sono come degli insiemi grossi che accomunano oggetti con certe propriet√†. Per√≤ noi stiamo utilizzando la Logica del Primo ordine e quindi una categoria √® un particolare predicato, che pu√≤ essere reificato in un oggetto (ossia invece di tenerti il concetto astratto, definisci tutto quello che serve per poterlo rappresentare, proprio come se fosse una conversione).\nLa cosa bella √® che esistono sottocategorie, che prendono in AUTOMATICO tutte le propriet√† delle proprie super-categorie\nDecomposizione delle categorie Possiamo andare a definire delle partizioni (molto simile a quelle in teoria degli insiemi, anzi direi che il concetto √® praticamente lo stesso lol).\nDisgiunzione (se non hanno nessun elemento in comune) Decomposizione esaustiva (se la loro unione √® l‚Äôelemento iniziale) Partizione (se a due a due sono disgiunti e vale anche 2). Se sai teoria degli insiemi credo che per questa parte non c‚Äô√® nulla da dire\nRappresentazione di oggetti fisici Sono molto importanti le funzione bunchOf, partOf che definiscono un insieme di cose (che possono essere ad esempio 3 mele, o una parte di essa, come la gamba √® una parte del corpo)\n(poi su part of puoi fare la decomposizione come per le categorie, il concetto credo sia esattamente lo stesso).\nMisurazione Di solito per la misurazione ti tieni una funzione di unit√† che restituisce il valore di unit√† astratto, questa poi la puoi andare ad eguagliare all‚Äôunit√† specifiche, come il metro, il pollice, la spanna etc.\nquindi as esempio $lunghezza(L) = metro(1) = pollici(39,3701)$ etc. e questa cosa la fai per tutti. √à una misurazione pi√π astratta possibile.\nSecondo il libro questo √® un campo molto sviluppato in fisica quantitativa, anche se Milanese ha cringiato quando l‚Äôho condiviso.\nCategorie naturali Le categorie naturali sono molto difficili da definire con delle regole esatte come stiamo provando con la logica (l‚Äôessere umano √® molto ambiguo a riguardo). Potremmo solo definire qualcosa di tipico e se soddisfa queste propriet√† chiamarlo Banana e simili. Comunque questa parte sembra essere stato analizzato per benino da Wittgenstein 1953.\nOggetti I concetti di maggiore importanza da capire degli oggetti √® che certi oggetti, anche se divisi, mantengono ancora la propria sostanza, un esempio di questo √® un butto, mentre invece esseri umani non lo sono (una mano o gamba non sono un essere umano, mentre un pezzo di burro √® ancora burro).\nQuindi differenza fra stuff and things.\nOltre a ci√≤ l‚Äôesistenza di propriet√† intrinseche ed estrinseche, ossia cose che sopravivivono o meno alla suddivisione\nEventi Le relazioni di maggiore imoprtanza per rappresentare gli eventi sono questi\nSe hai queste propriet√† definite, puoi proprio avere un sistema di calcolo degli eventi per descrivere quanto accade durante qualcosa, mentre in passato col fluente potevi solamente descrivere cosa c‚Äôera prima o dopo\nTempo No comment, questi sono quelle cose di cui hai bisogno per descrivere il tempo (si noti che si utilizza una funzione di misura descritta in precedenza).\nNota dei fluenti con oggetti\n√à difficile che l‚Äôoggett Presidente identifichi una certa persona, perch√© questa persona cambia nel tempo, quindi teniamo questo come se fosse una classe astratta. E una funzione che prende come input il tempo d‚Äôinizio e di fine e una persone e ti dice se √® vero o falso se questa persona era presidente in questo periodo di tempo.\nLogica modale La logica modale permette la rappresentazione metaconoscitiva ossia la conoscenza del conoscere.\nIntroduce il concetto di operatore modale (che in pratica √® come se fosse un punto di vista, un frame of reference), che √® come se restringesse il campo di conoscenza al singolo operatore.\nSemantica\nLa semantica di questa logica cambia totalmente, ora si pu√≤ dire che un modello √® vero, se √® vero in tutti i mondi accessibili, non tutti i mondi possibili. Un mondo √® accessibile quando non sa nulla su di essa.\nesempio se so A, allora questo √® accessibile nel mondo A and not B, ma anche al mondo A and B, e sarebbe vera in entrambi i mondi quindi OK.\nOnniscienza\nIl problema di questa logica √® che l‚Äôagente conosce tutto quello che pu√≤ sapere, automaticamente si ricava tutte le inferenze possibili da suo campo di sapere, questo √® alquanto irrealistico (altrimenti l‚Äôessere umano, lol, potrebbe conoscere tutte le conseguenze della matematica per esempio, perch√© tanto sono tutte inferenze da basi conosciute, ma √® chiaro che sia qualcosa di altamente irrealistico.\nSistemi di ragionamento su categorie Network semantici All‚Äôinizio della loro creazione, i network semantici erano in forte discussione con la logica, ma si √® poi notato a posteriore che non sono altro che la stessa cosa, ma formulati in modo molto differente.\nI network semantici permettono una bella e semplice visualizzazione dei concetti\nEsempio di un network semantico\nQuesti si comportano bene per l‚Äôereditariet√† (che puoi andare a sovrascrivere come se stessi lavorando su un OOP). per√≤ ha problemi con la eridariet√† molteplice, perch√© ci sarebbe ambiguit√† se entrambi i genitori condividono una informazione, ma sono contrarie uno dall‚Äôaltra.\nLogica descrittiva Non √® altro che una logica di primo ordine semplificata nella verbosit√†, soprattuto per i concetti di almeno n elementi e simili.\nInformazioni di default Spesso torna molto comodo nella semantica del database (in cui √® a mondo chiuso, tutto quello che non conosci espressamente √® negato) avere delle informazioni di default in esse, e questo si pu√≤ raggiungere principalemtne in due modi ora presentati molto velocemente\nCircoscrizione mah, non l‚Äôho proprio capita\nLogica di default Ovvero se vengono soddisfatte delle premesse, e la conseguenza non √® assurda, allora conoscer√≤ questa conseguenza.\nEsempietto\nTruth maintenance systems I sistemi come JTMS (Justification-based truth maintenance system) che tengono per tutte le inferenze che hanno una spiegazione ossia le regole usate per inferire questa cosa, quando si aggiorna tale sistema bisogna andare a togliere tutte le regole che hanno questa altra nella spiegazione .\nUn suo amico stretto √® ATMS(assumption-based truth maintenance system) in cui per colmare l‚Äôinesistenza di qualcosa si ha qualche regola di default (credo di stare sbagliando in questo passo) ma comunque non √® molto importante ed √® molto probabile che stia semplificando troppo in questa parte\n","permalink":"https://flecart.github.io/notes/rappresentazione-della-conoscenza/","summary":"Questo √® stato un capitolo molto vasto, che andava in certi punti a toccare la filosofia, la fisica. Un aspetto, quello di codifica delle informazioni reali in un ambiente logico (che per quanto i miei pregiudizi siano, ritengo una cosa molto impossibile, molto limitata e altrettanto impossibile). Si tratta dello studio della logica per rappresentazione di conoscenza.\nFatto sta che mi sembra assurdamente teorico tanto da non aver nessun utilizzo (probabilmente mi sbaglio di grosso), e che sia roba da filosofi.","title":"Rappresentazione della conoscenza"},{"content":"CIAA principles of security We have already outlined these principles in Sicurezza delle reti and talked about the concepts of authentication and integrity. Here we try to deepen these concepts and delve a little bit more on the attack vectors These are acronyms, usually called CIA and AAA for infrastructure\nConfidentiality This is one concerns about the secrecy of the sent message. We do not want others to be able to access and read what we are doing.\nEavesdropping üü© This is an example of attack of confidentiality. The setting is usually like this: Eve that intercepts the message sent by each other. For example in network security, it is quite easy to eavesdrop with Wireshark or similars.\nIntegrity Integrity concerns with message tampering. The received message should be the same as the sent one (man in the middle are common attacks).\nAuthentication Authentication is important when we need to know to whom we are talking to. We should need to be sure that that is exactly the person (or the machine) we are trying to connect (or talk to). In this framework it is about integrity. For more in depth analysis see User authentication.\nSpoofing attacksüü© When an attacker authenticates as another user.\nManipulation attacksüü© This is tampering.\nAvailability The system should be available, that is accessible by its users.\nDenial of service attacksüü© For example if you have limited number of ports, a common example of denial of service attack is the Syn flooding where multiple services ask to open a TCP connection, but it doesn\u0026rsquo;t continue with the communication, leaving the port occupied but useless.\nAnonymity On the internet we are not anonymous we are always tracked by ISP, cookies and many other strategies that I am not even aware of. This is a problem we we want to be anonymous, so how can we reach this target??\nAnonymity by proxyüü© We just use another computer to repeat my information, this computer doesn\u0026rsquo;t have access to the underlying information, but it substitutes his IP to ours, so the end receiver doesn\u0026rsquo;t exactly know where the initial message comes from.\nAAA principles of security See Sicurezza OS\nAuthentication Answers: who are you?\nAuthorization Answers: what can you do?\nAccounting Answers: what have you done?\n","permalink":"https://flecart.github.io/notes/theoretical-notions-of-security/","summary":"CIAA principles of security We have already outlined these principles in Sicurezza delle reti and talked about the concepts of authentication and integrity. Here we try to deepen these concepts and delve a little bit more on the attack vectors These are acronyms, usually called CIA and AAA for infrastructure\nConfidentiality This is one concerns about the secrecy of the sent message. We do not want others to be able to access and read what we are doing.","title":"Theoretical Notions of Security"},{"content":"Introduction to convolutional NN The convolution operator üü©- Il prodotto di convoluzione √® matematicamente molto contorto, anche se nella pratica √® una cosa molto molto semplice. In pratica voglio calcolare il valore di un pixel in funzione di certi suoi vicini, moltiplicati per un filter che in pratica √® una matrice di pesi, che definisce un pattern lineare a cui sarei interessato di cercare nell‚Äôimmagine.\nSlides ed esempi (molto pi√π chiaril)\nVedi che per calcolare quell‚Äô8 sto facendo cose lineari con tutti pixel intorno ad essa.\nQuesto operatore l‚Äôabbiamo gi√† trattato in modo molto breve in Deblur di immagini.\nSome properties and uses Sappiamo tutti che le immagini non sono altro che arrai di valori in un certo intervallo, che rappresentano l‚Äôintensit√† dei colori, o solamente del bianco-grigio nel caso delle immagini grigio nere.\nQueste intensit√† si potrebbero anche rappresentare come superfici 3d in cui la posizione del pixel identifica x e y, mentre l‚Äôintensit√† la z, abbiamo quindi proprio delle superfici!, delle montagne, valli fiumi etc. Le cose molto interessanti sono cambi di intensit√† improvvisi (con derivata molto alta) ossia i dirupi, le valli, questo cambio improvviso (il cambio di fase come dice Pedro di Master algorithm) √® classico anche in nautura, √® la parte con qualche informazione di interesse diciamo.\nTHE IDEA OF DERIVATIVE FOR CHANGES\nSlide finite approssimation of derivative h = 1 perch√© siamo in campo discreto (√® anche il minimo h che possiamo considerare in questo setting), quel filtro quindi ci √® utile per capire se ci sono dei cambi improvvisi. Questa idea ci permette di costruire il kernel per identificare le linee (visible contours of the image), orizzontali (cambi direzione e avresti verticale). it‚Äôs a feature map, of the image to some characteristic of the image. (ti dice se in questa zona √® presente, non c‚Äô√® , o c‚Äô√® l‚Äôopposto del pattern che cercavi).\nSome architectures Deepwise separable convolution Inception architecture üü® Andiamo a derfinire un modulo di inception (in cui va a fare in un certo senso scrambling, decomporre e recomporre dati, in che modo vanno ad estrarre delle features io non lo so!).\nComunque questa √® l‚Äôarchitettura classica, andare ad utilizzare reti convoluzionali e poi operarle con reti deep (alla fine non molto deep) in modo da collegargli insieme.\nEsempio di inception module !\nhttps://www.youtube.com/watch?v=VxhSouuSZDY\u0026amp;ab_channel=Udacity\nResidual layers Residual learning is the main concept of these networks, it‚Äôs when we have a direct link with the beginning! In pratica diamo la possibilit√† al neurone di scegliere di non modificare o invece s√¨ l‚Äôinput credo, provo a chiedermi se posso avere un valore migliore di quanto ho attualmente con qualche peso.\nStructure of residual layer https://arxiv.org/pdf/1512.03385.pdf\nUsually these links help the network learn (lesser vanishing gradient.\nTransfer learning Slide intuizione transfer learning expected graph with performance with transfer learning\n!\nComunque l‚Äôintuizione principale del transfer learning √® l‚Äôidea che i primi layers facciano una sorta di estrazione di features pi√π ad alto livello utili poi ai layers di deep NN. Se questa prima parte l‚Äôho trainata su un corpus enorme, allora gli aspetti che √® riuscito a generalizzare potrebbero essere utili anche per altro, e quindi utilizzo i pesi trovati in questa rete anche per altro, senza problemi.\nFine tune o finetuning √® un p√≤ rischioso, faccio un freeze di una parte del network pi√π larga, potrei andare a overfittare e fare cose simili! Per√≤ ha pi√π senso, ci aiuta a rendere l‚Äôintera architettura ancora pi√π focussato in quello che vogliamo fare noi (in un certo senso forse d√† via alcune generalizzazioni inutili nel nostro dominio)\nTraining of CNN Backpropagation of CNNs üü®++ We can unroll the input and output layers as a single linear trasformation of a deep network (with weights adjusted accordingly).\nIntuition of unrolling !\nBut how do we unroll?? We can see everything as a matrix with $[input\\_size \\times output\\_size]$ as you can see from the image in the toggle\nSlide convolution matrix of the weights !\nAfter we have modelled this matrix, we can learn using standard backpropagation we have talked about in Neural Networks.\nUn problema per questo metodo √® la matrice √® sparsa se input √® molto largo, e kernel piccolo, avrei un numero di zeri assurdo, quindi nemmeno molto efficiente da memorizzare in questo modo. (per√≤ possiamo computare in modo efficiente, ma questo non lo trattiamo).\nUn altro aspetto di questa matrice √® la ripetizione shiftata dei pesi, che sono gli stessi in ogni colonna della matrice, ma solamente shiftato. Questo cambia il modo di fare update dei pesi, si utilizza l‚Äôupdate con average pesato. fra le 4 computazioni delle 4 colonne in esempio.\nTransposed convolutions Dopo che ho fatto troppo downsampling con le CNN, vorrei tornare s√π di dimensione (se per esempio un input √® un‚Äôimmagine. Trasposed convolutions ci permettono di tornare su di dimensione. (anche tecniche statistiche credo che funzionino).\nSlide transposed convolutions ! !\nThis technique is called transposed convolution because if we transpose the convolution matrix, we see that we are upscaling the input!. Per√≤ non ho capito in che modo funziona!\nDilated convolutions üü© Slide intuizione di questo !\nFacciamo una specie di padding interno sul kernel (non vado a contare certe cose, per√≤ riesco a ingrandire la receptive field del mio network.\nHa pi√π senso fare sta cosa quando sto analizzando HIGH RESOLUTION IMAGE in cui il valore dei pixel cambia molto poco.\nUna differenza con le Transposed convolutions üü• √® il fatto che quelle sono fatte sull‚Äôinput, questa la facciamo su come viene calcolato il kernel.\nSono molto utilizzate in temporal convolution networks, in cui provo a diluire volta per volta lo spazio all‚Äôinterno del kernel, anche se non so ancora perch√© va\nSlide temporal convolution network !\nNormalization layers Why normalization üü• Slide 2 reasons !\nWhy is normalization a good idea :D?\nSo the quantitative values are comparable from each other (e.g. ages and income) We want the output of the layers to be comparable from each other, the middle outputs are inputs for other layers! We can better control the activation layers. (non vogliamo che faccia come output NaN üòü) Decoupling of the layers. (non dobbiamo andare ad imparare il range di input aspettato, dato che sar√† sempre data di stesso tipo) Batch Normalization üü• This is the most common form of normalization (ma l‚Äôidea √® sempre la stessa, computare varianza e media, e poi sottrarre media e dividere per varianza). La cosa in pi√π √® che vengono aggiunte delle varianze e una media, per denormalizzare l‚Äôoutput, in modo che abbia la forma dei dati migliore possibile.\nSlide batch normalization ! Other Normalization üü• Potremmo provare a normalizzare per canale\nSlide normalizations !!\n","permalink":"https://flecart.github.io/notes/convolutional-nn/","summary":"Introduction to convolutional NN The convolution operator üü©- Il prodotto di convoluzione √® matematicamente molto contorto, anche se nella pratica √® una cosa molto molto semplice. In pratica voglio calcolare il valore di un pixel in funzione di certi suoi vicini, moltiplicati per un filter che in pratica √® una matrice di pesi, che definisce un pattern lineare a cui sarei interessato di cercare nell‚Äôimmagine.\nSlides ed esempi (molto pi√π chiaril)","title":"Convolutional NN"},{"content":"HTTP HYPERTEXT-TRANSFER-PROTOCOL\nCaratteristiche principali (3) üü® Slide caratteristiche\nComunicazioni fra client e server, e quanto sono comunicate le cose si chiude la connessione e ci sono politiche di caching molto bone (tipo con i proxy) Generico: perch√© √® un protocollo utilizzato per caricare moltissime tipologie di risorse! Stateless, ossia non vengono mantenute informazioni su scambi vecchi, in un certo modo ne abbiamo parlato in Sicurezza delle reti quando abbiamo parlato di firewall stateless. Solitamente possiamo intendere questo protocollo come utile per scambiare risorse di cui abbiamo parlato in Uniform Resource Identifier.\nLa connessione üü©- √à importante oggi rendere efficienti le connessioni, al tempo come descritto in Livello applicazione e socket per HTTP, per richiedere ogni risorsa si apriva e si chiudeva una connessione (uno dopo l‚Äôaltro, senza parallelizzazione).\ncon HTTP2 gi√† questa cosa era cambiato, possiamo richiedere allo stesso tempo pi√π connessioni, √® la pipeline. Importante notare che la differenza col multiplexing √® che nel pipelining ti risponde con l‚Äôordine\nMultiplexing invece utilizza la stessa connessione per chiedere e rispondere pi√π volte (oggi anche pi√π comune). La differenza principale √® elaborare in ordine diverso rispetto a quanto abbia ricevuto.\nSlide connessioni\nSlide esempio tipologie di richiesta\nCi sono anche altri modi per rendere ancora pi√π veloce il protocollo, un esempio √® l‚Äôoperazione PUSH, per esempio quando fai la pagina HTML, il server sai gi√† che il client vai a richiedere altre risorse di quella pagina, quindi inizia subito a processare le richieste, prima che il client abbia effettivamente chiesto.\nUn altro modo per rendere pi√π veloce la trasmissione √® la compressione degli header per tutte le richieste e fatte anche in parallelo.\nRichiesta HTTP (5) üü© Vogliamo ora andare a parlare della struttura di un pacchetto HTTP affinch√© si possa considerare valido. Ci sono 5 campi principali:\nVersione del RFC per HTTP Metodo, tipo PUT, GET etc, ne parliamo sotto. URI, descritto in Uniform Resource Identifier. Header, che si articolano in molti sotto headers (ci sono molti headers) Body della richiesta Slide richiesta HTTP\nRisposta HTTP (4) üü© La risposta del server va di 4 campi (cio√® √® quello che ti ritorna dopo aver elaborato la tua richiesta)\nStatus code Version HTTP Headers (nota headers sono credo praticamente le stesse della richiesta) Body (in cui effettivamente ci sono le informazioni della risposta) Slide risposta HTTP\nEsempio di risposta HTTP\nStatus codes (5) üü© Ci sono 5 campi principali che vanno a descrivere a grandi linee il significato della risposta (in un certo senso √® come nella richiesta vado a specificare l‚Äôazione, gli status codes ti rispondono con informazioni precise riguardanti la tua richeista).\nSlides sugli status codes\nEsempi di status codes\n√à importante andare a utilizzare status codes corretti, per ragioni molto simili a un verbo HTTP corretto, perch√© questo aiuta tutti i servizi capire bene l‚Äôesito della nostra richiesta, aiuta i meccanismi di caching a capire se cachare o meno.\nHeaders (4) üü•++ Ci sono 4 tipologie principali di headers HTTP, andremo a descriverli ora.\nHEADERS GENERALI\nSlide generali\nSi mandano informazioni come cache, la codifica, la data, il tipo di connessione (se deve restare su o meno).\nHEADERS DI ENTIT√Ä\nSlides entit√†\nSono utili per andare ad interpretare le tipologie di content all‚Äôinterno del body. In parte questa parte √® condivisa anche negli headers per il MIME Headers del MIME (2)üü®.\nInfatti in risposta con una risorsa le content-type e lenght son oobbligatori per specificare informazioni sulla risorsa ritornata.\nHEADERS DI RICHIESTA\nSlides richiesta\nSono utili per dare informazioni sul client al server.\nEsempi sono l‚Äôhost, l‚Äôuser-agent che sta facendo la richiesta. Per esempio a seconda dello user agent ho dei CSS leggermente differenti!\nHEADERS DI RISPOSTA\nSlides risposta\nMetodi HTTP (!) I metodi HTTP sono presenti all‚Äôinterno del campo metodo di un pacchetto HTTP, sono anche chiamati verbi HTTP perch√© vanno a descrivere cosa bisogna andare a fare sulla risorsa identificata dall‚ÄôURI.\nSlide esempio di get e POST\nIn teoria tutto pu√≤ essere fatto con GEt, ma se utilizzo bene le API avere status codes corretti rende molto pi√π chiaro ed uniforme l‚Äôinterazione con essa, quindi molto pi√π interoperabile.\nCARATTERISTICHE METHODI HTTP (!!!)\nSono sicurezza e idempotenza. Vorremmo che HTTP sia stateless, quindi vorremmo che non generi cambiamenti dello stato oltre che avere dei logs.\nidempotente quando richieste identitiche hanno stesso risultato.\nGET\nSlide GET 3\nHEAD\nSlide HEAD 3\nPOST\nSlide POST 0\nPUT\nSlide PUT 2\nDELETE\nSlide DELETE 2\nPATCH\nSlide PATCH 0\nla differenza principale con PUT √® che patch √® per cambiare parzialmente una risorsa e non sostituirla completamente.\nOPTIONS\nSlide OPTIONS 3\nSlide riassunto caratteristiche\nE poi ce ne sarebbero altre, ma solitamente si utilizzano Get post put e delete perch√© sono quelle pi√π consone per il modello CRUD per rest.\nREST REpresentational State Transfer √® una metodologia di costruzione di API, avevamo gi√† fatto qualcosa cone tipo protobuf. √à un modello architetturale, ossia modo per creare applicazioni che sfruttano HTTP che possano essere utilizzati da altre applicazioni il modo pi√π chiaro possibile.\nConnesse sull‚Äôambiente di utilizzo (quindi cose come collezioni, singolo elemento della collezione e simili). Modello CRUD (!) (4) üü© Quando ho una collezione di dati vogliamo descrivere le operazioni principali che posso fare su essa:\nCreazione di elemento singolo o di un gruppo Lettura di un individuo o di un gruppo Aggiornamento di dati gi√† esistenti Eliminazione di dati Slide su CRUD\nImportante notare che questo pattern √® indipendente da REst, di solito utilizzato per Database, ma possiamo utilizzare lo stesso mecanismo con Rest e le operazioni di HTTP\nOssia URI come identificatore e Richieste HTTP per andare a modificarle.\nUtilizzo CRUD per Metodi HTTP\nEsempio Verbi HTTP con rest\nIn breve REST utilizza URI per identificare la risorsa, e semantica HTTP per andare a richiederla e stabilire la connessione di trasferimento.\nMetodologie URI REST üü®+ Ci sono delle specifiche metodologie per dare senso a un uri che possa essere rest, l\u0026rsquo;idea principale √® la distinzione fra collezione vs individuo, che implica anche un utilizzo di metodo HTTP diverso. Per distinguere collezioni da individui dobbiamo mettere il plurale e terminare con lo slash (che direi anche sia una cosa molto strana!)\nQueste entit√† cos√¨ definite possono essere anche gerarchiche, quindi uno impilato sull\u0026rsquo;altro, ma sembra tenere a mente la semplicit√† dell\u0026rsquo;interfaccia e della navigazione.\nOpen API Questa parte √® molto p√¨u pratica, andiamo direttamente ad impararla da l√¨!\nOpen api √® una sintassi di solito scritta in YAML presentato molto velocemente in HTML e Markup nella sezione di markup, permette di specificare in modo molto chiarlo l\u0026rsquo;interfaccia di un API, e la creazione della documentazione associata.\nDi solito questo √® il modello preferito (industry standard) per creare queste cose, rende molto chiara la comunicazione delle api diciamo, per il progetto potrebbe essere un buon metodo per interagire col database? Oppure meglio farci richiesta diretta con un ORM. Credo sia molto simile.\n","permalink":"https://flecart.github.io/notes/http-e-rest/","summary":"HTTP HYPERTEXT-TRANSFER-PROTOCOL\nCaratteristiche principali (3) üü® Slide caratteristiche\nComunicazioni fra client e server, e quanto sono comunicate le cose si chiude la connessione e ci sono politiche di caching molto bone (tipo con i proxy) Generico: perch√© √® un protocollo utilizzato per caricare moltissime tipologie di risorse! Stateless, ossia non vengono mantenute informazioni su scambi vecchi, in un certo modo ne abbiamo parlato in Sicurezza delle reti quando abbiamo parlato di firewall stateless.","title":"HTTP e REST"},{"content":"We will present some methods related to regression methods for data analysis. Most of the work here is from (Hastie et al. 2009).\nProblem setting In usual regression problems we want to reach the $\\arg \\min \\mathbb{E}_{Y \\mid X} \\left[ (Y - f(X))^{2} \\right]$ and the solution is given by the conditional mean: $f^{*} = \\mathbb{E}(Y \\mid X = x)$. We have done something similar with Logistic Regression, but that is just for classification analysis. For linear regression models we need to find the parameters $\\beta$ for this function $$ Y = \\beta_{0} + \\sum_{j = 1}^{d} X_{j}\\beta_{j} $$ We usually don\u0026rsquo;t know the distribution of $P(X)$ or $P(Y \\mid X)$ so we need to assume something about these distributions.\nOne approach is assuming the distribution $Y \\mid X \\sim \\mathcal{N}(f(X), \\sigma^{2}I)$ and then solve the log likelihood on the probability If we use a statistical learning approach then we know we want to minimize this $\\arg \\min_{f} \\sum_{i = 1}^{n} (y_{i} - f(x_{i})^{2}$ which is what is often used. Both methods end with the same solution. Usually for these kind of problems we use the Least Squares Method, initially studied in Minimi quadrati. We will describe it again better in this setting. Let\u0026rsquo;s consider the linear model\nNormal Equation solution $Y = \\beta_{0} + \\sum_{j = 1}^{d} X_{j}\\beta_{j}$ where $\\beta_{0}$ is the bias or intercept. We can introduce a fictitious variable $X_{1}$ so that we can rewrite the above in Matricial form: $$ Y = X^{T}\\beta $$ And we can attack this problem with the residual squares approach: $$ RSS(\\beta) = \\sum_{i = 1}^{n}(y_{i} - x_{i}^{T}\\beta)^{2} = (y - X\\beta)^{T}(y - X\\beta) $$ This loss can be briefly motivated: we don\u0026rsquo;t want to use normal $x - y$ because positive and negative errors can cancel out, then we want to square it to have better differentiability.\nWe can then use this form to minimize using standard multi variable calculus. And we find that the solution condition is: $$ \\nabla _{\\beta} RSS(\\beta) = 0 \\implies X^{T}(y - X\\beta) = 0 \\implies \\hat{\\beta} = (X^{T}X)^{-1} X^{T}y $$ Which is just slow because of the inverse part, but easily feasible. This is done in the old note section. In order to know that this indeed is the minimum we should also see the hessian, but should be easy to check that. (if not check chapter 3 of (Hastie et al. 2009)).\nThis is the solution: After the $\\hat{\\beta}$ have been computed then a prediction is just the following: $$ y = X\\hat{\\beta} = X(X^{T}X)^{-1}X^{T}y $$ The matrix $X(X^{T}X)^{-1}X^{T}$ is called the hat matrix which has some special properties. One can prove that the estimator is distributed in this way: $$ \\hat{\\beta} \\sim \\mathcal{N} (\\beta, (X^{T}X)^{-1}\\sigma^{2}) $$ And we know that this is usually an unbiased estimator.\nGauss Markov Theorem References [1] Hastie et al. ‚ÄúThe Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition‚Äù Springer Science \u0026amp; Business Media 2009\n","permalink":"https://flecart.github.io/notes/linear-regression-methods/","summary":"We will present some methods related to regression methods for data analysis. Most of the work here is from (Hastie et al. 2009).\nProblem setting In usual regression problems we want to reach the $\\arg \\min \\mathbb{E}_{Y \\mid X} \\left[ (Y - f(X))^{2} \\right]$ and the solution is given by the conditional mean: $f^{*} = \\mathbb{E}(Y \\mid X = x)$. We have done something similar with Logistic Regression, but that is just for classification analysis.","title":"Linear Regression methods"},{"content":"Def: Massimo minimo relativo (locale) Sia $x_{0} \\in \\mathcal{A}$ si dice punto di massimo relativo (o locale) se: $$ \\exists r \u003e 0 : f(x) \\leq f(x_{0}), \\, \\forall x \\in \\mathcal{A} \\cap I_{r}(x_{0}) $$ Dove $I_{r}(x_{0}) = \\left[ x_{0} -r, x_{0} + r \\right]$, √® un intorno\nDef: Massimo minimo assoluto Sia $x_{0} \\in \\mathcal{A}$ si dice punto di massimo assoluto se vale $$ f(x) \\leq f(x_{0}), \\, \\forall x \\in \\mathcal{A} $$ Fermat 6.2.1 Ipotesi Sia data una funzione $f: \\left[ a, b \\right] \\to \\mathbb{R}$ Se abbiamo che\n$x_{0} \\in \\left( a, b \\right)$ √® un punto di massimo o minimo relativo $f$ √® derivabile in $x_{0}$ Implica che $f'(x_{0}) = 0$\n6.2.2 Note Un p√≤ intuitivamente, questo teorema ci sta dicendo che il valore della derivata in un punto di massimo oppure di minimo deve essere uguale a 0.\nBisogno fare attenzione che il punto non deve essere sugli estremi perch√© la derivata l√¨ non √® definita in modo sufficiente per soddisfare questo teorema.\nDimostrazione\nSono due casi diversi, ma con la stessa logica\nLa permanenza del segno √® una dimostrazione per assurdo implicita, perch√© se si pone che il limite √® minore di 0 allora per la permanenza del segno per gli X presenti in quell\u0026rsquo;intorno vale che √® minore o uguale a 0!\nStessa cosa per quell\u0026rsquo;intorno.\n6.3 Rolle 6.3.1 Ipotesi Enunciato\n6.3.2 Note Ricorda l\u0026rsquo;esempio della montagnola per dare l\u0026rsquo;intuizione di questo teorema\nDimostrazione\nUso Weierstrass e posso dire che la funzione deve avere tutti i valori nel massimo e nel minimo.\nCi sono due casi, entrambi minimo e massimo sono estremi o uno dei due oppure uno dei due sono dentro l\u0026rsquo;intervallo, se sono dentro posso utilizzare fermat, invece la funzione √® constante nel primo caso.\n6.4 Lagrange 6.4.1 Ipotesi Enunciato\n6.4.2 Osservazioni Sembra che sia una generalizzazione di Rolle, in verit√† √® come Rolle ma con il piano cartesiano girato, in questo senso possiamo intuire che siano equivalenti, poi si pu√≤ anche provare a dimostrare (da Rolle si deriva lagrange e da lagrange si pu√≤ derivare rolle).\nDimostrazione\nPer la dimostrazione di questo teorema si vuole in qualche modo utilizzare il teorema di Rolle, quindi sarebbe buona cosa costruirsi una funzione ausiliaria in cui si possa utilizzare il teorema di Rolle.\n6.4.3 Corollario costante Dimostrazione\n6.5 Cauchy 6.5.1 Ipotesi Enunciato\nOsservazione sull\u0026rsquo;ipotesi 3\n6.5.2 Osservazioni La dimostrazione √® molto simile a Lagrange, in quanto voglio costruirmi una funzione ausiliaria che soddisfi Rolle.\n6.5.3 Legame con le altre funzioni Si pu√≤ notare che nel caso in cui la seconda funzione sia uguale alla funzione identit√† si pu√≤ trovare la funzione di Cauchy senza nessun problema, si pu√≤ dire che siano equivalenti\nSi pu√≤ quindi dire che i due teoremi sono equivalenti a livello logico in quanto sostanzialmente mi dicono la stessa cosa, in forme diverse (seque dalla coimplicazione delle funzioni).\n6.6 Monotonia funzioni Ora si tende a correlare la crescita di una funzione al segno di una funzione.\nEnunciato\n6.6.1 Nota Bisogna fare attenzione alla dimostrazione inversa.\nPerch√© non si pu√≤ utilizzare il teorema di Lagrange nello stesso modo con cui si va l\u0026rsquo;implica nella prima direzione. Per la seconda direzione bisogna utilizzare un assurdo con il teorema di permanenza del segno\n6.6.2 Dimostrazioni Freccia in gi√π\nFreccia in su\n6.7 Lo studio di funzione 6.7.1 I passi per l\u0026rsquo;analisi: Studio del dominio (Facoltativo) Studio di simmetrie Studio dei limiti sulle frontiere del dominio Studio della monotonia ","permalink":"https://flecart.github.io/notes/teoremi-base-analisi/","summary":"Def: Massimo minimo relativo (locale) Sia $x_{0} \\in \\mathcal{A}$ si dice punto di massimo relativo (o locale) se: $$ \\exists r \u003e 0 : f(x) \\leq f(x_{0}), \\, \\forall x \\in \\mathcal{A} \\cap I_{r}(x_{0}) $$ Dove $I_{r}(x_{0}) = \\left[ x_{0} -r, x_{0} + r \\right]$, √® un intorno\nDef: Massimo minimo assoluto Sia $x_{0} \\in \\mathcal{A}$ si dice punto di massimo assoluto se vale $$ f(x) \\leq f(x_{0}), \\, \\forall x \\in \\mathcal{A} $$ Fermat 6.","title":"Teoremi Base Analisi"},{"content":"Bag of words only takes into account the count of the words inside a document, ignoring all the syntax and boundaries. This method is very common for email classifications techniques. We can say bag of words can be some sort of pooling, it\u0026rsquo;s similar to the computer vision analogue. It\u0026rsquo;s difficult to say what is the best method (also a reason why people say NLP is difficult to teach).\nIntroduction to bag of words Faremo una introduzione di applicazione di Na√Øve Bayes applicato alla classificazione di documenti. Setting del problema üü®+ Questo √® una parte che √® importante nel caso volessimo fare document classification. e simili, In questa brevissima introduzione cerchiamo di calcolare $$ \\theta_{i, \\text{word}, l} = P(X_{i} = \\text{word} | Y = l) $$ Ossia quanto √® probabile che una parola sia word, che appaia alla posizione i, data la categoria $l$ del documento Assumendo che non dipenda dalla posizione posso solamente contare le parole per documento fregandomene della posizione, questa √® l\u0026rsquo;idea che ha portato ai primi approcci in questo campo.\nAssumiamo che siano anche indipendenti alla posizione per semplicit√†, che √® una assunzione molto forte perch√© proviamo a catalogare la classe solamente dalla frequenza delle parole\n$$ \\theta_{i, \\text{word}, l} = \\theta_{\\text{word}, l} $$ Note: assunzioni forti (2) üü© Perch√© √® una assunzione molto forte, e irrealistica il fatto che siano:\nIndipendenti dalla posizione indipendenti fra di loro (√® molto chiaro che certe parole vanno pi√π insieme rispetto ad altri, quindi √® una assunzione chiaramente false). Per√≤ √® didattica la cosa che un modello semplice come Na√Øve Bayes possa essere utilizzato per un problema del genere. Forward inference Una volta creato tutta la matrice di pesi e possibilit√† (quanto √® correlato), Per fare una forward inference non faccio altro che fare una dot product perch√© usiamo quella come metrica per fare inference.\nInference in breve üü• Calcolando la $s_{k}$ come in immagine sopra, posso avere una sorta di caratterizzazione del tema/categoria, in ogni singolo documento che ho.\nPoi per fare inferenza vedo il documento attuale √® pi√π simile rispetto a quale.\nCosine similarity üü© Questa √® una metrica molto utilizzata per dare una idea di somiglianza di vettori.\n","permalink":"https://flecart.github.io/notes/bag-of-words/","summary":"Bag of words only takes into account the count of the words inside a document, ignoring all the syntax and boundaries. This method is very common for email classifications techniques. We can say bag of words can be some sort of pooling, it\u0026rsquo;s similar to the computer vision analogue. It\u0026rsquo;s difficult to say what is the best method (also a reason why people say NLP is difficult to teach).\nIntroduction to bag of words Faremo una introduzione di applicazione di Na√Øve Bayes applicato alla classificazione di documenti.","title":"Bag of words"},{"content":"9.1 Caratteristiche Il sistema operativo non ha sempre avuto una interfaccia grafica.\n9.1.1 In generale Principalmente √® un gestore delle risorse come il disco, la CPU, l\u0026rsquo;output e l\u0026rsquo;input.\n√à qualcosa che si infrappone come interfaccia fra le applicazioni e quello che √® presente sotto.\n9.1.2 Ambiti principali 9.2 Paginazione Al programma non interessa se effettivamente √® presente in memoria fisica questa quantit√† di memoria, si di solito basta sempre.\nCi sono 3 casi:\nse la necessit√† di memoria √® anche superiore alla memoria virtuale esistente allora c\u0026rsquo;√® l\u0026rsquo;errore out-of-memory Se √® maggiore della fisica ma minore, dovr√† essere gestita dalla paginazione e simili. Se √® minore della memoria fisica allora tutto ok! Implementazione Slide\n9.2.1 Indirizzi virtuali e paginazione Vogliamo utilizzare tutti i bit per l\u0026rsquo;indirizzamento, anche se questi superano effettivamente la memoria effettiva, questa astrazione permette di facilitare al programma la comprensione di tutto. (ma il programma √® molto pi√π lento perch√© ogni volta doveva ricaricare la pagina di memoria).\n9.2.2 Hit and fault Si ha un page hit se la pagina √® caricata, altrimenti √® page fault e si deve ricaricare tutta la memoria per il programma.\n9.2.3 Memory Management Unit Esempio\nQuesto √® il chip che si differenzia dalla cache. Una pagina virtuale pu√≤ essere messo in qualunque pagina reale.\nTabella gestita dal sistema operativo che tiene in memoria le pagine che sono usate e quelle no.\nquindi se √® 1 (in memoria) si chiama working set.\n9.2.4 Algoritmi di paginazione (2) Ci dicono quale pagina togliere dalla memoria principale per sapere quale rimpiazzare con la nuova pagina.\nI principi che sono presenti per questi algoritmi di paginazione, sono molto simili ai principi della localit√† spaziale e temporale presenti per la Cache\nQuelle presentate sono LRU e FIFO, si pu√≤ dire che il primo funziona meglio mentre il secondo √® pi√π veloce, quindi bisogna vedere i tradeoff.\nQuesti algoritmi (in particolare La Least Recently Used √® utilizzata anche in Memoria per la cache).\n9.2.5 Dirty bit Si aggiunge un bit che ci dice se una pagina √® stata sporcata o meno (cos√¨ possiamo decidere se scrivere in memoria o no).\n9.2.6 Frammentazione interna Non vorremmo sprecare un pezzo del blocco, sprecheremmo mezzo blocco.\nPer ovviare a questo (il fatto di non utilizzare l\u0026rsquo;intero blocco si dice frammentazione interna)\n9.3 Segmentazione 9.3.1 Problemi della paginazione Questa opzione non √® pi√π presente nella realt√†, dato che si utilizza sempre la paginazione.\nProblemi della paginazione\nEvitare la frammentazione interna Le pagine sono scollegati dai programmi (potrebbe essere che un array sia scollegato in pi√π pagine, ho mano manovra). Si divide la memoria in segmenti che vengono dati a parti del processo (esempio i/o ) e altro a seconda dello scopo\n9.3.2 In memoria: frammentazione esterna Dato che i segmenti non sono della stessa grandezza, c\u0026rsquo;√® un p√≤ di complicazione mentre si trattano queste cose. ecco che si ha il fenomeno di frammentazione esterna in questo caso.\nL\u0026rsquo;operazione di compattare la memoria √® moolto costosa\u0026hellip;\nEsempio\n9.3.3 Scelta del \u0026ldquo;buco\u0026rdquo; (2) Ci sono due modi principali per scegliere la zone in cui mettere il programma\nBest Fit: (ci metto pi√π tempo perch√© devo cercare il buco migliore, ma poi trovo quello pi√π economico in cui c\u0026rsquo;√® meno spazio inusato) First fit: √® il pi√π veloce perch√© metto subito sul primo blocco, per√≤ grande spazio potrebbe essere inutilizzato 9.3.4 Combinazione segmentazione e paginazione Si possono mischiare: una parte per la segmentazione e poi la pagina per il segmento e da questo si raggiunge un blocco.\nEsempio\n9.4 Gestione del linking ! 9.4.1 il file oggetto Ogni file viene compilato assumendo che parta dall\u0026rsquo;indirizzo zero, poi questi vengono riorganizzati con successo da linker\nEsempio 9.4.2 Esempio 9.4.3 La rilocazione La rilocazione per chiamate di funzioni esterne (di sistema √® semplice), poi bisogna rilocare anche pointers e branches., si utilizza un dizionario di rilocazione.\n9.4.4 Indirizzamento dinamico Viene compilato normalmente, e viene linkato nel momento di esecuzione grazie al sistema operativo\nEsempio\nIndirizzamento dinamico\nViene compilato normalmente, e viene linkato nel momento di esecuzione grazie al sistema operativo\nEsempio\n","permalink":"https://flecart.github.io/notes/livello-os/","summary":"9.1 Caratteristiche Il sistema operativo non ha sempre avuto una interfaccia grafica.\n9.1.1 In generale Principalmente √® un gestore delle risorse come il disco, la CPU, l\u0026rsquo;output e l\u0026rsquo;input.\n√à qualcosa che si infrappone come interfaccia fra le applicazioni e quello che √® presente sotto.\n9.1.2 Ambiti principali 9.2 Paginazione Al programma non interessa se effettivamente √® presente in memoria fisica questa quantit√† di memoria, si di solito basta sempre.","title":"Livello OS"},{"content":"Introduzione alle catene di Markov La propriet√† di Markov Una sequenza di variabili aleatorie $X_{1}, X_{2}, X_{3}, \\dots$ gode della propriet√† di Markov se vale:\n$$ P(X_{n}| X_{n - 1}, X_{n - 2}, \\dots, X_{1}) = P(X_{n}|X_{n-1}) $$ Ossia posso scordarmi tutta la storia precedente, mi interessa solamente lo stato precedente per sapere la probabilit√† attuale.\nDa un punto di vista filosofico/fisico, ha senso perch√© mi sta dicendo che posso predire lo stato successivo se ho una conoscenza (completa, (lo dico io completo, originariamente non esiste)) del presente.\nLa catena di Markov La catena di Markov √® una successione di variabili aleatorie che possiede la propriet√† di Markov. Solitamente lo rappresentiamo a grafi oppure tramite la matrice di transizione. A me piace pi√π la versione a grafi. Matematicamente scriviamo $X = \\left\\{ X_{t} \\mid t = 0, 1, \\dots \\right\\}$ su uno spazio di stati $S = \\left\\{ 0, 1, 2, \\dots \\right\\}$ tali per cui per ogni $t, j, i_{0}, \\dots i_{t} \\in S$ abbiamo: $$ \\mathbb{P}(X_{t+1} = j \\mid X_{0} = i_{0}, \\dots, X_{t} = i_{t}) = \\mathbb{P}(X_{t + 1} = j \\mid X_{t} = i_{t}) = P_{ij} $$ Queste catene sono dette time-homogeneus. Con la probabilit√† di Markov si pu√≤ dimostrare che se $X_{0} \\sim \\mu_{0}$ con $\\mu_{0}$ il vettore riga, allora la probabilit√† della distribuzione $X_{t}$ sar√† $\\mu_{t} = \\mu_{0}P^{t}$. We have that $\\mu$ is a stationary distribution if $\\mu = \\mu P$ is valid. A study of this property is sometimes interesting.\nCatena di 3 variabili Siano $X, Y, Z$ √® chiaro che se viene formata la Catena di Markov $X \\to Y \\to Z$ allora deve valere $$ p(x, y, z) = p(x)p(y|x)p(z|y) $$ Altra cosa √® che deve vare se e solo se $X, Z$ sono indipendenti, dato $Y$ ossia se vale $$ P(x, z|y) = P(x|y)P(z|y) $$ Che dovrebbe essere una conseguenza diretta della parte di sopra. Una altra osservazione √® che se vale quella catena, vale anche l\u0026rsquo;inversa, ossia $Z \\to Y \\to X$.\nData processing inequality Se abbiamo una catena di Markov $X \\to Y \\to Z$ allora vale che $$ I(X ; Y) \\geq I(X; Z) $$ Perch√© una parte di computazione √® possibile modellarlo con la catena di Markov. E mi sta dicendo che l\u0026rsquo;informazione comune all\u0026rsquo;input $X$ con l\u0026rsquo;output $Y$ o output $Z$ dopo seguente computazione viene sempre meno con pi√π computazione, e anche che non aggiungo informazione con pi√π computazione.\nDimostrazione\nDefinizioni Comuni Raggiungibilit√† Il nodo $j$ √® raggiungibile da un nodo $i$ se esiste un numero di passi $m$, tale per cui $$ P_{ij}^{m} \u003e 0 $$ Molto pi√π facile vedere sta cosa se lo rappresentiamo come un comunissimo grafo.\nClasse di stati Sono un insieme di stati tutti raggiungibili fra di loro (comunque presi due stati all\u0026rsquo;interno della classe, esiste un percorso che parte da uno e finisce sull\u0026rsquo;altro per dire).\nRecurrent vs Transient √à recurrent se per ogni nodo, tutti i nodi raggiungibili da un nodo $i$ raggiungono anche il nodo $i$ stesso. Transient se non √® recurrent. Alcuni chiamano la recurrent come irreducible come in (Cover \u0026amp; Thomas 2012).\nPeriodic vs Aperiodic Sia $d$ il massimo comune divisore per tutti gli $m$ tali per cui vale $P_{ii}^{m} \u003e 0$ (ossia pu√≤ raggiungere s√© stesso con probabilit√† non nulla), allora √® periodico se $m \\neq 0$ altrimenti √® aperiodico.\nErgodic Markov Chain Una catena di markov si dice Ergodico se √® recurrent e aperiodico.\nPossiamo avere un teoremino carino su queste tipologie di catene, ed √® pi√π o meno il motivo per cui si chiamano ergodiche, ossia che una particella che segue questa legge prima o poi va a visitare tutti gli stati una volta. Abbiamo come teorema: $$ P^{(M - 1)^{2} + 1}_{ij} \u003e 0 $$ Con $M$ il numero totale di stati, e $ij$ qualunque stato iniziale o finale. Dimostrazione √® un esercizio\nUnichain Una catena che contiene una singola classe recurrent pi√π alcuni stati transienti\nChapman-Kolmogorov Equation Alla fine √® una relazione molto semplice, che deriva in modo facile dalle matrici di transizione, dice che Sia $P$ una matrice di transizione per un processo di Markov, allora $$ P^{n + m}_{ij} = \\sum_{k = 0}^{N} P_{ik}^{n} P_{kj}^{m} $$ Ossia posso moltiplicare matrici di transizione assieme per avere la probabilit√† di muovermi da uno stato $i$ a uno stato $j$ in $n + m$ passi.\nConvergenza Ha senso pensare che una catena di Markov converga nel proseguire delle transazioni.\nTeorema di convergenza per catene ergodiche Questo √® un teorema importante. Da fare.\nConvergenza per unichains ergodiche. Con rewards Vogliamo associare a ogni stato $i$ un reward $r_{i}$ Si pu√≤ creare allora una altra variabile aleatoria che prende la variabile aleatoria di Markov $X_{i}$ e lo mappa a un reward. Quello che ci interessano di pi√π sono le expectation dei rewards.\nNoi vogliamo il valore\n$$ E[R(X_{n})| X_{0} = i] = \\sum_{j}r_{j}P_{ij}^{n} $$ E per la propriet√† di Markov credo sia la stessa cosa quando non parto da step 0.\nAggregate reward function Questo √® definito anche come value function in Reinforcement Learning, a introduction.\n$v_{i}(n) = E[R(X_{m}) + \\dots + R(X_{m + n - 1}) | X_{m} = i]$\nSe la catena √® convergente, abbiamo che anche il value function √® convergente a un valore preciso, ed √®:\n$$ g = \\sum \\pi_{j}r_{j} = \\vec{\\pi} \\cdot \\vec{r} $$ Indipendentemente allo stato iniziale (che stupisce molto).\nReferences [1] Cover \u0026amp; Thomas ‚ÄúElements of Information Theory‚Äù John Wiley \u0026amp; Sons 2012\n","permalink":"https://flecart.github.io/notes/markov-chains/","summary":"Introduzione alle catene di Markov La propriet√† di Markov Una sequenza di variabili aleatorie $X_{1}, X_{2}, X_{3}, \\dots$ gode della propriet√† di Markov se vale:\n$$ P(X_{n}| X_{n - 1}, X_{n - 2}, \\dots, X_{1}) = P(X_{n}|X_{n-1}) $$ Ossia posso scordarmi tutta la storia precedente, mi interessa solamente lo stato precedente per sapere la probabilit√† attuale.\nDa un punto di vista filosofico/fisico, ha senso perch√© mi sta dicendo che posso predire lo stato successivo se ho una conoscenza (completa, (lo dico io completo, originariamente non esiste)) del presente.","title":"Markov Chains"},{"content":"XOR operation √à una operazione binaria abbastanza semplice per√≤ ci sar√† importante per andare ad analizzare dei cifrari di un certo genere. Come il ONE TIME PAD che faremo fra poco in OTP and Stream Ciphers.\nTeorema cifratura con XOR Prendiamo $X$ una variabile aleatoria in $\\left\\{ 0,1 \\right\\}^{n}$ uniforme, sia $Y$ una variabile aleatoria su uno stesso dominio come vogliamo. Tali per cui $X, Y$ siano indipendenti Allora avremo che $C = X \\oplus Y$ √® una variabile aleatoria uniforme.\nQuesto √® necessario per la sicurezza di OTP. Dimostrazione: Supponiamo $n=1$ poi credo si possa estendere a $n$ pi√π grande senza troppi problemi: $$ \\mathbb{P}(C=0) = \\mathbb{P}((X,Y) = (0,0)) + \\mathbb{P}((X, Y) =(1,1)) = \\frac{p_{0}}{2} + \\frac{p_{1}}{2} = \\frac{1}{2} $$ Quindi $\\mathbb{P}(C=1) = \\frac{1}{2}$ e si continua provando ad aggiungere parti.\nOne Time Pad Cipher Inventato da Vernam 1917. e 1926 sempre lui, infatti questo √® il cipher che √® nella teoria veramente unbreakable! Lo ha chiamato BSS = Binary Symmetric source, vedi: https://cs.ioc.ee/yik/schools/win2006/massey/slides1.pdf\nDescrizione del cipher üü© Prendiamo $K = M = C =\\left\\{ 1, 0 \\right\\}^{n}$ Allora $$ E(k, m) = k \\oplus m $$ e decrittazione diventa $$ D(k, C) = k \\oplus C $$ La cosa importante √® che $k$ √® usato solo una volta, altrimenti ho problemi di sicurezza molto importanti (vedi many-time-pad). Una altra cosa importante √® che $k$ sia uniforme, che poi usando il teorema di XOR di sopra, possiamo avere massima sicurezza (entropia massima)\nNecessit√† del mezzo comunicativo üü®++ Ci sono anche restrizioni sulla generazione e sulla conoscenza della chiave dai due parties che cercano di comunicare! Dimostrazione segretezza perfetta üü© Si basa sulla definizione in Classical Cyphers#Security of the Key.\nVogliamo dimostrare $\\mathbb{P}(E(k, m_{0}) = c) = \\mathbb{P}(E(k, m_{1}) = c)$, assumendo di fare sampling di $k$ in modo uniforme.\nAllora nel nostro caso abbiamo: $$ \\forall m,c: \\mathbb{P}(E(k, m) = c)] = \\frac{\\#\\text{Chiavi tali per cui } E(k,m) = c}{\\lvert K \\rvert } $$ Va vale il fatto che $\\forall m, c$ $\\#\\left\\{ k \\in K: E(k, m) = c \\right\\} = 1$ Quindi abbiamo la segretezza. (√® 1 perch√© con OTP √® unica la chiave che viene utilizzata per ottenere quello).\nQuesto √® importante perch√© dimostra che non esistono attacchi ciphertext only per OTP\nSvantaggi OTP üü© La difficolt√† di utilizzo di OTP, nonostante le forti garanzie teoriche √® dalla lunghezza della chiave. Vedi Classical Cyphers#Security of the Key per maggiori dettagli.\nLa chiave deve avere stessa lunghezza del messaggio (overhead, difficolt√† per mandare messaggi lunghi) Distruzione della chiave dopo l‚Äôutilizzo (che si fa solo una volta!) La comunicazione della chiave. Per questo motivo non si utilizza per applicazioni commerciali.\nAttacks on OTP Many time pad attack üü®+ Se ho $c_{1} = m_{1} \\oplus PRNG(k)$ e $c_{2} = m_{2} \\oplus PRNG(k)$ Io so che solitamente da $m_{1} \\oplus m_{2}$ riusciamo a ricavare $m_{1}$ e $m_{2}$ per ridondanze del linguaggio (questa √® una cosa curiosa, dovrebbe essere approfondita). Quindi avendo i due cipher-text posso avere il valore sopra, perch√© $$ c_{1} \\oplus c_{2} = k \\oplus m_{1} \\oplus k \\oplus m_{2} = m_{1} \\oplus m_{2} $$ Questo √® stato usato nel verona project (\u0026lsquo;41 - \u0026lsquo;80)\nAmerican National Security Agency decrypted Soviet messages that were transmitted in the 1940s. That was possible because the Soviets reused the keys in the one-time pad scheme.\nNel caso vecchio di MS-pptp √® stato possibile attaccarlo, perch√© la chiave viene riutilizzata per server-client e client to server. Stessa cosa per il WEP.\nNo integrit√† üü© Un attaccante pu√≤ cambiare a suo piacimento il valore del plaintext iniziale, questo √® soprattutto utile se sa bene cosa cambiare, altrimenti un umano probabilmente pu√≤ capire che il messaggio √® senza senso, ma nella teoria √® giusto, il ricevente non pu√≤ capire se il messaggio √® stato modificato, o originariamente √® stato mandato cos√¨:\nSe attaccante modifica $c$ creando $c^{*} = c \\oplus p$ il ricevente avr√† $m \\oplus p$ quindi √® modificato, e non sa che √® stato cambiato.\nNOTA particolare Questo attacco √® particolarmente pericolo quanso\nSi sa la posizione del testo da cambiare Si sa il contenuto del testo cifrato in quella posizione. Se si hanno queste informazioni posso metterci un valore a piacere in quella zona. Questa cosa dovresti riuscire a capire perch√© sia cos√¨. Ad alto livello ti dico: fai xor con quella parte di testo, cos√¨ hai 0 in plaintext, poi rifai xor col tuo messaggio per metterci quello che ti pare. Real-world attacks L\u0026rsquo;unico takeaway √® non usare chiavi ripetute, che vedi sopra.\nWindows NT PPT (non fare) Perch√© veniva ripetuta la chiave sia client che server\nWEP (non fare) IV veniva ripetuta ongi 16M frames, che era presente Le chiavi generate per i vari frame sono molto correlate, perch√© cambia solo IV in seguente (dice la prof. che inviava anche in chiaro). Non so esattamente i dettagli ma non dovrebbe essere importante. Stream Ciphers Now we talk about stream ciphers, next about block ciphers, after that asymmetric cipher.., con questra struttura\nIntroduction Motivation and basic stuff üü© LSM was first kind of crypto for cellphones, and it was a stream cipher (fast, at least 12 y ago confronted with the other ciphers that existed).\nEncrypting individual bits! when block ciphers encrypt blocks of it. This leads to simple encryption and decryption operations. (this is a big addendum! most of embeeded devices use this because its easy and fast!) The hardware is nice for these cyphers. Standard template of encrypt decrypt (non fare) And we can note it‚Äôs an shift cipher (affine cipher) discussed in the Classical Cyphers.\nA note is that the decryption uses the Plus! This is because we are in modulus 2, and a sum is actually a xor operation. (see the logic table of it).\nProof of why the two operations are the same\nSempre dalla tavola logica si pu√≤ vedere che uno 0 pu√≤ essere criptato 50% a 0 e 50% a1, quindi √® resistente ad attacchi di analisi delle frequenze (ma questo solo se ho un generatore randomico buono !).\nRandom generators As the security of the scream cipher is dependent on the keys, we need to have a way to generate random keys.\nCategories of random number generators (3) (non fare) Cercare su Randomness per descrizione sul tema.\nTrue Random Number Generators tipically from random physical processes ma non riesco a farlo moltro in fretta\nLancio di dati Rumore Movimento del mouse. Random keyboard types. (e distanza tempo fra di essi). Pseudo-random Number Generators (vorremmo qualcosa di random, ma che possa produrre la stessa sequenza deterministic\nMost of these are not criptografically secure! (are usually predictable, so useless for cryptography). But they satisfy important statistical properties necessary for randomness (and tests) Forma classica di computazione\nCryptographically Secure PRNGs (same as PRNGs, but with unpredictability).\nDefinition of unpredictability\nCio√® non riesco a predire in che modo la sequenza pu√≤ continuare in tempo polinomiale, data una sequenza di bits di output. Definizione PRNG √à una funzione $\\left\\{ 0, 1 \\right\\}^{s} \\to \\left\\{ 0, 1 \\right\\}^{n}$ in cui $s \\ll n$ computabile da funzioni deterministiche, con solo il seed che √® l\u0026rsquo;input al randomness. In teoria gli algoritmi possono generare cose infinite, ma per quanto ci interessa, vogliamo restringerci solamente a un numero finito di bit in output (che √® cosa nella pratica abbiamo) Una cosa √® che l\u0026rsquo;algoritmo che li genera √® deterministico, compattabile diciamo con Kolmogorov complexity, ma con buoni security guarantees e anche statistiche, vedi Randomness. √à importante che quanto prodotto sembri essere random.\nOPT tramite PRNGüü© Possiamo usare #One Time Pad Cipher usando i PRNG! Cos√¨ risolviamo il problema di comunicazione di cose troppo grosse.\nAnalisi sicurezza stream cipher con PRNG Non abbiamo segretezza perfetta. Solamente che abbiamo la nota teorica in Classical Cyphers#Security of the Key che non possiamo avere sicurezza se la chiave reale √® minore rispetto a quella reale.\nStiamo spostando la sicurezza dell\u0026rsquo;OTP sul seed che genera. Abbiamo bisogno di una nuova definizione di sicurezza.\nExamples of PRNGs Questi sono stati analizzati tempo fa da Knuth nell\u0026rsquo;art of computer programming.\nLinear Congruential Generatorüü© abbiamo una sequenza $r_{0} = seed$ e $r_{i+1} = a \\cdot r_{i} + b \\mod p$ Sembra che questa cosa molto semplice abbiamo propriet√† statistiche Randomness molto carine, ma molto facile da scoprire.\nglibc random (non impo) $r_{i} = (r_{i - 3} + r_{i - 31}) \\mod 2^{32}$ in cui gli index sono dei singoli bit credo Poi viene ritornato $r_{i} /2$ per qualche motivo\nNota: questo non √® sicuro per√≤ come generatore!\nSecurity necessities for PRNGs Non predictability Possiamo definire che un PRNG √® predictable se esiste $i \\in N$ tale per cui avendo la sequenza $x_{0}, x_{1}, \\dots, x_{i}$ esista un algoritmo computabile secondo La macchina di Turing e che sia anche efficiente tale per cui possa calcolare $x_{i+1}, \\dots$. con una probabilit√† alta. Se vale questo, e possono trovare l\u0026rsquo;algoritmo che computa questo algoritmo, avrei tutto poi per decifrare il messaggio (known plain-text attack), anche se non conosco la chiave iniziale.\nLa prof la definisce cos√¨: $\\exists A, \\exists i : 1 \\leq i \\leq n - 1$ tale per cui $$ \\mathbb{P}_{k \\leftarrow K} \\left[ A(G(k)|x_{1},x_{2}, \\dots, x_{i}) = G(k)|x_{i+1}\\right] \\geq \\frac{1}{2} + \\varepsilon $$ con $\\varepsilon = \\frac{1}{2^{30}}$. Quindi se riesce a farlo in modo migliore del random gi√† diciamo che √® predictable. In parole naturali vale se riusciamo a creare $A$ tale per cui riesce a predire con probabilit√† maggiore del random. Questa definizione di predictable ci permette di definire il unpredictable, ed √® per questo che ci importa (inizialmente potrebbe essere strana la definizione con l\u0026rsquo;$\\varepsilon$) Infatti la negazione logica diventa: $$ \\forall i \\text{ no \"eff\" adv. can predict bit } (i + 1) \\text{ for \"non-negligible\" }\\varepsilon $$ Definition of negligibility Usiamo negligible e simili per avere un rule of thumb per capire ogni quanto non viene mantenuta la propriet√†.\n$\\varepsilon \\geq \\frac{1}{2^{30}}$ significa che ogni 1GB di data ho un caso in cui succede. Se ho $\\varepsilon \\leq \\frac{1}{2^{80}}$ non avverr√† tipo mai. La cosa √® che questo non √® molto rigoroso. Nella teoria possiamo definirli come funzione di un parametro di sicurezza. $$ \\varepsilon : \\mathbb{Z}^{\\geq 0} \\to \\mathbb{R}^{\\geq 0} $$ $$ \\text{ non neg: } \\exists d: \\varepsilon(\\lambda) \\geq \\frac{1}{\\lambda^{d}} $$ $$ \\text{ negligible } \\forall d, \\lambda \\geq \\lambda_{d} : \\varepsilon(\\lambda) \\leq \\frac{1}{\\lambda^{d}} $$ la cosa che ci interessa di negligible, √® simile al limite, √® qualcosa che cresce con $\\lambda$ che va sempre gi√π Statistical Tests e Advantage Qui viene definito solo come un algoritmo che ritorna 0 o 1 dopo che gli diamo la stringa iniziale in input. Per dire se √® random oppure non. Note migliori dovrebbero essere in Randomness.\nCon questo test e la possibilit√† di definire una sequenza truly random $r$ possiamo definire il concetto di advantage che in breve √® quanto bene riusciamo a distinguere la PRNG dal random vero. A me sembra abbastanza inutile questa definizione. Per√≤ pu√≤ essere utile per definire che il PRNG non √® abbastanza simile al random. L\u0026rsquo;intuizione principale √® che lo spazio $\\left\\{ 0, 1 \\right\\}^{n}$ √® molto pi√π ampio rispetto alle stringhe effettivamente generabili da $k$ sampling da $K$. Per√≤ vogliamo che statisticamente siano indistinguibili. La misura di advantage ci dice quanto sono distinguibili.\nL\u0026rsquo;algoritmo $A$ √® spesso chiamato oracolo.\nSecurity with advantage Secondo la prof. questa \u0026ldquo;advantage\u0026rdquo; √® una misura di quanto il sistema √® rompibile. Se √® simile a 1 sono abbastanza sicuro, altrimenti √® 0.\nA PRNG $G : K \\to \\left\\{ 0, 1 \\right\\}^{n}$ √® sicuro se per ogni test possibile (e questo √® gi√† molto irrealistico) √® vero che $$ Adv_{PRNG}[A, G] \\leq \\varepsilon $$ dove $\\varepsilon$ √® molto molto piccolo, negligible si potrebbe dire. Sembra che questo problema si riduca a $P \\not= NP$ per qualche motivo strano. Queste sono definizioni con oracolo perch√© assumiamo di avere un $r$ che √® truly random.\nQuesta definizione comunque secondo (Stinson 2005) chapt 6.9 √® molto difficile da raggiungere, perch√© troppo facile da rompere, perch√© tratta di leaks di informazione, ma solitamente di molto poco conto.\nConseguenza su P e NP Se si riesce a dimostrare che esiste un $PRG$ sicuro sotto questa definizione si pu√≤ dimostrare che $P \\neq NP$ vedi Time and Space Complexity.\nPredictable =\u0026gt; insecurity Suppose you have a predictable $PRG$, that is $\\mathbb{P}_{k \\sim K}\\left[ A(G(k)\\mid_{1,\\dots,i}) = G(k) \\mid_{i = 1} \\right] \\geq \\frac{1}{2} + \\varepsilon$ We can have a statistical test with non negligible security. Let\u0026rsquo;s define\n$$ B(x) = \\begin{cases} \\text{ if } A(X \\mid_{1,\\dots,i}) = X_{i+1} \\text{ output } 1 \u0026 \\\\ \\text{ else output } 0 \\end{cases} $$ If $r \\sim_{R} \\left\\{ 0, 1 \\right\\}^{n}$ this statistical test gives $\\frac{1}{2}$ because we have supposed it is not predictable. If we have the predictable sequence, by definition we can predict with $\\frac{1}{2} + \\varepsilon$ so the advantage is greater than $\\varepsilon$ so it is insecure given this definition.\nWe have now proved that secure -\u0026gt; unpredictability. We can also prove unpredictability -\u0026gt; security (this is Yao'82). So these are equivalent.\nsecure PRG -\u0026gt; semantically secure stream cipher We say that for all semantic security adversary $A$, exists a $PRG$ adversary $B$ (statistical test) such that $$ Adv_{SS}\\left[ A, Q \\right] \\leq 2 \\cdot Adv_{PRG}\\left[ B,G \\right] $$ Given $G$ a secure $PRG$ and $Q$ the stream cipher derived from $G$.\nSemantic security Why is semantic security important? see here. It relates to the notion \u0026ldquo;no information about the plaintext from the ciphertext\u0026rdquo;. It can be viewed as a relaxed version for Classical Cyphers#Security of the Key. The idea has subtle connotations. This restricts the perfect secrecy idea onto computationally plausible scenarios, where you assume that a computational entity can\u0026rsquo;t distinguish it.\nDefinizione semantic security Da https://en.wikipedia.org/wiki/Semantic_security\na¬†semantically secure¬†cryptosystem¬†is one where only negligible information about the¬†plaintext¬†can be feasibly extracted from the¬†ciphertext.\nDa un punto di vista teorico, questo √® un rilassamento della nozione di Classical Cyphers#Security of the Key, in cui si richiede che siano uguali, in questo setting richiediamo che siano solo vicine le due probabilit√†. Solo che sembra che sia inutile la nozione per s√© quindi introduciamo l\u0026rsquo;esperimento.\nNelle slides si fa un gioco di questo genere:\nChallenger e adversary L\u0026rsquo;avversario invia due messaggi in chiaro, Challenger invia i messaggi cifrati L\u0026rsquo;obiettivo dell\u0026rsquo;avversario √® identificare quale ciphertext coincide a quale messaggio, se si pu√≤ fare, non √® sicuro secondo la definizione di semantic security di sopra, anche se non so nella pratica quanto sia vero. Questo √® vero quando #Security with advantage √® negligible, quindi non si pu√≤ fare. Per il prof. √® leggermente diverso rispetto a questo:\nProbabilit√† di associare il ciphertext al corrispettivo plaintext.\nQuesto si pu√≤ riassumere in questo: Ossia non √® in grado di distinguere la funzione fatta con chiave da una funzione a caso nell\u0026rsquo;insieme delle funzioni. E quindi per l\u0026rsquo;avversario entrambi i plain-text sembrano essere uguali e non ha advantage.\nSemantic security for many-time key Abbiamo ora che la chiave √® usata pi√π di una volta, quindi abbiamo molte coppie, magari anche qualche plain-text, vogliamo chiederci in teoria se √® possibile usare la stessa chiave e avere ancora lo stesso livello di sicurezza. Questo pattern √® molto comune, IPsec, criptare dischi\u0026hellip; Infatti pu√≤ scegliere quale plain-text avere a suo piacimento, si chiama chosen plain-text.\nOssia pu√≤ scegliere quanti messaggi vuole per un certo esperimento\nThe challenger chooses a $b$ to compute, then adversary can send messages and receive ciphertexts how many times as he likes. Security of same ciphertext under CPA If the cipher outputs the same message when encrypting the same plain-text, it can be proven that it has not CPA security. This urges the creation of ciphertexts that need to create different ciphertexts with the same plaintext!\n##### Nonce based-security L'idea √® la stessa di cui abbiamo parlato in [Sicurezza delle reti](/notes/sicurezza-delle-reti) per un protocollo di autenticazione. Un esempio carino di questo √® in [Block Ciphers#Cipher Block Chaining (CBC)](/notes/block-ciphers#cipher-block-chaining-(cbc)) per cercare di randomizzare l'IV. Semantic security for Chosen Ciphertext This definition is used for public encryption schemes. Two phases.\nAdversary can ask for decriptions of any ciphertext. Then classically sends two messages, and receives a ciphertext Then can again send ciphertext again, except for the ciphertext he received Then outputs $0$ or $1$. Practical stream ciphers In questo caso andiamo ad utilizzare un PRNGs, non pi√π truly random, per le ragioni di efficienza di comunicazione‚Ä¶\nla chiave sono i valori delle cose affini nel LCG.. (forse anche il seed? boh)\nRC4 cipher Non so bene come √® stato creato questo algoritmo, probabilmente provato cose a caso??? Questo √® stato inventato da Ron Rivest, lo stesso che ha inventato l\u0026rsquo;algoritmo di RSA del 1987.\nInizializzazione Usiamo il seed $s$ per inizializzare una permutazione dei primi 256 numeri\nS[i] \u0026lt;- arange(0, 257) s = len S j \u0026lt;- 0 for i \u0026lt;- 0 to 255 do: k \u0026lt;- S[i mod s] j \u0026lt;- (j + S[i] + k) mod 256 swap(s[i], s[j]) Con questo algoritmo in pseudocodice\nGenerazione (non fatta) #### Attacchi üü® Non segue la definizione di [Classical Cyphers#Security of the Key](/notes/classical-cyphers#security-of-the-key), c'√® del bias in quanto generato che si pu√≤ sfruttare in modo abbastanza semplice, per esempio si pu√≤ attaccare WEP che usava questo algoritmo in questo modo. ### Content Scrambling System (non fatto) Ma Dan Boneh parla di [#Linear Feedback Shift Registers](#linear-feedback-shift-registers) in questa sezione. eStream Cypher Si ha solitamente un nonce in questo caso, lo stesso che abbiamo usato in Sicurezza delle reti. Quindi un valore randomico utilizzato una singola volta\nSalsa 20 √à un algoritmo moderno di stream cipher, solitamente implementato in hardware per velocit√†. Prende una chiave 256 bit e un nonce di 64. Utilizza questo per fare un mix di 20 rounds e poi produrre ili bit stream utilizzato per encodare il plaintext iniziale. Questo √® ancora sicuro, attacchi esistenti non riescono a romperlo totalmente pagina wiki Veloce che fa Mezzo giga al secondo di cifrazione.\nLinear Feedback Shift Registers This is a way to create a stream of bits to xor with the message. This stream is generated with a key. One of the advantages is that it‚Äôs low power in hardware.\nShift registers You have to remember flip flops by Circuiti Sequenziali in architecture.\nCoso per storare un singolo bit sincronizzato dal clock del computer. La cosa interessante quando si collegano input e output fra flipflops diversi, √® che ad ogni ciclo di clock, si ha una specie di onda che shifta tutti i bit! Quando l‚Äôoutput √® rixorato in certi modi e rimesso all‚Äôinizio, ecco che riusciamo ad avere il feedback lineare!\nEsempio di mini Linear feedback Shift register\nEsempio di LFSR generalizzato\nMatematical Description Con p, per dire se √® 0 o 1 (o aperto o chiuso). E poi in pratica √® l‚Äôoperazione di +, o xor.\nWe want to have a LSFR which has a very long period\nPossiamo anche descrivere un LSFR con dei polinomi. In particolare √® importante sapere\nil numero dei registri Le porte che sono aperte e quelle che sono chiuse. Quindi si pu√≤ rappresentare come $$ P(x) = x^{m} + p_{m - 1}x^{m - 1} + \\dots + p_{1}x + p_{0} $$ Per√≤ non so ancora perch√© questa rappresentazione del LSFR √® utile, boh, lasciamo star.\nTheorem on the period of LSFR L‚Äôidea della dimostrazione √® tipo che gli stati interni della LSFR √® al massimo $2^m - 1$, quindi al massimo il periodo √® quello. (non posso avere 0 perch√© senn√≤ avrei periodo di 1, che non serve a niente).\nMa non tutti hanno periodo massimo! Forse centrano qualcosa i polinomi ciclotomici, per√≤ sta fuori dalla mia capacit√† matematica lol.\nEsempi di LSFR massimi e non\nKnown Plaintext Attacks Il nemico conosce\nTutto il ciphertext il grado dell‚ÄôLSFR (se non lo sa fa bruteforce, e quindi √® come se lo sapesse) Conosce i primi 2m bits del plaintext, quindi sa i primi 2m bits generati. Dal plaintext conosciuto, vorremme ricavare tutti i bits successivi di questo stream cipher. (basta ricavare i valori dei p, ora vediamo un metodo per ricavarli).\nDato che possiede 2m bits conosciuti e conosce m, deve risolvere un sistema di m incognite e m equazioni, e questo si fa, quindi cos√¨ riesce a ricavare LSFR da queste!\nReferences [1] Stinson ‚ÄúCryptography: Theory and Practice, Third Edition‚Äù CRC Press 2005\n","permalink":"https://flecart.github.io/notes/otp-and-stream-ciphers/","summary":"XOR operation √à una operazione binaria abbastanza semplice per√≤ ci sar√† importante per andare ad analizzare dei cifrari di un certo genere. Come il ONE TIME PAD che faremo fra poco in OTP and Stream Ciphers.\nTeorema cifratura con XOR Prendiamo $X$ una variabile aleatoria in $\\left\\{ 0,1 \\right\\}^{n}$ uniforme, sia $Y$ una variabile aleatoria su uno stesso dominio come vogliamo. Tali per cui $X, Y$ siano indipendenti Allora avremo che $C = X \\oplus Y$ √® una variabile aleatoria uniforme.","title":"OTP and Stream Ciphers"},{"content":"What is a part of Speech? A part of speech (POS) is a category of words that display similar syntactic behavior, i.e., they play similar roles within the grammatical structure of sentences. It has been known since the Latin era that some categories of words behave similarly (verbs for declination for example).\nThe intuitive take is that knowing a specific part of speech can help understand the meaning of the sentence.\nDefinition of the problem We assume there are some given categories (it has some drawbacks, because we can define too many categories sometimes, making the thing more difficult), for example, in a classical analysis, we would have articles, noun verbs.\nIt is possible to see this problem as a path in a graph, even though currently I don\u0026rsquo;t know what is the exact advantage for this. There is a relation between statistica models and combinatorial algorithms. We should use this relation to score the path.\nConditional Random Fields These are just Log Linear Models on structured data.\nWe define our conditional probabilistic model for sequence labeling, aka conditional random field:\n$$ p(t \\mid w) = \\frac{\\exp(s(t, w))}{\\sum_{t' \\in \\mathcal{T}^{N}} \\exp(s(t', w))} $$ where $s$ is the scoring function that marks the compatibility of a tag into a word or token. The score could also be negative. If the score is linear the whole random field would be a in The Exponential Family. The only requirement is that it returns a scalar.\nBut this algorithm is very slow! Computing the normalizer takes $\\mathcal{O}(\\lvert \\mathcal{T} \\rvert^{N})$ time. Assuming more structure (it is free information from another point of view), allows to have faster algorithms.\nAdditively decomposable assumption We assume additively decomposability into the score function: $$ s(t, w) = \\sum_{n = 1}^{N} s(\\langle t_{n - 1}, t_{n} \\rangle , w) \\implies \\exp(s(t, w)) = \\exp\\left( \\sum_{n = 1}^{N} s(\\langle t_{n - 1}, t_{n} \\rangle , w) \\right) \\prod_{n = 1}^{N} \\exp(s(\\langle t_{n - 1}, t_{n} \\rangle ,w)) $$ which means: instead of looking at the whole structure we only look adjacent tags. This is a strong assumption, but it\u0026rsquo;s ok to start doing something that might be useful. NOTE: we use a special symbol when $n = 1$. This makes it easy to compute the score, because we can just take adjacent couples instead of the whole string.\nIf the score is a neural network, then we can train this function without exactly knowing how they are made!\nSimplifying the partition function After we have a score, then it is just a shortest path problem, a combinatorial optimization problem, it\u0026rsquo;s nice to see the derivation of why it\u0026rsquo;s easy to compute the normalizer:\n$$\n\\begin{align} \\sum_{t \\in \\mathcal{T}^{N}} \\exp \\left{ \\sum_{n = 1}^{N} s(\\langle t_{n - 1}, t_{n} \\rangle , w) \\right} =\\ =\\sum {t{1:N} \\in \\mathcal{T}^{N}} \\prod_{n = 1}^{N} \\exp \\left{ s(\\langle t_{n - 1}, t_{n} \\rangle , w) \\right}\\ = \\sum {t{1:N-1} \\in \\mathcal{T}^{N-1}} \\sum_{t_{N} \\in \\mathcal{T}} \\prod_{n = 1}^{N} \\exp \\left{ s(\\langle t_{n - 1}, t_{n} \\rangle , w) \\right} \\ = \\sum {t{1:N-1} \\in \\mathcal{T}^{N-1}} \\prod_{n - 1}^{N - 1} \\exp \\left{ s(\\langle t_{n- 1}, t_{n} \\rangle , w) \\right} \\times \\sum_{t_{N} \\in \\mathcal{T}} \\exp \\left{ s(\\langle t_{N - 1}, t_{N} \\rangle , w) \\right} \\ = \\sum_{t_{1} \\in \\mathcal{T}} \\exp \\left{ s(\\langle t_{0}, t_{1} \\rangle , w) \\right} \\times \\dots \\times \\sum_{t_{N} \\in \\mathcal{T}} \\exp \\left{ s(\\langle t_{N - 1}, t_{N} \\rangle , w) \\right} \\end{align} $$\nWhere we have just applied a distributive property in the 4 line, and reapplied the same line of reasoning over and over again. Now we have a simple and fast way to calculate it, it\u0026rsquo;s just a linear number of terms. The deep insight is that here we derived an algorithm by just doing some algebra! Is there some deep links between an algebraic view of computation and algorithms with algebra?\nSo a simple algorithm could be:\nThe Viterbi algorithm How to find the highest-scoring tagging for a certain input sequence $w$? We just add a max operator instead of the sum! This makes it quite easy. This is very similar to the backward algorithm used to calculate the partition function: The only thing we need is a semi-ring.\nSemirings A semiring is a 5-tuple $R = (A, \\oplus, \\otimes, \\bar{0}, \\bar{1})$ such that.\n$(A, \\oplus, \\bar{0})$ is a commutative monoid $(A, \\otimes, \\bar{1})$ is a monoid $\\otimes$ distributes over $\\oplus$. $\\bar{0}$ is annihilator for $\\otimes$. Monoid Let $K, \\oplus$ be a set and a operation, then:\n$\\forall a, b, c \\in K$ we have that $a \\oplus (b \\oplus c) = (a \\oplus b) \\oplus c$ $\\exists 1$ such that $\\forall a \\in K$ we have $1 \\oplus a = a \\oplus 1 = a$ A monoid has associativity and identity element. This structure allows us to use that sort of backpropagation. A simple example of a semiring would be $\\left( \\mathbb{R}^{+}, +, \\times, 0, 1 \\right)$. We can show every property above. The deep insight is that dynamic programming just needs semirings with distributive property to work! All of the above derivation for the algebraic method for the algorithm just needs that our operation is a semiring! Then everything would work in the same manner.\nRing We have a semiring, with the addition that addition is invertible. So instead of monoid, we have a group for the addition.\\\nIf a semiring has a multiplication operation that is commutative, then it\u0026rsquo;s called communicative semiring. If semiring has idempotent operation, then it\u0026rsquo;s a idempotent semiring.\n","permalink":"https://flecart.github.io/notes/part-of-speech-tagging/","summary":"What is a part of Speech? A part of speech (POS) is a category of words that display similar syntactic behavior, i.e., they play similar roles within the grammatical structure of sentences. It has been known since the Latin era that some categories of words behave similarly (verbs for declination for example).\nThe intuitive take is that knowing a specific part of speech can help understand the meaning of the sentence.","title":"Part of Speech Tagging"},{"content":"In this note we explore a theme of time and space complexity. Those are cardinal themes in Theoretical CS. Time -\u0026gt; execution step bounds on algorithms Space -\u0026gt; the cells visited by a Turing Machine when executed.\nIntroduction to Time Complexity This note will build upon know techniques of algorithms analysis explained in Notazione Asintotica. We will need big-$O$ notation and $o$ notation. L\u0026rsquo;idea √® che il problema di decisione √® decidibile se limito la lunghezza del teorema. Simile al numero di Chaitin, che non √® computabile, ma √® approssimabile quanto si vuole. In un certo senso √® computabile. The general idea is to ask how the function $\\varphi$ that maps the longest $n$ proof to the number of steps of computation behaves.\nRobustness of the notion of time complexityüü® The notion of \u0026ldquo;computational steps\u0026rdquo; used to measure the time complexity varies along\nComputational models definition of computational steps The code of the input and output (not always binary, for example big numbers are not fixed size). Influence of the Computational Model In Complexity Theory the choice of the formal model influences the complexity class of the model! This is different from the argument from computational theory of the Church Turing Thesis, where it asserts that a function is computable in every computational model. See 7.7 in (Sipser 2012).\nMulti-tape vs single-tape TM It can be proved that every $t(n)$ time multi-tape TM can be simulated by a $t^{2}(n)$ single tape TM. See Theorem 7.8 of (Sipser 2012).\nThe Time Complexity Class Definition of the Time Complexity Classüü© Languages that are decidable in $O(t(n))$ time are part of this class, denoted as $TIME(t(n))$. With $t : \\mathbb{N} \\to \\mathbb{R}^{+}$.\nAnother way to understand this is that if a algorithms terminates in at most $t(n)$ steps then it belongs to this class.\nPolynomial Complexity Classüü© The polynomial class $P$ is defined as: $$ P = \\bigcup_{i \\geq 1} TIME(n^{i}) $$ This is defined as the class of the reasonable efficiency programs. NOTE: this is invariant with respect to the chosen coding system (if an algorithm is still in P, then it will remain in P even if you change code scheme).\nP is invariant for all models of computation that are polynomially equivalent to the deterministic single-tape Turing machine, and P roughly corresponds to the class of problems that are realistically solvable on a computer. Analogously we define $$ EXP = \\bigcup_{i \\geq 1} TIME(2^{n^{i}}) $$ See later.\nPATH is in Püü© We can prove that the language $\\left\\{ \\langle G, s, t \\rangle \\mid G \\text{ is a graph that has a route from } s \\text{ to } t \\right\\}$ is in $P$ class. (Just use Grafi#BFS or Grafi#DFS).\nNOTE: we have worked assuming that the algorithm worked on the nodes, but usually TM work with bits, the thing is that there is a polynomial algo that converts that nodes into binary format, so it is not much of a big deal.\nOverview of problems in $P$ Exponential Complexity Classüü© The exponential class $EXP$ is defined as: $$ EXP = \\bigcup_{i\\geq 1} TIME(2^{n^{i}}) $$ This class is common of the algorithms that use backtracking, for example Costraint Satisfaction Problems. Or just brute-force search all the branches.\nNon-deterministic Complexity Class Let $N$ be a non-deterministic decider (which means that the TM will halt on every computation branch) then we have that a problem is in this complexity class, called $NTIME$ if the running time cost $f: \\mathbb{N} \\to \\mathbb{N}$ is bounded by that (longest computational branch). The difference with #Polynomial Complexity Class is that here we consider the length of a single branch, but we explore everything at the same time!\nQuindi\n$$ NP = \\bigcup_{i\\geq 1} NTIME(n^{k}) $$ Simulation by Deterministic TM We can prove that every TM in NP can be simulated by a deterministic machine in $2^{Ot(n)}$ time, where $t(n)$ is the complexity class of the TM. The intuition is easy, just try every possible computational branch, and see for the result. We then observe that $NP \\subseteq EXP$ but this is not so useful.\nClique problem See Common problems in Theoretical CS#The Clique problem for description of the problem.\nNP algorithm Just\nSelect a subset of nodes from $G$. Do it non deterministically. Verify if this subset is a complete graph. If yes add it to the solution set. We can prove that this is correct, and it works, but it is a non deterministic algorithm, so it isn\u0026rsquo;t easily simulated by deterministic algorithms, even though we proved in Estensioni di Turing e altre macchine that from the computability point of view it is the same.\nVerifiable Given input the graph, and a subset, we need to\nFor each node in the subset, check if it is linked to each other. Return the previous truth result. So easy. Other NP-complete problems If you have some time, you should give a proof for each problem (poly-reduction from sat)\nVertex Cover Hamiltonian paths Undirected Hamiltonian paths Subset-sum Verifiability Def: verifiability Definition: $A$ is verifiable if exists a TM $M$ such that: $$ w \\in A \\iff \\exists c : M \\text{ accepts } \\langle w, c \\rangle $$ If $M$ is polynomial then we say that this is polynomially verifiable. We can prove that this notion is equivalent for $NP$ complexity classes. We also require that $c$ is of polynomial length.\nTh: Verifiability = NPüü© From a philosophical point of view, if a problem is in NP, we can just guess a solution, or just do brute force. There is no classical algorithmical solution that solves it, or a constructive proof for it.\n$\\leftarrow$: let\u0026rsquo;s suppose we have a $M$ that decides non deterministically that language. On input $\\langle w, c \\rangle$ we run $M(w)$ and if it accepts, return true if the branch is good. ($c$ guides us about what non-deterministic branch to choose).\n$\\to$ : let\u0026rsquo;s assume we have a polynomial verifier, we need to build a TM that decides it non deterministically in polynomial time. choose non deterministically a certificate $c$ the encodes the path of the non-deterministic computation. If this accepts then accept!\nPhilosophical thoughts on P vs NP Intuitively we can have this intuition: The class of problems in $P$ is the class of problems were you need to come up with a solution by yourself. The class of problems in $NP$ is the class of problems were you just need to verify if a given solution is valid. From a personal human point of view this clearly seem to indicate that the two classes are different. But we have no proof.\nIf P were equal to NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in ‚Äúcreative leaps‚Äù, no fundamental gap between solving a problem and recognizing the solution once it‚Äôs found. Everyone who could appreciate a symphony would be Mozart; Everyone who could follow a step-by-step argument would be Gauss.\n‚Äì Prof. Scott Aaronson, 2006\nSpace complexity terminology Def: space complexity Given a $\\mathcal{M}$ Turing Machine that halts on every input, then his space complexity is a function $t : \\mathbb{N} \\to \\mathbb{N}$ such that $t(n)$ is the maximum number of cells visited by $\\mathcal{M}$ on inputs of length $n$. We can say something very similar for the non-deterministic TM, se way that its space complexity is the maximum number of tape cells visited on a single computational branch.\nDef: Space complexity Class We define the space complexity class $SPACE(t(n))$ as all languages decidable by a TM in $O(t(n))$ space. Analogously the $NSPACE(t(n))$ complexity class is defined. We use a non-deterministic TM here.\nWe willl ater find that $$ P \\subseteq NP \\subseteq PSPACE = NPSPACE \\subseteq EXPTIME $$ The last subset is given by an observation that a TM that uses $f(n)$ space (PSPACE) cannot have more than $f(n)2^{O(f(n))}$ computational steps before looping. Def: PSPACE and NPSPACE We define in a matter similar to what is done in Time and Space Complexity: $$ PSPACE = \\bigcup_{k}SPACE(n^{k}) $$ And $$ NPSPACE = \\bigcup_{k} NSPACE(n^{k}) $$ Def: PSPACE-completeness We say that $L$ is PSPACE-complete if it is $\\in PSPACE$ and every other $L' \\in PSPACE$ is poly-reducible to it.\nTh: $NP \\in PSPACE$ In order to prove this we prove that $SAT \\in PSPACE$ because as it is $NP-complete$ every NP problem can be reduced to $SAT$ and so it is in $PSPACE$. For more about SAT see Common problems in Theoretical CS#The SAT problem.\nProof of SAT in PSPACE We note that the simple algorithm that just enumerates all possible assignments is in $PSPACE$. Consider this algorithm: For all assignments for the input boolean formula do:\nAssign it and verify in poly-time if it is ok. If ok return true else continue until every assignment is used. We note that just $O(m)$ space is used, where $m$ is the number of terms. All the computation could be done in polynomial space, so the problem is in PSPACE. $\\square$. References [1] Sipser ‚ÄúIntroduction to the Theory of Computation‚Äù Cengage Learning 2012\n","permalink":"https://flecart.github.io/notes/time-and-space-complexity/","summary":"In this note we explore a theme of time and space complexity. Those are cardinal themes in Theoretical CS. Time -\u0026gt; execution step bounds on algorithms Space -\u0026gt; the cells visited by a Turing Machine when executed.\nIntroduction to Time Complexity This note will build upon know techniques of algorithms analysis explained in Notazione Asintotica. We will need big-$O$ notation and $o$ notation. L\u0026rsquo;idea √® che il problema di decisione √® decidibile se limito la lunghezza del teorema.","title":"Time and Space Complexity"},{"content":"Ci chiediamo come facciamo a rendere sistemi informatici accessibili a persone attraverso certe tecnologie.\nSlide esempi di disabilit√†\n√à meglio renderlo accessibile perch√© √® illegale (nel senso che stai facendo una discriminazione verso un certo insieme di persone).\nWGAC Queste sono alcuni principi di accessibilit√†, basati su 4 principi fondamentali\n4 principi del WGAC POUR per facilit√† di ricordarsi\nPerceivable (che ci siano le informazioni necessarie per l\u0026rsquo;accessibilit√†) Operable Understandable Robus Linguaggio Il tag del linguaggio √® utilizzato per sapere in che accento leggere e dare gli ordini.\nImmagini C\u0026rsquo;√® una distinzione fra immagini decorative e non decorative, quelle decorative sono funzioni estetiche che vengono ignorate dai lettori. (si lasca la alt vuota).\nIntestazioni Dovremmo annidare solamente dei h2 in h1 e non viceversa!\nTabella Form Wrapping label √® un metodo Altrimenti ci metto un for (quindi label for) ","permalink":"https://flecart.github.io/notes/accessibilit%C3%A0/","summary":"Ci chiediamo come facciamo a rendere sistemi informatici accessibili a persone attraverso certe tecnologie.\nSlide esempi di disabilit√†\n√à meglio renderlo accessibile perch√© √® illegale (nel senso che stai facendo una discriminazione verso un certo insieme di persone).\nWGAC Queste sono alcuni principi di accessibilit√†, basati su 4 principi fondamentali\n4 principi del WGAC POUR per facilit√† di ricordarsi\nPerceivable (che ci siano le informazioni necessarie per l\u0026rsquo;accessibilit√†) Operable Understandable Robus Linguaggio Il tag del linguaggio √® utilizzato per sapere in che accento leggere e dare gli ordini.","title":"Accessibilit√†"},{"content":"Alberi BST e AVL 4.1 Alberi binari di ricerca (BST) Queste sono delle varianti rispetto all\u0026rsquo;albero, descritto in modo molto sommario sopra (binario perch√© ogni nodo ha al massimo due figli, mentre l\u0026rsquo;albero pu√≤ averne quanti se ne vuole).\n4.1.1 Introduzione La caratteristica principale dell\u0026rsquo;albero di ricerca √® una condizione sulle chiavi (che hanno i figli).\nInfatti questo albero binario di ricerca si pu√≤ vedere come una implementazione della struttura astratta del dizionario. (che ricordiamo, √® un struttura in cui a ogni nodo sono presenti due valori, una chiave (tute differenti) e un dato, e sono definite tre operazioni principali, possiamo vederla come interfaccia).\nAl massimo due figli per nodo. (albero binario) Il dizionario, quindi che ogni nodo abbia chiave. I figli di sinistra hanno chiavi minori del genitore, a destra maggiore. 4.1.2 Prototipo Possiamo definire alcune operazioni principali per l\u0026rsquo;albero di ricerca:\nLe tre standard che sono presenti per il dizionario. (search, insert e delete) Max e Min. Predecessor e successor Saltiamo le note di implementazione di questi algoritmi :D perch√© sono gi√† triti e ritriti.\nUna nota su predecessor:\nPer l\u0026rsquo;operazione di delete abbiamo solamente considerato il caso di predecessor quando il nodo da considerare possedeva il figlio giusto.\nMa √® possibile che non lo abbia, allora √® molto simile, ma opposto (invece di scendere continuamente a destra, salgo continuamente a sinistra, con continuamente nel senso finch√© c\u0026rsquo;√® ancora il nodo).\n4.2 Alberi AVL Questi sono alberi AVL (il cui nome deriva dal nome dei creatori, come RSA), alberi bilanciati secondo l\u0026rsquo;altezza dei sottonodi. La cosa buona √® che avendo i bilanciamenti abbiamo un altezza logaritmica. in particolare possiamo dire che questi siano autobilancianti.\nIntroduciamo ora alcuni concetti importanti per comprendere il bilanciamento\n4.2.1 il concetto di bilanciamento Il fattore di bilanciamento\nCerchiamo di considerare un fattore di bilanciamento che si ottiene con\ncon h una funzione che mi ritorna l\u0026rsquo;altezza. (da notare che √® l\u0026rsquo;altezza, non la funzione).\nE l\u0026rsquo;altezza parte da 0\n$$ \\beta = fattore\\_bilanciamento = h(sinistra) - h(destra) $$ Bilanciato in altezza\nConsideriamo un albero bilanciato in altezza se $|\\beta| \\leq 1$\n4.2.2 Altezza di un albero di fibonacci L\u0026rsquo;albero di fibonacci √® molto interessante da studiare dal punto di vista dell\u0026rsquo;altezza, infatti possiede il massimo sbilanciamento possibile\nIntuizione dell\u0026rsquo;albero (dalla costruzione puoi dimostrare la sua altezza in modo intuitiva)\nNumero di nodi nell\u0026rsquo;albero di fibonacci\nConclusione sull\u0026rsquo;altezza\n4.2.3 Operazioni elementari (rotazione e altezza) Altezza\nPossiamo definire un algoritmo per definire il fattore di bilanciamento e l\u0026rsquo;altezza di un sotto-albero (da sapere bene, fare attenzione ai casi null)\nAlgoritmo (fattore bilanciamento e update altezza di un nodo)\nOperazione di rotazione\nUna rotazione √® una operazione elementare di su un albero che mi riposiziona alcuni figli e genitori di un nodo.\nEsempi di rotazione semplice\nPseudocodice della rotazione\n4.2.4 Risoluzione degli sbilanciamenti Possiamo catalogare le possibili tipologie di sbilanciamento in 2 macrogruppi di 2 (sono simmetrici destra e sinistra), questi saranno risolvibili tramite rotazioni, che, come vedremo, hanno la propriet√† di diminuire l\u0026rsquo;altezza del nodo di rotazione di 1.\nTipi di sbilanciamento\nSbilanciamento di tipo SS (simmetrico DD)\nSbilanciamento di tipo DS\nPseudocodice per risolvere sbilanciamento\n4.2.5 Note su inserimento e rimozione Queste due operazioni sono le uniche che possono cambiare il bilanciamento dell\u0026rsquo;albero.\nSi pu√≤ dimostrare che l\u0026rsquo;inserimento sbilancia al massimo un nodo, per cui una unica rotazione √® sufficiente per il tutto.\nMentre la rimozione pu√≤ sbilanciare tutto il percorso fino la radice come questa operazione:\nEsempio\n","permalink":"https://flecart.github.io/notes/alberi-bst-e-avl/","summary":"Alberi BST e AVL 4.1 Alberi binari di ricerca (BST) Queste sono delle varianti rispetto all\u0026rsquo;albero, descritto in modo molto sommario sopra (binario perch√© ogni nodo ha al massimo due figli, mentre l\u0026rsquo;albero pu√≤ averne quanti se ne vuole).\n4.1.1 Introduzione La caratteristica principale dell\u0026rsquo;albero di ricerca √® una condizione sulle chiavi (che hanno i figli).\nInfatti questo albero binario di ricerca si pu√≤ vedere come una implementazione della struttura astratta del dizionario.","title":"Alberi BST e AVL"},{"content":"Ha senso solamente parlare di autovettori quando si ha una applicazione lineare con stesso dominio e stesso codominio.\nVorremmo trovare una buona matrice che sia diagonale.\n6.1 Diagonalizzabilit√† 6.1.1 Definizione per funzione e matrice Questo perch√© vorrei una base in cui si abbia un matrice diagonale. (quindi probabilmente P √® una matrice identit√†).\nPerch√© ci piacciono le matrici diagonali\nSe ho una matrice diagonale, si ha che l\u0026rsquo;applicazione lineare √® un semplice scaling dei vettori della base.\n6.1.2 Matrici simili Date due matrici in uno spazio vetoriale con le matrici, allora se esiste un P nello stesso spazio tale che $B = P^{-1}AP$ si dicono simili (in pratica fare uno scambio di base).\nOsservazione 1\nPosso dimostrare che la matrice $A_{ee'} \\sim A_{bb'}$ associata a una funzione, sono simili per il teorema del cambio di base di sopra\nOsservazione 2\nLa simile, √® una relazione di equivalenza (riflessivit√†, simmetria e transitivit√†)\n6.1.3 Diagonalizabilit√† di una matrice quadrata Si pu√≤ dire che una matrice quadrata A √® diagonalizzabile se √® simile a una matrice diagonale\n(Anche la definizione di sopra √® uguale (equivalente).\n6.1.4 Equivalenza della diagonalizzabilit√† funzionale e matriciale (9.1.4)(!!!) Si ha che una funzione F e la sua matrice associata.\nAllora F diagonalizzabile SSE la sua matrice associata √® diagonalizzabile.\nDimostrazione\n$\\implies$Supponiamo che la funzione sia diagonalizzabile, allora ho una base per cui si ha una matrice diagonale.\nA questo punto utilizzo il teorema del cambio di base per costruirmi la P voluta per la diagonalizzabilit√† (o avere una matrice simile) e ci√≤ finisce.\n$\\impliedby$ Supponiamo che si abbia una matrice diagonalizzabile, allora abbiamo una matrice P che mi dia una matrice diagonale.\nLemma: le righe di P sono linearmente indipendenti. Si dimostra per il teoremone (l‚Äôesistenza dell‚Äôinversa, implica che √® associata a una funzione bigettiva, che implica che le colonne sono indipendenti).\nConsidero le colonne di P, queste sono N vettori indipendenti che fanno quindi span sullo spazio vettoriale Rn. Ma allora P √® proprio $I_{be}$ con b la base definita dalle colonne!\nE quindi ho trovato la base per la funzione tale che sia diagonale, quindi la funzione √® diagonalizzabile.\n6.1.5 Condizione di diagonalizzabilit√† (!!!!) ‚≠ê Si pu√≤ dire che una funzione F sia diagonalizzabile sse esiste una base di Rn costituita da autovettori di F\nLa dimensione delle due frecce √® identica (almeno le tecniche lo sono)\nDimostrazione\n$\\impliedby$Sia una base di Rn costituita da autovettori della F. Allora la matrice associata a questa funzione √® una matrice diagonale per questa base (bisogna fare un p√≤ di conti).\n$\\implies$Sia b una base tale che la matrice associata alla funzione sia diagonalizzabile, allora ho una base per cui la funzione √® diagonale. Elimino questo esiste con la base beta, voglio dimostrare che siano autovettori.\n6.2 Calcolo degli autovettori e autovalori 6.2.1 Autovalore 0 e kernel (!) $Ker F \\neq 0_v \\iff F$ ha autovalore $0$\nDimostrazione\n$\\implies$ supponiamo che $v \\neq 0_v, v \\in Ker F$ allora $F(v) = 0\\cdot v = 0$, ossia 0 √® un autovalore.\n$\\impliedby$Supponiamo che 0 sia un autovalore, allora esiste un autovettore (per definizione diverso da 0) allora esiste un elemento diverso da 0 nel kernel, e quindi non √® iniettiva per una proposizione precedente\n6.2.2 Polinomio caratteristico Nota: si ha che se ho una matrice n x n il polinomio caratteristico ha grado n.\n6.2.3 Autospazio e Polinomio caratteristico (!!!) L\u0026rsquo;autospazio per un certo autovalore √® questo insieme\n$V_\\lambda = \\{v \\in \\R^n | F(v) = \\lambda v\\}$, ossia √® l\u0026rsquo;unione dei autovettori con lo zero.\nProposizione:\n$V_\\lambda = Ker(A - \\lambda I)$, con il kernel della matrice definita come le soluzioni del sistema lineare omogoneo associato ala matrice (che poi √® uguale al concetto della funzione).\nDimostrazione\n$\\implies$Sappiamo che $V_y$ √® l\u0026rsquo;insieme degli $x \\in R^n| Ax = \\lambda x$ con A la matrice associata la nostra funzione. Vogliamo dimostrare che se $x \\in V_\\lambda$ allora appartiene al kernel, il che √® abbastanza ovvio per la propriet√† distributiva della moltiplicazione matriciale.\n$\\impliedby$Se si ha un v appartenente al kernel, allora poi si ricava (aggiungendo e sottraendo una parte) che $Ax = \\lambda x$ che √® proprio la condizione sufficiente per appartenere all\u0026rsquo;autospazio\n6.2.4 Polinomio car per Matrici simili (no chiede) Matrici simili hanno lo stesso polinomio caratteristico, questo si dimostra con distributivit√† e associativit√† della moltiplicazione matriciale.\nDimo\n$A - \\lambda I = P^{-1}BP - \\lambda I = P^{-1}BP - P^{-1}P\\lambda I = P^{-1}(B - \\lambda I) P$\n6.2.5 Condizione dell‚Äôautovalore (!!!) Dimostrazione\n$\\iff$Se $\\lambda$ √® un autovalore, allora ho un autovettore che appartiene all\u0026rsquo;autospazio relativo.\nVogliamo che l\u0026rsquo;autospazio √® diverso da 0, questo √® vero sse il sistema lineare (A - lambdaI)x = 0 ha una soluzione non nulla, allora per il teoremone, questo √® vero sse il determinante della matrice √® uguale a 0. quindi sse lambda √® uno zero della nostra matrice.\n6.3 Molteplicit√† e autov{ettori, alori} 6.3.1 Autovalori diverse fanno autovettori indipendenti (no chiede) Si dimostra in modo induttivo, partendo da un unico vettore che √® necessariamente indipendente, saltando per il passo induttivo e finire.\n6.3.2 Molteplicit√† geometrica ed algebrica DOmanda da fare alla marta\nIl fatto che la moltiplicit√† geometrica √® minore o uguale alla molteplicit√† geometrica potrebbe essere insito nel polinomio caratteristico.\nPerch√© al massimo (√® da dimostrare) che il grado del polinomio caratteristico √® N, che √® anche la dimensione della molteplicit√† geometrica???\n6.3.3 Moltiplicit√† geometrica ‚â§ Molteplicit√† algebrica (no chiede) 6.3.4 Diagonalizzabilit√† per somma di M-algebrica (no chiede) Si pu√≤ dimostrare che √® un sse. e deve essere che le molteplicit√† algebriche e geometriche siano entrambi uguali.\nDim-libro\n!\nAutovettori gli autovettori sono i vettori di Ax che sono nella stessa direzione di x.\nPossiamo scriverlo come $Ax = \\lambda x$ e ho che lambda √® un autovalore\nSembra che\nLa somma degli autovalori √® uguale alla somma delle diagonali Una matrice di dimensioni n n ha n autovettori Autovettori e autovalori di proiezione Nell\u0026rsquo;esempio di una proiezione, un autovettore sarebbe stato $x_{a}$ in quanto sarebbe gi√† nello spazio colonna in arrivo, quindi non viene proprio modificato.\nMa non solo questi sono degli autovettori, ma anche i vettori che sono perpendicolari (hanno autovalore 0, perch√© vengono totalmente distrutti).\nCos√¨ abbiamo trovato gli autovalori per una matrice di proiezione che sono 0 e 1\nLa ricerca di autovettori: equazione dell‚Äôautovalore Possiamo riscrivere l‚Äôequazione in questo modo:\n$$ (A - I\\lambda)x = 0 $$ Quindi stiamo cercando soluzioni nello spazio nullo di una nuova matrice, che √® interessante solamente se questa matrice √® singolare, ossia che abbia una determinante uguale a 0\nCerchiamo le soluzioni di $\\det (A - I\\lambda) = 0$ per lambda i una nuova matrice, che √® interessante solamente se questa matrice √® singolare, ossia che abbia una determinante uguale a 0\nCerchiamo le soluzioni di $\\det (A - I\\lambda) = 0$ per lambda\nThis theorem is also sometimes called the Caley-Hamilton Theorem. See this chatgpt response.\n","permalink":"https://flecart.github.io/notes/autovalori-e-autovettori/","summary":"Ha senso solamente parlare di autovettori quando si ha una applicazione lineare con stesso dominio e stesso codominio.\nVorremmo trovare una buona matrice che sia diagonale.\n6.1 Diagonalizzabilit√† 6.1.1 Definizione per funzione e matrice Questo perch√© vorrei una base in cui si abbia un matrice diagonale. (quindi probabilmente P √® una matrice identit√†).\nPerch√© ci piacciono le matrici diagonali\nSe ho una matrice diagonale, si ha che l\u0026rsquo;applicazione lineare √® un semplice scaling dei vettori della base.","title":"Autovalori e Autovettori"},{"content":"Utilizzano blocchi per cifra invece che stream generators. $n$ bits in input and $m$ bits in output generally a key is expanded into multiple keys, one for each rounds, and applied to a round function that iterates on the $m$.\nDES 56 bit 3DES 56*3 bit di chiave AES che pu√≤ andare a 128, 196 o 256 Solitamente i stream ciphers studiati in OTP and Stream Ciphers sono pi√π veloci. Cipher Speed MB/sec RC4 126 Salsa20 643 Sosemanuk 727 AES 13 3DES 109 Data Encryption Standard - 1974 da IBM su commissione di NSA (Horst Feistel designed Lucifer at IBM in early 1970) - 1976 DES is federal standard with key-len 56 bits and block-len 64 bits. in quel periodo era solamente fatta dalla intelligence, non c‚Äôera bisogno di comunicazioni per il pubblico in quel periodo.\n1977 - 1998 questo era lo standard per gli stati uniti. best studied cipher in the world! Oggi insicuro, esiste una sua variante 3DES che √® pi√π sicura, ma comunque rotto 1997 DES broken by brute force. 2000 AES replaces DES. C\u0026rsquo;√® una step di **creazione delle chiavi\nFeistel network ##### Definizione Feistel üü© Definiamo una funzione di Feistel $f(L^{i - 1}, R^{i - 1}, K^{i}) \\to L^{i}, R^{i}$ la seguente: Uno state $u^{i}$ √® diviso in due parti, che vengono cifrati in questo modo: $$\n\\begin{cases} L^{i} = R^{i - 1}\\ R^{i} = L^{i - 1} \\oplus f^{i}(R^{i - 1}, K^{i}) \\end{cases} $$ Dove $f$ √® una funzione invertibile, se si ha la chiave.\nInvertibilit√† di Feistelüü© La caratteristica bella √® che data la chiave questo √® facilmente invertibile, anche se $f$ potrebbe non esserlo. Infatti la seguente funzione inverte in modo facile $$ \\begin{cases} L^{i - 1} = R^{i} \\oplus f^{i}(L^{i}, K^{i})\\\\ R^{i - 1} = L^{i} \\end{cases} $$ Si pu√≤ verificare in modo facile che funziona questo.\nThe $f$ functions are only used in inverse order. AES does not use those.\nTheoretical result: Suppose we have a $f: K \\times \\left\\{ 0, 1 \\right\\}^{n} \\to \\left\\{ 0, 1 \\right\\}^{n}$ then a 3-round Feistel using the same $f$ at each step $F: K^{3}\\times \\left\\{ 0, 1 \\right\\}^{2n} \\to \\left\\{ 0, 1 \\right\\}^{2n}$ is a secure $PRP$ so the security is dependent on the $f$ function, which makes sense to use this function.\nFunzionamento DESüü© Quindi\nmapping iniziale $IP$ che crea $L^{0}R^{0}$ rounds di Feistel Poi output La decryption √® simmetrica con la conoscenza della chiave.\n$f$ function in DESüü® Dove $A$ √® il 32 bit plain-text e $J$ √® la chiave di $48$ bits.\nLe funzioni $S$ sono tra le pi√π importanti per la sicurezza, perch√© resistono a certi tipi di attacchi conosciuti (che se riesco metto in questi appunti qui sotto). Sono in pratica una mappa di 4 bit e 2 bit a un 4 bit: functions $S: \\left\\{ 0, 1 \\right\\}^{6} \\to \\left\\{ 0, 1 \\right\\}^{4}$. These tables are built following some design principles: **Not linear**: Suppose they are linear, aka we can write $S_{i}(x) = A_{i}x \\mod 2$. If this is happens, then it\u0026rsquo;s just shuffling and xors, and the whole cipher would be linear because composition of linear functions is linear. If the whole cipher is linear then something like $$ DES(k, m_{1}) \\oplus DES(k, m_{2}) = B \\begin{bmatrix} m_{1} \\\\ k \\end{bmatrix}\\oplus B \\begin{bmatrix} m_{2} \\\\ k \\end{bmatrix}= B\\begin{bmatrix} m_{1} \\oplus m_{2} \\\\ k \\oplus k \\end{bmatrix} $$ Another theoretical result is that if DES is linear most of the time, it would be possible to break it.\nAttacchi a DESüü© Gli attacchi maggiori (alcuni lo vengono anche come servizio commerciale) √® semplicemente bruteforce perch√© la chiave di 56 bit usata non √® che sia molto utile. (In un giorno te o rompe). Gli attacchi con known plaintext esistono, ma usano un insieme di dati non feasible. di $2^{40}$ coppie di plaintext-ciphertext.\nUnicit√† della chiaveüü©- √à notabile osservare che √® probabile sia in DES che AES che √® molto probabile che sia unica la chiave usata per cifrare quello. Questa nota √® utile per dire che se trovi quella chiave, probabilmente ti funziona anche per altre comunicazioni che utilizzano roba simile.\nSuppose DES is a ideal PRF (ideal secure cipher!?): $$ DES:\\pi_{1},\\dots \\pi_{56} \\times \\left\\{ 0, 1 \\right\\}^{64} \\to \\left\\{ 0, 1 \\right\\}^{64} $$ Th: $\\forall m, c$ there is at most one key $k$ such that $c = DES(k, m)$ with probability $\\geq 1 - \\frac{1}{256} \\approx 99.5\\%$. Proof: $$ \\mathbb{P} \\left[ \\exists k' \\neq k : c = DES(k, m) = DES(k', m) \\right] \\leq \\sum_{k' \\in \\left\\{ 0, 1 \\right\\}^{56}} \\mathbb{P}\\left[ DES(k, m) = DES(k', m) \\right] = 2^{56}\\frac{1}{2^{64}} = \\frac{1}{256} $$ Which means that the probability of having a key different from $k$ such that the encryption is the same is $1 / 256$.\nIf you do the same math for two messages we have $1 - 1 / 2^{71}$. Same thing is true for AES. This means that having one or two input pairs is enough for finding the real key.\nAltre versioni di DES Attacco a 2-DESüü© Vorremmo trovare una coppia di chiavi $k_{1}, k_{2}$ tale che per cui $E(k_{2}, m) = D(k_{1}, c)$ ed √® possibile con un meet in the middle, che dovrebbe diminuire lo spazio di ricerca. Conseguenza: Mi basta un $\u003c 2^{63}$ e space $2^{56}$ non un $2^{112}$ per rompere la chiave con questo attacco. Per questo motivo uso un 3-DES che non permette di fare questo. Ma per essere possibile questo attacco ha bisogno della coppia $M, C$ reale. Usato su 3DES abbiamo $2^{118}$ ma da una parte abbiamo il doppio.\nDESX (non impo) Wikipedia, this is not standardized, but should resist more against meet in the middle attacks. Ha key len of $184$. (Best attach is $2^{120}$.)\nConsidero tre chiavi e considero $$ k_{1} \\oplus E(k_{2}, m\\oplus k_{3}) $$ In parole semplici ho due chiavi in pi√π che uso per fare un xor prima di mandarlo in #Data Encryption standard normale. La cosa da notare √® che non cresce la complessit√† di quanto ci si aspetta.\n3-DES In modo semplice per renderlo pi√π sicuro √® il 3-DES in pratica DES applicato 3 volte, con chiave lunga il triplo, quindi pi√π resistente a brute-force.\n$$ 3E(k_{1},k_{2},k_{3}, m) = E(k_{1}, D(k_{2}, E(k_{3}, m))) $$ We add a decryption because we can implement $DES$ if we want. 3 times slower. Keysize is $2^{168}$. But attach in time $2^{118}$ is present, so 3DES is usually considered secure.\nAdvanced Encryption Standard It\u0026rsquo;s a substitution permutation network.\nNote storiche di AES Da un punto di vista storico √® stata una competizione internazionale 1997 che poi √® stata standardizzata nel 2000. Una conferenza per questo (in particolare al seconda) √® stata fatta a Roma, cosa che era curiosa, solitamente non si faceva cos√¨). √à stato scelto in base a\nSicurezza Costo implementazione Velocit√† hardware e software. (DES troppo lento e insicuro) Alla fine √® un algoritmo molto parallelizzabile. Generazione della chiaveüü®- La lunghezza della chiave decide il numero di rounds, rispettivamente 10, 12, 14. In base al fatto che usiamo 128, 192, o 256. Vedere 4.6 di (Stinson 2005). Per l\u0026rsquo;algoritmo. La cosa √® che avremo una chiave di 16 bytes in output per il numero di rounds.\nFunzionamento del cifrarioüü©- Definiamo le operazioni (inizio con 16 bytes (blocco da 128 bits)) SubBytes (byte-by-byte substitution using an S-box) ShiftRows (a permutation, which cyclically shifts the last three rows in the State) MixColumns (substitution that uses Galois Fields, GF(2^8) arithmetic) Add Round key (bit-by-bit XOR with an expanded key\nSuboperations: Is a 1 byte S-box, a 256 byte table, so it is easily computable. $$ \\forall i,j : A_{k+1}[i, j] = S[A_{k}[i,j]] $$ Con $k$ lo step.\nMix Column is a linear transformation done independently (like $\\oplus$ xor operations and similar).\nCode-size vs performance Those tables can be compressed with a code that produces that. This has trade-offs for code-size and performance, but it can be allowed to be easily stored and implemented in embedded systems (like 8-bit wrist watches).\nModes of operation Electronic Code Book (ECB) Il problema principale di questo metodo na√Øve √® il fatto che posso vedere s e blocchi hanno avuto stesso input, perch√© non dipendono dalla posizione.\nQuesto non √® semantically secure secondo note in OTP and Stream Ciphers#Semantic security (!)\nDeterministic Counter (DETCTR) In pratica creo stream di bytes a blocchi per cifrare Th: questo cipher √® semanticamente sicuro se la funzione $F$ usata √® sicura. Ossia ha un buone garanzie teoriche se esiste e trovo tale $F$.\nCipher Block Chaining (CBC) Lo conosci.\nUna nota importante √® che si pu√≤ fare una analisi teorica, e sapere dopo quanti riusi di chiave √® necessario cambiarla, al fine di mantenere garanzie di sicurezza.\nSe si guarda le slides possiamo avere un risultato, che √® circa di $2^{48}$ blocchi per CBC. Si pu√≤ fare la stessa analisi per #Data Encryption Standard (per DES √® di circa $2^{12}$ (se ho pi√π di $2^{48}$ blocchi))\nNOTA: CBC non √® sicuro con un chosen plaintext se ho la capacit√† di predire gli IV Come:\nScelgo come mio chosen-plaintext $0$ cos√¨ ho in pratica la versione criptata di $IV$. Poi mando $m_{0} = IV \\oplus IV_{2}$ e $m_{1} \\neq m_{0}$ , se $c(m_{0})$ √® uguale al primo, allora ho indovinato il messaggio. Questo chiaramente d√† advantage 1 e rompe la definizione di semantic security. Diventa sicuro solamente se $IV$ √® abbastanza randomico.\nUna possibilit√† √® usare un IV creato dalla cifrazione di un Nonce, cos√¨ sei abbastanza sicuro che IV sia sicuro.\nCounter Mode (CTR) molto simile al counter mode per #Electronic Code Book (ECB) per√≤ ora abbiamo IV. Anche in questo caso possiamo usare una nonce based version. Per nonce-CTR abbiamo un $2^{64}$ di usage blocks (solitamente pi√π sicuro, e anche pi√π veloce, quindi verr√† pi√π utilizzato). Substitution-Permutation Networks (not required for exam) 2 componenti principali Abbiamo un box di sostituzione e un box di permutazione. La stringa iniziale viene divisa in molti blocchi di lunghezza $m$, e in totale avr√† lunghezza $lm$. Con padding finale possibile. C\u0026rsquo;√® un algoritmo abbastanza generale per questo genere di cifrari, che √® il 4.1 in (Stinson 2005). la cosa carina √® che queste funzioni alla fine sono molto semplici da implementare, sia in hardware e software. Non so bene su security garantuess\nKey generation and rounds In un unico round, viene encryptato molte volte (un round √® fra 10-20 cicli di criptazione) si chiamano iterated ciphers, e dalla chiave iniziale vengono generate 16 chiavi, una per ogni round. Questo lo chiamiamo round function e la funzione che genera le chiavi per ogni round sono key schedule.\nPseudo random function Main definition A $PRF$ defined over $(K, X, Y)$ (key, input, output space) is a function $$ F: K \\times X \\to Y $$ That has an efficient algorithm to evaluate this function. We say that this is random because we are considering three spaces of random variables (so the output should be a probability distribution over possible values!?)\nPseudo random permutation Solamente una pseudorandom-function tale per cui inizio e fine sono le stesse, quindi √® bigettiva\n$PRP$ defined over $K, X$ is a $$ E: K \\times X \\to X $$ Such that\n$E$ is easy to evaluate $E$ is one-to-one $E$ is easily invertible, a function $D: K \\times X \\to X$ that is invertible knowing the key. Secure Pseudo random functions Consider the set of all functions to $X \\to Y$ as $Funs\\left[ X, Y \\right]$ of size $Y^{X}$. Consider $S_{F} = \\left\\{ F(k, \\cdot) \\text{ s.t. } k \\in K \\right\\} \\subseteq Funs\\left[ X, Y \\right]$, which has the size of the $K$ keyspace\nWe say that PRF is secure if a random function in $Funs\\left[ X, Y \\right]$ is not distinguishable (with statistical tests or similar) from $S_{F}$. This is the similar idea from previous definitions of security (advantage with statistical tests, semantic security OTP and Stream Ciphers#Security necessities for PRNGs), if this is true it means an adversary has not knowledge of the original.\nFormal definition of secure PRF We define experiments in a way similar for semantic security. $b \\in \\left\\{ 0, 1 \\right\\}^{}$ we say that if $b=0$ then a PRF is sent. if $b= 1$ is sent a truly random function from $Funs$. We say that this is secure if the adversary doesn\u0026rsquo;t have any advantage.\nSame thing for $PRP$.\nPRF -\u0026gt; PRG Let\u0026rsquo;s take a valid $PRF$ $F: K \\times \\left\\{ 0,1 \\right\\}^{n} \\to \\left\\{ 0, 1 \\right\\}^{n}$we want to show that we can generate a $G: K \\to \\left\\{ 0, 1 \\right\\}^{nt}$\nWe define $$ G(k) = F(k, 0) \\mid \\dots \\mid F(k, t) $$ This is easily parallelizable. Output of the generation of the truly random function is indistinguishable from output of pseudo-random thanks to security.\nReferences [1] Stinson ‚ÄúCryptography: Theory and Practice, Third Edition‚Äù CRC Press 2005\n","permalink":"https://flecart.github.io/notes/block-ciphers/","summary":"Utilizzano blocchi per cifra invece che stream generators. $n$ bits in input and $m$ bits in output generally a key is expanded into multiple keys, one for each rounds, and applied to a round function that iterates on the $m$.\nDES 56 bit 3DES 56*3 bit di chiave AES che pu√≤ andare a 128, 196 o 256 Solitamente i stream ciphers studiati in OTP and Stream Ciphers sono pi√π veloci. Cipher Speed MB/sec RC4 126 Salsa20 643 Sosemanuk 727 AES 13 3DES 109 Data Encryption Standard - 1974 da IBM su commissione di NSA (Horst Feistel designed Lucifer at IBM in early 1970) - 1976 DES is federal standard with key-len 56 bits and block-len 64 bits.","title":"Block Ciphers"},{"content":"Halting theorem Questo √® un problema fondamentale, che abbiamo trattato anche in Fondamenti teorica#Halting problem, ma qui lo ritrattiamo, perch√© cos√¨ lo rifacciamo per bene. In parte √® stato trattato anche al corso di Logica.\nEnunciato Halting theoremüü© Questo √® molto simile a quanto presente sul (Sipser 2012). Ossia consideriamo il linguaggio $$ HALT = \\left\\{ \\langle x, y \\rangle \\in \\Sigma^{*} \\times \\Sigma^{*}: x = code(M),M \\text{ si ferma su } x\\right\\} $$ Dimostrazione Halting theoremüü© La parte del s√¨ √® facile perch√© basta eseguirlo e vedere che si ferma (quindi abbiamo una La macchina di Turing#La macchina di Turing universale. Se si ferma appartiene al linguaggio, altrimenti √® la parte in cui diverge.\nDimostrazione non decidibilit√† Supponiamo sia decidibile e dimostriamo l\u0026rsquo;assurdo. Se esiste una macchina $f$ tale per cui decida quel linguaggio, $$ \\begin{cases} f(g, y) = 1, g(y) \\downarrow\\\\ \\\\ f(g, y) = 0, g(y) \\uparrow \\end{cases} $$ allora possiamo usare questa macchina per costruire un $h$ tale che per cui $$ \\begin{cases} h(g) = 1, f(g, g) = 0 \\\\ \\\\ h(g) = \\uparrow, f(g, g) = 1 \\end{cases} $$ Allora la computazione della funzione $h(h)$ genera un assurdo.\nIl motivo √® che $h(h) = 1 \\iff f(h, h) = 0 \\iff h(h) = \\uparrow$ Questa cosa dovrebbe essere riscritta in modo $code$ per essere comprensibile da macchine di Turing.\nOpposto di Halting theoremüü© Ossia vogliamo riconoscere il linguaggio $$ HALT^{-} = \\left\\{ \\langle x, y \\rangle : x \\not= code(M) \\cup x=code(M) \\cap M \\text{ non si ferma su } x\\right\\} $$ Si pu√≤ dimostrare che questo problema non √® nemmeno riconoscibile da nessuno!\nDimostrazione complemento di halting theoremüü© Si ragiona anche qui per assurdo, se fosse riconoscibile, avremmo che Halting theorem principale sarebbe riconoscibile.\nMapping reducibility Definizione mapping reducibilityüü© Un linguaggio $L'$ √® riducibile a un altro linguaggio $L$ se esiste una funzione computabile totale $f : \\Sigma^{*} \\to \\Sigma^{*}$ tale che valga $$ x \\in L' \\iff f(x) \\in L $$ E si scrive che $L' \\leq L$ Ossia posso mappare qualunque parola in $L'$ in una stringa in $L$. √à molto importante che sia computabile, perch√© √® un modo di dire che non stiamo barando nella dimostrazione, e mi appoggio soltanto all\u0026rsquo;espressivit√† dei due linguaggi.\nPropriet√† di decidibilit√† basilariüü© Se $L$ √® decidibile, allora $\\forall L': L'\\leq L$ √® decidibile. Se $L'$ √® indecidibile allora lo √® anche $\\forall L: L' \\leq L$ perch√© altrimenti si avrebbe un assurdo Se $L$ √® decidibile e $L'$ no allora $L' \\not \\leq L$ altrimenti assurdo per il primo punto. Ogni linguaggio decidibile √® sempliceüü®+ Ossia se $L'$ √® decidibile allora per ogni $L$ tale che $L \\neq \\emptyset$ e $L \\neq \\Sigma^{*}$, ossia √® un linguaggio finito, si ha che $$ L' \\leq L $$ In altre parole, possiamo dire che i linguaggi decidibili sono mapping reducibili a qualunque altro linguaggio non banale, quindi sono le pi√π semplici esistenti in altre parole.\nDimostrazione: Dato che $L'$ √® decidibile, esiste $g(x), \\forall x \\in \\Sigma^{*}$ tale che decide se $x$ appartiene o meno a quel linguaggio. Dato che $L$ √® finito, esiste un $\\omega$ che non appartiene e un altro $v$ che appartiene. Allora costruisco la funzione $f$ cos√¨:\nRunno $g$, se appartiene, mappo a $v$ Se non appartiene mappo a $\\omega$. Ez. Indecidibilit√† su nastro vuotoüü© NOTA: in ogni caso devo vedere se il codice della macchina √® valido.\nDefinendo il linguaggio $$ ETH = \\left\\{ x \\in \\Sigma^{*}: x = code(\\mathcal{M}) \\text{ e } \\mathcal{M} \\text{ si ferma su } \\varepsilon \\right\\} $$ Per dimostrare ci√≤ basta dimostrare che $HALT \\leq ETH$ Ossia dobbiamo costruire una funzione che mappa ogni stringa di $HALT$ in una di $ETH$. Questo √® molto semplice, solo definire qualche dettaglio (non banale) Indicibilit√† ogni inputüü© Definiamo il linguaggio $$ FL = \\left\\{ x \\in \\Sigma^{*} : x = code(\\mathcal{M}) \\text{ e } \\mathcal{M} \\text{ ferma su ogni input} \\right\\} $$ Anche questo si pu√≤ dimostrare in maniera simile al precedente, con una mapping reduction. Questo √® anche pi√π semplice: Se $\\mathcal{M}$ non √® il codice di nessuna macchina ritorno quello. Altrimenti: Per ogni input $\\langle \\mathcal{M}, x \\rangle$ costruisco la seguente macchina\nLa macchina nuova prende un input $y$, la ignora per il momento, e simula $\\langle \\mathcal{M}, x \\rangle$. Se termina (e quindi appartiene a $HALT$) allora termino anche io ignorando l\u0026rsquo;input. Altrimenti divergo, e quindi non appartengo. Questa nuova macchina √® bona. Quindi funziona l\u0026rsquo;indicibilit√† Quindi Se $\\mathcal{M}$ non √® codice ho gi√† la risposta. Altrimenti $$ \\langle y, x \\rangle \\in HALT \\iff \\text{ macchina si ferma su }x \\iff \\mathcal{M}_{\\mathcal{M}, x} \\text{ si ferma sempre} \\iff f(\\langle y,x \\rangle ) = code(\\mathcal{M}_{\\mathcal{M}, x}) \\in FL $$ Equivalence problem decidability $$ EQ = \\left\\{ \\langle y, x \\rangle \\in \\Sigma^{*} \\times \\Sigma^{*} : x = code(\\mathcal{M}), y = code(\\mathcal{M'}) \\text{ e } \\mathcal{M}, \\mathcal{M'} \\text{ hanno la stessa funzione parziale} \\right\\} $$ Anche in questo caso proviamo a ridurci al caso $FL$. Sempre come prima, per input $\\langle \\mathcal{M}\\rangle$ mi costruisco questa macchina La correttezza di questo √® un po\u0026rsquo; pi√π fine, per√≤ √® giusto. Vedere qui.\nEquivalence problem recognizabilityüü®+ Il linguaggio del problema di equivalenza non √® nemmeno riconoscibile. Per fare ci√≤ devo ridurre $HALT^{-}$ a questo EQ. Dimostro la riduzione $HALT \\implies EQ^{-}$\nNota sulla gerarchia Cosa curiosa √® che $HALT$ √® il suo opposto non sono comparabili. Mentre ci aspetteremmo che HALT sia pi√π semplice. Una altra cosa curiosa √® che EQ non √® riconoscibile, e nemmeno il suo opposto lo √®. Quindi EQ non √® nemmeno semi-decidibile. Turing riducibilit√† Definizione di oracoloüü© Dato un linguaggio $L$ e una stringa $x$, l\u0026rsquo;oracolo mi dice in tempo finito se $x \\in L$.\nDefinizione Turing-riducibilit√†üü© Dato un $L'$ , questo √® Turing riducibile a $L$, quindi $L' \\leq_{TM} L$, se dato un oracolo per $L$ possiamo decidere $L'$\nMapping reducibility =\u0026gt; Turing-riducibilit√†üü© Possiamo dimostrare in modo semplice che con Turing-riducibilit√† $HALT$ √® riducibile a $HALT^{-}$. Senza problemi. Mentre non posso farlo con Mapping reducibility. Questo mi dice che Turing riducibilit√† √® una propriet√† pi√π forte della mapping reducibility, anche se non √® propriamente una dimostrazione di questa propriet√†.\nBaker-Gill-Soloway (1975) Questa sezione √® solamente una nota filosofica, ma di poco conto per l\u0026rsquo;esame.\nPrendiamo una macchina di Turing con oracolo, ossia possiamo chiedere se una stringa √® parte dell\u0026rsquo;oracolo in tempo costante (come se fosse un dizionario con accesso diretto).\nEsistono oracoli $O, O'$ tali per cui $P = NP$ con una macchina di Turing che usi il primo oracolo, e anche che $P \\neq NP$ usando il secondo oracolo. Questo teorema dice che la tecnica di diagonalizzazione di Cantor non pu√≤ essere usata per risolvere NP = P. Questo dato √® inutile per la maggior parte delle cose attuali credo. Oppure TM non sono buoni per risolvere questo problema (ha fatto nascere la branca con i circuiti booleani, non fatta qui).\nReferences [1] Sipser ‚ÄúIntroduction to the Theory of Computation‚Äù Cengage Learning 2012\n","permalink":"https://flecart.github.io/notes/halting-theorem-and-reducibility/","summary":"Halting theorem Questo √® un problema fondamentale, che abbiamo trattato anche in Fondamenti teorica#Halting problem, ma qui lo ritrattiamo, perch√© cos√¨ lo rifacciamo per bene. In parte √® stato trattato anche al corso di Logica.\nEnunciato Halting theoremüü© Questo √® molto simile a quanto presente sul (Sipser 2012). Ossia consideriamo il linguaggio $$ HALT = \\left\\{ \\langle x, y \\rangle \\in \\Sigma^{*} \\times \\Sigma^{*}: x = code(M),M \\text{ si ferma su } x\\right\\} $$ Dimostrazione Halting theoremüü© La parte del s√¨ √® facile perch√© basta eseguirlo e vedere che si ferma (quindi abbiamo una La macchina di Turing#La macchina di Turing universale.","title":"Halting Theorem and Reducibility"},{"content":"This set of notes tries to fix what I haven\u0026rsquo;t learned in 2021 course in algebra. It\u0026rsquo;s about inner product spaces. A good online reference on the topic is wilkinson.\nDefinitions Inner product space We define the vector space $V$ to be a inner product space, if we define a inner product operator ($\\langle \\cdot, \\cdot \\rangle : V \\times V \\to R$) such that the following are valid:\nIt is linear on both arguments: $$ \\langle \\alpha x_{1} + \\beta x_{2}, y \\rangle = \\alpha \\langle x_{1}, y \\rangle + \\beta \\langle x_{2}, y \\rangle $$ It is a symmetric operator: $\\langle x, y \\rangle = \\langle y, x \\rangle$ It is positive definite that is we have $\\forall x \\in V: \\langle x, x \\rangle \\geq 0$ with equality only if $x = \\boldsymbol{0}$ An example of such operator is the classical cosine distance which is just the angle, or euclidean distance. Also all $p-\\text{norms}$ are inner products.\nOrthogonal matrixes and vectors We define two vectors $u, v$ to be orthogonal if $\\lVert u \\rVert = \\lVert v \\rVert = 1$ and if $\\langle u, v \\rangle = 0$ with respect to some inner product (clearly if we use euclidean distance, this is not much interesting, but it is for the angle).\nWe can extend this idea for matrixes: given a square matrix $n\\times n$ $Q$, it is orthogonal if the following is valid: $$ QQ^{T} = Q^{T}Q = \\boldsymbol{1}_{n} $$ Where bold 1 is the unit vector. By this definition and the uniqueness of the inverse we conclude that it is orthonormal if and only if $Q^{T} = Q^{-1}$. We observe that $q_{i}^{T}q_{j} = \\delta_{ij}$ (see Kronecker Delta).\nOnly square matrices can have inverse This easy to prove if we know this property of the trace: For all matrices $A, B$ (such that their product is a square matrix) we have that $\\text{tr}(AB) = \\text{tr}(BA)$, remember that the trace is just the sum of the diagonal: $$ tr(\\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 \\dots \u0026 a_{1n} \\\\ \\dots \\\\ a_{n 1} \u0026 \\dots \u0026 \\dots \u0026 a_{n n} \\end{bmatrix}) = \\sum_{i = 1}^{n} a_{ii} $$ This is easy to prove, so we left it to the reader (Hint: just expand the product).\nWith this in mind we can prove that if $Q$ is a $n \\times p$ matrix, it does not have an inverse by looking at its trace.\nProjections We say that a $n\\times n$ matrix $P$ is a projection if it\u0026rsquo;s multiple application is idempotent (many other interesting things are idempotent, one thing is the http protocol). Intuitively, if we project twice, we have the same vector, this definition is saying that this is the only important property to define a projection. $$ P^{2} = P $$ Now let\u0026rsquo;s study its Image and Kernel. Let\u0026rsquo;s define $U = \\text{Im}(P)$ and $V = \\text{ Ker}(P)$, and say $P: W \\to W$.\nAt the end, I don\u0026rsquo;t think this is definition is so useful because I usually don\u0026rsquo;t want the kind of applications from $n \\times n$ usually it\u0026rsquo;s more a dimensionality reduction, useful for Principal Component Analysis.\nProperties of projections Every vector of the projection can be written as sum of kernel and image It\u0026rsquo;s easy to prove if you keep in mind that $(I - P)w \\in \\text{Ker}(P)$. We can write $$ w = Iw = (I - P)w + Pw $$ Which is a vector in kernel and one in the image. This is a general property of the projections, it seems.\n$(I - P)$ is a projection matrix A curious thing is that the matrix $(I - P)$ is a projection matrix too! We can prove this easily observing that $$ (I - P)^{2} = (I-P)^{T}(I-P) = (I-P) - (P- P^{2}) = I - P $$ Another way is just observing that this projection is very similar to $P$ because they just switch the image and the kernel. $\\text{Im}(I - P) = V = \\text{Ker}(P)$ and $\\text{Ker}(I - P) = U = \\text{Im}(P)$\nOrthogonal Subspaces Let\u0026rsquo;s take a inner product space $W$ and a subspace $U$ we define the orthogonal subspace $U^{\\perp}$ to be $$ U^{\\perp} = \\left\\{ w \\in W \\mid \\langle w, u \\rangle = 0, \\forall u \\in U \\right\\} $$ This is important especially for the following theorem\nOrthogonal subspace decomposition We assert that given $w \\in W$ there are $u \\in U \\cap u' \\in U^{\\perp}$ such that $w = u + u'$. Written in another way we have $$ \\text{dim}(U) + \\text{ dim}(U^{\\perp}) = \\text{dim}(W) = n $$ Which is very similar to the kernel and image decomposition in Applicazioni lineari. (And you also have the motivation up there). This is trivial to prove when you know how to build the linear application from $W \\text{ to } U$. Let\u0026rsquo;s build it in this way: Consider $B = \\left\\{ v_{1}, \\dots, v_{n} \\right\\}$ to be the basis for $W$, then build $A$ with every row, the coordinates of the vector in $U$. When we have that $U^{\\perp} = \\left\\{ x =(x_{1}, \\dots, x_{n} \\mid Ax = 0) \\right\\}$ which is just the Kernel of the application, using the dimensionality theorem we finish.\nOrthogonal projections Def: Projection Given a inner product space $W$ with a subspace $U$, (so the operator $\\langle \\cdot, \\cdot \\rangle$ is defined and has good properties) then the orthogonal projection of $w \\in W$ is the $u \\in U$ such that $$ \\text{ minimizes the value } \\lVert w - u \\rVert $$ Which means we want to approximate the value of that vector well. We observe that the perpendicular vectors in this space is exactly the kernel of a possible projection! We have proven before that every vector is just a simple, not weighted sum of kernel and image. i.e. if $P$ is the projection matrix, with Kernel and Image defined as above, we can write every $w \\in W$ as a sum $u + v$ such that one is from the kernel and the other is from the image. We also notice that\nThe projection matrix We can explicitly build the projection matrix by knowing the basis for $U$. We have a quick derivation, that we leave as exercise. But the solution is $$ P_{u} = A(A^{T}A)^{-1}A^{T} $$ With $A$ the matrix with the coordinates in $W$ of the basis of $U$ on each column. The proof is not so difficult. But it has close connections with the MSE error and least squares estimation explained in Minimi quadrati and Linear Regression methods.\n","permalink":"https://flecart.github.io/notes/inner-product-spaces/","summary":"This set of notes tries to fix what I haven\u0026rsquo;t learned in 2021 course in algebra. It\u0026rsquo;s about inner product spaces. A good online reference on the topic is wilkinson.\nDefinitions Inner product space We define the vector space $V$ to be a inner product space, if we define a inner product operator ($\\langle \\cdot, \\cdot \\rangle : V \\times V \\to R$) such that the following are valid:\nIt is linear on both arguments: $$ \\langle \\alpha x_{1} + \\beta x_{2}, y \\rangle = \\alpha \\langle x_{1}, y \\rangle + \\beta \\langle x_{2}, y \\rangle $$ It is a symmetric operator: $\\langle x, y \\rangle = \\langle y, x \\rangle$ It is positive definite that is we have $\\forall x \\in V: \\langle x, x \\rangle \\geq 0$ with equality only if $x = \\boldsymbol{0}$ An example of such operator is the classical cosine distance which is just the angle, or euclidean distance.","title":"Inner product spaces"},{"content":"Questo √® un protocollo di sicurezza a livello Rete e non pi√π a livello socket!\nPerch√© vorremmo avere sicurezza a questo livello? √à una cosa troppo comune da dover mettere a livello superiore (ma solitamente viene messa a questo livello per la sicurezza, quindi non √® implementata ovunque per dire), quindi IPsec vuole facilitare l\u0026rsquo;implementazione dei principi CIA a un livello pi√π basso, in modo che sia flessibile e customizzabile.\nVirtual Private Networks Virtual because it doesn\u0026rsquo;t exist, it is built upon real network and private because only you can have access.\n√à una cosa molto utile per implementare cose come i VPN di aziende. Solitamente solo per questo, in altro non √® implementato perch√© √® troppo complesso, per poco di guadagno.\nNota l\u0026rsquo;imbustamento e imbustamento √® fatto nei router nell\u0026rsquo;esempio qui, ma pu√≤ essre fatto anche di computer.\nIn qualche modo, che non ho capito, lo puoi vedere come se fosse la stessa rete, perch√© l‚ÄôIP locale √® messo nell\u0026rsquo;IP sec credo, anche se non sono molto sicuro\nTypes of VPN architectures Gateway to gateway Host-to gateway Host to host The names are self explicative.\nGaranzie IPsec Tutte le caratteristiche della CIA in questo caso vengono soddisfatte, a livello subito sopra quello di rete (quindi garanzia molto buona :D) Vedi Theoretical Notions of Security, l\u0026rsquo;unica cosa non fatta a questo livello √® implementazione dell\u0026rsquo;autenticazione dell\u0026rsquo;utente, abbiamo solo sull\u0026rsquo;origine, quindi necessitiamo qualcosa di pi√π per farlo a livello dell\u0026rsquo;utente.\nIntegrit√† dei dati Confidenzialit√† Autenticazione dell‚Äôorigine (credo perch√© conoscono solamente la chiave della VPN) Prevenzione dei replay attack Con Jocelyn vengono aggiunti anche altre due\nAccess control (quindi chi pu√≤ accedere a cosa) La cosa bella di applicare la sicurezza a questo livello √® che diventa trasparente rispetto agli utilizzi da utenti non bene addestrati o applicazioni che la ignorano. In ogni caso ho le garanzie di sopra.\nTunnelling mode (2) üü© Tunneling mode Routers IPsec aware, quando sono i routers che mettono su il protocollo Questo metodo solitamente viene utilizzato per reti VPN, perch√© √® il router che si occupa di decriptare ed inoltrare a livello rete locale. Tunnel Mode SA: Protects the entire IP packet by encapsulating it within a new IP packet. Transport mode Host IPsec-aware, in modo che siano solamente gli host che siano aware, mentre i routers non sanno niente, e si comportano in modo normale in questo modo, secondo una connessione IP. Transport Mode SA: Protects the payload of IP packets, leaving the IP header intact. In questo caso viene cryptato solo il payload, viene utilizzato in host-host Security Headers - Service Models Sembra end-to-end, che dovrebbe essere una garanzia a livello trasporto, dato che alla fine solamente gli utenti finali dovrebbero ricevere il messaggio. Possono essere Authentication header (AH) oppure Encapsulation Security Protocol (ESP), la prima non fornisce la confidenzialit√†, mentre la seconda anche la confidenzialit√†. Questa √® praticamente la differenza principale.\nAH ha il vantaggio che utilizzi meno energie perch√© non devi metterti a cifrare (ESP √® sicuro con chi sta parlando, per esempio uno streaming pu√≤ far uso di AH, dato che non ho bisogno di cifrare il tutto). √à la versione pi√π comune Tunnel mode con confidenzialit√† per gli usi in VPN. In entrambi i metodi esiste un sequence number che viene utilizzato per evitare replay attacks. In entrambi c\u0026rsquo;√® un hash per l\u0026rsquo;integrit√†.\nSecurity Association(4)üü®+ Security Association (SA): A set of parameters that define the security services and mechanisms for protecting communication between two network entities. Purpose: Establishes shared security attributes to secure data exchange, ensuring confidentiality, integrity, and authenticity. Prima di mettermi a scambiare messaggi, devo essere sicuro con chi sto parlando, quindi vogliamo andare a creare una security association, scambio di chiavi e algoritmi di criptazione comune, solo da una direzione verso l\u0026rsquo;altra. I due parametri SPI e l\u0026rsquo;IP di destinazione identificano una SA in modo univoco. Poi ci sono parametri che vanno ad identificare cose come tipologia di cifrario utilizzato, o tipologia di algoritmo utilizzato per l\u0026rsquo;integrit√†. Tutte le associations dovrebbero usare sequence numbers per evitare replay attacks.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 25.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 25\u0026quot;\u0026gt; Security association parameters Uses usually three parameters\nSecurity Parameter Index (32 bit) √® un identificatore della SA. IP destination e sorgente Identifier of the security protocol (ESP or AH). Altre chiavi di codifica e decodifica. Security Association Database Posso anche creare un database di SA questo si chiama SAD\nC‚Äô√® una security associazione fra tunnel e ogni host\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Sicurezza delle reti/Untitled 26.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Sicurezza delle reti/Untitled 26\u0026quot;\u0026gt; Cose che vengono memorizzate qui sono:\nIdentificatore di SA, SPI Chiavi di cifratura e algo di cifratura Interfaccia di inizio e arrivo della SA MAC e chiave di MAC Establishing a SA This is somewhat similar to SSL, because they first need to negotiate security parameters.\nInitiation: A request is made to establish a secure communication channel. Negotiation: Parameters such as encryption methods and keys are negotiated (e.g., via IKE). Creation: An SA is created with the agreed-upon parameters and stored in the SAD. Maintenance: SAs are monitored and periodically re-negotiated before expiration. IPsec Datagram üü® Si noti che anche il pacchetto di livello trasporto √® cifrato, quindi anche l\u0026rsquo;indirizzo di porta e l\u0026rsquo;indirizzo IP finale dovr√† essere cifrato\nIl modo con cui queste vengono programmate √® attraverso alcune regole del router (che controllano se il datagramma va verso certi host, oppure parte da certi host e simili).\nKey Determination Protocol Quello che viene usato in questo caso √® chiamato IKEv2. Che √® una versione di Diffie-Hellman in Key Exchange protocols. Ma risolve i problemi di Man in the middle, autenticando le due parti. E risolve anche problemi di denial of service dovuti al costo di computazione di diffie-hellman. Per il problema di flooding usano delle specie di cookie autenticati, che sono creati da chi vuole comunicare (firmati da questi diciamo). Poi usano un cifrario a chiave asymmetric come curve ellittiche o RSA\nIKEv2 Questo √® un protocollo di scambio chiavi, per certi versi simile a Diffie Hellman spiegato in Key Exchange protocols.\nAbbiamo sempre Alice e Bob, rispettivamente chiave privata $a, b$ con gruppo $g$, primo $p$, e modulo messo d\u0026rsquo;accordo. Poi si scambiano come da consuetudine $g^{a} \\mod p, N_{a}$ da $A \\to B$ e uguale e contrario da $B \\to A$. La chiave segreta sar√† $K = f(g^{ab} \\mod p, N_{a}, N_{b}$ e poi altra roba di integrit√† che non ho capito. Dovrei descriverlo meglio.\nIKE contenders Photuris SKIP ISAKMP TODO: approfondisci cosa sono queste. Why IPsec is not used Complexity in its setup (una cosa √® spesso √® molto lento perch√© richiede molti scambi, ha un overhead grosso). Bad compatibility with NAT (needs to know IP-port pair to route the packet) Application level security is often easier to implement ","permalink":"https://flecart.github.io/notes/ipsec-protocol/","summary":"Questo √® un protocollo di sicurezza a livello Rete e non pi√π a livello socket!\nPerch√© vorremmo avere sicurezza a questo livello? √à una cosa troppo comune da dover mettere a livello superiore (ma solitamente viene messa a questo livello per la sicurezza, quindi non √® implementata ovunque per dire), quindi IPsec vuole facilitare l\u0026rsquo;implementazione dei principi CIA a un livello pi√π basso, in modo che sia flessibile e customizzabile.","title":"IPSec protocol"},{"content":"Recurrent Neural Networks allows us to model arbitrarily long sequence dependencies, at least in theory. This is very handy, and has many interesting theoretical implication. But here we are also interested in the practical applicability, so we may need to analyze common architectures used to implement these models, the main limitation and drawbacks, the nice properties and some applications.\nA simple theoretical motivation Recall the content presented in Language Models (this is a hard prerequisite): we want an efficient way to model $p(y \\mid \\boldsymbol{y}_{","permalink":"https://flecart.github.io/notes/recurrent-neural-networks/","summary":"Recurrent Neural Networks allows us to model arbitrarily long sequence dependencies, at least in theory. This is very handy, and has many interesting theoretical implication. But here we are also interested in the practical applicability, so we may need to analyze common architectures used to implement these models, the main limitation and drawbacks, the nice properties and some applications.\nA simple theoretical motivation Recall the content presented in Language Models (this is a hard prerequisite): we want an efficient way to model $p(y \\mid \\boldsymbol{y}_{","title":"Recurrent Neural Networks"},{"content":"Bounds Markov Bound Questo bound √® abbastanza banale se fatto da un punto di vista grafico, comunque afferma che $$ P(X \\geq y) \\leq \\frac{E[X]}{y} $$ Il motivo √® che $$ yP(X \\geq y) = y\\int _{x =y}^{+\\infty} f(x) \\, dx \\leq \\int _{x=y}^{+\\infty} x f(x) \\, d \\leq \\int _{-\\infty}^{+\\infty}xf(x) \\, d = E[X] $$ Il che finisce la dimostrazione.\nChebychev Bound Questa √® una conseguenza abbastanza diretta sul bound precedente: Afferma che $$ P(\\mid x - E[X] \\mid \\geq y) \\leq \\frac{\\sigma^{2}}{y^{2}} $$ E in pratica dice che all\u0026rsquo;infinito viene tutto compattata sul valore atteso La dimostrazione √® abbastanza semplice, si sostituisce $(x - E[X])^{2}$ su $X$ di Markov e $\\varepsilon^{2}$ a $y$ e poi si dovrebbe gi√† avere il risultato\nChernoff Bound Moments of random variable https://en.wikipedia.org/wiki/Moment-generating_function Per capire il significato di questo bound invece, √® necessario prima capire cosa sia un moment generating function. √à una funzione generale che crea i momenti di una variabile aleatoria. Un momento per una variabile aleatoria √® descrivibile come n-esimo momento: $E[X^{n}]$ La funzione generatrice dei momenti √® describile come: $$ M_{X}(\\lambda) = E[\\exp(\\lambda X)] $$ Il motivo per cui vale, √® che con l\u0026rsquo;espansione di taylor, vedi Hopital, Taylor, Peano Possiamo estrarre in modo abbastanza semplice i momenti: Infatti: $$ e^{tX} = 1 + tX + \\frac{t^{2}X^{2}}{2!} + \\frac{t^{3}X^{3}}{3!} + \\dots $$ Quindi per esempio se volessimo il primo momento, prendiamo la derivata rispetto a $t$e settiamo $t=0$, perch√© la cosa molto bella √® che i coefficienti si cancellano tutti, e l\u0026rsquo;unico termine che rimane senza $t$ √® il momento cercato, per questo motivo estraiamo easy i momenti.\nDimostrazione Chernoff\u0026rsquo;s Bound Anche questa √® una conseguenza abbastanza immediata di Markov, viene affermato che $$ P(Z \\geq t) \\leq \\inf_{s \u003e 0} e^{-st} M_{Z}(s) = \\inf_{s \u003e 0} e^{-st} E[e^{sZ}] $$ Guardandolo dall\u0026rsquo;altro in basso non ho idea del perch√© valga.\nLa dimostrazione avviene cos√¨ $$ P(Z \\geq t) = P(e^{sZ} \\geq e^{st}) \\leq \\frac{E[e^{sZ}]}{e^{st}} $$ Dove $s$ √® qualunque $s \u003e 0$ perch√© per quello la funzione resta crescente, e quindi la dimostrazione vale ancora. La cosa interessante di questo bound √® che la probabilit√† che succeda scende in modo esponenziale.\nHoeffding\u0026rsquo;s Inequality L\u0026rsquo;enunciato √® che se considero la somma delle classiche variabili aleatorie con stessa media varianza $S_{n}$ allora vale che, tale per cui con probabilit√† $1$ vale che $a_{i} \\leq X_{i} \\leq b_{i}$ $$ P(\\lvert S_{n} - \\mathbf{E}[S_{n}] \\rvert \\geq t) \\leq e^{-2t^{2}/\\sum(b_{i} - a_{i})^{2} } $$ Questo ci dice quanto velocemente la media converge nel valore atteso che ci aspettiamo per la legge dei grandi numeri\nLa dimostrazione di questo mi sembra abbastanza tecnica, c\u0026rsquo;√® bisogno di guardare https://web.eecs.umich.edu/~cscott/past_courses/eecs598w14/notes/03_hoeffding.pdf Oppure https://cs229.stanford.edu/extra-notes/hoeffding.pdf.\nNon ho bene capito l\u0026rsquo;utilit√† se non nel caso Bernoulliano in cui sembra si semplifichi abbastanza questo.\nLaw of Large numbers Weak Law La dimostrazione di questo √® molto semplice, basta avere Chebicheff\nQuesta √® l\u0026rsquo;intuizione di quanto presente nell WLLN Abbiamo mean square convergence.\nAbbiamo che vale:\n$$ \\mathbb{P}\\left( \\left( \\frac{S_{n} - n\\bar{X}}{n} \\right)^{2} \u003e y \\right) \\leq \\frac{\\sigma^{2}_{X}}{ny} $$ E poi settando $y = \\varepsilon^{2}$ si pu√≤ avere il risultato. Nella forma corretta. Vedere capitolo 1.5 in questo.\nSi pu√≤ scrivere: $$ \\lim_{ n \\to \\infty } E \\left[ \\left( \\frac{S_{n}}{n} - \\bar{X} \\right)^{2} \\right] = 0 $$ In questo senso possiamo dire che la successione $S_{n}$ arriver√† sempre alla media.\nRicordiamo che $S_{n} = X_{1} + X_{2} + \\dots + X_{n}$. Dove tutte le variabili $X_{i}$ sono IID con media $\\bar{X}$ e varianza $\\sigma^{2}$.\nWeak law without finite variance Potremo scrivere $$ \\lim_{ n \\to \\infty } \\mathbb{P}\\left( \\mid \\frac{S_{n}}{n} - E[X]\\mid \u003e \\varepsilon \\right) = 0 $$ Teorema 1.5.3 nelle note.\nConvergence types Per qualche motivo che non ho ancora capito √® importante andare a distinguere tipologie di convergenza diverse fra di loro.\nConvergence in distribution Una sequenza di variabili aleatorie $Z_{1}, Z_{2}, \\dots$ converge in distribuzione se vale $$ \\lim_{ n \\to \\infty } F_{Z_{n}}(z) = F_{Z}(z) $$ Per ogni $z$ in cui $F_{Z}(z)$ √® continua. Una sequenza di distribuzioni che converge a una distribuzione. Un esempio in cui questo vale √® il central limit theorem in cui definiamo $$ Z_{n} = \\frac{S_{n} -n\\bar{X}}{\\sigma \\sqrt{ n }} $$ Converge alla normale, 0, 1 gaussiana. Un altro esempio √® la weak law of large numbers, in cui $\\frac{S_{n}}{n}$ converge a $\\bar{X}$.\nConvergence in probability Se prendiamo una sequenza $Z_{1}, Z_{2}, \\dots$ a $Z$ se vale $$ \\lim_{ n \\to \\infty } P(\\mid Z_{n} - Z\\mid \u003e \\varepsilon) = 0 $$ Vale anche qui l\u0026rsquo;esempio della WLLN.\nConvergence in mean square Una sequenza di $Z_{1}, Z_{2}, \\dots$ converge in mean square a $Z$ se vale $$ \\lim_{ n \\to \\infty } E[(Z_{n} - Z)^{2}] = 0 $$ La nota √® che Mean Square -\u0026gt; Convergence probability -\u0026gt; Convergence in distribution.\nConvergence almost everywhere (Il prof. lo chiama with probability 1 e secondo lui serve sapere measure theory per poter comprendere la definizione originale).\nDefiniamo una sequenza $Z_{1}, Z_{2}, \\dots$ e $\\Omega$ il suo spazio campionatorio e sia $Z$ una altra variabile aleatoria, allora la sequenza converge con probabilit√† 1 se vale\n$$ \\mathbb{P}(\\{\\omega \\in \\Omega : \\lim_{ n \\to \\infty }Z_{n}(\\omega) = Z(\\omega) \\}) = 1 $$ Ossia, per definizione di variabile aleatoria $Z_{n}(\\omega)$ √® un valore reale, queste sequenze di numeri reali a volte convergono, se convergono vogliamo che il valore sia esattamente $Z(\\omega)$. Quello che vogliamo dire con questo √® che la probabilit√† degli elementi dello spazio campionatorio che creano sequenze che convergono √® uguale a 1.\nThe strong Law Central Limit Theorem The Bernoulli Case The theorem $$ \\lim_{ n \\to \\infty } \\left[ \\mathbb{P}\\left( \\frac{S_{n} - n\\bar{X}}{\\sqrt{ n }\\sigma} \\leq y \\right)\\right] = \\int_{-\\infty}^{y} \\frac{1}{\\sqrt{ 2\\pi }} \\exp\\left( -\\frac{x^{2}}{2} \\right) \\, dx $$ Ossia che la sequenza di variabili aleatorie $$ Z_{i} = \\frac{S_{i} - n\\bar{X}}{\\sqrt{i} \\sigma} $$ Converger√† alla gaussiana normale. √à un motivo per cui √® una distribuzione molto importante.\n","permalink":"https://flecart.github.io/notes/central-limit-theorem-and-law-of-large-numbers/","summary":"Bounds Markov Bound Questo bound √® abbastanza banale se fatto da un punto di vista grafico, comunque afferma che $$ P(X \\geq y) \\leq \\frac{E[X]}{y} $$ Il motivo √® che $$ yP(X \\geq y) = y\\int _{x =y}^{+\\infty} f(x) \\, dx \\leq \\int _{x=y}^{+\\infty} x f(x) \\, d \\leq \\int _{-\\infty}^{+\\infty}xf(x) \\, d = E[X] $$ Il che finisce la dimostrazione.\nChebychev Bound Questa √® una conseguenza abbastanza diretta sul bound precedente: Afferma che $$ P(\\mid x - E[X] \\mid \\geq y) \\leq \\frac{\\sigma^{2}}{y^{2}} $$ E in pratica dice che all\u0026rsquo;infinito viene tutto compattata sul valore atteso La dimostrazione √® abbastanza semplice, si sostituisce $(x - E[X])^{2}$ su $X$ di Markov e $\\varepsilon^{2}$ a $y$ e poi si dovrebbe gi√† avere il risultato","title":"Central Limit Theorem and Law of Large Numbers"},{"content":"How can we transform a uniform into a random variable? It is true that we have $$ F(x) = \\int _{-\\infty}^{x} f(t) \\, dt $$ A volte la densit√† non √® definita, mentre la funzione cumulativa lo √® , per questo spesso cominciamo a definire partendo dalla definizione.\nSuppose we have a $x \\sim F_{X}(x)$ where $F$ is a cumulative distribution function, same thing, we just need to take the set, normal cumulative distribution function that we saw a lot in other courses. $$ F_{X}(x) = \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^{x} f_{X}(z) \\, dz $$ Generalized inverse Definition We want to have an inverse of the cdf, but i don\u0026rsquo;t know why. By some definition the transformation is still a random variable. The definition of the generalized inverse is: $$ F_{X}^{-1}(u) = inf \\left\\{ x; F_{X}(x) \\geq u \\right\\} $$ This has sense because we know that the inverse is a continuous function (we do or not?). This is useful because when we have a cumulative probability distribution this allows to recreate the original random variable distribution, and it\u0026rsquo;s quite easy to get it in this way.\nProbability Inverse transform Sample from $X$ when it\u0026rsquo;s difficult to sample from that distribution (for example function difficult to calculate?, Difficult to implement function?)\nRequirements:\nI know the functional form of $F_{X}(x)$ $X$ in continuous. For the exam you will be given the cumulative distribution and you need to use this theorem to sample\nTheorem The inverse distribution the cumulative of the uniform distribution is the same for that random variable $$ U \\sim F_{X}(x) \\iff \\mathbb{P}(Y \\leq x) =X $$ Where $Y = F_{X}^{-1}(U)$ this is just the definition of the cumulative function, the catch is the ???\n$F_{X}(u)$ is continuous then it is invertible If $U \\sim Unif(0, 1)$ then the c.d.f is easy, and it\u0026rsquo;s equal to $$ u \\in \\left[ 0, 1 \\right]: F_{U}(u) = \\begin{cases} 0, u \\leq 0 \\\\ u, 0\\leq u\\leq 1 \\\\ 1, u \\leq 1 \\end{cases} $$ And this is easy. This is proved to be the only distribution with this property, that the CDF is an identify $F_{X}(X) = U$ this is also called PIT See here for proof (it\u0026rsquo;s cool) Proof 1 $$ \\mathbb{P}(F_{X}^{-1}(U) \\leq x) = \\mathbb{P}(F_{X}\\left[ F_{X}^{-1}(U) \\right] \\leq F_{X}(x)) = \\mathbb{P}(U \\leq F_{X}(x)) = F_{U}[F_{X}(x)] = F_{X}(x) $$ In the first passage we used that the cumulative distribution function is monotonically increasing, in the second a clear property for the inverse, and at the end we used a property of the cumulative uniform distribution.\nProof 2 Proof of the same fact, so we have: Proof of the point 3. $$ U = F_{U}(u) = \\mathbb{P}(U \\leq u) = \\mathbb{P}(F_{X}(X) \\leq F_{X}(x)) = \\mathbb{P}(F_{X}^{-1}(F_{X}(X)) \\leq F_{X}^{-1}(F_{X}(x)) ) = \\mathbb{P}(X \\leq x) = F_{X}(x) $$ After you have this you can just use the inverse -\u0026gt; $$ F_{X}^{-1}(U) = X $$ So now you can sample.\nExample of application $$ X \\sim Exp(\\lambda = 1) $$ And given $F_{X}(x) = 1 - e^{-x}$, with $x \\in \\mathbb{R}^{+} \\cup \\left\\{ 0 \\right\\}$ Find the value of $X$ random variable.\nSolution example:\n$F_{X}(X) = U$, then set up the equation and solve $$ 1 - e^{-X} = U \\implies e^{-X} = 1 - U \\implies X = -\\log (1 - U) $$ We can notice that $1 - U$ and $U$ are both uniform distribution, so the above is the same as $X = -\\log(U)$ And in this way you get the correct random variable. Now we can sample from the uniform and get the correct result! -\u0026gt; Direct transformation method. With this process we prooved that $-\\log U \\sim Exp(\\lambda = 1)$ Famous function CDF Logistic function This is a function very similar to that used in Logistic Regression. We have $X \\sim \\text{Logistic}(\\mu ; \\beta)$, then $$ F_{X}(x) = \\frac{1}{1 + e^{-(x - \\mu)/\\beta}} $$ Let\u0026rsquo;s make the derivation: $$ U = F_{X}(X) = \\frac{1}{1 + e^{-(X - \\mu)/\\beta}} \\implies 1 + e^{-(X - \\mu)/\\beta} = \\frac{1}{U} \\implies -(X - \\mu)/\\beta = \\log(\\frac{1}{U} - 1) $$ $$ \\implies X = -\\beta \\log\\left( \\frac{1}{U} - 1 \\right) + \\mu $$ Where $\\beta$ and $\\mu$ are parameters of the distribution.\nCauchy distribution How to simulate data from a Cauchy distribution? $$ F_{X}(x) = \\frac{1}{2} + \\frac{1}{\\pi}\\arctan((x - \\mu) / \\sigma) $$ The derivation $$ U = F_{X}(X) = \\frac{1}{2} + \\frac{1}{\\pi}\\arctan((X - \\mu) / \\sigma) \\implies \\tan(\\pi\\left( U - \\frac{1}{2} \\right)) = (X - \\mu)/\\sigma \\implies X = \\sigma \\cdot \\tan(\\pi\\left( U - \\frac{1}{2} \\right)) + \\mu $$ So also in this case we have a way to sample a Cauchy distribution by just manipulating a uniform distribution.\nHow for the Gaussian? $$ \\Phi(x) = \\int _{-\\infty}^{x}f_{X}(z) \\, dz \\int _{-\\infty}^{x} \\frac{1}{\\sqrt{ 2\\pi } \\sigma^{2}} \\exp \\left\\{ - \\frac{(z - \\mu)^{2}}{2\\sigma^{2}} \\right\\} \\, dz $$ Doesn\u0026rsquo;t have a clear evaluation function because it\u0026rsquo;s difficult, in R it uses the Probability inverse transform.\nEmpirical C.D.F The definition is simple:, if we have a i.i.d. sample $$ (X_{1}, \\dots, X_{n}) : \\hat{F}_{X, m}(x) = \\frac{1}{n} \\cdot \\sum_{i = 1}^{n} \\mathbb{1}(X_{i} \\leq x) $$ It\u0026rsquo;s just the sum of all the sampled data that is lower than a certain value! (unbiased, on average, the emprirical cdf we have the right cdf!).\nOther famous distributions Chi squared distribution math exchange\nif we have $X_{i} \\sim Exp(1)$ then it is true that $$ Y = 2 \\sum_{i = 1}^{n}X_{i} \\sim \\chi^{2}_{2n} $$ Where $n$ is the degrees of freedom, bad thing is that this usually just even, so useful for that. (chi square gamma distribution)\n$$ Y = \\beta \\sum_{i= 1}^{n} X_{i} \\sim G(a, \\beta) : a \\in \\mathbb{N}^{*} $$ Which is a Gamma distribution, exponential is special case of gamma? $$ Y = \\frac{\\sum_{i=1}^{a} X_{i}}{\\sum_{i = 1}^{a + b} X_{i}} \\sim Be(a, b) $$ Which is a Beta regression, used for microbiome in the guts, I don\u0026rsquo;t know why.\nTransformation of random variables (no exam) La cosa strana per questi statistici e che non si capisce per quale fine stiamo facendo queste trasformazioni, che non sono molto utili a primo impatto. Nel senso che non so nemmeno quale sia il problema che stiamo provando a risolvere!\nSuppose $X \\sim f_{X}(x)$, and $Z= g(X)$ with $g$ an invertible function, then suppose $Z \\sim f_{Z}(z)$ Then the support of the density is in $X$ , we have that $$ f_{Z}(z) = \\frac{\\delta F_{Z}(z)}{\\delta z} = f_{X}\\left[ g^{-1}(z) \\right] \\cdot \\frac{\\delta g^{-1}(z)}{\\delta z} $$ Non so esattamente cosa mi possa servire questo e non so nemmeno perch√© funziona. Dopo: alla fine la dimostrazione di questo √® molto semplice (io sono un po\u0026rsquo; incapace nelle dimo a quanto pare e tendo ad impararle a memoria) Comunque lo trovi in https://en.wikipedia.org/wiki/Random_variable\nUniform random variable Permette la creazione di uniform tale per cui non siano sempre nel classico 0, 1 $$ U\\sim Unif(0, 1) \\implies f_{U}(u) = \\begin{cases} 0 : u \\not\\in \\left[ 0, 1 \\right] \\\\ 1 : u \\in \\left[ 0, 1 \\right] \\end{cases} $$ Allora la trasformazione sarebbe: $$ X = (b - a)U + a , \\, b \u003e a $$ Then $$ U = \\frac{x - a}{b - a} = g^{-1}(X) \\implies \\frac{\\delta g^{-1}(X)}{\\delta x} = \\frac{1}{b-a} \\implies f_{X}(x) = f_{U} \\left[ \\frac{x- a}{b - a} \\right] \\cdot \\frac{1}{b - a} $$ and we have that $f_{U}$ is in $\\left[ 0, 1 \\right]$ when we need to have $x \\geq a \\land x \\leq b$ in order to have a density different than 0. $$\n$$\nStandard Gaussian $X \\sim N(\\mu, \\sigma^{2})$ then $Z = (X - \\mu) / \\sigma$ . Which is closed under linear transformations! and $X = g^{-1}(Z) = \\sigma \\cdot Z + \\mu$ Then: $$ f_{Z}(z) = f_{X}(\\sigma z + \\mu) \\sigma = \\frac{1}{\\sqrt{ 2\\pi }} \\exp \\left\\{ - \\frac{Z^{2}}{2} \\right\\} $$ Where the first part is the density of a Gaussian\nBox-Muller algorithm (no exam) https://blog.cupcakephysics.com/computational%20physics/2015/05/10/the-box-muller-algorithm.html https://math.nyu.edu/~goodman/teaching/MonteCarlo2005/notes/GaussianSampling.pdf\nThis algorithm is used to produce Gaussian random variables: we have $U_{1}$ and $U_{2}$ that are normal uniform, then we can take $$ X_{1} = \\sqrt{ -2 \\log(U_{1}) } \\cos(2\\pi U_{2}), X_{2} = \\sqrt{ -2 \\log(U_{2}) } \\sin(2\\pi U_{1}), $$ Without any approximation, it is exact for some reason\nMultivariate cases We can use the re-parametrization trick to gen $N(\\mu, \\sigma^{2})$ just multiplying by the variance and add the mean. We are asking if we can do the same even for the multivariate case, how can we get $N_{p}(\\mu, \\Sigma)$ ? Let\u0026rsquo;s take a bi-variate Gaussian for example. It seems like a result that we have that the square root of a matrix is almost the same as a Cholesky decomposition. That will be our sigma. it\u0026rsquo;s always possible because we have a positive definite symmetric matrix for the Sigma. See Algebra lineare numerica for cholesky\nThe discrete case Vogliamo andare a prendere molte probabilit√† in questo modo $$ p_{0} = P_{\\theta}(X \\leq 0) , p_{1} = P_{\\theta}(X \\leq 1) e via $$ √à sempre come conoscere una CDF discreta. Poi prendiamo $$ X = k, p_{k-1} \\leq U \\leq p_{k} $$ e cos√¨ facciamo sampling della variabile per le distribuzioni discrete $X$\nAltre cose ","permalink":"https://flecart.github.io/notes/inverse-transform/","summary":"How can we transform a uniform into a random variable? It is true that we have $$ F(x) = \\int _{-\\infty}^{x} f(t) \\, dt $$ A volte la densit√† non √® definita, mentre la funzione cumulativa lo √® , per questo spesso cominciamo a definire partendo dalla definizione.\nSuppose we have a $x \\sim F_{X}(x)$ where $F$ is a cumulative distribution function, same thing, we just need to take the set, normal cumulative distribution function that we saw a lot in other courses.","title":"Inverse Transform"},{"content":"Gli isomorfismi sono delle propriet√† fondamentali per stabilire una sorta di equivalenza fra i gruppi. Utilizziamo questi isomorfismi per parlare della stessa cosa ma in modi diversi.\n3.1 Introduzione 3.1.1 Definizione Un gruppo si dice isomorfo rispetto ad un altro gruppo se, in paroloni semplici, esiste una funzione bigettiva tale che preservi l\u0026rsquo;operazione del gruppo.\nIn altre parole\n$$ \\phi:A \\to B,\\phi(ab) = \\phi(a)\\phi(b) $$ 3.1.2 Step di dimostrazione Esiste un modo preciso per dimostrare se due gruppi sono isomorfi. In particolare:\nTrovare la funzione per l\u0026rsquo;isomorfismo Dimostrare che √® iniettiva Dimostrare che √® suriettiva Dimostrare che preserva la struttura del gruppo 3.2 Ogni gruppo √® in isomorfismo con un gruppo di permutazione Questo √® uno dei teoremi principali per classificare i gruppi\nDimostrazione (left cosets as permutation groups)\n3.2.1 Note storiche su questo teorema Storicamente parlando si √® iniziati a studiare la teoria dei gruppi dal punto di vista delle permutazioni, questo teorema √® ci√≤ che ha permesso una maggiore astrazione rispetto al concreto gruppi delle permutazioni, permettendo lo sviluppo di questo campo in modo tale.\n3.3 Propriet√† dell\u0026rsquo;isomorfismo sugli elementi Abbiamo una unica slide che riassume tutte le propriet√†. Non dovrebbe essere molto difficile dimostrare il tutto.\n3.3.1 Preservazione dell‚Äôelemento neutro 3.3.2 Preservazione della potenza 3.3.3 Coimplica la commutativit√† 3.3.4 Coimplica la ciclicit√† 3.3.5 Stesso ordine 3.3.6 Preservazione del n_sol per equazioni del gruppo 3.3.7 Preservazione dell‚Äôordine degli elementi 3.4 Propriet√† dell‚Äôisomorfismo sui gruppi 3.4.1 La funzione inversa √® un isomorfismo 3.4.2 Coimplica abelianit√† 3.4.3 Coimplica la ciclicit√† 3.4.4 L\u0026rsquo;immagine di un sottogruppo √® un sottogruppo (del gruppo di arrivo) 3.5 Automorfismi 3.5.1 Definizione Un automorfismo di gruppo √® solamente un isomorfismo con una funzione che parte da s√© ed arriva a s√© stesso.\nUn esempio di automorfismo √® la permutazione (che mi scambia gli elementi, ma alla fine √® una funzione da s√© in s√©).\n3.5.2 Automorfismo interno L\u0026rsquo;automorfismo interno rispetto a un gruppo √® una specie di congiunzione:\n$G_a(x) = axa^{-1}$ si pu√≤ dimostrare che questo √® effettivamente un isomorfismo.\n3.5.3 Aut(Zn) ha stesso ordine di U(n) Gli unici isomorfismi di Zn a se stesso sono gli elementi che sono coprimi con zn, in quanto solo questi possono generare l\u0026rsquo;intero gruppo (ed essere generatore quindi\u0026hellip;) Questo √® lo stesso numero di elementi con U(n). Ad alto livello √® questo √® il motivo per cui vale questo teorema.\nDimostrazione\n!\n","permalink":"https://flecart.github.io/notes/isomorfismi/","summary":"Gli isomorfismi sono delle propriet√† fondamentali per stabilire una sorta di equivalenza fra i gruppi. Utilizziamo questi isomorfismi per parlare della stessa cosa ma in modi diversi.\n3.1 Introduzione 3.1.1 Definizione Un gruppo si dice isomorfo rispetto ad un altro gruppo se, in paroloni semplici, esiste una funzione bigettiva tale che preservi l\u0026rsquo;operazione del gruppo.\nIn altre parole\n$$ \\phi:A \\to B,\\phi(ab) = \\phi(a)\\phi(b) $$ 3.1.2 Step di dimostrazione Esiste un modo preciso per dimostrare se due gruppi sono isomorfi.","title":"Isomorfismi"},{"content":"DI Law of Large Numbers e Central limit theorem ne parliamo in Central Limit Theorem and Law of Large Numbers. Usually these methods are useful when you need to calculate following something similar to Bayes rule, but don\u0026rsquo;t know how to calculate the denominator, often infeasible integral. We estimate this value without explicitly calculating that.\nInterested in $\\mathbb{P}(x) = \\frac{1}{z} \\mathbb{P}^{*}(x) = \\frac{1}{Z} e^{-E(x)}$ Can evaluate E(x) at any x.\nProblem 1 Make samples x(r) ~ 2 P Problem 2 Estimate expectations $\\Phi = \\sum_{x}\\phi(x)\\mathbb{P}(x)$) What we\u0026rsquo;re not trying to do: We\u0026rsquo;re not trying to find the most probable state. We\u0026rsquo;re not trying to visit all typical states. Law of large numbers Data una sequenza di variabili aleatorie, $X_{1}, X_{2}, \\dots, X_{n}\\dots$, tali che siano i.i.d tali per cui $E(X_{1}) = E(X_{2}) = \\dots = E(X_{n}) =\\dots = \\mu$ tale che sia finito. Consideriamo $$ S_{n} = \\sum^n_{i=1} x_{i} ,:, \\bar{x}_{n} = \\frac{S_{n}}{n} $$ Allora questo teorema afferma che: $$ \\bar{x}_{n} \\to \\mu $$ Ossia il limite converge sul valore atteso di tutte le variabili aleatorie.\nInoltre se abbiamo che la varianza di tutte le variabili aleatorie, abbiamo che $$ var(\\hat{x}_{n}) = \\frac{\\sigma^{2}}{n} \\to 0 $$ Strong Law of large Numbers $$ \\mathbb{P}(\\lim_{ n \\to \\infty } \\bar{x}_{n} =\\mu) = 1 $$ Ci permette di prendere la sample average per quei valori di mezzo. E posso fare la stima della nostra funzione di interesse $h$ tenendo conto: $$ \\bar{h}_{n} = \\sum_{i=1}^{n} \\frac{h(x_{i})}{n} $$ E questo converge $O(\\sqrt{ n })$ per la legge dopo.\nCentral limit theorem Data una sequenza di variabili aleatorie, $X_{1}, X_{2}, \\dots, X_{n}\\dots$, tali che siano i.i.d tali per cui $E(X_{1}) = E(X_{2}) = \\dots = E(X_{n}) =\\dots = \\mu$ tale che sia finito, e con varianza tutti uguali $= \\sigma^{2}$ finito.\nAbbiamo come risultato che $$ \\sqrt{ n } (\\hat{x}_{n} - \\mu) \\to N(0, \\sigma^{2}) $$ La prima parte √® una variabile aleatoria e converge a quel valore. (questo permette di utilizzare la gaussiana quando $n$ √® grande abbastanza).\nMonte carlo integration Abbiamo che: $$ \\int_{X} h(x) \\cdot f(x) dx = E_{f}[h(x)] = \\mu $$ Questo √® tutto il significato dell\u0026rsquo;integrazione di monte carlo (molte variabili aleatorie per stimare il valore di qualcosa). E questo vale sempre, anche se $f$ non √® una funzione di densit√†, basta che sia positiva (basta riscalare).\nIl motivo per cui funziona √® per LLN, perch√© abbiamo che converger√† su $\\mu$ in lungo termine, basta considerare molte variabili aleatorie consecutive.\nCose interessanti:\nPosso stimare il valore atteso grazie a LLN Posso stimare la varianza grazie ad essa Posso stimare variabili condizionali. Importance sampling Deve soddisfare la cosa del supporto (contiene supporto sia di h che di f) Deve avere varianza finita per i pesi che sono trovati. (ci sono metodi per stimare poi il $g$). la frazione $\\frac{f}{g}$ deve essere limitata e la varianza di $h$ rispetto alla densit√† $f$ deve essere finita. ","permalink":"https://flecart.github.io/notes/monte-carlo-integration/","summary":"DI Law of Large Numbers e Central limit theorem ne parliamo in Central Limit Theorem and Law of Large Numbers. Usually these methods are useful when you need to calculate following something similar to Bayes rule, but don\u0026rsquo;t know how to calculate the denominator, often infeasible integral. We estimate this value without explicitly calculating that.\nInterested in $\\mathbb{P}(x) = \\frac{1}{z} \\mathbb{P}^{*}(x) = \\frac{1}{Z} e^{-E(x)}$ Can evaluate E(x) at any x.","title":"Monte carlo integration"},{"content":"Introduzione alla normalizzazione Perch√© si normalizza? üü© Cercare di aumentare la qualit√† del nostro database, perch√© praticamente andiamo a risolvere delle anomalie possibili al nostro interno, e questo aiuta per la qualit√†.\nTipologie di anomalie (!) (4) üü®+ Ridondanze, non vorrei avere la stessa informazione espressa pi√π volte in troppi punti. Update non consistente, quando per aggiornare un singolo valore devo aggiornare moltissime altre tuple dipendenti da essa. Deletion non consistente, la presenza di certe entit√† √® strettamente dipendente da presenza di altri, nell\u0026rsquo;esempio in questione sulle slides, se elimino tutti gli utenti, elimino anche i progetti su cui hanno partecipato, mentre invece dovrebbero essere separati. Insertion, ad esempio se non posso inserire un certa entry finch√© una altra propriet√† legata (ma per il resto indipendente non √® stat definita, nell\u0026rsquo;esempio del prof provare ad inserire un lavoratore, ma senza progetto.) Dipendenze funzionali Vogliamo cercare di identificare le dipendenze funzionali e separarle, questo aiuta a creare qualit√† nel database La dipendenza funzionale √® un vincolo di integrit√† speciale, simile a quello relazionale spiegato in Relazional Model\nDefinizione formale di dipendenza funzionale üü© Data una relazione $r$ sullo schema $R(X)$ due sottoinsiemi non vuoti di attributi $Y$ e $Z$ sono detti funzionalmente dipendenti per ogni coppia di tuple $t_{1}$ e $t_{2}$ in $r$ con stessi valori per tutti gli attributi in $Y$ abbiamo che questi hanno gli stessi valori anche su $Z$.\nOsservazioni:\nFunzione, perch√© in un certo senso il primo insieme √® il dominio, e il secondo √® il codominio, ed √® come se ci fosse una funzione che li associ. Esistono dipendenze funzionali banali quelli il cui il secondo insieme di attributi √® un sottoinsieme del primo. Dipendenza funzionale con chiave essendo unica, non abbiamo duplicati di chiave, quindi l\u0026rsquo;implica implicito nella definizione ha sempre l\u0026rsquo;ipotesi falsa, quindi √® sempre vero (guarda logica per capire il senso della mia frase). Definizione formale Boyce e Codd (!) üü© Una relazione $r$\tsi dice in forma normale di Boyce e Codd se per ogni dipendenza funzionale non banale $X \\to A$ definita sulla relazione, $X$ contiene una chiave $K$ di $r$, cio√® $X$ √® una super-chiave di $r$\nOssia vogliamo solamente dipendenza funzionali tramite chiavi, e non in altro modo, altrimenti probabilmente avr√≤ una ripetizione.\nDefinizione terza forma normale üü®\u0026ndash; √à una forma leggermente pi√π rilassata, utile per normalizzare anche quando BC non √® possibile fare.\nUna relazione $r$ √® in terza forma normale se per ogni dipendenza funzionale $X \\to Y$ non banale vengono verificate una delle due condizioni:\n$X$ ha una chiave di $r$ ogni attributo di $Y$ appartiene ad almeno una chiave di $r$ Il primo dovrebbe corrispondere a Boyce Codd. Il secondo credo sia nuovo, possiamo dire quindi che sia una estensione, che permette la definizione di normalizzazione essere applicata a pi√π cose. Questa decomposizione √® sempre possibile, abbiamo un teorema che lo dice.\nMetodi di normalizzazione Decomposizione senza perdita. üü© Sia dato un insieme di attributi $X$ e una decomposizione, non partizione, in $X_{1}$ e $X_{2}$, abbiamo che la relazione $r$ si decompone senza perdita su $X_{1}$ e $X_{2}$ quando la join delle due √® uguale a $r$. ossia: $\\pi_{X_{1}}(r) \\bowtie \\pi_{X_{2}}(r) = r$\nQuesta √® una necessit√† per ricostruire le informazioni iniziali senza nessuna perdita. Si pu√≤ notare che talvolta seguendo in modo cielo le dipendenze funzionali che si possono trovare seguendo una via di Boyce and Codd, non √® sufficiente per mantenere questa propriet√† tanto importante.\nPrendiamo un esempio con perdita (perch√© vado a ricostruire un esempio con pi√π informazioni): Questa non √® una cosa che vogliamo!\nUn modo per risolvere questo √® aggiungere degli attributi fittizi che ci aiutano a discriminare sulle cose che ci servono. Ci fanno da specie di chiave.\nConservazione delle dipendenze üü© Questo permette di mantenere i vincoli di integrit√†.\nUna decomposizione preserva la dipendenza se ogni dipendenza funzionale dello schema originale ha attributi che compaiono nello stesso schema, altrimenti non √® possibile rilevare le dipendenze funzionali (Atzeni, pagina 332)\nCio√® se spezzo una dipendenza funzionale in tavole diverse, questa propriet√† non viene soddisfatta, perch√© non sarei pi√π in grado di trackarlo.\nPrendiamo un esempio in cui questa caratteristica si dimostra utile\nNormalizzazione nello schema concettuale üü®\u0026ndash; Possiamo utilizzare questa idea anche nella parte di sviluppo di schemi E-R. Se riconosco a questo livello che c\u0026rsquo;√® una dipendenza funzionale, questo mi da indicazioni su come continuare lo sviluppo di questo. Nell\u0026rsquo;esempio sulle slides motiva un partizionamento verticale, vedi Database logical design.\n","permalink":"https://flecart.github.io/notes/normalizzazione-dei-database/","summary":"Introduzione alla normalizzazione Perch√© si normalizza? üü© Cercare di aumentare la qualit√† del nostro database, perch√© praticamente andiamo a risolvere delle anomalie possibili al nostro interno, e questo aiuta per la qualit√†.\nTipologie di anomalie (!) (4) üü®+ Ridondanze, non vorrei avere la stessa informazione espressa pi√π volte in troppi punti. Update non consistente, quando per aggiornare un singolo valore devo aggiornare moltissime altre tuple dipendenti da essa. Deletion non consistente, la presenza di certe entit√† √® strettamente dipendente da presenza di altri, nell\u0026rsquo;esempio in questione sulle slides, se elimino tutti gli utenti, elimino anche i progetti su cui hanno partecipato, mentre invece dovrebbero essere separati.","title":"Normalizzazione dei database"},{"content":"Vincoli sintattici contestuali Intro: dipendenze da contesto üü© I vincoli sintattici non sono esprimibili tramite BNF perch√© dipendono dal contesto, mentre le grammatiche libere sono per definizione libere da contesto, vogliamo quindi trovare una soluzione a questo problema. Vengono usati metodi Ad-Hoc nella fase di analisi semantica del programma.\nGrammatiche dipendenti dal contesto\nQueste grammatiche sono molto pi√π complicate (e lente) rispetto a quelle libere da contesto, quindi √® poco pratico e non utilizzabile (tempo esponenziale, quindi non finisce mai).\nSemantica statica üü© Facciamo differenza fra semantica statica e dinamica con il primo che √® analizzato nella fase di compilazione del programma, mentre per dinamico √® analizzato nella fase di run-time, ma √® una forzatura del nome, perch√© storicamente sintassi √® indicata solamente a grammatica libera, mentre semantica √® tutto il resto, ma in verit√† semantica statica √® parte di sintassi.\nPrincipalmente questa parte riguarda controlli ad-hoc sul programma durante la compilazione. (ad hoc perch√© non √® vista dall‚Äôalbero di sintassi).\nSemantica statica def slide\nEsempi di controlli semantica statica\nSempre da tenere in mente che gli errori riportati in questa fase sono riguardanti la sintassi del programma (quindi ad esempio l‚Äôutilizzo di variabili non assegnate √® possibile in C non in Java, questo √® un controllo di semantica statica che dipende da questa sintassi del programma)\nUtilizzo dell‚Äôassegnamento a una variabile Le funzioni sono chiamate col giusto numero di variabili Divisione per zero (guarda esempio sul libro non √® ben definita questa cosa sul fatto che sia statica o dinamica). Assegnamento di variabili dello stesso tipo. Questi sono esempi di vincoli sintattici contestuali.\nSemantica dinamica (e utilizzi) üü©‚Äî Def semantica dinamica slide\nQuesta semantica √® un modello matematico utile per ogni architettura! √à una sorta di specifica che deve descrivere il concetto di correttezza di un programma dal punto di vista semantico. √à una rappresentazione dell‚Äôesecuzione del programma!\nEsempi di utilizzi:\nSlide utilizzi (!!!)\nDimostrazione di propriet√† del programma\nSpecifica formale del linguaggio\nImplementazione √® corretta?\nQuesti utilizzi si possno distinguere se l\u0026rsquo;autore √® un programmatore, un progettista del linguaggio, un implementatore di un linguaggio. (vedere le slides)\nTecniche di definizione di semantica (4) üü© Questa parte descrive la semantica, ma per certi punti ha un sacco di roba in comune con Classical Cyphers\nOperazionale\nSi mostra l‚Äôeffetto di ogni istruzione durante l‚Äôesecuzione, per dare enfasi su questo aspetto dobbiamo avere bene in mente la macchina astratta (registri stati etc..) (o mini automa). In parole povere proviamo a far eseguire su una macchina astratta\nCome calcola? questo √® quello che andiamo a fare oggi.\nDenotazionale\nSi fa enfasi su cosa va a calcolare (in cui si fa enfasi sulla funzione che viene calcolata).\nPragmatica\nDa ricordare la pragmatica in Pragmatica üü© in cui vengono trattati in generale principi per la descrizione di un linguaggio. In pi√π si va a chiedersi sul come utilizzare un costrutto e sullo scopo del singolo comando.\nSi parla di stile di programmazione.\nEsempi di pragmatica\nImplementazione\nSi va a rispondere a domande come\nL‚Äôimplementazione √® corretta? (veramente il sorgente e l\u0026rsquo;output implementano la stessa semantica?) Come √® implementato? Il codice in output √® efficiente o meno? Le strutture di dati utilizzate sono troppo pesanti o sono ok? Struttura del compilatore Slide struttura del compilatore\nAnalisi lessicale (Scanner) üü© Viene generata e riempita una tabella di simboli, questa fase vengono identificati ogni singola parola (o token) che incontra nel nostro programma.\nIn breve fa queste cose\nGenera i token (il lessico ammissibile) Riporta errori se trova token non legali Riempie parzialmente la tabella dei simboli Se qualche parola non √® valida viene utilizzato un gestore dell\u0026rsquo;errore\nI token sono spesso\nidentificatori Numeri operatori Parentesi Parole riservate Sono usati in questa parte grammatiche regolari espressioni regolari automi NFA DFA\nAnalisi sintattica (Parser) üü© In input riceve i token, utilizza la grammatica del linguaggio per verificare se √® corretto in output restituisce un albero di sintassi astratta del nostro programma. (quindi riporta errori sintattici del nostro programma) e aggiunge informazioni alla tabella dei simboli.\nQuindi in breve\nGenerazione albero di derivazione Report degli errori sintattici (al livello di frase) Sono usati in questa parte grammatiche libere da contesto pushdown automata (DPDA)\nAnalisi semantica üü© Controlla se tutta la sintassi libera da contesto sia coerente con la semantica del contesto (quindi verifica tipi, verifica chiamate o moltiplicazioni che abbiano senso o meno)\nIn breve\nControlli di semantica statica (verifica dei tipi, parametri etc) vedi sopra Aggiorna la tabella dei simboli con informazioni sui tipi Espande l‚Äôalbero con cose sui tipi Codice intermedio üü©- Scrive questo codice intermedio pi√π semplice\nSi segue la struttura sintattica, quindi spesso genera del codice molto verboso\nProduce codice molto semplice ,spesso three-address code.\nEsempio di codice intermedio\nOttimizzazione (4) üü© Ottimizza il codice nella forma intermedia\nCodice inutile √® rimosso Ottimizzazioni varie Espansione delle chiamate in linea (inline) Fattorizzazione di sottoespressioni Mettere fuori cicli sottoespressioni che non variano Generazione codice üü© Ottimizzazione specifica all‚Äôarchitettura Generazione del codice specifico (quindi a livello del singolo registro, o gestione stack e simili La tabella dei simboli üü© Contiene informazioni riguardo tutti i simboli all\u0026rsquo;interno del programma, quindi molto utile nella fasi di analisi.\nQuindi contiene metainformazioni riguardo ai simboli di interesse.\nSemantica Operazionale strutturata The meaning of a program in the strict language is explained in terms of a hypothetical computer which performs the set of actions that constitute the elaboration of that program. (Algol68, Section 2)\nIntro: insiemi di riferimento üü® Ha un linguaggio definito con la sintassi astratta solita (qualunque stringa √® parte dell‚Äôalbero di sintassi valido)\nAgisce principalmente su 3 insiemi\nBooleani Numeri Variabili (simbolici) Con questi dati primitivi definiamo delle espressioni\nSlide\nEspressioni aritmetiche (che agiscono su numeri o variabili) Espressioni booleane Comandi (control flow, gestione memoria, move di variabili) La descrizione di questi insiemi con le BNF sono ambigue ma per l\u0026rsquo;analisi della semantica non ci serve che abbiano un senso vero per questa roba. Non ci interessa di farlo in modo dis-ambiguo ci interessa questa parte solo per la semantica dinamica\nI parser danno in output degli alberi in sintassi astratta\nSistema di transizione (!) üü©‚Äî Slide di definizione\nQuesto sistema di transizione ci √® utile per descrivere al meglio la semantica.\n√à una tripla $\\Gamma, T, \\to$ dove il primo √® l‚Äôinsieme degli stati, il secondo l‚Äôinsieme degli stati terminali e il terzo una relazione di transizione (che pi√π o meno ci dice in che modo possiamo muoverci all‚Äôinterno di questi stati).\nIndichiamo con computazione da uno stato $\\gamma_o$ di partenza una seguenza (possibilmente infinita) di transizioni.\nIndichiamo con $\\to^*$ la chiusura riflessiva e transitiva della relazione di transizione.\nInterna sinistra, destra, ed esterne üü© Questo concetto di definizione di operazioni interna sinistra,destra ed esterne √® solamente un metodo che piace al prof per descrivere questo, per√≤ mi sembra che sia praticamente inutile lmao.\nComunque una operazione la descrivi come interna se valuti entrambi gli operandi, sinistra se valuti prima il sinistro e poi il destro e poi viceversa.\nLa definisci come esterna se √® possibile valutare soltanto l‚Äôoperatore sinistro (quindi esterna sinistra) o destro.\nOltre IS, esistono anche ID, ES, ED e Interna Parallela = IP (in cui posso utilizzare in modo alternato il destro o sinistro, e quindi mi basta solo sum1 o sum1‚Äô, quindi questa √® non-deterministica), perch√© posso avere delle derivazioni diverse (ad ogni step posso avere pi√π di un unico assioma da utilizzare!), e potrei anche farli in parallelo.\nSemantica delle espressioni aritmetiche (!) üü© Assiomi per le relazioni (3 tipi)\nVar sostituzione con variabile con un numero terminale\nSum1 mi d√† una sorta di idea di equivalenza per la somma per alberi che si derivano.\nSum2 mi d√† una equivalenza quando la somma √® su un numero\nSum3 mi d√† una equivalenza nella somma nei naturali.\nSub{1,2,3} sono esattamente equivalenti ma per la sottrazione.\nOsservazioni\nLo store non viene mai modificato.\nPer la valutazione si preferisce valutare l‚Äôoperando pi√π a sinistra. ‚ÜíInterna sinistra in modo analogo esiste l‚Äôinterna destra.\nCostruzione solita, con store\nFunzione di transizione √® deterministica (non richiesta) üü• Questa √® una caratteristica importante della funzione di transizione, si fa uso della ricorsione strutturale presente in 4.6 Ricorsione strutturale.\n$$ y \\to y', y \\to y'' \\implies y' =y'' $$ Ossia ho una sola possibile mossa\nDimostrazione\nEval üü© Il fatto che sia deterministica ci permette di definire un concetto di eval tanto √® unica!\n√à definita con le funzioni di valutazione interne sinistre!\nEssere esterno significa che a volte non valuto tutti gli operandi nella nostra operazione, mentre le interne devono valutare tutte.\nIn generale valgono queste valutazioni\nEquivalenza (!!) üü©- Possiamo anche definire un concetto di equivalenza di espressioni come propriet√† di questo eval.\nDefinizione di equivalenza per espressioni\nSemantica delle espressioni booleane (!) üü© Assiomi per la semantica delle espressioni booleane\nValgono le propriet√† per le espressioni aritmetiche\nStore non cambia La relazione √® deterministica. Semantica dei comandi (statements) (!) üü®+ Assiomi per la semantica dei comandi\nCommenti sugli assiomi\nSkip non faccio niente, lascio la funzione di valutazione esattamente la stessa\nAssign viene fatto uno step di sostituzione (e quindi bisogna anche creare una funzione di sostituzione, ma √® definita bene in logica in questo blocco 8.1.2 Operazione di sostituzione.\nSeq cerca di far andare avanti la computazione\nIf decide in quale ramo andare, quindi due regole easy\nWhile in modo molto simile, decide se rieseguire il corpo del while oppure andare fuori.\nSi pu√≤ notare che anche questa semantica √® deterministica! In modo simile si pu√≤ dimostrare per ricorsione strutturale insieme le altre, dato che √® deterministica possiamo *definire una funzione exec. che √® definita solo se √® terminale\nDivergenza e deadlock sono EQUIVALENTI (Ossia computazione ch enon pu√≤ andare avanti e cicli infiniti, non si distinguono con questa semantica, bisogna introdurre delle cose in pi√π).\nErrori dinamici (runtime) üü® Regole di generazione e propagazione dell‚Äôerrore\nAltre regole per errori (che in un linguaggio solitamente esistono)\nNon determinismo e parallelismo üü® Non deterministico perch√© si pu√≤ eseguire in mondi diversi e ritornare cose diverse a seconda di quei mondi.\nParallelismo perch√© pu√≤ eseguire in contemporanea le istruzioni (in questo senso l‚Äôordine di esecuzione pu√≤ essere ben differente).\nSlide\nEsempio di esecuzione non deterministica\n","permalink":"https://flecart.github.io/notes/semantica-di-un-linguaggio/","summary":"Vincoli sintattici contestuali Intro: dipendenze da contesto üü© I vincoli sintattici non sono esprimibili tramite BNF perch√© dipendono dal contesto, mentre le grammatiche libere sono per definizione libere da contesto, vogliamo quindi trovare una soluzione a questo problema. Vengono usati metodi Ad-Hoc nella fase di analisi semantica del programma.\nGrammatiche dipendenti dal contesto\nQueste grammatiche sono molto pi√π complicate (e lente) rispetto a quelle libere da contesto, quindi √® poco pratico e non utilizzabile (tempo esponenziale, quindi non finisce mai).","title":"Semantica di un linguaggio"},{"content":"3.1 Successioni $$ \\begin{cases} f: \\mathbb{N} \\to \\mathbb{R} \\\\ n \\to f(n) \\\\ \\{a\\}_{n \\in \\mathbb{N}} \\vee a_n \\end{cases} $$ √à una funzione che mappa dai naturali ai Reali indicata spesso solamente come $$ \\left\\{ a \\right\\} _{n \\in \\mathbb{N}} $$ 3.1.1 Immagine e successione L\u0026rsquo;immagine di una successione (l\u0026rsquo;insieme dei suoi elementi) non √® una successione! la successione √® anche ordinata.\n3.1.2 Limitazioni della successione Come per gli insiemi si pu√≤ definire se l\u0026rsquo;insieme √® limitato superiormente, inferiormente o entrambi, a seconda di come lo definiamo in questo modo possiamo poi farci altri ragionamenti\nPer decidere se esiste questo limite, continui a fare gli stessi ragionamento sul maggiorante e minorante come per gli insiemi.\nSe uniamo l\u0026rsquo;essere superiormente o inferiormente limitato con la monotonia allora possiamo unire questa con il concetto di convergenza a un limite finito.\n3.1.3 Monotonia delle successioni Le successioni possono essere crescenti, descrescenti.\nLa definizione di queste successioni √® lasciata al lettore.\n3.2 Limiti di successioni 3.2.1 Intuizione Mi posso arrivare a un certo valore di quanto mi pare, del singolo valore che mi pare so che esiste sempre un valore che mi posso avvicinare.\n3.2.2 Limite Convergente Si definisce un limite per x che tende all\u0026rsquo;infinito di una successione $a_ n$ in questo modo:\n$$ L=\\lim_{x\\to\\infty} a_{n}:=\\forall \\epsilon\\in \\R^+, \\exists n_0\\in \\N^*,\\forall n \\in \\N:n \\geq n_0 \\implies |a_n - L| \u003c \\epsilon $$ 3.2.3 Limiti divergenti Ossia per qualunque k, posso andare a cercare un $n_0$ da qui in poi la successione √® sempre maggiore, posso scegliere come mi pare\n$$ \\infty = \\lim_{ x\\to +\\infty} a_ n:= \\forall k\\in \\R^+, \\exists n_0\\in \\N^*,\\forall n \\in \\N:n \\geq n_0 \\implies a_n \\geq k $$ $$ -\\infty = \\lim_{ x\\to +\\infty} a_ n:= \\forall k\\in \\R^+, \\exists n_0\\in \\N^*,\\forall n \\in \\N:n \\geq n_0 \\implies a_n \\leq k $$ Nota di italiano\nSI pu√≤ dire solamente se una successione tende ma non puoi mai dire che il limite tende a qualcosa, perch√© il limite √® definito come un certo valore.\n3.2.4 Limiti finiti Questa definizione di limite di rif√† al concetto di intorno, ed √® un limite valutato su un unico punto 3.2.5 Limiti su successioni monotone !!! Sia data una successione crescente $a_n$, allora $\\lim_{x \\to \\infty} = \\sup \\{a_n | n \\in \\N\\}$\nSimile per successioni decrescenti\nDimostrazione\nDimostriamo ora per il caso decrescente.\nAllora il limite $L$ √® o finito, o √® $-\\infty$.\nCaso 1 $L = -\\infty$:\nLa successione non ha un limite inferiore, quindi non esistono dei minoranti per questo insieme, allora $\\forall k \u003e0 \\implies \\exists n_0 : a_{n_0} \u003c k$ allora essendo la successione decrescente abbiamo che $\\forall n : n\\in\\N, n \u003c n_o \\implies a_n \u003c a_{n_0}$ quindi $a_n \u003c k$ per ogni n minore di $n_0$ ci√≤ √® sufficiente per dimostrare la tesi dell\u0026rsquo;esistenza del limite divergente\nCaso 2 $L$ finito:\ndobbiamo dimostrare che $-\\epsilon \\leq |a_n - L| \\leq \\epsilon \\iff L - \\epsilon \\leq a_n \\leq L + \\epsilon$ ma sappiamo in quanto $L$ √® un minorante che vale $L - \\epsilon \\leq a_n$, consideriamo ora, $L + \\epsilon$, non essendo un minorante, deve esistere un $a_{n_0} \u003c L + \\epsilon$ allora essendo la successione decrescente abbiamo che $\\forall n : n\\in\\N, n \u003c n_o \\implies a_n \u003c a_{n_0}$ , quindi esiste un $n_0$ tale per per ogni $n$ minore di quello vale la sufficienza per il limite.\n3.3 Algebra dei limiti Ipotesi e tesi di ci√≤\n3.3.1 Somma limiti finiti Siano $a_n , b_n$ successioni con limite finito $l_1,l_2$, allora il limite di $a_n + b_n$ √® $l _1 + l_2$.\n$-\\epsilon_a \\leq a_n - l_1 \\leq \\epsilon_a$\nallora $-\\epsilon_b \\leq b_n - l_1 \\leq \\epsilon_b$\nallora $-\\epsilon_a -\\epsilon_b \\leq a_n - l_1 + b_n - l_1\\leq \\epsilon_a +\\epsilon_b$ e ci√≤ finisce la dimostrazione.\n3.3.2 Somma limiti Se usiamo un limite tale che una dei due √® infinito e hanno lo stesso segno allora abbiamo quello che abbiamo\u0026hellip;. Guarda le slides!\n3.3.3 Prodotto dei limiti finiti 3.3.4 Prodotto di limiti infiniti 3.3.5 Forme indeterminate somma e prodotto e divisione Somma di $+\\infty-\\infty$ oppure il contrario.\n$0 \\cdot \\pm\\infty$\nQualunque divisione fra infiniti .\n3.4 Numero di Nepero 3.4.1 Necessit√† per dimostazioni Per dimostrare l\u0026rsquo;esistenza del numero di Nepero come\n$$ \\lim_{n \\to \\infty} (1 + \\dfrac{1}{n})^n = e $$ Devo dimostrare in particolare due cose:\nCrescenza della funzione Limitatezza della funzione (ricorda che per questa propriet√† ho che una successione crescente o √® limitata e ha limite finito o √® divergente) 3.4.2 La disuguaglianza di Bernoulli La tesi e ipotesi della disuguaglianza di Bernoulli\nDimostrazione:\nSi ha una dimostrazione per induzione\nPB:\n$n = 0 \\implies 1 \\geq 1$ Verificato\nSupponiamo che valga per n, dobbiamo dimostrare che\n$(1 + x) ^{n + 1} \\geq 1 + x + nx$\n$(1 + x) ^{n + 1} \\geq (1 + x)(1 + nx) = 1 + nx + x + nx^2$ ovvio che sia maggiore della parte di destra, per cui √® dimostrato.\n3.4.3 Crescenza della successione La successione √® strettamente crescente, con 2 pagine e mezzo di calcoli.\nPrima dimostri che la divisione fra due numeri successivi della sequenza sia $\u003e 1$, poi fai i calcoli, in modo strano, facendo delle mosse anche intelligenti per quanto riguarda togliere e aggiungere degli uno e finisci a dire che vale.\n3.4.4 Limitatezza della successione Questa dimostrazione si dimostra espandendo la definizione con il binomio di Newton, in seguito si devono avere queste seguenti osservazioni interessanti:\nSemplificare $\\dfrac{n(n-1)...(n-k+1)}{n^k}$ dicendo che √® minore di 1, in quanto tutti i $k$ fattori al numeratore sono minori del denominatore. Semplificare il restante $\\dfrac{1}{k!}$ con le somme telescopiche (usando la disuguaglianza 1/k! ‚â§ della somma telescopica) e dimostrare che √® finito. Si dimostra quindi che l\u0026rsquo;upper bound √® 3.\n","permalink":"https://flecart.github.io/notes/successioni/","summary":"3.1 Successioni $$ \\begin{cases} f: \\mathbb{N} \\to \\mathbb{R} \\\\ n \\to f(n) \\\\ \\{a\\}_{n \\in \\mathbb{N}} \\vee a_n \\end{cases} $$ √à una funzione che mappa dai naturali ai Reali indicata spesso solamente come $$ \\left\\{ a \\right\\} _{n \\in \\mathbb{N}} $$ 3.1.1 Immagine e successione L\u0026rsquo;immagine di una successione (l\u0026rsquo;insieme dei suoi elementi) non √® una successione! la successione √® anche ordinata.\n3.1.2 Limitazioni della successione Come per gli insiemi si pu√≤ definire se l\u0026rsquo;insieme √® limitato superiormente, inferiormente o entrambi, a seconda di come lo definiamo in questo modo possiamo poi farci altri ragionamenti","title":"Successioni"},{"content":"Introduction to topological spaces We want now to extend the idea of continuity presented in limits, which is a function $f : E^{n} \\to E^{n}$ is continuous if given $x$ then $\\forall\\varepsilon \u003e 0$ $\\exists \\delta$ such that $\\forall y : \\lVert y -x \\rVert \u003c \\delta \\implies \\lVert f(y) - f(x) \\rVert \u003c \\varepsilon$. But we want to get rid of the idea of distance, and base our definition on the idea of neighborhoods, which in $E^{n}$ are just spherical radius centered around a point.\nDefinition of Topological space We define a set $X$ to be a topological space and for each $x \\in X$ we define a set of subsets of $X$ called $N_{x} : \\forall S \\in N_{x}, S \\subseteq X$ such that they satisfy the following axioms:\n$\\forall S \\in N_{x} : x \\in S$ if $S, T \\in N_{x} \\implies S \\cap T \\in N_{x}$ if $S \\in N_{x}, U \\subseteq X, S \\subseteq U \\implies U \\in N_{x}$, this implies that the union of $S_{1}, S_{2} \\in N_{x}$ is in $N_{x}$. If $S \\in N_{x}$ and $T = \\left\\{ z \\in S \\mid S \\in N_{z} \\right\\}$ then we have that $T \\in N_{x}$. We call $T$ the interior of $S$ The first three conditions seems to be reasonable, and coherent to our intuitive idea of neighborhoods. Let\u0026rsquo;s use our geometrical interpretation of a neighborhood as circles in a 2D plane. 1. is trivial to check, the second condition is just the smallest radius of the two neighborhoods, the third condition is a little bit more tricky, as $U$ is not guaranteed to be a circle with some radius, but it satisfies the first two conditions (we see here a relaxing of the strict ball radius condition). The fourth condition is just the circle without the boundary.\nIn brief, if we have a set $X$ and an assignment of neighborhoods to each point $x \\in X$ then we have a topology over the set $X$.\nThis is good resource for topological spaces. Another definition is this (this should be a preferred definition because it\u0026rsquo;s easier to remember):\nWe say that a couple $(X, \\mathcal{T})$ is a topological space on a set $X$ when $\\mathcal{T}$ is a set of subsets of $X$ such that:\n$\\varnothing, X \\in \\mathcal{T}$ $G_{i} \\in \\mathcal{T}, \\forall i \\in A \\implies \\bigcup_{i}G_{i} \\in \\mathcal{T}$ $G_{i} \\in \\mathcal{T}, \\forall i \\in \\left\\{ 1, \\dots, n \\right\\} \\implies \\bigcap_{i}G_{i} \\in \\mathcal{T}$. This behaves well for infinite unions and finite intersections. But it is equivalent, but now I don\u0026rsquo;t know exactly why. Still the most important thing here is that we have a natural notion of neighbourhood .\nIt\u0026rsquo;s easy to see that every set $S \\subseteq X$ is a subspace-topology. An easy way to convince ourselves about why we need finite intersection bound for closeness is the classical example of accumulation point studied in Limiti, e.g. the succession of sets $\\left\\{(0, \\frac{1}{n}] \\mid n \\in \\mathbb{R} \\right\\}$.\nProduct Topologies One interesting observation is that if $(X, T_{x})$ and $(Y, T_{y})$ are topologies, then there exists a product topology $X \\times Y$. We just take all the possible open sets in $T_{x}$ and product that with $T_{y}$ and one can observe that the axioms of topology are good also in this case. One can observe that this kind of proof is somehow similar to the proofs presented in Grammatiche Regolari when we try to prove things joining other things together.\nContinuity of topological spaces Let\u0026rsquo;s take, say $X$ and $Y$ to be two topologies, then the function $f : X \\to Y$ is continuous if $\\forall x \\in X, \\forall S \\in N_{f(x)}, S \\subseteq Y$ we have that $f^{-1}(S) \\in N_{x}$. This is just a difficult way to say that if the function maps to a open set in the co-domain, then it should start from an open set in the domain. We can also write the above in the following manner: Given an open set $U \\subseteq Y$ we want the pre-image $f^{-1}(U)$ to be an open set for the domain topology, which seems a lot easier to understand.\nThis is just a different characterization of the ideas of continuity we developed in #Motivation.\nPath-connected spaces We say that a topology is path connected if for every $a, b \\in \\mathcal{X}$ exists a continuous function $f$ from $f: \\left[ 0, 1 \\right] \\to \\mathcal{X}$ such that $f(a) = 0$ and $f(b) = 1$ this function describes a path in the topology that connects the two points. This is usually considered a stronger condition on the connected condition of the topological space and it\u0026rsquo;s very useful for initial exploration of the mathematical space.\nTh: path-connected space implies connected. Proof: we assume path-connected and disconnected and try to prove a contradiction. By hypothesis of disconnected space, we have two disjoint open sets $A, B$ that make up the original space $\\mathcal{X}$, let\u0026rsquo;s consider now two points in these sets. We know that we have a continuous function $f$ that connects these two points. We would like to use the disconnected hypothesis to prove that the function is not continuous, getting a contradiction. Let\u0026rsquo;s consider the sets $f^{-1}(A)$ and $f^{-1}(B)$ these two sets are disjoint in $\\left[ 0, 1 \\right]$ and their union is $[0, 1]$ because $f$ is continuous and $[0, 1] = f^{-1}(\\mathcal{X}) = f^{-1}(A) \\cup f^{-1}(B)$. But these two sets are non empty. Which contradicts the connectivity of $[0,1]$ proved in [[Metric Spaces#Connectedness of $ left[ 0, 1 right]$]]. Thus we conclude that the original set is connected.\nOne Wrong proof This is a wrong proof, some wrong proofs are educational, so I\u0026rsquo;ll include this here. Consider a ball topology (strict inequality) on the real interval with the extremes $[0], [1]$ included. We can observe that $f^{-1}(\\mathcal{X}) = f^{-1}(A) \\cup f^{-1}(B) = [0, a) \\cup (b, 1]$, we can conclude that $a = b$, these sets are open sets for construction, but their union is not $[0, 1]$ which gives the contradiction.\nSome definitions Def: Interior and boundaries Given a topology $(X, \\mathcal{T})$ we call a set $S \\subseteq X$ open if $S \\in \\mathcal{T}$. A set is closed if its complement is open. This is a easier definition of open and closeness compared to the definition present in real analysis. In this case the concept of neighbourhood is built in.\nWe cal interior set of $A$ the union of all open sets of $A$. We call boundary the difference between the closure of the set $A$ and its interior set.\nDef: connected and disconnected spaces Intuitively, we say that a topology is disconnected if we can split the original set in at least two parts. Which means: given a topology $\\mathcal{X}, \\mathcal{T}$ we can find $A, B \\in T : A \\cap B = \\varnothing \\land A \\cup B = \\mathcal{X}$. If the above condition is false, then we say that the topology is connected.\nDef: Homeomorphism A function $f: X \\to Y$ where $X, Y$ are topological spaces is said to be a homeomorphism if\nBijective Continuous Inverse is continuous This definition allows us to define a concept of equivalence of two topologies. If two spaces are homeomorphic we write $X \\simeq Y$. Def: Isotopy $A$ is the ambient space, the space where the topologies live. We define a isotopy connecting $X \\subseteq A$ and $Y \\subseteq A$ to be a continuous map $\\phi: X \\times [0, 1] \\to A$ such that $\\phi(X, 0) = X$ and $\\phi(X, 1) = Y$ and $\\forall t \\in [0, 1]$ we have that $\\phi( \\cdot, t)$ is a homeomorphism between $X$ and its image. We say that two spaces are isotopic if there is an isotopy connecting them.\nDef: Surface A surface is a topological space in which each point has a neighbourhood homeomorphic to the plane, and for which any two distinct points possess disjoint neighborhoods.\nClassification Theorem Any closed surface is homeomorphic either to the sphere, or to the sphere with a finite number of handles added, or to the sphere with a finite number of discs removed and replaced by M√∂bius strips. No two of these surfaces are homeomorphic.\nThis is one of the most important theorems in topology, but for a student that just started to understand this field, it will be probably a little difficult to do so.\nFurstenberg\u0026rsquo;s proof of infinite prime numbers There is a nice proof explained here about the infiniteness of prime numbers by just assuming basic properties of arithmetic and successions.\nStatement Let\u0026rsquo;s consider the set $\\mathbb{Z}$ we define the set $S(a, b) := \\left\\{ an + b \\mid n \\in \\mathbb{Z} \\right\\}, a, b \\in \\mathbb{Z}$. Then we consider open a set $U \\subseteq \\mathbb{Z}$ if we have that $x \\in U \\implies \\exists a, b \\in \\mathbb{Z} : x \\in S(a, b) \\land S(a, b) \\subseteq U$ which means that the set $U$ is composed by unions (that could also be infinite) of $S(a, b)$ successions.\nProof We prove that with this definition of openness we have a topology:\n$\\varnothing, \\mathbb{Z}$ are contained in this definition, check. We have infinite unions, because by definition if we can unite $S(a, b)$ together as much as we want. We have finite unions, because it\u0026rsquo;s just taking the MCD. This is not a formal mathematical proof. but you can be convinced that this is right. Then we note that if a set is finite and non-empty it\u0026rsquo;s complementary set is not closed. We notice that the set $S(a, b)$ is both closed and open for all $a, b \\in \\mathbb{Z}$. This is quite easy to be convinced with. We notice that if we take $UU = \\bigcup_{p \\text{ is prime}} S(p, 0)$ this is equal to $\\mathbb{Z} - \\left\\{ -1, 1 \\right\\}$. So we know that this set is only open and cannot be closed, by the observation of finite sets. We note now that $$ \\left( \\bigcup_{p \\text{ is prime}} S(p, 0) \\right) ^{c} = \\bigcap_{p \\text{ is prime}} S(p, 0)^{c} $$ We know that $S(p, 0)^{c}$ is open, and now conclude that if the number of $p$ was finite, then by property of topology the set should be open, which implies that the set $UU$ should be closed. Contradiction, which means the number of primes if infinite. ","permalink":"https://flecart.github.io/notes/topological-spaces/","summary":"Introduction to topological spaces We want now to extend the idea of continuity presented in limits, which is a function $f : E^{n} \\to E^{n}$ is continuous if given $x$ then $\\forall\\varepsilon \u003e 0$ $\\exists \\delta$ such that $\\forall y : \\lVert y -x \\rVert \u003c \\delta \\implies \\lVert f(y) - f(x) \\rVert \u003c \\varepsilon$. But we want to get rid of the idea of distance, and base our definition on the idea of neighborhoods, which in $E^{n}$ are just spherical radius centered around a point.","title":"Topological Spaces"},{"content":"Origini di sfocatura \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Immagini/Untitled.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Immagini/Untitled\u0026quot;\u0026gt; Rumore causata da problemi fisici che sono errori di lettura del segnale analogico Questo si indica anche come errore gaussiano bianco e si pu√≤ considerare additivo. Rumore causato dalla digitalizzazione, quindi dalla discretizzazione di essa. Slide formalizzazione errori per sfocatura\nPoint spread function Un unico pixel bianco sembra influenzare il suo ambiente nero, come in immagine\nVorremmo utilizzare delle funzioni ce siano in grado di approssimare questa funzione.\nFunzioni solitamente utilizzate per approssimare e risultati\nConvoluzioni Questa cosa lo avevo gi√† studiato credo per CNN, in AI. La prof lo scrive in modo molto incomprensibile, ma √® la stessa cosa‚Ä¶ Che cosa triste..\nSlides\nRicostruzione immagini Ossia cerco di identificare le cause del blur, e da quello provo a tornare indietro\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Immagini/Untitled 7.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Immagini/Untitled 7\u0026quot;\u0026gt; Da tenere in mente il fatto che A √® mal condizionata!. Vogliamo quindi introdurre alcuni metodi di regolarizzazione in modo da far diventare pi√π gestibile questo problema. (quindi vorremmo avere una matrice equivalente che sia pi√π gestibile).\nTODO: vedere perch√© minimi quadrati √® mal condizionato.\nRegolarizzazione Andiamo ad utilizzare un funzionale di regolarizzazione con un parametro che mi indica quanto √® influenza la funzione finale.\nRegolarizzazione Tiknohov e Morozov Slide riassuntiva\nDi solito come funzione phi di x metto l‚Äôidentit√† e come lambda un valore che scelgo provando tante cose e prendendo alla fine il pi√π grande che mi soddisfa\ne √® l‚Äôerrore causato dal blur\nSi pu√≤ saltare la regolarizzazione con le altre norme üíÄ perch√© alla prof non piace, saddo.\nPeak signal to Noise Ratio Quanto pi√π il valore √® alto pi√π l‚Äôimmagine √® buona, questo √® un buon parametro per valutare che la funzione di approssimazione sia buona.\n","permalink":"https://flecart.github.io/notes/deblur-di-immagini/","summary":"Origini di sfocatura \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Immagini/Untitled.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Immagini/Untitled\u0026quot;\u0026gt; Rumore causata da problemi fisici che sono errori di lettura del segnale analogico Questo si indica anche come errore gaussiano bianco e si pu√≤ considerare additivo. Rumore causato dalla digitalizzazione, quindi dalla discretizzazione di essa. Slide formalizzazione errori per sfocatura\nPoint spread function Un unico pixel bianco sembra influenzare il suo ambiente nero, come in immagine\nVorremmo utilizzare delle funzioni ce siano in grado di approssimare questa funzione.","title":"Deblur di immagini"},{"content":"In questa parte del nostro percorso nei linguaggi di programmazione proviamo ad espandere NFA e DFA in modo che possano riconoscere linguaggi come $ww^r | w \\in \\{a, b\\}^*$ , con r maggiore o uguale a zero (r per dire che √® il contrario di w) (questo linguaggio per il pumping lemma).\nPush-down automata Introduzione automi a pila (7)üü© \u0026ndash; L‚Äôidea principale per espandere gli NFA √® il concetto di stato o memoria, avere quindi una stack o pila pu√≤ rendere molto pi√π espressivo queste entit√†.\nIl prof. definisce automa a pila non deterministico (PDA) questa settupla $(\\Sigma, Q, \\Gamma, \\delta, q_{0}, \\bot, F)$\n$\\Sigma$ l\u0026rsquo;alfabeto finito dei simboli in input $\\Gamma$ l\u0026rsquo;alfabeto dei simboli sulla pila $Q$ l\u0026rsquo;insieme degli stati $\\delta$ transizione, nella forma $\\delta: Q\\times (\\Sigma \\cup \\left\\{ \\varepsilon \\right\\}) \\times \\Gamma \\to \\mathbb{P}(Q \\times \\Gamma^{*})$ $q_{0}$ lo stato iniziale $\\bot \\in \\Gamma$ il simbolo iniziale sulla pila $F \\in Q$ l\u0026rsquo;insieme degli stati finali. Una differenza che fa questo prof. contro La macchina di Turing √® che lui fa distinzione dei simboli sulla pila, mentre l\u0026rsquo;altro no, una altra differenza √® che gli stati finali sono esterni nell\u0026rsquo;altro. Ma credo alla fine sia equivalente. Attenzione: l‚Äôautoma pu√≤ leggere qualcosa solo se la sua stack non √® vuota!\nLa parte intressante dei PDA rispetto agli automi studiati in Automi e Regexp √® la funzione di transizione, che √® ora nella forma\n$$ \\delta: Q \\times (\\Sigma \\cup\\{\\varepsilon\\}) \\times \\Gamma \\to P(Q \\times \\Gamma ^*) $$ Esempio hard di PDA Computazione automi a pilaüü© \u0026ndash; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Linguaggi liberi e PDA/Untitled 7.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Linguaggi liberi e PDA/Untitled 7\u0026quot;\u0026gt; Accettazione della stringa üü© La cosa particolare degli automi a pila √® che accettano la stringa anche quando la pila diventa vuota, non solo quando finisco di leggere e ho uno stato che √® bello. Ossia detto meglio, posso costruirmi un automa a Pila che accetta la stessa stringa quando la pila diventa vuota, c‚Äô√® una sorta di equivalenza fra stato e cose sulla pila.\nSlide\nLa cosa importante da capire per questa parte √® che si differenziano due metodi di accettazione per la stringa:\nPila vuota Stato finale. In entrambi i casi devo leggere tutto l‚Äôinput, e poi vado a vadere dove sto. Nel primo caso se ho letto tutto l‚Äôinput e la pila √® vuota allora accetto, nel secondo caso se ho letto tutta la stringa e sono in uno stato finale allora vado ad accettare.\nTeorema equivalenza accettazione Vuoto-Stato üü© Enunciato\nDimostrazione in slide\nL\u0026rsquo;idea dietro questo teorema √® molto simile a quanto presente nella conversione fra espressione regolare e NFA, perch√© sto andando in modo ricorsivo, supponendo che ho gi√† un vecchio automa che funzioni, e basta che ci costruisca cose intorno ad essa. (in questo caso simbolo iniziale nuovo e stato finale che pi√π o meno racchiude tutti gli stati finali!\nZ √® un simbolo stack nel nostro nuovo automa, solo utilizzato per gestire meglio alcune cose con la stack.\nOgni linguaggio √® libero sse riconosciuto da PDA (chiede)üü© Enunciato\nDimostrazione\nDiagramma PDA per ‚Üí\nNota questo non √® il PDA di cui parlava il prof nelle slides, bisognerebbe condensarlo in un unico stato. Questo qui risolve per stato finale, quello del prof per stack vuota\nNote sulla dimo\nVogliamo dimostrare un sse, in una proviamo a costruire un automa partendo dalle regole della grammatica, (non dimostriamo che l‚Äôautoma riconosce effettivamente, la costruiamo ebbasta.\nPer l‚Äôaltra freccia bisogna avere dimostrato prima alcuni lemmi che noi saltiamo per ora.\nPropriet√† dei linguaggi liberi Unione, Conc, e Kleene üü© Dimostrazione\nIn pratica i non terminali e terminali sono uniti assieme, e con qualche produzione in pi√π sullo stato iniziale per gestire le cose.\nIntersezione con linguaggio regolare (chiede per alto voto) üü© Questa √® qualcosa di leggermente pi√π tosta, per√≤ in soldoni sto facendo un bruteforce, e prendendo tutte le combinazioni possibili per cui si possa riconoscere\nTh e dimostrazione\nCon questo teorema √® spesso utile per dimostrare che un linguaggio non √® libero.\nInvece non sono chiusi per intersezione i linguaggi liberi\nEsempio di non chiusura\nDa questo dato si pu√≤ concludere che non sono chiusi per complemento altrimenti lo sarebbero anche per l\u0026rsquo;intersezione.\nPumping theorem, tosta (!) üü®++ Enunciato\nDimostrazione\nDimostrazione libro sispser (pi√π chiaro)\nL‚Äôidea √® sempre avere cos√¨ tanti stati che avr√≤ per forza dei non terminali duplicati. uno sotto l‚Äôaltro, in una forma ricorsiva, allora prendo il minore e vado a fare ragionamenti l√¨.\nClassificazione dei linguaggi Chomsky (5) üü•+ Chomsky, linguista, ha descritto una gerarchia di linguaggi\nCaratterizzazione dei linguaggi Sulla decidibilit√† guardare Fondamenti teorica e La macchina di Turing\nIn questo caso i nuovi sono\nGrammatiche dipendenti dal contesto, in cui una singola produzione pu√≤ avere pi√π non-terminali. Grammatiche motonone, le cui produzioni basta che crescano Grammatiche generali, in cui non c‚Äô√® nessun vincolo di produzioni Schema generale delle grammatiche üü© Per turing, vedere La macchina di Turing.\nGerarchia automi üü®+ In generale si pu√≤ estendere dicendo\nAutomi Limitati riconoscono grammatiche dipendenti dal contesto Automi di Turing riconoscono i linguaggi ricorsivi, e sono in grado di enumerare ricorsivamente quelle generali. (anche se √® semidecidibile, quindi forse non riesce a ricononscerli tutte??) ","permalink":"https://flecart.github.io/notes/linguaggi-liberi-e-pda/","summary":"In questa parte del nostro percorso nei linguaggi di programmazione proviamo ad espandere NFA e DFA in modo che possano riconoscere linguaggi come $ww^r | w \\in \\{a, b\\}^*$ , con r maggiore o uguale a zero (r per dire che √® il contrario di w) (questo linguaggio per il pumping lemma).\nPush-down automata Introduzione automi a pila (7)üü© \u0026ndash; L‚Äôidea principale per espandere gli NFA √® il concetto di stato o memoria, avere quindi una stack o pila pu√≤ rendere molto pi√π espressivo queste entit√†.","title":"Linguaggi liberi e PDA"},{"content":"I Nomi e oggetti Oggetti denotati e identificatoriüü© I nomi sono sequenze di caratteri o numeri aka: token alfanumerico (anche IDENTIFICATORE (per token guardare Grammatiche Regolari) utilizzate principalmente come Astrazione sul controllo e sui dati (quindi sono cose molto pi√π facili da ricordare rispetto il suo encoding binario o a indirizzi). Infatti utilizziamo i nomi per evitare di interessarci di informazioni come l‚Äôindirizzo di memoria del nostro dato o per creare una interfaccia con visibili solo nome della procedura e parametri.\nI nomi quindi possono essere utilizzati per cose come\nElementi definiti al momento di progettazione del linguaggio: Costanti predefinite operazioni primitive (+, * etc) Tipi di dato primitivi Elementi definiti da utenti Variabili Parametri Indirizzi di memoria. Procedure (le funzioni) Costanti dell‚Äôutente tipi dell‚Äôutente Bindings (4) üü©- Il binding √® proprio il collegamento che si ha fra il nome e l‚Äôoggetto che viene denotato da essa.\nQuesto binding √® creato in 4 momenti diversi:\nProgettazione del linguaggio In questa fase possono venire definite le cose come elencate sopra Struttura del programma In questa parte viene solamente iniziato il collegamento fra identificatore e variabile identificata (e.s. se identifica una zona di memoria non allocata, non √® ancora completato il binding), per questo motivo possiamo dire che √® iniziato il binding delle variabili definite dall‚Äôutente ma non √® stata completata. In fase di compilazione Per esempio in questa fase vengono allocate le variabili statiche (e.g. quelle globali su C/C++), quindi certe variabili effettivamente hanno finito di bindare in questa fase A runtime Per esempio nelle allocazioni dinamiche, oppure allocazione su stack (che comunque √® runtime), un identificatore come un indirizzo ha finito il binding con l‚Äôoggetto denotato solamente in questo momento. Importante a questo punto √® stabilire il concetto di statico vs dinamico.\nNell‚Äôesempio di sopra i primi 3 punti sono parte del binding statico, mentre il quarto √® dinamico. Questo perch√© statico si intendono tutte le associazioni fatte dal compilatore prima dell‚Äôesecuzione del programma, mentre dinamico √® solitamente fatto dalla macchina astratta al momento dell‚Äôesecuzione\nLifetime üü© Bisogna in questa fase fare una distinzione della vita dell‚Äôassociazione e vita dell‚Äôoggetto denotato.\nIn certi casi si pu√≤ avere che la vita dell‚Äôassociazione √® minore di quella dell‚Äôoggetto denotato, questo pu√≤ succedere per esempio quando l‚Äôassociazione √® cambiata (quindi distrutta e ricreata in altro modo), anche un cambio di ambiente (e quindi di blocco pu√≤ avere lo stesso effetto). (oppure un oggetto passato per riferimento nella chiamata di funzione, la vita del binding all‚Äôinterno della funzione resta quella)\nIn altri casi pu√≤ succedere che la vita dell‚Äôoggetto denotato sia minore dell‚Äôassociazione, questo pu√≤ capitare per esempio quando un oggetto allocato dinamicamente sia stato liberato, mentre l‚Äôassociazione non lo sia, si parla in questo caso di dangling reference.\nAmbiente √à l‚Äôinsieme di associazioni fra identificatori e oggetti denotati in un certo momento dell‚Äôesecuzione a uno specifico punto.\nIn certi punti di esecuzione del programma pu√≤ succedere che uno stesso oggetto √® denotato da pi√π nomi, in questo caso si dice che i nomi sono degli alias fra di loro.\nTipologie di ambiente (3) üü© Facciamo distinzione fra tre tipologie principali di ambiente:\nLocale (quelli creati dal blocco corrente) Non Locale (quelli creati da blocchi superiori (quindi quelli che non sono dichiarati localmente in pratica). Globale (quelli creati nel blocco pi√π sopra possibile, solitamente all‚Äôinizio del nostro programma) Blocco pi√π esterno Codice importato Operazioni sull\u0026rsquo;ambiente (5) üü© Dato che l‚Äôambiente √® l‚Äôinsieme di associazioni, questo sono anche operazioni sui nomi.\nNaming Quando proprio viene creato un nuovo collegamento con un oggetto. (aka dichiarazione). Unnaming Quando il collegamento viene distrutto Referencing Quando viene utilizzato un nome per accedere a un oggetto (quindi nessuna creazione qui). Attivazione binding Quando il collegamento con un oggetto viene ricreato Disattivazione binding Operazioni sugli oggetti (4) üü© Queste operazioni sembrano le classiche che si fanno per i databases:\nAccesso (sola lettura dell‚Äôoggetto) Modifica (scrittura sull‚Äôoggetto) Creazione Eliminazione dell‚Äôoggetto. Da notare la similitudine con il framework CRUD citato in HTTP e REST\nBlocchi Definizione üü® Un blocco testuale di codice, in cui sono dichiarate localmente delle variabili, che ha un inizio e una fine chiara.\nIn generale si fanno distinzione fra\nBlocchi procedurali (come le funzioni in pratica) Blocchi anonimi (sono blocchi in line che si possono mettere in qualunque posto del codice). Per√≤ a volte √® meglio creare delle regole specifiche del linguaggio che dipendano dal creatore del linguaggio. non vorremmo ad esempio poter utilizzare la variabile prima che fosse dichiarata. (ma dipende dalla pragmatica del linguaggio (oppure sintattica, dipende comunque da come √® stato progettato questo linguaggio)).\ne.g.\n{ a = 1; int a; } Questo per molti linguaggi dovrebbe essere un errore, di semantica statica! ma a seconda delle regole sintattiche potrebbe essere corretto (potrebbe essere una a esterna, se esiste).\nUn discorso simile si pu√≤ fare per le funzioni, che possono essere visibili o meno prima della dichiarazione o meno. Ma non credo questi dettagli siano troppo importanti, dopo un p√≤ capisci dai‚Ä¶\nAnnidamento üü© L‚Äôannidamento dei blocchi deve soddisfare alcune caratteristiche, per esempio non possono esistere delle intersezioni parziali fra blocchi quindi che siano tipo ABAB (con primo A l‚Äôinizio del blocco, e secondo A la fine). In un certo senso la stringa che deve esserci deve essere palindroma.\nVisibilit√† üü© Una dichiarazione locale ad un blocco √® visibile in quel blocco e in tutti i blocchi in esso annidati, a meno che non intervenga in tali blocchi una nuova dichiarazione dello stesso nome (che nasconde, o maschera, la precedente)\nQuesto principio di visibilit√† pu√≤ essere espresso in maniere differenti, ecco cos√¨ che si creano lo scoping statico e dinamico.\nRegola di Scope La regola di visibilit√† non √® definita in modo disambiguato, pu√≤ essere interpretato in modo differente:\nEsempio\nA seconda di una interpretazione di Scoping, che √® anche detta regola di visibilit√† che √® qulel enunciata poco sopra, stampa risultati diversi. In questa parte proviamo a fare pi√π chiarezza riguardo questo aspetto qui.\nPer capire bene questa parte sullo scope sarebbe meglio andare a guardare come di solito √® implementato, questo √® spiegato in Gestione della memoria\nStatico (3) üü© 3 Regole descrivono bene lo scoping statico\nL‚Äôambiente locale ha solamente in s√© le dichiarazioni locali del blocco (direi che √® una convenzione, poi col punto 2 ha pi√π senso questo mini algo, che vai a cercarti te). Se non viene trovato va a cercare nel blocco sopra, fino ad arrivare allo scope globale, se ancora qui non c‚Äô√® allora vado nelle built-in, se nemmeno qui c‚Äô√® allora errore (algoritmo stupido per fare la ricerca dell‚Äôassociazione). Per i blocchi con nome, il nome √® anche presente nello scope sopra (cos√¨ posso fare la ricorsione) Da notare che nello scoping statico quello che importa √® la struttura del nostro programma. Questo ci da alcuni vantaggi:\nFacile comprensione (perch√© non dobbiamo eseguire, basta leggere il programma, capire la struttura e sappiamo il binding corretto) Velocit√† (il compilatore si pu√≤ tenere degli offset per capire quale √® la variabile corretta a cui accedere). Per√≤ per tenersi lo scoping statico √® leggermente pi√π difficile perch√© non basta una stack, come invece √® per lo scope dinamico.\nDinamico üü© Lo scope dinamico √® molto pi√π semplice da implementare rispetto lo scope statico, √® guidato da questa unica regola.\nL‚Äôoggetto a cui si riferisce un nome X √® quella dichiarata pi√π recentemente a run-time, a patto che l‚Äôassociazione sia ancora attiva.\nQuindi se ci teniamo una stack di blocchi attivi (che poi vengono poppati, l‚Äôultima ad essere poppata √® il blocco globale, quello principale) √® molto facile seguire il percorso creazione di tutte le variabili per un blocco, e distruzione quando si esce dal blocco.\nSolitamente lo scope dinamico non viene mai utilizzato. (pi√π lento e meno leggibile, bisognerebbe sempre leggere).\nRidefinizione di variabili globali per funzioni, questo si potrebbe considerare una possibilit√† dello scope dinamico di gestire input per variabili globali:\nEsempio in slide\nIl modo corretto per fare questa cosa √® dichiarare la funzione in modo che accetti come parametro un altro colore.\n","permalink":"https://flecart.github.io/notes/nomi-e-scope/","summary":"I Nomi e oggetti Oggetti denotati e identificatoriüü© I nomi sono sequenze di caratteri o numeri aka: token alfanumerico (anche IDENTIFICATORE (per token guardare Grammatiche Regolari) utilizzate principalmente come Astrazione sul controllo e sui dati (quindi sono cose molto pi√π facili da ricordare rispetto il suo encoding binario o a indirizzi). Infatti utilizziamo i nomi per evitare di interessarci di informazioni come l‚Äôindirizzo di memoria del nostro dato o per creare una interfaccia con visibili solo nome della procedura e parametri.","title":"Nomi e Scope"},{"content":"Questi network bayesiani sono proprio dei grafi, che permettono una migliore comprensione delle relazioni causali o diagnostici fra le probabilit√†\nEsempio rete bayesiana\nNote generali Introduzione alla rete classica Una rete bayesiana ci permette di semplificare di molto il calcolo della full disjoint probability table, rendendola in questo modo\nOssia andiamo a utilizzare una probabilit√† locale, o sparsa per fare i conti, cosa che semplifica molto, e quindi velocizza il calcolo. v\nConditional probability table Ogni nodo deve avere anche una tabella per i valori di probabilit√† condizionale.\nIl mantello di Markov Il mantello di un nodo nell rete √® l‚Äôinsieme dei genitori, dei figli, e dei genitori dei figli, costituisce l‚Äôinsieme per cui il nodo attuale √® condizionalmente indipendente da tutti gli altri nodi.\n√à una nozione molto forte questa, che ha implicazioni molto profonde, un esempio √® Karl Friston che lo usa per fare delle argomentazioni forti sull‚Äôorigine della vita dalla zuppa primordiale.\nRete con variabili continue In cui servirebbe una base di analisi molto forte e anche di probabilit√† e statistica (quindi conoscere anche dal punto di vista matematico cosa sia la distribuzione normale etc).\nInferenza esatta Possiamo andare ad utilizzare le reti per calcolare il valore di probabilit√† di un evento, in questa parte si vede come.\nPer enumerazione Si va con la classica definizione di probabilit√†, andiamo a contare tutto, e ci√≤ ci comporta un tempo esponenziale di calcolo.\n$$ P(X \\mid e) = \\alpha P(X, e) = \\alpha \\sum_{y} P(X, e, y) $$ Pseudocodice\nEliminazione di variabili Con il metodo precedente, pu√≤ succedere che facciamo lo stesso calcolo molteplici volte, questa √® una chiarissima inefficienza. Si pu√≤ risolvere facendo una eliminazione di variabili in modo tale:\nPseudocodice\nAlgoritmi di clustering L‚Äôidea principale di questo √® raggruppare dei nodi in un nodo pi√π grosso.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Bayesian Networks/Untitled 6.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Bayesian Networks/Untitled 6\u0026quot;\u0026gt; Sampling (inferenza approssimata) ora andiamo ad utilizzare un metodo di monte carlo, che abbiamo visto per la prima volta (se non c‚Äô√® √® perch√© sono stato pigro e non l‚Äôho scritto) in Adversarial Search.\nPraticamente andremo a fare sampling di un evento tante volte, e cercheremo di carpirne delle informazioni con cui aggiornare il nostro modello.\nSampling diretto It\u0026rsquo;s the classical sampling method.\nSampling con rifiuto Accept Reject algorithm explains this algorithm in a better manner\nImportance sampling Monte carlo integration there is a section about monte carlo integration\nSimulazione con catene di Markov ","permalink":"https://flecart.github.io/notes/bayesian-networks/","summary":"Questi network bayesiani sono proprio dei grafi, che permettono una migliore comprensione delle relazioni causali o diagnostici fra le probabilit√†\nEsempio rete bayesiana\nNote generali Introduzione alla rete classica Una rete bayesiana ci permette di semplificare di molto il calcolo della full disjoint probability table, rendendola in questo modo\nOssia andiamo a utilizzare una probabilit√† locale, o sparsa per fare i conti, cosa che semplifica molto, e quindi velocizza il calcolo.","title":"Bayesian Networks"},{"content":"Introduction √à una cosa ormai risaputa che c\u0026rsquo;√® una sorta di trade-off fra la varianza e il bias per una certo modello. Aumentare la varianza del modello certamente ci permetter√† di avere un modello che abbia un errore di training molto basso, per√≤ appena vede dei dati nuovi non sar√† in grado di generalizzare correttamente. Dall\u0026rsquo;altra parte avere un bias alto significa avere un modello eccessivamente semplice, poco flessibile, che comunque allenato non riesce ad avere una grande accuratezza n√© in fase di allenamento, n√© di in fase di validazione o di test.\nMathematical decomposition Si pu√≤ derivare una decomposizione di questo trade-off da un punto di vista matematico, quanto enunciato √® dimostrato nel capitolo 8.1.1 delle Note di andrew NG 229 stanford proviamo a descrivere in modo molto leggero quanto presente in quelle note qui. Solitamente vogliamo minimizzare la loss, descritta come $$ \\mathcal{L}(\\theta) = \\mathbb{E}_{(x, y) \\sim \\mathcal{D}} [(y - h_{\\theta}(x))^{2}] $$ Assumiamo che in $y$ ci sia presente del rumore causato dalla misurazione, e che la famiglia di funzioni descritta da $h$ riesca a modellare la distribuzione reale, questo ci motiva a descrivere $y = h_{\\theta^{*}} + \\varepsilon$ dove $\\varepsilon$ √® l\u0026rsquo;errore intrinseco data dalla misurazione e $\\theta^{*}$ √® la parametrizzazione migliore esistente.\nAllora abbiamo: $$ MSE(x) = \\mathbb{E}[(y - h_{\\theta}(x))^{2}] = \\mathbb{E}[(h_{\\theta^{*} }+ \\varepsilon - h_{\\theta}(x))^{2}] \\mathbb{E}[\\varepsilon^{2}] + \\mathbb{E}[(h_{\\theta^{*}}(x) - h_{\\theta}(x))^{2}] $$\nQuesto si pu√≤ scomporre ancora assumendo l\u0026rsquo;esistenza di un modello medio. (vedere derivazione 121 delle note). Avremo alla fine che $$ MSE(x) = \\sigma^{2} + \\text{ bias}^{2} + \\text{ variance} $$ Dove $\\text{ bias} = h_{\\theta^{*}}(x) - h_{avg}(x)$ e la varianza uguale ad altro.\nDall\u0026rsquo;espressione matematica, deriviamo che anche nel caso in cui riusciamo ad eliminare del tutto la varianza e il bias, rimarrebbe l\u0026rsquo;errore irriducibile di cui abbiamo parlato in Introduction to statistical learning.\nConsiderazioni generali Questo trade-off √® nato principalmente nell\u0026rsquo;analisi teorica dei modelli, per√≤ √® bene tenere in mente la presenza di ci√≤ anche per i modelli reali. Non possiamo calcolare esplicitamente il MSE, per√≤ ci dovrebbe essere. Questa √® l\u0026rsquo;osservazione principale per asserire che non sempre il modelli pi√π complicato √® la migliore, abbiamo il no-free-lunch theorem!\nStatistical learning framework Introduction to the problem We will introduce the most common statistical learning framework. There will be a lot of new words to learn for this setting. We will have\nA classifier $h : \\mathcal{ X} \\to \\left\\{ 0, 1 \\right\\}$ mapping our data to a label, taken from a set $\\mathcal{H}$ of all possible hypothesis. Then pairs $(x, y)$ which are training examples and our dataset. A dataset $S_{in} = \\left( (x_{1}, y_{1}), \\dots, (x_{m}, y_{m}) \\right)$ our learning algorithm will be identified as an $\\mathcal{A} : \\text{ training sequence } \\to \\text{ classifier }$. So our training algorithm will output a classifier, which we call it in this manner: $h = A(S_{in})$ and we would like this to be correct, which means that $h(x) = y$. for most of our examples. We will briefly introduce also a simple error measure for this theory. There will be mainly two approaches, one based on statistics the other one based on game theory. We will briefly touch both of them. The statistical approach has been mainly explored by the famous Vapnik, then explored by Valiant. We point to (Shalev-Shwartz \u0026amp; Ben-David 2014) as a good resource for the statistical learning approach. We now assume that our dataset $(X, Y)$ is drawn from $D$ which is unknown. We assume that our data is i.i.d. which is a very strong assumption, but useful to give a general feeling about the field. We define a concept of risk also called loss, which we describe as $$ l_{D}(h) = P(h(X) \\not = Y) $$ Which is just the probability that our classifier is wrong.\nWe call the realizable case this $\\inf_{h \\in \\mathcal{H}} l_{D}(h) = 0$ Sometimes is interesting to try to characterize the expected loss, i.e. the value $\\mathbb{E}_{A}[l_{D}(A(S_{m}))]$. We define the optimal risk to be $\\inf_{h \\in \\mathcal{H}} l_{D}(h)$.\nWe define the excess risk to be $E_{m} (A, \\mathcal{H}) = \\sup_{D} (\\mathbb{E}\\left[ l_{D} (A(S_{m}))\\right] - \\inf_{h \\in \\mathcal{H}} l_{D}(h))$ We would like to minimize this, because this is the worst case scenario for a certain algorithm $A$. We say that the set of hypothesis $\\mathcal{H}$ is learnable if $E_{m}(\\mathcal{H}) = \\inf_{A} E_{m}(A, \\mathcal{H}) \\to 0$. as $m \\to \\infty$ (i think $m$ is number of training cases??)\nWe call the empirical risk minimizer to be $\\text{ erm}_{\\mathcal{H}} (S)$ to be classifier $\\mathcal{H}$ that minimizes classification mistakes on $S$. Now that we have these definitions we can ask some questions.\nIs $\\mathcal{H}$ learnable? How can we minimize the excess risk? how can we learn $\\mathcal{H}$ fast? Learnability We now try to further define the problem\nReferences [1] Shalev-Shwartz \u0026amp; Ben-David ‚ÄúUnderstanding Machine Learning: From Theory to Algorithms‚Äù Cambridge University Press 2014\n","permalink":"https://flecart.github.io/notes/bias-variance-trade-off/","summary":"Introduction √à una cosa ormai risaputa che c\u0026rsquo;√® una sorta di trade-off fra la varianza e il bias per una certo modello. Aumentare la varianza del modello certamente ci permetter√† di avere un modello che abbia un errore di training molto basso, per√≤ appena vede dei dati nuovi non sar√† in grado di generalizzare correttamente. Dall\u0026rsquo;altra parte avere un bias alto significa avere un modello eccessivamente semplice, poco flessibile, che comunque allenato non riesce ad avere una grande accuratezza n√© in fase di allenamento, n√© di in fase di validazione o di test.","title":"Bias Variance Trade-off"},{"content":"il livello isa √® il livallo delle istruzioni\n8.1 Struttura Solitamente le istruzioni sono divise in due parti:\n8.1.1 Opcode e indirizzamento Opcode\nQuesto opcode indica la tipologia di istruzione.\nPer esempio per l\u0026rsquo;architettura HACK √® il primo bit, che indica se √® una istruzione C oppure una istruzione A.\nQuesto insieme poi alle altre istruzioni che definiscono cosa deve fare costituiscono OPcode.\nIndirizzamento\nPoi c\u0026rsquo;√® una sezione che indirizza, cio√® dice all\u0026rsquo;istruzione cosa deve prendere e dove deve salvare.\n8.2 Indirizzamento 8.2.1 Diretto chiamato un indirizzamento diretto quando l\u0026rsquo;istruzione deve contenere l\u0026rsquo;informazione della memoria su come operare:\nun esempio √® $inc[5]$ per dire di incrementare il valore all\u0026rsquo;indirizzo 5\n8.2.2 Immediato Ha gi√† l\u0026rsquo;operando da usare. Quindi nel caso dell\u0026rsquo;architettura HACK, per l\u0026rsquo;istruzione A ho gi√† quello che devo fare\n8.2.3 Registro diretto Questo √® l\u0026rsquo;indizzamento solito, si utilizza il nome simbolico per dire su quale registro operare.\nAd esempio:\ninc dx in cui sto direttamente incrementando il registro\n8.2.4 Registro indiretto un esempio di indirizzamento indiretto √®\ninc [dx] in cui sto andando a operare sulla locazione di memoria contenuta in dx.\nQuindi prende la locazione di dx, che pu√≤ essere 5 10 o quel che i vuole e poi opera su questo.\n√à molto simile al diretto, ma utilizza i registri\n8.2.5 Indicizzato Per esempio :\ninc [dx + 5] Prendo l\u0026rsquo;indirizzo di dx e ci prendo un offset\nDi solito pu√≤ essere utile per activation record, che non so cosa sia, o accedere a certo tipo di strutture.\n8.2.6 con Stack Questa √® una indicizzazione molto utilizzata, tanto che ci sono dei registri apposta.\nAlcune operazioni solite sono pop e push, e la presenza di un registro sp che mantiene la locazione attuale dello stack (un pointer!)\nAnche questo per activation record\n8.3 Tipologie di istruzioni 8.3.1 Dati da memoria a registro.\nRegistro a registro e simili\n8.3.2 Aritmetico-logiche binarie Quindi somme, divisioni moltiplicazioni sottrazioni.\n8.3.3 Unarie Per esempio shift. (moltiplicazione o div per due)\nDi solito risparmiamo molte istruzioni a livello assembli utilizzando le operazioni unarie.\n8.3.4 Salti Quindi spostamento del PC che contiene l\u0026rsquo;istruction register\n8.3.5 Invocazione procedure In hack queste non esistono, ma esistono per la maggior parte delle altre architetture.\nQuesto salta alla procedura poi fa un return sulla procedure vecchia (si dice chiamata di stack)\nQuindi sono due comandi in pi√π che non esistono per il nostro calcolatore\n8.4 Procedure 8.4.1 Activation record Quando viene chiamata una procedura, si crea un nuovo frame, salvando\nVariabili locali delle nuova chiamata Un puntatore alla vecchia istruzione Quando si ritorna alla istruzione precedente tutta questa roba, questo nuovo frame, viene eliminato.\nEsempio di chiamata di procedure\n8.5 Trap \u0026amp; interrupt Questi due gestiscono errori del programma. NO\n8.5.1 Caratteristiche del trap Questo errore viene chiamato nel caso in cui ci siano accessi non consentiti come\nOpcode non definito (strano, succede solo se codice corrotto o sistema sballato) Un accesso a memoria non consentita Questo √® gestito dal sistema operativo con un gestore di trap. Quindi togliere il controllo (e ucciderlo) al programma con la forza grazie al sistema operativo.\n8.5.2 Differenze con Interrupt La differenza principale √® che interrupt √® chiamato dall\u0026rsquo;esterno e interpretato grazie al sistema opertivo: per esempio il ctrl-c per ucciderei l programma. Questo √® gestito da interrupt Service Routine - ISR. Si pu√≤ dire che sono asincroni mentre le trap sono sincrone.\nEs. quando la lezione √® interrota da una domanda a cui si vuole rispondere.\n8.5.3 Priorit√† dell\u0026rsquo;interrupt La CPU pu√≤ scegliere di non seguire gli interrupt, si parla di interrupt mascherati nel caso in cui ci sia un lavoro molto importante (per esempio passare da un thread all\u0026rsquo;altro, qualcosa di strano che non dovrebbe essere interrotto mentre sta operando).\nOppure anche per scegliere delle priorit√† se tastiera o disco e simili..\nTipo se il prof non risponde subito alla domanda e dice che lo far√† dopo.\n8.5.4 Busy waiting √à una altra soluzione all\u0026rsquo;interrupt, cio√® ogni 100 millisecondi il sistema operativo va a guardare se esiste un input umano. Ovviamente √® molto inefficiente. (in pratica sta aspettando se il disco ha finito per ricominciare a fare le cose normali).\n8.5.5 Polling √à molto simile al busi waiting, per√≤ invece di non fare nulla e aspettare soltanto quando non va a guardare, fa qualche operazione.\nTipo il prof che chiede se ci sono delle domande. e al busi waiting, per√≤ invece di non fare nulla e aspettare soltanto quando non va a guardare, fa qualche operazione.\nTipo il prof che chiede se ci sono delle domande.\n","permalink":"https://flecart.github.io/notes/livello-isa/","summary":"il livello isa √® il livallo delle istruzioni\n8.1 Struttura Solitamente le istruzioni sono divise in due parti:\n8.1.1 Opcode e indirizzamento Opcode\nQuesto opcode indica la tipologia di istruzione.\nPer esempio per l\u0026rsquo;architettura HACK √® il primo bit, che indica se √® una istruzione C oppure una istruzione A.\nQuesto insieme poi alle altre istruzioni che definiscono cosa deve fare costituiscono OPcode.\nIndirizzamento\nPoi c\u0026rsquo;√® una sezione che indirizza, cio√® dice all\u0026rsquo;istruzione cosa deve prendere e dove deve salvare.","title":"Livello ISA"},{"content":"Ripasso: May 19, 2023 Ultima modifica: May 11, 2023 8:38 PM Primo Abbozzo: May 5, 2023 2:21 PM Studi Personali: No\nMetadati web https://csunibo.github.io/tecnologie-web/lucidi/teoria/23-metadati.pdf https://csunibo.github.io/tecnologie-web/lucidi/teoria/24-a-web-semantico-lod-rdf-json-ld.pdf\ninconfrontabilit√† del sapere Stessa informazione in forme diverse Stessa parola per cose diversa. Serializzazione La semantica √® relegata alle applicazioni che devono decidere in che modo interpretarli, oppure esseri umani.\nPICS Platform for Internet Content Selection vuole cercare di tenere sotto controllo i materiali del film. √à un sistema di rating. ‚Üí tanti criteri di classificazione a seconda dei criteri ideologici su cui voglio andare a basarmi.\nClassificare e categorizzare, non`e una cosa centralizzata da parte di un governo. Fonte terza, non √® n√© l\u0026rsquo;usufruitore ne il creatore ‚Üí metadati = dati sui dati. Metadati Slide medatati\nvantaggi e svantaggi\nTesauri e tassonomie Si parla di gerarchizzazione e di relazione fra parole dello stesso livello\nTassonomia linneo Esempio di tassonomia La cosa che generalizza Esempi di relazioni has_a is_a instance of Classificazione a faccette possibilit√† di descrivere un oggetto complesso attraverso un insieme di affermazioni appartenenti ad uno schema fisso di propriet√†, ciascuna delle quali in grado di usare valori da un apposito tesauro.\nOntologie Vocabolario controllato Organizzato in thesaurus Una ontologia √® un sistema di classi, descritta da propriet√† che hanno valori puri o riferimenti ad istanze di altre classi (credo che questa cosa sia molto simile anche in database o simili).\nCritica alle ontologie\nComplessivamente, sono un approccio costoso, ingessato, non democratico, centralizzato e riduzionistico.\nFolksonomie Semantic web Resource description framework - RDF Sono delle triple soggetto predicato e oggetto, e posso creare degli alberi che sembrano delle tassonomie a riguardo.\nUna cosa interessante √® che tutto √® identificato da URI, nomi, predicati e oggetti, a volte ci sono degli elementi vuoti chiamati blank nodes.\nbisogna distinguere questo formato di triple con il formato di serializzazione che √® la forma in cui sono rappresentati sottostante.\nProblema delle relazioni n-arie Reificazione üü• La differenza principale con la modellizzazione a relazione n-aria √® che il blank era il soggetto e tutti erano oggetti di questo, mentre ora ogni cosa pu√≤ essere soggetto oppure oggetto. In particolare rdf:statement sub, pred, obj, ci sono sempre queste predicati per la reificazione.\nSlide reificazione\nMa ha un problema per i databases perch√© non vengono trovati le relazioni soggetto - predicato - oggetto classici.\nNamed graph Slide named graph\nossia ho sempre delle triple, ma queste sono messe a livello differente.\nSerializzazioni Serializzazione significa dare una sintassi per andare a descrivere le informazioni di rdf in modo che sia possibile metterli in database.\nTurtle RDF/XML JSON-LD Generazione di conoscenza utilizzare il database RDF per andare a generare nuove informazioni Andare a verificare la coerenza delle informazioni che abbiamo gi√† RDF schema √à l\u0026rsquo;insieme dei concetti possibili per un certo RDF.\nSlides rdf schema\nWeb Ontology language (OWL) SPARQL ","permalink":"https://flecart.github.io/notes/metadati-web-e-web-semantico/","summary":"Ripasso: May 19, 2023 Ultima modifica: May 11, 2023 8:38 PM Primo Abbozzo: May 5, 2023 2:21 PM Studi Personali: No\nMetadati web https://csunibo.github.io/tecnologie-web/lucidi/teoria/23-metadati.pdf https://csunibo.github.io/tecnologie-web/lucidi/teoria/24-a-web-semantico-lod-rdf-json-ld.pdf\ninconfrontabilit√† del sapere Stessa informazione in forme diverse Stessa parola per cose diversa. Serializzazione La semantica √® relegata alle applicazioni che devono decidere in che modo interpretarli, oppure esseri umani.\nPICS Platform for Internet Content Selection vuole cercare di tenere sotto controllo i materiali del film.","title":"Metadati web e web semantico"},{"content":"Il suo scopo principale √® gestire l\u0026rsquo;avvicendamento dei processi. Ad esempio sospendere il processo che chiede I/O. O un sistema time sharing, quando arriva un interrupt sul time.\nSolitamente il nome scheduler √® solamente un gestore dell\u0026rsquo;avvicendamento, si pu√≤ quindi utilizzare per indicare scheduler di altro tipo.\nNote introduttive Diagramma di Gantt Questo √® il diagramma per presentare lo scheduling, ossia da quando a quando √® eseguito cosa\nEsempio gantt\nMode switch (link) üü© il mode switch √® il passaggio fra user e kernel e viceversa, di cui abbiamo parlato in Note sull‚Äôarchitettura. si continua con lo stesso processo con permessi maggiori.\nContext switch (4) üü© Context switch invece si passa da un processo all‚Äôaltro, e bisogna salvare lo stato del vecchio processo nel PCB, come descritto in Processi e thread.\nEsempio context switch\nServe un mode switch, fanno cose, un altro mode switch, e stessa sequenza per tornare indietro, sono 2 context swithc qui\nCause del context switch\nSlide descrizione delle cause\nNota che per certe cause √® necessario fare un context switch in altri casi no.\nVita di un processo üü© Si parla di tutti i passaggi fra int\nSistema attesa e interrupt\nPraticamente il processo continua a runnare finch√© non lo fermano, con una syscall, con un interrupt di time slice oppure quando fa una syscall bloccante.\nQuando √® pronto a riprendere viene rimessa nella coda ready, e questa sar√† la coda gestita dallo scheduler.\nCatalogazione scheduler Preemptive e non-preemptive üü© Slide descrizione preempty non preemptive\nNon-preemptive √® quando cambio processo solamente se cedo io, processo, il controllo.\nMentre preemptive √® quando posso cambiare in ogni singolo caso.\nVantaggi dello scheduling cooperativo non richiede alcuni meccanismi hardware come ad esempio timer programmabili Potevi monopolizzare la CPU se programmavi male. Vantaggi dello scheduling preemptive permette di utilizzare al meglio le risorse per questo motivo gli scheduler sono sempre preemptive ora. Le risorse considerate (2) üü© Vogliamo ora trovare un modo per decidere in che modo decidere quale processo far partire e quale no.\nSlide scelta dello scheduler\nSistemi batch\nUtilizzo della risorsa CPU, vorremmo che la CPU stia sempre a lavorare. Massimizzare il numero di processi completati, ossia massimizzare il throughput, se ci mette poco lo faccio. Turnaround time, ossia minimizzare il tempo di risposta, da quando il processo √® sottomesso (issued) a quando √® completato Sistemi interattivi\nTempo di attesa deve essere minimizzato (il tempo di attesa nella ready queue) Tempo di risposta deve essere minimizzato (vorrei avere feedback molto veloce), almeno non percepibile dall‚Äôumano. When a request that is perceived as complex takes a long time, users accept that, but when a request that is perceived as simple takes a long time, users get irritated.\nSistemi real-time\nIl fatto che un processo venga runnato prima di un certo tempo (altrimenti si perdono un p√≤ di dati)\nLibro sui metodi di valutazione dello scheduler\n√à importante questa parte perch√© sulle slides vengono valutati solamente turnaround e throughput!\nNOTA: il tempo di utilizzo della CPU √® l√¨ riportata ma non √® una buona misura!\nAlgoritmi di scheduling (!!) FIFO: First come first served üü© Questo √® l\u0026rsquo;algoritmo pi√π banale, cio√® appena arriva un processo. √à una cosa molto semplice da implementare.\nSolitamente non √® molto veloce, buono per microcontrollori o comunque ambienti molto semplici. Per esempio se ho qualcosa che √® CPU bound ritarda un sacco tutti quei processi IO bound\nEsempio di processo lento\nAltro esempio con convoy effect\nQuando ho il convoy effect, ho continuamente il process dispendioso che fa ritardare tutti, e ci sono intere zone vuote.\nProcessi CPU bound piccoli vanno dopo CPU bound larghi, √® una cosa probabilistica, questo motiva la scelta di fare i lavori corti prima.\nShortest Job first üü©‚Äî Slide shortest Job first\nSi pu√≤ notare che il tempo di turnaround e il tempo di attesa scendono di molto! ma come sapere quanto tempo ci metteranno ad eseguire? Non si pu√≤ sapere a priori.\nSi pu√≤ anche dimostrare che √® la miglior soluzione possibile, per√≤ non √® possibile capire il cpu burst, posso solamente fare delle approssimazioni, che non sono per forza vere, non √® possibile implementarle\nMEDIA ESPONENZIALE\nQuesto √® la media che si utilizza per approssimare, √® la stessa media per le previsioni meteorologiche, che tengono conto del tempo.\nSlide media esponenziale\nVERSIONE PREEMPTIVE\nPraticamente √® un shortest remaining time first, che a seconda della predizione, si mette ad eseguire quello col tempo rimanente pi√π piccolo. (nota potrebbe essere negativa la previsione).\nPer la versioen non-preemptive si lascia\nRound robin üü© Slide round robin\nQuesta √® una soluzione pensata per sistemi interattivi, e a seconda del numero di questi processi, √® possibile definire il quanto di tempo, ossia il massima durata in cui pu√≤ rimanere in esecuzione, poi deve essere switchata.\nDeve essere abbastanza corto che il tempo non sia percepibile umanamente, in questo senso sono interattivi.\nQuando √® in coda si mette in FIFO.\nNon conviene mettere il quanto di tempo troppo piccolo perch√© si perderebbe troppo per switchare\nIMPLEMENTAZIONE\nC\u0026rsquo;√® bisogno di un timer che genera interrupt ogni tot tempo, questo √® il quanto di tempo per il round robin. Questa √® proprio una cosa necessaria. per implementarlo.\nQuesto interrupt √® settato! Nel senso ogni tot tempo da quando lo ho fatto partire.\nEsempio\nScheduling a priorit√† üü© In questa parte i concetti importanti sono:\nDifferenza priorit√† statica e dinamica I metodi per assegnare la priorit√† Aging (si implementa in un modo simile ai bit history visti in Paginazione e segmentazione Il sistema classi di priorit√† √à necessario un concetto di priorit√†, ad esempio se faccio video, non vorrei che sia rallentato da un servizio di posta, il primo ha bisogno di maggiore interattivit√†, quindi avrei bisogno questo concetto di priorit√†.\nLa priorit√† pu√≤ essere statica (che potrebbe fare starvation) o dinamica, per la dinamica si utilizza la tecnica di aging, in cui un processo ha una priorit√† naturale, che continua ad essere aumentato man mano resta nella coda di priorit√†.\nstatica si better for sistemi realtime per raggiungere.\nPossiamo anche fare classi di priorit√† diverse e scelta la classe si pu√≤ utilizzare la politica .\nQuesta politica √® molto simile a quello utilizzato nei router in Data Plane.\nServer Interattivi Processi utente FIFO demoni e vuoti FIFO banali Slide priorit√† (TODO: approfondire)\nEsempio: https://www.geeksforgeeks.org/multilevel-queue-mlq-cpu-scheduling/\nSISTEMI A REALTIME (non fare) Ci sono certe cose aperiodiche e periodiche. Periodico come reattori nucleari che devono stare a guardare sempre qualcosa (come cose per i reattori nucleari).\nPer periodici come rate monotonic (praticamente a priorit√†, quelli a frequenza alta sono di alta priorit√†) o earliest deadline first.\nSpiegazione di chatGPT\nRate Monotonic Scheduling (RMS): Rate Monotonic Scheduling is a widely used real-time scheduling algorithm. The RMS algorithm is based on priority assignment to periodic tasks, where the task with the shortest period has the highest priority. The scheduling of tasks is done in a way that the higher-priority task always preempt the lower-priority task.\nThe RMS algorithm assumes that the execution time of all tasks is known in advance and that there are no other sources of delay, such as I/O or interrupts. This is known as the \u0026ldquo;static scheduling\u0026rdquo; assumption.\nEarliest Deadline First Scheduling (EDF): Earliest Deadline First (EDF) is another real-time scheduling algorithm. In EDF, each task has a deadline, and the task with the earliest deadline is scheduled first. The deadlines can be either hard (absolute) or soft (flexible). Hard deadlines must be met, while soft deadlines can be missed, but a penalty is incurred for each missed deadline.\nLike RMS, EDF is based on the assumption of static scheduling, which means that the execution time of tasks is known in advance and there are no other sources of delay. EDF can also handle aperiodic tasks, which do not have a fixed period but must be executed within a specified time limit.\nThe key difference between RMS and EDF is that RMS uses a fixed priority assignment based on task period, while EDF assigns priority dynamically based on the task deadline.\nIn summary, both RMS and EDF are real-time scheduling algorithms used to schedule tasks in real-time systems. RMS assigns priority based on the task period, while EDF assigns priority dynamically based on the task deadline.\n","permalink":"https://flecart.github.io/notes/scheduler/","summary":"Il suo scopo principale √® gestire l\u0026rsquo;avvicendamento dei processi. Ad esempio sospendere il processo che chiede I/O. O un sistema time sharing, quando arriva un interrupt sul time.\nSolitamente il nome scheduler √® solamente un gestore dell\u0026rsquo;avvicendamento, si pu√≤ quindi utilizzare per indicare scheduler di altro tipo.\nNote introduttive Diagramma di Gantt Questo √® il diagramma per presentare lo scheduling, ossia da quando a quando √® eseguito cosa\nEsempio gantt","title":"Scheduler"},{"content":"Questa sezione la tengo separata rispetto agli altri per favorire lo studio, cos√¨ questa roba nuova la ripasso pi√π spesso, in seguito si pu√≤ accorpare.\nGoldberg Tarjan/Push-relabel Questo algoritmo √® importante perch√© introduce ragionamenti sul minimo locale che possa alla fine essere ricomposto come soluzione globale.\nQuesta lezione youtube lo spiega da Dio\nPreflusso üü© Slide\nLa parte nuova di questa cosa √® che i vincoli di bilanciamento possono diventare una disuguaglianza. (cio√® quello che arriva √® di pi√π rispetto quanto va fuori.\nAndiamo inoltre a definire un concetto di attivit√† del nodo, ossia il fatto o meno che abbia un eccesso di flusso in entrata (e che quindi io abbia cose da mandare fuori ancora).\nPush forward e backward üü© Slide\nVogliamo utilizzare un algoritmo locale che sposti il flusso in avanti oppure all‚Äôindietro, questi sono gli unici modi per spostare flussi in giro.\nPseudocodice üü®+ Slide\nSi noti che √® presente un sistema di etichettatura utilizzato per tenere sotto controllo il costo\nNOTA ERRORE: Devono tornare a 5 invece che a 6\nL‚Äôetichettatura üü©- L‚Äôetichettatura per questo algoritmo √® fondamentale. Lo utilizziamo principalmente per evitare che ci siano push che poi vadano a ciclo, cosa molto brutta dato che non finirebbe mai l‚Äôalgoritmo.\nSi fa una etichettatura iniziale in questo modo:\nSparo al massimo tutti gli archi che partono da S. Metto N l‚Äôaltezza di S, e 0 tutto il resto. In questo modo vengono soddisfatte queste INVARIANTI:\nil Label per S √® sempre N il label per L √® sempre 0 Esiste un arco nel grafo residuo fra v, w solo se $h(v) \\leq h(w) + 1$ Noi vorremmo pushare solamente se ho una relazione del tipo $h(v) = h(w) + 1$, ossia esattamente pi√π alto di 1.\nAnalisi del costo üü©+ Slide\nSul perch√© sia vero non lo presenta, bisogna fare un approfondimento a riguardo.\nSe si sceglie il nodo di altezza massima si avr√† alla fine un costo di $O(N^3)$.\nFlusso di costo minimo algoritmi simili a ford fulkelson non sono molto buoni per trovare la migliore soluzione per questo, vorremmo andare a cercare il pseudoflusso del costo minimo!\nPseudoflusso üü© Slide\nIntuitivamente sto prendendo qualunque flusso che soddisfi i vincoli di capacit√†, ma che non √® sufficiente per soddisfare i vincoli di bilanciamento sui nodi.\nNodi di eccesso e difetto e sbilanciamento compressivo üü© Slide\nCon la nozione di pseudoflusso √® utile fare questa differenza.\n$O_x$ i nodi con eccesso di flusso quindi $e$ positivo, ci√≤ che entra √® di pi√π\n$D_x$ il contrario. ci√≤ che esce √® di pi√π.\nQuesti sono molto importanti, perch√© vorremmo far partire ed arrivare flusso dai nodi O ai nodi D, in modo da renderli bilanciati. E poi vorremmo avere il percorso di costo minimo.\nCammini aumentanti üü©- Slide\nIn sta parte viene esteso il concetto di cammino aumentante introdotto in precedenza per introdurre il costo di un cammino aumentante.\nUna cosa in pi√π √® che si pu√≤ partizionare l‚Äôinsieme degli archi nel cammino. Questa cosa sar√† utile per calcolare il costo\nCosto dei cammini aumentanti üü© Slide calcolo costo cammino aumentante\nQuesto √® un concetto nuovo rispetto a quello passato perch√© prima non si faceva caso ai costi, invece ora s√¨.\nTh struttura equivalenza dei pseudoflussi (!!) üü© Enunciato\nNota, inizio e fine dei cammini\n√à un teorema molto forte, dati due pseudoflussi qualunque, possiamo legare questi due con un numero di cammini aumentanti!\nLa dimostrazione non si fa üòÄ.\nDimostrazione in dispensa\nTh struttura del pseudoflusso minimo (!) üü©- Enunciato e dimostrazione\nHint per ‚Üê\nConsideriamo il nostro pseudoflusso, per ipotesi non √® minimale, allora esiste un altro pseudoflusso di costo minore con gli stessi vettori di sbilanciamento, allora per il teorema precedente pu√≤ essere applicato, posso trasformare uno nell‚Äôaltro.\nLa parte difficile da qui √® trovare il ciclo con costo negativo. Per sapere questo bisogna fare un p√≤ meglio il teorema precedente, infatti si pu√≤ dire che tutti i percorsi sono dei cicli!\nQuindi il pseudoflusso di costo minimo √® strettamente legato all\u0026rsquo;esistenza di cicli aumentanti di costo negativo!. Quindi vogliamo andare a togliere questi cicli, se riesco a togliergli tutti allora possono trovare il pseudoflusso minimale.\nNOTA: si ricordi che gli pseudoflussi si possono confrontare fra di solo solo se hanno gli stessi sbilanciamenti!.\nTh pseudoflusso minimo con aggiornamenti (!!!) üü© Enunciato e dimo\nhint a dimostrazione\nDobbiamo prendere il cammino aumentante di costo minimo e poi anche il flusso di costo minimo! Questi due sono gli ingredienti fondamentali per questo teorema qui.\nE s√¨ tal cred, sta roba √® nell\u0026rsquo;enunciato\nDimostrazione\nCome mai quella relazione riguardo i theta? Perch√© altrimenti avrei che lo sbilanciamento fra start-finish sarebbe diverso.\nQuesto √® il teorema principale che ci garantisce l‚Äôinvariante! Riusciamo a mantenere lo pseudoflusso di costo minimo in seguito alle operazioni di update con i cammini aumentanti!\nQuindi si pu√≤ costruire un algoritmo che utilizza questa propriet√†\nTrova un pseudoflusso minimo fra tutti quelli con lo stesso vettore di sbilanciamento Aggirona finch√© c\u0026rsquo;√® cammino aumentante Quando non posso pi√π aggiornare ho finito, ho il pseudoflusso di costo minimo, e di flusso massimo. Algoritmo cammini minimi successivi Pseudocodice algo üü©‚Äî Per avere uno pseudoflusso minimale basta non avere cicli di costo negativo, vedremo fra poco come far ci√≤.\nDa notare che ora l‚Äôaggiornamento tengo conto anche del minimo fra inizio e arrivo! Ricordo che il mio obiettivo √® risolvere gli sbilanciamenti\nCorrettezza e terminazione üü©‚Äî Slide\nQuindi se termina allora √® corretto per i teoremi precedenti. Riguardo la terminazione riesco a fare ragionamenti sulla capacit√† del flusso, che posso dire che √® sempre intero, e diminuisci almeno di uno, quindi se andiamo a fare un bound sullo sbilanciamento iniziale riusciamo a fare una stima sul numero di iterazioni necessarie per finire.\nComplessit√† üü© Slide\nQuesto dipende fortemente dipende dallo sbilanciamento iniziale e dal tempo per trovare il cammino minimo (eg. bellman ford).\nAlgoritmo eliminazione cicli negativi Questo √® un altro algoritmo utilizzato per trovare il flusso minore, l\u0026rsquo;obiettivo √® trovare un qualunque flusso ammissibile, e poi togliere tutti i cicli negativi che trovo, in questo modo so per teorema precedente che il flusso che ho trovato √® il minore possibile.\nSe non sbaglio questo algoritmo √® acnhe chiamato algoritmo del ciclo di klein e ha complessit√† pseudopolinomiale di $O(m^2nCU)$ dove C √® la capacit√† massima e U il costo massimo. Il ragionamento per questa complessit√† √® che mi costa mn per Bellman ford per trovare il ciclo, e lo faccio diminuendo al massimo mCU volte (che √® il lower bound per il costo minimo).\nCostruzione flusso ammissibile üü© Vogliamo costruire un qualunque flusso ammissibile, e vogliamo cambiarlo in modo che essa abbia anche il costo minimo.\nRisolvere il problema di maximum flux, in questo modo ho un flusso ammissibile di flusso massimo Poi vado a cercare i cicli negativi, questi non cambiano nessun bilanciamento, e abbassano solamente il costo. So che il minimo costo sar√† quello che non avr√† cicli di costo negativo. In questo modo Ho trovato la migliore soluzione.\nPseudocodice üü© Slide\nAnalisi del costo e correttezza üü© Slide\nil bound per il numero di iterazioni √® molto banale, in pratica vado a considerare il massimo costo possibile, so che almeno diminuisce di 1 ad ogni iterazione, pi√π un costo di bellman ford per trovare i cicli. costo:\n$$ O(NA) \\cdot O(Auc) = O(NA^2uc) $$ ","permalink":"https://flecart.github.io/notes/tarjan-e-mcmf/","summary":"Questa sezione la tengo separata rispetto agli altri per favorire lo studio, cos√¨ questa roba nuova la ripasso pi√π spesso, in seguito si pu√≤ accorpare.\nGoldberg Tarjan/Push-relabel Questo algoritmo √® importante perch√© introduce ragionamenti sul minimo locale che possa alla fine essere ricomposto come soluzione globale.\nQuesta lezione youtube lo spiega da Dio\nPreflusso üü© Slide\nLa parte nuova di questa cosa √® che i vincoli di bilanciamento possono diventare una disuguaglianza.","title":"Tarjan e MCMF"},{"content":"Questo argomento √® stato trattato durante dopo la discussione dei Massimi minimi multi-variabile, per√≤ √® stato ripreso anche nella forma R to R, quindi credo necessiti di un foglio a parte.\nAffine set Lines Let\u0026rsquo;s take two points in $\\mathbb{R}$ $x_{1}, x_{2}$, if we consider the parametrization $$ x = \\theta x_{1} + (1 - \\theta)x_{2} $$ This is a parametrization of the line Example:\nDef: affine set A combination where the coefficients add up to 1. We can say that this set is unique given two points.\nExample: solution of $\\left\\{ x \\mid Ax = b \\right\\}$ is an affine set (easy to prove). It can be proven that every affine set is a solution of such set of algorithms\nConvex sets It\u0026rsquo;s an affine set, where $0 \\leq \\theta \\leq 1$. Sometimes it\u0026rsquo;s written like $\\left[ x_{1}, x_{2} \\right]$. Sometimes this is called a convex combination of the two values.\nEvery element of the set sees each other clearly, this is the intuitive notion of the convex sets Convex combination Given $x_{1}, x_{2}, \\dots, x_{k}$ then a convex combination is (sometimes called mixture, or weighted average, or expectation)\n$$ x = \\theta_{1}x_{1} + \\dots + \\theta_{n}x_{n} $$ Where $\\theta_{1} + \\dots + \\theta_{n} = 1, \\theta_{i} \\geq 0$\nConvex Hull It\u0026rsquo;s the convex combination of all points in $S$. (so it\u0026rsquo;s defined by the borders usually). It can be viewed as the Smallest convex set that contains a set of points!\nConvex Cone Here we don ¬¥t have the requirement that it all sums to one. so $x_{1}, x_{2}$, the convex cone is the set of points such that exists $\\theta_{1}, \\theta_{2}$ that $$ x = \\theta_{1}x_{1} + \\theta_{2}x_{2} $$ Proper:\nClosed (contains borders) Has an interior (some point in the middle of the borders). Doesn\u0026rsquo;t contain lines (pointed) It\u0026rsquo;s convex Norm Cone $$ \\left\\{ (x, t) \\mid \\lVert x \\rVert \\leq t \\right\\} $$ Also known as Lorentz cone (probably used for things related to relativity).\nPositive Semidefinite Cone Let $S^{n}$ be the set of symmetric matrices with $n$ elements, of dimension $\\frac{(n + 1)n}{2}$. $S^{n}_{++}$ denotes the positive definite set, with one $+$ indicating semidefinite. Sub-level set $f: \\mathbb{R}^{n} \\to \\mathbb{R}$ such that:\n$$ C_{\\alpha} = \\left\\{ x \\in dom f \\mid f(x) \\leq \\alpha \\right\\} $$ It\u0026rsquo;s a function that it\u0026rsquo;s the best limited to a certain value $\\alpha \\in \\mathbb{R}$\nWe call a level set the set of points where there is equality: $$ S_{\\alpha} = \\left\\{ x \\in dom f \\mid f(x) = \\alpha \\right\\} $$ Epigraph of function $$ epi f = \\left\\{ (x , t) \\in \\mathbb{R}^{n + 1} \\mid x \\in dom f, f(x) \\leq t \\right\\} $$ it\u0026rsquo;s the part of the function that is bigger or equal to the function.\nRelation with convex functions the function $f$ is convex iff $epi f$ is a convex set. So if $f$ creates a convex set above it, we can say it\u0026rsquo;s convex, this is a bridge between functions and geometry.\nConvessit√† e Concavit√† Definizione di convessit√† Funzione $f : \\mathbb{R}^{n} \\to \\mathbb{R}$ √® convessa se vale, con $0 \\leq \\theta \\leq 1$ $$ f(\\theta x + (1 - \\theta)y) \\leq \\theta f(x) + (1 - \\theta) f(y) $$ Concavo se $-f$ √® convesso\nL\u0026rsquo;approccio seguente √® quella fatta in analisi, ma √® abbastanza brutta. √à convessa se la derivata seconda √® diversa da 0, ma non √® una buona definizione perch√© non √® direttamente relazionata con la concavit√†.\nPossiamo definire la funzione secondo le tangenti, potremmo dire che la retta tangente sia sempre minore del grafico, in altro modo √® una forma di tailor!\n$f: A \\to R$ tale che f sia derivabile, allora se prendo un intervallo $(a,b) \\subseteq A$ posso dire che la funzione √® convessa in questo intervallo se $\\forall x,k \\in (a,b)$ ottengo che\n$f(x) \\geq f(k) + f'(k)(x -k) = T_1(x)$\nDefinizione vera Non vorremmo avere una definizione che dipenda dall\u0026rsquo;esistenza della derivata, quindi sia f una funzione ben definita, allora √® convessa sse $\\exists m$ nel dominio per cui valga che $f(x) \\geq f(y) + m(x - y)$\nOppure:\nDefinizione secondo libro (con i segmenti)\nAllora cerchiamo una definizione migliore:\nsia $f : \\mathbb{R}^n \\to \\mathbb{R}$ allora questa funzione si dice convessa sse $\\forall t \\in [0,1]$ si ha che\n$\\forall a,b \\in \\R^n: f(tb + (1 - t)a) \\leq t f(b) + (1-t) f(a)$ se vale con $\u003c$ posso dire che √® strettamente convessa.\nIntuizione:\nComunque prenda un punto all\u0026rsquo;interno di un intervallo ho che la funzione valutata in questo punto √® minore della somma della congiungente di questi due punti.\nConditions of convex functions Convex function to a line Consider $g(t) = f(x + tv)$ where the domain of $g$ are the $t$ such that $x + vt$ are in the domain of $f$. Then $f \\text{ is convex } \\iff g \\text{ is convex}$\nFirst-order condition in $\\mathbb{R}$ Questo √® un risultato molto simile a quanto ottenuto con le funzioni crescenti e la loro derivata prima, che si pu√≤ trovare in Teoremi Base Analisi.\nEnunciato Sia una funzione $f: \\mathbb{R} \\to \\mathbb{R}$, allora $f$ √® convessa sse la sua derivata prima √® $\u003e0$.\nLa dimostrazione √® abbastanza diretta quindi la si omette. (per√≤ la dovresti fare lo stesso perch√© √® importante).\nHintini di dimostrazione $\\implies$ Supponiamo che f sia convessa, allora vale quella formula in definizione, voglio dimostrare che la derivata sia crescente. (scrivo quella definizione due volte e ottengo qualcosa del tipo $0 \\geq$ intervallo * (intervallo funzione, e si pu√≤ risolvere senza molti problemi ottenendo il voluto, bisogna fare soprattutto attenzione a come definisci questi indici se vuoi andare a farlo in modo formale. $\\impliedby$ Supponiamo che la derivata sia crescente, allora poi vado ad utilizzare lagrange (due volte, prima con un intervallo x y tale che $x \u003c y$ e poi il contrario) fatto questo utilizzo la crescenza della derivata per concludere Corollario Possiamo utilizzare il risultato sopra per concludere che una funzione √® convessa sse la derivata seconda √® maggiore uguale a 0 (si possono utilizzare i teoremi riguardante le relazioni fra derivate e crescenza per questa).\nSegmento in Rn e convessit√† di punti Dati due punti in $\\mathbb{R}^n$ si pu√≤ individuare il segmento in due punti $x, y$ come l\u0026rsquo;insieme costituito da\n$\\{x + t (y - x) | t \\in [0,1]\\} = [x, y]$\nSI pu√≤ verificare che che √® uguale alla linea che li collega, in particolare √® una retta parametrica. Avendo questa definizione di segmento, posso andare a definire l\u0026rsquo;insieme convesso per Rn!.\nConvessit√† di un insieme di punti\nUn insieme di punti si dice convesso se $\\forall a, b \\in A \\subseteq \\mathbb{R}^n, [a,b] \\subseteq A$ (e la definizione di insieme concavo non esiste, potremmo dire non convesso, ma non che sia concavo).\nAvendo questo si pu√≤ dimostrare che l\u0026rsquo;intersezione di semipiani √® convesso.\nFirst-order condition in $\\mathbb{R}^{n}$ Possiamo allargare la definizione di funzione convessa che abbiamo dato poco fa in modo che ora sia buona anche a funzioni di pi√π variabili.\nf una funzione continua e differenziabile ovunque, allora √® convessa sse $\\forall a,b \\in A$ si ha che\n$f(a) \\geq f(b) + \\nabla f(b)^{T}(a - b)$ e per parlare di funzione concava basta rovesciare la disuguaglianza.\nQuesta formula da l\u0026rsquo;idea che la funzione deve essere sempre sopra al piano tangente per ogni punto! Si pu√≤ vedere come primo ordine Taylor approx ad un certo punto.\nNotiamo che se $b$ √® un punto di minimo, allora per fermat abbiamo che $\\nabla f(b) = 0$, questa √® una propriet√† locale che ci permette di avere una condizione globale: ossia abbiamo $\\forall a, b: f(a) \\geq f(b)$.\nSecond-order condition in $\\mathbb{R}^{n}$ sia $A \\subseteq \\mathbb{R}^n$ che sia aperto e convesso, sia $f\\in C^2(A) \\to \\mathbb{R}$ allora $f$ √® convessa su A $\\iff$ $Hf(x) \\geq 0, \\forall x \\in A$.\nNon √® definito ora il concetto di crescenza per un gradiente, o vettore, quindi vogliamo passare prima sul gradiente. Una funzione √® convessa sse la matrice hessiana √® semi-definita positiva. Sia la espansione di taylor come l\u0026rsquo;abbiamo definita prima (con resto secondo Lagrange). Pu√≤ essere utile dare un occhiata al teorema di Lagrange al secondo ordine a pi√π dimensioni prima\n$f(w + vt) = f(w) + \\langle \\nabla f(w), v \\rangle t + \\dfrac{1}{2}\\langle Hf(c)v,v\\rangle t^2$\nDimostrazione $\\impliedby$ Dato che $\\dfrac{1}{2}\\langle Hf(c)v,v\\rangle t^2 \\geq 0$ posso conclude la convessit√† (ossia la disuguaglianza appare abbastanza in fretta) $\\implies$ Assumiamo ora la convessit√†, vogliamo dimostrare che la hessiana sia semidefinita positiva. Per l\u0026rsquo;espansione di taylor ho che $f(a + h) = f(a) + \\langle\\nabla f(a), h\\rangle + \\dfrac{1}{2}\\langle H(f(a + \\theta h)) h, h\\rangle$ definendo a, h e theta correttamente. Per la convessit√† ho che $f(a + h) \\geq f(a) + \\langle\\nabla f(a), h \\rangle$ e questo vale $\\forall h : a + h \\in A$ Ma allora so che $\\dfrac{1}{2}\\langle H(f(a + \\theta h)) h, h\\rangle \\geq 0$ (perch√© altrimenti ci sarebbe un valore in input per cui nonvale la condizione di convessit√†.\nDevo dimostrare che $v \\in \\mathbb{R}^n \\neq 0 : a + v \\in A$, $\\langle H(f(a)) v, v\\rangle \\geq 0$, scelgo una successione in questo modo: $h_k = 1/k \\cdot v$ che tende a 0 per k che tende a infinito. Definito in questo modo ho che c\u0026rsquo;√® un theta per cui valga $\\dfrac{1}{2}\\langle H(f(a + \\theta v/k)) v/k, v/k\\rangle \\geq 0 \\iff \\dfrac{1}{2}\\langle H(f(a + \\theta v/k)) v, v\\rangle \\geq 0$ arrivato a questo punto mando k all\u0026rsquo;infintio e utilizzo\nPer continuit√† ho che il limite $\\lim_{k \\to \\infty}$ √® uguale a $\\langle H(f(a)) v, v\\rangle$ la permanenza del segno per concludere il voluto (se ogni elemento della successione √® maggiore di 0 allora anche il limite a cui sta tendendo √® maggiore di 0)\nSome properties Monotone slope property Consider the slope of a function at a certain point $t$ w.r.t. a point $x$ in the domain. $$ s_{f, x}(t) = \\frac{f(x + td) - f(x)}{b} $$ As $t$ increases the slope increases. The intuition of the proof is easy, just take two slopes and see that by convexity the point of the lower slope is under the slope of the higher derivative.\nTh: $s(t)$ is monotonically non-decreasing.\nDirectional derivatives We consider the directional derivative $f'(x; d)$ is $$ f'(x;d) \u003e \\lim_{ t \\to 0 } \\frac{f(x + td) - f(x)}{t} $$ This definition is cool because convex functions always have directional derivatives, even if the original function is not derivable.\nStrong Convexity Se say that a function $f$ si $\\mu$ strongly convex if the first order condition is satisfied with another bound: $$ f(y) \\geq f(x) + \\langle \\nabla f(x) , y - x \\rangle + \\frac{\\mu}{2}\\lVert x - y \\rVert ^{2} $$ Per qualche motivo avendo questa propriet√† possiamo sviluppare Metodi di Discesa migliori che utilizzino anche questa informazione.\nHow to know if a set is convex Definition application Try to prove the #Convex combination theorem. Aka, $\\forall x_{1}, x_{2} \\in C, 0 \\leq \\theta \\leq 1 \\implies \\theta x_{1} + (1 - \\theta)x_{2} \\in C$ But this is the last resort, not advised by prof. Stephen Boyd\nComposition of convex-preserving operations If we can create the $C$ by using this composition we can still have a convex set!\nIntersection is convex The intersection of convex sets is convex\nThis is easily provable.\nExample of interesting case: Consider $p(t) = x_{1}\\cos t + \\dots + x_{n}\\cos nt$ The set $\\left\\{ x \\in \\mathbb{R}^{n} \\mid \\lvert p(t) \\rvert \\leq 1 : t \\in \\left[ 0, \\frac{\\pi}{3} \\right] \\right\\}$ is convex. (It\u0026rsquo;s easy to show that this is an intersection of slabs (see lecture 2, the idea is beautiful, although not formally defined or proved, but it seems intuitive!))\nAffine functions are convex preserving Affine functions preserve convex sets\nIf we apply an affine function (that is just linear function + $b$) aka : $f(x) = Ax + b$. Because the inverse of affine is affine (if it exist), also the inverse of affine functions are inverse. This is easy to prove too.\nPerspective functions are convex preserving $P : \\mathbb{R}^{n + 1} \\to \\mathbb{R}^{n}$ is a perspective function (lower dimensional!)\nFor example a function is $P(x, t) = \\frac{x}{t}$\nImages and inverse images of convex sets under perspective are convex\nNot sure why is it true.\nAffine-fractional functions are convex preserving $$ f(x) = \\frac{Ax + b}{c^{T}x + d} $$ Example of these functions are mapping from 3D in computer geometry to flat camera views.\nTeoremi importanti Jensen Questo √® uno dei teoremi legati alla convessit√† (concavit√† pi√π usati in assoluto). Una applicazione classica √® per il il valore atteso, analizzato in Variabili aleatorie e simili. La cosa carina √® che lui non l\u0026rsquo;ha inventato, ma ha detto che tipo 14 tizi stavano usando sta cosa, senza chiamarla per nessun nome, quindi l\u0026rsquo;ha popolarizzato.\nSia $f$ una funzione convessa in un intervallo $[a, b] \\subseteq \\mathbb{R}$, allora vale che $$ f(\\lambda a + (1 - \\lambda)b) \\leq \\lambda f(a) + (1 - \\lambda) f(b) $$ Questa √® la formulazione semplice, ma si pu√≤ estendere per qualunque combinazione convessa dell\u0026rsquo;input (per combinazione convessa di $a_{1}, a_{2}, \\dots, a_{n}$ intendo $a_{1}\\lambda_{1} + \\dots + a_{n}\\lambda_{n}$ dei parametri $\\lambda_{1}, \\lambda_{2}, \\dots, \\lambda_{n}$ tale per cui $\\sum_{i=1}^{n}\\lambda_{i} = 1$).\nNon so bene la dimostrazione, ma l\u0026rsquo;intuizione √® abbastanza semplice in due variabili, se combini due punti su una retta sopra la funzione, questa sar√† maggiore del valore che ricevi combinando gli input, dato che √® convessa √® una funzione ad $U$.\nJensen for quasi convex functions $$ f(\\lambda a + (1 - \\lambda)b) \\leq \\max (f(a), f(b)) $$ Convexity preserving operations Pointwise Supremum If we take the max of some convex functions, this max is convex. (It\u0026rsquo;s intuitive if we see the max as the intersection of the epi sets of the functions!) In maths:, given convex functions\nSame with the infimum we can say that if $f(x, y)$ is convex for $(x, y) \\in C$ then $$ g(x) = \\inf_{y \\in C} f(x, y) $$ Is convex, sometimes called partial minimization. (partial maximization is convex too!). This could be used to prove something about shur\u0026rsquo;s complement but I don\u0026rsquo;t remember it.\nComposition of scalar functions Given $f : \\mathbb{R}^{n} \\to \\mathbb{R}$ and $h : \\mathbb{R} \\to \\mathbb{R}$ then the function $f = h(g(x))$ is convex if $g$ and $h$ is and $\\hbar$ is nondecreasing. Also if $g$ is concave and $\\hbar$ is nonincreasing.\nA good way to remember this is proving it for $n=1$ and it\u0026rsquo;s differentiable so you can get it back.\nThis argument is extendable to multiple dimensions, the same conditions hold, just for different indexes.\nGiven $g: \\mathbb{R}^{n} \\to \\mathbb{R}^{k}$ and $h: \\mathbb{R}^{k} \\to \\mathbb{R}$ Then $f(x) = h(g(x)) = h(g_{1}(x), \\dots, g_{k}(x))$ is convex is\n$g_{i}$ is convex, $h$ is convex and $\\hbar$ is nondecreasing in each argument $g_{i}$ is concave, $h$ is convex and $\\hbar$ is nonincreasing in each argument. Easy to prove something like $\\sum -\\log(x_{i})$ is convex. This is a more general test than the others.\nPerspective functions the perspective of $f: \\mathbb{R}^{n} \\to \\mathbb{R}$ is a function $g: \\mathbb{R}^{n} \\times \\mathbb{R} \\to \\mathbb{R}$ $$ g(x, t) = tf(x / t) $$ Where the domain of $g$ is $\\left[ (x , t) \\mid x / t \\in dom f, t \u003e 0 \\right]$\nIf a function $f$ is convex, so is it\u0026rsquo;s perspective!\nConjugate function This is also known as the Legendre Transform in physics, take a look at it here.\nThe conjugate function of $f$ is $$ f^{*}(y) = \\sup_{x \\in dom f} (y^{T}x - f(x)) $$ And this function is convex, even if $f$ is not! The intuition is that this is the supremum of an affine function, so it should be more intuitive that that is linear! Usually when we are talking about conjugates, we expect that the conjugate of the conjugate is the original thing. In this case, it not true. In this case it\u0026rsquo;s the convex envelope, but it\u0026rsquo;s not important here.\nQuasi-convex function $f$ quasi convex if $dom f$ sub-level sets are convex for all $\\alpha$. (remember the sub-level sets are the parts in the domain such that are less than a value). Remember that a level set is a set of the points in the function domain such that are below a certain threshold $\\alpha \\in \\mathbb{R}$. When we say that this set is convex we say that the set is connected (doesn\u0026rsquo;t have gaps between them).\nThe intuition is that if the function goes below a certain threshold, it does it only once in the whole domain.\nConvex representation of quasi-convex If $f$ is quasi convex, there exists a $\\phi$ what is convex in the domain of $f$, when you fix $t$ you can do some interesting stuff.\nSo:\n$\\phi_{t}(x)$ is convex for fixed $t$. $f_{0}(x) \\leq t \\iff \\phi_{t}(x) \\leq 0$. You can do binary search on the $t$ which is better and then solve a convex function. TODO: try to understand this better.\n","permalink":"https://flecart.github.io/notes/analisi-di-convessit%C3%A0/","summary":"Questo argomento √® stato trattato durante dopo la discussione dei Massimi minimi multi-variabile, per√≤ √® stato ripreso anche nella forma R to R, quindi credo necessiti di un foglio a parte.\nAffine set Lines Let\u0026rsquo;s take two points in $\\mathbb{R}$ $x_{1}, x_{2}$, if we consider the parametrization $$ x = \\theta x_{1} + (1 - \\theta)x_{2} $$ This is a parametrization of the line Example:\nDef: affine set A combination where the coefficients add up to 1.","title":"Analisi di Convessit√†"},{"content":"Introduzione ai condensatori Analisi introduttiva condensatori: tubi di flusso üü© Consideriamo un **tubo di flusso infinitesimo** come in immagine. abbiamo che $dQ$ √® la carica totale dentro al cubo. Tale che segua le linee di campo. Il flusso totale sarebbe $$ \\oint_{\\Sigma} \\vec{E} \\cdot d\\vec{s} = \\frac{Q_{T}}{\\varepsilon_{0}} $$ Sappiamo anche che $$ \\vec{E}_{1}d\\vec{s}_{1} + \\vec{E}_{2}d\\vec{s}_{2} = \\frac{dQ_{T}}{\\varepsilon_{0}} $$ Ma scegliamo il cubo di flusso in modo che le superfici siano **perpendicolari al nostro campo**, e cos√¨ posso considerare il problema da un puro punto di vista **scalare**. Sapendo che nell'esempio sott il campo non √® esistente, allora posso scrivere il campo elettrico che va fuori, semplicemente in punto di vista scalare: $$ E_{2} = \\frac{dQ}{\\varepsilon_{0}ds_{2}} $$ esChe √® molto molto simile alla forma $\\frac{\\sigma}{\\varepsilon_{0}}$. il parametro di nostro interesse in questo esempio (almeno la cosa di nostro interesse) √® *il concetto di distanza*, se ci allontaniamo dalla nostra superficie, $dS_{2}$ diventa pi√π larga Introduzione ai condensatori üü© Poniamo di avere due armature metalliche qualsiasi, che abbiamo cariche uguali ed opposte in segno di una forma qualunque a distanza qualunque, in questo setting teorico. La cosa interessante √® che suppongo di avere #Induzione completa in questo caso. √à una necessit√† per l\u0026rsquo;analisi dei condensatori.\nPotenziale elettrico e carica üü®+ Proviamo a seguire una linea di campo elettrico per studiare il potenziale elettrico, andiamo quindi a definire un **tubo di flusso**. Per risultato precedente abbiamo che $E_{i} = \\frac{dQ_{i}}{\\varepsilon_{0}dS_{i}}$ $$ V_{A} - V_{B} = \\int _{A}^{B} \\vec{E}_{i} \\, dr_{i} = \\int _{A}^{B} {E}_{i} \\, dr_{i} = \\int _{A}^{B} \\frac{dQ_{i}}{\\varepsilon_{0}dS_{i}}\\, dr_{i} = dQ_{i} \\int _{A}^{B} \\frac{1}{\\varepsilon_{0}dS_{i}}\\, dr_{i} $$ Portando dall\u0026rsquo;altra parte abbiamo $$ dQ_{i} = \\frac{V_{A} - V_{B}}{\\int \\frac{1}{\\varepsilon_{0}dS_{i}}\\, dr_{i} } $$ Poi sommo la carica di tutti i singoli tubettini di flusso, dato che abbiamo induzione completa (che non abbiamo ancora discusso, abbiamo allora che\n$$ Q = \\sum_{i=1}^{N}dQ_{i} = (V_{A} - V_{B})\\sum_{i=1}^{N}\\frac{1}{\\int \\frac{1}{\\varepsilon_{0}dS_{i}}\\, dr_{i} } $$ La cosa importante √® che dipende solo dalla geometria del nostro sistema, una volta fissata √® una costante. chiamiamo quella cosa una costante geometrica si pu√≤ scrivere che $$ V_{A} - V_{B} = \\frac{Q}{C} \\implies C = \\frac{Q}{\\Delta V} $$ ossia la capacit√† del condensatore √® la carica fratto la differenza di potenziale.\nAnalisi dimensionale capacit√† üü©- $$ \\left[ C \\right] = \\frac{[Q]}{[V]} =\\left[ Q \\right] / \\left[ ML^{2} T^{-2} Q^{-1} \\right] = \\left[ Q^{2} \\right] \\left[ M^{-1}L^{-2} T^{+2} \\right] = \\left[ F \\right] $$ Massa per velocit√† alla seconda per l\u0026rsquo;energia.\nUn Farad, ma essendo una quantit√† molto grande, difficile da usare, si utilizza il $1\\mu F$ che sono presenti nei circuiti, ma se ho troppa carica forse √® difficile da utilizzare (o hanno usi diversi).\nCondensatori piani Consideriamo un classico caso in cui abbiamo due condensatori piani, con la stessa carica, e area $=S$ Approssimazione\nConsideriamo le linee di campo del tutto parallele (campo come se fosse un piano infinito per chiarirci). Facce sono infinite (ma poi nella realt√† cambia solamente ai bordi). Campo elettrico in ogni regione üü© Si pu√≤ notare che Calcolo della direzione\nSinistra: √® 0 Centro sono $2\\vec{E}_{1} = \\vec{E}$ Destra: √® 0 Calcolo del modulo: Sappiamo che il campo elettrico per una singola armatura metallica √® $\\frac{\\sigma}{2 \\varepsilon_{0}}$, in questo caso sono uguali in modulo, e si sommano quindi:\n$$ \\vec{E} = \\frac{\\sigma}{\\varepsilon_{0}} $$ In mezzo ai conduttori. Questa analisi si pu√≤ fare con Gauss o semplicemente usando sovrapposizione, dovrebbe venire uguale, nel caso di conduttori infiniti.\nDisposizione superficiale di carica üü© Disposizione esterna Nel setting dei condensatori di sopra, possiamo chiederci dove stanno le cariche, si pu√≤ dimostrare usando Gauss che sulla superficie esterna √® nulla. Procedimento:\nPrendi una superficie cilindrica, che parte da dentro e arriva fuori a sinistra della piastra di sinistra. Sai che il campo dentro √® nullo per induzione elettrostatica Sai che fuori √® nullo perch√© hai supposto che si eliminano i campi (uguali perch√© stai assumendo siano infiniti). Quindi per Gauss la carica inclusa dovr√† essere nulla in quei punti. Disposizione interna Applico gauss con un cilindro molto simile, con un cerchio dentro (quindi campo nullo per induzione in Conduttori elettrici), ma ora l\u0026rsquo;altra estremit√† del cilindr√≤ avr√† un qualche valore:\n$$ \\oint_{\\Sigma¬¥} \\vec{E} \\cdot d\\vec{s} = \\frac{Q_{T}''}{\\varepsilon_{0}} \\implies \\oint_{\\Sigma'} \\lvert \\vec{E} \\rvert ds = \\lvert \\vec{E} \\rvert A = \\frac{Q_{T}''}{\\varepsilon_{0}} = \\frac{\\sigma A}{\\varepsilon_{0}} \\implies \\lvert \\vec{E} \\rvert = \\frac{\\sigma}{\\varepsilon_{0}} = \\frac{Q}{\\varepsilon_{0}S} $$ Abbiamo messo $S = A$ come superficie ed area, la stessa cosa in pratica. Quindi la discontinuit√† che abbiamo discusso (che non ho ancora scritto) √® ancora la stessa, solo ridisposta in modo diverso, descritto in Campo elettrico.\nPotenziale elettrico e capacit√† üü©- Utilizziamo la definizione: $$ \\Delta V = \\int _{A}^{B} \\vec{E} \\, d\\vec{r} = \\lvert \\vec{E} \\rvert \\int _{A}^{B} \\, d\\vec{r} = \\lvert \\vec{E} \\rvert d = \\frac{Qd}{\\varepsilon_{0}S} $$ Una volta ottenuto entrambi posso calcolare la capacit√†: $$ C = \\frac{Q}{\\Delta V} = \\frac{S\\varepsilon_{0}}{d} $$ E possiamo vedere che sono sempre fattori geometrici.\nCaso piani non infiniti üü© Nell\u0026rsquo;analisi soprastante, abbiamo assunto di avere piani metallici infiniti Nel caso reale:\nL\u0026rsquo;approssimazione funziona in mezzo al condensatore Ai bordi il campo inizia a curvare, quindi non √® come modellizzato di sopra. Disposizioni di condensatori Parallelo üü© Analizziamo sempre potenziali e capacit√†, da un punto di vista totale (vedendolo come un singolo condensatore). Chiamiamo a sinistra 1, a destra 2 **Osservazioni**: 1. Potenziale ai capi dei condensatori √® uguale, perch√© i primi due sopra sono collegati, cos√¨ come quelli sotto 2. Si sommano le capacit√† (e carica singole), anche perch√© √® *come se aumentassi la superficie*. $$ C_{T} = \\frac{Q_{T}}{\\Delta V} = \\frac{Q_{1} + Q_{2}}{\\Delta V} = C_{1} + C_{2} $$ In un sistema composto da due o pi√π condensatori posti in parallelo, la capacit√† totale √® pari alla somma delle singole capacit√†.\nIn serie üü® **Osservazione** 1. Conduttori su E √® isolato, quindi si *caricheranno solo per induzione*. Analizziamo le differenze di potenziali, allora abbiamo che $$ \\Delta V_{1} = V_{A} - V_{E} = \\frac{Q}{C_{1}} $$ In modo simile per il secondo, noi vogliamo trovare $\\Delta V = V_{A} - V_{B} = \\frac{Q}{C_{T}}$, ma posso usare lo stratagemma matematico e risolvere ci√≤ $$ \\Delta V = V_{A} - V_{B} = (V_{A} - V_{E}) + (V_{E} - V_{B}) = Q\\left( \\frac{1}{C_{1} } + \\frac{1}{C_{2}} \\right) = \\frac{Q}{C_{T}} \\implies \\frac{1}{C_{T}} = \\frac{1}{C_{2}} + \\frac{1}{C_{2}} $$ Possiamo vedere che la capacit√† cala, questo √® spiegato fisicamente perch√© la carica √® distribuita, mentre la superficie rimane sempre lo stesso.\nLa serie fra due o pi√π condensatori ha capacit√† totale $C_{T}$ il cui inverso √® pari alla somma degli inversi delle singole capacit√†\nEnergia nei condensatori Intuizione sul concetto di energia Partiamo sempre dal concetto di lavoro, √® equivalente al lavoro usato per caricarlo. anche chiamato autoenergia. L\u0026rsquo;energia di un sistema di cariche che cosa √®? √® il lavoro esterno compiuto per costruire il sistema, in modo pi√π intuitivo √® quanto sforzo √® stato necessario usare per partire dall\u0026rsquo;infinito e portare le particelle e portarle in quel punto. Se √® repulsiva (quindi energia positiva) io faccio lavoro positivo, altrimenti negativo, questo l\u0026rsquo;hai visto ieri. Se l\u0026rsquo;energia √® positiva posso estrarre energia da utilizzare, altrimenti no.\nEnergia di Interazione üü© L'energia di sistema (o di interazione fra le cariche) √® calcolato nel modo seguente: La prima carica non fa lavoro perch√© il campo √® nullo inizialmente La seconda carica fa un po\u0026rsquo; di fatica Se cambio l\u0026rsquo;ordine cambia l\u0026rsquo;ordine, ma l\u0026rsquo;equazione finale non cambia. (forse solo segno) $$ U_{12} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R_{12}} = q_{1} V_{21} $$ Calcoliamo l\u0026rsquo;energia necessaria per portare una terza, avremo che $$ U_{23} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{2}q_{3}}{R_{23}} = q_{2}V_{32} = q_{3}V_{23} $$ E si fa lo stesso per $U_{13}$ e poi si summa tutto Quindi in generale: $$ U_{tot} = \\sum_{i \u003c j} ^{N} q_{i}V_{ji} = \\frac{1}{2} \\sum_{i \\neq j} ^{N} q_{i}V_{ij} $$ Probabilmente il segno si deve fare attento. (Nota come semplificazione, sfruttando la sovrapposizione potremmo scrivere la roba di sopra come) $$ U_{tot} = \\frac{1}{2}\\sum_{i = 1}^{N}q_{i}V_{i} $$ Con $V_{i} = \\sum_{j\\neq i}^{N}V_{ij}$\nQuesta forma poi ci deve anche essere di interesse nel momento in cui vogliamo andare oltre al semplice caso discreto, perch√© allora possiamo scriverlo come $$ U_{tot} = \\frac{1}{2} \\int _{\\tau} \\rho V \\, d\\tau $$ E la stessa cosa vale per le superfici in pratica posso calcolare l\u0026rsquo;energia totale in ogni configurazione.\nLavoro di carica dei condensatori Primo modo: lavoro punto per punto üü®++ Consideriamo un condensatore, alla prima carica non c\u0026rsquo;√® lavoro, ma poi si crea un campo elettrico che si prova ad opporre al caricamento (quindi lavoro positivo, forza di Coulomb √® positivo).\nMan mano che si carica la $\\Delta V(q)$ cambia. Proviamo a vedere la formula superficiale. Lavoro fatto dal campo quando sposto una carica di un piccolissimo tratto. $$ dL' = \\vec{E} \\cdot d\\vec{r} = -dV $$ Lavoro della $\\vec{F}_{C}$ forza di coulomb (quello della forza esterna √® uguale e contraria). $$ dL = dq\\vec{E} \\cdot d\\vec{r} = -dqdV $$ Calcolando da A a B e sommando tutto abbiamo che (contando che il lavoro esterno deve essere opposto rispetto al nostro campo in considerazione).\n$$ \\Delta L_{E} = \\int _{A}^{B} dqdV = dq \\int _{A}^{B} \\, dV = dq \\Delta V_{q} $$ La differenza di potenziale quando le armature non sono state ancora calcolate, abbiamo che $\\Delta V_{q} = \\frac{q}{C}$ che si pu√≤ rimettere sopra, ossia il lavoro fatto nel momento in cui c\u0026rsquo;√® una piccola forza su una armatura. $$ \\Delta L_{E} = dq \\frac{q}{C} $$ $$ L_{E} = \\int _{0}^{Q} \\Delta L_{E} = \\int _{0}^{Q} \\frac{q}{C} \\, dq = \\frac{1}{2} \\frac{Q^{2}}{C} = \\frac{1}{2} Q \\Delta V = \\frac{1}{2}C \\,\\Delta V^{2} $$ Che √® esattamente il lavoro fatto per caricare il condensatore\nSecondo modo: energia di interazione üü© Posso subito dire che $$ U_{E} = \\frac{1}{2} \\left[ Q_{A} V_{A} + Q_{B}V_{B} \\right] = \\frac{1}{2} \\left[ C(V_{A} - V_{B})V_{A} + C(V_{B} - V_{A})V_{B}\\right] = \\frac{1}{2} C\\, \\Delta V^{2} $$ Densit√† di energia üü© L\u0026rsquo;energia immagazzinata √® stata utilizzata per costruire il campo. -\u0026gt; Campo elettrico porta energia! Rinnovabili per questo √® nice. Abbiamo che $$ U_{E} = \\frac{1}{2} C\\, \\Delta V^{2} \\land C=\\frac{\\varepsilon_{0}S}{d} \\land \\Delta V = Ed \\implies U_{E} = \\frac{1}{2}\\varepsilon_{0}E^{2}(Sd) = \\frac{1}{2}\\varepsilon_{0}E^{2}Volume $$ Questo ci permette di definire il concetto di densit√† di energia di un condensatore, dato che abbiamo un volume. $$ u_{e} = \\frac{1}{2}\\varepsilon_{0}E^{2} $$ Questo servir√† per il vettore di Poynting in seguito quando faremo il minimo di propagazione. (Base di energia solare, anche la parte di propagazione che ho fatto io, e spiega che si pu√≤ ottenere energia dal campo elettrico, costruendo o disfacendone).\nScarica e carica di condensatori Carica del condensatore Setting del problema üü© Ci stiamo chiedendo, come varia l\u0026rsquo;intensit√† di corrente in un circuito fatto di semplice condensatore e resistenza? In che modo cambia il potenziale? Se ho l\u0026rsquo;intensit√† di corrente per un dato momento, allora posso calcolare l\u0026rsquo;intensit√† di corrente. Possiamo usare le leggi presenti in Leggi di Ohm e osservare che vale, perch√© alla fine il campo esterno √® ancora conservativo (credo), anche se la corrente varia. $$ \\varepsilon = V_{C} + V_{R} = \\frac{q(t)}{C} + Ri(t)\n$$ In un certo istante specifico $t$, ma notiamo che per definizione, la corrente accumula sul condensatore un valore $i(t) = \\frac{dq(t)}{dt}$ e possiamo sostituire questo dentro e risolvere l\u0026rsquo;equazione differenziale associata.\n$$ \\varepsilon = \\frac{q(t)}{C} + \\frac{Rdq(t)}{dt} $$ Sono equazioni che si risolvono nella forma $Ae^{Bx}$ o qualcosa di simile, infatti possiamo sostituire questo l√¨ dentro e ricevere qualcosa cos√¨: $$ \\varepsilon = \\frac{A}{C}e^{Bt} + RABe^{Bt} $$ Ma questo non riesco a risolverlo tutto a un tratto: $$ dt\\left( \\varepsilon - \\frac{q(t)}{C} \\right) = dq(t) R \\implies \\frac{dt}{RC} = \\frac{dq(t)}{\\varepsilon C - q(t)} $$ Allora sappiamo che fra l\u0026rsquo;istante 0 in cui metto gi√π l\u0026rsquo;interruttore e il nostro tempo abbiamo: $$ \\int _{0}^{q} \\frac{dq(t)}{-\\varepsilon C + q(t))} = -\\int_{0}^{t} \\frac{dt}{RC} \\implies \\ln\\left( \\frac{-\\varepsilon C + q(t)}{-\\varepsilon C} \\right)=- \\frac{t}{RC} \\implies q(t) = -\\varepsilon C e^{-t/RC} + \\varepsilon C $$ Equazioni per la carica dei condensatori üü© Da quanto fatto sopra otteniamo che $$ q(t) = \\varepsilon C(1 - e^{-t/RC}) $$ $$ i(t) = \\frac{\\varepsilon}{R} e^{-t/RC} $$ E poi con questo posso ottenere a cascata tanti altri valori, come la differenza di potenziale sul condensatore, sulla resistenza e simili. $$ V_{c}(t) = \\frac{q(t)}{C} = \\varepsilon(1 - e^{-t/RC}) $$ E posso fare la stessa cosa per la resistenza $$ V_{b}(t) = i(t)R = \\varepsilon e^{-t/RC} $$ Come grafici questi hanno: Note sul tempo di carica üü© Nota: il condensatore non si carica mai al valore teorico di carica che pu√≤ avere (√® un asintoto orizzontale). Possiamo considerarlo carico quando √® tipo 1% del valore nominale, non ho capito esattamente perch√© questo, forse √® una convenzione.\nTempi tipici di carica sono microsecondi perch√© di solito Parliamo di micro-Farad e migliaia di Ohm di resistenza.\nSi pu√≤ notare risolvendo le equazioni di sopra otteniamo che: 0.95% -\u0026gt; 3$\\tau$ 0.99% -\u0026gt; 4.6$\\tau$ 0.999% -\u0026gt; 7$\\tau$ Per caricare il condensatore.\nPotenza erogata ed assorbita üü© Con le equazioni di sopra possiamo anche utilizzare le equazioni di energia spesa, perch√© sappiamo che il generatore eroga $$ P_{gen} = \\varepsilon i(t) = \\frac{\\varepsilon^{2}}{R}e^{-t/RC} $$ Mentre la potenza assorbita dalla resistenza √® di valore: $$ P_{b} = Ri(t)^{2} = \\frac{\\varepsilon^{2}}{R} e^{-2t/RC} $$ E possiamo notare che\n$$ P_{c} = \\frac{Vdq}{dt} = P_{gen} - P_{b} $$ Una altra cosa interessante √® che il valore del lavoro totale si pu√≤ ricalcolare con l\u0026rsquo;energia presente nel condensatore! $$ W_{gen} = \\int_{0}^{\\infty} P_{gen} \\, dt = C\\varepsilon^{2} $$ Allo stesso modo si poteva ottenere $$ W_{gen} = \\int_{0}^{q_{0}}Vdq = Vq = V^{2}C $$ E si pu√≤ togliere l\u0026rsquo;energia immagazzinata dal condensatore come $$ W_{c} = \\frac{1}{2}CV^{2} = \\frac{W_{gen}}{2} \\implies W_{r} = W_{c} $$ Scarica del condensatore Setting del problema üü© Ho un condensatore completamente carico come in figura Ad un certo punto chiudo l\u0026rsquo;interruttore e inizier√† a scorrere della carica, vogliamo capire in che modo varia $q(t)$ e in che modo varia $i(t)$\nEquazioni per la scarica dei condensatori üü© In modo simile al precedente possiamo mettere su una equazione differenziale: $$ 0 = \\frac{q(t)}{C} + \\frac{d(q)}{dt}R \\implies -\\frac{dt}{RC} = \\frac{d(q)}{q(t)} $$ E con questo abbiamo in modo del tutto analogo al precedente che $$ \\int_{q_{0}}^{q} \\, \\frac{dq}{q} = -\\int_{0}^{t} \\frac{dt}{RC} \\implies \\ln\\left( \\frac{q}{q_{0}} \\right) = -\\frac{t}{RC} \\implies q(t) = q_{0}e^{-t/RC} $$ E poi si possono fare tutte le altre cose.\nCampo magnetico in condensatore üü® Guardando Ampere e Faraday se cambia l\u0026rsquo;intensit√† del campo elettrico, come succede per questo circuito, abbiamo che si ha una densit√† di corrente di spostamento.\nCalcoliamo la circuitazione in una parte del filo (intorno a un punto, in modo classici diciamo) e allora abbiamo $$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{r} = \\mu_{0} i(t) = \\mu_{0} \\int _{\\Sigma(\\Gamma)} \\vec{J} \\cdot d\\vec{s} = \\mu_{0}(\\frac{\\varepsilon}{R} e^{-t/RC}) $$ Questo scegliendo la superficie pi√π semplice che esisteva. Posso per√≤ scegliere una altra superficie che passa dalle facce del condensatore, in questo caso io non ho corrente! Ecco che entra in gioco la correzione di Maxwell, per la corrente di spostamento. E facendo i calcoli si √® scoperto che la predizione era corretta, e il valore √® esattamente lo stesso.\n","permalink":"https://flecart.github.io/notes/condensatori-nel-vuoto/","summary":"Introduzione ai condensatori Analisi introduttiva condensatori: tubi di flusso üü© Consideriamo un **tubo di flusso infinitesimo** come in immagine. abbiamo che $dQ$ √® la carica totale dentro al cubo. Tale che segua le linee di campo. Il flusso totale sarebbe $$ \\oint_{\\Sigma} \\vec{E} \\cdot d\\vec{s} = \\frac{Q_{T}}{\\varepsilon_{0}} $$ Sappiamo anche che $$ \\vec{E}_{1}d\\vec{s}_{1} + \\vec{E}_{2}d\\vec{s}_{2} = \\frac{dQ_{T}}{\\varepsilon_{0}} $$ Ma scegliamo il cubo di flusso in modo che le superfici siano **perpendicolari al nostro campo**, e cos√¨ posso considerare il problema da un puro punto di vista **scalare**.","title":"Condensatori nel vuoto"},{"content":"Introduzione Ricordiamo che vogliamo cercare di arbitrare l‚Äôaccesso al canale fisico sottostante. In questo momento andiamo ad assumere di avere gi√† tutto l‚Äôimpianto di trasmissione fisica che abbiamo in Tecnologia Wireless, Modulazione wireless Fisica del Wireless.\nObiettivi: Arbitraggio del singolo canale fisico (la tesi di dottorato del prof era su collision avoidance di wifi). Sia in tempo Sia in spazio (come gestire il segnale mandato nello stesso spazio) Utilizzo minimo di energia Quality of service Adaptive behaviour (come il 6G che vuole andare ad utilizzare AI per fare predizione). Evitare segnale spaghetti o jammed Collisioni fanno sprecare energia ad entrambi (sia ricevente sia sender) bisogna trovare un metodo per fare risoluzione (controllare il sender riguardo la trasmissione, in quanto non sono in grado di trasmettere e ascoltare in modo contemporaneo) Questo si lega alla parte di arbitraggio del canale Ricordiamo che ethernet provava ad ascoltare il segnale e provare a trasmettere, si pu√≤ utilizzare la stessa cosa anche qui? No, ethernet permetteva di ascolatare il segnale nel momento di generazione, mentre wifi non pu√≤, perch√© semplicemente il segnale prodotto localmente √® molto pi√π grande. Inoltre wifi ha anche bisogno di fare multiplexing sullo spazio non solo nel tempo come per l‚Äôethernet.\nAnticollisione primo tentativo Allora, in questa parte continuiamo ad analizzare un protocollo che tenti di evitare la collisione, si pu√≤ utilizzare un sistema simile ad ethernet?\nRisposta negativa: non evita le collisioni Slide fenomeno\nNonostante i senders non sentano niente, c\u0026rsquo;√® interferenza, credo si chiami anche problema del terminale nascosto, perch√© non senti l‚Äôinterferenza (asimmetria di informazioni).\nNon arbitra niente alla fine‚Ä¶ Classificazione accesso multiplo MAC-WIFIüü© Senza contesa, ossia si cerca di evitare la contesa della rete wifi Centralizzati statici, con un coordinatore statico che dica quando puoi comunicare (prenotazioni registrate da un coordinatore) ‚Üí garanzia del servizio Costo coordinatore (centralizzato, quindi se cade cade tutto, facile da attaccare) Costo allocazione statica delle risorse. token-based chi vuole comunicare tiene solamente il token (solo che il rischio √® che si perda il token per una interferenza o simili). Content, provare a prendersi il segnale, o provare finch√© non ci si riesce. Probabilistico √® quello pi√π sicuro dal punto di vista della sicurezza, e ha allocazione dinamica di servizi (provare a comunicare a tempi random, probabilisticamente parlando provandoci cos√¨ prima o poi si comunicher√†). Solo che ha il problema delle collissioni ,quindi sarebbe molto buono questo metodo di allocazioen dinamica con il server centrale (0 collisioni e 0tempi vuoti). Solo che il coordinatore ha un costo. ‚Üí reliability della comunicazione. Deterministico (mi sono distratto a configurare alacritty e non ho capito). Abbiamo un accesso probabilistico in cui si prova a comunciare nel vuoto (nel senso che non si pu√≤ spegnere questa rete, nel caso della presenza di un accesso centralizzato allora si utilizza quella. (ma nessuno paga))\nAloha protocol Funzionamento in breveüü© √à stato uno dei primi protocolli radio presenti. Stiamo parlando di 1970, Abramson1970 era alle Hawaii e aveva solamente dispositivi radio a disposizione, sono le prime sperimentazioni.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Mac Wifi/Untitled 2.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Mac Wifi/Untitled 2\u0026quot;\u0026gt; Il round trip time veniva calcolato, se non riceve l‚Äôack aspetta un tempo un p√≤ random. (il seme sar√† diverso, tipo l‚Äôid della scheda di rete, il tempo di backoff che coincida √® abbastanza basso)\nAnalisi dominio di collisioneüü© Ci vogliamo chiedere quando √® il time frame in cui pu√≤ avvenire una collisione?\nSiano due comunicanti, che devono entrambi trasmettere, se uno trasmette, quando non potrebbe trasmettere l √°ltro per evitare la connessioen? Ci interessa solamente il tempo.\nLa risposta √® semplice, vogliamo solo che sia una dimensione di frame prima e una dimensione di frame dopo: tempo/slot di collisione √® due volte.\nSlide intuizione dominio di collisione\nCon questa osservazione, possiamo cambiare leggermente l\u0026rsquo;algoritmo di aloha al fine di risolvere, o meglio alleviare, il problema della collisione:\nSlotted alohaüü© Lo slotted aloha permette solamente la trasmissione in certi slot di tempo, questo aiuta ad alleviare il problema della collisione:\nHa senso che la dimensione dello slot √® dimensione massima del frame con anche trasmission delay vogliamo andare a contare anche il delay della trasmissione perch√© altrimenti due frames possono comunque influenzarsi fra di loro durante la trasmissione.\nSlide slotted aloha\nQuindi ora il tempo di vulnerabilit√† √® ridotto a slot + propagation, invece che due slots (anche se solitamente pensavo che il tempo di propagazione √® maggiore? Credo dipenda‚Ä¶).\nCSMA Carrier sense multiple access\nIntroduzione all\u0026rsquo;algoritmoüü© In questo caso il FVT (frame vulnerability time) √® due volte il propagation, perch√© se sono dentro a questo intervallo allora non sento il segnale dell\u0026rsquo;altro, che non √® ancora arrivato. Questo valore solitamente √® molto pi√π piccolo rispetto al frame size.\nSlotted CSMAüü© Alla fine molto simile questa idea allo slotted aloha, tutti possono trasmettere soltanto in certi slots di times\nThroughput comparisonüü© Vediamoc he il throughput cambia molto seguendo i protocolli (e va gi√π perch√© ci sono troppe collisioni se provo a trasmettere troppo.\nMi serve sapere il numero di stazioni trasmittenti, una cosa che non conosco generalmente.\nMACA hidden and exposed terminals üü© Vogliamo cercare di limitare le trasmittenti a comunicare bene con un ricevitore (sto ragionando sull esempio di ACBD in mezzo) cio√® in un caso di hidden terminal in cui due senders non si sentono fra di loro, ma il loro segnale potrebbe interferire in un certo punto.\nUn problema opposto √® il exposed terminal quando il sender √® condiviso da pi√π host, un host che vorrebbe comunicare, a un host diverso, non pu√≤ comunicare perch√© sente questo.\nRTS and CTSüü®++ Un altro problema di hidden terminal oltre alla trasmissione su un terminale comune √® il fatto che se CB provano a comunicare a persone differenti (rispettivamente ad A e D, B non pu√≤ perch√© sente ricevere).\nUna soluzione semplice √® semplicemente chiedere al canale ricevente se ci sono interferenze o meno. (un pacchetto breve che si chaiama RTS (request to send).) questo √® un piccolo pacchetto, potrebbe interferire, si spera che faccia molti pochi interferenze.\nIl ricevitore risponde con un CTS (clear to send) Se il cts √® ricevuto allora comincia a rispondere.\n‚Üí Non ho carrier sensing qui.\nRTS and CTS drawback Non abbiamo garanzia di comunicazione senza interferenze, questa garanzia c\u0026rsquo;√® solamente quando il range di comunicazione sono uguali fra di loro, un esempio in cui non funziona √® l‚Äôesempio qui sotto in cui esiste una rete grande ch epossa andare a fare interferenza con tutte. MACAW Voglio ritardare il RTS in un tempo casuale in modo che non sovrappongano fra di loro. C\u0026rsquo;√® carrier sensing **per gli acks, posso spedire solo quando mando RTS cos√¨ posso ricevere ack in silenzio. Gli altri quando sentono dovrebbero restare in silenzio.\nRTS Carrier sensing (anche questa credo sia la cosa nuova, il sistema RTS/CTS √® lo stesso di MACA) backoff (questa √® l‚Äôunica cosa nuov acredo). L‚Äôunico che ha preso la RTS sar√† l‚Äôunico a comunicare, gli altri stanno in silenzion perch√© sentono il canale occupato.\nSi pu√≤ settare il RTS threshhol superiore alla soglia per dire che non verr√† mai utilizzato.\nChe √® molto simile a un coordinator function with backoff, solo che questo √® senza infrastruttura, mentre nell\u0026rsquo;altro credo ci sia.\nAd hoc networks Ci sono delle cose nuove che sono delle veicole infrastructures ossia in realt√† non esisterebbe una infrastruttura per questa connessione, ma passa da veicolo a veicolo quindi √® una comunicazione locale. fino a un certo punto in cui alla fine si comunica con una infrastruttura. Come se le auto stesse fossero diventati dei sensori del traffico (quindi molte auto ferme riescono a dire se c\u0026rsquo;√® troppo traffico o meno.\nnon sono ancora diffusi questi servizi, ma stanno arrivanto, u n altro metodo √® fare unit√† di ricarica per i veicoli.\nC\u0026rsquo;√® una trasmissione con CSMA/CA , poi c\u0026rsquo;√® una fase di contention in cui si potrebbero trasmettere cose e cose di altro tipo. ci otrebbero essere un sacco di rts che vadano a vuoto. Ognuna delle fasi di rts √® un passaggio indipendente in cui si rischia ancora la collisione.\nMa quando trasmette indietro potrei avere delle (la collisione :\nFast forward intra-stream in cui il RTS del nodo successivo √® interpretato dal nodo davanti come se fosse un ACK, questo risolve il problema delle interferenze (la fase di contesa non ci sarebbe pi√π). (c\u0026rsquo;√® un campo che rappresenta il tipo di questo segnale, che valga sia come ack sia come rts). Quick exchange inter-stream, se i due nodi intermedi hanno cose da scambiarsi in direzioni diverse, potrebbe essere una buonissima soluzione il fatto di scambiarsi i dati nello stesso stream di dati (dopo l\u0026rsquo;ack di una direzione viene mandato il dato dell\u0026rsquo;altra direzione). Se uno cade allora c\u0026rsquo;√® tempo vuoto e viene interpretato come autorizzazione alla trasmissione\nCarrier sensing virtuale Carrier sensing virtuale sapere che il canale sia occupato senza andare ad ascoltarlo? Appena sentono un RTS, e se sanno la lunghezza del campo di trasmissione classico (Network Allocation Vector NAV) allora sicuramente nessuno ascolta il canale.\nQuesto fa risparmiare batteria al destinatario. E trasmettere prende un sacco di energia, anche solamente andare ad ascoltare consuma.\nFAMA Voglio utilizzare una soglia adattiva oltre la quale comincio ad utilizzare il meccanismo rts/cts. Solitamente questo mi serve quando ho troppe connessioni.\nSe il frame √® minore di una soglia allor anon ha bisogno di rts/cts, altrimenti ha bisogno.\nAnche questo √® per reti ad hoc.\nCoordinator functions Ci sono principalemente due meccanismi che vanno a regolare l‚Äôaccesso al canale C‚Äô√® l‚Äôaccess point che fa un beacon e che rende possibile la coordinazione (cose come il nome della rete e annuncio della sua esistenza √® il beacon che sempre ogni tanto manda il beacon!).\nUna volta fatto una comunciazione coordinata d√† il temop alla DCF. In questo momento l‚ÄôAP non comunca\nPoint coordination functionüü© Slide PCF\nQuando esiste un access point che cerchi di evitare le collisioni e governi tutto la comunicazione nel canale.\nQuesta cosa √® bella perch√© funziona anche se muore l\u0026rsquo;access point. Ma alla fine l‚Äôunica cosa rimasta √® la DCF, quindi abbiamo molte pi√π collisioni. (perch√© creare firmware era molto costoso).\nInter-Frame spaces \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Mac Wifi/Untitled 13.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Mac Wifi/Untitled 13\u0026quot;\u0026gt; Point, ditributed and short,, sono una ddurata di tempo in cui carrier sensing deve avere vuoto prima di poter tentare di comunicare.\nShort IFS SIFS tempo prima di autorizzare la comunicazione qualcuno che sa gi√† che deve parlare a seconda del contesto (e dovrebbe essere solamente un unico host) Se non parte significa o che sia morto o non ci sia nessuno. E Questo √® necessario per avere un PIFS Point IFS PIFS questo √® il tempo per far parlare l\u0026rsquo;access point. se nemmeno questo c\u0026rsquo;√® (ad esempio se l\u0026rsquo;access point vuole permettere la comunicazione contesa) allora il tempo aumenta e diventa un difs. (pu√≤ essere che trasmettino un polling, con l\u0026rsquo;id di quello che deve andare a trasmettere). Distributed IFS DIFS Questo √® come dire un liberi tutti quindi si rientra al tempo di contesa del WIFI. Distributed coordination functionüü© Spazio RTS-CTS anche adattivo con una soglia\nTempo √® avoidance con carrier sensing, in un ambiente distribuito. In questo caso tutti provano a comunicare, finch√© non ci riescono.\nLo slot non √® l\u0026rsquo;intero frame come in ALOHA, ma solamente il tempo di propagazione (esempio il tempo necessario per la luce in 100 metri), gli slots sono messi in questo senso. Nello slot successivo sicuramente il tentativo √® stato ricevuto.\nil backoff √® basato sul numero di questi slot vuoti che abbiamo ascoltato. E se vado a 0 allora mi metto a comunicare in modo descritto da sopra.\nIl numero degli slot dovrebbe dipendere dal numero di comunicanti questo non √® a priori definito (e non √® nemmeno possibile stimarla secondo il prof).\nGestione del back-offüü© Il backoff √® via via crescente, si potrebbe dire che sia la come la dimensione della finestra di contesa CW = contention window che √® diversa rispetto alla congestion window, per√≤ il signfiicato √® completamente diverso! Congestion trattato in Livello di trasporto serve per mandare tot frammenti allo stesso tempo senza far esplodere il router (il livello √® diverso!) mentre ora siamo a livello fisico, e si prova a comunicare localmente.\nLa cosa brutta √® che deve andare a sperimentare contesa per sapere quanta contesa ci sia! Per questo motivo si dice che non sia efficiente: se il canale √® occupato con questo metodo ci provi lo stesso e quindi vai a disturbare.\nQuando va a 0 allora io faccio proprio la tramissi contione e aspetto ack, se arrivo √® ok, altrimenti si aumenta timer nel backoff e si rif√†. Continua finch√© non ce la fai.\n","permalink":"https://flecart.github.io/notes/mac-wifi/","summary":"Introduzione Ricordiamo che vogliamo cercare di arbitrare l‚Äôaccesso al canale fisico sottostante. In questo momento andiamo ad assumere di avere gi√† tutto l‚Äôimpianto di trasmissione fisica che abbiamo in Tecnologia Wireless, Modulazione wireless Fisica del Wireless.\nObiettivi: Arbitraggio del singolo canale fisico (la tesi di dottorato del prof era su collision avoidance di wifi). Sia in tempo Sia in spazio (come gestire il segnale mandato nello stesso spazio) Utilizzo minimo di energia Quality of service Adaptive behaviour (come il 6G che vuole andare ad utilizzare AI per fare predizione).","title":"Mac Wifi"},{"content":"Introduzione a Na√Øve Bayes Bisognerebbe in primo momento avere benissimo in mente il significato di probabilit√† condizionata e la regola di naive Bayes in seguito.\nBayes ad alto livello üü© Da un punto di vista intuitivo non √® altro che predire la cosa che abbiamo visto pi√π spesso in quello spazio Assunzioni principali per na√Øve Bayes üü© I sample di input sono condizionalmente indipendenti uno con l\u0026rsquo;altro. Questo permette di utilizzare questa ipotesi $$ P(X_{1}\\dots X_{n} | Y = y_{i}) = \\prod_{i}^{n} P(X_{i} | Y) $$ E permette di rendere la parte di inferenza anche molto semplice perch√© per classificare un caso basta prendere label con la probabilit√† maggiore. che √® dato solamente dal numeratore durante la regola di Bayes. Tecnica generativa üü© La distinzione fra generativa e discriminativa √® fatta in Introduction to machine learning. Ossia cerchiamo di capire come si distribuiscono i dati? (ossia prova a capire le probabilit√† che abbiano generato questi dati). Mentre in modelli supervisionati classici si potrebbe dire che provano a capire $Y$ assumendo i dati esistenti di training.\nProva a capire $P(X|Y)$ diciamo e poi da questo si pu√≤ ricalcolare $P(Y | X)$ grazie alla formula di Bayes una volta capito $P(X)$ e l\u0026rsquo;altro.\n$$ P(Y | X) = \\frac{P(X|Y)P(Y)}{P(X)} $$ Classificazione lineare Bayes üü©- Si viene a scoprire che Na√Øve bayes alla fine fa classificazione lineare, che ci dice che √® un modello molto molto semplice.\nConsideriamo $x_{i}$ e $Y$ booleani (sar√† necessario per fare la nostra approssimazione), allora la nostra Naive Bayes classificherebbe 1 sse $$ \\frac{P(Y = 1, X_{1}\\dots X_{n} = \\vec{x})}{P(Y = 0, X_{1}\\dots X_{n} = \\vec{x})} = \\frac{P(Y = 1 | X_{1}\\dots X_{n} = \\vec{x})}{P(Y = 0 | X_{1}\\dots X_{n} = \\vec{x})}\\geq 1 $$ La prima uguaglianza di sopra √® ottenuta osservando che $P(Y=1, X_{1}, \\dots, X_{n} = \\vec{x}) = P(Y=1 | X_{1}, \\dots, X_{n} = \\vec{x}) \\cdot P(X_{1}, \\dots, X_{n} = \\vec{x})$ E poi semplificando entrambi.\nPossiamo prendere il logaritmo e utilizzare l\u0026rsquo;ipotesi di essere condizionalmente indipendenti e abbiamo $$ \\log \\frac{P(Y=1)}{P(Y=0)} + \\sum_{i} \\log \\frac{P(X_{i} = x_{i} | Y=1)}{P(X_{i} = x_{i} | Y=0)} \\geq 0 $$ E usando un trucco lo facciamo diventare lineare (vedi slide 126)\nNotiamo che una funzione da booleani a booleani si pu√≤ approssimare come\n$$ f(x) = x f(1) + (1 - x) f(0) $$ E quindi si pu√≤ esprimere l\u0026rsquo;intera seconda somma a sinistra in un modo lineare, in quanto siamo rimasti in setting lineare. Poniamo $$ \\theta_{ik} = P(X_{i} = 1 | Y = y_{k}) $$ Non so in che modo possa essere estesa ad altri casi, ma nel caso booleano funziona Quindi unendo le due cose abbiamo:\n$$ \\sum_{i} \\log \\frac{P(X_{i} = x_{i} | Y=1)}{P(X_{i} = x_{i} | Y=0)} = \\sum_{i}x_{i} \\log \\frac{\\theta_{i1}}{\\theta_{i0}} + \\sum_{i} (1 - x_{i}) \\log \\frac{1 - \\theta_{i1}}{1- \\theta_{i0}} $$ Assumendo che $f(x) = \\log \\frac{P(X_{i} = x | Y=1)}{P(X_{i} = x | Y=0)}$ Vediamo da sopra che √® lineare.\nCaso continuo Introduzione modellazione nel caso continuo üü®+ Per ora abbiamo sempre assunto che le classi da predire fossero discreti, per√≤ si pu√≤ utilizzare anche in un caso continuo, e in questo caso si usa una gaussiana.\nScegliamo una legge gaussiana perch√© naturalmente se sommiamo un sacco di distribuzioni, verr√† che sar√† una gaussiana. Legge dei grandi numeri, quindi √® una fra le distribuzioni pi√π naturali. √à la distribuzione con entropia maggiore fra tutte le distribuzioni con data media e varianza. Se si hanno altre informazioni, sarebbe molto pi√π sensato utilizzare una altra distribuzione, ma introdurrebbe un bias di un certo tipo. Metriche TP FP TN FN üü©- Questa parte √® molto importante per sapere quali metriche siano importanti, riguardo\nTrue positives False positives True Negatives False positives E con queste possiamo definire concetti come accuratezza, recall e precisione Inferenza nel caso continuo üü©\u0026ndash; Sembra molto simile a una Gaussian Mixture Models, perch√© alla fine √® una interpolazione in un certo senso, solo che √® motivato in modo diverso. Training nel caso continuo E probabilmente si pu√≤ dimostrare, facendo un ragionamento come Maximum Likelihood extimate anche in questo caso. Algoritmo di fitting Si tratta quindi di creare tutti i parametri $\\theta_{ijk}$, anche se in questo momento non sto capendo in che modo Al fine di stimare questo usiamo maximum likelihood extimate. Guardare #Sul MLE sotto per capire in che modo sono stimati.\nStima P(Y) üü© Poniamo la cosa pi√π banale, la stima di $P(Y = y_{i})$ √® solamente la percentuale delle labels che abbiamo, ossia\n$$ \\pi_{i} = P(Y = y_{i}) = \\frac{\\#D(Y = y_{i})}{\\lvert D \\rvert} $$ Utilizziamo $\\pi$ per scrivere in modo pi√π veloce la probabilit√† del singolo label.\nStima parametri P(X|Y) üü© Anche per questo caso andiamo a fare una cosa alla fine banale che √® contare il numero dei training samples con quel label $$ \\theta_{ijk} = P(X = x_{ij} | Y = y_{k}) = \\frac{\\#D(X_{i} = x_{i,j} \\cap Y = y_{k})}{\\#D(Y=y_{k})} $$ Edge cases (2) üü©- Probabilit√† id zero: Non vogliamo avere che $P(X_{i}|Y) = 0$ perch√© produrrebbe sempre nullo (questo succede per esempio per i modelli di testo mi pareva), √® improbabile che sia 0 perch√© noi per ora ci stiamo concentrando su una stima, una cosa che fanno √® aggiungere sempre almeno un esempio perch√© cos√¨ non ho una probabilit√† nulla per tutto in questo caso.\nCasi non indipendenti Questo √® molto difficile da gestire, dipende da come abbiamo generato i dati, quindi √® esterna a questa fase di scelta del modello diciamo. Bayes √® probabilmente non molto utile in questi casi, perch√© questo caso viola l\u0026rsquo;assunzione iniziale, si dovrebbe probabilmente fare preprocessing per cercare di limitare la dipendenza.\nMaximum Likelihood estimation Di questo parleremo molto meglio in Parametric Models.\nIntroduzione al problema C\u0026rsquo;√® una parte teorica molto pi√π interessante per quanto si tratta di maximum likelihood estimation. Andiamo a giustificare il motivo per cui stime molto semplici ed intuitive come quelli presenti in #Stima P(Y) e #Stima parametri P(X Y) possono funzionare. Ci chiediamo in questa istanza quale sia il caso pi√π probabile ossia quello con maximum likelihood\nMLE su bernoulli Supponiamo di avere $n$ lanci con una moneta unfair, ossia $p(X) \\neq 0.5$ di avere testa. Date certe osservazioni, quale √® il valore pi√π probabile di $P(X)$?\nConsideriamo $X^{n}$ la variabile aleatoria che misura il numero di 0 all\u0026rsquo;interno del nostro problema, allora questo segue la legge di Bernoulli.\n$$ P(X^{n} = \\alpha_{0} | \\theta) = \\binom{n}{\\alpha_{0}} \\theta^{\\alpha_{0}} (1 - \\theta)^{n-\\alpha_{0}} $$ Seguendo l\u0026rsquo;idea del pi√π probabile quello che noi stiamo cercando √®\n$$ \\hat{\\theta} = \\arg\\max_{\\theta} P(X^{n} = \\alpha_{0} | \\theta) $$ Soluzione problema analitico Prendiamo il logaritmo, che non cambia il nostro massimo, dato che √® monotona, ma ci semplifica un sacco l\u0026rsquo;analisi\n$$ \\ln(\\theta^{\\alpha} (1- \\theta)^{n - \\alpha }) = \\alpha \\ln \\theta + (n- \\alpha) \\ln(1 - \\theta) $$ Derivando rispetto a $\\theta$ abbiamo che\n$$ \\frac{\\alpha}{\\theta} - \\frac{n - \\alpha}{1- \\theta} = \\frac{\\alpha - \\alpha \\theta - (n - \\alpha) \\theta}{\\theta (1 - \\theta)} $$ che √® un massimo o un minimo se $$ \\alpha - \\alpha \\theta - (n - \\alpha) \\theta = 0 \\implies \\theta = \\frac{\\alpha}{n} $$ E se ben ricordiamo, $\\alpha$ non era altro che il numero di samples negativi, quindi questo √® un esempio locale in cui MLE √® la soluzione ottimale per stimare.\n","permalink":"https://flecart.github.io/notes/na%C3%AFve-bayes/","summary":"Introduzione a Na√Øve Bayes Bisognerebbe in primo momento avere benissimo in mente il significato di probabilit√† condizionata e la regola di naive Bayes in seguito.\nBayes ad alto livello üü© Da un punto di vista intuitivo non √® altro che predire la cosa che abbiamo visto pi√π spesso in quello spazio Assunzioni principali per na√Øve Bayes üü© I sample di input sono condizionalmente indipendenti uno con l\u0026rsquo;altro. Questo permette di utilizzare questa ipotesi $$ P(X_{1}\\dots X_{n} | Y = y_{i}) = \\prod_{i}^{n} P(X_{i} | Y) $$ E permette di rendere la parte di inferenza anche molto semplice perch√© per classificare un caso basta prendere label con la probabilit√† maggiore.","title":"Na√Øve Bayes"},{"content":"I processi di Poisson sono dei processi stocastici, interpretabili come collezione indicizzata dal tempo di variabili aleatorie. Esempi semplici sono una uniforme, altri pi√π complessi potrebbe essere una catena di Markov (see Markov Chains) (utile per modellare cammini randomici) o quella di Poisson spiegata qui.\nIntroduzione ai processi di Poisson Arrival processes Sia una sequenza di variabili aleatorie $0 \u003c S_{1} \u003c S_{2} \u003c \\dots$ (il fatto che sia positivo significa che per ogni elemento del dominio vale che quell\u0026rsquo;elemento √® \u0026lt;, non so se mi sono spiegato.) Il fatto che siano crescenti ci permette di metterli in linea, perch√© siamo sicuri che $S_{2}$ produrr√† un valore maggiore di $S_{1}$.\nIncline a questo c\u0026rsquo;√® anche il arrival counting process che semplicemente va a contare il numero di arrivi (indicati dagli $S_{i}$). La relazione con l\u0026rsquo;originale √® abbastanza semplice, e dato da questo evento: $$ \\{S_{n} \\leq t\\} = \\{N(t) \\geq n\\} $$ Possiamo connettere questa nozione con le reti di petri e quantum (Baez \u0026amp; Biamonte 2019)\ndef: Renewal processes un arrival process in cui inter-arrival times $x_{1}, x_{2}, \\dots$ sono IID.\ndef: Poisson processes Sono renewal processes in cui gli $X_{1}, X_{2}, \\dots$ $F_{X}(x) = 1 - \\exp(-\\lambda x)$, ossia seguono la cumulativa di Poisson.\nPropriet√† def: Memory-less Variabile aleatoria √® memory-less se vale. $$ P(X \u003e t + x)= P(X \u003e t) P(X \u003e x) $$ Lo chiamiamo cos√¨ perch√© assumiamo che non dipende dal tempo passato: $$ P(X \u003e t + x | X \u003e t) = P(X \u003e x) $$ il prof. dice che non ha perso tempo n√© guadagnato niente. Perso tempo perch√© se vuoi la cosa prima o poi devi entrare in coda.\nSi pu√≤ dimostrare che se e solamente se la variabile aleatoria √® esponenziale allora √® memory-less.\nTeorema indipendenza di arrival counting and arrival process sketch:\nPrendiamo un tempo $t$\nStationary increment property Se prendiamo un counting process, questo si dice stazionario se la variabile $N(t') - N(t)$ con $t' \u003e t \u003e 0$ ha la stessa distribuzione di $N(t'- t)$ ossia √® lineare senza costanti. Questo sembra chiaro perch√© ci sta dicendo che il numero di arrivi in un lasso di tempo resta sempre lo stesso.\nUn esempio √® che nel lavoro di Ermanno le sue cose non rispettano la stationary property.\nIndependent property Vale se data una sequenza $0, t_{1}, t_{2}, t_{3}, \\dots$ crescente vale che le distribuzioni $$ N(t_{1}) - N(0), N(t_{2}) - N(t_{1}), \\dots $$ Sono indipendenti fra di loro\nPer il teorema dimostrato sopra si pu√≤ dire che la distribuzione di Poisson possieda queste propriet√†.\nEquivalenze con i processi di Poisson Arrival counting processes Si pu√≤ dire che un processo che soddisfa (reference al libro) che sia independent increment e stationary increment sia un processo di poisson\nConditional arrival densities Se so che in un intervallo c\u0026rsquo;√® un arrivo, allora √® uniforme la probabilit√† di dove sia arrivato (solo che abbiamo una uniforme su un volume molto strano). Questo √® una cosa che credo sia relazionata con la indipendenza di Poisson per questo genere di processi.\nLa cosa da notare √® che questa densit√† √® indipendente da $s_{1}, s_{2}, .., s_{n}$.\nsi avr√† che $$ f(s_{1}s_{2}\\dots s_{n}|n) = \\frac{n!}{t^{n}} $$ Applicazioni Neuronal firing Da approfondire\nOptical trasmission Da approfondire\nReferences [1] Baez \u0026amp; Biamonte ‚ÄúQuantum Techniques for Stochastic Mechanics‚Äù 2019\n","permalink":"https://flecart.github.io/notes/poisson-processes/","summary":"I processi di Poisson sono dei processi stocastici, interpretabili come collezione indicizzata dal tempo di variabili aleatorie. Esempi semplici sono una uniforme, altri pi√π complessi potrebbe essere una catena di Markov (see Markov Chains) (utile per modellare cammini randomici) o quella di Poisson spiegata qui.\nIntroduzione ai processi di Poisson Arrival processes Sia una sequenza di variabili aleatorie $0 \u003c S_{1} \u003c S_{2} \u003c \\dots$ (il fatto che sia positivo significa che per ogni elemento del dominio vale che quell\u0026rsquo;elemento √® \u0026lt;, non so se mi sono spiegato.","title":"Poisson processes"},{"content":"Introduzione all\u0026rsquo;algebra relazionale Confronto con relazioni matematiche Le relazioni come le intendiamo in database sono leggermente diverse rispetto a quelle presenti per le relazioni matematiche:\nNon conta l\u0026rsquo;ordine Ci sono gli attributi Per il resto se introduciamo questo sistema per tenere conto delle astrazioni, possiamo analizzarle matematicamente, e questo ci fornisce qualche sicurezza in pi√π diciamo.\nDefinition of tuples üü© Le relazioni sono esattamente quelle definite in matematica, per√≤ noi aggiungiamo anche gli attributi, in modo da poter considerare l\u0026rsquo;ordine delle colonne non importante.\nPer prendere anche gli attributi possiamo definire cos√¨:\nTupla = funzione che associa attributo (una stringa) a un valore del dominio dell\u0026rsquo;attributo, definito da una funzione esterna Relazione √® un insieme di tuple. Facendo in questo modo ho risolto il problema dell\u0026rsquo;ordine Set operations Possiamo modellare l\u0026rsquo;algebra come se\nUnions Intersections üü© Vengono indicati con i simboli classici presenti nella teoria degli insiemi $\\cap ,\\cup$ Questa parte non ho capito perch√© deve esistere\u0026hellip; Che scopo ha?\nOperazioni principali Renaming Sintassi e semantica üü© Questo √® un operatore unario.\nIt produces changes on the schema that keep the underlying data un-altered\nDa questa immagine √® abbastanza intuitivo la sintassi utilizzata. $$ \\rho_{end \\impliedby start} (table) $$ **Semantica:** Un attributo del dataset viene richiamato con altro nome. ### Selection Anche questo √® un **operatore unario**. #### Propriet√† della selection (3) üü©- 1. Schema dell'output √® lo stesso 2. L'output soddisfa un predicato (logico). 3. L'output √® solamente un subset. **Concatenazione**: $$ \\sigma_{a}(\\sigma_{b}(R)) = \\sigma_{a \\land b }(R) $$ Distributivit√† su unione e differenza $$ \\sigma_{a}(R_{1}\\cup R_{2}) = \\sigma_{a}(R_{1}) \\cup \\sigma_{a}(R_{2}) $$ $$ \\sigma_{a}(R_{1} - R_{2}) = \\sigma_{a}(R_{1}) - \\sigma_{a}(R_{2}) $$ Altro con insiemi Possiamo notare che operano proprio come se fossero dei set, nel senso unione per or, intersezione per and, e anche intersezione col contrario con il meno.\nSintassi e semantica üü© $$ \\sigma_{predicate}(Relation) $$ Semantica: un insieme che soddisfa le #Propriet√† della selection\nProjection Anche questo √® un unary operator.\nSemantica e sintassi üü© $$ \\pi_{attribute}(Relation) $$ Semantica: viene ritornato un insieme con numero tuple della relazione iniziale (o minore per ripetizioni), ma solo con gli attributi di riferimento.\n$$ \\pi_{Y}(r) = \\left\\{ t[Y] | t \\in r \\right\\} $$ Ossia prendo i valori della tupla che corrispondono a quegli attributi, per ogni singola tupla presente in relazione\nCaso ripetizioni üü© Questa √® una cosa da notare, a differenza di Structured Query Language le cose ripetute vengono scartate, si ha unico, in questo caso, perch√© qui siamo nel reame degli insiemi\nPropriet√† di proiezioni üü© Idempotenza $$ \\pi_{x}(R) = \\pi_{x}(\\pi_{xy}(R)) $$ Se lo applico pi√π volte (anche con cose leggermente diverse rimane uguale)\nDistributivit√† su unione $$ \\pi_{x}(R_{1} \\cup R_{2}) = \\pi_{x}(R_{1}) \\cup \\pi_{x}(R_{2}) $$ Join La join √® necessaria nel caso vogliamo creare correlazione fra tuple presenti in relazioni diverse fra di loro, mentre con #Projection e #Selection possiamo farlo solamente sulla prima.\nFull and empty joins üü© Full -\u0026gt; Every tuple is used (not full is some is used) Empty -\u0026gt; with no outputs Questo √® direttamente dipendente da quali chiavi abbiamo usato durante la join Types of Joins (2) üü©- Natural Joins Siano dati due relazioni $R_{1}(X_{1}), R_{2}(X_{2})$ definisco $$ R_{1} \\bowtie R_{2} = \\left\\{ t \\text{ on } X_{1} \\cup X_{2} | \\exists t_{1} \\in R_{1} \\text{ and } \\exists t_{2} \\in R_{2} \\text{ with } t[X_{1}] = t_{1} \\text{ and } t[X_{2}] = t_{2}\\right\\} $$ Ossia data una tupla nella nuova relazione cos√¨ creata, se prendo i attributi appartenenti alla prima relazione avr√≤ che esiste effettivamente uguale per il secondo.\nOuter joins: Che sono le stesse spiegate in Structured Query Language, ossia andiamo a considerare left, right and full $A ‚üï B, A ‚üñB , A‚üóB$, sono i simboli utilizzati, ma user√≤ sempre $\\bowtie$ con pedice l, r, f per indicarne il tipo, per semplicit√† di notazione.\nLa semantica di questi √® la stessa per SQL, la descriviamo prevemente, sar√† left outer, nel caso in cui ho la garanzia che solamente le tuple della relazione 1 ci sar√†, contrario per right, per il full outer, ho la garanzia che una data tupla finale, sar√† presente in almeno uno dei due iniziali, ma non so quale.\nPropriet√† (2) üü© Push selection Distributivit√† sull\u0026rsquo;unione $$ R \\bowtie(R_{1} \\cup R_{2}) = (R \\bowtie R_{1}) \\cup(R\\bowtie R_{2}) $$ Theta Join üü©- Il theta join viene motivato grazie al fatto che solitamente bisogna sempre rinominare prima di fare una selection, o bisogna fare sempre selection, per questo motivo. Solo che questo √® possibile fare solo se sono una #Cartesian product, ossia non abbiano attributi in comune.\nLa sintassi ammessa nella condizione sono solamente and e relazioni booleane binarie (minore, maggiore, uguale e combinazione fra questi). Altra cosa necesssaria per la theta join, √® che non ci siano attributi in comune fra le due relazioni.\nE si pu√≤ notare sulle slides che questo √® molto simile alla natural join dopo renaming espresso in #Types of Joins (2) in precedenza.\nEqui Join üü© Quello pi√π interessante sono le equi-join che accade quando ho relazioni di equivalenza, questo si manifesta solamente quando la theta join di sopra √® fatta da atomi di uguaglianza, questo mi dovrebbe garantire per certo tale propriet√†.\nCartesian product Si pu√≤ considerare come una join naturale su relazioni senza attributi in comune (quindi tutto si pu√≤ combinare con tutto!).\nViews Introduzione alle data-views üü©- Sono delle rappresentazioni diverse dello stesso genere di data, solitamente utili per fare view diverse (e.g. dipartimento altro avr√† necessit√† diverse), abbiamo accennato a questa necessit√† durante la nostra Introduction to data-bases. Nel caso preciso di SQL ne andiamo a parlare in Advanced SQL.\nNel caso di algebra relazionale, √® soltanto una specie di dichiarazione di variabile con un altro nome, che specifica quale √® il risultato della sua query.\nView utilization Questa √® una cosa classica in informatica, il concetto di astrazione implementazione presente come descritto in Astrazione sul controllo#Significato di astrazione E dividere in questo modo quello che √® effettivamente memorizzato da quello che l\u0026rsquo;utente deve volere vedere.\nMaterialized views üü©\u0026ndash; La differenza con l\u0026rsquo;altra tipologia di view che viene proposta √® che questa view √® storata fisicamente sui dispositivi di memorizzazione.\nPros:\nVeloce da leggere (non da creare ogni volta) Cons:\nRidondanza dei dati update deve essere doppio (problemi di coerenza) Non supportati dai DBMS. Virtual views üü® Al fine di creare la view viene fatto una query sul database. Non so esattamente se questi possono essere fatti sempre o meno.\nView update üü© Nel caso di sql possiamo andare a definire due valori local o cascade, con il primo la view non aggiorna le tabelle effettivamente presenti, mentre con cascade s√¨. Ma credo non si possa sempre fare e bisogna sempre stare leggermente attenti.\nSome notes on update difficulties √à molto pi√π difficile updatare la view, perch√© questo update deve essere coerente con la versione originale che era esistente! Per questo motivo non tutti gli update sono disponibili per update.\nRelational calculi üü• Si differenzia leggermente dall\u0026rsquo;al\nIntroduction to relational calculi Alla fine si basano tutti su Logica del Primo ordine, Questo √® sempre un modo per modellare le relazioni che sono molto comuni nei casi che abbiamo trovato di relational databases, ma invece di utilizzare algebra utilizzano una logica, descritta sotto.\nQuesto √® molto pi√π vicino all\u0026rsquo;approccio logico, sviluppato durante gli anni 70-80 con knowledge bases in AI.\nGeneral form üü®+ $$ \\left\\{ A_{1}: x_{1}, \\dots A_{k} : x_{k} | f \\right\\} $$ In cui abbiamo\n$f$ che √® una formula che probabilmente da un booleano per decidere se prenderlo o meno. $A_{i}$ che sono degli attributi $x_{i}$ che sono delle variabili Avremo come output una tupla di $(x_{1}, \\dots x_{n})$ che soddisfano $f$ Esempi: Esistono forme anche leggermente pi√π complicate, ma dobbiamo introdurre gli esistenziali: Esistono anche i de morgan rules che si possono applicare, perch√© in pratica √® logica.\nRelational calculi, considerations Aspetti negativi (2) üü® Moltissime variabili inutili (troppo verboso scriverci). Presenza di espressioni senza senso e dipendenti dal dominio questo significa che se cambiamo il dominio di definizione cambiamo anche i valori che sono possibilmente denotati (non ho capito perch√© questa dovrebbe essere una caratteristica negativa poi). Per risolvere il primo problema si aggiunge una sintassi pi√π compatta, presentata come \u0026ldquo;range declaration syntax\u0026rdquo; (ma non √® espressivo quanto algebra, in qualche modo si dimostra)\u0026hellip;\nRange declaration syntax üü® Pagina 78 del libro ne parla meglio, dovrei approfondire quello. #### Indipendenza da dominio üü® L\u0026rsquo;espressione $$ A_{1} : x_{1} | not R(A_{1} : x_{1}) $$ √à dipendente dal dominio, perch√© prende l\u0026rsquo;insieme degli elementi nel dominio, tali che non sono presenti nella relazione. Abbiamo bisogno di questa propriet√† perch√© se √® dipendente dal dominio si potrebbero produrre risultati enormi, che rendono l\u0026rsquo;applicazione pratica nulla.\nEquivalenza con Algebra relazionale üü© Si pu√≤ dimostrare che se ci limitiamo alle espressioni indipendenti col dominio, i due modelli sono esattamente uguali, ossia possiamo dire che possiamo creare una espressione di algebra, partendo da calcolo, e viceversa.\nLa dimostrazione (che non facciamo) andr√† per induzione strutturale, quella che trovi in Logica in Deduzione naturale.\nPossiamo notare che l\u0026rsquo;algebra √® indipendente dal dominio, perch√© l√¨ non √® mai esplicitata la relazione in che dominio sia (abbiamo operazioni chiuse si pu√≤ dire).\n","permalink":"https://flecart.github.io/notes/relational-algebra/","summary":"Introduzione all\u0026rsquo;algebra relazionale Confronto con relazioni matematiche Le relazioni come le intendiamo in database sono leggermente diverse rispetto a quelle presenti per le relazioni matematiche:\nNon conta l\u0026rsquo;ordine Ci sono gli attributi Per il resto se introduciamo questo sistema per tenere conto delle astrazioni, possiamo analizzarle matematicamente, e questo ci fornisce qualche sicurezza in pi√π diciamo.\nDefinition of tuples üü© Le relazioni sono esattamente quelle definite in matematica, per√≤ noi aggiungiamo anche gli attributi, in modo da poter considerare l\u0026rsquo;ordine delle colonne non importante.","title":"Relational Algebra"},{"content":"Note matematiche introduttive Vettori ortonormali üü© Questa parte √® fatto molto meglio in Inner product spaces.\nDue vettori si dicono ortonormali se $vv^T = ||v|| = 1$ e sono ortogonali, ossia $v_i v^T_j = 0$ con i e j diversi fra di loro\nMatrici ortogonale (4) üü©- Matrici si dicono ortonomali se le sue colonne sono vettori sono ortonormali\nMatrici ortonormali sono isometrie, cio√® mantengono le distanze. Queste matrici sono tutte non singolari e quadrate per definizione La sua inversa √® ortogonale La sua inversa √® uguale alla trasposta slide Propriet√† matrice ortonormale\nMinimi quadrati lineari Introduzione al problema Sappiamo che non esiste una soluzione esatta per sistemi di equazione lineare che pi√π equazioni che soluzioni. Si pu√≤ concludere che la soluzione a questo problema (in slide) esiste sempre ed √® unica se $k = n$, se √® minore ci sono infinite soluzioni.\nSlide introduzione\nOssia mi interessa solamente l‚Äôascissa del minimo, ossia\n$\\text{ argmin }\\lVert Ax - b \\rVert$, cercando la x.\nSoluzione con equazione normale üü® Questo si pu√≤ fare solamente se $k = n$\nTeorema, soddisfacimento delle equazioni normali √® sufficiente per trovare una soluzione\nIn questo caso esiste una soluzione unica.\nSoluzione equazione normale\nnota ci sono errori sia sulla trasposta che sul gradiente in immagine\nIn breve\nFare il gradiente della funzione ed eguagliarlo a 0, perch√© solo se ho 0 ho il punto di minimo di questa funzione convessa della norma\nSingular Value decomposition Next time, use this resource.\nDi solito √® utilizzata per ridurre lo spazio utilizzato trattenendo la maggiore quantit√† di informazione possibile, utilizzata spesso in Principal Component Analys\nEnunciato SVD slide\nImmagine esplicativa\nQuesto √® qualcosa che si pu√≤ applicare a qualunque matrice. Sono di particolare interesse le matrici con numero di colonne maggiore del numero di righe.1\nSlide vecchia\nRelazione valori singolari con AAt üü©- Con k ho il numero di numeri non zero che sono il rango della matrice. Questa matrice √® particolare, la chiamiamo gramiano ed √® sempre definita positiva.\nSlide\nQuindi i valori singolari che sono gli autovalori della matrice $A^TA$ sono\n$\\geq 0$ $\\in \\R$ se k √® il rango di $A$, ho k elementi diversi da 0. Il motivo per cui succede quanto sopra √® perch√© √® come se stessi facendo il cambio di base per trovare una matrice diagonale! Cambio di Base, e non c\u0026rsquo;√® nessuna relazione altra fra la matrice di A e il valore singolare, deve essere con AAt!\nRelazione molto importante (!!!!!)\nVettori singolari sinistri e destri üü© Definiamo in questo modo i vettori associati a $\\sigma_i$ che formano una base ortonormale rispettivamente di $R^m, R^n$. E in particolare sono le colonne delle matrici $U, V$\nNOTA: √® molto probabile che la relazione sotto che lega vettori singolari sinistri e destri sia errata perch√© sulla pagina di wiki u e v sono invertite. √à pi√π importante il fatto che i vettori singolari sinistri e destri sono rispettivamente autovettori di AAt e AtA.\nSlide\nDecomposizione diadica üü•+ \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 11.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Minimi quadrati/Untitled 11\u0026quot;\u0026gt; In pratica con la decomposizione a valori singolari, e utilizzando i vettori singolari si pu√≤ dimostrare che\n$$ A = U\\Sigma V^T = \\sum_{i=1}^k \\sigma_iu_iv_i^T $$ Espandere questi calcoli √® abbastanza easy creddo, perch√© la matrice di mezzo √® molto semplice da gestire. L‚Äôintuito per sta parte (che √® l‚Äôunica cosa di cui si √® preoccupata di spiegare) √® che √® utile qui il concetto di un prodotto esterno che po\nRisoluzione minimi quadrati con SVD üü®+ \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 12.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Minimi quadrati/Untitled 12\u0026quot;\u0026gt; Dimostrazione\nRegressione Polinomiale (!) Abbiamo un insieme di dati, vogliamo creare un algoritmo che stimi la funzione migliore per approssimare i dati.\nSiano dati un insieme di punti $(x_i, y_i)$, sia un polinomio p cos√¨ definito\n$p(x) = \\sum_{i =0} ^m c_ix^i$, vogliamo andare a definire per bene i valori dei coefficienti in modo che aderiscano ai dati.\nPer fare questo, in pratica √® la risoluzione di certi errori.\nIn pratica mi costruisco la matrice di vandermonde per tutti gli input di dati, di n numero di colonne, con n l‚Äôesponente massimo del polinomio che voglio andare ad approssimare.\nPoi faccio cose per minimizzare l‚Äôerrori di questo e lo possono fare con SVD o minimi quadrati (nel cosi in cui il rango fosse giusto).\nImportante per questa parte la matrice di vandermonde.\nPseudo inversa (4) üü• Slide\nQuesta definizione ci permette di scrivere il problema dei minimi quadrati in modo pi√π clean, infatti la soluzione della SVD diventa\n$x = V\\Sigma^+U^Tb = A^+b$, come se stessi prendendo l‚Äôinversa üòÄ, quindi ci permette di semplificare questa notazione.\nSi pu√≤ notare che l‚Äôinversa possiede tutte le propriet√† della pseudoinversa.\nIn soldoni: inverto le matrici di vettori singolari e inverto tutti i valori singolari (prendo iil loro reciproco).\nImportanti sono alcune loro propriet√† (hermitiana per AA* e A*A, ossia simmetrica, inversa debole e l‚Äôaltra boh).\nSecondo la definizione di moore-penrose quelle 4 propriet√† sono sufficienti per una pseudoinversa, in questo caso abbiamo la pseudoinversa della SVD, che √® una cosa leggermente diversa (cio√® istanziazione specifica della pseudoinversa).\nCondizionamento in LSQ (non fare) Questa sezione ha cose da ricordare a memoria (gi√† leggermente presentate in precedenza) quindi non ha molto senso dare attenzione a sta roba brutta, imparare poi a memoria il costo dei vari argoritmi bruuh\nVogliamo in questa sezione andare ad indagare quanto influenza il numero di condizione tutte le tecniche che abbiamo introdotto in questo capitolo.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 16.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Minimi quadrati/Untitled 16\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Minimi quadrati/Untitled 17.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Minimi quadrati/Untitled 17\u0026quot;\u0026gt; Da ricordarsi di Norme e Condizionamento, che il condizionamento ci dice quanto cambia la soluzione quando cambio i dati (la b)\n","permalink":"https://flecart.github.io/notes/minimi-quadrati/","summary":"Note matematiche introduttive Vettori ortonormali üü© Questa parte √® fatto molto meglio in Inner product spaces.\nDue vettori si dicono ortonormali se $vv^T = ||v|| = 1$ e sono ortogonali, ossia $v_i v^T_j = 0$ con i e j diversi fra di loro\nMatrici ortogonale (4) üü©- Matrici si dicono ortonomali se le sue colonne sono vettori sono ortonormali\nMatrici ortonormali sono isometrie, cio√® mantengono le distanze. Queste matrici sono tutte non singolari e quadrate per definizione La sua inversa √® ortogonale La sua inversa √® uguale alla trasposta slide Propriet√† matrice ortonormale","title":"Minimi quadrati"},{"content":"Algebra modulare Assunzioni Andiamo ora ad assumere l\u0026rsquo;esistenza e correttezza di alcune cose di base. (in teoria si possono dimostrare da cose pi√π di base, ma non ho tempo).\nTeorema fondamentale dell\u0026rsquo;algebra Ogni numero intero si fattorizza in modo unico.\nAlgoritmo di Euclide La conseguenza pi√π importante di questo teorema, dovuto ad Euclide √® che se ho $a, b \\in \\mathbb{Z}$ allora esistono resto e dividendo fra i due. Ossia $\\exists q, p : a\\mid b = qk + p$ per qualche $k$ intero\nDare una occhiata all\u0026rsquo; implementazione potrebbe essere interessante.\nMCD e divisibilit√† Se $a \\mid d$ e sono interi allora esiste esiste c tale per cui d = ca. (tutti interi senza restrizioni) mcd fra interi a e b √® il pi√π grande intero che divide sia a sia b. Osservazione: $mcd(a, 0) = a$\nTeorema di B√©zout che dice che esistono r ed s tali che per ogni 2 interi a,b ho che ar + sb = gdc(a,b); E da questo possiamo andare a fare algoritmo di Euclide esteso.\nClassi di resto modulo n Si dicono che $a \\equiv b \\mod n \\iff n | a - b$\nSI indica con $[a]_n = \\{ b \\in \\mathbb{Z} :b \\equiv a \\mod n\\}$ elementi la cui differenza con a √® divisibile per n\nE indichiamo con $\\mathbb{Z}_n$ come l\u0026rsquo;insieme di tutte le classi di equivalenza ossia $\\{[[a]_n : a \\in \\mathbb{Z}\\}$ ossia insieme quoziente, Relazioni fra insiemi.\nDimostrazione classe di equivalenza Riflessivit√†\nsi ha che $n | a- a \\iff n | 0$ che √® vero\nSimmetrica\nse $a \\equiv b \\iff b \\equiv a$ in quanto se $a \\equiv b \\iff n | a - b \\iff n | b - a \\iff b \\equiv a$ (cio√® basta moltiplicare per qualcosa di negativo, si ha lo stesso risultato\nTransitiva, mi sono rotto\nAllora sappiamo di avere una classe di equivalenza (una partizione su Z in pratica).\nProp equivalenza con resto Sia $a\\in \\mathbb{Z}$ e r il suo resto di divisione per n, allora $a \\equiv r \\mod n$ ossia appartengono alla stessa classe di equivalenza\nProp costituzione dell\u0026rsquo;insieme quoziente Per la proposizione precedente posso trovare proprio come √® costituito\n$Z_n = \\{[0]_n, [1]_n...,[n-1]_n\\}$\nDimostrazione:\ndimostrare che $\\impliedby$ ossia destra √® contenuto in sinistra √® ovvio per definizione di Zn, per dimostrare che $\\implies$si utilizza la proposizione sopra:\nSia $[a]_n \\in \\mathbb{Z}_n$ per proposizione sopra si ha che $[a]_n = [r]_n \\in \\{[0]_n,...,[n - 1]_n\\}$\nPer concludere (se voglio dimostrare nel modo classico utilizzando classe di equivalenza) devo dimostrare che tutte le classi presenti in Zn sono effettivamente distinte.\nPrendo $i,j \\in [0...n-1]$ wlog $i \u003e j$ allora $0 \u003c i - j \\leq i \\leq n- 1$ allora $n \\not | i-j,$ quindi si ha che $i \\not\\equiv j \\mod n$ e questo conclude che Zn ha n elementi\nSomma e prodotto in questa classe La definizione di classe modulo resto in questo modo √® molto simile alla classica definizione di somma e prodotto (ma non per la divisione, non √® sempre invertibile).\nE si dimostrano anche\nCommutativit√† Associativit√† Distributivit√† (entrambe, destro e sinistra) C\u0026rsquo;√® il neutro per la somma Prop. invertibilit√† di una classe Si dice che $[a]_n \\in \\mathbb{Z}_n$ √® invertibile se esiste $[b]_n \\in \\mathbb{Z}_n : [a][b] = [1]$ (sottinteso indici)\nSi dimostra che √® invertibile se solo se √® co-primo col modulo poi (perch√© con Euclide esteso riesco a trovarmi l\u0026rsquo;inversa).\nProp. unica soluzione diofantea √à un corollario della precedente, praticamente dice che se $ax = b, gcd(a,n) = 1$ allora esiste una unica soluzione.\nUn approfondimento √® presente nella teoria dei gruppi per sta parte (le cose che potrebbero essere interessanti sono i Campi da questo punto di vista). Vedere Gruppi Gruppi ciclici e permutazioni e Gruppi Normali.\n","permalink":"https://flecart.github.io/notes/algebra-modulare/","summary":"Algebra modulare Assunzioni Andiamo ora ad assumere l\u0026rsquo;esistenza e correttezza di alcune cose di base. (in teoria si possono dimostrare da cose pi√π di base, ma non ho tempo).\nTeorema fondamentale dell\u0026rsquo;algebra Ogni numero intero si fattorizza in modo unico.\nAlgoritmo di Euclide La conseguenza pi√π importante di questo teorema, dovuto ad Euclide √® che se ho $a, b \\in \\mathbb{Z}$ allora esistono resto e dividendo fra i due. Ossia $\\exists q, p : a\\mid b = qk + p$ per qualche $k$ intero","title":"Algebra modulare"},{"content":"Devices Categorizzazione (6)üü®- Trasferimento dei dati Accesso al device sinfonia del trasferimento condivisone fra processi Velocit√† del trasferimento I/O direction (scrittura o lettura) Vediamo che molte caratteristiche sono riguardo il trasferimento\nSlide categorizzazione I/O\nBlocchi o caratteri üü©- Slide devices blocchi o caratteri\nTecniche di gestione devices (4) üü®- Buffering Possiamo mettere un buffer per favorire la comunicazione fra i devices. la cos amigliore che fa √® creare maggiore efficienza. Un altro motivo √® la velocit√† diversa di consumo.\nAnche le schede audio, in cui viene riempito un buffer e poi l‚Äôaudio viene playato da questo (differenza consumer e producer), anche per questo motivo √® difficile sincornizzare dispositivi differenti (se hanno buffer distinti).\nCache Invece la cache √® trasparente pe ril programma, e rende il tutto pi√π veloce. La differenza maggiore con il buffering √® che qui viene mantenuta una copia, non una istanza dell‚Äôinformazione.\nSpooling Gia trattato per le stampanti in Gestione delle risorse\nScheduling I/O \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Devices OS/Untitled 4.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Devices OS/Untitled 4\u0026quot;\u0026gt; Storage area network üü© Slide SAN\nIl vantaggio principale √® resilienza del server, che ho il device in altra parte. (non ho iil tight coupling fra server e disco in questo modo, prima se si rompe qualunque, si rompe il servizio).\nOra se si rompe un server, ci sar√† un altro server che sostituisce, se si rompe un storage array, ci sar√† ridondanza, e altro storage ti risponderebbe. Si vede che questa parte √® strettamente collegata con cose fatte in Reti di Calcolatori\nMemoria secondaria Solid State Drive üü®+ Slide SSD\nUn sacco di vantaggi come\nVelocit√† di accesso Meno consumo energetico Meno fragilit√† Velocit√† di lettura √® molto veloce. Poche scritture (comuqnue tante) comunque limitati cicli di scrittura. Uniforme velocit√† in tutto il disco (questo rende l\u0026rsquo;accesso veloce :D). Non andiamo ad approfondire sugli algoritmi di scheduling per le scritture a banco, trattiamo meglio gli HDD.\nHard Disk Drive üü®+ Soffrono molto i terremoti perch√© la testina √® vicina al disco e non soffrono problemi di pressione.\nDevo avere:\nTestine settore giusto La traccia desiderata si muova e mi dia le cose giuste Questo mi crea 3 parametri per valutare questo accesso\nVelocit√† di rotazione, Tempo di seek o di cambiare cilindro**, velocit√† di trasferimento**.\nSolitamente il tempo pi√π lungo √® per il cilindro, poi devo andare alla sezione, e andare alla testina corretta.\nIn generale sul disco:\nOssia solitamente mezzo giro, + tempo cambio\nVALUTAZIONE TEMPO DI ACCESSO\nSlide tempi di accesso per dischi\nIn media 100 giri al secondo, quindi tipo 5 ms per andare a trovare la testina corretta, potrebbe essere 2.5 se √® il doppio o 1, ma l‚Äôordine di grandezza resta questo per il ritardo.\nRAID Introduzione ai Redundant Array of Indipendent Disks I RAID ne abbiamo parlato in Memoria. Come facciamo a stare su alla velocit√† del processore se questa va a crescere in modo esponenziale? Parallelizzazione della ricerca!. Ecco perch√© ci serve raid (oltre alla ridondanza quindi pi√π sicuro). E possono anche fallire. ‚Üí ammette recovery.\nE una altra cosa bella dei raid √® che sono hot-swappable cio√® li puoi sostituire anche quando stanno runnando.\nSlide RAID\nlivello 0 (striping) üü© I dati vengono messi su pi√π dischi. Viene utilizzato per applicazioni in cui serve velocit√†, senza interesse di perdita di dati. Ad esempio in dipartimento ci mettono copie di SO per aggiornare il sistema operativo.\nUTILIZZI:\nper grandi trasferimenti di dati, efficiente, in particolare se la quantit√† di dati richiesta √® relativamente grande rispetto alla dimensione degli strip\nper un gran numero di richieste indipendenti efficiente, in particolare se la quantit√† di dati richiesta √® paragonabile alla dimensione degli strip\nSlide RAID 0\nhttps://www.notion.so\nLivello 1 (mirroring) üü© Ci sono 2n dischi e met√† sono delle copie esatte.\nSlide RAID 1\nIn questo caso la scrittura √® pi√π lenta della lettura.\nTollera un singolo guasto al massimo, o pi√π dischi differenti (non devono essere le due copie diciamo). Si dice fault tolerance livello 1.\nLivello 4 üü© Slide introduzione raid livello 4\nUtilizzo un intero disco solamente per la parit√† su un disco. cos√¨ se si rompe un disco riesco a ricostruire le informazioni di quel disco.\nNon √® efficiente perch√© se cambio un dato devo andare sempre a fare due write su dischi diversi. E poi continuo sempre a scrivere sullo stesso disco! Quindi fai finta 4 write contemporanei, per aggiornare gli altri dischi! Per questo c\u0026rsquo;√® il bottleneck\nLivello 5 üü© Slide intuizione raid livello 5\nSe c\u0026rsquo;√® un disco rotto si rallenta, ma non si perdono dei dati! √® il funzionamento degradato dei raid.\nNon ho problemi di bottleneck, e ho ancora la velocit√† del livello 1\nLivello 6 üü®++ Slide raid livello 6\nhttp://www.cs.unibo.it/~renzo/doc/p245-blaum\nQuesto √® per cose sicure, riesce a tollerare livello 2 fino a due dischi rotti.\nOvviamente √® una parit√† diversa, in modo che riesco ad avere pi√π fault tolerance.\nSi utilizza un XOR in diagonale e questo sembra funzionare, anche se non ho capito perch√©.\nIntuizione mia\nIn pratica qualunque modo prendi due dischi non di check (se uno √® un disco di check √® molto ez).\nAllora puoi fare questo:\nRecovery dei dischi in alto a sinistra e in basso a destra, questi si possono recoverare solamente con i bits diagonali, quindi posso gi√† farlo. Utilizzo questi strips recuperati e utilizzo quelli orizzontali per recuperare l‚Äôaltro della stessa row, poi utilizzo diagonale per recuperare quelli corrispondenti in row diverse e continuo cos√¨ e riesco a recuperare tutto., Sarebbe molto utile fare un esempio per mostrare questo, ma spero che il me futuro quando legge questo riesca a ricordarsi l‚Äôesempio su carta.\nAlgoritmi per HHD First Come First Served üü© Questo √® un algoritmo fair, nel senso che eseguo a seconda di quanto viene, questo non general starvation. Per√≤ non minimizza il numero di seek, quindi in generale √® pi√π lento. Se invece facciamo in batch, in gruppo di richeiste alla volta sarebbe molto pi√π semplice!\nQuesta √® l\u0026rsquo;idea del prossimo algoritmo\nShortest Seek Time First üü© seleziona la richieste che prevede il minor spostamento della testina dalla posizione corrente\npu√≤ provocare starvation, quando arrivano tante vicine, non visito mai quelle lontane!\nQuindi non abbiamo fairness, e non c‚Äô√® una buona velocit√† di risposta per le richieste agli estremi.\nLook - Algoritmo dell‚Äôascensore üü© Praticamente vado avanti indietro, e quando arrivo alla fine torno indietro, continuo cos√¨ a soddisfare le richieste.\nIl tempo medio di accesso non √® omogeneo, le tracce centrali sono accesse pi√π spesso.\nEsempio ascensore\nDISCUSSIONE DI IMPLEMENTAZIONE\nSi utilizzano due code. Una coda a scendere e una coda a salire.\nPotrei creare starvation quando mi arrivano richieste sullo stesso cilindro, quindi quando succede devo mettere la richiesta nell\u0026rsquo;altra coda.\nImplementazione delle due code\nC-Look üü© √à molto simile all\u0026rsquo;algoritmo dell‚Äôascensore, ma solo che quando arrivo alla fine torno all‚Äôinizio.\nNon ho ancora capito in quali casi pu√≤ essere utile.\nSlide esempio C-Look\n","permalink":"https://flecart.github.io/notes/devices-os/","summary":"Devices Categorizzazione (6)üü®- Trasferimento dei dati Accesso al device sinfonia del trasferimento condivisone fra processi Velocit√† del trasferimento I/O direction (scrittura o lettura) Vediamo che molte caratteristiche sono riguardo il trasferimento\nSlide categorizzazione I/O\nBlocchi o caratteri üü©- Slide devices blocchi o caratteri\nTecniche di gestione devices (4) üü®- Buffering Possiamo mettere un buffer per favorire la comunicazione fra i devices. la cos amigliore che fa √® creare maggiore efficienza. Un altro motivo √® la velocit√† diversa di consumo.","title":"Devices OS"},{"content":"https://virtuale.unibo.it/pluginfile.php/1295166/mod_resource/content/0/Lez18-Gorrieri.pdf\nHalting problem Questo asserisce che non esiste nessun programma che sia in grado di decidere la terminazione di un altro programma\nQuesto √® un problema che ci √® interessante perch√© vorremmo costruire un compilatore che sia in grado di osservare tutti gli errori possibili del programma. Come vedremo tra poco la risposta sar√† negativa.\nDimostrazione tesi üü®++ Supponiamo che questo programma esista, lo chiamiamo check(P) che restituisce 0 se termina 1 se non termina, allora devo poter essere in grado di scrivere un programma di questo genere\nprocess ABSURD(x): if (check(ABSURD(x))): return 0; else: while (true); endprocess Allora se il processo ABSURD con x in input termina, si avr√† che non termina e vale anche il contrario. E questo √® un chiarissimo assurdo. In questo modo troviamo una funzione non calcolabile ed √® stato uno dei primi episodi storici di non calcolabilit√† (Turing 1936) in quello storico paper.\nNOTA: questa sezione non √® molto formale, √® utile per√≤ per dare l‚Äôintuizione, per andare in modo formale √® bene andare a guardarsi le slide del prof (c‚Äô√® un errore di input di funzioni).\nNon calcolabilit√† dell‚Äôeguaglianza üü•+ Si pu√≤ dimostrare che non esiste un programma che decida se due programmi calcolano la stessa cosa, altrimenti ci potremmo ricondurre a un caso molto simile a quello di sopra.\nDimostrazione\nSe esistesse tale funzione, potrei costruire la funzione che decide se quanto calcolato √® uguale alla funzione costante 0. Se ho questa funzione allora posso costruire una funzione\nF(P) che prende in input una funzione e un dato, e calcola 0 se converge, e diverge con essa se diverge. Con questa funzione posso costruire la funzione check perch√© se converge posso dire con sicurezza che √® 1, e se diverge posso dire che √® 0\nCostruzioni del prof. (3) üü®++ Assurdo che esista un programma che mi dica se un programma si stoppi o meno\nQuesta sezione √® utile se vuoi ripetere quello che dice il prof.\n$$ H(P,x) = \\begin{cases} 1\\, P(x)\\downarrow \\\\ 0 \\, P(x) \\uparrow \\end{cases} $$ $$ K(P) = H(P,P) $$ $$ G(P) = \\begin{cases} 1\\, K(P) = 0 \\\\ \\uparrow, K(P) = 1 \\end{cases} $$ Ma se proviamo a calcolare $G(G)$ vediamo che se $G(G)$, che √® quello che va a calcolare K, termina, allora non terminer√†, per come ho costruito G, se non terminer√† allora termina per come ho costruito G.\nNessun programma mi pu√≤ dire se una funzione calcola una costante o meno üü•\n$$ Z(P) = \\begin{cases} 1, \\forall x, P(x) = 0 \\\\ 0, \\exists x, P(x) \\neq 0 \\end{cases} \\\\ F(P,x) = \\begin{cases} 0, P(x) \\downarrow \\\\ \\uparrow, P(x) \\uparrow \\end{cases} $$ Si noti che entrambe le funzioni di sopra sono calcolabili, allora se vale questo vale che\n$$ K(P) = H(P, P) = Z(F(P,P)) $$ Il trucco non sta altro che sfruttare il fatto che Z termina lo stesso anche se una funzione pu√≤ divergere talvolta, senza restituire qualcosa (allora so che non dar√† mai la costante), ma se funzione normalmente fa sempre 0.\nNessun programma pu√≤ dire che due programmi sono equivalenti\n$$ Equiv(P, Q) = \\begin{cases} 1, \\forall x, P(x) = Q(x) \\vee P(x) = \\uparrow = Q(x) \\\\ 0, \\text{altrimenti} \\end{cases} \\\\ Z(P) = Equiv(P, zero) $$ E quindi avrei una funzione che calcoli se una funzione √® 0.\nDecidibilit√† Vedere La macchina di Turing#Problemi di decisione per definizione pi√π adatta e corrente.\nIntroduzione üü®+ Decidibilit√† (2)\nDati certi input, devo rispondere con 1 o 0 in tempo finito, questo √® l‚Äôunico output che posso dare. Un esempio di problema di decidibilit√† √® dire se appartiene o meno a un certo insieme.\nUn problema che non √® decidibile √® indecidibile.\nSemidecibilit√†\nQuando in tempo finito riesce a dirmi 1, ma per dire 0 diverge. Un esempio di programma con questa propriet√† √® la funzione check che stavamo sviluppando prima, che dice 1 se converge e 0 se non converge.\nNotare che il caso contrario, quello che per 1 diverge, e per 0 converge, non √® semidecidibile (il problema della divergenza non √® semidecidibile).\nEsempi di problemi indecibili ! (5) Se la funzione calcola una costante Se la funzione termina Se la funzione diverge (il suo contrario) Se due programmi sono equivalenti Se esistono errori run-time del programma La macchina di turing Introduzione (6) üü© Una macchina di turing pu√≤ essere determinata da 6 variabili.\nStati\nAlfabeto in input\nAlfabeto del nastro infinito\nStato iniziale\nstato finale\nFUnzione di stransizione da (stato, simbolo nastro) ‚Üí (stato, simbolo nastro, spostamento sinistra/destra)\nSlide\nIn modo analogo a quanto fatto in precedenza possiamo andare a definire un alfabeto riconosciuto dalla macchina di turing.\nCalcolabilit√† secondo Turing üü®+ Definizione di calcolabilit√†\nMolto easy, Calcolabile secondo turing se esiste una macchina di turing (quindi definita da quelle 6 cose) che calcola quella funzione\nSlide\nOsservazioni\nSi pu√≤ notare che il numero che le funzioni che sono turing calcolabili sono solamente numerabili quindi c‚Äô√® una stragrande maggioranza delle funzioni che non possiamo nemmeno andare a calcolare!\nJacopini-B√∂hn e l‚Äôequivalenza üü© Si pu√≤ dimostrare che molti formalismi sono turing-completi ossia sono in grado di calcolare esattamente le stesse funzioni della macchina di turing. (basta che il programma abbia tutta la memoria di cui necessita).\nIl teorema di JB ci dice che se un linguaggio di programmazione possiede\nIf-then-else While statements e assegnamento ‚Üí Turing completo.\nCome conseguenza di questo teorema ci fu, storicamente parlando, uno sviluppo della programmazione strutturata, in cui andiamo solamente a guardare i parametri locali per decidere e capire cosa faccia la funzione.\nTesi di church turing Vedere La macchina di Turing#Tesi di Church-Turing\nSe una funzione pu√≤ essere calcolata algoritmicamente in un qualche formalismo allora √® calcolabile con il formalismo della macchina di turing\nQuesto non √® un teorema √® solamente una tesi che √® riuscita a resistere al tempo, che da grande valore al significato della macchina di turing.\nLa nota informale di questa tesi che non permette ancora un attacco matematico-formale √® che\nil concetto di algoritmo non √® ancora stato ben formalizzato, e non si pu√≤ applicare per tutti i formalsimo Questa cosa deve essere vera per ogni formalismo, ma come formalizzare il formalismo stesso e poter parlare subito per tutti i formalismi? Note finali Comparazione fra le macchine üü• Slide comparazione\nAbbiamo visto che\nMacchina di turing √® la pi√π generale, utilizza grmamatiche generali (quindi senza vincoli) e calcola cose semidecibili\nPDA, libera, calcola cose decidibili, anche se non sono in grado di dire cose riguardanti ugualgianza boh.\nDFA pu√≤ essere utilizzata per modellizzare tante cose come\nVending machine Circuiti logici Find/replace principalmente √® tutto decibile per questo qua.\n","permalink":"https://flecart.github.io/notes/fondamenti-teorica/","summary":"https://virtuale.unibo.it/pluginfile.php/1295166/mod_resource/content/0/Lez18-Gorrieri.pdf\nHalting problem Questo asserisce che non esiste nessun programma che sia in grado di decidere la terminazione di un altro programma\nQuesto √® un problema che ci √® interessante perch√© vorremmo costruire un compilatore che sia in grado di osservare tutti gli errori possibili del programma. Come vedremo tra poco la risposta sar√† negativa.\nDimostrazione tesi üü®++ Supponiamo che questo programma esista, lo chiamiamo check(P) che restituisce 0 se termina 1 se non termina, allora devo poter essere in grado di scrivere un programma di questo genere","title":"Fondamenti teorica"},{"content":"This small note is an introduction to Topology that follows the introductory arguments of (Armstrong 2013).\nEuler\u0026rsquo;s Theorem We will start our journey in topology following a classical example in the history of Mathematics the relation:\n$$ v - e + f = 2 $$ Valid for classical Polyhedrons.\nBasic definitions Polyhedron It\u0026rsquo;s a collection of plane polygons (see Programmazione lineare#Poliedro) such that:\nEvery polygon shares each of its edges with exactly another polygon We have vertexes that can be shared by many polygons. Informally we have a piece of surface with a vertex. Theorem statement If we have a Polygon $P$ such that\nAny two vertices of $P$ are connected through a path in the edges. (connected principle) Any loop on $P$ made of its vertices made of straight line segments (we don\u0026rsquo;t need to pass through the edges) separates $P$ in two pieces. (informally if we cut there then the surface does not separate completely). Then we have $v - e + f = 2$, where $v$ are the number of vertices, $e$ the number of edges and $f$ the number of faces. The two conditions above are justified by the counter example observations: . Which clearly do not follow the theorem\nSimple proof Here, I will just sketch the general proof (there will be some interesting observation, but that is left for later). We know that vertices + edges are just a graph, and for every graph there is a easy way to find a tree $T$ with all of the graph nodes. By a property of the trees, we know that every tree has $v - e = 1$, easily provable with induction on the number of nodes. The we construct some sort of a dual tree which we call $\\Gamma$ built in this way.\nVertices are random points on every face of $P$ Two vertices are connected if their corresponding faces share an edge, and this edge does not belong to $T$. It can be proven that $\\Gamma$ is indeed a tree, thanks to the 2 initial hypothesis, and then we know that $$ v - e + f = v(T) - \\left[ e(T) + e(\\Gamma)\\right] - v(\\Gamma) = \\left[ v(T) - e(T) \\right] + \\left[ v(\\Gamma) - e(\\Gamma) \\right] = 1 + 1 = 2 $$ The beautiful observation about this proof, is that every polygon that satisfies those hypothesis can be divided in two parts, which imply it is topologically equivalent to split a sphere (this is why it\u0026rsquo;s 2!) Which means that it is just a deformed sphere from the faces point of view.\nLegendre\u0026rsquo;s Proof Before we can understand this proof, we need to understand how to calculate the area of a spherical polygon which is just a polygon mapped to the surface of a unit sphere.\nSpherical Polygon Area Lemma: given angles $\\alpha_{1}, \\dots \\alpha_{k}$ and $n$ edges then the area of the spherical polygon is $$ \\sum_{i = 1}^{k} \\alpha_{i} + 2\\pi - n\\pi $$ This value is known as the excess in spherical geometry, and one can prove that the area is equal to $A = E\\cdot R^{2}$ where $R$ is the radius of the sphere. This is also known as Girard\u0026rsquo;s theorem.\nProof: If you have Girard\u0026rsquo;s theorem (advised to check the link for a visualization), useful for simple triangles, then it\u0026rsquo;s easy to recompose everything and have that theorem, in this case we will just prove Girard\u0026rsquo;s theorem:\nConsider a Spherical Lune, it\u0026rsquo;s easy to see that it\u0026rsquo;s area, given an angle $\\alpha$, is given by this proportion $$ 2\\pi : \\alpha = 4\\pi : \\text{ Area} \\implies \\text{Area} = 2\\alpha $$ If we sum all the lunes of a triangle, we have the area of the entire sphere and three times our triangle. Let\u0026rsquo;s all $A$ the area of the triangle, we have (because we count the antipodal triangle, and use lunes to cover the entire sphere): $$ 2(2\\alpha + 2\\beta + 2\\gamma) = 4\\pi + 2A + 2A \\implies A = \\alpha + \\beta + \\gamma - \\pi = E $$ The proof So now we know that a specific spherical polygon\u0026rsquo;s area is $\\sum_{i = 1}^{k} \\alpha_{i} - (2 - n) \\pi$ We now sum over all the polygons and we obtain $2\\pi v - 2n\\pi e + 2\\pi f = 4\\pi$ where $v$ is the number of vertices, $e$ of edges and $f$ faces, that is the number of polygons. This is true because every vertex at the end is counted as $2\\pi$ in radians, and every edge is counted twice, and we are summing $f$ polygons so we have the last term. Simplifying the $2\\pi$ we obtain $v - e + f = 2$ which is the Euler\u0026rsquo;s theorem. This is a nice proof, and quite easy after you know the Spherical Polygon area lemma.\nReferences [1] Armstrong ‚ÄúBasic Topology‚Äù Springer Science \u0026amp; Business Media 2013\n","permalink":"https://flecart.github.io/notes/introduction-to-topology/","summary":"This small note is an introduction to Topology that follows the introductory arguments of (Armstrong 2013).\nEuler\u0026rsquo;s Theorem We will start our journey in topology following a classical example in the history of Mathematics the relation:\n$$ v - e + f = 2 $$ Valid for classical Polyhedrons.\nBasic definitions Polyhedron It\u0026rsquo;s a collection of plane polygons (see Programmazione lineare#Poliedro) such that:\nEvery polygon shares each of its edges with exactly another polygon We have vertexes that can be shared by many polygons.","title":"Introduction to Topology"},{"content":"Introduzione ai campi magnetici Introduzione storica (non impo) üü© Il magnetismo √® stato in primi osservato e documentato da Greci, che hanno osservato che materiali metallici come ferro, questo √® successo in magnesia, una penisola dell\u0026rsquo;Asia minore, mentre elettro era pi√π sull\u0026rsquo;ambra, che credo fosse il nome dato a quel materiale.\nUna cosa nota era che se vicino a un materiale magnetico, venivano create linee con materiale ferroso all\u0026rsquo;estremit√† (limatura magnetica).\nUna altra cosa, conosciuta dai cinesi, era che un materiale magnetico si orientava sempre sullo stesso verso, per cui possiamo chiamare polo magnetico sulla barretta. E si chiamavano poli nord e sud geografici. Si pu√≤ paragonare a un Dipolo elettrico. E permette di analizzarlo come se fosse una carica magnetica. abbiamo quindi un dipolo magnetico, almeno matematicamente analizzabile in questo modo.\nSperimentalmente si √® osservato che *poli stesso segno si respingevano e di valore opposto si attraevano in modo simile a quanto succedeva per Legge di Coulomb. Solo che in questo caso non ha senso parlare di unit√† di carica che la genera diciamo. C\u0026rsquo;√® la teoria del monopolo ma poi quella non so quanto sia effettivamente vero.\nFino al 1800 questo √® quanto si sapeva, dopo si ebbe uno studio sistematico, permesso da un progresso tecnologico (forse direi ingegneristico), grazie alla pila di Alessandro Volta, con l\u0026rsquo;inizio dello studio dei circuiti. Con lo studio dell\u0026rsquo;interazione del campo magnetico ed elettrico si hanno i bei risultati :).\nCampo magnetico terrestre üü© La terra si comporta come un magnete gigante :D. E creer√† momenti di dipolo per i magnetini presenti sulla superficie. ma nota: il polo sud geografico, in realt√† √® il polo nord magnetico! E anche il contrario. Esiste anche una versione periodica (non definita), ogni qualche milioni di anni. Si nota da come si sono solidificati i magma nel tempo (si solidificher√† in un certo modo). La teoria pi√π buona √® che ci sono delle specie di dinamo all\u0026rsquo;interno della Terra che generano il campo. Il monopolo magnetico üü© Se esistesse il monopolo magnetico potremmo definirlo in modo simile a Coulomb, vedi Legge di Coulomb: $$ \\lvert \\vec{F} \\rvert = k_{m} \\frac{C_{m}^{1}C_{m}^{2}}{r^{2}} $$ Per il Dipolo elettrico √® facile questo, basta prendere il dipolo e separarlo! Come si fa per il monopolo? Se taglio una calamita in due, avr√≤ due nuove calamite, questa caratteristica continua anche a livello atomico -\u0026gt; non esistono monopoli magnetici secondo questa scia La ricerca del monopolo magnetico √® molto sentita, perch√© il modello standard prevede l\u0026rsquo;esistenza di questi monopoli per√≤ sperimentalmente non sono stati rilevati ancora. Questa cosa motiva che la legge simile a Coulomb √® abbastanza inutile. NOTA: essendo la legge sperimentalmente sempre inversamente proporzionale a $r^{2}$ si pu√≤ utilizzare la Legge di Gauss. Condizione necessaria per far funzionare la dimostrazione con angoli solidi.\nL\u0026rsquo;induzione magnetica e dipolo magnetico üü© Partendo da conoscenze presenti per il Dipolo elettrico possiamo andare a definire il campo magnetico come la linea individuata dai dipoli magnetici, perch√© i dipoli si allineeranno in qualche modo quando sono dentro un campo magnetico. Con la convenzione che entra in sud ed esce in nord. In un certo senso il sud √® equivalente al - del dipolo elettrico e il nord al +.\nQuesto √® il campo di induzione magnetica chiamato $\\vec{B}$\nFigure descrittive di quanto detto sul campo magnetico, in ordine vediamo i campi, molto simili a quelli che si possono trovare per il dipolo, e l\u0026rsquo;allineamento di dipoli . Si pu√≤ anche avere un ferro di cavallo per avere un campo uniforme. Campo solenoidale üü© Essendo il monopolo magnetico non esistente, c\u0026rsquo;√® ancora una propriet√† simile alla Legge di Gauss anche nel nostro caso, ma la somma totale √® sempre nullo (perch√© se divido un dipolo ho un altro dipolo). $$ \\oint_{\\Sigma}\\vec{B} \\cdot \\vec{s} = \\frac{M_{tot}}{k} = 0 $$ Che √® la definizione di un campo solenoidale, ossia sempre 0 per qualunque superficie.\nQuindi immediatamente possiamo usare il teorema della divergenza -\u0026gt; Divergenza e Circuitazione e otteniamo $$ \\vec{\\nabla} \\cdot \\vec{B} = 0 $$ √à anche chiamata la seconda legge di Maxwell.\nRiguardo alla circuitazione, basta prendere un percorso sulla stessa linea (il campo √® sempre sullo stesso verso, anche fra i poli (cosa che invece per dipoli elettrici non √® vero)), √® diverso da zero, quindi il campo che abbiamo non √® conservativo, questo √® sempre vero per campi solenoidali. Questo √® quanto si sapeva all\u0026rsquo;inizio del 800, fine 700.\nCi dice che non ci sono monopoli magnetici, perch√© √® una parte della materia (√® il singolo atomo che √® un dipolo, per questo si distrugge tutto), i dipoli non sono altro che correnti elettriche in materiali!\nDa approfondire: In Diamagnetici √® Larmor in Magnetismo nella materia. In paramagnetici √® corrente intrinseco In ferromagnetici √® lo spin degli elettroni\nEsperimenti storici Facciamo una carrellata fra esperimenti storici che hanno relazionato correnti e cambi magnetici e hanno contribuito a una migliore comprensione del motivo per cui abbiamo certi fenomeni. Attorno al 1820 questi esperimenti, poi nel 1865 Maxwell enuncia le leggi, in poco tempo conosciamo del tutto tutti i fenomeni di elettromagnetismo classico.\nEsperimenti di Oersted üü© Un filo percorso da corrente genera un campo magnetico\nQuesto √® un primo collegamento col campo elettrico! Come fanno cariche che si muovono a creare campo elettrico?\nOersted ha messo un magnete vicino a un filo. E ha osservato che se si chiude lo switch del circuito, l\u0026rsquo;ago magnetico gira. Esperimenti di Faraday üü©- Faraday ha poi l\u0026rsquo;intuizione che un magnete pi√π magnete √® in grado di influenzare la corrente, vede che se non c\u0026rsquo;√® corrente √® tutto ok, non succede niente, se per√≤ ci fa scorrere corrente, vede una forza perpendicolare al filo.\nUn filo percorso da corrente si comporta come un magnete\nOssia il filo √® in grado di attrarre il magnete.\nEsperimenti di Ampere üü© Ampere ha avuto l\u0026rsquo;intuizione che pu√≤ trattare fili come magneti, quindi due fili con corrente vicina dovrebbero essere soggette a forza, ed √® effettivamente ci√≤ che nota. E nota anche quanto presente in immagine: se sono verso diverso sono repulsive, altrimenti attrattive. Questo veramente sembra motivare l\u0026rsquo;utilizzo del filo per studiare il campo magnetico. il vantaggio di usare questo √® che\nFacilit√† di costruzione rispetto alla calamita La geometria del filo √® sotto mio controllo L\u0026rsquo;intensit√† di corrente √® modulabile, quindi posso definire l\u0026rsquo;intensit√† del campo nei magneti. Seconda legge di Laplace e Esperimento üü© Definiamo l\u0026rsquo;esperimento come segue, una sbarretta metallica libera di scorrere fra le due e due supporti sopra, sotto abbiamo una batteria. Ci metto un dinamometro, e cos√¨ ho la misura della forza esercitata sulla sbarretta metallica mi serve per misurare la forza del campo magnetico. Nel nostro sistema avremo che la barretta ha lunghezza $d\\vec{l}$, e una corrente che sale e scende (proprio come circuito) Le osservazioni sono:\n$\\lvert d\\vec{F} \\rvert \\propto i \\lvert d\\vec{l} \\rvert$ $d\\vec{F} \\perp d\\vec{l}$ $\\lvert d\\vec{F} \\rvert = f(\\theta)$, dove $\\theta$ √® l\u0026rsquo;orientazione nello spazio di $d\\vec{l}$, e ho sempre un angolo in cui √® 0, che quello uscente dal piano credo. Allora cos√¨ ho definito l\u0026rsquo;interazione del campo $\\vec{B}$ con un filo percorso da corrente $i$. allora abbiamo con le osservazioni di sopra possiamo dire Seconda legge di Laplace: $$ d\\vec{F} = id\\vec{l} \\times \\vec{B} = i\\lvert d\\vec{l} \\rvert \\lvert \\vec{B} \\rvert \\sin \\theta $$ Questo permette ricavare il modulo della forza di B. Posso anche misurare la direzione con l\u0026rsquo;angolo. Questo √® utile per dare la definizione del campo magnetico. Probabilmente la forza √® sulla nuvola di elettroni o portatori di carica dentro al filo quando si muovono. Questo motiva chiedersi quanto sia la forza sul singolo elettrone che si muove:\nCampo magnetico Anche qui vale il principio di sovrapposizione! vedi Campo elettrico.\nAnalisi forza su cariche in movimento üü©- Dall\u0026rsquo;esperimento di Laplace abbiamo modo di derivare la forza esercitata sul singolo elettrone in movimento $$ d\\vec{F} = \\vec{J} \\cdot d\\vec{S} \\cdot d\\vec{l} \\land \\vec{B} $$ Ho che $J$ e $dS$ hanno stessa direzione e verso per costruzione, e sarebbe bene prendere stesso verso anche per la lunghezza, mi permette di scrivere $dS$ e $dl$ stesso verso, quindi √® solamente uno scalare, e posso spostarlo in giro nel prodotto vettoriale:\n$$ d\\vec{F} = \\vec{J} \\land \\vec{B} (d\\vec{s} \\cdot d\\vec{l}) = \\vec{J} \\land \\vec{B} d\\tau $$ Quindi ora abbiamo la forza in funzione al volume, ma io conosco il volume e conosco $J$ quindi abbiamo: $$ d\\vec{F} = nq\\vec{v}_{d} \\land \\vec{B} d\\tau $$ Ma ricordiamo da Corrente Elettrica che $n$ √® il numero di cariche per unit√† di volume, ma abbiamo l\u0026rsquo;unit√† di volume, quindi $n d\\tau = N$ il numero totale di elettroni in uno spazio molto piccolo $dl$!, quindi abbiamo che\n$$ d\\vec{F} = dNq\\vec{v}_{d} \\land \\vec{B} $$ Questa √® relazione diretta fra chi si muove dentro e la quantit√† di forza che ho! Questa √® la su un segmento di filo infinitesimale!\nForza di Lorentz üü© Abbiamo che la forza esercitata su una singola carica √® uguale a: $$ \\vec{F} = q\\vec{v} \\land \\vec{B} $$ $$ \\lvert \\vec{F} \\rvert = \\lvert q \\rvert \\lvert \\vec{v} \\rvert \\lvert \\vec{B} \\rvert \\sin \\theta $$ E la forza totale √® la somma di tutte queste particelle in una sezione di filo!. La nota importante √® che una forza perpendicolare alla direzione della velocit√†, quindi √® una forza centripeta che implica che non pu√≤ cambiare il modulo della forza di $v$. pu√≤ solo cambiare la direzione, il che implica che non fa lavoro!.\n-\u0026gt; La forza di Lorentz non √® posizionale, quindi non ha senso chiedersi se √® conservativa, perch√© tanto lavoro √® sempre 0.\n-\u0026gt; √à una forza media sul portatore di carica, perch√© non posso andare a misurare il singolo portatore, da un punto di vista qualitativo la forza di Laplace √® molto meglio!\nQuesto ci permette di definire una nuova unit√†, che √® il Tesla, ossia quanto campo magnetico per avere 1N di forza su una singola particella di $q$\nForza di Lorentz generalizzata üü© possiamo generalizzare la Forza di Lorentz per una forza su una carica, dovuta ai due campi: $$ \\vec{F} = q\\vec{E} + q\\vec{v} \\land \\vec{B} $$ Se ho due cariche che stanno ferme, tutta la teoria sviluppata in elettrostatica funziona ancora! Se una delle due, invece, si muove c\u0026rsquo;√® solo elettrostatica ancora\nSistema di due cariche Se entrambe si muovono ho entrambe le forze\nIntroduzione al problema üü© Una cosa strana √® che dipende dal sistema di riferimento perch√© la velocit√† pu√≤ cambiare col sistema. √à un hint sulla correlazione fra i due campi. Come si pu√≤ risolvere questo? Se ho due cariche ferme, ma io mi muovo, allora per me loro si muovono entrambe, e dal mio punto di vista sono soggette anche di forza magnetica sulle cariche.\nQuindi succede che per una carica ho sia forza elettrica, e anche in questo caso una forza magnetica opposta! Mentre per il filo si vede sempre non cambiando anche sistema di riferimento!\nAnalisi della forza caso per caso üü®- Proviamo ad analizzare secondo due sistemi di riferimento, una in cui il sistema √® solidale con le due cariche, una altra con riferimento inerziale, con velocit√† $v$ lungo asse $x$. Per il principio di relativit√† di galileo, dovrei osservare la stessa cosa, vediamo nei due cosa si vede.\nO: Agisce solamente la forza di coulomb. $$ \\vec{F} = q_{1}\\vec{E}_{2} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R_{2}} \\hat{d} $$ $O'$: dal mio sistema di riferimento, le due cariche si muovono con velocit√† $-v$ verso la parte opposta. $$ \\vec{v}_{1} = \\vec{v}_{2} = -v $$ Allora per la forza di Lorentz abbiamo: $$ \\vec{F}' = q_{1}\\vec{E}_{2} + q_{1}\\vec{v}_{1} \\times \\vec{B}_{2} $$ Quindi abbiamo un campo magnetico generato dal movimento dell\u0026rsquo;altra carica in pi√π.\nProviamo a guardare il campo magnetico generato, possiamo usare la relazione del campo magnetico generato da singola carica e abbiamo: $$ \\vec{B}_{2} = \\mu_{0} \\frac{q_{2}}{4\\pi} \\frac{ \\vec{v}_{2} \\times\\hat{r}}{r^{2}} = \\mu_{0} \\frac{q_{2}}{4\\pi} \\frac{ \\vec{v}_{2} \\times -\\hat{k}}{r^{2}} \\implies \\vec{F} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R^{2}} \\hat{d} + \\frac{1}{4\\pi\\varepsilon_{0}} q_{1} v \\cdot \\mu_{0}\\varepsilon_{0} \\frac{q_{2} v \\cdot (-\\hat{d})}{R^{2}} $$ in cui la direzione √® dentro il foglio, per il campo magnetico. Raccogliendo l\u0026rsquo;ultima abbiamo\n$$ \\vec{F} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R^{2}} [1 - \\varepsilon_{0} \\mu_{0} v^{2}] \\hat{d} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q_{1}q_{2}}{R^{2}} \\left[ 1 - \\frac{v^{2}}{c^{2}} \\right] \\hat{d} $$ Questo √® vero perch√© per velocit√† molto piccole √® simile al normale, ma la cosa strana si ha quando cominciamo ad avvicinarci alla velocit√† della luce, perch√© l√¨ cambia! Abbiamo forze diverse in due sistemi di riferimento inerziali!\nCorrelazione E e B per relativit√† galileiana üü®- Proviamo a utilizzare la relativit√† galileiana (che √® una legge prima presente, e affinch√© valga i campi elettrici e magnetici devono essere correlati), per questo ragionamento deve essere necessariamente che le due forze siano uguali, ma allora abbiamo questo risultato: $$ \\vec{F}' = \\vec{F} \\implies q_{1}\\vec{E}_{2} = q_{1}\\vec{E}_{2}' + q_{1}\\vec{v}_{1} \\times \\vec{B}_{2}' \\implies \\vec{E}_{2} = \\vec{E}_{2}' + \\vec{v}_{1} \\times \\vec{B}_{2}' $$ Ossia che il campo elettrico cambi a seconda del sistema di riferimento, e la stessa cosa per il campo magnetico. Proviamo a capire in che modo cambiano questi a a seconda del sistema di riferimento. Questo lega strettamente i valori di $E$ e $B$ in due sistemi di riferimento inerziali. Possiamo fare la stessa cosa per i campi magnetici $$ \\vec{B}_{2} = 0 = \\vec{B}_{2}' - \\frac{1}{c^{2}} \\vec{v} \\times \\vec{E}_{2}' $$ Cosa che si deriva utilizzando la relazione campo magnetico ed elettrico. Fino al 1905 si √® convinti di questo.\nCorrelazione E e B per relativit√† ristretta (non fare). La forza tridimensionale non √® un invariante relativistico, ma la forza che conta anche il tempo. (per quella relativit√† non c\u0026rsquo;√® problema che la forza vari).\nLa teoria di Einstein afferma che: $$ \\begin{cases} F_{x}' = F_{x} \\\\ F_{y}' = F_{y} \\sqrt{ 1 - \\frac{v^{2}}{c^{2}} } \\\\ F_{z}' = F_{z} \\sqrt{ 1 - \\frac{v^{2}}{c^{2}} } \\end{cases} $$ Nel momento in cui la velocit√† √® lungo $x$, quindi la forza cambia secondo la radice. Ma nell\u0026rsquo;analisi di sopra non abbiamo il rapporto con la radice, ma velocit√† senza radice, come mai? Anche qui $E$ ha dipendenze con $B$, ma le relazioni sono diverse.\nE sono (li ha dati cos√¨ il prof. senza giustificarli): $$ \\begin{cases} E_{x}' = E_{x} \\\\ E_{y}' = \\gamma [E_{y} - v B_{z}] \\\\ E_{z}' = \\gamma [ E_{y} + v B_{z}] \\\\ B_{x}' = B_{x}' \\\\ B_{y}' = \\gamma [B_{y} + \\frac{v}{c^{2} }E_{z} ] \\\\ B_{z}' = \\gamma \\left[ B_{z} - \\frac{v}{c^{2}} E_{y} \\right] \\end{cases} $$ Dove $\\gamma = \\frac{1}{\\sqrt{ 1 - \\frac{v^{2}}{c^{2}}} }$ Applicando queste trasformazioni nel nostro sistema a due cariche abbiamo che\n$$ E_{y}' = \\gamma E_{y} = \\frac{\\gamma}{4\\pi\\varepsilon_{0}} \\frac{q_{2}q_{1}}{R^{2}} $$ E che $$ B_{z}' = \\frac{\\gamma v}{c^{2}} E_{y} $$ E possiamo sostituirli dentro la legge generale di Lorentz per la forza finale, che √® simile a quella versione di Galileo, un po\u0026rsquo; differente\n$$ F' = q_{1}\\gamma E_{y} + q_{1}v \\frac{\\gamma v}{c^{2}} E_{y} = \\gamma q_{1} E_{y}\\left( 1 + \\frac{v^{2}}{c^{2}}\\right) = q_{1}E_{y} \\sqrt{ 1 + \\frac{v^{2}}{c^{2}} } $$ Questo valore √® proprio il valore predetto come trasformazione secondo la relativit√†?\nPrima legge di Laplace Prima legge di Laplace üü© Vogliamo sapere esattamente quale sia il valore del campo magnetico generato da un filo. Il piccolo tratto di energia sar√† di valore $$ d\\vec{B} = \\frac{\\mu_{0}i}{4\\pi} \\frac{d\\vec{l} \\times \\hat{r}}{ r^{2}} $$ Questa √® la **prima legge di Laplace**. Osservazioni:\nPerpendicolare sempre a l e r, quindi al piano del nostro disegno Permette di capire quale sia il modulo del campo magnetico, e si nota che cade su $\\frac{1}{r^{2}}$ che √® la cosa che permette l\u0026rsquo;utilizzo della legge di gauss per i monopoli magnetici Sulla congiungente della retta dl, il valore del campo magnetico √® 0! Permeabilit√† magnetica del vuoto üü© Il valore di $\\mu_{0}$ verr√† trovato sperimentalmente, e sar√†: $$ \\text{permeabilit√† magnetica del vuoto}: \\mu_{0} = 4\\pi \\times 10 ^{7} \\, \\frac{Tm}{A} $$ Scoperta direi in modo simile a quanto fatto per permeabilit√† elettrica nel vuoto! Per Legge di Coulomb\nIl valore del campo magnetico e la forza di un altro filo definiscono il comportamento qualitativo per i campi magnetici!\nCampo magnetico totale üü© Per trovare il valore basta sommare tutti i contributi!\n$$ \\vec{B} = \\int _{Filo} d\\vec{B} = \\int _{Filo} \\frac{\\mu_{0}i}{4\\pi} \\frac{d\\vec{l} \\times\\hat{r}}{r^{2}} $$ In modo simile a quanto fatto in Campo elettrico, se siamo in regime stazionario, la $i$ pu√≤ essere portata fuori dall\u0026rsquo;integrale\nCampo magnetico da singola carica üü®+ La definizione precedente, con il $4\\pi$ ci permette anche di scrivere in una forma carica utilizzando la densit√† di corrente Corrente Elettrica. $$ id\\vec{l} = \\vec{J} \\cdot d\\vec{s} d\\vec{l} = \\vec{J} \\cdot d\\tau = nq\\vec{v}_{d} d\\tau = Nq\\vec{v}_{d} $$ Quindi ha un valore generato dal totale di cariche in movimento in un unit√† di volume infinitesimo. Questa osservazione ci permette di scrivere la seconda legge in relazione alla velocit√† di deriva: E isolare anche il campo magnetico per singola carica!\n$$ \\vec{B} = \\frac{\\mu_{0}q}{4\\pi} \\frac{\\vec{v}_{d} \\times\\hat{r}}{r^{2}} $$ Da qui osserviamo che se si muovono pi√π in fretta allora il campo magnetico va pi√π in fretta! E sappiamo che la velocit√† √® dipendente dal campo elettrico da cui sono sottoposti.\nLegame col campo elettrico üü®+ Dalla formula di sopra possiamo trovare la relazione col campo elettrico ponendo che $$ \\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{q\\hat{r}}{r^{2}} \\implies \\frac{q}{r^{3}} = \\vec{E} 4\\pi\\varepsilon_{0} $$ E questo valore si pu√≤ sostituire sopra, e diventa $$ \\vec{B} = \\frac{\\mu_{0}\\vec{v}_{d}}{4\\pi} \\times \\vec{E} 4\\pi\\varepsilon_{0} = \\mu_{0}\\varepsilon_{0} \\vec{v}_{d} \\times \\vec{E} = \\frac{1}{c^{2}} \\vec{v}_{d} \\times \\vec{E} $$ E la relazione stupenda √® con la velocit√† della luce, e si nota come queste sono veramente costanti fondamentali dell\u0026rsquo;universo!? √à da notare per√≤ che questo vale solo per valori della velocit√† tali per cui siano molto minori rispetto alla velocit√† della luce. (regimi non relativistici).\n","permalink":"https://flecart.github.io/notes/magnetismo/","summary":"Introduzione ai campi magnetici Introduzione storica (non impo) üü© Il magnetismo √® stato in primi osservato e documentato da Greci, che hanno osservato che materiali metallici come ferro, questo √® successo in magnesia, una penisola dell\u0026rsquo;Asia minore, mentre elettro era pi√π sull\u0026rsquo;ambra, che credo fosse il nome dato a quel materiale.\nUna cosa nota era che se vicino a un materiale magnetico, venivano create linee con materiale ferroso all\u0026rsquo;estremit√† (limatura magnetica).","title":"Magnetismo"},{"content":"Struttura del DBMS Introduzione ai DBMS Schema riassuntivo #### Operazioni classiche Ci stiamo chiedendo, come facciamo a descrivere i processi che portano alla comprensione della query e della retrieval degli elementi utili? Questo deve fare il DBMS, ossia capace di - Aggiornare tuple - Trovare tuple - Gestire gli accessi - Gestire accessi concorrenti? ### Query processor #### Query compiler (3) üü© - Parsing (crea l'albero di derivazione per la nostra query) - Pre-processing (fa check semantici sulla query) - Optimization, si occupa lui di migliorare L'ottimizzazione #### Execution engine üü© Esegue l'effettiva computazione per la query, ed √® il punto d'incontro col resto (indexes, e logging per dire) Esegue il piano di esecuzione che probabilmente un livello superiore ha calcolato Interagisce con tutti gli altri componenti del db (ad esempio Log per transazioni e durabilit√†, buffer e scheduler delle operazioni prolly). Anche se non so nei dettagli in che modo esegue questo (alla fine roba assembly? che livello di astrazione ha?)\nThe resource manager Compiti del resource manager (2) üü©\u0026ndash; La cosa principale che fa questo √®:\nSapere dove siano le informazioni di interessa Sapere come leggerli e restituirli in fretta In questo senso gestisce le risorse, perch√© gestisce le informazioni, in questo caso risorsa principale del nostro db.\nIndex file record manager üü®++ √à la parte del database che conosce le strutture delle tables e sa accedere ai dati, ossia contiene le strutture di dati utili per l\u0026rsquo;accesso a queste tables.\nPer√≤ non so in che modo √® implementato un index, dovresti guardare in Index, B-trees and hashes.\nBuffer Manager üü© Si occupa di memorizzare in modo temporaneo le informazioni necessarie per fare le join e altre operazioni (anche una cache diciamo). ram riservata. Qui sar√† presente un nodo pi√π forte e normale tipo! Pu√≤ essere molto utile per tenere gli indici, per tabelle pi√π frequentemente accedute! Solitamente 100MB di ram qui!, circa 25k nodi di b-tree anche!\nStorage Manager üü© Probabilmente utilizza hash Index, B-trees and hashes per capire quale esatto blocco gli √® stato richiesto.\nSi occupa di tenere traccia dei blocchi precisi con informazioni nel disco principale (√® la parte del sistema che si occupa di restituire il blocco di interesse una volta richiesto la chiave).\nOther parts Transaction Manager Permette di fare le transazioni. Logging üü©- Come per i filesystem basati su logging, questo √® un metodo utile per tenere traccia dei cambiamenti effettivamente fatti o meno. vedere Filesystem. Aiuta a creare l\u0026rsquo;atomicit√† e la consistenza necessari per ACID.\nCosa fa: Scrive log in RAM, nel buffer manager, e ci sono protocolli per far s√¨ che questi vengano correttamente salvati sul disco. Nel caso di problemi, comunica col recovery manager in modo che il database torni indietro in stato consistente.\nConcurrency control Questa parte si occupa della isolation in ACID, cerca di fare s√¨ che tutte le operazioni siano eseguite come se fossero isolate uno dall\u0026rsquo;altra, in questo caso si parla di serializzabilit√† dell\u0026rsquo;operazione.\nQuesta √® la parte che ha il controllo sui locks come i Semafori o Monitor per la gestione della concorrenza.\nSchedule üü® Una sequenza di azioni (read, write, commit, abort) da un** insieme di transazioni**\nIn questo contesto le transazioni sono una cosa primitiva per dire. (esecuzione cronologica).\nSerializzazione üü•+ Questo schedule si pu√≤ classificare in completo se prende in esame le operazioni di ogni singola transazione. Seriale se viene eseguita una azione alla volta per ogni transazione (anche se potrei farne di pi√π assieme). Significa che faccio prima tutte le operazioni di una singola transazione, poi della prossima e cos√¨ via.\nUno schedule √® serializzabile, se l\u0026rsquo;effetto finale √® come di uno schedule completo seriale.\nTipologie di anomalie di concorrenza (4) Una cosa carina √® che questi processi possono essere intesi come errori di Theory of mind secondo me. Si hanno errori quando una serie fa qualcosa, ma l'altro pensa che lo stato sia di un altro genere. Pi√π in generale questo problema si pu√≤ riassumere in phantom anomaly, perch√© un oggetto viene cambiato nel momento in cui una altra transazione pensa resti la stessa.\nTransaction isolation levels üü• Concurrency control methods (3) La prima √® la pi√π restrittiva, per√≤ ha forti garanzie su serializzabilit√† basate su locks, praticamente il concetto principale √® che una singola risorsa pu√≤ essere usata da una transazione alla volta (non √® totalmente corretto, le read possono essere condivise, ma il concetto resta quello l√¨), quindi se √® concorrente su risorse diverse, non ho problemi Optimistic concurrency control in pratica faccio tutto come se non ci fosse niente, e poi faccio. Timestamping concurrency control, ad ogni transazione √® associata un timestamp e si utilizza questo per decidere chi va prima. Se l\u0026rsquo;ordine viene violato basta rollback della transazione che lo ha violato. Join methods Nested loop join üü© √à l\u0026rsquo;algoritmo $O(n^{2})$ idiota classico per la comparisons\nSingle loop join üü®++ Viene utilizzato un hash o un tree esterno di una relazione per comparare in fretta e vedere se c\u0026rsquo;√® l\u0026rsquo;esistenza.\nIn pratica si chiama single loop perch√© ciclo solamente sulla struttura esterna\nHash based join üü®+ Usiamo double hash!? Non ho capito come. Prendiamo una relazione, quella relazione la salviamo tutta dentro la hash table (con i rispettivi buckets, che siano linked list o rb-trees). Poi prendiamo l\u0026rsquo;altra relazione, passiamo dalla stessa hash, questa avr√† anche lui un bucket, poi su questo bucket ci faccio ricerca lineare per trovare le cose che mi interessano (quindi match su cose piccole). √à molto simile a single loop, solo che in questo caso la struttura √® necessariamente un hash per dire.\nSort Merge Join üü© L\u0026rsquo;algoritmo lineare di sort merge, utile quando si ha un doppio ordinamento per andare a confrontare per benino i due cosi. (this should be the fastest !?!?! solo per dati generali per√≤, but needs ordering).\n","permalink":"https://flecart.github.io/notes/the-database-management-system/","summary":"Struttura del DBMS Introduzione ai DBMS Schema riassuntivo #### Operazioni classiche Ci stiamo chiedendo, come facciamo a descrivere i processi che portano alla comprensione della query e della retrieval degli elementi utili? Questo deve fare il DBMS, ossia capace di - Aggiornare tuple - Trovare tuple - Gestire gli accessi - Gestire accessi concorrenti? ### Query processor #### Query compiler (3) üü© - Parsing (crea l'albero di derivazione per la nostra query) - Pre-processing (fa check semantici sulla query) - Optimization, si occupa lui di migliorare L'ottimizzazione #### Execution engine üü© Esegue l'effettiva computazione per la query, ed √® il punto d'incontro col resto (indexes, e logging per dire) Esegue il piano di esecuzione che probabilmente un livello superiore ha calcolato Interagisce con tutti gli altri componenti del db (ad esempio Log per transazioni e durabilit√†, buffer e scheduler delle operazioni prolly).","title":"The Database Management System"},{"content":" Equivalenza dei tipi (2) üü© Quando possiamo dire che due tipi siano uguali? Solitamente vengono utilizzati due metodi:\nEquivalenza Nominale Quando un nuono tipo introduce un nuovo nome diverso fra tutti i presenti. Credo cos√¨ vada golang. Quindi in questo caso si pu√≤ dire che un tipo √® equivalente solamente a s√© stesso.\nVogliamo fare in questo modo perch√© se definiamo un nuovo tipo solitamente dovrebbe avere funzioni diverse, quindi √® giusto che sia diverso da uqello iniziale.\nEquivalenza di struttura Ossia quando tutte le operazioni, strutture e sottoelementi sono uguali possiamo andare a definire una equivalenza di struttura. (vado anche di pi√π a guardare come vengo utilizzati, a tempo di compilazione).\nIn un modo forse pi√π intuitivo possiamo dire che abbiamo una equivalenza di struttura quando tutti i campi all‚Äôinterno della struttura sono gli stessi.\nPossiamo anche utilizzare una forma pi√π lasca (molto ispirata dal duck typing) chaichiamo questa la compatibilit√† di tipo).\nDuck typing e confronto equivalenza Questo √® molto simile a quanto si fa in duck typing in slide\nSlide duck typing\nIf it walks like a duck, and it quacks like a duck, then it must be a duck. ~a duck\nSlide confronto fra i tipi di equivalenza\nIn pratica possiamo dire che l‚Äôequivalenza nominale porta vantaggi rispetto a quello strutturale.\nNotazione molto pi√π chiara per tipi ricorsivi. Di solito si utilizza una cosa di messo, tipo una parte nominale per dichiarare, e poi fare un controllo strutturale in secondo momento. Controllo del sottotipaggio √® molto pi√π semplice dal punto di vista nominale. Compatibilit√† dei tipi (3) Diciamo che il tipo T √® compatibile con il tipo s, se un valore di tipo T √® ammesso in un qualsiasi contesto in cui sarebbe richiesto un valore di tipo s.\nQuesto √® abbastanza naturale, la compatibilit√† essendo anche simmetrica, sussume anche un ordine parziale (riflessivo e transitivo) su questo possiamo andare ad avere tipi compatibili con l‚Äôiniziale (quindi convertibili, o se parli con set theory li puoi vedere uguali).\nSlide compatibilit√† dei tipi\nQuando ho queste propriet√†:\nAbitanti di un tipo sono anche abitanti di tipo2 (ad esempio in rust andiamo a definire le traits sulle structs). Ci sono le stesse operazioni Conversioni canoniche, o arbitrarie. Allora potrei prendere il primo tipo e considerarlo come del secondo, in questo senso posso dire che sono dei tipi compatibili fra di loro.\nConversione di tipi Pu√≤ essere silente o espicito, se il silente non √® controlalto potrebbe dare dei bugs.\nImportante sottolineare la differenza fra conversione sintattica che in pratica √® solamente una interpretazione diversa della zona di memoria (stessa grandezza credo) oppure proprio da una funzione che applichi questa conversione.\nQuando faccio una conversioen diretta sto facendo una coercizione, ossia una conversione diretta seguendo un certo modo, anche detto marshalling).\nType inference Type inference\nSlide type inference\nQuando con il parsing riesco ad accumulare informazioni irguardo un certo tipo o operazione, quindi riesco ad assegnare un tipo senza che sia stato specificato in modo esplicito.\nAlla fine vado a risolvere una specie di equazioni con i tipi. Se non √® possibile avere abbastanza informazioni per escludere tutto si ritorna un errore. (semmai con una proposta di segnatura, o signature)\nAlgoritmo di unificazione \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Algebra dei tipi/Untitled 8.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Algebra dei tipi/Untitled 8\u0026quot;\u0026gt; ","permalink":"https://flecart.github.io/notes/algebra-dei-tipi/","summary":"Equivalenza dei tipi (2) üü© Quando possiamo dire che due tipi siano uguali? Solitamente vengono utilizzati due metodi:\nEquivalenza Nominale Quando un nuono tipo introduce un nuovo nome diverso fra tutti i presenti. Credo cos√¨ vada golang. Quindi in questo caso si pu√≤ dire che un tipo √® equivalente solamente a s√© stesso.\nVogliamo fare in questo modo perch√© se definiamo un nuovo tipo solitamente dovrebbe avere funzioni diverse, quindi √® giusto che sia diverso da uqello iniziale.","title":"Algebra dei tipi"},{"content":"Sull\u0026rsquo;encoding Introduzione üü© Ossia trattiamo metodi per codificare caratteri dei linguaggi umani, come ASCII, UCS e UTF.\nDigitalizzare significa encodarlo in un sistema che possa essere memorizzato su un dispositivo di memorizzazione elettronico. Ovviamente non possiamo mantenere l\u0026rsquo;informazione cos√¨ come √®, ma vogliamo memorizzarne una forma equivalente, ma pi√π facile da manipolare dal punto di vista del computer. Creiamo quindi un mapping, o anche isomorfismo tra il valore di mappatura (o encoding), solitamente un valore numerico, tra il singolo valore atomico originale e il numero.\nEsempi di cose atomiche per encoding sono:\nCarattere per le parole Pixel per le immagini Sequenza sinusoidale per FFT per il suono o la musica. Vogliamo creare un mapping non ambiguo, quindi uno standard √® necessario!.\nSulle differenze linguistiche (non fare) üü® Ma come fare a creare uno standard che possa essere adatto sia a caratteri arabi, inglesi, cirillici, cinesi coreani o giapponesi?\nSulle caratteristiche linguistiche diverse\nLa scrittura non √® in grado di rappresentare il suono della lingua in modo univoco per tutti i linguaggi (esempi accenti in certe lingue, come l\u0026rsquo;italiano, oppure il fatto che l‚Äôinglese molte pronuncie sono diverse rispetto a quanto si scrive), Danese cambia proprio suono. In ebraico contano solamente le consonenti, le vocali sono solamente un ausilio per la pronuncia.\nArabo ha una forma di corsivo, e la forma del carattere dipende dai caratteri che sono di fianco.\nSecondo ragionamento sulle caratteristiche delle lingue diverse\nOssia pu√≤ cambiare proprio la semantica della parola, a seconda della lingua in cui si interpretano gli stessi caratteri. Quasi il linguaggio si potrebbe intendere una funzione di interpretazione semantica , accennato in Logica Proposizionale.\nLa ricerca dello spazio di rappresentazione (3) üü©- ci interessano in partioclare tre caratteristiche per trovare lo spazio di rappresentazione per i nostri caratteri (che comunque rientrano nei numeri, e sono tutti in $\\N$).\nSlide\nContiguit√† (se ho certi numeri che hanno un certo senso all‚Äôinterno di un) Raggruppamento logico (se hanno funzioni simili vorremmo che siano ancora vicini) Ordine, vorremmo seguire l‚Äôordine alfabetico per questo encoding. (credo il motivo di questa scelta √® affinch√© sia un p√≤ pi√π naturale!) Altre caratteristiche che fanno parte dell\u0026rsquo;encoding (che √® una funzione parziale)\nShift: un codice riservato che cambia mappa da adesso in poi. Lo stesso shift o un secondo carattere di shift, pu√≤ poi far tornare alla mappa originaria Codici liberi: codici non associati a nessun carattere. La loro presenza in un flusso di dati indica probabilmente un errore di trasmissione. Codici di controllo: codici associati alla trasmissione e non al messaggio. Standard passati Stardard poco utilizzati (non importante) üü• Baudot\nUna codifica vecchissima, che nessuno usa, e io non ho mai sentito (siamo circa nel 1850).\nEBCDIC\nSlide\nISO 656-1991\nQuesto √® presente nelle slides ma completamente saltato\nASCII e ISO Latin 1 üü©- American Standard Code for Information Interchange.\nSono 7bit utilizzate e uno come bit di parit√†. Questo mette uno standard fra codifiche fra telescriventi e schede perforate che erano molto presenti all\u0026rsquo;epoca. Ed √® solamente alfabeto latino inglese.\nORIGINE BACKSPACE DELETE, CR E LF\nNella telescrivente avevo bisogno di backspace, per eliminare un carattere. Nelle schede perforate utilizzavo tutti i buchi presenti per significare che non avevo questo carattere, ecco la delete.\nCarriage return, nella telescrivente avevo una testina che andava avanti a scrivere, e bisognava farlo tornare indietro, e per far girare la testina utilizzavo Line-feed.\nEstensioni custom:\nDopo un p√≤ l‚Äôhardware √® diventato molto affidabile, quindi utilizziamo il bit in pi√π per memorizzare un codice come ci √® pi√π comodo. sono le Codepage di ASCII, e ognuno si fa una propria versione.\nGreco\nCirillico\nArabo\nMa nessuno di questo √® standard! L\u0026rsquo;unico forse √® ISO Latin 1\nCaratteri orientali e testi multilingua üü© CODIFICA DEI CARATTERI ORIENTALI\nMa per il cinese non √® possibile mettere tutto in un singolo byte, Quindi utilizzano due byte qui.\nMa anche con due byte non √® possibile avere tutti i caratteri nella lingua, per questo motivo metto solamente i caratteri pi√π utilizzati\nCodifiche cinese giapponesi e coreani\nSlide alfabeti CJK\nIL PROBLEMA DEI TESTI MULTILINGUA\nMa cosa succede se ho un testo multilingua? Come faccio a codificarlo in modo disambiguato?\nDichiarazioni esterne (no, sarebbe per l‚Äôintero documento, dovrei utilizzare un markup per specificarti l‚Äôencoding?? Troppo brutto) Intestazioni interne (sarebbe molto scomodo dover stabilire ogni volta che encoding sia!) Dovrei forse spezzettartelo in troppi modi. Per questo motivo bisognerebbe creare un nuovo encoding, ed √® questo quello che viene fatto in Unicode.\nUnicode e Universal Transformation Format Unicode e ISO/IEC 10646 (storia) üü®+ UN PO DI STORIA\nQuesti due standard sono nati per fare le stesse due cose, senza sapere che facevano la stessa cosa. (UNICODE √® sponsorizzato dai produttori di hardware, ISO √® internazionale ed √® spinto dalle nazioni estere).\nIl problema principale che vanno a risolvere √® quello di essere standard unico per tutti i linguaggi, per esempio in questo modo posso scrivere testo in lingua mista senza darmi troppi problemi!\nHanno avuto una difficolt√† ad universi quando l\u0026rsquo;uno ha scoperto dell‚Äôesistenza dell‚Äôaltro. Poi sono andati a convergere, ossia sono ancora d‚Äôaccordo con l‚Äôencoding presente.\nCOSA √à ENCODATO\nCos√¨ sono nate UCS-2/4 e UTF-8/16/32 che rappresentando rispettivamente una codifica fissa o variable. Questi sono in grado di rappresentare codici di tutti i codici passati!\n3 categorie di cose encodate\nEsempi di codici encodati\nCon tanto spazio disponibile possiamo anche encodare i linguaggi di star trek e Lord of the ring, per√≤ non potevano includere questi linguaggi in uno standard, comunque √® possibile encodarli in uno Private Use Area (6400 di base, che sono quelli inizialmente utilizzate per klingon o Lord of ring) e poi 65k liberi.\nSlide\nPrincipi di unicode (10) (troppi, a memoria non va bene)üü•+ In pratica tutti i caratteri di Unicode sono distinti per semantica, caratteri (quindi la sharfes es tedesca o versione greca sono codici diversi), se ho una P in alfabeti diversi hanno codifiche diverse. Non ho cose riguardanti la grafica!.\nla Composizione dinamica √® una cosa molto cool, per esempio √® quello che sto utilizzando ora, il fatto che scrivo `e, e mi appare la √® accentata.\nSlides\nUniversal Coded Character/UNICODE üü©- Universal Coded Character same as UCS-2 UCS-4\nIn UCS-4 il primo bit √® utilizzato per identificare la differenza fra UTF-8 e UCS-4.\nSlide struttura generale\nIl piano 14 √® in disuso, per tag strani.\nBasic Multilingual Plane (BMP) sono tutti i caratteri nel piano 0, sono quelli pi√π comuni per alfabeti west\nEsempio suddivisione dei piani\nQuesto √® una cosa svantaggiosa per i caratteri latini che andavano gi√† bene con un singolo byte per trasmettere, ecco che entra in gioco il UTF.\nUnicode Trasformation Format üü©- √à una forma variabile per la rappresentazione precedente, il motivo principale per cui esiste √® che per gli americani sarebbe stata una perdita enorme dover aggiugnere quell‚Äôoverhead inutile nella loro trasmissione, loro con 256 restavano gi√† bene.\nSlide necessit√† di UTF\nSPAZI DI CODIFICA IN UTF\nASCII √® compatibilissimo per UTF, in 2 byte ho tutti il resto dei caratteri. in 3 byte stanno tutti i caratteri CJK, in 4 byte stanno tutti i caratteri antichi.\nSlide numero di byte necessari per la codifica\nSTRUTTURA DEI CARATTERI UTF\nEssendo questa una codifica variabile non ho possibilit√† di predire il numero di caratteri in un file, perch√© certi caratteri occuperanno un byte (ASCII normale), mentre altri caratteri occuperanno due byte, come le lettere accentate.\nAllora devo utilizzare un codice per capire se sono all‚Äôinizio del blocco o sto continuando, o lo devo droppare (quando ricevo 10, ma non ho nessun blocco iniziato!) (sono gli schemi di 10, 0, e 110 etc..)\nLa cosa importante √® che ASCII √® subset diretto di UTF, dato che i caratteri latini sono sempre un singolo byte.\nConfronto UTF e UCS\nAlcuni problemi di trasmissione e conversione Byte order mark üü© Utilizzato per risolvere il problema di risolvere se interpretare quanto mandato in Little o big endian.\nUtilizziamo un carattere speciale in unicode, chiamato Zero-Width No-Break Space (ZWNBSP), Il cui codice √® FEFF per capire se il sistema che mi sta mandando qualcosa √® in formato little endian oppure big endian, accennato qui (molto importante per l\u0026rsquo;ordinamento!)\nSlide\nUTF-8 vs Latin-1 üü© Si possono avere problemi di conversione fra questi due standard (perch√© latin 1 utilizza un singolo byte per le cose accentate, mentre utf-8 ne utilizza due).\nSlide problemi comuni di conversione\nContent encoding Escaping ed encoding üü© La necessit√† di fare encoding o escaping √® giustificata principalmente dal fatto che certe applicazioni utilizzano certi caratteri come simboli speciali (e quindi non si potrebbe utilizzarli, un esempio √® l‚Äôandare accapo credo).\nIn pratica si utilizzano questi metodi per aggirare quelli\nEscaping\nOssia sostituiamo il carattere proibito con sequenze alternative che corrispondono alla stessa cosa. Ad esempoio \u0026amp;quot rappresentano le virgolette\n3\nEncoding quando utilizzo una sintassi speciale per rappresentare il suo encoding naturale.\nSlides encoding ed escaping\nMIME I Limiti di SMTP (3) SMTP √® un protocollo molto vecchio, affinch√© le necessit√† nuove siano retrocompatibili, sono presenti alcuni accorgimenti che vedremo in sto pezzo.\nPrincipalmente questi problemi di endoing e escaping sono nati nell‚Äôambiente del protocollo SMTP, perch√©e li c‚Äôerano alcuni caratteri speciali del protocollo, e potevi mandare solamente ascii 7 bit.\nslides limiti SMTP\nMassimo 1 MB Solo ascii 7 bit Ogni 1000 caratteri ci deve essere un CRLF. Il motivo √® che queste restrizioni erano presenti nelle RFC iniziali per SMTP, e dato che non possiamo farne nuovi (troppo costo prolly) ci dobbiamo tenere queste cose.\nGuardare internet message format\nSu come funziona SMTP sono accennate in Livello applicazione e socket\nMultipurpose Internet Mail Extensions üü© il mime riesce a risolvere questi problemi di limiti di SMTP, riesco a trasformare il tutto in un formato compatibile, e riesco anche a ritrasformarlo indietro!\nSchema protocollo MIME\nIn questo modo riesco a risolvere tutti i problemi di limiti SMTP\nCaratteri ASCII US Le sequenze CRLF E la lunghezza dei messaggi (che viene spezzato) TODO: parlare del multitipo\nHeaders del MIME (2)üü® Esempio di headers MIME\nDevono essere specificati due campi:\nContent Type (il tipo del dato, con sottotimo e altri parametri utili che viene mandato, per capire poi dal ricevente cosa conviene convocare per capire il messaggio) Content-Transfer encoding, sono modalit√† per codificare i dati in modo che possano essere adatti al MIME. Esempi di transfer encoding sono sotto. Quoted Printable and Base 64 üü© Esempi di CTE sono quoted-printable, BASE64, nel primo si fanno escaping per caratteri che non sono printabili con un = seguito dal numero corrisopndente al carattere, di solito sono utilizzati solamente per messaggi con poche eccezzioni rispetto ASCII\nSlide Quoted-printable\nBASE64 da leggere BaseSessantaquattro, o BeisSicstiFor, non mix.\nPer BASE √® tutto tradotto in una codifica byte printabile, ossia si utilizzano 64 caratteri ASCII printabili per codificare 3 byte alla volta, questi 3 byte sono codificati in 4 lettere della mappa precedente, che si noti sono 2alla 6 caratteri.\nSe mi mancano byte alla fine aggiungo del padding, che sono delle = nella parte encodata (il resto sono degli 0 credo).\nSlides base64\n","permalink":"https://flecart.github.io/notes/codifica-dei-caratteri/","summary":"Sull\u0026rsquo;encoding Introduzione üü© Ossia trattiamo metodi per codificare caratteri dei linguaggi umani, come ASCII, UCS e UTF.\nDigitalizzare significa encodarlo in un sistema che possa essere memorizzato su un dispositivo di memorizzazione elettronico. Ovviamente non possiamo mantenere l\u0026rsquo;informazione cos√¨ come √®, ma vogliamo memorizzarne una forma equivalente, ma pi√π facile da manipolare dal punto di vista del computer. Creiamo quindi un mapping, o anche isomorfismo tra il valore di mappatura (o encoding), solitamente un valore numerico, tra il singolo valore atomico originale e il numero.","title":"Codifica dei caratteri"},{"content":"Processo design del database Il design Some design steps (3) (non impo) How to gather requirements? üü®+ Come si pu√≤ raccogliere i dati degli utilizzatori?\nparlare col il personale che dovr√† utilizzare questi sistemi Documentazione esistente Interview di persone che dovr√† utilizzare queste risorse O Moduli per fare sampling Top-down approach La cosa brutta √® che questi requisiti non possono essere standardizzati, ci sono molte necessit√†, molto diverse fra i loro, quindi √® utile andare a parlare con gli esperti e capire cosa abbiano bisogno per i dati. Consiglio del prof. √® partire dai senior e poi scendere, perch√© quelli in alto hanno un punto di vista pi√π ampio ma con meno dettagli diciamo.\nHow to ask the requirements √à molto facile non capire un interlocutore, basta usare il gergo specifico di quell\u0026rsquo;ambito. Anche i maranza per esempio hanno il proprio gergo che non √® comprensibile. Bisogna chiedere cosa hai bisogno, secondo le necessit√† soprattutto! Esempi possono semplificare un sacco. Una cosa molto importante √® mantenere il linguaggio semplice e fare le domande giuste (dividere le domande funzionali con le domande di dati utili da memorizzare). √à difficile sapere cosa √® importante mantenere per una istituzione. Solitamente se usano un gergo specifico √® bene provare a comprendere cosa significhi la parola specifica. Un bias comune √® che le persone tendono a parlare di problemi recenti, che non potrebbero riflettere le necessit√† a lungo termine per i dati.\nUn glossario dei termini √® molto importante per stabilire il significato in quel contesto.\nHow to create entities and relations? (4) ##### Storicizzazione (!) Pu√≤ essere fatta in due modi, o con due relazioni, oppure con una generalizzazione. Metodi di modellazione Top down üü© Parto dai requisiti e provo a raffinarli passo passo fino ad avere uno schema finale Bottom up üü© Parto dalle specifiche e costruisco i singoli componenti fino ad arrivare a schemi collegati assieme Inside out üü© Parto da un requisito chiaro, che costruisco e poi inizio a costruire gli altri secondo quando bene ho capito sono relazionati.\nSteps per design concettuale Per il prof. si pu√≤ passare al design logico subito se si √® molto bravi, per√≤ il suo consiglio √® sempre partire da alto livello e poi andare a definire tutte le relazioni. Entity-Relationship model Introduction to modeling phases The conceptual modelling phase üü© It\u0026rsquo;s a data representation is independent from the system, but it\u0026rsquo;s useful to show how are the different entities connected to each other.\nQuesta √® la prima fase del processo di design di un database, nasce principalmente da una inefficacy of the relational structure (too much information), quindi si vuole usare come via di alto livello per analizzare la struttura!\nVisual documentation that is useful for docs. Other modelling phases (2) üü© Logico, ne parliamo in Database logical design e poi il fisico non viene trattato in questo corso, e dovrebbe essere bene astratto.\nEntity Definition of entity üü© An entity represents a class of \u0026ldquo;objects\u0026rdquo; sharing common properties, but still having an autonomous existence. It is clearly heavily linked to the concept of object in OOP (see Classi OOP), that is the framework where the ER model was born.\nEntity identifier, internal üü© NOTA: queste non sono chiavi! Si chiamano in modo diverso! It could be an internal identifier formed by the attributes of the single relationship, or external if it is identified by some kind of relationship. External identifier üü© #### Generalization and specialization üü© One entity $E$ could be composed by many components $E_{1}, E_{2}, \\dots E_{N}$, this is a **generalization** relationship, the inverse is a a specialization. There are also some properties to consider: - Every property in $E_{i}$ is used in some way in $E$ - Every instance of $E_{i}$ is an instance of $E$ too. Types of generalization (2) üü© It could be total/partial or disjoint/Overlapped. It is total if the parent is totally composed by the child entities, otherwise it\u0026rsquo;s partial. A total relationship has a full arrow, while a partial has an outlined arrow as pointer.\nIt is disjoint if the children doesn\u0026rsquo;t have anything in common (property-wise) and overlapped otherwise.\nData dictionary (3) üü© The data dictionary is a quick way to represent the conceptual model, some examples are given down there. There are also some non-expressible constraints that in the example is not reported, but are the cardinality or other types of constraints that the model has. Relationships Definition of relationships üü© A relationship is a connection between two or more entity types. Usually is given a name to the relationship, that summarizes his semantic meaning. Singular nouns are preferred.\nExample of relationship: Arity of relationship üü© A relationship is not limited to connect two entity types, it can connect more, and this value defines the arity of the relationship. In each case the relationship is represented as a tuple, that is unique, meaning that more instances of the same type could not exist: You can\u0026rsquo;t have the same tuple within the relationship.\nRelationship promotion to entity üü© Sometimes a relationship is not enough to model some constraints, in these cases it is useful to use an entity instead.\nExample: Cardinality of relationship üü©\u0026ndash; This is different from the arity. It\u0026rsquo;s a constraint that defines the minimum and maximum value that a relationship can have. There is a convention to use $N$ if we don\u0026rsquo;t have an upper limit\nTypes of relationship cardinality (3) üü© The classical classification is\nMany-to-many One to many 1 to 1 It\u0026rsquo;s clear what they mean, it\u0026rsquo;s a cardinality relation, for example current_spouse relationship is a 1-1 in the modern society, schools frequented could be one to many, the exams taken by a student in the course entity is a many to many.\nAttributes Definition of attributes üü© Sono propriet√† o di entit√† o associazioni, che assumono valori da un certo dominio\nComposite attributes üü© They are used to group together different attributes to the same class or relationship. This is useful if different attributes share the same semantic meaning.\nIn the example in the image it\u0026rsquo;s the address. Cardinality of attributes üü© It is possible to define a cardinality for single attributes, because an employee could have more phone numbers, or the driving licence is optional (not everybody has it!)\n","permalink":"https://flecart.github.io/notes/design-del-database/","summary":"Processo design del database Il design Some design steps (3) (non impo) How to gather requirements? üü®+ Come si pu√≤ raccogliere i dati degli utilizzatori?\nparlare col il personale che dovr√† utilizzare questi sistemi Documentazione esistente Interview di persone che dovr√† utilizzare queste risorse O Moduli per fare sampling Top-down approach La cosa brutta √® che questi requisiti non possono essere standardizzati, ci sono molte necessit√†, molto diverse fra i loro, quindi √® utile andare a parlare con gli esperti e capire cosa abbiano bisogno per i dati.","title":"Design del database"},{"content":"Gruppi ciclici e permutazioni Il gruppo ciclico Definizione gruppo ciclico Abbiamo definito in Gruppi per la prima volta il significato di gruppo ciclico generato da un elemento del gruppo, questo insieme si √® poi dimostrato essere un sottogruppo del gruppo\nUn gruppo $G$ √® chiamato ciclico se esiste un $a \\in G$ tel per cui $$ G = \\left\\{ a^{n} \\mid n \\in \\mathbb{Z} \\right\\} $$ Dove a √® chiamato elemento generatore.\nScriviamo $G = \\langle a \\rangle$ per dire che $G$ √® generato dall\u0026rsquo;elemento $a$. L\u0026rsquo;ordine del gruppo √® la cardinalit√†: $$ ord(G) = \\lvert \\langle a \\rangle \\rvert $$ Criterio $a^{i} = a^{j}$ Probabilmente ha qualche relazione con [Teorema di Lagrange](/notes/teorema-di-lagrange). note sull\u0026rsquo;enunciato entrambe le frecce $\\impliedby$ sono abbastanza ovvie.\nRagionando sul primo caso, nel caso in cui √® infinito, se succedesse che $a^i = a^j \\land i \\neq j$ si avrebbe che l\u0026rsquo;ordine √® finito, perch√© si ripeterebbe ogni tot, quindi dimostri cos√¨. Nel secondo caso credo sia cos√¨, ma non saprei come formalizzare la cosa.\nDimostrazione Come si pu√≤ notare, mi sto riducendo a una classe di resto con l\u0026rsquo;algoritmo di euclide nel secondo caso.\nQuesto √® un teorema molto importante nei gruppi finiti, soprattutto, perch√© mi sta dicendo che ci possiamo sempre ridurre a una classe di resto per l\u0026rsquo;esponente.\nCorollario 1 $\\text{ Per ogni elemento di gruppo A, si ha che: } |A| = |\\langle A\\rangle|$\nCorollario 2\n$a\\in G, |a| = n \\in \\mathbb{N}, k \\in \\mathbb{Z}, a^k = e_g \\implies n \\mid k$\nOsservazione\nQuesto fatto che la moltiplicazione fra due elementi funziona come una addizione fra due elementi in $\\Z_n$ ci fa intuire come sia possibile un isomorfismo fra questi due gruppi.\nInfatti esiste, dimostreremo poi che per ogni gruppo ciclico finito di ordine n esiste un isomorfismo con Zn (credo)\nRelazione fra ordine $n, e$ un $k$ in $\\mathbb{Z}$ e $gcd(n,k)$ Dimostrazione Questo teorema ci √® molto utile per ridurre il generatore di un gruppo in un altro pi√π gestibile o pi√π semplice da manipolare\nCorollario 1\nIn un gruppo ciclico, l\u0026rsquo;ordine di un elemento divide l\u0026rsquo;ordine del gruppo.\nIn simboli\n$$ a\\in G, |a| =k, |G| = n,\\implies k \\mid n $$ (da notare l\u0026rsquo;ordine opposto dei divide rispetto al corollario 2 del teorema precedente)\nCorollario 2 criterio $\\lvert a_{i} \\rvert = \\lvert a_{j} \\rvert$\nQuesto √® molto simile al teorema precedente, ma ora stiamo parlando di ordine.\nEnunciato\nDimostrazione\ncorollario 3 Generatori di gruppi ciclici finiti\nQuesto √® un corollario del corollario üòÇ. In pratica afferma che\nIl gruppo generato da $\\langle a \\rangle$ √® uguale a $\\langle a^j \\rangle$ sse $gcd(n, j) = 1$ con n l\u0026rsquo;ordine di a. cosa simile con $|a| = |a^j| \\iff gcd(n,j) = 1$\nE avendo questo possiamo definire con concretezza di generatori del gruppo finito Zk\nCorollario 4 Generatori di Zn\nsia $k \\in \\mathbb{Z}_n$, k √® un generatore sse $gcd(n,k) = 1$.\nla dimostrazione segue dal fatto che 1 √® un generatore di Zn, e vogliamo che il gruppo generato da 1 e k sia lo stesso.\nClassificazione di sottogruppi di gruppi ciclici Teorema fondamentale dei gruppi ciclici Dimostrazione Corollario Sottogruppi di Zn\nDal teorema fondamentale dei sottogruppi di gruppi ciclici abbiamo una caratterizzazione precisa dei sottogruppi presenti in Zn, sono in particolare tutti i divisori di n.\nNumero di elementi di un un certo ordine in un gruppo ciclico Dimostrazione\nQuesto √® anche una dimostrazione per Teorema di Lagrange#Teorema di Eulero.\nCorollario 1 Numero di elementi di ordine d\nEnunciato\nDimostrazione\nGruppi di permutazione Decomposizione in cicli Esiste una sintassi per scrivere le permutazioni con una notazione a cicli. Vogliamo dimostrare ora che questa sintassi √® sempre possibile (quindi corrisponde a una equivalenza)\nDimostrazione\nLa dimostrazione procede per via costruttiva, proponendo una specie di algoritmo per trovare tutti i cicli fino ad esaurimento di elementi nell‚Äôinsieme.\nCommutativit√† di cicli disgiunti Dimostrazione\nUna volta letta la dimostrazione sembra una cosa ovvia, ma probabilmente l‚Äôidea √® sulla scelta degli elementi iniziali?\nOrdine di una permutazione (scomposizione con ordine di sottocicli) Dimostrazione\nDecomposizione in permutazioni bicicle Dimostrazione\nProposizione\nQuesto lemma si pu√≤ estendere a un caso pi√π generale, dove si possono iniziare a distinguere permutazioni pari e dispari. Vedremo che avranno certe propriet√† (legate alle matrici poi anche).\nDimostrazione\nParit√† e disparit√† di 2-cicli Dimostrazione\nL‚Äôinsieme di permutazioni pari √® un sottogruppo di Sn Dimostrazione\nSiano a, b due elementi di questo insieme, vogliamo dimostrare che $ab^{-1} \\in S$ notiamo che per il teorema 5.5 $b^{-1}$ deve essere pari, perch√© altrimenti avrei che $e = bb^{-1}$ sarebbe scrivibile come un prodotto di permutazioni 2-cicle dispari. Inoltre, chiaramente un prodotto di 2 permutazioni pari √® ancora pari (basta concatenare queste, che poi al massimo si eliminano a due a due). Ecco il sottogruppo.\nIl gruppo alternante di n ha ordine n! L‚Äôenunciato √® proprio questo titolo, quindi non lo riporto (sul libro √® il numero 5.7).\nInvece riporto la definizione di gruppo alternante:\nDimostrazione\nResidui Quadratici Si dice che $x \\in G$ √® un residuo quadratico nel suo gruppo se ha una radice quadrata in quel gruppo, ossia un $a \\in G$ tale per cui $a^{2} = x$. Questo √® di particolare interesse per robe di crittografia come per Asymmetric Cryptography.\nSimbolo di Legendre √à il valore $$ x^{(p - 1)/2} $$ √à strettamente legata ai residui quadratici\nSe $x \\in Z_{p}$ √® un residuo quadratico allora $x^{(p-1)/2} \\equiv 1 \\mod p$. Computing modulo e-roots is as difficult as factorization.\n","permalink":"https://flecart.github.io/notes/gruppi-ciclici-e-permutazioni/","summary":"Gruppi ciclici e permutazioni Il gruppo ciclico Definizione gruppo ciclico Abbiamo definito in Gruppi per la prima volta il significato di gruppo ciclico generato da un elemento del gruppo, questo insieme si √® poi dimostrato essere un sottogruppo del gruppo\nUn gruppo $G$ √® chiamato ciclico se esiste un $a \\in G$ tel per cui $$ G = \\left\\{ a^{n} \\mid n \\in \\mathbb{Z} \\right\\} $$ Dove a √® chiamato elemento generatore.","title":"Gruppi ciclici e permutazioni"},{"content":"Planning Automatico Vogliamo andare a creare un programma che sia in grado di creare un piano per fare una azione, andiamo in questo capitolo gli algoritmi storicamente migliori adatti a risolvere questo problema\nIl problema di pianificazione Andiamo a rappresentare il nostro problema di pianificazione con un linguaggio molto simile alla Logica del Primo ordine.\n√à il PDDL ossia il Planning domain definition language\nPDDL Questo linguaggio √® definito da\nUna serie di predicati in FOL iniziali Una serie di predicati in FOL di arrivo Una serie di azioni Con una serie di precondizioni E una serie di effetti Il nostro obiettivo sar√† principalmente raggiungere un obiettivo finale, utilizzando le azioni per cambiare lo stato attuale\nEsempio\nIn cui si pu√≤ notare che una soluzione di questo problema √® molto semplice:\nAlgoritmi generali Gli algoritmi principali per risolvere la PDDL sono di due tipologie\nForward search Backward search Entrambe dovrebbero avere delle euristiche molto forti per funzionare in un ambiente reale. (nota: essendo questa poi una rappresentazione fattorizzata del mondo, si possono creare delle euristiche indipendenti dal dominio molto forti!).\nSulla soddisfacibilit√† booleana\nSi pu√≤ anche trasformare il problema di pianificazione in un problema di logica proposizionale da dare in pasto ad un sat solver. Con lo stato attuale dei sat solver questo potrebbe anche essere considerato una soluzione possibile interessante.\nAltri metodi da almeno tenere in mente i nomi\nPlanning graph\nSituation calculus **praticamente sat-plan ma con la FOL\nPartial ordering planning, molto figo perch√© ci fanno i rover per andare su marte questo üòÄ, √® usato perch√© puoi vedere in modo molto chiaro il motivo per cui ha scelto questo piano.\nBackward search Vogliamo partire dall‚Äôobiettivo, dal nostro goal, ed andare indietro fino a trovare uno stato che sia adatto allo stato iniziale.\nPer fare questo vogliamo cercare azioni che siano rilevanti, ossia le cui precondizioni non siano assurde con quello che avremmo gi√†. Questo aiuta moltro a diminuire il fattore di branching.\nPer maggiori dettagli su come si faccia l‚Äôupdate dello stato andare a vedere sul libro.\nForward search Praticamente andiamo a guardare tutte le soluzioni, √® la stessa cosa di un Problemi di ricerca ed √® quindi facilmente attaccabile (se non per la grandezza dello spazio di ricerca) dagli algoritmi l√¨ studiati. Il pi√π importante dei quali resta sempre A* con una buona euristica.\n","permalink":"https://flecart.github.io/notes/planning-automatico/","summary":"Planning Automatico Vogliamo andare a creare un programma che sia in grado di creare un piano per fare una azione, andiamo in questo capitolo gli algoritmi storicamente migliori adatti a risolvere questo problema\nIl problema di pianificazione Andiamo a rappresentare il nostro problema di pianificazione con un linguaggio molto simile alla Logica del Primo ordine.\n√à il PDDL ossia il Planning domain definition language\nPDDL Questo linguaggio √® definito da","title":"Planning automatico"},{"content":"Sentiment analysis is one of the oldest tasks in natural language processing. In this note we will introduce some examples and terminology, some key problems in the field and a simple model that we can understand by just knowing Backpropagation Log Linear Models and the Softmax Function.\nWe say:\nPolarity: the orientation of the sentiment. Subjectivity: if it expresses personal feelings. See demo\nSome applications: Businesses use sentiment analysis to understand if users are happy or not with their product. It\u0026rsquo;s linked to revenue: if the reviews are good, usually you make more money. But companies can\u0026rsquo;t read every review, so they want automatic methods.\nOther applications are opinion mining: if you like a politician or not. Spam detection. Recommender systems.\nA simple solution: MLP Traditionally you define a set of features and then try to log linear model to get a result. This is a complicated pipeline to get this result. A surprising result from Iyyer (2015) says we just need a bag of words model and an MLP to get good result. Over 90% accuracy they say!. With this solution you just:\nPool the embeddings of the input sequence tokens. Pass this to MLP layers Softmax at the end. Currently, we can have the same thing asking ChatGPT and it also works quite well. (Prof. Cotterell says it could have been trained on this kind of tasks). With 2-3 layers it works the best! And it seems the network is very sentitive to the sentiment of the kind of word that is used e.g. (okay, good, terrible etc\u0026hellip;).\n","permalink":"https://flecart.github.io/notes/sentiment-analysis/","summary":"Sentiment analysis is one of the oldest tasks in natural language processing. In this note we will introduce some examples and terminology, some key problems in the field and a simple model that we can understand by just knowing Backpropagation Log Linear Models and the Softmax Function.\nWe say:\nPolarity: the orientation of the sentiment. Subjectivity: if it expresses personal feelings. See demo\nSome applications: Businesses use sentiment analysis to understand if users are happy or not with their product.","title":"Sentiment Analysis"},{"content":"Introduction Da ricordare il \u0026ldquo;The State Machine Replication (SMR) Problem\u0026rdquo; in Consensus protocols che √® importantissimo per comprendere questa parte.\nStoria locale Transazioni al singolo noto Problema del sync fra tutti questi nodi.\nGoal of SMR solution in blockchains Andiamo a considerare alcune propriet√† di safety e liveness Programmi Concorrenti\nConsistenza i nodi devono essere daccordo su quale transazione mettere prima e dopo ‚Üí stessa storia per tutte le transazioni. (con la possibilit√† di alcuni nodi che siano indietro, ma solo prefisso!). Liveness che vogliamo dire che tutte le transazioni valide devono essere aggiunte alla fine Assunzioni per sincrono (4) Permissioned, ossia i nodi del nostro modello sono fissi, non possiamo averne di pi√π, non possiamo averne di meno e sono conosciuti. Public key infrastructure, Ogni nodo ha una coppia pubblica e privata. Synchronous, esiste una sorta di stato globale, e tutti i nodi condividono questa informazione. 0, 1, ‚Ä¶ t. I messaggi sono tutti mandati bene, e arrivano esattamente uno step dopo. (mandato al tempo t, arriva a t + 1). Onest√† di tutti i nodi (sar√† lasciato subito questa assunzione). 4‚Äô. Una percentuale dei nodi √® bizantina.\nAltre di base trattate prima\nesistenza di internet Esistenza di crittografia Si pu√≤ notare che le ultime due assunzioni sono le stesse pi√π generali definite in Consensus protocols, andremo negli appunti in seguito solamente a rilassare alcune assunzioni di 1 e 2.\nLa 1 √® stata storicamente molto sensata, dato che era pensata per database che comunicassero fra di loro, e chiaramente quello era un settings pi√π controllato, per blockchain vorremmo anche provare rilassare questo.\nBizantine broadcast problem Questo √® un problema molto simile a SMR, tanto che si potr√† dimostra che che risolvere SMR si pu√≤ ridurre a dimostrare BB. Andremo quindi a descrivere questo problema\nFaulty/Bizantine Nodes Alcuni nodi falliscono, anche se non intenzionalmente, per esempio con errori di hardware.\nUn nodo che non √® onesto (comporta come si dovrebbe comportare) √® faulty.\nFault types Crash fault (errore del software oppure dell‚Äôhardware). Omission fault (in cui la trasmissione di informazione importante √® fallita, pu√≤ essere intenzionale o meno) Omissione di send-receive O altro genere di omissione simile. Bizantine fault (un certo insieme di nodi fa come gli pare) √à molto importante comprendere questo concetto, dato che sar√† di base nell\u0026rsquo;analisi della costruzione di protocolli che funzionino per BB.\nIn modo intuitivo possiamo intendere un nodo come bizantino sse non si comporta come dovrebbe. E l√¨ vengono descritte anche 3 cause per il suo non-comportamento corretto.\nDescrizione del problema Un nodo leader e n - 1 nodi non leader. Il leader ha una informazione privata $v ^*$ che deve mandare a tutti. Una soluzione del problema deve soddisfare queste tre caratteristiche\nValidit√† ossia se il nodo sender (leader) √® onesto, gli altri devono essere d\u0026rsquo;accordo che il messaggio √® $v^*$ Terminazione non di deve essere deadlock, i nodi devono terminare con qualche risultato. Agreement quando termina, tutti i nodi onesti devono essere d‚Äôaccordo sullo stesso risultato. SMR si riduce a BB Prenderemo in questa soluzione l‚Äôidea presente in #Round-Robin leaders, ad avere ad ogni momento un leader.\nAllora dato questo leader, utilizziamo BB con leader = sender, e gli altri nodi per mandare il messaggio privato.\nAllora questo algoritmo possiede sia liveness che consistency. Liveness per stesso motivo di prima, prima o poi un nodo diventa un leader, quindi riesce ad aggiungere la sua informazione privata.\nConsistency perch√© perla soluzione di BB, ogni nodo onesto alla fine sar√† d‚Äôaccordo su quanto deve aggiungere alla sua lista privata. In particolare se il leader √® onesto sar√† esattamente quanto mandato dal sender.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Syncronous model/Untitled.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Syncronous model/Untitled\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Syncronous model/Untitled 1.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Syncronous model/Untitled 1\u0026quot;\u0026gt; Alcune soluzioni Lazy SMR Se ogni nodo non comunicasse, ma aggiungesse alla propria lista privata la transazione, questo non funziona. Non c‚Äô√® proprio la consistenza. Non ci si pu√≤ aspettare che il nodo esterno, la transazione riesca a richiedere allo stesso tempo a tutti i nodi.\nDa qui concludiamo che i nodi devono comunicare fra di loro (che √® una cosa molto banale).\nRound-Robin leaders Quest√† √® una idea che ogni nodo diventa leader e si mette a coordinare i nodi a turni, in un certo senso √® molto simile all‚Äôidea presente in Architettura e livelli 1, 2 riguardo le reti ad anello e il passaggio del testimone.\nFunzionamento I nodi diventano leader a seconda del tempo globale. Il nodo leader manda a tutti gli altri la sua lista, gli altri aggiungeranno al proprio alla fine, all‚Äôinizio metto le propria (quindi).\nCorrettezza Sia consistenza sia liveness vengono soddisfatti. La liveness √® soddisfatta perch√© prima o poi il nodo n sar√† il leader, allora avr√† l‚Äôoccasione di aggiungere alla catena i suoi dati privati.\nLa consistenza viene soddisfatta perch√© sotto le assunzioni che abbiamo i messaggi vengono mandati e ricevuti esattamente in uno step di tempo, quindi ogni nodo riesce ad aggiungere alla sua lista privata quello che gli √® di interesse.\nNecessit√† dell\u0026rsquo;onest√† Se un nodo non onesto diventa leader, potrebbe mandare un p√≤ della sua lista ad lacuni nodi e niente ad altro (omission fault) e quindi questo rompe tutta la consistenza! Quindi questo metodo funziona solamente nel caso in cui nessun nodo fallisca. Vorremmo per√≤ resiste anche al fallimento!\nDolev-Strong protocol L‚Äôidea generale di questo protocollo √® capire se il sender √® onesto o meno. Se si riesce a capire questa cosa, allora se √® onesto prendo il suo valore, altrimenti metto bottom sulla mia pila\nConvincing messages \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Syncronous model/Untitled 2.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Syncronous model/Untitled 2\u0026quot;\u0026gt; The protocol Quel mandare cose √® pi√π o meno cercare di capire se il nodo sender ha mandato messaggi contraddittori.\nProof of correctness PKI (Hexagon proof) https://groups.csail.mit.edu/tds/papers/Lynch/jacm88.pdf Pease, Shostak, and Lamport [PSL80], and later the proof was simplified by Fischer, Lynch, and Merritt [FLM85].\nQuesta √® una dimostrazione molto importante per quanto riguarda questo modello. Mostra che ci sono delle limitazioni pesanti riguardanti il modello. Come si vedr√† in seguito anche in Asynchronous model, ci saranno delle limitazioni in praticamente qualunque modello.\nEnunciato Siano n nodi all‚Äôinterno di un modello a comunicazione sincrona in cui non √® presente un setting PKI (chiave privata e pubblica), se i nodi bizantini sono $f \\geq n / 3$, allora non √® possibile avere contemporaneamente terminazione, safety e liveness.\nDimostrazione Dimostreremo solamente il caso in cui n = 3, poi si dovrebbe estendere senza molto sforzo al caso maggiore generico.\nQuesta dimostrazione va a contraddizione. Supponiamo di avere un setting a 6 nodi come in figura\nI nodi F sono i sender, mentre M e L sono le altre cose.\nOra da notare √® che il protocollo pu√≤ eseguire su questo sistema, cio√® anche se era inteso per essere eseguito nel caso $n = 3$, le uniche cose di cui ha bisogno il protocollo √®\nSapere se √® un sender o meno Il messaggio da inviare se √® il sender I suoi n - 2 vicini (quindi sapere a chi mandare). Quindi sotto queste assunzioni il protocollo pu√≤ eseguire\nAllora andiamo a considerare 3 scenari possibili:\nScenario 1 F bizantino\nSupponiamo di essere in un sistema a 3, con L, M, F, ma F √® il nodo bizantino. F dato che √® bizantino pu√≤ fare cose arbitrarie, in particolare facciamo finta che simuli i nodi F‚Äô, M‚Äô, L‚Äô, F collegati come di sopra.\nAllora dato che il nosto protocollo deve soddisfare consistenza, ossia tutti i nodi onesti devono finere per essere d‚Äôaccordo su qualcosa, deve essere che nel sistema l‚Äôoutput di L = M\nScenario 2 L bizantino\nSistema a 3 dato da L, M, e F‚Äô, ma in questo caso ora il nodo M simula i nodi M, L, F, M‚Äô. Per validit√† del protocollo deve essere che L √® d\u0026rsquo;accordo con l‚Äôoutput 1, del sender F‚Äô.\nScenario 3 M bizantino\nSimile al sistema tre nel primo caso, ora L simula L, F‚Äô, M‚Äô, L‚Äô. Quindi per validit√† M d√† in output F.\nma allora abbiamo un assurdo perch√© L dovrebbe essere uguale a M, invece l\u0026rsquo;output √® diverso. Quindi questo scenario non pu√≤ succedere.\n","permalink":"https://flecart.github.io/notes/syncronous-model/","summary":"Introduction Da ricordare il \u0026ldquo;The State Machine Replication (SMR) Problem\u0026rdquo; in Consensus protocols che √® importantissimo per comprendere questa parte.\nStoria locale Transazioni al singolo noto Problema del sync fra tutti questi nodi.\nGoal of SMR solution in blockchains Andiamo a considerare alcune propriet√† di safety e liveness Programmi Concorrenti\nConsistenza i nodi devono essere daccordo su quale transazione mettere prima e dopo ‚Üí stessa storia per tutte le transazioni. (con la possibilit√† di alcuni nodi che siano indietro, ma solo prefisso!","title":"Syncronous model"},{"content":"Ripasso: May 14, 2023 Ultima modifica: May 6, 2023 6:25 PM Primo Abbozzo: March 30, 2023 4:20 PM Studi Personali: No\nCookies Gli utilizzi pi√π soliti sono per Autenticazione e per Autorizzazione, perch√© sono delle informazioni che il server genera e mette al client, come se fossero dei segreti cifrati.\nCookie Questi sono una estensione di netscape, che si appoggiano al protocollo HTTP per implementare certe funzionalit√† (soprattutto il fatto di essere stateless, quindi √® utile per avere informazioni sugli stati su qualcosa.)\nSlide cookie\nVengon utilizzati header specifici per settare il cookie.\nArchitettura dei cookie I cookie sono briciole di informazioni sul client generati dall\u0026rsquo;applicazione server, di seguito nelle slides vedi in che modo funzionano solitamente:\nSlide cookie\nTipologie di coockie Permanenti sono utili soprattutto per mantenere informazioni di **preferenza sugli utenti. Di sessione qui ti diverti a fare cose sulla sicurezza üòÄ. Di terze parti sono utilizzati per decidere che pubblicit√† mostrarti, per esempio basandosi sulla history di ricerche. Autenticazione Non ci piacerebbe autenticarci ogni volta a ogni cambio di tab ossia identificare chi stia facendo l\u0026rsquo;acceso alla risorsa come se fosse un riconoscimento, i cookie sono buoni per storare queste informazioni.\nSchemi di autenticazione (3) Se provi ad accedere a una risorsa, il server dovrebbe risponderti con 401 Not authenticated e darti un header WWW-authenticate dandoti informazioni su come autenticarti.\nBASIC\nSlide basic auth\nQuesto manda in pratica tutto in chiaro attraverso l\u0026rsquo;header del client, ovviamente non √® che sia molto sicuro‚Ä¶\nQuindi √® in disuso.\nDIGEST\nSlide digest auth\nIn pratica √® come il basic, ma invece di mandare la cosa in chiaro si manda hash + nonce, in modo da evitare replay attack come specificato in Sicurezza delle reti.\nAnche qui √® difficile capire quando la sessione scade.\nBEARER\nIn pratica il server produce qualcosa, un token e poi il client utilizza solo questo per autenticarsi nelle connessioni successive.\nPu√≤ essere utilizzato sia in session sia in token auth\nSession-based authentication Slides session based authentication\nIn pratica al primo collegamento ti metto dei cookie, che sono i cookie di sessioen, che scadono in un certo tempo. Poi per ogni collegamento ti mando anche i cookie di sessione, che danno informazioni di autenticazione.\nQuesto √® uno schema classico, il server ha il controllo sul tempo e sulla revoca di questa sessione.\nToken-based authentication Slides token based auth\nPraticamente quando la prima volta fai auth io ti rispondo con un token firmato come potrebbe essere Il token JWT.\nQuesto poi viene utilizzato. la cosa bella √® che utilizzo il server molto meno, nel senso che deve andare a memorizzare molto meno, basta verificare la firma ogni volta.\nIl token JWT Questo l\u0026rsquo;abbiamo utilizzato molto spesso per la parte di cybersec!\nSlide JWT\nContenuto Header Payload e signature\nAltre note: CORS e Caching Introduzione Cross site vulnerability Slide headers CORS\nNon vorremmo avere le javascript esterno non controllato, potrebbero avere codice maligno! Pensa se ti riuscissero a pishare il cookie di sessione.\nPosso mettere nelle options di HTTP scripts permessi\nCORS headers Slide headers per cors\nHTTP Caching (2) Server specified expiration\nSlide server specified expiration\nIn pratica attraverso certe specificazioni dico quando il cache sar√† expired.\nHeuristic expiration\nHeuristic expiration\nQuesto perch√© spesso\nRisposta dalla cache\nSe √® non modificata ti mando un codice 304 Not modified altrimenti ti risponso, cos√¨ non devo fare due richeiste, una head per veder elast modified e una altra per mandarti la get.\n","permalink":"https://flecart.github.io/notes/cookie-e-autenticazione/","summary":"Ripasso: May 14, 2023 Ultima modifica: May 6, 2023 6:25 PM Primo Abbozzo: March 30, 2023 4:20 PM Studi Personali: No\nCookies Gli utilizzi pi√π soliti sono per Autenticazione e per Autorizzazione, perch√© sono delle informazioni che il server genera e mette al client, come se fossero dei segreti cifrati.\nCookie Questi sono una estensione di netscape, che si appoggiano al protocollo HTTP per implementare certe funzionalit√† (soprattutto il fatto di essere stateless, quindi √® utile per avere informazioni sugli stati su qualcosa.","title":"Cookie e autenticazione"},{"content":"Introduzione Data or Control plane come fanno i router a fare forwarding dei pacchetti? e decidere come mandare? Come fanno a passare. Sono le tabelle di instradamento. Si pu√≤ dire di end-to-end perch√© solamente il sender e receiver andranno a livello applicazione, e leggeranno le cose (se criptato veramente solo loro riescono a fare questo).\nFunzioni principali Forwarding che in pratica √® passare il pacchetto al successivo, √® parte del data plane.\nQuesta √® una cosa molto semplice, in pratica bisogna capire da una porta di ingresso quale sar√† la porta d‚Äôuscita del router. Guardando l\u0026rsquo;intestazione del pacchetto. Se non fa match nessuna riga della tabella allora manda nel router di default che avr√† un reach maggiore, pi√π probabile che sappia dove mandare.\nRouting invece va a scrivere mappe nel grafico della rete, cio√® capisce quale sia il percorso pi√π breve all\u0026rsquo;interno della rete, √® parte del control plane.\nTutta la rete in modo coordinato prova a creare questo piano (me se stesse segnalando se una segnaletica funziona ancora, se la strada va ancora dove dovrebbe andare (e.g. se √® crollato un ponte dovresti sapere se quella strada non funziona pi√π)).\nSolitamente questo √® fatto con un software chiamato SDN (ma anche un umano potrebbe farle, anche se sarebbe troppo lento).\nRouting control planes La differenza fra i due √® sostanzialmente architetturale, se ne parla in Architetture a livello applicazione üü©.\nPER ROUTER CONTROL PLANE possiamo dire che sia un modo semplice del control plane per stabilire la tabella di instradamento, in pratica listo tutti i collegamenti che ho nella tabella con i loro IP di interesse, quindi se un prefisso matcha quello allora mando l√¨. √à strano che i router siano anche in grado di fare prefisso pi√π lungo per matchare. In questo modo utilizzando un algoirtmo locale, distribuito, posso avere una tabella di istradamento. gli algoritmi locali possono fare scelte non coordinate, dato che pu√≤ cambiare nel tempo la situazione, l\u0026rsquo;informazione locale potrebbe non essere del tutto corretta.\nLOGICALLY CENTRALIZED CONTROL PLANE quando c\u0026rsquo;√® una struttura centrale che contiene tutte le informazioni dei singoli router (o almeno quanto trasmesso), e da l√¨ aggiorna le tabelle di instradamento dei singoli router. (Control Agent √® il singolo router, che trasmette a un controllo remoto). La cosa importante √® che il cos Remote Contorller √® conoscente di tutti i dati principali della rete. Questo rende pi√π efficiente, perch√© ha tutte le informazioni per fare le decisioni migliori.\nPer√≤ ha bisogno di comunicare fra CA e RC, e se non funziona la comunicazione non avrei comunque le informazioni perfette.\nInoltre deve essere un processo bono, e si dovrebbe capire chi avrebbe la responsabilti√† di pagare il remote controller, i provider? gli utenti finali?\nImmagine semplificazione Data e Control Plane\nService Model I modelli di servizio definiscono le caratteristiche che dovrebbe avere il servizio di trasporto end-to-end dei pacchetti. Alcune caratteristiche potrebbero esser come consegna garantita, o garantita consegna entro certo tempo, oppure il flow dei datagrammi in ordine, minima bandwidth, servizi di sicurezza sul trasporto. Ma queste caratteristiche alla fine non sono comunque mai garantite. Quindi possiamo indire un sistema best-effort, ma non √® che sia comunque garantito qualcosa, potrei dire che una rete che non √® in grado di trasportare niente sta facendo il massimo di quanto riesce a fare. Non ci aiuta molto.\nATM (asynchronous transfer model) √® un servizio che prova a fare questo, cercare di misurare il modello di servizio del trasporto che in una specifico spazio temporale posso darti tutte le risorse, e allora avresti le garanzie dette sopra. E se non riesco a riempire tutto il canale in quel tempo, do lo spazio in pi√π ad altri che non hanno bisogno di quella garanzia.\nC‚Äô√® un Overhead per la quantit√† di dati e la lunghezza di header (se header molto lungo, alla fine trasmetto meno percentuale di dati), per√≤ se faccio troppo lungo ci metto di pi√π a mandare, quindi altri pacchetti potrebbero metterci molto di pi√π ad arrivare, e perdere la garanzia sul tempo minimo di arrivare. era 32 o 64, quindi si √® fatta una scelta politica che √® 48 byte, e fa schifo perch√© non √® una potenza di 2 e devi fare check leggermente pi√π complicate.\nA noi di solito non serve questa garanzia, noi utenti dico, ma al backbone di internet √® importante e si sono messi cos√¨. Ci sono molti tipologie di ATM come\nconstant bit rate ( voice over Ip, abbiamo biosgno di flusso costante per la voce, vogliamo real time, oppure coso di un reattore nucleare, senza nessuna congestione e con forti garanzie su loss, ordering e timing).\nVariable bit rate, come il video, perch√© ha bisongo di un sacchissimo di informazioni, un byte per un pixel bianco e nero, non si pu√≤ trasmettere tanta roba..\nAltro che non listo\nSlide garanzie Service Models\nThe Router Router architecture ci sono credo molti modi per implementare la funzione di router, in generale in un singolo ciclo di clock ti riescono a far entrare e far uscire il pacchetto, questo sarebbe il router buono\nQuindi possiamo individuare\nPorte di input Un processore di routing che ti indirizza nell uscita giusta Un sistema di switching fabric per poter mandare l\u0026rsquo;informazione nella porta giusta Porte di uscita Slide sistema di routing\nla parte del processore √® molto pi√π utilizzato nella parte di Control Plane\nForwarding Il forwarding tratta delle politiche che il processore di routing dovrebbe utilizzare per capire in quale porta di output ti potrebbe mandare\nDestination based forwarding in cui si va a guardare l\u0026rsquo;indirizzo di arrivo e si decide in questo modo come mandarti.\nVediamo un esempio di questa tipologia di forwarding.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Data Plane/Untitled 3.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Data Plane/Untitled 3\u0026quot;\u0026gt; Da notare che sono degli intervalli in questo caso di esempio, ed √® esattamente come avevamo diviso le subnets in un esercizio passato, in Livello di Rete.\nQuesto √® il pi√π usato, √® il longest prefix match. Questo √® bello perch√© si possono indirizzare nelle (TCAMs Ternary content addressable memories, CISCO ha inventato sta tecnologia ed √® la pi√π forte sul mercato attualmente) che praticamente ti trova in singolo ciclo di clock quello corretto.\nL‚Äôalgoritmo normale per trovare l\u0026rsquo;indirizzo corretto, sarebbe comunque fatto in $O(n)$, ma se l‚Äôhardware riesce a fare in parallelo con tutte le tabelle in un singolo ciclo di clock allora ho un $O(1)$, quindi ez.\nGeneralized forwarding Software defined networking\nGeneralizzato perch√© √® indipendente dal router che facciamo perch√© √® tutto gestito da un controller centralizzato.\nOgni router ha una flow table, la stessa cosa di cui si parla nei IPv6 in Livello di Rete#Datagramma IPv6 . Questa tabella √® costruita col routing plane centralizzato, descritta dal software. Importante che tutta la rete sia SDN, senn√≤ non funziona questo.\nOpen Flow Slide flow table\nAbbiamo certe regole di gestione del pacchetto che si basa tu match-action. Se c‚Äô√® un match sugli header del pacchetto, allora faccio una azione su quel pacchetto. (come drop, forward, modify) e ci permette di fare molta roba, come le IP tables, o il NAT. Il router ora pu√≤ assumere molt funzioni diverse.\nAbbiamo anche una priority, mentre nella destination based √® solamente longest prefix.\nSwitching fabrics Questi switching fabrics lo fanno andare molto molto infretta La prima √® una memoria, ma √® molto lento perch√© ha bisogno di due copie di memoria. Ognuno pu√≤ avere un bus condiviso, si sceglie a livello del sender il bus di arrivo, ma posso far passare solamente un bus alla volta, quindi posso avere un singolo alla volta che passa. La cosa migliore √® la TRANSFER SWITCH. Cos√¨ posso far passare in parallelo dei pacchetti, per√≤ √® la cosa pi√π complessa, per√≤ √® anche la cosa pi√π efficiente, perch√© non devo n√© copiare, n√© avere collisioni sul bus Ritardi possibili Input Queuing Quando due pacchetti di entrata devono andare sulla stessa uscita. Head of the line blocking, quando ci sono pi√π pacchetti che stanno aspettando, quello avanti √® bloccato, ma quello dietro potrebbe andare. Slide input queuing\nOutput queuing Ho due cose buffering ossia quanto velocemente la switching fabric copia sui bus di uscita e scheduling che determina l\u0026rsquo;ordine di invio credo.\nPer decidere la quantit√† di buffering voluta per avere un certo bandwitdth √® in slide (una formula precisa): buffering delle uscite meno radice quadrata di quelle di ientrate.\n\u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Data Plane/Untitled 9.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Data Plane/Untitled 9\u0026quot;\u0026gt; Se il buffer di uscita diventa pieno, allora comincio a perdere i pacchetti! Posso perderlo secondo certe politiche:\nL\u0026rsquo;ultimo che arriva Cade uno a caso Cado quello con meno priorit√† (per fare questo devi fare hardware diverso perch√© non basta un semplice hardware). Scheduling dei routers Ci sono certi algoritmi di scheduling banali, come il First Come First served, e poi droppo tutti quelli che stanno fuori, oppure farli droppare a caso.\nPriority scheduling \u0026lt;img src=\u0026quot;/images/notes/image/universita/ex-notion/Data Plane/Untitled 10.png\u0026quot; alt=\u0026quot;image/universita/ex-notion/Data Plane/Untitled 10\u0026quot;\u0026gt; in pratica ho un classificatore, che dice se √® di priorit√† o meno.\nPoi per mandare guardo se c\u0026rsquo;√® qualcosa di priorit√† maggiore, se √® vuoto provo a mandare quelli minori.\nMa questo pu√≤ generare starvation.\nRound robin scheduling Questo non fa starvation.\nIn pratica provo uno per classe ad ogni ciclo.\nWeighted fair queuing Tipo se ho massima priority, ne mando 4, se sono nella seconda ne mano 2, se sono nella terza ne mando 1, quindi esiste ancora la priority e non ho starvation perch√© anche nella coda brutta riesco sempre ad andare avanti.\nSul pacchetto IP Livello di Rete#Indirizzo IP\n","permalink":"https://flecart.github.io/notes/data-plane/","summary":"Introduzione Data or Control plane come fanno i router a fare forwarding dei pacchetti? e decidere come mandare? Come fanno a passare. Sono le tabelle di instradamento. Si pu√≤ dire di end-to-end perch√© solamente il sender e receiver andranno a livello applicazione, e leggeranno le cose (se criptato veramente solo loro riescono a fare questo).\nFunzioni principali Forwarding che in pratica √® passare il pacchetto al successivo, √® parte del data plane.","title":"Data Plane"},{"content":"Introduzione Spettro del wireless networks (skip) Slide spettro Wirelesss networks\nQuesto solamente la classica differenziazione fra radio, visibile, raggi x raggi gamma etcetera.\nSe andiamo a guardare le onde radio, quelle che ci interessano, se ho frequenza alta ho densit√† di frequenza alta, se ho frequenza bassa ho alta capacit√† di suparamento di ostacoli.\nISM √® una banda da 2 a 5.0 GHz e c\u0026rsquo;√® tutto il WiFi, bluetooth. (anche wifi a 5 ghz.\nGSM prima rete cellulare a 900, poi 1800 nella seconda versione.\nDivisione statica delle frequenze\nAvre una frequenza comprata √® una miniera d\u0026rsquo;oro, attualmente il prof sta facendo della ricerca su come andare a\nTrasmissione via wireless : bandwidth (!) üü© Slide bandwidth\nSolitamente √® una ampiezza di frequenza ossia quando √® grande un insieme di frequenza (questa √® anche la definizione formale da utilizzare). Per√≤ √® erroneamente utilizzata anche per descrivere il numero di bits trasmessi (che √® il bitrate nominale), √® un errore voluto perch√© solitamente se hai una bandwidth maggiore riesci a trasmettere pi√π dati.\nNotare che la velocit√† del segnale √® sempre la stessa che √® quella della radiofrquenza (quella della luce), √® solamente l\u0026rsquo;alternarsi di quelle scatolette di colore diverso (codifica diversa).\nSe il segnale √® pi√π lungo allora √® pi√π facile andare ad interpretare se √® uno 0 oppure √® uno 1, diciamo che c\u0026rsquo;√® il tradeoff sulla reliability del segnale credo, anche se √® principalmente limitato dalla capacit√† del ricevente\ndef: connettivit√† di link üü© Slides connettivit√†\nIl primo √® una partizione, poi unidirezionali e bidirezionali.\nNota: solamente sui link direzionali possiamo andare a definire un link simmetrico o asimmetrico.\nLe parole principali sono:\nUnidirezionale Bidirezionale Partizione. Tipologie di wireless Slide introduzione alle tecnologie wireless\nNarrowband system √à un frequenza molto piccola in cui si pu√≤ comunicare (statica diciamo).\nProblemi di privacy perch√© mi posso connettere alla frequenza e ascoltare quanto viene mandato. Problemi di interferenza se voglio comunicare su questa frequenza con canali diversi Infatti per questa tipologia √® molto semplice fare un attacco di Jamming, ossia mando informazioni alla stessa frequenza, impedendo la comunicazione sul canale.\nFrequency Hopping Possiamo utilizzare pseudogeneratori per andare a saltare in modo pseudorandom in spettri di frequenza diversi.\nAbbiamo bisogno di una sincronizzazione di questi salti, quindi un clock comune sarebbe molto comodo. (per√≤ dell‚Äôhardware per filtri per quelle frequenze ci dovrebbe essere).\nQuesto era soprattuttto un modo per trasmettere nel tentativo di non essere ascoltati. In questo senso di hop, √® protetto by design.\nCuriosit√†: inventata da una attrice di hollywood, Hedy Lamarr (perch√© il suo canto andava fuori sinc lol) donato poi senza brevetto per salvare i soldati americani.\nDirect sequence spread spectrumüü® Ne parliamo un po\u0026rsquo; meglio in Modulazione wireless\nOssia mando il segnale encodato su tutto lo spettro con un chipping code. E qui si pu√≤ riutilizzare la metafora del vagone e del treno, nel senso che se √® lungo allora riconosco meglio il valore del bit encodato con quella forma.\nIn un certo senso √® anche sicura rispetto al narrowband, perch√© devi conoscere il pattern del chip code per poterlo decodificare correttamente. (vari interlocutori avrebbero un codice non correlata fra di loro, cio√® la comunciazione sovrapposta sembra una interferenza casuale) Questo ci permette di riestrarre da molte comunicazioni la nostra comunicazione iniziale.\nIn breve sembra che questa forma di trasmissione sia quella pi√π affidabile per errori (anche la natura in modo naturale pu√≤ dare interferenze)\nNote sulle generazioni (skip) 1G era solamente come codifica della voce, la differenza principale con la 2G √® con la digitalizzazione, con 2G possiamo trasmettere megabytes, per√≤ era pagato per la durata di trasmissione (era telefonare per trasmettere bits lol, per√≤ era lenta, quindi pagava tanto, questa parte l\u0026rsquo;abbiamo accennata in Introduzione a reti, dato che la banda era occupata per tempo).\nCon 2.5G andiamo a sfruttare il tempo libero delle altre comunicazioni, ecco la differenza fra commutazione a pacchetto rispetto a commutazione a circuito\n3G era bono 1Mbit si pensava risolveva tutto.\nInfrastruttura wifi Struttura WWAN WMAN üü®- C\u0026rsquo;√® il problema di scoprire access points, e connettersi ai access point e anche predire il movimento delle persone per prevenire il collegamento alla rete.\nUn altro problema √® tipo il cambio dell‚Äôindirizzo IP ad ogni cambio di rete connettendoci ad access point diverso, per questo motivo si utilizza una forma mobile di IPv4 per mantenere lo stesso IP (se cambiasse sempre allora non potrei sostenere video o simili quando mi sposto).\nGeostazionario: che gira insieme alla terra, quindi l‚Äôabbiamo costantemente sopra la nostra testa questo satellite.\nWLAN Queste sono delle reti ad hoc peer to peer, senza infrastruttura, sono solamente dei nodi che si trovano nella stessa stanza!\nNon abbiamo costi di gestione e manutenzione se siamo senza infrastruttura e possiamo comunicare localmente senza problemi\nBridges with wires Solitamente potremmo avere un access point che sia dual stack con due interfacci una che va in wireless, l‚Äôaltra in wire, a livello 3 posso fare delle bridging functions,\nSvantaggi wireless üü®‚Äî Location tracking √® la cosa di pi√π rilievo riguardo a questo, e anche la cosa pi√π figa perch√© l‚Äôinformazione per trackare le persone ci sarebbe üòÄ\nMultiplexing wireless Slide multiplexing\nDa cui vediamo che abbiamo 4 modi per fare multiplexing dello stesso segnale\nCodice Frequenza del sengale Tempo (non credo abbiamo molto controllo suq uesto lol) E spazio Vogliamo rendere non ambiguo la trasmissione, pi√π dispositivi che utilizzino la stessa risorsa (mezzo di trasmissione di RF diciamo).\nFrequency üü© Slide frequenza\nLe energie di canali diversi dovrebbero essere separate, se comunque si vada ad invadere, il filtro dovrebbe essere sufficiente per ignorare gli altri canali, oppure possiamo separare di pi√π le frequenze, questi spazi vuoti sono spazi di guardia\nUn altro lato negativo √® che il canale √® occupato, quindi quando c\u0026rsquo;√® una asimmetria rispetto al modo in cui √® occupato, allora c\u0026rsquo;√® uno spreco.\nTime multiplexing üü© Slide time multiplex\nSi va in round robin in pratica, c‚Äô√® uno spazio di guardia nel tempo. Che √® uno spreco.\ne c‚Äô√® bisongo di sincronizzazione tra i mezzi trasmissivi molto forte. Il vantaggio principale √® che posso fare una trasmissione molto densa. (va diciamo a burst, quindi anche questo √® uno svantaggio).\nTime and frequency multiplexing üü© Slide time and frequency\nViene utilizzato in GSM wifi. (√® il provider che fornisce per ogni collegamento il seme per la gene), anche per quesot motivo era una comunicazione per tempo. (pagare telefonate per comunicare 9600 bit al secondo avevano di bitrate, costava molto).\nServe coordinamento preciso:\nMappa dei salti deve essere conosciuto Doppio spazio di guardia, sia per tempo sia per frequenze. (quindi anche qui utilizziamo molto spreco! Code multiplexing üü© La magia del CDMA in Modulazione wireless\nSlide code multiplexing\nQuesto sembra molto antiintuitivo, come facciamo ad utilizzare lo stesso canale per comunicare informazioni differenti?\nUtilizzo un codice che mi permette di riestrarre! Che figa la cosa che si pu√≤ riestrarre dal caos.\nbandwidth efficient ossia maggior bitrate con la minore banda. dal punto di vista dell‚Äôuser √® pi√π lento (singolarmente pi√π lento, ma complessivamente di maggiore utilizzo). Un p√≤ di computazione in pi√π per ricevere e mandare. Space multiplexing üü©- Slide space multiplexing\nOssia posizioniamo le nostre antenne in zone differenti. (abbiamo tipo tiling problem) (5G prova a ridurre al minimo l‚Äôarea del segnale)\n","permalink":"https://flecart.github.io/notes/tecnologia-wireless/","summary":"Introduzione Spettro del wireless networks (skip) Slide spettro Wirelesss networks\nQuesto solamente la classica differenziazione fra radio, visibile, raggi x raggi gamma etcetera.\nSe andiamo a guardare le onde radio, quelle che ci interessano, se ho frequenza alta ho densit√† di frequenza alta, se ho frequenza bassa ho alta capacit√† di suparamento di ostacoli.\nISM √® una banda da 2 a 5.0 GHz e c\u0026rsquo;√® tutto il WiFi, bluetooth. (anche wifi a 5 ghz.","title":"Tecnologia Wireless"},{"content":"Introduzione a OOP Per la definizione di classe andare a guardare Object orientation, per√≤ lo ripeto in questa occasione, √® solamente un modello su cui andare a costruire degli oggetti.\nCapisaldiüü© Incapsulazione Astrazione Ereditariet√† Dispatch dinamico Costruttori üü©- Il costruttore √® un codice utilizzato per inizializzare correttamente lo stato interno. Le regole sono le stesse dei metodi sovraccaricati (dinamica per la chiamata, statica per il numero dei parametri che prende in input).\nIncapsulazione Carat incapsulazione üü© ossia la distinzione fra pubblico e privato, il fatto che posso decidere quanto nascondere e quanto esporre. All\u0026rsquo;esterno sono esposte solamente le interfacce che sono solitamente pubblici.\nSolamente le cose dichiarate come pubbliche sono esposte, mentre tutto lo stato interno √® nascosto e non √® accessibile all\u0026rsquo;esterno.\nSottotipi (liskov) üü© Questo √® il principio di sostituzione di liskov, che in pratica ci dice che se S √® sottotipo di T, allora posso utilizzare S in qualunque posto di T.\nSe utilizizmao una notazione matematica, allora se ho unap ropriet√† per un oggetto in T allora questa propriet√† vale anche per un oggetto in S.\nDifferenza tipo e classe üü© C\u0026rsquo;√® una differenza fra struttura delle operazioni (quindi il tipo, cosa prendo e cosa ritorno) con l‚Äôimplementazione effettiva delle funzioni, i check per privati e pubblici (implementati dalle classi). Quando dichiariamo alla classe √® come se dichiarassimo allo stesso momento una interfaccia per essa.\nconsideriamo la definizione di una classe come accompagnata da una definizione implicita di un\u0026rsquo;interfaccia della vista pubblica di quella classe.\nIn questo senso la classe diventa un elemento nel nostro sistema dei tipi.\nAstrazione (!) üü© La nozione di astrazione √® strettamente legata all\u0026rsquo;interfaccia implicita che la classe induce.\nL‚Äôastrazione di permette di andare ad elaborare con alcuni concetti che nativamente non esistono, per esempio non esiste nativamente il tipo Euro, ma pu√≤ essere implementata attraverso il tipo concreto degli interi. Le classi forniscono delle interfacce che permettono una modifica controllata dell‚Äôoggetto che viene rappresentato, questo √® il significato di astrazione.\nle interfacce ci permettono di fornire ai clienti una descrizione del \u0026ldquo;contratto\u0026rdquo; che i nostri oggetti promettono di soddisfare, senza costringerci a fornire la loro effettiva implementazione.\nossia descrive ci√≤ che prende in input, ci√≤ che deve andare a ritornare. senza dire esattamente come √® implementata quella logica.\nClassi astratte üü© Sono una via di mezzo fra interfaccia e classe nel senso che possono lasciare delle funzioni non implementate\nEreditariet√† Sottotipaggio ed ereditariet√† (2) Ci sono due keyworks principali quando andiamo a parlare di sottotipaggoi ed ereditariet√†, sono extends and implements.\nExtends: prende anche i metodi (proprio l\u0026rsquo;implementazione) di tutti metodi e gli stati del genitore. Doppia operazione: Relazione di sottotipaggio col tipo da cui estende Prendere tutti i metodi dichiarati sono presenti ora anche qui. Implements: crea l\u0026rsquo;implementazione dell‚Äôinterfaccia astratta. C\u0026rsquo;√® una leggera differenza fra queste keywords se utilizzate per interfacce oppure per classi. Credo l\u0026rsquo;unica cosa che cambia √® che per extends nelle classi mi porto dietro anche stati e funzioni e anche i vincoli di incapsulamento.\nIn breve: sottotipi parlano di operazioni, e manipolazione i interfacce fre la varie classi, mentre l‚Äôereditariet√† va a parlare di metodi che possono essere utilizzate o meno.\nDifferenza principale fra sottotipaggio ed ereditariet√†\nShadowing Come gestire i casi di ereditariet√† in cui una stessa variabile √® stata dichiarata con esattamente lo stesso nome?\nRegole di scoping statico! In pratica il parent √® visto come uno scope pi√π esterno, e si risolve in questo modo.\nOverriding dei metodi Coerentemente al principio di astrazione, posso cambiare il contenuto (quindi la semantica) di una funzione senza cambiarne la signature, sulla stessa logica posso reimplementare un metodo in un child class.\nUna differenza tra l\u0026rsquo;overriding dei metodi e lo shadowing delle variabili √® che il primo √® risolto dinamicamente, mentre il secondo √® risolto staticamente.\nModificatori di visibilit√† (2) Ci sono dei modi per andare a modificare la visibilit√† durante le relazioni di ereditariet√† fra le classi, queste son ooil packaged e protected\npackaged: se sei un figlio allora puoi vedere i metodi privati (tutto lo stesso pacchetto pu√≤ vedere questi metodi. Protected: tutte le sottoclassi, anche in moduli diversi possono utilizzare le funzioni ereditate protected, solo che l\u0026rsquo;esterno non pu√≤ comunque andare ad accederci. Tipi intersezione Questi tipi intersezione prendono in input due classi e creano una classe che abbia entrambe le caratteristiche delle due classi. Sono diverse dai tipi unione, perch√© questi tipi unione possono essere o uno o l‚Äôaltro, nel senso che non sono entrambi in contemporanea!.\nIn un certo senso sono concatenati questi valori. Una cosa interessante √® che il grafico delle inheritance √® un DAG\nEreditariet√† multipla problemi: diamante Slide introduzione dei problemi di ereditariet√† (2 sol)\nQuesta implementazione ha molti problemi quando eredito due cose che hanno una intersezione, come per esempio un metodo con lo stesso nome. Allora come si risolve questo problema?\nIl problema principale √® la diamond of death\nDynamic dispatch Early and late binding Late: quando ho l‚Äôoggetto io vado a cercare l‚Äôoggetto, se lo trovo allora lo eseguo, se non c‚Äô√® allora continuo la ricerca finch√© non lo trovo, allora do errore: √® una cosa molto simile al prototyping.\nEarly: Utilizza infomrazioni statiche per risolvere l‚Äôambiguit√†, questo dovrebbe farlo C per esempio.\nMetodi statici Niente ci vieta di andare a definire dei metodi statici che vengono risolti in modo statico.\nImplementazione degli oggetti (link) SI potrebbe tenere una lista linkata fra tutte le ereditariet√†, solo che diventa una cosa molto lenta, perch√© potrebbero esserci molti accessi: vado a cercare fino al top se ci sia o meno questo metodo per una certa classe.\nEarly and late binding Accesso via offset: per accedere allo stato, faccio in modo molto simile alle struct, che in pratica vanno a calcolare offset rispetto a qualcosa, il calcolo dell‚Äôoffset per il singolo stato √® molto veloce, una cosa leggermente pi√π complicata √® la ricerca del metodo corretto, se questo √® stato sovrascritto o simile. (fa ricerca lineare, va su finch√© non trova il metodo.\nCHIAMATA DEL METODO\nNon solo vogliamo andare a creare uno stack frame, variabili locali e parametri abbiamo in pi√π anche le variabili di istanza! Semplicemente prende il this e ci applica l‚Äôoffset per prendere le informazioni, le slides lo fanno molto pi√π complicato.\nVtables(!!) Ogni oggetto ha un puntatore alla propria vtable della propria classe, con gi√† tutti i puntatori alle funzioni corrette per le funzioni.\nSlides ereditariet√†\nDovrebbe funzionare solamente per ereditariet√† singola, non so per la multipla come funziona questa della vtable.\nClasse base fragile C‚Äô√® il problema della composizionalit√†, nel senso che non possiamo andare a compilarli in modo diverso, se cambiamo una classe padre, allora bisogna andare a ricompilare tutti childs, √® un problema di ingegneria del software questo.\nType parameter erasure In Java fragile Ci sono alcuni metodi per andare a gestire il problema della classe fragile. Come gestire questo problema quando l\u0026rsquo;intera classe √® stata compilata a s√© stante. Viene risolto a caricamento e la prima reference viene risolta e sostituita al codice di ricerca col riferimento al codice effettivo.\n","permalink":"https://flecart.github.io/notes/classi-oop/","summary":"Introduzione a OOP Per la definizione di classe andare a guardare Object orientation, per√≤ lo ripeto in questa occasione, √® solamente un modello su cui andare a costruire degli oggetti.\nCapisaldiüü© Incapsulazione Astrazione Ereditariet√† Dispatch dinamico Costruttori üü©- Il costruttore √® un codice utilizzato per inizializzare correttamente lo stato interno. Le regole sono le stesse dei metodi sovraccaricati (dinamica per la chiamata, statica per il numero dei parametri che prende in input).","title":"Classi OOP"},{"content":"Project, product management, project management Bisogna capire queste definizioni. Vedere https://dynamik.vercel.app/ingegneria-del-software/lucidi/13-gestione-del-progetto.pdf?from=informatica, slide 5 per definizione\nProgetto: inizia e finisce in tempo preciso. √à importante comunque ricordare gli steps principali per il progetto ossia ideazione, creazione, mantenimento, rilascio, e poi morte, questo in genere √® per qualunque progetto.\nProject Manager Compiti principali (costi e risorse) Vedere se il progetto √® fattibile Allocare risorse Monitorare come sta andando. (preventivo e consuntivo). Work Breakdown structure Descrizione WBS √à una suddivisione del progetto in piccoli sottoparti che si possono gestire in modo autonomo.\nA Work Breakdown Structure (WBS) is a hierarchical decomposition of a project into phases, deliverables, and work packages. It is a visual representation that helps project managers and teams organize and define the scope of work required to complete a project. The WBS breaks down the project into smaller, more manageable components, making it easier to plan, execute, and control.\nhttps://chat.openai.com/share/1d74fa24-d198-4c17-9fbe-1c8cc93333d4\nSi pu√≤ rappresentare con un grafico di Gantt (vedi Scheduler#Diagramma di Gantt). Perch√© cos√¨ so quando ogni singola attivit√† inizia e finisce.\nMilestone e percorso critico Debito tecnico Il debito tecnico √® una stima del costo di futuro sforzo addizionale causato da una soluzione prematura adottata oggi pur di consegnare un prodotto con qualche valore (lo sforzo futuro andr√† ripagato con gli interessi)\nIl costo di versioni successive, √® costo in debito tecnico, per questo motivo √® maggiore. E si dovrebbe dare valore prima.\nMisura dei costi di sviluppo Misura nel software costo e valore del software Valore √® sul ricavo -\u0026gt; numero di utenti * ricavo medio. Mentre il costo del software e tempo persona.\nPer stimare il costo usiamo 4 cose:\nCosto hardware Costo sviluppo del software Costo risorse umane Durata del progetto. Metodi generici di stima (4) Design-to-cost nel senso che chi √® in industria fa prodotto tailored al costo. L\u0026rsquo;ultima √® funzionale\nLinee di codice (fisiche e logiche) Fisiche sono quelle effettivamente presenti nel codice, invece le linee logiche sono quelle che contengono istruzioni base (per base intendo quelli C like). Se si riesce a fare una stima dell\u0026rsquo;architettura del progetto, e poi delle linee logiche necessarie per fare questo sviluppo, possiamo tenere conto di una media di numeri giornalieri, e possiamo calcolare cose come costo totale del software avendo una media per riga. Chiaramente mi sembra che questa stima sia fortemente imprecisa.\nVantaggi e svantaggi di LOC La cosa carina di questo metodo √® che √® facile da fare. Poi abbiamo metriche derivate molto semplici da intendere come:\nBugs per kLoC. la produttivit√† √® una cosa molto facile. Il costo per linea di codice Sono certe metriche che potrebbero servire lato business, per√≤ sono abbastanza senza senso per quanto riguarda features date al cliente. Mi sembra il caso in cui una metrica pu√≤ diventare facilmente l\u0026rsquo;oggetto (massimizzare per cosa sbagliata dico), e non una linea guida Per√≤\ndipende dal linguaggio quasi nessuna correlazione con la qualit√† del software (quindi produce bloatware per dire), non viene prodotto software conciso o efficiente. Non tiene conto della complessit√†, certe istruzioni possono fare un sacco di cose, a seconda del livello di astrazione. Non possiamo distinguere bene le linee logiche con quelle fisiche, non abbiamo un metodo per contarle per dire. Function point Idea principale del metodo L‚Äôanalisi Function Point enumera le funzionalit√† di un sistema dal punto di vista utente\nElaborata da un certo Dr. Allan Albrecht in 1979, sono il numero di features fatte, che l\u0026rsquo;utente pu√≤ utilizzare (e questa stima mi piace molto di pi√π rispetto a quello di linee di codice). Cerchiamo di analizzare il software tramite le funzionalit√† nuove che possono venire offerte.\nL\u0026rsquo;idea √® partire da quello che √® necessario all cliente, quelli che chiamiamo functional requirements trattati a Requisiti e backlog del software. Insieme a questi sono collegati i non functional requirements che sono features necessarie a sviluppatori, e non utenti.\nUFC e TFC Ufc √® Unadjusted Function Count che √® la somma semplice di tutte le funzionalit√† su tutti i lati in cui potrebebro essere necessit√† di function points.\nCocomo e modelli di costo Non fatti.\n","permalink":"https://flecart.github.io/notes/project-management/","summary":"Project, product management, project management Bisogna capire queste definizioni. Vedere https://dynamik.vercel.app/ingegneria-del-software/lucidi/13-gestione-del-progetto.pdf?from=informatica, slide 5 per definizione\nProgetto: inizia e finisce in tempo preciso. √à importante comunque ricordare gli steps principali per il progetto ossia ideazione, creazione, mantenimento, rilascio, e poi morte, questo in genere √® per qualunque progetto.\nProject Manager Compiti principali (costi e risorse) Vedere se il progetto √® fattibile Allocare risorse Monitorare come sta andando. (preventivo e consuntivo). Work Breakdown structure Descrizione WBS √à una suddivisione del progetto in piccoli sottoparti che si possono gestire in modo autonomo.","title":"Project Management"},{"content":"Replication and consistency Introduzione Ci sono due vantaggi principali nella replicazione dei dati\nVelocit√† Vicinanza geografica (quindi meno tempo ad andare a tornare) Maggiore computazione, quindi avere molti pi√π processori che cercano di offrire lo stesso servizio. Affidabilit√† Cos√¨ se una sede diventa corrotta, posso avere abbondanza, avere una copia da una altra parte, cos√¨ non perdo le informazioni! Se una macchina cade in errore, ho altre macchine che lo sostituiscono! Quindi dal punto di vista dell‚Äôutente funziona ancora. Ma provare ad avere lo stesso dato in zone diverse porta a grandi problemi riguardo la consistenza! Come facciamo ad avere la garanzia che due cose diverse abbiano la stessa informazione?\nConsistency La nozione di consistenza non √® che sia definito in modo molto formale, possiamo solo descriverlo in modo molto generale come un contratto fra processo e dati su cui opera. Si pu√≤ dire che un processo √® consistente se fa quello che dovrebbe fare (quindi vago vago descrizione).\nContinuous consistency Questo √® un modello molto vecchio, caduto in disuso perch√© principalemente pone delle interfaccie di difficile implementazione, nel senso che √® difficile utilizzarle e definirle in casi di applicazione reale (credo un p√≤ come se stessi utilizzando i semafori).\nIl concetto principale √® di errore assoluto o relativo di inconsistenza (‚Üí quando l‚Äôinconsistenza supera una certa deviazione, allora si prova a rimediare e ristabilire la consistenza), che andiamo a chiamare il conit. A seconda di quanto conit abbiamo decidiamo o meno se propagare la consistenza. Si nota subito da qui che √® difficile dare un valore di inconsistenza e quindi andiamo a disuso.\nEsempi di caso d‚Äôuso sono i prezzi degli stock. Se variano di poco, non so 0.0001, allora non provo a renderlo consistente ancora (per quanto riguarda la lettura)\nPer maggiori informazioni consultare il capitolo 7 sulla consistenza continua.\nOrdered consistency (2) In questa parte trattiamo un idea presente gi√† da tempo negli studi di parallelismo e sistemi distribuiti. L‚Äôidea principale √® che cerchiamo di ordinare la sequenza di lettura e scrittura. Questo sar√† la cosa comune ai vari protocolli.\nSequential consistency Definito in Lamport 1979\nThe result of any execution is the same as if the (read and write) operations by all processes on the data store were executed in some sequential order and the operations of each individual process appear in this sequence in the order specified by its program\nIn questa definizione lo vediamo come ci sia il bozzolo dell‚Äôidea che il sistema distribuito sia una unica macchina un pochetto sparsa. Abbiamo che tutte le operazioni sono sequenziali, come se stessimo su una macchina! In particolare ci basta che siano in ordine non sappiamo per√≤ quale ordine sia.\nCausal consistency Questo √® un tipo speciale di sequential consistency, e l‚Äôidea principale si basa sul fatto che non ha senso dare un ordine a delle cose indipendenti fra di loro, per esempio se faccio solamente dei read, non ha senso che provi a dare un ordine di lettura, tanto le cose che leggo sono le stesse.\nQuindi avrebbe senso ordinare solo le read che hanno una write che la influenza quindi che sia in qualche modo causato o influenzato dalla write.\nEventual consistency TODO\nClient-centric consistency Questo √® un modello che abbiamo creato principalmente per i dispositivi mobili. Vogliamo garantire consistenza all‚Äôutente anche quando il server non potrebbe essere pienamente consistente. Il motivo di cambiare visuale e ora metterci dal punto di vista dell‚Äôutente √® che non possiamo predire lo spostamento di essa. E per esempio cambiare password in un punto. Spostarsi, e provare a loggare da un altro punto porta a un fallimento, questa non √® una buona cosa. La client centric consistency prova a risolvere questo problema\nEventual consistency\nOssia prima o poi il dato sar√† sincronizzato fra i dispositivi diversi (un giorno? due giorni? prima o poi lo fa!).\nPer molte cose questo ritardo non √® molto importante, per esempio i DNS.\nRead \u0026amp; write consistencies Monotonic-read consistency if a process reads the value of a data item x, any successive read operation on x by the process will always return that same value or a more recent value\nOssia, una volta letto una cosa al tempo t, non posso pi√π leggere cose al tempo \u0026lt; t.\nEsempio: email , non voglio rileggere una email che ho gi√† letto.\nMonotonic-write consistency a write operation by a process on a data item x is completed before any successive operation on x by the same process\nOssia se voglio scrivere cose al tempo t, devo aspettare che tutte le write prima di t finiscano per fare qualunque cosa dopo t.\nUpdate del software, devo andare a leggere o scrivere sulla versione pi√π recente.\nRead your writes the effect of a write operation by a process on data item x will always be seen by a successive read operation on x by the same process\nOssia prima scrivo poi leggo.\nEs: password update. (non voglio che una password vecchia sia ancora considerata come valida dopo un cambio).\nWrites follow reads a write operation by a process on data item x following a previous read operation on x by the same process is guaranteed to take place on the same or a more recent value of x that was read\nOssia quando modifico, lo faccio solo sull‚Äôultimo valore. (cio√® non posso scrivere su elementi vecchi (aka, non pu√≤ succedere che il mio messaggio arrivi prima del messaggio che ho letto, dopo che c‚Äô√® stato consistenza))\nReplication Questa √® una parte complicata.\nPosso replicare non solo i dati ma ANCHE i servizi. E qui sale il problema dell‚Äôidentit√†. Come gestire i servizi che fanno esattamente la stessa cosa?\n","permalink":"https://flecart.github.io/notes/replication-and-consistency/","summary":"Replication and consistency Introduzione Ci sono due vantaggi principali nella replicazione dei dati\nVelocit√† Vicinanza geografica (quindi meno tempo ad andare a tornare) Maggiore computazione, quindi avere molti pi√π processori che cercano di offrire lo stesso servizio. Affidabilit√† Cos√¨ se una sede diventa corrotta, posso avere abbondanza, avere una copia da una altra parte, cos√¨ non perdo le informazioni! Se una macchina cade in errore, ho altre macchine che lo sostituiscono!","title":"Replication and consistency"},{"content":"Abbiamo trattato i modelli classici in Convolutional NN. Con i vecchi files di notion\nIl Kernel I punti interessanti delle immagini sono solamente i punti di cambio solo che attualmente siamo in stato discreto, quindi ci √® difficile usare una derivata, si usano kernel del tipo: $\\left[ 1, 0, -1 \\right]$, che sar√† positivo se cresce verso sinistra, negativo se scende. feature map Sono delle mappe che rappresentano alcune informazioni interessanti della nostra immagine.\nPrincipi di base Nota sulla depth Come viene spiegato in (Cohen et al. 2016) shallow e deep sono equivalenti, ma c\u0026rsquo;√® una esplosione esponenziale sul numero di neuroni necessari\nCaratteristiche di convoluzionali Localit√†, Condivisione, Invarianza per traslazioni Localit√† perch√© ho una field of view, che √® la grandezza del kernel precedente, condivisione perch√© i pesi del kernel sono sempre gli stessi. Poi non ho capito perch√© il pooling fa invarianza per traslazioni.\nReferences [1] Cohen et al. ‚ÄúOn the Expressive Power of Deep Learning: A Tensor Analysis‚Äù 2016\n","permalink":"https://flecart.github.io/notes/reti-convoluzionali/","summary":"Abbiamo trattato i modelli classici in Convolutional NN. Con i vecchi files di notion\nIl Kernel I punti interessanti delle immagini sono solamente i punti di cambio solo che attualmente siamo in stato discreto, quindi ci √® difficile usare una derivata, si usano kernel del tipo: $\\left[ 1, 0, -1 \\right]$, che sar√† positivo se cresce verso sinistra, negativo se scende. feature map Sono delle mappe che rappresentano alcune informazioni interessanti della nostra immagine.","title":"Reti convoluzionali"},{"content":"Spazi vettoriali 1.1 Piano cartesiano 1.1.1 Definizione Possiamo considerare il piano cartesiano come l\u0026rsquo;insieme $\\R^2$ potremmo dire che esiste una corrispondenza fra una coordinata e un punto del piano, una volta che abbiamo definito un punto di origine. Si pu√≤ vedere anche come corrispondenza biunivoca con vettori del piano per l\u0026rsquo;origine (parte dall\u0026rsquo;origine).\nQuesta cosa vale anche per uno spazio n-dimensionale, non soltanto due, ma per semplicit√† di introduzione di questo lo faccio con 2\n1.1.2 Operazioni definite Possiamo definire una somma fra questi punti in coordinata e un prodotto.\nSomma\n$\\forall a,b,c,d \\in \\R \\,\\,\\langle a,b\\rangle + \\langle c,d \\rangle = \\langle a + c, b+d\\rangle$\n(dovremmo definire invece queste cose nello spazio vettoriale, in quanto non necessariamente dobbiamo averle in R)\nProdotto scalare\n$\\forall a,b \\in V, \\lambda \\in \\R, \\lambda\\langle a, b\\rangle = \\langle \\lambda a, \\lambda b \\rangle$\n1.2 Introduzione agli spazi vettoriali 1.2.1 Assiomi di base Definiamo qui le propriet√† necessarie per essere uno spazio vettoriale.\nGruppo abeliano rispetto alla addizione (4) $V \\times V \\to V$ Vedi: Gruppi Moltiplicazione √® scalare, definito su un campo $C \\times V \\to V$ Associativit√† Elemento neutro presente. Vale distributivit√† destra e sinistra che collega addizione e prodotto 1.2.2 Conseguenze principali degli assiomi 1.2.3 Interpretazione geometrica (2) Principalmente ci sono due interpretazioni possibili. Per punti o vettori.\nPunti esiste una corrispondenza biunivoca fra uno spazio n-dimensionale e la coordinata Vettori esiste una corrispondenza biunivoca fra vettori che iniziano dall\u0026rsquo;origine e in punti. 1.2.4 Polinomi a coefficienti in R (Esempio) Questo √® un esempio di spazio vettoriale. Si pu√≤ fare una verifica per vedere che gli assiomi sono soddisfatti.\nAltri spazi vettoriali sono l\u0026rsquo;insieme delle matrici con coefficienti reali, l\u0026rsquo;insieme delle funzioni continue in R.\n1.2.5 Sottospazio vettoriale (def e banale) Un sottospazio vettoriale √® un sottoinsieme che √® chiuso per l\u0026rsquo;addizione e moltiplicazione.\nSia U un sottospazio di V, allora per definizione vale:\nU non √® vuoto chiuso rispetto somma Chiuso rispetto moltiplicazione Il sottospazio banale √® un sottospazio che contiene solo l\u0026rsquo;elemento nullo per l\u0026rsquo;addizione\nSi pu√≤ anche trovare una serie di assiomi equivalenti per il sottospazio\n1\u0026rsquo;. il vettore $0_v$appartiene al sottospazio U, e valgono 2 e 3\nE si pu√≤ scrivere una propriet√† equivalente a 2 e 3, ossia chiuso rispetto a una combinazione lineare.\nEsercizio\nDimostrare che le ipotesi 2 e 3 implicano che $\\lambda a + \\lambda_2b \\in V,$ con i lambda valori del campo.\n1.2.6 Minimi sottospazi (classificazione sottospazi di R2) Se prendiamo un punto nel piano, ci basta una retta che passa per essa e per l\u0026rsquo;origine per avere il minimo sottospazio che lo contenga.\nIl ragionamento per dire che √® il minimo √® pi√π o meno su questa scia:\nSe contiene quel punto diverso da 0, allora deve contenere tutti i punti sulla retta almeno (altrimenti non √® chiuso per il prodotto scalare). Se ne contiene di pi√π non √® pi√π il minimo sottospazio, se ne contenesse di meno allora ci sarebbe un assurdo con il punto uno. Si pu√≤ dire la stessa cosa per 2 o pi√π punti allineati. Se per√≤ non sono allineati, allora devo prendere il loro span. Ovvero se ho $u, v$ indipendenti fra di loro allora il minimo sottospazio √®\n$\\alpha v + \\beta u$ che √® l\u0026rsquo;intero piano. (questo poi √® anche la condizione 23 per dimostrare che √® sottopiano).\nSu questa analisi pu√≤ dimostrare che gli unici sottospazi di R2 sono 3.\nBanale Retta R2 Possiamo formalizzare il senso di pi√π piccolo sottospazio che contiene un elemento come l\u0026rsquo;insieme sottospazio che √® contenuto in ogni altro sottospazio (e si potrebbe dire quindi anche che non esiste un altro sottospazio pi√π piccolo)\n1.3 Combinazioni lineari 1.3.1 definizione Si dice che $v$ √® combinazione lineare di vettori $v_1, ... v_n$ se esistono $\\lambda_1,...,\\lambda_n \\in K$ tali che\n$\\lambda_1v_1 + ....+ \\lambda_n v_n = v$\nPossiamo prendere l\u0026rsquo;insieme delle combinazioni lineari cihe scriviamo come\n$\\langle v_1, ..., v_n \\rangle = \\{\\lambda_1 v_1 +... + \\lambda_n v_n | \\lambda_1, ..., \\lambda_n \\in R\\}$\nSe $V = \\langle v_1, ..., v_n \\rangle$ allora i vettori $v_1, ..., v_n$ generano lo spazio vettoriale $V$\n1.3.2 Proposizione 3.1.5 minimo sottospazio (chiede in esame) Enunciato:\nSia $V$ uno spazio vettoriale, allora $v_1, ..., v_n \\in V$ allora $\\langle v_1,...v_n\\rangle$ √® uno sottospazio vettoriale di $V$ ed √® il minimo sottospazio vettoriale contenenti questi punti.\nDimostrazione: esercizio (non troppo complessa).\nhint di dimostrazione\nBisogna dimostrare due cose: 1 √® uno sottospazio vettoriale (soddisfa quei tre requisiti) e 2 √® il minimo sottospazio vettoriale, quindi qualunque latro sottospazio vettoriale che contiene quei punti contiene anche questo spazio vettoriale).\n1.3.3 Prop 3.1.8 dipendenza lineare + 1 (relativo a span) sia $\\langle v_1, ..., v_n \\rangle$ uno spazio vettoriale generato da quei vettori, considero $\\langle v_1, ..., v_n, \\omega \\rangle$ con $\\omega$ una combinazione vettoriale dei vettori base, allora si ha che\n$\\langle v_1, ..., v_n \\rangle = \\langle v_1, ..., v_n, \\omega \\rangle$\nHint di dimostrazione\nil primo √® contenuto nel secondo (abbastanza ovvio, basta che tengo W 0), devo dimostrare che il secondo √® contenuto nel primo.\n(in pratica riesco a dimostrare che qualunque combinazione lineare con $\\omega$ √® esprimibile come combinazione lineare dei vettori che generano lo spazio vettoriale iniziale\nUn altro modo per dimostrarlo √® prendere Z generato dal primo insieme di vettori, so che tutti questi vettori sono contenuti in Z, cos√¨ anche omega √® contenuto, allora si ha per la 3.1.5 che questo spazio vettoriale √® contenuto in Z.\nSi pu√≤ dimostrare una cosa anche contraria, ovvero\n$\\langle v_1, ..., v_n \\rangle = \\langle v_1, ..., v_n, \\omega \\rangle \\implies \\omega$ combinazione lineare di $v_1,..., v_n$\n1.4 Indipendenza lineare Questo concetto di indipendenza lineare ci permette di definire una base per uno spazio vettoriale (ossia il minimo insieme di vettori necessario per generare uno spazio)\n1.4.1 Definizione Un insieme di vettori $v_1,..., v_n$ sono linearmente indipendenti sse $\\alpha_1v_1 + ... + \\alpha_nv_n = 0 \\iff \\alpha_1 = ... = \\alpha_n = 0$\nUn insieme di vettori allora si dice linearmente dipendente se esiste un insieme di coefficienti tali che non tutti diversi da zero ottengo che $\\alpha_1v_1 + ... + \\alpha_n = 0$\nOsservazione\nSe un insieme di vettori contiene il vettore $0_v$ allora so per certo che sono linearmente dipendenti in quanto a questo vettore posso molitplicare qualunque cosa, fatto che va contro la definizione di indipendenza lineare\n1.4.2 Prop 3.2.4 Corrispondenza combinazione e dipendenza lineare (chiede) Enunciato\nSe $v_1,...,v_n$ vettori dipendenti fra loro $\\iff$ almeno uno di essi √® combinazione lineare di dell\u0026rsquo;insieme dei vettori in questione.\nDimostrazione\n$\\implies$\nSiano v1\u0026hellip; vn vettori dipendenti fra loro, dobbiamo dimostrare che esiste uno che sia combinazione lineare di altri.\nPer ipotesi di dipendenza se $\\lambda_1v_1 +... + \\lambda_nv_n =0, \\exists k, 0 \u003c k \\leq n, \\lambda_k \\neq 0$.\nAllora $\\lambda_kv_k = -(\\lambda_1v_1 +...+ \\lambda_{k-1}v_{k-1} +\\lambda_{k+1}v_{k+1} +...+ \\lambda_nv_n)$ e da qui √® abbastanza ovvio che posso scrivere $v_k$ come combinazione lineare di altri.\n$\\impliedby$\nSia $v_k$ una combinazione lineare dell\u0026rsquo;insieme di vettori $v_1, ..., v_{k-1},v_{k+1},..., v_n$\nAllora ho che $v_k = \\lambda_1v_1 +...+ \\lambda_{k-1}v_{k-1} +\\lambda_{k+1}v_{k+1} +...+ \\lambda_nv_n$ per certi valori di lambda.\nAllora se considero questa combinazione lineare\n$-\\lambda_1v_1 +... -\\lambda_{k-1}v_{k-1} + 1\\cdot v_k -\\lambda_{k+1}v_{k+1} +...- \\lambda_nv_n$ ottengo che questo √® uguale a 0 e in particolare ho che il coefficiente di $v_k$ √® diverso da 0, quindi questi vettori sono dipendenti.\nOsservazione (sui multipli)\nNel caso in cui ho due vettori, il fatto che uno √® combinazione lineare dell\u0026rsquo;altro √® equivalente a dire che uno √® multiplo dell\u0026rsquo;altro.,\n1.4.3 Geometria nella dipendenza lineare Due vettori\nAbbiamo detto che due vettori sono linearmente dipendenti quando uno sono multiplo dell\u0026rsquo;altro, possiamo intendere questo fatto algebrico come un fatto geometrico osservando che tali vettori devono giacere sulla stessa retta\nTre vettori\nIn modo analogo al precedente, possiamo concludere che tre vettori sono linearmente dipendenti sse giacciono su uno stesso piano (COMPLANARI)\nPi√π vettori\nSe ho n vettori, questi se fossero indipendenti giacerebbero su uno spazio n-dimensionale, appena √® possibile esprimerli come appartenenti a uno spazio di dimensione minore di n, allora posso dire che questi n vettori sono dipendenti, questa √® l\u0026rsquo;astrazione necessaria per comprendere questo fatto.\n","permalink":"https://flecart.github.io/notes/spazi-vettoriali/","summary":"Spazi vettoriali 1.1 Piano cartesiano 1.1.1 Definizione Possiamo considerare il piano cartesiano come l\u0026rsquo;insieme $\\R^2$ potremmo dire che esiste una corrispondenza fra una coordinata e un punto del piano, una volta che abbiamo definito un punto di origine. Si pu√≤ vedere anche come corrispondenza biunivoca con vettori del piano per l\u0026rsquo;origine (parte dall\u0026rsquo;origine).\nQuesta cosa vale anche per uno spazio n-dimensionale, non soltanto due, ma per semplicit√† di introduzione di questo lo faccio con 2","title":"Spazi vettoriali"},{"content":"Classi laterali Dimostrazione dei lemmi sopra. La cosa interessante di questa parte √® possiamo usare una classe laterale per partizionare il gruppo iniziale!\nIl teorema di Lagrange Dividere significa che **partiziona** l'insieme iniziale in alcuni insiemi distinti. L'insieme $G:H$ √® l'insieme che contiene tutti i cosets, credo. Dimostrazione\n|G:H| = |G|/|H| |a| divide |G| Ossia un corollario dopo il teorema di Lagrange. La cosa citata √® dimostrata in Gruppi ciclici e permutazioni#Criterio $a {i} = a {j}$.\nI gruppi di ordine primo sono ciclici Se ho un gruppo di ordine primo, per il teorema di Lagrange non posso avere sottogruppi propri, perch√© l‚Äôordine di questi dovrebbe dividere l‚Äôordine del gruppo di partenza. Per questo motivo ho un unico gruppo. Ossia ogni elemento genera l‚Äôintero gruppo\na elevato all‚Äôordine del gruppo √® uguale ad e Dimostrazione L‚Äôordine dell‚Äôelemento a deve dividere l‚Äôordine di |G| per Lagrange, quindi, in simboli $$ |a| =n, |G| = m, n \\mid m \\implies m = nj, a^{|G|} = a^{nj} = e ^j = e $$ Il piccolo teorema di fermat Dimostrazione\nSolitamente si usa la versione $$ a^{p - 1} = 1 \\mod p $$ E la cosa comoda √® che $a^{p - 2}$ √® l\u0026rsquo;inversa di quello.\nTeorema di Eulero Proof. http://www.fen.bilkent.edu.tr/~franz/nt/ch7.pdf.\nQuesta √® una generalizzazione di #Il piccolo teorema di fermat. Afferma che $\\forall n \\in \\mathbb{N}$ vale che $$ a^{\\varphi(n)} = 1 \\mod n $$ Questo √® molto pi√π complesso da descrivere e dimostrare. Bisognerebbe per esempio anche definire propriet√† della funzione di Eulero.\nClassificazione dei gruppi di ordine 2p SCHIVA STO TEOREMA CHE NON MI SERVE A NUCAZZU\nIdee della dimostrazione\nDividere la discussione con la presenza o meno di elementi di ordine 2p Caso in cuinon ci sono elementi di ordine 2p Dimostrare che esiste almeno un elemento di ordine p, perch√© se fossero tutti di ordine 2, riesco a crearmi (in modo creativo) un sottogruppo di ordine 4 a piacere, molto simile al gruppo quaternione. Avendo un sottogruppo di ordine p, questo quozienta l‚Äôinsieme G per il teorema di lagrange, ho solamente un altro insieme che posso scrivere come elemento_fuori_a * gruppo_generato_da_a_di_ordine_p Dimostro che l‚Äôordine dell‚Äôelemento fuori da a deve essere necessariamente di ordine 2. (in qualche modo che non ho compreso) Dimostrazione\nStabilizzatore e orbita Stabilizzatore Orbita !\nTeorema orbita stabilizzatore !\n","permalink":"https://flecart.github.io/notes/teorema-di-lagrange/","summary":"Classi laterali Dimostrazione dei lemmi sopra. La cosa interessante di questa parte √® possiamo usare una classe laterale per partizionare il gruppo iniziale!\nIl teorema di Lagrange Dividere significa che **partiziona** l'insieme iniziale in alcuni insiemi distinti. L'insieme $G:H$ √® l'insieme che contiene tutti i cosets, credo. Dimostrazione\n|G:H| = |G|/|H| |a| divide |G| Ossia un corollario dopo il teorema di Lagrange. La cosa citata √® dimostrata in Gruppi ciclici e permutazioni#Criterio $a {i} = a {j}$.","title":"Teorema di Lagrange"},{"content":"Strutture algebriche Differenza matematica e informatica Una osservazione per quanto riguarda la logica intuizionista √® che sta a met√† fra matematica e informatica perch√© la dimostrazione intuizionista possiede in s√© un algoritmo e una struttura di dati.\nInfatti di solito l\u0026rsquo;informatico scrive senza fare la dimostrazione dell\u0026rsquo;algoritmo mentre il matematico scrive la dimostrazione senza fare l\u0026rsquo;algoritmo (inoltre pu√≤ definire degli enti ed oggetti che non siano rappresentabili come dati in quanto possono essere infiniti.\nUn opinione personale √® che l\u0026rsquo;informatica √® pi√π pratica, e limitata in quanto non pu√≤ estendersi al ragionamento infinito ma deve essere limitata al calcolo. Questo √® si molto pi√π utile ma molto meno creativo. Si pu√≤ attaccare per√≤ il problema in questi modi!\nOsservazioni generali La matematica utilizza questi metodi da molto tempo prima dell\u0026rsquo;esistenza di una macchina di calcolo.\nI concetti generali di matematica che si sono sviluppati nei secoli sono astrazioni e generalizzazioni. (non esiste ancora una base simile in informatica, e.g. le classi di java hanno proprio degli errori logici al suo interno, anche se non so esattamente quali, ma Coen dice di s√¨)\nAstrazione e generalizzazione Tesi di Church-Turing Vedere La macchina di Turing#Tesi di Church-Turing Guarda Questa tesi (non √® un teorema) definisce il significato di espressivit√† di un linguaggio di programmazione.\nIn altre parole deve avere:\nUn modo di ciclare branching (if condition) E numeri Ma quindi i linguaggi di programmazione non cambiano per capacit√† di calcolo, bens√¨ nella capacit√† di astrazione e generalizzazione.\nAssiomi di Peano Vedere https://it.wikipedia.org/wiki/Assiomi_di_Peano Sono i classici assiomi che caratterizzano i numeri naturali\nEsiste $0$, questo √® facile basta definirlo nel termine (vedi Logica del Primo ordine Esiste la funzione successore I successori si comportano bene ossia $\\forall x \\forall y ((S(x) = S(y)) \\implies x = y)$ Non esiste il predecessore di $0$ ossia $\\neg \\exists x \\mid S(x) = 0$ Esiste sempre il successore se non √® zero, $\\forall x \\mid \\neg(x = 0) \\to \\exists y: S(y) = x$ Wiki prende questo passo leggermente diverso, ma forse il concetto √® esattamente lo stesso. Astrazione Vedere note come Astrazione sul controllo per altri generi di astrazione, comunque √® una cosa molto importante per informatica e scienze.\nAlcune caratteristiche le trascuro perch√© sono accessorie (dipendono dall\u0026rsquo;implementazione, dal caso specifico), questo mi permetti cambiare una implementazione trattenendo aspetti degli oggetti che mi interessino. esempio di astrazione √® il quozientamento perch√© in questa operazione trattenevo solamente gli aspetti che mi interessavano buttando via tutto il resto. (il quozientamento non esiste in programmazione per la sua incapacit√† di gestire l\u0026rsquo;infinito)\nEsempio implementazione e astrazione di numeri naturali\nL\u0026rsquo;implementazione posso farla in molti modi, qui ne sono rappresentati due.\nMentre il concetto astratto sono le regole che mi definiscono l\u0026rsquo;ente (in questo caso gli assiomi di peano, il fatto che devo avere uno Zero una successione e l\u0026rsquo;insieme generali dei numeri naturali, un elemento appartiene a questo insieme solamente se √® uguale allo zero oppure √® un successore di un numero di questo insieme. S deve essere iniettiva. E nessun successore √® uguale allo zero).\nEsempio implementazione e astrazione liste di interi\nGeneralizzazione Quindi vorrei che una caratteristica in un caso particolare sia vero anche in molti altri casi!\nBenefici di ci√≤ (4) Struttura algebrica L\u0026rsquo;elemento neutro (generalizzazione di essa) Si una generalizzazione esiste ed √® questa:\nQueste generalizzazioni sono utili nel caso mi creino una teoria utile da studiare dal punto di vista astratto (cos√¨ posso scoprire altre propriet√†).\nSe questa teoria √® utile per comprendere concetti pi√π bassi (dal punto di vista di livelli di astrazione) allora posso dire che queste sono teorie informative.\nDefinizione struttura algebrica Il magma √® il concetto fondamentale per una struttura algebrica come in definizione.\nChiamiamo magma perch√© non √® ancora solidificato, qualcosa di abbastanza astratto. Dopo avere introdotto questi concetti astratti posso studiarle! Posso studiare una cosa che ho creato, mi piace sta scienza, perch√© chi ha creato qualcosa non sa a priori bene cosa ha creato.\nProdotto cartesiano in left unital magma Nell\u0026rsquo;esempio C √® un prodotto cartesiano di R per questo motivo riesco a dirlo da questa generalizzazione!\nMorfismi Il morfismo mi permette di preservare alcune propriet√† che perdo in astrazione\u0026rsquo;s trasformazione (un esempio √® la perdita della struttura di numeri quando lo rappresento con un LUM (Left Unital Magma)\nQuesto concetto √® importante anche in informatica perch√© vuol dire che posso prima applicare la funzione sulla somma di implementazioni oppure applicarli singolarmente.\nIsomorfismo L\u0026rsquo;isomorfismo √® simile a un morfismo a due parti (in cui vale questa relazione in entrambe le parti) quindi funzione bigettiva in cui anche l\u0026rsquo;inverso sia un morfismo. Questa cosa mi dice che esiste una certa corrispondenza fra strutture algebriche.\nEnunciato ed esempio\n","permalink":"https://flecart.github.io/notes/algebra-logica/","summary":"Strutture algebriche Differenza matematica e informatica Una osservazione per quanto riguarda la logica intuizionista √® che sta a met√† fra matematica e informatica perch√© la dimostrazione intuizionista possiede in s√© un algoritmo e una struttura di dati.\nInfatti di solito l\u0026rsquo;informatico scrive senza fare la dimostrazione dell\u0026rsquo;algoritmo mentre il matematico scrive la dimostrazione senza fare l\u0026rsquo;algoritmo (inoltre pu√≤ definire degli enti ed oggetti che non siano rappresentabili come dati in quanto possono essere infiniti.","title":"Algebra Logica"},{"content":"Questo documento √® totalmente concentrato sull\u0026rsquo;analisi del problema della selezione del k-esimo elemento.\n7.1 Introduzione al problema Dato un array di elementi vogliamo cercare di trovare un modo efficiente per selezionare il k-esimo elemento, ossia un elemento che sia maggiore di k-1 elementi\n7.1.1 Note sull\u0026rsquo;utilizzo Questo algoritmo √® utile per esempio per sapere cosa displayare in una pagina di ricerca, perch√© per esempio posso avere blocchi di tanta roba 140k, mentre ovviamente posso selezionare solamente un blocco ristretto.\nEs: mostrare i primi k in ordine di rilevanza!\n7.2 Prime soluzioni Notiamo che possiamo riadattare le soluzioni ai problemi di ordinamento per trovare il k-esimo elemento.\n7.2.1 Selezione del minimo Questo √® un algoritmo che va a modificare il selection sort (utilizzando la stessa idea per creare un subarray crescente).\nSlide\nFaccio k cicli per trovare i k minimi per circa n volte, anche se l\u0026rsquo;analisi esatta √® data da questa sommatoria, che √® qualcosa di simile, ma non esattamente quello.\n$\\sum_{i = n - k + 1} ^{n} i$\n7.2.2 HeapSelect Io utilizzo una heap per trovare i k-esimi minimi, praticamente sto facendo un heap sort, ma con l\u0026rsquo;altra heap, e sto espellendo piccoli elementi uno alla volta..\nSlide\nPiccole note sul costo (funziona se ordini inferiori!)\n7.2.3 QuickSelect Un primo approccio potrebbe essere utile cercare di ordinare l\u0026rsquo;array con questo e prendere il k-esimo elemento.\nPoi noto che posso sfruttare il divide e conquer di qucksort per sapere quanti elementi sono minori di k! ho principalmente 3 casi:\nPseudoalgo mio (molto a parole)\nho esattamente k - 1 elementi minori di x nel primo insieme dopo il partition, quindi ritorno x.\nHo meno elementi di k - 1 minori di x dopo il partition, quindi vado a cercare il k esimo in questo insieme qui.\nHo pi√π elementi di k - 1 minori di x dopo il partition, vado a cercare l\u0026rsquo;offset corretto nell\u0026rsquo;altro insieme.\nPseudocodice di slide\nPseudocodice bandiera nazionale che serve qui\nAnalisi nel caso ottimo e pessimo (e medio)\nL\u0026rsquo;ottimo e pessimo √® abbastanza facile perch√© si riconduce esattamente all\u0026rsquo;analisi di quicksort\nIn pratica O(n) nel caso migliore (perch√© ora ho una chiamata ricorsiva in meno)\nO(n2) nel caso peggiore perch√© √® identico a quicksort.\nIl caso medio √® un p√≤ pi√π difficile da analizzare, dimostreremo che √® in O(n). vediamo perch√©\nAnalisi medio\nSupponiamo che scegliamo sempre la partizione sfavorevole (quindi da n/2 a n), allora la relazione di ricorrenza (supponendo distribuzione uniforme semplice di queste possibilit√†) ho\nPosso dimostrare utilizzando la sostituzione questo. fine\n8 Priority-Queue √à di solito implementata con la Heap. Iniziamo a fare una descrizione di questa strututra\nAltre implementazioni che per√≤ non sono richieste ma interessanti\nBinomial Heap fibo-heap 8.1 Introduzione Questa struttura di dati sar√† utile in seguito per algoritmi di grafi come Dijstra o Prim per il MST.\nQuesta struttura come la Heap (anche fattibile con fibo-heap o heap binomiali!), manterr√† il minimo, non √® esattamente FIFO o LIFO come stack e queue\n8.1.1 Interfaccia della struttura Insertion (log n) Deletion (log n) Creation (n) Slide delle operazioni\n8.1.2 Esempi di utilizzi Base per altri algoritmi (come Dijstra o Prim) Processing di pacchetti per il routing Qualunque posto in cui c\u0026rsquo;√® bisogno di processare secondo un certo ordine 8.2 D-heap La differena con la heap normale √® che questo √® un albero che abbia d-rami.\nSlide di descrizione\n8.2.1 Altezza e Memorizzazione Lemma altezza della heap\nQuesta dimostrazione sull\u0026rsquo;altezza dell\u0026rsquo;heap √® molto simile a tutti gli alberi binari. Come gli alberi binari possiamo memorizzarli facendo un offset sulla cella attuale!\nMemorizzazione della d-heap\nOperazioni helper importanti:\nSono molto utilizzate per le operazioni di delete, insertion e simili.\nMuovi alto e muovi basso\n8.2.2 Sunto dei costi e note L\u0026rsquo;unica operazione che pu√≤ essere complessa √® la deletion, in cui bisogna contemplare anche il bubble up (viene eseguito solo una volta questa oppure bubble down).\nRiassunto in slide\n9 Union-Find 9.1 Introduzione Questa struttura di dati ci sar√† utile per gestire insiemi disgiunti\n9.1.1 Interfaccia della struttura Vedere se due elementi appartengono allo stesso insieme trovare il rappresentante Unire degli insiemi Slide interfaccia\nOgni insieme √® indicato da uno e un solo rappresentante, un suo elemento che fa finta di essere l\u0026rsquo;insieme stesso. Questa √® l\u0026rsquo;idea pi√π importante per comprendere la rappresentazione di questa struttura di dati.\n9.1.2 Intuizione sull‚Äôutilizzo Ho un insieme di ingredienti che siano tutti separati, vorrei unirli con magari un certo ordine, creando delle nuove cose. E continuare a vedere se li ho gi√† uniti o meno.\nAlla fine vedo l\u0026rsquo;unione degli elementi in questo modo\nEsempio di problema risolto con DSU\nSlide possibili implementazione (trattati subito dopo\n9.2 QuickFind Find in tempo costante e union in tempo lineare (possibile ammortizzare a tempo costante) 9.2.1 Metodi di rappresentazione (only lista) Un insieme √® rappresentato tramite un albero di altezza UNO.\nQuesto √® possibile tramite una lista concatenata, in cui ogni nodo punta sempre al nodo rappresentante.\nSlide rappresentazione tramite liste\nCi aggiungo io che si pu√≤ utilizzare anche un semplice array e l\u0026rsquo;index come un pointer per creare tale struttura.\n9.2.2 Union e sunto delle operazioni L\u0026rsquo;union di due insiemi √® una sovrascrittura del pointer del rappresentante dell\u0026rsquo;insieme che viene unito, come si pu√≤ intuire nell\u0026rsquo;esempio di union.\nIl find √® immediato, perch√© deve risalire di solamente un arco.\nEsempio di operazione di union\nRiassunto delle operazioni\n9.2.3 Euristica del peso (!!) Voglio cercare di limitare il tempo di unione di due insiemi.\nL\u0026rsquo;idea √® unire l\u0026rsquo;insieme con meno figli a quello con di pi√π. mi mantengo questa informazione sulla radice dell\u0026rsquo;albero.\nSlide dell\u0026rsquo;idea\nCosto di Union\nIl tempo resta lineare, per√≤ √® almeno dimezzato l\u0026rsquo;upper bound del tempo necessario per fare questa operazione.\nCosto ammortizzato\nPosso osservare che per la propriet√† sopra, se una foglia cambia radice l\u0026rsquo;insieme di arrivo √® grande almeno il doppio dell\u0026rsquo;insieme precedente, questa propriet√† mi permette di concludere che al massimo posso swappare log n volte.\nQuesto ragionamento mi permette di concludere un costo ammortizzato per questa operazione di union\nAnalisi union ammortizzato\nNotiamo che al massimo, in una union, $n/2$ elementi possono cambiare parente Quindi il caso pessimo di union in questo modo resta in $O(n)$, ma possiamo fare di meglio.\nNota: dopo n - 1 union, sto facendo union con se stesso, che non ha senso, quindi resto con n - 1, che √® il caso pessimo d union).\n9.3 QuickUnion √à una altra rappresentazione dell\u0026rsquo;union find, in cui √® presente una foresta (uguale alla precedente, ma in questo caso posso avere anche altezza superiore a 1!)\n9.3.1 Introduzione alla struttura e implementazione (array) Slide sulla struttura\nSlide di rappresentazione dell\u0026rsquo;array\nSi utilizza il parent vector!\n9.3.2 Find e sunto delle operazioni Per union basta infatti prendere la radice del primo insieme e farla puntare alla radice dell\u0026rsquo;insieme in cui si vuole unire, invece che farlo puntare a s√© stesso (fa questa ultima cosa perch√© era la radice)\nSlide di riassunto\n9.3.3 Euristica del rank (!!) Voglio cercare di limitare il tempo di ricerca del rappresentante. L\u0026rsquo;idea √® nel momento di fare l\u0026rsquo;union, lo faccio scegliendo di unire l\u0026rsquo;elemento con rank minore (ovvero con altezza dell\u0026rsquo;albero minore) con quello maggiore.\nAnalisi caso pessimo\nUpper bound rank di x (dim)\nLa dimostrazione √® abbastanza noiosa, basta che tengo in considerazione i tre casi: quando rank(a) = rank(b), quando √® minore, e quando √® maggiore, sapendo l\u0026rsquo;ipotesi induttiva, non dovrebbe essere tanto difficile concludere quanto voluto.\n(se ho una limitazione superiore all\u0026rsquo;altezza dell\u0026rsquo;albero allora √® chiaro che il find √® in log n.\nIn questo modo riesco proprio a creare un upper bound logaritmico al find, a differenza del costo ammortizzato di questo con l\u0026rsquo;euristica del peso in quickfind.\n","permalink":"https://flecart.github.io/notes/k-esimo-priority-q-dsu/","summary":"Questo documento √® totalmente concentrato sull\u0026rsquo;analisi del problema della selezione del k-esimo elemento.\n7.1 Introduzione al problema Dato un array di elementi vogliamo cercare di trovare un modo efficiente per selezionare il k-esimo elemento, ossia un elemento che sia maggiore di k-1 elementi\n7.1.1 Note sull\u0026rsquo;utilizzo Questo algoritmo √® utile per esempio per sapere cosa displayare in una pagina di ricerca, perch√© per esempio posso avere blocchi di tanta roba 140k, mentre ovviamente posso selezionare solamente un blocco ristretto.","title":"k-esimo priority-q DSU"},{"content":"Log Linear Models can be considered the most basic model used in natural languages. The main idea is to try to model the correlations of our data, or how the posterior $p(y \\mid x)$ varies, where $x$ is our single data point features and $y$ are the labels of interest. This is a form of generalization because contextualized events (x, y) with similar descriptions tend to have similar probabilities.\nThese kinds of models are so common that it has been discovered in many fields (and thus assuming different names): some of the most famous are Gibbs distributions, undirected graphical models, Markov Random Fields or Conditional Random Fields, exponential models, and (regularized) maximum entropy models. Special cases include logistic regression and Boltzmann machines.\nIntroduction to log linear models Counting: first approach A very easy model estimating $P(y \\mid x)$ is just taking the count, and assuming they are independent, so the value is $\\frac{\\text{count}(x, y)}{\\text{ count}(x)}$. But it\u0026rsquo;s easy to see what problems are we getting with this simple model: So we have two main drawbacks, described in the image.\nExponentiation It\u0026rsquo;s easy to define a score function and exponentiate that. This leads to a famous relation $$ p(y \\mid x) \\propto \\exp \\text{ score } (x, y) $$ We now define a function $f$ that attempts to extract features from the input. We assume at the beginning we have $K$ features, then the linear scoring function should be $$ \\exp \\text{ score}(x, y) = \\exp \\sum_{k = 1}^{K} (\\theta_{k} \\cdot f_{k}(x, y)) $$ We notice that the argument for the exp is always positive. At the current moment I do not understand why is this a property that we want. We would like to normalize our exponential function, so that we have a probability. We then introduce this value: $Z = \\sum_{y \\in Y} p(y \\mid x)$. This part is usually difficult to compute, it runs in$\\mathcal{O(\\lvert y \\rvert)}$ time.\nFor this reason sometimes is often easier to use logs, in this case we have that $$ \\log p(y \\mid x) = \\sum_{k = 1}^{K} (\\theta_{k} \\cdot f_{k}(x, y)) - \\log Z = \\vec{\\theta} \\cdot \\vec{f}(x, y) - \\log Z $$ Which is a nice form.\nFeature pipeline The preprocessing steps Historically, the features were hand-engineered, meaning people would try to extract functions after a step of preprocessing the text. the preprocessing step consisted in steps like\nTokenization Lower casing stemming (getting the root of the words) Stop word removal Reducing vocabulary. Here is an example: And then the input would be easy enough to be dealt with the log-linear method and the features. Feature engineering After we have preprocessed the texts, how can we define the features? There are some classical methods: N-grams\n(BOS, BOS, UNK), (BOS, UNK, ‚Äòs), \u0026hellip;, (complete, broke, ! One-hot encoding (0, 0, 1, 0, ..) for a single word. Bag-of-words (see spam classification) (0, 1, 0, 2, \u0026hellip;), we don\u0026rsquo;t care about the order of the words, just if they are present or not in the text. Word embeddings Convert words into continuous representations Can be contextual (e.g., ELMo, BERT) or not (e.g., Glove, fastText) More on this in future lectures! Bag-of-embeddings Average embeddings for all words in a sequence Domain-specific features (for example if we know we want to agree the gender of an adjective, this feature could be built-in!) After we have defined this, we use MLE to minimize the loss. In the case of log linear models, it is a convex function, so we have that the local minima is also the global minima, and it\u0026rsquo;s a easy problem to solve.\nWith the new approach, features are designed automatically with neural networks.\nExpectation matching Recall that the whole loss can be written as: $$ \\mathcal{L}(\\theta) = \\sum_{n = 1}^{N} \\vec{\\theta} \\cdot \\vec{f}(x_{n} , y_{n}) - \\sum_{n = 1}^{N} \\log\\sum_{y' \\in \\mathcal{Y}} p(y' \\mid x_{n} ; \\vec{\\theta}) $$ And that $p(y \\mid x) = \\exp(\\vec{\\theta} \\cdot \\vec{f}(x, y))$.\nThe only difficult derivative that we may find here is this: $$ \\frac{ \\partial }{ \\partial \\theta_{k} } \\log \\sum_{y \\in \\mathcal{Y}} \\exp(\\vec{\\theta} \\cdot \\vec{f} (x, y)) = \\frac{\\left( \\frac{ \\partial }{ \\partial \\theta_{k} } \\sum_{y \\in \\mathcal{Y}} \\exp(\\vec{\\theta} \\cdot \\vec{f} (x, y)) \\right)}{\\sum_{y \\in \\mathcal{Y}} \\exp(\\vec{\\theta} \\cdot \\vec{f} (x, y))} = \\frac{ f_{k}(x, y) \\sum_{y \\in \\mathcal{Y}} \\exp(\\vec{\\theta} \\cdot \\vec{f}(x, y))}{\\sum_{y \\in \\mathcal{Y}} p(y \\mid x) } $$ We observe that the denominator simplifies to 1 and the numerator is $f_{k}(x, y) \\sum_{y \\in \\mathcal{Y}} p(y \\mid x)$ which ends our quick derivation.\nThen we can write the derivatives explicitly $$ \\frac{ \\partial \\mathcal{L}(\\theta) }{ \\partial \\theta_{k} } = \\sum_{n = 1}^{N} f_{k}(x_{n}, y_{n}) - \\sum_{n = 1}^{N} \\sum_{y' \\in \\mathcal{Y}} p(y' \\mid x_{n}; \\theta) f_{k}(x_{n}, y') $$ The first part are the counts while the second part is the normalizer contribution. At the minimum we have that the above two are equal, because the derivative is zero. This is called expectation matching. (Berger 1996).\nIf we have Softmax Function for the loss it\u0026rsquo;s easy to explicitly write the gradient:\n$$ \\frac{ \\partial \\log \\text{ softmax}(\\vec{h}, y) }{ \\partial \\vec{\\theta} } = f(x, y) - \\sum_{y \\in \\mathcal{Y}} \\text{ softmax }(\\vec{h}, y) f(x, y) $$ The derivation is left as exercise.\nLearning Notes People at Johns Hopkins University have done something quite nice to learn log linear models, check it out here. There are also some formulas here\nThis is another resource, more math heavy, for understanding log linear models in NLP. See here.\n","permalink":"https://flecart.github.io/notes/log-linear-models/","summary":"Log Linear Models can be considered the most basic model used in natural languages. The main idea is to try to model the correlations of our data, or how the posterior $p(y \\mid x)$ varies, where $x$ is our single data point features and $y$ are the labels of interest. This is a form of generalization because contextualized events (x, y) with similar descriptions tend to have similar probabilities.\nThese kinds of models are so common that it has been discovered in many fields (and thus assuming different names): some of the most famous are Gibbs distributions, undirected graphical models, Markov Random Fields or Conditional Random Fields, exponential models, and (regularized) maximum entropy models.","title":"Log Linear Models"},{"content":"ora abbiamo alcune primitive per passarci i messaggi, vogliamo creare metodo in modo che i processi si possano sincronizzare mandando messaggi.\nla memoria √® sempre privata.\nPrimitive Send e receive üü© Send\nSpedizione del messaggio input deve avere un identificato al processo su cui spedire. Se si vuole espandere si possono avere multicast e broadcasting ma non li studieremo in questo corso.\nReceive\nRicevi messaggi\nTassonomia dei message passing (!)üü© Slide\nSincrono\nIn questo caso entrambi send e receive sono bloccanti, quindi non possono andare avanti finch√© non √® mandato e finch√© non √® ricevuto!\nAsincrono\nSimile al precedente, solo che il send non aspetta che il ricevente prenda il messaggio!\nNOTA: non si aspetta che il receiver riceva il messaggio!\nCompletamente asincrono\nnessuno di due aspetta, il receive se nessuno ha inviato non riceve niente!\nThoth proponeva 3, reply receive send, principalmente solo la reply √® bloccante.\npi√π o meno tutti gli autori avevano una sintassi diversa per il message passing\nEquivalenza fra sincrono asincrono Si pu√≤ vedere che questi due metodi si possono rivelare equivalenti\nSincrono dato quello asincrono üü© Slide\nPer bloccare il asendodevo fare un areceive per un ack, cos√¨ lo blocco\nNOTA: ed √® esattamente questo, un ack aggiuntivo che hai fatto all‚Äôesame che ti ha fatto perdere tipo 2 punti, stai attento!\nAsincrono dato quello sincrono üü©- Slide\nSi vede che il sincrono non √® espressivo tanto l‚Äôasincrono perch√© abbiamo bisogno di far uso di un altro processo server.\nProblemi classici üü® Filosofi a cena Slide\nBasta ricordarsi di fare anche il filosofo mancino e poi siamo apposto! Sarebbe poi la stessa soluzione proposta in Semafori\nProducer consumer Slide\n","permalink":"https://flecart.github.io/notes/message-passing/","summary":"ora abbiamo alcune primitive per passarci i messaggi, vogliamo creare metodo in modo che i processi si possano sincronizzare mandando messaggi.\nla memoria √® sempre privata.\nPrimitive Send e receive üü© Send\nSpedizione del messaggio input deve avere un identificato al processo su cui spedire. Se si vuole espandere si possono avere multicast e broadcasting ma non li studieremo in questo corso.\nReceive\nRicevi messaggi\nTassonomia dei message passing (!)üü© Slide","title":"Message Passing"},{"content":"First time we talked about this was in Sicurezza delle reti#Protocollo SSL But that was a simple toy model.\nSecure Socket Layer Secure socket Layer and TLS add security (see security principles in Theoretical Notions of Security) on the transport layers, whereas IPSec protocol adds it to the network level. So this works on a higher level of abstraction following the ISO OSI framework Architettura e livelli 1, 2#Livelli ISO/OSI.\nSSL is the old version of the TLS protocol. This provides integrity and confidentiality to the communication, see Theoretical Notions of Security. The main difference of SSL and TLS is that this has vulnerabilities like POODLE attack\nPrinciples Session It\u0026rsquo;s an association (probably something similar to SA in Sicurezza delle reti). That connects the client to the server. Defines the cryptographic parameters to allow the communication.\nStuff for session:\nSession identifier: generated by the server to identify an active or resumable session. Peer certificate: X 509v3 certificate. Compression method: algorithm used to compress the data before encryption. Cipher spec: encryption and hash algorithm, including hash size. Master secret: 48 byte secret shared between the client and server. Is resumable: indicates if the session can be used to initiate new connections. The main takeaways, similarly to what is done for SA, is that the session keeps identifying parameters and security parameters for the communication.\nConnection The same session can have more connections.\nServer¬†and¬†client:¬†random chosen¬†for¬†each¬†connection. Server write MAC secret: shared key used to computeMAC on¬†data¬†sent¬†by the¬†server. Client¬†writes¬†MAC¬†secret:¬†same¬†as¬†above¬†for¬†the¬†clientServer¬†write¬†key:¬†shared¬†key¬†used¬†by¬†encryption¬†whenserver¬†sends¬†data. Client¬†writes¬†key:¬†same¬†as¬†above¬†for¬†the¬†client.Initialization¬†vector:¬†initialization¬†vectors¬†required¬†byencryption.\nSequence¬†numbers:¬†both¬†server¬†and¬†client¬†maintain such¬†a¬†counter¬†to¬†prevent¬†replay,¬†cycle¬†is $2^{64} - 1$\nThe SSL record Alerts They are two bytes used for error/warning information.\nTLS handshake protocol TLS stands for Transport Layer Security, it provides CIA (See Theoretical Notions of Security) guaranties at the process level, not at the host or gateway level as IPSec does.\nThis works at the process layer to ensure security from the protocol perspective. It\u0026rsquo;s more granular because it is out of the ISO/OSI stack.\nProperties Two of the tree principles in Theoretical Notions of Security are done with this. Integrity and Confidentiality. Auth is implemented at the application layer.\nExchange of keys It\u0026rsquo;s important, TLS uses a symmetric key to communicate after communication is established. Another diagram that better specifies the encryption of the messages Exchange protocol Just use common exchange protocols!\nDiffie Hellman RSA And variations are some examples\nAuthenticity of certificates CA\u0026rsquo;s are used to exchange the security keys securely. This is the default, historically there have been some attacks on this method\nOther options could be just self sign the certificate and exchange that signed thing (needs other things, like manual operations to validate and trust it).\nValidation of the Certificates During the negotiation of the keys, a certificate is needed. Within this certificate are present some information about\nIssuer CA Issuing and expiration date. Public key, and who can use this cert Where it can be verified Where to look for if it has been revoked. These certificates build a chain of certification, which should be validated by the client before connecting.\nDomain Validation and extended validation: issuer makes different checks. With the former only the domain is validated (it is issued if the domain is owned), with the latter also organization or company is validated. So the main difference between the two is the cost of issuing a certificate. This is checked with the policy number on the certificate.\nRevocation of the certificatesüü®+ Hosts should check if the certificate is still valid or not. If a certificate has been revoked, it should be listed in a certificate revocation list on a site. You should check a serial number in the certificate. If this is present on the site then it is revoked.\nBut there is a more recent protocol, the OCSP (online certificate status protocol) that has an api style for checking the revocation. In this way the client doesn\u0026rsquo;t need to download the whole CRL.\nAttacks on TLS CA trustworthiness See verisign 2001 to Microsoft, Comodo hack, DigiNotar, TrustWave\nUsage of weak ciphers During the negotiation, some weak cipher could be chosen, this makes the communication easier to break. (AKA using RC4 or MD5).\nProtocol Attacks Renegotiate with NULL algorithm (lol!) Downgrade TSL version to a vulnerable one, or force usage of insecure ciphers. Man in the middle You need to stole a valid certificate, then you can put yourself in the middle of the communication with the user.\nUsually the main defense against this type of attack is certificate pinning.\nHearthbeat Some package sent to keep the communication on between idle times. Some firewalls for example could kill the connection if no package is sent. The response is a echo and random strings.\n","permalink":"https://flecart.github.io/notes/tls-ssl-protocol/","summary":"First time we talked about this was in Sicurezza delle reti#Protocollo SSL But that was a simple toy model.\nSecure Socket Layer Secure socket Layer and TLS add security (see security principles in Theoretical Notions of Security) on the transport layers, whereas IPSec protocol adds it to the network level. So this works on a higher level of abstraction following the ISO OSI framework Architettura e livelli 1, 2#Livelli ISO/OSI.","title":"TLS-SSL protocol"},{"content":"Omnidirezionali Antenne omnidirezionali üü© Slides antenne omnidirezionali\nIl senso di omnidirezionale √® in tutte le direzioni dell\u0026rsquo;antenna (nota: non √® isotropico, perch√© non √® da un singolo punto).\nin passato era importante andare a guardare la direzione per trovare la polarizzazione migliore. Praticamente irradia a 360 gradi sul piano permedicolare all‚Äôantenna.\nEsempio pattern di radiazione\nQuesto genere di antenne sono irrealizzabili la pi√π simile √® la antenna dipolo dipolo, ma comunque non rispetta le antenne in questo verso diciamo. ricorda i dBi che abbiamo citato in Fisica del Wireless.\nGuadagno passivo in ominidirezionali üü© Slide guadagno passivo\nSi pu√≤ concentrare l\u0026rsquo;energia nella shape del dipolo. Per esempio se lo faccio pi√π schiacciato, ho un range molto pi√π forte orizzontalmente, ma appena su o appena gi√π perdo segnale.\nMentre al contrario, se ho una forma pi√π arrotondata ho segnale solo se gli sto vicino, ma molta meno importanza stare sopra o sotto.\nEsempio del guadagno passivo e attivo delle antenne\nNOTA: posso avere un guadagno fino a 10 Db quindi 10 volte tanto.\nEd √® anche per questo motivo che andiamo a misurare l‚ÄôEIRP e non la potenza che finisce nell‚Äôantenna, anche chiamata Intentional radiator Power output.\nPOSIZIONAMENTO DELL ANTENNE\nAndiamo a chiederci in che modo mettere le antenne in modo che pi√π utenti possibili possano usufruire del segnale.\nUna soluzione potrebbe essere inclinare l‚Äôantenna:\nSlide inclinazione dell‚Äôantenna\nAntenna semidirezionale Semidirezionale (3) üü© Questi sono i pi√π comuni, sparano principalmente energia di fronte (quindi metterllo su un muro √® cosa buona).\nEsempi di antenne omnidirezionali\nDi solito si mettono nel muro (sono panel o patch, che praticamente cambiano di costruzione, ma alla fine hanno la stessa funzione ).\nMentre gli yagi sono sparati nella direzione in cui punta (e mirano alla posizione del ripetitore, perch√© da l√¨ ricevono meglio.\nbeam width (!!!) √® un valore che √® espresso in angoli, e misura quando largo o concentrato il segnale, √® lo spazio necessario per dimezzare il segnale, partendo dall\u0026rsquo;asse di direzione. Questa concezione ci serve per parlare di antenne altamente concentrate.\nHighly-directional antennas üü©- Slide esempio highly dir\nEsempi sono grid e parabolic dish che perdono energia attorno molto molto velocemente, per√≤ se sei nel beam width lo ricevi molto bene (va lontano si possono utilizzare per antenne lungo raggio come satelliti).\nPotrei anche s.ettorializzare la trasmissione: ogni antenna si prende solamente un certo angolo\nLine of Sight ossia la linea raggio dritta fra trasmissione e ricevitore.\nFresnel zone üü©‚Äî Definiamo al centro della line of size come la zona di fresnel, sarebbe meglio metterlo libera da ostacoli. Si concentrano il massimo numero di onde additive quindi se c‚Äô√® qualcosa mi toglie molto.\nSlide zona di fresnel\nSe √® pi√π di 20 percento occupata, allora √® meglio andare sugli ostacoli (altrimenti non ottengo maggiore ricezione, continuo a perdere energia negli ostacoli e ho inquinamento dei raggi).\nSe non √® ostruita sto permettendo l‚Äôenergia ad arrivare con massima efficienza al ricevitore.\nNOTA: la distanza √® dipendente solo da frequenza e distanza\nfresnel e curvatura terrestre\nSettorializzazione di antenne direzionale (boh) üü• Si parla di multiplexing spaziale perch√© possiamo andare ad utilizzare lo stesso canale, ma in zone diverse perch√© il segnale √® concentrato solamente in quella direzione.\nAzimuth and elevation charts üü© Slide azimuth and elevation charts\nQuesto grafico √® utilizzato per guardare in ogni angolo dell\u0026rsquo;antenna, quanto √® l‚Äôenergia che viene trasmessa.\nMentre azimuth gira in orizzontale (quindi visuale dall‚Äôalto), elevation gira in modo verticale (quindi visuale da terra diciamo).\nInoltre √® importante dislocare le antenne in posizioni sparse. Cos√¨ se ricevo un segnale posso provare a ricavare il segnale originale provando a buttare via il noise. Di questa parte si potrebbe ricollegare allo space multiplexing citato in Tecnologia Wireless\nSe li metto a lambda mezzi, allora almeno una delle due antenne prendono un segnale buono, l‚Äôaltra potrebbe essere in opposizione (mi sembra comunque un sacco di fisica che ignoriamo qui).\nSotto serve un controllore che riesca ad annullare e scegliere i segnali o gli sfasamenti o annullamenti. (questo controllore dovrebbe rifasare il segnale e rendere il segnale additivo.\nSlide antenna diversity\nBeam forming\nAvendo queste antenne, io riesco a creare un raggio RF, ritardando in modo opportuno certi piatti, e posso mandarlo dove mi pare. (controllo sulla direzione, solamente ritardando le fasi di certe antenne).\nPath loss in free space üü®- Slide path loss\nNotiamo che la perdita di segnale dipende dalla frequenza e dalla distanza ‚Üí frequenza alta implica segnale perso pi√π in fretta. 36.6 √® una costante che funziona sulla Terra.\nSi noti che duplicando la distanza, l\u0026rsquo;energia cade 4 volte e questo risultato √® coerente con questo dato.\nPer vedere se -86 dB √® sufficiente bisogna guardare la soglia di ricezione del nostro dispositivo. Se il link budget √® positivo allora si riceve, il nostro obiettivo √® progettare sistemi a link-budget positivi.\nSi noti che non √® necessario che questo link-budget sia positivo, significa che sto consumando un sacco di energia.\nSpreco energia nella trasmissione Disturbo trasmissione di altri Vogliamo il minimo link-budget positivo.\nQuesto si chiama system operative margin o valore operativo del sistema.\nIl margine extra √® chiamato fade margin per resister al path loss, fase, e riflessioni e simili, in generale questo fade margin √® un +10 fino +20\n","permalink":"https://flecart.github.io/notes/antenne/","summary":"Omnidirezionali Antenne omnidirezionali üü© Slides antenne omnidirezionali\nIl senso di omnidirezionale √® in tutte le direzioni dell\u0026rsquo;antenna (nota: non √® isotropico, perch√© non √® da un singolo punto).\nin passato era importante andare a guardare la direzione per trovare la polarizzazione migliore. Praticamente irradia a 360 gradi sul piano permedicolare all‚Äôantenna.\nEsempio pattern di radiazione\nQuesto genere di antenne sono irrealizzabili la pi√π simile √® la antenna dipolo dipolo, ma comunque non rispetta le antenne in questo verso diciamo.","title":"Antenne"},{"content":"This note briefly states and proves one of the most famous inequalities in geometry/analysis.\nTheorem Statement Given $2n$ real numbers (you can see these two also as $n$ dimensional vectors), such as $x_{1}, \\dots, x_{n}$ and $y_{1}, \\dots, y_{n}$ then we have that $$ \\left( \\sum_{i = 1}^{n} x_{i}y_{i} \\right) ^{2} \\leq \\left( \\sum_{i= 1}^{n} x^{2}_{i} \\right) \\left( \\sum_{i = 1}^{n} y^{2}_{i} \\right) $$ In vectorial form we can rewrite this as $$ \\lvert \\langle u, v \\rangle \\rvert ^{2} \\leq \\langle u, u \\rangle \\cdot \\langle v, v \\rangle $$ with $u = \\left( x_{1}, \\dots, x_{n} \\right)$ and $v = \\left( y_{1}, \\dots, y_{n} \\right)$ and the $\\langle \\cdot, \\cdot \\rangle$ operator is the inner product. We have equality if and only if $u$ and $v$ are linearly dependent (this one is easy to prove if seen from the vectorial view).\nThere are many possible proofs, but the easy one is just doing the counts:\nProof: direct counts This is the most stupid proof possible, just expand every possible count!\nFrom the hypothesis, we have that\n$$ \\sum_{i = 1}^{n}(x^{2}_{i}y^{2}_{i}) + \\sum_{i \\neq j}^{n} (x_{i}y_{i}x_{j}y_{j}) \\leq \\sum_{i = 1}^{n}(x^{2}_{i}y^{2}_{i}) + \\sum_{i \\neq j}^{n} (x_{i}^{2}y^{2}_{j}) $$ So now we just need to compare this: $$ \\sum_{i \\neq j}^{n} (x_{i}y_{i}x_{j}y_{j}) = 2\\sum_{i \u003c j}^{n} (x_{i}y_{i}x_{j}y_{j}) \\leq^{?} \\sum_{i \\neq j}^{n} (x_{i}^{2}y^{2}_{j}) $$ Now, if we take $i \u003c j$ as we want, we notice that $$ \\left( x_{i}y_{j} - x_{j}y_{i} \\right) ^{2} \\geq 0 \\implies x^{2}_{i}y^{2}_{j} + x^{2}_{j}y^{2}_{i} - 2x_{i}y_{i}x_{j}y_{j} \\geq 0 \\implies x^{2}_{i}y^{2}_{j} + x^{2}_{j}y^{2}_{i} \\geq 2x_{i}y_{i}x_{j}y_{j} $$ And when you sum up for all the couples $(i, j)$ you get the above inequality. This also tells you why it\u0026rsquo;s easy to check if $x_{i} = \\lambda y_{i}$ for some $\\lambda \\in \\mathbb{R}$ then the above sum is 0, so we have equality.\nDrawback: this proof works only on a specific inner product, general proof shouldn\u0026rsquo;t assume something about the product, but you get the gist of why it does work in this case anyway.\nProof: general approach Let\u0026rsquo;s consider the function $f(t) = \\lVert u - tv \\rVert^{2}$, we observe that $\\forall t \\in \\mathbb{R}$ we have that $f(t) \\geq 0$. Now let\u0026rsquo;s expand this product\n$$ f(t) = \\langle u - tv, u - tv \\rangle = \\langle u, u \\rangle - 2t \\langle u, v \\rangle + t^{2} \\langle v, v \\rangle = t^{2} \\lVert v^{2} \\rVert - 2 \\langle u, v \\rangle t + \\lVert u^{2} \\rVert $$ Now we use high school knowledge, as the function is always non-negative and it\u0026rsquo;s a simple $\\mathbb{R} \\to \\mathbb{R}$ function, we know that the discriminant should be non-positive, which means $b^{2} - 4ac \\leq 0$, let\u0026rsquo;s impose this condition on the function and we\u0026rsquo;ll have that:\n$$ 4\\lvert \\langle u, v \\rangle \\rvert ^{2} - 4 \\lVert v^{2} \\rVert \\lVert u^{2} \\rVert \\leq 0 \\implies \\lvert \\langle u, v \\rangle \\rvert ^{2} \\leq \\langle u, u \\rangle \\cdot \\langle v, v \\rangle $$ Which ends the proof $\\square$.\nApplications In this section I would like to list some known applications of this inequality. The inequality is a classical one, so one should expect many applications. I will try to expand this section when I see some during my studies.\nCovariance-Variance relations This is useful for the Rao-Cramer bound, studied in Parametric Models for example. Cauchy-Schwarz gives us an easy easy way to prove that given two random variables $X, Y$ then the following is true: $$ Cov(X, Y)^{2} \\leq Var(X) Var(Y) $$ This bound is usually used to calculate the correlation coefficient which is $$\\rho_{X, Y} = \\frac{Cov(X, Y)}{\\sqrt{ Var(X) Var(Y) }}$$ Proof: We can apply Cauchy-Schwarz in the context of expectation to get that $$\\mathbb{E}_{x, y}[XY]^{2} \\leq \\mathbb{E}_{x}[X^{2}]\\mathbb{E}_{y}[Y^{2}]$$ In order to apply this, you just need to see that the expectation operator can be viewed as a inner product on the space of random variables, so let\u0026rsquo;s prove this first: Let\u0026rsquo;s consider a probability space $(\\Omega, \\mathcal{F}, \\mathbb{P})$ with $\\Omega$ the sample space, $\\mathcal{F}$ the sigma algebra and $\\mathbb{P}$ the probability measure on this space, let\u0026rsquo;s also define $X, Y$ to be random variables, i.e. functions from $\\Omega$ to $\\mathbb{R}$. In order to prove that the expectation operator is a inner product we need to check three conditions:\nLinearity Symmetry Positive definiteness They should be all trivial to verify, so we move on. Now that we have this link, it\u0026rsquo;s easy to prove the original construct with covariance and variance: we just need to substitute the correct variables.\n","permalink":"https://flecart.github.io/notes/cauchy-schwarz-inequality/","summary":"This note briefly states and proves one of the most famous inequalities in geometry/analysis.\nTheorem Statement Given $2n$ real numbers (you can see these two also as $n$ dimensional vectors), such as $x_{1}, \\dots, x_{n}$ and $y_{1}, \\dots, y_{n}$ then we have that $$ \\left( \\sum_{i = 1}^{n} x_{i}y_{i} \\right) ^{2} \\leq \\left( \\sum_{i= 1}^{n} x^{2}_{i} \\right) \\left( \\sum_{i = 1}^{n} y^{2}_{i} \\right) $$ In vectorial form we can rewrite this as $$ \\lvert \\langle u, v \\rangle \\rvert ^{2} \\leq \\langle u, u \\rangle \\cdot \\langle v, v \\rangle $$ with $u = \\left( x_{1}, \\dots, x_{n} \\right)$ and $v = \\left( y_{1}, \\dots, y_{n} \\right)$ and the $\\langle \\cdot, \\cdot \\rangle$ operator is the inner product.","title":"Cauchy-Schwarz Inequality"},{"content":"Introduzione Vogliamo tenere in modo sincronizzato alcune macchine, questo √® il nostro obiettivo. Questo √® un problema abbastanza difficile‚Ä¶ Come tenere in sync se ci sono alcuni nodi maligni o la rete che non √® bona?\nAssunzioni principali (2) Esiste internet Esiste Crittografia Queste sono le assunzioni che non saranno mai rilassate per l‚Äôintero corso, diciamo che sono la nostra base su cui possiamo andare a costruire la base per il nostro studio.\nDigital signature scheme Vorremmo avere un sistema per firmare alcuni documenti online, e possiamo dividere questa cosa in tre passi fondamentali\nQuesta roba esiste da molto tempo, dagli anni 80 o prima.\nAlgoritmi per digital signature Una cosa importante √® che questi algoritmi di signature sono efficienti.\nGenerazione della chiave Deve essere nella forma $s \\to (pk, sk)$, ossia seed per public e secret key.\nFirma con la chiave Dovr√† essere una funzione nella forma $msg + sk \\to msg + sig$. Da notare √® che la signature √® dipendente dal contenuto. Ma non possiamo utilizzarlo in questi ambienti elettronici perch√© √® troppo facile copiare ed incollare una forma. Deve essere per forza che dipenda\nDall\u0026rsquo;identit√† di chi firma Da cosa vuole dire il firmatario. Verifica della chiave $msg + sig + pk \\to bool$, per capire se questa firma √® valida o meno, deve solamente dirmi questo valore booleano. In particolare la chiave √® pubblica quindi ognuno pu√≤ venire a verificare un messaggio, ma pu√≤ firmare solamente chi possiede la chiave privata.\nSicurezza (3 assunzioni) L‚Äôassunzione principale della sicurezza delle firme digitali √®\nIdeal signatures: Se non conosci la chiave privata ‚áí non posso mai generare la coppia msg + sig corretta\nDelle volte √® possibile rompere questa cosa (e.g. con brute force se ci metto abbastanza poco per farlo). Per√≤ noi assumeremo che valga questo. E ha bisogno di risorse infinite per poter usare bruteforce tutto se ha solamente quello come unica soluzione. Quindi una altra assunzione √® che l‚Äôavversario ha risorse finite, polinomiali.\nAssunzione di complessit√† vogliamo che non ci siano algoritmi efficienti per risolvere qualcosa in modo molto veloce\nThe State Machine Replication (SMR) Problem Intuizione al problema Prendiamo uno state machine, in modo simile a quanto fatto in Grammatiche Regolari, che ad ogni input e output cambia lo stato interno. Uno state machine pu√≤ essere un database, ma pu√≤ essere anche tutto l‚Äôambiente delle blockchain (e.g. mandare currency cambia lo stato) o un Automi e Regexp.\nLa replica √® necessaria per la performance, in modo che ci siano pi√π macchine uguali che rendano lo stesso servizio. Ma se ho tante macchine che fanno la stessa cosa, devo in qualche modo farci il sync, ed ecco il problema che nasce dai database, il problema dei sync write e read. Per noi la replicazione √® lo stato della macchina gigante della blockchain.\nNel contesto di blockchain\nAvremo una lista di transazioni, che sono niente altro che delle richieste a un certo nodo di fare qualcosa, e si registra la storia delle transazioni, √® molto importate che l‚Äôordine sia consistente. Il problema del consenso diventa quindi provare a sincronizzare la transazioni, che nota, non devo essere money! Basta richieste.\nConsistency Questa √® la propriet√† che tutti i nodi sono d‚Äôaccordo sulla storia, permettendo la possibilit√† che qualche nodo sia indietro (ma devono essere d‚Äôaccordo su quella parte comune!)\nLiveness e Safety Queste sono le stesse propriet√† descritte in Programmi Concorrenti. Con la liveness vogliamo che non ci siano deadlocks, e blocchi con la stessa logica ‚Üí alla fine il nodo dovr√† essere aggiunto!\n","permalink":"https://flecart.github.io/notes/consensus-protocols/","summary":"Introduzione Vogliamo tenere in modo sincronizzato alcune macchine, questo √® il nostro obiettivo. Questo √® un problema abbastanza difficile‚Ä¶ Come tenere in sync se ci sono alcuni nodi maligni o la rete che non √® bona?\nAssunzioni principali (2) Esiste internet Esiste Crittografia Queste sono le assunzioni che non saranno mai rilassate per l‚Äôintero corso, diciamo che sono la nostra base su cui possiamo andare a costruire la base per il nostro studio.","title":"Consensus protocols"},{"content":"Questo problema √® stato trattato in modo un po\u0026rsquo; pi√π semplificato (nel caso in cui la carica era esattamente a met√† in Campo elettrico#Dipolo elettrico). Questo problema √® stato storico, utilizzato per analizzare l\u0026rsquo;atomo.\nPotenziale del dipolo elettrico üü©\u0026ndash; Per il principio di sovrapposizione possiamo affermare che $$ V(P) = V_{r^{+}} + V_{r^{-}} = \\frac{q}{4\\pi\\varepsilon_{0}}\\left( \\frac{1}{r^{+}} - \\frac{1}{r^{-}} \\right) $$ Ora possiamo fare certe approssimazioni, supponendo che $r \\gg a$ con $r$ la congiungente fra il centro del dipolo e il nostro punto e $a$ la distanza fra le cariche, possiamo affermare che $$ r^{+} - r^{-} = -a \\cos \\theta $$ Sappiamo che l\u0026rsquo;angolo √® lo stesso (pi√π o meno), perch√© sappiamo che i due reggi sono ora paralleli (come assunsione di semplificazione) Inoltre abbiamo che $r^{+}r^{-} = r^{2}$ perch√© il punto √® molto lontano allora possiamo affermare che $$ \\left( \\frac{1}{r^{+}} - \\frac{1}{r^{-}} \\right) = \\frac{a\\cos \\theta}{r^{2}} $$ a $$ V(P) = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{qa\\cos \\theta}{r^{2}} = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P\\cos \\theta}{r^{2}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{\\vec{P}\\cdot \\hat{r}}{r^{2}} $$ Direttamente proporzionale al momento di tipolo Inversamente proporzionale al quadrato del raggio. Campo elettrico nel dipolo Abbiamo che √® uguale a $$ \\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}} \\vec{P} \\cdot \\frac{\\hat{r}}{r^{3}} $$ Per trovare questo basta calcolare $$ \\vec{E} = -\\vec{\\nabla} V $$ Componente parallela üü© Basta osservare che $$ \\vec{E} = - \\vec{\\nabla}V = -\\frac{\\delta V}{\\delta x}\\hat{i} -\\frac{\\delta V}{\\delta y}\\hat{j} -\\frac{\\delta V}{\\delta z}\\hat{k} $$ Sappiamo che $\\vec{P} = P\\hat{k}$ e $\\vec{r} = x\\hat{i} + y \\hat{j} + z \\hat{k}$ allora abbiamo che $\\vec{P} \\cdot \\vec{r} = Pz$ Poi abbiamo che $z = r \\cos \\theta$\nUna volta esplicitato abbiamo che $$ E_{z} = - \\frac{\\delta V}{\\delta z} = -\\frac{\\delta}{\\delta z} \\left[ \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Pz}{(x^{2} + y^{2} + z^{2})^{3/2}} \\right] = -\\frac{P}{4\\pi\\varepsilon_{0}}\\left[ \\frac{1}{(x^{2} + y^{2} + z^{2})^{3/2}} + z \\left( -\\frac{3}{2} \\right) \\frac{2z}{(x^{2} + y^{2} + z^{2})^{5/2}} \\right] $$ $$ = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P}{r^{3}}\\left[ \\frac{3z^{2}}{r^{2}} - 1 \\right] = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P}{r^{3}}\\left[ \\frac{3r^{2} \\cos ^{2} \\theta}{r^{2}} - 1 \\right] = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P}{r^{3}}\\left[ 3 \\cos ^{2} \\theta - 1 \\right] $$ Nota : $E_{z} = E_{\\parallel}$ dato che √® parallela al dipolo.\nComponente perpendicolare üü®+ $$ E_{\\perp} = \\sqrt{ E_{x}^{2} + E_{y} ^{2} } $$ Calcoliamo $E_{x}$ che si pu√≤ scoprire che √® simmetrico rispetto $y$ $$ E_{x} = - \\frac{\\delta V}{\\delta x} = \\frac{\\delta}{\\delta x} \\left[ \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{Pz}{(x^{2} + y^{2} + z^{2})^{3/2}} \\right] = -\\frac{Pz}{4\\pi\\varepsilon_{0}}\\left[ -\\frac{3}{2} \\frac{2x}{r^{5}} \\right] = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{3xPz}{r^{5}} $$ e in modo equivalente con $y$ $$ E_{y} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{3yPz}{r^{5}} $$ In questo modo otteniamo che $$ E_{\\perp} = \\frac{3}{4\\pi\\varepsilon_{0}} \\frac{Pz}{r^{5}}\\sqrt{ y^{2} + x^{2} } = \\frac{3}{4\\pi\\varepsilon_{0}} \\frac{P}{r^{5}}r\\sin \\theta \\, r\\cos \\theta = \\frac{3}{4\\pi\\varepsilon_{0}} \\frac{P}{r^{3}}\\sin \\theta \\, \\cos \\theta $$ Passaggi sopra sono giustificati perch√© $\\sqrt{ y^{2} + x^{2}} = r \\sin \\theta$ e anche che $z = r\\cos \\theta$ Che ha senso perch√© c\u0026rsquo;√® simmetria circolare su quel piano. E vale praticamente per ogni punto nello spazio.\nAnalisi dei risultati (non fare) $\\theta=0$ abbiamo che $E_{\\perp} = 0$ e rimane solamente $$E_{\\parallel} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{2P}{r^{3}} $$ Quindi √® positivo, il campo.\n$\\theta=90$ questo √® il caso trattato precedentemente. Abbiamo ancora che $E_{\\perp} = 0$ e che $$ E_{\\perp} = -\\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P}{r^{3}} $$ Che √® coerente col risultato che abbiamo calcolato tempo fa.\nEsercizio: In quale angolo si annulla $E_{\\parallel}$ (analiticamente, basta l\u0026rsquo;angolo che annulla $3 \\cos ^{2} \\theta - 1$) Che √® uguale a 54.71 gradi. Domanda: perch√© si annulla in qu\nCon coordinate polari üü• Vedere 58 del Mazzoldi avremo che $$ E = \\frac{p}{4\\pi\\varepsilon_{0}r^{3}}(2\\cos \\theta \\hat{r}+ \\sin \\theta \\hat{\\theta}) $$ Si pu√≤ riscrivere anche il momento di dipolo in coordinate polari, e questo permette una scrittura ancora pi√π clean, in cui risalta che √® la componente radiale del momento di dipolo la parte di interesse nella relazione:\nPerch√© possiamo riscrivere il momento di dipolo in coordinate polari e usare quello: $$ \\vec{p} = p\\cos \\theta \\hat{r} - \\sin \\theta \\hat{\\theta} $$ Se si riesce a riscriverlo in questa forma, la cosa diventa molto clean, posso trovare le componenti asse e piano mediano del dipolo subito, plug and play diciamo. Infatti avremo che $$\\vec{E} = \\frac{1}{4\\pi\\varepsilon_{0}r^{3}}(3p\\cos \\theta \\hat{r} - \\vec{p} )$$ Dipolo immerso in campo elettrico NOTA: Posso assumere il valore di $\\vec{E}$ come costante sulle due cariche perch√© tanto varia molto molto poco. Anche se non ho capito esattamente il ragionamento.\nSupponiamo che la carica negativa sia posta su $\\vec{r}$ quindi il sistema di riferimento √® qualunque e che $r \\gg a$. Energia potenziale del dipolo üü© Usando esattamente il metodo trattato in Condensatori nel vuoto, basta applicare $$ U(P) = qV(\\vec{r} + \\vec{a}) - qV(\\vec{r}) = q\\left[ V(x + a_{x}, y + a_{y}, z + a_{z}) - V(x, y, z) \\right] $$ Si pu√≤ notare che con l\u0026rsquo;assunzione $r \\gg a$ √® infinitesimo quindi √® un differenziale di V Quindi $$ U(P) = q \\, dV(x, y, z) $$ Applicando il teorema che $$ dV = \\frac{\\delta V}{\\delta x}dx + \\frac{\\delta V}{\\delta y}dy + \\frac{\\delta V}{\\delta z}dz = \\frac{\\delta V}{\\delta x}a_{x} + \\frac{\\delta V}{\\delta y}a_{y} + \\frac{\\delta V}{\\delta z}a_{z} =-E_{x}a_{x} -E_{y}a_{y} -E_{z}a_{z} $$ Quindi abbiamo che $$ U(P) = q(-E_{x}a_{x} -E_{y}a_{y} -E_{z}a_{z}) = - P_{x}E_x - P_{y}E_y - P_{z}E_z = -\\vec{P} \\cdot \\vec{E} = - PE\\cos \\theta $$ Mentre 0 allora l\u0026rsquo;energia √® minima (se √® minima allora √® stabile in meccanica poi, seguendo questa giustificazione, allora diventa stabile quando $\\theta = 0 deg$ quindi tende a stare parallelo al campo. L\u0026rsquo;equilibrio √® instabile se √® diverso da 0 gradi. Stabile se √® 0\nMomento di dipolo üü© $$ \\vec{F}_{T} = q\\vec{E}_{+} - q\\vec{E}_{-} = 0 \\iff \\vec{E}_{+} =\\vec{E}_{-} = \\vec{E} $$ Per qualche motivo, il momento pu√≤ essere calcolato rispetto a qualunque sistema di riferimento $$ \\vec{M}_{T} = \\vec{r}_{+}\\times \\vec{F}_{+} + \\vec{r}_{-}\\times \\vec{F}_{-} = \\vec{r}_{+}\\times q\\vec{E} - \\vec{r}_{-}\\times q\\vec{E} = (\\vec{r}_{+} - \\vec{r}_{-})\\times q\\vec{E} = \\vec{a} \\times q\\vec{E} = \\vec{P} \\times \\vec{E} $$ Quindi abbiamo che $$ \\lvert \\vec{M}_{T} \\rvert = PE\\sin \\theta $$ Questo √® coerente con i valori di equilibrio instabile e stabile presenti per l\u0026rsquo;energia. Ossia possiamo scrivere: $$ \\vec{M} = \\vec{P} \\times \\vec{E} $$ Distribuzione di carica Prendiamo una distribuzione di carica qualunque nello spazio, di dimensione $d$ massima #### Momento di dipolo elettrico del sistema #### Potenziale di sistema üü®+ Abbiamo che $\\vec{r} = \\vec{r}_{i} + \\vec{d}_{i}$, allora posso assumere che $\\vec{r}$ e $\\vec{r}_{i}$ siano paralleli e dire che $$ r_{i} = r - d_{i}\\cos \\theta_{i} = r - \\vec{d}_{i} \\cdot \\hat{r} $$ E con questo possiamo semplificare molte cose, ma guardiamo: $$ V(P) = \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}}{r_{i}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}}{r - \\vec{d}_{i}\\hat{r}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}(r + \\vec{d}_{i}\\hat{r})}{r^{2} - d_{i}^{2}} \\approx \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}(r + \\vec{d}_{i}\\hat{r})}{r^{2}} $$ Per concludere definisco $\\vec{P} = \\sum_{i=1}^{N}q_{i}\\vec{d}_{i}$ questo √® il momento di dipolo elettrico del sistema, perch√© sto semplicemente sommando il dipolo di tutte le singole cariche.\n$$ V(P) = \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}}{r} + \\frac{1}{4\\pi\\varepsilon_{0}} \\sum_{i=1}^{N} \\frac{q_{i}\\vec{d}_{i}\\hat{r}}{r^{2}} \\frac{Q}{4\\pi\\varepsilon_{0}r} + \\frac{\\vec{P} \\cdot \\hat{r}}{4\\pi\\varepsilon_{0}r^{2}} $$ Il primo di questi si chiama termine di monopolo $V_{0}$, mentre il secondo √® il termine di dipolo $V_{DP}$. Il primo spiega Potenziale con s√© stesso al centro, indipendente dalla distribuzione. Come se stessi ammassando tutta la carica in un punto e calcolando il potenziale l√¨. Il secondo termine mi d√† informazioni del potenziale al variare della distribuzione di carica. (concettualmente dice prof. Zoccoli che questo √® equivalente alla torque nei corpi rigidi, che concentri tutta la massa sull\u0026rsquo;asse per calcolare la torque)\nConseguenza importante: Anche un atomo neutro pu√≤ generare un campo elettrico nello spazio, che √® dato dal termine di dipolo\nMonopolo vs Dipolo grandezza üü©\u0026ndash; Abbiamo con una approssimazione che $$ \\lvert \\vec{P} \\rvert = \\left\\lvert \\sum_{i} q_{i}\\vec{d}_{i} \\right\\rvert \\approx \\left\\lvert \\sum_{i} q_{i} \\right\\rvert d = Qd $$ Se usiamo questa approssimazione allora abbiamo che $$ \\frac{V_{DP}}{V_{O}} = \\frac{Qd}{4\\pi\\varepsilon_{0}r^{2}} \\frac{4\\pi\\varepsilon_{0}r}{Q} = \\frac{d}{r} \\ll 1 $$ Ma nel caso in cui √® neutro, allora l\u0026rsquo;unico campo che c\u0026rsquo;√® √® il termine di dipolo! Quindi bisogna contare per avere il campo.\nTermine dipolo nullo üü© Abbiamo che $$ Q_{T} = 0 = Q_{+} + Q_{-} = \\sum_{i}\\lvert q_{i}^{+} \\rvert - \\sum_{i}\\lvert q_{i}^{-} \\rvert $$ Allora abbiamo che $$ \\vec{P} = \\sum_{i}^{N}q_{i}\\vec{a}_{i} = \\sum_{i}^{N}\\lvert q_{i}^{+} \\rvert \\vec{d}_{i}^{+} - \\sum_{i}^{N} \\lvert q_{i}^{-} \\rvert \\vec{d}_{i}^{-} $$ Simile alla media pesata di tutte le masse per la massa totale, mi trovo ora qui il centro di massa per le cariche, lo faccio per positive e negative in modo separato. $$ \\vec{d}^{+} = \\frac{1}{Q}\\sum_{i=1}^{N} \\lvert q_{i}^{+} \\rvert \\vec{d}_{i}^{+} $$ Esattamente la stessa cosa per $\\vec{d}^{-}$. Scritto in questo modo abbiamo che $$ \\vec{P} = Q\\vec{d}^{+} - Q\\vec{d}^{-} = Q(\\vec{d}^{+} - \\vec{d}^{-}) = Q\\vec{\\delta} $$ Ossia il termine di dipolo si pu√≤ riassumere come differenza del centro fra le cariche positive e negative. Se non hanno stesso centro allora ho un campo elettrico (questo √® coerente col caso classico di dipolo a due cariche!). E questo √® vero sempre! √® anche il motivo per cui l\u0026rsquo;acqua √® carica, perch√© ha un momento di dipolo!\n","permalink":"https://flecart.github.io/notes/dipolo-elettrico/","summary":"Questo problema √® stato trattato in modo un po\u0026rsquo; pi√π semplificato (nel caso in cui la carica era esattamente a met√† in Campo elettrico#Dipolo elettrico). Questo problema √® stato storico, utilizzato per analizzare l\u0026rsquo;atomo.\nPotenziale del dipolo elettrico üü©\u0026ndash; Per il principio di sovrapposizione possiamo affermare che $$ V(P) = V_{r^{+}} + V_{r^{-}} = \\frac{q}{4\\pi\\varepsilon_{0}}\\left( \\frac{1}{r^{+}} - \\frac{1}{r^{-}} \\right) $$ Ora possiamo fare certe approssimazioni, supponendo che $r \\gg a$ con $r$ la congiungente fra il centro del dipolo e il nostro punto e $a$ la distanza fra le cariche, possiamo affermare che $$ r^{+} - r^{-} = -a \\cos \\theta $$ Sappiamo che l\u0026rsquo;angolo √® lo stesso (pi√π o meno), perch√© sappiamo che i due reggi sono ora paralleli (come assunsione di semplificazione) Inoltre abbiamo che $r^{+}r^{-} = r^{2}$ perch√© il punto √® molto lontano allora possiamo affermare che $$ \\left( \\frac{1}{r^{+}} - \\frac{1}{r^{-}} \\right) = \\frac{a\\cos \\theta}{r^{2}} $$ a $$ V(P) = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{qa\\cos \\theta}{r^{2}} = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{P\\cos \\theta}{r^{2}} = \\frac{1}{4\\pi\\varepsilon_{0}} \\frac{\\vec{P}\\cdot \\hat{r}}{r^{2}} $$ Direttamente proporzionale al momento di tipolo Inversamente proporzionale al quadrato del raggio.","title":"Dipolo elettrico"},{"content":"Most of times the pattern of proving and verifying it is like this $prove \\to verify$, that is: there is an entity that generates the solution, and then another that tries to verify it. But more expressive algorithms could be possible if there is interaction between the two entities, ones that try to prove it, and others try to verify it. From some point of view, this is similar from what AlphaGo does when searching, there is a part that guides the search, another that actually searches for it. Or the modern alpha geometry in modern times.\nDeterministic Interactive Theorem-provers Def: deterministic interactive theorem provers We have $k$ rounds of exchange, at the end the prover produces something. Let\u0026rsquo;s formalize it: Given $V, P : \\left\\{ 0, 1 \\right\\}^{*} \\to \\left\\{ 0, 1 \\right\\}^{*}$ a verifier and a prover, and and input $x$ (a problem), a $k$ round interactive proof is defines as following: $$ a_{1} = V(x), a_{2} = P(x, a_{1}), \\dots, a_{2i + 1} = V(x, a_{1}, \\dots, a_{2i}), a_{2i + 2} = P(x, a_{1}, \\dots, a_{2i + 1}) $$ We write $$ out^{k}_{V}\\langle V, P \\rangle (x) \\in \\left\\{ 0, 1 \\right\\} \\text{ as the output of the k-round interactive proof} $$ Languages in $dIP(k)$ Given a language $L$ we say that it is in $dIP(k)$ if in $k$ rounds we have:\nCompleteness: that is there exists a prover that produces a correct result for a given verifier, if the solution is correct. Correctness: if a solution is correct, every interactive proof gives a false result. More formally, given a deterministic TM acting as verifier, working in polynomial time: Completeness: $$ x \\in L \\to \\exists P: out^{k}_{V}\\langle V, P \\rangle = 1 $$ Correctness: $$ x \\not\\in L \\to \\forall P : out^{k}_{V}\\langle V, P \\rangle = 0 $$ We also define the deterministic interactive prover class as $$ dIP = \\bigcup_{k \\geq 1} dIP(k) $$ 3SAT in $dIP$ This can be prooven quite easily. But I am tired to write this down. But the takeaway is the following: This follows that $dIP = NP$, which essentially says that you don\u0026rsquo;t have any advantage using this method.\nProbabilistic Interactive Theorem-Provers The definition is very similar to the above. Note: interactive theorem provers, intuitively, seem to be very similar to a conversation between two agents, that try to work together to reach to a solution.\n","permalink":"https://flecart.github.io/notes/interactive-theorem-provers/","summary":"Most of times the pattern of proving and verifying it is like this $prove \\to verify$, that is: there is an entity that generates the solution, and then another that tries to verify it. But more expressive algorithms could be possible if there is interaction between the two entities, ones that try to prove it, and others try to verify it. From some point of view, this is similar from what AlphaGo does when searching, there is a part that guides the search, another that actually searches for it.","title":"Interactive Theorem Provers"},{"content":"Introduction to the course Machine learning gives a new way of thinking about reality: instead of trying to capture a part of reality, as most of the old sciences, go to the meta-level and try to produce an automated method to capture reality. This first lesson will be more a lesson of philosophy. There a paradigm shift in the sense of Thomas Kuhn\u0026rsquo;s scientific revolutions.\nAn interesting observation is that in the last 100 years, we have had more progress in the field of computer science than the 5000 years of computer science. This is because we have more data, we have more scientists, we are developing with the Kurzweil\u0026rsquo;s exponential growth. When comparing brain and computers, one have more creativity, the other has more storage capacity. This gives a trade-off.\nIn principle, epistemology tells you how to extract knowledge from data, from this point of view it can be seen as the precursor of modern information retrieval systems. This tells you something about methods of derivation. The first of which is deduction (Euclid, Hilbert\u0026rsquo;s grundlagen der geometrie, David Mumford for bayesian reasoning and image processing, but this person is still living). Deduction allows us to create facts by starting with the core principles of our thinking. Later induction was born (philosophically created by Bacon), where you create theory from data, and it\u0026rsquo;s a little bit more machine learning like. The former goes by logic, the latter by intuition (but could be wrong, and it\u0026rsquo;s not formalized), now modelled by statistics. These two processes of reasoning can be modelled as computational processes. And this allows us to create nice machines that are able to achieve these :D.\nWe use digital data because we can control it:\nEfficient to manage Discover models test and simulate hypotheses Find solutions The last three points can perhaps be called intelligence. For Joachim M. Buhmann (the prof.), it\u0026rsquo;s impossible to understand the models, and this can be motivated to the limited storage capacity of our brains, so the attempt of interpretability (i.e. correctly understanding exactly what is happening, the law) is just a bias in the history of science for us humans. While if we understand interpretability as a way to summarize useful information, visualizing it, then it is ok.\nClassically we considered algorithms as a way to process data, efficiently, now we want to treat them as a relation between data and decisions. At the end, the decisions are what is important for us humans. Algorithm\u0026rsquo;s makes it easier for us. Classically we have studied a concept of complexity of runtime, memory, or energy, but we have not have a clear theory of abstraction or robustness. In our case, we have a probability distribution going in, and another going out. But modelling them as random variables, it\u0026rsquo;s difficult to have a clear definition of correctness.\nWe can now divide algorithms in three macro categories, based on human-expertise\nClassical algos: humans are able to solve this problems, and are also able to specify those kinds of problems in a logical way Supervised algos: humans are able to solve these kinds of problems, but don\u0026rsquo;t know how to formalize their logic. Unsupervised and self-play: humans are not able to solve these problem good enough, this gave rise to alpha fold, alpha go and stuff similar to this. For Prof. Buhmann a fundamental ability of intelligence is being able to do counterfactual reasoning and planning. So being able to simulate the future, and be able to plan the today\u0026rsquo;s action in order to change the future. This is similar to (Choi 2022) and abductive reasoning by Choi.\nEvery law is a social experiment on a not understood population\nWhen Buhmann tried to say that nobody exactly understands everything, but a correct level of abstraction is often enough (i.e. chemical processes of the combustion engine)\nStudying algorithms is the most complicated part of mathematics when mathematics becomes concrete. 29 September 2023 Joachim M. Buhmann, minute 5.44 in ETHz AML lesson\nHe said that Kolmogorov Complexity is Shannon\u0026rsquo;s Theory for Random variables?? What does it even mean?\nNoise is your friend because it prevents you to make a statement so precise that you cannot compute it\nNoise is an indicator that you can\u0026rsquo;t solve your job.\nFramework for learning algorithms We want to have a theory used to validate learning algorithms $\\mathcal{A}$, which admits stochastic data as input.\nWe define the data to be observations of some experiment of some genre. Mathematically we write $e \\in \\varepsilon \\to \\mathcal{X}$ , $e \\to \\mathcal{X}(e)$. Meaning: we have an experiment that contributes to the data $\\mathcal{X}$. We define a hypothesis class $\\mathcal{C}$ where possible hypothesis are located. We use these hypothesis to interpret the dataset $\\mathcal{X}$.\nSome definitions A definition of Data Science We say that data science studies the algorithms $\\mathcal{A}$ that map the data $\\mathcal{X}$ to the space of possible hypothesis $\\mathcal{C}$.\nStatistics usually studies the distribution of $\\mathcal{X}$ data science studies the mappings. Physics and Mathematics, and other sciences study the space of possible hypothesis.\nWhat is Data? Encyclopedia Britannica: Association of numbers with physical quantities and natural phenomena by comparing an unknown quantity with a known quantity of the same kind.\nMeasurements by sensors, factual information, numbers. It\u0026rsquo;s not very clear, I would say any numbers that can help you do some interesting inferences in some world (it has to affect some entities (i.e. humans))\nWhat are features? But we can\u0026rsquo;t use this data directly so we use features of data, that could be arbitrary transformations of the initial data (edges, corners, etc\u0026hellip;)\nTypes of data Measurements We say that we have a world of $R$ objects, and we do observations about these objects. We say $X$ is a measurement (so a data point) where we have a function $X : \\mathcal{O}^{(1)} \\times \\dots \\times \\mathcal{O}^{(R)} \\to \\mathbb{K}$\nFour types of data Feature vectors: $X: \\mathcal{O} \\to \\mathbb{R}^{d}$ Categorical data $X : \\mathcal{O} \\to \\mathbb{R}^{d} \\times \\left\\{ 1, \\dots, k \\right\\}$ Regression data $X : \\mathcal{O} \\to \\mathbb{R}^{d} \\times \\mathbb{R}$ Proximity data $X : \\mathcal{O} \\times \\mathcal{O} \\to \\mathbb{R}$\nThis division should be pretty intuitive. See the slides for some real examples. Scales Nominal or Categorical scales Example: binary $\\mathcal{X} = \\left\\{ 0, 1 \\right\\}$, or some nominal categories (sweet, sour etc)\nQuantitative scales We can divide these scales as interval scales for fahrenheit temperature scale. The important information is between the values, so scale and translation invariant. Ratio scale: the information is the difference with a focal point, for example Kelvin temperature scale Absolute scales where we the important is absolute thing (grade scale ahah).\nBuhmann believes humans are only good in relative scale judgement, when they try to do absolute scaling, they can bias negatively or positively.\nDesiderata for Data Science In this section we would like to describe what exactly is a good data science algorithm.\nHypothesis consistency The most important requirement is: If $x$ and $x'$ are drawn from the same distribution, then $\\mathbb{P}^{\\mathcal{A}}(c \\mid x) \\approx \\mathbb{P}^{\\mathcal{A}}(c\\mid x')$ meaning the probability of the hypothesis should be similar.\nWe can call this control experiment and interpret $x$ as training data and $x'$ as test data in this setting. But we need to take some care about this statement:\nWe want similar inputs to have similar hypothesis We want dissimilar inputs to have dissimilar hypothesis If we only had requirement 1, then always outputting the same thing could solve our problem, but more variability is more useful, so we also consider dissimilar hypothesis :). The classical problem When starting to model a problem, we Computer Scientists that have to work on data have to decide the format of the data that we want to use. We want a way to evaluate this problem, discover when it\u0026rsquo;s a good model or not. Usually the trade-off is between the expected classification error, while trying to maximize the generalization ability. We don\u0026rsquo;t have the true expected error, so we use a proxy, the empirical error we can find during the experiments.\nFollowing (Vapnik 2006) we define a learning problem a search of a $f(x) \\in \\mathcal{C}$, and we write $f : \\mathcal{X} \\to \\mathcal{Y}$. Commonly $f$ is parameterised by a $\\theta$. Now we want to compute the risk, which is a loss, a way to tell how much our hypothesis is wrong. There are many possible losses, we won\u0026rsquo;t talk about them here. We call this loss function $Q(Y, f(X))$ We say that the conditional expected risk is $$ R(f, X) = \\int _{\\mathcal{Y}} P(Y \\mid X) Q(Y, f(X)) \\, dY $$ And the total expected risk is $$ \\mathbf{E}_{x}\\left[ R(f, X) \\right] = \\int _{\\mathcal{X}} \\int _{\\mathcal{Y}} P(X, Y) Q(Y, f(X)) \\, dY \\, dX $$ But these values are marginalizations, and often infeasible to compute. But the most difficult part of this formula is estimating the $P(X, Y)$, which we don\u0026rsquo;t know. We try to estimate this value by splitting the dataset in training and testing data. But how well can we estimate this? How close is the estimate? We want to know the value of $$ \\mathbb{P} \\left( \\lvert \\hat{R}(\\hat{f}, Z^{test}) - \\mathbf{E}_{X} \\left[ R(\\hat{f}, X) \\right] \\rvert \u003e \\varepsilon \\right) = \\,? $$ Where $\\hat{f}$ is the best hypothesis for our training data, and $\\hat{R}$ is the loss for the test data. We need to have some statistics over this value. k-splitting is a good way to have these statistics.\nWhen we want to mathematically characterize this, we need to keep in mind topology, Inner product spaces, Spazi vettoriali, and Spazi di probabilita.\nLog posterior agreement This section is not exam material (but üü®\u0026ndash;), did not understand this part quite well, the takeaway are following:\nRobust bounds on correctness of ML systems can be achieved (noisy bounds) We care about out-of-distribution generalization and fixed entropy of our hypothesis space. There are algorithms to efficiently minimize the cost (aka risk, hamiltonian) of out-of-distribution inputs. We want a way to measure how well similar distributions induce similar hypothesis. (this is sort of a soundness property). Let\u0026rsquo;s consider this value $$ \\mathbf{E}_{x, x'} \\log \\sum_{c \\in \\mathcal{C}}p(c \\mid x) \\frac{p(c \\mid x')}{p(c)} $$ We know that $x$ and $x'$ are independently sampled from the input distribution. The $p(c)$ is the same as $\\mathbf{E}_{x'} p(c \\mid x')$ (mean) which is a normalizing factor for that probability. Remember this: $$ \\mathbf{E}_{x'} p(c \\mid x') = \\int p(x') p(c \\mid x') \\, dx' = \\int p(x', c) \\, dx' = p(c) $$ It\u0026rsquo;s just marginalization.\nNow we do some maths, also Jensen\u0026rsquo;s inequality will be needed: $$ \\mathbf{E}_{x, x'} \\log \\mathbf{E}_{c \\mid x} \\frac{p(c \\mid x')}{p(c)} \\leq -\\mathbf{E}_{x, x'} \\mathbf{E}_{c \\mid x} \\log \\frac{p(c \\mid x')}{p(c)} = -\\mathbf{E}_{x, x'} \\mathbf{E}_{c \\mid x'}\\log p(c \\mid x') + \\mathbf{E}_{c} \\log p(c) $$ Now we can do some interpretation: The first part is out of sample description length of the hypothesis $c$ given $x$ the second one is minus the entropy of $\\mathcal{C}$.\nWe want a way to describe the quality of an hypothesis (stats people call it risk, physics people call it Hamiltonian) is a function $\\mathcal{R} : \\mathcal{X} \\times \\mathcal{C} \\to \\mathbb{R}$.\nThe gibbs distribution is often a good way to do this: $$ p(c \\mid x) = \\frac{\\exp(- \\beta \\mathcal{R}(x, c))}{\\sum_{c'} \\exp(- \\beta \\mathcal{R}(x, c'))} $$ Some times this is written with the free energy parameter (normalization part) $$ p(c \\mid x) = e^{-\\beta (\\mathcal{R}(x, c) - F(x))} $$ Where $F(x) = - \\frac{1}{\\beta} \\log \\sum_{c'}e^{-\\beta\\mathcal{R(x, c'})}$.\nWe can plug this back into the upper bound (so we can try to minimize the upper bound)\n$$ -\\mathbf{E}_{x, x'} \\mathbf{E}_{c \\mid x'} \\left( -\\beta \\mathcal{R}(x', c) + \\beta F(x')\\right) + \\mathbf{E}_{c} \\log p(c) $$ So we may want to do this minimization: $$ \\min_{\\beta, \\mathcal{R}} \\left\\{ \\mathbf{E}_{c} \\mathbf{E}_{x'} \\left( \\beta \\mathcal{R}(x', c) - \\beta E_{x} F(x') \\right) - \\text{ entropy}(c) \\right\\} $$ I have not understood exactly why we are doing this.\nReferences [1] Choi ‚ÄúThe Curious Case of Commonsense Intelligence‚Äù Daedalus Vol. 151(2), pp. 139\u0026ndash;155 2022\n[2] Vapnik ‚ÄúEstimation of Dependences Based on Empirical Data‚Äù Springer 2006\n","permalink":"https://flecart.github.io/notes/introduction-to-advanced-machine-learning/","summary":"Introduction to the course Machine learning gives a new way of thinking about reality: instead of trying to capture a part of reality, as most of the old sciences, go to the meta-level and try to produce an automated method to capture reality. This first lesson will be more a lesson of philosophy. There a paradigm shift in the sense of Thomas Kuhn\u0026rsquo;s scientific revolutions.\nAn interesting observation is that in the last 100 years, we have had more progress in the field of computer science than the 5000 years of computer science.","title":"Introduction to Advanced Machine Learning"},{"content":"Introduzione alla legge di gauss Giustificazione con angoli solidi üü®\u0026ndash; Pagina 69 del Mazzoldi. Vogliamo chiederci quanto sia il flusso in qualunque superficie Da un punto di vista infinitesimo abbiamo che (perch√© il flusso √®, intuitivamente, la parte perpendicolare rispetto la superficie che abbiamo) $$ d\\Phi = \\vec{E}\\cdot \\vec{dS} = \\lvert \\vec{E} \\rvert \\lvert \\vec{dS} \\rvert \\cos \\theta = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{1}{r^{2}} ds = \\frac{Q}{4\\pi\\varepsilon}d\\Omega $$ Il secondo passaggio √® giustificabile andando su coordinate polari considerando l\u0026rsquo;angolo solido di un oggetto quindi non dovrebbe essere un problema.\nDall\u0026rsquo;equazione di sopra abbiamo il flusso che √® da dentro un punto interno, sommando tutti questi infinitesimi abbiamo che $$ \\Phi = \\int _{\\sum} \\, d\\Phi= \\int _{\\sum} \\frac{Q}{4\\pi\\varepsilon}\\, d\\Omega = \\frac{Q}{4\\pi\\varepsilon}\\int _{\\sum} \\, d\\Omega = \\frac{Q}{4\\pi\\varepsilon} 4\\pi = \\frac{Q}{\\varepsilon} $$ Nota il flusso dipende solamente dalla CARICA, indipendente dalla singola posizione. Enunciato legge di Gauss (linguaggio naturale) üü© Il flusso attraverso qualunque superficie chiusa $\\sigma$ eguaglia la somma algebrica delle cariche contenute all\u0026rsquo;interno della superficie comunque esse siano distribuite divisa per ma costante dielettrica del vuoto $\\varepsilon_{0}$\n(praticamente scritto in linguaggio ambiguo naturale quello che viene espresso in formule, niente di pi√π e niente di meno).\nLegge di Gauss in forma integrale üü© $$ \\oint_{\\sum} \\vec{E} \\, \\vec{ds} = \\frac{Q}{\\varepsilon_{0}} $$ E se ci sono pi√π cariche, per principio di sovrapposizione posso sommare tutte le cariche sopra, e quindi ho $Q_{T} = \\sum_{i=1}^{N}q_{i}$ questo vale per distribuzione di cariche discrete, se √® continuo √® leggermente diversa la cosa (per cose viste precedentemente il contributo delle cariche esterne √® zero.)\nLegge di Gauss e divergenza üü© Guarda il teorema della divergenza dimostrato pi√π generalmente in Divergenza e Circuitazione. Flusso di campo vettoriale su superficie chiusa sigma √® uguale a qualcosa sulla divergenza\n$$ \\oint_{\\Sigma} \\vec{E} \\, \\vec{d}s= \\int_{V(\\Sigma)} \\vec{\\nabla}\\vec{E} \\, dt $$ In qualche modo posso dire che la densit√† di carica sul volume si pu√≤ fare senza problemi, Sappiamo sempre per gauss che\n$$ \\frac{1}{\\varepsilon_{0}}\\int _{V(\\sigma)}\\rho \\, dt = \\frac{Q_{T}}{\\varepsilon_{0}} $$ Abbiamo quindi che $$ \\int _{V(\\Sigma)}\\vec{\\nabla}\\vec{E} \\, dt = \\int_{V(\\Sigma)} \\frac{\\rho}{\\varepsilon_{0}} \\, dt \\implies \\vec{\\nabla}\\cdot\\vec{E} = \\frac{\\rho}{\\varepsilon_{0}} $$ Legge di Gauss in forma differenziale (locale) üü© Esiste anche una altra forma, che √® si pu√≤ vedere la dimo in Divergenza e Circuitazione riguardo alle motivazioni. $$ \\vec{\\nabla}\\cdot\\vec{E} = \\frac{\\rho}{\\varepsilon_{0}} $$ $\\rho$ √® la densit√† volumetrica di carica.\nChe mi da informazione sul valore del campo sul singolo punto, ossia se in quel punto c\u0026rsquo;√® il campo.\nOsservazione 1 √à ovvio osservare che questa forma del teorema di Gauss √® applicabile solo nei casi in cui la funzione √® differenziabile ovunque nello spazio, cosa che non √® mai detto. Se ho un punto di discontinuit√†, devo usare la forma integrale\nOsservazione 2: questa √® una forma locale perch√© nel caso la densit√† cambiasse, questa legge non pu√≤ essere utilizzata, non √® immediato che il campo cambi infatti, per√≤ √® utile per calcolare il campo nella singola posizione.\nUtilizzi della legge di Gauss Esempio: flusso dipolo üü© Essendo che altre parti escono, altre entrano, il flusso totale √® zero. Questo √® anche un modo per dimostrare che **non esiste nessuna linea che entra o esce dall'infinito**, andandosi quindi a trattare di induzione completa. Metodi per calcolare il flusso üü© sommo tutte le cariche che sono presenti (quanto fatto sopra) Uso Gauss (superficie) Sommo potenziali (gradiente cambiato di segno (recuperare)) Considerazioni sulla legge vs Coulomb üü© Questa legge di gauss √® direttamente dipendente dalla Legge di Coulomb, (probabilmente quello che si vuole dire √® che da una puoi derivare l\u0026rsquo;altra) e funziona solamente per il fatto che scende in modo inversamente quadrato.\nCaso particolare: campo costante üü© Consideriamo il caso in cui il campo √® costante su tutta la superficie, allora avrei che $$ \\oint_{\\sum}\\lvert \\vec{E} \\rvert ds \\cos \\theta = \\lvert \\vec{E} \\rvert \\oint_{\\sum}ds\\cos \\theta \\implies \\lvert \\vec{E} \\rvert = \\frac{Q_{T}}{\\varepsilon_{0}} \\frac{1}{\\oint_{\\sum}ds\\cos \\theta} $$ Un aspetto particolare √® che questo integrale $\\oint_{\\sum}ds \\cos \\theta$ √® semplicemente l\u0026rsquo;area della superficie.\n","permalink":"https://flecart.github.io/notes/legge-di-gauss/","summary":"Introduzione alla legge di gauss Giustificazione con angoli solidi üü®\u0026ndash; Pagina 69 del Mazzoldi. Vogliamo chiederci quanto sia il flusso in qualunque superficie Da un punto di vista infinitesimo abbiamo che (perch√© il flusso √®, intuitivamente, la parte perpendicolare rispetto la superficie che abbiamo) $$ d\\Phi = \\vec{E}\\cdot \\vec{dS} = \\lvert \\vec{E} \\rvert \\lvert \\vec{dS} \\rvert \\cos \\theta = \\frac{1}{4\\pi\\varepsilon_{0}}\\frac{1}{r^{2}} ds = \\frac{Q}{4\\pi\\varepsilon}d\\Omega $$ Il secondo passaggio √® giustificabile andando su coordinate polari considerando l\u0026rsquo;angolo solido di un oggetto quindi non dovrebbe essere un problema.","title":"Legge di Gauss"},{"content":"introduzione ai dielettrici Esperimenti metalli e dielettrici üü© Verso gli anni del 1840 Faraday ha fatto molti sistematici esperimenti per scoprire come si comportava il potenziale e il campo elettrico di fronte a certi materiali. Sono stati principalmente posti delle sostanza (conduttrici o meno) in mezzo a lastre di condensatori, e hanno misurato come cambiava il potenziale elettrico fra le due lastre (che si pu√≤ vedere attraverso il modo con cui cambiano sull\u0026rsquo;elettroscopio). Cos√¨ ha scoperto che $$ V_{s} = (h - s) E_{0} $$ Questo √® vero perch√© semplicemente in mezzo al conduttore il campo elettrico √® nullo, come spiegato in Conduttori elettrici, quindi durante l\u0026rsquo;integrale, il percorso √® semplicemente minore, esattamente di quella quantit√†.\nNel caso di condensatore con spessore $h$ e materiale conduttore di spessore $s$ in mezzo. Ma questo non succedeva se metteva materiali isolanti! In questi il potenziale cadeva pi√π lentamente rispetto al metallo, ma comunque cadeva di un po\u0026rsquo;, in modo lineare fino a riempire l\u0026rsquo;intero spazio. Il potenziale in questo ultimo stadio lo chiamiamo $V_{k}$ e sperimentalmente hanno notato che vale sempre $$ k = \\frac{V_{0}}{V_{k}} \u003c 1 $$ Costante dielettrica relativa üü© Questa quantit√† non √® molto importante, forse semplifica i conti ma √® utile a descrivere il nuovo campo elettrico, perch√© se si assume di avere un campo uniforme allora abbiamo: $$ E_{k} = \\frac{V_{k}}{h} = \\frac{V_{0}}{kh} = \\frac{E_{0}}{k} = \\frac{\\sigma_{0}}{k\\varepsilon_{0}} = \\frac{\\sigma_{k}}{\\varepsilon_{0}} = \\frac{\\sigma_{0}}{\\varepsilon} $$ L\u0026rsquo;ultimo valore possiamo scriverlo come se avessimo una carica intermedia, saltando i calcoli (un esercizio che trovi nel Mazzoldi p/128) Abbiamo che $$ E_{k} = \\frac{\\sigma_{0}}{\\varepsilon_{0}} - \\frac{\\sigma_{p}}{\\varepsilon_{0}} $$ Con $$ \\sigma_{p} = \\frac{k - 1}{k} \\sigma_{0} $$ E si potrebbe definire anche $$ \\sigma_{k} = \\sigma_{0} - \\sigma_{p} = \\frac{\\sigma_{0}}{k} $$ Qui si pu√≤ giocare un po\u0026rsquo; senza nessun problema!\nL\u0026rsquo;equazione del nuovo campo elettrico √® utile per avere una intuizione, √® come se esistesse un campo contrario creato dal dielettrico, che ne affievolisce l\u0026rsquo;intensit√†, questo sar√† spiegato meglio dopo, esisteranno seriamente queste cariche!\nCostante dielettrica assoluta del dielettrico üü© Si trova che le relazioni di sopra funzionano per condensatori rotondi, piani, di qualunque forma, basta che siano condensatori (quindi ci sia l\u0026rsquo;induzione completa e abbiano stessa carica). Infatti abbiamo anche cose come $$ C_{p} = \\frac{q}{V_{p}} = \\frac{qk}{V_{0}} = k C_{0} $$ Ma andando a definire la nuova costante dielettrica abbiamo: $$ \\text{costante dielettrica assoluta del dielettrico: }\\varepsilon = k\\varepsilon_{0} $$ Che √® il nostro nuovo valore! Per i condensatori piani abbiamo $$ C_{p} = kC_{0} = k \\varepsilon_{0} \\frac{S}{d} = \\frac{\\varepsilon S}{d} $$ E notiamo che cambia solamente il valore di dielettrico, √® ancora molto clean la relazione.\nSecondo me non ha senso questa parte e possiamo soltanto dire che la capacit√† cresce col dielettrico\nPolarizzazione del dielettrico Polarizzazione per deformazione/elettronica üü®+ Questa polarizzazione si spiega a un **livello atomico** perch√© intuitivamente si pu√≤ dire che il punto medio delle cariche elettriche positive (nucleo) e negative (nube di elettroni) quando viene sottoposto a un campo elettrico si spostano, per cercare di bilanciare la piccola forza applicata dal campo elettrico, quindi √® un valore direttamente proporzionale al valore del campo elettrico, In questo caso: $$ \\vec{p}_{e} = Ze\\vec{x} $$ Con x il vettore della congiungente, $Z$ numero atomico $e$ la carica basilare dell'elettrone. Da quanto studiato in [Dipolo elettrico](/notes/dipolo-elettrico), quando ho un momento, c'√® un campo indotto. Insieme a questo, i mini dipoli si orientano sul verso del campo elettrico.\nPolarizzazione per orientamento (non fatta) Questo viene usato per discutere a livello molecolare come avviene la polarizzazione. Se prendo molecole polari, come l\u0026rsquo;acqua, si avr√† che pi√π √® sottoposta a campo intenso, pi√π in media i dipoli saranno orientati sul campo, infatti se non lo sono allora ci sar√† un momento di dipolo che prover√† a riportarli in quello stato, come studiato in Dipolo elettrico nella sezione dei momenti di dipolo.\nLa differenza col precedente √® che questo √® solamente un effetto di media!\nSuscettibilit√† elettrica (!) Definizione di suscettibilit√† elettrica üü© Andiamo a chiamare la quantit√† $$ \\text{ suscettivit√† dielettrica: } \\chi = k - 1 = \\frac{V_{k}}{V_{0}} - 1 $$ Andiamo a definire un valore $P$ che spiega quanto dipolo creato dal campo, ed √® in pratica momento di dipolo per unit√† di volume. Solitamente assume questa forma: $$\nP = \\varepsilon_{0}\\chi E $$ Se un dielettrico soddisfa questa relazione (solitamente √® omogeneo) si dice che sia dielettrico lineare, solitamente materiali amorfi (senza forma), dotati di isometria spaziale, nei cristalli in genere questo non succede.\nDimostrazione valore üü® NOTA: nell'immagine ho sbagliato a disegnare il verso dei singoli atomi allungati. Assumiamo di immergere un dielettrico in un campo elettrico uniforme, allora abbiamo che $$ \\sigma_{p} = nq\\delta $$ Perch√© in pratica $n = \\frac{\\Delta N}{\\Delta \\tau}$ √® la densit√† atomica (numeri di atomi per unit√† di volume), io con la relazione di sopra sto anche moltiplicando per la lunghezza del tratto considerato, quindi $n\\delta$ rappresenta numero di atomi nella superficie (dato che $n$ √® il numero di atomi per volume, moltiplicando per una lunghezza ho la densit√† superficiale), e $q$ gli do la carica, dimensionalmente torna l\u0026rsquo;idea. Ogni atomo ha $q$ di carica a causa della polarizzazione.\nMa allo stesso tempo il momento di dipolo di un singolo atomo √® $\\vec{p} = q\\vec{\\delta}$, e cos√¨ che definisco il momento di dipolo per unit√† di volume come $\\vec{P} = nq\\vec{\\delta}$ (sul libro √® presentato come $\\vec{P} = n \u003c \\vec{p}\u003e$) allora abbiamo che $$ \\sigma_{p} = \\lvert \\vec{P} \\rvert $$ Nel caso pi√π generale (in immagine) in cui il campo elettrico non √® perpendicolare al piano del dielettrico si ha $$ \\sigma_{p} = \\vec{P} \\cdot \\hat{n} $$ Applicando questo su una formula di sopra abbiamo: $$ E = \\frac{\\sigma_{0} - \\sigma_{p}}{\\varepsilon_{0}} = \\frac{\\sigma_{0} - \\lvert \\vec{P} \\rvert}{\\varepsilon_{0}} \\implies P = \\sigma_{0} - \\varepsilon_{0}E = kE\\varepsilon_{0} - \\varepsilon_{0} E = \\varepsilon_{0}E(k - 1) = \\varepsilon_{0}E\\chi $$ Valore tensoriale üü© Solitamente per materiali non isotropi √® un tensore, quindi lo abbiamo in una forma del genere $$ \\begin{pmatrix} P_{x} \\ P_{y} \\ P_{z}\n\\end{pmatrix} \\begin{pmatrix} \\chi_{11} \u0026amp; \\chi_{12} \u0026amp; \\chi_{13} \\ \\chi_{21} \u0026amp; \\chi_{22} \u0026amp; \\chi_{23} \\ \\chi_{31} \u0026amp; \\chi_{32} \u0026amp; \\chi_{33} \\\n\\end{pmatrix} \\cdot \\begin{pmatrix} E_{x} \\ E_{y} \\ E_{z} \\end{pmatrix} $$ Ma per qualche motivo che non conosco $\\chi$ √® una **matrice simmetrica reale** questo implica che √® diagonalizzabile per cui esiste una base di autovalori, che permette di riscrivere la matrice di sopra come $$ \\begin{pmatrix} P_{x} \\ P_{y} \\ P_{z} \\end{pmatrix} \\begin{pmatrix} \\chi_{11}\u0026rsquo; \u0026amp; 0 \u0026amp; 0 \\ 0 \u0026amp; \\chi_{22}\u0026rsquo; \u0026amp; 0 \\ 0 \u0026amp; 0 \u0026amp; \\chi_{33}' \\end{pmatrix} \\cdot \\begin{pmatrix} E_{x} \\ E_{y} \\ E_{z} \\end{pmatrix} $$ Che √® anche pi√π veloce da calcolare. La base di autovalori si chiama anche asse ottico\nPolarizzazione in materiali non omogenei Caso dipolo omogeneo üü© Questo √® come il caso di flusso esterno in una superficie qualunque. Presa una qualunque superficie $\\Sigma$, abbiamo che: $$ \\Delta Q = \\oint_{\\Sigma} \\vec{P} \\cdot d\\vec{s} = 0 $$ Si pu√≤ dire che √® uguale a zero perch√© il flusso esce ed entra, per lo stesso valore.\nCaso dipolo non omogeneo üü© sia $\\Delta Q'$ la carica rimasta internamente al volume, dato che il dielettrico √® neutro abbiamo che √® uguale ed opposta a quella rimasta all\u0026rsquo;esterno, che chiamiamo $\\Delta Q$ Quindi abbiamo che $$ \\Delta Q = \\oint_{\\Sigma}\\vec{P} d\\vec{s} = \\int _{V(\\tau)} \\vec{\\nabla} \\cdot\\vec{P} \\, d\\tau $$ Dove abbiamo utilizzato il teorema della divergenza spiegato in Divergenza e Circuitazione Allora, motivati dal fatto che internamente $Q' = \\int _{V(\\tau)} \\rho \\, d\\tau$ Possiamo definire $$ \\vec{\\nabla} \\cdot \\vec{P} = - \\rho_{i} $$ Ossia la divergenza del momento di dipolo per unit√† di volume √® uguale a meno densit√† di volume elettrico indotto internamente.\nEquazioni di Gauss rivisitate üü© Possiamo ora aggiornare le equazioni di gauss andando a contare gli effetti del dipolo in modo esplicito, abbiamo che\nForma divergente Forma integrale $\\vec{\\nabla} \\cdot \\vec{E} = \\frac{\\rho}{\\varepsilon_{0}}$ $\\oint_{\\Sigma} \\vec{E} \\cdot d\\vec{s}$ $\\vec{\\nabla} \\times \\vec{E} = 0$ $\\oint_{\\Gamma} \\vec{E} \\cdot d\\vec{s} = 0$ $\\vec{\\nabla} \\cdot \\vec{P} = -\\rho_{p}$ $\\oint_{\\Sigma} \\vec{P} \\cdot d\\vec{s} = Q_{p}$ $\\vec{\\nabla} \\cdot \\vec{D} = \\rho_{\\text{libero}}$ $\\oint_{\\Sigma} \\vec{D} \\cdot d\\vec{s} = Q_{L}$ Andiamo ad osservare la forma divergente di Gauss, abbiamo che $\\rho = \\rho_{libero} + \\rho_{pol}$ ossia della carica libera pi√π quella indotta da polarizzazione, approfondendo quello deriviamo: $$ \\vec{\\nabla} \\cdot \\vec{E} = \\frac{\\rho_{libero}}{\\varepsilon_{0}} + \\frac{\\rho_{pol}}{\\varepsilon_{0}} \\implies \\varepsilon_{0} \\vec{\\nabla} \\cdot \\vec{E} = \\rho_{libero} - \\vec{\\nabla} \\cdot \\vec{P} \\implies \\vec{\\nabla}(\\varepsilon_{0} \\vec{E} + \\vec{P}) = \\rho_{libero} $$ Vettore di spostamento elettrico/induzione dielettrica üü© Il vettore che abbiamo trovato poco sopra ha un significato speciale, proviamo ad analizzare propriet√† di $$ \\vec{D} = \\varepsilon_{0}\\vec{E} + \\vec{P} = \\varepsilon_{0}(\\vec{E} + \\chi \\vec{E}) = k\\vec{E}\\varepsilon_{0} = \\varepsilon \\vec{E} $$ Con questo poi possiamo ri-caratterizzare il vettore di momento di dipolo come $$ \\vec{P} = \\frac{k-1}{k} \\vec{D} $$ Possiamo notare che il vettore di spostamento non √® altro che il campo elettrico per un dielettrico differente.\nChe saranno una conseguenza diretta delle equazioni di sopra: $$ \\vec{\\nabla} \\cdot \\vec{D} = \\rho_{libero} $$ $$ \\oint_{\\Sigma} \\vec{D} \\cdot d\\vec{s} = Q_{L} $$ Ossia questo √® un valore che dipende solamente dalla carica LIBERA, per questo vettore di spostamento posso ignorare il valore di polarizzazione indotta.\nDiscontinuit√† nei dielettrici Sappiamo che le componenti tangenti vengono conservate passando da una superficie all\u0026rsquo;altra (vedi Campo elettrico), e anche le discontinuit√† per componenti perpendicolari. Ora vogliamo vedere se vale la stessa cosa nei dielettrici, quando abbiamo solamente cariche di polarizzazione, ed entrambi valgono ancora (ma la sigma nel secondo caso √® di polarizzazione)\nDiscontinuit√† superficiale üü©\u0026ndash; $$ \\oint_{\\Sigma}\\vec{E} d\\vec{s} = \\frac{Q_{T}}{\\varepsilon_{0}} \\implies \\Delta E_{\\perp} = \\frac{\\sigma_{p}}{\\varepsilon_{0}} $$ Da quanto fatto col vettore di spostamento avrebbe senso vedere cosa succede in quel caso. dato che dipende solamente da cariche libere abbiamo che\n$$ \\oint_{\\Sigma}\\vec{D} d\\vec{s} = Q_{Libero} = 0 $$ Quindi il vettore di spostamento per il dielettrico √® ancora costante, non varia diciamo passando da una superficie all\u0026rsquo;altra, quindi √® continua.\nAndiamo a fare la stessa analisi in immagine, assumendo che $dh \\to 0$ quindi non abbiamo flusso verticale $$ \\vec{D}_{1}d\\vec{S}_{1} + \\vec{D}_{2}d\\vec{S}_{2} = 0 \\implies \\vec{D}_{1}\\cos \\theta_{1} + \\vec{D}_{2} \\cos \\theta_{2} = 0 \\implies D_{1}\\cos \\theta_{1} - D_{2} \\cos \\theta_{2} = 0 $$ Quindi $$ \\Delta D_{N} = 0 $$ Legge di Snell revisited üü©\u0026ndash; Una volte descritte le equazioni di continuit√† ricavare questo √® molto semplice, poi √® molto molto simile (opposto) a quanto fatto per Magnetismo nella materia per la continuit√† dei campi magnetici nel passare su superfici con correnti.\nSappiamo che $E_{\\parallel}^{1} = E_{\\parallel}^{2}$, che $E_{\\perp}^{1} = E_{\\perp}^{2}$ e che $D_{\\perp}^{1} = D_{\\perp}^{2}$ E che $\\vec{D} = \\varepsilon_{0}k\\vec{E}$ Da quello sappiamo che $$ \\varepsilon_{0} k_{1} E^{1}_{\\perp} = \\varepsilon_{0}k_{2}E_{\\perp}^{2} $$ Riscrivendo le relazioni precedenti abbiamo: $$ \\begin{cases} E_{1}\\sin \\theta_{1} = E_{2}\\sin \\theta_{2} \\\\ k_{1}E_{1}\\cos \\theta_{1} = k_{2}E_{2} \\cos \\theta_{2} \\end{cases} \\implies \\frac{\\tan \\theta_{1}}{k_{1}} = \\frac{\\tan \\theta_{2}}{k_{2}} \\implies \\frac{k_{2}}{k_{1}} = \\frac{\\tan \\theta_{2}}{\\tan \\theta_{1}} $$ Quindi so esattamente in che modo il modulo e la direzione di $E$ cambia all\u0026rsquo;interno della superficie di separazione dei mezzi. Quindi se passo da superficie con $k_{2}$ pi√π alto i raggi tendono verso l\u0026rsquo;esterno (angolo pi√π grande), e stessa cosa al contrario. NOTA: il modulo del campo elettrico cambia sempre. NOTA-2: basta guardare le linee di campo per sapere se il materiale √® conduttore o meno (perch√© per il conduttore cambia le linee di campo anche all\u0026rsquo;esterno).\nEnergia nei condensatori con dielettrico (!) Derivazione con dielettrico üü©\u0026ndash; Sappiamo che l\u0026rsquo;energia totale √® ancora $$ U_{e} = \\frac{1}{2} CV^{2} = \\frac{1}{2} \\frac{\\varepsilon S}{d} V_{k}^{2} = \\frac{1}{2} \\varepsilon S E_{k}^{2}d = \\frac{1}{2}\\varepsilon E_{k}^{2} (Sd) = u_{e} \\cdot \\text{ Volume} $$ Solo che √® da considerare la $E_{k}$ presente con il dielettrico che √® uguale a $\\frac{E_{0}}{k}$ Possiamo calcolarlo anche in altro modo: $$ U = \\frac{1}{2} \\frac{Q^{2}}{C} = \\frac{1}{2} (\\sigma S)^{2} \\cdot \\frac{d}{\\varepsilon S} = \\frac{1}{2} \\varepsilon\\frac{\\sigma^{2}}{\\varepsilon^{2}} \\cdot Sd \\frac{1}{2}\\varepsilon E^{2} \\cdot Sd $$ E viene ugualmente come prima\nCon vettore di spostamento üü© abbiamo, considerando che $\\vec{D} = \\varepsilon \\vec{E}$, vale per dielettrico isotropo, ma per quello anisotropo, in cui non sono pi√π paralleli come si fa?\n$$ u_{E} = \\frac{1}{2} \\varepsilon E^{2}_{k} = \\frac{1}{2} \\frac{D^{2}}{\\varepsilon} $$ A parit√† di campo elettrico, spendo molta quantit√† di energia in pi√π per caricarlo.\nMateriale anisotropo üü©\u0026ndash; $$ u_{E} = \\frac{1}{2}\\varepsilon E^{2} = \\frac{1}{2} \\vec{E} \\cdot \\vec{D} $$ Perch√© devo contare la parte parallela.\n","permalink":"https://flecart.github.io/notes/condensatori-con-dielettrici/","summary":"introduzione ai dielettrici Esperimenti metalli e dielettrici üü© Verso gli anni del 1840 Faraday ha fatto molti sistematici esperimenti per scoprire come si comportava il potenziale e il campo elettrico di fronte a certi materiali. Sono stati principalmente posti delle sostanza (conduttrici o meno) in mezzo a lastre di condensatori, e hanno misurato come cambiava il potenziale elettrico fra le due lastre (che si pu√≤ vedere attraverso il modo con cui cambiano sull\u0026rsquo;elettroscopio).","title":"Condensatori con dielettrici"},{"content":"L‚Äôottimizzazione combinatoria √® un altro nome per la ricerca operativa. √à uno strumento utile a prendere le decisioni migliori, fatto sta che √® anche molto utile al machine learning e si potrebbe dire che ne sia una base, questa √® una cosa molto buona.\nRicerca operativa Questo √® un campo a forte impatto economico perch√© prova a minimizzare i costi e massimizzare i profitti.\nSteps üü©, üü® Individuazione del problema (almeno riconoscere che ci sia un problema) Raccoglimento dei dati Modellizzazione del problema Ricerca di una soluzione Analisi dei risultati della soluzione La ricerca operativa si interessa principalmente degli step 3 e 4, nonostante gli steps non sempre vengono eseguiti in maniera lineare, ma c‚Äô√® un ciclo di feedback a riguardo.\nModelli (3) üü© Un modello √® una descrizione astratta, e scritta nel linguaggio della matematica, della parte di realt√† utile al processo decisionale\nGiochi\nCi sono una serie di agenti in un ambiente con alcune regole precise, i risultati sono visti come causati dall\u0026rsquo;interazione fra gli agenti. (Abbastanza recente, presente nel secolo scorso)\nEquilibrio Strategia sono due concetti molto interessanti per questo tipo di modellizzazione.\nSimulazioni\nSi cerca di capire cosa succede facendo una simulazione, √® certo che la possibilit√† di generare numeri casuali √® fondamentale in questo passo. Eg metodi monte-carlo\nAnalitici\nQuesti sono i modelli interessanti alla ricerca operativa perch√© tratta in modo matematico il modello, cercando il minimo o massimo di una funzione (si vede qui che ci sarebbe biosgno dianalisi, fa strano che non lo abbia messo nei prerequisiti).\nSono fedeli al problema, e devono essere astratti.\nUn problema Un problema non √® nient‚Äôaltro che una domanda, espressa in termini generali, ma la cui risposta dipende da un certo numero di parametri e variabili.\nQuindi possiamo affermare che un problema di ricerca operativa venga descritta tramite:\nParametri e variabili che sono in gioco Quanto la soluzione deve soddisfare per essere valida Sembra un p√≤ come se fosse un problema di CSP\nParametri e variabili üü© √à importantissimo fare una distinzione fra parametri e variabili.\nVariabile √® un valore ignoto che vorremmo trovare, spesso in funzione di parametri. Parametri sono valori, che possono essere conosciuti o meno, che supponiamo essere conosciute. eg. $ax^2 + bx + c=d$ i parametri sono $a,b,c,d$ e la variabile √® solo $x$, perch√© noi vorremmo trovare x in funzione dei parametri.\nIstanza di un problema üü© Con la definizione di parametri √® variabili si fa una distinzione fra una istanza di un problema, oppure il problema in senso generale. Quando i parametri non sono pi√π simbolici, allora √® una istanza, perch√© effettivamente ora possiamo andare a calcolare la soluzione.\nQuindi una sostituzione di tutti i parametri simbolici, con valori reali (probabilmetne ottenuti da osservazione, da dati) si ha una istanza di una soluzione.\nAmmissibilit√† delle soluzioni üü© Vogliamo cercare ora di definire da un punto di vista matematico cosa sia l\u0026rsquo;insieme delle soluzioni ammissibili.\nOssia, vorremmo trovare gli $x$, le variabili prese in un campo grande, come pu√≤ essere $\\R$. Quindi un primo step √® trovare l‚Äôinsieme delle soluzioni in funzione dei parametri.\nLe variabili che soddisfano tutti i costraints sono $x \\in \\mathbb{F}_p \\subseteq \\mathbb{G}$., con G un insieme in cui vivono le variabili.\nLe variabili $x \\in \\mathbb{G} - \\mathbb{F}$ sono non ammissibili.\nFunzione obiettivo !! üü© √à una misura di una bont√† della soluzione. spesso definita come $c_p : \\mathbb{F}_p \\to \\R$, ossia dalle soluzioni ammissibili ai Reali. Vorremmo cercare di minimizzare o massimizzare la soluzione a questo problema con questa funzione di valutazione o obiettivo. Si pu√≤ vedere molto facilmente che il problema di massimo √® equivalente al problema di minimo invertendo.\nSoluzione ottima √® il valore di $x \\in \\mathbb{F}_p : x = min \\{c_p(y) : y \\in \\mathbb{y}_p \\}$, definiremo questa x come $Z_p = x$\nValore ottimo √® $c_p(x) \\in \\mathbb{F}_p$ con $x$ il valore di sopra.\nCatalogazione dei problemi Ottimizzazione, decisione e certificato üü© Problema di ottimizzazione\nVogliamo trovare il minimo in qualcosa. Ma questo di solito √® un problema molto difficile perch√© bisogna prima trovare le soluzioni possibili, e poi bisogna anche trovare la migliore fra queste soluzioni possibili\nProblema di decisione\nSi tratta di cercare una soluzione $g: g \\in \\mathbb{F}_p$\nProblema di certificato\nVogliamo cercare di verificare se una soluzione √® nell\u0026rsquo;insieme che ci piaccia.\nsi tratta di verificare che se data $g$ si ha che $g \\in \\mathbb{F}_p$\nConversione da certificazione e ottimizzazione üü® Possiamo dire che un problema di certificazione dare dei valori fissati, quelli che ci piacciono sono di valore basso, in questo modo converto subito il valori che ci piacciono in questo caso come soluzioni del problema di ottimizzazione:\n$c_p(x) = 0 : x \\in F_p$, $c_p(x) = 1: x \\not\\in F_p$\nPossiamo anche convertire un problema di ottimizzazione in un problema decisionale, se conosciamo il costo ottimo √® semplice formalizzarlo, altrimenti si fa $\\leq k$ un valore fisso scelto\nSlide\nTipi di soluzione ai problemi üü©- Vuoto\nNon c\u0026rsquo;√® nessuna soluzione, faremo finta che il costo per implementare la soluzione a questo problema sia infinito\n$Z_p = \\infty$\nIllimitato (inferiormente o superiormente)\nOssia ho troppe soluzioni ammissibili,e possono prendere sempre una soluzione che abbia un costo minore:\nIn questo caso posso dire che $Z_p = -\\infty$ nel caso di un problema di minimizzazione.\nDi solito sono problemi artificiosi, nel mondo reale non succede quasi mai, anch emeno volte del vuoto.\nOttimo Finito, soluzione ottima non finita\nNel caso in cui esiste un costo finito, ma non esiste nel nostro insieme di partenza una soluzione che abbia questo costo\nesempio:\n$\\inf \\{ x \\in \\R : x \u003e 0\\}$, il minimo √® in 0, ma nessuno ci arriva.\nAd esempio utilizzare delle relazioni lasche evita questo problema.\nOttimo finito e soluzione finita\nCaso che ci piace\nAlgoritmi esatti e euristici üü©-, üü® Ossia descriviamo l‚Äôalgoritmo esatto e sappiamo che in output sar√† la soluzione perfetta, solo che la maggior parte dei casi √® troppo lento.\nL‚Äôalgoritmo euristico deve restituire un valore che sia simile al valore ottimo, quindi spesso √® molto pi√π efficiente. Possiamo in questo caso definire un concetto di approssimazione inferiore e superiore\nLa qualit√† dell‚Äôalgoritmo euristico si pu√≤ misurare col concetto di errore, quindi sia $R_p(g)$ l‚Äôerrore relativo rispetto al valore ottimo per questo problema, allora si pu√≤ dire che l‚Äôalgoritmo √® $\\varepsilon$-approssimato quando produce soluzioni $g :$ $R_p(g) \\leq \\varepsilon$\nRilassamenti üü©, üü® Vogliamo cercare di applicare le soluzioni del problema per permettere l‚Äôesistenza di algoritmi di complessit√† inferiori ( e per i problemi di minimo provare ad approssimare al ribasso, in modo tale che la soluzione ottima reale non √® meno della soluzione trovata\nSlide\nLa nota principale √® quando la soluzione del problema rilassato √® esattamente uguale al problema iniziale, in questo caso posso concludere di aver gi√† trovato la soluzione ottimale per il problema iniziale.\n","permalink":"https://flecart.github.io/notes/introduzione-a-ottimizzazione-combinatoria/","summary":"L‚Äôottimizzazione combinatoria √® un altro nome per la ricerca operativa. √à uno strumento utile a prendere le decisioni migliori, fatto sta che √® anche molto utile al machine learning e si potrebbe dire che ne sia una base, questa √® una cosa molto buona.\nRicerca operativa Questo √® un campo a forte impatto economico perch√© prova a minimizzare i costi e massimizzare i profitti.\nSteps üü©, üü® Individuazione del problema (almeno riconoscere che ci sia un problema) Raccoglimento dei dati Modellizzazione del problema Ricerca di una soluzione Analisi dei risultati della soluzione La ricerca operativa si interessa principalmente degli step 3 e 4, nonostante gli steps non sempre vengono eseguiti in maniera lineare, ma c‚Äô√® un ciclo di feedback a riguardo.","title":"Introduzione a ottimizzazione Combinatoria"},{"content":"Introduzione ai metodi di discesa. Generali sui metodi di discesa Vogliamo creare algoritmi che riescano a trovare i punti di minimo delle funzioni non vincolate.\nIn generale si trova un punto stazionario (condizioni necessarie) ma non √® garantito lo stato ottimo.\nSolitamente sono divisi in first order methods in cui viene considerata solamente la derivata prima della funzione. E cose di metodi superiori.\nCondizioni di arresto classiche (2) üü©- Slide\nDifferenza fra due iterati √® minore a una tolleranza, in modo simile a quanto fatto in Equazioni non lineari sulla tolleranza per il metodo delle approssimazioni I criteri di arresto sono i sempre classici\nNumero di iterazioni superate Tolleranza sull‚Äôobiettivo ossia gradiente $\\simeq$ 0 per il punto di stazionariet√†. Idea principale dei metodi di discesa üü© Slide\nTrovare una direzione di discesa Aggiornare x in modo da andare in quella direzione di un passo fissato. direzione di ricerca e lunghezza del passo sono due nuovi termini di interesse per questa roba Ottimizzazione non vincolata (non studiare) In pratica questa parte √® un ripasso molto veloce di 2 mesi di analisi 2‚Ä¶ E poi ovviamente fatti molto male!\nGuarda Massimi minimi multi-variabile. In pratica ottimizzazione √® trovare il massimo o il minimo di una funzione‚Ä¶\nDiscesa Condizione per direzione di discesaüü©- Slide\nSi pu√≤ osservare che io stia proprio scendendo, in questo senso vado a cercare qualcosa che sia uguale a 0.\nInterpretazione geometrica della condizione di discesa\nSe forma angolo ottuso con il gradiente √® OK!\nE guardare le curve di livello √® una cosa molto buona.\nAlgoritmo generale di GDüü© Slide\nSi pu√≤ notare che la scelta del passo √® la parte critica di questo algoritmo. Scegliere un alpha fisso non garantisce la convergenza, devono essere soddisfatte certe propriet√†.\nRicerca dell‚Äôalpha Scelta della alpha (linea esatta)üü©- Definizione di funzione dipendente da alpha\nVado a scegliere l‚Äôalpha in modo tale che assuma il valore pi√π piccolo possibile, significa minimizzare questa funzione di alpha.\nSolitamente si utilizza quando f √® in forma quadratica, per resto spesso non si utilizza (perch√© la f si calcola in modo molto veloce, di solito √® molto lento. dimostrato converge! punto minimo o massimo boh.\nlinea inesatta üü®+ Slide\nQuindi inesatta perch√© devo trovare l\u0026rsquo;insieme di alpha buoni, non quell preciso\nCondizioni di Wolfe üü®- Due funzioni costituiscono le condizioni di Wolfe:\nCondizione di Armijo: $f(x_{k} + \\alpha p_{k}) \\leq f(x_{k}) + c_{1}\\alpha \\nabla f(x_{k})^{T} p_{k}$ assicura una decrescita sufficiente di $f$ nella direzione trovata $p$. Questa condizione √® anche chiamata condizione della decrescita sufficiente. Condizione della curvatura: $\\nabla f(x_{k} + \\alpha_{k} p_{k})^{T} p_{k} \\geq c_{2} \\nabla f(x_{k})^{T} p_{k}$ impedisce che $\\alpha_{k}$ diventi troppo piccolo. Slide Armijo e backtrackingüü® Intro a backtracking\nbacktracking\nL‚Äôalgoritmo\nNOTA: bisgona anche mettere una condizione di maxit, se si esce per quella allora √® perch√© non si pu√≤ trovare! (molto probabilmente)\nCondizioni di ottimalit√† Definizione üü© Quando sono in un minimo locale o globale per la nostra funzione.\nAndiamo a definire una condizione di ottimalit√† di primo secondo oordine perch√© andiamo a guardare le derivata\nCondizione necessaria e sufficiente al primo e secondo ordine üü© Primo ordine\nQuesto non √® altro che il teorema di fermat del secondo ordine che puoi trovare qui 11.1.2 Condizione di stazionariet√† (fermat) !!!\nSlide\nNon esiste una condizione sufficiente al primo ordine\nSecondo ordine\nQuesto √® il modo con cui trovavamo i punti di minimo, √® anche una condizione sufficiente se √® definita positiva\nOttimalit√† per funzioni convesse ! üü© Funzioni quadratiche Questo tipo di funzioni ci piace molto perch√© sono convesse e le funzioni convesse sono facili da analizzare per sta robba.\nQuadratiche convesse üü• Slide\nCon $Q$ matrice simmetrica\nCon $q$ convessa se la matrice √® semidefinita positiva, e convessa stretta se √® definita positiva.\nQuesta funzione ci pu√≤ essere utile per la risoluzione dei Minimi quadrati. Quando mi calcolavo la norma quadrata per quel problema, avevo una funzione quadratica convessa (quasi, credo che il termine noto non fa male)!\nSoluzioni eq. normali Slide\nCon la roba di sopra dimostro anche che una soluzione ottima (ricorda che √® ottima anche una soluzione locale) esiste sempre.\nMetodo di newton puro L‚Äôunica cosa che cambia nello step di newton √® che la direzione di discesa √® calcolata in modo differente, in particolare possiamo vedere che lo step sia:\n$p_k = H(x_k) ^{-1} \\nabla f(x_k)$, le ragioni sono sconosciute (a me), e non √® conveniente in termini di tempo provare a capire questo. lo step √® sempre di 1.\nLa velocit√† di convergenza √® quadratica come nel caso descritto per newton in Equazioni non lineari. L\u0026rsquo;hessiana solitamente contiene informazioni sulla curvatura che permette, soprattutto nei casi in cui la nostra funzione √® quadratica, di convergere pi√π velocemente (invece di oscillare tanto, probabilmente va diretto nel minimo).\nRipasso (roba di analisi) Derivata parziale Guardare Calcolo differenziale. Ma √® una roba troppo base sta roba üòë\nHessiana Questa matrice ci da informazioni sulle derivate seconde\nMatrice simmetrica derivata $ij$, prima derivo su $i$, poi su $j$. Ricordarsi il teorema di Schwarz, che √® sufficiente per dimostrare che la matrice √® simmetrica\nJacobiana Questa ci da informazioni sulle derivate prime per tutti i modi possibili!\n$f: \\mathbb{R}^n \\to \\mathbb{R}^m$, $J(f) : \\mathbb{R}^n \\to \\mathbb{R}^{m\\times n}$\nIn particolare sulle righe ho tutte le derivate parziali possibili Sulle colonne ho la derivata fatta su tutte le funzioni possibili Analogo minimimo massimo Se ho il massimo e voglio il minimo, basta costruirsi la funzione swappata\n$$ \\arg \\max_{x} f(x) = \\arg \\min_{x} - f(x) $$ Teorema sulle funzioni differenziabili Calcolo differenziale Spiega bene questo teorema, con\nSe le derivate parziali esistono e sono continue, allora la funzione si dice differenziabile con continuit√† $C$.\nPunti di minimo locali e globali Globale\nQuando √® minimo per tutto il dominio.\nLocale\nSe √® un punto di minimo globale con dominio ridotto ad un intorno (basta che esista un interno).\nFunzioni convesse Questa parte √® trattata in analisi in Convessit√† (cenni)\nSlides\n!\nSlide\n!\n","permalink":"https://flecart.github.io/notes/metodi-di-discesa/","summary":"Introduzione ai metodi di discesa. Generali sui metodi di discesa Vogliamo creare algoritmi che riescano a trovare i punti di minimo delle funzioni non vincolate.\nIn generale si trova un punto stazionario (condizioni necessarie) ma non √® garantito lo stato ottimo.\nSolitamente sono divisi in first order methods in cui viene considerata solamente la derivata prima della funzione. E cose di metodi superiori.\nCondizioni di arresto classiche (2) üü©- Slide","title":"Metodi di Discesa"},{"content":"2.1 Elementi di base 2.1.1 Definizione e caratteristiche Tutto √® un insieme (su questo si basa la maggior parte della matematica) Efficace nella descrizione degli oggetti (infiniti √® ez), ma non √® efficiente nel calcolo in quanto non d√† nessun indizio sul\u0026rsquo;implementazione in memoria o sul modo per calcolarlo, c\u0026rsquo;√® solo una associazione Si pu√≤ concludere che per l\u0026rsquo;informatico non serve a molto questa teoria, ma √® la base per la matematica.\n2.1.2 Teoria Naif √à la teoria disposta a paradossi (Russel) che afferma che gli insiemi si possono formare liberamente ‚Üí Assioma di comprensione.\nAbbiamo gi√† analizzato in Logica meta-linguistica che questo paradosso √® distruttivo,\nin particolare guardare qui\nOperazioni di base\nl\u0026rsquo;appartenenza Creazione di sottoinsiemi 2.1.3 Diagrammi di Venn Il diagramma di Venn permette la rappresentazione di insiemi finiti\nL\u0026rsquo;unica cosa di ricordare, √® che non permette nesting di insiemi.\n2.2 Zermelo-Frank Set Theory Questa √® una possibile teoria assiomatica degli insiemi.\nEnti primitivi\nSono enti di cui non esiste la definizione (perch√© serve un punto di partenza).\nIn particolare sono enti primitivi\nAppartenenza Uguaglianza Nella slide c\u0026rsquo;√® scritto che non vengono definiti, ma poi l\u0026rsquo;assioma di estensionalit√† lo definisce, invece estensionalit√† definisce solo una relazione Insieme Andiamo ora a definire assiomi, cose ovvie di questa teoria che sia utile per dimostrare altre propriet√†\n2.2.1 Assioma di Estensionalit√† e sottoinsiemi Questo assioma definisce l\u0026rsquo;uguaglianza fra gli insiemi.\nPer ogni X e Y, i due insiemi sono uguali sse hanno gli stessi elementi (un Z che sta sia in X sia in Y, possiamo dire che Z √® un elemento temporaneo utile per la stesura)\nSottoinsieme\nDefinizione = #define in c++ ossia una sostituzione, una abbreviazione.\nUguale a sopra, ma invece di SSE, utilizziamo un SE.\nSe Z appartiene a X allora appartiene a Y.\nCosa √®\nRelazione fra l\u0026rsquo;ente primitivo uguaglianza con l\u0026rsquo;appartenenza, ma non √® definito come appartenenza, ente primitivo √® dato come gli pare.\n2.2.2 Assioma di separazione L\u0026rsquo;assioma di separazione √® lo strumento utile che hai visto durante la risoluzione del paradosso di Russel.\nQuindi definiamo un insieme Y a seconda di una caratteristica di X. Usiamo sempre un insieme temporaneo Z per definirlo.\nQuindi scriviamo $Y=\\{Z\\in X | P(X) \\}$ ossia esiste un Y definito per elementi Z tale che questo Z appartenga a X e soddisfa una propriet√† P(Z). Questo √® un abuso di notazione, che per√≤ d√† il senso, dovresti scrivere sempre in altro modo.\n$$ \\forall X,\\exist Y, \\forall Z, (Z \\in Y \\iff Z \\in X \\wedge Z \\in P(X)) $$ Esempio, L\u0026rsquo;insieme degli studenti biondi √® definito per gli studenti biondi che siano studenti (X) e che abbiano la propriet√† di essere biondi P(Z).\n2.2.3 Assioma dell\u0026rsquo;insieme vuoto e definizione Questo assioma definisce l\u0026rsquo;insieme vuoto e definisce alcune caratteristiche\nL\u0026rsquo;insieme vuoto non ha elementi\n$\\exist X, \\forall Z, Z \\not\\in X$ Ma √® ridondante perch√© √® sufficiente definirlo con l\u0026rsquo;assioma di separazione in questo modo:\nSto ottenendo l\u0026rsquo;insieme vuoto svuotandolo da un insieme che esiste gi√†, in questo modo:\n$$ \\empty \\coloneqq \\{X \\in Y| false\\} $$ 2.2.4 Definizione di intersezione infinita L\u0026rsquo;intersezione si pu√≤ definire come l\u0026rsquo;insieme tale che sia contenuto sia in X sia in Y, quindi utilizzando assioma di separazione di pu√≤ fare.\nTeorema di appartenenza a un insieme intersezione\nSi pu√≤ dimostrare subito partendo dall\u0026rsquo;assioma di separazione, intendi A come insieme da cui prendi e P(Z) come appartenza a B.\nEstensione a intersezioni infinite\nBasta prendere l\u0026rsquo;intersezione binaria e utilizzare l\u0026rsquo;insieme di ritorno per altri, in modo ricorsivo se potrebbe aiutare.\nQuesto per√≤ non funziona per l\u0026rsquo;intersezione infinita ecco che c\u0026rsquo;√® il bisogno di definire l\u0026rsquo;intersezione meglio.\nDefinizione di intersezione\nF √® l\u0026rsquo;insieme tdi tutti gli insiemi da intersecare, se F vuoto lo definisco come vuoto, altrimenti utilizzo un insieme A e interseco sempre per ogni insieme Y!.\n$$ A\\in F,\\{X \\in A\\,|\\,\\forall Y :Y \\in F \\implies X \\in Y\\} $$ $\\bigcap F =$ intersezione dell\u0026rsquo;insieme Insieme di tutti gli elementi da intersecare\nEsempio\n2.2.5 Assioma di unione L\u0026rsquo;assioma dell\u0026rsquo;unione definisce l\u0026rsquo;unione fra insiemi infiniti e la notazione √® molto simile per l\u0026rsquo;insieme intersezione\n$\\bigcup F$ definito in modo simile\n$$ \\exists A \\, \\forall X, \\{X \\in A\\iff\\,\\exists Y: Y \\in F \\wedge X \\in Y \\} $$ E da questo si pu√≤ dimostrare il teorema dell\u0026rsquo;unione binaria che √® la definizione di unione classica che abbiamo.\n2.2.6 Assioma del singoletto Se c\u0026rsquo;√® solo un elemento in un insieme allora questo si dice singoletto\n$$ \\forall X,\\exists Y, \\forall Z \\{Z \\in Y \\iff Z = X \\} $$ Si pu√≤ utilizzare insieme all\u0026rsquo;unione per relazionarsi all\u0026rsquo;ente primitivo dell\u0026rsquo;appartenenza.\nNOTA:\nl\u0026rsquo;assioma del singoletto a volte √® ridondante perch√© si potrebbe definire in altro modo, in particolare attraverso l\u0026rsquo;assioma di rimpiazzamento\nINSIEME A UNIONE\nPossiamo utilizzare un abuso di notazione di questo genere:\n$$ I = \\{ A_0,A_1 ... A_n\\} := \\{A_0\\} \\cup \\{A_1\\} \\cup ... \\cup \\{A_n\\} $$ Definendo ogni insieme con pi√π elementi tramite l\u0026rsquo;unione dei singoletti dei suoi elementi.\n2.2.7 Definizione dei numeri naturali e caratteristiche Definiamo ogni codifica del numero naturale partendo da $\\empty = 0$ e definendo in modo ricorsivo\n$[N + 1](/notes/n-+-1) = [N](/notes/n) \\bigcup \\{[N](/notes/n)\\}$\nUsiamo la notazione $[\\,\\,](/notes/\\,\\,)$ per le definizioni, una relazione, una implementazione di un concetto astratto\n2.2.8 Assioma dell\u0026rsquo;infinito Questo assioma permette la creazione di un insieme infinito da cui poi si possono creare i numeri, in finiti, unito all\u0026rsquo;assioma potenza si possono creare infiniti ancora pi√π grandi, dato che possiede all\u0026rsquo;interno tutte le codifiche dei numeri naturali, qualcosa di metamatematico. Alcuni matematici pensano che sia una classe.\n$$ \\exists Y(\\empty \\in Y, \\forall N(N\\in Y \\implies N \\cup\\{N\\} \\in Y)) $$ Definisce in modo univoco ogni elemento di N, partendo dagli insiemi, esiste una biunivicit√† fra elementi di questo insieme e elementi dei numeri naturali.\nAbusi di notazione\nL\u0026rsquo;insieme infinito cos√¨ definito si indica con $\\mathit{N}$\n2.2.9 Assioma dell\u0026rsquo;insieme potenza Questo insieme √® utile per espandere l\u0026rsquo;infinito ossia creare degli insiemi ancora pi√π grandi.\n√à il primo tra gli assiomi per ora esistenti che pu√≤ avere qualcosa di controverso.\n$$ \\forall X, \\exists Y, \\forall Z (Z \\in Y \\implies Z\\subseteq X) $$ Ossia l\u0026rsquo;insieme Y contiene tutti gli insiemi di X.\nAbusi di notazione\nPossiede due abusi di notazione possibili: come\n$2^{\\{1,2\\}} \\,\\text{or} \\,P(x)$\n2.2.10 Assioma di regolarit√† o fondazione $$ \\forall A (A \\neq \\empty \\implies \\exists B(B \\in A \\,\\wedge \\not\\exists C(C \\in A \\wedge C \\in B))) $$ Ogni insieme non vuoto ha un elemento dal quale √® disgiunto.\nFra le conseguenze: nessun insieme contiene (ricorsivamente) se stesso e ha quindi senso cercare di misurare la taglia (chiamata cardinalit√†) di un insieme.\nSi chiama di fondazione perch√© evita la ricorsione infinita permettendo, quindi, una fine. Sar√† in seguito su questa fine che si baser√† il concetto di cardinalit√† di un insieme.\nOssia l\u0026rsquo;insieme A deve possedere per questo assioma un elemento per cui l\u0026rsquo;intersezione sia vuota).\n2.2.11 Assioma di rimpiazzamento Questo √® un assioma dibattuto, in pratica mi dice che posso costruire un altro insieme a partire da un insieme e una funzione.\nIntuitivamente: l‚Äôimmagine di un insieme rispetto a una formula che descrive una funzione √® ancora un insieme.\nIntuitivamente: se A √® un insieme, quindi √® abbastanza piccolo, e a ogni elemento ne associo un altro, in una relazione molti-a-uno, quello che ottengo come immagine √® ancora piccolo.\nIntuizione\nData una funzione che associa elementi fra due insiemi, allora questo assioma stabilisce che l\u0026rsquo;insieme d\u0026rsquo;arrivo, l\u0026rsquo;immagine, esiste come insieme (cio√® √® un insieme ben definito\nQuesto assioma √® necessario per gli infiniti e gestire queste cose, per le cose finite non serve.`\n2.3 Regole di dimostrazione Queste regole sono presentate con maggiore rigore in Deduzione naturale\n2.3.1 Regole di introduzione e eliminazione Eliminazione mi serve per restringere sull\u0026rsquo;ipotesi, un risultato intermedio per avere qualcosa che voglio.\nQuesta eliminazione pu√≤ essere utilizzata con $\\forall X. P(X) ||\\implies$\nIntroduzione\n$\\subseteq$\n2.3.2 Abbreviazioni sia x tale che P(X) significa che prendo ogni x tale che valga quello. Probabilmente per dimostrare un certo risultato Q(X).\nDi solito si fa una lunga catena di relazioni da ipotesi che finiscono con un quindi per asserire la tesi.\n2.3.3 Esempi di dimostrazione Riflessivit√† di $\\subseteq$, Asimmetria di $\\subseteq$, transivit√† di $\\subseteq$\n2.3.4 Dimostrazione per assurdo Si utilizzano le ipotesi per dimostrare una contraddizione, per cui l\u0026rsquo;ipotesi √® falsa.\nPosso concludere qualunque cosa dopo la dimostrazione per assurdo ex-falso quodlibet abbiamo solamente dimostrato che le ipotesi sono false (quindi se le ipotesi sono binarie, √® vero l\u0026rsquo;opposto).\nSignifica che una volta giunto ad un assurdo posso dire qualunque cosa, in particolare quello che mi serviva, terminando la dimostrazione.\nL\u0026rsquo;assurdo si ha quando si ha una antinomia, un p√≤ come un paradosso in cui si conclude P e Not P.\nNON P\nsi pu√≤ definire non P come P $\\implies$Assurdo\nPoniamo che $P = \\text{true} \\,$ allora $\\bar P \\implies \\text{absurd}$ passando da qualche ragionamento, cosa che chiaramente √® contro la tesi.\nDimostrazione di ex-falso quodlibet\nIP: $P, \\bar{P}$\nHP: $B$\nessendo vera P, √® vera l\u0026rsquo;unione $P \\cup B$ partendo da questa ipotesi, e unendola con l\u0026rsquo;ipotesi $\\bar{P}$ si sa che $P$ √® falso allora $B$ deve essere vera affinch√© $P \\cup B$ sia vera. Ecco che da un assurdo si ha qualunque cosa.\n2.4 Relazioni fra insiemi Vedere la pagina di appunti sulle relazioni fra insiemi (classi di equivalenza e simili, con anche le funzioni!) Relazioni fra insiemi\n","permalink":"https://flecart.github.io/notes/teoria-assiomatica-degli-insiemi/","summary":"2.1 Elementi di base 2.1.1 Definizione e caratteristiche Tutto √® un insieme (su questo si basa la maggior parte della matematica) Efficace nella descrizione degli oggetti (infiniti √® ez), ma non √® efficiente nel calcolo in quanto non d√† nessun indizio sul\u0026rsquo;implementazione in memoria o sul modo per calcolarlo, c\u0026rsquo;√® solo una associazione Si pu√≤ concludere che per l\u0026rsquo;informatico non serve a molto questa teoria, ma √® la base per la matematica.","title":"Teoria assiomatica degli insiemi"},{"content":"The user authentication is one of the most important parts for computer security, because every security policy starts with authentication. This authentication should be easy to use, if not users will not use this. So this should be a good compromise.\nParts of authentication security security:\nRegistration Authentication check Recovery These three are the main parts of security. Some challenges in user authentication Intermediate principals A part that we will not cover are the intermediate principals which attach the mean of transmission or intermediate devices used in the transmission. E.g. a key-logger in the client system is enough to compromise the security of the authentication.\nUser identity Another problem is the user identity, how to be sure that we are talking with a specific person? With just a password authentication is often quite difficult to have this property. Some websites don\u0026rsquo;t need to know a lot about user identity, for example Amazon just needs to know your credit card, not about yourself. While others, like institutions, need to know that you are a student, so they need to know something more about you.\nPassword based authentication Why use password based? Password authentication is one of the most used. Why is that? It is user friendly, and usually convenient. The problem is that they are often easy to steal or to guess, offering no user identity verification, this is usually a problem. Most of the password on the internet are easy to guess and common names: Defense strategies So how can we defend ourselves against these attacks?\nUse the password in few places as possible Use single password for a single session (so change password). Use a password manager for these! Rate limit use. augment with second factor authentication. Rainbow attacks Usually password are stored with hashes like sha256 on the system. Another thing is that they use a slow hash function, because this would make the attacker very hard to calculate everything (and less side channel attacks). For example bcrypt is a slow one.\nRainbow attack is just -\u0026gt; Calculate hash of many common words -\u0026gt; Compare this hash to the value found in the db.\nFor this reason we hash with salt See Sicurezza OS#Autenticazione, that is random prefix or postfix saved in clear in the database to hash the password with. Would make rainbow attack much much harder.\nTwo factor authentication How 2FA helps? Weak passwords are not a problem anymore with 2FA, given if the second method is strong enough. Phishing attacks are not more useful, provided if the the attacker can\u0026rsquo;t break the second method. Implementation methods Just send a SMS with a second code, that could be used within a limited time. Time-based OTP for example the authenticator app, gives every moment some passwords, usually calculated as $H(\\text{ secret } \\mid \\text{ time })$ concatenated in this way. This is quite bad in the case the server gets compromised (change every single secret) Another downside is that it needs to be reinstalled on different phones if it is changed. Physical authentication with USB sticks. These are keys that contain the password or some other codes used to authenticate. ","permalink":"https://flecart.github.io/notes/user-authentication/","summary":"The user authentication is one of the most important parts for computer security, because every security policy starts with authentication. This authentication should be easy to use, if not users will not use this. So this should be a good compromise.\nParts of authentication security security:\nRegistration Authentication check Recovery These three are the main parts of security. Some challenges in user authentication Intermediate principals A part that we will not cover are the intermediate principals which attach the mean of transmission or intermediate devices used in the transmission.","title":"User authentication"},{"content":"Introduzione Per questa parte c‚Äô√® un sacco di roba in comune con Tecniche di definizione di semantica (4) üü©\nTrattiamo alcune caratteristiche che descrivono ad alto livello un linguaggio di programmazione. √à da notare che questa parte della spiegazione del linguaggio non √® limitante al solo linguaggio di programmazione, √® utile per analizzare tutti i linguaggi (tranne la parte di implementazione)\nSintassi üü©- Relazione fra segni. si occupa di decidere quando una frase √® corretta.\nAspetto lessicale\nIl lessico per una sintassi descrive le parole legali, In un linguaggio naturale il lessico √® descritto solamente da dizionari. Se un vocabolo non esiste nel lessico di interesse, allora √® erroneo, poi andremo a descrivere questo aspetto in modo formale\nVedere Scanner in appunti dopo\nAspetto grammaticale\nDescrive la descrizione di frasi corrette a partire dal lessico, pu√≤ essere utile in questo passo ricordarsi delle BNF Sintassi e RI strutturali del corso di logica\nPrincipalmente sono delle regole per costruire delle frasi che hanno un senso\nSemantica üü© Ossia riguardo il significato di una frase sintatticamente corretta‚Üí relazione fra segni e significato.\nLinguaggio di appartenenza\nUna stessa parola, a seconda della lingua di interpretazione, pu√≤ avere significati diversi ‚Üí FAME (fama, oppure fame?)\nVoglio utilizzare questo linguaggio per calcolare la semantica di questo linguaggio basandomi su qualcosa che gi√† esiste. (alla fine, per l\u0026rsquo;architettura esistente attuale, saranno sempre 0 e 1 di bits).\nPragmatica üü© Si occupa di studiare in quale modo le frase corrette sono utilizzate. Quindi va a rispondere a domande come ‚ÄúA cosa serve un costrutto?‚Äù, ‚ÄúCome si utilizza il comando‚Äù\nInsieme di regole per dare un indirizzo di uso\nEsempio: stile: non usare goto, scopo: questo comando fa quello e questo quindi usalo per‚Ä¶.\nDato che principalmente la pragmatica non √® presente al momento della creazione del linguaggio ma si evolve con l‚Äôuso di esso, non √® molto interessante da questo punto di vista (+ sull\u0026rsquo;ingegneria del software).\nUn altro esempio √® tipo utilizzare lei, invece del tu in contesti formali\nEsiste anche una pragmatica per la semantica Pragmatica\nIl linguaggio eseguibile üü®+ Un linguaggio formale deve soddisfare alcune regole in pi√π rispetto al linguaggio naturale, in particolare ‚Üí l\u0026rsquo;implementazione.\nEseguire una frase sintatticamente corretta in modo semanticamente corretto.\nQuindi si occupa dell\u0026rsquo;implementazione vera e propria del compilatore o dell‚Äôinterprete del linguaggio. (In questo corso si faranno solo cenni, dato che non si implementer√† tale linguaggio).\nLessico e frasi di un linguaggio Alfabeto lessico e frasi üü© Definiamo ora alcune parole fondamentali per poter parlare di linguaggi in modo formale:\nAlfabeto: a non-empty set of symbols/glyphs, typically thought of as representing letters, characters, or digits. (tipicamente finito, ma pu√≤ essere anche infinito)\nLessico: un insieme di parole finite formate da lettere dell\u0026rsquo;alfabeto che consideriamo validi\nFrasi: seguenze finite (o countably infinite, non vale per il lessico CREDO) di parole del lessico\nIl linguaggio formale üü© Sia $A$ il nostro alfabeto, e $A^0 = \\{ \\varepsilon \\}$, e $A^{n + 1} = A \\cdot A^n$ con dot un operazione di concatenazione, allora L √® un sottoinsieme solitamente finito di tutte le parole su $A$, ossia\n$L \\subseteq A^*$, $A^* = \\bigcup_{n \\geq 0}A^n$. Questo insieme si pu√≤ creare con un insieme di regole, ma anche come elenco √® corretto.\nEsempi di linguaggi\nNumerabilit√† per alfabeti Si pu√≤ dimostrare che $A^*$ formato da alfabeti infiniti √® ancora un infinito numerabile, si utilizza un argomento simile a Cantor spiegato in R e Intervalli e in Relazioni fra insiemi.\nDimostrazione numerabilit√† di A-star Questo dimostra che ogni unione di insiemi numerabili √® numerabile. C\u0026rsquo;√® una altra dimostrazione molto pi√π semplice rispetto a questa costruzione di funzioni.\nPraticamente numeriamo l\u0026rsquo;alfabeto finito che abbiamo, in ordine $\\sigma_{1} \\sigma_{2}, \\dots, \\sigma_{n}$ Allora questi hanno valore $1, \\dots, n$, poi per le stringhe nella forma $\\sigma_{1}\\sigma_{2}, \\sigma_{1}\\sigma_{3}, \\dots \\sigma_{n}\\sigma_{n}$ li metto anche ora in ordine di indice e inizio a contare da $n + 1$ e cos√¨ via. Cos√¨ so che ogni singola stringa del linguaggio ha un intero associato e posso dire che $A^{*}$ √® numerabile.\nDefinizioni operazioni di base (6) üü© Lunghezza\nViene definita in modo ricorsiva in questo modo:\nSlide\nConcatenazione\nSlide\nDeve soddisfare principalmente 3 propriet√†\nLa lunghezza della stringa risultante √® uguale alla somma della lunghezza delle singole stringhe prima parte della stringa risultato √® uguale alla prima stringa seconda parte della stringa risultato √® uguale alla seconda stringa Sottostringa, suffisso e prefisso\nSlide\n√à abbastanza banale dai, credo (in pratica posso prendere v in mezzo alla stringa di partenza mettendoci qualcosa prima e dopo\nPotenza n-esima\nSlide\nOssia provo a concatenera s√© stesso pi√π volte\nOperazioni di base su linguaggi (6) üü© Complemento\nUnione\nIntersezione\nConcatenazione\nQuesto √® la concatenazione a livello linguaggio, mentre prima era la concatenazione a livello stringa\nPotenza\nChiusura / stella di Kleene / Ripetizione\nRappresentazione del linguaggio (2) üü©- Generativo - sintetico\nNon posso rappresentare un alfabeto infinito di caratteri! Ma posso memorizzare le regole che la generano. Per esempio posso memorizzare i numeri naturali con solamente gli assiomi di peano (in particolare mi bastano 2 delle 5 regole di peano\nRiconoscimento - analitico\nSono le stringhe che vengono riconosciute da un automa che vedremo in seguito.\nMa non tutti i linguaggi sono riconoscibili da AUTOMI, resta il finito contabile come limite massimo, il motivo per cui √® questo √® perch√© le grammatiche sono equipotenti a $\\N$, mentre tutti i linguaggi sono sottoinsieme di $\\R$ e quindi non riesco a detectarlo.\nSlide grandezza di grammatiche ed alfabeti\nGrammatiche e BNF Def grammatica libera (4) üü© √à una quadrupla di\nNon terminali (insieme finito, indicato di lettere maiuscole) Terminali (insieme finito, indicato da lettere minuscole) Simbolo iniziale (simbolo speciale non terminale) Produzioni (ricorda qui che la grammatica libera si pu√≤ rappresentare con questa) Backus Naur-Form üü© In questa sezione cerchiamo di definire in modo pi√π dettagliato le BNF introdotte nella lezione di logica di Sintassi e RI strutturali trattati in logica.\nSlide esempio di una BNF per palindromi\nStesso precedente, ma scritto tramite la sintassi delle grammatiche\nDefinizione tramite assiomi\nDefinizione in via ricorsiva\nIndichiamo con $L(P)$ il linguaggio generabile a partire da un P, con le regole di inferenza di sopra\nL‚Äôunica differenza con le grammatiche libere √® la sintassi differente per la descrizione di essa (utilizzo delle \u0026lt;\u0026gt;), ma storicamente credo che si siano evolute in modo distinto, e poi si sono accorti che erano la stessa cosa\nDerivazioni (leftmost e rightmost) üü©‚Äî Definizione di derivazione immediata\nSia $G = (NT, T, R, S)$ una grammatica libera da contesto, si dice che $v$ deriva immediatamente da $w$, indicato con $w \\implies v$, quando $\\exists (A \\to z) \\in R$, con $R$ le produzioni e $A \\to z$ una produzione, e $w = xAy$, e $v = xzy$\nIn altre parole posso dire che una stringa √® derivata in modo immediato da una altra stringa quando posso ricavarla con una singola operazione di una funzione presente in produzione.\nSlide definizione derivazione immediata\nDefinizione derivazione ‚Äúgenerale‚Äù\nPosso affermare che da $v$ si deriva $w$ quando esiste una sequenza finita (anche vuota) di derivazioni immediate tali che\n$$ v \\implies w_0 \\implies ... \\implies w $$ Tale cosa √® riscritta come $v \\Rightarrow^* w$\nSlide Definizione di Derivazione generale (!!!)\nDerivazione left e rightmost\nConcetto di derivazione left e right most\nIl concetto pi√π generale √® che nel processo di derivazione di una stringa in un linguaggio viene sempre espanso il non terminale pi√π a sinistra.\nCheck appartenenza\nSi pu√≤ verificare che una stringa appartiene a un certo linguaggio descritto in modo formale come sopra se si pu√≤ creare un albero di derivazione\nEsempio di derivazione\nLinguaggio generato da grammatica üü© Data una grammatica $G = (NT, T, R, S)$ a contesto libero definiamo il linguaggio libero $L(G)$ generato dalla grammatica come\n$$ L(G) = \\{ w \\in T^* : S \\Rightarrow ^* w\\} $$ Ossia in parole umane, tutte le stringhe terminali generabili da quella grammatica.\nSlide definizione\nAlberi di derivazione Un albero di derivazione √® una rappresentazione molto utile per un compilatore per comprendere la struttura interna intermedia. fornisce informazioni semantiche!\nDefinizione albero di derivazione (5) + 1 üü®+ presenta alcune propriet√† dell‚Äôalbero, che √® invariante rispetto all‚Äôalbero, questa osservazione ci d√† anche un hint per la definizione del concetto di ambiguit√† per grammatiche e linguaggi.\nUna altra osservazione importante √® che possiamo associare un albero di derivazione a ogni Derivazione.\nDefinizione albero di derivazione (5) + 1 üü®+ Vogliamo descrivere la struttura di un albero di derivazione generale\nLa radice √® il non-terminale iniziale ossia $S$ Tutti i nodi hanno simboli in $NT \\cup T \\cup \\{\\varepsilon \\}$ I nodi interni hanno solo simboli $NT$ Esiste una relazione diretta fra padre e figli definiti da una produzione, pi√π in generale se $A\\in NT$ e $x_1,..., x_n$ sono nodi figli, esiste una produzione $A \\to x_1, ..., x_n$ Se $\\varepsilon$ √® su un nodo, allora quella √® una foglia ed esiste la produzione $A \\to \\varepsilon$, con A l‚Äôetichetta per il parent Inoltre andiamo a chiamare albero di derivazione COMPLETO se ogni foglia √® un terminale.\nSlide\nRelazione con derivazione üü®+ Si pu√≤ dimostrare che una stringa appartiene a un linguaggio, solo se esiste un albero di derivazione per essa in quel linguaggio, quindi √® un buon metodo per descrivere la derivabilit√† in modo non-ambiguo.\nIdee per la bigezione\nChiaramente se vado Derivazione ‚Üí Albero √® una cosa abbastanza ovvia perch√© √® il modo con cui si crea l‚Äôalbero\nSe vado nella direzione Albero ‚Üí Derivazione (dx, sx) sto facendo in pratica una DFS che espande sempre il primo a sinistra o primo a destra di non terminali, e ho anche bisogno di una funzione che sia in grado di restituirmi una stringa data dalle foglie, fatto ci√≤ dovrebbe essere easy.\nAlberi sintattici üü© Quando abbiamo un albero di derivazione completo, possiamo estrarre l‚Äôalbero formato dalle foglie, come in figura, per avere un albero che abbia qualche informazione riguardo la semantica di quanto descritto.\nEsempio estrazione albero sintattico\nAlbero di sintassi concreta o Astratta C‚Äô√® una leggera differenza fra sintassi astratta e concreta.\nDi sotto, durante la risoluzione delle ambiguit√† facciamo uso delle parentesi per disambiguare, questo utilizzo delle parentesi √® presente nell‚Äôalbero di sintassi concreta, anche chiamato parse tree.\nInvece l‚Äôalbero di sintassi astratta pu√≤ essere ambigua, rappresenta una astrazione sulla sintassi concreta del linguaggio e spesso √® ambigua.\nEmail mandata, in TODO\nAlbero di derivazione\n√à l\u0026rsquo;albero che soddisfa le 6 propriet√† presentate (radice √® il non terminale iniziale, i nodi\ninterni sono etichettati come non terminali, etc..).\nAlbero di sintassi concreta\n√à l\u0026rsquo;albero che rappresenta tutta la sintassi del programma (con anche zucchero sintattico)\nQuesto albero inoltre¬†√® un albero di derivazione¬†perch√© soddisfa tutte le propriet√†.\nAlbero di sintassi astratta√à formato solamente dalle foglie dell\u0026rsquo;albero di sintassi concreta, senza le foglie dovute allozucchero sintattico, quindi non √® un albero di derivazione perch√© non soddisfa le propriet√†di essa (e.g. nodi interni non terminali) e contiene informazioni semantiche riguardo al programma.\nAmbiguit√† Tipologie di ambiguit√† (con esempi 2) üü©- Ambiguit√† nella grammatica\nSi pu√≤ dire che una grammatica √® ambigua se esistono due alberi di derivazione differenti per una stessa stringa.\nEsempio di ambiguit√† per alberi di derivazione\nEsempio di grammatica ambigua\n$$ S \\to A | \\varepsilon \\\\ A \\to \\varepsilon $$ Questo linguaggio genera solamente dei vuoti, ma lo pu√≤ fare in modi diversi eg:\n$S \\to \\varepsilon$, o $S \\to A \\to \\varepsilon$\nUna altra grammatica che descrive il linguaggi equivalente non √® per√≤ ambiguo\n$S \\to \\varepsilon$\nAmbiguit√† nel linguaggio\nSi pu√≤ dire che un linguaggio √® ambiguo se ogni sua grammatica √® ambigua.\nEsempio di linguaggio ambiguo\nRisoluzione delle ambiguit√† üü© In modo simile a quanto trattato in Sintassi e RI strutturali bisogna stabilire:\nOrdine di precedenza degli operatori\nEsempio di problema di precedenza\nAssociativit√† sinistra o destra\nEsempio di necessit√† di associativit√† dx e sx\nParentesi\nQuesto √® un zucchero sintattico che non ha nessun valore semantico che aiuta a disambiguare la precedenza. (L\u0026rsquo;albero semantico non serve avere le informazioni sulle parentesi) Questo √® necessario per essere equivalente semanticamente ossia possono generare ora gli stessi alberi semantici Aggiunta parentesi\nGrammatica ambigua:\n$$ S = a|b...|S + S|S\\times S $$ Soluzione ambiguit√†\n$$ E = E + T | T \\\\ T = A \\times T | A \\\\ A = a|b ...| (E) $$ ","permalink":"https://flecart.github.io/notes/descrizione-linguaggio/","summary":"Introduzione Per questa parte c‚Äô√® un sacco di roba in comune con Tecniche di definizione di semantica (4) üü©\nTrattiamo alcune caratteristiche che descrivono ad alto livello un linguaggio di programmazione. √à da notare che questa parte della spiegazione del linguaggio non √® limitante al solo linguaggio di programmazione, √® utile per analizzare tutti i linguaggi (tranne la parte di implementazione)\nSintassi üü©- Relazione fra segni. si occupa di decidere quando una frase √® corretta.","title":"Descrizione linguaggio"},{"content":"6.1 Codifiche Si utilizzano codifiche, che sono delle convenzioni, qualcosa che un gruppo di umani ha deciso fosse utile darci un significato.\n6.1.1 Codifica posizionale Dove $d_i$ √® il valore in posizione $i$ e $b$ √® la base\n$$ \\sum_{i=0}^k d_ib $$ 6.1.2 Ottale, esadecimale e binario Queste sono le codifiche principali per i computer in quanto sono comodi da visualizzare. Inoltre Ottale e esadecimale in particolare sono riassunti dei binari, cio√® sono dei sottoinsiemi che possiedono ancora tutte le caratteristiche e quindi sono comodi\n6.1.3 Conversione di base Se la conversione √® fra ottali, esadecimali o binari allora √® molto semplice perch√© basta prendere un gruppo di bit e caricare un numero a seconda di quanto valga, la conversione dovrebbe essere abbastanza semplice.\nAnche la conversione da questi in base 10 non √® difficile, basta utilizzare la formula in codifica posizionale\nTecnica delle conversioni successive BIN‚Üí DEC\nQuesta √® una tecnica leggermente diversa ma fatta per parti piccoline, parti dal numero pi√π significativo e da l√¨ moltiplichi ogni volta per 2 e aggiungi 1 se c\u0026rsquo;√®.\nDEC ‚Üí BIN\nSi continua a dividere per due e si tiene il resto come risultato del numero binario.\nQuesto corrisponde al contrario delle conversioni successive\n6.2 Numeri negativi 6.2.1 Modulo e segno Un primo modo di codificare √® solamente prendere la cifra pi√π significativa come se fosse un uno e contare in modo uguale, ma questa codifica non √® molto utile poi per la somma, bisogna inventare un nuovo metodo.\n6.2.2 Complemento a 1 Il complemento a 1 √® praticamente la negazione del valore di 1. La cosa che non funziona √® che la somma non funziona perfettamente, esiste un zero positivo e un zero negativo, mentre invece per il complemento a 2 funziona grazie al modulo.\nQuesta codifica riesce a fare, dati $k \\text{ bit }, [-2^{k - 1} + 1, 2^{k-1} - 1]$ Per esempio -127 e 127\nSomma\nLa somma del complemento a 1 deve tenere conto del riporto se esiste (probabilmente causato dall\u0026rsquo;esistenza di uno 0 negativo), invece il complemento a due no.\n6.2.3 Complemento a 2 Il complemento a 2 √® fattibile a con questa formula:\ndati $b_{k},b_{k-1}...b_0$ con ogni $b$ i valori in rappresentazione binaria del numero, il numero nella forma decimale corrispondente √®\n$$ x = \\sum_{i=0}^{k-1}b_{i}2^k - b_k 2^k $$ In pratica √® il complemento a 1 sommato 1, si pu√≤ vedere mettendo tutti i numeri su un cerchio e notare che il complemento a 2 ha la parte negativa spostata di uno, in particolare si pu√≤ dire che il complemento a 2 utilizza il modulo.\n$k \\text{ bit }, [-2^{k - 1}, 2^{k-1} - 1]$, per esempio -128 fino a 127\n6.2.4 Codifica in eccesso Ad alcuni non piace che lo 0 si trovi proprio a 00000000, quindi lo metto a 10000000, cos√¨ a 0000000 ho il numero pi√π piccolo rappresentabile. In pratica sto sommando due alla k-1 rispetto alla rappresentazione normale di complemento a due.\nScelte, non so perch√© lo facciano per√≤.\n6.3 Floating point 6.3.1 La codifica Bisogna definire una mantissa(frazione) e caratteristica(esponente) e segno sono gli elementi pi√π importanti per la definizione di un floating point:\nIn particolare rappresentiamo N come $f \\times 10 ^{e}$ con f frazione e e esponente.\nLa mantissa √® definita tramite esponenti negativi.\n6.3.2 Overflow e underflow Questa codifica ha degli errori nella rappresentazione di numeri troppo grandi o troppo piccoli\n6.3.3 ISEE 754 Questo √® lo standard industriale per codificare floating points numbers.\n√à costituito da un totale di 32 bit per BINARY32, ma esiste anche il BINARY64 che utilizza un ragionamento molto simile per i floating points:\n1 bit per segno 8 per l\u0026rsquo;esponente 23 per la mantissa 6.3.4 Tecnica codifica Per trovare la codifica di un floating point, si moltiplica per due il numero che si deve codificare, e ogni volta che l\u0026rsquo;unit√† √® un uno si mette un uno, altrimenti uno zero, questo perch√© la moltiplicazione equivale a uno shift a sinistra.\n6.4 Caratteri Creo una funzione binaria per ogni carattere esistente, storicamente si utilizzavano 8 bit per fare questa codifica, di cui i primi 32 erano caratteri speciali per la stampa tipografica, altri erano utilizzati per maiuscole e minuscole e caratteri speciali\n6.4.1 ASCII American Standard Code of information exchange, √® la codifica storica per i caratteri, questa codifica per√≤ non bastava perch√© bisognava aggiungere codifiche per caratteri non alfabetici oppure agli emoji\n6.4.2 Unicode √® l\u0026rsquo;espansione con 16 bit al posto di 8 ma sono finiti molto presto e quindi c\u0026rsquo;√® bisogno di qualche altra forma che possa essere molto pi√π sicur\n6.4.3 UTF-8 Questa √® il nome della codifica moderna che permette di avere molti altri caratteri invece che solamente i caratteri dell\u0026rsquo;alfabeto inglese. (esempio gli accenti italiani sono codificati con UTF-8)\nDinamico in quanto pu√≤ prendre da 1 a 4 byte in modo dinamico.\nEsiste anche UTF-16 ma non √® ancora diffuso come UTF-8\n6.5 Errori 6.5.1 Necessit√† di errori Raggi cosmici, (mandare segnali a sonde spaziali √® molto facile avere interferenze e gli errori sono comuni) Errori di memorizzazione di trasmissione Vibrazioni e radiazioni dell\u0026rsquo;ambiente circostante, quindi vogliamo trasmettere in modo che non ci siano errori di trasmissione. A volte non c\u0026rsquo;√® necessit√† di controllare errori: esempio il protocollo UDP\nOppure se voglio fare una transazione il codice di errore allora √® molto pi√π importanti\n6.5.2 Parola codice Sto aggiungendo a m bit r bit di controllo e prendo n = m + r come la parola codice che contiene\nInformazioni di controllo correttezza (si prende che ci sia una probabilit√† molto piccola di errori). Informazioni da trasmettere 6.5.3 Costo controllo delle informazioni C\u0026rsquo;√® una differenza fra la correzione di un errore e il rilevamento, la correzione √® molto pi√π dispendiosa. C\u0026rsquo;√® un modo per correggere in modo semplice? Con poco costo?\n6.5.4 Distanza di Hamming Praticamente √® il numero di 1 dopo che si ha uno xor fra tutti.\nPer rappresentare di mettono n numeri in un cubo n dimensionale, e si valuta la distanza fra i due.\n6.5.5 Minima distanza per trovare un errore The minimum Hamming distance is used to define some essential notions in coding theory, such as error detecting and error correcting codes. In particular, a code C is said to be k error detecting if, and only if, the minimum Hamming distance between any two of its code-words is at least k+1.\nCome mai per trovare un errore su d bytes servono d + 1 bits? come mai per corregger di pi√π?\n6.5.6 Minima distanza per correggere un errore A code C is said to be k-errors correcting if, for every word w in the underlying Hamming space H, there exists at most one codeword c (from C) such that the Hamming distance between w and c is at most k. In other words, a code is k-errors correcting if, and only if, the minimum Hamming distance between any two of its codewords is at least $2k + 1$. This is more easily understood geometrically as any closed balls of radius k centered on distinct codewords being disjoint. These balls are also called Hamming spheres in this context.\nAssunto massimo un bit sbagliato abbiamo che il codice correttore deve soddisfare\n$2^m(1 + n) \\leq 2 ^n$\nIl bit di parit√† utilizza tanti bit.\nUna parola pu√≤ essere solo una sbagliata e poi m modi di sbagliarla ancora\n6.5.7 Studio del bit parit√† In pratica √® lo Xor fra tutti i bit della parola, quindi molto utile per scoprire errori di un singolo bit. Utile per rilevare gli errori.\n6.5.8 Codice di hamming Sull\u0026rsquo;ALU Ci sono alcune operazioni interessanti per come l\u0026rsquo;ALU calcola ci√≤ che calcola\nDimostrazione trucco per sottrazione !\nE poi nel caso + 1, basta sommare - 1, che si conosce\nShifters ","permalink":"https://flecart.github.io/notes/rappresentazione-delle-informazioni/","summary":"6.1 Codifiche Si utilizzano codifiche, che sono delle convenzioni, qualcosa che un gruppo di umani ha deciso fosse utile darci un significato.\n6.1.1 Codifica posizionale Dove $d_i$ √® il valore in posizione $i$ e $b$ √® la base\n$$ \\sum_{i=0}^k d_ib $$ 6.1.2 Ottale, esadecimale e binario Queste sono le codifiche principali per i computer in quanto sono comodi da visualizzare. Inoltre Ottale e esadecimale in particolare sono riassunti dei binari, cio√® sono dei sottoinsiemi che possiedono ancora tutte le caratteristiche e quindi sono comodi","title":"Rappresentazione delle informazioni"},{"content":"Introduzione (idea principale) In breve: essence card üü©- Giallo = Prodotto. Metafora staffetta-rugby üü© Con altri metodi si fanno produzioni stile staffetta, ossia un membro sta fermo, finch√© non ha il testimone e poi si uccide correndo\u0026hellip; Il metodo pi√π utile ispirato a scrum √® rugby, che tutti si muovo insieme collaborando. Un po\u0026rsquo; di tutto √® fatto durante lo sprint\nCicli di base (3) üü© Planning: in cui vengono scelti i task da eseguire durante questo sprint, solitamente questo viene preso da un subset dei task descritti dal product owner. Execution: questo √® abbastanza chiaro, si sviluppa. Retrospective and review: in cui vengono identificati i problemi che sono stati incontrati durante lo sviluppo, e modi possibili per risolverli. Lo sprint (3) üü©- Una cosa molto importante che aiuter√† di gran lunga lo sviluppo √® la costanza che Si scelgono\nTask READY che vengono fatte Queste vengono spostate in done quando sono fatte E poi vengono testate, questo per tutto il prodotto. Questo lo guarderemo in una sezione successiva.\nRuoli Introduzione in generale ai ruoli (3) üü© Product owner: deve rappresentare il cliente e scrivere le features pi√π interessanti per il team, sempre secondo ci√≤ che deve essere utile per il cliente.. Scrum Master deve cercare di eliminare gli ostacoli. Esempio: persone che litigano internamente al team Persone lavorano meno e non portano risultati, e si isola. Developer chi sviluppa. All\u0026rsquo;esterno ci sono gli stakeholders che sono in pratica i clienti, vuole cercare di capire esattamente cosa debba essere fatto.\nIn breve: Dinamiche del team üü® Auto-organizzazione, ossia il team stesso dovrebbe definire i suoi ruoli TODO: definire questa parte meglio, in che sensi si dovr√† auto-organizzare il team? Scrum pillars Scrum team A Scrum team is a group of individuals who work collaboratively to deliver high-quality product increments. The team is typically composed of a Scrum Master, a Product Owner, and Developers. The Scrum Team is cross-functional, self-organizing, and responsible for all product-related activities, including stakeholder collaboration, verification, maintenance, operation, experimentation, research, and development. The team is structured and empowered by the organization to manage their own work, and they work in Sprints at a sustainable pace to improve focus and consistency. The Scrum Team is small enough to remain nimble and large enough to complete significant work within a Sprint, typically consisting of 10 or fewer people. The team is focused on achieving the Product Goal and shares the same Product Backlog and Product Owner. The Scrum Team embodies the principles of transparency, inspection, and adaptation, and is essential for the successful implementation of the Scrum framework in delivering valuable products https://www.visual-paradigm.com/scrum/what-is-scrum-team/ Product Owner √à il membro del team che si relaziona con gli stakeholders esterni. rappresenta il punto di vista del cliente e deve essere in grado di descrivere il prodotto al team. Dato che √® il cliente che stabilisce le priorit√†, dovrebbe gestire le priorit√† (massimizza il valore dei rilasci). Dato che √® la figura che va con i clienti, deve anche essere in grado di recepire i cambiamenti di mercato e comunicarlo per bene al team. Deve sapere cosa prioritizzare per avere prodotto migliore nelle prossime iterazioni seguendo i dati che vengono raccolti durante lo scrum.\nResponsabilit√†\nProduct Goal. Triangolo di Ferro (3) Scope Cost Time Si tratta di migliorare la qualit√† del software restando dentro a questi limiti. √à anche una cosa che dovrebbe essere per Project Management, ossia quello che il manager deve considerare per fare stime dei progetti e consegnare pi√π qualit√†. In waterfall √® lo scopo la dimensione costante, cambiano le altre due.\nEventi scrum Riassunti eventi scrum (!!) (4) üü© Planning, in cui si scelgono le cose da fare Review, in cui si analizza quanto bene si √® fatto Retrospective, in cui si guarda come si potrebbe migliorare Daily Standup, feedback su quanto siamo messi. Sprint planning (2) üü© Si tengono in conto vari fattori (vedi immagine), e a seconda di questi vogliamo avere due output\nGOAL, l\u0026rsquo;obiettivo del nostro sprint Planning Chi fa cosa Il backlog presente Planning Poker üü© √à un gioco per stimare il tempo dei task https://planningpokeronline.com/ che √® molto divertente. Solve il problema di stimare il tempo necessario per fare qualcosa.\nVelocit√† sprint üü© Si pu√≤ intendere come il numero di story point completati, che solitamente √® dipendente da qualcosa di passato. Questo serve per stimare quanto si riuscir√† a fare negli sprint successivi.\nSprint review üü© In cui √® presente una demo del prodotto, con anche magari gli stakeholders Una specie di presentazione e pi√π gente forse :). Quindi si ha un feedback su quanto fatto per il prodotto durante lo sprint.\nSprint retrospective (3) üü© Si parla di ci√≤ che\nStart doing (che magari potrebbe aiutare, che prima non si faceva) Stop Doing che magari √® una cosa tossica da fare, non aiuta, e prende tempo Continue doing se va ancora bene √à sempre all\u0026rsquo;interno di scrum un modo per vedere se si pu√≤ migliorare il modo di lavorare. Artefatti Product backlog üü© Qui trattiamo l\u0026rsquo;insieme degli aspetti utili a gestire tutti i task che dovranno essere fatti\nGestione del backlog üü© La scelta dei singoli task √® fatta in maniera volontaria da parte di chi lavora. Il lavoro-board deve essere aggiornato volta volta in cui si continua a starci sopra. User story mapping üü© L\u0026rsquo;idea √® gi√† dividere task per task, nei sprint corretti.\nEsempi di mapping possibili Burndown chart üü© In pratica il numero totale di ore che sar√† una stima di quanto fatto.\nCaso ideale: lineare. Sono quindi dei grafici per valutare qualit√† del lavoro\nConclusioni Meta-scrum Cause effetti negativi NOTA: questa alla fine non √® scienza, si fa fatica a fare uno studio comparativo che cerchi di identificare se funziona o meno questo metodo, √® solamente\nDefinizioni di fatto o finito The DoR outlines the criteria that a specific user story must meet before being considered for estimation or inclusion into a sprint. It describes the characteristics of an effective user story and ensures that the team has a shared understanding of what\u0026rsquo;s needed for a user story to be brought into a sprint. The DoR is optional and is particularly useful when aspects of user stories are impeding progress, leading to stories being rolled into the next sprint. It is focused on user story level characteristics and is changeable based on the team\u0026rsquo;s needs\nThe DoD is a shared understanding among team members of what it means for a product backlog item (PBI) to be considered complete. It applies to all work in the backlog and represents the acceptance criteria for a sprint or release. The DoD outlines the quality standards that a piece of work needs to reach to be releasable. It is essential for ensuring consistent delivery of quality and is often standardized across the company. The DoD is changeable and may need to be adjusted based on the team\u0026rsquo;s needs\nMancanze di supporto Scrum master che non fa il lavoro Cattiva comunicazione di PO Cattiva comunicazione dei desiderata da parte degli stakeholders. ","permalink":"https://flecart.github.io/notes/scrum-method/","summary":"Introduzione (idea principale) In breve: essence card üü©- Giallo = Prodotto. Metafora staffetta-rugby üü© Con altri metodi si fanno produzioni stile staffetta, ossia un membro sta fermo, finch√© non ha il testimone e poi si uccide correndo\u0026hellip; Il metodo pi√π utile ispirato a scrum √® rugby, che tutti si muovo insieme collaborando. Un po\u0026rsquo; di tutto √® fatto durante lo sprint\nCicli di base (3) üü© Planning: in cui vengono scelti i task da eseguire durante questo sprint, solitamente questo viene preso da un subset dei task descritti dal product owner.","title":"Scrum Method"},{"content":"6.1 Introduzione 6.1.1 L‚Äôimportanza del topic Gli algoritmi di ordinamento sono molto di base per la comprensione dell\u0026rsquo;ampio raggio degli algoritmi. Utilizzano l\u0026rsquo;analisi, introducono tecniche di risoluzione dei problemi computazionali come greedy, divide et impera e simile. Permettono un primo uso di astrazioni e l\u0026rsquo;analisi di sottoproblemi.\n6.1.2 Il problema Il problema √® trovare una permutazione di un insieme di numeri iniziali tale per cui tale insieme di numeri si ordinato:\nQuesto si pu√≤ fare con qualunque collezione confrontabile fra di loro.\nSlide\nLoco: non vengono utilizzati array di appoggio, per esempio un quicksort sar√† di in loco, mentre mergesort no.\nStabile: se due elementi hanno la stessa chiave, questi compaiono con lo stesso ordine nell\u0026rsquo;array ordinato, per esempio radix sort √® stabile, merge sort √® stabile.\n6.2 Algoritmi incrementali Si possono dire incrementali algoritmi che si dimostrano in \u0026ldquo;maniera greedy\u0026rdquo;, ossia creano un sottoaray ordinato k, e al prossimo passo provano a creare un array k + 1.\n6.2.1 Selection sort Si trova l\u0026rsquo;elemento pi√π piccolo all\u0026rsquo;interno di $(k+1,n)$ e lo si swappa con quello in posizione k + 1, si continua cos√¨ fino a quando l\u0026rsquo;array non sia ordinato. NO stabile (spara dall\u0026rsquo;altra parte l\u0026rsquo;elemento con cui swappa).\nUna propriet√† che possiede selection ma non insertion √® che:\n$\\forall e \\in (1,k), \\forall b \\in (k + 1, n), e ","permalink":"https://flecart.github.io/notes/algoritmi-di-ordinamento/","summary":"6.1 Introduzione 6.1.1 L‚Äôimportanza del topic Gli algoritmi di ordinamento sono molto di base per la comprensione dell\u0026rsquo;ampio raggio degli algoritmi. Utilizzano l\u0026rsquo;analisi, introducono tecniche di risoluzione dei problemi computazionali come greedy, divide et impera e simile. Permettono un primo uso di astrazioni e l\u0026rsquo;analisi di sottoproblemi.\n6.1.2 Il problema Il problema √® trovare una permutazione di un insieme di numeri iniziali tale per cui tale insieme di numeri si ordinato:","title":"Algoritmi di ordinamento"},{"content":"Reti di Reti Le parti importanti per questo sono Data Plane e Control Plane (che ha saltato quasi tutto, ma almeno dijkstra lo dovresti fare bene)\nIntroduzione (puoi skippare üü©) La puoi skipppare perch√© tratta in modo molto generare parti che saranno trattati in modo pi√π approfondito in seguito. La parte importante forse √® il riassunto di cosa faccia questo livello.\nDiscussione rete locale globale Slide\nNo, non √® possible creare una connessione globale utilizzando le tecnologie locali, come hub, switch e simili, perch√© causerebbe flooding e impedirebbe scalabilit√† e crescita dinamica che √® classica della rete\nSe i milioni di calcolatori oggi connessi a Internet fossero tutti organizzati secondo i protocolli e gli schemi visti finora per le reti locali, la comunicazione tra due calcolatori su Internet richiederebbe di passare per migliaia di calcolatori intermedi, switch, bridge, segmenti di rete, ognuno dei quali aggiungerebbe ritardi di gestione, complessit√†, rischi di errore. Il problema dell‚Äôinstradamento dei frame (routing), ovvero il decidere da che parte o su che segmento deve essere inoltrato un frame per raggiungere il destinatario finale, richiederebbe in ogni dispositivo una lista completa (tabella di instradamento) di tutti gli indirizzi MAC dei dispositivi nel mondo, con a fianco l‚Äôindicazione della direzione di inoltro. Ovviamente questo limiterebbe in modo critico la scalabilit√† e la crescita di Internet. Inoltre causerebbe flooding perch√© praticamente ogni pacchetto di ogni computer rete di internet dovrebbe passare da ogni computer.\nUna soluzione semplice consiste nell‚Äôelezione di un rappresentante per ogni rete locale X (e indichiamo con la rete sotto di essa come dominio di rete locale) (il router di X), incaricato di ricevere tutti i pacchetti dati destinati a uno dei calcolatori della rete locale (es. mac1 di X, mac2 di X, ecc.). Ricevuti i pacchetti destinati alla rete locale, il router potrebbe occuparsi di recapitare alla rete locale i pacchetti, come se si trattasse di un frame a livello MAC/LLC destinato all‚Äôindirizzo MAC del destinatario. Allo stesso modo, ogni router dovrebbe farsi carico di inoltrare tutti i pacchetti uscenti dalla propria rete locale, verso i router delle reti di destinazione. Per rispettare le direttive dettate dallo standard ISO/OSI, il livello di indirizzamento e la gestione dell‚Äôinstradamento dei pacchetti tra i router vengono gestiti al terzo livello (rete) della gerarchia dei protocolli di Internet.\nPer ci√≤ che riguarda i router, tuttavia, lo scambio diretto tra router di pacchetti destinati alle rispettive reti locali potrebbe ridurre molto la complessit√† dell‚Äôinstradamento. I router comunicano quindi attraverso collegamenti dati molto veloci, dette dorsali (backbone). Ogni router deve ricordare in una tabella di instradamento (forwarding table) solo quale sia il primo router intermedio per raggiungere ogni altro router. La visione del sistema al terzo livello (Rete) da parte dei router √® quindi simile alla visione che appare a destra nella figura. Si nota come tutti i dettagli delle reti locali siano di fatto nascosti dai router a questo livello.\nIl router deve avere una mappa fra gli indirizzi IP e i mac!\nObiettivi generali del livello (6) (!) üü•+ Sintassi\nStruttura gerarchica fra dominio e host (per facilitare l‚Äôinvio) Busta a livello arancione, terzo livello. Semantica\nFrammentazione dei dati Questa parte non √® pi√π esistente per gli IPv6, perch√© √® un overhead in pi√π che non si vuole dare ai router Si occupa solamente di inviare. Un motivo per cui succede √® l‚Äôefficienza, tenere in memoria questa cosa √® molto costosa. I router devono solamente tritare pacchetti! Forwarding dei pacchetti, inoltramento dei pacchetti O ricezione del pacchetto se √® giusto. Non si occupa di affidabilit√† del trasporto (di cui si occupa il livello mac e trasporto) Hardware (operazionale credo)\nDispositivi fisici di questo livello, come i router (quindi tabelle di instradamento e protocollo di instradamento e aggiornamento) Protocollo di rete Slide1\nSlide2\nIn questa parte iniziamo ad analizzare il concetto di rete globale, ossia non √® pi√π locale!\nIl livello rete di Internet si basa sul protocollo IP (Internet Protocol). Il protocollo IP definisce un nuovo schema di indirizzamento globale e gerarchico, che permette di identificare univocamente tutti i dispositivi di rete e allo stesso tempo la loro rete locale di appartenenza. Gli indirizzi usati permettono di identificare intere reti locali come un riferimento singolo nella gestione dell‚Äôinstradamento dei pacchetti. Questo fatto semplifica molto la visione della rete che appare al livello Rete. Al protocollo IP, si possono associare protocolli di instradamento dei pacchetti dal mittente al destinatario finale (forwarding), originando servizi di trasmissione a pacchetto di tipo connectionless. Il protocollo IP richiede l‚Äôadozione di nuovi dispositivi amministratori dell‚Äôinoltro dei pacchetti a livello Rete, detti router.\nRouter I router sono forniti di tabelle di instradamento che illustrano la topologia della rete vista al livello dei router stessi (quindi non √® necessario conoscere gli indirizzi dei calcolatori di una LAN al di fuori della LAN stessa. I router devono implementare protocolli di aggiornamento delle tabelle di instradamento (detti protocolli di routing). Ulteriore compito dei router √® la gestione della frammentazione dei dati da spedire nei pacchetti, e la creazione della busta di livello rete con gli indirizzi del router mittente e destinatario di ogni pacchetto inoltrato.\nSono improntate alla efficienza! Principalmente √® solo hardware che √® in grado di far arrivare e partire un pacchetto a ogni ciclo di clock.\nNon self-similar üü© Si √® tentato di cercare di predire i dati futuri pensando a quanti dati ho ora. Ma si √® scoperto che non √® proprio possibile, perch√© ci sono dei burst di richieste, dipendenti dalle richieste delle singole applicazione, per questo motivo sembra che sia un sistema caotico (esempio della farfalla). Principalmente perch√© questo √® dipendente dai media (es. youtube).\nIndirizzo IP Gli indirizzi IP sono una nuova specie di indirizzi rispetto al MAC, necessari per il Protocollo omonimo;\nHeader IP üü®++ Slide del formato IP\nQuesto √® il bellissimo pacchetto di livello trasporto üôÇ. NOTA: vedi che contiene il pacchetto dello stato superiore.\nVersion sono 4 bit per la versione. Dimensione dell\u0026rsquo;header in byte (che il campo options lo rendere variabile). Il campo Type of Service, o TOS, definisce il valore di priorit√†, di cui abbiamo parlato Scheduling dei routers (3+) üü©. Che √® principalmente utilizzato in internet due (basta un router che non lo sia e fa droppare le garanzie). (solitamente √® ignorato). 16 bit per la lunghezza, quindi al massimo posso mandare 65k nel payload. L‚Äôidentificazion di 16 + cose bits √® per capire la targa, meglio per la frammentazione (quel sistema per spezzattare file lunghi e inviarli a pezzetti), sono ricomposti a destinazione, il router lo ignora üôÇ, l\u0026rsquo;ultimo ha flag a 0, e offset pi√π lungo Time to live √® una cosa che viene decrementata ad ogni router e viene dropatto il pacchetto se vado a 0 Upper layer √® il protocollo di livello 4 da utilizzare. Per verificare se non ci sono stati errori di trasmissione. (Che √® molto facile da manipolare, per√≤ buono per errori a caso di trasmissione). Alcune opzioni tipo la rotta da prendere (tipo i router da visitare), itmestamp, La cosa √® che questa parte √® variabile.\nC\u0026rsquo;√® un overhead di 40 bytes!.\nFrammentazione e Reassembly üü© Per questa parte concetti importanti da comprendere sono:\nPerch√© si fa frammetnazione (MTU) e perch√© si riassembla solamente alla fine. Campi dell‚Äôheader IP utili alla frammentazione e perch√© vengono utilizzati. Non ha molto senso fare reassembly in mezzo, perch√© il pacchetto potrebbe fare una altra strada, sono indipendenti una volta spediti.\npoi si potrebbero fare fragmentation anche in un router intermedio, si potrebbero fare fragmentation ancora dopo! Frammentazione √® necessaria se il pacchetto √® pi√π grande del MTU Maximum Transfer Unit.\nSlide esempio di fragmentazione\nStruttura IPv4 üü© Un indirizzo IPv4 √® un valore espresso su 32 bit (4 Byte), e pu√≤ essere espresso anche come sequenza di 4 valori decimali, separati da punto. Ogni valore decimale pu√≤ essere compreso tra i valori 0 e 255. Un esempio di indirizzo IP valido √® (130.136.250.1).\nOgni indirizzo IP √® sempre composto da due parti:\nnumero della rete IP alla quale appartiene la scheda (network number), numero dell‚Äôinterfaccia di rete (host number) all‚Äôinterno della rete IP. Esistono dei numeri speciali per ogni rete:\nHost tutti 0 e tutti 1\nTutti 0 ‚Üí indica la rete stessa Tutti 1 ‚Üí indica l‚Äôindirizzo di broadcast Datagramma IPv6 Slide IPv6\nIL nextheader dice il protocollo che sta sopra, stesso di upper level di sopra\nIl campo priority √® siile al Type of service, ci da la priorit√† del flusso di dati Flow label identifica il flusso di dati (infatti non c‚Äô√® la frammentazione), anche se non √® ben definito il concetto di flusso. Hop limit √® la stessa cosa del time to live. Flow label (questo √® molto importante!, se il flusso identifica una comunicazione, non ho bisogno di indirizzi sorgente, finale, porta etc., per questo motivo posso compattare le informazioni!) Struttura delle reti Univocit√† e statico/dinamico üü© Slide\nEsempio slide\nAttualmente usati si riferiscono al protocollo IP versione 4, (IPv4). Un indirizzo IP viene associato a una e una sola (univoca) interfaccia di rete (scheda di rete). Potrebbe essere contemporaneamente identificato da pi√π di un indirizzo IP nel caso in cui ci siano pi√π interfaccie di rete (e pi√π MAC). Se l‚Äôassociazione univoca tra indirizzo MAC dell‚Äôinterfaccia di rete e l‚Äôindirizzo IP rimane sempre lo stesso, allora si parla di IP statico. In caso contrario, se pu√≤ cambiare l‚Äôassociazione MAC-IP a seconda di vari fattori, si parla di IP dinamico. (cambio da dove mi connetto!).\nQuando √® statico √® utile quando stiamo ad offrire dei servizi, cos√¨ non devo fare aggiornamenti, i computer sanno che strada devono fare per raggiungere un certo computer.\nClassi di rete üü© Sono definite tre classi di reti IP, che si differenziano sulla base del numero massimo di host supportabili. Il valore dell‚Äôindirizzo IP determina la classe della rete: A,B,C (vedere figura).\nLe reti di classe A sono al massimo 126 e ognuna pu√≤ contenere fino a oltre 16 milioni di host. Per le reti di classe A, il byte di indirizzo pi√π significativo (a sinistra) ha sempre il primo bit uguale a zero, e pu√≤ assumere i valori da 1 a 126 (network number) rispetto ai 128 valori possibili. I tre byte rimanenti possono assumere oltre 16 milioni di combinazioni, ognuna associabile a un host della rete. 0XXXXXXX.xxxxxxxx.xxxxxxxx.xxxxxxxx\nUna nota particolare √® l\u0026rsquo;indirizzo 127 che √® un indirizzo di loopback perch√© fa finta di uscire, e poi all‚Äôultimo rientra. Questo indirizzo √® utile per testare protocolli di rete.\nLe reti di classe B sono al massimo 16.382 e ognuna pu√≤ contenere fino a oltre 64.000 host. Per le reti di classe B, il network number √® dato dai due byte di indirizzo pi√π significativi (a sinistra), che hanno sempre i primi due bit uguali alla coppia (uno,zero). I network number di classe B possono assumere i valori da 128.0. a 191.255. I due byte rimanenti (host number) possono assumere oltre 64.000 combinazioni, ognuna associabile a un host della rete.\nforma di 10XXXXXX.XXXXXXXX.xxxxxxxx.xxxxxxxx\nLe reti di classe C sono oltre 2 milioni, e ognuna pu√≤ contenere fino a 254 host. Per le reti di classe C, i tre byte di indirizzo pi√π significativi (a sinistra) rappresentano il network number, e hanno sempre i primi tre bit uguali alla terna (uno,uno,zero). I network number di classe C possono assumere i valori da 192.0.0 a 223.255.255. Il byte rimanente (host number) pu√≤ assumere 254 combinazioni utili, su 256 possibili, ognuna associabile a un host della rete.\n110XXXXX.XXXXXXXX.XXXXXXXX.xxxxxxxx\nConvenzione l‚Äôultimo IP disponibile per l‚ÄôHost di solito √® dato al Router.\nSottoreti e netmask !!! (3) üü© Slide\nLa figura mostra a sinistra uno schema gerarchico di strutturazione di una rete di classe B. A partire dall‚Äôalto troviamo il router principale (default router) della rete 130.136, il cui indirizzo IP √® nell‚Äôesempio 130.136.0.254. Alla rete 130.136 appartengono anche tre router subordinati, con IP 130.136.1.254, 130.136.2.254, 130.136.3.254 rispettivamente amministratori delle sottoreti (130.136.1.), (130.136.2.) e (130.136.3.).\nNetmask\nIl Netmask identifica nelle zone in cui √® settato 1 l\u0026rsquo;indirizzo di rete e sottorete, dove √® 0 l‚Äôindirizzo di host. Quindi ci dice √¨l modo con cui si interpreta un byte di rete. Obbligatoriamente deve essere in questa forma ($1^n0^m: n + m = 32$ se vogliamo utilizzare una sintassi pi√π famigliare da Linguaggi di programmazione).\nIl concetto di creare sottoreti si pu√≤ riassumere in frazionare l‚Äôhost in altre due parti che rappresentano l‚Äôindirizzo di sottorete e l‚Äôhost. Queste sono nuove componenti logiche.\nFacendo questa operazione abbiamo $nreti \\times(nhost - 1)$, mentre prima era $nhostgrosso$. Alla fine se si svolge questo calcolo sono stesso numero di host, (magari perdo nreti numero di host per i router, per√≤ la ho gerarchizzata meglio).\nEsiste una notazione molto pi√π carina per i netmask che √® il CIDR (Classless Interdomain ROuting) in pratica stai dicendo quanti bit sono messi a 1\nCreazione sottoreti\nIn questo modo √® possibile creare una gerarchia di sottoreti, ognuna delle quali √® amministrata da un router (il default router). Esempio: data la rete di classe B 130.136. per semplicit√† decidiamo di considerare possibili 256 sottoreti: netmask 255.255.255.0.\nIl numero della sottorete √® quindi fornito dai primi tre byte dell‚Äôindirizzo IP, es. 130.136.1. √® la sottorete 1, 130.136.2. √® la sottorete 2, mentre ad esempio 130.136.1.22 √® l‚Äôhost 22 della sottorete 1, 130.136.3.48 √® l‚Äôhost 48 della sottorete 3, e cos√¨ via. (quindi un router sottorete ora prende IP del genere 130.136.1.254, perch√© indica la sottorete 1 della rete di classe B che si possiede).\nPer istruire ogni router subordinato sulla dimensione e sull‚Äôinterpretazione degli indirizzi IP da amministrare, ogni router subordinato deve essere fornito di una maschera di rete (netmask), evidenziata a destra.\nElementi fondamentali per il Protocollo IP\nSenza questi tre elementi il protocollo IP non funziona proprio. Quindi √® la prima cosa da fare per configurarlo.\nMaschera di rete Indirizzo IP Indirizzo default di router (il primo router sopra la gerarchia, che √® a chi mandare quando non so a chi mandare). (pu√≤ essere che con dispositivi stupidi abbiamo solamente l‚Äôindirizzo del router). La maschera di rete serve per capire\nNetmask\nIn particolare rileviamo qui 2 funzionalit√† principali per questo netmask:\nDire quanti subnet esistono, oltre alla rete principale Far sapere all‚Äôhost a quale rete appartiene √à quindi una quantit√† fondamentale per configurare la regte\nClassless Inter Domain Routing üü© Questo nuovo modo per fare netmask (nuovo rispetto gli anni 80) √® un modo per avere tagli di rete pi√π efficienti, nel senso che se prima la C non bastava, ti davano una B( Renzone a unibo ha avuto in questo modo una classe B). Ora possono avere molta pi√π disponibilit√† per i tagli negli indirizzi di rete. Questa cosa permette anche un concetto di supernetting. (in cui ho un insieme condiguo di classi pi√π piccole, e cos√¨ mi creo una rete maggiore, pi√π grosso delle classi, cos√¨ ho maggiore dinamicit√†).\nEsempio forwarding dei Pacchetti\nSlide\nSlide esempio\nLa figura mostra un esempio di instradamento su rete IP. Esistono tre router Ry, Rz e Rk rispettivamente amministratori delle reti (140.217.), (190.89.), e (130.136.). Il router Ry √® connesso a Rz, e Rz √® connesso a Rk. Tale informazione risulta dalle tabelle di instradamento di Ry, Rz, Rk. La rete del router Ry include due sottoreti (140.217.1.) e (140.217.2), amministrate dai rispettivi default router 140.217.1.254 e 140.217.2.254 . La rete del router Rk include tre sottoreti (130.136.1.), (130.136.2.) e (130.136.3.), amministrate dai rispettivi default router 130.136.1.254, 130.136.2.254 e 130.136.3.254 . Un pacchetto IP spedito dall‚Äôhost 140.217.2.10 all‚Äôhost 130.136.2.33 deve compiere il seguente tragitto: passa per il default router di sottorete 140.217.2.254 che, notando che il destinatario non appartiene alla sottorete, lo inoltra al default router del livello superiore di rete: 140.217.0.254. Il default router di rete controlla la propria tabella di forwarding e scopre che per raggiungere la destinazione il pacchetto deve essere inoltrato al router intermedio 190.89.0.254. Il router intermedio riceve il pacchetto, verifica la propria tabella di forwarding, scopre che il prossimo destinatario intermedio √® il router 130.136.0.254, al quale inoltra il pacchetto. Il router 130.136.2.254 riceve il pacchetto e verifica che appartiene alla propria rete, inoltrando quindi il pacchetto internamente. Il router di sottorete 130.136.2.254 riceve il pacchetto e scopre che appartiene alla propria sottorete, inoltrando il pacchetto internamente. Finalmente, l‚Äôhost 130.136.2.33 riceve il pacchetto a lui destinato. Si possono notare alcuni aspetti importanti: malgrado il numero elevato di host che potrebbero essere parte del sistema considerato, il processo di instradamento permane molto semplice, composto da piccole e semplici operazioni di base. Le tabelle di instradamento sono limitate agli elementi che agiscono allo stesso livello, e quindi l**‚Äôinstradamento √® gerarchico**.\nRouting üü® Si parler√† molto meglio del routing in Data Plane e Control Plane\nSlide\nIl problema del routing pu√≤ essere definito come il problema di mantenere l‚Äôaggiornamento delle tabelle di forwarding in tutti i router della rete. Questo problema pu√≤ essere a volte molto complesso, a causa di frequenti modifiche forzate dei cammini per i pacchetti in rete. Le cause di tali modifiche possono essere dovute a molti fattori, ad esempio: la mobilit√† degli host in reti senza fili, guasti di mezzi trasmissivi, interruzione delle linee, guasti di router, nuove politiche e accordi per lo scambio dei dati tra gestori di dorsali e sistemi autonomi.\nUn sistema autonomo (AS) √® sinonimo di una grossa rete, o una collezione di reti, soggetta a una comune politica di amministrazione. Gli accordi commerciali tra gestori di AS possono modificare i cammini consentiti per lo scambio dei pacchetti di dati. Per realizzare un parallelo intuitivo, gli AS si comportano come nazioni che permettano o meno il passaggio di pacchetti, analoghi a voli aerei, sul loro suolo nazionale. Ogni volta che si verifica uno dei problemi citati, esistono router che hanno indicazioni errate nelle loro tabelle di forwarding. Tutto ci√≤ pu√≤ causare la perdita di pacchetti, oppure pu√≤ determinare un disordine nell‚Äôarrivo di pacchetti che hanno seguito strade diverse. Ecco quindi una causa del servizio connectionless ottenuto dal livello rete basato solo sul protocollo IP. I router hanno bisogno di aggiornare al pi√π presto le loro tabelle, per evitare malfunzionamenti del servizio.\nIn pratica fanno lo stesso modo per decidere dove mandare, cio√® hanno lo stesso protocollo, ma dato che si trovano in parti diverse avranno poi tabelle di instradamento diverse.\nla Core network √® molto veloce nel trovare il percorso giusto (√® molto pi√π fisso, e sa pi√π o meno dove mandare le cose).\nI protocolli di routing hanno la funzione di richiedere e scambiare informazioni per trovare cammini alternativi (idealmente il cammino migliore tra le possibili alternative), tra mittenti e destinatari dei pacchetti, e consentire quindi l‚Äôaggiornamento delle tabelle di forwarding. A puro titolo informativo, si citano alcune sigle di protocolli di routing adottati in Internet: Routing Information Protocol (RIP), Open Shortest Path First (OSPF), Border Gateway protocol (BGP). Questi algoritmi sono tutti utilizzati in locale. La cosa brutta √® che il cammino ottimo cambia nel tempo (anche nell‚Äôordine dei secondi), quindi gli algoritmi si devono abituare dinamicamente a questi nuovi dati.\nNote sistemi distribuiti o centralizzati\nIl centralizzato √® bello perch√© √® chiaro a chi chiedere per andare poi a mandare il pacchetto dove si vuole, il problema √® che se il nodo centrale fallisce, cade l\u0026rsquo;intera rete.\nDistribuito √® bello perch√© risolve il problema del single point of failure per√≤ dall‚Äôaltra parte ogni nodo non ha una visione globale quindi non pu√≤ fare altro che andare a massimizzare localmente, che spesso non √® la cosa migliore.\nWikipedia sui sistemi autonomi\nLink, in pratica singola autorit√† amministrativa √® la parola chiave.\nProtocolli basati su IP Protocollo ICMP (6) üü®+ Slide\nICMP (Internet Control Message Protocol) √® un protocollo standard definito per supportare i messaggi di controllo per la gestione della rete al livello 3. ICMP viene usato da semplici host, da router e persino da gateway (router speciali con ulteriori funzioni) per scambiare informazioni utili alla gestione del livello Rete. Le informazioni scambiate sono trasferite sotto forma di pacchetti IP. Utile per stabilire una sintomatologia dei problemi di reti.\nAlcuni esempi di messaggi ICMP che possono essere scambiati indicano, ad esempio:\nsituazioni di rete di destinazione irraggiungibile (possibile sintomo di problemi di routing, o di rottura di un router). In questo caso pu√≤ convenire andare a cercare il problema di rete, che pu√≤ essere fisico, e fixarlo in questo modo rete di destinazione sconosciuta (possibile sintomo di indirizzo IP di rete male specificato) In questo caso il router non sa a chi mandare, quindi alcuni fix sono 1. aggiornare tabelle di instradamento, o provare altre strade. Ossia nessuno conosce l‚Äôindirizzo della rete locale host di destinazione non raggiungibile (possibile sintomo che l‚Äôhost sia spento o il cavo di connessione sia male collegato). Questo √® un problema che non ci riguarda, quindi probabile che l‚Äôhost si sia sconesso. Per questo significa che la rete √® conosciuta!, quindi problema di rete locale!. host di destinazione sconosciuto (possibile sintomo di host number del‚Äôindirizzo IP male specificato, malgrado la rete indicata esista e sia raggiungibile). problemi con indirizzo IP protocollo richiesto non disponibile (sintomo di un tentativo di dialogo tra dispositivi male configurati, che non forniscono i servizi richiesti). (come se stessi provando ad accedere a un servizio in una porta sbagliata, o versione IP sbagliata o simili). ricerca di cammino alternativo (pu√≤ essere usato per risolvere i problemi di routing). Anche chi riceve il messaggio, pu√≤ rispondere in modo preinpostato a quelle richieste. (e dato che √® preimpostato non c\u0026rsquo;√® bisogno di avere un frame grosso!).\nApplicazioni su ICMP (2) üü© Slide\nLe applicazioni sono utilizzate solitamente per la verifica delle cause o del semplice sospetto di problemi di rete. L‚Äôapplicazione PING permette di testare la connessione tra due host: eseguendo il comando ‚Äúping \u0026lt;indirizzo IP di host2‚Äù da un host1 qualsiasi (mittente) connesso in rete, l‚Äôapplicazione invia una richiesta ICMP di eco, alla quale l‚Äôhost2 indicato risponde con una risposta ICMP (eco della richiesta). Dopo l‚Äôinvio della richiesta, host1 fa partire un timer. In caso di successo, viene calcolato il tempo di andata e ritorno dei pacchetti (durata o Round Trip Time, RTT), mentre in caso di insuccesso viene indicato che il timer per la richiesta inviata √® scaduto senza ottenere risposta (secondo esempio della prima figura). Al termine dei tentativi, viene mostrato un elenco di statistiche sul numero di richieste andate a buon fine e i tempi medi stimati di andata e ritorno dei pacchetti.\nL‚Äôapplicazione Traceroute (tracert) permette di verificare la lista di tutti i router attraversati da una richiesta ICMP inviata da host1 a host2. Il comando ‚Äútracert ‚Äù eseguito da host1, causa l‚Äôinvio di una sequenza di richieste ICMP verso host2, per le quali viene fissato il numero massimo di router da attraversare (numero di passaggi o tempo di vita, TTL), a valori crescenti da 1 in poi. Ogni router a distanza TTL risponde con un messaggio ICMP di errore (tempo di vita scaduto) attraverso il quale √® possibile risalire al suo indirizzo IP (ognuno mostrato su righe successive).\nProtocollo ARP e RARP üü© Slide\nSlide immagine\nIl protocollo Address Resolution Protocol (ARP) aiuta a gestire l‚Äôassociazione tra indirizzo IP di un dispositivo a livello rete e il suo indirizzo MAC a livello MAC/LLC . Quando un router riceve un pacchetto a livello IP destinato alla sua sottorete (es. 130.136.2.33) esso verifica se a tale IP risulti o meno associato un indirizzo MAC. In caso contrario, il router spedisce sui segmenti della rete locale un frame in broadcast (cio√® ricevuto da tutti i dispositivi) contenente il codice di richiesta ARP, e l‚Äôindirizzo IP del destinatario del pacchetto. Tutti i riceventi vanno a confrontare, e se matcha risponde.\nIntuiviamente\nTale frame equivale quindi al rivolgere a tutti i dispositivi la domanda: ‚Äúquale indirizzo MAC ha il dispositivo corrispondente al seguente indirizzo IP‚Äù? Il dispositivo in questione, se esiste, risponde con un frame indirizzato all‚Äôindirizzo MAC del router, contenente il codice di risposta ARP, e con allegato l‚Äôindirizzo MAC richiesto. A questo punto il router pu√≤ quindi preparare e spedire la busta di livello MAC/LLC, indirizzata al MAC del dispositivo destinatario del pacchetto IP, contenente il pacchetto IP incapsulato all‚Äôinterno. Il destinatario riceve il frame e risponde con il frame di conferma per il sottolivello LLC.\nQuando √® risposto possiamo andare a mappare l‚ÄôIP con il MAC locale. Chi ha il MAC corrispondente pu√≤ rispondere col proprio IP.\nEsiste anche una versione analoga del protocollo ARP, detta Reverse-ARP, che risponde alla domanda: ‚Äúquale indirizzo IP corrisponde al dispositivo con questo indirizzo MAC‚Äù?. Pu√≤ essere utile ad esempio se mi arriva un pacchetto a un IP nella mia sottorete, ma non so a quale host √® destinato.\nProtocolo DHCP üü©- Slide\nSlide di immagine\nQuesto protocollo √® utilizzato per assegnare un IP in modo dinamico. porta 67, unico all\u0026rsquo;interno della rete, chi non ha un servizio l√¨ aperto droppa il messaggio.\nIntroduzione: assegnazione IP\nI numeri di rete delle classi A, B e C, ovvero la parte sinistra degli indirizzi IP vengono assegnati da enti internazionali quali RIPE, ICANN, ARIN, APNIC a enti, aziende, consorzi e imprese che ne fanno richiesta motivata. Un problema molto pi√π pratico riguarda il modo in cui un nuovo dispositivo che venga connesso a una rete esistente, veda associare al proprio indirizzo MAC un indirizzo IP della rete stessa. Il numero di rete o di sottorete viene automaticamente determinato dall‚Äôappartenenza alla rete, ovvero alla presenza al di sotto del dominio di gestione di un router.\nSoluzioni La prima, ovvia alternativa (molto usata) √® quella di avere un amministratore di rete che assegna manualmente uno dei numeri di host disponibili al nuovo indirizzo MAC. In questo modo l‚Äôassociazione indirizzo MAC e indirizzo IP pu√≤ essere mantenuta per un tempo indeterminato, e quindi si considera l‚Äôindirizzo IP come statico.\nLa seconda alternativa, molto usata in reti senza fili, in reti locali e nei collegamenti domestici a Internet Service Provider (ISP) via Modem o ADSL consiste nell‚Äôutilizzare un server per Dynamic Host Configuration Protocol (DHCP). Il server DHCP √® dotato di una lista di numeri di host liberi per la sottorete amministrata, che provvede ad associare su richiesta agli indirizzi MAC dei dispositivi che lo richiedono. Tale associazione dipende spesso dalla disponibilit√† degli indirizzi gi√† assegnati in precedenza, quindi allo stesso indirizzo MAC possono essere associati di volta in volta indirizzi IP diversi, e si parla in questo caso di indirizzi IP dinamici. E‚Äô possibile configurare attraverso DHCP anche altri parametri di rete, come la maschera di rete, il defaul router e il server DNS (che vedremo dopo). Il servizio DHCP equivale spesso al concetto di rete ‚Äúplug and play‚Äù, ovvero rete in cui basta connettere il dispositivo al medium e non c‚Äô√® bisogno di nessuna configurazione manuale aggiuntiva. √à questo √® quasi un must per le reti wireless! Sarebbe improponibile che ci fosse un sistemista ad assegnare un indirizzo IP per ogni dispositivo che si connette!\nIn breve:\nHost che assegna IP a chi lo richiede Gestione degli IP liberi e associazione ai MAC Questa √® chiaramente una forma di indirizzamento dinamico discusso in Univocit√† e statico/dinamico üü© Ogni tot di tempo √® fatto un ping se la macchina risponde √® ancora l√¨, altrimenti libera l‚ÄôIP.\nMAGGIORE DETTAGLIO 4passi\nSlides\n√à importante avere 4 passi, perch√© l‚ÄôHOST deve rispondere con la scelta del DHCP, nel caso in una sottorete ci siano molto DHCP.\nma Non esiste nessuna autenticazione, quindi √® molto fragile ad attacchi (uno si potrebbe impersonare a DHCP senza problemi). I primi due passaggi sono facoltativi, ma lo rendono pi√π solido contro possibilit√† di avere 2 DHCP server.\nNOTA: comuqnue non √® un protocollo per dare IP a dispositivi mobili che si spostino.\nIPv6 e tunnelling üü© Slide\nhttps://www.notion.so\nImmagine\nNella figura viene mostrato come sia possibile spedire pacchetti IPv6 tra due router IPv6 passando per cammini che includono router IPv4, attraverso il tunnelling IPv6 in IPv4. Il pacchetto IPv6 viene incapsulato dai ogni router IPv4 in pacchetti IPv4, in modo da poter essere instradato lungo la rete di router IPv4. Uscito dal tunnel IPv4 il pacchetto IPv6 prosegue il suo inoltro fino alla destinazione IPv6 finale.\nIl motivo principale della necessit√† di IPv6 √® la necessit√† di altri indirizzi IP. IPv6 perch√© hanno tentato di fare un IPv5 in molti modi ma sono caduti in disuso.\nNon c\u0026rsquo;√® frammentazione, con IPv6, mentre IPv4 ha bisogno‚Ä¶ questo toglie il lavoro del router, e quindi rende tutto pi√π veloce.\nDal 1990 √® stato avviato un progetto di definizione e sviluppo di una nuova versione del protocollo IPv4, denominato versione IPv6. In seguito all‚Äôesplosione del collegamento di calcolatori in rete, e quindi dell‚Äôutilizzo di indirizzi e reti IP, le proiezioni mostrano che al ritmo attuale gli indirizzi IPv4 saranno esauriti nel decennio 2008-2018. Brevemente, le caratteristiche salienti di IPv6 vanno nella direzione di ovviare a questo problema, oltre a migliorare alcuni aspetti di IPv4. La caratteristica fondamentale di IPv6 √® la definizione di nuovi indirizzi IPv6 composti da 128 bit (16 byte), cio√® ben quattro volte la dimensione degli indirizzi IPv4. Questo incredibile numero di indirizzi potrebbe consentire di avere circa 15000 indirizzi IPv6 per dispositivi diversi su ogni metro quadrato di superficie dell‚Äôintero pianeta, oceani inclusi.\nSono inoltre stati ridefiniti i campi che costituiscono la busta dei pacchetti di livello IPv4, aggiungendo ad esempio parametri per la gestione di flussi di pacchetti IP con diversi livelli di priorit√†. Purtroppo la definizione di IPv6 nella maggioranza dei casi non permette di continuare a usare i vecchi router IPv4, e quindi non √® compatibile con l‚Äôattuale struttura di Internet.\nTunnelling\nIl tunnelling √® fondamentale per la compatibilit√† fra IPV4 e IPv6\nLa sperimentazione e lo sviluppo di IPv6 sta procedendo su reti IPv6 separate, che possono in certi casi integrarsi alle reti IPv4 usando la tecnica del tunnelling dei pacchetti IPv6 in IPv4. Quindi wrappo con un pacchetto IPv4 i router che capiscono solo IPv4.\nSi chiama tunnelling perch√© il wrap ci assomiglia tanto!\nNAT Cose vecchie Confronto col MAC L\u0026rsquo;indirizzo Internet Protocol √® il protocollo internet a livello 3 pi√π utile per la comunicazione fra reti locali diverse. Una delle caratteristiche che la contraddistingue dal MAC √® il fatto che sia gerarchico, ossia c\u0026rsquo;√® una sorta di indirizzo generale, indirizzo specifico e indirizzo della rete locale!. Oltre al fatto che √® gerarchico non √® univoco, perch√© pu√≤ succedere molto spesso che viene riassegnato.\nCaratteristiche IP (3) Globale perch√© non esiste rete connessa ad Internet che non abbia indirizzo IP; Strutturato perch√© √® diviso in due parti, una per l‚Äôindirizzo della rete locale e l‚Äôaltro per l‚Äôindirizzo della scheda di rete interna alla rete locale; Gerarchico perch√© appunto le due parti di indirizzo sono in ordine gerarchico (rete locale \u0026gt; scheda di rete). Indirizzamento IP Se succede che due IP sono uguali, questo succede solamente a rete locale perch√© anche la prima parte dell‚ÄôIP deve essere uguale, quindi se ne accorge il Router e risolve questo.\nStaticit√† e dinamicit√†\nStatico ‚Üí IP associato a MAC\nDinamico ‚Üí IP che cambia, quindi √® pi√π difficile\nClassi di rete Dividiamo l‚ÄôIP in 3 classi principali A, B, C a seconda di quanti IP riescono a supportare\nClasse A\nIl bit pi√π significativo √® 0. Quindi la prima sezione va da 1 a 126, perch√© 0 √® utilizzato per l‚Äôidentificazione. Sono quelle pi√π prezione perch√© possono avere pi√π host ($2^{24}$ host).\nClasse B\nHanno i primi due bit come valore 10. e vanno da 128 a 191,\nClasse C\nRouter I router ricevono pacchetti e guardano la parte di rete locale, se matcha √® OK, viene inoltrato ad altri router della rete locale per smistare ulteriormente, altrimenti inoltra ad altri router in altre reti, attraverso i collegamenti chiamati dorsali.\nTabelle e protocollo di instradamento Queste sono tabelle che hanno un utilizzo molto simile a quanto utilizzato per lo switch, che mappa una porta a un indirizzo MAC. In questo caso mappa la tolopogia di rete (che non so in che modo sia intesa questa mappa). Di solito il router √® collegato a un solo altro router che viene chiamato default gateway.\nIl protocollo, invece, si occupa di aggiornare questa tabella secondo le occorrenza (TODO, non so su quali regole).\nProtocollo di routing Questo protocollo che si occupa di trovare il percorso pi√π breve, e di frammentare il messaggio originale in pacchetti pi√π piccoli, ma senza fare controlli su un arrivo corretto di queste informazioni. Quind fa una scelta per capire che strada fare\nCIDR Classless Inter Domain Routing Si utilizza una scrittura molto compatta per\n","permalink":"https://flecart.github.io/notes/livello-di-rete/","summary":"Reti di Reti Le parti importanti per questo sono Data Plane e Control Plane (che ha saltato quasi tutto, ma almeno dijkstra lo dovresti fare bene)\nIntroduzione (puoi skippare üü©) La puoi skipppare perch√© tratta in modo molto generare parti che saranno trattati in modo pi√π approfondito in seguito. La parte importante forse √® il riassunto di cosa faccia questo livello.\nDiscussione rete locale globale Slide\nNo, non √® possible creare una connessione globale utilizzando le tecnologie locali, come hub, switch e simili, perch√© causerebbe flooding e impedirebbe scalabilit√† e crescita dinamica che √® classica della rete","title":"Livello di Rete"},{"content":"Introduction to the Rice Theorem Ci sono molti teoremi che non possono essere decisi, vedere Halting Theorem and Reducibility. Qui andiamo a chiederci quale sia l\u0026rsquo;insieme dei problemi decidibili.\nPropriet√† dei linguaggi TMüü© Data una macchina $\\mathcal{M}$ definiamo il suo linguaggio come $$ L_{\\mathcal{M}} = \\left\\{ x \\in \\Sigma^{*}: \\mathcal{M} \\text{ accetta } x \\right\\} $$ Allora con questa definizione di linguaggio possiamo dire che una propriet√†, ossia una funzione da tutti i $TM$ possibili a $\\left\\{ 0, 1 \\right\\}$ tale per cui se il linguaggio riconosciuto √® lo stesso, ossia $$ L_{\\mathcal{M}} = L_{\\mathcal{M}'} \\implies P(\\mathcal{M}) = P(\\mathcal{M}') $$ Definiamo questa non triviale se esiste una macchina per cui √® 0, e una per cui √® 1 (ossia non √® costante). Practically this definition is useful when we need to have a difference between the language and the Turing machine that decides that language.\nThree properties of Turing Machinesüü© Language properties (what language does it decide? This property concerns Rice\u0026rsquo;s Theorem) Structural properties (what are constituents of turing machine?) Algorithmic properties (how is computing) It is important to note that only Language properties concerns Rice\u0026rsquo;s Lemma. Enunciato di Rice Se $P$ √® una propriet√† dei linguaggi TM, allora √® indecidibile il problema \u0026ldquo;$\\mathcal{M}$ ha la propriet√† $P$\u0026rdquo;.\nProof of Rice We want to prove that the language $$ \\left\\{ \\langle M \\rangle : code(\\mathcal{M}) \\land P(M) = 1 \\right\\} $$ is undecidable. We proved this by Mapping reducibility with the HALT language.\nWithout loss of generality, we assume that given a $P$ we have that $P(\\mathcal{M}_{\\varnothing}) = 0$. Then, given the fact that the property is not trivial we have that exists a $\\mathcal{M}$ such that $P(\\mathcal{M}) = 1$. Let\u0026rsquo;s procede by contradiction. Assume that $P$ is decidable. Let\u0026rsquo;s proof that $HALT \\leq P$ where $P$ is the language that knows the same stuff. This proves Rice Theorem by mapping reducibility properties.\nL\u0026rsquo;insieme delle funzioni non decidibili Qui andiamo a dimostrare che la stragrande maggioranza dei linguaggi non sono riconoscibili. TODO: questo si potrebbe ripassare dalle slides e verrebbe fatto in maniera diversa.\nUnione di insiemi numerabili √® numerabileüü© Vedi Descrizione linguaggio#Numerabilit√† per alfabeti per costruzione e dimostrazione. Sarebbe buono saperlo fare da solo. L\u0026rsquo;idea √® avere un parametro che di dice quanto √® l\u0026rsquo;esponente dell\u0026rsquo;insieme. E poi andare per sorta di ricorsione.\nL\u0026rsquo;insieme delle TM √® numerabile.üü© Basta vedere che l\u0026rsquo;insieme delle TM √® un sottoinsieme di $A^{*}$, che √® numerabile. Questo quando usiamo la codifica binaria, quindi $A = \\left\\{ 0, 1 \\right\\}$.\nL\u0026rsquo;insieme dei linguaggi su alfabeto finito non √® numerabileüü© Possiamo rappresentare un linguaggio su un alfabeto con funzioni indicatrici. Avremmo cos√¨ una stringa binaria che ci indica o no se una stringa √® presente nel linguaggio o meno. Allora posso praticamente usare lo stesso argomento usato in diagonalizzazione di Cantor e avere il risultato.\n","permalink":"https://flecart.github.io/notes/teorema-di-rice/","summary":"Introduction to the Rice Theorem Ci sono molti teoremi che non possono essere decisi, vedere Halting Theorem and Reducibility. Qui andiamo a chiederci quale sia l\u0026rsquo;insieme dei problemi decidibili.\nPropriet√† dei linguaggi TMüü© Data una macchina $\\mathcal{M}$ definiamo il suo linguaggio come $$ L_{\\mathcal{M}} = \\left\\{ x \\in \\Sigma^{*}: \\mathcal{M} \\text{ accetta } x \\right\\} $$ Allora con questa definizione di linguaggio possiamo dire che una propriet√†, ossia una funzione da tutti i $TM$ possibili a $\\left\\{ 0, 1 \\right\\}$ tale per cui se il linguaggio riconosciuto √® lo stesso, ossia $$ L_{\\mathcal{M}} = L_{\\mathcal{M}'} \\implies P(\\mathcal{M}) = P(\\mathcal{M}') $$ Definiamo questa non triviale se esiste una macchina per cui √® 0, e una per cui √® 1 (ossia non √® costante).","title":"Teorema di Rice"},{"content":"3.1 Introduzione e definizione Si definisce applicazione lineare una funzione (omomorfica) che preserva la struttura dello spazio vettoriale, ossia vale che\n$$ f:V \\to W, \\text{ tale che } \\\\ f(u + v) = f(u) +f(v)\\\\, f(\\lambda v) = \\lambda f(v) $$ Vengono mantenute alcune caratteristiche principali. In modo simile si possono definire omomorfismi per tutte le altre strutture algebriche, la cosa importante √® che lo spazio d\u0026rsquo;arrivo possieda ancora tutte le stesse operazioni.\n3.1.1 Conservazione delle combinazioni lineari In particolare le due propriet√† delle applicazioni lineari mi preservano le applicazioni lineari, ovvero:\n$f(\\lambda_1 a + \\lambda_2 b) = \\lambda_1 f(a) + \\lambda_2f(b)$ e questo lo puoi estendere a qualunque tipo di vettore\n3.1.2 L\u0026rsquo;elemento neutro L\u0026rsquo;elemento neutro √® conservato nell\u0026rsquo;applicazione lineare (mappa sempre l\u0026rsquo;elemento neutro di uno all\u0026rsquo;elemento neutro dell\u0026rsquo;insieme di arrivo)\n3.1.3 Esempi Un esempio importante √® la matrice che mappa da $\\mathbb{R}^n\\to \\mathbb{R}^m$\n3.2 Esiste omomorfismo a insiemi qualunque 5.1.7 sul libro.\nDimostrazione Il passo pi√π importante √® definire l\u0026rsquo;applicazione lineare. Lo definiamo in questo modo: preso $v\\in V$, allora in quanto ho una base di $V$, posso dire che $v = \\alpha_1v_1 +...+ \\alpha_n v_n$, allora definiamo la nostra funzione $L:V\\to W$ tale che $L(v) = \\alpha_1w_1 +...+\\alpha_nw_n$, da notare che i coefficienti sono gli stessi, ma i vettori diversi e abbiamo anche cambiato possibilmente lo spazio\n√à una applicazione: fai i calcoli e puoi notare che effettivamente √® una applicazione lineare.\nCalcoli Unicit√†: l\u0026rsquo;unicit√† di questa applicazione si pu√≤ identificare con l\u0026rsquo;unicit√† delle coordinate rispetto alla base, c\u0026rsquo;√® solo una tale funzione definita in questo modo per ogni vettore. Ma questa non √® formale, quindi appiccico la dimostrazione formale: (si utilizza l\u0026rsquo;ipotesi dell\u0026rsquo;unicit√† delle coordinate inmodo implicito sctivendo v come combinazione lineare della base) Corollario: Coincidenza su basi La dimostrazione √® abbastanza ovvia, sappiamo che esiste un unica applicazione lineare su una base e che arriva a W.\nQuesto teorema ci permette di avere delle applicazioni lineari a piacere, per qualunque spazio vettoriale, basta avere una base dello spazio iniziale.\nmodi di vedere l‚Äôapplicazione lineare Esistono tre modi per avere la definizione di applicazione lineare.\nClassica definizione F(v) = espressione Una matrice che mi rappresenta l\u0026rsquo;applicazione F(base1) = qualcosa, \u0026hellip; F(basen) = qualcosaltro. 3.3 Teoremi su Ker e Im 3.3.1 Kernel e Immagine sono sottospazi Devo dimostrare che questi insiemi siano dei sottospazi.\nIl vettore nullo appartiene a $\\text{Ker }f$ Poi si dovrebbe dimostrare che siano chiusi per l\u0026rsquo;operazione di somma e prodotto scalare, anche questo √® semplice. In modo simile a quanto fatto in Spazi vettoriali 3.3.2 Suriettivit√† e iniettivit√† Enunciato:\nData una applicazione lineare $F: V\\to W$\nSuriettivo sse $Im(F) = W$, questa √® abbastanza ovvio.\nIniettiva sse $Ker(F) = \\{0\\}$\nDimostrazione\n$\\implies$Supponiamo che sia iniettiva, allora $F(x) = F(y) \\implies x = y$,\nin quanto √® una applicazione lineare so che $F(0) = 0_w$, quindi supponiamo che $v \\in V |F(v) = 0$ per iniettivit√† ho che $v= 0$, quindi l\u0026rsquo;unico elemento di $Ker(F)$ √® 0.\n$\\impliedby$Supponiamo che $Ker(F) = \\{0 \\}$ supponiamo che $F(x) = F(y)$ per certi $x,y \\in V$,\nvogliamo dimostrare che $x= y$.\nValutiamo $F(x - y) = F(x) - F(y) = 0_w$, ma quindi $x-y = 0_v$ in quanto per ipotesi l\u0026rsquo;unico elemento in Ker(F) √® 0v e abbiamo dimostrato che (x-y) appartiene a Ker(F), quindi $x = y$.\n3.3.3 Calcolo del nucleo Dato un omomorfismo, l\u0026rsquo;unica cosa che dobbiamo fare √® risolvere la matrice omogenea associata. In parole migliori\nKer F √® l\u0026rsquo;insieme delle soluzioni del sistema lineare omogeneo associato ad A, dato A matrice dell\u0026rsquo;applicazione lineare\nQuesto dato si pu√≤ utilizzare per calcolarne poi la dimensione, usando riduzione di Gauss\n3.3.4 Corrispondenza fra base V nell‚Äôimmagine Teorema 5.4.4. Dimostrazione corrispondenza Vogliamo dimostrare una doppia inclusione, perch√© √® questa la definizione dell\u0026rsquo;uguaglianza per un assioma di estensionalit√† in Teoria assiomatica degli insiemi.\nCaso $\\implies$, sia $w \\in Im(F)$, allora $\\exists v\\in V, F(v) = w$, dato che abbiamo una base, si ha che $v = \\lambda_1v_1 +...+ \\lambda_nv_n$, allora\n$F(\\lambda_1v_1 +...+ \\lambda_nv_n) = F(\\lambda_1v_1) +...+ F(\\lambda_nv_n) = \\lambda_1F(v_1) +...+ \\lambda_nF(v_n) \\in \\langle F(v_1),...., F(v_n)\\rangle$ e finisco questa freccia.\nCaso $\\impliedby$Questa praticamente √® uguale alla precedente, oppure, possiamo ricordare che per la 3.1.5 presente in Spazi vettoriali si ha che √® il pi√π piccolo sottospazio generato da quei elementi. Quindi questa inclusione √® fatta in modo immediato. Ma anche ripercorrere la dimostrazione al contrario non √® un problema.\nNote: Questo teorema ci √® molto utile per calcolare lo spazio generato dell\u0026rsquo;immagine, perch√© ci permette di fare una sorta di cambio di base (che non √® un cambio di base) stiamo solamente prendendo qualcosa di molto simile a una base, ma in un altro spazio vettoriale (non √® detto che sia una base per√≤! so solo che genera quello spazio vettoriale).\n3.3.5 Calcolo dell\u0026rsquo;immagine Avendo il teorema precedente, il calcolo del sottospazio dell\u0026rsquo;immagine √® abbastanza veloce:\nprendo l\u0026rsquo;insieme immagine della base poi faccio gauss in modo diretto su questa. SI pu√≤ dimostrare che questo non √® altro che gauss sulla TRASPOSTA.\nTeorema della dimensione In immagine √® la 5.5.1 Questo √® uno dei teoremi pi√π importanti per tutto il corso di geometria! Vale per qualunque applicazione lineare per spazi vettoriali!\nIdee per la dimostrazione\nA caratteri generali, i passi logici principali per la dimostrazione √® questa:\nPrendiamo una base di V, e la base per Ker(F). Per il completamento posso completare la base del nucleo in una base di V. Prendo l\u0026rsquo;insieme dei vettori che ho aggiunto al nucleo, voglio dimostrare che la funzione applicata a questi vettori sia in grado di generare l\u0026rsquo;immagine, se questo succede, allora ho finito perch√© ho praticamente scomposto la base di V, in una per Ker(F), e una altra per Im L. Dimostro che effettivamente quanto preso √® una base di Im F cercata, utilizzando la linearit√† dell\u0026rsquo;applicazione, e il fatto che l\u0026rsquo;insieme di vettori iniziale era base per V Dimostrazione\n3.4.1 Verifica iniettivit√† Mi pu√≤ dare in modo quasi immediato nozioni di iniettivit√† e suriettivit√†, se l\u0026rsquo;applicazione lineare ha la dimensione di kernel = 0 allora scopro subito che √® iniettiva!\nSiano dati due spazi vettoriali tali che $\\dim V \u003e \\dim W$ allora non ho cose iniettive.\nPerch√© supponiamo che ci sia tale applicazione lineare, ma al massimo l\u0026rsquo;immagine √® di dimensione W, quindi la dimensione del Kernel non √® nulla, per cui ho che non √® iniettivo per il teorema in link\n3.4.2 Verifica suriettivit√† Se la dimensione dell\u0026rsquo;immagine ha la stessa dimensione del codominio, allora ho trovato subito un una base per il codominio! Quindi so subito che √® suriettiva.\nIn modo simile se ho due spazi vettoriali tali per cui $\\dim V \u003c \\dim W$ allora non ho funzioni suriettive perch√© la dimensione di arrivo √® al massimo V.\n3.5 Isomorfismi 3.5.1 Definizione √à una applicazione lineare bigettiva\nSI pu√≤ dimostrare che se V ha dimensione n, allora √® isomorfo con $\\mathbb{R}^n$\n3.5.2 Equivalenza delle dimensioni per ISO (!! chiede) Sse due spazi vettoriali sono isomorfi allora hanno la stessa dimensione.\nDimostrazione\n$\\implies$ In quanto √® un isomorfismo si ha che √® iniettiva e suriettiva, quindi\ndim V = 0 + dim W quindi hanno la stessa dimensione.\n$\\impliedby$Suppongo che le dimensioni siano le stesse, vogliamo dimostrare che i due insiemi siano isomorfi.\nDate le rispettive basi di V e W, vogliamo costruirci un isomorfismo:\nMi costruisco la funzione e dimostro che √® suriettiva perch√© voglio mandare il vettore base 1 di V al vettore base 1 di W, cos√¨ a corrispondere fino alla dimensione Poi uso il teorema delle dimensioni per concludere che la dimensione del nucleo √® 0, per cui √® iniettiva. ","permalink":"https://flecart.github.io/notes/applicazioni-lineari/","summary":"3.1 Introduzione e definizione Si definisce applicazione lineare una funzione (omomorfica) che preserva la struttura dello spazio vettoriale, ossia vale che\n$$ f:V \\to W, \\text{ tale che } \\\\ f(u + v) = f(u) +f(v)\\\\, f(\\lambda v) = \\lambda f(v) $$ Vengono mantenute alcune caratteristiche principali. In modo simile si possono definire omomorfismi per tutte le altre strutture algebriche, la cosa importante √® che lo spazio d\u0026rsquo;arrivo possieda ancora tutte le stesse operazioni.","title":"Applicazioni lineari"},{"content":"TODO: this file should be written better later.\nPositional encoding We need to keep positional information about the contents.\nTh: High dimensional unit vectors are almost always orthogonal This theorem states that given $a, b \\in \\mathbb{R}^{n}$, and $\\lVert a \\rVert = \\lVert b \\rVert = 1$ we have that it is highly probable that $a \\cdot b \u003c \\varepsilon$. For a small epsilon. This is not exactly a formal proof (we haven\u0026rsquo;t formalized the idea of highly probable)., but it gives an idea about why does it work. We will say that the expected product will be 0.\nProof We want to prove that $\\mathbf{E}\\left[ a \\cdot b \\right] = 0$ We know that $a \\cdot b = \\sum a_{i} b_{i}$. Then we know that the mean of this distribution is 0 (easy to calculate). For the variance it\u0026rsquo;s a little bit more difficult.\nWe have to find the value for $Var(a_{i}b_{i}) = \\mathbf{E}\\left[ a_{i}^{2}b_{i}^{2} \\right] - (\\mathbf{E}[a_{i}b_{i}])^{2}$, and after you found this you should be able to calculate $Var(a\\cdot b) = Var\\left( \\sum_{}a_{i}b_{i} \\right) = \\sum Var(a_{i}b_{i})$ last is true because the correlation between the two is zero.\nFrom this we see that $Var(a_{i}b_{i}) = \\mathbf{E}\\left[ a_{i}^{2} \\right] \\mathbf{E}\\left[ b_{i}^{2} \\right]$ An observing that $\\sum a_{i}^{2} = 1$ and saying that every dimension is independent from each other we conclude that $\\mathbf{E}\\left[ a_{i}^{2} \\right] = \\mathbf{E}\\left[ b_{i}^{2} \\right] = \\frac{1}{n}$ Then it\u0026rsquo;s a easy calculation to conclude that the variance of the original product (you need to prove the variance of the sum of n independent variables with the same variance) is $$ Var(a\\cdot b) = \\frac{n}{n^{2}} = \\frac{1}{n} $$ which says that it will be very probably centered around the origin for large dimensions.\nAnother fact: Concatenation is similar to addition: https://chatgpt.com/share/3bc87143-006a-4821-807e-5a35b06ec4da\n","permalink":"https://flecart.github.io/notes/transformers/","summary":"TODO: this file should be written better later.\nPositional encoding We need to keep positional information about the contents.\nTh: High dimensional unit vectors are almost always orthogonal This theorem states that given $a, b \\in \\mathbb{R}^{n}$, and $\\lVert a \\rVert = \\lVert b \\rVert = 1$ we have that it is highly probable that $a \\cdot b \u003c \\varepsilon$. For a small epsilon. This is not exactly a formal proof (we haven\u0026rsquo;t formalized the idea of highly probable).","title":"Transformers"},{"content":" \u0026ldquo;Information theory must precede probability theory, and not be based on it. By the very essence of this discipline, the foundations of information theory have a finite combinatorial character.\u0026rdquo; Kolmogorov, A. N. (1983).¬†Combinatorial foundations of information theory and the calculus of probabilities.\nRussian mathematical surveys,¬†38¬†(4), 29-40.\n\u0026ldquo;it is clear that elements requiring an extremely large number of words for their definition should be considered as having an extremely low probability.\u0026rdquo; (Borel E.,¬†1909¬†p. 272).\nQuesta sezione si distacca dalla probabilit√† classica che abbiamo fatto in questo corso, ma per vicinanza metto qui l\u0026rsquo;appunto.\nPrefix Complexity Definizione $$ K(s) = min_{p}\\left\\{ \\lvert p \\rvert : U_{pr}(p) = s \\right\\} $$ L\u0026rsquo;unica differenza con Kolmogorov complexity √® che qui usiamo una macchina di turing con prefix codes.\nIntuizione Una macchina che esegue programmi random pu√≤ produrre una certa stringa? Definiamo la probabilit√† come $$ P(x) = \\sum_{p:U(p)=x} 2^{-l(p)} $$ Che √® un modo per dire generare in modo random certi programmi. Il valore di sopra √® simile a $$ P(x) \\approx 2^{-K(x)} $$ Per $K$ vedi Kolmogorov complexity. TODO: cercare di capire perch√© limitarsi solamente alla versione pi√π corta.\nPrefix Machine Da Leonid Levin, risolve il problema di termine di interpretazione, perch√© prefix codes hanno valore sempre minore di 1 come descritto in Entropy#Krafts Inequality. Se non si escludono, fanno qualcosa di brutto con quel valore di probabilit√†, perch√© la somma di tutti avrebbe superato $1$ e non avrebbe soddisfatto gli assiomi La propriet√† principale √® che non esistono due programmi per questa macchina tale per cui uno sia prefisso di altro.\nSelf delimiting codes Con i prefix codes posso avere delle cose self-delimiting, perch√© so quando un codice finisce e posso interpretarlo per la propriet√† dei prefissi.\nDefinition of prefix complexity Praticamente per encodare un numero encodiamo la sua lunghezza binaria con un codice e poi concateniamo il numero stesso. Quindi il codice finale avrebbe lunghezza di $$ 2\\log \\log(\\lvert s \\rvert ) + \\lvert s \\rvert $$ Relazione con complessit√† normale $$ C(s) + O(1) \\leq K(s) \u003c C(s) + 2\\log(C(s)) + O(1) $$ La prima diseguaglianza sembra essere presa da Kolmogorov complexity#Teorema dell\u0026rsquo;invarianza, mentre la seconda dallo stesso teorema pi√π dal fatto che stiamo usando una macchina di Turing con prefissi.\nAlgorithmic probability Definizione algorithmic probability $$ \\mathbb{P}(x) = \\sum_{p:U(p)=x} 2^{-l(p)} $$ TODO: sarebbe carino provare ad esplorare di pi√π questo topic, perch√© mi sembra abbia belle connessioni con resto. Poi un sacco di questo content √® bloggabile.\n","permalink":"https://flecart.github.io/notes/algorithmic-probability/","summary":"\u0026ldquo;Information theory must precede probability theory, and not be based on it. By the very essence of this discipline, the foundations of information theory have a finite combinatorial character.\u0026rdquo; Kolmogorov, A. N. (1983).¬†Combinatorial foundations of information theory and the calculus of probabilities.\nRussian mathematical surveys,¬†38¬†(4), 29-40.\n\u0026ldquo;it is clear that elements requiring an extremely large number of words for their definition should be considered as having an extremely low probability.","title":"Algorithmic Probability"},{"content":"Descrivo ora alcune domande utili per ripasso:\nQuali sono schematicmente quali sono le operazioni migliori per un parser top-down? Cosa √® un prefisso viabile? Quali sono i conflitti possibli, e come risolverli‚Ä¶ Non sai nemmeno definire inmodo formale cosa sia un item Bottom up Intro shift-reduce e LR üü© Slide\nIn breve:\nShift = simbolo terminale messo nella stack Riduzione utilizzando una produzione LR = dettura da Sinistra, creazione della stringa da destra (derivazione rightmost) Algoritmo classico üü®+ Quello che credo che intendevo per questo algoritmo classico √® quello non deterministico, nel senso che prova a fare backtracking, finch√© non ha finito tutte le possibilit√†, oppure trova la derivazione giusta.\nSlide\nQuesto √® esattamente lo stesso presentato alla fine di Linguaggi Deterministici e DPDA\nEsempio\nIl drawback classico di queste tipologie di parser √® che c‚Äô√® un enorme non determinismo causato dai conflitti shift-reduce e reduce-reduce, che non hanno una lettura immediata, andremo quindi in seguito a creare metodi che possano disambiguare ci√≤.\nIl parser LR Struttura di un parser LR üü®++ Slide schematizzazione\nIn figura sono descritte tutte le componenti del parser in modo molto schematico.\nComponenti importanti sono\nDFA e stack degli stati del DFA Pila dei simboli Tabella di parsing Algoritmo alto livello di parsing üü© Mosse di parser LR deterministico\nOssia le operazioni che pu√≤ fare il parser\nAlgoritmo in pseudocodice\nEsempio di parsing LR\nNota, spesso √® molto comodo fare una grammatica aumentata in questo modo\nIl DFA degli stati pare quindi fondamentale per la costruzione della tabella di parsing, in seguito andremo a costruire dei metodi automatici utili a far questo.\nQuesto √® un DFA con alcuni modi di tornare indietro.\n√à bene quindi andare prima a fondare una teoria solida per questa roba, la crazione dell‚Äôautoma canonico per il parsing LR.\nPrefisso viabile I prefissi viabili sono un modo per risolvere il non determinismo di un parser classico bottom up, ci permette di capire in modo univoco se andare a fare shift e reduce col sistema degli handle.\nPer poter controllare bene i prefissi viabili utilizziamo una tabella di parsing per controllare lo stato dell‚Äôhandle.\nIntroduzione al perch√© (informale, non fare) üü© Slide\nL‚Äôidea √® far in modo che in cima alla pila ci sia solamente qualcosa che possa essere un prefisso di una produzione se non lo pu√≤ esere si pu√≤ concludere chiaramente che non sia possibile!\nPer controllare questi prefissi utilizzeremo di nuovo una tabella di parsing, ma con altra logica sotto.\nDefinizione üü® ‚Äî Slide sui prefissi viabili.\nInformalmente: una sequenza $\\in (T \\cup NT)^*$ che pu√≤ apparire sulla pila del parser bottom up per una configurazione che accetta l‚Äôinput.\nDa notare differenza della definizione per stringa e per gramamtica.\nPer stringa √® qualunque stringa che pu√≤ apparire sulla pila, al momento di una computazione che va a buon fine Per grammatica, invece, andiamo a considerare le derivazioni destre. In questa parte si introducono anche concetti come prefisso viabile completo e handle. **(non credo sia importante questa definizione la salto). Gli handle sono di interesse perch√© appena li abbiamo siamo sicuri che vogliamo andare a fare una reduce, vorremmo trovare un modo per farceli comparire sti handle quando ne ho bisogno!\nNOTA: la derivazione deve essere rightmost almeno nella definizione, anche se non ho ben capito per quale motivo deve essere cosi`.\nTh. prefissi variabili di G libera sono un linguaggio regolare üü© Slide\nQuesto teorema ci √® molto utile per continuare la nostra costruzione del parser, perch√© ora possiamo utilizzare questo DFA di supporto generato dal linguaggio regolare dei prefissi variabili per decidere cosa fare:\nSe √® completo faccio reduce Se non lo √® faccio shift Se non √® nemmeno un prefisso variabile sono in errore, perch√© mai ci potr√≤ fare una reduce, questo per definizione di prefisso variabile. Abbiamo cos√¨ discusso su vantaggi che questo teorema ci pu√≤ dare, ma non abbiamo ancora dato un modo per dimostrare questo teorema, lo dimostreremo in seguito, con la costruzione degli item e un DFA per esse. e poi sappiamo che i DFA sono anch‚Äôesse equivalenti a un linguaggio regolare.\nShift e reduce sullo stato del DFA üü© In questa minisezione andiamo a trattare in che modo potremmo codificare il DFA in modo efficiente, in modo da non rifare ad ogni shift e reduce il ricalcolo dell‚Äôintera stringa!\nSlide\nQuindi per lo shift molto easy, basta che ricomincio dallo stato vecchio.\nPer il reduce invece mi serve poter tornare indietro! il modo pi√π semplice per fare questo √® tenersi uno stack degli stati, in modo che possa tornare indietro in modo lineare (poi quindi credo che l‚Äôalgoritmo sar√† lineare nei nodi dell‚Äôalbero in questo modo).\nAutoma canonico L‚Äôautoma canonico per il parser LR(0) √® un DFA utilizzato per decidere se fare reduce oppure shift. (quindi vede se prefisso viabile √® completo o meno).\nItem LR(0) üü© L‚Äôitem √® un costituente del DFA di supporto per il nostro DFA\nSlide\nIn pratica apro la produzione che ho, in un sacco di produzioni che contengono un punto, questo punto mi indica pi√π o meno quanto √® presente sulla stack.\nIntro Costruzione NFA dei prefissi üü®‚Äî Slide\nL‚Äôidea per questo algoritmo √® utilizzata per gestire la grammatica aumentata degli item!.\nAvanzamento dell‚Äôitem, in questo caso avanzo semplicemente il punto (vado in stato corrispondente con punto in pi√π!) Letttura di un altro simbolo, collegamento epsilon a quest‚Äôaltro punto. Esempio\nClos e Goto üü©- Slide algo\nQuesti due algoritmi codificano in pseudocodice i concetti precedenti.\nClos, √® utilizzato per lettura di un altro collegamento epsilon, dato che va a checkare tutte le produzioni con quel coso in pi√π, simula tutto il raggiungibile senza leggere in un certo senso. Goto √® per avanzare il punto, quindi mi crea tutte le produzioni con avanzamento del punto, e le chiude, specificatamente alle produzioni in una certa forma. simula una lettura in un certo senso. Queste saranno delle funzioni di supporto per la costruzione dell\u0026rsquo;automa canonico di riferimento, cos√¨ non dovremo passare all\u0026rsquo;algoritmo esponenziale per la costruzione del DFA, l‚Äôautoma canonico.\nCostruzione dell‚Äôautoma canonico üü® Slide algo\nQuesto algoritmo parte dal NFA dei prefissi viabili, e utilizza Goto e Clos per trovare il NFA in modo molto efficiente!\nEsempio 1\nEsempio 2\nTabella di parsing LR üü© Slide, descrizione generale, molto simile a LL\nCostruzione tabella per LR(0)\nEsempio tabella di parsing\nEsempio 2\n","permalink":"https://flecart.github.io/notes/bottom-up-parser-lr0/","summary":"Descrivo ora alcune domande utili per ripasso:\nQuali sono schematicmente quali sono le operazioni migliori per un parser top-down? Cosa √® un prefisso viabile? Quali sono i conflitti possibli, e come risolverli‚Ä¶ Non sai nemmeno definire inmodo formale cosa sia un item Bottom up Intro shift-reduce e LR üü© Slide\nIn breve:\nShift = simbolo terminale messo nella stack Riduzione utilizzando una produzione LR = dettura da Sinistra, creazione della stringa da destra (derivazione rightmost) Algoritmo classico üü®+ Quello che credo che intendevo per questo algoritmo classico √® quello non deterministico, nel senso che prova a fare backtracking, finch√© non ha finito tutte le possibilit√†, oppure trova la derivazione giusta.","title":"Bottom-up Parser LR(0)"},{"content":"Nozioni da avere prima di Cambio di Base Applicazioni lineari La definizione di applicazione lineare La matrice associata L\u0026rsquo;esistenza e unicit√† di una applicazione lineare rispetto a una base Le coordinate di un punto rispetto a una base. Matrice del Cambio di Base Se ho due spazi vettoriali\nIntuizione in $R$ Le coordinate dei punti in $R$ sono uguali a $V$ per le basi canoniche, ma questo vale solamente per $R$, ora vogliamo andare a dire una cosa pi√π forte, il cambio di base Poi sar√† importantissimo questa nozione, applicazione di base in ML √® Principal Component Analysis. Se ho una applicazione lineare $F: V \\to W$ e un insieme di basi del dominio e del codominio, allora esiste una matrice $A \\in M_{m \\times n} (\\mathbb{R})$ tali che vale il cambio di base.\nQuesta matrice me la costruisco mettendo per ogni colonna le coordinate di $F(v_1)$ rispetto alla base del vettore di arrivo.\n$F(v)_{\\beta '} = A v_{\\beta}$ cio√® le coordinate di v rispetto alla base d arrivo √® uguale a una matrice (costituita dalle coordinate dell\u0026rsquo;immagine delle basi ) per il vettore coordinate iniziali.\nDal libro\n5.2.1 Matrici associate all‚Äôidentit√† Questa mÃÄatrice sono per applicazioni lineari del tipo $f:V \\to W$, $V = W$ e ele due basi sono l\u0026rsquo;identit√†. Allora la matrice associata a queste due basi √® $I_{\\beta \\beta'}$\nSe le due basi sono esattamente le stesse, allora posso dire che √® la matrice identit√†, la cosa un p√≤ cambia quando le basi sono diverse.\nOvvero se mando la stessa base, le coordinate non cambiano, quindi riesco a costruirmi abbastanza in fretta la matrice identit√†.\nOssia $I_{\\beta\\beta} = I$, che √® uguale rispetto a una base canonica qualunque.\nQuindi la matrice associata a questa √® $$ \\begin{pmatrix} 1 \u0026 0 \\\\ 0 \u0026 1 \\end{pmatrix} $$ e simili\n5.2.2 L‚Äôinversa della composta dell‚Äôidentit√† Nel libro della prof questa √® la proposizione (8.2.2), ed √® molto importante\nSi ha che $I_{eb} = I_{be}^{-1}$, ovvero la matrice identit√† per certe basi √® esattamente l\u0026rsquo;inversa. Questo perch√© supponendo che le matrici associate si comportano bene per la moltiplicazione, ho che $I_{eb}I_{be} = I_{bb} = I$ ovvero √® l\u0026rsquo;applicazione identit√†. E bisogna anche verificare l\u0026rsquo;inverso quindi $I_{be}I_{eb} = I_{ee} = I$\n5.2.3 Coordinate di un vettore rispetto a una base non canonica Sia v un vettore nel nostro spazio, e sia b una base di Rn allora si ha che\n$(v)_{\\beta} = I_{\\beta e}^{-1}v$.\nPrendiamo in considerazione la matrice $I_{e\\beta}$, allora\n$id(v)_{\\beta} = I_{e\\beta}(v)_e$ per come abbiamo definito la matrice, ossia riusciamo a calcolarci le coordinate di v nella nuova base, utilizzando il teorema di sopra /\n5.2.4 Composizione fra matrici con basi qualsiasi Posso dimostrare che un fatto dimostrato precedentemente si comporta bene anche con basi qualsiasi.\nOvvero vogliamo dimostrare che date le funzioni $F: A \\to B, G: B\\to C$ con ognuna una base, voglio una matrice associata per la composizione di funzioni si comporti bene. (comunque s√¨ si pu√≤ dimostrare)\n5.3 Il cambio di base L\u0026rsquo;idea principale di questo cambio di base per applicazioni lineari √® ricondurci a una base voluta, pi√π comoda per i nostri calcoli, quindi passare da qualcosa in mezzo\nQuindi avremo una applicazione lineare del tipo:\n$A_{\\beta\\beta'} = I_{e'\\beta'} A_{ee'}I_{\\beta e} = I_{\\beta'e'}^{-1} A_{ee'}I_{\\beta e}$ ricordandosi che applico le funzioni a destra per prime.\n(da notare che la la matrice $I_{\\beta e}$ √® molto semplice da calcolare, perch√© l\u0026rsquo;insieme di arrivo √® canonico, e quindi √® semplice.\nAutovalori e Autovettori Moved to Autovalori e Autovettori the 19th of July 2024.\n","permalink":"https://flecart.github.io/notes/cambio-di-base/","summary":"Nozioni da avere prima di Cambio di Base Applicazioni lineari La definizione di applicazione lineare La matrice associata L\u0026rsquo;esistenza e unicit√† di una applicazione lineare rispetto a una base Le coordinate di un punto rispetto a una base. Matrice del Cambio di Base Se ho due spazi vettoriali\nIntuizione in $R$ Le coordinate dei punti in $R$ sono uguali a $V$ per le basi canoniche, ma questo vale solamente per $R$, ora vogliamo andare a dire una cosa pi√π forte, il cambio di base Poi sar√† importantissimo questa nozione, applicazione di base in ML √® Principal Component Analysis.","title":"Cambio di Base"},{"content":"La deduzione naturale √® un possibile sistema deduttivo che utilizza il linguaggio naturale per questo motivo pi√π beginner friendly. Lo facciamo prima per la Logica Proposizionale che √® molto facile\nIl sistema deduttivo Poniamo l\u0026rsquo;esistenza di Assiomi (formule in una certa logica) e regole di inferenza definite sotto. Esempi sono $P \\vdash \\varphi$ se $\\varphi$ √® un assioma. O altre cose simili con $\\land$ e simili\u0026hellip;\nUna dimostrazione allora √® una sequenza di $\\varphi_{1}, \\dots, \\varphi_{n}$ dove $\\varphi_{i}$ √® derivata con le regole di inferenza e $\\varphi_{1}, \\dots, \\varphi_{i - 1}$.\nLa differenza con la deduzione naturale √® che solitamente non ci sono assiomi\nSintassi Caratteristiche della sintassi (4) Si utilizza una BNF bidimensionale per rappresentare la ramificazione di una dimostrazione in deduzione naturale (cos√¨ possiamo capire bene in quale parte del ramo viene utilizzata l\u0026rsquo;ipotesi).\nRadice √® la conclusione, anche indicata come top. Nodi sono rappresentate da alcune formule Le foglie sono formule scaricate (con parentesi quadre), queste sono ipotesi locali che valgono solo in quel ramo (come l\u0026rsquo;analisi per l\u0026rsquo;or). Le foglie non scaricate rappresentano le ipotesi del problema La ricorsivit√† Come caratteristica delle BNF io opero in modo ricorsivo su sotto-alberi pi√π semplici.\nPer ogni albero utilizzo delle regole di eliminazione o di introduzione per collegare gli alberi insieme, ecco che utilizzo le regole di introduzione ed eliminazione per collegare le regole fra di loro e cos√¨ faccio la verifica di correttezza della dimostrazione.\nRegole di inferenza Sintassi delle regole di inferenza Doppia lettura (top-down, bottom up)!\nDove al corrispondente del numeratore si hanno le ipotesi necessarie (che nel caso siano 0 si dicono assioma, in modo differente rispetto all\u0026rsquo;utilizzo finora)\nFormula di $\\Gamma$ sono chiamati assioni Regole senza ipotesi sono assiomi Quindi questa definizione di assioma pu√≤ avere pi√π denotazioni, (ambigua?) no! perch√© √® un insieme pi√π grande che comprende entrambe le possibilit√†.\nDevo dimostrare anche la verit√† di quelle ipotesi, posso allargare l\u0026rsquo;albero sopra!\nIn modo pi√π generale\nRegole di introduzione ed elimitazione Queste regole sono state per la prima volta utilizzate in Teoria assiomatica degli insiemi per i primi esercizi.\nCome faccio a concludere qualcosa sapendo qualcosa?\nCosa viene ricavata da una conoscenza?\nRegole Bottom up e top down Di solito le dimostrazioni sono presentate come bottom up, perch√© √® considerato pi√π elegante, ma di solito si lavora sulla conclusione nel caso di troppe ipotesi (due letture per BNF)\nCorrettezza di una regola Poi si potr√† dimostrare che si avr√† conseguenza logica per regole assemblate fra di loro. (ipotesi scaricate, devono essere rappresentate con un implica, ricorda che scaricate vuol dire che hanno ipotesi locali).\nInvertibilit√† di una regola Motivo: Ci permette di dire che le regole che stiamo dimostrando saranno poi ancora conseguenze logiche per la nostra tesi finale.\nNon scegliere regole non invertibili se posso ancora utilizzare una regola invertibile Valutare intuitivamente la \u0026ldquo;pericolosit√†\u0026rdquo; di questa regola. (come se fosse un se solo se) (equivalenza logica fra tante formule, mentre di solito √® una formula sola); Dimostrazione correttezza e invertibilit√† di regole classiche 7.3.1 AND ‚àß L\u0026rsquo;AND intro- corretta e invertibile.(per invertibilit√†, devo espandere secondo le regole della semantica).\n$$ \\dfrac{A \\,\\,\\, B }{A\\wedge B} $$ Quindi la dimostrazione della regola di introduzione dell\u0026rsquo;and √® vera, posso sempre spezzare quando mi pare.\nDimostrazione\nAND elim - La regola di eliminazione ci permette di utilizzare una ipotesi a scelta collegate con il connettivo dell\u0026rsquo;and\nRegola di eliminazione classica\nDimostrazione\nNon invertibilit√†\nFormula di eliminazione pi√π generale\nDimostrazione\nRicorda associativit√† a destra di $\\implies$\nNon invertibilit√† parziale\nMa si pu√≤ vedere che non sia invertibile\n7.3.2 OR ‚à® Introduzione\nEnunciato\nCorrettezza\nNon invertibilit√†\nPerch√© √® invertibile in un caso, e non nell\u0026rsquo;altro utilizzando le regole di eliminazione dell\u0026rsquo;OR ma non √® ancora conseguenza logica)\nQuesta regola non √® invertibile! Spesso non va bene utilizzarlo.\nEsempio non-invertibilit√†.\nConsideriamo l\u0026rsquo;opzione $A \\vee \\neg A$ , quest √® conseguenza logica in tutti mondi, la dimostrazione √® molto semplice. quindi $\\Vdash A \\vee \\neg A$\nPer√≤ A / quello di sopra, non √® vero in tutti i mondi, quindi possiamo dire che le due non sono equivalenti, quindi non √® invertibile.\nQuindi $\\not\\Vdash A$ e $\\not \\Vdash \\neg A$.\nLa best practice √® utilizzare le ipotesi, e la top down non vale sempre, bisogna avere pi√π ipotesi\u0026hellip;.\nEliminazione\nIn generale mi devo ridurre a ragionare nei mondi in cui solamente F1 o F2 valgono (un mondo pi√π particolare), e poi ricompongo per dimostrare F3.\nperch√© √® possibile restringersi su un mondo particolare prima di analizzarli? Perch√© alla fin fine li sto analizzando tutti, ma in tempi (o rami diversi)\n√à una regola molto molto invertibile, quindi √® da utilizzare subito!\nEnunciato\nCorrettezza\nInvertibilit√† simile a AND\n7.3.3 Bottom e Top Bottom\nEnunciato\nSi pu√≤ notare che c\u0026rsquo;√® l\u0026rsquo;armonia anche qua, non c\u0026rsquo;√® nessun caso di introduzione e quindi non ho ipotesi nell\u0026rsquo;eliminazione.\nQuesta non √® una regola invertibile, ossia non √® vero che $F \\Vdash \\bot$ perch√© bot √® sempre falso.\nTop\nIl Top √® un assioma, unico assioma in questa sintassi in quanto non ho bisogno di ipotesi per dimostrarlo. (Notare che non √® una foglia).\nEnunciato\nL\u0026rsquo;eliminazione del top √® inutile, perch√© √® gi√† insita l\u0026rsquo;ipotesi in un altro, per√≤ puoi notare che √® invertibile. infatti $F \\Vdash \\top$\n7.3.4 Implicazione materiale Introduzione\nQuesta regola √® molto forte, sia corretta sia invertibile, perch√© la dimostrazione possiede sia LHS sia RHS le stesse cose quasi\nEnunciato\nDimostrazione invertibilit√† e correttezza\n$F_1 \\implies F_2 \\Vdash F_1 \\implies F_2$ ovvia\u0026hellip;.\nEliminazione\nLa cosa strana √® che in questo caso devo dimostrare anche l\u0026rsquo;ipotesi.\nEcco che questa non √® invertibile\u0026hellip; √à la cosa che mi rende difficile la dimostrazione perch√© dopo quelle regole invertibili ho queste ipotesi con implicazioni e non √® sempre ovvio.\nEnunciato\nCorrettezza\nNon invertibilit√†\n7.3.5 Negazione Questa √® quello che creer√† la necessit√† di una altra logica, perch√© il not me lo rende complesso..\nSi pu√≤ dire che Non F √® una altra denotazione di questa implicazione: $F \\implies \\bot$ perch√© gli unici casi in cui vale questo √® che le ipotesi siano false.\nIntroduzione\nEnunciato\n$F_1 \\implies \\bot \\Vdash\\neg F_1$\nInvertibilit√†\nMolto simile a quello sopra, riesco a dimostrare l\u0026rsquo;assurdo\nEliminazione\nEnunciato\nQuando riesco a dimostrare l\u0026rsquo;assurdo posso dimostrare qualunque cosa, la teoria √® inconsistente.\nQuesto mi elimina il Not, per√≤ mi rende tutto inconsistente.‚ÄºÔ∏è In questo ramo tutto diventa invertibile! ‚ÄºÔ∏è Diventa solamente un gioco meccanico.\n7.3.6 RAA Reductium ad abdsurdum Questa regola √® molto simile all\u0026rsquo;introduzione del not ed √® necessario per avere la completezza per la deduzione semantica\nEnunciato\nDimostrazione\n7.4 Derivabilit√† Intuitivamente\nQueste regole di derivabilit√† sono molto utili per stabilire l\u0026rsquo;eguaglianza fra regole diverse (quando una √® derivabile dall\u0026rsquo;altra e viceversa..\n7.4.1 Dimostrazione per induzione strutturale Intuitivamente:\nDate due insieme delle regole, posso fare la dimostrazione utilizzando le regole con l\u0026rsquo;altro insieme e la dimostrazione √® uguale.\n!\n7.4.2 Derivabilit√† delle eliminazioni di AND Questo teorema e dimostrazione √® molto utile per stabilire l\u0026rsquo;equaglianza delle due regole, in altre parole ci sta dicendo che le due regole siano identiche.\nEnunciato e dimostrazione\nNOTA: per la seconda parte sto prendendo in esame solamente un sotto-albero di interesse.\n7.5 Armonia delle regole Sembra che il numero delle regole di eliminazione corrisponda con il numero di regole di introduzione per ogni connettivo. (e ognuno viene corrisposto)\nEliminazione ha un caso per ogni caso di introduzione e questa utilizza le regole di introduzione.\nNOTA: questo principio √® molto utile per guidarci nella creazione di regole\n7.5.1 Armonia OR Slide\n7.5.2 Armonia AND Slide\n7.6 Teorema completezza e correttezza meglio in Connettivi Logici, correttezza, variabili\n7.6.1 Correttezza Enunciato\nIl teorema di correttezza stabilisce la correttezza di tutte le regole date\nNotenotenote\nDimostrazioni di conseguenza logica\nDevi fissa il mondo porre coso giutsto e poi utilizzare la semantica del mondo.\n7.7 Deduzione naturale in logica di primo ordine Possiamo estendere la deduzione naturale con alcune regole di $\\forall, \\exists$ qui are la semantica del mondo.\n7.7 Deduzione naturale in logica di primo ordine Possiamo estendere la deduzione naturale con alcune regole di $\\forall, \\exists$ qui\nRegistro Ripassi Vecchi dubbi Come si dimostra la correttezza e l\u0026rsquo;invertibilita di una regola? il concetto di derivabilit√† Perch√© la eliminazione della negazione non √® l\u0026rsquo;introduzione del bottom? il concetto di armonia DA CHIEDERE Ripasso Prox: 15 Ripasso: December 22, 2021 Ultima modifica: September 30, 2022 3:19 PM Primo Abbozzo: November 10, 2021 9:33 AM Stato: üåïüåïüåïüåïüåï Studi Personali: No\n","permalink":"https://flecart.github.io/notes/deduzione-naturale/","summary":"La deduzione naturale √® un possibile sistema deduttivo che utilizza il linguaggio naturale per questo motivo pi√π beginner friendly. Lo facciamo prima per la Logica Proposizionale che √® molto facile\nIl sistema deduttivo Poniamo l\u0026rsquo;esistenza di Assiomi (formule in una certa logica) e regole di inferenza definite sotto. Esempi sono $P \\vdash \\varphi$ se $\\varphi$ √® un assioma. O altre cose simili con $\\land$ e simili\u0026hellip;\nUna dimostrazione allora √® una sequenza di $\\varphi_{1}, \\dots, \\varphi_{n}$ dove $\\varphi_{i}$ √® derivata con le regole di inferenza e $\\varphi_{1}, \\dots, \\varphi_{i - 1}$.","title":"Deduzione naturale"},{"content":"This small note sections tries to fix 5 important concepts in software engineering\nSub-system and modules üü© We need to differentiate from sub-system, which is a part of a system that tries to achieve some objective, and a module, which is more language specific way of saying imported file, or set of functions or classes.\nInformation hiding üü© This is a very important principle present in object oriented programming. Within this philosophy we should be able to access only public methods or data, this allows the construction of abstractions that allow us to think at a higher level.\nA good think about this is that changing implementation doesn\u0026rsquo;t change the interface, this allows lower level of coupling within the system.\nCoupling Meaning of coupling üü© Two methods are said to be highly coupled when every change to one of them, needs the other one to be changed too! Clearly if we have a highly coupled system refactoring is a hell of a nightmare. Low coupling provides independency, creating a easier to maintain software.\nCoupling sources (7) üü© There are many coupling sources, here is a not definitive list:\nFunction or method calling Data coupling, for example the prop drilling hell present in react, where you have to pass other data to other data on an indefinite chain. Hereditary coupling, where you have too long chain of sub-classes. OS-coupling, where you don\u0026rsquo;t have an equivalent function for other OSes Common coupling:, e.g. global variables, config files, that are used by many files. Content coupling: happens when the #Information hiding is not implemented, an other module directly sees internal data-structure of another module, implying a very bad implementation!. Cohesion üü© Cohesion is a concept that similarly to Memoria#4.2 Memoria Cache, with the location principle, common functions should be grouped together, the best thing that could happen is the functional cohesion, where code that tries to implement the same abstraction tries to be together, another one is content cohesion, where code that needs same input structure is close.\nA bad example is random ordering, where code with no shared meaning stays together.\nSimplicity üü© This is also one of the main pillars of Software engineering. In this case it is advised not to generalize too early, probably You aren\u0026rsquo;t gonna need it.\nWhen we are talking about methods instead, you should follow the principles explained in clean code, so keep the names descriptive, keep the public methods small and precise, use small functions, and keep code smell low (avoid duplicates for example).\n","permalink":"https://flecart.github.io/notes/general-swe-principles/","summary":"This small note sections tries to fix 5 important concepts in software engineering\nSub-system and modules üü© We need to differentiate from sub-system, which is a part of a system that tries to achieve some objective, and a module, which is more language specific way of saying imported file, or set of functions or classes.\nInformation hiding üü© This is a very important principle present in object oriented programming. Within this philosophy we should be able to access only public methods or data, this allows the construction of abstractions that allow us to think at a higher level.","title":"General SWE principles"},{"content":"Con la logica proposizionale studiamo le denotazioni che hanno un valore di verit√†, ovvero deve essere una sentenza assertiva. Studio solamente le connotazioni che hanno una capacit√† denotativa, in quanto √® solo quello ch emi importa.\n6.1 La sintassi Vengono qui definite le produzioni che valgono in ogni singolo mondo.\n$$ F ::= \\top|\\bot|A|B|...|\\not F| F \\wedge F| F \\vee F| F \\implies F $$ Questa √® la BNF della nostra sintassi.\nLe lettere sono asserzioni, sono sentenze dichiarative a cui posso dare un valore\nConnotazioni atomiche Sono solamente ABCD e le singole lettere che rappresentano le proposizioni.\n6.1.1 Formalizzazione Ovvero il tentativo di esprimere asserzioni attraverso la sintassi della logica proposizionale. Quindi dare un valore logico a frasi come oggi piove, marco √® bello, marco √® brutto e simili. Quest √® importante perch√© √® probabile che all\u0026rsquo;esame ci sia un esercizio di formalizzazione\n6.1.2 Note per attenzione Fare attenzione ai sinonimi e contrari, che devono avere la stessa lettera, non √® ovvio.\nUna altra cosa su cui fare attenzione sono le connotazioni ovvero modi diversi per dire la stessa denotazione come:\n$A \\implies B$ √® la denotazione delle connotazioni : A √® condizione sufficiente di B, B √® condizione necessaria di A e altro.\n6.2 La semantica La semantica classica associa il valore di verit√† per ogni connotazione del linguaggio. Allora si dice che stiamo utilizzando la logica proposizionale classica\nNoi parliamo tutti i giorni con una semantica naturale, principale o intesa sono tutti dei sinonimi Devo partire da alcune premesse filosofiche che mi portano alla logica classica.\n$filosofia \\implies logica \\implies matematica$\nNota di wiki La semantica studia il significato delle parole, quindi ci dice cosa deve significare una connotazione, e possono essere molto diverse: molte semantiche per una stessa sintassi.\nEsempio semantica (interpretazione) in prog Semantica che interpreta la sintassi in termini di tempo: Interpreto i miei costrutti come il tempo che impiega ad eseguire (molto utile per avere una complessit√† computazionale (es. if, vado a guardare guardia). Semantica che interpreta la sintassi in termini di memoria occupata. 6.2.1 Dominio di interpretazione, f semantica Dominio di interpretazione sono connotazioni (definite tramite BNF)\nDipende dai mondi in Verita, Teorie, modelli, connotazione, denotazione, ossia si pu√≤ interpretare la connotazione in modi diversi a seconda della denotazione in quello specifico mondo\nSi potrebbe dire che ogni mondo possieda una funzione semantica che parte da un dominio di interpretazione e denota queste connotazioni con oggetti precisi in un mondo.\n6.2.2 Enunciati della logica classica TODO: fai una parte a s√© per questo\nQuesta logica parla della verit√†.\nManicheo (visioni estreme)\nSulla falsit√† e verit√†\nOgni enunciato √® vero o falso (esistono gradi di verit√†, secondo alcuni, dibattibile ~Fuzziness) Ogni enunciato non pu√≤ essere vero o falso allo stesso momento Platoniche\nStaticit√† il valore di verit√† non muta nel tempo, immutabile. No libero arbitrio o possibilit√† di cambiare il proprio futuro (se √® una verit√†\u0026hellip;) ah i trip mentali. Determinatezza il valore di verit√† √® sempre determinato (simile al primo aristoteo?) Tutto il futuro √® predicibile e non si pu√≤ fare niente (ma mancano le conoscenze). Utilizzando queste due caratteristiche del valore di verit√† possiamo gi√† fare delle inferenze:\nDifferenza fra verit√† e conoscenza La conoscenza non possiede il senso di staticit√† e determinatezza (pu√≤ cambiare nel tempo (cresce), e non √® sempre quella) mentre la verit√† lo √®\nDifferenza fra verit√† e risorse La verit√† √® statica (si pu√≤ utilizzare quante volte si vuole), mentre le risorse vengono consumate (esempio cibo, se lo mangio scompare,o almeno non √® pi√π nella forma attuale).\nCritiche della logica intuizionista Esistono dei mondi non determinati che si possono determinare a seconda dei mondi, non posso avere una verit√† statica immutabile.\nNon vale per la conoscenza e mondi non-deterministici\n6.2.3 Booleani e funzione di interpretazione classica Scegliemo di indicare i booloani come 1 ‚Üí Vero 0 ‚Üí Falso Per tre motivi principali:\nPosso utilizzare le regole dell\u0026rsquo;algebra in quanto sono dei numeri e possiedono quelle propriet√† Non vanno in confuzione con top e bottom per il loro essere dei numeri (altrimenti avrei dovuto distinguere il vero e il falso a livello sintattivo, a livello denotativo e poi latro) Si pu√≤ facilmente trovare un intervallo di verit√†. Interpretazione Si pu√≤ definire (funzione di) interpretazione (classica) di un mondo, possibile solamente grazie all\u0026rsquo;esistenza di cui sopra dei boleani, che associa a ogni sentenza del mondo un valore di verit√†.\nAllora dato che √® una funzione, possiamo notare che possiede i valori di:\nStaticit√†, in quanto le funzioni sono solamente quelle e non cambiano Determinatezza per le propriet√† delle funzioni, ossia per ogni sentenza del mondo posso associare un valore di verit√†. 6.2.4 funzione semantica per la logica classica Questo √® definito tramite BNF e fissa il linguaggio della logica in un mondo preciso.\nNOTA: distingui bene la differenza fra valore semantico e interpretazione in un mondo.\n6.2.5 Tabella di verit√† Le tabelle di verit√† hanno senso solamente nell\u0026rsquo;ambito della logica classica, in quanto pu√≤ solamente rappresentare una logica finita,, quindi la classica non la intuizionistica.\nLe tabelle di verit√† sono le stesse viste in Porte Logiche (con una nota particolare sulla implicazione materiale, molto diversa dalla normale relazione di causalit√† utilizzata tutti i giorni\nSemantica Tarskiana\n√à una logica che utilizzano i matematici (molto lapalissiana, inutile dal punto di vista di nuove informazioni che la definizione riesce a dare) (Coen critica anche che questo √® perch√© i matematici se ne fregano della logica, di quello che sta sotto la matematica).\nPraticamente utilizza il linguaggio naturale per descrivere la funzione semantica descritta qui sopra, cosa che funziona solamente con la logica classica, e appena si esce da questo reame non ha pi√π senso. Utilizza troppe nozioni meta-linguistiche, tanto che potrebbe dire che meta-linquistica e linguistica siano quasi la stessa cosa\n6.3 Conseguenza logica (formale) Questa √® la definizione formale di conseguenza logica\n$$ \\Gamma \\Vdash F \\iff \\forall v, (\\forall G \\in \\Gamma, [G](/notes/g)^v = 1) \\implies [F](/notes/f)^v = 1 $$ NOTA 1 questa definizione non √® computabile, non √® direttamente studiabile in ambito informatico, allora c\u0026rsquo;√® bisogno della creazione di un #6.4 Sistemi deduttivi. (In questa definizione stiamo parlando di infiniti (di mondi v e assiomi G, che chiaramente non √® computabile quindi non √® possibile prendere decisioni in questo ambito).\nNOTA 2 Intelligenza artificiale forte, che possa sapere tutto, √® ucciso da questa osservazione, in quanto la computazione non pu√≤ arrivare a sapere tutto. (quindi non pu√≤ essere un programma\u0026hellip; mmmm).\n6.3.1 Equivalenza logica ovvero la semantica per ogni modello v di una teoria √® uguale, quindi possiamo dire che valgono per gli stessi mondi. $G \\equiv F \\iff \\forall v, [F](/notes/f)^v = [G](/notes/g)^v$\n6.4 Sistemi deduttivi 6.4.1 Intro Esistono sistemi deduttivi diversi, quella che vediamo noi √® la deduzione naturale.\nPossono variare per\nSintassi diverse Esigenze diverse Cosa √® un sistema deduttivo\nIl sistema deduttivo √® una nozione sintattica **che contiene in s√© una prova (dimostrazione) di una proposizione. (sintattico perch√© parla di connotazioni, non di denotazione esatta di quello presente sotto).\nDeve quindi utilizzare regole precise per le prove. Ci sono molti modi per fare regole, la pi√π naturale √® la deduzione naturale.\n6.4.2 Deduzione (3) $\\Gamma \\vdash F$, si legge da $\\Gamma$ deduco $F$, ed √® una nuova nozione sintattica (prova esplicita tale per cui la sintassi vada, quasi algoritmico). Poi si potr√† dire che ogni dimostrazione deve essere una conseguenza logica e il contrario. Dimostrazione √® un dato!\nDeve esserci una prova esplicita\n√à possibile scrivere una dimostrazione in una qualche sintassi, questo √® il significato di deduzione.\nSe √® sintatizzabile (si pu√≤ scrivere con una sintassi) si pu√≤ trasmettere ecco che si cerca una sintassi per le dimostrazioni.\nDeve essere corretta, ossia $\\Gamma \\vdash F \\implies \\Gamma \\Vdash F$\nDevo definire il motivo per cui le regole di dimostrazione siano giuste (Le varie regole di introduzione e eliminazione. non vale per le logiche espressive ma solo per la classica! Questa nozione √® dimostrata in quando parliamo di connettivi, anche se utilizza solamente il concetto di induzione strutturale per dimostrarla\u0026hellip;\nCompletezza (non per logiche espressive (?)) $\\forall \\Gamma, F, \\Gamma \\Vdash F \\implies \\Gamma \\vdash F$ vale per logiche semplici, ma esistono dimostrazioni logiche che non saremo mai in grado di dimostrare, in modo simile alla non implementabilit√† di funzioni matematiche, utilizzando paradossi.\nQuesta dimostrazione esiste ma √® molto complessa, lo ha saltato di striscio il prof.\n6.4.3 La deduzione naturale Studieremo la deduzione naturale in Deduzione naturale\n6.6 Definizioni 6.6.1 Tautologia $\\Vdash F$, quando √® √® conseguenza logica per tutto. Quindi √® anche una verit√† assoluta perch√© non dipende da mondo in esame. (la tabella logica in esame possiede solamente delgi uno).\nNot-tautologia ricorda che il contrario del per ogni √® l\u0026rsquo;esiste il not!, quindi basta un mondo in cui questa proposizione sia falsa.\n6.6.2 Soddisfacibilit√† e non Soddisfacibilit√†\nSi utilizza lo stesso simbolo $\\exists v,v \\Vdash F \\iff \\llbracket F \\rrbracket ^v = 1$ tale che v sia un mondo\nInsoddisfacibilit√†\nQuando non esiste nessun mondo, quindi per ogni mondo nno vale la cosa sopra.\n(Pi√π o meno questa propriet√† √®\nTaotologicit√† (teorema)\nSi pu√≤ dimostrare da sopra che una formula √® tautologica se per ogni mondo vale che la funzione semantica per input quella propriet√† si ha 1\nNota: tautologica implica soddisfacibile, quindi devi fare attenzione!\n6.6.3 Conseguenza logica per mondi diversi Ricondursi al concetto di variabile presente in Connettivi Logici, correttezza, variabili\nRagionamento Con questo per trovare una conseguenza logica mi posso ridurre a leggere le tabelle di verit√†.\nDrawback Le righe totali sono $2 ^n$ per le $n$ variabili totali, m per numeri grossi Non mi dice il perch√© sia una conseguenza logica. Quindi sappiamo che esiste ma non si fa mai.\n6.7 Deduzione semantica 6.7.1 Teorema di DS Questo teorema √® molto importante per dare il senso all\u0026rsquo;implicazione materiale. $$ \\Gamma \\Vdash F \\implies G \\iff \\Gamma, F \\Vdash G $$ Dim Destra Dim Sinistra Nota: dopo aver supposto che $v \\Vdash \\Gamma$, sto utilizzando l\u0026rsquo;eliminazione dell\u0026rsquo;or $F \\vee \\neg F$ per finire la dimostrazione (questa √® una tautologia).\n6.7.2 Corollario DS La conclusione dovrebbe essere quasi banale grazie al teorema sopra. (Questo mi diche che sono quasi **infinite le tautologie**!) Possiamo trovare cose vere in ogni mondi. 6.7.3 Teoremini $\\Vdash F \\iff \\neg F$ insoddisfacibile $\\Gamma$ Insoddisfacibile sse $\\Gamma\\Vdash \\bot$ e √® soddisfacibile nel caso in cui non √® conseguenza logica $\\Gamma \\Vdash F \\iff \\Gamma,\\neg F$, insoddisfacibili.,Gamma finito $\\neg F \\equiv F \\implies \\bot$ ash \\bot$ e √® soddisfacibile nel caso in cui non √® conseguenza logica $\\Gamma \\Vdash F \\iff \\Gamma,\\neg F$, insoddisfacibili.,Gamma finito $\\neg F \\equiv F \\implies \\bot$\n","permalink":"https://flecart.github.io/notes/logica-proposizionale/","summary":"Con la logica proposizionale studiamo le denotazioni che hanno un valore di verit√†, ovvero deve essere una sentenza assertiva. Studio solamente le connotazioni che hanno una capacit√† denotativa, in quanto √® solo quello ch emi importa.\n6.1 La sintassi Vengono qui definite le produzioni che valgono in ogni singolo mondo.\n$$ F ::= \\top|\\bot|A|B|...|\\not F| F \\wedge F| F \\vee F| F \\implies F $$ Questa √® la BNF della nostra sintassi.","title":"Logica Proposizionale"},{"content":"Analisi macroscopica Setting dell\u0026rsquo;esperimento üü© Provare a guardare 269 del Mazzoldi. (227 per la defivazione della forza.) Si pu√≤ dimostrare che $$ \\vec{F} = -\\vec{\\nabla} \\cdot U \\implies F = -\\vec{\\nabla}(\\vec{m} \\cdot \\vec{B}) = \\pm m \\frac{dB}{dx} $$ La prima relazione si deriva da definizione di lavoro e forza. (esteso al caso di una forza applicata su spira che non √® banale, facciamola brevemente).\nSappiamo che $U = - m \\cdot B$, quindi √® vero che $dW = -dU = i d \\Phi (B)$ e poi utilizzando una propriet√† del gradiente in Divergenza e Circuitazione abbiamo $$ Fds = dW = -dU = i \\nabla \\Phi(B) ds \\implies F = i\\nabla \\Phi(B) = m \\cdot \\nabla B = -\\nabla U $$ La cosa da notare √® che per campi uniformi abbiamo che si pu√≤ definire il lavoro.\nComunque questo esperimento √® stato importante per dire che se metto un materiale nella bobina, a volte viene attratta, altre volte respinta, quindi faceva pensare che esiste qualcosa nel materiale che induceva queste cose.\nMagnetizzazione üü© Considerando la forza per unit√† di volume si pu√≤ introdurre la densit√† del momento magnetico, anche chiamata magnetizzazione.\n$$ M = \\frac{m}{\\tau} $$ Campo magnetico in materiali Possiamo misurare il campo magnetico tramite una sonda di Hall, e otteniamo se il solenoide √® immerso in un campo magnetico abbiamo: $$ \\frac{B}{B_{0}} = k_{m} $$ Simile a quanto abbiamo fatto in Condensatori con dielettrici.\nPermeabilit√† magnetica relativa üü© $$ \\mu = \\mu_{0} k_{m} $$ In modo simile a quanto fatto per la costante dielettrica.\nInterpretazione correnti Amperiane üü© Quindi vengono create delle sorte di correnti sul nostro materiale quando questa viene sommersa in un certo campo magnetico, che hanno modulo $$ \\vec{B}_{m} = \\mu_{0}\\chi_{m}ni $$ Vedere pagina 272 del Mazzoldi. Ed effettivamente ci sono delle correnti cos√¨ indotte su questo materiale. Si potranno studiare da un punto di vista microscopico dopo.\nSuscettivit√† magnetica üü© Ci dice quanto √® cambiato il campo magnetico passando di mezzo, e quindi abbiamo: $$ \\chi_{m } = k_{m } - 1 $$ Classificazione di sostanze magnetiche Diamagnetiche üü© Se $k_{m} \u003c 1$ Ossia le correnti amperiane hanno verso opposto.\nparamagnetiche üü© Se $k_{m} \u003e 1$. In cui si ha anche una dipendenza con la temperatura. A temperatura normale questo sono piccolissime\nFerromagnetiche üü© Quando la differenza √® tipo $10^{3}$, ed √® una relazione non lineare.\nConsiderazioni microscopiche Analisi del momento angolare Questa analisi √® verso pagine 234 del Mencuccini, da fare un po\u0026rsquo; meglio.\nProviamo a considerare il modello di Rutherford (credo), in cui abbiamo un atomo centrale e poi roba (elettroni) che ci girano attorno.\nConsiderando un singolo elettrone abbiamo, che il momento angolare (credo si chiami cos√¨, da controllare) √® $$ \\vec{L} = \\vec{r} \\times m\\vec{v}_{e} \\implies L = rm v_{e} $$ Dove $v_{e}$ √® la velocit√† dell\u0026rsquo;elettrone e anche $m$ √® la massa dell\u0026rsquo;elettrone. Inoltre sappiamo, per definizione che $m = i\\pi r^{2} = -\\frac{evr}{2}$ Dove abbiamo preso $i = -\\frac{e}{T} = -\\frac{ev}{2\\pi r}$ Combinando le equazioni del momento magnetico e della corrente elettrica si ha $$ \\vec{m}= -\\frac{er}{2} \\left( \\frac{\\vec{L}}{rm} \\right) = -\\frac{e}{2m} \\vec{L} $$ Dove si ha una chiara relazione fra momento magnetico (quella cosa necessaria per magnetizzazione) direttamente nel nucleo di un atomo.\nMagnetone di Bohr Seguendo il modello di Sommerfield-Bohr in cui il momento angolare viene quantizzato, esiste anche un momento magnetico intrinseco dovuto allo spin dell\u0026rsquo;elettrone, che segue praticamente la stessa legge di sopra: $$ \\mu_{e} = \\frac{e}{2m} \\hbar $$ dove lo spin √® uguale a $\\lvert S \\rvert = \\frac{1}{2}\\hbar$ Questa costante trovata di sopra √® detta magnetone di Bohr che √® da notare opposta al momento magnetico precedente. Infatti nella maggior parte dei materiali questo si cancella, mentre in alcuni materiali non succede, e abbiamo il paramagnetismo.\nModello diamagnetismo In questo modello si assume che non ci sia momento magnetico intrinseco degli atomi, si pu√≤ dimostrare che abbiamo un moto di precessione:\nAbbiamo\n$$ \\vec{M} = \\vec{m} \\times \\vec{B} = -\\frac{e}{2m} \\vec{L} \\times \\vec{B} $$ E che $$ M = \\frac{dL}{dt} = \\vec{\\omega_{L}} \\times \\vec{L} \\implies \\vec{\\omega_{L}} = \\frac{e}{2m}\\vec{B} $$ Dove il secondo √® una velocit√† angolare indotta dal campo magnetico che implica un moto di precessione. Questa √® la precessione di Larmor.\nQuesta precessione di Larmor induce una corrente uguale a: $$ \\Delta i = -\\frac{e}{T_{L}} = -\\frac{e}{2\\pi}\\omega_{L} = -\\frac{e^{2}}{4\\pi m}B $$ Che induce un momento magnetico $$ \\Delta m = i\\pi r^{2} = -\\frac{e^{2}r^{2}}{4m}B $$ Ora conviene analizzare questo dato da un punto di vista mean field theory e assumere un raggio medio perch√© non conosciamo il valore di $r$ nell\u0026rsquo;orbita di precessione nemmeno il verso rispetto al campo magnetico esterno. Quindi prendiamo una media, assumiamo una simmetria sferica $x^{2} + y^{2} + z^{2} = r^{2}$ che che i tre assi siano equamente equiprobabili, quindi $x^{2} = y^{2} = z^{2} = \\frac{r^{2}}{3}$\nCon questo abbiamo che il raggio medio sulla stessa orbita dell\u0026rsquo;elettrone (piano xy) diventa ora $r_{i}^{2} = x^{2} + y^{2} = \\frac{2}{3} r^{2}$ Se messo dentro l√¨ sopra abbiamo ora\n$$ \\Delta m = -e^{2} \\frac{r^{2}}{6m} B $$ E nel caso ci siano pi√π elettroni prendiamo un raggio medio, e si avr√† lo stesso valore.\nApproccio in classe non compreso (non fare) Possiamo da questo ricavare la velocit√† angolare di cui troviamo il valore sia $$ \\omega_{0} = \\frac{v}{r} = \\frac{L}{r^{2}m_{e}} $$ Poi notiamo che $\\vec{m} \\parallel \\vec{L}$ perch√© entrambi perpendicolari alla nostra spira-elettrone. abbiamo poi che $$ i = -\\frac{e}{T}, \\vec{m}_{0} = -\\frac{e}{T} \\pi r^{2} \\hat{u}_{n}, v = \\omega r, L = r m_{e} \\omega r = m_{e} \\omega r^{2} $$ Poi abbiamo anche che: $$ T = \\frac{2\\pi}{\\omega} = \\frac{2\\pi}{L} r^{2}m_{e} $$ Utilizzando quanto avevamo ricavato prima sulla velocit√† angolare dell\u0026rsquo;elettrone.\nQuesto si pu√≤ mettere dentro al momento magnetico $$ \\vec{m}_{0} = i \\Sigma = -\\frac{e \\vec{L}}{2m_{e}} $$ Nel momento in cui una sostanza √® in un campo magnetico, sar√† generata una corrente che si oppone, e si avr√† una forza repulsiva, questo c\u0026rsquo;√® sempre in tutto.\nOgni atomo crea un momento magnetico all\u0026rsquo;interno del suo atomo.\nAltre cose, abbiamo che\n$$ \\vec{M} = i\\vec{S} \\times \\vec{B} = \\vec{\\omega_{L}} \\times \\vec{L} $$ Noi dovremmo essere in grado di sapere quanto sia la corrente e la superficie e in questo modo dovrei riuscire a ricavare omega.\nLe sostanze diamagnetiche vengono solo respinte. (??)\n$$ \\vec{m}_{L} = -\\frac{e^{2}}{6m_{e}} \\left( \\sum_{i=1}^{z} r_{i}^{2} \\vec{B} \\right) $$ Facciamo una altra analisi, fra la frequenza di Larbor e quella originale, Larbor √®. Poi sapendo che $T_{0} = 1.5 \\cdot 10^{-16}s$ e abbiamo che la massa √® $9.1 \\cdot 10^{-31} kg$. $$ \\omega_{L} = \\frac{eB}{2m_{e}} $$ E vorremmo chiederci se la frequenza di Larbor sia maggiore o minore rispetto a quella iniziale. E si scopre in qualche modo che se $B \\ll 5 \\times 10^{5} T$ si avr√† che il periodo di Larbor √® molto piccolo rispetto a quello iniziale. E nella realt√† max 100 tesla, e non si riesce a raggiungere.\nTutta la parte sopra dovrebbe essere fatta prima pagina 274 del mazzoldi.\nLarmor üü®\u0026ndash; Quando proviamo a definire il momento angolare, tramite una velocit√† angolare e inerzia, introduciamo la velocit√† angolare di Larbor\n$$ \\vec{M} = \\vec{\\omega}_{L} \\times \\vec{L} $$ Questo si pu√≤ mettere in relazione con $$ \\vec{M} = \\vec{m}_{0} \\times \\vec{B} = \\vec{\\omega}_{L} \\times \\vec{L} $$ E troviamo il risultato $$ \\omega_{L} = \\frac{eB}{2m_{e}} $$ Con questo possiamo andare a definire un momento di Larmor.\nOssia: $$ m_{L} = i_{L}S_{L} = -\\frac{e}{T_{L}} S_{L} $$ E abbiamo che $$ T_{L} = \\frac{2\\pi}{\\omega_{L}} \\implies \\frac{4\\pi m_{e}}{eB} $$ E questo si pu√≤ sostituire si sopra e otteniamo che il momento di Larbor √®:\nPrecessione di Larmor üü®\u0026ndash; Abbiamo detto che abbiamo un fattore di momento angolare che √® dipendente dal campo magnetico, per questo motivo possiamo spiegare l\u0026rsquo;effetto del campo magnetico nel creare correnti (in questo caso l\u0026rsquo;elettrone che si muove).\nMomento magnetico per unit√† di volume üü©\u0026ndash; momento magnetico per unit√† di volume √® uguale al momento magnetico del nostro atomo per il numero di atomi per unit√† di volume, e abbiamo un valore di magnetizzazione che √® in pratica una corrente amperiana. In formule: $$ \\vec{M} = \\frac{\\Delta \\vec{m}}{\\Delta \\tau}, \\Delta \\vec{m} = n $$ Con N il numero di atomi per unit√† di volume e $\\vec{m}$ il momento magnetico per unit√† di volume.\n$\\vec{M}$ descritto sopra √® il momento magnetico per unit√† di volume, chiamato anche MAGNETIZZAZIONE.\nConsideriamo ora un cilindro con un certo momento magnetico. Per un certo principio di equivalenza di Ampere, possiamo dire che il momento magnetico\u0026hellip; (vedere pagina 275 Mazzoldi).\n$$ dm = di_{m}dS\\hat{u} = M dSdz\\hat{u} \\implies di_{m} = Mdz $$ Ma tutte le correnti interne si elideranno, e questo sar√† equivalente a un circuito esterno (una spira per dire), questo motiva anche l'utilizzo del solenoide, perch√© sembra simile a questo setting. Vedere [Geometrie di spire](/notes/geometrie-di-spire). allora: $$ i_{m} = \\int \\, di_{m} = \\int M \\, dz = Mh $$ Possiamo definire il concetto di densit√† lineare di corrente amperiana come $j$ $$ j_{m} = \\frac{i}{h} = \\lvert M \\rvert = \\vec{M} \\times \\hat{u} $$ Caso Magnetizzazione non uniforme üü®\u0026ndash; Questo rende la cosa un po\u0026rsquo; pi√π compelssa perch√© le correnti amperiane non si cancellano. Consideriamo il setting in figura: abbiamo che $$ di_{1} - di_{2} = (M_{z} - M'_{z})dz = -\\frac{\\delta M_{z}}{dx} dxdz $$ Cos√¨ abbiamo la corrente che scorre lungo $y$ nel disegno di sopra, ma ho un contributo lungo $y$ anche dal cubo di una altra direzione! Si pu√≤ ripetere la stessa cosa, su una direzione diversa. $$ di_{3} - di_{4} = (M'_{x} - M_{x})dx = \\frac{\\delta M_{x}}{\\delta z}dzdx $$ E possiamo considerare ora il valore totale:\n$$ di = di_{1} - di_{2} + di_{3} - di_{4} = \\left( \\frac{\\delta M_{x}}{\\delta z} - \\frac{\\delta M_{z}}{\\delta x} \\right) dxdz $$ E si pu√≤ estendere questo concetto il rotore facendo praticamente la stessa cosa anche per altri e abbiamo:\n$$ j = \\vec{\\nabla} \\times \\vec{M} $$ dove $j$ √® la densit√† lineare di corrente.\nIn forma integrale abbiamo: $$ \\oint_{\\Gamma} \\vec{M} d\\vec{l} = i_{m} $$ Equazioni del campo magnetico revisited üü©- abbiamo che $$ \\oint_{\\Gamma} \\vec{B} \\cdot d\\vec{l} = \\mu_{0} (i_{c} + i_{m}) = \\mu_{0}i_{c} + \\mu_{0} \\oint_{\\Gamma} \\vec{M} \\cdot d\\vec{l} $$ Dove aggiungiamo anche la corrente di ampere oltre la corrente concatenata.\nPortando dall\u0026rsquo;altra parte abbiamo: $$ \\oint_{\\Gamma} (\\vec{B} - \\mu_{0} \\vec{M}) \\cdot d\\vec{l} = \\mu_{0}i_{c} $$ E dividendo per $\\mu_{0}$ si ha\n$$ \\oint_{\\Gamma} \\left( \\frac{\\vec{B}}{\\mu_{0}} -\\vec{M} \\right) \\cdot d\\vec{l} = i_{c} $$ In cui abbiamo una altra sorgente del campo magnetico che √® dipendente dal materiale presente al campo magnetico.\nForma divergente üü© $$ \\vec{\\nabla} \\times \\vec{B} = \\mu_{0}(\\vec{J} + \\vec{J}{M}) = \\mu{0}(\\vec{J}_{c} + \\vec{\\nabla} \\times \\vec{M}) \\vec{\\nabla} \\times (\\vec{B} - \\mu_{0} \\vec{M}) = \\mu_{0} \\vec{J}_{c} $$\nCampo di magnetizzante üü©- In modo simile al campo di induzione elettrica o vettore di spostamento, √® sensato definire una nuova dimensione $$ \\vec{H} = \\frac{\\vec{B}}{\\mu_{0}} - \\vec{M} $$ In modo simile a quanto fatto in Condensatori con dielettrici in cui definiamo il vettore di spostamento, la cosa carina √® che: $$ \\vec{\\nabla} \\times \\vec{H} = \\vec{J}_{c} $$ E $$ \\oint_{\\Gamma} \\vec{H} d\\vec{l} = i_{c} $$ Dimensione Ampere su Metro, la stessa del vettore di magnetizzazione.\nRelazioni M, H, B üü©\u0026ndash; VALGONO SOLO PER MATERIALI NON FERROMAGNETICI!\nE abbiamo anche la relazione: $$ \\vec{M} = \\chi_{m} \\vec{H} $$ Poi abbiamo anche $$ \\vec{B} = \\mu_{0} (\\vec{H} + \\vec{M}) = \\mu_{0}(1 + \\chi_{m}) \\vec{H} = \\mu \\vec{H} $$ Si ha anche la stessa relazione fra M e B rispetto a quello vecchio!\n$$ \\vec{M} = \\frac{k - 1}{k} \\vec{B} $$ Discontinuit√† nelle superfici magnetizzate üü®++ Consideriamo il campo magnetico in due mezzi, queste saranno sottoposte a correnti amperiane diverse. Applichiamo il classico cilindro sulla superficie di separazione. Avremo allora che $$ 0 = \\oint_{\\Sigma}\\vec{B} \\cdot \\hat{u}_{N} dS = B_{1}\\cdot \\cos \\theta_{1} dS - B_{2} \\cdot \\cos \\theta_{2} dS \\implies B_{1} \\cos \\theta_{1} = B_{2}\\cos \\theta_{2} $$ Ossia abbiamo che c\u0026rsquo;√® una continuit√† della componente normale. Questo possiamo dire che $$ k_{1} H_{1 \\perp} = k_{2} H_{2\\perp} $$ E possiamo dire che la componente $H$ √® discontinua.\nCambiamo setting, consideriamo un rettangolino di altezza infinitesima (anche questa stessa idea). Allora abbiamo che $$ i_{c} = 0 = \\oint_{\\Gamma} H\\cdot dS = H_{1}h - H_{2}h \\implies H_{1} = H_{2} $$ Quindi non abbiamo discontinuita per la componente tangente. Abbiamo quindi: $$ H_{1} \\sin \\theta_{1} = H_{2} \\sin \\theta_{2} $$ Abbiamo quindi che c\u0026rsquo;√® una discontinuit√† per il campo magnetico e il suo valore √®: $$ \\frac{B_{1 \\parallel}}{k_{1}} = \\frac{B_{2\\parallel}}{k_{2}} $$ calcoliamo il modulo di $B_{2}$ in funzione di $B_{1}$ che mi serve per calcolare il rapporto:\n$$ B_{2}^{2} = B_{1}^{2} \\cos ^{2} \\theta_{1} + B_{1}^{2} \\frac{\\cos ^{2}\\theta_{1}}{\\cos ^{2} \\theta_{2}} $$ Scriviamo in modo chiaro le componenti normali e non per $H$ Allora abbiamo che\n$$ H_{1t} = H_{2t} $$ E $$ k_{1}H_{1n} = k_{2}H_{2n} $$ E allora abbiamo:\n$$ \\frac{\\tan \\theta_{2}}{\\mu_{2}} = \\frac{H_{2t}}{\\mu_{2}H_{2n}} = \\frac{H_{1t}}{\\mu_{1}H_{1n}} = \\frac{\\tan \\theta_{1}}{\\mu_{1}} $$ Quindi abbiamo che $$ \\frac{\\tan \\theta_{1}}{\\tan \\theta_{2}} = \\frac{\\mu_{1}}{\\mu_{2}} = \\frac{k_{1}}{k_{2}} $$ Schermi magnetici üü© Pensiamo di avere un materiale ferromagnetico, e facciamo finta che abbiamo campo magnetico entrante. Per questa relazione abbiamo che probabilmente per ogni angolo, questo sar√† deflesso in modo praticamente parallelo alla superficie. E se c\u0026rsquo;√® un buco, allora non ci passa praticamente campo magnetico, e possiamo costruire schermi magnetici in questo modo. Quindi se il materiale del conduttore √® fatto di roba ferromagnetica, questa scherma sia campo magnetico che elettrico.\nMateriale ferromagnetico Certi materiali si magnetizzano velocemente quando si mettono vicino a campi magnetici forti\nConsideriamo un toroide, uguale a quello descritto in Geometrie di spire, abbiamo che quando mettiamo un materiale, $H$ non cambia, perch√© dipende solo da correnti concatenate.\nMagnetizzazione in funzione di H üü© Lo **stato vergine** √® lo stato iniziale del materiale. POi si ha la **curva di prima magnetizzazione** che √® la curva $a$ in figura. Per **magnetizzazione residua** si indica il valore di $M_{sat}$ quando $H = 0$ dopo aver salito la prima curva $a$. Abbiamo questo grafico (che poi si spiega con teorie quantistiche), che se aumento la corrente oltre un certo punto la magnetizzazione non aumenta. Questo si chiama magnetizzazione di saturazione. La cosa particolare √® che dopo che sono state magnetizzate, questi sono magneti permanenti. Si parla di campo coercitivo quando abbiamo un campo che fa diventare 0 la magnetizzazione.\nCiclo di isteresi di smagnetizzazione: In pratica devo fargli fare tanti giri (senza portarlo a saturazione!)\nCiclo di isteresi üü© √à il grafico che abbiamo visto di sopra, in cui il materiale va su e gi√π. e si potrebbero anche definire concetti come permeabilit√† differenziale che mi rappresenta come cambia in fretta se seconda dell\u0026rsquo;induzione magnetica\n$$ \\mu_{d} = \\frac{dB}{dH} $$ √à un diagramma di stato questo ciclo, in un certo senso come quelli descritti da Unified Modeling Language.\nUna altra osservazione √® che posso avere tutti i punti all\u0026rsquo;interno del ciclo, ed √® per questo che posso smagnetizzare un magnete. Il metodo √® accende e spegnere in un certo modo $H$.\nMateriali duri e dolci üü© Dolci sono usati solamente negli elettromagneti, perch√© sono facili da magnetizzare. Quelli duri sono difficili da magnetizzare, e hanno solitamente un ciclo di isteresi molto lungo.\nSeconda legge di curie (non importante) üü®++ Questa √® la relazione per materiali dolci, e lega la temperatura con la suscettibilit√† magnetica ()\n$$ \\chi_{m} (T - T_{c}))/\\rho = C $$ dove $\\rho$ √® la densit√† della sostanza.\nDomini di Weiss üü®\u0026ndash; Trattato pagina 316 del Mazzoldi:\nPossiamo caratterizzare alcuni domini magnetici ($~10^{5}$ atomi per il prof, per il libro circa $10^{11}$ atomi, sono regioni di circa 0.001 picometri., che ha senso perch√© i ferromagnetici sono questo fattore pi√π grandi rispetto agli altri., e poi vanno ad influenzare ed ingrandire, capire da Heisemberg (ma per il prof. difficili).\nUna cosa strana √® che $H$ dentro a un solenoide √® verso gi√π all\u0026rsquo;interno, perch√© abbiamo che \u0026hellip; boh non ho capito per√≤ la cosa strana era che era direzione opposta.\nSolenoide infinitamente lungo: non abbiamo vettore H perch√© la circuitazione √® sempre 0. ","permalink":"https://flecart.github.io/notes/magnetismo-nella-materia/","summary":"Analisi macroscopica Setting dell\u0026rsquo;esperimento üü© Provare a guardare 269 del Mazzoldi. (227 per la defivazione della forza.) Si pu√≤ dimostrare che $$ \\vec{F} = -\\vec{\\nabla} \\cdot U \\implies F = -\\vec{\\nabla}(\\vec{m} \\cdot \\vec{B}) = \\pm m \\frac{dB}{dx} $$ La prima relazione si deriva da definizione di lavoro e forza. (esteso al caso di una forza applicata su spira che non √® banale, facciamola brevemente).\nSappiamo che $U = - m \\cdot B$, quindi √® vero che $dW = -dU = i d \\Phi (B)$ e poi utilizzando una propriet√† del gradiente in Divergenza e Circuitazione abbiamo $$ Fds = dW = -dU = i \\nabla \\Phi(B) ds \\implies F = i\\nabla \\Phi(B) = m \\cdot \\nabla B = -\\nabla U $$ La cosa da notare √® che per campi uniformi abbiamo che si pu√≤ definire il lavoro.","title":"Magnetismo nella materia"},{"content":"I problem idi accoppiamento sono abbastanza comuni per ottimizzazione a grafi. In questa serie di note andiamo a trattare brevemente i problemi principali, con un accenno veloce ad alcuni algoritmi di soluzione per esse.\nGrafo bipartitoüü© Un grafo bipartito √® un insieme $(O \\cup D), (A)$ di nodi e di archi. Tutti i nodi sono o fra i nodi di origine oppure fra i nodi di destinazione, e gli archi sono solamente collegati fra nodi di origine e nodi di destinazione.\nAccoppiamenti (lessico)üü© Consideriamo $M$ archi che non abbiano nodi in comune, vogliamo cercare in questo senso di fare un accoppiamento fra i nodi di origine e i nodi di destinazione.\ndiciamo accoppiamento perfetto se tutti i nodi sono stati accoppiati\nArco di bottleneck √® l\u0026rsquo;arco di costo massimo, che si dice costo di bottleneck.\nAccoppiamento di massima cardinalita Trasformazione del problemaüü© Vogliamo cercare di utilizzare gli algoritmi noti sui flussi di costo minimo e flusso massimo, algo di flusso massimo. In questo caso se giriamo il problema in modo opportuno possiamo renderlo un problema di flusso massimo\nCreo nuovo nodo fittizzio di origine e destinazione, in modo simile a quanto fatto in precedenza in Reti di flusso Capacit√† degli archi sono tutti 1, se c\u0026rsquo;√® flusso lo prendo, altrimenti no. (in questo senso i flussi devono essere interi! Osservazioni sulla tipologia di pathüü© La path che viene in questo modo creata dovr√† essere per forza alternanti, che vanno a rimbalzare fra i nodi interni!\nRicorda cosa sono gli archi interni e gli archi estermi.\nDato un insieme $M$ di tutti gli archi del nostro grafo bipartito che andiamo a prendere, consideriamo archi interni questi, ed archi estermi l\u0026rsquo;insieme $P - M$, con P tutti gli archi.\nChiaramente devo passare dalla sorgente alla destinazione, e lo posso fare solamente una volta per ecco che si pu√≤ dire che\n$$ |P_e| - |P_i| = 1 $$ con Pe l\u0026rsquo;insieme degli archi esterni che prendo e Pi l‚Äôinsieme degli archi interni che vado a prendere, vado poi solamente a considerare la cardinalit√† di questo robo.\nQuesta osservazione √® importante per poter mettere in relazione molto stretta il fatto che i cammini aumentanti ‚Üî cammini alternanti con quella propriet√†, perch√© in questo modo il cammino alternante inizia e finisce in un nodo esterno, cio√® un nodo che non √® mai stato utilizzato per l‚Äôaccoppiamento.\nAccoppiamento di costo minimo Possiamo utilizzare gli algoritmi di MCMF per risolvere questo problema qui!\nImportante notare che gli accoppiamenti devono essere perfetti, ossia non ho nessun nodo libero.\nAccoppiamento di minimo bottleneck Anche qui deve esere fra tutti gli accopiamenti perfetti.\nIn questo caso si cerca di avere il minimo arco maggiore possibile, non per forza il minimo di costo.\n","permalink":"https://flecart.github.io/notes/problemi-di-accoppiamento/","summary":"I problem idi accoppiamento sono abbastanza comuni per ottimizzazione a grafi. In questa serie di note andiamo a trattare brevemente i problemi principali, con un accenno veloce ad alcuni algoritmi di soluzione per esse.\nGrafo bipartitoüü© Un grafo bipartito √® un insieme $(O \\cup D), (A)$ di nodi e di archi. Tutti i nodi sono o fra i nodi di origine oppure fra i nodi di destinazione, e gli archi sono solamente collegati fra nodi di origine e nodi di destinazione.","title":"Problemi di accoppiamento"},{"content":"2.1 Necessit√† e caratteristiche di R 2.1.1 Radici di N non perfetti e Q $\\sqrt{n} \\in \\mathbb{Q} \\implies n \\text{ √® quadrato perfetto}$\nFai lemma della divisibilit√† fra due numeri\nLemma: Dati $m,n,l$ tali che $MCD(m,l)=1$ e $l | m n$ allora allora $l | n$ Questo si risolve con ragionamenti sui fattori di m e n. Per dimostrare che √® razionale la radice di solamente una radice perfetta parto da un numero razionale, faccio certi ragionamenti e scoprir√≤ alla fine che il numero deve essere una radice perfetta.\nQuesto teorema si pu√≤ ancora estendere con questo:\nEsercizio (dimostrare) 2.1.2 Necessit√† di R Per dimostrazione del punto precedente, ci sono un sacco di lacune in quanto la maggior parte delle radici non appartiene a Q. C\u0026rsquo;√® bisogno di un insieme che operi bene al limite, cosa che con Q non va bene.\nIntuizione di R\nAggiungere a Q tutti i punti di cui mancano. Si dice che R √® Continuo\nEsempio inefficacia di Q\nIn questo esempio l\u0026rsquo;esistenza di un $sup$ c\u0026rsquo;√® solo in R perch√© in Q la radice di due non √® presente e quindi non c\u0026rsquo;√®\u0026hellip;\nCaratteristican unica\nSupremum property esiste sempre il limite superiore o inferiore di un insieme ,questo non succede anche per Q.\n2.1.3 Completezza di R $$ \\forall A:A\\neq\\empty \\implies A\\in \\R $$ Si ottiene completando Q con i pezzi mancanti, per farlo si deve introdurre il concetto di Continuit√† ‚Üí Intervalli\nQuesta propriet√† di R √® molti importante perch√© permette di avere sup e inf definiti in seguito qui\nInnumerabilit√† di R Cardinalit√†\nSi pu√≤ affermare che la cardinalit√† di R sia molto maggiore di N, infatti si pu√≤ dimostrare che √® innumerabile grazie\nCantor, si fa la costruzione a tabella e si dimostra che non √® suriettiva, ovvero che nell\u0026rsquo;intervallo $[0,1[$ esiste un numero che non √® mai raggiunto da un numero naturale, infatti riesco a costruire un numero che sia diverso in una cifra da tutti i numeri decimali in tabella. Questa √® la dimostrazione pi√π semplice di Cantor.\nUn altro argomento insiemistico lo puoi trovare qui Relazioni fra insiemi#Diagonalizzazione di Cantor.\n2.1.5 Esistenza unicit√† della radice File per pdf di lezione per questa\n$$ \\forall a \\in \\R_+, \\forall n \\in \\N - \\{0\\} ,\\exists !b \\in \\R_+ : b^n = a $$ Si indica con $^n\\sqrt{a} = b$\nUna serie di lemmi utili per la dimostrazione:\nLemmi $x^n \\geq y^n \\implies x \\geq y$ $x^n \\leq y^n \\implies x \\leq y$ $x ^n = y^n \\implies x = y$ $x^n \u003c y \\implies \\exists \\epsilon ,(x + \\epsilon) ^n \u003c y$ $x ^n \u003e y \\implies \\exists\\epsilon (x - \\epsilon)^n \u003e y$ NOTA: per dimostrare i lemmi potrebbe essere molto pi√π semplice provare a dimostrare prima per $n = 2$ e poi estendere da questo e poi passando per n generalizzatot\nSapendo di tutti questi lemmi si pu√≤ dimostrare esistenza ed unicit√† della radice n-esima.\nPer l\u0026rsquo;unicit√† basta utilizzare il lemma numero 3 (che si dimostra utilizzando i lemmi 1 e 2)\nPer dimostrare l\u0026rsquo;esistenza della radice bisogna dimostrare l\u0026rsquo;assurdo che la radice sia minore di quello e maggiore di quello (quello nel senso di 4 e 5)\nPer farlo si parte dalla continuit√† di R creando prima un insieme in cui il sup √® x, e da l√¨ dimostrare che √® assurdo che la radice sia diversa da quello\nDimostrazione:\nSia $A := \\{x \\in \\mathbb{R} \\mid x^2 \\leq b\\}$ devo dimostrare che esiste ed √® unico la radice a: $a ^2= b$\nAllora pongo per assurdo che non esiste tale radice, quindi devo dimostrare l\u0026rsquo;assurdo per $a ^2 \u003c b \\wedge a ^2 \u003e b$.\nPoniamo $a$ come il sup dell\u0026rsquo;insieme A, cosa che esiste dato che √® superiormente limitato. (poi usiamo i lemmi 4 e 5)\nCaso 1:\n$a^2 \u003c b \\implies (a + \\epsilon) ^2 \u003c b \\implies a + \\epsilon \\in A \\implies a + \\epsilon \u003c a \\implies absurd$\nCaso 2:\n$a^2 \u003e b \\implies (a - \\epsilon)^2 \u003e b \\implies a - \\epsilon \\not\\in A \\implies a - \\epsilon \\geq a \\implies absurd$\nQuindi esiste la radice.\nPer dimostrare che sia unico mi basta usare il lemma 3\n2.2 Intervalli, Maggioranti ed estremi 2.2.1 Intervalli Intervalli\n2.2.2 Maggioranti o minoranti Un maggiorante (o minorante) √® un elemento che √® maggiore (o minore di tutti gli elementi) di un certo insieme.\n2.2.3 Limitatezza Un insieme √® maggiormente o inferiormente limitato se esiste un maggiorante o un minorante di un insieme.\nSe un insieme √® sia maggiormente sia inferiormente limitato si dice che √® limitato\n2.2.4 Estremi (superiori ed inferiori) Un estremo √® definito in questo modo, che funziona anche per i razionali.\n$$ l = sup X \\iff \\begin{cases} \\forall x \\in X , l \\geq x \\\\ \\forall\\epsilon : \\epsilon \u003e 0,\\exists x \\in X, l-\\epsilon \\leq x \\\\ \\end{cases} $$ l √® un maggiorante l √® anche il pi√π piccolo dei minoranti. In modo simile si pu√≤ definire la parte inferiore.\nDetto in altre parole il sup √® il minimo dell\u0026rsquo;intero insieme dei maggioranti, se esiste questo insieme\n2.2.5 Massimi e minimi di insiemi Dato un $x \\in X, x:= _{min} \\forall y: y\\in X \\implies x \\leq y$\nE in modo simile i massimi.\nSi pu√≤ mettere in relazione massimi e minimi fra di loro, quindi posso dire che:\nSe esiste il minimo, questo √® il MASSIMO fra tutti i minoranti.\nPunto di massimo e minimo Questa parte sar√† utile per weierstrass.\nPMassimo:\n$f:X \\to\\R$ si dice punto di massimo $x$ se:\n$\\forall x_0 \\in X, f(x) \\geq f(x_0)$\nPMinimo\n$f:X \\to\\R$ si dice punto di massimo $x$ se:\n$\\forall x_0 \\in X, f(x) \\leq f(x_0)$\nüí° Stai molto attento a non confondere il punto di massimo assoluto con il massimo assoluto! Uno sta sul dominio, l'altro sul codominio 2.3 Valore assoluto Definizione del valore assoluto $\\lvert a \\rvert = max(a, -a)$ e si pu√≤ fare anche una funzione a tratti\n2.3.1 7 Propriet√† del valore assoluto $|a| \\geq 0$ $|a| =|-a|$ $-|a| \\leq a \\leq |a|$ $|a + b| \\leq | a| + | b|$ $||a|-|b|| \\leq |a-b|$ Espansione con disuguaglianze con altre cose senza valore assoluto Caratteristiche di R Campo ordinato Ordine totale e completo (completo = con gli infiniti) **(in cui le relazioni di ordine valgono) vedi pp 76 di Foundations of real analisys.\nPropriet√† archimedea nessun numero in R √® infinitamente grande Nessun elemento in R √® infinitamente piccolo (esiste sempre un elemento in Q pi√π piccolo). L\u0026rsquo;insieme R √® denso e nessun numero in R √® infinitamente grande Nessun elemento in R √® infinitamente piccolo (esiste sempre un elemento in Q pi√π piccolo).\n","permalink":"https://flecart.github.io/notes/r-e-intervalli/","summary":"2.1 Necessit√† e caratteristiche di R 2.1.1 Radici di N non perfetti e Q $\\sqrt{n} \\in \\mathbb{Q} \\implies n \\text{ √® quadrato perfetto}$\nFai lemma della divisibilit√† fra due numeri\nLemma: Dati $m,n,l$ tali che $MCD(m,l)=1$ e $l | m n$ allora allora $l | n$ Questo si risolve con ragionamenti sui fattori di m e n. Per dimostrare che √® razionale la radice di solamente una radice perfetta parto da un numero razionale, faccio certi ragionamenti e scoprir√≤ alla fine che il numero deve essere una radice perfetta.","title":"R e Intervalli"},{"content":"La struttura del neurone Parti strutturali principali (2) üü© Possiamo identificare tre parti principali per quanto riguarda la struttura di un singolo neurone\nAssoni che si occupano di mandare activation potential signal all\u0026rsquo;esterno, a comunicare con altre cellule. Il segnale che parte dall\u0026rsquo;assone inizia da una sezione che viene chiamato segmento iniziale. Dentriti che si occupano di ricevere segnali da altri neuroni. Gli assoni e dentriti non sono connessi, ma c\u0026rsquo;√® un piccolo spazio in mezzo a questi che si chiama Synaptic cleft, (la scoperta di questo √® stato di stupore, in passato pensavano che fosse una cosa continua il cervello, invece abbiamo qualche piccola unit√† discreta, scoperto con la colorazione d\u0026rsquo;argento metodi di Golgi) l\u0026rsquo;informazione in questo spazio pre e post sinaptico √® gestito da neurotrasmettitori.\nSolitamente per un singolo neurone siamo nell\u0026rsquo;ordine di grandezza dei micrometri\nPossiamo anche analizzare il neurone da un punto di vista delle parti funzionali principali, in tal caso diventano 4, come espressi in immagine, per tipologie di neuroni differenti. La cosa magicamente interessante √® che i collegamenti possono essere tanto diversi, ma rispettare alla fine un concetto simile abbastanza coerente delle parti (in un certo senso anche qui troviamo il ragionamento per astrazioni comune in informatica, probabilmente dal punto di vista fisico dei neurotrasmettitori ci saranno cose diverse, ma offrono la stessa interfaccia in cui attaccarsi per cos√¨ dire).\nClassificazioni dei neuroni üü© Ci sono molte tipologie di neuroni in natura, specialmente differiscono a seconda se stiamo parlando di vertebrati o invertebrati. In generale possiamo caratterizzarli in\nUnipolar Bipolar Multipolar Che viene riassunto dal diagramma sottostante. Solitamente i multipolar sono dei vertebrati. Convergenza e divergenza üü© Questa √® una cosa che probabilmente non abbiamo in modo naturale nelle reti, si parla di divergenza del segnale neuronale nel momento in cui un singolo neurone eccitato va a comunicare con molti neuroni, potenzialmente attivandone molti. Convergenza invece quando un neurone, prendiamo caso quello incaricato per fare contrarre il muscolo, deve prendere input da molti neuroni sensoriali, e quindi decidere se si deve contrarre o estendere a seconda di questa informazione.\nRam√≥n two principles üü® Veder 24 del KANDEL Principle of dynamic polarization: afferma che l\u0026rsquo;eccitazione di un neurone va linearmente in un verso (prolly per escludere il fatto che torni indietro)\nConnectional specificity: afferma che c\u0026rsquo;√® un senso, una semantica per cos√¨ dire, sul perch√© certi neuroni sono connessi assieme.\nCellule Gliali Funzione ed etimologia üü© Solitamente queste cellule, come dice il nome stesso latino, simile all\u0026rsquo;inglese glue, sono cellule di collegamento, ossia permettono la comunicazione corretta fra un neurone all\u0026rsquo;altro.\nTipologie di cellule gliali (3) üü® I primi formano la mielina per gli assoni nel sistema centrale, i secondi in quello periferico (√® un burrito, molti avvolgimenti). I terzi non si conosce la funzione. Circuiti neuronali Sono dei pattern di collegamento che si possono trovare fra i neuroni. In modo naturale si sviluppano dei piccoli sistemi che inibiscono o eccitano i propri vicini in qualche modo speciale. TODO: capire perch√© sono importanti.\nFeedforward inhibition Feedback inhibition Sinapsi Sono il collegamento che esiste fra un neurone e un altro, quindi potremmo intenderlo come il canale di comunicazione fra un neurone e un altro.\nGap Junction üü© Sono dei collegamenti pi√π diretti fra i neuroni, e permettono di passare ioni di eccitazione in modo abbastanza diretto (questa √® la differenza con quelli basati su cose chimiche), √® un circuito pi√π simile a quello elettronico, perch√© √® **pi√π veloce**. Solitamente √® necessario per cose veloci, quando vogliamo fare andare dei neuroni assieme, come i arc reflexes.\nChemical basedüü© Sono delle porte pi√π lente, i classici, quelli che poi andiamo a chiamare neurotrasmettitori, quando abbiamo un potenziale di azione, le vesicles vengono rilasciate nello spazio intracellulare, sull\u0026rsquo;altro neurone ci sono dei recettori che prendono questi neurotrasmettitori e si attivano di conseguenza.\nLa cosa interessante di questo metodo √® che il recettore pu√≤ cambiare porte per capire quanto gli importa questa nuova informazione. (quindi se gli importa quel segnale, pu√≤ aumentare il numero di porte altrimenti diminuirle, almeno questa √® la teoria).\nLa corteggia cerebrale consiste in una fra le parti pi√π importanti del cervello. Consiste in 6 strati uniformi di neuroni che seguono un pattern simile.\n1, 4 hanno input da higher cortical areas, 4 da parti sottocorticali, 6, con quelle interne come talami.\nCorrelazioni con tempo di action potential Fra due neuroni che comunicano, c\u0026rsquo;√® una correlazione abbastanza evidente che implica un aumento della forza della connessione (synaptic strength) con il tempo degli spykes. Long Term Depression e Long Term Potentiation si chiamano.\nEPSP √® Excitatory Post-Synaptic potentiation, nell\u0026rsquo;immagine vediamo che se il secondo neurone si attiva dopo che si √® attivato il primo neurone, allora tendono a potenziare il segnale, altrimenti diminuire.\nPer la diminuzione ha senso perch√© √® come se io ti dessi indietro il segnale (anche se non necessariamente connessi), oppure l\u0026rsquo;altro √® stanco lol.\n","permalink":"https://flecart.github.io/notes/the-neuron/","summary":"La struttura del neurone Parti strutturali principali (2) üü© Possiamo identificare tre parti principali per quanto riguarda la struttura di un singolo neurone\nAssoni che si occupano di mandare activation potential signal all\u0026rsquo;esterno, a comunicare con altre cellule. Il segnale che parte dall\u0026rsquo;assone inizia da una sezione che viene chiamato segmento iniziale. Dentriti che si occupano di ricevere segnali da altri neuroni. Gli assoni e dentriti non sono connessi, ma c\u0026rsquo;√® un piccolo spazio in mezzo a questi che si chiama Synaptic cleft, (la scoperta di questo √® stato di stupore, in passato pensavano che fosse una cosa continua il cervello, invece abbiamo qualche piccola unit√† discreta, scoperto con la colorazione d\u0026rsquo;argento metodi di Golgi) l\u0026rsquo;informazione in questo spazio pre e post sinaptico √® gestito da neurotrasmettitori.","title":"The Neuron"},{"content":"Introduction to tokenization Tokenization is the process of converting normal strings into small little pieces that could be fed into one of our models. It usually comes from a tradition in programming languages, as we can see in Automi e Regexp where we define a specific token to have a known pattern, usually recognized by regular expressions.\nThere have been historically been many approaches to tokenization, let\u0026rsquo;s see a few:\nUn approccio semplice (e non funzionante) Uno dei primi approcci che potrebbe venire in mente per questo problema di divisione delle parole √® avere delle componenti fisse (ad esempio lettere di alfabeto, o lettere) e utilizzare queste per fare tokenization. Cio√® stiamo mappando parti delle parole in modo greedy, prima arriva meglio √®. Si potrebbe rappresentare in questo modo: Da questo ipynb Subword tokenization A volte conviene dividere una stessa parola in token che siano pi√π piccoli della parola, perch√© questi potrebbero essere utilizzati in modo ricorrente in suffissi o prefissi (questo ha senso), per√≤ abbiamo bisogno di algoritmi che facciano questa tokenizzazione. Byte Pair Encoding Viene tratta per benino in ambito NLU (Sennrich et al. 2016)\nAlgoritmo in breve With this approach we use al algorithm similar to this:\nStart with each character as a different symbol (create a set) begin iterate The most frequent pair of symbols is merged into a single symbol. end iteration on n done iterations, or when the set is considered small enough So this is just a small and easy algorithm that we can use to create tokenizations over a single text corpus.\nStudio versione in paper (Credo da (Sennrich et al. 2016)) Un esempio breve in python tratto dal papero stesso:\nimport re, collections def get_stats(vocab): pairs = collections.defaultdict(int) for word, freq in vocab.items(): symbols = word.split() for i in range(len(symbols)-1): pairs[symbols[i],symbols[i+1]] += freq return pairs def merge_vocab(pair, v_in): v_out = {} bigram = re.escape(\u0026#39; \u0026#39;.join(pair)) p = re.compile(r\u0026#39;(?\u0026lt;!\\S)\u0026#39; + bigram + r\u0026#39;(?!\\S)\u0026#39;) for word in v_in: w_out = p.sub(\u0026#39;\u0026#39;.join(pair), word) v_out[w_out] = v_in[word] return v_out vocab = {\u0026#39;l o w \u0026lt;/w\u0026gt;\u0026#39; : 5, \u0026#39;l o w e r \u0026lt;/w\u0026gt;\u0026#39; : 2, \u0026#39;n e w e s t \u0026lt;/w\u0026gt;\u0026#39;:6, \u0026#39;w i d e s t \u0026lt;/w\u0026gt;\u0026#39;:3} num_merges = 10 for i in range(num_merges): pairs = get_stats(vocab) best = max(pairs, key=pairs.get) vocab = merge_vocab(best, vocab) print(best) NOTE: defaultdict √® solamente un dict normale che ha un default value, in questo caso 0 se non esiste la chiave, e get che ritorna None se non c\u0026rsquo;√®, invece di dare errore.\nVersione di GPT In GPT √® stato introdotto l\u0026rsquo;idea di creare gruppi di cattura che escludessero suffissi diversi, per esempio \u0026rsquo;s, punteggiature et cetera. Puoi vedere meglio in sezione 2.2 qui (Radford et al. 2019). Esempio del regex pattern Grammatiche Regolari per GPT2 del paper citato:\ngp2pat = re.compile(r\u0026#34;\u0026#34;\u0026#34;\u0026#39;s|\u0026#39;t|\u0026#39;re|\u0026#39;ve|\u0026#39;m|\u0026#39;ll|\u0026#39;d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?! \\S) |\\s+\u0026#34;\u0026#34;\u0026#34;) Durante l\u0026rsquo;allenamento dei GPT sono stati presenti anche tokens speciali come \u0026lt;|endoftext|\u0026gt; tokens speciali per indicare fine documento. Credo sia stata una cosa per facilitare il training effettivo. https://tiktokenizer.vercel.app/ se vuoi vedere.\nReferences [1] Sennrich et al. ‚ÄúNeural Machine Translation of Rare Words with Subword Units‚Äù 2016\n[2] Radford et al. ‚ÄúLanguage Models Are Unsupervised Multitask Learners‚Äù 2019\n","permalink":"https://flecart.github.io/notes/tokenization/","summary":"Introduction to tokenization Tokenization is the process of converting normal strings into small little pieces that could be fed into one of our models. It usually comes from a tradition in programming languages, as we can see in Automi e Regexp where we define a specific token to have a known pattern, usually recognized by regular expressions.\nThere have been historically been many approaches to tokenization, let\u0026rsquo;s see a few:","title":"Tokenization"},{"content":"This is also known as Lagrange Optimization or undetermined multipliers. Some of these notes are based on Appendix E of (Bishop 2006), others were found when studying bits of rational mechanics.\nLet\u0026rsquo;s consider a standard linear optimization problem $$ \\begin{array} \\\\ \\min f_{0}(x) \\\\ \\text{subject to } f_{i}(x) \\leq 0 \\\\ h_{j}(x) = 0 \\end{array} $$ Lagrangian function And let\u0026rsquo;s consider the Lagrangian function associated to this problem defined as $$ \\mathcal{L}(x, \\lambda, \\nu) = f_{0}(x) + \\sum \\lambda_{i}f_{i}(x) + \\sum\\nu_{j}h_{j}(x) $$ We want to say something about this function, because it is able to simplify the optimization problem a lot, but first we want to study this mathematically.\nWe call $\\lambda_{i}, \\nu_{i}$ the lagrange multipliers associated with their function.\nThen we define the dual function to be $g(\\lambda, \\nu) = \\min_{x} L(x, \\lambda, \\nu)$.\nMotivation In this section we try to explain step by step why this method works. We will find that it is easier than we could expect this. With this, we will evaluate the maximum (for the minimum just take the dual)\nSingle Equation constraint In this case we have our function $f$ along with a constraint $g(x) = b$ where $b$ is a constant in $\\mathbb{R}$ and $x$ is a vector. Note: we use $g(x) = b$ but it\u0026rsquo;s the same if $b =0$ just define $h(x) = g(x) - b$ and you have your other function compared to a 0, which is usually easier in this context. Let\u0026rsquo;s consider the solutions of $g(x) = b$, this usually gives us a set of points (sometimes contiguous) where we have to look for a solution of $f$, we want to find among these points the one that minimizes the function $f$. The constraint on $g$ is somewhat similar to convex analysis\u0026rsquo; level sets. One thing that is easily observable (this way is very physicist\u0026rsquo;s way to motivate things, you do something similar when analyzing the parallel electric field in conductors see Condensatori nel vuoto), is that if you have a $g(x)$ and you move slightly along the path of $g(x + \\varepsilon)$ the value is the same, so the derivative along this direction is null. This allows us to say that the derivative of $g$ is perpendicular to the direction of the curve. (Bishop\u0026rsquo;s argument is different and slightly more detailed). Then we can also say something about the gradient of $f$, because if it is not perfectly perpendicular to that surface, we would have that moving slightly along the surface could increase or decrease the value of $f$. So we need the two to be parallel or anti-parallel. Which motivates us to write $\\nabla f + \\lambda \\nabla g = 0$ which in turn motivates the creation of the so called lagrangian function: $$ \\mathcal{L}(x, \\lambda) = f(x) + \\lambda g(x) $$ We observe that its stationary point needs to have its partial derivatives set to zero, so we would have the original partial derivative condition, and also the inequality constrain for $\\lambda \\neq 0$. In this way we can find both the $x$ and the $\\lambda$.\nIn the case we want to minimize, we can choose the lagrangian to be $$ \\mathcal{L}(x, \\lambda) = f(x) - \\lambda g(x) $$ So that the derivative has opposite direction. (actually I don\u0026rsquo;t have understood this point).\nInequality constraints If instead of having bounds like $g(x) = b$ we have bounds like $g(x) \\geq b$ it\u0026rsquo;s just a little bit more complicated, we have more points, and could be useful to divide the case when $g(x)= b$ with $g(x) \u003e b$. In the latter case, we just set $\\lambda = 0$ (because this is what we get if we take the derivative w.r.t. to $\\lambda$ and set $\\lambda g(x) = 0$) and maximize the lagrangian (doesn\u0026rsquo;t matter the direction of the gradient of $f$ now), when the solution is border, we should take a little bit more care: we want the gradient of $f$ to be away from the region $g$, which motivates us to have an equation like $\\lambda \\nabla g(x) = -\\nabla f(x)$ and $\\lambda \u003e 0$. So we have the same Lagrangian as before, but we have some other constraints, those are called the Karush-Kuhn-Tucker conditions: $$ \\begin{cases} g(x) \\geq 0 \\\\ \\lambda \\geq 0 \\\\ \\lambda g(x) = 0 \\end{cases} $$ Duality The Lagrangian Multiplier method allows us to define the concept of dual optimization problem also in this context. If we consider this classical optimization problem $$ \\begin{array} \\\\ \\min_{w} f(w) \\\\ \\text{ s.t. } g_{i}(w) \\leq 0 \\\\ h_{i}(w) = 0 \\end{array} $$ We can build the Lagrange Multiplier as $$ \\mathcal{L}(w, \\lambda, \\nu) = f(w) + \\sum_{i} \\lambda_{i}g_{i}(w) + \\sum_{i}\\nu_{i}h_{i}(w) $$ with $\\lambda_{i} \\geq 0$ and $\\nu_{i} \\neq 0$, these are the classical conditions, motivated above (just note the minimization problem, so we inverted one condition). Now consider this primal value: $$ \\theta_{\\mathcal{P}}(w) = \\max_{\\lambda, \\nu : \\lambda_{i} \\geq 0} \\mathcal{L}(w, \\lambda, \\nu) $$ We observe that if any of the condition $g_{i}(w) \\leq 0$ or $h_{i}(w) = 0$ is violated, then it\u0026rsquo;s easy to say that $\\theta_{\\mathcal{P}} = +\\infty$. So we say that this formulation is the same as the above: $$ p^{*} = \\min_{w} \\theta_{\\mathcal{P}}(w) = \\min_{w} \\max_{\\lambda, \\nu: \\lambda_{i} \\geq 0} \\mathcal{L}(w, \\lambda, \\nu) $$ The dual of this optimization problem is just inverting the values in some manner.\nDual problem is the following: $$ \\theta_{\\mathcal{D}}(w) = \\min_{\\omega} \\mathcal{L}(w, \\lambda, \\nu) $$ And then taking the $\\max$ for $\\theta_{\\mathcal{D}}(w)$.\nBoundness of the dual function Consider the Lagrangian $$\n\\mathcal{L}(x, \\lambda, \\nu) = f_{0}(x) + \\sum \\lambda_{i}f_{i}(x) + \\sum\\nu_{j}h_{j}(x) $$ Given $x^{*}$ the solution of the optimization problem, we say that, after fixing $\\lambda \\geq 0$ and $\\nu$ $g(\\lambda, \\nu) \\leq f_{0}(x^{*})$. This is called weak duality. When Equality holds for the best $\\lambda$ and $\\nu$ we say that we have strong duality.\nWe observe that if $x$ is a solution to the optimization problem then we have that $f_{i}(x) \\leq 0$ and $h_{i}(x) = 0$ this follows that $\\sum \\lambda_{i}f_{i}(x) + \\sum\\nu_{j}h_{j}(x) \\leq 0$ now it\u0026rsquo;s easy to prove that\n$$ g(\\lambda, \\nu) = min_{x} L(x, \\lambda, \\nu) \\leq L(x, \\lambda, \\nu) = f_{0}(x) + \\sum \\lambda_{i}f_{i}(x) + \\sum\\nu_{j}h_{j}(x) \\leq f_{0}(x) $$ For every feasible solution.\nBecause when we have\nSlater\u0026rsquo;s condition This is a special case that allows us to say when duality holds: if given the following optimization problem $$ \\begin{array} \\\\ \\min f(w), \u0026 w \\in \\mathbb{R}^{d} \\\\ \\text{ s.t. } g_{i}(w) = 0, \u0026 i \\leq m \\\\ h_{j}(w) \\leq 0 \u0026 j \\leq n \\end{array} $$ And we have that $f, h_{j}$ are all convex and $g_{i}$ is affine, then this theorem asserts that\nif there is a feasible $w$ such that $h_{j}(w) \u003c 0$ for all $j \\leq n$ then we have strong duality.\nWhen we have strong duality, we can solve the dual problem instead of the original problem.\nReferences [1] Bishop ‚ÄúPattern Recognition and Machine Learning‚Äù Springer 2006\n","permalink":"https://flecart.github.io/notes/lagrange-multipliers/","summary":"This is also known as Lagrange Optimization or undetermined multipliers. Some of these notes are based on Appendix E of (Bishop 2006), others were found when studying bits of rational mechanics.\nLet\u0026rsquo;s consider a standard linear optimization problem $$ \\begin{array} \\\\ \\min f_{0}(x) \\\\ \\text{subject to } f_{i}(x) \\leq 0 \\\\ h_{j}(x) = 0 \\end{array} $$ Lagrangian function And let\u0026rsquo;s consider the Lagrangian function associated to this problem defined as $$ \\mathcal{L}(x, \\lambda, \\nu) = f_{0}(x) + \\sum \\lambda_{i}f_{i}(x) + \\sum\\nu_{j}h_{j}(x) $$ We want to say something about this function, because it is able to simplify the optimization problem a lot, but first we want to study this mathematically.","title":"Lagrange Multipliers"},{"content":"DPDA Definizione (2)üü© La definizione di DPDA √® molto simile a quella trattata in Linguaggi liberi e PDA, con solo costraints sulla deterministicit√†, che si traducono in due condizioni:\nAl massimo posso avere un risultato per ogni coppia di lettura e simbolo su stack Se ho una transizione senza leggere, posso avere solo quella Slide\nLinguaggio libero deterministico Un linguaggio √® libero deterministico se esiste un PDA che lo riconosce per stato finale.\nPropriet√† accettazione per DPDAüü© Per stato finale accettato resta sempre, cambia un p√≤ l‚Äôaccettazione per pila vuota, in cui si deve avere una prefix property.\nQuesta prefix property ha un certo interesse perch√© basta aggiungere un simbolo che non √® presente nell‚Äôalfabeto, e ho la prefix property! (guarda esempi Lez12 prime slide).\nPrefix propertyüü© Due parole del linguaggio in cui il primo √® interamente dentro il secondo.\nslide Prefix property\nSe aggiungo un simbolo $ riesco a far sempre che ci sia la prefix property.\nLa dimostrazione √® pi√π o meno su questa scia. affinch√© uno sia prefisso dell‚Äôaltro, deve avere il dollaro nella stessa posizione, allora hanno la stessa lunghezza, ma se hanno la stessa lunghezza devono essere uguali, ecco la prefix property.\nEsiste DPDA che riconosce linguaggi regolariüü© Enunciato\nDimostrazione\nPraticamente la dimostrazione √® la stessa per Grammatiche Regolari, ma ho anche lo stack, basta che non lo uso e ho finito.\nNon ambiguit√† dei DPDAüü© Enunciato\nQuindi se esiste un DPDA che riconosce il linguaggio, si pu√≤ creare una grammatica non ambigua che riconosce lo stesso linguaggio.\nCon la lezione del 29/11 abbiamo introdotto che un linguaggio √® deterministico sse SLR(1) in LR(k) e YACC, quindi probabile che i DPDA posso essere ricondotti in una forma deterministica a singolo\nPropriet√† dei linguaggi deterministiciüü© Complemento s√¨ Unione o intersezione no. Complemento probabilmente s√¨ perch√© basta applicare lo stesso ragionamento fatto per le regex in Automi e Regexp, ossia basta invertire gli stati accettati.\nPer dimostrare che non sono chiusi per intersezione o unione sarebbe buona cosa fornire un esempio.\nEsempio non intersezione ‚áí non unione.\nAnalizzatori sintattici In modo simile a quanto presentato in Grammatiche Regolari nell discussione dei Lex.\nQuesta parte utilizziamo abbiamo i strumenti automatici che prendono una grammatica libera e resituiscono un DPDA\nTipologie di parser (2-2-2)üü© Deterministico o non-deterministico Top-Bottom Oltre a ci√≤ possiamo anche dividere i parse a seconda di\nLettura da destra o da sinistra Creazione derivazione rightmost o leftmost Numero di look ahead. Quindi per esempio se ho una grammatica che inizia a leggere da sinistra, crea derivazione leftmost e ha un lookahead di 1, lo rappresento come $LL(1)$\nTop down parsing con PDA singolo statoüü© Simile a quanto fatto in Linguaggi liberi e PDA per il teorema di equivalenza di linguaggio libero e PDA, vado a crearmi un automa in un certo modo (in particolare con singolo stato riconosce per pila vuota).\nSlide enunciato\nQuesta √® una semplice soluzione non deterministica, possiamo togliere questo non determinismo con il Look Ahead come rpesentato sotto\nLook Ahead(+)üü© Posso andare a guardare la lettera avanti per capire in che modo comportarmi con la derivazione.\nUtilizzo una tabella di parsing per capire in che modo devo espandere il non-terminale.\nEsempio di look ahead 1\ncon $S := aSb|\\varepsilon$\nNote per risolvere i conflitti\nPosso\nFattorizzare (creare una nuov agrammatic aequivalente senza ricorsione sinistra che non riesco a gestirla, va a divergere, quindi non finisce mai Fare un look ahead maggiore di 1 Queso √® utile per togliere il non determinismo.\nBottom up parsing(3)üü®- Si tratta sempre della creazione di un PDA a singolo stato!, ma fatto in modo di verso, in modo tale che ci sia una derivazione rightmost.\nImportanti in questa parte sono 3 operazioni\nShift, in cui facci ocrescere verso destra la pila, come se stessi facendo lo shift Reduce, quando creo il non terminale come se fosse una espansione di non terminale. Accept Esempio di creazione di parser bottom up\nEsempio di derivazione con il parser di sopra\nProblema non determinismo per sopra\nMa comunque andiamo a discutere meglio di questa parte in Bottom-up Parser LR(0).\nTipologie di conflitti di bottom up Shift-reduce Reduce-Reduce Oltre a questo c\u0026rsquo;√® un grandissimo problema delle produzioni del tipo $A \\to \\varepsilon$, perch√© queste divergono sempre, quindi √® meglio non avere grammatiche con questa produzione se vogliamo utilizzare parsing bottom up.3\n","permalink":"https://flecart.github.io/notes/linguaggi-deterministici-e-dpda/","summary":"DPDA Definizione (2)üü© La definizione di DPDA √® molto simile a quella trattata in Linguaggi liberi e PDA, con solo costraints sulla deterministicit√†, che si traducono in due condizioni:\nAl massimo posso avere un risultato per ogni coppia di lettura e simbolo su stack Se ho una transizione senza leggere, posso avere solo quella Slide\nLinguaggio libero deterministico Un linguaggio √® libero deterministico se esiste un PDA che lo riconosce per stato finale.","title":"Linguaggi Deterministici e DPDA"},{"content":"The main difference between reinforcement learning and other machine learning, pattern inference methods is that reinforcement learning takes the concept of actions into its core: models developed in this field can be actively developed to have an effect in its environment, while other methods are mainly used to summarize interesting data or generating sort of reports.\nReinforcement learning¬†(RL) is an interdisciplinary area of¬†machine learning¬†and¬†optimal control¬†concerned with how an¬†intelligent agent¬†ought to take¬†actions¬†in a dynamic environment in order to maximize the¬†cumulative reward. ~Wikipedia page.\nNote: there is a big gap between theory and practise in this field.\nIntroduzione Una delle idee migliori riguardanti questo campo del reinforcement learning √® il focus sul processo decisionale del singolo agente, condizionato al reward che l‚Äôambiente esterno gli d√† (feedback). Il setting classico di questo genere di problemi √® un caso speciale della caratterizzazione presente in l‚Äôintelligenza.\nAbbiamo in questo caso un agente all‚Äôinterno del suo ambiente. L‚Äôagente √® in grado di interagire col suo ambiente attraverso alcune azioni ben definite, e l‚Äôambiente restituisce un feedback ad ogni azione. L‚Äôagente si regola di conseguenza, nel tentativo di massimizzare il reward che riceve.\n√à da notare che questa impostazione √® molto diversa rispetto al machine learning classico, seppur si pu√≤ comunque collocare al suo interno. Classifcamente nei modelli di machine learning supervised si cerca di minimizzare un errore con alcuni dataset etichettati, mentre qui non abbiamo nessuna etichetta, mentre nel unsupervised proviamo a trovare alcuni pattern nei dati, mentre qui non cerchiamo nessun pattern. Si potrebbe dire che questo sia un terzo paradigma di machine learning.\nNOTA: questi appunti riassumono concetti dai primi 4 capitoli del Sutton and Barto 2020\nUn problema classico: n-bandit Vedere N-Bandit Problem.\nSetting classico (Model Policy Reward) Quando andiamo a parlare di Reinforcement learning andiamo a considerare un setting classico di agente che interagisce con un ambiente attraverso delle azioni, e l‚Äôambiente che risponde attraverso i reward. L‚Äôagente osserva quindi lo stato (se √® full-observable vede lo stato esterno, altrimenti partially observable vede solamente parte delle informazioni dello stato dell‚Äôambiente) e insieme al reward percepito prova a eseguire delle altre azioni.\nSono particolarmente importanti quindi 3 parole chiave utili per descrivere una delle 3 frecce in immagine\nModel Il modello dell\u0026rsquo;ambiente lo indichiamo anche come dinamica o sistema di transizione dell‚Äôambiente. nel modello sono definite tutte le distribuzioni di probabilit√† che portano uno stato a un altro: $P(s'|s)$, questo possiamo dire, ossia partendo da uno stato s, quanto √® probabile finire in uno stato s‚Äô ??\nQuesto √® quello che ci dice il modello. Solitamente si pu√≤ modellare nella seguente maniera: √® un insieme $(P, r)$ definito cos√¨: $$ \\begin{align} P: S \\times \\mathcal{A} \\to \\Delta(S) \\\\ r: S \\times \\mathcal{A} \\to [0, 1] \\end{align} $$ Dove $\\Delta$ √® una distribuzione su $S$.\nPolicy La policy √® un indicatore delle azioni del singolo agente, ci dice quanto √® probabile che l‚Äôagente esegua una certa azione, dato che sia sopra un certo stato s, lo indichiamo solitamente con $\\pi(a | s)$. Nel caso in cui √® una policy deterministica, nel senso che a uno stato corrisponde uno e un solo azione, potremmo scrivere qualcosa del tipo $\\pi (s) = a$ Quindi √® una funzione $\\pi: S \\to \\Delta(\\mathcal{A})$.\nReward Il reward descrive il feedback che l‚Äôambiente ritorna al giocatore una volta che una azione √® stata eseguita, spesso lo indichiamo in questi modi\n$$ r(s, a) \\\\ r(s, a, s') \\\\ r(s) $$ A seconda di quanto vogliamo esprimere (quindi il reward atteso dopo aver fatto una azione da unc erto stato, il reward atteso dopo aver fatto una azione da un certo stato ed essere arrivati a un certo stao e cos√¨ via\nThe Value function Associamo ad ogni stato un reward $r$, si avr√† una history ossia una sequenza di $O, A, S$ osservazione dall\u0026rsquo;ambiente, azione fatta e stato presente. Ad ogni stato avr√≤ un reward. quindi $$ v_{i}(S_{j}) = \\mathbf{E} [r_{i} + r_{i + 1} + \\dots | S_{j}] $$ Ossia se io al passo $i$ sono sullo stato $S_{j}$ la value function per quello stato √® il valore atteso dei rewards tutti successivi. Solitamente i valori hanno un valore di discounting $\\gamma$. Questo si pu√≤ scrivere in maniera pi√π compatta come $$ v_{i}(S_{j}) = \\mathbf{E} [r_{i} + v_{i+1}(S) | S_{j}] $$ Con $S$ uno stato su cui puoi essere al passo successivo.\nAll components are functions:\nPolicies: $\\pi: S \\rightarrow A$ (or to probabilities over A) Value functions: $v: S \\rightarrow R$ Models: $m: S \\rightarrow S$ and/or $r: S \\rightarrow R$ State update: $u: S \\times O \\rightarrow S$ Categorie di agenti Policy - Value categorization Value Based ha solamente value based, la sua policy √® basata sul suo valore (in modo greedy va a cercare quale sia lo stato con valore maggiore) Esempi sono Monte Carlo, SARSA, Q-learning, DQN.\nPolicy based Il contrario, non ha value function, ma solamente la policy, tenta direttamente Policy Gradient, NPG, TRPO, PPO.\nActor Critic Ha entrambi, ha sia policy (l\u0026rsquo;attore) e il critico che cerca di aiutare. Questi sono anche chiamati model based.\nModels Model free Se hanno policy o value, ma non hanno nessun modello sull\u0026rsquo;ambiente in cui sono presenti Solitamente sono molto semplici, e permettono di imparare direttamente la policy migliore possibili per questo ambiente.\nModel based Hanno il modello dell\u0026rsquo;ambiente, e non necessariamente hanno policy o value function. Questi potremmo anche chiamarli (Ha \u0026amp; Schmidhuber 2018). Solitamente questi permettono di utilizzare l\u0026rsquo;esperienza meglio (+ sample efficient).\nOther definitions Prediction and control Prediction √® la capacit√† di sapere come sar√† il futuro Control √® la capacit√† di ottimizzare la propria value function. Solitamente sono molto legati fra di loro.\nOnline vs Offline RL Per i modelli online possiamo andare direttamente ad agire sull\u0026rsquo;ambiente per ottenere dei dati. Si parla di exploitation exploration tradeoff. Solo che bisogna stare attenti perch√© ci pu√≤ essere un rischio per certe azioni. Per esempio una macchina potrebbe schiantarsi quando esplora, perch√© lo sta facendo nel mondo reale. Per i modelli offline abbiamo gi√† collezionato un sacco di dati, e possiamo usare questo per cercare di creare un modello ed imparare. Sono anche chiamati batched RL.\nOn-policy vs Off-policy RL Con on-policy √® sempre un RL online, in cui andiamo ad imparare utilizzando la policy attuale. Con off-policy stiamo usando una policy diversa per andare ad imparare la nostra policy finale. Magari abbiamo un buffer in questo caso che utilizziamo per memorizzare in modo temporaneo le nostre informazioni.\nMarkov chains Dovrebbe essere approfondito meglio in Markov Chains\nMarkov property üü© Uno stato si pu√≤ dire di godere della propriet√† di Markov se, intuitivamente parlando, possiede gi√† tutte le informazioni necessarie per predire lo stato successivo, ossia, supponiamo di avere la sequenza di stati $(S_n)_{n \\in \\mathbb{N}}$, allora si ha che $P(S_k | S_{k-1}) = P(S_k|S_0S_1...S_{k - 1})$, ossia lo stato attuale in Sk dipende solamente dallo stato precedente.\nNormalmente poche cose nel mondo reale si possono dire puramente Markoviane, per√≤ non si pu√≤ negare che √® un modello molto buono di partenza come modello di decisione.\nma potremmo sempre rendere Markoviano creando una nuova variabile che ci rappresenta tutta la storia (√® qualcosa che non ho capito molto bene, ma credo si possa fare senza probbi).\nMarkov processes üü®- Possiamo andare a definire un processo markoviano come un insieme di stati e il modello di transizione probabilistico: $(S, P)$, una coppia di stati e tutto il modello di transizione. mi sembra di aver letto che un processo markoviano sia molto buono per studiare i moti browniani in fisica. Praticamente a random abbiamo che ogni punto si pu√≤ muovere\nEsempio di processo markoviano\nMarkov Reward Processes (!!!) Quando andiamo a parlare di processo markoviano con reward indichiamo che associamo una funzione valore $V(s)$ che restituisce un certo valore a ogni stato. Di solito questo valore ci √® ignoto a noi agenti che seguiamo iil modello, quindi diventa un buon problema in questo setting provare a stimare il valore dello stato in seguito a numerose osservazioni. Solitamente non vogliamo considerare tutti i reward con lo stesso peso. Vorremmo avere anche a disposizione un parametro che ci indichi quanto siano importanti i reward subito di ora, e i reward nel futuro. Con questo indichiamo un discount factor $\\gamma$\nUn tale processo viene formalizzato tramite una quadrupla $S, P, R,\\gamma$, con s stati possibili, P il modello di transizoine e R la funzione che ritorna il reward per ogni stato.\nSolitamente viene definito state value function:\n$$ V(s) = \\mathbb{E}[R_t + \\gamma R_{t + 1} + \\gamma^2 R_{t + 2} + ... | s = s _{t}] $$ La parte dentro il valore atteso √® solitamente indicata con $G_t$.\nMetodi di estimazione della funzione valore:\nAbbiamo abbastanza metodi per stimare il valore della funzione: metodi di sampling, metodi diretti (analitici) e metodi basati su programmazione dinamica.\nRiguardo i metodi di sampling questi sono i pi√π dinamici, nel senso che permettono l‚Äôapplicazione a pi√π problemi possibili, in generale hanno una precisione che va nell‚Äôordine dell $\\dfrac{1}{\\sqrt {n}}$ anche se non so su quali basi in particolare.\nI metodi diretti sono leggermente pi√π lenti, perch√© si tratta di risolvere l‚Äôinversa della matrice, cosa che va in $O(n^3)$. Il motivo di questo √® che possiamo sfruttare la propriet√† di V\nOssia possiamo dire che\n$$ V_k(s_t) = \\mathbb{E}[R_t + \\gamma G_{t + 1} | s = s _{t}] = R(s) + \\gamma \\sum_{s'}P(s'|s)V_{k -1}(s') $$ Questa osservazione permette di sviluppare un algoritmo iterativo per stivare il V fino a convergenza (sul perch√© converge sicuramente guardare altro, prolly idea degli operatori di bellman pu√≤ essere utile)\nAlgoritmo iterativo per valutazione della MRP\nSoluzione analitica:\nUtilizzando la stessa propriet√† (solamente ora scritta in modo analitico, possiamo risolverlo come se fosse una matrice\nSoluzione analitica\nMarkov Decision Process Questo √® molto simile alla MRP, solo che ora introduciamo una policy, ossia una funzione che ci dica quanto √® probabile compiere una certa azione in un certo stato\n$(S, A, P, R, \\gamma)$, ossia ora abbiamo sia stato, sia azione possibile e la funzione di transizione deve contare entrambi: $P(\\cdot | s, a)$, mentre le reward sono ancora come prima.\nS l‚Äôinsieme di stati possibili A l‚Äôinsieme di azioni possibili P probabilit√† di raggiungereun certo stato, dato uno stato inizial e una azione R reward di uno stato gamma: decadimento del reward. √à da notare che se possediamo una policy, allora possiamo ridurci al caso di Markov Reward Process, infatti possiamo dire che\n$$ R^\\pi(s) = \\sum_{a \\in A}\\pi(a | s)R(s) \\\nP^\\pi(s\u0026rsquo;|s) = \\sum_{a \\in A} \\pi(a | s) P(s\u0026rsquo;|s, a) $$ √à interessante modellare il concetto di expected returncome $\\mathbf{E}\\left[ \\sum_{t= 1}^{T} r_{t} \\right]$.\nQuindi data una policy possiamo utilizzare gli argomenti fatti di sopra e riuscire a dare una valutazione di essa\nAlgoritmo iterativo DP per policy evaluation\nPolicy Search Cerchiamo ora la policy migliore possibile da applicare a un MDP, questo √® il problema del policy control ora che sappiamo come fare policy evalutation √® il momento giusto per introdurre soluzioni a questo problema.\nUna soluzione na√Øve √® semplicemente enumerare tutte le policy e utilizzare l‚Äôalgoritmo di policy evaluation, poi andare a vedere quale sia la migliore. Questo √® molto dispendioso perch√© assumento che posso applicare tutto l‚Äôinsieme di azioni a tutti gli stati ho potenzialmente $|S|^{|A|}$ policy possibili,, che sono troppi , e troppo brutti.\n√à bene raggiunti questo punto provare a dare alcune definizioni utili.\nDefinitions: state-action-value, optimal value policy Sia $\\pi$ una policy e $V^\\pi$ la evaluation di quella policy, allora possiamo andare a definire la state-action-value function in questo modo:\n$$ Q(s, a) = R(s, a) + \\gamma \\sum_{s'} P(s'|s, a)V^\\pi(s') $$ ossia ci dice pi√π o meno il valore atteso dell‚Äôazione a un certo stato!\nPossiamo anche definire la policy migliore:\n$$ \\pi^*(s) = argmax_{\\pi} V^\\pi(s) $$ Ossia √® la policy che rende massimo il valore in qualunque stato!\nPolicy iteration and his monotonicity Una volta creato una policy iteration, √® una cosa molto sensata andare a definire una nuova policy $\\pi_{k + 1}$ definita in questo modo:\n$$ \\forall s, \\pi_{k + 1}(s) = argmax_a Q(s, a) $$ Ossia andiamo proprio a crearci una nuova policy, cercando di rendere maggiore possibile il valore atteso a fare una certa azione a uno stato! Riusciremo a dimostrare che $\\forall s, V^{\\pi_{k + 1}}(s) \\geq V^{\\pi_{k}}(s)$\nDimostrazione dal sutton e barto\nl‚Äôidea principalmente √® prendere sempre il massimo volta dopo volta, e dimostrarlo per induzione in pratica‚Ä¶ Anche non ho capito come formalizzare e non ho capito se posso trarne vantaggi didattici nella formalizzazione di questa merda\nValue Iteration L‚Äôidea di value iteration √® sostituirla subito, cio√® non stare a sviluppare fino in fondo la value evaluation, ma aggiornare la policy subito dopo appena si ha il valore.\nPseudocodice value iteration\nBellman operator Si pu√≤ dimostrare che questo operatore √® una contrazione, quindi value iteration converge qualunque sia il punto di partenza\nCon questo operatore, possiamo anche riscrivere in modo migliore la policy evaluation\nSlide\nProof of contraction of bellman operator\nReferences [1] Ha \u0026amp; Schmidhuber ‚ÄúWorld Models‚Äù 2018\n","permalink":"https://flecart.github.io/notes/reinforcement-learning-a-introduction/","summary":"The main difference between reinforcement learning and other machine learning, pattern inference methods is that reinforcement learning takes the concept of actions into its core: models developed in this field can be actively developed to have an effect in its environment, while other methods are mainly used to summarize interesting data or generating sort of reports.\nReinforcement learning¬†(RL) is an interdisciplinary area of¬†machine learning¬†and¬†optimal control¬†concerned with how an¬†intelligent agent¬†ought to take¬†actions¬†in a dynamic environment in order to maximize the¬†cumulative reward.","title":"Reinforcement Learning, a introduction"},{"content":"Ripasso Prox: 80 Ripasso: May 21, 2023 Ultima modifica: March 12, 2023 10:00 AM Primo Abbozzo: October 8, 2022 11:30 AM Stato: üåïüåïüåïüåïüåë Studi Personali: No\nElementi di ripasso 2 Sezioni Critiche Introduzione La parte di un programma che utilizza una o pi√π risorse condivise viene detta sezione critica (critical section, o CS)\nAndiamo in questa altra parte a valutare certe soluzioni:\nProgramma d‚Äôesempio üü© Vorremmo garantire che a = b invariante. (espressione logica verificata nell\u0026rsquo;esecuzione di questo programma). quindi una coerenza di uno prima dell\u0026rsquo;altro vogliamo.\nNon funziona lasciare la gestione dell\u0026rsquo;invarianza al sistema operativo o al compilatore perch√© manca questa informazione (quindi non abbiamo potere per la gestione dell‚Äôordine in questo caso.\nRequisiti per le CS (5) üü©‚Äî‚Äî Vogliamo ora cercare di listare le propriet√† delle critical sections in modo teorico, per implementare un programma che riesca ad implementare la critical section.\nSlide requisiti\nSafety:\nMutua esclusione, solo uno all\u0026rsquo;interno della CS No deadlocks Liveness:\nUn processo fuori dalla CS non dovrebbe ritardare l‚Äôentrata di un altro programma Un processo eventualmente deve entrarci Altro:\nNessun processo pu√≤ terminare in una critical section (secondo me perch√© si porterebbe la risorsa critica con s√©, nel senso che nessun altro programam pu√≤ utilizzarlo, suppongo. Questo si pu√≤ associare al principio 4 di Liveness. Algoritmo di Dekker Listo qua in breve le idee principali che daranno vita all‚Äôalgoritmo\nTurni per disambiguare chi pu√≤ entrare e chi vuole entrare Booleani per esprimere il concetto di voler entrare. Dare la precedenza all‚Äôaltro. Soluzioni provate e non funzionanti üü©- (prolly non richiede) Soluzione 1 (busy waiting esterno con i turni)\nNon √® buona perch√© viola il principio 3 del non rallentamento. Pu√≤ succedere che nessuno √® dentro la sezione critica, ma uno non ci pu√≤ entrare finch√© l‚Äôaltro non ci entra ed esce (ma pu√≤ essere che l‚Äôaltro sia molto pi√π lento!)\nSoluzione 2 (busy waiting esterno con 2 booleani)\nIl problema √® che possono entrambi entrare nella soluzione critica, quindi non √® mutex e quindi non √® una soluzione\nSoluzione 3 (2 booleani, assegnamento prima)\nPu√≤ accadere un deadlock, viola principio 4\nSoluzione 4 (livelook, assegnamenti nel busy waiting)\nPu√≤ accadere starvation in questo problema nel requisito 4, ossia uno non entra mai.\nl‚Äôalgoritmo üü® Questo √® un algoritmo che funziona per implementare le sezioni critiche.\nAndremo in questa parte a considerare moltissime soluzioni che non soddisfano i requisiti esplicitati precedentemente, fino a raggiungere l‚Äôalgoritmo di dekker. (Questo √® proprio il processo seguito da Dijkstra nel raggiungimento della soluzione!)\nAlgoritmo di Dekker\nDimostrazione correttezza di Dekker üü©- Mutua esclusione\nMutua esclusione\nIn pratica si riduce che in un certo momento deve esserci un momenti in cui uno √® nella critical section, e il valore di need associato deve essere falso. Ci√≤ √® impossibile, devo essere eseguite entrambe le istruzioni di uscita!\nAssenza di deadlock\nSlide\nAssenza di ritardi\nSlide\nAssenza di starvation\nSlide\nAlgoritmo di Peterson Descrizione dell‚Äôalgoritmo üü©‚Äî Slide\nAlgortitmo generalizzato üü• Slide peterson generalizzato (non so perch√© funzioni, comunque il prof. lo ha saltato).\nTODO: se vuoi fare bene questo pezzo sarebbe anche Peterson\n√à una cosa molto pi√π compatta rispetto Dekker, e l\u0026rsquo;idea principale √® che il turno √® stabilito prima di entrare nel while\nDimostrazione correttezza di Peterson üü© Mutua esclusione\nSlide\nAssenza deadlock\nSlide\n√à quasi ovvio perch√© turn non pu√≤ avere due variabili diverse\nAssenza di ritardi\nSlide\nAssenza di starvation\nSlide\nSoluzioni hardware Perch√© √® meglio di software (3) üü®- Si preferirebbero delle soluzioni hardware perch√© tutte le soluzioni software fanno utilizzo di busy waiting che √® molto dispendioso.\nDispendioso dal punto di vista della CPU per il busy waiting Difficile da implementare senza bug (difficile da testare) Gestione delle responsabilit√† a livello software (cosa che non si vuole) Disabilitazione interrupt (2) üü© Cos√¨ non posso passare ad un altro processo all\u0026rsquo;inizio di una sezione critica. (ma c\u0026rsquo;√® il problema dei multicore perch√© dovrei disabilitarlo per tutti!).\nCi sono altri motivi per cui questa √® una brutta soluzione:\nLasciare la gestione degli interrupt ai programmi perch√© agisce sull\u0026rsquo;intera macchina, ma non dovrebbe avere questo diritto. Multicore dovrebbero essere sincronizzati su questo aspetto (quindi difficolt√† di parallelizzazione). Quindi non posso essere interrotto Non funziona su multicore perch√© anche se li disabilito su entrambi, pu√≤ esser che due processi lavorano sempre con la stessa sezione critica Test \u0026amp; set (spin lock) üü©- L‚Äôhardware ha delle istruzioni in pi√π che aiutano a creare l‚Äôimplementazione per le sezioni critiche.\nProgramma con test e set\nDimostrazione di correttezza (senza starvation)\nOltre a questo si pu√≤ implementare con altre istruzioni atomiche come fetch and set, compare and swap.\nCS con swap e divisione üü©- Protocollo entrata con swap\nlock = 0; do { v = 1; swap(v, lock); } while(v); Chiaramente posso entrare quando lock √® 0, altrimenti lock √® sempre 1.\nProtocollo entrata con divisione\nlock = 2 do v = \u0026lt; lock /= 2 \u0026gt; while (v != 1) Con questo abbiamo raggiunto una notevole semplificazione nella programmazione (ed anche della generalizzazione di questa soluzione), ma non sono risolti i problemi di starvation n√© busy waiting, ancora fortemente inefficiente.\n","permalink":"https://flecart.github.io/notes/sezioni-critiche/","summary":"Ripasso Prox: 80 Ripasso: May 21, 2023 Ultima modifica: March 12, 2023 10:00 AM Primo Abbozzo: October 8, 2022 11:30 AM Stato: üåïüåïüåïüåïüåë Studi Personali: No\nElementi di ripasso 2 Sezioni Critiche Introduzione La parte di un programma che utilizza una o pi√π risorse condivise viene detta sezione critica (critical section, o CS)\nAndiamo in questa altra parte a valutare certe soluzioni:\nProgramma d‚Äôesempio üü© Vorremmo garantire che a = b invariante.","title":"Sezioni Critiche"},{"content":"Introduzione Quando abbiamo una switch, ma vogliamo allo stesso momento andare a creare pi√π LAN, allora abbiamo bisogno delle VLAN. Questi switch che hanno delle VLAN si chiamano managed switches\nQueste vlan sono numerate (ricorda l‚Äôespericomento cn LUCA!).\nIl problema Sono un protocollo livello 2 (Link-Layer, di collegamento), non vorremmo per esempio che un broadcast di una certa rete vada anche in altre reti che non centrino praticamente nulla, come possiamo vedere in figura.\nEsempio problema di vlan\nImplementazione: porte Posso andare a raggruppare alcune porte come se fossero in una unica network separata rispetto al resto. Posso andare a numerare certe porte e proprio andare a taggarli come se sono parte di una altra rete.\nSi noti che per comincare fra VLAN in switches diverse, bisogna che il pacchetto possieda informazioni riguardo la VLAN in modo che quando viene ricevuto venga correttamente interpretato essere nell vlan corretta.\nVantaggi delle VLAN (3) Formato pacchetto VLAN √à una estensione del pacchetto livello MAC classico con informazioni riguardo le vlan\nPreable: sincronizzare chi trasmette e chi riceve Dest e source sono gli stessi classici livello 2, quindi con MAC. Multiprotocol Layer switching MPLS Esempio\nData center networks Load balancers Cerca di equalizzare il carico di lavoro di tutti.\n","permalink":"https://flecart.github.io/notes/vlan/","summary":"Introduzione Quando abbiamo una switch, ma vogliamo allo stesso momento andare a creare pi√π LAN, allora abbiamo bisogno delle VLAN. Questi switch che hanno delle VLAN si chiamano managed switches\nQueste vlan sono numerate (ricorda l‚Äôespericomento cn LUCA!).\nIl problema Sono un protocollo livello 2 (Link-Layer, di collegamento), non vorremmo per esempio che un broadcast di una certa rete vada anche in altre reti che non centrino praticamente nulla, come possiamo vedere in figura.","title":"VLAN"}]