<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>ðŸ““Big-Data on X. Angelo Huang&#39;s Blog</title>
    <link>https://flecart.github.io/tags/big-data/</link>
    <description>Recent content in ðŸ““Big-Data on X. Angelo Huang&#39;s Blog</description>
    <image>
      <title>X. Angelo Huang&#39;s Blog</title>
      <url>https://flecart.github.io/images/papermod-cover.png</url>
      <link>https://flecart.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <atom:link href="https://flecart.github.io/tags/big-data/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cloud Storage</title>
      <link>https://flecart.github.io/notes/cloud-storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cloud-storage/</guid>
      <description>Paradigms of data storage ETL framework ðŸŸ© This is the classical database approach: We load the data in the database and let the underlying system handle it. This method needs some added cost in extracting, transforming and loading the data that we have stored previously in an optimized format so that it can be used for views, or else.
Data Lakes ðŸŸ© We usually refer to Data Lakes when we store our data with Distributed file systems or using Cloud Storage: cheap ways to dump the data without caring about the possibility of modifying them.</description>
    </item>
    <item>
      <title>Graph Databases</title>
      <link>https://flecart.github.io/notes/graph-databases/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/graph-databases/</guid>
      <description>We have first cited the graph data model in the Introduction to Big Data note. Until now, we have explored many aspects of relational data bases, but now we are changing the data model completely. The main reason driving this discussion are the limitations of classical relational databases: queries like traversal of a high number of relationships, reverse traversal requiring also indexing foreign keys (need double index! Index only work in one direction for relationship traversal, i.</description>
    </item>
    <item>
      <title>Normalizzazione dei database</title>
      <link>https://flecart.github.io/notes/normalizzazione-dei-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/normalizzazione-dei-database/</guid>
      <description>Introduzione alla normalizzazione PerchÃ© si normalizza? ðŸŸ© Cercare di aumentare la qualitÃ  del nostro database, perchÃ© praticamente andiamo a risolvere delle anomalie possibili al nostro interno, e questo aiuta per la qualitÃ . Solitamente queste anomalie sono interessanti per sistemi write intensive, in cui vogliamo mantenere i nostri dati in una forma buona. PerÃ² capita non raramente che vogliamo solamente leggere. In quei casi sistemi come Cloud Storage, Distributed file systems potrebbero risultare piÃ¹ effettivi.</description>
    </item>
    <item>
      <title>Massive Parallel Processing</title>
      <link>https://flecart.github.io/notes/massive-parallel-processing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/massive-parallel-processing/</guid>
      <description>We have a group of mappers that work on dividing the keys for some reducers that actually work on that same group of data. The bottleneck is the assigning part: when mappers finish and need to handle the data to the reducers.
Introduction Common input formats ðŸŸ¨ You need to know well what
Shards Textual input binary, parquet and similars CSV and similars Sharding It is a common practice to divide a big dataset into chunks (or shards), smaller parts which recomposed give the original dataset.</description>
    </item>
    <item>
      <title>Markup</title>
      <link>https://flecart.github.io/notes/markup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/markup/</guid>
      <description>Introduzione alle funzioni del markup ðŸŸ© La semantica di una parola Ã¨ caratterizzata dalla mia scelta (design sul significato). Non mi dice molto, quindi proviamo a raccontare qualcosa in piÃ¹.
Definiamo markup ogni mezzo per rendere esplicita una particolare interpretazione di un testo.
In particolare Ã¨ un modo per esplicitare qualche significato. (un po&amp;rsquo; come la punteggiatura, che da qualche altra informazione oltre le singole parole, rende piÃ¹ chiaro l&amp;rsquo;uso del testo).</description>
    </item>
    <item>
      <title>Querying Denormalized Data</title>
      <link>https://flecart.github.io/notes/querying-denormalized-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/querying-denormalized-data/</guid>
      <description>TODO: write the introduction to the note.
JSONiq purports as an easy query language that could run everywhere. It attempts to solve common problems in SQL i.e. the lack of support for nested data structures and also the lack of support for JSON data types. A nice thing about JSONiq is that it is functional, which makes its queries quite powerful and flexible. It is also declarative and set-based. These are some commonalities with SQL.</description>
    </item>
    <item>
      <title>Wide Column Storage</title>
      <link>https://flecart.github.io/notes/wide-column-storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/wide-column-storage/</guid>
      <description>We now start with data modelling after having dealt with the syntax in Markup and data storage methods in Cloud Storage and Distributed file systems. In this case we want the data to be denormalized (see Normalizzazione dei database) but still looking like tables.
Usage of Wide Column Storages Wide column stores were invented to provide more control over performance and in particular, in order to achieve high-throughput and low latency for objects ranging from a few bytes to about 10 MB, which are too big and numerous to be efficiently stored as so-called clobs (character large objects) or blobs (binary large objects) in a relational database system, but also too small and numerous to be efficiently accessed in a distributed file system.</description>
    </item>
    <item>
      <title>HTTP e REST</title>
      <link>https://flecart.github.io/notes/http-e-rest/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/http-e-rest/</guid>
      <description>HTTP is the acronym for HyperText Transfer Protocol.
Caratteristiche principali (3) ðŸŸ¨ Comunicazioni fra client e server, e quanto sono comunicate le cose si chiude la connessione e ci sono politiche di caching molto bone (tipo con i proxy) Generico: perchÃ© Ã¨ un protocollo utilizzato per caricare moltissime tipologie di risorse! Stateless, ossia non vengono mantenute informazioni su scambi vecchi, in un certo modo ne abbiamo parlato in Sicurezza delle reti quando abbiamo parlato di firewall stateless.</description>
    </item>
    <item>
      <title>Document Stores</title>
      <link>https://flecart.github.io/notes/document-stores/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/document-stores/</guid>
      <description>Document stores provide a native database management system for semi-structured data. Document stores also scale to Gigabytes or Ter- abytes of data, and typically millions or billions of records (a record being a JSON object or an XML document).
Introduction to Document Stores a document store, unlike a data lake, manages the data directly and the users do not see the physical layout.
Unlike data lakes, using document stores prevent us from breaking data independence and reading the data file directly: it offers an automatic manager service for semi-structured data that we need to throw and read quickly.</description>
    </item>
    <item>
      <title>Codifica dei caratteri</title>
      <link>https://flecart.github.io/notes/codifica-dei-caratteri/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/codifica-dei-caratteri/</guid>
      <description>Introduzione sull&amp;rsquo;encoding Ossia trattiamo metodi per codificare caratteri dei linguaggi umani, come ASCII, UCS e UTF.
Digitalizzare significa encodarlo in un sistema che possa essere memorizzato su un dispositivo di memorizzazione elettronico. Ovviamente non possiamo mantenere l&amp;rsquo;informazione cosÃ¬ come Ã¨, ma vogliamo memorizzarne una forma equivalente, ma piÃ¹ facile da manipolare dal punto di vista del computer. Creiamo quindi un mapping, o anche isomorfismo tra il valore di mappatura (o encoding), solitamente un valore numerico, tra il singolo valore atomico originale e il numero.</description>
    </item>
    <item>
      <title>Introduction to Big Data</title>
      <link>https://flecart.github.io/notes/introduction-to-big-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-big-data/</guid>
      <description>Data Science is similar to physics: it attemps to create theories of realities based on some formalism that another science brings. For physics it was mathematics, for data science it is computer science. Data has grown expeditiously in these last years and has reached a distance that in metres is the distance to Jupiter. The galaxy is in the order of magnitude of 400 Yottametres, which has $3 \cdot 8$ zeros following after it.</description>
    </item>
    <item>
      <title>Structured Query Language</title>
      <link>https://flecart.github.io/notes/structured-query-language/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/structured-query-language/</guid>
      <description>Little bits of history It was invented in 1970 in Almaden (San Jose) by IBM (Don Chamberlin, Raymond Boyce worked on this) for the first relational database, called system R. Then for copyright issues it hasn&amp;rsquo;t been called SEQUEL, so they branded it as SQL.
SQL is a declarative language With declaratives language there is a separation between what I call the intentionality and the actual process. In declarative languages we just say what we want the result to be, and don&amp;rsquo;t care what the actual implementation is like.</description>
    </item>
    <item>
      <title>Uniform Resource Identifier</title>
      <link>https://flecart.github.io/notes/uniform-resource-identifier/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/uniform-resource-identifier/</guid>
      <description>URI Sono stata LA vera invenzione di Berners Lee accennati in Storia del web. Il problema Ã¨ avere un modo per identificare una risorsa in modo univoco sullâ€™internet.
Introduzione La risorsa ðŸŸ© Una risorsa Ã¨ qualunque struttura che sia oggetto di scambio tra applicazioni allâ€™interno del World Wide Web.
Ora una risorsa puÃ² essere qualunque cosa, non solamente solo un file! Quindi Ã¨ agnostico rispetto a contenuto oppure metodo di memorizzazione del dato, appare anche in questo ambiente importante vedere quanto siano importanti standard che permettano una comunicazione</description>
    </item>
    <item>
      <title>Distributed file systems</title>
      <link>https://flecart.github.io/notes/distributed-file-systems/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/distributed-file-systems/</guid>
      <description>We want to know how to handle systems that have a large number of data. In previous lesson we have discovered how to quickly access and make Scalable systems with huge dimensions, see Cloud Storage. Object storage could store billions of files, we want to handle millions of petabyte files.
Desiderata of distributed file systems ðŸŸ© In this case we have a Filesystem. In 2004 google created his own FS. With hundreds or thousands of machines the systems are practically guaranteed to fail.</description>
    </item>
    <item>
      <title>Data Cubes</title>
      <link>https://flecart.github.io/notes/data-cubes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/data-cubes/</guid>
      <description>Data Cubes is a data format especially useful for heavy reads. It has been popularized in business environments where the main use for data was to make reports (many reads). This also links with the OLAP (Online Analytical Processing) vs OLTP (Online Transaction Processing) concepts, where one is optimized for reads and the other for writes.
The main driver behind data cubes was business intelligence. While traditional relational database systems are focused on the day-to-day business of a company and record keeping (with customers placing or- ders, inventories kept up to date, etc), business intelligence is focused on the production of high-level reports for supporting C-level executives in making informed decisions.</description>
    </item>
    <item>
      <title>Data Models and Validation</title>
      <link>https://flecart.github.io/notes/data-models-and-validation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/data-models-and-validation/</guid>
      <description>A data model is an abstract view over the data that hides the way it is stored physically.
The same idea from (Codd 1970) This is why we should not modify data directly, but pass though some abstraction that maintain the properties of that specific data model.
Data Models Tree view We can view all JSON and XML data, as presented in HTML and Markup, as trees. This structure is usually quite evident, as it is inherent in their design.</description>
    </item>
    <item>
      <title>Apache Spark</title>
      <link>https://flecart.github.io/notes/apache-spark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/apache-spark/</guid>
      <description>This is a new framework that is faster than MapReduce (See Massive Parallel Processing). It is written in Scala and has a more functional approach to programming. Spark extends the previous MapReduce framework to a generic distributed dataflow, properly modeled as a DAG. There are other benefits of using Spark instead of the Map reduce Framework:
Spark processes data in memory, avoiding the disk I/O overhead of MapReduce, making it significantly faster.</description>
    </item>
  </channel>
</rss>
