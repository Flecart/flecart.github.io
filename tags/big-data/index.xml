<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>ðŸ““Big-Data on X. Angelo Huang&#39;s Blog</title>
    <link>https://flecart.github.io/tags/big-data/</link>
    <description>Recent content in ðŸ““Big-Data on X. Angelo Huang&#39;s Blog</description>
    <image>
      <title>X. Angelo Huang&#39;s Blog</title>
      <url>https://flecart.github.io/images/papermod-cover.png</url>
      <link>https://flecart.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.143.1</generator>
    <language>en</language>
    <atom:link href="https://flecart.github.io/tags/big-data/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cloud Storage</title>
      <link>https://flecart.github.io/notes/cloud-storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cloud-storage/</guid>
      <description>&lt;h2 id=&#34;object-stores&#34;&gt;Object Stores&lt;/h2&gt;
&lt;h3 id=&#34;characteristics-of-cloud-systems&#34;&gt;Characteristics of Cloud Systems&lt;/h3&gt;
&lt;h4 id=&#34;object-storage-design-principles-&#34;&gt;Object storage design principles ðŸŸ¨++&lt;/h4&gt;
&lt;p&gt;We don&amp;rsquo;t want the hierarchy that is common in &lt;a href=&#34;https://flecart.github.io/notes/filesystem&#34;&gt;Filesystem&lt;/a&gt;s, so we need to simplify that and have these four principles:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Black-box objects&lt;/li&gt;
&lt;li&gt;Flat and global &lt;strong&gt;key-value&lt;/strong&gt; model (trivial model, easy to access, without the need to trasverse a file hierarchy).&lt;/li&gt;
&lt;li&gt;Flexible &lt;strong&gt;metadata&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Commodity hardware (the battery idea of Tesla until 2017).&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;object-storage-usages-&#34;&gt;Object storage usages ðŸŸ©&lt;/h4&gt;
&lt;p&gt;Object storage are useful to store things that are usually read-intensive. Some examples are&lt;/p&gt;</description>
    </item>
    <item>
      <title>Massive Parallel Processing</title>
      <link>https://flecart.github.io/notes/massive-parallel-processing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/massive-parallel-processing/</guid>
      <description>&lt;p&gt;We have a group of mappers that work on dividing the keys for some reducers that actually work on that same group of data. The bottleneck is the assigning part: when mappers finish and need to handle the data to the reducers.&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;h4 id=&#34;common-input-formats-&#34;&gt;Common input formats ðŸŸ¨&lt;/h4&gt;
&lt;p&gt;You need to know well what&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Shards&lt;/li&gt;
&lt;li&gt;Textual input&lt;/li&gt;
&lt;li&gt;binary, parquet and similars&lt;/li&gt;
&lt;li&gt;CSV and similars&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sharding-&#34;&gt;Sharding ðŸŸ©&lt;/h4&gt;
&lt;p&gt;It is a common practice to divide a big dataset into &lt;em&gt;chunks&lt;/em&gt; (or shards), smaller parts which recomposed give the original dataset.
For example, in &lt;a href=&#34;https://flecart.github.io/notes/cloud-storage&#34;&gt;Cloud Storage&lt;/a&gt; settings we often divide big files into chunks, while in &lt;a href=&#34;https://flecart.github.io/notes/distributed-file-systems&#34;&gt;Distributed file systems&lt;/a&gt; the system automatically divides big files into native files of maximum 10 GB size.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache Spark</title>
      <link>https://flecart.github.io/notes/apache-spark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/apache-spark/</guid>
      <description>&lt;p&gt;This is a new framework that is faster than MapReduce (See &lt;a href=&#34;https://flecart.github.io/notes/massive-parallel-processing&#34;&gt;Massive Parallel Processing&lt;/a&gt;). It is written in Scala and has a more functional approach to programming.
Spark extends the previous MapReduce framework to a generic distributed dataflow, properly modeled as a DAG.
There are other benefits of using Spark instead of the Map reduce Framework:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spark processes data in memory, avoiding the disk I/O overhead of MapReduce, making it significantly faster.&lt;/li&gt;
&lt;li&gt;Spark uses a DAG to optimize the entire workflow, reducing data shuffling and stage count.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But MapReduce sometimes has its advantages:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Cubes</title>
      <link>https://flecart.github.io/notes/data-cubes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/data-cubes/</guid>
      <description>&lt;p&gt;Data Cubes is a data format especially useful for heavy reads. It has been popularized in business environments where the main use for data was to make reports (many reads).
This also links with the OLAP (Online Analytical Processing) vs OLTP (Online Transaction Processing) concepts, where one is optimized for reads and the other for writes.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The main driver behind data cubes was business intelligence. While
traditional relational database systems are focused on the day-to-day
business of a company and record keeping (with customers placing or-
ders, inventories kept up to date, etc), business intelligence is focused on
the production of high-level reports for supporting C-level executives
in making informed decisions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Models and Validation</title>
      <link>https://flecart.github.io/notes/data-models-and-validation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/data-models-and-validation/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;A data model is an abstract view over the data that hides the way it is stored physically.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The same idea from &lt;a href=&#34;https://dl.acm.org/doi/10.1145/362384.362685&#34;&gt;(Codd 1970)&lt;/a&gt;
This is why we should not modify data directly, but pass though some abstraction that maintain the properties of that specific data model.&lt;/p&gt;
&lt;h2 id=&#34;data-models&#34;&gt;Data Models&lt;/h2&gt;
&lt;h4 id=&#34;tree-view-&#34;&gt;Tree view ðŸŸ©&lt;/h4&gt;
&lt;p&gt;We can view all JSON and XML data, as presented in &lt;a href=&#34;https://flecart.github.io/notes/markup&#34;&gt;Markup&lt;/a&gt;, as &lt;strong&gt;trees&lt;/strong&gt;. This structure is usually quite evident, as it is inherent in their design. Converting from the tree structure to a memory model is known as serialization, while the reverse process is called &lt;strong&gt;parsing&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Distributed file systems</title>
      <link>https://flecart.github.io/notes/distributed-file-systems/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/distributed-file-systems/</guid>
      <description>&lt;p&gt;We want to know how to handle systems that have a large number of data. In previous lesson we have discovered how to quickly access and make Scalable systems with huge dimensions, see &lt;a href=&#34;https://flecart.github.io/notes/cloud-storage&#34;&gt;Cloud Storage&lt;/a&gt;. Object storage could store billions of files, we want to handle millions of petabyte files.&lt;/p&gt;
&lt;h3 id=&#34;designing-dfss&#34;&gt;Designing DFSs&lt;/h3&gt;
&lt;h4 id=&#34;the-use-case&#34;&gt;The Use Case&lt;/h4&gt;
&lt;p&gt;Remember that the size of the files where heavily limited for &lt;a href=&#34;https://flecart.github.io/notes/cloud-storage&#34;&gt;Cloud Storage&lt;/a&gt;. The physical limitation was due to the limited size of a single hard disk, which was usually in the order of the Terabytes.
Here, we would like to easily store &lt;em&gt;petabytes&lt;/em&gt; of data in a single file, for example &lt;strong&gt;big datasets&lt;/strong&gt;.
Another feature that should be easily supported is &lt;strong&gt;highly concurrent access&lt;/strong&gt; to the filesystem, last but not least being able to set up permissions in the system.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Document Stores</title>
      <link>https://flecart.github.io/notes/document-stores/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/document-stores/</guid>
      <description>&lt;p&gt;p&amp;gt; Document stores provide a native database management system for &lt;strong&gt;semi-structured&lt;/strong&gt; data. Document stores also scale to Gigabytes or Terabytes of data, and typically millions or billions of records (a record being a JSON object or an XML document).&lt;/p&gt;
&lt;h3 id=&#34;introduction-to-document-stores&#34;&gt;Introduction to Document Stores&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;A document store, unlike a data lake, manages the data &lt;em&gt;directly&lt;/em&gt; and the users do not see the physical layout.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Unlike data lakes, using document stores prevent us from breaking data independence and reading the data file directly: it offers an automatic manager service for &lt;strong&gt;semi-structured&lt;/strong&gt; data that we need to throw and read quickly.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Graph Databases</title>
      <link>https://flecart.github.io/notes/graph-databases/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/graph-databases/</guid>
      <description>&lt;p&gt;We have first cited the graph data model in the &lt;a href=&#34;https://flecart.github.io/notes/introduction-to-big-data&#34;&gt;Introduction to Big Data&lt;/a&gt; note.
Until now, we have explored many aspects of relational data bases, but now we are changing the data model completely. The main reason driving this discussion are the limitations of classical relational databases: queries like traversal of a high number of relationships, reverse traversal requiring
also indexing foreign keys (need double index! Index only work in one direction for relationship traversal, i.e. if you need both direction you should build an index both for the forward key and backward key), looking for patterns in the relationships, are especially expensive when using normal databases.
We have improved over the problem of joining with relational database using &lt;a href=&#34;https://flecart.github.io/notes/document-stores&#34;&gt;Document Stores&lt;/a&gt; with three data structure, but these &lt;em&gt;cannot&lt;/em&gt; have cycles.
We call &lt;em&gt;index-free adjacency&lt;/em&gt;: we use physical memory pointers to store the graph.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Big Data</title>
      <link>https://flecart.github.io/notes/introduction-to-big-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-big-data/</guid>
      <description>&lt;p&gt;Data Science is similar to physics: it attemps to create theories of realities based on some formalism that another science brings. For physics it was mathematics, for data science it is computer science.
Data has grown expeditiously in these last years and has reached a distance that in metres is the distance to Jupiter. The galaxy is in the order of magnitude of 400 Yottametres, which has $3 \cdot 8$ zeros following after it. So quite a lot. We don&amp;rsquo;t know if the magnitude of the data will grow this fast but certainly we need to be able to face this case.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Markup</title>
      <link>https://flecart.github.io/notes/markup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/markup/</guid>
      <description>&lt;h3 id=&#34;introduzione-alle-funzioni-del-markup-&#34;&gt;Introduzione alle funzioni del markup ðŸŸ©&lt;/h3&gt;
&lt;p&gt;La semantica di una parola Ã¨ caratterizzata dalla mia scelta (design sul significato). Non mi dice molto, quindi proviamo a raccontare qualcosa in piÃ¹.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Definiamo markup ogni mezzo per rendere esplicita una particolare &lt;em&gt;interpretazione&lt;/em&gt; di un testo.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In particolare Ã¨ un modo per esplicitare qualche significato. (un po&amp;rsquo; come la punteggiatura, che da qualche altra informazione oltre le singole parole, rende piÃ¹ chiaro l&amp;rsquo;uso del testo).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Performance at Large Scales</title>
      <link>https://flecart.github.io/notes/performance-at-large-scales/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/performance-at-large-scales/</guid>
      <description>&lt;p&gt;Some specific phenomenons in modern systems happen only when we scale into large systems. This note will gather some observations about the most important phenomena we observe at these scales.&lt;/p&gt;
&lt;h4 id=&#34;tail-latency-phenomenon&#34;&gt;Tail Latency Phenomenon&lt;/h4&gt;
&lt;p&gt;Tail latency refers to the high-end response time experienced by
When scaling our services, using &lt;a href=&#34;https://flecart.github.io/notes/massive-parallel-processing&#34;&gt;Massive Parallel Processing&lt;/a&gt;, and similar technology, it is not rare that
a small percentage of requests in a system experience a &lt;strong&gt;high-end response&lt;/strong&gt; time, typically measured at the 95th or 99th percentile.
This significant delays that can degrade user experience or system reliability.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Querying Denormalized Data</title>
      <link>https://flecart.github.io/notes/querying-denormalized-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/querying-denormalized-data/</guid>
      <description>&lt;p&gt;TODO: write the introduction to the note.&lt;/p&gt;
&lt;p&gt;JSONiq purports as an easy query language that could run everywhere. It attempts to solve common problems in SQL i.e. the lack of support for nested data structures and also the lack of support for JSON data types.
A nice thing about JSONiq is that it is functional, which makes its queries quite powerful and flexible. It is also declarative and &lt;strong&gt;set-based&lt;/strong&gt;. These are some commonalities with SQL.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Wide Column Storage</title>
      <link>https://flecart.github.io/notes/wide-column-storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/wide-column-storage/</guid>
      <description>&lt;h3 id=&#34;introduction-to-wide-column-storages&#34;&gt;Introduction to Wide Column Storages&lt;/h3&gt;
&lt;p&gt;One of the bottlenecks of traditional relational databases is the speed of the Joints, which could be done in $\mathcal{O}(n)$ using a merge join, assuming some indexes are present which make the keys already sorted.
The other solution, of just using &lt;a href=&#34;https://flecart.github.io/notes/distributed-file-systems&#34;&gt;Distributed file systems&lt;/a&gt;, is also not optimal: they have usually a high latency, with high throughput, that is not optimal with the series of small files that it is optimized for.
While Object Storages, do not have APIs that could be helpful -&amp;gt; &lt;strong&gt;richer logical model&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Codifica dei caratteri</title>
      <link>https://flecart.github.io/notes/codifica-dei-caratteri/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/codifica-dei-caratteri/</guid>
      <description>&lt;h3 id=&#34;introduzione-sullencoding&#34;&gt;Introduzione sull&amp;rsquo;encoding&lt;/h3&gt;
&lt;p&gt;Ossia trattiamo metodi per codificare caratteri dei linguaggi umani, come ASCII, UCS e UTF.&lt;/p&gt;
&lt;p&gt;Digitalizzare significa encodarlo in un sistema che possa essere memorizzato su un dispositivo di memorizzazione elettronico. Ovviamente non possiamo mantenere l&amp;rsquo;informazione cosÃ¬ come Ã¨, ma vogliamo memorizzarne una forma equivalente, ma piÃ¹ facile da manipolare dal punto di vista del computer. Creiamo quindi un mapping, o anche isomorfismo tra il valore di mappatura (o encoding), solitamente un valore numerico, tra il singolo valore atomico originale e il numero.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Normalizzazione dei database</title>
      <link>https://flecart.github.io/notes/normalizzazione-dei-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/normalizzazione-dei-database/</guid>
      <description>&lt;h3 id=&#34;introduzione-alla-normalizzazione&#34;&gt;Introduzione alla normalizzazione&lt;/h3&gt;
&lt;h4 id=&#34;perchÃ©-si-normalizza-&#34;&gt;PerchÃ© si normalizza? ðŸŸ©&lt;/h4&gt;
&lt;p&gt;Cercare di aumentare la qualitÃ  del nostro database, perchÃ© praticamente andiamo a risolvere delle anomalie possibili al nostro interno, e questo aiuta per la qualitÃ .
Solitamente queste anomalie sono interessanti per sistemi write intensive, in cui vogliamo mantenere i nostri dati in una forma buona. PerÃ² capita non raramente che vogliamo solamente leggere. In quei casi sistemi come &lt;a href=&#34;https://flecart.github.io/notes/cloud-storage&#34;&gt;Cloud Storage&lt;/a&gt;, &lt;a href=&#34;https://flecart.github.io/notes/distributed-file-systems&#34;&gt;Distributed file systems&lt;/a&gt; potrebbero risultare piÃ¹ effettivi.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Structured Query Language</title>
      <link>https://flecart.github.io/notes/structured-query-language/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/structured-query-language/</guid>
      <description>&lt;h3 id=&#34;little-bits-of-history&#34;&gt;Little bits of history&lt;/h3&gt;
&lt;p&gt;It was invented in 1970 in Almaden (San Jose) by IBM (Don Chamberlin, Raymond Boyce worked on this) for the first relational database, called system R. Then for copyright issues it hasn&amp;rsquo;t been called SEQUEL, so they branded it as SQL.&lt;/p&gt;
&lt;h4 id=&#34;sql-is-a-declarative-language&#34;&gt;SQL is a declarative language&lt;/h4&gt;
&lt;p&gt;With declaratives language there is a separation between what I call the intentionality and the actual process. In declarative languages we just say what we want the result to be, and don&amp;rsquo;t care what the actual implementation is like.
This allows queries to be executed and optimized in different ways, even if the query on the surface is the same&lt;/p&gt;</description>
    </item>
    <item>
      <title>Uniform Resource Identifier</title>
      <link>https://flecart.github.io/notes/uniform-resource-identifier/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/uniform-resource-identifier/</guid>
      <description>&lt;h1 id=&#34;uri&#34;&gt;URI&lt;/h1&gt;
&lt;p&gt;Sono stata LA vera invenzione di Berners Lee accennati in &lt;a href=&#34;https://flecart.github.io/notes/storia-del-web&#34;&gt;Storia del web&lt;/a&gt;. Il problema Ã¨ avere un modo per identificare una risorsa in modo univoco sullâ€™internet.&lt;/p&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;h3 id=&#34;la-risorsa-&#34;&gt;La risorsa ðŸŸ©&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Una risorsa Ã¨ qualunque struttura che sia oggetto di scambio tra
applicazioni allâ€™interno del World Wide Web.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ora una risorsa puÃ² essere qualunque cosa, non solamente solo un file! Quindi Ã¨ agnostico rispetto a contenuto oppure metodo di memorizzazione del dato, appare anche in questo ambiente importante vedere quanto siano importanti standard che permettano una comunicazione&lt;/p&gt;</description>
    </item>
    <item>
      <title>HTTP e REST</title>
      <link>https://flecart.github.io/notes/http-e-rest/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/http-e-rest/</guid>
      <description>&lt;p&gt;HTTP is the acronym for HyperText Transfer Protocol.&lt;/p&gt;
&lt;h3 id=&#34;caratteristiche-principali-3&#34;&gt;Caratteristiche principali (3)&lt;/h3&gt;
&lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/HTTP e REST/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/HTTP e REST/Untitled&#34;&gt;
&lt;ol&gt;
&lt;li&gt;Comunicazioni fra client e server, e quanto sono comunicate le cose si chiude la connessione e ci sono politiche di caching molto bone (tipo con i proxy)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generico&lt;/strong&gt;: perchÃ© Ã¨ un protocollo utilizzato per caricare moltissime tipologie di risorse!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stateless&lt;/strong&gt;, ossia non vengono mantenute informazioni su scambi vecchi, in un certo modo ne abbiamo parlato in &lt;a href=&#34;https://flecart.github.io/notes/sicurezza-delle-reti&#34;&gt;Sicurezza delle reti&lt;/a&gt; quando abbiamo parlato di firewall stateless.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Solitamente possiamo intendere questo protocollo come utile per &lt;strong&gt;scambiare risorse&lt;/strong&gt; di cui abbiamo parlato in &lt;a href=&#34;https://flecart.github.io/notes/uniform-resource-identifier&#34;&gt;Uniform Resource Identifier&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
