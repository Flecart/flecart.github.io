<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>ðŸ““Big-Data on X. Angelo Huang&#39;s Blog</title>
    <link>https://flecart.github.io/tags/big-data/</link>
    <description>Recent content in ðŸ““Big-Data on X. Angelo Huang&#39;s Blog</description>
    <image>
      <title>X. Angelo Huang&#39;s Blog</title>
      <url>https://flecart.github.io/images/papermod-cover.png</url>
      <link>https://flecart.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <atom:link href="https://flecart.github.io/tags/big-data/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Codifica dei caratteri</title>
      <link>https://flecart.github.io/notes/codifica-dei-caratteri/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/codifica-dei-caratteri/</guid>
      <description>Introduzione sull&amp;rsquo;encoding Ossia trattiamo metodi per codificare caratteri dei linguaggi umani, come ASCII, UCS e UTF.
Digitalizzare significa encodarlo in un sistema che possa essere memorizzato su un dispositivo di memorizzazione elettronico. Ovviamente non possiamo mantenere l&amp;rsquo;informazione cosÃ¬ come Ã¨, ma vogliamo memorizzarne una forma equivalente, ma piÃ¹ facile da manipolare dal punto di vista del computer. Creiamo quindi un mapping, o anche isomorfismo tra il valore di mappatura (o encoding), solitamente un valore numerico, tra il singolo valore atomico originale e il numero.</description>
    </item>
    <item>
      <title>Apache Spark</title>
      <link>https://flecart.github.io/notes/apache-spark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/apache-spark/</guid>
      <description>This is a new framework that is faster than MapReduce (See Massive Parallel Processing). It is written in Scala and has a more functional approach to programming. Spark extends the previous MapReduce framework to a generic distributed dataflow, properly modeled as a DAG. There are other benefits of using Spark instead of the Map reduce Framework:
Spark processes data in memory, avoiding the disk I/O overhead of MapReduce, making it significantly faster.</description>
    </item>
    <item>
      <title>Cloud Storage</title>
      <link>https://flecart.github.io/notes/cloud-storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cloud-storage/</guid>
      <description>Object Stores Object storage design principles ðŸŸ¨&amp;ndash; We don&amp;rsquo;t want the hierarchy that is common in Filesystems, so we need to simplify that and have these four principles:
Black-box objects Flat and global key-value model (trivial model, easy to access, without the need to trasverse a file hieararchy). Flexible metadata Commodity hardware (the battery idea of Tesla until 2017). Object storage usages ðŸŸ© Object storages are useful to store things that are usually read-intensive.</description>
    </item>
    <item>
      <title>Wide Column Storage</title>
      <link>https://flecart.github.io/notes/wide-column-storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/wide-column-storage/</guid>
      <description>Introduction to Wide Column Storages One of the bottlenecks of traditional relational databases is the speed of the Joints, which could be done in $\mathcal{O}(n)$ using a merge join, assuming some indexes are present which make the keys already sorted. The other solution, of just using Distributed file systems, is also not optimal: they have usually a high latency, with high throughput, that is not optimal with the series of small files that it is optimized for.</description>
    </item>
    <item>
      <title>Normalizzazione dei database</title>
      <link>https://flecart.github.io/notes/normalizzazione-dei-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/normalizzazione-dei-database/</guid>
      <description>Introduzione alla normalizzazione PerchÃ© si normalizza? ðŸŸ© Cercare di aumentare la qualitÃ  del nostro database, perchÃ© praticamente andiamo a risolvere delle anomalie possibili al nostro interno, e questo aiuta per la qualitÃ . Solitamente queste anomalie sono interessanti per sistemi write intensive, in cui vogliamo mantenere i nostri dati in una forma buona. PerÃ² capita non raramente che vogliamo solamente leggere. In quei casi sistemi come Cloud Storage, Distributed file systems potrebbero risultare piÃ¹ effettivi.</description>
    </item>
    <item>
      <title>Structured Query Language</title>
      <link>https://flecart.github.io/notes/structured-query-language/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/structured-query-language/</guid>
      <description>Little bits of history It was invented in 1970 in Almaden (San Jose) by IBM (Don Chamberlin, Raymond Boyce worked on this) for the first relational database, called system R. Then for copyright issues it hasn&amp;rsquo;t been called SEQUEL, so they branded it as SQL.
SQL is a declarative language With declaratives language there is a separation between what I call the intentionality and the actual process. In declarative languages we just say what we want the result to be, and don&amp;rsquo;t care what the actual implementation is like.</description>
    </item>
    <item>
      <title>Data Models and Validation</title>
      <link>https://flecart.github.io/notes/data-models-and-validation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/data-models-and-validation/</guid>
      <description>A data model is an abstract view over the data that hides the way it is stored physically.
The same idea from (Codd 1970) This is why we should not modify data directly, but pass though some abstraction that maintain the properties of that specific data model.
Data Models Tree view ðŸŸ© We can view all JSON and XML data, as presented in Markup, as trees. This structure is usually quite evident, as it is inherent in their design.</description>
    </item>
    <item>
      <title>Distributed file systems</title>
      <link>https://flecart.github.io/notes/distributed-file-systems/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/distributed-file-systems/</guid>
      <description>We want to know how to handle systems that have a large number of data. In previous lesson we have discovered how to quickly access and make Scalable systems with huge dimensions, see Cloud Storage. Object storage could store billions of files, we want to handle millions of petabyte files.
Designing DFSs The Use Case Remember that the size of the files where heavily limited for Cloud Storage. The physical limitation was due to the limited size of a single hard disk, which was usually in the order of the Terabytes.</description>
    </item>
    <item>
      <title>Massive Parallel Processing</title>
      <link>https://flecart.github.io/notes/massive-parallel-processing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/massive-parallel-processing/</guid>
      <description>We have a group of mappers that work on dividing the keys for some reducers that actually work on that same group of data. The bottleneck is the assigning part: when mappers finish and need to handle the data to the reducers.
Introduction Common input formats ðŸŸ¨ You need to know well what
Shards Textual input binary, parquet and similars CSV and similars Sharding ðŸŸ© It is a common practice to divide a big dataset into chunks (or shards), smaller parts which recomposed give the original dataset.</description>
    </item>
    <item>
      <title>Document Stores</title>
      <link>https://flecart.github.io/notes/document-stores/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/document-stores/</guid>
      <description>p&amp;gt; Document stores provide a native database management system for semi-structured data. Document stores also scale to Gigabytes or Terabytes of data, and typically millions or billions of records (a record being a JSON object or an XML document).
Introduction to Document Stores A document store, unlike a data lake, manages the data directly and the users do not see the physical layout.
Unlike data lakes, using document stores prevent us from breaking data independence and reading the data file directly: it offers an automatic manager service for semi-structured data that we need to throw and read quickly.</description>
    </item>
    <item>
      <title>HTTP e REST</title>
      <link>https://flecart.github.io/notes/http-e-rest/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/http-e-rest/</guid>
      <description>HTTP is the acronym for HyperText Transfer Protocol.
Caratteristiche principali (3) Comunicazioni fra client e server, e quanto sono comunicate le cose si chiude la connessione e ci sono politiche di caching molto bone (tipo con i proxy) Generico: perchÃ© Ã¨ un protocollo utilizzato per caricare moltissime tipologie di risorse! Stateless, ossia non vengono mantenute informazioni su scambi vecchi, in un certo modo ne abbiamo parlato in Sicurezza delle reti quando abbiamo parlato di firewall stateless.</description>
    </item>
    <item>
      <title>Data Cubes</title>
      <link>https://flecart.github.io/notes/data-cubes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/data-cubes/</guid>
      <description>Data Cubes is a data format especially useful for heavy reads. It has been popularized in business environments where the main use for data was to make reports (many reads). This also links with the OLAP (Online Analytical Processing) vs OLTP (Online Transaction Processing) concepts, where one is optimized for reads and the other for writes.
The main driver behind data cubes was business intelligence. While traditional relational database systems are focused on the day-to-day business of a company and record keeping (with customers placing or- ders, inventories kept up to date, etc), business intelligence is focused on the production of high-level reports for supporting C-level executives in making informed decisions.</description>
    </item>
    <item>
      <title>Introduction to Big Data</title>
      <link>https://flecart.github.io/notes/introduction-to-big-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-big-data/</guid>
      <description>Data Science is similar to physics: it attemps to create theories of realities based on some formalism that another science brings. For physics it was mathematics, for data science it is computer science. Data has grown expeditiously in these last years and has reached a distance that in metres is the distance to Jupiter. The galaxy is in the order of magnitude of 400 Yottametres, which has $3 \cdot 8$ zeros following after it.</description>
    </item>
    <item>
      <title>Uniform Resource Identifier</title>
      <link>https://flecart.github.io/notes/uniform-resource-identifier/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/uniform-resource-identifier/</guid>
      <description>URI Sono stata LA vera invenzione di Berners Lee accennati in Storia del web. Il problema Ã¨ avere un modo per identificare una risorsa in modo univoco sullâ€™internet.
Introduzione La risorsa ðŸŸ© Una risorsa Ã¨ qualunque struttura che sia oggetto di scambio tra applicazioni allâ€™interno del World Wide Web.
Ora una risorsa puÃ² essere qualunque cosa, non solamente solo un file! Quindi Ã¨ agnostico rispetto a contenuto oppure metodo di memorizzazione del dato, appare anche in questo ambiente importante vedere quanto siano importanti standard che permettano una comunicazione</description>
    </item>
    <item>
      <title>Graph Databases</title>
      <link>https://flecart.github.io/notes/graph-databases/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/graph-databases/</guid>
      <description>We have first cited the graph data model in the Introduction to Big Data note. Until now, we have explored many aspects of relational data bases, but now we are changing the data model completely. The main reason driving this discussion are the limitations of classical relational databases: queries like traversal of a high number of relationships, reverse traversal requiring also indexing foreign keys (need double index! Index only work in one direction for relationship traversal, i.</description>
    </item>
    <item>
      <title>Markup</title>
      <link>https://flecart.github.io/notes/markup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/markup/</guid>
      <description>Introduzione alle funzioni del markup ðŸŸ© La semantica di una parola Ã¨ caratterizzata dalla mia scelta (design sul significato). Non mi dice molto, quindi proviamo a raccontare qualcosa in piÃ¹.
Definiamo markup ogni mezzo per rendere esplicita una particolare interpretazione di un testo.
In particolare Ã¨ un modo per esplicitare qualche significato. (un po&amp;rsquo; come la punteggiatura, che da qualche altra informazione oltre le singole parole, rende piÃ¹ chiaro l&amp;rsquo;uso del testo).</description>
    </item>
    <item>
      <title>Performance at Large Scales</title>
      <link>https://flecart.github.io/notes/performance-at-large-scales/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/performance-at-large-scales/</guid>
      <description>Some specific phenomenons in modern systems happen only when we scale into large systems. This note will gather some observations about the most important phenomena we observe at these scales.
Tail Latency Phenomenon Tail latency refers to the high-end response time experienced by When scaling our services, using Massive Parallel Processing, and similar technology, it is not rare that a small percentage of requests in a system experience a high-end response time, typically measured at the 95th or 99th percentile.</description>
    </item>
    <item>
      <title>Querying Denormalized Data</title>
      <link>https://flecart.github.io/notes/querying-denormalized-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/querying-denormalized-data/</guid>
      <description>TODO: write the introduction to the note.
JSONiq purports as an easy query language that could run everywhere. It attempts to solve common problems in SQL i.e. the lack of support for nested data structures and also the lack of support for JSON data types. A nice thing about JSONiq is that it is functional, which makes its queries quite powerful and flexible. It is also declarative and set-based. These are some commonalities with SQL.</description>
    </item>
  </channel>
</rss>
