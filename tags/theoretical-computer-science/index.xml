<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Theoretical-Computer-Science on X. Angelo Huang&#39;s Blog</title>
    <link>https://flecart.github.io/tags/theoretical-computer-science/</link>
    <description>Recent content in Theoretical-Computer-Science on X. Angelo Huang&#39;s Blog</description>
    <image>
      <title>X. Angelo Huang&#39;s Blog</title>
      <url>https://flecart.github.io/images/papermod-cover.png</url>
      <link>https://flecart.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.143.1</generator>
    <language>en</language>
    <atom:link href="https://flecart.github.io/tags/theoretical-computer-science/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Estensioni di Turing e altre macchine</title>
      <link>https://flecart.github.io/notes/estensioni-di-turing-e-altre-macchine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/estensioni-di-turing-e-altre-macchine/</guid>
      <description>&lt;p&gt;Sono variazioni possibili equivalenti:
• Nastri addizionali • Testine addizionali • Nastri infiniti su entrambi i lati • Non-determinismo • Scelta probabilistica • Scelta quantistica
Si può dire che la definizione di TM è stata &lt;strong&gt;robusta&lt;/strong&gt; nella storia perché tantissimi formalismi che intuitivamente sembrano essere molto diversi rispetto alla TM alla fine possono essere dimostrate essere equivalenti.&lt;/p&gt;
&lt;h3 id=&#34;turing-con-nastri-addizionali&#34;&gt;Turing con nastri addizionali&lt;/h3&gt;
&lt;p&gt;Questo è presente in modo abbastanza facile sul Sipser.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Interactive Theorem Provers</title>
      <link>https://flecart.github.io/notes/interactive-theorem-provers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/interactive-theorem-provers/</guid>
      <description>&lt;p&gt;Most of times the pattern of proving and verifying it is like this $prove \to verify$, that is: there is an entity that generates the solution, andPo then another that tries to verify it.
But more expressive algorithms could be possible if there is &lt;strong&gt;interaction&lt;/strong&gt; between the two entities, ones that try to prove it, and others try to verify it.
From some point of view, this is similar from what AlphaGo does when searching, there is a part that guides the search, another that actually searches for it. Or the modern &lt;a href=&#34;https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/&#34;&gt;alpha geometry&lt;/a&gt; in modern times.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Time and Space Complexity</title>
      <link>https://flecart.github.io/notes/time-and-space-complexity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/time-and-space-complexity/</guid>
      <description>&lt;p&gt;In this note we explore a theme of time and space complexity. Those are cardinal themes in Theoretical CS.
Time -&amp;gt; execution step bounds on algorithms
Space -&amp;gt; the cells visited by a &lt;a href=&#34;https://flecart.github.io/notes/la-macchina-di-turing&#34;&gt;Turing Machine&lt;/a&gt; when executed.&lt;/p&gt;
&lt;h2 id=&#34;introduction-to-time-complexity&#34;&gt;Introduction to Time Complexity&lt;/h2&gt;
&lt;p&gt;This note will build upon know techniques of algorithms analysis explained in &lt;a href=&#34;https://flecart.github.io/notes/notazione-asintotica&#34;&gt;Notazione Asintotica&lt;/a&gt;.
We will need big-$O$ notation and $o$ notation.
L&amp;rsquo;idea è che il problema di decisione è decidibile se limito la lunghezza del teorema.
Simile al &lt;a href=&#34;https://en.wikipedia.org/wiki/Chaitin%27s_constant&#34;&gt;numero di Chaitin&lt;/a&gt;, che non è computabile, ma è approssimabile quanto si vuole. In un certo senso è computabile.
The general idea is to ask how the function $\varphi$ that maps the longest $n$ proof to the number of steps of computation behaves.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Common problems in Theoretical CS</title>
      <link>https://flecart.github.io/notes/common-problems-in-theoretical-cs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/common-problems-in-theoretical-cs/</guid>
      <description>&lt;p&gt;This note is useful to gather in a single place the description of some common problems in CS and their theoretical implications explained in other notes.&lt;/p&gt;
&lt;h2 id=&#34;the-clique-problem&#34;&gt;The Clique problem&lt;/h2&gt;
&lt;h3 id=&#34;description-of-the-problem&#34;&gt;Description of the problem&lt;/h3&gt;
&lt;p&gt;This problem is in NP, find all sub-graphs where all nodes are connected (this set of nodes forms a complete graph).&lt;/p&gt;
&lt;p&gt;We can prove that the problem is in NP because there is an easy non-deterministic algorithm that computes it.
See &lt;a href=&#34;https://flecart.github.io/notes/time-and-space-complexity#clique-problem&#34;&gt;Time and Space Complexity#Clique problem&lt;/a&gt; for details of this proof.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Complexity Hierarchies</title>
      <link>https://flecart.github.io/notes/complexity-hierarchies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/complexity-hierarchies/</guid>
      <description>&lt;p&gt;Intractable problems are solvable in principle, but in reality they require so much time or space that there no physical computers that can solve them in reasonable time.
We would like to define a clear hierarchy of these set of problems.&lt;/p&gt;
&lt;h2 id=&#34;space-hierarchies&#34;&gt;Space Hierarchies&lt;/h2&gt;
&lt;h3 id=&#34;def-space-constructible&#34;&gt;Def: Space constructible&lt;/h3&gt;
&lt;p&gt;We say that a function $f: \mathbb{N} \to \mathbb{N}$ such that $f(n) \geq O(\log n)$ is space constructible if there exists a function from $1^{n} \to \langle f(n) \rangle$ is $O(f(n))$ &lt;a href=&#34;https://flecart.github.io/notes/time-and-space-complexity&#34;&gt;space complexity&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cook-Levin and Savitch</title>
      <link>https://flecart.github.io/notes/cook-levin-and-savitch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/cook-levin-and-savitch/</guid>
      <description>&lt;p&gt;Cook Levin theorem is important because says that in 1971 if $SAT \in P$ then $NP = P$. We will start with this idea to define the concept of &lt;strong&gt;NP-completeness&lt;/strong&gt;. Let&amp;rsquo;s start with the basics.&lt;/p&gt;
&lt;h3 id=&#34;poly-reduction&#34;&gt;Poly-reduction&lt;/h3&gt;
&lt;h4 id=&#34;def-poly-reduction&#34;&gt;Def: poly-reduction&lt;/h4&gt;
$$
x \in L&#39; \iff f(x) \in L
$$&lt;p&gt;
This is very similar to the &lt;a href=&#34;https://flecart.github.io/notes/halting-theorem-and-reducibility#mapping-reducibility&#34;&gt;Halting Theorem and Reducibility#Mapping reducibility&lt;/a&gt;.
The difference is that it needs to be &lt;em&gt;polynomially-bounded&lt;/em&gt;, so to say, it is efficient function.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Halting Theorem and Reducibility</title>
      <link>https://flecart.github.io/notes/halting-theorem-and-reducibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/halting-theorem-and-reducibility/</guid>
      <description>&lt;h3 id=&#34;halting-theorem&#34;&gt;Halting theorem&lt;/h3&gt;
&lt;p&gt;Questo è un problema fondamentale, che abbiamo trattato anche in &lt;a href=&#34;https://flecart.github.io/notes/fondamenti-teorica#halting-problem&#34;&gt;Fondamenti teorica#Halting problem&lt;/a&gt;, ma qui lo ritrattiamo, perché così lo rifacciamo per bene. In parte è stato trattato anche al corso di Logica.&lt;/p&gt;
&lt;h4 id=&#34;enunciato-halting-theorem&#34;&gt;Enunciato Halting theorem&lt;/h4&gt;
$$
HALT = \left\{ \langle x, y \rangle \in \Sigma^{*} \times \Sigma^{*}: x = code(M),M \text{ si ferma su } x\right\}
$$&lt;h4 id=&#34;dimostrazione-halting-theorem&#34;&gt;Dimostrazione Halting theorem&lt;/h4&gt;
&lt;p&gt;La parte del sì è facile perché basta eseguirlo e vedere che si ferma (quindi abbiamo una &lt;a href=&#34;https://flecart.github.io/notes/la-macchina-di-turing#la-macchina-di-turing-universale&#34;&gt;La macchina di Turing#La macchina di Turing universale&lt;/a&gt;. Se si ferma appartiene al linguaggio, altrimenti è la parte in cui diverge.&lt;/p&gt;</description>
    </item>
    <item>
      <title>La macchina di Turing</title>
      <link>https://flecart.github.io/notes/la-macchina-di-turing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/la-macchina-di-turing/</guid>
      <description>&lt;h3 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h3&gt;
&lt;h4 id=&#34;note-filosofiche-non-impo&#34;&gt;Note filosofiche (non impo)&lt;/h4&gt;
&lt;p&gt;Bisogna in primo momento cercare di definire &lt;strong&gt;cosa è la computazione&lt;/strong&gt; e cosa è un computer.
Aristotele faceva la distinzione fra proprietà &lt;strong&gt;essenziali&lt;/strong&gt; e &lt;strong&gt;accidentali&lt;/strong&gt;. Quelle essenziali sono proprie dell&amp;rsquo;oggetto.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Una sedia può essere fatta di legno o di metallo, ma questa proprietà è accidentale, ovvero, essa rimane una sedia indipendentemente dal materiale di cui è fatta.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Solitamente in matematica si prova ad astrarre (vedi &lt;a href=&#34;https://flecart.github.io/notes/astrazione-sul-controllo&#34;&gt;Astrazione sul controllo&lt;/a&gt; per nota generale sull&amp;rsquo;astrazione). Però in questo campo si sono trovati molte concezioni equivalenti. Fino ad arrivare a concepire la tesi di Church-Turing. Il prof. nota che questo è strano, perché in altre discipline si converge in unico modello, mentre qui molte cose sono indifferenti.
Questo è importante per capire come la concezione di Computer Science si è evoluta &lt;a href=&#34;https://dl.acm.org/doi/10.1145/1880066.1880067&#34;&gt;(Denning 2010)&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Teorema di Rice</title>
      <link>https://flecart.github.io/notes/teorema-di-rice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/teorema-di-rice/</guid>
      <description>&lt;h2 id=&#34;introduction-to-the-rice-theorem&#34;&gt;Introduction to the Rice Theorem&lt;/h2&gt;
&lt;p&gt;Ci sono molti teoremi che non possono essere decisi, vedere &lt;a href=&#34;https://flecart.github.io/notes/halting-theorem-and-reducibility&#34;&gt;Halting Theorem and Reducibility&lt;/a&gt;.
Qui andiamo a chiederci quale sia l&amp;rsquo;insieme dei problemi decidibili.&lt;/p&gt;
&lt;h3 id=&#34;proprietà-dei-linguaggi-tm&#34;&gt;Proprietà dei linguaggi TM&lt;/h3&gt;
$$
L_{\mathcal{M}} = \left\{ x \in \Sigma^{*}: \mathcal{M} \text{ accetta } x \right\} 
$$$$
L_{\mathcal{M}} = L_{\mathcal{M}&#39;} \implies P(\mathcal{M}) = P(\mathcal{M}&#39;)
$$&lt;p&gt;
Definiamo questa &lt;strong&gt;non triviale&lt;/strong&gt; se esiste una macchina per cui è 0, e una per cui è 1 (ossia non è costante).
Practically this definition is useful when we need to have a difference between the language and the Turing machine that decides that language.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Probabilistic Turing Machines</title>
      <link>https://flecart.github.io/notes/probabilistic-turing-machines/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/probabilistic-turing-machines/</guid>
      <description>&lt;h2 id=&#34;introduction-to-the-probabilistic-turing-machine&#34;&gt;Introduction to the probabilistic Turing Machine&lt;/h2&gt;
&lt;p&gt;Most of real phenomena are better comprehended by a probabilistic view. This pushes to build a formal model that takes probability into account&lt;/p&gt;
&lt;h3 id=&#34;def-probabilistic-tm&#34;&gt;Def: Probabilistic TM&lt;/h3&gt;
$$
\mathbb{P}(b) = 2^{-k}
$$&lt;p&gt;
Where $k$ is the length of the branch.
Then the probability of accepting the word is given by this:&lt;/p&gt;
$$
\mathbb{P}(\mathcal{M} \text{ accepts }  \omega) = \sum_{b \text{ is an accepting branch}} \mathbb{P}(b)
$$&lt;p&gt;
Note that this is very similar to the Algorithmic probability defined in &lt;a href=&#34;https://flecart.github.io/notes/kolmogorov-complexity&#34;&gt;Kolmogorov complexity&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
