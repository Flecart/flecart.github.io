<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>üìàOptimization on X. Angelo Huang&#39;s Blog</title>
    <link>https://flecart.github.io/tags/optimization/</link>
    <description>Recent content in üìàOptimization on X. Angelo Huang&#39;s Blog</description>
    <image>
      <title>X. Angelo Huang&#39;s Blog</title>
      <url>https://flecart.github.io/images/papermod-cover.png</url>
      <link>https://flecart.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.143.1</generator>
    <language>en</language>
    <atom:link href="https://flecart.github.io/tags/optimization/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Lagrange Multipliers</title>
      <link>https://flecart.github.io/notes/lagrange-multipliers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/lagrange-multipliers/</guid>
      <description>&lt;p&gt;This is also known as &lt;em&gt;Lagrange Optimization&lt;/em&gt; or &lt;em&gt;undetermined multipliers&lt;/em&gt;. Some of these notes are based on Appendix E of &lt;a href=&#34;https://link.springer.com/book/9780387310732&#34;&gt;(Bishop 2006)&lt;/a&gt;, others were found when studying bits of rational mechanics.
Also &lt;a href=&#34;https://web.stanford.edu/~boyd/cvxbook/&#34;&gt;(Boyd &amp;amp; Vandenberghe 2004)&lt;/a&gt; chapter 5 should be a good resource on this topic.&lt;/p&gt;
$$
\begin{array} \\
\min f_{0}(x)  \\
\text{subject to } f_{i}(x) \leq 0 \\
h_{j}(x) = 0
\end{array}
$$&lt;h3 id=&#34;lagrangian-function&#34;&gt;Lagrangian function&lt;/h3&gt;
$$
\mathcal{L}(x, \lambda, \nu) = f_{0}(x) + \sum \lambda_{i}f_{i}(x) + \sum\nu_{j}h_{j}(x)
$$&lt;p&gt;
We want to say something about this function, because it is able to simplify the optimization problem a lot, but first we want to study this mathematically.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Problemi di accoppiamento</title>
      <link>https://flecart.github.io/notes/problemi-di-accoppiamento/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/problemi-di-accoppiamento/</guid>
      <description>&lt;p&gt;I problem idi accoppiamento sono abbastanza comuni per ottimizzazione a grafi. In questa serie di note andiamo a trattare brevemente i problemi principali, con un accenno veloce ad alcuni algoritmi di soluzione per esse.&lt;/p&gt;
&lt;h3 id=&#34;grafo-bipartito&#34;&gt;Grafo bipartito&lt;/h3&gt;
&lt;p&gt;Un grafo bipartito √® un insieme $(O \cup D), (A)$ di nodi e di archi. Tutti i nodi sono o fra i nodi di origine oppure fra i nodi di destinazione, e gli archi sono solamente collegati fra nodi di origine e nodi di destinazione.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reti di flusso</title>
      <link>https://flecart.github.io/notes/reti-di-flusso/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/reti-di-flusso/</guid>
      <description>&lt;p&gt;Questi problemi sono una &lt;strong&gt;sottoclasse della programmazione lineare&lt;/strong&gt; con variabili reali. (Alcuni riescono a riconoscere se un problema √® in questa forma, e lo risolvono in modo istantaneo se questo succede).&lt;/p&gt;
&lt;p&gt;Un problema dei router √® un classico problema di flusso, che si risolvono con questi algoritmi polinomiali&lt;/p&gt;
&lt;h2 id=&#34;note-introduttive&#34;&gt;Note introduttive&lt;/h2&gt;
&lt;h3 id=&#34;rete-terminologia&#34;&gt;Rete, terminologia&lt;/h3&gt;
&lt;p&gt;In questo caso andiamo ad indicare con rete un grafo con $G = (N, A)$ con $N$ nodi e $A$ archi, che solitamente sono diretti con pesi associati.
Possiamo interpretare gli archi come &lt;strong&gt;canali&lt;/strong&gt; in cui fluiranno un qualcosa (ad esempio acqua in un tubo). Questi possono essere discreti o continui (mi sembra di ricordare che il discreto stranamente √® pi√π facile del continuo, non  so se vale anche in questo caso).
Abbiamo poi i &lt;em&gt;nodi&lt;/em&gt; che sono &lt;strong&gt;punti di ingresso e uscita&lt;/strong&gt; della nostra rete.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tarjan e MCMF</title>
      <link>https://flecart.github.io/notes/tarjan-e-mcmf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/tarjan-e-mcmf/</guid>
      <description>&lt;p&gt;Questa sezione la tengo separata rispetto agli altri per favorire lo studio, cos√¨ questa roba nuova la ripasso pi√π spesso, in seguito si pu√≤ accorpare.&lt;/p&gt;
&lt;h2 id=&#34;goldberg-tarjanpush-relabel&#34;&gt;Goldberg Tarjan/Push-relabel&lt;/h2&gt;
&lt;p&gt;Questo algoritmo √® importante perch√© introduce ragionamenti sul &lt;strong&gt;minimo locale&lt;/strong&gt; che possa alla fine essere ricomposto come soluzione globale.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0hI89H39USg&#34;&gt;Questa lezione youtube&lt;/a&gt; lo spiega da Dio&lt;/p&gt;
&lt;h3 id=&#34;preflusso&#34;&gt;Preflusso&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Tarjan e MCMF/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Tarjan e MCMF/Untitled&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La parte nuova di questa cosa √® che i vincoli di bilanciamento possono diventare una disuguaglianza. (cio√® quello che arriva √® di pi√π rispetto quanto va fuori.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Programmazione lineare</title>
      <link>https://flecart.github.io/notes/programmazione-lineare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/programmazione-lineare/</guid>
      <description>&lt;p&gt;Vogliamo cercare di restare nel nostro spazio delle soluzioni ammissibili, senza dover stare ad esplorare tutto, vogliamo andare a concentrarci su una parte specifica di essa. Vogliamo utilizzare una struttura fondamentale per i problemi di programmazione lineare, che √® quello con cui vogliamo andare a fare. Il fatto √® che spostandoci leggermente da un punto tra le soluzioni, possiamo gestire in modo molto semplice il modo con cui si sposta la retta dei valori.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Duality Theory</title>
      <link>https://flecart.github.io/notes/duality-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/duality-theory/</guid>
      <description>&lt;p&gt;√à una branca dell&amp;rsquo;algebra lineare che ci permette di semplificare tutti i concetti.&lt;/p&gt;
&lt;h2 id=&#34;intro-dualit√†&#34;&gt;Intro dualit√†&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&amp;quot;/images/notes/image/universita/ex-notion/Programmazione lineare/Untitled 8.png&amp;quot; style=&amp;quot;width: 100%&amp;quot; class=&amp;quot;center&amp;quot; alt=&amp;quot;image/universita/ex-notion/Programmazione lineare/Untitled 8&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Si fa una sorta di trasposta alla matrice di A.&lt;/li&gt;
&lt;li&gt;y √® pari al numero di righe di A&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La trasformazione al duale √® molto facile, ed √® abbastanza intuitiva una volta che capiamo che vogliamo andare a fare l‚Äôupper bound.&lt;/p&gt;
&lt;h3 id=&#34;dualit√†-asimmetrica&#34;&gt;Dualit√† asimmetrica&lt;/h3&gt;
&lt;h3 id=&#34;teorema-debole-di-dualit√†&#34;&gt;Teorema debole di dualit√†&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduzione a ottimizzazione Combinatoria</title>
      <link>https://flecart.github.io/notes/introduzione-a-ottimizzazione-combinatoria/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduzione-a-ottimizzazione-combinatoria/</guid>
      <description>&lt;p&gt;L‚Äôottimizzazione combinatoria √® un altro nome per la ricerca operativa. √à uno &lt;strong&gt;strumento&lt;/strong&gt; utile a prendere le decisioni migliori, fatto sta che √® anche molto utile al machine learning e si potrebbe dire che ne sia una base, questa √® una cosa molto buona.&lt;/p&gt;
&lt;h2 id=&#34;ricerca-operativa&#34;&gt;Ricerca operativa&lt;/h2&gt;
&lt;p&gt;Questo √® un campo a &lt;strong&gt;forte impatto economico&lt;/strong&gt; perch√© prova a minimizzare i costi e massimizzare i profitti.&lt;/p&gt;
&lt;h3 id=&#34;steps&#34;&gt;Steps&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Individuazione del problema (almeno riconoscere che ci sia un problema)&lt;/li&gt;
&lt;li&gt;Raccoglimento dei dati&lt;/li&gt;
&lt;li&gt;Modellizzazione del problema&lt;/li&gt;
&lt;li&gt;Ricerca di una soluzione&lt;/li&gt;
&lt;li&gt;Analisi dei risultati della soluzione&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;La ricerca operativa si interessa principalmente degli step 3 e 4, nonostante gli steps non sempre vengono eseguiti in maniera lineare, ma c‚Äô√® un ciclo di feedback a riguardo.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Modelizzazione</title>
      <link>https://flecart.github.io/notes/modelizzazione/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/modelizzazione/</guid>
      <description>&lt;h1 id=&#34;programmazione-lineare&#34;&gt;Programmazione lineare&lt;/h1&gt;
&lt;p&gt;Programmazione lineare contiene alcuni algoritmi utili per risolvere certi problemi di ottimizzazione.&lt;/p&gt;
&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;Andiamo in questa sezione a definire un problema di programmazione lineare&lt;/p&gt;
&lt;h3 id=&#34;definizione&#34;&gt;Definizione&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Variabili reali&lt;/em&gt; che saranno le variabili del nostro problema, sono in numero finito (eg. tutti in Rn)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Funzione obiettivo&lt;/em&gt; che ci definisce il costo $f: \R^n \to \R$&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Vincoli lineari&lt;/em&gt; che limitano il dominio delle variabili reali e li mettono in relazione fra di loro&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Se le variabili appartengono agli interi andiamo a parlare di &lt;strong&gt;programmazione lineare intera&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Simplesso e B&amp;B</title>
      <link>https://flecart.github.io/notes/simplesso-e-bb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/simplesso-e-bb/</guid>
      <description>&lt;h2 id=&#34;algoritmo-del-simplesso&#34;&gt;Algoritmo del simplesso&lt;/h2&gt;
&lt;h3 id=&#34;ricerca-della-direzione-migliore&#34;&gt;Ricerca della direzione migliore&lt;/h3&gt;
&lt;h3 id=&#34;ricerca-dello-step&#34;&gt;Ricerca dello step&lt;/h3&gt;
&lt;h3 id=&#34;pseudocodice&#34;&gt;Pseudocodice&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;
&lt;p&gt;B sono gli indici di partenza, poi questi vengono aggiornati&lt;/p&gt;
  &lt;img src=&#34;https://flecart.github.io/images/notes/image/universita/ex-notion/Simplesso e B&amp;B/Untitled.png&#34; style=&#34;width: 100%&#34; class=&#34;center&#34; alt=&#34;image/universita/ex-notion/Simplesso e B&amp;B/Untitled&#34;&gt;
&lt;p&gt;In riga 5 vado a checkare se ho &lt;strong&gt;direzioni di crescita possibili&lt;/strong&gt;, se √® tutto positivo non ne ho.&lt;/p&gt;
&lt;p&gt;in riga 6, si sceglie il pi√π piccol per &lt;strong&gt;evitare loop&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;L&amp;rsquo;idea in generale va in questo modo&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Cerco di trovare il duale e confrontarlo con la x attuale
&lt;ol&gt;
&lt;li&gt;Se sono uguali, allora ho trovato l‚Äôottimo ed esco&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Altrimenti cerco una direzione di crescita che sia anche ammissibile&lt;/li&gt;
&lt;li&gt;Continuo fino a trovare un vertice, se ho il vertice allora mi muovo l√¨ e riapplico,
altrimenti √® illimitata, se non esiste un vertice.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;correttezza&#34;&gt;Correttezza&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Slide&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
