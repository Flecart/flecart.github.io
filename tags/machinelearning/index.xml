<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Machinelearning on X. Angelo Huang&#39;s Blog</title>
    <link>https://flecart.github.io/tags/machinelearning/</link>
    <description>Recent content in Machinelearning on X. Angelo Huang&#39;s Blog</description>
    <image>
      <title>X. Angelo Huang&#39;s Blog</title>
      <url>https://flecart.github.io/images/papermod-cover.png</url>
      <link>https://flecart.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <atom:link href="https://flecart.github.io/tags/machinelearning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Na√Øve Bayes</title>
      <link>https://flecart.github.io/notes/na%C3%AFve-bayes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/na%C3%AFve-bayes/</guid>
      <description>Introduzione a Na√Øve Bayes Bisognerebbe in primo momento avere benissimo in mente il significato di probabilit√† condizionata e la regola di naive Bayes in seguito.
Bayes ad alto livello üü© Da un punto di vista intuitivo non √® altro che predire la cosa che abbiamo visto pi√π spesso in quello spazio Assunzioni principali per na√Øve Bayes üü© I sample di input sono condizionalmente indipendenti uno con l&amp;rsquo;altro. Questo permette di utilizzare questa ipotesi $$ P(X_{1}\dots X_{n} | Y = y_{i}) = \prod_{i}^{n} P(X_{i} | Y) $$ E permette di rendere la parte di inferenza anche molto semplice perch√© per classificare un caso basta prendere label con la probabilit√† maggiore.</description>
    </item>
    <item>
      <title>Bag of words</title>
      <link>https://flecart.github.io/notes/bag-of-words/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/bag-of-words/</guid>
      <description>Bag of words only takes into account the count of the words inside a document, ignoring all the syntax and boundaries. This method is very common for email classifications techniques.
Introduzione a bag of words Faremo una introduzione di applicazione di Na√Øve Bayes applicato alla classificazione di documenti.
Setting del problema üü®+ Questo √® una parte che √® importante nel caso volessimo fare document classification. e simili, In questa brevissima introduzione cerchiamo di calcolare $$ \theta_{i, \text{word}, l} = P(X_{i} = \text{word} | Y = l) $$ Ossia quanto √® probabile che una parola sia word, che appaia alla posizione i, data la categoria $l$ del documento Assumendo che non dipenda dalla posizione posso solamente contare le parole per documento fregandomene della posizione, questa √® l&amp;rsquo;idea che ha portato ai primi approcci in questo campo.</description>
    </item>
    <item>
      <title>Alberi di decisione</title>
      <link>https://flecart.github.io/notes/alberi-di-decisione/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/alberi-di-decisione/</guid>
      <description>Introduzione agli alberi di decisione Setting del problema üü©- Spazio delle ipotesi Definizione spazio ipotesi üü©&amp;mdash; Per spazio delle ipotesi andiamo a considerare l&amp;rsquo;insieme delle funzioni rappresentabili dal nostro modello. Questo implica che l&amp;rsquo;allenamento ricerca l&amp;rsquo;ipotesi ossia la parametrizzazione ottimale del nostro modello, ottimale in quanto minimizza l&amp;rsquo;errore che viene compiuto nel training set.
L&amp;rsquo;insieme iniziale si pu√≤ anche considerare come inductive bias ossia il restringimento solamente a certe ipotesi e non tutte.</description>
    </item>
    <item>
      <title>Object detection and Segmentation</title>
      <link>https://flecart.github.io/notes/object-detection-and-segmentation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/object-detection-and-segmentation/</guid>
      <description>Definition of problems Object detection Bisogna trovare all&amp;rsquo;interno dell&amp;rsquo;immagine quali siano gli oggetti presenti, e in pi√π vogliamo sapere dove siano quindi utilizzare una bounding box per caratterizzarli sarebbe buono.
Object segmentation √à riuscire a caratterizzare categoria per categoria per singoli pixelsm e per questo motivo potrei riuscire a fare delle image map in cui colorare singoli oggetti in una categoria.
Datasets Example datasets Pascal VOC 2012 Coco datasets Cityscapes dataset Autogenerated datasets But I don&amp;rsquo;t know much about these datasets Applications Auto drive Campo medico (per segmentazione medica o riconoscimento immagini).</description>
    </item>
    <item>
      <title>Autoencoders</title>
      <link>https://flecart.github.io/notes/autoencoders/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/autoencoders/</guid>
      <description>In questa serie di appunti proviamo a descrivere tutto quello che sappiamo al meglio riguardanti gli autoencoders Blog di riferimento Blog secondario che sembra buono
Introduzione agli autoencoders L&amp;rsquo;idea degli autoencoders √® rappresentare la stessa cosa attraverso uno spazio minore, in un certo senso √® la compressione con loss. Per cosa intendiamo qualunque tipologia di dato, che pu√≤ spaziare fra immagini, video, testi, musica e simili. Qualunque cosa che noi possiamo rappresentare in modo digitale possiamo costruirci un autoencoder.</description>
    </item>
    <item>
      <title>Reti convoluzionali</title>
      <link>https://flecart.github.io/notes/reti-convoluzionali/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/reti-convoluzionali/</guid>
      <description>Abbiamo trattato i modelli classici in Convolutional NN. Con i vecchi files di notion
Il Kernel I punti interessanti delle immagini sono solamente i punti di cambio solo che attualmente siamo in stato discreto, quindi ci √® difficile usare una derivata, si usano kernel del tipo: $\left[ 1, 0, -1 \right]$, che sar√† positivo se cresce verso sinistra, negativo se scende. feature map Sono delle mappe che rappresentano alcune informazioni interessanti della nostra immagine.</description>
    </item>
    <item>
      <title>Backpropagation</title>
      <link>https://flecart.github.io/notes/backpropagation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/backpropagation/</guid>
      <description>Backpropagation is perhaps the most important algorithm of the 21th century. It is used everywhere in machine learning. It has also connected to computing marginal distributions. This is the motivation why all machine learning scientists, all data scientists should understand this algorithm very well. An important observation is that this algorithm is linear: the time complexity is the same as the forward pass. Karpathy has a nice resource for this topic.</description>
    </item>
    <item>
      <title>Proximal Policy Optimization</title>
      <link>https://flecart.github.io/notes/proximal-policy-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/proximal-policy-optimization/</guid>
      <description>(Schulman et al. 2017) √® uno degli articoli principali che praticamente hanno dato via al campo. Anche questo √® buono per Policy gradients:
https://lilianweng.github.io/posts/2018-04-08-policy-gradient/
Introduzione a PPO References [1] Schulman et al. ‚ÄúProximal Policy Optimization Algorithms‚Äù 2017</description>
    </item>
    <item>
      <title>The RLHF pipeline</title>
      <link>https://flecart.github.io/notes/the-rlhf-pipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/the-rlhf-pipeline/</guid>
      <description>https://huyenchip.com/2023/05/02/rlhf.html √® un blog post che lo descrive in modo abbastanza dettagliato e buono.
Introduzione a RLHF Questo √® il processo che √® quasi la migliore per la produzione di LLM moderni (maggior parte si basano su questo per dire).
Struttura generale Si pu√≤ dire che RLHF si divida in 3 parti fondamentali
Completion il modello viene allenato a completare parole dal web,solitamente √® molto inutile Fine tuning per le singole task, per esempio riassumere, rispondere in certo modo etc.</description>
    </item>
    <item>
      <title>Word Embeddings</title>
      <link>https://flecart.github.io/notes/word-embeddings/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/word-embeddings/</guid>
      <description>Theory Johnson-Lindenstrauss Lemma This lemma basically says that semantic embedding is possible, without giving a real algorithm to do so. This seems to be a nice resource about this lemma.
For any $0 &lt; \varepsilon &lt; 1$ and any $k$ bigger than $f(\varepsilon)\log n$ (see the reference for $f(\varepsilon)$ its a simple function). The for any $n \in \mathbb{R}^{d}$ there is a function $f: \mathbb{R}^{d} \to \mathbb{R}^{k}$ such that $\forall x_{i} x_{j} \in A$ we have $$ (1 - \varepsilon)\lVert x_{i} - x_{j} \rVert ^{2} \leq \lVert f(x_{i}) - f(x_{j}) \rVert^{2} \leq (1 + \varepsilon) \lVert x_{i} - x_{j} \rVert ^{2} $$ It says that the pairwise distances can be preserved (if meaning is relation between different entities, then this is everything that is needed to keep that concept almost unaltered.</description>
    </item>
    <item>
      <title>Logistic Regression</title>
      <link>https://flecart.github.io/notes/logistic-regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/logistic-regression/</guid>
      <description>Introduzione alla logistic regression Questo documento, per come √® scritto, lo giudico il 2024-08-10 Lettera a Nicole pressoch√© inutile.
Giustificazione del metodo Questo √® uno dei modelli classici, creati da Minsky qualche decennio fa In questo caso andiamo direttamente a computare il valore di $P(Y|X)$ durante l&amp;rsquo;inferenza, quindi si parla di modello discriminativo.
Introduzione al problema Supponiamo che
$Y$ siano variabili booleane $X_{i}$ siano variabili continue $X_{i}$ siano indipendenti uno dall&amp;rsquo;altro.</description>
    </item>
    <item>
      <title>Tokenization</title>
      <link>https://flecart.github.io/notes/tokenization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/tokenization/</guid>
      <description>Introduction to tokenization Tokenization is the process of converting normal strings into small little pieces that could be fed into one of our models. It usually comes from a tradition in programming languages, as we can see in Automi e Regexp where we define a specific token to have a known pattern, usually recognized by regular expressions.
There have been historically been many approaches to tokenization, let&amp;rsquo;s see a few:</description>
    </item>
  </channel>
</rss>
