<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Statistics on X. Angelo Huang&#39;s Blog</title>
    <link>https://flecart.github.io/tags/statistics/</link>
    <description>Recent content in Statistics on X. Angelo Huang&#39;s Blog</description>
    <image>
      <title>X. Angelo Huang&#39;s Blog</title>
      <url>https://flecart.github.io/images/papermod-cover.png</url>
      <link>https://flecart.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.143.1</generator>
    <language>en</language>
    <lastBuildDate>Thu, 29 Aug 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://flecart.github.io/tags/statistics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bias Variance Trade-off</title>
      <link>https://flecart.github.io/notes/bias-variance-trade-off/</link>
      <pubDate>Tue, 18 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/bias-variance-trade-off/</guid>
      <description>&lt;p&gt;This note should be considered deprecated.
There is not much about Bias Variance Trade-off, and its quite random and old. For a correct derivation for this, you should consider looking at &lt;a href=&#34;https://flecart.github.io/notes/linear-regression-methods&#34;&gt;Linear Regression methods&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;È una cosa ormai risaputa che c&amp;rsquo;è una sorta di trade-off fra la varianza e il bias per una certo modello. Aumentare la varianza del modello certamente ci permetterà di avere un modello che abbia un errore di training molto basso, però appena vede dei dati nuovi non sarà in grado di generalizzare correttamente.
Dall&amp;rsquo;altra parte avere un bias alto significa avere un modello eccessivamente semplice, poco flessibile, che comunque allenato non riesce ad avere una grande accuratezza né in fase di allenamento, né di in fase di validazione o di test.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to statistical learning</title>
      <link>https://flecart.github.io/notes/introduction-to-statistical-learning/</link>
      <pubDate>Thu, 29 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-statistical-learning/</guid>
      <description>&lt;h2 id=&#34;introduzione&#34;&gt;Introduzione&lt;/h2&gt;
&lt;p&gt;This is a short introduction to statistical learning, made with the help of the book &lt;a href=&#34;https://link.springer.com/10.1007/978-3-031-38747-0&#34;&gt;(James et al. 2023)&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;statistical learning refers to a set of approaches for estimating $f$ .&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;utilizzi-del-statistical-learning&#34;&gt;Utilizzi del statistical learning&lt;/h3&gt;
&lt;p&gt;Solitamente sono due gli utilizzi &lt;strong&gt;Predizione&lt;/strong&gt; e &lt;strong&gt;inferenza&lt;/strong&gt;. Per predizione intendiamo il miglior modello che possa produrre le Y che ancora non conosciamo.
Per inferenza significa il miglior modello f per predire Y che conosciamo.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
