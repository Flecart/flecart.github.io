<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Statistics on X. Angelo Huang&#39;s Blog</title>
    <link>https://flecart.github.io/tags/statistics/</link>
    <description>Recent content in Statistics on X. Angelo Huang&#39;s Blog</description>
    <image>
      <title>X. Angelo Huang&#39;s Blog</title>
      <url>https://flecart.github.io/images/papermod-cover.png</url>
      <link>https://flecart.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <atom:link href="https://flecart.github.io/tags/statistics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bias Variance Trade-off</title>
      <link>https://flecart.github.io/notes/bias-variance-trade-off/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/bias-variance-trade-off/</guid>
      <description>This note should be considered deprecated. There is not much about Bias Variance Trade-off, and its quite random and old. For a correct derivation for this, you should consider looking at Linear Regression methods.
Introduction È una cosa ormai risaputa che c&amp;rsquo;è una sorta di trade-off fra la varianza e il bias per una certo modello. Aumentare la varianza del modello certamente ci permetterà di avere un modello che abbia un errore di training molto basso, però appena vede dei dati nuovi non sarà in grado di generalizzare correttamente.</description>
    </item>
    <item>
      <title>Introduction to statistical learning</title>
      <link>https://flecart.github.io/notes/introduction-to-statistical-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://flecart.github.io/notes/introduction-to-statistical-learning/</guid>
      <description>Introduzione This is a short introduction to statistical learning, made with the help of the book (James et al. 2023).
statistical learning refers to a set of approaches for estimating $f$ .
Utilizzi del statistical learning Solitamente sono due gli utilizzi Predizione e inferenza. Per predizione intendiamo il miglior modello che possa produrre le Y che ancora non conosciamo. Per inferenza significa il miglior modello f per predire Y che conosciamo.</description>
    </item>
  </channel>
</rss>
